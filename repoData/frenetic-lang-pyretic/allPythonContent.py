__FILENAME__ = conf
# -*- coding: utf-8 -*-
#
# Pyretic documentation build configuration file, created by
# sphinx-quickstart on Fri Oct 25 03:45:52 2013.
#
# This file is execfile()d with the current directory set to its
# containing dir.
#
# Note that not all possible configuration values are present in this
# autogenerated file.
#
# All configuration values have a default; values that are commented out
# serve to show the default.

import sys
import os

# If extensions (or modules to document with autodoc) are in another directory,
# add these directories to sys.path here. If the directory is relative to the
# documentation root, use os.path.abspath to make it absolute, like shown here.
#sys.path.insert(0, os.path.abspath('.'))

# -- General configuration ------------------------------------------------

# If your documentation needs a minimal Sphinx version, state it here.
#needs_sphinx = '1.0'

# Add any Sphinx extension module names here, as strings. They can be
# extensions coming with Sphinx (named 'sphinx.ext.*') or your custom
# ones.
extensions = [
    'sphinx.ext.autodoc',
    'sphinx.ext.intersphinx',
    'sphinx.ext.ifconfig',
    'sphinx.ext.inheritance_diagram'
]

# Add any paths that contain templates here, relative to this directory.
templates_path = ['_templates']

# The suffix of source filenames.
source_suffix = '.rst'

# The encoding of source files.
#source_encoding = 'utf-8-sig'

# The master toctree document.
master_doc = 'index'

# General information about the project.
project = u'Pyretic'
copyright = u'2013, Team Pyretic'

# The version info for the project you're documenting, acts as replacement for
# |version| and |release|, also used in various other places throughout the
# built documents.
#
# The short X.Y version.
version = '0.2.2'
# The full version, including alpha/beta/rc tags.
release = '0.2.2'

# The language for content autogenerated by Sphinx. Refer to documentation
# for a list of supported languages.
#language = None

# There are two options for replacing |today|: either, you set today to some
# non-false value, then it is used:
#today = ''
# Else, today_fmt is used as the format for a strftime call.
#today_fmt = '%B %d, %Y'

# List of patterns, relative to source directory, that match files and
# directories to ignore when looking for source files.
exclude_patterns = ['_build']

# The reST default role (used for this markup: `text`) to use for all
# documents.
#default_role = None

# If true, '()' will be appended to :func: etc. cross-reference text.
#add_function_parentheses = True

# If true, the current module name will be prepended to all description
# unit titles (such as .. function::).
#add_module_names = True

# If true, sectionauthor and moduleauthor directives will be shown in the
# output. They are ignored by default.
#show_authors = False

# The name of the Pygments (syntax highlighting) style to use.
pygments_style = 'sphinx'

# A list of ignored prefixes for module index sorting.
#modindex_common_prefix = []

# If true, keep warnings as "system message" paragraphs in the built documents.
#keep_warnings = False


# -- Options for HTML output ----------------------------------------------

# The theme to use for HTML and HTML Help pages.  See the documentation for
# a list of builtin themes.
html_theme = 'default'

# Theme options are theme-specific and customize the look and feel of a theme
# further.  For a list of options available for each theme, see the
# documentation.
#html_theme_options = {}

# Add any paths that contain custom themes here, relative to this directory.
#html_theme_path = []

# The name for this set of Sphinx documents.  If None, it defaults to
# "<project> v<release> documentation".
#html_title = None

# A shorter title for the navigation bar.  Default is the same as html_title.
#html_short_title = None

# The name of an image file (relative to this directory) to place at the top
# of the sidebar.
#html_logo = None

# The name of an image file (within the static path) to use as favicon of the
# docs.  This file should be a Windows icon file (.ico) being 16x16 or 32x32
# pixels large.
#html_favicon = None

# Add any paths that contain custom static files (such as style sheets) here,
# relative to this directory. They are copied after the builtin static files,
# so a file named "default.css" will overwrite the builtin "default.css".
html_static_path = ['_static']

# Add any extra paths that contain custom files (such as robots.txt or
# .htaccess) here, relative to this directory. These files are copied
# directly to the root of the documentation.
#html_extra_path = []

# If not '', a 'Last updated on:' timestamp is inserted at every page bottom,
# using the given strftime format.
#html_last_updated_fmt = '%b %d, %Y'

# If true, SmartyPants will be used to convert quotes and dashes to
# typographically correct entities.
#html_use_smartypants = True

# Custom sidebar templates, maps document names to template names.
#html_sidebars = {}

# Additional templates that should be rendered to pages, maps page names to
# template names.
#html_additional_pages = {}

# If false, no module index is generated.
#html_domain_indices = True

# If false, no index is generated.
#html_use_index = True

# If true, the index is split into individual pages for each letter.
#html_split_index = False

# If true, links to the reST sources are added to the pages.
#html_show_sourcelink = True

# If true, "Created using Sphinx" is shown in the HTML footer. Default is True.
#html_show_sphinx = True

# If true, "(C) Copyright ..." is shown in the HTML footer. Default is True.
#html_show_copyright = True

# If true, an OpenSearch description file will be output, and all pages will
# contain a <link> tag referring to it.  The value of this option must be the
# base URL from which the finished HTML is served.
#html_use_opensearch = ''

# This is the file name suffix for HTML files (e.g. ".xhtml").
#html_file_suffix = None

# Output file base name for HTML help builder.
htmlhelp_basename = 'Pyreticdoc'


# -- Options for LaTeX output ---------------------------------------------

latex_elements = {
# The paper size ('letterpaper' or 'a4paper').
#'papersize': 'letterpaper',

# The font size ('10pt', '11pt' or '12pt').
#'pointsize': '10pt',

# Additional stuff for the LaTeX preamble.
#'preamble': '',
}

# Grouping the document tree into LaTeX files. List of tuples
# (source start file, target name, title,
#  author, documentclass [howto, manual, or own class]).
latex_documents = [
  ('index', 'Pyretic.tex', u'Pyretic Documentation',
   u'Team Pyretic', 'manual'),
]

# The name of an image file (relative to this directory) to place at the top of
# the title page.
#latex_logo = None

# For "manual" documents, if this is true, then toplevel headings are parts,
# not chapters.
#latex_use_parts = False

# If true, show page references after internal links.
#latex_show_pagerefs = False

# If true, show URL addresses after external links.
#latex_show_urls = False

# Documents to append as an appendix to all manuals.
#latex_appendices = []

# If false, no module index is generated.
#latex_domain_indices = True


# -- Options for manual page output ---------------------------------------

# One entry per manual page. List of tuples
# (source start file, name, description, authors, manual section).
man_pages = [
    ('index', 'pyretic', u'Pyretic Documentation',
     [u'Team Pyretic'], 1)
]

# If true, show URL addresses after external links.
#man_show_urls = False


# -- Options for Texinfo output -------------------------------------------

# Grouping the document tree into Texinfo files. List of tuples
# (source start file, target name, title, author,
#  dir menu entry, description, category)
texinfo_documents = [
  ('index', 'Pyretic', u'Pyretic Documentation',
   u'Team Pyretic', 'Pyretic', 'One line description of project.',
   'Miscellaneous'),
]

# Documents to append as an appendix to all manuals.
#texinfo_appendices = []

# If false, no module index is generated.
#texinfo_domain_indices = True

# How to display URL addresses: 'footnote', 'no', or 'inline'.
#texinfo_show_urls = 'footnote'

# If true, do not generate a @detailmenu in the "Top" node's menu.
#texinfo_no_detailmenu = False


# Example configuration for intersphinx: refer to the Python standard library.
intersphinx_mapping = {'http://docs.python.org/': None}


inheritance_graph_attrs = dict(rankdir="LR", size='"11.0, 8.0"', ratio='compress')

########NEW FILE########
__FILENAME__ = extra-topos

from mininet.topo import Topo

class ChainTopo(Topo):
 
    def __init__(self, numSwitches, numClients, numServers=0, noIP=False):

        # Add default members to class.
        super(ChainTopo, self ).__init__()

        switch_inds = range(1,numSwitches+1)
        self.add_switches(switch_inds)
        self.connect_switches(switch_inds)

        client_ids = ['h'+str(i) for i in range(1,numClients+1)]
        server_ids = ['hs'+str(i) for i in range(1,numServers+1)]

        self.add_hosts(client_ids + server_ids,noIP)
        self.connect_hosts(switch_inds,client_ids,server_ids)

    def add_switches(self,switch_inds):
        for i in switch_inds:
            self.addSwitch('s'+str(i))

    def add_hosts(self,host_ids,noIP):
        for i in host_ids:
            if not noIP:
                self.addHost(i)
            else:
                self.addHost(i,ip=None)

    def connect_switches(self,switch_ids):

        # Topology trivial if less than 2 switch_ids
        if len(switch_ids) < 2:
            return

        # Connect switches in chain topology
        for s in switch_ids[:-1]:
            self.addLink('s'+str(s), 's'+str(s+1))

    def connect_hosts(self,switch_inds,client_ids,server_ids):
        # Connect nodes, divide them evenly across the switch_inds
        s = switch_inds[0]
        h = client_ids + server_ids
        hps = max(len(h) // len(switch_inds),1)
        while len(h) > 0:
            l = h[:hps]
            h = h[hps:]
            for j in l:
                self.addLink('s'+str(s),j)
            if [s] == switch_inds[-1:]:
                s = switch_inds[0]
            else:
                s += 1


class CycleTopo(ChainTopo):

    def connect_switches(self,switch_inds):

        # Topology trivial if less than 2 switches
        if len(switch_inds) < 3:
            raise Exception("Cycles must have at least three switches (use 'linear,2' for n=2, 'single' for n=1)")

        # Connect Switches in cycle topology
        for s in switch_inds:
            self.addLink('s'+str(s), 's'+str(1 + s % len(switch_inds)))


class CliqueTopo(ChainTopo):

    def connect_switches(self,switch_inds):
        # Topology trivial if less than 2 switches
        if len(switch_inds) < 3:
            raise Exception("Cliques must have at least three switches (use 'linear,2' for n=2, 'single' for n=1)")

        # Connect Switches in clique topology
        for s1 in switch_inds:
            for s2 in switch_inds:
                if s2 <= s1:
                    continue
                self.addLink('s'+str(s1), 's'+str(s2))


class BumpChainTopo(ChainTopo):

    def add_switches(self,switch_inds):
        super(BumpChainTopo, self ).add_switches(switch_inds)
        self.addSwitch('s101')
        self.addSwitch('s102')

    def connect_switches(self,switch_inds):
        super(BumpChainTopo, self ).connect_switches(switch_inds)
        self.addLink('s101','s'+str(switch_inds[0]))
        self.addLink('s102','s'+str(switch_inds[-1]))

    def connect_hosts(self,switch_inds,client_ids,server_ids):
        for client_id in client_ids:
            self.addLink('s101',client_id)
        for server_id in server_ids:
            self.addLink('s102',server_id)


class BumpCycleTopo(CycleTopo):

    def add_switches(self,switch_inds):
        super(BumpCycleTopo, self ).add_switches(switch_inds)
        self.addSwitch('s101')
        self.addSwitch('s102')

    def connect_switches(self,switch_inds):
        super(BumpCycleTopo, self ).connect_switches(switch_inds)
        self.addLink('s101','s'+str(switch_inds[0]))
        self.addLink('s102','s'+str(switch_inds[len(switch_inds) // 2]))

    def connect_hosts(self,switch_inds,client_ids,server_ids):
        for client_id in client_ids:
            self.addLink('s101',client_id)
        for server_id in server_ids:
            self.addLink('s102',server_id)


class BumpCliqueTopo(CliqueTopo):

    def add_switches(self,switch_inds):
        super(BumpCliqueTopo, self ).add_switches(switch_inds)
        self.addSwitch('s101')
        self.addSwitch('s102')

    def connect_switches(self,switch_inds):
        super(BumpCliqueTopo, self ).connect_switches(switch_inds)
        self.addLink('s101','s'+str(switch_inds[0]))
        self.addLink('s102','s'+str(switch_inds[len(switch_inds) // 2]))

    def connect_hosts(self,switch_inds,client_ids,server_ids):
        for client_id in client_ids:
            self.addLink('s101',client_id)
        for server_id in server_ids:
            self.addLink('s102',server_id)


class OneSwitchGatewayTopoNoSubnets(Topo):
    def __init__(self, numClients=3, numServers=3):        
        super(OneSwitchGatewayTopoNoSubnets, self).__init__()

        client_inds = range(1,numClients+1)
        server_inds = range(1,numServers+1)

        num_switches_left = 3
        num_switches_right = 3

        self.addSwitch('s1')
        for switch_id in xrange(2, 2 + num_switches_left + num_switches_right): 
            self.addSwitch('s'+str(switch_id))

        from mininet.util import ipParse,ipAdd
        
        for c in client_inds:
            self.addHost('h'+str(c))

        for s in server_inds: 
            self.addHost('hs'+str(s))
        
        # Ethernet side
        self.addLink('s1', 's2')  # s1[1] -- s2[1]
        self.addLink('s1', 's3')  # s1[2] -- s3[1]
        self.addLink('s2', 's4')  # s2[2] -- s4[1]
        self.addLink('s3', 's4')  # s3[2] -- s4[2]
        for c in client_inds:
            self.addLink('s'+str(c % num_switches_left + 2), 'h'+str(c))

        # IP side
        self.addLink('s1', 's5')  # s1[3] -- s5[1]
        self.addLink('s1', 's6')  # s1[4] -- s6[1]
        self.addLink('s5', 's7')  # s5[2] -- s7[1]
        self.addLink('s6', 's7')  # s6[2] -- s7[1]
        for s in server_inds:
            self.addLink('s'+str(s % num_switches_right + 2 + num_switches_left), 'hs'+str(s))


class ThreeSwitchGatewayTopoNoSubnets(Topo):
    def __init__(self, numClients=3, numServers=3):        
        super(ThreeSwitchGatewayTopoNoSubnets, self).__init__()

        client_inds = range(1,numClients+1)
        server_inds = range(1,numServers+1)

        num_switches_left = 3
        num_switches_right = 3

        self.addSwitch('s1000')
        self.addSwitch('s1001')
        self.addSwitch('s1002')
        for switch_id in xrange(2, 2 + num_switches_left + num_switches_right): 
            self.addSwitch('s'+str(switch_id))

        from mininet.util import ipParse,ipAdd
        
        for c in client_inds:
            self.addHost('h'+str(c))

        for s in server_inds: 
            self.addHost('hs'+str(s))

        # Ethernet side
        self.addLink('s1000', 's2')    # s1000[1] -- s2[1]
        self.addLink('s1000', 's3')    # s1000[2] -- s3[1]
        self.addLink('s2', 's4')       # s2[2] -- s4[1]
        self.addLink('s3', 's4')       # s3[2] -- s4[2]
        for c in client_inds:
            self.addLink('s'+str(c % num_switches_left + 2), 'h'+str(c))
        
        # IP side
        self.addLink('s1002', 's5')    # s1002[1] -- s5[1]
        self.addLink('s1002', 's6')    # s1002[2] -- s6[1]
        self.addLink('s5', 's7')       # s5[2] -- s7[1]
        self.addLink('s6', 's7')       # s6[2] -- s7[1]
        for s in server_inds:
            self.addLink('s'+str(s % num_switches_right + 2 + num_switches_left), 'hs'+str(s))

        # Link up physical gateway series
        self.addLink('s1001','s1000')  # s1001[1] -- s1000[3]
        self.addLink('s1001','s1002')  # s1001[2] -- s1002[3]


class OneSwitchGatewayTopo(Topo):
    def __init__(self, numClients=3, numServers=3):        
        super(OneSwitchGatewayTopo, self).__init__()

        prefix_size  = 24
        left_prefix  = '10.0.0.'
        right_prefix = '10.0.1.'

        client_inds = range(1,numClients+1)
        server_inds = range(1,numServers+1)

        num_switches_left = 3
        num_switches_right = 3

        self.addSwitch('s1')
        for switch_id in xrange(2, 2 + num_switches_left + num_switches_right): 
            self.addSwitch('s'+str(switch_id))

        from mininet.util import ipParse,ipAdd
        
        for c in client_inds:
            ipstr = left_prefix + str(c+1) + '/' + str(prefix_size)
            self.addHost('h'+str(c), ip=ipstr, gw=left_prefix+'1', gw_mac='AA:AA:AA:AA:AA:AA')

        for s in server_inds: 
            ipstr = right_prefix + str(s+1) + '/' + str(prefix_size)
            self.addHost('hs'+str(s), ip=ipstr, gw=right_prefix+'1', gw_mac='AA:AA:AA:AA:AA:AA')
        
        # Ethernet side
        self.addLink('s1', 's2')  # s1[1] -- s2[1]
        self.addLink('s1', 's3')  # s1[2] -- s3[1]
        self.addLink('s2', 's4')  # s2[2] -- s4[1]
        self.addLink('s3', 's4')  # s3[2] -- s4[2]
        for c in client_inds:
            self.addLink('s'+str(c % num_switches_left + 2), 'h'+str(c))

        # IP side
        self.addLink('s1', 's5')  # s1[3] -- s5[1]
        self.addLink('s1', 's6')  # s1[4] -- s6[1]
        self.addLink('s5', 's7')  # s5[2] -- s7[1]
        self.addLink('s6', 's7')  # s6[2] -- s7[1]
        for s in server_inds:
            self.addLink('s'+str(s % num_switches_right + 2 + num_switches_left), 'hs'+str(s))
            

class ThreeSwitchGatewayTopo(Topo):
    def __init__(self, numClients=3, numServers=3):        
        super(ThreeSwitchGatewayTopo, self).__init__()

        prefix_size  = 24
        left_prefix  = '10.0.0.'
        right_prefix = '10.0.1.'

        client_inds = range(1,numClients+1)
        server_inds = range(1,numServers+1)

        num_switches_left = 3
        num_switches_right = 3

        self.addSwitch('s1000')
        self.addSwitch('s1001')
        self.addSwitch('s1002')
        for switch_id in xrange(2, 2 + num_switches_left + num_switches_right): 
            self.addSwitch('s'+str(switch_id))

        from mininet.util import ipParse,ipAdd

        for c in client_inds:
            ipstr = left_prefix + str(c+1) + '/' + str(prefix_size)
            self.addHost('h'+str(c), ip=ipstr, gw=left_prefix+'1', gw_mac='AA:AA:AA:AA:AA:AA')

        for s in server_inds: 
            ipstr = right_prefix + str(s+1) + '/' + str(prefix_size)
            self.addHost('hs'+str(s), ip=ipstr, gw=right_prefix+'1', gw_mac='AA:AA:AA:AA:AA:AA')
        
        # Ethernet side
        self.addLink('s1000', 's2')    # s1000[1] -- s2[1]
        self.addLink('s1000', 's3')    # s1000[2] -- s3[1]
        self.addLink('s2', 's4')       # s2[2] -- s4[1]
        self.addLink('s3', 's4')       # s3[2] -- s4[2]
        for c in client_inds:
            self.addLink('s'+str(c % num_switches_left + 2), 'h'+str(c))
        
        # IP side
        self.addLink('s1002', 's5')    # s1002[1] -- s5[1]
        self.addLink('s1002', 's6')    # s1002[2] -- s6[1]
        self.addLink('s5', 's7')       # s5[2] -- s7[1]
        self.addLink('s6', 's7')       # s6[2] -- s7[1]
        for s in server_inds:
            self.addLink('s'+str(s % num_switches_right + 2 + num_switches_left), 'hs'+str(s))

        # Link up physical gateway series
        self.addLink('s1001','s1000')  # s1001[1] -- s1000[3]
        self.addLink('s1001','s1002')  # s1001[2] -- s1002[3]


class SimplePrefixTopo(Topo):
    def __init__(self):
        
        # Add default members to class.
        super(SimplePrefixTopo, self).__init__()

        # Set Node IDs for hosts and switches

        self.addHost('h1', ip='10.0.0.1')
        self.addHost('h2', ip='10.0.0.2')
        self.addHost('h3', ip='10.0.0.5')
        self.addSwitch('s1')

        # Add edges
        self.addLink('s1', 'h1')
        self.addLink('s1', 'h2')
        self.addLink('s1', 'h3')


topos = { 'triangle': ( lambda: CycleTopo(3,3) ), 
          'square': (lambda: CycleTopo(4,4)),
          'chain': ChainTopo,
          'clique': CliqueTopo,
          'cycle': CycleTopo,
          'bump_chain': BumpChainTopo,
          'bump_cycle': BumpCycleTopo,
          'bump_clique': BumpCliqueTopo,
          'gateway1': OneSwitchGatewayTopo,
          'gateway1_ns': OneSwitchGatewayTopoNoSubnets,
          'gateway3': ThreeSwitchGatewayTopo,
          'gateway3_ns': ThreeSwitchGatewayTopoNoSubnets,
          'simple_prefix': SimplePrefixTopo
}
 

########NEW FILE########
__FILENAME__ = pox_client

################################################################################
# The Pyretic Project                                                          #
# frenetic-lang.org/pyretic                                                    #
# author: Joshua Reich (jreich@cs.princeton.edu)                               #
# author: Christopher Monsanto (chris@monsan.to)                               #
################################################################################
# Licensed to the Pyretic Project by one or more contributors. See the         #
# NOTICES file distributed with this work for additional information           #
# regarding copyright and ownership. The Pyretic Project licenses this         #
# file to you under the following license.                                     #
#                                                                              #
# Redistribution and use in source and binary forms, with or without           #
# modification, are permitted provided the following conditions are met:       #
# - Redistributions of source code must retain the above copyright             #
#   notice, this list of conditions and the following disclaimer.              #
# - Redistributions in binary form must reproduce the above copyright          #
#   notice, this list of conditions and the following disclaimer in            #
#   the documentation or other materials provided with the distribution.       #
# - The names of the copyright holds and contributors may not be used to       #
#   endorse or promote products derived from this work without specific        #
#   prior written permission.                                                  #
#                                                                              #
# Unless required by applicable law or agreed to in writing, software          #
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT    #
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the     #
# LICENSE file distributed with this work for specific language governing      #
# permissions and limitations under the License.                               #
################################################################################

import threading

import pox.openflow.libopenflow_01 as of
from pox.core import core
from pox.lib import revent, addresses as packetaddr, packet as packetlib
from pox.lib.packet.ethernet      import ethernet
from pox.lib.packet.ethernet      import LLDP_MULTICAST, NDP_MULTICAST
from pox.lib.packet.lldp          import lldp, chassis_id, port_id, end_tlv
from pox.lib.packet.lldp          import ttl, system_description

from pyretic.backend.comm import *

def inport_value_hack(outport):
    if outport > 1:
        return 1
    else:
        return 2


class BackendChannel(asynchat.async_chat):
    """Sends messages to the server and receives responses.
    """
    def __init__(self, host, port, of_client):
        self.of_client = of_client
        self.received_data = []
        asynchat.async_chat.__init__(self)
        self.create_socket(socket.AF_INET, socket.SOCK_STREAM)
        self.connect((host, port))
        self.ac_in_buffer_size = 4096 * 3
        self.ac_out_buffer_size = 4096 * 3
        self.set_terminator(TERM_CHAR)
        return

    def handle_connect(self):
        print "Connected to pyretic frontend."
        
    def collect_incoming_data(self, data):
        """Read an incoming message from the client and put it into our outgoing queue."""
        with self.of_client.channel_lock:
            self.received_data.append(data)

    def dict2OF(self,d):
        def convert(h,val):
            if h in ['srcmac','dstmac']:
                return packetaddr.EthAddr(val)
            elif h in ['srcip','dstip']:
                try:
                    return packetaddr.IPAddr(val)
                except:
                    return val
            elif h in ['vlan_id','vlan_pcp'] and val == 'None':
                return None
            else:
                return val
        return { h : convert(h,val) for (h, val) in d.items()}

    def found_terminator(self):
        """The end of a command or message has been seen."""
        with self.of_client.channel_lock:
            msg = deserialize(self.received_data)

        # USE DESERIALIZED MSG
        if msg[0] == 'inject_discovery_packet':
            switch = msg[1]
            port = msg[2]
            self.of_client.inject_discovery_packet(switch,port)
        elif msg[0] == 'packet':
            packet = self.dict2OF(msg[1])
            self.of_client.send_to_switch(packet)
        elif msg[0] == 'install':
            pred = self.dict2OF(msg[1])
            priority = int(msg[2])
            actions = map(self.dict2OF,msg[3])
            self.of_client.install_flow(pred,priority,actions)
        elif msg[0] == 'delete':
            pred = self.dict2OF(msg[1])
            priority = int(msg[2])
            self.of_client.delete_flow(pred,priority)
        elif msg[0] == 'clear':
            switch = int(msg[1])
            self.of_client.clear(switch)
        elif msg[0] == 'barrier':
            switch = msg[1]
            self.of_client.barrier(switch)
        elif msg[0] == 'flow_stats_request':
            switch = msg[1]
            self.of_client.flow_stats_request(switch)
        else:
            print "ERROR: Unknown msg from frontend %s" % msg


class POXClient(revent.EventMixin):
    # NOT **kwargs
    def __init__(self,show_traces=False,debug_packet_in=False,ip='127.0.0.1',port=BACKEND_PORT):
        self.switches = {}
        self.show_traces = show_traces
        self.debug_packet_in = debug_packet_in
        self.packetno = 0
        self.channel_lock = threading.Lock()

        if core.hasComponent("openflow"):
            self.listenTo(core.openflow)

        self.backend_channel = BackendChannel(ip, port, self)
        self.adjacency = {} # From Link to time.time() stamp

    def packet_from_network(self, **kwargs):
        return kwargs

    def packet_to_network(self, packet):
        return packet['raw']

    def _handle_ComponentRegistered (self, event):
        if event.name == "openflow":
            self.listenTo(core.openflow)
            return EventRemove # We don't need this listener anymore

    def active_ofp_port_config(self,configs):
        active = []
        for (config,bit) in of.ofp_port_config_rev_map.items():
            if configs & bit:
                active.append(config)
        return active

    def active_ofp_port_state(self,states):
        """get active ofp port state values
        NOTE: POX's doesn't match ofp_port_state_rev_map"""
        active = []
        for (state,bit) in of.ofp_port_state_rev_map.items():
            if states & bit:
                active.append(state)
        return active

    def active_ofp_port_features(self,features):
        active = []
        for (feature,bit) in of.ofp_port_features_rev_map.items():
            if features & bit:
                active.append(feature)
        return active

    def inspect_ofp_phy_port(self,port,prefix=""):
        print "%sport_no:     " % prefix, 
        port_id = port.port_no
        for name,port_no in of.ofp_port_rev_map.iteritems():
            if port.port_no == port_no:
                port_id = name
        print port_id
        print "%shw_addr:     " % prefix, 
        print port.hw_addr
        print "%sname:        " % prefix, 
        print port.name
        print "%sconfig:      " % prefix, 
        print self.active_ofp_port_config(port.config)
        print "%sstate:       " % prefix, 
        print self.active_ofp_port_state(port.state)
        print "%scurr:        " % prefix, 
        print self.active_ofp_port_features(port.curr)
        print "%sadvertised:  " % prefix, 
        print self.active_ofp_port_features(port.advertised)
        print "%ssupported:   " % prefix, 
        print self.active_ofp_port_features(port.supported)
        print "%speer:        " % prefix, 
        print self.active_ofp_port_features(port.peer)


    def create_discovery_packet (self, dpid, port_num, port_addr):
        """
        Build discovery packet
        """
        import pox.lib.packet as pkt
        chassis_id = pkt.chassis_id(subtype=pkt.chassis_id.SUB_LOCAL)
        chassis_id.id = bytes('dpid:' + hex(long(dpid))[2:-1])
        
        port_id = pkt.port_id(subtype=pkt.port_id.SUB_PORT, id=str(port_num))

        ttl = pkt.ttl(ttl = 120)

        sysdesc = pkt.system_description()
        sysdesc.payload = bytes('dpid:' + hex(long(dpid))[2:-1])

        discovery_packet = pkt.lldp()
        discovery_packet.tlvs.append(chassis_id)
        discovery_packet.tlvs.append(port_id)
        discovery_packet.tlvs.append(ttl)
        discovery_packet.tlvs.append(sysdesc)
        discovery_packet.tlvs.append(pkt.end_tlv())

        eth = pkt.ethernet(type=pkt.ethernet.LLDP_TYPE)
        eth.src = port_addr
        eth.dst = pkt.ETHERNET.NDP_MULTICAST
        eth.payload = discovery_packet

        po = of.ofp_packet_out(action = of.ofp_action_output(port=port_num))
        po.data = eth.pack()
        return po.pack()


    def inject_discovery_packet(self,switch, port):
        try:
            hw_addr = self.switches[switch]['ports'][port]
            packet = self.create_discovery_packet(switch, port, hw_addr)
            core.openflow.sendToDPID(switch, packet)
        except KeyError:
            pass


    def send_to_pyretic(self,msg):
        serialized_msg = serialize(msg)
        try:
            with self.channel_lock:
                self.backend_channel.push(serialized_msg)
        except IndexError as e:
            print "ERROR PUSHING MESSAGE %s" % msg
            pass


    def send_to_switch(self,packet):
        switch = packet["switch"]
        outport = packet["outport"]
        try:
            inport = packet["inport"]
            if inport == -1 or inport == outport:
                inport = inport_value_hack(outport)
        except KeyError:
            inport = inport_value_hack(outport)
        
        msg = of.ofp_packet_out()
        msg.in_port = inport
        msg.data = self.packet_to_network(packet)
        msg.actions.append(of.ofp_action_output(port = outport))
 
        if self.show_traces:
            print "========= POX/OF SEND ================"
            print msg
            print packetlib.ethernet(msg._get_data())
            print

        ## HANDLE PACKETS SEND ON LINKS THAT HAVE TIMED OUT
        try:
            self.switches[switch]['connection'].send(msg)
        except RuntimeError, e:
            print "ERROR:send_to_switch: %s to switch %d" % (str(e),switch)
            # TODO - ATTEMPT TO RECONNECT SOCKET
        except KeyError, e:
            print "ERROR:send_to_switch: No connection to switch %d available" % switch
            # TODO - IF SOCKET RECONNECTION, THEN WAIT AND RETRY

    def build_of_match(self,switch,inport,pred):
        ### BUILD OF MATCH
        match = of.ofp_match()
        match.in_port = inport
        if 'srcmac' in pred:
            match.dl_src = pred['srcmac']
        if 'dstmac' in pred:
            match.dl_dst = pred['dstmac']
        if 'ethtype' in pred:
            match.dl_type = pred['ethtype']
        if 'vlan_id' in pred:
            match.dl_vlan = pred['vlan_id']
        if 'vlan_pcp' in pred:
            match.dl_vlan_pcp = pred['vlan_pcp']
        if 'protocol' in pred:
            match.nw_proto = pred['protocol']
        if 'srcip' in pred:
            match.set_nw_src(pred['srcip'])
        if 'dstip' in pred:
            match.set_nw_dst(pred['dstip'])
        if 'tos' in pred:
            match.nw_tos = pred['tos']
        if 'srcport' in pred:
            match.tp_src = pred['srcport']
        if 'dstport' in pred:
            match.tp_dst = pred['dstport']
        return match

    def build_of_actions(self,inport,action_list):
        ### BUILD OF ACTIONS
        of_actions = []
        for actions in action_list:
            outport = actions['outport']
            del actions['outport']
            if 'srcmac' in actions:
                of_actions.append(of.ofp_action_dl_addr.set_src(actions['srcmac']))
            if 'dstmac' in actions:
                of_actions.append(of.ofp_action_dl_addr.set_dst(actions['dstmac']))
            if 'srcip' in actions:
                of_actions.append(of.ofp_action_nw_addr.set_src(actions['srcip']))
            if 'dstip' in actions:
                of_actions.append(of.ofp_action_nw_addr.set_dst(actions['dstip']))
            if 'srcport' in actions:
                of_actions.append(of.ofp_action_tp_port.set_src(actions['srcport']))
            if 'dstport' in actions:
                of_actions.append(of.ofp_action_tp_port.set_dst(actions['dstport']))
            if 'vlan_id' in actions:
                if actions['vlan_id'] is None:
                    of_actions.append(of.ofp_action_strip_vlan())
                else:
                    of_actions.append(of.ofp_action_vlan_vid(vlan_vid=actions['vlan_id']))
            if 'vlan_pcp' in actions:
                if actions['vlan_pcp'] is None:
                    if not actions['vlan_id'] is None:
                        raise RuntimeError("vlan_id and vlan_pcp must be set together!")
                    pass
                else:
                    of_actions.append(of.ofp_action_vlan_pcp(vlan_pcp=actions['vlan_pcp']))
            if (not inport is None) and (outport == inport):
                of_actions.append(of.ofp_action_output(port=of.OFPP_IN_PORT))
            else:
                of_actions.append(of.ofp_action_output(port=outport))
        return of_actions

    def install_flow(self,pred,priority,action_list):
        switch = pred['switch']
        if 'inport' in pred:        
            inport = pred['inport']
        else:
            inport = None
        match = self.build_of_match(switch,inport,pred)
        of_actions = self.build_of_actions(inport,action_list)
        msg = of.ofp_flow_mod(command=of.OFPFC_ADD,
                              priority=priority,
                              idle_timeout=of.OFP_FLOW_PERMANENT,
                              hard_timeout=of.OFP_FLOW_PERMANENT,
                              match=match,
                              actions=of_actions)
        try:
            self.switches[switch]['connection'].send(msg)
        except RuntimeError, e:
            print "WARNING:install_flow: %s to switch %d" % (str(e),switch)
        except KeyError, e:
            print "WARNING:install_flow: No connection to switch %d available" % switch

    def delete_flow(self,pred,priority):
        switch = pred['switch']
        if 'inport' in pred:        
            inport = pred['inport']
        else:
            inport = None
        match = self.build_of_match(switch,inport,pred)
        msg = of.ofp_flow_mod(command=of.OFPFC_DELETE_STRICT,
                              priority=priority,
                              match=match)
        try:
            self.switches[switch]['connection'].send(msg)
        except RuntimeError, e:
            print "WARNING:delete_flow: %s to switch %d" % (str(e),switch)
        except KeyError, e:
            print "WARNING:delete_flow: No connection to switch %d available" % switch

    def barrier(self,switch):
        b = of.ofp_barrier_request()
        self.switches[switch]['connection'].send(b) 

    def flow_stats_request(self,switch):
        sr = of.ofp_stats_request()
        sr.body = of.ofp_flow_stats_request()
        match = of.ofp_match()
        sr.body.match = match
        sr.body.table_id = 0xff
        sr.body.out_port = of.OFPP_NONE
        self.switches[switch]['connection'].send(sr) 
    
    def clear(self,switch=None):
        if switch is None:
            for switch in self.switches.keys():
                self.clear(switch)
        else:
            d = of.ofp_flow_mod(command = of.OFPFC_DELETE)
            self.switches[switch]['connection'].send(d) 

    def _handle_ConnectionUp(self, event):
        assert event.dpid not in self.switches
        
        self.switches[event.dpid] = {}
        self.switches[event.dpid]['connection'] = event.connection
        self.switches[event.dpid]['ports'] = {}

        msg = of.ofp_flow_mod(match = of.ofp_match())
        msg.actions.append(of.ofp_action_output(port = of.OFPP_CONTROLLER))
        self.switches[event.dpid]['connection'].send(msg) 

        self.send_to_pyretic(['switch','join',event.dpid,'BEGIN'])

        # port type is ofp_phy_port
        for port in event.ofp.ports:
            if port.port_no <= of.OFPP_MAX:
                self.switches[event.dpid]['ports'][port.port_no] = port.hw_addr
                CONF_UP = not 'OFPPC_PORT_DOWN' in self.active_ofp_port_config(port.config)
                STAT_UP = not 'OFPPS_LINK_DOWN' in self.active_ofp_port_state(port.state)
                self.send_to_pyretic(['port','join',event.dpid, port.port_no, CONF_UP, STAT_UP])                        
   
        self.send_to_pyretic(['switch','join',event.dpid,'END'])

                        
    def _handle_ConnectionDown(self, event):
        assert event.dpid in self.switches

        del self.switches[event.dpid]
        self.send_to_pyretic(['switch','part',event.dpid])


    def of_match_to_dict(self, m):
        h = {}
        if not m.in_port is None:
            h["inport"] = m.in_port
        if not m.dl_src is None:
            h["srcmac"] = m.dl_src.toRaw()
        if not m.dl_dst is None:
            h["dstmac"] = m.dl_dst.toRaw()
        if not m.dl_type is None:
            h["ethtype"] = m.dl_type
        if not m.dl_vlan is None:
            h["vlan_id"] = m.dl_vlan
        if not m.dl_vlan_pcp is None:
            h["vlan_pcp"] = m.dl_vlan_pcp
        if not m.nw_src is None:
            h["srcip"] = m.nw_src.toRaw()
        if not m.nw_dst is None:
            h["dstip"] = m.nw_dst.toRaw()
        if not m.nw_proto is None:
            h["protocol"] = m.nw_proto
        if not m.nw_tos is None:
            h["tos"] = m.nw_tos
        if not m.tp_src is None:
            h["srcport"] = m.tp_src
        if not m.tp_dst is None:
            h["dstport"] = m.tp_dst
        return h

    def of_actions_to_dicts(self, actions):
        action_dicts = []
        for a in actions:
            d = {}
            if a.type == of.OFPAT_OUTPUT:
                d['output'] = a.port
            elif a.type == of.OFPAT_ENQUEUE:
                d['enqueue'] = a.port
            elif a.type == of.OFPAT_STRIP_VLAN:
                d['strip_vlan_id'] = 0
            elif a.type == of.OFPAT_SET_VLAN_VID:
                d['vlan_id'] = a.vlan_vid
            elif a.type == of.OFPAT_SET_VLAN_PCP:
                d['vlan_pcp'] = a.vlan_pcp
            elif a.type == of.OFPAT_SET_DL_SRC:
                d['srcmac'] = a.dl_addr.toRaw()
            elif a.type == of.OFPAT_SET_DL_DST:
                d['dstmac'] = a.dl_addr.toRaw()
            elif a.type == of.OFPAT_SET_NW_SRC:
                d['srcip'] = a.nw_addr.toRaw()
            elif a.type == of.OFPAT_SET_NW_DST:
                d['dstip'] = a.nw_addr.toRaw()
            elif a.type == of.OFPAT_SET_NW_TOS:
                d['tos'] = a.nw_tos
            elif a.type == of.OFPAT_SET_TP_SRC:
                d['srcport'] = a.tp_port
            elif a.type == of.OFPAT_SET_TP_DST:
                d['dstport'] = a.tp_port
            action_dicts.append(d)
        return action_dicts

    def _handle_FlowStatsReceived (self, event):
        dpid = event.connection.dpid
        def handle_ofp_flow_stat(flow_stat):
            flow_stat_dict = {}
            flow_stat_dict['table_id'] = flow_stat.table_id 
            #flow_stat.match
            flow_stat_dict['duration_sec'] = flow_stat.duration_sec
            flow_stat_dict['duration_nsec'] = flow_stat.duration_nsec
            flow_stat_dict['priority'] = flow_stat.priority
            flow_stat_dict['idle_timeout'] = flow_stat.idle_timeout
            flow_stat_dict['hard_timeout'] = flow_stat.hard_timeout
            flow_stat_dict['cookie'] = flow_stat.cookie    
            flow_stat_dict['packet_count'] = flow_stat.packet_count
            flow_stat_dict['byte_count'] = flow_stat.byte_count
            match = self.of_match_to_dict(flow_stat.match)
            flow_stat_dict['match'] = match
            actions = self.of_actions_to_dicts(flow_stat.actions)
            flow_stat_dict['actions'] = actions
            return flow_stat_dict
        flow_stats = [handle_ofp_flow_stat(s) for s in event.stats]
        self.send_to_pyretic(['flow_stats_reply',dpid,flow_stats])

    def _handle_PortStatus(self, event):
        port = event.ofp.desc
        if event.port <= of.OFPP_MAX:
            if event.added:
                self.switches[event.dpid]['ports'][event.port] = event.ofp.desc.hw_addr
                #self.runtime.network.port_joins.signal((event.dpid, event.port))
                CONF_UP = not 'OFPPC_PORT_DOWN' in self.active_ofp_port_config(port.config)
                STAT_UP = not 'OFPPS_LINK_DOWN' in self.active_ofp_port_state(port.state)
                self.send_to_pyretic(['port','join',event.dpid, port.port_no, CONF_UP, STAT_UP])
            elif event.deleted:
                try:
                    del self.switches[event.dpid]['ports'][event.port] 
                except KeyError:
                    pass  # SWITCH ALREADY DELETED
                self.send_to_pyretic(['port','part',event.dpid,event.port])
            elif event.modified:
                CONF_UP = not 'OFPPC_PORT_DOWN' in self.active_ofp_port_config(port.config)
                STAT_UP = not 'OFPPS_LINK_DOWN' in self.active_ofp_port_state(port.state)
                self.send_to_pyretic(['port','mod',event.dpid, event.port, CONF_UP, STAT_UP])
            else:
                raise RuntimeException("Unknown port status event")


    def handle_lldp(self,packet,event):
        import pox.lib.packet as pkt
        from pox.openflow.discovery import Discovery, LinkEvent
        import time

        lldph = packet.find(pkt.lldp)
        if lldph is None or not lldph.parsed:
            return
        if len(lldph.tlvs) < 3:
            return
        if lldph.tlvs[0].tlv_type != pkt.lldp.CHASSIS_ID_TLV:
            return
        if lldph.tlvs[1].tlv_type != pkt.lldp.PORT_ID_TLV:
            return
        if lldph.tlvs[2].tlv_type != pkt.lldp.TTL_TLV:
            return

        def lookInSysDesc ():
            r = None
            for t in lldph.tlvs[3:]:
                if t.tlv_type == pkt.lldp.SYSTEM_DESC_TLV:
                    # This is our favored way...
                    for line in t.payload.split('\n'):
                        if line.startswith('dpid:'):
                            try:
                                return int(line[5:], 16)
                            except:
                                pass
                    if len(t.payload) == 8:
                        # Maybe it's a FlowVisor LLDP...
                        # Do these still exist?
                        try:
                            return struct.unpack("!Q", t.payload)[0]
                        except:
                            pass
                        return None

        originatorDPID = lookInSysDesc()

        if originatorDPID == None:
            # We'll look in the CHASSIS ID
            if lldph.tlvs[0].subtype == pkt.chassis_id.SUB_LOCAL:
                if lldph.tlvs[0].id.startswith('dpid:'):
                    # This is how NOX does it at the time of writing
                    try:
                        originatorDPID = int(lldph.tlvs[0].id[5:], 16)
                    except:
                        pass
            if originatorDPID == None:
                if lldph.tlvs[0].subtype == pkt.chassis_id.SUB_MAC:
                    # Last ditch effort -- we'll hope the DPID was small enough
                    # to fit into an ethernet address
                    if len(lldph.tlvs[0].id) == 6:
                        try:
                            s = lldph.tlvs[0].id
                            originatorDPID = struct.unpack("!Q",'\x00\x00' + s)[0]
                        except:
                            pass

        if originatorDPID == None:
            return

        if originatorDPID not in core.openflow.connections:
            return

        # Get port number from port TLV
        if lldph.tlvs[1].subtype != pkt.port_id.SUB_PORT:
            return
        originatorPort = None
        if lldph.tlvs[1].id.isdigit():
            # We expect it to be a decimal value
            originatorPort = int(lldph.tlvs[1].id)
        elif len(lldph.tlvs[1].id) == 2:
            # Maybe it's a 16 bit port number...
            try:
                originatorPort  =  struct.unpack("!H", lldph.tlvs[1].id)[0]
            except:
                pass
        if originatorPort is None:
            return
        
        if (event.dpid, event.port) == (originatorDPID, originatorPort):
            return

        link = Discovery.Link(originatorDPID, originatorPort, event.dpid,
                              event.port)

        if link not in self.adjacency:
            self.adjacency[link] = time.time()
            self.raiseEventNoErrors(LinkEvent, True, link)
        else:
            # Just update timestamp
            self.adjacency[link] = time.time()

        self.send_to_pyretic(['link',originatorDPID, originatorPort, event.dpid, event.port])            
        return # Probably nobody else needs this event


    def _handle_PacketIn(self, event):
        packet = event.parsed
        if packet.type == ethernet.LLDP_TYPE: 
            self.handle_lldp(packet,event)
            return
        elif packet.type == 0x86dd:  # IGNORE IPV6
            return 

        if self.show_traces:
            self.packetno += 1
            print "-------- POX/OF RECV %d ---------------" % self.packetno
            print event.connection
            print event.ofp
            print "port\t%s" % event.port
            print "data\t%s" % packetlib.ethernet(event.data)
            print "dpid\t%s" % event.dpid
            print

        received = self.packet_from_network(switch=event.dpid, inport=event.ofp.in_port, raw=event.data)
        self.send_to_pyretic(['packet',received])
        
       
def launch():

    class asyncore_loop(threading.Thread):
        def run(self):
            asyncore.loop()

    POXClient()
    al = asyncore_loop()
    al.start()



    
    

########NEW FILE########
__FILENAME__ = backend

################################################################################
# The Pyretic Project                                                          #
# frenetic-lang.org/pyretic                                                    #
# author: Joshua Reich (jreich@cs.princeton.edu)                               #
################################################################################
# Licensed to the Pyretic Project by one or more contributors. See the         #
# NOTICES file distributed with this work for additional information           #
# regarding copyright and ownership. The Pyretic Project licenses this         #
# file to you under the following license.                                     #
#                                                                              #
# Redistribution and use in source and binary forms, with or without           #
# modification, are permitted provided the following conditions are met:       #
# - Redistributions of source code must retain the above copyright             #
#   notice, this list of conditions and the following disclaimer.              #
# - Redistributions in binary form must reproduce the above copyright          #
#   notice, this list of conditions and the following disclaimer in            #
#   the documentation or other materials provided with the distribution.       #
# - The names of the copyright holds and contributors may not be used to       #
#   endorse or promote products derived from this work without specific        #
#   prior written permission.                                                  #
#                                                                              #
# Unless required by applicable law or agreed to in writing, software          #
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT    #
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the     #
# LICENSE file distributed with this work for specific language governing      #
# permissions and limitations under the License.                               #
################################################################################

import threading
from pyretic.backend.comm import *

class BackendServer(asyncore.dispatcher):
    """Receives connections and establishes handlers for each backend.
    """
    def __init__(self, backend, address):
        asyncore.dispatcher.__init__(self)
        self.create_socket(socket.AF_INET, socket.SOCK_STREAM)
        self.set_reuse_addr()
        self.bind(address)
        self.address = self.socket.getsockname()
        self.listen(1)
        self.backend = backend
        return

    def handle_accept(self):
        # Called when a backend connects to our socket
        backend_info = self.accept()
        self.backend.backend_channel = BackendChannel(self.backend,sock=backend_info[0])
        # We only want to deal with one backend at a time,
        # so close as soon as we set up the handler.
        # Normally you would not do this and the server
        # would run forever or until it received instructions
        # to stop.
        self.handle_close()
        return
    
    def handle_close(self):
        self.close()


class BackendChannel(asynchat.async_chat):
    """Handles echoing messages from a single backend.
    """
    def __init__(self, backend, sock):
        self.backend = backend
        self.received_data = []
        asynchat.async_chat.__init__(self, sock)
        self.ac_in_buffer_size = 4096 * 3
        self.ac_out_buffer_size = 4096 * 3
        self.set_terminator(TERM_CHAR)
        return

    def collect_incoming_data(self, data):
        """Read an incoming message from the backend and put it into our outgoing queue."""
        with self.backend.channel_lock:
            self.received_data.append(data)

    def found_terminator(self):
        """The end of a command or message has been seen."""
        with self.backend.channel_lock:
            msg = deserialize(self.received_data)

        # USE DESERIALIZED MSG
        if msg is None or len(msg) == 0:
            print "ERROR: empty message"
        elif msg[0] == 'switch':
            if msg[1] == 'join':
                if msg[3] == 'BEGIN':
                    self.backend.runtime.handle_switch_join(msg[2])
            elif msg[1] == 'part':
                self.backend.runtime.handle_switch_part(msg[2])
            else:
                print "ERROR: Bad switch event"
        elif msg[0] == 'port':
            if msg[1] == 'join':
                self.backend.runtime.handle_port_join(msg[2],msg[3],msg[4],msg[5])
            elif msg[1] == 'mod':
                self.backend.runtime.handle_port_mod(msg[2],msg[3],msg[4],msg[5])
            elif msg[1] == 'part':
                self.backend.runtime.handle_port_part(msg[2],msg[3])
            else:
                print "ERROR: Bad port event"
        elif msg[0] == 'link':
            self.backend.runtime.handle_link_update(msg[1],msg[2],msg[3],msg[4])
        elif msg[0] == 'packet':
            packet = msg[1]
            self.backend.runtime.handle_packet_in(packet)
        elif msg[0] == 'flow_stats_reply':
            self.backend.runtime.handle_flow_stats_reply(msg[1],msg[2])
        else:
            print 'ERROR: Unknown msg from backend %s' % msg
        return


class Backend(object):

    class asyncore_loop(threading.Thread):
        def run(self):
            asyncore.loop()

    def __init__(self):
        self.backend_channel = None
        self.runtime = None
        self.channel_lock = threading.Lock()

        address = ('localhost', BACKEND_PORT) # USE KNOWN PORT
        self.backend_server = BackendServer(self,address)
        
        self.al = self.asyncore_loop()
        self.al.daemon = True
        self.al.start()
        
    def send_packet(self,packet):
        self.send_to_OF_client(['packet',packet])

    def send_install(self,pred,priority,action_list):
        self.send_to_OF_client(['install',pred,priority,action_list])

    def send_delete(self,pred,priority):
        self.send_to_OF_client(['delete',pred,priority])
        
    def send_clear(self,switch):
        self.send_to_OF_client(['clear',switch])

    def send_flow_stats_request(self,switch):
        self.send_to_OF_client(['flow_stats_request',switch])

    def send_barrier(self,switch):
        self.send_to_OF_client(['barrier',switch])

    def inject_discovery_packet(self,dpid, port):
        self.send_to_OF_client(['inject_discovery_packet',dpid,port])

    def send_to_OF_client(self,msg):
        serialized_msg = serialize(msg)
        with self.channel_lock:
            if not self.backend_channel is None:
                self.backend_channel.push(serialized_msg)

########NEW FILE########
__FILENAME__ = comm

################################################################################
# The Pyretic Project                                                          #
# frenetic-lang.org/pyretic                                                    #
# author: Joshua Reich (jreich@cs.princeton.edu)                               #
################################################################################
# Licensed to the Pyretic Project by one or more contributors. See the         #
# NOTICES file distributed with this work for additional information           #
# regarding copyright and ownership. The Pyretic Project licenses this         #
# file to you under the following license.                                     #
#                                                                              #
# Redistribution and use in source and binary forms, with or without           #
# modification, are permitted provided the following conditions are met:       #
# - Redistributions of source code must retain the above copyright             #
#   notice, this list of conditions and the following disclaimer.              #
# - Redistributions in binary form must reproduce the above copyright          #
#   notice, this list of conditions and the following disclaimer in            #
#   the documentation or other materials provided with the distribution.       #
# - The names of the copyright holds and contributors may not be used to       #
#   endorse or promote products derived from this work without specific        #
#   prior written permission.                                                  #
#                                                                              #
# Unless required by applicable law or agreed to in writing, software          #
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT    #
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the     #
# LICENSE file distributed with this work for specific language governing      #
# permissions and limitations under the License.                               #
################################################################################

import asynchat
import asyncore
import socket

import json

BACKEND_PORT=41414
TERM_CHAR='\n'

def serialize(msg):
    jsonable_msg = to_jsonable_format(msg)
    jsoned_msg = json.dumps(jsonable_msg)
    serialized_msg = jsoned_msg + TERM_CHAR
    return serialized_msg

def deserialize(serialized_msgs):
    def json2python(item):
        if isinstance(item, unicode):
            return item.encode('ascii')
        elif isinstance(item, dict):
            return bytelist2ascii({ 
                    json2python(k) : json2python(v) 
                    for (k,v) in item.items() })
        elif isinstance(item, list):
            return [ json2python(l)
                     for l in item ]
        else:
            return item
    serialized_msg = serialized_msgs.pop(0)
    jsoned_msg = serialized_msg.rstrip(TERM_CHAR)
    msg = None
    while True:
        try:
            msg = json.loads(jsoned_msg)  
            msg = json2python(msg)
            break
        except:
            if len(serialized_msgs) == 0:
                break
            next_part = serialized_msgs.pop(0).rstrip(TERM_CHAR)
            jsoned_msg += next_part
    return msg


def dict_to_ascii(d):
    def convert(h,v):
        if (isinstance(v,str) or
            isinstance(v,int)):
            return v
        else:
            return repr(v)
    return { h : convert(h,v) for (h,v) in d.items() }


def bytelist2ascii(packet_dict):
    def convert(h,val):
        if h in ['srcmac','dstmac','srcip','dstip','raw']:
            return ''.join([chr(d) for d in val])
        else:
            return val
    return { h : convert(h,val) for (h, val) in packet_dict.items()}


def ascii2bytelist(packet_dict):
    def convert(h,val):
        if h in ['srcmac','dstmac','srcip','dstip','raw']:
            return [ord(c) for c in val]
        else:
            return val
    return { h : convert(h,val) for (h, val) in packet_dict.items()}


def to_jsonable_format(item):
    if isinstance(item, dict):
        ascii_item = dict_to_ascii(item)
        bytelist_item = ascii2bytelist(ascii_item)
        return bytelist_item
    elif isinstance(item, list):
        return map(to_jsonable_format,item)
    else:
        return item

########NEW FILE########
__FILENAME__ = asynchat
# partially manual merge of cpython.asyncore_3.patch http://bugs.python.org/issue17925

# -*- Mode: Python; tab-width: 4 -*-
#       Id: asynchat.py,v 2.26 2000/09/07 22:29:26 rushing Exp
#       Author: Sam Rushing <rushing@nightmare.com>

# ======================================================================
# Copyright 1996 by Sam Rushing
#
#                         All Rights Reserved
#
# Permission to use, copy, modify, and distribute this software and
# its documentation for any purpose and without fee is hereby
# granted, provided that the above copyright notice appear in all
# copies and that both that copyright notice and this permission
# notice appear in supporting documentation, and that the name of Sam
# Rushing not be used in advertising or publicity pertaining to
# distribution of the software without specific, written prior
# permission.
#
# SAM RUSHING DISCLAIMS ALL WARRANTIES WITH REGARD TO THIS SOFTWARE,
# INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS, IN
# NO EVENT SHALL SAM RUSHING BE LIABLE FOR ANY SPECIAL, INDIRECT OR
# CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER RESULTING FROM LOSS
# OF USE, DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT,
# NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF OR IN
# CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.
# ======================================================================

r"""A class supporting chat-style (command/response) protocols.

This class adds support for 'chat' style protocols - where one side
sends a 'command', and the other sends a response (examples would be
the common internet protocols - smtp, nntp, ftp, etc..).

The handle_read() method looks at the input stream for the current
'terminator' (usually '\r\n' for single-line responses, '\r\n.\r\n'
for multi-line output), calling self.found_terminator() on its
receipt.

for example:
Say you build an async nntp client using this class.  At the start
of the connection, you'll have self.terminator set to '\r\n', in
order to process the single-line greeting.  Just before issuing a
'LIST' command you'll set it to '\r\n.\r\n'.  The output of the LIST
command will be accumulated (using your own 'collect_incoming_data'
method) up to the terminator, and then control will be returned to
you - by calling your self.found_terminator() method.
"""

import socket
import asyncore
from collections import deque
from sys import py3kwarning
from warnings import filterwarnings, catch_warnings

class async_chat (asyncore.dispatcher):
    """This is an abstract class.  You must derive from this class, and add
    the two methods collect_incoming_data() and found_terminator()"""

    # these are overridable defaults

    ac_in_buffer_size       = 4096
    ac_out_buffer_size      = 4096

    def __init__ (self, sock=None, map=None):
        # for string terminator matching
        self.ac_in_buffer = ''

        # we use a list here rather than cStringIO for a few reasons...
        # del lst[:] is faster than sio.truncate(0)
        # lst = [] is faster than sio.truncate(0)
        # cStringIO will be gaining unicode support in py3k, which
        # will negatively affect the performance of bytes compared to
        # a ''.join() equivalent
        self.incoming = []

        # we toss the use of the "simple producer" and replace it with
        # a pure deque, which the original fifo was a wrapping of
        self.producer_fifo = deque()
        asyncore.dispatcher.__init__ (self, sock, map)

    def collect_incoming_data(self, data):
        raise NotImplementedError("must be implemented in subclass")

    def _collect_incoming_data(self, data):
        self.incoming.append(data)

    def _get_data(self):
        d = ''.join(self.incoming)
        del self.incoming[:]
        return d

    def found_terminator(self):
        raise NotImplementedError("must be implemented in subclass")

    def set_terminator (self, term):
        "Set the input delimiter.  Can be a fixed string of any length, an integer, or None"
        self.terminator = term

    def get_terminator (self):
        return self.terminator

    # grab some more data from the socket,
    # throw it to the collector method,
    # check for the terminator,
    # if found, transition to the next state.

    def handle_read (self):

        try:
            data = self.recv (self.ac_in_buffer_size)
        except socket.error, why:
            self.handle_error()
            return

        self.ac_in_buffer = self.ac_in_buffer + data

        # Continue to search for self.terminator in self.ac_in_buffer,
        # while calling self.collect_incoming_data.  The while loop
        # is necessary because we might read several data+terminator
        # combos with a single recv(4096).

        while self.ac_in_buffer:
            lb = len(self.ac_in_buffer)
            terminator = self.get_terminator()
            if not terminator:
                # no terminator, collect it all
                self.collect_incoming_data (self.ac_in_buffer)
                self.ac_in_buffer = ''
            elif isinstance(terminator, int) or isinstance(terminator, long):
                # numeric terminator
                n = terminator
                if lb < n:
                    self.collect_incoming_data (self.ac_in_buffer)
                    self.ac_in_buffer = ''
                    self.terminator = self.terminator - lb
                else:
                    self.collect_incoming_data (self.ac_in_buffer[:n])
                    self.ac_in_buffer = self.ac_in_buffer[n:]
                    self.terminator = 0
                    self.found_terminator()
            else:
                # 3 cases:
                # 1) end of buffer matches terminator exactly:
                #    collect data, transition
                # 2) end of buffer matches some prefix:
                #    collect data to the prefix
                # 3) end of buffer does not match any prefix:
                #    collect data
                terminator_len = len(terminator)
                index = self.ac_in_buffer.find(terminator)
                if index != -1:
                    # we found the terminator
                    if index > 0:
                        # don't bother reporting the empty string (source of subtle bugs)
                        self.collect_incoming_data (self.ac_in_buffer[:index])
                    self.ac_in_buffer = self.ac_in_buffer[index+terminator_len:]
                    # This does the Right Thing if the terminator is changed here.
                    self.found_terminator()
                else:
                    # check for a prefix of the terminator
                    index = find_prefix_at_end (self.ac_in_buffer, terminator)
                    if index:
                        if index != lb:
                            # we found a prefix, collect up to the prefix
                            self.collect_incoming_data (self.ac_in_buffer[:-index])
                            self.ac_in_buffer = self.ac_in_buffer[-index:]
                        break
                    else:
                        # no prefix, collect it all
                        self.collect_incoming_data (self.ac_in_buffer)
                        self.ac_in_buffer = ''

    def handle_write (self):
        self.initiate_send()

    def handle_close (self):
        self.close()

    def push (self, data):
        sabs = self.ac_out_buffer_size
        if len(data) > sabs:
            for i in xrange(0, len(data), sabs):
                self.producer_fifo.append(data[i:i+sabs])
        else:
            self.producer_fifo.append(data)
        self.initiate_send()

    def push_with_producer (self, producer):
        self.producer_fifo.append(producer)
        self.initiate_send()

    def readable (self):
        "predicate for inclusion in the readable for select()"
        # cannot use the old predicate, it violates the claim of the
        # set_terminator method.

        # return (len(self.ac_in_buffer) <= self.ac_in_buffer_size)
        return 1

    def writable (self):
        "predicate for inclusion in the writable for select()"
        return self.producer_fifo or (not self.connected)

    def close_when_done (self):
        "automatically close this channel once the outgoing queue is empty"
        self.producer_fifo.append(None)

    def initiate_send(self):
        while self.producer_fifo and self.connected:
            first = self.producer_fifo.popleft()
            # handle empty string/buffer or None entry
            if not first:
                 if first is None:
                     self.handle_close()
                     return

            # handle classic producer behavior
            obs = self.ac_out_buffer_size
            try:
                with catch_warnings():
                    if py3kwarning:
                        filterwarnings("ignore", ".*buffer", DeprecationWarning)
                    data = buffer(first, 0, obs)
            except TypeError:
                data = first.more()
                if data:
                    self.producer_fifo.extendleft([data, first])
                continue

            # send the data
            try:
                num_sent = self.send(data)
            except socket.error:
                self.handle_error()
                return

            if num_sent:
                if num_sent < len(data) or obs < len(first):
                    self.producer_fifo.appendleft(first[num_sent:])
            # we tried to send some actual data
        return

    def discard_buffers (self):
        # Emergencies only!
        self.ac_in_buffer = ''
        del self.incoming[:]
        self.producer_fifo.clear()

class simple_producer:

    def __init__ (self, data, buffer_size=512):
        self.data = data
        self.buffer_size = buffer_size

    def more (self):
        if len (self.data) > self.buffer_size:
            result = self.data[:self.buffer_size]
            self.data = self.data[self.buffer_size:]
            return result
        else:
            result = self.data
            self.data = ''
            return result

class fifo:
    def __init__ (self, list=None):
        if not list:
            self.list = deque()
        else:
            self.list = deque(list)

    def __len__ (self):
        return len(self.list)

    def is_empty (self):
        return not self.list

    def first (self):
        return self.list[0]

    def push (self, data):
        self.list.append(data)

    def pop (self):
        if self.list:
            return (1, self.list.popleft())
        else:
            return (0, None)

# Given 'haystack', see if any prefix of 'needle' is at its end.  This
# assumes an exact match has already been checked.  Return the number of
# characters matched.
# for example:
# f_p_a_e ("qwerty\r", "\r\n") => 1
# f_p_a_e ("qwertydkjf", "\r\n") => 0
# f_p_a_e ("qwerty\r\n", "\r\n") => <undefined>

# this could maybe be made faster with a computed regex?
# [answer: no; circa Python-2.0, Jan 2001]
# new python:   28961/s
# old python:   18307/s
# re:        12820/s
# regex:     14035/s

def find_prefix_at_end (haystack, needle):
    l = len(needle) - 1
    while l and not haystack.endswith(needle[:l]):
        l -= 1
    return l

########NEW FILE########
__FILENAME__ = classifier

from collections import deque
import copy

###############################################################################
# Classifiers
# an intermediate representation for proactive compilation.


class Rule(object):
    """
    A rule contains a filter and the parallel composition of zero or more
    Pyretic actions.
    """

    # Matches m should be of the match class.  Actions acts should be a set of
    # modify, identity, and/or Controller/CountBucket/FwdBucket policies.
    # Actions is Rule are semantically meant to run in parallel
    # unlike OpenFlow rules.
    def __init__(self,m,acts):
        self.match = m
        self.actions = acts

    def __str__(self):
        return str(self.match) + '\n  -> ' + str(self.actions)

    def __repr__(self):
        return str(self)

    def __eq__(self, other):
        """Based on syntactic equality of policies."""
        return ( id(self) == id(other)
            or ( self.match == other.match
                 and self.actions == other.actions ) )

    def __ne__(self, other):
        """Based on syntactic equality of policies."""
        return not (self == other)

    def eval(self, in_pkt):
        """
        If this rule matches the packet, then return the union of the sets
        of packets produced by the actions.  Otherwise, return None.
        """
        filtered_pkt = self.match.eval(in_pkt)
        if len(filtered_pkt) == 0:
            return None
        rv = set()
        for pkt in filtered_pkt:
            for act in self.actions:
                rv |= act.eval(pkt)
        return rv


class Classifier(object):
    """
    A classifier contains a list of rules, where the order of the list implies
    the relative priorities of the rules.  Semantically, classifiers are
    functions from packets to sets of packets, similar to OpenFlow flow
    tables.
    """

    def __init__(self, new_rules=list()):
        import types
        if isinstance(new_rules, types.GeneratorType):
            self.rules = deque([r for r in new_rules])
        elif isinstance(new_rules,list):
            self.rules = deque(new_rules)
        elif isinstance(new_rules,deque):
            self.rules = new_rules
        else:
            raise TypeError

    def __len__(self):
        return len(self.rules)

    def __str__(self):
        return '\n '.join(map(str,self.rules))

    def __repr__(self):
        return str(self)

    def __eq__(self, other):
        """Based on syntactic equality of policies."""
        return ( id(self) == id(other)
            or ( self.rules == other.rules ) )

    def __ne__(self, other):
        """Based on syntactic equality of policies."""
        return not (self == other)

    def eval(self, in_pkt):
        """
        Evaluate against each rule in the classifier, starting with the
        highest priority.  Return the set of packets resulting from applying
        the actions of the first rule that matches.
        """
        for rule in self.rules:
            pkts = rule.eval(in_pkt)
            if pkts is not None:
                return pkts
        raise TypeError('Classifier is not total.')

    def prepend(self, item):
        if isinstance(item, Rule):
            self.rules.appendleft(item)
        elif isinstance(item, Classifier):
            self.rules.extendleft(item.rules)
        else:
            raise TypeError            

    def append(self, item):
        if isinstance(item, Rule):
            self.rules.append(item)
        elif isinstance(item, Classifier):
            self.rules.extend(item.rules)
        else:
            raise TypeError

    def remove_last_rule(self):
        self.rules.pop()

    def __copy__(self):
        copied_rules = map(copy.copy,self.rules)
        return Classifier(copied_rules)


    ### NEGATE ###
    def __invert__(self):
        from pyretic.core.language import identity
        c = copy.copy(self)
        for r in c.rules:
            if len(r.actions) == 0:
                r.actions = {identity}
            elif r.actions == {identity}:
                r.actions = set()
            else:
                raise TypeError  # TODO MAKE A CompileError TYPE
        return c


    ### PARALLEL COMPOSITION
            
    def __add__(c1, c2):
        from pyretic.core.language import drop, identity
        def _cross(r1,r2):
            intersection = r1.match.intersect(r2.match)
            if intersection != drop:
                actions = r1.actions | r2.actions
                return Rule(intersection, actions)
            else:
                return None

        # start with an empty set of rules for the output classifier
        c3 = Classifier()
        assert(not (c1 is None and c2 is None))
        # then cross all pairs of rules in the first and second classifiers
        for r1 in c1.rules:
            for r2 in c2.rules:
                crossed_r = _cross(r1,r2)
                if crossed_r:
                    c3.append(crossed_r)
        # if the classifier is empty, add a drop-all rule
        if len(c3) == 0:
            c3.append(Rule(identity,set()))
        # and optimize the classifier
        else:
            c3 = c3.optimize()
        return c3


    ### SEQUENTIAL COMPOSITION

    def __rshift__(c1, c2):
        from pyretic.core.language import match, modify, drop, identity, Controller, CountBucket, DerivedPolicy
        # given a test b and an action p, return a test
        # b' such that p >> b == b' >> p.
        def _commute_test(act, pkts):
            while isinstance(act, DerivedPolicy):
                act = act.policy
            if act == identity:
                return pkts
            elif act == Controller or isinstance(act, CountBucket):
                return identity
            elif isinstance(act, modify):
                new_match_dict = {}
                if pkts == identity:
                    return identity
                elif pkts == drop:
                    return drop
                for f, v in pkts.map.iteritems():
                    if f in act.map and act.map[f] == v:
                        continue
                    elif f in act.map and act.map[f] != v:
                        return drop
                    else:
                        new_match_dict[f] = v
                if len(new_match_dict) == 0:
                    return identity
                return match(**new_match_dict)
            else:
                raise TypeError

        # sequentially compose actions.  a1 must be a
        # single action.  Returns a list of actions.
        def _sequence_actions(a1, as2):
            while isinstance(a1, DerivedPolicy):
                a1 = a1.policy
            # TODO: be uniform about returning copied or modified objects.
            if a1 == Controller or isinstance(a1, CountBucket):
                return {a1}
            elif a1 == identity:
                return copy.copy(as2)
            elif isinstance(a1, modify):
                new_actions = set()
                for a2 in as2:
                    while isinstance(a2, DerivedPolicy):
                        a2 = a2.policy
                    if a2 == Controller or isinstance(a2, CountBucket): 
                        new_actions.add(a2)
                    elif a2 == identity:
                        new_actions.add(a1)
                    elif isinstance(a2, modify):
                        new_a1 = modify(**a1.map.copy())
                        new_a1.map.update(a2.map)
                        new_actions.add(new_a1)
                    else:
                        raise TypeError
                return new_actions
            else:
                raise TypeError

        # generates a (potentially) non-total classifier 
        # containing a single rule, or None
        def _cross_act(r1,act,r2):
            m = r1.match.intersect(_commute_test(act, r2.match))
            actions = _sequence_actions(act,r2.actions)
            if m == drop:
                return None
            else:
                return Classifier([Rule(m,actions)])

        # returns a potentially non-total classifier
        # suitable for concatenating w/ other potentially non-total classifiers
        def _cross(r1,r2):
            c = None
            for act in r1.actions:
                cross = _cross_act(r1,act,r2) 
                if c is None:
                    c = cross
                elif not cross is None:
                    # parallel compose to get c_tmp
                    c_tmp = c + cross
                    # but since both c and cross were potentially non-total
                    # we need to append both c and cross to c_tmp
                    c_tmp.append(c)
                    c_tmp.append(cross)
                    # set c to c_tmp and optimize
                    c = c_tmp
                    c = c.optimize()
            return c

        # core __rshift__ logic begins here.

        # start with an empty set of rules for the output classifier
        # then for each rule in the first classifier (self)
        c3 = Classifier()
        for r1 in c1.rules:
            if len(r1.actions) == 0:
                c3.append(r1)
            else:
                for r2 in c2.rules:
                    c_tmp = _cross(r1,r2)
                    if not c_tmp is None:
                        c3.append(c_tmp)
        # when all rules in c1 and c2 have been crossed
        # optimize c3
        c3 = c3.optimize()
        return c3


    ### SHADOW OPTIMIZATION

    def optimize(self):
        return self.remove_shadowed_cover_single()

    def remove_shadowed_exact_single(self):
        # Eliminate every rule exactly matched by some higher priority rule
        opt_c = Classifier()
        for r in self.rules:
            if not reduce(lambda acc, new_r: acc or
                          new_r.match == r.match,
                          opt_c.rules,
                          False):
                opt_c.rules.append(r)
        return opt_c

    def remove_shadowed_cover_single(self):
        # Eliminate every rule completely covered by some higher priority rule
        opt_c = Classifier()
        for r in self.rules:
            if not reduce(lambda acc, new_r: acc or
                          new_r.match.covers(r.match),
                          opt_c.rules,
                          False):
                opt_c.rules.append(r)
        return opt_c

########NEW FILE########
__FILENAME__ = language

################################################################################
# The Pyretic Project                                                          #
# frenetic-lang.org/pyretic                                                    #
# author: Joshua Reich (jreich@cs.princeton.edu)                               #
# author: Christopher Monsanto (chris@monsan.to)                               #
# author: Cole Schlesinger (cschlesi@cs.princeton.edu)                         #
################################################################################
# Licensed to the Pyretic Project by one or more contributors. See the         #
# NOTICES file distributed with this work for additional information           #
# regarding copyright and ownership. The Pyretic Project licenses this         #
# file to you under the following license.                                     #
#                                                                              #
# Redistribution and use in source and binary forms, with or without           #
# modification, are permitted provided the following conditions are met:       #
# - Redistributions of source code must retain the above copyright             #
#   notice, this list of conditions and the following disclaimer.              #
# - Redistributions in binary form must reproduce the above copyright          #
#   notice, this list of conditions and the following disclaimer in            #
#   the documentation or other materials provided with the distribution.       #
# - The names of the copyright holds and contributors may not be used to       #
#   endorse or promote products derived from this work without specific        #
#   prior written permission.                                                  #
#                                                                              #
# Unless required by applicable law or agreed to in writing, software          #
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT    #
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the     #
# LICENSE file distributed with this work for specific language governing      #
# permissions and limitations under the License.                               #
################################################################################

# This module is designed for import *.
import functools
import itertools
import struct
import time
from ipaddr import IPv4Network
from bitarray import bitarray

from pyretic.core import util
from pyretic.core.network import *
from pyretic.core.classifier import Rule, Classifier
from pyretic.core.util import frozendict, singleton

from multiprocessing import Condition

NO_CACHE=False

basic_headers = ["srcmac", "dstmac", "srcip", "dstip", "tos", "srcport", "dstport",
                 "ethtype", "protocol"]
tagging_headers = ["vlan_id", "vlan_pcp"]
native_headers = basic_headers + tagging_headers
location_headers = ["switch", "inport", "outport"]
compilable_headers = native_headers + location_headers
content_headers = [ "raw", "header_len", "payload_len"]

################################################################################
# Policy Language                                                              #
################################################################################

class Policy(object):
    """
    Top-level abstract class for policies.
    All Pyretic policies have methods for

    - evaluating on a single packet.
    - compilation to a switch Classifier
    """
    def eval(self, pkt):
        """
        evaluate this policy on a single packet

        :param pkt: the packet on which to be evaluated
        :type pkt: Packet
        :rtype: set Packet
        """
        raise NotImplementedError

    def invalidate_classifier(self):
        self._classifier = None

    def compile(self):
        """
        Produce a Classifier for this policy

        :rtype: Classifier
        """
        if NO_CACHE: 
            self._classifier = self.generate_classifier()
        return self._classifier

    def __add__(self, pol):
        """
        The parallel composition operator.

        :param pol: the Policy to the right of the operator
        :type pol: Policy
        :rtype: Parallel
        """
        if isinstance(pol,parallel):
            return parallel([self] + pol.policies)
        else:
            return parallel([self, pol])

    def __rshift__(self, other):
        """
        The sequential composition operator.

        :param pol: the Policy to the right of the operator
        :type pol: Policy
        :rtype: Sequential
        """
        if isinstance(other,sequential):
            return sequential([self] + other.policies)
        else:
            return sequential([self, other])

    def __eq__(self, other):
        """Syntactic equality."""
        raise NotImplementedError

    def __ne__(self,other):
        """Syntactic inequality."""
        return not (self == other)

    def name(self):
        return self.__class__.__name__

    def __repr__(self):
        return "%s : %d" % (self.name(),id(self))


class Filter(Policy):
    """
    Abstact class for filter policies.
    A filter Policy will always either 

    - pass packets through unchanged
    - drop them

    No packets will ever be modified by a Filter.
    """
    def eval(self, pkt):
        """
        evaluate this policy on a single packet

        :param pkt: the packet on which to be evaluated
        :type pkt: Packet
        :rtype: set Packet
        """
        raise NotImplementedError

    def __or__(self, pol):
        """
        The Boolean OR operator.

        :param pol: the filter Policy to the right of the operator
        :type pol: Filter
        :rtype: Union
        """
        if isinstance(pol,Filter):
            return union([self, pol])
        else:
            raise TypeError

    def __and__(self, pol):
        """
        The Boolean AND operator.

        :param pol: the filter Policy to the right of the operator
        :type pol: Filter
        :rtype: Intersection
        """
        if isinstance(pol,Filter):
            return intersection([self, pol])
        else:
            raise TypeError

    def __sub__(self, pol):
        """
        The Boolean subtraction operator.

        :param pol: the filter Policy to the right of the operator
        :type pol: Filter
        :rtype: Difference
        """
        if isinstance(pol,Filter):
            return difference(self, pol)
        else:
            raise TypeError

    def __invert__(self):
        """
        The Boolean negation operator.

        :param pol: the filter Policy to the right of the operator
        :type pol: Filter
        :rtype: negate
        """
        return negate([self])


class Singleton(Filter):
    """Abstract policy from which Singletons descend"""

    _classifier = None

    def compile(self):
        """
        Produce a Classifier for this policy

        :rtype: Classifier
        """
        if NO_CACHE: 
            self.__class__._classifier = self.generate_classifier()
        if self.__class__._classifier is None:
            self.__class__._classifier = self.generate_classifier()
        return self.__class__._classifier

    def generate_classifier(self):
        return Classifier([Rule(identity, {self})])


@singleton
class identity(Singleton):
    """The identity policy, leaves all packets unchanged."""
    def eval(self, pkt):
        """
        evaluate this policy on a single packet

        :param pkt: the packet on which to be evaluated
        :type pkt: Packet
        :rtype: set Packet
        """
        return {pkt}

    def intersect(self, other):
        return other

    def covers(self, other):
        return True

    def __eq__(self, other):
        return ( id(self) == id(other)
            or ( isinstance(other, match) and len(other.map) == 0) )

    def __repr__(self):
        return "identity"

passthrough = identity   # Imperative alias
true = identity          # Logic alias
all_packets = identity   # Matching alias


@singleton
class drop(Singleton):
    """The drop policy, produces the empty set of packets."""
    def eval(self, pkt):
        """
        evaluate this policy on a single packet

        :param pkt: the packet on which to be evaluated
        :type pkt: Packet
        :rtype: set Packet
        """
        return set()

    def generate_classifier(self):
        return Classifier([Rule(identity,set())])

    def intersect(self, other):
        return self

    def covers(self, other):
        return False

    def __eq__(self, other):
        return id(self) == id(other)

    def __repr__(self):
        return "drop"

none = drop
false = drop             # Logic alias
no_packets = drop        # Matching alias


@singleton
class Controller(Singleton):
    def eval(self, pkt):
        return set()

    def __eq__(self, other):
        return id(self) == id(other)

    def __repr__(self):
        return "Controller"
    

class match(Filter):
    """
    Match on all specified fields.
    Matched packets are kept, non-matched packets are dropped.

    :param *args: field matches in argument format
    :param **kwargs: field matches in keyword-argument format
    """
    def __init__(self, *args, **kwargs):
        if len(args) == 0 and len(kwargs) == 0:
            raise TypeError
        self.map = util.frozendict(dict(*args, **kwargs))
        self._classifier = self.generate_classifier()
        super(match,self).__init__()

    def eval(self, pkt):
        """
        evaluate this policy on a single packet

        :param pkt: the packet on which to be evaluated
        :type pkt: Packet
        :rtype: set Packet
        """

        for field, pattern in self.map.iteritems():
            try:
                v = pkt[field]
                if pattern is None or pattern != v:
                    return set()
            except:
                if pattern is not None:
                    return set()
        return {pkt}

    def generate_classifier(self):
        r1 = Rule(self,{identity})
        r2 = Rule(identity,set())
        return Classifier([r1, r2])

    def __eq__(self, other):
        return ( (isinstance(other, match) and self.map == other.map)
            or (other == identity and len(self.map) == 0) )

    def intersect(self, pol):

        def _intersect_ip(ipfx, opfx):
            most_specific = None
            if (IPv4Network(ipfx) in IPv4Network(opfx)):
                most_specific = ipfx
            elif (IPv4Network(opfx) in IPv4Network(ipfx)): 
                most_specific = opfx
            return most_specific

        if pol == identity:
            return self
        elif pol == drop:
            return drop
        elif not isinstance(pol,match):
            raise TypeError
        fs1 = set(self.map.keys())
        fs2 = set(pol.map.keys())
        shared = fs1 & fs2
        most_specific_src = None
        most_specific_dst = None

        for f in shared:
            if (f=='srcip'):
                most_specific_src = _intersect_ip(self.map[f], pol.map[f])
                if most_specific_src is None:
                    return drop
            elif (f=='dstip'):
                most_specific_dst = _intersect_ip(self.map[f], pol.map[f])
                if most_specific_dst is None:
                    return drop
            elif (self.map[f] != pol.map[f]):
                return drop

        d = self.map.update(pol.map)

        if most_specific_src is not None:
            d = d.update({'srcip' : most_specific_src})
        if most_specific_dst is not None:
            d = d.update({'dstip' : most_specific_dst})

        return match(**d)

    def __and__(self,pol):
        if isinstance(pol,match):
            return self.intersect(pol)
        else:
            return super(match,self).__and__(pol)

    ### hash : unit -> int
    def __hash__(self):
        return hash(self.map)

    def covers(self,other):
        # Return identity if self matches every packet that other matches (and maybe more).
        # eg. if other is specific on any field that self lacks.
        if other == identity and len(self.map.keys()) > 0:
            return False
        elif other == identity:
            return True
        elif other == drop:
            return True
        if set(self.map.keys()) - set(other.map.keys()):
            return False
        for (f,v) in self.map.items():
            if (f=='srcip' or f=='dstip'):
                if(IPv4Network(v) != IPv4Network(other.map[f])):
                    if(not IPv4Network(other.map[f]) in IPv4Network(v)):
                        return False
            elif v != other.map[f]:
                return False
        return True

    def __repr__(self):
        return "match: %s" % ' '.join(map(str,self.map.items()))


class modify(Policy):
    """
    Modify on all specified fields to specified values.

    :param *args: field assignments in argument format
    :param **kwargs: field assignments in keyword-argument format
    """
    ### init : List (String * FieldVal) -> List KeywordArg -> unit
    def __init__(self, *args, **kwargs):
        if len(args) == 0 and len(kwargs) == 0:
            raise TypeError
        self.map = dict(*args, **kwargs)
        self.has_virtual_headers = not \
            reduce(lambda acc, f:
                       acc and (f in compilable_headers),
                   self.map.keys(),
                   True)
        self._classifier = self.generate_classifier()
        super(modify,self).__init__()

    def eval(self, pkt):
        """
        evaluate this policy on a single packet

        :param pkt: the packet on which to be evaluated
        :type pkt: Packet
        :rtype: set Packet
        """
        return {pkt.modifymany(self.map)}

    def generate_classifier(self):
        if self.has_virtual_headers:
            r = Rule(identity,{Controller})
        else:
            r = Rule(identity,{self})
        return Classifier([r])

    def __repr__(self):
        return "modify: %s" % ' '.join(map(str,self.map.items()))

    def __eq__(self, other):
        return ( isinstance(other, modify)
           and (self.map == other.map) )


# FIXME: Srinivas =).
class Query(Filter):
    """
    Abstract class representing a data structure
    into which packets (conceptually) go and with which callbacks can register.
    """
    ### init : unit -> unit
    def __init__(self):
        from multiprocessing import Lock
        self.callbacks = []
        self.bucket = set()
        self.bucket_lock = Lock()
        super(Query,self).__init__()

    def eval(self, pkt):
        """
        evaluate this policy on a single packet

        :param pkt: the packet on which to be evaluated
        :type pkt: Packet
        :rtype: set Packet
        """
        with self.bucket_lock:
            self.bucket.add(pkt)
        return set()
        
    ### register_callback : (Packet -> X) -> unit
    def register_callback(self, fn):
        self.callbacks.append(fn)

    def __repr__(self):
        return "Query"


class FwdBucket(Query):
    """
    Class for registering callbacks on individual packets sent to
    the controller.
    """
    def __init__(self):
        self._classifier = self.generate_classifier()
        super(FwdBucket,self).__init__()

    def generate_classifier(self):
        return Classifier([Rule(identity,{Controller})])

    def apply(self):
        with self.bucket_lock:
            for pkt in self.bucket:
                for callback in self.callbacks:
                    callback(pkt)
            self.bucket.clear()
    
    def __repr__(self):
        return "FwdBucket"

    def __eq__(self, other):
        # TODO: if buckets eventually have names, equality should
        # be on names.
        return isinstance(other, FwdBucket)


class CountBucket(Query):
    """
    Class for registering callbacks on counts of packets sent to
    the controller.
    """
    def __init__(self):
        super(CountBucket, self).__init__()
        self.matches = set([])
        self.runtime_stats_query_fun = None
        self.outstanding_switches = []
        self.packet_count = 0
        self.byte_count = 0
        self.packet_count_persistent = 0
        self.byte_count_persistent = 0
        self.in_update_cv = Condition()
        self.in_update = False
        self._classifier = self.generate_classifier()
        
    def __repr__(self):
        return "CountBucket"

    def eval(self, pkt):
        """
        evaluate this policy on a single packet

        :param pkt: the packet on which to be evaluated
        :type pkt: Packet
        :rtype: set Packet
        """
        return set()

    def generate_classifier(self):
        return Classifier([Rule(identity,{self})])

    def apply(self):
        with self.bucket_lock:
            for pkt in self.bucket:
                self.packet_count_persistent += 1
                self.byte_count_persistent += pkt['header_len'] + pkt['payload_len']
            self.bucket.clear()

    def start_update(self):
        """
        Use a condition variable to mediate access to bucket state as it is
        being updated.

        Why condition variables and not locks? The main reason is that the state
        update doesn't happen in just a single function call here, since the
        runtime processes the classifier rule by rule and buckets may be touched
        in arbitrary order depending on the policy. They're not all updated in a
        single function call. In that case,

        (1) Holding locks *across* function calls seems dangerous and
        non-modular (in my opinion), since we need to be aware of this across a
        large function, and acquiring locks in different orders at different
        points in the code can result in tricky deadlocks (there is another lock
        involved in protecting bucket updates in runtime).

        (2) The "with" semantics in python is clean, and splitting that into
        lock.acquire() and lock.release() calls results in possibly replicated
        failure handling code that is boilerplate.

        """
        with self.in_update_cv:
            self.in_update = True
            self.matches = set([])
            self.runtime_stats_query_fun = None
            self.outstanding_switches = []

    def finish_update(self):
        with self.in_update_cv:
            self.in_update = False
            self.in_update_cv.notify_all()
        
    def add_match(self, m):
        """
        Add a match m to list of classifier rules to be queried for
        counts.
        """
        if not m in self.matches:
            self.matches.add(m)

    def add_pull_stats(self, fun):
        """
        Point to function that issues stats queries in the
        runtime.
        """
        if not self.runtime_stats_query_fun:
            self.runtime_stats_query_fun = fun

    def pull_stats(self):
        """Issue stats queries from the runtime"""
        queries_issued = False
        with self.in_update_cv:
            while self.in_update: # ensure buckets not updated concurrently
                self.in_update_cv.wait()
            if not self.runtime_stats_query_fun is None:
                self.outstanding_switches = []
                queries_issued = True
                self.runtime_stats_query_fun()
        # If no queries were issued, then no matches, so just call userland
        # registered callback routines
        if not queries_issued:
            self.packet_count = self.packet_count_persistent
            self.byte_count = self.byte_count_persistent
            for f in self.callbacks:
                f([self.packet_count, self.byte_count])

    def add_outstanding_switch_query(self,switch):
        self.outstanding_switches.append(switch)

    def handle_flow_stats_reply(self,switch,flow_stats):
        """
        Given a flow_stats_reply from switch s, collect only those
        counts which are relevant to this bucket.

        Very simple processing for now: just collect all packet and
        byte counts from rules that have a match that is in the set of
        matches this bucket is interested in.
        """
        def stat_in_bucket(flow_stat, s):
            table_match = match(f['match']).intersect(match(switch=s))
            network_match = match(f['match'])
            if table_match in self.matches or network_match in self.matches:
                return True
            return False

        with self.in_update_cv:
            while self.in_update:
                self.in_update_cv.wait()
            self.packet_count = self.packet_count_persistent
            self.byte_count = self.byte_count_persistent
            if switch in self.outstanding_switches:
                for f in flow_stats:
                    if 'match' in f:
                        if stat_in_bucket(f, switch):
                            self.packet_count += f['packet_count']
                            self.byte_count   += f['byte_count']
                self.outstanding_switches.remove(switch)
        # If have all necessary data, call user-land registered callbacks
        if not self.outstanding_switches:
            for f in self.callbacks:
                f([self.packet_count, self.byte_count])

    def __eq__(self, other):
        # TODO: if buckets eventually have names, equality should
        # be on names.
        return isinstance(other, CountBucket)

################################################################################
# Combinator Policies                                                          #
################################################################################

class CombinatorPolicy(Policy):
    """
    Abstract class for policy combinators.

    :param policies: the policies to be combined.
    :type policies: list Policy
    """
    ### init : List Policy -> unit
    def __init__(self, policies=[]):
        self.policies = list(policies)
        self._classifier = None
        super(CombinatorPolicy,self).__init__()

    def compile(self):
        """
        Produce a Classifier for this policy

        :rtype: Classifier
        """
        if NO_CACHE: 
            self._classifier = self.generate_classifier()
        if not self._classifier:
            self._classifier = self.generate_classifier()
        return self._classifier

    def __repr__(self):
        return "%s:\n%s" % (self.name(),util.repr_plus(self.policies))

    def __eq__(self, other):
        return ( self.__class__ == other.__class__
           and   self.policies == other.policies )


class negate(CombinatorPolicy,Filter):
    """
    Combinator that negates the input policy.

    :param policies: the policies to be negated.
    :type policies: list Filter
    """
    def eval(self, pkt):
        """
        evaluate this policy on a single packet

        :param pkt: the packet on which to be evaluated
        :type pkt: Packet
        :rtype: set Packet
        """
        if self.policies[0].eval(pkt):
            return set()
        else:
            return {pkt}

    def generate_classifier(self):
        inner_classifier = self.policies[0].compile()
        return ~inner_classifier


class parallel(CombinatorPolicy):
    """
    Combinator for several policies in parallel.

    :param policies: the policies to be combined.
    :type policies: list Policy
    """
    def __new__(self, policies=[]):
        # Hackety hack.
        if len(policies) == 0:
            return drop
        else:
            rv = super(parallel, self).__new__(parallel, policies)
            rv.__init__(policies)
            return rv

    def __init__(self, policies=[]):
        if len(policies) == 0:
            raise TypeError
        super(parallel, self).__init__(policies)

    def __add__(self, pol):
        if isinstance(pol,parallel):
            return parallel(self.policies + pol.policies)
        else:
            return parallel(self.policies + [pol])

    def eval(self, pkt):
        """
        evaluates to the set union of the evaluation
        of self.policies on pkt

        :param pkt: the packet on which to be evaluated
        :type pkt: Packet
        :rtype: set Packet
        """
        output = set()
        for policy in self.policies:
            output |= policy.eval(pkt)
        return output

    def generate_classifier(self):
        if len(self.policies) == 0:  # EMPTY PARALLEL IS A DROP
            return drop.compile()
        classifiers = map(lambda p: p.compile(), self.policies)
        return reduce(lambda acc, c: acc + c, classifiers)


class union(parallel,Filter):
    """
    Combinator for several filter policies in parallel.

    :param policies: the policies to be combined.
    :type policies: list Filter
    """
    def __new__(self, policies=[]):
        # Hackety hack.
        if len(policies) == 0:
            return drop
        else:
            rv = super(parallel, self).__new__(union, policies)
            rv.__init__(policies)
            return rv

    def __init__(self, policies=[]):
        if len(policies) == 0:
            raise TypeError
        super(union, self).__init__(policies)

    ### or : Filter -> Filter
    def __or__(self, pol):
        if isinstance(pol,union):
            return union(self.policies + pol.policies)
        elif isinstance(pol,Filter):
            return union(self.policies + [pol])
        else:
            raise TypeError


class sequential(CombinatorPolicy):
    """
    Combinator for several policies in sequence.

    :param policies: the policies to be combined.
    :type policies: list Policy
    """
    def __new__(self, policies=[]):
        # Hackety hack.
        if len(policies) == 0:
            return identity
        else:
            rv = super(sequential, self).__new__(sequential, policies)
            rv.__init__(policies)
            return rv

    def __init__(self, policies=[]):
        if len(policies) == 0:
            raise TypeError
        super(sequential, self).__init__(policies)

    def __rshift__(self, pol):
        if isinstance(pol,sequential):
            return sequential(self.policies + pol.policies)
        else:
            return sequential(self.policies + [pol])

    def eval(self, pkt):
        """
        evaluates to the set union of each policy in 
        self.policies on each packet in the output of the 
        previous.  The first policy in self.policies is 
        evaled on pkt.

        :param pkt: the packet on which to be evaluated
        :type pkt: Packet
        :rtype: set Packet
        """
        prev_output = {pkt}
        output = prev_output
        for policy in self.policies:
            if not prev_output:
                return set()
            if policy == identity:
                continue
            if policy == drop:
                return set()
            output = set()
            for p in prev_output:
                output |= policy.eval(p)
            prev_output = output
        return output

    def generate_classifier(self):
        assert(len(self.policies) > 0)
        classifiers = map(lambda p: p.compile(),self.policies)
        for c in classifiers:
            assert(c is not None)
        return reduce(lambda acc, c: acc >> c, classifiers)
        

class intersection(sequential,Filter):
    """
    Combinator for several filter policies in sequence.

    :param policies: the policies to be combined.
    :type policies: list Filter
    """
    def __new__(self, policies=[]):
        # Hackety hack.
        if len(policies) == 0:
            return identity
        else:
            rv = super(sequential, self).__new__(intersection, policies)
            rv.__init__(policies)
            return rv

    def __init__(self, policies=[]):
        if len(policies) == 0:
            raise TypeError
        super(intersection, self).__init__(policies)

    ### and : Filter -> Filter
    def __and__(self, pol):
        if isinstance(pol,intersection):
            return intersection(self.policies + pol.policies)
        elif isinstance(pol,Filter):
            return intersection(self.policies + [pol])
        else:
            raise TypeError


################################################################################
# Derived Policies                                                             #
################################################################################

class DerivedPolicy(Policy):
    """
    Abstract class for a policy derived from another policy.

    :param policy: the internal policy (assigned to self.policy)
    :type policy: Policy
    """
    def __init__(self, policy=identity):
        self.policy = policy
        self._classifier = None
        super(DerivedPolicy,self).__init__()

    def eval(self, pkt):
        """
        evaluates to the output of self.policy.

        :param pkt: the packet on which to be evaluated
        :type pkt: Packet
        :rtype: set Packet
        """
        return self.policy.eval(pkt)

    def compile(self):
        """
        Produce a Classifier for this policy

        :rtype: Classifier
        """
        if NO_CACHE: 
            self._classifier = self.generate_classifier()
        if not self._classifier:
            self._classifier = self.generate_classifier()
        return self._classifier

    def generate_classifier(self):
        return self.policy.compile()

    def __repr__(self):
        return "[DerivedPolicy]\n%s" % repr(self.policy)

    def __eq__(self, other):
        return ( self.__class__ == other.__class__
           and ( self.policy == other.policy ) )


class difference(DerivedPolicy,Filter):
    """
    The difference between two filter policies..

    :param f1: the minuend
    :type f1: Filter
    :param f2: the subtrahend
    :type f2: Filter
    """
    def __init__(self, f1, f2):
       self.f1 = f1
       self.f2 = f2
       super(difference,self).__init__(~f2 & f1)

    def __repr__(self):
        return "difference:\n%s" % util.repr_plus([self.f1,self.f2])


class if_(DerivedPolicy):
    """
    if pred holds, t_branch, otherwise f_branch.

    :param pred: the predicate
    :type pred: Filter
    :param t_branch: the true branch policy
    :type pred: Policy
    :param f_branch: the false branch policy
    :type pred: Policy
    """
    def __init__(self, pred, t_branch, f_branch=identity):
        self.pred = pred
        self.t_branch = t_branch
        self.f_branch = f_branch
        super(if_,self).__init__((self.pred >> self.t_branch) +
                                 ((~self.pred) >> self.f_branch))

    def eval(self, pkt):
        if self.pred.eval(pkt):
            return self.t_branch.eval(pkt)
        else:
            return self.f_branch.eval(pkt)

    def __repr__(self):
        return "if\n%s\nthen\n%s\nelse\n%s" % (util.repr_plus([self.pred]),
                                               util.repr_plus([self.t_branch]),
                                               util.repr_plus([self.f_branch]))


class fwd(DerivedPolicy):
    """
    fwd out a specified port.

    :param outport: the port on which to forward.
    :type outport: int
    """
    def __init__(self, outport):
        self.outport = outport
        super(fwd,self).__init__(modify(outport=self.outport))

    def __repr__(self):
        return "fwd %s" % self.outport


class xfwd(DerivedPolicy):
    """
    fwd out a specified port, unless the packet came in on that same port.
    (Semantically equivalent to OpenFlow's forward action

    :param outport: the port on which to forward.
    :type outport: int
    """
    def __init__(self, outport):
        self.outport = outport
        super(xfwd,self).__init__((~match(inport=outport)) >> fwd(outport))

    def __repr__(self):
        return "xfwd %s" % self.outport


################################################################################
# Dynamic Policies                                                             #
################################################################################

class DynamicPolicy(DerivedPolicy):
    """
    Abstact class for dynamic policies.
    The behavior of a dynamic policy changes each time self.policy is reassigned.
    """
    ### init : unit -> unit
    def __init__(self,policy=drop):
        self._policy = policy
        self.notify = None
        self._classifier = None
        super(DerivedPolicy,self).__init__()

    def set_network(self, network):
        pass

    def attach(self,notify):
        self.notify = notify

    def detach(self):
        self.notify = None

    def changed(self):
        if self.notify:
            self.notify(self)

    @property
    def policy(self):
        return self._policy

    @policy.setter
    def policy(self, policy):
        prev_policy = self._policy
        self._policy = policy
        self.changed()

    def __repr__(self):
        return "[DynamicPolicy]\n%s" % repr(self.policy)


class DynamicFilter(DynamicPolicy,Filter):
    """
    Abstact class for dynamic filter policies.
    The behavior of a dynamic filter policy changes each time self.policy is reassigned.
    """
    pass


class flood(DynamicPolicy):
    """
    Policy that floods packets on a minimum spanning tree, recalculated
    every time the network is updated (set_network).
    """
    def __init__(self):
        self.mst = None
        super(flood,self).__init__()

    def set_network(self, network):
        changed = False
        if not network is None:
            updated_mst = Topology.minimum_spanning_tree(network.topology)
            if not self.mst is None:
                if self.mst != updated_mst:
                    self.mst = updated_mst
                    changed = True
            else:
                self.mst = updated_mst
                changed = True
        if changed:
            self.policy = parallel([
                    match(switch=switch) >>
                        parallel(map(xfwd,attrs['ports'].keys()))
                    for switch,attrs in self.mst.nodes(data=True)])

    def __repr__(self):
        try:
            return "flood on:\n%s" % self.mst
        except:
            return "flood"


class ingress_network(DynamicFilter):
    """
    Returns True if a packet is located at a (switch,inport) pair entering
    the network, False otherwise.
    """
    def __init__(self):
        self.egresses = None
        super(ingress_network,self).__init__()

    def set_network(self, network):
        updated_egresses = network.topology.egress_locations()
        if not self.egresses == updated_egresses:
            self.egresses = updated_egresses
            self.policy = parallel([match(switch=l.switch,
                                       inport=l.port_no)
                                 for l in self.egresses])

    def __repr__(self):
        return "ingress_network"


class egress_network(DynamicFilter):
    """
    Returns True if a packet is located at a (switch,outport) pair leaving
    the network, False otherwise.
    """
    def __init__(self):
        self.egresses = None
        super(egress_network,self).__init__()

    def set_network(self, network):
        updated_egresses = network.topology.egress_locations()
        if not self.egresses == updated_egresses:
            self.egresses = updated_egresses
            self.policy = parallel([match(switch=l.switch,
                                       outport=l.port_no)
                                 for l in self.egresses])

    def __repr__(self):
        return "egress_network"

########NEW FILE########
__FILENAME__ = language_tools
from pyretic.core.language import *

###############################################################################
# Class hierarchy syntax tree traversal

def ast_fold(fun, acc, policy):
    import pyretic.lib.query as query
    if (  policy == identity or
          policy == drop or
          isinstance(policy,match) or
          isinstance(policy,modify) or
          policy == Controller or
          isinstance(policy,Query)):
        return fun(acc,policy)
    elif (isinstance(policy,negate) or
          isinstance(policy,parallel) or
          isinstance(policy,union) or
          isinstance(policy,sequential) or
          isinstance(policy,intersection)):
        acc = fun(acc,policy)
        for sub_policy in policy.policies:
            acc = ast_fold(fun,acc,sub_policy)
        return acc
    elif (isinstance(policy,difference) or
          isinstance(policy,if_) or
          isinstance(policy,fwd) or
          isinstance(policy,xfwd) or
          isinstance(policy,DynamicPolicy) or
          isinstance(policy,query.packets)):
        acc = fun(acc,policy)
        return ast_fold(fun,acc,policy.policy)
    else:
        raise NotImplementedError
    
def add_dynamic_sub_pols(acc, policy):
    if isinstance(policy,DynamicPolicy):
        return acc | {policy}
    else:
        return acc

def add_query_sub_pols(acc, policy):
    from pyretic.lib.query import packets
    if ( isinstance(policy,Query) or
         isinstance(policy,packets)) : ### TODO remove this hack once packets is refactored 
        return acc | {policy}
    else:
        return acc

def add_all_sub_pols(acc, policy):
    return acc | {policy}

def queries_in_eval(acc, policy):
    res,pkts = acc
    if policy == drop:
        acc = (res,set())
    elif policy == identity:
        pass
    elif (isinstance(policy,match) or 
          isinstance(policy,modify) or 
          isinstance(policy,negate)):
        new_pkts = set()
        for pkt in pkts:
            new_pkts |= policy.eval(pkt)
        acc = (res,new_pkts)
    elif isinstance(policy,Query):
        acc = (res | {policy}, set())
    elif isinstance(policy,DerivedPolicy):
        acc = queries_in_eval(acc,policy.policy)
    elif isinstance(policy,parallel):
        parallel_res = set()
        parallel_pkts = set()
        for sub_pol in policy.policies:
            new_res,new_pkts = queries_in_eval((res,pkts),sub_pol)
            parallel_res |= new_res
            parallel_pkts |= new_pkts
        acc = (parallel_res,parallel_pkts)
    elif isinstance(policy,sequential):
        for sub_pol in policy.policies:
            acc = queries_in_eval(acc,sub_pol)
            if not acc[1]:
                break
    return acc


def on_recompile_path(acc,pol_id,policy):
    if (  policy == identity or
          policy == drop or
          isinstance(policy,match) or
          isinstance(policy,modify) or
          policy == Controller or
          isinstance(policy,Query)):
        return set()
    elif (isinstance(policy,negate) or
          isinstance(policy,parallel) or
          isinstance(policy,union) or
          isinstance(policy,sequential) or
          isinstance(policy,intersection)):
        sub_acc = set()
        for sub_policy in policy.policies:
            sub_acc |= on_recompile_path(sub_acc,pol_id,sub_policy)
        if sub_acc:
            return acc | {policy} | sub_acc
        else:
            return sub_acc
    elif isinstance(policy,DerivedPolicy):
        if id(policy) == pol_id:
            return acc | {policy}
        else:
            sub_acc = on_recompile_path(set(),pol_id,policy.policy)
            if sub_acc:
                return acc | {policy} | sub_acc
            else:
                return set()
    else:
        raise NotImplementedError

########NEW FILE########
__FILENAME__ = network

################################################################################
# The Pyretic Project                                                          #
# frenetic-lang.org/pyretic                                                    #
# author: Joshua Reich (jreich@cs.princeton.edu)                               #
# author: Christopher Monsanto (chris@monsan.to)                               #
################################################################################
# Licensed to the Pyretic Project by one or more contributors. See the         #
# NOTICES file distributed with this work for additional information           #
# regarding copyright and ownership. The Pyretic Project licenses this         #
# file to you under the following license.                                     #
#                                                                              #
# Redistribution and use in source and binary forms, with or without           #
# modification, are permitted provided the following conditions are met:       #
# - Redistributions of source code must retain the above copyright             #
#   notice, this list of conditions and the following disclaimer.              #
# - Redistributions in binary form must reproduce the above copyright          #
#   notice, this list of conditions and the following disclaimer in            #
#   the documentation or other materials provided with the distribution.       #
# - The names of the copyright holds and contributors may not be used to       #
#   endorse or promote products derived from this work without specific        #
#   prior written permission.                                                  #
#                                                                              #
# Unless required by applicable law or agreed to in writing, software          #
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT    #
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the     #
# LICENSE file distributed with this work for specific language governing      #
# permissions and limitations under the License.                               #
################################################################################

import socket
import struct
from bitarray import bitarray
import networkx as nx

from pyretic.core import util

### DEFINITIONS
OFPP_IN_PORT = 0xfff8
OFPP_CONTROLLER = 0xfffd

LLDP_TYPE = 0x88cc
ARP_TYPE = 0x806
IP_TYPE  = 0x800

################################################################################
# Fixed width stuff
################################################################################

class IPPrefix(object):
    def __init__(self, pattern):
        self.masklen = 32
        parts = pattern.split("/")
        self.pattern = IP(parts[0])
        if len(parts) == 2:
            self.masklen = int(parts[1])
        else:
            raise TypeError
        self.prefix = self.pattern.to_bits()[:self.masklen]

    def __eq__(self, other):
        """Match by checking prefix equality"""
        if isinstance(other,IPAddr):
            return self.prefix == other.to_bits()[:self.masklen]
        else:
            return False

    def __ne__(self, other):
        return not (self == other)

    def __hash__(self):
        return hash((self.pattern,self.masklen))

    def __repr__(self):
        return "%s/%d" % (repr(self.pattern),self.masklen)

class IPAddr(object):
    def __init__(self, ip):

        # already a IP object
        if isinstance(ip, IPAddr):
            self.bits = ip.bits

        # otherwise will be in byte or string encoding
        else:
            assert isinstance(ip, basestring)
            
            b = bitarray()

            # byte encoding
            if len(ip) == 4:
                b.frombytes(ip)

            # string encoding
            else:
                b.frombytes(socket.inet_aton(ip))

            self.bits = b

    def to_bits(self):
        return self.bits

    def to01(self):
        return self.bits.to01()

    def to_bytes(self):
        return self.bits.tobytes()

    def fromRaw(self):
        return self.to_bytes()

    def __repr__(self):
        return socket.inet_ntoa(self.to_bytes())

    def __hash__(self):
        return hash(self.to_bytes())    

    def __eq__(self,other):
        return repr(self) == repr(other)

    def __ne__(self, other):
        return not (self == other)

class IP(IPAddr):
    pass

            
class EthAddr(object):
    def __init__(self, mac):

        # already a MAC object
        if isinstance(mac, EthAddr):
            self.bits = mac.bits

        # otherwise will be in byte or string encoding
        else:
            assert isinstance(mac, basestring)
            
            b = bitarray()

            # byte encoding
            if len(mac) == 6:
                b.frombytes(mac)

            # string encoding
            else:
                import re
                m = re.match(r"""(?xi)
                             ([0-9a-f]{1,2})[:-]+
                             ([0-9a-f]{1,2})[:-]+
                             ([0-9a-f]{1,2})[:-]+
                             ([0-9a-f]{1,2})[:-]+
                             ([0-9a-f]{1,2})[:-]+
                             ([0-9a-f]{1,2})
                             """, mac)
                if not m:
                    raise ValueError
                else:
                    b.frombytes(struct.pack("!BBBBBB", *(int(s, 16) for s in m.groups())))

            self.bits = b
        
    def to_bits(self):
        return self.bits

    def to01(self):
        return self.bits.to01()

    def to_bytes(self):
        return self.bits.tobytes()

    def __repr__(self):
        parts = struct.unpack("!BBBBBB", self.to_bytes())
        mac = ":".join(hex(part)[2:].zfill(2) for part in parts)
        return mac

    def __hash__(self):
        return hash(self.to_bytes())

    def __eq__(self,other):
        return repr(self) == repr(other)

    def __ne__(self, other):
        return not (self == other)

class MAC(EthAddr):
    pass

################################################################################
# Tools
################################################################################
class Port(object):
    def __init__(self, port_no, config=True, status=True,linked_to=None):
        self.port_no = port_no
        self.config = config
        self.status = status
        self.linked_to = linked_to

    def definitely_down(self):
        return not self.config and not self.status

    def possibly_up(self):
        """User switch reports ports having LINK_DOWN status when in fact link is up"""
        return not self.definitely_down()

    def __hash__(self):
        return hash(self.port_no)

    def __eq__(self,other):
        return (self.port_no == other.port_no and 
                self.config == other.config and 
                self.status == other.status and 
                self.linked_to == other.linked_to)

    def __repr__(self):
        return "%d:config_up=%s:status_up=%s:linked_to=%s" % (self.port_no,self.config,self.status,self.linked_to)



class Location(object):
    def __init__(self,switch,port_no):
        self.switch = switch
        self.port_no = port_no

    def __hash__(self):
        return hash((self.switch, self.port_no))

    def __eq__(self,other):
        if other is None:
            return False
        return self.switch == other.switch and self.port_no == other.port_no

    def __repr__(self):
        return "%s[%s]" % (self.switch,self.port_no)


class Topology(nx.Graph):
    def __eq__(self,other):
        def exact_node_match(n1,n2):
            return n1 == n2
        def exact_edge_match(e1,e2):
            return e1 == e2
        return nx.is_isomorphic(self,other,node_match=exact_node_match,edge_match=exact_edge_match)

    def add_switch(self,switch):
        self.add_node(switch, name=switch, ports={})  

    def add_port(self,switch,port_no,config,status):
        self.node[switch]["ports"][port_no] = Port(port_no,config,status)

    def add_link(self,loc1,loc2):
        self.add_edge(loc1.switch, loc2.switch, {loc1.switch: loc1.port_no, loc2.switch: loc2.port_no})
        self.node[loc1.switch]['ports'][loc1.port_no].linked_to = loc2
        self.node[loc2.switch]['ports'][loc2.port_no].linked_to = loc1

    def is_connected(self):
        return nx.is_connected(self)

    def egress_locations(self,switch=None):
        locs = set()
        if switch is None:
            for s in self.nodes():
                locs |= (self.egress_locations(s))
        else:
            try: 
                for port in self.node[switch]['ports'].values():
                    if port.possibly_up() and port.linked_to is None:
                        locs.add(Location(switch,port.port_no))
            except KeyError:
                pass
        return locs

    def interior_locations(self,switch=None):
        locs = set()
        if switch is None:
            for s in self.nodes():
                locs |= (self.interior_locations(s))
        else:
            for port in self.node[switch]['ports'].values():
                if port.possibly_up() and not port.linked_to is None:
                    locs.add(Location(switch,port.port_no))
        return locs

    def copy_attributes(self,initial_topo):
        """TAKES A TRANSFORMED TOPOLOGY AND COPIES IN ATTRIBUTES FROM INITIAL TOPOLOGY"""
        for s,data in initial_topo.nodes(data=True):
            try:
                if self.node[s] == data:
                    # matching node data
                    pass
                else:
                    # reconcile node data
                    for (k,v) in data.items():
                        self.node[s][k] = v
            except KeyError:
                # removed node
                pass

        # REMOVE PORT ATTRIBUTES CORRESPONDING TO REMOVED EDGES
        for (s1,s2,data) in initial_topo.edges(data=True):
            try:
                if self[s1][s2] == data:
                    # matching edge data
                    pass
                else:
                    # copying edge data
                    for (k,v) in data.items():
                        self[s1][s2][k] = v
            except: 
                # no edge to copy
                pass

    ### TAKES A TRANSFORMED TOPOLOGY AND UPDATES ITS ATTRIBUTES
    def reconcile_attributes(self,initial_topo,new_egress=False):
        # REMOVE PORT ATTRIBUTES CORRESPONDING TO REMOVED EDGES
        for (s1,s2,data) in initial_topo.edges(data=True):
            try:
                if self[s1][s2] == data:
                    # matching edge data
                    pass
                else:
                    raise RuntimeError("NON-MATCHING EDGE DATA")
            except KeyError:  
               # removed edge, reconcile node ports"
                to_remove = [Location(s1,data[s1]),Location(s2,data[s2])]
                for loc in to_remove:
                    try:
                        new_port_nos = self.node[loc.switch]['ports'].copy() 
                        if new_egress:
                            new_port_nos[loc.port_no].linked_to = None
                        else:
                            del new_port_nos[loc.port_no]
                            self.node[loc.switch]['ports'] = new_port_nos
                    except KeyError:
                        pass                # node removed

    def filter_nodes(self, switches=[]):
        remove = [ s for s in self.nodes() if not s in switches] 
        return self.filter_out_nodes(remove)

    def filter_out_nodes(self, switches=[]):
        filtered_copy = self.copy()
        filtered_copy.remove_nodes_from(switches)
        filtered_copy.reconcile_attributes(self,new_egress=True)
        return filtered_copy

    @classmethod
    def difference(cls,topo1,topo2):
        try:
            self = cls(nx.difference(topo1,topo2))
        except nx.NetworkXError:
            return None

        if len(self.edges()) == 0:
            return None

        self.copy_attributes(topo1)
        self.reconcile_attributes(topo1)
        return self

    @classmethod
    def minimum_spanning_tree(cls,topology):
        self = cls(nx.minimum_spanning_tree(topology))
        self.copy_attributes(topology)
        self.reconcile_attributes(topology)
        return self
        
    ### A RANDOMIZED MINIMUM SPANNING TREE
    @classmethod
    def random_minimum_spanning_tree(cls,topology):
        self = cls(Kruskal(topology))
        self.copy_attributes(topology)
        self.reconcile_attributes(topology)
        return self

    ### HEURISTIC. PICKS A RANDOM MST, REMOVES FROM TOPOLOGY, ADD TO SET
    ### WHILE TOPOLOGY STILL CONNECTED, LOOP
    @classmethod
    def disjoint_minimum_spanning_tree_set(cls,topology):
        msts = set()
        remainder = topology.copy()
        if remainder is None or len(remainder) == 0 or not remainder.is_connected():
            return msts
        mst = (cls.random_minimum_spanning_tree(remainder))
        msts.add(mst)
        remainder = Topology.difference(remainder,mst)
        while(not remainder is None and remainder.is_connected()):
            mst = (cls.random_minimum_spanning_tree(remainder))
            msts.add(mst)
            remainder = Topology.difference(remainder,mst)
        return msts

    @classmethod
    def all_pairs_shortest_path(cls,topology):
        location_paths = {}
        switch_paths = nx.all_pairs_shortest_path(topology)
        for s1, paths in switch_paths.items():
            location_paths[s1] = {}
            for s2, path in paths.items():
                location_paths[s1][s2] = []
                cur = s1
                for nxt in path + [s2]:
                    if cur != nxt:
                        link = topology[cur][nxt]
                        loc = Location(cur,link[cur])
                        location_paths[s1][s2].append(loc)
                    cur = nxt
        return location_paths

    def __repr__(self):
        output_str = ''
        edge_str = {}
        egress_str = {}
        switch_str_maxlen = len('switch')
        edge_str_maxlen = len('internal links')
        egress_str_maxlen = len('egress ports')
        for switch in self.nodes():
            edge_str[switch] = \
                ', '.join([ "%s[%s] --- %s[%s]" % (s1,port_nos[s1],s2,port_nos[s2]) \
                                for (s1,s2,port_nos) in self.edges(data=True) \
                                if s1 == switch or s2 == switch])
            egress_str[switch] = \
                ', '.join([ "%s---" % l for l in self.egress_locations(switch)])

        if len(self.nodes()) > 0:
            edge_str_maxlen = \
                max( [len(ed) for ed in edge_str.values()] + [edge_str_maxlen] )
            egress_str_maxlen = \
                max( [len(eg) for eg in egress_str.values()] + [egress_str_maxlen] )

        table_width = switch_str_maxlen + 5 + edge_str_maxlen + 5 + egress_str_maxlen + 3
        output_str += '\n'.rjust(table_width+1,'-')
        output_str += "%s  |  %s  |  %s  |\n" % \
            ('switch','switch edges'.rjust(edge_str_maxlen/2+1).ljust(edge_str_maxlen),\
                 'egress ports'.rjust(egress_str_maxlen/2+1).ljust(egress_str_maxlen),)        
        output_str += '\n'.rjust(table_width+1,'-')
        for switch in self.nodes():
            edge_str[switch] = edge_str[switch].ljust(edge_str_maxlen)
            egress_str[switch] = egress_str[switch].ljust(egress_str_maxlen)
            output_str += "%s  |  %s  |  %s  |\n" % \
                (str(switch).ljust(switch_str_maxlen),edge_str[switch],egress_str[switch])
        output_str += ''.rjust(table_width,'-')
        return output_str
        
    def __str__(self):
        return repr(self)
        

class Network(object):
    """Abstract class for networks"""
    def __init__(self,topology=None):
        if topology is None:
            self._topology = Topology()
        else:
            self._topology = topology

    @property
    def topology(self):
        return self._topology
    
    @topology.setter
    def topology(self,topology):
        self._topology = topology

    def inject_packet(self, pkt):
        raise NotImplementedError

    def __eq__(self,other):
        if other is None:
            return False
        return self._topology == other._topology

    def copy(self):
        topology = self._topology.copy()
        network = Network(topology)
        network.inject_packet = self.inject_packet
        return network

########NEW FILE########
__FILENAME__ = packet
import struct, re
import pyretic.vendor

from ryu.lib.packet import *
from ryu.lib        import addrconv

from pyretic.core import util
from pyretic.core.network import IPAddr, EthAddr

__all__ = ['of_field', 'of_fields', 'get_packet_processor', 'Packet']
_field_list = dict()

IPV4 = 0x0800
IPV6 = 0x86dd
VLAN = 0x8100
ARP  = 0x0806

ICMP_PROTO = 1
TCP_PROTO  = 6
UDP_PROTO  = 17

##################################################
# EMPTY TEMPLATE PACKETS FOR DIFFERENT PROTCOLS 
##################################################
def arp_packet_gen():
    pkt = packet.Packet()
    pkt.protocols.append(ethernet.ethernet("ff:ff:ff:ff:ff:ff", "ff:ff:ff:ff:ff:ff", ARP))
    pkt.protocols.append(arp.arp())

    return pkt

def ipv6_packet_gen():
    pkt = packet.Packet()
    pkt.protocols.append(ethernet.ethernet("ff:ff:ff:ff:ff:ff", "ff:ff:ff:ff:ff:ff", IPV6))
    pkt.protocols.append(ipv6.ipv6(6, 0, 0, 0, 0, 0, '0:0:0:0:0:0:0:0', '0:0:0:0:0:0:0:0'))

    return pkt

def udp_packet_gen():
    pkt = packet.Packet()
    pkt.protocols.append(ethernet.ethernet("ff:ff:ff:ff:ff:ff", "ff:ff:ff:ff:ff:ff", IPV4))
    pkt.protocols.append(ipv4.ipv4(proto=UDP_PROTO))
    pkt.protocols.append(udp.udp(0, 0))

    return pkt

def tcp_packet_gen():
    pkt = packet.Packet()
    pkt.protocols.append(ethernet.ethernet("ff:ff:ff:ff:ff:ff", "ff:ff:ff:ff:ff:ff", IPV4))
    pkt.protocols.append(ipv4.ipv4(proto=TCP_PROTO))
    pkt.protocols.append(tcp.tcp(0, 0, 0, 0, 0, 0, 0, 0, 0))

    return pkt
def icmp_packet_gen():
    pkt = packet.Packet()
    pkt.protocols.append(ethernet.ethernet("ff:ff:ff:ff:ff:ff", "ff:ff:ff:ff:ff:ff", IPV4))
    pkt.protocols.append(ipv4.ipv4(proto=ICMP_PROTO))
    pkt.protocols.append(icmp.icmp(0, 0, 0))

    return pkt

ethertype_packets = {
    IPV4: {
        ICMP_PROTO: icmp_packet_gen,
        TCP_PROTO : tcp_packet_gen,
        UDP_PROTO : udp_packet_gen
    },
    IPV6: ipv6_packet_gen,
    ARP: arp_packet_gen
}

def build_empty_packet(ethertype, proto=None):
    if ethertype:
        pkt = ethertype_packets[ethertype]
        if proto is not None and not callable(pkt): pkt = pkt[proto]


        return pkt()

    return packet.Packet()


def of_fields(version="1.0"):
    return _field_list[version]

def get_protocol(ryu_pkt, protocol):
    for idx, i in enumerate(ryu_pkt.protocols):
        if hasattr(i, "protocol_name") and i.protocol_name==protocol:
            return idx

    return None

################################################################################
# Processor
################################################################################
class Processor(object):
    def __init__(self):
        pass

    def compile(self):
        fields = of_fields()
        fields = [field() for _, field in fields.items()]

        validators         = { field.validator.__class__.__name__: dict() for field in fields }

        for field in fields:
            exclusive_validators = validators[field.validator.__class__.__name__]
            exclusive_validators.setdefault(field.validator, set())
            exclusive_validators[field.validator].add(field)

        def extract_exclusive_headers(ryu_pkt, exclusive_groups):
                headers = {}
                for validator, fields in exclusive_groups.items():
                    if not iter(fields).next().is_valid(ryu_pkt):
                        continue

                    for field in fields:
                        headers[field.pyretic_field] = field.decode(ryu_pkt)

                    break

                return headers

        def pack_pyretic_headers(pyr_pkt, tmp_pkt, exclusive_groups):
                headers = {}
                for validator, fields in exclusive_groups.items():
                    if not iter(fields).next().is_valid(pyr_pkt):
                        continue

                    for field in fields:
                        field.encode_in_place(pyr_pkt, tmp_pkt)

                    break

                return pyr_pkt

        def expand(ryu_pkt):
            if not isinstance(ryu_pkt, packet.Packet):
                ryu_pkt = packet.Packet(ryu_pkt)

            headers = {}

            for key, exclusive_groups in validators.items():
                headers.update( extract_exclusive_headers(ryu_pkt, exclusive_groups) )

            return headers

        def contract(pyr_pkt):
            pkt = packet.Packet(pyr_pkt['raw'])

            if len(pyr_pkt['raw']) == 0:
                pkt = build_empty_packet(pyr_pkt.get('ethtype', None), pyr_pkt.get('protocol', None))

            def convert(h, v):
                if isinstance(v, IPAddr):
                    return str(v)
                elif isinstance(v, EthAddr):
                    return str(v)
                else:
                    return v

            pyr_pkt = { h : convert(h, v) for h,v in pyr_pkt.items() }


            for key, exclusive_groups in validators.items():
                pack_pyretic_headers(pyr_pkt, pkt, exclusive_groups)

            pkt.serialize()
            pyr_pkt['raw'] = str(pkt.data)

            return str(pkt.data)


        setattr(self, 'unpack', expand)
        setattr(self, 'pack', contract)

        # Build the packet processor pipeline
        return self

def get_packet_processor():
    try:
        return get_packet_processor.processor   
    except AttributeError:
        get_packet_processor.processor = Processor().compile()
        return get_packet_processor.processor

################################################################################
# Field Validators
################################################################################
class Validator(object):
    __slots__ = ['value']

    def __init__(self, value):
        self.value = value

    def __eq__(self, other):
        return self.__class__ == other.__class__ and self.value == other.value

    def __repr__(self):
        return "%s: %s" % (self.__class__.__name__, self.value)

    def __hash__(self):
        return hash("%s_%s" % (self.__class__.__name__, self.value))

    def __call__(self, obj, pkt):
        if isinstance(pkt, packet.Packet):
            return self.validate_ryu_packet(obj, pkt)

        return self.validate_pyretic_packet(obj, pkt)

class ProtocolValidator(Validator):
    def validate_ryu_packet(self, obj, ryu_pkt):
        try:
            return obj.protocol(ryu_pkt, "ipv4").proto == self.value
        except:
            return False

    def validate_pyretic_packet(self, obj, pkt):
        try:
            return pkt["protocol"] == self.value
        except:
            return False



class EthertypeValidator(Validator):
    def validate_ryu_packet(self, obj, ryu_pkt):
        try:
            layer = obj.protocol(ryu_pkt, "vlan")
            if layer is None: layer = obj.protocol(ryu_pkt, "ethernet")
            return layer.ethertype == self.value
        except:
            return False

    def validate_pyretic_packet(self, obj, pkt):
        try:
            return pkt["ethtype"] == self.value
        except:
            return False

class VlanValidator(Validator):
    def __init__(self):
        self.value = VLAN


    def validate_ryu_packet(self, obj, ryu_pkt):
        try:
            return obj.protocol(ryu_pkt, "ethernet").ethertype == VLAN
        except:
            return False

    def validate_pyretic_packet(self, obj, pkt):
        if (not 'vlan_id' in pkt) and (not 'vlan_pcp' in pkt):
            return True

        try: return 'vlan_id' in pkt
        except: return False

        try: return 'vlan_pcp' in pkt
        except: return False


class TrueValidator(Validator):
    def validate_ryu_packet(self, obj, ryu_pkt):
        return True

    def validate_pyretic_packet(self, obj, pkt):
        return True

def proto_validator(value):
    return ProtocolValidator(value)

def ether_validator(value):
    return EthertypeValidator(value)

def true_validator(*args, **kwargs):
    return TrueValidator(True)

def vlan_validator(*args, **kwargs):
    return VlanValidator()


################################################################################
# Field Decorator
################################################################################
def of_field(match="", pyretic_field="", validator=true_validator(), version="1.0"):
    matches = match.split(".")

    def _of_field(cls):
        if len(matches) == 2: protocol, field = matches

        def get_protocol(ryu_pkt, protocol):
            for idx, i in enumerate(ryu_pkt.protocols):
                if hasattr(i, "protocol_name") and i.protocol_name==protocol:
                    return idx

            return None

        def _get_protocol(self, ryu_pkt, _protocol = None):
            if _protocol is None:
                _protocol = protocol

            idx = get_protocol(ryu_pkt, _protocol)
            if idx is None: return None

            return ryu_pkt.protocols[idx]

        def field_decode(self, ryu_pkt):
            #if not self.is_valid(ryu_pkt): return None

            layer = self.protocol(ryu_pkt)
            if layer is None: return None

            return getattr(layer, field)

        def field_encode(self, pyretic_pkt):
            pkt = packet.Packet(pyretic_pkt['raw'])

            field_encode_in_place(self, pyretic_pkt, pkt)

            pkt.serialize()
            pyretic_pkt['raw'] = pkt.data

            return pyretic_pkt

        def field_encode_in_place(self, pyretic_pkt, pkt):
            if not pyretic_field in pyretic_pkt: return pyretic_pkt

            layer = self.protocol(pkt)
            # Try to create the layer if it's not found
            if layer is None: raise ValueError

            setattr(layer, field, pyretic_pkt[pyretic_field])

            return pyretic_pkt


        def is_valid(self, ryu_pkt):
            return self.validator(self, ryu_pkt)

        # Add this field as an available field
        _field_list.setdefault(version, dict())
        _field_list[version][cls.__name__] = cls

        # Augment field clss with proper attributes and methods
        if not hasattr(cls, "protocol"): setattr(cls, "protocol", _get_protocol)
        if not hasattr(cls, "validator"): setattr(cls, "validator", validator)
        if not hasattr(cls, "is_valid"): setattr(cls, "is_valid", is_valid)
        if not hasattr(cls, "decode"): setattr(cls, "decode", field_decode)
        if not hasattr(cls, "encode"): setattr(cls, "encode", field_encode)
        if not hasattr(cls, "encode_in_place"): setattr(cls, "encode_in_place", field_encode_in_place)
        if not hasattr(cls, "pyretic_field"): setattr(cls, "pyretic_field", pyretic_field)

        return cls

    return _of_field

#######################
# OPENFLOW 1.0 FIELDS
#######################
@of_field("udp.dst_port", "dstport", proto_validator(UDP_PROTO), "1.0")
class UdpDstPort(object): pass

@of_field("udp.src_port", "srcport", proto_validator(UDP_PROTO), "1.0")
class UdpSrcPort(object): pass

@of_field("tcp.dst_port", "dstport", proto_validator(TCP_PROTO), "1.0")
class TcpDstPort(object): pass

@of_field("tcp.src_port", "srcport", proto_validator(TCP_PROTO), "1.0")
class TcpSrcPort(object): pass

@of_field("vlan.pcp", "vlan_pcp", vlan_validator(), "1.0")
class VlanPcp(object):
    def encode_in_place(self, pyr, pkt):
        if (not 'vlan_id' in pyr and not 'vlan_pcp' in pyr and vlan.vlan in pkt):
            for idx, proto in enumerate(pkt.protocols):
                if isinstance(proto, vlan.vlan):
                    pkt.protocols.pop(idx)

            return pyr

        if not 'vlan_pcp' in pyr:
            return pyr

        if not vlan.vlan in pkt:
            pkt.protocols.insert(1, vlan.vlan(ethertype=pkt.protocols[0].ethertype))

        gen = (protocol for protocol in pkt.protocols if protocol.__class__ == vlan.vlan)
        vl = gen.next()
        vl.pcp = pyr['vlan_pcp']
        pkt.protocols[0].ethertype = VLAN

        return pyr

@of_field("vlan.vid", "vlan_id", vlan_validator(), "1.0")
class VlanID(object):
    def encode_in_place(self, pyr, pkt):
        if (not 'vlan_id' in pyr and not 'vlan_pcp' in pyr and vlan.vlan in pkt):
            for idx, proto in enumerate(pkt.protocols):
                if isinstance(proto, vlan.vlan):
                    pkt.protocols.pop(idx)

            return pyr

        if not 'vlan_id' in pyr:
            return pyr

        if not vlan.vlan in pkt:
            pkt.protocols.insert(1, vlan.vlan(ethertype=pkt.protocols[0].ethertype))

        gen = (protocol for protocol in pkt.protocols if protocol.__class__ == vlan.vlan)
        vl = gen.next()
        vl.vid = pyr['vlan_id']
        pkt.protocols[0].ethertype = VLAN

        return pyr

@of_field("ethernet.src", "srcmac", version="1.0")
class SrcMac(object): pass

@of_field("ethernet.dst", "dstmac", version="1.0")
class DstMac(object): pass

@of_field("", "header_len", version="1.0")
class HeaderLength(object):
    def decode(self, ryu_pkt):
        return len(ryu_pkt.protocols[0])

    def encode_in_place(self, pyr, pkt):
        return pyr

@of_field("", "payload_len", version="1.0")
class PayloadLength(object):
    def decode(self, ryu_pkt):
        return len(ryu_pkt.data)

    def encode_in_place(self, pyr, pkt):
        return pyr


@of_field("ethernet.ethertype", "ethtype", version="1.0")
class EthType(object):
    def decode(self, ryu_pkt):
        try:
            layer = self.protocol(ryu_pkt, 'vlan')
            if layer is None: layer = self.protocol(ryu_pkt, 'ethernet')

            return layer.ethertype
        except:
            return None

@of_field("ipv6.srcip", "srcip", ether_validator(IPV6), version="1.0")
class Ipv6SrcIp(object): pass

@of_field("ipv6.dstip", "dstip", ether_validator(IPV6), version="1.0")
class Ipv6DstIp(object): pass

@of_field("ipv4.src", "srcip", ether_validator(IPV4), version="1.0")
class Ipv4SrcIp(object): pass

@of_field("ipv4.dst", "dstip", ether_validator(IPV4), version="1.0")
class Ipv4DstIp(object): pass

@of_field("ipv4.proto", "protocol", ether_validator(IPV4), version="1.0")
class Protocol(object): pass

@of_field("ipv4.tos", "tos", ether_validator(IPV4), version="1.0")
class TOS(object): pass

@of_field("icmp.type", "srcport", proto_validator(ICMP_PROTO), version="1.0")
class IcmpType(object): pass

@of_field("icmp.code", "dstport", proto_validator(ICMP_PROTO), version="1.0")
class IcmpCode(object): pass

@of_field("arp.opcode", "protocol", ether_validator(ARP), version="1.0")
class ArpOpcode(object): pass

@of_field("arp.src_ip", "srcip", ether_validator(ARP), version="1.0")
class ArpSrcIp(object): pass

@of_field("arp.dst_ip", "dstip", ether_validator(ARP), version="1.0")
class ArpDstIp(object): pass

################################################################################
# Packet 
################################################################################
class Packet(object):
    __slots__ = ["header"]
    
    def __init__(self, state={}):
        self.header = util.frozendict(state)

    def available_fields(self):
        return self.header.keys()

    def __eq__(self, other):
        return ( id(self) == id(other)
                 or ( isinstance(other, self.__class__)
                      and self.header == other.header ) )

    def __ne__(self, other):
        return not (self == other)
    
    def modifymany(self, d):
        add = {}
        delete = []
        for k, v in d.items():
            if v is None:
                delete.append(k)
            else:
                add[k] = v
        return Packet(self.header.update(add).remove(delete))


    def modify(self, **kwargs):
        return self.modifymany(kwargs)

    def virtual(self, layer, item):
        v = self.header.get(('v_%s_%s' % (layer, item)), None)

        if v is None:
            raise KeyError(item)

        return v

    def __getitem__(self, item):
        return self.header[item]

    def __hash__(self):
        return hash(self.header)
        
    def __repr__(self):
        import hashlib
        fixed_fields = {}
        fixed_fields['location'] = ['switch', 'inport', 'outport']
        fixed_fields['vlocation'] = ['vswitch', 'vinport', 'voutport']
        fixed_fields['source']   = ['srcip', 'srcmac']
        fixed_fields['dest']     = ['dstip', 'dstmac']
        order = ['location','vlocation','source','dest']
        all_fields = self.header.keys()
        outer = []
        size = max(map(len, self.header) or map(len, order) or [len('md5'),0]) + 3
        ### LOCATION, VLOCATION, SOURCE, and DEST - EACH ON ONE LINE
        for fields in order:
            inner = ["%s:%s" % (fields, " " * (size - len(fields)))]
            all_none = True
            for field in fixed_fields[fields]:
                try:             
                    all_fields.remove(field)
                except:          
                    pass
                try:             
                    inner.append(repr(self.header[field])) 
                    all_none = False
                except KeyError: 
                    inner.append('None')
            if not all_none:
                outer.append('\t'.join(inner))
        ### MD5 OF PAYLOAD
        field = 'raw'
        outer.append("%s:%s%s" % ('md5',
                                    " " * (size - len(field)),
                                    hashlib.md5(self.header[field]).hexdigest()))
        all_fields.remove(field)
        ### ANY ADDITIONAL FIELDS
        for field in sorted(all_fields):
            try:             
                if self.header[field]:
                    outer.append("%s:%s\t%s" % (field,
                                                " " * (size - len(field)),
                                                repr(self.header[field])))
            except KeyError: 
                pass
        return "\n".join(outer)

########NEW FILE########
__FILENAME__ = runtime
################################################################################
# The Pyretic Project                                                          #
# frenetic-lang.org/pyretic                                                    #
# author: Joshua Reich (jreich@cs.princeton.edu)                               #
# author: Christopher Monsanto (chris@monsan.to)                               #
################################################################################
# Licensed to the Pyretic Project by one or more contributors. See the         #
# NOTICES file distributed with this work for additional information           #
# regarding copyright and ownership. The Pyretic Project licenses this         #
# file to you under the following license.                                     #
#                                                                              #
# Redistribution and use in source and binary forms, with or without           #
# modification, are permitted provided the following conditions are met:       #
# - Redistributions of source code must retain the above copyright             #
#   notice, this list of conditions and the following disclaimer.              #
# - Redistributions in binary form must reproduce the above copyright          #
#   notice, this list of conditions and the following disclaimer in            #
#   the documentation or other materials provided with the distribution.       #
# - The names of the copyright holds and contributors may not be used to       #
#   endorse or promote products derived from this work without specific        #
#   prior written permission.                                                  #
#                                                                              #
# Unless required by applicable law or agreed to in writing, software          #
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT    #
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the     #
# LICENSE file distributed with this work for specific language governing      #
# permissions and limitations under the License.                               #
################################################################################

import pyretic.core.util as util

from pyretic.core.language import *
from pyretic.core.language_tools import *
from pyretic.core.network import *
from pyretic.core.packet import *

from multiprocessing import Process, Manager, RLock, Lock, Value, Queue, Condition
import logging, sys, time
from datetime import datetime

TABLE_MISS_PRIORITY = 0

class Runtime(object):
    """
    The Runtime system.  Includes packet handling, compilation to OF switches,
    topology maintenance, dynamic update of policies, querying support, etc.
    
    :param backend: handles the connection to switches
    :type backend: Backend
    :param main: the program to run
    :type main: pyretic program (.py)
    :param kwargs: arguments to main
    :type kwargs: dict from strings to values
    :param mode: one of interpreted/i, reactive0/r0, proactive0/p0
    :type mode: string
    :param verbosity: one of low, normal, high, please-make-it-stop
    :type verbosity: string
    """
    def __init__(self, backend, main, kwargs, mode='interpreted', verbosity='normal'):
        self.verbosity = self.verbosity_numeric(verbosity)
        self.log = logging.getLogger('%s.Runtime' % __name__)
        self.network = ConcreteNetwork(self)
        self.prev_network = self.network.copy()
        self.policy = main(**kwargs)
        self.mode = mode
        self.backend = backend
        self.backend.runtime = self
        self.policy_lock = RLock()
        self.network_lock = Lock()
        self.switch_lock = Lock()
        self.vlan_to_extended_values_db = {}
        self.extended_values_to_vlan_db = {}
        self.extended_values_lock = RLock()
        self.dynamic_sub_pols = set()
        self.update_dynamic_sub_pols()
        self.in_network_update = False
        self.in_bucket_apply = False
        self.network_triggered_policy_update = False
        self.bucket_triggered_policy_update = False
        self.global_outstanding_queries_lock = Lock()
        self.global_outstanding_queries = {}
        self.manager = Manager()
        self.old_rules_lock = Lock()
        self.old_rules = self.manager.list()
        self.update_rules_lock = Lock()
        self.update_buckets_lock = Lock()

    def verbosity_numeric(self,verbosity_option):
        numeric_map = { 'low': 1,
                        'normal': 2,
                        'high': 3,
                        'please-make-it-stop': 4}
        return numeric_map.get(verbosity_option, 0)


######################
# PACKET INTERPRETER 
######################

    def handle_packet_in(self, concrete_pkt):
        """
        The packet interpreter.
        
        :param concrete_packet: the packet to be interpreted.
        :type limit: payload of an OpenFlow packet_in message.
        """
        with self.policy_lock:
            pyretic_pkt = self.concrete2pyretic(concrete_pkt)

            # find the queries, if any in the policy, that will be evaluated
            queries,pkts = queries_in_eval((set(),{pyretic_pkt}),self.policy)

            # evaluate the policy
            output = self.policy.eval(pyretic_pkt)

            # apply the queries whose buckets have received new packets
            self.in_bucket_apply = True
            for q in queries:
                q.apply()
            self.in_bucket_apply = False
            
            # if the query changed the policy, update the controller and switch state
            if self.bucket_triggered_policy_update:
                self.update_dynamic_sub_pols()
                self.update_switch_classifiers()
                self.bucket_triggered_policy_update = False
                    
        # send output of evaluation into the network
        concrete_output = map(self.pyretic2concrete,output)
        map(self.send_packet,concrete_output)

        # if in reactive mode and no packets are forwarded to buckets, install microflow
        # Note: lack of forwarding to bucket implies no bucket-trigger update could have occured
        if self.mode == 'reactive0' and not queries:
            self.reactive0_install(pyretic_pkt,output)


#############
# DYNAMICS  
#############

    def handle_policy_change(self,sub_pol):
        """
        Updates runtime behavior (both interpreter and switch classifiers)
        some sub-policy in self.policy changes.
        """
        with self.policy_lock:

            # tag stale classifiers as invalid
            map(lambda p: p.invalidate_classifier(), 
                on_recompile_path(set(),id(sub_pol),self.policy))

            # if change was driven by a network update, flag
            if self.in_network_update:
                self.network_triggered_policy_update = True

            # if this change driven by a bucket side-effect, flag
            elif self.in_bucket_apply:
                self.bucket_triggered_policy_update = True

            # otherwise, update controller and switches accordingly
            else:
                self.update_dynamic_sub_pols()
                self.update_switch_classifiers()


    def handle_network_change(self):
        """
        Updates runtime behavior (both interpreter and switch classifiers)
        when the concrete network topology changes.
        """
        with self.network_lock:

            # if the topology hasn't changed, ignore
            if self.network.topology == self.prev_network.topology:
                return

            # otherwise copy the network object
            self.in_network_update = True
            self.prev_network = self.network.copy()

            # update the policy w/ the new network object
            with self.policy_lock:
                for policy in self.dynamic_sub_pols:
                    policy.set_network(self.network)

                # FIXME(joshreich) :-)
                # This is a temporary fix. We need to specialize the check below
                # instead of removing it completely, but will let @joshreich
                # take care of it. -- ngsrinivas
                # if self.network_triggered_policy_update:
                self.update_dynamic_sub_pols()
                self.update_switch_classifiers()
                self.network_triggered_policy_update = False

            self.in_network_update = False

    
    def update_switch_classifiers(self):
        """
        Updates switch classifiers
        """
        classifier = None
        
        if self.mode == 'reactive0':
            self.clear_all() 

        elif self.mode == 'proactive0' or self.mode == 'proactive1':
            classifier = self.policy.compile()
            self.log.debug(
                '|%s|\n\t%s\n\t%s\n\t%s\n' % (str(datetime.now()),
                                              "generate classifier",
                                              "policy="+repr(self.policy),
                                              "classifier="+repr(classifier)))
            self.install_classifier(classifier)


    def update_dynamic_sub_pols(self):
        """
        Updates the set of active dynamic sub-policies in self.policy
        """
        import copy
        old_dynamic_sub_pols = copy.copy(self.dynamic_sub_pols)
        self.dynamic_sub_pols = ast_fold(add_dynamic_sub_pols, set(), self.policy)
        for p in (old_dynamic_sub_pols - self.dynamic_sub_pols):
            p.detach()
        for p in (self.dynamic_sub_pols - old_dynamic_sub_pols):
            p.set_network(self.network)
            p.attach(self.handle_policy_change)


#######################
# REACTIVE COMPILATION
#######################

    def reactive0_install(self,in_pkt,out_pkts):
        """
        Reactively installs switch table entries based on a given policy evaluation.

        :param in_pkt: the input on which the policy was evaluated
        :type in_pkt: Packet
        :param out_pkts: the output of the evaluation
        :type out_pkts: set Packet
        """
        rule_tuple = self.match_on_all_fields_rule_tuple(in_pkt,out_pkts)
        if rule_tuple:
            self.install_rule(rule_tuple)
            self.log.debug(
                '|%s|\n\t%s\n\t%s\n\t%s\n' % (str(datetime.now()),
                                              " | install rule",
                                              rule_tuple[0],
                                              'actions='+repr(rule_tuple[2])))

    def match_on_all_fields(self, pkt):
        """
        Produces a concrete predicate exactly matching a given packet.

        :param pkt: the packet to match
        :type pkt: Packet
        :returns: an exact-match predicate 
        :rtype: dict of strings to values
        """        
        pred = pkt.copy()
        del pred['header_len']
        del pred['payload_len']
        del pred['raw']
        return pred

    def match_on_all_fields_rule_tuple(self, pkt_in, pkts_out):
        """
        Produces a rule tuple exactly matching a given packet 
        and outputing a given set of packets..

        :param pkt_in: the input packet
        :type pkt_in: Packet
        :param pkts_out: the output packets
        :type pkts_out: set Packet
        :returns: an exact-match (microflow) rule 
        :rtype: (dict of strings to values, int, list int)
        """        
        concrete_pkt_in = self.pyretic2concrete(pkt_in)
        concrete_pred = self.match_on_all_fields(concrete_pkt_in)
        action_list = []
        
        ### IF NO PKTS OUT THEN INSTALL DROP (EMPTY ACTION LIST)
        if len(pkts_out) == 0:
            return (concrete_pred,0,action_list)

        for pkt_out in pkts_out:
            concrete_pkt_out = self.pyretic2concrete(pkt_out)
            actions = {}
            header_fields = set(concrete_pkt_out.keys()) | set(concrete_pkt_in.keys())
            for field in header_fields:
                if field not in native_headers + ['outport']:
                    continue
                try:
                    in_val = concrete_pkt_in[field]
                except:
                    in_val = None
                try:
                    out_val = concrete_pkt_out[field]
                except:
                    out_val = None
                if not out_val == in_val: 
                    actions[field] = out_val
            action_list.append(actions)

        # DEAL W/ BUG IN OVS ACCEPTING ARP RULES THAT AREN'T ACTUALLY EXECUTED
        if pkt_in['ethtype'] == ARP_TYPE: 
            for action_set in action_list:
                if len(action_set) > 1:
                    return None

        return (concrete_pred,0,action_list)


#########################
# PROACTIVE COMPILATION 
#########################

    def install_classifier(self, classifier):
        """
        Proactively installs switch table entries based on the input classifier

        :param classifier: the input classifer
        :type classifier: Classifier
        """
        if classifier is None:
            return

        ### CLASSIFIER TRANSFORMS 

        # TODO (josh) logic for detecting action sets that can't be compiled
        # e.g., {modify(dstip='10.0.0.1',outport=1),modify(srcip='10.0.0.2',outport=2)]

        def remove_identity(classifier):
            """
            Removes identity policies from the action list.
            
            :param classifier: the input classifer
            :type classifier: Classifier
            :returns: the output classifier
            :rtype: Classifier
            """
            return Classifier(Rule(rule.match,
                                   filter(lambda a: a != identity,rule.actions))
                              for rule in classifier.rules)
                
        def controllerify(classifier):
            """
            Replaces each rule whose actions includes a send to controller action
            with one whose sole action sends packets to the controller. (Thereby
            avoiding the tricky situation of needing to determine whether a given 
            packet reached the controller b/c that packet is being forwarded to a 
            query bucket or b/c corresponding rules haven't yet been installed.
                        
            :param classifier: the input classifer
            :type classifier: Classifier
            :returns: the output classifier
            :rtype: Classifier
            """
            def controllerify_rule(rule):
                if reduce(lambda acc, a: acc | (a == Controller),rule.actions,False):
                    # DISCUSS (cole): should other actions be taken at the switch
                    # before sending to the controller?  i.e. a policy like:
                    # modify(srcip=1) >> ToController.
                    return Rule(rule.match,[Controller])
                else:
                    return rule
            return Classifier(controllerify_rule(rule) 
                              for rule in classifier.rules)

        def vlan_specialize(classifier):
            """
            Add Openflow's "default" VLAN match to identify packets which
            don't have any VLAN tags on them.

            :param classifier: the input classifer
            :type classifier: Classifier
            :returns: the output classifier
            :rtype: Classifier
            """
            specialized_rules = []
            default_vlan_match = match(vlan_id=0xFFFF, vlan_pcp=0)
            for rule in classifier.rules:
                if ( ( isinstance(rule.match, match) and
                       not 'vlan_id' in rule.match.map ) or
                     rule.match == identity ):
                    specialized_rules.append(Rule(rule.match.intersect(default_vlan_match),
                                                  rule.actions))
                else:
                    specialized_rules.append(rule)
            return Classifier(specialized_rules)

        def layer_3_specialize(classifier):
            """
            Specialize a layer-3 rule to several rules that match on layer-2 fields.
            OpenFlow requires a layer-3 match to match on layer-2 ethtype.  Also, 
            make sure that LLDP packets are reserved for use by the runtime.
            
            :param classifier: the input classifer
            :type classifier: Classifier
            :returns: the output classifier
            :rtype: Classifier
            """
            specialized_rules = []
            # Add a rule that routes the LLDP messages to the controller for topology maintenance.
            specialized_rules.append(Rule(match(ethtype=LLDP_TYPE),[Controller]))
            for rule in classifier.rules:
                if ( isinstance(rule.match, match) and
                     ( 'srcip' in rule.match.map or 
                       'dstip' in rule.match.map ) and 
                     not 'ethtype' in rule.match.map ):
                    specialized_rules.append(Rule(rule.match & match(ethtype=IP_TYPE),rule.actions))

                    # DEAL W/ BUG IN OVS ACCEPTING ARP RULES THAT AREN'T ACTUALLY EXECUTED
                    arp_bug = False
                    for action in rule.actions:
                        if action == Controller or isinstance(action, CountBucket):
                            pass
                        elif len(action.map) > 1:
                            arp_bug = True
                            break
                    if arp_bug:
                        specialized_rules.append(Rule(rule.match & match(ethtype=ARP_TYPE),[Controller]))
                    else:
                        specialized_rules.append(Rule(rule.match & match(ethtype=ARP_TYPE),rule.actions))
                else:
                    specialized_rules.append(rule)
            return Classifier(specialized_rules)

        def bookkeep_buckets(classifier):
            """
            Whenever rules are associated with counting buckets,
            add a reference to the classifier rule into the respective
            bucket for querying later. Count bucket actions operate at
            the pyretic level and are removed before installing rules.

            :param classifier: the input classifer
            :type classifier: Classifier
            :returns: the output classifier
            :rtype: Classifier
            """
            def collect_buckets(rules):
                """
                Scan classifier rules and collect distinct buckets into a
                dictionary.
                """
                bucket_list = {}
                for rule in rules:
                    for act in rule.actions:
                        if isinstance(act, CountBucket):
                            if not id(act) in bucket_list:
                                bucket_list[id(act)] = act
                return bucket_list

            def start_update(bucket_list):
                for b in bucket_list.values():
                    b.start_update()

            def hook_buckets_to_rule(rule):
                for act in rule.actions:
                    if isinstance(act, CountBucket):
                        act.add_match(rule.match)

            def hook_buckets_to_pull_stats(bucket_list):
                for b in bucket_list.values():
                    b.add_pull_stats(self.pull_stats_for_bucket(b))

            def finish_update(bucket_list):
                for b in bucket_list.values():
                    b.finish_update()

            with self.update_buckets_lock:
                """The start_update and finish_update functions per bucket guard
                against inconsistent state in a single bucket, and the global
                "update buckets" lock guards against inconsistent classifier
                match state *across* buckets.
                """
                bucket_list = collect_buckets(classifier.rules)
                start_update(bucket_list)
                map(hook_buckets_to_rule, classifier.rules)
                hook_buckets_to_pull_stats(bucket_list)
                finish_update(bucket_list)
        
        def remove_buckets(classifier):
            """
            Remove CountBucket policies from classifier rule actions.
            
            :param classifier: the input classifer
            :type classifier: Classifier
            :returns: the output classifier
            :rtype: Classifier
            """
            return Classifier(Rule(rule.match,
                                   filter(lambda a: 
                                          not isinstance(a, CountBucket),
                                          rule.actions))
                              for rule in classifier.rules)

        def switchify(classifier,switches):
            """
            Specialize a classifer to a set of switches.  Any rule that doesn't 
            specify a match on switch is turned into a set of rules matching on
            each switch respectively.
            
            :param classifier: the input classifer
            :type classifier: Classifier
            :param switches: the network switches
            :type switches: set int
            :returns: the output classifier
            :rtype: Classifier
            """
            new_rules = list()
            for rule in classifier.rules:
                if isinstance(rule.match, match) and 'switch' in rule.match.map:
                    if not rule.match.map['switch'] in switches:
                        continue
                    new_rules.append(rule)
                else:
                    for s in switches:
                        new_rules.append(Rule(
                                rule.match.intersect(match(switch=s)),
                                rule.actions))
            return Classifier(new_rules)

        def concretize(classifier):
            """
            Convert policies into dictionaries.
            
            :param classifier: the input classifer
            :type classifier: Classifier
            :returns: the output classifier
            :rtype: Classifier
            """
            def concretize_rule_actions(rule):
                def concretize_match(pred):
                    if pred == false:
                        return None
                    elif pred == true:
                        return {}
                    elif isinstance(pred, match):
                        return { k:v for (k,v) in pred.map.items() }
                def concretize_action(a):
                    if a == Controller:
                        return {'outport' : OFPP_CONTROLLER}
                    elif isinstance(a,modify):
                        return { k:v for (k,v) in a.map.items() }
                    else: # default
                        return a
                m = concretize_match(rule.match)
                acts = [concretize_action(a) for a in rule.actions]
                if m is None:
                    return None
                else:
                    return Rule(m,acts)
            crs = [concretize_rule_actions(r) for r in classifier.rules]
            crs = filter(lambda cr: not cr is None,crs)
            return Classifier(crs)

        def check_OF_rules(classifier):
            def check_OF_rule_has_outport(r):
                for a in r.actions:
                    if not 'outport' in a:
                        raise TypeError('Invalid rule: concrete actions must have an outport',str(r))  
            def check_OF_rule_has_compilable_action_list(r):
                if len(r.actions)<2:
                    pass
                else:
                    moded_fields = set(r.actions[0].keys())
                    for a in r.actions:
                        fields = set(a.keys())
                        if fields - moded_fields:
                            raise TypeError('Non-compilable rule',str(r))  
            for r in classifier.rules:
                check_OF_rule_has_outport(r)
                check_OF_rule_has_compilable_action_list(r)
            return Classifier(classifier.rules)

        def OF_inportize(classifier):
            """
            Specialize classifier to ensure that packets to be forwarded 
            out the inport on which they arrived are handled correctly.
            
            :param classifier: the input classifer
            :type classifier: Classifier
            :returns: the output classifier
            :rtype: Classifier
            """
            import copy
            def specialize_actions(actions,outport):
                new_actions = copy.deepcopy(actions)
                for action in new_actions:
                    try:
                        if action['outport'] == outport:
                            action['outport'] = OFPP_IN_PORT
                    except:
                        raise TypeError  # INVARIANT: every set of actions must go out a port
                                         # this may not hold when we move to OF 1.3
                return new_actions

            specialized_rules = []
            for rule in classifier.rules:
                phys_actions = filter(lambda a: (a['outport'] != OFPP_CONTROLLER 
                                                 and a['outport'] != OFPP_IN_PORT),
                                      rule.actions)
                outports_used = map(lambda a: a['outport'], phys_actions)
                if not 'inport' in rule.match:
                    # Add a modified rule for each of the outports_used
                    switch = rule.match['switch']
                    for outport in outports_used:
                        new_match = copy.deepcopy(rule.match)
                        new_match['inport'] = outport
                        new_actions = specialize_actions(rule.actions,outport)
                        specialized_rules.append(Rule(new_match,new_actions))
                    # And a default rule for any inport outside the set of outports_used
                    specialized_rules.append(rule)
                else:
                    if rule.match['inport'] in outports_used:
                        # Modify the set of actions
                        new_actions = specialize_actions(rule.actions,rule.match['inport'])
                        specialized_rules.append(Rule(rule.match,new_actions))
                    else:
                        # Leave as before
                        specialized_rules.append(rule)

            return Classifier(specialized_rules)

        def prioritize(classifier):
            """
            Add priorities to classifier rules based on their ordering.
            
            :param classifier: the input classifer
            :type classifier: Classifier
            :returns: the output classifier
            :rtype: Classifier
            """
            priority = {}
            tuple_rules = list()
            for rule in classifier.rules:
                s = rule.match['switch']
                try:
                    priority[s] -= 1
                except KeyError:
                    priority[s] = 60000
                tuple_rules.append((rule.match,priority[s],rule.actions))
            return tuple_rules

        ### UPDATE LOGIC

        def nuclear_install(classifier):
            """
            Delete all rules currently installed on switches and then
            install input classifier from scratch.
            
            :param classifier: the input classifer
            :type classifier: Classifier
            """
            switch_attrs_tuples = self.network.topology.nodes(data=True)
            switch_to_attrs = { k : v for (k,v) in switch_attrs_tuples }
            switches = switch_to_attrs.keys()
            classifier = switchify(classifier,switches)
            classifier = concretize(classifier)
            classifier = check_OF_rules(classifier)
            classifier = OF_inportize(classifier)
            new_rules = prioritize(classifier)

            for s in switches:
                self.send_barrier(s)
                self.send_clear(s)
                self.send_barrier(s)
                self.install_rule(({'switch' : s},TABLE_MISS_PRIORITY,[{'outport' : OFPP_CONTROLLER}]))

            for rule in new_rules:
                self.install_rule(rule)
                
            for s in switches:
                self.send_barrier(s)
                if self.verbosity >= self.verbosity_numeric('please-make-it-stop'):
                    self.request_flow_stats(s)

        ### INCREMENTAL UPDATE LOGIC

        def find_same_rule(target, rule_list):
            if rule_list is None:
                return None
            for rule in rule_list:
                if target[0] == rule[0] and target[1] == rule[1]:
                    return rule
            return None

        def install_diff_rules(classifier):
            """
            Calculate and install the difference between the input classifier
            and the current switch tables.
            
            :param classifier: the input classifer
            :type classifier: Classifier
            """
            with self.old_rules_lock:
                old_rules = self.old_rules
                switch_attrs_tuples = self.network.topology.nodes(data=True)
                switch_to_attrs = { k : v for (k,v) in switch_attrs_tuples }
                switches = switch_to_attrs.keys()
                classifier = switchify(classifier,switches)
                classifier = concretize(classifier)
                classifier = OF_inportize(classifier)
                new_rules = prioritize(classifier)

                # calculate diff
                to_add = list()
                to_delete = list()
                to_modify = list()
                for old in old_rules:
                    new = find_same_rule(old, new_rules)
                    if new is None:
                        to_delete.append(old)
                    else:
                        if old[2] != new[2]:
                            to_modify.append(new)
    
                for new in new_rules:
                    old = find_same_rule(new, old_rules)
                    if old is None:
                        to_add.append(new)
    
                # install diff
                if not to_add is None:
                    for rule in to_add:
                        self.install_rule(rule)
                for rule in to_delete:
                    if rule[0]['switch'] in switches:
                        self.delete_rule((rule[0], rule[1]))
                for rule in to_modify:
                    self.delete_rule((rule[0], rule[1]))
                    self.install_rule(rule)
    
                # update old_rule
                del old_rules[0:len(old_rules)]
                for rule in new_rules:
                    old_rules.append(rule)

                for s in switches:
                    self.send_barrier(s)

        ### PROCESS THAT DOES INSTALL

        def f(classifier):
            with self.switch_lock:
                if self.mode == 'proactive0':
                    nuclear_install(classifier)
                elif self.mode == 'proactive1':
                    install_diff_rules(classifier)

        # Process classifier to an openflow-compatible format before
        # sending out rule installs
        #classifier = send_drops_to_controller(classifier)
        classifier = remove_identity(classifier)
        classifier = controllerify(classifier)
        classifier = layer_3_specialize(classifier)
        classifier = vlan_specialize(classifier)
        bookkeep_buckets(classifier)
        classifier = remove_buckets(classifier)

        p = Process(target=f,args=(classifier,))
        p.daemon = True
        p.start()


###################
# QUERYING SUPPORT
###################

    def pull_stats_for_bucket(self,bucket):
        """
        Returns a function that can be used by counting buckets to
        issue queries from the runtime."""
        def pull_bucket_stats():
            switch_list = []
            for m in bucket.matches:
                if m == identity:
                    concrete_pred = {}
                else:
                    assert(isinstance(m, match))
                    concrete_pred = { k:v for (k,v) in m.map.items() }
                if 'switch' in concrete_pred:
                    switch_list.append(concrete_pred['switch'])
                else:
                    switch_list = self.network.topology.nodes()
                    break
            for s in switch_list:
                bucket.add_outstanding_switch_query(s)
                already_queried = self.add_global_outstanding_query(s, bucket)
                if not already_queried:
                    self.request_flow_stats(s)
        return pull_bucket_stats

    def add_global_outstanding_query(self, s, bucket):
        already_queried = False
        with self.global_outstanding_queries_lock:
            if not s in self.global_outstanding_queries:
                self.global_outstanding_queries[s] = [bucket]
            else:
                self.global_outstanding_queries[s].append(bucket)
                already_queried = True
        return already_queried


####################################
# PACKET MARSHALLING/UNMARSHALLING 
####################################

    def concrete2pyretic(self,raw_pkt):
        packet = get_packet_processor().unpack(raw_pkt['raw'])
        packet['raw'] = raw_pkt['raw']
        packet['switch'] = raw_pkt['switch']
        packet['inport'] = raw_pkt['inport']

        def convert(h,val):
            if h in ['srcmac','dstmac']:
                return MAC(val)
            elif h in ['srcip','dstip']:
                return IP(val)
            else:
                return val
        try:
            vlan_id = packet['vlan_id']
            vlan_pcp = packet['vlan_pcp']
            extended_values = self.decode_extended_values(vlan_id, vlan_pcp)
        except KeyError:
            extended_values = util.frozendict()       
        pyretic_packet = Packet(extended_values)
        d = { h : convert(h,v) for (h,v) in packet.items() if not h in ['vlan_id','vlan_pcp'] }
        return pyretic_packet.modifymany(d)
    def pyretic2concrete(self,packet):
        concrete_packet = {}
        headers         = {}

        for header in ['switch','inport','outport']:
            try:
                concrete_packet[header] = packet[header]
                headers[header]         = packet[header]
                packet = packet.pop(header)
            except:
                pass
        for header in native_headers + content_headers:
            try:
                val = packet[header]
                concrete_packet[header] = val
            except:
                pass
        for header in packet.header:
            try:
                if header in ['switch', 'inport', 'outport']: next
                val = packet[header]
                headers[header] = val
            except:
                pass
        extended_values = extended_values_from(packet)
        if extended_values:
            vlan_id, vlan_pcp = self.encode_extended_values(extended_values)
            concrete_packet['vlan_id'] = vlan_id
            concrete_packet['vlan_pcp'] = vlan_pcp
        concrete_packet['raw'] = get_packet_processor().pack(headers)
        return concrete_packet

#######################
# TO OPENFLOW         
#######################

    def send_packet(self,concrete_packet):
        self.backend.send_packet(concrete_packet)

    def install_rule(self,(concrete_pred,priority,action_list)):
        self.log.debug(
            '|%s|\n\t%s\n\t%s\n' % (str(datetime.now()),
                "sending openflow rule:",
                (str(priority) + " " + repr(concrete_pred) + " "+ repr(action_list))))
        self.backend.send_install(concrete_pred,priority,action_list)

    def delete_rule(self,(concrete_pred,priority)):
        self.backend.send_delete(concrete_pred,priority)

    def send_barrier(self,switch):
        self.backend.send_barrier(switch)

    def send_clear(self,switch):
        self.backend.send_clear(switch)

    def clear_all(self):
        def f():
            switches = self.network.topology.nodes()
            for s in switches:
                self.send_barrier(s)
                self.send_clear(s)
                self.send_barrier(s)
                self.install_rule(({'switch' : s},TABLE_MISS_PRIORITY,[{'outport' : OFPP_CONTROLLER}]))
        p = Process(target=f)
        p.daemon = True
        p.start()

    def request_flow_stats(self,switch):
        self.backend.send_flow_stats_request(switch)

    def inject_discovery_packet(self,dpid, port):
        self.backend.inject_discovery_packet(dpid,port)


#######################
# FROM OPENFLOW       
#######################

    def handle_switch_join(self,switch_id):
        self.network.handle_switch_join(switch_id)

    def handle_switch_part(self,switch_id):
        self.network.handle_switch_part(switch_id)

    def handle_port_join(self,switch_id,port_id,conf_up,stat_up):
        self.network.handle_port_join(switch_id,port_id,conf_up,stat_up)

    def handle_port_mod(self, switch, port_no, config, status):
        self.network.handle_port_mod(switch, port_no, config, status)

    def handle_port_part(self, switch, port_no):
        self.network.handle_port_part(switch, port_no)

    def handle_link_update(self, s1, p_no1, s2, p_no2):
        self.network.handle_link_update(s1, p_no1, s2, p_no2)

    def handle_flow_stats_reply(self, switch, flow_stats):
        def convert(f,val):
            if f == 'match':
                import ast
                val = ast.literal_eval(val)
                return { g : convert(g,v) for g,v in val.items() }
            if f == 'actions':
                import ast
                vals = ast.literal_eval(val)
                return [ { g : convert(g,v) for g,v in val.items() }
                         for val in vals ]
            if f in ['srcmac','dstmac']:
                return MAC(val)
            elif f in ['srcip','dstip']:
                return IP(val)
            else:
                return val
        flow_stats = [ { f : convert(f,v) 
                         for (f,v) in flow_stat.items() }
                       for flow_stat in flow_stats       ]
        flow_stats = sorted(flow_stats, key=lambda d: -d['priority'])
        def flow_stat_str(flow_stat):
            output = str(flow_stat['priority']) + ':\t' 
            output += str(flow_stat['match']) + '\n\t->'
            output += str(flow_stat['actions']) + '\n\t'
            output += 'packet_count=' + str(flow_stat['packet_count']) 
            output += '\tbyte_count=' + str(flow_stat['byte_count'])
            return output
        self.log.debug(
            '|%s|\n\t%s\n' % (str(datetime.now()),
                '\n'.join(['flow table for switch='+repr(switch)] + 
                    [flow_stat_str(f) for f in flow_stats])))
        with self.global_outstanding_queries_lock:
            if switch in self.global_outstanding_queries:
                for bucket in self.global_outstanding_queries[switch]:
                    bucket.handle_flow_stats_reply(switch, flow_stats)
                del self.global_outstanding_queries[switch]
            

##########################
# VIRTUAL HEADER SUPPORT 
##########################

    def encode_extended_values(self, extended_values):
        with self.extended_values_lock:
            vlan = self.extended_values_to_vlan_db.get(extended_values)
            if vlan is not None:
                return vlan
            r = 1+len(self.extended_values_to_vlan_db) #VLAN ZERO IS RESERVED
            pcp = r & 0b111000000000000
            vid = r & 0b000111111111111
            self.extended_values_to_vlan_db[extended_values] = (vid, pcp)
            self.vlan_to_extended_values_db[(vid, pcp)] = extended_values
            return (vid, pcp)
        
    def decode_extended_values(self, vid, pcp):
        with self.extended_values_lock:
            extended_values = self.vlan_to_extended_values_db.get((vid, pcp))
            assert extended_values is not None, "use of vlan that pyretic didn't allocate! not allowed."
            return extended_values

@util.cached
def extended_values_from(packet):
    extended_values = {}
    for k, v in packet.header.items():
        if k not in basic_headers + content_headers + location_headers and v:
            extended_values[k] = v
    return util.frozendict(extended_values)


################################################################################
# Concrete Network
################################################################################

import threading 

class ConcreteNetwork(Network):
    def __init__(self,runtime=None):
        super(ConcreteNetwork,self).__init__()
        self.next_topo = self.topology.copy()
        self.runtime = runtime
        self.wait_period = 0.25
        self.update_no_lock = threading.Lock()
        self.update_no = 0
        self.log = logging.getLogger('%s.ConcreteNetwork' % __name__)
        self.debug_log = logging.getLogger('%s.DEBUG_TOPO_DISCOVERY' % __name__)
        self.debug_log.setLevel(logging.DEBUG)

    def inject_packet(self, pkt):
        concrete_pkt = self.runtime.pyretic2concrete(pkt)
        self.runtime.send_packet(concrete_pkt)

    #
    # Topology Detection
    #

    def queue_update(self,this_update_no):
        def f(this_update_no):
            time.sleep(self.wait_period)
            with self.update_no_lock:
                if this_update_no != self.update_no:
                    return

            self.topology = self.next_topo.copy()
            self.runtime.handle_network_change()

        p = threading.Thread(target=f,args=(this_update_no,))
        p.start()

    def get_update_no(self):
        with self.update_no_lock:
            self.update_no += 1
            return self.update_no
           
    def inject_discovery_packet(self, dpid, port_no):
        self.runtime.inject_discovery_packet(dpid, port_no)
        
    def handle_switch_join(self, switch):
        self.debug_log.debug("handle_switch_joins")
        ## PROBABLY SHOULD CHECK TO SEE IF SWITCH ALREADY IN NEXT_TOPO
        self.next_topo.add_switch(switch)
        self.log.info("OpenFlow switch %s connected" % switch)
        self.debug_log.debug(str(self.next_topo))
        
    def remove_associated_link(self,location):
        port = self.next_topo.node[location.switch]["ports"][location.port_no]
        if not port.linked_to is None:
            # REMOVE CORRESPONDING EDGE
            try:      
                self.next_topo.remove_edge(location.switch, port.linked_to.switch)
            except:
                pass  # ALREADY REMOVED
            # UNLINK LINKED_TO PORT
            try:      
                self.next_topo.node[port.linked_to.switch]["ports"][port.linked_to.port_no].linked_to = None
            except KeyError:
                pass  # LINKED TO PORT ALREADY DELETED
            # UNLINK SELF
            self.next_topo.node[location.switch]["ports"][location.port_no].linked_to = None
        
    def handle_switch_part(self, switch):
        self.log.info("OpenFlow switch %s disconnected" % switch)
        self.debug_log.debug("handle_switch_parts")
        # REMOVE ALL ASSOCIATED LINKS
        for port_no in self.next_topo.node[switch]["ports"].keys():
            self.remove_associated_link(Location(switch,port_no))
        self.next_topo.remove_node(switch)
        self.debug_log.debug(str(self.next_topo))
        self.queue_update(self.get_update_no())
        
    def handle_port_join(self, switch, port_no, config, status):
        self.debug_log.debug("handle_port_joins %s:%s:%s:%s" % (switch, port_no, config, status))
        this_update_no = self.get_update_no()
        self.next_topo.add_port(switch,port_no,config,status)
        if config or status:
            self.inject_discovery_packet(switch,port_no)
            self.debug_log.debug(str(self.next_topo))
            self.queue_update(this_update_no)
            
    def handle_port_part(self, switch, port_no):
        self.debug_log.debug("handle_port_parts")
        try:
            self.remove_associated_link(Location(switch,port_no))
            del self.next_topo.node[switch]["ports"][port_no]
            self.debug_log.debug(str(self.next_topo))
            self.queue_update(self.get_update_no())
        except KeyError:
            pass  # THE SWITCH HAS ALREADY BEEN REMOVED BY handle_switch_parts
        
    def handle_port_mod(self, switch, port_no, config, status):
        self.debug_log.debug("handle_port_mods %s:%s:%s:%s" % (switch, port_no, config, status))
        # GET PREV VALUES
        try:
            prev_config = self.next_topo.node[switch]["ports"][port_no].config
            prev_status = self.next_topo.node[switch]["ports"][port_no].status
        except KeyError:
            self.log.warning("KeyError CASE!!!!!!!!")
            self.port_down(switch, port_no)
            return

        # UPDATE VALUES
        self.next_topo.node[switch]["ports"][port_no].config = config
        self.next_topo.node[switch]["ports"][port_no].status = status

        # DETERMINE IF/WHAT CHANGED
        if (prev_config and not config):
            self.port_down(switch, port_no)
        if (prev_status and not status):
            self.port_down(switch, port_no,double_check=True)

        if (not prev_config and config) or (not prev_status and status):
            self.port_up(switch, port_no)

    def port_up(self, switch, port_no):
        this_update_no = self.get_update_no()
        self.debug_log.debug("port_up %s:%s" % (switch,port_no))
        self.inject_discovery_packet(switch,port_no)
        self.debug_log.debug(str(self.next_topo))
        self.queue_update(this_update_no)

    def port_down(self, switch, port_no, double_check=False):
        self.debug_log.debug("port_down %s:%s:double_check=%s" % (switch,port_no,double_check))
        try:
            self.remove_associated_link(Location(switch,port_no))
            self.debug_log.debug(str(self.next_topo))
            self.queue_update(self.get_update_no())
            if double_check: self.inject_discovery_packet(switch,port_no)
        except KeyError:  
            pass  # THE SWITCH HAS ALREADY BEEN REMOVED BY handle_switch_parts

    def handle_link_update(self, s1, p_no1, s2, p_no2):
        self.debug_log.debug("handle_link_updates")
        try:
            p1 = self.next_topo.node[s1]["ports"][p_no1]
            p2 = self.next_topo.node[s2]["ports"][p_no2]
        except KeyError:
            self.log.warning("node doesn't yet exist")
            return  # at least one of these ports isn't (yet) in the next_topo

        # LINK ALREADY EXISTS
        try:
            link = self.next_topo[s1][s2]

            # LINK ON SAME PORT PAIR
            if link[s1] == p_no1 and link[s2] == p_no2:         
                if p1.possibly_up() and p2.possibly_up():   
                    self.debug_log.debug("nothing to do")
                    return                                      #   NOTHING TO DO
                else:                                           # ELSE RAISE AN ERROR - SOMETHING WEIRD IS HAPPENING
                    raise RuntimeError('Link update w/ bad port status %s,%s' % (p1,p2))
            # LINK PORTS CHANGED
            else:                                               
                # REMOVE OLD LINKS
                if link[s1] != p_no1:
                    self.remove_associated_link(Location(s1,link[s1]))
                if link[s2] != p_no2:
                    self.remove_associated_link(Location(s2,link[s2]))

        # COMPLETELY NEW LINK
        except KeyError:     
            pass
        
        # ADD LINK IF PORTS ARE UP
        if p1.possibly_up() and p2.possibly_up():
            self.next_topo.node[s1]["ports"][p_no1].linked_to = Location(s2,p_no2)
            self.next_topo.node[s2]["ports"][p_no2].linked_to = Location(s1,p_no1)   
            self.next_topo.add_edge(s1, s2, {s1: p_no1, s2: p_no2})
            
        # IF REACHED, WE'VE REMOVED AN EDGE, OR ADDED ONE, OR BOTH
        self.debug_log.debug(self.next_topo)
        self.queue_update(self.get_update_no())

########NEW FILE########
__FILENAME__ = util
################################################################################
# The Pyretic Project                                                          #
# frenetic-lang.org/pyretic                                                    #
# author: Joshua Reich (jreich@cs.princeton.edu)                               #
# author: Christopher Monsanto (chris@monsan.to)                               #
# author: Cole Schlesinger (cschlesi@cs.princeton.edu)                         #
################################################################################
# Licensed to the Pyretic Project by one or more contributors. See the         #
# NOTICES file distributed with this work for additional information           #
# regarding copyright and ownership. The Pyretic Project licenses this         #
# file to you under the following license.                                     #
#                                                                              #
# Redistribution and use in source and binary forms, with or without           #
# modification, are permitted provided the following conditions are met:       #
# - Redistributions of source code must retain the above copyright             #
#   notice, this list of conditions and the following disclaimer.              #
# - Redistributions in binary form must reproduce the above copyright          #
#   notice, this list of conditions and the following disclaimer in            #
#   the documentation or other materials provided with the distribution.       #
# - The names of the copyright holds and contributors may not be used to       #
#   endorse or promote products derived from this work without specific        #
#   prior written permission.                                                  #
#                                                                              #
# Unless required by applicable law or agreed to in writing, software          #
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT    #
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the     #
# LICENSE file distributed with this work for specific language governing      #
# permissions and limitations under the License.                               #
################################################################################
# /src/frenetic_util.py                                                        #
# Utility functions                                                            #
################################################################################

from functools import wraps

from multiprocessing import Lock
from logging import StreamHandler
import sys


def singleton(f):
    return f()

def cached(f):
    @wraps(f)
    def wrapper(*args):
        try:
            return wrapper.cache[args]
        except KeyError:
            wrapper.cache[args] = v = f(*args)
            return v
    wrapper.cache = {}
    return wrapper

class frozendict(object):
    __slots__ = ["_dict", "_cached_hash"]

    def __init__(self, new_dict=None, **kwargs):
        self._dict = dict()
        if new_dict is not None:
            self._dict.update(new_dict)
        self._dict.update(kwargs)

    def update(self, new_dict=None, **kwargs):
        d = self._dict.copy()
        
        if new_dict is not None:
            d.update(new_dict)    
        d.update(kwargs)
        
        return self.__class__(d)

    def remove(self, ks):
        d = self._dict.copy()
        for k in ks:
            if k in d:
                del d[k]
        return self.__class__(d)
        
    def pop(self, *ks):
        result = []
        for k in ks:
            result.append(self[k])
        result.append(self.remove(*ks))
        return result
      
    def __repr__(self):
        return repr(self._dict)

    def __iter__(self):
        return iter(self._dict)

    def __contains__(self, key):
        return key in self._dict

    def keys(self):
        return self._dict.keys()

    def values(self):
        return self._dict.values()
        
    def items(self):
        return self._dict.items()

    def iterkeys(self):
        return self._dict.iterkeys()

    def itervalues(self):
        return self._dict.itervalues()
        
    def iteritems(self):
        return self._dict.iteritems()

    def get(self, key, default=None):
        return self._dict.get(key, default)

    def __getitem__(self, item):
        return self._dict[item]

    def __hash__(self):
        try:
            return self._cached_hash
        except AttributeError:
            h = self._cached_hash = hash(frozenset(self._dict.items()))
            return h
        
    def __eq__(self, other):
        return self._dict == other._dict

    def __ne__(self, other):
        return self._dict != other._dict
        
    def __len__(self):
        return len(self._dict)


def indent_str(s, indent=4):
    return "\n".join(indent * " " + i for i in s.splitlines())


def repr_plus(ss, indent=4, sep="\n", prefix=""):
    if isinstance(ss, basestring):
        ss = [ss]
    return indent_str(sep.join(prefix + repr(s) for s in ss), indent)    

class LockStreamHandler(StreamHandler):
    '''Relies on a multiprocessing.Lock to serialize multiprocess writes to a
    stream.'''
    
    def __init__(self, lock, stream=sys.stderr):
        self.lock = lock
        super(MultiprocessStreamHandler, self).__init__(stream)

    def emit(self, record):
        '''Acquire the lock before emitting the record.'''
        self.lock.acquire()
        super(LockStreamHandler, self).emit(record)
        self.lock.release()

class QueueStreamHandler(StreamHandler):
    '''Relies on a multiprocessing.Lock to serialize multiprocess writes to a
    stream.'''
    
    def __init__(self, queue, stream=sys.stderr):
        self.queue = queue
        super(QueueStreamHandler, self).__init__(stream)

    def emit(self, record):
        '''Acquire the lock before emitting the record.'''
        self.queue.put(record)

########NEW FILE########
__FILENAME__ = aggregate_queries

################################################################################
# The Pyretic Project                                                          #
# frenetic-lang.org/pyretic                                                    #
# author: Joshua Reich (jreich@cs.princeton.edu)                               #
################################################################################
# Licensed to the Pyretic Project by one or more contributors. See the         #
# NOTICES file distributed with this work for additional information           #
# regarding copyright and ownership. The Pyretic Project licenses this         #
# file to you under the following license.                                     #
#                                                                              #
# Redistribution and use in source and binary forms, with or without           #
# modification, are permitted provided the following conditions are met:       #
# - Redistributions of source code must retain the above copyright             #
#   notice, this list of conditions and the following disclaimer.              #
# - Redistributions in binary form must reproduce the above copyright          #
#   notice, this list of conditions and the following disclaimer in            #
#   the documentation or other materials provided with the distribution.       #
# - The names of the copyright holds and contributors may not be used to       #
#   endorse or promote products derived from this work without specific        #
#   prior written permission.                                                  #
#                                                                              #
# Unless required by applicable law or agreed to in writing, software          #
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT    #
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the     #
# LICENSE file distributed with this work for specific language governing      #
# permissions and limitations under the License.                               #
################################################################################

################################################################################
# SETUP                                                                        #
# -------------------------------------------------------------------          #
# mininet: mininet.sh --topo=clique,5,5 (or other single subnet network)       #
# test:    updated network traffic statistics should be printed every second   #
################################################################################

from pyretic.lib.corelib import *
from pyretic.lib.std import *
from pyretic.lib.query import *
from pyretic.modules.mac_learner import mac_learner

def packet_count_printer(counts):
    print "----counts------"
    print counts

def packet_counts():
  q = count_packets(1,['srcip','dstip'])
  q.register_callback(packet_count_printer)
  return q

def byte_count_printer(n):
    print "----bytes------"
    print n

def byte_counts():
  q = count_bytes(1,['srcip','dstip'])
  q.register_callback(byte_count_printer)
  return q


### Main ###

def main():
    return (packet_counts() + 
            byte_counts() + 
            mac_learner())

########NEW FILE########
__FILENAME__ = bucket

################################################################################
# The Pyretic Project                                                          #
# frenetic-lang.org/pyretic                                                    #
# author: Srinivas Narayana (narayana@cs.princeton.edu)                        #
################################################################################
# Licensed to the Pyretic Project by one or more contributors. See the         #
# NOTICES file distributed with this work for additional information           #
# regarding copyright and ownership. The Pyretic Project licenses this         #
# file to you under the following license.                                     #
#                                                                              #
# Redistribution and use in source and binary forms, with or without           #
# modification, are permitted provided the following conditions are met:       #
# - Redistributions of source code must retain the above copyright             #
#   notice, this list of conditions and the following disclaimer.              #
# - Redistributions in binary form must reproduce the above copyright          #
#   notice, this list of conditions and the following disclaimer in            #
#   the documentation or other materials provided with the distribution.       #
# - The names of the copyright holds and contributors may not be used to       #
#   endorse or promote products derived from this work without specific        #
#   prior written permission.                                                  #
#                                                                              #
# Unless required by applicable law or agreed to in writing, software          #
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT    #
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the     #
# LICENSE file distributed with this work for specific language governing      #
# permissions and limitations under the License.                               #
################################################################################

################################################################################
# SETUP                                                                        #
# -------------------------------------------------------------------          #
# mininet: mininet.sh --topo=single,3                                          #
# pyretic: pyretic.py pyretic.examples.bucket -m p0                            #
# test:    `h_i ping h_j` produce increasing (packet/byte) counts every        #
#          10 seconds in buckets b_i.                                          #
#          In i/r0 modes, reported counts from switches are always 0.          #
################################################################################

from pyretic.lib.corelib import *
from pyretic.lib.std import *

import time
from datetime import datetime

# define some globals for use in various functions
ip1 = IPAddr('10.0.0.1')
ip2 = IPAddr('10.0.0.2')
ip3 = IPAddr('10.0.0.3')

fwding = ( (match(dstip=ip1) >> fwd(1)) +
           (match(dstip=ip2) >> fwd(2)) +
           (match(dstip=ip3) >> fwd(3)) )

class QueryTest(CountBucket):
    
    def __init__(self):
        super(QueryTest, self).__init__()
        self.register_callback(self.query_callback)
        import threading
        self.query_thread = threading.Thread(target=self.query_thread)
        self.query_thread.daemon = True
        self.query_thread.start()

    def query_thread(self):
        """Thread that issues stats queries every 10 seconds."""
        interval = 2.5
        while True:
            output = str(datetime.now()) + "| bucket " + str(id(self)) + ": print matches\n"
            for m in self.matches:
                output += str(m) + '\n'
            self.pull_stats()
            output += 'issued query, going to sleep for %f' % interval
            print output
            time.sleep(interval)

    def query_callback(self, counts):
        print "*** In user callback for bucket", id(self)
        print "(packet, byte) counts:", counts

def test_main1():
    """Tests a single match that is counted."""
    test_bucket = QueryTest()
    return (match(srcip=ip1) >> test_bucket) + fwding

def test_main2():
    """Tests buckets containing multiple matches for traffic."""
    b = [] # counting buckets
    for i in range(0,2):
        b.append(QueryTest())
        time.sleep(0.2)

    pol1 = match(srcip=ip1) >> b[0]
    pol2 = match(srcip=ip2) >> b[1]
    pol3 = match(srcip=ip3) >> b[0]

    return pol1 + pol2 + pol3 + fwding

def test_main3():
    """Test if the same traffic feeding into multiple buckets gets accounted
    correctly.
    """
    b = [] # counting buckets
    for i in range(0,3):
        b.append(QueryTest())
        time.sleep(0.2)

    query1 = match(srcip=ip1) >> match(dstip=ip2) >> b[0]
    query2 = match(srcip=ip1) >> match(dstip=ip2) >> b[1]
    query3 = match(srcip=ip1) >> match(dstip=ip3) >> b[2]

    return fwding + query1 + query2 + query3

def test_main4():
    """Test policy negation, but only for IP traffic."""
    test_bucket = QueryTest()
    matched_traffic = ( (~match(srcip=ip1) & match(dstip=ip2)) +
                        (~match(srcip=ip1) & match(dstip=ip3)) +
                        (~match(srcip=ip1) & match(dstip=ip1)) )
    return (matched_traffic >> test_bucket) + fwding

def test_main5():
    """Test policy negation covering all other traffic."""
    test_bucket = QueryTest()
    matched_traffic = ~match(srcip=ip1)
    return (matched_traffic >> test_bucket) + fwding

def main():
    return test_main1()

########NEW FILE########
__FILENAME__ = dpi

################################################################################
# The Pyretic Project                                                          #
# frenetic-lang.org/pyretic                                                    #
# author: Joshua Reich (jreich@cs.princeton.edu)                               #
################################################################################
# Licensed to the Pyretic Project by one or more contributors. See the         #
# NOTICES file distributed with this work for additional information           #
# regarding copyright and ownership. The Pyretic Project licenses this         #
# file to you under the following license.                                     #
#                                                                              #
# Redistribution and use in source and binary forms, with or without           #
# modification, are permitted provided the following conditions are met:       #
# - Redistributions of source code must retain the above copyright             #
#   notice, this list of conditions and the following disclaimer.              #
# - Redistributions in binary form must reproduce the above copyright          #
#   notice, this list of conditions and the following disclaimer in            #
#   the documentation or other materials provided with the distribution.       #
# - The names of the copyright holds and contributors may not be used to       #
#   endorse or promote products derived from this work without specific        #
#   prior written permission.                                                  #
#                                                                              #
# Unless required by applicable law or agreed to in writing, software          #
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT    #
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the     #
# LICENSE file distributed with this work for specific language governing      #
# permissions and limitations under the License.                               #
################################################################################

################################################################################
# SETUP                                                                        #
# -------------------------------------------------------------------          #
# mininet: mininet.sh (or other single subnet network)                         #
# test:    packet contents will be printed for each packet sent                #
#          to generate a packets with a payload try                            #
#          h1 hping3 -c 10 -d 100 -E ~/pyretic/mininet/test_payload.txt -S h2  #
################################################################################

from pyretic.lib.corelib import *
from pyretic.lib.std import *
from pyretic.lib.query import *

def printer(pkt):
    print "------packet--------"
    print pkt
    if pkt['ethtype'] == IP_TYPE:
        print "Ethernet packet, try to decode"
        raw_bytes = [ord(c) for c in pkt['raw']]
        print "ethernet payload is %d" % pkt['payload_len']    
        eth_payload_bytes = raw_bytes[pkt['header_len']:]   
        print "ethernet payload is %d bytes" % len(eth_payload_bytes)
        ip_version = (eth_payload_bytes[0] & 0b11110000) >> 4
        ihl = (eth_payload_bytes[0] & 0b00001111)
        ip_header_len = ihl * 4
        ip_payload_bytes = eth_payload_bytes[ip_header_len:]
        ip_proto = eth_payload_bytes[9]
        print "ip_version = %d" % ip_version
        print "ip_header_len = %d" % ip_header_len
        print "ip_proto = %d" % ip_proto
        print "ip payload is %d bytes" % len(ip_payload_bytes)
        if ip_proto == 0x06:
            print "TCP packet, try to decode"
            tcp_data_offset = (ip_payload_bytes[12] & 0b11110000) >> 4
            tcp_header_len = tcp_data_offset * 4
            print "tcp_header_len = %d" % tcp_header_len
            tcp_payload_bytes = ip_payload_bytes[tcp_header_len:]
            print "tcp payload is %d bytes" % len(tcp_payload_bytes)
            if len(tcp_payload_bytes) > 0:
                print "payload:\t",
                print ''.join([chr(d) for d in tcp_payload_bytes])
        elif ip_proto == 0x11:
            print "UDP packet, try to decode"
            udp_header_len = 8
            print "udp_header_len = %d" % udp_header_len
            udp_payload_bytes = ip_payload_bytes[udp_header_len:]
            print "udp payload is %d bytes" % len(udp_payload_bytes)
            if len(udp_payload_bytes) > 0:
                print "payload:\t",
                print ''.join([chr(d) for d in udp_payload_bytes])
        elif ip_proto == 0x01:
            print "ICMP packet"
        else:
            print "Unhandled packet type"

def dpi():
  q = packets()
  q.register_callback(printer)
  return q

### Main ###

def main():
    return (match(srcmac=EthAddr('00:00:00:00:00:01')) >> dpi()) + flood()


########NEW FILE########
__FILENAME__ = port_knocking
################################################################################
# The Pyretic Project                                                          #
# frenetic-lang.org/pyretic                                                    #
# author: Michael Greenberg (mg19@cs.princeton.edu)                            #
################################################################################
# Licensed to the Pyretic Project by one or more contributors. See the         #
# NOTICES file distributed with this work for additional information           #
# regarding copyright and ownership. The Pyretic Project licenses this         #
# file to you under the following license.                                     #
#                                                                              #
# Redistribution and use in source and binary forms, with or without           #
# modification, are permitted provided the following conditions are met:       #
# - Redistributions of source code must retain the above copyright             #
#   notice, this list of conditions and the following disclaimer.              #
# - Redistributions in binary form must reproduce the above copyright          #
#   notice, this list of conditions and the following disclaimer in            #
#   the documentation or other materials provided with the distribution.       #
# - The names of the copyright holds and contributors may not be used to       #
#   endorse or promote products derived from this work without specific        #
#   prior written permission.                                                  #
#                                                                              #
# Unless required by applicable law or agreed to in writing, software          #
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT    #
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the     #
# LICENSE file distributed with this work for specific language governing      #
# permissions and limitations under the License.                               #
################################################################################

################################################################################
# SETUP                                                                        #
# -------------------------------------------------------------------          #
# mininet:  mininet.sh                                                         #
# test: pingall # everything should work                                       #
#       h2 python -m SimpleHTTPServer 80 &                                     #
#       h2 wget -O - h2 # should work                                          #
#       h1 wget -O - -t 1 --timeout=2 h2 # should timeout                      #
#       h1 echo open sesame | nc -w 1 -u h2 1234                               #
#       h1 wget -O - h2 # should work                                          #
################################################################################

from pyretic.lib.corelib import *
from pyretic.lib.std import *
from pyretic.lib.query import *

class port_knocking(DynamicPolicy):
    def __init__(self,knock_port,open_port):
        super(port_knocking,self).__init__()
        self.knock_port = knock_port
        self.open_port = open_port
        self.set_initial_state()

    def set_initial_state(self):
        # the basic switching behavior
        self.switch = (match(inport=1)>>fwd(2)) + (match(inport=2)>>fwd(1))

        # always forward ARP and ICMP
        forwardARP = match(ethtype=0x0806) >> self.switch
        forwardICMP = match(ethtype=0x0800,protocol=1) >> self.switch
        self.forward = forwardARP + forwardICMP

        # but capture packets on the knocking port
        knock_knock = packets(1,['srcmac'])
        knock_knock.register_callback(self.whos_there)
        self.query = match(dstport=self.knock_port) >> knock_knock

        # combine the forwarding and the knock query
        self.update_policy()

    def update_policy(self):
        self.policy = self.forward + self.query

    def set_network(self,network):
        self.set_initial_state()

    def whos_there(self,pkt):
        mac = pkt['srcmac']
        self.forward = if_(match(srcmac=mac,dstport=self.open_port),
                           self.switch, # open up port for incoming...
                           if_(match(dstmac=mac,srcport=self.open_port),
                               self.switch, # and allow return traffic
                               self.forward))
        self.update_policy()
                              

def main():
    return port_knocking(1234,80)

########NEW FILE########
__FILENAME__ = prefix_route

################################################################################
# The Pyretic Project                                                          #
# frenetic-lang.org/pyretic                                                    #
# author: Joshua Reich (jreich@cs.princeton.edu)                               #
################################################################################
# Licensed to the Pyretic Project by one or more contributors. See the         #
# NOTICES file distributed with this work for additional information           #
# regarding copyright and ownership. The Pyretic Project licenses this         #
# file to you under the following license.                                     #
#                                                                              #
# Redistribution and use in source and binary forms, with or without           #
# modification, are permitted provided the following conditions are met:       #
# - Redistributions of source code must retain the above copyright             #
#   notice, this list of conditions and the following disclaimer.              #
# - Redistributions in binary form must reproduce the above copyright          #
#   notice, this list of conditions and the following disclaimer in            #
#   the documentation or other materials provided with the distribution.       #
# - The names of the copyright holds and contributors may not be used to       #
#   endorse or promote products derived from this work without specific        #
#   prior written permission.                                                  #
#                                                                              #
# Unless required by applicable law or agreed to in writing, software          #
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT    #
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the     #
# LICENSE file distributed with this work for specific language governing      #
# permissions and limitations under the License.                               #
################################################################################


################################################################################
# SETUP                                                                        #
# -------------------------------------------------------------------          #
# mininet:  mininet.sh --topo simple_prefix                                    #
# test:     pingall and check for full connectivity                            #
################################################################################

from pyretic.lib.corelib import *
from pyretic.lib.std import *

ipp1 = IPPrefix('10.0.0.0/31')
ipp2 = IPPrefix('10.0.0.2/31')
ipp3 = IPPrefix('10.0.0.4/31')

l3route = ((match(dstip=ipp1) >> fwd(1)) +
           (match(dstip=ipp2) >> fwd(2)) +
           (match(dstip=ipp3) >> fwd(3)) )

def main():
    return l3route





########NEW FILE########
__FILENAME__ = regexp
################################################################################
# The Pyretic Project                                                          #
# frenetic-lang.org/pyretic                                                    #
# author: Joshua Reich (jreich@cs.princeton.edu)                               #
################################################################################
# Licensed to the Pyretic Project by one or more contributors. See the         #
# NOTICES file distributed with this work for additional information           #
# regarding copyright and ownership. The Pyretic Project licenses this         #
# file to you under the following license.                                     #
#                                                                              #
# Redistribution and use in source and binary forms, with or without           #
# modification, are permitted provided the following conditions are met:       #
# - Redistributions of source code must retain the above copyright             #
#   notice, this list of conditions and the following disclaimer.              #
# - Redistributions in binary form must reproduce the above copyright          #
#   notice, this list of conditions and the following disclaimer in            #
#   the documentation or other materials provided with the distribution.       #
# - The names of the copyright holds and contributors may not be used to       #
#   endorse or promote products derived from this work without specific        #
#   prior written permission.                                                  #
#                                                                              #
# Unless required by applicable law or agreed to in writing, software          #
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT    #
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the     #
# LICENSE file distributed with this work for specific language governing      #
# permissions and limitations under the License.                               #
################################################################################

################################################################################
# SETUP                                                                        #
# -------------------------------------------------------------------          #
# mininet: mininet.sh --topo=single,3,3 (or other single subnet network)       #
# test:    h1 python2 -m SimpleHTTPServer 3000                                 #
#          h2 curl 10.0.0.1:3000                                               #
#                                                                              #
#          It should output:                                                   #
#                                                                              #
################################################################################

from pyretic.lib.corelib import *
from pyretic.lib.std import *
from pyretic.lib.query import *
from pyretic.modules.mac_learner import mac_learner

def print_urls(pkt, match):
    print 'verb: %-5s | path: %-25s | version: %-3s' % match.groups()
        
### Main ###
def main():
    re = RegexpQuery("(?P<verb>GET|POST|DELETE|PUT|HEAD)\s*(?P<path>.*?)\s*HTTP/(?P<http>.*?)\n")
    re.register_callback(print_urls)

    return mac_learner() + re

########NEW FILE########
__FILENAME__ = rewrite

################################################################################
# The Pyretic Project                                                          #
# frenetic-lang.org/pyretic                                                    #
# author: Joshua Reich (jreich@cs.princeton.edu)                               #
################################################################################
# Licensed to the Pyretic Project by one or more contributors. See the         #
# NOTICES file distributed with this work for additional information           #
# regarding copyright and ownership. The Pyretic Project licenses this         #
# file to you under the following license.                                     #
#                                                                              #
# Redistribution and use in source and binary forms, with or without           #
# modification, are permitted provided the following conditions are met:       #
# - Redistributions of source code must retain the above copyright             #
#   notice, this list of conditions and the following disclaimer.              #
# - Redistributions in binary form must reproduce the above copyright          #
#   notice, this list of conditions and the following disclaimer in            #
#   the documentation or other materials provided with the distribution.       #
# - The names of the copyright holds and contributors may not be used to       #
#   endorse or promote products derived from this work without specific        #
#   prior written permission.                                                  #
#                                                                              #
# Unless required by applicable law or agreed to in writing, software          #
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT    #
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the     #
# LICENSE file distributed with this work for specific language governing      #
# permissions and limitations under the License.                               #
################################################################################


################################################################################
# SETUP                                                                        #
# -------------------------------------------------------------------          #
# mininet:  mininet.sh --topo single,3                                         #
# test:     pingall and check for following connectivity pattern               #
#           h1 -> h2 h3                                                        # 
#           h2 -> X h3                                                         #
#           h3 -> X h2                                                         #
#           all hosts should also be able to ping 10.0.0.11                    #
################################################################################

from pyretic.lib.corelib import *
from pyretic.lib.std import *
from pyretic.lib.query import *

mac1 = EthAddr('00:00:00:00:00:01')
mac2 = EthAddr('00:00:00:00:00:02')
mac3 = EthAddr('00:00:00:00:00:03')
macB = EthAddr('FF:FF:FF:FF:FF:FF')
ip1 = IPAddr('10.0.0.1')
ip2 = IPAddr('10.0.0.2')
ip3 = IPAddr('10.0.0.3')
p = IPAddr('10.0.0.11')

modify = (if_(match(srcip=ip1),modify(srcip=p)) >> 
          if_(match(dstip=p),modify(dstip=ip1))    )
              
l2route = (((match(dstmac=mac1) | match(dstmac=macB)) >> fwd(1)) +
           ((match(dstmac=mac2) | match(dstmac=macB)) >> fwd(2)) +
           ((match(dstmac=mac3) | match(dstmac=macB)) >> fwd(3)) )

l3route = ((match(dstip=ip1) >> fwd(1)) +
           (match(dstip=ip2) >> fwd(2)) +
           (match(dstip=ip3) >> fwd(3)) )

policy = modify >> l2route

def main():
    return policy





########NEW FILE########
__FILENAME__ = simple_ui_firewall
################################################################################
# The Pyretic Project                                                          #
# frenetic-lang.org/pyretic                                                    #
# author: Nick Feamster (feamster@cc.gatech.edu)                               #
# author: Joshua Reich  (jreich@cs.princeton.edu)                              #
################################################################################

from pox.lib.addresses import EthAddr

from pyretic.lib.corelib import *
from pyretic.lib.std import *
from pyretic.modules.mac_learner import mac_learner

class firewall(DynamicPolicy):

    def __init__(self):
        # Initialize the firewall
        print "initializing firewall"      
        self.firewall = {}
        super(firewall,self).__init__(true)
        import threading
        self.ui = threading.Thread(target=self.ui_loop)
        self.ui.daemon = True
        self.ui.start()

    def AddRule (self, mac1, mac2):
        if (mac2,mac1) in self.firewall:
            print "Firewall rule for %s: %s already exists" % (mac1,mac2) 
            return
        self.firewall[(mac1,mac2)]=True
        print "Adding firewall rule in %s: %s" % (mac1,mac2) 
        self.update_policy()
    
    def DeleteRule (self, mac1, mac2):
        try:
            del self.firewall[(mac1,mac2)]
            print "Deleting firewall rule in %s: %s" % (mac1,mac2) 
            self.update_policy()
        except:
            pass
        try:
            del self.firewall[(mac2,mac1)]
            print "Deleting firewall rule in %s: %s" % (mac1,mac2) 
            self.update_policy()
        except:
            pass

    def update_policy (self):
        self.policy = ~union([ (match(srcmac=mac1) & 
                                match(dstmac=mac2)) |
                               (match(dstmac=mac1) & 
                                match(srcmac=mac2)) 
                               for (mac1,mac2) 
                               in self.firewall.keys()])
        print self.policy

    def ui_loop (self):
        while(True):
            nb = raw_input('(b)lock, (a)llow, or (q)uit? ')
            if nb == 'b':
                try:
                    nb = raw_input('enter MAC address pair ')
                    (str1,str2) = nb.split(',')
                    (mac1,mac2) = (MAC(str1),MAC(str2))
                    self.AddRule(mac1,mac2)
                except:
                    print "Invalid Format"
            elif nb == 'a':
                try:
                    nb = raw_input('enter MAC address pair ')
                    (str1,str2) = nb.split(',')
                    (mac1,mac2) = (MAC(str1),MAC(str2))
                    self.DeleteRule(mac1,mac2)
                except:
                    print "Invalid Format"
            elif nb == 'q':
                print "Quitting"
                import os, signal
                os.kill(os.getpid(), signal.SIGINT)
                return
            else:
                print "Invalid option"    


def main ():
    return firewall() >> flood()

########NEW FILE########
__FILENAME__ = topology_printer
################################################################################
# The Pyretic Project                                                          #
# frenetic-lang.org/pyretic                                                    #
# author: Joshua Reich  (jreich@cs.princeton.edu)                              #
################################################################################

from multiprocessing import Lock

from pyretic.lib.corelib import *
from pyretic.lib.std import *

class topology_printer(DynamicPolicy):

    def __init__(self):
        self.topology = None
        self.lock = Lock()
        super(topology_printer,self).__init__()

    def set_network(self, network):
        with self.lock:
            if self.topology and (self.topology == network.topology):
                pass
            else:
                print self.topology
                print network.topology
                self.topology = network.topology
                print self.topology


def main ():
    return topology_printer()

########NEW FILE########
__FILENAME__ = corelib
################################################################################
# The Pyretic Project                                                          #
# frenetic-lang.org/pyretic                                                    #
# author: Joshua Reich (jreich@cs.princeton.edu)                               #
# author: Christopher Monsanto (chris@monsan.to)                               #
################################################################################
# Licensed to the Pyretic Project by one or more contributors. See the         #
# NOTICES file distributed with this work for additional information           #
# regarding copyright and ownership. The Pyretic Project licenses this         #
# file to you under the following license.                                     #
#                                                                              #
# Redistribution and use in source and binary forms, with or without           #
# modification, are permitted provided the following conditions are met:       #
# - Redistributions of source code must retain the above copyright             #
#   notice, this list of conditions and the following disclaimer.              #
# - Redistributions in binary form must reproduce the above copyright          #
#   notice, this list of conditions and the following disclaimer in            #
#   the documentation or other materials provided with the distribution.       #
# - The names of the copyright holds and contributors may not be used to       #
#   endorse or promote products derived from this work without specific        #
#   prior written permission.                                                  #
#                                                                              #
# Unless required by applicable law or agreed to in writing, software          #
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT    #
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the     #
# LICENSE file distributed with this work for specific language governing      #
# permissions and limitations under the License.                               #
################################################################################

"""Core Pyretic Library"""

# This module is designed for import *.
import networkx as nx

from pyretic.core.network import *
from pyretic.core.language import *
from pyretic.core.packet import *







########NEW FILE########
__FILENAME__ = query
################################################################################
# The Pyretic Project                                                          #
# frenetic-lang.org/pyretic                                                    #
# author: Joshua Reich (jreich@cs.princeton.edu)                               #
################################################################################
# Licensed to the Pyretic Project by one or more contributors. See the         #
# NOTICES file distributed with this work for additional information           #
# regarding copyright and ownership. The Pyretic Project licenses this         #
# file to you under the following license.                                     #
#                                                                              #
# Redistribution and use in source and binary forms, with or without           #
# modification, are permitted provided the following conditions are met:       #
# - Redistributions of source code must retain the above copyright             #
#   notice, this list of conditions and the following disclaimer.              #
# - Redistributions in binary form must reproduce the above copyright          #
#   notice, this list of conditions and the following disclaimer in            #
#   the documentation or other materials provided with the distribution.       #
# - The names of the copyright holds and contributors may not be used to       #
#   endorse or promote products derived from this work without specific        #
#   prior written permission.                                                  #
#                                                                              #
# Unless required by applicable law or agreed to in writing, software          #
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT    #
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the     #
# LICENSE file distributed with this work for specific language governing      #
# permissions and limitations under the License.                               #
################################################################################

from pyretic.core.language import identity, match, union, DerivedPolicy, DynamicFilter, FwdBucket, Query
import time
import re
from threading import Thread

class LimitFilter(DynamicFilter):
    """A DynamicFilter that matches the first limit packets in a specified grouping.

    :param limit: the number of packets to be matched in each grouping.
    :type limit: int
    :param group_by: the fields by which to group packets.
    :type group_by: list string
    """
    def __init__(self,limit=None,group_by=[]):
        self.limit = limit
        self.group_by = group_by
        self.seen = {}
        self.done = []
        super(LimitFilter,self).__init__(identity)

    def update_policy(self,pkt):
        if self.group_by:    # MATCH ON PROVIDED GROUP_BY
            pred = match([(field,pkt[field]) for field in self.group_by])
        else:              # OTHERWISE, MATCH ON ALL AVAILABLE GROUP_BY
            pred = match([(field,pkt[field]) 
                              for field in pkt.available_group_by()])
        # INCREMENT THE NUMBER OF TIMES MATCHING PKT SEEN
        try:
            self.seen[pred] += 1
        except KeyError:
            self.seen[pred] = 1

        if self.seen[pred] == self.limit:
            val = {h : pkt[h] for h in self.group_by}
            self.done.append(match(val))
            self.policy = ~union(self.done)

    def __repr__(self):
        return "LimitFilter\n%s" % repr(self.policy)


class packets(DerivedPolicy):
    """A FwdBucket preceeded by a LimitFilter.

    :param limit: the number of packets to be matched in each grouping.
    :type limit: int
    :param group_by: the fields by which to group packets.
    :type group_by: list string
    """
    def __init__(self,limit=None,group_by=[]):
        self.fb = FwdBucket()
        self.register_callback = self.fb.register_callback
        if limit is None:
            super(packets,self).__init__(self.fb)
        else:
            self.limit_filter = LimitFilter(limit,group_by)
            self.fb.register_callback(self.limit_filter.update_policy)
            super(packets,self).__init__(self.limit_filter >> self.fb)
        
    def __repr__(self):
        return "packets\n%s" % repr(self.policy)


class AggregateFwdBucket(FwdBucket):
    """An abstract FwdBucket which calls back all registered routines every interval
    seconds (can take positive fractional values) with an aggregate value/dict.
    If group_by is empty, registered routines are called back with a single aggregate
    value.  Otherwise, group_by defines the set of headers used to group counts which
    are then returned as a dictionary."""
    ### init : int -> List String
    def __init__(self, interval, group_by=[]):
        FwdBucket.__init__(self)
        self.interval = interval
        self.group_by = group_by
        if group_by:
            self.aggregate = {}
        else:
            self.aggregate = 0
        
        def report_count(callbacks,aggregate,interval):
            while(True):
                for callback in callbacks:
                    callback(aggregate)
                time.sleep(interval)

        self.query_thread = Thread(target=report_count,args=(self.callbacks,self.aggregate,self.interval))
        self.query_thread.daemon = True
        self.query_thread.start()

    def aggregator(self,aggregate,pkt):
        raise NotImplementedError

    ### update : Packet -> unit
    def update_aggregate(self,pkt):
        if self.group_by:
            from pyretic.core.language import match
            groups = set(self.group_by) & set(pkt.available_fields())
            pred = match([(field,pkt[field]) for field in groups])
            try:
                self.aggregate[pred] = self.aggregator(self.aggregate[pred],pkt)
            except KeyError:
                self.aggregate[pred] = self.aggregator(0,pkt)
        else:
            self.aggregate = self.aggregator(self.aggregate,pkt)

    def eval(self, pkt):
        self.update_aggregate(pkt)
        return set()


class count_packets(AggregateFwdBucket):
    """AggregateFwdBucket that calls back with aggregate count of packets."""
    def aggregator(self,aggregate,pkt):
        return aggregate + 1


class count_bytes(AggregateFwdBucket):
    """AggregateFwdBucket that calls back with aggregate bytesize of packets."""
    def aggregator(self,aggregate,pkt):
        return aggregate + pkt['header_len'] + pkt['payload_len']

class RegexpQuery(Query):
    """
    Class for registering callbacks on matching string in packet data?
    """
    def __init__(self, pattern=""):
        super(RegexpQuery, self).__init__()
        self.re = pattern

    def compile(self):
        """Produce a Classifier for this policy

        :rtype: Classifier
        """
        r = Rule(identity,[Controller])
        return Classifier([r])

    @property
    def re(self):
        return self._re

    @re.setter
    def re(self, pattern):
        if not isinstance(pattern, re._pattern_type):
            pattern = re.compile(pattern, re.S)

        self._re = pattern

    def apply(self):
        with self.bucket_lock:
            for pkt in self.bucket:
                #XXX Should we go with raw data or payload?
                #XXX Logic for iteration here? first match or all of them?
                for m in self.re.finditer(pkt['raw']):
                    for callback in self.callbacks:
                        callback(pkt, m)

            self.bucket.clear()

    def __repr__(self):
        return "RegexpQuery"

    def __eq__(self, other):
        # TODO: if buckets eventually have names, equality should
        # be on names.
        return isinstance(other, RegexpQuery) and (other.re == self.re)





########NEW FILE########
__FILENAME__ = std
################################################################################
# The Pyretic Project                                                          #
# frenetic-lang.org/pyretic                                                    #
# author: Joshua Reich (jreich@cs.princeton.edu)                               #
################################################################################
# Licensed to the Pyretic Project by one or more contributors. See the         #
# NOTICES file distributed with this work for additional information           #
# regarding copyright and ownership. The Pyretic Project licenses this         #
# file to you under the following license.                                     #
#                                                                              #
# Redistribution and use in source and binary forms, with or without           #
# modification, are permitted provided the following conditions are met:       #
# - Redistributions of source code must retain the above copyright             #
#   notice, this list of conditions and the following disclaimer.              #
# - Redistributions in binary form must reproduce the above copyright          #
#   notice, this list of conditions and the following disclaimer in            #
#   the documentation or other materials provided with the distribution.       #
# - The names of the copyright holds and contributors may not be used to       #
#   endorse or promote products derived from this work without specific        #
#   prior written permission.                                                  #
#                                                                              #
# Unless required by applicable law or agreed to in writing, software          #
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT    #
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the     #
# LICENSE file distributed with this work for specific language governing      #
# permissions and limitations under the License.                               #
################################################################################

"""Pyretic Standard Library"""
from pyretic.core.language import Policy, Filter, DerivedPolicy, identity, all_packets, passthrough, no_packets, match, union
import pyretic.core.util as util
from datetime import datetime

### BREAKPOINT policy
class breakpoint(DerivedPolicy):
    def eval(self, pkt):
        if self.policy.eval(pkt):
            try:
                import ipdb as debugger
            except:
                import pdb as debugger
            debugger.set_trace()
        return {pkt}

    def __repr__(self):
        return "***breakpoint on %s***" % util.repr_plus([self.policy])


### CONVENIENCE policies

class _in(DerivedPolicy,Filter):
    def __init__(self,field,group):
        self.group = group
        self.field = field
        super(_in,self).__init__(union([match({field : i}) 
                                for i in group]))
    def __repr__(self):
        return "_in: %s" % self.group


class switch_in(_in):
    def __init__(self,switches):
        super(switch_in,self).__init__('switch',switches)

    def __repr__(self):
        return "switch%s" % super(switch_in,self).__repr__()


class dstip_in(_in):
    def __init__(self,dstips):
        super(dstip_in,self).__init__('dstip',dstips)

    def __repr__(self):
        return "dstip%s" % super(dstip_in,self).__repr__()


### PRINTING policies

class _print(Policy):
    def __init__(self,s=''):
        self.s = s
        super(_print,self).__init__()

    def print_str(self,pkt):
        raise NotImplementedError

    def eval(self,pkt):
        print self.print_str(pkt)
        return {pkt}

    def __repr__(self):
        return "[%s %s]" % (self.name(),self.s)

class str_print(_print):
    def print_str(self, pkt):
        return str(datetime.now()) + " | " + self.s

class pkt_print(_print):
    def print_str(self, pkt):
        output_str = ""
        if self.s != '':
            output_str = "---- " + self.s + " -------\n" 
        output_str += str(datetime.now()) + "\n"
        output_str += str(pkt)
        if self.s != '':
            output_str += "\n-------------------------------"
        return output_str

class topo_print(_print):
    def print_str(self, pkt):
        output_str = ""
        if self.s != '':
            output_str = "---- " + self.s + " -------\n" 
        output_str += str(datetime.now()) + "\n"
        output_str += str(self.network.topology)
        if self.s != '':
            output_str += "\n-------------------------------"
        return output_str

########NEW FILE########
__FILENAME__ = virt

################################################################################
# The Pyretic Project                                                          #
# frenetic-lang.org/pyretic                                                    #
# author: Joshua Reich (jreich@cs.princeton.edu)                               #
# author: Christopher Monsanto (chris@monsan.to)                               #
################################################################################
# Licensed to the Pyretic Project by one or more contributors. See the         #
# NOTICES file distributed with this work for additional information           #
# regarding copyright and ownership. The Pyretic Project licenses this         #
# file to you under the following license.                                     #
#                                                                              #
# Redistribution and use in source and binary forms, with or without           #
# modification, are permitted provided the following conditions are met:       #
# - Redistributions of source code must retain the above copyright             #
#   notice, this list of conditions and the following disclaimer.              #
# - Redistributions in binary form must reproduce the above copyright          #
#   notice, this list of conditions and the following disclaimer in            #
#   the documentation or other materials provided with the distribution.       #
# - The names of the copyright holds and contributors may not be used to       #
#   endorse or promote products derived from this work without specific        #
#   prior written permission.                                                  #
#                                                                              #
# Unless required by applicable law or agreed to in writing, software          #
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT    #
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the     #
# LICENSE file distributed with this work for specific language governing      #
# permissions and limitations under the License.                               #
################################################################################

# This module is designed for import *.
from pyretic.core.network import *
from pyretic.core.language import *
from pyretic.core import util
from pyretic.core.util import singleton
from pyretic.lib.std import pkt_print, str_print

import itertools

################################################################################
# Unique virtual network tags                                                  #
################################################################################

last_vtag = 0
def new_vtag():
    """Returns a new unique tag"""
    global last_vtag 
    last_vtag = last_vtag + 1
    return last_vtag


################################################################################
# Virtualization helper policies                                               #
################################################################################

class lower_packet(DerivedPolicy):
    """Lowers a packet from the derived network to the underlying network"""
    def __init__(self, vtag):
        self.vtag = vtag
        super(lower_packet,self).__init__(push(vtag=self.vtag) >> 
                                          move(voutport="outport",
                                               vswitch="switch",
                                               vinport="inport"))
        
        def __repr__(self):
            return "lower_packet %s" % self.vtag

        
@singleton
class lift_packet(DerivedPolicy):
    """Lifts a packet from the underlying network to the derived network"""
    def __init__(self):
        DerivedPolicy.__init__(self, 
                               pop("vtag") >>
                               move(outport="voutport", 
                                    switch="vswitch", 
                                    inport="vinport"))
        
    def __repr__(self):
        return "lift_packet"

        
@singleton
class pop_vheaders(DerivedPolicy):
    """Removes all headers used by this library"""
    def __init__(self):
        DerivedPolicy.__init__(self,
                               pop("vswitch", 
                                   "vinport", 
                                   "voutport", 
                                   "vtag"))
        
    def __repr__(self):
        return "pop_vheaders"


################################################################################
# VMAP functions
################################################################################

class vmap(object):
    """The mapping between underlying and physical ports.
    Also helper methods to generate various often-used implementation policies."""
    def __init__(self):
        self.d2u = {}
        self.u2d = {}

    def ingress_policy(self):
        non_ingress = ~union(union(match(switch=u.switch,
                                         inport=u.port_no) 
                                   for u in us) for (d, us) 
                             in self.d2u.iteritems())
        ingress = (union(union(match(switch=u.switch,
                                     inport=u.port_no)
                               for u in us) >> 
                         push(vtag='ingress', 
                              vswitch=d.switch, 
                              vinport=d.port_no, 
                              voutport=-1)
                         for (d, us) in self.d2u.iteritems()))
        return ingress + non_ingress

    def egress_policy(self):
        matches_egress = []
        valid_match_egress = []
        for (d, us) in self.d2u.iteritems():
            switch_pred = union(match(switch=u.switch, 
                                      outport=u.port_no) 
                                for u in us)
            matches_egress.append(switch_pred)
            valid_match_egress.append(match(vswitch=d.switch, 
                                            voutport=d.port_no) & switch_pred)
        return if_(union(matches_egress), 
                   union(valid_match_egress) >> pop_vheaders)

    def one_to_one_fabric_policy(self):
        fabric_policy = drop
        # ITERATE THROUGH ALL PAIRS OF VIRTUAL PORTS
        for (d1,[u1]) in self.d2u.items():
            for (d2,[u2]) in self.d2u.items():
                # FABRIC POLICY ONLY EXISTS WITHIN EACH VIRTUAL SWITCH
                if d1.switch != d2.switch:
                    continue
                # FORWARD OUT THE CORRECT PHYSICAL PORT
                fabric_policy += (match(vswitch=d1.switch,
                                        vinport=d1.port_no,
                                        voutport=d2.port_no) >>
                                  fwd(u2.port_no))
        return fabric_policy

    def shortest_path_fabric_policy(self,topo):
        fabric_policy = drop
        paths = Topology.all_pairs_shortest_path(topo)
        # ITERATE THROUGH ALL PAIRS OF VIRTUAL PORTS
        for (d1,[u1]) in self.d2u.items():
            for (d2,[u2]) in self.d2u.items():
                # FABRIC POLICY ONLY EXISTS WITHIN EACH VIRTUAL SWITCH
                if d1.switch != d2.switch:
                    continue
                # IF IDENTICAL VIRTUAL LOCATIONS, THEN WE KNOW FABRIC POLICY IS JUST TO FORWARD OUT MATCHING PHYSICAL PORT
                if d1.port_no == d2.port_no:
                    fabric_policy += (match(vswitch=d1.switch,
                                            vinport=d1.port_no,
                                            voutport=d2.port_no,
                                            switch=u2.switch) >> 
                                      fwd(u2.port_no))
                # OTHERWISE, GET THE PATH BETWEEN EACH PHYSICAL PAIR OF SWITCHES CORRESPONDING TO THE VIRTUAL LOCATION PAIR
                # THE FOR EACH PHYSICAL HOP ON THE PATH, CREATE THE APPROPRIATE FORWARDING RULE FOR THAT SWITCH
                # FINALLY ADD A RULE THAT FORWARDS OUT THE CORRECT PHYSICAL PORT AT THE LAST PHYSICAL SWITCH ON THE PATH
                else:
                    try:
                        for loc in paths[u1.switch][u2.switch]:
                            fabric_policy += (match(vswitch=d1.switch,
                                                    vinport=d1.port_no,
                                                    voutport=d2.port_no,
                                                    switch=loc.switch) >>
                                              fwd(loc.port_no))
                        fabric_policy += (match(vswitch=d1.switch,
                                                vinport=d1.port_no,
                                                voutport=d2.port_no,
                                                switch=u2.switch) >>
                                          fwd(u2.port_no))
                    except KeyError:
                        pass
        return fabric_policy


################################################################################
# Virtualization definition base class                                         #
################################################################################

class vdef(object):
    """Defines/implements a virtual network."""
    class DerivedNetwork(Network):
        def __init__(self,underlying=None,injection_policy=None):
            super(vdef.DerivedNetwork,self).__init__()
            self.underlying = underlying
            self.injection_policy = injection_policy
            self.inherited = set(underlying.topology.nodes())

        def inject_packet(self, pkt):
            if pkt['switch'] in self.inherited:
                self.underlying.inject_packet(pkt)
            else:
                output = self.injection_policy.eval(pkt)
                map(self.underlying.inject_packet,output)

    class locate_packet_in_underlying(Policy):
        def __init__(self):
            self.vmap = None
            super(vdef.locate_packet_in_underlying,self).__init__()

        def eval(self, pkt):
            try:
                switch = pkt['switch']
                inport = pkt['inport']
            except KeyError:
                vswitch = pkt['vswitch']
                voutport = pkt['voutport']
                u = self.vmap.d2u[Location(vswitch,voutport)][0]
                (switch,outport) = (u.switch,u.port_no)
                pkt = pkt.push(switch=switch)
                pkt = pkt.push(inport=-1)
                if not outport is None:
                    pkt = pkt.push(outport=outport)
                else:
                    pkt = pkt.push(outport=-1)
            return {pkt}

        def __repr__(self):
            return "locate_packet_in_underlying"

    def __init__(self):
        self.vmap = None
        self.underlying = None
        self.derived = None
        self.DEBUG = no_packets
        self.locate_in_underlying = self.locate_packet_in_underlying()

    def make_vmap(self):
        raise NotImplementedError

    def set_network(self,network):
        self.vmap = self.make_vmap()
        self.ingress_policy.vmap = self.vmap
        self.fabric_policy.vmap = self.vmap
        self.egress_policy.vmap = self.vmap
        self.locate_in_underlying.vmap = self.vmap
        self.ingress_policy.set_network(network)
        self.fabric_policy.set_network(network)
        self.egress_policy.set_network(network)

        ### THE INJECTION POLICY
        self.derived.injection_policy = (
            lower_packet(self.vtag) >>
            self.locate_in_underlying >>
            if_(match(outport=-1) | match(outport=None),   # IF NO OUTPORT 
                self.fabric_policy) >>  # THEN WE NEED TO RUN THE FABRIC POLICY
            self.egress_policy)

    
################################################################################
# Virtualize input policies based on virtualization definition                 #
################################################################################

class virtualize(DerivedPolicy):
    """Takes a policy for the unvirtualized components of the network, 
    another for the virtualized components of the network,
    and a virtualization defintion,
    and outputs a single policy for the underlying network."""
    def __init__(self, vpolicy, vdef, DEBUG=no_packets):
        self.vpolicy = vpolicy
        self.vnetwork = None
        self.vtag = new_vtag()
        self.vdef = vdef
        self.DEBUG = DEBUG
        self.vdef.DEBUG = self.DEBUG
        self.vdef.vtag = self.vtag

        ### THE VIRTUALIZED POLICY
        super(virtualize,self).__init__(
            if_(match(outport=None),push(outport=-1)) >>
            self.vdef.ingress_policy >> # set vlocation
            ### IF INGRESSING LIFT AND EVALUATE
            if_(match(vtag='ingress'), 
                lift_packet >> self.vpolicy >> lower_packet(self.vtag)) >>
            ### IF IN INTERIOR NETWORK ROUTE ON FABRIC AND IF APPLICABLE EGRESS
            if_(match(vtag=self.vtag), 
                self.vdef.fabric_policy >> self.vdef.egress_policy,
                self.vpolicy))
        
            
    def set_network(self, network):
        Policy.set_network(self,network)            
        self.vdef.set_network(network)
        if ((not self.vnetwork) or 
            self.vdef.derived.topology != self.vnetwork.topology):
            self.vnetwork = self.vdef.derived.copy()
            self.vpolicy.set_network(self.vnetwork) 
        
    def __repr__(self):
        return "virtualize %s\n%s" % (self.vtag, self.vdef)

########NEW FILE########
__FILENAME__ = arp

################################################################################
# The Pyretic Project                                                          #
# frenetic-lang.org/pyretic                                                    #
# author: Joshua Reich (jreich@cs.princeton.edu)                               #
################################################################################
# Licensed to the Pyretic Project by one or more contributors. See the         #
# NOTICES file distributed with this work for additional information           #
# regarding copyright and ownership. The Pyretic Project licenses this         #
# file to you under the following license.                                     #
#                                                                              #
# Redistribution and use in source and binary forms, with or without           #
# modification, are permitted provided the following conditions are met:       #
# - Redistributions of source code must retain the above copyright             #
#   notice, this list of conditions and the following disclaimer.              #
# - Redistributions in binary form must reproduce the above copyright          #
#   notice, this list of conditions and the following disclaimer in            #
#   the documentation or other materials provided with the distribution.       #
# - The names of the copyright holds and contributors may not be used to       #
#   endorse or promote products derived from this work without specific        #
#   prior written permission.                                                  #
#                                                                              #
# Unless required by applicable law or agreed to in writing, software          #
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT    #
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the     #
# LICENSE file distributed with this work for specific language governing      #
# permissions and limitations under the License.                               #
################################################################################

################################################################################
# SETUP                                                                        #
# -------------------------------------------------------------------          #
# mininet:  mininet.sh --topo cycle,4,4 (or other single subnet)               #
# test:     ping a neighbor - e.g., h1 ping -c5 h2                             #
#           then clear the arp entry for that neighbor - e.g., h1 arp -d h2    #
#           "NO RESPONSE AVAILABLE" message for h2 should only show up once    #
################################################################################

import collections

from pyretic.lib.corelib import *
from pyretic.lib.std import *
from pyretic.lib.query import *

from pyretic.modules.mac_learner import mac_learner

VERBOSE_LEVEL = 1
ARP = match(ethtype=ARP_TYPE)
REQUEST=1
RESPONSE=2

def send_arp(msg_type,network,switch,outport,srcip,srcmac,dstip,dstmac):
    """Construct an arp packet from scratch and send"""
    rp = Packet()
    rp = rp.modify(protocol=msg_type)
    rp = rp.modify(ethtype=ARP_TYPE)
    rp = rp.modify(switch=switch)
    rp = rp.modify(inport=-1)
    rp = rp.modify(outport=outport)
    rp = rp.modify(srcip=srcip)
    rp = rp.modify(srcmac=srcmac)
    rp = rp.modify(dstip=dstip)
    rp = rp.modify(dstmac=dstmac)
    rp = rp.modify(raw='')

    if VERBOSE_LEVEL > 0:
        if msg_type == RESPONSE:
            print "--------- INJECTING RESPONSE ON %d[%d] FOR %s TO %s -----------" % (switch,outport,srcip,dstip)
        if msg_type == REQUEST:
            print "--------- INJECTING REQUEST ON %d[%d] FOR %s FROM %s -----------" % (switch,outport,dstip,srcip)
        if VERBOSE_LEVEL > 1:
            print rp

    network.inject_packet(rp)


def translate(mac_of={}):
    """Translate dstmac based on input IP/MAC mapping"""
    known_ip = parallel([ match(dstip=ip) >> modify(dstmac=mac) 
                          for (ip,mac) in mac_of.iteritems() ])
    unknown_ip = ~dstip_in(mac_of.keys())
    return known_ip + unknown_ip


class arp(DynamicPolicy):
    """Respond to arp request for any known hosts,
       learn macs of unknown hosts, rewrite macs based on dstip"""
    def __init__(self,mac_of={}):
        self.mac_of = mac_of
        self.location_of = {}
        self.outstanding_requests = collections.defaultdict(dict)
        self.query = packets()
        self.query.register_callback(self.handle_arp)
        self.network = None
        super(arp,self).__init__(self.query)

    def set_network(self, network):
        self.network = network

    def handle_arp(self,pkt):
        switch = pkt['switch']
        inport = pkt['inport']
        srcip  = pkt['srcip']
        srcmac = pkt['srcmac']
        dstip  = pkt['dstip']
        dstmac = pkt['dstmac']
        opcode = pkt['protocol']

        # RECORD THE LOCATION AT WHICH THIS NODE IS ATTACHED TO THE NETWORK
        if not srcip in self.location_of:
            self.location_of[srcip] = Location(switch,inport)

        # IF THIS PACKET IS A REQUEST
        if opcode == 1:
            if dstip in self.mac_of:
                if VERBOSE_LEVEL > 0:
                    print "RECEIVED REQUEST FOR %s FROM %s, KNOWN HOST" % (dstip,srcip)
                    if VERBOSE_LEVEL > 1:
                        print pkt
                send_arp(RESPONSE,self.network,switch,inport,dstip,self.mac_of[dstip],srcip,srcmac)
            else:
                if VERBOSE_LEVEL > 0:
                    print "RECEIVED REQUEST FOR %s FROM %s, UNKNOWN HOST" % (dstip,srcip)
                    if VERBOSE_LEVEL > 1:
                        print pkt

                # LEARN MAC
                self.mac_of[srcip] = srcmac  

                # FORWARD REQUEST OUT OF ALL EGRESS PORTS
                self.outstanding_requests[srcip][dstip] = True
                if self.network is None:
                    return

                for loc in self.network.topology.egress_locations() - {Location(switch,inport)}:
                    switch  = loc.switch
                    outport = loc.port_no
                    srcip   = pkt['srcip']
                    srcmac  = pkt['srcmac']
                    dstip   = pkt['dstip']
                    dstmac  = pkt['dstmac']
                    send_arp(REQUEST,self.network,switch,outport,srcip,srcmac,dstip,dstmac)

        # THIS IS A RESPONSE THAT WE WILL ALSO LEARN FROM
        elif opcode == 2:
            try:
                del self.outstanding_requests[dstip][srcip]

                if VERBOSE_LEVEL > 0:
                    print "OUTSTANDING RESPONSE FOR %s TO %s" % (srcip,dstip)
                    if VERBOSE_LEVEL > 1:
                        print pkt

                # LEARN MAC
                self.mac_of[srcip] = srcmac
                loc = self.location_of[dstip]
                send_arp(RESPONSE,self.network,loc.switch,loc.port_no,srcip,self.mac_of[srcip],dstip,self.mac_of[dstip])
            except:

                if VERBOSE_LEVEL > 1:
                    print "IGNORABLE RESPONSE FOR %s TO %s" % (srcip,dstip)
                    print pkt
                pass    

def arp_and_flood():
    """Handle ARPs and do MAC learning"""
    return if_(ARP,arp(),flood())

def arp_and_mac_learn():
    """Handle ARPs and do MAC learning"""
    return if_(ARP,arp(),mac_learner())

def main():
    return arp_and_flood()




########NEW FILE########
__FILENAME__ = hub

################################################################################
# The Pyretic Project                                                          #
# frenetic-lang.org/pyretic                                                    #
# author: Joshua Reich (jreich@cs.princeton.edu)                               #
# author: Christopher Monsanto (chris@monsan.to)                               #
################################################################################
# Licensed to the Pyretic Project by one or more contributors. See the         #
# NOTICES file distributed with this work for additional information           #
# regarding copyright and ownership. The Pyretic Project licenses this         #
# file to you under the following license.                                     #
#                                                                              #
# Redistribution and use in source and binary forms, with or without           #
# modification, are permitted provided the following conditions are met:       #
# - Redistributions of source code must retain the above copyright             #
#   notice, this list of conditions and the following disclaimer.              #
# - Redistributions in binary form must reproduce the above copyright          #
#   notice, this list of conditions and the following disclaimer in            #
#   the documentation or other materials provided with the distribution.       #
# - The names of the copyright holds and contributors may not be used to       #
#   endorse or promote products derived from this work without specific        #
#   prior written permission.                                                  #
#                                                                              #
# Unless required by applicable law or agreed to in writing, software          #
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT    #
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the     #
# LICENSE file distributed with this work for specific language governing      #
# permissions and limitations under the License.                               #
################################################################################


################################################################################
# SETUP                                                                        #
# -------------------------------------------------------------------          #
# mininet:  mininet.sh --topo clique,4,4 (or other single subnet)              #
# test:     start xterms - e.g., 'xterm h1 h2 h3' in mininet console           #
#           start tcpdump:  in each xterm,                                     #
#           IF=`ifconfig | head -n 1 | awk '{print $1}'`;                      #
#           pingall, check dumps show identical packets for each host          #
# NOTE:     diff'ing for equality isn't foolproof                              #
#           as packets in tcpdumps may be reordered                            #
################################################################################

from pyretic.lib.corelib import *
from pyretic.lib.std import *

hub = flood()

def main():
    return hub

########NEW FILE########
__FILENAME__ = mac_learner

################################################################################
# The Pyretic Project                                                          #
# frenetic-lang.org/pyretic                                                    #
# author: Joshua Reich (jreich@cs.princeton.edu)                               #
################################################################################
# Licensed to the Pyretic Project by one or more contributors. See the         #
# NOTICES file distributed with this work for additional information           #
# regarding copyright and ownership. The Pyretic Project licenses this         #
# file to you under the following license.                                     #
#                                                                              #
# Redistribution and use in source and binary forms, with or without           #
# modification, are permitted provided the following conditions are met:       #
# - Redistributions of source code must retain the above copyright             #
#   notice, this list of conditions and the following disclaimer.              #
# - Redistributions in binary form must reproduce the above copyright          #
#   notice, this list of conditions and the following disclaimer in            #
#   the documentation or other materials provided with the distribution.       #
# - The names of the copyright holds and contributors may not be used to       #
#   endorse or promote products derived from this work without specific        #
#   prior written permission.                                                  #
#                                                                              #
# Unless required by applicable law or agreed to in writing, software          #
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT    #
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the     #
# LICENSE file distributed with this work for specific language governing      #
# permissions and limitations under the License.                               #
################################################################################

################################################################################
# SETUP                                                                        #
# -------------------------------------------------------------------          #
# mininet:  mininet.sh --topo linear,3 (or other single subnet)                #
# test:     start xterms - e.g., 'xterm h1 h2 h3' in mininet console           #
#           start tcpdump:  in each xterm,                                     #
#           IF=`ifconfig | head -n 1 | awk '{print $1}'`;                      #
#           tcpdump -XX -vvv -t -n -i $IF not ether proto 0x88cc > $IF.dump    #
#           h1 ping -c 2 h3                                                    #
#           examine dumps, confirm that h2 does not see packets on second ping #
################################################################################

from pyretic.lib.corelib import *
from pyretic.lib.std import *
from pyretic.lib.query import *

class mac_learner(DynamicPolicy):
    """Standard MAC-learning logic"""
    def __init__(self):
        super(mac_learner,self).__init__()
        self.flood = flood()           # REUSE A SINGLE FLOOD INSTANCE
        self.set_initial_state()

    def set_initial_state(self):
        self.query = packets(1,['srcmac','switch'])
        self.query.register_callback(self.learn_new_MAC)
        self.forward = self.flood  # REUSE A SINGLE FLOOD INSTANCE
        self.update_policy()

    def set_network(self,network):
        self.set_initial_state()

    def update_policy(self):
        """Update the policy based on current forward and query policies"""
        self.policy = self.forward + self.query

    def learn_new_MAC(self,pkt):
        """Update forward policy based on newly seen (mac,port)"""
        self.forward = if_(match(dstmac=pkt['srcmac'],
                                switch=pkt['switch']),
                          fwd(pkt['inport']),
                          self.forward) 
        self.update_policy()
       

def main():
    return mac_learner()

########NEW FILE########
__FILENAME__ = mininet_tests
from pyretic.tests.test_arp import *
from pyretic.tests.test_hub import *
from pyretic.tests.test_mac_learner import *

########NEW FILE########
__FILENAME__ = tests
from unit_tests import *
from mininet_tests import *

########NEW FILE########
__FILENAME__ = test_arp
#!/usr/bin/python

from mininet.net import Mininet
from mininet.node import RemoteController
import os, shlex, subprocess, utils, time
from utils import init


### Module Parameters

def get_controller():
    return 'pyretic.modules.arp'

def run_mininet():
    mn = os.path.abspath(os.path.join(os.path.dirname(__file__), '../../mininet.sh'))
    cmd = '%s --topo cycle,3,4 --mac --test=pingall' % mn
    subprocess.call(shlex.split(cmd))

def process_controller_output(oldf, newf):
    lines = oldf.readlines()
    lines.sort()
    keywords = ['TEST', 'ERROR', 'error']
    ## filter out lines that do not contain one of the keywords
    for line in lines:
        for kw in keywords:
            if line.find(kw) >= 0:
                newf.write(line)

def process_mininet_output(oldf, newf):
    lines = oldf.readlines()
    lines.sort()
    keywords = ['TEST', 'ERROR', 'error', 'received']
    ## filter out lines that do not contain one of the keywords
    for line in lines:
        for kw in keywords:
            if line.find(kw) >= 0:
                newf.write(line)


### Tests

test_arp = utils.TestModule( __name__, __file__, get_controller, run_mininet, process_controller_output, process_mininet_output)

def test_arp_i(init):
    utils.run_test(test_arp, init.test_dir, init.benchmark_dir, '-m i')
def test_arp_r0(init):
    utils.run_test(test_arp, init.test_dir, init.benchmark_dir, '-m r0')
def test_arp_p0(init):
    utils.run_test(test_arp, init.test_dir, init.benchmark_dir, '-m p0')

### Executing this file starts the mininet instance for this test.

if __name__ == "__main__":
    run_mininet()

########NEW FILE########
__FILENAME__ = test_hub
#!/usr/bin/python

from mininet.net import Mininet
from mininet.node import RemoteController
import os, shlex, subprocess, utils
from utils import init


### Module Parameters

def get_controller():
    return 'pyretic.modules.hub'

def run_mininet():
    # mn = Mininet()
    # mn.autoSetMacs = True
    # s1 = mn.addSwitch('s1')
    # h1 = mn.addHost('h1')
    # h2 = mn.addHost('h2')
    # h3 = mn.addHost('h3')
    # h4 = mn.addHost('h4')
    # mn.addLink(h1, s1)
    # mn.addLink(h2, s1)
    # mn.addLink(h3, s1)
    # mn.addLink(h4, s1)
    # mn.addController('c0', RemoteController)
    # mn.run(mn.pingAll)

    # Alternately, run mininet via the command line.  Note that we need to use
    # absolute path names because sudo mucks with the env.

    mn = os.path.abspath(os.path.join(os.path.dirname(__file__), '../../mininet.sh'))
    cmd = '%s --topo cycle,3,4 --mac --test=pingall' % mn
    subprocess.call(shlex.split(cmd))

def process_controller_output(oldf, newf):
    lines = oldf.readlines()
    lines.sort()
    keywords = ['TEST', 'ERROR', 'error']
    ## filter out lines that do not contain one of the keywords
    for line in lines:
        for kw in keywords:
            if line.find(kw) >= 0:
                newf.write(line)

def process_mininet_output(oldf, newf):
    lines = oldf.readlines()
    lines.sort()
    keywords = ['TEST', 'ERROR', 'error', 'received']
    ## filter out lines that do not contain one of the keywords
    for line in lines:
        for kw in keywords:
            if line.find(kw) >= 0:
                newf.write(line)


### Tests

test_hub = utils.TestModule( __name__, __file__, get_controller, run_mininet, process_controller_output, process_mininet_output)

def test_hub_i(init):
    utils.run_test(test_hub, init.test_dir, init.benchmark_dir, '-m i')
def test_hub_r0(init):
    utils.run_test(test_hub, init.test_dir, init.benchmark_dir, '-m r0')
def test_hub_p0(init):
    utils.run_test(test_hub, init.test_dir, init.benchmark_dir, '-m p0')

### Executing this file starts the mininet instance for this test.

if __name__ == "__main__":
    run_mininet()

########NEW FILE########
__FILENAME__ = test_language

################################################################################
# The Pyretic Project                                                          #
# frenetic-lang.org/pyretic                                                    #
# author: Joshua Reich (jreich@cs.princeton.edu)                               #
# author: Christopher Monsanto (chris@monsan.to)                               #
# author: Cole Schlesinger (cschlesi@cs.princeton.edu)                         #
################################################################################
# Licensed to the Pyretic Project by one or more contributors. See the         #
# NOTICES file distributed with this work for additional information           #
# regarding copyright and ownership. The Pyretic Project licenses this         #
# file to you under the following license.                                     #
#                                                                              #
# Redistribution and use in source and binary forms, with or without           #
# modification, are permitted provided the following conditions are met:       #
# - Redistributions of source code must retain the above copyright             #
#   notice, this list of conditions and the following disclaimer.              #
# - Redistributions in binary form must reproduce the above copyright          #
#   notice, this list of conditions and the following disclaimer in            #
#   the documentation or other materials provided with the distribution.       #
# - The names of the copyright holds and contributors may not be used to       #
#   endorse or promote products derived from this work without specific        #
#   prior written permission.                                                  #
#                                                                              #
# Unless required by applicable law or agreed to in writing, software          #
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT    #
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the     #
# LICENSE file distributed with this work for specific language governing      #
# permissions and limitations under the License.                               #
################################################################################

from pyretic.core.language import *
from pyretic.core.packet import *
from pyretic.lib.std import *

import pytest

### Equality tests ###

def test_list_equality_1():
    assert [match(switch=1),match(dstip='10.0.0.1')] == [match(switch=1),match(dstip='10.0.0.1')]

def test_list_equality_2():
    assert [match(switch=1),match(dstip='10.0.0.1')] != [match(dstip='10.0.0.1'),match(switch=1)]

def test_modify_equality_1():
    assert modify(outport=1) == modify(outport=1)

def test_modify_equality_2():
    assert modify(outport=1, srcip='10.0.0.1') == modify(outport=1, srcip='10.0.0.1')

def test_parallel_equality_1():
    assert parallel([modify(outport=1)]) == parallel([modify(outport=1)])

def test_parallel_equality_2():
    p1 = parallel([modify(srcip='10.0.0.1'), modify(outport=1)]) 
    p2 = parallel([modify(srcip='10.0.0.1'), modify(outport=1)])
    assert p1 == p2

def test_rule_equality():
    assert Rule(match(inport=1), [drop]) == Rule(match(inport=1), [drop])

def test_rule_list_equality():
    l1 = [ Rule(match(inport=1), [drop]), Rule(identity, [identity]) ]
    l2 = [ Rule(match(inport=1), [drop]), Rule(identity, [identity]) ]
    assert l1 == l2


### Match tests ###

def test_covers_1():
    assert identity.covers(identity)

def test_covers_2():
    assert match(dstip='10.0.0.1').covers(match(dstip='10.0.0.1'))

def test_covers_3():
    assert not match(inport=1).covers(identity)

# TODO check this test
def test_most_specific_prefix_matching():
    c1 = if_(
            match(srcip='10.0.0.1'), modify(outport=2), 
                if_(
                    match(srcip=IPPrefix('10.0.0.0/16')), modify(outport=3),
                    passthrough
                )
            ).compile()
    print c1
    assert c1.rules != [
        Rule(match(srcip='10.0.0.1'), [modify(outport=2)]),
        Rule(match(srcip='10.0.0.0/16'), [modify(outport=3)]),
        Rule(identity, [drop])]


### Classifier tests ###

# Initialization

def test_empty_initialization():
    c = Classifier([])
    assert c.rules == []

def test_single_initialization():
    c = Classifier([Rule(identity, [drop])])
    assert c.rules == [Rule(identity, [drop])]

def test_repeat_initialization():
    c1 = Classifier([Rule(identity, [drop])])
    c2 = Classifier([Rule(identity, [drop])])
    assert c2.rules == [Rule(identity, [drop])]


# Sequencing

def test_empty_sequential_composition():
    assert sequential() == identity

def test_commute_test_true():
    act = modify(srcip='10.0.0.1')
    pkts = match(srcip='10.0.0.1')
    m3 = Classifier()._commute_test(act, pkts)
    assert m3 == true

def test_commute_test_false_1():
    act = drop
    pkts = match(srcip='10.0.0.1')
    m3 = Classifier()._commute_test(act, pkts)
    assert m3 == false

def test_commute_test_false_2():
    act = modify(srcip='0')
    pkts = match(srcip='10.0.0.1')
    m3 = Classifier()._commute_test(act, pkts)
    assert m3 == false

def test_commute_test_incomparable():
    act = modify(srcip='10.0.0.1')
    pkts = match(dstip='10.0.0.2')
    m3 = Classifier()._commute_test(act, pkts)
    assert m3 == match(dstip='10.0.0.2')

def test_commute_id():
    act = identity
    pkts = match(outport=2)
    m3 = Classifier()._commute_test(act, pkts)
    assert m3 == pkts

def test_sequencing_drop_fwd():
    c1 = Classifier([Rule(identity, [drop])])
    c2 = Classifier([Rule(identity, [modify(outport=1)])])
    c3 = c1 >> c2
    print c3
    assert c3.rules == [Rule(identity, [drop])]

def test_sequencing_fwd_drop():
    c1 = Classifier([Rule(identity, [drop])])
    c2 = Classifier([Rule(identity, [modify(outport=1)])])
    c3 = c2 >> c1
    print c3
    assert c3.rules == [Rule(identity, [drop])]

def test_sequencing_fwd_fwd():
    c1 = Classifier([Rule(identity, [modify(outport=1)])])
    c2 = Classifier([Rule(identity, [modify(outport=2)])])
    c3 = c1 >> c2
    print c3
    assert c3.rules == [Rule(identity, [modify(outport=2)])]

def test_sequencing_fwd_fwd_shadow():
    c1 = Classifier([Rule(identity, [modify(outport=1)])])
    c2 = Classifier([Rule(identity, [modify(outport=2)]), Rule(identity, [modify(outport=3)])])
    c3 = c1 >> c2
    print c3
    assert c3.rules == [Rule(identity, [modify(outport=2)])]

def test_sequencing_fwd_fwd_fwd_1():
    c1 = Classifier([Rule(identity, [modify(outport=1)])])
    c2 = Classifier([Rule(identity, [modify(outport=2), modify(outport=3)])])
    c3 = c1 >> c2
    print c3
    assert c3.rules == [Rule(identity, [modify(outport=2), modify(outport=3)])]

def test_sequencing_fwd_fwd_fwd_2():
    c1 = Classifier([Rule(identity, [modify(outport=1), modify(outport=2)])])
    c2 = Classifier([Rule(identity, [modify(outport=3)])])
    c3 = c1 >> c2
    print c3
    assert c3.rules == [Rule(identity, [modify(outport=3), modify(outport=3)])]

def test_sequencing_mod_fwd():
    c1 = Classifier([Rule(identity, [modify(dstip='10.0.0.1', dstport=22)])])
    c2 = Classifier([Rule(match(dstip='10.0.0.1'), [modify(outport=3)])])
    c3 = c1 >> c2
    print c3
    assert c3.rules == [Rule(identity, [modify(dstip='10.0.0.1', dstport=22, outport=3)])]

def test_sequencing_fwd_mod():
    c1 = Classifier([Rule(identity, [modify(outport=3)])])
    c2 = Classifier([Rule(match(srcip='192.168.1.1'), [modify(srcip='10.0.0.1', srcport=1)])])
    c3 = c1 >> c2
    print c3
    assert c3.rules == [
        Rule(match(srcip='192.168.1.1'), [modify(srcip='10.0.0.1', srcport=1, outport=3)]),
        Rule(identity, [drop]) ]

def test_sequencing_match_match():
    c1 = Classifier([Rule(match(inport=1), [identity]), Rule(true, [drop])])
    c2 = Classifier([Rule(match(outport=2), [identity]), Rule(true, [drop])])
    c3 = c1 >> c2
    print c3
    assert c3.rules == [
        Rule(match(inport=1, outport=2), [identity]),
        Rule(match(inport=1), [drop]),
        Rule(true, [drop]) ]


# Parallel

def test_empty_parallel_composition():
    assert parallel() == drop


# Intersection

def test_intersect_1():
    assert match(inport=1).intersect(match(outport=2)) == match(inport=1, outport=2)


# Compilation

def test_nested_1():
    pol = match(inport=1) >> match(outport=2) >> modify(outport=3)
    classifier = pol.compile()
    print classifier
    assert classifier.rules == [
        Rule(match(inport=1, outport=2), [modify(outport=3)]),
        Rule(match(inport=1), [drop]),
        Rule(true, [drop]) ]

def test_if_compilation_1():
    pol = if_(true, modify(outport=1), modify(outport=2))
    classifier = pol.compile()
    assert classifier.rules == [
        Rule(true, [modify(outport=1)]) ]

def test_if_compilation_2():
    pol = if_(false, modify(outport=1), modify(outport=2))
    classifier = pol.compile()
    assert classifier.rules == [
        Rule(true, [modify(outport=2)]) ]

def test_if_compilation_3():
    pol = if_(match(inport=2), modify(outport=1), modify(outport=2))
    classifier = pol.compile()
    assert classifier.rules == [
        Rule(match(inport=2), [modify(outport=1)]),
        Rule(true, [modify(outport=2)]) ]

def test_if_compilation_4():
    pol = if_(match(inport=2), modify(outport=1), match(inport=4) >> modify(outport=2))
    classifier = pol.compile()
    print classifier
    assert classifier.rules == [
        Rule(match(inport=2), [modify(outport=1)]),
        Rule(match(inport=4), [modify(outport=2)]),
        Rule(true, [drop]) ]

def test_if_compilation_5():
    pol = if_(match(inport=2), modify(outport=1), modify(outport=3) + modify(outport=2))
    classifier = pol.compile()
    print classifier
    assert classifier.rules == [
        Rule(match(inport=2), [modify(outport=1)]),
        Rule(true, [modify(outport=3), modify(outport=2)]) ]

def test_if_compilation_x():
    mac1 = EthAddr('00:00:00:00:00:01')
    mac2 = EthAddr('00:00:00:00:00:02')
    macB = EthAddr('FF:FF:FF:FF:FF:FF')
    ip1 = IPAddr('10.0.0.1')
    ip2 = IPAddr('10.0.0.2')
    p = IPAddr('10.0.0.11')
    pol = if_(
            match(srcip=ip1),
            modify(srcip=p),
            if_(
              match(dstip=p),
              modify(dstip=ip1)))
    classifier = pol.compile()
    print pol.policy
    print classifier
    assert classifier.rules == [
        Rule(match(srcip=ip1), [modify(srcip=p)]),
        Rule(match(dstip=p), [modify(dstip=ip1)]),
        Rule(true, [identity]) ]


# Bug 1

class TestBug1:

    class TestEnv:
        def __init__(self):
            self.mac1 = EthAddr('00:00:00:00:00:01')
            self.mac2 = EthAddr('00:00:00:00:00:02')
            self.macB = EthAddr('FF:FF:FF:FF:FF:FF')
            self.ip1 = IPAddr('10.0.0.1')
            self.ip2 = IPAddr('10.0.0.2')
            self.p = IPAddr('10.0.0.11')

            self.mod = if_(
                         match(srcip=self.ip1),
                         modify(srcip=self.p),
                         if_(
                           match(dstip=self.p),
                           modify(dstip=self.ip1)))
            self.route = (
              ((match(dstmac=self.mac1) | match(dstmac=self.macB)) >> fwd(1)) +
              ((match(dstmac=self.mac2) | match(dstmac=self.macB)) >> fwd(2)) )

            self.policy = self.mod >> self.route
            self.classifier = self.policy.compile()

    @pytest.fixture
    def e(self):
        return self.TestEnv()

    # ARP request from h1.
    def test_bug_1(self, e):
        pkt = Packet({'srcmac':e.mac1,
                      'dstmac':e.macB,
                      'srcip':e.ip1,
                      'ethtype':ARP_TYPE})

        assert_out_pkts = set([
          Packet({'srcmac':e.mac1,
                  'dstmac':e.macB,
                  'srcip':e.p,
                  'ethtype':ARP_TYPE,
                  'outport':1}),
          Packet({'srcmac':e.mac1,
                  'dstmac':e.macB,
                  'srcip':e.p,
                  'ethtype':ARP_TYPE,
                  'outport':2})
          ])
        pol_out = e.policy.eval(pkt)
        class_out = e.classifier.eval(pkt)

        assert pol_out == class_out
        assert pol_out == assert_out_pkts

    # ARP response from h2 to h1.
    def test_bug_2(self, e):
        pkt = Packet({'srcmac':e.mac2,
                      'dstmac':e.mac1,
                      'srcip':e.ip2,
                      'dstip':e.p,
                      'ethtype':ARP_TYPE})

        assert_out_pkts = set([
          Packet({'srcmac':e.mac2,
                  'dstmac':e.mac1,
                  'srcip':e.ip2,
                  'dstip':e.ip1,
                  'ethtype':ARP_TYPE,
                  'outport':1})
          ])
        pol_out = e.policy.eval(pkt)
        class_out = e.classifier.eval(pkt)

        assert pol_out == class_out
        assert pol_out == assert_out_pkts

    # Ping from h1 to h2.
    def test_bug_3(self, e):
        pkt = Packet({'srcmac':e.mac1,
                      'dstmac':e.mac2,
                      'srcip':e.ip1,
                      'dstip':e.ip2,
                      'ethtype':IP_TYPE})

        assert_out_pkts = set([
          Packet({'srcmac':e.mac1,
                  'dstmac':e.mac2,
                  'srcip':e.p,
                  'dstip':e.ip2,
                  'ethtype':IP_TYPE,
                  'outport':2})
          ])
        pol_out = e.policy.eval(pkt)
        class_out = e.classifier.eval(pkt)

        assert pol_out == class_out
        assert pol_out == assert_out_pkts

    # Ping from h2 to h1.
    def test_bug_4(self, e):
        pkt = Packet({'srcmac':e.mac2,
                      'dstmac':e.mac1,
                      'srcip':e.ip2,
                      'dstip':e.p,
                      'ethtype':IP_TYPE})

        assert_out_pkts = set([
          Packet({'srcmac':e.mac2,
                  'dstmac':e.mac1,
                  'srcip':e.ip2,
                  'dstip':e.ip1,
                  'ethtype':IP_TYPE,
                  'outport':1})
          ])
        pol_out = e.policy.eval(pkt)
        class_out = e.classifier.eval(pkt)

        assert pol_out == class_out
        assert pol_out == assert_out_pkts

def test_match_compilation():
    pol = match(inport=1)
    classifier = pol.compile()
    assert classifier.rules == [
        Rule(match(inport=1), [identity]),
        Rule(identity, [drop]) ]

def test_negation_compilation():
    pol = ~match(inport=1)
    classifier = pol.compile()
    assert classifier.rules == [
        Rule(match(inport=1), [drop]),
        Rule(identity, [identity]) ]

def test_fwd_compilation():
    pol = fwd(1)
    classifier = pol.compile()
    assert classifier.rules == [Rule(identity, [modify(outport=1)])]

def test_match_fwd():
    pol = match(inport=1) >> fwd(2)
    classifier = pol.compile()
    print classifier
    assert classifier.rules == [
        Rule(match(inport=1), [modify(outport=2)]),
        Rule(identity, [drop]) ]

def test_xfwd_compilation():
    pol = xfwd(1)
    print pol.policy
    classifier = pol.compile()
    print classifier.rules
    assert classifier.rules == [
        Rule(match(inport=1), [drop]),
        Rule(identity, [modify(outport=1)]) ]

class FakeNetwork(Network):
    pass

def test_flood_compilation():
    pol = flood()
    topo = Topology()
    topo.add_switch('s1')
    topo.add_port('s1', 1, True, True)
    topo.add_port('s1', 2, True, True)
    pol.set_network(FakeNetwork(topo))
    
    classifier = pol.compile()
    print pol.policy
    print classifier
    assert classifier.rules == [
        Rule(match(switch='s1', inport=1), [modify(outport=2)]),
        Rule(match(switch='s1', inport=2), [modify(outport=1)]),
        Rule(match(switch='s1'), [modify(outport=1), modify(outport=2)]),
        Rule(identity, [drop]) ]

# Optimization

def test_remove_shadow_cover_single():
    c = Classifier([Rule(identity, [drop]), Rule(identity, [drop])])
    c = c.remove_shadowed_cover_single()
    print c
    assert c.rules == [Rule(identity, [drop])]

def test_optimize_bug_1():
    classifier = Classifier([
        Rule(match(inport=1), [modify(outport=1)]),
        Rule(identity, [drop]) ])
    print 'classifier:'
    print classifier
    print 'classifier.optimize():'
    print classifier.optimize()
    assert classifier == classifier.optimize()

########NEW FILE########
__FILENAME__ = test_mac_learner
#!/usr/bin/python

from mininet.net import Mininet
from mininet.node import RemoteController
import os, shlex, subprocess, utils, time
from utils import init


### Module Parameters

def get_controller():
    return 'pyretic.modules.mac_learner'

def run_mininet():
#     mn = Mininet()
#     s1 = mn.addSwitch('s1')
#     s2 = mn.addSwitch('s2')
#     s3 = mn.addSwitch('s3')
#     h1 = mn.addHost('h1')
#     h2 = mn.addHost('h2')
#     h3 = mn.addHost('h3')
#     mn.addLink(s1, s2)
#     mn.addLink(s1, s3)
#     mn.addLink(s2, s3)
#     mn.addLink(h1, s1)
#     mn.addLink(h2, s2)
#     mn.addLink(h3, s3)
#     mn.addController('c0', RemoteController)
#     time.sleep(1)
#     mn.run(mn.pingAll)

    # Alternately, run mininet via the command line.  Note that we need to use
    # absolute path names because sudo mucks with the env.

    mn = os.path.abspath(os.path.join(os.path.dirname(__file__), '../../mininet.sh'))
    cmd = '%s --topo cycle,3,4 --mac --test=pingall' % mn
    subprocess.call(shlex.split(cmd))

def process_controller_output(oldf, newf):
    lines = oldf.readlines()
    lines.sort()
    keywords = ['TEST', 'ERROR', 'error']
    ## filter out lines that do not contain one of the keywords
    for line in lines:
        for kw in keywords:
            if line.find(kw) >= 0:
                newf.write(line)

def process_mininet_output(oldf, newf):
    lines = oldf.readlines()
    lines.sort()
    keywords = ['TEST', 'ERROR', 'error', 'received']
    ## filter out lines that do not contain one of the keywords
    for line in lines:
        for kw in keywords:
            if line.find(kw) >= 0:
                newf.write(line)


### Tests

test_mac_learner = utils.TestModule( __name__, __file__, get_controller, run_mininet, process_controller_output, process_mininet_output)

def test_mac_learner_i(init):
    utils.run_test(test_mac_learner, init.test_dir, init.benchmark_dir, '-m i')
def test_mac_learner_r0(init):
    utils.run_test(test_mac_learner, init.test_dir, init.benchmark_dir, '-m r0')
def test_mac_learner_p0(init):
    utils.run_test(test_mac_learner, init.test_dir, init.benchmark_dir, '-m p0')

### Executing this file starts the mininet instance for this test.

if __name__ == "__main__":
    run_mininet()

########NEW FILE########
__FILENAME__ = test_packet
import pyretic.vendor

from ryu.lib.packet import *
from ryu.lib import addrconv

from pyretic.core.packet import *
from pyretic.core.packet import ProtocolValidator, EthertypeValidator, Processor
import pytest

udp_payload_srcmac="\x00\x00\x00\x00\x00\x01\x00\x00\x00\x00\x00\x01\x08\x00\x45\x00\x01\x48\x04\x46\x00\x00\x80\x11\xb4\x03\xc0\xa8\x00\x01\xc0\xa8\x00\x0a\x00\x43\x00\x44\x01\x34\xdf\xdb\x02\x01\x06\x00\x00\x00\x3d\x1e\x00\x00\x00\x00\x00\x00\x00\x00\xc0\xa8\x00\x0a\x00\x00\x00\x00\x00\x00\x00\x00\x00\x0b\x82\x01\xfc\x42\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x63\x82\x53\x63\x35\x01\x05\x3a\x04\x00\x00\x07\x08\x3b\x04\x00\x00\x0c\x4e\x33\x04\x00\x00\x0e\x10\x36\x04\xc0\xa8\x00\x01\x01\x04\xff\xff\xff\x00\xff\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00"
udp_payload="\x00\x00\x00\x00\x00\x01\x00\x00\x00\x00\x00\x02\x08\x00\x45\x00\x01\x48\x04\x46\x00\x00\x80\x11\xb4\x03\xc0\xa8\x00\x01\xc0\xa8\x00\x0a\x00\x43\x00\x44\x01\x34\xdf\xdb\x02\x01\x06\x00\x00\x00\x3d\x1e\x00\x00\x00\x00\x00\x00\x00\x00\xc0\xa8\x00\x0a\x00\x00\x00\x00\x00\x00\x00\x00\x00\x0b\x82\x01\xfc\x42\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x63\x82\x53\x63\x35\x01\x05\x3a\x04\x00\x00\x07\x08\x3b\x04\x00\x00\x0c\x4e\x33\x04\x00\x00\x0e\x10\x36\x04\xc0\xa8\x00\x01\x01\x04\xff\xff\xff\x00\xff\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00"

udp_pkt     = packet.Packet(udp_payload)
udp_pyr = { 'raw': udp_payload, 'inport': 12, 'outport': 14, 'dstip': '192.168.0.12' }

arp_payload="\xff\xff\xff\xff\xff\xff\x00\x16\xce\x6e\x8b\x24\x08\x06\x00\x01\x08\x00\x06\x04\x00\x01\x00\x16\xce\x6e\x8b\x24\xc0\xa8\x00\x72\x00\x00\x00\x00\x00\x00\xc0\xa8\x00\x01"
arp_pkt     = packet.Packet(arp_payload)
arp_pyr = { 'raw': arp_payload, 'inport': 12, 'outport': 14, 'dstip': '192.168.0.12', 'srcip': '192.168.0.234', 'protocol': 12 }

vlan_payload="\x00\x00\x00\x00\x00\x01\x00\x00\x00\x00\x00\x02\x81\x00\x45\x55\x08\x00\x45\x00\x01\x48\x04\x46\x00\x00\x80\x11\xb4\x03\xc0\xa8\x00\x01\xc0\xa8\x00\x0a\x00\x43\x00\x44\x01\x34\xdf\xdb\x02\x01\x06\x00\x00\x00\x3d\x1e\x00\x00\x00\x00\x00\x00\x00\x00\xc0\xa8\x00\x0a\x00\x00\x00\x00\x00\x00\x00\x00\x00\x0b\x82\x01\xfc\x42\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x63\x82\x53\x63\x35\x01\x05\x3a\x04\x00\x00\x07\x08\x3b\x04\x00\x00\x0c\x4e\x33\x04\x00\x00\x0e\x10\x36\x04\xc0\xa8\x00\x01\x01\x04\xff\xff\xff\x00\xff\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00"
vlan_pkt     = packet.Packet(vlan_payload)
vlan_pyr = { 'raw': vlan_payload, 'inport': 12, 'outport': 14, 'dstip': '192.168.0.12' }


def test_class_being_available_as_field_when_decorated_with_of_field():
    @of_field("ipv4.src", "testfield")
    class TestAvailableField(object):
        pass

    assert "TestAvailableField" in of_fields()

    of_fields().pop("TestAvailableField", None)

def test_field_encode():
    @of_field("ipv4.src", "srcip")
    class IpField(object):
        pass

    assert IpField().decode(udp_pkt) == "192.168.0.1"

    of_fields().pop("IpField", None)

def test_field_decode():
    @of_field("ipv4.dst", "dstip")
    class IpField(object):
        pass

    pkt = packet.Packet(IpField().encode(udp_pyr)['raw'])
    assert IpField().decode(pkt) == "192.168.0.12"
    of_fields().pop("IpField", None)

def test_validators():
    assert ProtocolValidator(12) != ProtocolValidator(11)
    assert ProtocolValidator(12) == ProtocolValidator(12)
    assert EthertypeValidator(0x0800) != EthertypeValidator(0x86dd)
    assert EthertypeValidator(0x0800) == EthertypeValidator(0x0800)

def test_udp_dst_port():
    field = of_fields()["UdpDstPort"]()
    assert field.is_valid(udp_pkt)
    assert field.decode(udp_pkt) == 68


def test_udp_src_port():
    field = of_fields()["UdpSrcPort"]()
    assert field.is_valid(udp_pkt)
    assert field.decode(udp_pkt) == 67

def test_tcp_src_port():
    field = of_fields()["TcpSrcPort"]()
    assert field.is_valid(udp_pkt) == False
    assert field.decode(udp_pkt) == None

def test_tcp_dst_port():
    field = of_fields()["TcpDstPort"]()
    assert field.is_valid(udp_pkt) == False
    assert field.decode(udp_pkt) == None

def test_icmp_code():
    field = of_fields()["IcmpCode"]()
    assert field.is_valid(udp_pkt) == False
    assert field.decode(udp_pkt) == None

def test_icmp_type():
    field = of_fields()["IcmpType"]()
    assert field.is_valid(udp_pkt) == False
    assert field.decode(udp_pkt) == None

def test_arp_opcode():
    field = of_fields()["ArpOpcode"]()
    assert field.is_valid(udp_pkt) == False
    assert field.decode(udp_pkt) == None

    assert field.is_valid(arp_pkt) == True
    assert field.decode(arp_pkt) == 1

    pkt = packet.Packet(field.encode(arp_pyr)['raw'])
    assert pkt.protocols[-1].opcode == 12

def test_arp_src_ip():
    field = of_fields()["ArpSrcIp"]()
    assert field.is_valid(udp_pkt) == False
    assert field.decode(udp_pkt) == None

    assert field.is_valid(arp_pkt) == True
    assert field.decode(arp_pkt) == "192.168.0.114"

    pkt = packet.Packet(field.encode(arp_pyr)['raw'])
    assert pkt.protocols[-1].src_ip == "192.168.0.234"

def test_arp_dst_ip():
    field = of_fields()["ArpDstIp"]()
    assert field.is_valid(udp_pkt) == False
    assert field.decode(udp_pkt) == None

    assert field.is_valid(arp_pkt) == True
    assert field.decode(arp_pkt) == "192.168.0.1"

    pkt = packet.Packet(field.encode(arp_pyr)['raw'])
    assert pkt.protocols[-1].dst_ip == "192.168.0.12"


def test_processor_packing():
    pro = Processor().compile()
    func = pro.unpack

    assert func(udp_payload) == {'dstip': '192.168.0.10', 'protocol': 17, 'srcmac': '00:00:00:00:00:02', 'tos': 0, 'dstmac': '00:00:00:00:00:01', 'ethtype': 2048, 'srcip': '192.168.0.1', 'dstport': 68, 'srcport': 67, 'header_len': 14, 'payload_len': len(udp_payload)}
    
    assert func(udp_pkt) == {'dstip': '192.168.0.10', 'protocol': 17, 'srcmac': '00:00:00:00:00:02', 'tos': 0, 'dstmac': '00:00:00:00:00:01', 'ethtype': 2048, 'srcip': '192.168.0.1', 'dstport': 68, 'srcport': 67, 'header_len': 14, 'payload_len': len(udp_payload)}

    assert func(arp_pkt) == {'dstip': '192.168.0.1', 'protocol': 1, 'srcmac': '00:16:ce:6e:8b:24', 'ethtype': 2054, 'srcip': '192.168.0.114', 'dstmac': 'ff:ff:ff:ff:ff:ff', 'header_len': 14, 'payload_len': len(arp_payload)}

    assert func(vlan_pkt) == {'dstip': '192.168.0.10', 'protocol': 17, 'srcmac': '00:00:00:00:00:02', 'tos': 0, 'vlan_pcp': 2, 'dstmac': '00:00:00:00:00:01', 'ethtype': 2048, 'srcip': '192.168.0.1', 'dstport': 68, 'srcport': 67, 'vlan_id': 1365, 'header_len': 14, 'payload_len': len(vlan_payload)}

def test_empty_raw_packet():
    from pyretic.core.packet import build_empty_packet

    q = build_empty_packet(2048, 17)
    assert udp.udp in q
    assert ipv4.ipv4 in q

def test_processor_unpacking():
    pro = Processor().compile()
    func = pro.pack

    res = func({'dstip': '192.168.0.10', 'protocol': 17, 'srcmac': '00:00:00:00:00:02', 'tos': 0, 'dstmac': '00:00:00:00:00:01', 'ethtype': 2048, 'srcip': '192.168.0.1', 'dstport': 68, 'srcport': 67, 'raw': udp_payload, 'vlan_id': 1365, 'vlan_pcp': 2})

    pkt = packet.Packet(res)

    assert vlan.vlan in pkt
    assert res == vlan_payload

    res = func({'dstip': '192.168.0.10', 'protocol': 17, 'srcmac': '00:00:00:00:00:02', 'tos': 0, 'dstmac': '00:00:00:00:00:01', 'ethtype': 2048, 'srcip': '192.168.0.1', 'dstport': 68, 'srcport': 67, 'raw': vlan_payload})

    pkt = packet.Packet(res)

    assert not vlan.vlan in pkt
    assert res == udp_payload


########NEW FILE########
__FILENAME__ = unit_tests
from test_language import *
from test_packet   import *

########NEW FILE########
__FILENAME__ = utils
'''Utilities for system-wide mininet tests.'''

from argparse import ArgumentParser
import difflib, filecmp, os, shlex, shutil, signal, subprocess, sys, tempfile, time
import filecmp, os, pytest

### Fixtures

class InitEnv():
    def __init__(self, benchmark_dir, test_dir):
        self.benchmark_dir = benchmark_dir
        self.test_dir = test_dir

@pytest.fixture(scope="module")
def init():
    '''Delete any old test files and return the name of the test output
    directory.'''
    benchmark_dir = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'regression')
    test_dir = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'results')
    # Check for benchmarks.
    assert os.path.exists(benchmark_dir)
    # Create test dir if not already present.
    if not os.path.exists(test_dir):
        os.mkdir(test_dir)
    # Delete any old test files.
    for f in os.listdir(test_dir):
        if f.endswith(".err") or f.endswith(".out") or f.endswith(".diff"):
            os.remove(os.path.join(test_dir, f))
    return InitEnv(benchmark_dir, test_dir)


### Utility functions

class TestCase():
    def __init__(self, test_name, test_file, test_output_dir, process_mininet_output, process_controller_output, controller_module, controller_opts):
        self.test_name = test_name
        self.test_file = test_file
        self.controller_module = controller_module
        self.test_output_dir = test_output_dir
        self.process_mininet_output = process_mininet_output
        self.process_controller_output = process_controller_output
        self.controller_opts = controller_opts
        self.name = '%s.%s' % (test_name, '.'.join(shlex.split(controller_opts)))
        self.tmpdir = tempfile.mkdtemp()

    def _start_controller(self):
        cmd = ["pyretic.py", self.controller_module, '-v', 'high'] + shlex.split(self.controller_opts)
        out_name = '%s.controller.out' % self.name
        err_name = '%s.controller.err' % self.name
        out_path = os.path.join(self.tmpdir, out_name)
        err_path = os.path.join(self.tmpdir, err_name)
        self.out = file(out_path, 'w')
        self.err = file(err_path, 'w')
        self.process = subprocess.Popen(cmd, stdout=self.out, stderr=self.err) 
        time.sleep(2)
        return [out_name, err_name]

    def _stop_controller(self):
        self.process.send_signal(signal.SIGINT)
        self.out.close()
        self.err.close()
        time.sleep(2)

    def _run_mininet(self):
        cmd = shlex.split('sudo %s' % self.test_file)
        out_name = '%s.mininet.out' % self.name
        err_name = '%s.mininet.err' % self.name
        out_path = os.path.join(self.tmpdir, out_name)
        err_path = os.path.join(self.tmpdir, err_name)
        out = file(out_path, 'w')
        err = file(err_path, 'w')
        subprocess.call(cmd, stdout=out, stderr=err)
        out.close()
        err.close()
        return [out_name, err_name]

    def _move_and_filter_result(self, filename, process_output):
        oldfname = os.path.join(self.tmpdir, filename)
        newfname = os.path.join(self.test_output_dir, filename)
        oldf = file(oldfname, 'r')
        newf = file(newfname, 'w')
        process_output(oldf, newf)
        oldf.close()
        newf.close()

    def _cleanup(self):
        subprocess.call(['sudo', 'mn', '-c'])        
        shutil.rmtree(self.tmpdir)

    def run(self):
        controller_files = self._start_controller()
        mininet_files = self._run_mininet()
        self._stop_controller()
        for f in controller_files:
            self._move_and_filter_result(f, self.process_controller_output)
        for f in mininet_files:
            self._move_and_filter_result(f, self.process_mininet_output)
        self._cleanup()
        return [os.path.join(self.test_output_dir, f) for f in mininet_files + controller_files]

class TestModule():
    def __init__(self, 
                 name,
                 filename,
                 get_controller,
                 run_mininet,
                 process_controller_output,
                 process_mininet_output):
        self.name = name
        self.filename = filename
        self.get_controller = get_controller
        self.run_mininet = run_mininet
        self.process_mininet_output = process_mininet_output
        self.process_controller_output = process_controller_output

def run_test(module, test_output_dir, benchmark_dir, controller_args):
    test_name = module.name.split('.')[-1]
    test_file = os.path.abspath(module.filename)
    # Run the test.
    test = TestCase(test_name, test_file, test_output_dir, 
                    module.process_mininet_output, module.process_controller_output,
                    module.get_controller(), controller_args)
    files = test.run()
    files = [os.path.basename(f) for f in files]
    # Compare the output.
    match, mismatch, errors = filecmp.cmpfiles(benchmark_dir, test_output_dir, files)
    if mismatch:
        for fname in mismatch:
            fname1 = os.path.join(benchmark_dir, fname)
            fname2 = os.path.join(test_output_dir, fname)
            diffname = os.path.join(test_output_dir, '%s.diff' % fname)
            f1 = file(fname1, 'r')
            f2 = file(fname2, 'r')
            fdiff = file(diffname, 'w')
            sys.stderr.write('--- Diff: %s vs. %s ---\n' %
              (os.path.basename(fname1), os.path.basename(fname2)))
            d = difflib.Differ()
            diff = difflib.ndiff(f1.readlines(), f2.readlines())
            for line in diff:
                sys.stderr.write(line)
                fdiff.write(line)
            f1.close()
            f2.close()
            fdiff.close()
        assert mismatch == []
    assert errors == []
    assert match == files

########NEW FILE########
__FILENAME__ = of_tutorial

################################################################################
# The Pyretic Project                                                          #
# frenetic-lang.org/pyretic                                                    #
# author: Joshua Reich (jreich@cs.princeton.edu)                               #
################################################################################
# Licensed to the Pyretic Project by one or more contributors. See the         #
# NOTICES file distributed with this work for additional information           #
# regarding copyright and ownership. The Pyretic Project licenses this         #
# file to you under the following license.                                     #
#                                                                              #
# Redistribution and use in source and binary forms, with or without           #
# modification, are permitted provided the following conditions are met:       #
# - Redistributions of source code must retain the above copyright             #
#   notice, this list of conditions and the following disclaimer.              #
# - Redistributions in binary form must reproduce the above copyright          #
#   notice, this list of conditions and the following disclaimer in            #
#   the documentation or other materials provided with the distribution.       #
# - The names of the copyright holds and contributors may not be used to       #
#   endorse or promote products derived from this work without specific        #
#   prior written permission.                                                  #
#                                                                              #
# Unless required by applicable law or agreed to in writing, software          #
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT    #
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the     #
# LICENSE file distributed with this work for specific language governing      #
# permissions and limitations under the License.                               #
################################################################################


################################################################################
# SETUP                                                                        #
# -------------------------------------------------------------------          #
# mininet:  mininet.sh --topo clique,4,4 (or other single subnet)              #
################################################################################

from pyretic.lib.corelib import *
from pyretic.lib.std import *
from pyretic.lib.query import *

def act_like_hub():
    """Implement hub-like behavior --- send all packets to all ports on a network
    minimum spanning tree, except for the input port"""
    return flood()  # Return the policy flood

# we create a new dynamic policy class with the name "act_like_switch"
class act_like_switch(DynamicPolicy):
    """
    Implement switch-like behavior.
    """
    """ # DELETE BOTH THIS LINE AND THE ONE BELOW TO START WORKING ON THE TUTORIAL # 
    # Here's some psuedocode to start you off implementing a learning
    # switch.  You'll need to rewrite it as real Python code using Pyretic predicates
    # and policies - all of which are defined and documented in pyretic/core/language.py

    def __init__(self):
        # Set up the initial forwarding behavior for your mac learning switch
        # Tip: set up a separate variable to track this
        self.forward = <some policy here>
        # hint, mac learning switches start off by flooding all packets

        # Set up a query that will receive new incoming packets
        self.query = <a packets query for the first packet w/ a given (srcmac,switch) pair>

        # Write a function to take each new packet p and update the forwarding policy
        # so subsequent incoming packets on this switch whose dstmac matches p's srcmac 
        # (accessed like in a dictionary p['srcmac']), those packets will be forwarded out
        # p's inport (pyretic packets are located, so we access this value just like srcmac
        # - i.e., p['inport'])
        def learn_from_a_packet(pkt):
            # perhaps we want to print the incoming packet so we can see it
            print pkt
            # and we will need to set the forwarding policy
            self.forward =  <....>  # hint use the 'match' policy and either 
                                    # if_(f,p1,p2) or
                                    # a combination of parallel and sequential composition

            # let's print the forwarding policy to see if it looks right
            print self.forward
            # and don't forget to update the dynamic policy to forward and query
            # (each dynamic policy has a member 'policy'
            # whenever this member is assigned, the dynamic policy updates itself)
            self.policy = <forwarding and query policies composed in parallel>
            # hint: 'P1 + P2'  is shorthand for parallel composition of P1 and P2
            #       'P1 >> P2' is shorthand for sequential composition of P1 and P2

        # we need to make sure learn_from_a_packet is called back 
        # every time our query sees a new packet
        self.query.register_callback(learn_from_a_packet)

        # finally, we initialize our dynamic policy 
        super(act_like_switch,self).__init__(<the first value 'self.policy' should take>)
    """ # DELETE BOTH THIS LINE AND THE ONE ABOVE TO START WORKING ON THE TUTORIAL # 


def main():
    ## The main method returns the policy that will be run  
    ## To try your code, comment the first return line and uncomment the second

    ### Part 0 - hub  ###
    return act_like_hub()

    ### Part 1 - write a basic mac learning module ###
#   return act_like_switch()


########NEW FILE########
__FILENAME__ = conf
# -*- coding: utf-8 -*-
#
# ryu documentation build configuration file, created by
# sphinx-quickstart on Mon Dec  5 15:38:48 2011.
#
# This file is execfile()d with the current directory set to its containing dir.
#
# Note that not all possible configuration values are present in this
# autogenerated file.
#
# All configuration values have a default; values that are commented out
# serve to show the default.

import sys, os

# If extensions (or modules to document with autodoc) are in another directory,
# add these directories to sys.path here. If the directory is relative to the
# documentation root, use os.path.abspath to make it absolute, like shown here.
sys.path.insert(0, os.path.abspath('../..'))

from ryu import version as ryu_version

# -- General configuration -----------------------------------------------------

# If your documentation needs a minimal Sphinx version, state it here.
#needs_sphinx = '1.0'

# Add any Sphinx extension module names here, as strings. They can be extensions
# coming with Sphinx (named 'sphinx.ext.*') or your custom ones.
extensions = [ 'sphinx.ext.autodoc' ]

# Add any paths that contain templates here, relative to this directory.
templates_path = ['_templates']

# The suffix of source filenames.
source_suffix = '.rst'

# The encoding of source files.
#source_encoding = 'utf-8-sig'

# The master toctree document.
master_doc = 'index'

# General information about the project.
project = u'Ryu'
copyright = u'2011-2013 Nippon Telegraph and Telephone Corporation'

# The version info for the project you're documenting, acts as replacement for
# |version| and |release|, also used in various other places throughout the
# built documents.
#
# The short X.Y version.
version = ryu_version
# The full version, including alpha/beta/rc tags.
release = ryu_version

# The language for content autogenerated by Sphinx. Refer to documentation
# for a list of supported languages.
#language = None

# There are two options for replacing |today|: either, you set today to some
# non-false value, then it is used:
#today = ''
# Else, today_fmt is used as the format for a strftime call.
#today_fmt = '%B %d, %Y'

# List of patterns, relative to source directory, that match files and
# directories to ignore when looking for source files.
exclude_patterns = []

# The reST default role (used for this markup: `text`) to use for all documents.
#default_role = None

# If true, '()' will be appended to :func: etc. cross-reference text.
#add_function_parentheses = True

# If true, the current module name will be prepended to all description
# unit titles (such as .. function::).
#add_module_names = True

# If true, sectionauthor and moduleauthor directives will be shown in the
# output. They are ignored by default.
#show_authors = False

# The name of the Pygments (syntax highlighting) style to use.
pygments_style = 'sphinx'

# A list of ignored prefixes for module index sorting.
#modindex_common_prefix = []


# -- Options for HTML output ---------------------------------------------------

# The theme to use for HTML and HTML Help pages.  See the documentation for
# a list of builtin themes.
html_theme = 'haiku'

# Theme options are theme-specific and customize the look and feel of a theme
# further.  For a list of options available for each theme, see the
# documentation.
#html_theme_options = {}

# Add any paths that contain custom themes here, relative to this directory.
#html_theme_path = []

# The name for this set of Sphinx documents.  If None, it defaults to
# "<project> v<release> documentation".
#html_title = None

# A shorter title for the navigation bar.  Default is the same as html_title.
#html_short_title = None

# The name of an image file (relative to this directory) to place at the top
# of the sidebar.
#html_logo = None

# The name of an image file (within the static path) to use as favicon of the
# docs.  This file should be a Windows icon file (.ico) being 16x16 or 32x32
# pixels large.
#html_favicon = None

# Add any paths that contain custom static files (such as style sheets) here,
# relative to this directory. They are copied after the builtin static files,
# so a file named "default.css" will overwrite the builtin "default.css".
html_static_path = ['_static']

# If not '', a 'Last updated on:' timestamp is inserted at every page bottom,
# using the given strftime format.
#html_last_updated_fmt = '%b %d, %Y'

# If true, SmartyPants will be used to convert quotes and dashes to
# typographically correct entities.
#html_use_smartypants = True

# Custom sidebar templates, maps document names to template names.
#html_sidebars = {}

# Additional templates that should be rendered to pages, maps page names to
# template names.
#html_additional_pages = {}

# If false, no module index is generated.
#html_domain_indices = True

# If false, no index is generated.
#html_use_index = True

# If true, the index is split into individual pages for each letter.
#html_split_index = False

# If true, links to the reST sources are added to the pages.
#html_show_sourcelink = True

# If true, "Created using Sphinx" is shown in the HTML footer. Default is True.
#html_show_sphinx = True

# If true, "(C) Copyright ..." is shown in the HTML footer. Default is True.
#html_show_copyright = True

# If true, an OpenSearch description file will be output, and all pages will
# contain a <link> tag referring to it.  The value of this option must be the
# base URL from which the finished HTML is served.
#html_use_opensearch = ''

# This is the file name suffix for HTML files (e.g. ".xhtml").
#html_file_suffix = None

# Output file base name for HTML help builder.
htmlhelp_basename = 'ryudoc'


# -- Options for LaTeX output --------------------------------------------------

# The paper size ('letter' or 'a4').
#latex_paper_size = 'letter'

# The font size ('10pt', '11pt' or '12pt').
#latex_font_size = '10pt'

# Grouping the document tree into LaTeX files. List of tuples
# (source start file, target name, title, author, documentclass [howto/manual]).
latex_documents = [
  ('index', 'ryu.tex', u'ryu Documentation',
   u'ryu development team', 'manual'),
]

# The name of an image file (relative to this directory) to place at the top of
# the title page.
#latex_logo = None

# For "manual" documents, if this is true, then toplevel headings are parts,
# not chapters.
#latex_use_parts = False

# If true, show page references after internal links.
#latex_show_pagerefs = False

# If true, show URL addresses after external links.
#latex_show_urls = False

# Additional stuff for the LaTeX preamble.
#latex_preamble = ''

# Documents to append as an appendix to all manuals.
#latex_appendices = []

# If false, no module index is generated.
#latex_domain_indices = True


# -- Options for manual page output --------------------------------------------

# One entry per manual page. List of tuples
# (source start file, name, description, authors, manual section).
man_pages = [
    ('index', 'ryu', u'ryu Documentation',
     [u'ryu development team'], 1),
    ('man/ryu_manager', 'ryu-manager', u'ryu manager',
     [u'ryu development team'], 1),
]

########NEW FILE########
__FILENAME__ = cbench
# Copyright (C) 2012 Nippon Telegraph and Telephone Corporation.
# Copyright (C) 2012 Isaku Yamahata <yamahata at valinux co jp>
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.


from ryu.base import app_manager
from ryu.controller import ofp_event
from ryu.controller.handler import MAIN_DISPATCHER
from ryu.controller.handler import set_ev_cls
from ryu.ofproto import ofproto_v1_0


class Cbench(app_manager.RyuApp):
    OFP_VERSIONS = [ofproto_v1_0.OFP_VERSION]

    def __init__(self, *args, **kwargs):
        super(Cbench, self).__init__(*args, **kwargs)

    @set_ev_cls(ofp_event.EventOFPPacketIn, MAIN_DISPATCHER)
    def packet_in_handler(self, ev):
        msg = ev.msg
        datapath = msg.datapath
        ofproto = datapath.ofproto

        match = datapath.ofproto_parser.OFPMatch(
            ofproto_v1_0.OFPFW_ALL, 0, 0, 0,
            0, 0, 0, 0, 0, 0, 0, 0, 0)

        mod = datapath.ofproto_parser.OFPFlowMod(
            datapath, match=match, cookie=0, command=ofproto.OFPFC_ADD,
            idle_timeout=0, hard_timeout=0,
            priority=ofproto.OFP_DEFAULT_PRIORITY,
            flags=0, actions=None)
        datapath.send_msg(mod)

########NEW FILE########
__FILENAME__ = client
# Copyright (C) 2011 Nippon Telegraph and Telephone Corporation.
# Copyright (C) 2011, 2012 Isaku Yamahata <yamahata at valinux co jp>
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# This is a client library for Ryu REST API.  (ryu.app.rest_quantum etc)
# This module is *not* used by ryu-manager.
# Imported and used by OpenStack Ryu plug-in and agent.

import httplib
import json
import urlparse


def ignore_http_not_found(func):
    """
    Ignore http not found(404) with Ryu client library.
    Ryu client raises httplib.HTTPException with an error in args[0]
    """
    try:
        func()
    except httplib.HTTPException as e:
        res = e.args[0]
        if res.status != httplib.NOT_FOUND:
            raise


class RyuClientBase(object):
    def __init__(self, version, address):
        super(RyuClientBase, self).__init__()
        self.version = version
        res = urlparse.SplitResult('', address, '', '', '')
        self.host = res.hostname
        self.port = res.port
        self.url_prefix = '/' + self.version + '/'

    def _do_request(self, method, action, body=None):
        conn = httplib.HTTPConnection(self.host, self.port)
        url = self.url_prefix + action
        headers = {}
        if body is not None:
            body = json.dumps(body)
            headers['Content-Type'] = 'application/json'
        conn.request(method, url, body, headers)
        res = conn.getresponse()
        if res.status in (httplib.OK,
                          httplib.CREATED,
                          httplib.ACCEPTED,
                          httplib.NO_CONTENT):
            return res

        raise httplib.HTTPException(
            res, 'code %d reason %s' % (res.status, res.reason),
            res.getheaders(), res.read())

    def _do_request_read(self, method, action):
        res = self._do_request(method, action)
        return res.read()


class OFPClientV1_0(RyuClientBase):
    version = 'v1.0'

    # /networks/{network_id}/{dpid}_{port}/macs/{mac_address}
    path_networks = 'networks'
    path_network = path_networks + '/%s'
    path_port = path_network + '/%s_%s'
    path_macs = path_port + '/macs'
    path_mac = path_macs + '/%s'

    def __init__(self, address):
        super(OFPClientV1_0, self).__init__(OFPClientV1_0.version, address)

    def get_networks(self):
        return self._do_request_read('GET', self.path_networks)

    def create_network(self, network_id):
        self._do_request('POST', self.path_network % network_id)

    def update_network(self, network_id):
        self._do_request('PUT', self.path_network % network_id)

    def delete_network(self, network_id):
        self._do_request('DELETE', self.path_network % network_id)

    def get_ports(self, network_id):
        return self._do_request_read('GET', self.path_network % network_id)

    def create_port(self, network_id, dpid, port):
        self._do_request('POST', self.path_port % (network_id, dpid, port))

    def update_port(self, network_id, dpid, port):
        self._do_request('PUT', self.path_port % (network_id, dpid, port))

    def delete_port(self, network_id, dpid, port):
        self._do_request('DELETE', self.path_port % (network_id, dpid, port))

    def list_macs(self, network_id, dpid, port):
        return self._do_request_read('GET',
                                     self.path_macs % (network_id, dpid, port))

    def create_mac(self, network_id, dpid, port, mac_address):
        self._do_request('POST', self.path_mac % (network_id, dpid, port,
                                                  mac_address))

    def update_mac(self, network_id, dpid, port, mac_address):
        self._do_request('PUT', self.path_mac % (network_id, dpid, port,
                                                 mac_address))


OFPClient = OFPClientV1_0


class TunnelClientV1_0(RyuClientBase):
    version = 'v1.0'

    # /tunnels/networks/{network-id}/key/{tunnel_key}
    # /tunnels/switches/{dpid}/ports/{port-id}/{remote_dpip}
    path_tunnels = 'tunnels'
    path_key = path_tunnels + '/networks/%(network_id)s/key'
    path_tunnel_key = path_key + '/%(tunnel_key)s'
    path_ports = path_tunnels + '/switches/%(dpid)s/ports'
    path_port = path_ports + '/%(port_no)s'
    path_remote_dpid = path_port + '/%(remote_dpid)s'

    def __init__(self, address):
        super(TunnelClientV1_0, self).__init__(self.version, address)

    def get_tunnel_key(self, network_id):
        return self._do_request_read('GET', self.path_key % locals())

    def delete_tunnel_key(self, network_id):
        return self._do_request_read('DELETE', self.path_key % locals())

    def create_tunnel_key(self, network_id, tunnel_key):
        self._do_request('POST', self.path_tunnel_key % locals())

    def update_tunnel_key(self, network_id, tunnel_key):
        self._do_request('PUT', self.path_tunnel_key % locals())

    def list_ports(self, dpid):
        return self._do_request_read('GET', self.path_ports % locals())

    def delete_port(self, dpid, port_no):
        return self._do_request_read('DELETE', self.path_port % locals())

    def get_remote_dpid(self, dpid, port_no):
        return self._do_request_read('GET', self.path_port % locals())

    def create_remote_dpid(self, dpid, port_no, remote_dpid):
        self._do_request('POST', self.path_remote_dpid % locals())

    def update_remote_dpid(self, dpid, port_no, remote_dpid):
        self._do_request('PUT', self.path_remote_dpid % locals())


TunnelClient = TunnelClientV1_0


class SwitchConfClientV1_0(RyuClientBase):
    version = 'v1.0'

    # /conf/switches
    # /conf/switches/<dpid>
    # /conf/switches/<dpid>/<key>
    path_conf_switches = 'conf/switches'
    path_switch = path_conf_switches + '/%(dpid)s'
    path_key = path_switch + '/%(key)s'

    def __init__(self, address):
        super(SwitchConfClientV1_0, self).__init__(self.version, address)

    def list_switches(self):
        return self._do_request_read('GET', self.path_conf_switches)

    def delete_switch(self, dpid):
        self._do_request('DELETE', self.path_switch % locals())

    def list_keys(self, dpid):
        return self._do_request_read('GET', self.path_switch % locals())

    def set_key(self, dpid, key, value):
        self._do_request('PUT', self.path_key % locals(), value)

    def get_key(self, dpid, key):
        return self._do_request_read('GET', self.path_key % locals())

    def delete_key(self, dpid, key):
        self._do_request('DELETE', self.path_key % locals())


SwitchConfClient = SwitchConfClientV1_0


class QuantumIfaceClientV1_0(RyuClientBase):
    version = 'v1.0'

    # /quantum/ports
    # /quantum/ports/{iface_id}
    # /quantum/ports/{iface_id}/keys/
    # /quantum/ports/{iface_id}/keys/{key}/{value}
    path_quantum_ports = 'quantum/ports'
    path_iface_id = path_quantum_ports + '/%(iface_id)s'
    path_keys = path_iface_id + '/keys'
    path_key = path_keys + '/%(key)s'
    path_value = path_key + '/%(value)s'

    def __init__(self, address):
        super(QuantumIfaceClientV1_0, self).__init__(self.version, address)

    def list_ifaces(self):
        return self._do_request_read('GET', self.path_quantum_ports)

    def delete_iface(self, iface_id):
        self._do_request('DELETE', self.path_iface_id % locals())

    def list_keys(self, iface_id):
        return self._do_request_read('GET', self.path_keys % locals())

    def get_key(self, iface_id, key):
        return self._do_request_read('GET', self.path_key % locals())

    def create_key(self, iface_id, key, value):
        self._do_request('POST', self.path_value % locals())

    def update_key(self, iface_id, key, value):
        self._do_request('PUT', self.path_value % locals())

    # for convenience
    def get_network_id(self, iface_id):
        return self.get_key(iface_id, 'network_id')

    def create_network_id(self, iface_id, network_id):
        self.create_key(iface_id, 'network_id', network_id)

    def update_network_id(self, iface_id, network_id):
        self.update_key(iface_id, 'network_id', network_id)


QuantumIfaceClient = QuantumIfaceClientV1_0
NeutronIfaceClient = QuantumIfaceClient   # project rename quantum -> neutron


class TopologyClientV1_0(RyuClientBase):
    version = 'v1.0'

    # /topology/switches
    # /topology/switches/{dpid}
    # /topology/links
    # /topology/links/{dpid}
    _path_switches = 'topology/switches'
    _path_links = 'topology/links'

    def __init__(self, address):
        super(TopologyClientV1_0, self).__init__(self.version, address)

    # dpid: string representation (see ryu.lib.dpid)
    #       if None, get all
    def list_switches(self, dpid=None):
        uri = self._path_switches
        if dpid:
            uri += '/%s' % (dpid)

        return self._do_request('GET', uri)

    # dpid: string representation (see ryu.lib.dpid)
    #       if None, get all
    def list_links(self, dpid=None):
        uri = self._path_links
        if dpid:
            uri += '/%s' % (dpid)
        return self._do_request('GET', uri)


TopologyClient = TopologyClientV1_0

########NEW FILE########
__FILENAME__ = conf_switch_key
# Copyright (C) 2012 Nippon Telegraph and Telephone Corporation.
# Copyright (C) 2012 Isaku Yamahata <yamahata at private email ne jp>
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.

OVSDB_ADDR = 'ovsdb_addr'               # value <method>:<ip>[:<port>]
OVS_TUNNEL_ADDR = 'ovs_tunnel_addr'     # ip address of tunnel

########NEW FILE########
__FILENAME__ = gre_tunnel
# Copyright (C) 2012 Nippon Telegraph and Telephone Corporation.
# Copyright (C) 2012 Isaku Yamahata <yamahata at private email ne jp>
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# This module updates flow table for OpenStack integration.
# Despite of the name, this module isn't GRE specific and
# should work for VXLAN etc as well.

import collections

from ryu import exception as ryu_exc
from ryu.app.rest_nw_id import (NW_ID_VPORT_GRE,
                                RESERVED_NETWORK_IDS)
from ryu.base import app_manager
from ryu.controller import (dpset,
                            event,
                            handler,
                            network,
                            ofp_event,
                            tunnels)
from ryu.ofproto import nx_match
from ryu.lib import dpid as dpid_lib
from ryu.lib import mac


def _is_reserved_port(ofproto, port_no):
    return port_no > ofproto.OFPP_MAX


def _link_is_up(dpset_, dp, port_no):
    try:
        state = dpset_.get_port(dp.id, port_no).state
        return not (state & dp.ofproto.OFPPS_LINK_DOWN)
    except ryu_exc.PortNotFound:
        return False


class PortSet(app_manager.RyuApp):

    # Those events are higher level events than events of network tenant,
    # tunnel ports as the race conditions are masked.
    # Add event is generated only when all necessary informations are gathered,
    # Del event is generated when any one of the informations are deleted.
    #
    # Example: ports for VMs
    # there is a race condition between ofp port add/del event and
    # register network_id for the port.

    class EventTunnelKeyDel(event.EventBase):
        def __init__(self, tunnel_key):
            super(PortSet.EventTunnelKeyDel, self).__init__()
            self.tunnel_key = tunnel_key

    class EventPortBase(event.EventBase):
        def __init__(self, dpid, port_no):
            super(PortSet.EventPortBase, self).__init__()
            self.dpid = dpid
            self.port_no = port_no

    class EventVMPort(EventPortBase):
        def __init__(self, network_id, tunnel_key,
                     dpid, port_no, mac_address, add_del):
            super(PortSet.EventVMPort, self).__init__(dpid, port_no)
            self.network_id = network_id
            self.tunnel_key = tunnel_key
            self.mac_address = mac_address
            self.add_del = add_del

        def __str__(self):
            return ('EventVMPort<dpid %s port_no %d '
                    'network_id %s tunnel_key %s mac %s add_del %s>' %
                    (dpid_lib.dpid_to_str(self.dpid), self.port_no,
                     self.network_id, self.tunnel_key,
                     mac.haddr_to_str(self.mac_address), self.add_del))

    class EventTunnelPort(EventPortBase):
        def __init__(self, dpid, port_no, remote_dpid, add_del):
            super(PortSet.EventTunnelPort, self).__init__(dpid, port_no)
            self.remote_dpid = remote_dpid
            self.add_del = add_del

        def __str__(self):
            return ('EventTunnelPort<dpid %s port_no %d remote_dpid %s '
                    'add_del %s>' %
                    (dpid_lib.dpid_to_str(self.dpid), self.port_no,
                     dpid_lib.dpid_to_str(self.remote_dpid), self.add_del))

    def __init__(self, **kwargs):
        super(PortSet, self).__init__()
        self.nw = kwargs['network']
        self.tunnels = kwargs['tunnels']
        self.dpset = kwargs['dpset']
        app_manager.register_app(self)

    def _check_link_state(self, dp, port_no, add_del):
        if add_del:
            # When adding port, the link should be UP.
            return _link_is_up(self.dpset, dp, port_no)
        else:
            # When deleting port, the link status isn't cared.
            return True

    # Tunnel port
    # of connecting: self.dpids by (dpid, port_no)
    #    datapath: connected: EventDP event
    #    port status: UP: port add/delete/modify event
    # remote dpid: self.tunnels by (dpid, port_no): tunnel port add/del even
    def _tunnel_port_handler(self, dpid, port_no, add_del):
        dp = self.dpset.get(dpid)
        if dp is None:
            return
        if not self._check_link_state(dp, port_no, add_del):
            return
        try:
            remote_dpid = self.tunnels.get_remote_dpid(dpid, port_no)
        except ryu_exc.PortNotFound:
            return

        self.send_event_to_observers(self.EventTunnelPort(dpid, port_no,
                                     remote_dpid, add_del))

    # VM port
    # of connection: self.dpids by (dpid, port_no)
    #    datapath: connected: EventDP event
    #    port status: UP: Port add/delete/modify event
    # network_id: self.nw by (dpid, port_no): network port add/del event
    # mac_address: self.nw by (dpid, port_no): mac address add/del event
    # tunnel key: from self.tunnels by network_id: tunnel key add/del event
    def _vm_port_handler(self, dpid, port_no,
                         network_id, mac_address, add_del):
        if network_id in RESERVED_NETWORK_IDS:
            return
        if mac_address is None:
            return
        dp = self.dpset.get(dpid)
        if dp is None:
            return
        if _is_reserved_port(dp.ofproto, port_no):
            return
        if not self._check_link_state(dp, port_no, add_del):
            return
        try:
            tunnel_key = self.tunnels.get_key(network_id)
        except tunnels.TunnelKeyNotFound:
            return

        self.send_event_to_observers(self.EventVMPort(network_id, tunnel_key,
                                     dpid, port_no, mac_address, add_del))

    def _vm_port_mac_handler(self, dpid, port_no, network_id, add_del):
        if network_id == NW_ID_VPORT_GRE:
            self._tunnel_port_handler(dpid, port_no, add_del)
            return

        try:
            mac_address = self.nw.get_mac(dpid, port_no)
        except ryu_exc.PortNotFound:
            return
        self._vm_port_handler(dpid, port_no, network_id, mac_address,
                              add_del)

    def _port_handler(self, dpid, port_no, add_del):
        """
        :type add_del: bool
        :param add_del: True for add, False for del
        """
        try:
            port = self.nw.get_port(dpid, port_no)
        except ryu_exc.PortNotFound:
            return

        if port.network_id is None:
            return

        if port.network_id == NW_ID_VPORT_GRE:
            self._tunnel_port_handler(dpid, port_no, add_del)
            return

        self._vm_port_handler(dpid, port_no, port.network_id,
                              port.mac_address, add_del)

    def _tunnel_key_del(self, tunnel_key):
        self.send_event_to_observers(self.EventTunnelKeyDel(tunnel_key))

    # nw: network del
    #           port add/del (vm/tunnel port)
    #           mac address add/del(only vm port)
    # tunnels: tunnel key add/del
    #          tunnel port add/del
    # dpset: eventdp
    #        port add/delete/modify

    @handler.set_ev_cls(network.EventNetworkDel)
    def network_del_handler(self, ev):
        network_id = ev.network_id
        if network_id in RESERVED_NETWORK_IDS:
            return
        try:
            tunnel_key = self.tunnels.get_key(network_id)
        except tunnels.TunnelKeyNotFound:
            return
        self._tunnel_key_del(tunnel_key)

    @handler.set_ev_cls(network.EventNetworkPort)
    def network_port_handler(self, ev):
        self._vm_port_mac_handler(ev.dpid, ev.port_no, ev.network_id,
                                  ev.add_del)

    @handler.set_ev_cls(network.EventMacAddress)
    def network_mac_address_handler(self, ev):
        self._vm_port_handler(ev.dpid, ev.port_no, ev.network_id,
                              ev.mac_address, ev.add_del)

    @handler.set_ev_cls(tunnels.EventTunnelKeyAdd)
    def tunnel_key_add_handler(self, ev):
        network_id = ev.network_id
        for (dpid, port_no) in self.nw.list_ports_noraise(network_id):
            self._vm_port_mac_handler(dpid, port_no, network_id, True)

    @handler.set_ev_cls(tunnels.EventTunnelKeyDel)
    def tunnel_key_del_handler(self, ev):
        network_id = ev.network_id
        for (dpid, port_no) in self.nw.list_ports_noraise(network_id):
            self._vm_port_mac_handler(dpid, port_no, network_id, False)
        if self.nw.has_network(network_id):
            self._tunnel_key_del(ev.tunnel_key)

    @handler.set_ev_cls(tunnels.EventTunnelPort)
    def tunnel_port_handler(self, ev):
        self._port_handler(ev.dpid, ev.port_no, ev.add_del)

    @handler.set_ev_cls(dpset.EventDP)
    def dp_handler(self, ev):
        self.send_event_to_observers(ev)
        enter_leave = ev.enter
        if not enter_leave:
            # TODO:XXX
            # What to do on datapath disconnection?
            self.logger.debug('dp disconnection ev:%s', ev)

        dpid = ev.dp.id
        ports = set(port.port_no for port in ev.ports)
        ports.update(port.port_no for port in self.nw.get_ports(dpid))
        for port_no in ports:
            self._port_handler(dpid, port_no, enter_leave)

    @handler.set_ev_cls(dpset.EventPortAdd)
    def port_add_handler(self, ev):
        self._port_handler(ev.dp.id, ev.port.port_no, True)

    @handler.set_ev_cls(dpset.EventPortDelete)
    def port_del_handler(self, ev):
        self._port_handler(ev.dp.id, ev.port.port_no, False)

    @handler.set_ev_cls(dpset.EventPortModify)
    def port_modify_handler(self, ev):
        # We don't know LINK status has been changed.
        # So VM/TUNNEL port event can be triggered many times.
        dp = ev.dp
        port = ev.port
        self._port_handler(dp.id, port.port_no,
                           not (port.state & dp.ofproto.OFPPS_LINK_DOWN))

    @handler.set_ev_cls(ofp_event.EventOFPPacketIn)
    def packet_in_handler(self, ev):
        # for debug
        self.send_event_to_observers(ev)


def cls_rule(in_port=None, tun_id=None, dl_src=None, dl_dst=None):
    """Convenience function to initialize nx_match.ClsRule()"""
    rule = nx_match.ClsRule()
    if in_port is not None:
        rule.set_in_port(in_port)
    if tun_id is not None:
        rule.set_tun_id(tun_id)
    if dl_src is not None:
        rule.set_dl_src(dl_src)
    if dl_dst is not None:
        rule.set_dl_dst(dl_dst)
    return rule


class GRETunnel(app_manager.RyuApp):
    """
    app for L2/L3 with gre tunneling

    PORTS
    VM-port: the port which is connected to VM instance
    TUNNEL-port: the ovs GRE vport

    TABLES: multi tables is used
    SRC_TABLE:
        This table is firstly used to match packets.
        by in_port, determine which port the packet comes VM-port or
        TUNNEL-port.
        If the packet came from VM-port, set tunnel id based on which network
        the VM belongs to, and send the packet to the tunnel out table.
        If the packet came from TUNNEL-port and its tunnel id is known to this
        switch, send the packet to local out table. Otherwise drop it.

    TUNNEL_OUT_TABLE:
        This table looks at tunnel id and dl_dst, send the packet to tunnel
        ports if necessary. And then, sends the packet to LOCAL_OUT_TABLE.
        By matching the packet with tunnel_id and dl_dst, determine which
        tunnel port the packet is send to.

    LOCAL_OUT_TABLE:
        This table looks at tunnel id and dl_dst, send the packet to local
        VM ports if necessary. Otherwise drop the packet.


    The packet from vm port traverses as
    SRC_TABLE -> TUNNEL_OUT_TABLE -> LOCAL_OUT_TABLE

    The packet from tunnel port traverses as
    SRC_TABLE -> LOCAL_OUT_TABLE


    The packet from vm port:
    SRC_TABLE
    match                       action
    in_port(VM) & dl_src        set_tunnel & goto TUNNEL_OUT_TABLE
    in_port(VM)                 drop                    (catch-all drop rule)

    in_port(TUNNEL) & tun_id    goto LOCAL_OUT_TABLE
    in_port(TUNNEL)             drop                    (catch-all drop rule)

    TUNNEL_OUT_TABLE
    match                       action
    tun_id & dl_dst             out tunnel port & goto LOCAL_OUT_TABLE
                                                        (unicast or broadcast)
    tun_id                      goto LOCAL_OUT_TABLE    (catch-all rule)

    LOCAL_OUT_TABLE
    tun_id & dl_dst             output(VM)              (unicast or broadcast)
    tun_id                      drop                    (catch-all drop rule)

    NOTE:
    adding/deleting flow entries should be done carefully in certain order
    such that packet in event should not be triggered.
    """
    _CONTEXTS = {
        'network': network.Network,
        'dpset': dpset.DPSet,
        'tunnels': tunnels.Tunnels,
    }

    DEFAULT_COOKIE = 0  # cookie isn't used. Just set 0

    # Tables
    SRC_TABLE = 0
    TUNNEL_OUT_TABLE = 1
    LOCAL_OUT_TABLE = 2
    FLOW_TABLES = [SRC_TABLE, TUNNEL_OUT_TABLE, LOCAL_OUT_TABLE]

    # Priorities. The only inequality is important.
    # '/ 2' is used just for easy looking instead of '- 1'.
    # 0x7ffff vs 0x4000
    TABLE_DEFAULT_PRPIRITY = 32768  # = ofproto.OFP_DEFAULT_PRIORITY

    # SRC_TABLE for VM-port
    SRC_PRI_MAC = TABLE_DEFAULT_PRPIRITY
    SRC_PRI_DROP = TABLE_DEFAULT_PRPIRITY / 2
    # SRC_TABLE for TUNNEL-port
    SRC_PRI_TUNNEL_PASS = TABLE_DEFAULT_PRPIRITY
    SRC_PRI_TUNNEL_DROP = TABLE_DEFAULT_PRPIRITY / 2

    # TUNNEL_OUT_TABLE
    TUNNEL_OUT_PRI_MAC = TABLE_DEFAULT_PRPIRITY
    TUNNEL_OUT_PRI_BROADCAST = TABLE_DEFAULT_PRPIRITY / 2
    TUNNEL_OUT_PRI_PASS = TABLE_DEFAULT_PRPIRITY / 4
    TUNNEL_OUT_PRI_DROP = TABLE_DEFAULT_PRPIRITY / 8

    # LOCAL_OUT_TABLE
    LOCAL_OUT_PRI_MAC = TABLE_DEFAULT_PRPIRITY
    LOCAL_OUT_PRI_BROADCAST = TABLE_DEFAULT_PRPIRITY / 2
    LOCAL_OUT_PRI_DROP = TABLE_DEFAULT_PRPIRITY / 4

    def __init__(self, *args, **kwargs):
        super(GRETunnel, self).__init__(*args, **kwargs)
        self.nw = kwargs['network']
        self.dpset = kwargs['dpset']
        self.tunnels = kwargs['tunnels']

        self.port_set = PortSet(**kwargs)
        map(lambda ev_cls: self.port_set.register_observer(ev_cls, self.name),
            [dpset.EventDP, PortSet.EventTunnelKeyDel, PortSet.EventVMPort,
             PortSet.EventTunnelPort, ofp_event.EventOFPPacketIn])

    # TODO: track active vm/tunnel ports

    @handler.set_ev_handler(dpset.EventDP)
    def dp_handler(self, ev):
        if not ev.enter:
            return

        # enable nicira extension
        # TODO:XXX error handling
        dp = ev.dp
        ofproto = dp.ofproto

        dp.send_nxt_set_flow_format(ofproto.NXFF_NXM)
        flow_mod_table_id = dp.ofproto_parser.NXTFlowModTableId(dp, 1)
        dp.send_msg(flow_mod_table_id)
        dp.send_barrier()

        # delete all flows in all tables
        # current controller.handlers takes care of only table = 0
        for table in self.FLOW_TABLES:
            rule = cls_rule()
            self.send_flow_del(dp, rule, table, ofproto.OFPFC_DELETE,
                               None, None)
        dp.send_barrier()

    @staticmethod
    def _make_command(table, command):
        return table << 8 | command

    def send_flow_mod(self, dp, rule, table, command, priority, actions):
        command = self._make_command(table, command)
        dp.send_flow_mod(rule=rule, cookie=self.DEFAULT_COOKIE,
                         command=command, idle_timeout=0,
                         hard_timeout=0, priority=priority, actions=actions)

    def send_flow_del(self, dp, rule, table, command, priority, out_port):
        command = self._make_command(table, command)
        dp.send_flow_mod(rule=rule, cookie=self.DEFAULT_COOKIE,
                         command=command, idle_timeout=0,
                         hard_timeout=0, priority=priority, out_port=out_port)

    def _list_tunnel_port(self, dp, remote_dpids):
        dpid = dp.id
        tunnel_ports = []
        for other_dpid in remote_dpids:
            if other_dpid == dpid:
                continue
            other_dp = self.dpset.get(other_dpid)
            if other_dp is None:
                continue
            try:
                port_no = self.tunnels.get_port(dpid, other_dpid)
            except ryu_exc.PortNotFound:
                continue
            if not self._link_is_up(dp, port_no):
                continue
            tunnel_ports.append(port_no)

        return tunnel_ports

    def _link_is_up(self, dp, port_no):
        return _link_is_up(self.dpset, dp, port_no)

    def _port_is_active(self, network_id, dp, nw_port):
        return (nw_port.network_id == network_id and
                nw_port.mac_address is not None and
                self._link_is_up(dp, nw_port.port_no))

    def _tunnel_port_with_mac(self, remote_dp, dpid, network_id, port_no,
                              mac_address):
        tunnel_ports = []
        ports = self.nw.get_ports_with_mac(network_id, mac_address).copy()
        ports.discard((dpid, port_no))
        assert len(ports) <= 1
        for port in ports:
            try:
                tunnel_port_no = self.tunnels.get_port(remote_dp.id, port.dpid)
            except ryu_exc.PortNotFound:
                pass
            else:
                if self._link_is_up(remote_dp, tunnel_port_no):
                    tunnel_ports.append(tunnel_port_no)

        assert len(tunnel_ports) <= 1
        return tunnel_ports

    def _vm_port_add(self, ev):
        dpid = ev.dpid
        dp = self.dpset.get(dpid)
        assert dp is not None
        ofproto = dp.ofproto
        ofproto_parser = dp.ofproto_parser
        mac_address = ev.mac_address
        network_id = ev.network_id
        tunnel_key = ev.tunnel_key
        remote_dpids = self.nw.get_dpids(network_id)
        remote_dpids.remove(dpid)

        # LOCAL_OUT_TABLE: unicast
        # live-migration: there can be two ports with same mac_address
        ports = self.nw.get_ports(dpid, network_id, mac_address)
        assert ev.port_no in [port.port_no for port in ports]
        rule = cls_rule(tun_id=tunnel_key, dl_dst=mac_address)
        actions = [ofproto_parser.OFPActionOutput(port.port_no)
                   for port in ports if self._link_is_up(dp, port.port_no)]
        self.send_flow_mod(dp, rule, self.LOCAL_OUT_TABLE, ofproto.OFPFC_ADD,
                           self.LOCAL_OUT_PRI_MAC, actions)

        # LOCAL_OUT_TABLE: broad cast
        rule = cls_rule(tun_id=tunnel_key, dl_dst=mac.BROADCAST)
        actions = []
        for port in self.nw.get_ports(dpid):
            if not self._port_is_active(network_id, dp, port):
                continue
            actions.append(ofproto_parser.OFPActionOutput(port.port_no))

        first_instance = (len(actions) == 1)
        assert actions
        if first_instance:
            command = ofproto.OFPFC_ADD
        else:
            command = ofproto.OFPFC_MODIFY_STRICT
        self.send_flow_mod(dp, rule, self.LOCAL_OUT_TABLE, command,
                           self.LOCAL_OUT_PRI_BROADCAST, actions)

        # LOCAL_OUT_TABLE: multicast TODO:XXX

        # LOCAL_OUT_TABLE: catch-all drop
        if first_instance:
            rule = cls_rule(tun_id=tunnel_key)
            self.send_flow_mod(dp, rule, self.LOCAL_OUT_TABLE,
                               ofproto.OFPFC_ADD, self.LOCAL_OUT_PRI_DROP, [])

        # TUNNEL_OUT_TABLE: unicast
        mac_to_ports = collections.defaultdict(set)
        for remote_dpid in remote_dpids:
            remote_dp = self.dpset.get(remote_dpid)
            if remote_dp is None:
                continue
            try:
                tunnel_port_no = self.tunnels.get_port(dpid, remote_dpid)
            except ryu_exc.PortNotFound:
                continue
            if not self._link_is_up(dp, tunnel_port_no):
                continue

            for port in self.nw.get_ports(remote_dpid):
                if not self._port_is_active(network_id, remote_dp, port):
                    continue
                # TUNNEL_OUT_TABLE: unicast
                # live-migration: there can be more than one tunnel-ports that
                #                 have a given mac address
                mac_to_ports[port.mac_address].add(tunnel_port_no)

            if first_instance:
                # SRC_TABLE: TUNNEL-port: resubmit to LOAL_OUT_TABLE
                rule = cls_rule(in_port=tunnel_port_no, tun_id=tunnel_key)
                resubmit_table = ofproto_parser.NXActionResubmitTable(
                    in_port=ofproto.OFPP_IN_PORT, table=self.LOCAL_OUT_TABLE)
                actions = [resubmit_table]
                self.send_flow_mod(dp, rule, self.SRC_TABLE,
                                   ofproto.OFPFC_ADD, self.SRC_PRI_TUNNEL_PASS,
                                   actions)

        # TUNNEL_OUT_TABLE: unicast
        for remote_mac_address, tunnel_ports in mac_to_ports.items():
            rule = cls_rule(tun_id=tunnel_key, dl_dst=remote_mac_address)
            outputs = [ofproto_parser.OFPActionOutput(tunnel_port_no)
                       for tunnel_port_no in tunnel_ports]
            resubmit_table = ofproto_parser.NXActionResubmitTable(
                in_port=ofproto.OFPP_IN_PORT, table=self.LOCAL_OUT_TABLE)
            actions = outputs + [resubmit_table]
            self.send_flow_mod(dp, rule, self.TUNNEL_OUT_TABLE,
                               ofproto.OFPFC_ADD, self.TUNNEL_OUT_PRI_MAC,
                               actions)

        if first_instance:
            # TUNNEL_OUT_TABLE: catch-all(resubmit to LOCAL_OUT_TABLE)
            rule = cls_rule(tun_id=tunnel_key)
            resubmit_table = ofproto_parser.NXActionResubmitTable(
                in_port=ofproto.OFPP_IN_PORT, table=self.LOCAL_OUT_TABLE)
            actions = [resubmit_table]
            self.send_flow_mod(dp, rule, self.TUNNEL_OUT_TABLE,
                               ofproto.OFPFC_ADD,
                               self.TUNNEL_OUT_PRI_PASS, actions)

            # TUNNEL_OUT_TABLE: broadcast
            rule = cls_rule(tun_id=tunnel_key, dl_dst=mac.BROADCAST)
            actions = [ofproto_parser.OFPActionOutput(tunnel_port_no)
                       for tunnel_port_no
                       in self._list_tunnel_port(dp, remote_dpids)]
            resubmit_table = ofproto_parser.NXActionResubmitTable(
                in_port=ofproto.OFPP_IN_PORT, table=self.LOCAL_OUT_TABLE)
            actions.append(resubmit_table)
            self.send_flow_mod(dp, rule, self.TUNNEL_OUT_TABLE,
                               ofproto.OFPFC_ADD,
                               self.TUNNEL_OUT_PRI_BROADCAST, actions)

        # TUNNEL_OUT_TABLE: multicast TODO:XXX

        # SRC_TABLE: VM-port unicast
        dp.send_barrier()
        rule = cls_rule(in_port=ev.port_no, dl_src=mac_address)
        set_tunnel = ofproto_parser.NXActionSetTunnel(tunnel_key)
        resubmit_table = ofproto_parser.NXActionResubmitTable(
            in_port=ofproto.OFPP_IN_PORT, table=self.TUNNEL_OUT_TABLE)
        actions = [set_tunnel, resubmit_table]
        self.send_flow_mod(dp, rule, self.SRC_TABLE, ofproto.OFPFC_ADD,
                           self.SRC_PRI_MAC, actions)

        # SRC_TABLE: VM-port catch-call drop
        rule = cls_rule(in_port=ev.port_no)
        self.send_flow_mod(dp, rule, self.SRC_TABLE, ofproto.OFPFC_ADD,
                           self.SRC_PRI_DROP, [])

        # remote dp
        for remote_dpid in remote_dpids:
            remote_dp = self.dpset.get(remote_dpid)
            if remote_dp is None:
                continue
            try:
                tunnel_port_no = self.tunnels.get_port(remote_dpid, dpid)
            except ryu_exc.PortNotFound:
                continue
            if not self._link_is_up(remote_dp, tunnel_port_no):
                continue

            remote_ofproto = remote_dp.ofproto
            remote_ofproto_parser = remote_dp.ofproto_parser

            # TUNNEL_OUT_TABLE: unicast
            # live-migration: there can be another port that has
            # same mac address
            tunnel_ports = self._tunnel_port_with_mac(remote_dp, dpid,
                                                      network_id, ev.port_no,
                                                      mac_address)
            tunnel_ports.append(tunnel_port_no)

            rule = cls_rule(tun_id=ev.tunnel_key, dl_dst=mac_address)
            outputs = [remote_ofproto_parser.OFPActionOutput(port_no)
                       for port_no in tunnel_ports]
            resubmit_table = remote_ofproto_parser.NXActionResubmitTable(
                in_port=remote_ofproto.OFPP_IN_PORT,
                table=self.LOCAL_OUT_TABLE)
            actions = outputs + [resubmit_table]
            self.send_flow_mod(remote_dp, rule, self.TUNNEL_OUT_TABLE,
                               remote_ofproto.OFPFC_ADD,
                               self.TUNNEL_OUT_PRI_MAC, actions)

            if not first_instance:
                continue

            # SRC_TABLE: TUNNEL-port
            rule = cls_rule(in_port=tunnel_port_no, tun_id=ev.tunnel_key)
            resubmit_table = remote_ofproto_parser.NXActionResubmitTable(
                in_port=remote_ofproto.OFPP_IN_PORT,
                table=self.LOCAL_OUT_TABLE)
            actions = [resubmit_table]
            self.send_flow_mod(remote_dp, rule, self.SRC_TABLE,
                               remote_ofproto.OFPFC_ADD,
                               self.SRC_PRI_TUNNEL_PASS, actions)

            # TUNNEL_OUT_TABLE: broadcast
            rule = cls_rule(tun_id=ev.tunnel_key, dl_dst=mac.BROADCAST)
            tunnel_ports = self._list_tunnel_port(remote_dp, remote_dpids)
            if tunnel_port_no not in tunnel_ports:
                tunnel_ports.append(tunnel_port_no)
            actions = [remote_ofproto_parser.OFPActionOutput(port_no)
                       for port_no in tunnel_ports]
            if len(actions) == 1:
                command = remote_dp.ofproto.OFPFC_ADD
            else:
                command = remote_dp.ofproto.OFPFC_MODIFY_STRICT
            resubmit_table = remote_ofproto_parser.NXActionResubmitTable(
                in_port=remote_ofproto.OFPP_IN_PORT,
                table=self.LOCAL_OUT_TABLE)
            actions.append(resubmit_table)
            self.send_flow_mod(remote_dp, rule, self.TUNNEL_OUT_TABLE,
                               command, self.TUNNEL_OUT_PRI_BROADCAST, actions)

            # TUNNEL_OUT_TABLE: multicast TODO:XXX

    def _vm_port_del(self, ev):
        dpid = ev.dpid
        dp = self.dpset.get(dpid)
        assert dp is not None
        ofproto = dp.ofproto
        ofproto_parser = dp.ofproto_parser
        mac_address = ev.mac_address
        network_id = ev.network_id
        tunnel_key = ev.tunnel_key

        local_ports = []
        for port in self.nw.get_ports(dpid):
            if port.port_no == ev.port_no:
                continue
            if not self._port_is_active(network_id, dp, port):
                continue
            local_ports.append(port.port_no)

        last_instance = not local_ports

        # SRC_TABLE: VM-port unicast and catch-call
        rule = cls_rule(in_port=ev.port_no)
        self.send_flow_mod(dp, rule, self.SRC_TABLE, ofproto.OFPFC_DELETE,
                           ofproto.OFP_DEFAULT_PRIORITY,
                           [])  # priority is ignored

        if last_instance:
            # SRC_TABLE: TUNNEL-port: all tunnel matching
            rule = cls_rule(tun_id=tunnel_key)
            self.send_flow_mod(dp, rule, self.SRC_TABLE,
                               ofproto.OFPFC_DELETE,
                               ofproto.OFP_DEFAULT_PRIORITY,
                               [])  # priority is ignored

            # TUNNEL_OUT_TABLE: (tun_id & dl_dst) and tun_id
            rule = cls_rule(tun_id=tunnel_key)
            self.send_flow_mod(dp, rule, self.TUNNEL_OUT_TABLE,
                               ofproto.OFPFC_DELETE,
                               ofproto.OFP_DEFAULT_PRIORITY,
                               [])  # priority is ignored

            # LOCAL_OUT: tun_id catch-all drop rule
            rule = cls_rule(tun_id=tunnel_key)
            self.send_flow_mod(dp, rule, self.LOCAL_OUT_TABLE,
                               ofproto.OFPFC_DELETE,
                               ofproto.OFP_DEFAULT_PRIORITY,
                               [])  # priority is ignored
        else:
            # LOCAL_OUT_TABLE: unicast
            # live-migration: there can be two ports with same mac_address
            ports = self.nw.get_ports(dpid, network_id, mac_address)
            port_nos = [port.port_no for port in ports
                        if (port.port_no != ev.port_no and
                            self._link_is_up(dp, port.port_no))]
            rule = cls_rule(tun_id=tunnel_key, dl_dst=mac_address)
            if port_nos:
                assert len(ports) == 1
                actions = [ofproto_parser.OFPActionOutput(port_no)
                           for port_no in port_nos]
                self.send_flow_mod(dp, rule, self.LOCAL_OUT_TABLE,
                                   ofproto.OFPFC_MODIFY_STRICT,
                                   self.LOCAL_OUT_PRI_MAC, actions)
            else:
                self.send_flow_del(dp, rule, self.LOCAL_OUT_TABLE,
                                   ofproto.OFPFC_DELETE_STRICT,
                                   self.LOCAL_OUT_PRI_MAC, ev.port_no)

            # LOCAL_OUT_TABLE: broadcast
            rule = cls_rule(tun_id=tunnel_key, dl_dst=mac.BROADCAST)
            actions = [ofproto_parser.OFPActionOutput(port_no)
                       for port_no in local_ports]
            self.send_flow_mod(dp, rule, self.LOCAL_OUT_TABLE,
                               ofproto.OFPFC_MODIFY_STRICT,
                               self.LOCAL_OUT_PRI_BROADCAST, actions)

            # LOCAL_OUT_TABLE: multicast TODO:XXX

        # remote dp
        remote_dpids = self.nw.get_dpids(ev.network_id)
        if dpid in remote_dpids:
            remote_dpids.remove(dpid)
        for remote_dpid in remote_dpids:
            remote_dp = self.dpset.get(remote_dpid)
            if remote_dp is None:
                continue
            try:
                tunnel_port_no = self.tunnels.get_port(remote_dpid, dpid)
            except ryu_exc.PortNotFound:
                continue
            if not self._link_is_up(remote_dp, tunnel_port_no):
                continue

            remote_ofproto = remote_dp.ofproto
            remote_ofproto_parser = remote_dp.ofproto_parser

            if last_instance:
                # SRC_TABLE: TUNNEL-port
                rule = cls_rule(in_port=tunnel_port_no, tun_id=tunnel_key)
                self.send_flow_del(remote_dp, rule, self.SRC_TABLE,
                                   remote_ofproto.OFPFC_DELETE_STRICT,
                                   self.SRC_PRI_TUNNEL_PASS, None)

                # SRC_TABLE: TUNNEL-port catch-call drop rule
                rule = cls_rule(in_port=tunnel_port_no)
                self.send_flow_del(remote_dp, rule, self.SRC_TABLE,
                                   remote_ofproto.OFPFC_DELETE_STRICT,
                                   self.SRC_PRI_TUNNEL_DROP, None)

                # TUNNEL_OUT_TABLE: broadcast
                #                   tunnel_ports.remove(tunnel_port_no)
                rule = cls_rule(tun_id=tunnel_key, dl_dst=mac.BROADCAST)
                tunnel_ports = self._list_tunnel_port(remote_dp,
                                                      remote_dpids)
                assert tunnel_port_no not in tunnel_ports
                actions = [remote_ofproto_parser.OFPActionOutput(port_no)
                           for port_no in tunnel_ports]
                if not actions:
                    command = remote_dp.ofproto.OFPFC_DELETE_STRICT
                else:
                    command = remote_dp.ofproto.OFPFC_MODIFY_STRICT
                    resubmit_table = \
                        remote_ofproto_parser.NXActionResubmitTable(
                            in_port=remote_ofproto.OFPP_IN_PORT,
                            table=self.LOCAL_OUT_TABLE)
                    actions.append(resubmit_table)
                self.send_flow_mod(remote_dp, rule, self.TUNNEL_OUT_TABLE,
                                   command, self.TUNNEL_OUT_PRI_BROADCAST,
                                   actions)

            # TUNNEL_OUT_TABLE: unicast
            # live-migration: there can be more than one (dpid, port_no)
            #                 with a given mac address
            tunnel_ports = self._tunnel_port_with_mac(remote_dp, dpid,
                                                      network_id, ev.port_no,
                                                      mac_address)
            rule = cls_rule(tun_id=tunnel_key, dl_dst=mac_address)
            if tunnel_ports:
                outputs = [remote_ofproto_parser.OFPActionOutput(port_no)
                           for port_no in tunnel_ports]
                resubmit_table = remote_ofproto_parser.NXActionResubmitTable(
                    in_port=remote_ofproto.OFPP_IN_PORT,
                    table=self.LOCAL_OUT_TABLE)
                actions = outputs + [resubmit_table]
                self.send_flow_mod(remote_dp, rule, self.TUNNEL_OUT_TABLE,
                                   remote_ofproto.OFPFC_ADD,
                                   self.TUNNEL_OUT_PRI_MAC, actions)
            else:
                self.send_flow_del(remote_dp, rule, self.TUNNEL_OUT_TABLE,
                                   remote_ofproto.OFPFC_DELETE_STRICT,
                                   self.TUNNEL_OUT_PRI_MAC, tunnel_port_no)

            # TODO:XXX multicast

    def _get_vm_ports(self, dpid):
        ports = collections.defaultdict(list)
        for port in self.nw.get_ports(dpid):
            if port.network_id in RESERVED_NETWORK_IDS:
                continue
            ports[port.network_id].append(port)
        return ports

    def _tunnel_port_add(self, ev):
        dpid = ev.dpid
        dp = self.dpset.get(dpid)
        ofproto = dp.ofproto
        ofproto_parser = dp.ofproto_parser
        remote_dpid = ev.remote_dpid

        local_ports = self._get_vm_ports(dpid)
        remote_ports = self._get_vm_ports(remote_dpid)

        # SRC_TABLE: TUNNEL-port catch-call drop rule
        # ingress flow from this tunnel port: remote -> tunnel port
        #            drop if unknown tunnel_key
        rule = cls_rule(in_port=ev.port_no)
        self.send_flow_mod(dp, rule, self.SRC_TABLE, ofproto.OFPFC_ADD,
                           self.SRC_PRI_TUNNEL_DROP, [])

        # SRC_TABLE: TUNNEL-port: pass if known tunnel_key
        for network_id in local_ports:
            try:
                tunnel_key = self.tunnels.get_key(network_id)
            except tunnels.TunnelKeyNotFound:
                continue
            if network_id not in remote_ports:
                continue

            rule = cls_rule(in_port=ev.port_no, tun_id=tunnel_key)
            resubmit_table = ofproto_parser.NXActionResubmitTable(
                in_port=ofproto.OFPP_IN_PORT, table=self.LOCAL_OUT_TABLE)
            actions = [resubmit_table]
            self.send_flow_mod(dp, rule, self.SRC_TABLE, ofproto.OFPFC_ADD,
                               self.SRC_PRI_TUNNEL_PASS, actions)

        # egress flow into this tunnel port: vm port -> tunnel port -> remote
        for network_id in local_ports:
            try:
                tunnel_key = self.tunnels.get_key(network_id)
            except tunnels.TunnelKeyNotFound:
                continue
            ports = remote_ports.get(network_id)
            if ports is None:
                continue

            # TUNNEL_OUT_TABLE: unicast
            for port in ports:
                if port.mac_address is None:
                    continue
                rule = cls_rule(tun_id=tunnel_key, dl_dst=port.mac_address)
                output = ofproto_parser.OFPActionOutput(ev.port_no)
                resubmit_table = ofproto_parser.NXActionResubmitTable(
                    in_port=ofproto.OFPP_IN_PORT, table=self.LOCAL_OUT_TABLE)
                actions = [output, resubmit_table]
                self.send_flow_mod(dp, rule, self.TUNNEL_OUT_TABLE,
                                   ofproto.OFPFC_ADD, self.TUNNEL_OUT_PRI_MAC,
                                   actions)

            # TUNNEL_OUT_TABLE: broadcast
            remote_dpids = self.nw.get_dpids(network_id)
            remote_dpids.remove(dpid)

            rule = cls_rule(tun_id=tunnel_key, dl_dst=mac.BROADCAST)
            tunnel_ports = self._list_tunnel_port(dp, remote_dpids)
            if ev.port_no not in tunnel_ports:
                tunnel_ports.append(ev.port_no)
            actions = [ofproto_parser.OFPActionOutput(port_no)
                       for port_no in tunnel_ports]
            resubmit_table = ofproto_parser.NXActionResubmitTable(
                in_port=ofproto.OFPP_IN_PORT, table=self.LOCAL_OUT_TABLE)
            actions.append(resubmit_table)
            if len(tunnel_ports) == 1:
                command = ofproto.OFPFC_ADD
            else:
                command = ofproto.OFPFC_MODIFY_STRICT
            self.send_flow_mod(dp, rule, self.TUNNEL_OUT_TABLE,
                               command, self.TUNNEL_OUT_PRI_BROADCAST, actions)

            # TUNNEL_OUT_TABLE: multicast TODO:XXX

    def _tunnel_port_del(self, ev):
        # almost nothing to do because all flow related to this tunnel port
        # should be handled by self._vm_port_del() as tunnel port deletion
        # follows vm port deletion.
        # the tunnel port is deleted if and only if no instance of same
        # tenants resides in both nodes of tunnel end points.
        self.logger.debug('tunnel_port_del %s', ev)
        dp = self.dpset.get(ev.dpid)

        # SRC_TABLE: TUNNEL-port catch-all drop rule
        rule = cls_rule(in_port=ev.port_no)
        self.send_flow_mod(dp, rule, self.SRC_TABLE,
                           dp.ofproto.OFPFC_DELETE_STRICT,
                           self.SRC_PRI_TUNNEL_DROP, [])

    @handler.set_ev_handler(PortSet.EventTunnelKeyDel)
    def tunnel_key_del_handler(self, ev):
        self.logger.debug('tunnel_key_del ev %s', ev)

    @handler.set_ev_handler(PortSet.EventVMPort)
    def vm_port_handler(self, ev):
        self.logger.debug('vm_port ev %s', ev)
        if ev.add_del:
            self._vm_port_add(ev)
        else:
            self._vm_port_del(ev)

    @handler.set_ev_handler(PortSet.EventTunnelPort)
    def tunnel_port_handler(self, ev):
        self.logger.debug('tunnel_port ev %s', ev)
        if ev.add_del:
            self._tunnel_port_add(ev)
        else:
            self._tunnel_port_del(ev)

    @handler.set_ev_handler(ofp_event.EventOFPPacketIn)
    def packet_in_handler(self, ev):
        # for debug
        msg = ev.msg
        self.logger.debug('packet in ev %s msg %s', ev, ev.msg)
        if msg.buffer_id != msg.datapath.ofproto.OFP_NO_BUFFER:
            msg.datapath.send_packet_out(msg.buffer_id, msg.in_port, [])

########NEW FILE########
__FILENAME__ = ofctl_rest
# Copyright (C) 2012 Nippon Telegraph and Telephone Corporation.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import logging

import json
from webob import Response

from ryu.base import app_manager
from ryu.controller import ofp_event
from ryu.controller import dpset
from ryu.controller.handler import MAIN_DISPATCHER
from ryu.controller.handler import set_ev_cls
from ryu.ofproto import ofproto_v1_0
from ryu.ofproto import ofproto_v1_3
from ryu.lib import ofctl_v1_0
from ryu.lib import ofctl_v1_3
from ryu.app.wsgi import ControllerBase, WSGIApplication


LOG = logging.getLogger('ryu.app.ofctl_rest')

# REST API
#
## Retrieve the switch stats
#
# get the list of all switches
# GET /stats/switches
#
# get the desc stats of the switch
# GET /stats/desc/<dpid>
#
# get flows stats of the switch
# GET /stats/flow/<dpid>
#
# get ports stats of the switch
# GET /stats/port/<dpid>
#
## Update the switch stats
#
# add a flow entry
# POST /stats/flowentry/add
#
# modify all matching flow entries
# POST /stats/flowentry/modify
#
# delete all matching flow entries
# POST /stats/flowentry/delete
#
# delete all flow entries of the switch
# DELETE /stats/flowentry/clear/<dpid>
#


class StatsController(ControllerBase):
    def __init__(self, req, link, data, **config):
        super(StatsController, self).__init__(req, link, data, **config)
        self.dpset = data['dpset']
        self.waiters = data['waiters']

    def get_dpids(self, req, **_kwargs):
        dps = self.dpset.dps.keys()
        body = json.dumps(dps)
        return (Response(content_type='application/json', body=body))

    def get_desc_stats(self, req, dpid, **_kwargs):
        dp = self.dpset.get(int(dpid))
        if dp is None:
            return Response(status=404)

        if dp.ofproto.OFP_VERSION == ofproto_v1_0.OFP_VERSION:
            desc = ofctl_v1_0.get_desc_stats(dp, self.waiters)
        elif dp.ofproto.OFP_VERSION == ofproto_v1_3.OFP_VERSION:
            desc = ofctl_v1_3.get_desc_stats(dp, self.waiters)
        else:
            LOG.debug('Unsupported OF protocol')
            return Response(status=501)

        body = json.dumps(desc)
        return (Response(content_type='application/json', body=body))

    def get_flow_stats(self, req, dpid, **_kwargs):
        dp = self.dpset.get(int(dpid))
        if dp is None:
            return Response(status=404)

        if dp.ofproto.OFP_VERSION == ofproto_v1_0.OFP_VERSION:
            flows = ofctl_v1_0.get_flow_stats(dp, self.waiters)
        elif dp.ofproto.OFP_VERSION == ofproto_v1_3.OFP_VERSION:
            flows = ofctl_v1_3.get_flow_stats(dp, self.waiters)
        else:
            LOG.debug('Unsupported OF protocol')
            return Response(status=501)

        body = json.dumps(flows)
        return (Response(content_type='application/json', body=body))

    def get_port_stats(self, req, dpid, **_kwargs):
        dp = self.dpset.get(int(dpid))
        if dp is None:
            return Response(status=404)

        if dp.ofproto.OFP_VERSION == ofproto_v1_0.OFP_VERSION:
            ports = ofctl_v1_0.get_port_stats(dp, self.waiters)
        elif dp.ofproto.OFP_VERSION == ofproto_v1_3.OFP_VERSION:
            ports = ofctl_v1_3.get_port_stats(dp, self.waiters)
        else:
            LOG.debug('Unsupported OF protocol')
            return Response(status=501)

        body = json.dumps(ports)
        return (Response(content_type='application/json', body=body))

    def mod_flow_entry(self, req, cmd, **_kwargs):
        try:
            flow = eval(req.body)
        except SyntaxError:
            LOG.debug('invalid syntax %s', req.body)
            return Response(status=400)

        dpid = flow.get('dpid')
        dp = self.dpset.get(int(dpid))
        if dp is None:
            return Response(status=404)

        if cmd == 'add':
            cmd = dp.ofproto.OFPFC_ADD
        elif cmd == 'modify':
            cmd = dp.ofproto.OFPFC_MODIFY
        elif cmd == 'delete':
            cmd = dp.ofproto.OFPFC_DELETE
        else:
            return Response(status=404)

        if dp.ofproto.OFP_VERSION == ofproto_v1_0.OFP_VERSION:
            ofctl_v1_0.mod_flow_entry(dp, flow, cmd)
        elif dp.ofproto.OFP_VERSION == ofproto_v1_3.OFP_VERSION:
            ofctl_v1_3.mod_flow_entry(dp, flow, cmd)
        else:
            LOG.debug('Unsupported OF protocol')
            return Response(status=501)

        return Response(status=200)

    def delete_flow_entry(self, req, dpid, **_kwargs):
        dp = self.dpset.get(int(dpid))
        if dp is None:
            return Response(status=404)

        if dp.ofproto.OFP_VERSION == ofproto_v1_0.OFP_VERSION:
            ofctl_v1_0.delete_flow_entry(dp)
        elif dp.ofproto.OFP_VERSION == ofproto_v1_3.OFP_VERSION:
            ofctl_v1_3.mod_flow_entry(dp, {}, dp.ofproto.OFPFC_DELETE)
        else:
            LOG.debug('Unsupported OF protocol')
            return Response(status=501)

        return Response(status=200)


class RestStatsApi(app_manager.RyuApp):
    OFP_VERSIONS = [ofproto_v1_0.OFP_VERSION,
                    ofproto_v1_3.OFP_VERSION]
    _CONTEXTS = {
        'dpset': dpset.DPSet,
        'wsgi': WSGIApplication
    }

    def __init__(self, *args, **kwargs):
        super(RestStatsApi, self).__init__(*args, **kwargs)
        self.dpset = kwargs['dpset']
        wsgi = kwargs['wsgi']
        self.waiters = {}
        self.data = {}
        self.data['dpset'] = self.dpset
        self.data['waiters'] = self.waiters
        mapper = wsgi.mapper

        wsgi.registory['StatsController'] = self.data
        path = '/stats'
        uri = path + '/switches'
        mapper.connect('stats', uri,
                       controller=StatsController, action='get_dpids',
                       conditions=dict(method=['GET']))

        uri = path + '/desc/{dpid}'
        mapper.connect('stats', uri,
                       controller=StatsController, action='get_desc_stats',
                       conditions=dict(method=['GET']))

        uri = path + '/flow/{dpid}'
        mapper.connect('stats', uri,
                       controller=StatsController, action='get_flow_stats',
                       conditions=dict(method=['GET']))

        uri = path + '/port/{dpid}'
        mapper.connect('stats', uri,
                       controller=StatsController, action='get_port_stats',
                       conditions=dict(method=['GET']))

        uri = path + '/flowentry/{cmd}'
        mapper.connect('stats', uri,
                       controller=StatsController, action='mod_flow_entry',
                       conditions=dict(method=['POST']))

        uri = path + '/flowentry/clear/{dpid}'
        mapper.connect('stats', uri,
                       controller=StatsController, action='delete_flow_entry',
                       conditions=dict(method=['DELETE']))

    def stats_reply_handler(self, ev):
        msg = ev.msg
        dp = msg.datapath

        if dp.id not in self.waiters:
            return
        if msg.xid not in self.waiters[dp.id]:
            return
        lock, msgs = self.waiters[dp.id][msg.xid]
        msgs.append(msg)

        flags = 0
        if dp.ofproto.OFP_VERSION == ofproto_v1_0.OFP_VERSION:
            flags = dp.ofproto.OFPSF_REPLY_MORE
        elif dp.ofproto.OFP_VERSION == ofproto_v1_3.OFP_VERSION:
            flags = dp.ofproto.OFPMPF_REPLY_MORE

        if msg.flags & flags:
            return
        del self.waiters[dp.id][msg.xid]
        lock.set()

    @set_ev_cls(ofp_event.EventOFPDescStatsReply, MAIN_DISPATCHER)
    def desc_stats_reply_handler(self, ev):
        self.stats_reply_handler(ev)

    @set_ev_cls(ofp_event.EventOFPFlowStatsReply, MAIN_DISPATCHER)
    def flow_stats_reply_handler(self, ev):
        self.stats_reply_handler(ev)

    @set_ev_cls(ofp_event.EventOFPPortStatsReply, MAIN_DISPATCHER)
    def port_stats_reply_handler(self, ev):
        self.stats_reply_handler(ev)

########NEW FILE########
__FILENAME__ = quantum_adapter
# Copyright (C) 2012 Nippon Telegraph and Telephone Corporation.
# Copyright (C) 2012 Isaku Yamahata <yamahata at private email ne jp>
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import traceback
from oslo.config import cfg

try:
    from neutronclient import client as q_client
    from neutronclient.common import exceptions as q_exc
    from neutronclient.common.exceptions import (NeutronClientException as
                                                 client_exc)
    from neutronclient.v2_0 import client as q_clientv2
except ImportError:
    from quantumclient import client as q_client
    from quantumclient.common import exceptions as q_exc
    from quantumclient.common.exceptions import (QuantumClientException as
                                                 client_exc)
    from quantumclient.v2_0 import client as q_clientv2

from ryu.app import conf_switch_key as cs_key
from ryu.app import rest_nw_id
from ryu.base import app_manager
from ryu.controller import (conf_switch,
                            dpset,
                            handler,
                            network)
from ryu import exception as ryu_exc
from ryu.lib import dpid as dpid_lib
from ryu.lib import mac as mac_lib
from ryu.lib import quantum_ifaces
from ryu.lib.ovs import bridge
from ryu.lib.quantum_ifaces import QuantumIfaces


CONF = cfg.CONF


def _get_auth_token(logger):
    httpclient = q_client.HTTPClient(
        username=CONF.neutron_admin_username,
        tenant_name=CONF.neutron_admin_tenant_name,
        password=CONF.neutron_admin_password,
        auth_url=CONF.neutron_admin_auth_url,
        timeout=CONF.neutron_url_timeout,
        auth_strategy=CONF.neutron_auth_strategy)
    try:
        httpclient.authenticate()
    except (q_exc.Unauthorized, q_exc.Forbidden, q_exc.EndpointNotFound) as e:
        logger.error("authentication failure: %s", e)
        return None
    # logger.debug("_get_auth_token: token=%s", httpclient.auth_token)
    return httpclient.auth_token


def _get_quantum_client(token):
    if token:
        my_client = q_clientv2.Client(
            endpoint_url=CONF.neutron_url,
            token=token, timeout=CONF.neutron_url_timeout)
    else:
        my_client = q_clientv2.Client(
            endpoint_url=CONF.neutron_url,
            auth_strategy=None, timeout=CONF.neutron_url_timeout)
    return my_client


class OVSPort(object):
    PORT_ERROR = -1
    PORT_UNKNOWN = 0
    PORT_GATEWAY = 1
    PORT_VETH_GATEWAY = 2
    PORT_GUEST = 3
    PORT_TUNNEL = 4

    # extra-ids: 'attached-mac', 'iface-id', 'iface-status', 'vm-uuid'
    def __init__(self, ofport, port_name):
        super(OVSPort, self).__init__()
        self.ofport = ofport
        self.name = port_name
        self.type = None
        self.ext_ids = {}
        self.options = {}

    def update(self, port):
        self.__dict__.update((key, port[key]) for key
                             in ['name', 'ofport', 'type']
                             if key in port)
        if 'external_ids' in port:
            self.ext_ids = dict(port['external_ids'])
        if 'options' in port:
            self.options = dict(port['options'])

    def get_port_type(self):
        if not isinstance(self.ofport, int):
            return self.PORT_ERROR
        if self.type == 'internal' and 'iface-id' in self.ext_ids:
            return self.PORT_GATEWAY
        if self.type == '' and 'iface-id' in self.ext_ids:
            return self.PORT_VETH_GATEWAY
        if (self.type == 'gre' and 'local_ip' in self.options and
                'remote_ip' in self.options):
            return self.PORT_TUNNEL
        if self.type == '' and 'vm-uuid' in self.ext_ids:
            return self.PORT_GUEST
        return self.PORT_UNKNOWN

    def __str__(self):
        return "type=%s ofport=%s name=%s, ext_ids=%s options=%s" % (
            self.type, self.ofport, self.name, self.ext_ids, self.options)

    def __eq__(self, other):
        return (other is not None and
                self.ofport == other.ofport and
                self.type == other.type and
                self.ext_ids == other.ext_ids and
                self.options == other.options)


class OVSSwitch(object):
    def __init__(self, dpid, nw, ifaces, logger):
        # TODO: clean up
        self.dpid = dpid
        self.network_api = nw
        self.ifaces = ifaces
        self.logger = logger
        self._q_api = None      # lazy initialization
        self.ctrl_addr = CONF.neutron_controller_addr
        if not self.ctrl_addr:
            raise ValueError('option neutron_controler_addr must be speicfied')

        self.ovsdb_addr = None
        self.tunnel_ip = None

        self.ovs_bridge = None
        self.ports = {}  # port_no -> OVSPort

        super(OVSSwitch, self).__init__()

    @property
    def q_api(self):
        if self._q_api is None:
            token = None
            if CONF.neutron_auth_strategy:
                token = _get_auth_token(self.logger)
            self._q_api = _get_quantum_client(token)
        return self._q_api

    def set_ovsdb_addr(self, dpid, ovsdb_addr):
        # easy check if the address format valid
        self.logger.debug('set_ovsdb_addr dpid %s ovsdb_addr %s',
                          dpid_lib.dpid_to_str(dpid), ovsdb_addr)
        _proto, _host, _port = ovsdb_addr.split(':')

        old_address = self.ovsdb_addr
        if old_address == ovsdb_addr:
            return
        if ovsdb_addr is None:
            # TODO: clean up this ovs switch
            if self.ovs_bridge:
                self.ovs_bridge.del_controller()
                self.ovs_bridge = None
            return
        self.ovsdb_addr = ovsdb_addr
        if self.ovs_bridge is None:
            self.logger.debug('ovsdb: adding ports %s', self.ports)
            ovs_bridge = bridge.OVSBridge(dpid, ovsdb_addr)
            self.ovs_bridge = ovs_bridge
            ovs_bridge.init()
            # TODO: for multi-controller
            #       not overwrite controllers, but append this controller
            ovs_bridge.set_controller([self.ctrl_addr])
            for port in self.ports.values():
                self.logger.debug('adding port %s', port)
                self.update_port(port.ofport, port.name, True)

    def _update_external_port(self, port, add=True):
        if add:
            self.network_api.update_port(rest_nw_id.NW_ID_EXTERNAL,
                                         self.dpid, port.ofport)
        else:
            self.network_api.remove_port(rest_nw_id.NW_ID_EXTERNAL,
                                         self.dpid, port.ofport)

    def _update_vif_port(self, port, add=True):
        # When ovs port is updated, the corresponding network id may or
        # may not exist because the order between the notification of
        # ovs port deletion via OVSDB protocol and the notification
        # network id/port deletion via REST from quantum plugin
        # isn't deterministic.
        self.logger.debug("_update_vif_port: %s %s", port, add)
        iface_id = port.ext_ids.get('iface-id')
        if iface_id is None:
            return
        try:
            network_id = self.ifaces.get_key(iface_id,
                                             QuantumIfaces.KEY_NETWORK_ID)
        except KeyError:
            return

        if not add:
            try:
                self.network_api.remove_port(network_id,
                                             self.dpid, port.ofport)
            except (network.NetworkNotFound, ryu_exc.PortNotFound) as e:
                self.logger.debug('remove_port %s', traceback.format_exc())
            ports = self.ifaces.get_key(iface_id, QuantumIfaces.KEY_PORTS)
            other_ovs_ports = None
            for p in ports:
                dpid = p.get(QuantumIfaces.SUBKEY_DATAPATH_ID)
                if dpid is None:
                    continue
                if dpid != self.dpid:
                    continue

                other_ovs_ports = self.ifaces.del_key(iface_id,
                                                      QuantumIfaces.KEY_PORTS,
                                                      p)
            if other_ovs_ports:
                # When live-migration, one of the two OVS ports is deleted.
                return

            port_data = {
                'status': 'DOWN'
            }
            body = {'port': port_data}
            # self.logger.debug("port-body = %s", body)

            try:
                self.q_api.update_port(port.ext_ids['iface-id'], body)
            except (q_exc.ConnectionFailed, client_exc) as e:
                self.logger.error("quantum update port failed: %s", e)
                # TODO: When authentication failure occurred,
                # it should get auth token again
            return

        # update {network, port, mac}
        try:
            self.network_api.update_network(network_id)
            self.network_api.update_port(network_id, self.dpid, port.ofport)
            mac = port.ext_ids.get('attached-mac')
            if mac:
                self.network_api.update_mac(network_id, self.dpid, port.ofport,
                                            mac_lib.haddr_to_bin(mac))
        except (network.NetworkNotFound, ryu_exc.PortNotFound) as e:
            self.logger.debug('update network/port/mac %s',
                              traceback.format_exc())

    def update_port(self, port_no, port_name, add):
        self.logger.debug('update_port port_no %d %s %s', port_no, port_name,
                          add)
        assert port_name is not None
        old_port = self.ports.get(port_no)
        if not add:
            new_port = None
            self.ports.pop(port_no, None)
        else:
            new_port = OVSPort(port_no, port_name)
            if self.ovs_bridge:
                port_cfg = self.ovs_bridge.get_quantum_ports(port_name)
                if port_cfg:
                    if 'ofport' not in port_cfg or not port_cfg['ofport']:
                        port_cfg['ofport'] = port_no
                    elif port_cfg['ofport'] != port_no:
                        self.logger.warn('inconsistent port_no: %d port_cfg '
                                         '%s', port_no, port_cfg)
                        return
                    if port_cfg['name'] != port_name:
                        self.logger.warn('inconsistent port_name: %s '
                                         'port_cfg %s', port_name, port_cfg)
                        return
                    new_port.update(port_cfg)

            self.ports[port_no] = new_port
            iface_id = new_port.ext_ids.get('iface-id')
            if iface_id:
                p = {QuantumIfaces.SUBKEY_DATAPATH_ID: self.dpid,
                     QuantumIfaces.SUBKEY_OFPORT: port_no,
                     QuantumIfaces.SUBKEY_NAME: port_name}
                self.ifaces.update_key(iface_id, QuantumIfaces.KEY_PORTS, p)

        if old_port == new_port:
            return

        if not new_port:
            port_type = old_port.get_port_type()
            if port_type == OVSPort.PORT_ERROR:
                return
            elif port_type == OVSPort.PORT_UNKNOWN:
                # self.logger.info("delete external port: %s", old_port)
                self._update_external_port(old_port, add=False)
            else:
                # self.logger.info("delete port: %s", old_port)
                if port_type != OVSPort.PORT_TUNNEL:
                    self._update_vif_port(old_port, add=False)
            return

        if new_port.ofport == -1:
            return
        if not old_port or old_port.ofport == -1:
            port_type = new_port.get_port_type()
            if port_type == OVSPort.PORT_ERROR:
                return
            elif port_type == OVSPort.PORT_UNKNOWN:
                # self.logger.info("create external port: %s", new_port)
                self._update_external_port(new_port)
            else:
                # self.logger.info("create port: %s", new_port)
                if port_type != OVSPort.PORT_TUNNEL:
                    self._update_vif_port(new_port)
            return
        if new_port.get_port_type() in (OVSPort.PORT_GUEST,
                                        OVSPort.PORT_GATEWAY,
                                        OVSPort.PORT_VETH_GATEWAY):
            # self.logger.info("update port: %s", new_port)
            self._update_vif_port(new_port)


class QuantumAdapter(app_manager.RyuApp):
    _CONTEXTS = {
        'conf_switch': conf_switch.ConfSwitchSet,
        'network': network.Network,
        'quantum_ifaces': quantum_ifaces.QuantumIfaces,
    }

    def __init__(self, *_args, **kwargs):
        super(QuantumAdapter, self).__init__()

        self.cs = kwargs['conf_switch']
        self.nw = kwargs['network']
        self.ifaces = kwargs['quantum_ifaces']
        self.dps = {}

        for network_id in rest_nw_id.RESERVED_NETWORK_IDS:
            if network_id == rest_nw_id.NW_ID_UNKNOWN:
                continue
            self.nw.update_network(network_id)

    def _get_ovs_switch(self, dpid, create=True):
        ovs_switch = self.dps.get(dpid)
        if not ovs_switch:
            if create:
                ovs_switch = OVSSwitch(dpid, self.nw, self.ifaces, self.logger)
                self.dps[dpid] = ovs_switch
        else:
            self.logger.debug('ovs switch %s is already known', dpid)
        return ovs_switch

    def _port_handler(self, dpid, port_no, port_name, add):
        ovs_switch = self._get_ovs_switch(dpid)
        if ovs_switch:
            ovs_switch.update_port(port_no, port_name, add)
        else:
            self.logger.warn('unknown ovs switch %s %s %s %s\n',
                             dpid, port_no, port_name, add)

    @handler.set_ev_cls(dpset.EventDP)
    def dp_handler(self, ev):
        dpid = ev.dp.id
        ovs_switch = self._get_ovs_switch(dpid)
        if not ovs_switch:
            return

        if ev.enter:
            for port in ev.ports:
                ovs_switch.update_port(port.port_no, port.name, True)
        else:
            # When dp leaving, we don't delete ports because OF connection
            # can be disconnected for some reason.
            # TODO: configuration needed to tell that this dp is really
            # removed.
            self.dps.pop(dpid, None)

    @handler.set_ev_cls(dpset.EventPortAdd)
    def port_add_handler(self, ev):
        port = ev.port
        name = port.name.rstrip('\0')
        self._port_handler(ev.dp.id, port.port_no, name, True)

    @handler.set_ev_cls(dpset.EventPortDelete)
    def port_del_handler(self, ev):
        port = ev.port
        name = port.name.rstrip('\0')
        self._port_handler(ev.dp.id, port.port_no, name, False)

    def _conf_switch_set_ovsdb_addr(self, dpid, value):
        ovs_switch = self._get_ovs_switch(dpid)
        ovs_switch.set_ovsdb_addr(dpid, value)

    def _conf_switch_del_ovsdb_addr(self, dpid):
        ovs_switch = self._get_ovs_switch(dpid, False)
        if ovs_switch:
            ovs_switch.set_ovsdb_addr(dpid, None)

    @handler.set_ev_cls(conf_switch.EventConfSwitchSet)
    def conf_switch_set_handler(self, ev):
        self.logger.debug("conf_switch set: %s", ev)
        if ev.key == cs_key.OVSDB_ADDR:
            self._conf_switch_set_ovsdb_addr(ev.dpid, ev.value)
        else:
            self.logger.debug("unknown event: %s", ev)

    @handler.set_ev_cls(conf_switch.EventConfSwitchDel)
    def conf_switch_del_handler(self, ev):
        self.logger.debug("conf_switch del: %s", ev)
        if ev.key == cs_key.OVSDB_ADDR:
            self._conf_switch_del_ovsdb_addr(ev.dpid)
        else:
            self.logger.debug("unknown event: %s", ev)

    @handler.set_ev_cls(quantum_ifaces.EventQuantumIfaceSet)
    def quantum_iface_set_handler(self, ev):
        if ev.key != quantum_ifaces.QuantumIfaces.KEY_NETWORK_ID:
            # self.logger.debug("unknown key %s", ev.key)
            return
        iface_id = ev.iface_id
        try:
            ports = self.ifaces.get_key(iface_id, QuantumIfaces.KEY_PORTS)
        except KeyError:
            return
        for p in ports:
            try:
                dpid = p[QuantumIfaces.SUBKEY_DATAPATH_ID]
                ofport = p[QuantumIfaces.SUBKEY_OFPORT]
                port_name = p[QuantumIfaces.SUBKEY_NAME]
            except KeyError:
                continue
            ovs_switch = self._get_ovs_switch(dpid, False)
            if ovs_switch:
                ovs_switch.update_port(ofport, port_name, True)

########NEW FILE########
__FILENAME__ = rest
# Copyright (C) 2012 Nippon Telegraph and Telephone Corporation.
# Copyright (C) 2012 Isaku Yamahata <yamahata at private email ne jp>
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# This module provides a basic set of REST API.
#   - Network registration
#   - End-point port management
#       - OpenFlow port number
#       - MAC address (for anti-spoofing)
#
# Used by OpenStack Ryu plug-in.

import json
from webob import Response

from ryu.app import wsgi as app_wsgi
from ryu.app.wsgi import ControllerBase, WSGIApplication
from ryu.base import app_manager
from ryu.controller import network
from ryu.exception import NetworkNotFound, NetworkAlreadyExist
from ryu.exception import PortNotFound, PortAlreadyExist
from ryu.lib import dpid as dpid_lib
from ryu.lib import mac as mac_lib

## TODO:XXX
## define db interface and store those information into db

# REST API

# get the list of networks
# GET /v1.0/networks/
#
# register a new network.
# Fail if the network is already registered.
# POST /v1.0/networks/{network-id}
#
# update a new network.
# Success as nop even if the network is already registered.
#
# PUT /v1.0/networks/{network-id}
#
# remove a network
# DELETE /v1.0/networks/{network-id}
#
# get the list of sets of dpid and port
# GET /v1.0/networks/{network-id}/
#
# register a new set of dpid and port
# Fail if the port is already registered.
# POST /v1.0/networks/{network-id}/{dpid}_{port-id}
#
# update a new set of dpid and port
# Success as nop even if same port already registered
# PUT /v1.0/networks/{network-id}/{dpid}_{port-id}
#
# remove a set of dpid and port
# DELETE /v1.0/networks/{network-id}/{dpid}_{port-id}
#
# get the list of mac addresses of dpid and port
# GET /v1.0/networks/{network-id}/{dpid}_{port-id}/macs/
#
# register a new mac address for dpid and port
# Fail if mac address is already registered or the mac address is used
# for other ports of the same network-id
# POST /v1.0/networks/{network-id}/{dpid}_{port-id}/macs/{mac}
#
# update a new mac address for dpid and port
# Success as nop even if same mac address is already registered.
# For now, changing mac address is not allows as it fails.
# PUT /v1.0/networks/{network-id}/{dpid}_{port-id}/macs/{mac}
#
# For now DELETE /v1.0/networks/{network-id}/{dpid}_{port-id}/macs/{mac}
# is not supported. mac address is released when port is deleted.
#


class NetworkController(ControllerBase):
    def __init__(self, req, link, data, **config):
        super(NetworkController, self).__init__(req, link, data, **config)
        self.nw = data

    def create(self, req, network_id, **_kwargs):
        try:
            self.nw.create_network(network_id)
        except NetworkAlreadyExist:
            return Response(status=409)
        else:
            return Response(status=200)

    def update(self, req, network_id, **_kwargs):
        self.nw.update_network(network_id)
        return Response(status=200)

    def lists(self, req, **_kwargs):
        body = json.dumps(self.nw.list_networks())
        return Response(content_type='application/json', body=body)

    def delete(self, req, network_id, **_kwargs):
        try:
            self.nw.remove_network(network_id)
        except NetworkNotFound:
            return Response(status=404)

        return Response(status=200)


class PortController(ControllerBase):
    def __init__(self, req, link, data, **config):
        super(PortController, self).__init__(req, link, data, **config)
        self.nw = data

    def create(self, req, network_id, dpid, port_id, **_kwargs):
        dpid = dpid_lib.str_to_dpid(dpid)
        port_id = int(port_id)
        try:
            self.nw.create_port(network_id, dpid, port_id)
        except NetworkNotFound:
            return Response(status=404)
        except PortAlreadyExist:
            return Response(status=409)

        return Response(status=200)

    def update(self, req, network_id, dpid, port_id, **_kwargs):
        dpid = dpid_lib.str_to_dpid(dpid)
        port_id = int(port_id)
        try:
            self.nw.update_port(network_id, dpid, port_id)
        except NetworkNotFound:
            return Response(status=404)

        return Response(status=200)

    def lists(self, req, network_id, **_kwargs):
        try:
            body = json.dumps(self.nw.list_ports(network_id))
        except NetworkNotFound:
            return Response(status=404)

        return Response(content_type='application/json', body=body)

    def delete(self, req, network_id, dpid, port_id, **_kwargs):
        dpid = dpid_lib.str_to_dpid(dpid)
        port_id = int(port_id)
        try:
            self.nw.remove_port(network_id, dpid, port_id)
        except (NetworkNotFound, PortNotFound):
            return Response(status=404)

        return Response(status=200)


class MacController(ControllerBase):
    def __init__(self, req, link, data, **config):
        super(MacController, self).__init__(req, link, data, **config)
        self.nw = data

    def create(self, _req, network_id, dpid, port_id, mac_addr, **_kwargs):
        dpid = dpid_lib.str_to_dpid(dpid)
        port_id = int(port_id)
        mac_addr = mac_lib.haddr_to_bin(mac_addr)
        try:
            self.nw.create_mac(network_id, dpid, port_id, mac_addr)
        except PortNotFound:
            return Response(status=404)
        except network.MacAddressAlreadyExist:
            return Response(status=409)

        return Response(status=200)

    def update(self, _req, network_id, dpid, port_id, mac_addr, **_kwargs):
        dpid = dpid_lib.str_to_dpid(dpid)
        port_id = int(port_id)
        mac_addr = mac_lib.haddr_to_bin(mac_addr)
        try:
            self.nw.update_mac(network_id, dpid, port_id, mac_addr)
        except PortNotFound:
            return Response(status=404)

        return Response(status=200)

    def lists(self, _req, network_id, dpid, port_id, **_kwargs):
        dpid = dpid_lib.str_to_dpid(dpid)
        port_id = int(port_id)
        try:
            body = json.dumps([mac_lib.haddr_to_str(mac_addr) for mac_addr in
                               self.nw.list_mac(dpid, port_id)])
        except PortNotFound:
            return Response(status=404)

        return Response(content_type='application/json', body=body)


class RestAPI(app_manager.RyuApp):
    _CONTEXTS = {
        'network': network.Network,
        'wsgi': WSGIApplication
    }

    def __init__(self, *args, **kwargs):
        super(RestAPI, self).__init__(*args, **kwargs)
        self.nw = kwargs['network']
        wsgi = kwargs['wsgi']
        mapper = wsgi.mapper

        wsgi.registory['NetworkController'] = self.nw
        route_name = 'networks'
        uri = '/v1.0/networks'
        mapper.connect(route_name, uri,
                       controller=NetworkController, action='lists',
                       conditions=dict(method=['GET', 'HEAD']))

        uri += '/{network_id}'
        s = mapper.submapper(controller=NetworkController)
        s.connect(route_name, uri, action='create',
                  conditions=dict(method=['POST']))
        s.connect(route_name, uri, action='update',
                  conditions=dict(method=['PUT']))
        s.connect(route_name, uri, action='delete',
                  conditions=dict(method=['DELETE']))

        wsgi.registory['PortController'] = self.nw
        route_name = 'ports'
        mapper.connect(route_name, uri,
                       controller=PortController, action='lists',
                       conditions=dict(method=['GET']))

        uri += '/{dpid}_{port_id}'
        requirements = {'dpid': dpid_lib.DPID_PATTERN,
                        'port_id': app_wsgi.DIGIT_PATTERN}
        s = mapper.submapper(controller=PortController,
                             requirements=requirements)
        s.connect(route_name, uri, action='create',
                  conditions=dict(method=['POST']))
        s.connect(route_name, uri, action='update',
                  conditions=dict(method=['PUT']))
        s.connect(route_name, uri, action='delete',
                  conditions=dict(method=['DELETE']))

        wsgi.registory['MacController'] = self.nw
        route_name = 'macs'
        uri += '/macs'
        mapper.connect(route_name, uri,
                       controller=MacController, action='lists',
                       conditions=dict(method=['GET']),
                       requirements=requirements)

        uri += '/{mac_addr}'
        requirements['mac_addr'] = mac_lib.HADDR_PATTERN
        s = mapper.submapper(controller=MacController,
                             requirements=requirements)
        s.connect(route_name, uri, action='create',
                  conditions=dict(method=['POST']))
        s.connect(route_name, uri, action='update',
                  conditions=dict(method=['PUT']))

########NEW FILE########
__FILENAME__ = rest_conf_switch
# Copyright (C) 2012 Nippon Telegraph and Telephone Corporation.
# Copyright (C) 2012 Isaku Yamahata <yamahata at private email ne jp>
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# This module provides a set of REST API for switch configuration.
#   - Per-switch Key-Value store
#
# Used by OpenStack Ryu agent.

import httplib
import json
import logging
from webob import Response

from ryu.app.wsgi import ControllerBase
from ryu.base import app_manager
from ryu.controller import conf_switch
from ryu.lib import dpid as dpid_lib


# REST API for switch configuration
#
# get all the switches
# GET /v1.0/conf/switches
#
# get all the configuration keys of a switch
# GET /v1.0/conf/switches/<dpid>
#
# delete all the configuration of a switch
# DELETE /v1.0/conf/switches/<dpid>
#
# set the <key> configuration of a switch
# PUT /v1.0/conf/switches/<dpid>/<key>
#
# get the <key> configuration of a switch
# GET /v1.0/conf/switches/<dpid>/<key>
#
# delete the <key> configuration of a switch
# DELETE /v1.0/conf/switches/<dpid>/<key>
#
# where
# <dpid>: datapath id in 16 hex


class ConfSwitchController(ControllerBase):
    def __init__(self, req, link, data, **config):
        super(ConfSwitchController, self).__init__(req, link, data, **config)
        self.conf_switch = data

    def list_switches(self, _req, **_kwargs):
        dpids = self.conf_switch.dpids()
        body = json.dumps([dpid_lib.dpid_to_str(dpid) for dpid in dpids])
        return Response(content_type='application/json', body=body)

    @staticmethod
    def _do_switch(dpid, func, ret_func):
        dpid = dpid_lib.str_to_dpid(dpid)
        try:
            ret = func(dpid)
        except KeyError:
            return Response(status=httplib.NOT_FOUND,
                            body='no dpid is found %s' %
                            dpid_lib.dpid_to_str(dpid))

        return ret_func(ret)

    def delete_switch(self, _req, dpid, **_kwargs):
        def _delete_switch(dpid):
            self.conf_switch.del_dpid(dpid)
            return None

        def _ret(_ret):
            return Response(status=httplib.ACCEPTED)

        return self._do_switch(dpid, _delete_switch, _ret)

    def list_keys(self, _req, dpid, **_kwargs):
        def _list_keys(dpid):
            return self.conf_switch.keys(dpid)

        def _ret(keys):
            body = json.dumps(keys)
            return Response(content_type='application/json', body=body)

        return self._do_switch(dpid, _list_keys, _ret)

    @staticmethod
    def _do_key(dpid, key, func, ret_func):
        dpid = dpid_lib.str_to_dpid(dpid)
        try:
            ret = func(dpid, key)
        except KeyError:
            return Response(status=httplib.NOT_FOUND,
                            body='no dpid/key is found %s %s' %
                            (dpid_lib.dpid_to_str(dpid), key))
        return ret_func(ret)

    def set_key(self, req, dpid, key, **_kwargs):
        def _set_val(dpid, key):
            val = json.loads(req.body)
            self.conf_switch.set_key(dpid, key, val)
            return None

        def _ret(_ret):
            return Response(status=httplib.CREATED)

        return self._do_key(dpid, key, _set_val, _ret)

    def get_key(self, _req, dpid, key, **_kwargs):
        def _get_key(dpid, key):
            return self.conf_switch.get_key(dpid, key)

        def _ret(val):
            return Response(content_type='application/json',
                            body=json.dumps(val))

        return self._do_key(dpid, key, _get_key, _ret)

    def delete_key(self, _req, dpid, key, **_kwargs):
        def _delete_key(dpid, key):
            self.conf_switch.del_key(dpid, key)
            return None

        def _ret(_ret):
            return Response()

        return self._do_key(dpid, key, _delete_key, _ret)


class ConfSwitchAPI(app_manager.RyuApp):
    _CONTEXTS = {
        'conf_switch': conf_switch.ConfSwitchSet,
    }

    def __init__(self, *args, **kwargs):
        super(ConfSwitchAPI, self).__init__(*args, **kwargs)
        self.conf_switch = kwargs['conf_switch']
        wsgi = kwargs['wsgi']
        mapper = wsgi.mapper

        controller = ConfSwitchController
        wsgi.registory[controller.__name__] = self.conf_switch
        route_name = 'conf_switch'
        uri = '/v1.0/conf/switches'
        mapper.connect(route_name, uri, controller=controller,
                       action='list_switches',
                       conditions=dict(method=['GET']))

        uri += '/{dpid}'
        requirements = {'dpid': dpid_lib.DPID_PATTERN}
        s = mapper.submapper(controller=controller, requirements=requirements)
        s.connect(route_name, uri, action='delete_switch',
                  conditions=dict(method=['DELETE']))
        s.connect(route_name, uri, action='list_keys',
                  conditions=dict(method=['GET']))

        uri += '/{key}'
        s.connect(route_name, uri, action='set_key',
                  conditions=dict(method=['PUT']))
        s.connect(route_name, uri, action='get_key',
                  conditions=dict(method=['GET']))
        s.connect(route_name, uri, action='delete_key',
                  conditions=dict(method=['DELETE']))

########NEW FILE########
__FILENAME__ = rest_firewall
# Copyright (C) 2013 Nippon Telegraph and Telephone Corporation.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.


import logging
import json

from webob import Response

from ryu.app.wsgi import ControllerBase
from ryu.app.wsgi import WSGIApplication
from ryu.base import app_manager
from ryu.controller import ofp_event
from ryu.controller import dpset
from ryu.controller.handler import MAIN_DISPATCHER
from ryu.controller.handler import set_ev_cls
from ryu.exception import OFPUnknownVersion
from ryu.lib import mac
from ryu.lib import dpid as dpid_lib
from ryu.lib import ofctl_v1_0
from ryu.lib import ofctl_v1_2
from ryu.lib.packet import packet
from ryu.ofproto import ether
from ryu.ofproto import inet
from ryu.ofproto import ofproto_v1_0
from ryu.ofproto import ofproto_v1_2
from ryu.ofproto import ofproto_v1_2_parser


#=============================
#          REST API
#=============================
#
#  Note: specify switch and vlan group, as follows.
#   {switch-id} : 'all' or switchID
#   {vlan-id}   : 'all' or vlanID
#
#
## about Firewall status
#
# get status of all firewall switches
# GET /firewall/module/status
#
# set enable the firewall switches
# PUT /firewall/module/enable/{switch-id}
#
# set disable the firewall switches
# PUT /firewall/module/disable/{switch-id}
#
#
## about Firewall logs
#
# get log status of all firewall switches
# GET /firewall/log/status
#
# set log enable the firewall switches
# PUT /firewall/log/enable/{switch-id}
#
# set log disable the firewall switches
# PUT /firewall/log/disable/{switch-id}
#
#
## about Firewall rules
#
# get rules of the firewall switches
# * for no vlan
# GET /firewall/rules/{switch-id}
#
# * for specific vlan group
# GET /firewall/rules/{switch-id}/{vlan-id}
#
#
# set a rule to the firewall switches
# * for no vlan
# POST /firewall/rules/{switch-id}
#
# * for specific vlan group
# POST /firewall/rules/{switch-id}/{vlan-id}
#
#  request body format:
#   {"<field1>":"<value1>", "<field2>":"<value2>",...}
#
#     <field>  : <value>
#    "priority": "0 to 65533"
#    "in_port" : "<int>"
#    "dl_src"  : "<xx:xx:xx:xx:xx:xx>"
#    "dl_dst"  : "<xx:xx:xx:xx:xx:xx>"
#    "dl_type" : "<ARP or IPv4>"
#    "nw_src"  : "<A.B.C.D/M>"
#    "nw_dst"  : "<A.B.C.D/M>"
#    "nw_proto": "<TCP or UDP or ICMP>"
#    "tp_src"  : "<int>"
#    "tp_dst"  : "<int>"
#    "actions" : "<ALLOW or DENY>"
#
#   Note: specifying nw_src/nw_dst
#         without specifying dl-type as "ARP" or "IPv4"
#         will automatically set dl-type as "IPv4".
#
#   Note: When "priority" has not been set up,
#         "0" is set to "priority".
#
#   Note: When "actions" has not been set up,
#         "ALLOW" is set to "actions".
#
#
# delete a rule of the firewall switches from ruleID
# * for no vlan
# DELETE /firewall/rules/{switch-id}
#
# * for specific vlan group
# DELETE /firewall/rules/{switch-id}/{vlan-id}
#
#  request body format:
#   {"<field>":"<value>"}
#
#     <field>  : <value>
#    "rule_id" : "<int>" or "all"
#


SWITCHID_PATTERN = dpid_lib.DPID_PATTERN + r'|all'
VLANID_PATTERN = r'[0-9]{1,4}|all'

REST_ALL = 'all'
REST_SWITCHID = 'switch_id'
REST_VLANID = 'vlan_id'
REST_RULE_ID = 'rule_id'
REST_STATUS = 'status'
REST_LOG_STATUS = 'log_status'
REST_STATUS_ENABLE = 'enable'
REST_STATUS_DISABLE = 'disable'
REST_COMMAND_RESULT = 'command_result'
REST_ACL = 'access_control_list'
REST_RULES = 'rules'
REST_COOKIE = 'cookie'
REST_PRIORITY = 'priority'
REST_MATCH = 'match'
REST_IN_PORT = 'in_port'
REST_SRC_MAC = 'dl_src'
REST_DST_MAC = 'dl_dst'
REST_DL_TYPE = 'dl_type'
REST_DL_TYPE_ARP = 'ARP'
REST_DL_TYPE_IPV4 = 'IPv4'
REST_DL_VLAN = 'dl_vlan'
REST_SRC_IP = 'nw_src'
REST_DST_IP = 'nw_dst'
REST_NW_PROTO = 'nw_proto'
REST_NW_PROTO_TCP = 'TCP'
REST_NW_PROTO_UDP = 'UDP'
REST_NW_PROTO_ICMP = 'ICMP'
REST_TP_SRC = 'tp_src'
REST_TP_DST = 'tp_dst'
REST_ACTION = 'actions'
REST_ACTION_ALLOW = 'ALLOW'
REST_ACTION_DENY = 'DENY'
REST_ACTION_PACKETIN = 'PACKETIN'


STATUS_FLOW_PRIORITY = ofproto_v1_2_parser.UINT16_MAX
ARP_FLOW_PRIORITY = ofproto_v1_2_parser.UINT16_MAX - 1
LOG_FLOW_PRIORITY = 0
ACL_FLOW_PRIORITY_MIN = LOG_FLOW_PRIORITY + 1
ACL_FLOW_PRIORITY_MAX = ofproto_v1_2_parser.UINT16_MAX - 2

VLANID_NONE = 0
VLANID_MIN = 2
VLANID_MAX = 4094
COOKIE_SHIFT_VLANID = 32


class RestFirewallAPI(app_manager.RyuApp):

    OFP_VERSIONS = [ofproto_v1_0.OFP_VERSION,
                    ofproto_v1_2.OFP_VERSION]

    _CONTEXTS = {'dpset': dpset.DPSet,
                 'wsgi': WSGIApplication}

    def __init__(self, *args, **kwargs):
        super(RestFirewallAPI, self).__init__(*args, **kwargs)

        # logger configure
        FirewallController.set_logger(self.logger)

        self.dpset = kwargs['dpset']
        wsgi = kwargs['wsgi']
        self.waiters = {}
        self.data = {}
        self.data['dpset'] = self.dpset
        self.data['waiters'] = self.waiters

        mapper = wsgi.mapper
        wsgi.registory['FirewallController'] = self.data
        path = '/firewall'
        requirements = {'switchid': SWITCHID_PATTERN,
                        'vlanid': VLANID_PATTERN}

        # for firewall status
        uri = path + '/module/status'
        mapper.connect('firewall', uri,
                       controller=FirewallController, action='get_status',
                       conditions=dict(method=['GET']))

        uri = path + '/module/enable/{switchid}'
        mapper.connect('firewall', uri,
                       controller=FirewallController, action='set_enable',
                       conditions=dict(method=['PUT']),
                       requirements=requirements)

        uri = path + '/module/disable/{switchid}'
        mapper.connect('firewall', uri,
                       controller=FirewallController, action='set_disable',
                       conditions=dict(method=['PUT']),
                       requirements=requirements)

        # for firewall logs
        uri = path + '/log/status'
        mapper.connect('firewall', uri,
                       controller=FirewallController, action='get_log_status',
                       conditions=dict(method=['GET']))

        uri = path + '/log/enable/{switchid}'
        mapper.connect('firewall', uri,
                       controller=FirewallController, action='set_log_enable',
                       conditions=dict(method=['PUT']),
                       requirements=requirements)

        uri = path + '/log/disable/{switchid}'
        mapper.connect('firewall', uri,
                       controller=FirewallController, action='set_log_disable',
                       conditions=dict(method=['PUT']),
                       requirements=requirements)

        # for no VLAN data
        uri = path + '/rules/{switchid}'
        mapper.connect('firewall', uri,
                       controller=FirewallController, action='get_rules',
                       conditions=dict(method=['GET']),
                       requirements=requirements)

        mapper.connect('firewall', uri,
                       controller=FirewallController, action='set_rule',
                       conditions=dict(method=['POST']),
                       requirements=requirements)

        mapper.connect('firewall', uri,
                       controller=FirewallController, action='delete_rule',
                       conditions=dict(method=['DELETE']),
                       requirements=requirements)

        # for VLAN data
        uri += '/{vlanid}'
        mapper.connect('firewall', uri, controller=FirewallController,
                       action='get_vlan_rules',
                       conditions=dict(method=['GET']),
                       requirements=requirements)

        mapper.connect('firewall', uri, controller=FirewallController,
                       action='set_vlan_rule',
                       conditions=dict(method=['POST']),
                       requirements=requirements)

        mapper.connect('firewall', uri, controller=FirewallController,
                       action='delete_vlan_rule',
                       conditions=dict(method=['DELETE']),
                       requirements=requirements)

    def stats_reply_handler(self, ev):
        msg = ev.msg
        dp = msg.datapath

        if dp.id not in self.waiters:
            return
        if msg.xid not in self.waiters[dp.id]:
            return
        lock, msgs = self.waiters[dp.id][msg.xid]
        msgs.append(msg)

        if msg.flags & dp.ofproto.OFPSF_REPLY_MORE:
            return
        del self.waiters[dp.id][msg.xid]
        lock.set()

    @set_ev_cls(dpset.EventDP, dpset.DPSET_EV_DISPATCHER)
    def handler_datapath(self, ev):
        if ev.enter:
            FirewallController.regist_ofs(ev.dp)
        else:
            FirewallController.unregist_ofs(ev.dp)

    # for OpenFlow version1.0
    @set_ev_cls(ofp_event.EventOFPFlowStatsReply, MAIN_DISPATCHER)
    def stats_reply_handler_v1_0(self, ev):
        self.stats_reply_handler(ev)

    # for OpenFlow version1.2
    @set_ev_cls(ofp_event.EventOFPStatsReply, MAIN_DISPATCHER)
    def stats_reply_handler_v1_2(self, ev):
        self.stats_reply_handler(ev)

    @set_ev_cls(ofp_event.EventOFPPacketIn, MAIN_DISPATCHER)
    def packet_in_handler(self, ev):
        FirewallController.packet_in_handler(ev.msg)


class FirewallOfsList(dict):
    def __init__(self):
        super(FirewallOfsList, self).__init__()

    def get_ofs(self, dp_id):
        if len(self) == 0:
            raise ValueError('firewall sw is not connected.')

        dps = {}
        if dp_id == REST_ALL:
            dps = self
        else:
            try:
                dpid = dpid_lib.str_to_dpid(dp_id)
            except:
                raise ValueError('Invalid switchID.')

            if dpid in self:
                dps = {dpid: self[dpid]}
            else:
                msg = 'firewall sw is not connected. : switchID=%s' % dp_id
                raise ValueError(msg)

        return dps


class FirewallController(ControllerBase):

    _OFS_LIST = FirewallOfsList()
    _LOGGER = None

    def __init__(self, req, link, data, **config):
        super(FirewallController, self).__init__(req, link, data, **config)
        self.dpset = data['dpset']
        self.waiters = data['waiters']

    @classmethod
    def set_logger(cls, logger):
        cls._LOGGER = logger
        cls._LOGGER.propagate = False
        hdlr = logging.StreamHandler()
        fmt_str = '[FW][%(levelname)s] %(message)s'
        hdlr.setFormatter(logging.Formatter(fmt_str))
        cls._LOGGER.addHandler(hdlr)

    @staticmethod
    def regist_ofs(dp):
        dpid_str = dpid_lib.dpid_to_str(dp.id)
        try:
            f_ofs = Firewall(dp)
        except OFPUnknownVersion, message:
            FirewallController._LOGGER.info('dpid=%s: %s',
                                            dpid_str, message)
            return

        FirewallController._OFS_LIST.setdefault(dp.id, f_ofs)

        f_ofs.set_disable_flow()
        f_ofs.set_arp_flow()
        f_ofs.set_log_enable()
        FirewallController._LOGGER.info('dpid=%s: Join as firewall.',
                                        dpid_str)

    @staticmethod
    def unregist_ofs(dp):
        if dp.id in FirewallController._OFS_LIST:
            del FirewallController._OFS_LIST[dp.id]
            FirewallController._LOGGER.info('dpid=%s: Leave firewall.',
                                            dpid_lib.dpid_to_str(dp.id))

    # GET /firewall/module/status
    def get_status(self, req, **_kwargs):
        return self._access_module(REST_ALL, 'get_status',
                                   waiters=self.waiters)

    # POST /firewall/module/enable/{switchid}
    def set_enable(self, req, switchid, **_kwargs):
        return self._access_module(switchid, 'set_enable_flow')

    # POST /firewall/module/disable/{switchid}
    def set_disable(self, req, switchid, **_kwargs):
        return self._access_module(switchid, 'set_disable_flow')

    # GET /firewall/log/status
    def get_log_status(self, dummy, **_kwargs):
        return self._access_module(REST_ALL, 'get_log_status',
                                   waiters=self.waiters)

    # PUT /firewall/log/enable/{switchid}
    def set_log_enable(self, dummy, switchid, **_kwargs):
        return self._access_module(switchid, 'set_log_enable')

    # PUT /firewall/log/disable/{switchid}
    def set_log_disable(self, dummy, switchid, **_kwargs):
        return self._access_module(switchid, 'set_log_disable')

    def _access_module(self, switchid, func, waiters=None):
        try:
            dps = self._OFS_LIST.get_ofs(switchid)
        except ValueError, message:
            return Response(status=400, body=str(message))

        msgs = []
        for f_ofs in dps.values():
            function = getattr(f_ofs, func)
            msg = function() if waiters is None else function(waiters)
            msgs.append(msg)

        body = json.dumps(msgs)
        return Response(content_type='application/json', body=body)

    # GET /firewall/rules/{switchid}
    def get_rules(self, req, switchid, **_kwargs):
        return self._get_rules(switchid)

    # GET /firewall/rules/{switchid}/{vlanid}
    def get_vlan_rules(self, req, switchid, vlanid, **_kwargs):
        return self._get_rules(switchid, vlan_id=vlanid)

    # POST /firewall/rules/{switchid}
    def set_rule(self, req, switchid, **_kwargs):
        return self._set_rule(req, switchid)

    # POST /firewall/rules/{switchid}/{vlanid}
    def set_vlan_rule(self, req, switchid, vlanid, **_kwargs):
        return self._set_rule(req, switchid, vlan_id=vlanid)

    # DELETE /firewall/rules/{switchid}
    def delete_rule(self, req, switchid, **_kwargs):
        return self._delete_rule(req, switchid)

    # DELETE /firewall/rules/{switchid}/{vlanid}
    def delete_vlan_rule(self, req, switchid, vlanid, **_kwargs):
        return self._delete_rule(req, switchid, vlan_id=vlanid)

    def _get_rules(self, switchid, vlan_id=VLANID_NONE):
        try:
            dps = self._OFS_LIST.get_ofs(switchid)
            vid = FirewallController._conv_toint_vlanid(vlan_id)
        except ValueError, message:
            return Response(status=400, body=str(message))

        msgs = []
        for f_ofs in dps.values():
            rules = f_ofs.get_rules(self.waiters, vid)
            msgs.append(rules)

        body = json.dumps(msgs)
        return Response(content_type='application/json', body=body)

    def _set_rule(self, req, switchid, vlan_id=VLANID_NONE):
        try:
            rule = eval(req.body)
        except SyntaxError:
            FirewallController._LOGGER.debug('invalid syntax %s', req.body)
            return Response(status=400)

        try:
            dps = self._OFS_LIST.get_ofs(switchid)
            vid = FirewallController._conv_toint_vlanid(vlan_id)
        except ValueError, message:
            return Response(status=400, body=str(message))

        msgs = []
        for f_ofs in dps.values():
            try:
                msg = f_ofs.set_rule(rule, vid)
                msgs.append(msg)
            except ValueError, message:
                return Response(status=400, body=str(message))

        body = json.dumps(msgs)
        return Response(content_type='application/json', body=body)

    def _delete_rule(self, req, switchid, vlan_id=VLANID_NONE):
        try:
            ruleid = eval(req.body)
        except SyntaxError:
            FirewallController._LOGGER.debug('invalid syntax %s', req.body)
            return Response(status=400)

        try:
            dps = self._OFS_LIST.get_ofs(switchid)
            vid = FirewallController._conv_toint_vlanid(vlan_id)
        except ValueError, message:
            return Response(status=400, body=str(message))

        msgs = []
        for f_ofs in dps.values():
            try:
                msg = f_ofs.delete_rule(ruleid, self.waiters, vid)
                msgs.append(msg)
            except ValueError, message:
                return Response(status=400, body=str(message))

        body = json.dumps(msgs)
        return Response(content_type='application/json', body=body)

    @staticmethod
    def _conv_toint_vlanid(vlan_id):
        if vlan_id != REST_ALL:
            vlan_id = int(vlan_id)
            if (vlan_id != VLANID_NONE and
                    (vlan_id < VLANID_MIN or VLANID_MAX < vlan_id)):
                msg = 'Invalid {vlan_id} value. Set [%d-%d]' % (VLANID_MIN,
                                                                VLANID_MAX)
                raise ValueError(msg)
        return vlan_id

    @staticmethod
    def packet_in_handler(msg):
        pkt = packet.Packet(msg.data)
        dpid_str = dpid_lib.dpid_to_str(msg.datapath.id)
        FirewallController._LOGGER.info('dpid=%s: Blocked packet = %s',
                                        dpid_str, pkt)


class Firewall(object):

    _OFCTL = {ofproto_v1_0.OFP_VERSION: ofctl_v1_0,
              ofproto_v1_2.OFP_VERSION: ofctl_v1_2}

    def __init__(self, dp):
        super(Firewall, self).__init__()
        self.vlan_list = {}
        self.vlan_list[VLANID_NONE] = 0  # for VLAN=None
        self.dp = dp
        version = dp.ofproto.OFP_VERSION

        if version not in self._OFCTL:
            raise OFPUnknownVersion(version=version)

        self.ofctl = self._OFCTL[version]

    def _update_vlan_list(self, vlan_list):
        for vlan_id in self.vlan_list.keys():
            if vlan_id is not VLANID_NONE and vlan_id not in vlan_list:
                del self.vlan_list[vlan_id]

    def _get_cookie(self, vlan_id):
        if vlan_id == REST_ALL:
            vlan_ids = self.vlan_list.keys()
        else:
            vlan_ids = [vlan_id]

        cookie_list = []
        for vlan_id in vlan_ids:
            self.vlan_list.setdefault(vlan_id, 0)
            self.vlan_list[vlan_id] += 1
            self.vlan_list[vlan_id] &= ofproto_v1_2_parser.UINT32_MAX
            cookie = (vlan_id << COOKIE_SHIFT_VLANID) + \
                self.vlan_list[vlan_id]
            cookie_list.append([cookie, vlan_id])

        return cookie_list

    @staticmethod
    def _cookie_to_ruleid(cookie):
        return cookie & ofproto_v1_2_parser.UINT32_MAX

    # REST command template
    def rest_command(func):
        def _rest_command(*args, **kwargs):
            key, value = func(*args, **kwargs)
            switch_id = dpid_lib.dpid_to_str(args[0].dp.id)
            return {REST_SWITCHID: switch_id,
                    key: value}
        return _rest_command

    @rest_command
    def get_status(self, waiters):
        msgs = self.ofctl.get_flow_stats(self.dp, waiters)

        status = REST_STATUS_ENABLE
        if str(self.dp.id) in msgs:
            flow_stats = msgs[str(self.dp.id)]
            for flow_stat in flow_stats:
                if flow_stat['priority'] == STATUS_FLOW_PRIORITY:
                    status = REST_STATUS_DISABLE

        return REST_STATUS, status

    @rest_command
    def set_disable_flow(self):
        cookie = 0
        priority = STATUS_FLOW_PRIORITY
        match = {}
        actions = []
        flow = self._to_of_flow(cookie=cookie, priority=priority,
                                match=match, actions=actions)

        cmd = self.dp.ofproto.OFPFC_ADD
        self.ofctl.mod_flow_entry(self.dp, flow, cmd)

        msg = {'result': 'success',
               'details': 'firewall stopped.'}
        return REST_COMMAND_RESULT, msg

    @rest_command
    def set_enable_flow(self):
        cookie = 0
        priority = STATUS_FLOW_PRIORITY
        match = {}
        actions = []
        flow = self._to_of_flow(cookie=cookie, priority=priority,
                                match=match, actions=actions)

        cmd = self.dp.ofproto.OFPFC_DELETE_STRICT
        self.ofctl.mod_flow_entry(self.dp, flow, cmd)

        msg = {'result': 'success',
               'details': 'firewall running.'}
        return REST_COMMAND_RESULT, msg

    @rest_command
    def get_log_status(self, waiters):
        msgs = self.ofctl.get_flow_stats(self.dp, waiters)

        status = REST_STATUS_DISABLE
        if str(self.dp.id) in msgs:
            flow_stats = msgs[str(self.dp.id)]
            for flow_stat in flow_stats:
                if flow_stat['priority'] == LOG_FLOW_PRIORITY:
                    if flow_stat['actions']:
                        status = REST_STATUS_ENABLE

        return REST_LOG_STATUS, status

    @rest_command
    def set_log_disable(self):
        return self._set_log_status(False)

    @rest_command
    def set_log_enable(self):
        return self._set_log_status(True)

    def _set_log_status(self, is_enable):
        if is_enable:
            actions = Action.to_openflow(self.dp,
                                         {REST_ACTION: REST_ACTION_PACKETIN})
            details = 'Log collection started.'
        else:
            actions = []
            details = 'Log collection stopped.'

        flow = self._to_of_flow(cookie=0, priority=LOG_FLOW_PRIORITY,
                                match={}, actions=actions)

        cmd = self.dp.ofproto.OFPFC_ADD
        self.ofctl.mod_flow_entry(self.dp, flow, cmd)

        msg = {'result': 'success',
               'details': details}
        return REST_COMMAND_RESULT, msg

    def set_arp_flow(self):
        cookie = 0
        priority = ARP_FLOW_PRIORITY
        match = {REST_DL_TYPE: ether.ETH_TYPE_ARP}
        action = {REST_ACTION: REST_ACTION_ALLOW}
        actions = Action.to_openflow(self.dp, action)
        flow = self._to_of_flow(cookie=cookie, priority=priority,
                                match=match, actions=actions)

        cmd = self.dp.ofproto.OFPFC_ADD
        self.ofctl.mod_flow_entry(self.dp, flow, cmd)

    @rest_command
    def set_rule(self, rest, vlan_id):
        msgs = []
        cookie_list = self._get_cookie(vlan_id)
        for cookie, vid in cookie_list:
            msg = self._set_rule(cookie, rest, vid)
            msgs.append(msg)
        return REST_COMMAND_RESULT, msgs

    def _set_rule(self, cookie, rest, vlan_id):
        priority = int(rest.get(REST_PRIORITY, ACL_FLOW_PRIORITY_MIN))

        if (priority < ACL_FLOW_PRIORITY_MIN
                or ACL_FLOW_PRIORITY_MAX < priority):
            raise ValueError('Invalid priority value. Set [%d-%d]'
                             % (ACL_FLOW_PRIORITY_MIN, ACL_FLOW_PRIORITY_MAX))

        if vlan_id:
            rest[REST_DL_VLAN] = vlan_id

        match = Match.to_openflow(rest)
        actions = Action.to_openflow(self.dp, rest)
        flow = self._to_of_flow(cookie=cookie, priority=priority,
                                match=match, actions=actions)

        cmd = self.dp.ofproto.OFPFC_ADD
        try:
            self.ofctl.mod_flow_entry(self.dp, flow, cmd)
        except:
            raise ValueError('Invalid rule parameter.')

        rule_id = Firewall._cookie_to_ruleid(cookie)
        msg = {'result': 'success',
               'details': 'Rule added. : rule_id=%d' % rule_id}

        if vlan_id != VLANID_NONE:
            msg.setdefault(REST_VLANID, vlan_id)
        return msg

    @rest_command
    def get_rules(self, waiters, vlan_id):
        rules = {}
        msgs = self.ofctl.get_flow_stats(self.dp, waiters)

        if str(self.dp.id) in msgs:
            flow_stats = msgs[str(self.dp.id)]
            for flow_stat in flow_stats:
                priority = flow_stat[REST_PRIORITY]
                if (priority != STATUS_FLOW_PRIORITY
                        and priority != ARP_FLOW_PRIORITY
                        and priority != LOG_FLOW_PRIORITY):
                    vid = flow_stat[REST_MATCH].get(REST_DL_VLAN, VLANID_NONE)
                    if vlan_id == REST_ALL or vlan_id == vid:
                        rule = self._to_rest_rule(flow_stat)
                        rules.setdefault(vid, [])
                        rules[vid].append(rule)

        get_data = []
        for vid, rule in rules.items():
            if vid == VLANID_NONE:
                vid_data = {REST_RULES: rule}
            else:
                vid_data = {REST_VLANID: vid, REST_RULES: rule}
            get_data.append(vid_data)

        return REST_ACL, get_data

    @rest_command
    def delete_rule(self, rest, waiters, vlan_id):
        try:
            if rest[REST_RULE_ID] == REST_ALL:
                rule_id = REST_ALL
            else:
                rule_id = int(rest[REST_RULE_ID])
        except:
            raise ValueError('Invalid ruleID.')

        vlan_list = []
        delete_list = []

        msgs = self.ofctl.get_flow_stats(self.dp, waiters)
        if str(self.dp.id) in msgs:
            flow_stats = msgs[str(self.dp.id)]
            for flow_stat in flow_stats:
                cookie = flow_stat[REST_COOKIE]
                ruleid = Firewall._cookie_to_ruleid(cookie)
                priority = flow_stat[REST_PRIORITY]
                dl_vlan = flow_stat[REST_MATCH].get(REST_DL_VLAN, VLANID_NONE)

                if (priority != STATUS_FLOW_PRIORITY
                        and priority != ARP_FLOW_PRIORITY
                        and priority != LOG_FLOW_PRIORITY):
                    if ((rule_id == REST_ALL or rule_id == ruleid) and
                            (vlan_id == dl_vlan or vlan_id == REST_ALL)):
                        match = Match.to_del_openflow(flow_stat[REST_MATCH])
                        delete_list.append([cookie, priority, match])
                    else:
                        if dl_vlan not in vlan_list:
                            vlan_list.append(dl_vlan)

        self._update_vlan_list(vlan_list)

        if len(delete_list) == 0:
            msg_details = 'Rule is not exist.'
            if rule_id != REST_ALL:
                msg_details += ' : ruleID=%d' % rule_id
            msg = {'result': 'failure',
                   'details': msg_details}
        else:
            cmd = self.dp.ofproto.OFPFC_DELETE_STRICT
            actions = []
            delete_ids = {}
            for cookie, priority, match in delete_list:
                flow = self._to_of_flow(cookie=cookie, priority=priority,
                                        match=match, actions=actions)
                self.ofctl.mod_flow_entry(self.dp, flow, cmd)

                vid = match.get(REST_DL_VLAN, VLANID_NONE)
                rule_id = Firewall._cookie_to_ruleid(cookie)
                delete_ids.setdefault(vid, '')
                delete_ids[vid] += (('%d' if delete_ids[vid] == ''
                                     else ',%d') % rule_id)

            msg = []
            for vid, rule_ids in delete_ids.items():
                del_msg = {'result': 'success',
                           'details': 'Rule deleted. : ruleID=%s' % rule_ids}
                if vid != VLANID_NONE:
                    del_msg.setdefault(REST_VLANID, vid)
                msg.append(del_msg)

        return REST_COMMAND_RESULT, msg

    def _to_of_flow(self, cookie, priority, match, actions):
        flow = {'cookie': cookie,
                'priority': priority,
                'flags': 0,
                'idle_timeout': 0,
                'hard_timeout': 0,
                'match': match,
                'actions': actions}
        return flow

    def _to_rest_rule(self, flow):
        ruleid = Firewall._cookie_to_ruleid(flow[REST_COOKIE])
        rule = {REST_RULE_ID: ruleid}
        rule.update({REST_PRIORITY: flow[REST_PRIORITY]})
        rule.update(Match.to_rest(flow))
        rule.update(Action.to_rest(flow))
        return rule


class Match(object):

    _CONVERT = {REST_DL_TYPE:
                {REST_DL_TYPE_ARP: ether.ETH_TYPE_ARP,
                 REST_DL_TYPE_IPV4: ether.ETH_TYPE_IP},
                REST_NW_PROTO:
                {REST_NW_PROTO_TCP: inet.IPPROTO_TCP,
                 REST_NW_PROTO_UDP: inet.IPPROTO_UDP,
                 REST_NW_PROTO_ICMP: inet.IPPROTO_ICMP}}

    @staticmethod
    def to_openflow(rest):
        match = {}
        set_dltype_flg = False

        for key, value in rest.items():
            if (key == REST_SRC_IP or key == REST_DST_IP
                    or key == REST_NW_PROTO):
                if (REST_DL_TYPE in rest) is False:
                    set_dltype_flg = True
                elif (rest[REST_DL_TYPE] != REST_DL_TYPE_IPV4
                        and rest[REST_DL_TYPE] != REST_DL_TYPE_ARP):
                    continue

            elif key == REST_TP_SRC or key == REST_TP_DST:
                if ((REST_NW_PROTO in rest) is False
                    or (rest[REST_NW_PROTO] != REST_NW_PROTO_TCP
                        and rest[REST_NW_PROTO] != REST_NW_PROTO_UDP)):
                    continue

            if key in Match._CONVERT:
                if value in Match._CONVERT[key]:
                    match.setdefault(key, Match._CONVERT[key][value])
                else:
                    raise ValueError('Invalid rule parameter. : key=%s' % key)
            else:
                match.setdefault(key, value)

            if set_dltype_flg:
                match.setdefault(REST_DL_TYPE, ether.ETH_TYPE_IP)

        return match

    @staticmethod
    def to_rest(openflow):
        of_match = openflow[REST_MATCH]

        mac_dontcare = mac.haddr_to_str(mac.DONTCARE)
        ip_dontcare = '0.0.0.0'

        match = {}
        for key, value in of_match.items():
            if key == REST_SRC_MAC or key == REST_DST_MAC:
                if value == mac_dontcare:
                    continue
            elif key == REST_SRC_IP or key == REST_DST_IP:
                if value == ip_dontcare:
                    continue
            elif value == 0:
                continue

            if key in Match._CONVERT:
                conv = Match._CONVERT[key]
                conv = dict((value, key) for key, value in conv.items())
                match.setdefault(key, conv[value])
            else:
                match.setdefault(key, value)

        return match

    @staticmethod
    def to_del_openflow(of_match):
        mac_dontcare = mac.haddr_to_str(mac.DONTCARE)
        ip_dontcare = '0.0.0.0'

        match = {}
        for key, value in of_match.items():
            if key == REST_SRC_MAC or key == REST_DST_MAC:
                if value == mac_dontcare:
                    continue
            elif key == REST_SRC_IP or key == REST_DST_IP:
                if value == ip_dontcare:
                    continue
            elif value == 0:
                continue

            match.setdefault(key, value)

        return match


class Action(object):

    @staticmethod
    def to_openflow(dp, rest):
        value = rest.get(REST_ACTION, REST_ACTION_ALLOW)

        if value == REST_ACTION_ALLOW:
            out_port = dp.ofproto.OFPP_NORMAL
            action = [{'type': 'OUTPUT',
                       'port': out_port}]
        elif value == REST_ACTION_DENY:
            action = []
        elif value == REST_ACTION_PACKETIN:
            out_port = dp.ofproto.OFPP_CONTROLLER
            action = [{'type': 'OUTPUT',
                       'port': out_port}]
        else:
            raise ValueError('Invalid action type.')

        return action

    @staticmethod
    def to_rest(openflow):
        if REST_ACTION in openflow:
            if len(openflow[REST_ACTION]) > 0:
                action = {REST_ACTION: REST_ACTION_ALLOW}
            else:
                action = {REST_ACTION: REST_ACTION_DENY}
        else:
            action = {REST_ACTION: 'Unknown action type.'}

        return action

########NEW FILE########
__FILENAME__ = rest_nw_id
# Copyright (C) 2011 Nippon Telegraph and Telephone Corporation.
# Copyright (C) 2011, 2012 Isaku Yamahata <yamahata at valinux co jp>
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.


NW_ID_EXTERNAL = '__NW_ID_EXTERNAL__'
NW_ID_RESERVED = '__NW_ID_RESERVED__'
NW_ID_VPORT_GRE = '__NW_ID_VPORT_GRE__'
NW_ID_UNKNOWN = '__NW_ID_UNKNOWN__'

RESERVED_NETWORK_IDS = (
    NW_ID_EXTERNAL,
    NW_ID_RESERVED,
    NW_ID_VPORT_GRE,
    NW_ID_UNKNOWN,
)

# tunnel type
_TUNNEL_TYPE_TO_NETWORK_ID = {
    'gre': NW_ID_VPORT_GRE,
}


def tunnel_type_to_network_id(tunnel_type):
    return _TUNNEL_TYPE_TO_NETWORK_ID[tunnel_type.lower()]

# PORT_TYPE_VM = 'guestvm'
# PORT_TYPE_GW = 'gateway'
# PORT_TYPE_EXTERNAL = 'external'

########NEW FILE########
__FILENAME__ = rest_quantum
# Copyright (C) 2012 Nippon Telegraph and Telephone Corporation.
# Copyright (C) 2012 Isaku Yamahata <yamahata at private email ne jp>
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# This module provides a set of REST API dedicated to OpenStack Ryu plug-in.
#   - Interface (uuid in ovsdb) registration
#   - Maintain interface association to a network
#
# Used by OpenStack Ryu plug-in.

import json
from webob import Response

from ryu.base import app_manager
from ryu.app.wsgi import (ControllerBase,
                          WSGIApplication)
from ryu.lib import quantum_ifaces

# REST API for openstack quantum
# get the list of iface-ids
# GET /v1.0/quantum/ports/
#
# register the iface_id
# POST /v1.0/quantum/ports/{iface_id}
#
# unregister iface_id
# DELETE /v1.0/quantum/ports/{iface_id}
#
# associate network_id with iface_id
# GET /v1.0/quantum/ports/{iface_id}/network_id
#
# associate network_id with iface_id
# POST /v1.0/quantum/ports/{iface_id}/network_id/{network_id}
#
# update network_id with iface_id
# PUT /v1.0/quantum/ports/{iface_id}/network_id/{network_id}


class QuantumController(ControllerBase):
    def __init__(self, req, link, data, **config):
        super(QuantumController, self).__init__(req, link, data, **config)
        self.ifaces = data

    def list_ifaces(self, _req, **_kwargs):
        body = json.dumps(self.ifaces.keys())
        return Response(content_type='application/json', body=body)

    def delete_iface(self, _req, iface_id, **_kwargs):
        self.ifaces.unregister(iface_id)
        return Response(status=200)

    def list_keys(self, _req, iface_id, **_kwargs):
        try:
            keys = self.ifaces.list_keys(iface_id)
        except KeyError:
            return Response(status=404)
        body = json.dumps(keys)
        return Response(content_type='application/json', body=body)

    def get_key(self, _req, iface_id, key, **_kwargs):
        try:
            value = self.ifaces.get_key(iface_id, key)
        except KeyError:
            return Response(status=404)
        body = json.dumps(value)
        return Response(content_type='application/json', body=body)

    def create_value(self, _req, iface_id, key, value, **_kwargs):
        try:
            self.ifaces.set_key(iface_id, key, value)
        except ValueError:
            return Response(status=404)
        return Response(status=200)

    def update_value(self, _req, iface_id, key, value, **_kwargs):
        try:
            self.ifaces.update_key(iface_id, key, value)
        except ValueError:
            return Response(status=404)
        return Response(status=200)


class QuantumIfaceAPI(app_manager.RyuApp):
    _CONTEXTS = {
        'quantum_ifaces': quantum_ifaces.QuantumIfaces,
        'wsgi': WSGIApplication,
    }

    def __init__(self, *args, **kwargs):
        super(QuantumIfaceAPI, self).__init__(*args, **kwargs)
        self.ifaces = kwargs['quantum_ifaces']
        wsgi = kwargs['wsgi']
        mapper = wsgi.mapper

        controller = QuantumController
        wsgi.registory[controller.__name__] = self.ifaces
        route_name = 'quantum_ifaces'
        uri = '/v1.0/quantum'

        ports_uri = uri + '/ports'
        s = mapper.submapper(controller=controller)
        s.connect(route_name, ports_uri, action='list_ifaces',
                  conditions=dict(method=['GET', 'HEAD']))

        iface_uri = ports_uri + '/{iface_id}'
        s.connect(route_name, iface_uri, action='delete_iface',
                  conditions=dict(method=['DELETE']))

        keys_uri = iface_uri + '/keys'
        s.connect(route_name, keys_uri, action='list_keys',
                  conditions=dict(method=['GET', 'HEAD']))

        key_uri = keys_uri + '/{key}'
        s.connect(route_name, key_uri, action='get_key',
                  conditions=dict(method=['GET', 'HEAD']))

        value_uri = keys_uri + '/{key}/{value}'
        s.connect(route_name, value_uri, action='create_value',
                  conditions=dict(method=['POST']))
        s.connect(route_name, value_uri, action='update_value',
                  conditions=dict(method=['PUT']))

########NEW FILE########
__FILENAME__ = rest_router
# Copyright (C) 2013 Nippon Telegraph and Telephone Corporation.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.


import logging
import socket
import struct

import json
from webob import Response

from ryu.app.wsgi import ControllerBase
from ryu.app.wsgi import WSGIApplication
from ryu.base import app_manager
from ryu.controller import dpset
from ryu.controller import ofp_event
from ryu.controller.handler import set_ev_cls
from ryu.controller.handler import MAIN_DISPATCHER
from ryu.exception import OFPUnknownVersion
from ryu.exception import RyuException
from ryu.lib import dpid as dpid_lib
from ryu.lib import hub
from ryu.lib import mac as mac_lib
from ryu.lib import addrconv
from ryu.lib.packet import arp
from ryu.lib.packet import ethernet
from ryu.lib.packet import icmp
from ryu.lib.packet import ipv4
from ryu.lib.packet import packet
from ryu.lib.packet import tcp
from ryu.lib.packet import udp
from ryu.lib.packet import vlan
from ryu.ofproto import ether
from ryu.ofproto import inet
from ryu.ofproto import ofproto_v1_0
from ryu.ofproto import ofproto_v1_2


#=============================
#          REST API
#=============================
#
#  Note: specify switch and vlan group, as follows.
#   {switch_id} : 'all' or switchID
#   {vlan_id}   : 'all' or vlanID
#
#
## 1. get address data and routing data.
#
# * get data of no vlan
# GET /router/{switch_id}
#
# * get data of specific vlan group
# GET /router/{switch_id}/{vlan_id}
#
#
## 2. set address data or routing data.
#
# * set data of no vlan
# POST /router/{switch_id}
#
# * set data of specific vlan group
# POST /router/{switch_id}/{vlan_id}
#
#  case1: set address data.
#    parameter = {"address": "A.B.C.D/M"}
#  case2-1: set static route.
#    parameter = {"destination": "A.B.C.D/M", "gateway": "E.F.G.H"}
#  case2-2: set default route.
#    parameter = {"gateway": "E.F.G.H"}
#
#
## 3. delete address data or routing data.
#
# * delete data of no vlan
# DELETE /router/{switch_id}
#
# * delete data of specific vlan group
# DELETE /router/{switch_id}/{vlan_id}
#
#  case1: delete address data.
#    parameter = {"address_id": "<int>"} or {"address_id": "all"}
#  case2: delete routing data.
#    parameter = {"route_id": "<int>"} or {"route_id": "all"}
#
#


UINT16_MAX = 0xffff
UINT32_MAX = 0xffffffff
UINT64_MAX = 0xffffffffffffffff

ETHERNET = ethernet.ethernet.__name__
VLAN = vlan.vlan.__name__
IPV4 = ipv4.ipv4.__name__
ARP = arp.arp.__name__
ICMP = icmp.icmp.__name__
TCP = tcp.tcp.__name__
UDP = udp.udp.__name__

MAX_SUSPENDPACKETS = 50  # Threshold of the packet suspends thread count.

ARP_REPLY_TIMER = 2  # sec
OFP_REPLY_TIMER = 1.0  # sec
CHK_ROUTING_TBL_INTERVAL = 1800  # sec

SWITCHID_PATTERN = dpid_lib.DPID_PATTERN + r'|all'
VLANID_PATTERN = r'[0-9]{1,4}|all'

VLANID_NONE = 0
VLANID_MIN = 2
VLANID_MAX = 4094

COOKIE_DEFAULT_ID = 0
COOKIE_SHIFT_VLANID = 32
COOKIE_SHIFT_ROUTEID = 16

DEFAULT_ROUTE = '0.0.0.0/0'
IDLE_TIMEOUT = 1800  # sec
DEFAULT_TTL = 64

REST_COMMAND_RESULT = 'command_result'
REST_RESULT = 'result'
REST_DETAILS = 'details'
REST_OK = 'success'
REST_NG = 'failure'
REST_ALL = 'all'
REST_SWITCHID = 'switch_id'
REST_VLANID = 'vlan_id'
REST_NW = 'internal_network'
REST_ADDRESSID = 'address_id'
REST_ADDRESS = 'address'
REST_ROUTEID = 'route_id'
REST_ROUTE = 'route'
REST_DESTINATION = 'destination'
REST_GATEWAY = 'gateway'

PRIORITY_VLAN_SHIFT = 1000
PRIORITY_NETMASK_SHIFT = 32

PRIORITY_NORMAL = 0
PRIORITY_ARP_HANDLING = 1
PRIORITY_DEFAULT_ROUTING = 1
PRIORITY_MAC_LEARNING = 2
PRIORITY_STATIC_ROUTING = 2
PRIORITY_IMPLICIT_ROUTING = 3
PRIORITY_L2_SWITCHING = 4
PRIORITY_IP_HANDLING = 5

PRIORITY_TYPE_ROUTE = 'priority_route'


def get_priority(priority_type, vid=0, route=None):
    log_msg = None
    priority = priority_type

    if priority_type == PRIORITY_TYPE_ROUTE:
        assert route is not None
        if route.dst_ip:
            priority_type = PRIORITY_STATIC_ROUTING
            priority = priority_type + route.netmask
            log_msg = 'static routing'
        else:
            priority_type = PRIORITY_DEFAULT_ROUTING
            priority = priority_type
            log_msg = 'default routing'

    if vid or priority_type == PRIORITY_IP_HANDLING:
        priority += PRIORITY_VLAN_SHIFT

    if priority_type > PRIORITY_STATIC_ROUTING:
        priority += PRIORITY_NETMASK_SHIFT

    if log_msg is None:
        return priority
    else:
        return priority, log_msg


def get_priority_type(priority, vid):
    if vid:
        priority -= PRIORITY_VLAN_SHIFT
    return priority


class NotFoundError(RyuException):
    message = 'Router SW is not connected. : switch_id=%(switch_id)s'


class CommandFailure(RyuException):
    pass


class RestRouterAPI(app_manager.RyuApp):

    OFP_VERSIONS = [ofproto_v1_0.OFP_VERSION,
                    ofproto_v1_2.OFP_VERSION]

    _CONTEXTS = {'dpset': dpset.DPSet,
                 'wsgi': WSGIApplication}

    def __init__(self, *args, **kwargs):
        super(RestRouterAPI, self).__init__(*args, **kwargs)

        # logger configure
        RouterController.set_logger(self.logger)

        wsgi = kwargs['wsgi']
        self.waiters = {}
        self.data = {'waiters': self.waiters}

        mapper = wsgi.mapper
        wsgi.registory['RouterController'] = self.data
        requirements = {'switch_id': SWITCHID_PATTERN,
                        'vlan_id': VLANID_PATTERN}

        # For no vlan data
        path = '/router/{switch_id}'
        mapper.connect('router', path, controller=RouterController,
                       requirements=requirements,
                       action='get_data',
                       conditions=dict(method=['GET']))
        mapper.connect('router', path, controller=RouterController,
                       requirements=requirements,
                       action='set_data',
                       conditions=dict(method=['POST']))
        mapper.connect('router', path, controller=RouterController,
                       requirements=requirements,
                       action='delete_data',
                       conditions=dict(method=['DELETE']))
        # For vlan data
        path = '/router/{switch_id}/{vlan_id}'
        mapper.connect('router', path, controller=RouterController,
                       requirements=requirements,
                       action='get_vlan_data',
                       conditions=dict(method=['GET']))
        mapper.connect('router', path, controller=RouterController,
                       requirements=requirements,
                       action='set_vlan_data',
                       conditions=dict(method=['POST']))
        mapper.connect('router', path, controller=RouterController,
                       requirements=requirements,
                       action='delete_vlan_data',
                       conditions=dict(method=['DELETE']))

    @set_ev_cls(dpset.EventDP, dpset.DPSET_EV_DISPATCHER)
    def datapath_handler(self, ev):
        if ev.enter:
            RouterController.register_router(ev.dp)
        else:
            RouterController.unregister_router(ev.dp)

    @set_ev_cls(ofp_event.EventOFPPacketIn, MAIN_DISPATCHER)
    def packet_in_handler(self, ev):
        RouterController.packet_in_handler(ev.msg)

    def _stats_reply_handler(self, ev):
        msg = ev.msg
        dp = msg.datapath

        if (dp.id not in self.waiters
                or msg.xid not in self.waiters[dp.id]):
            return
        event, msgs = self.waiters[dp.id][msg.xid]
        msgs.append(msg)

        if msg.flags & dp.ofproto.OFPSF_REPLY_MORE:
            return
        del self.waiters[dp.id][msg.xid]
        event.set()

    # for OpenFlow version1.0
    @set_ev_cls(ofp_event.EventOFPFlowStatsReply, MAIN_DISPATCHER)
    def stats_reply_handler_v1_0(self, ev):
        self._stats_reply_handler(ev)

    # for OpenFlow version1.2
    @set_ev_cls(ofp_event.EventOFPStatsReply, MAIN_DISPATCHER)
    def stats_reply_handler_v1_2(self, ev):
        self._stats_reply_handler(ev)

    #TODO: Update routing table when port status is changed.


# REST command template
def rest_command(func):
    def _rest_command(*args, **kwargs):
        try:
            msg = func(*args, **kwargs)
            return Response(content_type='application/json',
                            body=json.dumps(msg))

        except SyntaxError as e:
            status = 400
            details = e.msg
        except (ValueError, NameError) as e:
            status = 400
            details = e.message

        except NotFoundError as msg:
            status = 404
            details = str(msg)

        msg = {REST_RESULT: REST_NG,
               REST_DETAILS: details}
        return Response(status=status, body=json.dumps(msg))

    return _rest_command


class RouterController(ControllerBase):

    _ROUTER_LIST = {}
    _LOGGER = None

    def __init__(self, req, link, data, **config):
        super(RouterController, self).__init__(req, link, data, **config)
        self.waiters = data['waiters']

    @classmethod
    def set_logger(cls, logger):
        cls._LOGGER = logger
        cls._LOGGER.propagate = False
        hdlr = logging.StreamHandler()
        fmt_str = '[RT][%(levelname)s] switch_id=%(sw_id)s: %(message)s'
        hdlr.setFormatter(logging.Formatter(fmt_str))
        cls._LOGGER.addHandler(hdlr)

    @classmethod
    def register_router(cls, dp):
        dpid = {'sw_id': dpid_lib.dpid_to_str(dp.id)}
        try:
            router = Router(dp, cls._LOGGER)
        except OFPUnknownVersion as message:
            cls._LOGGER.error(str(message), extra=dpid)
            return
        cls._ROUTER_LIST.setdefault(dp.id, router)
        cls._LOGGER.info('Join as router.', extra=dpid)

    @classmethod
    def unregister_router(cls, dp):
        if dp.id in cls._ROUTER_LIST:
            cls._ROUTER_LIST[dp.id].delete()
            del cls._ROUTER_LIST[dp.id]

            dpid = {'sw_id': dpid_lib.dpid_to_str(dp.id)}
            cls._LOGGER.info('Leave router.', extra=dpid)

    @classmethod
    def packet_in_handler(cls, msg):
        dp_id = msg.datapath.id
        if dp_id in cls._ROUTER_LIST:
            router = cls._ROUTER_LIST[dp_id]
            router.packet_in_handler(msg)

    # GET /router/{switch_id}
    @rest_command
    def get_data(self, req, switch_id, **_kwargs):
        return self._access_router(switch_id, VLANID_NONE,
                                   'get_data', req.body)

    # GET /router/{switch_id}/{vlan_id}
    @rest_command
    def get_vlan_data(self, req, switch_id, vlan_id, **_kwargs):
        return self._access_router(switch_id, vlan_id,
                                   'get_data', req.body)

    # POST /router/{switch_id}
    @rest_command
    def set_data(self, req, switch_id, **_kwargs):
        return self._access_router(switch_id, VLANID_NONE,
                                   'set_data', req.body)

    # POST /router/{switch_id}/{vlan_id}
    @rest_command
    def set_vlan_data(self, req, switch_id, vlan_id, **_kwargs):
        return self._access_router(switch_id, vlan_id,
                                   'set_data', req.body)

    # DELETE /router/{switch_id}
    @rest_command
    def delete_data(self, req, switch_id, **_kwargs):
        return self._access_router(switch_id, VLANID_NONE,
                                   'delete_data', req.body)

    # DELETE /router/{switch_id}/{vlan_id}
    @rest_command
    def delete_vlan_data(self, req, switch_id, vlan_id, **_kwargs):
        return self._access_router(switch_id, vlan_id,
                                   'delete_data', req.body)

    def _access_router(self, switch_id, vlan_id, func, rest_param):
        rest_message = []
        routers = self._get_router(switch_id)
        param = eval(rest_param) if rest_param else {}
        for router in routers.values():
            function = getattr(router, func)
            data = function(vlan_id, param, self.waiters)
            rest_message.append(data)

        return rest_message

    def _get_router(self, switch_id):
        routers = {}

        if switch_id == REST_ALL:
            routers = self._ROUTER_LIST
        else:
            sw_id = dpid_lib.str_to_dpid(switch_id)
            if sw_id in self._ROUTER_LIST:
                routers = {sw_id: self._ROUTER_LIST[sw_id]}

        if routers:
            return routers
        else:
            raise NotFoundError(switch_id=switch_id)


class Router(dict):
    def __init__(self, dp, logger):
        super(Router, self).__init__()
        self.dp = dp
        self.dpid_str = dpid_lib.dpid_to_str(dp.id)
        self.sw_id = {'sw_id': self.dpid_str}
        self.logger = logger

        self.port_data = PortData(dp.ports)

        ofctl = OfCtl.factory(dp, logger)
        cookie = COOKIE_DEFAULT_ID

        # Set SW config: TTL error packet in (only OFPv1.2)
        ofctl.set_sw_config_for_ttl()

        # Set flow: ARP handling (packet in)
        priority = get_priority(PRIORITY_ARP_HANDLING)
        ofctl.set_packetin_flow(cookie, priority, dl_type=ether.ETH_TYPE_ARP)
        self.logger.info('Set ARP handling (packet in) flow [cookie=0x%x]',
                         cookie, extra=self.sw_id)

        # Set flow: L2 switching (normal)
        priority = get_priority(PRIORITY_NORMAL)
        ofctl.set_normal_flow(cookie, priority)
        self.logger.info('Set L2 switching (normal) flow [cookie=0x%x]',
                         cookie, extra=self.sw_id)

        # Set VlanRouter for vid=None.
        vlan_router = VlanRouter(VLANID_NONE, dp, self.port_data, logger)
        self[VLANID_NONE] = vlan_router

        # Start cyclic routing table check.
        self.thread = hub.spawn(self._cyclic_update_routing_tbl)
        self.logger.info('Start cyclic routing table update.',
                         extra=self.sw_id)

    def delete(self):
        hub.kill(self.thread)
        self.thread.wait()
        self.logger.info('Stop cyclic routing table update.',
                         extra=self.sw_id)

    def _get_vlan_router(self, vlan_id):
        vlan_routers = []

        if vlan_id == REST_ALL:
            vlan_routers = self.values()
        else:
            vlan_id = int(vlan_id)
            if (vlan_id != VLANID_NONE and
                    (vlan_id < VLANID_MIN or VLANID_MAX < vlan_id)):
                msg = 'Invalid {vlan_id} value. Set [%d-%d]'
                raise ValueError(msg % (VLANID_MIN, VLANID_MAX))
            elif vlan_id in self:
                vlan_routers = [self[vlan_id]]

        return vlan_routers

    def _add_vlan_router(self, vlan_id):
        vlan_id = int(vlan_id)
        if vlan_id not in self:
            vlan_router = VlanRouter(vlan_id, self.dp, self.port_data,
                                     self.logger)
            self[vlan_id] = vlan_router
        return self[vlan_id]

    def _del_vlan_router(self, vlan_id, waiters):
        #  Remove unnecessary VlanRouter.
        if vlan_id == VLANID_NONE:
            return

        vlan_router = self[vlan_id]
        if (len(vlan_router.address_data) == 0
                and len(vlan_router.routing_tbl) == 0):
            vlan_router.delete(waiters)
            del self[vlan_id]

    def get_data(self, vlan_id, dummy1, dummy2):
        vlan_routers = self._get_vlan_router(vlan_id)
        if vlan_routers:
            msgs = [vlan_router.get_data() for vlan_router in vlan_routers]
        else:
            msgs = [{REST_VLANID: vlan_id}]

        return {REST_SWITCHID: self.dpid_str,
                REST_NW: msgs}

    def set_data(self, vlan_id, param, waiters):
        vlan_routers = self._get_vlan_router(vlan_id)
        if not vlan_routers:
            vlan_routers = [self._add_vlan_router(vlan_id)]

        msgs = []
        for vlan_router in vlan_routers:
            try:
                msg = vlan_router.set_data(param)
                msgs.append(msg)
                if msg[REST_RESULT] == REST_NG:
                    # Data setting is failure.
                    self._del_vlan_router(vlan_router.vlan_id, waiters)
            except ValueError as err_msg:
                # Data setting is failure.
                self._del_vlan_router(vlan_router.vlan_id, waiters)
                raise err_msg

        return {REST_SWITCHID: self.dpid_str,
                REST_COMMAND_RESULT: msgs}

    def delete_data(self, vlan_id, param, waiters):
        msgs = []
        vlan_routers = self._get_vlan_router(vlan_id)
        if vlan_routers:
            for vlan_router in vlan_routers:
                msg = vlan_router.delete_data(param, waiters)
                if msg:
                    msgs.append(msg)
                # Check unnecessary VlanRouter.
                self._del_vlan_router(vlan_router.vlan_id, waiters)
        if not msgs:
            msgs = [{REST_RESULT: REST_NG,
                     REST_DETAILS: 'Data is nothing.'}]

        return {REST_SWITCHID: self.dpid_str,
                REST_COMMAND_RESULT: msgs}

    def packet_in_handler(self, msg):
        pkt = packet.Packet(msg.data)
        #TODO: Packet library convert to string
        #self.logger.debug('Packet in = %s', str(pkt), self.sw_id)
        header_list = dict((p.protocol_name, p)
                           for p in pkt.protocols if type(p) != str)
        if header_list:
            # Check vlan-tag
            vlan_id = VLANID_NONE
            if VLAN in header_list:
                vlan_id = header_list[VLAN].vid

            # Event dispatch
            if vlan_id in self:
                self[vlan_id].packet_in_handler(msg, header_list)
            else:
                self.logger.debug('Drop unknown vlan packet. [vlan_id=%d]',
                                  vlan_id, extra=self.sw_id)

    def _cyclic_update_routing_tbl(self):
        while True:
            # send ARP to all gateways.
            for vlan_router in self.values():
                vlan_router.send_arp_all_gw()
                hub.sleep(1)

            hub.sleep(CHK_ROUTING_TBL_INTERVAL)


class VlanRouter(object):
    def __init__(self, vlan_id, dp, port_data, logger):
        super(VlanRouter, self).__init__()
        self.vlan_id = vlan_id
        self.dp = dp
        self.sw_id = {'sw_id': dpid_lib.dpid_to_str(dp.id)}
        self.logger = logger

        self.port_data = port_data
        self.address_data = AddressData()
        self.routing_tbl = RoutingTable()
        self.packet_buffer = SuspendPacketList(self.send_icmp_unreach_error)
        self.ofctl = OfCtl.factory(dp, logger)

        # Set flow: default route (drop)
        self._set_defaultroute_drop()

    def delete(self, waiters):
        # Delete flow.
        msgs = self.ofctl.get_all_flow(waiters)
        for msg in msgs:
            for stats in msg.body:
                vlan_id = VlanRouter._cookie_to_id(REST_VLANID, stats.cookie)
                if vlan_id == self.vlan_id:
                    self.ofctl.delete_flow(stats)

        assert len(self.packet_buffer) == 0

    @staticmethod
    def _cookie_to_id(id_type, cookie):
        if id_type == REST_VLANID:
            rest_id = cookie >> COOKIE_SHIFT_VLANID
        elif id_type == REST_ADDRESSID:
            rest_id = cookie & UINT32_MAX
        else:
            assert id_type == REST_ROUTEID
            rest_id = (cookie & UINT32_MAX) >> COOKIE_SHIFT_ROUTEID

        return rest_id

    def _id_to_cookie(self, id_type, rest_id):
        vid = self.vlan_id << COOKIE_SHIFT_VLANID

        if id_type == REST_VLANID:
            cookie = rest_id << COOKIE_SHIFT_VLANID
        elif id_type == REST_ADDRESSID:
            cookie = vid + rest_id
        else:
            assert id_type == REST_ROUTEID
            cookie = vid + (rest_id << COOKIE_SHIFT_ROUTEID)

        return cookie

    def _get_priority(self, priority_type, route=None):
        return get_priority(priority_type, vid=self.vlan_id, route=route)

    def _response(self, msg):
        if msg and self.vlan_id:
            msg.setdefault(REST_VLANID, self.vlan_id)
        return msg

    def get_data(self):
        address_data = self._get_address_data()
        routing_data = self._get_routing_data()

        data = {}
        if address_data[REST_ADDRESS]:
            data.update(address_data)
        if routing_data[REST_ROUTE]:
            data.update(routing_data)

        return self._response(data)

    def _get_address_data(self):
        address_data = []
        for value in self.address_data.values():
            default_gw = ip_addr_ntoa(value.default_gw)
            address = '%s/%d' % (default_gw, value.netmask)
            data = {REST_ADDRESSID: value.address_id,
                    REST_ADDRESS: address}
            address_data.append(data)
        return {REST_ADDRESS: address_data}

    def _get_routing_data(self):
        routing_data = []
        for key, value in self.routing_tbl.items():
            if value.gateway_mac is not None:
                gateway = ip_addr_ntoa(value.gateway_ip)
                data = {REST_ROUTEID: value.route_id,
                        REST_DESTINATION: key,
                        REST_GATEWAY: gateway}
                routing_data.append(data)
        return {REST_ROUTE: routing_data}

    def set_data(self, data):
        details = None

        try:
            # Set address data
            if REST_ADDRESS in data:
                address = data[REST_ADDRESS]
                address_id = self._set_address_data(address)
                details = 'Add address [address_id=%d]' % address_id
            # Set routing data
            elif REST_GATEWAY in data:
                gateway = data[REST_GATEWAY]
                if REST_DESTINATION in data:
                    destination = data[REST_DESTINATION]
                else:
                    destination = DEFAULT_ROUTE
                route_id = self._set_routing_data(destination, gateway)
                details = 'Add route [route_id=%d]' % route_id

        except CommandFailure as err_msg:
            msg = {REST_RESULT: REST_NG, REST_DETAILS: str(err_msg)}
            return self._response(msg)

        if details is not None:
            msg = {REST_RESULT: REST_OK, REST_DETAILS: details}
            return self._response(msg)
        else:
            raise ValueError('Invalid parameter.')

    def _set_address_data(self, address):
        address = self.address_data.add(address)

        cookie = self._id_to_cookie(REST_ADDRESSID, address.address_id)

        # Set flow: host MAC learning (packet in)
        priority = self._get_priority(PRIORITY_MAC_LEARNING)
        self.ofctl.set_packetin_flow(cookie, priority,
                                     dl_type=ether.ETH_TYPE_IP,
                                     dl_vlan=self.vlan_id,
                                     dst_ip=address.nw_addr,
                                     dst_mask=address.netmask)
        log_msg = 'Set host MAC learning (packet in) flow [cookie=0x%x]'
        self.logger.info(log_msg, cookie, extra=self.sw_id)

        # set Flow: IP handling(PacketIn)
        priority = self._get_priority(PRIORITY_IP_HANDLING)
        self.ofctl.set_packetin_flow(cookie, priority,
                                     dl_type=ether.ETH_TYPE_IP,
                                     dl_vlan=self.vlan_id,
                                     dst_ip=address.default_gw)
        self.logger.info('Set IP handling (packet in) flow [cookie=0x%x]',
                         cookie, extra=self.sw_id)

        # Set flow: L2 switching (normal)
        outport = self.ofctl.dp.ofproto.OFPP_NORMAL
        priority = self._get_priority(PRIORITY_L2_SWITCHING)
        self.ofctl.set_routing_flow(
            cookie, priority, outport, dl_vlan=self.vlan_id,
            nw_src=address.nw_addr, src_mask=address.netmask,
            nw_dst=address.nw_addr, dst_mask=address.netmask)
        self.logger.info('Set L2 switching (normal) flow [cookie=0x%x]',
                         cookie, extra=self.sw_id)

        # Send GARP
        self.send_arp_request(address.default_gw, address.default_gw)

        return address.address_id

    def _set_routing_data(self, destination, gateway):
        err_msg = 'Invalid [%s] value.' % REST_GATEWAY
        dst_ip = ip_addr_aton(gateway, err_msg=err_msg)
        address = self.address_data.get_data(ip=dst_ip)
        if address is None:
            msg = 'Gateway=%s\'s address is not registered.' % gateway
            raise CommandFailure(msg=msg)
        elif dst_ip == address.default_gw:
            msg = 'Gateway=%s is used as default gateway of address_id=%d'\
                % (gateway, address.address_id)
            raise CommandFailure(msg=msg)
        else:
            src_ip = address.default_gw
            route = self.routing_tbl.add(destination, gateway)
            self._set_route_packetin(route)
            self.send_arp_request(src_ip, dst_ip)
            return route.route_id

    def _set_defaultroute_drop(self):
        cookie = self._id_to_cookie(REST_VLANID, self.vlan_id)
        priority = self._get_priority(PRIORITY_DEFAULT_ROUTING)
        outport = None  # for drop
        self.ofctl.set_routing_flow(cookie, priority, outport,
                                    dl_vlan=self.vlan_id)
        self.logger.info('Set default route (drop) flow [cookie=0x%x]',
                         cookie, extra=self.sw_id)

    def _set_route_packetin(self, route):
        cookie = self._id_to_cookie(REST_ROUTEID, route.route_id)
        priority, log_msg = self._get_priority(PRIORITY_TYPE_ROUTE,
                                               route=route)
        self.ofctl.set_packetin_flow(cookie, priority,
                                     dl_type=ether.ETH_TYPE_IP,
                                     dl_vlan=self.vlan_id,
                                     dst_ip=route.dst_ip,
                                     dst_mask=route.netmask)
        self.logger.info('Set %s (packet in) flow [cookie=0x%x]', log_msg,
                         cookie, extra=self.sw_id)

    def delete_data(self, data, waiters):
        if REST_ROUTEID in data:
            route_id = data[REST_ROUTEID]
            msg = self._delete_routing_data(route_id, waiters)
        elif REST_ADDRESSID in data:
            address_id = data[REST_ADDRESSID]
            msg = self._delete_address_data(address_id, waiters)
        else:
            raise ValueError('Invalid parameter.')

        return self._response(msg)

    def _delete_address_data(self, address_id, waiters):
        if address_id != REST_ALL:
            try:
                address_id = int(address_id)
            except ValueError as e:
                err_msg = 'Invalid [%s] value. %s'
                raise ValueError(err_msg % (REST_ADDRESSID, e.message))

        skip_ids = self._chk_addr_relation_route(address_id)

        # Get all flow.
        delete_list = []
        msgs = self.ofctl.get_all_flow(waiters)
        max_id = UINT16_MAX
        for msg in msgs:
            for stats in msg.body:
                vlan_id = VlanRouter._cookie_to_id(REST_VLANID, stats.cookie)
                if vlan_id != self.vlan_id:
                    continue
                addr_id = VlanRouter._cookie_to_id(REST_ADDRESSID,
                                                   stats.cookie)
                if addr_id in skip_ids:
                    continue
                elif address_id == REST_ALL:
                    if addr_id <= COOKIE_DEFAULT_ID or max_id < addr_id:
                        continue
                elif address_id != addr_id:
                    continue
                delete_list.append(stats)

        delete_ids = []
        for flow_stats in delete_list:
            # Delete flow
            self.ofctl.delete_flow(flow_stats)
            address_id = VlanRouter._cookie_to_id(REST_ADDRESSID,
                                                  flow_stats.cookie)

            del_address = self.address_data.get_data(addr_id=address_id)
            if del_address is not None:
                # Clean up suspend packet threads.
                self.packet_buffer.delete(del_addr=del_address)

                # Delete data.
                self.address_data.delete(address_id)
                if address_id not in delete_ids:
                    delete_ids.append(address_id)

        msg = {}
        if delete_ids:
            delete_ids = ','.join(str(addr_id) for addr_id in delete_ids)
            details = 'Delete address [address_id=%s]' % delete_ids
            msg = {REST_RESULT: REST_OK, REST_DETAILS: details}

        if skip_ids:
            skip_ids = ','.join(str(addr_id) for addr_id in skip_ids)
            details = 'Skip delete (related route exist) [address_id=%s]'\
                % skip_ids
            if msg:
                msg[REST_DETAILS] += ', %s' % details
            else:
                msg = {REST_RESULT: REST_NG, REST_DETAILS: details}

        return msg

    def _delete_routing_data(self, route_id, waiters):
        if route_id != REST_ALL:
            try:
                route_id = int(route_id)
            except ValueError as e:
                err_msg = 'Invalid [%s] value. %s'
                raise ValueError(err_msg % (REST_ROUTEID, e.message))

        # Get all flow.
        msgs = self.ofctl.get_all_flow(waiters)

        delete_list = []
        for msg in msgs:
            for stats in msg.body:
                vlan_id = VlanRouter._cookie_to_id(REST_VLANID, stats.cookie)
                if vlan_id != self.vlan_id:
                    continue
                rt_id = VlanRouter._cookie_to_id(REST_ROUTEID, stats.cookie)
                if route_id == REST_ALL:
                    if rt_id == COOKIE_DEFAULT_ID:
                        continue
                elif route_id != rt_id:
                    continue
                delete_list.append(stats)

        # Delete flow.
        delete_ids = []
        for flow_stats in delete_list:
            self.ofctl.delete_flow(flow_stats)
            route_id = VlanRouter._cookie_to_id(REST_ROUTEID,
                                                flow_stats.cookie)
            self.routing_tbl.delete(route_id)
            if route_id not in delete_ids:
                delete_ids.append(route_id)

            # case: Default route deleted. -> set flow (drop)
            route_type = get_priority_type(flow_stats.priority,
                                           vid=self.vlan_id)
            if route_type == PRIORITY_DEFAULT_ROUTING:
                self._set_defaultroute_drop()

        msg = {}
        if delete_ids:
            delete_ids = ','.join(str(route_id) for route_id in delete_ids)
            details = 'Delete route [route_id=%s]' % delete_ids
            msg = {REST_RESULT: REST_OK, REST_DETAILS: details}

        return msg

    def _chk_addr_relation_route(self, address_id):
        # Check exist of related routing data.
        relate_list = []
        gateways = self.routing_tbl.get_gateways()
        for gateway in gateways:
            address = self.address_data.get_data(ip=gateway)
            if address is not None:
                if (address_id == REST_ALL
                        and address.address_id not in relate_list):
                    relate_list.append(address.address_id)
                elif address.address_id == address_id:
                    relate_list = [address_id]
                    break
        return relate_list

    def packet_in_handler(self, msg, header_list):
        # Check invalid TTL (only OpenFlow V1.2)
        ofproto = self.dp.ofproto
        if ofproto.OFP_VERSION == ofproto_v1_2.OFP_VERSION:
            if msg.reason == ofproto.OFPR_INVALID_TTL:
                self._packetin_invalid_ttl(msg, header_list)
                return

        # Analyze event type.
        if ARP in header_list:
            self._packetin_arp(msg, header_list)
            return

        if IPV4 in header_list:
            rt_ports = self.address_data.get_default_gw()
            if header_list[IPV4].dst in rt_ports:
                # Packet to router's port.
                if ICMP in header_list:
                    if header_list[ICMP].type == icmp.ICMP_ECHO_REQUEST:
                        self._packetin_icmp_req(msg, header_list)
                        return
                elif TCP in header_list or UDP in header_list:
                    self._packetin_tcp_udp(msg, header_list)
                    return
            else:
                # Packet to internal host or gateway router.
                self._packetin_to_node(msg, header_list)
                return

    def _packetin_arp(self, msg, header_list):
        src_addr = self.address_data.get_data(ip=header_list[ARP].src_ip)
        if src_addr is None:
            return

        # case: Receive ARP from the gateway
        #  Update routing table.
        # case: Receive ARP from an internal host
        #  Learning host MAC.
        gw_flg = self._update_routing_tbl(msg, header_list)
        if gw_flg is False:
            self._learning_host_mac(msg, header_list)

        # ARP packet handling.
        in_port = self.ofctl.get_packetin_inport(msg)
        src_ip = header_list[ARP].src_ip
        dst_ip = header_list[ARP].dst_ip
        srcip = ip_addr_ntoa(src_ip)
        dstip = ip_addr_ntoa(dst_ip)
        rt_ports = self.address_data.get_default_gw()

        if src_ip == dst_ip:
            # GARP -> packet forward (normal)
            output = self.ofctl.dp.ofproto.OFPP_NORMAL
            self.ofctl.send_packet_out(in_port, output, msg.data)

            self.logger.info('Receive GARP from [%s].', srcip,
                             extra=self.sw_id)
            self.logger.info('Send GARP (normal).', extra=self.sw_id)

        elif dst_ip not in rt_ports:
            dst_addr = self.address_data.get_data(ip=dst_ip)
            if (dst_addr is not None and
                    src_addr.address_id == dst_addr.address_id):
                # ARP from internal host -> packet forward (normal)
                output = self.ofctl.dp.ofproto.OFPP_NORMAL
                self.ofctl.send_packet_out(in_port, output, msg.data)

                self.logger.info('Receive ARP from an internal host [%s].',
                                 srcip, extra=self.sw_id)
                self.logger.info('Send ARP (normal)', extra=self.sw_id)
        else:
            if header_list[ARP].opcode == arp.ARP_REQUEST:
                # ARP request to router port -> send ARP reply
                src_mac = header_list[ARP].src_mac
                dst_mac = self.port_data[in_port].mac
                arp_target_mac = dst_mac
                output = in_port
                in_port = self.ofctl.dp.ofproto.OFPP_CONTROLLER

                self.ofctl.send_arp(arp.ARP_REPLY, self.vlan_id,
                                    dst_mac, src_mac, dst_ip, src_ip,
                                    arp_target_mac, in_port, output)

                log_msg = 'Receive ARP request from [%s] to router port [%s].'
                self.logger.info(log_msg, srcip, dstip, extra=self.sw_id)
                self.logger.info('Send ARP reply to [%s]', srcip,
                                 extra=self.sw_id)

            elif header_list[ARP].opcode == arp.ARP_REPLY:
                #  ARP reply to router port -> suspend packets forward
                log_msg = 'Receive ARP reply from [%s] to router port [%s].'
                self.logger.info(log_msg, srcip, dstip, extra=self.sw_id)

                packet_list = self.packet_buffer.get_data(src_ip)
                if packet_list:
                    # stop ARP reply wait thread.
                    for suspend_packet in packet_list:
                        self.packet_buffer.delete(pkt=suspend_packet)

                    # send suspend packet.
                    output = self.ofctl.dp.ofproto.OFPP_TABLE
                    for suspend_packet in packet_list:
                        self.ofctl.send_packet_out(suspend_packet.in_port,
                                                   output,
                                                   suspend_packet.data)
                        self.logger.info('Send suspend packet to [%s].',
                                         srcip, extra=self.sw_id)

    def _packetin_icmp_req(self, msg, header_list):
        # Send ICMP echo reply.
        in_port = self.ofctl.get_packetin_inport(msg)
        self.ofctl.send_icmp(in_port, header_list, self.vlan_id,
                             icmp.ICMP_ECHO_REPLY,
                             icmp.ICMP_ECHO_REPLY_CODE,
                             icmp_data=header_list[ICMP].data)

        srcip = ip_addr_ntoa(header_list[IPV4].src)
        dstip = ip_addr_ntoa(header_list[IPV4].dst)
        log_msg = 'Receive ICMP echo request from [%s] to router port [%s].'
        self.logger.info(log_msg, srcip, dstip, extra=self.sw_id)
        self.logger.info('Send ICMP echo reply to [%s].', srcip,
                         extra=self.sw_id)

    def _packetin_tcp_udp(self, msg, header_list):
        # Send ICMP port unreach error.
        in_port = self.ofctl.get_packetin_inport(msg)
        self.ofctl.send_icmp(in_port, header_list, self.vlan_id,
                             icmp.ICMP_DEST_UNREACH,
                             icmp.ICMP_PORT_UNREACH_CODE,
                             msg_data=msg.data)

        srcip = ip_addr_ntoa(header_list[IPV4].src)
        dstip = ip_addr_ntoa(header_list[IPV4].dst)
        self.logger.info('Receive TCP/UDP from [%s] to router port [%s].',
                         srcip, dstip, extra=self.sw_id)
        self.logger.info('Send ICMP destination unreachable to [%s].', srcip,
                         extra=self.sw_id)

    def _packetin_to_node(self, msg, header_list):
        if len(self.packet_buffer) >= MAX_SUSPENDPACKETS:
            self.logger.info('Packet is dropped, MAX_SUSPENDPACKETS exceeded.',
                             extra=self.sw_id)
            return

        # Send ARP request to get node MAC address.
        in_port = self.ofctl.get_packetin_inport(msg)
        src_ip = None
        dst_ip = header_list[IPV4].dst
        srcip = ip_addr_ntoa(header_list[IPV4].src)
        dstip = ip_addr_ntoa(dst_ip)

        address = self.address_data.get_data(ip=dst_ip)
        if address is not None:
            log_msg = 'Receive IP packet from [%s] to an internal host [%s].'
            self.logger.info(log_msg, srcip, dstip, extra=self.sw_id)
            src_ip = address.default_gw
        else:
            route = self.routing_tbl.get_data(dst_ip=dst_ip)
            if route is not None:
                log_msg = 'Receive IP packet from [%s] to [%s].'
                self.logger.info(log_msg, srcip, dstip, extra=self.sw_id)
                gw_address = self.address_data.get_data(ip=route.gateway_ip)
                if gw_address is not None:
                    src_ip = gw_address.default_gw
                    dst_ip = route.gateway_ip

        if src_ip is not None:
            self.packet_buffer.add(in_port, header_list, msg.data)
            self.send_arp_request(src_ip, dst_ip, in_port=in_port)
            self.logger.info('Send ARP request (flood)', extra=self.sw_id)

    def _packetin_invalid_ttl(self, msg, header_list):
        # Send ICMP TTL error.
        srcip = ip_addr_ntoa(header_list[IPV4].src)
        self.logger.info('Receive invalid ttl packet from [%s].', srcip,
                         extra=self.sw_id)

        in_port = self.ofctl.get_packetin_inport(msg)
        src_ip = self._get_send_port_ip(header_list)
        if src_ip is not None:
            self.ofctl.send_icmp(in_port, header_list, self.vlan_id,
                                 icmp.ICMP_TIME_EXCEEDED,
                                 icmp.ICMP_TTL_EXPIRED_CODE,
                                 msg_data=msg.data, src_ip=src_ip)
            self.logger.info('Send ICMP time exceeded to [%s].', srcip,
                             extra=self.sw_id)

    def send_arp_all_gw(self):
        gateways = self.routing_tbl.get_gateways()
        for gateway in gateways:
            address = self.address_data.get_data(ip=gateway)
            self.send_arp_request(address.default_gw, gateway)

    def send_arp_request(self, src_ip, dst_ip, in_port=None):
        # Send ARP request from all ports.
        for send_port in self.port_data.values():
            if in_port is None or in_port != send_port.port_no:
                src_mac = send_port.mac
                dst_mac = mac_lib.BROADCAST_STR
                arp_target_mac = mac_lib.DONTCARE_STR
                inport = self.ofctl.dp.ofproto.OFPP_CONTROLLER
                output = send_port.port_no
                self.ofctl.send_arp(arp.ARP_REQUEST, self.vlan_id,
                                    src_mac, dst_mac, src_ip, dst_ip,
                                    arp_target_mac, inport, output)

    def send_icmp_unreach_error(self, packet_buffer):
        # Send ICMP host unreach error.
        self.logger.info('ARP reply wait timer was timed out.',
                         extra=self.sw_id)
        src_ip = self._get_send_port_ip(packet_buffer.header_list)
        if src_ip is not None:
            self.ofctl.send_icmp(packet_buffer.in_port,
                                 packet_buffer.header_list,
                                 self.vlan_id,
                                 icmp.ICMP_DEST_UNREACH,
                                 icmp.ICMP_HOST_UNREACH_CODE,
                                 msg_data=packet_buffer.data,
                                 src_ip=src_ip)

            dstip = ip_addr_ntoa(packet_buffer.dst_ip)
            self.logger.info('Send ICMP destination unreachable to [%s].',
                             dstip, extra=self.sw_id)

    def _update_routing_tbl(self, msg, header_list):
        # Set flow: routing to gateway.
        out_port = self.ofctl.get_packetin_inport(msg)
        src_mac = header_list[ARP].src_mac
        dst_mac = self.port_data[out_port].mac
        src_ip = header_list[ARP].src_ip

        gateway_flg = False
        for key, value in self.routing_tbl.items():
            if value.gateway_ip == src_ip:
                gateway_flg = True
                if value.gateway_mac == src_mac:
                    continue
                self.routing_tbl[key].gateway_mac = src_mac

                cookie = self._id_to_cookie(REST_ROUTEID, value.route_id)
                priority, log_msg = self._get_priority(PRIORITY_TYPE_ROUTE,
                                                       route=value)
                self.ofctl.set_routing_flow(cookie, priority, out_port,
                                            dl_vlan=self.vlan_id,
                                            src_mac=dst_mac,
                                            dst_mac=src_mac,
                                            nw_dst=value.dst_ip,
                                            dst_mask=value.netmask,
                                            dec_ttl=True)
                self.logger.info('Set %s flow [cookie=0x%x]', log_msg, cookie,
                                 extra=self.sw_id)
        return gateway_flg

    def _learning_host_mac(self, msg, header_list):
        # Set flow: routing to internal Host.
        out_port = self.ofctl.get_packetin_inport(msg)
        src_mac = header_list[ARP].src_mac
        dst_mac = self.port_data[out_port].mac
        src_ip = header_list[ARP].src_ip

        gateways = self.routing_tbl.get_gateways()
        if src_ip not in gateways:
            address = self.address_data.get_data(ip=src_ip)
            if address is not None:
                cookie = self._id_to_cookie(REST_ADDRESSID, address.address_id)
                priority = self._get_priority(PRIORITY_IMPLICIT_ROUTING)
                self.ofctl.set_routing_flow(cookie, priority,
                                            out_port, dl_vlan=self.vlan_id,
                                            src_mac=dst_mac, dst_mac=src_mac,
                                            nw_dst=src_ip,
                                            idle_timeout=IDLE_TIMEOUT,
                                            dec_ttl=True)
                self.logger.info('Set implicit routing flow [cookie=0x%x]',
                                 cookie, extra=self.sw_id)

    def _get_send_port_ip(self, header_list):
        try:
            src_mac = header_list[ETHERNET].src
            if IPV4 in header_list:
                src_ip = header_list[IPV4].src
            else:
                src_ip = header_list[ARP].src_ip
        except KeyError:
            self.logger.debug('Receive unsupported packet.', extra=self.sw_id)
            return None

        address = self.address_data.get_data(ip=src_ip)
        if address is not None:
            return address.default_gw
        else:
            route = self.routing_tbl.get_data(gw_mac=src_mac)
            if route is not None:
                address = self.address_data.get_data(ip=route.gateway_ip)
                if address is not None:
                    return address.default_gw

        self.logger.debug('Receive packet from unknown IP[%s].',
                          ip_addr_ntoa(src_ip), extra=self.sw_id)
        return None


class PortData(dict):
    def __init__(self, ports):
        super(PortData, self).__init__()
        for port in ports.values():
            data = Port(port.port_no, port.hw_addr)
            self[port.port_no] = data


class Port(object):
    def __init__(self, port_no, hw_addr):
        super(Port, self).__init__()
        self.port_no = port_no
        self.mac = hw_addr


class AddressData(dict):
    def __init__(self):
        super(AddressData, self).__init__()
        self.address_id = 1

    def add(self, address):
        err_msg = 'Invalid [%s] value.' % REST_ADDRESS
        nw_addr, mask, default_gw = nw_addr_aton(address, err_msg=err_msg)

        # Check overlaps
        for other in self.values():
            other_mask = mask_ntob(other.netmask)
            add_mask = mask_ntob(mask, err_msg=err_msg)
            if (other.nw_addr == ipv4_apply_mask(default_gw, other.netmask) or
                    nw_addr == ipv4_apply_mask(other.default_gw, mask,
                                               err_msg)):
                msg = 'Address overlaps [address_id=%d]' % other.address_id
                raise CommandFailure(msg=msg)

        address = Address(self.address_id, nw_addr, mask, default_gw)
        ip_str = ip_addr_ntoa(nw_addr)
        key = '%s/%d' % (ip_str, mask)
        self[key] = address

        self.address_id += 1
        self.address_id &= UINT32_MAX
        if self.address_id == COOKIE_DEFAULT_ID:
            self.address_id = 1

        return address

    def delete(self, address_id):
        for key, value in self.items():
            if value.address_id == address_id:
                del self[key]
                return

    def get_default_gw(self):
        return [address.default_gw for address in self.values()]

    def get_data(self, addr_id=None, ip=None):
        for address in self.values():
            if addr_id is not None:
                if addr_id == address.address_id:
                    return address
            else:
                assert ip is not None
                if ipv4_apply_mask(ip, address.netmask) == address.nw_addr:
                    return address
        return None


class Address(object):
    def __init__(self, address_id, nw_addr, netmask, default_gw):
        super(Address, self).__init__()
        self.address_id = address_id
        self.nw_addr = nw_addr
        self.netmask = netmask
        self.default_gw = default_gw

    def __contains__(self, ip):
        return bool(ipv4_apply_mask(ip, self.netmask) == self.nw_addr)


class RoutingTable(dict):
    def __init__(self):
        super(RoutingTable, self).__init__()
        self.route_id = 1

    def add(self, dst_nw_addr, gateway_ip):
        err_msg = 'Invalid [%s] value.'

        if dst_nw_addr == DEFAULT_ROUTE:
            dst_ip = 0
            netmask = 0
        else:
            dst_ip, netmask, dummy = nw_addr_aton(
                dst_nw_addr, err_msg=err_msg % REST_DESTINATION)

        gateway_ip = ip_addr_aton(gateway_ip, err_msg=err_msg % REST_GATEWAY)

        # Check overlaps
        overlap_route = None
        if dst_nw_addr == DEFAULT_ROUTE:
            if DEFAULT_ROUTE in self:
                overlap_route = self[DEFAULT_ROUTE].route_id
        elif dst_nw_addr in self:
            overlap_route = self[dst_nw_addr].route_id

        if overlap_route is not None:
            msg = 'Destination overlaps [route_id=%d]' % overlap_route
            raise CommandFailure(msg=msg)

        routing_data = Route(self.route_id, dst_ip, netmask, gateway_ip)
        ip_str = ip_addr_ntoa(dst_ip)
        key = '%s/%d' % (ip_str, netmask)
        self[key] = routing_data

        self.route_id += 1
        self.route_id &= UINT32_MAX
        if self.route_id == COOKIE_DEFAULT_ID:
            self.route_id = 1

        return routing_data

    def delete(self, route_id):
        for key, value in self.items():
            if value.route_id == route_id:
                del self[key]
                return

    def get_gateways(self):
        return [routing_data.gateway_ip for routing_data in self.values()]

    def get_data(self, gw_mac=None, dst_ip=None):
        if gw_mac is not None:
            for route in self.values():
                if gw_mac == route.gateway_mac:
                    return route
            return None

        elif dst_ip is not None:
            get_route = None
            mask = 0
            for route in self.values():
                if ipv4_apply_mask(dst_ip, route.netmask) == route.dst_ip:
                    # For longest match
                    if mask < route.netmask:
                        get_route = route
                        mask = route.netmask

            if get_route is None:
                get_route = self.get(DEFAULT_ROUTE, None)
            return get_route
        else:
            return None


class Route(object):
    def __init__(self, route_id, dst_ip, netmask, gateway_ip):
        super(Route, self).__init__()
        self.route_id = route_id
        self.dst_ip = dst_ip
        self.netmask = netmask
        self.gateway_ip = gateway_ip
        self.gateway_mac = None


class SuspendPacketList(list):
    def __init__(self, timeout_function):
        super(SuspendPacketList, self).__init__()
        self.timeout_function = timeout_function

    def add(self, in_port, header_list, data):
        suspend_pkt = SuspendPacket(in_port, header_list, data,
                                    self.wait_arp_reply_timer)
        self.append(suspend_pkt)

    def delete(self, pkt=None, del_addr=None):
        if pkt is not None:
            del_list = [pkt]
        else:
            assert del_addr is not None
            del_list = [pkt for pkt in self if pkt.dst_ip in del_addr]

        for pkt in del_list:
            self.remove(pkt)
            hub.kill(pkt.wait_thread)
            pkt.wait_thread.wait()

    def get_data(self, dst_ip):
        return [pkt for pkt in self if pkt.dst_ip == dst_ip]

    def wait_arp_reply_timer(self, suspend_pkt):
        hub.sleep(ARP_REPLY_TIMER)
        if suspend_pkt in self:
            self.timeout_function(suspend_pkt)
            self.delete(pkt=suspend_pkt)


class SuspendPacket(object):
    def __init__(self, in_port, header_list, data, timer):
        super(SuspendPacket, self).__init__()
        self.in_port = in_port
        self.dst_ip = header_list[IPV4].dst
        self.header_list = header_list
        self.data = data
        # Start ARP reply wait timer.
        self.wait_thread = hub.spawn(timer, self)


class OfCtl(object):
    _OF_VERSIONS = {}

    @staticmethod
    def register_of_version(version):
        def _register_of_version(cls):
            OfCtl._OF_VERSIONS.setdefault(version, cls)
            return cls
        return _register_of_version

    @staticmethod
    def factory(dp, logger):
        of_version = dp.ofproto.OFP_VERSION
        if of_version in OfCtl._OF_VERSIONS:
            ofctl = OfCtl._OF_VERSIONS[of_version](dp, logger)
        else:
            raise OFPUnknownVersion(version=of_version)

        return ofctl

    def __init__(self, dp, logger):
        super(OfCtl, self).__init__()
        self.dp = dp
        self.sw_id = {'sw_id': dpid_lib.dpid_to_str(dp.id)}
        self.logger = logger

    def set_sw_config_for_ttl(self):
        # OpenFlow v1_2 only.
        pass

    def set_flow(self, cookie, priority, dl_type=0, dl_dst=0, dl_vlan=0,
                 nw_src=0, src_mask=32, nw_dst=0, dst_mask=32,
                 nw_proto=0, idle_timeout=0, actions=None):
        # Abstract method
        raise NotImplementedError()

    def send_arp(self, arp_opcode, vlan_id, src_mac, dst_mac,
                 src_ip, dst_ip, arp_target_mac, in_port, output):
        # Generate ARP packet
        if vlan_id != VLANID_NONE:
            ether_proto = ether.ETH_TYPE_8021Q
            pcp = 0
            cfi = 0
            vlan_ether = ether.ETH_TYPE_ARP
            v = vlan.vlan(pcp, cfi, vlan_id, vlan_ether)
        else:
            ether_proto = ether.ETH_TYPE_ARP
        hwtype = 1
        arp_proto = ether.ETH_TYPE_IP
        hlen = 6
        plen = 4

        pkt = packet.Packet()
        e = ethernet.ethernet(dst_mac, src_mac, ether_proto)
        a = arp.arp(hwtype, arp_proto, hlen, plen, arp_opcode,
                    src_mac, src_ip, arp_target_mac, dst_ip)
        pkt.add_protocol(e)
        if vlan_id != VLANID_NONE:
            pkt.add_protocol(v)
        pkt.add_protocol(a)
        pkt.serialize()

        # Send packet out
        self.send_packet_out(in_port, output, pkt.data, data_str=str(pkt))

    def send_icmp(self, in_port, protocol_list, vlan_id, icmp_type,
                  icmp_code, icmp_data=None, msg_data=None, src_ip=None):
        # Generate ICMP reply packet
        csum = 0
        offset = ethernet.ethernet._MIN_LEN

        if vlan_id != VLANID_NONE:
            ether_proto = ether.ETH_TYPE_8021Q
            pcp = 0
            cfi = 0
            vlan_ether = ether.ETH_TYPE_IP
            v = vlan.vlan(pcp, cfi, vlan_id, vlan_ether)
            offset += vlan.vlan._MIN_LEN
        else:
            ether_proto = ether.ETH_TYPE_IP

        eth = protocol_list[ETHERNET]
        e = ethernet.ethernet(eth.src, eth.dst, ether_proto)

        if icmp_data is None and msg_data is not None:
            ip_datagram = msg_data[offset:]
            if icmp_type == icmp.ICMP_DEST_UNREACH:
                icmp_data = icmp.dest_unreach(data_len=len(ip_datagram),
                                              data=ip_datagram)
            elif icmp_type == icmp.ICMP_TIME_EXCEEDED:
                icmp_data = icmp.TimeExceeded(data_len=len(ip_datagram),
                                              data=ip_datagram)

        ic = icmp.icmp(icmp_type, icmp_code, csum, data=icmp_data)

        ip = protocol_list[IPV4]
        if src_ip is None:
            src_ip = ip.dst
        ip_total_length = ip.header_length * 4 + ic._MIN_LEN
        if ic.data is not None:
            ip_total_length += ic.data._MIN_LEN
            if ic.data.data is not None:
                ip_total_length += + len(ic.data.data)
        i = ipv4.ipv4(ip.version, ip.header_length, ip.tos,
                      ip_total_length, ip.identification, ip.flags,
                      ip.offset, DEFAULT_TTL, inet.IPPROTO_ICMP, csum,
                      src_ip, ip.src)

        pkt = packet.Packet()
        pkt.add_protocol(e)
        if vlan_id != VLANID_NONE:
            pkt.add_protocol(v)
        pkt.add_protocol(i)
        pkt.add_protocol(ic)
        pkt.serialize()

        # Send packet out
        self.send_packet_out(in_port, self.dp.ofproto.OFPP_IN_PORT,
                             pkt.data, data_str=str(pkt))

    def send_packet_out(self, in_port, output, data, data_str=None):
        actions = [self.dp.ofproto_parser.OFPActionOutput(output, 0)]
        self.dp.send_packet_out(buffer_id=UINT32_MAX, in_port=in_port,
                                actions=actions, data=data)
        #TODO: Packet library convert to string
        #if data_str is None:
        #    data_str = str(packet.Packet(data))
        #self.logger.debug('Packet out = %s', data_str, extra=self.sw_id)

    def set_normal_flow(self, cookie, priority):
        out_port = self.dp.ofproto.OFPP_NORMAL
        actions = [self.dp.ofproto_parser.OFPActionOutput(out_port, 0)]
        self.set_flow(cookie, priority, actions=actions)

    def set_packetin_flow(self, cookie, priority, dl_type=0, dl_dst=0,
                          dl_vlan=0, dst_ip=0, dst_mask=32, nw_proto=0):
        miss_send_len = UINT16_MAX
        actions = [self.dp.ofproto_parser.OFPActionOutput(
            self.dp.ofproto.OFPP_CONTROLLER, miss_send_len)]
        self.set_flow(cookie, priority, dl_type=dl_type, dl_dst=dl_dst,
                      dl_vlan=dl_vlan, nw_dst=dst_ip, dst_mask=dst_mask,
                      nw_proto=nw_proto, actions=actions)

    def send_stats_request(self, stats, waiters):
        self.dp.set_xid(stats)
        waiters_per_dp = waiters.setdefault(self.dp.id, {})
        event = hub.Event()
        msgs = []
        waiters_per_dp[stats.xid] = (event, msgs)
        self.dp.send_msg(stats)

        try:
            event.wait(timeout=OFP_REPLY_TIMER)
        except hub.Timeout:
            del waiters_per_dp[stats.xid]

        return msgs


@OfCtl.register_of_version(ofproto_v1_0.OFP_VERSION)
class OfCtl_v1_0(OfCtl):

    def __init__(self, dp, logger):
        super(OfCtl_v1_0, self).__init__(dp, logger)

    def get_packetin_inport(self, msg):
        return msg.in_port

    def get_all_flow(self, waiters):
        ofp = self.dp.ofproto
        ofp_parser = self.dp.ofproto_parser

        match = ofp_parser.OFPMatch(ofp.OFPFW_ALL, 0, 0, 0,
                                    0, 0, 0, 0, 0, 0, 0, 0, 0)
        stats = ofp_parser.OFPFlowStatsRequest(self.dp, 0, match,
                                               0xff, ofp.OFPP_NONE)
        return self.send_stats_request(stats, waiters)

    def set_flow(self, cookie, priority, dl_type=0, dl_dst=0, dl_vlan=0,
                 nw_src=0, src_mask=32, nw_dst=0, dst_mask=32,
                 nw_proto=0, idle_timeout=0, actions=None):
        ofp = self.dp.ofproto
        ofp_parser = self.dp.ofproto_parser
        cmd = ofp.OFPFC_ADD

        # Match
        wildcards = ofp.OFPFW_ALL
        if dl_type:
            wildcards &= ~ofp.OFPFW_DL_TYPE
        if dl_dst:
            wildcards &= ~ofp.OFPFW_DL_DST
        if dl_vlan:
            wildcards &= ~ofp.OFPFW_DL_VLAN
        if nw_src:
            v = (32 - src_mask) << ofp.OFPFW_NW_SRC_SHIFT | \
                ~ofp.OFPFW_NW_SRC_MASK
            wildcards &= v
            nw_src = ipv4_text_to_int(nw_src)
        if nw_dst:
            v = (32 - dst_mask) << ofp.OFPFW_NW_DST_SHIFT | \
                ~ofp.OFPFW_NW_DST_MASK
            wildcards &= v
            nw_dst = ipv4_text_to_int(nw_dst)
        if nw_proto:
            wildcards &= ~ofp.OFPFW_NW_PROTO

        match = ofp_parser.OFPMatch(wildcards, 0, 0, dl_dst, dl_vlan, 0,
                                    dl_type, 0, nw_proto,
                                    nw_src, nw_dst, 0, 0)
        actions = actions or []

        m = ofp_parser.OFPFlowMod(self.dp, match, cookie, cmd,
                                  idle_timeout=idle_timeout,
                                  priority=priority, actions=actions)
        self.dp.send_msg(m)

    def set_routing_flow(self, cookie, priority, outport, dl_vlan=0,
                         nw_src=0, src_mask=32, nw_dst=0, dst_mask=32,
                         src_mac=0, dst_mac=0, idle_timeout=0, **dummy):
        ofp_parser = self.dp.ofproto_parser

        dl_type = ether.ETH_TYPE_IP

        # Decrement TTL value is not supported at OpenFlow V1.0
        actions = []
        if src_mac:
            actions.append(ofp_parser.OFPActionSetDlSrc(
                           mac_lib.haddr_to_bin(src_mac)))
        if dst_mac:
            actions.append(ofp_parser.OFPActionSetDlDst(
                           mac_lib.haddr_to_bin(dst_mac)))
        if outport is not None:
            actions.append(ofp_parser.OFPActionOutput(outport))

        self.set_flow(cookie, priority, dl_type=dl_type, dl_vlan=dl_vlan,
                      nw_src=nw_src, src_mask=src_mask,
                      nw_dst=nw_dst, dst_mask=dst_mask,
                      idle_timeout=idle_timeout, actions=actions)

    def delete_flow(self, flow_stats):
        match = flow_stats.match
        cookie = flow_stats.cookie
        cmd = self.dp.ofproto.OFPFC_DELETE_STRICT
        priority = flow_stats.priority
        actions = []

        flow_mod = self.dp.ofproto_parser.OFPFlowMod(
            self.dp, match, cookie, cmd, priority=priority, actions=actions)
        self.dp.send_msg(flow_mod)
        self.logger.info('Delete flow [cookie=0x%x]', cookie, extra=self.sw_id)


@OfCtl.register_of_version(ofproto_v1_2.OFP_VERSION)
class OfCtl_v1_2(OfCtl):

    def __init__(self, dp, logger):
        super(OfCtl_v1_2, self).__init__(dp, logger)

    def set_sw_config_for_ttl(self):
        flags = self.dp.ofproto.OFPC_INVALID_TTL_TO_CONTROLLER
        miss_send_len = UINT16_MAX
        m = self.dp.ofproto_parser.OFPSetConfig(self.dp, flags,
                                                miss_send_len)
        self.dp.send_msg(m)
        self.logger.info('Set SW config for TTL error packet in.',
                         extra=self.sw_id)

    def get_packetin_inport(self, msg):
        in_port = self.dp.ofproto.OFPP_ANY
        for match_field in msg.match.fields:
            if match_field.header == self.dp.ofproto.OXM_OF_IN_PORT:
                in_port = match_field.value
                break
        return in_port

    def get_all_flow(self, waiters):
        ofp = self.dp.ofproto
        ofp_parser = self.dp.ofproto_parser

        match = ofp_parser.OFPMatch()
        stats = ofp_parser.OFPFlowStatsRequest(self.dp, 0, ofp.OFPP_ANY,
                                               ofp.OFPG_ANY, 0, 0, match)
        return self.send_stats_request(stats, waiters)

    def set_flow(self, cookie, priority, dl_type=0, dl_dst=0, dl_vlan=0,
                 nw_src=0, src_mask=32, nw_dst=0, dst_mask=32,
                 nw_proto=0, idle_timeout=0, actions=None):
        ofp = self.dp.ofproto
        ofp_parser = self.dp.ofproto_parser
        cmd = ofp.OFPFC_ADD

        # Match
        match = ofp_parser.OFPMatch()
        if dl_type:
            match.set_dl_type(dl_type)
        if dl_dst:
            match.set_dl_dst(dl_dst)
        if dl_vlan:
            match.set_vlan_vid(dl_vlan)
        if nw_src:
            match.set_ipv4_src_masked(ipv4_text_to_int(nw_src),
                                      mask_ntob(src_mask))
        if nw_dst:
            match.set_ipv4_dst_masked(ipv4_text_to_int(nw_dst),
                                      mask_ntob(dst_mask))
        if nw_proto:
            if dl_type == ether.ETH_TYPE_IP:
                match.set_ip_proto(nw_proto)
            elif dl_type == ether.ETH_TYPE_ARP:
                match.set_arp_opcode(nw_proto)

        # Instructions
        actions = actions or []
        inst = [ofp_parser.OFPInstructionActions(ofp.OFPIT_APPLY_ACTIONS,
                                                 actions)]

        m = ofp_parser.OFPFlowMod(self.dp, cookie, 0, 0, cmd, idle_timeout,
                                  0, priority, UINT32_MAX, ofp.OFPP_ANY,
                                  ofp.OFPG_ANY, 0, match, inst)
        self.dp.send_msg(m)

    def set_routing_flow(self, cookie, priority, outport, dl_vlan=0,
                         nw_src=0, src_mask=32, nw_dst=0, dst_mask=32,
                         src_mac=0, dst_mac=0, idle_timeout=0, dec_ttl=False):
        ofp = self.dp.ofproto
        ofp_parser = self.dp.ofproto_parser

        dl_type = ether.ETH_TYPE_IP

        actions = []
        if dec_ttl:
            actions.append(ofp_parser.OFPActionDecNwTtl())
        if src_mac:
            actions.append(ofp_parser.OFPActionSetField(eth_src=src_mac))
        if dst_mac:
            actions.append(ofp_parser.OFPActionSetField(eth_dst=dst_mac))
        if outport is not None:
            actions.append(ofp_parser.OFPActionOutput(outport, 0))

        self.set_flow(cookie, priority, dl_type=dl_type, dl_vlan=dl_vlan,
                      nw_src=nw_src, src_mask=src_mask,
                      nw_dst=nw_dst, dst_mask=dst_mask,
                      idle_timeout=idle_timeout, actions=actions)

    def delete_flow(self, flow_stats):
        ofp = self.dp.ofproto
        ofp_parser = self.dp.ofproto_parser

        cmd = ofp.OFPFC_DELETE
        cookie = flow_stats.cookie
        cookie_mask = UINT64_MAX
        match = ofp_parser.OFPMatch()
        inst = []

        flow_mod = ofp_parser.OFPFlowMod(self.dp, cookie, cookie_mask, 0, cmd,
                                         0, 0, 0, UINT32_MAX, ofp.OFPP_ANY,
                                         ofp.OFPG_ANY, 0, match, inst)
        self.dp.send_msg(flow_mod)
        self.logger.info('Delete flow [cookie=0x%x]', cookie, extra=self.sw_id)


def ip_addr_aton(ip_str, err_msg=None):
    try:
        return addrconv.ipv4.bin_to_text(socket.inet_aton(ip_str))
    except (struct.error, socket.error) as e:
        if err_msg is not None:
            e.message = '%s %s' % (err_msg, e.message)
        raise ValueError(e.message)


def ip_addr_ntoa(ip):
    return socket.inet_ntoa(addrconv.ipv4.text_to_bin(ip))


def mask_ntob(mask, err_msg=None):
    try:
        return (UINT32_MAX << (32 - mask)) & UINT32_MAX
    except ValueError:
        msg = 'illegal netmask'
        if err_msg is not None:
            msg = '%s %s' % (err_msg, msg)
        raise ValueError(msg)


def ipv4_apply_mask(address, prefix_len, err_msg=None):
    import itertools

    assert isinstance(address, str)
    address_int = ipv4_text_to_int(address)
    return ipv4_int_to_text(address_int & mask_ntob(prefix_len, err_msg))


def ipv4_int_to_text(ip_int):
    assert isinstance(ip_int, (int, long))
    return addrconv.ipv4.bin_to_text(struct.pack('!I', ip_int))


def ipv4_text_to_int(ip_text):
    if ip_text == 0:
        return ip_text
    assert isinstance(ip_text, str)
    return struct.unpack('!I', addrconv.ipv4.text_to_bin(ip_text))[0]


def nw_addr_aton(nw_addr, err_msg=None):
    ip_mask = nw_addr.split('/')
    default_route = ip_addr_aton(ip_mask[0], err_msg=err_msg)
    netmask = 32
    if len(ip_mask) == 2:
        try:
            netmask = int(ip_mask[1])
        except ValueError as e:
            if err_msg is not None:
                e.message = '%s %s' % (err_msg, e.message)
            raise ValueError(e.message)
    if netmask < 0:
        msg = 'illegal netmask'
        if err_msg is not None:
            msg = '%s %s' % (err_msg, msg)
        raise ValueError(msg)
    nw_addr = ipv4_apply_mask(default_route, netmask, err_msg)
    return nw_addr, netmask, default_route

########NEW FILE########
__FILENAME__ = rest_topology
# Copyright (C) 2013 Nippon Telegraph and Telephone Corporation.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import json
from webob import Response

from ryu.app.wsgi import ControllerBase, WSGIApplication
from ryu.base import app_manager
from ryu.lib import dpid as dpid_lib
from ryu.lib import port_no as port_no_lib
from ryu.topology.switches import get_switch, get_link

# REST API for switch configuration
#
# get all the switches
# GET /v1.0/topology/switches
#
# get the switch
# GET /v1.0/topology/switches/<dpid>
#
# get all the links
# GET /v1.0/topology/links
#
# get the links of a switch
# GET /v1.0/topology/links/<dpid>
#
# where
# <dpid>: datapath id in 16 hex


class TopologyController(ControllerBase):
    def __init__(self, req, link, data, **config):
        super(TopologyController, self).__init__(req, link, data, **config)
        self.topology_api_app = data['topology_api_app']

    def list_switches(self, req, **kwargs):
        dpid = None
        if 'dpid' in kwargs:
            dpid = dpid_lib.str_to_dpid(kwargs['dpid'])
        switches = get_switch(self.topology_api_app, dpid)
        body = json.dumps([switch.to_dict() for switch in switches])
        return Response(content_type='application/json', body=body)

    def list_links(self, req, **kwargs):
        dpid = None
        if 'dpid' in kwargs:
            dpid = dpid_lib.str_to_dpid(kwargs['dpid'])
        links = get_link(self.topology_api_app, dpid)
        body = json.dumps([link.to_dict() for link in links])
        return Response(content_type='application/json', body=body)


class TopologyAPI(app_manager.RyuApp):
    _CONTEXTS = {
        'wsgi': WSGIApplication
    }

    def __init__(self, *args, **kwargs):
        super(TopologyAPI, self).__init__(*args, **kwargs)
        wsgi = kwargs['wsgi']
        mapper = wsgi.mapper

        controller = TopologyController
        wsgi.registory[controller.__name__] = {'topology_api_app': self}
        route_name = 'topology'

        uri = '/v1.0/topology/switches'
        mapper.connect(route_name, uri, controller=controller,
                       action='list_switches',
                       conditions=dict(method=['GET']))

        uri = '/v1.0/topology/switches/{dpid}'
        requirements = {'dpid': dpid_lib.DPID_PATTERN}
        s = mapper.submapper(controller=controller, requirements=requirements)
        s.connect(route_name, uri, action='list_switches',
                  conditions=dict(method=['GET']))

        uri = '/v1.0/topology/links'
        mapper.connect(route_name, uri, controller=controller,
                       action='list_links',
                       conditions=dict(method=['GET']))

        uri = '/v1.0/topology/links/{dpid}'
        requirements = {'dpid': dpid_lib.DPID_PATTERN}
        s = mapper.submapper(controller=controller, requirements=requirements)
        s.connect(route_name, uri, action='list_links',
                  conditions=dict(method=['GET']))

########NEW FILE########
__FILENAME__ = rest_tunnel
# Copyright (C) 2012 Nippon Telegraph and Telephone Corporation.
# Copyright (C) 2012 Isaku Yamahata <yamahata at private email ne jp>
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import json
from webob import Response

from ryu.app import wsgi as app_wsgi
from ryu.app.wsgi import ControllerBase, WSGIApplication
from ryu.base import app_manager
from ryu.controller import network
from ryu.controller import tunnels
import ryu.exception as ryu_exc
from ryu.lib import dpid as dpid_lib


# REST API for tunneling
#
# register tunnel key of this network
# Fail if the key is already registered
# POST /v1.0/tunnels/networks/{network-id}/key/{tunnel_key}
#
# register tunnel key of this network
# Success as nop even if the same key is already registered
# PUT /v1.0/tunnels/networks/{network-id}/key/{tunnel_key}
#
# return allocated tunnel key of this network
# GET /v1.0/tunnels/networks/{network-id}/key
#
# get the ports of dpid that are used for tunneling
# GET /v1.0/tunnels/switches/{dpid}/ports
#
# get the dpid of the other end of tunnel
# GET /v1.0/tunnels/switches/{dpid}/ports/{port-id}/
#
# register the dpid of the other end of tunnel
# Fail if the dpid is already registered
# POST /v1.0/tunnels/switches/{dpid}/ports/{port-id}/{remote_dpid}
#
# register the dpid of the other end of tunnel
# Success as nop even if the dpid is already registered
# PUT /v1.0/tunnels/switches/{dpid}/ports/{port-id}/{remote_dpid}


class TunnelKeyController(ControllerBase):
    def __init__(self, req, link, data, **config):
        super(TunnelKeyController, self).__init__(req, link, data, **config)
        self.tunnels = data

    def create(self, _req, network_id, tunnel_key, **_kwargs):
        tunnel_key = int(tunnel_key)
        try:
            self.tunnels.register_key(network_id, tunnel_key)
        except (ryu_exc.NetworkAlreadyExist, tunnels.TunnelKeyAlreadyExist):
            return Response(status=409)

        return Response(status=200)

    def update(self, _req, network_id, tunnel_key, **_kwargs):
        tunnel_key = int(tunnel_key)
        try:
            self.tunnels.update_key(network_id, tunnel_key)
        except (ryu_exc.NetworkAlreadyExist, tunnels.TunnelKeyAlreadyExist):
            return Response(status=409)

        return Response(status=200)

    def lists(self, _req, network_id, **_kwargs):
        try:
            tunnel_key = self.tunnels.get_key(network_id)
        except tunnels.TunnelKeyNotFound:
            return Response(status=404)
        body = json.dumps(tunnel_key)

        return Response(content_type='application/json', body=body)

    def delete(self, _req, network_id, **_kwargs):
        try:
            self.tunnels.delete_key(network_id)
        except (ryu_exc.NetworkNotFound, tunnels.TunnelKeyNotFound):
            return Response(status=404)

        return Response(status=200)


class TunnelPortController(ControllerBase):
    def __init__(self, req, link, data, **config):
        super(TunnelPortController, self).__init__(req, link, data, **config)
        self.tunnels = data

    def create(self, _req, dpid, port_id, remote_dpid, **_kwargs):
        dpid = dpid_lib.str_to_dpid(dpid)
        port_id = int(port_id)
        remote_dpid = dpid_lib.str_to_dpid(remote_dpid)
        try:
            self.tunnels.register_port(dpid, port_id, remote_dpid)
        except ryu_exc.PortAlreadyExist:
            return Response(status=409)

        return Response(status=200)

    def update(self, _req, dpid, port_id, remote_dpid, **_kwargs):
        dpid = dpid_lib.str_to_dpid(dpid)
        port_id = int(port_id)
        remote_dpid = dpid_lib.str_to_dpid(remote_dpid)
        try:
            self.tunnels.update_port(dpid, port_id, remote_dpid)
        except tunnels.RemoteDPIDAlreadyExist:
            return Response(status=409)

        return Response(status=200)

    def lists(self, _req, dpid, **_kwargs):
        dpid = dpid_lib.str_to_dpid(dpid)
        ports = self.tunnels.list_ports(dpid)
        body = json.dumps(ports)

        return Response(content_type='application/json', body=body)

    def get(self, _req, dpid, port_id, **_kwargs):
        dpid = dpid_lib.str_to_dpid(dpid)
        port_id = int(port_id)
        try:
            remote_dpid = self.tunnels.get_remote_dpid(dpid, port_id)
        except ryu_exc.PortNotFound:
            return Response(status=404)
        body = json.dumps(dpid_lib.dpid_to_str(remote_dpid))

        return Response(content_type='application/json', body=body)

    def delete(self, _req, dpid, port_id, **_kwargs):
        dpid = dpid_lib.str_to_dpid(dpid)
        port_id = int(port_id)
        try:
            self.tunnels.delete_port(dpid, port_id)
        except ryu_exc.PortNotFound:
            return Response(status=404)

        return Response(status=200)


class TunnelAPI(app_manager.RyuApp):
    _CONTEXTS = {
        'network': network.Network,
        'tunnels': tunnels.Tunnels,
        'wsgi': WSGIApplication
    }

    def __init__(self, *_args, **kwargs):
        super(TunnelAPI, self).__init__()
        self.nw = kwargs['network']
        self.tunnels = kwargs['tunnels']
        wsgi = kwargs['wsgi']
        mapper = wsgi.mapper

        controller = TunnelKeyController
        wsgi.registory[controller.__name__] = self.tunnels
        route_name = 'tunnel_key'
        uri = '/v1.0/tunnels'
        key_uri = uri + '/networks/{network_id}/key'
        s = mapper.submapper(controller=controller)
        s.connect(route_name, key_uri, action='lists',
                  conditions=dict(method=['GET', 'HEAD']))
        s.connect(route_name, key_uri, action='delete',
                  conditions=dict(method=['DELETE']))

        key_uri += '/{tunnel_key}'
        requirements = {route_name: app_wsgi.DIGIT_PATTERN}
        s = mapper.submapper(controller=controller, requirements=requirements)
        s.connect(route_name, key_uri, action='create',
                  conditions=dict(method=['POST']))
        s.connect(route_name, key_uri, action='update',
                  conditions=dict(method=['PUT']))

        controller = TunnelPortController
        wsgi.registory[controller.__name__] = self.tunnels
        route_name = 'tunnel_port'
        sw_uri = uri + '/switches/{dpid}/ports'
        requirements = {'dpid': dpid_lib.DPID_PATTERN}
        mapper.connect(route_name, sw_uri, controller=controller,
                       action='lists', conditions=dict(method=['GET', 'HEAD']),
                       requirements=requirements)

        sw_uri += '/{port_id}'
        requirements['port_id'] = app_wsgi.DIGIT_PATTERN
        s = mapper.submapper(controller=controller, requirements=requirements)
        mapper.connect(route_name, sw_uri, action='get',
                       conditions=dict(method=['GET', 'HEAD']))
        mapper.connect(route_name, sw_uri, action='delete',
                       conditions=dict(method=['DELETE']))

        sw_uri += '/{remote_dpid}'
        requirements['remote_dpid'] = dpid_lib.DPID_PATTERN
        s = mapper.submapper(controller=controller, requirements=requirements)
        mapper.connect(route_name, sw_uri, action='create',
                       conditions=dict(method=['POST']))
        mapper.connect(route_name, sw_uri, action='update',
                       conditions=dict(method=['PUT']))

########NEW FILE########
__FILENAME__ = simple_isolation
# Copyright (C) 2011 Nippon Telegraph and Telephone Corporation.
# Copyright (C) 2011, 2012 Isaku Yamahata <yamahata at valinux co jp>
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import logging
import struct

from ryu.app.rest_nw_id import NW_ID_UNKNOWN, NW_ID_EXTERNAL
from ryu.base import app_manager
from ryu.exception import MacAddressDuplicated
from ryu.exception import PortUnknown
from ryu.controller import dpset
from ryu.controller import mac_to_network
from ryu.controller import mac_to_port
from ryu.controller import network
from ryu.controller import ofp_event
from ryu.controller.handler import MAIN_DISPATCHER
from ryu.controller.handler import CONFIG_DISPATCHER
from ryu.controller.handler import set_ev_cls
from ryu.ofproto import nx_match
from ryu.lib.mac import haddr_to_str
from ryu.lib import mac


class SimpleIsolation(app_manager.RyuApp):
    _CONTEXTS = {
        'network': network.Network,
        'dpset': dpset.DPSet,
    }

    def __init__(self, *args, **kwargs):
        super(SimpleIsolation, self).__init__(*args, **kwargs)
        self.nw = kwargs['network']
        self.dpset = kwargs['dpset']
        self.mac2port = mac_to_port.MacToPortTable()
        self.mac2net = mac_to_network.MacToNetwork(self.nw)

    @set_ev_cls(ofp_event.EventOFPSwitchFeatures, CONFIG_DISPATCHER)
    def switch_features_handler(self, ev):
        msg = ev.msg
        datapath = msg.datapath

        datapath.send_delete_all_flows()
        datapath.send_barrier()

        self.mac2port.dpid_add(ev.msg.datapath_id)
        self.nw.add_datapath(ev.msg)

    @staticmethod
    def _modflow_and_send_packet(msg, src, dst, actions):
        datapath = msg.datapath
        ofproto = datapath.ofproto

        #
        # install flow and then send packet
        #
        rule = nx_match.ClsRule()
        rule.set_in_port(msg.in_port)
        rule.set_dl_dst(dst)
        rule.set_dl_src(src)
        datapath.send_flow_mod(
            rule=rule, cookie=0, command=datapath.ofproto.OFPFC_ADD,
            idle_timeout=0, hard_timeout=0,
            priority=ofproto.OFP_DEFAULT_PRIORITY,
            buffer_id=ofproto.OFP_NO_BUFFER, out_port=ofproto.OFPP_NONE,
            flags=ofproto.OFPFF_SEND_FLOW_REM, actions=actions)

        datapath.send_packet_out(msg.buffer_id, msg.in_port, actions)

    def _forward_to_nw_id(self, msg, src, dst, nw_id, out_port):
        assert out_port is not None
        datapath = msg.datapath

        if not self.nw.same_network(datapath.id, nw_id, out_port,
                                    NW_ID_EXTERNAL):
            self.logger.debug('packet is blocked src %s dst %s '
                              'from %d to %d on datapath %d',
                              haddr_to_str(src), haddr_to_str(dst),
                              msg.in_port, out_port, datapath.id)
            return

        self.logger.debug("learned dpid %s in_port %d out_port "
                          "%d src %s dst %s",
                          datapath.id, msg.in_port, out_port,
                          haddr_to_str(src), haddr_to_str(dst))
        actions = [datapath.ofproto_parser.OFPActionOutput(out_port)]
        self._modflow_and_send_packet(msg, src, dst, actions)

    def _flood_to_nw_id(self, msg, src, dst, nw_id):
        datapath = msg.datapath
        actions = []
        self.logger.debug("dpid %s in_port %d src %s dst %s ports %s",
                          datapath.id, msg.in_port,
                          haddr_to_str(src), haddr_to_str(dst),
                          self.nw.dpids.get(datapath.id, {}).items())
        for port_no in self.nw.filter_ports(datapath.id, msg.in_port,
                                            nw_id, NW_ID_EXTERNAL):
            self.logger.debug("port_no %s", port_no)
            actions.append(datapath.ofproto_parser.OFPActionOutput(port_no))
        self._modflow_and_send_packet(msg, src, dst, actions)

    def _learned_mac_or_flood_to_nw_id(self, msg, src, dst,
                                       dst_nw_id, out_port):
        if out_port is not None:
            self._forward_to_nw_id(msg, src, dst, dst_nw_id, out_port)
        else:
            self._flood_to_nw_id(msg, src, dst, dst_nw_id)

    def _modflow_and_drop_packet(self, msg, src, dst):
        self._modflow_and_send_packet(msg, src, dst, [])

    def _drop_packet(self, msg):
        datapath = msg.datapath
        datapath.send_packet_out(msg.buffer_id, msg.in_port, [])

    @set_ev_cls(ofp_event.EventOFPPacketIn, MAIN_DISPATCHER)
    def packet_in_handler(self, ev):
        # self.logger.debug('packet in ev %s msg %s', ev, ev.msg)
        msg = ev.msg
        datapath = msg.datapath
        ofproto = datapath.ofproto

        dst, src, _eth_type = struct.unpack_from('!6s6sH', buffer(msg.data), 0)

        try:
            port_nw_id = self.nw.get_network(datapath.id, msg.in_port)
        except PortUnknown:
            port_nw_id = NW_ID_UNKNOWN

        if port_nw_id != NW_ID_UNKNOWN:
            # Here it is assumed that the
            # (port <-> network id)/(mac <-> network id) relationship
            # is stable once the port is created. The port will be destroyed
            # before assigning new network id to the given port.
            # This is correct nova-network/nova-compute.
            try:
                # allow external -> known nw id change
                self.mac2net.add_mac(src, port_nw_id, NW_ID_EXTERNAL)
            except MacAddressDuplicated:
                self.logger.warn('mac address %s is already in use.'
                                 ' So (dpid %s, port %s) can not use it',
                                 haddr_to_str(src), datapath.id, msg.in_port)
                #
                # should we install drop action pro-actively for future?
                #
                self._drop_packet(msg)
                return

        old_port = self.mac2port.port_add(datapath.id, msg.in_port, src)
        if old_port is not None and old_port != msg.in_port:
            # We really overwrite already learned mac address.
            # So discard already installed stale flow entry which conflicts
            # new port.
            rule = nx_match.ClsRule()
            rule.set_dl_dst(src)
            datapath.send_flow_mod(rule=rule,
                                   cookie=0,
                                   command=ofproto.OFPFC_DELETE,
                                   idle_timeout=0,
                                   hard_timeout=0,
                                   priority=ofproto.OFP_DEFAULT_PRIORITY,
                                   out_port=old_port)

            # to make sure the old flow entries are purged.
            datapath.send_barrier()

        src_nw_id = self.mac2net.get_network(src, NW_ID_UNKNOWN)
        dst_nw_id = self.mac2net.get_network(dst, NW_ID_UNKNOWN)

        # we handle multicast packet as same as broadcast
        broadcast = (dst == mac.BROADCAST) or mac.is_multicast(dst)
        out_port = self.mac2port.port_get(datapath.id, dst)

        #
        # there are several combinations:
        # in_port: known nw_id, external, unknown nw,
        # src mac: known nw_id, external, unknown nw,
        # dst mac: known nw_id, external, unknown nw, and broadcast/multicast
        # where known nw_id: is quantum network id
        #       external: means that these ports are connected to outside
        #       unknown nw: means that we don't know this port is bounded to
        #                   specific nw_id or external
        #       broadcast: the destination mac address is broadcast address
        #                  (or multicast address)
        #
        # Can the following logic be refined/shortened?
        #

        # When NW_ID_UNKNOWN is found, registering ports might be delayed.
        # So just drop only this packet and not install flow entry.
        # It is expected that when next packet arrives, the port is registers
        # with some network id

        if port_nw_id != NW_ID_EXTERNAL and port_nw_id != NW_ID_UNKNOWN:
            if broadcast:
                # flood to all ports of external or src_nw_id
                self._flood_to_nw_id(msg, src, dst, src_nw_id)
            elif src_nw_id == NW_ID_EXTERNAL:
                self._modflow_and_drop_packet(msg, src, dst)
                return
            elif src_nw_id == NW_ID_UNKNOWN:
                self._drop_packet(msg)
                return
            else:
                # src_nw_id != NW_ID_EXTERNAL and src_nw_id != NW_ID_UNKNOWN:
                #
                # try learned mac check if the port is net_id
                # or
                # flood to all ports of external or src_nw_id
                self._learned_mac_or_flood_to_nw_id(msg, src, dst,
                                                    src_nw_id, out_port)

        elif port_nw_id == NW_ID_EXTERNAL:
            if src_nw_id != NW_ID_EXTERNAL and src_nw_id != NW_ID_UNKNOWN:
                if broadcast:
                    # flood to all ports of external or src_nw_id
                    self._flood_to_nw_id(msg, src, dst, src_nw_id)
                elif (dst_nw_id != NW_ID_EXTERNAL and
                      dst_nw_id != NW_ID_UNKNOWN):
                    if src_nw_id == dst_nw_id:
                        # try learned mac
                        # check if the port is external or same net_id
                        # or
                        # flood to all ports of external or src_nw_id
                        self._learned_mac_or_flood_to_nw_id(msg, src, dst,
                                                            src_nw_id,
                                                            out_port)
                    else:
                        # should not occur?
                        self.logger.debug("should this case happen?")
                        self._drop_packet(msg)
                elif dst_nw_id == NW_ID_EXTERNAL:
                    # try learned mac
                    # or
                    # flood to all ports of external or src_nw_id
                    self._learned_mac_or_flood_to_nw_id(msg, src, dst,
                                                        src_nw_id, out_port)
                else:
                    assert dst_nw_id == NW_ID_UNKNOWN
                    self.logger.debug("Unknown dst_nw_id")
                    self._drop_packet(msg)
            elif src_nw_id == NW_ID_EXTERNAL:
                self._modflow_and_drop_packet(msg, src, dst)
            else:
                # should not occur?
                assert src_nw_id == NW_ID_UNKNOWN
                self._drop_packet(msg)
        else:
            # drop packets
            assert port_nw_id == NW_ID_UNKNOWN
            self._drop_packet(msg)
            # self.logger.debug("Unknown port_nw_id")

    def _port_add(self, ev):
        #
        # delete flows entries that matches with
        # dl_dst == broadcast/multicast
        # and dl_src = network id if network id of this port is known
        # to send broadcast packet to this newly added port.
        #
        # Openflow v1.0 doesn't support masked match of dl_dst,
        # so delete all flow entries. It's inefficient, though.
        #
        msg = ev.msg
        datapath = msg.datapath

        datapath.send_delete_all_flows()
        datapath.send_barrier()
        self.nw.port_added(datapath, msg.desc.port_no)

    def _port_del(self, ev):
        # free mac addresses associated to this VM port,
        # and delete related flow entries for later reuse of mac address

        dps_needs_barrier = set()

        msg = ev.msg
        datapath = msg.datapath
        datapath_id = datapath.id
        port_no = msg.desc.port_no

        rule = nx_match.ClsRule()
        rule.set_in_port(port_no)
        datapath.send_flow_del(rule=rule, cookie=0)

        rule = nx_match.ClsRule()
        datapath.send_flow_del(rule=rule, cookie=0, out_port=port_no)
        dps_needs_barrier.add(datapath)

        try:
            port_nw_id = self.nw.get_network(datapath_id, port_no)
        except PortUnknown:
            # race condition between rest api delete port
            # and openflow port deletion ofp_event
            pass
        else:
            if port_nw_id in (NW_ID_UNKNOWN, NW_ID_EXTERNAL):
                datapath.send_barrier()
                return

        for mac_ in self.mac2port.mac_list(datapath_id, port_no):
            for (_dpid, dp) in self.dpset.get_all():
                if self.mac2port.port_get(dp.id, mac_) is None:
                    continue

                rule = nx_match.ClsRule()
                rule.set_dl_src(mac_)
                dp.send_flow_del(rule=rule, cookie=0)

                rule = nx_match.ClsRule()
                rule.set_dl_dst(mac_)
                dp.send_flow_del(rule=rule, cookie=0)
                dps_needs_barrier.add(dp)

                self.mac2port.mac_del(dp.id, mac_)

            self.mac2net.del_mac(mac_)

        self.nw.port_deleted(datapath.id, port_no)

        for dp in dps_needs_barrier:
            dp.send_barrier()

    @set_ev_cls(ofp_event.EventOFPPortStatus, MAIN_DISPATCHER)
    def port_status_handler(self, ev):
        msg = ev.msg
        reason = msg.reason
        ofproto = msg.datapath.ofproto

        if reason == ofproto.OFPPR_ADD:
            self._port_add(ev)
        elif reason == ofproto.OFPPR_DELETE:
            self._port_del(ev)
        else:
            assert reason == ofproto.OFPPR_MODIFY

########NEW FILE########
__FILENAME__ = simple_switch
# Copyright (C) 2011 Nippon Telegraph and Telephone Corporation.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import logging
import struct

from ryu.base import app_manager
from ryu.controller import mac_to_port
from ryu.controller import ofp_event
from ryu.controller.handler import MAIN_DISPATCHER
from ryu.controller.handler import set_ev_cls
from ryu.ofproto import ofproto_v1_0
from ryu.lib.mac import haddr_to_bin
from ryu.lib.packet import packet
from ryu.lib.packet import ethernet


class SimpleSwitch(app_manager.RyuApp):
    OFP_VERSIONS = [ofproto_v1_0.OFP_VERSION]

    def __init__(self, *args, **kwargs):
        super(SimpleSwitch, self).__init__(*args, **kwargs)
        self.mac_to_port = {}

    def add_flow(self, datapath, in_port, dst, actions):
        ofproto = datapath.ofproto

        match = datapath.ofproto_parser.OFPMatch(
            in_port=in_port, dl_dst=haddr_to_bin(dst))

        mod = datapath.ofproto_parser.OFPFlowMod(
            datapath=datapath, match=match, cookie=0,
            command=ofproto.OFPFC_ADD, idle_timeout=0, hard_timeout=0,
            priority=ofproto.OFP_DEFAULT_PRIORITY,
            flags=ofproto.OFPFF_SEND_FLOW_REM, actions=actions)
        datapath.send_msg(mod)

    @set_ev_cls(ofp_event.EventOFPPacketIn, MAIN_DISPATCHER)
    def _packet_in_handler(self, ev):
        msg = ev.msg
        datapath = msg.datapath
        ofproto = datapath.ofproto

        pkt = packet.Packet(msg.data)
        eth = pkt.get_protocol(ethernet.ethernet)

        dst = eth.dst
        src = eth.src

        dpid = datapath.id
        self.mac_to_port.setdefault(dpid, {})

        self.logger.info("packet in %s %s %s %s", dpid, src, dst, msg.in_port)

        # learn a mac address to avoid FLOOD next time.
        self.mac_to_port[dpid][src] = msg.in_port

        if dst in self.mac_to_port[dpid]:
            out_port = self.mac_to_port[dpid][dst]
        else:
            out_port = ofproto.OFPP_FLOOD

        actions = [datapath.ofproto_parser.OFPActionOutput(out_port)]

        # install a flow to avoid packet_in next time
        if out_port != ofproto.OFPP_FLOOD:
            self.add_flow(datapath, msg.in_port, dst, actions)

        out = datapath.ofproto_parser.OFPPacketOut(
            datapath=datapath, buffer_id=msg.buffer_id, in_port=msg.in_port,
            actions=actions)
        datapath.send_msg(out)

    @set_ev_cls(ofp_event.EventOFPPortStatus, MAIN_DISPATCHER)
    def _port_status_handler(self, ev):
        msg = ev.msg
        reason = msg.reason
        port_no = msg.desc.port_no

        ofproto = msg.datapath.ofproto
        if reason == ofproto.OFPPR_ADD:
            self.logger.info("port added %s", port_no)
        elif reason == ofproto.OFPPR_DELETE:
            self.logger.info("port deleted %s", port_no)
        elif reason == ofproto.OFPPR_MODIFY:
            self.logger.info("port modified %s", port_no)
        else:
            self.logger.info("Illeagal port state %s %s", port_no, reason)

########NEW FILE########
__FILENAME__ = simple_switch_12
# Copyright (C) 2011 Nippon Telegraph and Telephone Corporation.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import logging
import struct

from ryu.base import app_manager
from ryu.controller import ofp_event
from ryu.controller.handler import MAIN_DISPATCHER
from ryu.controller.handler import set_ev_cls
from ryu.ofproto import ofproto_v1_2
from ryu.lib.packet import packet
from ryu.lib.packet import ethernet


class SimpleSwitch12(app_manager.RyuApp):
    OFP_VERSIONS = [ofproto_v1_2.OFP_VERSION]

    def __init__(self, *args, **kwargs):
        super(SimpleSwitch12, self).__init__(*args, **kwargs)
        self.mac_to_port = {}

    def add_flow(self, datapath, port, dst, actions):
        ofproto = datapath.ofproto

        match = datapath.ofproto_parser.OFPMatch(in_port=port,
                                                 eth_dst=dst)
        inst = [datapath.ofproto_parser.OFPInstructionActions(
                ofproto.OFPIT_APPLY_ACTIONS, actions)]

        mod = datapath.ofproto_parser.OFPFlowMod(
            datapath=datapath, cookie=0, cookie_mask=0, table_id=0,
            command=ofproto.OFPFC_ADD, idle_timeout=0, hard_timeout=0,
            priority=0, buffer_id=ofproto.OFP_NO_BUFFER,
            out_port=ofproto.OFPP_ANY,
            out_group=ofproto.OFPG_ANY,
            flags=0, match=match, instructions=inst)
        datapath.send_msg(mod)

    @set_ev_cls(ofp_event.EventOFPPacketIn, MAIN_DISPATCHER)
    def _packet_in_handler(self, ev):
        msg = ev.msg
        datapath = msg.datapath
        ofproto = datapath.ofproto
        in_port = msg.match['in_port']

        pkt = packet.Packet(msg.data)
        eth = pkt.get_protocols(ethernet.ethernet)[0]

        dst = eth.dst
        src = eth.src

        dpid = datapath.id
        self.mac_to_port.setdefault(dpid, {})

        self.logger.info("packet in %s %s %s %s", dpid, src, dst, in_port)

        # learn a mac address to avoid FLOOD next time.
        self.mac_to_port[dpid][src] = in_port

        if dst in self.mac_to_port[dpid]:
            out_port = self.mac_to_port[dpid][dst]
        else:
            out_port = ofproto.OFPP_FLOOD

        actions = [datapath.ofproto_parser.OFPActionOutput(out_port)]

        # install a flow to avoid packet_in next time
        if out_port != ofproto.OFPP_FLOOD:
            self.add_flow(datapath, in_port, dst, actions)

        out = datapath.ofproto_parser.OFPPacketOut(
            datapath=datapath, buffer_id=msg.buffer_id, in_port=in_port,
            actions=actions)
        datapath.send_msg(out)

########NEW FILE########
__FILENAME__ = simple_switch_13
# Copyright (C) 2011 Nippon Telegraph and Telephone Corporation.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from ryu.base import app_manager
from ryu.controller import ofp_event
from ryu.controller.handler import CONFIG_DISPATCHER, MAIN_DISPATCHER
from ryu.controller.handler import set_ev_cls
from ryu.ofproto import ofproto_v1_3
from ryu.lib.packet import packet
from ryu.lib.packet import ethernet


class SimpleSwitch13(app_manager.RyuApp):
    OFP_VERSIONS = [ofproto_v1_3.OFP_VERSION]

    def __init__(self, *args, **kwargs):
        super(SimpleSwitch13, self).__init__(*args, **kwargs)
        self.mac_to_port = {}

    @set_ev_cls(ofp_event.EventOFPSwitchFeatures, CONFIG_DISPATCHER)
    def switch_features_handler(self, ev):
        datapath = ev.msg.datapath
        ofproto = datapath.ofproto
        parser = datapath.ofproto_parser

        # install table-miss flow entry
        #
        # We specify NO BUFFER to max_len of the output action due to
        # OVS bug. At this moment, if we specify a lesser number, e.g.,
        # 128, OVS will send Packet-In with invalid buffer_id and
        # truncated packet data. In that case, we cannot output packets
        # correctly.
        match = parser.OFPMatch()
        actions = [parser.OFPActionOutput(ofproto.OFPP_CONTROLLER,
                                          ofproto.OFPCML_NO_BUFFER)]
        self.add_flow(datapath, 0, match, actions)

    def add_flow(self, datapath, priority, match, actions):
        ofproto = datapath.ofproto
        parser = datapath.ofproto_parser

        inst = [parser.OFPInstructionActions(ofproto.OFPIT_APPLY_ACTIONS,
                                             actions)]

        mod = parser.OFPFlowMod(datapath=datapath, priority=priority,
                                match=match, instructions=inst)
        datapath.send_msg(mod)

    @set_ev_cls(ofp_event.EventOFPPacketIn, MAIN_DISPATCHER)
    def _packet_in_handler(self, ev):
        msg = ev.msg
        datapath = msg.datapath
        ofproto = datapath.ofproto
        parser = datapath.ofproto_parser
        in_port = msg.match['in_port']

        pkt = packet.Packet(msg.data)
        eth = pkt.get_protocols(ethernet.ethernet)[0]

        dst = eth.dst
        src = eth.src

        dpid = datapath.id
        self.mac_to_port.setdefault(dpid, {})

        self.logger.info("packet in %s %s %s %s", dpid, src, dst, in_port)

        # learn a mac address to avoid FLOOD next time.
        self.mac_to_port[dpid][src] = in_port

        if dst in self.mac_to_port[dpid]:
            out_port = self.mac_to_port[dpid][dst]
        else:
            out_port = ofproto.OFPP_FLOOD

        actions = [parser.OFPActionOutput(out_port)]

        # install a flow to avoid packet_in next time
        if out_port != ofproto.OFPP_FLOOD:
            match = parser.OFPMatch(in_port=in_port, eth_dst=dst)
            self.add_flow(datapath, 1, match, actions)

        data = None
        if msg.buffer_id == ofproto.OFP_NO_BUFFER:
            data = msg.data

        out = parser.OFPPacketOut(datapath=datapath, buffer_id=msg.buffer_id,
                                  in_port=in_port, actions=actions, data=data)
        datapath.send_msg(out)

########NEW FILE########
__FILENAME__ = simple_switch_lacp
# Copyright (C) 2013 Nippon Telegraph and Telephone Corporation.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import struct

from ryu.base import app_manager
from ryu.controller.handler import set_ev_cls
from ryu.ofproto import ofproto_v1_0
from ryu.lib import addrconv
from ryu.lib import lacplib
from ryu.lib.dpid import str_to_dpid


class SimpleSwitchLacp(app_manager.RyuApp):
    OFP_VERSIONS = [ofproto_v1_0.OFP_VERSION]
    _CONTEXTS = {'lacplib': lacplib.LacpLib}

    def __init__(self, *args, **kwargs):
        super(SimpleSwitchLacp, self).__init__(*args, **kwargs)
        self.mac_to_port = {}
        self._lacp = kwargs['lacplib']
        # in this sample application, bonding i/fs of the switchs
        # shall be set up as follows:
        # - the port 1 and 2 of the datapath 1 face the slave i/fs.
        # - the port 3, 4 and 5 of the datapath 1 face the others.
        # - the port 1 and 2 of the datapath 2 face the others.
        self._lacp.add(
            dpid=str_to_dpid('0000000000000001'), ports=[1, 2])
        self._lacp.add(
            dpid=str_to_dpid('0000000000000001'), ports=[3, 4, 5])
        self._lacp.add(
            dpid=str_to_dpid('0000000000000002'), ports=[1, 2])

    def add_flow(self, datapath, in_port, dst, actions):
        ofproto = datapath.ofproto
        parser = datapath.ofproto_parser

        match = parser.OFPMatch(in_port=in_port,
                                dl_dst=addrconv.mac.text_to_bin(dst))
        mod = parser.OFPFlowMod(
            datapath=datapath, match=match, cookie=0,
            command=ofproto.OFPFC_ADD, actions=actions)
        datapath.send_msg(mod)

    def del_flow(self, datapath, dst):
        ofproto = datapath.ofproto
        parser = datapath.ofproto_parser

        match = parser.OFPMatch(dl_dst=addrconv.mac.text_to_bin(dst))
        mod = parser.OFPFlowMod(
            datapath=datapath, match=match, cookie=0,
            command=ofproto.OFPFC_DELETE)
        datapath.send_msg(mod)

    @set_ev_cls(lacplib.EventPacketIn, lacplib.LAG_EV_DISPATCHER)
    def _packet_in_handler(self, ev):
        msg = ev.msg
        datapath = msg.datapath
        ofproto = datapath.ofproto

        (dst_, src_, _eth_type) = struct.unpack_from(
            '!6s6sH', buffer(msg.data), 0)
        src = addrconv.mac.bin_to_text(src_)
        dst = addrconv.mac.bin_to_text(dst_)

        dpid = datapath.id
        self.mac_to_port.setdefault(dpid, {})

        self.logger.info("packet in %s %s %s %s",
                         dpid, src, dst, msg.in_port)

        # learn a mac address to avoid FLOOD next time.
        self.mac_to_port[dpid][src] = msg.in_port

        if dst in self.mac_to_port[dpid]:
            out_port = self.mac_to_port[dpid][dst]
        else:
            out_port = ofproto.OFPP_FLOOD

        actions = [datapath.ofproto_parser.OFPActionOutput(out_port)]

        # install a flow to avoid packet_in next time
        if out_port != ofproto.OFPP_FLOOD:
            self.add_flow(datapath, msg.in_port, dst, actions)

        out = datapath.ofproto_parser.OFPPacketOut(
            datapath=datapath, buffer_id=msg.buffer_id, in_port=msg.in_port,
            actions=actions)
        datapath.send_msg(out)

    @set_ev_cls(lacplib.EventSlaveStateChanged, lacplib.LAG_EV_DISPATCHER)
    def _slave_state_changed_handler(self, ev):
        datapath = ev.datapath
        dpid = datapath.id
        port_no = ev.port
        enabled = ev.enabled
        self.logger.info("slave state changed port: %d enabled: %s",
                         port_no, enabled)
        if dpid in self.mac_to_port:
            for mac in self.mac_to_port[dpid]:
                self.del_flow(datapath, mac)
            del self.mac_to_port[dpid]
        self.mac_to_port.setdefault(dpid, {})

########NEW FILE########
__FILENAME__ = simple_switch_stp
# Copyright (C) 2013 Nippon Telegraph and Telephone Corporation.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import struct

from ryu.base import app_manager
from ryu.controller.handler import set_ev_cls
from ryu.ofproto import ofproto_v1_0
from ryu.lib import dpid as dpid_lib
from ryu.lib import stplib
from ryu.lib.mac import haddr_to_str


class SimpleSwitchStp(app_manager.RyuApp):
    OFP_VERSIONS = [ofproto_v1_0.OFP_VERSION]
    _CONTEXTS = {'stplib': stplib.Stp}

    def __init__(self, *args, **kwargs):
        super(SimpleSwitchStp, self).__init__(*args, **kwargs)
        self.mac_to_port = {}
        self.stp = kwargs['stplib']

        # Sample of stplib config.
        #  please refer to stplib.Stp.set_config() for details.
        """
        config = {dpid_lib.str_to_dpid('0000000000000001'):
                     {'bridge': {'priority': 0x8000,
                                 'max_age': 10},
                      'ports': {1: {'priority': 0x80},
                                2: {'priority': 0x90}}},
                  dpid_lib.str_to_dpid('0000000000000002'):
                     {'bridge': {'priority': 0x9000}}}
        self.stp.set_config(config)
        """

    def add_flow(self, datapath, in_port, dst, actions):
        ofproto = datapath.ofproto

        wildcards = ofproto_v1_0.OFPFW_ALL
        wildcards &= ~ofproto_v1_0.OFPFW_IN_PORT
        wildcards &= ~ofproto_v1_0.OFPFW_DL_DST

        match = datapath.ofproto_parser.OFPMatch(
            wildcards, in_port, 0, dst,
            0, 0, 0, 0, 0, 0, 0, 0, 0)

        mod = datapath.ofproto_parser.OFPFlowMod(
            datapath=datapath, match=match, cookie=0,
            command=ofproto.OFPFC_ADD, idle_timeout=0, hard_timeout=0,
            priority=ofproto.OFP_DEFAULT_PRIORITY,
            flags=ofproto.OFPFF_SEND_FLOW_REM, actions=actions)
        datapath.send_msg(mod)

    def delete_flow(self, datapath):
        ofproto = datapath.ofproto

        wildcards = ofproto_v1_0.OFPFW_ALL
        match = datapath.ofproto_parser.OFPMatch(
            wildcards, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0)

        mod = datapath.ofproto_parser.OFPFlowMod(
            datapath=datapath, match=match, cookie=0,
            command=ofproto.OFPFC_DELETE)
        datapath.send_msg(mod)

    @set_ev_cls(stplib.EventPacketIn, stplib.STP_EV_DISPATCHER)
    def packet_in_handler(self, ev):
        msg = ev.msg
        datapath = msg.datapath
        ofproto = datapath.ofproto

        dst, src, _eth_type = struct.unpack_from('!6s6sH', buffer(msg.data), 0)

        dpid = datapath.id
        self.mac_to_port.setdefault(dpid, {})

        self.logger.debug("packet in %s %s %s %s",
                          dpid, haddr_to_str(src), haddr_to_str(dst),
                          msg.in_port)

        # learn a mac address to avoid FLOOD next time.
        self.mac_to_port[dpid][src] = msg.in_port

        if dst in self.mac_to_port[dpid]:
            out_port = self.mac_to_port[dpid][dst]
        else:
            out_port = ofproto.OFPP_FLOOD

        actions = [datapath.ofproto_parser.OFPActionOutput(out_port)]

        # install a flow to avoid packet_in next time
        if out_port != ofproto.OFPP_FLOOD:
            self.add_flow(datapath, msg.in_port, dst, actions)

        out = datapath.ofproto_parser.OFPPacketOut(
            datapath=datapath, buffer_id=msg.buffer_id, in_port=msg.in_port,
            actions=actions)
        datapath.send_msg(out)

    @set_ev_cls(stplib.EventTopologyChange, stplib.STP_EV_DISPATCHER)
    def _topology_change_handler(self, ev):
        dp = ev.dp
        dpid_str = dpid_lib.dpid_to_str(dp.id)
        msg = 'Receive topology change event. Flush MAC table.'
        self.logger.debug("[dpid=%s] %s", dpid_str, msg)

        if dp.id in self.mac_to_port:
            del self.mac_to_port[dp.id]
        self.delete_flow(dp)

    @set_ev_cls(stplib.EventPortStateChange, stplib.STP_EV_DISPATCHER)
    def _port_state_change_handler(self, ev):
        dpid_str = dpid_lib.dpid_to_str(ev.dp.id)
        of_state = {ofproto_v1_0.OFPPS_LINK_DOWN: 'DISABLE',
                    ofproto_v1_0.OFPPS_STP_BLOCK: 'BLOCK',
                    ofproto_v1_0.OFPPS_STP_LISTEN: 'LISTEN',
                    ofproto_v1_0.OFPPS_STP_LEARN: 'LEARN',
                    ofproto_v1_0.OFPPS_STP_FORWARD: 'FORWARD'}
        self.logger.debug("[dpid=%s][port=%d] state=%s",
                          dpid_str, ev.port_no, of_state[ev.port_state])

########NEW FILE########
__FILENAME__ = simple_vlan
# Copyright (C) 2012 Nippon Telegraph and Telephone Corporation.
# Copyright (C) 2012 Isaku Yamahata <yamahata at private email ne jp>
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from ryu.app import (conf_switch_key,
                     rest_nw_id)
from ryu.base import app_manager
from ryu.controller import (conf_switch,
                            dpset,
                            handler,
                            network,
                            tunnels)
import ryu.exception as ryu_exc
from ryu.lib import dpid as dpid_lib
from ryu.lib import hub
from ryu.lib.ovs import bridge
from ryu.ofproto import nx_match


def _is_reserved_port(dp, port_no):
    return port_no > dp.ofproto.OFPP_MAX


class SimpleVLAN(app_manager.RyuApp):
    _CONTEXTS = {
        'conf_switch': conf_switch.ConfSwitchSet,
        'dpset': dpset.DPSet,
        'network': network.Network,
        'tunnels': tunnels.Tunnels,
    }

    _PRIORITY_CATCHALL = 1
    _PRIORITY_NORMAL = 2

    _COOKIE_CATCHALL = 1
    _COOKIE_NORMAL = 2

    def __init__(self, *args, **kwargs):
        super(SimpleVLAN, self).__init__(*args, **kwargs)
        self.conf_sw = kwargs['conf_switch']
        self.dpset = kwargs['dpset']
        self.nw = kwargs['network']
        self.tunnels = kwargs['tunnels']

    def _port_flow_add(self, dp, port_no):
        self.logger.debug('ovs_port_update dpid %s port_no %s',
                          dpid_lib.dpid_to_str(dp.id), port_no)
        rule = nx_match.ClsRule()
        rule.set_in_port(port_no)
        ofproto = dp.ofproto
        actions = [dp.ofproto_parser.OFPActionOutput(ofproto.OFPP_NORMAL)]
        dp.send_flow_mod(rule=rule, cookie=self._COOKIE_NORMAL,
                         command=ofproto.OFPFC_ADD,
                         idle_timeout=0, hard_timeout=0,
                         priority=self._PRIORITY_NORMAL, actions=actions)

    def _port_flow_del(self, dp, port_no):
        self.logger.debug('_port_flow_del dp %s port_no %d',
                          dpid_lib.dpid_to_str(dp.id), port_no)
        rule = nx_match.ClsRule()
        rule.set_in_port(port_no)
        dp.send_flow_del(rule=rule, cookie=self._COOKIE_NORMAL)

    def _queue_port_flow_add(self, dp, port_no):
        self._port_flow_add(dp, port_no)

    def _queue_port_flow_del(self, dp, port_no):
        self._port_flow_del(dp, port_no)

    @handler.set_ev_cls(dpset.EventDP)
    def dp_handler(self, ev):
        if not ev.enter:
            return

        dp = ev.dp
        rule = nx_match.ClsRule()
        ofproto = dp.ofproto
        dp.send_flow_mod(rule=rule,
                         cookie=self._COOKIE_CATCHALL,
                         command=ofproto.OFPFC_ADD,
                         idle_timeout=0, hard_timeout=0,
                         priority=self._PRIORITY_CATCHALL,
                         actions=[])
        for port in ev.ports:
            self._port_add(dp, port.port_no)

    # There is no ordering between those events
    #   port creation: PortAdd event
    #   network_id assignment: NetworkPort event
    #   tunnel_key assignment: TunnelKeyAdd event
    #   ovsdb_addr: EventConfSwitchSet
    # So on each events, check all necessary parameters are setup
    def _port_setup(self, dp, port_no, tunnel_key):
        if _is_reserved_port(dp, port_no):
            return

        dpid = dp.id
        try:
            port = self.dpset.get_port(dpid, port_no)
        except ryu_exc.PortNotFound:
            self.logger.debug('port not found')
            return

        try:
            ovsdb_addr = self.conf_sw.get_key(dpid, conf_switch_key.OVSDB_ADDR)
        except KeyError:
            self.logger.debug('ovsdb_addr not found')
            return

        self._port_flow_add(dp, port_no)

        self.logger.debug('ovs_port_update dpid %s port_no %s', dpid, port_no)
        # ovs-vsctl --db=ovsdb_addr --timeout=2
        # set Port port.name tag=tunnel_key
        ovs_br = bridge.OVSBridge(dpid, ovsdb_addr, 2)
        # ofp_phy_port::name is zero-padded
        port_name = port.name.rstrip('\x00')
        try:
            ovs_br.set_db_attribute("Port", port_name, "tag", tunnel_key)
        except hub.Timeout:
            self.logger.error('timeout')
            return

        return True

    def _port_setup_netid(self, dpid, port_no, network_id):
        self.logger.debug('_port_setup_netid %s %s %s',
                          dpid_lib.dpid_to_str(dpid), port_no, network_id)
        dp = self.dpset.get(dpid)
        if dp is None:
            self.logger.debug('dp not found')
            return
        if _is_reserved_port(dp, port_no):
            return

        if network_id == rest_nw_id.NW_ID_EXTERNAL:
            self.logger.debug('external interface')
            self._queue_port_flow_add(dp, port_no)
            return True

        try:
            tunnel_key = self.tunnels.get_key(network_id)
        except tunnels.TunnelKeyNotFound:
            self.logger.debug('tunnel key not found')
            return

        return self._port_setup(dp, port_no, tunnel_key)

    def _port_add(self, dp, port_no):
        if _is_reserved_port(dp, port_no):
            return

        dpid = dp.id
        try:
            network_id = self.nw.get_network(dpid, port_no)
        except ryu_exc.PortUnknown:
            self.logger.debug('port_unknown')
            self._queue_port_flow_del(dp, port_no)
            return

        if not self._port_setup_netid(dpid, port_no, network_id):
            self.logger.debug('_port_setup_netid failed')
            self._queue_port_flow_del(dp, port_no)

    @handler.set_ev_cls(dpset.EventPortAdd)
    def port_add_handler(self, ev):
        self.logger.debug('port_add %s', ev)
        self._port_add(ev.dp, ev.port.port_no)

    @handler.set_ev_cls(dpset.EventPortDelete)
    def port_del_handler(self, ev):
        self.logger.debug('port_del %s', ev)
        dp = ev.dp
        port_no = ev.port.port_no
        if _is_reserved_port(dp, port_no):
            return
        self._queue_port_flow_del(dp, port_no)

    @handler.set_ev_cls(network.EventNetworkPort)
    def network_port_handler(self, ev):
        self.logger.debug('network_port %s', ev)
        if not ev.add_del:
            return
        self._port_setup_netid(ev.dpid, ev.port_no, ev.network_id)

    @handler.set_ev_cls(tunnels.EventTunnelKeyAdd)
    def tunnel_key_add_handler(self, ev):
        self.logger.debug('tunnel_add %s', ev)
        tunnel_key = ev.tunnel_key
        for (dpid, port_no) in self.nw.list_ports_noraise(ev.network_id):
            dp = self.dpset.get(dpid)
            if dp is None:
                continue
            self._port_setup(dp, port_no, tunnel_key)

    @handler.set_ev_cls(conf_switch.EventConfSwitchSet)
    def conf_switch_set_handler(self, ev):
        self.logger.debug('conf_switch_set %s', ev)
        if ev.key != conf_switch_key.OVSDB_ADDR:
            return

        dpid = ev.dpid
        try:
            ports = self.dpset.get_ports(dpid)
        except KeyError:
            return
        for port in ports:
            port_no = port.port_no
            try:
                network_id = self.nw.get_network(dpid, port_no)
            except ryu_exc.PortUnknown:
                continue
            self._port_setup_netid(dpid, port_no, network_id)

########NEW FILE########
__FILENAME__ = tunnel_port_updater
# Copyright (C) 2012 Nippon Telegraph and Telephone Corporation.
# Copyright (C) 2012 Isaku Yamahata <yamahata at private email ne jp>
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# This module updates OVS tunnel ports for OpenStack integration.

import collections
from oslo.config import cfg
import logging
import netaddr

from ryu import exception as ryu_exc
from ryu.app import conf_switch_key as cs_key
from ryu.app import rest_nw_id
from ryu.base import app_manager
from ryu.controller import (conf_switch,
                            handler,
                            network,
                            tunnels)
from ryu.lib import dpid as dpid_lib
from ryu.lib import hub
from ryu.lib.ovs import bridge as ovs_bridge


CONF = cfg.CONF
CONF.register_opts([
    cfg.StrOpt('tunnel-type', default='gre',
               help='tunnel type for ovs tunnel port')
])

_TUNNEL_TYPE_TO_NW_ID = {
    'gre': rest_nw_id.NW_ID_VPORT_GRE,
}


class NetworkAPI(object):
    """Internal adopter class for RestAPI"""
    def __init__(self, network_):
        super(NetworkAPI, self).__init__()
        self.nw = network_

    def update_network(self, network_id):
        self.nw.update_network(network_id)

    def create_port(self, network_id, dpid, port_id):
        self.nw.create_port(network_id, dpid, port_id)

    def update_port(self, network_id, dpid, port_id):
        self.nw.update_port(network_id, dpid, port_id)

    def delete_port(self, network_id, dpid, port_id):
        try:
            self.nw.remove_port(network_id, dpid, port_id)
        except (ryu_exc.NetworkNotFound, ryu_exc.PortNotFound):
            pass


class TunnelAPI(object):
    """Internal adopter class for RestTunnelAPI"""
    def __init__(self, tunnels_):
        super(TunnelAPI, self).__init__()
        self.tunnels = tunnels_

    def update_remote_dpid(self, dpid, port_id, remote_dpid):
        self.tunnels.update_port(dpid, port_id, remote_dpid)

    def create_remote_dpid(self, dpid, port_id, remote_dpid):
        self.tunnels.register_port(dpid, port_id, remote_dpid)

    def delete_port(self, dpid, port_id):
        try:
            self.tunnels.delete_port(dpid, port_id)
        except ryu_exc.PortNotFound:
            pass


class TunnelPort(object):
    def __init__(self, dpid, port_no, local_ip, remote_ip, remote_dpid=None):
        super(TunnelPort, self).__init__()
        self.dpid = dpid
        self.port_no = port_no
        self.local_ip = local_ip
        self.remote_ip = remote_ip
        self.remote_dpid = remote_dpid

    def __eq__(self, other):
        return (self.dpid == other.dpid and
                self.port_no == other.port_no and
                self.local_ip == other.local_ip and
                self.remote_ip == other.remote_ip and
                self.remote_dpid == other.remote_dpid)


class TunnelDP(object):
    def __init__(self, dpid, ovsdb_addr, tunnel_ip, tunnel_type, conf_switch_,
                 network_api, tunnel_api, logger):
        super(TunnelDP, self).__init__()
        self.dpid = dpid
        self.network_api = network_api
        self.tunnel_api = tunnel_api
        self.logger = logger

        self.ovs_bridge = ovs_bridge.OVSBridge(dpid, ovsdb_addr)

        self.tunnel_ip = tunnel_ip
        self.tunnel_type = tunnel_type
        self.tunnel_nw_id = _TUNNEL_TYPE_TO_NW_ID[tunnel_type]
        self.tunnels = {}       # port number -> TunnelPort

        self.conf_switch = conf_switch_
        self.inited = False

        self.req_q = hub.Queue()
        self.thr = hub.spawn(self._serve_loop)

    def _init(self):
        self.ovs_bridge.init()
        for tp in self.ovs_bridge.get_tunnel_ports(self.tunnel_type):
            if tp.local_ip != self.tunnel_ip:
                self.logger.warn('unknown tunnel port %s', tp)
                continue

            remote_dpid = self.conf_switch.find_dpid(cs_key.OVS_TUNNEL_ADDR,
                                                     tp.remote_ip)
            self.tunnels[tp.ofport] = TunnelPort(self.dpid, tp.ofport,
                                                 self.tunnel_ip, tp.remote_ip,
                                                 remote_dpid)
            if remote_dpid:
                self._api_update(tp.ofport, remote_dpid)

        self.conf_switch = None
        self.inited = True

    def _api_update(self, port_no, remote_dpid):
        self.network_api.update_port(self.tunnel_nw_id, self.dpid, port_no)
        self.tunnel_api.update_remote_dpid(self.dpid, port_no, remote_dpid)

    def _api_delete(self, port_no):
        self.network_api.delete_port(self.tunnel_nw_id, self.dpid, port_no)
        self.tunnel_api.delete_port(self.dpid, port_no)

    def _update_remote(self, remote_dpid, remote_ip):
        if self.dpid == remote_dpid:
            if self.tunnel_ip == remote_ip:
                return

            # tunnel ip address is changed.
            self.logger.warn('local ip address is changed %s: %s -> %s',
                             dpid_lib.dpid_to_str(remote_dpid),
                             self.tunnel_ip, remote_ip)
            # recreate tunnel ports.
            for tp in list(self.tunnels.values()):
                if tp.remote_dpid is None:
                    # TODO:XXX
                    continue

                self._del_tunnel_port(tp.port_no, tp.local_ip, tp.remote_ip)

                new_tp = self._add_tunnel_port(tp.remote_dpid, tp.remote_ip)
                self._api_update(new_tp.ofport, tp.remote_dpid)
            return

        if self.tunnel_ip == remote_ip:
            self.logger.error('ip conflict: %s %s %s',
                              dpid_lib.dpid_to_str(self.dpid),
                              dpid_lib.dpid_to_str(remote_dpid), remote_ip)
            # XXX What should we do?
            return

        for tp in list(self.tunnels.values()):
            if tp.remote_dpid == remote_dpid:
                if tp.remote_ip == remote_ip:
                    self._api_update(tp.port_no, remote_dpid)
                    continue

                self.logger.warn('remote ip address is changed %s: %s -> %s',
                                 dpid_lib.dpid_to_str(remote_dpid),
                                 tp.remote_ip, remote_ip)
                self._del_tunnel_port(tp.port_no, self.tunnel_ip, tp.remote_ip)

                new_tp = self._add_tunnel_port(remote_dpid, remote_ip)
                self._api_update(new_tp.ofport, remote_dpid)
            elif tp.remote_ip == remote_ip:
                assert tp.remote_dpid is None
                self._api_update(tp.port_no, remote_dpid)
                tp.remote_dpid = remote_dpid

    @staticmethod
    def _to_hex(ip_addr):
        # assuming IPv4 address
        assert netaddr.IPAddress(ip_addr).ipv4()
        return "%02x%02x%02x%02x" % netaddr.IPAddress(ip_addr).words

    @staticmethod
    def _port_name(local_ip, remote_ip):
        # ovs requires requires less or equals to 14 bytes length
        # gre<remote>-<local lsb>
        _PORT_NAME_LENGTH = 14
        local_hex = TunnelDP._to_hex(local_ip)
        remote_hex = TunnelDP._to_hex(remote_ip)
        return ("gre%s-%s" % (remote_hex, local_hex))[:_PORT_NAME_LENGTH]

    def _tunnel_port_exists(self, remote_dpid, remote_ip):
        return any(tp.remote_dpid == remote_dpid and tp.remote_ip == remote_ip
                   for tp in self.tunnels.values())

    def _add_tunnel_port(self, remote_dpid, remote_ip):
        self.logger.debug('add_tunnel_port local %s %s remote %s %s',
                          dpid_lib.dpid_to_str(self.dpid), self.tunnel_ip,
                          dpid_lib.dpid_to_str(remote_dpid), remote_ip)
        if self._tunnel_port_exists(remote_dpid, remote_ip):
            self.logger.debug('add_tunnel_port nop')
            return

        self.logger.debug('add_tunnel_port creating port')
        port_name = self._port_name(self.tunnel_ip, remote_ip)
        self.ovs_bridge.add_tunnel_port(port_name, self.tunnel_type,
                                        self.tunnel_ip, remote_ip, 'flow')

        tp = self.ovs_bridge.get_tunnel_port(port_name, self.tunnel_type)
        self.tunnels[tp.ofport] = TunnelPort(self.dpid, tp.ofport,
                                             tp.local_ip, tp.remote_ip,
                                             remote_dpid)
        self.network_api.create_port(self.tunnel_nw_id, self.dpid, tp.ofport)
        self.tunnel_api.create_remote_dpid(self.dpid, tp.ofport, remote_dpid)
        return tp

    def _del_tunnel_port(self, port_no, local_ip, remote_ip):
        port_name = self._port_name(local_ip, remote_ip)
        self.ovs_bridge.del_port(port_name)
        del self.tunnels[port_no]
        self._api_delete(port_no)

    def _del_tunnel_port_ip(self, remote_ip):
        for tp in self.tunnels.values():
            if tp.remote_ip == remote_ip:
                self._del_tunnel_port(tp.port_no, self.tunnel_ip, remote_ip)
                break

    # serialize requests to this OVS DP
    _RequestUpdateRemote = collections.namedtuple('_RequestUpdateRemote',
                                                 ('remote_dpid', 'remote_ip'))
    _RequestAddTunnelPort = collections.namedtuple('_RequestAddTunnelPort',
                                                  ('remote_dpid', 'remote_ip'))
    _RequestDelTunnelPort = collections.namedtuple('_RequestDelTunnelPort',
                                                  ('remote_ip'))

    class _RequestClose(object):
        pass

    def request_update_remote(self, remote_dpid, remote_ip):
        self.req_q.put(self._RequestUpdateRemote(remote_dpid, remote_ip))

    def request_add_tunnel_port(self, remote_dpid, remote_ip):
        self.req_q.put(self._RequestAddTunnelPort(remote_dpid, remote_ip))

    def request_del_tunnel_port(self, remote_ip):
        self.req_q.put(self._RequestDelTunnelPort(remote_ip))

    def close(self):
        # self.thr.kill()
        self.req_q.put(self._RequestClose())
        self.thr.join()
        self.thr = None

    def _serve_loop(self):
        # TODO:XXX backoff timeout
        # TOOD:XXX and then, abandon and notify the caller(TunnelPortUpdater)

        # TODO: if possible, squash requests?
        #       For example, RequestAddTunnelPort and RequestDelTunnelPort
        #       with same dpid are in the queue. AddTunnelPort request
        #       can be skipped.
        #       When ovsdb-server and vswitchd are over-loaded
        #       (or connection to ovsdb are unstable), squashing request
        #       would increase stability a bit?
        #       But unsure how effective it would be.

        if not self.inited:
            try:
                self._init()
            except hub.Timeout:
                self.logger.warn('_init timeouted')

        req = None
        while True:
            if req is None:
                req = self.req_q.get()
                if isinstance(req, self._RequestClose):
                    return

            try:
                if not self.inited:
                    self._init()

                # shoud use dispatcher?
                if isinstance(req, self._RequestUpdateRemote):
                    self.logger.debug('update_remote')
                    self._update_remote(req.remote_dpid, req.remote_ip)
                elif isinstance(req, self._RequestAddTunnelPort):
                    self.logger.debug('add_tunnel_port')
                    self._add_tunnel_port(req.remote_dpid, req.remote_ip)
                elif isinstance(req, self._RequestDelTunnelPort):
                    self.logger.debug('del_tunnel_port')
                    self._del_tunnel_port_ip(req.remote_ip)
                else:
                    self.logger.error('unknown request %s', req)
            except hub.Timeout:
                # timeout. try again
                self.logger.warn('timeout try again')
                continue
            else:
                # Done. move onto next request
                req = None


class TunnelDPSet(dict):
    """ dpid -> TunndlDP """
    pass


#import collections
#class TunnelRequests(collections.defaultdict(set)):
class TunnelRequests(dict):
    def add(self, dpid0, dpid1):
        self.setdefault(dpid0, set()).add(dpid1)
        self.setdefault(dpid1, set()).add(dpid0)

    def remove(self, dpid0, dpid1):
        self[dpid0].remove(dpid1)
        self[dpid1].remove(dpid0)

    def get_remote(self, dpid):
        return self.setdefault(dpid, set())


class TunnelPortUpdater(app_manager.RyuApp):
    _CONTEXTS = {
        'conf_switch': conf_switch.ConfSwitchSet,
        'network': network.Network,
        'tunnels': tunnels.Tunnels,
    }

    def __init__(self, *args, **kwargs):
        super(TunnelPortUpdater, self).__init__(args, kwargs)
        self.tunnel_type = CONF.tunnel_type
        self.cs = kwargs['conf_switch']
        self.nw = kwargs['network']
        self.tunnels = kwargs['tunnels']
        self.tunnel_dpset = TunnelDPSet()
        self.tunnel_requests = TunnelRequests()

        self.network_api = NetworkAPI(self.nw)
        self.tunnel_api = TunnelAPI(self.tunnels)
        self.network_api.update_network(
            _TUNNEL_TYPE_TO_NW_ID[self.tunnel_type])

    def _ovsdb_update(self, dpid, ovsdb_addr, ovs_tunnel_addr):
        self.logger.debug('_ovsdb_update %s %s %s',
                          dpid_lib.dpid_to_str(dpid), ovsdb_addr,
                          ovs_tunnel_addr)
        if dpid not in self.tunnel_dpset:
            # TODO:XXX changing ovsdb_addr, ovs_tunnel_addr
            tunnel_dp = TunnelDP(dpid, ovsdb_addr, ovs_tunnel_addr,
                                 self.tunnel_type, self.cs,
                                 self.network_api, self.tunnel_api,
                                 self.logger)
            self.tunnel_dpset[dpid] = tunnel_dp

        tunnel_dp = self.tunnel_dpset.get(dpid)
        assert tunnel_dp
        self._add_tunnel_ports(tunnel_dp,
                               self.tunnel_requests.get_remote(dpid))

    @handler.set_ev_cls(conf_switch.EventConfSwitchSet)
    def conf_switch_set_handler(self, ev):
        self.logger.debug('conf_switch_set_handler %s %s %s',
                          dpid_lib.dpid_to_str(ev.dpid), ev.key, ev.value)
        dpid = ev.dpid
        if (ev.key == cs_key.OVSDB_ADDR or ev.key == cs_key.OVS_TUNNEL_ADDR):
            if ((dpid, cs_key.OVSDB_ADDR) in self.cs and
                    (dpid, cs_key.OVS_TUNNEL_ADDR) in self.cs):
                self._ovsdb_update(
                    dpid, self.cs.get_key(dpid, cs_key.OVSDB_ADDR),
                    self.cs.get_key(dpid, cs_key.OVS_TUNNEL_ADDR))

        if ev.key == cs_key.OVS_TUNNEL_ADDR:
            for tunnel_dp in self.tunnel_dpset.values():
                tunnel_dp.request_update_remote(ev.dpid, ev.value)

    @handler.set_ev_cls(conf_switch.EventConfSwitchDel)
    def conf_switch_del_handler(self, ev):
        # TODO:XXX
        pass

    def _add_tunnel_ports(self, tunnel_dp, remote_dpids):
        self.logger.debug('_add_tunnel_ports %s %s', tunnel_dp, remote_dpids)
        for remote_dpid in remote_dpids:
            remote_dp = self.tunnel_dpset.get(remote_dpid)
            if remote_dp is None:
                continue
            tunnel_dp.request_add_tunnel_port(remote_dp.dpid,
                                              remote_dp.tunnel_ip)
            remote_dp.request_add_tunnel_port(tunnel_dp.dpid,
                                              tunnel_dp.tunnel_ip)

    def _vm_port_add(self, network_id, dpid):
        self.logger.debug('_vm_port_add %s %s', network_id,
                          dpid_lib.dpid_to_str(dpid))
        dpids = self.nw.get_dpids(network_id)
        dpids.remove(dpid)
        for remote_dpid in dpids:
            self.tunnel_requests.add(dpid, remote_dpid)

        tunnel_dp = self.tunnel_dpset.get(dpid)
        if tunnel_dp is None:
            return
        self._add_tunnel_ports(tunnel_dp, dpids)

    def _vm_port_del(self, network_id, dpid):
        self.logger.debug('_vm_port_del %s %s', network_id,
                          dpid_lib.dpid_to_str(dpid))
        if len(self.nw.get_ports(dpid, network_id)) > 0:
            return

        tunnel_networks = set(p.network_id
                              for p in self.nw.get_networks(dpid))
        tunnel_networks.discard(network_id)
        tunnel_networks.difference_update(rest_nw_id.RESERVED_NETWORK_IDS)
        dpids = self.nw.get_dpids(network_id).copy()
        dpids.discard(dpid)
        del_dpids = []
        for remote_dpid in dpids:
            remote_networks = set(p.network_id
                                  for p in self.nw.get_networks(remote_dpid))
            if tunnel_networks & remote_networks:
                continue
            self.tunnel_requests.remove(dpid, remote_dpid)
            del_dpids.append(remote_dpid)

        tunnel_dp = self.tunnel_dpset.get(dpid)
        if tunnel_dp is None:
            return
        for remote_dpid in del_dpids:
            remote_dp = self.tunnel_dpset.get(remote_dpid)
            if remote_dp is None:
                continue
            tunnel_dp.request_del_tunnel_port(remote_dp.tunnel_ip)
            remote_dp.request_del_tunnel_port(tunnel_dp.tunnel_ip)

    @handler.set_ev_cls(network.EventNetworkPort)
    def network_port_handler(self, ev):
        self.logger.debug('network_port_handler %s', ev)
        if ev.network_id in rest_nw_id.RESERVED_NETWORK_IDS:
            return

        if ev.add_del:
            self._vm_port_add(ev.network_id, ev.dpid)
        else:
            self._vm_port_del(ev.network_id, ev.dpid)

########NEW FILE########
__FILENAME__ = wsgi
# Copyright (C) 2012 Nippon Telegraph and Telephone Corporation.
# Copyright (C) 2012 Isaku Yamahata <yamahata at private email ne jp>
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import inspect

from oslo.config import cfg
import webob.dec

from ryu.lib import hub
from routes import Mapper
from routes.util import URLGenerator


CONF = cfg.CONF
CONF.register_cli_opts([
    cfg.StrOpt('wsapi-host', default='', help='webapp listen host'),
    cfg.IntOpt('wsapi-port', default=8080, help='webapp listen port')
])

HEX_PATTERN = r'0x[0-9a-z]+'
DIGIT_PATTERN = r'[1-9][0-9]*'


def route(name, path, methods=None, requirements=None):
    def _route(controller_method):
        controller_method.routing_info = {
            'name': name,
            'path': path,
            'methods': methods,
            'requirements': requirements,
        }
        return controller_method
    return _route


class ControllerBase(object):
    special_vars = ['action', 'controller']

    def __init__(self, req, link, data, **config):
        self.req = req
        self.link = link
        for name, value in config.items():
            setattr(self, name, value)

    def __call__(self, req):
        action = self.req.urlvars.get('action', 'index')
        if hasattr(self, '__before__'):
            self.__before__()

        kwargs = self.req.urlvars.copy()
        for attr in self.special_vars:
            if attr in kwargs:
                del kwargs[attr]

        return getattr(self, action)(req, **kwargs)


class WSGIApplication(object):
    def __init__(self, **config):
        self.config = config
        self.mapper = Mapper()
        self.registory = {}
        super(WSGIApplication, self).__init__()
        # XXX: Switch how to call the API of Routes for every version
        match_argspec = inspect.getargspec(self.mapper.match)
        if 'environ' in match_argspec.args:
            # New API
            self._match = self._match_with_environ
        else:
            # Old API
            self._match = self._match_with_path_info

    def _match_with_environ(self, req):
        match = self.mapper.match(environ=req.environ)
        return match

    def _match_with_path_info(self, req):
        self.mapper.environ = req.environ
        match = self.mapper.match(req.path_info)
        return match

    @webob.dec.wsgify
    def __call__(self, req):
        match = self._match(req)

        if not match:
            return webob.exc.HTTPNotFound()

        req.urlvars = match
        link = URLGenerator(self.mapper, req.environ)

        data = None
        name = match['controller'].__name__
        if name in self.registory:
            data = self.registory[name]

        controller = match['controller'](req, link, data, **self.config)
        return controller(req)

    def register(self, controller, data=None):
        methods = inspect.getmembers(controller,
                                     lambda v: inspect.ismethod(v) and
                                     hasattr(v, 'routing_info'))
        for method_name, method in methods:
            routing_info = getattr(method, 'routing_info')
            name = routing_info['name']
            path = routing_info['path']
            conditions = {}
            if routing_info.get('methods'):
                conditions['method'] = routing_info['methods']
            requirements = routing_info.get('requirements') or {}
            self.mapper.connect(name,
                                path,
                                controller=controller,
                                requirements=requirements,
                                action=method_name,
                                conditions=conditions)
        if data:
            self.registory[controller.__name__] = data


class WSGIServer(hub.WSGIServer):
    def __init__(self, application, **config):
        super(WSGIServer, self).__init__((CONF.wsapi_host, CONF.wsapi_port),
                                         application, **config)

    def __call__(self):
        self.serve_forever()


def start_service(app_mgr):
    for instance in app_mgr.contexts.values():
        if instance.__class__ == WSGIApplication:
            return WSGIServer(instance)

    return None

########NEW FILE########
__FILENAME__ = app_manager
# Copyright (C) 2011, 2012 Nippon Telegraph and Telephone Corporation.
# Copyright (C) 2011 Isaku Yamahata <yamahata at valinux co jp>
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import inspect
import itertools
import logging
import sys

from ryu import utils
from ryu.controller.handler import register_instance, get_dependent_services
from ryu.controller.controller import Datapath
from ryu.controller.event import EventRequestBase, EventReplyBase
from ryu.lib import hub

LOG = logging.getLogger('ryu.base.app_manager')

SERVICE_BRICKS = {}


def lookup_service_brick(name):
    return SERVICE_BRICKS.get(name)


def register_app(app):
    assert isinstance(app, RyuApp)
    assert not app.name in SERVICE_BRICKS
    SERVICE_BRICKS[app.name] = app
    register_instance(app)


class RyuApp(object):
    """
    Base class for Ryu network application
    """
    _CONTEXTS = {}
    _EVENTS = []  # list of events to be generated in app

    @classmethod
    def context_iteritems(cls):
        """
        Return iterator over the (key, contxt class) of application context
        """
        return cls._CONTEXTS.iteritems()

    def __init__(self, *_args, **_kwargs):
        super(RyuApp, self).__init__()
        self.name = self.__class__.__name__
        self.event_handlers = {}        # ev_cls -> handlers:list
        self.observers = {}     # ev_cls -> observer-name -> states:set
        self.threads = []
        self.events = hub.Queue(128)
        self.replies = hub.Queue()
        self.logger = logging.getLogger(self.name)
        self.threads.append(hub.spawn(self._event_loop))

    def register_handler(self, ev_cls, handler):
        assert callable(handler)
        self.event_handlers.setdefault(ev_cls, [])
        self.event_handlers[ev_cls].append(handler)

    def register_observer(self, ev_cls, name, states=None):
        states = states or set()
        ev_cls_observers = self.observers.setdefault(ev_cls, {})
        ev_cls_observers.setdefault(name, set()).update(states)

    def get_handlers(self, ev, state=None):
        handlers = self.event_handlers.get(ev.__class__, [])
        if state is None:
            return handlers

        return [handler for handler in handlers
                if not handler.dispatchers or state in handler.dispatchers]

    def get_observers(self, ev, state):
        observers = []
        for k, v in self.observers.get(ev.__class__, {}).iteritems():
            if not state or not v or state in v:
                observers.append(k)

        return observers

    def send_reply(self, rep):
        assert isinstance(rep, EventReplyBase)
        SERVICE_BRICKS[rep.dst].replies.put(rep)

    def send_request(self, req):
        assert isinstance(req, EventRequestBase)
        req.sync = True
        self.send_event(req.dst, req)
        # going to sleep for the reply
        return self.replies.get()

    def _event_loop(self):
        while True:
            ev, state = self.events.get()
            handlers = self.get_handlers(ev, state)
            for handler in handlers:
                handler(ev)

    def _send_event(self, ev, state):
        self.events.put((ev, state))

    def send_event(self, name, ev, state=None):
        if name in SERVICE_BRICKS:
            if isinstance(ev, EventRequestBase):
                ev.src = self.name
            LOG.debug("EVENT %s->%s %s" %
                      (self.name, name, ev.__class__.__name__))
            SERVICE_BRICKS[name]._send_event(ev, state)
        else:
            LOG.debug("EVENT LOST %s->%s %s" %
                      (self.name, name, ev.__class__.__name__))

    def send_event_to_observers(self, ev, state=None):
        for observer in self.get_observers(ev, state):
            self.send_event(observer, ev, state)

    def reply_to_request(self, req, rep):
        rep.dst = req.src
        if req.sync:
            self.send_reply(rep)
        else:
            self.send_event(rep.dst, rep)

    def close(self):
        """
        teardown method.
        The method name, close, is chosen for python context manager
        """
        pass


class AppManager(object):
    def __init__(self):
        self.applications_cls = {}
        self.applications = {}
        self.contexts_cls = {}
        self.contexts = {}

    def load_app(self, name):
        mod = utils.import_module(name)
        clses = inspect.getmembers(mod, lambda cls: (inspect.isclass(cls) and
                                                     issubclass(cls, RyuApp)))
        if clses:
            return clses[0][1]
        return None

    def load_apps(self, app_lists):
        app_lists = [app for app
                     in itertools.chain.from_iterable(app.split(',')
                                                      for app in app_lists)]
        while len(app_lists) > 0:
            app_cls_name = app_lists.pop(0)

            LOG.info('loading app %s', app_cls_name)

            cls = self.load_app(app_cls_name)
            if cls is None:
                continue

            self.applications_cls[app_cls_name] = cls

            services = []
            for key, context_cls in cls.context_iteritems():
                cls = self.contexts_cls.setdefault(key, context_cls)
                assert cls == context_cls

                if issubclass(context_cls, RyuApp):
                    services.extend(get_dependent_services(context_cls))

            services.extend(get_dependent_services(cls))
            if services:
                app_lists.extend(services)

    def create_contexts(self):
        for key, cls in self.contexts_cls.items():
            context = cls()
            LOG.info('creating context %s', key)
            assert not key in self.contexts
            self.contexts[key] = context
            # hack for dpset
            if issubclass(context.__class__, RyuApp):
                register_app(context)
        return self.contexts

    def instantiate_apps(self, *args, **kwargs):
        for app_name, cls in self.applications_cls.items():
            # for now, only single instance of a given module
            # Do we need to support multiple instances?
            # Yes, maybe for slicing.
            LOG.info('instantiating app %s', app_name)

            if hasattr(cls, 'OFP_VERSIONS'):
                for k in Datapath.supported_ofp_version.keys():
                    if not k in cls.OFP_VERSIONS:
                        del Datapath.supported_ofp_version[k]

            assert len(Datapath.supported_ofp_version), \
                'No OpenFlow version is available'

            assert app_name not in self.applications
            app = cls(*args, **kwargs)
            register_app(app)
            self.applications[app_name] = app

        for i in SERVICE_BRICKS.values():
            for _k, m in inspect.getmembers(i, inspect.ismethod):
                if not hasattr(m, 'observer'):
                    continue

                # name is module name of ev_cls
                name = m.observer.split('.')[-1]
                if name in SERVICE_BRICKS:
                    brick = SERVICE_BRICKS[name]
                    brick.register_observer(m.ev_cls, i.name, m.dispatchers)

                # allow RyuApp and Event class are in different module
                for brick in SERVICE_BRICKS.itervalues():
                    if m.ev_cls in brick._EVENTS:
                        brick.register_observer(m.ev_cls, i.name,
                                                m.dispatchers)

        for brick, i in SERVICE_BRICKS.items():
            LOG.debug("BRICK %s" % brick)
            for ev_cls, list in i.observers.items():
                LOG.debug("  PROVIDES %s TO %s" % (ev_cls.__name__, list))
            for ev_cls in i.event_handlers.keys():
                LOG.debug("  CONSUMES %s" % (ev_cls.__name__,))

    def close(self):
        def close_all(close_dict):
            for app in close_dict.values():
                close_method = getattr(app, 'close', None)
                if callable(close_method):
                    close_method()
            close_dict.clear()

        close_all(self.applications)
        close_all(self.contexts)

########NEW FILE########
__FILENAME__ = manager
#!/usr/bin/env python
#
# Copyright (C) 2011, 2012 Nippon Telegraph and Telephone Corporation.
# Copyright (C) 2011 Isaku Yamahata <yamahata at valinux co jp>
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from ryu.lib import hub
hub.patch()

# TODO:
#   Right now, we have our own patched copy of ovs python bindings
#   Once our modification is upstreamed and widely deployed,
#   use it
#
# NOTE: this modifies sys.path and thus affects the following imports.
# eg. oslo.config.cfg.
import ryu.contrib

from oslo.config import cfg
import logging
import sys

from ryu import log
log.early_init_log(logging.DEBUG)

from ryu import flags
from ryu import version
from ryu.app import wsgi
from ryu.base.app_manager import AppManager
from ryu.controller import controller
from ryu.topology import switches


CONF = cfg.CONF
CONF.register_cli_opts([
    cfg.ListOpt('app-lists', default=[],
                help='application module name to run'),
    cfg.MultiStrOpt('app', positional=True, default=[],
                    help='application module name to run')
])


def main():
    try:
        CONF(project='ryu', version='ryu-manager %s' % version,
             default_config_files=['/usr/local/etc/ryu/ryu.conf'])
    except cfg.ConfigFilesNotFoundError:
        CONF(project='ryu', version='ryu-manager %s' % version)

    log.init_log()

    app_lists = CONF.app_lists + CONF.app

    app_mgr = AppManager()
    app_mgr.load_apps(app_lists)
    contexts = app_mgr.create_contexts()
    app_mgr.instantiate_apps(**contexts)

    services = []

    # TODO: do the following in app_manager's instantiate_apps()
    ofpapp = controller.start_service(app_mgr)
    if ofpapp:
        thr = hub.spawn(ofpapp)
        services.append(thr)

    webapp = wsgi.start_service(app_mgr)
    if webapp:
        thr = hub.spawn(webapp)
        services.append(thr)

    try:
        hub.joinall(services)
    finally:
        app_mgr.close()


if __name__ == "__main__":
    main()

########NEW FILE########
__FILENAME__ = capabilities
# Copyright 2009 Shikhar Bhushan
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

def _abbreviate(uri):
    if uri.startswith("urn:ietf:params") and ":netconf:" in uri:
        splitted = uri.split(":")
        if ":capability:" in uri:
            if uri.startswith("urn:ietf:params:xml:ns:netconf"):
                name, version = splitted[7], splitted[8]
            else:
                name, version = splitted[5], splitted[6]
            return [ ":" + name, ":" + name + ":" + version ]
        elif ":base:" in uri:
            if uri.startswith("urn:ietf:params:xml:ns:netconf"):
                return [ ":base", ":base" + ":" + splitted[7] ]
            else:
                return [ ":base", ":base" + ":" + splitted[5] ]
    return []

def schemes(url_uri):
    "Given a URI that has a *scheme* query string (i.e. `:url` capability URI), will return a list of supported schemes."
    return url_uri.partition("?scheme=")[2].split(",")

class Capabilities:

    "Represents the set of capabilities available to a NETCONF client or server. It is initialized with a list of capability URI's."
    
    def __init__(self, capabilities):
        self._dict = {}
        for uri in capabilities:
            self._dict[uri] = _abbreviate(uri)

    def __contains__(self, key):
        if key in self._dict:
            return True
        for abbrs in self._dict.values():
            if key in abbrs:
                return True
        return False

    def __len__(self):
        return len(self._dict)

    def __iter__(self):
        return self._dict.iterkeys()

    def __repr__(self):
        return repr(self._dict.keys())

    def add(self, uri):
        "Add a capability."
        self._dict[uri] = _abbreviate(uri)

    def remove(self, uri):
        "Remove a capability."
        if key in self._dict:
            del self._dict[key]
########NEW FILE########
__FILENAME__ = debug
# Copyright 2009 Shikhar Bhushan
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from ncclient.transport import SessionListener

class PrintListener(SessionListener):

    def callback(self, root, raw):
        print('\n# RECEIVED MESSAGE with root=[tag=%r, attrs=%r] #\n%r\n' %
              (root[0], root[1], raw))

    def errback(self, err):
        print('\n# RECEIVED ERROR #\n%r\n' % err)

########NEW FILE########
__FILENAME__ = manager
# Copyright 2009 Shikhar Bhushan
# Copyright 2011 Leonidas Poulopoulos
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""This module is a thin layer of abstraction around the library. It exposes all core functionality."""

import capabilities
import operations
import transport

import logging

logger = logging.getLogger('ncclient.manager')

CAPABILITIES = [
    "urn:ietf:params:netconf:base:1.0",
    "urn:ietf:params:netconf:capability:writable-running:1.0",
    "urn:ietf:params:netconf:capability:candidate:1.0",
    "urn:ietf:params:netconf:capability:confirmed-commit:1.0",
    "urn:ietf:params:netconf:capability:rollback-on-error:1.0",
    "urn:ietf:params:netconf:capability:startup:1.0",
    "urn:ietf:params:netconf:capability:url:1.0?scheme=http,ftp,file,https,sftp",
    "urn:ietf:params:netconf:capability:validate:1.0",
    "urn:ietf:params:netconf:capability:xpath:1.0",
    "urn:liberouter:params:netconf:capability:power-control:1.0",
    "urn:ietf:params:netconf:capability:interleave:1.0"
]
"""A list of URI's representing the client's capabilities. This is used during the initial capability exchange. Modify this if you need to announce some capability not already included."""

OPERATIONS = {
    "get": operations.Get,
    "get_config": operations.GetConfig,
    "dispatch": operations.Dispatch,
    "edit_config": operations.EditConfig,
    "copy_config": operations.CopyConfig,
    "validate": operations.Validate,
    "commit": operations.Commit,
    "discard_changes": operations.DiscardChanges,
    "delete_config": operations.DeleteConfig,
    "lock": operations.Lock,
    "unlock": operations.Unlock,
    "close_session": operations.CloseSession,
    "kill_session": operations.KillSession,
    "poweroff_machine": operations.PoweroffMachine,
    "reboot_machine": operations.RebootMachine
}
"""Dictionary of method names and corresponding :class:`~ncclient.operations.RPC` subclasses. It is used to lookup operations, e.g. `get_config` is mapped to :class:`~ncclient.operations.GetConfig`. It is thus possible to add additional operations to the :class:`Manager` API."""

def connect_ssh(*args, **kwds):
    """Initialize a :class:`Manager` over the SSH transport. For documentation of arguments see :meth:`ncclient.transport.SSHSession.connect`.

    The underlying :class:`ncclient.transport.SSHSession` is created with :data:`CAPABILITIES`. It is first instructed to :meth:`~ncclient.transport.SSHSession.load_known_hosts` and then  all the provided arguments are passed directly to its implementation of :meth:`~ncclient.transport.SSHSession.connect`.
    """
    session = transport.SSHSession(capabilities.Capabilities(CAPABILITIES))
    session.load_known_hosts()
    session.connect(*args, **kwds)
    return Manager(session)

connect = connect_ssh
"Same as :func:`connect_ssh`, since SSH is the default (and currently, the only) transport."

class OpExecutor(type):

    def __new__(cls, name, bases, attrs):
        def make_wrapper(op_cls):
            def wrapper(self, *args, **kwds):
                return self.execute(op_cls, *args, **kwds)
            wrapper.func_doc = op_cls.request.func_doc
            return wrapper
        for op_name, op_cls in OPERATIONS.iteritems():
            attrs[op_name] = make_wrapper(op_cls)
        return super(OpExecutor, cls).__new__(cls, name, bases, attrs)

class Manager(object):

    """For details on the expected behavior of the operations and their parameters refer to :rfc:`4741`.

    Manager instances are also context managers so you can use it like this::

        with manager.connect("host") as m:
            # do your stuff

    ... or like this::

        m = manager.connect("host")
        try:
            # do your stuff
        finally:
            m.close_session()
    """

    __metaclass__ = OpExecutor

    def __init__(self, session, timeout=30):
        self._session = session
        self._async_mode = False
        self._timeout = timeout
        self._raise_mode = operations.RaiseMode.ALL

    def __enter__(self):
        return self

    def __exit__(self, *args):
        self.close_session()
        return False

    def __set_timeout(self, timeout):
        self._timeout = timeout

    def __set_async_mode(self, mode):
        self._async_mode = mode

    def __set_raise_mode(self, mode):
        assert(mode in (operations.RaiseMode.NONE, operations.RaiseMode.ERRORS, operations.RaiseMode.ALL))
        self._raise_mode = mode

    def execute(self, cls, *args, **kwds):
        return cls(self._session,
                   async=self._async_mode,
                   timeout=self._timeout,
                   raise_mode=self._raise_mode).request(*args, **kwds)

    def locked(self, target):
        """Returns a context manager for a lock on a datastore, where *target* is the name of the configuration datastore to lock, e.g.::

            with m.locked("running"):
                # do your stuff

        ... instead of::

            m.lock("running")
            try:
                # do your stuff
            finally:
                m.unlock("running")
        """
        return operations.LockContext(self._session, target)

    @property
    def client_capabilities(self):
        ":class:`~ncclient.capabilities.Capabilities` object representing the client's capabilities."
        return self._session._client_capabilities

    @property
    def server_capabilities(self):
        ":class:`~ncclient.capabilities.Capabilities` object representing the server's capabilities."
        return self._session._server_capabilities

    @property
    def session_id(self):
        "`session-id` assigned by the NETCONF server."
        return self._session.id

    @property
    def connected(self):
        "Whether currently connected to the NETCONF server."
        return self._session.connected

    async_mode = property(fget=lambda self: self._async_mode, fset=__set_async_mode)
    "Specify whether operations are executed asynchronously (`True`) or synchronously (`False`) (the default)."

    timeout = property(fget=lambda self: self._timeout, fset=__set_timeout)
    "Specify the timeout for synchronous RPC requests."

    raise_mode = property(fget=lambda self: self._raise_mode, fset=__set_raise_mode)
    "Specify which errors are raised as :exc:`~ncclient.operations.RPCError` exceptions. Valid values are the constants defined in :class:`~ncclient.operations.RaiseMode`. The default value is :attr:`~ncclient.operations.RaiseMode.ALL`."

########NEW FILE########
__FILENAME__ = edit
# Copyright 2009 Shikhar Bhushan
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from ncclient.xml_ import *

from rpc import RPC

import util

import logging

logger = logging.getLogger("ncclient.operations.edit")

"Operations related to changing device configuration"

class EditConfig(RPC):
    "`edit-config` RPC"

    def request(self, target, config, default_operation=None, test_option=None, error_option=None):
        """Loads all or part of the specified *config* to the *target* configuration datastore.

        *target* is the name of the configuration datastore being edited

        *config* is the configuration, which must be rooted in the `config` element. It can be specified either as a string or an :class:`~xml.etree.ElementTree.Element`.

        *default_operation* if specified must be one of { `"merge"`, `"replace"`, or `"none"` }

        *test_option* if specified must be one of { `"test_then_set"`, `"set"` }

        *error_option* if specified must be one of { `"stop-on-error"`, `"continue-on-error"`, `"rollback-on-error"` }

        The `"rollback-on-error"` *error_option* depends on the `:rollback-on-error` capability.
        """
        node = new_ele("edit-config")
        node.append(util.datastore_or_url("target", target, self._assert))
        if error_option is not None:
            if error_option == "rollback-on-error":
                self._assert(":rollback-on-error")
            sub_ele(node, "error-option").text = error_option
        if test_option is not None:
            self._assert(':validate')
            sub_ele(node, "test-option").text = test_option
        if default_operation is not None:
        # TODO: check if it is a valid default-operation
            sub_ele(node, "default-operation").text = default_operation
        node.append(validated_element(config, ("config", qualify("config"))))
        return self._request(node)


class DeleteConfig(RPC):
    "`delete-config` RPC"

    def request(self, target):
        """Delete a configuration datastore.

        *target* specifies the  name or URL of configuration datastore to delete

        :seealso: :ref:`srctarget_params`"""
        node = new_ele("delete-config")
        node.append(util.datastore_or_url("target", target, self._assert))
        return self._request(node)


class CopyConfig(RPC):
    "`copy-config` RPC"

    def request(self, source, target):
        """Create or replace an entire configuration datastore with the contents of another complete
        configuration datastore.

        *source* is the name of the configuration datastore to use as the source of the copy operation or `config` element containing the configuration subtree to copy

        *target* is the name of the configuration datastore to use as the destination of the copy operation

        :seealso: :ref:`srctarget_params`"""
        node = new_ele("copy-config")
        node.append(util.datastore_or_url("target", target, self._assert))
        node.append(util.datastore_or_url("source", source, self._assert))
        return self._request(node)


class Validate(RPC):
    "`validate` RPC. Depends on the `:validate` capability."

    DEPENDS = [':validate']

    def request(self, source):
        """Validate the contents of the specified configuration.

        *source* is the name of the configuration datastore being validated or `config` element containing the configuration subtree to be validated

        :seealso: :ref:`srctarget_params`"""
        node = new_ele("validate")
        try:
            src = validated_element(source, ("config", qualify("config")))
        except Exception as e:
            logger.debug(e)
            src = util.datastore_or_url("source", source, self._assert)
        (node if src.tag == "source" else sub_ele(node, "source")).append(src)
        return self._request(node)


class Commit(RPC):
    "`commit` RPC. Depends on the `:candidate` capability, and the `:confirmed-commit`."

    DEPENDS = [':candidate']

    def request(self, confirmed=False, timeout=None):
        """Commit the candidate configuration as the device's new current configuration. Depends on the `:candidate` capability.

        A confirmed commit (i.e. if *confirmed* is `True`) is reverted if there is no followup commit within the *timeout* interval. If no timeout is specified the confirm timeout defaults to 600 seconds (10 minutes). A confirming commit may have the *confirmed* parameter but this is not required. Depends on the `:confirmed-commit` capability.

        *confirmed* whether this is a confirmed commit

        *timeout* specifies the confirm timeout in seconds"""
        node = new_ele("commit")
        if confirmed:
            self._assert(":confirmed-commit")
            sub_ele(node, "confirmed")
            if timeout is not None:
                sub_ele(node, "confirm-timeout").text = timeout
        return self._request(node)


class DiscardChanges(RPC):
    "`discard-changes` RPC. Depends on the `:candidate` capability."

    DEPENDS = [":candidate"]

    def request(self):
        """Revert the candidate configuration to the currently running configuration. Any uncommitted changes are discarded."""
        return self._request(new_ele("discard-changes"))
########NEW FILE########
__FILENAME__ = errors
# Copyright 2009 Shikhar Bhushan
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from ncclient import NCClientError

class OperationError(NCClientError):
    pass

class TimeoutExpiredError(NCClientError):
    pass

class MissingCapabilityError(NCClientError):
    pass

########NEW FILE########
__FILENAME__ = flowmon
# Copyright 2h009 Shikhar Bhushan
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

'Power-control operations'

from ncclient.xml_ import *

from rpc import RPC

PC_URN = "urn:liberouter:params:xml:ns:netconf:power-control:1.0"

class PoweroffMachine(RPC):

    "*poweroff-machine* RPC (flowmon)"

    DEPENDS = ["urn:liberouter:param:netconf:capability:power-control:1.0"]
    
    def request(self):
        return self._request(new_ele(qualify("poweroff-machine", PC_URN)))

class RebootMachine(RPC):

    "*reboot-machine* RPC (flowmon)"

    DEPENDS = ["urn:liberouter:params:netconf:capability:power-control:1.0"]

    def request(self):
        return self._request(new_ele(qualify("reboot-machine", PC_URN)))

########NEW FILE########
__FILENAME__ = lock
# Copyright 2h009 Shikhar Bhushan
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"Locking-related NETCONF operations"

from ncclient.xml_ import *

from rpc import RaiseMode, RPC

# TODO: parse session-id from a lock-denied error, and raise a tailored exception?

class Lock(RPC):

    "`lock` RPC"
    
    def request(self, target):
        """Allows the client to lock the configuration system of a device.

        *target* is the name of the configuration datastore to lock
        """
        node = new_ele("lock")
        sub_ele(sub_ele(node, "target"), target)
        return self._request(node)


class Unlock(RPC):

    "`unlock` RPC"
    
    def request(self, target):
        """Release a configuration lock, previously obtained with the lock operation.

        *target* is the name of the configuration datastore to unlock
        """
        node = new_ele("unlock")
        sub_ele(sub_ele(node, "target"), target)
        return self._request(node)


class LockContext:

    """A context manager for the :class:`Lock` / :class:`Unlock` pair of RPC's.

    Any `rpc-error` will be raised as an exception.

    Initialise with (:class:`Session <ncclient.transport.Session>`) instance and lock target.
    """

    def __init__(self, session, target):
        self.session = session
        self.target = target

    def __enter__(self):
        Lock(self.session, raise_mode=RaiseMode.ERRORS).request(self.target)
        return self

    def __exit__(self, *args):
        Unlock(self.session, raise_mode=RaiseMode.ERRORS).request(self.target)
        return False

########NEW FILE########
__FILENAME__ = retrieve
# Copyright 2009 Shikhar Bhushan
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from rpc import RPC, RPCReply

from ncclient.xml_ import *

import util

class GetReply(RPCReply):

    """Adds attributes for the *data* element to `RPCReply`."""

    def _parsing_hook(self, root):
        self._data = None
        if not self._errors:
            self._data = root.find(qualify("data"))
    
    @property
    def data_ele(self):
        "*data* element as an :class:`~xml.etree.ElementTree.Element`"
        if not self._parsed:
            self.parse()
        return self._data

    @property
    def data_xml(self):
        "*data* element as an XML string"
        if not self._parsed:
            self.parse()
        return to_xml(self._data)
    
    data = data_ele
    "Same as :attr:`data_ele`"


class Get(RPC):

    "The *get* RPC."

    REPLY_CLS = GetReply
    "See :class:`GetReply`."

    def request(self, filter=None):
        """Retrieve running configuration and device state information.

        *filter* specifies the portion of the configuration to retrieve (by default entire configuration is retrieved)

        :seealso: :ref:`filter_params`
        """
        node = new_ele("get")
        if filter is not None:
            node.append(util.build_filter(filter))
        return self._request(node)


class GetConfig(RPC):

    "The *get-config* RPC."

    REPLY_CLS = GetReply
    "See :class:`GetReply`."

    def request(self, source, filter=None):
        """Retrieve all or part of a specified configuration.

        *source* name of the configuration datastore being queried

        *filter* specifies the portion of the configuration to retrieve (by default entire configuration is retrieved)

        :seealso: :ref:`filter_params`"""
        node = new_ele("get-config")
        node.append(util.datastore_or_url("source", source, self._assert))
        if filter is not None:
            node.append(util.build_filter(filter))
        return self._request(node)

class Dispatch(RPC):

    "Generic retrieving wrapper"

    REPLY_CLS = GetReply
    "See :class:`GetReply`."

    def request(self, rpc_command, source=None, filter=None):
        """
        *rpc_command* specifies rpc command to be dispatched either in plain text or in xml element format (depending on command)

        *source* name of the configuration datastore being queried

        *filter* specifies the portion of the configuration to retrieve (by default entire configuration is retrieved)

        :seealso: :ref:`filter_params`

        Examples of usage::

        dispatch('clear-arp-table')

        or dispatch element like ::

        xsd_fetch = new_ele('get-xnm-information')
        sub_ele(xsd_fetch, 'type').text="xml-schema"
        sub_ele(xsd_fetch, 'namespace').text="junos-configuration"
        dispatch(xsd_fetch)
        """

        if ET.iselement(rpc_command):
            node = rpc_command
        else:
            node = new_ele(rpc_command)
        if source is not None:
            node.append(util.datastore_or_url("source", source, self._assert))
        if filter is not None:
            node.append(util.build_filter(filter))
        return self._request(node)


########NEW FILE########
__FILENAME__ = rpc
# Copyright 2009 Shikhar Bhushan
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from threading import Event, Lock
from uuid import uuid1

from ncclient.xml_ import *
from ncclient.transport import SessionListener

from errors import OperationError, TimeoutExpiredError, MissingCapabilityError

import logging
logger = logging.getLogger("ncclient.operations.rpc")


class RPCError(OperationError):

    "Represents an `rpc-error`. It is a type of :exc:`OperationError` and can be raised as such."
    
    tag_to_attr = {
        qualify("error-type"): "_type",
        qualify("error-tag"): "_tag",
        qualify("error-severity"): "_severity",
        qualify("error-info"): "_info",
        qualify("error-path"): "_path",
        qualify("error-message"): "_message"
    }
    
    def __init__(self, raw):
        self._raw = raw
        for attr in RPCError.tag_to_attr.values():
            setattr(self, attr, None)
        for subele in raw:
            attr = RPCError.tag_to_attr.get(subele.tag, None)
            if attr is not None:
                setattr(self, attr, subele.text if attr != "_info" else to_xml(subele) )
        if self.message is not None:
            OperationError.__init__(self, self.message)
        else:
            OperationError.__init__(self, self.to_dict())
    
    def to_dict(self):
        return dict([ (attr[1:], getattr(self, attr)) for attr in RPCError.tag_to_attr.values() ])
    
    @property
    def xml(self):
        "The `rpc-error` element as returned in XML."
        return self._raw
    
    @property
    def type(self):
        "The contents of the `error-type` element."
        return self._type
    
    @property
    def tag(self):
        "The contents of the `error-tag` element."
        return self._tag
    
    @property
    def severity(self):
        "The contents of the `error-severity` element."
        return self._severity
    
    @property
    def path(self):
        "The contents of the `error-path` element if present or `None`."
        return self._path
    
    @property
    def message(self):
        "The contents of the `error-message` element if present or `None`."
        return self._message
    
    @property
    def info(self):
        "XML string or `None`; representing the `error-info` element."
        return self._info


class RPCReply:

    """Represents an *rpc-reply*. Only concerns itself with whether the operation was successful.

    .. note::
        If the reply has not yet been parsed there is an implicit, one-time parsing overhead to
        accessing some of the attributes defined by this class.
    """
    
    ERROR_CLS = RPCError
    "Subclasses can specify a different error class, but it should be a subclass of `RPCError`."
    
    def __init__(self, raw):
        self._raw = raw
        self._parsed = False
        self._root = None
        self._errors = []

    def __repr__(self):
        return self._raw
    
    def parse(self):
        "Parses the *rpc-reply*."
        if self._parsed: return
        root = self._root = to_ele(self._raw) # The <rpc-reply> element
        # Per RFC 4741 an <ok/> tag is sent when there are no errors or warnings
        ok = root.find(qualify("ok"))
        if ok is None:
            # Create RPCError objects from <rpc-error> elements
            error = root.find(qualify("rpc-error"))
            if error is not None:
                for err in root.getiterator(error.tag):
                    # Process a particular <rpc-error>
                    self._errors.append(self.ERROR_CLS(err))
        self._parsing_hook(root)
        self._parsed = True

    def _parsing_hook(self, root):
        "No-op by default. Gets passed the *root* element for the reply."
        pass
    
    @property
    def xml(self):
        "*rpc-reply* element as returned."
        return self._raw
    
    @property
    def ok(self):
        "Boolean value indicating if there were no errors."
        return not self.errors # empty list => false
    
    @property
    def error(self):
        "Returns the first :class:`RPCError` and `None` if there were no errors."
        self.parse()
        if self._errors:
            return self._errors[0]
        else:
            return None
    
    @property
    def errors(self):
        "List of `RPCError` objects. Will be empty if there were no *rpc-error* elements in reply."
        self.parse()
        return self._errors


class RPCReplyListener(SessionListener): # internal use
    
    creation_lock = Lock()
    
    # one instance per session -- maybe there is a better way??
    def __new__(cls, session):
        with RPCReplyListener.creation_lock:
            instance = session.get_listener_instance(cls)
            if instance is None:
                instance = object.__new__(cls)
                instance._lock = Lock()
                instance._id2rpc = {}
                #instance._pipelined = session.can_pipeline
                session.add_listener(instance)
            return instance

    def register(self, id, rpc):
        with self._lock:
            self._id2rpc[id] = rpc

    def callback(self, root, raw):
        tag, attrs = root
        if tag != qualify("rpc-reply"):
            return
        for key in attrs: # in the <rpc-reply> attributes
            if key == "message-id": # if we found msgid attr
                id = attrs[key] # get the msgid
                with self._lock:
                    try:
                        rpc = self._id2rpc[id] # the corresponding rpc
                        logger.debug("Delivering to %r" % rpc)
                        rpc.deliver_reply(raw)
                    except KeyError:
                        raise OperationError("Unknown 'message-id': %s", id)
                    # no catching other exceptions, fail loudly if must
                    else:
                        # if no error delivering, can del the reference to the RPC
                        del self._id2rpc[id]
                        break
        else:
            raise OperationError("Could not find 'message-id' attribute in <rpc-reply>")
    
    def errback(self, err):
        try:
            for rpc in self._id2rpc.values():
                rpc.deliver_error(err)
        finally:
            self._id2rpc.clear()


class RaiseMode(object):

    NONE = 0
    "Don't attempt to raise any type of `rpc-error` as :exc:`RPCError`."

    ERRORS = 1
    "Raise only when the `error-type` indicates it is an honest-to-god error."

    ALL = 2
    "Don't look at the `error-type`, always raise."


class RPC(object):
    
    """Base class for all operations, directly corresponding to *rpc* requests. Handles making the request, and taking delivery of the reply."""

    DEPENDS = []
    """Subclasses can specify their dependencies on capabilities as a list of URI's or abbreviated names, e.g. ':writable-running'. These are verified at the time of instantiation. If the capability is not available, :exc:`MissingCapabilityError` is raised."""
    
    REPLY_CLS = RPCReply
    "By default :class:`RPCReply`. Subclasses can specify a :class:`RPCReply` subclass."
    
    def __init__(self, session, async=False, timeout=30, raise_mode=RaiseMode.NONE):
        """
        *session* is the :class:`~ncclient.transport.Session` instance

        *async* specifies whether the request is to be made asynchronously, see :attr:`is_async`

        *timeout* is the timeout for a synchronous request, see :attr:`timeout`

        *raise_mode* specifies the exception raising mode, see :attr:`raise_mode`
        """
        self._session = session
        try:
            for cap in self.DEPENDS:
                self._assert(cap)
        except AttributeError:
            pass
        self._async = async
        self._timeout = timeout
        self._raise_mode = raise_mode
        self._id = uuid1().urn # Keeps things simple instead of having a class attr with running ID that has to be locked
        self._listener = RPCReplyListener(session)
        self._listener.register(self._id, self)
        self._reply = None
        self._error = None
        self._event = Event()
    
    def _wrap(self, subele):
        # internal use
        ele = new_ele("rpc", {"message-id": self._id})
        ele.append(subele)
        return to_xml(ele)

    def _request(self, op):
        """Implementations of :meth:`request` call this method to send the request and process the reply.
        
        In synchronous mode, blocks until the reply is received and returns :class:`RPCReply`. Depending on the :attr:`raise_mode` a `rpc-error` element in the reply may lead to an :exc:`RPCError` exception.
        
        In asynchronous mode, returns immediately, returning `self`. The :attr:`event` attribute will be set when the reply has been received (see :attr:`reply`) or an error occured (see :attr:`error`).
        
        *op* is the operation to be requested as an :class:`~xml.etree.ElementTree.Element`
        """
        logger.info('Requesting %r' % self.__class__.__name__)
        req = self._wrap(op)
        self._session.send(req)
        if self._async:
            logger.debug('Async request, returning %r', self)
            return self
        else:
            logger.debug('Sync request, will wait for timeout=%r' % self._timeout)
            self._event.wait(self._timeout)
            if self._event.isSet():
                if self._error:
                    # Error that prevented reply delivery
                    raise self._error
                self._reply.parse()
                if self._reply.error is not None:
                    # <rpc-error>'s [ RPCError ]
                    if self._raise_mode == RaiseMode.ALL:
                        raise self._reply.error
                    elif (self._raise_mode == RaiseMode.ERRORS and self._reply.error.type == "error"):
                        raise self._reply.error
                return self._reply
            else:
                raise TimeoutExpiredError

    def request(self):
        """Subclasses must implement this method. Typically only the request needs to be built as an
        :class:`~xml.etree.ElementTree.Element` and everything else can be handed off to
        :meth:`_request`."""
        pass
    
    def _assert(self, capability):
        """Subclasses can use this method to verify that a capability is available with the NETCONF
        server, before making a request that requires it. A :exc:`MissingCapabilityError` will be
        raised if the capability is not available."""
        if capability not in self._session.server_capabilities:
            raise MissingCapabilityError('Server does not support [%s]' % capability)
    
    def deliver_reply(self, raw):
        # internal use
        self._reply = self.REPLY_CLS(raw)
        self._event.set()

    def deliver_error(self, err):
        # internal use
        self._error = err
        self._event.set()
    
    @property
    def reply(self):
        ":class:`RPCReply` element if reply has been received or `None`"
        return self._reply
    
    @property
    def error(self):
        """:exc:`Exception` type if an error occured or `None`.
        
        .. note::
            This represents an error which prevented a reply from being received. An *rpc-error*
            does not fall in that category -- see `RPCReply` for that.
        """
        return self._error
    
    @property
    def id(self):
        "The *message-id* for this RPC."
        return self._id
    
    @property
    def session(self):
        "The `~ncclient.transport.Session` object associated with this RPC."
        return self._session

    @property
    def event(self):
        """:class:`~threading.Event` that is set when reply has been received or when an error preventing
        delivery of the reply occurs.
        """
        return self._event

    def __set_async(self, async=True):
        self._async = async
        if async and not session.can_pipeline:
            raise UserWarning('Asynchronous mode not supported for this device/session')

    def __set_raise_mode(self, mode):
        assert(choice in ("all", "errors", "none"))
        self._raise_mode = mode

    def __set_timeout(self, timeout):
        self._timeout = timeout

    raise_mode = property(fget=lambda self: self._raise_mode, fset=__set_raise_mode)
    """Depending on this exception raising mode, an `rpc-error` in the reply may be raised as an :exc:`RPCError` exception. Valid values are the constants defined in :class:`RaiseMode`. """
    
    is_async = property(fget=lambda self: self._async, fset=__set_async)
    """Specifies whether this RPC will be / was requested asynchronously. By default RPC's are synchronous."""
    
    timeout = property(fget=lambda self: self._timeout, fset=__set_timeout)
    """Timeout in seconds for synchronous waiting defining how long the RPC request will block on a reply before raising :exc:`TimeoutExpiredError`.
    
    Irrelevant for asynchronous usage.
    """

########NEW FILE########
__FILENAME__ = session
# Copyright 2009 Shikhar Bhushan
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"Session-related NETCONF operations"

from ncclient.xml_ import *

from rpc import RPC

class CloseSession(RPC):

    "`close-session` RPC. The connection to NETCONF server is also closed."

    def request(self):
        "Request graceful termination of the NETCONF session, and also close the transport."
        try:
            return self._request(new_ele("close-session"))
        finally:
            self.session.close()


class KillSession(RPC):

    "`kill-session` RPC."

    def request(self, session_id):
        """Force the termination of a NETCONF session (not the current one!)

        *session_id* is the session identifier of the NETCONF session to be terminated as a string
        """
        node = new_ele("kill-session")
        sub_ele(node, "session-id").text = session_id
        return self._request(node)

########NEW FILE########
__FILENAME__ = subscribe
# Copyright 2009 Shikhar Bhushan
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# TODO

class Notification:
    pass

class CreateSubscription:
    pass

class NotificationListener:
    pass

########NEW FILE########
__FILENAME__ = util
# Copyright 2009 Shikhar Bhushan
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

'Boilerplate ugliness'

from ncclient.xml_ import *

from errors import OperationError, MissingCapabilityError

def one_of(*args):
    "Verifies that only one of the arguments is not None"
    for i, arg in enumerate(args):
        if arg is not None:
            for argh in args[i+1:]:
                if argh is not None:
                    raise OperationError("Too many parameters")
            else:
                return
    raise OperationError("Insufficient parameters")

def datastore_or_url(wha, loc, capcheck=None):
    node = new_ele(wha)
    if "://" in loc: # e.g. http://, file://, ftp://
        if capcheck is not None:
            capcheck(":url") # url schema check at some point!
            sub_ele(node, "url").text = loc
    else:
        #if loc == 'candidate':
        #    capcheck(':candidate')
        #elif loc == 'startup':
        #    capcheck(':startup')
        #elif loc == 'running' and wha == 'target':
        #    capcheck(':writable-running')
        sub_ele(node, loc)
    return node

def build_filter(spec, capcheck=None):
    type = None
    if isinstance(spec, tuple):
        type, criteria = spec
        rep = new_ele("filter", type=type)
        if type == "xpath":
            rep.attrib["select"] = criteria
        elif type == "subtree":
            rep.append(to_ele(criteria))
        else:
            raise OperationError("Invalid filter type")
    else:
        rep = validated_element(spec, ("filter", qualify("filter")),
                                        attrs=("type",))
        # TODO set type var here, check if select attr present in case of xpath..
    if type == "xpath" and capcheck is not None:
        capcheck(":xpath")
    return rep

########NEW FILE########
__FILENAME__ = errors
# Copyright 2009 Shikhar Bhushan
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from ncclient import NCClientError

class TransportError(NCClientError):
    pass

class AuthenticationError(TransportError):
    pass

class SessionCloseError(TransportError):

    def __init__(self, in_buf, out_buf=None):
        msg = 'Unexpected session close'
        if in_buf:
            msg += '\nIN_BUFFER: `%s`' % in_buf
        if out_buf:
            msg += ' OUT_BUFFER: `%s`' % out_buf
        SSHError.__init__(self, msg)

class SSHError(TransportError):
    pass

class SSHUnknownHostError(SSHError):

    def __init__(self, host, fingerprint):
        SSHError.__init__(self, 'Unknown host key [%s] for [%s]' % (fingerprint, host))
        self.host = host
        self.fingerprint = fingerprint

########NEW FILE########
__FILENAME__ = session
# Copyright 2009 Shikhar Bhushan
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from Queue import Queue
from threading import Thread, Lock, Event

from ncclient.xml_ import *
from ncclient.capabilities import Capabilities

from errors import TransportError

import logging
logger = logging.getLogger('ncclient.transport.session')

class Session(Thread):

    "Base class for use by transport protocol implementations."

    def __init__(self, capabilities):
        Thread.__init__(self)
        self.setDaemon(True)
        self._listeners = set()
        self._lock = Lock()
        self.setName('session')
        self._q = Queue()
        self._client_capabilities = capabilities
        self._server_capabilities = None # yet
        self._id = None # session-id
        self._connected = False # to be set/cleared by subclass implementation
        logger.debug('%r created: client_capabilities=%r' %
                     (self, self._client_capabilities))

    def _dispatch_message(self, raw):
        try:
            root = parse_root(raw)
        except Exception as e:
            logger.error('error parsing dispatch message: %s' % e)
            return
        with self._lock:
            listeners = list(self._listeners)
        for l in listeners:
            logger.debug('dispatching message to %r: %s' % (l, raw))
            l.callback(root, raw) # no try-except; fail loudly if you must!
    
    def _dispatch_error(self, err):
        with self._lock:
            listeners = list(self._listeners)
        for l in listeners:
            logger.debug('dispatching error to %r' % l)
            try: # here we can be more considerate with catching exceptions
                l.errback(err) 
            except Exception as e:
                logger.warning('error dispatching to %r: %r' % (l, e))

    def _post_connect(self):
        "Greeting stuff"
        init_event = Event()
        error = [None] # so that err_cb can bind error[0]. just how it is.
        # callbacks
        def ok_cb(id, capabilities):
            self._id = id
            self._server_capabilities = capabilities
            init_event.set()
        def err_cb(err):
            error[0] = err
            init_event.set()
        listener = HelloHandler(ok_cb, err_cb)
        self.add_listener(listener)
        self.send(HelloHandler.build(self._client_capabilities))
        logger.debug('starting main loop')
        self.start()
        # we expect server's hello message
        init_event.wait()
        # received hello message or an error happened
        self.remove_listener(listener)
        if error[0]:
            raise error[0]
        #if ':base:1.0' not in self.server_capabilities:
        #    raise MissingCapabilityError(':base:1.0')
        logger.info('initialized: session-id=%s | server_capabilities=%s' %
                    (self._id, self._server_capabilities))

    def add_listener(self, listener):
        """Register a listener that will be notified of incoming messages and
        errors.

        :type listener: :class:`SessionListener`
        """
        logger.debug('installing listener %r' % listener)
        if not isinstance(listener, SessionListener):
            raise SessionError("Listener must be a SessionListener type")
        with self._lock:
            self._listeners.add(listener)

    def remove_listener(self, listener):
        """Unregister some listener; ignore if the listener was never
        registered.

        :type listener: :class:`SessionListener`
        """
        logger.debug('discarding listener %r' % listener)
        with self._lock:
            self._listeners.discard(listener)

    def get_listener_instance(self, cls):
        """If a listener of the specified type is registered, returns the
        instance.

        :type cls: :class:`SessionListener`
        """
        with self._lock:
            for listener in self._listeners:
                if isinstance(listener, cls):
                    return listener

    def connect(self, *args, **kwds): # subclass implements
        raise NotImplementedError

    def run(self): # subclass implements
        raise NotImplementedError

    def send(self, message):
        """Send the supplied *message* (xml string) to NETCONF server."""
        if not self.connected:
            raise TransportError('Not connected to NETCONF server')
        logger.debug('queueing %s' % message)
        self._q.put(message)

    ### Properties

    @property
    def connected(self):
        "Connection status of the session."
        return self._connected

    @property
    def client_capabilities(self):
        "Client's :class:`Capabilities`"
        return self._client_capabilities

    @property
    def server_capabilities(self):
        "Server's :class:`Capabilities`"
        return self._server_capabilities

    @property
    def id(self):
        """A string representing the `session-id`. If the session has not been initialized it will be `None`"""
        return self._id


class SessionListener(object):

    """Base class for :class:`Session` listeners, which are notified when a new
    NETCONF message is received or an error occurs.

    .. note::
        Avoid time-intensive tasks in a callback's context.
    """

    def callback(self, root, raw):
        """Called when a new XML document is received. The *root* argument allows the callback to determine whether it wants to further process the document.

        Here, *root* is a tuple of *(tag, attributes)* where *tag* is the qualified name of the root element and *attributes* is a dictionary of its attributes (also qualified names).

        *raw* will contain the XML document as a string.
        """
        raise NotImplementedError

    def errback(self, ex):
        """Called when an error occurs.

        :type ex: :exc:`Exception`
        """
        raise NotImplementedError


class HelloHandler(SessionListener):

    def __init__(self, init_cb, error_cb):
        self._init_cb = init_cb
        self._error_cb = error_cb

    def callback(self, root, raw):
        tag, attrs = root
        if (tag == qualify("hello")) or (tag == "hello"):
            try:
                id, capabilities = HelloHandler.parse(raw)
            except Exception as e:
                self._error_cb(e)
            else:
                self._init_cb(id, capabilities)

    def errback(self, err):
        self._error_cb(err)

    @staticmethod
    def build(capabilities):
        "Given a list of capability URI's returns <hello> message XML string"
        hello = new_ele("hello")
        caps = sub_ele(hello, "capabilities")
        def fun(uri): sub_ele(caps, "capability").text = uri
        map(fun, capabilities)
        return to_xml(hello)

    @staticmethod
    def parse(raw):
        "Returns tuple of (session-id (str), capabilities (Capabilities)"
        sid, capabilities = 0, []
        root = to_ele(raw)
        for child in root.getchildren():
            if child.tag == qualify("session-id") or child.tag == "session-id":
                sid = child.text
            elif child.tag == qualify("capabilities") or child.tag == "capabilities" :
                for cap in child.getchildren():
                    if cap.tag == qualify("capability") or cap.tag == "capability":
                        capabilities.append(cap.text)
        return sid, Capabilities(capabilities)

########NEW FILE########
__FILENAME__ = ssh
# Copyright 2009 Shikhar Bhushan
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import os
import socket
import getpass
from binascii import hexlify
from cStringIO import StringIO
from select import select

import paramiko

from errors import AuthenticationError, SessionCloseError, SSHError, SSHUnknownHostError
from session import Session

import logging
logger = logging.getLogger("ncclient.transport.ssh")

BUF_SIZE = 4096
MSG_DELIM = "]]>]]>"
TICK = 0.1

def default_unknown_host_cb(host, fingerprint):
    """An unknown host callback returns `True` if it finds the key acceptable, and `False` if not.

    This default callback always returns `False`, which would lead to :meth:`connect` raising a :exc:`SSHUnknownHost` exception.
    
    Supply another valid callback if you need to verify the host key programatically.

    *host* is the hostname that needs to be verified

    *fingerprint* is a hex string representing the host key fingerprint, colon-delimited e.g. `"4b:69:6c:72:6f:79:20:77:61:73:20:68:65:72:65:21"`
    """
    return False

def _colonify(fp):
    finga = fp[:2]
    for idx  in range(2, len(fp), 2):
        finga += ":" + fp[idx:idx+2]
    return finga

class SSHSession(Session):

    "Implements a :rfc:`4742` NETCONF session over SSH."

    def __init__(self, capabilities):
        Session.__init__(self, capabilities)
        self._host_keys = paramiko.HostKeys()
        self._transport = None
        self._connected = False
        self._channel = None
        self._buffer = StringIO() # for incoming data
        # parsing-related, see _parse()
        self._parsing_state = 0
        self._parsing_pos = 0
    
    def _parse(self):
        "Messages ae delimited by MSG_DELIM. The buffer could have grown by a maximum of BUF_SIZE bytes everytime this method is called. Retains state across method calls and if a byte has been read it will not be considered again."
        delim = MSG_DELIM
        n = len(delim) - 1
        expect = self._parsing_state
        buf = self._buffer
        buf.seek(self._parsing_pos)
        while True:
            x = buf.read(1)
            if not x: # done reading
                break
            elif x == delim[expect]: # what we expected
                expect += 1 # expect the next delim char
            else:
                expect = 0
                continue
            # loop till last delim char expected, break if other char encountered
            for i in range(expect, n):
                x = buf.read(1)
                if not x: # done reading
                    break
                if x == delim[expect]: # what we expected
                    expect += 1 # expect the next delim char
                else:
                    expect = 0 # reset
                    break
            else: # if we didn't break out of the loop, full delim was parsed
                msg_till = buf.tell() - n
                buf.seek(0)
                logger.debug('parsed new message')
                self._dispatch_message(buf.read(msg_till).strip())
                buf.seek(n+1, os.SEEK_CUR)
                rest = buf.read()
                buf = StringIO()
                buf.write(rest)
                buf.seek(0)
                expect = 0
        self._buffer = buf
        self._parsing_state = expect
        self._parsing_pos = self._buffer.tell()

    def load_known_hosts(self, filename=None):
        """Load host keys from an openssh :file:`known_hosts`-style file. Can be called multiple times.

        If *filename* is not specified, looks in the default locations i.e. :file:`~/.ssh/known_hosts` and :file:`~/ssh/known_hosts` for Windows.
        """
        if filename is None:
            filename = os.path.expanduser('~/.ssh/known_hosts')
            try:
                self._host_keys.load(filename)
            except IOError:
                # for windows
                filename = os.path.expanduser('~/ssh/known_hosts')
                try:
                    self._host_keys.load(filename)
                except IOError:
                    pass
        else:
            self._host_keys.load(filename)

    def close(self):
        if self._transport.is_active():
            self._transport.close()
        self._connected = False

    # REMEMBER to update transport.rst if sig. changes, since it is hardcoded there
    def connect(self, host, port=830, timeout=None, unknown_host_cb=default_unknown_host_cb,
                username=None, password=None, key_filename=None, allow_agent=True, look_for_keys=True):
        """Connect via SSH and initialize the NETCONF session. First attempts the publickey authentication method and then password authentication.

        To disable attempting publickey authentication altogether, call with *allow_agent* and *look_for_keys* as `False`.

        *host* is the hostname or IP address to connect to

        *port* is by default 830, but some devices use the default SSH port of 22 so this may need to be specified

        *timeout* is an optional timeout for socket connect

        *unknown_host_cb* is called when the server host key is not recognized. It takes two arguments, the hostname and the fingerprint (see the signature of :func:`default_unknown_host_cb`)

        *username* is the username to use for SSH authentication

        *password* is the password used if using password authentication, or the passphrase to use for unlocking keys that require it

        *key_filename* is a filename where a the private key to be used can be found

        *allow_agent* enables querying SSH agent (if found) for keys

        *look_for_keys* enables looking in the usual locations for ssh keys (e.g. :file:`~/.ssh/id_*`)
        """
        if username is None:
            username = getpass.getuser()
        
        sock = None
        for res in socket.getaddrinfo(host, port, socket.AF_UNSPEC, socket.SOCK_STREAM):
            af, socktype, proto, canonname, sa = res
            try:
                sock = socket.socket(af, socktype, proto)
                sock.settimeout(timeout)
            except socket.error:
                continue
            try:
                sock.connect(sa)
            except socket.error:
                sock.close()
                continue
            break
        else:
            raise SSHError("Could not open socket to %s:%s" % (host, port))

        t = self._transport = paramiko.Transport(sock)
        t.set_log_channel(logger.name)

        try:
            t.start_client()
        except paramiko.SSHException:
            raise SSHError('Negotiation failed')

        # host key verification
        server_key = t.get_remote_server_key()
        known_host = self._host_keys.check(host, server_key)

        fingerprint = _colonify(hexlify(server_key.get_fingerprint()))

        if not known_host and not unknown_host_cb(host, fingerprint):
            raise SSHUnknownHostError(host, fingerprint)

        if key_filename is None:
            key_filenames = []
        elif isinstance(key_filename, basestring):
            key_filenames = [ key_filename ]
        else:
            key_filenames = key_filename

        self._auth(username, password, key_filenames, allow_agent, look_for_keys)

        self._connected = True # there was no error authenticating

        c = self._channel = self._transport.open_session()
        c.set_name("netconf")
        c.invoke_subsystem("netconf")

        self._post_connect()
    
    # on the lines of paramiko.SSHClient._auth()
    def _auth(self, username, password, key_filenames, allow_agent,
              look_for_keys):
        saved_exception = None

        for key_filename in key_filenames:
            for cls in (paramiko.RSAKey, paramiko.DSSKey):
                try:
                    key = cls.from_private_key_file(key_filename, password)
                    logger.debug("Trying key %s from %s" %
                              (hexlify(key.get_fingerprint()), key_filename))
                    self._transport.auth_publickey(username, key)
                    return
                except Exception as e:
                    saved_exception = e
                    logger.debug(e)

        if allow_agent:
            for key in paramiko.Agent().get_keys():
                try:
                    logger.debug("Trying SSH agent key %s" %
                                 hexlify(key.get_fingerprint()))
                    self._transport.auth_publickey(username, key)
                    return
                except Exception as e:
                    saved_exception = e
                    logger.debug(e)

        keyfiles = []
        if look_for_keys:
            rsa_key = os.path.expanduser("~/.ssh/id_rsa")
            dsa_key = os.path.expanduser("~/.ssh/id_dsa")
            if os.path.isfile(rsa_key):
                keyfiles.append((paramiko.RSAKey, rsa_key))
            if os.path.isfile(dsa_key):
                keyfiles.append((paramiko.DSSKey, dsa_key))
            # look in ~/ssh/ for windows users:
            rsa_key = os.path.expanduser("~/ssh/id_rsa")
            dsa_key = os.path.expanduser("~/ssh/id_dsa")
            if os.path.isfile(rsa_key):
                keyfiles.append((paramiko.RSAKey, rsa_key))
            if os.path.isfile(dsa_key):
                keyfiles.append((paramiko.DSSKey, dsa_key))

        for cls, filename in keyfiles:
            try:
                key = cls.from_private_key_file(filename, password)
                logger.debug("Trying discovered key %s in %s" %
                          (hexlify(key.get_fingerprint()), filename))
                self._transport.auth_publickey(username, key)
                return
            except Exception as e:
                saved_exception = e
                logger.debug(e)

        if password is not None:
            try:
                self._transport.auth_password(username, password)
                return
            except Exception as e:
                saved_exception = e
                logger.debug(e)

        if saved_exception is not None:
            # need pep-3134 to do this right
            raise AuthenticationError(repr(saved_exception))

        raise AuthenticationError("No authentication methods available")

    def run(self):
        chan = self._channel
        q = self._q
        try:
            while True:
                # select on a paramiko ssh channel object does not ever return it in the writable list, so channels don't exactly emulate the socket api
                r, w, e = select([chan], [], [], TICK)
                # will wakeup evey TICK seconds to check if something to send, more if something to read (due to select returning chan in readable list)
                if r:
                    data = chan.recv(BUF_SIZE)
                    if data:
                        self._buffer.write(data)
                        self._parse()
                    else:
                        raise SessionCloseError(self._buffer.getvalue())
                if not q.empty() and chan.send_ready():
                    logger.debug("Sending message")
                    data = q.get() + MSG_DELIM
                    while data:
                        n = chan.send(data)
                        if n <= 0:
                            raise SessionCloseError(self._buffer.getvalue(), data)
                        data = data[n:]
        except Exception as e:
            logger.debug("Broke out of main loop, error=%r", e)
            self.close()
            self._dispatch_error(e)

    @property
    def transport(self):
        "Underlying `paramiko.Transport <http://www.lag.net/paramiko/docs/paramiko.Transport-class.html>`_ object. This makes it possible to call methods like :meth:`~paramiko.Transport.set_keepalive` on it."
        return self._transport

########NEW FILE########
__FILENAME__ = xml_
# Copyright 2009 Shikhar Bhushan
# Copyright 2011 Leonidas Poulopoulos
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"Methods for creating, parsing, and dealing with XML and ElementTree objects."

from cStringIO import StringIO
from xml.etree import cElementTree as ET

# In case issues come up with XML generation/parsing
# make sure you have the ElementTree v1.2.7+ lib

from ncclient import NCClientError

class XMLError(NCClientError): pass

### Namespace-related

#: Base NETCONF namespace
BASE_NS_1_0 = "urn:ietf:params:xml:ns:netconf:base:1.0"
#: Namespace for Tail-f core data model
TAILF_AAA_1_1 = "http://tail-f.com/ns/aaa/1.1"
#: Namespace for Tail-f execd data model
TAILF_EXECD_1_1 = "http://tail-f.com/ns/execd/1.1"
#: Namespace for Cisco data model
CISCO_CPI_1_0 = "http://www.cisco.com/cpi_10/schema"
#: Namespace for Flowmon data model
FLOWMON_1_0 = "http://www.liberouter.org/ns/netopeer/flowmon/1.0"
#: Namespace for Juniper 9.6R4. Tested with Junos 9.6R4+
JUNIPER_1_1 = "http://xml.juniper.net/xnm/1.1/xnm"
#
try:
    register_namespace = ET.register_namespace
except AttributeError:
    def register_namespace(prefix, uri):
        from xml.etree import ElementTree
        # cElementTree uses ElementTree's _namespace_map, so that's ok
        ElementTree._namespace_map[uri] = prefix
register_namespace.func_doc = "ElementTree's namespace map determines the prefixes for namespace URI's when serializing to XML. This method allows modifying this map to specify a prefix for a namespace URI."

for (ns, pre) in {
    BASE_NS_1_0: 'nc',
    TAILF_AAA_1_1: 'aaa',
    TAILF_EXECD_1_1: 'execd',
    CISCO_CPI_1_0: 'cpi',
    FLOWMON_1_0: 'fm',
    JUNIPER_1_1: 'junos',
}.items(): 
    register_namespace(pre, ns)

qualify = lambda tag, ns=BASE_NS_1_0: tag if ns is None else "{%s}%s" % (ns, tag)
"""Qualify a *tag* name with a *namespace*, in :mod:`~xml.etree.ElementTree` fashion i.e. *{namespace}tagname*."""

def to_xml(ele, encoding="UTF-8"):
    "Convert and return the XML for an *ele* (:class:`~xml.etree.ElementTree.Element`) with specified *encoding*."
    xml = ET.tostring(ele, encoding)
    return xml if xml.startswith('<?xml') else '<?xml version="1.0" encoding="%s"?>%s' % (encoding, xml)

def to_ele(x):
    "Convert and return the :class:`~xml.etree.ElementTree.Element` for the XML document *x*. If *x* is already an :class:`~xml.etree.ElementTree.Element` simply returns that."
    return x if ET.iselement(x) else ET.fromstring(x)

def parse_root(raw):
    "Efficiently parses the root element of a *raw* XML document, returning a tuple of its qualified name and attribute dictionary."
    fp = StringIO(raw)
    for event, element in ET.iterparse(fp, events=('start',)):
        return (element.tag, element.attrib)

def validated_element(x, tags=None, attrs=None):
    """Checks if the root element of an XML document or Element meets the supplied criteria.
    
    *tags* if specified is either a single allowable tag name or sequence of allowable alternatives

    *attrs* if specified is a sequence of required attributes, each of which may be a sequence of several allowable alternatives

    Raises :exc:`XMLError` if the requirements are not met.
    """
    ele = to_ele(x)
    if tags:
        if isinstance(tags, basestring):
            tags = [tags]
        if ele.tag not in tags:
            raise XMLError("Element [%s] does not meet requirement" % ele.tag)
    if attrs:
        for req in attrs:
            if isinstance(req, basestring): req = [req]
            for alt in req:
                if alt in ele.attrib:
                    break
            else:
                raise XMLError("Element [%s] does not have required attributes" % ele.tag)
    return ele

new_ele = lambda tag, attrs={}, **extra: ET.Element(qualify(tag), attrs, **extra)

sub_ele = lambda parent, tag, attrs={}, **extra: ET.SubElement(parent, qualify(tag), attrs, **extra)


########NEW FILE########
__FILENAME__ = daemon
# Copyright (c) 2010, 2011 Nicira, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at:
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import errno
import fcntl
import os
import resource
import signal
import sys
import time

import ovs.dirs
import ovs.fatal_signal
#import ovs.lockfile
import ovs.process
import ovs.socket_util
import ovs.timeval
import ovs.util
import ovs.vlog

vlog = ovs.vlog.Vlog("daemon")

# --detach: Should we run in the background?
_detach = False

# --pidfile: Name of pidfile (null if none).
_pidfile = None

# Our pidfile's inode and device, if we have created one.
_pidfile_dev = None
_pidfile_ino = None

# --overwrite-pidfile: Create pidfile even if one already exists and is locked?
_overwrite_pidfile = False

# --no-chdir: Should we chdir to "/"?
_chdir = True

# --monitor: Should a supervisory process monitor the daemon and restart it if
# it dies due to an error signal?
_monitor = False

# File descriptor used by daemonize_start() and daemonize_complete().
_daemonize_fd = None

RESTART_EXIT_CODE = 5


def make_pidfile_name(name):
    """Returns the file name that would be used for a pidfile if 'name' were
    provided to set_pidfile()."""
    if name is None or name == "":
        return "%s/%s.pid" % (ovs.dirs.RUNDIR, ovs.util.PROGRAM_NAME)
    else:
        return ovs.util.abs_file_name(ovs.dirs.RUNDIR, name)


def set_pidfile(name):
    """Sets up a following call to daemonize() to create a pidfile named
    'name'.  If 'name' begins with '/', then it is treated as an absolute path.
    Otherwise, it is taken relative to ovs.util.RUNDIR, which is
    $(prefix)/var/run by default.

    If 'name' is null, then ovs.util.PROGRAM_NAME followed by ".pid" is
    used."""
    global _pidfile
    _pidfile = make_pidfile_name(name)


def get_pidfile():
    """Returns an absolute path to the configured pidfile, or None if no
    pidfile is configured."""
    return _pidfile


def set_no_chdir():
    """Sets that we do not chdir to "/"."""
    global _chdir
    _chdir = False


def is_chdir_enabled():
    """Will we chdir to "/" as part of daemonizing?"""
    return _chdir


def ignore_existing_pidfile():
    """Normally, daemonize() or daemonize_start() will terminate the program
    with a message if a locked pidfile already exists.  If this function is
    called, an existing pidfile will be replaced, with a warning."""
    global _overwrite_pidfile
    _overwrite_pidfile = True


def set_detach():
    """Sets up a following call to daemonize() to detach from the foreground
    session, running this process in the background."""
    global _detach
    _detach = True


def get_detach():
    """Will daemonize() really detach?"""
    return _detach


def set_monitor():
    """Sets up a following call to daemonize() to fork a supervisory process to
    monitor the daemon and restart it if it dies due to an error signal."""
    global _monitor
    _monitor = True


def _fatal(msg):
    vlog.err(msg)
    sys.stderr.write("%s\n" % msg)
    sys.exit(1)


def _make_pidfile():
    """If a pidfile has been configured, creates it and stores the running
    process's pid in it.  Ensures that the pidfile will be deleted when the
    process exits."""
    pid = os.getpid()

    # Create a temporary pidfile.
    tmpfile = "%s.tmp%d" % (_pidfile, pid)
    ovs.fatal_signal.add_file_to_unlink(tmpfile)
    try:
        # This is global to keep Python from garbage-collecting and
        # therefore closing our file after this function exits.  That would
        # unlock the lock for us, and we don't want that.
        global file_handle

        file_handle = open(tmpfile, "w")
    except IOError, e:
        _fatal("%s: create failed (%s)" % (tmpfile, e.strerror))

    try:
        s = os.fstat(file_handle.fileno())
    except IOError, e:
        _fatal("%s: fstat failed (%s)" % (tmpfile, e.strerror))

    try:
        file_handle.write("%s\n" % pid)
        file_handle.flush()
    except OSError, e:
        _fatal("%s: write failed: %s" % (tmpfile, e.strerror))

    try:
        fcntl.lockf(file_handle, fcntl.LOCK_EX | fcntl.LOCK_NB)
    except IOError, e:
        _fatal("%s: fcntl failed: %s" % (tmpfile, e.strerror))

    # Rename or link it to the correct name.
    if _overwrite_pidfile:
        try:
            os.rename(tmpfile, _pidfile)
        except OSError, e:
            _fatal("failed to rename \"%s\" to \"%s\" (%s)"
                   % (tmpfile, _pidfile, e.strerror))
    else:
        while True:
            try:
                os.link(tmpfile, _pidfile)
                error = 0
            except OSError, e:
                error = e.errno
            if error == errno.EEXIST:
                _check_already_running()
            elif error != errno.EINTR:
                break
        if error:
            _fatal("failed to link \"%s\" as \"%s\" (%s)"
                   % (tmpfile, _pidfile, os.strerror(error)))

    # Ensure that the pidfile will get deleted on exit.
    ovs.fatal_signal.add_file_to_unlink(_pidfile)

    # Delete the temporary pidfile if it still exists.
    if not _overwrite_pidfile:
        error = ovs.fatal_signal.unlink_file_now(tmpfile)
        if error:
            _fatal("%s: unlink failed (%s)" % (tmpfile, os.strerror(error)))

    global _pidfile_dev
    global _pidfile_ino
    _pidfile_dev = s.st_dev
    _pidfile_ino = s.st_ino


def daemonize():
    """If configured with set_pidfile() or set_detach(), creates the pid file
    and detaches from the foreground session."""
    daemonize_start()
    daemonize_complete()


def _waitpid(pid, options):
    while True:
        try:
            return os.waitpid(pid, options)
        except OSError, e:
            if e.errno == errno.EINTR:
                pass
            return -e.errno, 0


def _fork_and_wait_for_startup():
    try:
        rfd, wfd = os.pipe()
    except OSError, e:
        sys.stderr.write("pipe failed: %s\n" % os.strerror(e.errno))
        sys.exit(1)

    try:
        pid = os.fork()
    except OSError, e:
        sys.stderr.write("could not fork: %s\n" % os.strerror(e.errno))
        sys.exit(1)

    if pid > 0:
        # Running in parent process.
        os.close(wfd)
        ovs.fatal_signal.fork()
        while True:
            try:
                s = os.read(rfd, 1)
                error = 0
            except OSError, e:
                s = ""
                error = e.errno
            if error != errno.EINTR:
                break
        if len(s) != 1:
            retval, status = _waitpid(pid, 0)
            if retval == pid:
                if os.WIFEXITED(status) and os.WEXITSTATUS(status):
                    # Child exited with an error.  Convey the same error to
                    # our parent process as a courtesy.
                    sys.exit(os.WEXITSTATUS(status))
                else:
                    sys.stderr.write("fork child failed to signal "
                                     "startup (%s)\n"
                                     % ovs.process.status_msg(status))
            else:
                assert retval < 0
                sys.stderr.write("waitpid failed (%s)\n"
                                 % os.strerror(-retval))
                sys.exit(1)

        os.close(rfd)
    else:
        # Running in parent process.
        os.close(rfd)
        ovs.timeval.postfork()
        #ovs.lockfile.postfork()

        global _daemonize_fd
        _daemonize_fd = wfd
    return pid


def _fork_notify_startup(fd):
    if fd is not None:
        error, bytes_written = ovs.socket_util.write_fully(fd, "0")
        if error:
            sys.stderr.write("could not write to pipe\n")
            sys.exit(1)
        os.close(fd)


def _should_restart(status):
    global RESTART_EXIT_CODE

    if os.WIFEXITED(status) and os.WEXITSTATUS(status) == RESTART_EXIT_CODE:
        return True

    if os.WIFSIGNALED(status):
        for signame in ("SIGABRT", "SIGALRM", "SIGBUS", "SIGFPE", "SIGILL",
                        "SIGPIPE", "SIGSEGV", "SIGXCPU", "SIGXFSZ"):
            if os.WTERMSIG(status) == getattr(signal, signame, None):
                return True
    return False


def _monitor_daemon(daemon_pid):
    # XXX should log daemon's stderr output at startup time
    # XXX should use setproctitle module if available
    last_restart = None
    while True:
        retval, status = _waitpid(daemon_pid, 0)
        if retval < 0:
            sys.stderr.write("waitpid failed\n")
            sys.exit(1)
        elif retval == daemon_pid:
            status_msg = ("pid %d died, %s"
                          % (daemon_pid, ovs.process.status_msg(status)))

            if _should_restart(status):
                if os.WCOREDUMP(status):
                    # Disable further core dumps to save disk space.
                    try:
                        resource.setrlimit(resource.RLIMIT_CORE, (0, 0))
                    except resource.error:
                        vlog.warn("failed to disable core dumps")

                # Throttle restarts to no more than once every 10 seconds.
                if (last_restart is not None and
                    ovs.timeval.msec() < last_restart + 10000):
                    vlog.warn("%s, waiting until 10 seconds since last "
                              "restart" % status_msg)
                    while True:
                        now = ovs.timeval.msec()
                        wakeup = last_restart + 10000
                        if now > wakeup:
                            break
                        print "sleep %f" % ((wakeup - now) / 1000.0)
                        time.sleep((wakeup - now) / 1000.0)
                last_restart = ovs.timeval.msec()

                vlog.err("%s, restarting" % status_msg)
                daemon_pid = _fork_and_wait_for_startup()
                if not daemon_pid:
                    break
            else:
                vlog.info("%s, exiting" % status_msg)
                sys.exit(0)

   # Running in new daemon process.


def _close_standard_fds():
    """Close stdin, stdout, stderr.  If we're started from e.g. an SSH session,
    then this keeps us from holding that session open artificially."""
    null_fd = ovs.socket_util.get_null_fd()
    if null_fd >= 0:
        os.dup2(null_fd, 0)
        os.dup2(null_fd, 1)
        os.dup2(null_fd, 2)


def daemonize_start():
    """If daemonization is configured, then starts daemonization, by forking
    and returning in the child process.  The parent process hangs around until
    the child lets it know either that it completed startup successfully (by
    calling daemon_complete()) or that it failed to start up (by exiting with a
    nonzero exit code)."""

    if _detach:
        if _fork_and_wait_for_startup() > 0:
            # Running in parent process.
            sys.exit(0)
        # Running in daemon or monitor process.

    if _monitor:
        saved_daemonize_fd = _daemonize_fd
        daemon_pid = _fork_and_wait_for_startup()
        if daemon_pid > 0:
            # Running in monitor process.
            _fork_notify_startup(saved_daemonize_fd)
            _close_standard_fds()
            _monitor_daemon(daemon_pid)
        # Running in daemon process

    if _pidfile:
        _make_pidfile()


def daemonize_complete():
    """If daemonization is configured, then this function notifies the parent
    process that the child process has completed startup successfully."""
    _fork_notify_startup(_daemonize_fd)

    if _detach:
        os.setsid()
        if _chdir:
            os.chdir("/")
        _close_standard_fds()


def usage():
    sys.stdout.write("""
Daemon options:
   --detach                run in background as daemon
   --no-chdir              do not chdir to '/'
   --pidfile[=FILE]        create pidfile (default: %s/%s.pid)
   --overwrite-pidfile     with --pidfile, start even if already running
""" % (ovs.dirs.RUNDIR, ovs.util.PROGRAM_NAME))


def __read_pidfile(pidfile, delete_if_stale):
    if _pidfile_dev is not None:
        try:
            s = os.stat(pidfile)
            if s.st_ino == _pidfile_ino and s.st_dev == _pidfile_dev:
                # It's our own pidfile.  We can't afford to open it,
                # because closing *any* fd for a file that a process
                # has locked also releases all the locks on that file.
                #
                # Fortunately, we know the associated pid anyhow.
                return os.getpid()
        except OSError:
            pass

    try:
        file_handle = open(pidfile, "r+")
    except IOError, e:
        if e.errno == errno.ENOENT and delete_if_stale:
            return 0
        vlog.warn("%s: open: %s" % (pidfile, e.strerror))
        return -e.errno

    # Python fcntl doesn't directly support F_GETLK so we have to just try
    # to lock it.
    try:
        fcntl.lockf(file_handle, fcntl.LOCK_EX | fcntl.LOCK_NB)

        # pidfile exists but wasn't locked by anyone.  Now we have the lock.
        if not delete_if_stale:
            file_handle.close()
            vlog.warn("%s: pid file is stale" % pidfile)
            return -errno.ESRCH

        # Is the file we have locked still named 'pidfile'?
        try:
            raced = False
            s = os.stat(pidfile)
            s2 = os.fstat(file_handle.fileno())
            if s.st_ino != s2.st_ino or s.st_dev != s2.st_dev:
                raced = True
        except IOError:
            raced = True
        if raced:
            vlog.warn("%s: lost race to delete pidfile" % pidfile)
            return -errno.EALREADY

        # We won the right to delete the stale pidfile.
        try:
            os.unlink(pidfile)
        except IOError, e:
            vlog.warn("%s: failed to delete stale pidfile (%s)"
                            % (pidfile, e.strerror))
            return -e.errno
        else:
            vlog.dbg("%s: deleted stale pidfile" % pidfile)
            file_handle.close()
            return 0
    except IOError, e:
        if e.errno not in [errno.EACCES, errno.EAGAIN]:
            vlog.warn("%s: fcntl: %s" % (pidfile, e.strerror))
            return -e.errno

    # Someone else has the pidfile locked.
    try:
        try:
            error = int(file_handle.readline())
        except IOError, e:
            vlog.warn("%s: read: %s" % (pidfile, e.strerror))
            error = -e.errno
        except ValueError:
            vlog.warn("%s does not contain a pid" % pidfile)
            error = -errno.EINVAL

        return error
    finally:
        try:
            file_handle.close()
        except IOError:
            pass


def read_pidfile(pidfile):
    """Opens and reads a PID from 'pidfile'.  Returns the positive PID if
    successful, otherwise a negative errno value."""
    return __read_pidfile(pidfile, False)


def _check_already_running():
    pid = __read_pidfile(_pidfile, True)
    if pid > 0:
        _fatal("%s: already running as pid %d, aborting" % (_pidfile, pid))
    elif pid < 0:
        _fatal("%s: pidfile check failed (%s), aborting"
               % (_pidfile, os.strerror(pid)))


def add_args(parser):
    """Populates 'parser', an ArgumentParser allocated using the argparse
    module, with the command line arguments required by the daemon module."""

    pidfile = make_pidfile_name(None)

    group = parser.add_argument_group(title="Daemon Options")
    group.add_argument("--detach", action="store_true",
            help="Run in background as a daemon.")
    group.add_argument("--no-chdir", action="store_true",
            help="Do not chdir to '/'.")
    group.add_argument("--monitor", action="store_true",
            help="Monitor %s process." % ovs.util.PROGRAM_NAME)
    group.add_argument("--pidfile", nargs="?", const=pidfile,
            help="Create pidfile (default %s)." % pidfile)
    group.add_argument("--overwrite-pidfile", action="store_true",
            help="With --pidfile, start even if already running.")


def handle_args(args):
    """Handles daemon module settings in 'args'.  'args' is an object
    containing values parsed by the parse_args() method of ArgumentParser.  The
    parent ArgumentParser should have been prepared by add_args() before
    calling parse_args()."""

    if args.detach:
        set_detach()

    if args.no_chdir:
        set_no_chdir()

    if args.pidfile:
        set_pidfile(args.pidfile)

    if args.overwrite_pidfile:
        ignore_existing_pidfile()

    if args.monitor:
        set_monitor()

########NEW FILE########
__FILENAME__ = data
# Copyright (c) 2009, 2010, 2011 Nicira, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at:
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import re
import uuid

import ovs.poller
import ovs.socket_util
import ovs.json
import ovs.jsonrpc
import ovs.ovsuuid

import ovs.db.parser
from ovs.db import error
import ovs.db.types


class ConstraintViolation(error.Error):
    def __init__(self, msg, json=None):
        error.Error.__init__(self, msg, json, tag="constraint violation")


def escapeCString(src):
    dst = []
    for c in src:
        if c in "\\\"":
            dst.append("\\" + c)
        elif ord(c) < 32:
            if c == '\n':
                dst.append('\\n')
            elif c == '\r':
                dst.append('\\r')
            elif c == '\a':
                dst.append('\\a')
            elif c == '\b':
                dst.append('\\b')
            elif c == '\f':
                dst.append('\\f')
            elif c == '\t':
                dst.append('\\t')
            elif c == '\v':
                dst.append('\\v')
            else:
                dst.append('\\%03o' % ord(c))
        else:
            dst.append(c)
    return ''.join(dst)


def returnUnchanged(x):
    return x


class Atom(object):
    def __init__(self, type_, value=None):
        self.type = type_
        if value is not None:
            self.value = value
        else:
            self.value = type_.default_atom()

    def __cmp__(self, other):
        if not isinstance(other, Atom) or self.type != other.type:
            return NotImplemented
        elif self.value < other.value:
            return -1
        elif self.value > other.value:
            return 1
        else:
            return 0

    def __hash__(self):
        return hash(self.value)

    @staticmethod
    def default(type_):
        """Returns the default value for the given type_, which must be an
        instance of ovs.db.types.AtomicType.

        The default value for each atomic type is;

          - 0, for integer or real atoms.

          - False, for a boolean atom.

          - "", for a string atom.

          - The all-zeros UUID, for a UUID atom."""
        return Atom(type_)

    def is_default(self):
        return self == self.default(self.type)

    @staticmethod
    def from_json(base, json, symtab=None):
        type_ = base.type
        json = ovs.db.parser.float_to_int(json)
        if ((type_ == ovs.db.types.IntegerType and type(json) in [int, long])
            or (type_ == ovs.db.types.RealType
                and type(json) in [int, long, float])
            or (type_ == ovs.db.types.BooleanType and type(json) == bool)
            or (type_ == ovs.db.types.StringType
                and type(json) in [str, unicode])):
            atom = Atom(type_, json)
        elif type_ == ovs.db.types.UuidType:
            atom = Atom(type_, ovs.ovsuuid.from_json(json, symtab))
        else:
            raise error.Error("expected %s" % type_.to_string(), json)
        atom.check_constraints(base)
        return atom

    @staticmethod
    def from_python(base, value):
        value = ovs.db.parser.float_to_int(value)
        if type(value) in base.type.python_types:
            atom = Atom(base.type, value)
        else:
            raise error.Error("expected %s, got %s" % (base.type, type(value)))
        atom.check_constraints(base)
        return atom

    def check_constraints(self, base):
        """Checks whether 'atom' meets the constraints (if any) defined in
        'base' and raises an ovs.db.error.Error if any constraint is violated.

        'base' and 'atom' must have the same type.
        Checking UUID constraints is deferred to transaction commit time, so
        this function does nothing for UUID constraints."""
        assert base.type == self.type
        if base.enum is not None and self not in base.enum:
            raise ConstraintViolation(
                "%s is not one of the allowed values (%s)"
                % (self.to_string(), base.enum.to_string()))
        elif base.type in [ovs.db.types.IntegerType, ovs.db.types.RealType]:
            if ((base.min is None or self.value >= base.min) and
                (base.max is None or self.value <= base.max)):
                pass
            elif base.min is not None and base.max is not None:
                raise ConstraintViolation(
                    "%s is not in the valid range %.15g to %.15g (inclusive)"
                    % (self.to_string(), base.min, base.max))
            elif base.min is not None:
                raise ConstraintViolation(
                    "%s is less than minimum allowed value %.15g"
                            % (self.to_string(), base.min))
            else:
                raise ConstraintViolation(
                    "%s is greater than maximum allowed value %.15g"
                    % (self.to_string(), base.max))
        elif base.type == ovs.db.types.StringType:
            # XXX The C version validates that the string is valid UTF-8 here.
            # Do we need to do that in Python too?
            s = self.value
            length = len(s)
            if length < base.min_length:
                raise ConstraintViolation(
                    '"%s" length %d is less than minimum allowed length %d'
                    % (s, length, base.min_length))
            elif length > base.max_length:
                raise ConstraintViolation(
                    '"%s" length %d is greater than maximum allowed '
                    'length %d' % (s, length, base.max_length))

    def to_json(self):
        if self.type == ovs.db.types.UuidType:
            return ovs.ovsuuid.to_json(self.value)
        else:
            return self.value

    def cInitAtom(self, var):
        if self.type == ovs.db.types.IntegerType:
            return ['%s.integer = %d;' % (var, self.value)]
        elif self.type == ovs.db.types.RealType:
            return ['%s.real = %.15g;' % (var, self.value)]
        elif self.type == ovs.db.types.BooleanType:
            if self.value:
                return ['%s.boolean = true;']
            else:
                return ['%s.boolean = false;']
        elif self.type == ovs.db.types.StringType:
            return ['%s.string = xstrdup("%s");'
                    % (var, escapeCString(self.value))]
        elif self.type == ovs.db.types.UuidType:
            return ovs.ovsuuid.to_c_assignment(self.value, var)

    def toEnglish(self, escapeLiteral=returnUnchanged):
        if self.type == ovs.db.types.IntegerType:
            return '%d' % self.value
        elif self.type == ovs.db.types.RealType:
            return '%.15g' % self.value
        elif self.type == ovs.db.types.BooleanType:
            if self.value:
                return 'true'
            else:
                return 'false'
        elif self.type == ovs.db.types.StringType:
            return escapeLiteral(self.value)
        elif self.type == ovs.db.types.UuidType:
            return self.value.value

    __need_quotes_re = re.compile("$|true|false|[^_a-zA-Z]|.*[^-._a-zA-Z]")

    @staticmethod
    def __string_needs_quotes(s):
        return Atom.__need_quotes_re.match(s)

    def to_string(self):
        if self.type == ovs.db.types.IntegerType:
            return '%d' % self.value
        elif self.type == ovs.db.types.RealType:
            return '%.15g' % self.value
        elif self.type == ovs.db.types.BooleanType:
            if self.value:
                return 'true'
            else:
                return 'false'
        elif self.type == ovs.db.types.StringType:
            if Atom.__string_needs_quotes(self.value):
                return ovs.json.to_string(self.value)
            else:
                return self.value
        elif self.type == ovs.db.types.UuidType:
            return str(self.value)

    @staticmethod
    def new(x):
        if type(x) in [int, long]:
            t = ovs.db.types.IntegerType
        elif type(x) == float:
            t = ovs.db.types.RealType
        elif x in [False, True]:
            t = ovs.db.types.BooleanType
        elif type(x) in [str, unicode]:
            t = ovs.db.types.StringType
        elif isinstance(x, uuid):
            t = ovs.db.types.UuidType
        else:
            raise TypeError
        return Atom(t, x)


class Datum(object):
    def __init__(self, type_, values={}):
        self.type = type_
        self.values = values

    def __cmp__(self, other):
        if not isinstance(other, Datum):
            return NotImplemented
        elif self.values < other.values:
            return -1
        elif self.values > other.values:
            return 1
        else:
            return 0

    __hash__ = None

    def __contains__(self, item):
        return item in self.values

    def copy(self):
        return Datum(self.type, dict(self.values))

    @staticmethod
    def default(type_):
        if type_.n_min == 0:
            values = {}
        elif type_.is_map():
            values = {type_.key.default(): type_.value.default()}
        else:
            values = {type_.key.default(): None}
        return Datum(type_, values)

    def is_default(self):
        return self == Datum.default(self.type)

    def check_constraints(self):
        """Checks that each of the atoms in 'datum' conforms to the constraints
        specified by its 'type' and raises an ovs.db.error.Error.

        This function is not commonly useful because the most ordinary way to
        obtain a datum is ultimately via Datum.from_json() or Atom.from_json(),
        which check constraints themselves."""
        for keyAtom, valueAtom in self.values.iteritems():
            keyAtom.check_constraints(self.type.key)
            if valueAtom is not None:
                valueAtom.check_constraints(self.type.value)

    @staticmethod
    def from_json(type_, json, symtab=None):
        """Parses 'json' as a datum of the type described by 'type'.  If
        successful, returns a new datum.  On failure, raises an
        ovs.db.error.Error.

        Violations of constraints expressed by 'type' are treated as errors.

        If 'symtab' is nonnull, then named UUIDs in 'symtab' are accepted.
        Refer to ovsdb/SPECS for information about this, and for the syntax
        that this function accepts."""
        is_map = type_.is_map()
        if (is_map or
            (type(json) == list and len(json) > 0 and json[0] == "set")):
            if is_map:
                class_ = "map"
            else:
                class_ = "set"

            inner = ovs.db.parser.unwrap_json(json, class_, [list, tuple],
                                              "array")
            n = len(inner)
            if n < type_.n_min or n > type_.n_max:
                raise error.Error("%s must have %d to %d members but %d are "
                                  "present" % (class_, type_.n_min,
                                               type_.n_max, n),
                                  json)

            values = {}
            for element in inner:
                if is_map:
                    key, value = ovs.db.parser.parse_json_pair(element)
                    keyAtom = Atom.from_json(type_.key, key, symtab)
                    valueAtom = Atom.from_json(type_.value, value, symtab)
                else:
                    keyAtom = Atom.from_json(type_.key, element, symtab)
                    valueAtom = None

                if keyAtom in values:
                    if is_map:
                        raise error.Error("map contains duplicate key")
                    else:
                        raise error.Error("set contains duplicate")

                values[keyAtom] = valueAtom

            return Datum(type_, values)
        else:
            keyAtom = Atom.from_json(type_.key, json, symtab)
            return Datum(type_, {keyAtom: None})

    def to_json(self):
        if self.type.is_map():
            return ["map", [[k.to_json(), v.to_json()]
                            for k, v in sorted(self.values.items())]]
        elif len(self.values) == 1:
            key = self.values.keys()[0]
            return key.to_json()
        else:
            return ["set", [k.to_json() for k in sorted(self.values.keys())]]

    def to_string(self):
        head = tail = None
        if self.type.n_max > 1 or len(self.values) == 0:
            if self.type.is_map():
                head = "{"
                tail = "}"
            else:
                head = "["
                tail = "]"

        s = []
        if head:
            s.append(head)

        for i, key in enumerate(sorted(self.values)):
            if i:
                s.append(", ")

            s.append(key.to_string())
            if self.type.is_map():
                s.append("=")
                s.append(self.values[key].to_string())

        if tail:
            s.append(tail)
        return ''.join(s)

    def as_list(self):
        if self.type.is_map():
            return [[k.value, v.value] for k, v in self.values.iteritems()]
        else:
            return [k.value for k in self.values.iterkeys()]

    def as_dict(self):
        return dict(self.values)

    def as_scalar(self):
        if len(self.values) == 1:
            if self.type.is_map():
                k, v = self.values.iteritems()[0]
                return [k.value, v.value]
            else:
                return self.values.keys()[0].value
        else:
            return None

    def to_python(self, uuid_to_row):
        """Returns this datum's value converted into a natural Python
        representation of this datum's type, according to the following
        rules:

        - If the type has exactly one value and it is not a map (that is,
          self.type.is_scalar() returns True), then the value is:

            * An int or long, for an integer column.

            * An int or long or float, for a real column.

            * A bool, for a boolean column.

            * A str or unicode object, for a string column.

            * A uuid.UUID object, for a UUID column without a ref_table.

            * An object represented the referenced row, for a UUID column with
              a ref_table.  (For the Idl, this object will be an ovs.db.idl.Row
              object.)

          If some error occurs (e.g. the database server's idea of the column
          is different from the IDL's idea), then the default value for the
          scalar type is used (see Atom.default()).

        - Otherwise, if the type is not a map, then the value is a Python list
          whose elements have the types described above.

        - Otherwise, the type is a map, and the value is a Python dict that
          maps from key to value, with key and value types determined as
          described above.

        'uuid_to_row' must be a function that takes a value and an
        ovs.db.types.BaseType and translates UUIDs into row objects."""
        if self.type.is_scalar():
            value = uuid_to_row(self.as_scalar(), self.type.key)
            if value is None:
                return self.type.key.default()
            else:
                return value
        elif self.type.is_map():
            value = {}
            for k, v in self.values.iteritems():
                dk = uuid_to_row(k.value, self.type.key)
                dv = uuid_to_row(v.value, self.type.value)
                if dk is not None and dv is not None:
                    value[dk] = dv
            return value
        else:
            s = set()
            for k in self.values:
                dk = uuid_to_row(k.value, self.type.key)
                if dk is not None:
                    s.add(dk)
            return sorted(s)

    @staticmethod
    def from_python(type_, value, row_to_uuid):
        """Returns a new Datum with the given ovs.db.types.Type 'type_'.  The
        new datum's value is taken from 'value', which must take the form
        described as a valid return value from Datum.to_python() for 'type'.

        Each scalar value within 'value' is initally passed through
        'row_to_uuid', which should convert objects that represent rows (if
        any) into uuid.UUID objects and return other data unchanged.

        Raises ovs.db.error.Error if 'value' is not in an appropriate form for
        'type_'."""
        d = {}
        if type(value) == dict:
            for k, v in value.iteritems():
                ka = Atom.from_python(type_.key, row_to_uuid(k))
                va = Atom.from_python(type_.value, row_to_uuid(v))
                d[ka] = va
        elif type(value) in (list, tuple):
            for k in value:
                ka = Atom.from_python(type_.key, row_to_uuid(k))
                d[ka] = None
        else:
            ka = Atom.from_python(type_.key, row_to_uuid(value))
            d[ka] = None

        datum = Datum(type_, d)
        datum.check_constraints()
        if not datum.conforms_to_type():
            raise error.Error("%d values when type requires between %d and %d"
                              % (len(d), type_.n_min, type_.n_max))

        return datum

    def __getitem__(self, key):
        if not isinstance(key, Atom):
            key = Atom.new(key)
        if not self.type.is_map():
            raise IndexError
        elif key not in self.values:
            raise KeyError
        else:
            return self.values[key].value

    def get(self, key, default=None):
        if not isinstance(key, Atom):
            key = Atom.new(key)
        if key in self.values:
            return self.values[key].value
        else:
            return default

    def __str__(self):
        return self.to_string()

    def conforms_to_type(self):
        n = len(self.values)
        return self.type.n_min <= n <= self.type.n_max

    def cInitDatum(self, var):
        if len(self.values) == 0:
            return ["ovsdb_datum_init_empty(%s);" % var]

        s = ["%s->n = %d;" % (var, len(self.values))]
        s += ["%s->keys = xmalloc(%d * sizeof *%s->keys);"
              % (var, len(self.values), var)]

        for i, key in enumerate(sorted(self.values)):
            s += key.cInitAtom("%s->keys[%d]" % (var, i))

        if self.type.value:
            s += ["%s->values = xmalloc(%d * sizeof *%s->values);"
                  % (var, len(self.values), var)]
            for i, (key, value) in enumerate(sorted(self.values.items())):
                s += value.cInitAtom("%s->values[%d]" % (var, i))
        else:
            s += ["%s->values = NULL;" % var]

        if len(self.values) > 1:
            s += ["ovsdb_datum_sort_assert(%s, OVSDB_TYPE_%s);"
                  % (var, self.type.key.type.to_string().upper())]

        return s

########NEW FILE########
__FILENAME__ = error
# Copyright (c) 2009, 2010, 2011 Nicira, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at:
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import ovs.json


class Error(Exception):
    def __init__(self, msg, json=None, tag=None):
        self.msg = msg
        self.json = json
        if tag is None:
            if json is None:
                self.tag = "ovsdb error"
            else:
                self.tag = "syntax error"
        else:
            self.tag = tag

        # Compose message.
        syntax = ""
        if self.json is not None:
                syntax = 'syntax "%s": ' % ovs.json.to_string(self.json)
        Exception.__init__(self, "%s%s: %s" % (syntax, self.tag, self.msg))

########NEW FILE########
__FILENAME__ = idl
# Copyright (c) 2009, 2010, 2011, 2012 Nicira, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at:
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import uuid

import ovs.jsonrpc
import ovs.db.parser
import ovs.db.schema
from ovs.db import error
import ovs.ovsuuid
import ovs.poller
import ovs.vlog

vlog = ovs.vlog.Vlog("idl")

__pychecker__ = 'no-classattr no-objattrs'


class Idl:
    """Open vSwitch Database Interface Definition Language (OVSDB IDL).

    The OVSDB IDL maintains an in-memory replica of a database.  It issues RPC
    requests to an OVSDB database server and parses the responses, converting
    raw JSON into data structures that are easier for clients to digest.

    The IDL also assists with issuing database transactions.  The client
    creates a transaction, manipulates the IDL data structures, and commits or
    aborts the transaction.  The IDL then composes and issues the necessary
    JSON-RPC requests and reports to the client whether the transaction
    completed successfully.

    The client is allowed to access the following attributes directly, in a
    read-only fashion:

    - 'tables': This is the 'tables' map in the ovs.db.schema.DbSchema provided
      to the Idl constructor.  Each ovs.db.schema.TableSchema in the map is
      annotated with a new attribute 'rows', which is a dict from a uuid.UUID
      to a Row object.

      The client may directly read and write the Row objects referenced by the
      'rows' map values.  Refer to Row for more details.

    - 'change_seqno': A number that represents the IDL's state.  When the IDL
      is updated (by Idl.run()), its value changes.  The sequence number can
      occasionally change even if the database does not.  This happens if the
      connection to the database drops and reconnects, which causes the
      database contents to be reloaded even if they didn't change.  (It could
      also happen if the database server sends out a "change" that reflects
      what the IDL already thought was in the database.  The database server is
      not supposed to do that, but bugs could in theory cause it to do so.)

    - 'lock_name': The name of the lock configured with Idl.set_lock(), or None
      if no lock is configured.

    - 'has_lock': True, if the IDL is configured to obtain a lock and owns that
      lock, and False otherwise.

      Locking and unlocking happens asynchronously from the database client's
      point of view, so the information is only useful for optimization
      (e.g. if the client doesn't have the lock then there's no point in trying
      to write to the database).

    - 'is_lock_contended': True, if the IDL is configured to obtain a lock but
      the database server has indicated that some other client already owns the
      requested lock, and False otherwise.

    - 'txn': The ovs.db.idl.Transaction object for the database transaction
      currently being constructed, if there is one, or None otherwise.
"""

    def __init__(self, remote, schema):
        """Creates and returns a connection to the database named 'db_name' on
        'remote', which should be in a form acceptable to
        ovs.jsonrpc.session.open().  The connection will maintain an in-memory
        replica of the remote database.

        'schema' should be the schema for the remote database.  The caller may
        have cut it down by removing tables or columns that are not of
        interest.  The IDL will only replicate the tables and columns that
        remain.  The caller may also add a attribute named 'alert' to selected
        remaining columns, setting its value to False; if so, then changes to
        those columns will not be considered changes to the database for the
        purpose of the return value of Idl.run() and Idl.change_seqno.  This is
        useful for columns that the IDL's client will write but not read.

        As a convenience to users, 'schema' may also be an instance of the
        SchemaHelper class.

        The IDL uses and modifies 'schema' directly."""

        assert isinstance(schema, SchemaHelper)
        schema = schema.get_idl_schema()

        self.tables = schema.tables
        self._db = schema
        self._session = ovs.jsonrpc.Session.open(remote)
        self._monitor_request_id = None
        self._last_seqno = None
        self.change_seqno = 0

        # Database locking.
        self.lock_name = None          # Name of lock we need, None if none.
        self.has_lock = False          # Has db server said we have the lock?
        self.is_lock_contended = False  # Has db server said we can't get lock?
        self._lock_request_id = None   # JSON-RPC ID of in-flight lock request.

        # Transaction support.
        self.txn = None
        self._outstanding_txns = {}

        for table in schema.tables.itervalues():
            for column in table.columns.itervalues():
                if not hasattr(column, 'alert'):
                    column.alert = True
            table.need_table = False
            table.rows = {}
            table.idl = self

    def close(self):
        """Closes the connection to the database.  The IDL will no longer
        update."""
        self._session.close()

    def run(self):
        """Processes a batch of messages from the database server.  Returns
        True if the database as seen through the IDL changed, False if it did
        not change.  The initial fetch of the entire contents of the remote
        database is considered to be one kind of change.  If the IDL has been
        configured to acquire a database lock (with Idl.set_lock()), then
        successfully acquiring the lock is also considered to be a change.

        This function can return occasional false positives, that is, report
        that the database changed even though it didn't.  This happens if the
        connection to the database drops and reconnects, which causes the
        database contents to be reloaded even if they didn't change.  (It could
        also happen if the database server sends out a "change" that reflects
        what we already thought was in the database, but the database server is
        not supposed to do that.)

        As an alternative to checking the return value, the client may check
        for changes in self.change_seqno."""
        assert not self.txn
        initial_change_seqno = self.change_seqno
        self._session.run()
        i = 0
        while i < 50:
            i += 1
            if not self._session.is_connected():
                break

            seqno = self._session.get_seqno()
            if seqno != self._last_seqno:
                self._last_seqno = seqno
                self.__txn_abort_all()
                self.__send_monitor_request()
                if self.lock_name:
                    self.__send_lock_request()
                break

            msg = self._session.recv()
            if msg is None:
                break
            if (msg.type == ovs.jsonrpc.Message.T_NOTIFY
                and msg.method == "update"
                and len(msg.params) == 2
                and msg.params[0] == None):
                # Database contents changed.
                self.__parse_update(msg.params[1])
            elif (msg.type == ovs.jsonrpc.Message.T_REPLY
                  and self._monitor_request_id is not None
                  and self._monitor_request_id == msg.id):
                # Reply to our "monitor" request.
                try:
                    self.change_seqno += 1
                    self._monitor_request_id = None
                    self.__clear()
                    self.__parse_update(msg.result)
                except error.Error, e:
                    vlog.err("%s: parse error in received schema: %s"
                              % (self._session.get_name(), e))
                    self.__error()
            elif (msg.type == ovs.jsonrpc.Message.T_REPLY
                  and self._lock_request_id is not None
                  and self._lock_request_id == msg.id):
                # Reply to our "lock" request.
                self.__parse_lock_reply(msg.result)
            elif (msg.type == ovs.jsonrpc.Message.T_NOTIFY
                  and msg.method == "locked"):
                # We got our lock.
                self.__parse_lock_notify(msg.params, True)
            elif (msg.type == ovs.jsonrpc.Message.T_NOTIFY
                  and msg.method == "stolen"):
                # Someone else stole our lock.
                self.__parse_lock_notify(msg.params, False)
            elif msg.type == ovs.jsonrpc.Message.T_NOTIFY and msg.id == "echo":
                # Reply to our echo request.  Ignore it.
                pass
            elif (msg.type in (ovs.jsonrpc.Message.T_ERROR,
                               ovs.jsonrpc.Message.T_REPLY)
                  and self.__txn_process_reply(msg)):
                # __txn_process_reply() did everything needed.
                pass
            else:
                # This can happen if a transaction is destroyed before we
                # receive the reply, so keep the log level low.
                vlog.dbg("%s: received unexpected %s message"
                         % (self._session.get_name(),
                             ovs.jsonrpc.Message.type_to_string(msg.type)))

        return initial_change_seqno != self.change_seqno

    def wait(self, poller):
        """Arranges for poller.block() to wake up when self.run() has something
        to do or when activity occurs on a transaction on 'self'."""
        self._session.wait(poller)
        self._session.recv_wait(poller)

    def has_ever_connected(self):
        """Returns True, if the IDL successfully connected to the remote
        database and retrieved its contents (even if the connection
        subsequently dropped and is in the process of reconnecting).  If so,
        then the IDL contains an atomic snapshot of the database's contents
        (but it might be arbitrarily old if the connection dropped).

        Returns False if the IDL has never connected or retrieved the
        database's contents.  If so, the IDL is empty."""
        return self.change_seqno != 0

    def force_reconnect(self):
        """Forces the IDL to drop its connection to the database and reconnect.
        In the meantime, the contents of the IDL will not change."""
        self._session.force_reconnect()

    def set_lock(self, lock_name):
        """If 'lock_name' is not None, configures the IDL to obtain the named
        lock from the database server and to avoid modifying the database when
        the lock cannot be acquired (that is, when another client has the same
        lock).

        If 'lock_name' is None, drops the locking requirement and releases the
        lock."""
        assert not self.txn
        assert not self._outstanding_txns

        if self.lock_name and (not lock_name or lock_name != self.lock_name):
            # Release previous lock.
            self.__send_unlock_request()
            self.lock_name = None
            self.is_lock_contended = False

        if lock_name and not self.lock_name:
            # Acquire new lock.
            self.lock_name = lock_name
            self.__send_lock_request()

    def __clear(self):
        changed = False

        for table in self.tables.itervalues():
            if table.rows:
                changed = True
                table.rows = {}

        if changed:
            self.change_seqno += 1

    def __update_has_lock(self, new_has_lock):
        if new_has_lock and not self.has_lock:
            if self._monitor_request_id is None:
                self.change_seqno += 1
            else:
                # We're waiting for a monitor reply, so don't signal that the
                # database changed.  The monitor reply will increment
                # change_seqno anyhow.
                pass
            self.is_lock_contended = False
        self.has_lock = new_has_lock

    def __do_send_lock_request(self, method):
        self.__update_has_lock(False)
        self._lock_request_id = None
        if self._session.is_connected():
            msg = ovs.jsonrpc.Message.create_request(method, [self.lock_name])
            msg_id = msg.id
            self._session.send(msg)
        else:
            msg_id = None
        return msg_id

    def __send_lock_request(self):
        self._lock_request_id = self.__do_send_lock_request("lock")

    def __send_unlock_request(self):
        self.__do_send_lock_request("unlock")

    def __parse_lock_reply(self, result):
        self._lock_request_id = None
        got_lock = type(result) == dict and result.get("locked") is True
        self.__update_has_lock(got_lock)
        if not got_lock:
            self.is_lock_contended = True

    def __parse_lock_notify(self, params, new_has_lock):
        if (self.lock_name is not None
            and type(params) in (list, tuple)
            and params
            and params[0] == self.lock_name):
            self.__update_has_lock(self, new_has_lock)
            if not new_has_lock:
                self.is_lock_contended = True

    def __send_monitor_request(self):
        monitor_requests = {}
        for table in self.tables.itervalues():
            monitor_requests[table.name] = {"columns": table.columns.keys()}
        msg = ovs.jsonrpc.Message.create_request(
            "monitor", [self._db.name, None, monitor_requests])
        self._monitor_request_id = msg.id
        self._session.send(msg)

    def __parse_update(self, update):
        try:
            self.__do_parse_update(update)
        except error.Error, e:
            vlog.err("%s: error parsing update: %s"
                     % (self._session.get_name(), e))

    def __do_parse_update(self, table_updates):
        if type(table_updates) != dict:
            raise error.Error("<table-updates> is not an object",
                              table_updates)

        for table_name, table_update in table_updates.iteritems():
            table = self.tables.get(table_name)
            if not table:
                raise error.Error('<table-updates> includes unknown '
                                  'table "%s"' % table_name)

            if type(table_update) != dict:
                raise error.Error('<table-update> for table "%s" is not '
                                  'an object' % table_name, table_update)

            for uuid_string, row_update in table_update.iteritems():
                if not ovs.ovsuuid.is_valid_string(uuid_string):
                    raise error.Error('<table-update> for table "%s" '
                                      'contains bad UUID "%s" as member '
                                      'name' % (table_name, uuid_string),
                                      table_update)
                uuid = ovs.ovsuuid.from_string(uuid_string)

                if type(row_update) != dict:
                    raise error.Error('<table-update> for table "%s" '
                                      'contains <row-update> for %s that '
                                      'is not an object'
                                      % (table_name, uuid_string))

                parser = ovs.db.parser.Parser(row_update, "row-update")
                old = parser.get_optional("old", [dict])
                new = parser.get_optional("new", [dict])
                parser.finish()

                if not old and not new:
                    raise error.Error('<row-update> missing "old" and '
                                      '"new" members', row_update)

                if self.__process_update(table, uuid, old, new):
                    self.change_seqno += 1

    def __process_update(self, table, uuid, old, new):
        """Returns True if a column changed, False otherwise."""
        row = table.rows.get(uuid)
        changed = False
        if not new:
            # Delete row.
            if row:
                del table.rows[uuid]
                changed = True
            else:
                # XXX rate-limit
                vlog.warn("cannot delete missing row %s from table %s"
                          % (uuid, table.name))
        elif not old:
            # Insert row.
            if not row:
                row = self.__create_row(table, uuid)
                changed = True
            else:
                # XXX rate-limit
                vlog.warn("cannot add existing row %s to table %s"
                          % (uuid, table.name))
            if self.__row_update(table, row, new):
                changed = True
        else:
            if not row:
                row = self.__create_row(table, uuid)
                changed = True
                # XXX rate-limit
                vlog.warn("cannot modify missing row %s in table %s"
                          % (uuid, table.name))
            if self.__row_update(table, row, new):
                changed = True
        return changed

    def __row_update(self, table, row, row_json):
        changed = False
        for column_name, datum_json in row_json.iteritems():
            column = table.columns.get(column_name)
            if not column:
                # XXX rate-limit
                vlog.warn("unknown column %s updating table %s"
                          % (column_name, table.name))
                continue

            try:
                datum = ovs.db.data.Datum.from_json(column.type, datum_json)
            except error.Error, e:
                # XXX rate-limit
                vlog.warn("error parsing column %s in table %s: %s"
                          % (column_name, table.name, e))
                continue

            if datum != row._data[column_name]:
                row._data[column_name] = datum
                if column.alert:
                    changed = True
            else:
                # Didn't really change but the OVSDB monitor protocol always
                # includes every value in a row.
                pass
        return changed

    def __create_row(self, table, uuid):
        data = {}
        for column in table.columns.itervalues():
            data[column.name] = ovs.db.data.Datum.default(column.type)
        row = table.rows[uuid] = Row(self, table, uuid, data)
        return row

    def __error(self):
        self._session.force_reconnect()

    def __txn_abort_all(self):
        while self._outstanding_txns:
            txn = self._outstanding_txns.popitem()[1]
            txn._status = Transaction.TRY_AGAIN

    def __txn_process_reply(self, msg):
        txn = self._outstanding_txns.pop(msg.id, None)
        if txn:
            txn._process_reply(msg)


def _uuid_to_row(atom, base):
    if base.ref_table:
        return base.ref_table.rows.get(atom)
    else:
        return atom


def _row_to_uuid(value):
    if type(value) == Row:
        return value.uuid
    else:
        return value


class Row(object):
    """A row within an IDL.

    The client may access the following attributes directly:

    - 'uuid': a uuid.UUID object whose value is the row's database UUID.

    - An attribute for each column in the Row's table, named for the column,
      whose values are as returned by Datum.to_python() for the column's type.

      If some error occurs (e.g. the database server's idea of the column is
      different from the IDL's idea), then the attribute values is the
      "default" value return by Datum.default() for the column's type.  (It is
      important to know this because the default value may violate constraints
      for the column's type, e.g. the default integer value is 0 even if column
      contraints require the column's value to be positive.)

      When a transaction is active, column attributes may also be assigned new
      values.  Committing the transaction will then cause the new value to be
      stored into the database.

      *NOTE*: In the current implementation, the value of a column is a *copy*
      of the value in the database.  This means that modifying its value
      directly will have no useful effect.  For example, the following:
        row.mycolumn["a"] = "b"              # don't do this
      will not change anything in the database, even after commit.  To modify
      the column, instead assign the modified column value back to the column:
        d = row.mycolumn
        d["a"] = "b"
        row.mycolumn = d
"""
    def __init__(self, idl, table, uuid, data):
        # All of the explicit references to self.__dict__ below are required
        # to set real attributes with invoking self.__getattr__().
        self.__dict__["uuid"] = uuid

        self.__dict__["_idl"] = idl
        self.__dict__["_table"] = table

        # _data is the committed data.  It takes the following values:
        #
        #   - A dictionary that maps every column name to a Datum, if the row
        #     exists in the committed form of the database.
        #
        #   - None, if this row is newly inserted within the active transaction
        #     and thus has no committed form.
        self.__dict__["_data"] = data

        # _changes describes changes to this row within the active transaction.
        # It takes the following values:
        #
        #   - {}, the empty dictionary, if no transaction is active or if the
        #     row has yet not been changed within this transaction.
        #
        #   - A dictionary that maps a column name to its new Datum, if an
        #     active transaction changes those columns' values.
        #
        #   - A dictionary that maps every column name to a Datum, if the row
        #     is newly inserted within the active transaction.
        #
        #   - None, if this transaction deletes this row.
        self.__dict__["_changes"] = {}

        # A dictionary whose keys are the names of columns that must be
        # verified as prerequisites when the transaction commits.  The values
        # in the dictionary are all None.
        self.__dict__["_prereqs"] = {}

    def __getattr__(self, column_name):
        assert self._changes is not None

        datum = self._changes.get(column_name)
        if datum is None:
            if self._data is None:
                raise AttributeError("%s instance has no attribute '%s'" %
                                     (self.__class__.__name__, column_name))
            datum = self._data[column_name]

        return datum.to_python(_uuid_to_row)

    def __setattr__(self, column_name, value):
        assert self._changes is not None
        assert self._idl.txn

        column = self._table.columns[column_name]
        try:
            datum = ovs.db.data.Datum.from_python(column.type, value,
                                                  _row_to_uuid)
        except error.Error, e:
            # XXX rate-limit
            vlog.err("attempting to write bad value to column %s (%s)"
                     % (column_name, e))
            return
        self._idl.txn._write(self, column, datum)

    def verify(self, column_name):
        """Causes the original contents of column 'column_name' in this row to
        be verified as a prerequisite to completing the transaction.  That is,
        if 'column_name' changed in this row (or if this row was deleted)
        between the time that the IDL originally read its contents and the time
        that the transaction commits, then the transaction aborts and
        Transaction.commit() returns Transaction.TRY_AGAIN.

        The intention is that, to ensure that no transaction commits based on
        dirty reads, an application should call Row.verify() on each data item
        read as part of a read-modify-write operation.

        In some cases Row.verify() reduces to a no-op, because the current
        value of the column is already known:

          - If this row is a row created by the current transaction (returned
            by Transaction.insert()).

          - If the column has already been modified within the current
            transaction.

        Because of the latter property, always call Row.verify() *before*
        modifying the column, for a given read-modify-write.

        A transaction must be in progress."""
        assert self._idl.txn
        assert self._changes is not None
        if not self._data or column_name in self._changes:
            return

        self._prereqs[column_name] = None

    def delete(self):
        """Deletes this row from its table.

        A transaction must be in progress."""
        assert self._idl.txn
        assert self._changes is not None
        if self._data is None:
            del self._idl.txn._txn_rows[self.uuid]
        self.__dict__["_changes"] = None
        del self._table.rows[self.uuid]

    def increment(self, column_name):
        """Causes the transaction, when committed, to increment the value of
        'column_name' within this row by 1.  'column_name' must have an integer
        type.  After the transaction commits successfully, the client may
        retrieve the final (incremented) value of 'column_name' with
        Transaction.get_increment_new_value().

        The client could accomplish something similar by reading and writing
        and verify()ing columns.  However, increment() will never (by itself)
        cause a transaction to fail because of a verify error.

        The intended use is for incrementing the "next_cfg" column in
        the Open_vSwitch table."""
        self._idl.txn._increment(self, column_name)


def _uuid_name_from_uuid(uuid):
    return "row%s" % str(uuid).replace("-", "_")


def _where_uuid_equals(uuid):
    return [["_uuid", "==", ["uuid", str(uuid)]]]


class _InsertedRow(object):
    def __init__(self, op_index):
        self.op_index = op_index
        self.real = None


class Transaction(object):
    """A transaction may modify the contents of a database by modifying the
    values of columns, deleting rows, inserting rows, or adding checks that
    columns in the database have not changed ("verify" operations), through
    Row methods.

    Reading and writing columns and inserting and deleting rows are all
    straightforward.  The reasons to verify columns are less obvious.
    Verification is the key to maintaining transactional integrity.  Because
    OVSDB handles multiple clients, it can happen that between the time that
    OVSDB client A reads a column and writes a new value, OVSDB client B has
    written that column.  Client A's write should not ordinarily overwrite
    client B's, especially if the column in question is a "map" column that
    contains several more or less independent data items.  If client A adds a
    "verify" operation before it writes the column, then the transaction fails
    in case client B modifies it first.  Client A will then see the new value
    of the column and compose a new transaction based on the new contents
    written by client B.

    When a transaction is complete, which must be before the next call to
    Idl.run(), call Transaction.commit() or Transaction.abort().

    The life-cycle of a transaction looks like this:

    1. Create the transaction and record the initial sequence number:

        seqno = idl.change_seqno(idl)
        txn = Transaction(idl)

    2. Modify the database with Row and Transaction methods.

    3. Commit the transaction by calling Transaction.commit().  The first call
       to this function probably returns Transaction.INCOMPLETE.  The client
       must keep calling again along as this remains true, calling Idl.run() in
       between to let the IDL do protocol processing.  (If the client doesn't
       have anything else to do in the meantime, it can use
       Transaction.commit_block() to avoid having to loop itself.)

    4. If the final status is Transaction.TRY_AGAIN, wait for Idl.change_seqno
       to change from the saved 'seqno' (it's possible that it's already
       changed, in which case the client should not wait at all), then start
       over from step 1.  Only a call to Idl.run() will change the return value
       of Idl.change_seqno.  (Transaction.commit_block() calls Idl.run().)"""

    # Status values that Transaction.commit() can return.
    UNCOMMITTED = "uncommitted"  # Not yet committed or aborted.
    UNCHANGED = "unchanged"      # Transaction didn't include any changes.
    INCOMPLETE = "incomplete"    # Commit in progress, please wait.
    ABORTED = "aborted"          # ovsdb_idl_txn_abort() called.
    SUCCESS = "success"          # Commit successful.
    TRY_AGAIN = "try again"      # Commit failed because a "verify" operation
                                 # reported an inconsistency, due to a network
                                 # problem, or other transient failure.  Wait
                                 # for a change, then try again.
    NOT_LOCKED = "not locked"    # Server hasn't given us the lock yet.
    ERROR = "error"              # Commit failed due to a hard error.

    @staticmethod
    def status_to_string(status):
        """Converts one of the status values that Transaction.commit() can
        return into a human-readable string.

        (The status values are in fact such strings already, so
        there's nothing to do.)"""
        return status

    def __init__(self, idl):
        """Starts a new transaction on 'idl' (an instance of ovs.db.idl.Idl).
        A given Idl may only have a single active transaction at a time.

        A Transaction may modify the contents of a database by assigning new
        values to columns (attributes of Row), deleting rows (with
        Row.delete()), or inserting rows (with Transaction.insert()).  It may
        also check that columns in the database have not changed with
        Row.verify().

        When a transaction is complete (which must be before the next call to
        Idl.run()), call Transaction.commit() or Transaction.abort()."""
        assert idl.txn is None

        idl.txn = self
        self._request_id = None
        self.idl = idl
        self.dry_run = False
        self._txn_rows = {}
        self._status = Transaction.UNCOMMITTED
        self._error = None
        self._comments = []
        self._commit_seqno = self.idl.change_seqno

        self._inc_row = None
        self._inc_column = None

        self._inserted_rows = {}  # Map from UUID to _InsertedRow

    def add_comment(self, comment):
        """Appens 'comment' to the comments that will be passed to the OVSDB
        server when this transaction is committed.  (The comment will be
        committed to the OVSDB log, which "ovsdb-tool show-log" can print in a
        relatively human-readable form.)"""
        self._comments.append(comment)

    def wait(self, poller):
        """Causes poll_block() to wake up if this transaction has completed
        committing."""
        if self._status not in (Transaction.UNCOMMITTED,
                                Transaction.INCOMPLETE):
            poller.immediate_wake()

    def _substitute_uuids(self, json):
        if type(json) in (list, tuple):
            if (len(json) == 2
                and json[0] == 'uuid'
                and ovs.ovsuuid.is_valid_string(json[1])):
                uuid = ovs.ovsuuid.from_string(json[1])
                row = self._txn_rows.get(uuid, None)
                if row and row._data is None:
                    return ["named-uuid", _uuid_name_from_uuid(uuid)]
            else:
                return [self._substitute_uuids(elem) for elem in json]
        return json

    def __disassemble(self):
        self.idl.txn = None

        for row in self._txn_rows.itervalues():
            if row._changes is None:
                row._table.rows[row.uuid] = row
            elif row._data is None:
                del row._table.rows[row.uuid]
            row.__dict__["_changes"] = {}
            row.__dict__["_prereqs"] = {}
        self._txn_rows = {}

    def commit(self):
        """Attempts to commit 'txn'.  Returns the status of the commit
        operation, one of the following constants:

          Transaction.INCOMPLETE:

              The transaction is in progress, but not yet complete.  The caller
              should call again later, after calling Idl.run() to let the
              IDL do OVSDB protocol processing.

          Transaction.UNCHANGED:

              The transaction is complete.  (It didn't actually change the
              database, so the IDL didn't send any request to the database
              server.)

          Transaction.ABORTED:

              The caller previously called Transaction.abort().

          Transaction.SUCCESS:

              The transaction was successful.  The update made by the
              transaction (and possibly other changes made by other database
              clients) should already be visible in the IDL.

          Transaction.TRY_AGAIN:

              The transaction failed for some transient reason, e.g. because a
              "verify" operation reported an inconsistency or due to a network
              problem.  The caller should wait for a change to the database,
              then compose a new transaction, and commit the new transaction.

              Use Idl.change_seqno to wait for a change in the database.  It is
              important to use its value *before* the initial call to
              Transaction.commit() as the baseline for this purpose, because
              the change that one should wait for can happen after the initial
              call but before the call that returns Transaction.TRY_AGAIN, and
              using some other baseline value in that situation could cause an
              indefinite wait if the database rarely changes.

          Transaction.NOT_LOCKED:

              The transaction failed because the IDL has been configured to
              require a database lock (with Idl.set_lock()) but didn't
              get it yet or has already lost it.

        Committing a transaction rolls back all of the changes that it made to
        the IDL's copy of the database.  If the transaction commits
        successfully, then the database server will send an update and, thus,
        the IDL will be updated with the committed changes."""
        # The status can only change if we're the active transaction.
        # (Otherwise, our status will change only in Idl.run().)
        if self != self.idl.txn:
            return self._status

        # If we need a lock but don't have it, give up quickly.
        if self.idl.lock_name and not self.idl.has_lock():
            self._status = Transaction.NOT_LOCKED
            self.__disassemble()
            return self._status

        operations = [self.idl._db.name]

        # Assert that we have the required lock (avoiding a race).
        if self.idl.lock_name:
            operations.append({"op": "assert",
                               "lock": self.idl.lock_name})

        # Add prerequisites and declarations of new rows.
        for row in self._txn_rows.itervalues():
            if row._prereqs:
                rows = {}
                columns = []
                for column_name in row._prereqs:
                    columns.append(column_name)
                    rows[column_name] = row._data[column_name].to_json()
                operations.append({"op": "wait",
                                   "table": row._table.name,
                                   "timeout": 0,
                                   "where": _where_uuid_equals(row.uuid),
                                   "until": "==",
                                   "columns": columns,
                                   "rows": [rows]})

        # Add updates.
        any_updates = False
        for row in self._txn_rows.itervalues():
            if row._changes is None:
                if row._table.is_root:
                    operations.append({"op": "delete",
                                       "table": row._table.name,
                                       "where": _where_uuid_equals(row.uuid)})
                    any_updates = True
                else:
                    # Let ovsdb-server decide whether to really delete it.
                    pass
            elif row._changes:
                op = {"table": row._table.name}
                if row._data is None:
                    op["op"] = "insert"
                    op["uuid-name"] = _uuid_name_from_uuid(row.uuid)
                    any_updates = True

                    op_index = len(operations) - 1
                    self._inserted_rows[row.uuid] = _InsertedRow(op_index)
                else:
                    op["op"] = "update"
                    op["where"] = _where_uuid_equals(row.uuid)

                row_json = {}
                op["row"] = row_json

                for column_name, datum in row._changes.iteritems():
                    if row._data is not None or not datum.is_default():
                        row_json[column_name] = (
                                self._substitute_uuids(datum.to_json()))

                        # If anything really changed, consider it an update.
                        # We can't suppress not-really-changed values earlier
                        # or transactions would become nonatomic (see the big
                        # comment inside Transaction._write()).
                        if (not any_updates and row._data is not None and
                            row._data[column_name] != datum):
                            any_updates = True

                if row._data is None or row_json:
                    operations.append(op)

        # Add increment.
        if self._inc_row and any_updates:
            self._inc_index = len(operations) - 1

            operations.append({"op": "mutate",
                               "table": self._inc_row._table.name,
                               "where": self._substitute_uuids(
                                   _where_uuid_equals(self._inc_row.uuid)),
                               "mutations": [[self._inc_column, "+=", 1]]})
            operations.append({"op": "select",
                               "table": self._inc_row._table.name,
                               "where": self._substitute_uuids(
                                   _where_uuid_equals(self._inc_row.uuid)),
                               "columns": [self._inc_column]})

        # Add comment.
        if self._comments:
            operations.append({"op": "comment",
                               "comment": "\n".join(self._comments)})

        # Dry run?
        if self.dry_run:
            operations.append({"op": "abort"})

        if not any_updates:
            self._status = Transaction.UNCHANGED
        else:
            msg = ovs.jsonrpc.Message.create_request("transact", operations)
            self._request_id = msg.id
            if not self.idl._session.send(msg):
                self.idl._outstanding_txns[self._request_id] = self
                self._status = Transaction.INCOMPLETE
            else:
                self._status = Transaction.TRY_AGAIN

        self.__disassemble()
        return self._status

    def commit_block(self):
        """Attempts to commit this transaction, blocking until the commit
        either succeeds or fails.  Returns the final commit status, which may
        be any Transaction.* value other than Transaction.INCOMPLETE.

        This function calls Idl.run() on this transaction'ss IDL, so it may
        cause Idl.change_seqno to change."""
        while True:
            status = self.commit()
            if status != Transaction.INCOMPLETE:
                return status

            self.idl.run()

            poller = ovs.poller.Poller()
            self.idl.wait(poller)
            self.wait(poller)
            poller.block()

    def get_increment_new_value(self):
        """Returns the final (incremented) value of the column in this
        transaction that was set to be incremented by Row.increment.  This
        transaction must have committed successfully."""
        assert self._status == Transaction.SUCCESS
        return self._inc_new_value

    def abort(self):
        """Aborts this transaction.  If Transaction.commit() has already been
        called then the transaction might get committed anyhow."""
        self.__disassemble()
        if self._status in (Transaction.UNCOMMITTED,
                            Transaction.INCOMPLETE):
            self._status = Transaction.ABORTED

    def get_error(self):
        """Returns a string representing this transaction's current status,
        suitable for use in log messages."""
        if self._status != Transaction.ERROR:
            return Transaction.status_to_string(self._status)
        elif self._error:
            return self._error
        else:
            return "no error details available"

    def __set_error_json(self, json):
        if self._error is None:
            self._error = ovs.json.to_string(json)

    def get_insert_uuid(self, uuid):
        """Finds and returns the permanent UUID that the database assigned to a
        newly inserted row, given the UUID that Transaction.insert() assigned
        locally to that row.

        Returns None if 'uuid' is not a UUID assigned by Transaction.insert()
        or if it was assigned by that function and then deleted by Row.delete()
        within the same transaction.  (Rows that are inserted and then deleted
        within a single transaction are never sent to the database server, so
        it never assigns them a permanent UUID.)

        This transaction must have completed successfully."""
        assert self._status in (Transaction.SUCCESS,
                                Transaction.UNCHANGED)
        inserted_row = self._inserted_rows.get(uuid)
        if inserted_row:
            return inserted_row.real
        return None

    def _increment(self, row, column):
        assert not self._inc_row
        self._inc_row = row
        self._inc_column = column

    def _write(self, row, column, datum):
        assert row._changes is not None

        txn = row._idl.txn

        # If this is a write-only column and the datum being written is the
        # same as the one already there, just skip the update entirely.  This
        # is worth optimizing because we have a lot of columns that get
        # periodically refreshed into the database but don't actually change
        # that often.
        #
        # We don't do this for read/write columns because that would break
        # atomicity of transactions--some other client might have written a
        # different value in that column since we read it.  (But if a whole
        # transaction only does writes of existing values, without making any
        # real changes, we will drop the whole transaction later in
        # ovsdb_idl_txn_commit().)
        if not column.alert and row._data.get(column.name) == datum:
            new_value = row._changes.get(column.name)
            if new_value is None or new_value == datum:
                return

        txn._txn_rows[row.uuid] = row
        row._changes[column.name] = datum.copy()

    def insert(self, table, new_uuid=None):
        """Inserts and returns a new row in 'table', which must be one of the
        ovs.db.schema.TableSchema objects in the Idl's 'tables' dict.

        The new row is assigned a provisional UUID.  If 'uuid' is None then one
        is randomly generated; otherwise 'uuid' should specify a randomly
        generated uuid.UUID not otherwise in use.  ovsdb-server will assign a
        different UUID when 'txn' is committed, but the IDL will replace any
        uses of the provisional UUID in the data to be to be committed by the
        UUID assigned by ovsdb-server."""
        assert self._status == Transaction.UNCOMMITTED
        if new_uuid is None:
            new_uuid = uuid.uuid4()
        row = Row(self.idl, table, new_uuid, None)
        table.rows[row.uuid] = row
        self._txn_rows[row.uuid] = row
        return row

    def _process_reply(self, msg):
        if msg.type == ovs.jsonrpc.Message.T_ERROR:
            self._status = Transaction.ERROR
        elif type(msg.result) not in (list, tuple):
            # XXX rate-limit
            vlog.warn('reply to "transact" is not JSON array')
        else:
            hard_errors = False
            soft_errors = False
            lock_errors = False

            ops = msg.result
            for op in ops:
                if op is None:
                    # This isn't an error in itself but indicates that some
                    # prior operation failed, so make sure that we know about
                    # it.
                    soft_errors = True
                elif type(op) == dict:
                    error = op.get("error")
                    if error is not None:
                        if error == "timed out":
                            soft_errors = True
                        elif error == "not owner":
                            lock_errors = True
                        elif error == "aborted":
                            pass
                        else:
                            hard_errors = True
                            self.__set_error_json(op)
                else:
                    hard_errors = True
                    self.__set_error_json(op)
                    # XXX rate-limit
                    vlog.warn("operation reply is not JSON null or object")

            if not soft_errors and not hard_errors and not lock_errors:
                if self._inc_row and not self.__process_inc_reply(ops):
                    hard_errors = True

                for insert in self._inserted_rows.itervalues():
                    if not self.__process_insert_reply(insert, ops):
                        hard_errors = True

            if hard_errors:
                self._status = Transaction.ERROR
            elif lock_errors:
                self._status = Transaction.NOT_LOCKED
            elif soft_errors:
                self._status = Transaction.TRY_AGAIN
            else:
                self._status = Transaction.SUCCESS

    @staticmethod
    def __check_json_type(json, types, name):
        if not json:
            # XXX rate-limit
            vlog.warn("%s is missing" % name)
            return False
        elif type(json) not in types:
            # XXX rate-limit
            vlog.warn("%s has unexpected type %s" % (name, type(json)))
            return False
        else:
            return True

    def __process_inc_reply(self, ops):
        if self._inc_index + 2 > len(ops):
            # XXX rate-limit
            vlog.warn("reply does not contain enough operations for "
                      "increment (has %d, needs %d)" %
                      (len(ops), self._inc_index + 2))

        # We know that this is a JSON object because the loop in
        # __process_reply() already checked.
        mutate = ops[self._inc_index]
        count = mutate.get("count")
        if not Transaction.__check_json_type(count, (int, long),
                                             '"mutate" reply "count"'):
            return False
        if count != 1:
            # XXX rate-limit
            vlog.warn('"mutate" reply "count" is %d instead of 1' % count)
            return False

        select = ops[self._inc_index + 1]
        rows = select.get("rows")
        if not Transaction.__check_json_type(rows, (list, tuple),
                                             '"select" reply "rows"'):
            return False
        if len(rows) != 1:
            # XXX rate-limit
            vlog.warn('"select" reply "rows" has %d elements '
                      'instead of 1' % len(rows))
            return False
        row = rows[0]
        if not Transaction.__check_json_type(row, (dict,),
                                             '"select" reply row'):
            return False
        column = row.get(self._inc_column)
        if not Transaction.__check_json_type(column, (int, long),
                                             '"select" reply inc column'):
            return False
        self._inc_new_value = column
        return True

    def __process_insert_reply(self, insert, ops):
        if insert.op_index >= len(ops):
            # XXX rate-limit
            vlog.warn("reply does not contain enough operations "
                      "for insert (has %d, needs %d)"
                      % (len(ops), insert.op_index))
            return False

        # We know that this is a JSON object because the loop in
        # __process_reply() already checked.
        reply = ops[insert.op_index]
        json_uuid = reply.get("uuid")
        if not Transaction.__check_json_type(json_uuid, (tuple, list),
                                             '"insert" reply "uuid"'):
            return False

        try:
            uuid_ = ovs.ovsuuid.from_json(json_uuid)
        except error.Error:
            # XXX rate-limit
            vlog.warn('"insert" reply "uuid" is not a JSON UUID')
            return False

        insert.real = uuid_
        return True


class SchemaHelper(object):
    """IDL Schema helper.

    This class encapsulates the logic required to generate schemas suitable
    for creating 'ovs.db.idl.Idl' objects.  Clients should register columns
    they are interested in using register_columns().  When finished, the
    get_idl_schema() function may be called.

    The location on disk of the schema used may be found in the
    'schema_location' variable."""

    def __init__(self, location=None, schema_json=None):
        """Creates a new Schema object.

        'location' file path to ovs schema. None means default location
        'schema_json' schema in json preresentation in memory
        """

        if location and schema_json:
            raise ValueError("both location and schema_json can't be "
                             "specified. it's ambiguous.")
        if schema_json is None:
            if location is None:
                location = "%s/vswitch.ovsschema" % ovs.dirs.PKGDATADIR
            schema_json = ovs.json.from_file(location)

        self.schema_json = schema_json
        self._tables = {}
        self._all = False

    def register_columns(self, table, columns):
        """Registers interest in the given 'columns' of 'table'.  Future calls
        to get_idl_schema() will include 'table':column for each column in
        'columns'. This function automatically avoids adding duplicate entries
        to the schema.

        'table' must be a string.
        'columns' must be a list of strings.
        """

        assert type(table) is str
        assert type(columns) is list

        columns = set(columns) | self._tables.get(table, set())
        self._tables[table] = columns

    def register_table(self, table):
        """Registers interest in the given all columns of 'table'. Future calls
        to get_idl_schema() will include all columns of 'table'.

        'table' must be a string
        """
        assert type(table) is str
        self._tables[table] = set()  # empty set means all columns in the table

    def register_all(self):
        """Registers interest in every column of every table."""
        self._all = True

    def get_idl_schema(self):
        """Gets a schema appropriate for the creation of an 'ovs.db.id.IDL'
        object based on columns registered using the register_columns()
        function."""

        schema = ovs.db.schema.DbSchema.from_json(self.schema_json)
        self.schema_json = None

        if not self._all:
            schema_tables = {}
            for table, columns in self._tables.iteritems():
                schema_tables[table] = (
                    self._keep_table_columns(schema, table, columns))

            schema.tables = schema_tables
        return schema

    def _keep_table_columns(self, schema, table_name, columns):
        assert table_name in schema.tables
        table = schema.tables[table_name]

        if not columns:
            # empty set means all columns in the table
            return table

        new_columns = {}
        for column_name in columns:
            assert type(column_name) is str
            assert column_name in table.columns

            new_columns[column_name] = table.columns[column_name]

        table.columns = new_columns
        return table

########NEW FILE########
__FILENAME__ = parser
# Copyright (c) 2010, 2011 Nicira, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at:
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import re

from ovs.db import error


class Parser(object):
    def __init__(self, json, name):
        self.name = name
        self.json = json
        if type(json) != dict:
            self.__raise_error("Object expected.")
        self.used = set()

    def __get(self, name, types, optional, default=None):
        if name in self.json:
            self.used.add(name)
            member = float_to_int(self.json[name])
            if is_identifier(member) and "id" in types:
                return member
            if len(types) and type(member) not in types:
                self.__raise_error("Type mismatch for member '%s'." % name)
            return member
        else:
            if not optional:
                self.__raise_error("Required '%s' member is missing." % name)
            return default

    def get(self, name, types):
        return self.__get(name, types, False)

    def get_optional(self, name, types, default=None):
        return self.__get(name, types, True, default)

    def __raise_error(self, message):
        raise error.Error("Parsing %s failed: %s" % (self.name, message),
                          self.json)

    def finish(self):
        missing = set(self.json) - set(self.used)
        if missing:
            name = missing.pop()
            if len(missing) > 1:
                present = "and %d other members are" % len(missing)
            elif missing:
                present = "and 1 other member are"
            else:
                present = "is"
            self.__raise_error("Member '%s' %s present but not allowed here" %
                               (name, present))


def float_to_int(x):
    # XXX still needed?
    if type(x) == float:
        integer = int(x)
        if integer == x and -2 ** 53 <= integer < 2 ** 53:
            return integer
    return x


id_re = re.compile("[_a-zA-Z][_a-zA-Z0-9]*$")


def is_identifier(s):
    return type(s) in [str, unicode] and id_re.match(s)


def json_type_to_string(type_):
    if type_ == None:
        return "null"
    elif type_ == bool:
        return "boolean"
    elif type_ == dict:
        return "object"
    elif type_ == list:
        return "array"
    elif type_ in [int, long, float]:
        return "number"
    elif type_ in [str, unicode]:
        return "string"
    else:
        return "<invalid>"


def unwrap_json(json, name, types, desc):
    if (type(json) not in (list, tuple) or len(json) != 2 or json[0] != name or
        type(json[1]) not in types):
        raise error.Error('expected ["%s", <%s>]' % (name, desc), json)
    return json[1]


def parse_json_pair(json):
    if type(json) != list or len(json) != 2:
        raise error.Error("expected 2-element array", json)
    return json

########NEW FILE########
__FILENAME__ = schema
# Copyright (c) 2009, 2010, 2011 Nicira, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at:
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import re
import sys

from ovs.db import error
import ovs.db.parser
from ovs.db import types


def _check_id(name, json):
    if name.startswith('_'):
        raise error.Error('names beginning with "_" are reserved', json)
    elif not ovs.db.parser.is_identifier(name):
        raise error.Error("name must be a valid id", json)


class DbSchema(object):
    """Schema for an OVSDB database."""

    def __init__(self, name, version, tables):
        self.name = name
        self.version = version
        self.tables = tables

        # "isRoot" was not part of the original schema definition.  Before it
        # was added, there was no support for garbage collection.  So, for
        # backward compatibility, if the root set is empty then assume that
        # every table is in the root set.
        if self.__root_set_size() == 0:
            for table in self.tables.itervalues():
                table.is_root = True

        # Find the "ref_table"s referenced by "ref_table_name"s.
        #
        # Also force certain columns to be persistent, as explained in
        # __check_ref_table().  This requires 'is_root' to be known, so this
        # must follow the loop updating 'is_root' above.
        for table in self.tables.itervalues():
            for column in table.columns.itervalues():
                self.__follow_ref_table(column, column.type.key, "key")
                self.__follow_ref_table(column, column.type.value, "value")

    def __root_set_size(self):
        """Returns the number of tables in the schema's root set."""
        n_root = 0
        for table in self.tables.itervalues():
            if table.is_root:
                n_root += 1
        return n_root

    @staticmethod
    def from_json(json):
        parser = ovs.db.parser.Parser(json, "database schema")
        name = parser.get("name", ['id'])
        version = parser.get_optional("version", [str, unicode])
        parser.get_optional("cksum", [str, unicode])
        tablesJson = parser.get("tables", [dict])
        parser.finish()

        if (version is not None and
            not re.match('[0-9]+\.[0-9]+\.[0-9]+$', version)):
            raise error.Error('schema version "%s" not in format x.y.z'
                              % version)

        tables = {}
        for tableName, tableJson in tablesJson.iteritems():
            _check_id(tableName, json)
            tables[tableName] = TableSchema.from_json(tableJson, tableName)

        return DbSchema(name, version, tables)

    def to_json(self):
        # "isRoot" was not part of the original schema definition.  Before it
        # was added, there was no support for garbage collection.  So, for
        # backward compatibility, if every table is in the root set then do not
        # output "isRoot" in table schemas.
        default_is_root = self.__root_set_size() == len(self.tables)

        tables = {}
        for table in self.tables.itervalues():
            tables[table.name] = table.to_json(default_is_root)
        json = {"name": self.name, "tables": tables}
        if self.version:
            json["version"] = self.version
        return json

    def copy(self):
        return DbSchema.from_json(self.to_json())

    def __follow_ref_table(self, column, base, base_name):
        if not base or base.type != types.UuidType or not base.ref_table_name:
            return

        base.ref_table = self.tables.get(base.ref_table_name)
        if not base.ref_table:
            raise error.Error("column %s %s refers to undefined table %s"
                              % (column.name, base_name, base.ref_table_name),
                              tag="syntax error")

        if base.is_strong_ref() and not base.ref_table.is_root:
            # We cannot allow a strong reference to a non-root table to be
            # ephemeral: if it is the only reference to a row, then replaying
            # the database log from disk will cause the referenced row to be
            # deleted, even though it did exist in memory.  If there are
            # references to that row later in the log (to modify it, to delete
            # it, or just to point to it), then this will yield a transaction
            # error.
            column.persistent = True


class IdlSchema(DbSchema):
    def __init__(self, name, version, tables, idlPrefix, idlHeader):
        DbSchema.__init__(self, name, version, tables)
        self.idlPrefix = idlPrefix
        self.idlHeader = idlHeader

    @staticmethod
    def from_json(json):
        parser = ovs.db.parser.Parser(json, "IDL schema")
        idlPrefix = parser.get("idlPrefix", [str, unicode])
        idlHeader = parser.get("idlHeader", [str, unicode])

        subjson = dict(json)
        del subjson["idlPrefix"]
        del subjson["idlHeader"]
        schema = DbSchema.from_json(subjson)

        return IdlSchema(schema.name, schema.version, schema.tables,
                         idlPrefix, idlHeader)


def column_set_from_json(json, columns):
    if json is None:
        return tuple(columns)
    elif type(json) != list:
        raise error.Error("array of distinct column names expected", json)
    else:
        for column_name in json:
            if type(column_name) not in [str, unicode]:
                raise error.Error("array of distinct column names expected",
                                  json)
            elif column_name not in columns:
                raise error.Error("%s is not a valid column name"
                                  % column_name, json)
        if len(set(json)) != len(json):
            # Duplicate.
            raise error.Error("array of distinct column names expected", json)
        return tuple([columns[column_name] for column_name in json])


class TableSchema(object):
    def __init__(self, name, columns, mutable=True, max_rows=sys.maxint,
                 is_root=True, indexes=[]):
        self.name = name
        self.columns = columns
        self.mutable = mutable
        self.max_rows = max_rows
        self.is_root = is_root
        self.indexes = indexes

    @staticmethod
    def from_json(json, name):
        parser = ovs.db.parser.Parser(json, "table schema for table %s" % name)
        columns_json = parser.get("columns", [dict])
        mutable = parser.get_optional("mutable", [bool], True)
        max_rows = parser.get_optional("maxRows", [int])
        is_root = parser.get_optional("isRoot", [bool], False)
        indexes_json = parser.get_optional("indexes", [list], [])
        parser.finish()

        if max_rows == None:
            max_rows = sys.maxint
        elif max_rows <= 0:
            raise error.Error("maxRows must be at least 1", json)

        if not columns_json:
            raise error.Error("table must have at least one column", json)

        columns = {}
        for column_name, column_json in columns_json.iteritems():
            _check_id(column_name, json)
            columns[column_name] = ColumnSchema.from_json(column_json,
                                                          column_name)

        indexes = []
        for index_json in indexes_json:
            index = column_set_from_json(index_json, columns)
            if not index:
                raise error.Error("index must have at least one column", json)
            elif len(index) == 1:
                index[0].unique = True
            for column in index:
                if not column.persistent:
                    raise error.Error("ephemeral columns (such as %s) may "
                                      "not be indexed" % column.name, json)
            indexes.append(index)

        return TableSchema(name, columns, mutable, max_rows, is_root, indexes)

    def to_json(self, default_is_root=False):
        """Returns this table schema serialized into JSON.

        The "isRoot" member is included in the JSON only if its value would
        differ from 'default_is_root'.  Ordinarily 'default_is_root' should be
        false, because ordinarily a table would be not be part of the root set
        if its "isRoot" member is omitted.  However, garbage collection was not
        orginally included in OVSDB, so in older schemas that do not include
        any "isRoot" members, every table is implicitly part of the root set.
        To serialize such a schema in a way that can be read by older OVSDB
        tools, specify 'default_is_root' as True.
        """
        json = {}
        if not self.mutable:
            json["mutable"] = False
        if default_is_root != self.is_root:
            json["isRoot"] = self.is_root

        json["columns"] = columns = {}
        for column in self.columns.itervalues():
            if not column.name.startswith("_"):
                columns[column.name] = column.to_json()

        if self.max_rows != sys.maxint:
            json["maxRows"] = self.max_rows

        if self.indexes:
            json["indexes"] = []
            for index in self.indexes:
                json["indexes"].append([column.name for column in index])

        return json


class ColumnSchema(object):
    def __init__(self, name, mutable, persistent, type_):
        self.name = name
        self.mutable = mutable
        self.persistent = persistent
        self.type = type_
        self.unique = False

    @staticmethod
    def from_json(json, name):
        parser = ovs.db.parser.Parser(json, "schema for column %s" % name)
        mutable = parser.get_optional("mutable", [bool], True)
        ephemeral = parser.get_optional("ephemeral", [bool], False)
        type_ = types.Type.from_json(parser.get("type", [dict, str, unicode]))
        parser.finish()

        return ColumnSchema(name, mutable, not ephemeral, type_)

    def to_json(self):
        json = {"type": self.type.to_json()}
        if not self.mutable:
            json["mutable"] = False
        if not self.persistent:
            json["ephemeral"] = True
        return json

########NEW FILE########
__FILENAME__ = types
# Copyright (c) 2009, 2010, 2011, 2012 Nicira, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at:
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import sys
import uuid

from ovs.db import error
import ovs.db.parser
import ovs.db.data
import ovs.ovsuuid


class AtomicType(object):
    def __init__(self, name, default, python_types):
        self.name = name
        self.default = default
        self.python_types = python_types

    @staticmethod
    def from_string(s):
        if s != "void":
            for atomic_type in ATOMIC_TYPES:
                if s == atomic_type.name:
                    return atomic_type
        raise error.Error('"%s" is not an atomic-type' % s, s)

    @staticmethod
    def from_json(json):
        if type(json) not in [str, unicode]:
            raise error.Error("atomic-type expected", json)
        else:
            return AtomicType.from_string(json)

    def __str__(self):
        return self.name

    def to_string(self):
        return self.name

    def to_json(self):
        return self.name

    def default_atom(self):
        return ovs.db.data.Atom(self, self.default)

VoidType = AtomicType("void", None, ())
IntegerType = AtomicType("integer", 0, (int, long))
RealType = AtomicType("real", 0.0, (int, long, float))
BooleanType = AtomicType("boolean", False, (bool,))
StringType = AtomicType("string", "", (str, unicode))
UuidType = AtomicType("uuid", ovs.ovsuuid.zero(), (uuid.UUID,))

ATOMIC_TYPES = [VoidType, IntegerType, RealType, BooleanType, StringType,
                UuidType]


def escapeCString(src):
    dst = ""
    for c in src:
        if c in "\\\"":
            dst += "\\" + c
        elif ord(c) < 32:
            if c == '\n':
                dst += '\\n'
            elif c == '\r':
                dst += '\\r'
            elif c == '\a':
                dst += '\\a'
            elif c == '\b':
                dst += '\\b'
            elif c == '\f':
                dst += '\\f'
            elif c == '\t':
                dst += '\\t'
            elif c == '\v':
                dst += '\\v'
            else:
                dst += '\\%03o' % ord(c)
        else:
            dst += c
    return dst


def commafy(x):
    """Returns integer x formatted in decimal with thousands set off by
    commas."""
    return _commafy("%d" % x)


def _commafy(s):
    if s.startswith('-'):
        return '-' + _commafy(s[1:])
    elif len(s) <= 3:
        return s
    else:
        return _commafy(s[:-3]) + ',' + _commafy(s[-3:])


def returnUnchanged(x):
    return x


class BaseType(object):
    def __init__(self, type_, enum=None, min=None, max=None,
                 min_length=0, max_length=sys.maxint, ref_table_name=None):
        assert isinstance(type_, AtomicType)
        self.type = type_
        self.enum = enum
        self.min = min
        self.max = max
        self.min_length = min_length
        self.max_length = max_length
        self.ref_table_name = ref_table_name
        if ref_table_name:
            self.ref_type = 'strong'
        else:
            self.ref_type = None
        self.ref_table = None

    def default(self):
        return ovs.db.data.Atom.default(self.type)

    def __eq__(self, other):
        if not isinstance(other, BaseType):
            return NotImplemented
        return (self.type == other.type and self.enum == other.enum and
                self.min == other.min and self.max == other.max and
                self.min_length == other.min_length and
                self.max_length == other.max_length and
                self.ref_table_name == other.ref_table_name)

    def __ne__(self, other):
        if not isinstance(other, BaseType):
            return NotImplemented
        else:
            return not (self == other)

    @staticmethod
    def __parse_uint(parser, name, default):
        value = parser.get_optional(name, [int, long])
        if value is None:
            value = default
        else:
            max_value = 2 ** 32 - 1
            if not (0 <= value <= max_value):
                raise error.Error("%s out of valid range 0 to %d"
                                  % (name, max_value), value)
        return value

    @staticmethod
    def from_json(json):
        if type(json) in [str, unicode]:
            return BaseType(AtomicType.from_json(json))

        parser = ovs.db.parser.Parser(json, "ovsdb type")
        atomic_type = AtomicType.from_json(parser.get("type", [str, unicode]))

        base = BaseType(atomic_type)

        enum = parser.get_optional("enum", [])
        if enum is not None:
            base.enum = ovs.db.data.Datum.from_json(
                    BaseType.get_enum_type(base.type), enum)
        elif base.type == IntegerType:
            base.min = parser.get_optional("minInteger", [int, long])
            base.max = parser.get_optional("maxInteger", [int, long])
            if (base.min is not None and base.max is not None
                    and base.min > base.max):
                raise error.Error("minInteger exceeds maxInteger", json)
        elif base.type == RealType:
            base.min = parser.get_optional("minReal", [int, long, float])
            base.max = parser.get_optional("maxReal", [int, long, float])
            if (base.min is not None and base.max is not None
                    and base.min > base.max):
                raise error.Error("minReal exceeds maxReal", json)
        elif base.type == StringType:
            base.min_length = BaseType.__parse_uint(parser, "minLength", 0)
            base.max_length = BaseType.__parse_uint(parser, "maxLength",
                                                    sys.maxint)
            if base.min_length > base.max_length:
                raise error.Error("minLength exceeds maxLength", json)
        elif base.type == UuidType:
            base.ref_table_name = parser.get_optional("refTable", ['id'])
            if base.ref_table_name:
                base.ref_type = parser.get_optional("refType", [str, unicode],
                                                   "strong")
                if base.ref_type not in ['strong', 'weak']:
                    raise error.Error('refType must be "strong" or "weak" '
                                      '(not "%s")' % base.ref_type)
        parser.finish()

        return base

    def to_json(self):
        if not self.has_constraints():
            return self.type.to_json()

        json = {'type': self.type.to_json()}

        if self.enum:
            json['enum'] = self.enum.to_json()

        if self.type == IntegerType:
            if self.min is not None:
                json['minInteger'] = self.min
            if self.max is not None:
                json['maxInteger'] = self.max
        elif self.type == RealType:
            if self.min is not None:
                json['minReal'] = self.min
            if self.max is not None:
                json['maxReal'] = self.max
        elif self.type == StringType:
            if self.min_length != 0:
                json['minLength'] = self.min_length
            if self.max_length != sys.maxint:
                json['maxLength'] = self.max_length
        elif self.type == UuidType:
            if self.ref_table_name:
                json['refTable'] = self.ref_table_name
                if self.ref_type != 'strong':
                    json['refType'] = self.ref_type
        return json

    def copy(self):
        base = BaseType(self.type, self.enum.copy(), self.min, self.max,
                        self.min_length, self.max_length, self.ref_table_name)
        base.ref_table = self.ref_table
        return base

    def is_valid(self):
        if self.type in (VoidType, BooleanType, UuidType):
            return True
        elif self.type in (IntegerType, RealType):
            return self.min is None or self.max is None or self.min <= self.max
        elif self.type == StringType:
            return self.min_length <= self.max_length
        else:
            return False

    def has_constraints(self):
        return (self.enum is not None or self.min is not None or
                self.max is not None or
                self.min_length != 0 or self.max_length != sys.maxint or
                self.ref_table_name is not None)

    def without_constraints(self):
        return BaseType(self.type)

    @staticmethod
    def get_enum_type(atomic_type):
        """Returns the type of the 'enum' member for a BaseType whose
        'type' is 'atomic_type'."""
        return Type(BaseType(atomic_type), None, 1, sys.maxint)

    def is_ref(self):
        return self.type == UuidType and self.ref_table_name is not None

    def is_strong_ref(self):
        return self.is_ref() and self.ref_type == 'strong'

    def is_weak_ref(self):
        return self.is_ref() and self.ref_type == 'weak'

    def toEnglish(self, escapeLiteral=returnUnchanged):
        if self.type == UuidType and self.ref_table_name:
            s = escapeLiteral(self.ref_table_name)
            if self.ref_type == 'weak':
                s = "weak reference to " + s
            return s
        else:
            return self.type.to_string()

    def constraintsToEnglish(self, escapeLiteral=returnUnchanged,
                             escapeNumber=returnUnchanged):
        if self.enum:
            literals = [value.toEnglish(escapeLiteral)
                        for value in self.enum.values]
            if len(literals) == 2:
                english = 'either %s or %s' % (literals[0], literals[1])
            else:
                english = 'one of %s, %s, or %s' % (literals[0],
                                                    ', '.join(literals[1:-1]),
                                                    literals[-1])
        elif self.min is not None and self.max is not None:
            if self.type == IntegerType:
                english = 'in range %s to %s' % (
                    escapeNumber(commafy(self.min)),
                    escapeNumber(commafy(self.max)))
            else:
                english = 'in range %s to %s' % (
                    escapeNumber("%g" % self.min),
                    escapeNumber("%g" % self.max))
        elif self.min is not None:
            if self.type == IntegerType:
                english = 'at least %s' % escapeNumber(commafy(self.min))
            else:
                english = 'at least %s' % escapeNumber("%g" % self.min)
        elif self.max is not None:
            if self.type == IntegerType:
                english = 'at most %s' % escapeNumber(commafy(self.max))
            else:
                english = 'at most %s' % escapeNumber("%g" % self.max)
        elif self.min_length != 0 and self.max_length != sys.maxint:
            if self.min_length == self.max_length:
                english = ('exactly %s characters long'
                           % commafy(self.min_length))
            else:
                english = ('between %s and %s characters long'
                        % (commafy(self.min_length),
                           commafy(self.max_length)))
        elif self.min_length != 0:
            return 'at least %s characters long' % commafy(self.min_length)
        elif self.max_length != sys.maxint:
            english = 'at most %s characters long' % commafy(self.max_length)
        else:
            english = ''

        return english

    def toCType(self, prefix):
        if self.ref_table_name:
            return "struct %s%s *" % (prefix, self.ref_table_name.lower())
        else:
            return {IntegerType: 'int64_t ',
                    RealType: 'double ',
                    UuidType: 'struct uuid ',
                    BooleanType: 'bool ',
                    StringType: 'char *'}[self.type]

    def toAtomicType(self):
        return "OVSDB_TYPE_%s" % self.type.to_string().upper()

    def copyCValue(self, dst, src):
        args = {'dst': dst, 'src': src}
        if self.ref_table_name:
            return ("%(dst)s = %(src)s->header_.uuid;") % args
        elif self.type == StringType:
            return "%(dst)s = xstrdup(%(src)s);" % args
        else:
            return "%(dst)s = %(src)s;" % args

    def initCDefault(self, var, is_optional):
        if self.ref_table_name:
            return "%s = NULL;" % var
        elif self.type == StringType and not is_optional:
            return '%s = "";' % var
        else:
            pattern = {IntegerType: '%s = 0;',
                       RealType: '%s = 0.0;',
                       UuidType: 'uuid_zero(&%s);',
                       BooleanType: '%s = false;',
                       StringType: '%s = NULL;'}[self.type]
            return pattern % var

    def cInitBaseType(self, indent, var):
        stmts = []
        stmts.append('ovsdb_base_type_init(&%s, %s);' % (
                var, self.toAtomicType()))
        if self.enum:
            stmts.append("%s.enum_ = xmalloc(sizeof *%s.enum_);"
                         % (var, var))
            stmts += self.enum.cInitDatum("%s.enum_" % var)
        if self.type == IntegerType:
            if self.min is not None:
                stmts.append('%s.u.integer.min = INT64_C(%d);'
                        % (var, self.min))
            if self.max is not None:
                stmts.append('%s.u.integer.max = INT64_C(%d);'
                        % (var, self.max))
        elif self.type == RealType:
            if self.min is not None:
                stmts.append('%s.u.real.min = %d;' % (var, self.min))
            if self.max is not None:
                stmts.append('%s.u.real.max = %d;' % (var, self.max))
        elif self.type == StringType:
            if self.min_length is not None:
                stmts.append('%s.u.string.minLen = %d;'
                        % (var, self.min_length))
            if self.max_length != sys.maxint:
                stmts.append('%s.u.string.maxLen = %d;'
                        % (var, self.max_length))
        elif self.type == UuidType:
            if self.ref_table_name is not None:
                stmts.append('%s.u.uuid.refTableName = "%s";'
                        % (var, escapeCString(self.ref_table_name)))
                stmts.append('%s.u.uuid.refType = OVSDB_REF_%s;'
                        % (var, self.ref_type.upper()))
        return '\n'.join([indent + stmt for stmt in stmts])


class Type(object):
    DEFAULT_MIN = 1
    DEFAULT_MAX = 1

    def __init__(self, key, value=None, n_min=DEFAULT_MIN, n_max=DEFAULT_MAX):
        self.key = key
        self.value = value
        self.n_min = n_min
        self.n_max = n_max

    def copy(self):
        if self.value is None:
            value = None
        else:
            value = self.value.copy()
        return Type(self.key.copy(), value, self.n_min, self.n_max)

    def __eq__(self, other):
        if not isinstance(other, Type):
            return NotImplemented
        return (self.key == other.key and self.value == other.value and
                self.n_min == other.n_min and self.n_max == other.n_max)

    def __ne__(self, other):
        if not isinstance(other, Type):
            return NotImplemented
        else:
            return not (self == other)

    def is_valid(self):
        return (self.key.type != VoidType and self.key.is_valid() and
                (self.value is None or
                 (self.value.type != VoidType and self.value.is_valid())) and
                self.n_min <= 1 <= self.n_max)

    def is_scalar(self):
        return self.n_min == 1 and self.n_max == 1 and not self.value

    def is_optional(self):
        return self.n_min == 0 and self.n_max == 1

    def is_composite(self):
        return self.n_max > 1

    def is_set(self):
        return self.value is None and (self.n_min != 1 or self.n_max != 1)

    def is_map(self):
        return self.value is not None

    def is_smap(self):
        return (self.is_map()
                and self.key.type == StringType
                and self.value.type == StringType)

    def is_optional_pointer(self):
        return (self.is_optional() and not self.value
                and (self.key.type == StringType or self.key.ref_table_name))

    @staticmethod
    def __n_from_json(json, default):
        if json is None:
            return default
        elif type(json) == int and 0 <= json <= sys.maxint:
            return json
        else:
            raise error.Error("bad min or max value", json)

    @staticmethod
    def from_json(json):
        if type(json) in [str, unicode]:
            return Type(BaseType.from_json(json))

        parser = ovs.db.parser.Parser(json, "ovsdb type")
        key_json = parser.get("key", [dict, str, unicode])
        value_json = parser.get_optional("value", [dict, str, unicode])
        min_json = parser.get_optional("min", [int])
        max_json = parser.get_optional("max", [int, str, unicode])
        parser.finish()

        key = BaseType.from_json(key_json)
        if value_json:
            value = BaseType.from_json(value_json)
        else:
            value = None

        n_min = Type.__n_from_json(min_json, Type.DEFAULT_MIN)

        if max_json == 'unlimited':
            n_max = sys.maxint
        else:
            n_max = Type.__n_from_json(max_json, Type.DEFAULT_MAX)

        type_ = Type(key, value, n_min, n_max)
        if not type_.is_valid():
            raise error.Error("ovsdb type fails constraint checks", json)
        return type_

    def to_json(self):
        if self.is_scalar() and not self.key.has_constraints():
            return self.key.to_json()

        json = {"key": self.key.to_json()}
        if self.value is not None:
            json["value"] = self.value.to_json()
        if self.n_min != Type.DEFAULT_MIN:
            json["min"] = self.n_min
        if self.n_max == sys.maxint:
            json["max"] = "unlimited"
        elif self.n_max != Type.DEFAULT_MAX:
            json["max"] = self.n_max
        return json

    def toEnglish(self, escapeLiteral=returnUnchanged):
        keyName = self.key.toEnglish(escapeLiteral)
        if self.value:
            valueName = self.value.toEnglish(escapeLiteral)

        if self.is_scalar():
            return keyName
        elif self.is_optional():
            if self.value:
                return "optional %s-%s pair" % (keyName, valueName)
            else:
                return "optional %s" % keyName
        else:
            if self.n_max == sys.maxint:
                if self.n_min:
                    quantity = "%s or more " % commafy(self.n_min)
                else:
                    quantity = ""
            elif self.n_min:
                quantity = "%s to %s " % (commafy(self.n_min),
                                          commafy(self.n_max))
            else:
                quantity = "up to %s " % commafy(self.n_max)

            if self.value:
                return "map of %s%s-%s pairs" % (quantity, keyName, valueName)
            else:
                if keyName.endswith('s'):
                    plural = keyName + "es"
                else:
                    plural = keyName + "s"
                return "set of %s%s" % (quantity, plural)

    def constraintsToEnglish(self, escapeLiteral=returnUnchanged,
                             escapeNumber=returnUnchanged):
        constraints = []
        keyConstraints = self.key.constraintsToEnglish(escapeLiteral,
                                                       escapeNumber)
        if keyConstraints:
            if self.value:
                constraints.append('key %s' % keyConstraints)
            else:
                constraints.append(keyConstraints)

        if self.value:
            valueConstraints = self.value.constraintsToEnglish(escapeLiteral,
                                                               escapeNumber)
            if valueConstraints:
                constraints.append('value %s' % valueConstraints)

        return ', '.join(constraints)

    def cDeclComment(self):
        if self.n_min == 1 and self.n_max == 1 and self.key.type == StringType:
            return "\t/* Always nonnull. */"
        else:
            return ""

    def cInitType(self, indent, var):
        initKey = self.key.cInitBaseType(indent, "%s.key" % var)
        if self.value:
            initValue = self.value.cInitBaseType(indent, "%s.value" % var)
        else:
            initValue = ('%sovsdb_base_type_init(&%s.value, '
                         'OVSDB_TYPE_VOID);' % (indent, var))
        initMin = "%s%s.n_min = %s;" % (indent, var, self.n_min)
        if self.n_max == sys.maxint:
            n_max = "UINT_MAX"
        else:
            n_max = self.n_max
        initMax = "%s%s.n_max = %s;" % (indent, var, n_max)
        return "\n".join((initKey, initValue, initMin, initMax))

########NEW FILE########
__FILENAME__ = dirs
import os
PKGDATADIR = os.environ.get("OVS_PKGDATADIR", """/usr/share/openvswitch""")
RUNDIR = os.environ.get("OVS_RUNDIR", """/var/run/openvswitch""")
LOGDIR = os.environ.get("OVS_LOGDIR", """/var/log/openvswitch""")
BINDIR = os.environ.get("OVS_BINDIR", """/usr/bin""")

DBDIR = os.environ.get("OVS_DBDIR")
if not DBDIR:
    sysconfdir = os.environ.get("OVS_SYSCONFDIR")
    if sysconfdir:
        DBDIR = "%s/openvswitch" % sysconfdir
    else:
        DBDIR = """/etc/openvswitch"""

########NEW FILE########
__FILENAME__ = fatal_signal
# Copyright (c) 2010, 2011 Nicira, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at:
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import atexit
import os
import signal

import ovs.vlog

_hooks = []
vlog = ovs.vlog.Vlog("fatal-signal")


def add_hook(hook, cancel, run_at_exit):
    _init()
    _hooks.append((hook, cancel, run_at_exit))


def fork():
    """Clears all of the fatal signal hooks without executing them.  If any of
    the hooks passed a 'cancel' function to add_hook(), then those functions
    will be called, allowing them to free resources, etc.

    Following a fork, one of the resulting processes can call this function to
    allow it to terminate without calling the hooks registered before calling
    this function.  New hooks registered after calling this function will take
    effect normally."""
    global _hooks
    for hook, cancel, run_at_exit in _hooks:
        if cancel:
            cancel()

    _hooks = []

_added_hook = False
_files = {}


def add_file_to_unlink(file):
    """Registers 'file' to be unlinked when the program terminates via
    sys.exit() or a fatal signal."""
    global _added_hook
    if not _added_hook:
        _added_hook = True
        add_hook(_unlink_files, _cancel_files, True)
    _files[file] = None


def remove_file_to_unlink(file):
    """Unregisters 'file' from being unlinked when the program terminates via
    sys.exit() or a fatal signal."""
    if file in _files:
        del _files[file]


def unlink_file_now(file):
    """Like fatal_signal_remove_file_to_unlink(), but also unlinks 'file'.
    Returns 0 if successful, otherwise a positive errno value."""
    error = _unlink(file)
    if error:
        vlog.warn("could not unlink \"%s\" (%s)" % (file, os.strerror(error)))
    remove_file_to_unlink(file)
    return error


def _unlink_files():
    for file_ in _files:
        _unlink(file_)


def _cancel_files():
    global _added_hook
    global _files
    _added_hook = False
    _files = {}


def _unlink(file_):
    try:
        os.unlink(file_)
        return 0
    except OSError, e:
        return e.errno


def _signal_handler(signr, _):
    _call_hooks(signr)

    # Re-raise the signal with the default handling so that the program
    # termination status reflects that we were killed by this signal.
    signal.signal(signr, signal.SIG_DFL)
    os.kill(os.getpid(), signr)


def _atexit_handler():
    _call_hooks(0)


recurse = False


def _call_hooks(signr):
    global recurse
    if recurse:
        return
    recurse = True

    for hook, cancel, run_at_exit in _hooks:
        if signr != 0 or run_at_exit:
            hook()


_inited = False


def _init():
    global _inited
    if not _inited:
        _inited = True

        for signr in (signal.SIGTERM, signal.SIGINT,
                      signal.SIGHUP, signal.SIGALRM):
            if signal.getsignal(signr) == signal.SIG_DFL:
                signal.signal(signr, _signal_handler)
        atexit.register(_atexit_handler)

########NEW FILE########
__FILENAME__ = json
# Copyright (c) 2010, 2011, 2012 Nicira, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at:
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import re
import StringIO
import sys

__pychecker__ = 'no-stringiter'

escapes = {ord('"'): u"\\\"",
           ord("\\"): u"\\\\",
           ord("\b"): u"\\b",
           ord("\f"): u"\\f",
           ord("\n"): u"\\n",
           ord("\r"): u"\\r",
           ord("\t"): u"\\t"}
for esc in range(32):
    if esc not in escapes:
        escapes[esc] = u"\\u%04x" % esc

SPACES_PER_LEVEL = 2


class _Serializer(object):
    def __init__(self, stream, pretty, sort_keys):
        self.stream = stream
        self.pretty = pretty
        self.sort_keys = sort_keys
        self.depth = 0

    def __serialize_string(self, s):
        self.stream.write(u'"%s"' % ''.join(escapes.get(ord(c), c) for c in s))

    def __indent_line(self):
        if self.pretty:
            self.stream.write('\n')
            self.stream.write(' ' * (SPACES_PER_LEVEL * self.depth))

    def serialize(self, obj):
        if obj is None:
            self.stream.write(u"null")
        elif obj is False:
            self.stream.write(u"false")
        elif obj is True:
            self.stream.write(u"true")
        elif type(obj) in (int, long):
            self.stream.write(u"%d" % obj)
        elif type(obj) == float:
            self.stream.write("%.15g" % obj)
        elif type(obj) == unicode:
            self.__serialize_string(obj)
        elif type(obj) == str:
            self.__serialize_string(unicode(obj))
        elif type(obj) == dict:
            self.stream.write(u"{")

            self.depth += 1
            self.__indent_line()

            if self.sort_keys:
                items = sorted(obj.items())
            else:
                items = obj.iteritems()
            for i, (key, value) in enumerate(items):
                if i > 0:
                    self.stream.write(u",")
                    self.__indent_line()
                self.__serialize_string(unicode(key))
                self.stream.write(u":")
                if self.pretty:
                    self.stream.write(u' ')
                self.serialize(value)

            self.stream.write(u"}")
            self.depth -= 1
        elif type(obj) in (list, tuple):
            self.stream.write(u"[")
            self.depth += 1

            if obj:
                self.__indent_line()

                for i, value in enumerate(obj):
                    if i > 0:
                        self.stream.write(u",")
                        self.__indent_line()
                    self.serialize(value)

            self.depth -= 1
            self.stream.write(u"]")
        else:
            raise Exception("can't serialize %s as JSON" % obj)


def to_stream(obj, stream, pretty=False, sort_keys=True):
    _Serializer(stream, pretty, sort_keys).serialize(obj)


def to_file(obj, name, pretty=False, sort_keys=True):
    stream = open(name, "w")
    try:
        to_stream(obj, stream, pretty, sort_keys)
    finally:
        stream.close()


def to_string(obj, pretty=False, sort_keys=True):
    output = StringIO.StringIO()
    to_stream(obj, output, pretty, sort_keys)
    s = output.getvalue()
    output.close()
    return s


def from_stream(stream):
    p = Parser(check_trailer=True)
    while True:
        buf = stream.read(4096)
        if buf == "" or p.feed(buf) != len(buf):
            break
    return p.finish()


def from_file(name):
    stream = open(name, "r")
    try:
        return from_stream(stream)
    finally:
        stream.close()


def from_string(s):
    try:
        s = unicode(s, 'utf-8')
    except UnicodeDecodeError, e:
        seq = ' '.join(["0x%2x" % ord(c)
                        for c in e.object[e.start:e.end] if ord(c) >= 0x80])
        return ("not a valid UTF-8 string: invalid UTF-8 sequence %s" % seq)
    p = Parser(check_trailer=True)
    p.feed(s)
    return p.finish()


class Parser(object):
    ## Maximum height of parsing stack. ##
    MAX_HEIGHT = 1000

    def __init__(self, check_trailer=False):
        self.check_trailer = check_trailer

        # Lexical analysis.
        self.lex_state = Parser.__lex_start
        self.buffer = ""
        self.line_number = 0
        self.column_number = 0
        self.byte_number = 0

        # Parsing.
        self.parse_state = Parser.__parse_start
        self.stack = []
        self.member_name = None

        # Parse status.
        self.done = False
        self.error = None

    def __lex_start_space(self, c):
        pass

    def __lex_start_alpha(self, c):
        self.buffer = c
        self.lex_state = Parser.__lex_keyword

    def __lex_start_token(self, c):
        self.__parser_input(c)

    def __lex_start_number(self, c):
        self.buffer = c
        self.lex_state = Parser.__lex_number

    def __lex_start_string(self, _):
        self.lex_state = Parser.__lex_string

    def __lex_start_error(self, c):
        if ord(c) >= 32 and ord(c) < 128:
            self.__error("invalid character '%s'" % c)
        else:
            self.__error("invalid character U+%04x" % ord(c))

    __lex_start_actions = {}
    for c in " \t\n\r":
        __lex_start_actions[c] = __lex_start_space
    for c in "abcdefghijklmnopqrstuvwxyz":
        __lex_start_actions[c] = __lex_start_alpha
    for c in "[{]}:,":
        __lex_start_actions[c] = __lex_start_token
    for c in "-0123456789":
        __lex_start_actions[c] = __lex_start_number
    __lex_start_actions['"'] = __lex_start_string

    def __lex_start(self, c):
        Parser.__lex_start_actions.get(
            c, Parser.__lex_start_error)(self, c)
        return True

    __lex_alpha = {}
    for c in "abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ":
        __lex_alpha[c] = True

    def __lex_finish_keyword(self):
        if self.buffer == "false":
            self.__parser_input(False)
        elif self.buffer == "true":
            self.__parser_input(True)
        elif self.buffer == "null":
            self.__parser_input(None)
        else:
            self.__error("invalid keyword '%s'" % self.buffer)

    def __lex_keyword(self, c):
        if c in Parser.__lex_alpha:
            self.buffer += c
            return True
        else:
            self.__lex_finish_keyword()
            return False

    __number_re = re.compile("(-)?(0|[1-9][0-9]*)"
            "(?:\.([0-9]+))?(?:[eE]([-+]?[0-9]+))?$")

    def __lex_finish_number(self):
        s = self.buffer
        m = Parser.__number_re.match(s)
        if m:
            sign, integer, fraction, exp = m.groups()
            if (exp is not None and
                (long(exp) > sys.maxint or long(exp) < -sys.maxint - 1)):
                self.__error("exponent outside valid range")
                return

            if fraction is not None and len(fraction.lstrip('0')) == 0:
                fraction = None

            sig_string = integer
            if fraction is not None:
                sig_string += fraction
            significand = int(sig_string)

            pow10 = 0
            if fraction is not None:
                pow10 -= len(fraction)
            if exp is not None:
                pow10 += long(exp)

            if significand == 0:
                self.__parser_input(0)
                return
            elif significand <= 2 ** 63:
                while pow10 > 0 and significand <= 2 ** 63:
                    significand *= 10
                    pow10 -= 1
                while pow10 < 0 and significand % 10 == 0:
                    significand /= 10
                    pow10 += 1
                if (pow10 == 0 and
                    ((not sign and significand < 2 ** 63) or
                     (sign and significand <= 2 ** 63))):
                    if sign:
                        self.__parser_input(-significand)
                    else:
                        self.__parser_input(significand)
                    return

            value = float(s)
            if value == float("inf") or value == float("-inf"):
                self.__error("number outside valid range")
                return
            if value == 0:
                # Suppress negative zero.
                value = 0
            self.__parser_input(value)
        elif re.match("-?0[0-9]", s):
            self.__error("leading zeros not allowed")
        elif re.match("-([^0-9]|$)", s):
            self.__error("'-' must be followed by digit")
        elif re.match("-?(0|[1-9][0-9]*)\.([^0-9]|$)", s):
            self.__error("decimal point must be followed by digit")
        elif re.search("e[-+]?([^0-9]|$)", s):
            self.__error("exponent must contain at least one digit")
        else:
            self.__error("syntax error in number")

    def __lex_number(self, c):
        if c in ".0123456789eE-+":
            self.buffer += c
            return True
        else:
            self.__lex_finish_number()
            return False

    __4hex_re = re.compile("[0-9a-fA-F]{4}")

    def __lex_4hex(self, s):
        if len(s) < 4:
            self.__error("quoted string ends within \\u escape")
        elif not Parser.__4hex_re.match(s):
            self.__error("malformed \\u escape")
        elif s == "0000":
            self.__error("null bytes not supported in quoted strings")
        else:
            return int(s, 16)

    @staticmethod
    def __is_leading_surrogate(c):
        """Returns true if 'c' is a Unicode code point for a leading
        surrogate."""
        return c >= 0xd800 and c <= 0xdbff

    @staticmethod
    def __is_trailing_surrogate(c):
        """Returns true if 'c' is a Unicode code point for a trailing
        surrogate."""
        return c >= 0xdc00 and c <= 0xdfff

    @staticmethod
    def __utf16_decode_surrogate_pair(leading, trailing):
        """Returns the unicode code point corresponding to leading surrogate
        'leading' and trailing surrogate 'trailing'.  The return value will not
        make any sense if 'leading' or 'trailing' are not in the correct ranges
        for leading or trailing surrogates."""
        #  Leading surrogate:         110110wwwwxxxxxx
        # Trailing surrogate:         110111xxxxxxxxxx
        #         Code point: 000uuuuuxxxxxxxxxxxxxxxx
        w = (leading >> 6) & 0xf
        u = w + 1
        x0 = leading & 0x3f
        x1 = trailing & 0x3ff
        return (u << 16) | (x0 << 10) | x1
    __unescape = {'"': u'"',
                  "\\": u"\\",
                  "/": u"/",
                  "b": u"\b",
                  "f": u"\f",
                  "n": u"\n",
                  "r": u"\r",
                  "t": u"\t"}

    def __lex_finish_string(self):
        inp = self.buffer
        out = u""
        while len(inp):
            backslash = inp.find('\\')
            if backslash == -1:
                out += inp
                break
            out += inp[:backslash]
            inp = inp[backslash + 1:]
            if inp == "":
                self.__error("quoted string may not end with backslash")
                return

            replacement = Parser.__unescape.get(inp[0])
            if replacement is not None:
                out += replacement
                inp = inp[1:]
                continue
            elif inp[0] != u'u':
                self.__error("bad escape \\%s" % inp[0])
                return

            c0 = self.__lex_4hex(inp[1:5])
            if c0 is None:
                return
            inp = inp[5:]

            if Parser.__is_leading_surrogate(c0):
                if inp[:2] != u'\\u':
                    self.__error("malformed escaped surrogate pair")
                    return
                c1 = self.__lex_4hex(inp[2:6])
                if c1 is None:
                    return
                if not Parser.__is_trailing_surrogate(c1):
                    self.__error("second half of escaped surrogate pair is "
                                 "not trailing surrogate")
                    return
                code_point = Parser.__utf16_decode_surrogate_pair(c0, c1)
                inp = inp[6:]
            else:
                code_point = c0
            out += unichr(code_point)
        self.__parser_input('string', out)

    def __lex_string_escape(self, c):
        self.buffer += c
        self.lex_state = Parser.__lex_string
        return True

    def __lex_string(self, c):
        if c == '\\':
            self.buffer += c
            self.lex_state = Parser.__lex_string_escape
        elif c == '"':
            self.__lex_finish_string()
        elif ord(c) >= 0x20:
            self.buffer += c
        else:
            self.__error("U+%04X must be escaped in quoted string" % ord(c))
        return True

    def __lex_input(self, c):
        eat = self.lex_state(self, c)
        assert eat is True or eat is False
        return eat

    def __parse_start(self, token, unused_string):
        if token == '{':
            self.__push_object()
        elif token == '[':
            self.__push_array()
        else:
            self.__error("syntax error at beginning of input")

    def __parse_end(self, unused_token, unused_string):
        self.__error("trailing garbage at end of input")

    def __parse_object_init(self, token, string):
        if token == '}':
            self.__parser_pop()
        else:
            self.__parse_object_name(token, string)

    def __parse_object_name(self, token, string):
        if token == 'string':
            self.member_name = string
            self.parse_state = Parser.__parse_object_colon
        else:
            self.__error("syntax error parsing object expecting string")

    def __parse_object_colon(self, token, unused_string):
        if token == ":":
            self.parse_state = Parser.__parse_object_value
        else:
            self.__error("syntax error parsing object expecting ':'")

    def __parse_object_value(self, token, string):
        self.__parse_value(token, string, Parser.__parse_object_next)

    def __parse_object_next(self, token, unused_string):
        if token == ",":
            self.parse_state = Parser.__parse_object_name
        elif token == "}":
            self.__parser_pop()
        else:
            self.__error("syntax error expecting '}' or ','")

    def __parse_array_init(self, token, string):
        if token == ']':
            self.__parser_pop()
        else:
            self.__parse_array_value(token, string)

    def __parse_array_value(self, token, string):
        self.__parse_value(token, string, Parser.__parse_array_next)

    def __parse_array_next(self, token, unused_string):
        if token == ",":
            self.parse_state = Parser.__parse_array_value
        elif token == "]":
            self.__parser_pop()
        else:
            self.__error("syntax error expecting ']' or ','")

    def __parser_input(self, token, string=None):
        self.lex_state = Parser.__lex_start
        self.buffer = ""
        self.parse_state(self, token, string)

    def __put_value(self, value):
        top = self.stack[-1]
        if type(top) == dict:
            top[self.member_name] = value
        else:
            top.append(value)

    def __parser_push(self, new_json, next_state):
        if len(self.stack) < Parser.MAX_HEIGHT:
            if len(self.stack) > 0:
                self.__put_value(new_json)
            self.stack.append(new_json)
            self.parse_state = next_state
        else:
            self.__error("input exceeds maximum nesting depth %d" %
                         Parser.MAX_HEIGHT)

    def __push_object(self):
        self.__parser_push({}, Parser.__parse_object_init)

    def __push_array(self):
        self.__parser_push([], Parser.__parse_array_init)

    def __parser_pop(self):
        if len(self.stack) == 1:
            self.parse_state = Parser.__parse_end
            if not self.check_trailer:
                self.done = True
        else:
            self.stack.pop()
            top = self.stack[-1]
            if type(top) == list:
                self.parse_state = Parser.__parse_array_next
            else:
                self.parse_state = Parser.__parse_object_next

    def __parse_value(self, token, string, next_state):
        if token in [False, None, True] or type(token) in [int, long, float]:
            self.__put_value(token)
        elif token == 'string':
            self.__put_value(string)
        else:
            if token == '{':
                self.__push_object()
            elif token == '[':
                self.__push_array()
            else:
                self.__error("syntax error expecting value")
            return
        self.parse_state = next_state

    def __error(self, message):
        if self.error is None:
            self.error = ("line %d, column %d, byte %d: %s"
                          % (self.line_number, self.column_number,
                             self.byte_number, message))
            self.done = True

    def feed(self, s):
        i = 0
        while True:
            if self.done or i >= len(s):
                return i

            c = s[i]
            if self.__lex_input(c):
                self.byte_number += 1
                if c == '\n':
                    self.column_number = 0
                    self.line_number += 1
                else:
                    self.column_number += 1

                i += 1

    def is_done(self):
        return self.done

    def finish(self):
        if self.lex_state == Parser.__lex_start:
            pass
        elif self.lex_state in (Parser.__lex_string,
                                Parser.__lex_string_escape):
            self.__error("unexpected end of input in quoted string")
        else:
            self.__lex_input(" ")

        if self.parse_state == Parser.__parse_start:
            self.__error("empty input stream")
        elif self.parse_state != Parser.__parse_end:
            self.__error("unexpected end of input")

        if self.error == None:
            assert len(self.stack) == 1
            return self.stack.pop()
        else:
            return self.error

########NEW FILE########
__FILENAME__ = jsonrpc
# Copyright (c) 2010, 2011, 2012 Nicira, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at:
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import errno
import os

import ovs.json
import ovs.poller
import ovs.reconnect
import ovs.stream
import ovs.timeval
import ovs.util
import ovs.vlog

EOF = ovs.util.EOF
vlog = ovs.vlog.Vlog("jsonrpc")


class Message(object):
    T_REQUEST = 0               # Request.
    T_NOTIFY = 1                # Notification.
    T_REPLY = 2                 # Successful reply.
    T_ERROR = 3                 # Error reply.

    __types = {T_REQUEST: "request",
               T_NOTIFY: "notification",
               T_REPLY: "reply",
               T_ERROR: "error"}

    def __init__(self, type_, method, params, result, error, id):
        self.type = type_
        self.method = method
        self.params = params
        self.result = result
        self.error = error
        self.id = id

    _next_id = 0

    @staticmethod
    def _create_id():
        this_id = Message._next_id
        Message._next_id += 1
        return this_id

    @staticmethod
    def create_request(method, params):
        return Message(Message.T_REQUEST, method, params, None, None,
                       Message._create_id())

    @staticmethod
    def create_notify(method, params):
        return Message(Message.T_NOTIFY, method, params, None, None,
                       None)

    @staticmethod
    def create_reply(result, id):
        return Message(Message.T_REPLY, None, None, result, None, id)

    @staticmethod
    def create_error(error, id):
        return Message(Message.T_ERROR, None, None, None, error, id)

    @staticmethod
    def type_to_string(type_):
        return Message.__types[type_]

    def __validate_arg(self, value, name, must_have):
        if (value is not None) == (must_have != 0):
            return None
        else:
            type_name = Message.type_to_string(self.type)
            if must_have:
                verb = "must"
            else:
                verb = "must not"
            return "%s %s have \"%s\"" % (type_name, verb, name)

    def is_valid(self):
        if self.params is not None and type(self.params) != list:
            return "\"params\" must be JSON array"

        pattern = {Message.T_REQUEST: 0x11001,
                   Message.T_NOTIFY:  0x11000,
                   Message.T_REPLY:   0x00101,
                   Message.T_ERROR:   0x00011}.get(self.type)
        if pattern is None:
            return "invalid JSON-RPC message type %s" % self.type

        return (
            self.__validate_arg(self.method, "method", pattern & 0x10000) or
            self.__validate_arg(self.params, "params", pattern & 0x1000) or
            self.__validate_arg(self.result, "result", pattern & 0x100) or
            self.__validate_arg(self.error, "error", pattern & 0x10) or
            self.__validate_arg(self.id, "id", pattern & 0x1))

    @staticmethod
    def from_json(json):
        if type(json) != dict:
            return "message is not a JSON object"

        # Make a copy to avoid modifying the caller's dict.
        json = dict(json)

        if "method" in json:
            method = json.pop("method")
            if type(method) not in [str, unicode]:
                return "method is not a JSON string"
        else:
            method = None

        params = json.pop("params", None)
        result = json.pop("result", None)
        error = json.pop("error", None)
        id_ = json.pop("id", None)
        if len(json):
            return "message has unexpected member \"%s\"" % json.popitem()[0]

        if result is not None:
            msg_type = Message.T_REPLY
        elif error is not None:
            msg_type = Message.T_ERROR
        elif id_ is not None:
            msg_type = Message.T_REQUEST
        else:
            msg_type = Message.T_NOTIFY

        msg = Message(msg_type, method, params, result, error, id_)
        validation_error = msg.is_valid()
        if validation_error is not None:
            return validation_error
        else:
            return msg

    def to_json(self):
        json = {}

        if self.method is not None:
            json["method"] = self.method

        if self.params is not None:
            json["params"] = self.params

        if self.result is not None or self.type == Message.T_ERROR:
            json["result"] = self.result

        if self.error is not None or self.type == Message.T_REPLY:
            json["error"] = self.error

        if self.id is not None or self.type == Message.T_NOTIFY:
            json["id"] = self.id

        return json

    def __str__(self):
        s = [Message.type_to_string(self.type)]
        if self.method is not None:
            s.append("method=\"%s\"" % self.method)
        if self.params is not None:
            s.append("params=" + ovs.json.to_string(self.params))
        if self.result is not None:
            s.append("result=" + ovs.json.to_string(self.result))
        if self.error is not None:
            s.append("error=" + ovs.json.to_string(self.error))
        if self.id is not None:
            s.append("id=" + ovs.json.to_string(self.id))
        return ", ".join(s)


class Connection(object):
    def __init__(self, stream):
        self.name = stream.name
        self.stream = stream
        self.status = 0
        self.input = ""
        self.output = ""
        self.parser = None
        self.received_bytes = 0

    def close(self):
        self.stream.close()
        self.stream = None

    def run(self):
        if self.status:
            return

        while len(self.output):
            retval = self.stream.send(self.output)
            if retval >= 0:
                self.output = self.output[retval:]
            else:
                if retval != -errno.EAGAIN:
                    vlog.warn("%s: send error: %s" %
                              (self.name, os.strerror(-retval)))
                    self.error(-retval)
                break

    def wait(self, poller):
        if not self.status:
            self.stream.run_wait(poller)
            if len(self.output):
                self.stream.send_wait(poller)

    def get_status(self):
        return self.status

    def get_backlog(self):
        if self.status != 0:
            return 0
        else:
            return len(self.output)

    def get_received_bytes(self):
        return self.received_bytes

    def __log_msg(self, title, msg):
        vlog.dbg("%s: %s %s" % (self.name, title, msg))

    def send(self, msg):
        if self.status:
            return self.status

        self.__log_msg("send", msg)

        was_empty = len(self.output) == 0
        self.output += ovs.json.to_string(msg.to_json())
        if was_empty:
            self.run()
        return self.status

    def send_block(self, msg):
        error = self.send(msg)
        if error:
            return error

        while True:
            self.run()
            if not self.get_backlog() or self.get_status():
                return self.status

            poller = ovs.poller.Poller()
            self.wait(poller)
            poller.block()

    def recv(self):
        if self.status:
            return self.status, None

        while True:
            if not self.input:
                error, data = self.stream.recv(4096)
                if error:
                    if error == errno.EAGAIN:
                        return error, None
                    else:
                        # XXX rate-limit
                        vlog.warn("%s: receive error: %s"
                                  % (self.name, os.strerror(error)))
                        self.error(error)
                        return self.status, None
                elif not data:
                    self.error(EOF)
                    return EOF, None
                else:
                    self.input += data
                    self.received_bytes += len(data)
            else:
                if self.parser is None:
                    self.parser = ovs.json.Parser()
                self.input = self.input[self.parser.feed(self.input):]
                if self.parser.is_done():
                    msg = self.__process_msg()
                    if msg:
                        return 0, msg
                    else:
                        return self.status, None

    def recv_block(self):
        while True:
            error, msg = self.recv()
            if error != errno.EAGAIN:
                return error, msg

            self.run()

            poller = ovs.poller.Poller()
            self.wait(poller)
            self.recv_wait(poller)
            poller.block()

    def transact_block(self, request):
        id_ = request.id

        error = self.send(request)
        reply = None
        while not error:
            error, reply = self.recv_block()
            if (reply
                and (reply.type == Message.T_REPLY
                     or reply.type == Message.T_ERROR)
                and reply.id == id_):
                break
        return error, reply

    def __process_msg(self):
        json = self.parser.finish()
        self.parser = None
        if type(json) in [str, unicode]:
            # XXX rate-limit
            vlog.warn("%s: error parsing stream: %s" % (self.name, json))
            self.error(errno.EPROTO)
            return

        msg = Message.from_json(json)
        if not isinstance(msg, Message):
            # XXX rate-limit
            vlog.warn("%s: received bad JSON-RPC message: %s"
                      % (self.name, msg))
            self.error(errno.EPROTO)
            return

        self.__log_msg("received", msg)
        return msg

    def recv_wait(self, poller):
        if self.status or self.input:
            poller.immediate_wake()
        else:
            self.stream.recv_wait(poller)

    def error(self, error):
        if self.status == 0:
            self.status = error
            self.stream.close()
            self.output = ""


class Session(object):
    """A JSON-RPC session with reconnection."""

    def __init__(self, reconnect, rpc):
        self.reconnect = reconnect
        self.rpc = rpc
        self.stream = None
        self.pstream = None
        self.seqno = 0

    @staticmethod
    def open(name):
        """Creates and returns a Session that maintains a JSON-RPC session to
        'name', which should be a string acceptable to ovs.stream.Stream or
        ovs.stream.PassiveStream's initializer.

        If 'name' is an active connection method, e.g. "tcp:127.1.2.3", the new
        session connects and reconnects, with back-off, to 'name'.

        If 'name' is a passive connection method, e.g. "ptcp:", the new session
        listens for connections to 'name'.  It maintains at most one connection
        at any given time.  Any new connection causes the previous one (if any)
        to be dropped."""
        reconnect = ovs.reconnect.Reconnect(ovs.timeval.msec())
        reconnect.set_name(name)
        reconnect.enable(ovs.timeval.msec())

        if ovs.stream.PassiveStream.is_valid_name(name):
            reconnect.set_passive(True, ovs.timeval.msec())

        if ovs.stream.stream_or_pstream_needs_probes(name):
            reconnect.set_probe_interval(0)

        return Session(reconnect, None)

    @staticmethod
    def open_unreliably(jsonrpc):
        reconnect = ovs.reconnect.Reconnect(ovs.timeval.msec())
        reconnect.set_quiet(True)
        reconnect.set_name(jsonrpc.name)
        reconnect.set_max_tries(0)
        reconnect.connected(ovs.timeval.msec())
        return Session(reconnect, jsonrpc)

    def close(self):
        if self.rpc is not None:
            self.rpc.close()
            self.rpc = None
        if self.stream is not None:
            self.stream.close()
            self.stream = None
        if self.pstream is not None:
            self.pstream.close()
            self.pstream = None

    def __disconnect(self):
        if self.rpc is not None:
            self.rpc.error(EOF)
            self.rpc.close()
            self.rpc = None
            self.seqno += 1
        elif self.stream is not None:
            self.stream.close()
            self.stream = None
            self.seqno += 1

    def __connect(self):
        self.__disconnect()

        name = self.reconnect.get_name()
        if not self.reconnect.is_passive():
            error, self.stream = ovs.stream.Stream.open(name)
            if not error:
                self.reconnect.connecting(ovs.timeval.msec())
            else:
                self.reconnect.connect_failed(ovs.timeval.msec(), error)
        elif self.pstream is not None:
            error, self.pstream = ovs.stream.PassiveStream.open(name)
            if not error:
                self.reconnect.listening(ovs.timeval.msec())
            else:
                self.reconnect.connect_failed(ovs.timeval.msec(), error)

        self.seqno += 1

    def run(self):
        if self.pstream is not None:
            error, stream = self.pstream.accept()
            if error == 0:
                if self.rpc or self.stream:
                    # XXX rate-limit
                    vlog.info("%s: new connection replacing active "
                              "connection" % self.reconnect.get_name())
                    self.__disconnect()
                self.reconnect.connected(ovs.timeval.msec())
                self.rpc = Connection(stream)
            elif error != errno.EAGAIN:
                self.reconnect.listen_error(ovs.timeval.msec(), error)
                self.pstream.close()
                self.pstream = None

        if self.rpc:
            backlog = self.rpc.get_backlog()
            self.rpc.run()
            if self.rpc.get_backlog() < backlog:
                # Data previously caught in a queue was successfully sent (or
                # there's an error, which we'll catch below).
                #
                # We don't count data that is successfully sent immediately as
                # activity, because there's a lot of queuing downstream from
                # us, which means that we can push a lot of data into a
                # connection that has stalled and won't ever recover.
                self.reconnect.activity(ovs.timeval.msec())

            error = self.rpc.get_status()
            if error != 0:
                self.reconnect.disconnected(ovs.timeval.msec(), error)
                self.__disconnect()
        elif self.stream is not None:
            self.stream.run()
            error = self.stream.connect()
            if error == 0:
                self.reconnect.connected(ovs.timeval.msec())
                self.rpc = Connection(self.stream)
                self.stream = None
            elif error != errno.EAGAIN:
                self.reconnect.connect_failed(ovs.timeval.msec(), error)
                self.stream.close()
                self.stream = None

        action = self.reconnect.run(ovs.timeval.msec())
        if action == ovs.reconnect.CONNECT:
            self.__connect()
        elif action == ovs.reconnect.DISCONNECT:
            self.reconnect.disconnected(ovs.timeval.msec(), 0)
            self.__disconnect()
        elif action == ovs.reconnect.PROBE:
            if self.rpc:
                request = Message.create_request("echo", [])
                request.id = "echo"
                self.rpc.send(request)
        else:
            assert action == None

    def wait(self, poller):
        if self.rpc is not None:
            self.rpc.wait(poller)
        elif self.stream is not None:
            self.stream.run_wait(poller)
            self.stream.connect_wait(poller)
        if self.pstream is not None:
            self.pstream.wait(poller)
        self.reconnect.wait(poller, ovs.timeval.msec())

    def get_backlog(self):
        if self.rpc is not None:
            return self.rpc.get_backlog()
        else:
            return 0

    def get_name(self):
        return self.reconnect.get_name()

    def send(self, msg):
        if self.rpc is not None:
            return self.rpc.send(msg)
        else:
            return errno.ENOTCONN

    def recv(self):
        if self.rpc is not None:
            received_bytes = self.rpc.get_received_bytes()
            error, msg = self.rpc.recv()
            if received_bytes != self.rpc.get_received_bytes():
                # Data was successfully received.
                #
                # Previously we only counted receiving a full message as
                # activity, but with large messages or a slow connection that
                # policy could time out the session mid-message.
                self.reconnect.activity(ovs.timeval.msec())

            if not error:
                if msg.type == Message.T_REQUEST and msg.method == "echo":
                    # Echo request.  Send reply.
                    self.send(Message.create_reply(msg.params, msg.id))
                elif msg.type == Message.T_REPLY and msg.id == "echo":
                    # It's a reply to our echo request.  Suppress it.
                    pass
                else:
                    return msg
        return None

    def recv_wait(self, poller):
        if self.rpc is not None:
            self.rpc.recv_wait(poller)

    def is_alive(self):
        if self.rpc is not None or self.stream is not None:
            return True
        else:
            max_tries = self.reconnect.get_max_tries()
            return max_tries is None or max_tries > 0

    def is_connected(self):
        return self.rpc is not None

    def get_seqno(self):
        return self.seqno

    def force_reconnect(self):
        self.reconnect.force_reconnect(ovs.timeval.msec())

########NEW FILE########
__FILENAME__ = ovsuuid
# Copyright (c) 2009, 2010, 2011 Nicira, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at:
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import re
import uuid

from ovs.db import error
import ovs.db.parser

uuidRE = re.compile("^xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx$"
                    .replace('x', '[0-9a-fA-F]'))


def zero():
    return uuid.UUID(int=0)


def is_valid_string(s):
    return uuidRE.match(s) is not None


def from_string(s):
    if not is_valid_string(s):
        raise error.Error("%s is not a valid UUID" % s)
    return uuid.UUID(s)


def from_json(json, symtab=None):
    try:
        s = ovs.db.parser.unwrap_json(json, "uuid", [str, unicode], "string")
        if not uuidRE.match(s):
            raise error.Error("\"%s\" is not a valid UUID" % s, json)
        return uuid.UUID(s)
    except error.Error, e:
        if not symtab:
            raise e
        try:
            name = ovs.db.parser.unwrap_json(json, "named-uuid",
                                             [str, unicode], "string")
        except error.Error:
            raise e

        if name not in symtab:
            symtab[name] = uuid.uuid4()
        return symtab[name]


def to_json(uuid_):
    return ["uuid", str(uuid_)]


def to_c_assignment(uuid_, var):
    """Returns an array of strings, each of which contain a C statement.  The
    statements assign 'uuid_' to a "struct uuid" as defined in Open vSwitch
    lib/uuid.h."""

    hex_string = uuid_.hex
    return ["%s.parts[%d] = 0x%s;" % (var, x, hex_string[x * 8:(x + 1) * 8])
            for x in range(4)]

########NEW FILE########
__FILENAME__ = poller
# Copyright (c) 2010 Nicira, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at:
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import errno
import ovs.timeval
import ovs.vlog
import select
import socket

try:
    import eventlet.patcher

    def _using_eventlet_green_select():
        return eventlet.patcher.is_monkey_patched(select)
except:
    def _using_eventlet_green_select():
        return False

vlog = ovs.vlog.Vlog("poller")

POLLIN = 0x001
POLLOUT = 0x004
POLLERR = 0x008
POLLHUP = 0x010
POLLNVAL = 0x020

# eventlet/gevent doesn't support select.poll. If select.poll is used,
# python interpreter is blocked as a whole instead of switching from the
# current thread that is about to block to other runnable thread.
# So emulate select.poll by select.select because using python means that
# performance isn't so important.
class _SelectSelect(object):
    """ select.poll emulation by using select.select.
    Only register and poll are needed at the moment.
    """
    def __init__(self):
        self.rlist = []
        self.wlist = []
        self.xlist = []

    def register(self, fd, events):
        if isinstance(fd, socket.socket):
            fd = fd.fileno()
        assert isinstance(fd, int)
        if events & POLLIN:
            self.rlist.append(fd)
            events &= ~POLLIN
        if events & POLLOUT:
            self.wlist.append(fd)
            events &= ~POLLOUT
        if events:
            self.xlist.append(fd)

    def poll(self, timeout):
        if timeout == -1:
            # epoll uses -1 for infinite timeout, select uses None.
            timeout = None
        else:
            timeout = float(timeout) / 1000
        # XXX workaround a bug in eventlet
        # see https://github.com/eventlet/eventlet/pull/25
        if timeout == 0 and _using_eventlet_green_select():
            timeout = 0.1

        rlist, wlist, xlist = select.select(self.rlist, self.wlist, self.xlist,
                                            timeout)
        # collections.defaultdict is introduced by python 2.5 and
        # XenServer uses python 2.4. We don't use it for XenServer.
        # events_dict = collections.defaultdict(int)
        # events_dict[fd] |= event
        events_dict = {}
        for fd in rlist:
            events_dict[fd] = events_dict.get(fd, 0) | POLLIN
        for fd in wlist:
            events_dict[fd] = events_dict.get(fd, 0) | POLLOUT
        for fd in xlist:
            events_dict[fd] = events_dict.get(fd, 0) | (POLLERR |
                                                        POLLHUP |
                                                        POLLNVAL)
        return events_dict.items()


SelectPoll = _SelectSelect
# If eventlet/gevent isn't used, we can use select.poll by replacing
# _SelectPoll with select.poll class
# _SelectPoll = select.poll


class Poller(object):
    """High-level wrapper around the "poll" system call.

    Intended usage is for the program's main loop to go about its business
    servicing whatever events it needs to.  Then, when it runs out of immediate
    tasks, it calls each subordinate module or object's "wait" function, which
    in turn calls one (or more) of the functions Poller.fd_wait(),
    Poller.immediate_wake(), and Poller.timer_wait() to register to be awakened
    when the appropriate event occurs.  Then the main loop calls
    Poller.block(), which blocks until one of the registered events happens."""

    def __init__(self):
        self.__reset()

    def fd_wait(self, fd, events):
        """Registers 'fd' as waiting for the specified 'events' (which should
        be select.POLLIN or select.POLLOUT or their bitwise-OR).  The following
        call to self.block() will wake up when 'fd' becomes ready for one or
        more of the requested events.

        The event registration is one-shot: only the following call to
        self.block() is affected.  The event will need to be re-registered
        after self.block() is called if it is to persist.

        'fd' may be an integer file descriptor or an object with a fileno()
        method that returns an integer file descriptor."""
        self.poll.register(fd, events)

    def __timer_wait(self, msec):
        if self.timeout < 0 or msec < self.timeout:
            self.timeout = msec

    def timer_wait(self, msec):
        """Causes the following call to self.block() to block for no more than
        'msec' milliseconds.  If 'msec' is nonpositive, the following call to
        self.block() will not block at all.

        The timer registration is one-shot: only the following call to
        self.block() is affected.  The timer will need to be re-registered
        after self.block() is called if it is to persist."""
        if msec <= 0:
            self.immediate_wake()
        else:
            self.__timer_wait(msec)

    def timer_wait_until(self, msec):
        """Causes the following call to self.block() to wake up when the
        current time, as returned by ovs.timeval.msec(), reaches 'msec' or
        later.  If 'msec' is earlier than the current time, the following call
        to self.block() will not block at all.

        The timer registration is one-shot: only the following call to
        self.block() is affected.  The timer will need to be re-registered
        after self.block() is called if it is to persist."""
        now = ovs.timeval.msec()
        if msec <= now:
            self.immediate_wake()
        else:
            self.__timer_wait(msec - now)

    def immediate_wake(self):
        """Causes the following call to self.block() to wake up immediately,
        without blocking."""
        self.timeout = 0

    def block(self):
        """Blocks until one or more of the events registered with
        self.fd_wait() occurs, or until the minimum duration registered with
        self.timer_wait() elapses, or not at all if self.immediate_wake() has
        been called."""
        try:
            try:
                events = self.poll.poll(self.timeout)
                self.__log_wakeup(events)
            except select.error, e:
                # XXX rate-limit
                error, msg = e
                if error != errno.EINTR:
                    vlog.err("poll: %s" % e[1])
        finally:
            self.__reset()

    def __log_wakeup(self, events):
        if not events:
            vlog.dbg("%d-ms timeout" % self.timeout)
        else:
            for fd, revents in events:
                if revents != 0:
                    s = ""
                    if revents & POLLIN:
                        s += "[POLLIN]"
                    if revents & POLLOUT:
                        s += "[POLLOUT]"
                    if revents & POLLERR:
                        s += "[POLLERR]"
                    if revents & POLLHUP:
                        s += "[POLLHUP]"
                    if revents & POLLNVAL:
                        s += "[POLLNVAL]"
                    vlog.dbg("%s on fd %d" % (s, fd))

    def __reset(self):
        self.poll = SelectPoll()
        self.timeout = -1

########NEW FILE########
__FILENAME__ = process
# Copyright (c) 2010, 2011 Nicira, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at:
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import os
import signal


def _signal_status_msg(type_, signr):
    s = "%s by signal %d" % (type_, signr)
    for name in signal.__dict__:
        if name.startswith("SIG") and getattr(signal, name) == signr:
            return "%s (%s)" % (s, name)
    return s


def status_msg(status):
    """Given 'status', which is a process status in the form reported by
    waitpid(2) and returned by process_status(), returns a string describing
    how the process terminated."""
    if os.WIFEXITED(status):
        s = "exit status %d" % os.WEXITSTATUS(status)
    elif os.WIFSIGNALED(status):
        s = _signal_status_msg("killed", os.WTERMSIG(status))
    elif os.WIFSTOPPED(status):
        s = _signal_status_msg("stopped", os.WSTOPSIG(status))
    else:
        s = "terminated abnormally (%x)" % status
    if os.WCOREDUMP(status):
        s += ", core dumped"
    return s

########NEW FILE########
__FILENAME__ = reconnect
# Copyright (c) 2010, 2011, 2012 Nicira, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at:
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import os

import ovs.vlog
import ovs.util

# Values returned by Reconnect.run()
CONNECT = 'connect'
DISCONNECT = 'disconnect'
PROBE = 'probe'

EOF = ovs.util.EOF
vlog = ovs.vlog.Vlog("reconnect")


class Reconnect(object):
    """A finite-state machine for connecting and reconnecting to a network
    resource with exponential backoff.  It also provides optional support for
    detecting a connection on which the peer is no longer responding.

    The library does not implement anything networking related, only an FSM for
    networking code to use.

    Many Reconnect methods take a "now" argument.  This makes testing easier
    since there is no hidden state.  When not testing, just pass the return
    value of ovs.time.msec().  (Perhaps this design should be revisited
    later.)"""

    class Void(object):
        name = "VOID"
        is_connected = False

        @staticmethod
        def deadline(fsm):
            return None

        @staticmethod
        def run(fsm, now):
            return None

    class Listening(object):
        name = "LISTENING"
        is_connected = False

        @staticmethod
        def deadline(fsm):
            return None

        @staticmethod
        def run(fsm, now):
            return None

    class Backoff(object):
        name = "BACKOFF"
        is_connected = False

        @staticmethod
        def deadline(fsm):
            return fsm.state_entered + fsm.backoff

        @staticmethod
        def run(fsm, now):
            return CONNECT

    class ConnectInProgress(object):
        name = "CONNECTING"
        is_connected = False

        @staticmethod
        def deadline(fsm):
            return fsm.state_entered + max(1000, fsm.backoff)

        @staticmethod
        def run(fsm, now):
            return DISCONNECT

    class Active(object):
        name = "ACTIVE"
        is_connected = True

        @staticmethod
        def deadline(fsm):
            if fsm.probe_interval:
                base = max(fsm.last_activity, fsm.state_entered)
                return base + fsm.probe_interval
            return None

        @staticmethod
        def run(fsm, now):
            vlog.dbg("%s: idle %d ms, sending inactivity probe"
                     % (fsm.name,
                        now - max(fsm.last_activity, fsm.state_entered)))
            fsm._transition(now, Reconnect.Idle)
            return PROBE

    class Idle(object):
        name = "IDLE"
        is_connected = True

        @staticmethod
        def deadline(fsm):
            if fsm.probe_interval:
                return fsm.state_entered + fsm.probe_interval
            return None

        @staticmethod
        def run(fsm, now):
            vlog.err("%s: no response to inactivity probe after %.3g "
                     "seconds, disconnecting"
                      % (fsm.name, (now - fsm.state_entered) / 1000.0))
            return DISCONNECT

    class Reconnect(object):
        name = "RECONNECT"
        is_connected = False

        @staticmethod
        def deadline(fsm):
            return fsm.state_entered

        @staticmethod
        def run(fsm, now):
            return DISCONNECT

    def __init__(self, now):
        """Creates and returns a new reconnect FSM with default settings.  The
        FSM is initially disabled.  The caller will likely want to call
        self.enable() and self.set_name() on the returned object."""

        self.name = "void"
        self.min_backoff = 1000
        self.max_backoff = 8000
        self.probe_interval = 5000
        self.passive = False
        self.info_level = vlog.info

        self.state = Reconnect.Void
        self.state_entered = now
        self.backoff = 0
        self.last_activity = now
        self.last_connected = None
        self.last_disconnected = None
        self.max_tries = None

        self.creation_time = now
        self.n_attempted_connections = 0
        self.n_successful_connections = 0
        self.total_connected_duration = 0
        self.seqno = 0

    def set_quiet(self, quiet):
        """If 'quiet' is true, this object will log informational messages at
        debug level, by default keeping them out of log files.  This is
        appropriate if the connection is one that is expected to be
        short-lived, so that the log messages are merely distracting.

        If 'quiet' is false, this object logs informational messages at info
        level.  This is the default.

        This setting has no effect on the log level of debugging, warning, or
        error messages."""
        if quiet:
            self.info_level = vlog.dbg
        else:
            self.info_level = vlog.info

    def get_name(self):
        return self.name

    def set_name(self, name):
        """Sets this object's name to 'name'.  If 'name' is None, then "void"
        is used instead.

        The name is used in log messages."""
        if name is None:
            self.name = "void"
        else:
            self.name = name

    def get_min_backoff(self):
        """Return the minimum number of milliseconds to back off between
        consecutive connection attempts.  The default is 1000 ms."""
        return self.min_backoff

    def get_max_backoff(self):
        """Return the maximum number of milliseconds to back off between
        consecutive connection attempts.  The default is 8000 ms."""
        return self.max_backoff

    def get_probe_interval(self):
        """Returns the "probe interval" in milliseconds.  If this is zero, it
        disables the connection keepalive feature.  If it is nonzero, then if
        the interval passes while the FSM is connected and without
        self.activity() being called, self.run() returns ovs.reconnect.PROBE.
        If the interval passes again without self.activity() being called,
        self.run() returns ovs.reconnect.DISCONNECT."""
        return self.probe_interval

    def set_max_tries(self, max_tries):
        """Limits the maximum number of times that this object will ask the
        client to try to reconnect to 'max_tries'.  None (the default) means an
        unlimited number of tries.

        After the number of tries has expired, the FSM will disable itself
        instead of backing off and retrying."""
        self.max_tries = max_tries

    def get_max_tries(self):
        """Returns the current remaining number of connection attempts,
        None if the number is unlimited."""
        return self.max_tries

    def set_backoff(self, min_backoff, max_backoff):
        """Configures the backoff parameters for this FSM.  'min_backoff' is
        the minimum number of milliseconds, and 'max_backoff' is the maximum,
        between connection attempts.

        'min_backoff' must be at least 1000, and 'max_backoff' must be greater
        than or equal to 'min_backoff'."""
        self.min_backoff = max(min_backoff, 1000)
        if self.max_backoff:
            self.max_backoff = max(max_backoff, 1000)
        else:
            self.max_backoff = 8000
        if self.min_backoff > self.max_backoff:
            self.max_backoff = self.min_backoff

        if (self.state == Reconnect.Backoff and
            self.backoff > self.max_backoff):
                self.backoff = self.max_backoff

    def set_probe_interval(self, probe_interval):
        """Sets the "probe interval" to 'probe_interval', in milliseconds.  If
        this is zero, it disables the connection keepalive feature.  If it is
        nonzero, then if the interval passes while this FSM is connected and
        without self.activity() being called, self.run() returns
        ovs.reconnect.PROBE.  If the interval passes again without
        self.activity() being called, self.run() returns
        ovs.reconnect.DISCONNECT.

        If 'probe_interval' is nonzero, then it will be forced to a value of at
        least 1000 ms."""
        if probe_interval:
            self.probe_interval = max(1000, probe_interval)
        else:
            self.probe_interval = 0

    def is_passive(self):
        """Returns true if 'fsm' is in passive mode, false if 'fsm' is in
        active mode (the default)."""
        return self.passive

    def set_passive(self, passive, now):
        """Configures this FSM for active or passive mode.  In active mode (the
        default), the FSM is attempting to connect to a remote host.  In
        passive mode, the FSM is listening for connections from a remote
        host."""
        if self.passive != passive:
            self.passive = passive

            if ((passive and self.state in (Reconnect.ConnectInProgress,
                                            Reconnect.Reconnect)) or
                (not passive and self.state == Reconnect.Listening
                 and self.__may_retry())):
                self._transition(now, Reconnect.Backoff)
                self.backoff = 0

    def is_enabled(self):
        """Returns true if this FSM has been enabled with self.enable().
        Calling another function that indicates a change in connection state,
        such as self.disconnected() or self.force_reconnect(), will also enable
        a reconnect FSM."""
        return self.state != Reconnect.Void

    def enable(self, now):
        """If this FSM is disabled (the default for newly created FSMs),
        enables it, so that the next call to reconnect_run() for 'fsm' will
        return ovs.reconnect.CONNECT.

        If this FSM is not disabled, this function has no effect."""
        if self.state == Reconnect.Void and self.__may_retry():
            self._transition(now, Reconnect.Backoff)
            self.backoff = 0

    def disable(self, now):
        """Disables this FSM.  Until 'fsm' is enabled again, self.run() will
        always return 0."""
        if self.state != Reconnect.Void:
            self._transition(now, Reconnect.Void)

    def force_reconnect(self, now):
        """If this FSM is enabled and currently connected (or attempting to
        connect), forces self.run() to return ovs.reconnect.DISCONNECT the next
        time it is called, which should cause the client to drop the connection
        (or attempt), back off, and then reconnect."""
        if self.state in (Reconnect.ConnectInProgress,
                          Reconnect.Active,
                          Reconnect.Idle):
            self._transition(now, Reconnect.Reconnect)

    def disconnected(self, now, error):
        """Tell this FSM that the connection dropped or that a connection
        attempt failed.  'error' specifies the reason: a positive value
        represents an errno value, EOF indicates that the connection was closed
        by the peer (e.g. read() returned 0), and 0 indicates no specific
        error.

        The FSM will back off, then reconnect."""
        if self.state not in (Reconnect.Backoff, Reconnect.Void):
            # Report what happened
            if self.state in (Reconnect.Active, Reconnect.Idle):
                if error > 0:
                    vlog.warn("%s: connection dropped (%s)"
                              % (self.name, os.strerror(error)))
                elif error == EOF:
                    self.info_level("%s: connection closed by peer"
                                    % self.name)
                else:
                    self.info_level("%s: connection dropped" % self.name)
            elif self.state == Reconnect.Listening:
                if error > 0:
                    vlog.warn("%s: error listening for connections (%s)"
                              % (self.name, os.strerror(error)))
                else:
                    self.info_level("%s: error listening for connections"
                                    % self.name)
            else:
                if self.passive:
                    type_ = "listen"
                else:
                    type_ = "connection"
                if error > 0:
                    vlog.warn("%s: %s attempt failed (%s)"
                              % (self.name, type_, os.strerror(error)))
                else:
                    self.info_level("%s: %s attempt timed out"
                                    % (self.name, type_))

            if (self.state in (Reconnect.Active, Reconnect.Idle)):
                self.last_disconnected = now

            # Back off
            if (self.state in (Reconnect.Active, Reconnect.Idle) and
                (self.last_activity - self.last_connected >= self.backoff or
                 self.passive)):
                if self.passive:
                    self.backoff = 0
                else:
                    self.backoff = self.min_backoff
            else:
                if self.backoff < self.min_backoff:
                    self.backoff = self.min_backoff
                elif self.backoff >= self.max_backoff / 2:
                    self.backoff = self.max_backoff
                else:
                    self.backoff *= 2

                if self.passive:
                    self.info_level("%s: waiting %.3g seconds before trying "
                                    "to listen again"
                                    % (self.name, self.backoff / 1000.0))
                else:
                    self.info_level("%s: waiting %.3g seconds before reconnect"
                                    % (self.name, self.backoff / 1000.0))

            if self.__may_retry():
                self._transition(now, Reconnect.Backoff)
            else:
                self._transition(now, Reconnect.Void)

    def connecting(self, now):
        """Tell this FSM that a connection or listening attempt is in progress.

        The FSM will start a timer, after which the connection or listening
        attempt will be aborted (by returning ovs.reconnect.DISCONNECT from
        self.run())."""
        if self.state != Reconnect.ConnectInProgress:
            if self.passive:
                self.info_level("%s: listening..." % self.name)
            else:
                self.info_level("%s: connecting..." % self.name)
            self._transition(now, Reconnect.ConnectInProgress)

    def listening(self, now):
        """Tell this FSM that the client is listening for connection attempts.
        This state last indefinitely until the client reports some change.

        The natural progression from this state is for the client to report
        that a connection has been accepted or is in progress of being
        accepted, by calling self.connecting() or self.connected().

        The client may also report that listening failed (e.g. accept()
        returned an unexpected error such as ENOMEM) by calling
        self.listen_error(), in which case the FSM will back off and eventually
        return ovs.reconnect.CONNECT from self.run() to tell the client to try
        listening again."""
        if self.state != Reconnect.Listening:
            self.info_level("%s: listening..." % self.name)
            self._transition(now, Reconnect.Listening)

    def listen_error(self, now, error):
        """Tell this FSM that the client's attempt to accept a connection
        failed (e.g. accept() returned an unexpected error such as ENOMEM).

        If the FSM is currently listening (self.listening() was called), it
        will back off and eventually return ovs.reconnect.CONNECT from
        self.run() to tell the client to try listening again.  If there is an
        active connection, this will be delayed until that connection drops."""
        if self.state == Reconnect.Listening:
            self.disconnected(now, error)

    def connected(self, now):
        """Tell this FSM that the connection was successful.

        The FSM will start the probe interval timer, which is reset by
        self.activity().  If the timer expires, a probe will be sent (by
        returning ovs.reconnect.PROBE from self.run().  If the timer expires
        again without being reset, the connection will be aborted (by returning
        ovs.reconnect.DISCONNECT from self.run()."""
        if not self.state.is_connected:
            self.connecting(now)

            self.info_level("%s: connected" % self.name)
            self._transition(now, Reconnect.Active)
            self.last_connected = now

    def connect_failed(self, now, error):
        """Tell this FSM that the connection attempt failed.

        The FSM will back off and attempt to reconnect."""
        self.connecting(now)
        self.disconnected(now, error)

    def activity(self, now):
        """Tell this FSM that some activity occurred on the connection.  This
        resets the probe interval timer, so that the connection is known not to
        be idle."""
        if self.state != Reconnect.Active:
            self._transition(now, Reconnect.Active)
        self.last_activity = now

    def _transition(self, now, state):
        if self.state == Reconnect.ConnectInProgress:
            self.n_attempted_connections += 1
            if state == Reconnect.Active:
                self.n_successful_connections += 1

        connected_before = self.state.is_connected
        connected_now = state.is_connected
        if connected_before != connected_now:
            if connected_before:
                self.total_connected_duration += now - self.last_connected
            self.seqno += 1

        vlog.dbg("%s: entering %s" % (self.name, state.name))
        self.state = state
        self.state_entered = now

    def run(self, now):
        """Assesses whether any action should be taken on this FSM.  The return
        value is one of:

            - None: The client need not take any action.

            - Active client, ovs.reconnect.CONNECT: The client should start a
              connection attempt and indicate this by calling
              self.connecting().  If the connection attempt has definitely
              succeeded, it should call self.connected().  If the connection
              attempt has definitely failed, it should call
              self.connect_failed().

              The FSM is smart enough to back off correctly after successful
              connections that quickly abort, so it is OK to call
              self.connected() after a low-level successful connection
              (e.g. connect()) even if the connection might soon abort due to a
              failure at a high-level (e.g. SSL negotiation failure).

            - Passive client, ovs.reconnect.CONNECT: The client should try to
              listen for a connection, if it is not already listening.  It
              should call self.listening() if successful, otherwise
              self.connecting() or reconnected_connect_failed() if the attempt
              is in progress or definitely failed, respectively.

              A listening passive client should constantly attempt to accept a
              new connection and report an accepted connection with
              self.connected().

            - ovs.reconnect.DISCONNECT: The client should abort the current
              connection or connection attempt or listen attempt and call
              self.disconnected() or self.connect_failed() to indicate it.

            - ovs.reconnect.PROBE: The client should send some kind of request
              to the peer that will elicit a response, to ensure that the
              connection is indeed in working order.  (This will only be
              returned if the "probe interval" is nonzero--see
              self.set_probe_interval())."""

        deadline = self.state.deadline(self)
        if deadline is not None and now >= deadline:
            return self.state.run(self, now)
        else:
            return None

    def wait(self, poller, now):
        """Causes the next call to poller.block() to wake up when self.run()
        should be called."""
        timeout = self.timeout(now)
        if timeout >= 0:
            poller.timer_wait(timeout)

    def timeout(self, now):
        """Returns the number of milliseconds after which self.run() should be
        called if nothing else notable happens in the meantime, or None if this
        is currently unnecessary."""
        deadline = self.state.deadline(self)
        if deadline is not None:
            remaining = deadline - now
            return max(0, remaining)
        else:
            return None

    def is_connected(self):
        """Returns True if this FSM is currently believed to be connected, that
        is, if self.connected() was called more recently than any call to
        self.connect_failed() or self.disconnected() or self.disable(), and
        False otherwise."""
        return self.state.is_connected

    def get_last_connect_elapsed(self, now):
        """Returns the number of milliseconds since 'fsm' was last connected
        to its peer. Returns None if never connected."""
        if self.last_connected:
            return now - self.last_connected
        else:
            return None

    def get_last_disconnect_elapsed(self, now):
        """Returns the number of milliseconds since 'fsm' was last disconnected
        from its peer. Returns None if never disconnected."""
        if self.last_disconnected:
            return now - self.last_disconnected
        else:
            return None

    def get_stats(self, now):
        class Stats(object):
            pass
        stats = Stats()
        stats.creation_time = self.creation_time
        stats.last_connected = self.last_connected
        stats.last_disconnected = self.last_disconnected
        stats.last_activity = self.last_activity
        stats.backoff = self.backoff
        stats.seqno = self.seqno
        stats.is_connected = self.is_connected()
        stats.msec_since_connect = self.get_last_connect_elapsed(now)
        stats.msec_since_disconnect = self.get_last_disconnect_elapsed(now)
        stats.total_connected_duration = self.total_connected_duration
        if self.is_connected():
            stats.total_connected_duration += (
                    self.get_last_connect_elapsed(now))
        stats.n_attempted_connections = self.n_attempted_connections
        stats.n_successful_connections = self.n_successful_connections
        stats.state = self.state.name
        stats.state_elapsed = now - self.state_entered
        return stats

    def __may_retry(self):
        if self.max_tries is None:
            return True
        elif self.max_tries > 0:
            self.max_tries -= 1
            return True
        else:
            return False

########NEW FILE########
__FILENAME__ = socket_util
# Copyright (c) 2010, 2012 Nicira, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at:
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import errno
import os
import select
import socket
import sys

import ovs.fatal_signal
import ovs.poller
import ovs.vlog

vlog = ovs.vlog.Vlog("socket_util")


def make_unix_socket(style, nonblock, bind_path, connect_path):
    """Creates a Unix domain socket in the given 'style' (either
    socket.SOCK_DGRAM or socket.SOCK_STREAM) that is bound to 'bind_path' (if
    'bind_path' is not None) and connected to 'connect_path' (if 'connect_path'
    is not None).  If 'nonblock' is true, the socket is made non-blocking.

    Returns (error, socket): on success 'error' is 0 and 'socket' is a new
    socket object, on failure 'error' is a positive errno value and 'socket' is
    None."""

    try:
        sock = socket.socket(socket.AF_UNIX, style)
    except socket.error, e:
        return get_exception_errno(e), None

    try:
        if nonblock:
            set_nonblocking(sock)
        if bind_path is not None:
            # Delete bind_path but ignore ENOENT.
            try:
                os.unlink(bind_path)
            except OSError, e:
                if e.errno != errno.ENOENT:
                    return e.errno, None

            ovs.fatal_signal.add_file_to_unlink(bind_path)
            sock.bind(bind_path)

            try:
                if sys.hexversion >= 0x02060000:
                    os.fchmod(sock.fileno(), 0700)
                else:
                    os.chmod("/dev/fd/%d" % sock.fileno(), 0700)
            except OSError, e:
                pass
        if connect_path is not None:
            try:
                sock.connect(connect_path)
            except socket.error, e:
                if get_exception_errno(e) != errno.EINPROGRESS:
                    raise
        return 0, sock
    except socket.error, e:
        sock.close()
        if bind_path is not None:
            ovs.fatal_signal.unlink_file_now(bind_path)
        return get_exception_errno(e), None


def check_connection_completion(sock):
    p = ovs.poller.SelectPoll()
    p.register(sock, ovs.poller.POLLOUT)
    if len(p.poll(0)) == 1:
        return get_socket_error(sock)
    else:
        return errno.EAGAIN


def inet_parse_active(target, default_port):
    address = target.split(":")
    host_name = address[0]
    if not host_name:
        raise ValueError("%s: bad peer name format" % target)
    if len(address) >= 2:
        port = int(address[1])
    elif default_port:
        port = default_port
    else:
        raise ValueError("%s: port number must be specified" % target)
    return (host_name, port)


def inet_open_active(style, target, default_port, dscp):
    address = inet_parse_active(target, default_port)
    try:
        sock = socket.socket(socket.AF_INET, style, 0)
    except socket.error, e:
        return get_exception_errno(e), None

    try:
        set_nonblocking(sock)
        set_dscp(sock, dscp)
        try:
            sock.connect(address)
        except socket.error, e:
            if get_exception_errno(e) != errno.EINPROGRESS:
                raise
        return 0, sock
    except socket.error, e:
        sock.close()
        return get_exception_errno(e), None


def get_socket_error(sock):
    """Returns the errno value associated with 'socket' (0 if no error) and
    resets the socket's error status."""
    return sock.getsockopt(socket.SOL_SOCKET, socket.SO_ERROR)


def get_exception_errno(e):
    """A lot of methods on Python socket objects raise socket.error, but that
    exception is documented as having two completely different forms of
    arguments: either a string or a (errno, string) tuple.  We only want the
    errno."""
    if type(e.args) == tuple:
        return e.args[0]
    else:
        return errno.EPROTO


null_fd = -1


def get_null_fd():
    """Returns a readable and writable fd for /dev/null, if successful,
    otherwise a negative errno value.  The caller must not close the returned
    fd (because the same fd will be handed out to subsequent callers)."""
    global null_fd
    if null_fd < 0:
        try:
            null_fd = os.open("/dev/null", os.O_RDWR)
        except OSError, e:
            vlog.err("could not open /dev/null: %s" % os.strerror(e.errno))
            return -e.errno
    return null_fd


def write_fully(fd, buf):
    """Returns an (error, bytes_written) tuple where 'error' is 0 on success,
    otherwise a positive errno value, and 'bytes_written' is the number of
    bytes that were written before the error occurred.  'error' is 0 if and
    only if 'bytes_written' is len(buf)."""
    bytes_written = 0
    if len(buf) == 0:
        return 0, 0
    while True:
        try:
            retval = os.write(fd, buf)
            assert retval >= 0
            if retval == len(buf):
                return 0, bytes_written + len(buf)
            elif retval == 0:
                vlog.warn("write returned 0")
                return errno.EPROTO, bytes_written
            else:
                bytes_written += retval
                buf = buf[:retval]
        except OSError, e:
            return e.errno, bytes_written


def set_nonblocking(sock):
    try:
        sock.setblocking(0)
    except socket.error, e:
        vlog.err("could not set nonblocking mode on socket: %s"
                 % os.strerror(get_socket_error(e)))


def set_dscp(sock, dscp):
    if dscp > 63:
        raise ValueError("Invalid dscp %d" % dscp)
    val = dscp << 2
    sock.setsockopt(socket.IPPROTO_IP, socket.IP_TOS, val)

########NEW FILE########
__FILENAME__ = stream
# Copyright (c) 2010, 2011, 2012 Nicira, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at:
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import errno
import os
import socket

import ovs.poller
import ovs.socket_util
import ovs.vlog

vlog = ovs.vlog.Vlog("stream")


def stream_or_pstream_needs_probes(name):
    """ 1 if the stream or pstream specified by 'name' needs periodic probes to
    verify connectivity.  For [p]streams which need probes, it can take a long
    time to notice the connection was dropped.  Returns 0 if probes aren't
    needed, and -1 if 'name' is invalid"""

    if PassiveStream.is_valid_name(name) or Stream.is_valid_name(name):
        # Only unix and punix are supported currently.
        return 0
    else:
        return -1


class Stream(object):
    """Bidirectional byte stream.  Currently only Unix domain sockets
    are implemented."""

    # States.
    __S_CONNECTING = 0
    __S_CONNECTED = 1
    __S_DISCONNECTED = 2

    # Kinds of events that one might wait for.
    W_CONNECT = 0               # Connect complete (success or failure).
    W_RECV = 1                  # Data received.
    W_SEND = 2                  # Send buffer room available.

    _SOCKET_METHODS = {}

    @staticmethod
    def register_method(method, cls):
        Stream._SOCKET_METHODS[method + ":"] = cls

    @staticmethod
    def _find_method(name):
        for method, cls in Stream._SOCKET_METHODS.items():
            if name.startswith(method):
                return cls
        return None

    @staticmethod
    def is_valid_name(name):
        """Returns True if 'name' is a stream name in the form "TYPE:ARGS" and
        TYPE is a supported stream type (currently only "unix:" and "tcp:"),
        otherwise False."""
        return bool(Stream._find_method(name))

    def __init__(self, socket, name, status):
        self.socket = socket
        self.name = name
        if status == errno.EAGAIN:
            self.state = Stream.__S_CONNECTING
        elif status == 0:
            self.state = Stream.__S_CONNECTED
        else:
            self.state = Stream.__S_DISCONNECTED

        self.error = 0

    # Default value of dscp bits for connection between controller and manager.
    # Value of IPTOS_PREC_INTERNETCONTROL = 0xc0 which is defined
    # in <netinet/ip.h> is used.
    IPTOS_PREC_INTERNETCONTROL = 0xc0
    DSCP_DEFAULT = IPTOS_PREC_INTERNETCONTROL >> 2

    @staticmethod
    def open(name, dscp=DSCP_DEFAULT):
        """Attempts to connect a stream to a remote peer.  'name' is a
        connection name in the form "TYPE:ARGS", where TYPE is an active stream
        class's name and ARGS are stream class-specific.  Currently the only
        supported TYPEs are "unix" and "tcp".

        Returns (error, stream): on success 'error' is 0 and 'stream' is the
        new Stream, on failure 'error' is a positive errno value and 'stream'
        is None.

        Never returns errno.EAGAIN or errno.EINPROGRESS.  Instead, returns 0
        and a new Stream.  The connect() method can be used to check for
        successful connection completion."""
        cls = Stream._find_method(name)
        if not cls:
            return errno.EAFNOSUPPORT, None

        suffix = name.split(":", 1)[1]
        error, sock = cls._open(suffix, dscp)
        if error:
            return error, None
        else:
            status = ovs.socket_util.check_connection_completion(sock)
            return 0, Stream(sock, name, status)

    @staticmethod
    def _open(suffix, dscp):
        raise NotImplementedError("This method must be overrided by subclass")

    @staticmethod
    def open_block((error, stream)):
        """Blocks until a Stream completes its connection attempt, either
        succeeding or failing.  (error, stream) should be the tuple returned by
        Stream.open().  Returns a tuple of the same form.

        Typical usage:
        error, stream = Stream.open_block(Stream.open("unix:/tmp/socket"))"""

        if not error:
            while True:
                error = stream.connect()
                if error != errno.EAGAIN:
                    break
                stream.run()
                poller = ovs.poller.Poller()
                stream.run_wait(poller)
                stream.connect_wait(poller)
                poller.block()
            assert error != errno.EINPROGRESS

        if error and stream:
            stream.close()
            stream = None
        return error, stream

    def close(self):
        self.socket.close()

    def __scs_connecting(self):
        retval = ovs.socket_util.check_connection_completion(self.socket)
        assert retval != errno.EINPROGRESS
        if retval == 0:
            self.state = Stream.__S_CONNECTED
        elif retval != errno.EAGAIN:
            self.state = Stream.__S_DISCONNECTED
            self.error = retval

    def connect(self):
        """Tries to complete the connection on this stream.  If the connection
        is complete, returns 0 if the connection was successful or a positive
        errno value if it failed.  If the connection is still in progress,
        returns errno.EAGAIN."""

        if self.state == Stream.__S_CONNECTING:
            self.__scs_connecting()

        if self.state == Stream.__S_CONNECTING:
            return errno.EAGAIN
        elif self.state == Stream.__S_CONNECTED:
            return 0
        else:
            assert self.state == Stream.__S_DISCONNECTED
            return self.error

    def recv(self, n):
        """Tries to receive up to 'n' bytes from this stream.  Returns a
        (error, string) tuple:

            - If successful, 'error' is zero and 'string' contains between 1
              and 'n' bytes of data.

            - On error, 'error' is a positive errno value.

            - If the connection has been closed in the normal fashion or if 'n'
              is 0, the tuple is (0, "").

        The recv function will not block waiting for data to arrive.  If no
        data have been received, it returns (errno.EAGAIN, "") immediately."""

        retval = self.connect()
        if retval != 0:
            return (retval, "")
        elif n == 0:
            return (0, "")

        try:
            return (0, self.socket.recv(n))
        except socket.error, e:
            return (ovs.socket_util.get_exception_errno(e), "")

    def send(self, buf):
        """Tries to send 'buf' on this stream.

        If successful, returns the number of bytes sent, between 1 and
        len(buf).  0 is only a valid return value if len(buf) is 0.

        On error, returns a negative errno value.

        Will not block.  If no bytes can be immediately accepted for
        transmission, returns -errno.EAGAIN immediately."""

        retval = self.connect()
        if retval != 0:
            return -retval
        elif len(buf) == 0:
            return 0

        try:
            return self.socket.send(buf)
        except socket.error, e:
            return -ovs.socket_util.get_exception_errno(e)

    def run(self):
        pass

    def run_wait(self, poller):
        pass

    def wait(self, poller, wait):
        assert wait in (Stream.W_CONNECT, Stream.W_RECV, Stream.W_SEND)

        if self.state == Stream.__S_DISCONNECTED:
            poller.immediate_wake()
            return

        if self.state == Stream.__S_CONNECTING:
            wait = Stream.W_CONNECT
        if wait == Stream.W_RECV:
            poller.fd_wait(self.socket, ovs.poller.POLLIN)
        else:
            poller.fd_wait(self.socket, ovs.poller.POLLOUT)

    def connect_wait(self, poller):
        self.wait(poller, Stream.W_CONNECT)

    def recv_wait(self, poller):
        self.wait(poller, Stream.W_RECV)

    def send_wait(self, poller):
        self.wait(poller, Stream.W_SEND)

    def __del__(self):
        # Don't delete the file: we might have forked.
        self.socket.close()


class PassiveStream(object):
    @staticmethod
    def is_valid_name(name):
        """Returns True if 'name' is a passive stream name in the form
        "TYPE:ARGS" and TYPE is a supported passive stream type (currently only
        "punix:"), otherwise False."""
        return name.startswith("punix:")

    def __init__(self, sock, name, bind_path):
        self.name = name
        self.socket = sock
        self.bind_path = bind_path

    @staticmethod
    def open(name):
        """Attempts to start listening for remote stream connections.  'name'
        is a connection name in the form "TYPE:ARGS", where TYPE is an passive
        stream class's name and ARGS are stream class-specific.  Currently the
        only supported TYPE is "punix".

        Returns (error, pstream): on success 'error' is 0 and 'pstream' is the
        new PassiveStream, on failure 'error' is a positive errno value and
        'pstream' is None."""
        if not PassiveStream.is_valid_name(name):
            return errno.EAFNOSUPPORT, None

        bind_path = name[6:]
        error, sock = ovs.socket_util.make_unix_socket(socket.SOCK_STREAM,
                                                       True, bind_path, None)
        if error:
            return error, None

        try:
            sock.listen(10)
        except socket.error, e:
            vlog.err("%s: listen: %s" % (name, os.strerror(e.error)))
            sock.close()
            return e.error, None

        return 0, PassiveStream(sock, name, bind_path)

    def close(self):
        """Closes this PassiveStream."""
        self.socket.close()
        if self.bind_path is not None:
            ovs.fatal_signal.unlink_file_now(self.bind_path)
            self.bind_path = None

    def accept(self):
        """Tries to accept a new connection on this passive stream.  Returns
        (error, stream): if successful, 'error' is 0 and 'stream' is the new
        Stream object, and on failure 'error' is a positive errno value and
        'stream' is None.

        Will not block waiting for a connection.  If no connection is ready to
        be accepted, returns (errno.EAGAIN, None) immediately."""

        while True:
            try:
                sock, addr = self.socket.accept()
                ovs.socket_util.set_nonblocking(sock)
                return 0, Stream(sock, "unix:%s" % addr, 0)
            except socket.error, e:
                error = ovs.socket_util.get_exception_errno(e)
                if error != errno.EAGAIN:
                    # XXX rate-limit
                    vlog.dbg("accept: %s" % os.strerror(error))
                return error, None

    def wait(self, poller):
        poller.fd_wait(self.socket, ovs.poller.POLLIN)

    def __del__(self):
        # Don't delete the file: we might have forked.
        self.socket.close()


def usage(name):
    return """
Active %s connection methods:
  unix:FILE               Unix domain socket named FILE
  tcp:IP:PORT             TCP socket to IP with port no of PORT

Passive %s connection methods:
  punix:FILE              Listen on Unix domain socket FILE""" % (name, name)


class UnixStream(Stream):
    @staticmethod
    def _open(suffix, dscp):
        connect_path = suffix
        return  ovs.socket_util.make_unix_socket(socket.SOCK_STREAM,
                                                 True, None, connect_path)
Stream.register_method("unix", UnixStream)


class TCPStream(Stream):
    @staticmethod
    def _open(suffix, dscp):
        error, sock = ovs.socket_util.inet_open_active(socket.SOCK_STREAM,
                                                       suffix, 0, dscp)
        if not error:
            sock.setsockopt(socket.IPPROTO_TCP, socket.TCP_NODELAY, 1)
        return error, sock
Stream.register_method("tcp", TCPStream)

########NEW FILE########
__FILENAME__ = timeval
# Copyright (c) 2009, 2010 Nicira, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at:
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import time


def msec():
    """Returns the current time, as the amount of time since the epoch, in
    milliseconds, as a float."""
    return time.time() * 1000.0


def postfork():
    # Just a stub for now
    pass

########NEW FILE########
__FILENAME__ = client
# Copyright (c) 2011, 2012 Nicira, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at:
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import copy
import errno
import os
import types

import ovs.jsonrpc
import ovs.stream
import ovs.util


vlog = ovs.vlog.Vlog("unixctl_client")
strtypes = types.StringTypes


class UnixctlClient(object):
    def __init__(self, conn):
        assert isinstance(conn, ovs.jsonrpc.Connection)
        self._conn = conn

    def transact(self, command, argv):
        assert isinstance(command, strtypes)
        assert isinstance(argv, list)
        for arg in argv:
            assert isinstance(arg, strtypes)

        request = ovs.jsonrpc.Message.create_request(command, argv)
        error, reply = self._conn.transact_block(request)

        if error:
            vlog.warn("error communicating with %s: %s"
                      % (self._conn.name, os.strerror(error)))
            return error, None, None

        if reply.error is not None:
            return 0, str(reply.error), None
        else:
            assert reply.result is not None
            return 0, None, str(reply.result)

    def close(self):
        self._conn.close()
        self.conn = None

    @staticmethod
    def create(path):
        assert isinstance(path, str)

        unix = "unix:%s" % ovs.util.abs_file_name(ovs.dirs.RUNDIR, path)
        error, stream = ovs.stream.Stream.open_block(
            ovs.stream.Stream.open(unix))

        if error:
            vlog.warn("failed to connect to %s" % path)
            return error, None

        return 0, UnixctlClient(ovs.jsonrpc.Connection(stream))

########NEW FILE########
__FILENAME__ = server
# Copyright (c) 2012 Nicira, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at:
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import copy
import errno
import os
import types

import ovs.dirs
import ovs.jsonrpc
import ovs.stream
import ovs.unixctl
import ovs.util
import ovs.version
import ovs.vlog

Message = ovs.jsonrpc.Message
vlog = ovs.vlog.Vlog("unixctl_server")
strtypes = types.StringTypes


class UnixctlConnection(object):
    def __init__(self, rpc):
        assert isinstance(rpc, ovs.jsonrpc.Connection)
        self._rpc = rpc
        self._request_id = None

    def run(self):
        self._rpc.run()
        error = self._rpc.get_status()
        if error or self._rpc.get_backlog():
            return error

        for _ in range(10):
            if error or self._request_id:
                break

            error, msg = self._rpc.recv()
            if msg:
                if msg.type == Message.T_REQUEST:
                    self._process_command(msg)
                else:
                    # XXX: rate-limit
                    vlog.warn("%s: received unexpected %s message"
                              % (self._rpc.name,
                                 Message.type_to_string(msg.type)))
                    error = errno.EINVAL

            if not error:
                error = self._rpc.get_status()

        return error

    def reply(self, body):
        self._reply_impl(True, body)

    def reply_error(self, body):
        self._reply_impl(False, body)

    # Called only by unixctl classes.
    def _close(self):
        self._rpc.close()
        self._request_id = None

    def _wait(self, poller):
        self._rpc.wait(poller)
        if not self._rpc.get_backlog():
            self._rpc.recv_wait(poller)

    def _reply_impl(self, success, body):
        assert isinstance(success, bool)
        assert body is None or isinstance(body, strtypes)

        assert self._request_id is not None

        if body is None:
            body = ""

        if body and not body.endswith("\n"):
            body += "\n"

        if success:
            reply = Message.create_reply(body, self._request_id)
        else:
            reply = Message.create_error(body, self._request_id)

        self._rpc.send(reply)
        self._request_id = None

    def _process_command(self, request):
        assert isinstance(request, ovs.jsonrpc.Message)
        assert request.type == ovs.jsonrpc.Message.T_REQUEST

        self._request_id = request.id

        error = None
        params = request.params
        method = request.method
        command = ovs.unixctl.commands.get(method)
        if command is None:
            error = '"%s" is not a valid command' % method
        elif len(params) < command.min_args:
            error = '"%s" command requires at least %d arguments' \
                    % (method, command.min_args)
        elif len(params) > command.max_args:
            error = '"%s" command takes at most %d arguments' \
                    % (method, command.max_args)
        else:
            for param in params:
                if not isinstance(param, strtypes):
                    error = '"%s" command has non-string argument' % method
                    break

            if error is None:
                unicode_params = [unicode(p) for p in params]
                command.callback(self, unicode_params, command.aux)

        if error:
            self.reply_error(error)


def _unixctl_version(conn, unused_argv, version):
    assert isinstance(conn, UnixctlConnection)
    version = "%s (Open vSwitch) %s" % (ovs.util.PROGRAM_NAME, version)
    conn.reply(version)

class UnixctlServer(object):
    def __init__(self, listener):
        assert isinstance(listener, ovs.stream.PassiveStream)
        self._listener = listener
        self._conns = []

    def run(self):
        for _ in range(10):
            error, stream = self._listener.accept()
            if not error:
                rpc = ovs.jsonrpc.Connection(stream)
                self._conns.append(UnixctlConnection(rpc))
            elif error == errno.EAGAIN:
                break
            else:
                # XXX: rate-limit
                vlog.warn("%s: accept failed: %s" % (self._listener.name,
                                                     os.strerror(error)))

        for conn in copy.copy(self._conns):
            error = conn.run()
            if error and error != errno.EAGAIN:
                conn._close()
                self._conns.remove(conn)

    def wait(self, poller):
        self._listener.wait(poller)
        for conn in self._conns:
            conn._wait(poller)

    def close(self):
        for conn in self._conns:
            conn._close()
        self._conns = None

        self._listener.close()
        self._listener = None

    @staticmethod
    def create(path, version=None):
        """Creates a new UnixctlServer which listens on a unixctl socket
        created at 'path'.  If 'path' is None, the default path is chosen.
        'version' contains the version of the server as reported by the unixctl
        version command.  If None, ovs.version.VERSION is used."""

        assert path is None or isinstance(path, strtypes)

        if path is not None:
            path = "punix:%s" % ovs.util.abs_file_name(ovs.dirs.RUNDIR, path)
        else:
            path = "punix:%s/%s.%d.ctl" % (ovs.dirs.RUNDIR,
                                           ovs.util.PROGRAM_NAME, os.getpid())

        if version is None:
            version = ovs.version.VERSION

        error, listener = ovs.stream.PassiveStream.open(path)
        if error:
            ovs.util.ovs_error(error, "could not initialize control socket %s"
                               % path)
            return error, None

        ovs.unixctl.command_register("version", "", 0, 0, _unixctl_version,
                                     version)

        return 0, UnixctlServer(listener)


class UnixctlClient(object):
    def __init__(self, conn):
        assert isinstance(conn, ovs.jsonrpc.Connection)
        self._conn = conn

    def transact(self, command, argv):
        assert isinstance(command, strtypes)
        assert isinstance(argv, list)
        for arg in argv:
            assert isinstance(arg, strtypes)

        request = Message.create_request(command, argv)
        error, reply = self._conn.transact_block(request)

        if error:
            vlog.warn("error communicating with %s: %s"
                      % (self._conn.name, os.strerror(error)))
            return error, None, None

        if reply.error is not None:
            return 0, str(reply.error), None
        else:
            assert reply.result is not None
            return 0, None, str(reply.result)

    def close(self):
        self._conn.close()
        self.conn = None

    @staticmethod
    def create(path):
        assert isinstance(path, str)

        unix = "unix:%s" % ovs.util.abs_file_name(ovs.dirs.RUNDIR, path)
        error, stream = ovs.stream.Stream.open_block(
            ovs.stream.Stream.open(unix))

        if error:
            vlog.warn("failed to connect to %s" % path)
            return error, None

        return 0, UnixctlClient(ovs.jsonrpc.Connection(stream))

########NEW FILE########
__FILENAME__ = util
# Copyright (c) 2010, 2011, 2012 Nicira, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at:
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import os
import os.path
import sys

PROGRAM_NAME = os.path.basename(sys.argv[0])
EOF = -1


def abs_file_name(dir_, file_name):
    """If 'file_name' starts with '/', returns a copy of 'file_name'.
    Otherwise, returns an absolute path to 'file_name' considering it relative
    to 'dir_', which itself must be absolute.  'dir_' may be None or the empty
    string, in which case the current working directory is used.

    Returns None if 'dir_' is None and getcwd() fails.

    This differs from os.path.abspath() in that it will never change the
    meaning of a file name."""
    if file_name.startswith('/'):
        return file_name
    else:
        if dir_ is None or dir_ == "":
            try:
                dir_ = os.getcwd()
            except OSError:
                return None

        if dir_.endswith('/'):
            return dir_ + file_name
        else:
            return "%s/%s" % (dir_, file_name)


def ovs_retval_to_string(retval):
    """Many OVS functions return an int which is one of:
    - 0: no error yet
    - >0: errno value
    - EOF: end of file (not necessarily an error; depends on the function
      called)

    Returns the appropriate human-readable string."""

    if not retval:
        return ""
    if retval > 0:
        return os.strerror(retval)
    if retval == EOF:
        return "End of file"
    return "***unknown return value: %s***" % retval


def ovs_error(err_no, message, vlog=None):
    """Prints 'message' on stderr and emits an ERROR level log message to
    'vlog' if supplied.  If 'err_no' is nonzero, then it is formatted with
    ovs_retval_to_string() and appended to the message inside parentheses.

    'message' should not end with a new-line, because this function will add
    one itself."""

    err_msg = "%s: %s" % (PROGRAM_NAME, message)
    if err_no:
        err_msg += " (%s)" % ovs_retval_to_string(err_no)

    sys.stderr.write("%s\n" % err_msg)
    if vlog:
        vlog.err(err_msg)


def ovs_fatal(*args, **kwargs):
    """Prints 'message' on stderr and emits an ERROR level log message to
    'vlog' if supplied.  If 'err_no' is nonzero, then it is formatted with
    ovs_retval_to_string() and appended to the message inside parentheses.
    Then, terminates with exit code 1 (indicating a failure).

    'message' should not end with a new-line, because this function will add
    one itself."""

    ovs_error(*args, **kwargs)
    sys.exit(1)

########NEW FILE########
__FILENAME__ = version
# Generated automatically -- do not modify!    -*- buffer-read-only: t -*-
VERSION = "1.7.90"

########NEW FILE########
__FILENAME__ = vlog

# Copyright (c) 2011, 2012 Nicira, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at:
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import datetime
import logging
import logging.handlers
import re
import socket
import sys

import ovs.dirs
import ovs.unixctl
import ovs.util

FACILITIES = {"console": "info", "file": "info", "syslog": "info"}
LEVELS = {
    "dbg": logging.DEBUG,
    "info": logging.INFO,
    "warn": logging.WARNING,
    "err": logging.ERROR,
    "emer": logging.CRITICAL,
    "off": logging.CRITICAL
}


def get_level(level_str):
    return LEVELS.get(level_str.lower())


class Vlog:
    __inited = False
    __msg_num = 0
    __mfl = {}  # Module -> facility -> level
    __log_file = None
    __file_handler = None

    def __init__(self, name):
        """Creates a new Vlog object representing a module called 'name'.  The
        created Vlog object will do nothing until the Vlog.init() static method
        is called.  Once called, no more Vlog objects may be created."""

        assert not Vlog.__inited
        self.name = name.lower()
        if name not in Vlog.__mfl:
            Vlog.__mfl[self.name] = FACILITIES.copy()

    def __log(self, level, message, **kwargs):
        if not Vlog.__inited:
            return

        now = datetime.datetime.utcnow().strftime("%Y-%m-%dT%H:%M:%SZ")
        message = ("%s|%s|%s|%s|%s"
                   % (now, Vlog.__msg_num, self.name, level, message))

        level = LEVELS.get(level.lower(), logging.DEBUG)
        Vlog.__msg_num += 1

        for f, f_level in Vlog.__mfl[self.name].iteritems():
            f_level = LEVELS.get(f_level, logging.CRITICAL)
            if level >= f_level:
                logging.getLogger(f).log(level, message, **kwargs)

    def emer(self, message, **kwargs):
        self.__log("EMER", message, **kwargs)

    def err(self, message, **kwargs):
        self.__log("ERR", message, **kwargs)

    def warn(self, message, **kwargs):
        self.__log("WARN", message, **kwargs)

    def info(self, message, **kwargs):
        self.__log("INFO", message, **kwargs)

    def dbg(self, message, **kwargs):
        self.__log("DBG", message, **kwargs)

    def exception(self, message):
        """Logs 'message' at ERR log level.  Includes a backtrace when in
        exception context."""
        self.err(message, exc_info=True)

    @staticmethod
    def init(log_file=None):
        """Intializes the Vlog module.  Causes Vlog to write to 'log_file' if
        not None.  Should be called after all Vlog objects have been created.
        No logging will occur until this function is called."""

        if Vlog.__inited:
            return

        Vlog.__inited = True
        logging.raiseExceptions = False
        Vlog.__log_file = log_file
        for f in FACILITIES:
            logger = logging.getLogger(f)
            logger.setLevel(logging.DEBUG)

            try:
                if f == "console":
                    logger.addHandler(logging.StreamHandler(sys.stderr))
                elif f == "syslog":
                    logger.addHandler(logging.handlers.SysLogHandler(
                        address="/dev/log",
                        facility=logging.handlers.SysLogHandler.LOG_DAEMON))
                elif f == "file" and Vlog.__log_file:
                    Vlog.__file_handler = logging.FileHandler(Vlog.__log_file)
                    logger.addHandler(Vlog.__file_handler)
            except (IOError, socket.error):
                logger.setLevel(logging.CRITICAL)

        ovs.unixctl.command_register("vlog/reopen", "", 0, 0,
                                     Vlog._unixctl_vlog_reopen, None)
        ovs.unixctl.command_register("vlog/set", "spec", 1, sys.maxint,
                                     Vlog._unixctl_vlog_set, None)
        ovs.unixctl.command_register("vlog/list", "", 0, 0,
                                     Vlog._unixctl_vlog_list, None)

    @staticmethod
    def set_level(module, facility, level):
        """ Sets the log level of the 'module'-'facility' tuple to 'level'.
        All three arguments are strings which are interpreted the same as
        arguments to the --verbose flag.  Should be called after all Vlog
        objects have already been created."""

        module = module.lower()
        facility = facility.lower()
        level = level.lower()

        if facility != "any" and facility not in FACILITIES:
            return

        if module != "any" and module not in Vlog.__mfl:
            return

        if level not in LEVELS:
            return

        if module == "any":
            modules = Vlog.__mfl.keys()
        else:
            modules = [module]

        if facility == "any":
            facilities = FACILITIES.keys()
        else:
            facilities = [facility]

        for m in modules:
            for f in facilities:
                Vlog.__mfl[m][f] = level

    @staticmethod
    def set_levels_from_string(s):
        module = None
        level = None
        facility = None

        for word in [w.lower() for w in re.split('[ :]', s)]:
            if word == "any":
                pass
            elif word in FACILITIES:
                if facility:
                    return "cannot specify multiple facilities"
                facility = word
            elif word in LEVELS:
                if level:
                    return "cannot specify multiple levels"
                level = word
            elif word in Vlog.__mfl:
                if module:
                    return "cannot specify multiple modules"
                module = word
            else:
                return "no facility, level, or module \"%s\"" % word

        Vlog.set_level(module or "any", facility or "any", level or "any")

    @staticmethod
    def get_levels():
        lines = ["                 console    syslog    file\n",
                 "                 -------    ------    ------\n"]
        lines.extend(sorted(["%-16s  %4s       %4s       %4s\n"
                             % (m,
                                Vlog.__mfl[m]["console"],
                                Vlog.__mfl[m]["syslog"],
                                Vlog.__mfl[m]["file"]) for m in Vlog.__mfl]))
        return ''.join(lines)

    @staticmethod
    def reopen_log_file():
        """Closes and then attempts to re-open the current log file.  (This is
        useful just after log rotation, to ensure that the new log file starts
        being used.)"""

        if Vlog.__log_file:
            logger = logging.getLogger("file")
            logger.removeHandler(Vlog.__file_handler)
            Vlog.__file_handler = logging.FileHandler(Vlog.__log_file)
            logger.addHandler(Vlog.__file_handler)

    @staticmethod
    def _unixctl_vlog_reopen(conn, unused_argv, unused_aux):
        if Vlog.__log_file:
            Vlog.reopen_log_file()
            conn.reply(None)
        else:
            conn.reply("Logging to file not configured")

    @staticmethod
    def _unixctl_vlog_set(conn, argv, unused_aux):
        for arg in argv:
            msg = Vlog.set_levels_from_string(arg)
            if msg:
                conn.reply(msg)
                return
        conn.reply(None)

    @staticmethod
    def _unixctl_vlog_list(conn, unused_argv, unused_aux):
        conn.reply(Vlog.get_levels())

def add_args(parser):
    """Adds vlog related options to 'parser', an ArgumentParser object.  The
    resulting arguments parsed by 'parser' should be passed to handle_args."""

    group = parser.add_argument_group(title="Logging Options")
    group.add_argument("--log-file", nargs="?", const="default",
                       help="Enables logging to a file.  Default log file"
                       " is used if LOG_FILE is omitted.")
    group.add_argument("-v", "--verbose", nargs="*",
                       help="Sets logging levels, see ovs-vswitchd(8)."
                       "  Defaults to dbg.")


def handle_args(args):
    """ Handles command line arguments ('args') parsed by an ArgumentParser.
    The ArgumentParser should have been primed by add_args().  Also takes care
    of initializing the Vlog module."""

    log_file = args.log_file
    if log_file == "default":
        log_file = "%s/%s.log" % (ovs.dirs.LOGDIR, ovs.util.PROGRAM_NAME)

    if args.verbose is None:
        args.verbose = []
    elif args.verbose == []:
        args.verbose = ["any:any:dbg"]

    for verbose in args.verbose:
        msg = Vlog.set_levels_from_string(verbose)
        if msg:
            ovs.util.ovs_fatal(0, "processing \"%s\": %s" % (verbose, msg))

    Vlog.init(log_file)

########NEW FILE########
__FILENAME__ = conf_switch
# Copyright (C) 2012 Nippon Telegraph and Telephone Corporation.
# Copyright (C) 2012 Isaku Yamahata <yamahata at private email ne jp>
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import logging

from ryu.controller import event
from ryu.lib.dpid import dpid_to_str
from ryu.base import app_manager

LOG = logging.getLogger(__name__)


class EventConfSwitchDelDPID(event.EventBase):
    def __init__(self, dpid):
        super(EventConfSwitchDelDPID, self).__init__()
        self.dpid = dpid

    def __str__(self):
        return 'EventConfSwitchDelDPID<%s>' % dpid_to_str(self.dpid)


class EventConfSwitchSet(event.EventBase):
    def __init__(self, dpid, key, value):
        super(EventConfSwitchSet, self).__init__()
        self.dpid = dpid
        self.key = key
        self.value = value

    def __str__(self):
        return 'EventConfSwitchSet<%s, %s, %s>' % (
            dpid_to_str(self.dpid), self.key, self.value)


class EventConfSwitchDel(event.EventBase):
    def __init__(self, dpid, key):
        super(EventConfSwitchDel, self).__init__()
        self.dpid = dpid
        self.key = key

    def __str__(self):
        return 'EventConfSwitchDel<%s, %s>' % (dpid_to_str(self.dpid),
                                               self.key)


class ConfSwitchSet(app_manager.RyuApp):
    def __init__(self):
        super(ConfSwitchSet, self).__init__()
        self.name = 'conf_switch'
        self.confs = {}

    def dpids(self):
        return self.confs.keys()

    def del_dpid(self, dpid):
        del self.confs[dpid]
        self.send_event_to_observers(EventConfSwitchDelDPID(dpid))

    def keys(self, dpid):
        return self.confs[dpid].keys()

    def set_key(self, dpid, key, value):
        conf = self.confs.setdefault(dpid, {})
        conf[key] = value
        self.send_event_to_observers(EventConfSwitchSet(dpid, key, value))

    def get_key(self, dpid, key):
        return self.confs[dpid][key]

    def del_key(self, dpid, key):
        del self.confs[dpid][key]
        self.send_event_to_observers(EventConfSwitchDel(dpid, key))

    # methods for TunnelUpdater
    def __contains__(self, (dpid, key)):
        """(dpid, key) in <ConfSwitchSet instance>"""
        return dpid in self.confs and key in self.confs[dpid]

    def find_dpid(self, key, value):
        for dpid, conf in self.confs.items():
            if key in conf:
                if conf[key] == value:
                    return dpid

        return None

########NEW FILE########
__FILENAME__ = controller
# Copyright (C) 2011, 2012 Nippon Telegraph and Telephone Corporation.
# Copyright (C) 2011, 2012 Isaku Yamahata <yamahata at valinux co jp>
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import contextlib
from oslo.config import cfg
import logging
from ryu.lib import hub
from ryu.lib.hub import StreamServer
import traceback
import random
import ssl

import ryu.base.app_manager

from ryu.ofproto import ofproto_common
from ryu.ofproto import ofproto_parser
from ryu.ofproto import ofproto_v1_0
from ryu.ofproto import ofproto_v1_0_parser
from ryu.ofproto import ofproto_v1_2
from ryu.ofproto import ofproto_v1_2_parser
from ryu.ofproto import ofproto_v1_3
from ryu.ofproto import ofproto_v1_3_parser
from ryu.ofproto import nx_match

from ryu.controller import handler
from ryu.controller import ofp_event

from ryu.lib.dpid import dpid_to_str

LOG = logging.getLogger('ryu.controller.controller')

CONF = cfg.CONF
CONF.register_cli_opts([
    cfg.StrOpt('ofp-listen-host', default='', help='openflow listen host'),
    cfg.IntOpt('ofp-tcp-listen-port', default=ofproto_common.OFP_TCP_PORT,
               help='openflow tcp listen port'),
    cfg.IntOpt('ofp-ssl-listen-port', default=ofproto_common.OFP_SSL_PORT,
               help='openflow ssl listen port'),
    cfg.StrOpt('ctl-privkey', default=None, help='controller private key'),
    cfg.StrOpt('ctl-cert', default=None, help='controller certificate'),
    cfg.StrOpt('ca-certs', default=None, help='CA certificates')
])


class OpenFlowController(object):
    def __init__(self):
        super(OpenFlowController, self).__init__()

    # entry point
    def __call__(self):
        #LOG.debug('call')
        self.server_loop()

    def server_loop(self):
        if CONF.ctl_privkey is not None and CONF.ctl_cert is not None:
            if CONF.ca_certs is not None:
                server = StreamServer((CONF.ofp_listen_host,
                                       CONF.ofp_ssl_listen_port),
                                      datapath_connection_factory,
                                      keyfile=CONF.ctl_privkey,
                                      certfile=CONF.ctl_cert,
                                      cert_reqs=ssl.CERT_REQUIRED,
                                      ca_certs=CONF.ca_certs,
                                      ssl_version=ssl.PROTOCOL_TLSv1)
            else:
                server = StreamServer((CONF.ofp_listen_host,
                                       CONF.ofp_ssl_listen_port),
                                      datapath_connection_factory,
                                      keyfile=CONF.ctl_privkey,
                                      certfile=CONF.ctl_cert,
                                      ssl_version=ssl.PROTOCOL_TLSv1)
        else:
            server = StreamServer((CONF.ofp_listen_host,
                                   CONF.ofp_tcp_listen_port),
                                  datapath_connection_factory)

        #LOG.debug('loop')
        server.serve_forever()


def _deactivate(method):
    def deactivate(self):
        try:
            method(self)
        finally:
            self.is_active = False
    return deactivate


class Datapath(object):
    supported_ofp_version = {
        ofproto_v1_0.OFP_VERSION: (ofproto_v1_0,
                                   ofproto_v1_0_parser),
        ofproto_v1_2.OFP_VERSION: (ofproto_v1_2,
                                   ofproto_v1_2_parser),
        ofproto_v1_3.OFP_VERSION: (ofproto_v1_3,
                                   ofproto_v1_3_parser),
    }

    def __init__(self, socket, address):
        super(Datapath, self).__init__()

        self.socket = socket
        self.address = address
        self.is_active = True

        # The limit is arbitrary. We need to limit queue size to
        # prevent it from eating memory up
        self.send_q = hub.Queue(16)

        self.set_version(max(self.supported_ofp_version))
        self.xid = random.randint(0, self.ofproto.MAX_XID)
        self.id = None  # datapath_id is unknown yet
        self.ports = None
        self.flow_format = ofproto_v1_0.NXFF_OPENFLOW10
        self.ofp_brick = ryu.base.app_manager.lookup_service_brick('ofp_event')
        self.set_state(handler.HANDSHAKE_DISPATCHER)

    def close(self):
        self.set_state(handler.DEAD_DISPATCHER)

    def set_state(self, state):
        self.state = state
        ev = ofp_event.EventOFPStateChange(self)
        ev.state = state
        self.ofp_brick.send_event_to_observers(ev, state)

    def set_version(self, version):
        assert version in self.supported_ofp_version
        self.ofproto, self.ofproto_parser = self.supported_ofp_version[version]

    # Low level socket handling layer
    @_deactivate
    def _recv_loop(self):
        buf = bytearray()
        required_len = ofproto_common.OFP_HEADER_SIZE

        count = 0
        while self.is_active:
            ret = self.socket.recv(required_len)
            if len(ret) == 0:
                self.is_active = False
                break
            buf += ret
            while len(buf) >= required_len:
                (version, msg_type, msg_len, xid) = ofproto_parser.header(buf)
                required_len = msg_len
                if len(buf) < required_len:
                    break

                msg = ofproto_parser.msg(self,
                                         version, msg_type, msg_len, xid, buf)
                #LOG.debug('queue msg %s cls %s', msg, msg.__class__)
                ev = ofp_event.ofp_msg_to_ev(msg)
                self.ofp_brick.send_event_to_observers(ev, self.state)

                handlers = [handler for handler in
                            self.ofp_brick.get_handlers(ev) if self.state in
                            handler.dispatchers]
                for handler in handlers:
                    handler(ev)

                buf = buf[required_len:]
                required_len = ofproto_common.OFP_HEADER_SIZE

                # We need to schedule other greenlets. Otherwise, ryu
                # can't accept new switches or handle the existing
                # switches. The limit is arbitrary. We need the better
                # approach in the future.
                count += 1
                if count > 2048:
                    count = 0
                    hub.sleep(0)

    @_deactivate
    def _send_loop(self):
        try:
            while self.is_active:
                buf = self.send_q.get()
                self.socket.sendall(buf)
        finally:
            q = self.send_q
            # first, clear self.send_q to prevent new references.
            self.send_q = None
            # there might be threads currently blocking in send_q.put().
            # unblock them by draining the queue.
            try:
                while q.get(block=False):
                    pass
            except hub.QueueEmpty:
                pass

    def send(self, buf):
        if self.send_q:
            self.send_q.put(buf)

    def set_xid(self, msg):
        self.xid += 1
        self.xid &= self.ofproto.MAX_XID
        msg.set_xid(self.xid)
        return self.xid

    def send_msg(self, msg):
        assert isinstance(msg, self.ofproto_parser.MsgBase)
        if msg.xid is None:
            self.set_xid(msg)
        msg.serialize()
        # LOG.debug('send_msg %s', msg)
        self.send(msg.buf)

    def serve(self):
        send_thr = hub.spawn(self._send_loop)

        # send hello message immediately
        hello = self.ofproto_parser.OFPHello(self)
        self.send_msg(hello)

        try:
            self._recv_loop()
        finally:
            hub.kill(send_thr)
            hub.joinall([send_thr])

    #
    # Utility methods for convenience
    #
    def send_packet_out(self, buffer_id=0xffffffff, in_port=None,
                        actions=None, data=None):
        if in_port is None:
            in_port = self.ofproto.OFPP_NONE
        packet_out = self.ofproto_parser.OFPPacketOut(
            self, buffer_id, in_port, actions, data)
        self.send_msg(packet_out)

    def send_flow_mod(self, rule, cookie, command, idle_timeout, hard_timeout,
                      priority=None, buffer_id=0xffffffff,
                      out_port=None, flags=0, actions=None):
        if priority is None:
            priority = self.ofproto.OFP_DEFAULT_PRIORITY
        if out_port is None:
            out_port = self.ofproto.OFPP_NONE
        flow_format = rule.flow_format()
        assert (flow_format == ofproto_v1_0.NXFF_OPENFLOW10 or
                flow_format == ofproto_v1_0.NXFF_NXM)
        if self.flow_format < flow_format:
            self.send_nxt_set_flow_format(flow_format)
        if flow_format == ofproto_v1_0.NXFF_OPENFLOW10:
            match_tuple = rule.match_tuple()
            match = self.ofproto_parser.OFPMatch(*match_tuple)
            flow_mod = self.ofproto_parser.OFPFlowMod(
                self, match, cookie, command, idle_timeout, hard_timeout,
                priority, buffer_id, out_port, flags, actions)
        else:
            flow_mod = self.ofproto_parser.NXTFlowMod(
                self, cookie, command, idle_timeout, hard_timeout,
                priority, buffer_id, out_port, flags, rule, actions)
        self.send_msg(flow_mod)

    def send_flow_del(self, rule, cookie, out_port=None):
        self.send_flow_mod(rule=rule, cookie=cookie,
                           command=self.ofproto.OFPFC_DELETE,
                           idle_timeout=0, hard_timeout=0, priority=0,
                           out_port=out_port)

    def send_delete_all_flows(self):
        rule = nx_match.ClsRule()
        self.send_flow_mod(
            rule=rule, cookie=0, command=self.ofproto.OFPFC_DELETE,
            idle_timeout=0, hard_timeout=0, priority=0, buffer_id=0,
            out_port=self.ofproto.OFPP_NONE, flags=0, actions=None)

    def send_barrier(self):
        barrier_request = self.ofproto_parser.OFPBarrierRequest(self)
        self.send_msg(barrier_request)

    def send_nxt_set_flow_format(self, flow_format):
        assert (flow_format == ofproto_v1_0.NXFF_OPENFLOW10 or
                flow_format == ofproto_v1_0.NXFF_NXM)
        if self.flow_format == flow_format:
            # Nothing to do
            return
        self.flow_format = flow_format
        set_format = self.ofproto_parser.NXTSetFlowFormat(self, flow_format)
        # FIXME: If NXT_SET_FLOW_FORMAT or NXFF_NXM is not supported by
        # the switch then an error message will be received. It may be
        # handled by setting self.flow_format to
        # ofproto_v1_0.NXFF_OPENFLOW10 but currently isn't.
        self.send_msg(set_format)
        self.send_barrier()

    def is_reserved_port(self, port_no):
        return port_no > self.ofproto.OFPP_MAX


def datapath_connection_factory(socket, address):
    LOG.debug('connected socket:%s address:%s', socket, address)
    with contextlib.closing(Datapath(socket, address)) as datapath:
        try:
            datapath.serve()
        except:
            # Something went wrong.
            # Especially malicious switch can send malformed packet,
            # the parser raise exception.
            # Can we do anything more graceful?
            if datapath.id is None:
                dpid_str = "%s" % datapath.id
            else:
                dpid_str = dpid_to_str(datapath.id)
            LOG.error("Error in the datapath %s from %s", dpid_str, address)
            raise


def start_service(app_mgr):
    for app in app_mgr.applications:
        if app.endswith('ofp_handler'):
            return OpenFlowController()

########NEW FILE########
__FILENAME__ = dpset
# Copyright (C) 2012, 2013 Nippon Telegraph and Telephone Corporation.
# Copyright (C) 2012 Isaku Yamahata <yamahata at valinux co jp>
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import logging

from ryu.base import app_manager
from ryu.controller import event
from ryu.controller import handler
from ryu.controller import ofp_event
from ryu.controller.handler import set_ev_cls
import ryu.exception as ryu_exc

from ryu.lib.dpid import dpid_to_str

LOG = logging.getLogger('ryu.controller.dpset')

DPSET_EV_DISPATCHER = "dpset"


class EventDPBase(event.EventBase):
    def __init__(self, dp):
        super(EventDPBase, self).__init__()
        self.dp = dp


class EventDP(EventDPBase):
    def __init__(self, dp, enter_leave):
        # enter_leave
        # True: dp entered
        # False: dp leaving
        super(EventDP, self).__init__(dp)
        self.enter = enter_leave
        self.ports = []  # port list when enter or leave


class EventPortBase(EventDPBase):
    def __init__(self, dp, port):
        super(EventPortBase, self).__init__(dp)
        self.port = port


class EventPortAdd(EventPortBase):
    def __init__(self, dp, port):
        super(EventPortAdd, self).__init__(dp, port)


class EventPortDelete(EventPortBase):
    def __init__(self, dp, port):
        super(EventPortDelete, self).__init__(dp, port)


class EventPortModify(EventPortBase):
    def __init__(self, dp, new_port):
        super(EventPortModify, self).__init__(dp, new_port)


class PortState(dict):
    def __init__(self):
        super(PortState, self).__init__()

    def add(self, port_no, port):
        self[port_no] = port

    def remove(self, port_no):
        del self[port_no]

    def modify(self, port_no, port):
        self[port_no] = port


# this depends on controller::Datapath and dispatchers in handler
class DPSet(app_manager.RyuApp):
    """
    DPSet application manages a set of switches (datapaths)
    connected to this controller.
    """

    def __init__(self):
        super(DPSet, self).__init__()
        self.name = 'dpset'

        self.dps = {}   # datapath_id => class Datapath
        self.port_state = {}  # datapath_id => ports

    def _register(self, dp):
        LOG.debug('DPSET: register datapath %s', dp)
        assert dp.id is not None

        # while dpid should be unique, we need to handle duplicates here
        # because it's entirely possible for a switch to reconnect us
        # before we notice the drop of the previous connection.
        # in that case,
        # - forget the older connection as it likely will disappear soon
        # - do not send EventDP leave/enter events
        # - keep the PortState for the dpid
        if dp.id in self.dps:
            self.logger.warning('DPSET: Multiple connections from %s',
                                dpid_to_str(dp.id))
            self.logger.debug('DPSET: Forgetting datapath %s', self.dps[dp.id])
            self.logger.debug('DPSET: New datapath %s', dp)
        self.dps[dp.id] = dp
        if not dp.id in self.port_state:
            self.port_state[dp.id] = PortState()
            ev = EventDP(dp, True)
            for port in dp.ports.values():
                self._port_added(dp, port)
                ev.ports.append(port)
            self.send_event_to_observers(ev)

    def _unregister(self, dp):
        # see the comment in _register().
        if not dp in self.dps.values():
            return
        LOG.debug('DPSET: unregister datapath %s', dp)
        assert self.dps[dp.id] == dp

        # Now datapath is already dead, so port status change event doesn't
        # interfere us.
        ev = EventDP(dp, False)
        for port in self.port_state.get(dp.id, {}).values():
            self._port_deleted(dp, port)
            ev.ports.append(port)

        self.send_event_to_observers(ev)

        del self.dps[dp.id]
        del self.port_state[dp.id]

    def get(self, dp_id):
        """
        This method returns the ryu.controller.controller.Datapath
        instance for the given Datapath ID.
        Raises KeyError if no such a datapath connected to this controller.
        """
        return self.dps.get(dp_id)

    def get_all(self):
        """
        This method returns a list of tuples which represents
        instances for switches connected to this controller.
        The tuple consists of a Datapath Id and an instance of
        ryu.controller.controller.Datapath.
        A return value looks like the following:

            [ (dpid_A, Datapath_A), (dpid_B, Datapath_B), ... ]
        """
        return self.dps.items()

    def _port_added(self, datapath, port):
        self.port_state[datapath.id].add(port.port_no, port)

    def _port_deleted(self, datapath, port):
        self.port_state[datapath.id].remove(port.port_no)

    @set_ev_cls(ofp_event.EventOFPStateChange,
                [handler.MAIN_DISPATCHER, handler.DEAD_DISPATCHER])
    def dispacher_change(self, ev):
        datapath = ev.datapath
        assert datapath is not None
        if ev.state == handler.MAIN_DISPATCHER:
            self._register(datapath)
        elif ev.state == handler.DEAD_DISPATCHER:
            self._unregister(datapath)

    @set_ev_cls(ofp_event.EventOFPSwitchFeatures, handler.CONFIG_DISPATCHER)
    def switch_features_handler(self, ev):
        msg = ev.msg
        datapath = msg.datapath
        # ofp_handler.py does the following so we could remove...
        if datapath.ofproto.OFP_VERSION < 0x04:
            datapath.ports = msg.ports

    @set_ev_cls(ofp_event.EventOFPPortStatus, handler.MAIN_DISPATCHER)
    def port_status_handler(self, ev):
        msg = ev.msg
        reason = msg.reason
        datapath = msg.datapath
        port = msg.desc
        ofproto = datapath.ofproto

        if reason == ofproto.OFPPR_ADD:
            LOG.debug('DPSET: A port was added.' +
                      '(datapath id = %s, port number = %s)',
                      dpid_to_str(datapath.id), port.port_no)
            self._port_added(datapath, port)
            self.send_event_to_observers(EventPortAdd(datapath, port))
        elif reason == ofproto.OFPPR_DELETE:
            LOG.debug('DPSET: A port was deleted.' +
                      '(datapath id = %s, port number = %s)',
                      dpid_to_str(datapath.id), port.port_no)
            self._port_deleted(datapath, port)
            self.send_event_to_observers(EventPortDelete(datapath, port))
        else:
            assert reason == ofproto.OFPPR_MODIFY
            LOG.debug('DPSET: A port was modified.' +
                      '(datapath id = %s, port number = %s)',
                      dpid_to_str(datapath.id), port.port_no)
            self.port_state[datapath.id].modify(port.port_no, port)
            self.send_event_to_observers(EventPortModify(datapath, port))

    def get_port(self, dpid, port_no):
        """
        This method returns the ryu.controller.dpset.PortState
        instance for the given Datapath ID and the port number.
        Raises ryu_exc.PortNotFound if no such a datapath connected to
        this controller or no such a port exists.
        """
        try:
            return self.port_state[dpid][port_no]
        except KeyError:
            raise ryu_exc.PortNotFound(dpid=dpid, port=port_no,
                                       network_id=None)

    def get_ports(self, dpid):
        """
        This method returns a list of ryu.controller.dpset.PortState
        instances for the given Datapath ID.
        Raises KeyError if no such a datapath connected to this controller.
        """
        return self.port_state[dpid].values()

########NEW FILE########
__FILENAME__ = event
# Copyright (C) 2011 Nippon Telegraph and Telephone Corporation.
# Copyright (C) 2011 Isaku Yamahata <yamahata at valinux co jp>
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.


class EventBase(object):
    # Nothing yet
    pass


class EventRequestBase(EventBase):
    def __init__(self):
        super(EventRequestBase, self).__init__()
        self.dst = None  # app.name of provide the event.
        self.src = None
        self.sync = False


class EventReplyBase(EventBase):
    def __init__(self, dst):
        super(EventReplyBase, self).__init__()
        self.dst = dst

########NEW FILE########
__FILENAME__ = handler
# Copyright (C) 2011, 2012 Nippon Telegraph and Telephone Corporation.
# Copyright (C) 2011, 2012 Isaku Yamahata <yamahata at valinux co jp>
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import inspect
import logging
import sys

LOG = logging.getLogger('ryu.controller.handler')

# just represent OF datapath state. datapath specific so should be moved.
HANDSHAKE_DISPATCHER = "handshake"
CONFIG_DISPATCHER = "config"
MAIN_DISPATCHER = "main"
DEAD_DISPATCHER = "dead"


# should be named something like 'observe_event'
def set_ev_cls(ev_cls, dispatchers=None):
    def _set_ev_cls_dec(handler):
        handler.ev_cls = ev_cls
        handler.dispatchers = _listify(dispatchers)
        handler.observer = ev_cls.__module__
        return handler
    return _set_ev_cls_dec


def set_ev_handler(ev_cls, dispatchers=None):
    def _set_ev_cls_dec(handler):
        handler.ev_cls = ev_cls
        handler.dispatchers = _listify(dispatchers)
        return handler
    return _set_ev_cls_dec


def _is_ev_cls(meth):
    return hasattr(meth, 'ev_cls')


def _listify(may_list):
    if may_list is None:
        may_list = []
    if not isinstance(may_list, list):
        may_list = [may_list]
    return may_list


def register_instance(i):
    for _k, m in inspect.getmembers(i, inspect.ismethod):
        # LOG.debug('instance %s k %s m %s', i, _k, m)
        if _is_ev_cls(m):
            i.register_handler(m.ev_cls, m)


def get_dependent_services(cls):
    services = []
    for _k, m in inspect.getmembers(cls, inspect.ismethod):
        if _is_ev_cls(m):
            service = getattr(sys.modules[m.ev_cls.__module__],
                              '_SERVICE_NAME', None)
            if service:
                # avoid cls that registers the own events (like ofp_handler)
                if cls.__module__ != service:
                    services.append(service)

    services = list(set(services))
    return services


def register_service(service):
    frm = inspect.stack()[1]
    m = inspect.getmodule(frm[0])
    m._SERVICE_NAME = service

########NEW FILE########
__FILENAME__ = mac_to_network
# Copyright (C) 2011 Nippon Telegraph and Telephone Corporation.
# Copyright (C) 2011 Isaku Yamahata <yamahata at valinux co jp>
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import logging

from ryu.exception import MacAddressDuplicated
from ryu.lib.mac import haddr_to_str

LOG = logging.getLogger('ryu.controller.mac_to_network')


class MacToNetwork(object):
    def __init__(self, nw):
        super(MacToNetwork, self).__init__()
        self.mac_to_net = {}
        self.dpid = {}
        self.nw = nw

    def get_network(self, mac, default=None):
        return self.mac_to_net.get(mac, default)

    def add_mac(self, mac, nw_id, nw_id_external=None):
        _nw_id = self.mac_to_net.get(mac)
        if _nw_id == nw_id:
            return

        # allow changing from nw_id_external to known nw id
        if _nw_id is None or _nw_id == nw_id_external:
            self.mac_to_net[mac] = nw_id
            LOG.debug('overwrite nw_id: mac %s nw old %s new %s',
                      haddr_to_str(mac), _nw_id, nw_id)
            return

        if nw_id == nw_id_external:
            # this can happens when the packet traverses
            # VM-> tap-> ovs-> ext-port-> wire-> ext-port-> ovs-> tap-> VM
            return

        LOG.warn('duplicated nw_id: mac %s nw old %s new %s',
                 haddr_to_str(mac), _nw_id, nw_id)

        raise MacAddressDuplicated(mac=mac)

    def del_mac(self, mac):
        del self.mac_to_net[mac]

########NEW FILE########
__FILENAME__ = mac_to_port
# Copyright (C) 2011 Nippon Telegraph and Telephone Corporation.
# Copyright (C) 2011 Isaku Yamahata <yamahata at valinux co jp>
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import logging
from ryu.lib.mac import haddr_to_str

LOG = logging.getLogger('ryu.controller.mac_to_port')


class MacToPortTable(object):
    """MAC addr <-> (dpid, port name)"""

    def __init__(self):
        super(MacToPortTable, self).__init__()
        self.mac_to_port = {}

    def dpid_add(self, dpid):
        LOG.debug('dpid_add: 0x%016x', dpid)
        self.mac_to_port.setdefault(dpid, {})

    def port_add(self, dpid, port, mac):
        """
        :returns: old port if learned. (this may be = port)
                  None otherwise
        """
        old_port = self.mac_to_port[dpid].get(mac, None)
        self.mac_to_port[dpid][mac] = port

        if old_port is not None and old_port != port:
            LOG.debug('port_add: 0x%016x 0x%04x %s',
                      dpid, port, haddr_to_str(mac))

        return old_port

    def port_get(self, dpid, mac):
        # LOG.debug('dpid 0x%016x mac %s', dpid, haddr_to_str(mac))
        return self.mac_to_port[dpid].get(mac)

    def mac_list(self, dpid, port):
        return [mac for (mac, port_) in self.mac_to_port.get(dpid).items()
                if port_ == port]

    def mac_del(self, dpid, mac):
        del self.mac_to_port[dpid][mac]

########NEW FILE########
__FILENAME__ = network
# Copyright (C) 2011 Nippon Telegraph and Telephone Corporation.
# Copyright (C) 2011 Isaku Yamahata <yamahata at valinux co jp>
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import collections

from ryu.base import app_manager
import ryu.exception as ryu_exc
from ryu.app.rest_nw_id import NW_ID_UNKNOWN
from ryu.controller import event
from ryu.exception import NetworkNotFound, NetworkAlreadyExist
from ryu.exception import PortAlreadyExist, PortNotFound, PortUnknown


class MacAddressAlreadyExist(ryu_exc.RyuException):
    message = 'port (%(dpid)s, %(port)s) has already mac %(mac_address)s'


class EventNetworkDel(event.EventBase):
    def __init__(self, network_id):
        super(EventNetworkDel, self).__init__()
        self.network_id = network_id


class EventNetworkPort(event.EventBase):
    def __init__(self, network_id, dpid, port_no, add_del):
        super(EventNetworkPort, self).__init__()
        self.network_id = network_id
        self.dpid = dpid
        self.port_no = port_no
        self.add_del = add_del


class EventMacAddress(event.EventBase):
    def __init__(self, dpid, port_no, network_id, mac_address, add_del):
        super(EventMacAddress, self).__init__()
        assert network_id is not None
        assert mac_address is not None
        self.dpid = dpid
        self.port_no = port_no
        self.network_id = network_id
        self.mac_address = mac_address
        self.add_del = add_del


class Networks(dict):
    "network_id -> set of (dpid, port_no)"
    def __init__(self, f):
        super(Networks, self).__init__()
        self.send_event = f

    def list_networks(self):
        return self.keys()

    def has_network(self, network_id):
        return network_id in self

    def update_network(self, network_id):
        self.setdefault(network_id, set())

    def create_network(self, network_id):
        if network_id in self:
            raise NetworkAlreadyExist(network_id=network_id)

        self[network_id] = set()

    def remove_network(self, network_id):
        try:
            ports = self[network_id]
        except KeyError:
            raise NetworkNotFound(network_id=network_id)

        while ports:
            (dpid, port_no) = ports.pop()
            self._remove_event(network_id, dpid, port_no)
        if self.pop(network_id, None) is not None:
            self.send_event(EventNetworkDel(network_id))

    def list_ports(self, network_id):
        try:
            # use list() to keep compatibility for output
            # set() isn't json serializable
            return list(self[network_id])
        except KeyError:
            raise NetworkNotFound(network_id=network_id)

    def add_raw(self, network_id, dpid, port_no):
        self[network_id].add((dpid, port_no))

    def add_event(self, network_id, dpid, port_no):
        self.send_event(
            EventNetworkPort(network_id, dpid, port_no, True))

    # def add(self, network_id, dpid, port_no):
    #     self.add_raw(network_id, dpid, port_no)
    #     self.add_event(network_id, dpid, port_no)

    def _remove_event(self, network_id, dpid, port_no):
        self.send_event(EventNetworkPort(network_id, dpid, port_no, False))

    def remove_raw(self, network_id, dpid, port_no):
        ports = self[network_id]
        if (dpid, port_no) in ports:
            ports.remove((dpid, port_no))
            self._remove_event(network_id, dpid, port_no)

    def remove(self, network_id, dpid, port_no):
        try:
            self.remove_raw(network_id, dpid, port_no)
        except KeyError:
            raise NetworkNotFound(network_id=network_id)
        except ValueError:
            raise PortNotFound(network_id=network_id, dpid=dpid, port=port_no)

    def has_port(self, network_id, dpid, port):
        return (dpid, port) in self[network_id]

    def get_dpids(self, network_id):
        try:
            ports = self[network_id]
        except KeyError:
            return set()

        # python 2.6 doesn't support set comprehension
        # port = (dpid, port_no)
        return set([port[0] for port in ports])


class Port(object):
    def __init__(self, port_no, network_id, mac_address=None):
        super(Port, self).__init__()
        self.port_no = port_no
        self.network_id = network_id
        self.mac_address = mac_address


class DPIDs(dict):
    """dpid -> port_no -> Port(port_no, network_id, mac_address)"""
    def __init__(self, f, nw_id_unknown):
        super(DPIDs, self).__init__()
        self.send_event = f
        self.nw_id_unknown = nw_id_unknown

    def setdefault_dpid(self, dpid):
        return self.setdefault(dpid, {})

    def _setdefault_network(self, dpid, port_no, default_network_id):
        dp = self.setdefault_dpid(dpid)
        return dp.setdefault(port_no, Port(port_no=port_no,
                                           network_id=default_network_id))

    def setdefault_network(self, dpid, port_no):
        self._setdefault_network(dpid, port_no, self.nw_id_unknown)

    def update_port(self, dpid, port_no, network_id):
        port = self._setdefault_network(dpid, port_no, network_id)
        port.network_id = network_id

    def remove_port(self, dpid, port_no):
        try:
            # self.dpids[dpid][port_no] can be already deleted by
            # port_deleted()
            port = self[dpid].pop(port_no, None)
            if port and port.network_id and port.mac_address:
                self.send_event(EventMacAddress(dpid, port_no,
                                                port.network_id,
                                                port.mac_address,
                                                False))
        except KeyError:
            raise PortNotFound(dpid=dpid, port=port_no, network_id=None)

    def get_ports(self, dpid, network_id=None, mac_address=None):
        if network_id is None:
            return self.get(dpid, {}).values()
        if mac_address is None:
            return [p for p in self.get(dpid, {}).values()
                    if p.network_id == network_id]

        # live-migration: There can be two ports that have same mac address.
        return [p for p in self.get(dpid, {}).values()
                if p.network_id == network_id and p.mac_address == mac_address]

    def get_port(self, dpid, port_no):
        try:
            return self[dpid][port_no]
        except KeyError:
            raise PortNotFound(dpid=dpid, port=port_no, network_id=None)

    def get_network(self, dpid, port_no):
        try:
            return self[dpid][port_no].network_id
        except KeyError:
            raise PortUnknown(dpid=dpid, port=port_no)

    def get_networks(self, dpid):
        return set(self[dpid].values())

    def get_network_safe(self, dpid, port_no):
        port = self.get(dpid, {}).get(port_no)
        if port is None:
            return self.nw_id_unknown
        return port.network_id

    def get_mac(self, dpid, port_no):
        port = self.get_port(dpid, port_no)
        return port.mac_address

    def _set_mac(self, network_id, dpid, port_no, port, mac_address):
        if not (port.network_id is None or
                port.network_id == network_id or
                port.network_id == self.nw_id_unknown):
            raise PortNotFound(network_id=network_id, dpid=dpid, port=port_no)

        port.network_id = network_id
        port.mac_address = mac_address
        if port.network_id and port.mac_address:
            self.send_event(EventMacAddress(
                            dpid, port_no, port.network_id, port.mac_address,
                            True))

    def set_mac(self, network_id, dpid, port_no, mac_address):
        port = self.get_port(dpid, port_no)
        if port.mac_address is not None:
            raise MacAddressAlreadyExist(dpid=dpid, port=port_no,
                                         mac_address=mac_address)
        self._set_mac(network_id, dpid, port_no, port, mac_address)

    def update_mac(self, network_id, dpid, port_no, mac_address):
        port = self.get_port(dpid, port_no)
        if port.mac_address is None:
            self._set_mac(network_id, dpid, port_no, port, mac_address)
            return

        # For now, we don't allow changing mac address.
        if port.mac_address != mac_address:
            raise MacAddressAlreadyExist(dpid=dpid, port=port_no,
                                         mac_address=port.mac_address)


MacPort = collections.namedtuple('MacPort', ('dpid', 'port_no'))


class MacToPort(collections.defaultdict):
    """mac_address -> set of MacPort(dpid, port_no)"""
    def __init__(self):
        super(MacToPort, self).__init__(set)

    def add_port(self, dpid, port_no, mac_address):
        self[mac_address].add(MacPort(dpid, port_no))

    def remove_port(self, dpid, port_no, mac_address):
        ports = self[mac_address]
        ports.discard(MacPort(dpid, port_no))
        if not ports:
            del self[mac_address]

    def get_ports(self, mac_address):
        return self[mac_address]


class MacAddresses(dict):
    """network_id -> mac_address -> set of (dpid, port_no)"""
    def add_port(self, network_id, dpid, port_no, mac_address):
        mac2port = self.setdefault(network_id, MacToPort())
        mac2port.add_port(dpid, port_no, mac_address)

    def remove_port(self, network_id, dpid, port_no, mac_address):
        mac2port = self.get(network_id)
        if mac2port is None:
            return
        mac2port.remove_port(dpid, port_no, mac_address)
        if not mac2port:
            del self[network_id]

    def get_ports(self, network_id, mac_address):
        mac2port = self.get(network_id)
        if not mac2port:
            return set()
        return mac2port.get_ports(mac_address)


class Network(app_manager.RyuApp):
    def __init__(self, nw_id_unknown=NW_ID_UNKNOWN):
        super(Network, self).__init__()
        self.name = 'network'
        self.nw_id_unknown = nw_id_unknown
        self.networks = Networks(self.send_event_to_observers)
        self.dpids = DPIDs(self.send_event_to_observers, nw_id_unknown)
        self.mac_addresses = MacAddresses()

    def _check_nw_id_unknown(self, network_id):
        if network_id == self.nw_id_unknown:
            raise NetworkAlreadyExist(network_id=network_id)

    def list_networks(self):
        return self.networks.list_networks()

    def update_network(self, network_id):
        self._check_nw_id_unknown(network_id)
        self.networks.update_network(network_id)

    def create_network(self, network_id):
        self._check_nw_id_unknown(network_id)
        self.networks.create_network(network_id)

    def remove_network(self, network_id):
        self.networks.remove_network(network_id)

    def list_ports(self, network_id):
        return self.networks.list_ports(network_id)

    def list_ports_noraise(self, network_id):
        try:
            return self.list_ports(network_id)
        except NetworkNotFound:
            return []

    def _update_port(self, network_id, dpid, port, port_may_exist):
        def _known_nw_id(nw_id):
            return nw_id is not None and nw_id != self.nw_id_unknown

        queue_add_event = False
        self._check_nw_id_unknown(network_id)
        try:
            old_network_id = self.dpids.get_network_safe(dpid, port)
            if (self.networks.has_port(network_id, dpid, port) or
                    _known_nw_id(old_network_id)):
                if not port_may_exist:
                    raise PortAlreadyExist(network_id=network_id,
                                           dpid=dpid, port=port)

            if old_network_id != network_id:
                queue_add_event = True
                self.networks.add_raw(network_id, dpid, port)
                if _known_nw_id(old_network_id):
                    self.networks.remove_raw(old_network_id, dpid, port)
        except KeyError:
            raise NetworkNotFound(network_id=network_id)

        self.dpids.update_port(dpid, port, network_id)
        if queue_add_event:
            self.networks.add_event(network_id, dpid, port)

    def create_port(self, network_id, dpid, port):
        self._update_port(network_id, dpid, port, False)

    def update_port(self, network_id, dpid, port):
        self._update_port(network_id, dpid, port, True)

    def _get_old_mac(self, network_id, dpid, port_no):
        try:
            port = self.dpids.get_port(dpid, port_no)
        except PortNotFound:
            pass
        else:
            if port.network_id == network_id:
                return port.mac_address
        return None

    def remove_port(self, network_id, dpid, port_no):
        # generate event first, then do the real task
        old_mac_address = self._get_old_mac(network_id, dpid, port_no)

        self.dpids.remove_port(dpid, port_no)
        try:
            self.networks.remove(network_id, dpid, port_no)
        except NetworkNotFound:
            # port deletion can be called after network deletion
            # due to Openstack auto deletion port.(dhcp/router port)
            pass
        if old_mac_address is not None:
            self.mac_addresses.remove_port(network_id, dpid, port_no,
                                           old_mac_address)

    #
    # methods for gre tunnel
    #

    def get_dpids(self, network_id):
        return self.networks.get_dpids(network_id)

    def has_network(self, network_id):
        return self.networks.has_network(network_id)

    def get_networks(self, dpid):
        return self.dpids.get_networks(dpid)

    def create_mac(self, network_id, dpid, port_no, mac_address):
        self.mac_addresses.add_port(network_id, dpid, port_no, mac_address)
        self.dpids.set_mac(network_id, dpid, port_no, mac_address)

    def update_mac(self, network_id, dpid, port_no, mac_address):
        old_mac_address = self._get_old_mac(network_id, dpid, port_no)

        self.dpids.update_mac(network_id, dpid, port_no, mac_address)
        if old_mac_address is not None:
            self.mac_addresses.remove_port(network_id, dpid, port_no,
                                           old_mac_address)
        self.mac_addresses.add_port(network_id, dpid, port_no, mac_address)

    def get_mac(self, dpid, port_no):
        return self.dpids.get_mac(dpid, port_no)

    def list_mac(self, dpid, port_no):
        mac_address = self.dpids.get_mac(dpid, port_no)
        if mac_address is None:
            return []
        return [mac_address]

    def get_ports(self, dpid, network_id=None, mac_address=None):
        return self.dpids.get_ports(dpid, network_id, mac_address)

    def get_port(self, dpid, port_no):
        return self.dpids.get_port(dpid, port_no)

    def get_ports_with_mac(self, network_id, mac_address):
        return self.mac_addresses.get_ports(network_id, mac_address)

    #
    # methods for simple_isolation
    #

    def same_network(self, dpid, nw_id, out_port, allow_nw_id_external=None):
        assert nw_id != self.nw_id_unknown
        out_nw = self.dpids.get_network_safe(dpid, out_port)

        if nw_id == out_nw:
            return True

        if (allow_nw_id_external is not None and
                (allow_nw_id_external == nw_id or
                    allow_nw_id_external == out_nw)):
            # allow external network -> known network id
            return True

        self.logger.debug('blocked dpid %s nw_id %s out_port %d out_nw %s'
                          'external %s',
                          dpid, nw_id, out_port, out_nw, allow_nw_id_external)
        return False

    def get_network(self, dpid, port):
        return self.dpids.get_network(dpid, port)

    def add_datapath(self, ofp_switch_features):
        datapath = ofp_switch_features.datapath
        dpid = ofp_switch_features.datapath_id
        ports = ofp_switch_features.ports
        self.dpids.setdefault_dpid(dpid)
        for port_no in ports:
            self.port_added(datapath, port_no)

    def port_added(self, datapath, port_no):
        if port_no == 0 or port_no >= datapath.ofproto.OFPP_MAX:
            # skip fake output ports
            return

        self.dpids.setdefault_network(datapath.id, port_no)

    def port_deleted(self, dpid, port_no):
        self.dpids.remove_port(dpid, port_no)

    def filter_ports(self, dpid, in_port, nw_id, allow_nw_id_external=None):
        assert nw_id != self.nw_id_unknown
        ret = []

        for port in self.get_ports(dpid):
            nw_id_ = port.network_id
            if port.port_no == in_port:
                continue

            if nw_id_ == nw_id:
                ret.append(port.port_no)
            elif (allow_nw_id_external is not None and
                  nw_id_ == allow_nw_id_external):
                ret.append(port.port_no)

        return ret

########NEW FILE########
__FILENAME__ = ofp_event
# Copyright (C) 2012 Nippon Telegraph and Telephone Corporation.
# Copyright (C) 2011 Isaku Yamahata <yamahata at valinux co jp>
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import inspect

from ryu.controller import handler
from ryu import ofproto
from ryu import utils
from . import event


class EventOFPMsgBase(event.EventBase):
    def __init__(self, msg):
        super(EventOFPMsgBase, self).__init__()
        self.msg = msg


#
# Create ofp_event type corresponding to OFP Msg
#

_OFP_MSG_EVENTS = {}


def _ofp_msg_name_to_ev_name(msg_name):
    return 'Event' + msg_name


def ofp_msg_to_ev(msg):
    name = _ofp_msg_name_to_ev_name(msg.__class__.__name__)
    return _OFP_MSG_EVENTS[name](msg)


def _create_ofp_msg_ev_class(msg_cls):
    name = _ofp_msg_name_to_ev_name(msg_cls.__name__)
    # print 'creating ofp_event %s' % name

    if name in _OFP_MSG_EVENTS:
        return

    cls = type(name, (EventOFPMsgBase,),
               dict(__init__=lambda self, msg:
                    super(self.__class__, self).__init__(msg)))
    globals()[name] = cls
    _OFP_MSG_EVENTS[name] = cls


def _create_ofp_msg_ev_from_module(ofp_praser):
    # print mod
    for _k, cls in inspect.getmembers(ofp_parser, inspect.isclass):
        if not hasattr(cls, 'cls_msg_type'):
            continue
        _create_ofp_msg_ev_class(cls)


for ofp_mods in ofproto.get_ofp_modules().values():
    ofp_parser = ofp_mods[1]
    # print 'loading module %s' % ofp_parser
    _create_ofp_msg_ev_from_module(ofp_parser)


class EventOFPStateChange(event.EventBase):
    def __init__(self, dp):
        super(EventOFPStateChange, self).__init__()
        self.datapath = dp


handler.register_service('ryu.controller.ofp_handler')

########NEW FILE########
__FILENAME__ = ofp_handler
# Copyright (C) 2011, 2012 Nippon Telegraph and Telephone Corporation.
# Copyright (C) 2011, 2012 Isaku Yamahata <yamahata at valinux co jp>
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import itertools
import logging

import ryu.base.app_manager

from ryu import utils
from ryu.controller import ofp_event
from ryu.controller.handler import set_ev_handler
from ryu.controller.handler import HANDSHAKE_DISPATCHER, CONFIG_DISPATCHER,\
    MAIN_DISPATCHER


# The state transition: HANDSHAKE -> CONFIG -> MAIN
#
# HANDSHAKE: if it receives HELLO message with the valid OFP version,
# sends Features Request message, and moves to CONFIG.
#
# CONFIG: it receives Features Reply message and moves to MAIN
#
# MAIN: it does nothing. Applications are expected to register their
# own handlers.
#
# Note that at any state, when we receive Echo Request message, send
# back Echo Reply message.


class OFPHandler(ryu.base.app_manager.RyuApp):
    def __init__(self, *args, **kwargs):
        super(OFPHandler, self).__init__(*args, **kwargs)
        self.name = 'ofp_event'

    def _hello_failed(self, datapath, error_desc):
        self.logger.error(error_desc)
        error_msg = datapath.ofproto_parser.OFPErrorMsg(datapath)
        error_msg.type = datapath.ofproto.OFPET_HELLO_FAILED
        error_msg.code = datapath.ofproto.OFPHFC_INCOMPATIBLE
        error_msg.data = error_desc
        datapath.send_msg(error_msg)

    @set_ev_handler(ofp_event.EventOFPHello, HANDSHAKE_DISPATCHER)
    def hello_handler(self, ev):
        self.logger.debug('hello ev %s', ev)
        msg = ev.msg
        datapath = msg.datapath

        # check if received version is supported.
        # pre 1.0 is not supported
        elements = getattr(msg, 'elements', None)
        if elements:
            switch_versions = set()
            for version in itertools.chain.from_iterable(
                    element.versions for element in elements):
                switch_versions.add(version)
            usable_versions = switch_versions & set(
                datapath.supported_ofp_version)

            # We didn't send our supported versions for interoperability as
            # most switches would not understand elements at the moment.
            # So the switch would think that the negotiated version would
            # be max(negotiated_versions), but actual usable version is
            # max(usable_versions).
            negotiated_versions = set(
                version for version in switch_versions
                if version <= max(datapath.supported_ofp_version))
            if negotiated_versions and not usable_versions:
                # e.g.
                # versions of OF 1.0 and 1.1 from switch
                # max of OF 1.2 from Ryu and supported_ofp_version = (1.2, )
                # negotiated version = 1.1
                # usable version = None
                error_desc = (
                    'no compatible version found: '
                    'switch versions %s controller version 0x%x, '
                    'the negotiated version is 0x%x, '
                    'but no usable version found. '
                    'If possible, set the switch to use one of OF version %s'
                    % (switch_versions, max(datapath.supported_ofp_version),
                       max(negotiated_versions),
                       sorted(datapath.supported_ofp_version)))
                self._hello_failed(datapath, error_desc)
                return
            if (negotiated_versions and usable_versions and
                    max(negotiated_versions) != max(usable_versions)):
                # e.g.
                # versions of OF 1.0 and 1.1 from switch
                # max of OF 1.2 from Ryu and supported_ofp_version = (1.0, 1.2)
                # negotiated version = 1.1
                # usable version = 1.0
                #
                # TODO: In order to get the version 1.0, Ryu need to send
                # supported verions.
                error_desc = (
                    'no compatible version found: '
                    'switch versions 0x%x controller version 0x%x, '
                    'the negotiated version is %s but found usable %s. '
                    'If possible, '
                    'set the switch to use one of OF version %s' % (
                        max(switch_versions),
                        max(datapath.supported_ofp_version),
                        sorted(negotiated_versions),
                        sorted(usable_versions), sorted(usable_versions)))
                self._hello_failed(datapath, error_desc)
                return
        else:
            usable_versions = set(version for version
                                  in datapath.supported_ofp_version
                                  if version <= msg.version)
            if (usable_versions and
                max(usable_versions) != min(msg.version,
                                            datapath.ofproto.OFP_VERSION)):
                # The version of min(msg.version, datapath.ofproto.OFP_VERSION)
                # should be used according to the spec. But we can't.
                # So log it and use max(usable_versions) with the hope that
                # the switch is able to understand lower version.
                # e.g.
                # OF 1.1 from switch
                # OF 1.2 from Ryu and supported_ofp_version = (1.0, 1.2)
                # In this case, 1.1 should be used according to the spec,
                # but 1.1 can't be used.
                #
                # OF1.3.1 6.3.1
                # Upon receipt of this message, the recipient must
                # calculate the OpenFlow protocol version to be used. If
                # both the Hello message sent and the Hello message
                # received contained a OFPHET_VERSIONBITMAP hello element,
                # and if those bitmaps have some common bits set, the
                # negotiated version must be the highest version set in
                # both bitmaps. Otherwise, the negotiated version must be
                # the smaller of the version number that was sent and the
                # one that was received in the version fields.  If the
                # negotiated version is supported by the recipient, then
                # the connection proceeds. Otherwise, the recipient must
                # reply with an OFPT_ERROR message with a type field of
                # OFPET_HELLO_FAILED, a code field of OFPHFC_INCOMPATIBLE,
                # and optionally an ASCII string explaining the situation
                # in data, and then terminate the connection.
                version = max(usable_versions)
                error_desc = (
                    'no compatible version found: '
                    'switch 0x%x controller 0x%x, but found usable 0x%x. '
                    'If possible, set the switch to use OF version 0x%x' % (
                        msg.version, datapath.ofproto.OFP_VERSION,
                        version, version))
                self._hello_failed(datapath, error_desc)
                return

        if not usable_versions:
            error_desc = (
                'unsupported version 0x%x. '
                'If possible, set the switch to use one of the versions %s' % (
                    msg.version, sorted(datapath.supported_ofp_version)))
            self._hello_failed(datapath, error_desc)
            return
        datapath.set_version(max(usable_versions))

        # now send feature
        features_reqeust = datapath.ofproto_parser.OFPFeaturesRequest(datapath)
        datapath.send_msg(features_reqeust)

        # now move on to config state
        self.logger.debug('move onto config mode')
        datapath.set_state(CONFIG_DISPATCHER)

    @set_ev_handler(ofp_event.EventOFPSwitchFeatures, CONFIG_DISPATCHER)
    def switch_features_handler(self, ev):
        msg = ev.msg
        datapath = msg.datapath
        self.logger.debug('switch features ev %s', msg)

        datapath.id = msg.datapath_id

        # hacky workaround, will be removed. OF1.3 doesn't have
        # ports. An application should not depend on them. But there
        # might be such bad applications so keep this workaround for
        # while.
        if datapath.ofproto.OFP_VERSION < 0x04:
            datapath.ports = msg.ports
        else:
            datapath.ports = {}

        ofproto = datapath.ofproto
        ofproto_parser = datapath.ofproto_parser
        set_config = ofproto_parser.OFPSetConfig(
            datapath, ofproto.OFPC_FRAG_NORMAL,
            128  # TODO:XXX
        )
        datapath.send_msg(set_config)

        if datapath.ofproto.OFP_VERSION < 0x04:
            self.logger.debug('move onto main mode')
            ev.msg.datapath.set_state(MAIN_DISPATCHER)
        else:
            port_desc = datapath.ofproto_parser.OFPPortDescStatsRequest(
                datapath, 0)
            datapath.send_msg(port_desc)

    @set_ev_handler(ofp_event.EventOFPPortDescStatsReply, CONFIG_DISPATCHER)
    def multipart_reply_handler(self, ev):
        msg = ev.msg
        datapath = msg.datapath
        for port in msg.body:
            datapath.ports[port.port_no] = port

        if msg.flags & datapath.ofproto.OFPMPF_REPLY_MORE:
            return
        self.logger.debug('move onto main mode')
        ev.msg.datapath.set_state(MAIN_DISPATCHER)

    @set_ev_handler(ofp_event.EventOFPEchoRequest,
                    [HANDSHAKE_DISPATCHER, CONFIG_DISPATCHER, MAIN_DISPATCHER])
    def echo_request_handler(self, ev):
        msg = ev.msg
        datapath = msg.datapath
        echo_reply = datapath.ofproto_parser.OFPEchoReply(datapath)
        echo_reply.xid = msg.xid
        echo_reply.data = msg.data
        datapath.send_msg(echo_reply)

    @set_ev_handler(ofp_event.EventOFPErrorMsg,
                    [HANDSHAKE_DISPATCHER, CONFIG_DISPATCHER, MAIN_DISPATCHER])
    def error_msg_handler(self, ev):
        msg = ev.msg
        self.logger.debug('error msg ev %s type 0x%x code 0x%x %s',
                          msg, msg.type, msg.code, utils.hex_array(msg.data))

########NEW FILE########
__FILENAME__ = tunnels
# Copyright (C) 2012 Nippon Telegraph and Telephone Corporation.
# Copyright (C) 2012 Isaku Yamahata <yamahata at private email ne jp>
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import collections
import logging

import ryu.exception as ryu_exc
from ryu.base import app_manager
from ryu.controller import event


class RemoteDPIDAlreadyExist(ryu_exc.RyuException):
    message = ('port (%(dpid)s, %(port)s) has already '
               'remote dpid %(remote_dpid)s')


class TunnelKeyAlreadyExist(ryu_exc.RyuException):
    message = 'tunnel key %(tunnel_key)s already exists'


class TunnelKeyNotFound(ryu_exc.RyuException):
    message = 'no tunnel key for network %(network_id)s'


class EventTunnelKeyBase(event.EventBase):
    def __init__(self, network_id, tunnel_key):
        super(EventTunnelKeyBase, self).__init__()
        self.network_id = network_id
        self.tunnel_key = tunnel_key


class EventTunnelKeyAdd(EventTunnelKeyBase):
    def __init__(self, network_id, tunnel_key):
        super(EventTunnelKeyAdd, self).__init__(network_id, tunnel_key)


class EventTunnelKeyDel(EventTunnelKeyBase):
    def __init__(self, network_id, tunnel_key):
        super(EventTunnelKeyDel, self).__init__(network_id, tunnel_key)


class EventTunnelPort(event.EventBase):
    def __init__(self, dpid, port_no, remote_dpid, add_del):
        super(EventTunnelPort, self).__init__()
        self.dpid = dpid
        self.port_no = port_no
        self.remote_dpid = remote_dpid
        self.add_del = add_del


class TunnelKeys(dict):
    """network id(uuid) <-> tunnel key(32bit unsigned int)"""
    def __init__(self, f):
        super(TunnelKeys, self).__init__()
        self.send_event = f

    def get_key(self, network_id):
        try:
            return self[network_id]
        except KeyError:
            raise TunnelKeyNotFound(network_id=network_id)

    def _set_key(self, network_id, tunnel_key):
        self[network_id] = tunnel_key
        self.send_event(EventTunnelKeyAdd(network_id, tunnel_key))

    def register_key(self, network_id, tunnel_key):
        if network_id in self:
            raise ryu_exc.NetworkAlreadyExist(network_id=network_id)
        if tunnel_key in self.values():
            raise TunnelKeyAlreadyExist(tunnel_key=tunnel_key)
        self._set_key(network_id, tunnel_key)

    def update_key(self, network_id, tunnel_key):
        if network_id not in self and tunnel_key in self.values():
            raise TunnelKeyAlreadyExist(key=tunnel_key)

        key = self.get(network_id)
        if key is None:
            self._set_key(network_id, tunnel_key)
            return
        if key != tunnel_key:
            raise ryu_exc.NetworkAlreadyExist(network_id=network_id)

    def delete_key(self, network_id):
        try:
            tunnel_key = self[network_id]
            self.send_event(EventTunnelKeyDel(network_id, tunnel_key))
            del self[network_id]
        except KeyError:
            raise ryu_exc.NetworkNotFound(network_id=network_id)


class DPIDs(object):
    """dpid -> port_no -> remote_dpid"""
    def __init__(self, f):
        super(DPIDs, self).__init__()
        self.dpids = collections.defaultdict(dict)
        self.send_event = f

    def list_ports(self, dpid):
        return self.dpids[dpid]

    def _add_remote_dpid(self, dpid, port_no, remote_dpid):
        self.dpids[dpid][port_no] = remote_dpid
        self.send_event(EventTunnelPort(dpid, port_no, remote_dpid, True))

    def add_remote_dpid(self, dpid, port_no, remote_dpid):
        if port_no in self.dpids[dpid]:
            raise ryu_exc.PortAlreadyExist(dpid=dpid, port=port_no,
                                           network_id=None)
        self._add_remote_dpid(dpid, port_no, remote_dpid)

    def update_remote_dpid(self, dpid, port_no, remote_dpid):
        remote_dpid_ = self.dpids[dpid].get(port_no)
        if remote_dpid_ is None:
            self._add_remote_dpid(dpid, port_no, remote_dpid)
        elif remote_dpid_ != remote_dpid:
            raise ryu_exc.RemoteDPIDAlreadyExist(dpid=dpid, port=port_no,
                                                 remote_dpid=remote_dpid)

    def get_remote_dpid(self, dpid, port_no):
        try:
            return self.dpids[dpid][port_no]
        except KeyError:
            raise ryu_exc.PortNotFound(dpid=dpid, port=port_no)

    def delete_port(self, dpid, port_no):
        try:
            remote_dpid = self.dpids[dpid][port_no]
            self.send_event(EventTunnelPort(dpid, port_no, remote_dpid, False))
            del self.dpids[dpid][port_no]
        except KeyError:
            raise ryu_exc.PortNotFound(dpid=dpid, port=port_no)

    def get_port(self, dpid, remote_dpid):
        try:
            dp = self.dpids[dpid]
        except KeyError:
            raise ryu_exc.PortNotFound(dpid=dpid, port=None, network_id=None)

        res = [port_no for (port_no, remote_dpid_) in dp.items()
               if remote_dpid_ == remote_dpid]
        assert len(res) <= 1
        if len(res) == 0:
            raise ryu_exc.PortNotFound(dpid=dpid, port=None, network_id=None)
        return res[0]


class Tunnels(app_manager.RyuApp):
    def __init__(self):
        super(Tunnels, self).__init__()
        self.name = 'tunnels'
        self.tunnel_keys = TunnelKeys(self.send_event_to_observers)
        self.dpids = DPIDs(self.send_event_to_observers)

    def get_key(self, network_id):
        return self.tunnel_keys.get_key(network_id)

    def register_key(self, network_id, tunnel_key):
        self.tunnel_keys.register_key(network_id, tunnel_key)

    def update_key(self, network_id, tunnel_key):
        self.tunnel_keys.update_key(network_id, tunnel_key)

    def delete_key(self, network_id):
        self.tunnel_keys.delete_key(network_id)

    def list_ports(self, dpid):
        return self.dpids.list_ports(dpid).keys()

    def register_port(self, dpid, port_no, remote_dpid):
        self.dpids.add_remote_dpid(dpid, port_no, remote_dpid)

    def update_port(self, dpid, port_no, remote_dpid):
        self.dpids.update_remote_dpid(dpid, port_no, remote_dpid)

    def get_remote_dpid(self, dpid, port_no):
        return self.dpids.get_remote_dpid(dpid, port_no)

    def delete_port(self, dpid, port_no):
        self.dpids.delete_port(dpid, port_no)

    #
    # methods for gre tunnel
    #
    def get_port(self, dpid, remote_dpid):
        return self.dpids.get_port(dpid, remote_dpid)

########NEW FILE########
__FILENAME__ = exception
# Copyright (C) 2011 Nippon Telegraph and Telephone Corporation.
# Copyright (C) 2011 Isaku Yamahata <yamahata at valinux co jp>
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.


class RyuException(Exception):
    message = 'An unknown exception'

    def __init__(self, msg=None, **kwargs):
        self.kwargs = kwargs
        if msg is None:
            msg = self.message

        try:
            msg = msg % kwargs
        except Exception:
            msg = self.message

        super(RyuException, self).__init__(msg)


class OFPUnknownVersion(RyuException):
    message = 'unknown version %(version)x'


class OFPMalformedMessage(RyuException):
    message = 'malformed message'


class NetworkNotFound(RyuException):
    message = 'no such network id %(network_id)s'


class NetworkAlreadyExist(RyuException):
    message = 'network id %(network_id)s already exists'


class PortNotFound(RyuException):
    message = 'no such port (%(dpid)s, %(port)s) in network %(network_id)s'


class PortAlreadyExist(RyuException):
    message = 'port (%(dpid)s, %(port)s) in network %(network_id)s ' \
              'already exists'


class PortUnknown(RyuException):
    message = 'unknown network id for port (%(dpid)s %(port)s)'


class MacAddressDuplicated(RyuException):
    message = 'MAC address %(mac)s is duplicated'

########NEW FILE########
__FILENAME__ = flags
# Copyright (C) 2011 Nippon Telegraph and Telephone Corporation.
# Copyright (C) 2011 Isaku Yamahata <yamahata at valinux co jp>
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.
"""
global flags
"""

from oslo.config import cfg

CONF = cfg.CONF

CONF.register_cli_opts([
    # app/quantum_adapter
    cfg.StrOpt('neutron-url', default='http://localhost:9696',
               help='URL for connecting to neutron',
               deprecated_name='quantum-url'),
    cfg.IntOpt('neutron-url-timeout', default=30,
               help='timeout value for connecting to neutron in seconds',
               deprecated_name='quantum-url-timeout'),
    cfg.StrOpt('neutron-admin-username', default='neutron',
               help='username for connecting to neutron in admin context',
               deprecated_name='quantum-admin-username'),
    cfg.StrOpt('neutron-admin-password', default='service_password',
               help='password for connecting to neutron in admin context',
               deprecated_name='quantum-admin-password'),
    cfg.StrOpt('neutron-admin-tenant-name', default='service',
               help='tenant name for connecting to neutron in admin context',
               deprecated_name='quantum-admin-tenant-name'),
    cfg.StrOpt('neutron-admin-auth-url', default='http://localhost:5000/v2.0',
               help='auth url for connecting to neutron in admin context',
               deprecated_name='quantum-admin-auth-url'),
    cfg.StrOpt('neutron-auth-strategy', default='keystone',
               help='auth strategy for connecting to neutron in admin'
               'context',
               deprecated_name='quantum-auth-strategy'),
    cfg.StrOpt('neutron-controller-addr', default=None,
               help='openflow method:address:port to set controller of'
               'ovs bridge',
               deprecated_name='quantum-controller-addr')
])

########NEW FILE########
__FILENAME__ = hooks
# vim: tabstop=4 shiftwidth=4 softtabstop=4

# Copyright 2013 Hewlett-Packard Development Company, L.P.
# All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may
# not use this file except in compliance with the License. You may obtain
# a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
# License for the specific language governing permissions and limitations
# under the License.

import os
import sys
from setuptools.command import easy_install
from ryu import version


# Global variables in this module doesn't work as we expect
# because, during the setup procedure, this module seems to be
# copied (as a file) and can be loaded multiple times.
# We save them into __main__ module instead.
def _main_module():
    return sys.modules['__main__']


def save_orig():
    """Save original easy_install.get_script_args.
    This is necessary because pbr's setup_hook is sometimes called
    before ours."""
    _main_module()._orig_get_script_args = easy_install.get_script_args


def setup_hook(config):
    """Filter config parsed from a setup.cfg to inject our defaults."""
    metadata = config['metadata']
    if sys.platform == 'win32':
        requires = metadata.get('requires_dist', list()).split('\n')
        requires.append('pywin32')
        requires.append('wmi')
        requires.remove('pyudev')
        metadata['requires_dist'] = "\n".join(requires)
    config['metadata'] = metadata

    metadata['version'] = str(version)

    # pbr's setup_hook replaces easy_install.get_script_args with
    # their own version, override_get_script_args, prefering simpler
    # scripts which are not aware of multi-version.
    # prevent that by doing the opposite.  it's a horrible hack
    # but we are in patching wars already...
    from pbr import packaging

    def my_get_script_args(*args, **kwargs):
        return _main_module()._orig_get_script_args(*args, **kwargs)

    packaging.override_get_script_args = my_get_script_args
    easy_install.get_script_args = my_get_script_args

    # another hack to allow setup from tarball.
    orig_get_version = packaging.get_version

    def my_get_version(package_name, pre_version=None):
        if package_name == 'ryu':
            return str(version)
        return orig_get_version(package_name, pre_version)

    packaging.get_version = my_get_version

########NEW FILE########
__FILENAME__ = addrconv
# Copyright (C) 2013 Nippon Telegraph and Telephone Corporation.
# Copyright (C) 2013 YAMAMOTO Takashi <yamamoto at valinux co jp>
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import netaddr


class AddressConverter(object):
    def __init__(self, addr, strat, **kwargs):
        self._addr = addr
        self._strat = strat
        self._addr_kwargs = kwargs

    def text_to_bin(self, text):
        return self._addr(text, **self._addr_kwargs).packed

    def bin_to_text(self, bin):
        return str(self._addr(self._strat.packed_to_int(bin),
                              **self._addr_kwargs))

ipv4 = AddressConverter(netaddr.IPAddress, netaddr.strategy.ipv4, version=4)
ipv6 = AddressConverter(netaddr.IPAddress, netaddr.strategy.ipv6, version=6)


class mac_mydialect(netaddr.mac_unix):
    word_fmt = '%.2x'
mac = AddressConverter(netaddr.EUI, netaddr.strategy.eui48, version=48,
                       dialect=mac_mydialect)

########NEW FILE########
__FILENAME__ = dpid
# Copyright (C) 2012 Nippon Telegraph and Telephone Corporation.
# Copyright (C) 2012 Isaku Yamahata <yamahata at private email ne jp>
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# Internal representation of datapath id is quad int
# string representation is in hex without '0x'

_DPID_LEN = 16
_DPID_LEN_STR = str(_DPID_LEN)
_DPID_FMT = '%0' + _DPID_LEN_STR + 'x'
DPID_PATTERN = r'[0-9a-f]{%d}' % _DPID_LEN


def dpid_to_str(dpid):
    return _DPID_FMT % dpid


def str_to_dpid(dpid_str):
    assert len(dpid_str) == _DPID_LEN
    return int(dpid_str, 16)

########NEW FILE########
__FILENAME__ = hub
# Copyright (C) 2013 Nippon Telegraph and Telephone Corporation.
# Copyright (C) 2013 YAMAMOTO Takashi <yamamoto at valinux co jp>
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import logging
import os


# we don't bother to use cfg.py because monkey patch needs to be
# called very early.  instead, we use an environment variable to
# select the type of hub.
HUB_TYPE = os.getenv('RYU_HUB_TYPE', 'eventlet')

LOG = logging.getLogger('ryu.lib.hub')

if HUB_TYPE == 'eventlet':
    import eventlet
    import eventlet.event
    import eventlet.queue
    import eventlet.timeout
    import eventlet.wsgi
    import greenlet
    import ssl
    import socket
    import traceback

    getcurrent = eventlet.getcurrent
    patch = eventlet.monkey_patch
    sleep = eventlet.sleep

    def spawn(*args, **kwargs):
        def _launch(func, *args, **kwargs):
            # mimic gevent's default raise_error=False behaviour
            # by not propergating an exception to the joiner.
            try:
                func(*args, **kwargs)
            except greenlet.GreenletExit:
                pass
            except:
                # log uncaught exception.
                # note: this is an intentional divergence from gevent
                # behaviour.  gevent silently ignores such exceptions.
                LOG.error('hub: uncaught exception: %s',
                          traceback.format_exc())

        return eventlet.spawn(_launch, *args, **kwargs)

    def kill(thread):
        thread.kill()

    def joinall(threads):
        for t in threads:
            # this try-except is necessary when killing an inactive
            # greenthread
            try:
                t.wait()
            except greenlet.GreenletExit:
                pass

    Queue = eventlet.queue.Queue
    QueueEmpty = eventlet.queue.Empty

    class StreamServer(object):
        def __init__(self, listen_info, handle=None, backlog=None,
                     spawn='default', **ssl_args):
            assert backlog is None
            assert spawn == 'default'

            if ':' in listen_info[0]:
                self.server = eventlet.listen(listen_info,
                                              family=socket.AF_INET6)
            else:
                self.server = eventlet.listen(listen_info)
            if ssl_args:
                def wrap_and_handle(sock, addr):
                    ssl_args.setdefault('server_side', True)
                    handle(ssl.wrap_socket(sock, **ssl_args), addr)

                self.handle = wrap_and_handle
            else:
                self.handle = handle

        def serve_forever(self):
            while True:
                sock, addr = self.server.accept()
                spawn(self.handle, sock, addr)

    class WSGIServer(StreamServer):
        def serve_forever(self):
            eventlet.wsgi.server(self.server, self.handle)

    Timeout = eventlet.timeout.Timeout

    class Event(object):
        def __init__(self):
            self._ev = eventlet.event.Event()
            self._cond = False

        def _wait(self, timeout=None):
            while not self._cond:
                self._ev.wait()

        def _broadcast(self):
            self._ev.send()
            # because eventlet Event doesn't allow mutiple send() on an event,
            # re-create the underlying event.
            # note: _ev.reset() is obsolete.
            self._ev = eventlet.event.Event()

        def set(self):
            self._cond = True
            self._broadcast()

        def clear(self):
            self._cond = False

        def wait(self, timeout=None):
            if timeout is None:
                self._wait()
            else:
                try:
                    with Timeout(timeout):
                        self._wait()
                except Timeout:
                    pass

            return self._cond

########NEW FILE########
__FILENAME__ = ip
from ryu.lib import addrconv


def ipv4_to_bin(ip):
    '''
        Parse an IP address and return an unsigned int.
        The IP address is in dotted decimal notation.
    '''
    return addrconv.ipv4.text_to_bin(ip)


def ipv4_to_str(ip):
    """Generate IP address string from an unsigned int.
       ip: unsigned int of form w << 24 | x << 16 | y << 8 | z
       returns: ip address string w.x.y.z"""
    return addrconv.ipv4.bin_to_text(ip)


def ipv6_to_bin(ipv6):
    '''
        convert ipv6 string to binary representation
    '''
    return addrconv.ipv6.text_to_bin(ipv6)


def ipv6_to_str(bin_addr):
    '''
        convert binary representation to human readable string
    '''
    return addrconv.ipv6.bin_to_text(bin_addr)

########NEW FILE########
__FILENAME__ = lacplib
# Copyright (C) 2013 Nippon Telegraph and Telephone Corporation.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import logging

from ryu.base import app_manager
from ryu.controller import event
from ryu.controller import ofp_event
from ryu.controller.handler import MAIN_DISPATCHER
from ryu.controller.handler import set_ev_cls
from ryu.ofproto import ether
from ryu.ofproto import ofproto_v1_0
from ryu.ofproto import ofproto_v1_2
from ryu.ofproto import ofproto_v1_3
from ryu.lib import addrconv
from ryu.lib.dpid import dpid_to_str
from ryu.lib.packet import packet
from ryu.lib.packet import ethernet
from ryu.lib.packet import slow


LAG_EV_DISPATCHER = "lacplib"


class EventPacketIn(event.EventBase):
    """a PacketIn event class using except LACP."""
    def __init__(self, msg):
        """initialization."""
        super(EventPacketIn, self).__init__()
        self.msg = msg


class EventSlaveStateChanged(event.EventBase):
    """a event class that notifies the changes of the statuses of the
    slave i/fs."""
    def __init__(self, datapath, port, enabled):
        """initialization."""
        super(EventSlaveStateChanged, self).__init__()
        self.datapath = datapath
        self.port = port
        self.enabled = enabled


class LacpLib(app_manager.RyuApp):
    """LACP exchange library. this works only in a PASSIVE mode."""

    #-------------------------------------------------------------------
    # PUBLIC METHODS
    #-------------------------------------------------------------------
    def __init__(self):
        """initialization."""
        super(LacpLib, self).__init__()
        self.name = 'lacplib'
        self._bonds = []
        self._add_flow = {
            ofproto_v1_0.OFP_VERSION: self._add_flow_v1_0,
            ofproto_v1_2.OFP_VERSION: self._add_flow_v1_2,
            ofproto_v1_3.OFP_VERSION: self._add_flow_v1_2,
        }
        self._set_logger()

    def add(self, dpid, ports):
        """add a setting of a bonding i/f.
        'add' method takes the corresponding args in this order.

        ========= =====================================================
        Attribute Description
        ========= =====================================================
        dpid      datapath id.

        ports     a list of integer values that means the ports face
                  with the slave i/fs.
        ========= =====================================================

        if you want to use multi LAG, call 'add' method more than once.
        """
        assert isinstance(ports, list)
        assert 2 <= len(ports)
        ifs = {}
        for port in ports:
            ifs[port] = {'enabled': False, 'timeout': 0}
        bond = {}
        bond[dpid] = ifs
        self._bonds.append(bond)

    #-------------------------------------------------------------------
    # PUBLIC METHODS ( EVENT HANDLERS )
    #-------------------------------------------------------------------
    @set_ev_cls(ofp_event.EventOFPPacketIn, MAIN_DISPATCHER)
    def packet_in_handler(self, evt):
        """PacketIn event handler. when the received packet was LACP,
        proceed it. otherwise, send a event."""
        req_pkt = packet.Packet(evt.msg.data)
        if slow.lacp in req_pkt:
            (req_lacp, ) = req_pkt.get_protocols(slow.lacp)
            (req_eth, ) = req_pkt.get_protocols(ethernet.ethernet)
            self._do_lacp(req_lacp, req_eth.src, evt.msg)
        else:
            self.send_event_to_observers(EventPacketIn(evt.msg))

    @set_ev_cls(ofp_event.EventOFPFlowRemoved, MAIN_DISPATCHER)
    def flow_removed_handler(self, evt):
        """FlowRemoved event handler. when the removed flow entry was
        for LACP, set the status of the slave i/f to disabled, and
        send a event."""
        msg = evt.msg
        datapath = msg.datapath
        ofproto = datapath.ofproto
        dpid = datapath.id
        match = msg.match
        if ofproto.OFP_VERSION == ofproto_v1_0.OFP_VERSION:
            port = match.in_port
            dl_type = match.dl_type
        else:
            port = match['in_port']
            dl_type = match['eth_type']
        if ether.ETH_TYPE_SLOW != dl_type:
            return
        self.logger.info(
            "SW=%s PORT=%d LACP exchange timeout has occurred.",
            dpid_to_str(dpid), port)
        self._set_slave_enabled(dpid, port, False)
        self._set_slave_timeout(dpid, port, 0)
        self.send_event_to_observers(
            EventSlaveStateChanged(datapath, port, False))

    #-------------------------------------------------------------------
    # PRIVATE METHODS ( RELATED TO LACP )
    #-------------------------------------------------------------------
    def _do_lacp(self, req_lacp, src, msg):
        """packet-in process when the received packet is LACP."""
        datapath = msg.datapath
        dpid = datapath.id
        ofproto = datapath.ofproto
        parser = datapath.ofproto_parser
        if ofproto.OFP_VERSION == ofproto_v1_0.OFP_VERSION:
            port = msg.in_port
        else:
            port = msg.match['in_port']

        self.logger.info("SW=%s PORT=%d LACP received.",
                         dpid_to_str(dpid), port)
        self.logger.debug(str(req_lacp))

        # when LACP arrived at disabled port, update the status of
        # the slave i/f to enabled, and send a event.
        if not self._get_slave_enabled(dpid, port):
            self.logger.info(
                "SW=%s PORT=%d the slave i/f has just been up.",
                dpid_to_str(dpid), port)
            self._set_slave_enabled(dpid, port, True)
            self.send_event_to_observers(
                EventSlaveStateChanged(datapath, port, True))

        # set the idle_timeout time using the actor state of the
        # received packet.
        if req_lacp.LACP_STATE_SHORT_TIMEOUT == \
           req_lacp.actor_state_timeout:
            idle_timeout = req_lacp.SHORT_TIMEOUT_TIME
        else:
            idle_timeout = req_lacp.LONG_TIMEOUT_TIME

        # when the timeout time has changed, update the timeout time of
        # the slave i/f and re-enter a flow entry for the packet from
        # the slave i/f with idle_timeout.
        if idle_timeout != self._get_slave_timeout(dpid, port):
            self.logger.info(
                "SW=%s PORT=%d the timeout time has changed.",
                dpid_to_str(dpid), port)
            self._set_slave_timeout(dpid, port, idle_timeout)
            func = self._add_flow.get(ofproto.OFP_VERSION)
            assert func
            func(src, port, idle_timeout, datapath)

        # create a response packet.
        res_pkt = self._create_response(datapath, port, req_lacp)

        # packet-out the response packet.
        out_port = ofproto.OFPP_IN_PORT
        actions = [parser.OFPActionOutput(out_port)]
        out = datapath.ofproto_parser.OFPPacketOut(
            datapath=datapath, buffer_id=ofproto.OFP_NO_BUFFER,
            data=res_pkt.data, in_port=port, actions=actions)
        datapath.send_msg(out)

    def _create_response(self, datapath, port, req):
        """create a packet including LACP."""
        src = datapath.ports[port].hw_addr
        res_ether = ethernet.ethernet(
            slow.SLOW_PROTOCOL_MULTICAST, src, ether.ETH_TYPE_SLOW)
        res_lacp = self._create_lacp(datapath, port, req)
        res_pkt = packet.Packet()
        res_pkt.add_protocol(res_ether)
        res_pkt.add_protocol(res_lacp)
        res_pkt.serialize()
        return res_pkt

    def _create_lacp(self, datapath, port, req):
        """create a LACP packet."""
        actor_system = datapath.ports[datapath.ofproto.OFPP_LOCAL].hw_addr
        res = slow.lacp(
            actor_system_priority=0xffff,
            actor_system=actor_system,
            actor_key=req.actor_key,
            actor_port_priority=0xff,
            actor_port=port,
            actor_state_activity=req.LACP_STATE_PASSIVE,
            actor_state_timeout=req.actor_state_timeout,
            actor_state_aggregation=req.actor_state_aggregation,
            actor_state_synchronization=req.actor_state_synchronization,
            actor_state_collecting=req.actor_state_collecting,
            actor_state_distributing=req.actor_state_distributing,
            actor_state_defaulted=req.LACP_STATE_OPERATIONAL_PARTNER,
            actor_state_expired=req.LACP_STATE_NOT_EXPIRED,
            partner_system_priority=req.actor_system_priority,
            partner_system=req.actor_system,
            partner_key=req.actor_key,
            partner_port_priority=req.actor_port_priority,
            partner_port=req.actor_port,
            partner_state_activity=req.actor_state_activity,
            partner_state_timeout=req.actor_state_timeout,
            partner_state_aggregation=req.actor_state_aggregation,
            partner_state_synchronization=req.actor_state_synchronization,
            partner_state_collecting=req.actor_state_collecting,
            partner_state_distributing=req.actor_state_distributing,
            partner_state_defaulted=req.actor_state_defaulted,
            partner_state_expired=req.actor_state_expired,
            collector_max_delay=0)
        self.logger.info("SW=%s PORT=%d LACP sent.",
                         dpid_to_str(datapath.id), port)
        self.logger.debug(str(res))
        return res

    def _get_slave_enabled(self, dpid, port):
        """get whether a slave i/f at some port of some datapath is
        enable or not."""
        slave = self._get_slave(dpid, port)
        if slave:
            return slave['enabled']
        else:
            return False

    def _set_slave_enabled(self, dpid, port, enabled):
        """set whether a slave i/f at some port of some datapath is
        enable or not."""
        slave = self._get_slave(dpid, port)
        if slave:
            slave['enabled'] = enabled

    def _get_slave_timeout(self, dpid, port):
        """get the timeout time at some port of some datapath."""
        slave = self._get_slave(dpid, port)
        if slave:
            return slave['timeout']
        else:
            return 0

    def _set_slave_timeout(self, dpid, port, timeout):
        """set the timeout time at some port of some datapath."""
        slave = self._get_slave(dpid, port)
        if slave:
            slave['timeout'] = timeout

    def _get_slave(self, dpid, port):
        """get slave i/f at some port of some datapath."""
        result = None
        for bond in self._bonds:
            if dpid in bond:
                if port in bond[dpid]:
                    result = bond[dpid][port]
                    break
        return result

    #-------------------------------------------------------------------
    # PRIVATE METHODS ( RELATED TO OPEN FLOW PROTOCOL )
    #-------------------------------------------------------------------
    def _add_flow_v1_0(self, src, port, timeout, datapath):
        """enter a flow entry for the packet from the slave i/f
        with idle_timeout. for OpenFlow ver1.0."""
        ofproto = datapath.ofproto
        parser = datapath.ofproto_parser

        match = parser.OFPMatch(
            in_port=port, dl_src=addrconv.mac.text_to_bin(src),
            dl_type=ether.ETH_TYPE_SLOW)
        actions = [parser.OFPActionOutput(
            ofproto.OFPP_CONTROLLER, 65535)]
        mod = parser.OFPFlowMod(
            datapath=datapath, match=match, cookie=0,
            command=ofproto.OFPFC_ADD, idle_timeout=timeout,
            priority=65535, flags=ofproto.OFPFF_SEND_FLOW_REM,
            actions=actions)
        datapath.send_msg(mod)

    def _add_flow_v1_2(self, src, port, timeout, datapath):
        """enter a flow entry for the packet from the slave i/f
        with idle_timeout. for OpenFlow ver1.2 and ver1.3."""
        ofproto = datapath.ofproto
        parser = datapath.ofproto_parser

        match = parser.OFPMatch(
            in_port=port, eth_src=src, eth_type=ether.ETH_TYPE_SLOW)
        actions = [parser.OFPActionOutput(
            ofproto.OFPP_CONTROLLER, ofproto.OFPCML_MAX)]
        inst = [parser.OFPInstructionActions(
            ofproto.OFPIT_APPLY_ACTIONS, actions)]
        mod = parser.OFPFlowMod(
            datapath=datapath, command=ofproto.OFPFC_ADD,
            idle_timeout=timeout, priority=65535,
            flags=ofproto.OFPFF_SEND_FLOW_REM, match=match,
            instructions=inst)
        datapath.send_msg(mod)

    #-------------------------------------------------------------------
    # PRIVATE METHODS ( OTHERS )
    #-------------------------------------------------------------------
    def _set_logger(self):
        """change log format."""
        self.logger.propagate = False
        hdl = logging.StreamHandler()
        fmt_str = '[LACP][%(levelname)s] %(message)s'
        hdl.setFormatter(logging.Formatter(fmt_str))
        self.logger.addHandler(hdl)

########NEW FILE########
__FILENAME__ = mac
# Copyright (C) 2011 Nippon Telegraph and Telephone Corporation.
# Copyright (C) 2011 Isaku Yamahata <yamahata at valinux co jp>
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from ryu.lib import addrconv

import itertools

# string representation
HADDR_PATTERN = r'([0-9a-f]{2}:){5}[0-9a-f]{2}'

DONTCARE = '\x00' * 6
BROADCAST = '\xff' * 6
DONTCARE_STR = '00:00:00:00:00:00'
BROADCAST_STR = 'ff:ff:ff:ff:ff:ff'
MULTICAST = 'fe:ff:ff:ff:ff:ff'
UNICAST = '01:00:00:00:00:00'


def is_multicast(addr):
    return bool(ord(addr[0]) & 0x01)


def haddr_to_str(addr):
    """Format mac address in internal representation into human readable
    form"""
    if addr is None:
        return 'None'
    try:
        return addrconv.mac.bin_to_text(addr)
    except:
        raise AssertionError


def haddr_to_bin(string):
    """Parse mac address string in human readable format into
    internal representation"""
    try:
        return addrconv.mac.text_to_bin(string)
    except:
        raise ValueError


def haddr_bitand(addr, mask):
    return ''.join(chr(ord(a) & ord(m)) for (a, m)
                   in itertools.izip(addr, mask))

########NEW FILE########
__FILENAME__ = constants
# Copyright (C) 2013 Nippon Telegraph and Telephone Corporation.
# Copyright (C) 2013 Isaku Yamahata <yamahata at valinux co jp>
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# based on netconf.xsd

# rpc
RPC = 'rpc'
MESSAGE_ID = 'message-id'      # message-id attribute

# error
TRANSPORT = 'transport'
PROTOCOL = 'protocol'
APPLICATION = 'application'

# error-tag
IN_USE = 'in-use'
INVALID_VALUE = 'invalid-value'
TOO_BIG = 'too-big'
MISSING_ATTRIBUTE = 'missing-attribute'
BAD_ATTRIBUTE = 'bad-attribute'
UNKNOWN_ATTRIBUTE = 'unknown-attribute'
MISSING_ELEMENT = 'missing-element'
BAD_ELEMENT = 'bad-element'
UNKNOWN_ELEMENT = 'unknown-element'
UNKNOWN_NAMESPACE = 'unknown-namespace'
ACCESS_DENIED = 'access-denied'
LOCK_DENIED = 'lock-denied'
RESOURCE_DENIED = 'resource-denied'
ROLLBACK_FAILED = 'rollback-failed'
DATA_EXISTS = 'data-exists'
DATA_MISSING = 'data-missing'
OPERATION_NOT_SUPPORTED = 'operation-not-supported'
OPERATION_FAILED = 'operation-failed'
PARTIAL_OPERATION = 'partial-operation'
MALFORMED_MESSAGE = 'malformed-message'

# error-severity
ERROR = 'error'
WARNING = 'warning'

# error-info
# bad-element and ok-element are defined above
BAD_ATTRIBUTE = 'bad-attribute'
# BAD_ELEMENT = 'bad-element'
# OK_ELEMENT = 'ok-element'
ERR_ELEMENT = 'err-element'
NOOP_ELEMENT = 'noop-element'
BAD_NAMESPACE = 'bad-namespace'

# rpc-error
ERROR_TYPE = 'error-type'
ERROR_TAG = 'error-tag'
ERROR_SEVERITY = 'error-severity'
ERROR_APP_TAG = 'error-app-tag'
ERROR_PATH = 'error-path'
ERROR_MESSAGE = 'error-message'
ERROR_INFO = 'error-info'

# edit-operation
OPERATION = 'operation'         # operation attribute
MERGE = 'merge'
REPLACE = 'replace'
CREATE = 'create'
DELETE = 'delete'
REMOVE = 'remove'

# default-operation
# merge and replace are defined above
# MERGE = 'merge'
# REPLACE = 'replace'
NONE = 'none'
DEFAULT_OPERATION = 'default-operation'

# rpc-reply
OK = 'ok'
RPC_REPLY = 'rpc-reply'

# data-inline
DATA = 'data'
RPC_ERROR = 'rpc-error'

# rpc-operation
RPCOPERATION = 'rpcOperation'

# rpc-response
RPCRESPONSE = 'rpcResponse'
HELLO = 'hello'
CAPABILITIES = 'capabilities'
CAPABILITY = 'capability'

# config-inline
CONFIG = 'config'

# config-name
CONFIG_NAME = 'config-name'
STARTUP = 'startup'
CANDIDATE = 'candidate'
RUNNING = 'running'

# config-uri
URL = 'url'

# rpc-operation-source
SOURCE = 'source'

# rpc-operation-target
TARGET = 'target'

# filter
SUBTREE = 'subtree'
XPATH = 'xpath'

# filter-inline
TYPE = 'type'           # type attribute
FILTER = 'filter'

# test-option
TEST_THEN_SET = 'test-then-set'
SET = 'set'
TEST_OPTION = 'test-option'

# error-option
STOP_ON_ERROR = 'stop-on-error'
IGNORE_ERROR = 'ignore-error'
ROLLBACK_ON_ERROR = 'rollback-on-error'
ERROR_OPTION = 'error-option'

# get
GET = 'get'

# get-config
GET_CONFIG = 'get-config'

# edit-config
EDIT_CONFIG = 'edit-config'

# copy-config
COPY_CONFIG = 'copy-config'

# delete-config
DELETE_CONFIG = 'delete-config'

# lock
LOCK = 'lock'

# unlock
UNLOCK = 'unlock'

# validate
VALIDATE = 'validate'

# commit
CONFIRMED = 'confirmed'
CONFIRM_TIMEOUT = 'confirm-timeout'
PERSIST = 'persist'
PERSIST_ID = 'persist-id'
COMMIT = 'commit'

# cancel-commit
# persist-id is defined above
# PERSIST_ID = 'persist-id'
CANCEL_COMMIT = 'cancel-commit'

# discard-changes
DISCARD_CHANGES = 'discard-changes'

# close-session
CLOSE_SESSION = 'close-session'

# kill-session
KILL_SESSION = 'kill-session'

########NEW FILE########
__FILENAME__ = ofctl_v1_0
# Copyright (C) 2012 Nippon Telegraph and Telephone Corporation.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import struct
import socket
import logging

from ryu.ofproto import ofproto_v1_0
from ryu.lib import hub
from ryu.lib.mac import haddr_to_bin, haddr_to_str


LOG = logging.getLogger('ryu.lib.ofctl_v1_0')

DEFAULT_TIMEOUT = 1.0   # TODO:XXX


def to_actions(dp, acts):
    actions = []
    for a in acts:
        action_type = a.get('type')
        if action_type == 'OUTPUT':
            out_port = int(a.get('port', ofproto_v1_0.OFPP_NONE))
            if out_port == dp.ofproto.OFPP_CONTROLLER:
                miss_send_len = ofproto_v1_0.OFP_DEFAULT_MISS_SEND_LEN
                actions.append(dp.ofproto_parser.OFPActionOutput(
                    out_port, max_len=miss_send_len))
            else:
                actions.append(dp.ofproto_parser.OFPActionOutput(out_port))
        elif action_type == 'SET_VLAN_VID':
            vlan_vid = int(a.get('vlan_vid', 0xffff))
            actions.append(dp.ofproto_parser.OFPActionVlanVid(vlan_vid))
        elif action_type == 'SET_VLAN_PCP':
            vlan_pcp = int(a.get('vlan_pcp', 0))
            actions.append(dp.ofproto_parser.OFPActionVlanPcp(vlan_pcp))
        elif action_type == 'STRIP_VLAN':
            actions.append(dp.ofproto_parser.OFPActionStripVlan())
        elif action_type == 'SET_DL_SRC':
            dl_src = haddr_to_bin(a.get('dl_src'))
            actions.append(dp.ofproto_parser.OFPActionSetDlSrc(dl_src))
        elif action_type == 'SET_DL_DST':
            dl_dst = haddr_to_bin(a.get('dl_dst'))
            actions.append(dp.ofproto_parser.OFPActionSetDlDst(dl_dst))
        else:
            LOG.debug('Unknown action type')

    return actions


def actions_to_str(acts):
    actions = []
    for a in acts:
        action_type = a.cls_action_type

        if action_type == ofproto_v1_0.OFPAT_OUTPUT:
            buf = 'OUTPUT:' + str(a.port)
        elif action_type == ofproto_v1_0.OFPAT_SET_VLAN_VID:
            buf = 'SET_VLAN_VID:' + str(a.vlan_vid)
        elif action_type == ofproto_v1_0.OFPAT_SET_VLAN_PCP:
            buf = 'SET_VLAN_PCP:' + str(a.vlan_pcp)
        elif action_type == ofproto_v1_0.OFPAT_STRIP_VLAN:
            buf = 'STRIP_VLAN'
        elif action_type == ofproto_v1_0.OFPAT_SET_DL_SRC:
            buf = 'SET_DL_SRC:' + haddr_to_str(a.dl_addr)
        elif action_type == ofproto_v1_0.OFPAT_SET_DL_DST:
            buf = 'SET_DL_DST:' + haddr_to_str(a.dl_addr)
        else:
            buf = 'UNKNOWN'
        actions.append(buf)

    return actions


def to_match(dp, attrs):
    ofp = dp.ofproto

    wildcards = ofp.OFPFW_ALL
    in_port = 0
    dl_src = 0
    dl_dst = 0
    dl_vlan = 0
    dl_vlan_pcp = 0
    dl_type = 0
    nw_tos = 0
    nw_proto = 0
    nw_src = 0
    nw_dst = 0
    tp_src = 0
    tp_dst = 0

    for key, value in attrs.items():
        if key == 'in_port':
            in_port = int(value)
            wildcards &= ~ofp.OFPFW_IN_PORT
        elif key == 'dl_src':
            dl_src = haddr_to_bin(value)
            wildcards &= ~ofp.OFPFW_DL_SRC
        elif key == 'dl_dst':
            dl_dst = haddr_to_bin(value)
            wildcards &= ~ofp.OFPFW_DL_DST
        elif key == 'dl_vlan':
            dl_vlan = int(value)
            wildcards &= ~ofp.OFPFW_DL_VLAN
        elif key == 'dl_vlan_pcp':
            dl_vlan_pcp = int(value)
            wildcards &= ~ofp.OFPFW_DL_VLAN_PCP
        elif key == 'dl_type':
            dl_type = int(value)
            wildcards &= ~ofp.OFPFW_DL_TYPE
        elif key == 'nw_tos':
            nw_tos = int(value)
            wildcards &= ~ofp.OFPFW_NW_TOS
        elif key == 'nw_proto':
            nw_proto = int(value)
            wildcards &= ~ofp.OFPFW_NW_PROTO
        elif key == 'nw_src':
            ip = value.split('/')
            nw_src = struct.unpack('!I', socket.inet_aton(ip[0]))[0]
            mask = 32
            if len(ip) == 2:
                mask = int(ip[1])
                assert 0 < mask <= 32
            v = (32 - mask) << ofp.OFPFW_NW_SRC_SHIFT | \
                ~ofp.OFPFW_NW_SRC_MASK
            wildcards &= v
        elif key == 'nw_dst':
            ip = value.split('/')
            nw_dst = struct.unpack('!I', socket.inet_aton(ip[0]))[0]
            mask = 32
            if len(ip) == 2:
                mask = int(ip[1])
                assert 0 < mask <= 32
            v = (32 - mask) << ofp.OFPFW_NW_DST_SHIFT | \
                ~ofp.OFPFW_NW_DST_MASK
            wildcards &= v
        elif key == 'tp_src':
            tp_src = int(value)
            wildcards &= ~ofp.OFPFW_TP_SRC
        elif key == 'tp_dst':
            tp_dst = int(value)
            wildcards &= ~ofp.OFPFW_TP_DST
        else:
            LOG.debug("unknown match name %s, %s, %d", key, value, len(key))

    match = dp.ofproto_parser.OFPMatch(
        wildcards, in_port, dl_src, dl_dst, dl_vlan, dl_vlan_pcp,
        dl_type, nw_tos, nw_proto, nw_src, nw_dst, tp_src, tp_dst)

    return match


def match_to_str(m):
    return {'dl_dst': haddr_to_str(m.dl_dst),
            'dl_src': haddr_to_str(m.dl_src),
            'dl_type': m.dl_type,
            'dl_vlan': m.dl_vlan,
            'dl_vlan_pcp': m.dl_vlan_pcp,
            'in_port': m.in_port,
            'nw_dst': nw_dst_to_str(m.wildcards, m.nw_dst),
            'nw_proto': m.nw_proto,
            'nw_src': nw_src_to_str(m.wildcards, m.nw_src),
            'tp_src': m.tp_src,
            'tp_dst': m.tp_dst}


def nw_src_to_str(wildcards, addr):
    ip = socket.inet_ntoa(struct.pack('!I', addr))
    mask = 32 - ((wildcards & ofproto_v1_0.OFPFW_NW_SRC_MASK)
                 >> ofproto_v1_0.OFPFW_NW_SRC_SHIFT)
    if mask == 32:
        mask = 0
    if mask:
        ip += '/%d' % mask
    return ip


def nw_dst_to_str(wildcards, addr):
    ip = socket.inet_ntoa(struct.pack('!I', addr))
    mask = 32 - ((wildcards & ofproto_v1_0.OFPFW_NW_DST_MASK)
                 >> ofproto_v1_0.OFPFW_NW_DST_SHIFT)
    if mask == 32:
        mask = 0
    if mask:
        ip += '/%d' % mask
    return ip


def send_stats_request(dp, stats, waiters, msgs):
    dp.set_xid(stats)
    waiters_per_dp = waiters.setdefault(dp.id, {})
    lock = hub.Event()
    waiters_per_dp[stats.xid] = (lock, msgs)
    dp.send_msg(stats)

    try:
        lock.wait(timeout=DEFAULT_TIMEOUT)
    except hub.Timeout:
        del waiters_per_dp[stats.xid]


def get_desc_stats(dp, waiters):
    stats = dp.ofproto_parser.OFPDescStatsRequest(dp, 0)
    msgs = []
    send_stats_request(dp, stats, waiters, msgs)

    for msg in msgs:
        stats = msg.body
        s = {'mfr_desc': stats.mfr_desc,
             'hw_desc': stats.hw_desc,
             'sw_desc': stats.sw_desc,
             'serial_num': stats.serial_num,
             'dp_desc': stats.dp_desc}
    desc = {str(dp.id): s}
    return desc


def get_flow_stats(dp, waiters):
    match = dp.ofproto_parser.OFPMatch(
        dp.ofproto.OFPFW_ALL, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0)
    stats = dp.ofproto_parser.OFPFlowStatsRequest(
        dp, 0, match, 0xff, dp.ofproto.OFPP_NONE)
    msgs = []
    send_stats_request(dp, stats, waiters, msgs)

    flows = []
    for msg in msgs:
        for stats in msg.body:
            actions = actions_to_str(stats.actions)
            match = match_to_str(stats.match)

            s = {'priority': stats.priority,
                 'cookie': stats.cookie,
                 'idle_timeout': stats.idle_timeout,
                 'hard_timeout': stats.hard_timeout,
                 'actions': actions,
                 'match': match,
                 'byte_count': stats.byte_count,
                 'duration_sec': stats.duration_sec,
                 'duration_nsec': stats.duration_nsec,
                 'packet_count': stats.packet_count,
                 'table_id': stats.table_id}
            flows.append(s)
    flows = {str(dp.id): flows}
    return flows


def get_port_stats(dp, waiters):
    stats = dp.ofproto_parser.OFPPortStatsRequest(
        dp, 0, dp.ofproto.OFPP_NONE)
    msgs = []
    send_stats_request(dp, stats, waiters, msgs)

    ports = []
    for msg in msgs:
        for stats in msg.body:
            s = {'port_no': stats.port_no,
                 'rx_packets': stats.rx_packets,
                 'tx_packets': stats.tx_packets,
                 'rx_bytes': stats.rx_bytes,
                 'tx_bytes': stats.tx_bytes,
                 'rx_dropped': stats.rx_dropped,
                 'tx_dropped': stats.tx_dropped,
                 'rx_errors': stats.rx_errors,
                 'tx_errors': stats.tx_errors,
                 'rx_frame_err': stats.rx_frame_err,
                 'rx_over_err': stats.rx_over_err,
                 'rx_crc_err': stats.rx_crc_err,
                 'collisions': stats.collisions}
            ports.append(s)
    ports = {str(dp.id): ports}
    return ports


def mod_flow_entry(dp, flow, cmd):
    cookie = int(flow.get('cookie', 0))
    priority = int(flow.get('priority',
                            dp.ofproto.OFP_DEFAULT_PRIORITY))
    flags = int(flow.get('flags', 0))
    idle_timeout = int(flow.get('idle_timeout', 0))
    hard_timeout = int(flow.get('hard_timeout', 0))
    actions = to_actions(dp, flow.get('actions', []))
    match = to_match(dp, flow.get('match', {}))

    flow_mod = dp.ofproto_parser.OFPFlowMod(
        datapath=dp, match=match, cookie=cookie,
        command=cmd, idle_timeout=idle_timeout,
        hard_timeout=hard_timeout, priority=priority, flags=flags,
        actions=actions)

    dp.send_msg(flow_mod)


def delete_flow_entry(dp):
    match = dp.ofproto_parser.OFPMatch(
        dp.ofproto.OFPFW_ALL, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0)

    flow_mod = dp.ofproto_parser.OFPFlowMod(
        datapath=dp, match=match, cookie=0,
        command=dp.ofproto.OFPFC_DELETE)

    dp.send_msg(flow_mod)

########NEW FILE########
__FILENAME__ = ofctl_v1_2
# Copyright (C) 2013 Nippon Telegraph and Telephone Corporation.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import struct
import socket
import logging

from ryu.ofproto import inet
from ryu.ofproto import ofproto_v1_2
from ryu.ofproto import ofproto_v1_2_parser
from ryu.lib import hub
from ryu.lib import mac


LOG = logging.getLogger('ryu.lib.ofctl_v1_2')

DEFAULT_TIMEOUT = 1.0


def to_actions(dp, acts):
    inst = []

    for a in acts:
        action_type = a.get('type')
        if action_type == 'OUTPUT':
            out_port = int(a.get('port', ofproto_v1_2.OFPP_ANY))
            miss_send_len = (128 if out_port == dp.ofproto.OFPP_CONTROLLER
                             else 0)
            actions = [dp.ofproto_parser.OFPActionOutput(
                       out_port, max_len=miss_send_len)]
            inst_type = dp.ofproto.OFPIT_APPLY_ACTIONS
            inst = [dp.ofproto_parser.OFPInstructionActions(
                    inst_type, actions)]
        else:
            LOG.debug('Unknown action type')

    return inst


def actions_to_str(instructions):
    actions = []

    for instruction in instructions:
        if not isinstance(instruction,
                          ofproto_v1_2_parser.OFPInstructionActions):
            continue
        for a in instruction.actions:
            action_type = a.cls_action_type

            if action_type == ofproto_v1_2.OFPAT_OUTPUT:
                buf = 'OUTPUT:' + str(a.port)
            else:
                buf = 'UNKNOWN'
            actions.append(buf)

    return actions


def to_match(dp, attrs):
    match = dp.ofproto_parser.OFPMatch()

    convert = {'in_port': int,
               'dl_src': mac.haddr_to_bin,
               'dl_dst': mac.haddr_to_bin,
               'dl_type': int,
               'dl_vlan': int,
               'nw_src': to_match_ip,
               'nw_dst': to_match_ip,
               'nw_proto': int,
               'tp_src': int,
               'tp_dst': int}

    match_append = {'in_port': match.set_in_port,
                    'dl_src': match.set_dl_src,
                    'dl_dst': match.set_dl_dst,
                    'dl_type': match.set_dl_type,
                    'dl_vlan': match.set_vlan_vid,
                    'nw_src': match.set_ipv4_src_masked,
                    'nw_dst': match.set_ipv4_dst_masked,
                    'nw_proto': match.set_ip_proto,
                    'tp_src': to_match_tpsrc,
                    'tp_dst': to_match_tpdst}

    for key, value in attrs.items():
        if key in convert:
            value = convert[key](value)
        if key in match_append:
            if key == 'nw_src' or key == 'nw_dst':
                # IP address
                ip = value[0]
                mask = value[1]
                match_append[key](ip, mask)
            elif key == 'tp_src' or key == 'tp_dst':
                # tp_src/dst
                match = match_append[key](value, match, attrs)
            else:
                # others
                match_append[key](value)

    return match


def to_match_tpsrc(value, match, rest):
    match_append = {inet.IPPROTO_TCP: match.set_tcp_src,
                    inet.IPPROTO_UDP: match.set_udp_src}

    nw_proto = rest.get('nw_proto', 0)
    if nw_proto in match_append:
        match_append[nw_proto](value)

    return match


def to_match_tpdst(value, match, rest):
    match_append = {inet.IPPROTO_TCP: match.set_tcp_dst,
                    inet.IPPROTO_UDP: match.set_udp_dst}

    nw_proto = rest.get('nw_proto', 0)
    if nw_proto in match_append:
        match_append[nw_proto](value)

    return match


def to_match_ip(value):
    ip_mask = value.split('/')
    # ip
    ipv4 = struct.unpack('!I', socket.inet_aton(ip_mask[0]))[0]
    # netmask
    mask = 32
    if len(ip_mask) == 2:
        mask = int(ip_mask[1])
    netmask = ofproto_v1_2_parser.UINT32_MAX << 32 - mask\
        & ofproto_v1_2_parser.UINT32_MAX

    return ipv4, netmask


def match_to_str(ofmatch):
    keys = {ofproto_v1_2.OXM_OF_IN_PORT: 'in_port',
            ofproto_v1_2.OXM_OF_ETH_SRC: 'dl_src',
            ofproto_v1_2.OXM_OF_ETH_DST: 'dl_dst',
            ofproto_v1_2.OXM_OF_ETH_TYPE: 'dl_type',
            ofproto_v1_2.OXM_OF_VLAN_VID: 'dl_vlan',
            ofproto_v1_2.OXM_OF_IPV4_SRC: 'nw_src',
            ofproto_v1_2.OXM_OF_IPV4_DST: 'nw_dst',
            ofproto_v1_2.OXM_OF_IPV4_SRC_W: 'nw_src',
            ofproto_v1_2.OXM_OF_IPV4_DST_W: 'nw_dst',
            ofproto_v1_2.OXM_OF_IP_PROTO: 'nw_proto',
            ofproto_v1_2.OXM_OF_TCP_SRC: 'tp_src',
            ofproto_v1_2.OXM_OF_TCP_DST: 'tp_dst',
            ofproto_v1_2.OXM_OF_UDP_SRC: 'tp_src',
            ofproto_v1_2.OXM_OF_UDP_DST: 'tp_dst'}

    match = {}
    for match_field in ofmatch.fields:
        key = keys[match_field.header]
        if key == 'dl_src' or key == 'dl_dst':
            value = mac.haddr_to_str(match_field.value)
        elif key == 'nw_src' or key == 'nw_dst':
            value = match_ip_to_str(match_field.value, match_field.mask)
        else:
            value = match_field.value
        match.setdefault(key, value)

    return match


def match_ip_to_str(value, mask):
    ip = socket.inet_ntoa(struct.pack('!I', value))

    if mask is not None and mask != 0:
        binary_str = bin(mask)[2:].zfill(8)
        netmask = '/%d' % len(binary_str.rstrip('0'))
    else:
        netmask = ''

    return ip + netmask


def send_stats_request(dp, stats, waiters, msgs):
    dp.set_xid(stats)
    waiters_per_dp = waiters.setdefault(dp.id, {})
    lock = hub.Event()
    waiters_per_dp[stats.xid] = (lock, msgs)
    dp.send_msg(stats)

    try:
        lock.wait(timeout=DEFAULT_TIMEOUT)
    except hub.Timeout:
        del waiters_per_dp[stats.xid]


def get_flow_stats(dp, waiters):
    table_id = 0
    out_port = dp.ofproto.OFPP_ANY
    out_group = dp.ofproto.OFPG_ANY
    cookie = 0
    cookie_mask = 0
    match = dp.ofproto_parser.OFPMatch()

    stats = dp.ofproto_parser.OFPFlowStatsRequest(
        dp, table_id, out_port, out_group, cookie, cookie_mask, match)

    msgs = []
    send_stats_request(dp, stats, waiters, msgs)

    flows = []
    for msg in msgs:
        for stats in msg.body:
            actions = actions_to_str(stats.instructions)
            match = match_to_str(stats.match)

            s = {'priority': stats.priority,
                 'cookie': stats.cookie,
                 'idle_timeout': stats.idle_timeout,
                 'hard_timeout': stats.hard_timeout,
                 'actions': actions,
                 'match': match,
                 'byte_count': stats.byte_count,
                 'duration_sec': stats.duration_sec,
                 'duration_nsec': stats.duration_nsec,
                 'packet_count': stats.packet_count,
                 'table_id': stats.table_id}
            flows.append(s)
    flows = {str(dp.id): flows}

    return flows


def mod_flow_entry(dp, flow, cmd):
    cookie = int(flow.get('cookie', 0))
    cookie_mask = int(flow.get('cookie_mask', 0))
    table_id = int(flow.get('table_id', 0))
    idle_timeout = int(flow.get('idle_timeout', 0))
    hard_timeout = int(flow.get('hard_timeout', 0))
    priority = int(flow.get('priority', 0))
    buffer_id = int(flow.get('buffer_id', dp.ofproto.OFP_NO_BUFFER))
    out_port = int(flow.get('out_port', dp.ofproto.OFPP_ANY))
    out_group = int(flow.get('out_group', dp.ofproto.OFPG_ANY))
    flags = int(flow.get('flags', 0))
    match = to_match(dp, flow.get('match', {}))
    inst = to_actions(dp, flow.get('actions', []))

    flow_mod = dp.ofproto_parser.OFPFlowMod(
        dp, cookie, cookie_mask, table_id, cmd, idle_timeout,
        hard_timeout, priority, buffer_id, out_port, out_group,
        flags, match, inst)

    dp.send_msg(flow_mod)

########NEW FILE########
__FILENAME__ = ofctl_v1_3
# Copyright (C) 2013 Nippon Telegraph and Telephone Corporation.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import struct
import socket
import logging

from ryu.ofproto import inet
from ryu.ofproto import ofproto_v1_3
from ryu.ofproto import ofproto_v1_3_parser
from ryu.lib import hub
from ryu.lib import mac


LOG = logging.getLogger('ryu.lib.ofctl_v1_3')

DEFAULT_TIMEOUT = 1.0


def to_actions(dp, acts):
    inst = []
    actions = []
    ofp = dp.ofproto
    parser = dp.ofproto_parser

    for a in acts:
        action_type = a.get('type')
        if action_type == 'OUTPUT':
            out_port = int(a.get('port', ofproto_v1_3.OFPP_ANY))
            max_len = int(a.get('max_len', 0))
            actions.append((parser.OFPActionOutput(out_port,
                                                   max_len)))
        elif action_type == 'COPY_TTL_OUT':
            pass
        elif action_type == 'COPY_TTL_IN':
            pass
        elif action_type == 'SET_MPLS_TTL':
            mpls_ttl = int(a.get('mpls_ttl'))
            actions.append((parser.OFPActionSetMplsTtl(mpls_ttl)))
        elif action_type == 'DEC_MPLS_TTL':
            actions.append((parser.OFPActionDecMplsTtl()))
        elif action_type == 'PUSH_VLAN':
            ethertype = int(a.get('ethertype'))
            actions.append((parser.OFPActionPushVlan(ethertype)))
        elif action_type == 'POP_VLAN':
            actions.append(parser.OFPActionPopVlan())
        elif action_type == 'PUSH_MPLS':
            ethertype = int(a.get('ethertype'))
            actions.append(parser.OFPActionPushMpls(ethertype))
        elif action_type == 'POP_MPLS':
            ethertype = int(a.get('ethertype'))
            actions.append(parser.OFPActionPopMpls(ethertype))
        elif action_type == 'SET_QUEUE':
            queue_id = int(a.get('queue_id'))
            actions.append(parser.OFPActionSetQueue(queue_id))
        elif action_type == 'GROUP':
            pass
        elif action_type == 'SET_NW_TTL':
            nw_ttl = int(a.get('nw_ttl'))
            actions.append(parser.OFPActionSetNwTtl(nw_ttl))
        elif action_type == 'DEC_NW_TTL':
            actions.append(parser.OFPActionDecNwTtl())
        elif action_type == 'SET_FIELD':
            field = a.get('field')
            value = a.get('value')
            if field == 'eth_dst':
                field = ofp.OXM_OF_ETH_DST
                value = mac.haddr_to_bin(str(value))
            elif field == 'eth_src':
                field = ofp.OXM_OF_ETH_SRC
                value = mac.haddr_to_bin(str(value))
            elif field == 'vlan_vid':
                field = ofp.OXM_OF_VLAN_VID
                value = int(value)
            elif field == 'mpls_label':
                field = ofp.OXM_OF_MPLS_LABEL
                value = int(value)
            else:
                LOG.debug('Unknown field: %s' % field)
                continue
            f = parser.OFPMatchField.make(field, value)
            actions.append(parser.OFPActionSetField(f))
        elif action_type == 'PUSH_PBB':
            pass
        elif action_type == 'POP_PBB':
            pass
        elif action_type == 'GOTO_TABLE':
            table_id = int(a.get('table_id'))
            inst.append(parser.OFPInstructionGotoTable(table_id))
        else:
            LOG.debug('Unknown action type: %s' % action_type)

    inst.append(parser.OFPInstructionActions(ofp.OFPIT_APPLY_ACTIONS,
                                             actions))
    return inst


def to_match(dp, attrs):
    match = dp.ofproto_parser.OFPMatch()

    convert = {'in_port': int,
               'dl_src': mac.haddr_to_bin,
               'dl_dst': mac.haddr_to_bin,
               'dl_type': int,
               'dl_vlan': int,
               'nw_src': to_match_ip,
               'nw_dst': to_match_ip,
               'nw_proto': int,
               'tp_src': int,
               'tp_dst': int,
               'mpls_label': int}

    match_append = {'in_port': match.set_in_port,
                    'dl_src': match.set_dl_src,
                    'dl_dst': match.set_dl_dst,
                    'dl_type': match.set_dl_type,
                    'dl_vlan': match.set_vlan_vid,
                    'nw_src': match.set_ipv4_src_masked,
                    'nw_dst': match.set_ipv4_dst_masked,
                    'nw_proto': match.set_ip_proto,
                    'tp_src': to_match_tpsrc,
                    'tp_dst': to_match_tpdst,
                    'mpls_label': match.set_mpls_label}

    for key, value in attrs.items():
        if key in convert:
            value = convert[key](value)
        if key in match_append:
            if key == 'nw_src' or key == 'nw_dst':
                # IP address
                ip = value[0]
                mask = value[1]
                match_append[key](ip, mask)
            elif key == 'tp_src' or key == 'tp_dst':
                # tp_src/dst
                match = match_append[key](value, match, attrs)
            else:
                # others
                match_append[key](value)

    return match


def to_match_tpsrc(value, match, rest):
    match_append = {inet.IPPROTO_TCP: match.set_tcp_src,
                    inet.IPPROTO_UDP: match.set_udp_src}

    nw_proto = rest.get('nw_proto', 0)
    if nw_proto in match_append:
        match_append[nw_proto](value)

    return match


def to_match_tpdst(value, match, rest):
    match_append = {inet.IPPROTO_TCP: match.set_tcp_dst,
                    inet.IPPROTO_UDP: match.set_udp_dst}

    nw_proto = rest.get('nw_proto', 0)
    if nw_proto in match_append:
        match_append[nw_proto](value)

    return match


def to_match_ip(value):
    ip_mask = value.split('/')
    # ip
    ipv4 = struct.unpack('!I', socket.inet_aton(ip_mask[0]))[0]
    # netmask
    mask = 32
    if len(ip_mask) == 2:
        mask = int(ip_mask[1])
    netmask = ofproto_v1_3_parser.UINT32_MAX << 32 - mask\
        & ofproto_v1_3_parser.UINT32_MAX

    return ipv4, netmask


def send_stats_request(dp, stats, waiters, msgs):
    dp.set_xid(stats)
    waiters_per_dp = waiters.setdefault(dp.id, {})
    lock = hub.Event()
    waiters_per_dp[stats.xid] = (lock, msgs)
    dp.send_msg(stats)

    try:
        lock.wait(timeout=DEFAULT_TIMEOUT)
    except hub.Timeout:
        del waiters_per_dp[stats.xid]


def get_desc_stats(dp, waiters):
    stats = dp.ofproto_parser.OFPDescStatsRequest(dp, 0)
    msgs = []
    send_stats_request(dp, stats, waiters, msgs)

    for msg in msgs:
        stats = msg.body
        s = {'mfr_desc': stats.mfr_desc,
             'hw_desc': stats.hw_desc,
             'sw_desc': stats.sw_desc,
             'serial_num': stats.serial_num,
             'dp_desc': stats.dp_desc}
    desc = {str(dp.id): s}
    return desc


def get_flow_stats(dp, waiters):
    table_id = 0
    flags = 0
    out_port = dp.ofproto.OFPP_ANY
    out_group = dp.ofproto.OFPG_ANY
    cookie = 0
    cookie_mask = 0
    match = dp.ofproto_parser.OFPMatch()

    stats = dp.ofproto_parser.OFPFlowStatsRequest(
        dp, flags, table_id, out_port, out_group, cookie, cookie_mask,
        match)

    msgs = []
    send_stats_request(dp, stats, waiters, msgs)

    flows = []
    for msg in msgs:
        for stats in msg.body:
            actions = []
            for action in stats.instructions:
                actions.append(action.to_jsondict())
            match = stats.match.to_jsondict()

            s = {'priority': stats.priority,
                 'cookie': stats.cookie,
                 'idle_timeout': stats.idle_timeout,
                 'hard_timeout': stats.hard_timeout,
                 'byte_count': stats.byte_count,
                 'duration_sec': stats.duration_sec,
                 'duration_nsec': stats.duration_nsec,
                 'packet_count': stats.packet_count,
                 'table_id': stats.table_id,
                 'match': match,
                 'actions': actions}
            flows.append(s)
    flows = {str(dp.id): flows}

    return flows


def get_port_stats(dp, waiters):
    stats = dp.ofproto_parser.OFPPortStatsRequest(
        dp, 0, dp.ofproto.OFPP_ANY)
    msgs = []
    send_stats_request(dp, stats, waiters, msgs)

    ports = []
    for msg in msgs:
        for stats in msg.body:
            s = {'port_no': stats.port_no,
                 'rx_packets': stats.rx_packets,
                 'tx_packets': stats.tx_packets,
                 'rx_bytes': stats.rx_bytes,
                 'tx_bytes': stats.tx_bytes,
                 'rx_dropped': stats.rx_dropped,
                 'tx_dropped': stats.tx_dropped,
                 'rx_errors': stats.rx_errors,
                 'tx_errors': stats.tx_errors,
                 'rx_frame_err': stats.rx_frame_err,
                 'rx_over_err': stats.rx_over_err,
                 'rx_crc_err': stats.rx_crc_err,
                 'collisions': stats.collisions}
            ports.append(s)
    ports = {str(dp.id): ports}
    return ports


def mod_flow_entry(dp, flow, cmd):
    cookie = int(flow.get('cookie', 0))
    cookie_mask = int(flow.get('cookie_mask', 0))
    table_id = int(flow.get('table_id', 0))
    idle_timeout = int(flow.get('idle_timeout', 0))
    hard_timeout = int(flow.get('hard_timeout', 0))
    priority = int(flow.get('priority', 0))
    buffer_id = int(flow.get('buffer_id', dp.ofproto.OFP_NO_BUFFER))
    out_port = int(flow.get('out_port', dp.ofproto.OFPP_ANY))
    out_group = int(flow.get('out_group', dp.ofproto.OFPG_ANY))
    flags = int(flow.get('flags', 0))
    match = to_match(dp, flow.get('match', {}))
    inst = to_actions(dp, flow.get('actions', []))

    flow_mod = dp.ofproto_parser.OFPFlowMod(
        dp, cookie, cookie_mask, table_id, cmd, idle_timeout,
        hard_timeout, priority, buffer_id, out_port, out_group,
        flags, match, inst)

    dp.send_msg(flow_mod)

########NEW FILE########
__FILENAME__ = ofp_pktinfilter
# Copyright (C) 2013 Stratosphere Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# vim: tabstop=4 shiftwidth=4 softtabstop=4

import logging
from abc import ABCMeta, abstractmethod

from ryu.lib.packet import packet

LOG = logging.getLogger(__name__)


def packet_in_filter(cls, args=None):
    def _packet_in_filter(packet_in_handler):
        def __packet_in_filter(self, ev):
            pkt = packet.Packet(ev.msg.data)
            if not packet_in_handler.pkt_in_filter.filter(pkt):
                LOG.debug('The packet is discarded by %s: %s' % (cls, pkt))
                return
            return packet_in_handler(self, ev)
        pkt_in_filter = cls(args)
        packet_in_handler.pkt_in_filter = pkt_in_filter
        return __packet_in_filter
    return _packet_in_filter


class PacketInFilterBase(object):
    __metaclass__ = ABCMeta

    def __init__(self, args):
        self.args = args

    @abstractmethod
    def filter(self, pkt):
        pass


class RequiredTypeFilter(PacketInFilterBase):

    def filter(self, pkt):
        required_types = self.args.get('types') or []
        for required_type in required_types:
            if not pkt.get_protocol(required_type):
                return False
        return True

########NEW FILE########
__FILENAME__ = capable_switch
# Copyright (C) 2013 Nippon Telegraph and Telephone Corporation.
# Copyright (C) 2013 Isaku Yamahata <yamahata at private email ne jp>
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import ncclient
import ncclient.manager
import ncclient.xml_

from ryu import exception as ryu_exc
from ryu.lib import of_config
from ryu.lib.of_config import constants as ofc_consts


# TODO: When we re-organize ncclient, its NCClientError will be
#       subclass of RyuException.
class OFConfigCapableSwitchNotFound(ryu_exc.RyuException,
                                    ncclient.NCClientError):
    message = 'OpenFlow Capable Switch not found'


def get_ns_tag(tag):
    if tag[0] == '{':
        return tuple(tag[1:].split('}', 1))
    return (None, tag)


class OFCapableSwitch(object):
    def __init__(self, connect_method='connect_ssh', *args, **kwargs):
        super(OFCapableSwitch, self).__init__()
        self._connect_method = connect_method
        self._connect_args = args
        self._connect_kwargs = kwargs
        self.version = None
        self.namespace = None

        connect = getattr(ncclient.manager, self._connect_method)
        self.netconf = connect(*self._connect_args, **self._connect_kwargs)

    def close_session(self):
        if self.netconf:
            self.netconf.close_session()
            self.netconf = None

    def __enter__(self):
        return self

    def __exit__(self):
        self.close_session()

    def client_capabilities(self):
        return self.netconf.client_capabilities

    def server_capabilities(self):
        return self.netconf.server_capabilities

    def _find_capable_switch(self, tree):
        capable_switch = None
        for element in tree:
            ns, tag = get_ns_tag(element.tag)
            if tag != ofc_consts.CAPABLE_SWITCH:
                continue

            # assumes that <get> returns only single capable switch
            assert capable_switch is None

            capable_switch = element
            if not self.version:
                versions = [(version, ns_) for version, ns_ in
                            of_config.OFCONFIG_YANG_NAMESPACES.items()
                            if ns == ns_]
                if versions:
                    assert len(versions) == 1
                    version = versions[0]
                    self.version, self.namespace = version

        if not capable_switch:
            raise OFConfigCapableSwitchNotFound()

        return capable_switch

    def _find_capable_switch_xml(self, tree):
        return ncclient.xml_.to_xml(self._find_capable_switch(tree))

    def get(self, filter=None):
        reply = self.netconf.get(filter)
        return self._find_capable_switch_xml(reply.data_ele)

    def get_config(self, source, filter=None):
        reply = self.netconf.get_config(source, filter)
        return self._find_capable_switch_xml(reply.data_ele)

    def edit_config(self, target, config, default_operation=None,
                    test_option=None, error_option=None):
        self.netconf.edit_config(target, config,
                                 default_operation, test_option, error_option)

    # TODO: more netconf operations
    # TODO: convinience(higher level) methods

########NEW FILE########
__FILENAME__ = constants
# Copyright (C) 2013 Nippon Telegraph and Telephone Corporation.
# Copyright (C) 2013 Isaku Yamahata <yamahata at valinux co jp>
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# based on of-config-1.1.1.xsd

# commonly used
TYPE = 'type'
ID = 'id'
OPERATION = 'operation'
PORT = 'port'
PROTOCOL = 'protocol'

# of-configuration-point-protocol
SSH = 'ssh'
SOAP = 'soap'
TLS = 'tls'
BEEP = 'beep'

# of-open-flow-version
VERSION = 'version'
NOT_APPLICABLE = 'not-applicable'
OF_VERSION_1_0 = '1.0'
OF_VERSION_1_0_1 = '1.0.1'
OF_VERSION_1_1 = '1.1'
OF_VERSION_1_2 = '1.2'
OF_VERSION_1_3 = '1.3'
OF_VERSION_1_3_1 = '1.3.1'

# of-up-down-state
UP = 'up'
DOWN = 'down'

# of-port-rate
PORT_RATE_10MB_HD = '10Mb-HD'
PORT_RATE_10MB_FD = '10Mb-FD'
PORT_RATE_100MB_HD = '100Mb-HD'
PORT_RATE_100MB_FD = '100Mb-FD'
PORT_RATE_1GB_HD = '1Gb-HD'
PORT_RATE_1GB_FD = '1Gb-FD'
PORT_RATE_10GB = '10Gb'
PORT_RATE_40GB = '40Gb'
PORT_RATE_100GB = '100Gb'
PORT_RATE_1TB = '1 Tb'
PORT_RATE_1TB_ = '1Tb'          # of-config-1.1.1.xsd uses non space version
                                # to be checked after of-config 1.1.1 is
                                # publicly release
PORT_RATE_OTHER = 'Other'
PORT_RATE_other = 'other'       # of-config-1.1.1 uses lower case.
                                # to be checked after of-config 1.1.1 is
                                # publicly release

# of-action
OUTPUT = 'output'
COPY_TTL_OUT = 'copy-ttl-out'
COPY_TTL_IN = 'copy-ttl-in'
SET_MPLS_TTL = 'set-mpls-ttl'
DEC_MPLS_TTL = 'dec-mpls-ttl'
PUSH_VLAN = 'push-vlan'
POP_VLAN = 'pop-vlan'
PUSH_MPLS = 'push-mpls'
POP_MPLS = 'pop-mpls'
SET_QUEUE = 'set-queue'
GROUP = 'group'
SET_NW_TTL = 'set-nw-ttl'
DEC_NW_TTL = 'dec-nw-ttl'
SET_FIELD = 'set-field'

# of-instruction
APPLY_ACTIONS = 'apply-actions'
CLEAR_ACTIONS = 'clear-actions'
WRITE_ACTIONS = 'write-actions'
WRITE_METADATA = 'write-metadata'
GOTO_TABLE = 'goto-table'

# of-match-field
INPUT_PORT = 'input-port'
PHYSICAL_INPUT_PORT = 'physical-input-port'
METADATA = 'metadata'
ETHERNET_DEST = 'ethernet-dest'
ETHERNET_SRC = 'ethernet-src'
ETHERNET_FRAME_TYPE = 'ethernet-frame-type'
VLAN_ID = 'vlan-id'
VLAN_PRIORITY = 'vlan-priority'
IP_DSCP = 'ip-dscp'
IP_ECN = 'ip-ecn'
IP_PROTOCOL = 'ip-protocol'
IPV4_SRC = 'ipv4-src'
IPV4_DEST = 'ipv4-dest'
TCP_SRC = 'tcp-src'
TCP_DEST = 'tcp-dest'
UDP_SRC = 'udp-src'
UDP_DEST = 'udp-dest'
SCTP_SRC = 'sctp-src'
SCTP_DEST = 'sctp-dest'
ICMPV4_TYPE = 'icmpv4-type'
ICMPV4_CODE = 'icmpv4-code'
ARP_OP = 'arp-op'
ARP_SRC_IP_ADDRESS = 'arp-src-ip-address'
ARP_TARGET_IP_ADDRESS = 'arp-target-ip-address'
ARP_SRC_HARDWARE_ADDRESS = 'arp-src-hardware-address'
ARP_TARGET_HARDWARE_ADDRESS = 'arp-target-hardware-address'
IPV6_SRC = 'ipv6-src'
IPV6_DEST = 'ipv6-dest'
IPV6_FLOW_LABEL = 'ipv6-flow-label'
ICMPV6_TYPE = 'icmpv6-type'
ICMPV6_CODE = 'icmpv6-code'
IPV6_ND_TARGET = 'ipv6-nd-target'
IPV6_ND_SOURCE_LINK_LAYER = 'ipv6-nd-source-link-layer'
IPV6_ND_TARGET_LINK_LAYER = 'ipv6-nd-target-link-layer'
MPLS_LABEL = 'mpls-label'
MPLS_TC = 'mpls-tc'

# of-port-current-feature-list and of-port-other-feature-list
RATE = 'rate'
AUTO_NEGOTIATE = 'auto-negotiate'
MEDIUM = 'medium'
COPPER = 'copper'
FIBER = 'fiber'
PAUSE = 'pause'
UNSUPPORTED = 'unsupported'
SYMMETRIC = 'symmetric'
ASYMMETRIC = 'asymmetric'

# DSA-key-value
DSA_KEY_VALUE_P = 'P'
DSA_KEY_VALUE_Q = 'Q'
DSA_KEY_VALUE_J = 'J'
DSA_KEY_VALUE_G = 'G'
DSA_KEY_VALUE_Y = 'Y'
DSA_KEY_VALUE_SEED = 'Seed'
DSA_KEY_VALUE_PGENCOUNTER = 'PgenCounter'

# of-port-base-tunnel
LOCAL_ENDPOINT_IPV4_ADDRESS = 'local-endpoint-ipv4-address'
REMOTE_ENDPOINT_IPV4_ADDRESS = 'remote-endpoint-ipv4-address'
LOCAL_ENDPOINT_IPV6_ADDRESS = 'local-endpoint-ipv6-address'
REMOTE_ENDPOINT_IPV6_ADDRESS = 'remote-endpoint-ipv6-address'
LOCAL_ENDPOINT_MAC_ADRESS = 'local-endpoint-mac-adress'
REMOTE_ENDPOINT_MAC_ADRESS = 'remote-endpoint-mac-adress'

# of-port-ip-gre-tunnel
CHECKSUM_PRESENT = 'checksum-present'
KEY_PRESENT = 'key-present'
KEY = 'key'
SEQUENCE_NUMBER_PRESENT = 'sequence-number-present'

# of-port-nvgre-tunnel
TNI = 'tni'
TNI_RESV = 'tni-resv'
TNI_MULTICAST_GROUP = 'tni-multicast-group'

# of-queue
# ID = 'id'
# PORT = 'port'
PROPERTIES = 'properties'
MIN_RATE = 'min-rate'
MAX_RATE = 'max-rate'
EXPERIMENTER = 'experimenter'

# of-owned-certificate and of-external-certificate
CERTIFICATE = 'certificate'
PRIVATE_KEY = 'private-key'

# of-configuration-point
# ID = 'id'
URI = 'uri'
# PROTOCOL = 'protocol'

# rsa-key-value
MODULUS = 'Modulus'
EXPONENT = 'Exponent'

# of-flow-table
MAX_ENTRIES = 'max-entries'
NEXT_TABLES = 'next-tables'
TABLE_ID = 'table-id'
INSTRUCTIONS = 'instructions'
# TYPE = 'type'
MATCHES = 'matches'
# TYPE = 'type'
# WRITE_ACTIONS = 'write-actions'
# TYPE = 'type'
# APPLY_ACTIONS = 'apply-actions'
# TYPE = 'type'
# WRITE_SETFIELDS = 'write-setfields'
# TYPE = 'type'
# APPLY_SETFIELDS = 'apply-setfields'
# TYPE = 'type'
WILDCARDS = 'wildcards'
# TYPE = 'type'
METADATA_MATCH = 'metadata-match'
METADATA_WRITE = 'metadata-write'

# of-logical-switch
# ID = 'id'
CAPABILITIES = 'capabilities'
DATAPATH_ID = 'datapath-id'
ENABLED = 'enabled'
CHECK_CONTROLLER_CERTIFICATE = 'check-controller-certificate'
LOST_CONNECTION_BEHAVIOR = 'lost-connection-behavior'
FAILSECUREMODE = 'failSecureMode'
FAILSTANDALONEMODE = 'failStandaloneMode'
CONTROLLERS = 'controllers'
CONTROLLER = 'controller'
# OPERATION = 'operation'
KEY_CONTROLLERS_CONTROLLER = 'key_controllers_controller'
RESOURCES = 'resources'
# PORT = 'port'
QUEUE = 'queue'
# CERTIFICATE = 'certificate'
# FLOW_TABLE = 'flow-table'

# key-value
DSAKEYVALUE = 'DSAKeyValue'
RSAKEYVALUE = 'RSAKeyValue'

# of-logical-switch-capabilities
MAX_BUFFERED_PACKETS = 'max-buffered-packets'
MAX_TABLES = 'max-tables'
MAX_PORTS = 'max-ports'
FLOW_STATISTICS = 'flow-statistics'
TABLE_STATISTICS = 'table-statistics'
# PORT_STATISTICS = 'port-statistics'
GROUP_STATISTICS = 'group-statistics'
QUEUE_STATISTICS = 'queue-statistics'
REASSEMBLE_IP_FRAGMENTS = 'reassemble-ip-fragments'
BLOCK_LOOPING_PORTS = 'block-looping-ports'
RESERVED_PORT_TYPES = 'reserved-port-types'
# TYPE = 'type'
ALL = 'all'
# CONTROLLER = 'controller'
TABLE = 'table'
INPORT = 'inport'
ANY = 'any'
NORMAL = 'normal'
FLOOD = 'flood'
GROUP_TYPES = 'group-types'
# TYPE = 'type'
# ALL = 'all'
SELECT = 'select'
INDIRECT = 'indirect'
FAST_FAILOVER = 'fast-failover'
GROUP_CAPABILITIES = 'group-capabilities'
CAPABILITY = 'capability'
SELECT_WEIGHT = 'select-weight'
SELECT_LIVENESS = 'select-liveness'
CHAINING = 'chaining'
CHAINING_CHECK = 'chaining-check'
ACTION_TYPES = 'action-types'
# TYPE = 'type'
INSTRUCTION_TYPES = 'instruction-types'
# TYPE = 'type'

# of-port
NUMBER = 'number'
NAME = 'name'
CURRENT_RATE = 'current-rate'
# MAX_RATE = 'max-rate'
CONFIGURATION = 'configuration'
ADMIN_STATE = 'admin-state'
NO_RECEIVE = 'no-receive'
NO_FORWARD = 'no-forward'
NO_PACKET_IN = 'no-packet-in'
# OPERATION = 'operation'
STATE = 'state'
OPER_STATE = 'oper-state'
BLOCKED = 'blocked'
LIVE = 'live'
FEATURES = 'features'
CURRENT = 'current'
ADVERTISED = 'advertised'
# OPERATION = 'operation'
SUPPORTED = 'supported'
ADVERTISED_PEER = 'advertised-peer'
TUNNEL = 'tunnel'
IPGRE_TUNNEL = 'ipgre-tunnel'
VXLAN_TUNNEL = 'vxlan-tunnel'
NVGRE_TUNNEL = 'nvgre-tunnel'

# of-resource
RESOURCE_ID = 'resource-id'

# of-port-vxlan-tunnel
VNI_VALID = 'vni-valid'
VNI = 'vni'
VNI_MULTICAST_GROUP = 'vni-multicast-group'
UDP_SOURCE_PORT = 'udp-source-port'
UDP_DEST_PORT = 'udp-dest-port'
UDP_CHECKSUM = 'udp-checksum'

# of-controller
# ID = 'id'
ROLE = 'role'
MASTER = 'master'
SLAVE = 'slave'
EQUAL = 'equal'
IP_ADDRESS = 'ip-address'
# PORT = 'port'
LOCAL_IP_ADDRESS = 'local-ip-address'
LOCAL_PORT = 'local-port'
# PROTOCOL = 'protocol'
TCP = 'tcp'
# TLS = 'tls'
# STATE = 'state'
CONNECTION_STATE = 'connection-state'
CURRENT_VERSION = 'current-version'
SUPPORTED_VERSIONS = 'supported-versions'
LOCAL_IP_ADDRESS_IN_USE = 'local-ip-address-in-use'
LOCAL_PORT_IN_USE = 'local-port-in-use'
CAPABLE_SWITCH = 'capable-switch'
# ID = 'id'
CONFIG_VERSION = 'config-version'
CONFIGURATION_POINTS = 'configuration-points'
CONFIGURATION_POINT = 'configuration-point'
KEY_CONFIGURATION_POINTS_CAPABLESWITCH_CONFIGURATION_POINT = (
    'key_configuration-points_capableswitch_configuration-point')
# RESOURCES = 'resources'
# PORT = 'port'
# QUEUE = 'queue'
# OPERATION = 'operation'
OWNED_CERTIFICATE = 'owned-certificate'
EXTERNAL_CERTIFICATE = 'external-certificate'
# OPERATION = 'operation'
FLOW_TABLE = 'flow-table'
KEY_RESOURCES_CAPABLE_SWITCH_PORT = 'key_resources_capable-switch_port'
KEY_RESOURCES_CAPABLE_SWITCH_QUEUE = 'key_resources_capable-switch_queue'
KEY_RESOURCES_CAPABLE_SWITCH_OWNED_CERTIFICATE = (
    'key_resources_capable-switch_owned-certificate')
KEY_RESOURCES_CAPABLE_SWITCH_EXTERNAL_CERTIFICATE = (
    'key_resources_capable-switch_external-certificate')
KEY_RESOURCES_CAPABLE_SWITCH_FLOW_TABLE = (
    'key_resources_capable-switch_flow-table')
LOGICAL_SWITCHES = 'logical-switches'
SWITCH = 'switch'
KEY_LOGICAL_SWITCHES_CAPABLE_SWITCH_SWITCH = (
    'key_logical-switches_capable-switch_switch')

########NEW FILE########
__FILENAME__ = bridge
# Copyright (C) 2012 Nippon Telegraph and Telephone Corporation.
# Copyright (C) 2012 Isaku Yamahata <yamahata at private email ne jp>
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""
slimmed down version of OVSBridge in quantum agent
"""

import functools
from oslo.config import cfg
import logging

import ryu.exception as ryu_exc
import ryu.lib.dpid as dpid_lib
import ryu.lib.ovs.vsctl as ovs_vsctl

LOG = logging.getLogger(__name__)

CONF = cfg.CONF
CONF.register_opts([
    cfg.IntOpt('ovsdb-timeout', default=2, help='ovsdb timeout')
])


class OVSBridgeNotFound(ryu_exc.RyuException):
    message = 'no bridge for datapath_id %(datapath_id)s'


class VifPort(object):
    def __init__(self, port_name, ofport, vif_id, vif_mac, switch):
        super(VifPort, self).__init__()
        self.port_name = port_name
        self.ofport = ofport
        self.vif_id = vif_id
        self.vif_mac = vif_mac
        self.switch = switch

    def __str__(self):
        return ('iface-id=%s, '
                'vif_mac=%s, '
                'port_name=%s, '
                'ofport=%d, '
                'bridge_name=%s' % (self.vif_id,
                                    self.vif_mac,
                                    self.port_name,
                                    self.ofport,
                                    self.switch.br_name))


class TunnelPort(object):
    def __init__(self, port_name, ofport, tunnel_type, local_ip, remote_ip):
        super(TunnelPort, self).__init__()
        self.port_name = port_name
        self.ofport = ofport
        self.tunnel_type = tunnel_type
        self.local_ip = local_ip
        self.remote_ip = remote_ip

    def __eq__(self, other):
        return (self.port_name == other.port_name and
                self.ofport == other.ofport and
                self.tunnel_type == other.tunnel_type and
                self.local_ip == other.local_ip and
                self.remote_ip == other.remote_ip)

    def __str__(self):
        return ('port_name=%s, '
                'ofport=%s, '
                'type=%s, '
                'local_ip=%s, '
                'remote_ip=%s' % (self.port_name,
                                  self.ofport,
                                  self.tunnel_type,
                                  self.local_ip,
                                  self.remote_ip))


class OVSBridge(object):
    def __init__(self, datapath_id, ovsdb_addr, timeout=None, exception=None):
        super(OVSBridge, self).__init__()
        self.datapath_id = datapath_id
        self.vsctl = ovs_vsctl.VSCtl(ovsdb_addr)
        self.timeout = timeout or CONF.ovsdb_timeout
        self.exception = exception

        self.br_name = None

    def run_command(self, commands):
        self.vsctl.run_command(commands, self.timeout, self.exception)

    def init(self):
        if self.br_name is None:
            self.br_name = self._get_bridge_name()

    def _get_bridge_name(self):
        """ get Bridge name of a given 'datapath_id' """
        command = ovs_vsctl.VSCtlCommand(
            'find',
            ('Bridge',
             'datapath_id=%s' % dpid_lib.dpid_to_str(self.datapath_id)))
        self.run_command([command])
        result = command.result
        if len(result) == 0 or len(result) > 1:
            raise OVSBridgeNotFound(
                datapath_id=dpid_lib.dpid_to_str(self.datapath_id))
        return result[0].name

    def get_controller(self):
        command = ovs_vsctl.VSCtlCommand('get-controller', [self.br_name])
        self.run_command([command])
        return command.result[0]

    def set_controller(self, controllers):
        command = ovs_vsctl.VSCtlCommand('set-controller', [self.br_name])
        command.args.extend(controllers)
        self.run_command([command])

    def del_controller(self):
        command = ovs_vsctl.VSCtlCommand('del-controller', [self.br_name])
        self.run_command([command])

    def set_db_attribute(self, table_name, record, column, value):
        command = ovs_vsctl.VSCtlCommand(
            'set', (table_name, record, '%s=%s' % (column, value)))
        self.run_command([command])

    def clear_db_attribute(self, table_name, record, column):
        command = ovs_vsctl.VSCtlCommand('clear', (table_name, record, column))
        self.run_command([command])

    def db_get_val(self, table, record, column):
        command = ovs_vsctl.VSCtlCommand('get', (table, record, column))
        self.run_command([command])
        assert len(command.result) == 1
        return command.result[0]

    def db_get_map(self, table, record, column):
        val = self.db_get_val(table, record, column)
        assert type(val) == dict
        return val

    def get_datapath_id(self):
        return self.db_get_val('Bridge', self.br_name, 'datapath_id')

    def delete_port(self, port_name):
        command = ovs_vsctl.VSCtlCommand(
            'del-port', (self.br_name, port_name), ('--if-exists'))
        self.run_command([command])

    def get_ofport(self, port_name):
        ofport_list = self.db_get_val('Interface', port_name, 'ofport')
        assert len(ofport_list) == 1
        return int(ofport_list[0])

    def get_port_name_list(self):
        command = ovs_vsctl.VSCtlCommand('list-ports', (self.br_name, ))
        self.run_command([command])
        return command.result

    def add_tunnel_port(self, name, tunnel_type, local_ip, remote_ip,
                        key=None):
        options = 'local_ip=%(local_ip)s,remote_ip=%(remote_ip)s' % locals()
        if key:
            options += ',key=%(key)s' % locals()

        command_add = ovs_vsctl.VSCtlCommand('add-port', (self.br_name, name))
        command_set = ovs_vsctl.VSCtlCommand(
            'set', ('Interface', name,
                    'type=%s' % tunnel_type, 'options=%s' % options))
        self.run_command([command_add, command_set])

    def add_gre_port(self, name, local_ip, remote_ip, key=None):
        self.add_tunnel_port(name, 'gre', local_ip, remote_ip, key=key)

    def del_port(self, port_name):
        command = ovs_vsctl.VSCtlCommand('del-port', (self.br_name, port_name))
        self.run_command([command])

    def _get_ports(self, get_port):
        ports = []
        port_names = self.get_port_name_list()
        for name in port_names:
            if self.get_ofport(name) < 0:
                continue
            port = get_port(name)
            if port:
                ports.append(port)

        return ports

    def _vifport(self, name, external_ids):
        ofport = self.get_ofport(name)
        return VifPort(name, ofport, external_ids['iface-id'],
                       external_ids['attached-mac'], self)

    def _get_vif_port(self, name):
        external_ids = self.db_get_map('Interface', name, 'external_ids')
        if 'iface-id' in external_ids and 'attached-mac' in external_ids:
            return self._vifport(name, external_ids)

    def get_vif_ports(self):
        'returns a VIF object for each VIF port'
        return self._get_ports(self._get_vif_port)

    def _get_external_port(self, name):
        # exclude vif ports
        external_ids = self.db_get_map('Interface', name, 'external_ids')
        if external_ids:
            return

        # exclude tunnel ports
        options = self.db_get_map('Interface', name, 'options')
        if 'remote_ip' in options:
            return

        ofport = self.get_ofport(name)
        return VifPort(name, ofport, None, None, self)

    def get_external_ports(self):
        return self._get_ports(self._get_external_port)

    def get_tunnel_port(self, name, tunnel_type='gre'):
        type_ = self.db_get_val('Interface', name, 'type')
        if type_ != tunnel_type:
            return

        options = self.db_get_map('Interface', name, 'options')
        if 'local_ip' in options and 'remote_ip' in options:
            ofport = self.get_ofport(name)
            return TunnelPort(name, ofport, tunnel_type,
                              options['local_ip'], options['remote_ip'])

    def get_tunnel_ports(self, tunnel_type='gre'):
        get_tunnel_port = functools.partial(self.get_tunnel_port,
                                            tunnel_type=tunnel_type)
        return self._get_ports(get_tunnel_port)

    def get_quantum_ports(self, port_name):
        LOG.debug('port_name %s', port_name)
        command = ovs_vsctl.VSCtlCommand(
            'list-ifaces-verbose',
            [dpid_lib.dpid_to_str(self.datapath_id), port_name])
        self.run_command([command])
        if command.result:
            return command.result[0]
        return None

########NEW FILE########
__FILENAME__ = db_client
# Copyright (C) 2012 Nippon Telegraph and Telephone Corporation.
# Copyright (C) 2012 Isaku Yamahata <yamahata at private email ne jp>
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import logging
import os

from ovs import (jsonrpc,
                 stream)
from ovs import util as ovs_util
from ovs.db import schema

LOG = logging.getLogger(__name__)


class DBClient(object):
    def __init__(self, remote):
        super(DBClient, self).__init__()
        self.remote = remote

    def run_command(self, args):
        _COMMANDS = {
            'list-dbs': self._list_dbs,
            'get-schema': self._get_schema,
            'get-schema-version': self._get_schema_version,
            'list-tables': self._list_tables,
            'list-columns': self._list_columns,
            'transact': self._transact,
            'monitor': self._monitor,
            'dump': self._dump,
        }

        command = args[0]
        args = args[1:]

        error, stream_ = stream.Stream.open_block(
            stream.Stream.open(self.remote))
        if error:
            RuntimeError('can not open socket to %s: %s' %
                         (self.remote, os.strerror(error)))
            raise
        rpc = jsonrpc.Connection(stream_)

        ret = _COMMANDS[command](rpc, *args)
        LOG.info('ret %s', ret)
        rpc.close()

    def _check_txn(self, error, reply):
        if error:
            ovs_util.ovs_fatal(error, os.strerror(error))
        elif reply.error:
            ovs_util.ovs_fatal(reply.error, 'error %s' % reply.error)

    def _fetch_dbs(self, rpc):
        request = jsonrpc.Message.create_request('list_dbs', [])
        error, reply = rpc.transact_block(request)
        self._check_txn(error, reply)

        dbs = set()
        for name in reply.result:
            dbs.add(name)

        return dbs

    def _fetch_schema_json(self, rpc, database):
        request = jsonrpc.Message.create_request('get_schema', [database])
        error, reply = rpc.transact_block(request)
        self._check_txn(error, reply)
        return reply.result

    def _fetch_schema(self, rpc, database):
        return schema.DbSchema.from_json(self._fetch_schema_json(rpc,
                                                                 database))

    # commands
    def _list_dbs(self, rpc, *_args):
        return self._fetch_dbs(rpc)

    def _get_schema(self, rpc, *args):
        database = args[0]
        return self._fetch_schema(rpc, database).to_json()

    def _get_schema_version(self, rpc, *_args):
        database = _args[0]
        schema_ = self._fetch_schema(rpc, database)
        return schema_.version

    def _list_tables(self, rpc, *args):
        database = args[0]
        schema_ = self._fetch_schema(rpc, database)
        return [table.to_json() for table in schema_.tables.values()]

    def _list_columns(self, rpc, *args):
        database = args[0]
        table_name = None
        if len(args) > 1:
            table_name = args[1]

        schema_ = self._fetch_schema(rpc, database)
        if table_name is None:
            tables = [table for table in schema_.tables.values()]
        else:
            tables = [table for table in schema_.tables.values()
                      if table.name == table_name]

        columns = []
        for table in tables:
            columns.extend(table.columns.values())
        return [column.to_json() for column in columns]

    def _transact(self, rpc, *args):
        raise NotImplementedError()

    def _monitor(self, rpc, *args):
        raise NotImplementedError()

    def _dump(self, rpc, *args):
        raise NotImplementedError()

########NEW FILE########
__FILENAME__ = vsctl
# Copyright (C) 2012 Nippon Telegraph and Telephone Corporation.
# Copyright (C) 2012 Isaku Yamahata <yamahata at private email ne jp>
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.


import itertools
import logging
import operator
import os
import sys
import weakref

import ovs.db.data
import ovs.db.types
import ovs.poller
from ovs import (jsonrpc,
                 ovsuuid,
                 stream)
from ovs.db import idl

from ryu.lib import hub
from ryu.lib.ovs import vswitch_idl

LOG = logging.getLogger(__name__)       # use ovs.vlog?


# for debug
def ovsrec_row_changes_to_string(ovsrec_row):
    if not ovsrec_row._changes:
        return ovsrec_row._changes

    return dict((key, value.to_string())
                for key, value in ovsrec_row._changes.items())


# for debug
def ovsrec_row_to_string(ovsrec_row):
    output = ''
    output += 'uuid: %s ' % ovsrec_row.uuid
    if ovsrec_row._data:
        output += '_data: %s ' % dict((key, value.to_string()) for key, value
                                      in ovsrec_row._data.items())
    else:
        output += '_data: %s ' % ovsrec_row._data
    output += '_changes: %s' % ovsrec_row_changes_to_string(ovsrec_row)
    return output


def atom_from_string(base, value_string, symtab=None):
    type_ = base.type
    atom = None
    if type_ == ovs.db.types.IntegerType:
        atom = ovs.db.data.Atom(type_, int(value_string))
    elif type_ == ovs.db.types.RealType:
        # TODO:XXX negation
        atom = ovs.db.data.Atom(
            type_, ovs.db.parser.float_to_int(float(value_string)))
    elif type_ == ovs.db.types.BooleanType:
        if value_string in ("true", "yes", "on", "1"):
            atom = ovs.db.data.Atom(type_, True)
        elif value_string == ("false", "no", "off", "0"):
            atom = ovs.db.data.Atom(type_, False)
    elif type_ == ovs.db.types.StringType:
        # TODO:XXXX escape: if value_string[0] == '"':
        atom = ovs.db.data.Atom(type_, value_string)
    elif type_ == ovs.db.types.UuidType:
        if value_string[0] == "@":
            assert symtab is not None
            uuid_ = symtab[value_string]
            atom = ovs.db.data.Atom(type_, uuid_)
        else:
            atom = ovs.db.data.Atom(type_,
                                    ovs.ovsuuid.from_string(value_string))
    if atom is None:
        raise ValueError("expected %s" % type_.to_string(), value_string)
    atom.check_constraints(base)
    return atom


def datum_from_string(type_, value_string, symtab=None):
    value_string = value_string.strip()
    if type_.is_map():
        if value_string.startswith('{'):
            # TODO:dict case
            LOG.debug('value_string %s', value_string)
            raise NotImplementedError()
        d = dict(v.split('=', 1) for v in value_string.split(','))
        d = dict((atom_from_string(type_.key, key, symtab),
                  atom_from_string(type_.value, value, symtab))
                 for key, value in d.items())
    elif type_.is_set():
        if value_string.startswith('['):
            # TODO:set case
            LOG.debug('value_string %s', value_string)
            raise NotImplementedError()
        values = value_string.split(',')
        d = dict((atom_from_string(type_.key, value, symtab), None)
                 for value in values)
    else:
        atom = atom_from_string(type_.key, value_string, symtab)
        d = {atom: None}

    datum = ovs.db.data.Datum(type_, d)
    return datum.to_json()


def ifind(pred, seq):
    try:
        return itertools.ifilter(pred, seq).next()
    except StopIteration:
        return None


def not_reached():
    os.abort()


def vsctl_fatal(msg):
    LOG.error(msg)
    raise Exception(msg)        # not call ovs.utils.ovs_fatal for reusability


class VSCtlBridge(object):
    def __init__(self, ovsrec_bridge, name, parent, vlan):
        super(VSCtlBridge, self).__init__()
        self.br_cfg = ovsrec_bridge
        self.name = name
        self.ports = set()

        self.parent = parent
        self.vlan = vlan
        self.children = set()   # WeakSet is needed?

    def find_vlan_bridge(self, vlan):
        return ifind(lambda child: child.vlan == vlan, self.children)


class VSCtlPort(object):
    def __init__(self, vsctl_bridge_parent, ovsrec_port):
        super(VSCtlPort, self).__init__()
        self.bridge = weakref.ref(vsctl_bridge_parent)  # backpointer
        self.port_cfg = ovsrec_port

        self.ifaces = set()


class VSCtlIface(object):
    def __init__(self, vsctl_port_parent, ovsrec_iface):
        super(VSCtlIface, self).__init__()
        self.port = weakref.ref(vsctl_port_parent)      # backpointer
        self.iface_cfg = ovsrec_iface


class VSCtlContext(object):
    def _invalidate_cache(self):
        self.cache_valid = False
        self.bridges.clear()
        self.ports.clear()
        self.ifaces.clear()

    def __init__(self, idl_, txn, ovsrec_open_vswitch):
        super(VSCtlContext, self).__init__()

        # Modifiable state
        # self.table = None
        self.idl = idl_
        self.txn = txn
        self.ovs = ovsrec_open_vswitch
        self.symtab = None      # TODO:XXX
        self.verified_ports = False

        # A cache of the contents of the database.
        self.cache_valid = False
        self.bridges = {}       # bridge name -> VSCtlBridge
        self.ports = {}         # port name -> VSCtlPort
        self.ifaces = {}        # iface name -> VSCtlIface

        self.try_again = False  # used by wait-until command

    def done(self):
        self._invalidate_cache()

    def verify_bridges(self):
        self.ovs.verify(vswitch_idl.OVSREC_OPEN_VSWITCH_COL_BRIDGES)

    def verify_ports(self):
        if self.verified_ports:
            return

        self.verify_bridges()
        for ovsrec_bridge in self.idl.tables[
                vswitch_idl.OVSREC_TABLE_BRIDGE].rows.values():
            ovsrec_bridge.verify(vswitch_idl.OVSREC_BRIDGE_COL_PORTS)
        for ovsrec_port in self.idl.tables[
                vswitch_idl.OVSREC_TABLE_PORT].rows.values():
            ovsrec_port.verify(vswitch_idl.OVSREC_PORT_COL_INTERFACES)
        self.verified_ports = True

    def add_bridge_to_cache(self, ovsrec_bridge, name, parent, vlan):
        vsctl_bridge = VSCtlBridge(ovsrec_bridge, name, parent, vlan)
        if parent:
            parent.children.add(vsctl_bridge)
        self.bridges[name] = vsctl_bridge
        return vsctl_bridge

    def del_cached_bridge(self, vsctl_bridge):
        assert not vsctl_bridge.ports
        assert not vsctl_bridge.children

        parent = vsctl_bridge.parent
        if parent:
            parent.children.remove(vsctl_bridge)
            vsctl_bridge.parent = None  # break circular reference
        ovsrec_bridge = vsctl_bridge.br_cfg
        if ovsrec_bridge:
            ovsrec_bridge.delete()
            self.ovs_delete_bridge(ovsrec_bridge)

        del self.bridges[vsctl_bridge.name]

    def add_port_to_cache(self, vsctl_bridge_parent, ovsrec_port):
        tag = getattr(ovsrec_port, vswitch_idl.OVSREC_PORT_COL_TAG, None)
        if (tag is not None and tag >= 0 and tag < 4096):
            vlan_bridge = vsctl_bridge_parent.find_vlan_bridge()
            if vlan_bridge:
                vsctl_bridge_parent = vlan_bridge

        vsctl_port = VSCtlPort(vsctl_bridge_parent, ovsrec_port)
        vsctl_bridge_parent.ports.add(vsctl_port)
        self.ports[ovsrec_port.name] = vsctl_port
        return vsctl_port

    def del_cached_port(self, vsctl_port):
        assert not vsctl_port.ifaces
        vsctl_port.bridge().ports.remove(vsctl_port)
        vsctl_port.bridge = None
        port = self.ports.pop(vsctl_port.port_cfg.name)
        assert port == vsctl_port
        vsctl_port.port_cfg.delete()

    def add_iface_to_cache(self, vsctl_port_parent, ovsrec_iface):
        vsctl_iface = VSCtlIface(vsctl_port_parent, ovsrec_iface)
        vsctl_port_parent.ifaces.add(vsctl_iface)
        self.ifaces[ovsrec_iface.name] = vsctl_iface

    def del_cached_iface(self, vsctl_iface):
        vsctl_iface.port().ifaces.remove(vsctl_iface)
        vsctl_iface.port = None
        del self.ifaces[vsctl_iface.iface_cfg.name]
        vsctl_iface.iface_cfg.delete()

    def invalidate_cache(self):
        if not self.cache_valid:
            return
        self._invalidate_cache()

    def populate_cache(self):
        self._populate_cache(self.idl.tables[vswitch_idl.OVSREC_TABLE_BRIDGE])

    @staticmethod
    def port_is_fake_bridge(ovsrec_port):
        return (ovsrec_port.fake_bridge and
                ovsrec_port.tag >= 0 and ovsrec_port.tab <= 4095)

    def _populate_cache(self, ovsrec_bridges):
        if self.cache_valid:
            return
        self.cache_valid = True

        bridges = set()
        ports = set()
        for ovsrec_bridge in ovsrec_bridges.rows.values():
            name = ovsrec_bridge.name
            if name in bridges:
                LOG.warn('%s: database contains duplicate bridge name', name)
            bridges.add(name)
            vsctl_bridge = self.add_bridge_to_cache(ovsrec_bridge, name,
                                                    None, 0)
            if not vsctl_bridge:
                continue
            for ovsrec_port in ovsrec_bridge.ports:
                port_name = ovsrec_port.name
                if port_name in ports:
                    # Duplicate ovsrec_port name.
                    # (We will warn about that later.)
                    continue
                ports.add(port_name)
                if (self.port_is_fake_bridge(ovsrec_port) and
                        port_name not in bridges):
                    bridges.add(port_name)
                    self.add_bridge_to_cache(None, port_name, vsctl_bridge,
                                             ovsrec_port.tag)

        bridges = set()
        for ovsrec_bridge in ovsrec_bridges.rows.values():
            name = ovsrec_bridge.name
            if name in bridges:
                continue
            bridges.add(name)
            vsctl_bridge = self.bridges[name]
            for ovsrec_port in ovsrec_bridge.ports:
                port_name = ovsrec_port.name
                vsctl_port = self.ports.get(port_name)
                if vsctl_port:
                    if ovsrec_port == vsctl_port.port_cfg:
                        LOG.warn('%s: vsctl_port is in multiple bridges '
                                 '(%s and %s)',
                                 port_name, vsctl_bridge.name,
                                 vsctl_port.br.name)
                    else:
                        LOG.error('%s: database contains duplicate '
                                  'vsctl_port name',
                                  ovsrec_port.name)
                    continue

                if (self.port_is_fake_bridge(ovsrec_port) and
                        port_name in bridges):
                    continue

                # LOG.debug('ovsrec_port %s %s %s',
                #           ovsrec_port, ovsrec_port._data, ovsrec_port.tag)
                vsctl_port = self.add_port_to_cache(vsctl_bridge, ovsrec_port)
                # LOG.debug('vsctl_port %s', vsctl_port)
                for ovsrec_iface in ovsrec_port.interfaces:
                    iface = self.ifaces.get(ovsrec_iface.name)
                    if iface:
                        if ovsrec_iface == iface.iface_cfg:
                            LOG.warn(
                                '%s: interface is in multiple ports '
                                '(%s and %s)',
                                ovsrec_iface.name,
                                iface.port().port_cfg.name,
                                vsctl_port.port_cfg.name)
                        else:
                            LOG.error(
                                '%s: database contains duplicate interface '
                                'name',
                                ovsrec_iface.name)
                        continue
                    self.add_iface_to_cache(vsctl_port, ovsrec_iface)

    def check_conflicts(self, name, msg):
        self.verify_ports()
        if name in self.bridges:
            vsctl_fatal('%s because a bridge named %s already exists' %
                        (msg, name))
        if name in self.ports:
            vsctl_fatal('%s because a port named %s already exists on '
                        'bridge %s' %
                        (msg, name, self.ports[name].bridge().name))
        if name in self.ifaces:
            vsctl_fatal('%s because an interface named %s already '
                        'exists on bridge %s' %
                        (msg, name, self.ifaces[name].port().bridge().name))

    def find_bridge(self, name, must_exist):
        assert self.cache_valid
        vsctl_bridge = self.bridges.get(name)
        if must_exist and not vsctl_bridge:
            vsctl_fatal('no bridge named %s' % name)
        self.verify_bridges()
        return vsctl_bridge

    def find_real_bridge(self, name, must_exist):
        vsctl_bridge = self.find_bridge(name, must_exist)
        if vsctl_bridge and vsctl_bridge.parent:
            vsctl_fatal('%s is a fake bridge' % name)
        return vsctl_bridge

    def find_bridge_by_id(self, datapath_id, must_exist):
        assert self.cache_valid
        for vsctl_bridge in self.bridges.values():
            if vsctl_bridge.br_cfg.datapath_id[0].strip('"') == datapath_id:
                self.verify_bridges()
                return vsctl_bridge

        if must_exist:
            vsctl_fatal('no bridge id %s' % datapath_id)
        return None

    def find_port(self, name, must_exist):
        assert self.cache_valid
        vsctl_port = self.ports.get(name)
        if vsctl_port and name == vsctl_port.bridge().name:
            vsctl_port = None
        if must_exist and not vsctl_port:
            vsctl_fatal('no vsctl_port named %s' % name)
        return vsctl_port

    def find_iface(self, name, must_exist):
        assert self.cache_valid
        vsctl_iface = self.ifaces.get(name)
        if vsctl_iface and name == vsctl_iface.port().bridge().name:
            vsctl_iface = None
        if must_exist and not vsctl_iface:
            vsctl_fatal('no interface named %s' % name)
        self.verify_ports()
        return vsctl_iface

    @staticmethod
    def _column_set(ovsrec_row, column, ovsrec_value):
        # need to trigger Row.__setattr__()
        setattr(ovsrec_row, column, ovsrec_value)

    @staticmethod
    def _column_insert(ovsrec_row, column, ovsrec_add):
        value = getattr(ovsrec_row, column)
        value.append(ovsrec_add)
        VSCtlContext._column_set(ovsrec_row, column, value)

    @staticmethod
    def _column_delete(ovsrec_row, column, ovsrec_del):
        value = getattr(ovsrec_row, column)
        try:
            value.remove(ovsrec_del)
        except ValueError:
            # Datum.to_python() with _uuid_to_row trims down deleted
            # references. If ovsrec_del.delete() is called before
            # _column_delete(), value doesn't include ovsrec_del.
            pass

        VSCtlContext._column_set(ovsrec_row, column, value)

    @staticmethod
    def bridge_insert_port(ovsrec_bridge, ovsrec_port):
        VSCtlContext._column_insert(ovsrec_bridge,
                                    vswitch_idl.OVSREC_BRIDGE_COL_PORTS,
                                    ovsrec_port)

    @staticmethod
    def bridge_delete_port(ovsrec_bridge, ovsrec_port):
        VSCtlContext._column_delete(ovsrec_bridge,
                                    vswitch_idl.OVSREC_BRIDGE_COL_PORTS,
                                    ovsrec_port)

    def ovs_insert_bridge(self, ovsrec_bridge):
        self._column_insert(self.ovs,
                            vswitch_idl.OVSREC_OPEN_VSWITCH_COL_BRIDGES,
                            ovsrec_bridge)

    def ovs_delete_bridge(self, ovsrec_bridge):
        self._column_delete(self.ovs,
                            vswitch_idl.OVSREC_OPEN_VSWITCH_COL_BRIDGES,
                            ovsrec_bridge)

    def del_port(self, vsctl_port):
        if vsctl_port.bridge().parent:
            ovsrec_bridge = vsctl_port.bridge().parent.br_cfg
        else:
            ovsrec_bridge = vsctl_port.bridge().br_cfg
        self.bridge_delete_port(ovsrec_bridge, vsctl_port.port_cfg)

        for vsctl_iface in vsctl_port.ifaces.copy():
            self.del_cached_iface(vsctl_iface)
        self.del_cached_port(vsctl_port)

    def del_bridge(self, vsctl_bridge):
        for child in vsctl_bridge.children.copy():
            self.del_bridge(child)
        for vsctl_port in vsctl_bridge.ports.copy():
            self.del_port(vsctl_port)
        self.del_cached_bridge(vsctl_bridge)

    def add_port(self, br_name, port_name, may_exist, fake_iface,
                 iface_names, settings=None):
        """
        :type settings: list of (column, key, value_json)
                                where column and key are str,
                                      value_json is json that is represented
                                      by Datum.to_json()
        """
        settings = settings or []

        self.populate_cache()
        if may_exist:
            vsctl_port = self.find_port(port_name, False)
            if vsctl_port:
                want_names = set(iface_names)
                have_names = set(ovsrec_iface.name for ovsrec_iface in
                                 vsctl_port.port_cfg.interfaces)
                if vsctl_port.bridge().name != br_name:
                    vsctl_fatal('"%s" but %s is actually attached to '
                                'vsctl_bridge %s',
                                br_name, port_name, vsctl_port.bridge().name)
                if want_names != have_names:
                    want_names_string = ','.join(want_names)
                    have_names_string = ','.join(have_names)
                    vsctl_fatal('"%s" but %s actually has interface(s) %s' %
                                (want_names_string,
                                 port_name, have_names_string))
                return
        self.check_conflicts(port_name,
                             'cannot create a port named %s' % port_name)
        for iface_name in iface_names:
            self.check_conflicts(
                iface_name, 'cannot create an interface named %s' % iface_name)

        vsctl_bridge = self.find_bridge(br_name, True)
        ifaces = []
        for iface_name in iface_names:
            ovsrec_iface = self.txn.insert(
                self.idl.tables[vswitch_idl.OVSREC_TABLE_INTERFACE])
            ovsrec_iface.name = iface_name
            ifaces.append(ovsrec_iface)

        ovsrec_port = self.txn.insert(
            self.idl.tables[vswitch_idl.OVSREC_TABLE_PORT])
        ovsrec_port.name = port_name
        ovsrec_port.interfaces = ifaces
        ovsrec_port.bond_fake_iface = fake_iface

        if vsctl_bridge.parent:
            tag = vsctl_bridge.vlan
            ovsrec_port.tag = tag
        for setting in settings:
            # TODO:XXX self.symtab:
            column, key, value = setting
            self.set_column(ovsrec_port, column, key, value)

        if vsctl_bridge.parent:
            ovsrec_bridge = vsctl_bridge.parent.br_cfg
        else:
            ovsrec_bridge = vsctl_bridge.br_cfg
        self.bridge_insert_port(ovsrec_bridge, ovsrec_port)
        vsctl_port = self.add_port_to_cache(vsctl_bridge, ovsrec_port)
        for ovsrec_iface in ifaces:
            self.add_iface_to_cache(vsctl_port, ovsrec_iface)

    def add_bridge(self, br_name, parent_name=None, vlan=0, may_exist=False):
        self.populate_cache()
        if may_exist:
            vsctl_bridge = self.find_bridge(br_name, False)
            if vsctl_bridge:
                if not parent_name:
                    if vsctl_bridge.parent:
                        vsctl_fatal('"--may-exist add-vsctl_bridge %s" '
                                    'but %s is a VLAN bridge for VLAN %d' %
                                    (br_name, br_name, vsctl_bridge.vlan))
                else:
                    if not vsctl_bridge.parent:
                        vsctl_fatal('"--may-exist add-vsctl_bridge %s %s %d" '
                                    'but %s is not a VLAN bridge' %
                                    (br_name, parent_name, vlan, br_name))
                    elif vsctl_bridge.parent.name != parent_name:
                        vsctl_fatal('"--may-exist add-vsctl_bridge %s %s %d" '
                                    'but %s has the wrong parent %s' %
                                    (br_name, parent_name, vlan,
                                     br_name, vsctl_bridge.parent.name))
                    elif vsctl_bridge.vlan != vlan:
                        vsctl_fatal('"--may-exist add-vsctl_bridge %s %s %d" '
                                    'but %s is a VLAN bridge for the wrong '
                                    'VLAN %d' %
                                    (br_name, parent_name, vlan, br_name,
                                     vsctl_bridge.vlan))
                return

        self.check_conflicts(br_name,
                             'cannot create a bridge named %s' % br_name)

        txn = self.txn
        tables = self.idl.tables
        if not parent_name:
            ovsrec_iface = txn.insert(
                tables[vswitch_idl.OVSREC_TABLE_INTERFACE])
            ovsrec_iface.name = br_name
            ovsrec_iface.type = 'internal'

            ovsrec_port = txn.insert(tables[vswitch_idl.OVSREC_TABLE_PORT])
            ovsrec_port.name = br_name
            ovsrec_port.interfaces = [ovsrec_iface]
            ovsrec_port.fake_bridge = False

            ovsrec_bridge = txn.insert(tables[vswitch_idl.OVSREC_TABLE_BRIDGE])
            ovsrec_bridge.name = br_name
            ovsrec_bridge.ports = [ovsrec_port]

            self.ovs_insert_bridge(ovsrec_bridge)
        else:
            parent = self.find_bridge(parent_name, False)
            if parent and parent.parent:
                vsctl_fatal('cannot create bridge with fake bridge as parent')
            if not parent:
                vsctl_fatal('parent bridge %s does not exist' % parent_name)

            ovsrec_iface = txn.insert(
                tables[vswitch_idl.OVSREC_TABLE_INTERFACE])
            ovsrec_iface.name = br_name
            ovsrec_iface.type = 'internal'

            ovsrec_port = txn.insert(tables[vswitch_idl.OVSREC_TABLE_PORT])
            ovsrec_port.name = br_name
            ovsrec_port.interfaces = [ovsrec_iface]
            ovsrec_port.fake_bridge = True
            ovsrec_port.tag = [vlan]

            self.bridge_insert_port(parent.br_cfg, ovsrec_port)

        self.invalidate_cache()

    @staticmethod
    def parse_column_key_value(table_schema, setting_string):
        """
        parse <column>[:<key>]=<value>
        """
        column_value = setting_string.split('=', 1)
        if len(column_value) == 1:
            column = column_value[0]
            value = None
        else:
            column, value = column_value

        if ':' in column:
            column, key = column.split(':', 1)
        else:
            key = None
        if value is not None:
            LOG.debug("columns %s", table_schema.columns.keys())
            type_ = table_schema.columns[column].type
            value = datum_from_string(type_, value)
            LOG.debug("column %s value %s", column, value)

        return (column, key, value)

    def set_column(self, ovsrec_row, column, key, value_json):
        if column not in ovsrec_row._table.columns:
            vsctl_fatal('%s does not contain a column whose name matches "%s"'
                        % (ovsrec_row._table.name, column))

        column_schema = ovsrec_row._table.columns[column]
        if key is not None:
            value_json = ['map', [[key, value_json]]]
            if column_schema.type.value.type == ovs.db.types.VoidType:
                vsctl_fatal('cannot specify key to set for non-map column %s' %
                            column)
            datum = ovs.db.data.Datum.from_json(column_schema.type, value_json,
                                                self.symtab)
            values = getattr(ovsrec_row, column, {})
            values.update(datum.to_python(ovs.db.idl._uuid_to_row))
            setattr(ovsrec_row, column, values)
        else:
            datum = ovs.db.data.Datum.from_json(column_schema.type, value_json,
                                                self.symtab)
            setattr(ovsrec_row, column,
                    datum.to_python(ovs.db.idl._uuid_to_row))

    def _get_row_by_id(self, table_name, vsctl_row_id, record_id):
        if not vsctl_row_id.table:
            return None

        if not vsctl_row_id.name_column:
            if record_id != '.':
                return None
            values = self.idl.tables[vsctl_row_id.table].rows.values()
            if not values or len(values) > 2:
                return None
            referrer = values[0]
        else:
            referrer = None
            for ovsrec_row in self.idl.tables[
                    vsctl_row_id.table].rows.values():
                name = getattr(ovsrec_row, vsctl_row_id.name_column)
                assert type(name) in (list, str, unicode)
                if type(name) != list and name == record_id:
                    if (referrer):
                        vsctl_fatal('multiple rows in %s match "%s"' %
                                    (table_name, record_id))
                    referrer = ovsrec_row

        if not referrer:
            return None

        final = None
        if vsctl_row_id.uuid_column:
            referrer.verify(vsctl_row_id.uuid_column)
            uuid = getattr(referrer, vsctl_row_id.uuid_column)

            uuid_ = referrer._data[vsctl_row_id.uuid_column]
            assert uuid_.type.key.type == ovs.db.types.UuidType
            assert uuid_.type.value is None
            assert type(uuid) == list

            if len(uuid) == 1:
                final = uuid[0]
        else:
            final = referrer

        return final

    def get_row(self, vsctl_table, record_id):
        table_name = vsctl_table.table_name
        if ovsuuid.is_valid_string(record_id):
            uuid = ovsuuid.from_string(record_id)
            return self.idl.tables[table_name].rows.get(uuid)
        else:
            for vsctl_row_id in vsctl_table.row_ids:
                ovsrec_row = self._get_row_by_id(table_name, vsctl_row_id,
                                                 record_id)
                if ovsrec_row:
                    return ovsrec_row

        return None

    def must_get_row(self, vsctl_table, record_id):
        ovsrec_row = self.get_row(vsctl_table, record_id)
        if not ovsrec_row:
            vsctl_fatal('no row "%s" in table %s' % (record_id,
                                                     vsctl_table.table_name))
        return ovsrec_row


class _CmdShowTable(object):
    def __init__(self, table, name_column, columns, recurse):
        super(_CmdShowTable, self).__init__()
        self.table = table
        self.name_column = name_column
        self.columns = columns
        self.recurse = recurse


class _VSCtlRowID(object):
    def __init__(self, table, name_column, uuid_column):
        super(_VSCtlRowID, self).__init__()
        self.table = table
        self.name_column = name_column
        self.uuid_column = uuid_column


class _VSCtlTable(object):
    def __init__(self, table_name, vsctl_row_id_list):
        super(_VSCtlTable, self).__init__()
        self.table_name = table_name
        self.row_ids = vsctl_row_id_list


class VSCtlCommand(object):
    def __init__(self, command, args=None, options=None):
        super(VSCtlCommand, self).__init__()
        self.command = command
        self.args = args or []
        self.options = options or []

        # Data modified by commands
        self.result = None

        # internally used by VSCtl
        self._prerequisite = None
        self._run = None

    def has_option(self, option):
        return option in self.options


class VSCtl(object):
    def _reset(self):
        self.schema_helper = None
        self.ovs = None
        self.txn = None
        self.wait_for_reload = True
        self.dry_run = False

    def __init__(self, remote):
        super(VSCtl, self).__init__()
        self.remote = remote

        self.schema_json = None
        self.schema = None
        self.schema_helper = None
        self.ovs = None
        self.txn = None
        self.wait_for_reload = True
        self.dry_run = False

    def _rpc_get_schema_json(self, database):
        LOG.debug('remote %s', self.remote)
        error, stream_ = stream.Stream.open_block(
            stream.Stream.open(self.remote))
        if error:
            vsctl_fatal('error %s' % os.strerror(error))
        rpc = jsonrpc.Connection(stream_)
        request = jsonrpc.Message.create_request('get_schema', [database])
        error, reply = rpc.transact_block(request)
        rpc.close()

        if error:
            vsctl_fatal(os.strerror(error))
        elif reply.error:
            vsctl_fatal('error %s' % reply.error)
        return reply.result

    def _init_schema_helper(self):
        if self.schema_json is None:
            self.schema_json = self._rpc_get_schema_json(
                vswitch_idl.OVSREC_DB_NAME)
            schema_helper = idl.SchemaHelper(None, self.schema_json)
            schema_helper.register_all()
            self.schema = schema_helper.get_idl_schema()
        # LOG.debug('schema_json %s', schema_json)
        self.schema_helper = idl.SchemaHelper(None, self.schema_json)

    @staticmethod
    def _idl_block(idl_):
        poller = ovs.poller.Poller()
        idl_.wait(poller)
        poller.block()

    @staticmethod
    def _idl_wait(idl_, seqno):
        while idl_.change_seqno == seqno and not idl_.run():
            VSCtl._idl_block(idl_)

    def _run_prerequisites(self, commands):
        schema_helper = self.schema_helper
        schema_helper.register_table(vswitch_idl.OVSREC_TABLE_OPEN_VSWITCH)
        if self.wait_for_reload:
            # LOG.debug('schema_helper._tables %s', schema_helper._tables)
            schema_helper.register_columns(
                vswitch_idl.OVSREC_TABLE_OPEN_VSWITCH,
                [vswitch_idl.OVSREC_OPEN_VSWITCH_COL_CUR_CFG])

        for command in commands:
            if not command._prerequisite:
                continue
            ctx = VSCtlContext(None, None, None)
            command._prerequisite(ctx, command)
            ctx.done()

    def _do_vsctl(self, idl_, commands):
        txn = idl.Transaction(idl_)
        self.txn = txn
        if self.dry_run:
            txn.dry_run = True

        txn.add_comment('ovs-vsctl')  # TODO:XXX add operation name. args
        ovs_rows = idl_.tables[vswitch_idl.OVSREC_TABLE_OPEN_VSWITCH].rows
        if ovs_rows:
            ovs_ = ovs_rows.values()[0]
        else:
            # XXX add verification that table is empty
            ovs_ = txn.insert(
                idl_.tables[vswitch_idl.OVSREC_TABLE_OPEN_VSWITCH])

        if self.wait_for_reload:
            ovs_.increment(vswitch_idl.OVSREC_OPEN_VSWITCH_COL_NEXT_CFG)

        # TODO:XXX
        # symtab = ovsdb_symbol_table_create()
        ctx = VSCtlContext(idl_, txn, ovs_)
        for command in commands:
            if not command._run:
                continue
            command._run(ctx, command)
            if ctx.try_again:
                return False
        LOG.debug('result:\n%s', [command.result for command in commands])
        ctx.done()

        # TODO:XXX check if created symbols are really created, referenced.

        status = txn.commit_block()
        next_cfg = 0
        if self.wait_for_reload and status == idl.Transaction.SUCCESS:
            next_cfg = txn.get_increment_new_value()

        # TODO:XXX
        # if status in (idl.Transaction.UNCHANGED, idl.Transaction.SUCCESS):
        #     for command in commands:
        #         if not command.post_func:
        #             continue
        #         ctx = VSCtlContext(idl_, txn, self.ovs)
        #         command.post_func(ctx)
        #         ctx.done()

        txn_ = self.txn
        self.txn = None
        txn = None

        if status in (idl.Transaction.UNCOMMITTED, idl.Transaction.INCOMPLETE):
            not_reached()
        elif status == idl.Transaction.ABORTED:
            vsctl_fatal('transaction aborted')
        elif status in (idl.Transaction.UNCHANGED, idl.Transaction.SUCCESS):
            pass
        elif status == idl.Transaction.TRY_AGAIN:
            return False
        elif status == idl.Transaction.ERROR:
            vsctl_fatal('transaction error: %s' % txn_.get_error())
        elif status == idl.Transaction.NOT_LOCKED:
            vsctl_fatal('database not locked')
        else:
            not_reached()

        if self.wait_for_reload and status != idl.Transaction.UNCHANGED:
            while True:
                idl_.run()
                if (ovs_.cur_cfg >= next_cfg):
                    break
                self._idl_block(idl_)

        return True

    def _do_main(self, commands):
        """
        :type commands: list of VSCtlCommand
        """
        self._reset()
        self._init_schema_helper()
        self._run_prerequisites(commands)

        idl_ = idl.Idl(self.remote, self.schema_helper)
        seqno = idl_.change_seqno
        while True:
            self._idl_wait(idl_, seqno)

            seqno = idl_.change_seqno
            if self._do_vsctl(idl_, commands):
                break

            if self.txn:
                self.txn.abort()
                self.txn = None
            # TODO:XXX
            # ovsdb_symbol_table_destroy(symtab)

        idl_.close()

    def _run_command(self, commands):
        """
        :type commands: list of VSCtlCommand
        """
        all_commands = {
            # Open vSwitch commands.
            'init': (None, self._cmd_init),
            'show': (self._pre_cmd_show, self._cmd_show),

            # Bridge commands.
            'add-br': (self._pre_add_br, self._cmd_add_br),
            'del-br': (self._pre_get_info, self._cmd_del_br),
            'list-br': (self._pre_get_info, self._cmd_list_br),

            # Port. commands
            'list-ports': (self._pre_get_info, self._cmd_list_ports),
            'add-port': (self._pre_cmd_add_port, self._cmd_add_port),
            'del-port': (self._pre_get_info, self._cmd_del_port),
            # 'add-bond':
            # 'port-to-br':

            # Interface commands.
            'list-ifaces': (self._pre_get_info, self._cmd_list_ifaces),
            # 'iface-to-br':

            # Controller commands.
            'get-controller': (self._pre_controller, self._cmd_get_controller),
            'del-controller': (self._pre_controller, self._cmd_del_controller),
            'set-controller': (self._pre_controller, self._cmd_set_controller),
            # 'get-fail-mode':
            # 'del-fail-mode':
            # 'set-fail-mode':

            # Manager commands.
            # 'get-manager':
            # 'del-manager':
            # 'set-manager':

            # Switch commands.
            # 'emer-reset':

            # Database commands.
            # 'comment':
            'get': (self._pre_cmd_get, self._cmd_get),
            # 'list':
            'find': (self._pre_cmd_find, self._cmd_find),
            'set': (self._pre_cmd_set, self._cmd_set),
            # 'add':
            'clear': (self._pre_cmd_clear, self._cmd_clear),
            # 'create':
            # 'destroy':
            # 'wait-until':

            # for quantum_adapter
            'list-ifaces-verbose': (self._pre_cmd_list_ifaces_verbose,
                                    self._cmd_list_ifaces_verbose),
        }

        for command in commands:
            funcs = all_commands[command.command]
            command._prerequisite, command._run = funcs
        self._do_main(commands)

    def run_command(self, commands, timeout_sec=None, exception=None):
        if timeout_sec is None:
            self._run_command(commands)
        else:
            with hub.Timeout(timeout_sec, exception):
                self._run_command(commands)

    # commands
    def _cmd_init(self, _ctx, _command):
        # nothing. Just check connection to ovsdb
        pass

    _CMD_SHOW_TABLES = [
        _CmdShowTable(vswitch_idl.OVSREC_TABLE_OPEN_VSWITCH, None,
                      [vswitch_idl.OVSREC_OPEN_VSWITCH_COL_MANAGER_OPTIONS,
                       vswitch_idl.OVSREC_OPEN_VSWITCH_COL_BRIDGES,
                       vswitch_idl.OVSREC_OPEN_VSWITCH_COL_OVS_VERSION],
                      False),
        _CmdShowTable(vswitch_idl.OVSREC_TABLE_BRIDGE,
                      vswitch_idl.OVSREC_BRIDGE_COL_NAME,
                      [vswitch_idl.OVSREC_BRIDGE_COL_CONTROLLER,
                       vswitch_idl.OVSREC_BRIDGE_COL_FAIL_MODE,
                       vswitch_idl.OVSREC_BRIDGE_COL_PORTS],
                      False),
        _CmdShowTable(vswitch_idl.OVSREC_TABLE_PORT,
                      vswitch_idl.OVSREC_PORT_COL_NAME,
                      [vswitch_idl.OVSREC_PORT_COL_TAG,
                       vswitch_idl.OVSREC_PORT_COL_TRUNKS,
                       vswitch_idl.OVSREC_PORT_COL_INTERFACES],
                      False),
        _CmdShowTable(vswitch_idl.OVSREC_TABLE_INTERFACE,
                      vswitch_idl.OVSREC_INTERFACE_COL_NAME,
                      [vswitch_idl.OVSREC_INTERFACE_COL_TYPE,
                       vswitch_idl.OVSREC_INTERFACE_COL_OPTIONS],
                      False),
        _CmdShowTable(vswitch_idl.OVSREC_TABLE_CONTROLLER,
                      vswitch_idl.OVSREC_CONTROLLER_COL_TARGET,
                      [vswitch_idl.OVSREC_CONTROLLER_COL_IS_CONNECTED],
                      False),
        _CmdShowTable(vswitch_idl.OVSREC_TABLE_MANAGER,
                      vswitch_idl.OVSREC_MANAGER_COL_TARGET,
                      [vswitch_idl.OVSREC_MANAGER_COL_IS_CONNECTED],
                      False),
    ]

    def _pre_cmd_show(self, _ctx, _command):
        schema_helper = self.schema_helper
        for show in self._CMD_SHOW_TABLES:
            schema_helper.register_table(show.table)
            if show.name_column:
                schema_helper.register_columns(show.table, [show.name_column])
            schema_helper.register_columns(show.table, show.columns)

    @staticmethod
    def _cmd_show_find_table_by_row(row):
        for show in VSCtl._CMD_SHOW_TABLES:
            if show.table == row._table.name:
                return show
        return None

    @staticmethod
    def _cmd_show_find_table_by_name(name):
        for show in VSCtl._CMD_SHOW_TABLES:
            if show.table == name:
                return show
        return None

    @staticmethod
    def _cmd_show_row(ctx, row, level):
        _INDENT_SIZE = 4  # # of spaces per indent
        show = VSCtl._cmd_show_find_table_by_row(row)
        output = ''

        output += ' ' * level * _INDENT_SIZE
        if show and show.name_column:
            output += '%s ' % show.table
            datum = getattr(row, show.name_column)
            output += datum
        else:
            output += str(row.uuid)
        output += '\n'

        if not show or show.recurse:
            return

        show.recurse = True
        for column in show.columns:
            datum = row._data[column]
            key = datum.type.key
            if (key.type == ovs.db.types.UuidType and key.ref_table_name):
                ref_show = VSCtl._cmd_show_find_table_by_name(
                    key.ref_table_name)
                if ref_show:
                    for atom in datum.values:
                        ref_row = ctx.idl.tables[ref_show.table].rows.get(
                            atom.value)
                        if ref_row:
                            VSCtl._cmd_show_row(ctx, ref_row, level + 1)
                    continue

            if not datum.is_default():
                output += ' ' * (level + 1) * _INDENT_SIZE
                output += '%s: %s\n' % (column, datum)

        show.recurse = False
        return output

    def _cmd_show(self, ctx, command):
        for row in ctx.idl.tables[
                self._CMD_SHOW_TABLES[0].table].rows.values():
            output = self._cmd_show_row(ctx, row, 0)
            command.result = output

    def _pre_get_info(self, _ctx, _command):
        schema_helper = self.schema_helper

        schema_helper.register_columns(
            vswitch_idl.OVSREC_TABLE_OPEN_VSWITCH,
            [vswitch_idl.OVSREC_OPEN_VSWITCH_COL_BRIDGES])
        schema_helper.register_columns(
            vswitch_idl.OVSREC_TABLE_BRIDGE,
            [vswitch_idl.OVSREC_BRIDGE_COL_NAME,
             vswitch_idl.OVSREC_BRIDGE_COL_CONTROLLER,
             vswitch_idl.OVSREC_BRIDGE_COL_FAIL_MODE,
             vswitch_idl.OVSREC_BRIDGE_COL_PORTS])
        schema_helper.register_columns(
            vswitch_idl.OVSREC_TABLE_PORT,
            [vswitch_idl.OVSREC_PORT_COL_NAME,
             vswitch_idl.OVSREC_PORT_COL_FAKE_BRIDGE,
             vswitch_idl.OVSREC_PORT_COL_TAG,
             vswitch_idl.OVSREC_PORT_COL_INTERFACES])
        schema_helper.register_columns(
            vswitch_idl.OVSREC_TABLE_INTERFACE,
            [vswitch_idl.OVSREC_INTERFACE_COL_NAME])

    def _cmd_list_br(self, ctx, command):
        ctx.populate_cache()
        command.result = sorted(ctx.bridges.keys())

    def _pre_add_br(self, ctx, command):
        self._pre_get_info(ctx, command)

        schema_helper = self.schema_helper
        schema_helper.register_columns(
            vswitch_idl.OVSREC_TABLE_INTERFACE,
            [vswitch_idl.OVSREC_INTERFACE_COL_TYPE])

    def _cmd_add_br(self, ctx, command):
        br_name = command.args[0]
        if len(command.args) == 1:
            parent_name = None
            vlan = 0
        elif len(command.args) == 3:
            parent_name = command.args[1]
            vlan = int(command.args[2])
            if vlan < 0 or vlan > 4095:
                vsctl_fatal("vlan must be between 0 and 4095 %d" % vlan)
        else:
            vsctl_fatal('this command takes exactly 1 or 3 argument')

        ctx.add_bridge(br_name, parent_name, vlan)

    def _del_br(self, ctx, br_name, must_exist=False):
        ctx.populate_cache()
        br = ctx.find_bridge(br_name, must_exist)
        if br:
            ctx.del_bridge(br)

    def _cmd_del_br(self, ctx, command):
        br_name = command.args[0]
        self._del_br(ctx, br_name)

    def _list_ports(self, ctx, br_name):
        ctx.populate_cache()
        br = ctx.find_bridge(br_name, True)
        if br.br_cfg:
            br.br_cfg.verify(vswitch_idl.OVSREC_BRIDGE_COL_PORTS)
        else:
            br.parent.br_cfg.verify(vswitch_idl.OVSREC_BRIDGE_COL_PORTS)

        return [port.port_cfg.name for port in br.ports
                if port.port_cfg.name != br.name]

    def _cmd_list_ports(self, ctx, command):
        br_name = command.args[0]
        port_names = self._list_ports(ctx, br_name)
        command.result = sorted(port_names)

    def _pre_add_port(self, _ctx, columns):
        schema_helper = self.schema_helper
        schema_helper.register_columns(
            vswitch_idl.OVSREC_TABLE_PORT,
            [vswitch_idl.OVSREC_PORT_COL_NAME,
             vswitch_idl.OVSREC_PORT_COL_BOND_FAKE_IFACE])
        schema_helper.register_columns(
            vswitch_idl.OVSREC_TABLE_PORT, columns)

    def _pre_cmd_add_port(self, ctx, command):
        self._pre_get_info(ctx, command)

        columns = [ctx.parse_column_key_value(
            self.schema.tables[vswitch_idl.OVSREC_TABLE_PORT], setting)[0]
            for setting in command.args[2:]]
        self._pre_add_port(ctx, columns)

    def _cmd_add_port(self, ctx, command):
        may_exist = command.has_option('--may_exist')

        br_name = command.args[0]
        port_name = command.args[1]
        iface_names = [command.args[1]]
        settings = [ctx.parse_column_key_value(
            self.schema.tables[vswitch_idl.OVSREC_TABLE_PORT], setting)
            for setting in command.args[2:]]
        ctx.add_port(br_name, port_name, may_exist,
                     False, iface_names, settings)

    def _del_port(self, ctx, br_name=None, target=None,
                  must_exist=False, with_iface=False):
        assert target is not None

        ctx.populate_cache()
        if not with_iface:
            vsctl_port = ctx.find_port(target, must_exist)
        else:
            vsctl_port = ctx.find_port(target, False)
            if not vsctl_port:
                vsctl_iface = ctx.find_iface(target, False)
                if vsctl_iface:
                    vsctl_port = vsctl_iface.port()
                if must_exist and not vsctl_port:
                    vsctl_fatal('no port or interface named %s' % target)

        if not vsctl_port:
            return
        if not br_name:
            vsctl_bridge = ctx.find_bridge(br_name, True)
            if vsctl_port.bridge() != vsctl_bridge:
                if vsctl_port.bridge().parent == vsctl_bridge:
                    vsctl_fatal('bridge %s does not have a port %s (although '
                                'its parent bridge %s does)' %
                                (br_name, target, vsctl_bridge.parent.name))
                else:
                    vsctl_fatal('bridge %s does not have a port %s' %
                                (br_name, target))

        ctx.del_port(vsctl_port)

    def _cmd_del_port(self, ctx, command):
        must_exist = command.has_option('--must-exist')
        with_iface = command.has_option('--with-iface')
        target = command.args[-1]
        br_name = command.args[0] if len(command.args) == 2 else None
        self._del_port(ctx, br_name, target, must_exist, with_iface)

    def _list_ifaces(self, ctx, br_name):
        ctx.populate_cache()

        br = ctx.find_bridge(br_name, True)
        ctx.verify_ports()

        iface_names = set()
        for vsctl_port in br.ports:
            for vsctl_iface in vsctl_port.ifaces:
                iface_name = vsctl_iface.iface_cfg.name
                if iface_name != br_name:
                    iface_names.add(iface_name)
        return iface_names

    def _cmd_list_ifaces(self, ctx, command):
        br_name = command.args[0]
        iface_names = self._list_ifaces(ctx, br_name)
        command.result = sorted(iface_names)

    def _pre_cmd_list_ifaces_verbose(self, ctx, command):
        self._pre_get_info(ctx, command)
        schema_helper = self.schema_helper
        schema_helper.register_columns(
            vswitch_idl.OVSREC_TABLE_BRIDGE,
            [vswitch_idl.OVSREC_BRIDGE_COL_DATAPATH_ID])
        schema_helper.register_columns(
            vswitch_idl.OVSREC_TABLE_INTERFACE,
            [vswitch_idl.OVSREC_INTERFACE_COL_TYPE,
             vswitch_idl.OVSREC_INTERFACE_COL_NAME,
             vswitch_idl.OVSREC_INTERFACE_COL_EXTERNAL_IDS,
             vswitch_idl.OVSREC_INTERFACE_COL_OPTIONS,
             vswitch_idl.OVSREC_INTERFACE_COL_OFPORT])

    @staticmethod
    def _iface_to_dict(iface_cfg):
        _ATTRIBUTE = ['name', 'ofport', 'type', 'external_ids', 'options']
        attr = dict((key, getattr(iface_cfg, key)) for key in _ATTRIBUTE)

        if attr['ofport']:
            attr['ofport'] = attr['ofport'][0]
        return attr

    def _list_ifaces_verbose(self, ctx, datapath_id, port_name):
        ctx.populate_cache()

        br = ctx.find_bridge_by_id(datapath_id, True)
        ctx.verify_ports()

        iface_cfgs = []
        if port_name is None:
            for vsctl_port in br.ports:
                iface_cfgs.extend(self._iface_to_dict(vsctl_iface.iface_cfg)
                                  for vsctl_iface in vsctl_port.ifaces)
        else:
            # When port is created, ofport column might be None.
            # So try with port name if it happended
            for vsctl_port in br.ports:
                iface_cfgs.extend(
                    self._iface_to_dict(vsctl_iface.iface_cfg)
                    for vsctl_iface in vsctl_port.ifaces
                    if (vsctl_iface.iface_cfg.name == port_name))

        return iface_cfgs

    def _cmd_list_ifaces_verbose(self, ctx, command):
        datapath_id = command.args[0]
        port_name = None
        if len(command.args) >= 2:
            port_name = command.args[1]
        LOG.debug('command.args %s', command.args)
        iface_cfgs = self._list_ifaces_verbose(ctx, datapath_id, port_name)
        command.result = sorted(iface_cfgs)

    def _verify_controllers(self, ovsrec_bridge):
        ovsrec_bridge.verify(vswitch_idl.OVSREC_BRIDGE_COL_CONTROLLER)
        for controller in ovsrec_bridge.controller:
            controller.verify(vswitch_idl.OVSREC_CONTROLLER_COL_TARGET)

    def _pre_controller(self, ctx, command):
        self._pre_get_info(ctx, command)
        self.schema_helper.register_columns(
            vswitch_idl.OVSREC_TABLE_CONTROLLER,
            [vswitch_idl.OVSREC_CONTROLLER_COL_TARGET])

    def _get_controller(self, ctx, br_name):
        ctx.populate_cache()
        br = ctx.find_bridge(br_name, True)
        self._verify_controllers(br.br_cfg)
        return set(controller.target for controller in br.br_cfg.controller)

    def _cmd_get_controller(self, ctx, command):
        br_name = command.args[0]
        controller_names = self._get_controller(ctx, br_name)
        command.result = sorted(controller_names)

    def _delete_controllers(self, ovsrec_controllers):
        for controller in ovsrec_controllers:
            controller.delete()

    def _del_controller(self, ctx, br_name):
        ctx.populate_cache()
        br = ctx.find_real_bridge(br_name, True)
        ovsrec_bridge = br.br_cfg
        self._verify_controllers(ovsrec_bridge)
        if ovsrec_bridge.controller:
            self._delete_controllers(ovsrec_bridge.controller)
            ovsrec_bridge.controller = []

    def _cmd_del_controller(self, ctx, command):
        br_name = command.args[0]
        self._del_controller(ctx, br_name)

    def _insert_controllers(self, controller_names):
        ovsrec_controllers = []
        for name in controller_names:
            # TODO: check if the name startswith() supported protocols
            ovsrec_controller = self.txn.insert(
                self.txn.idl.tables[vswitch_idl.OVSREC_TABLE_CONTROLLER])
            ovsrec_controller.target = name
            ovsrec_controllers.append(ovsrec_controller)
        return ovsrec_controllers

    def _set_controller(self, ctx, br_name, controller_names):
        ctx.populate_cache()
        ovsrec_bridge = ctx.find_real_bridge(br_name, True).br_cfg
        self._verify_controllers(ovsrec_bridge)
        self._delete_controllers(ovsrec_bridge.controller)
        controllers = self._insert_controllers(controller_names)
        ovsrec_bridge.controller = controllers

    def _cmd_set_controller(self, ctx, command):
        br_name = command.args[0]
        controller_names = command.args[1:]
        self._set_controller(ctx, br_name, controller_names)

    _TABLES = [
        _VSCtlTable(vswitch_idl.OVSREC_TABLE_BRIDGE,
                    [_VSCtlRowID(vswitch_idl.OVSREC_TABLE_BRIDGE,
                                 vswitch_idl.OVSREC_BRIDGE_COL_NAME,
                                 None)]),
        _VSCtlTable(vswitch_idl.OVSREC_TABLE_CONTROLLER,
                    [_VSCtlRowID(vswitch_idl.OVSREC_TABLE_BRIDGE,
                                 vswitch_idl.OVSREC_BRIDGE_COL_NAME,
                                 vswitch_idl.OVSREC_BRIDGE_COL_CONTROLLER)]),
        _VSCtlTable(vswitch_idl.OVSREC_TABLE_INTERFACE,
                    [_VSCtlRowID(vswitch_idl.OVSREC_TABLE_INTERFACE,
                                 vswitch_idl.OVSREC_INTERFACE_COL_NAME,
                                 None)]),
        _VSCtlTable(vswitch_idl.OVSREC_TABLE_MIRROR,
                    [_VSCtlRowID(vswitch_idl.OVSREC_TABLE_MIRROR,
                                 vswitch_idl.OVSREC_MIRROR_COL_NAME,
                                 None)]),
        _VSCtlTable(vswitch_idl.OVSREC_TABLE_MANAGER,
                    [_VSCtlRowID(vswitch_idl.OVSREC_TABLE_MANAGER,
                                 vswitch_idl.OVSREC_MANAGER_COL_TARGET,
                                 None)]),
        _VSCtlTable(vswitch_idl.OVSREC_TABLE_NETFLOW,
                    [_VSCtlRowID(vswitch_idl.OVSREC_TABLE_BRIDGE,
                                 vswitch_idl.OVSREC_BRIDGE_COL_NAME,
                                 vswitch_idl.OVSREC_BRIDGE_COL_NETFLOW)]),
        _VSCtlTable(vswitch_idl.OVSREC_TABLE_OPEN_VSWITCH,
                    [_VSCtlRowID(vswitch_idl.OVSREC_TABLE_OPEN_VSWITCH,
                                 None,
                                 None)]),
        _VSCtlTable(vswitch_idl.OVSREC_TABLE_PORT,
                    [_VSCtlRowID(vswitch_idl.OVSREC_TABLE_PORT,
                                 vswitch_idl.OVSREC_PORT_COL_NAME,
                                 None)]),
        _VSCtlTable(vswitch_idl.OVSREC_TABLE_QOS,
                    [_VSCtlRowID(vswitch_idl.OVSREC_TABLE_PORT,
                                 vswitch_idl.OVSREC_PORT_COL_NAME,
                                 vswitch_idl.OVSREC_PORT_COL_QOS)]),
        _VSCtlTable(vswitch_idl.OVSREC_TABLE_QUEUE, []),
        _VSCtlTable(vswitch_idl.OVSREC_TABLE_SSL,
                    [_VSCtlRowID(vswitch_idl.OVSREC_TABLE_OPEN_VSWITCH,
                                 None,
                                 vswitch_idl.OVSREC_OPEN_VSWITCH_COL_SSL)]),
        _VSCtlTable(vswitch_idl.OVSREC_TABLE_SFLOW,
                    [_VSCtlRowID(vswitch_idl.OVSREC_TABLE_BRIDGE,
                                 vswitch_idl.OVSREC_BRIDGE_COL_NAME,
                                 vswitch_idl.OVSREC_BRIDGE_COL_SFLOW)]),
        _VSCtlTable(vswitch_idl.OVSREC_TABLE_FLOW_TABLE,
                    [_VSCtlRowID(vswitch_idl.OVSREC_TABLE_FLOW_TABLE,
                                 vswitch_idl.OVSREC_FLOW_TABLE_COL_NAME,
                                 None)]),
    ]

    @staticmethod
    def _score_partial_match(name, s):
        _MAX_SCORE = 0xffffffff
        assert len(name) < _MAX_SCORE
        s = s[:_MAX_SCORE - 1]  # in practice, this doesn't matter
        if name == s:
            return _MAX_SCORE

        name = name.lower().replace('-', '_')
        s = s.lower().replace('-', '_')
        if s.startswith(name):
            return _MAX_SCORE - 1
        if name.startswith(s):
            return len(s)

        return 0

    @staticmethod
    def _get_table(table_name):
        best_match = None
        best_score = 0
        for table in VSCtl._TABLES:
            score = VSCtl._score_partial_match(table.table_name, table_name)
            if score > best_score:
                best_match = table
                best_score = score
            elif score == best_score:
                best_match = None

        if best_match:
            return best_match
        elif best_score:
            vsctl_fatal('multiple table names match "%s"' % table_name)
        else:
            vsctl_fatal('unknown table "%s"' % table_name)

    def _pre_get_table(self, _ctx, table_name):
        vsctl_table = self._get_table(table_name)

        schema_helper = self.schema_helper
        schema_helper.register_table(vsctl_table.table_name)
        for row_id in vsctl_table.row_ids:
            if row_id.table:
                schema_helper.register_table(row_id.table)
            if row_id.name_column:
                schema_helper.register_columns(row_id.table,
                                               [row_id.name_column])
            if row_id.uuid_column:
                schema_helper.register_columns(row_id.table,
                                               [row_id.uuid_column])
        return vsctl_table

    def _get_column(self, table_name, column_name):
        best_match = None
        best_score = 0

        columns = self.schema.tables[table_name].columns.keys()
        for column in columns:
            score = VSCtl._score_partial_match(column, column_name)
            if score > best_score:
                best_match = column
                best_score = score
            elif score == best_score:
                best_match = None

        if best_match:
            # ovs.db.schema_helper._keep_table_columns() requires that
            # column_name is type of str. Not unicode string
            return str(best_match)
        elif best_score:
            vsctl_fatal('%s contains more than one column whose name '
                        'matches "%s"' % (table_name, column_name))
        else:
            vsctl_fatal('%s does not contain a column whose name matches '
                        '"%s"' % (table_name, column_name))

    def _pre_get_column(self, _ctx, table_name, column):
        column_name = self._get_column(table_name, column)
        self.schema_helper.register_columns(table_name, [column_name])

    def _pre_get(self, ctx, table_name, columns):
        vsctl_table = self._pre_get_table(ctx, table_name)
        for column in columns:
            self._pre_get_column(ctx, vsctl_table.table_name, column)

    def _pre_cmd_get(self, ctx, command):
        table_name = command.args[0]
        table_schema = self.schema.tables[table_name]
        columns = [ctx.parse_column_key_value(table_schema, column_key)[0]
                   for column_key in command.args[2:]]
        self._pre_get(ctx, table_name, columns)

    def _get(self, ctx, table_name, record_id, column_keys,
             id_=None, if_exists=False):
        """
        :type column_keys: list of (column, key_string)
                                   where column and key are str
        """
        vsctl_table = self._get_table(table_name)
        row = ctx.must_get_row(vsctl_table, record_id)
        if id_:
            raise NotImplementedError()  # TODO:XXX

            symbol, new = ctx.create_symbol(id_)
            if not new:
                vsctl_fatal('row id "%s" specified on "get" command was used '
                            'before it was defined' % id_)
            symbol.uuid = row.uuid
            symbol.strong_ref = True

        values = []
        for column, key_string in column_keys:
            row.verify(column)
            datum = getattr(row, column)
            if key_string:
                if type(datum) != dict:
                    vsctl_fatal('cannot specify key to get for non-map column '
                                '%s' % column)
                values.append(datum[key_string])
            else:
                values.append(datum)

        return values

    def _cmd_get(self, ctx, command):
        id_ = None      # TODO:XXX      --id
        if_exists = command.has_option('--if-exists')
        table_name = command.args[0]
        record_id = command.args[1]
        table_schema = self.schema.tables[table_name]
        column_keys = [ctx.parse_column_key_value(table_schema, column_key)[:2]
                       for column_key in command.args[2:]]

        values = self._get(ctx, table_name, record_id, column_keys,
                           id_, if_exists)
        command.result = values

    def _pre_cmd_find(self, ctx, command):
        table_name = command.args[0]
        table_schema = self.schema.tables[table_name]
        columns = [ctx.parse_column_key_value(table_schema,
                                              column_key_value)[0]
                   for column_key_value in command.args[1:]]
        LOG.debug('columns %s', columns)
        self._pre_get(ctx, table_name, columns)

    def _check_value(self, ovsrec_row, column_key_value):
        column, key, value_json = column_key_value
        column_schema = ovsrec_row._table.columns[column]
        value = ovs.db.data.Datum.from_json(
            column_schema.type, value_json).to_python(ovs.db.idl._uuid_to_row)
        datum = getattr(ovsrec_row, column)
        if key is None:
            if datum == value:
                return True
        else:
            if datum[key] != value:
                return True
        return False

    def _find(self, ctx, table_name, column_key_values):
        result = []
        for ovsrec_row in ctx.idl.tables[table_name].rows.values():
            LOG.debug('ovsrec_row %s', ovsrec_row_to_string(ovsrec_row))
            if all(self._check_value(ovsrec_row, column_key_value)
                   for column_key_value in column_key_values):
                result.append(ovsrec_row)

        return result

    def _cmd_find(self, ctx, command):
        table_name = command.args[0]
        table_schema = self.schema.tables[table_name]
        column_key_values = [ctx.parse_column_key_value(table_schema,
                                                        column_key_value)
                             for column_key_value in command.args[1:]]
        command.result = self._find(ctx, table_name, column_key_values)

    def _check_mutable(self, table_name, column):
        column_schema = self.schema.tables[table_name].columns[column]
        if not column_schema.mutable:
            vsctl_fatal('cannot modify read-only column %s in table %s' %
                        (column, table_name))

    def _pre_set(self, ctx, table_name, columns):
        self._pre_get_table(ctx, table_name)
        for column in columns:
            self._pre_get_column(ctx, table_name, column)
            self._check_mutable(table_name, column)

    def _pre_cmd_set(self, ctx, command):
        table_name = command.args[0]
        table_schema = self.schema.tables[table_name]
        columns = [ctx.parse_column_key_value(table_schema,
                                              column_key_value)[0]
                   for column_key_value in command.args[2:]]
        self._pre_set(ctx, table_name, columns)

    def _set(self, ctx, table_name, record_id, column_key_values):
        """
        :type column_key_values: list of (column, key_string, value_json)
        """
        vsctl_table = self._get_table(table_name)
        ovsrec_row = ctx.must_get_row(vsctl_table, record_id)
        for column, key, value in column_key_values:
            ctx.set_column(ovsrec_row, column, key, value)
        ctx.invalidate_cache()

    def _cmd_set(self, ctx, command):
        table_name = command.args[0]
        record_id = command.args[1]

        # column_key_value: <column>[:<key>]=<value>
        table_schema = self.schema.tables[table_name]
        column_key_values = [ctx.parse_column_key_value(table_schema,
                                                        column_key_value)
                             for column_key_value in command.args[2:]]

        self._set(ctx, table_name, record_id, column_key_values)

    def _pre_clear(self, ctx, table_name, column):
        self._pre_get_table(ctx, table_name)
        self._pre_get_column(ctx, table_name, column)
        self._check_mutable(table_name, column)

    def _pre_cmd_clear(self, ctx, command):
        table_name = command.args[0]
        column = command.args[2]
        self._pre_clear(ctx, table_name, column)

    def _clear(self, ctx, table_name, record_id, column):
        vsctl_table = self._get_table(table_name)
        ovsrec_row = ctx.must_get_row(vsctl_table, record_id)
        column_schema = ctx.idl.tables[table_name].columns[column]
        if column_schema.type.n_min > 0:
            vsctl_fatal('"clear" operation cannot be applied to column %s '
                        'of table %s, which is not allowed to be empty' %
                        (column, table_name))

        # assuming that default datum is empty.
        default_datum = ovs.db.data.Datum.default(column_schema.type)
        setattr(ovsrec_row, column,
                default_datum.to_python(ovs.db.idl._uuid_to_row))
        ctx.invalidate_cache()

    def _cmd_clear(self, ctx, command):
        table_name = command.args[0]
        record_id = command.args[1]
        column = command.args[2]
        self._clear(ctx, table_name, record_id, column)


#
# Create constants from ovs db schema
#

def schema_print(schema_location, prefix):
    prefix = prefix.upper()

    json = ovs.json.from_file(schema_location)
    schema = ovs.db.schema.DbSchema.from_json(json)

    print '# Do NOT edit.'
    print '# This is automatically generated.'
    print '# created based on version %s' % (schema.version or 'unknown')
    print ''
    print ''
    print '%s_DB_NAME = \'%s\'' % (prefix, schema.name)
    for table in sorted(schema.tables.values(),
                        key=operator.attrgetter('name')):
        print ''
        print '%s_TABLE_%s = \'%s\'' % (prefix,
                                        table.name.upper(), table.name)
        for column in sorted(table.columns.values(),
                             key=operator.attrgetter('name')):
            print '%s_%s_COL_%s = \'%s\'' % (prefix, table.name.upper(),
                                             column.name.upper(),
                                             column.name)


def main():
    if len(sys.argv) <= 2:
        print 'Usage: %s <schema file> <prefix>' % sys.argv[0]

    location = sys.argv[1]
    prefix = sys.argv[2]
    schema_print(location, prefix)


if __name__ == '__main__':
    main()

########NEW FILE########
__FILENAME__ = vswitch_idl
# Copyright (C) 2012 Nippon Telegraph and Telephone Corporation.
# Copyright (C) 2012 Isaku Yamahata <yamahata at private email ne jp>
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# created based on
# "version": "6.10.0"
# "cksum": "3699312094 16958"

OVSREC_DB_NAME = 'Open_vSwitch'

OVSREC_TABLE_BRIDGE = 'Bridge'
OVSREC_BRIDGE_COL_CONTROLLER = 'controller'
OVSREC_BRIDGE_COL_DATAPATH_ID = 'datapath_id'
OVSREC_BRIDGE_COL_DATAPATH_TYPE = 'datapath_type'
OVSREC_BRIDGE_COL_EXTERNAL_IDS = 'external_ids'
OVSREC_BRIDGE_COL_FAIL_MODE = 'fail_mode'
OVSREC_BRIDGE_COL_FLOOD_VLANS = 'flood_vlans'
OVSREC_BRIDGE_COL_FLOW_TABLES = 'flow_tables'
OVSREC_BRIDGE_COL_MIRRORS = 'mirrors'
OVSREC_BRIDGE_COL_NAME = 'name'
OVSREC_BRIDGE_COL_NETFLOW = 'netflow'
OVSREC_BRIDGE_COL_OTHER_CONFIG = 'other_config'
OVSREC_BRIDGE_COL_PORTS = 'ports'
OVSREC_BRIDGE_COL_SFLOW = 'sflow'
OVSREC_BRIDGE_COL_STATUS = 'status'
OVSREC_BRIDGE_COL_STP_ENABLE = 'stp_enable'

OVSREC_TABLE_CONTROLLER = 'Controller'
OVSREC_CONTROLLER_COL_CONNECTION_MODE = 'connection_mode'
OVSREC_CONTROLLER_COL_CONTROLLER_BURST_LIMIT = 'controller_burst_limit'
OVSREC_CONTROLLER_COL_CONTROLLER_RATE_LIMIT = 'controller_rate_limit'
OVSREC_CONTROLLER_COL_ENABLE_ASYNC_MESSAGES = 'enable_async_messages'
OVSREC_CONTROLLER_COL_EXTERNAL_IDS = 'external_ids'
OVSREC_CONTROLLER_COL_INACTIVITY_PROBE = 'inactivity_probe'
OVSREC_CONTROLLER_COL_IS_CONNECTED = 'is_connected'
OVSREC_CONTROLLER_COL_LOCAL_GATEWAY = 'local_gateway'
OVSREC_CONTROLLER_COL_LOCAL_IP = 'local_ip'
OVSREC_CONTROLLER_COL_LOCAL_NETMASK = 'local_netmask'
OVSREC_CONTROLLER_COL_MAX_BACKOFF = 'max_backoff'
OVSREC_CONTROLLER_COL_OTHER_CONFIG = 'other_config'
OVSREC_CONTROLLER_COL_ROLE = 'role'
OVSREC_CONTROLLER_COL_STATUS = 'status'
OVSREC_CONTROLLER_COL_TARGET = 'target'

OVSREC_TABLE_FLOW_TABLE = 'Flow_Table'
OVSREC_FLOW_TABLE_COL_FLOW_LIMIT = 'flow_limit'
OVSREC_FLOW_TABLE_COL_GROUPS = 'groups'
OVSREC_FLOW_TABLE_COL_NAME = 'name'
OVSREC_FLOW_TABLE_COL_OVERFLOW_POLICY = 'overflow_policy'

OVSREC_TABLE_INTERFACE = 'Interface'
OVSREC_INTERFACE_COL_ADMIN_STATE = 'admin_state'
OVSREC_INTERFACE_COL_CFM_FAULT = 'cfm_fault'
OVSREC_INTERFACE_COL_CFM_FAULT_STATUS = 'cfm_fault_status'
OVSREC_INTERFACE_COL_CFM_HEALTH = 'cfm_health'
OVSREC_INTERFACE_COL_CFM_MPID = 'cfm_mpid'
OVSREC_INTERFACE_COL_CFM_REMOTE_MPIDS = 'cfm_remote_mpids'
OVSREC_INTERFACE_COL_CFM_REMOTE_OPSTATE = 'cfm_remote_opstate'
OVSREC_INTERFACE_COL_DUPLEX = 'duplex'
OVSREC_INTERFACE_COL_EXTERNAL_IDS = 'external_ids'
OVSREC_INTERFACE_COL_INGRESS_POLICING_BURST = 'ingress_policing_burst'
OVSREC_INTERFACE_COL_INGRESS_POLICING_RATE = 'ingress_policing_rate'
OVSREC_INTERFACE_COL_LACP_CURRENT = 'lacp_current'
OVSREC_INTERFACE_COL_LINK_RESETS = 'link_resets'
OVSREC_INTERFACE_COL_LINK_SPEED = 'link_speed'
OVSREC_INTERFACE_COL_LINK_STATE = 'link_state'
OVSREC_INTERFACE_COL_MAC = 'mac'
OVSREC_INTERFACE_COL_MTU = 'mtu'
OVSREC_INTERFACE_COL_NAME = 'name'
OVSREC_INTERFACE_COL_OFPORT = 'ofport'
OVSREC_INTERFACE_COL_OPTIONS = 'options'
OVSREC_INTERFACE_COL_OTHER_CONFIG = 'other_config'
OVSREC_INTERFACE_COL_STATISTICS = 'statistics'
OVSREC_INTERFACE_COL_STATUS = 'status'
OVSREC_INTERFACE_COL_TYPE = 'type'

OVSREC_TABLE_MANAGER = 'Manager'
OVSREC_MANAGER_COL_CONNECTION_MODE = 'connection_mode'
OVSREC_MANAGER_COL_EXTERNAL_IDS = 'external_ids'
OVSREC_MANAGER_COL_INACTIVITY_PROBE = 'inactivity_probe'
OVSREC_MANAGER_COL_IS_CONNECTED = 'is_connected'
OVSREC_MANAGER_COL_MAX_BACKOFF = 'max_backoff'
OVSREC_MANAGER_COL_OTHER_CONFIG = 'other_config'
OVSREC_MANAGER_COL_STATUS = 'status'
OVSREC_MANAGER_COL_TARGET = 'target'

OVSREC_TABLE_MIRROR = 'Mirror'
OVSREC_MIRROR_COL_EXTERNAL_IDS = 'external_ids'
OVSREC_MIRROR_COL_NAME = 'name'
OVSREC_MIRROR_COL_OUTPUT_PORT = 'output_port'
OVSREC_MIRROR_COL_OUTPUT_VLAN = 'output_vlan'
OVSREC_MIRROR_COL_SELECT_ALL = 'select_all'
OVSREC_MIRROR_COL_SELECT_DST_PORT = 'select_dst_port'
OVSREC_MIRROR_COL_SELECT_SRC_PORT = 'select_src_port'
OVSREC_MIRROR_COL_SELECT_VLAN = 'select_vlan'
OVSREC_MIRROR_COL_STATISTICS = 'statistics'

OVSREC_TABLE_NETFLOW = 'NetFlow'
OVSREC_NETFLOW_COL_ACTIVE_TIMEOUT = 'active_timeout'
OVSREC_NETFLOW_COL_ADD_ID_TO_INTERFACE = 'add_id_to_interface'
OVSREC_NETFLOW_COL_ENGINE_ID = 'engine_id'
OVSREC_NETFLOW_COL_ENGINE_TYPE = 'engine_type'
OVSREC_NETFLOW_COL_EXTERNAL_IDS = 'external_ids'
OVSREC_NETFLOW_COL_TARGETS = 'targets'

OVSREC_TABLE_OPEN_VSWITCH = 'Open_vSwitch'
OVSREC_OPEN_VSWITCH_COL_BRIDGES = 'bridges'
OVSREC_OPEN_VSWITCH_COL_CUR_CFG = 'cur_cfg'
OVSREC_OPEN_VSWITCH_COL_DB_VERSION = 'db_version'
OVSREC_OPEN_VSWITCH_COL_EXTERNAL_IDS = 'external_ids'
OVSREC_OPEN_VSWITCH_COL_MANAGER_OPTIONS = 'manager_options'
OVSREC_OPEN_VSWITCH_COL_NEXT_CFG = 'next_cfg'
OVSREC_OPEN_VSWITCH_COL_OTHER_CONFIG = 'other_config'
OVSREC_OPEN_VSWITCH_COL_OVS_VERSION = 'ovs_version'
OVSREC_OPEN_VSWITCH_COL_SSL = 'ssl'
OVSREC_OPEN_VSWITCH_COL_STATISTICS = 'statistics'
OVSREC_OPEN_VSWITCH_COL_SYSTEM_TYPE = 'system_type'
OVSREC_OPEN_VSWITCH_COL_SYSTEM_VERSION = 'system_version'

OVSREC_TABLE_PORT = 'Port'
OVSREC_PORT_COL_BOND_DOWNDELAY = 'bond_downdelay'
OVSREC_PORT_COL_BOND_FAKE_IFACE = 'bond_fake_iface'
OVSREC_PORT_COL_BOND_MODE = 'bond_mode'
OVSREC_PORT_COL_BOND_UPDELAY = 'bond_updelay'
OVSREC_PORT_COL_EXTERNAL_IDS = 'external_ids'
OVSREC_PORT_COL_FAKE_BRIDGE = 'fake_bridge'
OVSREC_PORT_COL_INTERFACES = 'interfaces'
OVSREC_PORT_COL_LACP = 'lacp'
OVSREC_PORT_COL_MAC = 'mac'
OVSREC_PORT_COL_NAME = 'name'
OVSREC_PORT_COL_OTHER_CONFIG = 'other_config'
OVSREC_PORT_COL_QOS = 'qos'
OVSREC_PORT_COL_STATISTICS = 'statistics'
OVSREC_PORT_COL_STATUS = 'status'
OVSREC_PORT_COL_TAG = 'tag'
OVSREC_PORT_COL_TRUNKS = 'trunks'
OVSREC_PORT_COL_VLAN_MODE = 'vlan_mode'

OVSREC_TABLE_QOS = 'QoS'
OVSREC_QOS_COL_EXTERNAL_IDS = 'external_ids'
OVSREC_QOS_COL_OTHER_CONFIG = 'other_config'
OVSREC_QOS_COL_QUEUES = 'queues'
OVSREC_QOS_COL_TYPE = 'type'

OVSREC_TABLE_QUEUE = 'Queue'
OVSREC_QUEUE_COL_DSCP = 'dscp'
OVSREC_QUEUE_COL_EXTERNAL_IDS = 'external_ids'
OVSREC_QUEUE_COL_OTHER_CONFIG = 'other_config'

OVSREC_TABLE_SSL = 'SSL'
OVSREC_SSL_COL_BOOTSTRAP_CA_CERT = 'bootstrap_ca_cert'
OVSREC_SSL_COL_CA_CERT = 'ca_cert'
OVSREC_SSL_COL_CERTIFICATE = 'certificate'
OVSREC_SSL_COL_EXTERNAL_IDS = 'external_ids'
OVSREC_SSL_COL_PRIVATE_KEY = 'private_key'

OVSREC_TABLE_SFLOW = 'sFlow'
OVSREC_SFLOW_COL_AGENT = 'agent'
OVSREC_SFLOW_COL_EXTERNAL_IDS = 'external_ids'
OVSREC_SFLOW_COL_HEADER = 'header'
OVSREC_SFLOW_COL_POLLING = 'polling'
OVSREC_SFLOW_COL_SAMPLING = 'sampling'
OVSREC_SFLOW_COL_TARGETS = 'targets'

########NEW FILE########
__FILENAME__ = afi
# Copyright (C) 2013 Nippon Telegraph and Telephone Corporation.
# Copyright (C) 2013 YAMAMOTO Takashi <yamamoto at valinux co jp>
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""
Address Family Idenitifier (AFI)
http://www.iana.org/assignments/address-family-numbers/\
address-family-numbers.xhtml
"""

IP = 1
IP6 = 2

########NEW FILE########
__FILENAME__ = arp
# Copyright (C) 2012 Nippon Telegraph and Telephone Corporation.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import struct

from ryu.ofproto import ether
from ryu.lib import addrconv
from . import packet_base

ARP_HW_TYPE_ETHERNET = 1  # ethernet hardware type

# arp operation codes
ARP_REQUEST = 1
ARP_REPLY = 2
ARP_REV_REQUEST = 3
ARP_REV_REPLY = 4


class arp(packet_base.PacketBase):
    """ARP (RFC 826) header encoder/decoder class.

    An instance has the following attributes at least.
    Most of them are same to the on-wire counterparts but in host byte order.
    IPv4 addresses are represented as a string like '192.0.2.1'.
    MAC addresses are represented as a string like '08:60:6e:7f:74:e7'.
    __init__ takes the corresponding args in this order.

    ============== ==================== =====================
    Attribute      Description          Example
    ============== ==================== =====================
    hwtype         ar$hrd
    proto          ar$pro
    hlen           ar$hln
    plen           ar$pln
    opcode         ar$op
    src_mac        ar$sha               '08:60:6e:7f:74:e7'
    src_ip         ar$spa               '192.0.2.1'
    dst_mac        ar$tha               '00:00:00:00:00:00'
    dst_ip         ar$tpa               '192.0.2.2'
    ============== ==================== =====================
    """

    _PACK_STR = '!HHBBH6s4s6s4s'
    _MIN_LEN = struct.calcsize(_PACK_STR)

    def __init__(self, hwtype=ARP_HW_TYPE_ETHERNET, proto=ether.ETH_TYPE_IP,
                 hlen=6, plen=4, opcode=ARP_REQUEST,
                 src_mac='ff:ff:ff:ff:ff:ff',
                 src_ip='0.0.0.0',
                 dst_mac='ff:ff:ff:ff:ff:ff',
                 dst_ip='0.0.0.0'):
        super(arp, self).__init__()
        self.hwtype = hwtype
        self.proto = proto
        self.hlen = hlen
        self.plen = plen
        self.opcode = opcode
        self.src_mac = src_mac
        self.src_ip = src_ip
        self.dst_mac = dst_mac
        self.dst_ip = dst_ip

    @classmethod
    def parser(cls, buf):
        (hwtype, proto, hlen, plen, opcode, src_mac, src_ip,
         dst_mac, dst_ip) = struct.unpack_from(cls._PACK_STR, buf)
        return cls(hwtype, proto, hlen, plen, opcode,
                   addrconv.mac.bin_to_text(src_mac),
                   addrconv.ipv4.bin_to_text(src_ip),
                   addrconv.mac.bin_to_text(dst_mac),
                   addrconv.ipv4.bin_to_text(dst_ip)), None, buf[arp._MIN_LEN:]

    def serialize(self, payload, prev):
        return struct.pack(arp._PACK_STR, self.hwtype, self.proto,
                           self.hlen, self.plen, self.opcode,
                           addrconv.mac.text_to_bin(self.src_mac),
                           addrconv.ipv4.text_to_bin(self.src_ip),
                           addrconv.mac.text_to_bin(self.dst_mac),
                           addrconv.ipv4.text_to_bin(self.dst_ip))


def arp_ip(opcode, src_mac, src_ip, dst_mac, dst_ip):
    """A convenient wrapper for IPv4 ARP for Ethernet.

    This is an equivalent of the following code.

        arp(ARP_HW_TYPE_ETHERNET, ether.ETH_TYPE_IP, \
               6, 4, opcode, src_mac, src_ip, dst_mac, dst_ip)
    """
    return arp(ARP_HW_TYPE_ETHERNET, ether.ETH_TYPE_IP,
               6,  # ether mac address length
               4,  # ipv4 address length,
               opcode, src_mac, src_ip, dst_mac, dst_ip)

########NEW FILE########
__FILENAME__ = bgp
# Copyright (C) 2013 Nippon Telegraph and Telephone Corporation.
# Copyright (C) 2013 YAMAMOTO Takashi <yamamoto at valinux co jp>
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""
RFC 4271 BGP-4
"""

# todo
# - notify data
# - notify subcode constants
# - RFC 3107 Carrying Label Information in BGP-4
# - RFC 4364 BGP/MPLS IP Virtual Private Networks (VPNs)
# - RFC 4486 Subcodes for BGP Cease Notification Message

import abc
import struct

from ryu.ofproto.ofproto_parser import msg_pack_into
from ryu.lib.stringify import StringifyMixin
from ryu.lib.packet import packet_base
from ryu.lib.packet import stream_parser
from ryu.lib import addrconv


BGP_MSG_OPEN = 1
BGP_MSG_UPDATE = 2
BGP_MSG_NOTIFICATION = 3
BGP_MSG_KEEPALIVE = 4
BGP_MSG_ROUTE_REFRESH = 5  # RFC 2918

# RFC 4271 4.5.
BGP_ERROR_MESSAGE_HEADER_ERROR = 1
BGP_ERROR_OPEN_MESSAGE_ERROR = 2
BGP_ERROR_UPDATE_MESSAGE_ERROR = 3
BGP_ERROR_HOLD_TIMER_EXPIRED = 4
BGP_ERROR_FSM_ERROR = 5
BGP_ERROR_CEASE = 6

_VERSION = 4
_MARKER = 16 * '\xff'

BGP_OPT_CAPABILITY = 2  # RFC 5492

BGP_CAP_MULTIPROTOCOL = 1  # RFC 4760
BGP_CAP_ROUTE_REFRESH = 2  # RFC 2918
BGP_CAP_FOUR_OCTET_AS_NUMBER = 65  # RFC 4893

BGP_ATTR_FLAG_OPTIONAL = 1 << 7
BGP_ATTR_FLAG_TRANSITIVE = 1 << 6
BGP_ATTR_FLAG_PARTIAL = 1 << 5
BGP_ATTR_FLAG_EXTENDED_LENGTH = 1 << 4

BGP_ATTR_TYPE_ORIGIN = 1  # 0,1,2 (1 byte)
BGP_ATTR_TYPE_AS_PATH = 2  # a list of AS_SET/AS_SEQUENCE  eg. {1 2 3} 4 5
BGP_ATTR_TYPE_NEXT_HOP = 3  # an IPv4 address
BGP_ATTR_TYPE_MULTI_EXIT_DISC = 4  # uint32 metric
BGP_ATTR_TYPE_LOCAL_PREF = 5  # uint32
BGP_ATTR_TYPE_ATOMIC_AGGREGATE = 6  # 0 bytes
BGP_ATTR_TYPE_AGGREGATOR = 7  # AS number and IPv4 address
BGP_ATTR_TYPE_COMMUNITIES = 8  # RFC 1997
BGP_ATTR_TYPE_MP_REACH_NLRI = 14  # RFC 4760
BGP_ATTR_TYPE_MP_UNREACH_NLRI = 15  # RFC 4760
BGP_ATTR_TYPE_EXTENDED_COMMUNITIES = 16  # RFC 4360
BGP_ATTR_TYPE_AS4_PATH = 17  # RFC 4893
BGP_ATTR_TYPE_AS4_AGGREGATOR = 18  # RFC 4893

AS_TRANS = 23456  # RFC 4893

# Well known commmunities  (RFC 1997)
BGP_COMMUNITY_NO_EXPORT = 0xffffff01
BGP_COMMUNITY_NO_ADVERTISE = 0xffffff02
BGP_COMMUNITY_NO_EXPORT_SUBCONFED = 0xffffff03

# RFC 4360
BGP_EXTENDED_COMMUNITY_ROUTE_TARGET = 0x02
BGP_EXTENDED_COMMUNITY_ROUTE_ORIGIN = 0x03


def pad(bin, len_):
    assert len(bin) <= len_
    return bin + (len_ - len(bin)) * '\0'


class _AddrPrefix(StringifyMixin):
    __metaclass__ = abc.ABCMeta
    _PACK_STR = '!B'  # length

    def __init__(self, length, addr):
        self.length = length
        self.addr = addr

    @staticmethod
    @abc.abstractmethod
    def _to_bin(addr):
        return addr

    @staticmethod
    @abc.abstractmethod
    def _to_text(addr):
        return addr

    @classmethod
    def parser(cls, buf):
        (length, ) = struct.unpack_from(cls._PACK_STR, buffer(buf))
        rest = buf[struct.calcsize(cls._PACK_STR):]
        byte_length = (length + 7) / 8
        addr = cls._to_text(rest[:byte_length])
        rest = rest[byte_length:]
        return cls(length=length, addr=addr), rest

    def serialize(self):
        # fixup
        byte_length = (self.length + 7) / 8
        bin_addr = self._to_bin(self.addr)
        if (self.length % 8) == 0:
            bin_addr = bin_addr[:byte_length]
        else:
            # clear trailing bits in the last octet.
            # rfc doesn't require this.
            mask = 0xff00 >> (self.length % 8)
            last_byte = chr(ord(bin_addr[byte_length - 1]) & mask)
            bin_addr = bin_addr[:byte_length - 1] + last_byte
        self.addr = self._to_text(bin_addr)

        buf = bytearray()
        msg_pack_into(self._PACK_STR, buf, 0, self.length)
        return buf + bytes(bin_addr)


class _BinAddrPrefix(_AddrPrefix):
    @staticmethod
    def _to_bin(addr):
        return addr

    @staticmethod
    def _to_text(addr):
        return addr


class _IPAddrPrefix(_AddrPrefix):
    @staticmethod
    def _to_bin(addr):
        return addrconv.ipv4.text_to_bin(addr)

    @staticmethod
    def _to_text(addr):
        return addrconv.ipv4.bin_to_text(pad(addr, 4))


class _Value(object):
    _VALUE_PACK_STR = None
    _VALUE_FIELDS = ['value']

    @staticmethod
    def do_init(cls, self, kwargs, **extra_kwargs):
        ourfields = {}
        for f in cls._VALUE_FIELDS:
            v = kwargs[f]
            del kwargs[f]
            ourfields[f] = v
        kwargs.update(extra_kwargs)
        super(cls, self).__init__(**kwargs)
        self.__dict__.update(ourfields)

    @classmethod
    def parse_value(cls, buf):
        values = struct.unpack_from(cls._VALUE_PACK_STR, buffer(buf))
        return dict(zip(cls._VALUE_FIELDS, values))

    def serialize_value(self):
        args = []
        for f in self._VALUE_FIELDS:
            args.append(getattr(self, f))
        buf = bytearray()
        msg_pack_into(self._VALUE_PACK_STR, buf, 0, *args)
        return buf


class _TypeDisp(object):
    _TYPES = {}
    _REV_TYPES = None
    _UNKNOWN_TYPE = None

    @classmethod
    def register_unknown_type(cls):
        def _register_type(subcls):
            cls._UNKNOWN_TYPE = subcls
            return subcls
        return _register_type

    @classmethod
    def register_type(cls, type_):
        cls._TYPES = cls._TYPES.copy()

        def _register_type(subcls):
            cls._TYPES[type_] = subcls
            cls._REV_TYPES = None
            return subcls
        return _register_type

    @classmethod
    def _lookup_type(cls, type_):
        try:
            return cls._TYPES[type_]
        except KeyError:
            return cls._UNKNOWN_TYPE

    @classmethod
    def _rev_lookup_type(cls, targ_cls):
        if cls._REV_TYPES is None:
            rev = dict((v, k) for k, v in cls._TYPES.iteritems())
            cls._REV_TYPES = rev
        return cls._REV_TYPES[targ_cls]


class _OptParam(StringifyMixin, _TypeDisp, _Value):
    _PACK_STR = '!BB'  # type, length

    def __init__(self, type_, value=None, length=None):
        if type_ is None:
            type_ = self._rev_lookup_type(self.__class__)
        self.type = type_
        self.length = length
        if not value is None:
            self.value = value

    @classmethod
    def parser(cls, buf):
        (type_, length) = struct.unpack_from(cls._PACK_STR, buffer(buf))
        rest = buf[struct.calcsize(cls._PACK_STR):]
        value = bytes(rest[:length])
        rest = rest[length:]
        subcls = cls._lookup_type(type_)
        kwargs, subcls = subcls.parse_value(value)
        return subcls(type_=type_, length=length, **kwargs), rest

    def serialize(self):
        # fixup
        value = self.serialize_value()
        self.length = len(value)

        buf = bytearray()
        msg_pack_into(self._PACK_STR, buf, 0, self.type, self.length)
        return buf + value


@_OptParam.register_unknown_type()
class BGPOptParamUnknown(_OptParam):
    @classmethod
    def parse_value(cls, buf):
        return {
            'value': buf
        }, cls

    def serialize_value(self):
        return self.value


@_OptParam.register_type(BGP_OPT_CAPABILITY)
class _OptParamCapability(_OptParam, _TypeDisp):
    _CAP_HDR_PACK_STR = '!BB'

    def __init__(self, cap_code=None, cap_value=None, cap_length=None,
                 type_=None, length=None):
        super(_OptParamCapability, self).__init__(type_=BGP_OPT_CAPABILITY,
                                                  length=length)
        if cap_code is None:
            cap_code = self._rev_lookup_type(self.__class__)
        self.cap_code = cap_code
        if not cap_value is None:
            self.cap_value = cap_value
        if not cap_length is None:
            self.cap_length = cap_length

    @classmethod
    def parse_value(cls, buf):
        (code, length) = struct.unpack_from(cls._CAP_HDR_PACK_STR, buffer(buf))
        value = buf[struct.calcsize(cls._CAP_HDR_PACK_STR):]
        assert len(value) == length
        kwargs = {
            'cap_code': code,
            'cap_length': length,
        }
        subcls = cls._lookup_type(code)
        kwargs.update(subcls.parse_cap_value(value))
        return kwargs, subcls

    def serialize_value(self):
        # fixup
        cap_value = self.serialize_cap_value()
        self.cap_length = len(cap_value)

        buf = bytearray()
        msg_pack_into(self._CAP_HDR_PACK_STR, buf, 0, self.cap_code,
                      self.cap_length)
        return buf + cap_value


@_OptParamCapability.register_unknown_type()
class BGPOptParamCapabilityUnknown(_OptParamCapability):
    @classmethod
    def parse_cap_value(cls, buf):
        return {'cap_value': buf}

    def serialize_cap_value(self):
        return self.cap_value


@_OptParamCapability.register_type(BGP_CAP_ROUTE_REFRESH)
class BGPOptParamCapabilityRouteRefresh(_OptParamCapability):
    @classmethod
    def parse_cap_value(cls, buf):
        return {}

    def serialize_cap_value(self):
        return bytearray()


@_OptParamCapability.register_type(BGP_CAP_FOUR_OCTET_AS_NUMBER)
class BGPOptParamCapabilityFourOctetAsNumber(_OptParamCapability):
    _CAP_PACK_STR = '!I'

    def __init__(self, as_number, **kwargs):
        super(BGPOptParamCapabilityFourOctetAsNumber, self).__init__(**kwargs)
        self.as_number = as_number

    @classmethod
    def parse_cap_value(cls, buf):
        (as_number, ) = struct.unpack_from(cls._CAP_PACK_STR, buffer(buf))
        return {'as_number': as_number}

    def serialize_cap_value(self):
        buf = bytearray()
        msg_pack_into(self._CAP_PACK_STR, buf, 0, self.as_number)
        return buf


@_OptParamCapability.register_type(BGP_CAP_MULTIPROTOCOL)
class BGPOptParamCapabilityMultiprotocol(_OptParamCapability):
    _CAP_PACK_STR = '!HBB'  # afi, reserved, safi

    def __init__(self, afi, safi, reserved=0, **kwargs):
        super(BGPOptParamCapabilityMultiprotocol, self).__init__(**kwargs)
        self.afi = afi
        self.reserved = reserved
        self.safi = safi

    @classmethod
    def parse_cap_value(cls, buf):
        (afi, reserved, safi,) = struct.unpack_from(cls._CAP_PACK_STR,
                                                    buffer(buf))
        return {
            'afi': afi,
            'reserved': reserved,
            'safi': safi,
        }

    def serialize_cap_value(self):
        # fixup
        self.reserved = 0

        buf = bytearray()
        msg_pack_into(self._CAP_PACK_STR, buf, 0,
                      self.afi, self.reserved, self.safi)
        return buf


class BGPWithdrawnRoute(_IPAddrPrefix):
    pass


class _PathAttribute(StringifyMixin, _TypeDisp, _Value):
    _PACK_STR = '!BB'  # flags, type
    _PACK_STR_LEN = '!B'  # length
    _PACK_STR_EXT_LEN = '!H'  # length w/ BGP_ATTR_FLAG_EXTENDED_LENGTH
    _ATTR_FLAGS = None

    def __init__(self, value=None, flags=0, type_=None, length=None):
        if type_ is None:
            type_ = self._rev_lookup_type(self.__class__)
        self.flags = flags
        self.type = type_
        self.length = length
        if not value is None:
            self.value = value

    @classmethod
    def parser(cls, buf):
        (flags, type_) = struct.unpack_from(cls._PACK_STR, buffer(buf))
        rest = buf[struct.calcsize(cls._PACK_STR):]
        if (flags & BGP_ATTR_FLAG_EXTENDED_LENGTH) != 0:
            len_pack_str = cls._PACK_STR_EXT_LEN
        else:
            len_pack_str = cls._PACK_STR_LEN
        (length,) = struct.unpack_from(len_pack_str, buffer(rest))
        rest = rest[struct.calcsize(len_pack_str):]
        value = bytes(rest[:length])
        rest = rest[length:]
        subcls = cls._lookup_type(type_)
        return subcls(flags=flags, type_=type_, length=length,
                      **subcls.parse_value(value)), rest

    def serialize(self):
        # fixup
        if not self._ATTR_FLAGS is None:
            self.flags = self.flags \
                & ~(BGP_ATTR_FLAG_OPTIONAL | BGP_ATTR_FLAG_TRANSITIVE) \
                | self._ATTR_FLAGS
        value = self.serialize_value()
        self.length = len(value)
        if self.length > 255:
            self.flags |= BGP_ATTR_FLAG_EXTENDED_LENGTH
            len_pack_str = self._PACK_STR_EXT_LEN
        else:
            self.flags &= ~BGP_ATTR_FLAG_EXTENDED_LENGTH
            len_pack_str = self._PACK_STR_LEN

        buf = bytearray()
        msg_pack_into(self._PACK_STR, buf, 0, self.flags, self.type)
        msg_pack_into(len_pack_str, buf, len(buf), self.length)
        return buf + value


@_PathAttribute.register_unknown_type()
class BGPPathAttributeUnknown(_PathAttribute):
    @classmethod
    def parse_value(cls, buf):
        return {
            'value': buf
        }

    def serialize_value(self):
        return self.value


class _PathAttributeUint32(_PathAttribute):
    _VALUE_PACK_STR = '!I'


@_PathAttribute.register_type(BGP_ATTR_TYPE_ORIGIN)
class BGPPathAttributeOrigin(_PathAttribute):
    _VALUE_PACK_STR = '!B'
    _ATTR_FLAGS = BGP_ATTR_FLAG_TRANSITIVE


class _BGPPathAttributeAsPathCommon(_PathAttribute):
    _AS_SET = 1
    _AS_SEQUENCE = 2
    _SEG_HDR_PACK_STR = '!BB'
    _AS_PACK_STR = None
    _ATTR_FLAGS = BGP_ATTR_FLAG_TRANSITIVE

    @classmethod
    def parse_value(cls, buf):
        result = []
        while buf:
            (type_, num_as) = struct.unpack_from(cls._SEG_HDR_PACK_STR,
                                                 buffer(buf))
            buf = buf[struct.calcsize(cls._SEG_HDR_PACK_STR):]
            l = []
            for i in xrange(0, num_as):
                (as_number,) = struct.unpack_from(cls._AS_PACK_STR,
                                                  buffer(buf))
                buf = buf[struct.calcsize(cls._AS_PACK_STR):]
                l.append(as_number)
            if type_ == cls._AS_SET:
                result.append(set(l))
            elif type_ == cls._AS_SEQUENCE:
                result.append(l)
            else:
                assert(0)  # protocol error
        return {
            'value': result
        }

    def serialize_value(self):
        buf = bytearray()
        offset = 0
        for e in self.value:
            if isinstance(e, set):
                type_ = self._AS_SET
            elif isinstance(e, list):
                type_ = self._AS_SEQUENCE
            l = list(e)
            num_as = len(l)
            msg_pack_into(self._SEG_HDR_PACK_STR, buf, offset, type_, num_as)
            offset += struct.calcsize(self._SEG_HDR_PACK_STR)
            for i in l:
                msg_pack_into(self._AS_PACK_STR, buf, offset, i)
                offset += struct.calcsize(self._AS_PACK_STR)
        return buf


@_PathAttribute.register_type(BGP_ATTR_TYPE_AS_PATH)
class BGPPathAttributeAsPath(_BGPPathAttributeAsPathCommon):
    # XXX currently this implementation assumes 16 bit AS numbers.
    # depends on negotiated capability, AS numbers can be 32 bit.
    # while wireshark seems to attempt auto-detect, it seems that
    # there's no way to detect it reliably.  for example, the
    # following byte sequence can be interpreted in two ways.
    #   01 02 99 88 77 66 02 01 55 44
    #   AS_SET num=2 9988 7766 AS_SEQUENCE num=1 5544
    #   AS_SET num=2 99887766 02015544
    _AS_PACK_STR = '!H'


@_PathAttribute.register_type(BGP_ATTR_TYPE_AS4_PATH)
class BGPPathAttributeAs4Path(_BGPPathAttributeAsPathCommon):
    _AS_PACK_STR = '!I'


@_PathAttribute.register_type(BGP_ATTR_TYPE_NEXT_HOP)
class BGPPathAttributeNextHop(_PathAttribute):
    _VALUE_PACK_STR = '!4s'
    _ATTR_FLAGS = BGP_ATTR_FLAG_TRANSITIVE

    @classmethod
    def parse_value(cls, buf):
        (ip_addr,) = struct.unpack_from(cls._VALUE_PACK_STR, buffer(buf))
        return {
            'value': addrconv.ipv4.bin_to_text(ip_addr),
        }

    def serialize_value(self):
        buf = bytearray()
        msg_pack_into(self._VALUE_PACK_STR, buf, 0,
                      addrconv.ipv4.text_to_bin(self.value))
        return buf


@_PathAttribute.register_type(BGP_ATTR_TYPE_MULTI_EXIT_DISC)
class BGPPathAttributeMultiExitDisc(_PathAttributeUint32):
    _ATTR_FLAGS = BGP_ATTR_FLAG_OPTIONAL


@_PathAttribute.register_type(BGP_ATTR_TYPE_LOCAL_PREF)
class BGPPathAttributeLocalPref(_PathAttributeUint32):
    _ATTR_FLAGS = BGP_ATTR_FLAG_TRANSITIVE


@_PathAttribute.register_type(BGP_ATTR_TYPE_ATOMIC_AGGREGATE)
class BGPPathAttributeAtomicAggregate(_PathAttribute):
    _ATTR_FLAGS = BGP_ATTR_FLAG_TRANSITIVE

    @classmethod
    def parse_value(cls, buf):
        return {}

    def serialize_value(self):
        return ''


class _BGPPathAttributeAggregatorCommon(_PathAttribute):
    _VALUE_PACK_STR = None
    _ATTR_FLAGS = BGP_ATTR_FLAG_OPTIONAL | BGP_ATTR_FLAG_TRANSITIVE

    def __init__(self, as_number, addr, flags=0, type_=None, length=None):
        super(_BGPPathAttributeAggregatorCommon, self).__init__(flags=flags,
                                                                type_=type_,
                                                                length=length)
        self.as_number = as_number
        self.addr = addr

    @classmethod
    def parse_value(cls, buf):
        (as_number, addr) = struct.unpack_from(cls._VALUE_PACK_STR,
                                               buffer(buf))
        return {
            'as_number': as_number,
            'addr': addrconv.ipv4.bin_to_text(addr),
        }

    def serialize_value(self):
        buf = bytearray()
        msg_pack_into(self._VALUE_PACK_STR, buf, 0, self.as_number,
                      addrconv.ipv4.text_to_bin(self.addr))
        return buf


@_PathAttribute.register_type(BGP_ATTR_TYPE_AGGREGATOR)
class BGPPathAttributeAggregator(_BGPPathAttributeAggregatorCommon):
    # XXX currently this implementation assumes 16 bit AS numbers.
    _VALUE_PACK_STR = '!H4s'


@_PathAttribute.register_type(BGP_ATTR_TYPE_AS4_AGGREGATOR)
class BGPPathAttributeAs4Aggregator(_BGPPathAttributeAggregatorCommon):
    _VALUE_PACK_STR = '!I4s'


@_PathAttribute.register_type(BGP_ATTR_TYPE_COMMUNITIES)
class BGPPathAttributeCommunities(_PathAttribute):
    _VALUE_PACK_STR = '!I'
    _ATTR_FLAGS = BGP_ATTR_FLAG_OPTIONAL | BGP_ATTR_FLAG_TRANSITIVE

    def __init__(self, communities,
                 flags=0, type_=None, length=None):
        super(BGPPathAttributeCommunities, self).__init__(flags=flags,
                                                          type_=type_,
                                                          length=length)
        self.communities = communities

    @classmethod
    def parse_value(cls, buf):
        rest = buf
        communities = []
        elem_size = struct.calcsize(cls._VALUE_PACK_STR)
        while len(rest) >= elem_size:
            (comm, ) = struct.unpack_from(cls._VALUE_PACK_STR, buffer(rest))
            communities.append(comm)
            rest = rest[elem_size:]
        return {
            'communities': communities,
        }

    def serialize_value(self):
        buf = bytearray()
        for comm in self.communities:
            bincomm = bytearray()
            msg_pack_into(self._VALUE_PACK_STR, bincomm, 0, comm)
            buf += bincomm
        return buf


# Extended Communities
# RFC 4360
# RFC 5668
# IANA registry:
# https://www.iana.org/assignments/bgp-extended-communities/
# bgp-extended-communities.xml
#
# type
# high  low
# 00    sub-type    Two-Octet AS Specific Extended Community (transitive)
# 40    sub-type    Two-Octet AS Specific Extended Community
#                   payload:
#                     2 byte Global Administrator (AS number)
#                     4 byte Local Administrator (defined by sub-type)
# 01    sub-type    IPv4 Address Specific Extended Community (transitive)
# 41    sub-type    IPv4 Address Specific Extended Community
#                   payload:
#                     4 byte Global Administrator (IPv4 address)
#                     2 byte Local Administrator (defined by sub-type)
# 03    sub-type    Opaque Extended Community (transitive)
# 43    sub-type    Opaque Extended Community
#                   payload:
#                     6 byte opaque value (defined by sub-type)
#
# 00    02          Route Target Community (two-octet AS specific)
# 01    02          Route Target Community (IPv4 address specific)
# 02    02          Route Target Community (four-octet AS specific, RFC 5668)
# 00    03          Route Origin Community (two-octet AS specific)
# 01    03          Route Origin Community (IPv4 address specific)
# 02    03          Route Origin Community (four-octet AS specific, RFC 5668)
@_PathAttribute.register_type(BGP_ATTR_TYPE_EXTENDED_COMMUNITIES)
class BGPPathAttributeExtendedCommunities(_PathAttribute):
    _ATTR_FLAGS = BGP_ATTR_FLAG_OPTIONAL | BGP_ATTR_FLAG_TRANSITIVE

    def __init__(self, communities,
                 flags=0, type_=None, length=None):
        super(BGPPathAttributeExtendedCommunities,
              self).__init__(flags=flags,
                             type_=type_,
                             length=length)
        self.communities = communities

    @classmethod
    def parse_value(cls, buf):
        rest = buf
        communities = []
        while rest:
            comm, rest = _ExtendedCommunity.parse(rest)
            communities.append(comm)
        return {
            'communities': communities,
        }

    def serialize_value(self):
        buf = bytearray()
        for comm in self.communities:
            buf += comm.serialize()
        return buf


class _ExtendedCommunity(StringifyMixin, _TypeDisp, _Value):
    _PACK_STR = '!B7s'  # type high (+ type low) + value
    IANA_AUTHORITY = 0x80
    TRANSITIVE = 0x40
    _TYPE_HIGH_MASK = ~TRANSITIVE

    TWO_OCTET_AS_SPECIFIC = 0x00
    IPV4_ADDRESS_SPECIFIC = 0x01
    FOUR_OCTET_AS_SPECIFIC = 0x02
    OPAQUE = 0x03

    def __init__(self, type_):
        self.type = type_

    @classmethod
    def parse(cls, buf):
        (type_high, payload) = struct.unpack_from(cls._PACK_STR, buffer(buf))
        rest = buf[struct.calcsize(cls._PACK_STR):]
        type_ = type_high & cls._TYPE_HIGH_MASK
        subcls = cls._lookup_type(type_)
        return subcls(type_=type_high,
                      **subcls.parse_value(payload)), rest

    def serialize(self):
        buf = bytearray()
        msg_pack_into(self._PACK_STR, buf, 0, self.type,
                      bytes(self.serialize_value()))
        return buf


@_ExtendedCommunity.register_type(_ExtendedCommunity.TWO_OCTET_AS_SPECIFIC)
class BGPTwoOctetAsSpecificExtendedCommunity(_ExtendedCommunity):
    _VALUE_PACK_STR = '!BHI'  # sub type, as number, local adm
    _VALUE_FIELDS = ['subtype', 'as_number', 'local_administrator']

    def __init__(self, type_=_ExtendedCommunity.TWO_OCTET_AS_SPECIFIC,
                 **kwargs):
        self.do_init(BGPTwoOctetAsSpecificExtendedCommunity, self, kwargs,
                     type_=type_)


@_ExtendedCommunity.register_type(_ExtendedCommunity.IPV4_ADDRESS_SPECIFIC)
class BGPIPv4AddressSpecificExtendedCommunity(_ExtendedCommunity):
    _VALUE_PACK_STR = '!B4sH'  # sub type, IPv4 address, local adm
    _VALUE_FIELDS = ['subtype', 'ipv4_address', 'local_administrator']

    def __init__(self, type_=_ExtendedCommunity.IPV4_ADDRESS_SPECIFIC,
                 **kwargs):
        self.do_init(BGPIPv4AddressSpecificExtendedCommunity, self, kwargs,
                     type_=type_)

    @classmethod
    def parse_value(cls, buf):
        d_ = super(BGPIPv4AddressSpecificExtendedCommunity,
                   cls).parse_value(buf)
        d_['ipv4_address'] = addrconv.ipv4.bin_to_text(d_['ipv4_address'])
        return d_

    def serialize_value(self):
        args = []
        for f in self._VALUE_FIELDS:
            v = getattr(self, f)
            if f == 'ipv4_address':
                v = bytes(addrconv.ipv4.text_to_bin(v))
            args.append(v)
        buf = bytearray()
        msg_pack_into(self._VALUE_PACK_STR, buf, 0, *args)
        return buf


@_ExtendedCommunity.register_type(_ExtendedCommunity.FOUR_OCTET_AS_SPECIFIC)
class BGPFourOctetAsSpecificExtendedCommunity(_ExtendedCommunity):
    _VALUE_PACK_STR = '!BIH'  # sub type, as number, local adm
    _VALUE_FIELDS = ['subtype', 'as_number', 'local_administrator']

    def __init__(self, type_=_ExtendedCommunity.FOUR_OCTET_AS_SPECIFIC,
                 **kwargs):
        self.do_init(BGPFourOctetAsSpecificExtendedCommunity, self, kwargs,
                     type_=type_)


@_ExtendedCommunity.register_type(_ExtendedCommunity.OPAQUE)
class BGPOpaqueExtendedCommunity(_ExtendedCommunity):
    _VALUE_PACK_STR = '!7s'  # opaque value
    _VALUE_FIELDS = ['opaque']

    def __init__(self, type_=_ExtendedCommunity.OPAQUE,
                 **kwargs):
        self.do_init(BGPOpaqueExtendedCommunity, self, kwargs,
                     type_=type_)


@_ExtendedCommunity.register_unknown_type()
class BGPUnknownExtendedCommunity(_ExtendedCommunity):
    _VALUE_PACK_STR = '!7s'  # opaque value

    def __init__(self, **kwargs):
        self.do_init(BGPUnknownExtendedCommunity, self, kwargs)


@_PathAttribute.register_type(BGP_ATTR_TYPE_MP_REACH_NLRI)
class BGPPathAttributeMpReachNLRI(_PathAttribute):
    _VALUE_PACK_STR = '!HBB'  # afi, safi, next hop len
    _ATTR_FLAGS = BGP_ATTR_FLAG_OPTIONAL

    def __init__(self, afi, safi, next_hop, nlri,
                 next_hop_len=0, reserved='\0',
                 flags=0, type_=None, length=None):
        super(BGPPathAttributeMpReachNLRI, self).__init__(flags=flags,
                                                          type_=type_,
                                                          length=length)
        self.afi = afi
        self.safi = safi
        self.next_hop_len = next_hop_len
        self.next_hop = next_hop
        self.reserved = reserved
        self.nlri = nlri

    @classmethod
    def parse_value(cls, buf):
        (afi, safi, next_hop_len,) = struct.unpack_from(cls._VALUE_PACK_STR,
                                                        buffer(buf))
        rest = buf[struct.calcsize(cls._VALUE_PACK_STR):]
        next_hop_bin = rest[:next_hop_len]
        rest = rest[next_hop_len:]
        reserved = rest[:1]
        binnlri = rest[1:]
        nlri = []
        while binnlri:
            n, binnlri = _BinAddrPrefix.parser(binnlri)
            nlri.append(n)
        return {
            'afi': afi,
            'safi': safi,
            'next_hop_len': next_hop_len,
            'next_hop': next_hop_bin,
            'reserved': reserved,
            'nlri': nlri,
        }

    def serialize_value(self):
        # fixup
        self.next_hop_len = len(self.next_hop)
        self.reserved = '\0'

        buf = bytearray()
        msg_pack_into(self._VALUE_PACK_STR, buf, 0, self.afi,
                      self.safi, self.next_hop_len)
        buf += self.next_hop
        buf += self.reserved
        binnlri = bytearray()
        for n in self.nlri:
            binnlri += n.serialize()
        buf += binnlri
        return buf


@_PathAttribute.register_type(BGP_ATTR_TYPE_MP_UNREACH_NLRI)
class BGPPathAttributeMpUnreachNLRI(_PathAttribute):
    _VALUE_PACK_STR = '!HB'  # afi, safi
    _ATTR_FLAGS = BGP_ATTR_FLAG_OPTIONAL

    def __init__(self, afi, safi, withdrawn_routes,
                 flags=0, type_=None, length=None):
        super(BGPPathAttributeMpUnreachNLRI, self).__init__(flags=flags,
                                                            type_=type_,
                                                            length=length)
        self.afi = afi
        self.safi = safi
        self.withdrawn_routes = withdrawn_routes

    @classmethod
    def parse_value(cls, buf):
        (afi, safi,) = struct.unpack_from(cls._VALUE_PACK_STR, buffer(buf))
        binnlri = buf[struct.calcsize(cls._VALUE_PACK_STR):]
        nlri = []
        while binnlri:
            n, binnlri = _BinAddrPrefix.parser(binnlri)
            nlri.append(n)
        return {
            'afi': afi,
            'safi': safi,
            'withdrawn_routes': nlri,
        }

    def serialize_value(self):
        buf = bytearray()
        msg_pack_into(self._VALUE_PACK_STR, buf, 0, self.afi, self.safi)
        binnlri = bytearray()
        for n in self.withdrawn_routes:
            binnlri += n.serialize()
        buf += binnlri
        return buf


class BGPNLRI(_IPAddrPrefix):
    pass


class BGPMessage(packet_base.PacketBase, _TypeDisp):
    """Base class for BGP-4 messages.

    An instance has the following attributes at least.
    Most of them are same to the on-wire counterparts but in host byte
    order.
    __init__ takes the corresponding args in this order.

    ========================== ===============================================
    Attribute                  Description
    ========================== ===============================================
    marker                     Marker field.  Ignored when encoding.
    len                        Length field.  Ignored when encoding.
    type                       Type field.  one of BGP\_MSG\_ constants.
    ========================== ===============================================
    """

    _HDR_PACK_STR = '!16sHB'  # marker, len, type
    _HDR_LEN = struct.calcsize(_HDR_PACK_STR)

    def __init__(self, type_, len_=None, marker=None):
        if marker is None:
            self.marker = _MARKER
        else:
            self.marker = marker
        self.len = len_
        self.type = type_

    @classmethod
    def parser(cls, buf):
        if len(buf) < cls._HDR_LEN:
            raise stream_parser.StreamParser.TooSmallException(
                '%d < %d' % (len(buf), cls._HDR_LEN))
        (marker, len_, type_) = struct.unpack_from(cls._HDR_PACK_STR,
                                                   buffer(buf))
        msglen = len_
        if len(buf) < msglen:
            raise stream_parser.StreamParser.TooSmallException(
                '%d < %d' % (len(buf), msglen))
        binmsg = buf[cls._HDR_LEN:msglen]
        rest = buf[msglen:]
        subcls = cls._lookup_type(type_)
        kwargs = subcls.parser(binmsg)
        return subcls(marker=marker, len_=len_, type_=type_, **kwargs), rest

    def serialize(self):
        # fixup
        self.marker = _MARKER
        tail = self.serialize_tail()
        self.len = self._HDR_LEN + len(tail)

        hdr = bytearray(struct.pack(self._HDR_PACK_STR, self.marker,
                                    self.len, self.type))
        return hdr + tail

    def __len__(self):
        # XXX destructive
        buf = self.serialize()
        return len(buf)


@BGPMessage.register_type(BGP_MSG_OPEN)
class BGPOpen(BGPMessage):
    """BGP-4 OPEN Message encoder/decoder class.

    An instance has the following attributes at least.
    Most of them are same to the on-wire counterparts but in host byte
    order.
    __init__ takes the corresponding args in this order.

    ========================== ===============================================
    Attribute                  Description
    ========================== ===============================================
    marker                     Marker field.  Ignored when encoding.
    len                        Length field.  Ignored when encoding.
    type                       Type field.  The default is BGP_MSG_OPEN.
    version                    Version field.  The default is 4.
    my_as                      My Autonomous System field.  2 octet unsigned
                               integer.
    hold_time                  Hold Time field.  2 octet unsigned integer.
                               The default is 0.
    bgp_identifier             BGP Identifier field.  An IPv4 address.
                               For example, '192.0.2.1'
    opt_param_len              Optional Parameters Length field.
                               Ignored when encoding.
    opt_param                  Optional Parameters field.  A list of
                               BGPOptParam instances.  The default is [].
    ========================== ===============================================
    """

    _PACK_STR = '!BHH4sB'
    _MIN_LEN = BGPMessage._HDR_LEN + struct.calcsize(_PACK_STR)

    def __init__(self, my_as, bgp_identifier, type_=BGP_MSG_OPEN,
                 opt_param_len=0, opt_param=[],
                 version=_VERSION, hold_time=0, len_=None, marker=None):
        super(BGPOpen, self).__init__(marker=marker, len_=len_, type_=type_)
        self.version = version
        self.my_as = my_as
        self.bgp_identifier = bgp_identifier
        self.hold_time = hold_time
        self.opt_param_len = opt_param_len
        self.opt_param = opt_param

    @classmethod
    def parser(cls, buf):
        (version, my_as, hold_time,
         bgp_identifier, opt_param_len) = struct.unpack_from(cls._PACK_STR,
                                                             buffer(buf))
        rest = buf[struct.calcsize(cls._PACK_STR):]
        binopts = rest[:opt_param_len]
        opt_param = []
        while binopts:
            opt, binopts = _OptParam.parser(binopts)
            opt_param.append(opt)
        return {
            "version": version,
            "my_as": my_as,
            "hold_time": hold_time,
            "bgp_identifier": addrconv.ipv4.bin_to_text(bgp_identifier),
            "opt_param_len": opt_param_len,
            "opt_param": opt_param,
        }

    def serialize_tail(self):
        # fixup
        self.version = _VERSION
        binopts = bytearray()
        for opt in self.opt_param:
            binopts += opt.serialize()
        self.opt_param_len = len(binopts)

        msg = bytearray(struct.pack(self._PACK_STR,
                                    self.version,
                                    self.my_as,
                                    self.hold_time,
                                    addrconv.ipv4.text_to_bin(
                                        self.bgp_identifier),
                                    self.opt_param_len))
        msg += binopts
        return msg


@BGPMessage.register_type(BGP_MSG_UPDATE)
class BGPUpdate(BGPMessage):
    """BGP-4 UPDATE Message encoder/decoder class.

    An instance has the following attributes at least.
    Most of them are same to the on-wire counterparts but in host byte
    order.
    __init__ takes the corresponding args in this order.

    ========================== ===============================================
    Attribute                  Description
    ========================== ===============================================
    marker                     Marker field.  Ignored when encoding.
    len                        Length field.  Ignored when encoding.
    type                       Type field.  The default is BGP_MSG_UPDATE.
    withdrawn_routes_len       Withdrawn Routes Length field.
                               Ignored when encoding.
    withdrawn_routes           Withdrawn Routes field.  A list of
                               BGPWithdrawnRoute instances.
                               The default is [].
    total_path_attribute_len   Total Path Attribute Length field.
                               Ignored when encoding.
    path_attributes            Path Attributes field.  A list of
                               BGPPathAttribute instances.
                               The default is [].
    nlri                       Network Layer Reachability Information field.
                               A list of BGPNLRI instances.
                               The default is [].
    ========================== ===============================================
    """

    def __init__(self, type_=BGP_MSG_UPDATE,
                 withdrawn_routes_len=None,
                 withdrawn_routes=[],
                 total_path_attribute_len=None,
                 path_attributes=[],
                 nlri=[],
                 len_=None, marker=None):
        super(BGPUpdate, self).__init__(marker=marker, len_=len_, type_=type_)
        self.withdrawn_routes_len = withdrawn_routes_len
        self.withdrawn_routes = withdrawn_routes
        self.total_path_attribute_len = total_path_attribute_len
        self.path_attributes = path_attributes
        self.nlri = nlri

    @classmethod
    def parser(cls, buf):
        offset = 0
        (withdrawn_routes_len,) = struct.unpack_from('!H', buffer(buf), offset)
        binroutes = buffer(buf[offset + 2:
                               offset + 2 + withdrawn_routes_len])
        offset += 2 + withdrawn_routes_len
        (total_path_attribute_len,) = struct.unpack_from('!H', buffer(buf),
                                                         offset)
        binpathattrs = buffer(buf[offset + 2:
                                  offset + 2 + total_path_attribute_len])
        binnlri = buffer(buf[offset + 2 + total_path_attribute_len:])
        withdrawn_routes = []
        while binroutes:
            r, binroutes = BGPWithdrawnRoute.parser(binroutes)
            withdrawn_routes.append(r)
        path_attributes = []
        while binpathattrs:
            pa, binpathattrs = _PathAttribute.parser(binpathattrs)
            path_attributes.append(pa)
        offset += 2 + total_path_attribute_len
        nlri = []
        while binnlri:
            n, binnlri = BGPNLRI.parser(binnlri)
            nlri.append(n)
        return {
            "withdrawn_routes_len": withdrawn_routes_len,
            "withdrawn_routes": withdrawn_routes,
            "total_path_attribute_len": total_path_attribute_len,
            "path_attributes": path_attributes,
            "nlri": nlri,
        }

    def serialize_tail(self):
        # fixup
        binroutes = bytearray()
        for r in self.withdrawn_routes:
            binroutes += r.serialize()
        self.withdrawn_routes_len = len(binroutes)
        binpathattrs = bytearray()
        for pa in self.path_attributes:
            binpathattrs += pa.serialize()
        self.total_path_attribute_len = len(binpathattrs)
        binnlri = bytearray()
        for n in self.nlri:
            binnlri += n.serialize()

        msg = bytearray()
        offset = 0
        msg_pack_into('!H', msg, offset, self.withdrawn_routes_len)
        msg += binroutes
        offset += 2 + self.withdrawn_routes_len
        msg_pack_into('!H', msg, offset, self.total_path_attribute_len)
        msg += binpathattrs
        offset += 2 + self.total_path_attribute_len
        msg += binnlri
        return msg


@BGPMessage.register_type(BGP_MSG_KEEPALIVE)
class BGPKeepAlive(BGPMessage):
    """BGP-4 KEEPALIVE Message encoder/decoder class.

    An instance has the following attributes at least.
    Most of them are same to the on-wire counterparts but in host byte
    order.
    __init__ takes the corresponding args in this order.

    ========================== ===============================================
    Attribute                  Description
    ========================== ===============================================
    marker                     Marker field.  Ignored when encoding.
    len                        Length field.  Ignored when encoding.
    type                       Type field.  The default is BGP_MSG_KEEPALIVE.
    ========================== ===============================================
    """

    _MIN_LEN = BGPMessage._HDR_LEN

    def __init__(self, type_=BGP_MSG_KEEPALIVE, len_=None, marker=None):
        super(BGPKeepAlive, self).__init__(marker=marker, len_=len_,
                                           type_=type_)

    @classmethod
    def parser(cls, buf):
        return {}

    def serialize_tail(self):
        return bytearray()


@BGPMessage.register_type(BGP_MSG_NOTIFICATION)
class BGPNotification(BGPMessage):
    """BGP-4 NOTIFICATION Message encoder/decoder class.

    An instance has the following attributes at least.
    Most of them are same to the on-wire counterparts but in host byte
    order.
    __init__ takes the corresponding args in this order.

    ========================== ===============================================
    Attribute                  Description
    ========================== ===============================================
    marker                     Marker field.  Ignored when encoding.
    len                        Length field.  Ignored when encoding.
    type                       Type field.  The default is
                               BGP_MSG_NOTIFICATION.
    error_code                 Error code field.
    error_subcode              Error subcode field.
    data                       Data field.  The default is ''.
    ========================== ===============================================
    """

    _PACK_STR = '!BB'
    _MIN_LEN = BGPMessage._HDR_LEN + struct.calcsize(_PACK_STR)

    def __init__(self,
                 error_code,
                 error_subcode,
                 data='',
                 type_=BGP_MSG_NOTIFICATION, len_=None, marker=None):
        super(BGPNotification, self).__init__(marker=marker, len_=len_,
                                              type_=type_)
        self.error_code = error_code
        self.error_subcode = error_subcode
        self.data = data

    @classmethod
    def parser(cls, buf):
        (error_code, error_subcode,) = struct.unpack_from(cls._PACK_STR,
                                                          buffer(buf))
        data = bytes(buf[2:])
        return {
            "error_code": error_code,
            "error_subcode": error_subcode,
            "data": data,
        }

    def serialize_tail(self):
        msg = bytearray(struct.pack(self._PACK_STR, self.error_code,
                                    self.error_subcode))
        msg += self.data
        return msg


@BGPMessage.register_type(BGP_MSG_ROUTE_REFRESH)
class BGPRouteRefresh(BGPMessage):
    """BGP-4 ROUTE REFRESH Message (RFC 2918) encoder/decoder class.

    An instance has the following attributes at least.
    Most of them are same to the on-wire counterparts but in host byte
    order.
    __init__ takes the corresponding args in this order.

    ========================== ===============================================
    Attribute                  Description
    ========================== ===============================================
    marker                     Marker field.  Ignored when encoding.
    len                        Length field.  Ignored when encoding.
    type                       Type field.  The default is
                               BGP_MSG_ROUTE_REFRESH.
    afi                        Address Family Identifier
    safi                       Subsequent Address Family Identifier
    ========================== ===============================================
    """

    _PACK_STR = '!HBB'
    _MIN_LEN = BGPMessage._HDR_LEN + struct.calcsize(_PACK_STR)

    def __init__(self,
                 afi, safi, reserved=0,
                 type_=BGP_MSG_ROUTE_REFRESH, len_=None, marker=None):
        super(BGPRouteRefresh, self).__init__(marker=marker, len_=len_,
                                              type_=type_)
        self.afi = afi
        self.safi = safi
        self.reserved = reserved

    @classmethod
    def parser(cls, buf):
        (afi, reserved, safi,) = struct.unpack_from(cls._PACK_STR,
                                                    buffer(buf))
        return {
            "afi": afi,
            "reserved": reserved,
            "safi": safi,
        }

    def serialize_tail(self):
        # fixup
        self.reserved = 0

        return bytearray(struct.pack(self._PACK_STR, self.afi,
                                     self.reserved, self.safi))


class StreamParser(stream_parser.StreamParser):
    """Streaming parser for BGP-4 messages.

    This is a subclass of ryu.lib.packet.stream_parser.StreamParser.
    Its parse method returns a list of BGPMessage subclass instances.
    """

    def try_parse(self, data):
        return BGPMessage.parser(data)

########NEW FILE########
__FILENAME__ = bpdu
# Copyright (C) 2013 Nippon Telegraph and Telephone Corporation.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.


"""
Bridge Protocol Data Unit(BPDU, IEEE 802.1D) parser/serializer
http://standards.ieee.org/getieee802/download/802.1D-2004.pdf


Configuration BPDUs format

    +----------------------------------------------+---------+
    |                  Structure                   |  Octet  |
    +==============================================+=========+
    | Protocol Identifier = 0000 0000 0000 0000    |  1 - 2  |
    |                                              |         |
    +----------------------------------------------+---------+
    | Protocol Version Identifier = 0000 0000      |  3      |
    +----------------------------------------------+---------+
    | BPDU Type = 0000 0000                        |  4      |
    +----------------------------------------------+---------+
    | Flags                                        |  5      |
    +----------------------------------------------+---------+
    | Root Identifier                              |  6 - 13 |
    |  include - priority                          |         |
    |            system ID extension               |         |
    |            MAC address                       |         |
    +----------------------------------------------+---------+
    | Root Path Cost                               | 14 - 17 |
    |                                              |         |
    +----------------------------------------------+---------+
    | Bridge Identifier                            | 18 - 25 |
    |  include - priority                          |         |
    |            system ID extension               |         |
    |            MAC address                       |         |
    +----------------------------------------------+---------+
    | Port Identifier                              | 26 - 27 |
    |  include - priority                          |         |
    |            port number                       |         |
    +----------------------------------------------+---------+
    | Message Age                                  | 28 - 29 |
    |                                              |         |
    +----------------------------------------------+---------+
    | Max Age                                      | 30 - 31 |
    |                                              |         |
    +----------------------------------------------+---------+
    | Hello Time                                   | 32 - 33 |
    |                                              |         |
    +----------------------------------------------+---------+
    | Forward Delay                                | 34 - 35 |
    |                                              |         |
    +----------------------------------------------+---------+


Topology Change NotificationBPDUs format

    +----------------------------------------------+---------+
    |                  Structure                   |  Octet  |
    +==============================================+=========+
    | Protocol Identifier = 0000 0000 0000 0000    |  1 - 2  |
    |                                              |         |
    +----------------------------------------------+---------+
    | Protocol Version Identifier = 0000 0000      |  3      |
    +----------------------------------------------+---------+
    | BPDU Type = 1000 0000                        |  4      |
    +----------------------------------------------+---------+


Rapid Spanning Tree BPDUs(RST BPDUs) format

    +----------------------------------------------+---------+
    |                  Structure                   |  Octet  |
    +==============================================+=========+
    | Protocol Identifier = 0000 0000 0000 0000    |  1 - 2  |
    |                                              |         |
    +----------------------------------------------+---------+
    | Protocol Version Identifier = 0000 0010      |  3      |
    +----------------------------------------------+---------+
    | BPDU Type = 0000 0010                        |  4      |
    +----------------------------------------------+---------+
    | Flags                                        |  5      |
    +----------------------------------------------+---------+
    | Root Identifier                              |  6 - 13 |
    |  include - priority                          |         |
    |            system ID extension               |         |
    |            MAC address                       |         |
    +----------------------------------------------+---------+
    | Root Path Cost                               | 14 - 17 |
    |                                              |         |
    +----------------------------------------------+---------+
    | Bridge Identifier                            | 18 - 25 |
    |  include - priority                          |         |
    |            system ID extension               |         |
    |            MAC address                       |         |
    +----------------------------------------------+---------+
    | Port Identifier                              | 26 - 27 |
    |  include - priority                          |         |
    |            port number                       |         |
    +----------------------------------------------+---------+
    | Message Age                                  | 28 - 29 |
    |                                              |         |
    +----------------------------------------------+---------+
    | Max Age                                      | 30 - 31 |
    |                                              |         |
    +----------------------------------------------+---------+
    | Hello Time                                   | 32 - 33 |
    |                                              |         |
    +----------------------------------------------+---------+
    | Forward Delay                                | 34 - 35 |
    |                                              |         |
    +----------------------------------------------+---------+
    | Version 1 Length = 0000 0000                 | 36      |
    +----------------------------------------------+---------+

"""


import binascii
import struct
from . import packet_base
from ryu.lib import addrconv


# BPDU destination
BRIDGE_GROUP_ADDRESS = '01:80:c2:00:00:00'


PROTOCOL_IDENTIFIER = 0
PROTOCOLVERSION_ID_BPDU = 0
PROTOCOLVERSION_ID_RSTBPDU = 2
TYPE_CONFIG_BPDU = 0
TYPE_TOPOLOGY_CHANGE_BPDU = 128
TYPE_RSTBPDU = 2
DEFAULT_BRIDGE_PRIORITY = 32768
DEFAULT_PORT_PRIORITY = 128
PORT_PATH_COST_100KB = 200000000
PORT_PATH_COST_1MB = 20000000
PORT_PATH_COST_10MB = 2000000
PORT_PATH_COST_100MB = 200000
PORT_PATH_COST_1GB = 20000
PORT_PATH_COST_10GB = 2000
PORT_PATH_COST_100GB = 200
PORT_PATH_COST_1TB = 20
PORT_PATH_COST_10TB = 2
DEFAULT_MAX_AGE = 20
DEFAULT_HELLO_TIME = 2
DEFAULT_FORWARD_DELAY = 15
VERSION_1_LENGTH = 0


class bpdu(packet_base.PacketBase):
    """Bridge Protocol Data Unit(BPDU) header encoder/decoder base class.
    """
    _PACK_STR = '!HBB'
    _PACK_LEN = struct.calcsize(_PACK_STR)
    _BPDU_TYPES = {}

    _MIN_LEN = _PACK_LEN

    @staticmethod
    def register_bpdu_type(sub_cls):
        bpdu._BPDU_TYPES[sub_cls.BPDU_TYPE] = sub_cls
        return sub_cls

    def __init__(self):
        super(bpdu, self).__init__()

        assert hasattr(self, 'VERSION_ID')
        assert hasattr(self, 'BPDU_TYPE')

        self.protocol_id = PROTOCOL_IDENTIFIER
        self.version_id = self.VERSION_ID
        self.bpdu_type = self.BPDU_TYPE

        if hasattr(self, 'check_parameters'):
            self.check_parameters()

    @classmethod
    def parser(cls, buf):
        assert len(buf) >= cls._PACK_LEN
        (protocol_id, version_id,
         bpdu_type) = struct.unpack_from(cls._PACK_STR, buf)
        assert protocol_id == PROTOCOL_IDENTIFIER

        bpdu_cls = cls._BPDU_TYPES.get(bpdu_type, None)

        if bpdu_cls:
            assert version_id == bpdu_cls.VERSION_ID
            assert len(buf[cls._PACK_LEN:]) >= bpdu_cls.PACK_LEN
            return bpdu_cls.parser(buf[cls._PACK_LEN:])
        else:
            # Unknown bdpu type.
            return buf, None, None

    def serialize(self, payload, prev):
        return struct.pack(bpdu._PACK_STR, self.protocol_id,
                           self.version_id, self.bpdu_type)


@bpdu.register_bpdu_type
class ConfigurationBPDUs(bpdu):
    """Configuration BPDUs(IEEE 802.1D) header encoder/decoder class.

    An instance has the following attributes at least.
    Most of them are same to the on-wire counterparts but in host byte
    order.
    __init__ takes the corresponding args in this order.

    ========================== ===============================================
    Attribute                  Description
    ========================== ===============================================
    flags                      | Bit 1: Topology Change flag
                               | Bits 2 through 7: unused and take the value 0
                               | Bit 8: Topology Change Acknowledgment flag
    root_priority              Root Identifier priority \
                               set 0-61440 in steps of 4096
    root_system_id_extension   Root Identifier system ID extension
    root_mac_address           Root Identifier MAC address
    root_path_cost             Root Path Cost
    bridge_priority            Bridge Identifier priority \
                               set 0-61440 in steps of 4096
    bridge_system_id_extension Bridge Identifier system ID extension
    bridge_mac_address         Bridge Identifier MAC address
    port_priority              Port Identifier priority \
                               set 0-240 in steps of 16
    port_number                Port Identifier number
    message_age                Message Age timer value
    max_age                    Max Age timer value
    hello_time                 Hello Time timer value
    forward_delay              Forward Delay timer value
    ========================== ===============================================
    """

    VERSION_ID = PROTOCOLVERSION_ID_BPDU
    BPDU_TYPE = TYPE_CONFIG_BPDU
    _PACK_STR = '!BQIQHHHHH'
    PACK_LEN = struct.calcsize(_PACK_STR)

    _BRIDGE_PRIORITY_STEP = 4096
    _PORT_PRIORITY_STEP = 16
    _TIMER_STEP = float(1)/256

    def __init__(self, flags=0, root_priority=DEFAULT_BRIDGE_PRIORITY,
                 root_system_id_extension=0,
                 root_mac_address='00:00:00:00:00:00',
                 root_path_cost=0, bridge_priority=DEFAULT_BRIDGE_PRIORITY,
                 bridge_system_id_extension=0,
                 bridge_mac_address='00:00:00:00:00:00',
                 port_priority=DEFAULT_PORT_PRIORITY, port_number=0,
                 message_age=0, max_age=DEFAULT_MAX_AGE,
                 hello_time=DEFAULT_HELLO_TIME,
                 forward_delay=DEFAULT_FORWARD_DELAY):
        self.flags = flags
        self.root_priority = root_priority
        self.root_system_id_extension = root_system_id_extension
        self.root_mac_address = root_mac_address
        self.root_path_cost = root_path_cost
        self.bridge_priority = bridge_priority
        self.bridge_system_id_extension = bridge_system_id_extension
        self.bridge_mac_address = bridge_mac_address
        self.port_priority = port_priority
        self.port_number = port_number
        self.message_age = message_age
        self.max_age = max_age
        self.hello_time = hello_time
        self.forward_delay = forward_delay

        super(ConfigurationBPDUs, self).__init__()

    def check_parameters(self):
        assert (self.flags >> 1 & 0b111111) == 0
        assert self.root_priority % self._BRIDGE_PRIORITY_STEP == 0
        assert self.bridge_priority % self._BRIDGE_PRIORITY_STEP == 0
        assert self.port_priority % self._PORT_PRIORITY_STEP == 0
        assert self.message_age % self._TIMER_STEP == 0
        assert self.max_age % self._TIMER_STEP == 0
        assert self.hello_time % self._TIMER_STEP == 0
        assert self.forward_delay % self._TIMER_STEP == 0

    @classmethod
    def parser(cls, buf):
        (flags, root_id, root_path_cost, bridge_id,
         port_id, message_age, max_age, hello_time,
         forward_delay) = struct.unpack_from(ConfigurationBPDUs._PACK_STR, buf)

        (root_priority,
         root_system_id_extension,
         root_mac_address) = cls._decode_bridge_id(root_id)
        (bridge_priority,
         bridge_system_id_extension,
         bridge_mac_address) = cls._decode_bridge_id(bridge_id)
        (port_priority,
         port_number) = cls._decode_port_id(port_id)

        return (cls(flags, root_priority, root_system_id_extension,
                    root_mac_address, root_path_cost,
                    bridge_priority, bridge_system_id_extension,
                    bridge_mac_address, port_priority, port_number,
                    cls._decode_timer(message_age),
                    cls._decode_timer(max_age),
                    cls._decode_timer(hello_time),
                    cls._decode_timer(forward_delay)),
                None, buf[ConfigurationBPDUs.PACK_LEN:])

    def serialize(self, payload, prev):
        base = super(ConfigurationBPDUs, self).serialize(payload, prev)

        root_id = self.encode_bridge_id(self.root_priority,
                                        self.root_system_id_extension,
                                        self.root_mac_address)
        bridge_id = self.encode_bridge_id(self.bridge_priority,
                                          self.bridge_system_id_extension,
                                          self.bridge_mac_address)
        port_id = self.encode_port_id(self.port_priority,
                                      self.port_number)
        sub = struct.pack(ConfigurationBPDUs._PACK_STR,
                          self.flags,
                          root_id,
                          self.root_path_cost,
                          bridge_id,
                          port_id,
                          self._encode_timer(self.message_age),
                          self._encode_timer(self.max_age),
                          self._encode_timer(self.hello_time),
                          self._encode_timer(self.forward_delay))

        return base + sub

    @staticmethod
    def _decode_bridge_id(bridge_id):
        priority = (bridge_id >> 48) & 0xf000
        system_id_extension = (bridge_id >> 48) & 0xfff
        mac_addr = bridge_id & 0xffffffffffff

        mac_addr_list = [format((mac_addr >> (8 * i)) & 0xff, '02x')
                         for i in range(0, 6)]
        mac_addr_list.reverse()
        mac_address_bin = binascii.a2b_hex(''.join(mac_addr_list))
        mac_address = addrconv.mac.bin_to_text(mac_address_bin)

        return priority, system_id_extension, mac_address

    @staticmethod
    def encode_bridge_id(priority, system_id_extension, mac_address):
        mac_addr = int(binascii.hexlify(addrconv.mac.text_to_bin(mac_address)),
                       16)
        return ((priority + system_id_extension) << 48) + mac_addr

    @staticmethod
    def _decode_port_id(port_id):
        priority = port_id >> 8 & 0xf0
        port_number = port_id & 0xfff
        return priority, port_number

    @staticmethod
    def encode_port_id(priority, port_number):
        return (priority << 8) + port_number

    @staticmethod
    def _decode_timer(timer):
        return timer / float(0x100)

    @staticmethod
    def _encode_timer(timer):
        return timer * 0x100


@bpdu.register_bpdu_type
class TopologyChangeNotificationBPDUs(bpdu):
    """Topology Change Notification BPDUs(IEEE 802.1D)
    header encoder/decoder class.
    """

    VERSION_ID = PROTOCOLVERSION_ID_BPDU
    BPDU_TYPE = TYPE_TOPOLOGY_CHANGE_BPDU
    _PACK_STR = ''
    PACK_LEN = struct.calcsize(_PACK_STR)

    def __init__(self):
        super(TopologyChangeNotificationBPDUs, self).__init__()

    @classmethod
    def parser(cls, buf):
        return cls(), None, buf[bpdu._PACK_LEN:]


@bpdu.register_bpdu_type
class RstBPDUs(ConfigurationBPDUs):
    """Rapid Spanning Tree BPDUs(RST BPDUs, IEEE 802.1D)
    header encoder/decoder class.

    An instance has the following attributes at least.
    Most of them are same to the on-wire counterparts but in host byte
    order.
    __init__ takes the corresponding args in this order.

    ========================== ===========================================
    Attribute                  Description
    ========================== ===========================================
    flags                      | Bit 1: Topology Change flag
                               | Bit 2: Proposal flag
                               | Bits 3 and 4: Port Role
                               | Bit 5: Learning flag
                               | Bit 6: Forwarding flag
                               | Bit 7: Agreement flag
                               | Bit 8: Topology Change Acknowledgment flag
    root_priority              Root Identifier priority \
                               set 0-61440 in steps of 4096
    root_system_id_extension   Root Identifier system ID extension
    root_mac_address           Root Identifier MAC address
    root_path_cost             Root Path Cost
    bridge_priority            Bridge Identifier priority \
                               set 0-61440 in steps of 4096
    bridge_system_id_extension Bridge Identifier system ID extension
    bridge_mac_address         Bridge Identifier MAC address
    port_priority              Port Identifier priority \
                               set 0-240 in steps of 16
    port_number                Port Identifier number
    message_age                Message Age timer value
    max_age                    Max Age timer value
    hello_time                 Hello Time timer value
    forward_delay              Forward Delay timer value
    ========================== ===========================================
    """

    VERSION_ID = PROTOCOLVERSION_ID_RSTBPDU
    BPDU_TYPE = TYPE_RSTBPDU
    _PACK_STR = '!B'
    PACK_LEN = struct.calcsize(_PACK_STR)

    def __init__(self, flags=0, root_priority=DEFAULT_BRIDGE_PRIORITY,
                 root_system_id_extension=0,
                 root_mac_address='00:00:00:00:00:00',
                 root_path_cost=0, bridge_priority=DEFAULT_BRIDGE_PRIORITY,
                 bridge_system_id_extension=0,
                 bridge_mac_address='00:00:00:00:00:00',
                 port_priority=DEFAULT_PORT_PRIORITY, port_number=0,
                 message_age=0, max_age=DEFAULT_MAX_AGE,
                 hello_time=DEFAULT_HELLO_TIME,
                 forward_delay=DEFAULT_FORWARD_DELAY):
        self.version_1_length = VERSION_1_LENGTH

        super(RstBPDUs, self).__init__(flags, root_priority,
                                       root_system_id_extension,
                                       root_mac_address, root_path_cost,
                                       bridge_priority,
                                       bridge_system_id_extension,
                                       bridge_mac_address,
                                       port_priority, port_number,
                                       message_age, max_age,
                                       hello_time, forward_delay)

    def check_parameters(self):
        assert self.root_priority % self._BRIDGE_PRIORITY_STEP == 0
        assert self.bridge_priority % self._BRIDGE_PRIORITY_STEP == 0
        assert self.port_priority % self._PORT_PRIORITY_STEP == 0
        assert self.message_age % self._TIMER_STEP == 0
        assert self.max_age % self._TIMER_STEP == 0
        assert self.hello_time % self._TIMER_STEP == 0
        assert self.forward_delay % self._TIMER_STEP == 0

    @classmethod
    def parser(cls, buf):
        get_cls, next_type, buf = super(RstBPDUs, cls).parser(buf)

        (version_1_length,) = struct.unpack_from(RstBPDUs._PACK_STR, buf)
        assert version_1_length == VERSION_1_LENGTH

        return get_cls, next_type, buf[RstBPDUs.PACK_LEN:]

    def serialize(self, payload, prev):
        base = super(RstBPDUs, self).serialize(payload, prev)
        sub = struct.pack(RstBPDUs._PACK_STR, self.version_1_length)
        return base + sub

########NEW FILE########
__FILENAME__ = dhcp
# Copyright (C) 2013 Nippon Telegraph and Telephone Corporation.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""
DHCP packet parser/serializer

RFC 2131
DHCP packet format

    0                   1                   2                   3
    0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1
    +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
    |     op (1)    |   htype (1)   |   hlen (1)    |   hops (1)    |
    +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
    |                            xid (4)                            |
    +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
    |           secs (2)            |           flags (2)           |
    +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
    |                          ciaddr  (4)                          |
    +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
    |                          yiaddr  (4)                          |
    +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
    |                          siaddr  (4)                          |
    +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
    |                          giaddr  (4)                          |
    +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
    |                                                               |
    |                          chaddr  (16)                         |
    |                                                               |
    |                                                               |
    +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
    |                                                               |
    |                          sname   (64)                         |
    +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
    |                                                               |
    |                          file    (128)                        |
    +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
    |                                                               |
    |                          options (variable)                   |
    +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+

"""
import binascii
import random
import struct

from . import packet_base
from ryu.lib import addrconv
from ryu.lib import stringify


DHCP_BOOT_REQUEST = 1
DHCP_BOOT_REPLY = 2

# DHCP message type code
DHCP_DISCOVER = 1
DHCP_OFFER = 2
DHCP_REQUEST = 3
DHCP_ACK = 5

# DHCP options tag code
DHCP_PAD_OPT = 0
DHCP_SUBNET_MASK_OPT = 1
DHCP_GATEWAY_ADDR_OPT = 3
DHCP_DNS_SERVER_ADDR_OPT = 6
DHCP_HOST_NAME_OPT = 12
DHCP_REQUESTED_IP_ADDR_OPT = 50
DHCP_IP_ADDR_LEASE_TIME_OPT = 51
DHCP_MESSAGE_TYPE_OPT = 53
DHCP_SERVER_IDENTIFIER_OPT = 54
DHCP_PARAMETER_REQUEST_LIST_OPT = 55
DHCP_RENEWAL_TIME_OPT = 58
DHCP_REBINDING_TIME_OPT = 59
DHCP_END_OPT = 255


class dhcp(packet_base.PacketBase):
    """DHCP (RFC 2131) header encoder/decoder class.

    The serialized packet would looks like the ones described
    in the following sections.

    * RFC 2131 DHCP packet format

    An instance has the following attributes at least.
    Most of them are same to the on-wire counterparts but in host byte order.
    __init__ takes the corresponding args in this order.

    .. tabularcolumns:: |l|L|

    ============== ====================
    Attribute      Description
    ============== ====================
    op             Message op code / message type.\
                   1 = BOOTREQUEST, 2 = BOOTREPLY
    htype          Hardware address type (e.g.  '1' = 10mb ethernet).
    hlen           Hardware address length (e.g.  '6' = 10mb ethernet).
    hops           Client sets to zero, optionally used by relay agent\
                   when booting via a relay agent.
    xid            Transaction ID, a random number chosen by the client,\
                   used by the client and serverto associate messages\
                   and responses between a client and a server.
    secs           Filled in by client, seconds elapsed since client\
                   began address acquisition or renewal process.
    flags          Flags.
    ciaddr         Client IP address; only filled in if client is in\
                   BOUND, RENEW or REBINDING state and can respond\
                   to ARP requests.
    yiaddr         'your' (client) IP address.
    siaddr         IP address of next server to use in bootstrap;\
                   returned in DHCPOFFER, DHCPACK by server.
    giaddr         Relay agent IP address, used in booting via a\
                   relay agent.
    chaddr         Client hardware address.
    sname          Optional server host name, null terminated string.
    boot_file      Boot file name, null terminated string; "generic"\
                   name or null in DHCPDISCOVER, fully qualified\
                   directory-path name in DHCPOFFER.
    options        Optional parameters field\
                   ('DHCP message type' option must be included in\
                    every DHCP message).
    ============== ====================
    """
    _HLEN_UNPACK_STR = '!BBB'
    _HLEN_UNPACK_LEN = struct.calcsize(_HLEN_UNPACK_STR)
    _DHCP_UNPACK_STR = '!BIHH4s4s4s4s%ds%ds64s128s'
    _DHCP_PACK_STR = '!BBBBIHH4s4s4s4s16s64s128s'
    _DHCP_CHADDR_LEN = 16
    _HARDWARE_TYPE_ETHERNET = 1

    def __init__(self, op, chaddr, options, htype=_HARDWARE_TYPE_ETHERNET,
                 hlen=0, hops=0, xid=None, secs=0, flags=0,
                 ciaddr='0.0.0.0', yiaddr='0.0.0.0', siaddr='0.0.0.0',
                 giaddr='0.0.0.0', sname='', boot_file=''):
        super(dhcp, self).__init__()
        self.op = op
        self.htype = htype
        if hlen == 0:
            self.hlen = len(chaddr)
        else:
            self.hlen = hlen
        self.hops = hops
        if xid is None:
            self.xid = random.randint(0, 0xffffffff)
        else:
            self.xid = xid
        self.secs = secs
        self.flags = flags
        self.ciaddr = ciaddr
        self.yiaddr = yiaddr
        self.siaddr = siaddr
        self.giaddr = giaddr
        self.chaddr = chaddr
        self.sname = sname
        self.boot_file = boot_file
        self.options = options

    @classmethod
    def parser(cls, buf):
        (op, htype, hlen) = struct.unpack_from(cls._HLEN_UNPACK_STR, buf)
        buf = buf[cls._HLEN_UNPACK_LEN:]
        unpack_str = cls._DHCP_UNPACK_STR % (hlen,
                                             (cls._DHCP_CHADDR_LEN - hlen))
        min_len = struct.calcsize(unpack_str)
        (hops, xid, secs, flags, ciaddr, yiaddr, siaddr, giaddr, chaddr,
         dummy, sname, boot_file
         ) = struct.unpack_from(unpack_str, buf)
        length = min_len
        if len(buf) > min_len:
            parse_opt = options.parser(buf[min_len:])
            length += parse_opt.options_len
        return (cls(op, addrconv.mac.bin_to_text(chaddr), parse_opt,
                    htype, hlen, hops, xid, secs, flags,
                    addrconv.ipv4.bin_to_text(ciaddr),
                    addrconv.ipv4.bin_to_text(yiaddr),
                    addrconv.ipv4.bin_to_text(siaddr),
                    addrconv.ipv4.bin_to_text(giaddr), sname, boot_file),
                None, buf[length:])

    def serialize(self, payload, prev):
        seri_opt = self.options.serialize()
        pack_str = '%s%ds' % (self._DHCP_PACK_STR,
                              self.options.options_len)
        return struct.pack(pack_str, self.op, self.htype, self.hlen,
                           self.hops, self.xid, self.secs, self.flags,
                           addrconv.ipv4.text_to_bin(self.ciaddr),
                           addrconv.ipv4.text_to_bin(self.yiaddr),
                           addrconv.ipv4.text_to_bin(self.siaddr),
                           addrconv.ipv4.text_to_bin(self.giaddr),
                           addrconv.mac.text_to_bin(self.chaddr),
                           self.sname, self.boot_file, seri_opt)


class options(stringify.StringifyMixin):
    """DHCP (RFC 2132) options encoder/decoder class.

    This is used with ryu.lib.packet.dhcp.dhcp.

    An instance has the following attributes at least.
    Most of them are same to the on-wire counterparts but in host byte order.
    __init__ takes the corresponding args in this order.

    .. tabularcolumns:: |l|L|

    ============== ====================
    Attribute      Description
    ============== ====================
    option_list    'end option' and 'pad option' are added automatically\
                   after the option class is stored in array.
    options_len    Option's byte length.\
                   ('magic cookie', 'end option' and 'pad option'\
                    length including.)
    magic_cookie   The first four octets contain the decimal values\
                   99, 130, 83 and 99.
    ============== ====================
    """
    _MAGIC_COOKIE_UNPACK_STR = '!4s'
    # same magic cookie as is defined in RFC 1497
    _MAGIC_COOKIE = '99.130.83.99'
    _OPT_TAG_LEN_BYTE = 2

    def __init__(self, option_list=None, options_len=0,
                 magic_cookie=_MAGIC_COOKIE):
        super(options, self).__init__()
        if option_list is None:
            self.option_list = []
        else:
            self.option_list = option_list
        self.options_len = options_len
        self.magic_cookie = magic_cookie

    @classmethod
    def parser(cls, buf):
        opt_parse_list = []
        offset = struct.calcsize(cls._MAGIC_COOKIE_UNPACK_STR)
        magic_cookie = struct.unpack_from(cls._MAGIC_COOKIE_UNPACK_STR, buf)[0]
        while len(buf) > offset:
            opt_buf = buf[offset:]
            opt = option.parser(opt_buf)
            if opt is None:
                break
            opt_parse_list.append(opt)
            offset += opt.length + cls._OPT_TAG_LEN_BYTE
        return cls(opt_parse_list, len(buf),
                   addrconv.ipv4.bin_to_text(magic_cookie))

    def serialize(self):
        seri_opt = addrconv.ipv4.text_to_bin(self.magic_cookie)
        for opt in self.option_list:
            seri_opt += opt.serialize()
        seri_opt += binascii.a2b_hex('%x' % DHCP_END_OPT)
        if self.options_len == 0:
            self.options_len = len(seri_opt)
        return seri_opt


class option(stringify.StringifyMixin):
    """DHCP (RFC 2132) options encoder/decoder class.

    This is used with ryu.lib.packet.dhcp.dhcp.options.

    An instance has the following attributes at least.
    Most of them are same to the on-wire counterparts but in host byte order.
    __init__ takes the corresponding args in this order.

    ============== ====================
    Attribute      Description
    ============== ====================
    tag            Option type.\
                   (except for the 'magic cookie', 'pad option'\
                    and 'end option'.)
    value          Option's value.\
                   (set the value that has been converted to hexadecimal.)
    length         Option's value length.\
                   (calculated automatically from the length of value.)
    ============== ====================
    """
    _UNPACK_STR = '!B'
    _MIN_LEN = struct.calcsize(_UNPACK_STR)

    def __init__(self, tag, value, length=0):
        super(option, self).__init__()
        self.tag = tag
        self.value = value
        self.length = length

    @classmethod
    def parser(cls, buf):
        tag = struct.unpack_from(cls._UNPACK_STR, buf)[0]
        if tag == DHCP_END_OPT or tag == DHCP_PAD_OPT:
            return None
        buf = buf[cls._MIN_LEN:]
        length = struct.unpack_from(cls._UNPACK_STR, buf)[0]
        buf = buf[cls._MIN_LEN:]
        value_unpack_str = '%ds' % length
        value = struct.unpack_from(value_unpack_str, buf)[0]
        return cls(tag, value, length)

    def serialize(self):
        if self.length == 0:
            self.length = len(self.value)
        options_pack_str = '!BB%ds' % self.length
        return struct.pack(options_pack_str, self.tag, self.length, self.value)

########NEW FILE########
__FILENAME__ = ethernet
# Copyright (C) 2012 Nippon Telegraph and Telephone Corporation.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import struct
from . import packet_base
from . import vlan
from . import mpls
from ryu.ofproto import ether
from ryu.lib import addrconv


class ethernet(packet_base.PacketBase):
    """Ethernet header encoder/decoder class.

    An instance has the following attributes at least.
    MAC addresses are represented as a string like '08:60:6e:7f:74:e7'.
    __init__ takes the corresponding args in this order.

    ============== ==================== =====================
    Attribute      Description          Example
    ============== ==================== =====================
    dst            destination address  'ff:ff:ff:ff:ff:ff'
    src            source address       '08:60:6e:7f:74:e7'
    ethertype      ether type           0x0800
    ============== ==================== =====================
    """

    _PACK_STR = '!6s6sH'
    _MIN_LEN = struct.calcsize(_PACK_STR)

    def __init__(self, dst='ff:ff:ff:ff:ff:ff', src='00:00:00:00:00:00',
                 ethertype=ether.ETH_TYPE_IP):
        super(ethernet, self).__init__()
        self.dst = dst
        self.src = src
        self.ethertype = ethertype

    @classmethod
    def parser(cls, buf):
        dst, src, ethertype = struct.unpack_from(cls._PACK_STR, buf)
        return (cls(addrconv.mac.bin_to_text(dst),
                    addrconv.mac.bin_to_text(src), ethertype),
                ethernet.get_packet_type(ethertype),
                buf[ethernet._MIN_LEN:])

    def serialize(self, payload, prev):
        return struct.pack(ethernet._PACK_STR,
                           addrconv.mac.text_to_bin(self.dst),
                           addrconv.mac.text_to_bin(self.src),
                           self.ethertype)

    @classmethod
    def get_packet_type(cls, type_):
        """Override method for the ethernet IEEE802.3 Length/Type
        field (self.ethertype).

        If the value of Length/Type field is less than or equal to
        1500 decimal(05DC hexadecimal), it means Length interpretation
        and be passed to the LLC sublayer."""
        if type_ <= ether.ETH_TYPE_IEEE802_3:
            type_ = ether.ETH_TYPE_IEEE802_3
        return cls._TYPES.get(type_)


# copy vlan _TYPES
ethernet._TYPES = vlan.vlan._TYPES
ethernet.register_packet_type(vlan.vlan, ether.ETH_TYPE_8021Q)
ethernet.register_packet_type(vlan.svlan, ether.ETH_TYPE_8021AD)
ethernet.register_packet_type(mpls.mpls, ether.ETH_TYPE_MPLS)

########NEW FILE########
__FILENAME__ = icmp
# Copyright (C) 2012 Nippon Telegraph and Telephone Corporation.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import struct

from . import packet_base
from . import packet_utils
from ryu.lib import stringify


ICMP_ECHO_REPLY = 0
ICMP_DEST_UNREACH = 3
ICMP_SRC_QUENCH = 4
ICMP_REDIRECT = 5
ICMP_ECHO_REQUEST = 8
ICMP_TIME_EXCEEDED = 11

ICMP_ECHO_REPLY_CODE = 0
ICMP_HOST_UNREACH_CODE = 1
ICMP_PORT_UNREACH_CODE = 3
ICMP_TTL_EXPIRED_CODE = 0


class icmp(packet_base.PacketBase):
    """ICMP (RFC 792) header encoder/decoder class.

    An instance has the following attributes at least.
    Most of them are same to the on-wire counterparts but in host byte order.
    __init__ takes the corresponding args in this order.

    .. tabularcolumns:: |l|L|

    ============== ====================
    Attribute      Description
    ============== ====================
    type           Type
    code           Code
    csum           CheckSum \
                   (0 means automatically-calculate when encoding)
    data           Payload. \
                   Either a bytearray, or \
                   ryu.lib.packet.icmp.echo or \
                   ryu.lib.packet.icmp.dest_unreach or \
                   ryu.lib.packet.icmp.TimeExceeded object \
                   NOTE for icmp.echo: \
                   This includes "unused" 16 bits and the following \
                   "Internet Header + 64 bits of Original Data Datagram" of \
                   the ICMP header. \
                   NOTE for icmp.dest_unreach and icmp.TimeExceeded: \
                   This includes "unused" 8 or 24 bits and the following \
                   "Internet Header + leading octets of original datagram" \
                   of the original packet.
    ============== ====================
    """

    _PACK_STR = '!BBH'
    _MIN_LEN = struct.calcsize(_PACK_STR)
    _ICMP_TYPES = {}

    @staticmethod
    def register_icmp_type(*args):
        def _register_icmp_type(cls):
            for type_ in args:
                icmp._ICMP_TYPES[type_] = cls
            return cls
        return _register_icmp_type

    def __init__(self, type_=ICMP_ECHO_REQUEST, code=0, csum=0, data=None):
        super(icmp, self).__init__()
        self.type = type_
        self.code = code
        self.csum = csum
        self.data = data

    @classmethod
    def parser(cls, buf):
        (type_, code, csum) = struct.unpack_from(cls._PACK_STR, buf)
        msg = cls(type_, code, csum)
        offset = cls._MIN_LEN

        if len(buf) > offset:
            cls_ = cls._ICMP_TYPES.get(type_, None)
            if cls_:
                msg.data = cls_.parser(buf, offset)
            else:
                msg.data = buf[offset:]

        return msg, None, None

    def serialize(self, payload, prev):
        hdr = bytearray(struct.pack(icmp._PACK_STR, self.type,
                                    self.code, self.csum))

        if self.data is not None:
            if self.type in icmp._ICMP_TYPES:
                hdr += self.data.serialize()
            else:
                hdr += self.data
        else:
            self.data = echo()
            hdr += self.data.serialize()

        if self.csum == 0:
            self.csum = packet_utils.checksum(hdr)
            struct.pack_into('!H', hdr, 2, self.csum)

        return hdr

    def __len__(self):
        return self._MIN_LEN + len(self.data)


@icmp.register_icmp_type(ICMP_ECHO_REPLY, ICMP_ECHO_REQUEST)
class echo(stringify.StringifyMixin):
    """ICMP sub encoder/decoder class for Echo and Echo Reply messages.

    This is used with ryu.lib.packet.icmp.icmp for
    ICMP Echo and Echo Reply messages.

    An instance has the following attributes at least.
    Most of them are same to the on-wire counterparts but in host byte order.
    __init__ takes the corresponding args in this order.

    .. tabularcolumns:: |l|L|

    ============== ====================
    Attribute      Description
    ============== ====================
    id             Identifier
    seq            Sequence Number
    data           Internet Header + 64 bits of Original Data Datagram
    ============== ====================
    """

    _PACK_STR = '!HH'
    _MIN_LEN = struct.calcsize(_PACK_STR)

    def __init__(self, id_=0, seq=0, data=None):
        super(echo, self).__init__()
        self.id = id_
        self.seq = seq
        self.data = data

    @classmethod
    def parser(cls, buf, offset):
        (id_, seq) = struct.unpack_from(cls._PACK_STR, buf, offset)
        msg = cls(id_, seq)
        offset += cls._MIN_LEN

        if len(buf) > offset:
            msg.data = buf[offset:]

        return msg

    def serialize(self):
        hdr = bytearray(struct.pack(echo._PACK_STR, self.id,
                                    self.seq))

        if self.data is not None:
            hdr += self.data

        return hdr

    def __len__(self):
        length = self._MIN_LEN
        if self.data is not None:
            length += len(self.data)
        return length


@icmp.register_icmp_type(ICMP_DEST_UNREACH)
class dest_unreach(stringify.StringifyMixin):
    """ICMP sub encoder/decoder class for Destination Unreachable Message.

    This is used with ryu.lib.packet.icmp.icmp for
    ICMP Destination Unreachable Message.

    An instance has the following attributes at least.
    Most of them are same to the on-wire counterparts but in host byte order.
    __init__ takes the corresponding args in this order.

    [RFC1191] reserves bits for the "Next-Hop MTU" field.
    [RFC4884] introduced 8-bit data length attribute.

    .. tabularcolumns:: |l|p{35em}|

    ============== =====================================================
    Attribute      Description
    ============== =====================================================
    data_len       data length
    mtu            Next-Hop MTU

                   NOTE: This field is required when icmp code is 4

                   code 4 = fragmentation needed and DF set
    data           Internet Header + leading octets of original datagram
    ============== =====================================================
    """

    _PACK_STR = '!xBH'
    _MIN_LEN = struct.calcsize(_PACK_STR)

    def __init__(self, data_len=0, mtu=0, data=None):
        super(dest_unreach, self).__init__()
        self.data_len = data_len
        self.mtu = mtu
        self.data = data

    @classmethod
    def parser(cls, buf, offset):
        (data_len, mtu) = struct.unpack_from(cls._PACK_STR,
                                             buf, offset)
        msg = cls(data_len, mtu)
        offset += cls._MIN_LEN

        if len(buf) > offset:
            msg.data = buf[offset:]

        return msg

    def serialize(self):
        hdr = bytearray(struct.pack(dest_unreach._PACK_STR,
                        self.data_len, self.mtu))

        if self.data is not None:
            hdr += self.data

        return hdr

    def __len__(self):
        length = self._MIN_LEN
        if self.data is not None:
            length += len(self.data)
        return length


@icmp.register_icmp_type(ICMP_TIME_EXCEEDED)
class TimeExceeded(stringify.StringifyMixin):
    """ICMP sub encoder/decoder class for Time Exceeded Message.

    This is used with ryu.lib.packet.icmp.icmp for
    ICMP Time Exceeded Message.

    An instance has the following attributes at least.
    Most of them are same to the on-wire counterparts but in host byte order.
    __init__ takes the corresponding args in this order.

    [RFC4884] introduced 8-bit data length attribute.

    .. tabularcolumns:: |l|L|

    ============== ====================
    Attribute      Description
    ============== ====================
    data_len       data length
    data           Internet Header + leading octets of original datagram
    ============== ====================
    """

    _PACK_STR = '!xBxx'
    _MIN_LEN = struct.calcsize(_PACK_STR)

    def __init__(self, data_len=0, data=None):
        self.data_len = data_len
        self.data = data

    @classmethod
    def parser(cls, buf, offset):
        (data_len, ) = struct.unpack_from(cls._PACK_STR, buf, offset)
        msg = cls(data_len)
        offset += cls._MIN_LEN

        if len(buf) > offset:
            msg.data = buf[offset:]

        return msg

    def serialize(self):
        hdr = bytearray(struct.pack(TimeExceeded._PACK_STR, self.data_len))

        if self.data is not None:
            hdr += self.data

        return hdr

    def __len__(self):
        length = self._MIN_LEN
        if self.data is not None:
            length += len(self.data)
        return length

########NEW FILE########
__FILENAME__ = icmpv6
# Copyright (C) 2012 Nippon Telegraph and Telephone Corporation.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import abc
import struct
import sys
import array
import binascii

from . import packet_base
from . import packet_utils
from ryu.lib import addrconv
from ryu.lib import stringify

ICMPV6_DST_UNREACH = 1       # dest unreachable, codes:
ICMPV6_PACKET_TOO_BIG = 2       # packet too big
ICMPV6_TIME_EXCEEDED = 3       # time exceeded, code:
ICMPV6_PARAM_PROB = 4       # ip6 header bad

ICMPV6_ECHO_REQUEST = 128     # echo service
ICMPV6_ECHO_REPLY = 129     # echo reply
MLD_LISTENER_QUERY = 130     # multicast listener query
MLD_LISTENER_REPOR = 131     # multicast listener report
MLD_LISTENER_DONE = 132     # multicast listener done

# RFC2292 decls
ICMPV6_MEMBERSHIP_QUERY = 130     # group membership query
ICMPV6_MEMBERSHIP_REPORT = 131     # group membership report
ICMPV6_MEMBERSHIP_REDUCTION = 132     # group membership termination

ND_ROUTER_SOLICIT = 133     # router solicitation
ND_ROUTER_ADVERT = 134     # router advertisment
ND_NEIGHBOR_SOLICIT = 135     # neighbor solicitation
ND_NEIGHBOR_ADVERT = 136     # neighbor advertisment
ND_REDIREC = 137     # redirect

ICMPV6_ROUTER_RENUMBERING = 138     # router renumbering

ICMPV6_WRUREQUEST = 139     # who are you request
ICMPV6_WRUREPLY = 140     # who are you reply
ICMPV6_FQDN_QUERY = 139     # FQDN query
ICMPV6_FQDN_REPLY = 140     # FQDN reply
ICMPV6_NI_QUERY = 139     # node information request
ICMPV6_NI_REPLY = 140     # node information reply

ICMPV6_MAXTYPE = 201

# ND_OPTIONS from RFC 4861
ND_OPTION_SLA = 1  # Source Link-Layer Address
ND_OPTION_TLA = 2  # Target Link-Layer Address
ND_OPTION_PI = 3   # Prefix Information
ND_OPTION_RH = 4   # Redirected Header
ND_OPTION_MTU = 5  # MTU


class icmpv6(packet_base.PacketBase):
    """ICMPv6 (RFC 2463) header encoder/decoder class.

    An instance has the following attributes at least.
    Most of them are same to the on-wire counterparts but in host byte order.
    __init__ takes the corresponding args in this order.

    .. tabularcolumns:: |l|p{35em}|

    ============== ====================
    Attribute      Description
    ============== ====================
    type\_         Type
    code           Code
    csum           CheckSum
                   (0 means automatically-calculate when encoding)
    data           Payload.

                   ryu.lib.packet.icmpv6.echo object, \
                   ryu.lib.packet.icmpv6.nd_neighbor object, \
                   ryu.lib.packet.icmpv6.nd_router_solicit object, \
                   ryu.lib.packet.icmpv6.nd_router_advert object, \
                   or a bytearray.
    ============== ====================
    """
    _PACK_STR = '!BBH'
    _MIN_LEN = struct.calcsize(_PACK_STR)
    _ICMPV6_TYPES = {}

    @staticmethod
    def register_icmpv6_type(*args):
        def _register_icmpv6_type(cls):
            for type_ in args:
                icmpv6._ICMPV6_TYPES[type_] = cls
            return cls
        return _register_icmpv6_type

    def __init__(self, type_=0, code=0, csum=0, data=None):
        super(icmpv6, self).__init__()
        self.type_ = type_
        self.code = code
        self.csum = csum
        self.data = data

    @classmethod
    def parser(cls, buf):
        (type_, code, csum) = struct.unpack_from(cls._PACK_STR, buf)
        msg = cls(type_, code, csum)
        offset = cls._MIN_LEN
        if len(buf) > offset:
            cls_ = cls._ICMPV6_TYPES.get(type_, None)
            if cls_:
                msg.data = cls_.parser(buf, offset)
            else:
                msg.data = buf[offset:]

        return msg, None, None

    def serialize(self, payload, prev):
        hdr = bytearray(struct.pack(icmpv6._PACK_STR, self.type_,
                                    self.code, self.csum))

        if self.data is not None:
            if self.type_ in icmpv6._ICMPV6_TYPES:
                hdr += self.data.serialize()
            else:
                hdr += self.data
        if self.csum == 0:
            self.csum = packet_utils.checksum_ip(prev, len(hdr), hdr + payload)
            struct.pack_into('!H', hdr, 2, self.csum)

        return hdr

    def __len__(self):
        length = self._MIN_LEN
        if self.data is not None:
            length += len(self.data)
        return length


@icmpv6.register_icmpv6_type(ND_NEIGHBOR_SOLICIT, ND_NEIGHBOR_ADVERT)
class nd_neighbor(stringify.StringifyMixin):
    """ICMPv6 sub encoder/decoder class for Neighbor Solicitation and
    Neighbor Advertisement messages. (RFC 4861)

    This is used with ryu.lib.packet.icmpv6.icmpv6.

    An instance has the following attributes at least.
    Most of them are same to the on-wire counterparts but in host byte order.
    __init__ takes the corresponding args in this order.

    .. tabularcolumns:: |l|p{35em}|

    ============== ====================
    Attribute      Description
    ============== ====================
    res            R,S,O Flags for Neighbor Advertisement. \
                   The 3 MSBs of "Reserved" field for Neighbor Solicitation.
    dst            Target Address
    option         a derived object of ryu.lib.packet.icmpv6.nd_option \
                   or a bytearray. None if no options.
    ============== ====================
    """

    _PACK_STR = '!I16s'
    _MIN_LEN = struct.calcsize(_PACK_STR)
    _ND_OPTION_TYPES = {}

    @staticmethod
    def register_nd_option_type(*args):
        def _register_nd_option_type(cls):
            nd_neighbor._ND_OPTION_TYPES[cls.option_type()] = cls
            return cls
        return _register_nd_option_type(args[0])

    def __init__(self, res=0, dst='::', option=None):
        self.res = res
        self.dst = dst
        self.option = option

    @classmethod
    def parser(cls, buf, offset):
        (res, dst) = struct.unpack_from(cls._PACK_STR, buf, offset)
        offset += cls._MIN_LEN
        option = None
        if len(buf) > offset:
            (type_, ) = struct.unpack_from('!B', buf, offset)
            cls_ = cls._ND_OPTION_TYPES.get(type_)
            if cls_ is not None:
                option = cls_.parser(buf, offset)
            else:
                option = buf[offset:]
        msg = cls(res >> 29, addrconv.ipv6.bin_to_text(dst), option)
        return msg

    def serialize(self):
        res = self.res << 29
        hdr = bytearray(struct.pack(
            nd_neighbor._PACK_STR, res,
            addrconv.ipv6.text_to_bin(self.dst)))
        if self.option is not None:
            if isinstance(self.option, nd_option):
                hdr.extend(self.option.serialize())
            else:
                hdr.extend(self.option)
        return str(hdr)

    def __len__(self):
        length = self._MIN_LEN
        if self.option is not None:
            length += len(self.option)
        return length


@icmpv6.register_icmpv6_type(ND_ROUTER_SOLICIT)
class nd_router_solicit(stringify.StringifyMixin):
    """ICMPv6 sub encoder/decoder class for Router Solicitation messages.
    (RFC 4861)

    This is used with ryu.lib.packet.icmpv6.icmpv6.

    An instance has the following attributes at least.
    Most of them are same to the on-wire counterparts but in host byte order.
    __init__ takes the corresponding args in this order.

    .. tabularcolumns:: |l|p{35em}|

    ============== ====================
    Attribute      Description
    ============== ====================
    res            This field is unused.  It MUST be initialized to zero.
    option         a derived object of ryu.lib.packet.icmpv6.nd_option \
                   or a bytearray. None if no options.
    ============== ====================
    """

    _PACK_STR = '!I'
    _MIN_LEN = struct.calcsize(_PACK_STR)
    _ND_OPTION_TYPES = {}

    @staticmethod
    def register_nd_option_type(*args):
        def _register_nd_option_type(cls):
            nd_router_solicit._ND_OPTION_TYPES[cls.option_type()] = cls
            return cls
        return _register_nd_option_type(args[0])

    def __init__(self, res=0, option=None):
        self.res = res
        self.option = option

    @classmethod
    def parser(cls, buf, offset):
        (res, ) = struct.unpack_from(cls._PACK_STR, buf, offset)
        offset += cls._MIN_LEN
        option = None
        if len(buf) > offset:
            (type_, ) = struct.unpack_from('!B', buf, offset)
            cls_ = cls._ND_OPTION_TYPES.get(type_)
            if cls_ is not None:
                option = cls_.parser(buf, offset)
            else:
                option = buf[offset:]
        msg = cls(res, option)
        return msg

    def serialize(self):
        hdr = bytearray(struct.pack(
            nd_router_solicit._PACK_STR, self.res))
        if self.option is not None:
            if isinstance(self.option, nd_option):
                hdr.extend(self.option.serialize())
            else:
                hdr.extend(self.option)
        return str(hdr)

    def __len__(self):
        length = self._MIN_LEN
        if self.option is not None:
            length += len(self.option)
        return length


@icmpv6.register_icmpv6_type(ND_ROUTER_ADVERT)
class nd_router_advert(stringify.StringifyMixin):
    """ICMPv6 sub encoder/decoder class for Router Advertisement messages.
    (RFC 4861)

    This is used with ryu.lib.packet.icmpv6.icmpv6.

    An instance has the following attributes at least.
    Most of them are same to the on-wire counterparts but in host byte order.
    __init__ takes the corresponding args in this order.

    .. tabularcolumns:: |l|p{35em}|

    ============== ====================
    Attribute      Description
    ============== ====================
    ch_l           Cur Hop Limit.
    res            M,O Flags for Router Advertisement.
    rou_l          Router Lifetime.
    rea_t          Reachable Time.
    ret_t          Retrans Timer.
    options        List of a derived object of \
                   ryu.lib.packet.icmpv6.nd_option or a bytearray. \
                   None if no options.
    ============== ====================
    """

    _PACK_STR = '!BBHII'
    _MIN_LEN = struct.calcsize(_PACK_STR)
    _ND_OPTION_TYPES = {}

    @staticmethod
    def register_nd_option_type(*args):
        def _register_nd_option_type(cls):
            nd_router_advert._ND_OPTION_TYPES[cls.option_type()] = cls
            return cls
        return _register_nd_option_type(args[0])

    def __init__(self, ch_l=0, res=0, rou_l=0, rea_t=0, ret_t=0, options=None):
        self.ch_l = ch_l
        self.res = res
        self.rou_l = rou_l
        self.rea_t = rea_t
        self.ret_t = ret_t
        options = options or []
        assert isinstance(options, list)
        self.options = options

    @classmethod
    def parser(cls, buf, offset):
        (ch_l, res, rou_l, rea_t, ret_t
         ) = struct.unpack_from(cls._PACK_STR, buf, offset)
        offset += cls._MIN_LEN
        options = []
        while len(buf) > offset:
            (type_, length) = struct.unpack_from('!BB', buf, offset)
            cls_ = cls._ND_OPTION_TYPES.get(type_)
            if cls_ is not None:
                option = cls_.parser(buf, offset)
            else:
                option = buf[offset:offset + (length * 8 - 2)]
            options.append(option)
            offset += len(option)
        msg = cls(ch_l, res >> 6, rou_l, rea_t, ret_t, options)
        return msg

    def serialize(self):
        res = self.res << 6
        hdr = bytearray(struct.pack(
            nd_router_advert._PACK_STR, self.ch_l, res, self.rou_l,
            self.rea_t, self.ret_t))
        for option in self.options:
            if isinstance(option, nd_option):
                hdr.extend(option.serialize())
            else:
                hdr.extend(option)
        return str(hdr)

    def __len__(self):
        length = self._MIN_LEN
        for option in self.options:
            length += len(option)
        return length


class nd_option(stringify.StringifyMixin):

    __metaclass__ = abc.ABCMeta

    @classmethod
    @abc.abstractmethod
    def option_type(cls):
        pass

    @abc.abstractmethod
    def __init__(self, _type, length):
        self._type = _type
        self.length = length

    @classmethod
    @abc.abstractmethod
    def parser(cls, buf):
        pass

    @abc.abstractmethod
    def serialize(self):
        pass

    def __len__(self):
        return self._MIN_LEN


class nd_option_la(nd_option):

    _PACK_STR = '!BB6s'
    _MIN_LEN = struct.calcsize(_PACK_STR)

    @abc.abstractmethod
    def __init__(self, length, hw_src, data):
        super(nd_option_la, self).__init__(self.option_type(), length)
        self.hw_src = hw_src
        self.data = data

    @classmethod
    def parser(cls, buf, offset):
        (_, length, hw_src) = struct.unpack_from(cls._PACK_STR, buf, offset)
        msg = cls(length, addrconv.mac.bin_to_text(hw_src))
        offset += cls._MIN_LEN
        if len(buf) > offset:
            msg.data = buf[offset:]

        return msg

    def serialize(self):
        buf = bytearray(struct.pack(
            self._PACK_STR, self.option_type(), self.length,
            addrconv.mac.text_to_bin(self.hw_src)))
        if self.data is not None:
            buf.extend(self.data)
        mod = len(buf) % 8
        if mod:
            buf.extend(bytearray(8 - mod))
        if 0 == self.length:
            self.length = len(buf) / 8
            struct.pack_into('!B', buf, 1, self.length)
        return str(buf)

    def __len__(self):
        length = self._MIN_LEN
        if self.data is not None:
            length += len(self.data)
        return length


@nd_neighbor.register_nd_option_type
@nd_router_solicit.register_nd_option_type
@nd_router_advert.register_nd_option_type
class nd_option_sla(nd_option_la):
    """ICMPv6 sub encoder/decoder class for Neighbor discovery
    Source Link-Layer Address Option. (RFC 4861)

    This is used with ryu.lib.packet.icmpv6.nd_neighbor,
    ryu.lib.packet.icmpv6.nd_router_solicit or
    ryu.lib.packet.icmpv6.nd_router_advert.

    An instance has the following attributes at least.
    Most of them are same to the on-wire counterparts but in host byte order.
    __init__ takes the corresponding args in this order.

    .. tabularcolumns:: |l|p{35em}|

    ============== ====================
    Attribute      Description
    ============== ====================
    length         length of the option. \
                   (0 means automatically-calculate when encoding)
    hw_src         Link-Layer Address. \
                   NOTE: If the address is longer than 6 octets this contains \
                   the first 6 octets in the address. \
                   This implementation assumes the address has at least \
                   6 octets.
    data           A bytearray which contains the rest of Link-Layer Address \
                   and padding.  When encoding a packet, it's user's \
                   responsibility to provide necessary padding for 8-octets \
                   alignment required by the protocol.
    ============== ====================
    """

    @classmethod
    def option_type(cls):
        return ND_OPTION_SLA

    def __init__(self, length=0, hw_src='00:00:00:00:00:00', data=None):
        super(nd_option_sla, self).__init__(length, hw_src, data)


@nd_neighbor.register_nd_option_type
class nd_option_tla(nd_option_la):
    """ICMPv6 sub encoder/decoder class for Neighbor discovery
    Target Link-Layer Address Option. (RFC 4861)

    This is used with ryu.lib.packet.icmpv6.nd_neighbor.

    An instance has the following attributes at least.
    Most of them are same to the on-wire counterparts but in host byte order.
    __init__ takes the corresponding args in this order.

    .. tabularcolumns:: |l|p{35em}|

    ============== ====================
    Attribute      Description
    ============== ====================
    length         length of the option. \
                   (0 means automatically-calculate when encoding)
    hw_src         Link-Layer Address. \
                   NOTE: If the address is longer than 6 octets this contains \
                   the first 6 octets in the address. \
                   This implementation assumes the address has at least \
                   6 octets.
    data           A bytearray which contains the rest of Link-Layer Address \
                   and padding.  When encoding a packet, it's user's \
                   responsibility to provide necessary padding for 8-octets \
                   alignment required by the protocol.
    ============== ====================
    """

    @classmethod
    def option_type(cls):
        return ND_OPTION_TLA

    def __init__(self, length=0, hw_src='00:00:00:00:00:00', data=None):
        super(nd_option_tla, self).__init__(length, hw_src, data)


@nd_router_advert.register_nd_option_type
class nd_option_pi(nd_option):
    """ICMPv6 sub encoder/decoder class for Neighbor discovery
    Prefix Information Option. (RFC 4861)

    This is used with ryu.lib.packet.icmpv6.nd_router_advert.

    An instance has the following attributes at least.
    Most of them are same to the on-wire counterparts but in host byte order.
    __init__ takes the corresponding args in this order.

    .. tabularcolumns:: |l|p{35em}|

    ============== ====================
    Attribute      Description
    ============== ====================
    length         length of the option. \
                   (0 means automatically-calculate when encoding)
    pl             Prefix Length.
    res1           L,A,R\* Flags for Prefix Information.
    val_l          Valid Lifetime.
    pre_l          Preferred Lifetime.
    res2           This field is unused. It MUST be initialized to zero.
    prefix         An IP address or a prefix of an IP address.
    ============== ====================

    \*R flag is defined in (RFC 3775)
    """

    _PACK_STR = '!BBBBIII16s'
    _MIN_LEN = struct.calcsize(_PACK_STR)

    @classmethod
    def option_type(cls):
        return ND_OPTION_PI

    def __init__(self, length=0, pl=0, res1=0, val_l=0, pre_l=0, res2=0,
                 prefix='::'):
        super(nd_option_pi, self).__init__(self.option_type(), length)
        self.pl = pl
        self.res1 = res1
        self.val_l = val_l
        self.pre_l = pre_l
        self.res2 = res2
        self.prefix = prefix

    @classmethod
    def parser(cls, buf, offset):
        (_, length, pl, res1, val_l, pre_l, res2, prefix
         ) = struct.unpack_from(cls._PACK_STR, buf, offset)
        msg = cls(length, pl, res1 >> 5, val_l, pre_l, res2,
                  addrconv.ipv6.bin_to_text(prefix))

        return msg

    def serialize(self):
        res1 = self.res1 << 5
        hdr = bytearray(struct.pack(
            self._PACK_STR, self.option_type(), self.length, self.pl,
            res1, self.val_l, self.pre_l, self.res2,
            addrconv.ipv6.text_to_bin(self.prefix)))
        if 0 == self.length:
            self.length = len(hdr) / 8
            struct.pack_into('!B', hdr, 1, self.length)
        return str(hdr)


@icmpv6.register_icmpv6_type(ICMPV6_ECHO_REPLY, ICMPV6_ECHO_REQUEST)
class echo(stringify.StringifyMixin):
    """ICMPv6 sub encoder/decoder class for Echo Request and Echo Reply
    messages.

    This is used with ryu.lib.packet.icmpv6.icmpv6 for
    ICMPv6 Echo Request and Echo Reply messages.

    An instance has the following attributes at least.
    Most of them are same to the on-wire counterparts but in host byte order.
    __init__ takes the corresponding args in this order.

    ============== ====================
    Attribute      Description
    ============== ====================
    id             Identifier
    seq            Sequence Number
    data           Data
    ============== ====================
    """

    _PACK_STR = '!HH'
    _MIN_LEN = struct.calcsize(_PACK_STR)

    def __init__(self, id_=0, seq=0, data=None):
        self.id = id_
        self.seq = seq
        self.data = data

    @classmethod
    def parser(cls, buf, offset):
        (id_, seq) = struct.unpack_from(cls._PACK_STR, buf, offset)
        msg = cls(id_, seq)
        offset += cls._MIN_LEN

        if len(buf) > offset:
            msg.data = buf[offset:]

        return msg

    def serialize(self):
        hdr = bytearray(struct.pack(echo._PACK_STR, self.id,
                                    self.seq))
        if self.data is not None:
            hdr += bytearray(self.data)

        return hdr

    def __len__(self):
        length = self._MIN_LEN
        if self.data is not None:
            length += len(self.data)
        return length

########NEW FILE########
__FILENAME__ = igmp
# Copyright (C) 2013 Nippon Telegraph and Telephone Corporation.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""
Internet Group Management Protocol(IGMP) packet parser/serializer

RFC 1112
IGMP v1 format

    0                   1                   2                   3
    0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1
   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
   |Version| Type  |    Unused     |           Checksum            |
   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
   |                         Group Address                         |
   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+

RFC 2236
IGMP v2 format

    0                   1                   2                   3
    0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1
   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
   |      Type     | Max Resp Time |           Checksum            |
   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
   |                         Group Address                         |
   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
"""

import struct

from ryu.lib import addrconv
from ryu.lib.packet import packet_base
from ryu.lib.packet import packet_utils


IGMP_TYPE_QUERY = 0x11
IGMP_TYPE_REPORT_V1 = 0x12
IGMP_TYPE_REPORT_V2 = 0x16
IGMP_TYPE_LEAVE = 0x17
IGMP_TYPE_REPORT_V3 = 0x22

QUERY_RESPONSE_INTERVAL = 10.0
LAST_MEMBER_QUERY_INTERVAL = 1.0

MULTICAST_IP_ALL_HOST = '224.0.0.1'
MULTICAST_MAC_ALL_HOST = '01:00:5e:00:00:01'


class igmp(packet_base.PacketBase):
    """
    Internet Group Management Protocol(IGMP, RFC 1112, RFC 2236)
    header encoder/decoder class.

    http://www.ietf.org/rfc/rfc1112.txt

    http://www.ietf.org/rfc/rfc2236.txt

    An instance has the following attributes at least.
    Most of them are same to the on-wire counterparts but in host byte
    order.
    __init__ takes the corresponding args in this order.

    =============== ====================================================
    Attribute       Description
    =============== ====================================================
    msgtype         a message type for v2, or a combination of
                    version and a message type for v1.
    maxresp         max response time in unit of 1/10 second. it is
                    meaningful only in Query Message.
    csum            a check sum value. 0 means automatically-calculate
                    when encoding.
    address         a group address value.
    =============== ====================================================

    * NOTE: IGMP v3(RFC 3376) is not supported yet.
    """
    _PACK_STR = '!BBH4s'
    _MIN_LEN = struct.calcsize(_PACK_STR)

    def __init__(self, msgtype, maxresp, csum, address):
        super(igmp, self).__init__()
        self.msgtype = msgtype
        self.maxresp = maxresp
        self.csum = csum
        self.address = address

    @classmethod
    def parser(cls, buf):
        assert cls._MIN_LEN <= len(buf)
        (msgtype, maxresp, csum, address
         ) = struct.unpack_from(cls._PACK_STR, buf)
        return (cls(msgtype, maxresp, csum,
                    addrconv.ipv4.bin_to_text(address)),
                None,
                buf[cls._MIN_LEN:])

    def serialize(self, payload, prev):
        hdr = bytearray(struct.pack(self._PACK_STR, self.msgtype,
                        self.maxresp, self.csum,
                        addrconv.ipv4.text_to_bin(self.address)))

        if self.csum == 0:
            self.csum = packet_utils.checksum(hdr)
            struct.pack_into('!H', hdr, 2, self.csum)

        return hdr

########NEW FILE########
__FILENAME__ = ipv4
# Copyright (C) 2012 Nippon Telegraph and Telephone Corporation.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import struct

from . import packet_base
from . import packet_utils
from . import icmp
from . import igmp
from . import udp
from . import tcp
from . import sctp
from ryu.ofproto import inet
from ryu.lib import addrconv


IPV4_ADDRESS_PACK_STR = '!I'
IPV4_ADDRESS_LEN = struct.calcsize(IPV4_ADDRESS_PACK_STR)
IPV4_PSEUDO_HEADER_PACK_STR = '!4s4s2xHH'


class ipv4(packet_base.PacketBase):
    """IPv4 (RFC 791) header encoder/decoder class.

    NOTE: When decoding, this implementation tries to decode the upper
    layer protocol even for a fragmented datagram.  It isn't likely
    what a user would want.

    An instance has the following attributes at least.
    Most of them are same to the on-wire counterparts but in host byte order.
    IPv4 addresses are represented as a string like '192.0.2.1'.
    __init__ takes the corresponding args in this order.

    ============== ======================================== ==================
    Attribute      Description                              Example
    ============== ======================================== ==================
    version        Version
    header_length  IHL
    tos            Type of Service
    total_length   Total Length
                   (0 means automatically-calculate
                   when encoding)
    identification Identification
    flags          Flags
    offset         Fragment Offset
    ttl            Time to Live
    proto          Protocol
    csum           Header Checksum
                   (Ignored and automatically-calculated
                   when encoding)
    src            Source Address                           '192.0.2.1'
    dst            Destination Address                      '192.0.2.2'
    option         A bytearray which contains the entire
                   Options, or None for  no Options
    ============== ======================================== ==================
    """

    _PACK_STR = '!BBHHHBBH4s4s'
    _MIN_LEN = struct.calcsize(_PACK_STR)

    def __init__(self, version=4, header_length=5, tos=0,
                 total_length=0, identification=0, flags=0,
                 offset=0, ttl=255, proto=0, csum=0,
                 src='0.0.0.0',
                 dst='0.0.0.0',
                 option=None):
        super(ipv4, self).__init__()
        self.version = version
        self.header_length = header_length
        self.tos = tos
        self.total_length = total_length
        self.identification = identification
        self.flags = flags
        self.offset = offset
        self.ttl = ttl
        self.proto = proto
        self.csum = csum
        self.src = src
        self.dst = dst
        self.option = option

    def __len__(self):
        return self.header_length * 4

    @classmethod
    def parser(cls, buf):
        (version, tos, total_length, identification, flags, ttl, proto, csum,
         src, dst) = struct.unpack_from(cls._PACK_STR, buf)
        header_length = version & 0xf
        version = version >> 4
        offset = flags & ((1 << 13) - 1)
        flags = flags >> 13
        length = header_length * 4
        if length > ipv4._MIN_LEN:
            option = buf[ipv4._MIN_LEN:length]
        else:
            option = None
        msg = cls(version, header_length, tos, total_length, identification,
                  flags, offset, ttl, proto, csum,
                  addrconv.ipv4.bin_to_text(src),
                  addrconv.ipv4.bin_to_text(dst), option)

        return msg, ipv4.get_packet_type(proto), buf[length:total_length]

    def serialize(self, payload, prev):
        length = len(self)
        hdr = bytearray(length)
        version = self.version << 4 | self.header_length
        flags = self.flags << 13 | self.offset
        if self.total_length == 0:
            self.total_length = self.header_length * 4 + len(payload)
        struct.pack_into(ipv4._PACK_STR, hdr, 0, version, self.tos,
                         self.total_length, self.identification, flags,
                         self.ttl, self.proto, 0,
                         addrconv.ipv4.text_to_bin(self.src),
                         addrconv.ipv4.text_to_bin(self.dst))

        if self.option:
            assert (length - ipv4._MIN_LEN) >= len(self.option)
            hdr[ipv4._MIN_LEN:ipv4._MIN_LEN + len(self.option)] = self.option

        self.csum = packet_utils.checksum(hdr)
        struct.pack_into('!H', hdr, 10, self.csum)
        return hdr

ipv4.register_packet_type(icmp.icmp, inet.IPPROTO_ICMP)
ipv4.register_packet_type(igmp.igmp, inet.IPPROTO_IGMP)
ipv4.register_packet_type(tcp.tcp, inet.IPPROTO_TCP)
ipv4.register_packet_type(udp.udp, inet.IPPROTO_UDP)
ipv4.register_packet_type(sctp.sctp, inet.IPPROTO_SCTP)

########NEW FILE########
__FILENAME__ = ipv6
# Copyright (C) 2012 Nippon Telegraph and Telephone Corporation.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import abc
import struct
from . import packet_base
from . import icmpv6
from . import tcp
from . import udp
from . import sctp
from ryu.ofproto import inet
from ryu.lib import addrconv
from ryu.lib import stringify


IPV6_ADDRESS_PACK_STR = '!16s'
IPV6_ADDRESS_LEN = struct.calcsize(IPV6_ADDRESS_PACK_STR)
IPV6_PSEUDO_HEADER_PACK_STR = '!16s16s3xB'


class ipv6(packet_base.PacketBase):
    """IPv6 (RFC 2460) header encoder/decoder class.

    An instance has the following attributes at least.
    Most of them are same to the on-wire counterparts but in host byte order.
    IPv6 addresses are represented as a string like 'ff02::1'.
    __init__ takes the corresponding args in this order.

    .. tabularcolumns:: |l|p{30em}|l|

    ============== ======================================== ==================
    Attribute      Description                              Example
    ============== ======================================== ==================
    version        Version
    traffic_class  Traffic Class
    flow_label     When decoding, Flow Label.
                   When encoding, the most significant 8
                   bits of Flow Label.
    payload_length Payload Length
    nxt            Next Header
    hop_limit      Hop Limit
    src            Source Address                           'ff02::1'
    dst            Destination Address                      '::'
    ext_hdrs       Extension Headers
    ============== ======================================== ==================
    """

    _PACK_STR = '!IHBB16s16s'
    _MIN_LEN = struct.calcsize(_PACK_STR)
    _IPV6_EXT_HEADER_TYPE = {}

    @staticmethod
    def register_header_type(type_):
        def _register_header_type(cls):
            ipv6._IPV6_EXT_HEADER_TYPE[type_] = cls
            return cls
        return _register_header_type

    def __init__(self, version=6, traffic_class=0, flow_label=0,
                 payload_length=0, nxt=inet.IPPROTO_TCP, hop_limit=255,
                 src='::', dst='::', ext_hdrs=None):
        super(ipv6, self).__init__()
        self.version = version
        self.traffic_class = traffic_class
        self.flow_label = flow_label
        self.payload_length = payload_length
        self.nxt = nxt
        self.hop_limit = hop_limit
        self.src = src
        self.dst = dst
        ext_hdrs = ext_hdrs or []
        assert isinstance(ext_hdrs, list)
        for ext_hdr in ext_hdrs:
            assert isinstance(ext_hdr, header)
        self.ext_hdrs = ext_hdrs

    @classmethod
    def parser(cls, buf):
        (v_tc_flow, payload_length, nxt, hlim, src, dst) = struct.unpack_from(
            cls._PACK_STR, buf)
        version = v_tc_flow >> 28
        traffic_class = (v_tc_flow >> 20) & 0xff
        flow_label = v_tc_flow & 0xfffff
        hop_limit = hlim
        offset = cls._MIN_LEN
        last = nxt
        ext_hdrs = []
        while True:
            cls_ = cls._IPV6_EXT_HEADER_TYPE.get(last)
            if not cls_:
                break
            hdr = cls_.parser(buf[offset:])
            ext_hdrs.append(hdr)
            offset += len(hdr)
            last = hdr.nxt
        msg = cls(version, traffic_class, flow_label, payload_length,
                  nxt, hop_limit, addrconv.ipv6.bin_to_text(src),
                  addrconv.ipv6.bin_to_text(dst), ext_hdrs)
        return (msg, ipv6.get_packet_type(last),
                buf[offset:offset+payload_length])

    def serialize(self, payload, prev):
        hdr = bytearray(40)
        v_tc_flow = (self.version << 28 | self.traffic_class << 20 |
                     self.flow_label)
        struct.pack_into(ipv6._PACK_STR, hdr, 0, v_tc_flow,
                         self.payload_length, self.nxt, self.hop_limit,
                         addrconv.ipv6.text_to_bin(self.src),
                         addrconv.ipv6.text_to_bin(self.dst))
        if self.ext_hdrs:
            for ext_hdr in self.ext_hdrs:
                hdr.extend(ext_hdr.serialize())
        if 0 == self.payload_length:
            payload_length = len(payload)
            for ext_hdr in self.ext_hdrs:
                payload_length += len(ext_hdr)
            self.payload_length = payload_length
            struct.pack_into('!H', hdr, 4, self.payload_length)
        return hdr

    def __len__(self):
        ext_hdrs_len = 0
        for ext_hdr in self.ext_hdrs:
            ext_hdrs_len += len(ext_hdr)
        return self._MIN_LEN + ext_hdrs_len

ipv6.register_packet_type(icmpv6.icmpv6, inet.IPPROTO_ICMPV6)
ipv6.register_packet_type(tcp.tcp, inet.IPPROTO_TCP)
ipv6.register_packet_type(udp.udp, inet.IPPROTO_UDP)
ipv6.register_packet_type(sctp.sctp, inet.IPPROTO_SCTP)


class header(stringify.StringifyMixin):
    """extension header abstract class."""

    __metaclass__ = abc.ABCMeta

    def __init__(self, nxt):
        self.nxt = nxt

    @classmethod
    @abc.abstractmethod
    def parser(cls, buf):
        pass

    @abc.abstractmethod
    def serialize(self):
        pass

    @abc.abstractmethod
    def __len__(self):
        pass

# TODO: implement a class for routing header


class opt_header(header):
    """an abstract class for Hop-by-Hop Options header and destination
    header."""

    _PACK_STR = '!BB'
    _MIN_LEN = struct.calcsize(_PACK_STR)
    _FIX_SIZE = 8

    @abc.abstractmethod
    def __init__(self, nxt, size, data):
        super(opt_header, self).__init__(nxt)
        assert not (size % 8)
        self.size = size
        self.data = data

    @classmethod
    def parser(cls, buf):
        (nxt, len_) = struct.unpack_from(cls._PACK_STR, buf)
        data_len = cls._FIX_SIZE + int(len_)
        data = []
        size = cls._MIN_LEN
        while size < data_len:
            (type_, ) = struct.unpack_from('!B', buf[size:])
            if type_ == 0:
                opt = option(type_, -1, None)
                size += 1
            else:
                opt = option.parser(buf[size:])
                size += len(opt)
            data.append(opt)
        return cls(nxt, len_, data)

    def serialize(self):
        buf = struct.pack(self._PACK_STR, self.nxt, self.size)
        buf = bytearray(buf)
        if self.data is None:
            self.data = [option(type_=1, len_=6,
                                data='\x00\x00\x00\x00\x00\x00')]
        for opt in self.data:
            buf.extend(opt.serialize())
        return buf

    def __len__(self):
        return self._FIX_SIZE + self.size


@ipv6.register_header_type(inet.IPPROTO_HOPOPTS)
class hop_opts(opt_header):
    """IPv6 (RFC 2460) Hop-by-Hop Options header encoder/decoder class.

    This is used with ryu.lib.packet.ipv6.ipv6.

    An instance has the following attributes at least.
    Most of them are same to the on-wire counterparts but in host byte order.
    __init__ takes the corresponding args in this order.

    .. tabularcolumns:: |l|L|

    ============== =======================================
    Attribute      Description
    ============== =======================================
    nxt            Next Header
    size           the length of the Hop-by-Hop Options header,
                   not include the first 8 octet.
    data           IPv6 options.
    ============== =======================================
    """
    TYPE = inet.IPPROTO_HOPOPTS

    def __init__(self, nxt=inet.IPPROTO_TCP, size=0, data=None):
        super(hop_opts, self).__init__(nxt, size, data)


@ipv6.register_header_type(inet.IPPROTO_DSTOPTS)
class dst_opts(opt_header):
    """IPv6 (RFC 2460) destination header encoder/decoder class.

    This is used with ryu.lib.packet.ipv6.ipv6.

    An instance has the following attributes at least.
    Most of them are same to the on-wire counterparts but in host byte order.
    __init__ takes the corresponding args in this order.

    .. tabularcolumns:: |l|L|

    ============== =======================================
    Attribute      Description
    ============== =======================================
    nxt            Next Header
    size           the length of the destination header,
                   not include the first 8 octet.
    data           IPv6 options.
    ============== =======================================
    """
    TYPE = inet.IPPROTO_DSTOPTS

    def __init__(self, nxt=inet.IPPROTO_TCP, size=0, data=None):
        super(dst_opts, self).__init__(nxt, size, data)


class option(stringify.StringifyMixin):
    """IPv6 (RFC 2460) Options header encoder/decoder class.

    This is used with ryu.lib.packet.ipv6.hop_opts or
                      ryu.lib.packet.ipv6.dst_opts.

    An instance has the following attributes at least.
    Most of them are same to the on-wire counterparts but in host byte order.
    __init__ takes the corresponding args in this order.

    .. tabularcolumns:: |l|L|

    ============== =======================================
    Attribute      Description
    ============== =======================================
    type\_         option type.
    len\_          the length of data. -1 if type\_ is 0.
    data           an option value. None if len\_ is 0 or -1.
    ============== =======================================
    """

    _PACK_STR = '!BB'
    _MIN_LEN = struct.calcsize(_PACK_STR)

    def __init__(self, type_=0, len_=-1, data=None):
        self.type_ = type_
        self.len_ = len_
        self.data = data

    @classmethod
    def parser(cls, buf):
        (type_, ) = struct.unpack_from('!B', buf)
        if not type_:
            cls_ = cls(type_, -1, None)
        else:
            data = None
            (type_, len_) = struct.unpack_from(cls._PACK_STR, buf)
            if len_:
                form = "%ds" % len_
                (data, ) = struct.unpack_from(form, buf, cls._MIN_LEN)
            cls_ = cls(type_, len_, data)
        return cls_

    def serialize(self):
        data = None
        if not self.type_:
            data = struct.pack('!B', self.type_)
        elif not self.len_:
            data = struct.pack(self._PACK_STR, self.type_, self.len_)
        else:
            form = "%ds" % self.len_
            data = struct.pack(self._PACK_STR + form, self.type_,
                               self.len_, self.data)
        return data

    def __len__(self):
        return self._MIN_LEN + self.len_


@ipv6.register_header_type(inet.IPPROTO_FRAGMENT)
class fragment(header):
    """IPv6 (RFC 2460) fragment header encoder/decoder class.

    This is used with ryu.lib.packet.ipv6.ipv6.

    An instance has the following attributes at least.
    Most of them are same to the on-wire counterparts but in host byte order.
    __init__ takes the corresponding args in this order.

    .. tabularcolumns:: |l|L|

    ============== =======================================
    Attribute      Description
    ============== =======================================
    nxt            Next Header
    offset         offset, in 8-octet units, relative to
                   the start of the fragmentable part of
                   the original packet.
    more           1 means more fragments follow;
                   0 means last fragment.
    id\_           packet identification value.
    ============== =======================================
    """
    TYPE = inet.IPPROTO_FRAGMENT

    _PACK_STR = '!BxHI'
    _MIN_LEN = struct.calcsize(_PACK_STR)

    def __init__(self, nxt=inet.IPPROTO_TCP, offset=0, more=0, id_=0):
        super(fragment, self).__init__(nxt)
        self.offset = offset
        self.more = more
        self.id_ = id_

    @classmethod
    def parser(cls, buf):
        (nxt, off_m, id_) = struct.unpack_from(cls._PACK_STR, buf)
        offset = off_m >> 3
        more = off_m & 0x1
        return cls(nxt, offset, more, id_)

    def serialize(self):
        off_m = (self.offset << 3 | self.more)
        buf = struct.pack(self._PACK_STR, self.nxt, off_m, self.id_)
        return buf

    def __len__(self):
        return self._MIN_LEN


@ipv6.register_header_type(inet.IPPROTO_AH)
class auth(header):
    """IP Authentication header (RFC 2402) encoder/decoder class.

    This is used with ryu.lib.packet.ipv6.ipv6.

    An instance has the following attributes at least.
    Most of them are same to the on-wire counterparts but in host byte order.
    __init__ takes the corresponding args in this order.

    .. tabularcolumns:: |l|L|

    ============== =======================================
    Attribute      Description
    ============== =======================================
    nxt            Next Header
    size           the length of the Authentication Header
                   in 64-bit words, subtracting 1.
    spi            security parameters index.
    seq            sequence number.
    data           authentication data.
    ============== =======================================
    """
    TYPE = inet.IPPROTO_AH

    _PACK_STR = '!BB2xII'
    _MIN_LEN = struct.calcsize(_PACK_STR)

    def __init__(self, nxt=inet.IPPROTO_TCP, size=3, spi=0, seq=0,
                 data='\x00\x00\x00\x00'):
        super(auth, self).__init__(nxt)
        assert data is not None
        self.size = size
        self.spi = spi
        self.seq = seq
        self.data = data

    @classmethod
    def _get_size(cls, size):
        return (int(size) - 1) * 8

    @classmethod
    def parser(cls, buf):
        (nxt, size, spi, seq) = struct.unpack_from(cls._PACK_STR, buf)
        form = "%ds" % (cls._get_size(size) - cls._MIN_LEN)
        (data, ) = struct.unpack_from(form, buf, cls._MIN_LEN)
        return cls(nxt, size, spi, seq, data)

    def serialize(self):
        buf = struct.pack(self._PACK_STR, self.nxt, self.size, self.spi,
                          self.seq)
        buf = bytearray(buf)
        form = "%ds" % (auth._get_size(self.size) - self._MIN_LEN)
        buf.extend(struct.pack(form, self.data))
        return buf

    def __len__(self):
        return auth._get_size(self.size)

########NEW FILE########
__FILENAME__ = llc
# Copyright (C) 2013 Nippon Telegraph and Telephone Corporation.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.


"""
Logical Link Control(LLC, IEEE 802.2) parser/serializer
http://standards.ieee.org/getieee802/download/802.2-1998.pdf


LLC format

    +-----------------+--------------+
    | DSAP address    | 8 bits       |
    +-----------------+--------------+
    | SSAP address    | 8 bits       |
    +-----------------+--------------+
    | Control         | 8 or 16 bits |
    +-----------------+--------------+


DSAP address field

      LSB
    +-----+---+---+---+---+---+---+---+
    | I/G | D | D | D | D | D | D | D |
    +-----+---+---+---+---+---+---+---+
     I/G bit = 0 : Individual DSAP
     I/G bit = 1 : Group DSA
     D : DSAP address

SSAP address field

      LSB
    +-----+---+---+---+---+---+---+---+
    | C/R | S | S | S | S | S | S | S |
    +-----+---+---+---+---+---+---+---+
     C/R bit = 0 : Command
     C/R bit = 1 : Response
     S : SSAP address


Control field

 Information transfer
 command/response
 (I-format PDU)
      1   2   3   4   5   6   7   8    9   10-16
    +---+---+---+---+---+---+---+---+-----+------+
    | 0 |           N(S)            | P/F | N(R) |
    +---+---+---+---+---+---+---+---+-----+------+

 Supervisory
 commands/responses
 (S-format PDUs)
      1   2   3   4   5   6   7   8    9   10-16
    +---+---+---+---+---+---+---+---+-----+------+
    | 1   0 | S   S | 0   0   0   0 | P/F | N(R) |
    +---+---+---+---+---+---+---+---+-----+------+

 Unnumbered
 commands/responses
 (U-format PDUs)
      1   2   3    4    5    6   7    8
    +---+---+----+---+-----+---+----+---+
    | 1   1 | M1  M1 | P/F | M2  M2  M2 |
    +---+---+----+---+-----+---+----+---+

    N(S) : sender send sequence number (Bit 2=lower-order-bit)
    N(R) : sender receive sequence number (Bit 10=lower-order-bit)
    S    : supervisory function bit
    M1/M2: modifier function bit
    P/F  : poll bit - command LLC PDUs
           final bit - response LLC PDUs

"""


import struct
from . import bpdu
from . import packet_base
from ryu.lib import stringify


SAP_BPDU = 0x42


class llc(packet_base.PacketBase):
    """LLC(IEEE 802.2) header encoder/decoder class.

    An instance has the following attributes at least.
    Most of them are same to the on-wire counterparts but in host byte
    order.
    __init__ takes the corresponding args in this order.

    .. tabularcolumns:: |l|L|

    =============== ===============================================
    Attribute       Description
    =============== ===============================================
    dsap_addr       Destination service access point address field \
                    includes I/G bit at least significant bit.
    ssap_addr       Source service access point address field \
                    includes C/R bit at least significant bit.
    control         Control field \
                    [16 bits for formats that include sequence \
                    numbering, and 8 bits for formats that do not]. \
                    Either ryu.lib.packet.llc.ControlFormatI or \
                    ryu.lib.packet.llc.ControlFormatS or \
                    ryu.lib.packet.llc.ControlFormatU object.
    =============== ===============================================
    """

    _PACK_STR = '!BB'
    _PACK_LEN = struct.calcsize(_PACK_STR)
    _CTR_TYPES = {}
    _CTR_PACK_STR = '!2xB'

    _MIN_LEN = _PACK_LEN

    @staticmethod
    def register_control_type(register_cls):
        llc._CTR_TYPES[register_cls.TYPE] = register_cls
        return register_cls

    def __init__(self, dsap_addr, ssap_addr, control):
        super(llc, self).__init__()

        assert getattr(control, 'TYPE', None) in self._CTR_TYPES

        self.dsap_addr = dsap_addr
        self.ssap_addr = ssap_addr
        self.control = control

    @classmethod
    def parser(cls, buf):
        assert len(buf) >= cls._PACK_LEN
        (dsap_addr, ssap_addr) = struct.unpack_from(cls._PACK_STR, buf)

        (control,) = struct.unpack_from(cls._CTR_PACK_STR, buf)
        ctrl = cls._get_control(control)
        control, information = ctrl.parser(buf[cls._PACK_LEN:])

        return (cls(dsap_addr, ssap_addr, control),
                cls.get_packet_type(dsap_addr), information)

    def serialize(self, payload, prev):
        addr = struct.pack(self._PACK_STR, self.dsap_addr, self.ssap_addr)
        control = self.control.serialize()
        return addr + control

    @classmethod
    def _get_control(cls, buf):
        key = buf & 0b1 if buf & 0b1 == ControlFormatI.TYPE else buf & 0b11
        return cls._CTR_TYPES[key]


@llc.register_control_type
class ControlFormatI(stringify.StringifyMixin):
    """LLC sub encoder/decoder class for control I-format field.

    An instance has the following attributes at least.
    Most of them are same to the on-wire counterparts but in host byte
    order.
    __init__ takes the corresponding args in this order.

    ======================== ===============================
    Attribute                Description
    ======================== ===============================
    send_sequence_number     sender send sequence number
    pf_bit                   poll/final bit
    receive_sequence_number  sender receive sequence number
    ======================== ===============================
    """
    TYPE = 0b0
    _PACK_STR = '!H'
    _PACK_LEN = struct.calcsize(_PACK_STR)

    def __init__(self, send_sequence_number=0, pf_bit=0,
                 receive_sequence_number=0):
        super(ControlFormatI, self).__init__()
        self.send_sequence_number = send_sequence_number
        self.pf_bit = pf_bit
        self.receive_sequence_number = receive_sequence_number

    @classmethod
    def parser(cls, buf):
        assert len(buf) >= cls._PACK_LEN
        (control,) = struct.unpack_from(cls._PACK_STR, buf)
        assert (control >> 8) & 0b1 == cls.TYPE

        send_sequence_number = (control >> 9) & 0b1111111
        pf_bit = (control >> 8) & 0b1
        receive_sequence_number = (control >> 1) & 0b1111111

        return cls(send_sequence_number, pf_bit,
                   receive_sequence_number), buf[cls._PACK_LEN:]

    def serialize(self):
        control = (self.send_sequence_number << 9 |
                   self.TYPE << 8 |
                   self.receive_sequence_number << 1 |
                   self.pf_bit)
        return struct.pack(self._PACK_STR, control)


@llc.register_control_type
class ControlFormatS(stringify.StringifyMixin):
    """LLC sub encoder/decoder class for control S-format field.

    An instance has the following attributes at least.
    Most of them are same to the on-wire counterparts but in host byte
    order.
    __init__ takes the corresponding args in this order.

    ======================== ===============================
    Attribute                Description
    ======================== ===============================
    supervisory_function     supervisory function bit
    pf_bit                   poll/final bit
    receive_sequence_number  sender receive sequence number
    ======================== ===============================
    """

    TYPE = 0b01
    _PACK_STR = '!H'
    _PACK_LEN = struct.calcsize(_PACK_STR)

    def __init__(self, supervisory_function=0, pf_bit=0,
                 receive_sequence_number=0):
        super(ControlFormatS, self).__init__()
        self.supervisory_function = supervisory_function
        self.pf_bit = pf_bit
        self.receive_sequence_number = receive_sequence_number

    @classmethod
    def parser(cls, buf):
        assert len(buf) >= cls._PACK_LEN
        (control,) = struct.unpack_from(cls._PACK_STR, buf)

        assert (control >> 8) & 0b11 == cls.TYPE
        assert (control >> 12) & 0b1111 == 0

        supervisory_function = (control >> 10) & 0b11
        pf_bit = (control >> 8) & 0b1
        receive_sequence_number = (control >> 1) & 0b1111111

        return cls(supervisory_function, pf_bit,
                   receive_sequence_number), buf[cls._PACK_LEN:]

    def serialize(self):
        control = (self.supervisory_function << 10 |
                   self.TYPE << 8 |
                   self.receive_sequence_number << 1 |
                   self.pf_bit)
        return struct.pack(self._PACK_STR, control)


@llc.register_control_type
class ControlFormatU(stringify.StringifyMixin):
    """LLC sub encoder/decoder class for control U-format field.

    An instance has the following attributes at least.
    Most of them are same to the on-wire counterparts but in host byte
    order.
    __init__ takes the corresponding args in this order.

    ======================== ===============================
    Attribute                Description
    ======================== ===============================
    modifier_function1       modifier function bit
    pf_bit                   poll/final bit
    modifier_function2       modifier function bit
    ======================== ===============================
    """

    TYPE = 0b11
    _PACK_STR = '!B'
    _PACK_LEN = struct.calcsize(_PACK_STR)

    def __init__(self, modifier_function1=0, pf_bit=0, modifier_function2=0):
        super(ControlFormatU, self).__init__()
        self.modifier_function1 = modifier_function1
        self.pf_bit = pf_bit
        self.modifier_function2 = modifier_function2

    @classmethod
    def parser(cls, buf):
        assert len(buf) >= cls._PACK_LEN
        (control,) = struct.unpack_from(cls._PACK_STR, buf)

        assert control & 0b11 == cls.TYPE

        modifier_function1 = (control >> 2) & 0b11
        pf_bit = (control >> 4) & 0b1
        modifier_function2 = (control >> 5) & 0b111

        return cls(modifier_function1, pf_bit,
                   modifier_function2), buf[cls._PACK_LEN:]

    def serialize(self):
        control = (self.modifier_function2 << 5 |
                   self.pf_bit << 4 |
                   self.modifier_function1 << 2 |
                   self.TYPE)
        return struct.pack(self._PACK_STR, control)


llc.register_packet_type(bpdu.bpdu, SAP_BPDU)

########NEW FILE########
__FILENAME__ = lldp
# Copyright (C) 2012 Nippon Telegraph and Telephone Corporation.
# Copyright (C) 2012 Isaku Yamahata <yamahata at private email ne jp>
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""
Link Layer Discovery Protocol(LLDP, IEEE 802.1AB)
http://standards.ieee.org/getieee802/download/802.1AB-2009.pdf


basic TLV format

octets | 1          | 2             | 3 ...             n + 2 |
       --------------------------------------------------------
       | TLV type | TLV information | TLV information string  |
       | (7bits)  | string length   | ( 0 <= n <= 511 octets) |
       |          | (9bits)         |                         |
       --------------------------------------------------------
bits   |8        2|1|8             1|


LLDPDU format

 ------------------------------------------------------------------------
 | Chassis ID | Port ID | TTL | optional TLV | ... | optional TLV | End |
 ------------------------------------------------------------------------

Chasis ID, Port ID, TTL, End are mandatory
optional TLV may be inserted in any order
"""

import struct
from ryu.lib import stringify
from ryu.lib.packet import packet_base


# LLDP destination MAC address
LLDP_MAC_NEAREST_BRIDGE = '01:80:c2:00:00:0e'
LLDP_MAC_NEAREST_NON_TPMR_BRIDGE = '01:80:c2:00:00:03'
LLDP_MAC_NEAREST_CUSTOMER_BRIDGE = '01:80:c2:00:00:00'


LLDP_TLV_TYPELEN_STR = '!H'
LLDP_TLV_SIZE = 2
LLDP_TLV_TYPE_MASK = 0xfe00
LLDP_TLV_TYPE_SHIFT = 9
LLDP_TLV_LENGTH_MASK = 0x01ff


# LLDP TLV type
LLDP_TLV_END = 0                        # End of LLDPDU
LLDP_TLV_CHASSIS_ID = 1                 # Chassis ID
LLDP_TLV_PORT_ID = 2                    # Port ID
LLDP_TLV_TTL = 3                        # Time To Live
LLDP_TLV_PORT_DESCRIPTION = 4           # Port Description
LLDP_TLV_SYSTEM_NAME = 5                # System Name
LLDP_TLV_SYSTEM_DESCRIPTION = 6         # System Description
LLDP_TLV_SYSTEM_CAPABILITIES = 7        # System Capabilities
LLDP_TLV_MANAGEMENT_ADDRESS = 8         # Management Address
LLDP_TLV_ORGANIZATIONALLY_SPECIFIC = 127  # organizationally Specific TLVs


class LLDPBasicTLV(stringify.StringifyMixin):
    _LEN_MIN = 0
    _LEN_MAX = 511
    tlv_type = None

    def __init__(self, buf=None, *_args, **_kwargs):
        super(LLDPBasicTLV, self).__init__()
        if buf:
            (self.typelen, ) = struct.unpack(
                LLDP_TLV_TYPELEN_STR, buf[:LLDP_TLV_SIZE])
            tlv_type = \
                (self.typelen & LLDP_TLV_TYPE_MASK) >> LLDP_TLV_TYPE_SHIFT
            assert self.tlv_type == tlv_type

            self.len = self.typelen & LLDP_TLV_LENGTH_MASK
            assert len(buf) >= self.len + LLDP_TLV_SIZE

            self.tlv_info = buf[LLDP_TLV_SIZE:]
            self.tlv_info = self.tlv_info[:self.len]

    @staticmethod
    def get_type(buf):
        (typelen, ) = struct.unpack(LLDP_TLV_TYPELEN_STR, buf[:LLDP_TLV_SIZE])
        return (typelen & LLDP_TLV_TYPE_MASK) >> LLDP_TLV_TYPE_SHIFT

    @staticmethod
    def set_tlv_type(subcls, tlv_type):
        assert issubclass(subcls, LLDPBasicTLV)
        subcls.tlv_type = tlv_type

    def _len_valid(self):
        return self._LEN_MIN <= self.len and self.len <= self._LEN_MAX


class lldp(packet_base.PacketBase):
    _tlv_parsers = {}

    def __init__(self, tlvs):
        super(lldp, self).__init__()
        self.tlvs = tlvs

    # at least it must have chassis id, port id, ttl and end
    def _tlvs_len_valid(self):
        return len(self.tlvs) >= 4

    # chassis id, port id, ttl and end
    def _tlvs_valid(self):
        return (self.tlvs[0].tlv_type == LLDP_TLV_CHASSIS_ID and
                self.tlvs[1].tlv_type == LLDP_TLV_PORT_ID and
                self.tlvs[2].tlv_type == LLDP_TLV_TTL and
                self.tlvs[-1].tlv_type == LLDP_TLV_END)

    @classmethod
    def parser(cls, buf):
        tlvs = []

        while buf:
            tlv_type = LLDPBasicTLV.get_type(buf)
            tlv = cls._tlv_parsers[tlv_type](buf)
            tlvs.append(tlv)
            offset = LLDP_TLV_SIZE + tlv.len
            buf = buf[offset:]
            if tlv.tlv_type == LLDP_TLV_END:
                break
            assert len(buf) > 0

        lldp_pkt = cls(tlvs)

        assert lldp_pkt._tlvs_len_valid()
        assert lldp_pkt._tlvs_valid()

        return lldp_pkt, None, buf

    def serialize(self, payload, prev):
        data = bytearray()
        for tlv in self.tlvs:
            data += tlv.serialize()

        return data

    @classmethod
    def set_type(cls, tlv_cls):
        cls._tlv_parsers[tlv_cls.tlv_type] = tlv_cls

    @classmethod
    def get_type(cls, tlv_type):
        return cls._tlv_parsers[tlv_type]

    @classmethod
    def set_tlv_type(cls, tlv_type):
        def _set_type(tlv_cls):
            tlv_cls.set_tlv_type(tlv_cls, tlv_type)
            cls.set_type(tlv_cls)
            return tlv_cls
        return _set_type

    def __len__(self):
        return sum(LLDP_TLV_SIZE + tlv.len for tlv in self.tlvs)


@lldp.set_tlv_type(LLDP_TLV_END)
class End(LLDPBasicTLV):
    def __init__(self, buf=None, *args, **kwargs):
        super(End, self).__init__(buf, *args, **kwargs)
        if buf:
            pass
        else:
            self.len = 0
            self.typelen = 0

    def serialize(self):
        return struct.pack('!H', self.typelen)


@lldp.set_tlv_type(LLDP_TLV_CHASSIS_ID)
class ChassisID(LLDPBasicTLV):
    _PACK_STR = '!B'
    _PACK_SIZE = struct.calcsize(_PACK_STR)
    # subtype id(1 octet) + chassis id length(1 - 255 octet)
    _LEN_MIN = 2
    _LEN_MAX = 256

    # Chassis ID subtype
    SUB_CHASSIS_COMPONENT = 1   # EntPhysicalAlias (IETF RFC 4133)
    SUB_INTERFACE_ALIAS = 2     # IfAlias (IETF RFC 2863)
    SUB_PORT_COMPONENT = 3      # EntPhysicalAlias (IETF RFC 4133)
    SUB_MAC_ADDRESS = 4         # MAC address (IEEE std 802)
    SUB_NETWORK_ADDRESS = 5     # networkAddress
    SUB_INTERFACE_NAME = 6      # IfName (IETF RFC 2863)
    SUB_LOCALLY_ASSIGNED = 7    # local

    def __init__(self, buf=None, *args, **kwargs):
        super(ChassisID, self).__init__(buf, *args, **kwargs)
        if buf:
            (self.subtype, ) = struct.unpack(
                self._PACK_STR, self.tlv_info[:self._PACK_SIZE])
            self.chassis_id = self.tlv_info[self._PACK_SIZE:]
        else:
            self.subtype = kwargs['subtype']
            self.chassis_id = kwargs['chassis_id']
            self.len = self._PACK_SIZE + len(self.chassis_id)
            assert self._len_valid()
            self.typelen = (self.tlv_type << LLDP_TLV_TYPE_SHIFT) | self.len

    def serialize(self):
        return struct.pack('!HB', self.typelen, self.subtype) + self.chassis_id


@lldp.set_tlv_type(LLDP_TLV_PORT_ID)
class PortID(LLDPBasicTLV):
    _PACK_STR = '!B'
    _PACK_SIZE = struct.calcsize(_PACK_STR)

    # subtype id(1 octet) + port id length(1 - 255 octet)
    _LEN_MIN = 2
    _LEN_MAX = 256

    # Port ID subtype
    SUB_INTERFACE_ALIAS = 1     # ifAlias (IETF RFC 2863)
    SUB_PORT_COMPONENT = 2      # entPhysicalAlias (IETF RFC 4133)
    SUB_MAC_ADDRESS = 3         # MAC address (IEEE Std 802)
    SUB_NETWORK_ADDRESS = 4     # networkAddress
    SUB_INTERFACE_NAME = 5      # ifName (IETF RFC 2863)
    SUB_AGENT_CIRCUIT_ID = 6    # agent circuit ID(IETF RFC 3046)
    SUB_LOCALLY_ASSIGNED = 7    # local

    def __init__(self, buf=None, *args, **kwargs):
        super(PortID, self).__init__(buf, *args, **kwargs)
        if buf:
            (self.subtype, ) = struct.unpack(
                self._PACK_STR, self.tlv_info[:self._PACK_SIZE])
            self.port_id = self.tlv_info[self._PACK_SIZE:]
        else:
            self.subtype = kwargs['subtype']
            self.port_id = kwargs['port_id']
            self.len = self._PACK_SIZE + len(self.port_id)
            assert self._len_valid()
            self.typelen = (self.tlv_type << LLDP_TLV_TYPE_SHIFT) | self.len

    def serialize(self):
        return struct.pack('!HB', self.typelen, self.subtype) + self.port_id


@lldp.set_tlv_type(LLDP_TLV_TTL)
class TTL(LLDPBasicTLV):
    _PACK_STR = '!H'
    _PACK_SIZE = struct.calcsize(_PACK_STR)
    _LEN_MIN = _PACK_SIZE
    _LEN_MAX = _PACK_SIZE

    def __init__(self, buf=None, *args, **kwargs):
        super(TTL, self).__init__(buf, *args, **kwargs)
        if buf:
            (self.ttl, ) = struct.unpack(
                self._PACK_STR, self.tlv_info[:self._PACK_SIZE])
        else:
            self.ttl = kwargs['ttl']
            self.len = self._PACK_SIZE
            assert self._len_valid()
            self.typelen = (self.tlv_type << LLDP_TLV_TYPE_SHIFT) | self.len

    def serialize(self):
        return struct.pack('!HH', self.typelen, self.ttl)


@lldp.set_tlv_type(LLDP_TLV_PORT_DESCRIPTION)
class PortDescription(LLDPBasicTLV):
    _LEN_MAX = 255

    def __init__(self, buf=None, *args, **kwargs):
        super(PortDescription, self).__init__(buf, *args, **kwargs)
        if buf:
            pass
        else:
            self.port_description = kwargs['port_description']
            self.len = len(self.port_description)
            assert self._len_valid()
            self.typelen = (self.tlv_type << LLDP_TLV_TYPE_SHIFT) | self.len

    def serialize(self):
        return struct.pack('!H', self.typelen) + self.port_description

    @property
    def port_description(self):
        return self.tlv_info

    @port_description.setter
    def port_description(self, value):
        self.tlv_info = value


@lldp.set_tlv_type(LLDP_TLV_SYSTEM_NAME)
class SystemName(LLDPBasicTLV):
    _LEN_MAX = 255

    def __init__(self, buf=None, *args, **kwargs):
        super(SystemName, self).__init__(buf, *args, **kwargs)
        if buf:
            pass
        else:
            self.system_name = kwargs['system_name']
            self.len = len(self.system_name)
            assert self._len_valid()
            self.typelen = (self.tlv_type << LLDP_TLV_TYPE_SHIFT) | self.len

    def serialize(self):
        return struct.pack('!H', self.typelen) + self.tlv_info

    @property
    def system_name(self):
        return self.tlv_info

    @system_name.setter
    def system_name(self, value):
        self.tlv_info = value


@lldp.set_tlv_type(LLDP_TLV_SYSTEM_DESCRIPTION)
class SystemDescription(LLDPBasicTLV):
    _LEN_MAX = 255

    def __init__(self, buf=None, *args, **kwargs):
        super(SystemDescription, self).__init__(buf, *args, **kwargs)
        if buf:
            pass
        else:
            self.system_description = kwargs['system_description']
            self.len = len(self.system_description)
            assert self._len_valid()
            self.typelen = (self.tlv_type << LLDP_TLV_TYPE_SHIFT) | self.len

    def serialize(self):
        return struct.pack('!H', self.typelen) + self.tlv_info

    @property
    def system_description(self):
        return self.tlv_info

    @system_description.setter
    def system_description(self, value):
        self.tlv_info = value


@lldp.set_tlv_type(LLDP_TLV_SYSTEM_CAPABILITIES)
class SystemCapabilities(LLDPBasicTLV):
    # chassis subtype(1) + system cap(2) + enabled cap(2)
    _PACK_STR = '!BHH'
    _PACK_SIZE = struct.calcsize(_PACK_STR)
    _LEN_MIN = _PACK_SIZE
    _LEN_MAX = _PACK_SIZE

    # System Capabilities
    CAP_REPEATER = (1 << 1)             # IETF RFC 2108
    CAP_MAC_BRIDGE = (1 << 2)           # IEEE Std 802.1D
    CAP_WLAN_ACCESS_POINT = (1 << 3)    # IEEE Std 802.11 MIB
    CAP_ROUTER = (1 << 4)               # IETF RFC 1812
    CAP_TELEPHONE = (1 << 5)            # IETF RFC 4293
    CAP_DOCSIS = (1 << 6)               # IETF RFC 4639 and IETF RFC 4546
    CAP_STATION_ONLY = (1 << 7)         # IETF RFC 4293
    CAP_CVLAN = (1 << 8)                # IEEE Std 802.1Q
    CAP_SVLAN = (1 << 9)                # IEEE Std 802.1Q
    CAP_TPMR = (1 << 10)                # IEEE Std 802.1Q

    def __init__(self, buf=None, *args, **kwargs):
        super(SystemCapabilities, self).__init__(buf, *args, **kwargs)
        if buf:
            (self.subtype, self.system_cap, self.enabled_cap) = \
                struct.unpack(self._PACK_STR, self.tlv_info[:self._PACK_SIZE])
        else:
            self.subtype = kwargs['subtype']
            self.system_cap = kwargs['system_cap']
            self.enabled_cap = kwargs['enabled_cap']
            self.len = self._PACK_SIZE
            assert self._len_valid()
            self.typelen = (self.tlv_type << LLDP_TLV_TYPE_SHIFT) | self.len

    def serialize(self):
        return struct.pack('!HBHH',
                           self.typelen, self.subtype,
                           self.system_cap, self.enabled_cap)


@lldp.set_tlv_type(LLDP_TLV_MANAGEMENT_ADDRESS)
class ManagementAddress(LLDPBasicTLV):
    _LEN_MIN = 9
    _LEN_MAX = 167

    _ADDR_PACK_STR = '!BB'    # address string length, address subtype
    _ADDR_PACK_SIZE = struct.calcsize(_ADDR_PACK_STR)
    _ADDR_LEN_MIN = 1
    _ADDR_LEN_MAX = 31

    _INTF_PACK_STR = '!BIB'   # interface subtype, interface number, oid length
    _INTF_PACK_SIZE = struct.calcsize(_INTF_PACK_STR)
    _OID_LEN_MIN = 0
    _OID_LEN_MAX = 128

    def __init__(self, buf=None, *args, **kwargs):
        super(ManagementAddress, self).__init__(buf, *args, **kwargs)
        if buf:
            (self.addr_len, self.addr_subtype) = struct.unpack(
                self._ADDR_PACK_STR, self.tlv_info[:self._ADDR_PACK_SIZE])
            assert self._addr_len_valid()
            offset = self._ADDR_PACK_SIZE + self.addr_len - 1
            self.addr = self.tlv_info[self._ADDR_PACK_SIZE:offset]

            (self.intf_subtype, self.intf_num, self.oid_len) = struct.unpack(
                self._INTF_PACK_STR,
                self.tlv_info[offset:offset + self._INTF_PACK_SIZE])
            assert self._oid_len_valid()

            offset = offset + self._INTF_PACK_SIZE
            self.oid = self.tlv_info[offset:]
        else:
            self.addr_subtype = kwargs['addr_subtype']
            self.addr = kwargs['addr']
            self.addr_len = len(self.addr) + 1  # 1 octet subtype
            assert self._addr_len_valid()

            self.intf_subtype = kwargs['intf_subtype']
            self.intf_num = kwargs['intf_num']

            self.oid = kwargs['oid']
            self.oid_len = len(self.oid)
            assert self._oid_len_valid()

            self.len = self._ADDR_PACK_SIZE + self.addr_len - 1 \
                + self._INTF_PACK_SIZE + self.oid_len
            assert self._len_valid()
            self.typelen = (self.tlv_type << LLDP_TLV_TYPE_SHIFT) | self.len

    def serialize(self):
        tlv_info = struct.pack(self._ADDR_PACK_STR,
                               self.addr_len, self.addr_subtype)
        tlv_info += self.addr
        tlv_info += struct.pack(self._INTF_PACK_STR,
                                self.intf_subtype, self.intf_num, self.oid_len)
        tlv_info += self.oid
        return struct.pack('!H', self.typelen) + tlv_info

    def _addr_len_valid(self):
        return (self._ADDR_LEN_MIN <= self.addr_len or
                self.addr_len <= self._ADDR_LEN_MAX)

    def _oid_len_valid(self):
        return (self._OID_LEN_MIN <= self.oid_len and
                self.oid_len <= self._OID_LEN_MAX)


@lldp.set_tlv_type(LLDP_TLV_ORGANIZATIONALLY_SPECIFIC)
class OrganizationallySpecific(LLDPBasicTLV):
    _PACK_STR = '!3sB'
    _PACK_SIZE = struct.calcsize(_PACK_STR)
    _LEN_MIN = _PACK_SIZE
    _LEN_MAX = 511

    def __init__(self, buf=None, *args, **kwargs):
        super(OrganizationallySpecific, self).__init__(buf, *args, **kwargs)
        if buf:
            (self.oui, self.subtype) = struct.unpack(
                self._PACK_STR, self.tlv_info[:self._PACK_SIZE])
        else:
            self.oui = kwargs['oui']
            self.subtype = kwargs['subtype']
            self.info = kwargs['info']
            self.len = self._PACK_SIZE + len(self.info)
            assert self._len_valid()
            self.typelen = (self.tlv_type << LLDP_TLV_TYPE_SHIFT) | self.len

    def serialize(self):
        return struct.pack('!H3sB', self.typelen, self.oui, self.subtype)

########NEW FILE########
__FILENAME__ = mpls
# Copyright (C) 2012 Nippon Telegraph and Telephone Corporation.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import struct
import socket
from . import packet_base
from . import packet_utils
from . import ipv4
from ryu.ofproto import ether


class mpls(packet_base.PacketBase):
    """MPLS (RFC 3032) header encoder/decoder class.

    NOTE: When decoding, this implementation assumes that the inner protocol
    is IPv4.

    An instance has the following attributes at least.
    Most of them are same to the on-wire counterparts but in host byte order.
    __init__ takes the corresponding args in this order.

    ============== ====================
    Attribute      Description
    ============== ====================
    label          Label Value
    exp            Experimental Use
    bsb            Bottom of Stack
    ttl            Time To Live
    ============== ====================
    """

    _PACK_STR = '!I'
    _MIN_LEN = struct.calcsize(_PACK_STR)

    def __init__(self, label=0, exp=0, bsb=1, ttl=255):
        super(mpls, self).__init__()
        self.label = label
        self.exp = exp
        self.bsb = bsb
        self.ttl = ttl

    @classmethod
    def parser(cls, buf):
        (label,) = struct.unpack_from(cls._PACK_STR, buf)
        ttl = label & 0xff
        bsb = (label >> 8) & 1
        exp = (label >> 9) & 7
        label = label >> 12
        msg = cls(label, exp, bsb, ttl)
        if bsb:
            return msg, ipv4.ipv4, buf[msg._MIN_LEN:]
        else:
            return msg, mpls, buf[msg._MIN_LEN:]

    def serialize(self, payload, prev):
        val = self.label << 12 | self.exp << 9 | self.bsb << 8 | self.ttl
        return struct.pack(mpls._PACK_STR, val)

########NEW FILE########
__FILENAME__ = packet
# Copyright (C) 2012 Nippon Telegraph and Telephone Corporation.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import inspect
import struct

from . import packet_base
from . import ethernet


class Packet(object):
    """A packet decoder/encoder class.

    An instance is used to either decode or encode a single packet.

    *data* is a bytearray to describe a raw datagram to decode.
    When decoding, a Packet object is iteratable.
    Iterated values are protocol (ethernet, ipv4, ...) headers and the payload.
    Protocol headers are instances of subclass of packet_base.PacketBase.
    The payload is a bytearray.  They are iterated in on-wire order.

    *data* should be omitted when encoding a packet.
    """

    def __init__(self, data=None, protocols=None, parse_cls=ethernet.ethernet):
        super(Packet, self).__init__()
        self.data = data
        if protocols is None:
            self.protocols = []
        else:
            self.protocols = protocols
        self.protocol_idx = 0
        if self.data:
            self._parser(parse_cls)

    def _parser(self, cls):
        rest_data = self.data
        while cls:
            try:
                proto, cls, rest_data = cls.parser(rest_data)
            except struct.error:
                break
            if proto:
                self.protocols.append(proto)
        if rest_data:
            self.protocols.append(rest_data)

    def serialize(self):
        """Encode a packet and store the resulted bytearray in self.data.

        This method is legal only when encoding a packet.
        """

        self.data = bytearray()
        r = self.protocols[::-1]
        for i, p in enumerate(r):
            if isinstance(p, packet_base.PacketBase):
                if i == len(r) - 1:
                    prev = None
                else:
                    prev = r[i + 1]
                data = p.serialize(self.data, prev)
            else:
                data = str(p)
            self.data = data + self.data

    def add_protocol(self, proto):
        """Register a protocol *proto* for this packet.

        This method is legal only when encoding a packet.

        When encoding a packet, register a protocol (ethernet, ipv4, ...)
        header to add to this packet.
        Protocol headers should be registered in on-wire order before calling
        self.serialize.
        """

        self.protocols.append(proto)

    def get_protocols(self, protocol):
        """Returns a list of protocols that matches to the specified protocol.
        """
        if isinstance(protocol, packet_base.PacketBase):
            protocol = protocol.__class__
        assert issubclass(protocol, packet_base.PacketBase)
        return [p for p in self.protocols if isinstance(p, protocol)]

    def get_protocol(self, protocol):
        """Returns the firstly found protocol that matches to the
        specified protocol.
        """
        result = self.get_protocols(protocol)
        if len(result) > 0:
            return result[0]
        return None

    def next(self):
        try:
            p = self.protocols[self.protocol_idx]
        except:
            self.protocol_idx = 0
            raise StopIteration

        self.protocol_idx += 1
        return p

    def __div__(self, trailer):
        self.add_protocol(trailer)
        return self

    def __iter__(self):
        return self

    def __getitem__(self, idx):
        return self.protocols[idx]

    def __setitem__(self, idx, item):
        self.protocols[idx] = item

    def __delitem__(self, idx):
        del self.protocols[idx]

    def __len__(self):
        return len(self.protocols)

    def __contains__(self, protocol):
        if (inspect.isclass(protocol) and
                issubclass(protocol, packet_base.PacketBase)):
            return protocol in [p.__class__ for p in self.protocols]
        return protocol in self.protocols

    def __str__(self):
        return ', '.join(repr(protocol) for protocol in self.protocols)
    __repr__ = __str__  # note: str(list) uses __repr__ for elements


# XXX: Hack for preventing recursive import
def _PacketBase__div__(self, trailer):
    pkt = Packet()
    pkt.add_protocol(self)
    pkt.add_protocol(trailer)
    return pkt

packet_base.PacketBase.__div__ = _PacketBase__div__

########NEW FILE########
__FILENAME__ = packet_base
# Copyright (C) 2012 Nippon Telegraph and Telephone Corporation.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import abc
from ryu.lib import stringify


class PacketBase(stringify.StringifyMixin):
    """A base class for a protocol (ethernet, ipv4, ...) header."""
    __metaclass__ = abc.ABCMeta
    _TYPES = {}

    @classmethod
    def get_packet_type(cls, type_):
        """Per-protocol dict-like get method.

        Provided for convenience of protocol implementers.
        Internal use only."""
        return cls._TYPES.get(type_)

    @classmethod
    def register_packet_type(cls, cls_, type_):
        """Per-protocol dict-like set method.

        Provided for convenience of protocol implementers.
        Internal use only."""
        cls._TYPES[type_] = cls_

    def __init__(self):
        super(PacketBase, self).__init__()

    def __len__(self):
        return self._MIN_LEN

    @property
    def protocol_name(self):
        return self.__class__.__name__

    @classmethod
    @abc.abstractmethod
    def parser(cls, buf):
        """Decode a protocol header.

        This method is used only when decoding a packet.

        Decode a protocol header at offset 0 in bytearray *buf*.
        Returns the following three objects.

        * An object to describe the decoded header.

        * A packet_base.PacketBase subclass appropriate for the rest of
          the packet.  None when the rest of the packet should be considered
          as raw payload.

        * The rest of packet.

        """
        pass

    def serialize(self, payload, prev):
        """Encode a protocol header.

        This method is used only when encoding a packet.

        Encode a protocol header.
        Returns a bytearray which contains the header.

        *payload* is the rest of the packet which will immediately follow
        this header.

        *prev* is a packet_base.PacketBase subclass for the outer protocol
        header.  *prev* is None if the current header is the outer-most.
        For example, *prev* is ipv4 or ipv6 for tcp.serialize.
        """
        pass

########NEW FILE########
__FILENAME__ = packet_utils
# Copyright (C) 2012 Nippon Telegraph and Telephone Corporation.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import array
import socket
import struct
from ryu.lib import addrconv


def carry_around_add(a, b):
    c = a + b
    return (c & 0xffff) + (c >> 16)


def checksum(data):
    if len(data) % 2:
        data += '\x00'

    data = str(data)    # input can be bytearray.
    s = sum(array.array('H', data))
    s = (s & 0xffff) + (s >> 16)
    s += (s >> 16)
    return socket.ntohs(~s & 0xffff)


# avoid circular import
_IPV4_PSEUDO_HEADER_PACK_STR = '!4s4sxBH'
_IPV6_PSEUDO_HEADER_PACK_STR = '!16s16sI3xB'


def checksum_ip(ipvx, length, payload):
    """
    calculate checksum of IP pseudo header

    IPv4 pseudo header
    UDP RFC768
    TCP RFC793 3.1

     0      7 8     15 16    23 24    31
    +--------+--------+--------+--------+
    |          source address           |
    +--------+--------+--------+--------+
    |        destination address        |
    +--------+--------+--------+--------+
    |  zero  |protocol|    length       |
    +--------+--------+--------+--------+


    IPv6 pseudo header
    RFC2460 8.1
    +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
    |                                                               |
    +                                                               +
    |                                                               |
    +                         Source Address                        +
    |                                                               |
    +                                                               +
    |                                                               |
    +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
    |                                                               |
    +                                                               +
    |                                                               |
    +                      Destination Address                      +
    |                                                               |
    +                                                               +
    |                                                               |
    +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
    |                   Upper-Layer Packet Length                   |
    +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
    |                      zero                     |  Next Header  |
    +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
    """
    if ipvx.version == 4:
        header = struct.pack(_IPV4_PSEUDO_HEADER_PACK_STR,
                             addrconv.ipv4.text_to_bin(ipvx.src),
                             addrconv.ipv4.text_to_bin(ipvx.dst),
                             ipvx.proto, length)
    elif ipvx.version == 6:
        header = struct.pack(_IPV6_PSEUDO_HEADER_PACK_STR,
                             addrconv.ipv6.text_to_bin(ipvx.src),
                             addrconv.ipv6.text_to_bin(ipvx.dst),
                             length, ipvx.nxt)
    else:
        raise ValueError('Unknown IP version %d' % ipvx.version)

    buf = header + payload
    return checksum(buf)

########NEW FILE########
__FILENAME__ = pbb
# Copyright (C) 2013 Nippon Telegraph and Telephone Corporation.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import struct
from ryu.lib.packet import packet_base
from ryu.ofproto import ether


class itag(packet_base.PacketBase):
    """I-TAG (IEEE 802.1ah-2008) header encoder/decoder class.

    An instance has the following attributes at least.
    Most of them are same to the on-wire counterparts but in host byte order.
    __init__ takes the corresponding args in this order.

    ============== ====================
    Attribute      Description
    ============== ====================
    pcp            Priority Code Point
    dei            Drop Eligible Indication
    uca            Use Customer Address
    sid            Service Instance ID
    ============== ====================
    """

    _PACK_STR = "!I"
    _MIN_LEN = struct.calcsize(_PACK_STR)

    def __init__(self, pcp=0, dei=0, uca=0, sid=0):
        super(itag, self).__init__()
        self.pcp = pcp
        self.dei = dei
        self.uca = uca
        self.sid = sid

    @classmethod
    def parser(cls, buf):
        (data, ) = struct.unpack_from(cls._PACK_STR, buf)
        pcp = data >> 29
        dei = data >> 28 & 1
        uca = data >> 27 & 1
        sid = data & 0x00ffffff
        from ryu.lib.packet import ethernet
        return (cls(pcp, dei, uca, sid), ethernet.ethernet,
                buf[cls._MIN_LEN:])

    def serialize(self, payload, prev):
        data = self.pcp << 29 | self.dei << 28 | self.uca << 27 | self.sid
        return struct.pack(self._PACK_STR, data)

########NEW FILE########
__FILENAME__ = safi
# Copyright (C) 2013 Nippon Telegraph and Telephone Corporation.
# Copyright (C) 2013 YAMAMOTO Takashi <yamamoto at valinux co jp>
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""
Subsequent Address Family Idenitifier (SAFI)
http://www.iana.org/assignments/safi-namespace/safi-namespace.xhtml
"""

UNICAST = 1
MULTICAST = 2
MPLS_VPN = 128  # RFC 4364

########NEW FILE########
__FILENAME__ = sctp
# Copyright (C) 2013 Nippon Telegraph and Telephone Corporation.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import abc
import struct

from ryu.lib import addrconv
from ryu.lib import stringify
from ryu.lib.packet import packet_base

# Chunk Types
TYPE_DATA = 0
TYPE_INIT = 1
TYPE_INIT_ACK = 2
TYPE_SACK = 3
TYPE_HEARTBEAT = 4
TYPE_HEARTBEAT_ACK = 5
TYPE_ABORT = 6
TYPE_SHUTDOWN = 7
TYPE_SHUTDOWN_ACK = 8
TYPE_ERROR = 9
TYPE_COOKIE_ECHO = 10
TYPE_COOKIE_ACK = 11
TYPE_ECN_ECHO = 12
TYPE_CWR = 13
TYPE_SHUTDOWN_COMPLETE = 14

# Cause Code
CCODE_INVALID_STREAM_ID = 1
CCODE_MISSING_PARAM = 2
CCODE_STALE_COOKIE = 3
CCODE_OUT_OF_RESOURCE = 4
CCODE_UNRESOLVABLE_ADDR = 5
CCODE_UNRECOGNIZED_CHUNK = 6
CCODE_INVALID_PARAM = 7
CCODE_UNRECOGNIZED_PARAM = 8
CCODE_NO_USERDATA = 9
CCODE_COOKIE_WHILE_SHUTDOWN = 10
CCODE_RESTART_WITH_NEW_ADDR = 11
CCODE_USER_INITIATED_ABORT = 12
CCODE_PROTOCOL_VIOLATION = 13

# Chunk Parameter Types
PTYPE_HEARTBEAT = 1
PTYPE_IPV4 = 5
PTYPE_IPV6 = 6
PTYPE_STATE_COOKIE = 7
PTYPE_UNRECOGNIZED_PARAM = 8
PTYPE_COOKIE_PRESERVE = 9
PTYPE_HOST_ADDR = 11
PTYPE_SUPPORTED_ADDR = 12
PTYPE_ECN = 32768


class sctp(packet_base.PacketBase):
    """Stream Control Transmission Protocol (SCTP)
    header encoder/decoder class (RFC 4960).

    An instance has the following attributes at least.
    Most of them are same to the on-wire counterparts but in host byte order.
    __init__ takes the corresponding args in this order.

    .. tabularcolumns:: |l|L|

    ============== =====================================================
    Attribute      Description
    ============== =====================================================
    src_port       Source Port
    dst_port       Destination Port
    vtag           Verification Tag
    csum           Checksum
                   (0 means automatically-calculate when encoding)
    chunks         a list of derived classes of ryu.lib.packet.sctp.chunk.
    ============== =====================================================
    """

    _PACK_STR = '!HHII'
    _MIN_LEN = struct.calcsize(_PACK_STR)
    _SCTP_CHUNK_TYPE = {}
    _class_prefixes = ['chunk_']

    @staticmethod
    def register_chunk_type(*args):
        def _register_chunk_type(cls):
            sctp._SCTP_CHUNK_TYPE[cls.chunk_type()] = cls
            return cls
        return _register_chunk_type(args[0])

    def __init__(self, src_port=0, dst_port=0, vtag=0, csum=0, chunks=None):
        super(sctp, self).__init__()
        self.src_port = src_port
        self.dst_port = dst_port
        self.vtag = vtag
        self.csum = csum
        chunks = chunks or []
        assert isinstance(chunks, list)
        for one in chunks:
            assert isinstance(one, chunk)
        self.chunks = chunks

    @classmethod
    def parser(cls, buf):
        (src_port, dst_port, vtag, csum) = struct.unpack_from(
            cls._PACK_STR, buf)
        chunks = []
        offset = cls._MIN_LEN
        while offset < len(buf):
            (type_, ) = struct.unpack_from('!B', buf, offset)
            cls_ = cls._SCTP_CHUNK_TYPE.get(type_)
            if not cls_:
                break
            ins = cls_.parser(buf[offset:])
            chunks.append(ins)
            offset += len(ins)
        msg = cls(src_port, dst_port, vtag, csum, chunks)
        return msg, None, buf[offset:]

    def serialize(self, payload, prev):
        buf = bytearray(struct.pack(
            self._PACK_STR, self.src_port, self.dst_port, self.vtag,
            self.csum))
        if self.chunks:
            for one in self.chunks:
                buf.extend(one.serialize())
        if self.csum == 0:
            self.csum = self._checksum(buf)
            struct.pack_into('!I', buf, 8, self.csum)
        return str(buf)

    def __len__(self):
        length = self._MIN_LEN
        if self.chunks is not None:
            for one in self.chunks:
                length += len(one)
        return length

    def _checksum(self, data):
        # from RFC 3309
        crc_c = [
            0x00000000, 0xF26B8303, 0xE13B70F7, 0x1350F3F4,
            0xC79A971F, 0x35F1141C, 0x26A1E7E8, 0xD4CA64EB,
            0x8AD958CF, 0x78B2DBCC, 0x6BE22838, 0x9989AB3B,
            0x4D43CFD0, 0xBF284CD3, 0xAC78BF27, 0x5E133C24,
            0x105EC76F, 0xE235446C, 0xF165B798, 0x030E349B,
            0xD7C45070, 0x25AFD373, 0x36FF2087, 0xC494A384,
            0x9A879FA0, 0x68EC1CA3, 0x7BBCEF57, 0x89D76C54,
            0x5D1D08BF, 0xAF768BBC, 0xBC267848, 0x4E4DFB4B,
            0x20BD8EDE, 0xD2D60DDD, 0xC186FE29, 0x33ED7D2A,
            0xE72719C1, 0x154C9AC2, 0x061C6936, 0xF477EA35,
            0xAA64D611, 0x580F5512, 0x4B5FA6E6, 0xB93425E5,
            0x6DFE410E, 0x9F95C20D, 0x8CC531F9, 0x7EAEB2FA,
            0x30E349B1, 0xC288CAB2, 0xD1D83946, 0x23B3BA45,
            0xF779DEAE, 0x05125DAD, 0x1642AE59, 0xE4292D5A,
            0xBA3A117E, 0x4851927D, 0x5B016189, 0xA96AE28A,
            0x7DA08661, 0x8FCB0562, 0x9C9BF696, 0x6EF07595,
            0x417B1DBC, 0xB3109EBF, 0xA0406D4B, 0x522BEE48,
            0x86E18AA3, 0x748A09A0, 0x67DAFA54, 0x95B17957,
            0xCBA24573, 0x39C9C670, 0x2A993584, 0xD8F2B687,
            0x0C38D26C, 0xFE53516F, 0xED03A29B, 0x1F682198,
            0x5125DAD3, 0xA34E59D0, 0xB01EAA24, 0x42752927,
            0x96BF4DCC, 0x64D4CECF, 0x77843D3B, 0x85EFBE38,
            0xDBFC821C, 0x2997011F, 0x3AC7F2EB, 0xC8AC71E8,
            0x1C661503, 0xEE0D9600, 0xFD5D65F4, 0x0F36E6F7,
            0x61C69362, 0x93AD1061, 0x80FDE395, 0x72966096,
            0xA65C047D, 0x5437877E, 0x4767748A, 0xB50CF789,
            0xEB1FCBAD, 0x197448AE, 0x0A24BB5A, 0xF84F3859,
            0x2C855CB2, 0xDEEEDFB1, 0xCDBE2C45, 0x3FD5AF46,
            0x7198540D, 0x83F3D70E, 0x90A324FA, 0x62C8A7F9,
            0xB602C312, 0x44694011, 0x5739B3E5, 0xA55230E6,
            0xFB410CC2, 0x092A8FC1, 0x1A7A7C35, 0xE811FF36,
            0x3CDB9BDD, 0xCEB018DE, 0xDDE0EB2A, 0x2F8B6829,
            0x82F63B78, 0x709DB87B, 0x63CD4B8F, 0x91A6C88C,
            0x456CAC67, 0xB7072F64, 0xA457DC90, 0x563C5F93,
            0x082F63B7, 0xFA44E0B4, 0xE9141340, 0x1B7F9043,
            0xCFB5F4A8, 0x3DDE77AB, 0x2E8E845F, 0xDCE5075C,
            0x92A8FC17, 0x60C37F14, 0x73938CE0, 0x81F80FE3,
            0x55326B08, 0xA759E80B, 0xB4091BFF, 0x466298FC,
            0x1871A4D8, 0xEA1A27DB, 0xF94AD42F, 0x0B21572C,
            0xDFEB33C7, 0x2D80B0C4, 0x3ED04330, 0xCCBBC033,
            0xA24BB5A6, 0x502036A5, 0x4370C551, 0xB11B4652,
            0x65D122B9, 0x97BAA1BA, 0x84EA524E, 0x7681D14D,
            0x2892ED69, 0xDAF96E6A, 0xC9A99D9E, 0x3BC21E9D,
            0xEF087A76, 0x1D63F975, 0x0E330A81, 0xFC588982,
            0xB21572C9, 0x407EF1CA, 0x532E023E, 0xA145813D,
            0x758FE5D6, 0x87E466D5, 0x94B49521, 0x66DF1622,
            0x38CC2A06, 0xCAA7A905, 0xD9F75AF1, 0x2B9CD9F2,
            0xFF56BD19, 0x0D3D3E1A, 0x1E6DCDEE, 0xEC064EED,
            0xC38D26C4, 0x31E6A5C7, 0x22B65633, 0xD0DDD530,
            0x0417B1DB, 0xF67C32D8, 0xE52CC12C, 0x1747422F,
            0x49547E0B, 0xBB3FFD08, 0xA86F0EFC, 0x5A048DFF,
            0x8ECEE914, 0x7CA56A17, 0x6FF599E3, 0x9D9E1AE0,
            0xD3D3E1AB, 0x21B862A8, 0x32E8915C, 0xC083125F,
            0x144976B4, 0xE622F5B7, 0xF5720643, 0x07198540,
            0x590AB964, 0xAB613A67, 0xB831C993, 0x4A5A4A90,
            0x9E902E7B, 0x6CFBAD78, 0x7FAB5E8C, 0x8DC0DD8F,
            0xE330A81A, 0x115B2B19, 0x020BD8ED, 0xF0605BEE,
            0x24AA3F05, 0xD6C1BC06, 0xC5914FF2, 0x37FACCF1,
            0x69E9F0D5, 0x9B8273D6, 0x88D28022, 0x7AB90321,
            0xAE7367CA, 0x5C18E4C9, 0x4F48173D, 0xBD23943E,
            0xF36E6F75, 0x0105EC76, 0x12551F82, 0xE03E9C81,
            0x34F4F86A, 0xC69F7B69, 0xD5CF889D, 0x27A40B9E,
            0x79B737BA, 0x8BDCB4B9, 0x988C474D, 0x6AE7C44E,
            0xBE2DA0A5, 0x4C4623A6, 0x5F16D052, 0xAD7D5351,
        ]

        crc32 = 0xffffffff
        for c in str(data):
            crc32 = (crc32 >> 8) ^ crc_c[(crc32 ^ (ord(c))) & 0xFF]
        crc32 = (~crc32) & 0xffffffff
        return struct.unpack(">I", struct.pack("<I", crc32))[0]


#=======================================================================
#
# Chunk Types
#
#=======================================================================
class chunk(stringify.StringifyMixin):

    __metaclass__ = abc.ABCMeta
    _PACK_STR = '!BBH'
    _MIN_LEN = struct.calcsize(_PACK_STR)

    @classmethod
    @abc.abstractmethod
    def chunk_type(cls):
        pass

    @abc.abstractmethod
    def __init__(self, type_, length):
        self._type = type_
        self.length = length

    @classmethod
    @abc.abstractmethod
    def parser(cls, buf):
        pass

    def __len__(self):
        return self.length


class chunk_init_base(chunk):

    __metaclass__ = abc.ABCMeta
    _PACK_STR = '!BBHIIHHI'
    _MIN_LEN = struct.calcsize(_PACK_STR)

    def __init__(self, flags=0, length=0, init_tag=0, a_rwnd=0, os=0,
                 mis=0, i_tsn=0, params=None):
        super(chunk_init_base, self).__init__(self.chunk_type(), length)
        self.flags = flags
        self.init_tag = init_tag
        self.a_rwnd = a_rwnd
        self.os = os
        self.mis = mis
        self.i_tsn = i_tsn
        params = params or []
        assert isinstance(params, list)
        for one in params:
            assert isinstance(one, param)
        self.params = params

    @classmethod
    def parser_base(cls, buf, recog):
        (_, flags, length, init_tag, a_rwnd, os, mis, i_tsn
         ) = struct.unpack_from(cls._PACK_STR, buf)
        params = []
        offset = cls._MIN_LEN
        while offset < length:
            (ptype, ) = struct.unpack_from('!H', buf, offset)
            cls_ = recog.get(ptype)
            if not cls_:
                break
            ins = cls_.parser(buf[offset:])
            params.append(ins)
            offset += len(ins)
        msg = cls(flags, length, init_tag, a_rwnd, os, mis, i_tsn, params)
        return msg

    def serialize(self):
        buf = bytearray(struct.pack(
            self._PACK_STR, self.chunk_type(), self.flags,
            self.length, self.init_tag, self.a_rwnd, self.os, self.mis,
            self.i_tsn))
        for one in self.params:
            buf.extend(one.serialize())
        if 0 == self.length:
            self.length = len(buf)
            struct.pack_into('!H', buf, 2, self.length)
        return str(buf)


class chunk_heartbeat_base(chunk):

    __metaclass__ = abc.ABCMeta

    def __init__(self, flags=0, length=0, info=None):
        super(chunk_heartbeat_base, self).__init__(
            self.chunk_type(), length)
        self.flags = flags
        if info is not None:
            assert isinstance(info, param)
        self.info = info

    @classmethod
    def parser_base(cls, buf, recog):
        (_, flags, length) = struct.unpack_from(cls._PACK_STR, buf)
        (ptype, ) = struct.unpack_from('!H', buf, cls._MIN_LEN)
        cls_ = recog.get(ptype)
        info = cls_.parser(buf[cls._MIN_LEN:])
        msg = cls(flags, length, info)
        return msg

    def serialize(self):
        buf = bytearray(struct.pack(
            self._PACK_STR, self.chunk_type(), self.flags,
            self.length))
        if self.info is not None:
            buf.extend(self.info.serialize())
        if 0 == self.length:
            self.length = len(buf)
            struct.pack_into('!H', buf, 2, self.length)
        return str(buf)


class chunk_ack_base(chunk):

    __metaclass__ = abc.ABCMeta

    def __init__(self, flags=0, length=0):
        super(chunk_ack_base, self).__init__(self.chunk_type(), length)
        self.flags = flags

    @classmethod
    def parser(cls, buf):
        (_, flags, length) = struct.unpack_from(cls._PACK_STR, buf)
        return cls(flags, length)

    def serialize(self):
        if 0 == self.length:
            self.length = self._MIN_LEN
        buf = struct.pack(
            self._PACK_STR, self.chunk_type(), self.flags,
            self.length)
        return buf


class chunk_ecn_base(chunk):

    __metaclass__ = abc.ABCMeta
    _PACK_STR = '!BBHI'
    _MIN_LEN = struct.calcsize(_PACK_STR)

    def __init__(self, flags=0, length=0, low_tsn=0):
        super(chunk_ecn_base, self).__init__(self.chunk_type(), length)
        self.flags = flags
        self.low_tsn = low_tsn

    @classmethod
    def parser(cls, buf):
        (_, flags, length, low_tsn) = struct.unpack_from(cls._PACK_STR, buf)
        return cls(flags, length, low_tsn)

    def serialize(self):
        if 0 == self.length:
            self.length = self._MIN_LEN
        buf = struct.pack(
            self._PACK_STR, self.chunk_type(), self.flags, self.length,
            self.low_tsn)
        return buf


@sctp.register_chunk_type
class chunk_data(chunk):
    """Stream Control Transmission Protocol (SCTP)
    sub encoder/decoder class for Payload Data (DATA) chunk (RFC 4960).

    This is used with ryu.lib.packet.sctp.sctp.

    An instance has the following attributes at least.
    Most of them are same to the on-wire counterparts but in host byte order.
    __init__ takes the corresponding args in this order.

    .. tabularcolumns:: |l|L|

    ============== =====================================================
    Attribute      Description
    ============== =====================================================
    unordered      if set to '1', the receiver ignores the sequence number.
    begin          if set to '1', this chunk is the first fragment.
    end            if set to '1', this chunk is the last fragment.
    length         length of this chunk containing this header.
                   (0 means automatically-calculate when encoding)
    tsn            Transmission Sequence Number.
    sid            stream id.
    seq            the sequence number.
    payload_id     application specified protocol id. '0' means that
                   no application id is identified.
    payload_data   user data.
    ============== =====================================================
    """

    _PACK_STR = '!BBHIHHI'
    _MIN_LEN = struct.calcsize(_PACK_STR)

    @classmethod
    def chunk_type(cls):
        return TYPE_DATA

    def __init__(self, unordered=0, begin=0, end=0, length=0, tsn=0,
                 sid=0, seq=0, payload_id=0, payload_data=None):
        assert (1 == unordered | 1)
        assert (1 == begin | 1)
        assert (1 == end | 1)
        assert (payload_data is not None)
        super(chunk_data, self).__init__(self.chunk_type(), length)
        self.unordered = unordered
        self.begin = begin
        self.end = end
        self.tsn = tsn
        self.sid = sid
        self.seq = seq
        self.payload_id = payload_id
        self.payload_data = payload_data

    @classmethod
    def parser(cls, buf):
        (_, flags, length, tsn, sid, seq, payload_id
         ) = struct.unpack_from(cls._PACK_STR, buf)
        unordered = (flags >> 2) & 1
        begin = (flags >> 1) & 1
        end = (flags >> 0) & 1
        fmt = '!%ds' % (length - cls._MIN_LEN)
        (payload_data, ) = struct.unpack_from(fmt, buf, cls._MIN_LEN)
        return cls(unordered, begin, end, length, tsn, sid, seq,
                   payload_id, payload_data)

    def serialize(self):
        flags = (
            (self.unordered << 2) |
            (self.begin << 1) |
            (self.end << 0))
        buf = bytearray(struct.pack(
            self._PACK_STR, self.chunk_type(), flags, self.length,
            self.tsn, self.sid, self.seq, self.payload_id))
        buf.extend(self.payload_data)
        if 0 == self.length:
            self.length = len(buf)
            struct.pack_into('!H', buf, 2, self.length)
        return str(buf)


@sctp.register_chunk_type
class chunk_init(chunk_init_base):
    """Stream Control Transmission Protocol (SCTP)
    sub encoder/decoder class for Initiation (INIT) chunk (RFC 4960).

    This is used with ryu.lib.packet.sctp.sctp.

    An instance has the following attributes at least.
    Most of them are same to the on-wire counterparts but in host byte order.
    __init__ takes the corresponding args in this order.

    .. tabularcolumns:: |l|L|

    ============== =====================================================
    Attribute      Description
    ============== =====================================================
    flags          set to '0'. this field will be ignored.
    length         length of this chunk containing this header.
                   (0 means automatically-calculate when encoding)
    init_tag       the tag that be used as Verification Tag.
    a_rwnd         Advertised Receiver Window Credit.
    os             number of outbound streams.
    mis            number of inbound streams.
    i_tsn          Transmission Sequence Number that the sender will use.
    params         Optional/Variable-Length Parameters.

                   a list of derived classes of ryu.lib.packet.sctp.param.
    ============== =====================================================
    """

    _RECOGNIZED_PARAMS = {}

    @staticmethod
    def register_param_type(*args):
        def _register_param_type(cls):
            chunk_init._RECOGNIZED_PARAMS[cls.param_type()] = cls
            return cls
        return _register_param_type(args[0])

    @classmethod
    def chunk_type(cls):
        return TYPE_INIT

    @classmethod
    def parser(cls, buf):
        return super(chunk_init, cls).parser_base(
            buf, cls._RECOGNIZED_PARAMS)


@sctp.register_chunk_type
class chunk_init_ack(chunk_init_base):
    """Stream Control Transmission Protocol (SCTP)
    sub encoder/decoder class for Initiation Acknowledgement (INIT ACK)
    chunk (RFC 4960).

    This is used with ryu.lib.packet.sctp.sctp.

    An instance has the following attributes at least.
    Most of them are same to the on-wire counterparts but in host byte order.
    __init__ takes the corresponding args in this order.

    .. tabularcolumns:: |l|L|

    ============== =====================================================
    Attribute      Description
    ============== =====================================================
    flags          set to '0'. this field will be ignored.
    length         length of this chunk containing this header.
                   (0 means automatically-calculate when encoding)
    init_tag       the tag that be used as Verification Tag.
    a_rwnd         Advertised Receiver Window Credit.
    os             number of outbound streams.
    mis            number of inbound streams.
    i_tsn          Transmission Sequence Number that the sender will use.
    params         Optional/Variable-Length Parameters.

                   a list of derived classes of ryu.lib.packet.sctp.param.
    ============== =====================================================
    """

    _RECOGNIZED_PARAMS = {}

    @staticmethod
    def register_param_type(*args):
        def _register_param_type(cls):
            chunk_init_ack._RECOGNIZED_PARAMS[cls.param_type()] = cls
            return cls
        return _register_param_type(args[0])

    @classmethod
    def chunk_type(cls):
        return TYPE_INIT_ACK

    @classmethod
    def parser(cls, buf):
        return super(chunk_init_ack, cls).parser_base(
            buf, cls._RECOGNIZED_PARAMS)


@sctp.register_chunk_type
class chunk_sack(chunk):
    """Stream Control Transmission Protocol (SCTP)
    sub encoder/decoder class for Selective Acknowledgement (SACK) chunk
    (RFC 4960).

    This is used with ryu.lib.packet.sctp.sctp.

    An instance has the following attributes at least.
    Most of them are same to the on-wire counterparts but in host byte order.
    __init__ takes the corresponding args in this order.

    .. tabularcolumns:: |l|L|

    ============== =====================================================
    Attribute      Description
    ============== =====================================================
    flags          set to '0'. this field will be ignored.
    length         length of this chunk containing this header.
                   (0 means automatically-calculate when encoding)
    tsn_ack        TSN of the last DATA chunk received in sequence
                   before a gap.
    a_rwnd         Advertised Receiver Window Credit.
    gapack_num     number of Gap Ack blocks.
    duptsn_num     number of duplicate TSNs.
    gapacks        a list of Gap Ack blocks. one block is made of a list
                   with the start offset and the end offset from tsn_ack.
                   e.g.) gapacks = [[2, 3], [10, 12], [19, 21]]
    duptsns        a list of duplicate TSN.
    ============== =====================================================
    """

    _PACK_STR = '!BBHIIHH'
    _MIN_LEN = struct.calcsize(_PACK_STR)
    _GAPACK_STR = '!HH'
    _GAPACK_LEN = struct.calcsize(_GAPACK_STR)
    _DUPTSN_STR = '!I'
    _DUPTSN_LEN = struct.calcsize(_DUPTSN_STR)

    @classmethod
    def chunk_type(cls):
        return TYPE_SACK

    def __init__(self, flags=0, length=0, tsn_ack=0, a_rwnd=0,
                 gapack_num=0, duptsn_num=0, gapacks=None, duptsns=None):
        super(chunk_sack, self).__init__(self.chunk_type(), length)
        self.flags = flags
        self.tsn_ack = tsn_ack
        self.a_rwnd = a_rwnd
        self.gapack_num = gapack_num
        self.duptsn_num = duptsn_num
        gapacks = gapacks or []
        assert isinstance(gapacks, list)
        for one in gapacks:
            assert isinstance(one, list)
            assert 2 == len(one)
        self.gapacks = gapacks
        duptsns = duptsns or []
        assert isinstance(duptsns, list)
        self.duptsns = duptsns

    @classmethod
    def parser(cls, buf):
        (_, flags, length, tsn_ack, a_rwnd, gapack_num, duptsn_num
         ) = struct.unpack_from(cls._PACK_STR, buf)
        gapacks = []
        offset = cls._MIN_LEN
        for _ in range(gapack_num):
            (gapack_start, gapack_end) = struct.unpack_from(
                cls._GAPACK_STR, buf, offset)
            gapacks.append([gapack_start, gapack_end])
            offset += cls._GAPACK_LEN
        duptsns = []
        for _ in range(duptsn_num):
            (duptsn, ) = struct.unpack_from(cls._DUPTSN_STR, buf, offset)
            duptsns.append(duptsn)
            offset += cls._DUPTSN_LEN
        return cls(flags, length, tsn_ack, a_rwnd, gapack_num, duptsn_num,
                   gapacks, duptsns)

    def serialize(self):
        buf = bytearray(struct.pack(
            self._PACK_STR, self.chunk_type(), self.flags,
            self.length, self.tsn_ack, self.a_rwnd, self.gapack_num,
            self.duptsn_num))
        for one in self.gapacks:
            buf.extend(struct.pack(chunk_sack._GAPACK_STR, one[0], one[1]))
        for one in self.duptsns:
            buf.extend(struct.pack(chunk_sack._DUPTSN_STR, one))
        if 0 == self.length:
            self.length = len(buf)
            struct.pack_into('!H', buf, 2, self.length)
        return str(buf)


@sctp.register_chunk_type
class chunk_heartbeat(chunk_heartbeat_base):
    """Stream Control Transmission Protocol (SCTP)
    sub encoder/decoder class for Heartbeat Request (HEARTBEAT) chunk
    (RFC 4960).

    This is used with ryu.lib.packet.sctp.sctp.

    An instance has the following attributes at least.
    Most of them are same to the on-wire counterparts but in host byte order.
    __init__ takes the corresponding args in this order.

    .. tabularcolumns:: |l|L|

    ============== =====================================================
    Attribute      Description
    ============== =====================================================
    flags          set to '0'. this field will be ignored.
    length         length of this chunk containing this header.
                   (0 means automatically-calculate when encoding)
    info           ryu.lib.packet.sctp.param_heartbeat.
    ============== =====================================================
    """

    _RECOGNIZED_PARAMS = {}

    @staticmethod
    def register_param_type(*args):
        def _register_param_type(cls):
            chunk_heartbeat._RECOGNIZED_PARAMS[cls.param_type()] = cls
            return cls
        return _register_param_type(args[0])

    @classmethod
    def chunk_type(cls):
        return TYPE_HEARTBEAT

    @classmethod
    def parser(cls, buf):
        return super(chunk_heartbeat, cls).parser_base(
            buf, cls._RECOGNIZED_PARAMS)


@sctp.register_chunk_type
class chunk_heartbeat_ack(chunk_heartbeat_base):
    """Stream Control Transmission Protocol (SCTP)
    sub encoder/decoder class for Heartbeat Acknowledgement
    (HEARTBEAT ACK) chunk (RFC 4960).

    This is used with ryu.lib.packet.sctp.sctp.

    An instance has the following attributes at least.
    Most of them are same to the on-wire counterparts but in host byte order.
    __init__ takes the corresponding args in this order.

    .. tabularcolumns:: |l|L|

    ============== =====================================================
    Attribute      Description
    ============== =====================================================
    flags          set to '0'. this field will be ignored.
    length         length of this chunk containing this header.
                   (0 means automatically-calculate when encoding)
    info           ryu.lib.packet.sctp.param_heartbeat.
    ============== =====================================================
    """

    _RECOGNIZED_PARAMS = {}

    @staticmethod
    def register_param_type(*args):
        def _register_param_type(cls):
            chunk_heartbeat_ack._RECOGNIZED_PARAMS[cls.param_type()] = cls
            return cls
        return _register_param_type(args[0])

    @classmethod
    def chunk_type(cls):
        return TYPE_HEARTBEAT_ACK

    @classmethod
    def parser(cls, buf):
        return super(chunk_heartbeat_ack, cls).parser_base(
            buf, cls._RECOGNIZED_PARAMS)


@sctp.register_chunk_type
class chunk_abort(chunk):
    """Stream Control Transmission Protocol (SCTP)
    sub encoder/decoder class for Abort Association (ABORT) chunk (RFC 4960).

    This is used with ryu.lib.packet.sctp.sctp.

    An instance has the following attributes at least.
    Most of them are same to the on-wire counterparts but in host byte order.
    __init__ takes the corresponding args in this order.

    .. tabularcolumns:: |l|L|

    ============== =====================================================
    Attribute      Description
    ============== =====================================================
    tflag          '0' means the Verification tag is normal. '1' means
                   the Verification tag is copy of the sender.
    length         length of this chunk containing this header.
                   (0 means automatically-calculate when encoding)
    causes         a list of derived classes of ryu.lib.packet.sctp.causes.
    ============== =====================================================
    """

    _class_prefixes = ['cause_']
    _RECOGNIZED_CAUSES = {}

    @staticmethod
    def register_cause_code(*args):
        def _register_cause_code(cls):
            chunk_abort._RECOGNIZED_CAUSES[cls.cause_code()] = cls
            return cls
        return _register_cause_code(args[0])

    @classmethod
    def chunk_type(cls):
        return TYPE_ABORT

    def __init__(self, tflag=0, length=0, causes=None):
        super(chunk_abort, self).__init__(self.chunk_type(), length)
        assert (1 == tflag | 1)
        self.tflag = tflag
        causes = causes or []
        assert isinstance(causes, list)
        for one in causes:
            assert isinstance(one, cause)
        self.causes = causes

    @classmethod
    def parser(cls, buf):
        (_, flags, length) = struct.unpack_from(cls._PACK_STR, buf)
        tflag = (flags >> 0) & 1
        causes = []
        offset = cls._MIN_LEN
        while offset < length:
            (ccode, ) = struct.unpack_from('!H', buf, offset)
            cls_ = cls._RECOGNIZED_CAUSES.get(ccode)
            if not cls_:
                break
            ins = cls_.parser(buf[offset:])
            causes.append(ins)
            offset += len(ins)
        return cls(tflag, length, causes)

    def serialize(self):
        flags = (self.tflag << 0)
        buf = bytearray(struct.pack(
            self._PACK_STR, self.chunk_type(), flags, self.length))
        for one in self.causes:
            buf.extend(one.serialize())
        if 0 == self.length:
            self.length = len(buf)
            struct.pack_into('!H', buf, 2, self.length)
        return str(buf)


@sctp.register_chunk_type
class chunk_shutdown(chunk):
    """Stream Control Transmission Protocol (SCTP)
    sub encoder/decoder class for Shutdown Association (SHUTDOWN) chunk
    (RFC 4960).

    This is used with ryu.lib.packet.sctp.sctp.

    An instance has the following attributes at least.
    Most of them are same to the on-wire counterparts but in host byte order.
    __init__ takes the corresponding args in this order.

    .. tabularcolumns:: |l|L|

    ============== =====================================================
    Attribute      Description
    ============== =====================================================
    flags          set to '0'. this field will be ignored.
    length         length of this chunk containing this header.
                   (0 means automatically-calculate when encoding)
    tsn_ack        TSN of the last DATA chunk received in sequence
                   before a gap.
    ============== =====================================================
    """

    _PACK_STR = '!BBHI'
    _MIN_LEN = struct.calcsize(_PACK_STR)

    @classmethod
    def chunk_type(cls):
        return TYPE_SHUTDOWN

    def __init__(self, flags=0, length=0, tsn_ack=0):
        super(chunk_shutdown, self).__init__(self.chunk_type(), length)
        self.flags = flags
        self.tsn_ack = tsn_ack

    @classmethod
    def parser(cls, buf):
        (_, flags, length, tsn_ack
         ) = struct.unpack_from(cls._PACK_STR, buf)
        msg = cls(flags, length, tsn_ack)
        return msg

    def serialize(self):
        if 0 == self.length:
            self.length = self._MIN_LEN
        buf = struct.pack(
            self._PACK_STR, self.chunk_type(), self.flags,
            self.length, self.tsn_ack)
        return buf


@sctp.register_chunk_type
class chunk_shutdown_ack(chunk_ack_base):
    """Stream Control Transmission Protocol (SCTP)
    sub encoder/decoder class for Shutdown Acknowledgement (SHUTDOWN ACK)
    chunk (RFC 4960).

    This is used with ryu.lib.packet.sctp.sctp.

    An instance has the following attributes at least.
    Most of them are same to the on-wire counterparts but in host byte order.
    __init__ takes the corresponding args in this order.

    .. tabularcolumns:: |l|L|

    ============== =====================================================
    Attribute      Description
    ============== =====================================================
    flags          set to '0'. this field will be ignored.
    length         length of this chunk containing this header.
                   (0 means automatically-calculate when encoding)
    ============== =====================================================
    """

    @classmethod
    def chunk_type(cls):
        return TYPE_SHUTDOWN_ACK


@sctp.register_chunk_type
class chunk_error(chunk):
    """Stream Control Transmission Protocol (SCTP)
    sub encoder/decoder class for Operation Error (ERROR) chunk (RFC 4960).

    This is used with ryu.lib.packet.sctp.sctp.

    An instance has the following attributes at least.
    Most of them are same to the on-wire counterparts but in host byte order.
    __init__ takes the corresponding args in this order.

    .. tabularcolumns:: |l|L|

    ============== =====================================================
    Attribute      Description
    ============== =====================================================
    flags          set to '0'. this field will be ignored.
    length         length of this chunk containing this header.
                   (0 means automatically-calculate when encoding)
    causes         a list of derived classes of ryu.lib.packet.sctp.causes.
    ============== =====================================================
    """

    _class_prefixes = ['cause_']
    _RECOGNIZED_CAUSES = {}

    @staticmethod
    def register_cause_code(*args):
        def _register_cause_code(cls):
            chunk_error._RECOGNIZED_CAUSES[cls.cause_code()] = cls
            return cls
        return _register_cause_code(args[0])

    @classmethod
    def chunk_type(cls):
        return TYPE_ERROR

    def __init__(self, flags=0, length=0, causes=None):
        super(chunk_error, self).__init__(self.chunk_type(), length)
        self.flags = flags
        causes = causes or []
        assert isinstance(causes, list)
        for one in causes:
            assert isinstance(one, cause)
        self.causes = causes

    @classmethod
    def parser(cls, buf):
        (_, flags, length) = struct.unpack_from(cls._PACK_STR, buf)
        causes = []
        offset = cls._MIN_LEN
        while offset < length:
            (ccode, ) = struct.unpack_from('!H', buf, offset)
            cls_ = cls._RECOGNIZED_CAUSES.get(ccode)
            if not cls_:
                break
            ins = cls_.parser(buf[offset:])
            causes.append(ins)
            offset += len(ins)
        return cls(flags, length, causes)

    def serialize(self):
        buf = bytearray(struct.pack(
            self._PACK_STR, self.chunk_type(), self.flags, self.length))
        for one in self.causes:
            buf.extend(one.serialize())
        if 0 == self.length:
            self.length = len(buf)
            struct.pack_into('!H', buf, 2, self.length)
        return str(buf)


@sctp.register_chunk_type
class chunk_cookie_echo(chunk):
    """Stream Control Transmission Protocol (SCTP)
    sub encoder/decoder class for Cookie Echo (COOKIE ECHO) chunk (RFC 4960).

    This is used with ryu.lib.packet.sctp.sctp.

    An instance has the following attributes at least.
    Most of them are same to the on-wire counterparts but in host byte order.
    __init__ takes the corresponding args in this order.

    .. tabularcolumns:: |l|L|

    ============== =====================================================
    Attribute      Description
    ============== =====================================================
    flags          set to '0'. this field will be ignored.
    length         length of this chunk containing this header.
                   (0 means automatically-calculate when encoding)
    cookie         cookie data.
    ============== =====================================================
    """

    _PACK_STR = '!BBH'
    _MIN_LEN = struct.calcsize(_PACK_STR)

    @classmethod
    def chunk_type(cls):
        return TYPE_COOKIE_ECHO

    def __init__(self, flags=0, length=0, cookie=None):
        super(chunk_cookie_echo, self).__init__(self.chunk_type(), length)
        self.flags = flags
        self.cookie = cookie

    @classmethod
    def parser(cls, buf):
        (_, flags, length) = struct.unpack_from(cls._PACK_STR, buf)
        _len = length - cls._MIN_LEN
        cookie = None
        if _len:
            fmt = '%ds' % _len
            (cookie, ) = struct.unpack_from(fmt, buf, cls._MIN_LEN)
        return cls(flags, length, cookie)

    def serialize(self):
        buf = bytearray(struct.pack(
            self._PACK_STR, self.chunk_type(), self.flags,
            self.length))
        if self.cookie is not None:
            buf.extend(self.cookie)
        if 0 == self.length:
            self.length = len(buf)
            struct.pack_into('!H', buf, 2, self.length)
        mod = len(buf) % 4
        if mod:
            buf.extend(bytearray(4 - mod))
        return str(buf)


@sctp.register_chunk_type
class chunk_cookie_ack(chunk_ack_base):
    """Stream Control Transmission Protocol (SCTP)
    sub encoder/decoder class for Cookie Acknowledgement (COOKIE ACK)
    chunk (RFC 4960).

    This is used with ryu.lib.packet.sctp.sctp.

    An instance has the following attributes at least.
    Most of them are same to the on-wire counterparts but in host byte order.
    __init__ takes the corresponding args in this order.

    .. tabularcolumns:: |l|L|

    ============== =====================================================
    Attribute      Description
    ============== =====================================================
    flags          set to '0'. this field will be ignored.
    length         length of this chunk containing this header.
                   (0 means automatically-calculate when encoding)
    ============== =====================================================
    """

    @classmethod
    def chunk_type(cls):
        return TYPE_COOKIE_ACK


@sctp.register_chunk_type
class chunk_ecn_echo(chunk_ecn_base):
    """Stream Control Transmission Protocol (SCTP)
    sub encoder/decoder class for ECN-Echo chunk (RFC 4960 Appendix A.).

    This is used with ryu.lib.packet.sctp.sctp.

    An instance has the following attributes at least.
    Most of them are same to the on-wire counterparts but in host byte order.
    __init__ takes the corresponding args in this order.

    .. tabularcolumns:: |l|L|

    ============== =====================================================
    Attribute      Description
    ============== =====================================================
    flags          set to '0'. this field will be ignored.
    length         length of this chunk containing this header.
                   (0 means automatically-calculate when encoding)
    low_tsn        the lowest TSN.
    ============== =====================================================
    """

    @classmethod
    def chunk_type(cls):
        return TYPE_ECN_ECHO


@sctp.register_chunk_type
class chunk_cwr(chunk_ecn_base):
    """Stream Control Transmission Protocol (SCTP)
    sub encoder/decoder class for CWR chunk (RFC 4960 Appendix A.).

    This is used with ryu.lib.packet.sctp.sctp.

    An instance has the following attributes at least.
    Most of them are same to the on-wire counterparts but in host byte order.
    __init__ takes the corresponding args in this order.

    .. tabularcolumns:: |l|L|

    ============== =====================================================
    Attribute      Description
    ============== =====================================================
    flags          set to '0'. this field will be ignored.
    length         length of this chunk containing this header.
                   (0 means automatically-calculate when encoding)
    low_tsn        the lowest TSN.
    ============== =====================================================
    """

    @classmethod
    def chunk_type(cls):
        return TYPE_CWR


@sctp.register_chunk_type
class chunk_shutdown_complete(chunk):
    """Stream Control Transmission Protocol (SCTP)
    sub encoder/decoder class for Shutdown Complete (SHUTDOWN COMPLETE)
    chunk (RFC 4960).

    This is used with ryu.lib.packet.sctp.sctp.

    An instance has the following attributes at least.
    Most of them are same to the on-wire counterparts but in host byte order.
    __init__ takes the corresponding args in this order.

    .. tabularcolumns:: |l|L|

    ============== =====================================================
    Attribute      Description
    ============== =====================================================
    tflag          '0' means the Verification tag is normal. '1' means
                   the Verification tag is copy of the sender.
    length         length of this chunk containing this header.
                   (0 means automatically-calculate when encoding)
    ============== =====================================================
    """

    _PACK_STR = '!BBH'
    _MIN_LEN = struct.calcsize(_PACK_STR)

    @classmethod
    def chunk_type(cls):
        return TYPE_SHUTDOWN_COMPLETE

    def __init__(self, tflag=0, length=0):
        assert (1 == tflag | 1)
        super(chunk_shutdown_complete, self).__init__(
            self.chunk_type(), length)
        self.tflag = tflag

    @classmethod
    def parser(cls, buf):
        (_, flags, length) = struct.unpack_from(cls._PACK_STR, buf)
        tflag = flags & 1
        msg = cls(tflag, length)
        return msg

    def serialize(self):
        if 0 == self.length:
            self.length = self._MIN_LEN
        buf = struct.pack(
            self._PACK_STR, self.chunk_type(),
            self.tflag, self.length)
        return buf


#=======================================================================
#
# Cause Code
#
#=======================================================================
class cause(stringify.StringifyMixin):

    __metaclass__ = abc.ABCMeta
    _PACK_STR = '!HH'
    _MIN_LEN = struct.calcsize(_PACK_STR)

    @classmethod
    @abc.abstractmethod
    def cause_code(cls):
        pass

    def __init__(self, length=0):
        self.length = length

    @classmethod
    @abc.abstractmethod
    def parser(cls, buf):
        pass

    def serialize(self):
        if 0 == self.length:
            self.length = self._MIN_LEN
        buf = struct.pack(
            self._PACK_STR, self.cause_code(), self.length)
        return buf

    def __len__(self):
        length = self.length
        mod = length % 4
        if mod:
            length += 4 - mod
        return length


class cause_with_value(cause):

    __metaclass__ = abc.ABCMeta

    def __init__(self, value=None, length=0):
        super(cause_with_value, self).__init__(length)
        self.value = value

    @classmethod
    def parser(cls, buf):
        (_, length) = struct.unpack_from(cls._PACK_STR, buf)
        value = None
        if (cls._MIN_LEN < length):
            fmt = '%ds' % (length - cls._MIN_LEN)
            (value, ) = struct.unpack_from(fmt, buf, cls._MIN_LEN)
        return cls(value, length)

    def serialize(self):
        buf = bytearray(struct.pack(
            self._PACK_STR, self.cause_code(), self.length))
        if self.value is not None:
            buf.extend(self.value)
        if 0 == self.length:
            self.length = len(buf)
            struct.pack_into('!H', buf, 2, self.length)
        mod = len(buf) % 4
        if mod:
            buf.extend(bytearray(4 - mod))
        return str(buf)


@chunk_abort.register_cause_code
@chunk_error.register_cause_code
class cause_invalid_stream_id(cause_with_value):
    """Stream Control Transmission Protocol (SCTP)
    sub encoder/decoder class for Invalid Stream Identifier (RFC 4960).

    This is used with ryu.lib.packet.sctp.chunk_abort and
                      ryu.lib.packet.sctp.chunk_error.

    An instance has the following attributes at least.
    Most of them are same to the on-wire counterparts but in host byte order.
    __init__ takes the corresponding args in this order.

    .. tabularcolumns:: |l|L|

    ============== =====================================================
    Attribute      Description
    ============== =====================================================
    value          stream id.
    length         length of this cause containing this header.
                   (0 means automatically-calculate when encoding)
    ============== =====================================================
    """

    _PACK_STR = '!HHH2x'
    _MIN_LEN = struct.calcsize(_PACK_STR)

    @classmethod
    def cause_code(cls):
        return CCODE_INVALID_STREAM_ID

    def __init__(self, value=0, length=0):
        super(cause_invalid_stream_id, self).__init__(value, length)

    @classmethod
    def parser(cls, buf):
        (_, length, value) = struct.unpack_from(cls._PACK_STR, buf)
        return cls(value, length)

    def serialize(self):
        if 0 == self.length:
            self.length = self._MIN_LEN
        buf = struct.pack(
            self._PACK_STR, self.cause_code(), self.length, self.value)
        return buf


@chunk_abort.register_cause_code
@chunk_error.register_cause_code
class cause_missing_param(cause):
    """Stream Control Transmission Protocol (SCTP)
    sub encoder/decoder class for Missing Mandatory Parameter (RFC 4960).

    This is used with ryu.lib.packet.sctp.chunk_abort and
                      ryu.lib.packet.sctp.chunk_error.

    An instance has the following attributes at least.
    Most of them are same to the on-wire counterparts but in host byte order.
    __init__ takes the corresponding args in this order.

    .. tabularcolumns:: |l|L|

    ============== =====================================================
    Attribute      Description
    ============== =====================================================
    types          a list of missing params.
    num            Number of missing params.
                   (0 means automatically-calculate when encoding)
    length         length of this cause containing this header.
                   (0 means automatically-calculate when encoding)
    ============== =====================================================
    """

    _PACK_STR = '!HHI'
    _MIN_LEN = struct.calcsize(_PACK_STR)

    @classmethod
    def cause_code(cls):
        return CCODE_MISSING_PARAM

    def __init__(self, types=None, num=0, length=0):
        super(cause_missing_param, self).__init__(length)
        types = types or []
        assert isinstance(types, list)
        for one in types:
            assert isinstance(one, int)
        self.types = types
        self.num = num

    @classmethod
    def parser(cls, buf):
        (_, length, num) = struct.unpack_from(cls._PACK_STR, buf)
        types = []
        offset = cls._MIN_LEN
        for count in range(num):
            offset = cls._MIN_LEN + (struct.calcsize('!H') * count)
            (one, ) = struct.unpack_from('!H', buf, offset)
            types.append(one)
        return cls(types, num, length)

    def serialize(self):
        buf = bytearray(struct.pack(
            self._PACK_STR, self.cause_code(), self.length, self.num))
        for one in self.types:
            buf.extend(struct.pack('!H', one))
        if 0 == self.num:
            self.num = len(self.types)
            struct.pack_into('!I', buf, 4, self.num)
        if 0 == self.length:
            self.length = len(buf)
            struct.pack_into('!H', buf, 2, self.length)
        mod = len(buf) % 4
        if mod:
            buf.extend(bytearray(4 - mod))
        return str(buf)


@chunk_abort.register_cause_code
@chunk_error.register_cause_code
class cause_stale_cookie(cause_with_value):
    """Stream Control Transmission Protocol (SCTP)
    sub encoder/decoder class for Stale Cookie Error (RFC 4960).

    This is used with ryu.lib.packet.sctp.chunk_abort and
                      ryu.lib.packet.sctp.chunk_error.

    An instance has the following attributes at least.
    Most of them are same to the on-wire counterparts but in host byte order.
    __init__ takes the corresponding args in this order.

    .. tabularcolumns:: |l|L|

    ============== =====================================================
    Attribute      Description
    ============== =====================================================
    value          Measure of Staleness.
    length         length of this cause containing this header.
                   (0 means automatically-calculate when encoding)
    ============== =====================================================
    """

    @classmethod
    def cause_code(cls):
        return CCODE_STALE_COOKIE


@chunk_abort.register_cause_code
@chunk_error.register_cause_code
class cause_out_of_resource(cause):
    """Stream Control Transmission Protocol (SCTP)
    sub encoder/decoder class for Out of Resource (RFC 4960).

    This is used with ryu.lib.packet.sctp.chunk_abort and
                      ryu.lib.packet.sctp.chunk_error.

    An instance has the following attributes at least.
    Most of them are same to the on-wire counterparts but in host byte order.
    __init__ takes the corresponding args in this order.

    .. tabularcolumns:: |l|L|

    ============== =====================================================
    Attribute      Description
    ============== =====================================================
    length         length of this cause containing this header.
                   (0 means automatically-calculate when encoding)
    ============== =====================================================
    """

    @classmethod
    def cause_code(cls):
        return CCODE_OUT_OF_RESOURCE

    @classmethod
    def parser(cls, buf):
        (_, length) = struct.unpack_from(cls._PACK_STR, buf)
        return cls(length)


@chunk_abort.register_cause_code
@chunk_error.register_cause_code
class cause_unresolvable_addr(cause_with_value):
    """Stream Control Transmission Protocol (SCTP)
    sub encoder/decoder class for Unresolvable Address (RFC 4960).

    This is used with ryu.lib.packet.sctp.chunk_abort and
                      ryu.lib.packet.sctp.chunk_error.

    An instance has the following attributes at least.
    Most of them are same to the on-wire counterparts but in host byte order.
    __init__ takes the corresponding args in this order.

    .. tabularcolumns:: |l|L|

    ============== =====================================================
    Attribute      Description
    ============== =====================================================
    value          Unresolvable Address. one of follows:

                   ryu.lib.packet.sctp.param_host_addr,

                   ryu.lib.packet.sctp.param_ipv4, or

                   ryu.lib.packet.sctp.param_ipv6.
    length         length of this cause containing this header.
                   (0 means automatically-calculate when encoding)
    ============== =====================================================
    """

    _RECOGNIZED_PARAMS = {}

    @staticmethod
    def register_param_type(*args):
        def _register_param_type(cls):
            cause_unresolvable_addr._RECOGNIZED_PARAMS[cls.param_type()] = cls
            return cls
        return _register_param_type(args[0])

    @classmethod
    def cause_code(cls):
        return CCODE_UNRESOLVABLE_ADDR

    @classmethod
    def parser(cls, buf):
        (_, length) = struct.unpack_from(cls._PACK_STR, buf)
        (ptype, ) = struct.unpack_from('!H', buf, cls._MIN_LEN)
        cls_ = cls._RECOGNIZED_PARAMS.get(ptype)
        value = cls_.parser(buf[cls._MIN_LEN:])
        return cls(value, length)

    def serialize(self):
        buf = bytearray(struct.pack(
            self._PACK_STR, self.cause_code(), self.length))
        buf.extend(self.value.serialize())
        if 0 == self.length:
            self.length = len(buf)
            struct.pack_into('!H', buf, 2, self.length)
        mod = len(buf) % 4
        if mod:
            buf.extend(bytearray(4 - mod))
        return str(buf)


@chunk_abort.register_cause_code
@chunk_error.register_cause_code
class cause_unrecognized_chunk(cause_with_value):
    """Stream Control Transmission Protocol (SCTP)
    sub encoder/decoder class for Unrecognized Chunk Type (RFC 4960).

    This is used with ryu.lib.packet.sctp.chunk_abort and
                      ryu.lib.packet.sctp.chunk_error.

    An instance has the following attributes at least.
    Most of them are same to the on-wire counterparts but in host byte order.
    __init__ takes the corresponding args in this order.

    .. tabularcolumns:: |l|L|

    ============== =====================================================
    Attribute      Description
    ============== =====================================================
    value          Unrecognized Chunk.
    length         length of this cause containing this header.
                   (0 means automatically-calculate when encoding)
    ============== =====================================================
    """

    @classmethod
    def cause_code(cls):
        return CCODE_UNRECOGNIZED_CHUNK


@chunk_abort.register_cause_code
@chunk_error.register_cause_code
class cause_invalid_param(cause):
    """Stream Control Transmission Protocol (SCTP)
    sub encoder/decoder class for Invalid Mandatory Parameter (RFC 4960).

    This is used with ryu.lib.packet.sctp.chunk_abort and
                      ryu.lib.packet.sctp.chunk_error.

    An instance has the following attributes at least.
    Most of them are same to the on-wire counterparts but in host byte order.
    __init__ takes the corresponding args in this order.

    .. tabularcolumns:: |l|L|

    ============== =====================================================
    Attribute      Description
    ============== =====================================================
    length         length of this cause containing this header.
                   (0 means automatically-calculate when encoding)
    ============== =====================================================
    """

    @classmethod
    def cause_code(cls):
        return CCODE_INVALID_PARAM

    @classmethod
    def parser(cls, buf):
        (_, length) = struct.unpack_from(cls._PACK_STR, buf)
        return cls(length)


@chunk_abort.register_cause_code
@chunk_error.register_cause_code
class cause_unrecognized_param(cause_with_value):
    """Stream Control Transmission Protocol (SCTP)
    sub encoder/decoder class for Unrecognized Parameters (RFC 4960).

    This is used with ryu.lib.packet.sctp.chunk_abort and
                      ryu.lib.packet.sctp.chunk_error.

    An instance has the following attributes at least.
    Most of them are same to the on-wire counterparts but in host byte order.
    __init__ takes the corresponding args in this order.

    .. tabularcolumns:: |l|L|

    ============== =====================================================
    Attribute      Description
    ============== =====================================================
    value          Unrecognized Parameter.
    length         length of this cause containing this header.
                   (0 means automatically-calculate when encoding)
    ============== =====================================================
    """

    @classmethod
    def cause_code(cls):
        return CCODE_UNRECOGNIZED_PARAM


@chunk_abort.register_cause_code
@chunk_error.register_cause_code
class cause_no_userdata(cause_with_value):
    """Stream Control Transmission Protocol (SCTP)
    sub encoder/decoder class for No User Data (RFC 4960).

    This is used with ryu.lib.packet.sctp.chunk_abort and
                      ryu.lib.packet.sctp.chunk_error.

    An instance has the following attributes at least.
    Most of them are same to the on-wire counterparts but in host byte order.
    __init__ takes the corresponding args in this order.

    .. tabularcolumns:: |l|L|

    ============== =====================================================
    Attribute      Description
    ============== =====================================================
    value          the TSN of the DATA chunk received with no user data
                   field.
    length         length of this cause containing this header.
                   (0 means automatically-calculate when encoding)
    ============== =====================================================
    """

    @classmethod
    def cause_code(cls):
        return CCODE_NO_USERDATA


@chunk_abort.register_cause_code
@chunk_error.register_cause_code
class cause_cookie_while_shutdown(cause):
    """Stream Control Transmission Protocol (SCTP)
    sub encoder/decoder class for Cookie Received While Shutting Down
    (RFC 4960).

    This is used with ryu.lib.packet.sctp.chunk_abort and
                      ryu.lib.packet.sctp.chunk_error.

    An instance has the following attributes at least.
    Most of them are same to the on-wire counterparts but in host byte order.
    __init__ takes the corresponding args in this order.

    .. tabularcolumns:: |l|L|

    ============== =====================================================
    Attribute      Description
    ============== =====================================================
    length         length of this cause containing this header.
                   (0 means automatically-calculate when encoding)
    ============== =====================================================
    """

    @classmethod
    def cause_code(cls):
        return CCODE_COOKIE_WHILE_SHUTDOWN

    @classmethod
    def parser(cls, buf):
        (_, length) = struct.unpack_from(cls._PACK_STR, buf)
        return cls(length)


@chunk_abort.register_cause_code
@chunk_error.register_cause_code
class cause_restart_with_new_addr(cause_with_value):
    """Stream Control Transmission Protocol (SCTP)
    sub encoder/decoder class for Restart of an Association with New
    Addresses (RFC 4960).

    This is used with ryu.lib.packet.sctp.chunk_abort and
                      ryu.lib.packet.sctp.chunk_error.

    An instance has the following attributes at least.
    Most of them are same to the on-wire counterparts but in host byte order.
    __init__ takes the corresponding args in this order.

    .. tabularcolumns:: |l|L|

    ============== =====================================================
    Attribute      Description
    ============== =====================================================
    value          New Address TLVs.
    length         length of this cause containing this header.
                   (0 means automatically-calculate when encoding)
    ============== =====================================================
    """

    _RECOGNIZED_PARAMS = {}

    @staticmethod
    def register_param_type(*args):
        def _register_param_type(cls):
            cause_restart_with_new_addr._RECOGNIZED_PARAMS[
                cls.param_type()] = cls
            return cls
        return _register_param_type(args[0])

    @classmethod
    def cause_code(cls):
        return CCODE_RESTART_WITH_NEW_ADDR

    def __init__(self, value=None, length=0):
        if not isinstance(value, list):
            value = [value]
        super(cause_restart_with_new_addr, self).__init__(value, length)

    @classmethod
    def parser(cls, buf):
        (_, length) = struct.unpack_from(cls._PACK_STR, buf)
        value = []
        offset = cls._MIN_LEN
        while offset < length:
            (ptype, ) = struct.unpack_from('!H', buf, offset)
            cls_ = cls._RECOGNIZED_PARAMS.get(ptype)
            if not cls_:
                break
            ins = cls_.parser(buf[offset:])
            value.append(ins)
            offset += len(ins)
        return cls(value, length)

    def serialize(self):
        buf = bytearray(struct.pack(
            self._PACK_STR, self.cause_code(), self.length))
        for one in self.value:
            buf.extend(one.serialize())
        if 0 == self.length:
            self.length = len(buf)
            struct.pack_into('!H', buf, 2, self.length)
        mod = len(buf) % 4
        if mod:
            buf.extend(bytearray(4 - mod))
        return str(buf)


@chunk_abort.register_cause_code
@chunk_error.register_cause_code
class cause_user_initiated_abort(cause_with_value):
    """Stream Control Transmission Protocol (SCTP)
    sub encoder/decoder class for User-Initiated Abort (RFC 4960).

    This is used with ryu.lib.packet.sctp.chunk_abort and
                      ryu.lib.packet.sctp.chunk_error.

    An instance has the following attributes at least.
    Most of them are same to the on-wire counterparts but in host byte order.
    __init__ takes the corresponding args in this order.

    .. tabularcolumns:: |l|L|

    ============== =====================================================
    Attribute      Description
    ============== =====================================================
    value          Upper Layer Abort Reason.
    length         length of this cause containing this header.
                   (0 means automatically-calculate when encoding)
    ============== =====================================================
    """

    @classmethod
    def cause_code(cls):
        return CCODE_USER_INITIATED_ABORT


@chunk_abort.register_cause_code
@chunk_error.register_cause_code
class cause_protocol_violation(cause_with_value):
    """Stream Control Transmission Protocol (SCTP)
    sub encoder/decoder class for Protocol Violation (RFC 4960).

    This is used with ryu.lib.packet.sctp.chunk_abort and
                      ryu.lib.packet.sctp.chunk_error.

    An instance has the following attributes at least.
    Most of them are same to the on-wire counterparts but in host byte order.
    __init__ takes the corresponding args in this order.

    .. tabularcolumns:: |l|L|

    ============== =====================================================
    Attribute      Description
    ============== =====================================================
    value          Additional Information.
    length         length of this cause containing this header.
                   (0 means automatically-calculate when encoding)
    ============== =====================================================
    """

    @classmethod
    def cause_code(cls):
        return CCODE_PROTOCOL_VIOLATION


#=======================================================================
#
# Chunk Parameter Types
#
#=======================================================================
class param(stringify.StringifyMixin):

    __metaclass__ = abc.ABCMeta
    _PACK_STR = '!HH'
    _MIN_LEN = struct.calcsize(_PACK_STR)

    @classmethod
    @abc.abstractmethod
    def param_type(cls):
        pass

    def __init__(self, value=None, length=0):
        self.length = length
        self.value = value

    @classmethod
    def parser(cls, buf):
        (_, length) = struct.unpack_from(cls._PACK_STR, buf)
        value = None
        if (cls._MIN_LEN < length):
            fmt = '%ds' % (length - cls._MIN_LEN)
            (value, ) = struct.unpack_from(fmt, buf, cls._MIN_LEN)
        return cls(value, length)

    def serialize(self):
        buf = bytearray(struct.pack(
            self._PACK_STR, self.param_type(), self.length))
        if self.value:
            buf.extend(self.value)
        if 0 == self.length:
            self.length = len(buf)
            struct.pack_into('!H', buf, 2, self.length)
        mod = len(buf) % 4
        if mod:
            buf.extend(bytearray(4 - mod))
        return str(buf)

    def __len__(self):
        length = self.length
        mod = length % 4
        if mod:
            length += 4 - mod
        return length


@chunk_heartbeat.register_param_type
@chunk_heartbeat_ack.register_param_type
class param_heartbeat(param):
    """Stream Control Transmission Protocol (SCTP)
    sub encoder/decoder class for Heartbeat Info Parameter (RFC 4960).

    This is used with ryu.lib.packet.sctp.chunk_heartbeat and
                      ryu.lib.packet.sctp.chunk_heartbeat_ack.

    An instance has the following attributes at least.
    Most of them are same to the on-wire counterparts but in host byte order.
    __init__ takes the corresponding args in this order.

    .. tabularcolumns:: |l|L|

    ============== =====================================================
    Attribute      Description
    ============== =====================================================
    value          the sender-specific heartbeat information.
    length         length of this param containing this header.
                   (0 means automatically-calculate when encoding)
    ============== =====================================================
    """

    @classmethod
    def param_type(cls):
        return PTYPE_HEARTBEAT


@chunk_init_ack.register_param_type
class param_state_cookie(param):
    """Stream Control Transmission Protocol (SCTP)
    sub encoder/decoder class for State Cookie Parameter (RFC 4960).

    This is used with ryu.lib.packet.sctp.chunk_init_ack.

    An instance has the following attributes at least.
    Most of them are same to the on-wire counterparts but in host byte order.
    __init__ takes the corresponding args in this order.

    .. tabularcolumns:: |l|L|

    ============== =====================================================
    Attribute      Description
    ============== =====================================================
    value          the state cookie. see Section 5.1.3 in RFC 4960.
    length         length of this param containing this header.
                   (0 means automatically-calculate when encoding)
    ============== =====================================================
    """

    @classmethod
    def param_type(cls):
        return PTYPE_STATE_COOKIE


@chunk_init_ack.register_param_type
class param_unrecognized_param(param):
    """Stream Control Transmission Protocol (SCTP)
    sub encoder/decoder class for Unrecognized Parameter (RFC 4960).

    This is used with ryu.lib.packet.sctp.chunk_init_ack.

    An instance has the following attributes at least.
    Most of them are same to the on-wire counterparts but in host byte order.
    __init__ takes the corresponding args in this order.

    .. tabularcolumns:: |l|L|

    ============== =====================================================
    Attribute      Description
    ============== =====================================================
    value          the unrecognized parameter in the INIT chunk.
    length         length of this param containing this header.
                   (0 means automatically-calculate when encoding)
    ============== =====================================================
    """

    @classmethod
    def param_type(cls):
        return PTYPE_UNRECOGNIZED_PARAM


@chunk_init.register_param_type
class param_cookie_preserve(param):
    """Stream Control Transmission Protocol (SCTP)
    sub encoder/decoder class for Cookie Preservative Parameter (RFC 4960).

    This is used with ryu.lib.packet.sctp.chunk_init.

    An instance has the following attributes at least.
    Most of them are same to the on-wire counterparts but in host byte order.
    __init__ takes the corresponding args in this order.

    .. tabularcolumns:: |l|L|

    ============== =====================================================
    Attribute      Description
    ============== =====================================================
    value          Suggested Cookie Life-Span Increment (msec).
    length         length of this param containing this header.
                   (0 means automatically-calculate when encoding)
    ============== =====================================================
    """

    _PACK_STR = '!HHI'
    _MIN_LEN = struct.calcsize(_PACK_STR)

    @classmethod
    def param_type(cls):
        return PTYPE_COOKIE_PRESERVE

    def __init__(self, value=0, length=0):
        super(param_cookie_preserve, self).__init__(value, length)

    @classmethod
    def parser(cls, buf):
        (_, length, value) = struct.unpack_from(cls._PACK_STR, buf)
        return cls(value, length)

    def serialize(self):
        if 0 == self.length:
            self.length = self._MIN_LEN
        buf = struct.pack(
            self._PACK_STR, self.param_type(), self.length, self.value)
        return buf


@chunk_init.register_param_type
@chunk_init_ack.register_param_type
class param_ecn(param):
    """Stream Control Transmission Protocol (SCTP)
    sub encoder/decoder class for ECN Parameter (RFC 4960 Appendix A.).

    This is used with ryu.lib.packet.sctp.chunk_init and
                      ryu.lib.packet.sctp.chunk_init_ack.

    An instance has the following attributes at least.
    Most of them are same to the on-wire counterparts but in host byte order.
    __init__ takes the corresponding args in this order.

    .. tabularcolumns:: |l|L|

    ============== =====================================================
    Attribute      Description
    ============== =====================================================
    value          set to None.
    length         length of this param containing this header.
                   (0 means automatically-calculate when encoding)
    ============== =====================================================
    """

    @classmethod
    def param_type(cls):
        return PTYPE_ECN

    def __init__(self, value=None, length=0):
        super(param_ecn, self).__init__(value, length)
        assert 4 == length or 0 == length
        assert None is value


@chunk_init.register_param_type
@chunk_init_ack.register_param_type
@cause_unresolvable_addr.register_param_type
@cause_restart_with_new_addr.register_param_type
class param_host_addr(param):
    """Stream Control Transmission Protocol (SCTP)
    sub encoder/decoder class for Host Name Address Parameter (RFC 4960).

    This is used with ryu.lib.packet.sctp.chunk_init and
                      ryu.lib.packet.sctp.chunk_init_ack.

    An instance has the following attributes at least.
    Most of them are same to the on-wire counterparts but in host byte order.
    __init__ takes the corresponding args in this order.

    .. tabularcolumns:: |l|L|

    ============== =====================================================
    Attribute      Description
    ============== =====================================================
    value          a host name that ends with null terminator.
    length         length of this param containing this header.
                   (0 means automatically-calculate when encoding)
    ============== =====================================================
    """

    @classmethod
    def param_type(cls):
        return PTYPE_HOST_ADDR


@chunk_init.register_param_type
class param_supported_addr(param):
    """Stream Control Transmission Protocol (SCTP)
    sub encoder/decoder class for Supported Address Types Parameter (RFC 4960).

    This is used with ryu.lib.packet.sctp.chunk_init.

    An instance has the following attributes at least.
    Most of them are same to the on-wire counterparts but in host byte order.
    __init__ takes the corresponding args in this order.

    .. tabularcolumns:: |l|L|

    ============== =====================================================
    Attribute      Description
    ============== =====================================================
    value          a list of parameter types. odd cases pad with 0x0000.
    length         length of this param containing this header.
                   (0 means automatically-calculate when encoding)
    ============== =====================================================
    """

    _VALUE_STR = '!H'
    _VALUE_LEN = struct.calcsize(_VALUE_STR)

    @classmethod
    def param_type(cls):
        return PTYPE_SUPPORTED_ADDR

    def __init__(self, value=None, length=0):
        if not isinstance(value, list):
            value = [value]
        for one in value:
            assert isinstance(one, int)
        super(param_supported_addr, self).__init__(value, length)

    @classmethod
    def parser(cls, buf):
        (_, length) = struct.unpack_from(cls._PACK_STR, buf)
        value = []
        offset = cls._MIN_LEN
        while offset < length:
            (one, ) = struct.unpack_from(cls._VALUE_STR, buf, offset)
            value.append(one)
            offset += cls._VALUE_LEN
        return cls(value, length)

    def serialize(self):
        buf = bytearray(struct.pack(
            self._PACK_STR, self.param_type(), self.length))
        for one in self.value:
            buf.extend(struct.pack(param_supported_addr._VALUE_STR, one))
        if 0 == self.length:
            self.length = len(buf)
            struct.pack_into('!H', buf, 2, self.length)
        mod = len(buf) % 4
        if mod:
            buf.extend(bytearray(4 - mod))
        return str(buf)


@chunk_init.register_param_type
@chunk_init_ack.register_param_type
@cause_unresolvable_addr.register_param_type
@cause_restart_with_new_addr.register_param_type
class param_ipv4(param):
    """Stream Control Transmission Protocol (SCTP)
    sub encoder/decoder class for IPv4 Address Parameter (RFC 4960).

    This is used with ryu.lib.packet.sctp.chunk_init and
                      ryu.lib.packet.sctp.chunk_init_ack.

    An instance has the following attributes at least.
    Most of them are same to the on-wire counterparts but in host byte order.
    __init__ takes the corresponding args in this order.

    .. tabularcolumns:: |l|L|

    ============== =====================================================
    Attribute      Description
    ============== =====================================================
    value          IPv4 address of the sending endpoint.
    length         length of this param containing this header.
                   (0 means automatically-calculate when encoding)
    ============== =====================================================
    """

    _TYPE = {'ascii': ['value']}

    @classmethod
    def param_type(cls):
        return PTYPE_IPV4

    def __init__(self, value='127.0.0.1', length=0):
        super(param_ipv4, self).__init__(value, length)

    @classmethod
    def parser(cls, buf):
        (_, length) = struct.unpack_from(cls._PACK_STR, buf)
        value = None
        if (cls._MIN_LEN < length):
            fmt = '%ds' % (length - cls._MIN_LEN)
            (value, ) = struct.unpack_from(fmt, buf, cls._MIN_LEN)
        return cls(addrconv.ipv4.bin_to_text(value), length)

    def serialize(self):
        buf = bytearray(struct.pack(
            self._PACK_STR, self.param_type(), self.length))
        if self.value:
            buf.extend(addrconv.ipv4.text_to_bin(self.value))
        if 0 == self.length:
            self.length = len(buf)
            struct.pack_into('!H', buf, 2, self.length)
        return str(buf)


@chunk_init.register_param_type
@chunk_init_ack.register_param_type
@cause_unresolvable_addr.register_param_type
@cause_restart_with_new_addr.register_param_type
class param_ipv6(param):
    """Stream Control Transmission Protocol (SCTP)
    sub encoder/decoder class for IPv6 Address Parameter (RFC 4960).

    This is used with ryu.lib.packet.sctp.chunk_init and
                      ryu.lib.packet.sctp.chunk_init_ack.

    An instance has the following attributes at least.
    Most of them are same to the on-wire counterparts but in host byte order.
    __init__ takes the corresponding args in this order.

    .. tabularcolumns:: |l|L|

    ============== =====================================================
    Attribute      Description
    ============== =====================================================
    value          IPv6 address of the sending endpoint.
    length         length of this param containing this header.
                   (0 means automatically-calculate when encoding)
    ============== =====================================================
    """

    _TYPE = {'ascii': ['value']}

    @classmethod
    def param_type(cls):
        return PTYPE_IPV6

    def __init__(self, value='::1', length=0):
        super(param_ipv6, self).__init__(value, length)

    @classmethod
    def parser(cls, buf):
        (_, length) = struct.unpack_from(cls._PACK_STR, buf)
        value = None
        if (cls._MIN_LEN < length):
            fmt = '%ds' % (length - cls._MIN_LEN)
            (value, ) = struct.unpack_from(fmt, buf, cls._MIN_LEN)
        return cls(addrconv.ipv6.bin_to_text(value), length)

    def serialize(self):
        buf = bytearray(struct.pack(
            self._PACK_STR, self.param_type(), self.length))
        if self.value:
            buf.extend(addrconv.ipv6.text_to_bin(self.value))
        if 0 == self.length:
            self.length = len(buf)
            struct.pack_into('!H', buf, 2, self.length)
        return str(buf)

########NEW FILE########
__FILENAME__ = slow
# Copyright (C) 2013 Nippon Telegraph and Telephone Corporation.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import struct
from . import packet_base
from ryu.lib import addrconv

# Slow Protocol Multicast destination
SLOW_PROTOCOL_MULTICAST = '01:80:c2:00:00:02'

# Slow Protocol SubType
SLOW_SUBTYPE_LACP = 0x01
SLOW_SUBTYPE_MARKER = 0x02
SLOW_SUBTYPE_OAM = 0x03
SLOW_SUBTYPE_OSSP = 0x0a


class slow(packet_base.PacketBase):
    """Slow Protocol header decoder class.
    This class has only the parser method.

    http://standards.ieee.org/getieee802/download/802.3-2012_section5.pdf

    Slow Protocols Subtypes

    +---------------+--------------------------------------------------+
    | Subtype Value | Protocol Name                                    |
    +===============+==================================================+
    | 0             | Unused - Illegal Value                           |
    +---------------+--------------------------------------------------+
    | 1             | Link Aggregation Control Protocol(LACP)          |
    +---------------+--------------------------------------------------+
    | 2             | Link Aggregation - Marker Protocol               |
    +---------------+--------------------------------------------------+
    | 3             | Operations, Administration, and Maintenance(OAM) |
    +---------------+--------------------------------------------------+
    | 4 - 9         | Reserved for future use                          |
    +---------------+--------------------------------------------------+
    | 10            | Organization Specific Slow Protocol(OSSP)        |
    +---------------+--------------------------------------------------+
    | 11 - 255      | Unused - Illegal values                          |
    +---------------+--------------------------------------------------+
    """
    _PACK_STR = '!B'

    @classmethod
    def parser(cls, buf):
        (subtype, ) = struct.unpack_from(cls._PACK_STR, buf)
        switch = {
            SLOW_SUBTYPE_LACP: lacp,
            # TODO: make parsers of other subtypes.
            SLOW_SUBTYPE_MARKER: None,
            SLOW_SUBTYPE_OAM: None,
            SLOW_SUBTYPE_OSSP: None,
        }
        cls_ = switch.get(subtype)
        if cls_:
            return cls_.parser(buf)
        else:
            return None, None, buf


class lacp(packet_base.PacketBase):
    """Link Aggregation Control Protocol(LACP, IEEE 802.1AX)
    header encoder/decoder class.

    http://standards.ieee.org/getieee802/download/802.1AX-2008.pdf

    LACPDU format

    +------------------------------------------------+--------+
    | LACPDU structure                               | Octets |
    +================================================+========+
    | Subtype = LACP                                 | 1      |
    +------------------------------------------------+--------+
    | Version Number                                 | 1      |
    +------------+-----------------------------------+--------+
    | TLV        | TLV_type = Actor Information      | 1      |
    | Actor      |                                   |        |
    +------------+-----------------------------------+--------+
    |            | Actor_Information_Length = 20     | 1      |
    +------------+-----------------------------------+--------+
    |            | Actor_System_Priority             | 2      |
    +------------+-----------------------------------+--------+
    |            | Actor_System                      | 6      |
    +------------+-----------------------------------+--------+
    |            | Actor_Key                         | 2      |
    +------------+-----------------------------------+--------+
    |            | Actor_Port_Priority               | 2      |
    +------------+-----------------------------------+--------+
    |            | Actor_Port                        | 2      |
    +------------+-----------------------------------+--------+
    |            | Actor_State                       | 1      |
    +------------+-----------------------------------+--------+
    |            | Reserved                          | 3      |
    +------------+-----------------------------------+--------+
    | TLV        | TLV_type = Partner Information    | 1      |
    | Partner    |                                   |        |
    +------------+-----------------------------------+--------+
    |            | Partner_Information_Length = 20   | 1      |
    +------------+-----------------------------------+--------+
    |            | Partner_System_Priority           | 2      |
    +------------+-----------------------------------+--------+
    |            | Partner_System                    | 6      |
    +------------+-----------------------------------+--------+
    |            | Partner_Key                       | 2      |
    +------------+-----------------------------------+--------+
    |            | Partner_Port_Priority             | 2      |
    +------------+-----------------------------------+--------+
    |            | Partner_Port                      | 2      |
    +------------+-----------------------------------+--------+
    |            | Partner_State                     | 1      |
    +------------+-----------------------------------+--------+
    |            | Reserved                          | 3      |
    +------------+-----------------------------------+--------+
    | TLV        | TLV_type = Collector Information  | 1      |
    | Collector  |                                   |        |
    +------------+-----------------------------------+--------+
    |            | Collector_Information_Length = 16 | 1      |
    +------------+-----------------------------------+--------+
    |            | Collector_Max_Delay               | 2      |
    +------------+-----------------------------------+--------+
    |            | Reserved                          | 12     |
    +------------+-----------------------------------+--------+
    | TLV        | TLV_type = Terminator             | 1      |
    | Terminator |                                   |        |
    +------------+-----------------------------------+--------+
    |            | Terminator_Length = 0             | 1      |
    +------------+-----------------------------------+--------+
    |            | Reserved                          | 50     |
    +------------+-----------------------------------+--------+


    Terminator information uses a length value of 0 (0x00).

    NOTE--The use of a Terminator_Length of 0 is intentional.
          In TLV encoding schemes it is common practice
          for the terminator encoding to be 0 both
          for the type and the length.

    Actor_State and Partner_State encoded as individual bits within
    a single octet as follows:

    +------+------+------+------+------+------+------+------+
    | 7    | 6    | 5    | 4    | 3    | 2    | 1    | 0    |
    +======+======+======+======+======+======+======+======+
    | EXPR | DFLT | DIST | CLCT | SYNC | AGGR | TMO  | ACT  |
    +------+------+------+------+------+------+------+------+

    ACT
        bit 0.
        about the activity control value with regard to this link.
    TMO
        bit 1.
        about the timeout control value with regard to this link.
    AGGR
        bit 2.
        about how the system regards this link from the point of view
        of the aggregation.
    SYNC
        bit 3.
        about how the system regards this link from the point of view
        of the synchronization.
    CLCT
        bit 4.
        about collecting of incoming frames.
    DIST
        bit 5.
        about distributing of outgoing frames.
    DFLT
        bit 6.
        about the opposite system information which the system use.
    EXPR
        bit 7.
        about the expire state of the system.

    An instance has the following attributes at least.
    Most of them are same to the on-wire counterparts but in host byte
    order.
    __init__ takes the corresponding args in this order.

    .. tabularcolumns:: |l|L|

    =============================== ====================================
    Attribute                       Description
    =============================== ====================================
    version                         LACP version. This parameter must be
                                    set to LACP_VERSION_NUMBER(i.e. 1).

    actor_system_priority           The priority assigned to this
                                    System.

    actor_system                    The Actor's System ID, encoded as
                                    a MAC address.

    actor_key                       The operational Key value assigned
                                    to the port by the Actor.

    actor_port_priority             The priority assigned to this port.

    actor_port                      The port number assigned to the
                                    port by the Actor.

    actor_state_activity            .. _lacp_activity:

                                    about the activity control value
                                    with regard to this link.

                                    LACP_STATE_ACTIVE(1)

                                    LACP_STATE_PASSIVE(0)

    actor_state_timeout             .. _lacp_timeout:

                                    about the timeout control value
                                    with regard to this link.

                                    LACP_STATE_SHORT_TIMEOUT(1)

                                    LACP_STATE_LONG_TIMEOUT(0)

    actor_state_aggregation         .. _lacp_aggregation:

                                    about how the system regards this
                                    link from the point of view of the
                                    aggregation.

                                    LACP_STATE_AGGREGATEABLE(1)

                                    LACP_STATE_INDIVIDUAL(0)

    actor_state_synchronization     .. _lacp_synchronization:

                                    about how the system regards this
                                    link from the point of view of the
                                    synchronization.

                                    LACP_STATE_IN_SYNC(1)

                                    LACP_STATE_OUT_OF_SYNC(0)

    actor_state_collecting          .. _lacp_collecting:

                                    about collecting of incoming frames.

                                    LACP_STATE_COLLECTING_ENABLED(1)

                                    LACP_STATE_COLLECTING_DISABLED(0)

    actor_state_distributing        .. _lacp_distributing:

                                    about distributing of outgoing frames.

                                    LACP_STATE_DISTRIBUTING_ENABLED(1)

                                    LACP_STATE_DISTRIBUTING_DISABLED(0)

    actor_state_defaulted           .. _lacp_defaulted:

                                    about the Partner information
                                    which the the Actor use.

                                    LACP_STATE_DEFAULTED_PARTNER(1)

                                    LACP_STATE_OPERATIONAL_PARTNER(0)

    actor_state_expired             .. _lacp_expired:

                                    about the state of the Actor.

                                    LACP_STATE_EXPIRED(1)

                                    LACP_STATE_NOT_EXPIRED(0)

    partner_system_priority         The priority assigned to the
                                    Partner System.

    partner_system                  The Partner's System ID, encoded
                                    as a MAC address.

    partner_key                     The operational Key value assigned
                                    to the port by the Partner.

    partner_port_priority           The priority assigned to this port
                                    by the Partner.

    partner_port                    The port number assigned to the
                                    port by the Partner.

    partner_state_activity          See :ref:`actor_state_activity\
                                    <lacp_activity>`.

    partner_state_timeout           See :ref:`actor_state_timeout\
                                    <lacp_timeout>`.

    partner_state_aggregation       See :ref:`actor_state_aggregation\
                                    <lacp_aggregation>`.

    partner_state_synchronization   See
                                    :ref:`actor_state_synchronization\
                                    <lacp_synchronization>`.

    partner_state_collecting        See :ref:`actor_state_collecting\
                                    <lacp_collecting>`.

    partner_state_distributing      See :ref:`actor_state_distributing\
                                    <lacp_distributing>`.

    partner_state_defaulted         See :ref:`actor_state_defaulted\
                                    <lacp_defaulted>`.

    partner_state_expired           See :ref:`actor_state_expired\
                                    <lacp_expired>`.

    collector_max_delay             the maximum time that the Frame
                                    Collector may delay.
    =============================== ====================================

    """
    LACP_VERSION_NUMBER = 1

    # LACP TLV type
    LACP_TLV_TYPE_ACTOR = 1
    LACP_TLV_TYPE_PARTNER = 2
    LACP_TLV_TYPE_COLLECTOR = 3
    LACP_TLV_TYPE_TERMINATOR = 0

    # LACP state(LACP_Activity)
    LACP_STATE_ACTIVE = 1
    LACP_STATE_PASSIVE = 0
    # LACP state(LACP_Timeout)
    LACP_STATE_SHORT_TIMEOUT = 1
    LACP_STATE_LONG_TIMEOUT = 0
    # LACP state(Aggregation)
    LACP_STATE_AGGREGATEABLE = 1
    LACP_STATE_INDIVIDUAL = 0
    # LACP state(Synchronization)
    LACP_STATE_IN_SYNC = 1
    LACP_STATE_OUT_OF_SYNC = 0
    # LACP state(Collecting)
    LACP_STATE_COLLECTING_ENABLED = 1
    LACP_STATE_COLELCTING_DISABLED = 0
    # LACP state(Distributing)
    LACP_STATE_DISTRIBUTING_ENABLED = 1
    LACP_STATE_DISTRIBUTING_DISABLED = 0
    # LACP state(Defaulted)
    LACP_STATE_DEFAULED_PARTNER = 1
    LACP_STATE_OPERATIONAL_PARTNER = 0
    # LACP state(Expired)
    LACP_STATE_EXPIRED = 1
    LACP_STATE_NOT_EXPIRED = 0

    # The number of seconds between periodic transmissions using
    # Short Timeouts.
    FAST_PERIODIC_TIME = 1
    # The number of seconds between periodic transmissions using
    # Long Timeouts.
    SLOW_PERIODIC_TIME = 30
    # The number of seconds before invalidating received LACPDU
    # information when using Short Timeouts(3 x Fast_Periodic_Time).
    SHORT_TIMEOUT_TIME = 3 * FAST_PERIODIC_TIME
    # The number of seconds before invalidating received LACPDU
    # information when using Long Timeouts (3 x Slow_Periodic_Time).
    LONG_TIMEOUT_TIME = 3 * SLOW_PERIODIC_TIME

    _HLEN_PACK_STR = '!BB'
    _HLEN_PACK_LEN = struct.calcsize(_HLEN_PACK_STR)
    _ACTPRT_INFO_PACK_STR = '!BBH6sHHHB3x'
    _ACTPRT_INFO_PACK_LEN = struct.calcsize(_ACTPRT_INFO_PACK_STR)
    _COL_INFO_PACK_STR = '!BBH12x'
    _COL_INFO_PACK_LEN = struct.calcsize(_COL_INFO_PACK_STR)
    _TRM_PACK_STR = '!BB50x'
    _TRM_PACK_LEN = struct.calcsize(_TRM_PACK_STR)
    _ALL_PACK_LEN = _HLEN_PACK_LEN + _ACTPRT_INFO_PACK_LEN * 2 + \
        _COL_INFO_PACK_LEN + _TRM_PACK_LEN

    _MIN_LEN = _ALL_PACK_LEN

    def __init__(self, version=LACP_VERSION_NUMBER,
                 actor_system_priority=0,
                 actor_system='00:00:00:00:00:00',
                 actor_key=0, actor_port_priority=0, actor_port=0,
                 actor_state_activity=0, actor_state_timeout=0,
                 actor_state_aggregation=0,
                 actor_state_synchronization=0,
                 actor_state_collecting=0, actor_state_distributing=0,
                 actor_state_defaulted=0, actor_state_expired=0,
                 partner_system_priority=0,
                 partner_system='00:00:00:00:00:00',
                 partner_key=0, partner_port_priority=0, partner_port=0,
                 partner_state_activity=0, partner_state_timeout=0,
                 partner_state_aggregation=0,
                 partner_state_synchronization=0,
                 partner_state_collecting=0,
                 partner_state_distributing=0,
                 partner_state_defaulted=0, partner_state_expired=0,
                 collector_max_delay=0):
        super(lacp, self).__init__()
        # parameter check
        assert (1 == actor_state_activity | 1)
        assert (1 == actor_state_timeout | 1)
        assert (1 == actor_state_aggregation | 1)
        assert (1 == actor_state_synchronization | 1)
        assert (1 == actor_state_collecting | 1)
        assert (1 == actor_state_distributing | 1)
        assert (1 == actor_state_defaulted | 1)
        assert (1 == actor_state_expired | 1)
        assert (1 == partner_state_activity | 1)
        assert (1 == partner_state_timeout | 1)
        assert (1 == partner_state_aggregation | 1)
        assert (1 == partner_state_synchronization | 1)
        assert (1 == partner_state_collecting | 1)
        assert (1 == partner_state_distributing | 1)
        assert (1 == partner_state_defaulted | 1)
        assert (1 == partner_state_expired | 1)
        #------------------------------
        # Header
        #------------------------------
        self.subtype = SLOW_SUBTYPE_LACP
        self.version = version
        #------------------------------
        # Actor Information
        #------------------------------
        self.actor_tag = self.LACP_TLV_TYPE_ACTOR
        self.actor_length = self._ACTPRT_INFO_PACK_LEN
        self.actor_system_priority = actor_system_priority
        self.actor_system = actor_system
        self.actor_key = actor_key
        self.actor_port_priority = actor_port_priority
        self.actor_port = actor_port
        self.actor_state_activity = actor_state_activity
        self.actor_state_timeout = actor_state_timeout
        self.actor_state_aggregation = actor_state_aggregation
        self.actor_state_synchronization = actor_state_synchronization
        self.actor_state_collecting = actor_state_collecting
        self.actor_state_distributing = actor_state_distributing
        self.actor_state_defaulted = actor_state_defaulted
        self.actor_state_expired = actor_state_expired
        self.actor_state = (
            (self.actor_state_activity << 0) |
            (self.actor_state_timeout << 1) |
            (self.actor_state_aggregation << 2) |
            (self.actor_state_synchronization << 3) |
            (self.actor_state_collecting << 4) |
            (self.actor_state_distributing << 5) |
            (self.actor_state_defaulted << 6) |
            (self.actor_state_expired << 7))
        #------------------------------
        # Partner Information
        #------------------------------
        self.partner_tag = self.LACP_TLV_TYPE_PARTNER
        self.partner_length = self._ACTPRT_INFO_PACK_LEN
        self.partner_system_priority = partner_system_priority
        self.partner_system = partner_system
        self.partner_key = partner_key
        self.partner_port_priority = partner_port_priority
        self.partner_port = partner_port
        self.partner_state_activity = partner_state_activity
        self.partner_state_timeout = partner_state_timeout
        self.partner_state_aggregation = partner_state_aggregation
        self.partner_state_synchronization = \
            partner_state_synchronization
        self.partner_state_collecting = partner_state_collecting
        self.partner_state_distributing = partner_state_distributing
        self.partner_state_defaulted = partner_state_defaulted
        self.partner_state_expired = partner_state_expired
        self.partner_state = (
            (self.partner_state_activity << 0) |
            (self.partner_state_timeout << 1) |
            (self.partner_state_aggregation << 2) |
            (self.partner_state_synchronization << 3) |
            (self.partner_state_collecting << 4) |
            (self.partner_state_distributing << 5) |
            (self.partner_state_defaulted << 6) |
            (self.partner_state_expired << 7))
        #------------------------------
        # Collector Information
        #------------------------------
        self.collector_tag = self.LACP_TLV_TYPE_COLLECTOR
        self.collector_length = self._COL_INFO_PACK_LEN
        self.collector_max_delay = collector_max_delay
        #------------------------------
        # Terminator
        #------------------------------
        self.terminator_tag = self.LACP_TLV_TYPE_TERMINATOR
        self.terminator_length = 0

    @classmethod
    def parser(cls, buf):
        assert cls._ALL_PACK_LEN == len(buf)
        offset = 0
        #------------------------------
        # Header
        #------------------------------
        (subtype, version
         ) = struct.unpack_from(cls._HLEN_PACK_STR, buf, offset)
        assert SLOW_SUBTYPE_LACP == subtype
        assert cls.LACP_VERSION_NUMBER == version
        offset += cls._HLEN_PACK_LEN
        #------------------------------
        # Actor Information
        #------------------------------
        (actor_tag, actor_length, actor_system_priority, actor_system,
         actor_key, actor_port_priority, actor_port, actor_state
         ) = struct.unpack_from(cls._ACTPRT_INFO_PACK_STR, buf, offset)
        assert cls.LACP_TLV_TYPE_ACTOR == actor_tag
        assert cls._ACTPRT_INFO_PACK_LEN == actor_length
        offset += cls._ACTPRT_INFO_PACK_LEN
        actor_state_activity = (actor_state >> 0) & 1
        actor_state_timeout = (actor_state >> 1) & 1
        actor_state_aggregation = (actor_state >> 2) & 1
        actor_state_synchronization = (actor_state >> 3) & 1
        actor_state_collecting = (actor_state >> 4) & 1
        actor_state_distributing = (actor_state >> 5) & 1
        actor_state_defaulted = (actor_state >> 6) & 1
        actor_state_expired = (actor_state >> 7) & 1
        #------------------------------
        # Partner Information
        #------------------------------
        (partner_tag, partner_length, partner_system_priority,
         partner_system, partner_key, partner_port_priority,
         partner_port, partner_state
         ) = struct.unpack_from(cls._ACTPRT_INFO_PACK_STR, buf, offset)
        assert cls.LACP_TLV_TYPE_PARTNER == partner_tag
        assert cls._ACTPRT_INFO_PACK_LEN == partner_length
        offset += cls._ACTPRT_INFO_PACK_LEN
        partner_state_activity = (partner_state >> 0) & 1
        partner_state_timeout = (partner_state >> 1) & 1
        partner_state_aggregation = (partner_state >> 2) & 1
        partner_state_synchronization = (partner_state >> 3) & 1
        partner_state_collecting = (partner_state >> 4) & 1
        partner_state_distributing = (partner_state >> 5) & 1
        partner_state_defaulted = (partner_state >> 6) & 1
        partner_state_expired = (partner_state >> 7) & 1
        #------------------------------
        # Collector Information
        #------------------------------
        (collector_tag, collector_length, collector_max_delay
         ) = struct.unpack_from(cls._COL_INFO_PACK_STR, buf, offset)
        assert cls.LACP_TLV_TYPE_COLLECTOR == collector_tag
        assert cls._COL_INFO_PACK_LEN == collector_length
        offset += cls._COL_INFO_PACK_LEN
        #------------------------------
        # Terminator Information
        #------------------------------
        (terminator_tag, terminator_length
         ) = struct.unpack_from(cls._TRM_PACK_STR, buf, offset)
        assert cls.LACP_TLV_TYPE_TERMINATOR == terminator_tag
        assert 0 == terminator_length
        return cls(version,
                   actor_system_priority,
                   addrconv.mac.bin_to_text(actor_system),
                   actor_key, actor_port_priority,
                   actor_port, actor_state_activity,
                   actor_state_timeout, actor_state_aggregation,
                   actor_state_synchronization, actor_state_collecting,
                   actor_state_distributing, actor_state_defaulted,
                   actor_state_expired, partner_system_priority,
                   addrconv.mac.bin_to_text(partner_system),
                   partner_key, partner_port_priority,
                   partner_port, partner_state_activity,
                   partner_state_timeout, partner_state_aggregation,
                   partner_state_synchronization,
                   partner_state_collecting, partner_state_distributing,
                   partner_state_defaulted, partner_state_expired,
                   collector_max_delay), None, buf[lacp._ALL_PACK_LEN:]

    def serialize(self, payload, prev):
        header = struct.pack(self._HLEN_PACK_STR, self.subtype,
                             self.version)
        actor = struct.pack(self._ACTPRT_INFO_PACK_STR,
                            self.actor_tag, self.actor_length,
                            self.actor_system_priority,
                            addrconv.mac.text_to_bin(self.actor_system),
                            self.actor_key,
                            self.actor_port_priority, self.actor_port,
                            self.actor_state)
        partner = struct.pack(self._ACTPRT_INFO_PACK_STR,
                              self.partner_tag, self.partner_length,
                              self.partner_system_priority,
                              addrconv.mac.text_to_bin(self.partner_system),
                              self.partner_key,
                              self.partner_port_priority,
                              self.partner_port, self.partner_state)
        collector = struct.pack(self._COL_INFO_PACK_STR,
                                self.collector_tag,
                                self.collector_length,
                                self.collector_max_delay)
        terminator = struct.pack(self._TRM_PACK_STR,
                                 self.terminator_tag,
                                 self.terminator_length)
        return header + actor + partner + collector + terminator

########NEW FILE########
__FILENAME__ = stream_parser
# Copyright (C) 2013 Nippon Telegraph and Telephone Corporation.
# Copyright (C) 2013 YAMAMOTO Takashi <yamamoto at valinux co jp>
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.


from abc import ABCMeta, abstractmethod


class StreamParser(object):
    """Streaming parser base class.

    An instance of a subclass of this class is used to extract messages
    from a raw byte stream.

    It's designed to be used for data read from a transport which doesn't
    preserve message boundaries.  A typical example of such a transport
    is TCP.

    """

    __metaclass__ = ABCMeta

    class TooSmallException(Exception):
        pass

    def __init__(self):
        self._q = bytearray()

    def parse(self, data):
        """Tries to extract messages from a raw byte stream.

        The data argument would be python bytes newly read from the input
        stream.

        Returns an ordered list of extracted messages.
        It can be an empty list.

        The rest of data which doesn't produce a complete message is
        kept internally and will be used when more data is come.
        I.e. next time this method is called again.
        """
        self._q.append(data)
        msgs = []
        while True:
            try:
                msg, self._q = self.try_parse(self._q)
            except self.TooSmallException:
                break
            msgs.append(msg)
        return msgs

    @abstractmethod
    def try_parse(self, q):
        """Try to extract a message from the given bytes.

        This is an override point for subclasses.

        This method tries to extract a message from bytes given by the
        argument.

        Raises TooSmallException if the given data is not enough to
        extract a complete message but there's still a chance to extract
        a message if more data is come later.
        """
        pass

########NEW FILE########
__FILENAME__ = tcp
# Copyright (C) 2012 Nippon Telegraph and Telephone Corporation.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import struct

from . import packet_base
from . import packet_utils


class tcp(packet_base.PacketBase):
    """TCP (RFC 793) header encoder/decoder class.

    An instance has the following attributes at least.
    Most of them are same to the on-wire counterparts but in host byte order.
    __init__ takes the corresponding args in this order.

    ============== ====================
    Attribute      Description
    ============== ====================
    src_port       Source Port
    dst_port       Destination Port
    seq            Sequence Number
    ack            Acknowledgement Number
    offset         Data Offset \
                   (0 means automatically-calculate when encoding)
    bits           Control Bits
    window_size    Window
    csum           Checksum \
                   (0 means automatically-calculate when encoding)
    urgent         Urgent Pointer
    option         An bytearray containing Options and following Padding. \
                   None if no options.
    ============== ====================
    """

    _PACK_STR = '!HHIIBBHHH'
    _MIN_LEN = struct.calcsize(_PACK_STR)

    def __init__(self, src_port=0, dst_port=0, seq=0, ack=0, offset=0,
                 bits=0, window_size=0, csum=0, urgent=0, option=None):
        super(tcp, self).__init__()
        self.src_port = src_port
        self.dst_port = dst_port
        self.seq = seq
        self.ack = ack
        self.offset = offset
        self.bits = bits
        self.window_size = window_size
        self.csum = csum
        self.urgent = urgent
        self.option = option

    def __len__(self):
        return self.offset * 4

    @classmethod
    def parser(cls, buf):
        (src_port, dst_port, seq, ack, offset, bits, window_size,
         csum, urgent) = struct.unpack_from(cls._PACK_STR, buf)
        offset = offset >> 4
        bits = bits & 0x3f
        length = offset * 4
        if length > tcp._MIN_LEN:
            option = buf[tcp._MIN_LEN:length]
        else:
            option = None
        msg = cls(src_port, dst_port, seq, ack, offset, bits,
                  window_size, csum, urgent, option)

        return msg, None, buf[length:]

    def serialize(self, payload, prev):
        offset = self.offset << 4
        h = bytearray(struct.pack(
            tcp._PACK_STR, self.src_port, self.dst_port, self.seq,
            self.ack, offset, self.bits, self.window_size, self.csum,
            self.urgent))

        if self.option:
            h.extend(self.option)
            mod = len(self.option) % 4
            if mod:
                h.extend(bytearray(4 - mod))
            if self.offset:
                offset = self.offset << 2
                if len(h) < offset:
                    h.extend(bytearray(offset - len(h)))

        if 0 == self.offset:
            self.offset = len(h) >> 2
            offset = self.offset << 4
            struct.pack_into('!B', h, 12, offset)

        if self.csum == 0:
            total_length = len(h) + len(payload)
            self.csum = packet_utils.checksum_ip(prev, total_length,
                                                 h + payload)
            struct.pack_into('!H', h, 16, self.csum)
        return str(h)

########NEW FILE########
__FILENAME__ = udp
# Copyright (C) 2012 Nippon Telegraph and Telephone Corporation.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import struct

from . import packet_base
from . import packet_utils


class udp(packet_base.PacketBase):
    """UDP (RFC 768) header encoder/decoder class.

    An instance has the following attributes at least.
    Most of them are same to the on-wire counterparts but in host byte order.
    __init__ takes the corresponding args in this order.

    ============== ====================
    Attribute      Description
    ============== ====================
    src_port       Source Port
    dst_port       Destination Port
    total_length   Length \
                   (0 means automatically-calculate when encoding)
    csum           Checksum \
                   (0 means automatically-calculate when encoding)
    ============== ====================
    """

    _PACK_STR = '!HHHH'
    _MIN_LEN = struct.calcsize(_PACK_STR)

    def __init__(self, src_port=0, dst_port=0, total_length=0, csum=0):
        super(udp, self).__init__()
        self.src_port = src_port
        self.dst_port = dst_port
        self.total_length = total_length
        self.csum = csum

    @classmethod
    def parser(cls, buf):
        (src_port, dst_port, total_length, csum) = struct.unpack_from(
            cls._PACK_STR, buf)
        msg = cls(src_port, dst_port, total_length, csum)
        return msg, None, buf[msg._MIN_LEN:total_length]

    def serialize(self, payload, prev):
        if self.total_length == 0:
            self.total_length = udp._MIN_LEN + len(payload)
        h = struct.pack(udp._PACK_STR, self.src_port, self.dst_port,
                        self.total_length, self.csum)
        if self.csum == 0:
            self.csum = packet_utils.checksum_ip(
                prev, self.total_length, h + payload)
            h = struct.pack(udp._PACK_STR, self.src_port, self.dst_port,
                            self.total_length, self.csum)
        return h

########NEW FILE########
__FILENAME__ = vlan
# Copyright (C) 2012 Nippon Telegraph and Telephone Corporation.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import abc
import struct
from . import packet_base
from . import arp
from . import ipv4
from . import ipv6
from . import lldp
from . import slow
from . import llc
from . import pbb
from ryu.ofproto import ether


class _vlan(packet_base.PacketBase):

    __metaclass__ = abc.ABCMeta
    _PACK_STR = "!HH"
    _MIN_LEN = struct.calcsize(_PACK_STR)

    @abc.abstractmethod
    def __init__(self, pcp, cfi, vid, ethertype):
        super(_vlan, self).__init__()
        self.pcp = pcp
        self.cfi = cfi
        self.vid = vid
        self.ethertype = ethertype

    @classmethod
    def parser(cls, buf):
        tci, ethertype = struct.unpack_from(cls._PACK_STR, buf)
        pcp = tci >> 13
        cfi = (tci >> 12) & 1
        vid = tci & ((1 << 12) - 1)
        return (cls(pcp, cfi, vid, ethertype),
                vlan.get_packet_type(ethertype), buf[vlan._MIN_LEN:])

    def serialize(self, payload, prev):
        tci = self.pcp << 13 | self.cfi << 12 | self.vid
        return struct.pack(vlan._PACK_STR, tci, self.ethertype)


class vlan(_vlan):
    """VLAN (IEEE 802.1Q) header encoder/decoder class.

    An instance has the following attributes at least.
    Most of them are same to the on-wire counterparts but in host byte order.
    __init__ takes the corresponding args in this order.

    ============== ====================
    Attribute      Description
    ============== ====================
    pcp            Priority Code Point
    cfi            Canonical Format Indicator
    vid            VLAN Identifier
    ethertype      EtherType
    ============== ====================
    """

    def __init__(self, pcp=0, cfi=0, vid=0, ethertype=ether.ETH_TYPE_IP):
        super(vlan, self).__init__(pcp, cfi, vid, ethertype)

    @classmethod
    def get_packet_type(cls, type_):
        """Override method for the Length/Type field (self.ethertype).
        The Length/Type field means Length or Type interpretation,
        same as ethernet IEEE802.3.
        If the value of Length/Type field is less than or equal to
        1500 decimal(05DC hexadecimal), it means Length interpretation
        and be passed to the LLC sublayer."""
        if type_ <= ether.ETH_TYPE_IEEE802_3:
            type_ = ether.ETH_TYPE_IEEE802_3
        return cls._TYPES.get(type_)


class svlan(_vlan):
    """S-VLAN (IEEE 802.1ad) header encoder/decoder class.


    An instance has the following attributes at least.
    Most of them are same to the on-wire counterparts but in host byte order.
    __init__ takes the corresponding args in this order.

    ============== ====================
    Attribute      Description
    ============== ====================
    pcp            Priority Code Point
    cfi            Canonical Format Indicator.
                   In a case to be used as B-TAG,
                   this field means DEI(Drop Eligible Indication).
    vid            VLAN Identifier
    ethertype      EtherType
    ============== ====================
    """

    def __init__(self, pcp=0, cfi=0, vid=0, ethertype=ether.ETH_TYPE_8021Q):
        super(svlan, self).__init__(pcp, cfi, vid, ethertype)

    @classmethod
    def get_packet_type(cls, type_):
        return cls._TYPES.get(type_)


vlan.register_packet_type(arp.arp, ether.ETH_TYPE_ARP)
vlan.register_packet_type(ipv4.ipv4, ether.ETH_TYPE_IP)
vlan.register_packet_type(ipv6.ipv6, ether.ETH_TYPE_IPV6)
vlan.register_packet_type(lldp.lldp, ether.ETH_TYPE_LLDP)
vlan.register_packet_type(slow.slow, ether.ETH_TYPE_SLOW)
vlan.register_packet_type(llc.llc, ether.ETH_TYPE_IEEE802_3)

svlan.register_packet_type(vlan, ether.ETH_TYPE_8021Q)
svlan.register_packet_type(pbb.itag, ether.ETH_TYPE_8021AH)

########NEW FILE########
__FILENAME__ = vrrp
# Copyright (C) 2013 Nippon Telegraph and Telephone Corporation.
# Copyright (C) 2013 Isaku Yamahata <yamahata at private email ne jp>
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""
VRRP packet parser/serializer

RFC 3768
VRRP v2 packet format
    0                   1                   2                   3
    0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1
   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
   |Version| Type  | Virtual Rtr ID|   Priority    | Count IP Addrs|
   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
   |   Auth Type   |   Adver Int   |          Checksum             |
   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
   |                         IP Address (1)                        |
   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
   |                            .                                  |
   |                            .                                  |
   |                            .                                  |
   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
   |                         IP Address (n)                        |
   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
   |                     Authentication Data (1)                   |
   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
   |                     Authentication Data (2)                   |
   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+


RFC 5798
VRRP v3 packet format
     0                   1                   2                   3
     0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1
    +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
    |                    IPv4 Fields or IPv6 Fields                 |
   ...                                                             ...
    |                                                               |
    +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
    |Version| Type  | Virtual Rtr ID|   Priority    |Count IPvX Addr|
    +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
    |(rsvd) |     Max Adver Int     |          Checksum             |
    +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
    |                                                               |
    +                                                               +
    |                       IPvX Address(es)                        |
    +                                                               +
    +                                                               +
    +                                                               +
    +                                                               +
    |                                                               |
    +                                                               +
    |                                                               |
    +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+

"""

import struct

from ryu.lib.packet import ethernet
from ryu.lib.packet import ipv4
from ryu.lib.packet import ipv6
from ryu.lib.packet import packet
from ryu.lib.packet import packet_base
from ryu.lib.packet import packet_utils
from ryu.lib.packet import vlan
from ryu.ofproto import ether
from ryu.ofproto import inet
from ryu.lib import addrconv


# IPv4
# the LSB 8 bits is used for VRID
VRRP_IPV4_SRC_MAC_ADDRESS_FMT = '00:00:5E:00:01:%02x'
VRRP_IPV4_DST_MAC_ADDRESS = '01:00:5E:00:00:12'
VRRP_IPV4_DST_ADDRESS = '224.0.0.18'
VRRP_IPV4_TTL = 255


def vrrp_ipv4_src_mac_address(vrid):
    return VRRP_IPV4_SRC_MAC_ADDRESS_FMT % vrid


# IPv6
# the LSB 8 bits is used for VRID
VRRP_IPV6_SRC_MAC_ADDRESS_FMT = '00:00:5E:00:02:%02x'
VRRP_IPV6_DST_MAC_ADDRESS = '33:33:00:00:00:12'
VRRP_IPV6_DST_ADDRESS = 'ff02::12'
VRRP_IPV6_HOP_LIMIT = 255


def vrrp_ipv6_src_mac_address(vrid):
    return VRRP_IPV6_SRC_MAC_ADDRESS_FMT % vrid


VRRP_VERSION_SHIFT = 4
VRRP_TYPE_MASK = 0xf


def vrrp_from_version_type(version_type):
    return (version_type >> VRRP_VERSION_SHIFT, version_type & VRRP_TYPE_MASK)


def vrrp_to_version_type(version, type_):
    return (version << VRRP_VERSION_SHIFT) | type_


# VRRP version
VRRP_VERSION_V2 = 2
VRRP_VERSION_V3 = 3

# VRRP type
VRRP_TYPE_ADVERTISEMENT = 1

# VRRP VRID: 0 isn't used
VRRP_VRID_MIN = 1
VRRP_VRID_MAX = 255

# VRRP priority
VRRP_PRIORITY_MIN = 0
VRRP_PRIORITY_MAX = 255
VRRP_PRIORITY_RELEASE_RESPONSIBILITY = 0
VRRP_PRIORITY_BACKUP_MIN = 1
VRRP_PRIORITY_BACKUP_DEFAULT = 100
VRRP_PRIORITY_BACKUP_MAX = 254
VRRP_PRIORITY_ADDRESS_OWNER = 255

# VRRP auth type (VRRP v2 only)
VRRP_AUTH_NO_AUTH = 0
VRRP_AUTH_RESERVED1 = 1
VRRP_AUTH_RESERVED2 = 2
VRRP_AUTH_DATA1 = 0
VRRP_AUTH_DATA2 = 0
VRRP_AUTH_DATA = (VRRP_AUTH_DATA1, VRRP_AUTH_DATA2)

# VRRP Max advertisement interval
VRRP_MAX_ADVER_INT_DEFAULT_IN_SEC = 1   # 1 second

VRRP_V3_MAX_ADVER_INT_MASK = 0xfff      # in centiseconds
VRRP_V3_MAX_ADVER_INT_DEFAULT = 100     # = 1 second
VRRP_V3_MAX_ADVER_INT_MIN = 1           # don't allow 0
VRRP_V3_MAX_ADVER_INT_MAX = 0xfff

VRRP_V2_MAX_ADVER_INT_MASK = 0xff       # in seconds
VRRP_V2_MAX_ADVER_INT_DEFAULT = 1       # 1 second
VRRP_V2_MAX_ADVER_INT_MIN = 1           # don't allow 0
VRRP_V2_MAX_ADVER_INT_MAX = 0xff


def is_ipv6(ip_address):
    assert type(ip_address) == str
    try:
        addrconv.ipv4.text_to_bin(ip_address)
    except:
        addrconv.ipv6.text_to_bin(ip_address)  # sanity
        return True
    return False


class vrrp(packet_base.PacketBase):
    """The base class for VRRPv2 (RFC 3768) and VRRPv3 (RFC 5798)
    header encoder/decoder classes.

    Unlike other ryu.lib.packet.packet_base.PacketBase derived classes,
    This class should not be directly instantiated by user.

    An instance has the following attributes at least.
    Most of them are same to the on-wire counterparts but in host byte order.

    ============== ====================
    Attribute      Description
    ============== ====================
    version        Version
    type           Type
    vrid           Virtual Rtr ID (VRID)
    priority       Priority
    count_ip       Count IPvX Addr. \
                   Calculated automatically when encoding.
    max_adver_int  Maximum Advertisement Interval (Max Adver Int)
    checksum       Checksum. \
                   Calculated automatically when encoding.
    ip_addresses   IPvX Address(es).  A python list of IP addresses.
    auth_type      Authentication Type (only for VRRPv2)
    auth_data      Authentication Data (only for VRRPv2)
    ============== ====================
    """

    _VERSION_PACK_STR = '!B'
    _IPV4_ADDRESS_PACK_STR_RAW = '4s'
    _IPV4_ADDRESS_PACK_STR = '!' + _IPV4_ADDRESS_PACK_STR_RAW
    _IPV4_ADDRESS_LEN = struct.calcsize(_IPV4_ADDRESS_PACK_STR)
    _IPV6_ADDRESS_LEN = 16
    _IPV6_ADDRESS_PACK_STR_RAW = '%ds' % _IPV6_ADDRESS_LEN
    _IPV6_ADDRESS_PACK_STR = '!' + _IPV6_ADDRESS_PACK_STR_RAW
    _IPV6_ADDRESS_LEN = struct.calcsize(_IPV6_ADDRESS_PACK_STR)

    _VRRP_VERSIONS = {}
    _SEC_IN_MAX_ADVER_INT_UNIT = {}

    @staticmethod
    def get_payload(packet_):
        may_ip = None
        may_vrrp = None

        idx = 0
        for protocol in packet_:
            if isinstance(protocol, ipv4.ipv4) or isinstance(protocol,
                                                             ipv6.ipv6):
                may_ip = protocol
                try:
                    if isinstance(packet_.protocols[idx + 1], vrrp):
                        may_vrrp = packet_.protocols[idx + 1]
                finally:
                    break
            idx += 1

        if may_ip and may_vrrp:
            return may_ip, may_vrrp
        else:
            return None, None

    @classmethod
    def register_vrrp_version(cls, version,
                              sec_in_max_adver_int_unit):
        def _register_vrrp_version(cls_):
            cls._VRRP_VERSIONS[version] = cls_
            cls._SEC_IN_MAX_ADVER_INT_UNIT[version] = sec_in_max_adver_int_unit
            return cls_
        return _register_vrrp_version

    @staticmethod
    def sec_to_max_adver_int(version, seconds):
        return int(seconds * vrrp._SEC_IN_MAX_ADVER_INT_UNIT[version])

    @staticmethod
    def max_adver_int_to_sec(version, max_adver_int):
        return float(max_adver_int) / vrrp._SEC_IN_MAX_ADVER_INT_UNIT[version]

    def __init__(self, version, type_, vrid, priority, count_ip,
                 max_adver_int, checksum, ip_addresses,

                 # auth_type/auth_data is for vrrp v2
                 auth_type=None, auth_data=None):
        super(vrrp, self).__init__()
        self.version = version
        self.type = type_
        self.vrid = vrid
        self.priority = priority
        self.count_ip = count_ip
        self.max_adver_int = max_adver_int

        self.checksum = checksum
        self.ip_addresses = ip_addresses
        assert len(ip_addresses) == self.count_ip

        self.auth_type = auth_type
        self.auth_data = auth_data

        self._is_ipv6 = is_ipv6(self.ip_addresses[0])
        self.identification = 0         # used for ipv4 identification

    def checksum_ok(self, ipvx, vrrp_buf):
        cls_ = self._VRRP_VERSIONS[self.version]
        return cls_.checksum_ok(self, ipvx, vrrp_buf)

    @property
    def max_adver_int_in_sec(self):
        # return seconds of float as time.sleep() accepts such type.
        return self.max_adver_int_to_sec(self.version, self.max_adver_int)

    @property
    def is_ipv6(self):
        return self._is_ipv6

    def __len__(self):
        cls_ = self._VRRP_VERSIONS[self.version]
        return cls_.__len__(self)

    @staticmethod
    def create_version(version, type_, vrid, priority, max_adver_int,
                       ip_addresses, auth_type=None, auth_data=None):
        cls_ = vrrp._VRRP_VERSIONS.get(version, None)
        if not cls_:
            raise ValueError('unknown VRRP version %d' % version)

        if priority is None:
            priority = VRRP_PRIORITY_BACKUP_DEFAULT
        count_ip = len(ip_addresses)
        if max_adver_int is None:
            max_adver_int = cls_.sec_to_max_adver_int(
                VRRP_MAX_ADVER_INT_DEFAULT_IN_SEC)
        return cls_(version, type_, vrid, priority, count_ip, max_adver_int,
                    None, ip_addresses,
                    auth_type=auth_type, auth_data=auth_data)

    def get_identification(self):
        self.identification += 1
        self.identification &= 0xffff
        if self.identification == 0:
            self.identification += 1
            self.identification &= 0xffff
        return self.identification

    def create_packet(self, primary_ip_address, vlan_id=None):
        """Prepare a VRRP packet.

        Returns a newly created ryu.lib.packet.packet.Packet object
        with appropriate protocol header objects added by add_protocol().
        It's caller's responsibility to serialize().
        The serialized packet would looks like the ones described in
        the following sections.

        * RFC 3768 5.1. VRRP Packet Format
        * RFC 5798 5.1. VRRP Packet Format

        ================== ====================
        Argument           Description
        ================== ====================
        primary_ip_address Source IP address
        vlan_id            VLAN ID.  None for no VLAN.
        ================== ====================
        """
        if self.is_ipv6:
            traffic_class = 0xc0        # set tos to internetwork control
            flow_label = 0
            payload_length = ipv6.ipv6._MIN_LEN + len(self)     # XXX _MIN_LEN
            e = ethernet.ethernet(VRRP_IPV6_DST_MAC_ADDRESS,
                                  vrrp_ipv6_src_mac_address(self.vrid),
                                  ether.ETH_TYPE_IPV6)
            ip = ipv6.ipv6(6, traffic_class, flow_label, payload_length,
                           inet.IPPROTO_VRRP, VRRP_IPV6_HOP_LIMIT,
                           primary_ip_address, VRRP_IPV6_DST_ADDRESS)
        else:
            header_length = ipv4.ipv4._MIN_LEN / 4      # XXX _MIN_LEN
            total_length = 0
            tos = 0xc0  # set tos to internetwork control
            identification = self.get_identification()
            e = ethernet.ethernet(VRRP_IPV4_DST_MAC_ADDRESS,
                                  vrrp_ipv4_src_mac_address(self.vrid),
                                  ether.ETH_TYPE_IP)
            ip = ipv4.ipv4(4, header_length, tos, total_length, identification,
                           0, 0, VRRP_IPV4_TTL, inet.IPPROTO_VRRP, 0,
                           primary_ip_address, VRRP_IPV4_DST_ADDRESS)

        p = packet.Packet()
        p.add_protocol(e)
        if vlan_id is not None:
            vlan_ = vlan.vlan(0, 0, vlan_id, e.ethertype)
            e.ethertype = ether.ETH_TYPE_8021Q
            p.add_protocol(vlan_)
        p.add_protocol(ip)
        p.add_protocol(self)
        return p

    @classmethod
    def parser(cls, buf):
        (version_type,) = struct.unpack_from(cls._VERSION_PACK_STR, buf)
        version, _type = vrrp_from_version_type(version_type)
        cls_ = cls._VRRP_VERSIONS[version]
        return cls_.parser(buf)

    @staticmethod
    def serialize_static(vrrp_, prev):
        # self can be a instance of vrrpv2 or vrrpv3.
        assert isinstance(vrrp_, vrrp)
        cls = vrrp._VRRP_VERSIONS[vrrp_.version]
        return cls.serialize_static(vrrp_, prev)

    def serialize(self, payload, prev):
        return self.serialize_static(self, prev)

    @staticmethod
    def is_valid_ttl(ipvx):
        version = ipvx.version
        if version == 4:
            return ipvx.ttl == VRRP_IPV4_TTL
        if version == 6:
            return ipvx.hop_limit == VRRP_IPV6_HOP_LIMIT

        raise ValueError('invalid ip version %d' % version)

    def is_valid(self):
        cls = self._VRRP_VERSIONS.get(self.version, None)
        if cls is None:
            return False
        return cls.is_valid(self)


# max_adver_int is in seconds
@vrrp.register_vrrp_version(VRRP_VERSION_V2, 1)
class vrrpv2(vrrp):
    """VRRPv2 (RFC 3768) header encoder/decoder class.

    Unlike other ryu.lib.packet.packet_base.PacketBase derived classes,
    *create* method should be used to instantiate an object of this class.
    """

    _PACK_STR = '!BBBBBBH'
    _MIN_LEN = struct.calcsize(_PACK_STR)
    _CHECKSUM_PACK_STR = '!H'
    _CHECKSUM_OFFSET = 6
    _AUTH_DATA_PACK_STR = '!II'
    _AUTH_DATA_LEN = struct.calcsize('!II')

    def __len__(self):
        return (self._MIN_LEN + self._IPV4_ADDRESS_LEN * self.count_ip +
                self._AUTH_DATA_LEN)

    def checksum_ok(self, ipvx, vrrp_buf):
        return packet_utils.checksum(vrrp_buf) == 0

    @staticmethod
    def create(type_, vrid, priority, max_adver_int, ip_addresses):
        """Unlike other ryu.lib.packet.packet_base.PacketBase derived classes,
        this method should be used to instantiate an object of this class.

        This method's arguments are same as ryu.lib.packet.vrrp.vrrp object's
        attributes of the same name.  (except that *type_* corresponds to
        *type* attribute.)
        """

        return vrrp.create_version(VRRP_VERSION_V2, type_, vrid, priority,
                                   max_adver_int,
                                   ip_addresses,
                                   auth_type=VRRP_AUTH_NO_AUTH,
                                   auth_data=VRRP_AUTH_DATA)

    @staticmethod
    def _ip_addresses_pack_str(count_ip):
        return '!' + vrrpv2._IPV4_ADDRESS_PACK_STR_RAW * count_ip

    @classmethod
    def parser(cls, buf):
        (version_type, vrid, priority, count_ip, auth_type, adver_int,
         checksum) = struct.unpack_from(cls._PACK_STR, buf)
        (version, type_) = vrrp_from_version_type(version_type)

        offset = cls._MIN_LEN
        ip_addresses_pack_str = cls._ip_addresses_pack_str(count_ip)
        ip_addresses_bin = struct.unpack_from(ip_addresses_pack_str, buf,
                                              offset)
        ip_addresses = map(lambda x: addrconv.ipv4.bin_to_text(x),
                           ip_addresses_bin)

        offset += struct.calcsize(ip_addresses_pack_str)
        auth_data = struct.unpack_from(cls._AUTH_DATA_PACK_STR, buf, offset)

        msg = cls(version, type_, vrid, priority, count_ip, adver_int,
                  checksum, ip_addresses, auth_type, auth_data)
        return msg, None, buf[len(msg):]

    @staticmethod
    def serialize_static(vrrp_, prev):
        assert not vrrp_.is_ipv6        # vrrpv2 defines only IPv4
        ip_addresses_pack_str = vrrpv2._ip_addresses_pack_str(vrrp_.count_ip)
        ip_addresses_len = struct.calcsize(ip_addresses_pack_str)
        vrrp_len = vrrpv2._MIN_LEN + ip_addresses_len + vrrpv2._AUTH_DATA_LEN

        checksum = False
        if vrrp_.checksum is None:
            checksum = True
            vrrp_.checksum = 0

        if vrrp_.auth_type is None:
            vrrp_.auth_type = VRRP_AUTH_NO_AUTH
        if vrrp_.auth_data is None:
            vrrp_.auth_data = VRRP_AUTH_DATA

        buf = bytearray(vrrp_len)
        offset = 0
        struct.pack_into(vrrpv2._PACK_STR, buf, offset,
                         vrrp_to_version_type(vrrp_.version, vrrp_.type),
                         vrrp_.vrid, vrrp_.priority,
                         vrrp_.count_ip, vrrp_.auth_type, vrrp_.max_adver_int,
                         vrrp_.checksum)
        offset += vrrpv2._MIN_LEN
        struct.pack_into(ip_addresses_pack_str, buf, offset,
                         *map(lambda x: addrconv.ipv4.text_to_bin(x),
                              vrrp_.ip_addresses))
        offset += ip_addresses_len
        struct.pack_into(vrrpv2._AUTH_DATA_PACK_STR, buf, offset,
                         *vrrp_.auth_data)
        if checksum:
            vrrp_.checksum = packet_utils.checksum(buf)
            struct.pack_into(vrrpv2._CHECKSUM_PACK_STR, buf,
                             vrrpv2._CHECKSUM_OFFSET, vrrp_.checksum)
        return buf

    def is_valid(self):
        return (self.version == VRRP_VERSION_V2 and
                self.type == VRRP_TYPE_ADVERTISEMENT and
                VRRP_VRID_MIN <= self.vrid and self.vrid <= VRRP_VRID_MAX and
                VRRP_PRIORITY_MIN <= self.priority and
                self.priority <= VRRP_PRIORITY_MAX and
                self.auth_type == VRRP_AUTH_NO_AUTH and
                VRRP_V2_MAX_ADVER_INT_MIN <= self.max_adver_int and
                self.max_adver_int <= VRRP_V2_MAX_ADVER_INT_MAX and
                self.count_ip == len(self.ip_addresses))


# max_adver_int is in centi seconds: 1 second = 100 centiseconds
@vrrp.register_vrrp_version(VRRP_VERSION_V3, 100)
class vrrpv3(vrrp):
    """VRRPv3 (RFC 5798) header encoder/decoder class.

    Unlike other ryu.lib.packet.packet_base.PacketBase derived classes,
    *create* method should be used to instantiate an object of this class.
    """

    _PACK_STR = '!BBBBHH'
    _MIN_LEN = struct.calcsize(_PACK_STR)
    _CHECKSUM_PACK_STR = '!H'
    _CHECKSUM_OFFSET = 6

    def __len__(self):
        if self.is_ipv6:
            address_len = self._IPV6_ADDRESS_LEN
        else:
            address_len = self._IPV4_ADDRESS_LEN
        return self._MIN_LEN + address_len * self.count_ip

    def checksum_ok(self, ipvx, vrrp_buf):
        # There are two interpretation of IPv4 checksum
        # include IPv4 pseudo header or not.
        # http://www.ietf.org/mail-archive/web/vrrp/current/msg01473.html
        # if not self.is_ipv6:
        #     return packet_utils.checksum(vrrp_buf) == 0
        return packet_utils.checksum_ip(ipvx, len(self), vrrp_buf) == 0

    @staticmethod
    def create(type_, vrid, priority, max_adver_int, ip_addresses):
        """Unlike other ryu.lib.packet.packet_base.PacketBase derived classes,
        this method should be used to instantiate an object of this class.

        This method's arguments are same as ryu.lib.packet.vrrp.vrrp object's
        attributes of the same name.  (except that *type_* corresponds to
        *type* attribute.)
        """
        return vrrp.create_version(VRRP_VERSION_V3, type_, vrid, priority,
                                   max_adver_int, ip_addresses)

    @classmethod
    def parser(cls, buf):
        (version_type, vrid, priority, count_ip, max_adver_int,
         checksum) = struct.unpack_from(cls._PACK_STR, buf)
        (version, type_) = vrrp_from_version_type(version_type)

        # _rsvd = (max_adver_int & ~VRRP_V3_MAX_ADVER_INT_MASK) >> 12
        # asssert _rsvd == 0
        max_adver_int &= VRRP_V3_MAX_ADVER_INT_MASK

        offset = cls._MIN_LEN
        address_len = (len(buf) - offset) / count_ip
        # Address version (IPv4 or IPv6) is determined by network layer
        # header type.
        # Unfortunately it isn't available. Guess it by vrrp packet length.
        if address_len == cls._IPV4_ADDRESS_LEN:
            pack_str = '!' + cls._IPV4_ADDRESS_PACK_STR_RAW * count_ip
            conv = addrconv.ipv4.bin_to_text
        elif address_len == cls._IPV6_ADDRESS_LEN:
            pack_str = '!' + cls._IPV6_ADDRESS_PACK_STR_RAW * count_ip
            conv = addrconv.ipv6.bin_to_text
        else:
            raise ValueError(
                'unknown address version address_len %d count_ip %d' % (
                    address_len, count_ip))

        ip_addresses_bin = struct.unpack_from(pack_str, buf, offset)
        ip_addresses = map(lambda x: conv(x), ip_addresses_bin)
        msg = cls(version, type_, vrid, priority,
                  count_ip, max_adver_int, checksum, ip_addresses)
        return msg, None, buf[len(msg):]

    @staticmethod
    def serialize_static(vrrp_, prev):
        if isinstance(prev, ipv4.ipv4):
            assert type(vrrp_.ip_addresses[0]) == str
            conv = addrconv.ipv4.text_to_bin
            ip_address_pack_raw = vrrpv3._IPV4_ADDRESS_PACK_STR_RAW
        elif isinstance(prev, ipv6.ipv6):
            assert type(vrrp_.ip_addresses[0]) == str
            conv = addrconv.ipv6.text_to_bin
            ip_address_pack_raw = vrrpv3._IPV6_ADDRESS_PACK_STR_RAW
        else:
            raise ValueError('Unkown network layer %s' % type(prev))

        ip_addresses_pack_str = '!' + ip_address_pack_raw * vrrp_.count_ip
        ip_addresses_len = struct.calcsize(ip_addresses_pack_str)
        vrrp_len = vrrpv3._MIN_LEN + ip_addresses_len

        checksum = False
        if vrrp_.checksum is None:
            checksum = True
            vrrp_.checksum = 0

        buf = bytearray(vrrp_len)
        assert vrrp_.max_adver_int <= VRRP_V3_MAX_ADVER_INT_MASK
        struct.pack_into(vrrpv3._PACK_STR, buf, 0,
                         vrrp_to_version_type(vrrp_.version, vrrp_.type),
                         vrrp_.vrid, vrrp_.priority,
                         vrrp_.count_ip, vrrp_.max_adver_int, vrrp_.checksum)
        struct.pack_into(ip_addresses_pack_str, buf, vrrpv3._MIN_LEN,
                         *map(lambda x: conv(x), vrrp_.ip_addresses))

        if checksum:
            vrrp_.checksum = packet_utils.checksum_ip(prev, len(buf), buf)
            struct.pack_into(vrrpv3._CHECKSUM_PACK_STR, buf,
                             vrrpv3._CHECKSUM_OFFSET, vrrp_.checksum)
        return buf

    def is_valid(self):
        return (self.version == VRRP_VERSION_V3 and
                self.type == VRRP_TYPE_ADVERTISEMENT and
                VRRP_VRID_MIN <= self.vrid and self.vrid <= VRRP_VRID_MAX and
                VRRP_PRIORITY_MIN <= self.priority and
                self.priority <= VRRP_PRIORITY_MAX and
                VRRP_V3_MAX_ADVER_INT_MIN <= self.max_adver_int and
                self.max_adver_int <= VRRP_V3_MAX_ADVER_INT_MAX and
                self.count_ip == len(self.ip_addresses))


ipv4.ipv4.register_packet_type(vrrp, inet.IPPROTO_VRRP)
ipv6.ipv6.register_packet_type(vrrp, inet.IPPROTO_VRRP)

########NEW FILE########
__FILENAME__ = port_no
# Copyright (C) 2013 Nippon Telegraph and Telephone Corporation.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# Internal representation of port_no id is int(32bit)
# string representation is in hex without '0x'

_PORT_NO_LEN = 8
_PORT_NO_LEN_STR = str(_PORT_NO_LEN)
_PORT_NO_FMT = '%0' + _PORT_NO_LEN_STR + 'x'
PORT_NO_PATTERN = r'[0-9a-f]{%d}' % _PORT_NO_LEN


def port_no_to_str(port_no):
    return _PORT_NO_FMT % port_no


def str_to_port_no(port_no_str):
    assert len(port_no_str) == _PORT_NO_LEN
    return int(port_no_str, 16)

########NEW FILE########
__FILENAME__ = quantum_ifaces
# Copyright (C) 2012 Nippon Telegraph and Telephone Corporation.
# Copyright (C) 2012 Isaku Yamahata <yamahata at private email ne jp>
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import logging

from ryu.base import app_manager
from ryu.controller import event

LOG = logging.getLogger(__name__)


class EventQuantumIfaceSet(event.EventBase):
    def __init__(self, iface_id, key, value):
        super(EventQuantumIfaceSet, self).__init__()
        self.iface_id = iface_id
        self.key = key
        self.value = value

    def __str__(self):
        return 'EventQuantumIfaceSet<%s, %s, %s>' % (
            self.iface_id, self.key, self.value)


class QuantumIfaces(app_manager.RyuApp, dict):
    # iface-id => dict
    #    {'iface_id': {
    #         'network_id': net-id,
    #         'ports': [{'datapath_id': dpid, 'ofport': ofport, 'name': name}]
    #     }}

    KEY_NETWORK_ID = 'network_id'
    KEY_PORTS = 'ports'
    SUBKEY_DATAPATH_ID = 'datapath_id'
    SUBKEY_OFPORT = 'ofport'
    SUBKEY_NAME = 'name'

    def __init__(self):
        super(QuantumIfaces, self).__init__()
        self.name = 'quantum_ifaces'

    def register(self, iface_id):
        self.setdefault(iface_id, {})

    def unregister(self, iface_id):
        del self[iface_id]

    def get_iface_dict(self, iface_id):
        return self[iface_id]

    def list_keys(self, iface_id):
        return self[iface_id].keys()

    def get_key(self, iface_id, key):
        return self[iface_id][key]

    def _update_key(self, iface_id, key, value):
        if key == self.KEY_PORTS:
            ports = self[iface_id].setdefault(key, [])
            try:
                ports.remove(value)
            except ValueError:
                pass
            ports.append(value)
        else:
            self[iface_id][key] = value
        self.send_event_to_observers(
            EventQuantumIfaceSet(iface_id, key, value))

    def set_key(self, iface_id, key, value):
        iface = self.setdefault(iface_id, {})
        if key in iface:
            raise ValueError('trying to set already existing value '
                             '%s %s -> %s', key, iface[key], value)
        self._update_key(iface_id, key, value)

    def update_key(self, iface_id, key, value):
        iface = self.setdefault(iface_id, {})
        if key in iface:
            err = False
            if key == self.KEY_PORTS:
                dpid = value.get(self.SUBKEY_DATAPATH_ID)
                ofport = value.get(self.SUBKEY_OFPORT)
                name = value.get(self.SUBKEY_NAME)
                if not dpid or not ofport or not name:
                    raise ValueError(
                        'invalid port data: dpid=%s ofport=%s name=%s',
                        dpid, ofport, name)
                for p in iface[key]:
                    if (p[self.SUBKEY_DATAPATH_ID] == dpid and
                        (p[self.SUBKEY_OFPORT] != ofport or
                         p[self.SUBKEY_NAME] != name)):
                        err = True
                        break
            elif iface[key] != value:
                err = True
            if err:
                raise ValueError('unmatched updated %s %s -> %s',
                                 key, iface[key], value)
        self._update_key(iface_id, key, value)

    def del_key(self, iface_id, key, value=None):
        if iface_id not in self or key not in self[iface_id]:
            return

        if key != self.KEY_PORTS:
            assert value is None
            del self[iface_id][key]
            return

        ports = self[iface_id][key]
        try:
            ports.remove(value)
        except ValueError:
            pass
        if not ports:
            del self[iface_id][key]
            return
        return True

########NEW FILE########
__FILENAME__ = stplib
# Copyright (C) 2013 Nippon Telegraph and Telephone Corporation.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.


import logging

from ryu.base import app_manager
from ryu.controller import event
from ryu.controller import handler
from ryu.controller import ofp_event
from ryu.controller.handler import set_ev_cls
from ryu.exception import RyuException
from ryu.exception import OFPUnknownVersion
from ryu.lib import hub
from ryu.lib.dpid import dpid_to_str
from ryu.lib.packet import bpdu
from ryu.lib.packet import ethernet
from ryu.lib.packet import llc
from ryu.lib.packet import packet
from ryu.ofproto import ofproto_v1_0


STP_EV_DISPATCHER = "stplib"


MAX_PORT_NO = 0xfff

# Result of compared config BPDU priority.
SUPERIOR = -1
REPEATED = 0
INFERIOR = 1

# Port role
DESIGNATED_PORT = 0  # The port which sends BPDU.
ROOT_PORT = 1  # The port which receives BPDU from a root bridge.
NON_DESIGNATED_PORT = 2  # The port which blocked.

""" How to decide the port roles.

     Root bridge:
       a bridge has smallest bridge ID is chosen as a root.
       it sends original config BPDU.
     Non Root bridge:
       forwards config BPDU received from the root bridge.

                   +-----------------------+
                   |      Root bridge      |
                   +-----------------------+
                     (D)               (D)
                      |                 |
                      |                 |
                     (R)               (R)
        +-----------------+          +-----------------+
        | Non Root bridge |(D)---(ND)| Non Root bridge |
        +-----------------+          +-----------------+

     ROOT_PORT(R):
       the nearest port to a root bridge of the bridge.
       it is determined by the cost of the path, etc.
     DESIGNATED_PORT(D):
       the port of the side near the root bridge of each link.
       it is determined by the cost of the path, etc.
     NON_DESIGNATED_PORT(ND):
       the port other than a ROOT_PORT and DESIGNATED_PORT.
"""


# Port state
#  DISABLE: Administratively down or link down by an obstacle.
#  BLOCK  : Not part of spanning tree.
#  LISTEN : Not learning or relaying frames.
#  LEARN  : Learning but not relaying frames.
#  FORWARD: Learning and relaying frames.
PORT_STATE_DISABLE = (ofproto_v1_0.OFPPC_NO_RECV_STP
                      | ofproto_v1_0.OFPPC_NO_RECV
                      | ofproto_v1_0.OFPPC_NO_FLOOD
                      | ofproto_v1_0.OFPPC_NO_FWD)
PORT_STATE_BLOCK = (ofproto_v1_0.OFPPC_NO_RECV
                    | ofproto_v1_0.OFPPC_NO_FLOOD
                    | ofproto_v1_0.OFPPC_NO_FWD)
PORT_STATE_LISTEN = (ofproto_v1_0.OFPPC_NO_RECV
                     | ofproto_v1_0.OFPPC_NO_FLOOD)
PORT_STATE_LEARN = ofproto_v1_0.OFPPC_NO_FLOOD
PORT_STATE_FORWARD = 0

""" Port state machine

    +------------------------<--------------------------+
    |                                                   |*2
    +--> [BLOCK] -----+--> [LISTEN] ----> [LEARN] ------+----> [FORWARD]
                  *3  |        |    15sec    |    15sec   *1       |
                      |        |*3           |*3                   |*3
                      +----<---+------<------+----------<----------+

          *1 if port role == DESIGNATED_PORT or ROOT_PORT
          *2 if port role == NON_DESIGNATED_PORT
          *3 re-calculation of Spanning tree occurred.

      When bridge has started, each port state is set to [LISTEN]
       except port configuration is disable.
      If port configuration is disable or link down occurred,
       the port state is set to [DISABLE]
"""


# Throw this event when network topology is changed.
# Flush filtering database, when you receive this event.
class EventTopologyChange(event.EventBase):
    def __init__(self, dp):
        super(EventTopologyChange, self).__init__()
        self.dp = dp


# Throw this event when port status is changed.
class EventPortStateChange(event.EventBase):
    def __init__(self, dp, port):
        super(EventPortStateChange, self).__init__()

        of_state = {PORT_STATE_DISABLE: ofproto_v1_0.OFPPS_LINK_DOWN,
                    PORT_STATE_BLOCK: ofproto_v1_0.OFPPS_STP_BLOCK,
                    PORT_STATE_LISTEN: ofproto_v1_0.OFPPS_STP_LISTEN,
                    PORT_STATE_LEARN: ofproto_v1_0.OFPPS_STP_LEARN,
                    PORT_STATE_FORWARD: ofproto_v1_0.OFPPS_STP_FORWARD}

        self.dp = dp
        self.port_no = port.ofport.port_no
        self.port_state = of_state[port.state]


# Event for receive packet in message except BPDU packet.
class EventPacketIn(event.EventBase):
    def __init__(self, msg):
        super(EventPacketIn, self).__init__()
        self.msg = msg


class Stp(app_manager.RyuApp):
    """ STP(spanning tree) library. """

    OFP_VERSIONS = [ofproto_v1_0.OFP_VERSION]

    def __init__(self):
        super(Stp, self).__init__()
        self.name = 'stplib'
        self._set_logger()
        self.config = {}
        self.bridge_list = {}

    def close(self):
        for dpid in self.bridge_list.keys():
            self._unregister_bridge(dpid)

    def _set_logger(self):
        self.logger.propagate = False
        hdlr = logging.StreamHandler()
        fmt_str = '[STP][%(levelname)s] dpid=%(dpid)s: %(message)s'
        hdlr.setFormatter(logging.Formatter(fmt_str))
        self.logger.addHandler(hdlr)

    def set_config(self, config):
        """ Use this API if you want to set up configuration
             of each bridge and ports.
            Set configuration with 'config' parameter as follows.

             config = {<dpid>: {'bridge': {'priority': <value>,
                                           'sys_ext_id': <value>,
                                           'max_age': <value>,
                                           'hello_time': <value>,
                                           'fwd_delay': <value>}
                                'ports': {<port_no>: {'priority': <value>,
                                                      'path_cost': <value>,
                                                      'enable': <True/False>},
                                          <port_no>: {...},,,}}
                       <dpid>: {...},
                       <dpid>: {...},,,}

             NOTE: You may omit each field.
                    If omitted, a default value is set up.
                   It becomes effective when a bridge starts.

             Default values:
             ------------------------------------------------------
             | bridge | priority   | bpdu.DEFAULT_BRIDGE_PRIORITY |
             |        | sys_ext_id | 0                            |
             |        | max_age    | bpdu.DEFAULT_MAX_AGE         |
             |        | hello_time | bpdu.DEFAULT_HELLO_TIME      |
             |        | fwd_delay  | bpdu.DEFAULT_FORWARD_DELAY   |
             |--------|------------|------------------------------|
             | port   | priority   | bpdu.DEFAULT_PORT_PRIORITY   |
             |        | path_cost  | (Set up automatically        |
             |        |            |   according to link speed.)  |
             |        | enable     | True                         |
             ------------------------------------------------------
        """
        assert isinstance(config, dict)
        self.config = config

    @set_ev_cls(ofp_event.EventOFPStateChange,
                [handler.MAIN_DISPATCHER, handler.DEAD_DISPATCHER])
    def dispacher_change(self, ev):
        assert ev.datapath is not None
        if ev.state == handler.MAIN_DISPATCHER:
            self._register_bridge(ev.datapath)
        elif ev.state == handler.DEAD_DISPATCHER:
            self._unregister_bridge(ev.datapath.id)

    def _register_bridge(self, dp):
        self._unregister_bridge(dp.id)

        dpid_str = {'dpid': dpid_to_str(dp.id)}
        self.logger.info('Join as stp bridge.', extra=dpid_str)
        try:
            bridge = Bridge(dp, self.logger,
                            self.config.get(dp.id, {}),
                            self.send_event_to_observers)
        except OFPUnknownVersion as message:
            self.logger.error(str(message), extra=dpid_str)
            return

        self.bridge_list[dp.id] = bridge

    def _unregister_bridge(self, dp_id):
        if dp_id in self.bridge_list:
            self.bridge_list[dp_id].delete()
            del self.bridge_list[dp_id]
            self.logger.info('Leave stp bridge.',
                             extra={'dpid': dpid_to_str(dp_id)})

    @set_ev_cls(ofp_event.EventOFPPacketIn, handler.MAIN_DISPATCHER)
    def packet_in_handler(self, ev):
        if ev.msg.datapath.id in self.bridge_list:
            bridge = self.bridge_list[ev.msg.datapath.id]
            bridge.packet_in_handler(ev.msg)

    @set_ev_cls(ofp_event.EventOFPPortStatus, handler.MAIN_DISPATCHER)
    def port_status_handler(self, ev):
        dp = ev.msg.datapath
        dpid_str = {'dpid': dpid_to_str(dp.id)}
        port = ev.msg.desc
        reason = ev.msg.reason
        link_down_flg = port.state & 0b1

        if dp.id in self.bridge_list:
            bridge = self.bridge_list[dp.id]

            if reason is dp.ofproto.OFPPR_ADD:
                self.logger.info('[port=%d] Port add.',
                                 port.port_no, extra=dpid_str)
                bridge.port_add(port)
            elif reason is dp.ofproto.OFPPR_DELETE:
                self.logger.info('[port=%d] Port delete.',
                                 port.port_no, extra=dpid_str)
                bridge.port_delete(port.port_no)
            else:
                assert reason is dp.ofproto.OFPPR_MODIFY
                if link_down_flg:
                    self.logger.info('[port=%d] Link down.',
                                     port.port_no, extra=dpid_str)
                    bridge.link_down(port.port_no)
                else:
                    self.logger.info('[port=%d] Link up.',
                                     port.port_no, extra=dpid_str)
                    bridge.link_up(port.port_no)

    @staticmethod
    def compare_root_path(path_cost1, path_cost2, bridge_id1, bridge_id2,
                          port_id1, port_id2):
        """ Decide the port of the side near a root bridge.
            It is compared by the following priorities.
             1. root path cost
             2. designated bridge ID value
             3. designated port ID value """
        result = Stp._cmp_value(path_cost1, path_cost2)
        if not result:
            result = Stp._cmp_value(bridge_id1, bridge_id2)
            if not result:
                result = Stp._cmp_value(port_id1, port_id2)
        return result

    @staticmethod
    def compare_bpdu_info(my_priority, my_times, rcv_priority, rcv_times):
        """ Check received BPDU is superior to currently held BPDU
             by the following comparison.
             - root bridge ID value
             - root path cost
             - designated bridge ID value
             - designated port ID value
             - times """
        if my_priority is None:
            result = SUPERIOR
        else:
            result = Stp._cmp_value(rcv_priority.root_id.value,
                                    my_priority.root_id.value)
            if not result:
                result = Stp.compare_root_path(
                    rcv_priority.root_path_cost,
                    my_priority.root_path_cost,
                    rcv_priority.designated_bridge_id.value,
                    my_priority.designated_bridge_id.value,
                    rcv_priority.designated_port_id.value,
                    my_priority.designated_port_id.value)
                if not result:
                    result1 = Stp._cmp_value(
                        rcv_priority.designated_bridge_id.value,
                        my_priority.designated_bridge_id.mac_addr)
                    result2 = Stp._cmp_value(
                        rcv_priority.designated_port_id.value,
                        my_priority.designated_port_id.port_no)
                    if not result1 and not result2:
                        result = SUPERIOR
                    else:
                        result = Stp._cmp_obj(rcv_times, my_times)
        return result

    @staticmethod
    def _cmp_value(value1, value2):
        result = cmp(value1, value2)
        if result < 0:
            return SUPERIOR
        elif result == 0:
            return REPEATED
        else:
            return INFERIOR

    @staticmethod
    def _cmp_obj(obj1, obj2):
        for key in obj1.__dict__.keys():
            if (not hasattr(obj2, key)
                    or getattr(obj1, key) != getattr(obj2, key)):
                return SUPERIOR
        return REPEATED


class Bridge(object):
    _DEFAULT_VALUE = {'priority': bpdu.DEFAULT_BRIDGE_PRIORITY,
                      'sys_ext_id': 0,
                      'max_age': bpdu.DEFAULT_MAX_AGE,
                      'hello_time': bpdu.DEFAULT_HELLO_TIME,
                      'fwd_delay': bpdu.DEFAULT_FORWARD_DELAY}

    def __init__(self, dp, logger, config, send_ev_func):
        super(Bridge, self).__init__()
        self.dp = dp
        self.logger = logger
        self.dpid_str = {'dpid': dpid_to_str(dp.id)}
        self.send_event = send_ev_func

        # Bridge data
        bridge_conf = config.get('bridge', {})
        values = self._DEFAULT_VALUE
        for key, value in bridge_conf.items():
            values[key] = value
        system_id = dp.ports.values()[0].hw_addr

        self.bridge_id = BridgeId(values['priority'],
                                  values['sys_ext_id'],
                                  system_id)
        self.bridge_times = Times(0,  # message_age
                                  values['max_age'],
                                  values['hello_time'],
                                  values['fwd_delay'])
        # Root bridge data
        self.root_priority = Priority(self.bridge_id, 0, None, None)
        self.root_times = self.bridge_times
        # Ports
        self.ports = {}
        self.ports_conf = config.get('ports', {})
        for ofport in dp.ports.values():
            self.port_add(ofport)

    @property
    def is_root_bridge(self):
        return bool(self.bridge_id.value == self.root_priority.root_id.value)

    def delete(self):
        for port in self.ports.values():
            port.delete()

    def port_add(self, ofport):
        if ofport.port_no <= MAX_PORT_NO:
            port_conf = self.ports_conf.get(ofport.port_no, {})
            self.ports[ofport.port_no] = Port(self.dp, self.logger,
                                              port_conf, self.send_event,
                                              self.recalculate_spanning_tree,
                                              self.topology_change_notify,
                                              self.bridge_id,
                                              self.bridge_times,
                                              ofport)

    def port_delete(self, port_no):
        self.link_down(port_no)
        self.ports[port_no].delete()
        del self.ports[port_no]

    def link_up(self, port_no):
        port = self.ports[port_no]
        port.up(DESIGNATED_PORT, self.root_priority, self.root_times)

    def link_down(self, port_no):
        """ DESIGNATED_PORT/NON_DESIGNATED_PORT: change status to DISABLE.
            ROOT_PORT: change status to DISABLE and recalculate STP. """
        port = self.ports[port_no]
        init_stp_flg = bool(port.role is ROOT_PORT)

        port.down(PORT_STATE_DISABLE, msg_init=True)
        if init_stp_flg:
            self.recalculate_spanning_tree()

    def packet_in_handler(self, msg):
        if not msg.in_port in self.ports:
            return

        pkt = packet.Packet(msg.data)
        in_port = self.ports[msg.in_port]

        if bpdu.ConfigurationBPDUs in pkt:
            """ Receive Configuration BPDU.
                 - If receive superior BPDU:
                    re-caluculation of spanning tree.
                 - If receive Topology Change BPDU:
                    throw EventTopologyChange.
                    forward Topology Change BPDU. """
            (bpdu_pkt, ) = pkt.get_protocols(bpdu.ConfigurationBPDUs)
            if bpdu_pkt.message_age > bpdu_pkt.max_age:
                log_msg = 'Drop BPDU packet which message_age exceeded.'
                self.logger.debug(log_msg, extra=self.dpid_str)
                return

            rcv_info, rcv_tc = in_port.rcv_config_bpdu(bpdu_pkt)

            if rcv_info is SUPERIOR:
                self.logger.info('[port=%d] Receive superior BPDU.',
                                 msg.in_port, extra=self.dpid_str)
                self.recalculate_spanning_tree(init=False)

            elif rcv_tc:
                self.send_event(EventTopologyChange(self.dp))

            if in_port.role is ROOT_PORT:
                self._forward_tc_bpdu(rcv_tc)

        elif bpdu.TopologyChangeNotificationBPDUs in pkt:
            """ Receive Topology Change Notification BPDU.
                 send Topology Change Ack BPDU.
                 throw EventTopologyChange.
                 - Root bridge:
                    send Topology Change BPDU from all port.
                 - Non root bridge:
                    send Topology Change Notification BPDU to root bridge. """
            in_port.transmit_ack_bpdu()
            self.topology_change_notify(None)

        elif bpdu.RstBPDUs in pkt:
            """ Receive Rst BPDU. """
            #TODO: RSTP
            pass

        else:
            """ Receive non BPDU packet.
                 throw EventPacketIn. """
            self.send_event(EventPacketIn(msg))

    def recalculate_spanning_tree(self, init=True):
        """ Re-calculation of spanning tree. """
        # All port down.
        for port in self.ports.values():
            if port.state is not PORT_STATE_DISABLE:
                port.down(PORT_STATE_BLOCK, msg_init=init)

        # Send topology change event.
        if init:
            self.send_event(EventTopologyChange(self.dp))

        # Update tree roles.
        port_roles = {}
        self.root_priority = Priority(self.bridge_id, 0, None, None)
        self.root_times = self.bridge_times

        if init:
            self.logger.info('Root bridge.', extra=self.dpid_str)
            for port_no in self.ports.keys():
                port_roles[port_no] = DESIGNATED_PORT
        else:
            (port_roles,
             self.root_priority,
             self.root_times) = self._spanning_tree_algorithm()

        # All port up.
        for port_no, role in port_roles.items():
            if self.ports[port_no].state is not PORT_STATE_DISABLE:
                self.ports[port_no].up(role, self.root_priority,
                                       self.root_times)

    def _spanning_tree_algorithm(self):
        """ Update tree roles.
             - Root bridge:
                all port is DESIGNATED_PORT.
             - Non root bridge:
                select one ROOT_PORT and some DESIGNATED_PORT,
                and the other port is set to NON_DESIGNATED_PORT."""
        port_roles = {}

        root_port = self._select_root_port()

        if root_port is None:
            # My bridge is a root bridge.
            self.logger.info('Root bridge.', extra=self.dpid_str)
            root_priority = self.root_priority
            root_times = self.root_times

            for port_no in self.ports.keys():
                if self.ports[port_no].state is not PORT_STATE_DISABLE:
                    port_roles[port_no] = DESIGNATED_PORT
        else:
            # Other bridge is a root bridge.
            self.logger.info('Non root bridge.', extra=self.dpid_str)
            root_priority = root_port.designated_priority
            root_times = root_port.designated_times

            port_roles[root_port.ofport.port_no] = ROOT_PORT

            d_ports = self._select_designated_port(root_port)
            for port_no in d_ports:
                port_roles[port_no] = DESIGNATED_PORT

            for port in self.ports.values():
                if port.state is not PORT_STATE_DISABLE:
                    port_roles.setdefault(port.ofport.port_no,
                                          NON_DESIGNATED_PORT)

        return port_roles, root_priority, root_times

    def _select_root_port(self):
        """ ROOT_PORT is the nearest port to a root bridge.
            It is determined by the cost of path, etc. """
        root_port = None

        for port in self.ports.values():
            root_msg = (self.root_priority if root_port is None
                        else root_port.designated_priority)
            port_msg = port.designated_priority
            if port.state is PORT_STATE_DISABLE or port_msg is None:
                continue
            if root_msg.root_id.value > port_msg.root_id.value:
                result = SUPERIOR
            elif root_msg.root_id.value == port_msg.root_id.value:
                if root_msg.designated_bridge_id is None:
                    result = INFERIOR
                else:
                    result = Stp.compare_root_path(
                        port_msg.root_path_cost,
                        root_msg.root_path_cost,
                        port_msg.designated_bridge_id.value,
                        root_msg.designated_bridge_id.value,
                        port_msg.designated_port_id.value,
                        root_msg.designated_port_id.value)
            else:
                result = INFERIOR

            if result is SUPERIOR:
                root_port = port

        return root_port

    def _select_designated_port(self, root_port):
        """ DESIGNATED_PORT is a port of the side near the root bridge
            of each link. It is determined by the cost of each path, etc
            same as ROOT_PORT. """
        d_ports = []
        root_msg = root_port.designated_priority

        for port in self.ports.values():
            port_msg = port.designated_priority
            if (port.state is PORT_STATE_DISABLE
                    or port.ofport.port_no == root_port.ofport.port_no):
                continue
            if (port_msg is None or
                    (port_msg.root_id.value != root_msg.root_id.value)):
                d_ports.append(port.ofport.port_no)
            else:
                result = Stp.compare_root_path(
                    root_msg.root_path_cost,
                    port_msg.root_path_cost - port.path_cost,
                    self.bridge_id.value,
                    port_msg.designated_bridge_id.value,
                    port.port_id.value,
                    port_msg.designated_port_id.value)
                if result is SUPERIOR:
                    d_ports.append(port.ofport.port_no)

        return d_ports

    def topology_change_notify(self, port_state):
        notice = False
        if port_state is PORT_STATE_FORWARD:
            for port in self.ports.values():
                if port.role is DESIGNATED_PORT:
                    notice = True
                    break
        else:
            notice = True

        if notice:
            self.send_event(EventTopologyChange(self.dp))
            if self.is_root_bridge:
                self._transmit_tc_bpdu()
            else:
                self._transmit_tcn_bpdu()

    def _transmit_tc_bpdu(self):
        for port in self.ports.values():
            port.transmit_tc_bpdu()

    def _transmit_tcn_bpdu(self):
        root_port = None
        for port in self.ports.values():
            if port.role is ROOT_PORT:
                root_port = port
                break
        if root_port:
            root_port.transmit_tcn_bpdu()

    def _forward_tc_bpdu(self, fwd_flg):
        for port in self.ports.values():
            port.send_tc_flg = fwd_flg


class Port(object):
    _DEFAULT_VALUE = {'priority': bpdu.DEFAULT_PORT_PRIORITY,
                      'path_cost': bpdu.PORT_PATH_COST_10MB,
                      'enable': True}

    _PATH_COST = {ofproto_v1_0.OFPPF_10MB_HD: bpdu.PORT_PATH_COST_10MB,
                  ofproto_v1_0.OFPPF_10MB_FD: bpdu.PORT_PATH_COST_10MB,
                  ofproto_v1_0.OFPPF_100MB_HD: bpdu.PORT_PATH_COST_100MB,
                  ofproto_v1_0.OFPPF_100MB_FD: bpdu.PORT_PATH_COST_100MB,
                  ofproto_v1_0.OFPPF_1GB_HD: bpdu.PORT_PATH_COST_1GB,
                  ofproto_v1_0.OFPPF_1GB_FD: bpdu.PORT_PATH_COST_1GB,
                  ofproto_v1_0.OFPPF_10GB_FD: bpdu.PORT_PATH_COST_10GB}

    def __init__(self, dp, logger, config, send_ev_func, timeout_func,
                 topology_change_func, bridge_id, bridge_times, ofport):
        super(Port, self).__init__()
        self.dp = dp
        self.logger = logger
        self.dpid_str = {'dpid': dpid_to_str(dp.id)}
        self.config_enable = config.get('enable',
                                        self._DEFAULT_VALUE['enable'])
        self.send_event = send_ev_func
        self.wait_bpdu_timeout = timeout_func
        self.topology_change_notify = topology_change_func
        self.ofctl = OfCtl_v1_0(dp)

        # Bridge data
        self.bridge_id = bridge_id
        # Root bridge data
        self.port_priority = None
        self.port_times = None
        # ofproto_v1_0_parser.OFPPhyPort data
        self.ofport = ofport
        # Port data
        values = self._DEFAULT_VALUE
        for rate in sorted(self._PATH_COST.keys(), reverse=True):
            if ofport.curr & rate:
                values['path_cost'] = self._PATH_COST[rate]
                break
        for key, value in values.items():
            values[key] = value
        self.port_id = PortId(values['priority'], ofport.port_no)
        self.path_cost = values['path_cost']
        self.state = (None if self.config_enable else PORT_STATE_DISABLE)
        self.role = None
        # Receive BPDU data
        self.designated_priority = None
        self.designated_times = None
        # BPDU handling threads
        self.send_bpdu_thread = PortThread(self._transmit_config_bpdu)
        self.wait_bpdu_thread = PortThread(self._wait_bpdu_timer)
        self.send_tc_thread = PortThread(self._transmit_tc_bpdu)
        self.send_tcn_thread = PortThread(self._transmit_tcn_bpdu)
        self.send_tc_flg = None
        self.send_tcn_flg = None
        self.wait_timer_event = None
        # State machine thread
        self.state_machine = PortThread(self._state_machine)
        self.state_event = None

        self.up(DESIGNATED_PORT,
                Priority(bridge_id, 0, None, None),
                bridge_times)

        self.state_machine.start()
        self.logger.debug('[port=%d] Start port state machine.',
                          self.ofport.port_no, extra=self.dpid_str)

    def delete(self):
        self.state_machine.stop()
        self.send_bpdu_thread.stop()
        self.wait_bpdu_thread.stop()
        self.send_tc_thread.stop()
        self.send_tcn_thread.stop()
        if self.state_event is not None:
            self.state_event.set()
            self.state_event = None
        if self.wait_timer_event is not None:
            self.wait_timer_event.set()
            self.wait_timer_event = None
        self.logger.debug('[port=%d] Stop port threads.',
                          self.ofport.port_no, extra=self.dpid_str)

    def up(self, role, root_priority, root_times):
        """ A port is started in the state of LISTEN.  """
        self.port_priority = root_priority
        self.port_times = root_times

        state = (PORT_STATE_LISTEN if self.config_enable
                 else PORT_STATE_DISABLE)
        self._change_role(role)
        self._change_status(state)

    def down(self, state, msg_init=False):
        """ A port will be in the state of DISABLE or BLOCK,
             and be stopped.  """
        assert (state is PORT_STATE_DISABLE
                or state is PORT_STATE_BLOCK)
        if not self.config_enable:
            return

        if msg_init:
            self.designated_priority = None
            self.designated_times = None

        self._change_role(DESIGNATED_PORT)
        self._change_status(state)

    def _state_machine(self):
        """ Port state machine.
             Change next status when timer is exceeded
             or _change_status() method is called."""
        role_str = {ROOT_PORT: 'ROOT_PORT          ',
                    DESIGNATED_PORT: 'DESIGNATED_PORT    ',
                    NON_DESIGNATED_PORT: 'NON_DESIGNATED_PORT'}
        state_str = {PORT_STATE_DISABLE: 'DISABLE',
                     PORT_STATE_BLOCK: 'BLOCK',
                     PORT_STATE_LISTEN: 'LISTEN',
                     PORT_STATE_LEARN: 'LEARN',
                     PORT_STATE_FORWARD: 'FORWARD'}

        if self.state is PORT_STATE_DISABLE:
            self.ofctl.set_port_status(self.ofport, self.state)

        while True:
            self.logger.info('[port=%d] %s / %s', self.ofport.port_no,
                             role_str[self.role], state_str[self.state],
                             extra=self.dpid_str)

            self.state_event = hub.Event()
            timer = self._get_timer()
            if timer:
                timeout = hub.Timeout(timer)
                try:
                    self.state_event.wait()
                except hub.Timeout as t:
                    if t is not timeout:
                        err_msg = 'Internal error. Not my timeout.'
                        raise RyuException(msg=err_msg)
                    new_state = self._get_next_state()
                    self._change_status(new_state, thread_switch=False)
                finally:
                    timeout.cancel()
            else:
                self.state_event.wait()

            self.state_event = None

    def _get_timer(self):
        timer = {PORT_STATE_DISABLE: None,
                 PORT_STATE_BLOCK: None,
                 PORT_STATE_LISTEN: self.port_times.forward_delay,
                 PORT_STATE_LEARN: self.port_times.forward_delay,
                 PORT_STATE_FORWARD: None}
        return timer[self.state]

    def _get_next_state(self):
        next_state = {PORT_STATE_DISABLE: None,
                      PORT_STATE_BLOCK: None,
                      PORT_STATE_LISTEN: PORT_STATE_LEARN,
                      PORT_STATE_LEARN: (PORT_STATE_FORWARD
                                         if (self.role is ROOT_PORT or
                                             self.role is DESIGNATED_PORT)
                                         else PORT_STATE_BLOCK),
                      PORT_STATE_FORWARD: None}
        return next_state[self.state]

    def _change_status(self, new_state, thread_switch=True):
        if new_state is not PORT_STATE_DISABLE:
            self.ofctl.set_port_status(self.ofport, new_state)

        if(new_state is PORT_STATE_FORWARD or
                (self.state is PORT_STATE_FORWARD and
                    (new_state is PORT_STATE_DISABLE or
                     new_state is PORT_STATE_BLOCK))):
            self.topology_change_notify(new_state)

        if (new_state is PORT_STATE_DISABLE
                or new_state is PORT_STATE_BLOCK):
            self.send_tc_flg = False
            self.send_tcn_flg = False
            self.send_bpdu_thread.stop()
            self.send_tc_thread.stop()
            self.send_tcn_thread.stop()
        elif new_state is PORT_STATE_LISTEN:
            self.send_bpdu_thread.start()

        self.state = new_state
        self.send_event(EventPortStateChange(self.dp, self))

        if self.state_event is not None:
            self.state_event.set()
            self.state_event = None
        if thread_switch:
            hub.sleep(0)  # For thread switching.

    def _change_role(self, new_role):
        if self.role is new_role:
            return
        self.role = new_role
        if (new_role is ROOT_PORT
                or new_role is NON_DESIGNATED_PORT):
            self.wait_bpdu_thread.start()
        else:
            assert new_role is DESIGNATED_PORT
            self.wait_bpdu_thread.stop()

    def rcv_config_bpdu(self, bpdu_pkt):
        # Check received BPDU is superior to currently held BPDU.
        root_id = BridgeId(bpdu_pkt.root_priority,
                           bpdu_pkt.root_system_id_extension,
                           bpdu_pkt.root_mac_address)
        root_path_cost = bpdu_pkt.root_path_cost
        designated_bridge_id = BridgeId(bpdu_pkt.bridge_priority,
                                        bpdu_pkt.bridge_system_id_extension,
                                        bpdu_pkt.bridge_mac_address)
        designated_port_id = PortId(bpdu_pkt.port_priority,
                                    bpdu_pkt.port_number)

        msg_priority = Priority(root_id, root_path_cost,
                                designated_bridge_id,
                                designated_port_id)
        msg_times = Times(bpdu_pkt.message_age,
                          bpdu_pkt.max_age,
                          bpdu_pkt.hello_time,
                          bpdu_pkt.forward_delay)

        rcv_info = Stp.compare_bpdu_info(self.designated_priority,
                                         self.designated_times,
                                         msg_priority, msg_times)
        if rcv_info is SUPERIOR:
            self.designated_priority = msg_priority
            self.designated_times = msg_times

        chk_flg = False
        if ((rcv_info is SUPERIOR or rcv_info is REPEATED)
                and (self.role is ROOT_PORT
                     or self.role is NON_DESIGNATED_PORT)):
            self._update_wait_bpdu_timer()
            chk_flg = True
        elif(rcv_info is INFERIOR and self.role is DESIGNATED_PORT):
            chk_flg = True

        # Check TopologyChange flag.
        rcv_tc = False
        if chk_flg:
            tc_flag_mask = 0b00000001
            tcack_flag_mask = 0b10000000
            if bpdu_pkt.flags & tc_flag_mask:
                self.logger.debug('[port=%d] receive TopologyChange BPDU.',
                                  self.ofport.port_no, extra=self.dpid_str)
                rcv_tc = True
            if bpdu_pkt.flags & tcack_flag_mask:
                self.logger.debug('[port=%d] receive TopologyChangeAck BPDU.',
                                  self.ofport.port_no, extra=self.dpid_str)
                if self.send_tcn_flg:
                    self.send_tcn_flg = False

        return rcv_info, rcv_tc

    def _update_wait_bpdu_timer(self):
        if self.wait_timer_event is not None:
            self.wait_timer_event.set()
            self.wait_timer_event = None
        hub.sleep(0)  # For thread switching.

    def _wait_bpdu_timer(self):
        time_exceed = False

        while True:
            self.wait_timer_event = hub.Event()
            message_age = (self.designated_times.message_age
                           if self.designated_times else 0)
            timer = self.port_times.max_age - message_age
            timeout = hub.Timeout(timer)
            try:
                self.wait_timer_event.wait()
            except hub.Timeout as t:
                if t is not timeout:
                    err_msg = 'Internal error. Not my timeout.'
                    raise RyuException(msg=err_msg)
                self.logger.info('[port=%d] Wait BPDU timer is exceeded.',
                                 self.ofport.port_no, extra=self.dpid_str)
                time_exceed = True
            finally:
                timeout.cancel()
                self.wait_timer_event = None

            if time_exceed:
                break

        if time_exceed:  # Bridge.recalculate_spanning_tree
            hub.spawn(self.wait_bpdu_timeout)

    def _transmit_config_bpdu(self):
        """ Send config BPDU packet if port role is DESIGNATED_PORT. """
        while True:
            if self.role == DESIGNATED_PORT:
                flags = 0b00000000
                log_msg = '[port=%d] Send Config BPDU.'
                if self.send_tc_flg:
                    flags = 0b00000001
                    log_msg = '[port=%d] Send TopologyChange BPDU.'
                bpdu_data = self._generate_config_bpdu(flags)
                self.ofctl.send_packet_out(self.ofport.port_no, bpdu_data)
                self.logger.debug(log_msg, self.ofport.port_no,
                                  extra=self.dpid_str)
            hub.sleep(self.port_times.hello_time)

    def transmit_tc_bpdu(self):
        self.send_tc_thread.start()

    def _transmit_tc_bpdu(self):
        """ Set send_tc_flg to send Topology Change BPDU. """
        timer = self.port_times.max_age + self.port_times.forward_delay

        self.send_tc_flg = True
        hub.sleep(timer)
        self.send_tc_flg = False

    def transmit_ack_bpdu(self):
        """ Send Topology Change Ack BPDU. """
        ack_flags = 0b10000001
        bpdu_data = self._generate_config_bpdu(ack_flags)
        self.ofctl.send_packet_out(self.ofport.port_no, bpdu_data)

    def transmit_tcn_bpdu(self):
        self.send_tcn_thread.start()

    def _transmit_tcn_bpdu(self):
        """ Send Topology Change Notification BPDU until receive Ack. """
        self.send_tcn_flg = True
        local_hello_time = bpdu.DEFAULT_HELLO_TIME
        while self.send_tcn_flg:
            bpdu_data = self._generate_tcn_bpdu()
            self.ofctl.send_packet_out(self.ofport.port_no, bpdu_data)
            self.logger.debug('[port=%d] Send TopologyChangeNotify BPDU.',
                              self.ofport.port_no, extra=self.dpid_str)
            hub.sleep(local_hello_time)

    def _generate_config_bpdu(self, flags):
        src_mac = self.ofport.hw_addr
        dst_mac = bpdu.BRIDGE_GROUP_ADDRESS
        length = (bpdu.bpdu._PACK_LEN + bpdu.ConfigurationBPDUs.PACK_LEN
                  + llc.llc._PACK_LEN + llc.ControlFormatU._PACK_LEN)

        e = ethernet.ethernet(dst_mac, src_mac, length)
        l = llc.llc(llc.SAP_BPDU, llc.SAP_BPDU, llc.ControlFormatU())
        b = bpdu.ConfigurationBPDUs(
            flags=flags,
            root_priority=self.port_priority.root_id.priority,
            root_mac_address=self.port_priority.root_id.mac_addr,
            root_path_cost=self.port_priority.root_path_cost+self.path_cost,
            bridge_priority=self.bridge_id.priority,
            bridge_mac_address=self.bridge_id.mac_addr,
            port_priority=self.port_id.priority,
            port_number=self.ofport.port_no,
            message_age=self.port_times.message_age+1,
            max_age=self.port_times.max_age,
            hello_time=self.port_times.hello_time,
            forward_delay=self.port_times.forward_delay)

        pkt = packet.Packet()
        pkt.add_protocol(e)
        pkt.add_protocol(l)
        pkt.add_protocol(b)
        pkt.serialize()

        return pkt.data

    def _generate_tcn_bpdu(self):
        src_mac = self.ofport.hw_addr
        dst_mac = bpdu.BRIDGE_GROUP_ADDRESS
        length = (bpdu.bpdu._PACK_LEN
                  + bpdu.TopologyChangeNotificationBPDUs.PACK_LEN
                  + llc.llc._PACK_LEN + llc.ControlFormatU._PACK_LEN)

        e = ethernet.ethernet(dst_mac, src_mac, length)
        l = llc.llc(llc.SAP_BPDU, llc.SAP_BPDU, llc.ControlFormatU())
        b = bpdu.TopologyChangeNotificationBPDUs()

        pkt = packet.Packet()
        pkt.add_protocol(e)
        pkt.add_protocol(l)
        pkt.add_protocol(b)
        pkt.serialize()

        return pkt.data


class PortThread(object):
    def __init__(self, function):
        super(PortThread, self).__init__()
        self.function = function
        self.thread = None

    def start(self):
        self.stop()
        self.thread = hub.spawn(self.function)

    def stop(self):
        if self.thread is not None:
            hub.kill(self.thread)
            hub.joinall([self.thread])
            self.thread = None


class BridgeId(object):
    def __init__(self, priority, system_id_extension, mac_addr):
        super(BridgeId, self).__init__()
        self.priority = priority
        self.system_id_extension = system_id_extension
        self.mac_addr = mac_addr
        self.value = bpdu.ConfigurationBPDUs.encode_bridge_id(
            priority, system_id_extension, mac_addr)


class PortId(object):
    def __init__(self, priority, port_no):
        super(PortId, self).__init__()
        self.priority = priority
        self.port_no = port_no
        self.value = bpdu.ConfigurationBPDUs.encode_port_id(priority, port_no)


class Priority(object):
    def __init__(self, root_id, root_path_cost,
                 designated_bridge_id, designated_port_id):
        super(Priority, self).__init__()
        self.root_id = root_id
        self.root_path_cost = root_path_cost
        self.designated_bridge_id = designated_bridge_id
        self.designated_port_id = designated_port_id


class Times(object):
    def __init__(self, message_age, max_age, hello_time, forward_delay):
        super(Times, self).__init__()
        self.message_age = message_age
        self.max_age = max_age
        self.hello_time = hello_time
        self.forward_delay = forward_delay


class OfCtl_v1_0(object):
    def __init__(self, dp):
        super(OfCtl_v1_0, self).__init__()
        self.dp = dp

    def send_packet_out(self, out_port, data):
        actions = [self.dp.ofproto_parser.OFPActionOutput(out_port, 0)]
        self.dp.send_packet_out(buffer_id=self.dp.ofproto.OFP_NO_BUFFER,
                                in_port=self.dp.ofproto.OFPP_CONTROLLER,
                                actions=actions, data=data)

    def set_port_status(self, port, config):
        ofproto_parser = self.dp.ofproto_parser
        mask = 0b1111111
        msg = ofproto_parser.OFPPortMod(self.dp, port.port_no, port.hw_addr,
                                        config, mask, port.advertised)
        self.dp.send_msg(msg)

########NEW FILE########
__FILENAME__ = stringify
#!/usr/bin/env python
#
# Copyright (C) 2013 Nippon Telegraph and Telephone Corporation.
# Copyright (C) 2013 YAMAMOTO Takashi <yamamoto at valinux co jp>
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import base64
import collections
import inspect


# Some arguments to __init__ is mungled in order to avoid name conflicts
# with builtin names.
# The standard mangling is to append '_' in order to avoid name clashes
# with reserved keywords.
#
# PEP8:
# Function and method arguments
#   If a function argument's name clashes with a reserved keyword,
#   it is generally better to append a single trailing underscore
#   rather than use an abbreviation or spelling corruption. Thus
#   class_ is better than clss. (Perhaps better is to avoid such
#   clashes by using a synonym.)
#
# grep __init__ *.py | grep '[^_]_\>' showed that
# 'len', 'property', 'set', 'type'
# A bit more generic way is adopted
import __builtin__
_RESERVED_KEYWORD = dir(__builtin__)


_mapdict = lambda f, d: dict([(k, f(v)) for k, v in d.items()])
_mapdict_key = lambda f, d: dict([(f(k), v) for k, v in d.items()])
_mapdict_kv = lambda f, d: dict([(k, f(k, v)) for k, v in d.items()])


class TypeDescr(object):
    pass


class AsciiStringType(TypeDescr):
    @staticmethod
    def encode(v):
        return unicode(v, 'ascii')

    @staticmethod
    def decode(v):
        return v.encode('ascii')


class Utf8StringType(TypeDescr):
    @staticmethod
    def encode(v):
        return unicode(v, 'utf-8')

    @staticmethod
    def decode(v):
        return v.encode('utf-8')


_types = {
    'ascii': AsciiStringType,
    'utf-8': Utf8StringType,
}


class StringifyMixin(object):

    _TYPE = {}
    """_TYPE class attribute is used to annotate types of attributes.

    This type information is used to find an appropriate conversion for
    a JSON style dictionary.

    Currently the following types are implemented.

    ===== ==========
    Type  Descrption
    ===== ==========
    ascii US-ASCII
    utf-8 UTF-8
    ===== ==========

    Example::
        _TYPE = {
            'ascii': [
                'hw_addr',
            ],
            'utf-8': [
                'name',
            ]
        }
    """

    _class_prefixes = []

    def stringify_attrs(self):
        """an override point for sub classes"""
        return obj_python_attrs(self)

    def __str__(self):
        # repr() to escape binaries
        return self.__class__.__name__ + '(' + \
            ','.join("%s=%s" % (k, repr(v)) for k, v in
                     self.stringify_attrs()) + ')'
    __repr__ = __str__  # note: str(list) uses __repr__ for elements

    @classmethod
    def _is_class(cls, dict_):
        # we distinguish a dict like OFPSwitchFeatures.ports
        # from OFPxxx classes using heuristics.
        # exmples of OFP classes:
        #   {"OFPMatch": { ... }}
        #   {"MTIPv6SRC": { ... }}
        assert isinstance(dict_, dict)
        if len(dict_) != 1:
            return False
        k = dict_.keys()[0]
        if not isinstance(k, (bytes, unicode)):
            return False
        for p in cls._class_prefixes:
            if k.startswith(p):
                return True
        return False

    @classmethod
    def _get_type(cls, k):
        if hasattr(cls, '_TYPE'):
            for t, attrs in cls._TYPE.iteritems():
                if k in attrs:
                    return _types[t]
        return None

    @classmethod
    def _get_encoder(cls, k, encode_string):
        t = cls._get_type(k)
        if t:
            return t.encode
        return cls._get_default_encoder(encode_string)

    @classmethod
    def _encode_value(cls, k, v, encode_string=base64.b64encode):
        return cls._get_encoder(k, encode_string)(v)

    @classmethod
    def _get_default_encoder(cls, encode_string):
        def _encode(v):
            if isinstance(v, (bytes, unicode)):
                json_value = encode_string(v)
            elif isinstance(v, list):
                json_value = map(_encode, v)
            elif isinstance(v, dict):
                json_value = _mapdict(_encode, v)
                # while a python dict key can be any hashable object,
                # a JSON object key should be a string.
                json_value = _mapdict_key(str, json_value)
                assert not cls._is_class(json_value)
            else:
                try:
                    json_value = v.to_jsondict()
                except:
                    json_value = v
            return json_value
        return _encode

    def to_jsondict(self, encode_string=base64.b64encode):
        """
        This method returns a JSON style dict to describe this object.

        The returned dict is compatible with json.dumps() and json.loads().

        Suppose ClassName object inherits StringifyMixin.
        For an object like the following::

            ClassName(Param1=100, Param2=200)

        this method would produce::

            { "ClassName": {"Param1": 100, "Param2": 200} }

        This method takes the following arguments.

        =============  =====================================================
        Argument       Description
        =============  =====================================================
        encode_string  (Optional) specify how to encode attributes which has
                       python 'str' type.
                       The default is base64.
                       This argument is used only for attributes which don't
                       have explicit type annotations in _TYPE class attribute.
        =============  =====================================================
        """
        dict_ = {}
        encode = lambda k, x: self._encode_value(k, x, encode_string)
        for k, v in obj_attrs(self):
            dict_[k] = encode(k, v)
        return {self.__class__.__name__: dict_}

    @classmethod
    def cls_from_jsondict_key(cls, k):
        # find a class with the given name from our class' module.
        import sys
        mod = sys.modules[cls.__module__]
        return getattr(mod, k)

    @classmethod
    def obj_from_jsondict(cls, jsondict):
        assert len(jsondict) == 1
        for k, v in jsondict.iteritems():
            obj_cls = cls.cls_from_jsondict_key(k)
            return obj_cls.from_jsondict(v)

    @classmethod
    def _get_decoder(cls, k, decode_string):
        t = cls._get_type(k)
        if t:
            return t.decode
        return cls._get_default_decoder(decode_string)

    @classmethod
    def _decode_value(cls, k, json_value, decode_string=base64.b64decode):
        return cls._get_decoder(k, decode_string)(json_value)

    @classmethod
    def _get_default_decoder(cls, decode_string):
        def _decode(json_value):
            if isinstance(json_value, (bytes, unicode)):
                v = decode_string(json_value)
            elif isinstance(json_value, list):
                v = map(_decode, json_value)
            elif isinstance(json_value, dict):
                if cls._is_class(json_value):
                    v = cls.obj_from_jsondict(json_value)
                else:
                    v = _mapdict(_decode, json_value)
                    # XXXhack
                    # try to restore integer keys used by
                    # OFPSwitchFeatures.ports.
                    try:
                        v = _mapdict_key(int, v)
                    except ValueError:
                        pass
            else:
                v = json_value
            return v
        return _decode

    @staticmethod
    def _restore_args(dict_):
        def restore(k):
            if k in _RESERVED_KEYWORD:
                return k + '_'
            return k
        return _mapdict_key(restore, dict_)

    @classmethod
    def from_jsondict(cls, dict_, decode_string=base64.b64decode,
                      **additional_args):
        """Create an instance from a JSON style dict.

        Instantiate this class with parameters specified by the dict.

        This method takes the following arguments.

        =============== =====================================================
        Argument        Descrpition
        =============== =====================================================
        dict\_          A dictionary which describes the parameters.
                        For example, {"Param1": 100, "Param2": 200}
        decode_string   (Optional) specify how to decode strings.
                        The default is base64.
                        This argument is used only for attributes which don't
                        have explicit type annotations in _TYPE class
                        attribute.
        additional_args (Optional) Additional kwargs for constructor.
        =============== =====================================================
        """
        decode = lambda k, x: cls._decode_value(k, x, decode_string)
        kwargs = cls._restore_args(_mapdict_kv(decode, dict_))
        try:
            return cls(**dict(kwargs, **additional_args))
        except TypeError:
            #debug
            print "CLS", cls
            print "ARG", dict_
            print "KWARG", kwargs
            raise


def obj_python_attrs(msg_):
    """iterate object attributes for stringify purposes
    """

    # a special case for namedtuple which seems widely used in
    # ofp parser implementations.
    if hasattr(msg_, '_fields'):
        for k in msg_._fields:
            yield(k, getattr(msg_, k))
        return
    base = getattr(msg_, '_base_attributes', [])
    for k, v in inspect.getmembers(msg_):
        if k.startswith('_'):
            continue
        if callable(v):
            continue
        if k in base:
            continue
        if hasattr(msg_.__class__, k):
            continue
        yield (k, v)


def obj_attrs(msg_):
    """similar to obj_python_attrs() but deals with python reserved keywords
    """

    if isinstance(msg_, StringifyMixin):
        iter = msg_.stringify_attrs()
    else:
        # probably called by msg_str_attr
        iter = obj_python_attrs(msg_)
    for k, v in iter:
        if k.endswith('_') and k[:-1] in _RESERVED_KEYWORD:
            # XXX currently only StringifyMixin has restoring logic
            assert isinstance(msg_, StringifyMixin)
            k = k[:-1]
        yield (k, v)

########NEW FILE########
__FILENAME__ = netflow
# Copyright (C) 2013 Nippon Telegraph and Telephone Corporation.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import struct

NETFLOW_V1 = 0x01
NETFLOW_V5 = 0x05
NETFLOW_V6 = 0x06
NETFLOW_V7 = 0x07
NETFLOW_V8 = 0x08
NETFLOW_V9 = 0x09


class NetFlow(object):
    _PACK_STR = '!H'
    _NETFLOW_VERSIONS = {}

    @staticmethod
    def register_netflow_version(version):
        def _register_netflow_version(cls):
            NetFlow._NETFLOW_VERSIONS[version] = cls
            return cls
        return _register_netflow_version

    def __init__(self):
        super(NetFlow, self).__init__()

    @classmethod
    def parser(cls, buf):
        (version,) = struct.unpack_from(cls._PACK_STR, buf)

        cls_ = cls._NETFLOW_VERSIONS.get(version, None)
        if cls_:
            return cls_.parser(buf)
        else:
            return None


@NetFlow.register_netflow_version(NETFLOW_V5)
class NetFlowV5(object):
    _PACK_STR = '!HHIIIIBBH'
    _MIN_LEN = struct.calcsize(_PACK_STR)

    def __init__(self, version, count, sys_uptime, unix_secs,
                 unix_nsecs, flow_sequence, engine_type, engine_id,
                 sampling_interval, flows=None):
        self.version = version
        self.count = count
        self.sys_uptime = sys_uptime
        self.unix_secs = unix_secs
        self.unix_nsecs = unix_nsecs
        self.flow_sequence = flow_sequence
        self.engine_type = engine_type
        self.engine_id = engine_id
        self.sampling_interval = sampling_interval

    @classmethod
    def parser(cls, buf):
        (version, count, sys_uptime, unix_secs, unix_nsecs,
         flow_sequence, engine_type, engine_id, sampling_interval) = \
            struct.unpack_from(cls._PACK_STR, buf)

        msg = cls(version, count, sys_uptime, unix_secs, unix_nsecs,
                  flow_sequence, engine_type, engine_id,
                  sampling_interval)
        offset = cls._MIN_LEN
        msg.flows = []
        while len(buf) > offset:
            f = NetFlowV5Flow.parser(buf, offset)
            offset += NetFlowV5Flow._MIN_LEN
            msg.flows.append(f)

        return msg


class NetFlowV5Flow(object):
    _PACK_STR = '!IIIHHIIIIHHxBBBHHBB2x'
    _MIN_LEN = struct.calcsize(_PACK_STR)

    def __init__(self, srcaddr, dstaddr, nexthop, input_, output,
                 dpkts, doctets, first, last, srcport, dstport,
                 tcp_flags, prot, tos, src_as, dst_as, src_mask,
                 dst_mask):
        self.srcaddr = srcaddr
        self.dstaddr = dstaddr
        self.nexthop = nexthop
        self.input = input_
        self.output = output
        self.dpkts = dpkts
        self.doctets = doctets
        self.first = first
        self.last = last
        self.srcport = srcport
        self.dstport = dstport
        self.tcp_flags = tcp_flags
        self.prot = prot
        self.tos = tos
        self.src_as = src_as
        self.dst_as = dst_as
        self.src_mask = src_mask
        self.dst_mask = dst_mask

    @classmethod
    def parser(cls, buf, offset):
        (srcaddr, dstaddr, nexthop, input_, output, dpkts, doctets,
         first, last, srcport, dstport, tcp_flags, prot, tos, src_as,
         dst_as, src_mask, dst_mask) = struct.unpack_from(
            cls._PACK_STR, buf, offset)
        msg = cls(srcaddr, dstaddr, nexthop, input_, output, dpkts,
                  doctets, first, last, srcport, dstport, tcp_flags,
                  prot, tos, src_as, dst_as, src_mask, dst_mask)

        return msg

########NEW FILE########
__FILENAME__ = sflow
# Copyright (C) 2013 Nippon Telegraph and Telephone Corporation.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import struct
import logging

SFLOW_V2 = 0x00000002
SFLOW_V3 = 0x00000003
SFLOW_V4 = 0x00000004
SFLOW_V5 = 0x00000005

LOG = logging.getLogger('ryu.lib.xflow.sflow')


class sFlow(object):
    _PACK_STR = '!i'
    _SFLOW_VERSIONS = {}

    @staticmethod
    def register_sflow_version(version):
        def _register_sflow_version(cls):
            sFlow._SFLOW_VERSIONS[version] = cls
            return cls
        return _register_sflow_version

    def __init__(self):
        super(sFlow, self).__init__()

    @classmethod
    def parser(cls, buf):
        (version,) = struct.unpack_from(cls._PACK_STR, buf)

        cls_ = cls._SFLOW_VERSIONS.get(version, None)
        if cls_:
            return cls_.parser(buf)
        else:
            return None


@sFlow.register_sflow_version(SFLOW_V5)
class sFlowV5(object):
    _PACK_STR = '!ii'
    _PACK_STR_IPV4 = '!iiIIIII'
    _PACK_STR_IPV6 = '!ii4IIIII'
    _AGENT_IPTYPE_V4 = 1
    _AGENT_IPTYPE_V6 = 2
    _MIN_LEN_V4 = struct.calcsize(_PACK_STR_IPV4)
    _MIN_LEN_V6 = struct.calcsize(_PACK_STR_IPV6)

    def __init__(self, version, address_type, agent_address, sub_agent_id,
                 sequence_number, uptime, samples_num, samples):
        super(sFlowV5, self).__init__()
        self.version = version
        self.address_type = address_type
        self.agent_address = agent_address
        self.sub_agent_id = sub_agent_id
        self.sequence_number = sequence_number
        self.uptime = uptime
        self.samples_num = samples_num
        self.samples = samples

    @classmethod
    def parser(cls, buf):
        (version, address_type) = struct.unpack_from(cls._PACK_STR, buf)

        if address_type == cls._AGENT_IPTYPE_V4:
            pack_str = cls._PACK_STR_IPV4
            min_len = cls._MIN_LEN_V4
        elif address_type == cls._AGENT_IPTYPE_V6:
            pack_str = cls._PACK_STR_IPV6
            min_len = cls._MIN_LEN_V6
        else:
            LOG.info("Unknown address_type. sFlowV5.address_type=%d"
                     % address_type)
            return None

        (version, address_type, agent_address, sub_agent_id, sequence_number,
         uptime, samples_num) = struct.unpack_from(pack_str, buf)
        offset = min_len

        samples = []

        while len(buf) > offset:
            sample = sFlowV5Sample.parser(buf, offset)
            offset += sFlowV5Sample.MIN_LEN + sample.sample_length
            samples.append(sample)

        msg = cls(version, address_type, agent_address, sub_agent_id,
                  sequence_number, uptime, samples_num, samples)

        return msg


class sFlowV5Sample(object):
    _PACK_STR = '!II'
    MIN_LEN = struct.calcsize(_PACK_STR)

    def __init__(self, enterprise, sample_format, sample_length, sample):
        super(sFlowV5Sample, self).__init__()
        self.enterprise = enterprise
        self.sample_format = sample_format
        self.sample_length = sample_length
        self.sample = sample

    @classmethod
    def parser(cls, buf, offset):
        (sampledata_format,
         sample_length) = struct.unpack_from(cls._PACK_STR, buf, offset)

        format_mask = 0xfff
        enterprise_shiftbit = 12

        sample_format = sampledata_format & format_mask
        enterprise = sampledata_format >> enterprise_shiftbit

        offset += cls.MIN_LEN

        if sample_format == 1:
            # Flow Sample
            sample = sFlowV5FlowSample.parser(buf, offset)
        elif sample_format == 2:
            # Counter Sample
            sample = sFlowV5CounterSample.parser(buf, offset)
        else:
            #TODO:
            # sample_format == 3    : Expanded Flow Sample
            # sample_format == 4    : Expanded Counter Sample
            LOG.info("Unknown format. sFlowV5Sample.sample_format=%d"
                     % sample_format)
            pack_str = '!%sc' % sample_length
            sample = struct.unpack_from(pack_str, buf, offset)

        msg = cls(enterprise, sample_format, sample_length, sample)

        return msg


class sFlowV5FlowSample(object):
    _PACK_STR = '!IIIIIIII'

    def __init__(self, sequence_number, source_id_type, source_id_index,
                 sampling_rate, sample_pool, drops, input_if, output_if,
                 flow_records_num, flow_records):
        super(sFlowV5FlowSample, self).__init__()
        self.sequence_number = sequence_number
        self.source_id_type = source_id_type
        self.source_id_index = source_id_index
        self.sampling_rate = sampling_rate
        self.sample_pool = sample_pool
        self.drops = drops
        self.input_if = input_if
        self.output_if = output_if
        self.flow_records_num = flow_records_num
        self.flow_records = flow_records

    @classmethod
    def parser(cls, buf, offset):
        (sequence_number, source_id, sampling_rate,
         sample_pool, drops, input_if, output_if,
         flow_records_num) = struct.unpack_from(cls._PACK_STR, buf, offset)

        index_mask = 0xffffff
        type_shiftbit = 24

        source_id_index = source_id & index_mask
        source_id_type = source_id >> type_shiftbit

        offset += struct.calcsize(cls._PACK_STR)

        flow_records = []

        for i in range(flow_records_num):
            flow_record = sFlowV5FlowRecord.parser(buf, offset)
            offset += sFlowV5FlowRecord.MIN_LEN + flow_record.flow_data_length
            flow_records.append(flow_record)

        msg = cls(sequence_number, source_id_type, source_id_index,
                  sampling_rate, sample_pool, drops, input_if, output_if,
                  flow_records_num, flow_records)

        return msg


class sFlowV5FlowRecord(object):
    _PACK_STR = '!II'
    MIN_LEN = struct.calcsize(_PACK_STR)

    def __init__(self, enterprise, flow_data_format,
                 flow_data_length, flow_data):
        super(sFlowV5FlowRecord, self).__init__()
        self.enterprise = enterprise
        self.flow_data_format = flow_data_format
        self.flow_data_length = flow_data_length
        self.flow_data = flow_data

    @classmethod
    def parser(cls, buf, offset):
        (flowdata_format,
         flow_data_length) = struct.unpack_from(cls._PACK_STR, buf, offset)

        format_mask = 0xfff
        enterprise_shiftbit = 12

        flow_data_format = flowdata_format & format_mask
        enterprise = flowdata_format >> enterprise_shiftbit

        offset += cls.MIN_LEN

        if flow_data_format == 1:
            # Raw Packet Header
            flow_data = sFlowV5RawPacketHeader.parser(buf, offset)
        elif flow_data_format == 1001:
            # Extended Switch Data
            flow_data = sFlowV5ExtendedSwitchData.parser(buf, offset)
        else:
            #TODO:
            # flow_data_format == 2    : Ethernet Frame Data
            # flow_data_format == 3    : IPv4 Data
            # flow_data_format == 4    : IPv6 Data
            # flow_data_format == 1002 : Extended Router Data
            # flow_data_format == 1003 : Extended Gateway Data
            # flow_data_format == 1004 : Extended User Data
            # flow_data_format == 1005 : Extended Url Data
            # flow_data_format == 1006 : Extended MPLS Data
            # flow_data_format == 1007 : Extended NAT Data
            # flow_data_format == 1008 : Extended MPLS Tunnel
            # flow_data_format == 1009 : Extended MPLS VC
            # flow_data_format == 1010 : Extended MPLS FEC
            # flow_data_format == 1011 : Extended MPLS LVP FEC
            # flow_data_format == 1012 : Extended VLAN tunnel
            LOG.info("Unknown format. sFlowV5FlowRecord.flow_data_format=%d"
                     % flow_data_format)
            pack_str = '!%sc' % flow_data_length
            flow_data = struct.unpack_from(pack_str, buf, offset)

        msg = cls(enterprise, flow_data_format, flow_data_length, flow_data)

        return msg


class sFlowV5RawPacketHeader(object):
    _PACK_STR = '!iIII'

    def __init__(self, header_protocol, frame_length, stripped,
                 header_size, header):
        super(sFlowV5RawPacketHeader, self).__init__()
        self.header_protocol = header_protocol
        self.frame_length = frame_length
        self.stripped = stripped
        self.header_size = header_size
        self.header = header

    @classmethod
    def parser(cls, buf, offset):
        (header_protocol, frame_length, stripped,
         header_size) = struct.unpack_from(cls._PACK_STR, buf, offset)

        offset += struct.calcsize(cls._PACK_STR)

        header_pack_str = '!%sc' % header_size
        header = struct.unpack_from(header_pack_str, buf, offset)

        msg = cls(header_protocol, frame_length, stripped, header_size, header)
        return msg


class sFlowV5ExtendedSwitchData(object):
    _PACK_STR = '!IIII'

    def __init__(self, src_vlan, src_priority, dest_vlan, dest_priority):
        super(sFlowV5ExtendedSwitchData, self).__init__()
        self.src_vlan = src_vlan
        self.src_priority = src_priority
        self.dest_vlan = dest_vlan
        self.dest_priority = dest_priority

    @classmethod
    def parser(cls, buf, offset):
        (src_vlan, src_priority, dest_vlan,
         dest_priority) = struct.unpack_from(cls._PACK_STR, buf, offset)

        msg = cls(src_vlan, src_priority, dest_vlan, dest_priority)
        return msg


class sFlowV5CounterSample(object):
    _PACK_STR = '!III'

    def __init__(self, sequence_number, source_id_type, source_id_index,
                 counters_records_num, counters_records):
        super(sFlowV5CounterSample, self).__init__()
        self.sequence_number = sequence_number
        self.source_id_type = source_id_type
        self.source_id_index = source_id_index
        self.counters_records_num = counters_records_num
        self.counters_records = counters_records

    @classmethod
    def parser(cls, buf, offset):
        (sequence_number, source_id,
         counters_records_num) = struct.unpack_from(cls._PACK_STR, buf, offset)

        index_mask = 0xffffff
        type_shiftbit = 24

        source_id_index = source_id & index_mask
        source_id_type = source_id >> type_shiftbit

        offset += struct.calcsize(cls._PACK_STR)

        counters_records = []

        for i in range(counters_records_num):
            counter_record = sFlowV5CounterRecord.parser(buf, offset)
            offset += sFlowV5CounterRecord.MIN_LEN
            offset += counter_record.counter_data_length
            counters_records.append(counter_record)

        msg = cls(sequence_number, source_id_type, source_id_index,
                  counters_records_num, counters_records)

        return msg


class sFlowV5CounterRecord(object):
    _PACK_STR = '!II'
    MIN_LEN = struct.calcsize(_PACK_STR)

    def __init__(self, enterprise, counter_data_format,
                 counter_data_length, counter_data):
        super(sFlowV5CounterRecord, self).__init__()
        self.enterprise = enterprise
        self.counter_data_format = counter_data_format
        self.counter_data_length = counter_data_length
        self.counter_data = counter_data

    @classmethod
    def parser(cls, buf, offset):
        (counterdata_format,
         counter_data_length) = struct.unpack_from(cls._PACK_STR, buf, offset)

        format_mask = 0xfff
        enterprise_shiftbit = 12

        counter_data_format = counterdata_format & format_mask
        enterprise = counterdata_format >> enterprise_shiftbit

        offset += cls.MIN_LEN

        if counter_data_format == 1:
            # Generic Interface Counters
            counter_data = sFlowV5GenericInterfaceCounters.parser(buf, offset)
        else:
            #TODO:
            # counter_data_format == 2    : Ethernet Interface Counters
            # counter_data_format == 3    : Token Ring Counters
            # counter_data_format == 4    : 100 BaseVG Interface Counters
            # counter_data_format == 5    : VLAN Counters
            # counter_data_format == 1001 : Processor Information
            LOG.info("Unknown format. " +
                     "sFlowV5CounterRecord.counter_data_format=%d"
                     % counter_data_format)
            pack_str = '!%sc' % counter_data_length
            counter_data = struct.unpack_from(pack_str, buf, offset)

        msg = cls(enterprise, counter_data_format,
                  counter_data_length, counter_data)

        return msg


class sFlowV5GenericInterfaceCounters(object):
    _PACK_STR = '!IIQIIQIIIIIIQIIIIII'

    def __init__(self, ifIndex, ifType, ifSpeed, ifDirection,
                 ifAdminStatus, ifOperStatus, ifInOctets, ifInUcastPkts,
                 ifInMulticastPkts, ifInBroadcastPkts, ifInDiscards,
                 ifInErrors, ifInUnknownProtos, ifOutOctets,
                 ifOutUcastPkts, ifOutMulticastPkts, ifOutBroadcastPkts,
                 ifOutDiscards, ifOutErrors, ifPromiscuousMode):
        super(sFlowV5GenericInterfaceCounters, self).__init__()
        self.ifIndex = ifIndex
        self.ifType = ifType
        self.ifSpeed = ifSpeed
        self.ifDirection = ifDirection
        self.ifAdminStatus = ifAdminStatus
        self.ifOperStatus = ifOperStatus
        self.ifInOctets = ifInOctets
        self.ifInUcastPkts = ifInUcastPkts
        self.ifInMulticastPkts = ifInMulticastPkts
        self.ifInBroadcastPkts = ifInBroadcastPkts
        self.ifInDiscards = ifInDiscards
        self.ifInErrors = ifInErrors
        self.ifInUnknownProtos = ifInUnknownProtos
        self.ifOutOctets = ifOutOctets
        self.ifOutUcastPkts = ifOutUcastPkts
        self.ifOutMulticastPkts = ifOutMulticastPkts
        self.ifOutBroadcastPkts = ifOutBroadcastPkts
        self.ifOutDiscards = ifOutDiscards
        self.ifOutErrors = ifOutErrors
        self.ifPromiscuousMode = ifPromiscuousMode

    @classmethod
    def parser(cls, buf, offset):
        (ifIndex, ifType, ifSpeed, ifDirection, ifStatus, ifInOctets,
         ifInUcastPkts, ifInMulticastPkts, ifInBroadcastPkts, ifInDiscards,
         ifInErrors, ifInUnknownProtos, ifOutOctets, ifOutUcastPkts,
         ifOutMulticastPkts, ifOutBroadcastPkts, ifOutDiscards, ifOutErrors,
         ifPromiscuousMode,) = struct.unpack_from(cls._PACK_STR, buf, offset)

        ifStatus_mask = 0x1
        ifAdminStatus_shiftbit = 1

        ifOperStatus = ifStatus & ifStatus_mask
        ifAdminStatus = ifStatus >> ifAdminStatus_shiftbit & ifStatus_mask

        msg = cls(ifIndex, ifType, ifSpeed, ifDirection, ifAdminStatus,
                  ifOperStatus, ifInOctets, ifInUcastPkts,
                  ifInMulticastPkts, ifInBroadcastPkts, ifInDiscards,
                  ifInErrors, ifInUnknownProtos, ifOutOctets,
                  ifOutUcastPkts, ifOutMulticastPkts, ifOutBroadcastPkts,
                  ifOutDiscards, ifOutErrors, ifPromiscuousMode)

        return msg

########NEW FILE########
__FILENAME__ = log
# Copyright (C) 2011 Nippon Telegraph and Telephone Corporation.
# Copyright (C) 2011 Isaku Yamahata <yamahata at valinux co jp>
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from __future__ import print_function
from oslo.config import cfg
import inspect
import logging
import logging.config
import logging.handlers
import os
import sys
import ConfigParser


CONF = cfg.CONF

CONF.register_cli_opts([
    cfg.IntOpt('default-log-level', default=None, help='default log level'),
    cfg.BoolOpt('verbose', default=False, help='show debug output'),
    cfg.BoolOpt('use-stderr', default=True, help='log to standard error'),
    cfg.BoolOpt('use-syslog', default=False, help='output to syslog'),
    cfg.StrOpt('log-dir', default=None, help='log file directory'),
    cfg.StrOpt('log-file', default=None, help='log file name'),
    cfg.StrOpt('log-file-mode', default='0644',
               help='default log file permission'),
    cfg.StrOpt('log-config-file', default=None,
               help='Path to a logging config file to use')
])


_EARLY_LOG_HANDLER = None


def early_init_log(level=None):
    global _EARLY_LOG_HANDLER
    _EARLY_LOG_HANDLER = logging.StreamHandler(sys.stderr)

    log = logging.getLogger()
    log.addHandler(_EARLY_LOG_HANDLER)
    if level is not None:
        log.setLevel(level)


def _get_log_file():
    if CONF.log_file:
        return CONF.log_file
    if CONF.log_dir:
        return os.path.join(CONF.log_dir,
                            os.path.basename(inspect.stack()[-1][1])) + '.log'
    return None


def init_log():
    global _EARLY_LOG_HANDLER

    log = logging.getLogger()

    if CONF.log_config_file:
        try:
            logging.config.fileConfig(CONF.log_config_file,
                                      disable_existing_loggers=True)
        except ConfigParser.Error as e:
            print('Failed to parse %s: %s' % (CONF.log_config_file, e),
                  file=sys.stderr)
            sys.exit(2)
        return

    if CONF.use_stderr:
        log.addHandler(logging.StreamHandler(sys.stderr))
    if _EARLY_LOG_HANDLER is not None:
        log.removeHandler(_EARLY_LOG_HANDLER)
        _EARLY_LOG_HANDLER = None

    if CONF.use_syslog:
        syslog = logging.handlers.SysLogHandler(address='/dev/log')
        log.addHandler(syslog)

    log_file = _get_log_file()
    if log_file is not None:
        log.addHandler(logging.handlers.WatchedFileHandler(log_file))
        mode = int(CONF.log_file_mode, 8)
        os.chmod(log_file, mode)

    if CONF.default_log_level is not None:
        log.setLevel(CONF.default_log_level)
    elif CONF.verbose:
        log.setLevel(logging.DEBUG)
    else:
        log.setLevel(logging.INFO)

########NEW FILE########
__FILENAME__ = ether
# Copyright (C) 2012 Nippon Telegraph and Telephone Corporation.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.


ETH_TYPE_IP = 0x0800
ETH_TYPE_ARP = 0x0806
ETH_TYPE_8021Q = 0x8100
ETH_TYPE_IPV6 = 0x86dd
ETH_TYPE_SLOW = 0x8809
ETH_TYPE_MPLS = 0x8847
ETH_TYPE_8021AD = 0x88a8
ETH_TYPE_LLDP = 0x88cc
ETH_TYPE_8021AH = 0x88e7
ETH_TYPE_IEEE802_3 = 0x05dc

########NEW FILE########
__FILENAME__ = inet
# Copyright (C) 2012 Nippon Telegraph and Telephone Corporation.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.


IPPROTO_IP = 0
IPPROTO_HOPOPTS = 0
IPPROTO_ICMP = 1
IPPROTO_IGMP = 2
IPPROTO_TCP = 6
IPPROTO_UDP = 17
IPPROTO_ROUTING = 43
IPPROTO_FRAGMENT = 44
IPPROTO_AH = 51
IPPROTO_ICMPV6 = 58
IPPROTO_NONE = 59
IPPROTO_DSTOPTS = 60
IPPROTO_VRRP = 112
IPPROTO_SCTP = 132

########NEW FILE########
__FILENAME__ = nx_match
# Copyright (C) 2011, 2012 Nippon Telegraph and Telephone Corporation.
# Copyright (C) 2011, 2012 Isaku Yamahata <yamahata at valinux co jp>
# Copyright (C) 2012 Simon Horman <horms ad verge net au>
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import struct
import itertools

from ryu import exception
from ryu.lib import mac
from . import ofproto_parser
from . import ofproto_v1_0
from . import inet

import logging
LOG = logging.getLogger('ryu.ofproto.nx_match')


UINT64_MAX = (1 << 64) - 1
UINT32_MAX = (1 << 32) - 1
UINT16_MAX = (1 << 16) - 1

FWW_IN_PORT = 1 << 0
FWW_DL_TYPE = 1 << 4
FWW_NW_PROTO = 1 << 5
# No corresponding OFPFW_* bits
FWW_NW_DSCP = 1 << 1
FWW_NW_ECN = 1 << 2
FWW_ARP_SHA = 1 << 3
FWW_ARP_THA = 1 << 6
FWW_IPV6_LABEL = 1 << 7
FWW_NW_TTL = 1 << 8
FWW_ALL = (1 << 13) - 1

FLOW_NW_FRAG_ANY = 1 << 0
FLOW_NW_FRAG_LATER = 1 << 1
FLOW_NW_FRAG_MASK = FLOW_NW_FRAG_ANY | FLOW_NW_FRAG_LATER

IP_ECN_MASK = 0x03
IP_DSCP_MASK = 0xfc

MF_PACK_STRING_BE64 = '!Q'
MF_PACK_STRING_BE32 = '!I'
MF_PACK_STRING_BE16 = '!H'
MF_PACK_STRING_8 = '!B'
MF_PACK_STRING_MAC = '!6s'
MF_PACK_STRING_IPV6 = '!8H'

_MF_FIELDS = {}

FLOW_N_REGS = 8  # ovs 1.5


class Flow(object):
    def __init__(self):
        self.in_port = 0
        self.dl_vlan = 0
        self.dl_vlan_pcp = 0
        self.dl_src = mac.DONTCARE
        self.dl_dst = mac.DONTCARE
        self.dl_type = 0
        self.tp_dst = 0
        self.tp_src = 0
        self.nw_tos = 0
        self.vlan_tci = 0
        self.nw_ttl = 0
        self.nw_proto = 0
        self.arp_sha = 0
        self.arp_tha = 0
        self.nw_src = 0
        self.nw_dst = 0
        self.tun_id = 0
        self.arp_spa = 0
        self.arp_tpa = 0
        self.ipv6_src = []
        self.ipv6_dst = []
        self.nd_target = []
        self.nw_frag = 0
        self.regs = [0] * FLOW_N_REGS
        self.ipv6_label = 0


class FlowWildcards(object):
    def __init__(self):
        self.dl_src_mask = 0
        self.dl_dst_mask = 0
        self.tp_src_mask = 0
        self.tp_dst_mask = 0
        self.nw_src_mask = 0
        self.nw_dst_mask = 0
        self.tun_id_mask = 0
        self.arp_spa_mask = 0
        self.arp_tpa_mask = 0
        self.vlan_tci_mask = 0
        self.ipv6_src_mask = []
        self.ipv6_dst_mask = []
        self.nd_target_mask = []
        self.nw_frag_mask = 0
        self.regs_bits = 0
        self.regs_mask = [0] * FLOW_N_REGS
        self.wildcards = ofproto_v1_0.OFPFW_ALL


class ClsRule(object):
    """describe a matching rule for OF 1.0 OFPMatch (and NX).
    """
    def __init__(self):
        self.wc = FlowWildcards()
        self.flow = Flow()

    def set_in_port(self, port):
        self.wc.wildcards &= ~FWW_IN_PORT
        self.flow.in_port = port

    def set_dl_vlan(self, dl_vlan):
        self.wc.wildcards &= ~ofproto_v1_0.OFPFW_DL_VLAN
        self.flow.dl_vlan = dl_vlan

    def set_dl_vlan_pcp(self, dl_vlan_pcp):
        self.wc.wildcards &= ~ofproto_v1_0.OFPFW_DL_VLAN_PCP
        self.flow.dl_vlan_pcp = dl_vlan_pcp

    def set_dl_dst(self, dl_dst):
        self.flow.dl_dst = dl_dst

    def set_dl_dst_masked(self, dl_dst, mask):
        self.wc.dl_dst_mask = mask
        # bit-wise and of the corresponding elements of dl_dst and mask
        self.flow.dl_dst = mac.haddr_bitand(dl_dst, mask)

    def set_dl_src(self, dl_src):
        self.flow.dl_src = dl_src

    def set_dl_src_masked(self, dl_src, mask):
        self.wc.dl_src_mask = mask
        self.flow.dl_src = mac.haddr_bitand(dl_src, mask)

    def set_dl_type(self, dl_type):
        self.wc.wildcards &= ~FWW_DL_TYPE
        self.flow.dl_type = dl_type

    def set_dl_tci(self, tci):
        self.set_dl_tci_masked(tci, UINT16_MAX)

    def set_dl_tci_masked(self, tci, mask):
        self.wc.vlan_tci_mask = mask
        self.flow.vlan_tci = tci

    def set_tp_src(self, tp_src):
        self.set_tp_src_masked(tp_src, UINT16_MAX)

    def set_tp_src_masked(self, tp_src, mask):
        self.wc.tp_src_mask = mask
        self.flow.tp_src = tp_src & mask

    def set_tp_dst(self, tp_dst):
        self.set_tp_dst_masked(tp_dst, UINT16_MAX)

    def set_tp_dst_masked(self, tp_dst, mask):
        self.wc.tp_dst_mask = mask
        self.flow.tp_dst = tp_dst & mask

    def set_nw_proto(self, nw_proto):
        self.wc.wildcards &= ~FWW_NW_PROTO
        self.flow.nw_proto = nw_proto

    def set_nw_src(self, nw_src):
        self.set_nw_src_masked(nw_src, UINT32_MAX)

    def set_nw_src_masked(self, nw_src, mask):
        self.flow.nw_src = nw_src
        self.wc.nw_src_mask = mask

    def set_nw_dst(self, nw_dst):
        self.set_nw_dst_masked(nw_dst, UINT32_MAX)

    def set_nw_dst_masked(self, nw_dst, mask):
        self.flow.nw_dst = nw_dst
        self.wc.nw_dst_mask = mask

    def set_nw_dscp(self, nw_dscp):
        self.wc.wildcards &= ~FWW_NW_DSCP
        self.flow.nw_tos &= ~IP_DSCP_MASK
        self.flow.nw_tos |= nw_dscp & IP_DSCP_MASK

    def set_icmp_type(self, icmp_type):
        self.set_tp_src(icmp_type)

    def set_icmp_code(self, icmp_code):
        self.set_tp_dst(icmp_code)

    def set_tun_id(self, tun_id):
        self.set_tun_id_masked(tun_id, UINT64_MAX)

    def set_tun_id_masked(self, tun_id, mask):
        self.wc.tun_id_mask = mask
        self.flow.tun_id = tun_id & mask

    def set_nw_ecn(self, nw_ecn):
        self.wc.wildcards &= ~FWW_NW_ECN
        self.flow.nw_tos &= ~IP_ECN_MASK
        self.flow.nw_tos |= nw_ecn & IP_ECN_MASK

    def set_nw_ttl(self, nw_ttl):
        self.wc.wildcards &= ~FWW_NW_TTL
        self.flow.nw_ttl = nw_ttl

    def set_nw_frag(self, nw_frag):
        self.wc.nw_frag_mask |= FLOW_NW_FRAG_MASK
        self.flow.nw_frag = nw_frag

    def set_nw_frag_masked(self, nw_frag, mask):
        self.wc.nw_frag_mask = mask
        self.flow.nw_frag = nw_frag & mask

    def set_arp_spa(self, spa):
        self.set_arp_spa_masked(spa, UINT32_MAX)

    def set_arp_spa_masked(self, spa, mask):
        self.flow.arp_spa = spa
        self.wc.arp_spa_mask = mask

    def set_arp_tpa(self, tpa):
        self.set_arp_tpa_masked(tpa, UINT32_MAX)

    def set_arp_tpa_masked(self, tpa, mask):
        self.flow.arp_tpa = tpa
        self.wc.arp_tpa_mask = mask

    def set_arp_sha(self, sha):
        self.wc.wildcards &= ~FWW_ARP_SHA
        self.flow.arp_sha = sha

    def set_arp_tha(self, tha):
        self.wc.wildcards &= ~FWW_ARP_THA
        self.flow.arp_tha = tha

    def set_icmpv6_type(self, icmp_type):
        self.set_tp_src(icmp_type)

    def set_icmpv6_code(self, icmp_code):
        self.set_tp_dst(icmp_code)

    def set_ipv6_label(self, label):
        self.wc.wildcards &= ~FWW_IPV6_LABEL
        self.flow.ipv6_label = label

    def set_ipv6_label(self, label):
        self.wc.wildcards &= ~FWW_IPV6_LABEL
        self.flow.ipv6_label = label

    def set_ipv6_src_masked(self, src, mask):
        self.wc.ipv6_src_mask = mask
        self.flow.ipv6_src = [x & y for (x, y) in itertools.izip(src, mask)]

    def set_ipv6_src(self, src):
        self.flow.ipv6_src = src

    def set_ipv6_dst_masked(self, dst, mask):
        self.wc.ipv6_dst_mask = mask
        self.flow.ipv6_dst = [x & y for (x, y) in itertools.izip(dst, mask)]

    def set_ipv6_dst(self, dst):
        self.flow.ipv6_dst = dst

    def set_nd_target_masked(self, target, mask):
        self.wc.nd_target_mask = mask
        self.flow.nd_target = [x & y for (x, y) in
                               itertools.izip(target, mask)]

    def set_nd_target(self, target):
        self.flow.nd_target = target

    def set_reg(self, reg_idx, value):
        self.set_reg_masked(reg_idx, value, 0)

    def set_reg_masked(self, reg_idx, value, mask):
        self.wc.regs_mask[reg_idx] = mask
        self.flow.regs[reg_idx] = value
        self.wc.regs_bits |= (1 << reg_idx)

    def flow_format(self):
        # Tunnel ID is only supported by NXM
        if self.wc.tun_id_mask != 0:
            return ofproto_v1_0.NXFF_NXM

        # Masking DL_DST is only supported by NXM
        if self.wc.dl_dst_mask:
            return ofproto_v1_0.NXFF_NXM

        # Masking DL_SRC is only supported by NXM
        if self.wc.dl_src_mask:
            return ofproto_v1_0.NXFF_NXM

        # ECN is only supported by NXM
        if not self.wc.wildcards & FWW_NW_ECN:
            return ofproto_v1_0.NXFF_NXM

        return ofproto_v1_0.NXFF_OPENFLOW10

    def match_tuple(self):
        """return a tuple which can be used as *args for
        ofproto_v1_0_parser.OFPMatch.__init__().
        see Datapath.send_flow_mod.
        """
        assert self.flow_format() == ofproto_v1_0.NXFF_OPENFLOW10
        wildcards = ofproto_v1_0.OFPFW_ALL

        if not self.wc.wildcards & FWW_IN_PORT:
            wildcards &= ~ofproto_v1_0.OFPFW_IN_PORT

        if self.flow.dl_src != mac.DONTCARE:
            wildcards &= ~ofproto_v1_0.OFPFW_DL_SRC

        if self.flow.dl_dst != mac.DONTCARE:
            wildcards &= ~ofproto_v1_0.OFPFW_DL_DST

        if not self.wc.wildcards & FWW_DL_TYPE:
            wildcards &= ~ofproto_v1_0.OFPFW_DL_TYPE

        if self.flow.dl_vlan != 0:
            wildcards &= ~ofproto_v1_0.OFPFW_DL_VLAN

        if self.flow.dl_vlan_pcp != 0:
            wildcards &= ~ofproto_v1_0.OFPFW_DL_VLAN_PCP

        if self.flow.nw_tos != 0:
            wildcards &= ~ofproto_v1_0.OFPFW_NW_TOS

        if self.flow.nw_proto != 0:
            wildcards &= ~ofproto_v1_0.OFPFW_NW_PROTO

        if self.wc.nw_src_mask != 0 and "01" not in bin(self.wc.nw_src_mask):
            wildcards &= ~ofproto_v1_0.OFPFW_NW_SRC_MASK
            maskbits = (bin(self.wc.nw_src_mask).count("0") - 1)
            wildcards |= (maskbits << ofproto_v1_0.OFPFW_NW_SRC_SHIFT)

        if self.wc.nw_dst_mask != 0 and "01" not in bin(self.wc.nw_dst_mask):
            wildcards &= ~ofproto_v1_0.OFPFW_NW_DST_MASK
            maskbits = (bin(self.wc.nw_dst_mask).count("0") - 1)
            wildcards |= (maskbits << ofproto_v1_0.OFPFW_NW_DST_SHIFT)

        if self.flow.tp_src != 0:
            wildcards &= ~ofproto_v1_0.OFPFW_TP_SRC

        if self.flow.tp_dst != 0:
            wildcards &= ~ofproto_v1_0.OFPFW_TP_DST

        return (wildcards, self.flow.in_port, self.flow.dl_src,
                self.flow.dl_dst, self.flow.dl_vlan, self.flow.dl_vlan_pcp,
                self.flow.dl_type, self.flow.nw_tos & IP_DSCP_MASK,
                self.flow.nw_proto, self.flow.nw_src, self.flow.nw_dst,
                self.flow.tp_src, self.flow.tp_dst)


def _set_nxm_headers(nxm_headers):
    '''Annotate corresponding NXM header'''
    def _set_nxm_headers_dec(self):
        self.nxm_headers = nxm_headers
        return self
    return _set_nxm_headers_dec


def _register_make(cls):
    '''class decorator to Register mf make'''
    assert cls.nxm_headers is not None
    assert cls.nxm_headers is not []
    for nxm_header in cls.nxm_headers:
        assert nxm_header not in _MF_FIELDS
        _MF_FIELDS[nxm_header] = cls.make
    return cls


def mf_from_nxm_header(nxm_header):
    if nxm_header not in _MF_FIELDS:
        return None
    make = _MF_FIELDS.get(nxm_header)
    assert make is not None
    return make(nxm_header)


class MFField(object):
    _FIELDS_HEADERS = {}

    @staticmethod
    def register_field_header(headers):
        def _register_field_header(cls):
            for header in headers:
                MFField._FIELDS_HEADERS[header] = cls
            return cls
        return _register_field_header

    def __init__(self, nxm_header, pack_str):
        self.nxm_header = nxm_header
        self.pack_str = pack_str
        self.n_bytes = struct.calcsize(pack_str)
        self.n_bits = self.n_bytes * 8

    @classmethod
    def parser(cls, buf, offset):
        (header,) = struct.unpack_from('!I', buf, offset)

        cls_ = MFField._FIELDS_HEADERS.get(header)

        if cls_:
            field = cls_.field_parser(header, buf, offset)
        else:
            # print 'unknown field type'
            raise
        field.length = (header & 0xff) + 4

        return field

    @classmethod
    def field_parser(cls, header, buf, offset):
        hasmask = (header >> 8) & 1
        mask = None
        if hasmask:
            pack_str = '!' + cls.pack_str[1:] * 2
            (value, mask) = struct.unpack_from(pack_str, buf,
                                               offset + 4)
        else:
            (value,) = struct.unpack_from(cls.pack_str, buf,
                                          offset + 4)
        return cls(header, value, mask)

    def _put(self, buf, offset, value):
        ofproto_parser.msg_pack_into(self.pack_str, buf, offset, value)
        return self.n_bytes

    def putw(self, buf, offset, value, mask):
        len_ = self._put(buf, offset, value)
        return len_ + self._put(buf, offset + len_, mask)

    def _is_all_ones(self, value):
        return value == (1 << self.n_bits) - 1

    def putm(self, buf, offset, value, mask):
        if mask == 0:
            return 0
        elif self._is_all_ones(mask):
            return self._put(buf, offset, value)
        else:
            return self.putw(buf, offset, value, mask)

    def _putv6(self, buf, offset, value):
        ofproto_parser.msg_pack_into(self.pack_str, buf, offset,
                                     *value)
        return self.n_bytes

    def putv6(self, buf, offset, value, mask):
        len_ = self._putv6(buf, offset, value)
        if len(mask):
            return len_ + self._putv6(buf, offset + len_, mask)
        return len_


@_register_make
@_set_nxm_headers([ofproto_v1_0.NXM_OF_IN_PORT])
@MFField.register_field_header([ofproto_v1_0.NXM_OF_IN_PORT])
class MFInPort(MFField):
    pack_str = MF_PACK_STRING_BE16

    def __init__(self, header, value, mask=None):
        super(MFInPort, self).__init__(header, MFInPort.pack_str)
        self.value = value

    @classmethod
    def make(cls, header):
        return cls(header, MFInPort.pack_str)

    def put(self, buf, offset, rule):
        return self._put(buf, offset, rule.flow.in_port)


@_register_make
@_set_nxm_headers([ofproto_v1_0.NXM_OF_ETH_DST, ofproto_v1_0.NXM_OF_ETH_DST_W])
@MFField.register_field_header([ofproto_v1_0.NXM_OF_ETH_DST,
                                ofproto_v1_0.NXM_OF_ETH_DST_W])
class MFEthDst(MFField):
    pack_str = MF_PACK_STRING_MAC

    def __init__(self, header, value, mask=None):
        super(MFEthDst, self).__init__(header, MFEthDst.pack_str)
        self.value = value

    @classmethod
    def make(cls, header):
        return cls(header, MFEthDst.pack_str)

    def put(self, buf, offset, rule):
        if rule.wc.dl_dst_mask:
            return self.putw(buf, offset, rule.flow.dl_dst,
                             rule.wc.dl_dst_mask)
        else:
            return self._put(buf, offset, rule.flow.dl_dst)


@_register_make
@_set_nxm_headers([ofproto_v1_0.NXM_OF_ETH_SRC, ofproto_v1_0.NXM_OF_ETH_SRC_W])
@MFField.register_field_header([ofproto_v1_0.NXM_OF_ETH_SRC,
                                ofproto_v1_0.NXM_OF_ETH_SRC_W])
class MFEthSrc(MFField):
    pack_str = MF_PACK_STRING_MAC

    def __init__(self, header, value, mask=None):
        super(MFEthSrc, self).__init__(header, MFEthSrc.pack_str)
        self.value = value

    @classmethod
    def make(cls, header):
        return cls(header, MFEthSrc.pack_str)

    def put(self, buf, offset, rule):
        if rule.wc.dl_src_mask:
            return self.putw(buf, offset, rule.flow.dl_src,
                             rule.wc.dl_src_mask)
        else:
            return self._put(buf, offset, rule.flow.dl_src)


@_register_make
@_set_nxm_headers([ofproto_v1_0.NXM_OF_ETH_TYPE])
@MFField.register_field_header([ofproto_v1_0.NXM_OF_ETH_TYPE])
class MFEthType(MFField):
    pack_str = MF_PACK_STRING_BE16

    def __init__(self, header, value, mask=None):
        super(MFEthType, self).__init__(header, MFEthType.pack_str)
        self.value = value

    @classmethod
    def make(cls, header):
        return cls(header, MFEthType.pack_str)

    def put(self, buf, offset, rule):
        return self._put(buf, offset, rule.flow.dl_type)


@_register_make
@_set_nxm_headers([ofproto_v1_0.NXM_OF_VLAN_TCI,
                   ofproto_v1_0.NXM_OF_VLAN_TCI_W])
@MFField.register_field_header([ofproto_v1_0.NXM_OF_VLAN_TCI,
                                ofproto_v1_0.NXM_OF_VLAN_TCI_W])
class MFVlan(MFField):
    pack_str = MF_PACK_STRING_BE16

    def __init__(self, header, value, mask=None):
        super(MFVlan, self).__init__(header, MFVlan.pack_str)
        self.value = value

    @classmethod
    def make(cls, header):
        return cls(header, MFVlan.pack_str)

    def put(self, buf, offset, rule):
        return self.putm(buf, offset, rule.flow.vlan_tci,
                         rule.wc.vlan_tci_mask)


@_register_make
@_set_nxm_headers([ofproto_v1_0.NXM_OF_IP_TOS])
@MFField.register_field_header([ofproto_v1_0.NXM_OF_IP_TOS])
class MFIPDSCP(MFField):
    pack_str = MF_PACK_STRING_8

    def __init__(self, header, value, mask=None):
        super(MFIPDSCP, self).__init__(header, MFIPDSCP.pack_str)
        self.value = value

    @classmethod
    def make(cls, header):
        return cls(header, MFIPDSCP.pack_str)

    def put(self, buf, offset, rule):
        return self._put(buf, offset,
                         rule.flow.nw_tos & IP_DSCP_MASK)


@_register_make
@_set_nxm_headers([ofproto_v1_0.NXM_NX_TUN_ID,
                   ofproto_v1_0.NXM_NX_TUN_ID_W])
@MFField.register_field_header([ofproto_v1_0.NXM_NX_TUN_ID,
                                ofproto_v1_0.NXM_NX_TUN_ID_W])
class MFTunId(MFField):
    pack_str = MF_PACK_STRING_BE64

    def __init__(self, header, value, mask=None):
        super(MFTunId, self).__init__(header, MFTunId.pack_str)
        self.value = value

    @classmethod
    def make(cls, header):
        return cls(header, MFTunId.pack_str)

    def put(self, buf, offset, rule):
        return self.putm(buf, offset, rule.flow.tun_id, rule.wc.tun_id_mask)


@_register_make
@_set_nxm_headers([ofproto_v1_0.NXM_OF_IP_SRC, ofproto_v1_0.NXM_OF_IP_SRC_W])
@MFField.register_field_header([ofproto_v1_0.NXM_OF_IP_SRC,
                                ofproto_v1_0.NXM_OF_IP_SRC_W])
class MFIPSrc(MFField):
    pack_str = MF_PACK_STRING_BE32

    def __init__(self, header, value, mask=None):
        super(MFIPSrc, self).__init__(header, MFIPSrc.pack_str)
        self.value = value
        self.mask = mask

    @classmethod
    def make(cls, header):
        return cls(header, MFIPSrc.pack_str)

    def put(self, buf, offset, rule):
        return self.putm(buf, offset, rule.flow.nw_src, rule.wc.nw_src_mask)


@_register_make
@_set_nxm_headers([ofproto_v1_0.NXM_OF_IP_DST, ofproto_v1_0.NXM_OF_IP_DST_W])
@MFField.register_field_header([ofproto_v1_0.NXM_OF_IP_DST,
                                ofproto_v1_0.NXM_OF_IP_DST_W])
class MFIPDst(MFField):
    pack_str = MF_PACK_STRING_BE32

    def __init__(self, header, value, mask=None):
        super(MFIPDst, self).__init__(header, MFIPDst.pack_str)
        self.value = value
        self.mask = mask

    @classmethod
    def make(cls, header):
        return cls(header, MFIPDst.pack_str)

    def put(self, buf, offset, rule):
        return self.putm(buf, offset, rule.flow.nw_dst, rule.wc.nw_dst_mask)


@_register_make
@_set_nxm_headers([ofproto_v1_0.NXM_NX_IP_ECN])
class MFIPECN(MFField):
    @classmethod
    def make(cls, header):
        return cls(header, MF_PACK_STRING_8)

    def put(self, buf, offset, rule):
        return self._put(buf, offset,
                         rule.flow.nw_tos & IP_ECN_MASK)


@_register_make
@_set_nxm_headers([ofproto_v1_0.NXM_NX_IP_TTL])
class MFIPTTL(MFField):
    @classmethod
    def make(cls, header):
        return cls(header, MF_PACK_STRING_8)

    def put(self, buf, offset, rule):
        return self._put(buf, offset, rule.flow.nw_ttl)


@_register_make
@_set_nxm_headers([ofproto_v1_0.NXM_OF_IP_PROTO])
class MFIPProto(MFField):
    @classmethod
    def make(cls, header):
        return cls(header, MF_PACK_STRING_8)

    def put(self, buf, offset, rule):
        return self._put(buf, offset, rule.flow.nw_proto)


@_register_make
@_set_nxm_headers([ofproto_v1_0.NXM_OF_TCP_SRC, ofproto_v1_0.NXM_OF_TCP_SRC_W,
                   ofproto_v1_0.NXM_OF_UDP_SRC, ofproto_v1_0.NXM_OF_UDP_SRC_W])
class MFTPSRC(MFField):
    @classmethod
    def make(cls, header):
        return cls(header, MF_PACK_STRING_BE16)

    def put(self, buf, offset, rule):
        return self.putm(buf, offset, rule.flow.tp_src, rule.wc.tp_src_mask)


@_register_make
@_set_nxm_headers([ofproto_v1_0.NXM_OF_TCP_DST, ofproto_v1_0.NXM_OF_TCP_DST_W,
                   ofproto_v1_0.NXM_OF_UDP_DST, ofproto_v1_0.NXM_OF_UDP_DST_W])
class MFTPDST(MFField):
    @classmethod
    def make(cls, header):
        return cls(header, MF_PACK_STRING_BE16)

    def put(self, buf, offset, rule):
        return self.putm(buf, offset, rule.flow.tp_dst, rule.wc.tp_dst_mask)


@_register_make
@_set_nxm_headers([ofproto_v1_0.NXM_OF_ARP_SPA, ofproto_v1_0.NXM_OF_ARP_SPA_W])
class MFArpSpa(MFField):
    @classmethod
    def make(cls, header):
        return cls(header, MF_PACK_STRING_BE32)

    def put(self, buf, offset, rule):
        return self.putm(buf, offset, rule.flow.arp_spa, rule.wc.arp_spa_mask)


@_register_make
@_set_nxm_headers([ofproto_v1_0.NXM_OF_ARP_TPA, ofproto_v1_0.NXM_OF_ARP_TPA_W])
class MFArpTpa(MFField):
    @classmethod
    def make(cls, header):
        return cls(header, MF_PACK_STRING_BE32)

    def put(self, buf, offset, rule):
        return self.putm(buf, offset, rule.flow.arp_tpa, rule.wc.arp_tpa_mask)


@_register_make
@_set_nxm_headers([ofproto_v1_0.NXM_NX_ARP_SHA])
class MFArpSha(MFField):
    @classmethod
    def make(cls, header):
        return cls(header, MF_PACK_STRING_MAC)

    def put(self, buf, offset, rule):
        return self._put(buf, offset, rule.flow.arp_sha)


class MFIPV6(object):
    pack_str = MF_PACK_STRING_IPV6

    @classmethod
    def field_parser(cls, header, buf, offset):
        hasmask = (header >> 8) & 1
        if hasmask:
            pack_string = '!' + cls.pack_str[1:] * 2
            value = struct.unpack_from(pack_string, buf, offset + 4)
            return cls(header, list(value[:8]), list(value[8:]))
        else:
            value = struct.unpack_from(cls.pack_str, buf, offset + 4)
            return cls(header, list(value))


@_register_make
@_set_nxm_headers([ofproto_v1_0.NXM_NX_IPV6_SRC,
                   ofproto_v1_0.NXM_NX_IPV6_SRC_W])
@MFField.register_field_header([ofproto_v1_0.NXM_NX_IPV6_SRC,
                                ofproto_v1_0.NXM_NX_IPV6_SRC_W])
class MFIPV6Src(MFIPV6, MFField):
    def __init__(self, header, value, mask=None):
        super(MFIPV6Src, self).__init__(header, MFIPV6Src.pack_str)
        self.value = value
        self.mask = mask

    @classmethod
    def make(cls, header):
        return cls(header, cls.pack_str)

    def put(self, buf, offset, rule):
        return self.putv6(buf, offset,
                          rule.flow.ipv6_src,
                          rule.wc.ipv6_src_mask)


@_register_make
@_set_nxm_headers([ofproto_v1_0.NXM_NX_IPV6_DST,
                   ofproto_v1_0.NXM_NX_IPV6_DST_W])
@MFField.register_field_header([ofproto_v1_0.NXM_NX_IPV6_DST,
                                ofproto_v1_0.NXM_NX_IPV6_DST_W])
class MFIPV6Dst(MFIPV6, MFField):
    def __init__(self, header, value, mask=None):
        super(MFIPV6Dst, self).__init__(header, MFIPV6Dst.pack_str)
        self.value = value
        self.mask = mask

    @classmethod
    def make(cls, header):
        return cls(header, cls.pack_str)

    def put(self, buf, offset, rule):
        return self.putv6(buf, offset,
                          rule.flow.ipv6_dst,
                          rule.wc.ipv6_dst_mask)


@_register_make
@_set_nxm_headers([ofproto_v1_0.NXM_NX_ND_TARGET,
                   ofproto_v1_0.NXM_NX_ND_TARGET_W])
class MFNdTarget(MFField):
    @classmethod
    def make(cls, header):
        return cls(header, '!4I')

    def put(self, buf, offset, rule):
        return self.putv6(buf, offset,
                          rule.flow.nd_target,
                          rule.wc.nd_target_mask)


@_register_make
@_set_nxm_headers([ofproto_v1_0.NXM_NX_IP_FRAG,
                   ofproto_v1_0.NXM_NX_IP_FRAG_W])
class MFIpFrag(MFField):
    @classmethod
    def make(cls, header):
        return cls(header, '!B')

    def put(self, buf, offset, rule):
        if rule.wc.nw_frag_mask == FLOW_NW_FRAG_MASK:
            return self._put(buf, offset, rule.flow.nw_frag)
        else:
            return self.putw(buf, offset, rule.flow.nw_frag,
                             rule.wc.nw_frag_mask & FLOW_NW_FRAG_MASK)


@_register_make
@_set_nxm_headers([ofproto_v1_0.NXM_NX_ARP_THA])
class MFArpTha(MFField):
    @classmethod
    def make(cls, header):
        return cls(header, MF_PACK_STRING_MAC)

    def put(self, buf, offset, rule):
        return self._put(buf, offset, rule.flow.arp_tha)


@_register_make
@_set_nxm_headers([ofproto_v1_0.NXM_OF_ICMP_TYPE])
class MFICMPType(MFField):
    @classmethod
    def make(cls, header):
        return cls(header, MF_PACK_STRING_8)

    def put(self, buf, offset, rule):
        return self._put(buf, offset, rule.flow.tp_src)


@_register_make
@_set_nxm_headers([ofproto_v1_0.NXM_OF_ICMP_CODE])
class MFICMPCode(MFField):
    @classmethod
    def make(cls, header):
        return cls(header, MF_PACK_STRING_8)

    def put(self, buf, offset, rule):
        return self._put(buf, offset, rule.flow.tp_dst)


@_register_make
@_set_nxm_headers([ofproto_v1_0.NXM_NX_ICMPV6_TYPE])
class MFICMPV6Type(MFField):
    @classmethod
    def make(cls, header):
        return cls(header, MF_PACK_STRING_8)

    def put(self, buf, offset, rule):
        return self._put(buf, offset, rule.flow.tp_src)


@_register_make
@_set_nxm_headers([ofproto_v1_0.NXM_NX_ICMPV6_CODE])
class MFICMPV6Code(MFField):
    @classmethod
    def make(cls, header):
        return cls(header, MF_PACK_STRING_8)

    def put(self, buf, offset, rule):
        return self._put(buf, offset, rule.flow.tp_dst)


@_register_make
@_set_nxm_headers([ofproto_v1_0.NXM_NX_IPV6_LABEL])
class MFICMPV6Label(MFField):
    @classmethod
    def make(cls, header):
        return cls(header, MF_PACK_STRING_BE32)

    def put(self, buf, offset, rule):
        return self._put(buf, offset, rule.flow.ipv6_label)


@_register_make
@_set_nxm_headers([ofproto_v1_0.nxm_nx_reg(i) for i in range(FLOW_N_REGS)]
                  + [ofproto_v1_0.nxm_nx_reg_w(i) for i in range(FLOW_N_REGS)])
class MFRegister(MFField):
    @classmethod
    def make(cls, header):
        return cls(header, MF_PACK_STRING_BE32)

    def put(self, buf, offset, rule):
        for i in range(FLOW_N_REGS):
            if (ofproto_v1_0.nxm_nx_reg(i) == self.nxm_header or
                    ofproto_v1_0.nxm_nx_reg_w(i) == self.nxm_header):
                if rule.wc.regs_mask[i]:
                    return self.putm(buf, offset, rule.flow.regs[i],
                                     rule.wc.regs_mask[i])
                else:
                    return self._put(buf, offset, rule.flow.regs[i])


def serialize_nxm_match(rule, buf, offset):
    old_offset = offset

    if not rule.wc.wildcards & FWW_IN_PORT:
        offset += nxm_put(buf, offset, ofproto_v1_0.NXM_OF_IN_PORT, rule)

    # Ethernet.
    if rule.flow.dl_dst != mac.DONTCARE:
        if rule.wc.dl_dst_mask:
            header = ofproto_v1_0.NXM_OF_ETH_DST_W
        else:
            header = ofproto_v1_0.NXM_OF_ETH_DST
        offset += nxm_put(buf, offset, header, rule)

    if rule.flow.dl_src != mac.DONTCARE:
        if rule.wc.dl_src_mask:
            header = ofproto_v1_0.NXM_OF_ETH_SRC_W
        else:
            header = ofproto_v1_0.NXM_OF_ETH_SRC
        offset += nxm_put(buf, offset, header, rule)

    if not rule.wc.wildcards & FWW_DL_TYPE:
        offset += nxm_put(buf, offset, ofproto_v1_0.NXM_OF_ETH_TYPE, rule)

    # 802.1Q
    if rule.wc.vlan_tci_mask != 0:
        if rule.wc.vlan_tci_mask == UINT16_MAX:
            header = ofproto_v1_0.NXM_OF_VLAN_TCI
        else:
            header = ofproto_v1_0.NXM_OF_VLAN_TCI_W
        offset += nxm_put(buf, offset, header, rule)

    # L3
    if not rule.wc.wildcards & FWW_NW_DSCP:
        offset += nxm_put(buf, offset, ofproto_v1_0.NXM_OF_IP_TOS, rule)
    if not rule.wc.wildcards & FWW_NW_ECN:
        offset += nxm_put(buf, offset, ofproto_v1_0.NXM_NX_IP_ECN, rule)
    if not rule.wc.wildcards & FWW_NW_TTL:
        offset += nxm_put(buf, offset, ofproto_v1_0.NXM_NX_IP_TTL, rule)
    if not rule.wc.wildcards & FWW_NW_PROTO:
        offset += nxm_put(buf, offset, ofproto_v1_0.NXM_OF_IP_PROTO, rule)

    if not rule.wc.wildcards & FWW_NW_PROTO and (rule.flow.nw_proto
                                                 == inet.IPPROTO_ICMP):
        if rule.wc.tp_src_mask != 0:
            offset += nxm_put(buf, offset, ofproto_v1_0.NXM_OF_ICMP_TYPE, rule)
        if rule.wc.tp_dst_mask != 0:
            offset += nxm_put(buf, offset, ofproto_v1_0.NXM_OF_ICMP_CODE, rule)

    if rule.flow.tp_src != 0:
        if rule.flow.nw_proto == 6:
            if rule.wc.tp_src_mask == UINT16_MAX:
                header = ofproto_v1_0.NXM_OF_TCP_SRC
            else:
                header = ofproto_v1_0.NXM_OF_TCP_SRC_W
        elif rule.flow.nw_proto == 17:
            if rule.wc.tp_src_mask == UINT16_MAX:
                header = ofproto_v1_0.NXM_OF_UDP_SRC
            else:
                header = ofproto_v1_0.NXM_OF_UDP_SRC_W
        else:
            header = 0
        if header != 0:
            offset += nxm_put(buf, offset, header, rule)

    if rule.flow.tp_dst != 0:
        if rule.flow.nw_proto == 6:
            if rule.wc.tp_dst_mask == UINT16_MAX:
                header = ofproto_v1_0.NXM_OF_TCP_DST
            else:
                header = ofproto_v1_0.NXM_OF_TCP_DST_W
        elif rule.flow.nw_proto == 17:
            if rule.wc.tp_dst_mask == UINT16_MAX:
                header = ofproto_v1_0.NXM_OF_UDP_DST
            else:
                header = ofproto_v1_0.NXM_OF_UDP_DST_W
        else:
            header = 0
        if header != 0:
            offset += nxm_put(buf, offset, header, rule)

    # IP Source and Destination
    if rule.flow.nw_src != 0:
        if rule.wc.nw_src_mask == UINT32_MAX:
            header = ofproto_v1_0.NXM_OF_IP_SRC
        else:
            header = ofproto_v1_0.NXM_OF_IP_SRC_W
        offset += nxm_put(buf, offset, header, rule)

    if rule.flow.nw_dst != 0:
        if rule.wc.nw_dst_mask == UINT32_MAX:
            header = ofproto_v1_0.NXM_OF_IP_DST
        else:
            header = ofproto_v1_0.NXM_OF_IP_DST_W
        offset += nxm_put(buf, offset, header, rule)

    # IPv6
    if not rule.wc.wildcards & FWW_NW_PROTO and (rule.flow.nw_proto
                                                 == inet.IPPROTO_ICMPV6):
        if rule.wc.tp_src_mask != 0:
            offset += nxm_put(buf, offset, ofproto_v1_0.NXM_NX_ICMPV6_TYPE,
                              rule)
        if rule.wc.tp_dst_mask != 0:
            offset += nxm_put(buf, offset, ofproto_v1_0.NXM_NX_ICMPV6_CODE,
                              rule)

    if not rule.wc.wildcards & FWW_IPV6_LABEL:
        offset += nxm_put(buf, offset, ofproto_v1_0.NXM_NX_IPV6_LABEL, rule)

    if len(rule.flow.ipv6_src):
        if len(rule.wc.ipv6_src_mask):
            header = ofproto_v1_0.NXM_NX_IPV6_SRC_W
        else:
            header = ofproto_v1_0.NXM_NX_IPV6_SRC
        offset += nxm_put(buf, offset, header, rule)

    if len(rule.flow.ipv6_dst):
        if len(rule.wc.ipv6_dst_mask):
            header = ofproto_v1_0.NXM_NX_IPV6_DST_W
        else:
            header = ofproto_v1_0.NXM_NX_IPV6_DST
        offset += nxm_put(buf, offset, header, rule)

    if len(rule.flow.nd_target):
        if len(rule.wc.nd_target_mask):
            header = ofproto_v1_0.NXM_NX_ND_TARGET_W
        else:
            header = ofproto_v1_0.NXM_NX_ND_TARGET
        offset += nxm_put(buf, offset, header, rule)

    # ARP
    if rule.flow.arp_spa != 0:
        if rule.wc.arp_spa_mask == UINT32_MAX:
            header = ofproto_v1_0.NXM_OF_ARP_SPA
        else:
            header = ofproto_v1_0.NXM_OF_ARP_SPA_W
        offset += nxm_put(buf, offset, header, rule)

    if rule.flow.arp_tpa != 0:
        if rule.wc.arp_tpa_mask == UINT32_MAX:
            header = ofproto_v1_0.NXM_OF_ARP_TPA
        else:
            header = ofproto_v1_0.NXM_OF_ARP_TPA_W
        offset += nxm_put(buf, offset, header, rule)

    if not rule.wc.wildcards & FWW_ARP_SHA:
        offset += nxm_put(buf, offset, ofproto_v1_0.NXM_NX_ARP_SHA, rule)
    if not rule.wc.wildcards & FWW_ARP_THA:
        offset += nxm_put(buf, offset, ofproto_v1_0.NXM_NX_ARP_THA, rule)

    if rule.flow.nw_frag:
        if rule.wc.nw_frag_mask == FLOW_NW_FRAG_MASK:
            header = ofproto_v1_0.NXM_NX_IP_FRAG
        else:
            header = ofproto_v1_0.NXM_NX_IP_FRAG_W
        offset += nxm_put(buf, offset, header, rule)

    # Tunnel Id
    if rule.wc.tun_id_mask != 0:
        if rule.wc.tun_id_mask == UINT64_MAX:
            header = ofproto_v1_0.NXM_NX_TUN_ID
        else:
            header = ofproto_v1_0.NXM_NX_TUN_ID_W
        offset += nxm_put(buf, offset, header, rule)

    # XXX: Cookie

    for i in range(FLOW_N_REGS):
        if rule.wc.regs_bits & (1 << i):
            if rule.wc.regs_mask[i]:
                header = ofproto_v1_0.nxm_nx_reg_w(i)
            else:
                header = ofproto_v1_0.nxm_nx_reg(i)
            offset += nxm_put(buf, offset, header, rule)

    # Pad
    pad_len = round_up(offset) - offset
    ofproto_parser.msg_pack_into("%dx" % pad_len, buf, offset)

    # The returned length, the match_len, does not include the pad
    return offset - old_offset


def nxm_put(buf, offset, header, rule):
    nxm = NXMatch(header)
    len_ = nxm.put_header(buf, offset)
    mf = mf_from_nxm_header(nxm.header)
    return len_ + mf.put(buf, offset + len_, rule)


def round_up(length):
    return (length + 7) / 8 * 8  # Round up to a multiple of 8


class NXMatch(object):
    def __init__(self, header):
        self.header = header

    @classmethod
    def parser(cls, buf, offset, match_len):
        if match_len < 4:
            raise exception.OFPMalformedMessage
        (header,) = struct.unpack_from(ofproto_v1_0.NXM_HEADER_PACK_STRING,
                                       buf, offset)
        instance = cls(header)
        payload_len = instance.length()
        if payload_len == 0 or match_len < payload_len + 4:
            raise exception.OFPMalformedMessage
        return instance

    def vendor(self):
        return self.header >> 16

    def field(self):
        return (self.header >> 9) % 0x7f

    def type(self):
        return (self.header >> 9) % 0x7fffff

    def hasmask(self):
        return (self.header >> 8) & 1

    def length(self):
        return self.header & 0xff

    def show(self):
        return ('%08x (vendor=%x, field=%x, hasmask=%x len=%x)' %
                (self.header, self.vendor(), self.field(),
                 self.hasmask(), self.length()))

    def put_header(self, buf, offset):
        ofproto_parser.msg_pack_into(ofproto_v1_0.NXM_HEADER_PACK_STRING,
                                     buf, offset, self.header)
        return struct.calcsize(ofproto_v1_0.NXM_HEADER_PACK_STRING)

########NEW FILE########
__FILENAME__ = ofproto_common
# Copyright (C) 2011, 2012 Nippon Telegraph and Telephone Corporation.
# Copyright (C) 2011 Isaku Yamahata <yamahata at valinux co jp>
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from struct import calcsize


OFP_HEADER_PACK_STR = '!BBHI'
OFP_HEADER_SIZE = 8
assert calcsize(OFP_HEADER_PACK_STR) == OFP_HEADER_SIZE

# note: while IANA assigned port number for OpenFlow is 6653,
# 6633 is (still) the defacto standard.
OFP_TCP_PORT = 6633
OFP_SSL_PORT = 6633

# Vendor/Experimenter IDs
NX_EXPERIMENTER_ID = 0x00002300  # Nicira
BSN_EXPERIMENTER_ID = 0x005c16c7  # Big Switch Networks
ONF_EXPERIMENTER_ID = 0x4f4e4600  # OpenFlow Extensions for 1.3.X Pack 1

########NEW FILE########
__FILENAME__ = ofproto_parser
# Copyright (C) 2011, 2012 Nippon Telegraph and Telephone Corporation.
# Copyright (C) 2011 Isaku Yamahata <yamahata at valinux co jp>
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import collections
import logging
import struct
import sys
import functools

from ryu import exception
from ryu import utils
from ryu.lib import stringify

from . import ofproto_common

LOG = logging.getLogger('ryu.ofproto.ofproto_parser')


def header(buf):
    assert len(buf) >= ofproto_common.OFP_HEADER_SIZE
    #LOG.debug('len %d bufsize %d', len(buf), ofproto.OFP_HEADER_SIZE)
    return struct.unpack_from(ofproto_common.OFP_HEADER_PACK_STR, buffer(buf))


_MSG_PARSERS = {}


def register_msg_parser(version):
    def register(msg_parser):
        _MSG_PARSERS[version] = msg_parser
        return msg_parser
    return register


def msg(datapath, version, msg_type, msg_len, xid, buf):
    assert len(buf) >= msg_len

    msg_parser = _MSG_PARSERS.get(version)
    if msg_parser is None:
        raise exception.OFPUnknownVersion(version=version)

    try:
        return msg_parser(datapath, version, msg_type, msg_len, xid, buf)
    except struct.error:
        LOG.exception(
            'Encounter an error during parsing OpenFlow packet from switch.'
            'This implies switch sending a malfold OpenFlow packet.'
            'version 0x%02x msg_type %d msg_len %d xid %d buf %s',
            version, msg_type, msg_len, xid, utils.bytearray_to_hex(buf))
        raise


def create_list_of_base_attributes(f):
    @functools.wraps(f)
    def wrapper(self, *args, **kwargs):
        ret = f(self, *args, **kwargs)
        cls = self.__class__
        # hasattr(cls, '_base_attributes') doesn't work because super class
        # may already have the attribute.
        if '_base_attributes' not in cls.__dict__:
            cls._base_attributes = set(dir(self))
        return ret
    return wrapper


def ofp_msg_from_jsondict(dp, jsondict):
    """
    This function instanticates an appropriate OpenFlow message class
    from the given JSON style dictionary.
    The objects created by following two code fragments are equivalent.

    Code A::

        jsonstr = '{ "OFPSetConfig": { "flags": 0, "miss_send_len": 128 } }'
        jsondict = json.loads(jsonstr)
        o = ofp_msg_from_jsondict(dp, jsondict)

    Code B::

        o = dp.ofproto_parser.OFPSetConfig(flags=0, miss_send_len=128)

    This function takes the following arguments.

    ======== =======================================
    Argument Description
    ======== =======================================
    dp       An instance of ryu.controller.Datapath.
    jsondict A JSON style dict.
    ======== =======================================
    """
    parser = dp.ofproto_parser
    assert len(jsondict) == 1
    for k, v in jsondict.iteritems():
        cls = getattr(parser, k)
        assert issubclass(cls, MsgBase)
        return cls.from_jsondict(v, datapath=dp)


class StringifyMixin(stringify.StringifyMixin):
    _class_prefixes = ["OFP", "MT"]

    @classmethod
    def cls_from_jsondict_key(cls, k):
        obj_cls = super(StringifyMixin, cls).cls_from_jsondict_key(k)
        assert not issubclass(obj_cls, MsgBase)
        return obj_cls


class MsgBase(StringifyMixin):
    """
    This is a base class for OpenFlow message classes.

    An instance of this class has at least the following attributes.

    ========= ==============================
    Attribute Description
    ========= ==============================
    datapath  A ryu.controller.controller.Datapath instance for this message
    version   OpenFlow protocol version
    msg_type  Type of OpenFlow message
    msg_len   Length of the message
    xid       Transaction id
    buf       Raw data
    ========= ==============================
    """

    @create_list_of_base_attributes
    def __init__(self, datapath):
        super(MsgBase, self).__init__()
        self.datapath = datapath
        self.version = None
        self.msg_type = None
        self.msg_len = None
        self.xid = None
        self.buf = None

    def set_headers(self, version, msg_type, msg_len, xid):
        assert msg_type == self.cls_msg_type

        self.version = version
        self.msg_type = msg_type
        self.msg_len = msg_len
        self.xid = xid

    def set_xid(self, xid):
        assert self.xid is None
        self.xid = xid

    def set_buf(self, buf):
        self.buf = buffer(buf)

    def __str__(self):
        buf = 'version: 0x%x msg_type 0x%x xid 0x%x ' % (self.version,
                                                         self.msg_type,
                                                         self.xid)
        return buf + StringifyMixin.__str__(self)

    @classmethod
    def parser(cls, datapath, version, msg_type, msg_len, xid, buf):
        msg_ = cls(datapath)
        msg_.set_headers(version, msg_type, msg_len, xid)
        msg_.set_buf(buf)
        return msg_

    def _serialize_pre(self):
        self.version = self.datapath.ofproto.OFP_VERSION
        self.msg_type = self.cls_msg_type
        self.buf = bytearray(self.datapath.ofproto.OFP_HEADER_SIZE)

    def _serialize_header(self):
        # buffer length is determined after trailing data is formated.
        assert self.version is not None
        assert self.msg_type is not None
        assert self.buf is not None
        assert len(self.buf) >= self.datapath.ofproto.OFP_HEADER_SIZE

        self.msg_len = len(self.buf)
        if self.xid is None:
            self.xid = 0

        struct.pack_into(self.datapath.ofproto.OFP_HEADER_PACK_STR,
                         self.buf, 0,
                         self.version, self.msg_type, self.msg_len, self.xid)

    def _serialize_body(self):
        pass

    def serialize(self):
        self._serialize_pre()
        self._serialize_body()
        self._serialize_header()


def msg_pack_into(fmt, buf, offset, *args):
    if len(buf) < offset:
        buf += bytearray(offset - len(buf))

    if len(buf) == offset:
        buf += struct.pack(fmt, *args)
        return

    needed_len = offset + struct.calcsize(fmt)
    if len(buf) < needed_len:
        buf += bytearray(needed_len - len(buf))

    struct.pack_into(fmt, buf, offset, *args)


def namedtuple(typename, fields, **kwargs):
    class _namedtuple(StringifyMixin,
                      collections.namedtuple(typename, fields, **kwargs)):
        pass
    return _namedtuple


def msg_str_attr(msg_, buf, attr_list=None):
    if attr_list is None:
        attr_list = stringify.obj_attrs(msg_)
    for attr in attr_list:
        val = getattr(msg_, attr, None)
        if val is not None:
            buf += ' %s %s' % (attr, val)

    return buf

########NEW FILE########
__FILENAME__ = ofproto_v1_0
# Copyright (C) 2011, 2012 Nippon Telegraph and Telephone Corporation.
# Copyright (C) 2011, 2012 Isaku Yamahata <yamahata at valinux co jp>
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from struct import calcsize


MAX_XID = 0xffffffff

# define constants
OFP_VERSION = 0x01
OFP_MAX_TABLE_NAME_LEN = 32
OFP_MAX_TABLE_NAME_LEN_STR = str(OFP_MAX_TABLE_NAME_LEN)
OFP_MAX_PORT_NAME_LEN = 16
OFP_TCP_PORT = 6633
OFP_SSL_PORT = 6633
OFP_ETH_ALEN = 6
OFP_ETH_ALEN_STR = str(OFP_ETH_ALEN)

OFP_NO_BUFFER = 0xffffffff

# enum ofp_port
OFPP_MAX = 0xff00
OFPP_IN_PORT = 0xfff8   # Send the packet out the input port. This
                        # virtual port must be explicitly used
                        # in order to send back out of the input
                        # port.
OFPP_TABLE = 0xfff9     # Perform actions in flow table.
                        # NB: This can only be the destination
                        # port for packet-out messages.
OFPP_NORMAL = 0xfffa    # Process with normal L2/L3 switching.
OFPP_FLOOD = 0xfffb     # All physical ports except input port and
                        # those disabled by STP.
OFPP_ALL = 0xfffc       # All physical ports except input port.
OFPP_CONTROLLER = 0xfffd        # Send to controller.
OFPP_LOCAL = 0xfffe     # Local openflow "port".
OFPP_NONE = 0xffff      # Not associated with a physical port.

# enum ofp_type
OFPT_HELLO = 0  # Symmetric message
OFPT_ERROR = 1  # Symmetric message
OFPT_ECHO_REQUEST = 2   # Symmetric message
OFPT_ECHO_REPLY = 3     # Symmetric message
OFPT_VENDOR = 4         # Symmetric message
OFPT_FEATURES_REQUEST = 5       # Controller/switch message
OFPT_FEATURES_REPLY = 6         # Controller/switch message
OFPT_GET_CONFIG_REQUEST = 7     # Controller/switch message
OFPT_GET_CONFIG_REPLY = 8       # Controller/switch message
OFPT_SET_CONFIG = 9      # Controller/switch message
OFPT_PACKET_IN = 10      # Async message
OFPT_FLOW_REMOVED = 11   # Async message
OFPT_PORT_STATUS = 12    # Async message
OFPT_PACKET_OUT = 13     # Controller/switch message
OFPT_FLOW_MOD = 14       # Controller/switch message
OFPT_PORT_MOD = 15       # Controller/switch message
OFPT_STATS_REQUEST = 16  # Controller/switch message
OFPT_STATS_REPLY = 17    # Controller/switch message
OFPT_BARRIER_REQUEST = 18       # Controller/switch message
OFPT_BARRIER_REPLY = 19  # Controller/switch message
OFPT_QUEUE_GET_CONFIG_REQUEST = 20      # Controller/switch message
OFPT_QUEUE_GET_CONFIG_REPLY = 21        # Controller/switch message

OFP_HEADER_PACK_STR = '!BBHI'
OFP_HEADER_SIZE = 8
OFP_MSG_SIZE_MAX = 65535
assert calcsize(OFP_HEADER_PACK_STR) == OFP_HEADER_SIZE

# define constants
OFP_DEFAULT_MISS_SEND_LEN = 128

# enum ofp_config_flags
OFPC_FRAG_NORMAL = 0    # No special handling for fragments.
OFPC_FRAG_DROP = 1      # Drop fragments.
OFPC_FRAG_REASM = 2     # Reassemble (only if OFPC_IP_REASM set).
OFPC_FRAG_NX_MATCH = 3  # Make first fragments available for matching.
OFPC_FRAG_MASK = 3

OFP_SWITCH_CONFIG_PACK_STR = '!HH'
OFP_SWITCH_CONFIG_SIZE = 12
assert (calcsize(OFP_SWITCH_CONFIG_PACK_STR) + OFP_HEADER_SIZE ==
        OFP_SWITCH_CONFIG_SIZE)

# enum ofp_capabilities
OFPC_FLOW_STATS = 1 << 0        # Flow statistics.
OFPC_TABLE_STATS = 1 << 1       # Table statistics.
OFPC_PORT_STATS = 1 << 2        # Port statistics.
OFPC_STP = 1 << 3               # 802.1d spanning tree.
OFPC_RESERVED = 1 << 4          # Reserved, must not be set.
OFPC_IP_REASM = 1 << 5          # Can reassemble IP fragments.
OFPC_QUEUE_STATS = 1 << 6       # Queue statistics.
OFPC_ARP_MATCH_IP = 1 << 7      # Match IP addresses in ARP pkts.

# enum ofp_port_config
OFPPC_PORT_DOWN = 1 << 0        # Port is administratively down.
OFPPC_NO_STP = 1 << 1           # Disable 802.1D spanning tree on port.
OFPPC_NO_RECV = 1 << 2          # Drop all packets except 802.1D
                                # spanning tree packets
OFPPC_NO_RECV_STP = 1 << 3      # Drop received 802.1D STP packets.
OFPPC_NO_FLOOD = 1 << 4         # Do not include this port when flooding.
OFPPC_NO_FWD = 1 << 5           # Drop packets forwarded to port.
OFPPC_NO_PACKET_IN = 1 << 6     # Do not send packet-in msgs for port.

# enum ofp_port_state
OFPPS_LINK_DOWN = 1 << 0        # No physical link present.
OFPPS_STP_LISTEN = 0 << 8       # Not learning or relaying frames.
OFPPS_STP_LEARN = 1 << 8        # Learning but not relaying frames.
OFPPS_STP_FORWARD = 2 << 8      # Learning and relaying frames.
OFPPS_STP_BLOCK = 3 << 8        # Not part of spanning tree.
OFPPS_STP_MASK = 3 << 8         # Bit mask for OFPPS_STP_* values.

# enum ofp_port_features
OFPPF_10MB_HD = 1 << 0          # 10 Mb half-duplex rate support.
OFPPF_10MB_FD = 1 << 1          # 10 Mb full-duplex rate support.
OFPPF_100MB_HD = 1 << 2         # 100 Mb half-duplex rate support.
OFPPF_100MB_FD = 1 << 3         # 100 Mb full-duplex rate support.
OFPPF_1GB_HD = 1 << 4           # 1 Gb half-duplex rate support.
OFPPF_1GB_FD = 1 << 5           # 1 Gb full-duplex rate support.
OFPPF_10GB_FD = 1 << 6          # 10 Gb full-duplex rate support.
OFPPF_COPPER = 1 << 7           # Copper medium.
OFPPF_FIBER = 1 << 8            # Fiber medium.
OFPPF_AUTONEG = 1 << 9          # Auto-negotiation.
OFPPF_PAUSE = 1 << 10           # Pause.
OFPPF_PAUSE_ASYM = 1 << 11      # Asymmetric pause.

_OFP_PHY_PORT_PACK_STR = 'H' + OFP_ETH_ALEN_STR + 's' + \
                         str(OFP_MAX_PORT_NAME_LEN) + 'sIIIIII'
OFP_PHY_PORT_PACK_STR = '!' + _OFP_PHY_PORT_PACK_STR
OFP_PHY_PORT_SIZE = 48
assert calcsize(OFP_PHY_PORT_PACK_STR) == OFP_PHY_PORT_SIZE

OFP_SWITCH_FEATURES_PACK_STR = '!QIB3xII'
OFP_SWITCH_FEATURES_SIZE = 32
assert (calcsize(OFP_SWITCH_FEATURES_PACK_STR) + OFP_HEADER_SIZE ==
        OFP_SWITCH_FEATURES_SIZE)

# enum ofp_port_reason
OFPPR_ADD = 0           # The port was added.
OFPPR_DELETE = 1        # The port was removed.
OFPPR_MODIFY = 2        # Some attribute of the port has changed.

OFP_PORT_STATUS_PACK_STR = '!B7x' + _OFP_PHY_PORT_PACK_STR
OFP_PORT_STATUS_DESC_OFFSET = OFP_HEADER_SIZE + 8
OFP_PORT_STATUS_SIZE = 64
assert (calcsize(OFP_PORT_STATUS_PACK_STR) + OFP_HEADER_SIZE ==
        OFP_PORT_STATUS_SIZE)

OFP_PORT_MOD_PACK_STR = '!H' + OFP_ETH_ALEN_STR + 'sIII4x'
OFP_PORT_MOD_SIZE = 32
assert calcsize(OFP_PORT_MOD_PACK_STR) + OFP_HEADER_SIZE == OFP_PORT_MOD_SIZE

# enum ofp_packet_in_reason
OFPR_NO_MATCH = 0       # No matching flow.
OFPR_ACTION = 1         # Action explicitly output to controller.

# OF1.0 spec says OFP_ASSERT(sizeof(struct ofp_packet_in) == 20).
# It's quite bogus as it assumes a specific class of C implementations.
# (well, if it was C.  it's unclear from the spec itself.)
# We just use the real size of the structure as this is not C.  This
# agrees with on-wire messages OpenFlow Reference Release and Open vSwitch
# produce.
OFP_PACKET_IN_PACK_STR = '!IHHBx'
OFP_PACKET_IN_SIZE = 18
assert calcsize(OFP_PACKET_IN_PACK_STR) + OFP_HEADER_SIZE == OFP_PACKET_IN_SIZE

# enum ofp_action_type
OFPAT_OUTPUT = 0        # Output to switch port.
OFPAT_SET_VLAN_VID = 1  # Set the 802.1q VLAN id.
OFPAT_SET_VLAN_PCP = 2  # Set the 802.1q priority.
OFPAT_STRIP_VLAN = 3    # Strip the 802.1q header.
OFPAT_SET_DL_SRC = 4    # Ethernet source address.
OFPAT_SET_DL_DST = 5    # Ethernet destination address.
OFPAT_SET_NW_SRC = 6    # IP source address.
OFPAT_SET_NW_DST = 7    # IP destination address.
OFPAT_SET_NW_TOS = 8    # IP ToS (DSCP field, 6 bits).
OFPAT_SET_TP_SRC = 9    # TCP/UDP source port.
OFPAT_SET_TP_DST = 10   # TCP/UDP destination port.
OFPAT_ENQUEUE = 11      # Output to queue.
OFPAT_VENDOR = 0xffff

OFP_ACTION_OUTPUT_PACK_STR = '!HHHH'
OFP_ACTION_OUTPUT_SIZE = 8
assert calcsize(OFP_ACTION_OUTPUT_PACK_STR) == OFP_ACTION_OUTPUT_SIZE

# define constants
OFP_VLAN_NONE = 0xffff

OFP_ACTION_VLAN_VID_PACK_STR = '!HHH2x'
OFP_ACTION_VLAN_VID_SIZE = 8
assert calcsize(OFP_ACTION_VLAN_VID_PACK_STR) == OFP_ACTION_VLAN_VID_SIZE

OFP_ACTION_VLAN_PCP_PACK_STR = '!HHB3x'
OFP_ACTION_VLAN_PCP_SIZE = 8
assert calcsize(OFP_ACTION_VLAN_PCP_PACK_STR) == OFP_ACTION_VLAN_PCP_SIZE

OFP_ACTION_DL_ADDR_PACK_STR = '!HH' + OFP_ETH_ALEN_STR + 's6x'
OFP_ACTION_DL_ADDR_SIZE = 16
assert calcsize(OFP_ACTION_DL_ADDR_PACK_STR) == OFP_ACTION_DL_ADDR_SIZE

OFP_ACTION_NW_ADDR_PACK_STR = '!HHI'
OFP_ACTION_NW_ADDR_SIZE = 8
assert calcsize(OFP_ACTION_NW_ADDR_PACK_STR) == OFP_ACTION_NW_ADDR_SIZE

OFP_ACTION_NW_TOS_PACK_STR = '!HHB3x'
OFP_ACTION_NW_TOS_SIZE = 8
assert calcsize(OFP_ACTION_NW_TOS_PACK_STR) == OFP_ACTION_NW_TOS_SIZE

OFP_ACTION_TP_PORT_PACK_STR = '!HHH2x'
OFP_ACTION_TP_PORT_SIZE = 8
assert calcsize(OFP_ACTION_TP_PORT_PACK_STR) == OFP_ACTION_TP_PORT_SIZE

OFP_ACTION_VENDOR_HEADER_PACK_STR = '!HHI'
OFP_ACTION_VENDOR_HEADER_SIZE = 8
assert (calcsize(OFP_ACTION_VENDOR_HEADER_PACK_STR) ==
        OFP_ACTION_VENDOR_HEADER_SIZE)

OFP_ACTION_HEADER_PACK_STR = '!HH4x'
OFP_ACTION_HEADER_SIZE = 8
assert calcsize(OFP_ACTION_HEADER_PACK_STR) == OFP_ACTION_HEADER_SIZE

OFP_ACTION_ENQUEUE_PACK_STR = '!HHH6xI'
OFP_ACTION_ENQUEUE_SIZE = 16
assert calcsize(OFP_ACTION_ENQUEUE_PACK_STR) == OFP_ACTION_ENQUEUE_SIZE

OFP_ACTION_PACK_STR = '!H'
# because of union ofp_action
# OFP_ACTION_SIZE = 8
# assert calcsize(OFP_ACTION_PACK_STR) == OFP_ACTION_SIZE

# enum nx_action_subtype
NXAST_RESUBMIT = 1
NXAST_SET_TUNNEL = 2
NXAST_DROP_SPOOFED_ARP__OBSOLETE = 3
NXAST_SET_QUEUE = 4
NXAST_POP_QUEUE = 5
NXAST_REG_MOVE = 6
NXAST_REG_LOAD = 7
NXAST_NOTE = 8
NXAST_SET_TUNNEL64 = 9
NXAST_MULTIPATH = 10
NXAST_AUTOPATH = 11
NXAST_BUNDLE = 12
NXAST_BUNDLE_LOAD = 13
NXAST_RESUBMIT_TABLE = 14
NXAST_OUTPUT_REG = 15
NXAST_LEARN = 16
NXAST_EXIT = 17
NXAST_DEC_TTL = 18
NXAST_FIN_TIMEOUT = 19
NXAST_CONTROLLER = 20

NX_ACTION_RESUBMIT_PACK_STR = '!HHIHHB3x'
NX_ACTION_RESUBMIT_SIZE = 16
assert calcsize(NX_ACTION_RESUBMIT_PACK_STR) == NX_ACTION_RESUBMIT_SIZE

NX_ACTION_SET_TUNNEL_PACK_STR = '!HHIH2xI'
NX_ACTION_SET_TUNNEL_SIZE = 16
assert calcsize(NX_ACTION_SET_TUNNEL_PACK_STR) == NX_ACTION_SET_TUNNEL_SIZE

NX_ACTION_SET_QUEUE_PACK_STR = '!HHIH2xI'
NX_ACTION_SET_QUEUE_SIZE = 16
assert calcsize(NX_ACTION_SET_QUEUE_PACK_STR) == NX_ACTION_SET_QUEUE_SIZE

NX_ACTION_POP_QUEUE_PACK_STR = '!HHIH6x'
NX_ACTION_POP_QUEUE_SIZE = 16
assert calcsize(NX_ACTION_POP_QUEUE_PACK_STR) == NX_ACTION_POP_QUEUE_SIZE

NX_ACTION_REG_MOVE_PACK_STR = '!HHIHHHHII'
NX_ACTION_REG_MOVE_SIZE = 24
assert calcsize(NX_ACTION_REG_MOVE_PACK_STR) == NX_ACTION_REG_MOVE_SIZE

NX_ACTION_REG_LOAD_PACK_STR = '!HHIHHIQ'
NX_ACTION_REG_LOAD_SIZE = 24
assert calcsize(NX_ACTION_REG_LOAD_PACK_STR) == NX_ACTION_REG_LOAD_SIZE

NX_ACTION_SET_TUNNEL64_PACK_STR = '!HHIH6xQ'
NX_ACTION_SET_TUNNEL64_SIZE = 24
assert calcsize(NX_ACTION_SET_TUNNEL64_PACK_STR) == NX_ACTION_SET_TUNNEL64_SIZE

NX_ACTION_MULTIPATH_PACK_STR = '!HHIHHH2xHHI2xHI'
NX_ACTION_MULTIPATH_SIZE = 32
assert calcsize(NX_ACTION_MULTIPATH_PACK_STR) == NX_ACTION_MULTIPATH_SIZE

NX_ACTION_NOTE_PACK_STR = '!HHIH6B'
NX_ACTION_NOTE_SIZE = 16
assert calcsize(NX_ACTION_NOTE_PACK_STR) == NX_ACTION_NOTE_SIZE

NX_ACTION_BUNDLE_PACK_STR = '!HHIHHHHIHHI4x'
NX_ACTION_BUNDLE_SIZE = 32
assert calcsize(NX_ACTION_BUNDLE_PACK_STR) == NX_ACTION_BUNDLE_SIZE

NX_ACTION_AUTOPATH_PACK_STR = '!HHIHHII4x'
NX_ACTION_AUTOPATH_SIZE = 24
assert calcsize(NX_ACTION_AUTOPATH_PACK_STR) == NX_ACTION_AUTOPATH_SIZE

NX_ACTION_OUTPUT_REG_PACK_STR = '!HHIHHIH6x'
NX_ACTION_OUTPUT_REG_SIZE = 24
assert calcsize(NX_ACTION_OUTPUT_REG_PACK_STR) == NX_ACTION_OUTPUT_REG_SIZE

NX_ACTION_LEARN_PACK_STR = '!HHIHHHHQHBxHH'
NX_ACTION_LEARN_SIZE = 32
assert calcsize(NX_ACTION_LEARN_PACK_STR) == NX_ACTION_LEARN_SIZE

NX_ACTION_CONTROLLER_PACK_STR = '!HHIHHHBB'
NX_ACTION_CONTROLLER_SIZE = 16
assert calcsize(NX_ACTION_CONTROLLER_PACK_STR) == NX_ACTION_CONTROLLER_SIZE

NX_ACTION_FIN_TIMEOUT_PACK_STR = '!HHIHHH2x'
NX_ACTION_FIN_TIMEOUT_SIZE = 16
assert calcsize(NX_ACTION_FIN_TIMEOUT_PACK_STR) == NX_ACTION_FIN_TIMEOUT_SIZE

NX_ACTION_HEADER_PACK_STR = '!HHIH6x'
NX_ACTION_HEADER_SIZE = 16
assert calcsize(NX_ACTION_HEADER_PACK_STR) == NX_ACTION_HEADER_SIZE

OFP_PACKET_OUT_PACK_STR = '!IHH'
OFP_PACKET_OUT_SIZE = 16
assert (calcsize(OFP_PACKET_OUT_PACK_STR) + OFP_HEADER_SIZE ==
        OFP_PACKET_OUT_SIZE)

# enum ofp_flow_mod_command
OFPFC_ADD = 0               # New flow.
OFPFC_MODIFY = 1            # Modify all matching flows.
OFPFC_MODIFY_STRICT = 2     # Modify entry strictly matching wildcards
OFPFC_DELETE = 3            # Delete all matching flows.
OFPFC_DELETE_STRICT = 4     # Strictly match wildcards and priority.

# enum ofp_flow_wildcards
OFPFW_IN_PORT = 1 << 0      # Switch input port.
OFPFW_DL_VLAN = 1 << 1      # VLAN vid.
OFPFW_DL_SRC = 1 << 2       # Ethernet source address.
OFPFW_DL_DST = 1 << 3       # Ethernet destination address.
OFPFW_DL_TYPE = 1 << 4      # Ethernet frame type.
OFPFW_NW_PROTO = 1 << 5     # IP protocol.
OFPFW_TP_SRC = 1 << 6       # TCP/UDP source port.
OFPFW_TP_DST = 1 << 7       # TCP/UDP destination port.
OFPFW_NW_SRC_SHIFT = 8
OFPFW_NW_SRC_BITS = 6
OFPFW_NW_SRC_MASK = ((1 << OFPFW_NW_SRC_BITS) - 1) << OFPFW_NW_SRC_SHIFT
OFPFW_NW_SRC_ALL = 32 << OFPFW_NW_SRC_SHIFT
OFPFW_NW_DST_SHIFT = 14
OFPFW_NW_DST_BITS = 6
OFPFW_NW_DST_MASK = ((1 << OFPFW_NW_DST_BITS) - 1) << OFPFW_NW_DST_SHIFT
OFPFW_NW_DST_ALL = 32 << OFPFW_NW_DST_SHIFT
OFPFW_DL_VLAN_PCP = 1 << 20     # VLAN priority.
OFPFW_NW_TOS = 1 << 21  # IP ToS (DSCP field, 6 bits).
OFPFW_ALL = ((1 << 22) - 1)

# define constants
OFPFW_ICMP_TYPE = OFPFW_TP_SRC
OFPFW_ICMP_CODE = OFPFW_TP_DST
OFP_DL_TYPE_ETH2_CUTOFF = 0x0600
OFP_DL_TYPE_NOT_ETH_TYPE = 0x05ff
OFP_VLAN_NONE = 0xffff

_OFP_MATCH_PACK_STR = 'IH' + OFP_ETH_ALEN_STR + 's' + OFP_ETH_ALEN_STR + \
                      'sHBxHBB2xIIHH'
OFP_MATCH_PACK_STR = '!' + _OFP_MATCH_PACK_STR
OFP_MATCH_SIZE = 40
assert calcsize(OFP_MATCH_PACK_STR) == OFP_MATCH_SIZE

OFP_FLOW_PERMANENT = 0
OFP_DEFAULT_PRIORITY = 0x8000

# enum ofp_flow_mod_flags
OFPFF_SEND_FLOW_REM = 1 << 0    # Send flow removed message when flow
                                # expires or is deleted.
OFPFF_CHECK_OVERLAP = 1 << 1    # Check for overlapping entries first.
OFPFF_EMERG = 1 << 2            # Ramark this is for emergency.

_OFP_FLOW_MOD_PACK_STR0 = 'QHHHHIHH'
OFP_FLOW_MOD_PACK_STR = '!' + _OFP_MATCH_PACK_STR + _OFP_FLOW_MOD_PACK_STR0
OFP_FLOW_MOD_PACK_STR0 = '!' + _OFP_FLOW_MOD_PACK_STR0
OFP_FLOW_MOD_SIZE = 72
assert calcsize(OFP_FLOW_MOD_PACK_STR) + OFP_HEADER_SIZE == OFP_FLOW_MOD_SIZE

# enum ofp_flow_removed_reason
OFPRR_IDLE_TIMEOUT = 0  # Flow idle time exceeded idle_timeout.
OFPRR_HARD_TIMEOUT = 1  # Time exceeded hard_timeout.
OFPRR_DELETE = 2        # Evicted by a DELETE flow mod.

_OFP_FLOW_REMOVED_PACK_STR0 = 'QHBxIIH2xQQ'
OFP_FLOW_REMOVED_PACK_STR = '!' + _OFP_MATCH_PACK_STR + \
                            _OFP_FLOW_REMOVED_PACK_STR0
OFP_FLOW_REMOVED_PACK_STR0 = '!' + _OFP_FLOW_REMOVED_PACK_STR0
OFP_FLOW_REMOVED_SIZE = 88
assert (calcsize(OFP_FLOW_REMOVED_PACK_STR) + OFP_HEADER_SIZE ==
        OFP_FLOW_REMOVED_SIZE)


# enum ofp_error_type
OFPET_HELLO_FAILED = 0  # Hello protocol failed.
OFPET_BAD_REQUEST = 1   # Request was not understood.
OFPET_BAD_ACTION = 2    # Error in action description.
OFPET_FLOW_MOD_FAILED = 3       # Problem modifying flow entry.
OFPET_PORT_MOD_FAILED = 4       # OFPT_PORT_MOD failed.
OFPET_QUEUE_OP_FAILED = 5       # Queue operation failed.

# enum ofp_hello_failed_code
OFPHFC_INCOMPATIBLE = 0  # No compatible version.
OFPHFC_EPERM = 1         # Permissions error.

# enum ofp_bad_request_code
OFPBRC_BAD_VERSION = 0          # ofp_header.version not supported.
OFPBRC_BAD_TYPE = 1             # ofp_header.type not supported.
OFPBRC_BAD_STAT = 2             # ofp_stats_msg.type not supported.
OFPBRC_BAD_VENDOR = 3           # Vendor not supported (in ofp_vendor_header
                                # or ofp_stats_msg).
OFPBRC_BAD_SUBTYPE = 4          # Vendor subtype not supported.
OFPBRC_EPERM = 5                # Permissions error.
OFPBRC_BAD_LEN = 6              # Wrong request length for type.
OFPBRC_BUFFER_EMPTY = 7         # Specified buffer has already been used.
OFPBRC_BUFFER_UNKNOWN = 8       # Specified buffer does not exist.

# enum ofp_bad_action_code
OFPBAC_BAD_TYPE = 0         # Unknown action type.
OFPBAC_BAD_LEN = 1          # Length problem in actions.
OFPBAC_BAD_VENDOR = 2       # Unknown vendor id specified.
OFPBAC_BAD_VENDOR_TYPE = 3  # Unknown action type for vendor id.
OFPBAC_BAD_OUT_PORT = 4     # Problem validating output action.
OFPBAC_BAD_ARGUMENT = 5     # Bad action argument.
OFPBAC_EPERM = 6            # Permissions error.
OFPBAC_TOO_MANY = 7         # Can't handle this many actions.
OFPBAC_BAD_QUEUE = 8        # Problem validating output queue.

# enum ofp_flow_mod_failed_code
OFPFMFC_ALL_TABLES_FULL = 0     # Flow not added because of full tables.
OFPFMFC_OVERLAP = 1             # Attempted to add overlapping flow with
                                # CHECK_OVERLAP flags set.
OFPFMFC_EPERM = 2               # Permissions error.
OFPFMFC_BAD_EMERG_TIMEOUT = 3   # Flow not added because of non-zero idle/hard
                                # timeout.
OFPFMFC_BAD_COMMAND = 4         # Unknown command.
OFPFMFC_UNSUPPORTED = 5         # Unsupported action list - cannot process in
                                # the order specified.

# enum ofp_port_mod_failed_code
OFPPMFC_BAD_PORT = 0        # Specified port does not exist.
OFPPMFC_BAD_HW_ADDR = 1     # Specified hardware address is wrong.

# enum ofp_queue_op_failed_code
OFPQOFC_BAD_PORT = 0    # Invalid port (or port does not exist).
OFPQOFC_BAD_QUEUE = 1   # Queue does not exist.
OFPQOFC_EPERM = 2       # Permissions error.

OFP_ERROR_MSG_PACK_STR = '!HH'
OFP_ERROR_MSG_SIZE = 12
assert calcsize(OFP_ERROR_MSG_PACK_STR) + OFP_HEADER_SIZE == OFP_ERROR_MSG_SIZE

# enum ofp_stats_types
OFPST_DESC = 0
OFPST_FLOW = 1
OFPST_AGGREGATE = 2
OFPST_TABLE = 3
OFPST_PORT = 4
OFPST_QUEUE = 5
OFPST_VENDOR = 0xffff

_OFP_STATS_MSG_PACK_STR = 'HH'
OFP_STATS_MSG_PACK_STR = '!' + _OFP_STATS_MSG_PACK_STR
OFP_STATS_MSG_SIZE = 12
assert calcsize(OFP_STATS_MSG_PACK_STR) + OFP_HEADER_SIZE == OFP_STATS_MSG_SIZE

# enum ofp_stats_reply_flags
OFPSF_REPLY_MORE = 1 << 0       # More replies to follow.

# define constants
DESC_STR_LEN = 256
DESC_STR_LEN_STR = str(DESC_STR_LEN)
SERIAL_NUM_LEN = 32
SERIAL_NUM_LEN_STR = str(SERIAL_NUM_LEN)

OFP_DESC_STATS_PACK_STR = '!' + \
                          DESC_STR_LEN_STR + 's' + \
                          DESC_STR_LEN_STR + 's' + \
                          DESC_STR_LEN_STR + 's' + \
                          SERIAL_NUM_LEN_STR + 's' + \
                          DESC_STR_LEN_STR + 's'
OFP_DESC_STATS_SIZE = 1068
assert (calcsize(OFP_DESC_STATS_PACK_STR) + OFP_STATS_MSG_SIZE ==
        OFP_DESC_STATS_SIZE)

_OFP_FLOW_STATS_REQUEST_ID_PORT_STR = 'BxH'
OFP_FLOW_STATS_REQUEST_ID_PORT_STR = '!' + _OFP_FLOW_STATS_REQUEST_ID_PORT_STR
OFP_FLOW_STATS_REQUEST_PACK_STR = '!' + _OFP_MATCH_PACK_STR + \
                                  _OFP_FLOW_STATS_REQUEST_ID_PORT_STR
OFP_FLOW_STATS_REQUEST_SIZE = 56
assert (calcsize(OFP_FLOW_STATS_REQUEST_PACK_STR) + OFP_STATS_MSG_SIZE ==
        OFP_FLOW_STATS_REQUEST_SIZE)

_OFP_FLOW_STATS_0_PACK_STR = 'HBx'
OFP_FLOW_STATS_0_PACK_STR = '!' + _OFP_FLOW_STATS_0_PACK_STR
OFP_FLOW_STATS_0_SIZE = 4
assert calcsize(OFP_FLOW_STATS_0_PACK_STR) == OFP_FLOW_STATS_0_SIZE
_OFP_FLOW_STATS_1_PACK_STR = 'IIHHH6xQQQ'
OFP_FLOW_STATS_1_PACK_STR = '!' + _OFP_FLOW_STATS_1_PACK_STR
OFP_FLOW_STATS_1_SIZE = 44
assert calcsize(OFP_FLOW_STATS_1_PACK_STR) == OFP_FLOW_STATS_1_SIZE
OFP_FLOW_STATS_PACK_STR = '!' + _OFP_FLOW_STATS_0_PACK_STR +\
                          _OFP_MATCH_PACK_STR + _OFP_FLOW_STATS_1_PACK_STR
OFP_FLOW_STATS_SIZE = 88
assert calcsize(OFP_FLOW_STATS_PACK_STR) == OFP_FLOW_STATS_SIZE

OFP_AGGREGATE_STATS_REPLY_PACK_STR = '!QQI4x'
OFP_AGGREGATE_STATS_REPLY_SIZE = 36
assert (calcsize(OFP_AGGREGATE_STATS_REPLY_PACK_STR) +
        OFP_STATS_MSG_SIZE == OFP_AGGREGATE_STATS_REPLY_SIZE)

OFP_TABLE_STATS_PACK_STR = '!B3x' + OFP_MAX_TABLE_NAME_LEN_STR + 'sIIIQQ'
OFP_TABLE_STATS_SIZE = 64
assert calcsize(OFP_TABLE_STATS_PACK_STR) == OFP_TABLE_STATS_SIZE

OFP_PORT_STATS_REQUEST_PACK_STR = '!H6x'
OFP_PORT_STATS_REQUEST_SIZE = 20
assert (calcsize(OFP_PORT_STATS_REQUEST_PACK_STR) + OFP_STATS_MSG_SIZE ==
        OFP_PORT_STATS_REQUEST_SIZE)

OFP_PORT_STATS_PACK_STR = '!H6xQQQQQQQQQQQQ'
OFP_PORT_STATS_SIZE = 104
assert calcsize(OFP_PORT_STATS_PACK_STR) == OFP_PORT_STATS_SIZE

OFPQ_ALL = 0xffffffff

OFP_QUEUE_STATS_REQUEST_PACK_STR = '!HxxI'
OFP_QUEUE_STATS_REQUEST_SIZE = 8
assert (calcsize(OFP_QUEUE_STATS_REQUEST_PACK_STR) ==
        OFP_QUEUE_STATS_REQUEST_SIZE)

OFP_QUEUE_STATS_PACK_STR = '!H2xIQQQ'
OFP_QUEUE_STATS_SIZE = 32
assert calcsize(OFP_QUEUE_STATS_PACK_STR) == OFP_QUEUE_STATS_SIZE

OFP_VENDOR_STATS_MSG_PACK_STR = '!I'
OFP_VENDOR_STATS_MSG_SIZE = 16
assert (calcsize(OFP_VENDOR_STATS_MSG_PACK_STR) + OFP_STATS_MSG_SIZE ==
        OFP_VENDOR_STATS_MSG_SIZE)

OFP_VENDOR_HEADER_PACK_STR = '!I'
OFP_VENDOR_HEADER_SIZE = 12
assert (calcsize(OFP_VENDOR_HEADER_PACK_STR) + OFP_HEADER_SIZE ==
        OFP_VENDOR_HEADER_SIZE)

OFP_QUEUE_GET_CONFIG_REQUEST_PACK_STR = '!H2x'
OFP_QUEUE_GET_CONFIG_REQUEST_SIZE = 12
assert (calcsize(OFP_QUEUE_GET_CONFIG_REQUEST_PACK_STR) + OFP_HEADER_SIZE ==
        OFP_QUEUE_GET_CONFIG_REQUEST_SIZE)

OFP_QUEUE_GET_CONFIG_REPLY_PACK_STR = '!H6x'
OFP_QUEUE_GET_CONFIG_REPLY_SIZE = 16
assert (calcsize(OFP_QUEUE_GET_CONFIG_REPLY_PACK_STR) + OFP_HEADER_SIZE ==
        OFP_QUEUE_GET_CONFIG_REPLY_SIZE)

OFP_PACKET_QUEUE_PQCK_STR = '!IH2x'
OFP_PACKET_QUEUE_SIZE = 8
assert calcsize(OFP_PACKET_QUEUE_PQCK_STR) == OFP_PACKET_QUEUE_SIZE

OFPQT_NONE = 0
OFPQT_MIN_RATE = 1

OFP_QUEUE_PROP_HEADER_PACK_STR = '!HH4x'
OFP_QUEUE_PROP_HEADER_SIZE = 8
assert calcsize(OFP_QUEUE_PROP_HEADER_PACK_STR) == OFP_QUEUE_PROP_HEADER_SIZE

OFP_QUEUE_PROP_MIN_RATE_PACK_STR = '!H6x'
OFP_QUEUE_PROP_MIN_RATE_SIZE = 16
assert (calcsize(OFP_QUEUE_PROP_MIN_RATE_PACK_STR) +
        OFP_QUEUE_PROP_HEADER_SIZE == OFP_QUEUE_PROP_MIN_RATE_SIZE)

NX_VENDOR_ID = 0x00002320

# enum nicira_type (abridged)
NXT_ROLE_REQUEST = 10
NXT_ROLE_REPLY = 11
NXT_SET_FLOW_FORMAT = 12
NXT_FLOW_MOD = 13
NXT_FLOW_REMOVED = 14
NXT_FLOW_MOD_TABLE_ID = 15
NXT_SET_PACKET_IN_FORMAT = 16
NXT_PACKET_IN = 17
NXT_FLOW_AGE = 18
NXT_SET_ASYNC_CONFIG = 19
NXT_SET_CONTROLLER_ID = 20

# enum nx_role
NX_ROLE_OTHER = 0
NX_ROLE_MASTER = 1
NX_ROLE_SLAVE = 2

# enum nx_flow_format
NXFF_OPENFLOW10 = 0
NXFF_NXM = 2

# enum nx_packet_in_format
NXPIF_OPENFLOW10 = 0
NXPIF_NXM = 1

# enum nx_stats_types
NXST_FLOW = 0
NXST_AGGREGATE = 1
NXST_FLOW_MONITOR = 2

NICIRA_HEADER_PACK_STR = '!II'
NICIRA_HEADER_SIZE = 16
assert (calcsize(NICIRA_HEADER_PACK_STR) +
        OFP_HEADER_SIZE == NICIRA_HEADER_SIZE)

NX_ROLE_PACK_STR = '!I'
NX_ROLE_SIZE = 20
assert (calcsize(NX_ROLE_PACK_STR) +
        NICIRA_HEADER_SIZE == NX_ROLE_SIZE)

NX_FLOW_MOD_PACK_STR = '!Q4HI3H6x'
NX_FLOW_MOD_SIZE = 48
assert (calcsize(NX_FLOW_MOD_PACK_STR) +
        NICIRA_HEADER_SIZE == NX_FLOW_MOD_SIZE)

NX_SET_FLOW_FORMAT_PACK_STR = '!I'
NX_SET_FLOW_FORMAT_SIZE = 20
assert (calcsize(NX_SET_FLOW_FORMAT_PACK_STR) +
        NICIRA_HEADER_SIZE == NX_SET_FLOW_FORMAT_SIZE)

NX_FLOW_REMOVED_PACK_STR = '!QHBxIIHHQQ'
NX_FLOW_REMOVED_SIZE = 56
assert (calcsize(NX_FLOW_REMOVED_PACK_STR) +
        NICIRA_HEADER_SIZE == NX_FLOW_REMOVED_SIZE)

NX_FLOW_MOD_TABLE_ID_PACK_STR = '!B7x'
NX_FLOW_MOD_TABLE_ID_SIZE = 24
assert (calcsize(NX_FLOW_MOD_TABLE_ID_PACK_STR) +
        NICIRA_HEADER_SIZE == NX_FLOW_MOD_TABLE_ID_SIZE)

NX_SET_PACKET_IN_FORMAT_PACK_STR = '!I'
NX_SET_PACKET_IN_FORMAT_SIZE = 20
assert (calcsize(NX_SET_PACKET_IN_FORMAT_PACK_STR) +
        NICIRA_HEADER_SIZE == NX_SET_PACKET_IN_FORMAT_SIZE)

NX_PACKET_IN_PACK_STR = '!IHBBQH6x'
NX_PACKET_IN_SIZE = 40
assert (calcsize(NX_PACKET_IN_PACK_STR) +
        NICIRA_HEADER_SIZE == NX_PACKET_IN_SIZE)

NX_ASYNC_CONFIG_PACK_STR = '!IIIIII'
NX_ASYNC_CONFIG_SIZE = 40
assert (calcsize(NX_ASYNC_CONFIG_PACK_STR) +
        NICIRA_HEADER_SIZE == NX_ASYNC_CONFIG_SIZE)

NX_CONTROLLER_ID_PACK_STR = '!6xH'
NX_CONTROLLER_ID_SIZE = 24
assert (calcsize(NX_CONTROLLER_ID_PACK_STR) +
        NICIRA_HEADER_SIZE == NX_CONTROLLER_ID_SIZE)

NX_STATS_MSG_PACK_STR = '!I4x'
NX_STATS_MSG0_SIZE = 8
assert calcsize(NX_STATS_MSG_PACK_STR) == NX_STATS_MSG0_SIZE
NX_STATS_MSG_SIZE = 24
assert (calcsize(NX_STATS_MSG_PACK_STR) + OFP_VENDOR_STATS_MSG_SIZE ==
        NX_STATS_MSG_SIZE)

NX_FLOW_STATS_REQUEST_PACK_STR = '!2HB3x'
NX_FLOW_STATS_REQUEST_SIZE = 8
assert (calcsize(NX_FLOW_STATS_REQUEST_PACK_STR) ==
        NX_FLOW_STATS_REQUEST_SIZE)

NX_FLOW_STATS_PACK_STR = '!HBxIIHHHHHHQQQ'
NX_FLOW_STATS_SIZE = 48
assert calcsize(NX_FLOW_STATS_PACK_STR) == NX_FLOW_STATS_SIZE

NX_AGGREGATE_STATS_REQUEST_PACK_STR = '!2HB3x'
NX_AGGREGATE_STATS_REQUEST_SIZE = 8
assert (calcsize(NX_AGGREGATE_STATS_REQUEST_PACK_STR) ==
        NX_AGGREGATE_STATS_REQUEST_SIZE)

NX_AGGREGATE_STATS_REPLY_PACK_STR = '!QQI4x'
NX_AGGREGATE_STATS_REPLY_SIZE = 24
assert (calcsize(NX_AGGREGATE_STATS_REPLY_PACK_STR) ==
        NX_AGGREGATE_STATS_REPLY_SIZE)


def nxm_header__(vendor, field, hasmask, length):
    return (vendor << 16) | (field << 9) | (hasmask << 8) | length


def nxm_header(vendor, field, length):
    return nxm_header__(vendor, field, 0, length)


def nxm_header_w(vendor, field, length):
    return nxm_header__(vendor, field, 1, (length) * 2)


NXM_OF_IN_PORT = nxm_header(0x0000, 0, 2)

NXM_OF_ETH_DST = nxm_header(0x0000, 1, 6)
NXM_OF_ETH_DST_W = nxm_header_w(0x0000, 1, 6)
NXM_OF_ETH_SRC = nxm_header(0x0000, 2, 6)
NXM_OF_ETH_SRC_W = nxm_header_w(0x0000, 2, 6)
NXM_OF_ETH_TYPE = nxm_header(0x0000, 3, 2)

NXM_OF_VLAN_TCI = nxm_header(0x0000, 4, 2)
NXM_OF_VLAN_TCI_W = nxm_header_w(0x0000, 4, 2)

NXM_OF_IP_TOS = nxm_header(0x0000, 5, 1)

NXM_OF_IP_PROTO = nxm_header(0x0000, 6, 1)

NXM_OF_IP_SRC = nxm_header(0x0000,  7, 4)
NXM_OF_IP_SRC_W = nxm_header_w(0x0000,  7, 4)
NXM_OF_IP_DST = nxm_header(0x0000,  8, 4)
NXM_OF_IP_DST_W = nxm_header_w(0x0000,  8, 4)

NXM_OF_TCP_SRC = nxm_header(0x0000, 9, 2)
NXM_OF_TCP_SRC_W = nxm_header_w(0x0000, 9, 2)
NXM_OF_TCP_DST = nxm_header(0x0000, 10, 2)
NXM_OF_TCP_DST_W = nxm_header_w(0x0000, 10, 2)

NXM_OF_UDP_SRC = nxm_header(0x0000, 11, 2)
NXM_OF_UDP_SRC_W = nxm_header_w(0x0000, 11, 2)
NXM_OF_UDP_DST = nxm_header(0x0000, 12, 2)
NXM_OF_UDP_DST_W = nxm_header_w(0x0000, 12, 2)

NXM_OF_ICMP_TYPE = nxm_header(0x0000, 13, 1)
NXM_OF_ICMP_CODE = nxm_header(0x0000, 14, 1)

NXM_OF_ARP_OP = nxm_header(0x0000, 15, 2)

NXM_OF_ARP_SPA = nxm_header(0x0000, 16, 4)
NXM_OF_ARP_SPA_W = nxm_header_w(0x0000, 16, 4)
NXM_OF_ARP_TPA = nxm_header(0x0000, 17, 4)
NXM_OF_ARP_TPA_W = nxm_header_w(0x0000, 17, 4)

NXM_NX_TUN_ID = nxm_header(0x0001, 16, 8)
NXM_NX_TUN_ID_W = nxm_header_w(0x0001, 16, 8)

NXM_NX_ARP_SHA = nxm_header(0x0001, 17, 6)
NXM_NX_ARP_THA = nxm_header(0x0001, 18, 6)

NXM_NX_IPV6_SRC = nxm_header(0x0001, 19, 16)
NXM_NX_IPV6_SRC_W = nxm_header_w(0x0001, 19, 16)
NXM_NX_IPV6_DST = nxm_header(0x0001, 20, 16)
NXM_NX_IPV6_DST_W = nxm_header_w(0x0001, 20, 16)

NXM_NX_ICMPV6_TYPE = nxm_header(0x0001, 21, 1)
NXM_NX_ICMPV6_CODE = nxm_header(0x0001, 22, 1)

NXM_NX_ND_TARGET = nxm_header(0x0001, 23, 16)
NXM_NX_ND_TARGET_W = nxm_header_w(0x0001, 23, 16)

NXM_NX_ND_SLL = nxm_header(0x0001, 24, 6)

NXM_NX_ND_TLL = nxm_header(0x0001, 25, 6)

NXM_NX_IP_FRAG = nxm_header(0x0001, 26, 1)
NXM_NX_IP_FRAG_W = nxm_header_w(0x0001, 26, 1)

NXM_NX_IPV6_LABEL = nxm_header(0x0001, 27, 4)

NXM_NX_IP_ECN = nxm_header(0x0001, 28, 1)

NXM_NX_IP_TTL = nxm_header(0x0001, 29, 1)


def nxm_nx_reg(idx):
    return nxm_header(0x0001, idx, 4)


def nxm_nx_reg_w(idx):
    return nxm_header_w(0x0001, idx, 4)

NXM_HEADER_PACK_STRING = '!I'

# enum nx_hash_fields
NX_HASH_FIELDS_ETH_SRC = 0
NX_HASH_FIELDS_SYMMETRIC_L4 = 1

# enum nx_mp_algorithm
NX_MP_ALG_MODULO_N = 0
NX_MP_ALG_HASH_THRESHOLD = 1
NX_MP_ALG_HRW = 2
NX_MP_ALG_ITER_HASH = 3

# enum nx_bd_algorithm
NX_BD_ALG_ACTIVE_BACKUP = 0
NX_BD_ALG_HRW = 1

# nx_learn constants
NX_LEARN_N_BITS_MASK = 0x3ff
NX_LEARN_SRC_FIELD = 0 << 13  # Copy from field.
NX_LEARN_SRC_IMMEDIATE = 1 << 13  # Copy from immediate value.
NX_LEARN_SRC_MASK = 1 << 13
NX_LEARN_DST_MATCH = 0 << 11  # Add match criterion.
NX_LEARN_DST_LOAD = 1 << 11  # Add NXAST_REG_LOAD action
NX_LEARN_DST_OUTPUT = 2 << 11  # Add OFPAT_OUTPUT action.
NX_LEARN_DST_RESERVED = 3 << 11  # Not yet defined.
NX_LEARN_DST_MASK = 3 << 11

########NEW FILE########
__FILENAME__ = ofproto_v1_0_parser
# Copyright (C) 2011, 2012 Nippon Telegraph and Telephone Corporation.
# Copyright (C) 2011, 2012 Isaku Yamahata <yamahata at valinux co jp>
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import struct
import binascii

from ofproto_parser import StringifyMixin, MsgBase, msg_pack_into, msg_str_attr
from ryu.lib import addrconv
from ryu.lib import mac
from . import ofproto_parser
from . import ofproto_v1_0
from . import nx_match
from ryu import utils

import logging
LOG = logging.getLogger('ryu.ofproto.ofproto_v1_0_parser')

_MSG_PARSERS = {}


def _set_msg_type(msg_type):
    '''Annotate corresponding OFP message type'''
    def _set_cls_msg_type(cls):
        cls.cls_msg_type = msg_type
        return cls
    return _set_cls_msg_type


def _register_parser(cls):
    '''class decorator to register msg parser'''
    assert cls.cls_msg_type is not None
    assert cls.cls_msg_type not in _MSG_PARSERS
    _MSG_PARSERS[cls.cls_msg_type] = cls.parser
    return cls


@ofproto_parser.register_msg_parser(ofproto_v1_0.OFP_VERSION)
def msg_parser(datapath, version, msg_type, msg_len, xid, buf):
    parser = _MSG_PARSERS.get(msg_type)
    return parser(datapath, version, msg_type, msg_len, xid, buf)


# OFP_MSG_REPLY = {
#     OFPFeaturesRequest: OFPSwitchFeatures,
#     OFPBarrierRequest: OFPBarrierReply,
#     OFPQueueGetConfigRequest: OFPQueueGetConfigReply,
#
#     # ofp_stats_request -> ofp_stats_reply
#     OFPDescStatsRequest: OFPDescStatsReply,
#     OFPFlowStatsRequest: OFPFlowStatsReply,
#     OFPAggregateStatsRequest: OFPAggregateStatsReply,
#     OFPTableStatsRequest: OFPTableStatsReply,
#     OFPPortStatsRequest: OFPPortStatsReply,
#     OFPQueueStatsRequest: OFPQueueStatsReply,
#     OFPVendorStatsRequest: OFPVendorStatsReply,
#     }
def _set_msg_reply(msg_reply):
    '''Annotate OFP reply message class'''
    def _set_cls_msg_reply(cls):
        cls.cls_msg_reply = msg_reply
        return cls
    return _set_cls_msg_reply


#
# common structures
#

class OFPPhyPort(ofproto_parser.namedtuple('OFPPhyPort', (
        'port_no', 'hw_addr', 'name', 'config', 'state', 'curr', 'advertised',
        'supported', 'peer'))):

    _TYPE = {
        'ascii': [
            'hw_addr',
        ],
        'utf-8': [
            # OF spec is unclear about the encoding of name.
            # we assumes UTF-8, which is used by OVS.
            'name',
        ]
    }

    @classmethod
    def parser(cls, buf, offset):
        port = struct.unpack_from(ofproto_v1_0.OFP_PHY_PORT_PACK_STR,
                                  buf, offset)
        port = list(port)
        i = cls._fields.index('hw_addr')
        port[i] = addrconv.mac.bin_to_text(port[i])
        i = cls._fields.index('name')
        port[i] = port[i].rstrip('\0')
        return cls(*port)


class OFPMatch(StringifyMixin):
    def __init__(self, wildcards=None, in_port=None, dl_src=None, dl_dst=None,
                 dl_vlan=None, dl_vlan_pcp=None, dl_type=None, nw_tos=None,
                 nw_proto=None, nw_src=None, nw_dst=None,
                 tp_src=None, tp_dst=None, nw_src_mask=32, nw_dst_mask=32):
        super(OFPMatch, self).__init__()
        wc = ofproto_v1_0.OFPFW_ALL
        if in_port is None:
            self.in_port = 0
        else:
            wc &= ~ofproto_v1_0.OFPFW_IN_PORT
            self.in_port = in_port

        if dl_src is None:
            self.dl_src = mac.DONTCARE
        else:
            wc &= ~ofproto_v1_0.OFPFW_DL_SRC
            if dl_src == 0:
                self.dl_src = mac.DONTCARE
            else:
                self.dl_src = dl_src

        if dl_dst is None:
            self.dl_dst = mac.DONTCARE
        else:
            wc &= ~ofproto_v1_0.OFPFW_DL_DST
            if dl_dst == 0:
                self.dl_dst = mac.DONTCARE
            else:
                self.dl_dst = dl_dst

        if dl_vlan is None:
            self.dl_vlan = 0
        else:
            wc &= ~ofproto_v1_0.OFPFW_DL_VLAN
            self.dl_vlan = dl_vlan

        if dl_vlan_pcp is None:
            self.dl_vlan_pcp = 0
        else:
            wc &= ~ofproto_v1_0.OFPFW_DL_VLAN_PCP
            self.dl_vlan_pcp = dl_vlan_pcp

        if dl_type is None:
            self.dl_type = 0
        else:
            wc &= ~ofproto_v1_0.OFPFW_DL_TYPE
            self.dl_type = dl_type

        if nw_tos is None:
            self.nw_tos = 0
        else:
            wc &= ~ofproto_v1_0.OFPFW_NW_TOS
            self.nw_tos = nw_tos

        if nw_proto is None:
            self.nw_proto = 0
        else:
            wc &= ~ofproto_v1_0.OFPFW_NW_PROTO
            self.nw_proto = nw_proto

        if nw_src is None:
            self.nw_src = 0
        else:
            wc &= (32 - nw_src_mask) << ofproto_v1_0.OFPFW_NW_SRC_SHIFT \
                | ~ofproto_v1_0.OFPFW_NW_SRC_MASK
            self.nw_src = nw_src

        if nw_dst is None:
            self.nw_dst = 0
        else:
            wc &= (32 - nw_dst_mask) << ofproto_v1_0.OFPFW_NW_DST_SHIFT \
                | ~ofproto_v1_0.OFPFW_NW_DST_MASK
            self.nw_dst = nw_dst

        if tp_src is None:
            self.tp_src = 0
        else:
            wc &= ~ofproto_v1_0.OFPFW_TP_SRC
            self.tp_src = tp_src

        if tp_dst is None:
            self.tp_dst = 0
        else:
            wc &= ~ofproto_v1_0.OFPFW_TP_DST
            self.tp_dst = tp_dst

        if wildcards is None:
            self.wildcards = wc
        else:
            self.wildcards = wildcards

    def serialize(self, buf, offset):
        msg_pack_into(ofproto_v1_0.OFP_MATCH_PACK_STR, buf, offset,
                      self.wildcards, self.in_port, self.dl_src,
                      self.dl_dst, self.dl_vlan, self.dl_vlan_pcp,
                      self.dl_type, self.nw_tos, self.nw_proto,
                      self.nw_src, self.nw_dst, self.tp_src, self.tp_dst)

    @classmethod
    def parse(cls, buf, offset):
        match = struct.unpack_from(ofproto_v1_0.OFP_MATCH_PACK_STR,
                                   buf, offset)
        return cls(*match)


class OFPActionHeader(StringifyMixin):
    _base_attributes = ['type', 'len']

    def __init__(self, type_, len_):
        self.type = type_
        self.len = len_

    def serialize(self, buf, offset):
        msg_pack_into(ofproto_v1_0.OFP_ACTION_HEADER_PACK_STR,
                      buf, offset, self.type, self.len)


class OFPAction(OFPActionHeader):
    _ACTION_TYPES = {}

    @staticmethod
    def register_action_type(type_, len_):
        def _register_action_type(cls):
            cls.cls_action_type = type_
            cls.cls_action_len = len_
            OFPAction._ACTION_TYPES[cls.cls_action_type] = cls
            return cls
        return _register_action_type

    def __init__(self):
        cls = self.__class__
        super(OFPAction, self).__init__(cls.cls_action_type,
                                        cls.cls_action_len)

    @classmethod
    def parser(cls, buf, offset):
        type_, len_ = struct.unpack_from(
            ofproto_v1_0.OFP_ACTION_HEADER_PACK_STR, buf, offset)
        cls_ = cls._ACTION_TYPES.get(type_)
        assert cls_ is not None
        return cls_.parser(buf, offset)


@OFPAction.register_action_type(ofproto_v1_0.OFPAT_OUTPUT,
                                ofproto_v1_0.OFP_ACTION_OUTPUT_SIZE)
class OFPActionOutput(OFPAction):
    # NOTE: The reason of this magic number (0xffe5)
    #       is because there is no good constant in of1.0.
    #       The same value as OFPCML_MAX of of1.2 and of1.3 is used.
    def __init__(self, port, max_len=0xffe5):
        super(OFPActionOutput, self).__init__()
        self.port = port
        self.max_len = max_len

    @classmethod
    def parser(cls, buf, offset):
        type_, len_, port, max_len = struct.unpack_from(
            ofproto_v1_0.OFP_ACTION_OUTPUT_PACK_STR, buf, offset)
        assert type_ == ofproto_v1_0.OFPAT_OUTPUT
        assert len_ == ofproto_v1_0.OFP_ACTION_OUTPUT_SIZE
        return cls(port, max_len)

    def serialize(self, buf, offset):
        msg_pack_into(ofproto_v1_0.OFP_ACTION_OUTPUT_PACK_STR, buf,
                      offset, self.type, self.len, self.port, self.max_len)


@OFPAction.register_action_type(ofproto_v1_0.OFPAT_SET_VLAN_VID,
                                ofproto_v1_0.OFP_ACTION_VLAN_VID_SIZE)
class OFPActionVlanVid(OFPAction):
    def __init__(self, vlan_vid):
        super(OFPActionVlanVid, self).__init__()
        self.vlan_vid = vlan_vid

    @classmethod
    def parser(cls, buf, offset):
        type_, len_, vlan_vid = struct.unpack_from(
            ofproto_v1_0.OFP_ACTION_VLAN_VID_PACK_STR, buf, offset)
        assert type_ == ofproto_v1_0.OFPAT_SET_VLAN_VID
        assert len_ == ofproto_v1_0.OFP_ACTION_VLAN_VID_SIZE
        return cls(vlan_vid)

    def serialize(self, buf, offset):
        msg_pack_into(ofproto_v1_0.OFP_ACTION_VLAN_VID_PACK_STR,
                      buf, offset, self.type, self.len, self.vlan_vid)


@OFPAction.register_action_type(ofproto_v1_0.OFPAT_SET_VLAN_PCP,
                                ofproto_v1_0.OFP_ACTION_VLAN_PCP_SIZE)
class OFPActionVlanPcp(OFPAction):
    def __init__(self, vlan_pcp):
        super(OFPActionVlanPcp, self).__init__()
        self.vlan_pcp = vlan_pcp

    @classmethod
    def parser(cls, buf, offset):
        type_, len_, vlan_pcp = struct.unpack_from(
            ofproto_v1_0.OFP_ACTION_VLAN_PCP_PACK_STR, buf, offset)
        assert type_ == ofproto_v1_0.OFPAT_SET_VLAN_PCP
        assert len_ == ofproto_v1_0.OFP_ACTION_VLAN_PCP_SIZE
        return cls(vlan_pcp)

    def serialize(self, buf, offset):
        msg_pack_into(ofproto_v1_0.OFP_ACTION_VLAN_PCP_PACK_STR,
                      buf, offset, self.type, self.len, self.vlan_pcp)


@OFPAction.register_action_type(ofproto_v1_0.OFPAT_STRIP_VLAN,
                                ofproto_v1_0.OFP_ACTION_HEADER_SIZE)
class OFPActionStripVlan(OFPAction):
    def __init__(self):
        super(OFPActionStripVlan, self).__init__()

    @classmethod
    def parser(cls, buf, offset):
        type_, len_ = struct.unpack_from(
            ofproto_v1_0.OFP_ACTION_HEADER_PACK_STR, buf, offset)
        assert type_ == ofproto_v1_0.OFPAT_STRIP_VLAN
        assert len_ == ofproto_v1_0.OFP_ACTION_HEADER_SIZE
        return cls()


class OFPActionDlAddr(OFPAction):
    def __init__(self, dl_addr):
        super(OFPActionDlAddr, self).__init__()
        self.dl_addr = dl_addr

    @classmethod
    def parser(cls, buf, offset):
        type_, len_, dl_addr = struct.unpack_from(
            ofproto_v1_0.OFP_ACTION_DL_ADDR_PACK_STR, buf, offset)
        assert type_ in (ofproto_v1_0.OFPAT_SET_DL_SRC,
                         ofproto_v1_0.OFPAT_SET_DL_DST)
        assert len_ == ofproto_v1_0.OFP_ACTION_DL_ADDR_SIZE
        return cls(dl_addr)

    def serialize(self, buf, offset):
        msg_pack_into(ofproto_v1_0.OFP_ACTION_DL_ADDR_PACK_STR,
                      buf, offset, self.type, self.len, self.dl_addr)


@OFPAction.register_action_type(ofproto_v1_0.OFPAT_SET_DL_SRC,
                                ofproto_v1_0.OFP_ACTION_DL_ADDR_SIZE)
class OFPActionSetDlSrc(OFPActionDlAddr):
    def __init__(self, dl_addr):
        super(OFPActionSetDlSrc, self).__init__(dl_addr)


@OFPAction.register_action_type(ofproto_v1_0.OFPAT_SET_DL_DST,
                                ofproto_v1_0.OFP_ACTION_DL_ADDR_SIZE)
class OFPActionSetDlDst(OFPActionDlAddr):
    def __init__(self, dl_addr):
        super(OFPActionSetDlDst, self).__init__(dl_addr)


class OFPActionNwAddr(OFPAction):
    def __init__(self, nw_addr):
        super(OFPActionNwAddr, self).__init__()
        self.nw_addr = nw_addr

    @classmethod
    def parser(cls, buf, offset):
        type_, len_, nw_addr = struct.unpack_from(
            ofproto_v1_0.OFP_ACTION_NW_ADDR_PACK_STR, buf, offset)
        assert type_ in (ofproto_v1_0.OFPAT_SET_NW_SRC,
                         ofproto_v1_0.OFPAT_SET_NW_DST)
        assert len_ == ofproto_v1_0.OFP_ACTION_NW_ADDR_SIZE
        return cls(nw_addr)

    def serialize(self, buf, offset):
        msg_pack_into(ofproto_v1_0.OFP_ACTION_NW_ADDR_PACK_STR,
                      buf, offset, self.type, self.len, self.nw_addr)


@OFPAction.register_action_type(ofproto_v1_0.OFPAT_SET_NW_SRC,
                                ofproto_v1_0.OFP_ACTION_NW_ADDR_SIZE)
class OFPActionSetNwSrc(OFPActionNwAddr):
    def __init__(self, nw_addr):
        super(OFPActionSetNwSrc, self).__init__(nw_addr)


@OFPAction.register_action_type(ofproto_v1_0.OFPAT_SET_NW_DST,
                                ofproto_v1_0.OFP_ACTION_NW_ADDR_SIZE)
class OFPActionSetNwDst(OFPActionNwAddr):
    def __init__(self, nw_addr):
        super(OFPActionSetNwDst, self).__init__(nw_addr)


@OFPAction.register_action_type(ofproto_v1_0.OFPAT_SET_NW_TOS,
                                ofproto_v1_0.OFP_ACTION_NW_TOS_SIZE)
class OFPActionSetNwTos(OFPAction):
    def __init__(self, tos):
        super(OFPActionSetNwTos, self).__init__()
        self.tos = tos

    @classmethod
    def parser(cls, buf, offset):
        type_, len_, tos = struct.unpack_from(
            ofproto_v1_0.OFP_ACTION_NW_TOS_PACK_STR, buf, offset)
        assert type_ == ofproto_v1_0.OFPAT_SET_NW_TOS
        assert len_ == ofproto_v1_0.OFP_ACTION_NW_TOS_SIZE
        return cls(tos)

    def serialize(self, buf, offset):
        msg_pack_into(ofproto_v1_0.OFP_ACTION_NW_TOS_PACK_STR,
                      buf, offset, self.type, self.len, self.tos)


class OFPActionTpPort(OFPAction):
    def __init__(self, tp):
        super(OFPActionTpPort, self).__init__()
        self.tp = tp

    @classmethod
    def parser(cls, buf, offset):
        type_, len_, tp = struct.unpack_from(
            ofproto_v1_0.OFP_ACTION_TP_PORT_PACK_STR, buf, offset)
        assert type_ in (ofproto_v1_0.OFPAT_SET_TP_SRC,
                         ofproto_v1_0.OFPAT_SET_TP_DST)
        assert len_ == ofproto_v1_0.OFP_ACTION_TP_PORT_SIZE
        return cls(tp)

    def serialize(self, buf, offset):
        msg_pack_into(ofproto_v1_0.OFP_ACTION_TP_PORT_PACK_STR,
                      buf, offset, self.type, self.len, self.tp)


@OFPAction.register_action_type(ofproto_v1_0.OFPAT_SET_TP_SRC,
                                ofproto_v1_0.OFP_ACTION_TP_PORT_SIZE)
class OFPActionSetTpSrc(OFPActionTpPort):
    def __init__(self, tp):
        super(OFPActionSetTpSrc, self).__init__(tp)


@OFPAction.register_action_type(ofproto_v1_0.OFPAT_SET_TP_DST,
                                ofproto_v1_0.OFP_ACTION_TP_PORT_SIZE)
class OFPActionSetTpDst(OFPActionTpPort):
    def __init__(self, tp):
        super(OFPActionSetTpDst, self).__init__(tp)


@OFPAction.register_action_type(ofproto_v1_0.OFPAT_ENQUEUE,
                                ofproto_v1_0.OFP_ACTION_ENQUEUE_SIZE)
class OFPActionEnqueue(OFPAction):
    def __init__(self, port, queue_id):
        super(OFPActionEnqueue, self).__init__()
        self.port = port
        self.queue_id = queue_id

    @classmethod
    def parser(cls, buf, offset):
        type_, len_, port, queue_id = struct.unpack_from(
            ofproto_v1_0.OFP_ACTION_ENQUEUE_PACK_STR, buf, offset)
        assert type_ == ofproto_v1_0.OFPAT_ENQUEUE
        assert len_ == ofproto_v1_0.OFP_ACTION_ENQUEUE_SIZE
        return cls(port, queue_id)

    def serialize(self, buf, offset):
        msg_pack_into(ofproto_v1_0.OFP_ACTION_ENQUEUE_PACK_STR, buf, offset,
                      self.type, self.len, self.port, self.queue_id)


@OFPAction.register_action_type(ofproto_v1_0.OFPAT_VENDOR, 0)
class OFPActionVendor(OFPAction):
    _ACTION_VENDORS = {}

    @staticmethod
    def register_action_vendor(vendor):
        def _register_action_vendor(cls):
            cls.cls_vendor = vendor
            OFPActionVendor._ACTION_VENDORS[cls.cls_vendor] = cls
            return cls
        return _register_action_vendor

    def __init__(self):
        super(OFPActionVendor, self).__init__()
        self.vendor = self.cls_vendor

    @classmethod
    def parser(cls, buf, offset):
        type_, len_, vendor = struct.unpack_from(
            ofproto_v1_0.OFP_ACTION_VENDOR_HEADER_PACK_STR, buf, offset)
        cls_ = cls._ACTION_VENDORS.get(vendor)
        return cls_.parser(buf, offset)


@OFPActionVendor.register_action_vendor(ofproto_v1_0.NX_VENDOR_ID)
class NXActionHeader(OFPActionVendor):
    _NX_ACTION_SUBTYPES = {}

    @staticmethod
    def register_nx_action_subtype(subtype, len_):
        def _register_nx_action_subtype(cls):
            cls.cls_action_len = len_
            cls.cls_subtype = subtype
            NXActionHeader._NX_ACTION_SUBTYPES[cls.cls_subtype] = cls
            return cls
        return _register_nx_action_subtype

    def __init__(self):
        super(NXActionHeader, self).__init__()
        self.subtype = self.cls_subtype

    def serialize(self, buf, offset):
        msg_pack_into(ofproto_v1_0.OFP_ACTION_HEADER_PACK_STR,
                      buf, offset, self.type, self.len)

    @classmethod
    def parser(cls, buf, offset):
        type_, len_, vendor, subtype = struct.unpack_from(
            ofproto_v1_0.NX_ACTION_HEADER_PACK_STR, buf, offset)
        cls_ = cls._NX_ACTION_SUBTYPES.get(subtype)
        return cls_.parser(buf, offset)


class NXActionResubmitBase(NXActionHeader):
    def __init__(self, in_port, table):
        super(NXActionResubmitBase, self).__init__()
        assert self.subtype in (ofproto_v1_0.NXAST_RESUBMIT,
                                ofproto_v1_0.NXAST_RESUBMIT_TABLE)
        self.in_port = in_port
        self.table = table

    def serialize(self, buf, offset):
        msg_pack_into(ofproto_v1_0.NX_ACTION_RESUBMIT_PACK_STR, buf, offset,
                      self.type, self.len, self.vendor, self.subtype,
                      self.in_port, self.table)


@NXActionHeader.register_nx_action_subtype(
    ofproto_v1_0.NXAST_RESUBMIT, ofproto_v1_0.NX_ACTION_RESUBMIT_SIZE)
class NXActionResubmit(NXActionResubmitBase):
    def __init__(self, in_port=ofproto_v1_0.OFPP_IN_PORT):
        super(NXActionResubmit, self).__init__(in_port, 0)

    @classmethod
    def parser(cls, buf, offset):
        type_, len_, vendor, subtype, in_port, table = struct.unpack_from(
            ofproto_v1_0.NX_ACTION_RESUBMIT_PACK_STR, buf, offset)
        return cls(in_port)


@NXActionHeader.register_nx_action_subtype(
    ofproto_v1_0.NXAST_RESUBMIT_TABLE, ofproto_v1_0.NX_ACTION_RESUBMIT_SIZE)
class NXActionResubmitTable(NXActionResubmitBase):
    def __init__(self, in_port=ofproto_v1_0.OFPP_IN_PORT, table=0xff):
        super(NXActionResubmitTable, self).__init__(in_port, table)

    @classmethod
    def parser(cls, buf, offset):
        type_, len_, vendor, subtype, in_port, table = struct.unpack_from(
            ofproto_v1_0.NX_ACTION_RESUBMIT_PACK_STR, buf, offset)
        return cls(in_port, table)


@NXActionHeader.register_nx_action_subtype(
    ofproto_v1_0.NXAST_SET_TUNNEL, ofproto_v1_0.NX_ACTION_SET_TUNNEL_SIZE)
class NXActionSetTunnel(NXActionHeader):
    def __init__(self, tun_id):
        super(NXActionSetTunnel, self).__init__()
        self.tun_id = tun_id

    def serialize(self, buf, offset):
        msg_pack_into(ofproto_v1_0.NX_ACTION_SET_TUNNEL_PACK_STR, buf,
                      offset, self.type, self.len, self.vendor, self.subtype,
                      self.tun_id)

    @classmethod
    def parser(cls, buf, offset):
        type_, len_, vendor, subtype, tun_id = struct.unpack_from(
            ofproto_v1_0.NX_ACTION_SET_TUNNEL_PACK_STR, buf, offset)
        return cls(tun_id)


@NXActionHeader.register_nx_action_subtype(
    ofproto_v1_0.NXAST_SET_QUEUE, ofproto_v1_0.NX_ACTION_SET_QUEUE_SIZE)
class NXActionSetQueue(NXActionHeader):
    def __init__(self, queue_id):
        super(NXActionSetQueue, self).__init__()
        self.queue_id = queue_id

    def serialize(self, buf, offset):
        msg_pack_into(ofproto_v1_0.NX_ACTION_SET_QUEUE_PACK_STR, buf,
                      offset, self.type, self.len, self.vendor,
                      self.subtype, self.queue_id)

    @classmethod
    def parser(cls, buf, offset):
        (type_, len_, vendor, subtype, queue_id) = struct.unpack_from(
            ofproto_v1_0.NX_ACTION_SET_QUEUE_PACK_STR, buf, offset)
        return cls(queue_id)


@NXActionHeader.register_nx_action_subtype(
    ofproto_v1_0.NXAST_POP_QUEUE, ofproto_v1_0.NX_ACTION_POP_QUEUE_SIZE)
class NXActionPopQueue(NXActionHeader):
    def __init__(self):
        super(NXActionPopQueue, self).__init__()

    def serialize(self, buf, offset):
        msg_pack_into(ofproto_v1_0.NX_ACTION_POP_QUEUE_PACK_STR, buf,
                      offset, self.type, self.len, self.vendor,
                      self.subtype)

    @classmethod
    def parser(cls, buf, offset):
        (type_, len_, vendor, subtype) = struct.unpack_from(
            ofproto_v1_0.NX_ACTION_POP_QUEUE_PACK_STR, buf, offset)
        return cls()


@NXActionHeader.register_nx_action_subtype(
    ofproto_v1_0.NXAST_REG_MOVE, ofproto_v1_0.NX_ACTION_REG_MOVE_SIZE)
class NXActionRegMove(NXActionHeader):
    def __init__(self, n_bits, src_ofs, dst_ofs, src, dst):
        super(NXActionRegMove, self).__init__()
        self.n_bits = n_bits
        self.src_ofs = src_ofs
        self.dst_ofs = dst_ofs
        self.src = src
        self.dst = dst

    def serialize(self, buf, offset):
        msg_pack_into(ofproto_v1_0.NX_ACTION_REG_MOVE_PACK_STR, buf,
                      offset, self.type, self.len, self.vendor,
                      self.subtype, self.n_bits, self.src_ofs, self.dst_ofs,
                      self.src, self.dst)

    @classmethod
    def parser(cls, buf, offset):
        (type_, len_, vendor, subtype, n_bits, src_ofs, dst_ofs,
            src, dst) = struct.unpack_from(
            ofproto_v1_0.NX_ACTION_REG_MOVE_PACK_STR, buf, offset)
        return cls(n_bits, src_ofs, dst_ofs, src, dst)


@NXActionHeader.register_nx_action_subtype(
    ofproto_v1_0.NXAST_REG_LOAD, ofproto_v1_0.NX_ACTION_REG_LOAD_SIZE)
class NXActionRegLoad(NXActionHeader):
    def __init__(self, ofs_nbits, dst, value):
        super(NXActionRegLoad, self).__init__()
        self.ofs_nbits = ofs_nbits
        self.dst = dst
        self.value = value

    def serialize(self, buf, offset):
        msg_pack_into(ofproto_v1_0.NX_ACTION_REG_LOAD_PACK_STR, buf,
                      offset, self.type, self.len, self.vendor,
                      self.subtype, self.ofs_nbits, self.dst, self.value)

    @classmethod
    def parser(cls, buf, offset):
        (type_, len_, vendor, subtype, ofs_nbits, dst,
            value) = struct.unpack_from(
            ofproto_v1_0.NX_ACTION_REG_LOAD_PACK_STR, buf, offset)
        return cls(ofs_nbits, dst, value)


@NXActionHeader.register_nx_action_subtype(
    ofproto_v1_0.NXAST_SET_TUNNEL64, ofproto_v1_0.NX_ACTION_SET_TUNNEL64_SIZE)
class NXActionSetTunnel64(NXActionHeader):
    def __init__(self, tun_id):
        super(NXActionSetTunnel64, self).__init__()
        self.tun_id = tun_id

    def serialize(self, buf, offset):
        msg_pack_into(ofproto_v1_0.NX_ACTION_SET_TUNNEL64_PACK_STR, buf,
                      offset, self.type, self.len, self.vendor, self.subtype,
                      self.tun_id)

    @classmethod
    def parser(cls, buf, offset):
        type_, len_, vendor, subtype, tun_id = struct.unpack_from(
            ofproto_v1_0.NX_ACTION_SET_TUNNEL64_PACK_STR, buf, offset)
        return cls(tun_id)


@NXActionHeader.register_nx_action_subtype(
    ofproto_v1_0.NXAST_MULTIPATH, ofproto_v1_0.NX_ACTION_MULTIPATH_SIZE)
class NXActionMultipath(NXActionHeader):
    def __init__(self, fields, basis, algorithm, max_link, arg,
                 ofs_nbits, dst):
        super(NXActionMultipath, self).__init__()
        self.fields = fields
        self.basis = basis
        self.algorithm = algorithm
        self.max_link = max_link
        self.arg = arg
        self.ofs_nbits = ofs_nbits
        self.dst = dst

    def serialize(self, buf, offset):
        msg_pack_into(ofproto_v1_0.NX_ACTION_MULTIPATH_PACK_STR, buf,
                      offset, self.type, self.len, self.vendor, self.subtype,
                      self.fields, self.basis, self.algorithm, self.max_link,
                      self.arg, self.ofs_nbits, self.dst)

    @classmethod
    def parser(cls, buf, offset):
        (type_, len_, vendor, subtype, fields, basis, algorithm,
            max_link, arg, ofs_nbits, dst) = struct.unpack_from(
            ofproto_v1_0.NX_ACTION_MULTIPATH_PACK_STR, buf, offset)
        return cls(fields, basis, algorithm, max_link, arg, ofs_nbits,
                   dst)


@NXActionHeader.register_nx_action_subtype(ofproto_v1_0.NXAST_NOTE, 0)
class NXActionNote(NXActionHeader):
    def __init__(self, note):
        super(NXActionNote, self).__init__()
        # should check here if the note is valid (only hex values)
        pad = (len(note) + 10) % 8
        if pad:
            note += [0x0 for i in range(8 - pad)]
        self.note = note
        self.len = len(note) + 10

    def serialize(self, buf, offset):
        note = self.note
        extra = None
        extra_len = len(self.note) - 6
        if extra_len > 0:
            extra = note[6:]
        note = note[0:6]
        msg_pack_into(ofproto_v1_0.NX_ACTION_NOTE_PACK_STR, buf,
                      offset, self.type, self.len, self.vendor, self.subtype,
                      *note)
        if extra_len > 0:
            msg_pack_into('B' * extra_len, buf,
                          offset + ofproto_v1_0.NX_ACTION_NOTE_SIZE,
                          *extra)

    @classmethod
    def parser(cls, buf, offset):
        note = struct.unpack_from(
            ofproto_v1_0.NX_ACTION_NOTE_PACK_STR, buf, offset)
        (type_, len_, vendor, subtype) = note[0:4]
        note = [i for i in note[4:]]
        if len_ > ofproto_v1_0.NX_ACTION_NOTE_SIZE:
            note_start = offset + ofproto_v1_0.NX_ACTION_NOTE_SIZE
            note_end = note_start + len_ - ofproto_v1_0.NX_ACTION_NOTE_SIZE
            note += [int(binascii.b2a_hex(i), 16) for i
                     in buf[note_start:note_end]]
        return cls(note)


class NXActionBundleBase(NXActionHeader):
    def __init__(self, algorithm, fields, basis, slave_type, n_slaves,
                 ofs_nbits, dst, slaves):
        super(NXActionBundleBase, self).__init__()
        _len = ofproto_v1_0.NX_ACTION_BUNDLE_SIZE + len(slaves) * 2
        _len += (_len % 8)
        self.len = _len

        self.algorithm = algorithm
        self.fields = fields
        self.basis = basis
        self.slave_type = slave_type
        self.n_slaves = n_slaves
        self.ofs_nbits = ofs_nbits
        self.dst = dst
        self.slaves = slaves

    def serialize(self, buf, offset):
        slave_offset = offset + ofproto_v1_0.NX_ACTION_BUNDLE_SIZE

        for s in self.slaves:
            msg_pack_into('!H', buf, slave_offset, s)
            slave_offset += 2

        pad_len = (len(self.slaves) * 2 +
                   ofproto_v1_0.NX_ACTION_BUNDLE_SIZE) % 8

        if pad_len != 0:
            msg_pack_into('%dx' % pad_len, buf, slave_offset)

        msg_pack_into(ofproto_v1_0.NX_ACTION_BUNDLE_PACK_STR, buf,
                      offset, self.type, self.len, self.vendor, self.subtype,
                      self.algorithm, self.fields, self.basis,
                      self.slave_type, self.n_slaves,
                      self.ofs_nbits, self.dst)

    @classmethod
    def parser(cls, action_cls, buf, offset):
        (type_, len_, vendor, subtype, algorithm, fields, basis,
            slave_type, n_slaves, ofs_nbits, dst) = struct.unpack_from(
            ofproto_v1_0.NX_ACTION_BUNDLE_PACK_STR, buf, offset)
        slave_offset = offset + ofproto_v1_0.NX_ACTION_BUNDLE_SIZE

        slaves = []
        for i in range(0, n_slaves):
            s = struct.unpack_from('!H', buf, slave_offset)
            slaves.append(s[0])
            slave_offset += 2

        return action_cls(algorithm, fields, basis, slave_type,
                          n_slaves, ofs_nbits, dst, slaves)


@NXActionHeader.register_nx_action_subtype(ofproto_v1_0.NXAST_BUNDLE, 0)
class NXActionBundle(NXActionBundleBase):
    def __init__(self, algorithm, fields, basis, slave_type, n_slaves,
                 ofs_nbits, dst, slaves):
        super(NXActionBundle, self).__init__(
            algorithm, fields, basis, slave_type, n_slaves,
            ofs_nbits, dst, slaves)

    @classmethod
    def parser(cls, buf, offset):
        return NXActionBundleBase.parser(NXActionBundle, buf, offset)


@NXActionHeader.register_nx_action_subtype(ofproto_v1_0.NXAST_BUNDLE_LOAD, 0)
class NXActionBundleLoad(NXActionBundleBase):
    def __init__(self, algorithm, fields, basis, slave_type, n_slaves,
                 ofs_nbits, dst, slaves):
        super(NXActionBundleLoad, self).__init__(
            algorithm, fields, basis, slave_type, n_slaves,
            ofs_nbits, dst, slaves)

    @classmethod
    def parser(cls, buf, offset):
        return NXActionBundleBase.parser(NXActionBundleLoad, buf, offset)


@NXActionHeader.register_nx_action_subtype(
    ofproto_v1_0.NXAST_AUTOPATH, ofproto_v1_0.NX_ACTION_AUTOPATH_SIZE)
class NXActionAutopath(NXActionHeader):
    def __init__(self, ofs_nbits, dst, id_):
        super(NXActionAutopath, self).__init__()
        self.ofs_nbits = ofs_nbits
        self.dst = dst
        self.id = id_

    def serialize(self, buf, offset):
        msg_pack_into(ofproto_v1_0.NX_ACTION_AUTOPATH_PACK_STR, buf, offset,
                      self.type, self.len, self.vendor, self.subtype,
                      self.ofs_nbits, self.dst, self.id)

    @classmethod
    def parser(cls, buf, offset):
        (type_, len_, vendor, subtype, ofs_nbits, dst,
            id_) = struct.unpack_from(
            ofproto_v1_0.NX_ACTION_AUTOPATH_PACK_STR, buf, offset)
        return cls(ofs_nbits, dst, id_)


@NXActionHeader.register_nx_action_subtype(
    ofproto_v1_0.NXAST_OUTPUT_REG, ofproto_v1_0.NX_ACTION_OUTPUT_REG_SIZE)
class NXActionOutputReg(NXActionHeader):
    def __init__(self, ofs_nbits, src, max_len):
        super(NXActionOutputReg, self).__init__()
        self.ofs_nbits = ofs_nbits
        self.src = src
        self.max_len = max_len

    def serialize(self, buf, offset):
        msg_pack_into(ofproto_v1_0.NX_ACTION_OUTPUT_REG_PACK_STR, buf, offset,
                      self.type, self.len, self.vendor, self.subtype,
                      self.ofs_nbits, self.src, self.max_len)

    @classmethod
    def parser(cls, buf, offset):
        (type_, len_, vendor, subtype, ofs_nbits, src,
            max_len) = struct.unpack_from(
            ofproto_v1_0.NX_ACTION_OUTPUT_REG_PACK_STR, buf, offset)
        return cls(ofs_nbits, src, max_len)


@NXActionHeader.register_nx_action_subtype(
    ofproto_v1_0.NXAST_EXIT, ofproto_v1_0.NX_ACTION_HEADER_SIZE)
class NXActionExit(NXActionHeader):
    def __init__(self):
        super(NXActionExit, self).__init__()

    def serialize(self, buf, offset):
        msg_pack_into(ofproto_v1_0.NX_ACTION_HEADER_PACK_STR, buf, offset,
                      self.type, self.len, self.vendor, self.subtype)

    @classmethod
    def parser(cls, buf, offset):
        (type_, len_, vendor, subtype) = struct.unpack_from(
            ofproto_v1_0.NX_ACTION_HEADER_PACK_STR, buf, offset)
        return cls()


@NXActionHeader.register_nx_action_subtype(
    ofproto_v1_0.NXAST_DEC_TTL, ofproto_v1_0.NX_ACTION_HEADER_SIZE)
class NXActionDecTtl(NXActionHeader):
    def __init__(self):
        super(NXActionDecTtl, self).__init__()

    def serialize(self, buf, offset):
        msg_pack_into(ofproto_v1_0.NX_ACTION_HEADER_PACK_STR, buf, offset,
                      self.type, self.len, self.vendor, self.subtype)

    @classmethod
    def parser(cls, buf, offset):
        (type_, len_, vendor, subtype) = struct.unpack_from(
            ofproto_v1_0.NX_ACTION_HEADER_PACK_STR, buf, offset)
        return cls()


@NXActionHeader.register_nx_action_subtype(ofproto_v1_0.NXAST_LEARN, 0)
class NXActionLearn(NXActionHeader):
    def __init__(self, idle_timeout, hard_timeout, priority, cookie, flags,
                 table_id, fin_idle_timeout, fin_hard_timeout, spec):
        super(NXActionLearn, self).__init__()
        len_ = len(spec) + ofproto_v1_0.NX_ACTION_LEARN_SIZE
        pad_len = 8 - (len_ % 8)
        self.len = len_ + pad_len

        self.idle_timeout = idle_timeout
        self.hard_timeout = hard_timeout
        self.priority = priority
        self.cookie = cookie
        self.flags = flags
        self.table_id = table_id
        self.fin_idle_timeout = fin_idle_timeout
        self.fin_hard_timeout = fin_hard_timeout
        self.spec = spec + bytearray('\x00' * pad_len)

    def serialize(self, buf, offset):
        msg_pack_into(ofproto_v1_0.NX_ACTION_LEARN_PACK_STR, buf, offset,
                      self.type, self.len, self.vendor, self.subtype,
                      self.idle_timeout, self.hard_timeout, self.priority,
                      self.cookie, self.flags, self.table_id,
                      self.fin_idle_timeout, self.fin_hard_timeout)
        buf += self.spec

    @classmethod
    def parser(cls, buf, offset):
        (type_, len_, vendor, subtype, idle_timeout, hard_timeout, priority,
            cookie, flags, table_id, fin_idle_timeout,
            fin_hard_timeout) = struct.unpack_from(
            ofproto_v1_0.NX_ACTION_LEARN_PACK_STR, buf, offset)
        spec = buf[offset + ofproto_v1_0.NX_ACTION_LEARN_SIZE:]
        return cls(idle_timeout, hard_timeout, priority,
                   cookie, flags, table_id, fin_idle_timeout,
                   fin_hard_timeout, spec)


@NXActionHeader.register_nx_action_subtype(
    ofproto_v1_0.NXAST_CONTROLLER, ofproto_v1_0.NX_ACTION_CONTROLLER_SIZE)
class NXActionController(NXActionHeader):
    def __init__(self, max_len, controller_id, reason):
        super(NXActionController, self).__init__()
        self.max_len = max_len
        self.controller_id = controller_id
        self.reason = reason

    def serialize(self, buf, offset):
        msg_pack_into(ofproto_v1_0.NX_ACTION_CONTROLLER_PACK_STR, buf, offset,
                      self.type, self.len, self.vendor, self.subtype,
                      self.max_len, self.controller_id, self.reason, 0)

    @classmethod
    def parser(cls, buf, offset):
        (type_, len_, vendor, subtype, max_len, controller_id, reason,
            _zero) = struct.unpack_from(
            ofproto_v1_0.NX_ACTION_CONTROLLER_PACK_STR, buf, offset)
        return cls(max_len, controller_id, reason)


@NXActionHeader.register_nx_action_subtype(
    ofproto_v1_0.NXAST_FIN_TIMEOUT, ofproto_v1_0.NX_ACTION_FIN_TIMEOUT_SIZE)
class NXActionFinTimeout(NXActionHeader):
    def __init__(self, fin_idle_timeout, fin_hard_timeout):
        super(NXActionFinTimeout, self).__init__()
        self.fin_idle_timeout = fin_idle_timeout
        self.fin_hard_timeout = fin_hard_timeout

    def serialize(self, buf, offset):
        msg_pack_into(ofproto_v1_0.NX_ACTION_FIN_TIMEOUT_PACK_STR, buf, offset,
                      self.type, self.len, self.vendor, self.subtype,
                      self.fin_idle_timeout, self.fin_hard_timeout)

    @classmethod
    def parser(cls, buf, offset):
        (type_, len_, vendor, subtype, fin_idle_timeout,
            fin_hard_timeout) = struct.unpack_from(
            ofproto_v1_0.NX_ACTION_FIN_TIMEOUT_PACK_STR, buf, offset)
        return cls(fin_idle_timeout, fin_hard_timeout)


class OFPDescStats(ofproto_parser.namedtuple('OFPDescStats', (
        'mfr_desc', 'hw_desc', 'sw_desc', 'serial_num', 'dp_desc'))):

    _TYPE = {
        'ascii': [
            'mfr_desc',
            'hw_desc',
            'sw_desc',
            'serial_num',
            'dp_desc',
        ]
    }

    @classmethod
    def parser(cls, buf, offset):
        desc = struct.unpack_from(ofproto_v1_0.OFP_DESC_STATS_PACK_STR,
                                  buf, offset)
        desc = list(desc)
        desc = map(lambda x: x.rstrip('\0'), desc)
        stats = cls(*desc)
        stats.length = ofproto_v1_0.OFP_DESC_STATS_SIZE
        return stats


class OFPFlowStats(StringifyMixin):
    def __init__(self):
        super(OFPFlowStats, self).__init__()
        self.length = None
        self.table_id = None
        self.match = None
        self.duration_sec = None
        self.duration_nsec = None
        self.priority = None
        self.idle_timeout = None
        self.hard_timeout = None
        self.cookie = None
        self.packet_count = None
        self.byte_count = None
        self.actions = None

    @classmethod
    def parser(cls, buf, offset):
        flow_stats = cls()

        flow_stats.length, flow_stats.table_id = struct.unpack_from(
            ofproto_v1_0.OFP_FLOW_STATS_0_PACK_STR, buf, offset)
        offset += ofproto_v1_0.OFP_FLOW_STATS_0_SIZE

        flow_stats.match = OFPMatch.parse(buf, offset)
        offset += ofproto_v1_0.OFP_MATCH_SIZE

        (flow_stats.duration_sec,
         flow_stats.duration_nsec,
         flow_stats.priority,
         flow_stats.idle_timeout,
         flow_stats.hard_timeout,
         flow_stats.cookie,
         flow_stats.packet_count,
         flow_stats.byte_count) = struct.unpack_from(
            ofproto_v1_0.OFP_FLOW_STATS_1_PACK_STR, buf, offset)
        offset += ofproto_v1_0.OFP_FLOW_STATS_1_SIZE

        flow_stats.actions = []
        length = ofproto_v1_0.OFP_FLOW_STATS_SIZE
        while length < flow_stats.length:
            action = OFPAction.parser(buf, offset)
            flow_stats.actions.append(action)

            offset += action.len
            length += action.len

        return flow_stats


class OFPAggregateStats(ofproto_parser.namedtuple('OFPAggregateStats', (
        'packet_count', 'byte_count', 'flow_count'))):
    @classmethod
    def parser(cls, buf, offset):
        agg = struct.unpack_from(
            ofproto_v1_0.OFP_AGGREGATE_STATS_REPLY_PACK_STR, buf, offset)
        stats = cls(*agg)
        stats.length = ofproto_v1_0.OFP_AGGREGATE_STATS_REPLY_SIZE
        return stats


class OFPTableStats(ofproto_parser.namedtuple('OFPTableStats', (
        'table_id', 'name', 'wildcards', 'max_entries', 'active_count',
        'lookup_count', 'matched_count'))):

    _TYPE = {
        'utf-8': [
            # OF spec is unclear about the encoding of name.
            # we assumes UTF-8.
            'name',
        ]
    }

    @classmethod
    def parser(cls, buf, offset):
        tbl = struct.unpack_from(ofproto_v1_0.OFP_TABLE_STATS_PACK_STR,
                                 buf, offset)
        tbl = list(tbl)
        i = cls._fields.index('name')
        tbl[i] = tbl[i].rstrip('\0')
        stats = cls(*tbl)
        stats.length = ofproto_v1_0.OFP_TABLE_STATS_SIZE
        return stats


class OFPPortStats(ofproto_parser.namedtuple('OFPPortStats', (
        'port_no', 'rx_packets', 'tx_packets', 'rx_bytes', 'tx_bytes',
        'rx_dropped', 'tx_dropped', 'rx_errors', 'tx_errors',
        'rx_frame_err', 'rx_over_err', 'rx_crc_err', 'collisions'))):
    @classmethod
    def parser(cls, buf, offset):
        port = struct.unpack_from(ofproto_v1_0.OFP_PORT_STATS_PACK_STR,
                                  buf, offset)
        stats = cls(*port)
        stats.length = ofproto_v1_0.OFP_PORT_STATS_SIZE
        return stats


class OFPQueueStats(ofproto_parser.namedtuple('OFPQueueStats', (
        'port_no', 'queue_id', 'tx_bytes', 'tx_packets', 'tx_errors'))):
    @classmethod
    def parser(cls, buf, offset):
        queue = struct.unpack_from(ofproto_v1_0.OFP_QUEUE_STATS_PACK_STR,
                                   buf, offset)
        stats = cls(*queue)
        stats.length = ofproto_v1_0.OFP_QUEUE_STATS_SIZE
        return stats


class OFPVendorStats(ofproto_parser.namedtuple('OFPVendorStats',
                                               ('specific_data'))):
    @classmethod
    def parser(cls, buf, offset):
        stats = cls(buf[offset:])
        stats.length = len(stats.specific_data)
        return stats


class NXFlowStats(StringifyMixin):
    def __init__(self):
        super(NXFlowStats, self).__init__()
        self.length = None
        self.table_id = None
        self.duration_sec = None
        self.duration_nsec = None
        self.priority = None
        self.idle_timeout = None
        self.hard_timeout = None
        self.match_len = None
        self.idle_age = None
        self.hard_age = None
        self.cookie = None
        self.packet_count = None
        self.byte_count = None

    @classmethod
    def parser(cls, buf, offset):
        original_offset = offset
        nxflow_stats = cls()
        (nxflow_stats.length, nxflow_stats.table_id,
         nxflow_stats.duration_sec, nxflow_stats.duration_nsec,
         nxflow_stats.priority, nxflow_stats.idle_timeout,
         nxflow_stats.hard_timeout, nxflow_stats.match_len,
         nxflow_stats.idle_age, nxflow_stats.hard_age,
         nxflow_stats.cookie, nxflow_stats.packet_count,
         nxflow_stats.byte_count) = struct.unpack_from(
            ofproto_v1_0.NX_FLOW_STATS_PACK_STR, buf, offset)
        offset += ofproto_v1_0.NX_FLOW_STATS_SIZE

        fields = []
        match_len = nxflow_stats.match_len
        match_len -= 4
        while match_len > 0:
            field = nx_match.MFField.parser(buf, offset)
            offset += field.length
            match_len -= field.length
            fields.append(field)
        nxflow_stats.fields = fields

        actions = []
        total_len = original_offset + nxflow_stats.length
        match_len = nxflow_stats.match_len
        offset += utils.round_up(match_len, 8) - match_len
        while offset < total_len:
            action = OFPAction.parser(buf, offset)
            actions.append(action)
            offset += action.len
        nxflow_stats.actions = actions

        return nxflow_stats


class NXAggregateStats(ofproto_parser.namedtuple('NXAggregateStats', (
        'packet_count', 'byte_count', 'flow_count'))):
    @classmethod
    def parser(cls, buf, offset):
        agg = struct.unpack_from(
            ofproto_v1_0.NX_AGGREGATE_STATS_REPLY_PACK_STR, buf, offset)
        stats = cls(*agg)
        stats.length = ofproto_v1_0.NX_AGGREGATE_STATS_REPLY_SIZE

        return stats


class OFPQueuePropHeader(StringifyMixin):
    _QUEUE_PROPERTIES = {}

    @staticmethod
    def register_queue_property(prop_type, prop_len):
        def _register_queue_propery(cls):
            cls.cls_prop_type = prop_type
            cls.cls_prop_len = prop_len
            OFPQueuePropHeader._QUEUE_PROPERTIES[prop_type] = cls
            return cls
        return _register_queue_propery

    def __init__(self):
        self.property = self.cls_prop_type
        self.len = self.cls_prop_len

    @classmethod
    def parser(cls, buf, offset):
        property_, len_ = struct.unpack_from(
            ofproto_v1_0.OFP_QUEUE_PROP_HEADER_PACK_STR, buf, offset)
        prop_cls = cls._QUEUE_PROPERTIES[property_]
        assert property_ == prop_cls.cls_prop_type
        assert len_ == prop_cls.cls_prop_len

        offset += ofproto_v1_0.OFP_QUEUE_PROP_HEADER_SIZE
        return prop_cls.parser(buf, offset)


@OFPQueuePropHeader.register_queue_property(
    ofproto_v1_0.OFPQT_NONE, ofproto_v1_0.OFP_QUEUE_PROP_HEADER_SIZE)
class OFPQueuePropNone(OFPQueuePropHeader):
    def __init__(self):
        super(OFPQueuePropNone, self).__init__()

    @classmethod
    def parser(cls, buf, offset):
        return cls()


@OFPQueuePropHeader.register_queue_property(
    ofproto_v1_0.OFPQT_MIN_RATE, ofproto_v1_0.OFP_QUEUE_PROP_MIN_RATE_SIZE)
class OFPQueuePropMinRate(OFPQueuePropHeader):
    def __init__(self, rate):
        super(OFPQueuePropMinRate, self).__init__()
        self.rate = rate

    @classmethod
    def parser(cls, buf, offset):
        (rate,) = struct.unpack_from(
            ofproto_v1_0.OFP_QUEUE_PROP_MIN_RATE_PACK_STR,
            buf, offset)
        return cls(rate)


class OFPPacketQueue(StringifyMixin):
    def __init__(self, queue_id, len_):
        self.queue_id = queue_id
        self.len = len_
        self.properties = None

    @classmethod
    def parser(cls, buf, offset):
        queue_id, len_ = struct.unpack_from(
            ofproto_v1_0.OFP_PACKET_QUEUE_PQCK_STR, buf, offset)
        packet_queue = cls(queue_id, len_)

        packet_queue.properties = []
        cur_len = ofproto_v1_0.OFP_PACKET_QUEUE_SIZE
        offset += ofproto_v1_0.OFP_PACKET_QUEUE_SIZE
        while (cur_len + ofproto_v1_0.OFP_QUEUE_PROP_HEADER_SIZE <=
               packet_queue.len):
            prop = OFPQueuePropHeader.parser(buf, offset)
            packet_queue.properties.append(prop)

            cur_len += prop.len
            offset += prop.len

        return packet_queue

#
# Symmetric messages
# parser + serializer
#


@_register_parser
@_set_msg_type(ofproto_v1_0.OFPT_HELLO)
class OFPHello(MsgBase):
    def __init__(self, datapath):
        super(OFPHello, self).__init__(datapath)


@_register_parser
@_set_msg_type(ofproto_v1_0.OFPT_ERROR)
class OFPErrorMsg(MsgBase):
    def __init__(self, datapath, type_=None, code=None, data=None):
        super(OFPErrorMsg, self).__init__(datapath)
        self.type = type_
        self.code = code
        self.data = data

    @classmethod
    def parser(cls, datapath, version, msg_type, msg_len, xid, buf):
        msg = super(OFPErrorMsg, cls).parser(datapath, version, msg_type,
                                             msg_len, xid, buf)
        msg.type, msg.code = struct.unpack_from(
            ofproto_v1_0.OFP_ERROR_MSG_PACK_STR, msg.buf,
            ofproto_v1_0.OFP_HEADER_SIZE)
        msg.data = msg.buf[ofproto_v1_0.OFP_ERROR_MSG_SIZE:]
        return msg

    def _serialize_body(self):
        assert self.data is not None
        msg_pack_into(ofproto_v1_0.OFP_ERROR_MSG_PACK_STR, self.buf,
                      ofproto_v1_0.OFP_HEADER_SIZE, self.type, self.code)
        self.buf += self.data


@_register_parser
@_set_msg_type(ofproto_v1_0.OFPT_ECHO_REQUEST)
class OFPEchoRequest(MsgBase):
    def __init__(self, datapath, data=None):
        super(OFPEchoRequest, self).__init__(datapath)
        self.data = data

    @classmethod
    def parser(cls, datapath, version, msg_type, msg_len, xid, buf):
        msg = super(OFPEchoRequest, cls).parser(datapath, version, msg_type,
                                                msg_len, xid, buf)
        msg.data = msg.buf[ofproto_v1_0.OFP_HEADER_SIZE:]
        return msg

    def _serialize_body(self):
        if self.data is not None:
            self.buf += self.data


@_register_parser
@_set_msg_type(ofproto_v1_0.OFPT_ECHO_REPLY)
class OFPEchoReply(MsgBase):
    def __init__(self, datapath, data=None):
        super(OFPEchoReply, self).__init__(datapath)
        self.data = data

    @classmethod
    def parser(cls, datapath, version, msg_type, msg_len, xid, buf):
        msg = super(OFPEchoReply, cls).parser(datapath, version, msg_type,
                                              msg_len, xid, buf)
        msg.data = msg.buf[ofproto_v1_0.OFP_HEADER_SIZE:]
        return msg

    def _serialize_body(self):
        assert self.data is not None
        self.buf += self.data


@_register_parser
@_set_msg_type(ofproto_v1_0.OFPT_VENDOR)
class OFPVendor(MsgBase):
    _VENDORS = {}

    @staticmethod
    def register_vendor(id_):
        def _register_vendor(cls):
            OFPVendor._VENDORS[id_] = cls
            return cls
        return _register_vendor

    def __init__(self, datapath):
        super(OFPVendor, self).__init__(datapath)
        self.data = None
        self.vendor = None

    @classmethod
    def parser(cls, datapath, version, msg_type, msg_len, xid, buf):
        msg = super(OFPVendor, cls).parser(datapath, version, msg_type,
                                           msg_len, xid, buf)
        (msg.vendor,) = struct.unpack_from(
            ofproto_v1_0.OFP_VENDOR_HEADER_PACK_STR, msg.buf,
            ofproto_v1_0.OFP_HEADER_SIZE)

        cls_ = cls._VENDORS.get(msg.vendor)
        if cls_:
            msg.data = cls_.parser(datapath, msg.buf, 0)
        else:
            msg.data = msg.buf[ofproto_v1_0.OFP_VENDOR_HEADER_SIZE:]

        return msg

    def serialize_header(self):
        msg_pack_into(ofproto_v1_0.OFP_VENDOR_HEADER_PACK_STR,
                      self.buf, ofproto_v1_0.OFP_HEADER_SIZE, self.vendor)

    def _serialize_body(self):
        assert self.data is not None
        self.serialize_header()
        self.buf += self.data


@OFPVendor.register_vendor(ofproto_v1_0.NX_VENDOR_ID)
class NiciraHeader(OFPVendor):
    _NX_SUBTYPES = {}

    @staticmethod
    def register_nx_subtype(subtype):
        def _register_nx_subtype(cls):
            cls.cls_subtype = subtype
            NiciraHeader._NX_SUBTYPES[cls.cls_subtype] = cls
            return cls
        return _register_nx_subtype

    def __init__(self, datapath, subtype):
        super(NiciraHeader, self).__init__(datapath)
        self.vendor = ofproto_v1_0.NX_VENDOR_ID
        self.subtype = subtype

    def serialize_header(self):
        super(NiciraHeader, self).serialize_header()
        msg_pack_into(ofproto_v1_0.NICIRA_HEADER_PACK_STR,
                      self.buf, ofproto_v1_0.OFP_HEADER_SIZE,
                      self.vendor, self.subtype)

    @classmethod
    def parser(cls, datapath, buf, offset):
        vendor, subtype = struct.unpack_from(
            ofproto_v1_0.NICIRA_HEADER_PACK_STR, buf,
            offset + ofproto_v1_0.OFP_HEADER_SIZE)
        cls_ = cls._NX_SUBTYPES.get(subtype)
        return cls_.parser(datapath, buf,
                           offset + ofproto_v1_0.NICIRA_HEADER_SIZE)


class NXTSetFlowFormat(NiciraHeader):
    def __init__(self, datapath, flow_format):
        super(NXTSetFlowFormat, self).__init__(
            datapath, ofproto_v1_0.NXT_SET_FLOW_FORMAT)
        self.format = flow_format

    def _serialize_body(self):
        self.serialize_header()
        msg_pack_into(ofproto_v1_0.NX_SET_FLOW_FORMAT_PACK_STR,
                      self.buf, ofproto_v1_0.NICIRA_HEADER_SIZE, self.format)


class NXTFlowMod(NiciraHeader):
    def __init__(self, datapath, cookie, command,
                 idle_timeout=0, hard_timeout=0,
                 priority=ofproto_v1_0.OFP_DEFAULT_PRIORITY,
                 buffer_id=0xffffffff, out_port=ofproto_v1_0.OFPP_NONE,
                 flags=0, rule=None, actions=None):

        # the argument, rule, is positioned at the one before the last due
        # to the layout struct nxt_flow_mod.
        # Although rule must be given, default argument to rule, None,
        # is given to allow other default value of argument before rule.
        assert rule is not None

        if actions is None:
            actions = []
        super(NXTFlowMod, self).__init__(datapath, ofproto_v1_0.NXT_FLOW_MOD)
        self.cookie = cookie
        self.command = command
        self.idle_timeout = idle_timeout
        self.hard_timeout = hard_timeout
        self.priority = priority
        self.buffer_id = buffer_id
        self.out_port = out_port
        self.flags = flags
        self.rule = rule
        self.actions = actions

    def _serialize_body(self):
        self.serialize_header()

        offset = ofproto_v1_0.NX_FLOW_MOD_SIZE
        match_len = nx_match.serialize_nxm_match(self.rule, self.buf, offset)
        offset += nx_match.round_up(match_len)

        msg_pack_into(ofproto_v1_0.NX_FLOW_MOD_PACK_STR,
                      self.buf, ofproto_v1_0.NICIRA_HEADER_SIZE,
                      self.cookie, self.command, self.idle_timeout,
                      self.hard_timeout, self.priority, self.buffer_id,
                      self.out_port, self.flags, match_len)

        if self.actions is not None:
            for a in self.actions:
                a.serialize(self.buf, offset)
                offset += a.len


class NXTRoleRequest(NiciraHeader):
    def __init__(self, datapath, role):
        super(NXTRoleRequest, self).__init__(
            datapath, ofproto_v1_0.NXT_ROLE_REQUEST)
        self.role = role

    def _serialize_body(self):
        self.serialize_header()
        msg_pack_into(ofproto_v1_0.NX_ROLE_PACK_STR,
                      self.buf, ofproto_v1_0.NICIRA_HEADER_SIZE, self.role)


@NiciraHeader.register_nx_subtype(ofproto_v1_0.NXT_ROLE_REPLY)
class NXTRoleReply(NiciraHeader):
    def __init__(self, datapath, role):
        super(NXTRoleReply, self).__init__(
            datapath, ofproto_v1_0.NXT_ROLE_REPLY)
        self.role = role

    @classmethod
    def parser(cls, datapath, buf, offset):
        (role,) = struct.unpack_from(
            ofproto_v1_0.NX_ROLE_PACK_STR, buf, offset)
        return cls(datapath, role)


class NXTFlowModTableId(NiciraHeader):
    def __init__(self, datapath, set_):
        super(NXTFlowModTableId, self).__init__(
            datapath, ofproto_v1_0.NXT_FLOW_MOD_TABLE_ID)
        self.set = set_

    def _serialize_body(self):
        self.serialize_header()
        msg_pack_into(ofproto_v1_0.NX_FLOW_MOD_TABLE_ID_PACK_STR,
                      self.buf, ofproto_v1_0.NICIRA_HEADER_SIZE,
                      self.set)


@NiciraHeader.register_nx_subtype(ofproto_v1_0.NXT_FLOW_REMOVED)
class NXTFlowRemoved(NiciraHeader):
    def __init__(self, datapath, cookie, priority, reason,
                 duration_sec, duration_nsec, idle_timeout, match_len,
                 packet_count, byte_count, match):
        super(NXTFlowRemoved, self).__init__(
            datapath, ofproto_v1_0.NXT_FLOW_REMOVED)
        self.cookie = cookie
        self.priority = priority
        self.reason = reason
        self.duration_sec = duration_sec
        self.duration_nsec = duration_nsec
        self.idle_timeout = idle_timeout
        self.match_len = match_len
        self.packet_count = packet_count
        self.byte_count = byte_count
        self.match = match

    @classmethod
    def parser(cls, datapath, buf, offset):
        (cookie, priority, reason, duration_sec, duration_nsec,
         idle_timeout, match_len,
         packet_count, byte_count) = struct.unpack_from(
            ofproto_v1_0.NX_FLOW_REMOVED_PACK_STR, buf, offset)
        offset += (ofproto_v1_0.NX_FLOW_REMOVED_SIZE
                   - ofproto_v1_0.NICIRA_HEADER_SIZE)
        match = nx_match.NXMatch.parser(buf, offset, match_len)
        return cls(datapath, cookie, priority, reason, duration_sec,
                   duration_nsec, idle_timeout, match_len, packet_count,
                   byte_count, match)


class NXTSetPacketInFormat(NiciraHeader):
    def __init__(self, datapath, packet_in_format):
        super(NXTSetPacketInFormat, self).__init__(
            datapath, ofproto_v1_0.NXT_SET_PACKET_IN_FORMAT)
        self.format = packet_in_format

    def _serialize_body(self):
        self.serialize_header()
        msg_pack_into(ofproto_v1_0.NX_SET_PACKET_IN_FORMAT_PACK_STR,
                      self.buf, ofproto_v1_0.NICIRA_HEADER_SIZE,
                      self.format)


@NiciraHeader.register_nx_subtype(ofproto_v1_0.NXT_PACKET_IN)
class NXTPacketIn(NiciraHeader):
    def __init__(self, datapath, buffer_id, total_len, reason, table_id,
                 cookie, match_len, match, frame):
        super(NXTPacketIn, self).__init__(
            datapath, ofproto_v1_0.NXT_PACKET_IN)
        self.buffer_id = buffer_id
        self.total_len = total_len
        self.reason = reason
        self.table_id = table_id
        self.cookie = cookie
        self.match_len = match_len
        self.match = match
        self.frame = frame

    @classmethod
    def parser(cls, datapath, buf, offset):
        (buffer_id, total_len, reason, table_id,
         cookie, match_len) = struct.unpack_from(
            ofproto_v1_0.NX_PACKET_IN_PACK_STR, buf, offset)

        offset += (ofproto_v1_0.NX_PACKET_IN_SIZE
                   - ofproto_v1_0.NICIRA_HEADER_SIZE)

        match = nx_match.NXMatch.parser(buf, offset, match_len)
        offset += (match_len + 7) / 8 * 8
        frame = buf[offset:]
        if total_len < len(frame):
            frame = frame[:total_len]
        return cls(datapath, buffer_id, total_len, reason, table_id,
                   cookie, match_len, match, frame)


class NXTFlowAge(NiciraHeader):
    def __init__(self, datapath):
        super(NXTFlowAge, self).__init__(
            datapath, ofproto_v1_0.NXT_FLOW_AGE)

    def _serialize_body(self):
        self.serialize_header()


class NXTSetAsyncConfig(NiciraHeader):
    def __init__(self, datapath, packet_in_mask, port_status_mask,
                 flow_removed_mask):
        super(NXTSetAsyncConfig, self).__init__(
            datapath, ofproto_v1_0.NXT_SET_ASYNC_CONFIG)
        self.packet_in_mask = packet_in_mask
        self.port_status_mask = port_status_mask
        self.flow_removed_mask = flow_removed_mask

    def _serialize_body(self):
        self.serialize_header()
        msg_pack_into(ofproto_v1_0.NX_ASYNC_CONFIG_PACK_STR,
                      self.buf, ofproto_v1_0.NICIRA_HEADER_SIZE,
                      self.packet_in_mask[0], self.packet_in_mask[1],
                      self.port_status_mask[0], self.port_status_mask[1],
                      self.flow_removed_mask[0], self.flow_removed_mask[1])


class NXTSetControllerId(NiciraHeader):
    def __init__(self, datapath, controller_id):
        super(NXTSetControllerId, self).__init__(
            datapath, ofproto_v1_0.NXT_SET_CONTROLLER_ID)
        self.controller_id = controller_id

    def _serialize_body(self):
        self.serialize_header()
        msg_pack_into(ofproto_v1_0.NX_CONTROLLER_ID_PACK_STR,
                      self.buf, ofproto_v1_0.NICIRA_HEADER_SIZE,
                      self.controller_id)


#
# asymmetric message (datapath -> controller)
# parser only
#


@_register_parser
@_set_msg_type(ofproto_v1_0.OFPT_FEATURES_REPLY)
class OFPSwitchFeatures(MsgBase):
    def __init__(self, datapath, datapath_id=None, n_buffers=None,
                 n_tables=None, capabilities=None, actions=None, ports=None):
        super(OFPSwitchFeatures, self).__init__(datapath)
        self.datapath_id = datapath_id
        self.n_buffers = n_buffers
        self.n_tables = n_tables
        self.capabilities = capabilities
        self.actions = actions
        self.ports = ports

    @classmethod
    def parser(cls, datapath, version, msg_type, msg_len, xid, buf):
        msg = super(OFPSwitchFeatures, cls).parser(datapath, version, msg_type,
                                                   msg_len, xid, buf)
        (msg.datapath_id,
         msg.n_buffers,
         msg.n_tables,
         msg.capabilities,
         msg.actions) = struct.unpack_from(
            ofproto_v1_0.OFP_SWITCH_FEATURES_PACK_STR, msg.buf,
            ofproto_v1_0.OFP_HEADER_SIZE)

        msg.ports = {}
        n_ports = ((msg_len - ofproto_v1_0.OFP_SWITCH_FEATURES_SIZE) /
                   ofproto_v1_0.OFP_PHY_PORT_SIZE)
        offset = ofproto_v1_0.OFP_SWITCH_FEATURES_SIZE
        for _i in range(n_ports):
            port = OFPPhyPort.parser(msg.buf, offset)
            # print 'port = %s' % str(port)
            msg.ports[port.port_no] = port
            offset += ofproto_v1_0.OFP_PHY_PORT_SIZE

        return msg


@_register_parser
@_set_msg_type(ofproto_v1_0.OFPT_PORT_STATUS)
class OFPPortStatus(MsgBase):
    def __init__(self, datapath, reason=None, desc=None):
        super(OFPPortStatus, self).__init__(datapath)
        self.reason = reason
        self.desc = desc

    @classmethod
    def parser(cls, datapath, version, msg_type, msg_len, xid, buf):
        msg = super(OFPPortStatus, cls).parser(datapath, version, msg_type,
                                               msg_len, xid, buf)
        msg.reason = struct.unpack_from(
            ofproto_v1_0.OFP_PORT_STATUS_PACK_STR,
            msg.buf, ofproto_v1_0.OFP_HEADER_SIZE)[0]
        msg.desc = OFPPhyPort.parser(msg.buf,
                                     ofproto_v1_0.OFP_PORT_STATUS_DESC_OFFSET)
        return msg


@_register_parser
@_set_msg_type(ofproto_v1_0.OFPT_PACKET_IN)
class OFPPacketIn(MsgBase):
    def __init__(self, datapath, buffer_id=None, total_len=None, in_port=None,
                 reason=None, data=None):
        super(OFPPacketIn, self).__init__(datapath)
        self.buffer_id = buffer_id
        self.total_len = total_len
        self.in_port = in_port
        self.reason = reason
        self.data = data

    @classmethod
    def parser(cls, datapath, version, msg_type, msg_len, xid, buf):
        msg = super(OFPPacketIn, cls).parser(datapath, version, msg_type,
                                             msg_len, xid, buf)
        (msg.buffer_id,
         msg.total_len,
         msg.in_port,
         msg.reason) = struct.unpack_from(
            ofproto_v1_0.OFP_PACKET_IN_PACK_STR,
            msg.buf, ofproto_v1_0.OFP_HEADER_SIZE)
        msg.data = msg.buf[ofproto_v1_0.OFP_PACKET_IN_SIZE:]
        if msg.total_len < len(msg.data):
            # discard padding for 8-byte alignment of OFP packet
            msg.data = msg.data[:msg.total_len]
        return msg


@_register_parser
@_set_msg_type(ofproto_v1_0.OFPT_GET_CONFIG_REPLY)
class OFPGetConfigReply(MsgBase):
    def __init__(self, datapath):
        super(OFPGetConfigReply, self).__init__(datapath)

    @classmethod
    def parser(cls, datapath, version, msg_type, msg_len, xid, buf):
        msg = super(OFPGetConfigReply, cls).parser(datapath, version, msg_type,
                                                   msg_len, xid, buf)
        (msg.flags, msg.miss_send_len) = struct.unpack_from(
            ofproto_v1_0.OFP_SWITCH_CONFIG_PACK_STR,
            msg.buf, ofproto_v1_0.OFP_HEADER_SIZE)
        return msg


@_register_parser
@_set_msg_type(ofproto_v1_0.OFPT_BARRIER_REPLY)
class OFPBarrierReply(MsgBase):
    def __init__(self, datapath):
        super(OFPBarrierReply, self).__init__(datapath)


@_register_parser
@_set_msg_type(ofproto_v1_0.OFPT_FLOW_REMOVED)
class OFPFlowRemoved(MsgBase):
    def __init__(self, datapath):
        super(OFPFlowRemoved, self).__init__(datapath)

    @classmethod
    def parser(cls, datapath, version, msg_type, msg_len, xid, buf):
        msg = super(OFPFlowRemoved, cls).parser(datapath, version, msg_type,
                                                msg_len, xid, buf)

        msg.match = OFPMatch.parse(msg.buf, ofproto_v1_0.OFP_HEADER_SIZE)

        (msg.cookie,
         msg.priority,
         msg.reason,
         msg.duration_sec,
         msg.duration_nsec,
         msg.idle_timeout,
         msg.packet_count,
         msg.byte_count) = struct.unpack_from(
            ofproto_v1_0.OFP_FLOW_REMOVED_PACK_STR0, msg.buf,
            ofproto_v1_0.OFP_HEADER_SIZE + ofproto_v1_0.OFP_MATCH_SIZE)

        return msg


@_register_parser
@_set_msg_type(ofproto_v1_0.OFPT_QUEUE_GET_CONFIG_REPLY)
class OFPQueueGetConfigReply(MsgBase):
    def __init__(self, datapath):
        super(OFPQueueGetConfigReply, self).__init__(datapath)

    @classmethod
    def parser(cls, datapath, version, msg_type, msg_len, xid, buf):
        msg = super(OFPQueueGetConfigReply, cls).parser(
            datapath, version, msg_type, msg_len, xid, buf)

        offset = ofproto_v1_0.OFP_HEADER_SIZE
        (msg.port,) = struct.unpack_from(
            ofproto_v1_0.OFP_QUEUE_GET_CONFIG_REPLY_PACK_STR, msg.buf, offset)

        msg.queues = []
        offset = ofproto_v1_0.OFP_QUEUE_GET_CONFIG_REPLY_SIZE
        while offset + ofproto_v1_0.OFP_PACKET_QUEUE_SIZE <= msg_len:
            queue = OFPPacketQueue.parser(msg.buf, offset)
            msg.queues.append(queue)

            offset += queue.len

        return msg


def _set_stats_type(stats_type, stats_body_cls):
    def _set_cls_stats_type(cls):
        cls.cls_stats_type = stats_type
        cls.cls_stats_body_cls = stats_body_cls
        return cls
    return _set_cls_stats_type


@_register_parser
@_set_msg_type(ofproto_v1_0.OFPT_STATS_REPLY)
class OFPStatsReply(MsgBase):
    _STATS_MSG_TYPES = {}

    @staticmethod
    def register_stats_type(body_single_struct=False):
        def _register_stats_type(cls):
            assert cls.cls_stats_type is not None
            assert cls.cls_stats_type not in OFPStatsReply._STATS_MSG_TYPES
            assert cls.cls_stats_body_cls is not None
            cls.cls_body_single_struct = body_single_struct
            OFPStatsReply._STATS_MSG_TYPES[cls.cls_stats_type] = cls
            return cls
        return _register_stats_type

    def __init__(self, datapath):
        super(OFPStatsReply, self).__init__(datapath)
        self.type = None
        self.flags = None
        self.body = None

    @classmethod
    def parser_stats_body(cls, buf, msg_len, offset):
        body_cls = cls.cls_stats_body_cls
        body = []
        while offset < msg_len:
            entry = body_cls.parser(buf, offset)
            body.append(entry)
            offset += entry.length

        if cls.cls_body_single_struct:
            return body[0]
        return body

    @classmethod
    def parser_stats(cls, datapath, version, msg_type, msg_len, xid, buf):
        # call MsgBase::parser, not OFPStatsReply::parser
        msg = MsgBase.parser.__func__(
            cls, datapath, version, msg_type, msg_len, xid, buf)
        msg.body = msg.parser_stats_body(msg.buf, msg.msg_len,
                                         ofproto_v1_0.OFP_STATS_MSG_SIZE)
        return msg

    @classmethod
    def parser(cls, datapath, version, msg_type, msg_len, xid, buf):
        type_, flags = struct.unpack_from(ofproto_v1_0.OFP_STATS_MSG_PACK_STR,
                                          buffer(buf),
                                          ofproto_v1_0.OFP_HEADER_SIZE)
        stats_type_cls = cls._STATS_MSG_TYPES.get(type_)
        msg = stats_type_cls.parser_stats(
            datapath, version, msg_type, msg_len, xid, buf)
        msg.type = type_
        msg.flags = flags
        return msg


@OFPStatsReply.register_stats_type(body_single_struct=True)
@_set_stats_type(ofproto_v1_0.OFPST_DESC, OFPDescStats)
@_set_msg_type(ofproto_v1_0.OFPT_STATS_REPLY)
class OFPDescStatsReply(OFPStatsReply):
    def __init__(self, datapath):
        super(OFPDescStatsReply, self).__init__(datapath)


@OFPStatsReply.register_stats_type()
@_set_stats_type(ofproto_v1_0.OFPST_FLOW, OFPFlowStats)
@_set_msg_type(ofproto_v1_0.OFPT_STATS_REPLY)
class OFPFlowStatsReply(OFPStatsReply):
    def __init__(self, datapath):
        super(OFPFlowStatsReply, self).__init__(datapath)


@OFPStatsReply.register_stats_type()
@_set_stats_type(ofproto_v1_0.OFPST_AGGREGATE, OFPAggregateStats)
@_set_msg_type(ofproto_v1_0.OFPT_STATS_REPLY)
class OFPAggregateStatsReply(OFPStatsReply):
    def __init__(self, datapath):
        super(OFPAggregateStatsReply, self).__init__(datapath)


@OFPStatsReply.register_stats_type()
@_set_stats_type(ofproto_v1_0.OFPST_TABLE, OFPTableStats)
@_set_msg_type(ofproto_v1_0.OFPT_STATS_REPLY)
class OFPTableStatsReply(OFPStatsReply):
    def __init__(self, datapath):
        super(OFPTableStatsReply, self).__init__(datapath)


@OFPStatsReply.register_stats_type()
@_set_stats_type(ofproto_v1_0.OFPST_PORT, OFPPortStats)
@_set_msg_type(ofproto_v1_0.OFPT_STATS_REPLY)
class OFPPortStatsReply(OFPStatsReply):
    def __init__(self, datapath):
        super(OFPPortStatsReply, self).__init__(datapath)


@OFPStatsReply.register_stats_type()
@_set_stats_type(ofproto_v1_0.OFPST_QUEUE, OFPQueueStats)
@_set_msg_type(ofproto_v1_0.OFPT_STATS_REPLY)
class OFPQueueStatsReply(OFPStatsReply):
    def __init__(self, datapath):
        super(OFPQueueStatsReply, self).__init__(datapath)


@OFPStatsReply.register_stats_type()
@_set_stats_type(ofproto_v1_0.OFPST_VENDOR, OFPVendorStats)
@_set_msg_type(ofproto_v1_0.OFPT_STATS_REPLY)
class OFPVendorStatsReply(OFPStatsReply):
    _STATS_VENDORS = {}

    @staticmethod
    def register_stats_vendor(vendor):
        def _register_stats_vendor(cls):
            cls.cls_vendor = vendor
            OFPVendorStatsReply._STATS_VENDORS[cls.cls_vendor] = cls
            return cls
        return _register_stats_vendor

    def __init__(self, datapath):
        super(OFPVendorStatsReply, self).__init__(datapath)

    @classmethod
    def parser_stats(cls, datapath, version, msg_type, msg_len, xid,
                     buf):
        (type_,) = struct.unpack_from(
            ofproto_v1_0.OFP_VENDOR_STATS_MSG_PACK_STR, buffer(buf),
            ofproto_v1_0.OFP_STATS_MSG_SIZE)

        cls_ = cls._STATS_VENDORS.get(type_)

        if cls_ is None:
            msg = MsgBase.parser.__func__(
                cls, datapath, version, msg_type, msg_len, xid, buf)
            body_cls = cls.cls_stats_body_cls
            body = body_cls.parser(buf,
                                   ofproto_v1_0.OFP_STATS_MSG_SIZE)
            msg.body = body
            return msg

        return cls_.parser(
            datapath, version, msg_type, msg_len, xid, buf,
            ofproto_v1_0.OFP_VENDOR_STATS_MSG_SIZE)


@OFPVendorStatsReply.register_stats_vendor(ofproto_v1_0.NX_VENDOR_ID)
class NXStatsReply(OFPStatsReply):
    _NX_STATS_TYPES = {}

    @staticmethod
    def register_nx_stats_type(body_single_struct=False):
        def _register_nx_stats_type(cls):
            assert cls.cls_stats_type is not None
            assert cls.cls_stats_type not in \
                NXStatsReply._NX_STATS_TYPES
            assert cls.cls_stats_body_cls is not None
            cls.cls_body_single_struct = body_single_struct
            NXStatsReply._NX_STATS_TYPES[cls.cls_stats_type] = cls
            return cls
        return _register_nx_stats_type

    @classmethod
    def parser_stats_body(cls, buf, msg_len, offset):
        body_cls = cls.cls_stats_body_cls
        body = []
        while offset < msg_len:
            entry = body_cls.parser(buf, offset)
            body.append(entry)
            offset += entry.length

        if cls.cls_body_single_struct:
            return body[0]
        return body

    @classmethod
    def parser_stats(cls, datapath, version, msg_type, msg_len, xid,
                     buf, offset):
        msg = MsgBase.parser.__func__(
            cls, datapath, version, msg_type, msg_len, xid, buf)
        msg.body = msg.parser_stats_body(msg.buf, msg.msg_len, offset)

        return msg

    @classmethod
    def parser(cls, datapath, version, msg_type, msg_len, xid, buf,
               offset):
        (type_,) = struct.unpack_from(
            ofproto_v1_0.NX_STATS_MSG_PACK_STR, buffer(buf), offset)
        offset += ofproto_v1_0.NX_STATS_MSG0_SIZE

        cls_ = cls._NX_STATS_TYPES.get(type_)

        msg = cls_.parser_stats(
            datapath, version, msg_type, msg_len, xid, buf, offset)

        return msg


@NXStatsReply.register_nx_stats_type()
@_set_stats_type(ofproto_v1_0.NXST_FLOW, NXFlowStats)
class NXFlowStatsReply(NXStatsReply):
    def __init__(self, datapath):
        super(NXFlowStatsReply, self).__init__(datapath)


@NXStatsReply.register_nx_stats_type()
@_set_stats_type(ofproto_v1_0.NXST_AGGREGATE, NXAggregateStats)
class NXAggregateStatsReply(NXStatsReply):
    def __init__(self, datapath):
        super(NXAggregateStatsReply, self).__init__(datapath)


#
# controller-to-switch message
# serializer only
#


@_set_msg_reply(OFPSwitchFeatures)
@_set_msg_type(ofproto_v1_0.OFPT_FEATURES_REQUEST)
class OFPFeaturesRequest(MsgBase):
    def __init__(self, datapath):
        super(OFPFeaturesRequest, self).__init__(datapath)


@_set_msg_type(ofproto_v1_0.OFPT_GET_CONFIG_REQUEST)
class OFPGetConfigRequest(MsgBase):
    def __init__(self, datapath):
        super(OFPGetConfigRequest, self).__init__(datapath)


@_set_msg_type(ofproto_v1_0.OFPT_SET_CONFIG)
class OFPSetConfig(MsgBase):
    def __init__(self, datapath, flags=None, miss_send_len=None):
        super(OFPSetConfig, self).__init__(datapath)
        self.flags = flags
        self.miss_send_len = miss_send_len

    def _serialize_body(self):
        assert self.flags is not None
        assert self.miss_send_len is not None
        msg_pack_into(ofproto_v1_0.OFP_SWITCH_CONFIG_PACK_STR,
                      self.buf, ofproto_v1_0.OFP_HEADER_SIZE,
                      self.flags, self.miss_send_len)


@_set_msg_type(ofproto_v1_0.OFPT_PACKET_OUT)
class OFPPacketOut(MsgBase):
    def __init__(self, datapath, buffer_id=None, in_port=None, actions=None,
                 data=None):
        super(OFPPacketOut, self).__init__(datapath)
        self.buffer_id = buffer_id
        self.in_port = in_port
        self._actions_len = None
        self.actions = actions
        self.data = data

    def _serialize_body(self):
        assert self.buffer_id is not None
        assert self.in_port is not None
        assert self.actions is not None

        self._actions_len = 0
        offset = ofproto_v1_0.OFP_PACKET_OUT_SIZE
        for a in self.actions:
            a.serialize(self.buf, offset)
            offset += a.len
            self._actions_len += a.len

        if self.data is not None:
            assert self.buffer_id == 0xffffffff
            self.buf += self.data

        msg_pack_into(ofproto_v1_0.OFP_PACKET_OUT_PACK_STR,
                      self.buf, ofproto_v1_0.OFP_HEADER_SIZE,
                      self.buffer_id, self.in_port, self._actions_len)


@_set_msg_type(ofproto_v1_0.OFPT_FLOW_MOD)
class OFPFlowMod(MsgBase):
    def __init__(self, datapath, match, cookie, command,
                 idle_timeout=0, hard_timeout=0,
                 priority=ofproto_v1_0.OFP_DEFAULT_PRIORITY,
                 buffer_id=0xffffffff, out_port=ofproto_v1_0.OFPP_NONE,
                 flags=0, actions=None):
        if actions is None:
            actions = []
        super(OFPFlowMod, self).__init__(datapath)
        self.match = match
        self.cookie = cookie
        self.command = command
        self.idle_timeout = idle_timeout
        self.hard_timeout = hard_timeout
        self.priority = priority
        self.buffer_id = buffer_id
        self.out_port = out_port
        self.flags = flags
        self.actions = actions

    def _serialize_body(self):
        offset = ofproto_v1_0.OFP_HEADER_SIZE
        self.match.serialize(self.buf, offset)

        offset += ofproto_v1_0.OFP_MATCH_SIZE
        msg_pack_into(ofproto_v1_0.OFP_FLOW_MOD_PACK_STR0, self.buf, offset,
                      self.cookie, self.command,
                      self.idle_timeout, self.hard_timeout,
                      self.priority, self.buffer_id, self.out_port,
                      self.flags)

        offset = ofproto_v1_0.OFP_FLOW_MOD_SIZE
        if self.actions is not None:
            for a in self.actions:
                a.serialize(self.buf, offset)
                offset += a.len


@_set_msg_type(ofproto_v1_0.OFPT_PORT_MOD)
class OFPPortMod(MsgBase):

    _TYPE = {
        'ascii': [
            'hw_addr',
        ]
    }

    def __init__(self, datapath, port_no, hw_addr, config, mask, advertise):
        super(OFPPortMod, self).__init__(datapath)
        self.port_no = port_no
        self.hw_addr = hw_addr
        self.config = config
        self.mask = mask
        self.advertise = advertise

    def _serialize_body(self):
        msg_pack_into(ofproto_v1_0.OFP_PORT_MOD_PACK_STR,
                      self.buf, ofproto_v1_0.OFP_HEADER_SIZE,
                      self.port_no, addrconv.mac.text_to_bin(self.hw_addr),
                      self.config, self.mask, self.advertise)


@_set_msg_reply(OFPBarrierReply)
@_set_msg_type(ofproto_v1_0.OFPT_BARRIER_REQUEST)
class OFPBarrierRequest(MsgBase):
    def __init__(self, datapath):
        super(OFPBarrierRequest, self).__init__(datapath)


@_set_msg_reply(OFPQueueGetConfigReply)
@_set_msg_type(ofproto_v1_0.OFPT_QUEUE_GET_CONFIG_REQUEST)
class OFPQueueGetConfigRequest(MsgBase):
    def __init__(self, datapath, port):
        super(OFPQueueGetConfigRequest, self).__init__(datapath)
        self.port = port

    def _serialize_body(self):
        msg_pack_into(ofproto_v1_0.OFP_QUEUE_GET_CONFIG_REQUEST_PACK_STR,
                      self.buf, ofproto_v1_0.OFP_HEADER_SIZE, self.port)


class OFPStatsRequest(MsgBase):
    def __init__(self, datapath, flags):
        assert flags == 0       # none yet defined

        super(OFPStatsRequest, self).__init__(datapath)
        self.type = self.__class__.cls_stats_type
        self.flags = flags

    def _serialize_stats_body(self):
        pass

    def _serialize_body(self):
        msg_pack_into(ofproto_v1_0.OFP_STATS_MSG_PACK_STR,
                      self.buf, ofproto_v1_0.OFP_HEADER_SIZE,
                      self.type, self.flags)
        self._serialize_stats_body()


@_set_msg_reply(OFPDescStatsReply)
@_set_stats_type(ofproto_v1_0.OFPST_DESC, OFPDescStats)
@_set_msg_type(ofproto_v1_0.OFPT_STATS_REQUEST)
class OFPDescStatsRequest(OFPStatsRequest):
    def __init__(self, datapath, flags):
        super(OFPDescStatsRequest, self).__init__(datapath, flags)


class OFPFlowStatsRequestBase(OFPStatsRequest):
    def __init__(self, datapath, flags, match, table_id, out_port):
        super(OFPFlowStatsRequestBase, self).__init__(datapath, flags)
        self.match = match
        self.table_id = table_id
        self.out_port = out_port

    def _serialize_stats_body(self):
        offset = ofproto_v1_0.OFP_STATS_MSG_SIZE
        self.match.serialize(self.buf, offset)

        offset += ofproto_v1_0.OFP_MATCH_SIZE
        msg_pack_into(ofproto_v1_0.OFP_FLOW_STATS_REQUEST_ID_PORT_STR,
                      self.buf, offset, self.table_id, self.out_port)


@_set_msg_reply(OFPFlowStatsReply)
@_set_stats_type(ofproto_v1_0.OFPST_FLOW, OFPFlowStats)
@_set_msg_type(ofproto_v1_0.OFPT_STATS_REQUEST)
class OFPFlowStatsRequest(OFPFlowStatsRequestBase):
    def __init__(self, datapath, flags, match, table_id, out_port):
        super(OFPFlowStatsRequest, self).__init__(
            datapath, flags, match, table_id, out_port)


@_set_msg_reply(OFPAggregateStatsReply)
@_set_stats_type(ofproto_v1_0.OFPST_AGGREGATE, OFPAggregateStats)
@_set_msg_type(ofproto_v1_0.OFPT_STATS_REQUEST)
class OFPAggregateStatsRequest(OFPFlowStatsRequestBase):
    def __init__(self, datapath, flags, match, table_id, out_port):
        super(OFPAggregateStatsRequest, self).__init__(
            datapath, flags, match, table_id, out_port)


@_set_msg_reply(OFPTableStatsReply)
@_set_stats_type(ofproto_v1_0.OFPST_TABLE, OFPTableStats)
@_set_msg_type(ofproto_v1_0.OFPT_STATS_REQUEST)
class OFPTableStatsRequest(OFPStatsRequest):
    def __init__(self, datapath, flags):
        super(OFPTableStatsRequest, self).__init__(datapath, flags)


@_set_msg_reply(OFPPortStatsReply)
@_set_stats_type(ofproto_v1_0.OFPST_PORT, OFPPortStats)
@_set_msg_type(ofproto_v1_0.OFPT_STATS_REQUEST)
class OFPPortStatsRequest(OFPStatsRequest):
    def __init__(self, datapath, flags, port_no):
        super(OFPPortStatsRequest, self).__init__(datapath, flags)
        self.port_no = port_no

    def _serialize_stats_body(self):
        msg_pack_into(ofproto_v1_0.OFP_PORT_STATS_REQUEST_PACK_STR,
                      self.buf, ofproto_v1_0.OFP_STATS_MSG_SIZE, self.port_no)


@_set_msg_reply(OFPQueueStatsReply)
@_set_stats_type(ofproto_v1_0.OFPST_QUEUE, OFPQueueStats)
@_set_msg_type(ofproto_v1_0.OFPT_STATS_REQUEST)
class OFPQueueStatsRequest(OFPStatsRequest):
    def __init__(self, datapath, flags, port_no, queue_id):
        super(OFPQueueStatsRequest, self).__init__(datapath, flags)
        self.port_no = port_no
        self.queue_id = queue_id

    def _serialize_stats_body(self):
        msg_pack_into(ofproto_v1_0.OFP_QUEUE_STATS_REQUEST_PACK_STR,
                      self.buf, ofproto_v1_0.OFP_STATS_MSG_SIZE,
                      self.port_no, self.queue_id)


@_set_msg_reply(OFPVendorStatsReply)
@_set_stats_type(ofproto_v1_0.OFPST_VENDOR, OFPVendorStats)
@_set_msg_type(ofproto_v1_0.OFPT_STATS_REQUEST)
class OFPVendorStatsRequest(OFPStatsRequest):
    def __init__(self, datapath, flags, vendor, specific_data=None):
        super(OFPVendorStatsRequest, self).__init__(datapath, flags)
        self.vendor = vendor
        self.specific_data = specific_data

    def _serialize_vendor_stats(self):
        self.buf += self.specific_data

    def _serialize_stats_body(self):
        msg_pack_into(ofproto_v1_0.OFP_VENDOR_STATS_MSG_PACK_STR,
                      self.buf, ofproto_v1_0.OFP_STATS_MSG_SIZE,
                      self.vendor)
        self._serialize_vendor_stats()


class NXStatsRequest(OFPVendorStatsRequest):
    def __init__(self, datapath, flags, subtype):
        super(NXStatsRequest, self).__init__(datapath, flags,
                                             ofproto_v1_0.NX_VENDOR_ID)
        self.subtype = subtype

    def _serialize_vendor_stats_body(self):
        pass

    def _serialize_vendor_stats(self):
        msg_pack_into(ofproto_v1_0.NX_STATS_MSG_PACK_STR, self.buf,
                      ofproto_v1_0.OFP_VENDOR_STATS_MSG_SIZE,
                      self.subtype)
        self._serialize_vendor_stats_body()


class NXFlowStatsRequest(NXStatsRequest):
    def __init__(self, datapath, flags, out_port, table_id, rule=None):
        super(NXFlowStatsRequest, self).__init__(datapath, flags,
                                                 ofproto_v1_0.NXST_FLOW)
        self.out_port = out_port
        self.table_id = table_id
        self.rule = rule
        self.match_len = 0

    def _serialize_vendor_stats_body(self):
        if self.rule is not None:
            offset = ofproto_v1_0.NX_STATS_MSG_SIZE + \
                ofproto_v1_0.NX_FLOW_STATS_REQUEST_SIZE
            self.match_len = nx_match.serialize_nxm_match(
                self.rule, self.buf, offset)

        msg_pack_into(
            ofproto_v1_0.NX_FLOW_STATS_REQUEST_PACK_STR,
            self.buf, ofproto_v1_0.NX_STATS_MSG_SIZE, self.out_port,
            self.match_len, self.table_id)


class NXAggregateStatsRequest(NXStatsRequest):
    def __init__(self, datapath, flags, out_port, table_id, rule=None):
        super(NXAggregateStatsRequest, self).__init__(
            datapath, flags, ofproto_v1_0.NXST_AGGREGATE)
        self.out_port = out_port
        self.table_id = table_id
        self.rule = rule
        self.match_len = 0

    def _serialize_vendor_stats_body(self):
        if self.rule is not None:
            offset = ofproto_v1_0.NX_STATS_MSG_SIZE + \
                ofproto_v1_0.NX_AGGREGATE_STATS_REQUEST_SIZE
            self.match_len = nx_match.serialize_nxm_match(
                self.rule, self.buf, offset)

        msg_pack_into(
            ofproto_v1_0.NX_AGGREGATE_STATS_REQUEST_PACK_STR,
            self.buf, ofproto_v1_0.NX_STATS_MSG_SIZE, self.out_port,
            self.match_len, self.table_id)

########NEW FILE########
__FILENAME__ = ofproto_v1_2
# Copyright (C) 2012 Nippon Telegraph and Telephone Corporation.
# Copyright (C) 2012 Isaku Yamahata <yamahata at valinux co jp>
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from ryu.ofproto import oxm_fields

from struct import calcsize

# struct ofp_header
OFP_HEADER_PACK_STR = '!BBHI'
OFP_HEADER_SIZE = 8
assert calcsize(OFP_HEADER_PACK_STR) == OFP_HEADER_SIZE

# enum ofp_type
OFPT_HELLO = 0    # Symmetric message
OFPT_ERROR = 1    # Symmetric message
OFPT_ECHO_REQUEST = 2    # Symmetric message
OFPT_ECHO_REPLY = 3    # Symmetric message
OFPT_EXPERIMENTER = 4    # Symmetric message
# Immutable message
OFPT_FEATURES_REQUEST = 5    # Controller/switch message
OFPT_FEATURES_REPLY = 6    # Controller/switch message
OFPT_GET_CONFIG_REQUEST = 7    # Controller/switch message
OFPT_GET_CONFIG_REPLY = 8    # Controller/switch message
OFPT_SET_CONFIG = 9    # Controller/switch message

OFPT_PACKET_IN = 10    # Async message
OFPT_FLOW_REMOVED = 11    # Async message
OFPT_PORT_STATUS = 12    # Async message

OFPT_PACKET_OUT = 13    # Controller/switch message
OFPT_FLOW_MOD = 14    # Controller/switch message
OFPT_GROUP_MOD = 15    # Controller/switch message
OFPT_PORT_MOD = 16    # Controller/switch message
OFPT_TABLE_MOD = 17    # Controller/switch message

OFPT_STATS_REQUEST = 18    # Controller/switch message
OFPT_STATS_REPLY = 19    # Controller/switch message

OFPT_BARRIER_REQUEST = 20    # Controller/switch message
OFPT_BARRIER_REPLY = 21    # Controller/switch message

OFPT_QUEUE_GET_CONFIG_REQUEST = 22    # Controller/switch message
OFPT_QUEUE_GET_CONFIG_REPLY = 23    # Controller/switch message

OFPT_ROLE_REQUEST = 24    # Controller/switch message
OFPT_ROLE_REPLY = 25    # Controller/switch message

# struct ofp_port
OFP_MAX_PORT_NAME_LEN = 16
OFP_ETH_ALEN = 6
OFP_ETH_ALEN_STR = str(OFP_ETH_ALEN)
_OFP_PORT_PACK_STR = 'I4x' + OFP_ETH_ALEN_STR + 's' + '2x' + \
                     str(OFP_MAX_PORT_NAME_LEN) + 's' + 'IIIIIIII'
OFP_PORT_PACK_STR = '!' + _OFP_PORT_PACK_STR
OFP_PORT_SIZE = 64
assert calcsize(OFP_PORT_PACK_STR) == OFP_PORT_SIZE

# enum ofp_port_config
OFPPC_PORT_DOWN = 1 << 0    # Port is administratively down.
OFPPC_NO_RECV = 1 << 2        # Drop all packets recieved by port.
OFPPC_NO_FWD = 1 << 5        # Drop packets forwarded to port.
OFPPC_NO_PACKET_IN = 1 << 6    # Do not send packet-in msgs for port.

# enum ofp_port_state
OFPPS_LINK_DOWN = 1 << 0    # No physical link present.
OFPPS_BLOCKED = 1 << 1        # Port is blocked.
OFPPS_LIVE = 1 << 2        # Live for Fast Failover Group.

# enum ofp_port_no
OFPP_MAX = 0xffffff00
OFPP_IN_PORT = 0xfffffff8       # Send the packet out the input port. This
                                # virtual port must be explicitly used
                                # in order to send back out of the input
                                # port.
OFPP_TABLE = 0xfffffff9         # Perform actions in flow table.
                                # NB: This can only be the destination
                                # port for packet-out messages.
OFPP_NORMAL = 0xfffffffa        # Process with normal L2/L3 switching.
OFPP_FLOOD = 0xfffffffb         # All physical ports except input port and
                                # those disabled by STP.
OFPP_ALL = 0xfffffffc           # All physical ports except input port.
OFPP_CONTROLLER = 0xfffffffd    # Send to controller.
OFPP_LOCAL = 0xfffffffe         # Local openflow "port".
OFPP_ANY = 0xffffffff 	        # Not associated with a physical port.

# All ones is used to indicate all queues in a port (for stats retrieval).
OFPQ_ALL = 0xffffffff

# enum ofp_port_features
OFPPF_10MB_HD = 1 << 0    # 10 Mb half-duplex rate support.
OFPPF_10MB_FD = 1 << 1    # 10 Mb full-duplex rate support.
OFPPF_100MB_HD = 1 << 2    # 100 Mb half-duplex rate support.
OFPPF_100MB_FD = 1 << 3    # 100 Mb full-duplex rate support.
OFPPF_1GB_HD = 1 << 4    # 1 Gb half-duplex rate support.
OFPPF_1GB_FD = 1 << 5    # 1 Gb full-duplex rate support.
OFPPF_10GB_FD = 1 << 6    # 10 Gb full-duplex rate support.
OFPPF_40GB_FD = 1 << 7    # 40 Gb full-duplex rate support.
OFPPF_100GB_FD = 1 << 8    # 100 Gb full-duplex rate support.
OFPPF_1TB_FD = 1 << 9    # 1 Tb full-duplex rate support.
OFPPF_OTHER = 1 << 10    # Other rate, not in the list.
OFPPF_COPPER = 1 << 11    # Copper medium.
OFPPF_FIBER = 1 << 12    # Fiber medium.
OFPPF_AUTONEG = 1 << 13    # Auto-negotiation.
OFPPF_PAUSE = 1 << 14    # Pause.
OFPPF_PAUSE_ASYM = 1 << 15    # Asymmetric pause.

# struct ofp_packet_queue
OFP_PACKET_QUEUE_PACK_STR = '!IIH6x'
OFP_PACKET_QUEUE_SIZE = 16
assert calcsize(OFP_PACKET_QUEUE_PACK_STR) == OFP_PACKET_QUEUE_SIZE

# enum ofp_queue_properties
OFPQT_MIN_RATE = 1        # Minimum datarate guaranteed.
OFPQT_MAX_RATE = 2        # Maximum datarate.
OFPQT_EXPERIMENTER = 0xffff     # Experimenter defined property.

# struct ofp_queue_prop_header
OFP_QUEUE_PROP_HEADER_PACK_STR = '!HH4x'
OFP_QUEUE_PROP_HEADER_SIZE = 8
assert calcsize(OFP_QUEUE_PROP_HEADER_PACK_STR) == OFP_QUEUE_PROP_HEADER_SIZE

# struct ofp_queue_prop_min_rate
OFP_QUEUE_PROP_MIN_RATE_PACK_STR = '!H6x'
OFP_QUEUE_PROP_MIN_RATE_SIZE = 16
assert (calcsize(OFP_QUEUE_PROP_MIN_RATE_PACK_STR) +
        OFP_QUEUE_PROP_HEADER_SIZE) == OFP_QUEUE_PROP_MIN_RATE_SIZE

# struct ofp_queue_prop_max_rate
OFP_QUEUE_PROP_MAX_RATE_PACK_STR = '!H6x'
OFP_QUEUE_PROP_MAX_RATE_SIZE = 16
assert (calcsize(OFP_QUEUE_PROP_MAX_RATE_PACK_STR) +
        OFP_QUEUE_PROP_HEADER_SIZE) == OFP_QUEUE_PROP_MAX_RATE_SIZE

# struct ofp_queue_prop_experimenter
OFP_QUEUE_PROP_EXPERIMENTER_PACK_STR = '!I4x'
OFP_QUEUE_PROP_EXPERIMENTER_SIZE = 16
assert (calcsize(OFP_QUEUE_PROP_EXPERIMENTER_PACK_STR) +
        OFP_QUEUE_PROP_HEADER_SIZE) == OFP_QUEUE_PROP_EXPERIMENTER_SIZE

# struct ofp_match
_OFP_MATCH_PACK_STR = 'HHBBBB'
OFP_MATCH_PACK_STR = '!' + _OFP_MATCH_PACK_STR
OFP_MATCH_SIZE = 8
assert calcsize(OFP_MATCH_PACK_STR) == OFP_MATCH_SIZE

# enum ofp_match_type
OFPMT_STANDARD = 0  # Deprecated
OFPMT_OXM = 1  # OpenFlow Extensible Match

# enum ofp_oxm_class
OFPXMC_NXM_0 = 0x0000  # Backward compatibility with NXM
OFPXMC_NXM_1 = 0x0001  # Backward compatibility with NXM
OFPXMC_OPENFLOW_BASIC = 0x8000  # Basic class for OpenFlow
OFPXMC_EXPERIMENTER = 0xFFFF  # Experimenter class

# enum ofp_vlan_id
OFPVID_PRESENT = 0x1000  # bit that indicate that a VLAN id is set.
OFPVID_NONE = 0x0000  # No VLAN id was set.

# struct ofp_oxm_experimenter_header
OFP_OXM_EXPERIMENTER_HEADER_PACK_STR = '!II'
OFP_OXM_EXPERIMENTER_HEADER_SIZE = 8
assert (calcsize(OFP_OXM_EXPERIMENTER_HEADER_PACK_STR) ==
        OFP_OXM_EXPERIMENTER_HEADER_SIZE)

# enum ofp_instruction_type
OFPIT_GOTO_TABLE = 1  # Setup the next table in the lookup pipeline.
OFPIT_WRITE_METADATA = 2  # Setup the metadata field for use later in
                          # pipeline.
OFPIT_WRITE_ACTIONS = 3  # Write the action(s) onto the datapath
                         # action set
OFPIT_APPLY_ACTIONS = 4  # Applies the action(s) immediately
OFPIT_CLEAR_ACTIONS = 5  # Clears all actions from the datapath action
                         # set
OFPIT_EXPERIMENTER = 0xFFFF   # Experimenter instruction

# struct ofp_instruction_goto_table
OFP_INSTRUCTION_GOTO_TABLE_PACK_STR = '!HHB3x'
OFP_INSTRUCTION_GOTO_TABLE_SIZE = 8
assert (calcsize(OFP_INSTRUCTION_GOTO_TABLE_PACK_STR) ==
        OFP_INSTRUCTION_GOTO_TABLE_SIZE)

# struct ofp_instruction_write_metadata
OFP_INSTRUCTION_WRITE_METADATA_PACK_STR = '!HH4xQQ'
OFP_INSTRUCTION_WRITE_METADATA_SIZE = 24
assert (calcsize(OFP_INSTRUCTION_WRITE_METADATA_PACK_STR) ==
        OFP_INSTRUCTION_WRITE_METADATA_SIZE)

# struct ofp_instaruction_actions
OFP_INSTRUCTION_ACTIONS_PACK_STR = '!HH4x'
OFP_INSTRUCTION_ACTIONS_SIZE = 8
assert (calcsize(OFP_INSTRUCTION_ACTIONS_PACK_STR) ==
        OFP_INSTRUCTION_ACTIONS_SIZE)

# enum ofp_action_type
OFPAT_OUTPUT = 0    # Output to switch port.
OFPAT_COPY_TTL_OUT = 11  # Copy TTL "outwards" -- from
                         # next-to-outermost to outermost
OFPAT_COPY_TTL_IN = 12  # Copy TTL "inwards" -- from outermost to
                        # next-to-outermost
OFPAT_SET_MPLS_TTL = 15  # MPLS TTL.
OFPAT_DEC_MPLS_TTL = 16  # Decrement MPLS TTL
OFPAT_PUSH_VLAN = 17  # Push a new VLAN tag
OFPAT_POP_VLAN = 18  # Pop the outer VLAN tag
OFPAT_PUSH_MPLS = 19  # Push a new MPLS tag
OFPAT_POP_MPLS = 20  # Pop the outer MPLS tag
OFPAT_SET_QUEUE = 21  # Set queue id when outputting to a port
OFPAT_GROUP = 22  # Apply group
OFPAT_SET_NW_TTL = 23  # IP TTL.
OFPAT_DEC_NW_TTL = 24  # Decrement IP TTL.
OFPAT_SET_FIELD = 25  # Set a header field using OXM TLV format.
OFPAT_EXPERIMENTER = 0xffff

# struct ofp_action_header
OFP_ACTION_HEADER_PACK_STR = '!HH4x'
OFP_ACTION_HEADER_SIZE = 8
assert calcsize(OFP_ACTION_HEADER_PACK_STR) == OFP_ACTION_HEADER_SIZE

# struct ofp_action_output
OFP_ACTION_OUTPUT_PACK_STR = '!HHIH6x'
OFP_ACTION_OUTPUT_SIZE = 16
assert calcsize(OFP_ACTION_OUTPUT_PACK_STR) == OFP_ACTION_OUTPUT_SIZE

# enum ofp_controller_max_len
OFPCML_MAX = 0xffe5  # maximum max_len value which can be used to
                     # request a specific byte length.
OFPCML_NO_BUFFER = 0xffff  # indicates that no buffering should be
                           # applied and the whole packet is to be
                           # sent to the controller.

# struct ofp_action_group
OFP_ACTION_GROUP_PACK_STR = '!HHI'
OFP_ACTION_GROUP_SIZE = 8
assert calcsize(OFP_ACTION_GROUP_PACK_STR) == OFP_ACTION_GROUP_SIZE

# struct ofp_action_set_queue
OFP_ACTION_SET_QUEUE_PACK_STR = '!HHI'
OFP_ACTION_SET_QUEUE_SIZE = 8
assert calcsize(OFP_ACTION_SET_QUEUE_PACK_STR) == OFP_ACTION_SET_QUEUE_SIZE

# struct ofp_aciton_mpls_ttl
OFP_ACTION_MPLS_TTL_PACK_STR = '!HHB3x'
OFP_ACTION_MPLS_TTL_SIZE = 8
assert calcsize(OFP_ACTION_MPLS_TTL_PACK_STR) == OFP_ACTION_MPLS_TTL_SIZE

# struct ofp_action_nw_ttl
OFP_ACTION_NW_TTL_PACK_STR = '!HHB3x'
OFP_ACTION_NW_TTL_SIZE = 8
assert calcsize(OFP_ACTION_NW_TTL_PACK_STR) == OFP_ACTION_NW_TTL_SIZE

# struct ofp_action_push
OFP_ACTION_PUSH_PACK_STR = '!HHH2x'
OFP_ACTION_PUSH_SIZE = 8
assert calcsize(OFP_ACTION_PUSH_PACK_STR) == OFP_ACTION_PUSH_SIZE

# struct ofp_action_pop_mpls
OFP_ACTION_POP_MPLS_PACK_STR = '!HHH2x'
OFP_ACTION_POP_MPLS_SIZE = 8
assert calcsize(OFP_ACTION_POP_MPLS_PACK_STR) == OFP_ACTION_POP_MPLS_SIZE

# struct ofp_action_set_field
OFP_ACTION_SET_FIELD_PACK_STR = '!HH4B'
OFP_ACTION_SET_FIELD_SIZE = 8
assert calcsize(OFP_ACTION_SET_FIELD_PACK_STR) == OFP_ACTION_SET_FIELD_SIZE

# struct ofp_action_experimenter_header
OFP_ACTION_EXPERIMENTER_HEADER_PACK_STR = '!HHI'
OFP_ACTION_EXPERIMENTER_HEADER_SIZE = 8
assert (calcsize(OFP_ACTION_EXPERIMENTER_HEADER_PACK_STR) ==
        OFP_ACTION_EXPERIMENTER_HEADER_SIZE)

# struct ofp_switch_feature
OFP_SWITCH_FEATURES_PACK_STR = '!QIB3xII'
OFP_SWITCH_FEATURES_SIZE = 32
assert (calcsize(OFP_SWITCH_FEATURES_PACK_STR) + OFP_HEADER_SIZE ==
        OFP_SWITCH_FEATURES_SIZE)

# enum ofp_capabilities
OFPC_FLOW_STATS = 1 << 0    # Flow statistics.
OFPC_TABLE_STATS = 1 << 1    # Table statistics.
OFPC_PORT_STATS = 1 << 2    # Port statistics.
OFPC_GROUP_STATS = 1 << 3    # Group statistics.
OFPC_IP_REASM = 1 << 5        # Can reassemble IP fragments.
OFPC_QUEUE_STATS = 1 << 6    # Queue statistics.
OFPC_PORT_BLOCKED = 1 << 8    # Switch will block looping ports.

# struct ofp_switch_config
OFP_SWITCH_CONFIG_PACK_STR = '!HH'
OFP_SWITCH_CONFIG_SIZE = 12
assert (calcsize(OFP_SWITCH_CONFIG_PACK_STR) + OFP_HEADER_SIZE ==
        OFP_SWITCH_CONFIG_SIZE)

# enum ofp_config_flags
OFPC_FRAG_NORMAL = 0    # No special handling for fragments.
OFPC_FRAG_DROP = 1      # Drop fragments.
OFPC_FRAG_REASM = 2     # Reassemble (only if OFPC_IP_REASM set).
OFPC_FRAG_MASK = 3
OFPC_INVALID_TTL_TO_CONTROLLER = 1 << 2  # Send packets with invalid
                                         # TTL to the controller.

# enum ofp_table
OFPTT_MAX = 0xfe
OFPTT_ALL = 0xff

# struct ofp_table_mod
OFP_TABLE_MOD_PACK_STR = '!B3xI'
OFP_TABLE_MOD_SIZE = 16
assert (calcsize(OFP_TABLE_MOD_PACK_STR) + OFP_HEADER_SIZE ==
        OFP_TABLE_MOD_SIZE)

# enum ofp_table_config
OFPTC_TABLE_MISS_CONTROLLER = 0
OFPTC_TABLE_MISS_CONTINUE = 1 << 0
OFPTC_TABLE_MISS_DROP = 1 << 1
OFPTC_TABLE_MISS_MASK = 3

# struct ofp_flow_mod
_OFP_FLOW_MOD_PACK_STR0 = 'QQBBHHHIIIH2x'
OFP_FLOW_MOD_PACK_STR = '!' + _OFP_FLOW_MOD_PACK_STR0 + _OFP_MATCH_PACK_STR
OFP_FLOW_MOD_PACK_STR0 = '!' + _OFP_FLOW_MOD_PACK_STR0
OFP_FLOW_MOD_SIZE = 56
assert (calcsize(OFP_FLOW_MOD_PACK_STR) + OFP_HEADER_SIZE == OFP_FLOW_MOD_SIZE)

# enum ofp_flow_mod_command
OFPFC_ADD = 0    # New flow.
OFPFC_MODIFY = 1    # Modify all matching flows.
OFPFC_MODIFY_STRICT = 2    # Modify entry strictly matching wildcards
OFPFC_DELETE = 3    # Delete all matching flows.
OFPFC_DELETE_STRICT = 4    # Strictly match wildcards and priority.

# enum ofp_flow_mod_flags
OFPFF_SEND_FLOW_REM = 1 << 0    # Send flow removed message when flow
                                # expires or is deleted.
OFPFF_CHECK_OVERLAP = 1 << 1    # Check for overlapping entries first.
OFPFF_RESET_COUNT = 1 << 2    # Reset flow packet and byte counts.

# struct ofp_group_mod
OFP_GROUP_MOD_PACK_STR = '!HBxI'
OFP_GROUP_MOD_SIZE = 16
assert (calcsize(OFP_GROUP_MOD_PACK_STR) + OFP_HEADER_SIZE ==
        OFP_GROUP_MOD_SIZE)

# enum ofp_group
OFPG_MAX = 0xffffff00
OFPG_ALL = 0xfffffffc
OFPG_ANY = 0xffffffff

# enum ofp_group_mod_command
OFPGC_ADD = 0  # New group.
OFPGC_MODIFY = 1  # Modify all matching groups.
OFPGC_DELETE = 2  # Deletes all matching groups.

# enum ofp_group_type
OFPGT_ALL = 0  # All (multicast/broadcast) group.
OFPGT_SELECT = 1  # Select group.
OFPGT_INDIRECT = 2  # Indirect group.
OFPGT_FF = 3  # Fast failover group.

# struct ofp_bucket
OFP_BUCKET_PACK_STR = '!HHII4x'
OFP_BUCKET_SIZE = 16
assert calcsize(OFP_BUCKET_PACK_STR) == OFP_BUCKET_SIZE

# struct ofp_port_mod
OFP_PORT_MOD_PACK_STR = '!I4x' + OFP_ETH_ALEN_STR + 's' + '2xIII4x'
OFP_PORT_MOD_SIZE = 40
assert calcsize(OFP_PORT_MOD_PACK_STR) + OFP_HEADER_SIZE == OFP_PORT_MOD_SIZE

# sturct ofp_stats_request
OFP_STATS_REQUEST_PACK_STR = '!HH4x'
OFP_STATS_REQUEST_SIZE = 16
assert (calcsize(OFP_STATS_REQUEST_PACK_STR) + OFP_HEADER_SIZE ==
        OFP_STATS_REQUEST_SIZE)

# enum ofp_stats_reply_flags
OFPSF_REPLY_MORE = 1 << 0       # More replies to follow.

# struct ofp_stats_reply
OFP_STATS_REPLY_PACK_STR = '!HH4x'
OFP_STATS_REPLY_SIZE = 16
assert (calcsize(OFP_STATS_REPLY_PACK_STR) + OFP_HEADER_SIZE ==
        OFP_STATS_REPLY_SIZE)

# enum ofp_stats_types
OFPST_DESC = 0
OFPST_FLOW = 1
OFPST_AGGREGATE = 2
OFPST_TABLE = 3
OFPST_PORT = 4
OFPST_QUEUE = 5
OFPST_GROUP = 6
OFPST_GROUP_DESC = 7
OFPST_GROUP_FEATURES = 8
OFPST_EXPERIMENTER = 0xffff

# struct ofp_desc_stats
DESC_STR_LEN = 256
DESC_STR_LEN_STR = str(DESC_STR_LEN)
SERIAL_NUM_LEN = 32
SERIAL_NUM_LEN_STR = str(SERIAL_NUM_LEN)
OFP_DESC_STATS_PACK_STR = '!' + \
                          DESC_STR_LEN_STR + 's' + \
                          DESC_STR_LEN_STR + 's' + \
                          DESC_STR_LEN_STR + 's' + \
                          SERIAL_NUM_LEN_STR + 's' + \
                          DESC_STR_LEN_STR + 's'
OFP_DESC_STATS_SIZE = 1056
assert calcsize(OFP_DESC_STATS_PACK_STR) == OFP_DESC_STATS_SIZE

# struct ofp_flow_stats_request
OFP_FLOW_STATS_REQUEST_PACK_STR = '!B3xII4xQQ'
OFP_FLOW_STATS_REQUEST_SIZE = 40
assert (calcsize(OFP_FLOW_STATS_REQUEST_PACK_STR) + OFP_MATCH_SIZE ==
        OFP_FLOW_STATS_REQUEST_SIZE)

# struct ofp_flow_stats
OFP_FLOW_STATS_PACK_STR = '!HBxIIHHH6xQQQ'
OFP_FLOW_STATS_SIZE = 56
assert (calcsize(OFP_FLOW_STATS_PACK_STR) + OFP_MATCH_SIZE ==
        OFP_FLOW_STATS_SIZE)

# struct ofp_aggregate_stats_request
OFP_AGGREGATE_STATS_REQUEST_PACK_STR = '!B3xII4xQQ'
OFP_AGGREGATE_STATS_REQUEST_SIZE = 40
assert (calcsize(OFP_AGGREGATE_STATS_REQUEST_PACK_STR) + OFP_MATCH_SIZE ==
        OFP_AGGREGATE_STATS_REQUEST_SIZE)

# struct ofp_aggregate_stats_reply
OFP_AGGREGATE_STATS_REPLY_PACK_STR = '!QQI4x'
OFP_AGGREGATE_STATS_REPLY_SIZE = 24
assert (calcsize(OFP_AGGREGATE_STATS_REPLY_PACK_STR) ==
        OFP_AGGREGATE_STATS_REPLY_SIZE)

# sturct ofp_table_stats
OFP_TABLE_STATS_SIZE = 128
OFP_MAX_TABLE_NAME_LEN = 32
OFP_MAX_TABLE_NAME_LEN_STR = str(OFP_MAX_TABLE_NAME_LEN)
OFP_TABLE_STATS_PACK_STR = '!B7x' + OFP_MAX_TABLE_NAME_LEN_STR + \
                           'sQQIIQQQQIIIIQQ'
assert calcsize(OFP_TABLE_STATS_PACK_STR) == OFP_TABLE_STATS_SIZE

# struct ofp_port_stats_request
OFP_PORT_STATS_REQUEST_PACK_STR = '!I4x'
OFP_PORT_STATS_REQUEST_SIZE = 8
assert calcsize(OFP_PORT_STATS_REQUEST_PACK_STR) == OFP_PORT_STATS_REQUEST_SIZE

# struct ofp_port_stats
OFP_PORT_STATS_PACK_STR = '!I4xQQQQQQQQQQQQ'
OFP_PORT_STATS_SIZE = 104
assert calcsize(OFP_PORT_STATS_PACK_STR) == OFP_PORT_STATS_SIZE

# struct ofp_queue_stats_request
OFP_QUEUE_STATS_REQUEST_PACK_STR = '!II'
OFP_QUEUE_STATS_REQUEST_SIZE = 8
assert (calcsize(OFP_QUEUE_STATS_REQUEST_PACK_STR) ==
        OFP_QUEUE_STATS_REQUEST_SIZE)

# struct ofp_queue_stats
OFP_QUEUE_STATS_PACK_STR = '!IIQQQ'
OFP_QUEUE_STATS_SIZE = 32
assert calcsize(OFP_QUEUE_STATS_PACK_STR) == OFP_QUEUE_STATS_SIZE

# struct ofp_group_stats_request
OFP_GROUP_STATS_REQUEST_PACK_STR = '!I4x'
OFP_GROUP_STATS_REQUEST_SIZE = 8
assert (calcsize(OFP_GROUP_STATS_REQUEST_PACK_STR) ==
        OFP_GROUP_STATS_REQUEST_SIZE)

# struct ofp_group_stats
OFP_GROUP_STATS_PACK_STR = '!H2xII4xQQ'
OFP_GROUP_STATS_SIZE = 32
assert calcsize(OFP_GROUP_STATS_PACK_STR) == OFP_GROUP_STATS_SIZE

# struct ofp_bucket_counter
OFP_BUCKET_COUNTER_PACK_STR = '!QQ'
OFP_BUCKET_COUNTER_SIZE = 16
assert calcsize(OFP_BUCKET_COUNTER_PACK_STR) == OFP_BUCKET_COUNTER_SIZE

# struct ofp_group_desc_stats
OFP_GROUP_DESC_STATS_PACK_STR = '!HBxI'
OFP_GROUP_DESC_STATS_SIZE = 8
assert calcsize(OFP_GROUP_DESC_STATS_PACK_STR) == OFP_GROUP_DESC_STATS_SIZE

# struct ofp_group_features_stats
OFP_GROUP_FEATURES_STATS_PACK_STR = '!II4I4I'
OFP_GROUP_FEATURES_STATS_SIZE = 40
assert (calcsize(OFP_GROUP_FEATURES_STATS_PACK_STR) ==
        OFP_GROUP_FEATURES_STATS_SIZE)

# enmu ofp_group_capabilities
OFPGFC_SELECT_WEIGHT = 1 << 0  # Support weight for select groups.
OFPGFC_SELECT_LIVENESS = 1 << 1  # Support liveness for select groups.
OFPGFC_CHAINING = 1 << 2  # Support chaining groups.
OFPGFC_CHAINING_CHECKS = 1 << 3  # Check chaining for loops and delete

# struct ofp_experimenter_stats_header
OFP_EXPERIMENTER_STATS_HEADER_PACK_STR = '!II'
OFP_EXPERIMENTER_STATS_HEADER_SIZE = 8
assert (calcsize(OFP_EXPERIMENTER_STATS_HEADER_PACK_STR) ==
        OFP_EXPERIMENTER_STATS_HEADER_SIZE)

# struct opf_queue_get_config_request
OFP_QUEUE_GET_CONFIG_REQUEST_PACK_STR = '!I4x'
OFP_QUEUE_GET_CONFIG_REQUEST_SIZE = 16
assert (calcsize(OFP_QUEUE_GET_CONFIG_REQUEST_PACK_STR) + OFP_HEADER_SIZE ==
        OFP_QUEUE_GET_CONFIG_REQUEST_SIZE)

# struct ofp_queue_get_config_reply
OFP_QUEUE_GET_CONFIG_REPLY_PACK_STR = '!I4x'
OFP_QUEUE_GET_CONFIG_REPLY_SIZE = 16
assert (calcsize(OFP_QUEUE_GET_CONFIG_REPLY_PACK_STR) + OFP_HEADER_SIZE ==
        OFP_QUEUE_GET_CONFIG_REPLY_SIZE)

# struct ofp_packet_out
OFP_PACKET_OUT_PACK_STR = '!IIH6x'
OFP_PACKET_OUT_SIZE = 24
assert (calcsize(OFP_PACKET_OUT_PACK_STR) + OFP_HEADER_SIZE ==
        OFP_PACKET_OUT_SIZE)

# struct ofp_role_request
OFP_ROLE_REQUEST_PACK_STR = '!I4xQ'
OFP_ROLE_REQUEST_SIZE = 24
assert (calcsize(OFP_ROLE_REQUEST_PACK_STR) + OFP_HEADER_SIZE ==
        OFP_ROLE_REQUEST_SIZE)

# enum ofp_controller_role
OFPCR_ROLE_NOCHANGE = 0  # Don't change current role.
OFPCR_ROLE_EQUAL = 1  # Default role, full access.
OFPCR_ROLE_MASTER = 2  # Full access, at most one master.
OFPCR_ROLE_SLAVE = 3  # Read-only access.

# struct ofp_packet_in
OFP_PACKET_IN_PACK_STR = '!IHBB'
OFP_PACKET_IN_SIZE = 24
assert (calcsize(OFP_PACKET_IN_PACK_STR) + OFP_MATCH_SIZE + OFP_HEADER_SIZE ==
        OFP_PACKET_IN_SIZE)

# enum ofp_packet_in_reason
OFPR_NO_MATCH = 0    # No matching flow.
OFPR_ACTION = 1        # Action explicitly output to controller.
OFPR_INVALID_TTL = 2    # Packet has invalid TTL.

# struct ofp_flow_removed
_OFP_FLOW_REMOVED_PACK_STR0 = 'QHBBIIHHQQ'
OFP_FLOW_REMOVED_PACK_STR = '!' + _OFP_FLOW_REMOVED_PACK_STR0 + \
                            _OFP_MATCH_PACK_STR
OFP_FLOW_REMOVED_PACK_STR0 = '!' + _OFP_FLOW_REMOVED_PACK_STR0
OFP_FLOW_REMOVED_SIZE = 56
assert (calcsize(OFP_FLOW_REMOVED_PACK_STR) + OFP_HEADER_SIZE ==
        OFP_FLOW_REMOVED_SIZE)

# enum ofp_flow_removed_reason
OFPRR_IDLE_TIMEOUT = 0    # Flow idle time exceeded idle_timeout.
OFPRR_HARD_TIMEOUT = 1    # Time exceeded hard_timeout.
OFPRR_DELETE = 2    # Evicted by a DELETE flow mod.
OFPRR_GROUP_DELETE = 3  # Group was removed.

# struct ofp_port_status
OFP_PORT_STATUS_PACK_STR = '!B7x' + _OFP_PORT_PACK_STR
OFP_PORT_STATUS_DESC_OFFSET = OFP_HEADER_SIZE + 8
OFP_PORT_STATUS_SIZE = 80
assert (calcsize(OFP_PORT_STATUS_PACK_STR) + OFP_HEADER_SIZE ==
        OFP_PORT_STATUS_SIZE)

# enum ofp_port_reason
OFPPR_ADD = 0    # The port was added.
OFPPR_DELETE = 1    # The port was removed.
OFPPR_MODIFY = 2    # Some attribute of the port has changed.

# struct ofp_error_msg
OFP_ERROR_MSG_PACK_STR = '!HH'
OFP_ERROR_MSG_SIZE = 12
assert calcsize(OFP_ERROR_MSG_PACK_STR) + OFP_HEADER_SIZE == OFP_ERROR_MSG_SIZE

# enum ofp_error_type
OFPET_HELLO_FAILED = 0        # Hello protocol failed.
OFPET_BAD_REQUEST = 1        # Request was not understood.
OFPET_BAD_ACTION = 2        # Error in action description.
OFPET_BAD_INSTRUCTION = 3    # Error in instruction list.
OFPET_BAD_MATCH = 4        # Error in match.
OFPET_FLOW_MOD_FAILED = 5    # Problem modifying flow entry.
OFPET_GROUP_MOD_FAILED = 6    # Problem modifying group entry.
OFPET_PORT_MOD_FAILED = 7    # OFPT_PORT_MOD failed.
OFPET_TABLE_MOD_FAILED = 8    # Table mod request failed.
OFPET_QUEUE_OP_FAILED = 9    # Queue operation failed.
OFPET_SWITCH_CONFIG_FAILED = 10    # Switch config request failed.
OFPET_ROLE_REQUEST_FAILED = 11    # Controller Role request failed.
OFPET_EXPERIMENTER = 0xffff    # Experimenter error messages.

# enum ofp_hello_failed_code
OFPHFC_INCOMPATIBLE = 0        # No compatible version.
OFPHFC_EPERM = 1        # Permissions error.

# enum ofp_bad_request_code
OFPBRC_BAD_VERSION = 0        # ofp_header.version not supported.
OFPBRC_BAD_TYPE = 1        # ofp_header.type not supported.
OFPBRC_BAD_STAT = 2        # ofp_stats_msg.type not supported.
OFPBRC_BAD_EXPERIMENTER = 3    # Experimenter id not supported
                # (in ofp_experimenter_header
                            # or ofp_stats_request or ofp_stats_reply).
OFPBRC_BAD_EXP_TYPE = 4        # Experimenter type not supported.
OFPBRC_EPERM = 5        # Permissions error.
OFPBRC_BAD_LEN = 6        # Wrong request length for type.
OFPBRC_BUFFER_EMPTY = 7        # Specified buffer has already been used.
OFPBRC_BUFFER_UNKNOWN = 8    # Specified buffer does not exist.
OFPBRC_BAD_TABLE_ID = 9        # Specified table-id invalid or does not exist.
OFPBRC_IS_SLAVE = 10        # Denied because controller is slave.
OFPBRC_BAD_PORT = 11        # Invalid port.
OFPBRC_BAD_PACKET = 12        # Invalid packet in packet-out

# enum ofp_bad_action_code
OFPBAC_BAD_TYPE = 0        # Unknown action type.
OFPBAC_BAD_LEN = 1        # Length problem in actions.
OFPBAC_BAD_EXPERIMENTER = 2    # Unknown experimenter id specified.
OFPBAC_BAD_EXP_TYPE = 3        # Unknown action type for experimenter id.
OFPBAC_BAD_OUT_PORT = 4        # Problem validating output action.
OFPBAC_BAD_ARGUMENT = 5        # Bad action argument.
OFPBAC_EPERM = 6        # Permissions error.
OFPBAC_TOO_MANY = 7        # Can't handle this many actions.
OFPBAC_BAD_QUEUE = 8        # Problem validating output queue.
OFPBAC_BAD_OUT_GROUP = 9    # Invalid group id in forward action.
OFPBAC_MATCH_INCONSISTENT = 10    # Action can't apply for this match,
                # or Set-Field missing prerequisite.
OFPBAC_UNSUPPORTED_ORDER = 11    # Action order is unsupported for
                # the action list in an Apply-Actions
                # instruction
OFPBAC_BAD_TAG = 12        # Actions uses an unsupported tag/encap.
OFPBAC_BAD_SET_TYPE = 13        # Unsupported type in SET_FIELD action.
OFPBAC_BAD_SET_LEN = 14        # Length problem in SET_FIELD action.
OFPBAC_BAD_SET_ARGUMENT = 15    # Bad arguement in SET_FIELD action.

# enum ofp_bad_instruction_code
OFPBIC_UNKNOWN_INST = 0        # Unknown instruction.
OFPBIC_UNSUP_INST = 1        # Switch or table does not support
                # the instruction.
OFPBIC_BAD_TABLE_ID = 2        # Invalid Table-Id specified
OFPBIC_UNSUP_METADATA = 3    # Metadata value unsupported by datapath.
OFPBIC_UNSUP_METADATA_MASK = 4    # Metadata mask value unsupported by
                # datapath.
OFPBIC_BAD_EXPERIMENTER = 5    # Unknown experimenter id specified.
OFPBIC_BAD_EXP_TYPE = 6        # Unknown instruction for experimenter id.
OFPBIC_BAD_LEN = 7        # Length problem in instrucitons.
OFPBIC_EPERM = 8        # Permissions error.

# enum ofp_bad_match_code
OFPBMC_BAD_TYPE = 0        # Unsupported match type apecified by
                                # the match.
OFPBMC_BAD_LEN = 1        # Length problem in math.
OFPBMC_BAD_TAG = 2        # Match uses an unsupported tag/encap.
OFPBMC_BAD_DL_ADDR_MASK = 3    # Unsupported datalink addr mask -
                                # switch does not support arbitrary
                                # datalink address mask.
OFPBMC_BAD_NW_ADDR_MASK = 4    # Unsupported network addr mask -
                                # switch does not support arbitrary
                                # network addres mask.
OFPBMC_BAD_WILDCARDS = 5    # Unsupported combination of fields
                                # masked or omitted in the match.
OFPBMC_BAD_FIELD = 6        # Unsupported field type in the match.
OFPBMC_BAD_VALUE = 7        # Unsupported value in a match field.
OFPBMC_BAD_MASK = 8        # Unsupported mask specified in the
                                # match.
OFPBMC_BAD_PREREQ = 9        # A prerequisite was not met.
OFPBMC_DUP_FIELD = 10        # A field type was duplicated.
OFPBMC_EPERM = 11         # Permissions error.

# enum ofp_flow_mod_failed_code
OFPFMFC_UNKNOWN = 0        # Unspecified error.
OFPFMFC_TABLE_FULL = 1        # Flow not added because table was full.
OFPFMFC_BAD_TABLE_ID = 2    # Table does not exist
OFPFMFC_OVERLAP = 3        # Attempted to add overlapping flow
                                # with CHECK_OVERLAP flag set.
OFPFMFC_EPERM = 4        # Permissions error.
OFPFMFC_BAD_TIMEOUT = 5        # Flow not added because of
                                # unsupported idle/hard timeout.
OFPFMFC_BAD_COMMAND = 6        # Unsupported or unknown command.
OFPFMFC_BAD_FLAGS = 7        # Unsupported or unknown flags.

# enum ofp_group_mod_failed_code
OFPGMFC_GROUP_EXISTS = 0
OFPGMFC_INVALID_GROUP = 1
OFPGMFC_WEIGHT_UNSUPPORTED = 2    # Switch does not support unequal load
                                  # sharing with select groups.
OFPGMFC_OUT_OF_GROUPS = 3         # The group table is full.
OFPGMFC_OUT_OF_BUCKETS = 4        # The maximum number of action buckets
                                  # for a group has been exceeded.
OFPGMFC_CHAINING_UNSUPPORTED = 5  # Switch does not support groups that
                                  # forward to groups.
OFPGMFC_WATCH_UNSUPPORTED = 6     # This group cannot watch the
                                  # watch_port or watch_group specified.
OFPGMFC_LOOP = 7                  # Group entry would cause a loop.
OFPGMFC_UNKNOWN_GROUP = 8         # Group not modified because a group
                                  # MODIFY attempted to modify a
                                  # non-existent group.
OFPGMFC_CHAINED_GROUP = 9         # Group not deleted because another
                                  # group is forwarding to it.
OFPGMFC_BAD_TYPE = 10             # Unsupported or unknown group type.
OFPGMFC_BAD_COMMAND = 11          # Unsupported or unknown command.
OFPGMFC_BAD_BUCKET = 12           # Error in bucket.
OFPGMFC_BAD_WATCH = 13            # Error in watch port/group.
OFPGMFC_EPERM = 14                # Permissions error.

# enum ofp_port_mod_failed_code
OFPPMFC_BAD_PORT = 0        # Specified port does not exist.
OFPPMFC_BAD_HW_ADDR = 1        # Specified hardware address does not
                                # match the port number.
OFPPMFC_BAD_CONFIG = 2        # Specified config is invalid.
OFPPMFC_BAD_ADVERTISE = 3    # Specified advertise is invalid.
OFPPMFC_EPERM = 4        # Permissions error.

# enum ofp_table_mod_failed_code
OFPTMFC_BAD_TABLE = 0        # Specified table does not exist.
OFPTMFC_BAD_CONFIG = 1        # Specified config is invalid.
OFPTMFC_EPERM = 2        # Permissions error

# enum ofp_queue_op_failed_code
OFPQOFC_BAD_PORT = 0        # Invalid port (or port does not exist).
OFPQOFC_BAD_QUEUE = 1        # Queue does not exist.
OFPQOFC_EPERM = 2        # Permissions error.

# enum ofp_switch_config_failed_code
OFPSCFC_BAD_FLAGS = 0        # Specified flags is invalid.
OFPSCFC_BAD_LEN = 1        # Specified len is invalid.
OFPQCFC_EPERM = 2        # Permissions error.

# enum ofp_role_request_failed_code
OFPRRFC_STALE = 0        # Stale Message: old generation_id.
OFPRRFC_UNSUP = 1        # Controller role change unsupported.
OFPRRFC_BAD_ROLE = 2        # Invalid role.

# struct ofp_error_experimenter_msg
OFP_ERROR_EXPERIMENTER_MSG_PACK_STR = '!HHI'
OFP_ERROR_EXPERIMENTER_MSG_SIZE = 16
assert (calcsize(OFP_ERROR_EXPERIMENTER_MSG_PACK_STR) + OFP_HEADER_SIZE ==
        OFP_ERROR_EXPERIMENTER_MSG_SIZE)

# struct ofp_experimenter_header
OFP_EXPERIMENTER_HEADER_PACK_STR = '!II'
OFP_EXPERIMENTER_HEADER_SIZE = 16
assert (calcsize(OFP_EXPERIMENTER_HEADER_PACK_STR) + OFP_HEADER_SIZE ==
        OFP_EXPERIMENTER_HEADER_SIZE)


# OXM


def _oxm_tlv_header(class_, field, hasmask, length):
    return (class_ << 16) | (field << 9) | (hasmask << 8) | length


def oxm_tlv_header(field, length):
    return _oxm_tlv_header(OFPXMC_OPENFLOW_BASIC, field, 0, length)


def oxm_tlv_header_w(field, length):
    return _oxm_tlv_header(OFPXMC_OPENFLOW_BASIC, field, 1, length * 2)


def oxm_tlv_header_extract_hasmask(header):
    return (header >> 8) & 1


def oxm_tlv_header_extract_length(header):
    if oxm_tlv_header_extract_hasmask(header):
        length = (header & 0xff) / 2
    else:
        length = header & 0xff
    return length

oxm_types = [
    oxm_fields.OpenFlowBasic('in_port', 0, oxm_fields.Int4),
    oxm_fields.OpenFlowBasic('in_phy_port', 1, oxm_fields.Int4),
    oxm_fields.OpenFlowBasic('metadata', 2, oxm_fields.Int8),
    oxm_fields.OpenFlowBasic('eth_dst', 3, oxm_fields.MacAddr),
    oxm_fields.OpenFlowBasic('eth_src', 4, oxm_fields.MacAddr),
    oxm_fields.OpenFlowBasic('eth_type', 5, oxm_fields.Int2),
    oxm_fields.OpenFlowBasic('vlan_vid', 6, oxm_fields.Int2),
    oxm_fields.OpenFlowBasic('vlan_pcp', 7, oxm_fields.Int1),
    oxm_fields.OpenFlowBasic('ip_dscp', 8, oxm_fields.Int1),
    oxm_fields.OpenFlowBasic('ip_ecn', 9, oxm_fields.Int1),
    oxm_fields.OpenFlowBasic('ip_proto', 10, oxm_fields.Int1),
    oxm_fields.OpenFlowBasic('ipv4_src', 11, oxm_fields.IPv4Addr),
    oxm_fields.OpenFlowBasic('ipv4_dst', 12, oxm_fields.IPv4Addr),
    oxm_fields.OpenFlowBasic('tcp_src', 13, oxm_fields.Int2),
    oxm_fields.OpenFlowBasic('tcp_dst', 14, oxm_fields.Int2),
    oxm_fields.OpenFlowBasic('udp_src', 15, oxm_fields.Int2),
    oxm_fields.OpenFlowBasic('udp_dst', 16, oxm_fields.Int2),
    oxm_fields.OpenFlowBasic('sctp_src', 17, oxm_fields.Int2),
    oxm_fields.OpenFlowBasic('sctp_dst', 18, oxm_fields.Int2),
    oxm_fields.OpenFlowBasic('icmpv4_type', 19, oxm_fields.Int1),
    oxm_fields.OpenFlowBasic('icmpv4_code', 20, oxm_fields.Int1),
    oxm_fields.OpenFlowBasic('arp_op', 21, oxm_fields.Int2),
    oxm_fields.OpenFlowBasic('arp_spa', 22, oxm_fields.IPv4Addr),
    oxm_fields.OpenFlowBasic('arp_tpa', 23, oxm_fields.IPv4Addr),
    oxm_fields.OpenFlowBasic('arp_sha', 24, oxm_fields.MacAddr),
    oxm_fields.OpenFlowBasic('arp_tha', 25, oxm_fields.MacAddr),
    oxm_fields.OpenFlowBasic('ipv6_src', 26, oxm_fields.IPv6Addr),
    oxm_fields.OpenFlowBasic('ipv6_dst', 27, oxm_fields.IPv6Addr),
    oxm_fields.OpenFlowBasic('ipv6_flabel', 28, oxm_fields.Int4),
    oxm_fields.OpenFlowBasic('icmpv6_type', 29, oxm_fields.Int1),
    oxm_fields.OpenFlowBasic('icmpv6_code', 30, oxm_fields.Int1),
    oxm_fields.OpenFlowBasic('ipv6_nd_target', 31, oxm_fields.IPv6Addr),
    oxm_fields.OpenFlowBasic('ipv6_nd_sll', 32, oxm_fields.MacAddr),
    oxm_fields.OpenFlowBasic('ipv6_nd_tll', 33, oxm_fields.MacAddr),
    oxm_fields.OpenFlowBasic('mpls_label', 34, oxm_fields.Int4),
    oxm_fields.OpenFlowBasic('mpls_tc', 35, oxm_fields.Int1),
]

oxm_fields.generate(__name__)


# define constants
OFP_VERSION = 0x03
OFP_TCP_PORT = 6633

MAX_XID = 0xffffffff

OFP_NO_BUFFER = 0xffffffff

########NEW FILE########
__FILENAME__ = ofproto_v1_2_parser
# Copyright (C) 2012 Nippon Telegraph and Telephone Corporation.
# Copyright (C) 2012 Isaku Yamahata <yamahata at valinux co jp>
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import struct
import itertools

from ryu.lib import addrconv
from ryu.lib import mac
from ryu import utils
from ofproto_parser import StringifyMixin, MsgBase, msg_pack_into, msg_str_attr
from . import ofproto_parser
from . import ofproto_v1_2

import logging
LOG = logging.getLogger('ryu.ofproto.ofproto_v1_2_parser')

_MSG_PARSERS = {}


def _set_msg_type(msg_type):
    def _set_cls_msg_type(cls):
        cls.cls_msg_type = msg_type
        return cls
    return _set_cls_msg_type


def _register_parser(cls):
    '''class decorator to register msg parser'''
    assert cls.cls_msg_type is not None
    assert cls.cls_msg_type not in _MSG_PARSERS
    _MSG_PARSERS[cls.cls_msg_type] = cls.parser
    return cls


@ofproto_parser.register_msg_parser(ofproto_v1_2.OFP_VERSION)
def msg_parser(datapath, version, msg_type, msg_len, xid, buf):
    parser = _MSG_PARSERS.get(msg_type)
    return parser(datapath, version, msg_type, msg_len, xid, buf)


@_register_parser
@_set_msg_type(ofproto_v1_2.OFPT_HELLO)
class OFPHello(MsgBase):
    """
    Hello message

    When connection is started, the hello message is exchanged between a
    switch and a controller.

    This message is handled by the Ryu framework, so the Ryu application
    do not need to process this typically.
    """
    def __init__(self, datapath):
        super(OFPHello, self).__init__(datapath)


@_register_parser
@_set_msg_type(ofproto_v1_2.OFPT_ERROR)
class OFPErrorMsg(MsgBase):
    """
    Error message

    The switch notifies controller of problems by this message.

    ========== =========================================================
    Attribute  Description
    ========== =========================================================
    type       High level type of error
    code       Details depending on the type
    data       Variable length data depending on the type and code
    ========== =========================================================

    ``type`` attribute corresponds to ``type_`` parameter of __init__.

    Types and codes are defined in ``ryu.ofproto.ofproto_v1_2``.

    ============================= ===========
    Type                          Code
    ============================= ===========
    OFPET_HELLO_FAILED            OFPHFC_*
    OFPET_BAD_REQUEST             OFPBRC_*
    OFPET_BAD_ACTION              OFPBAC_*
    OFPET_BAD_INSTRUCTION         OFPBIC_*
    OFPET_BAD_MATCH               OFPBMC_*
    OFPET_FLOW_MOD_FAILED         OFPFMFC_*
    OFPET_GROUP_MOD_FAILED        OFPGMFC_*
    OFPET_PORT_MOD_FAILED         OFPPMFC_*
    OFPET_TABLE_MOD_FAILED        OFPTMFC_*
    OFPET_QUEUE_OP_FAILED         OFPQOFC_*
    OFPET_SWITCH_CONFIG_FAILED    OFPSCFC_*
    OFPET_ROLE_REQUEST_FAILED     OFPRRFC_*
    OFPET_EXPERIMENTER            N/A
    ============================= ===========

    Example::

        @set_ev_cls(ofp_event.EventOFPErrorMsg,
                    [HANDSHAKE_DISPATCHER, CONFIG_DISPATCHER, MAIN_DISPATCHER])
        def error_msg_handler(self, ev):
            msg = ev.msg

            self.logger.debug('OFPErrorMsg received: type=0x%02x code=0x%02x '
                              'message=%s',
                              msg.type, msg.code, utils.hex_array(msg.data))
    """
    def __init__(self, datapath, type_=None, code=None, data=None):
        super(OFPErrorMsg, self).__init__(datapath)
        self.type = type_
        self.code = code
        self.data = data

    @classmethod
    def parser(cls, datapath, version, msg_type, msg_len, xid, buf):
        type_, = struct.unpack_from('!H', buffer(buf),
                                    ofproto_v1_2.OFP_HEADER_SIZE)
        if type_ == ofproto_v1_2.OFPET_EXPERIMENTER:
            return OFPErrorExperimenterMsg.parser(datapath, version, msg_type,
                                                  msg_len, xid, buf)

        msg = super(OFPErrorMsg, cls).parser(datapath, version, msg_type,
                                             msg_len, xid, buf)
        msg.type, msg.code = struct.unpack_from(
            ofproto_v1_2.OFP_ERROR_MSG_PACK_STR, msg.buf,
            ofproto_v1_2.OFP_HEADER_SIZE)
        msg.data = msg.buf[ofproto_v1_2.OFP_ERROR_MSG_SIZE:]
        return msg

    def _serialize_body(self):
        assert self.data is not None
        msg_pack_into(ofproto_v1_2.OFP_ERROR_MSG_PACK_STR, self.buf,
                      ofproto_v1_2.OFP_HEADER_SIZE, self.type, self.code)
        self.buf += self.data


class OFPErrorExperimenterMsg(MsgBase):
    def __init__(self, datapath, type_=None, exp_type=None, experimenter=None,
                 data=None):
        super(OFPErrorExperimenterMsg, self).__init__(datapath)
        self.type = ofproto_v1_2.OFPET_EXPERIMENTER
        self.exp_type = exp_type
        self.experimenter = experimenter
        self.data = data

    @classmethod
    def parser(cls, datapath, version, msg_type, msg_len, xid, buf):
        cls.cls_msg_type = msg_type
        msg = super(OFPErrorExperimenterMsg, cls).parser(
            datapath, version, msg_type, msg_len, xid, buf)
        msg.type, msg.exp_type, msg.experimenter = struct.unpack_from(
            ofproto_v1_2.OFP_ERROR_EXPERIMENTER_MSG_PACK_STR, msg.buf,
            ofproto_v1_2.OFP_HEADER_SIZE)
        msg.data = msg.buf[ofproto_v1_2.OFP_ERROR_EXPERIMENTER_MSG_SIZE:]
        return msg

    def _serialize_body(self):
        assert self.data is not None
        msg_pack_into(ofproto_v1_2.OFP_ERROR_EXPERIMENTER_MSG_PACK_STR,
                      self.buf, ofproto_v1_2.OFP_HEADER_SIZE,
                      self.type, self.exp_type, self.experimenter)
        self.buf += self.data


@_register_parser
@_set_msg_type(ofproto_v1_2.OFPT_ECHO_REQUEST)
class OFPEchoRequest(MsgBase):
    """
    Echo request message

    This message is handled by the Ryu framework, so the Ryu application
    do not need to process this typically.

    ========== =========================================================
    Attribute  Description
    ========== =========================================================
    data       An arbitrary length data
    ========== =========================================================

    Example::

        def send_echo_request(self, datapath, data):
            ofp = datapath.ofproto
            ofp_parser = datapath.ofproto_parser

            req = ofp_parser.OFPEchoRequest(datapath, data)
            datapath.send_msg(req)

        @set_ev_cls(ofp_event.EventOFPEchoRequest,
                    [HANDSHAKE_DISPATCHER, CONFIG_DISPATCHER, MAIN_DISPATCHER])
        def echo_request_handler(self, ev):
            self.logger.debug('OFPEchoRequest received: data=%s',
                              utils.hex_array(ev.msg.data))
    """
    def __init__(self, datapath, data=None):
        super(OFPEchoRequest, self).__init__(datapath)
        self.data = data

    @classmethod
    def parser(cls, datapath, version, msg_type, msg_len, xid, buf):
        msg = super(OFPEchoRequest, cls).parser(datapath, version, msg_type,
                                                msg_len, xid, buf)
        msg.data = msg.buf[ofproto_v1_2.OFP_HEADER_SIZE:]
        return msg

    def _serialize_body(self):
        if self.data is not None:
            self.buf += self.data


@_register_parser
@_set_msg_type(ofproto_v1_2.OFPT_ECHO_REPLY)
class OFPEchoReply(MsgBase):
    """
    Echo reply message

    This message is handled by the Ryu framework, so the Ryu application
    do not need to process this typically.

    ========== =========================================================
    Attribute  Description
    ========== =========================================================
    data       An arbitrary length data
    ========== =========================================================

    Example::

        def send_echo_reply(self, datapath, data):
            ofp = datapath.ofproto
            ofp_parser = datapath.ofproto_parser

            reply = ofp_parser.OFPEchoReply(datapath, data)
            datapath.send_msg(reply)

        @set_ev_cls(ofp_event.EventOFPEchoReply,
                    [HANDSHAKE_DISPATCHER, CONFIG_DISPATCHER, MAIN_DISPATCHER])
        def echo_reply_handler(self, ev):
            self.logger.debug('OFPEchoReply received: data=%s',
                              utils.hex_array(ev.msg.data))
    """
    def __init__(self, datapath, data=None):
        super(OFPEchoReply, self).__init__(datapath)
        self.data = data

    @classmethod
    def parser(cls, datapath, version, msg_type, msg_len, xid, buf):
        msg = super(OFPEchoReply, cls).parser(datapath, version, msg_type,
                                              msg_len, xid, buf)
        msg.data = msg.buf[ofproto_v1_2.OFP_HEADER_SIZE:]
        return msg

    def _serialize_body(self):
        assert self.data is not None
        self.buf += self.data


@_register_parser
@_set_msg_type(ofproto_v1_2.OFPT_EXPERIMENTER)
class OFPExperimenter(MsgBase):
    """
    Experimenter extension message

    ============= =========================================================
    Attribute     Description
    ============= =========================================================
    experimenter  Experimenter ID
    exp_type      Experimenter defined
    data          Experimenter defined arbitrary additional data
    ============= =========================================================
    """
    def __init__(self, datapath, experimenter=None, exp_type=None, data=None):
        super(OFPExperimenter, self).__init__(datapath)
        self.experimenter = experimenter
        self.exp_type = exp_type
        self.data = data

    @classmethod
    def parser(cls, datapath, version, msg_type, msg_len, xid, buf):
        msg = super(OFPExperimenter, cls).parser(datapath, version, msg_type,
                                                 msg_len, xid, buf)
        (msg.experimenter, msg.exp_type) = struct.unpack_from(
            ofproto_v1_2.OFP_EXPERIMENTER_HEADER_PACK_STR, msg.buf,
            ofproto_v1_2.OFP_HEADER_SIZE)
        msg.data = msg.buf[ofproto_v1_2.OFP_EXPERIMENTER_HEADER_SIZE:]

        return msg

    def _serialize_body(self):
        assert self.data is not None
        msg_pack_into(ofproto_v1_2.OFP_EXPERIMENTER_HEADER_PACK_STR,
                      self.buf, ofproto_v1_2.OFP_HEADER_SIZE,
                      self.experimenter, self.exp_type)
        self.buf += self.data


class OFPPort(ofproto_parser.namedtuple('OFPPort', (
        'port_no', 'hw_addr', 'name', 'config', 'state', 'curr',
        'advertised', 'supported', 'peer', 'curr_speed', 'max_speed'))):

    _TYPE = {
        'ascii': [
            'hw_addr',
        ],
        'utf-8': [
            # OF spec is unclear about the encoding of name.
            # we assumes UTF-8, which is used by OVS.
            'name',
        ]
    }

    @classmethod
    def parser(cls, buf, offset):
        port = struct.unpack_from(ofproto_v1_2.OFP_PORT_PACK_STR, buf, offset)
        port = list(port)
        i = cls._fields.index('hw_addr')
        port[i] = addrconv.mac.bin_to_text(port[i])
        i = cls._fields.index('name')
        port[i] = port[i].rstrip('\0')
        return cls(*port)


@_set_msg_type(ofproto_v1_2.OFPT_FEATURES_REQUEST)
class OFPFeaturesRequest(MsgBase):
    """
    Features request message

    The controller sends a feature request to the switch upon session
    establishment.

    This message is handled by the Ryu framework, so the Ryu application
    do not need to process this typically.

    Example::

        def send_features_request(self, datapath):
            ofp_parser = datapath.ofproto_parser

            req = ofp_parser.OFPFeaturesRequest(datapath)
            datapath.send_msg(req)
    """
    def __init__(self, datapath):
        super(OFPFeaturesRequest, self).__init__(datapath)


@_register_parser
@_set_msg_type(ofproto_v1_2.OFPT_FEATURES_REPLY)
class OFPSwitchFeatures(MsgBase):
    """
    Features reply message

    The switch responds with a features reply message to a features
    request.

    This message is handled by the Ryu framework, so the Ryu application
    do not need to process this typically.

    Example::

        @set_ev_cls(ofp_event.EventOFPSwitchFeatures, CONFIG_DISPATCHER)
        def switch_features_handler(self, ev):
            msg = ev.msg

            self.logger.debug('OFPSwitchFeatures received: '
                              'datapath_id=0x%016x n_buffers=%d '
                              'n_tables=%d capabilities=0x%08x ports=%s',
                              msg.datapath_id, msg.n_buffers, msg.n_tables,
                              msg.capabilities, msg.ports)
    """
    def __init__(self, datapath, datapath_id=None, n_buffers=None,
                 n_tables=None, capabilities=None, ports=None):
        super(OFPSwitchFeatures, self).__init__(datapath)
        self.datapath_id = datapath_id
        self.n_buffers = n_buffers
        self.n_tables = n_tables
        self.capabilities = capabilities
        self.ports = ports

    @classmethod
    def parser(cls, datapath, version, msg_type, msg_len, xid, buf):
        msg = super(OFPSwitchFeatures, cls).parser(datapath, version, msg_type,
                                                   msg_len, xid, buf)
        (msg.datapath_id,
         msg.n_buffers,
         msg.n_tables,
         msg.capabilities,
         msg._reserved) = struct.unpack_from(
            ofproto_v1_2.OFP_SWITCH_FEATURES_PACK_STR, msg.buf,
            ofproto_v1_2.OFP_HEADER_SIZE)

        msg.ports = {}
        n_ports = ((msg_len - ofproto_v1_2.OFP_SWITCH_FEATURES_SIZE) /
                   ofproto_v1_2.OFP_PORT_SIZE)
        offset = ofproto_v1_2.OFP_SWITCH_FEATURES_SIZE
        for i in range(n_ports):
            port = OFPPort.parser(msg.buf, offset)
            msg.ports[port.port_no] = port
            offset += ofproto_v1_2.OFP_PORT_SIZE

        return msg


@_set_msg_type(ofproto_v1_2.OFPT_GET_CONFIG_REQUEST)
class OFPGetConfigRequest(MsgBase):
    """
    Get config request message

    The controller sends a get config request to query configuration
    parameters in the switch.

    Example::

        def send_get_config_request(self, datapath):
            ofp_parser = datapath.ofproto_parser

            req = ofp_parser.OFPGetConfigRequest(datapath)
            datapath.send_msg(req)
    """
    def __init__(self, datapath):
        super(OFPGetConfigRequest, self).__init__(datapath)


@_register_parser
@_set_msg_type(ofproto_v1_2.OFPT_GET_CONFIG_REPLY)
class OFPGetConfigReply(MsgBase):
    """
    Get config reply message

    The switch responds to a configuration request with a get config reply
    message.

    ============= =========================================================
    Attribute     Description
    ============= =========================================================
    flags         One of the following configuration flags.
                  OFPC_FRAG_NORMAL
                  OFPC_FRAG_DROP
                  OFPC_FRAG_REASM
                  OFPC_FRAG_MASK
                  OFPC_INVALID_TTL_TO_CONTROLLER
    miss_send_len Max bytes of new flow that datapath should send to the
                  controller
    ============= =========================================================

    Example::

        @set_ev_cls(ofp_event.EventOFPGetConfigReply, MAIN_DISPATCHER)
        def get_config_reply_handler(self, ev):
            msg = ev.msg
            dp = msg.datapath
            ofp = dp.ofproto

            if msg.flags == ofp.OFPC_FRAG_NORMAL:
                flags = 'NORMAL'
            elif msg.flags == ofp.OFPC_FRAG_DROP:
                flags = 'DROP'
            elif msg.flags == ofp.OFPC_FRAG_REASM:
                flags = 'REASM'
            elif msg.flags == ofp.OFPC_FRAG_MASK:
                flags = 'MASK'
            elif msg.flags == ofp.OFPC_INVALID_TTL_TO_CONTROLLER:
                flags = 'INVALID TTL TO CONTROLLER'
            else:
                flags = 'unknown'
            self.logger.debug('OFPGetConfigReply received: '
                              'flags=%s miss_send_len=%d',
                              flags, msg.miss_send_len)
    """
    def __init__(self, datapath, flags=None, miss_send_len=None):
        super(OFPGetConfigReply, self).__init__(datapath)
        self.flags = flags
        self.miss_send_len = miss_send_len

    @classmethod
    def parser(cls, datapath, version, msg_type, msg_len, xid, buf):
        msg = super(OFPGetConfigReply, cls).parser(datapath, version, msg_type,
                                                   msg_len, xid, buf)
        msg.flags, msg.miss_send_len = struct.unpack_from(
            ofproto_v1_2.OFP_SWITCH_CONFIG_PACK_STR, msg.buf,
            ofproto_v1_2.OFP_HEADER_SIZE)
        return msg


@_set_msg_type(ofproto_v1_2.OFPT_SET_CONFIG)
class OFPSetConfig(MsgBase):
    """
    Set config request message

    The controller sends a set config request message to set configuraion
    parameters.

    ============= =========================================================
    Attribute     Description
    ============= =========================================================
    flags         One of the following configuration flags.
                  OFPC_FRAG_NORMAL
                  OFPC_FRAG_DROP
                  OFPC_FRAG_REASM
                  OFPC_FRAG_MASK
                  OFPC_INVALID_TTL_TO_CONTROLLER
    miss_send_len Max bytes of new flow that datapath should send to the
                  controller
    ============= =========================================================

    Example::

        def send_set_config(self, datapath):
            ofp = datapath.ofproto
            ofp_parser = datapath.ofproto_parser

            req = ofp_parser.OFPSetConfig(datapath, ofp.OFPC_FRAG_NORMAL, 256)
            datapath.send_msg(req)
    """
    def __init__(self, datapath, flags=0, miss_send_len=0):
        super(OFPSetConfig, self).__init__(datapath)
        self.flags = flags
        self.miss_send_len = miss_send_len

    def _serialize_body(self):
        assert self.flags is not None
        assert self.miss_send_len is not None
        msg_pack_into(ofproto_v1_2.OFP_SWITCH_CONFIG_PACK_STR,
                      self.buf, ofproto_v1_2.OFP_HEADER_SIZE,
                      self.flags, self.miss_send_len)


@_register_parser
@_set_msg_type(ofproto_v1_2.OFPT_PACKET_IN)
class OFPPacketIn(MsgBase):
    """
    Packet-In message

    The switch sends the packet that received to the controller by this
    message.

    ============= =========================================================
    Attribute     Description
    ============= =========================================================
    buffer_id     ID assigned by datapath
    total_len     Full length of frame
    reason        Reason packet is being sent.
                  OFPR_NO_MATCH
                  OFPR_ACTION
                  OFPR_INVALID_TTL
    table_id      ID of the table that was looked up
    match         Instance of ``OFPMatch``
    data          Ethernet frame
    ============= =========================================================

    Example::

        @set_ev_cls(ofp_event.EventOFPPacketIn, MAIN_DISPATCHER)
        def packet_in_handler(self, ev):
            msg = ev.msg
            ofp = dp.ofproto

            if msg.reason == ofp.OFPR_NO_MATCH:
                reason = 'NO MATCH'
            elif msg.reason == ofp.OFPR_ACTION:
                reason = 'ACTION'
            elif msg.reason == ofp.OFPR_INVALID_TTL:
                reason = 'INVALID TTL'
            else:
                reason = 'unknown'

            self.logger.debug('OFPPacketIn received: '
                              'buffer_id=%x total_len=%d reason=%s '
                              'table_id=%d match=%s data=%s',
                              msg.buffer_id, msg.total_len, reason,
                              msg.table_id, msg.match,
                              utils.hex_array(msg.data))
    """
    def __init__(self, datapath, buffer_id=None, total_len=None, reason=None,
                 table_id=None, match=None, data=None):
        super(OFPPacketIn, self).__init__(datapath)
        self.buffer_id = buffer_id
        self.total_len = total_len
        self.reason = reason
        self.table_id = table_id
        self.match = match
        self.data = data

    @classmethod
    def parser(cls, datapath, version, msg_type, msg_len, xid, buf):
        msg = super(OFPPacketIn, cls).parser(datapath, version, msg_type,
                                             msg_len, xid, buf)
        (msg.buffer_id, msg.total_len, msg.reason,
         msg.table_id) = struct.unpack_from(
            ofproto_v1_2.OFP_PACKET_IN_PACK_STR,
            msg.buf, ofproto_v1_2.OFP_HEADER_SIZE)

        msg.match = OFPMatch.parser(msg.buf, ofproto_v1_2.OFP_PACKET_IN_SIZE -
                                    ofproto_v1_2.OFP_MATCH_SIZE)

        match_len = utils.round_up(msg.match.length, 8)
        msg.data = msg.buf[(ofproto_v1_2.OFP_PACKET_IN_SIZE -
                            ofproto_v1_2.OFP_MATCH_SIZE + match_len + 2):]

        if msg.total_len < len(msg.data):
            # discard padding for 8-byte alignment of OFP packet
            msg.data = msg.data[:msg.total_len]

        return msg


@_register_parser
@_set_msg_type(ofproto_v1_2.OFPT_FLOW_REMOVED)
class OFPFlowRemoved(MsgBase):
    """
    Flow removed message

    When flow entries time out or are deleted, the switch notifies controller
    with this message.

    ================ ======================================================
    Attribute        Description
    ================ ======================================================
    cookie           Opaque controller-issued identifier
    priority         Priority level of flow entry
    reason           One of the following values.
                     OFPRR_IDLE_TIMEOUT
                     OFPRR_HARD_TIMEOUT
                     OFPRR_DELETE
                     OFPRR_GROUP_DELETE
    table_id         ID of the table
    duration_sec     Time flow was alive in seconds
    duration_nsec    Time flow was alive in nanoseconds beyond duration_sec
    idle_timeout     Idle timeout from original flow mod
    hard_timeout     Hard timeout from original flow mod
    packet_count     Number of packets that was associated with the flow
    byte_count       Number of bytes that was associated with the flow
    match            Instance of ``OFPMatch``
    ================ ======================================================

    Example::

        @set_ev_cls(ofp_event.EventOFPFlowRemoved, MAIN_DISPATCHER)
        def flow_removed_handler(self, ev):
            msg = ev.msg
            dp = msg.datapath
            ofp = dp.ofproto

            if msg.reason == ofp.OFPRR_IDLE_TIMEOUT:
                reason = 'IDLE TIMEOUT'
            elif msg.reason == ofp.OFPRR_HARD_TIMEOUT:
                reason = 'HARD TIMEOUT'
            elif msg.reason == ofp.OFPRR_DELETE:
                reason = 'DELETE'
            elif msg.reason == ofp.OFPRR_GROUP_DELETE:
                reason = 'GROUP DELETE'
            else:
                reason = 'unknown'

            self.logger.debug('OFPFlowRemoved received: '
                              'cookie=%d priority=%d reason=%s table_id=%d '
                              'duration_sec=%d duration_nsec=%d '
                              'idle_timeout=%d hard_timeout=%d '
                              'packet_count=%d byte_count=%d match.fields=%s',
                              msg.cookie, msg.priority, reason, msg.table_id,
                              msg.duration_sec, msg.duration_nsec,
                              msg.idle_timeout, msg.hard_timeout,
                              msg.packet_count, msg.byte_count, msg.match)
    """
    def __init__(self, datapath, cookie=None, priority=None, reason=None,
                 table_id=None, duration_sec=None, duration_nsec=None,
                 idle_timeout=None, hard_timeout=None, packet_count=None,
                 byte_count=None, match=None):
        super(OFPFlowRemoved, self).__init__(datapath)
        self.cookie = cookie
        self.priority = priority
        self.reason = reason
        self.table_id = table_id
        self.duration_sec = duration_sec
        self.duration_nsec = duration_nsec
        self.idle_timeout = idle_timeout
        self.hard_timeout = hard_timeout
        self.packet_count = packet_count
        self.byte_count = byte_count
        self.match = match

    @classmethod
    def parser(cls, datapath, version, msg_type, msg_len, xid, buf):
        msg = super(OFPFlowRemoved, cls).parser(datapath, version, msg_type,
                                                msg_len, xid, buf)

        (msg.cookie, msg.priority, msg.reason,
         msg.table_id, msg.duration_sec, msg.duration_nsec,
         msg.idle_timeout, msg.hard_timeout, msg.packet_count,
         msg.byte_count) = struct.unpack_from(
            ofproto_v1_2.OFP_FLOW_REMOVED_PACK_STR0,
            msg.buf,
            ofproto_v1_2.OFP_HEADER_SIZE)

        offset = (ofproto_v1_2.OFP_FLOW_REMOVED_SIZE -
                  ofproto_v1_2.OFP_MATCH_SIZE)

        msg.match = OFPMatch.parser(msg.buf, offset)

        return msg


@_register_parser
@_set_msg_type(ofproto_v1_2.OFPT_PORT_STATUS)
class OFPPortStatus(MsgBase):
    """
    Port status message

    The switch notifies controller of change of ports.

    ================ ======================================================
    Attribute        Description
    ================ ======================================================
    reason           One of the following values.
                     OFPPR_ADD
                     OFPPR_DELETE
                     OFPPR_MODIFY
    desc             instance of ``OFPPort``
    ================ ======================================================

    Example::

        @set_ev_cls(ofp_event.EventOFPPortStatus, MAIN_DISPATCHER)
        def port_status_handler(self, ev):
            msg = ev.msg
            dp = msg.datapath
            ofp = dp.ofproto

            if msg.reason == ofp.OFPPR_ADD:
                reason = 'ADD'
            elif msg.reason == ofp.OFPPR_DELETE:
                reason = 'DELETE'
            elif msg.reason == ofp.OFPPR_MODIFY:
                reason = 'MODIFY'
            else:
                reason = 'unknown'

            self.logger.debug('OFPPortStatus received: reason=%s desc=%s',
                              reason, msg.desc)
    """
    def __init__(self, datapath, reason=None, desc=None):
        super(OFPPortStatus, self).__init__(datapath)
        self.reason = reason
        self.desc = desc

    @classmethod
    def parser(cls, datapath, version, msg_type, msg_len, xid, buf):
        msg = super(OFPPortStatus, cls).parser(datapath, version, msg_type,
                                               msg_len, xid, buf)
        msg.reason = struct.unpack_from(
            ofproto_v1_2.OFP_PORT_STATUS_PACK_STR, msg.buf,
            ofproto_v1_2.OFP_HEADER_SIZE)[0]
        msg.desc = OFPPort.parser(msg.buf,
                                  ofproto_v1_2.OFP_PORT_STATUS_DESC_OFFSET)
        return msg


@_set_msg_type(ofproto_v1_2.OFPT_PACKET_OUT)
class OFPPacketOut(MsgBase):
    """
    Packet-Out message

    The controller uses this message to send a packet out throught the
    switch.

    ================ ======================================================
    Attribute        Description
    ================ ======================================================
    buffer_id        ID assigned by datapath (OFP_NO_BUFFER if none)
    in_port          Packet's input port or ``OFPP_CONTROLLER``
    actions          list of OpenFlow action class
    data             Packet data
    ================ ======================================================

    Example::

        def send_packet_out(self, datapath, buffer_id, in_port):
            ofp = datapath.ofproto
            ofp_parser = datapath.ofproto_parser

            actions = [ofp_parser.OFPActionOutput(ofp.OFPP_FLOOD, 0)]
            req = ofp_parser.OFPPacketOut(datapath, buffer_id,
                                          in_port, actions)
            datapath.send_msg(req)
    """
    def __init__(self, datapath, buffer_id=None, in_port=None, actions=None,
                 data=None, actions_len=None):
        # The in_port field is the ingress port that must be associated
        # with the packet for OpenFlow processing.
        assert in_port is not None

        super(OFPPacketOut, self).__init__(datapath)
        self.buffer_id = buffer_id
        self.in_port = in_port
        self.actions_len = 0
        self.actions = actions
        self.data = data

    def _serialize_body(self):
        self.actions_len = 0
        offset = ofproto_v1_2.OFP_PACKET_OUT_SIZE
        for a in self.actions:
            a.serialize(self.buf, offset)
            offset += a.len
            self.actions_len += a.len

        if self.data is not None:
            assert self.buffer_id == 0xffffffff
            self.buf += self.data

        msg_pack_into(ofproto_v1_2.OFP_PACKET_OUT_PACK_STR,
                      self.buf, ofproto_v1_2.OFP_HEADER_SIZE,
                      self.buffer_id, self.in_port, self.actions_len)


@_set_msg_type(ofproto_v1_2.OFPT_FLOW_MOD)
class OFPFlowMod(MsgBase):
    """
    Modify Flow entry message

    The controller sends this message to modify the flow table.

    ================ ======================================================
    Attribute        Description
    ================ ======================================================
    cookie           Opaque controller-issued identifier
    cookie_mask      Mask used to restrict the cookie bits that must match
                     when the command is ``OPFFC_MODIFY*`` or
                     ``OFPFC_DELETE*``
    table_id         ID of the table to put the flow in
    command          One of the following values.
                     OFPFC_ADD
                     OFPFC_MODIFY
                     OFPFC_MODIFY_STRICT
                     OFPFC_DELETE
                     OFPFC_DELETE_STRICT
    idle_timeout     Idle time before discarding (seconds)
    hard_timeout     Max time before discarding (seconds)
    priority         Priority level of flow entry
    buffer_id        Buffered packet to apply to (or OFP_NO_BUFFER)
    out_port         For ``OFPFC_DELETE*`` commands, require matching
                     entries to include this as an output port
    out_group        For ``OFPFC_DELETE*`` commands, require matching
                     entries to include this as an output group
    flags            One of the following values.
                     OFPFF_SEND_FLOW_REM
                     OFPFF_CHECK_OVERLAP
                     OFPFF_RESET_COUNTS
    match            Instance of ``OFPMatch``
    instructions     list of ``OFPInstruction*`` instance
    ================ ======================================================

    Example::

        def send_flow_mod(self, datapath):
            ofp = datapath.ofproto
            ofp_parser = datapath.ofproto_parser

            cookie = cookie_mask = 0
            table_id = 0
            idle_timeout = hard_timeout = 0
            priority = 32768
            buffer_id = ofp.OFP_NO_BUFFER
            match = ofp_parser.OFPMatch(in_port=1, eth_dst='ff:ff:ff:ff:ff:ff')
            actions = [ofp_parser.OFPActionOutput(ofp.OFPP_NORMAL, 0)]
            inst = [ofp_parser.OFPInstructionActions(ofp.OFPIT_APPLY_ACTIONS,
                                                     actions)]
            req = ofp_parser.OFPFlowMod(datapath, cookie, cookie_mask,
                                        table_id, ofp.OFPFC_ADD,
                                        idle_timeout, hard_timeout,
                                        priority, buffer_id,
                                        ofp.OFPP_ANY, ofp.OFPG_ANY,
                                        ofp.OFPFF_SEND_FLOW_REM,
                                        match, inst)
            datapath.send_msg(req)
    """
    def __init__(self, datapath, cookie=0, cookie_mask=0, table_id=0,
                 command=ofproto_v1_2.OFPFC_ADD,
                 idle_timeout=0, hard_timeout=0, priority=0,
                 buffer_id=ofproto_v1_2.OFP_NO_BUFFER,
                 out_port=0, out_group=0, flags=0,
                 match=None,
                 instructions=[]):
        super(OFPFlowMod, self).__init__(datapath)
        self.cookie = cookie
        self.cookie_mask = cookie_mask
        self.table_id = table_id
        self.command = command
        self.idle_timeout = idle_timeout
        self.hard_timeout = hard_timeout
        self.priority = priority
        self.buffer_id = buffer_id
        self.out_port = out_port
        self.out_group = out_group
        self.flags = flags
        if match is None:
            match = OFPMatch()
        self.match = match
        self.instructions = instructions

    def _serialize_body(self):
        msg_pack_into(ofproto_v1_2.OFP_FLOW_MOD_PACK_STR0, self.buf,
                      ofproto_v1_2.OFP_HEADER_SIZE,
                      self.cookie, self.cookie_mask, self.table_id,
                      self.command, self.idle_timeout, self.hard_timeout,
                      self.priority, self.buffer_id, self.out_port,
                      self.out_group, self.flags)

        offset = (ofproto_v1_2.OFP_FLOW_MOD_SIZE -
                  ofproto_v1_2.OFP_MATCH_SIZE)

        match_len = self.match.serialize(self.buf, offset)
        offset += match_len

        for inst in self.instructions:
            inst.serialize(self.buf, offset)
            offset += inst.len


class OFPInstruction(StringifyMixin):
    _INSTRUCTION_TYPES = {}

    @staticmethod
    def register_instruction_type(types):
        def _register_instruction_type(cls):
            for type_ in types:
                OFPInstruction._INSTRUCTION_TYPES[type_] = cls
            return cls
        return _register_instruction_type

    @classmethod
    def parser(cls, buf, offset):
        (type_, len_) = struct.unpack_from('!HH', buf, offset)
        cls_ = cls._INSTRUCTION_TYPES.get(type_)
        return cls_.parser(buf, offset)


@OFPInstruction.register_instruction_type([ofproto_v1_2.OFPIT_GOTO_TABLE])
class OFPInstructionGotoTable(StringifyMixin):
    """
    Goto table instruction

    This instruction indicates the next table in the processing pipeline.

    ================ ======================================================
    Attribute        Description
    ================ ======================================================
    table_id         Next table
    ================ ======================================================
    """
    def __init__(self, table_id, type_=None, len_=None):
        super(OFPInstructionGotoTable, self).__init__()
        self.type = ofproto_v1_2.OFPIT_GOTO_TABLE
        self.len = ofproto_v1_2.OFP_INSTRUCTION_GOTO_TABLE_SIZE
        self.table_id = table_id

    @classmethod
    def parser(cls, buf, offset):
        (type_, len_, table_id) = struct.unpack_from(
            ofproto_v1_2.OFP_INSTRUCTION_GOTO_TABLE_PACK_STR,
            buf, offset)
        return cls(table_id)

    def serialize(self, buf, offset):
        msg_pack_into(ofproto_v1_2.OFP_INSTRUCTION_GOTO_TABLE_PACK_STR,
                      buf, offset, self.type, self.len, self.table_id)


@OFPInstruction.register_instruction_type([ofproto_v1_2.OFPIT_WRITE_METADATA])
class OFPInstructionWriteMetadata(StringifyMixin):
    """
    Write metadata instruction

    This instruction writes the masked metadata value into the metadata field.

    ================ ======================================================
    Attribute        Description
    ================ ======================================================
    metadata         Metadata value to write
    metadata_mask    Metadata write bitmask
    ================ ======================================================
    """
    def __init__(self, metadata, metadata_mask, len_=None):
        super(OFPInstructionWriteMetadata, self).__init__()
        self.type = ofproto_v1_2.OFPIT_WRITE_METADATA
        self.len = ofproto_v1_2.OFP_INSTRUCTION_WRITE_METADATA_SIZE
        self.metadata = metadata
        self.metadata_mask = metadata_mask

    @classmethod
    def parser(cls, buf, offset):
        (type_, len_, metadata, metadata_mask) = struct.unpack_from(
            ofproto_v1_2.OFP_INSTRUCTION_WRITE_METADATA_PACK_STR,
            buf, offset)
        return cls(metadata, metadata_mask)

    def serialize(self, buf, offset):
        msg_pack_into(ofproto_v1_2.OFP_INSTRUCTION_WRITE_METADATA_PACK_STR,
                      buf, offset, self.type, self.len, self.metadata,
                      self.metadata_mask)


@OFPInstruction.register_instruction_type([ofproto_v1_2.OFPIT_WRITE_ACTIONS,
                                           ofproto_v1_2.OFPIT_APPLY_ACTIONS,
                                           ofproto_v1_2.OFPIT_CLEAR_ACTIONS])
class OFPInstructionActions(StringifyMixin):
    """
    Actions instruction

    This instruction writes/applies/clears the actions.

    ================ ======================================================
    Attribute        Description
    ================ ======================================================
    type             One of following values.
                     OFPIT_WRITE_ACTIONS
                     OFPIT_APPLY_ACTIONS
                     OFPIT_CLEAR_ACTIONS
    actions          list of OpenFlow action class
    ================ ======================================================

    ``type`` attribute corresponds to ``type_`` parameter of __init__.
    """
    def __init__(self, type_, actions=None, len_=None):
        super(OFPInstructionActions, self).__init__()
        self.type = type_
        self.actions = actions

    @classmethod
    def parser(cls, buf, offset):
        (type_, len_) = struct.unpack_from(
            ofproto_v1_2.OFP_INSTRUCTION_ACTIONS_PACK_STR,
            buf, offset)

        offset += ofproto_v1_2.OFP_INSTRUCTION_ACTIONS_SIZE
        actions = []
        actions_len = len_ - ofproto_v1_2.OFP_INSTRUCTION_ACTIONS_SIZE
        while actions_len > 0:
            a = OFPAction.parser(buf, offset)
            actions.append(a)
            actions_len -= a.len
            offset += a.len

        inst = cls(type_, actions)
        inst.len = len_
        return inst

    def serialize(self, buf, offset):
        action_offset = offset + ofproto_v1_2.OFP_INSTRUCTION_ACTIONS_SIZE
        if self.actions:
            for a in self.actions:
                assert isinstance(a, OFPAction)
                a.serialize(buf, action_offset)
                action_offset += a.len

        self.len = action_offset - offset
        pad_len = utils.round_up(self.len, 8) - self.len
        ofproto_parser.msg_pack_into("%dx" % pad_len, buf, action_offset)
        self.len += pad_len

        msg_pack_into(ofproto_v1_2.OFP_INSTRUCTION_ACTIONS_PACK_STR,
                      buf, offset, self.type, self.len)


class OFPActionHeader(StringifyMixin):
    def __init__(self, type_, len_):
        self.type = type_
        self.len = len_

    def serialize(self, buf, offset):
        msg_pack_into(ofproto_v1_2.OFP_ACTION_HEADER_PACK_STR,
                      buf, offset, self.type, self.len)


class OFPAction(OFPActionHeader):
    _ACTION_TYPES = {}

    @staticmethod
    def register_action_type(type_, len_):
        def _register_action_type(cls):
            cls.cls_action_type = type_
            cls.cls_action_len = len_
            OFPAction._ACTION_TYPES[cls.cls_action_type] = cls
            return cls
        return _register_action_type

    def __init__(self):
        cls = self.__class__
        super(OFPAction, self).__init__(cls.cls_action_type,
                                        cls.cls_action_len)

    @classmethod
    def parser(cls, buf, offset):
        type_, len_ = struct.unpack_from(
            ofproto_v1_2.OFP_ACTION_HEADER_PACK_STR, buf, offset)
        cls_ = cls._ACTION_TYPES.get(type_)
        assert cls_ is not None
        return cls_.parser(buf, offset)

    def serialize(self, buf, offset):
        msg_pack_into(ofproto_v1_2.OFP_ACTION_HEADER_PACK_STR, buf,
                      offset, self.type, self.len)


@OFPAction.register_action_type(ofproto_v1_2.OFPAT_OUTPUT,
                                ofproto_v1_2.OFP_ACTION_OUTPUT_SIZE)
class OFPActionOutput(OFPAction):
    """
    Output action

    This action indicates output a packet to the switch port.

    ================ ======================================================
    Attribute        Description
    ================ ======================================================
    port             Output port
    max_len          Max length to send to controller
    ================ ======================================================
    """
    def __init__(self, port, max_len=ofproto_v1_2.OFPCML_MAX,
                 type_=None, len_=None):
        super(OFPActionOutput, self).__init__()
        self.port = port
        self.max_len = max_len

    @classmethod
    def parser(cls, buf, offset):
        type_, len_, port, max_len = struct.unpack_from(
            ofproto_v1_2.OFP_ACTION_OUTPUT_PACK_STR, buf, offset)
        return cls(port, max_len)

    def serialize(self, buf, offset):
        msg_pack_into(ofproto_v1_2.OFP_ACTION_OUTPUT_PACK_STR, buf,
                      offset, self.type, self.len, self.port, self.max_len)


@OFPAction.register_action_type(ofproto_v1_2.OFPAT_GROUP,
                                ofproto_v1_2.OFP_ACTION_GROUP_SIZE)
class OFPActionGroup(OFPAction):
    """
    Group action

    This action indicates the group used to process the packet.

    ================ ======================================================
    Attribute        Description
    ================ ======================================================
    group_id         Group identifier
    ================ ======================================================
    """
    def __init__(self, group_id, type_=None, len_=None):
        super(OFPActionGroup, self).__init__()
        self.group_id = group_id

    @classmethod
    def parser(cls, buf, offset):
        (type_, len_, group_id) = struct.unpack_from(
            ofproto_v1_2.OFP_ACTION_GROUP_PACK_STR, buf, offset)
        return cls(group_id)

    def serialize(self, buf, offset):
        msg_pack_into(ofproto_v1_2.OFP_ACTION_GROUP_PACK_STR, buf,
                      offset, self.type, self.len, self.group_id)


@OFPAction.register_action_type(ofproto_v1_2.OFPAT_SET_QUEUE,
                                ofproto_v1_2.OFP_ACTION_SET_QUEUE_SIZE)
class OFPActionSetQueue(OFPAction):
    """
    Set queue action

    This action sets the queue id that will be used to map a flow to an
    already-configured queue on a port.

    ================ ======================================================
    Attribute        Description
    ================ ======================================================
    queue_id         Queue ID for the packets
    ================ ======================================================
    """
    def __init__(self, queue_id, type_=None, len_=None):
        super(OFPActionSetQueue, self).__init__()
        self.queue_id = queue_id

    @classmethod
    def parser(cls, buf, offset):
        (type_, len_, queue_id) = struct.unpack_from(
            ofproto_v1_2.OFP_ACTION_SET_QUEUE_PACK_STR, buf, offset)
        return cls(queue_id)

    def serialize(self, buf, offset):
        msg_pack_into(ofproto_v1_2.OFP_ACTION_SET_QUEUE_PACK_STR, buf,
                      offset, self.type, self.len, self.queue_id)


@OFPAction.register_action_type(ofproto_v1_2.OFPAT_SET_MPLS_TTL,
                                ofproto_v1_2.OFP_ACTION_MPLS_TTL_SIZE)
class OFPActionSetMplsTtl(OFPAction):
    """
    Set MPLS TTL action

    This action sets the MPLS TTL.

    ================ ======================================================
    Attribute        Description
    ================ ======================================================
    mpls_ttl         MPLS TTL
    ================ ======================================================
    """
    def __init__(self, mpls_ttl, type_=None, len_=None):
        super(OFPActionSetMplsTtl, self).__init__()
        self.mpls_ttl = mpls_ttl

    @classmethod
    def parser(cls, buf, offset):
        (type_, len_, mpls_ttl) = struct.unpack_from(
            ofproto_v1_2.OFP_ACTION_MPLS_TTL_PACK_STR, buf, offset)
        return cls(mpls_ttl)

    def serialize(self, buf, offset):
        msg_pack_into(ofproto_v1_2.OFP_ACTION_MPLS_TTL_PACK_STR, buf,
                      offset, self.type, self.len, self.mpls_ttl)


@OFPAction.register_action_type(ofproto_v1_2.OFPAT_DEC_MPLS_TTL,
                                ofproto_v1_2.OFP_ACTION_HEADER_SIZE)
class OFPActionDecMplsTtl(OFPAction):
    """
    Decrement MPLS TTL action

    This action decrements the MPLS TTL.
    """
    def __init__(self, type_=None, len_=None):
        super(OFPActionDecMplsTtl, self).__init__()

    @classmethod
    def parser(cls, buf, offset):
        (type_, len_) = struct.unpack_from(
            ofproto_v1_2.OFP_ACTION_HEADER_PACK_STR, buf, offset)
        return cls()


@OFPAction.register_action_type(ofproto_v1_2.OFPAT_SET_NW_TTL,
                                ofproto_v1_2.OFP_ACTION_NW_TTL_SIZE)
class OFPActionSetNwTtl(OFPAction):
    """
    Set IP TTL action

    This action sets the IP TTL.

    ================ ======================================================
    Attribute        Description
    ================ ======================================================
    nw_ttl           IP TTL
    ================ ======================================================
    """
    def __init__(self, nw_ttl, type_=None, len_=None):
        super(OFPActionSetNwTtl, self).__init__()
        self.nw_ttl = nw_ttl

    @classmethod
    def parser(cls, buf, offset):
        (type_, len_, nw_ttl) = struct.unpack_from(
            ofproto_v1_2.OFP_ACTION_NW_TTL_PACK_STR, buf, offset)
        return cls(nw_ttl)

    def serialize(self, buf, offset):
        msg_pack_into(ofproto_v1_2.OFP_ACTION_NW_TTL_PACK_STR, buf, offset,
                      self.type, self.len, self.nw_ttl)


@OFPAction.register_action_type(ofproto_v1_2.OFPAT_DEC_NW_TTL,
                                ofproto_v1_2.OFP_ACTION_HEADER_SIZE)
class OFPActionDecNwTtl(OFPAction):
    """
    Decrement IP TTL action

    This action decrements the IP TTL.
    """
    def __init__(self, type_=None, len_=None):
        super(OFPActionDecNwTtl, self).__init__()

    @classmethod
    def parser(cls, buf, offset):
        (type_, len_) = struct.unpack_from(
            ofproto_v1_2.OFP_ACTION_HEADER_PACK_STR, buf, offset)
        return cls()


@OFPAction.register_action_type(ofproto_v1_2.OFPAT_COPY_TTL_OUT,
                                ofproto_v1_2.OFP_ACTION_HEADER_SIZE)
class OFPActionCopyTtlOut(OFPAction):
    """
    Copy TTL Out action

    This action copies the TTL from the next-to-outermost header with TTL to
    the outermost header with TTL.
    """
    def __init__(self, type_=None, len_=None):
        super(OFPActionCopyTtlOut, self).__init__()

    @classmethod
    def parser(cls, buf, offset):
        (type_, len_) = struct.unpack_from(
            ofproto_v1_2.OFP_ACTION_HEADER_PACK_STR, buf, offset)
        return cls()


@OFPAction.register_action_type(ofproto_v1_2.OFPAT_COPY_TTL_IN,
                                ofproto_v1_2.OFP_ACTION_HEADER_SIZE)
class OFPActionCopyTtlIn(OFPAction):
    """
    Copy TTL In action

    This action copies the TTL from the outermost header with TTL to the
    next-to-outermost header with TTL.
    """
    def __init__(self, type_=None, len_=None):
        super(OFPActionCopyTtlIn, self).__init__()

    @classmethod
    def parser(cls, buf, offset):
        (type_, len_) = struct.unpack_from(
            ofproto_v1_2.OFP_ACTION_HEADER_PACK_STR, buf, offset)
        return cls()


@OFPAction.register_action_type(ofproto_v1_2.OFPAT_PUSH_VLAN,
                                ofproto_v1_2.OFP_ACTION_PUSH_SIZE)
class OFPActionPushVlan(OFPAction):
    """
    Push VLAN action

    This action pushes a new VLAN tag to the packet.

    ================ ======================================================
    Attribute        Description
    ================ ======================================================
    ethertype        Ether type
    ================ ======================================================
    """
    def __init__(self, ethertype, type_=None, len_=None):
        super(OFPActionPushVlan, self).__init__()
        self.ethertype = ethertype

    @classmethod
    def parser(cls, buf, offset):
        (type_, len_, ethertype) = struct.unpack_from(
            ofproto_v1_2.OFP_ACTION_PUSH_PACK_STR, buf, offset)
        return cls(ethertype)

    def serialize(self, buf, offset):
        msg_pack_into(ofproto_v1_2.OFP_ACTION_PUSH_PACK_STR, buf, offset,
                      self.type, self.len, self.ethertype)


@OFPAction.register_action_type(ofproto_v1_2.OFPAT_PUSH_MPLS,
                                ofproto_v1_2.OFP_ACTION_PUSH_SIZE)
class OFPActionPushMpls(OFPAction):
    """
    Push MPLS action

    This action pushes a new MPLS header to the packet.

    ================ ======================================================
    Attribute        Description
    ================ ======================================================
    ethertype        Ether type
    ================ ======================================================
    """
    def __init__(self, ethertype, type_=None, len_=None):
        super(OFPActionPushMpls, self).__init__()
        self.ethertype = ethertype

    @classmethod
    def parser(cls, buf, offset):
        (type_, len_, ethertype) = struct.unpack_from(
            ofproto_v1_2.OFP_ACTION_PUSH_PACK_STR, buf, offset)
        return cls(ethertype)

    def serialize(self, buf, offset):
        msg_pack_into(ofproto_v1_2.OFP_ACTION_PUSH_PACK_STR, buf, offset,
                      self.type, self.len, self.ethertype)


@OFPAction.register_action_type(ofproto_v1_2.OFPAT_POP_VLAN,
                                ofproto_v1_2.OFP_ACTION_HEADER_SIZE)
class OFPActionPopVlan(OFPAction):
    """
    Pop VLAN action

    This action pops the outermost VLAN tag from the packet.
    """
    def __init__(self, type_=None, len_=None):
        super(OFPActionPopVlan, self).__init__()

    @classmethod
    def parser(cls, buf, offset):
        (type_, len_) = struct.unpack_from(
            ofproto_v1_2.OFP_ACTION_HEADER_PACK_STR, buf, offset)
        return cls()


@OFPAction.register_action_type(ofproto_v1_2.OFPAT_POP_MPLS,
                                ofproto_v1_2.OFP_ACTION_POP_MPLS_SIZE)
class OFPActionPopMpls(OFPAction):
    """
    Pop MPLS action

    This action pops the MPLS header from the packet.
    """
    def __init__(self, ethertype, type_=None, len_=None):
        super(OFPActionPopMpls, self).__init__()
        self.ethertype = ethertype

    @classmethod
    def parser(cls, buf, offset):
        (type_, len_, ethertype) = struct.unpack_from(
            ofproto_v1_2.OFP_ACTION_POP_MPLS_PACK_STR, buf, offset)
        return cls(ethertype)

    def serialize(self, buf, offset):
        msg_pack_into(ofproto_v1_2.OFP_ACTION_POP_MPLS_PACK_STR, buf, offset,
                      self.type, self.len, self.ethertype)


@OFPAction.register_action_type(ofproto_v1_2.OFPAT_SET_FIELD,
                                ofproto_v1_2.OFP_ACTION_SET_FIELD_SIZE)
class OFPActionSetField(OFPAction):
    """
    Set field action

    This action modifies a header field in the packet.

    ================ ======================================================
    Attribute        Description
    ================ ======================================================
    field            Instance of ``OFPMatchField``
    ================ ======================================================
    """
    def __init__(self, field=None, **kwargs):
        # old api
        #   OFPActionSetField(field)
        # new api
        #   OFPActionSetField(eth_src="00:00:00:00:00")
        super(OFPActionSetField, self).__init__()
        if isinstance(field, OFPMatchField):
            # old api compat
            assert len(kwargs) == 0
            self.field = field
        else:
            # new api
            assert len(kwargs) == 1
            key = kwargs.keys()[0]
            value = kwargs[key]
            assert isinstance(key, (str, unicode))
            assert not isinstance(value, tuple)  # no mask
            self.key = key
            self.value = value

    @classmethod
    def parser(cls, buf, offset):
        (type_, len_) = struct.unpack_from('!HH', buf, offset)
        (n, value, mask, _len) = ofproto_v1_2.oxm_parse(buf, offset + 4)
        k, uv = ofproto_v1_2.oxm_to_user(n, value, mask)
        action = cls(**{k: uv})
        action.len = len_

        # old api compat
        action.field = OFPMatchField.parser(buf, offset + 4)

        return action

    def serialize(self, buf, offset):
        # old api compat
        if self._composed_with_old_api():
            return self.serialize_old(buf, offset)

        n, value, mask = ofproto_v1_2.oxm_from_user(self.key, self.value)
        len_ = ofproto_v1_2.oxm_serialize(n, value, mask, buf, offset + 4)
        self.len = utils.round_up(4 + len_, 8)
        msg_pack_into('!HH', buf, offset, self.type, self.len)
        pad_len = self.len - (4 + len_)
        ofproto_parser.msg_pack_into("%dx" % pad_len, buf, offset + 4 + len_)

    # XXX old api compat
    def serialize_old(self, buf, offset):
        len_ = ofproto_v1_2.OFP_ACTION_SET_FIELD_SIZE + self.field.oxm_len()
        self.len = utils.round_up(len_, 8)
        pad_len = self.len - len_

        msg_pack_into('!HH', buf, offset, self.type, self.len)
        self.field.serialize(buf, offset + 4)
        offset += len_
        ofproto_parser.msg_pack_into("%dx" % pad_len, buf, offset)

    # XXX old api compat
    def _composed_with_old_api(self):
        return not hasattr(self, 'value')

    def to_jsondict(self):
        # XXX old api compat
        if self._composed_with_old_api():
            # copy object first because serialize_old is destructive
            o2 = OFPActionSetField(self.field)
            # serialize and parse to fill new fields
            buf = bytearray()
            o2.serialize(buf, 0)
            o = OFPActionSetField.parser(str(buf), 0)
        else:
            o = self
        return {
            self.__class__.__name__: {
                'field': ofproto_v1_2.oxm_to_jsondict(self.key, self.value)
            }
        }

    @classmethod
    def from_jsondict(cls, dict_):
        k, v = ofproto_v1_2.oxm_from_jsondict(dict_['field'])
        o = OFPActionSetField(**{k: v})

        # XXX old api compat
        # serialize and parse to fill old attributes
        buf = bytearray()
        o.serialize(buf, 0)
        return OFPActionSetField.parser(str(buf), 0)

    # XXX old api compat
    def __str__(self):
        # XXX old api compat
        if self._composed_with_old_api():
            # copy object first because serialize_old is destructive
            o2 = OFPActionSetField(self.field)
            # serialize and parse to fill new fields
            buf = bytearray()
            o2.serialize(buf, 0)
            o = OFPActionSetField.parser(str(buf), 0)
        else:
            o = self
        return super(OFPActionSetField, o).__str__()

    __repr__ = __str__

    def stringify_attrs(self):
        yield (self.key, self.value)


@OFPAction.register_action_type(
    ofproto_v1_2.OFPAT_EXPERIMENTER,
    ofproto_v1_2.OFP_ACTION_EXPERIMENTER_HEADER_SIZE)
class OFPActionExperimenter(OFPAction):
    """
    Experimenter action

    This action is an extensible action for the experimenter.

    ================ ======================================================
    Attribute        Description
    ================ ======================================================
    experimenter     Experimenter ID
    ================ ======================================================
    """
    def __init__(self, experimenter, type_=None, len_=None):
        super(OFPActionExperimenter, self).__init__()
        self.experimenter = experimenter

    @classmethod
    def parser(cls, buf, offset):
        (type_, len_, experimenter) = struct.unpack_from(
            ofproto_v1_2.OFP_ACTION_EXPERIMENTER_HEADER_PACK_STR, buf, offset)
        ex = cls(experimenter)
        ex.len = len_
        return ex

    def serialize(self, buf, offset):
        msg_pack_into(ofproto_v1_2.OFP_ACTION_EXPERIMENTER_HEADER_PACK_STR,
                      buf, offset, self.type, self.len, self.experimenter)


class OFPBucket(StringifyMixin):
    def __init__(self, weight, watch_port, watch_group, actions, len_=None):
        super(OFPBucket, self).__init__()
        self.weight = weight
        self.watch_port = watch_port
        self.watch_group = watch_group
        self.actions = actions

    @classmethod
    def parser(cls, buf, offset):
        (len_, weigth, watch_port, watch_group) = struct.unpack_from(
            ofproto_v1_2.OFP_BUCKET_PACK_STR, buf, offset)

        length = ofproto_v1_2.OFP_BUCKET_SIZE
        offset += ofproto_v1_2.OFP_BUCKET_SIZE
        actions = []
        while length < len_:
            action = OFPAction.parser(buf, offset)
            actions.append(action)
            offset += action.len
            length += action.len

        m = cls(weigth, watch_port, watch_group, actions)
        m.len = len_
        return m

    def serialize(self, buf, offset):
        action_offset = offset + ofproto_v1_2.OFP_BUCKET_SIZE
        action_len = 0
        for a in self.actions:
            a.serialize(buf, action_offset)
            action_offset += a.len
            action_len += a.len

        self.len = utils.round_up(ofproto_v1_2.OFP_BUCKET_SIZE + action_len, 8)
        msg_pack_into(ofproto_v1_2.OFP_BUCKET_PACK_STR, buf, offset,
                      self.len, self.weight, self.watch_port,
                      self.watch_group)


@_set_msg_type(ofproto_v1_2.OFPT_GROUP_MOD)
class OFPGroupMod(MsgBase):
    """
    Modify group entry message

    The controller sends this message to modify the group table.

    ================ ======================================================
    Attribute        Description
    ================ ======================================================
    command          One of the following values.
                     OFPFC_ADD
                     OFPFC_MODIFY
                     OFPFC_DELETE
    type             One of the following values.
                     OFPGT_ALL
                     OFPGT_SELECT
                     OFPGT_INDIRECT
                     OFPGT_FF
    group_id         Group identifier
    buckets          list of ``OFPBucket``
    ================ ======================================================

    ``type`` attribute corresponds to ``type_`` parameter of __init__.

    Example::

        def send_group_mod(self, datapath):
            ofp = datapath.ofproto
            ofp_parser = datapath.ofproto_parser

            port = 1
            max_len = 2000
            actions = [ofp_parser.OFPActionOutput(port, max_len)]

            weight = 100
            watch_port = 0
            watch_group = 0
            buckets = [ofp_parser.OFPBucket(weight, watch_port, watch_group,
                                            actions)]

            group_id = 1
            req = ofp_parser.OFPGroupMod(datapath, ofp.OFPFC_ADD,
                                         ofp.OFPGT_SELECT, group_id, buckets)
            datapath.send_msg(req)
    """
    def __init__(self, datapath, command, type_, group_id, buckets):
        super(OFPGroupMod, self).__init__(datapath)
        self.command = command
        self.type = type_
        self.group_id = group_id
        self.buckets = buckets

    def _serialize_body(self):
        msg_pack_into(ofproto_v1_2.OFP_GROUP_MOD_PACK_STR, self.buf,
                      ofproto_v1_2.OFP_HEADER_SIZE,
                      self.command, self.type, self.group_id)

        offset = ofproto_v1_2.OFP_GROUP_MOD_SIZE
        for b in self.buckets:
            b.serialize(self.buf, offset)
            offset += b.len


@_set_msg_type(ofproto_v1_2.OFPT_PORT_MOD)
class OFPPortMod(MsgBase):
    """
    Port modification message

    The controller sneds this message to modify the behavior of the port.

    ================ ======================================================
    Attribute        Description
    ================ ======================================================
    port_no          Port number to modify
    hw_addr          The hardware address that must be the same as hw_addr
                     of ``OFPPort`` of ``OFPSwitchFeatures``
    config           Bitmap of configuration flags.
                     OFPPC_PORT_DOWN
                     OFPPC_NO_RECV
                     OFPPC_NO_FWD
                     OFPPC_NO_PACKET_IN
    mask             Bitmap of configuration flags above to be changed
    advertise        Bitmap of the following flags.
                     OFPPF_10MB_HD
                     OFPPF_10MB_FD
                     OFPPF_100MB_HD
                     OFPPF_100MB_FD
                     OFPPF_1GB_HD
                     OFPPF_1GB_FD
                     OFPPF_10GB_FD
                     OFPPF_40GB_FD
                     OFPPF_100GB_FD
                     OFPPF_1TB_FD
                     OFPPF_OTHER
                     OFPPF_COPPER
                     OFPPF_FIBER
                     OFPPF_AUTONEG
                     OFPPF_PAUSE
                     OFPPF_PAUSE_ASYM
    ================ ======================================================

    Example::

        def send_port_mod(self, datapath):
            ofp = datapath.ofproto
            ofp_parser = datapath.ofproto_parser

            port_no = 3
            hw_addr = 'fa:c8:e8:76:1d:7e'
            config = 0
            mask = (ofp.OFPPC_PORT_DOWN | ofp.OFPPC_NO_RECV |
                    ofp.OFPPC_NO_FWD | ofp.OFPPC_NO_PACKET_IN)
            advertise = (ofp.OFPPF_10MB_HD | ofp.OFPPF_100MB_FD |
                         ofp.OFPPF_1GB_FD | ofp.OFPPF_COPPER |
                         ofp.OFPPF_AUTONEG | ofp.OFPPF_PAUSE |
                         ofp.OFPPF_PAUSE_ASYM)
            req = ofp_parser.OFPPortMod(datapath, port_no, hw_addr, config,
                                        mask, advertise)
            datapath.send_msg(req)
    """

    _TYPE = {
        'ascii': [
            'hw_addr',
        ]
    }

    def __init__(self, datapath, port_no, hw_addr, config, mask, advertise):
        super(OFPPortMod, self).__init__(datapath)
        self.port_no = port_no
        self.hw_addr = hw_addr
        self.config = config
        self.mask = mask
        self.advertise = advertise

    def _serialize_body(self):
        msg_pack_into(ofproto_v1_2.OFP_PORT_MOD_PACK_STR, self.buf,
                      ofproto_v1_2.OFP_HEADER_SIZE,
                      self.port_no, addrconv.mac.text_to_bin(self.hw_addr),
                      self.config,
                      self.mask, self.advertise)


@_set_msg_type(ofproto_v1_2.OFPT_TABLE_MOD)
class OFPTableMod(MsgBase):
    """
    Flow table configuration message

    The controller sends this message to configure table state.

    ================ ======================================================
    Attribute        Description
    ================ ======================================================
    table_id         ID of the table (OFPTT_ALL indicates all tables)
    config           Bitmap of the following flags.
                     OFPTC_TABLE_MISS_CONTROLLER
                     OFPTC_TABLE_MISS_CONTINUE
                     OFPTC_TABLE_MISS_DROP
                     OFPTC_TABLE_MISS_MASK
    ================ ======================================================

    Example::

        def send_table_mod(self, datapath):
            ofp = datapath.ofproto
            ofp_parser = datapath.ofproto_parser

            req = ofp_parser.OFPTableMod(datapath, ofp.OFPTT_ALL,
                                         ofp.OFPTC_TABLE_MISS_DROP)
            datapath.send_msg(req)
    """
    def __init__(self, datapath, table_id, config):
        super(OFPTableMod, self).__init__(datapath)
        self.table_id = table_id
        self.config = config

    def _serialize_body(self):
        msg_pack_into(ofproto_v1_2.OFP_TABLE_MOD_PACK_STR, self.buf,
                      ofproto_v1_2.OFP_HEADER_SIZE,
                      self.table_id, self.config)


class OFPStatsRequest(MsgBase):
    def __init__(self, datapath, type_, flags=0):
        super(OFPStatsRequest, self).__init__(datapath)
        self.type = type_
        self.flags = flags

    def to_jsondict(self):
        # remove some redundant attributes
        d = super(OFPStatsRequest, self).to_jsondict()
        v = d[self.__class__.__name__]
        del v['type']  # implied by subclass
        return d

    def _serialize_stats_body(self):
        pass

    def _serialize_body(self):
        msg_pack_into(ofproto_v1_2.OFP_STATS_REQUEST_PACK_STR,
                      self.buf, ofproto_v1_2.OFP_HEADER_SIZE,
                      self.type, self.flags)

        self._serialize_stats_body()


@_register_parser
@_set_msg_type(ofproto_v1_2.OFPT_STATS_REPLY)
class OFPStatsReply(MsgBase):
    _STATS_TYPES = {}

    @staticmethod
    def register_stats_reply_type(type_, body_single_struct=False):
        def _register_stats_reply_type(cls):
            OFPStatsReply._STATS_TYPES[type_] = cls
            cls.cls_body_single_struct = body_single_struct
            return cls
        return _register_stats_reply_type

    def __init__(self, datapath, type_=None, flags=None, body=None):
        super(OFPStatsReply, self).__init__(datapath)
        self.type = type_
        self.flags = flags
        self.body = body

    @classmethod
    def parser(cls, datapath, version, msg_type, msg_len, xid, buf):
        msg = super(OFPStatsReply, cls).parser(datapath, version, msg_type,
                                               msg_len, xid, buf)
        msg.type, msg.flags = struct.unpack_from(
            ofproto_v1_2.OFP_STATS_REPLY_PACK_STR, msg.buf,
            ofproto_v1_2.OFP_HEADER_SIZE)
        stats_type_cls = cls._STATS_TYPES.get(msg.type)

        offset = ofproto_v1_2.OFP_STATS_REPLY_SIZE
        body = []
        while offset < msg_len:
            r = stats_type_cls.parser(msg.buf, offset)
            body.append(r)
            offset += r.length

        if stats_type_cls.cls_body_single_struct:
            msg.body = body[0]
        else:
            msg.body = body

        return msg


@_set_msg_type(ofproto_v1_2.OFPT_STATS_REQUEST)
class OFPDescStatsRequest(OFPStatsRequest):
    """
    Description statistics request message

    The controller uses this message to query description of the switch.

    ================ ======================================================
    Attribute        Description
    ================ ======================================================
    flags            Zero (none yet defined in the spec)
    ================ ======================================================

    Example::

        def send_desc_stats_request(self, datapath):
            ofp_parser = datapath.ofproto_parser

            req = ofp_parser.OFPDescStatsRequest(datapath)
            datapath.send_msg(req)
    """
    def __init__(self, datapath, flags=0):
        super(OFPDescStatsRequest, self).__init__(datapath,
                                                  ofproto_v1_2.OFPST_DESC,
                                                  flags)


@OFPStatsReply.register_stats_reply_type(ofproto_v1_2.OFPST_DESC,
                                         body_single_struct=True)
class OFPDescStats(ofproto_parser.namedtuple('OFPDescStats', (
        'mfr_desc', 'hw_desc', 'sw_desc', 'serial_num', 'dp_desc'))):
    """
    Description statistics reply message

    The switch responds with a stats reply that include this message to
    a description statistics request.

    ================ ======================================================
    Attribute        Description
    ================ ======================================================
    mfr_desc         Manufacturer description
    hw_desc          Hardware description
    sw_desc          Software description
    serial_num       Serial number
    dp_desc          Human readable description of datapath
    ================ ======================================================

    Example::

        @set_ev_cls(ofp_event.EventOFPStatsReply, MAIN_DISPATCHER)
        def stats_reply_handler(self, ev):
            msg = ev.msg
            ofp = msg.datapath.ofproto
            body = ev.msg.body

            if msg.type == ofp.OFPST_DESC:
                self.desc_stats_reply_handler(body)

        def desc_stats_reply_handler(self, body):
            self.logger.debug('DescStats: mfr_desc=%s hw_desc=%s sw_desc=%s '
                              'serial_num=%s dp_desc=%s',
                              body.mfr_desc, body.hw_desc, body.sw_desc,
                              body.serial_num, body.dp_desc)
    """

    _TYPE = {
        'ascii': [
            'mfr_desc',
            'hw_desc',
            'sw_desc',
            'serial_num',
            'dp_desc',
        ]
    }

    @classmethod
    def parser(cls, buf, offset):
        desc = struct.unpack_from(ofproto_v1_2.OFP_DESC_STATS_PACK_STR,
                                  buf, offset)
        desc = list(desc)
        desc = map(lambda x: x.rstrip('\0'), desc)
        stats = cls(*desc)
        stats.length = ofproto_v1_2.OFP_DESC_STATS_SIZE
        return stats


@_set_msg_type(ofproto_v1_2.OFPT_STATS_REQUEST)
class OFPFlowStatsRequest(OFPStatsRequest):
    """
    Individual flow statistics request message

    The controller uses this message to query individual flow statistics.

    ================ ======================================================
    Attribute        Description
    ================ ======================================================
    table_id         ID of table to read
    out_port         Require matching entries to include this as an output
                     port
    out_group        Require matching entries to include this as an output
                     group
    cookie           Require matching entries to contain this cookie value
    cookie_mask      Mask used to restrict the cookie bits that must match
    match            Instance of ``OFPMatch``
    flags            Zero (none yet defined in the spec)
    ================ ======================================================

    Example::

        def send_flow_stats_request(self, datapath):
            ofp = datapath.ofproto
            ofp_parser = datapath.ofproto_parser

            cookie = cookie_mask = 0
            match = ofp_parser.OFPMatch(in_port=1)
            req = ofp_parser.OFPFlowStatsRequest(datapath,
                                                 ofp.OFPTT_ALL,
                                                 ofp.OFPP_ANY, ofp.OFPG_ANY,
                                                 cookie, cookie_mask, match)
            datapath.send_msg(req)
    """
    def __init__(self, datapath, table_id=ofproto_v1_2.OFPTT_ALL,
                 out_port=ofproto_v1_2.OFPP_ANY,
                 out_group=ofproto_v1_2.OFPG_ANY,
                 cookie=0, cookie_mask=0, match=None, flags=0):
        super(OFPFlowStatsRequest, self).__init__(datapath,
                                                  ofproto_v1_2.OFPST_FLOW,
                                                  flags)
        self.table_id = table_id
        self.out_port = out_port
        self.out_group = out_group
        self.cookie = cookie
        self.cookie_mask = cookie_mask
        if match is None:
            match = OFPMatch()
        self.match = match

    def _serialize_stats_body(self):
        msg_pack_into(ofproto_v1_2.OFP_FLOW_STATS_REQUEST_PACK_STR,
                      self.buf, ofproto_v1_2.OFP_STATS_REQUEST_SIZE,
                      self.table_id, self.out_port, self.out_group,
                      self.cookie, self.cookie_mask)

        offset = (ofproto_v1_2.OFP_STATS_REQUEST_SIZE +
                  ofproto_v1_2.OFP_FLOW_STATS_REQUEST_SIZE -
                  ofproto_v1_2.OFP_MATCH_SIZE)

        self.match.serialize(self.buf, offset)


@OFPStatsReply.register_stats_reply_type(ofproto_v1_2.OFPST_FLOW)
class OFPFlowStats(StringifyMixin):
    """
    Individual flow statistics reply message

    The switch responds with a stats reply that include this message to
    an individual flow statistics request.

    ================ ======================================================
    Attribute        Description
    ================ ======================================================
    table_id         ID of table flow came from
    duration_sec     Time flow has been alive in seconds
    duration_nsec    Time flow has been alive in nanoseconds beyond
                     duration_sec
    priority         Priority of the entry
    idle_timeout     Number of seconds idle before expiration
    hard_timeout     Number of seconds before expiration
    cookie           Opaque controller-issued identifier
    packet_count     Number of packets in flow
    byte_count       Number of bytes in flow
    match            Instance of ``OFPMatch``
    instructions     list of ``OFPInstruction*`` instance
    ================ ======================================================

    Example::

        @set_ev_cls(ofp_event.EventOFPStatsReply, MAIN_DISPATCHER)
        def stats_reply_handler(self, ev):
            msg = ev.msg
            ofp = msg.datapath.ofproto
            body = ev.msg.body

            if msg.type == ofp.OFPST_FLOW:
                 self.flow_stats_reply_handler(body)

        def flow_stats_reply_handler(self, body):
            flows = []
            for stat in body:
                flows.append('table_id=%s '
                             'duration_sec=%d duration_nsec=%d '
                             'priority=%d '
                             'idle_timeout=%d hard_timeout=%d '
                             'cookie=%d packet_count=%d byte_count=%d '
                             'match=%s instructions=%s' %
                             (stat.table_id,
                              stat.duration_sec, stat.duration_nsec,
                              stat.priority,
                              stat.idle_timeout, stat.hard_timeout,
                              stat.cookie, stat.packet_count, stat.byte_count,
                              stat.match, stat.instructions))
            self.logger.debug('FlowStats: %s', flows)
    """
    def __init__(self, table_id, duration_sec, duration_nsec,
                 priority, idle_timeout, hard_timeout, cookie, packet_count,
                 byte_count, match, instructions=None, length=None):
        super(OFPFlowStats, self).__init__()
        self.table_id = table_id
        self.duration_sec = duration_sec
        self.duration_nsec = duration_nsec
        self.priority = priority
        self.idle_timeout = idle_timeout
        self.hard_timeout = hard_timeout
        self.cookie = cookie
        self.packet_count = packet_count
        self.byte_count = byte_count
        self.match = match
        self.instructions = instructions

    @classmethod
    def parser(cls, buf, offset):
        (length, table_id, duration_sec,
         duration_nsec, priority,
         idle_timeout, hard_timeout,
         cookie, packet_count, byte_count) = struct.unpack_from(
            ofproto_v1_2.OFP_FLOW_STATS_PACK_STR,
            buf, offset)
        offset += (ofproto_v1_2.OFP_FLOW_STATS_SIZE -
                   ofproto_v1_2.OFP_MATCH_SIZE)
        match = OFPMatch.parser(buf, offset)

        match_length = utils.round_up(match.length, 8)
        inst_length = (length - (ofproto_v1_2.OFP_FLOW_STATS_SIZE -
                                 ofproto_v1_2.OFP_MATCH_SIZE + match_length))
        offset += match_length
        instructions = []
        while inst_length > 0:
            inst = OFPInstruction.parser(buf, offset)
            instructions.append(inst)
            offset += inst.len
            inst_length -= inst.len

        o = cls(table_id, duration_sec, duration_nsec, priority,
                idle_timeout, hard_timeout, cookie, packet_count,
                byte_count, match, instructions)
        o.length = length
        return o


@_set_msg_type(ofproto_v1_2.OFPT_STATS_REQUEST)
class OFPAggregateStatsRequest(OFPStatsRequest):
    """
    Aggregate flow statistics request message

    The controller uses this message to query aggregate flow statictics.

    ================ ======================================================
    Attribute        Description
    ================ ======================================================
    table_id         ID of table to read
    out_port         Require matching entries to include this as an output
                     port
    out_group        Require matching entries to include this as an output
                     group
    cookie           Require matching entries to contain this cookie value
    cookie_mask      Mask used to restrict the cookie bits that must match
    match            Instance of ``OFPMatch``
    flags            Zero (none yet defined in the spec)
    ================ ======================================================

    Example::

        def send_aggregate_stats_request(self, datapath):
            ofp = datapath.ofproto
            ofp_parser = datapath.ofproto_parser

            cookie = cookie_mask = 0
            match = ofp_parser.OFPMatch(in_port=1)
            req = ofp_parser.OFPAggregateStatsRequest(datapath, 0,
                                                      ofp.OFPTT_ALL,
                                                      ofp.OFPP_ANY,
                                                      ofp.OFPG_ANY,
                                                      cookie, cookie_mask,
                                                      match)
            datapath.send_msg(req)
    """
    def __init__(self, datapath, table_id, out_port, out_group,
                 cookie, cookie_mask, match, flags=0):
        super(OFPAggregateStatsRequest, self).__init__(
            datapath,
            ofproto_v1_2.OFPST_AGGREGATE,
            flags)
        self.table_id = table_id
        self.out_port = out_port
        self.out_group = out_group
        self.cookie = cookie
        self.cookie_mask = cookie_mask
        self.match = match

    def _serialize_stats_body(self):
        msg_pack_into(ofproto_v1_2.OFP_AGGREGATE_STATS_REQUEST_PACK_STR,
                      self.buf,
                      ofproto_v1_2.OFP_STATS_REQUEST_SIZE,
                      self.table_id, self.out_port, self.out_group,
                      self.cookie, self.cookie_mask)

        offset = (ofproto_v1_2.OFP_STATS_REQUEST_SIZE +
                  ofproto_v1_2.OFP_AGGREGATE_STATS_REQUEST_SIZE -
                  ofproto_v1_2.OFP_MATCH_SIZE)

        self.match.serialize(self.buf, offset)


@OFPStatsReply.register_stats_reply_type(ofproto_v1_2.OFPST_AGGREGATE,
                                         body_single_struct=True)
class OFPAggregateStatsReply(ofproto_parser.namedtuple('OFPAggregateStats', (
        'packet_count', 'byte_count', 'flow_count'))):
    """
    Aggregate flow statistics reply message

    The switch responds with a stats reply that include this message to
    an aggregate flow statistics request.

    ================ ======================================================
    Attribute        Description
    ================ ======================================================
    packet_count     Number of packets in flows
    byte_count       Number of bytes in flows
    flow_count       Number of flows
    ================ ======================================================

    Example::

        @set_ev_cls(ofp_event.EventOFPStatsReply, MAIN_DISPATCHER)
        def stats_reply_handler(self, ev):
            msg = ev.msg
            ofp = msg.datapath.ofproto
            body = ev.msg.body

            if msg.type == ofp.OFPST_AGGREGATE:
                self.aggregate_stats_reply_handler(body)

        def aggregate_stats_reply_handler(self, body):
            self.logger.debug('AggregateStats: packet_count=%d byte_count=%d '
                              'flow_count=%d',
                              body.packet_count, body.byte_count,
                              body.flow_count)
    """

    @classmethod
    def parser(cls, buf, offset):
        desc = struct.unpack_from(
            ofproto_v1_2.OFP_AGGREGATE_STATS_REPLY_PACK_STR,
            buf, offset)
        stats = cls(*desc)
        stats.length = ofproto_v1_2.OFP_AGGREGATE_STATS_REPLY_SIZE
        return stats


@_set_msg_type(ofproto_v1_2.OFPT_STATS_REQUEST)
class OFPTableStatsRequest(OFPStatsRequest):
    """
    Table statistics request message

    The controller uses this message to query flow table statictics.

    ================ ======================================================
    Attribute        Description
    ================ ======================================================
    flags            Zero (none yet defined in the spec)
    ================ ======================================================

    Example::

        def send_table_stats_request(self, datapath):
            ofp = datapath.ofproto
            ofp_parser = datapath.ofproto_parser

            req = ofp_parser.OFPTableStatsRequest(datapath)
            datapath.send_msg(req)
    """
    def __init__(self, datapath, flags=0):
        super(OFPTableStatsRequest, self).__init__(datapath,
                                                   ofproto_v1_2.OFPST_TABLE,
                                                   flags)


@OFPStatsReply.register_stats_reply_type(ofproto_v1_2.OFPST_TABLE)
class OFPTableStats(
    ofproto_parser.namedtuple('OFPTableStats',
                              ('table_id', 'name', 'match', 'wildcards',
                               'write_actions', 'apply_actions',
                               'write_setfields', 'apply_setfields',
                               'metadata_match', 'metadata_write',
                               'instructions', 'config',
                               'max_entries', 'active_count',
                               'lookup_count', 'matched_count'))):
    """
    Table statistics reply message

    The switch responds with a stats reply that include this message to
    a table statistics request.

    ================ ======================================================
    Attribute        Description
    ================ ======================================================
    table_id         ID of table
    name             table name
    match            Bitmap of (1 << OFPXMT_*) that indicate the fields
                     the table can match on
    wildcards        Bitmap of (1 << OFPXMT_*) wildcards that are supported
                     by the table
    write_actions    Bitmap of OFPAT_* that are supported by the table with
                     OFPIT_WRITE_ACTIONS
    apply_actions    Bitmap of OFPAT_* that are supported by the table with
                     OFPIT_APPLY_ACTIONS
    write_setfields  Bitmap of (1 << OFPXMT_*) header fields that can be set
                     with OFPIT_WRITE_ACTIONS
    apply_setfields  Bitmap of (1 << OFPXMT_*) header fields that can be set
                     with OFPIT_APPLY_ACTIONS
    metadata_match   Bits of metadata table can match
    metadata_write   Bits of metadata table can write
    instructions     Bitmap of OFPIT_* values supported
    config           Bitmap of OFPTC_* values
    max_entries      Max number of entries supported
    active_count     Number of active entries
    lookup_count     Number of packets looked up in table
    matched_count    Number of packets that hit table
    ================ ======================================================

    Example::

        @set_ev_cls(ofp_event.EventOFPStatsReply, MAIN_DISPATCHER)
        def stats_reply_handler(self, ev):
            msg = ev.msg
            ofp = msg.datapath.ofproto
            body = ev.msg.body

            if msg.type == ofp.OFPST_TABLE:
                self.table_stats_reply_handler(body)

        def table_stats_reply_handler(self, body):
            tables = []
            for stat in body:
                tables.append('table_id=%d active_count=%d lookup_count=%d '
                              ' matched_count=%d' %
                              (stat.table_id, stat.active_count,
                               stat.lookup_count, stat.matched_count))
            self.logger.debug('TableStats: %s', tables)
    """

    _TYPE = {
        'utf-8': [
            # OF spec is unclear about the encoding of name.
            # we assumes UTF-8.
            'name',
        ]
    }

    @classmethod
    def parser(cls, buf, offset):
        table = struct.unpack_from(
            ofproto_v1_2.OFP_TABLE_STATS_PACK_STR,
            buf, offset)
        table = list(table)
        i = cls._fields.index('name')
        table[i] = table[i].rstrip('\0')
        stats = cls(*table)
        stats.length = ofproto_v1_2.OFP_TABLE_STATS_SIZE
        return stats


@_set_msg_type(ofproto_v1_2.OFPT_STATS_REQUEST)
class OFPPortStatsRequest(OFPStatsRequest):
    """
    Port statistics request message

    The controller uses this message to query information about ports
    statistics.

    ================ ======================================================
    Attribute        Description
    ================ ======================================================
    port_no          Port number to read (OFPP_ANY to all ports)
    flags            Zero (none yet defined in the spec)
    ================ ======================================================

    Example::

        def send_port_stats_request(self, datapath):
            ofp = datapath.ofproto
            ofp_parser = datapath.ofproto_parser

            req = ofp_parser.OFPPortStatsRequest(datapath, ofp.OFPP_ANY)
            datapath.send_msg(req)
    """
    def __init__(self, datapath, port_no, flags=0):
        super(OFPPortStatsRequest, self).__init__(datapath,
                                                  ofproto_v1_2.OFPST_PORT,
                                                  flags)
        self.port_no = port_no

    def _serialize_stats_body(self):
        msg_pack_into(ofproto_v1_2.OFP_PORT_STATS_REQUEST_PACK_STR,
                      self.buf, ofproto_v1_2.OFP_STATS_REQUEST_SIZE,
                      self.port_no)


@OFPStatsReply.register_stats_reply_type(ofproto_v1_2.OFPST_PORT)
class OFPPortStats(
    ofproto_parser.namedtuple('OFPPortStats',
                              ('port_no', 'rx_packets', 'tx_packets',
                               'rx_bytes', 'tx_bytes',
                               'rx_dropped', 'tx_dropped',
                               'rx_errors', 'tx_errors',
                               'rx_frame_err', 'rx_over_err',
                               'rx_crc_err', 'collisions'))):
    """
    Port statistics reply message

    The switch responds with a stats reply that include this message to
    a port statistics request.

    ================ ======================================================
    Attribute        Description
    ================ ======================================================
    port_no          Port number
    rx_packets       Number of received packets
    tx_packets       Number of transmitted packets
    rx_bytes         Number of received bytes
    tx_bytes         Number of transmitted bytes
    rx_dropped       Number of packets dropped by RX
    tx_dropped       Number of packets dropped by TX
    rx_errors        Number of receive errors
    tx_errors        Number of transmit errors
    rx_frame_err     Number of frame alignment errors
    rx_over_err      Number of packet with RX overrun
    rx_crc_err       Number of CRC errors
    collisions       Number of collisions
    ================ ======================================================

    Example::

        @set_ev_cls(ofp_event.EventOFPStatsReply, MAIN_DISPATCHER)
        def stats_reply_handler(self, ev):
            msg = ev.msg
            ofp = msg.datapath.ofproto
            body = ev.msg.body

            if msg.type == ofp.OFPST_PORT:
                self.port_stats_reply_handler(body)

        def port_stats_reply_handler(self, body):
            ports = []
            for stat in body:
                ports.append('port_no=%d '
                             'rx_packets=%d tx_packets=%d '
                             'rx_bytes=%d tx_bytes=%d '
                             'rx_dropped=%d tx_dropped=%d '
                             'rx_errors=%d tx_errors=%d '
                             'rx_frame_err=%d rx_over_err=%d rx_crc_err=%d '
                             'collisions=%d' %
                             (stat.port_no,
                              stat.rx_packets, stat.tx_packets,
                              stat.rx_bytes, stat.tx_bytes,
                              stat.rx_dropped, stat.tx_dropped,
                              stat.rx_errors, stat.tx_errors,
                              stat.rx_frame_err, stat.rx_over_err,
                              stat.rx_crc_err, stat.collisions))
            self.logger.debug('PortStats: %s', ports)
    """
    @classmethod
    def parser(cls, buf, offset):
        port = struct.unpack_from(ofproto_v1_2.OFP_PORT_STATS_PACK_STR,
                                  buf, offset)
        stats = cls(*port)
        stats.length = ofproto_v1_2.OFP_PORT_STATS_SIZE
        return stats


@_set_msg_type(ofproto_v1_2.OFPT_STATS_REQUEST)
class OFPQueueStatsRequest(OFPStatsRequest):
    """
    Queue statistics request message

    The controller uses this message to query queue statictics.

    ================ ======================================================
    Attribute        Description
    ================ ======================================================
    port_no          Port number to read
    queue_id         ID of queue to read
    flags            Zero (none yet defined in the spec)
    ================ ======================================================

    Example::

        def send_queue_stats_request(self, datapath):
            ofp = datapath.ofproto
            ofp_parser = datapath.ofproto_parser

            req = ofp_parser.OFPQueueStatsRequest(datapath, ofp.OFPP_ANY,
                                                  ofp.OFPQ_ALL)
            datapath.send_msg(req)
    """
    def __init__(self, datapath, port_no, queue_id, flags=0):
        super(OFPQueueStatsRequest, self).__init__(datapath,
                                                   ofproto_v1_2.OFPST_QUEUE,
                                                   flags)
        self.port_no = port_no
        self.queue_id = queue_id

    def _serialize_stats_body(self):
        msg_pack_into(ofproto_v1_2.OFP_QUEUE_STATS_REQUEST_PACK_STR,
                      self.buf, ofproto_v1_2.OFP_STATS_REQUEST_SIZE,
                      self.port_no, self.queue_id)


@OFPStatsReply.register_stats_reply_type(ofproto_v1_2.OFPST_QUEUE)
class OFPQueueStats(
    ofproto_parser.namedtuple('OFPQueueStats',
                              ('port_no', 'queue_id', 'tx_bytes',
                               'tx_packets', 'tx_errors'))):
    """
    Queue statistics reply message

    The switch responds with a stats reply that include this message to
    an aggregate flow statistics request.

    ================ ======================================================
    Attribute        Description
    ================ ======================================================
    port_no          Port number
    queue_id         ID of queue
    tx_bytes         Number of transmitted bytes
    tx_packets       Number of transmitted packets
    tx_errors        Number of packets dropped due to overrun
    ================ ======================================================

    Example::

        @set_ev_cls(ofp_event.EventOFPStatsReply, MAIN_DISPATCHER)
        def stats_reply_handler(self, ev):
            msg = ev.msg
            ofp = msg.datapath.ofproto
            body = ev.msg.body

            if msg.type == ofp.OFPST_QUEUE:
                self.queue_stats_reply_handler(body)

        def queue_stats_reply_handler(self, body):
            queues = []
            for stat in body:
                queues.append('port_no=%d queue_id=%d '
                              'tx_bytes=%d tx_packets=%d tx_errors=%d ' %
                              (stat.port_no, stat.queue_id,
                               stat.tx_bytes, stat.tx_packets, stat.tx_errors))
            self.logger.debug('QueueStats: %s', queues)
    """
    @classmethod
    def parser(cls, buf, offset):
        queue = struct.unpack_from(ofproto_v1_2.OFP_QUEUE_STATS_PACK_STR,
                                   buf, offset)
        stats = cls(*queue)
        stats.length = ofproto_v1_2.OFP_QUEUE_STATS_SIZE
        return stats


class OFPBucketCounter(StringifyMixin):
    def __init__(self, packet_count, byte_count):
        super(OFPBucketCounter, self).__init__()
        self.packet_count = packet_count
        self.byte_count = byte_count

    @classmethod
    def parser(cls, buf, offset):
        packet, byte = struct.unpack_from(
            ofproto_v1_2.OFP_BUCKET_COUNTER_PACK_STR,
            buf, offset)
        return cls(packet, byte)


@_set_msg_type(ofproto_v1_2.OFPT_STATS_REQUEST)
class OFPGroupStatsRequest(OFPStatsRequest):
    """
    Group statistics request message

    The controller uses this message to query statistics of one or more
    groups.

    ================ ======================================================
    Attribute        Description
    ================ ======================================================
    group_id         ID of group to read (OFPG_ALL to all groups)
    flags            Zero (none yet defined in the spec)
    ================ ======================================================

    Example::

        def send_group_stats_request(self, datapath):
            ofp = datapath.ofproto
            ofp_parser = datapath.ofproto_parser

            req = ofp_parser.OFPGroupStatsRequest(datapath, ofp.OFPG_ALL)
            datapath.send_msg(req)
    """
    def __init__(self, datapath, group_id, flags=0):
        super(OFPGroupStatsRequest, self).__init__(datapath,
                                                   ofproto_v1_2.OFPST_GROUP,
                                                   flags)
        self.group_id = group_id

    def _serialize_stats_body(self):
        msg_pack_into(ofproto_v1_2.OFP_GROUP_STATS_REQUEST_PACK_STR,
                      self.buf, ofproto_v1_2.OFP_STATS_REQUEST_SIZE,
                      self.group_id)


@OFPStatsReply.register_stats_reply_type(ofproto_v1_2.OFPST_GROUP)
class OFPGroupStats(StringifyMixin):
    """
    Group statistics reply message

    The switch responds with a stats reply that include this message to
    a group statistics request.

    ================ ======================================================
    Attribute        Description
    ================ ======================================================
    group_id         Group identifier
    ref_count        Number of flows or groups that directly forward to
                     this group
    packet_count     Number of packets processed by group
    byte_count       Number of bytes processed by group
    bucket_counters  List of ``OFPBucketCounter`` instance
    ================ ======================================================

    Example::

        @set_ev_cls(ofp_event.EventOFPStatsReply, MAIN_DISPATCHER)
        def stats_reply_handler(self, ev):
            msg = ev.msg
            ofp = msg.datapath.ofproto
            body = ev.msg.body

            if msg.type == ofp.OFPST_GROUP:
                self.group_stats_reply_handler(body)

        def group_stats_reply_handler(self, body):
            groups = []
            for stat in body:
                groups.append('group_id=%d ref_count=%d packet_count=%d '
                              'byte_count=%d bucket_counters=%s' %
                              (stat.group_id,
                               stat.ref_count, stat.packet_count,
                               stat.byte_count, stat.bucket_counters))
            self.logger.debug('GroupStats: %s', groups)
    """

    def __init__(self, group_id, ref_count, packet_count,
                 byte_count, bucket_counters):
        super(OFPGroupStats, self).__init__()
        self.group_id = group_id
        self.ref_count = ref_count
        self.packet_count = packet_count
        self.byte_count = byte_count
        self.bucket_counters = bucket_counters

    @classmethod
    def parser(cls, buf, offset):
        (length, group_id, ref_count, packet_count,
         byte_count) = struct.unpack_from(
            ofproto_v1_2.OFP_GROUP_STATS_PACK_STR,
            buf, offset)

        bucket_len = length - ofproto_v1_2.OFP_GROUP_STATS_SIZE
        offset += ofproto_v1_2.OFP_GROUP_STATS_SIZE
        bucket_counters = []
        while bucket_len > 0:
            bucket_counters.append(OFPBucketCounter.parser(buf, offset))
            offset += ofproto_v1_2.OFP_BUCKET_COUNTER_SIZE
            bucket_len -= ofproto_v1_2.OFP_BUCKET_COUNTER_SIZE

        o = cls(group_id, ref_count, packet_count,
                byte_count, bucket_counters)
        o.length = length
        return o


@_set_msg_type(ofproto_v1_2.OFPT_STATS_REQUEST)
class OFPGroupDescStatsRequest(OFPStatsRequest):
    """
    Group description request message

    The controller uses this message to list the set of groups on a switch.

    ================ ======================================================
    Attribute        Description
    ================ ======================================================
    flags            Zero (none yet defined in the spec)
    ================ ======================================================

    Example::

        def send_group_desc_stats_request(self, datapath):
            ofp = datapath.ofproto
            ofp_parser = datapath.ofproto_parser

            req = ofp_parser.OFPGroupDescStatsRequest(datapath)
            datapath.send_msg(req)
    """
    def __init__(self, datapath, flags=0):
        super(OFPGroupDescStatsRequest, self).__init__(
            datapath,
            ofproto_v1_2.OFPST_GROUP_DESC,
            flags)


@OFPStatsReply.register_stats_reply_type(ofproto_v1_2.OFPST_GROUP_DESC)
class OFPGroupDescStats(StringifyMixin):
    """
    Group description reply message

    The switch responds with a stats reply that include this message to
    a group description request.

    ================ ======================================================
    Attribute        Description
    ================ ======================================================
    type             One of OFPGT_*
    group_id         Group identifier
    buckets          List of ``OFPBucket`` instance
    ================ ======================================================

    ``type`` attribute corresponds to ``type_`` parameter of __init__.

    Example::

        @set_ev_cls(ofp_event.EventOFPStatsReply, MAIN_DISPATCHER)
        def stats_reply_handler(self, ev):
            msg = ev.msg
            ofp = msg.datapath.ofproto
            body = ev.msg.body

            if msg.type == ofp.OFPST_GROUP_DESC:
                self.group_desc_stats_reply_handler(body)

        def group_desc_stats_reply_handler(self, body):
            descs = []
            for stat in body:
                descs.append('type=%d group_id=%d buckets=%s' %
                             (stat.type, stat.group_id, stat.buckets))
            self.logger.debug('GroupDescStats: %s', descs)
    """
    def __init__(self, type_, group_id, buckets, length=None):
        self.type = type_
        self.group_id = group_id
        self.buckets = buckets

    @classmethod
    def parser(cls, buf, offset):
        (length, type_, group_id) = struct.unpack_from(
            ofproto_v1_2.OFP_GROUP_DESC_STATS_PACK_STR,
            buf, offset)

        bucket_len = length - ofproto_v1_2.OFP_GROUP_DESC_STATS_SIZE
        offset += ofproto_v1_2.OFP_GROUP_DESC_STATS_SIZE
        buckets = []
        while bucket_len > 0:
            bucket = OFPBucket.parser(buf, offset)
            buckets.append(bucket)
            offset += bucket.len
            bucket_len -= bucket.len

        o = cls(type_, group_id, buckets)
        o.length = length
        return o


@_set_msg_type(ofproto_v1_2.OFPT_STATS_REQUEST)
class OFPGroupFeaturesStatsRequest(OFPStatsRequest):
    """
    Group features request message

    The controller uses this message to list the capabilities of groups on
    a switch.

    ================ ======================================================
    Attribute        Description
    ================ ======================================================
    flags            Zero (none yet defined in the spec)
    ================ ======================================================

    Example::

        def send_group_features_stats_request(self, datapath):
            ofp = datapath.ofproto
            ofp_parser = datapath.ofproto_parser

            req = ofp_parser.OFPGroupFeaturesStatsRequest(datapath)
            datapath.send_msg(req)
    """
    def __init__(self, datapath, flags=0):
        super(OFPGroupFeaturesStatsRequest, self).__init__(
            datapath,
            ofproto_v1_2.OFPST_GROUP_FEATURES,
            flags)


@OFPStatsReply.register_stats_reply_type(ofproto_v1_2.OFPST_GROUP_FEATURES,
                                         body_single_struct=True)
class OFPGroupFeaturesStats(StringifyMixin):
    """
    Group features reply message

    The switch responds with a stats reply that include this message to
    a group features request.

    ================ ======================================================
    Attribute        Description
    ================ ======================================================
    types            Bitmap of OFPGT_* values supported
    capabilities     Bitmap of OFPGFC_* capability supported
    max_groups       Maximum number of groups for each type
    actions          Bitmaps of OFPAT_* that are supported
    ================ ======================================================

    Example::

        @set_ev_cls(ofp_event.EventOFPStatsReply, MAIN_DISPATCHER)
        def stats_reply_handler(self, ev):
            msg = ev.msg
            ofp = msg.datapath.ofproto
            body = ev.msg.body

            if msg.type == ofp.OFPST_GROUP_FEATURES:
                self.group_features_stats_reply_handler(body)

        def group_features_stats_reply_handler(self, body):
            self.logger.debug('GroupFeaturesStats: types=%d '
                              'capabilities=0x%08x max_groups=%s '
                              'actions=%s',
                              body.types, body.capabilities, body.max_groups,
                              body.actions)
    """
    def __init__(self, types, capabilities, max_groups, actions, length=None):
        self.types = types
        self.capabilities = capabilities
        self.max_groups = max_groups
        self.actions = actions

    @classmethod
    def parser(cls, buf, offset):
        stats = struct.unpack_from(
            ofproto_v1_2.OFP_GROUP_FEATURES_STATS_PACK_STR, buf, offset)
        types = stats[0]
        capabilities = stats[1]
        max_groups = list(stats[2:6])
        actions = list(stats[6:10])

        o = cls(types, capabilities, max_groups, actions)
        o.length = ofproto_v1_2.OFP_GROUP_FEATURES_STATS_SIZE
        return o


@_set_msg_type(ofproto_v1_2.OFPT_QUEUE_GET_CONFIG_REQUEST)
class OFPQueueGetConfigRequest(MsgBase):
    """
    Queue configuration request message

    ================ ======================================================
    Attribute        Description
    ================ ======================================================
    port             Port to be queried (OFPP_ANY to all configured queues)
    ================ ======================================================

    Example::

        def send_queue_get_config_request(self, datapath):
            ofp = datapath.ofproto
            ofp_parser = datapath.ofproto_parser

            req = ofp_parser.OFPQueueGetConfigRequest(datapath, ofp.OFPP_ANY)
            datapath.send_msg(req)
    """
    def __init__(self, datapath, port):
        super(OFPQueueGetConfigRequest, self).__init__(datapath)
        self.port = port

    def _serialize_body(self):
        msg_pack_into(ofproto_v1_2.OFP_QUEUE_GET_CONFIG_REQUEST_PACK_STR,
                      self.buf, ofproto_v1_2.OFP_HEADER_SIZE, self.port)


class OFPQueuePropHeader(StringifyMixin):
    def __init__(self, property_, len_=None):
        self.property = property_
        self.len = len_

    def serialize(self, buf, offset):
        msg_pack_into(ofproto_v1_2.OFP_QUEUE_PROP_HEADER_PACK_STR,
                      buf, offset, self.property, self.len)


class OFPQueueProp(OFPQueuePropHeader):
    _QUEUE_PROP_PROPERTIES = {}

    @staticmethod
    def register_property(property_, len_):
        def _register_property(cls):
            cls.cls_property = property_
            cls.cls_len = len_
            OFPQueueProp._QUEUE_PROP_PROPERTIES[cls.cls_property] = cls
            return cls
        return _register_property

    def __init__(self):
        cls = self.__class__
        super(OFPQueueProp, self).__init__(cls.cls_property,
                                           cls.cls_len)

    @classmethod
    def parser(cls, buf, offset):
        (property_, len_) = struct.unpack_from(
            ofproto_v1_2.OFP_QUEUE_PROP_HEADER_PACK_STR,
            buf, offset)
        cls_ = cls._QUEUE_PROP_PROPERTIES.get(property_)
        offset += ofproto_v1_2.OFP_QUEUE_PROP_HEADER_SIZE
        return cls_.parser(buf, offset)


class OFPPacketQueue(StringifyMixin):
    def __init__(self, queue_id, port, properties, len_=None):
        super(OFPPacketQueue, self).__init__()
        self.queue_id = queue_id
        self.port = port
        self.len = len_
        self.properties = properties

    @classmethod
    def parser(cls, buf, offset):
        (queue_id, port, len_) = struct.unpack_from(
            ofproto_v1_2.OFP_PACKET_QUEUE_PACK_STR, buf, offset)
        length = ofproto_v1_2.OFP_PACKET_QUEUE_SIZE
        offset += ofproto_v1_2.OFP_PACKET_QUEUE_SIZE
        properties = []
        while length < len_:
            queue_prop = OFPQueueProp.parser(buf, offset)
            properties.append(queue_prop)
            offset += queue_prop.len
            length += queue_prop.len
        o = cls(queue_id, port, properties)
        o.len = len_
        return o


@OFPQueueProp.register_property(ofproto_v1_2.OFPQT_MIN_RATE,
                                ofproto_v1_2.OFP_QUEUE_PROP_MIN_RATE_SIZE)
class OFPQueuePropMinRate(OFPQueueProp):
    def __init__(self, rate, property_=None, len_=None):
        super(OFPQueuePropMinRate, self).__init__()
        self.rate = rate

    @classmethod
    def parser(cls, buf, offset):
        (rate,) = struct.unpack_from(
            ofproto_v1_2.OFP_QUEUE_PROP_MIN_RATE_PACK_STR, buf, offset)
        return cls(rate)


@OFPQueueProp.register_property(ofproto_v1_2.OFPQT_MAX_RATE,
                                ofproto_v1_2.OFP_QUEUE_PROP_MAX_RATE_SIZE)
class OFPQueuePropMaxRate(OFPQueueProp):
    def __init__(self, rate, property_=None, len_=None):
        super(OFPQueuePropMaxRate, self).__init__()
        self.rate = rate

    @classmethod
    def parser(cls, buf, offset):
        (rate,) = struct.unpack_from(
            ofproto_v1_2.OFP_QUEUE_PROP_MAX_RATE_PACK_STR, buf, offset)
        return cls(rate)


@_register_parser
@_set_msg_type(ofproto_v1_2.OFPT_QUEUE_GET_CONFIG_REPLY)
class OFPQueueGetConfigReply(MsgBase):
    """
    Queue configuration reply message

    The switch responds with this message to a queue configuration request.

    ================ ======================================================
    Attribute        Description
    ================ ======================================================
    port             Port which was queried
    queues           list of ``OFPPacketQueue`` instance
    ================ ======================================================

    Example::

        @set_ev_cls(ofp_event.EventOFPQueueGetConfigReply, MAIN_DISPATCHER)
        def queue_get_config_reply_handler(self, ev):
            msg = ev.msg

            self.logger.debug('OFPQueueGetConfigReply received: '
                              'port=%s queues=%s',
                              msg.port, msg.queues)
    """
    def __init__(self, datapath, port=None, queues=None):
        super(OFPQueueGetConfigReply, self).__init__(datapath)
        self.port = port
        self.queues = queues

    @classmethod
    def parser(cls, datapath, version, msg_type, msg_len, xid, buf):
        msg = super(OFPQueueGetConfigReply, cls).parser(datapath, version,
                                                        msg_type,
                                                        msg_len, xid, buf)
        (msg.port,) = struct.unpack_from(
            ofproto_v1_2.OFP_QUEUE_GET_CONFIG_REPLY_PACK_STR, msg.buf,
            ofproto_v1_2.OFP_HEADER_SIZE)

        msg.queues = []
        length = ofproto_v1_2.OFP_QUEUE_GET_CONFIG_REPLY_SIZE
        offset = ofproto_v1_2.OFP_QUEUE_GET_CONFIG_REPLY_SIZE
        while length < msg.msg_len:
            queue = OFPPacketQueue.parser(msg.buf, offset)
            msg.queues.append(queue)

            offset += queue.len
            length += queue.len

        return msg


@_set_msg_type(ofproto_v1_2.OFPT_BARRIER_REQUEST)
class OFPBarrierRequest(MsgBase):
    """
    Barrier request message

    The controller sends this message to ensure message dependencies have
    been met or receive notifications for completed operations.

    Example::

        def send_barrier_request(self, datapath):
            ofp_parser = datapath.ofproto_parser

            req = ofp_parser.OFPBarrierRequest(datapath)
            datapath.send_msg(req)
    """
    def __init__(self, datapath):
        super(OFPBarrierRequest, self).__init__(datapath)


@_register_parser
@_set_msg_type(ofproto_v1_2.OFPT_BARRIER_REPLY)
class OFPBarrierReply(MsgBase):
    """
    Barrier reply message

    The switch responds with this message to a barrier request.

    Example::

        @set_ev_cls(ofp_event.EventOFPBarrierReply, MAIN_DISPATCHER)
        def barrier_reply_handler(self, ev):
            self.logger.debug('OFPBarrierReply received')
    """
    def __init__(self, datapath):
        super(OFPBarrierReply, self).__init__(datapath)


@_set_msg_type(ofproto_v1_2.OFPT_ROLE_REQUEST)
class OFPRoleRequest(MsgBase):
    """
    Role request message

    The controller uses this message to change its role.

    ================ ======================================================
    Attribute        Description
    ================ ======================================================
    role             One of the following values.
                     OFPCR_ROLE_NOCHANGE
                     OFPCR_ROLE_EQUAL
                     OFPCR_ROLE_MASTER
                     OFPCR_ROLE_SLAVE
    generation_id    Master Election Generation ID
    ================ ======================================================

    Example::

        def send_role_request(self, datapath):
            ofp = datapath.ofproto
            ofp_parser = datapath.ofproto_parser

            req = ofp_parser.OFPRoleRequest(datapath, ofp.OFPCR_ROLE_EQUAL, 0)
            datapath.send_msg(req)
    """
    def __init__(self, datapath, role, generation_id):
        super(OFPRoleRequest, self).__init__(datapath)
        self.role = role
        self.generation_id = generation_id

    def _serialize_body(self):
        msg_pack_into(ofproto_v1_2.OFP_ROLE_REQUEST_PACK_STR,
                      self.buf, ofproto_v1_2.OFP_HEADER_SIZE,
                      self.role, self.generation_id)


@_register_parser
@_set_msg_type(ofproto_v1_2.OFPT_ROLE_REPLY)
class OFPRoleReply(MsgBase):
    """
    Role reply message

    The switch responds with this message to a role request.

    ================ ======================================================
    Attribute        Description
    ================ ======================================================
    role             One of the following values.
                     OFPCR_ROLE_NOCHANGE
                     OFPCR_ROLE_EQUAL
                     OFPCR_ROLE_MASTER
                     OFPCR_ROLE_SLAVE
    generation_id    Master Election Generation ID
    ================ ======================================================

    Example::

        @set_ev_cls(ofp_event.EventOFPRoleReply, MAIN_DISPATCHER)
        def role_reply_handler(self, ev):
            msg = ev.msg
            ofp = dp.ofproto

            if msg.role == ofp.OFPCR_ROLE_NOCHANGE:
                role = 'NOCHANGE'
            elif msg.role == ofp.OFPCR_ROLE_EQUAL:
                role = 'EQUAL'
            elif msg.role == ofp.OFPCR_ROLE_MASTER:
                role = 'MASTER'
            elif msg.role == ofp.OFPCR_ROLE_SLAVE:
                role = 'SLAVE'
            else:
                role = 'unknown'

            self.logger.debug('OFPRoleReply received: '
                              'role=%s generation_id=%d',
                              role, msg.generation_id)
    """
    def __init__(self, datapath, role=None, generation_id=None):
        super(OFPRoleReply, self).__init__(datapath)
        self.role = role
        self.generation_id = generation_id

    @classmethod
    def parser(cls, datapath, version, msg_type, msg_len, xid, buf):
        msg = super(OFPRoleReply, cls).parser(datapath, version,
                                              msg_type,
                                              msg_len, xid, buf)
        (msg.role, msg.generation_id) = struct.unpack_from(
            ofproto_v1_2.OFP_ROLE_REQUEST_PACK_STR, msg.buf,
            ofproto_v1_2.OFP_HEADER_SIZE)

        return msg


UINT64_MAX = (1 << 64) - 1
UINT32_MAX = (1 << 32) - 1
UINT16_MAX = (1 << 16) - 1


class Flow(object):
    def __init__(self):
        self.in_port = 0
        self.in_phy_port = 0
        self.metadata = 0
        self.dl_dst = mac.DONTCARE
        self.dl_src = mac.DONTCARE
        self.dl_type = 0
        self.vlan_vid = 0
        self.vlan_pcp = 0
        self.ip_dscp = 0
        self.ip_ecn = 0
        self.ip_proto = 0
        self.ipv4_src = 0
        self.ipv4_dst = 0
        self.tcp_src = 0
        self.tcp_dst = 0
        self.udp_src = 0
        self.udp_dst = 0
        self.sctp_src = 0
        self.sctp_dst = 0
        self.icmpv4_type = 0
        self.icmpv4_code = 0
        self.arp_op = 0
        self.arp_spa = 0
        self.arp_tpa = 0
        self.arp_sha = 0
        self.arp_tha = 0
        self.ipv6_src = []
        self.ipv6_dst = []
        self.ipv6_flabel = 0
        self.icmpv6_type = 0
        self.icmpv6_code = 0
        self.ipv6_nd_target = []
        self.ipv6_nd_sll = 0
        self.ipv6_nd_tll = 0
        self.mpls_label = 0
        self.mpls_tc = 0


class FlowWildcards(object):
    def __init__(self):
        self.metadata_mask = 0
        self.dl_dst_mask = 0
        self.dl_src_mask = 0
        self.vlan_vid_mask = 0
        self.ipv4_src_mask = 0
        self.ipv4_dst_mask = 0
        self.arp_spa_mask = 0
        self.arp_tpa_mask = 0
        self.arp_sha_mask = 0
        self.arp_tha_mask = 0
        self.ipv6_src_mask = []
        self.ipv6_dst_mask = []
        self.ipv6_flabel_mask = 0
        self.wildcards = (1 << 64) - 1

    def ft_set(self, shift):
        self.wildcards &= ~(1 << shift)

    def ft_test(self, shift):
        return not self.wildcards & (1 << shift)


class OFPMatch(StringifyMixin):
    """
    Flow Match Structure

    This class is implementation of the flow match structure having
    compose/query API.
    There are new API and old API for compatibility. the old API is
    supposed to be removed later.

    You can define the flow match by the keyword arguments.
    The following arguments are available.

    ================ =============== ==================================
    Argument         Value           Description
    ================ =============== ==================================
    in_port          Integer 32bit   Switch input port
    in_phy_port      Integer 32bit   Switch physical input port
    metadata         Integer 64bit   Metadata passed between tables
    eth_dst          MAC address     Ethernet destination address
    eth_src          MAC address     Ethernet source address
    eth_type         Integer 16bit   Ethernet frame type
    vlan_vid         Integer 16bit   VLAN id
    vlan_pcp         Integer 8bit    VLAN priority
    ip_dscp          Integer 8bit    IP DSCP (6 bits in ToS field)
    ip_ecn           Integer 8bit    IP ECN (2 bits in ToS field)
    ip_proto         Integer 8bit    IP protocol
    ipv4_src         IPv4 address    IPv4 source address
    ipv4_dst         IPv4 address    IPv4 destination address
    tcp_src          Integer 16bit   TCP source port
    tcp_dst          Integer 16bit   TCP destination port
    udp_src          Integer 16bit   UDP source port
    udp_dst          Integer 16bit   UDP destination port
    sctp_src         Integer 16bit   SCTP source port
    sctp_dst         Integer 16bit   SCTP destination port
    icmpv4_type      Integer 8bit    ICMP type
    icmpv4_code      Integer 8bit    ICMP code
    arp_op           Integer 16bit   ARP opcode
    arp_spa          IPv4 address    ARP source IPv4 address
    arp_tpa          IPv4 address    ARP target IPv4 address
    arp_sha          MAC address     ARP source hardware address
    arp_tha          MAC address     ARP target hardware address
    ipv6_src         IPv6 address    IPv6 source address
    ipv6_dst         IPv6 address    IPv6 destination address
    ipv6_flabel      Integer 32bit   IPv6 Flow Label
    icmpv6_type      Integer 8bit    ICMPv6 type
    icmpv6_code      Integer 8bit    ICMPv6 code
    ipv6_nd_target   IPv6 address    Target address for ND
    ipv6_nd_sll      MAC address     Source link-layer for ND
    ipv6_nd_tll      MAC address     Target link-layer for ND
    mpls_label       Integer 32bit   MPLS label
    mpls_tc          Integer 8bit    MPLS TC
    ================ =============== ==================================

    Example::

        >>> # compose
        >>> match = parser.OFPMatch(
        ...     in_port=1,
        ...     eth_type=0x86dd,
        ...     ipv6_src=('2001:db8:bd05:1d2:288a:1fc0:1:10ee',
        ...               'ffff:ffff:ffff:ffff::'),
        ...     ipv6_dst='2001:db8:bd05:1d2:288a:1fc0:1:10ee')
        >>> # query
        >>> if 'ipv6_src' in match:
        ...     print match['ipv6_src']
        ...
        ('2001:db8:bd05:1d2:288a:1fc0:1:10ee', 'ffff:ffff:ffff:ffff::')
    """

    def __init__(self, type_=None, length=None, _ordered_fields=None,
                 **kwargs):
        super(OFPMatch, self).__init__()
        self._wc = FlowWildcards()
        self._flow = Flow()
        self.fields = []
        self.type = ofproto_v1_2.OFPMT_OXM
        self.length = length

        if not _ordered_fields is None:
            assert not kwargs
            self._fields2 = _ordered_fields
        else:
            # eg.
            #   OFPMatch(eth_src=('ff:ff:ff:00:00:00'), eth_type=0x800,
            #            ipv4_src='10.0.0.1')
            kwargs = dict(ofproto_v1_2.oxm_normalize_user(k, v) for
                          (k, v) in kwargs.iteritems())
            fields = [ofproto_v1_2.oxm_from_user(k, v) for (k, v)
                      in kwargs.iteritems()]
            # assumption: sorting by OXM type values makes fields
            # meet ordering requirements (eg. eth_type before ipv4_src)
            fields.sort()
            self._fields2 = [ofproto_v1_2.oxm_to_user(n, v, m) for (n, v, m)
                             in fields]

    def __getitem__(self, key):
        return dict(self._fields2)[key]

    def __contains__(self, key):
        return key in dict(self._fields2)

    def iteritems(self):
        return dict(self._fields2).iteritems()

    def get(self, key, default=None):
        return dict(self._fields2).get(key, default)

    def stringify_attrs(self):
        yield "oxm_fields", dict(self._fields2)

    def to_jsondict(self):
        """
        Returns a dict expressing the flow match.
        """
        # XXX old api compat
        if self._composed_with_old_api():
            # copy object first because serialize_old is destructive
            o2 = OFPMatch()
            o2.fields = self.fields[:]
            # serialize and parse to fill OFPMatch._fields2
            buf = bytearray()
            o2.serialize(buf, 0)
            o = OFPMatch.parser(str(buf), 0)
        else:
            o = self

        body = {"oxm_fields": [ofproto_v1_2.oxm_to_jsondict(k, uv) for k, uv
                               in o._fields2],
                "length": o.length,
                "type": o.type}
        return {self.__class__.__name__: body}

    @classmethod
    def from_jsondict(cls, dict_):
        """
        Returns an object which is generated from a dict.

        Exception raises:
        KeyError -- Unknown match field is defined in dict
        """
        fields = [ofproto_v1_2.oxm_from_jsondict(f) for f
                  in dict_['oxm_fields']]
        o = OFPMatch(_ordered_fields=fields)
        # XXX old api compat
        # serialize and parse to fill OFPMatch.fields
        buf = bytearray()
        o.serialize(buf, 0)
        return OFPMatch.parser(str(buf), 0)

    def __str__(self):
        # XXX old api compat
        if self._composed_with_old_api():
            # copy object first because serialize_old is destructive
            o2 = OFPMatch()
            o2.fields = self.fields[:]
            # serialize and parse to fill OFPMatch._fields2
            buf = bytearray()
            o2.serialize(buf, 0)
            o = OFPMatch.parser(str(buf), 0)
        else:
            o = self
        return super(OFPMatch, o).__str__()

    __repr__ = __str__

    def append_field(self, header, value, mask=None):
        """
        Append a match field.

        ========= =======================================================
        Argument  Description
        ========= =======================================================
        header    match field header ID which is defined automatically in
                  ``ofproto_v1_3``
        value     match field value
        mask      mask value to the match field
        ========= =======================================================

        The available ``header`` is as follows.

        ====================== ===================================
        Header ID              Description
        ====================== ===================================
        OXM_OF_IN_PORT         Switch input port
        OXM_OF_IN_PHY_PORT     Switch physical input port
        OXM_OF_METADATA        Metadata passed between tables
        OXM_OF_ETH_DST         Ethernet destination address
        OXM_OF_ETH_SRC         Ethernet source address
        OXM_OF_ETH_TYPE        Ethernet frame type
        OXM_OF_VLAN_VID        VLAN id
        OXM_OF_VLAN_PCP        VLAN priority
        OXM_OF_IP_DSCP         IP DSCP (6 bits in ToS field)
        OXM_OF_IP_ECN          IP ECN (2 bits in ToS field)
        OXM_OF_IP_PROTO        IP protocol
        OXM_OF_IPV4_SRC        IPv4 source address
        OXM_OF_IPV4_DST        IPv4 destination address
        OXM_OF_TCP_SRC         TCP source port
        OXM_OF_TCP_DST         TCP destination port
        OXM_OF_UDP_SRC         UDP source port
        OXM_OF_UDP_DST         UDP destination port
        OXM_OF_SCTP_SRC        SCTP source port
        OXM_OF_SCTP_DST        SCTP destination port
        OXM_OF_ICMPV4_TYPE     ICMP type
        OXM_OF_ICMPV4_CODE     ICMP code
        OXM_OF_ARP_OP          ARP opcode
        OXM_OF_ARP_SPA         ARP source IPv4 address
        OXM_OF_ARP_TPA         ARP target IPv4 address
        OXM_OF_ARP_SHA         ARP source hardware address
        OXM_OF_ARP_THA         ARP target hardware address
        OXM_OF_IPV6_SRC        IPv6 source address
        OXM_OF_IPV6_DST        IPv6 destination address
        OXM_OF_IPV6_FLABEL     IPv6 Flow Label
        OXM_OF_ICMPV6_TYPE     ICMPv6 type
        OXM_OF_ICMPV6_CODE     ICMPv6 code
        OXM_OF_IPV6_ND_TARGET  Target address for ND
        OXM_OF_IPV6_ND_SLL     Source link-layer for ND
        OXM_OF_IPV6_ND_TLL     Target link-layer for ND
        OXM_OF_MPLS_LABEL      MPLS label
        OXM_OF_MPLS_TC         MPLS TC
        ====================== ===================================
        """
        self.fields.append(OFPMatchField.make(header, value, mask))

    def _composed_with_old_api(self):
        return (self.fields and not self._fields2) or \
            self._wc.__dict__ != FlowWildcards().__dict__

    def serialize(self, buf, offset):
        """
        Outputs the expression of the wire protocol of the flow match into
        the buf.
        Returns the output length.
        """
        # XXX compat
        if self._composed_with_old_api():
            return self.serialize_old(buf, offset)

        fields = [ofproto_v1_2.oxm_from_user(k, uv) for (k, uv)
                  in self._fields2]

        hdr_pack_str = '!HH'
        field_offset = offset + struct.calcsize(hdr_pack_str)
        for (n, value, mask) in fields:
            field_offset += ofproto_v1_2.oxm_serialize(n, value, mask, buf,
                                                       field_offset)

        length = field_offset - offset
        msg_pack_into(hdr_pack_str, buf, offset,
                      ofproto_v1_2.OFPMT_OXM, length)
        self.length = length

        pad_len = utils.round_up(length, 8) - length
        ofproto_parser.msg_pack_into("%dx" % pad_len, buf, field_offset)

        return length + pad_len

    def serialize_old(self, buf, offset):
        if hasattr(self, '_serialized'):
            raise Exception('serializing an OFPMatch composed with '
                            'old API multiple times is not supported')
        self._serialized = True

        if self._wc.ft_test(ofproto_v1_2.OFPXMT_OFB_IN_PORT):
            self.append_field(ofproto_v1_2.OXM_OF_IN_PORT,
                              self._flow.in_port)

        if self._wc.ft_test(ofproto_v1_2.OFPXMT_OFB_IN_PHY_PORT):
            self.append_field(ofproto_v1_2.OXM_OF_IN_PHY_PORT,
                              self._flow.in_phy_port)

        if self._wc.ft_test(ofproto_v1_2.OFPXMT_OFB_METADATA):
            if self._wc.metadata_mask == UINT64_MAX:
                header = ofproto_v1_2.OXM_OF_METADATA
            else:
                header = ofproto_v1_2.OXM_OF_METADATA_W
            self.append_field(header, self._flow.metadata,
                              self._wc.metadata_mask)

        if self._wc.ft_test(ofproto_v1_2.OFPXMT_OFB_ETH_DST):
            if self._wc.dl_dst_mask:
                header = ofproto_v1_2.OXM_OF_ETH_DST_W
            else:
                header = ofproto_v1_2.OXM_OF_ETH_DST
            self.append_field(header, self._flow.dl_dst, self._wc.dl_dst_mask)

        if self._wc.ft_test(ofproto_v1_2.OFPXMT_OFB_ETH_SRC):
            if self._wc.dl_src_mask:
                header = ofproto_v1_2.OXM_OF_ETH_SRC_W
            else:
                header = ofproto_v1_2.OXM_OF_ETH_SRC
            self.append_field(header, self._flow.dl_src, self._wc.dl_src_mask)

        if self._wc.ft_test(ofproto_v1_2.OFPXMT_OFB_ETH_TYPE):
            self.append_field(ofproto_v1_2.OXM_OF_ETH_TYPE, self._flow.dl_type)

        if self._wc.ft_test(ofproto_v1_2.OFPXMT_OFB_VLAN_VID):
            if self._wc.vlan_vid_mask == UINT16_MAX:
                header = ofproto_v1_2.OXM_OF_VLAN_VID
            else:
                header = ofproto_v1_2.OXM_OF_VLAN_VID_W
            self.append_field(header, self._flow.vlan_vid,
                              self._wc.vlan_vid_mask)

        if self._wc.ft_test(ofproto_v1_2.OFPXMT_OFB_VLAN_PCP):
            self.append_field(ofproto_v1_2.OXM_OF_VLAN_PCP,
                              self._flow.vlan_pcp)

        if self._wc.ft_test(ofproto_v1_2.OFPXMT_OFB_IP_DSCP):
            self.append_field(ofproto_v1_2.OXM_OF_IP_DSCP, self._flow.ip_dscp)

        if self._wc.ft_test(ofproto_v1_2.OFPXMT_OFB_IP_ECN):
            self.append_field(ofproto_v1_2.OXM_OF_IP_ECN, self._flow.ip_ecn)

        if self._wc.ft_test(ofproto_v1_2.OFPXMT_OFB_IP_PROTO):
            self.append_field(ofproto_v1_2.OXM_OF_IP_PROTO,
                              self._flow.ip_proto)

        if self._wc.ft_test(ofproto_v1_2.OFPXMT_OFB_IPV4_SRC):
            if self._wc.ipv4_src_mask == UINT32_MAX:
                header = ofproto_v1_2.OXM_OF_IPV4_SRC
            else:
                header = ofproto_v1_2.OXM_OF_IPV4_SRC_W
            self.append_field(header, self._flow.ipv4_src,
                              self._wc.ipv4_src_mask)

        if self._wc.ft_test(ofproto_v1_2.OFPXMT_OFB_IPV4_DST):
            if self._wc.ipv4_dst_mask == UINT32_MAX:
                header = ofproto_v1_2.OXM_OF_IPV4_DST
            else:
                header = ofproto_v1_2.OXM_OF_IPV4_DST_W
            self.append_field(header, self._flow.ipv4_dst,
                              self._wc.ipv4_dst_mask)

        if self._wc.ft_test(ofproto_v1_2.OFPXMT_OFB_TCP_SRC):
            self.append_field(ofproto_v1_2.OXM_OF_TCP_SRC, self._flow.tcp_src)

        if self._wc.ft_test(ofproto_v1_2.OFPXMT_OFB_TCP_DST):
            self.append_field(ofproto_v1_2.OXM_OF_TCP_DST, self._flow.tcp_dst)

        if self._wc.ft_test(ofproto_v1_2.OFPXMT_OFB_UDP_SRC):
            self.append_field(ofproto_v1_2.OXM_OF_UDP_SRC, self._flow.udp_src)

        if self._wc.ft_test(ofproto_v1_2.OFPXMT_OFB_UDP_DST):
            self.append_field(ofproto_v1_2.OXM_OF_UDP_DST, self._flow.udp_dst)

        if self._wc.ft_test(ofproto_v1_2.OFPXMT_OFB_SCTP_SRC):
            self.append_field(ofproto_v1_2.OXM_OF_SCTP_SRC,
                              self._flow.sctp_src)

        if self._wc.ft_test(ofproto_v1_2.OFPXMT_OFB_SCTP_DST):
            self.append_field(ofproto_v1_2.OXM_OF_SCTP_DST,
                              self._flow.sctp_dst)

        if self._wc.ft_test(ofproto_v1_2.OFPXMT_OFB_ICMPV4_TYPE):
            self.append_field(ofproto_v1_2.OXM_OF_ICMPV4_TYPE,
                              self._flow.icmpv4_type)

        if self._wc.ft_test(ofproto_v1_2.OFPXMT_OFB_ICMPV4_CODE):
            self.append_field(ofproto_v1_2.OXM_OF_ICMPV4_CODE,
                              self._flow.icmpv4_code)

        if self._wc.ft_test(ofproto_v1_2.OFPXMT_OFB_ARP_OP):
            self.append_field(ofproto_v1_2.OXM_OF_ARP_OP, self._flow.arp_op)

        if self._wc.ft_test(ofproto_v1_2.OFPXMT_OFB_ARP_SPA):
            if self._wc.arp_spa_mask == UINT32_MAX:
                header = ofproto_v1_2.OXM_OF_ARP_SPA
            else:
                header = ofproto_v1_2.OXM_OF_ARP_SPA_W
            self.append_field(header, self._flow.arp_spa,
                              self._wc.arp_spa_mask)

        if self._wc.ft_test(ofproto_v1_2.OFPXMT_OFB_ARP_TPA):
            if self._wc.arp_tpa_mask == UINT32_MAX:
                header = ofproto_v1_2.OXM_OF_ARP_TPA
            else:
                header = ofproto_v1_2.OXM_OF_ARP_TPA_W
            self.append_field(header, self._flow.arp_tpa,
                              self._wc.arp_tpa_mask)

        if self._wc.ft_test(ofproto_v1_2.OFPXMT_OFB_ARP_SHA):
            if self._wc.arp_sha_mask:
                header = ofproto_v1_2.OXM_OF_ARP_SHA_W
            else:
                header = ofproto_v1_2.OXM_OF_ARP_SHA
            self.append_field(header, self._flow.arp_sha,
                              self._wc.arp_sha_mask)

        if self._wc.ft_test(ofproto_v1_2.OFPXMT_OFB_ARP_THA):
            if self._wc.arp_tha_mask:
                header = ofproto_v1_2.OXM_OF_ARP_THA_W
            else:
                header = ofproto_v1_2.OXM_OF_ARP_THA
            self.append_field(header, self._flow.arp_tha,
                              self._wc.arp_tha_mask)

        if self._wc.ft_test(ofproto_v1_2.OFPXMT_OFB_IPV6_SRC):
            if len(self._wc.ipv6_src_mask):
                header = ofproto_v1_2.OXM_OF_IPV6_SRC_W
            else:
                header = ofproto_v1_2.OXM_OF_IPV6_SRC
            self.append_field(header, self._flow.ipv6_src,
                              self._wc.ipv6_src_mask)

        if self._wc.ft_test(ofproto_v1_2.OFPXMT_OFB_IPV6_DST):
            if len(self._wc.ipv6_dst_mask):
                header = ofproto_v1_2.OXM_OF_IPV6_DST_W
            else:
                header = ofproto_v1_2.OXM_OF_IPV6_DST
            self.append_field(header, self._flow.ipv6_dst,
                              self._wc.ipv6_dst_mask)

        if self._wc.ft_test(ofproto_v1_2.OFPXMT_OFB_IPV6_FLABEL):
            if self._wc.ipv6_flabel_mask == UINT32_MAX:
                header = ofproto_v1_2.OXM_OF_IPV6_FLABEL
            else:
                header = ofproto_v1_2.OXM_OF_IPV6_FLABEL_W
            self.append_field(header, self._flow.ipv6_flabel,
                              self._wc.ipv6_flabel_mask)

        if self._wc.ft_test(ofproto_v1_2.OFPXMT_OFB_ICMPV6_TYPE):
            self.append_field(ofproto_v1_2.OXM_OF_ICMPV6_TYPE,
                              self._flow.icmpv6_type)

        if self._wc.ft_test(ofproto_v1_2.OFPXMT_OFB_ICMPV6_CODE):
            self.append_field(ofproto_v1_2.OXM_OF_ICMPV6_CODE,
                              self._flow.icmpv6_code)

        if self._wc.ft_test(ofproto_v1_2.OFPXMT_OFB_IPV6_ND_TARGET):
            self.append_field(ofproto_v1_2.OXM_OF_IPV6_ND_TARGET,
                              self._flow.ipv6_nd_target)

        if self._wc.ft_test(ofproto_v1_2.OFPXMT_OFB_IPV6_ND_SLL):
            self.append_field(ofproto_v1_2.OXM_OF_IPV6_ND_SLL,
                              self._flow.ipv6_nd_sll)

        if self._wc.ft_test(ofproto_v1_2.OFPXMT_OFB_IPV6_ND_TLL):
            self.append_field(ofproto_v1_2.OXM_OF_IPV6_ND_TLL,
                              self._flow.ipv6_nd_tll)

        if self._wc.ft_test(ofproto_v1_2.OFPXMT_OFB_MPLS_LABEL):
            self.append_field(ofproto_v1_2.OXM_OF_MPLS_LABEL,
                              self._flow.mpls_label)

        if self._wc.ft_test(ofproto_v1_2.OFPXMT_OFB_MPLS_TC):
            self.append_field(ofproto_v1_2.OXM_OF_MPLS_TC,
                              self._flow.mpls_tc)

        field_offset = offset + 4
        for f in self.fields:
            f.serialize(buf, field_offset)
            field_offset += f.length

        length = field_offset - offset
        msg_pack_into('!HH', buf, offset, ofproto_v1_2.OFPMT_OXM, length)

        pad_len = utils.round_up(length, 8) - length
        ofproto_parser.msg_pack_into("%dx" % pad_len, buf, field_offset)

        return length + pad_len

    @classmethod
    def parser(cls, buf, offset):
        """
        Returns an object which is generated from a buffer including the
        expression of the wire protocol of the flow match.
        """
        match = OFPMatch()
        type_, length = struct.unpack_from('!HH', buf, offset)

        match.type = type_
        match.length = length

        # ofp_match adjustment
        offset += 4
        length -= 4

        # XXXcompat
        cls.parser_old(match, buf, offset, length)

        fields = []
        while length > 0:
            n, value, mask, field_len = ofproto_v1_2.oxm_parse(buf, offset)
            k, uv = ofproto_v1_2.oxm_to_user(n, value, mask)
            fields.append((k, uv))
            offset += field_len
            length -= field_len
        match._fields2 = fields
        return match

    @staticmethod
    def parser_old(match, buf, offset, length):
        while length > 0:
            field = OFPMatchField.parser(buf, offset)
            offset += field.length
            length -= field.length
            match.fields.append(field)

    def set_in_port(self, port):
        self._wc.ft_set(ofproto_v1_2.OFPXMT_OFB_IN_PORT)
        self._flow.in_port = port

    def set_in_phy_port(self, phy_port):
        self._wc.ft_set(ofproto_v1_2.OFPXMT_OFB_IN_PHY_PORT)
        self._flow.in_phy_port = phy_port

    def set_metadata(self, metadata):
        self.set_metadata_masked(metadata, UINT64_MAX)

    def set_metadata_masked(self, metadata, mask):
        self._wc.ft_set(ofproto_v1_2.OFPXMT_OFB_METADATA)
        self._wc.metadata_mask = mask
        self._flow.metadata = metadata & mask

    def set_dl_dst(self, dl_dst):
        self._wc.ft_set(ofproto_v1_2.OFPXMT_OFB_ETH_DST)
        self._flow.dl_dst = dl_dst

    def set_dl_dst_masked(self, dl_dst, mask):
        self._wc.ft_set(ofproto_v1_2.OFPXMT_OFB_ETH_DST)
        self._wc.dl_dst_mask = mask
        # bit-wise and of the corresponding elements of dl_dst and mask
        self._flow.dl_dst = mac.haddr_bitand(dl_dst, mask)

    def set_dl_src(self, dl_src):
        self._wc.ft_set(ofproto_v1_2.OFPXMT_OFB_ETH_SRC)
        self._flow.dl_src = dl_src

    def set_dl_src_masked(self, dl_src, mask):
        self._wc.ft_set(ofproto_v1_2.OFPXMT_OFB_ETH_SRC)
        self._wc.dl_src_mask = mask
        self._flow.dl_src = mac.haddr_bitand(dl_src, mask)

    def set_dl_type(self, dl_type):
        self._wc.ft_set(ofproto_v1_2.OFPXMT_OFB_ETH_TYPE)
        self._flow.dl_type = dl_type

    def set_vlan_vid(self, vid):
        self.set_vlan_vid_masked(vid, UINT16_MAX)

    def set_vlan_vid_masked(self, vid, mask):
        self._wc.ft_set(ofproto_v1_2.OFPXMT_OFB_VLAN_VID)
        self._wc.vlan_vid_mask = mask
        self._flow.vlan_vid = vid

    def set_vlan_pcp(self, pcp):
        self._wc.ft_set(ofproto_v1_2.OFPXMT_OFB_VLAN_PCP)
        self._flow.vlan_pcp = pcp

    def set_ip_dscp(self, ip_dscp):
        self._wc.ft_set(ofproto_v1_2.OFPXMT_OFB_IP_DSCP)
        self._flow.ip_dscp = ip_dscp

    def set_ip_ecn(self, ip_ecn):
        self._wc.ft_set(ofproto_v1_2.OFPXMT_OFB_IP_ECN)
        self._flow.ip_ecn = ip_ecn

    def set_ip_proto(self, ip_proto):
        self._wc.ft_set(ofproto_v1_2.OFPXMT_OFB_IP_PROTO)
        self._flow.ip_proto = ip_proto

    def set_ipv4_src(self, ipv4_src):
        self.set_ipv4_src_masked(ipv4_src, UINT32_MAX)

    def set_ipv4_src_masked(self, ipv4_src, mask):
        self._wc.ft_set(ofproto_v1_2.OFPXMT_OFB_IPV4_SRC)
        self._flow.ipv4_src = ipv4_src
        self._wc.ipv4_src_mask = mask

    def set_ipv4_dst(self, ipv4_dst):
        self.set_ipv4_dst_masked(ipv4_dst, UINT32_MAX)

    def set_ipv4_dst_masked(self, ipv4_dst, mask):
        self._wc.ft_set(ofproto_v1_2.OFPXMT_OFB_IPV4_DST)
        self._flow.ipv4_dst = ipv4_dst
        self._wc.ipv4_dst_mask = mask

    def set_tcp_src(self, tcp_src):
        self._wc.ft_set(ofproto_v1_2.OFPXMT_OFB_TCP_SRC)
        self._flow.tcp_src = tcp_src

    def set_tcp_dst(self, tcp_dst):
        self._wc.ft_set(ofproto_v1_2.OFPXMT_OFB_TCP_DST)
        self._flow.tcp_dst = tcp_dst

    def set_udp_src(self, udp_src):
        self._wc.ft_set(ofproto_v1_2.OFPXMT_OFB_UDP_SRC)
        self._flow.udp_src = udp_src

    def set_udp_dst(self, udp_dst):
        self._wc.ft_set(ofproto_v1_2.OFPXMT_OFB_UDP_DST)
        self._flow.udp_dst = udp_dst

    def set_sctp_src(self, sctp_src):
        self._wc.ft_set(ofproto_v1_2.OFPXMT_OFB_SCTP_SRC)
        self._flow.sctp_src = sctp_src

    def set_sctp_dst(self, sctp_dst):
        self._wc.ft_set(ofproto_v1_2.OFPXMT_OFB_SCTP_DST)
        self._flow.sctp_dst = sctp_dst

    def set_icmpv4_type(self, icmpv4_type):
        self._wc.ft_set(ofproto_v1_2.OFPXMT_OFB_ICMPV4_TYPE)
        self._flow.icmpv4_type = icmpv4_type

    def set_icmpv4_code(self, icmpv4_code):
        self._wc.ft_set(ofproto_v1_2.OFPXMT_OFB_ICMPV4_CODE)
        self._flow.icmpv4_code = icmpv4_code

    def set_arp_opcode(self, arp_op):
        self._wc.ft_set(ofproto_v1_2.OFPXMT_OFB_ARP_OP)
        self._flow.arp_op = arp_op

    def set_arp_spa(self, arp_spa):
        self.set_arp_spa_masked(arp_spa, UINT32_MAX)

    def set_arp_spa_masked(self, arp_spa, mask):
        self._wc.ft_set(ofproto_v1_2.OFPXMT_OFB_ARP_SPA)
        self._wc.arp_spa_mask = mask
        self._flow.arp_spa = arp_spa

    def set_arp_tpa(self, arp_tpa):
        self.set_arp_tpa_masked(arp_tpa, UINT32_MAX)

    def set_arp_tpa_masked(self, arp_tpa, mask):
        self._wc.ft_set(ofproto_v1_2.OFPXMT_OFB_ARP_TPA)
        self._wc.arp_tpa_mask = mask
        self._flow.arp_tpa = arp_tpa

    def set_arp_sha(self, arp_sha):
        self._wc.ft_set(ofproto_v1_2.OFPXMT_OFB_ARP_SHA)
        self._flow.arp_sha = arp_sha

    def set_arp_sha_masked(self, arp_sha, mask):
        self._wc.ft_set(ofproto_v1_2.OFPXMT_OFB_ARP_SHA)
        self._wc.arp_sha_mask = mask
        self._flow.arp_sha = mac.haddr_bitand(arp_sha, mask)

    def set_arp_tha(self, arp_tha):
        self._wc.ft_set(ofproto_v1_2.OFPXMT_OFB_ARP_THA)
        self._flow.arp_tha = arp_tha

    def set_arp_tha_masked(self, arp_tha, mask):
        self._wc.ft_set(ofproto_v1_2.OFPXMT_OFB_ARP_THA)
        self._wc.arp_tha_mask = mask
        self._flow.arp_tha = mac.haddr_bitand(arp_tha, mask)

    def set_ipv6_src(self, src):
        self._wc.ft_set(ofproto_v1_2.OFPXMT_OFB_IPV6_SRC)
        self._flow.ipv6_src = src

    def set_ipv6_src_masked(self, src, mask):
        self._wc.ft_set(ofproto_v1_2.OFPXMT_OFB_IPV6_SRC)
        self._wc.ipv6_src_mask = mask
        self._flow.ipv6_src = [x & y for (x, y) in itertools.izip(src, mask)]

    def set_ipv6_dst(self, dst):
        self._wc.ft_set(ofproto_v1_2.OFPXMT_OFB_IPV6_DST)
        self._flow.ipv6_dst = dst

    def set_ipv6_dst_masked(self, dst, mask):
        self._wc.ft_set(ofproto_v1_2.OFPXMT_OFB_IPV6_DST)
        self._wc.ipv6_dst_mask = mask
        self._flow.ipv6_dst = [x & y for (x, y) in itertools.izip(dst, mask)]

    def set_ipv6_flabel(self, flabel):
        self.set_ipv6_flabel_masked(flabel, UINT32_MAX)

    def set_ipv6_flabel_masked(self, flabel, mask):
        self._wc.ft_set(ofproto_v1_2.OFPXMT_OFB_IPV6_FLABEL)
        self._wc.ipv6_flabel_mask = mask
        self._flow.ipv6_flabel = flabel

    def set_icmpv6_type(self, icmpv6_type):
        self._wc.ft_set(ofproto_v1_2.OFPXMT_OFB_ICMPV6_TYPE)
        self._flow.icmpv6_type = icmpv6_type

    def set_icmpv6_code(self, icmpv6_code):
        self._wc.ft_set(ofproto_v1_2.OFPXMT_OFB_ICMPV6_CODE)
        self._flow.icmpv6_code = icmpv6_code

    def set_ipv6_nd_target(self, target):
        self._wc.ft_set(ofproto_v1_2.OFPXMT_OFB_IPV6_ND_TARGET)
        self._flow.ipv6_nd_target = target

    def set_ipv6_nd_sll(self, ipv6_nd_sll):
        self._wc.ft_set(ofproto_v1_2.OFPXMT_OFB_IPV6_ND_SLL)
        self._flow.ipv6_nd_sll = ipv6_nd_sll

    def set_ipv6_nd_tll(self, ipv6_nd_tll):
        self._wc.ft_set(ofproto_v1_2.OFPXMT_OFB_IPV6_ND_TLL)
        self._flow.ipv6_nd_tll = ipv6_nd_tll

    def set_mpls_label(self, mpls_label):
        self._wc.ft_set(ofproto_v1_2.OFPXMT_OFB_MPLS_LABEL)
        self._flow.mpls_label = mpls_label

    def set_mpls_tc(self, mpls_tc):
        self._wc.ft_set(ofproto_v1_2.OFPXMT_OFB_MPLS_TC)
        self._flow.mpls_tc = mpls_tc


class OFPMatchField(StringifyMixin):
    _FIELDS_HEADERS = {}

    @staticmethod
    def register_field_header(headers):
        def _register_field_header(cls):
            for header in headers:
                OFPMatchField._FIELDS_HEADERS[header] = cls
            return cls
        return _register_field_header

    def __init__(self, header):
        self.header = header
        self.n_bytes = ofproto_v1_2.oxm_tlv_header_extract_length(header)
        self.length = 0

    @classmethod
    def cls_to_header(cls, cls_, hasmask):
        # XXX efficiency
        inv = dict((v, k) for k, v in cls._FIELDS_HEADERS.iteritems()
                   if (((k >> 8) & 1) != 0) == hasmask)
        return inv[cls_]

    @staticmethod
    def make(header, value, mask=None):
        cls_ = OFPMatchField._FIELDS_HEADERS.get(header)
        return cls_(header, value, mask)

    @classmethod
    def parser(cls, buf, offset):
        (header,) = struct.unpack_from('!I', buf, offset)
        cls_ = OFPMatchField._FIELDS_HEADERS.get(header)
        if cls_:
            field = cls_.field_parser(header, buf, offset)
        else:
            field = OFPMatchField(header)
        field.length = (header & 0xff) + 4
        return field

    @classmethod
    def field_parser(cls, header, buf, offset):
        mask = None
        if ofproto_v1_2.oxm_tlv_header_extract_hasmask(header):
            pack_str = '!' + cls.pack_str[1:] * 2
            (value, mask) = struct.unpack_from(pack_str, buf, offset + 4)
        else:
            (value,) = struct.unpack_from(cls.pack_str, buf, offset + 4)
        return cls(header, value, mask)

    def serialize(self, buf, offset):
        if ofproto_v1_2.oxm_tlv_header_extract_hasmask(self.header):
            self.put_w(buf, offset, self.value, self.mask)
        else:
            self.put(buf, offset, self.value)

    def _put_header(self, buf, offset):
        ofproto_parser.msg_pack_into('!I', buf, offset, self.header)
        self.length = 4

    def _put(self, buf, offset, value):
        ofproto_parser.msg_pack_into(self.pack_str, buf, offset, value)
        self.length += self.n_bytes

    def put_w(self, buf, offset, value, mask):
        self._put_header(buf, offset)
        self._put(buf, offset + self.length, value)
        self._put(buf, offset + self.length, mask)

    def put(self, buf, offset, value):
        self._put_header(buf, offset)
        self._put(buf, offset + self.length, value)

    def _putv6(self, buf, offset, value):
        ofproto_parser.msg_pack_into(self.pack_str, buf, offset,
                                     *value)
        self.length += self.n_bytes

    def putv6(self, buf, offset, value, mask=None):
        self._put_header(buf, offset)
        self._putv6(buf, offset + self.length, value)
        if mask and len(mask):
            self._putv6(buf, offset + self.length, mask)

    def oxm_len(self):
        return self.header & 0xff

    def to_jsondict(self):
        # remove some redundant attributes
        d = super(OFPMatchField, self).to_jsondict()
        v = d[self.__class__.__name__]
        del v['header']
        del v['length']
        del v['n_bytes']
        return d

    @classmethod
    def from_jsondict(cls, dict_):
        # just pass the dict around.
        # it will be converted by OFPMatch.__init__().
        return {cls.__name__: dict_}

    def stringify_attrs(self):
        f = super(OFPMatchField, self).stringify_attrs
        if not ofproto_v1_2.oxm_tlv_header_extract_hasmask(self.header):
            # something like the following, but yield two values (k,v)
            # return itertools.ifilter(lambda k, v: k != 'mask', iter())
            def g():
                for k, v in f():
                    if k != 'mask':
                        yield (k, v)
            return g()
        else:
            return f()


@OFPMatchField.register_field_header([ofproto_v1_2.OXM_OF_IN_PORT])
class MTInPort(OFPMatchField):
    pack_str = '!I'

    def __init__(self, header, value, mask=None):
        super(MTInPort, self).__init__(header)
        self.value = value


@OFPMatchField.register_field_header([ofproto_v1_2.OXM_OF_METADATA,
                                      ofproto_v1_2.OXM_OF_METADATA_W])
class MTMetadata(OFPMatchField):
    pack_str = '!Q'

    def __init__(self, header, value, mask=None):
        super(MTMetadata, self).__init__(header)
        self.value = value
        self.mask = mask


@OFPMatchField.register_field_header([ofproto_v1_2.OXM_OF_IN_PHY_PORT])
class MTInPhyPort(OFPMatchField):
    pack_str = '!I'

    def __init__(self, header, value, mask=None):
        super(MTInPhyPort, self).__init__(header)
        self.value = value


@OFPMatchField.register_field_header([ofproto_v1_2.OXM_OF_ETH_DST,
                                      ofproto_v1_2.OXM_OF_ETH_DST_W])
class MTEthDst(OFPMatchField):
    pack_str = '!6s'

    def __init__(self, header, value, mask=None):
        super(MTEthDst, self).__init__(header)
        self.value = value
        self.mask = mask


@OFPMatchField.register_field_header([ofproto_v1_2.OXM_OF_ETH_SRC,
                                      ofproto_v1_2.OXM_OF_ETH_SRC_W])
class MTEthSrc(OFPMatchField):
    pack_str = '!6s'

    def __init__(self, header, value, mask=None):
        super(MTEthSrc, self).__init__(header)
        self.value = value
        self.mask = mask


@OFPMatchField.register_field_header([ofproto_v1_2.OXM_OF_ETH_TYPE])
class MTEthType(OFPMatchField):
    pack_str = '!H'

    def __init__(self, header, value, mask=None):
        super(MTEthType, self).__init__(header)
        self.value = value


@OFPMatchField.register_field_header([ofproto_v1_2.OXM_OF_VLAN_VID,
                                      ofproto_v1_2.OXM_OF_VLAN_VID_W])
class MTVlanVid(OFPMatchField):
    pack_str = '!H'

    def __init__(self, header, value, mask=None):
        super(MTVlanVid, self).__init__(header)
        self.value = value
        self.mask = mask

    @classmethod
    def field_parser(cls, header, buf, offset):
        m = super(MTVlanVid, cls).field_parser(header, buf, offset)
        m.value &= ~ofproto_v1_2.OFPVID_PRESENT
        return m

    def serialize(self, buf, offset):
        self.value |= ofproto_v1_2.OFPVID_PRESENT
        super(MTVlanVid, self).serialize(buf, offset)


@OFPMatchField.register_field_header([ofproto_v1_2.OXM_OF_VLAN_PCP])
class MTVlanPcp(OFPMatchField):
    pack_str = '!B'

    def __init__(self, header, value, mask=None):
        super(MTVlanPcp, self).__init__(header)
        self.value = value


@OFPMatchField.register_field_header([ofproto_v1_2.OXM_OF_IP_DSCP])
class MTIPDscp(OFPMatchField):
    pack_str = '!B'

    def __init__(self, header, value, mask=None):
        super(MTIPDscp, self).__init__(header)
        self.value = value


@OFPMatchField.register_field_header([ofproto_v1_2.OXM_OF_IP_ECN])
class MTIPECN(OFPMatchField):
    pack_str = '!B'

    def __init__(self, header, value, mask=None):
        super(MTIPECN, self).__init__(header)
        self.value = value


@OFPMatchField.register_field_header([ofproto_v1_2.OXM_OF_IP_PROTO])
class MTIPProto(OFPMatchField):
    pack_str = '!B'

    def __init__(self, header, value, mask=None):
        super(MTIPProto, self).__init__(header)
        self.value = value


@OFPMatchField.register_field_header([ofproto_v1_2.OXM_OF_IPV4_SRC,
                                      ofproto_v1_2.OXM_OF_IPV4_SRC_W])
class MTIPV4Src(OFPMatchField):
    pack_str = '!I'

    def __init__(self, header, value, mask=None):
        super(MTIPV4Src, self).__init__(header)
        self.value = value
        self.mask = mask


@OFPMatchField.register_field_header([ofproto_v1_2.OXM_OF_IPV4_DST,
                                      ofproto_v1_2.OXM_OF_IPV4_DST_W])
class MTIPV4Dst(OFPMatchField):
    pack_str = '!I'

    def __init__(self, header, value, mask=None):
        super(MTIPV4Dst, self).__init__(header)
        self.value = value
        self.mask = mask


@OFPMatchField.register_field_header([ofproto_v1_2.OXM_OF_TCP_SRC])
class MTTCPSrc(OFPMatchField):
    pack_str = '!H'

    def __init__(self, header, value, mask=None):
        super(MTTCPSrc, self).__init__(header)
        self.value = value


@OFPMatchField.register_field_header([ofproto_v1_2.OXM_OF_TCP_DST])
class MTTCPDst(OFPMatchField):
    pack_str = '!H'

    def __init__(self, header, value, mask=None):
        super(MTTCPDst, self).__init__(header)
        self.value = value


@OFPMatchField.register_field_header([ofproto_v1_2.OXM_OF_UDP_SRC])
class MTUDPSrc(OFPMatchField):
    pack_str = '!H'

    def __init__(self, header, value, mask=None):
        super(MTUDPSrc, self).__init__(header)
        self.value = value


@OFPMatchField.register_field_header([ofproto_v1_2.OXM_OF_UDP_DST])
class MTUDPDst(OFPMatchField):
    pack_str = '!H'

    def __init__(self, header, value, mask=None):
        super(MTUDPDst, self).__init__(header)
        self.value = value


@OFPMatchField.register_field_header([ofproto_v1_2.OXM_OF_SCTP_SRC])
class MTSCTPSrc(OFPMatchField):
    pack_str = '!H'

    def __init__(self, header, value, mask=None):
        super(MTSCTPSrc, self).__init__(header)
        self.value = value


@OFPMatchField.register_field_header([ofproto_v1_2.OXM_OF_SCTP_DST])
class MTSCTPDst(OFPMatchField):
    pack_str = '!H'

    def __init__(self, header, value, mask=None):
        super(MTSCTPDst, self).__init__(header)
        self.value = value


@OFPMatchField.register_field_header([ofproto_v1_2.OXM_OF_ICMPV4_TYPE])
class MTICMPV4Type(OFPMatchField):
    pack_str = '!B'

    def __init__(self, header, value, mask=None):
        super(MTICMPV4Type, self).__init__(header)
        self.value = value


@OFPMatchField.register_field_header([ofproto_v1_2.OXM_OF_ICMPV4_CODE])
class MTICMPV4Code(OFPMatchField):
    pack_str = '!B'

    def __init__(self, header, value, mask=None):
        super(MTICMPV4Code, self).__init__(header)
        self.value = value


@OFPMatchField.register_field_header([ofproto_v1_2.OXM_OF_ARP_OP])
class MTArpOp(OFPMatchField):
    pack_str = '!H'

    def __init__(self, header, value, mask=None):
        super(MTArpOp, self).__init__(header)
        self.value = value


@OFPMatchField.register_field_header([ofproto_v1_2.OXM_OF_ARP_SPA,
                                      ofproto_v1_2.OXM_OF_ARP_SPA_W])
class MTArpSpa(OFPMatchField):
    pack_str = '!I'

    def __init__(self, header, value, mask=None):
        super(MTArpSpa, self).__init__(header)
        self.value = value
        self.mask = mask


@OFPMatchField.register_field_header([ofproto_v1_2.OXM_OF_ARP_TPA,
                                      ofproto_v1_2.OXM_OF_ARP_TPA_W])
class MTArpTpa(OFPMatchField):
    pack_str = '!I'

    def __init__(self, header, value, mask=None):
        super(MTArpTpa, self).__init__(header)
        self.value = value
        self.mask = mask


@OFPMatchField.register_field_header([ofproto_v1_2.OXM_OF_ARP_SHA,
                                      ofproto_v1_2.OXM_OF_ARP_SHA_W])
class MTArpSha(OFPMatchField):
    pack_str = '!6s'

    def __init__(self, header, value, mask=None):
        super(MTArpSha, self).__init__(header)
        self.value = value
        self.mask = mask


@OFPMatchField.register_field_header([ofproto_v1_2.OXM_OF_ARP_THA,
                                      ofproto_v1_2.OXM_OF_ARP_THA_W])
class MTArpTha(OFPMatchField):
    pack_str = '!6s'

    def __init__(self, header, value, mask=None):
        super(MTArpTha, self).__init__(header)
        self.value = value
        self.mask = mask


class MTIPv6(object):
    @classmethod
    def field_parser(cls, header, buf, offset):
        if ofproto_v1_2.oxm_tlv_header_extract_hasmask(header):
            pack_str = '!' + cls.pack_str[1:] * 2
            value = struct.unpack_from(pack_str, buf, offset + 4)
            return cls(header, list(value[:8]), list(value[8:]))
        else:
            value = struct.unpack_from(cls.pack_str, buf, offset + 4)
            return cls(header, list(value))

    def serialize(self, buf, offset):
        self.putv6(buf, offset, self.value, self.mask)


@OFPMatchField.register_field_header([ofproto_v1_2.OXM_OF_IPV6_SRC,
                                      ofproto_v1_2.OXM_OF_IPV6_SRC_W])
class MTIPv6Src(MTIPv6, OFPMatchField):
    pack_str = '!8H'

    def __init__(self, header, value, mask=None):
        super(MTIPv6Src, self).__init__(header)
        self.value = value
        self.mask = mask


@OFPMatchField.register_field_header([ofproto_v1_2.OXM_OF_IPV6_DST,
                                      ofproto_v1_2.OXM_OF_IPV6_DST_W])
class MTIPv6Dst(MTIPv6, OFPMatchField):
    pack_str = '!8H'

    def __init__(self, header, value, mask=None):
        super(MTIPv6Dst, self).__init__(header)
        self.value = value
        self.mask = mask


@OFPMatchField.register_field_header([ofproto_v1_2.OXM_OF_IPV6_FLABEL,
                                      ofproto_v1_2.OXM_OF_IPV6_FLABEL_W])
class MTIPv6Flabel(OFPMatchField):
    pack_str = '!I'

    def __init__(self, header, value, mask=None):
        super(MTIPv6Flabel, self).__init__(header)
        self.value = value
        self.mask = mask


@OFPMatchField.register_field_header([ofproto_v1_2.OXM_OF_MPLS_LABEL])
class MTMplsLabel(OFPMatchField):
    pack_str = '!I'

    def __init__(self, header, value, mask=None):
        super(MTMplsLabel, self).__init__(header)
        self.value = value


@OFPMatchField.register_field_header([ofproto_v1_2.OXM_OF_ICMPV6_TYPE])
class MTICMPV6Type(OFPMatchField):
    pack_str = '!B'

    def __init__(self, header, value, mask=None):
        super(MTICMPV6Type, self).__init__(header)
        self.value = value


@OFPMatchField.register_field_header([ofproto_v1_2.OXM_OF_ICMPV6_CODE])
class MTICMPV6Code(OFPMatchField):
    pack_str = '!B'

    def __init__(self, header, value, mask=None):
        super(MTICMPV6Code, self).__init__(header)
        self.value = value


@OFPMatchField.register_field_header([ofproto_v1_2.OXM_OF_IPV6_ND_TARGET])
class MTIPv6NdTarget(MTIPv6, OFPMatchField):
    pack_str = '!8H'

    def __init__(self, header, value, mask=None):
        super(MTIPv6NdTarget, self).__init__(header)
        self.value = value

    def serialize(self, buf, offset):
        self.putv6(buf, offset, self.value)


@OFPMatchField.register_field_header([ofproto_v1_2.OXM_OF_IPV6_ND_SLL])
class MTIPv6NdSll(OFPMatchField):
    pack_str = '!6s'

    def __init__(self, header, value, mask=None):
        super(MTIPv6NdSll, self).__init__(header)
        self.value = value


@OFPMatchField.register_field_header([ofproto_v1_2.OXM_OF_IPV6_ND_TLL])
class MTIPv6NdTll(OFPMatchField):
    pack_str = '!6s'

    def __init__(self, header, value, mask=None):
        super(MTIPv6NdTll, self).__init__(header)
        self.value = value


@OFPMatchField.register_field_header([ofproto_v1_2.OXM_OF_MPLS_TC])
class MTMplsTc(OFPMatchField):
    pack_str = '!B'

    def __init__(self, header, value, mask=None):
        super(MTMplsTc, self).__init__(header)
        self.value = value

########NEW FILE########
__FILENAME__ = ofproto_v1_3
# Copyright (C) 2012 Nippon Telegraph and Telephone Corporation.
# Copyright (C) 2012 Isaku Yamahata <yamahata at valinux co jp>
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from ryu.ofproto import oxm_fields

from struct import calcsize

# struct ofp_header
OFP_HEADER_PACK_STR = '!BBHI'
OFP_HEADER_SIZE = 8
assert calcsize(OFP_HEADER_PACK_STR) == OFP_HEADER_SIZE

# enum ofp_type
OFPT_HELLO = 0    # Symmetric message
OFPT_ERROR = 1    # Symmetric message
OFPT_ECHO_REQUEST = 2    # Symmetric message
OFPT_ECHO_REPLY = 3    # Symmetric message
OFPT_EXPERIMENTER = 4    # Symmetric message

OFPT_FEATURES_REQUEST = 5    # Controller/switch message
OFPT_FEATURES_REPLY = 6    # Controller/switch message
OFPT_GET_CONFIG_REQUEST = 7    # Controller/switch message
OFPT_GET_CONFIG_REPLY = 8    # Controller/switch message
OFPT_SET_CONFIG = 9    # Controller/switch message

OFPT_PACKET_IN = 10    # Async message
OFPT_FLOW_REMOVED = 11    # Async message
OFPT_PORT_STATUS = 12    # Async message

OFPT_PACKET_OUT = 13    # Controller/switch message
OFPT_FLOW_MOD = 14    # Controller/switch message
OFPT_GROUP_MOD = 15    # Controller/switch message
OFPT_PORT_MOD = 16    # Controller/switch message
OFPT_TABLE_MOD = 17    # Controller/switch message

OFPT_MULTIPART_REQUEST = 18    # Controller/switch message
OFPT_MULTIPART_REPLY = 19    # Controller/switch message

OFPT_BARRIER_REQUEST = 20    # Controller/switch message
OFPT_BARRIER_REPLY = 21    # Controller/switch message
OFPT_QUEUE_GET_CONFIG_REQUEST = 22    # Controller/switch message
OFPT_QUEUE_GET_CONFIG_REPLY = 23    # Controller/switch message

OFPT_ROLE_REQUEST = 24    # Controller/switch message
OFPT_ROLE_REPLY = 25    # Controller/switch message

OFPT_GET_ASYNC_REQUEST = 26    # Controller/switch message
OFPT_GET_ASYNC_REPLY = 27    # Controller/switch message
OFPT_SET_ASYNC = 28    # Controller/switch message

OFPT_METER_MOD = 29    # Controller/switch message

# struct ofp_port
OFP_MAX_PORT_NAME_LEN = 16
OFP_ETH_ALEN = 6
OFP_ETH_ALEN_STR = str(OFP_ETH_ALEN)
_OFP_PORT_PACK_STR = 'I4x' + OFP_ETH_ALEN_STR + 's' + '2x' + \
                     str(OFP_MAX_PORT_NAME_LEN) + 's' + 'IIIIIIII'
OFP_PORT_PACK_STR = '!' + _OFP_PORT_PACK_STR
OFP_PORT_SIZE = 64
assert calcsize(OFP_PORT_PACK_STR) == OFP_PORT_SIZE

# enum ofp_port_config
OFPPC_PORT_DOWN = 1 << 0    # Port is administratively down.
OFPPC_NO_RECV = 1 << 2        # Drop all packets recieved by port.
OFPPC_NO_FWD = 1 << 5        # Drop packets forwarded to port.
OFPPC_NO_PACKET_IN = 1 << 6    # Do not send packet-in msgs for port.

# enum ofp_port_state
OFPPS_LINK_DOWN = 1 << 0    # No physical link present.
OFPPS_BLOCKED = 1 << 1        # Port is blocked.
OFPPS_LIVE = 1 << 2        # Live for Fast Failover Group.

# enum ofp_port_no
OFPP_MAX = 0xffffff00
OFPP_IN_PORT = 0xfffffff8       # Send the packet out the input port. This
                                # virtual port must be explicitly used
                                # in order to send back out of the input
                                # port.
OFPP_TABLE = 0xfffffff9         # Perform actions in flow table.
                                # NB: This can only be the destination
                                # port for packet-out messages.
OFPP_NORMAL = 0xfffffffa        # Process with normal L2/L3 switching.
OFPP_FLOOD = 0xfffffffb         # All physical ports except input port and
                                # those disabled by STP.
OFPP_ALL = 0xfffffffc           # All physical ports except input port.
OFPP_CONTROLLER = 0xfffffffd    # Send to controller.
OFPP_LOCAL = 0xfffffffe         # Local openflow "port".
OFPP_ANY = 0xffffffff 	        # Not associated with a physical port.

# All ones is used to indicate all queues in a port (for stats retrieval).
OFPQ_ALL = 0xffffffff

# enum ofp_port_features
OFPPF_10MB_HD = 1 << 0    # 10 Mb half-duplex rate support.
OFPPF_10MB_FD = 1 << 1    # 10 Mb full-duplex rate support.
OFPPF_100MB_HD = 1 << 2    # 100 Mb half-duplex rate support.
OFPPF_100MB_FD = 1 << 3    # 100 Mb full-duplex rate support.
OFPPF_1GB_HD = 1 << 4    # 1 Gb half-duplex rate support.
OFPPF_1GB_FD = 1 << 5    # 1 Gb full-duplex rate support.
OFPPF_10GB_FD = 1 << 6    # 10 Gb full-duplex rate support.
OFPPF_40GB_FD = 1 << 7    # 40 Gb full-duplex rate support.
OFPPF_100GB_FD = 1 << 8    # 100 Gb full-duplex rate support.
OFPPF_1TB_FD = 1 << 9    # 1 Tb full-duplex rate support.
OFPPF_OTHER = 1 << 10    # Other rate, not in the list.
OFPPF_COPPER = 1 << 11    # Copper medium.
OFPPF_FIBER = 1 << 12    # Fiber medium.
OFPPF_AUTONEG = 1 << 13    # Auto-negotiation.
OFPPF_PAUSE = 1 << 14    # Pause.
OFPPF_PAUSE_ASYM = 1 << 15    # Asymmetric pause.

# struct ofp_packet_queue
OFP_PACKET_QUEUE_PACK_STR = '!IIH6x'
OFP_PACKET_QUEUE_SIZE = 16
assert calcsize(OFP_PACKET_QUEUE_PACK_STR) == OFP_PACKET_QUEUE_SIZE

# enum ofp_queue_properties
OFPQT_MIN_RATE = 1    # Minimum datarate guaranteed.
OFPQT_MAX_RATE = 2    # Maximum datarate.
OFPQT_EXPERIMENTER = 0xffff    # Experimenter defined property.

# struct ofp_queue_prop_header
OFP_QUEUE_PROP_HEADER_PACK_STR = '!HH4x'
OFP_QUEUE_PROP_HEADER_SIZE = 8
assert calcsize(OFP_QUEUE_PROP_HEADER_PACK_STR) == OFP_QUEUE_PROP_HEADER_SIZE

# struct ofp_queue_prop_min_rate
OFP_QUEUE_PROP_MIN_RATE_PACK_STR = '!H6x'
OFP_QUEUE_PROP_MIN_RATE_SIZE = 16
assert (calcsize(OFP_QUEUE_PROP_MIN_RATE_PACK_STR) +
        OFP_QUEUE_PROP_HEADER_SIZE) == OFP_QUEUE_PROP_MIN_RATE_SIZE

# struct ofp_queue_prop_max_rate
OFP_QUEUE_PROP_MAX_RATE_PACK_STR = '!H6x'
OFP_QUEUE_PROP_MAX_RATE_SIZE = 16
assert (calcsize(OFP_QUEUE_PROP_MAX_RATE_PACK_STR) +
        OFP_QUEUE_PROP_HEADER_SIZE) == OFP_QUEUE_PROP_MAX_RATE_SIZE

# struct ofp_queue_prop_experimenter
OFP_QUEUE_PROP_EXPERIMENTER_PACK_STR = '!I4x'
OFP_QUEUE_PROP_EXPERIMENTER_SIZE = 16
assert (calcsize(OFP_QUEUE_PROP_EXPERIMENTER_PACK_STR) +
        OFP_QUEUE_PROP_HEADER_SIZE) == OFP_QUEUE_PROP_EXPERIMENTER_SIZE

# struct ofp_match
_OFP_MATCH_PACK_STR = 'HHBBBB'
OFP_MATCH_PACK_STR = '!' + _OFP_MATCH_PACK_STR
OFP_MATCH_SIZE = 8
assert calcsize(OFP_MATCH_PACK_STR) == OFP_MATCH_SIZE

# enum ofp_match_type
OFPMT_STANDARD = 0  # Deprecated
OFPMT_OXM = 1  # OpenFlow Extensible Match

# enum ofp_oxm_class
OFPXMC_NXM_0 = 0x0000  # Backward compatibility with NXM
OFPXMC_NXM_1 = 0x0001  # Backward compatibility with NXM
OFPXMC_OPENFLOW_BASIC = 0x8000  # Basic class for OpenFlow
OFPXMC_EXPERIMENTER = 0xFFFF  # Experimenter class

# enum ofp_vlan_id
OFPVID_PRESENT = 0x1000  # bit that indicate that a VLAN id is set.
OFPVID_NONE = 0x0000  # No VLAN id was set.

# enum ofp_ipv6exthdr_flags
OFPIEH_NONEXT = 1 << 0    # "No next header" encountered.
OFPIEH_ESP = 1 << 1    # Encrypted Sec Payload header present.
OFPIEH_AUTH = 1 << 2    # Authentication header present.
OFPIEH_DEST = 1 << 3    # 1 or 2 dest headers present.
OFPIEH_FRAG = 1 << 4    # Fragment header present.
OFPIEH_ROUTER = 1 << 5    # Router header present.
OFPIEH_HOP = 1 << 6    # Hop-by-hop header present.
OFPIEH_UNREP = 1 << 7    # Unexpected repeats encountered.
OFPIEH_UNSEQ = 1 << 8    # Unexpected sequencing encountered.

# ofp_oxm_experimenter_header
OFP_OXM_EXPERIMENTER_HEADER_PACK_STR = '!II'
OFP_OXM_EXPERIMENTER_HEADER_SIZE = 8
assert (calcsize(OFP_OXM_EXPERIMENTER_HEADER_PACK_STR) ==
        OFP_OXM_EXPERIMENTER_HEADER_SIZE)

# enum ofp_instruction_type
OFPIT_GOTO_TABLE = 1  # Setup the next table in the lookup pipeline.
OFPIT_WRITE_METADATA = 2  # Setup the metadata field for use later in
                          # pipeline.
OFPIT_WRITE_ACTIONS = 3  # Write the action(s) onto the datapath
                         # action set
OFPIT_APPLY_ACTIONS = 4  # Applies the action(s) immediately
OFPIT_CLEAR_ACTIONS = 5  # Clears all actions from the datapath action
                         # set
OFPIT_METER = 6  # Apply meter (rate limiter)
OFPIT_EXPERIMENTER = 0xFFFF   # Experimenter instruction

# struct ofp_instruction_goto_table
OFP_INSTRUCTION_GOTO_TABLE_PACK_STR = '!HHB3x'
OFP_INSTRUCTION_GOTO_TABLE_SIZE = 8
assert (calcsize(OFP_INSTRUCTION_GOTO_TABLE_PACK_STR) ==
        OFP_INSTRUCTION_GOTO_TABLE_SIZE)

# struct ofp_instruction_write_metadata
OFP_INSTRUCTION_WRITE_METADATA_PACK_STR = '!HH4xQQ'
OFP_INSTRUCTION_WRITE_METADATA_SIZE = 24
assert (calcsize(OFP_INSTRUCTION_WRITE_METADATA_PACK_STR) ==
        OFP_INSTRUCTION_WRITE_METADATA_SIZE)

# struct ofp_instruction_actions
OFP_INSTRUCTION_ACTIONS_PACK_STR = '!HH4x'
OFP_INSTRUCTION_ACTIONS_SIZE = 8
assert (calcsize(OFP_INSTRUCTION_ACTIONS_PACK_STR) ==
        OFP_INSTRUCTION_ACTIONS_SIZE)

# struct ofp_instruction_meter
OFP_INSTRUCTION_METER_PACK_STR = '!HHI'
OFP_INSTRUCTION_METER_SIZE = 8
assert calcsize(OFP_INSTRUCTION_METER_PACK_STR) == OFP_INSTRUCTION_METER_SIZE

# enum ofp_action_type
OFPAT_OUTPUT = 0    # Output to switch port.
OFPAT_COPY_TTL_OUT = 11  # Copy TTL "outwards" -- from
                         # next-to-outermost to outermost
OFPAT_COPY_TTL_IN = 12  # Copy TTL "inwards" -- from outermost to
                        # next-to-outermost
OFPAT_SET_MPLS_TTL = 15  # MPLS TTL.
OFPAT_DEC_MPLS_TTL = 16  # Decrement MPLS TTL
OFPAT_PUSH_VLAN = 17  # Push a new VLAN tag
OFPAT_POP_VLAN = 18  # Pop the outer VLAN tag
OFPAT_PUSH_MPLS = 19  # Push a new MPLS tag
OFPAT_POP_MPLS = 20  # Pop the outer MPLS tag
OFPAT_SET_QUEUE = 21  # Set queue id when outputting to a port
OFPAT_GROUP = 22  # Apply group
OFPAT_SET_NW_TTL = 23  # IP TTL.
OFPAT_DEC_NW_TTL = 24  # Decrement IP TTL.
OFPAT_SET_FIELD = 25  # Set a header field using OXM TLV format.
OFPAT_PUSH_PBB = 26  # Push a new PBB service tag (I-TAG)
OFPAT_POP_PBB = 27  # Pop the outer PBB service tag (I-TAG)
OFPAT_EXPERIMENTER = 0xffff

# struct ofp_action_header
OFP_ACTION_HEADER_PACK_STR = '!HH4x'
OFP_ACTION_HEADER_SIZE = 8
assert calcsize(OFP_ACTION_HEADER_PACK_STR) == OFP_ACTION_HEADER_SIZE

# struct ofp_action_output
OFP_ACTION_OUTPUT_PACK_STR = '!HHIH6x'
OFP_ACTION_OUTPUT_SIZE = 16
assert calcsize(OFP_ACTION_OUTPUT_PACK_STR) == OFP_ACTION_OUTPUT_SIZE

# enum ofp_controller_max_len
OFPCML_MAX = 0xffe5  # maximum max_len value which can be used to
                     # request a specific byte length.
OFPCML_NO_BUFFER = 0xffff  # indicates that no buffering should be
                           # applied and the whole packet is to be
                           # sent to the controller.

# struct ofp_action_group
OFP_ACTION_GROUP_PACK_STR = '!HHI'
OFP_ACTION_GROUP_SIZE = 8
assert calcsize(OFP_ACTION_GROUP_PACK_STR) == OFP_ACTION_GROUP_SIZE

# struct ofp_action_set_queue
OFP_ACTION_SET_QUEUE_PACK_STR = '!HHI'
OFP_ACTION_SET_QUEUE_SIZE = 8
assert calcsize(OFP_ACTION_SET_QUEUE_PACK_STR) == OFP_ACTION_SET_QUEUE_SIZE

# struct ofp_action_mpls_ttl
OFP_ACTION_MPLS_TTL_PACK_STR = '!HHB3x'
OFP_ACTION_MPLS_TTL_SIZE = 8
assert calcsize(OFP_ACTION_MPLS_TTL_PACK_STR) == OFP_ACTION_MPLS_TTL_SIZE

# struct ofp_action_nw_ttl
OFP_ACTION_NW_TTL_PACK_STR = '!HHB3x'
OFP_ACTION_NW_TTL_SIZE = 8
assert calcsize(OFP_ACTION_NW_TTL_PACK_STR) == OFP_ACTION_NW_TTL_SIZE

# struct ofp_action_push
OFP_ACTION_PUSH_PACK_STR = '!HHH2x'
OFP_ACTION_PUSH_SIZE = 8
assert calcsize(OFP_ACTION_PUSH_PACK_STR) == OFP_ACTION_PUSH_SIZE

# struct ofp_action_pop_mpls
OFP_ACTION_POP_MPLS_PACK_STR = '!HHH2x'
OFP_ACTION_POP_MPLS_SIZE = 8
assert calcsize(OFP_ACTION_POP_MPLS_PACK_STR) == OFP_ACTION_POP_MPLS_SIZE

# struct ofp_action_set_field
OFP_ACTION_SET_FIELD_PACK_STR = '!HH4x'
OFP_ACTION_SET_FIELD_SIZE = 8
assert calcsize(OFP_ACTION_SET_FIELD_PACK_STR) == OFP_ACTION_SET_FIELD_SIZE

# struct ofp_action_experimenter_header
OFP_ACTION_EXPERIMENTER_HEADER_PACK_STR = '!HHI'
OFP_ACTION_EXPERIMENTER_HEADER_SIZE = 8
assert (calcsize(OFP_ACTION_EXPERIMENTER_HEADER_PACK_STR) ==
        OFP_ACTION_EXPERIMENTER_HEADER_SIZE)

# ofp_switch_features
OFP_SWITCH_FEATURES_PACK_STR = '!QIBB2xII'
OFP_SWITCH_FEATURES_SIZE = 32
assert (calcsize(OFP_SWITCH_FEATURES_PACK_STR) + OFP_HEADER_SIZE ==
        OFP_SWITCH_FEATURES_SIZE)

# enum ofp_capabilities
OFPC_FLOW_STATS = 1 << 0    # Flow statistics.
OFPC_TABLE_STATS = 1 << 1    # Table statistics.
OFPC_PORT_STATS = 1 << 2    # Port statistics.
OFPC_GROUP_STATS = 1 << 3    # Group statistics.
OFPC_IP_REASM = 1 << 5        # Can reassemble IP fragments.
OFPC_QUEUE_STATS = 1 << 6    # Queue statistics.
OFPC_PORT_BLOCKED = 1 << 8    # Switch will block looping ports.

# struct ofp_switch_config
OFP_SWITCH_CONFIG_PACK_STR = '!HH'
OFP_SWITCH_CONFIG_SIZE = 12
assert (calcsize(OFP_SWITCH_CONFIG_PACK_STR) + OFP_HEADER_SIZE ==
        OFP_SWITCH_CONFIG_SIZE)

# enum ofp_config_flags
OFPC_FRAG_NORMAL = 0    # No special handling for fragments.
OFPC_FRAG_DROP = 1      # Drop fragments.
OFPC_FRAG_REASM = 2     # Reassemble (only if OFPC_IP_REASM set).
OFPC_FRAG_MASK = 3

# enum ofp_table
OFPTT_MAX = 0xfe
OFPTT_ALL = 0xff

# struct ofp_table_mod
OFP_TABLE_MOD_PACK_STR = '!B3xI'
OFP_TABLE_MOD_SIZE = 16
assert (calcsize(OFP_TABLE_MOD_PACK_STR) + OFP_HEADER_SIZE ==
        OFP_TABLE_MOD_SIZE)

_OFP_FLOW_MOD_PACK_STR0 = 'QQBBHHHIIIH2x'
OFP_FLOW_MOD_PACK_STR = '!' + _OFP_FLOW_MOD_PACK_STR0 + _OFP_MATCH_PACK_STR
OFP_FLOW_MOD_PACK_STR0 = '!' + _OFP_FLOW_MOD_PACK_STR0
OFP_FLOW_MOD_SIZE = 56
assert (calcsize(OFP_FLOW_MOD_PACK_STR) + OFP_HEADER_SIZE ==
        OFP_FLOW_MOD_SIZE)

# enum ofp_flow_mod_command
OFPFC_ADD = 0    # New flow.
OFPFC_MODIFY = 1    # Modify all matching flows.
OFPFC_MODIFY_STRICT = 2    # Modify entry strictly matching wildcards
OFPFC_DELETE = 3    # Delete all matching flows.
OFPFC_DELETE_STRICT = 4    # Strictly match wildcards and priority.

# enum ofp_flow_mod_flags
OFPFF_SEND_FLOW_REM = 1 << 0    # Send flow removed message when flow
                                # expires or is deleted.
OFPFF_CHECK_OVERLAP = 1 << 1    # Check for overlapping entries first.
OFPFF_RESET_COUNT = 1 << 2    # Reset flow packet and byte counts.
OFPFF_NO_PKT_COUNTS = 1 << 3    # Don't keep track of packet count.
OFPFF_NO_BYT_COUNTS = 1 << 4    # Don't keep track of byte count.

# struct ofp_group_mod
OFP_GROUP_MOD_PACK_STR = '!HBxI'
OFP_GROUP_MOD_SIZE = 16
assert (calcsize(OFP_GROUP_MOD_PACK_STR) + OFP_HEADER_SIZE ==
        OFP_GROUP_MOD_SIZE)

# enum ofp_group_mod_command
OFPGC_ADD = 0  # New group.
OFPGC_MODIFY = 1  # Modify all matching groups.
OFPGC_DELETE = 2  # Delete all matching groups.

# enum ofp_group
OFPG_MAX = 0xffffff00  # Last usable group number.
#Fake groups
OFPG_ALL = 0xfffffffc  # Represents all groups for group delete commands.
OFPG_ANY = 0xffffffff  # Wildcard group used only for flow stats requests.
                       # Selects all flows regardless of group
                       # (including flows with no group).

# enum ofp_group_type
OFPGT_ALL = 0  # All (multicast/broadcast) group.
OFPGT_SELECT = 1  # Select group.
OFPGT_INDIRECT = 2  # Indirect group.
OFPGT_FF = 3  # Fast failover group.

# struct ofp_bucket
OFP_BUCKET_PACK_STR = '!HHII4x'
OFP_BUCKET_SIZE = 16
assert calcsize(OFP_BUCKET_PACK_STR) == OFP_BUCKET_SIZE

# struct ofp_port_mod
OFP_PORT_MOD_PACK_STR = '!I4x' + OFP_ETH_ALEN_STR + 's2xIII4x'
OFP_PORT_MOD_SIZE = 40
assert (calcsize(OFP_PORT_MOD_PACK_STR) + OFP_HEADER_SIZE ==
        OFP_PORT_MOD_SIZE)

# struct ofp_meter_mod
OFP_METER_MOD_PACK_STR = '!HHI'
OFP_METER_MOD_SIZE = 16
assert (calcsize(OFP_METER_MOD_PACK_STR) + OFP_HEADER_SIZE ==
        OFP_METER_MOD_SIZE)

# enum ofp_meter
OFPM_MAX = 0xffff0000
OFPM_SLOWPATH = 0xfffffffd  # Meter for slow datapath, if any.
OFPM_CONTROLLER = 0xfffffffe  # Meter for controller connection.
OFPM_ALL = 0xffffffff  # Represents all meters for stat requests commands.

# enum ofp_meter_mod_command
OFPMC_ADD = 0  # New meter.
OFPMC_MODIFY = 1  # Modify specified meter.
OFPMC_DELETE = 2  # Delete specified meter.

# enum ofp_meter_flags
OFPMF_KBPS = 1 << 0  # Rate value in kb/s (kilo-bit per second).
OFPMF_PKTPS = 1 << 1  # Rate value in packet/sec.
OFPMF_BURST = 1 << 2  # Do burst size.
OFPMF_STATS = 1 << 3  # Collect statistics.

# struct ofp_meter_band_header
OFP_METER_BAND_HEADER_PACK_STR = '!HHII'
OFP_METER_BAND_HEADER_SIZE = 12
assert (calcsize(OFP_METER_BAND_HEADER_PACK_STR) ==
        OFP_METER_BAND_HEADER_SIZE)

# enum ofp_meter_band_type
OFPMBT_DROP = 1  # Drop packet.
OFPMBT_DSCP_REMARK = 2  # Remark DSCP in the IP header.
OFPMBT_EXPERIMENTER = 0xFFFF  # Experimenter meter band.

# struct ofp_meter_band_drop
OFP_METER_BAND_DROP_PACK_STR = '!HHII4x'
OFP_METER_BAND_DROP_SIZE = 16
assert (calcsize(OFP_METER_BAND_DROP_PACK_STR) ==
        OFP_METER_BAND_DROP_SIZE)

# struct ofp_meter_band_dscp_remark
OFP_METER_BAND_DSCP_REMARK_PACK_STR = '!HHIIB3x'
OFP_METER_BAND_DSCP_REMARK_SIZE = 16
assert (calcsize(OFP_METER_BAND_DSCP_REMARK_PACK_STR) ==
        OFP_METER_BAND_DSCP_REMARK_SIZE)

# struct ofp_meter_band_experimenter
OFP_METER_BAND_EXPERIMENTER_PACK_STR = '!HHIII'
OFP_METER_BAND_EXPERIMENTER_SIZE = 16
assert (calcsize(OFP_METER_BAND_EXPERIMENTER_PACK_STR) ==
        OFP_METER_BAND_EXPERIMENTER_SIZE)

# struct ofp_multipart_request
OFP_MULTIPART_REQUEST_PACK_STR = '!HH4x'
OFP_MULTIPART_REQUEST_SIZE = 16
assert (calcsize(OFP_MULTIPART_REQUEST_PACK_STR) + OFP_HEADER_SIZE ==
        OFP_MULTIPART_REQUEST_SIZE)

# enum ofp_multipart_request_flags
OFPMPF_REQ_MORE = 1 << 0  # More requests to follow.

# struct ofp_multipart_reply
OFP_MULTIPART_REPLY_PACK_STR = '!HH4x'
OFP_MULTIPART_REPLY_SIZE = 16
assert (calcsize(OFP_MULTIPART_REPLY_PACK_STR) + OFP_HEADER_SIZE ==
        OFP_MULTIPART_REPLY_SIZE)

# enum ofp_multipart_reply_flags
OFPMPF_REPLY_MORE = 1 << 0  # More replies to follow.

# enum ofp_multipart_types
OFPMP_DESC = 0
OFPMP_FLOW = 1
OFPMP_AGGREGATE = 2
OFPMP_TABLE = 3
OFPMP_PORT_STATS = 4
OFPMP_QUEUE = 5
OFPMP_GROUP = 6
OFPMP_GROUP_DESC = 7
OFPMP_GROUP_FEATURES = 8
OFPMP_METER = 9
OFPMP_METER_CONFIG = 10
OFPMP_METER_FEATURES = 11
OFPMP_TABLE_FEATURES = 12
OFPMP_PORT_DESC = 13
OFPMP_EXPERIMENTER = 0xffff

# struct ofp_desc
DESC_STR_LEN = 256
DESC_STR_LEN_STR = str(DESC_STR_LEN)
SERIAL_NUM_LEN = 32
SERIAL_NUM_LEN_STR = str(SERIAL_NUM_LEN)
OFP_DESC_PACK_STR = '!' + \
                    DESC_STR_LEN_STR + 's' + \
                    DESC_STR_LEN_STR + 's' + \
                    DESC_STR_LEN_STR + 's' + \
                    SERIAL_NUM_LEN_STR + 's' + \
                    DESC_STR_LEN_STR + 's'
OFP_DESC_SIZE = 1056
assert calcsize(OFP_DESC_PACK_STR) == OFP_DESC_SIZE


# struct ofp_flow_stats_request
_OFP_FLOW_STATS_REQUEST_0_PACK_STR = 'B3xII4xQQ'
OFP_FLOW_STATS_REQUEST_0_PACK_STR = '!' + _OFP_FLOW_STATS_REQUEST_0_PACK_STR
OFP_FLOW_STATS_REQUEST_0_SIZE = 32
assert (calcsize(OFP_FLOW_STATS_REQUEST_0_PACK_STR) ==
        OFP_FLOW_STATS_REQUEST_0_SIZE)
OFP_FLOW_STATS_REQUEST_PACK_STR = (OFP_FLOW_STATS_REQUEST_0_PACK_STR +
                                   _OFP_MATCH_PACK_STR)
OFP_FLOW_STATS_REQUEST_SIZE = 40
assert (calcsize(OFP_FLOW_STATS_REQUEST_PACK_STR) ==
        OFP_FLOW_STATS_REQUEST_SIZE)

# struct ofp_flow_stats
_OFP_FLOW_STATS_0_PACK_STR = 'HBxIIHHHH4xQQQ'
OFP_FLOW_STATS_0_PACK_STR = '!' + _OFP_FLOW_STATS_0_PACK_STR
OFP_FLOW_STATS_0_SIZE = 48
assert calcsize(OFP_FLOW_STATS_0_PACK_STR) == OFP_FLOW_STATS_0_SIZE
OFP_FLOW_STATS_PACK_STR = (OFP_FLOW_STATS_0_PACK_STR +
                           _OFP_MATCH_PACK_STR)
OFP_FLOW_STATS_SIZE = 56
assert calcsize(OFP_FLOW_STATS_PACK_STR) == OFP_FLOW_STATS_SIZE

# struct ofp_flow_stats_request
_OFP_AGGREGATE_STATS_REQUEST_0_PACK_STR = 'B3xII4xQQ'
OFP_AGGREGATE_STATS_REQUEST_0_PACK_STR = '!' + \
    _OFP_AGGREGATE_STATS_REQUEST_0_PACK_STR
OFP_AGGREGATE_STATS_REQUEST_0_SIZE = 32
assert (calcsize(OFP_AGGREGATE_STATS_REQUEST_0_PACK_STR) ==
        OFP_AGGREGATE_STATS_REQUEST_0_SIZE)
OFP_AGGREGATE_STATS_REQUEST_PACK_STR = \
    OFP_AGGREGATE_STATS_REQUEST_0_PACK_STR + _OFP_MATCH_PACK_STR
OFP_AGGREGATE_STATS_REQUEST_SIZE = 40
assert (calcsize(OFP_AGGREGATE_STATS_REQUEST_PACK_STR) ==
        OFP_AGGREGATE_STATS_REQUEST_SIZE)

# struct ofp_aggregate_stats_request
OFP_AGGREGATE_STATS_REQUEST_PACK_STR = '!B3xII4xQQ' + _OFP_MATCH_PACK_STR
OFP_AGGREGATE_STATS_REQUEST_SIZE = 40
assert (calcsize(OFP_AGGREGATE_STATS_REQUEST_PACK_STR) ==
        OFP_AGGREGATE_STATS_REQUEST_SIZE)

# struct ofp_aggregate_stats_reply
OFP_AGGREGATE_STATS_REPLY_PACK_STR = '!QQI4x'
OFP_AGGREGATE_STATS_REPLY_SIZE = 24
assert (calcsize(OFP_AGGREGATE_STATS_REPLY_PACK_STR) ==
        OFP_AGGREGATE_STATS_REPLY_SIZE)

# struct ofp_table_stats
OFP_TABLE_STATS_PACK_STR = '!B3xIQQ'
OFP_TABLE_STATS_SIZE = 24
assert calcsize(OFP_TABLE_STATS_PACK_STR) == OFP_TABLE_STATS_SIZE

# struct ofp_table_features
OFP_MAX_TABLE_NAME_LEN = 32
OFP_MAX_TABLE_NAME_LEN_STR = str(OFP_MAX_TABLE_NAME_LEN)
OFP_TABLE_FEATURES_PACK_STR = '!HB5x' + OFP_MAX_TABLE_NAME_LEN_STR + \
                              's' + 'QQII'
OFP_TABLE_FEATURES_SIZE = 64
assert (calcsize(OFP_TABLE_FEATURES_PACK_STR) ==
        OFP_TABLE_FEATURES_SIZE)

# enum ofp_table_feature_prop_type
OFPTFPT_INSTRUCTIONS = 0
OFPTFPT_INSTRUCTIONS_MISS = 1
OFPTFPT_NEXT_TABLES = 2
OFPTFPT_NEXT_TABLES_MISS = 3
OFPTFPT_WRITE_ACTIONS = 4
OFPTFPT_WRITE_ACTIONS_MISS = 5
OFPTFPT_APPLY_ACTIONS = 6
OFPTFPT_APPLY_ACTIONS_MISS = 7
OFPTFPT_MATCH = 8
OFPTFPT_WILDCARDS = 10
OFPTFPT_WRITE_SETFIELD = 12
OFPTFPT_WRITE_SETFIELD_MISS = 13
OFPTFPT_APPLY_SETFIELD = 14
OFPTFPT_APPLY_SETFIELD_MISS = 15
OFPTFPT_EXPERIMENTER = 0xFFFE
OFPTFPT_EXPERIMENTER_MISS = 0xFFFF

# struct ofp_table_feature_prop_instructions
OFP_TABLE_FEATURE_PROP_INSTRUCTIONS_PACK_STR = '!HH'
OFP_TABLE_FEATURE_PROP_INSTRUCTIONS_SIZE = 4
assert (calcsize(OFP_TABLE_FEATURE_PROP_INSTRUCTIONS_PACK_STR) ==
        OFP_TABLE_FEATURE_PROP_INSTRUCTIONS_SIZE)

# struct ofp_table_feature_prop_next_tables
OFP_TABLE_FEATURE_PROP_NEXT_TABLES_PACK_STR = '!HH'
OFP_TABLE_FEATURE_PROP_NEXT_TABLES_SIZE = 4
assert (calcsize(OFP_TABLE_FEATURE_PROP_NEXT_TABLES_PACK_STR) ==
        OFP_TABLE_FEATURE_PROP_NEXT_TABLES_SIZE)

# struct ofp_table_feature_prop_actions
OFP_TABLE_FEATURE_PROP_ACTIONS_PACK_STR = '!HH'
OFP_TABLE_FEATURE_PROP_ACTIONS_SIZE = 4
assert (calcsize(OFP_TABLE_FEATURE_PROP_ACTIONS_PACK_STR) ==
        OFP_TABLE_FEATURE_PROP_ACTIONS_SIZE)

# struct ofp_table_feature_prop_oxm
OFP_TABLE_FEATURE_PROP_OXM_PACK_STR = '!HH'
OFP_TABLE_FEATURE_PROP_OXM_SIZE = 4
assert (calcsize(OFP_TABLE_FEATURE_PROP_OXM_PACK_STR) ==
        OFP_TABLE_FEATURE_PROP_OXM_SIZE)

# struct ofp_port_stats_request
OFP_PORT_STATS_REQUEST_PACK_STR = '!I4x'
OFP_PORT_STATS_REQUEST_SIZE = 8
assert (calcsize(OFP_PORT_STATS_REQUEST_PACK_STR) ==
        OFP_PORT_STATS_REQUEST_SIZE)

# struct ofp_port_stats
OFP_PORT_STATS_PACK_STR = '!I4xQQQQQQQQQQQQII'
OFP_PORT_STATS_SIZE = 112
assert calcsize(OFP_PORT_STATS_PACK_STR) == OFP_PORT_STATS_SIZE

# struct ofp_queue_stats_request
OFP_QUEUE_STATS_REQUEST_PACK_STR = '!II'
OFP_QUEUE_STATS_REQUEST_SIZE = 8
assert (calcsize(OFP_QUEUE_STATS_REQUEST_PACK_STR) ==
        OFP_QUEUE_STATS_REQUEST_SIZE)

# struct ofp_queue_stats
OFP_QUEUE_STATS_PACK_STR = '!IIQQQII'
OFP_QUEUE_STATS_SIZE = 40
assert calcsize(OFP_QUEUE_STATS_PACK_STR) == OFP_QUEUE_STATS_SIZE

# struct ofp_group_stats_request
OFP_GROUP_STATS_REQUEST_PACK_STR = '!I4x'
OFP_GROUP_STATS_REQUEST_SIZE = 8
assert (calcsize(OFP_GROUP_STATS_REQUEST_PACK_STR) ==
        OFP_GROUP_STATS_REQUEST_SIZE)

# struct ofp_group_stats
OFP_GROUP_STATS_PACK_STR = '!H2xII4xQQII'
OFP_GROUP_STATS_SIZE = 40
assert calcsize(OFP_GROUP_STATS_PACK_STR) == OFP_GROUP_STATS_SIZE

# struct ofp_bucket_counter
OFP_BUCKET_COUNTER_PACK_STR = '!QQ'
OFP_BUCKET_COUNTER_SIZE = 16
assert calcsize(OFP_BUCKET_COUNTER_PACK_STR) == OFP_BUCKET_COUNTER_SIZE

# struct ofp_group_desc_stats
OFP_GROUP_DESC_STATS_PACK_STR = '!HBxI'
OFP_GROUP_DESC_STATS_SIZE = 8
assert calcsize(OFP_GROUP_DESC_STATS_PACK_STR) == OFP_GROUP_DESC_STATS_SIZE

# struct ofp_group_features
OFP_GROUP_FEATURES_PACK_STR = '!II4I4I'
OFP_GROUP_FEATURES_SIZE = 40
assert calcsize(OFP_GROUP_FEATURES_PACK_STR) == OFP_GROUP_FEATURES_SIZE

# enum ofp_group_capabilities
OFPGFC_SELECT_WEIGHT = 1 << 0  # Support weight for select groups.
OFPGFC_SELECT_LIVENESS = 1 << 1  # Support liveness for select groups.
OFPGFC_CHAINING = 1 << 2  # Support chaining groups.
OFPGFC_CHAINING_CHECKS = 1 << 3  # Check chaining for loops and delete

# struct ofp_meter_multipart_request
OFP_METER_MULTIPART_REQUEST_PACK_STR = '!I4x'
OFP_METER_MULTIPART_REQUEST_SIZE = 8
assert (calcsize(OFP_METER_MULTIPART_REQUEST_PACK_STR) ==
        OFP_METER_MULTIPART_REQUEST_SIZE)

# struct ofp_meter_stats
OFP_METER_STATS_PACK_STR = '!IH6xIQQII'
OFP_METER_STATS_SIZE = 40
assert calcsize(OFP_METER_STATS_PACK_STR) == OFP_METER_STATS_SIZE

# struct ofp_meter_band_stats
OFP_METER_BAND_STATS_PACK_STR = '!QQ'
OFP_METER_BAND_STATS_SIZE = 16
assert (calcsize(OFP_METER_BAND_STATS_PACK_STR) ==
        OFP_METER_BAND_STATS_SIZE)

# struct ofp_meter_config
OFP_METER_CONFIG_PACK_STR = '!HHI'
OFP_METER_CONFIG_SIZE = 8
assert calcsize(OFP_METER_CONFIG_PACK_STR) == OFP_METER_CONFIG_SIZE

# struct ofp_meter_features
OFP_METER_FEATURES_PACK_STR = '!IIIBB2x'
OFP_METER_FEATURES_SIZE = 16
assert (calcsize(OFP_METER_FEATURES_PACK_STR) ==
        OFP_METER_FEATURES_SIZE)

# struct ofp_experimenter_multipart_header
OFP_EXPERIMENTER_MULTIPART_HEADER_PACK_STR = '!II'
OFP_EXPERIMENTER_MULTIPART_HEADER_SIZE = 8
assert (calcsize(OFP_EXPERIMENTER_MULTIPART_HEADER_PACK_STR) ==
        OFP_EXPERIMENTER_MULTIPART_HEADER_SIZE)

# struct ofp_queue_get_config_request
OFP_QUEUE_GET_CONFIG_REQUEST_PACK_STR = '!I4x'
OFP_QUEUE_GET_CONFIG_REQUEST_SIZE = 16
assert (calcsize(OFP_QUEUE_GET_CONFIG_REQUEST_PACK_STR) +
        OFP_HEADER_SIZE) == OFP_QUEUE_GET_CONFIG_REQUEST_SIZE

# struct ofp_queue_get_config_reply
OFP_QUEUE_GET_CONFIG_REPLY_PACK_STR = '!I4x'
OFP_QUEUE_GET_CONFIG_REPLY_SIZE = 16
assert (calcsize(OFP_QUEUE_GET_CONFIG_REPLY_PACK_STR) +
        OFP_HEADER_SIZE) == OFP_QUEUE_GET_CONFIG_REPLY_SIZE

# struct ofp_packet_out
OFP_PACKET_OUT_PACK_STR = '!IIH6x'
OFP_PACKET_OUT_SIZE = 24
assert (calcsize(OFP_PACKET_OUT_PACK_STR) + OFP_HEADER_SIZE ==
        OFP_PACKET_OUT_SIZE)

# struct ofp_role_request
OFP_ROLE_REQUEST_PACK_STR = '!I4xQ'
OFP_ROLE_REQUEST_SIZE = 24
assert (calcsize(OFP_ROLE_REQUEST_PACK_STR) + OFP_HEADER_SIZE ==
        OFP_ROLE_REQUEST_SIZE)

# enum ofp_controller_role
OFPCR_ROLE_NOCHANGE = 0  # Don't change current role.
OFPCR_ROLE_EQUAL = 1  # Default role, full access.
OFPCR_ROLE_MASTER = 2  # Full access, at most one master.
OFPCR_ROLE_SLAVE = 3  # Read-only access.

# struct ofp_async_config
OFP_ASYNC_CONFIG_PACK_STR = '!2I2I2I'
OFP_ASYNC_CONFIG_SIZE = 32
assert (calcsize(OFP_ASYNC_CONFIG_PACK_STR) + OFP_HEADER_SIZE ==
        OFP_ASYNC_CONFIG_SIZE)

# struct ofp_packet_in
OFP_PACKET_IN_PACK_STR = '!IHBBQ'
OFP_PACKET_IN_SIZE = 32
assert (calcsize(OFP_PACKET_IN_PACK_STR) + OFP_MATCH_SIZE + OFP_HEADER_SIZE ==
        OFP_PACKET_IN_SIZE)

# enum ofp_packet_in_reason
OFPR_NO_MATCH = 0    # No matching flow.
OFPR_ACTION = 1        # Action explicitly output to controller.
OFPR_INVALID_TTL = 2    # Packet has invalid TTL.

# struct ofp_flow_removed
_OFP_FLOW_REMOVED_PACK_STR0 = 'QHBBIIHHQQ'
OFP_FLOW_REMOVED_PACK_STR = '!' + _OFP_FLOW_REMOVED_PACK_STR0 + \
                            _OFP_MATCH_PACK_STR
OFP_FLOW_REMOVED_PACK_STR0 = '!' + _OFP_FLOW_REMOVED_PACK_STR0
OFP_FLOW_REMOVED_SIZE = 56
assert (calcsize(OFP_FLOW_REMOVED_PACK_STR) + OFP_HEADER_SIZE ==
        OFP_FLOW_REMOVED_SIZE)

# enum ofp_flow_removed_reason
OFPRR_IDLE_TIMEOUT = 0    # Flow idle time exceeded idle_timeout.
OFPRR_HARD_TIMEOUT = 1    # Time exceeded hard_timeout.
OFPRR_DELETE = 2    # Evicted by a DELETE flow mod.
OFPRR_GROUP_DELETE = 3  # Group was removed.

# struct ofp_port_status
OFP_PORT_STATUS_PACK_STR = '!B7x' + _OFP_PORT_PACK_STR
OFP_PORT_STATUS_DESC_OFFSET = OFP_HEADER_SIZE + 8
OFP_PORT_STATUS_SIZE = 80
assert (calcsize(OFP_PORT_STATUS_PACK_STR) + OFP_HEADER_SIZE ==
        OFP_PORT_STATUS_SIZE)

# enum ofp_port_reason
OFPPR_ADD = 0    # The port was added.
OFPPR_DELETE = 1    # The port was removed.
OFPPR_MODIFY = 2    # Some attribute of the port has changed.

# struct ofp_error_msg
OFP_ERROR_MSG_PACK_STR = '!HH'
OFP_ERROR_MSG_SIZE = 12
assert (calcsize(OFP_ERROR_MSG_PACK_STR) + OFP_HEADER_SIZE ==
        OFP_ERROR_MSG_SIZE)

# enum ofp_error_type
OFPET_HELLO_FAILED = 0        # Hello protocol failed.
OFPET_BAD_REQUEST = 1        # Request was not understood.
OFPET_BAD_ACTION = 2        # Error in action description.
OFPET_BAD_INSTRUCTION = 3    # Error in instruction list.
OFPET_BAD_MATCH = 4        # Error in match.
OFPET_FLOW_MOD_FAILED = 5    # Problem modifying flow entry.
OFPET_GROUP_MOD_FAILED = 6    # Problem modifying group entry.
OFPET_PORT_MOD_FAILED = 7    # OFPT_PORT_MOD failed.
OFPET_TABLE_MOD_FAILED = 8    # Table mod request failed.
OFPET_QUEUE_OP_FAILED = 9    # Queue operation failed.
OFPET_SWITCH_CONFIG_FAILED = 10    # Switch config request failed.
OFPET_ROLE_REQUEST_FAILED = 11    # Controller Role request failed.
OFPET_METER_MOD_FAILED = 12    # Error in meter.
OFPET_TABLE_FEATURES_FAILED = 13    # Setting table features failed.
OFPET_EXPERIMENTER = 0xffff    # Experimenter error messages.

# enum ofp_hello_failed_code
OFPHFC_INCOMPATIBLE = 0        # No compatible version.
OFPHFC_EPERM = 1        # Permissions error.

# enum ofp_bad_request_code
OFPBRC_BAD_VERSION = 0        # ofp_header.version not supported.
OFPBRC_BAD_TYPE = 1        # ofp_header.type not supported.
OFPBRC_BAD_MULTIPART = 2        # ofp_stats_msg.type not supported.
OFPBRC_BAD_EXPERIMENTER = 3    # Experimenter id not supported
                               # (in ofp_experimenter_header
                               # or ofp_stats_request or
                               # ofp_stats_reply).
OFPBRC_BAD_EXP_TYPE = 4        # Experimenter type not supported.
OFPBRC_EPERM = 5        # Permissions error.
OFPBRC_BAD_LEN = 6        # Wrong request length for type.
OFPBRC_BUFFER_EMPTY = 7        # Specified buffer has already been used.
OFPBRC_BUFFER_UNKNOWN = 8    # Specified buffer does not exist.
OFPBRC_BAD_TABLE_ID = 9        # Specified table-id invalid or does not exist.
OFPBRC_IS_SLAVE = 10        # Denied because controller is slave.
OFPBRC_BAD_PORT = 11        # Invalid port.
OFPBRC_BAD_PACKET = 12        # Invalid packet in packet-out
OFPBRC_MULTIPART_BUFFER_OVERFLOW = 13       # ofp_multipart_request
                                            # overflowed the assigned buffer.

# enum ofp_bad_action_code
OFPBAC_BAD_TYPE = 0        # Unknown action type.
OFPBAC_BAD_LEN = 1        # Length problem in actions.
OFPBAC_BAD_EXPERIMENTER = 2    # Unknown experimenter id specified.
OFPBAC_BAD_EXP_TYPE = 3        # Unknown action type for experimenter id.
OFPBAC_BAD_OUT_PORT = 4        # Problem validating output action.
OFPBAC_BAD_ARGUMENT = 5        # Bad action argument.
OFPBAC_EPERM = 6        # Permissions error.
OFPBAC_TOO_MANY = 7        # Can't handle this many actions.
OFPBAC_BAD_QUEUE = 8        # Problem validating output queue.
OFPBAC_BAD_OUT_GROUP = 9    # Invalid group id in forward action.
OFPBAC_MATCH_INCONSISTENT = 10    # Action can't apply for this match,
                                  # or Set-Field missing prerequisite.
OFPBAC_UNSUPPORTED_ORDER = 11    # Action order is unsupported for
                                 # the action list in an Apply-Actions
                                 # instruction
OFPBAC_BAD_TAG = 12        # Actions uses an unsupported tag/encap.
OFPBAC_BAD_SET_TYPE = 13        # Unsupported type in SET_FIELD action.
OFPBAC_BAD_SET_LEN = 14        # Length problem in SET_FIELD action.
OFPBAC_BAD_SET_ARGUMENT = 15    # Bad arguement in SET_FIELD action.

# enum ofp_bad_instruction_code
OFPBIC_UNKNOWN_INST = 0        # Unknown instruction.
OFPBIC_UNSUP_INST = 1        # Switch or table does not support
                             # the instruction.
OFPBIC_BAD_TABLE_ID = 2        # Invalid Table-Id specified
OFPBIC_UNSUP_METADATA = 3    # Metadata value unsupported by datapath.
OFPBIC_UNSUP_METADATA_MASK = 4    # Metadata mask value unsupported by
                                  # datapath.
OFPBIC_BAD_EXPERIMENTER = 5    # Unknown experimenter id specified.
OFPBIC_BAD_EXP_TYPE = 6        # Unknown instruction for experimenter id.
OFPBIC_BAD_EXP_LEN = 7        # Length problem in instrucitons.
OFPBIC_EPERM = 8        # Permissions error.

# enum ofp_bad_match_code
OFPBMC_BAD_TYPE = 0        # Unsupported match type apecified by
                           # the match.
OFPBMC_BAD_LEN = 1        # Length problem in math.
OFPBMC_BAD_TAG = 2        # Match uses an unsupported tag/encap.
OFPBMC_BAD_DL_ADDR_MASK = 3    # Unsupported datalink addr mask -
                                # switch does not support arbitrary
                                # datalink address mask.
OFPBMC_BAD_NW_ADDR_MASK = 4    # Unsupported network addr mask -
                                # switch does not support arbitrary
                                # network addres mask.
OFPBMC_BAD_WILDCARDS = 5    # Unsupported combination of fields
                                # masked or omitted in the match.
OFPBMC_BAD_FIELD = 6        # Unsupported field type in the match.
OFPBMC_BAD_VALUE = 7        # Unsupported value in a match field.
OFPBMC_BAD_MASK = 8        # Unsupported mask specified in the
                                # match.
OFPBMC_BAD_PREREQ = 9        # A prerequisite was not met.
OFPBMC_DUP_FIELD = 10        # A field type was duplicated.
OFPBMC_EPERM = 11         # Permissions error.

# enum ofp_flow_mod_failed_code
OFPFMFC_UNKNOWN = 0        # Unspecified error.
OFPFMFC_TABLES_FULL = 1        # Flow not added because table was full.
OFPFMFC_BAD_TABLE_ID = 2    # Table does not exist
OFPFMFC_OVERLAP = 3        # Attempted to add overlapping flow
                                # with CHECK_OVERLAP flag set.
OFPFMFC_EPERM = 4        # Permissions error.
OFPFMFC_BAD_TIMEOUT = 5        # Flow not added because of
                                # unsupported idle/hard timeout.
OFPFMFC_BAD_COMMAND = 6        # Unsupported or unknown command.
OFPFMFC_BAD_FLAGS = 7        # Unsupported or unknown flags.

# enum ofp_group_mod_failed_code
OFPGMFC_GROUP_EXISTS = 0
OFPGMFC_INVALID_GROUP = 1
OFPGMFC_WEIGHT_UNSUPPORTED = 2    # Switch does not support unequal load
                                  # sharing with select groups.
OFPGMFC_OUT_OF_GROUPS = 3         # The group table is full.
OFPGMFC_OUT_OF_BUCKETS = 4        # The maximum number of action buckets
                                  # for a group has been exceeded.
OFPGMFC_CHAINING_UNSUPPORTED = 5  # Switch does not support groups that
                                  # forward to groups.
OFPGMFC_WATCH_UNSUPPORTED = 6     # This group cannot watch the
                                  # watch_port or watch_group specified.
OFPGMFC_LOOP = 7                  # Group entry would cause a loop.
OFPGMFC_UNKNOWN_GROUP = 8         # Group not modified because a group
                                  # MODIFY attempted to modify a
                                  # non-existent group.
OFPGMFC_CHAINED_GROUP = 9         # Group not deleted because another
                                  # group is forwarding to it.
OFPGMFC_BAD_TYPE = 10             # Unsupported or unknown group type.
OFPGMFC_BAD_COMMAND = 11          # Unsupported or unknown command.
OFPGMFC_BAD_BUCKET = 12           # Error in bucket.
OFPGMFC_BAD_WATCH = 13            # Error in watch port/group.
OFPGMFC_EPERM = 14                # Permissions error.

# enum ofp_port_mod_failed_code
OFPPMFC_BAD_PORT = 0        # Specified port does not exist.
OFPPMFC_BAD_HW_ADDR = 1        # Specified hardware address does not
                                # match the port number.
OFPPMFC_BAD_CONFIG = 2        # Specified config is invalid.
OFPPMFC_BAD_ADVERTISE = 3    # Specified advertise is invalid.
OFPPMFC_EPERM = 4        # Permissions error.

# enum ofp_table_mod_failed_code
OFPTMFC_BAD_TABLE = 0        # Specified table does not exist.
OFPTMFC_BAD_CONFIG = 1        # Specified config is invalid.
OFPTMFC_EPERM = 2        # Permissions error

# enum ofp_queue_op_failed_code
OFPQOFC_BAD_PORT = 0        # Invalid port (or port does not exist).
OFPQOFC_BAD_QUEUE = 1        # Queue does not exist.
OFPQOFC_EPERM = 2        # Permissions error.

# enum ofp_switch_config_failed_code
OFPSCFC_BAD_FLAGS = 0        # Specified flags is invalid.
OFPSCFC_BAD_LEN = 1        # Specified len is invalid.
OFPQCFC_EPERM = 2        # Permissions error.

# enum ofp_role_request_failed_code
OFPRRFC_STALE = 0        # Stale Message: old generation_id.
OFPRRFC_UNSUP = 1        # Controller role change unsupported.
OFPRRFC_BAD_ROLE = 2        # Invalid role.

# enum ofp_meter_mod_failed_code
OFPMMFC_UNKNOWN = 0        # Unspecified error.
OFPMMFC_METER_EXISTS = 1        # Meter not added because a Meter ADD
                                # attempted to replace an existing Meter.
OFPMMFC_INVALID_METER = 2        # Meter not added because Meter specified
                                # is invalid.
OFPMMFC_UNKNOWN_METER = 3        # Meter not modified because a Meter
                                 # MODIFY attempted to modify a non-existent
                                 # Meter.
OFPMMFC_BAD_COMMAND = 4        # Unsupported or unknown command.
OFPMMFC_BAD_FLAGS = 5        # Flag configuration unsupported.
OFPMMFC_BAD_RATE = 6        # Rate unsupported.
OFPMMFC_BAD_BURST = 7        # Burst size unsupported.
OFPMMFC_BAD_BAND = 8        # Band unsupported.
OFPMMFC_BAD_BAND_VALUE = 9        # Band value unsupported.
OFPMMFC_OUT_OF_METERS = 10        # No more meters availabile.
OFPMMFC_OUT_OF_BANDS = 11        # The maximum number of properties
                                 # for a meter has been exceeded.

# enum ofp_table_features_failed_code
OFPTFFC_BAD_TABLE = 0        # Specified table does not exist.
OFPTFFC_BAD_METADATA = 1        # Invalid metadata mask.
OFPTFFC_BAD_TYPE = 2        # Unknown property type.
OFPTFFC_BAD_LEN = 3        # Length problem in properties.
OFPTFFC_BAD_ARGUMENT = 4        # Unsupported property value.
OFPTFFC_EPERM = 5        # Permissions error.

# struct ofp_error_experimenter_msg
OFP_ERROR_EXPERIMENTER_MSG_PACK_STR = '!HHI'
OFP_ERROR_EXPERIMENTER_MSG_SIZE = 16
assert (calcsize(OFP_ERROR_EXPERIMENTER_MSG_PACK_STR) +
        OFP_HEADER_SIZE) == OFP_ERROR_EXPERIMENTER_MSG_SIZE

# struct ofp_experimenter_header
OFP_EXPERIMENTER_HEADER_PACK_STR = '!II'
OFP_EXPERIMENTER_HEADER_SIZE = 16
assert (calcsize(OFP_EXPERIMENTER_HEADER_PACK_STR) + OFP_HEADER_SIZE
        == OFP_EXPERIMENTER_HEADER_SIZE)

# struct ofp_hello
OFP_HELLO_HEADER_SIZE = 8

# struct ofp_hello_elem_header
OFP_HELLO_ELEM_HEADER_PACK_STR = '!HH'
OFP_HELLO_ELEM_HEADER_SIZE = 4
assert (calcsize(OFP_HELLO_ELEM_HEADER_PACK_STR) == OFP_HELLO_ELEM_HEADER_SIZE)

# enum ofp_hello_elem_type
OFPHET_VERSIONBITMAP = 1

# struct ofp_hello_elem_versionbitmap
OFP_HELLO_ELEM_VERSIONBITMAP_HEADER_PACK_STR = '!HH'
OFP_HELLO_ELEM_VERSIONBITMAP_HEADER_SIZE = 4
assert (calcsize(OFP_HELLO_ELEM_VERSIONBITMAP_HEADER_PACK_STR) ==
        OFP_HELLO_ELEM_VERSIONBITMAP_HEADER_SIZE)

# OXM


def _oxm_tlv_header(class_, field, hasmask, length):
    return (class_ << 16) | (field << 9) | (hasmask << 8) | length


def oxm_tlv_header(field, length):
    return _oxm_tlv_header(OFPXMC_OPENFLOW_BASIC, field, 0, length)


def oxm_tlv_header_w(field, length):
    return _oxm_tlv_header(OFPXMC_OPENFLOW_BASIC, field, 1, length * 2)


def oxm_tlv_header_extract_hasmask(header):
    return (header >> 8) & 1


def oxm_tlv_header_extract_length(header):
    if oxm_tlv_header_extract_hasmask(header):
        length = (header & 0xff) / 2
    else:
        length = header & 0xff
    return length

oxm_types = [
    oxm_fields.OpenFlowBasic('in_port', 0, oxm_fields.Int4),
    oxm_fields.OpenFlowBasic('in_phy_port', 1, oxm_fields.Int4),
    oxm_fields.OpenFlowBasic('metadata', 2, oxm_fields.Int8),
    oxm_fields.OpenFlowBasic('eth_dst', 3, oxm_fields.MacAddr),
    oxm_fields.OpenFlowBasic('eth_src', 4, oxm_fields.MacAddr),
    oxm_fields.OpenFlowBasic('eth_type', 5, oxm_fields.Int2),
    oxm_fields.OpenFlowBasic('vlan_vid', 6, oxm_fields.Int2),
    oxm_fields.OpenFlowBasic('vlan_pcp', 7, oxm_fields.Int1),
    oxm_fields.OpenFlowBasic('ip_dscp', 8, oxm_fields.Int1),
    oxm_fields.OpenFlowBasic('ip_ecn', 9, oxm_fields.Int1),
    oxm_fields.OpenFlowBasic('ip_proto', 10, oxm_fields.Int1),
    oxm_fields.OpenFlowBasic('ipv4_src', 11, oxm_fields.IPv4Addr),
    oxm_fields.OpenFlowBasic('ipv4_dst', 12, oxm_fields.IPv4Addr),
    oxm_fields.OpenFlowBasic('tcp_src', 13, oxm_fields.Int2),
    oxm_fields.OpenFlowBasic('tcp_dst', 14, oxm_fields.Int2),
    oxm_fields.OpenFlowBasic('udp_src', 15, oxm_fields.Int2),
    oxm_fields.OpenFlowBasic('udp_dst', 16, oxm_fields.Int2),
    oxm_fields.OpenFlowBasic('sctp_src', 17, oxm_fields.Int2),
    oxm_fields.OpenFlowBasic('sctp_dst', 18, oxm_fields.Int2),
    oxm_fields.OpenFlowBasic('icmpv4_type', 19, oxm_fields.Int1),
    oxm_fields.OpenFlowBasic('icmpv4_code', 20, oxm_fields.Int1),
    oxm_fields.OpenFlowBasic('arp_op', 21, oxm_fields.Int2),
    oxm_fields.OpenFlowBasic('arp_spa', 22, oxm_fields.IPv4Addr),
    oxm_fields.OpenFlowBasic('arp_tpa', 23, oxm_fields.IPv4Addr),
    oxm_fields.OpenFlowBasic('arp_sha', 24, oxm_fields.MacAddr),
    oxm_fields.OpenFlowBasic('arp_tha', 25, oxm_fields.MacAddr),
    oxm_fields.OpenFlowBasic('ipv6_src', 26, oxm_fields.IPv6Addr),
    oxm_fields.OpenFlowBasic('ipv6_dst', 27, oxm_fields.IPv6Addr),
    oxm_fields.OpenFlowBasic('ipv6_flabel', 28, oxm_fields.Int4),
    oxm_fields.OpenFlowBasic('icmpv6_type', 29, oxm_fields.Int1),
    oxm_fields.OpenFlowBasic('icmpv6_code', 30, oxm_fields.Int1),
    oxm_fields.OpenFlowBasic('ipv6_nd_target', 31, oxm_fields.IPv6Addr),
    oxm_fields.OpenFlowBasic('ipv6_nd_sll', 32, oxm_fields.MacAddr),
    oxm_fields.OpenFlowBasic('ipv6_nd_tll', 33, oxm_fields.MacAddr),
    oxm_fields.OpenFlowBasic('mpls_label', 34, oxm_fields.Int4),
    oxm_fields.OpenFlowBasic('mpls_tc', 35, oxm_fields.Int1),
    oxm_fields.OpenFlowBasic('mpls_bos', 36, oxm_fields.Int1),
    oxm_fields.OpenFlowBasic('pbb_isid', 37, oxm_fields.Int3),
    oxm_fields.OpenFlowBasic('tunnel_id', 38, oxm_fields.Int8),
    oxm_fields.OpenFlowBasic('ipv6_exthdr', 39, oxm_fields.Int2),
]

oxm_fields.generate(__name__)


# define constants
OFP_VERSION = 0x04
OFP_TCP_PORT = 6633
MAX_XID = 0xffffffff

OFP_NO_BUFFER = 0xffffffff

########NEW FILE########
__FILENAME__ = ofproto_v1_3_parser
# Copyright (C) 2012 Nippon Telegraph and Telephone Corporation.
# Copyright (C) 2012, 2013 Isaku Yamahata <yamahata at valinux co jp>
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import struct
import itertools

from ryu.lib import addrconv
from ryu.lib import mac
from ryu import utils
from ofproto_parser import StringifyMixin, MsgBase, msg_pack_into, msg_str_attr
from . import ofproto_parser
from . import ofproto_v1_3

import logging
LOG = logging.getLogger('ryu.ofproto.ofproto_v1_3_parser')

_MSG_PARSERS = {}


def _set_msg_type(msg_type):
    def _set_cls_msg_type(cls):
        cls.cls_msg_type = msg_type
        return cls
    return _set_cls_msg_type


def _register_parser(cls):
    '''class decorator to register msg parser'''
    assert cls.cls_msg_type is not None
    assert cls.cls_msg_type not in _MSG_PARSERS
    _MSG_PARSERS[cls.cls_msg_type] = cls.parser
    return cls


@ofproto_parser.register_msg_parser(ofproto_v1_3.OFP_VERSION)
def msg_parser(datapath, version, msg_type, msg_len, xid, buf):
    parser = _MSG_PARSERS.get(msg_type)
    return parser(datapath, version, msg_type, msg_len, xid, buf)


@_register_parser
@_set_msg_type(ofproto_v1_3.OFPT_HELLO)
class OFPHello(MsgBase):
    """
    Hello message

    When connection is started, the hello message is exchanged between a
    switch and a controller.

    This message is handled by the Ryu framework, so the Ryu application
    do not need to process this typically.

    ========== =========================================================
    Attribute  Description
    ========== =========================================================
    elements   list of ``OFPHelloElemVersionBitmap`` instance
    ========== =========================================================
    """
    def __init__(self, datapath, elements=[]):
        super(OFPHello, self).__init__(datapath)
        self.elements = elements

    @classmethod
    def parser(cls, datapath, version, msg_type, msg_len, xid, buf):
        msg = super(OFPHello, cls).parser(datapath, version, msg_type,
                                          msg_len, xid, buf)

        offset = ofproto_v1_3.OFP_HELLO_HEADER_SIZE
        elems = []
        while offset < msg.msg_len:
            type_, length = struct.unpack_from(
                ofproto_v1_3.OFP_HELLO_ELEM_HEADER_PACK_STR, msg.buf, offset)

            # better to register Hello Element classes but currently
            # Only VerisonBitmap is supported so let's be simple.

            if type_ == ofproto_v1_3.OFPHET_VERSIONBITMAP:
                elem = OFPHelloElemVersionBitmap.parser(msg.buf, offset)
                elems.append(elem)

            offset += length
        msg.elements = elems
        return msg


class OFPHelloElemVersionBitmap(StringifyMixin):
    """
    Version bitmap Hello Element

    ========== =========================================================
    Attribute  Description
    ========== =========================================================
    versions   list of versions of OpenFlow protocol a device supports
    ========== =========================================================
    """
    def __init__(self, versions, type_=None, length=None):
        super(OFPHelloElemVersionBitmap, self).__init__()
        self.type = ofproto_v1_3.OFPHET_VERSIONBITMAP
        self.length = None
        self._bitmaps = None
        self.versions = versions

    @classmethod
    def parser(cls, buf, offset):
        type_, length = struct.unpack_from(
            ofproto_v1_3.OFP_HELLO_ELEM_VERSIONBITMAP_HEADER_PACK_STR,
            buf, offset)
        assert type_ == ofproto_v1_3.OFPHET_VERSIONBITMAP

        bitmaps_len = (length -
                       ofproto_v1_3.OFP_HELLO_ELEM_VERSIONBITMAP_HEADER_SIZE)
        offset += ofproto_v1_3.OFP_HELLO_ELEM_VERSIONBITMAP_HEADER_SIZE
        bitmaps = []
        while bitmaps_len >= 4:
            bitmap = struct.unpack_from('!I', buf, offset)
            bitmaps.append(bitmap[0])
            offset += 4
            bitmaps_len -= 4

        versions = [i * 32 + shift
                    for i, bitmap in enumerate(bitmaps)
                    for shift in range(31) if bitmap & (1 << shift)]
        elem = cls(versions)
        elem.length = length
        elem._bitmaps = bitmaps
        return elem


@_register_parser
@_set_msg_type(ofproto_v1_3.OFPT_ERROR)
class OFPErrorMsg(MsgBase):
    """
    Error message

    The switch notifies controller of problems by this message.

    ========== =========================================================
    Attribute  Description
    ========== =========================================================
    type       High level type of error
    code       Details depending on the type
    data       Variable length data depending on the type and code
    ========== =========================================================

    ``type`` attribute corresponds to ``type_`` parameter of __init__.

    Types and codes are defined in ``ryu.ofproto.ofproto_v1_3``.

    ============================= ===========
    Type                          Code
    ============================= ===========
    OFPET_HELLO_FAILED            OFPHFC_*
    OFPET_BAD_REQUEST             OFPBRC_*
    OFPET_BAD_ACTION              OFPBAC_*
    OFPET_BAD_INSTRUCTION         OFPBIC_*
    OFPET_BAD_MATCH               OFPBMC_*
    OFPET_FLOW_MOD_FAILED         OFPFMFC_*
    OFPET_GROUP_MOD_FAILED        OFPGMFC_*
    OFPET_PORT_MOD_FAILED         OFPPMFC_*
    OFPET_TABLE_MOD_FAILED        OFPTMFC_*
    OFPET_QUEUE_OP_FAILED         OFPQOFC_*
    OFPET_SWITCH_CONFIG_FAILED    OFPSCFC_*
    OFPET_ROLE_REQUEST_FAILED     OFPRRFC_*
    OFPET_METER_MOD_FAILED        OFPMMFC_*
    OFPET_TABLE_FEATURES_FAILED   OFPTFFC_*
    OFPET_EXPERIMENTER            N/A
    ============================= ===========

    Example::

        @set_ev_cls(ofp_event.EventOFPErrorMsg,
                    [HANDSHAKE_DISPATCHER, CONFIG_DISPATCHER, MAIN_DISPATCHER])
        def error_msg_handler(self, ev):
            msg = ev.msg

            self.logger.debug('OFPErrorMsg received: type=0x%02x code=0x%02x '
                              'message=%s',
                              msg.type, msg.code, utils.hex_array(msg.data))
    """
    def __init__(self, datapath, type_=None, code=None, data=None):
        super(OFPErrorMsg, self).__init__(datapath)
        self.type = type_
        self.code = code
        self.data = data

    @classmethod
    def parser(cls, datapath, version, msg_type, msg_len, xid, buf):
        type_, = struct.unpack_from('!H', buffer(buf),
                                    ofproto_v1_3.OFP_HEADER_SIZE)
        if type_ == ofproto_v1_3.OFPET_EXPERIMENTER:
            return OFPErrorExperimenterMsg.parser(datapath, version, msg_type,
                                                  msg_len, xid, buf)
        msg = super(OFPErrorMsg, cls).parser(datapath, version, msg_type,
                                             msg_len, xid, buf)
        msg.type, msg.code = struct.unpack_from(
            ofproto_v1_3.OFP_ERROR_MSG_PACK_STR, msg.buf,
            ofproto_v1_3.OFP_HEADER_SIZE)
        msg.data = msg.buf[ofproto_v1_3.OFP_ERROR_MSG_SIZE:]
        return msg

    def _serialize_body(self):
        assert self.data is not None
        msg_pack_into(ofproto_v1_3.OFP_ERROR_MSG_PACK_STR, self.buf,
                      ofproto_v1_3.OFP_HEADER_SIZE, self.type, self.code)
        self.buf += self.data


class OFPErrorExperimenterMsg(MsgBase):
    def __init__(self, datapath, type_=None, exp_type=None, experimenter=None,
                 data=None):
        super(OFPErrorExperimenterMsg, self).__init__(datapath)
        self.type = ofproto_v1_3.OFPET_EXPERIMENTER
        self.exp_type = exp_type
        self.experimenter = experimenter
        self.data = data

    @classmethod
    def parser(cls, datapath, version, msg_type, msg_len, xid, buf):
        cls.cls_msg_type = msg_type
        msg = super(OFPErrorExperimenterMsg, cls).parser(
            datapath, version, msg_type, msg_len, xid, buf)
        msg.type, msg.exp_type, msg.experimenter = struct.unpack_from(
            ofproto_v1_3.OFP_ERROR_EXPERIMENTER_MSG_PACK_STR, msg.buf,
            ofproto_v1_3.OFP_HEADER_SIZE)
        msg.data = msg.buf[ofproto_v1_3.OFP_ERROR_EXPERIMENTER_MSG_SIZE:]
        return msg

    def _serialize_body(self):
        assert self.data is not None
        msg_pack_into(ofproto_v1_3.OFP_ERROR_EXPERIMENTER_MSG_PACK_STR,
                      self.buf, ofproto_v1_3.OFP_HEADER_SIZE,
                      self.type, self.exp_type, self.experimenter)
        self.buf += self.data


@_register_parser
@_set_msg_type(ofproto_v1_3.OFPT_ECHO_REQUEST)
class OFPEchoRequest(MsgBase):
    """
    Echo request message

    This message is handled by the Ryu framework, so the Ryu application
    do not need to process this typically.

    ========== =========================================================
    Attribute  Description
    ========== =========================================================
    data       An arbitrary length data
    ========== =========================================================

    Example::

        def send_echo_request(self, datapath, data):
            ofp = datapath.ofproto
            ofp_parser = datapath.ofproto_parser

            req = ofp_parser.OFPEchoRequest(datapath, data)
            datapath.send_msg(req)

        @set_ev_cls(ofp_event.EventOFPEchoRequest,
                    [HANDSHAKE_DISPATCHER, CONFIG_DISPATCHER, MAIN_DISPATCHER])
        def echo_request_handler(self, ev):
            self.logger.debug('OFPEchoRequest received: data=%s',
                              utils.hex_array(ev.msg.data))
    """
    def __init__(self, datapath, data=None):
        super(OFPEchoRequest, self).__init__(datapath)
        self.data = data

    @classmethod
    def parser(cls, datapath, version, msg_type, msg_len, xid, buf):
        msg = super(OFPEchoRequest, cls).parser(datapath, version, msg_type,
                                                msg_len, xid, buf)
        msg.data = msg.buf[ofproto_v1_3.OFP_HEADER_SIZE:]
        return msg

    def _serialize_body(self):
        if self.data is not None:
            self.buf += self.data


@_register_parser
@_set_msg_type(ofproto_v1_3.OFPT_ECHO_REPLY)
class OFPEchoReply(MsgBase):
    """
    Echo reply message

    This message is handled by the Ryu framework, so the Ryu application
    do not need to process this typically.

    ========== =========================================================
    Attribute  Description
    ========== =========================================================
    data       An arbitrary length data
    ========== =========================================================

    Example::

        def send_echo_reply(self, datapath, data):
            ofp = datapath.ofproto
            ofp_parser = datapath.ofproto_parser

            reply = ofp_parser.OFPEchoReply(datapath, data)
            datapath.send_msg(reply)

        @set_ev_cls(ofp_event.EventOFPEchoReply,
                    [HANDSHAKE_DISPATCHER, CONFIG_DISPATCHER, MAIN_DISPATCHER])
        def echo_reply_handler(self, ev):
            self.logger.debug('OFPEchoReply received: data=%s',
                              utils.hex_array(ev.msg.data))
    """
    def __init__(self, datapath, data=None):
        super(OFPEchoReply, self).__init__(datapath)
        self.data = data

    @classmethod
    def parser(cls, datapath, version, msg_type, msg_len, xid, buf):
        msg = super(OFPEchoReply, cls).parser(datapath, version, msg_type,
                                              msg_len, xid, buf)
        msg.data = msg.buf[ofproto_v1_3.OFP_HEADER_SIZE:]
        return msg

    def _serialize_body(self):
        assert self.data is not None
        self.buf += self.data


@_register_parser
@_set_msg_type(ofproto_v1_3.OFPT_EXPERIMENTER)
class OFPExperimenter(MsgBase):
    """
    Experimenter extension message

    ============= =========================================================
    Attribute     Description
    ============= =========================================================
    experimenter  Experimenter ID
    exp_type      Experimenter defined
    data          Experimenter defined arbitrary additional data
    ============= =========================================================
    """
    def __init__(self, datapath, experimenter=None, exp_type=None, data=None):
        super(OFPExperimenter, self).__init__(datapath)
        self.experimenter = experimenter
        self.exp_type = exp_type
        self.data = data

    @classmethod
    def parser(cls, datapath, version, msg_type, msg_len, xid, buf):
        msg = super(OFPExperimenter, cls).parser(datapath, version,
                                                 msg_type, msg_len,
                                                 xid, buf)
        (msg.experimenter, msg.exp_type) = struct.unpack_from(
            ofproto_v1_3.OFP_EXPERIMENTER_HEADER_PACK_STR, msg.buf,
            ofproto_v1_3.OFP_HEADER_SIZE)
        msg.data = msg.buf[ofproto_v1_3.OFP_EXPERIMENTER_HEADER_SIZE:]

        return msg

    def _serialize_body(self):
        assert self.data is not None
        msg_pack_into(ofproto_v1_3.OFP_EXPERIMENTER_HEADER_PACK_STR,
                      self.buf, ofproto_v1_3.OFP_HEADER_SIZE,
                      self.experimenter, self.exp_type)
        self.buf += self.data


@_set_msg_type(ofproto_v1_3.OFPT_FEATURES_REQUEST)
class OFPFeaturesRequest(MsgBase):
    """
    Features request message

    The controller sends a feature request to the switch upon session
    establishment.

    This message is handled by the Ryu framework, so the Ryu application
    do not need to process this typically.

    Example::

        def send_features_request(self, datapath):
            ofp_parser = datapath.ofproto_parser

            req = ofp_parser.OFPFeaturesRequest(datapath)
            datapath.send_msg(req)
    """
    def __init__(self, datapath):
        super(OFPFeaturesRequest, self).__init__(datapath)


@_register_parser
@_set_msg_type(ofproto_v1_3.OFPT_FEATURES_REPLY)
class OFPSwitchFeatures(MsgBase):
    """
    Features reply message

    The switch responds with a features reply message to a features
    request.

    This message is handled by the Ryu framework, so the Ryu application
    do not need to process this typically.

    Example::

        @set_ev_cls(ofp_event.EventOFPSwitchFeatures, CONFIG_DISPATCHER)
        def switch_features_handler(self, ev):
            msg = ev.msg

            self.logger.debug('OFPSwitchFeatures received: '
                              'datapath_id=0x%016x n_buffers=%d '
                              'n_tables=%d auxiliary_id=%d '
                              'capabilities=0x%08x',
                              msg.datapath_id, msg.n_buffers, msg.n_tables,
                              msg.auxiliary_id, msg.capabilities)
    """
    def __init__(self, datapath, datapath_id=None, n_buffers=None,
                 n_tables=None, auxiliary_id=None, capabilities=None):
        super(OFPSwitchFeatures, self).__init__(datapath)
        self.datapath_id = datapath_id
        self.n_buffers = n_buffers
        self.n_tables = n_tables
        self.auxiliary_id = auxiliary_id
        self.capabilities = capabilities

    @classmethod
    def parser(cls, datapath, version, msg_type, msg_len, xid, buf):
        msg = super(OFPSwitchFeatures, cls).parser(datapath, version, msg_type,
                                                   msg_len, xid, buf)
        (msg.datapath_id,
         msg.n_buffers,
         msg.n_tables,
         msg.auxiliary_id,
         msg.capabilities,
         msg._reserved) = struct.unpack_from(
            ofproto_v1_3.OFP_SWITCH_FEATURES_PACK_STR, msg.buf,
            ofproto_v1_3.OFP_HEADER_SIZE)
        return msg


@_set_msg_type(ofproto_v1_3.OFPT_GET_CONFIG_REQUEST)
class OFPGetConfigRequest(MsgBase):
    """
    Get config request message

    The controller sends a get config request to query configuration
    parameters in the switch.

    Example::

        def send_get_config_request(self, datapath):
            ofp_parser = datapath.ofproto_parser

            req = ofp_parser.OFPGetConfigRequest(datapath)
            datapath.send_msg(req)
    """
    def __init__(self, datapath):
        super(OFPGetConfigRequest, self).__init__(datapath)


@_register_parser
@_set_msg_type(ofproto_v1_3.OFPT_GET_CONFIG_REPLY)
class OFPGetConfigReply(MsgBase):
    """
    Get config reply message

    The switch responds to a configuration request with a get config reply
    message.

    ============= =========================================================
    Attribute     Description
    ============= =========================================================
    flags         One of the following configuration flags.
                  OFPC_FRAG_NORMAL
                  OFPC_FRAG_DROP
                  OFPC_FRAG_REASM
                  OFPC_FRAG_MASK
    miss_send_len Max bytes of new flow that datapath should send to the
                  controller
    ============= =========================================================

    Example::

        @set_ev_cls(ofp_event.EventOFPGetConfigReply, MAIN_DISPATCHER)
        def get_config_reply_handler(self, ev):
            msg = ev.msg
            dp = msg.datapath
            ofp = dp.ofproto

            if msg.flags == ofp.OFPC_FRAG_NORMAL:
                flags = 'NORMAL'
            elif msg.flags == ofp.OFPC_FRAG_DROP:
                flags = 'DROP'
            elif msg.flags == ofp.OFPC_FRAG_REASM:
                flags = 'REASM'
            elif msg.flags == ofp.OFPC_FRAG_MASK:
                flags = 'MASK'
            else:
                flags = 'unknown'
            self.logger.debug('OFPGetConfigReply received: '
                              'flags=%s miss_send_len=%d',
                              flags, msg.miss_send_len)
    """
    def __init__(self, datapath, flags=None, miss_send_len=None):
        super(OFPGetConfigReply, self).__init__(datapath)
        self.flags = flags
        self.miss_send_len = miss_send_len

    @classmethod
    def parser(cls, datapath, version, msg_type, msg_len, xid, buf):
        msg = super(OFPGetConfigReply, cls).parser(datapath, version, msg_type,
                                                   msg_len, xid, buf)
        msg.flags, msg.miss_send_len = struct.unpack_from(
            ofproto_v1_3.OFP_SWITCH_CONFIG_PACK_STR, msg.buf,
            ofproto_v1_3.OFP_HEADER_SIZE)
        return msg


@_set_msg_type(ofproto_v1_3.OFPT_SET_CONFIG)
class OFPSetConfig(MsgBase):
    """
    Set config request message

    The controller sends a set config request message to set configuraion
    parameters.

    ============= =========================================================
    Attribute     Description
    ============= =========================================================
    flags         One of the following configuration flags.
                  OFPC_FRAG_NORMAL
                  OFPC_FRAG_DROP
                  OFPC_FRAG_REASM
                  OFPC_FRAG_MASK
    miss_send_len Max bytes of new flow that datapath should send to the
                  controller
    ============= =========================================================

    Example::

        def send_set_config(self, datapath):
            ofp = datapath.ofproto
            ofp_parser = datapath.ofproto_parser

            req = ofp_parser.OFPSetConfig(datapath, ofp.OFPC_FRAG_NORMAL, 256)
            datapath.send_msg(req)
    """
    def __init__(self, datapath, flags=0, miss_send_len=0):
        super(OFPSetConfig, self).__init__(datapath)
        self.flags = flags
        self.miss_send_len = miss_send_len

    def _serialize_body(self):
        assert self.flags is not None
        assert self.miss_send_len is not None
        msg_pack_into(ofproto_v1_3.OFP_SWITCH_CONFIG_PACK_STR,
                      self.buf, ofproto_v1_3.OFP_HEADER_SIZE,
                      self.flags, self.miss_send_len)


UINT64_MAX = (1 << 64) - 1
UINT32_MAX = (1 << 32) - 1
UINT16_MAX = (1 << 16) - 1


class Flow(object):
    def __init__(self):
        self.in_port = 0
        self.in_phy_port = 0
        self.metadata = 0
        self.dl_dst = mac.DONTCARE
        self.dl_src = mac.DONTCARE
        self.dl_type = 0
        self.vlan_vid = 0
        self.vlan_pcp = 0
        self.ip_dscp = 0
        self.ip_ecn = 0
        self.ip_proto = 0
        self.ipv4_src = 0
        self.ipv4_dst = 0
        self.tcp_src = 0
        self.tcp_dst = 0
        self.udp_src = 0
        self.udp_dst = 0
        self.sctp_src = 0
        self.sctp_dst = 0
        self.icmpv4_type = 0
        self.icmpv4_code = 0
        self.arp_op = 0
        self.arp_spa = 0
        self.arp_tpa = 0
        self.arp_sha = 0
        self.arp_tha = 0
        self.ipv6_src = []
        self.ipv6_dst = []
        self.ipv6_flabel = 0
        self.icmpv6_type = 0
        self.icmpv6_code = 0
        self.ipv6_nd_target = []
        self.ipv6_nd_sll = 0
        self.ipv6_nd_tll = 0
        self.mpls_label = 0
        self.mpls_tc = 0
        self.mpls_bos = 0
        self.pbb_isid = 0
        self.tunnel_id = 0
        self.ipv6_exthdr = 0


class FlowWildcards(object):
    def __init__(self):
        self.metadata_mask = 0
        self.dl_dst_mask = 0
        self.dl_src_mask = 0
        self.vlan_vid_mask = 0
        self.ipv4_src_mask = 0
        self.ipv4_dst_mask = 0
        self.arp_spa_mask = 0
        self.arp_tpa_mask = 0
        self.arp_sha_mask = 0
        self.arp_tha_mask = 0
        self.ipv6_src_mask = []
        self.ipv6_dst_mask = []
        self.ipv6_flabel_mask = 0
        self.pbb_isid_mask = 0
        self.tunnel_id_mask = 0
        self.ipv6_exthdr_mask = 0
        self.wildcards = (1 << 64) - 1

    def ft_set(self, shift):
        self.wildcards &= ~(1 << shift)

    def ft_test(self, shift):
        return not self.wildcards & (1 << shift)


class OFPMatch(StringifyMixin):
    """
    Flow Match Structure

    This class is implementation of the flow match structure having
    compose/query API.
    There are new API and old API for compatibility. the old API is
    supposed to be removed later.

    You can define the flow match by the keyword arguments.
    The following arguments are available.

    ================ =============== ==================================
    Argument         Value           Description
    ================ =============== ==================================
    in_port          Integer 32bit   Switch input port
    in_phy_port      Integer 32bit   Switch physical input port
    metadata         Integer 64bit   Metadata passed between tables
    eth_dst          MAC address     Ethernet destination address
    eth_src          MAC address     Ethernet source address
    eth_type         Integer 16bit   Ethernet frame type
    vlan_vid         Integer 16bit   VLAN id
    vlan_pcp         Integer 8bit    VLAN priority
    ip_dscp          Integer 8bit    IP DSCP (6 bits in ToS field)
    ip_ecn           Integer 8bit    IP ECN (2 bits in ToS field)
    ip_proto         Integer 8bit    IP protocol
    ipv4_src         IPv4 address    IPv4 source address
    ipv4_dst         IPv4 address    IPv4 destination address
    tcp_src          Integer 16bit   TCP source port
    tcp_dst          Integer 16bit   TCP destination port
    udp_src          Integer 16bit   UDP source port
    udp_dst          Integer 16bit   UDP destination port
    sctp_src         Integer 16bit   SCTP source port
    sctp_dst         Integer 16bit   SCTP destination port
    icmpv4_type      Integer 8bit    ICMP type
    icmpv4_code      Integer 8bit    ICMP code
    arp_op           Integer 16bit   ARP opcode
    arp_spa          IPv4 address    ARP source IPv4 address
    arp_tpa          IPv4 address    ARP target IPv4 address
    arp_sha          MAC address     ARP source hardware address
    arp_tha          MAC address     ARP target hardware address
    ipv6_src         IPv6 address    IPv6 source address
    ipv6_dst         IPv6 address    IPv6 destination address
    ipv6_flabel      Integer 32bit   IPv6 Flow Label
    icmpv6_type      Integer 8bit    ICMPv6 type
    icmpv6_code      Integer 8bit    ICMPv6 code
    ipv6_nd_target   IPv6 address    Target address for ND
    ipv6_nd_sll      MAC address     Source link-layer for ND
    ipv6_nd_tll      MAC address     Target link-layer for ND
    mpls_label       Integer 32bit   MPLS label
    mpls_tc          Integer 8bit    MPLS TC
    mpls_bos         Integer 8bit    MPLS BoS bit
    pbb_isid         Integer 24bit   PBB I-SID
    tunnel_id        Integer 64bit   Logical Port Metadata
    ipv6_exthdr      Integer 16bit   IPv6 Extension Header pseudo-field
    ================ =============== ==================================

    Example::

        >>> # compose
        >>> match = parser.OFPMatch(
        ...     in_port=1,
        ...     eth_type=0x86dd,
        ...     ipv6_src=('2001:db8:bd05:1d2:288a:1fc0:1:10ee',
        ...               'ffff:ffff:ffff:ffff::'),
        ...     ipv6_dst='2001:db8:bd05:1d2:288a:1fc0:1:10ee')
        >>> # query
        >>> if 'ipv6_src' in match:
        ...     print match['ipv6_src']
        ...
        ('2001:db8:bd05:1d2:288a:1fc0:1:10ee', 'ffff:ffff:ffff:ffff::')
    """

    def __init__(self, type_=None, length=None, _ordered_fields=None,
                 **kwargs):
        """
        You can define the flow match by the keyword arguments.
        Please refer to ofproto_v1_3.oxm_types for the key which you can
        define.
        """
        super(OFPMatch, self).__init__()
        self._wc = FlowWildcards()
        self._flow = Flow()
        self.fields = []
        self.type = ofproto_v1_3.OFPMT_OXM
        self.length = length

        if not _ordered_fields is None:
            assert not kwargs
            self._fields2 = _ordered_fields
        else:
            # eg.
            #   OFPMatch(eth_src=('ff:ff:ff:00:00:00'), eth_type=0x800,
            #            ipv4_src='10.0.0.1')
            kwargs = dict(ofproto_v1_3.oxm_normalize_user(k, v) for
                          (k, v) in kwargs.iteritems())
            fields = [ofproto_v1_3.oxm_from_user(k, v) for (k, v)
                      in kwargs.iteritems()]
            # assumption: sorting by OXM type values makes fields
            # meet ordering requirements (eg. eth_type before ipv4_src)
            fields.sort()
            self._fields2 = [ofproto_v1_3.oxm_to_user(n, v, m) for (n, v, m)
                             in fields]

    def __getitem__(self, key):
        return dict(self._fields2)[key]

    def __contains__(self, key):
        return key in dict(self._fields2)

    def iteritems(self):
        return dict(self._fields2).iteritems()

    def get(self, key, default=None):
        return dict(self._fields2).get(key, default)

    def stringify_attrs(self):
        yield "oxm_fields", dict(self._fields2)

    def to_jsondict(self):
        """
        Returns a dict expressing the flow match.
        """
        # XXX old api compat
        if self._composed_with_old_api():
            # copy object first because serialize_old is destructive
            o2 = OFPMatch()
            o2.fields = self.fields[:]
            # serialize and parse to fill OFPMatch._fields2
            buf = bytearray()
            o2.serialize(buf, 0)
            o = OFPMatch.parser(str(buf), 0)
        else:
            o = self

        body = {"oxm_fields": [ofproto_v1_3.oxm_to_jsondict(k, uv) for k, uv
                               in o._fields2],
                "length": o.length,
                "type": o.type}
        return {self.__class__.__name__: body}

    @classmethod
    def from_jsondict(cls, dict_):
        """
        Returns an object which is generated from a dict.

        Exception raises:
        KeyError -- Unknown match field is defined in dict
        """
        fields = [ofproto_v1_3.oxm_from_jsondict(f) for f
                  in dict_['oxm_fields']]
        o = OFPMatch(_ordered_fields=fields)
        # XXX old api compat
        # serialize and parse to fill OFPMatch.fields
        buf = bytearray()
        o.serialize(buf, 0)
        return OFPMatch.parser(str(buf), 0)

    def __str__(self):
        # XXX old api compat
        if self._composed_with_old_api():
            # copy object first because serialize_old is destructive
            o2 = OFPMatch()
            o2.fields = self.fields[:]
            # serialize and parse to fill OFPMatch._fields2
            buf = bytearray()
            o2.serialize(buf, 0)
            o = OFPMatch.parser(str(buf), 0)
        else:
            o = self
        return super(OFPMatch, o).__str__()

    __repr__ = __str__

    def append_field(self, header, value, mask=None):
        """
        Append a match field.

        ========= =======================================================
        Argument  Description
        ========= =======================================================
        header    match field header ID which is defined automatically in
                  ``ofproto_v1_3``
        value     match field value
        mask      mask value to the match field
        ========= =======================================================

        The available ``header`` is as follows.

        ====================== ===================================
        Header ID              Description
        ====================== ===================================
        OXM_OF_IN_PORT         Switch input port
        OXM_OF_IN_PHY_PORT     Switch physical input port
        OXM_OF_METADATA        Metadata passed between tables
        OXM_OF_ETH_DST         Ethernet destination address
        OXM_OF_ETH_SRC         Ethernet source address
        OXM_OF_ETH_TYPE        Ethernet frame type
        OXM_OF_VLAN_VID        VLAN id
        OXM_OF_VLAN_PCP        VLAN priority
        OXM_OF_IP_DSCP         IP DSCP (6 bits in ToS field)
        OXM_OF_IP_ECN          IP ECN (2 bits in ToS field)
        OXM_OF_IP_PROTO        IP protocol
        OXM_OF_IPV4_SRC        IPv4 source address
        OXM_OF_IPV4_DST        IPv4 destination address
        OXM_OF_TCP_SRC         TCP source port
        OXM_OF_TCP_DST         TCP destination port
        OXM_OF_UDP_SRC         UDP source port
        OXM_OF_UDP_DST         UDP destination port
        OXM_OF_SCTP_SRC        SCTP source port
        OXM_OF_SCTP_DST        SCTP destination port
        OXM_OF_ICMPV4_TYPE     ICMP type
        OXM_OF_ICMPV4_CODE     ICMP code
        OXM_OF_ARP_OP          ARP opcode
        OXM_OF_ARP_SPA         ARP source IPv4 address
        OXM_OF_ARP_TPA         ARP target IPv4 address
        OXM_OF_ARP_SHA         ARP source hardware address
        OXM_OF_ARP_THA         ARP target hardware address
        OXM_OF_IPV6_SRC        IPv6 source address
        OXM_OF_IPV6_DST        IPv6 destination address
        OXM_OF_IPV6_FLABEL     IPv6 Flow Label
        OXM_OF_ICMPV6_TYPE     ICMPv6 type
        OXM_OF_ICMPV6_CODE     ICMPv6 code
        OXM_OF_IPV6_ND_TARGET  Target address for ND
        OXM_OF_IPV6_ND_SLL     Source link-layer for ND
        OXM_OF_IPV6_ND_TLL     Target link-layer for ND
        OXM_OF_MPLS_LABEL      MPLS label
        OXM_OF_MPLS_TC         MPLS TC
        OXM_OF_MPLS_BOS        MPLS BoS bit
        OXM_OF_PBB_ISID        PBB I-SID
        OXM_OF_TUNNEL_ID       Logical Port Metadata
        OXM_OF_IPV6_EXTHDR     IPv6 Extension Header pseudo-field
        ====================== ===================================
        """
        self.fields.append(OFPMatchField.make(header, value, mask))

    def _composed_with_old_api(self):
        return (self.fields and not self._fields2) or \
            self._wc.__dict__ != FlowWildcards().__dict__

    def serialize(self, buf, offset):
        """
        Outputs the expression of the wire protocol of the flow match into
        the buf.
        Returns the output length.
        """
        # XXX compat
        if self._composed_with_old_api():
            return self.serialize_old(buf, offset)

        fields = [ofproto_v1_3.oxm_from_user(k, uv) for (k, uv)
                  in self._fields2]

        hdr_pack_str = '!HH'
        field_offset = offset + struct.calcsize(hdr_pack_str)
        for (n, value, mask) in fields:
            field_offset += ofproto_v1_3.oxm_serialize(n, value, mask, buf,
                                                       field_offset)

        length = field_offset - offset
        msg_pack_into(hdr_pack_str, buf, offset,
                      ofproto_v1_3.OFPMT_OXM, length)
        self.length = length

        pad_len = utils.round_up(length, 8) - length
        ofproto_parser.msg_pack_into("%dx" % pad_len, buf, field_offset)

        return length + pad_len

    def serialize_old(self, buf, offset):
        if hasattr(self, '_serialized'):
            raise Exception('serializing an OFPMatch composed with '
                            'old API multiple times is not supported')
        self._serialized = True

        if self._wc.ft_test(ofproto_v1_3.OFPXMT_OFB_IN_PORT):
            self.append_field(ofproto_v1_3.OXM_OF_IN_PORT,
                              self._flow.in_port)

        if self._wc.ft_test(ofproto_v1_3.OFPXMT_OFB_IN_PHY_PORT):
            self.append_field(ofproto_v1_3.OXM_OF_IN_PHY_PORT,
                              self._flow.in_phy_port)

        if self._wc.ft_test(ofproto_v1_3.OFPXMT_OFB_METADATA):
            if self._wc.metadata_mask == UINT64_MAX:
                header = ofproto_v1_3.OXM_OF_METADATA
            else:
                header = ofproto_v1_3.OXM_OF_METADATA_W
            self.append_field(header, self._flow.metadata,
                              self._wc.metadata_mask)

        if self._wc.ft_test(ofproto_v1_3.OFPXMT_OFB_ETH_DST):
            if self._wc.dl_dst_mask:
                header = ofproto_v1_3.OXM_OF_ETH_DST_W
            else:
                header = ofproto_v1_3.OXM_OF_ETH_DST
            self.append_field(header, self._flow.dl_dst, self._wc.dl_dst_mask)

        if self._wc.ft_test(ofproto_v1_3.OFPXMT_OFB_ETH_SRC):
            if self._wc.dl_src_mask:
                header = ofproto_v1_3.OXM_OF_ETH_SRC_W
            else:
                header = ofproto_v1_3.OXM_OF_ETH_SRC
            self.append_field(header, self._flow.dl_src, self._wc.dl_src_mask)

        if self._wc.ft_test(ofproto_v1_3.OFPXMT_OFB_ETH_TYPE):
            self.append_field(ofproto_v1_3.OXM_OF_ETH_TYPE, self._flow.dl_type)

        if self._wc.ft_test(ofproto_v1_3.OFPXMT_OFB_VLAN_VID):
            if self._wc.vlan_vid_mask == UINT16_MAX:
                header = ofproto_v1_3.OXM_OF_VLAN_VID
            else:
                header = ofproto_v1_3.OXM_OF_VLAN_VID_W
            self.append_field(header, self._flow.vlan_vid,
                              self._wc.vlan_vid_mask)

        if self._wc.ft_test(ofproto_v1_3.OFPXMT_OFB_VLAN_PCP):
            self.append_field(ofproto_v1_3.OXM_OF_VLAN_PCP,
                              self._flow.vlan_pcp)

        if self._wc.ft_test(ofproto_v1_3.OFPXMT_OFB_IP_DSCP):
            self.append_field(ofproto_v1_3.OXM_OF_IP_DSCP, self._flow.ip_dscp)

        if self._wc.ft_test(ofproto_v1_3.OFPXMT_OFB_IP_ECN):
            self.append_field(ofproto_v1_3.OXM_OF_IP_ECN, self._flow.ip_ecn)

        if self._wc.ft_test(ofproto_v1_3.OFPXMT_OFB_IP_PROTO):
            self.append_field(ofproto_v1_3.OXM_OF_IP_PROTO,
                              self._flow.ip_proto)

        if self._wc.ft_test(ofproto_v1_3.OFPXMT_OFB_IPV4_SRC):
            if self._wc.ipv4_src_mask == UINT32_MAX:
                header = ofproto_v1_3.OXM_OF_IPV4_SRC
            else:
                header = ofproto_v1_3.OXM_OF_IPV4_SRC_W
            self.append_field(header, self._flow.ipv4_src,
                              self._wc.ipv4_src_mask)

        if self._wc.ft_test(ofproto_v1_3.OFPXMT_OFB_IPV4_DST):
            if self._wc.ipv4_dst_mask == UINT32_MAX:
                header = ofproto_v1_3.OXM_OF_IPV4_DST
            else:
                header = ofproto_v1_3.OXM_OF_IPV4_DST_W
            self.append_field(header, self._flow.ipv4_dst,
                              self._wc.ipv4_dst_mask)

        if self._wc.ft_test(ofproto_v1_3.OFPXMT_OFB_TCP_SRC):
            self.append_field(ofproto_v1_3.OXM_OF_TCP_SRC, self._flow.tcp_src)

        if self._wc.ft_test(ofproto_v1_3.OFPXMT_OFB_TCP_DST):
            self.append_field(ofproto_v1_3.OXM_OF_TCP_DST, self._flow.tcp_dst)

        if self._wc.ft_test(ofproto_v1_3.OFPXMT_OFB_UDP_SRC):
            self.append_field(ofproto_v1_3.OXM_OF_UDP_SRC, self._flow.udp_src)

        if self._wc.ft_test(ofproto_v1_3.OFPXMT_OFB_UDP_DST):
            self.append_field(ofproto_v1_3.OXM_OF_UDP_DST, self._flow.udp_dst)

        if self._wc.ft_test(ofproto_v1_3.OFPXMT_OFB_SCTP_SRC):
            self.append_field(ofproto_v1_3.OXM_OF_SCTP_SRC,
                              self._flow.sctp_src)

        if self._wc.ft_test(ofproto_v1_3.OFPXMT_OFB_SCTP_DST):
            self.append_field(ofproto_v1_3.OXM_OF_SCTP_DST,
                              self._flow.sctp_dst)

        if self._wc.ft_test(ofproto_v1_3.OFPXMT_OFB_ICMPV4_TYPE):
            self.append_field(ofproto_v1_3.OXM_OF_ICMPV4_TYPE,
                              self._flow.icmpv4_type)

        if self._wc.ft_test(ofproto_v1_3.OFPXMT_OFB_ICMPV4_CODE):
            self.append_field(ofproto_v1_3.OXM_OF_ICMPV4_CODE,
                              self._flow.icmpv4_code)

        if self._wc.ft_test(ofproto_v1_3.OFPXMT_OFB_ARP_OP):
            self.append_field(ofproto_v1_3.OXM_OF_ARP_OP, self._flow.arp_op)

        if self._wc.ft_test(ofproto_v1_3.OFPXMT_OFB_ARP_SPA):
            if self._wc.arp_spa_mask == UINT32_MAX:
                header = ofproto_v1_3.OXM_OF_ARP_SPA
            else:
                header = ofproto_v1_3.OXM_OF_ARP_SPA_W
            self.append_field(header, self._flow.arp_spa,
                              self._wc.arp_spa_mask)

        if self._wc.ft_test(ofproto_v1_3.OFPXMT_OFB_ARP_TPA):
            if self._wc.arp_tpa_mask == UINT32_MAX:
                header = ofproto_v1_3.OXM_OF_ARP_TPA
            else:
                header = ofproto_v1_3.OXM_OF_ARP_TPA_W
            self.append_field(header, self._flow.arp_tpa,
                              self._wc.arp_tpa_mask)

        if self._wc.ft_test(ofproto_v1_3.OFPXMT_OFB_ARP_SHA):
            if self._wc.arp_sha_mask:
                header = ofproto_v1_3.OXM_OF_ARP_SHA_W
            else:
                header = ofproto_v1_3.OXM_OF_ARP_SHA
            self.append_field(header, self._flow.arp_sha,
                              self._wc.arp_sha_mask)

        if self._wc.ft_test(ofproto_v1_3.OFPXMT_OFB_ARP_THA):
            if self._wc.arp_tha_mask:
                header = ofproto_v1_3.OXM_OF_ARP_THA_W
            else:
                header = ofproto_v1_3.OXM_OF_ARP_THA
            self.append_field(header, self._flow.arp_tha,
                              self._wc.arp_tha_mask)

        if self._wc.ft_test(ofproto_v1_3.OFPXMT_OFB_IPV6_SRC):
            if len(self._wc.ipv6_src_mask):
                header = ofproto_v1_3.OXM_OF_IPV6_SRC_W
            else:
                header = ofproto_v1_3.OXM_OF_IPV6_SRC
            self.append_field(header, self._flow.ipv6_src,
                              self._wc.ipv6_src_mask)

        if self._wc.ft_test(ofproto_v1_3.OFPXMT_OFB_IPV6_DST):
            if len(self._wc.ipv6_dst_mask):
                header = ofproto_v1_3.OXM_OF_IPV6_DST_W
            else:
                header = ofproto_v1_3.OXM_OF_IPV6_DST
            self.append_field(header, self._flow.ipv6_dst,
                              self._wc.ipv6_dst_mask)

        if self._wc.ft_test(ofproto_v1_3.OFPXMT_OFB_IPV6_FLABEL):
            if self._wc.ipv6_flabel_mask == UINT32_MAX:
                header = ofproto_v1_3.OXM_OF_IPV6_FLABEL
            else:
                header = ofproto_v1_3.OXM_OF_IPV6_FLABEL_W
            self.append_field(header, self._flow.ipv6_flabel,
                              self._wc.ipv6_flabel_mask)

        if self._wc.ft_test(ofproto_v1_3.OFPXMT_OFB_ICMPV6_TYPE):
            self.append_field(ofproto_v1_3.OXM_OF_ICMPV6_TYPE,
                              self._flow.icmpv6_type)

        if self._wc.ft_test(ofproto_v1_3.OFPXMT_OFB_ICMPV6_CODE):
            self.append_field(ofproto_v1_3.OXM_OF_ICMPV6_CODE,
                              self._flow.icmpv6_code)

        if self._wc.ft_test(ofproto_v1_3.OFPXMT_OFB_IPV6_ND_TARGET):
            self.append_field(ofproto_v1_3.OXM_OF_IPV6_ND_TARGET,
                              self._flow.ipv6_nd_target)

        if self._wc.ft_test(ofproto_v1_3.OFPXMT_OFB_IPV6_ND_SLL):
            self.append_field(ofproto_v1_3.OXM_OF_IPV6_ND_SLL,
                              self._flow.ipv6_nd_sll)

        if self._wc.ft_test(ofproto_v1_3.OFPXMT_OFB_IPV6_ND_TLL):
            self.append_field(ofproto_v1_3.OXM_OF_IPV6_ND_TLL,
                              self._flow.ipv6_nd_tll)

        if self._wc.ft_test(ofproto_v1_3.OFPXMT_OFB_MPLS_LABEL):
            self.append_field(ofproto_v1_3.OXM_OF_MPLS_LABEL,
                              self._flow.mpls_label)

        if self._wc.ft_test(ofproto_v1_3.OFPXMT_OFB_MPLS_TC):
            self.append_field(ofproto_v1_3.OXM_OF_MPLS_TC,
                              self._flow.mpls_tc)

        if self._wc.ft_test(ofproto_v1_3.OFPXMT_OFB_MPLS_BOS):
            self.append_field(ofproto_v1_3.OXM_OF_MPLS_BOS,
                              self._flow.mpls_bos)

        if self._wc.ft_test(ofproto_v1_3.OFPXMT_OFB_PBB_ISID):
            if self._wc.pbb_isid_mask:
                header = ofproto_v1_3.OXM_OF_PBB_ISID_W
            else:
                header = ofproto_v1_3.OXM_OF_PBB_ISID
            self.append_field(header, self._flow.pbb_isid,
                              self._wc.pbb_isid_mask)

        if self._wc.ft_test(ofproto_v1_3.OFPXMT_OFB_TUNNEL_ID):
            if self._wc.tunnel_id_mask:
                header = ofproto_v1_3.OXM_OF_TUNNEL_ID_W
            else:
                header = ofproto_v1_3.OXM_OF_TUNNEL_ID
            self.append_field(header, self._flow.tunnel_id,
                              self._wc.tunnel_id_mask)

        if self._wc.ft_test(ofproto_v1_3.OFPXMT_OFB_IPV6_EXTHDR):
            if self._wc.ipv6_exthdr_mask:
                header = ofproto_v1_3.OXM_OF_IPV6_EXTHDR_W
            else:
                header = ofproto_v1_3.OXM_OF_IPV6_EXTHDR
            self.append_field(header, self._flow.ipv6_exthdr,
                              self._wc.ipv6_exthdr_mask)

        field_offset = offset + 4
        for f in self.fields:
            f.serialize(buf, field_offset)
            field_offset += f.length

        length = field_offset - offset
        msg_pack_into('!HH', buf, offset, ofproto_v1_3.OFPMT_OXM, length)

        pad_len = utils.round_up(length, 8) - length
        ofproto_parser.msg_pack_into("%dx" % pad_len, buf, field_offset)

        return length + pad_len

    @classmethod
    def parser(cls, buf, offset):
        """
        Returns an object which is generated from a buffer including the
        expression of the wire protocol of the flow match.
        """
        match = OFPMatch()
        type_, length = struct.unpack_from('!HH', buf, offset)

        match.type = type_
        match.length = length

        # ofp_match adjustment
        offset += 4
        length -= 4

        # XXXcompat
        cls.parser_old(match, buf, offset, length)

        fields = []
        while length > 0:
            n, value, mask, field_len = ofproto_v1_3.oxm_parse(buf, offset)
            k, uv = ofproto_v1_3.oxm_to_user(n, value, mask)
            fields.append((k, uv))
            offset += field_len
            length -= field_len
        match._fields2 = fields
        return match

    @staticmethod
    def parser_old(match, buf, offset, length):
        while length > 0:
            field = OFPMatchField.parser(buf, offset)
            offset += field.length
            length -= field.length
            match.fields.append(field)

    def set_in_port(self, port):
        self._wc.ft_set(ofproto_v1_3.OFPXMT_OFB_IN_PORT)
        self._flow.in_port = port

    def set_in_phy_port(self, phy_port):
        self._wc.ft_set(ofproto_v1_3.OFPXMT_OFB_IN_PHY_PORT)
        self._flow.in_phy_port = phy_port

    def set_metadata(self, metadata):
        self.set_metadata_masked(metadata, UINT64_MAX)

    def set_metadata_masked(self, metadata, mask):
        self._wc.ft_set(ofproto_v1_3.OFPXMT_OFB_METADATA)
        self._wc.metadata_mask = mask
        self._flow.metadata = metadata & mask

    def set_dl_dst(self, dl_dst):
        self._wc.ft_set(ofproto_v1_3.OFPXMT_OFB_ETH_DST)
        self._flow.dl_dst = dl_dst

    def set_dl_dst_masked(self, dl_dst, mask):
        self._wc.ft_set(ofproto_v1_3.OFPXMT_OFB_ETH_DST)
        self._wc.dl_dst_mask = mask
        # bit-wise and of the corresponding elements of dl_dst and mask
        self._flow.dl_dst = mac.haddr_bitand(dl_dst, mask)

    def set_dl_src(self, dl_src):
        self._wc.ft_set(ofproto_v1_3.OFPXMT_OFB_ETH_SRC)
        self._flow.dl_src = dl_src

    def set_dl_src_masked(self, dl_src, mask):
        self._wc.ft_set(ofproto_v1_3.OFPXMT_OFB_ETH_SRC)
        self._wc.dl_src_mask = mask
        self._flow.dl_src = mac.haddr_bitand(dl_src, mask)

    def set_dl_type(self, dl_type):
        self._wc.ft_set(ofproto_v1_3.OFPXMT_OFB_ETH_TYPE)
        self._flow.dl_type = dl_type

    def set_vlan_vid(self, vid):
        self.set_vlan_vid_masked(vid, UINT16_MAX)

    def set_vlan_vid_masked(self, vid, mask):
        self._wc.ft_set(ofproto_v1_3.OFPXMT_OFB_VLAN_VID)
        self._wc.vlan_vid_mask = mask
        self._flow.vlan_vid = vid

    def set_vlan_pcp(self, pcp):
        self._wc.ft_set(ofproto_v1_3.OFPXMT_OFB_VLAN_PCP)
        self._flow.vlan_pcp = pcp

    def set_ip_dscp(self, ip_dscp):
        self._wc.ft_set(ofproto_v1_3.OFPXMT_OFB_IP_DSCP)
        self._flow.ip_dscp = ip_dscp

    def set_ip_ecn(self, ip_ecn):
        self._wc.ft_set(ofproto_v1_3.OFPXMT_OFB_IP_ECN)
        self._flow.ip_ecn = ip_ecn

    def set_ip_proto(self, ip_proto):
        self._wc.ft_set(ofproto_v1_3.OFPXMT_OFB_IP_PROTO)
        self._flow.ip_proto = ip_proto

    def set_ipv4_src(self, ipv4_src):
        self.set_ipv4_src_masked(ipv4_src, UINT32_MAX)

    def set_ipv4_src_masked(self, ipv4_src, mask):
        self._wc.ft_set(ofproto_v1_3.OFPXMT_OFB_IPV4_SRC)
        self._flow.ipv4_src = ipv4_src
        self._wc.ipv4_src_mask = mask

    def set_ipv4_dst(self, ipv4_dst):
        self.set_ipv4_dst_masked(ipv4_dst, UINT32_MAX)

    def set_ipv4_dst_masked(self, ipv4_dst, mask):
        self._wc.ft_set(ofproto_v1_3.OFPXMT_OFB_IPV4_DST)
        self._flow.ipv4_dst = ipv4_dst
        self._wc.ipv4_dst_mask = mask

    def set_tcp_src(self, tcp_src):
        self._wc.ft_set(ofproto_v1_3.OFPXMT_OFB_TCP_SRC)
        self._flow.tcp_src = tcp_src

    def set_tcp_dst(self, tcp_dst):
        self._wc.ft_set(ofproto_v1_3.OFPXMT_OFB_TCP_DST)
        self._flow.tcp_dst = tcp_dst

    def set_udp_src(self, udp_src):
        self._wc.ft_set(ofproto_v1_3.OFPXMT_OFB_UDP_SRC)
        self._flow.udp_src = udp_src

    def set_udp_dst(self, udp_dst):
        self._wc.ft_set(ofproto_v1_3.OFPXMT_OFB_UDP_DST)
        self._flow.udp_dst = udp_dst

    def set_sctp_src(self, sctp_src):
        self._wc.ft_set(ofproto_v1_3.OFPXMT_OFB_SCTP_SRC)
        self._flow.sctp_src = sctp_src

    def set_sctp_dst(self, sctp_dst):
        self._wc.ft_set(ofproto_v1_3.OFPXMT_OFB_SCTP_DST)
        self._flow.sctp_dst = sctp_dst

    def set_icmpv4_type(self, icmpv4_type):
        self._wc.ft_set(ofproto_v1_3.OFPXMT_OFB_ICMPV4_TYPE)
        self._flow.icmpv4_type = icmpv4_type

    def set_icmpv4_code(self, icmpv4_code):
        self._wc.ft_set(ofproto_v1_3.OFPXMT_OFB_ICMPV4_CODE)
        self._flow.icmpv4_code = icmpv4_code

    def set_arp_opcode(self, arp_op):
        self._wc.ft_set(ofproto_v1_3.OFPXMT_OFB_ARP_OP)
        self._flow.arp_op = arp_op

    def set_arp_spa(self, arp_spa):
        self.set_arp_spa_masked(arp_spa, UINT32_MAX)

    def set_arp_spa_masked(self, arp_spa, mask):
        self._wc.ft_set(ofproto_v1_3.OFPXMT_OFB_ARP_SPA)
        self._wc.arp_spa_mask = mask
        self._flow.arp_spa = arp_spa

    def set_arp_tpa(self, arp_tpa):
        self.set_arp_tpa_masked(arp_tpa, UINT32_MAX)

    def set_arp_tpa_masked(self, arp_tpa, mask):
        self._wc.ft_set(ofproto_v1_3.OFPXMT_OFB_ARP_TPA)
        self._wc.arp_tpa_mask = mask
        self._flow.arp_tpa = arp_tpa

    def set_arp_sha(self, arp_sha):
        self._wc.ft_set(ofproto_v1_3.OFPXMT_OFB_ARP_SHA)
        self._flow.arp_sha = arp_sha

    def set_arp_sha_masked(self, arp_sha, mask):
        self._wc.ft_set(ofproto_v1_3.OFPXMT_OFB_ARP_SHA)
        self._wc.arp_sha_mask = mask
        self._flow.arp_sha = mac.haddr_bitand(arp_sha, mask)

    def set_arp_tha(self, arp_tha):
        self._wc.ft_set(ofproto_v1_3.OFPXMT_OFB_ARP_THA)
        self._flow.arp_tha = arp_tha

    def set_arp_tha_masked(self, arp_tha, mask):
        self._wc.ft_set(ofproto_v1_3.OFPXMT_OFB_ARP_THA)
        self._wc.arp_tha_mask = mask
        self._flow.arp_tha = mac.haddr_bitand(arp_tha, mask)

    def set_ipv6_src(self, src):
        self._wc.ft_set(ofproto_v1_3.OFPXMT_OFB_IPV6_SRC)
        self._flow.ipv6_src = src

    def set_ipv6_src_masked(self, src, mask):
        self._wc.ft_set(ofproto_v1_3.OFPXMT_OFB_IPV6_SRC)
        self._wc.ipv6_src_mask = mask
        self._flow.ipv6_src = [x & y for (x, y) in itertools.izip(src, mask)]

    def set_ipv6_dst(self, dst):
        self._wc.ft_set(ofproto_v1_3.OFPXMT_OFB_IPV6_DST)
        self._flow.ipv6_dst = dst

    def set_ipv6_dst_masked(self, dst, mask):
        self._wc.ft_set(ofproto_v1_3.OFPXMT_OFB_IPV6_DST)
        self._wc.ipv6_dst_mask = mask
        self._flow.ipv6_dst = [x & y for (x, y) in itertools.izip(dst, mask)]

    def set_ipv6_flabel(self, flabel):
        self.set_ipv6_flabel_masked(flabel, UINT32_MAX)

    def set_ipv6_flabel_masked(self, flabel, mask):
        self._wc.ft_set(ofproto_v1_3.OFPXMT_OFB_IPV6_FLABEL)
        self._wc.ipv6_flabel_mask = mask
        self._flow.ipv6_flabel = flabel

    def set_icmpv6_type(self, icmpv6_type):
        self._wc.ft_set(ofproto_v1_3.OFPXMT_OFB_ICMPV6_TYPE)
        self._flow.icmpv6_type = icmpv6_type

    def set_icmpv6_code(self, icmpv6_code):
        self._wc.ft_set(ofproto_v1_3.OFPXMT_OFB_ICMPV6_CODE)
        self._flow.icmpv6_code = icmpv6_code

    def set_ipv6_nd_target(self, target):
        self._wc.ft_set(ofproto_v1_3.OFPXMT_OFB_IPV6_ND_TARGET)
        self._flow.ipv6_nd_target = target

    def set_ipv6_nd_sll(self, ipv6_nd_sll):
        self._wc.ft_set(ofproto_v1_3.OFPXMT_OFB_IPV6_ND_SLL)
        self._flow.ipv6_nd_sll = ipv6_nd_sll

    def set_ipv6_nd_tll(self, ipv6_nd_tll):
        self._wc.ft_set(ofproto_v1_3.OFPXMT_OFB_IPV6_ND_TLL)
        self._flow.ipv6_nd_tll = ipv6_nd_tll

    def set_mpls_label(self, mpls_label):
        self._wc.ft_set(ofproto_v1_3.OFPXMT_OFB_MPLS_LABEL)
        self._flow.mpls_label = mpls_label

    def set_mpls_tc(self, mpls_tc):
        self._wc.ft_set(ofproto_v1_3.OFPXMT_OFB_MPLS_TC)
        self._flow.mpls_tc = mpls_tc

    def set_mpls_bos(self, bos):
        self._wc.ft_set(ofproto_v1_3.OFPXMT_OFB_MPLS_BOS)
        self._flow.mpls_bos = bos

    def set_pbb_isid(self, isid):
        self._wc.ft_set(ofproto_v1_3.OFPXMT_OFB_PBB_ISID)
        self._flow.pbb_isid = isid

    def set_pbb_isid_masked(self, isid, mask):
        self._wc.ft_set(ofproto_v1_3.OFPXMT_OFB_PBB_ISID)
        self._wc.pbb_isid_mask = mask
        self._flow.pbb_isid = isid

    def set_tunnel_id(self, tunnel_id):
        self._wc.ft_set(ofproto_v1_3.OFPXMT_OFB_TUNNEL_ID)
        self._flow.tunnel_id = tunnel_id

    def set_tunnel_id_masked(self, tunnel_id, mask):
        self._wc.ft_set(ofproto_v1_3.OFPXMT_OFB_TUNNEL_ID)
        self._wc.tunnel_id_mask = mask
        self._flow.tunnel_id = tunnel_id

    def set_ipv6_exthdr(self, hdr):
        self._wc.ft_set(ofproto_v1_3.OFPXMT_OFB_IPV6_EXTHDR)
        self._flow.ipv6_exthdr = hdr

    def set_ipv6_exthdr_masked(self, hdr, mask):
        self._wc.ft_set(ofproto_v1_3.OFPXMT_OFB_IPV6_EXTHDR)
        self._wc.ipv6_exthdr_mask = mask
        self._flow.ipv6_exthdr = hdr


class OFPMatchField(StringifyMixin):
    _FIELDS_HEADERS = {}

    @staticmethod
    def register_field_header(headers):
        def _register_field_header(cls):
            for header in headers:
                OFPMatchField._FIELDS_HEADERS[header] = cls
            return cls
        return _register_field_header

    def __init__(self, header):
        self.header = header
        self.n_bytes = ofproto_v1_3.oxm_tlv_header_extract_length(header)
        self.length = 0

    @classmethod
    def cls_to_header(cls, cls_, hasmask):
        # XXX efficiency
        inv = dict((v, k) for k, v in cls._FIELDS_HEADERS.iteritems()
                   if (((k >> 8) & 1) != 0) == hasmask)
        return inv[cls_]

    @staticmethod
    def make(header, value, mask=None):
        cls_ = OFPMatchField._FIELDS_HEADERS.get(header)
        return cls_(header, value, mask)

    @classmethod
    def parser(cls, buf, offset):
        (header,) = struct.unpack_from('!I', buf, offset)
        cls_ = OFPMatchField._FIELDS_HEADERS.get(header)
        if cls_:
            field = cls_.field_parser(header, buf, offset)
        else:
            field = OFPMatchField(header)
        field.length = (header & 0xff) + 4
        return field

    @classmethod
    def field_parser(cls, header, buf, offset):
        hasmask = (header >> 8) & 1
        mask = None
        if ofproto_v1_3.oxm_tlv_header_extract_hasmask(header):
            pack_str = '!' + cls.pack_str[1:] * 2
            (value, mask) = struct.unpack_from(pack_str, buf, offset + 4)
        else:
            (value,) = struct.unpack_from(cls.pack_str, buf, offset + 4)
        return cls(header, value, mask)

    def serialize(self, buf, offset):
        if ofproto_v1_3.oxm_tlv_header_extract_hasmask(self.header):
            self.put_w(buf, offset, self.value, self.mask)
        else:
            self.put(buf, offset, self.value)

    def _put_header(self, buf, offset):
        ofproto_parser.msg_pack_into('!I', buf, offset, self.header)
        self.length = 4

    def _put(self, buf, offset, value):
        ofproto_parser.msg_pack_into(self.pack_str, buf, offset, value)
        self.length += self.n_bytes

    def put_w(self, buf, offset, value, mask):
        self._put_header(buf, offset)
        self._put(buf, offset + self.length, value)
        self._put(buf, offset + self.length, mask)

    def put(self, buf, offset, value):
        self._put_header(buf, offset)
        self._put(buf, offset + self.length, value)

    def _putv6(self, buf, offset, value):
        ofproto_parser.msg_pack_into(self.pack_str, buf, offset,
                                     *value)
        self.length += self.n_bytes

    def putv6(self, buf, offset, value, mask=None):
        self._put_header(buf, offset)
        self._putv6(buf, offset + self.length, value)
        if mask and len(mask):
            self._putv6(buf, offset + self.length, mask)

    def oxm_len(self):
        return self.header & 0xff

    def to_jsondict(self):
        # remove some redundant attributes
        d = super(OFPMatchField, self).to_jsondict()
        v = d[self.__class__.__name__]
        del v['header']
        del v['length']
        del v['n_bytes']
        return d

    @classmethod
    def from_jsondict(cls, dict_):
        # just pass the dict around.
        # it will be converted by OFPMatch.__init__().
        return {cls.__name__: dict_}

    def stringify_attrs(self):
        f = super(OFPMatchField, self).stringify_attrs
        if not ofproto_v1_3.oxm_tlv_header_extract_hasmask(self.header):
            # something like the following, but yield two values (k,v)
            # return itertools.ifilter(lambda k, v: k != 'mask', iter())
            def g():
                for k, v in f():
                    if k != 'mask':
                        yield (k, v)
            return g()
        else:
            return f()


@OFPMatchField.register_field_header([ofproto_v1_3.OXM_OF_IN_PORT])
class MTInPort(OFPMatchField):
    pack_str = '!I'

    def __init__(self, header, value, mask=None):
        super(MTInPort, self).__init__(header)
        self.value = value


@OFPMatchField.register_field_header([ofproto_v1_3.OXM_OF_METADATA,
                                      ofproto_v1_3.OXM_OF_METADATA_W])
class MTMetadata(OFPMatchField):
    pack_str = '!Q'

    def __init__(self, header, value, mask=None):
        super(MTMetadata, self).__init__(header)
        self.value = value
        self.mask = mask


@OFPMatchField.register_field_header([ofproto_v1_3.OXM_OF_IN_PHY_PORT])
class MTInPhyPort(OFPMatchField):
    pack_str = '!I'

    def __init__(self, header, value, mask=None):
        super(MTInPhyPort, self).__init__(header)
        self.value = value


@OFPMatchField.register_field_header([ofproto_v1_3.OXM_OF_ETH_DST,
                                      ofproto_v1_3.OXM_OF_ETH_DST_W])
class MTEthDst(OFPMatchField):
    pack_str = '!6s'

    def __init__(self, header, value, mask=None):
        super(MTEthDst, self).__init__(header)
        self.value = value
        self.mask = mask


@OFPMatchField.register_field_header([ofproto_v1_3.OXM_OF_ETH_SRC,
                                      ofproto_v1_3.OXM_OF_ETH_SRC_W])
class MTEthSrc(OFPMatchField):
    pack_str = '!6s'

    def __init__(self, header, value, mask=None):
        super(MTEthSrc, self).__init__(header)
        self.value = value
        self.mask = mask


@OFPMatchField.register_field_header([ofproto_v1_3.OXM_OF_ETH_TYPE])
class MTEthType(OFPMatchField):
    pack_str = '!H'

    def __init__(self, header, value, mask=None):
        super(MTEthType, self).__init__(header)
        self.value = value


@OFPMatchField.register_field_header([ofproto_v1_3.OXM_OF_VLAN_VID,
                                      ofproto_v1_3.OXM_OF_VLAN_VID_W])
class MTVlanVid(OFPMatchField):
    pack_str = '!H'

    def __init__(self, header, value, mask=None):
        super(MTVlanVid, self).__init__(header)
        self.value = value
        self.mask = mask

    @classmethod
    def field_parser(cls, header, buf, offset):
        m = super(MTVlanVid, cls).field_parser(header, buf, offset)
        m.value &= ~ofproto_v1_3.OFPVID_PRESENT
        return m

    def serialize(self, buf, offset):
        self.value |= ofproto_v1_3.OFPVID_PRESENT
        super(MTVlanVid, self).serialize(buf, offset)


@OFPMatchField.register_field_header([ofproto_v1_3.OXM_OF_VLAN_PCP])
class MTVlanPcp(OFPMatchField):
    pack_str = '!B'

    def __init__(self, header, value, mask=None):
        super(MTVlanPcp, self).__init__(header)
        self.value = value


@OFPMatchField.register_field_header([ofproto_v1_3.OXM_OF_IP_DSCP])
class MTIPDscp(OFPMatchField):
    pack_str = '!B'

    def __init__(self, header, value, mask=None):
        super(MTIPDscp, self).__init__(header)
        self.value = value


@OFPMatchField.register_field_header([ofproto_v1_3.OXM_OF_IP_ECN])
class MTIPECN(OFPMatchField):
    pack_str = '!B'

    def __init__(self, header, value, mask=None):
        super(MTIPECN, self).__init__(header)
        self.value = value


@OFPMatchField.register_field_header([ofproto_v1_3.OXM_OF_IP_PROTO])
class MTIPProto(OFPMatchField):
    pack_str = '!B'

    def __init__(self, header, value, mask=None):
        super(MTIPProto, self).__init__(header)
        self.value = value


@OFPMatchField.register_field_header([ofproto_v1_3.OXM_OF_IPV4_SRC,
                                      ofproto_v1_3.OXM_OF_IPV4_SRC_W])
class MTIPV4Src(OFPMatchField):
    pack_str = '!I'

    def __init__(self, header, value, mask=None):
        super(MTIPV4Src, self).__init__(header)
        self.value = value
        self.mask = mask


@OFPMatchField.register_field_header([ofproto_v1_3.OXM_OF_IPV4_DST,
                                      ofproto_v1_3.OXM_OF_IPV4_DST_W])
class MTIPV4Dst(OFPMatchField):
    pack_str = '!I'

    def __init__(self, header, value, mask=None):
        super(MTIPV4Dst, self).__init__(header)
        self.value = value
        self.mask = mask


@OFPMatchField.register_field_header([ofproto_v1_3.OXM_OF_TCP_SRC])
class MTTCPSrc(OFPMatchField):
    pack_str = '!H'

    def __init__(self, header, value, mask=None):
        super(MTTCPSrc, self).__init__(header)
        self.value = value


@OFPMatchField.register_field_header([ofproto_v1_3.OXM_OF_TCP_DST])
class MTTCPDst(OFPMatchField):
    pack_str = '!H'

    def __init__(self, header, value, mask=None):
        super(MTTCPDst, self).__init__(header)
        self.value = value


@OFPMatchField.register_field_header([ofproto_v1_3.OXM_OF_UDP_SRC])
class MTUDPSrc(OFPMatchField):
    pack_str = '!H'

    def __init__(self, header, value, mask=None):
        super(MTUDPSrc, self).__init__(header)
        self.value = value


@OFPMatchField.register_field_header([ofproto_v1_3.OXM_OF_UDP_DST])
class MTUDPDst(OFPMatchField):
    pack_str = '!H'

    def __init__(self, header, value, mask=None):
        super(MTUDPDst, self).__init__(header)
        self.value = value


@OFPMatchField.register_field_header([ofproto_v1_3.OXM_OF_SCTP_SRC])
class MTSCTPSrc(OFPMatchField):
    pack_str = '!H'

    def __init__(self, header, value, mask=None):
        super(MTSCTPSrc, self).__init__(header)
        self.value = value


@OFPMatchField.register_field_header([ofproto_v1_3.OXM_OF_SCTP_DST])
class MTSCTPDst(OFPMatchField):
    pack_str = '!H'

    def __init__(self, header, value, mask=None):
        super(MTSCTPDst, self).__init__(header)
        self.value = value


@OFPMatchField.register_field_header([ofproto_v1_3.OXM_OF_ICMPV4_TYPE])
class MTICMPV4Type(OFPMatchField):
    pack_str = '!B'

    def __init__(self, header, value, mask=None):
        super(MTICMPV4Type, self).__init__(header)
        self.value = value


@OFPMatchField.register_field_header([ofproto_v1_3.OXM_OF_ICMPV4_CODE])
class MTICMPV4Code(OFPMatchField):
    pack_str = '!B'

    def __init__(self, header, value, mask=None):
        super(MTICMPV4Code, self).__init__(header)
        self.value = value


@OFPMatchField.register_field_header([ofproto_v1_3.OXM_OF_ARP_OP])
class MTArpOp(OFPMatchField):
    pack_str = '!H'

    def __init__(self, header, value, mask=None):
        super(MTArpOp, self).__init__(header)
        self.value = value


@OFPMatchField.register_field_header([ofproto_v1_3.OXM_OF_ARP_SPA,
                                      ofproto_v1_3.OXM_OF_ARP_SPA_W])
class MTArpSpa(OFPMatchField):
    pack_str = '!I'

    def __init__(self, header, value, mask=None):
        super(MTArpSpa, self).__init__(header)
        self.value = value
        self.mask = mask


@OFPMatchField.register_field_header([ofproto_v1_3.OXM_OF_ARP_TPA,
                                      ofproto_v1_3.OXM_OF_ARP_TPA_W])
class MTArpTpa(OFPMatchField):
    pack_str = '!I'

    def __init__(self, header, value, mask=None):
        super(MTArpTpa, self).__init__(header)
        self.value = value
        self.mask = mask


@OFPMatchField.register_field_header([ofproto_v1_3.OXM_OF_ARP_SHA,
                                      ofproto_v1_3.OXM_OF_ARP_SHA_W])
class MTArpSha(OFPMatchField):
    pack_str = '!6s'

    def __init__(self, header, value, mask=None):
        super(MTArpSha, self).__init__(header)
        self.value = value
        self.mask = mask


@OFPMatchField.register_field_header([ofproto_v1_3.OXM_OF_ARP_THA,
                                      ofproto_v1_3.OXM_OF_ARP_THA_W])
class MTArpTha(OFPMatchField):
    pack_str = '!6s'

    def __init__(self, header, value, mask=None):
        super(MTArpTha, self).__init__(header)
        self.value = value
        self.mask = mask


class MTIPv6(StringifyMixin):
    @classmethod
    def field_parser(cls, header, buf, offset):
        if ofproto_v1_3.oxm_tlv_header_extract_hasmask(header):
            pack_str = '!' + cls.pack_str[1:] * 2
            value = struct.unpack_from(pack_str, buf, offset + 4)
            return cls(header, list(value[:8]), list(value[8:]))
        else:
            value = struct.unpack_from(cls.pack_str, buf, offset + 4)
            return cls(header, list(value))

    def serialize(self, buf, offset):
        self.putv6(buf, offset, self.value, self.mask)


@OFPMatchField.register_field_header([ofproto_v1_3.OXM_OF_IPV6_SRC,
                                      ofproto_v1_3.OXM_OF_IPV6_SRC_W])
class MTIPv6Src(MTIPv6, OFPMatchField):
    pack_str = '!8H'

    def __init__(self, header, value, mask=None):
        super(MTIPv6Src, self).__init__(header)
        self.value = value
        self.mask = mask


@OFPMatchField.register_field_header([ofproto_v1_3.OXM_OF_IPV6_DST,
                                      ofproto_v1_3.OXM_OF_IPV6_DST_W])
class MTIPv6Dst(MTIPv6, OFPMatchField):
    pack_str = '!8H'

    def __init__(self, header, value, mask=None):
        super(MTIPv6Dst, self).__init__(header)
        self.value = value
        self.mask = mask


@OFPMatchField.register_field_header([ofproto_v1_3.OXM_OF_IPV6_FLABEL,
                                      ofproto_v1_3.OXM_OF_IPV6_FLABEL_W])
class MTIPv6Flabel(OFPMatchField):
    pack_str = '!I'

    def __init__(self, header, value, mask=None):
        super(MTIPv6Flabel, self).__init__(header)
        self.value = value
        self.mask = mask


@OFPMatchField.register_field_header([ofproto_v1_3.OXM_OF_MPLS_LABEL])
class MTMplsLabel(OFPMatchField):
    pack_str = '!I'

    def __init__(self, header, value, mask=None):
        super(MTMplsLabel, self).__init__(header)
        self.value = value


@OFPMatchField.register_field_header([ofproto_v1_3.OXM_OF_ICMPV6_TYPE])
class MTICMPV6Type(OFPMatchField):
    pack_str = '!B'

    def __init__(self, header, value, mask=None):
        super(MTICMPV6Type, self).__init__(header)
        self.value = value


@OFPMatchField.register_field_header([ofproto_v1_3.OXM_OF_ICMPV6_CODE])
class MTICMPV6Code(OFPMatchField):
    pack_str = '!B'

    def __init__(self, header, value, mask=None):
        super(MTICMPV6Code, self).__init__(header)
        self.value = value


@OFPMatchField.register_field_header([ofproto_v1_3.OXM_OF_IPV6_ND_TARGET])
class MTIPv6NdTarget(MTIPv6, OFPMatchField):
    pack_str = '!8H'

    def __init__(self, header, value, mask=None):
        super(MTIPv6NdTarget, self).__init__(header)
        self.value = value

    def serialize(self, buf, offset):
        self.putv6(buf, offset, self.value)


@OFPMatchField.register_field_header([ofproto_v1_3.OXM_OF_IPV6_ND_SLL])
class MTIPv6NdSll(OFPMatchField):
    pack_str = '!6s'

    def __init__(self, header, value, mask=None):
        super(MTIPv6NdSll, self).__init__(header)
        self.value = value


@OFPMatchField.register_field_header([ofproto_v1_3.OXM_OF_IPV6_ND_TLL])
class MTIPv6NdTll(OFPMatchField):
    pack_str = '!6s'

    def __init__(self, header, value, mask=None):
        super(MTIPv6NdTll, self).__init__(header)
        self.value = value


@OFPMatchField.register_field_header([ofproto_v1_3.OXM_OF_MPLS_TC])
class MTMplsTc(OFPMatchField):
    pack_str = '!B'

    def __init__(self, header, value, mask=None):
        super(MTMplsTc, self).__init__(header)
        self.value = value


@OFPMatchField.register_field_header([ofproto_v1_3.OXM_OF_MPLS_BOS])
class MTMplsBos(OFPMatchField):
    pack_str = '!B'

    def __init__(self, header, value, mask=None):
        super(MTMplsBos, self).__init__(header)
        self.value = value


@OFPMatchField.register_field_header([ofproto_v1_3.OXM_OF_PBB_ISID,
                                      ofproto_v1_3.OXM_OF_PBB_ISID_W])
class MTPbbIsid(OFPMatchField):
    pack_str = '!3B'

    def __init__(self, header, value, mask=None):
        super(MTPbbIsid, self).__init__(header)
        self.value = value
        self.mask = mask

    @classmethod
    def field_parser(cls, header, buf, offset):
        hasmask = (header >> 8) & 1
        mask = None
        if ofproto_v1_3.oxm_tlv_header_extract_hasmask(header):
            pack_str = '!' + cls.pack_str[1:] * 2
            (v1, v2, v3, m1, m2, m3) = struct.unpack_from(pack_str, buf,
                                                          offset + 4)
            value = v1 << 16 | v2 << 8 | v3
            mask = m1 << 16 | m2 << 8 | m3
        else:
            (v1, v2, v3,) = struct.unpack_from(cls.pack_str, buf, offset + 4)
            value = v1 << 16 | v2 << 8 | v3
        return cls(header, value, mask)

    def _put(self, buf, offset, value):
        ofproto_parser.msg_pack_into(self.pack_str, buf, offset,
                                     (value >> 16) & 0xff,
                                     (value >> 8) & 0xff,
                                     (value >> 0) & 0xff)
        self.length += self.n_bytes


@OFPMatchField.register_field_header([ofproto_v1_3.OXM_OF_TUNNEL_ID,
                                      ofproto_v1_3.OXM_OF_TUNNEL_ID_W])
class MTTunnelId(OFPMatchField):
    pack_str = '!Q'

    def __init__(self, header, value, mask=None):
        super(MTTunnelId, self).__init__(header)
        self.value = value
        self.mask = mask


@OFPMatchField.register_field_header([ofproto_v1_3.OXM_OF_IPV6_EXTHDR,
                                      ofproto_v1_3.OXM_OF_IPV6_EXTHDR_W])
class MTIPv6ExtHdr(OFPMatchField):
    pack_str = '!H'

    def __init__(self, header, value, mask=None):
        super(MTIPv6ExtHdr, self).__init__(header)
        self.value = value
        self.mask = mask


@_register_parser
@_set_msg_type(ofproto_v1_3.OFPT_PACKET_IN)
class OFPPacketIn(MsgBase):
    """
    Packet-In message

    The switch sends the packet that received to the controller by this
    message.

    ============= =========================================================
    Attribute     Description
    ============= =========================================================
    buffer_id     ID assigned by datapath
    total_len     Full length of frame
    reason        Reason packet is being sent.
                  OFPR_NO_MATCH
                  OFPR_ACTION
                  OFPR_INVALID_TTL
    table_id      ID of the table that was looked up
    cookie        Cookie of the flow entry that was looked up
    match         Instance of ``OFPMatch``
    data          Ethernet frame
    ============= =========================================================

    Example::

        @set_ev_cls(ofp_event.EventOFPPacketIn, MAIN_DISPATCHER)
        def packet_in_handler(self, ev):
            msg = ev.msg
            ofp = dp.ofproto

            if msg.reason == ofp.OFPR_NO_MATCH:
                reason = 'NO MATCH'
            elif msg.reason == ofp.OFPR_ACTION:
                reason = 'ACTION'
            elif msg.reason == ofp.OFPR_INVALID_TTL:
                reason = 'INVALID TTL'
            else:
                reason = 'unknown'

            self.logger.debug('OFPPacketIn received: '
                              'buffer_id=%x total_len=%d reason=%s '
                              'table_id=%d cookie=%d match=%s data=%s',
                              msg.buffer_id, msg.total_len, reason,
                              msg.table_id, msg.cookie, msg.match,
                              utils.hex_array(msg.data))
    """
    def __init__(self, datapath, buffer_id=None, total_len=None, reason=None,
                 table_id=None, cookie=None, match=None, data=None):
        super(OFPPacketIn, self).__init__(datapath)
        self.buffer_id = buffer_id
        self.total_len = total_len
        self.reason = reason
        self.table_id = table_id
        self.cookie = cookie
        self.match = match
        self.data = data

    @classmethod
    def parser(cls, datapath, version, msg_type, msg_len, xid, buf):
        msg = super(OFPPacketIn, cls).parser(datapath, version, msg_type,
                                             msg_len, xid, buf)
        (msg.buffer_id, msg.total_len, msg.reason,
         msg.table_id, msg.cookie) = struct.unpack_from(
            ofproto_v1_3.OFP_PACKET_IN_PACK_STR,
            msg.buf, ofproto_v1_3.OFP_HEADER_SIZE)

        msg.match = OFPMatch.parser(msg.buf, ofproto_v1_3.OFP_PACKET_IN_SIZE -
                                    ofproto_v1_3.OFP_MATCH_SIZE)

        match_len = utils.round_up(msg.match.length, 8)
        msg.data = msg.buf[(ofproto_v1_3.OFP_PACKET_IN_SIZE -
                            ofproto_v1_3.OFP_MATCH_SIZE + match_len + 2):]

        if msg.total_len < len(msg.data):
            # discard padding for 8-byte alignment of OFP packet
            msg.data = msg.data[:msg.total_len]

        return msg


@_register_parser
@_set_msg_type(ofproto_v1_3.OFPT_FLOW_REMOVED)
class OFPFlowRemoved(MsgBase):
    """
    Flow removed message

    When flow entries time out or are deleted, the switch notifies controller
    with this message.

    ================ ======================================================
    Attribute        Description
    ================ ======================================================
    cookie           Opaque controller-issued identifier
    priority         Priority level of flow entry
    reason           One of the following values.
                     OFPRR_IDLE_TIMEOUT
                     OFPRR_HARD_TIMEOUT
                     OFPRR_DELETE
                     OFPRR_GROUP_DELETE
    table_id         ID of the table
    duration_sec     Time flow was alive in seconds
    duration_nsec    Time flow was alive in nanoseconds beyond duration_sec
    idle_timeout     Idle timeout from original flow mod
    hard_timeout     Hard timeout from original flow mod
    packet_count     Number of packets that was associated with the flow
    byte_count       Number of bytes that was associated with the flow
    match            Instance of ``OFPMatch``
    ================ ======================================================

    Example::

        @set_ev_cls(ofp_event.EventOFPFlowRemoved, MAIN_DISPATCHER)
        def flow_removed_handler(self, ev):
            msg = ev.msg
            dp = msg.datapath
            ofp = dp.ofproto

            if msg.reason == ofp.OFPRR_IDLE_TIMEOUT:
                reason = 'IDLE TIMEOUT'
            elif msg.reason == ofp.OFPRR_HARD_TIMEOUT:
                reason = 'HARD TIMEOUT'
            elif msg.reason == ofp.OFPRR_DELETE:
                reason = 'DELETE'
            elif msg.reason == ofp.OFPRR_GROUP_DELETE:
                reason = 'GROUP DELETE'
            else:
                reason = 'unknown'

            self.logger.debug('OFPFlowRemoved received: '
                              'cookie=%d priority=%d reason=%s table_id=%d '
                              'duration_sec=%d duration_nsec=%d '
                              'idle_timeout=%d hard_timeout=%d '
                              'packet_count=%d byte_count=%d match.fields=%s',
                              msg.cookie, msg.priority, reason, msg.table_id,
                              msg.duration_sec, msg.duration_nsec,
                              msg.idle_timeout, msg.hard_timeout,
                              msg.packet_count, msg.byte_count, msg.match)
    """
    def __init__(self, datapath, cookie=None, priority=None, reason=None,
                 table_id=None, duration_sec=None, duration_nsec=None,
                 idle_timeout=None, hard_timeout=None, packet_count=None,
                 byte_count=None, match=None):
        super(OFPFlowRemoved, self).__init__(datapath)
        self.cookie = cookie
        self.priority = priority
        self.reason = reason
        self.table_id = table_id
        self.duration_sec = duration_sec
        self.duration_nsec = duration_nsec
        self.idle_timeout = idle_timeout
        self.hard_timeout = hard_timeout
        self.packet_count = packet_count
        self.byte_count = byte_count
        self.match = match

    @classmethod
    def parser(cls, datapath, version, msg_type, msg_len, xid, buf):
        msg = super(OFPFlowRemoved, cls).parser(datapath, version, msg_type,
                                                msg_len, xid, buf)

        (msg.cookie, msg.priority, msg.reason,
         msg.table_id, msg.duration_sec, msg.duration_nsec,
         msg.idle_timeout, msg.hard_timeout, msg.packet_count,
         msg.byte_count) = struct.unpack_from(
            ofproto_v1_3.OFP_FLOW_REMOVED_PACK_STR0,
            msg.buf, ofproto_v1_3.OFP_HEADER_SIZE)

        offset = (ofproto_v1_3.OFP_FLOW_REMOVED_SIZE -
                  ofproto_v1_3.OFP_MATCH_SIZE)

        msg.match = OFPMatch.parser(msg.buf, offset)

        return msg


class OFPPort(ofproto_parser.namedtuple('OFPPort', (
        'port_no', 'hw_addr', 'name', 'config', 'state', 'curr',
        'advertised', 'supported', 'peer', 'curr_speed', 'max_speed'))):

    _TYPE = {
        'ascii': [
            'hw_addr',
        ],
        'utf-8': [
            # OF spec is unclear about the encoding of name.
            # we assumes UTF-8, which is used by OVS.
            'name',
        ]
    }

    @classmethod
    def parser(cls, buf, offset):
        port = struct.unpack_from(ofproto_v1_3.OFP_PORT_PACK_STR, buf, offset)
        port = list(port)
        i = cls._fields.index('hw_addr')
        port[i] = addrconv.mac.bin_to_text(port[i])
        i = cls._fields.index('name')
        port[i] = port[i].rstrip('\0')
        ofpport = cls(*port)
        ofpport.length = ofproto_v1_3.OFP_PORT_SIZE
        return ofpport


@_register_parser
@_set_msg_type(ofproto_v1_3.OFPT_PORT_STATUS)
class OFPPortStatus(MsgBase):
    """
    Port status message

    The switch notifies controller of change of ports.

    ================ ======================================================
    Attribute        Description
    ================ ======================================================
    reason           One of the following values.
                     OFPPR_ADD
                     OFPPR_DELETE
                     OFPPR_MODIFY
    desc             instance of ``OFPPort``
    ================ ======================================================

    Example::

        @set_ev_cls(ofp_event.EventOFPPortStatus, MAIN_DISPATCHER)
        def port_status_handler(self, ev):
            msg = ev.msg
            dp = msg.datapath
            ofp = dp.ofproto

            if msg.reason == ofp.OFPPR_ADD:
                reason = 'ADD'
            elif msg.reason == ofp.OFPPR_DELETE:
                reason = 'DELETE'
            elif msg.reason == ofp.OFPPR_MODIFY:
                reason = 'MODIFY'
            else:
                reason = 'unknown'

            self.logger.debug('OFPPortStatus received: reason=%s desc=%s',
                              reason, msg.desc)
    """
    def __init__(self, datapath, reason=None, desc=None):
        super(OFPPortStatus, self).__init__(datapath)
        self.reason = reason
        self.desc = desc

    @classmethod
    def parser(cls, datapath, version, msg_type, msg_len, xid, buf):
        msg = super(OFPPortStatus, cls).parser(datapath, version, msg_type,
                                               msg_len, xid, buf)
        msg.reason = struct.unpack_from(
            ofproto_v1_3.OFP_PORT_STATUS_PACK_STR, msg.buf,
            ofproto_v1_3.OFP_HEADER_SIZE)[0]
        msg.desc = OFPPort.parser(msg.buf,
                                  ofproto_v1_3.OFP_PORT_STATUS_DESC_OFFSET)
        return msg


@_set_msg_type(ofproto_v1_3.OFPT_PACKET_OUT)
class OFPPacketOut(MsgBase):
    """
    Packet-Out message

    The controller uses this message to send a packet out throught the
    switch.

    ================ ======================================================
    Attribute        Description
    ================ ======================================================
    buffer_id        ID assigned by datapath (OFP_NO_BUFFER if none)
    in_port          Packet's input port or ``OFPP_CONTROLLER``
    actions          list of OpenFlow action class
    data             Packet data
    ================ ======================================================

    Example::

        def send_packet_out(self, datapath, buffer_id, in_port):
            ofp = datapath.ofproto
            ofp_parser = datapath.ofproto_parser

            actions = [ofp_parser.OFPActionOutput(ofp.OFPP_FLOOD, 0)]
            req = ofp_parser.OFPPacketOut(datapath, buffer_id,
                                          in_port, actions)
            datapath.send_msg(req)
    """
    def __init__(self, datapath, buffer_id=None, in_port=None, actions=None,
                 data=None, actions_len=None):
        assert in_port is not None

        super(OFPPacketOut, self).__init__(datapath)
        self.buffer_id = buffer_id
        self.in_port = in_port
        self.actions_len = 0
        self.actions = actions
        self.data = data

    def _serialize_body(self):
        self.actions_len = 0
        offset = ofproto_v1_3.OFP_PACKET_OUT_SIZE
        for a in self.actions:
            a.serialize(self.buf, offset)
            offset += a.len
            self.actions_len += a.len

        if self.data is not None:
            assert self.buffer_id == 0xffffffff
            self.buf += self.data

        msg_pack_into(ofproto_v1_3.OFP_PACKET_OUT_PACK_STR,
                      self.buf, ofproto_v1_3.OFP_HEADER_SIZE,
                      self.buffer_id, self.in_port, self.actions_len)


@_set_msg_type(ofproto_v1_3.OFPT_FLOW_MOD)
class OFPFlowMod(MsgBase):
    """
    Modify Flow entry message

    The controller sends this message to modify the flow table.

    ================ ======================================================
    Attribute        Description
    ================ ======================================================
    cookie           Opaque controller-issued identifier
    cookie_mask      Mask used to restrict the cookie bits that must match
                     when the command is ``OPFFC_MODIFY*`` or
                     ``OFPFC_DELETE*``
    table_id         ID of the table to put the flow in
    command          One of the following values.
                     OFPFC_ADD
                     OFPFC_MODIFY
                     OFPFC_MODIFY_STRICT
                     OFPFC_DELETE
                     OFPFC_DELETE_STRICT
    idle_timeout     Idle time before discarding (seconds)
    hard_timeout     Max time before discarding (seconds)
    priority         Priority level of flow entry
    buffer_id        Buffered packet to apply to (or OFP_NO_BUFFER)
    out_port         For ``OFPFC_DELETE*`` commands, require matching
                     entries to include this as an output port
    out_group        For ``OFPFC_DELETE*`` commands, require matching
                     entries to include this as an output group
    flags            One of the following values.
                     OFPFF_SEND_FLOW_REM
                     OFPFF_CHECK_OVERLAP
                     OFPFF_RESET_COUNTS
                     OFPFF_NO_PKT_COUNTS
                     OFPFF_NO_BYT_COUNTS
    match            Instance of ``OFPMatch``
    instructions     list of ``OFPInstruction*`` instance
    ================ ======================================================

    Example::

        def send_flow_mod(self, datapath):
            ofp = datapath.ofproto
            ofp_parser = datapath.ofproto_parser

            cookie = cookie_mask = 0
            table_id = 0
            idle_timeout = hard_timeout = 0
            priority = 32768
            buffer_id = ofp.OFP_NO_BUFFER
            match = ofp_parser.OFPMatch(in_port=1, eth_dst='ff:ff:ff:ff:ff:ff')
            actions = [ofp_parser.OFPActionOutput(ofp.OFPP_NORMAL, 0)]
            inst = [ofp_parser.OFPInstructionActions(ofp.OFPIT_APPLY_ACTIONS,
                                                     actions)]
            req = ofp_parser.OFPFlowMod(datapath, cookie, cookie_mask,
                                        table_id, ofp.OFPFC_ADD,
                                        idle_timeout, hard_timeout,
                                        priority, buffer_id,
                                        ofp.OFPP_ANY, ofp.OFPG_ANY,
                                        ofp.OFPFF_SEND_FLOW_REM,
                                        match, inst)
            datapath.send_msg(req)
    """
    def __init__(self, datapath, cookie=0, cookie_mask=0, table_id=0,
                 command=ofproto_v1_3.OFPFC_ADD,
                 idle_timeout=0, hard_timeout=0, priority=0,
                 buffer_id=ofproto_v1_3.OFP_NO_BUFFER,
                 out_port=0, out_group=0, flags=0,
                 match=None,
                 instructions=[]):
        super(OFPFlowMod, self).__init__(datapath)
        self.cookie = cookie
        self.cookie_mask = cookie_mask
        self.table_id = table_id
        self.command = command
        self.idle_timeout = idle_timeout
        self.hard_timeout = hard_timeout
        self.priority = priority
        self.buffer_id = buffer_id
        self.out_port = out_port
        self.out_group = out_group
        self.flags = flags
        if match is None:
            match = OFPMatch()
        self.match = match
        self.instructions = instructions

    def _serialize_body(self):
        msg_pack_into(ofproto_v1_3.OFP_FLOW_MOD_PACK_STR0, self.buf,
                      ofproto_v1_3.OFP_HEADER_SIZE,
                      self.cookie, self.cookie_mask, self.table_id,
                      self.command, self.idle_timeout, self.hard_timeout,
                      self.priority, self.buffer_id, self.out_port,
                      self.out_group, self.flags)

        offset = (ofproto_v1_3.OFP_FLOW_MOD_SIZE -
                  ofproto_v1_3.OFP_MATCH_SIZE)

        match_len = self.match.serialize(self.buf, offset)
        offset += match_len

        for inst in self.instructions:
            inst.serialize(self.buf, offset)
            offset += inst.len


class OFPInstruction(object):
    _INSTRUCTION_TYPES = {}

    @staticmethod
    def register_instruction_type(types):
        def _register_instruction_type(cls):
            for type_ in types:
                OFPInstruction._INSTRUCTION_TYPES[type_] = cls
            return cls
        return _register_instruction_type

    @classmethod
    def parser(cls, buf, offset):
        (type_, len_) = struct.unpack_from('!HH', buf, offset)
        cls_ = cls._INSTRUCTION_TYPES.get(type_)
        return cls_.parser(buf, offset)


@OFPInstruction.register_instruction_type([ofproto_v1_3.OFPIT_GOTO_TABLE])
class OFPInstructionGotoTable(StringifyMixin):
    """
    Goto table instruction

    This instruction indicates the next table in the processing pipeline.

    ================ ======================================================
    Attribute        Description
    ================ ======================================================
    table_id         Next table
    ================ ======================================================
    """
    def __init__(self, table_id, type_=None, len_=None):
        super(OFPInstructionGotoTable, self).__init__()
        self.type = ofproto_v1_3.OFPIT_GOTO_TABLE
        self.len = ofproto_v1_3.OFP_INSTRUCTION_GOTO_TABLE_SIZE
        self.table_id = table_id

    @classmethod
    def parser(cls, buf, offset):
        (type_, len_, table_id) = struct.unpack_from(
            ofproto_v1_3.OFP_INSTRUCTION_GOTO_TABLE_PACK_STR,
            buf, offset)
        return cls(table_id)

    def serialize(self, buf, offset):
        msg_pack_into(ofproto_v1_3.OFP_INSTRUCTION_GOTO_TABLE_PACK_STR,
                      buf, offset, self.type, self.len, self.table_id)


@OFPInstruction.register_instruction_type([ofproto_v1_3.OFPIT_WRITE_METADATA])
class OFPInstructionWriteMetadata(StringifyMixin):
    """
    Write metadata instruction

    This instruction writes the masked metadata value into the metadata field.

    ================ ======================================================
    Attribute        Description
    ================ ======================================================
    metadata         Metadata value to write
    metadata_mask    Metadata write bitmask
    ================ ======================================================
    """
    def __init__(self, metadata, metadata_mask, len_=None):
        super(OFPInstructionWriteMetadata, self).__init__()
        self.type = ofproto_v1_3.OFPIT_WRITE_METADATA
        self.len = ofproto_v1_3.OFP_INSTRUCTION_WRITE_METADATA_SIZE
        self.metadata = metadata
        self.metadata_mask = metadata_mask

    @classmethod
    def parser(cls, buf, offset):
        (type_, len_, metadata, metadata_mask) = struct.unpack_from(
            ofproto_v1_3.OFP_INSTRUCTION_WRITE_METADATA_PACK_STR,
            buf, offset)
        return cls(metadata, metadata_mask)

    def serialize(self, buf, offset):
        msg_pack_into(ofproto_v1_3.OFP_INSTRUCTION_WRITE_METADATA_PACK_STR,
                      buf, offset, self.type, self.len, self.metadata,
                      self.metadata_mask)


@OFPInstruction.register_instruction_type([ofproto_v1_3.OFPIT_WRITE_ACTIONS,
                                           ofproto_v1_3.OFPIT_APPLY_ACTIONS,
                                           ofproto_v1_3.OFPIT_CLEAR_ACTIONS])
class OFPInstructionActions(StringifyMixin):
    """
    Actions instruction

    This instruction writes/applies/clears the actions.

    ================ ======================================================
    Attribute        Description
    ================ ======================================================
    type             One of following values.
                     OFPIT_WRITE_ACTIONS
                     OFPIT_APPLY_ACTIONS
                     OFPIT_CLEAR_ACTIONS
    actions          list of OpenFlow action class
    ================ ======================================================

    ``type`` attribute corresponds to ``type_`` parameter of __init__.
    """
    def __init__(self, type_, actions=None, len_=None):
        super(OFPInstructionActions, self).__init__()
        self.type = type_
        self.actions = actions

    @classmethod
    def parser(cls, buf, offset):
        (type_, len_) = struct.unpack_from(
            ofproto_v1_3.OFP_INSTRUCTION_ACTIONS_PACK_STR,
            buf, offset)

        offset += ofproto_v1_3.OFP_INSTRUCTION_ACTIONS_SIZE
        actions = []
        actions_len = len_ - ofproto_v1_3.OFP_INSTRUCTION_ACTIONS_SIZE
        while actions_len > 0:
            a = OFPAction.parser(buf, offset)
            actions.append(a)
            actions_len -= a.len
            offset += a.len

        inst = cls(type_, actions)
        inst.len = len_
        return inst

    def serialize(self, buf, offset):
        action_offset = offset + ofproto_v1_3.OFP_INSTRUCTION_ACTIONS_SIZE
        if self.actions:
            for a in self.actions:
                a.serialize(buf, action_offset)
                action_offset += a.len

        self.len = action_offset - offset
        pad_len = utils.round_up(self.len, 8) - self.len
        ofproto_parser.msg_pack_into("%dx" % pad_len, buf, action_offset)
        self.len += pad_len

        msg_pack_into(ofproto_v1_3.OFP_INSTRUCTION_ACTIONS_PACK_STR,
                      buf, offset, self.type, self.len)


@OFPInstruction.register_instruction_type([ofproto_v1_3.OFPIT_METER])
class OFPInstructionMeter(StringifyMixin):
    """
    Meter instruction

    This instruction applies the meter.

    ================ ======================================================
    Attribute        Description
    ================ ======================================================
    meter_id         Meter instance
    ================ ======================================================
    """
    _base_attributes = ['type', 'len']

    def __init__(self, meter_id):
        super(OFPInstructionMeter, self).__init__()
        self.type = ofproto_v1_3.OFPIT_METER
        self.len = ofproto_v1_3.OFP_INSTRUCTION_METER_SIZE
        self.meter_id = meter_id

    @classmethod
    def parser(cls, buf, offset):
        (type_, len_, meter_id) = struct.unpack_from(
            ofproto_v1_3.OFP_INSTRUCTION_METER_PACK_STR,
            buf, offset)
        return cls(meter_id)

    def serialize(self, buf, offset):
        msg_pack_into(ofproto_v1_3.OFP_INSTRUCTION_METER_PACK_STR,
                      buf, offset, self.type, self.len, self.meter_id)


class OFPActionHeader(StringifyMixin):
    def __init__(self, type_, len_):
        self.type = type_
        self.len = len_

    def serialize(self, buf, offset):
        msg_pack_into(ofproto_v1_3.OFP_ACTION_HEADER_PACK_STR,
                      buf, offset, self.type, self.len)


class OFPAction(OFPActionHeader):
    _ACTION_TYPES = {}

    @staticmethod
    def register_action_type(type_, len_):
        def _register_action_type(cls):
            cls.cls_action_type = type_
            cls.cls_action_len = len_
            OFPAction._ACTION_TYPES[cls.cls_action_type] = cls
            return cls
        return _register_action_type

    def __init__(self):
        cls = self.__class__
        super(OFPAction, self).__init__(cls.cls_action_type,
                                        cls.cls_action_len)

    @classmethod
    def parser(cls, buf, offset):
        type_, len_ = struct.unpack_from(
            ofproto_v1_3.OFP_ACTION_HEADER_PACK_STR, buf, offset)
        cls_ = cls._ACTION_TYPES.get(type_)
        assert cls_ is not None
        return cls_.parser(buf, offset)


@OFPAction.register_action_type(ofproto_v1_3.OFPAT_OUTPUT,
                                ofproto_v1_3.OFP_ACTION_OUTPUT_SIZE)
class OFPActionOutput(OFPAction):
    """
    Output action

    This action indicates output a packet to the switch port.

    ================ ======================================================
    Attribute        Description
    ================ ======================================================
    port             Output port
    max_len          Max length to send to controller
    ================ ======================================================
    """
    def __init__(self, port, max_len=ofproto_v1_3.OFPCML_MAX,
                 type_=None, len_=None):
        super(OFPActionOutput, self).__init__()
        self.port = port
        self.max_len = max_len

    @classmethod
    def parser(cls, buf, offset):
        type_, len_, port, max_len = struct.unpack_from(
            ofproto_v1_3.OFP_ACTION_OUTPUT_PACK_STR, buf, offset)
        return cls(port, max_len)

    def serialize(self, buf, offset):
        msg_pack_into(ofproto_v1_3.OFP_ACTION_OUTPUT_PACK_STR, buf,
                      offset, self.type, self.len, self.port, self.max_len)


@OFPAction.register_action_type(ofproto_v1_3.OFPAT_GROUP,
                                ofproto_v1_3.OFP_ACTION_GROUP_SIZE)
class OFPActionGroup(OFPAction):
    """
    Group action

    This action indicates the group used to process the packet.

    ================ ======================================================
    Attribute        Description
    ================ ======================================================
    group_id         Group identifier
    ================ ======================================================
    """
    def __init__(self, group_id, type_=None, len_=None):
        super(OFPActionGroup, self).__init__()
        self.group_id = group_id

    @classmethod
    def parser(cls, buf, offset):
        (type_, len_, group_id) = struct.unpack_from(
            ofproto_v1_3.OFP_ACTION_GROUP_PACK_STR, buf, offset)
        return cls(group_id)

    def serialize(self, buf, offset):
        msg_pack_into(ofproto_v1_3.OFP_ACTION_GROUP_PACK_STR, buf,
                      offset, self.type, self.len, self.group_id)


@OFPAction.register_action_type(ofproto_v1_3.OFPAT_SET_QUEUE,
                                ofproto_v1_3.OFP_ACTION_SET_QUEUE_SIZE)
class OFPActionSetQueue(OFPAction):
    """
    Set queue action

    This action sets the queue id that will be used to map a flow to an
    already-configured queue on a port.

    ================ ======================================================
    Attribute        Description
    ================ ======================================================
    queue_id         Queue ID for the packets
    ================ ======================================================
    """
    def __init__(self, queue_id, type_=None, len_=None):
        super(OFPActionSetQueue, self).__init__()
        self.queue_id = queue_id

    @classmethod
    def parser(cls, buf, offset):
        (type_, len_, queue_id) = struct.unpack_from(
            ofproto_v1_3.OFP_ACTION_SET_QUEUE_PACK_STR, buf, offset)
        return cls(queue_id)

    def serialize(self, buf, offset):
        msg_pack_into(ofproto_v1_3.OFP_ACTION_SET_QUEUE_PACK_STR, buf,
                      offset, self.type, self.len, self.queue_id)


@OFPAction.register_action_type(ofproto_v1_3.OFPAT_SET_MPLS_TTL,
                                ofproto_v1_3.OFP_ACTION_MPLS_TTL_SIZE)
class OFPActionSetMplsTtl(OFPAction):
    """
    Set MPLS TTL action

    This action sets the MPLS TTL.

    ================ ======================================================
    Attribute        Description
    ================ ======================================================
    mpls_ttl         MPLS TTL
    ================ ======================================================
    """
    def __init__(self, mpls_ttl, type_=None, len_=None):
        super(OFPActionSetMplsTtl, self).__init__()
        self.mpls_ttl = mpls_ttl

    @classmethod
    def parser(cls, buf, offset):
        (type_, len_, mpls_ttl) = struct.unpack_from(
            ofproto_v1_3.OFP_ACTION_MPLS_TTL_PACK_STR, buf, offset)
        return cls(mpls_ttl)

    def serialize(self, buf, offset):
        msg_pack_into(ofproto_v1_3.OFP_ACTION_MPLS_TTL_PACK_STR, buf,
                      offset, self.type, self.len, self.mpls_ttl)


@OFPAction.register_action_type(ofproto_v1_3.OFPAT_DEC_MPLS_TTL,
                                ofproto_v1_3.OFP_ACTION_HEADER_SIZE)
class OFPActionDecMplsTtl(OFPAction):
    """
    Decrement MPLS TTL action

    This action decrements the MPLS TTL.
    """
    def __init__(self, type_=None, len_=None):
        super(OFPActionDecMplsTtl, self).__init__()

    @classmethod
    def parser(cls, buf, offset):
        (type_, len_) = struct.unpack_from(
            ofproto_v1_3.OFP_ACTION_HEADER_PACK_STR, buf, offset)
        return cls()


@OFPAction.register_action_type(ofproto_v1_3.OFPAT_SET_NW_TTL,
                                ofproto_v1_3.OFP_ACTION_NW_TTL_SIZE)
class OFPActionSetNwTtl(OFPAction):
    """
    Set IP TTL action

    This action sets the IP TTL.

    ================ ======================================================
    Attribute        Description
    ================ ======================================================
    nw_ttl           IP TTL
    ================ ======================================================
    """
    def __init__(self, nw_ttl, type_=None, len_=None):
        super(OFPActionSetNwTtl, self).__init__()
        self.nw_ttl = nw_ttl

    @classmethod
    def parser(cls, buf, offset):
        (type_, len_, nw_ttl) = struct.unpack_from(
            ofproto_v1_3.OFP_ACTION_NW_TTL_PACK_STR, buf, offset)
        return cls(nw_ttl)

    def serialize(self, buf, offset):
        msg_pack_into(ofproto_v1_3.OFP_ACTION_NW_TTL_PACK_STR, buf, offset,
                      self.type, self.len, self.nw_ttl)


@OFPAction.register_action_type(ofproto_v1_3.OFPAT_DEC_NW_TTL,
                                ofproto_v1_3.OFP_ACTION_HEADER_SIZE)
class OFPActionDecNwTtl(OFPAction):
    """
    Decrement IP TTL action

    This action decrements the IP TTL.
    """
    def __init__(self, type_=None, len_=None):
        super(OFPActionDecNwTtl, self).__init__()

    @classmethod
    def parser(cls, buf, offset):
        (type_, len_) = struct.unpack_from(
            ofproto_v1_3.OFP_ACTION_HEADER_PACK_STR, buf, offset)
        return cls()


@OFPAction.register_action_type(ofproto_v1_3.OFPAT_COPY_TTL_OUT,
                                ofproto_v1_3.OFP_ACTION_HEADER_SIZE)
class OFPActionCopyTtlOut(OFPAction):
    """
    Copy TTL Out action

    This action copies the TTL from the next-to-outermost header with TTL to
    the outermost header with TTL.
    """
    def __init__(self, type_=None, len_=None):
        super(OFPActionCopyTtlOut, self).__init__()

    @classmethod
    def parser(cls, buf, offset):
        (type_, len_) = struct.unpack_from(
            ofproto_v1_3.OFP_ACTION_HEADER_PACK_STR, buf, offset)
        return cls()


@OFPAction.register_action_type(ofproto_v1_3.OFPAT_COPY_TTL_IN,
                                ofproto_v1_3.OFP_ACTION_HEADER_SIZE)
class OFPActionCopyTtlIn(OFPAction):
    """
    Copy TTL In action

    This action copies the TTL from the outermost header with TTL to the
    next-to-outermost header with TTL.
    """
    def __init__(self, type_=None, len_=None):
        super(OFPActionCopyTtlIn, self).__init__()

    @classmethod
    def parser(cls, buf, offset):
        (type_, len_) = struct.unpack_from(
            ofproto_v1_3.OFP_ACTION_HEADER_PACK_STR, buf, offset)
        return cls()


@OFPAction.register_action_type(ofproto_v1_3.OFPAT_PUSH_VLAN,
                                ofproto_v1_3.OFP_ACTION_PUSH_SIZE)
class OFPActionPushVlan(OFPAction):
    """
    Push VLAN action

    This action pushes a new VLAN tag to the packet.

    ================ ======================================================
    Attribute        Description
    ================ ======================================================
    ethertype        Ether type
    ================ ======================================================
    """
    def __init__(self, ethertype, type_=None, len_=None):
        super(OFPActionPushVlan, self).__init__()
        self.ethertype = ethertype

    @classmethod
    def parser(cls, buf, offset):
        (type_, len_, ethertype) = struct.unpack_from(
            ofproto_v1_3.OFP_ACTION_PUSH_PACK_STR, buf, offset)
        return cls(ethertype)

    def serialize(self, buf, offset):
        msg_pack_into(ofproto_v1_3.OFP_ACTION_PUSH_PACK_STR, buf, offset,
                      self.type, self.len, self.ethertype)


@OFPAction.register_action_type(ofproto_v1_3.OFPAT_PUSH_MPLS,
                                ofproto_v1_3.OFP_ACTION_PUSH_SIZE)
class OFPActionPushMpls(OFPAction):
    """
    Push MPLS action

    This action pushes a new MPLS header to the packet.

    ================ ======================================================
    Attribute        Description
    ================ ======================================================
    ethertype        Ether type
    ================ ======================================================
    """
    def __init__(self, ethertype, type_=None, len_=None):
        super(OFPActionPushMpls, self).__init__()
        self.ethertype = ethertype

    @classmethod
    def parser(cls, buf, offset):
        (type_, len_, ethertype) = struct.unpack_from(
            ofproto_v1_3.OFP_ACTION_PUSH_PACK_STR, buf, offset)
        return cls(ethertype)

    def serialize(self, buf, offset):
        msg_pack_into(ofproto_v1_3.OFP_ACTION_PUSH_PACK_STR, buf, offset,
                      self.type, self.len, self.ethertype)


@OFPAction.register_action_type(ofproto_v1_3.OFPAT_POP_VLAN,
                                ofproto_v1_3.OFP_ACTION_HEADER_SIZE)
class OFPActionPopVlan(OFPAction):
    """
    Pop VLAN action

    This action pops the outermost VLAN tag from the packet.
    """
    def __init__(self, type_=None, len_=None):
        super(OFPActionPopVlan, self).__init__()

    @classmethod
    def parser(cls, buf, offset):
        (type_, len_) = struct.unpack_from(
            ofproto_v1_3.OFP_ACTION_HEADER_PACK_STR, buf, offset)
        return cls()


@OFPAction.register_action_type(ofproto_v1_3.OFPAT_POP_MPLS,
                                ofproto_v1_3.OFP_ACTION_POP_MPLS_SIZE)
class OFPActionPopMpls(OFPAction):
    """
    Pop MPLS action

    This action pops the MPLS header from the packet.
    """
    def __init__(self, ethertype, type_=None, len_=None):
        super(OFPActionPopMpls, self).__init__()
        self.ethertype = ethertype

    @classmethod
    def parser(cls, buf, offset):
        (type_, len_, ethertype) = struct.unpack_from(
            ofproto_v1_3.OFP_ACTION_POP_MPLS_PACK_STR, buf, offset)
        return cls(ethertype)

    def serialize(self, buf, offset):
        msg_pack_into(ofproto_v1_3.OFP_ACTION_POP_MPLS_PACK_STR, buf, offset,
                      self.type, self.len, self.ethertype)


@OFPAction.register_action_type(ofproto_v1_3.OFPAT_SET_FIELD,
                                ofproto_v1_3.OFP_ACTION_SET_FIELD_SIZE)
class OFPActionSetField(OFPAction):
    """
    Set field action

    This action modifies a header field in the packet.

    ================ ======================================================
    Attribute        Description
    ================ ======================================================
    field            Instance of ``OFPMatchField``
    ================ ======================================================
    """
    def __init__(self, field=None, **kwargs):
        # old api
        #   OFPActionSetField(field)
        # new api
        #   OFPActionSetField(eth_src="00:00:00:00:00")
        super(OFPActionSetField, self).__init__()
        if isinstance(field, OFPMatchField):
            # old api compat
            assert len(kwargs) == 0
            self.field = field
        else:
            # new api
            assert len(kwargs) == 1
            key = kwargs.keys()[0]
            value = kwargs[key]
            assert isinstance(key, (str, unicode))
            assert not isinstance(value, tuple)  # no mask
            self.key = key
            self.value = value

    @classmethod
    def parser(cls, buf, offset):
        (type_, len_) = struct.unpack_from(
            ofproto_v1_3.OFP_ACTION_SET_FIELD_PACK_STR, buf, offset)
        (n, value, mask, _len) = ofproto_v1_3.oxm_parse(buf, offset + 4)
        k, uv = ofproto_v1_3.oxm_to_user(n, value, mask)
        action = cls(**{k: uv})
        action.len = len_

        # old api compat
        action.field = OFPMatchField.parser(buf, offset + 4)

        return action

    def serialize(self, buf, offset):
        # old api compat
        if self._composed_with_old_api():
            return self.serialize_old(buf, offset)

        n, value, mask = ofproto_v1_3.oxm_from_user(self.key, self.value)
        len_ = ofproto_v1_3.oxm_serialize(n, value, mask, buf, offset + 4)
        self.len = utils.round_up(4 + len_, 8)
        msg_pack_into('!HH', buf, offset, self.type, self.len)
        pad_len = self.len - (4 + len_)
        ofproto_parser.msg_pack_into("%dx" % pad_len, buf, offset + 4 + len_)

    # XXX old api compat
    def serialize_old(self, buf, offset):
        len_ = ofproto_v1_3.OFP_ACTION_SET_FIELD_SIZE + self.field.oxm_len()
        self.len = utils.round_up(len_, 8)
        pad_len = self.len - len_

        msg_pack_into('!HH', buf, offset, self.type, self.len)
        self.field.serialize(buf, offset + 4)
        offset += len_
        ofproto_parser.msg_pack_into("%dx" % pad_len, buf, offset)

    # XXX old api compat
    def _composed_with_old_api(self):
        return not hasattr(self, 'value')

    def to_jsondict(self):
        # XXX old api compat
        if self._composed_with_old_api():
            # copy object first because serialize_old is destructive
            o2 = OFPActionSetField(self.field)
            # serialize and parse to fill new fields
            buf = bytearray()
            o2.serialize(buf, 0)
            o = OFPActionSetField.parser(str(buf), 0)
        else:
            o = self
        return {
            self.__class__.__name__: {
                'field': ofproto_v1_3.oxm_to_jsondict(self.key, self.value)
            }
        }

    @classmethod
    def from_jsondict(cls, dict_):
        k, v = ofproto_v1_3.oxm_from_jsondict(dict_['field'])
        o = OFPActionSetField(**{k: v})

        # XXX old api compat
        # serialize and parse to fill old attributes
        buf = bytearray()
        o.serialize(buf, 0)
        return OFPActionSetField.parser(str(buf), 0)

    # XXX old api compat
    def __str__(self):
        # XXX old api compat
        if self._composed_with_old_api():
            # copy object first because serialize_old is destructive
            o2 = OFPActionSetField(self.field)
            # serialize and parse to fill new fields
            buf = bytearray()
            o2.serialize(buf, 0)
            o = OFPActionSetField.parser(str(buf), 0)
        else:
            o = self
        return super(OFPActionSetField, o).__str__()

    __repr__ = __str__

    def stringify_attrs(self):
        yield (self.key, self.value)


@OFPAction.register_action_type(ofproto_v1_3.OFPAT_PUSH_PBB,
                                ofproto_v1_3.OFP_ACTION_PUSH_SIZE)
class OFPActionPushPbb(OFPAction):
    """
    Push PBB action

    This action pushes a new PBB header to the packet.

    ================ ======================================================
    Attribute        Description
    ================ ======================================================
    ethertype        Ether type
    ================ ======================================================
    """
    def __init__(self, ethertype, type_=None, len_=None):
        super(OFPActionPushPbb, self).__init__()
        self.ethertype = ethertype

    @classmethod
    def parser(cls, buf, offset):
        (type_, len_, ethertype) = struct.unpack_from(
            ofproto_v1_3.OFP_ACTION_PUSH_PACK_STR, buf, offset)
        return cls(ethertype)

    def serialize(self, buf, offset):
        msg_pack_into(ofproto_v1_3.OFP_ACTION_PUSH_PACK_STR, buf, offset,
                      self.type, self.len, self.ethertype)


@OFPAction.register_action_type(ofproto_v1_3.OFPAT_POP_PBB,
                                ofproto_v1_3.OFP_ACTION_HEADER_SIZE)
class OFPActionPopPbb(OFPAction):
    """
    Pop PBB action

    This action pops the outermost PBB service instance header from
    the packet.
    """
    def __init__(self, type_=None, len_=None):
        super(OFPActionPopPbb, self).__init__()

    @classmethod
    def parser(cls, buf, offset):
        (type_, len_) = struct.unpack_from(
            ofproto_v1_3.OFP_ACTION_HEADER_PACK_STR, buf, offset)
        return cls()

    @classmethod
    def parser(cls, buf, offset):
        (type_, len_) = struct.unpack_from(
            ofproto_v1_3.OFP_ACTION_HEADER_PACK_STR, buf, offset)
        return cls()


@OFPAction.register_action_type(
    ofproto_v1_3.OFPAT_EXPERIMENTER,
    ofproto_v1_3.OFP_ACTION_EXPERIMENTER_HEADER_SIZE)
class OFPActionExperimenter(OFPAction):
    """
    Experimenter action

    This action is an extensible action for the experimenter.

    ================ ======================================================
    Attribute        Description
    ================ ======================================================
    experimenter     Experimenter ID
    ================ ======================================================
    """
    def __init__(self, experimenter, type_=None, len_=None):
        super(OFPActionExperimenter, self).__init__()
        self.experimenter = experimenter

    @classmethod
    def parser(cls, buf, offset):
        (type_, len_, experimenter) = struct.unpack_from(
            ofproto_v1_3.OFP_ACTION_EXPERIMENTER_HEADER_PACK_STR, buf, offset)
        return cls(experimenter)

    def serialize(self, buf, offset):
        msg_pack_into(ofproto_v1_3.OFP_ACTION_EXPERIMENTER_HEADER_PACK_STR,
                      buf, offset, self.type, self.len, self.experimenter)


class OFPBucket(StringifyMixin):
    def __init__(self, weight, watch_port, watch_group, actions, len_=None):
        super(OFPBucket, self).__init__()
        self.weight = weight
        self.watch_port = watch_port
        self.watch_group = watch_group
        self.actions = actions

    @classmethod
    def parser(cls, buf, offset):
        (len_, weight, watch_port, watch_group) = struct.unpack_from(
            ofproto_v1_3.OFP_BUCKET_PACK_STR, buf, offset)
        msg = cls(weight, watch_port, watch_group, [])
        msg.len = len_

        length = ofproto_v1_3.OFP_BUCKET_SIZE
        offset += ofproto_v1_3.OFP_BUCKET_SIZE
        while length < msg.len:
            action = OFPAction.parser(buf, offset)
            msg.actions.append(action)
            offset += action.len
            length += action.len

        return msg

    def serialize(self, buf, offset):
        action_offset = offset + ofproto_v1_3.OFP_BUCKET_SIZE
        action_len = 0
        for a in self.actions:
            a.serialize(buf, action_offset)
            action_offset += a.len
            action_len += a.len

        self.len = utils.round_up(ofproto_v1_3.OFP_BUCKET_SIZE + action_len, 8)
        msg_pack_into(ofproto_v1_3.OFP_BUCKET_PACK_STR, buf, offset,
                      self.len, self.weight, self.watch_port,
                      self.watch_group)


@_set_msg_type(ofproto_v1_3.OFPT_GROUP_MOD)
class OFPGroupMod(MsgBase):
    """
    Modify group entry message

    The controller sends this message to modify the group table.

    ================ ======================================================
    Attribute        Description
    ================ ======================================================
    command          One of the following values.
                     OFPFC_ADD
                     OFPFC_MODIFY
                     OFPFC_DELETE
    type             One of the following values.
                     OFPGT_ALL
                     OFPGT_SELECT
                     OFPGT_INDIRECT
                     OFPGT_FF
    group_id         Group identifier
    buckets          list of ``OFPBucket``
    ================ ======================================================

    ``type`` attribute corresponds to ``type_`` parameter of __init__.

    Example::

        def send_group_mod(self, datapath):
            ofp = datapath.ofproto
            ofp_parser = datapath.ofproto_parser

            port = 1
            max_len = 2000
            actions = [ofp_parser.OFPActionOutput(port, max_len)]

            weight = 100
            watch_port = 0
            watch_group = 0
            buckets = [ofp_parser.OFPBucket(weight, watch_port, watch_group,
                                            actions)]

            group_id = 1
            req = ofp_parser.OFPGroupMod(datapath, ofp.OFPFC_ADD,
                                         ofp.OFPGT_SELECT, group_id, buckets)
            datapath.send_msg(req)
    """
    def __init__(self, datapath, command, type_, group_id, buckets):
        super(OFPGroupMod, self).__init__(datapath)
        self.command = command
        self.type = type_
        self.group_id = group_id
        self.buckets = buckets

    def _serialize_body(self):
        msg_pack_into(ofproto_v1_3.OFP_GROUP_MOD_PACK_STR, self.buf,
                      ofproto_v1_3.OFP_HEADER_SIZE,
                      self.command, self.type, self.group_id)

        offset = ofproto_v1_3.OFP_GROUP_MOD_SIZE
        for b in self.buckets:
            b.serialize(self.buf, offset)
            offset += b.len


@_set_msg_type(ofproto_v1_3.OFPT_PORT_MOD)
class OFPPortMod(MsgBase):
    """
    Port modification message

    The controller sneds this message to modify the behavior of the port.

    ================ ======================================================
    Attribute        Description
    ================ ======================================================
    port_no          Port number to modify
    hw_addr          The hardware address that must be the same as hw_addr
                     of ``OFPPort`` of ``OFPSwitchFeatures``
    config           Bitmap of configuration flags.
                     OFPPC_PORT_DOWN
                     OFPPC_NO_RECV
                     OFPPC_NO_FWD
                     OFPPC_NO_PACKET_IN
    mask             Bitmap of configuration flags above to be changed
    advertise        Bitmap of the following flags.
                     OFPPF_10MB_HD
                     OFPPF_10MB_FD
                     OFPPF_100MB_HD
                     OFPPF_100MB_FD
                     OFPPF_1GB_HD
                     OFPPF_1GB_FD
                     OFPPF_10GB_FD
                     OFPPF_40GB_FD
                     OFPPF_100GB_FD
                     OFPPF_1TB_FD
                     OFPPF_OTHER
                     OFPPF_COPPER
                     OFPPF_FIBER
                     OFPPF_AUTONEG
                     OFPPF_PAUSE
                     OFPPF_PAUSE_ASYM
    ================ ======================================================

    Example::

        def send_port_mod(self, datapath):
            ofp = datapath.ofproto
            ofp_parser = datapath.ofproto_parser

            port_no = 3
            hw_addr = 'fa:c8:e8:76:1d:7e'
            config = 0
            mask = (ofp.OFPPC_PORT_DOWN | ofp.OFPPC_NO_RECV |
                    ofp.OFPPC_NO_FWD | ofp.OFPPC_NO_PACKET_IN)
            advertise = (ofp.OFPPF_10MB_HD | ofp.OFPPF_100MB_FD |
                         ofp.OFPPF_1GB_FD | ofp.OFPPF_COPPER |
                         ofp.OFPPF_AUTONEG | ofp.OFPPF_PAUSE |
                         ofp.OFPPF_PAUSE_ASYM)
            req = ofp_parser.OFPPortMod(datapath, port_no, hw_addr, config,
                                        mask, advertise)
            datapath.send_msg(req)
    """

    _TYPE = {
        'ascii': [
            'hw_addr',
        ]
    }

    def __init__(self, datapath, port_no, hw_addr, config, mask, advertise):
        super(OFPPortMod, self).__init__(datapath)
        self.port_no = port_no
        self.hw_addr = hw_addr
        self.config = config
        self.mask = mask
        self.advertise = advertise

    def _serialize_body(self):
        msg_pack_into(ofproto_v1_3.OFP_PORT_MOD_PACK_STR, self.buf,
                      ofproto_v1_3.OFP_HEADER_SIZE,
                      self.port_no, addrconv.mac.text_to_bin(self.hw_addr),
                      self.config,
                      self.mask, self.advertise)


@_set_msg_type(ofproto_v1_3.OFPT_METER_MOD)
class OFPMeterMod(MsgBase):
    """
    Meter modification message

    The controller sends this message to modify the meter.

    ================ ======================================================
    Attribute        Description
    ================ ======================================================
    command          One of the following values.
                     OFPMC_ADD
                     OFPMC_MODIFY
                     OFPMC_DELETE
    flags            One of the following flags.
                     OFPMF_KBPS
                     OFPMF_PKTPS
                     OFPMF_BURST
                     OFPMF_STATS
    meter_id         Meter instance
    bands            list of the following class instance.
                     OFPMeterBandDrop
                     OFPMeterBandDscpRemark
                     OFPMeterBandExperimenter
    ================ ======================================================
    """
    def __init__(self, datapath, command, flags, meter_id, bands):
        super(OFPMeterMod, self).__init__(datapath)
        self.command = command
        self.flags = flags
        self.meter_id = meter_id
        self.bands = bands

    def _serialize_body(self):
        msg_pack_into(ofproto_v1_3.OFP_METER_MOD_PACK_STR, self.buf,
                      ofproto_v1_3.OFP_HEADER_SIZE,
                      self.command, self.flags, self.meter_id)

        offset = ofproto_v1_3.OFP_METER_MOD_SIZE
        for b in self.bands:
            b.serialize(self.buf, offset)
            offset += b.len


@_set_msg_type(ofproto_v1_3.OFPT_TABLE_MOD)
class OFPTableMod(MsgBase):
    """
    Flow table configuration message

    The controller sends this message to configure table state.

    ================ ======================================================
    Attribute        Description
    ================ ======================================================
    table_id         ID of the table (OFPTT_ALL indicates all tables)
    config           Bitmap of the following flags.
                     OFPTC_DEPRECATED_MASK (3)
    ================ ======================================================

    Example::

        def send_table_mod(self, datapath):
            ofp = datapath.ofproto
            ofp_parser = datapath.ofproto_parser

            req = ofp_parser.OFPTableMod(datapath, 1, 3)
            datapath.send_msg(req)
    """
    def __init__(self, datapath, table_id, config):
        super(OFPTableMod, self).__init__(datapath)
        self.table_id = table_id
        self.config = config

    def _serialize_body(self):
        msg_pack_into(ofproto_v1_3.OFP_TABLE_MOD_PACK_STR, self.buf,
                      ofproto_v1_3.OFP_HEADER_SIZE,
                      self.table_id, self.config)


def _set_stats_type(stats_type, stats_body_cls):
    def _set_cls_stats_type(cls):
        cls.cls_stats_type = stats_type
        cls.cls_stats_body_cls = stats_body_cls
        return cls
    return _set_cls_stats_type


@_set_msg_type(ofproto_v1_3.OFPT_MULTIPART_REQUEST)
class OFPMultipartRequest(MsgBase):
    def __init__(self, datapath, flags):
        super(OFPMultipartRequest, self).__init__(datapath)
        self.type = self.__class__.cls_stats_type
        self.flags = flags

    def _serialize_stats_body(self):
        pass

    def _serialize_body(self):
        msg_pack_into(ofproto_v1_3.OFP_MULTIPART_REQUEST_PACK_STR,
                      self.buf, ofproto_v1_3.OFP_HEADER_SIZE,
                      self.type, self.flags)
        self._serialize_stats_body()


@_register_parser
@_set_msg_type(ofproto_v1_3.OFPT_MULTIPART_REPLY)
class OFPMultipartReply(MsgBase):
    _STATS_MSG_TYPES = {}

    @staticmethod
    def register_stats_type(body_single_struct=False):
        def _register_stats_type(cls):
            assert cls.cls_stats_type is not None
            assert cls.cls_stats_type not in OFPMultipartReply._STATS_MSG_TYPES
            assert cls.cls_stats_body_cls is not None
            cls.cls_body_single_struct = body_single_struct
            OFPMultipartReply._STATS_MSG_TYPES[cls.cls_stats_type] = cls
            return cls
        return _register_stats_type

    def __init__(self, datapath, body=None, flags=None):
        super(OFPMultipartReply, self).__init__(datapath)
        self.body = body
        self.flags = flags

    @classmethod
    def parser_stats_body(cls, buf, msg_len, offset):
        body_cls = cls.cls_stats_body_cls
        body = []
        while offset < msg_len:
            entry = body_cls.parser(buf, offset)
            body.append(entry)
            offset += entry.length

        if cls.cls_body_single_struct:
            return body[0]
        return body

    @classmethod
    def parser_stats(cls, datapath, version, msg_type, msg_len, xid, buf):
        msg = MsgBase.parser.__func__(
            cls, datapath, version, msg_type, msg_len, xid, buf)
        msg.body = msg.parser_stats_body(msg.buf, msg.msg_len,
                                         ofproto_v1_3.OFP_MULTIPART_REPLY_SIZE)
        return msg

    @classmethod
    def parser(cls, datapath, version, msg_type, msg_len, xid, buf):
        type_, flags = struct.unpack_from(
            ofproto_v1_3.OFP_MULTIPART_REPLY_PACK_STR, buffer(buf),
            ofproto_v1_3.OFP_HEADER_SIZE)
        stats_type_cls = cls._STATS_MSG_TYPES.get(type_)
        msg = super(OFPMultipartReply, stats_type_cls).parser(
            datapath, version, msg_type, msg_len, xid, buf)
        msg.type = type_
        msg.flags = flags

        offset = ofproto_v1_3.OFP_MULTIPART_REPLY_SIZE
        body = []
        while offset < msg_len:
            b = stats_type_cls.cls_stats_body_cls.parser(msg.buf, offset)
            body.append(b)
            offset += b.length if hasattr(b, 'length') else b.len

        if stats_type_cls.cls_body_single_struct:
            msg.body = body[0]
        else:
            msg.body = body
        return msg


class OFPDescStats(ofproto_parser.namedtuple('OFPDescStats', (
        'mfr_desc', 'hw_desc', 'sw_desc', 'serial_num', 'dp_desc'))):

    _TYPE = {
        'ascii': [
            'mfr_desc',
            'hw_desc',
            'sw_desc',
            'serial_num',
            'dp_desc',
        ]
    }

    @classmethod
    def parser(cls, buf, offset):
        desc = struct.unpack_from(ofproto_v1_3.OFP_DESC_PACK_STR,
                                  buf, offset)
        desc = list(desc)
        desc = map(lambda x: x.rstrip('\0'), desc)
        stats = cls(*desc)
        stats.length = ofproto_v1_3.OFP_DESC_SIZE
        return stats


@_set_stats_type(ofproto_v1_3.OFPMP_DESC, OFPDescStats)
@_set_msg_type(ofproto_v1_3.OFPT_MULTIPART_REQUEST)
class OFPDescStatsRequest(OFPMultipartRequest):
    """
    Description statistics request message

    The controller uses this message to query description of the switch.

    ================ ======================================================
    Attribute        Description
    ================ ======================================================
    flags            Zero or ``OFPMPF_REQ_MORE``
    ================ ======================================================

    Example::

        def send_desc_stats_request(self, datapath):
            ofp = datapath.ofproto
            ofp_parser = datapath.ofproto_parser

            req = ofp_parser.OFPDescStatsRequest(datapath, 0)
            datapath.send_msg(req)
    """
    def __init__(self, datapath, flags, type_=None):
        super(OFPDescStatsRequest, self).__init__(datapath, flags)


@OFPMultipartReply.register_stats_type(body_single_struct=True)
@_set_stats_type(ofproto_v1_3.OFPMP_DESC, OFPDescStats)
@_set_msg_type(ofproto_v1_3.OFPT_MULTIPART_REPLY)
class OFPDescStatsReply(OFPMultipartReply):
    """
    Description statistics reply message

    The switch responds with this message to a description statistics
    request.

    ================ ======================================================
    Attribute        Description
    ================ ======================================================
    body             Instance of ``OFPDescStats``
    ================ ======================================================

    Example::

        @set_ev_cls(ofp_event.EventOFPDescStatsReply, MAIN_DISPATCHER)
        def desc_stats_reply_handler(self, ev):
            body = ev.msg.body

            self.logger.debug('DescStats: mfr_desc=%s hw_desc=%s sw_desc=%s '
                              'serial_num=%s dp_desc=%s',
                              body.mfr_desc, body.hw_desc, body.sw_desc,
                              body.serial_num, body.dp_desc)
    """
    def __init__(self, datapath, type_=None, **kwargs):
        super(OFPDescStatsReply, self).__init__(datapath, **kwargs)


class OFPFlowStats(StringifyMixin):
    def __init__(self, table_id=None, duration_sec=None, duration_nsec=None,
                 priority=None, idle_timeout=None, hard_timeout=None,
                 flags=None, cookie=None, packet_count=None,
                 byte_count=None, match=None, instructions=None,
                 length=None):
        super(OFPFlowStats, self).__init__()
        self.length = 0
        self.table_id = table_id
        self.duration_sec = duration_sec
        self.duration_nsec = duration_nsec
        self.priority = priority
        self.idle_timeout = idle_timeout
        self.hard_timeout = hard_timeout
        self.flags = flags
        self.cookie = cookie
        self.packet_count = packet_count
        self.byte_count = byte_count
        self.match = match
        self.instructions = instructions

    @classmethod
    def parser(cls, buf, offset):
        flow_stats = cls()

        (flow_stats.length, flow_stats.table_id,
         flow_stats.duration_sec, flow_stats.duration_nsec,
         flow_stats.priority, flow_stats.idle_timeout,
         flow_stats.hard_timeout, flow_stats.flags,
         flow_stats.cookie, flow_stats.packet_count,
         flow_stats.byte_count) = struct.unpack_from(
            ofproto_v1_3.OFP_FLOW_STATS_0_PACK_STR, buf, offset)
        offset += ofproto_v1_3.OFP_FLOW_STATS_0_SIZE

        flow_stats.match = OFPMatch.parser(buf, offset)
        match_length = utils.round_up(flow_stats.match.length, 8)
        inst_length = (flow_stats.length - (ofproto_v1_3.OFP_FLOW_STATS_SIZE -
                                            ofproto_v1_3.OFP_MATCH_SIZE +
                                            match_length))
        offset += match_length
        instructions = []
        while inst_length > 0:
            inst = OFPInstruction.parser(buf, offset)
            instructions.append(inst)
            offset += inst.len
            inst_length -= inst.len

        flow_stats.instructions = instructions
        return flow_stats


class OFPFlowStatsRequestBase(OFPMultipartRequest):
    def __init__(self, datapath, flags, table_id, out_port, out_group,
                 cookie, cookie_mask, match):
        super(OFPFlowStatsRequestBase, self).__init__(datapath, flags)
        self.table_id = table_id
        self.out_port = out_port
        self.out_group = out_group
        self.cookie = cookie
        self.cookie_mask = cookie_mask
        self.match = match

    def _serialize_stats_body(self):
        offset = ofproto_v1_3.OFP_MULTIPART_REQUEST_SIZE
        msg_pack_into(ofproto_v1_3.OFP_FLOW_STATS_REQUEST_0_PACK_STR,
                      self.buf, offset, self.table_id, self.out_port,
                      self.out_group, self.cookie, self.cookie_mask)

        offset += ofproto_v1_3.OFP_FLOW_STATS_REQUEST_0_SIZE
        self.match.serialize(self.buf, offset)


@_set_stats_type(ofproto_v1_3.OFPMP_FLOW, OFPFlowStats)
@_set_msg_type(ofproto_v1_3.OFPT_MULTIPART_REQUEST)
class OFPFlowStatsRequest(OFPFlowStatsRequestBase):
    """
    Individual flow statistics request message

    The controller uses this message to query individual flow statistics.

    ================ ======================================================
    Attribute        Description
    ================ ======================================================
    flags            Zero or ``OFPMPF_REQ_MORE``
    table_id         ID of table to read
    out_port         Require matching entries to include this as an output
                     port
    out_group        Require matching entries to include this as an output
                     group
    cookie           Require matching entries to contain this cookie value
    cookie_mask      Mask used to restrict the cookie bits that must match
    match            Instance of ``OFPMatch``
    ================ ======================================================

    Example::

        def send_flow_stats_request(self, datapath):
            ofp = datapath.ofproto
            ofp_parser = datapath.ofproto_parser

            cookie = cookie_mask = 0
            match = ofp_parser.OFPMatch(in_port=1)
            req = ofp_parser.OFPFlowStatsRequest(datapath, 0,
                                                 ofp.OFPTT_ALL,
                                                 ofp.OFPP_ANY, ofp.OFPG_ANY,
                                                 cookie, cookie_mask,
                                                 match)
            datapath.send_msg(req)
    """
    def __init__(self, datapath, flags=0, table_id=ofproto_v1_3.OFPTT_ALL,
                 out_port=ofproto_v1_3.OFPP_ANY,
                 out_group=ofproto_v1_3.OFPG_ANY,
                 cookie=0, cookie_mask=0, match=None, type_=None):
        if match is None:
            match = OFPMatch()
        super(OFPFlowStatsRequest, self).__init__(datapath, flags, table_id,
                                                  out_port, out_group,
                                                  cookie, cookie_mask, match)


@OFPMultipartReply.register_stats_type()
@_set_stats_type(ofproto_v1_3.OFPMP_FLOW, OFPFlowStats)
@_set_msg_type(ofproto_v1_3.OFPT_MULTIPART_REPLY)
class OFPFlowStatsReply(OFPMultipartReply):
    """
    Individual flow statistics reply message

    The switch responds with this message to an individual flow statistics
    request.

    ================ ======================================================
    Attribute        Description
    ================ ======================================================
    body             List of ``OFPFlowStats`` instance
    ================ ======================================================

    Example::

        @set_ev_cls(ofp_event.EventOFPFlowStatsReply, MAIN_DISPATCHER)
        def flow_stats_reply_handler(self, ev):
            flows = []
            for stat in ev.msg.body:
                flows.append('table_id=%s '
                             'duration_sec=%d duration_nsec=%d '
                             'priority=%d '
                             'idle_timeout=%d hard_timeout=%d flags=0x%04x '
                             'cookie=%d packet_count=%d byte_count=%d '
                             'match=%s instructions=%s' %
                             (stat.table_id,
                              stat.duration_sec, stat.duration_nsec,
                              stat.priority,
                              stat.idle_timeout, stat.hard_timeout, stat.flags,
                              stat.cookie, stat.packet_count, stat.byte_count,
                              stat.match, stat.instructions))
            self.logger.debug('FlowStats: %s', flows)
    """
    def __init__(self, datapath, type_=None, **kwargs):
        super(OFPFlowStatsReply, self).__init__(datapath, **kwargs)


class OFPAggregateStats(ofproto_parser.namedtuple('OFPAggregateStats', (
        'packet_count', 'byte_count', 'flow_count'))):
    @classmethod
    def parser(cls, buf, offset):
        agg = struct.unpack_from(
            ofproto_v1_3.OFP_AGGREGATE_STATS_REPLY_PACK_STR, buf, offset)
        stats = cls(*agg)
        stats.length = ofproto_v1_3.OFP_AGGREGATE_STATS_REPLY_SIZE
        return stats


@_set_stats_type(ofproto_v1_3.OFPMP_AGGREGATE, OFPAggregateStats)
@_set_msg_type(ofproto_v1_3.OFPT_MULTIPART_REQUEST)
class OFPAggregateStatsRequest(OFPFlowStatsRequestBase):
    """
    Aggregate flow statistics request message

    The controller uses this message to query aggregate flow statictics.

    ================ ======================================================
    Attribute        Description
    ================ ======================================================
    flags            Zero or ``OFPMPF_REQ_MORE``
    table_id         ID of table to read
    out_port         Require matching entries to include this as an output
                     port
    out_group        Require matching entries to include this as an output
                     group
    cookie           Require matching entries to contain this cookie value
    cookie_mask      Mask used to restrict the cookie bits that must match
    match            Instance of ``OFPMatch``
    ================ ======================================================

    Example::

        def send_aggregate_stats_request(self, datapath):
            ofp = datapath.ofproto
            ofp_parser = datapath.ofproto_parser

            cookie = cookie_mask = 0
            match = ofp_parser.OFPMatch(in_port=1)
            req = ofp_parser.OFPAggregateStatsRequest(datapath, 0,
                                                      ofp.OFPTT_ALL,
                                                      ofp.OFPP_ANY,
                                                      ofp.OFPG_ANY,
                                                      cookie, cookie_mask,
                                                      match)
            datapath.send_msg(req)
    """
    def __init__(self, datapath, flags, table_id, out_port, out_group,
                 cookie, cookie_mask, match, type_=None):
        super(OFPAggregateStatsRequest, self).__init__(datapath,
                                                       flags,
                                                       table_id,
                                                       out_port,
                                                       out_group,
                                                       cookie,
                                                       cookie_mask,
                                                       match)


@OFPMultipartReply.register_stats_type(body_single_struct=True)
@_set_stats_type(ofproto_v1_3.OFPMP_AGGREGATE, OFPAggregateStats)
@_set_msg_type(ofproto_v1_3.OFPT_MULTIPART_REPLY)
class OFPAggregateStatsReply(OFPMultipartReply):
    """
    Aggregate flow statistics reply message

    The switch responds with this message to an aggregate flow statistics
    request.

    ================ ======================================================
    Attribute        Description
    ================ ======================================================
    body             Instance of ``OFPAggregateStats``
    ================ ======================================================

    Example::

        @set_ev_cls(ofp_event.EventOFPAggregateStatsReply, MAIN_DISPATCHER)
        def aggregate_stats_reply_handler(self, ev):
            body = ev.msg.body

            self.logger.debug('AggregateStats: packet_count=%d byte_count=%d '
                              'flow_count=%d',
                              body.packet_count, body.byte_count,
                              body.flow_count)
    """
    def __init__(self, datapath, type_=None, **kwargs):
        super(OFPAggregateStatsReply, self).__init__(datapath, **kwargs)


class OFPTableStats(ofproto_parser.namedtuple('OFPTableStats', (
        'table_id', 'active_count', 'lookup_count',
        'matched_count'))):
    @classmethod
    def parser(cls, buf, offset):
        tbl = struct.unpack_from(ofproto_v1_3.OFP_TABLE_STATS_PACK_STR,
                                 buf, offset)
        stats = cls(*tbl)
        stats.length = ofproto_v1_3.OFP_TABLE_STATS_SIZE
        return stats


@_set_stats_type(ofproto_v1_3.OFPMP_TABLE, OFPTableStats)
@_set_msg_type(ofproto_v1_3.OFPT_MULTIPART_REQUEST)
class OFPTableStatsRequest(OFPMultipartRequest):
    """
    Table statistics request message

    The controller uses this message to query flow table statictics.

    ================ ======================================================
    Attribute        Description
    ================ ======================================================
    flags            Zero or ``OFPMPF_REQ_MORE``
    ================ ======================================================

    Example::

        def send_table_stats_request(self, datapath):
            ofp = datapath.ofproto
            ofp_parser = datapath.ofproto_parser

            req = ofp_parser.OFPTableStatsRequest(datapath, 0)
            datapath.send_msg(req)
    """
    def __init__(self, datapath, flags, type_=None):
        super(OFPTableStatsRequest, self).__init__(datapath, flags)


@OFPMultipartReply.register_stats_type()
@_set_stats_type(ofproto_v1_3.OFPMP_TABLE, OFPTableStats)
@_set_msg_type(ofproto_v1_3.OFPT_MULTIPART_REPLY)
class OFPTableStatsReply(OFPMultipartReply):
    """
    Table statistics reply message

    The switch responds with this message to a table statistics request.

    ================ ======================================================
    Attribute        Description
    ================ ======================================================
    body             List of ``OFPTableStats`` instance
    ================ ======================================================

    Example::

        @set_ev_cls(ofp_event.EventOFPTableStatsReply, MAIN_DISPATCHER)
        def table_stats_reply_handler(self, ev):
            tables = []
            for stat in ev.msg.body:
                tables.append('table_id=%d active_count=%d lookup_count=%d '
                              ' matched_count=%d' %
                              (stat.table_id, stat.active_count,
                               stat.lookup_count, stat.matched_count))
             self.logger.debug('TableStats: %s', tables)
    """
    def __init__(self, datapath, type_=None, **kwargs):
        super(OFPTableStatsReply, self).__init__(datapath, **kwargs)


class OFPPortStats(ofproto_parser.namedtuple('OFPPortStats', (
        'port_no', 'rx_packets', 'tx_packets', 'rx_bytes', 'tx_bytes',
        'rx_dropped', 'tx_dropped', 'rx_errors', 'tx_errors',
        'rx_frame_err', 'rx_over_err', 'rx_crc_err', 'collisions',
        'duration_sec', 'duration_nsec'))):
    @classmethod
    def parser(cls, buf, offset):
        port = struct.unpack_from(ofproto_v1_3.OFP_PORT_STATS_PACK_STR,
                                  buf, offset)
        stats = cls(*port)
        stats.length = ofproto_v1_3.OFP_PORT_STATS_SIZE
        return stats


@_set_stats_type(ofproto_v1_3.OFPMP_PORT_STATS, OFPPortStats)
@_set_msg_type(ofproto_v1_3.OFPT_MULTIPART_REQUEST)
class OFPPortStatsRequest(OFPMultipartRequest):
    """
    Port statistics request message

    The controller uses this message to query information about ports
    statistics.

    ================ ======================================================
    Attribute        Description
    ================ ======================================================
    flags            Zero or ``OFPMPF_REQ_MORE``
    port_no          Port number to read (OFPP_ANY to all ports)
    ================ ======================================================

    Example::

        def send_port_stats_request(self, datapath):
            ofp = datapath.ofproto
            ofp_parser = datapath.ofproto_parser

            req = ofp_parser.OFPPortStatsRequest(datapath, 0, ofp.OFPP_ANY)
            datapath.send_msg(req)
    """
    def __init__(self, datapath, flags, port_no, type_=None):
        super(OFPPortStatsRequest, self).__init__(datapath, flags)
        self.port_no = port_no

    def _serialize_stats_body(self):
        msg_pack_into(ofproto_v1_3.OFP_PORT_STATS_REQUEST_PACK_STR,
                      self.buf,
                      ofproto_v1_3.OFP_MULTIPART_REQUEST_SIZE,
                      self.port_no)


@OFPMultipartReply.register_stats_type()
@_set_stats_type(ofproto_v1_3.OFPMP_PORT_STATS, OFPPortStats)
@_set_msg_type(ofproto_v1_3.OFPT_MULTIPART_REPLY)
class OFPPortStatsReply(OFPMultipartReply):
    """
    Port statistics reply message

    The switch responds with this message to a port statistics request.

    ================ ======================================================
    Attribute        Description
    ================ ======================================================
    body             List of ``OFPPortStats`` instance
    ================ ======================================================

    Example::

        @set_ev_cls(ofp_event.EventOFPPortStatsReply, MAIN_DISPATCHER)
        def port_stats_reply_handler(self, ev):
            ports = []
            for stat in ev.msg.body:
                ports.append('port_no=%d '
                             'rx_packets=%d tx_packets=%d '
                             'rx_bytes=%d tx_bytes=%d '
                             'rx_dropped=%d tx_dropped=%d '
                             'rx_errors=%d tx_errors=%d '
                             'rx_frame_err=%d rx_over_err=%d rx_crc_err=%d '
                             'collisions=%d duration_sec=%d duration_nsec=%d' %
                             (stat.port_no,
                              stat.rx_packets, stat.tx_packets,
                              stat.rx_bytes, stat.tx_bytes,
                              stat.rx_dropped, stat.tx_dropped,
                              stat.rx_errors, stat.tx_errors,
                              stat.rx_frame_err, stat.rx_over_err,
                              stat.rx_crc_err, stat.collisions,
                              stat.duration_sec, stat.duration_nsec))
        self.logger.debug('PortStats: %s', ports)
    """
    def __init__(self, datapath, type_=None, **kwargs):
        super(OFPPortStatsReply, self).__init__(datapath, **kwargs)


class OFPQueueStats(ofproto_parser.namedtuple('OFPQueueStats', (
        'port_no', 'queue_id', 'tx_bytes', 'tx_packets', 'tx_errors',
        'duration_sec', 'duration_nsec'))):
    @classmethod
    def parser(cls, buf, offset):
        queue = struct.unpack_from(ofproto_v1_3.OFP_QUEUE_STATS_PACK_STR,
                                   buf, offset)
        stats = cls(*queue)
        stats.length = ofproto_v1_3.OFP_QUEUE_STATS_SIZE
        return stats


@_set_stats_type(ofproto_v1_3.OFPMP_QUEUE, OFPQueueStats)
@_set_msg_type(ofproto_v1_3.OFPT_MULTIPART_REQUEST)
class OFPQueueStatsRequest(OFPMultipartRequest):
    """
    Queue statistics request message

    The controller uses this message to query queue statictics.

    ================ ======================================================
    Attribute        Description
    ================ ======================================================
    flags            Zero or ``OFPMPF_REQ_MORE``
    port_no          Port number to read
    queue_id         ID of queue to read
    ================ ======================================================

    Example::

        def send_queue_stats_request(self, datapath):
            ofp = datapath.ofproto
            ofp_parser = datapath.ofproto_parser

            req = ofp_parser.OFPQueueStatsRequest(datapath, 0, ofp.OFPP_ANY,
                                                  ofp.OFPQ_ALL)
            datapath.send_msg(req)
    """
    def __init__(self, datapath, flags, port_no, queue_id, type_=None):
        super(OFPQueueStatsRequest, self).__init__(datapath, flags)
        self.port_no = port_no
        self.queue_id = queue_id

    def _serialize_stats_body(self):
        msg_pack_into(ofproto_v1_3.OFP_QUEUE_STATS_REQUEST_PACK_STR,
                      self.buf,
                      ofproto_v1_3.OFP_MULTIPART_REQUEST_SIZE,
                      self.port_no, self.queue_id)


@OFPMultipartReply.register_stats_type()
@_set_stats_type(ofproto_v1_3.OFPMP_QUEUE, OFPQueueStats)
@_set_msg_type(ofproto_v1_3.OFPT_MULTIPART_REPLY)
class OFPQueueStatsReply(OFPMultipartReply):
    """
    Queue statistics reply message

    The switch responds with this message to an aggregate flow statistics
    request.

    ================ ======================================================
    Attribute        Description
    ================ ======================================================
    body             List of ``OFPQueueStats`` instance
    ================ ======================================================

    Example::

        @set_ev_cls(ofp_event.EventOFPQueueStatsReply, MAIN_DISPATCHER)
        def queue_stats_reply_handler(self, ev):
            queues = []
            for stat in ev.msg.body:
                queues.append('port_no=%d queue_id=%d '
                              'tx_bytes=%d tx_packets=%d tx_errors=%d '
                              'duration_sec=%d duration_nsec=%d' %
                              (stat.port_no, stat.queue_id,
                               stat.tx_bytes, stat.tx_packets, stat.tx_errors,
                               stat.duration_sec, stat.duration_nsec))
            self.logger.debug('QueueStats: %s', queues)
    """
    def __init__(self, datapath, type_=None, **kwargs):
        super(OFPQueueStatsReply, self).__init__(datapath, **kwargs)


class OFPBucketCounter(StringifyMixin):
    def __init__(self, packet_count, byte_count):
        super(OFPBucketCounter, self).__init__()
        self.packet_count = packet_count
        self.byte_count = byte_count

    @classmethod
    def parser(cls, buf, offset):
        packet_count, byte_count = struct.unpack_from(
            ofproto_v1_3.OFP_BUCKET_COUNTER_PACK_STR, buf, offset)
        return cls(packet_count, byte_count)


class OFPGroupStats(StringifyMixin):
    def __init__(self, length=None, group_id=None, ref_count=None,
                 packet_count=None, byte_count=None, duration_sec=None,
                 duration_nsec=None, bucket_stats=None):
        super(OFPGroupStats, self).__init__()
        self.length = length
        self.group_id = group_id
        self.ref_count = ref_count
        self.packet_count = packet_count
        self.byte_count = byte_count
        self.duration_sec = duration_sec
        self.duration_nsec = duration_nsec
        self.bucket_stats = bucket_stats

    @classmethod
    def parser(cls, buf, offset):
        group = struct.unpack_from(ofproto_v1_3.OFP_GROUP_STATS_PACK_STR,
                                   buf, offset)
        group_stats = cls(*group)

        group_stats.bucket_stats = []
        total_len = group_stats.length + offset
        offset += ofproto_v1_3.OFP_GROUP_STATS_SIZE
        while total_len > offset:
            b = OFPBucketCounter.parser(buf, offset)
            group_stats.bucket_stats.append(b)
            offset += ofproto_v1_3.OFP_BUCKET_COUNTER_SIZE

        return group_stats


@_set_stats_type(ofproto_v1_3.OFPMP_GROUP, OFPGroupStats)
@_set_msg_type(ofproto_v1_3.OFPT_MULTIPART_REQUEST)
class OFPGroupStatsRequest(OFPMultipartRequest):
    """
    Group statistics request message

    The controller uses this message to query statistics of one or more
    groups.

    ================ ======================================================
    Attribute        Description
    ================ ======================================================
    flags            Zero or ``OFPMPF_REQ_MORE``
    group_id         ID of group to read (OFPG_ALL to all groups)
    ================ ======================================================

    Example::

        def send_group_stats_request(self, datapath):
            ofp = datapath.ofproto
            ofp_parser = datapath.ofproto_parser

            req = ofp_parser.OFPGroupStatsRequest(datapath, 0, ofp.OFPG_ALL)
            datapath.send_msg(req)
    """
    def __init__(self, datapath, flags, group_id, type_=None):
        super(OFPGroupStatsRequest, self).__init__(datapath, flags)
        self.group_id = group_id

    def _serialize_stats_body(self):
        msg_pack_into(ofproto_v1_3.OFP_GROUP_STATS_REQUEST_PACK_STR,
                      self.buf,
                      ofproto_v1_3.OFP_MULTIPART_REQUEST_SIZE,
                      self.group_id)


@OFPMultipartReply.register_stats_type()
@_set_stats_type(ofproto_v1_3.OFPMP_GROUP, OFPGroupStats)
@_set_msg_type(ofproto_v1_3.OFPT_MULTIPART_REPLY)
class OFPGroupStatsReply(OFPMultipartReply):
    """
    Group statistics reply message

    The switch responds with this message to a group statistics request.

    ================ ======================================================
    Attribute        Description
    ================ ======================================================
    body             List of ``OFPGroupStats`` instance
    ================ ======================================================

    Example::

        @set_ev_cls(ofp_event.EventOFPGroupStatsReply, MAIN_DISPATCHER)
        def group_stats_reply_handler(self, ev):
            groups = []
            for stat in ev.msg.body:
                groups.append('length=%d group_id=%d '
                              'ref_count=%d packet_count=%d byte_count=%d '
                              'duration_sec=%d duration_nsec=%d' %
                              (stat.length, stat.group_id,
                               stat.ref_count, stat.packet_count,
                               stat.byte_count, stat.duration_sec,
                               stat.duration_nsec))
            self.logger.debug('GroupStats: %s', groups)
    """
    def __init__(self, datapath, type_=None, **kwargs):
        super(OFPGroupStatsReply, self).__init__(datapath, **kwargs)


class OFPGroupDescStats(StringifyMixin):
    def __init__(self, type_=None, group_id=None, buckets=None, length=None):
        super(OFPGroupDescStats, self).__init__()
        self.type = type_
        self.group_id = group_id
        self.buckets = buckets

    @classmethod
    def parser(cls, buf, offset):
        stats = cls()

        (stats.length, stats.type, stats.group_id) = struct.unpack_from(
            ofproto_v1_3.OFP_GROUP_DESC_STATS_PACK_STR, buf, offset)
        offset += ofproto_v1_3.OFP_GROUP_DESC_STATS_SIZE

        stats.buckets = []
        length = ofproto_v1_3.OFP_GROUP_DESC_STATS_SIZE
        while length < stats.length:
            bucket = OFPBucket.parser(buf, offset)
            stats.buckets.append(bucket)

            offset += bucket.len
            length += bucket.len

        return stats


@_set_stats_type(ofproto_v1_3.OFPMP_GROUP_DESC, OFPGroupDescStats)
@_set_msg_type(ofproto_v1_3.OFPT_MULTIPART_REQUEST)
class OFPGroupDescStatsRequest(OFPMultipartRequest):
    """
    Group description request message

    The controller uses this message to list the set of groups on a switch.

    ================ ======================================================
    Attribute        Description
    ================ ======================================================
    flags            Zero or ``OFPMPF_REQ_MORE``
    ================ ======================================================

    Example::

        def send_group_desc_stats_request(self, datapath):
            ofp = datapath.ofproto
            ofp_parser = datapath.ofproto_parser

            req = ofp_parser.OFPGroupDescStatsRequest(datapath, 0)
            datapath.send_msg(req)
    """
    def __init__(self, datapath, flags, type_=None):
        super(OFPGroupDescStatsRequest, self).__init__(datapath, flags)


@OFPMultipartReply.register_stats_type()
@_set_stats_type(ofproto_v1_3.OFPMP_GROUP_DESC, OFPGroupDescStats)
@_set_msg_type(ofproto_v1_3.OFPT_MULTIPART_REPLY)
class OFPGroupDescStatsReply(OFPMultipartReply):
    """
    Group description reply message

    The switch responds with this message to a group description request.

    ================ ======================================================
    Attribute        Description
    ================ ======================================================
    body             List of ``OFPGroupDescStats`` instance
    ================ ======================================================

    Example::

        @set_ev_cls(ofp_event.EventOFPGroupDescStatsReply, MAIN_DISPATCHER)
        def group_desc_stats_reply_handler(self, ev):
            descs = []
            for stat in ev.msg.body:
                descs.append('length=%d type=%d group_id=%d '
                             'buckets=%s' %
                             (stat.length, stat.type, stat.group_id,
                              stat.bucket))
            self.logger.debug('GroupDescStats: %s', groups)
    """
    def __init__(self, datapath, type_=None, **kwargs):
        super(OFPGroupDescStatsReply, self).__init__(datapath, **kwargs)


class OFPGroupFeaturesStats(ofproto_parser.namedtuple('OFPGroupFeaturesStats',
                            ('types', 'capabilities', 'max_groups',
                             'actions'))):
    @classmethod
    def parser(cls, buf, offset):
        group_features = struct.unpack_from(
            ofproto_v1_3.OFP_GROUP_FEATURES_PACK_STR, buf, offset)
        types = group_features[0]
        capabilities = group_features[1]
        max_groups = list(group_features[2:6])
        actions = list(group_features[6:10])
        stats = cls(types, capabilities, max_groups, actions)
        stats.length = ofproto_v1_3.OFP_GROUP_FEATURES_SIZE
        return stats


@_set_stats_type(ofproto_v1_3.OFPMP_GROUP_FEATURES, OFPGroupFeaturesStats)
@_set_msg_type(ofproto_v1_3.OFPT_MULTIPART_REQUEST)
class OFPGroupFeaturesStatsRequest(OFPMultipartRequest):
    """
    Group features request message

    The controller uses this message to list the capabilities of groups on
    a switch.

    ================ ======================================================
    Attribute        Description
    ================ ======================================================
    flags            Zero or ``OFPMPF_REQ_MORE``
    ================ ======================================================

    Example::

        def send_group_features_stats_request(self, datapath):
            ofp = datapath.ofproto
            ofp_parser = datapath.ofproto_parser

            req = ofp_parser.OFPGroupFeaturesStatsRequest(datapath, 0)
            datapath.send_msg(req)
    """
    def __init__(self, datapath, flags, type_=None):
        super(OFPGroupFeaturesStatsRequest, self).__init__(datapath, flags)


@OFPMultipartReply.register_stats_type(body_single_struct=True)
@_set_stats_type(ofproto_v1_3.OFPMP_GROUP_FEATURES, OFPGroupFeaturesStats)
@_set_msg_type(ofproto_v1_3.OFPT_MULTIPART_REPLY)
class OFPGroupFeaturesStatsReply(OFPMultipartReply):
    """
    Group features reply message

    The switch responds with this message to a group features request.

    ================ ======================================================
    Attribute        Description
    ================ ======================================================
    body             Instance of ``OFPGroupFeaturesStats``
    ================ ======================================================

    Example::

        @set_ev_cls(ofp_event.EventOFPGroupFeaturesStatsReply, MAIN_DISPATCHER)
        def group_features_stats_reply_handler(self, ev):
            body = ev.msg.body

            self.logger.debug('GroupFeaturesStats: types=%d '
                              'capabilities=0x%08x max_groups=%s '
                              'actions=%s',
                              body.types, body.capabilities,
                              body.max_groups, body.actions)
    """
    def __init__(self, datapath, type_=None, **kwargs):
        super(OFPGroupFeaturesStatsReply, self).__init__(datapath, **kwargs)


class OFPMeterBandStats(StringifyMixin):
    def __init__(self, packet_band_count, byte_band_count):
        super(OFPMeterBandStats, self).__init__()
        self.packet_band_count = packet_band_count
        self.byte_band_count = byte_band_count

    @classmethod
    def parser(cls, buf, offset):
        band_stats = struct.unpack_from(
            ofproto_v1_3.OFP_METER_BAND_STATS_PACK_STR, buf, offset)
        return cls(*band_stats)


class OFPMeterStats(StringifyMixin):
    def __init__(self, meter_id=None, flow_count=None, packet_in_count=None,
                 byte_in_count=None, duration_sec=None, duration_nsec=None,
                 band_stats=None, len_=None):
        super(OFPMeterStats, self).__init__()
        self.meter_id = meter_id
        self.len = 0
        self.flow_count = flow_count
        self.packet_in_count = packet_in_count
        self.byte_in_count = byte_in_count
        self.duration_sec = duration_sec
        self.duration_nsec = duration_nsec
        self.band_stats = band_stats

    @classmethod
    def parser(cls, buf, offset):
        meter_stats = cls()

        (meter_stats.meter_id, meter_stats.len,
         meter_stats.flow_count, meter_stats.packet_in_count,
         meter_stats.byte_in_count, meter_stats.duration_sec,
         meter_stats.duration_nsec) = struct.unpack_from(
            ofproto_v1_3.OFP_METER_STATS_PACK_STR, buf, offset)
        offset += ofproto_v1_3.OFP_METER_STATS_SIZE

        meter_stats.band_stats = []
        length = ofproto_v1_3.OFP_METER_STATS_SIZE
        while length < meter_stats.len:
            band_stats = OFPMeterBandStats.parser(buf, offset)
            meter_stats.band_stats.append(band_stats)
            offset += ofproto_v1_3.OFP_METER_BAND_STATS_SIZE
            length += ofproto_v1_3.OFP_METER_BAND_STATS_SIZE

        return meter_stats


@_set_stats_type(ofproto_v1_3.OFPMP_METER, OFPMeterStats)
@_set_msg_type(ofproto_v1_3.OFPT_MULTIPART_REQUEST)
class OFPMeterStatsRequest(OFPMultipartRequest):
    """
    Meter statistics request message

    The controller uses this message to query statistics for one or more
    meters.

    ================ ======================================================
    Attribute        Description
    ================ ======================================================
    flags            Zero or ``OFPMPF_REQ_MORE``
    meter_id         ID of meter to read (OFPM_ALL to all meters)
    ================ ======================================================

    Example::

        def send_meter_stats_request(self, datapath):
            ofp = datapath.ofproto
            ofp_parser = datapath.ofproto_parser

            req = ofp_parser.OFPMeterStatsRequest(datapath, 0, ofp.OFPM_ALL)
            datapath.send_msg(req)
    """
    def __init__(self, datapath, flags, meter_id, type_=None):
        super(OFPMeterStatsRequest, self).__init__(datapath, flags)
        self.meter_id = meter_id

    def _serialize_stats_body(self):
        msg_pack_into(ofproto_v1_3.OFP_METER_MULTIPART_REQUEST_PACK_STR,
                      self.buf,
                      ofproto_v1_3.OFP_MULTIPART_REQUEST_SIZE,
                      self.meter_id)


@OFPMultipartReply.register_stats_type()
@_set_stats_type(ofproto_v1_3.OFPMP_METER, OFPMeterStats)
@_set_msg_type(ofproto_v1_3.OFPT_MULTIPART_REPLY)
class OFPMeterStatsReply(OFPMultipartReply):
    """
    Meter statistics reply message

    The switch responds with this message to a meter statistics request.

    ================ ======================================================
    Attribute        Description
    ================ ======================================================
    body             List of ``OFPMeterStats`` instance
    ================ ======================================================

    Example::

        @set_ev_cls(ofp_event.EventOFPMeterStatsReply, MAIN_DISPATCHER)
        def meter_stats_reply_handler(self, ev):
            meters = []
            for stat in ev.msg.body:
                meters.append('meter_id=0x%08x len=%d flow_count=%d '
                              'packet_in_count=%d byte_in_count=%d '
                              'duration_sec=%d duration_nsec=%d '
                              'band_stats=%s' %
                              (stat.meter_id, stat.len, stat.flow_count,
                               stat.packet_in_count, stat.byte_in_count,
                               stat.duration_sec, stat.duration_nsec,
                               stat.band_stats))
            self.logger.debug('MeterStats: %s', meters)
    """
    def __init__(self, datapath, type_=None, **kwargs):
        super(OFPMeterStatsReply, self).__init__(datapath, **kwargs)


class OFPMeterBand(StringifyMixin):
    def __init__(self, type_, len_):
        super(OFPMeterBand, self).__init__()
        self.type = type_
        self.len = len_


class OFPMeterBandHeader(OFPMeterBand):
    _METER_BAND = {}

    @staticmethod
    def register_meter_band_type(type_, len_):
        def _register_meter_band_type(cls):
            OFPMeterBandHeader._METER_BAND[type_] = cls
            cls.cls_meter_band_type = type_
            cls.cls_meter_band_len = len_
            return cls
        return _register_meter_band_type

    def __init__(self):
        cls = self.__class__
        super(OFPMeterBandHeader, self).__init__(cls.cls_meter_band_type,
                                                 cls.cls_meter_band_len)

    @classmethod
    def parser(cls, buf, offset):
        type_, len_, _rate, _burst_size = struct.unpack_from(
            ofproto_v1_3.OFP_METER_BAND_HEADER_PACK_STR, buf, offset)
        cls_ = cls._METER_BAND[type_]
        assert cls_.cls_meter_band_len == len_
        return cls_.parser(buf, offset)


@OFPMeterBandHeader.register_meter_band_type(
    ofproto_v1_3.OFPMBT_DROP, ofproto_v1_3.OFP_METER_BAND_DROP_SIZE)
class OFPMeterBandDrop(OFPMeterBandHeader):
    def __init__(self, rate, burst_size, type_=None, len_=None):
        super(OFPMeterBandDrop, self).__init__()
        self.rate = rate
        self.burst_size = burst_size

    def serialize(self, buf, offset):
        msg_pack_into(ofproto_v1_3.OFP_METER_BAND_DROP_PACK_STR, buf, offset,
                      self.type, self.len, self.rate, self.burst_size)

    @classmethod
    def parser(cls, buf, offset):
        type_, len_, rate, burst_size = struct.unpack_from(
            ofproto_v1_3.OFP_METER_BAND_DROP_PACK_STR, buf, offset)
        assert cls.cls_meter_band_type == type_
        assert cls.cls_meter_band_len == len_
        return cls(rate, burst_size)


@OFPMeterBandHeader.register_meter_band_type(
    ofproto_v1_3.OFPMBT_DSCP_REMARK,
    ofproto_v1_3.OFP_METER_BAND_DSCP_REMARK_SIZE)
class OFPMeterBandDscpRemark(OFPMeterBandHeader):
    def __init__(self, rate, burst_size, prec_level, type_=None, len_=None):
        super(OFPMeterBandDscpRemark, self).__init__()
        self.rate = rate
        self.burst_size = burst_size
        self.prec_level = prec_level

    def serialize(self, buf, offset):
        msg_pack_into(ofproto_v1_3.OFP_METER_BAND_DSCP_REMARK_PACK_STR, buf,
                      offset, self.type, self.len, self.rate,
                      self.burst_size, self.prec_level)

    @classmethod
    def parser(cls, buf, offset):
        type_, len_, rate, burst_size, prec_level = struct.unpack_from(
            ofproto_v1_3.OFP_METER_BAND_DSCP_REMARK_PACK_STR, buf, offset)
        assert cls.cls_meter_band_type == type_
        assert cls.cls_meter_band_len == len_
        return cls(rate, burst_size, prec_level)


@OFPMeterBandHeader.register_meter_band_type(
    ofproto_v1_3.OFPMBT_EXPERIMENTER,
    ofproto_v1_3.OFP_METER_BAND_EXPERIMENTER_SIZE)
class OFPMeterBandExperimenter(OFPMeterBandHeader):
    def __init__(self, rate, burst_size, experimenter, type_=None, len_=None):
        super(OFPMeterBandExperimenter, self).__init__()
        self.rate = rate
        self.burst_size = burst_size
        self.experimenter = experimenter

    def serialize(self, buf, offset):
        msg_pack_into(ofproto_v1_3.OFP_METER_BAND_EXPERIMENTER_PACK_STR, buf,
                      offset, self.type, self.len, self.rate,
                      self.burst_size, self.experimenter)

    @classmethod
    def parser(cls, buf, offset):
        type_, len_, rate, burst_size, experimenter = struct.unpack_from(
            ofproto_v1_3.OFP_METER_BAND_EXPERIMENTER_PACK_STR, buf, offset)
        assert cls.cls_meter_band_type == type_
        assert cls.cls_meter_band_len == len_
        return cls(rate, burst_size, experimenter)


class OFPMeterConfigStats(StringifyMixin):
    def __init__(self, flags=None, meter_id=None, bands=None, length=None):
        super(OFPMeterConfigStats, self).__init__()
        self.length = None
        self.flags = flags
        self.meter_id = meter_id
        self.bands = bands

    @classmethod
    def parser(cls, buf, offset):
        meter_config = cls()

        (meter_config.length, meter_config.flags,
         meter_config.meter_id) = struct.unpack_from(
            ofproto_v1_3.OFP_METER_CONFIG_PACK_STR, buf, offset)
        offset += ofproto_v1_3.OFP_METER_CONFIG_SIZE

        meter_config.bands = []
        length = ofproto_v1_3.OFP_METER_CONFIG_SIZE
        while length < meter_config.length:
            band = OFPMeterBandHeader.parser(buf, offset)
            meter_config.bands.append(band)
            offset += band.len
            length += band.len

        return meter_config


@_set_stats_type(ofproto_v1_3.OFPMP_METER_CONFIG, OFPMeterConfigStats)
@_set_msg_type(ofproto_v1_3.OFPT_MULTIPART_REQUEST)
class OFPMeterConfigStatsRequest(OFPMultipartRequest):
    """
    Meter configuration statistics request message

    The controller uses this message to query configuration for one or more
    meters.

    ================ ======================================================
    Attribute        Description
    ================ ======================================================
    flags            Zero or ``OFPMPF_REQ_MORE``
    meter_id         ID of meter to read (OFPM_ALL to all meters)
    ================ ======================================================

    Example::

        def send_meter_config_stats_request(self, datapath):
            ofp = datapath.ofproto
            ofp_parser = datapath.ofproto_parser

            req = ofp_parser.OFPMeterConfigStatsRequest(datapath, 0,
                                                        ofp.OFPM_ALL)
            datapath.send_msg(req)
    """
    def __init__(self, datapath, flags, meter_id, type_=None):
        super(OFPMeterConfigStatsRequest, self).__init__(datapath, flags)
        self.meter_id = meter_id

    def _serialize_stats_body(self):
        msg_pack_into(ofproto_v1_3.OFP_METER_MULTIPART_REQUEST_PACK_STR,
                      self.buf,
                      ofproto_v1_3.OFP_MULTIPART_REQUEST_SIZE,
                      self.meter_id)


@OFPMultipartReply.register_stats_type()
@_set_stats_type(ofproto_v1_3.OFPMP_METER_CONFIG, OFPMeterConfigStats)
@_set_msg_type(ofproto_v1_3.OFPT_MULTIPART_REPLY)
class OFPMeterConfigStatsReply(OFPMultipartReply):
    """
    Meter configuration statistics reply message

    The switch responds with this message to a meter configuration
    statistics request.

    ================ ======================================================
    Attribute        Description
    ================ ======================================================
    body             List of ``OFPMeterConfigStats`` instance
    ================ ======================================================

    Example::

        @set_ev_cls(ofp_event.EventOFPMeterConfigStatsReply, MAIN_DISPATCHER)
        def meter_config_stats_reply_handler(self, ev):
            configs = []
            for stat in ev.msg.body:
                configs.append('length=%d flags=0x%04x meter_id=0x%08x '
                               'bands=%s' %
                               (stat.length, stat.flags, stat.meter_id,
                                stat.bands))
            self.logger.debug('MeterConfigStats: %s', configs)
    """
    def __init__(self, datapath, type_=None, **kwargs):
        super(OFPMeterConfigStatsReply, self).__init__(datapath, **kwargs)


class OFPMeterFeaturesStats(ofproto_parser.namedtuple('OFPMeterFeaturesStats',
                            ('max_meter', 'band_types', 'capabilities',
                             'max_band', 'max_color'))):
    @classmethod
    def parser(cls, buf, offset):
        meter_features = struct.unpack_from(
            ofproto_v1_3.OFP_METER_FEATURES_PACK_STR, buf, offset)
        stats = cls(*meter_features)
        stats.length = ofproto_v1_3.OFP_METER_FEATURES_SIZE
        return stats


@_set_stats_type(ofproto_v1_3.OFPMP_METER_FEATURES, OFPMeterFeaturesStats)
@_set_msg_type(ofproto_v1_3.OFPT_MULTIPART_REQUEST)
class OFPMeterFeaturesStatsRequest(OFPMultipartRequest):
    """
    Meter features statistics request message

    The controller uses this message to query the set of features of the
    metering subsystem.

    ================ ======================================================
    Attribute        Description
    ================ ======================================================
    flags            Zero or ``OFPMPF_REQ_MORE``
    ================ ======================================================

    Example::

        def send_meter_features_stats_request(self, datapath):
            ofp_parser = datapath.ofproto_parser

            req = ofp_parser.OFPMeterFeaturesStatsRequest(datapath, 0)
            datapath.send_msg(req)
    """
    def __init__(self, datapath, flags, type_=None):
        super(OFPMeterFeaturesStatsRequest, self).__init__(datapath, flags)


@OFPMultipartReply.register_stats_type()
@_set_stats_type(ofproto_v1_3.OFPMP_METER_FEATURES, OFPMeterFeaturesStats)
@_set_msg_type(ofproto_v1_3.OFPT_MULTIPART_REPLY)
class OFPMeterFeaturesStatsReply(OFPMultipartReply):
    """
    Meter features statistics reply message

    The switch responds with this message to a meter features statistics
    request.

    ================ ======================================================
    Attribute        Description
    ================ ======================================================
    body             List of ``OFPMeterFeaturesStats`` instance
    ================ ======================================================

    Example::

        @set_ev_cls(ofp_event.EventOFPMeterFeaturesStatsReply, MAIN_DISPATCHER)
        def meter_features_stats_reply_handler(self, ev):
            features = []
            for stat in ev.msg.body:
                features.append('max_meter=%d band_types=0x%08x '
                                'capabilities=0x%08x max_band=%d '
                                'max_color=%d' %
                                (stat.max_meter, stat.band_types,
                                 stat.capabilities, stat.max_band,
                                 stat.max_color))
            self.logger.debug('MeterFeaturesStats: %s', configs)
    """
    def __init__(self, datapath, type_=None, **kwargs):
        super(OFPMeterFeaturesStatsReply, self).__init__(datapath, **kwargs)


class OFPTableFeaturesStats(StringifyMixin):

    _TYPE = {
        'utf-8': [
            # OF spec is unclear about the encoding of name.
            # we assumes UTF-8.
            'name',
        ]
    }

    def __init__(self, table_id=None, name=None, metadata_match=None,
                 metadata_write=None, config=None, max_entries=None,
                 properties=None, length=None):
        super(OFPTableFeaturesStats, self).__init__()
        self.length = None
        self.table_id = table_id
        self.name = name
        self.metadata_match = metadata_match
        self.metadata_write = metadata_write
        self.config = config
        self.max_entries = max_entries
        self.properties = properties

    @classmethod
    def parser(cls, buf, offset):
        table_features = cls()
        (table_features.length, table_features.table_id,
         name, table_features.metadata_match,
         table_features.metadata_write, table_features.config,
         table_features.max_entries
         ) = struct.unpack_from(ofproto_v1_3.OFP_TABLE_FEATURES_PACK_STR,
                                buf, offset)
        table_features.name = name.rstrip('\0')

        props = []
        rest = buf[offset + ofproto_v1_3.OFP_TABLE_FEATURES_SIZE:
                   offset + table_features.length]
        while rest:
            p, rest = OFPTableFeatureProp.parse(rest)
            props.append(p)
        table_features.properties = props

        return table_features

    def serialize(self):
        # fixup
        bin_props = bytearray()
        for p in self.properties:
            bin_props += p.serialize()
        self.length = ofproto_v1_3.OFP_TABLE_FEATURES_SIZE + len(bin_props)

        buf = bytearray()
        msg_pack_into(ofproto_v1_3.OFP_TABLE_FEATURES_PACK_STR, buf, 0,
                      self.length, self.table_id, self.name,
                      self.metadata_match, self.metadata_write,
                      self.config, self.max_entries)
        return buf + bin_props


class OFPTableFeatureProp(StringifyMixin):
    _PACK_STR = '!HH'  # type, length
    _TYPES = {}  # OFPTFPT_ -> class

    def __init__(self, type_, length=None):
        self.type = type_
        self.length = length

    @classmethod
    def register_type(cls, type_):
        def _register_type(subcls):
            cls._TYPES[type_] = subcls
            return subcls
        return _register_type

    @classmethod
    def parse(cls, buf):
        (type_, length,) = struct.unpack_from(cls._PACK_STR, buffer(buf), 0)
        bin_prop = buf[struct.calcsize(cls._PACK_STR):length]
        rest = buf[utils.round_up(length, 8):]
        try:
            subcls = cls._TYPES[type_]
        except KeyError:
            subcls = OFPTableFeaturePropUnknown
        kwargs = subcls._parse_prop(bin_prop)
        kwargs['type_'] = type_
        kwargs['length'] = length
        return subcls(**kwargs), rest

    def serialize(self):
        # fixup
        bin_prop = self._serialize_prop()
        self.length = struct.calcsize(self._PACK_STR) + len(bin_prop)

        buf = bytearray()
        msg_pack_into(self._PACK_STR, buf, 0, self.type, self.length)
        pad_len = utils.round_up(self.length, 8) - self.length
        return buf + bin_prop + pad_len * '\0'


class OFPTableFeaturePropUnknown(OFPTableFeatureProp):
    def __init__(self, type_, length=None, data=None):
        super(OFPTableFeaturePropUnknown, self).__init__(type_, length)
        self.data = data

    @classmethod
    def _parse_prop(cls, buf):
        return {'data': buf}

    def _serialize_prop(self):
        return self.data


# Implementation note: While OpenFlow 1.3.2 shares the same ofp_instruction
# for flow_mod and table_features, we have separate classes.  We named this
# class to match with OpenFlow 1.4's name.  (ofp_instruction_id)
class OFPInstructionId(StringifyMixin):
    _PACK_STR = '!HH'  # type, len

    def __init__(self, type_, len_=None):
        self.type = type_
        self.len = len_
        # XXX experimenter

    @classmethod
    def parse(cls, buf):
        (type_, len_,) = struct.unpack_from(cls._PACK_STR, buffer(buf), 0)
        rest = buf[len_:]
        return cls(type_=type_, len_=len_), rest

    def serialize(self):
        # fixup
        self.len = struct.calcsize(self._PACK_STR)

        buf = bytearray()
        msg_pack_into(self._PACK_STR, buf, 0, self.type, self.len)
        return buf


@OFPTableFeatureProp.register_type(ofproto_v1_3.OFPTFPT_INSTRUCTIONS)
@OFPTableFeatureProp.register_type(ofproto_v1_3.OFPTFPT_INSTRUCTIONS_MISS)
class OFPTableFeaturePropInstructions(OFPTableFeatureProp):
    def __init__(self, type_, instruction_ids=[], length=None):
        super(OFPTableFeaturePropInstructions, self).__init__(type_, length)
        self.instruction_ids = instruction_ids

    @classmethod
    def _parse_prop(cls, buf):
        rest = buf
        ids = []
        while rest:
            i, rest = OFPInstructionId.parse(rest)
            ids.append(i)
        return {
            'instruction_ids': ids,
        }

    def _serialize_prop(self):
        bin_ids = bytearray()
        for i in self.instruction_ids:
            bin_ids += i.serialize()
        return bin_ids


@OFPTableFeatureProp.register_type(ofproto_v1_3.OFPTFPT_NEXT_TABLES)
@OFPTableFeatureProp.register_type(ofproto_v1_3.OFPTFPT_NEXT_TABLES_MISS)
class OFPTableFeaturePropNextTables(OFPTableFeatureProp):
    _TABLE_ID_PACK_STR = '!B'

    def __init__(self, type_, table_ids=[], length=None):
        super(OFPTableFeaturePropNextTables, self).__init__(type_, length)
        self.table_ids = table_ids

    @classmethod
    def _parse_prop(cls, buf):
        rest = buf
        ids = []
        while rest:
            (i,) = struct.unpack_from(cls._TABLE_ID_PACK_STR, buffer(rest), 0)
            rest = rest[struct.calcsize(cls._TABLE_ID_PACK_STR):]
            ids.append(i)
        return {
            'table_ids': ids,
        }

    def _serialize_prop(self):
        bin_ids = bytearray()
        for i in self.table_ids:
            bin_id = bytearray()
            msg_pack_into(self._TABLE_ID_PACK_STR, bin_id, 0, i)
            bin_ids += bin_id
        return bin_ids


# Implementation note: While OpenFlow 1.3.2 shares the same ofp_action_header
# for flow_mod and table_features, we have separate classes.  We named this
# class to match with OpenFlow 1.4's name.  (ofp_action_id)
class OFPActionId(StringifyMixin):
    # XXX
    # ofp_action_header should have trailing pad bytes.
    # however, i guess it's a specification bug as:
    #  - the spec explicitly says non-experimenter actions are 4 bytes
    #  - linc/of_protocol doesn't use them
    #  - OpenFlow 1.4 changed to use a separate structure
    _PACK_STR = '!HH'  # type, len

    def __init__(self, type_, len_=None):
        self.type = type_
        self.len = len_
        # XXX experimenter

    @classmethod
    def parse(cls, buf):
        (type_, len_,) = struct.unpack_from(cls._PACK_STR, buffer(buf), 0)
        rest = buf[len_:]
        return cls(type_=type_, len_=len_), rest

    def serialize(self):
        # fixup
        self.len = struct.calcsize(self._PACK_STR)

        buf = bytearray()
        msg_pack_into(self._PACK_STR, buf, 0, self.type, self.len)
        return buf


@OFPTableFeatureProp.register_type(ofproto_v1_3.OFPTFPT_WRITE_ACTIONS)
@OFPTableFeatureProp.register_type(ofproto_v1_3.OFPTFPT_WRITE_ACTIONS_MISS)
@OFPTableFeatureProp.register_type(ofproto_v1_3.OFPTFPT_APPLY_ACTIONS)
@OFPTableFeatureProp.register_type(ofproto_v1_3.OFPTFPT_APPLY_ACTIONS_MISS)
class OFPTableFeaturePropActions(OFPTableFeatureProp):
    def __init__(self, type_, action_ids=[], length=None):
        super(OFPTableFeaturePropActions, self).__init__(type_, length)
        self.action_ids = action_ids

    @classmethod
    def _parse_prop(cls, buf):
        rest = buf
        ids = []
        while rest:
            i, rest = OFPActionId.parse(rest)
            ids.append(i)
        return {
            'action_ids': ids,
        }

    def _serialize_prop(self):
        bin_ids = bytearray()
        for i in self.action_ids:
            bin_ids += i.serialize()
        return bin_ids


# Implementation note: OFPOxmId is specific to this implementation.
# It does not have a corresponding structure in the specification.
# (the specification uses plain uint32_t for them.)
#
# i have taken a look at some of software switch implementations
# but they all look broken or incomplete.  according to the spec,
# oxm_hasmask should be 1 if a switch supports masking for the type.
# the right value for oxm_length is not clear from the spec.
# update: OpenFlow 1.3.3 "clarified" that oxm_length here is the payload
# length.  it's still unclear if it should be doubled for hasmask or not,
# though.
#   ofsoftswitch13
#     oxm_hasmask  always 0
#     oxm_length   same as ofp_match etc (as without mask)
#   linc/of_protocol
#     oxm_hasmask  always 0
#     oxm_length   always 0
#   ovs:
#     table-feature is not implemented
class OFPOxmId(StringifyMixin):
    _PACK_STR = '!I'  # oxm header

    _TYPE = {
        'ascii': [
            'type',
        ],
    }

    def __init__(self, type_, hasmask=False, length=None):
        self.type = type_
        self.hasmask = hasmask
        self.length = length
        # XXX experimenter

    @classmethod
    def parse(cls, buf):
        (oxm,) = struct.unpack_from(cls._PACK_STR, buffer(buf), 0)
        (type_, _v) = ofproto_v1_3.oxm_to_user(oxm >> 9, None, None)
        hasmask = ofproto_v1_3.oxm_tlv_header_extract_hasmask(oxm)
        length = oxm & 0xff  # XXX see the comment on OFPOxmId
        rest = buf[4:]  # XXX see the comment on OFPOxmId
        return cls(type_=type_, hasmask=hasmask, length=length), rest

    def serialize(self):
        # fixup
        self.length = 0  # XXX see the comment on OFPOxmId

        (n, _v, _m) = ofproto_v1_3.oxm_from_user(self.type, None)
        oxm = (n << 9) | (self.hasmask << 8) | self.length
        buf = bytearray()
        msg_pack_into(self._PACK_STR, buf, 0, oxm)
        return buf


@OFPTableFeatureProp.register_type(ofproto_v1_3.OFPTFPT_MATCH)
@OFPTableFeatureProp.register_type(ofproto_v1_3.OFPTFPT_WILDCARDS)
@OFPTableFeatureProp.register_type(ofproto_v1_3.OFPTFPT_WRITE_SETFIELD)
@OFPTableFeatureProp.register_type(ofproto_v1_3.OFPTFPT_WRITE_SETFIELD_MISS)
@OFPTableFeatureProp.register_type(ofproto_v1_3.OFPTFPT_APPLY_SETFIELD)
@OFPTableFeatureProp.register_type(ofproto_v1_3.OFPTFPT_APPLY_SETFIELD_MISS)
class OFPTableFeaturePropOxm(OFPTableFeatureProp):
    def __init__(self, type_, oxm_ids=[], length=None):
        super(OFPTableFeaturePropOxm, self).__init__(type_, length)
        self.oxm_ids = oxm_ids

    @classmethod
    def _parse_prop(cls, buf):
        rest = buf
        ids = []
        while rest:
            i, rest = OFPOxmId.parse(rest)
            ids.append(i)
        return {
            'oxm_ids': ids,
        }

    def _serialize_prop(self):
        bin_ids = bytearray()
        for i in self.oxm_ids:
            bin_ids += i.serialize()
        return bin_ids


# XXX ofproto_v1_3.OFPTFPT_EXPERIMENTER
# XXX ofproto_v1_3.OFPTFPT_EXPERIMENTER_MISS


@_set_stats_type(ofproto_v1_3.OFPMP_TABLE_FEATURES, OFPTableFeaturesStats)
@_set_msg_type(ofproto_v1_3.OFPT_MULTIPART_REQUEST)
class OFPTableFeaturesStatsRequest(OFPMultipartRequest):
    """
    Table features statistics request message

    The controller uses this message to query table features.
    """
    def __init__(self, datapath, flags,
                 body=[],
                 properties=[], type_=None):
        super(OFPTableFeaturesStatsRequest, self).__init__(datapath, flags)
        self.body = body

    def _serialize_stats_body(self):
        bin_body = bytearray()
        for p in self.body:
            bin_body += p.serialize()
        self.buf += bin_body


@OFPMultipartReply.register_stats_type()
@_set_stats_type(ofproto_v1_3.OFPMP_TABLE_FEATURES, OFPTableFeaturesStats)
@_set_msg_type(ofproto_v1_3.OFPT_MULTIPART_REPLY)
class OFPTableFeaturesStatsReply(OFPMultipartReply):
    """
    Table features statistics reply message

    The switch responds with this message to a table features statistics
    request.

    This implmentation is still incomplete.
    Namely, this implementation does not parse ``properties`` list and
    always reports it empty.

    ================ ======================================================
    Attribute        Description
    ================ ======================================================
    body             List of ``OFPTableFeaturesStats`` instance
    ================ ======================================================
    """
    def __init__(self, datapath, type_=None, **kwargs):
        super(OFPTableFeaturesStatsReply, self).__init__(datapath, **kwargs)


@_set_stats_type(ofproto_v1_3.OFPMP_PORT_DESC, OFPPort)
@_set_msg_type(ofproto_v1_3.OFPT_MULTIPART_REQUEST)
class OFPPortDescStatsRequest(OFPMultipartRequest):
    """
    Port description request message

    The controller uses this message to query description of all the ports.

    ================ ======================================================
    Attribute        Description
    ================ ======================================================
    flags            Zero or ``OFPMPF_REQ_MORE``
    ================ ======================================================

    Example::

        def send_port_desc_stats_request(self, datapath):
            ofp_parser = datapath.ofproto_parser

            req = ofp_parser.OFPPortDescStatsRequest(datapath, 0)
            datapath.send_msg(req)
    """
    def __init__(self, datapath, flags, type_=None):
        super(OFPPortDescStatsRequest, self).__init__(datapath, flags)


@OFPMultipartReply.register_stats_type()
@_set_stats_type(ofproto_v1_3.OFPMP_PORT_DESC, OFPPort)
@_set_msg_type(ofproto_v1_3.OFPT_MULTIPART_REPLY)
class OFPPortDescStatsReply(OFPMultipartReply):
    """
    Port description reply message

    The switch responds with this message to a port description request.

    ================ ======================================================
    Attribute        Description
    ================ ======================================================
    body             List of ``OFPPortDescStats`` instance
    ================ ======================================================

    Example::

        @set_ev_cls(ofp_event.EventOFPPortDescStatsReply, MAIN_DISPATCHER)
        def port_desc_stats_reply_handler(self, ev):
            ports = []
            for p in ev.msg.body:
                ports.append('port_no=%d hw_addr=%s name=%s config=0x%08x '
                             'state=0x%08x curr=0x%08x advertised=0x%08x '
                             'supported=0x%08x peer=0x%08x curr_speed=%d '
                             'max_speed=%d' %
                             (p.port_no, p.hw_addr,
                              p.name, p.config,
                              p.state, p.curr, p.advertised,
                              p.supported, p.peer, p.curr_speed,
                              p.max_speed))
            self.logger.debug('OFPPortDescStatsReply received: %s', ports)
    """
    def __init__(self, datapath, type_=None, **kwargs):
        super(OFPPortDescStatsReply, self).__init__(datapath, **kwargs)


# XXX should this allow different interpretations for request and reply?
class OFPExperimenterMultipart(ofproto_parser.namedtuple(
                               'OFPExperimenterMultipart',
                               ('experimenter', 'exp_type', 'data'))):
    """
    The body of OFPExperimenterStatsRequest/OFPExperimenterStatsReply
    multipart messages.

    ================ ======================================================
    Attribute        Description
    ================ ======================================================
    experimenter     Experimenter ID
    exp_type         Experimenter defined
    data             Experimenter defined additional data
    ================ ======================================================
    """

    @classmethod
    def parser(cls, buf, offset):
        args = struct.unpack_from(
            ofproto_v1_3.OFP_EXPERIMENTER_MULTIPART_HEADER_PACK_STR, buf,
            offset)
        args = list(args)
        args.append(buf[offset +
                        ofproto_v1_3.OFP_EXPERIMENTER_MULTIPART_HEADER_SIZE:])
        stats = cls(*args)
        stats.length = ofproto_v1_3.OFP_METER_FEATURES_SIZE
        return stats

    def serialize(self):
        buf = bytearray()
        msg_pack_into(ofproto_v1_3.OFP_EXPERIMENTER_MULTIPART_HEADER_PACK_STR,
                      buf, 0,
                      self.experimenter, self.exp_type)
        return buf + self.data


@_set_stats_type(ofproto_v1_3.OFPMP_EXPERIMENTER, OFPExperimenterMultipart)
@_set_msg_type(ofproto_v1_3.OFPT_MULTIPART_REQUEST)
class OFPExperimenterStatsRequest(OFPMultipartRequest):
    """
    Experimenter multipart request message

    ================ ======================================================
    Attribute        Description
    ================ ======================================================
    flags            Zero or ``OFPMPF_REQ_MORE``
    body             An ``OFPExperimenterMultipart`` instance
    ================ ======================================================
    """
    def __init__(self, datapath, flags, body, type_=None):
        super(OFPExperimenterStatsRequest, self).__init__(datapath, flags)
        self.body = body

    def _serialize_stats_body(self):
        bin_body = self.body.serialize()
        self.buf += bin_body


@OFPMultipartReply.register_stats_type(body_single_struct=True)
@_set_stats_type(ofproto_v1_3.OFPMP_EXPERIMENTER, OFPExperimenterMultipart)
@_set_msg_type(ofproto_v1_3.OFPT_MULTIPART_REPLY)
class OFPExperimenterStatsReply(OFPMultipartReply):
    """
    Experimenter multipart reply message

    ================ ======================================================
    Attribute        Description
    ================ ======================================================
    body             An ``OFPExperimenterMultipart`` instance
    ================ ======================================================
    """
    def __init__(self, datapath, type_=None, **kwargs):
        super(OFPExperimenterStatsReply, self).__init__(datapath, **kwargs)


@_set_msg_type(ofproto_v1_3.OFPT_BARRIER_REQUEST)
class OFPBarrierRequest(MsgBase):
    """
    Barrier request message

    The controller sends this message to ensure message dependencies have
    been met or receive notifications for completed operations.

    Example::

        def send_barrier_request(self, datapath):
            ofp_parser = datapath.ofproto_parser

            req = ofp_parser.OFPBarrierRequest(datapath)
            datapath.send_msg(req)
    """
    def __init__(self, datapath):
        super(OFPBarrierRequest, self).__init__(datapath)


@_register_parser
@_set_msg_type(ofproto_v1_3.OFPT_BARRIER_REPLY)
class OFPBarrierReply(MsgBase):
    """
    Barrier reply message

    The switch responds with this message to a barrier request.

    Example::

        @set_ev_cls(ofp_event.EventOFPBarrierReply, MAIN_DISPATCHER)
        def barrier_reply_handler(self, ev):
            self.logger.debug('OFPBarrierReply received')
    """
    def __init__(self, datapath):
        super(OFPBarrierReply, self).__init__(datapath)


@_set_msg_type(ofproto_v1_3.OFPT_QUEUE_GET_CONFIG_REQUEST)
class OFPQueueGetConfigRequest(MsgBase):
    """
    Queue configuration request message

    ================ ======================================================
    Attribute        Description
    ================ ======================================================
    port             Port to be queried (OFPP_ANY to all configured queues)
    ================ ======================================================

    Example::

        def send_queue_get_config_request(self, datapath):
            ofp = datapath.ofproto
            ofp_parser = datapath.ofproto_parser

            req = ofp_parser.OFPQueueGetConfigRequest(datapath, ofp.OFPP_ANY)
            datapath.send_msg(req)
    """
    def __init__(self, datapath, port):
        super(OFPQueueGetConfigRequest, self).__init__(datapath)
        self.port = port

    def _serialize_body(self):
        msg_pack_into(ofproto_v1_3.OFP_QUEUE_GET_CONFIG_REQUEST_PACK_STR,
                      self.buf, ofproto_v1_3.OFP_HEADER_SIZE, self.port)


class OFPQueuePropHeader(StringifyMixin):
    def __init__(self, property_, len_):
        self.property = property_
        self.len = len_

    def serialize(self, buf, offset):
        msg_pack_into(ofproto_v1_3.OFP_QUEUE_PROP_HEADER_PACK_STR,
                      buf, offset, self.property, self.len)


class OFPQueueProp(OFPQueuePropHeader):
    _QUEUE_PROP_PROPERTIES = {}

    @staticmethod
    def register_queue_property(property_, len_):
        def _register_queue_property(cls):
            cls.cls_property = property_
            cls.cls_len = len_
            OFPQueueProp._QUEUE_PROP_PROPERTIES[cls.cls_property] = cls
            return cls
        return _register_queue_property

    def __init__(self):
        cls = self.__class__
        super(OFPQueueProp, self).__init__(cls.cls_property,
                                           cls.cls_len)

    @classmethod
    def parser(cls, buf, offset):
        (property_, len_) = struct.unpack_from(
            ofproto_v1_3.OFP_QUEUE_PROP_HEADER_PACK_STR,
            buf, offset)
        cls_ = cls._QUEUE_PROP_PROPERTIES.get(property_)
        offset += ofproto_v1_3.OFP_QUEUE_PROP_HEADER_SIZE
        return cls_.parser(buf, offset)


@OFPQueueProp.register_queue_property(
    ofproto_v1_3.OFPQT_MIN_RATE,
    ofproto_v1_3.OFP_QUEUE_PROP_MIN_RATE_SIZE)
class OFPQueuePropMinRate(OFPQueueProp):
    def __init__(self, rate, property_=None, len_=None):
        super(OFPQueuePropMinRate, self).__init__()
        self.rate = rate

    @classmethod
    def parser(cls, buf, offset):
        (rate,) = struct.unpack_from(
            ofproto_v1_3.OFP_QUEUE_PROP_MIN_RATE_PACK_STR, buf, offset)
        return cls(rate)


@OFPQueueProp.register_queue_property(
    ofproto_v1_3.OFPQT_MAX_RATE,
    ofproto_v1_3.OFP_QUEUE_PROP_MAX_RATE_SIZE)
class OFPQueuePropMaxRate(OFPQueueProp):
    def __init__(self, rate, property_=None, len_=None):
        super(OFPQueuePropMaxRate, self).__init__()
        self.rate = rate

    @classmethod
    def parser(cls, buf, offset):
        (rate,) = struct.unpack_from(
            ofproto_v1_3.OFP_QUEUE_PROP_MAX_RATE_PACK_STR, buf, offset)
        return cls(rate)


# TODO: add ofp_queue_prop_experimenter


class OFPPacketQueue(StringifyMixin):
    def __init__(self, queue_id, port, properties, len_=None):
        super(OFPPacketQueue, self).__init__()
        self.queue_id = queue_id
        self.port = port
        self.len = len_
        self.properties = properties

    @classmethod
    def parser(cls, buf, offset):
        (queue_id, port, len_) = struct.unpack_from(
            ofproto_v1_3.OFP_PACKET_QUEUE_PACK_STR, buf, offset)
        length = ofproto_v1_3.OFP_PACKET_QUEUE_SIZE
        offset += ofproto_v1_3.OFP_PACKET_QUEUE_SIZE
        properties = []
        while length < len_:
            queue_prop = OFPQueueProp.parser(buf, offset)
            properties.append(queue_prop)
            offset += queue_prop.len
            length += queue_prop.len
        o = cls(queue_id, port, properties)
        o.len = len_
        return o


@_register_parser
@_set_msg_type(ofproto_v1_3.OFPT_QUEUE_GET_CONFIG_REPLY)
class OFPQueueGetConfigReply(MsgBase):
    """
    Queue configuration reply message

    The switch responds with this message to a queue configuration request.

    ================ ======================================================
    Attribute        Description
    ================ ======================================================
    queues           list of ``OFPPacketQueue`` instance
    port             Port which was queried
    ================ ======================================================

    Example::

        @set_ev_cls(ofp_event.EventOFPQueueGetConfigReply, MAIN_DISPATCHER)
        def queue_get_config_reply_handler(self, ev):
            msg = ev.msg

            self.logger.debug('OFPQueueGetConfigReply received: '
                              'port=%s queues=%s',
                              msg.port, msg.queues)
    """
    def __init__(self, datapath, queues=None, port=None):
        super(OFPQueueGetConfigReply, self).__init__(datapath)
        self.queues = queues
        self.port = port

    @classmethod
    def parser(cls, datapath, version, msg_type, msg_len, xid, buf):
        msg = super(OFPQueueGetConfigReply, cls).parser(datapath, version,
                                                        msg_type,
                                                        msg_len, xid, buf)
        (msg.port,) = struct.unpack_from(
            ofproto_v1_3.OFP_QUEUE_GET_CONFIG_REPLY_PACK_STR, msg.buf,
            ofproto_v1_3.OFP_HEADER_SIZE)

        msg.queues = []
        offset = ofproto_v1_3.OFP_QUEUE_GET_CONFIG_REPLY_SIZE
        while offset < msg_len:
            queue = OFPPacketQueue.parser(msg.buf, offset)
            msg.queues.append(queue)
            offset += queue.len

        return msg


@_set_msg_type(ofproto_v1_3.OFPT_ROLE_REQUEST)
class OFPRoleRequest(MsgBase):
    """
    Role request message

    The controller uses this message to change its role.

    ================ ======================================================
    Attribute        Description
    ================ ======================================================
    role             One of the following values.
                     OFPCR_ROLE_NOCHANGE
                     OFPCR_ROLE_EQUAL
                     OFPCR_ROLE_MASTER
                     OFPCR_ROLE_SLAVE
    generation_id    Master Election Generation ID
    ================ ======================================================

    Example::

        def send_role_request(self, datapath):
            ofp = datapath.ofproto
            ofp_parser = datapath.ofproto_parser

            req = ofp_parser.OFPRoleRequest(datapath, ofp.OFPCR_ROLE_EQUAL, 0)
            datapath.send_msg(req)
    """
    def __init__(self, datapath, role=None, generation_id=None):
        super(OFPRoleRequest, self).__init__(datapath)
        self.role = role
        self.generation_id = generation_id

    def _serialize_body(self):
        assert self.role is not None
        assert self.generation_id is not None
        msg_pack_into(ofproto_v1_3.OFP_ROLE_REQUEST_PACK_STR,
                      self.buf, ofproto_v1_3.OFP_HEADER_SIZE,
                      self.role, self.generation_id)


@_register_parser
@_set_msg_type(ofproto_v1_3.OFPT_ROLE_REPLY)
class OFPRoleReply(MsgBase):
    """
    Role reply message

    The switch responds with this message to a role request.

    ================ ======================================================
    Attribute        Description
    ================ ======================================================
    role             One of the following values.
                     OFPCR_ROLE_NOCHANGE
                     OFPCR_ROLE_EQUAL
                     OFPCR_ROLE_MASTER
                     OFPCR_ROLE_SLAVE
    generation_id    Master Election Generation ID
    ================ ======================================================

    Example::

        @set_ev_cls(ofp_event.EventOFPRoleReply, MAIN_DISPATCHER)
        def role_reply_handler(self, ev):
            msg = ev.msg
            ofp = dp.ofproto

            if msg.role == ofp.OFPCR_ROLE_NOCHANGE:
                role = 'NOCHANGE'
            elif msg.role == ofp.OFPCR_ROLE_EQUAL:
                role = 'EQUAL'
            elif msg.role == ofp.OFPCR_ROLE_MASTER:
                role = 'MASTER'
            elif msg.role == ofp.OFPCR_ROLE_SLAVE:
                role = 'SLAVE'
            else:
                role = 'unknown'

            self.logger.debug('OFPRoleReply received: '
                              'role=%s generation_id=%d',
                              role, msg.generation_id)
    """
    def __init__(self, datapath, role=None, generation_id=None):
        super(OFPRoleReply, self).__init__(datapath)
        self.role = role
        self.generation_id = generation_id

    @classmethod
    def parser(cls, datapath, version, msg_type, msg_len, xid, buf):
        msg = super(OFPRoleReply, cls).parser(datapath, version,
                                              msg_type, msg_len, xid,
                                              buf)
        (msg.role, msg.generation_id) = struct.unpack_from(
            ofproto_v1_3.OFP_ROLE_REQUEST_PACK_STR, msg.buf,
            ofproto_v1_3.OFP_HEADER_SIZE)
        return msg


@_set_msg_type(ofproto_v1_3.OFPT_GET_ASYNC_REQUEST)
class OFPGetAsyncRequest(MsgBase):
    """
    Get asynchronous configuration request message

    The controller uses this message to query the asynchronous message.

    Example::

        def send_get_async_request(self, datapath):
            ofp_parser = datapath.ofproto_parser

            req = ofp_parser.OFPGetAsyncRequest(datapath)
            datapath.send_msg(req)
    """
    def __init__(self, datapath):
        super(OFPGetAsyncRequest, self).__init__(datapath)


@_register_parser
@_set_msg_type(ofproto_v1_3.OFPT_GET_ASYNC_REPLY)
class OFPGetAsyncReply(MsgBase):
    """
    Get asynchronous configuration reply message

    The switch responds with this message to a get asynchronous configuration
    request.

    ================== ====================================================
    Attribute          Description
    ================== ====================================================
    packet_in_mask     2-element array: element 0, when the controller has a
                       OFPCR_ROLE_EQUAL or OFPCR_ROLE_MASTER role. element 1,
                       OFPCR_ROLE_SLAVE role controller.
                       Bitmasks of following values.
                       OFPR_NO_MATCH
                       OFPR_ACTION
                       OFPR_INVALID_TTL
    port_status_mask   2-element array.
                       Bitmasks of following values.
                       OFPPR_ADD
                       OFPPR_DELETE
                       OFPPR_MODIFY
    flow_removed_mask  2-element array.
                       Bitmasks of following values.
                       OFPRR_IDLE_TIMEOUT
                       OFPRR_HARD_TIMEOUT
                       OFPRR_DELETE
                       OFPRR_GROUP_DELETE
    ================== ====================================================

    Example::

        @set_ev_cls(ofp_event.EventOFPGetAsyncReply, MAIN_DISPATCHER)
        def get_async_reply_handler(self, ev):
            msg = ev.msg

            self.logger.debug('OFPGetAsyncReply received: '
                              'packet_in_mask=0x%08x:0x%08x '
                              'port_status_mask=0x%08x:0x%08x '
                              'flow_removed_mask=0x%08x:0x%08x',
                              msg.packet_in_mask[0],
                              msg.packet_in_mask[1],
                              msg.port_status_mask[0],
                              msg.port_status_mask[1],
                              msg.flow_removed_mask[0],
                              msg.flow_removed_mask[1])
    """
    def __init__(self, datapath, packet_in_mask=None, port_status_mask=None,
                 flow_removed_mask=None):
        super(OFPGetAsyncReply, self).__init__(datapath)
        self.packet_in_mask = packet_in_mask
        self.port_status_mask = port_status_mask
        self.flow_removed_mask = flow_removed_mask

    @classmethod
    def parser(cls, datapath, version, msg_type, msg_len, xid, buf):
        msg = super(OFPGetAsyncReply, cls).parser(datapath, version,
                                                  msg_type, msg_len,
                                                  xid, buf)
        (packet_in_mask_m, packet_in_mask_s,
         port_status_mask_m, port_status_mask_s,
         flow_removed_mask_m, flow_removed_mask_s) = struct.unpack_from(
            ofproto_v1_3.OFP_ASYNC_CONFIG_PACK_STR, msg.buf,
            ofproto_v1_3.OFP_HEADER_SIZE)
        msg.packet_in_mask = [packet_in_mask_m, packet_in_mask_s]
        msg.port_status_mask = [port_status_mask_m, port_status_mask_s]
        msg.flow_removed_mask = [flow_removed_mask_m, flow_removed_mask_s]
        return msg


@_set_msg_type(ofproto_v1_3.OFPT_SET_ASYNC)
class OFPSetAsync(MsgBase):
    """
    Set asynchronous configuration message

    The controller sends this message to set the asynchronous messages that
    it wants to receive on a given OpneFlow channel.

    ================== ====================================================
    Attribute          Description
    ================== ====================================================
    packet_in_mask     2-element array: element 0, when the controller has a
                       OFPCR_ROLE_EQUAL or OFPCR_ROLE_MASTER role. element 1,
                       OFPCR_ROLE_SLAVE role controller.
                       Bitmasks of following values.
                       OFPR_NO_MATCH
                       OFPR_ACTION
                       OFPR_INVALID_TTL
    port_status_mask   2-element array.
                       Bitmasks of following values.
                       OFPPR_ADD
                       OFPPR_DELETE
                       OFPPR_MODIFY
    flow_removed_mask  2-element array.
                       Bitmasks of following values.
                       OFPRR_IDLE_TIMEOUT
                       OFPRR_HARD_TIMEOUT
                       OFPRR_DELETE
                       OFPRR_GROUP_DELETE
    ================== ====================================================

    Example::

        def send_set_async(self, datapath):
            ofp = datapath.ofproto
            ofp_parser = datapath.ofproto_parser

            packet_in_mask = ofp.OFPR_ACTION | ofp.OFPR_INVALID_TTL
            port_status_mask = (ofp.OFPPR_ADD | ofp.OFPPR_DELETE |
                                ofp.OFPPR_MODIFY)
            flow_removed_mask = (ofp.OFPRR_IDLE_TIMEOUT |
                                 ofp.OFPRR_HARD_TIMEOUT |
                                 ofp.OFPRR_DELETE)
            req = ofp_parser.OFPSetAsync(datapath,
                                         [packet_in_mask, 0],
                                         [port_status_mask, 0],
                                         [flow_removed_mask, 0])
            datapath.send_msg(req)
    """
    def __init__(self, datapath,
                 packet_in_mask, port_status_mask, flow_removed_mask):
        super(OFPSetAsync, self).__init__(datapath)
        self.packet_in_mask = packet_in_mask
        self.port_status_mask = port_status_mask
        self.flow_removed_mask = flow_removed_mask

    def _serialize_body(self):
        msg_pack_into(ofproto_v1_3.OFP_ASYNC_CONFIG_PACK_STR, self.buf,
                      ofproto_v1_3.OFP_HEADER_SIZE,
                      self.packet_in_mask[0], self.packet_in_mask[1],
                      self.port_status_mask[0], self.port_status_mask[1],
                      self.flow_removed_mask[0], self.flow_removed_mask[1])

########NEW FILE########
__FILENAME__ = oxm_fields
# Copyright (C) 2013 Nippon Telegraph and Telephone Corporation.
# Copyright (C) 2013 YAMAMOTO Takashi <yamamoto at valinux co jp>
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# there are two representations of value and mask this module deal with.
#
# "user"
#   (value, mask) or value.  the latter means no mask.
#   value and mask are strings.
#
# "internal"
#   value and mask are on-wire bytes.
#   mask is None if no mask.

import itertools
import struct
from ofproto_parser import msg_pack_into

from ryu.lib import addrconv


class TypeDescr(object):
    pass


class IntDescr(TypeDescr):
    def __init__(self, size):
        self.size = size

    def to_user(self, bin):
        i = 0
        for x in xrange(self.size):
            c = bin[:1]
            i = i * 256 + ord(c)
            bin = bin[1:]
        return i

    def from_user(self, i):
        bin = ''
        for x in xrange(self.size):
            bin = chr(i & 255) + bin
            i /= 256
        return bin

Int1 = IntDescr(1)
Int2 = IntDescr(2)
Int3 = IntDescr(3)
Int4 = IntDescr(4)
Int8 = IntDescr(8)


class MacAddr(TypeDescr):
    size = 6
    to_user = addrconv.mac.bin_to_text
    from_user = addrconv.mac.text_to_bin


class IPv4Addr(TypeDescr):
    size = 4
    to_user = addrconv.ipv4.bin_to_text
    from_user = addrconv.ipv4.text_to_bin


class IPv6Addr(TypeDescr):
    size = 16
    to_user = addrconv.ipv6.bin_to_text
    from_user = addrconv.ipv6.text_to_bin


class UnknownType(TypeDescr):
    import base64

    to_user = staticmethod(base64.b64encode)
    from_user = staticmethod(base64.b64decode)


OFPXMC_OPENFLOW_BASIC = 0x8000


class OpenFlowBasic(object):
    _class = OFPXMC_OPENFLOW_BASIC

    def __init__(self, name, num, type_):
        self.name = name
        self.num = num | (self._class << 7)
        self.type = type_


def generate(modname):
    import sys
    import string
    import functools

    mod = sys.modules[modname]

    def add_attr(k, v):
        setattr(mod, k, v)

    for i in mod.oxm_types:
        uk = string.upper(i.name)
        oxm_class = i.num >> 7
        if oxm_class != OFPXMC_OPENFLOW_BASIC:
            continue
        ofpxmt = i.num & 0x3f
        td = i.type
        add_attr('OFPXMT_OFB_' + uk, ofpxmt)
        add_attr('OXM_OF_' + uk, mod.oxm_tlv_header(ofpxmt, td.size))
        add_attr('OXM_OF_' + uk + '_W', mod.oxm_tlv_header_w(ofpxmt, td.size))

    name_to_field = dict((f.name, f) for f in mod.oxm_types)
    num_to_field = dict((f.num, f) for f in mod.oxm_types)
    add_attr('oxm_from_user', functools.partial(from_user, name_to_field))
    add_attr('oxm_to_user', functools.partial(to_user, num_to_field))
    add_attr('oxm_normalize_user', functools.partial(normalize_user, mod))
    add_attr('oxm_parse', functools.partial(parse, mod))
    add_attr('oxm_serialize', serialize)
    add_attr('oxm_to_jsondict', to_jsondict)
    add_attr('oxm_from_jsondict', from_jsondict)


def from_user(name_to_field, name, user_value):
    try:
        f = name_to_field[name]
        t = f.type
        num = f.num
    except KeyError:
        t = UnknownType
        if name.startswith('field_'):
            num = int(name.split('_')[1])
        else:
            raise KeyError('unknown match field ' + name)
    # the 'list' case below is a bit hack; json.dumps silently maps
    # python tuples into json lists.
    if isinstance(user_value, (tuple, list)):
        (value, mask) = user_value
    else:
        value = user_value
        mask = None
    if not value is None:
        value = t.from_user(value)
    if not mask is None:
        mask = t.from_user(mask)
    return num, value, mask


def to_user(num_to_field, n, v, m):
    try:
        f = num_to_field[n]
        t = f.type
        name = f.name
    except KeyError:
        t = UnknownType
        name = 'field_%d' % n
    if not v is None:
        value = t.to_user(v)
    else:
        value = None
    if m is None:
        user_value = value
    else:
        user_value = (value, t.to_user(m))
    return name, user_value


def normalize_user(mod, k, uv):
    (n, v, m) = mod.oxm_from_user(k, uv)
    # apply mask
    if not m is None:
        v = ''.join(chr(ord(x) & ord(y)) for (x, y)
            in itertools.izip(v, m))
    (k2, uv2) = mod.oxm_to_user(n, v, m)
    assert k2 == k
    return (k2, uv2)


def parse(mod, buf, offset):
    hdr_pack_str = '!I'
    (header, ) = struct.unpack_from(hdr_pack_str, buf, offset)
    hdr_len = struct.calcsize(hdr_pack_str)
    oxm_type = header >> 9  # class|field
    oxm_hasmask = mod.oxm_tlv_header_extract_hasmask(header)
    value_len = mod.oxm_tlv_header_extract_length(header)
    value_pack_str = '!%ds' % value_len
    assert struct.calcsize(value_pack_str) == value_len
    (value, ) = struct.unpack_from(value_pack_str, buf,
                                   offset + hdr_len)
    if oxm_hasmask:
        (mask, ) = struct.unpack_from(value_pack_str, buf,
                                      offset + hdr_len + value_len)
    else:
        mask = None
    field_len = hdr_len + (header & 0xff)
    return oxm_type, value, mask, field_len


def serialize(n, value, mask, buf, offset):
    if mask:
        assert len(value) == len(mask)
        pack_str = "!I%ds%ds" % (len(value), len(mask))
        msg_pack_into(pack_str, buf, offset,
                      (n << 9) | (1 << 8) | (len(value) * 2), value, mask)
    else:
        pack_str = "!I%ds" % (len(value),)
        msg_pack_into(pack_str, buf, offset,
                      (n << 9) | (0 << 8) | len(value), value)
    return struct.calcsize(pack_str)


def to_jsondict(k, uv):
    if isinstance(uv, tuple):
        (value, mask) = uv
    else:
        value = uv
        mask = None
    return {"OXMTlv": {"field": k, "value": value, "mask": mask}}


def from_jsondict(j):
    tlv = j['OXMTlv']
    field = tlv['field']
    value = tlv['value']
    mask = tlv.get('mask')
    if mask is None:
        uv = value
    else:
        uv = (value, mask)
    return (field, uv)

########NEW FILE########
__FILENAME__ = run_tests_with_ovs12
#!/usr/bin/env python
# Copyright (C) 2013 Nippon Telegraph and Telephone Corporation.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import unittest
from nose.tools import ok_, eq_, timed, nottest

from subprocess import Popen, PIPE, STDOUT
import time

from mininet.net import Mininet
from mininet.node import RemoteController, OVSKernelSwitch

TIMEOUT = 60
RYU_HOST = '127.0.0.1'
RYU_PORT = 6633
PYTHON_BIN = '.venv/bin/python'
RYU_MGR = './bin/ryu-manager'


class OVS12KernelSwitch(OVSKernelSwitch):
    """Set protocols parameter for OVS version 1.10"""
    def start(self, controllers):
        super(OVS12KernelSwitch, self).start(controllers)
        self.cmd('ovs-vsctl set Bridge', self,
                 "protocols='[OpenFlow10, OpenFlow12]'")


class TestWithOVS12(unittest.TestCase):
    @classmethod
    def setUpClass(cls):
        cls.mn = Mininet()
        c = cls.mn.addController(controller=RemoteController,
                                 ip=RYU_HOST, port=RYU_PORT)
        c.start()

        s1 = cls.mn.addSwitch('s1', cls=OVS12KernelSwitch)
        s1.start(cls.mn.controllers)

        h1 = cls.mn.addHost('h1', ip='0.0.0.0/0')

        link = cls.mn.addLink(h1, s1)
        s1.attach(link.intf2)

    @classmethod
    def tearDownClass(cls):
        cls.mn.stop()

    @timed(TIMEOUT)
    def test_add_flow_v10(self):
        app = 'ryu/tests/integrated/test_add_flow_v10.py'
        self._run_ryu_manager_and_check_output(app)

    @timed(TIMEOUT)
    def test_request_reply_v12(self):
        app = 'ryu/tests/integrated/test_request_reply_v12.py'
        self._run_ryu_manager_and_check_output(app)

    @timed(TIMEOUT)
    def test_add_flow_v12_actions(self):
        app = 'ryu/tests/integrated/test_add_flow_v12_actions.py'
        self._run_ryu_manager_and_check_output(app)

    @timed(TIMEOUT)
    def test_add_flow_v12_matches(self):
        app = 'ryu/tests/integrated/test_add_flow_v12_matches.py'
        self._run_ryu_manager_and_check_output(app)

    @nottest
    def test_of_config(self):
        # OVS 1.10 does not support of_config
        pass

    def _run_ryu_manager_and_check_output(self, app):
        cmd = [PYTHON_BIN, RYU_MGR, app]
        p = Popen(cmd, stdout=PIPE, stderr=STDOUT)

        while True:
            if p.poll() is not None:
                raise Exception('Another ryu-manager already running?')

            line = p.stdout.readline().strip()
            if line == '':
                time.sleep(1)
                continue

            print "ryu-manager: %s" % line
            if line.find('TEST_FINISHED') != -1:
                ok_(line.find('Completed=[True]') != -1)
                p.terminate()
                p.communicate()  # wait for subprocess is terminated
                break


if __name__ == '__main__':
    unittest.main()

########NEW FILE########
__FILENAME__ = tester
# Copyright (C) 2012 Nippon Telegraph and Telephone Corporation.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# vim: tabstop=4 shiftwidth=4 softtabstop=4

import sys
import logging
import itertools

from ryu import utils
from ryu.lib import mac
from ryu.base import app_manager
from ryu.controller import ofp_event
from ryu.controller import handler
from ryu.controller import dpset
from ryu.controller.handler import MAIN_DISPATCHER
from ryu.controller.handler import CONFIG_DISPATCHER
from ryu.controller.handler import set_ev_cls
from ryu.ofproto import ofproto_v1_0
from ryu.ofproto import ofproto_v1_2


LOG = logging.getLogger(__name__)


LOG_TEST_START = 'TEST_START: %s'
LOG_TEST_RESULTS = 'TEST_RESULTS:'
LOG_TEST_FINISH = 'TEST_FINISHED: Completed=[%s] (OK=%s NG=%s SKIP=%s)'
LOG_TEST_UNSUPPORTED = 'SKIP (unsupported)'


class TestFlowBase(app_manager.RyuApp):
    """
    To run the tests is required for the following pair of functions.
        1. test_<test name>()
            To send flows to switch.

        2. verify_<test name>() or _verify_default()
            To check flows of switch.
    """

    _CONTEXTS = {'dpset': dpset.DPSet}

    def __init__(self, *args, **kwargs):
        super(TestFlowBase, self).__init__(*args, **kwargs)
        self.pending = []
        self.results = {}
        self.current = None
        self.unclear = 0

        for t in dir(self):
            if t.startswith("test_"):
                self.pending.append(t)
        self.pending.sort(reverse=True)
        self.unclear = len(self.pending)

    def delete_all_flows(self, dp):
        if dp.ofproto == ofproto_v1_0:
            match = dp.ofproto_parser.OFPMatch(dp.ofproto.OFPFW_ALL,
                                               0, 0, 0, 0, 0,
                                               0, 0, 0, 0, 0, 0, 0)
            m = dp.ofproto_parser.OFPFlowMod(dp, match, 0,
                                             dp.ofproto.OFPFC_DELETE,
                                             0, 0, 0, 0,
                                             dp.ofproto.OFPP_NONE, 0, None)
        elif dp.ofproto == ofproto_v1_2:
            match = dp.ofproto_parser.OFPMatch()
            m = dp.ofproto_parser.OFPFlowMod(dp, 0, 0, dp.ofproto.OFPTT_ALL,
                                             dp.ofproto.OFPFC_DELETE,
                                             0, 0, 0, 0xffffffff,
                                             dp.ofproto.OFPP_ANY,
                                             dp.ofproto.OFPG_ANY,
                                             0, match, [])

        dp.send_msg(m)

    def send_flow_stats(self, dp):
        if dp.ofproto == ofproto_v1_0:
            match = dp.ofproto_parser.OFPMatch(dp.ofproto.OFPFW_ALL,
                                               0, 0, 0, 0, 0,
                                               0, 0, 0, 0, 0, 0, 0)
            m = dp.ofproto_parser.OFPFlowStatsRequest(dp, 0, match,
                                                      0, dp.ofproto.OFPP_NONE)
        elif dp.ofproto == ofproto_v1_2:
            match = dp.ofproto_parser.OFPMatch()
            m = dp.ofproto_parser.OFPFlowStatsRequest(dp, dp.ofproto.OFPTT_ALL,
                                                      dp.ofproto.OFPP_ANY,
                                                      dp.ofproto.OFPG_ANY,
                                                      0, 0, match)

        dp.send_msg(m)

    def verify_default(self, dp, stats):
        return 'function %s() is not found.' % ("verify" + self.current[4:], )

    def start_next_test(self, dp):
        self.delete_all_flows(dp)
        dp.send_barrier()
        if len(self.pending):
            t = self.pending.pop()
            if self.is_supported(t):
                LOG.info(LOG_TEST_START, t)
                self.current = t
                getattr(self, t)(dp)
                dp.send_barrier()
                self.send_flow_stats(dp)
            else:
                self.results[t] = LOG_TEST_UNSUPPORTED
                self.unclear -= 1
                self.start_next_test(dp)
        else:
            self.print_results()

    def print_results(self):
        LOG.info("TEST_RESULTS:")
        ok = 0
        ng = 0
        skip = 0
        for t in sorted(self.results.keys()):
            if self.results[t] is True:
                ok += 1
            elif self.results[t] == LOG_TEST_UNSUPPORTED:
                skip += 1
            else:
                ng += 1
            LOG.info("    %s: %s", t, self.results[t])
        LOG.info(LOG_TEST_FINISH, self.unclear == 0, ok, ng, skip)

    @handler.set_ev_cls(ofp_event.EventOFPFlowStatsReply,
                        handler.MAIN_DISPATCHER)
    def flow_reply_handler(self, ev):
        self.run_verify(ev)

    @handler.set_ev_cls(ofp_event.EventOFPStatsReply,
                        handler.MAIN_DISPATCHER)
    def stats_reply_handler(self, ev):
        self.run_verify(ev)

    def run_verify(self, ev):
        msg = ev.msg
        dp = msg.datapath

        verify_func = self.verify_default
        v = "verify" + self.current[4:]
        if hasattr(self, v):
            verify_func = getattr(self, v)

        result = verify_func(dp, msg.body)
        if result is True:
            self.unclear -= 1

        self.results[self.current] = result
        self.start_next_test(dp)

    @handler.set_ev_cls(dpset.EventDP)
    def handler_datapath(self, ev):
        if ev.enter:
            self.start_next_test(ev.dp)

    @set_ev_cls(ofp_event.EventOFPBarrierReply, MAIN_DISPATCHER)
    def barrier_replay_handler(self, ev):
        pass

    def haddr_to_str(self, addr):
        return mac.haddr_to_str(addr)

    def haddr_to_bin(self, string):
        return mac.haddr_to_bin(string)

    def haddr_masked(self, haddr_bin, mask_bin):
        return mac.haddr_bitand(haddr_bin, mask_bin)

    def ipv4_to_str(self, integre):
        ip_list = [str((integre >> (24 - (n * 8)) & 255)) for n in range(4)]
        return '.'.join(ip_list)

    def ipv4_to_int(self, string):
        ip = string.split('.')
        assert len(ip) == 4
        i = 0
        for b in ip:
            b = int(b)
            i = (i << 8) | b
        return i

    def ipv4_masked(self, ip_int, mask_int):
        return ip_int & mask_int

    def ipv6_to_str(self, integres):
        return ':'.join(hex(x)[2:] for x in integres)

    def ipv6_to_int(self, string):
        ip = string.split(':')
        assert len(ip) == 8
        return [int(x, 16) for x in ip]

    def ipv6_masked(self, ipv6_int, mask_int):
        return [x & y for (x, y) in
                itertools.izip(ipv6_int, mask_int)]

    def is_supported(self, t):
        return True

########NEW FILE########
__FILENAME__ = test_add_flow_v10
# Copyright (C) 2012 Nippon Telegraph and Telephone Corporation.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# vim: tabstop=4 shiftwidth=4 softtabstop=4

import logging

from ryu.tests.integrated import tester
from ryu.ofproto import ofproto_v1_0
from ryu.ofproto import ether
from ryu.ofproto import nx_match

LOG = logging.getLogger(__name__)


class RunTest(tester.TestFlowBase):
    """ Test case for add flows of1.0
    """
    OFP_VERSIONS = [ofproto_v1_0.OFP_VERSION]

    def __init__(self, *args, **kwargs):
        super(RunTest, self).__init__(*args, **kwargs)
        self._verify = []

    def add_action(self, dp, action):
        rule = nx_match.ClsRule()
        self.send_flow_mod(
            dp, rule, 0, dp.ofproto.OFPFC_ADD, 0, 0, None,
            0xffffffff, None, dp.ofproto.OFPFF_SEND_FLOW_REM, action)

    def add_rule(self, dp, rule):
        self.send_flow_mod(
            dp, rule, 0, dp.ofproto.OFPFC_ADD, 0, 0, None,
            0xffffffff, None, dp.ofproto.OFPFF_SEND_FLOW_REM, [])

    def send_flow_mod(self, dp, rule, cookie, command, idle_timeout,
                      hard_timeout, priority=None, buffer_id=0xffffffff,
                      out_port=None, flags=0, actions=None):

        if priority is None:
            priority = dp.ofproto.OFP_DEFAULT_PRIORITY
        if out_port is None:
            out_port = dp.ofproto.OFPP_NONE

        match_tuple = rule.match_tuple()
        match = dp.ofproto_parser.OFPMatch(*match_tuple)

        m = dp.ofproto_parser.OFPFlowMod(
            dp, match, cookie, command, idle_timeout, hard_timeout,
            priority, buffer_id, out_port, flags, actions)

        dp.send_msg(m)

    def _verify_action(self, actions, type_, name, value):
        try:
            action = actions[0]
            if action.cls_action_type != type_:
                return "Action type error. send:%s, val:%s" \
                    % (type_, action.cls_action_type)
        except IndexError:
            return "Action is not setting."

        f_value = None
        if name:
            try:
                if isinstance(name, list):
                    f_value = [getattr(action, n) for n in name]
                else:
                    f_value = getattr(action, name)
            except AttributeError:
                pass

        if f_value != value:
            return "Value error. send:%s=%s val:%s" \
                % (name, value, f_value)
        return True

    def _verify_rule(self, rule, name, value):
        f_value = getattr(rule, name)
        if f_value != value:
            return "Value error. send:%s=%s val:%s" \
                % (name, value, f_value)
        return True

    def verify_default(self, dp, stats):
        verify = self._verify
        self._verify = []
        match = stats[0].match
        actions = stats[0].actions

        if len(verify) == 2:
            return self._verify_rule(match, *verify)
        elif len(verify) == 3:
            return self._verify_action(actions, *verify)
        else:
            return "self._verify is invalid."

    # Test of Actions
    def test_action_output(self, dp):
        out_port = 2
        self._verify = [dp.ofproto.OFPAT_OUTPUT,
                        'port', out_port]
        action = dp.ofproto_parser.OFPActionOutput(out_port)
        self.add_action(dp, [action, ])

    def test_rule_set_in_port(self, dp):
        in_port = 32
        self._verify = ['in_port', in_port]

        rule = nx_match.ClsRule()
        rule.set_in_port(in_port)
        self.add_rule(dp, rule)

    def test_action_vlan_vid(self, dp):
        vlan_vid = 2
        self._verify = [dp.ofproto.OFPAT_SET_VLAN_VID,
                        'vlan_vid', vlan_vid]
        action = dp.ofproto_parser.OFPActionVlanVid(vlan_vid)
        self.add_action(dp, [action, ])

    def test_action_vlan_pcp(self, dp):
        vlan_pcp = 4
        self._verify = [dp.ofproto.OFPAT_SET_VLAN_PCP,
                        'vlan_pcp', vlan_pcp]
        action = dp.ofproto_parser.OFPActionVlanPcp(vlan_pcp)
        self.add_action(dp, [action, ])

    def test_action_strip_vlan(self, dp):
        vlan_pcp = 4
        self._verify = [dp.ofproto.OFPAT_STRIP_VLAN,
                        None, None]
        action = dp.ofproto_parser.OFPActionStripVlan()
        self.add_action(dp, [action, ])

    def test_action_set_dl_src(self, dp):
        dl_src = '56:b3:42:04:b2:7a'
        dl_src_bin = self.haddr_to_bin(dl_src)
        self._verify = [dp.ofproto.OFPAT_SET_DL_SRC,
                        'dl_addr', dl_src_bin]
        action = dp.ofproto_parser.OFPActionSetDlSrc(dl_src_bin)
        self.add_action(dp, [action, ])

    def test_action_set_dl_dst(self, dp):
        dl_dst = 'c2:93:a2:fb:d0:f4'
        dl_dst_bin = self.haddr_to_bin(dl_dst)
        self._verify = [dp.ofproto.OFPAT_SET_DL_DST,
                        'dl_addr', dl_dst_bin]
        action = dp.ofproto_parser.OFPActionSetDlDst(dl_dst_bin)
        self.add_action(dp, [action, ])

    def test_action_set_nw_src(self, dp):
        nw_src = '216.132.81.105'
        nw_src_int = self.ipv4_to_int(nw_src)
        self._verify = [dp.ofproto.OFPAT_SET_NW_SRC,
                        'nw_addr', nw_src_int]
        action = dp.ofproto_parser.OFPActionSetNwSrc(nw_src_int)
        self.add_action(dp, [action, ])

    def test_action_set_nw_dst(self, dp):
        nw_dst = '223.201.206.3'
        nw_dst_int = self.ipv4_to_int(nw_dst)
        self._verify = [dp.ofproto.OFPAT_SET_NW_DST,
                        'nw_addr', nw_dst_int]
        action = dp.ofproto_parser.OFPActionSetNwDst(nw_dst_int)
        self.add_action(dp, [action, ])

    def test_action_set_nw_tos(self, dp):
        # lowest two bits must be zero
        nw_tos = 1 << 2
        self._verify = [dp.ofproto.OFPAT_SET_NW_TOS,
                        'tos', nw_tos]
        action = dp.ofproto_parser.OFPActionSetNwTos(nw_tos)
        self.add_action(dp, [action, ])

    def test_action_set_tp_src(self, dp):
        tp_src = 55420
        self._verify = [dp.ofproto.OFPAT_SET_TP_SRC,
                        'tp', tp_src]
        action = dp.ofproto_parser.OFPActionSetTpSrc(tp_src)
        self.add_action(dp, [action, ])

    def test_action_set_tp_dst(self, dp):
        tp_dst = 15430
        self._verify = [dp.ofproto.OFPAT_SET_TP_DST,
                        'tp', tp_dst]
        action = dp.ofproto_parser.OFPActionSetTpDst(tp_dst)
        self.add_action(dp, [action, ])

    def test_action_enqueue(self, dp):
        port = 207
        queue_id = 4287508753
        self._verify = [dp.ofproto.OFPAT_ENQUEUE,
                        ['port', 'queue_id'], [port, queue_id]]
        action = dp.ofproto_parser.OFPActionEnqueue(port, queue_id)
        self.add_action(dp, [action, ])

    # Test of Rules
    def test_rule_set_in_port(self, dp):
        in_port = 32
        self._verify = ['in_port', in_port]

        rule = nx_match.ClsRule()
        rule.set_in_port(in_port)
        self.add_rule(dp, rule)

    def test_rule_set_dl_src(self, dp):
        dl_src = 'b8:a1:94:51:78:83'
        dl_src_bin = self.haddr_to_bin(dl_src)
        self._verify = ['dl_src', dl_src_bin]

        rule = nx_match.ClsRule()
        rule.set_dl_src(dl_src_bin)
        self.add_rule(dp, rule)

    def test_rule_set_dl_type_ip(self, dp):
        dl_type = ether.ETH_TYPE_IP
        self._verify = ['dl_type', dl_type]

        rule = nx_match.ClsRule()
        rule.set_dl_type(dl_type)
        self.add_rule(dp, rule)

    def test_rule_set_dl_type_arp(self, dp):
        dl_type = ether.ETH_TYPE_ARP
        self._verify = ['dl_type', dl_type]

        rule = nx_match.ClsRule()
        rule.set_dl_type(dl_type)
        self.add_rule(dp, rule)

    def test_rule_set_dl_type_vlan(self, dp):
        dl_type = ether.ETH_TYPE_8021Q
        self._verify = ['dl_type', dl_type]

        rule = nx_match.ClsRule()
        rule.set_dl_type(dl_type)
        self.add_rule(dp, rule)

    def test_rule_set_dl_type_ipv6(self, dp):
        dl_type = ether.ETH_TYPE_IPV6
        self._verify = ['dl_type', dl_type]

        rule = nx_match.ClsRule()
        rule.set_dl_type(dl_type)
        self.add_rule(dp, rule)

    def test_rule_set_dl_type_lacp(self, dp):
        dl_type = ether.ETH_TYPE_SLOW
        self._verify = ['dl_type', dl_type]

        rule = nx_match.ClsRule()
        rule.set_dl_type(dl_type)
        self.add_rule(dp, rule)

########NEW FILE########
__FILENAME__ = test_add_flow_v12_actions
# Copyright (C) 2012 Nippon Telegraph and Telephone Corporation.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# vim: tabstop=4 shiftwidth=4 softtabstop=4

import logging

from ryu.ofproto import ofproto_v1_2
from ryu.ofproto import ether
from ryu.ofproto import inet
from ryu.tests.integrated import tester

LOG = logging.getLogger(__name__)


class RunTest(tester.TestFlowBase):
    """ Test case for add flows of Actions
    """
    OFP_VERSIONS = [ofproto_v1_2.OFP_VERSION]

    def __init__(self, *args, **kwargs):
        super(RunTest, self).__init__(*args, **kwargs)

        self._verify = []

    def add_apply_actions(self, dp, actions, match=None):
        inst = [dp.ofproto_parser.OFPInstructionActions(
                dp.ofproto.OFPIT_APPLY_ACTIONS, actions)]
        if match is None:
            match = dp.ofproto_parser.OFPMatch()
        m = dp.ofproto_parser.OFPFlowMod(dp, 0, 0, 0,
                                         dp.ofproto.OFPFC_ADD,
                                         0, 0, 0xff, 0xffffffff,
                                         dp.ofproto.OFPP_ANY,
                                         dp.ofproto.OFPG_ANY,
                                         0, match, inst)
        dp.send_msg(m)

    def add_set_field_action(self, dp, field, value, match=None):
        self._verify = [dp.ofproto.OFPAT_SET_FIELD,
                        'field', field, value]
        f = dp.ofproto_parser.OFPMatchField.make(field, value)
        actions = [dp.ofproto_parser.OFPActionSetField(f), ]
        self.add_apply_actions(dp, actions, match=match)

    def verify_default(self, dp, stats):
        verify = self._verify
        self._verify = []

        type_ = name = field = value = None
        if len(verify) == 1:
            (type_, ) = verify
        elif len(verify) == 3:
            (type_, name, value) = verify
        elif len(verify) == 4:
            (type_, name, field, value) = verify
        else:
            return "self._verify is invalid."

        try:
            action = stats[0].instructions[0].actions[0]
            if action.cls_action_type != type_:
                return "Action type error. send:%s, val:%s" \
                    % (type_, action.cls_action_type)
        except IndexError:
            return "Action is not setting."

        s_val = None
        if name:
            try:
                s_val = getattr(action, name)
            except AttributeError:
                pass

        if name == 'field':
            if s_val.header != field:
                return "Field error. send:%s val:%s" \
                    % (field, s_val.field)
            s_val = s_val.value

        if name and s_val != value:
                return "Value error. send:%s=%s val:%s" \
                    % (name, value, s_val)

        return True

    def verify_action_drop(self, dp, stats):
        for s in stats:
            for i in s.instructions:
                if len(i.actions):
                    return "has actions. %s" % (i.actions)
        return True

    # Test of General Actions
    def test_action_output(self, dp):
        out_port = 255
        self._verify = [dp.ofproto.OFPAT_OUTPUT,
                        'port', out_port]

        actions = [dp.ofproto_parser.OFPActionOutput(out_port, 0), ]
        self.add_apply_actions(dp, actions)

    def test_action_drop(self, dp):
        self.add_apply_actions(dp, [])

    # Test of Push-Tag/Pop-Tag Actions
    def test_action_push_vlan(self, dp):
        ethertype = ether.ETH_TYPE_8021Q
        self._verify = [dp.ofproto.OFPAT_PUSH_VLAN,
                        'ethertype', ethertype]

        actions = [dp.ofproto_parser.OFPActionPushVlan(ethertype)]
        self.add_apply_actions(dp, actions)

    def test_action_pop_vlan(self, dp):
        self._verify = [dp.ofproto.OFPAT_POP_VLAN, ]

        actions = [dp.ofproto_parser.OFPActionPopVlan(), ]
        self.add_apply_actions(dp, actions)

    def test_action_push_mpls(self, dp):
        ethertype = ether.ETH_TYPE_MPLS
        self._verify = [dp.ofproto.OFPAT_PUSH_MPLS,
                        'ethertype', ethertype]

        actions = [dp.ofproto_parser.OFPActionPushMpls(ethertype), ]
        self.add_apply_actions(dp, actions)

    def test_action_pop_mpls(self, dp):
        ethertype = ether.ETH_TYPE_8021Q
        self._verify = [dp.ofproto.OFPAT_POP_MPLS,
                        'ethertype', ethertype]
        actions = [dp.ofproto_parser.OFPActionPopMpls(ethertype), ]
        self.add_apply_actions(dp, actions)

    # Test of Set-Filed Actions
    def test_action_set_field_dl_dst(self, dp):
        field = dp.ofproto.OXM_OF_ETH_DST
        dl_dst = 'e2:7a:09:79:0b:0f'
        value = self.haddr_to_bin(dl_dst)

        self.add_set_field_action(dp, field, value)

    def test_action_set_field_dl_src(self, dp):
        field = dp.ofproto.OXM_OF_ETH_SRC
        dl_src = '08:82:63:b6:62:05'
        value = self.haddr_to_bin(dl_src)

        self.add_set_field_action(dp, field, value)

    def test_action_set_field_dl_type(self, dp):
        field = dp.ofproto.OXM_OF_ETH_TYPE
        value = ether.ETH_TYPE_IPV6

        self.add_set_field_action(dp, field, value)

    def test_action_set_field_vlan_vid(self, dp):
        field = dp.ofproto.OXM_OF_VLAN_VID
        value = 0x1e4

        self.add_set_field_action(dp, field, value)

    def test_action_set_field_vlan_pcp(self, dp):
        field = dp.ofproto.OXM_OF_VLAN_PCP
        value = 3

        match = dp.ofproto_parser.OFPMatch()
        match.set_vlan_vid(1)

        self.add_set_field_action(dp, field, value, match)

    def test_action_set_field_nw_dscp(self, dp):
        field = dp.ofproto.OXM_OF_IP_DSCP
        value = 32

        match = dp.ofproto_parser.OFPMatch()
        match.set_dl_type(ether.ETH_TYPE_IP)

        self.add_set_field_action(dp, field, value, match)

    def test_action_set_field_nw_ecn(self, dp):
        field = dp.ofproto.OXM_OF_IP_ECN
        value = 1

        match = dp.ofproto_parser.OFPMatch()
        match.set_dl_type(ether.ETH_TYPE_IP)

        self.add_set_field_action(dp, field, value, match)

    def test_action_set_field_ip_proto(self, dp):
        field = dp.ofproto.OXM_OF_IP_PROTO
        value = inet.IPPROTO_TCP

        match = dp.ofproto_parser.OFPMatch()
        match.set_dl_type(ether.ETH_TYPE_IP)

        self.add_set_field_action(dp, field, value, match)

    def test_action_set_field_ipv4_src(self, dp):
        field = dp.ofproto.OXM_OF_IPV4_SRC
        ipv4_src = '192.168.3.92'
        value = self.ipv4_to_int(ipv4_src)

        match = dp.ofproto_parser.OFPMatch()
        match.set_dl_type(ether.ETH_TYPE_IP)

        self.add_set_field_action(dp, field, value, match)

    def test_action_set_field_ipv4_dst(self, dp):
        field = dp.ofproto.OXM_OF_IPV4_DST
        ipv4_dst = '192.168.74.122'
        value = self.ipv4_to_int(ipv4_dst)

        match = dp.ofproto_parser.OFPMatch()
        match.set_dl_type(ether.ETH_TYPE_IP)

        self.add_set_field_action(dp, field, value, match)

    def test_action_set_field_tcp_src(self, dp):
        field = dp.ofproto.OXM_OF_TCP_SRC
        value = 105

        match = dp.ofproto_parser.OFPMatch()
        match.set_dl_type(ether.ETH_TYPE_IP)
        match.set_ip_proto(inet.IPPROTO_TCP)

        self.add_set_field_action(dp, field, value, match)

    def test_action_set_field_tcp_dst(self, dp):
        field = dp.ofproto.OXM_OF_TCP_DST
        value = 75

        match = dp.ofproto_parser.OFPMatch()
        match.set_dl_type(ether.ETH_TYPE_IP)
        match.set_ip_proto(inet.IPPROTO_TCP)

        self.add_set_field_action(dp, field, value, match)

    def test_action_set_field_udp_src(self, dp):
        field = dp.ofproto.OXM_OF_UDP_SRC
        value = 197

        match = dp.ofproto_parser.OFPMatch()
        match.set_dl_type(ether.ETH_TYPE_IP)
        match.set_ip_proto(inet.IPPROTO_UDP)

        self.add_set_field_action(dp, field, value, match)

    def test_action_set_field_udp_dst(self, dp):
        field = dp.ofproto.OXM_OF_UDP_DST
        value = 17

        match = dp.ofproto_parser.OFPMatch()
        match.set_dl_type(ether.ETH_TYPE_IP)
        match.set_ip_proto(inet.IPPROTO_UDP)

        self.add_set_field_action(dp, field, value, match)

    def test_action_set_field_icmpv4_type(self, dp):
        field = dp.ofproto.OXM_OF_ICMPV4_TYPE
        value = 8

        match = dp.ofproto_parser.OFPMatch()
        match.set_ip_proto(inet.IPPROTO_ICMP)

        self.add_set_field_action(dp, field, value, match)

    def test_action_set_field_icmpv4_code(self, dp):
        field = dp.ofproto.OXM_OF_ICMPV4_CODE
        value = 2

        match = dp.ofproto_parser.OFPMatch()
        match.set_ip_proto(inet.IPPROTO_ICMP)

        self.add_set_field_action(dp, field, value, match)

    def test_action_set_field_arp_op(self, dp):
        field = dp.ofproto.OXM_OF_ARP_OP
        value = 2

        match = dp.ofproto_parser.OFPMatch()
        match.set_dl_type(ether.ETH_TYPE_ARP)
        self.add_set_field_action(dp, field, value, match)

    def test_action_set_field_arp_spa(self, dp):
        field = dp.ofproto.OXM_OF_ARP_SPA
        nw_src = '192.168.132.179'
        value = self.ipv4_to_int(nw_src)

        match = dp.ofproto_parser.OFPMatch()
        match.set_dl_type(ether.ETH_TYPE_ARP)
        self.add_set_field_action(dp, field, value, match)

    def test_action_set_field_arp_tpa(self, dp):
        field = dp.ofproto.OXM_OF_ARP_TPA
        nw_dst = '192.168.118.85'
        value = self.ipv4_to_int(nw_dst)

        match = dp.ofproto_parser.OFPMatch()
        match.set_dl_type(ether.ETH_TYPE_ARP)
        self.add_set_field_action(dp, field, value, match)

    def test_action_set_field_arp_sha(self, dp):
        field = dp.ofproto.OXM_OF_ARP_SHA
        arp_sha = '50:29:e7:7f:6c:7f'
        value = self.haddr_to_bin(arp_sha)

        match = dp.ofproto_parser.OFPMatch()
        match.set_dl_type(ether.ETH_TYPE_ARP)
        self.add_set_field_action(dp, field, value, match)

    def test_action_set_field_arp_tha(self, dp):
        field = dp.ofproto.OXM_OF_ARP_THA
        arp_tha = '71:c8:72:2f:47:fd'
        value = self.haddr_to_bin(arp_tha)

        match = dp.ofproto_parser.OFPMatch()
        match.set_dl_type(ether.ETH_TYPE_ARP)
        self.add_set_field_action(dp, field, value, match)

    def test_action_set_field_ipv6_src(self, dp):
        field = dp.ofproto.OXM_OF_IPV6_SRC
        ipv6_src = '7527:c798:c772:4a18:117a:14ff:c1b6:e4ef'
        value = self.ipv6_to_int(ipv6_src)

        self.add_set_field_action(dp, field, value)

    def test_action_set_field_ipv6_dst(self, dp):
        field = dp.ofproto.OXM_OF_IPV6_DST
        ipv6_dst = '8893:65b3:6b49:3bdb:3d2:9401:866c:c96'
        value = self.ipv6_to_int(ipv6_dst)

        self.add_set_field_action(dp, field, value)

    def test_action_set_field_ipv6_flabel(self, dp):
        field = dp.ofproto.OXM_OF_IPV6_FLABEL
        value = 0x2c12

        self.add_set_field_action(dp, field, value)

    def test_action_set_field_icmpv6_type(self, dp):
        field = dp.ofproto.OXM_OF_ICMPV6_TYPE
        value = 129

        self.add_set_field_action(dp, field, value)

    def test_action_set_field_icmpv6_code(self, dp):
        field = dp.ofproto.OXM_OF_ICMPV6_CODE
        value = 2

        self.add_set_field_action(dp, field, value)

    def test_action_set_field_ipv6_nd_target(self, dp):
        field = dp.ofproto.OXM_OF_IPV6_ND_TARGET
        target = "5420:db3f:921b:3e33:2791:98f:dd7f:2e19"
        value = self.ipv6_to_int(target)

        self.add_set_field_action(dp, field, value)

    def test_action_set_field_ipv6_nd_sll(self, dp):
        field = dp.ofproto.OXM_OF_IPV6_ND_SLL
        sll = "54:db:3f:3e:27:19"
        value = self.haddr_to_bin(sll)

        self.add_set_field_action(dp, field, value)

    def test_action_set_field_ipv6_nd_tll(self, dp):
        field = dp.ofproto.OXM_OF_IPV6_ND_TLL
        tll = "83:13:48:1e:d0:b0"
        value = self.haddr_to_bin(tll)

        self.add_set_field_action(dp, field, value)

    def test_action_set_field_mpls_label(self, dp):
        field = dp.ofproto.OXM_OF_MPLS_LABEL
        value = 0x4c

        match = dp.ofproto_parser.OFPMatch()
        match.set_dl_type(ether.ETH_TYPE_MPLS)

        self.add_set_field_action(dp, field, value, match)

    def test_action_set_field_mpls_tc(self, dp):
        field = dp.ofproto.OXM_OF_MPLS_TC
        value = 0b101

        match = dp.ofproto_parser.OFPMatch()
        match.set_dl_type(ether.ETH_TYPE_MPLS)

        self.add_set_field_action(dp, field, value, match)

    # Test of Change-TTL Actions
    def test_action_set_mpls_ttl(self, dp):
        mpls_ttl = 8
        self._verify = [dp.ofproto.OFPAT_SET_MPLS_TTL,
                        'mpls_ttl', mpls_ttl]
        actions = [dp.ofproto_parser.OFPActionSetMplsTtl(mpls_ttl), ]
        self.add_apply_actions(dp, actions)

    def test_action_dec_mpls_ttl(self, dp):
        self._verify = [dp.ofproto.OFPAT_DEC_MPLS_TTL]
        actions = [dp.ofproto_parser.OFPActionDecMplsTtl(), ]
        self.add_apply_actions(dp, actions)

    def test_action_set_nw_ttl(self, dp):
        nw_ttl = 64
        self._verify = [dp.ofproto.OFPAT_SET_NW_TTL,
                        'nw_ttl', nw_ttl]
        actions = [dp.ofproto_parser.OFPActionSetNwTtl(nw_ttl), ]
        self.add_apply_actions(dp, actions)

    def test_action_dec_nw_ttl(self, dp):
        self._verify = [dp.ofproto.OFPAT_DEC_NW_TTL]
        actions = [dp.ofproto_parser.OFPActionDecNwTtl(), ]
        self.add_apply_actions(dp, actions)

    def test_action_copy_ttl_out(self, dp):
        self._verify = [dp.ofproto.OFPAT_COPY_TTL_OUT]
        actions = [dp.ofproto_parser.OFPActionCopyTtlOut(), ]
        self.add_apply_actions(dp, actions)

    def test_action_copy_ttl_in(self, dp):
        self._verify = [dp.ofproto.OFPAT_COPY_TTL_IN]
        actions = [dp.ofproto_parser.OFPActionCopyTtlIn(), ]
        self.add_apply_actions(dp, actions)

    def is_supported(self, t):
        # Open vSwitch 1.10 does not support MPLS yet.
        unsupported = [
            'test_action_set_field_ip_proto',
            'test_action_set_field_dl_type',
            'test_action_set_field_arp',
            'test_action_set_field_ipv6',
            'test_action_set_field_icmp',
            'test_action_set_nw_ttl',
            'test_action_copy_ttl_in',
            'test_action_copy_ttl_out',
            'test_action_dec_mpls_ttl',
            'test_action_pop_mpls',
            'test_action_push_mpls',
            'test_action_set_field_mpls_label',
            'test_action_set_field_mpls_tc',
            'test_action_set_mpls_ttl'
        ]
        for u in unsupported:
            if t.find(u) != -1:
                return False

        return True

########NEW FILE########
__FILENAME__ = test_add_flow_v12_matches
# Copyright (C) 2012 Nippon Telegraph and Telephone Corporation.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# vim: tabstop=4 shiftwidth=4 softtabstop=4

import logging

from ryu.ofproto import ofproto_v1_2
from ryu.ofproto import ether
from ryu.ofproto import inet
from ryu.tests.integrated import tester

LOG = logging.getLogger(__name__)


class RunTest(tester.TestFlowBase):
    """ Test case for add flows of Matches
    """
    OFP_VERSIONS = [ofproto_v1_2.OFP_VERSION]

    def __init__(self, *args, **kwargs):
        super(RunTest, self).__init__(*args, **kwargs)

        self._verify = {}

    def add_matches(self, dp, match):
        m = dp.ofproto_parser.OFPFlowMod(dp, 0, 0, 0,
                                         dp.ofproto.OFPFC_ADD,
                                         0, 0, 0, 0xffffffff,
                                         dp.ofproto.OFPP_ANY,
                                         0xffffffff, 0, match, [])
        dp.send_msg(m)

    def _set_verify(self, headers, value, mask=None,
                    all_bits_masked=False, type_='int'):
        self._verify = {}
        self._verify['headers'] = headers
        self._verify['value'] = value
        self._verify['mask'] = mask
        self._verify['all_bits_masked'] = all_bits_masked
        self._verify['type'] = type_

    def verify_default(self, dp, stats):
        type_ = self._verify['type']
        headers = self._verify['headers']
        value = self._verify['value']
        mask = self._verify['mask']
        value_masked = self._masked(type_, value, mask)
        all_bits_masked = self._verify['all_bits_masked']

        field = None
        for s in stats:
            for f in s.match.fields:
                if f.header in headers:
                    field = f
                    break

        if field is None:
            if self._is_all_zero_bit(type_, mask):
                return True
            return 'Field not found.'

        f_value = field.value
        if hasattr(field, 'mask'):
            f_mask = field.mask
        else:
            f_mask = None

        if (f_value == value) or (f_value == value_masked):
            if (f_mask == mask) or (all_bits_masked and f_mask is None):
                return True

        return "send: %s/%s, reply: %s/%s" \
            % (self._cnv_to_str(type_, value, mask, f_value, f_mask))

    def _masked(self, type_, value, mask):
        if mask is None:
            v = value
        elif type_ == 'int':
            v = value & mask
        elif type_ == 'mac':
            v = self.haddr_masked(value, mask)
        elif type_ == 'ipv4':
            v = self.ipv4_masked(value, mask)
        elif type_ == 'ipv6':
            v = self.ipv6_masked(value, mask)
        else:
            raise 'Unknown type'
        return v

    def _is_all_zero_bit(self, type_, val):
        if type_ == 'int' or type_ == 'ipv4':
            return val == 0
        elif type_ == 'mac':
            for v in val:
                if v != '\x00':
                    return False
            return True
        elif type_ == 'ipv6':
            for v in val:
                if v != 0:
                    return False
            return True
        else:
            raise 'Unknown type'

    def _cnv_to_str(self, type_, value, mask, f_value, f_mask):
        func = None
        if type_ == 'int':
            pass
        elif type_ == 'mac':
            func = self.haddr_to_str
        elif type_ == 'ipv4':
            func = self.ipv4_to_str
        elif type_ == 'ipv6':
            func = self.ipv6_to_str
        else:
            raise 'Unknown type'

        if func:
            value = func(value)
            f_value = func(f_value)
            if mask:
                mask = func(mask)
            if f_mask:
                f_mask = func(f_mask)

        return value, mask, f_value, f_mask

    def test_rule_set_dl_dst(self, dp):
        dl_dst = 'e2:7a:09:79:0b:0f'
        dl_dst_bin = self.haddr_to_bin(dl_dst)

        headers = [dp.ofproto.OXM_OF_ETH_DST, dp.ofproto.OXM_OF_ETH_DST_W]
        self._set_verify(headers, dl_dst_bin, type_='mac')

        match = dp.ofproto_parser.OFPMatch()
        match.set_dl_dst(dl_dst_bin)
        self.add_matches(dp, match)

    def test_rule_set_dl_dst_masked_ff(self, dp):
        dl_dst = 'd0:98:79:b4:75:b5'
        dl_dst_bin = self.haddr_to_bin(dl_dst)
        mask = 'ff:ff:ff:ff:ff:ff'
        mask_bin = self.haddr_to_bin(mask)

        headers = [dp.ofproto.OXM_OF_ETH_DST, dp.ofproto.OXM_OF_ETH_DST_W]
        self._set_verify(headers, dl_dst_bin, mask_bin, True, type_='mac')

        match = dp.ofproto_parser.OFPMatch()
        match.set_dl_dst_masked(dl_dst_bin, mask_bin)
        self.add_matches(dp, match)

    def test_rule_set_dl_dst_masked_f0(self, dp):
        dl_dst = 'e2:7a:09:79:0b:0f'
        dl_dst_bin = self.haddr_to_bin(dl_dst)
        mask = 'ff:ff:ff:ff:ff:00'
        mask_bin = self.haddr_to_bin(mask)

        headers = [dp.ofproto.OXM_OF_ETH_DST, dp.ofproto.OXM_OF_ETH_DST_W]
        self._set_verify(headers, dl_dst_bin, mask_bin, type_='mac')

        match = dp.ofproto_parser.OFPMatch()
        match.set_dl_dst_masked(dl_dst_bin, mask_bin)
        self.add_matches(dp, match)

    def test_rule_set_dl_dst_masked_00(self, dp):
        dl_dst = 'e2:7a:09:79:0b:0f'
        dl_dst_bin = self.haddr_to_bin(dl_dst)
        mask = '00:00:00:00:00:00'
        mask_bin = self.haddr_to_bin(mask)

        headers = [dp.ofproto.OXM_OF_ETH_DST, dp.ofproto.OXM_OF_ETH_DST_W]
        self._set_verify(headers, dl_dst_bin, mask_bin, type_='mac')

        match = dp.ofproto_parser.OFPMatch()
        match.set_dl_dst_masked(dl_dst_bin, mask_bin)
        self.add_matches(dp, match)

    def test_rule_set_dl_src(self, dp):
        dl_src = 'e2:7a:09:79:0b:0f'
        dl_src_bin = self.haddr_to_bin(dl_src)

        headers = [dp.ofproto.OXM_OF_ETH_SRC, dp.ofproto.OXM_OF_ETH_SRC_W]
        self._set_verify(headers, dl_src_bin, type_='mac')

        match = dp.ofproto_parser.OFPMatch()
        match.set_dl_src(dl_src_bin)
        self.add_matches(dp, match)

    def test_rule_set_dl_src_masked_ff(self, dp):
        dl_src = 'e2:7a:09:79:0b:0f'
        dl_src_bin = self.haddr_to_bin(dl_src)
        mask = 'ff:ff:ff:ff:ff:ff'
        mask_bin = self.haddr_to_bin(mask)

        headers = [dp.ofproto.OXM_OF_ETH_SRC, dp.ofproto.OXM_OF_ETH_SRC_W]
        self._set_verify(headers, dl_src_bin, mask_bin, True, type_='mac')

        match = dp.ofproto_parser.OFPMatch()
        match.set_dl_src_masked(dl_src_bin, mask_bin)
        self.add_matches(dp, match)

    def test_rule_set_dl_src_masked_f0(self, dp):
        dl_src = 'e2:7a:09:79:0b:0f'
        dl_src_bin = self.haddr_to_bin(dl_src)
        mask = 'ff:ff:ff:ff:ff:00'
        mask_bin = self.haddr_to_bin(mask)

        headers = [dp.ofproto.OXM_OF_ETH_SRC, dp.ofproto.OXM_OF_ETH_SRC_W]
        self._set_verify(headers, dl_src_bin, mask_bin, type_='mac')

        match = dp.ofproto_parser.OFPMatch()
        match.set_dl_src_masked(dl_src_bin, mask_bin)
        self.add_matches(dp, match)

    def test_rule_set_dl_src_masked_00(self, dp):
        dl_src = 'e2:7a:09:79:0b:0f'
        dl_src_bin = self.haddr_to_bin(dl_src)
        mask = '00:00:00:00:00:00'
        mask_bin = self.haddr_to_bin(mask)

        headers = [dp.ofproto.OXM_OF_ETH_SRC, dp.ofproto.OXM_OF_ETH_SRC_W]
        self._set_verify(headers, dl_src_bin, mask_bin, type_='mac')

        match = dp.ofproto_parser.OFPMatch()
        match.set_dl_src_masked(dl_src_bin, mask_bin)
        self.add_matches(dp, match)

    def test_rule_set_dl_type_ip(self, dp):
        dl_type = ether.ETH_TYPE_IP

        headers = [dp.ofproto.OXM_OF_ETH_TYPE]
        self._set_verify(headers, dl_type)

        match = dp.ofproto_parser.OFPMatch()
        match.set_dl_type(dl_type)
        self.add_matches(dp, match)

    def test_rule_set_dl_type_arp(self, dp):
        dl_type = ether.ETH_TYPE_ARP

        headers = [dp.ofproto.OXM_OF_ETH_TYPE]
        self._set_verify(headers, dl_type)

        match = dp.ofproto_parser.OFPMatch()
        match.set_dl_type(dl_type)
        self.add_matches(dp, match)

    def test_rule_set_dl_type_vlan(self, dp):
        dl_type = ether.ETH_TYPE_8021Q

        headers = [dp.ofproto.OXM_OF_ETH_TYPE]
        self._set_verify(headers, dl_type)

        match = dp.ofproto_parser.OFPMatch()
        match.set_dl_type(dl_type)
        self.add_matches(dp, match)

    def test_rule_set_dl_type_ipv6(self, dp):
        dl_type = ether.ETH_TYPE_IPV6

        headers = [dp.ofproto.OXM_OF_ETH_TYPE]
        self._set_verify(headers, dl_type)

        match = dp.ofproto_parser.OFPMatch()
        match.set_dl_type(dl_type)
        self.add_matches(dp, match)

    def test_rule_set_dl_type_lacp(self, dp):
        dl_type = ether.ETH_TYPE_SLOW

        headers = [dp.ofproto.OXM_OF_ETH_TYPE]
        self._set_verify(headers, dl_type)

        match = dp.ofproto_parser.OFPMatch()
        match.set_dl_type(dl_type)
        self.add_matches(dp, match)

    def test_rule_set_ip_dscp(self, dp):
        ip_dscp = 36
        dl_type = ether.ETH_TYPE_IP

        headers = [dp.ofproto.OXM_OF_IP_DSCP]
        self._set_verify(headers, ip_dscp)

        match = dp.ofproto_parser.OFPMatch()
        match.set_dl_type(dl_type)
        match.set_ip_dscp(ip_dscp)
        self.add_matches(dp, match)

    def test_rule_set_vlan_vid(self, dp):
        vlan_vid = 0x4ef

        headers = [dp.ofproto.OXM_OF_VLAN_VID, dp.ofproto.OXM_OF_VLAN_VID_W]
        self._set_verify(headers, vlan_vid)

        match = dp.ofproto_parser.OFPMatch()
        match.set_vlan_vid(vlan_vid)
        self.add_matches(dp, match)

    def test_rule_set_vlan_vid_masked_ff(self, dp):
        vlan_vid = 0x4ef
        mask = 0xfff

        headers = [dp.ofproto.OXM_OF_VLAN_VID, dp.ofproto.OXM_OF_VLAN_VID_W]
        self._set_verify(headers, vlan_vid, mask, True)

        match = dp.ofproto_parser.OFPMatch()
        match.set_vlan_vid_masked(vlan_vid, mask)
        self.add_matches(dp, match)

    def test_rule_set_vlan_vid_masked_f0(self, dp):
        vlan_vid = 0x4ef
        mask = 0xff0

        headers = [dp.ofproto.OXM_OF_VLAN_VID, dp.ofproto.OXM_OF_VLAN_VID_W]
        self._set_verify(headers, vlan_vid, mask)

        match = dp.ofproto_parser.OFPMatch()
        match.set_vlan_vid_masked(vlan_vid, mask)
        self.add_matches(dp, match)

    def test_rule_set_vlan_vid_masked_00(self, dp):
        vlan_vid = 0x4ef
        mask = 0x000

        headers = [dp.ofproto.OXM_OF_VLAN_VID, dp.ofproto.OXM_OF_VLAN_VID_W]
        self._set_verify(headers, vlan_vid, mask)

        match = dp.ofproto_parser.OFPMatch()
        match.set_vlan_vid_masked(vlan_vid, mask)
        self.add_matches(dp, match)

    def test_rule_set_vlan_pcp(self, dp):
        vlan_vid = 0x4ef
        vlan_pcp = 5

        headers = [dp.ofproto.OXM_OF_VLAN_PCP]
        self._set_verify(headers, vlan_pcp)

        match = dp.ofproto_parser.OFPMatch()
        match.set_vlan_vid(vlan_vid)
        match.set_vlan_pcp(vlan_pcp)
        self.add_matches(dp, match)

    def test_rule_set_ip_ecn(self, dp):
        dl_type = ether.ETH_TYPE_IP
        ip_ecn = 3

        headers = [dp.ofproto.OXM_OF_IP_ECN]
        self._set_verify(headers, ip_ecn)

        match = dp.ofproto_parser.OFPMatch()
        match.set_dl_type(dl_type)
        match.set_ip_ecn(ip_ecn)
        self.add_matches(dp, match)

    def test_rule_set_ip_proto_icmp(self, dp):
        dl_type = ether.ETH_TYPE_IP
        ip_proto = inet.IPPROTO_ICMP

        headers = [dp.ofproto.OXM_OF_IP_PROTO]
        self._set_verify(headers, ip_proto)

        match = dp.ofproto_parser.OFPMatch()
        match.set_dl_type(dl_type)
        match.set_ip_proto(ip_proto)
        self.add_matches(dp, match)

    def test_rule_set_ip_proto_tcp(self, dp):
        dl_type = ether.ETH_TYPE_IP
        ip_proto = inet.IPPROTO_TCP

        headers = [dp.ofproto.OXM_OF_IP_PROTO]
        self._set_verify(headers, ip_proto)

        match = dp.ofproto_parser.OFPMatch()
        match.set_dl_type(dl_type)
        match.set_ip_proto(ip_proto)
        self.add_matches(dp, match)

    def test_rule_set_ip_proto_udp(self, dp):
        dl_type = ether.ETH_TYPE_IP
        ip_proto = inet.IPPROTO_UDP

        headers = [dp.ofproto.OXM_OF_IP_PROTO]
        self._set_verify(headers, ip_proto)

        match = dp.ofproto_parser.OFPMatch()
        match.set_dl_type(dl_type)
        match.set_ip_proto(ip_proto)
        self.add_matches(dp, match)

    def test_rule_set_ip_proto_ipv6_route(self, dp):
        dl_type = ether.ETH_TYPE_IPV6
        ip_proto = inet.IPPROTO_ROUTING

        headers = [dp.ofproto.OXM_OF_IP_PROTO]
        self._set_verify(headers, ip_proto)

        match = dp.ofproto_parser.OFPMatch()
        match.set_dl_type(dl_type)
        match.set_ip_proto(ip_proto)
        self.add_matches(dp, match)

    def test_rule_set_ip_proto_ipv6_frag(self, dp):
        dl_type = ether.ETH_TYPE_IPV6
        ip_proto = inet.IPPROTO_FRAGMENT

        headers = [dp.ofproto.OXM_OF_IP_PROTO]
        self._set_verify(headers, ip_proto)

        match = dp.ofproto_parser.OFPMatch()
        match.set_dl_type(dl_type)
        match.set_ip_proto(ip_proto)
        self.add_matches(dp, match)

    def test_rule_set_ip_proto_ipv6_icmp(self, dp):
        dl_type = ether.ETH_TYPE_IPV6
        ip_proto = inet.IPPROTO_ICMPV6

        headers = [dp.ofproto.OXM_OF_IP_PROTO]
        self._set_verify(headers, ip_proto)

        match = dp.ofproto_parser.OFPMatch()
        match.set_dl_type(dl_type)
        match.set_ip_proto(ip_proto)
        self.add_matches(dp, match)

    def test_rule_set_ip_proto_ipv6_none(self, dp):
        dl_type = ether.ETH_TYPE_IPV6
        ip_proto = inet.IPPROTO_NONE

        headers = [dp.ofproto.OXM_OF_IP_PROTO]
        self._set_verify(headers, ip_proto)

        match = dp.ofproto_parser.OFPMatch()
        match.set_dl_type(dl_type)
        match.set_ip_proto(ip_proto)
        self.add_matches(dp, match)

    def test_rule_set_ip_proto_ipv6_dstopts(self, dp):
        dl_type = ether.ETH_TYPE_IPV6
        ip_proto = inet.IPPROTO_DSTOPTS

        headers = [dp.ofproto.OXM_OF_IP_PROTO]
        self._set_verify(headers, ip_proto)

        match = dp.ofproto_parser.OFPMatch()
        match.set_dl_type(dl_type)
        match.set_ip_proto(ip_proto)
        self.add_matches(dp, match)

    def test_rule_set_ipv4_src(self, dp):
        dl_type = ether.ETH_TYPE_IP
        src = '192.168.196.250'
        src_int = self.ipv4_to_int(src)

        headers = [dp.ofproto.OXM_OF_IPV4_SRC, dp.ofproto.OXM_OF_IPV4_SRC_W]
        self._set_verify(headers, src_int, type_='ipv4')

        match = dp.ofproto_parser.OFPMatch()
        match.set_dl_type(dl_type)
        match.set_ipv4_src(src_int)
        self.add_matches(dp, match)

    def test_rule_set_ipv4_src_masked_32(self, dp):
        dl_type = ether.ETH_TYPE_IP
        src = '192.168.196.250'
        src_int = self.ipv4_to_int(src)
        mask = '255.255.255.255'
        mask_int = self.ipv4_to_int(mask)

        headers = [dp.ofproto.OXM_OF_IPV4_SRC, dp.ofproto.OXM_OF_IPV4_SRC_W]
        self._set_verify(headers, src_int, mask_int, True, type_='ipv4')

        match = dp.ofproto_parser.OFPMatch()
        match.set_dl_type(dl_type)
        match.set_ipv4_src_masked(src_int, mask_int)
        self.add_matches(dp, match)

    def test_rule_set_ipv4_src_masked_24(self, dp):
        dl_type = ether.ETH_TYPE_IP
        src = '192.168.196.250'
        src_int = self.ipv4_to_int(src)
        mask = '255.255.255.0'
        mask_int = self.ipv4_to_int(mask)

        headers = [dp.ofproto.OXM_OF_IPV4_SRC, dp.ofproto.OXM_OF_IPV4_SRC_W]
        self._set_verify(headers, src_int, mask_int, type_='ipv4')

        match = dp.ofproto_parser.OFPMatch()
        match.set_dl_type(dl_type)
        match.set_ipv4_src_masked(src_int, mask_int)
        self.add_matches(dp, match)

    def test_rule_set_ipv4_src_masked_0(self, dp):
        dl_type = ether.ETH_TYPE_IP
        src = '192.168.196.250'
        src_int = self.ipv4_to_int(src)
        mask = '0.0.0.0'
        mask_int = self.ipv4_to_int(mask)

        headers = [dp.ofproto.OXM_OF_IPV4_SRC, dp.ofproto.OXM_OF_IPV4_SRC_W]
        self._set_verify(headers, src_int, mask_int, type_='ipv4')

        match = dp.ofproto_parser.OFPMatch()
        match.set_dl_type(dl_type)
        match.set_ipv4_src_masked(src_int, mask_int)
        self.add_matches(dp, match)

    def test_rule_set_ipv4_dst(self, dp):
        dl_type = ether.ETH_TYPE_IP
        dst = '192.168.54.155'
        dst_int = self.ipv4_to_int(dst)

        headers = [dp.ofproto.OXM_OF_IPV4_DST, dp.ofproto.OXM_OF_IPV4_DST_W]
        self._set_verify(headers, dst_int, type_='ipv4')

        match = dp.ofproto_parser.OFPMatch()
        match.set_dl_type(dl_type)
        match.set_ipv4_dst(dst_int)
        self.add_matches(dp, match)

    def test_rule_set_ipv4_dst_masked_32(self, dp):
        dl_type = ether.ETH_TYPE_IP
        dst = '192.168.54.155'
        dst_int = self.ipv4_to_int(dst)
        mask = '255.255.255.255'
        mask_int = self.ipv4_to_int(mask)

        headers = [dp.ofproto.OXM_OF_IPV4_DST, dp.ofproto.OXM_OF_IPV4_DST_W]
        self._set_verify(headers, dst_int, mask_int, True, type_='ipv4')

        match = dp.ofproto_parser.OFPMatch()
        match.set_dl_type(dl_type)
        match.set_ipv4_dst_masked(dst_int, mask_int)
        self.add_matches(dp, match)

    def test_rule_set_ipv4_dst_masked_24(self, dp):
        dl_type = ether.ETH_TYPE_IP
        dst = '192.168.54.155'
        dst_int = self.ipv4_to_int(dst)
        mask = '255.255.255.0'
        mask_int = self.ipv4_to_int(mask)

        headers = [dp.ofproto.OXM_OF_IPV4_DST, dp.ofproto.OXM_OF_IPV4_DST_W]
        self._set_verify(headers, dst_int, mask_int, type_='ipv4')

        match = dp.ofproto_parser.OFPMatch()
        match.set_dl_type(dl_type)
        match.set_ipv4_dst_masked(dst_int, mask_int)
        self.add_matches(dp, match)

    def test_rule_set_ipv4_dst_masked_0(self, dp):
        dl_type = ether.ETH_TYPE_IP
        dst = '192.168.54.155'
        dst_int = self.ipv4_to_int(dst)
        mask = '0.0.0.0'
        mask_int = self.ipv4_to_int(mask)

        headers = [dp.ofproto.OXM_OF_IPV4_DST, dp.ofproto.OXM_OF_IPV4_DST_W]
        self._set_verify(headers, dst_int, mask_int, type_='ipv4')

        match = dp.ofproto_parser.OFPMatch()
        match.set_dl_type(dl_type)
        match.set_ipv4_dst_masked(dst_int, mask_int)
        self.add_matches(dp, match)

    def test_rule_set_tcp_src(self, dp):
        dl_type = ether.ETH_TYPE_IP
        ip_proto = inet.IPPROTO_TCP
        tp_src = 1103

        headers = [dp.ofproto.OXM_OF_TCP_SRC]
        self._set_verify(headers, tp_src)

        match = dp.ofproto_parser.OFPMatch()
        match.set_dl_type(dl_type)
        match.set_ip_proto(ip_proto)
        match.set_tcp_src(tp_src)
        self.add_matches(dp, match)

    def test_rule_set_tcp_dst(self, dp):
        dl_type = ether.ETH_TYPE_IP
        ip_proto = inet.IPPROTO_TCP
        tp_dst = 236

        headers = [dp.ofproto.OXM_OF_TCP_DST]
        self._set_verify(headers, tp_dst)

        match = dp.ofproto_parser.OFPMatch()
        match.set_dl_type(dl_type)
        match.set_ip_proto(ip_proto)
        match.set_tcp_dst(tp_dst)
        self.add_matches(dp, match)

    def test_rule_set_udp_src(self, dp):
        dl_type = ether.ETH_TYPE_IP
        ip_proto = inet.IPPROTO_UDP
        tp_src = 56617

        headers = [dp.ofproto.OXM_OF_UDP_SRC]
        self._set_verify(headers, tp_src)

        match = dp.ofproto_parser.OFPMatch()
        match.set_dl_type(dl_type)
        match.set_ip_proto(ip_proto)
        match.set_udp_src(tp_src)
        self.add_matches(dp, match)

    def test_rule_set_udp_dst(self, dp):
        dl_type = ether.ETH_TYPE_IP
        ip_proto = inet.IPPROTO_UDP
        tp_dst = 61278

        headers = [dp.ofproto.OXM_OF_UDP_DST]
        self._set_verify(headers, tp_dst)

        match = dp.ofproto_parser.OFPMatch()
        match.set_dl_type(dl_type)
        match.set_ip_proto(ip_proto)
        match.set_udp_dst(tp_dst)
        self.add_matches(dp, match)

    def test_rule_set_icmpv4_type(self, dp):
        dl_type = ether.ETH_TYPE_IP
        ip_proto = inet.IPPROTO_ICMP
        icmp_type = 8

        headers = [dp.ofproto.OXM_OF_ICMPV4_TYPE]
        self._set_verify(headers, icmp_type)

        match = dp.ofproto_parser.OFPMatch()
        match.set_dl_type(dl_type)
        match.set_ip_proto(ip_proto)
        match.set_icmpv4_type(icmp_type)
        self.add_matches(dp, match)

    def test_rule_set_icmpv4_code(self, dp):
        dl_type = ether.ETH_TYPE_IP
        ip_proto = inet.IPPROTO_ICMP
        icmp_type = 9
        icmp_code = 16

        headers = [dp.ofproto.OXM_OF_ICMPV4_CODE]
        self._set_verify(headers, icmp_code)

        match = dp.ofproto_parser.OFPMatch()
        match.set_dl_type(dl_type)
        match.set_ip_proto(ip_proto)
        match.set_icmpv4_type(icmp_type)
        match.set_icmpv4_code(icmp_code)
        self.add_matches(dp, match)

    def test_rule_set_arp_opcode(self, dp):
        dl_type = ether.ETH_TYPE_ARP
        arp_op = 1

        headers = [dp.ofproto.OXM_OF_ARP_OP]
        self._set_verify(headers, arp_op)

        match = dp.ofproto_parser.OFPMatch()
        match.set_dl_type(dl_type)
        match.set_arp_opcode(arp_op)
        self.add_matches(dp, match)

    def test_rule_set_arp_spa(self, dp):
        dl_type = ether.ETH_TYPE_ARP
        nw_src = '192.168.222.57'
        nw_src_int = self.ipv4_to_int(nw_src)

        headers = [dp.ofproto.OXM_OF_ARP_SPA, dp.ofproto.OXM_OF_ARP_SPA_W]
        self._set_verify(headers, nw_src_int, type_='ipv4')

        match = dp.ofproto_parser.OFPMatch()
        match.set_dl_type(dl_type)
        match.set_arp_spa(nw_src_int)
        self.add_matches(dp, match)

    def test_rule_set_arp_spa_masked_32(self, dp):
        dl_type = ether.ETH_TYPE_ARP
        nw_src = '192.168.222.57'
        nw_src_int = self.ipv4_to_int(nw_src)
        mask = '255.255.255.255'
        mask_int = self.ipv4_to_int(mask)

        headers = [dp.ofproto.OXM_OF_ARP_SPA, dp.ofproto.OXM_OF_ARP_SPA_W]
        self._set_verify(headers, nw_src_int, mask_int, True, type_='ipv4')

        match = dp.ofproto_parser.OFPMatch()
        match.set_dl_type(dl_type)
        match.set_arp_spa_masked(nw_src_int, mask_int)
        self.add_matches(dp, match)

    def test_rule_set_arp_spa_masked_24(self, dp):
        dl_type = ether.ETH_TYPE_ARP
        nw_src = '192.168.222.57'
        nw_src_int = self.ipv4_to_int(nw_src)
        mask = '255.255.255.0'
        mask_int = self.ipv4_to_int(mask)

        headers = [dp.ofproto.OXM_OF_ARP_SPA, dp.ofproto.OXM_OF_ARP_SPA_W]
        self._set_verify(headers, nw_src_int, mask_int, type_='ipv4')

        match = dp.ofproto_parser.OFPMatch()
        match.set_dl_type(dl_type)
        match.set_arp_spa_masked(nw_src_int, mask_int)
        self.add_matches(dp, match)

    def test_rule_set_arp_spa_masked_00(self, dp):
        dl_type = ether.ETH_TYPE_ARP
        nw_src = '192.168.222.57'
        nw_src_int = self.ipv4_to_int(nw_src)
        mask = '0.0.0.0'
        mask_int = self.ipv4_to_int(mask)

        headers = [dp.ofproto.OXM_OF_ARP_SPA, dp.ofproto.OXM_OF_ARP_SPA_W]
        self._set_verify(headers, nw_src_int, mask_int, type_='ipv4')

        match = dp.ofproto_parser.OFPMatch()
        match.set_dl_type(dl_type)
        match.set_arp_spa_masked(nw_src_int, mask_int)
        self.add_matches(dp, match)

    def test_rule_set_arp_tpa(self, dp):
        dl_type = ether.ETH_TYPE_ARP
        nw_dst = '192.168.198.233'
        nw_dst_int = self.ipv4_to_int(nw_dst)

        headers = [dp.ofproto.OXM_OF_ARP_TPA, dp.ofproto.OXM_OF_ARP_TPA_W]
        self._set_verify(headers, nw_dst_int, type_='ipv4')

        match = dp.ofproto_parser.OFPMatch()
        match.set_dl_type(dl_type)
        match.set_arp_tpa(nw_dst_int)
        self.add_matches(dp, match)

    def test_rule_set_arp_tpa_masked_32(self, dp):
        dl_type = ether.ETH_TYPE_ARP
        nw_dst = '192.168.198.233'
        nw_dst_int = self.ipv4_to_int(nw_dst)
        mask = '255.255.255.255'
        mask_int = self.ipv4_to_int(mask)

        headers = [dp.ofproto.OXM_OF_ARP_TPA, dp.ofproto.OXM_OF_ARP_TPA_W]
        self._set_verify(headers, nw_dst_int, mask_int, True, type_='ipv4')

        match = dp.ofproto_parser.OFPMatch()
        match.set_dl_type(dl_type)
        match.set_arp_tpa_masked(nw_dst_int, mask_int)
        self.add_matches(dp, match)

    def test_rule_set_arp_tpa_masked_24(self, dp):
        dl_type = ether.ETH_TYPE_ARP
        nw_dst = '192.168.198.233'
        nw_dst_int = self.ipv4_to_int(nw_dst)
        mask = '255.255.255.0'
        mask_int = self.ipv4_to_int(mask)

        headers = [dp.ofproto.OXM_OF_ARP_TPA, dp.ofproto.OXM_OF_ARP_TPA_W]
        self._set_verify(headers, nw_dst_int, mask_int, type_='ipv4')

        match = dp.ofproto_parser.OFPMatch()
        match.set_dl_type(dl_type)
        match.set_arp_tpa_masked(nw_dst_int, mask_int)
        self.add_matches(dp, match)

    def test_rule_set_arp_tpa_masked_00(self, dp):
        dl_type = ether.ETH_TYPE_ARP
        nw_dst = '192.168.198.233'
        nw_dst_int = self.ipv4_to_int(nw_dst)
        mask = '0.0.0.0'
        mask_int = self.ipv4_to_int(mask)

        headers = [dp.ofproto.OXM_OF_ARP_TPA, dp.ofproto.OXM_OF_ARP_TPA_W]
        self._set_verify(headers, nw_dst_int, mask_int, type_='ipv4')

        match = dp.ofproto_parser.OFPMatch()
        match.set_dl_type(dl_type)
        match.set_arp_tpa_masked(nw_dst_int, mask_int)
        self.add_matches(dp, match)

    def test_rule_set_arp_sha(self, dp):
        dl_type = ether.ETH_TYPE_ARP
        arp_sha = '3e:ec:13:9b:f3:0b'
        arp_sha_bin = self.haddr_to_bin(arp_sha)

        headers = [dp.ofproto.OXM_OF_ARP_SHA, dp.ofproto.OXM_OF_ARP_SHA_W]
        self._set_verify(headers, arp_sha_bin, type_='mac')

        match = dp.ofproto_parser.OFPMatch()
        match.set_dl_type(dl_type)
        match.set_arp_sha(arp_sha_bin)
        self.add_matches(dp, match)

    def test_rule_set_arp_sha_masked_ff(self, dp):
        dl_type = ether.ETH_TYPE_ARP
        arp_sha = '3e:ec:13:9b:f3:0b'
        arp_sha_bin = self.haddr_to_bin(arp_sha)
        mask = 'ff:ff:ff:ff:ff:ff'
        mask_bin = self.haddr_to_bin(mask)

        headers = [dp.ofproto.OXM_OF_ARP_SHA, dp.ofproto.OXM_OF_ARP_SHA_W]
        self._set_verify(headers, arp_sha_bin, mask_bin, True, type_='mac')

        match = dp.ofproto_parser.OFPMatch()
        match.set_dl_type(dl_type)
        match.set_arp_sha_masked(arp_sha_bin, mask_bin)
        self.add_matches(dp, match)

    def test_rule_set_arp_sha_masked_f0(self, dp):
        dl_type = ether.ETH_TYPE_ARP
        arp_sha = '3e:ec:13:9b:f3:0b'
        arp_sha_bin = self.haddr_to_bin(arp_sha)
        mask = 'ff:ff:ff:ff:ff:00'
        mask_bin = self.haddr_to_bin(mask)

        headers = [dp.ofproto.OXM_OF_ARP_SHA, dp.ofproto.OXM_OF_ARP_SHA_W]
        self._set_verify(headers, arp_sha_bin, mask_bin, type_='mac')

        match = dp.ofproto_parser.OFPMatch()
        match.set_dl_type(dl_type)
        match.set_arp_sha_masked(arp_sha_bin, mask_bin)
        self.add_matches(dp, match)

    def test_rule_set_arp_sha_masked_00(self, dp):
        dl_type = ether.ETH_TYPE_ARP
        arp_sha = '3e:ec:13:9b:f3:0b'
        arp_sha_bin = self.haddr_to_bin(arp_sha)
        mask = '00:00:00:00:00:00'
        mask_bin = self.haddr_to_bin(mask)

        headers = [dp.ofproto.OXM_OF_ARP_SHA, dp.ofproto.OXM_OF_ARP_SHA_W]
        self._set_verify(headers, arp_sha_bin, mask_bin, type_='mac')

        match = dp.ofproto_parser.OFPMatch()
        match.set_dl_type(dl_type)
        match.set_arp_sha_masked(arp_sha_bin, mask_bin)
        self.add_matches(dp, match)

    def test_rule_set_arp_tha(self, dp):
        dl_type = ether.ETH_TYPE_ARP
        arp_tha = '83:6c:21:52:49:68'
        arp_tha_bin = self.haddr_to_bin(arp_tha)

        headers = [dp.ofproto.OXM_OF_ARP_THA, dp.ofproto.OXM_OF_ARP_THA_W]
        self._set_verify(headers, arp_tha_bin, type_='mac')

        match = dp.ofproto_parser.OFPMatch()
        match.set_dl_type(dl_type)
        match.set_arp_tha(arp_tha_bin)
        self.add_matches(dp, match)

    def test_rule_set_arp_tha_masked_ff(self, dp):
        dl_type = ether.ETH_TYPE_ARP
        arp_tha = '83:6c:21:52:49:68'
        arp_tha_bin = self.haddr_to_bin(arp_tha)
        mask = 'ff:ff:ff:ff:ff:ff'
        mask_bin = self.haddr_to_bin(mask)

        headers = [dp.ofproto.OXM_OF_ARP_THA, dp.ofproto.OXM_OF_ARP_THA_W]
        self._set_verify(headers, arp_tha_bin, mask_bin, True, type_='mac')

        match = dp.ofproto_parser.OFPMatch()
        match.set_dl_type(dl_type)
        match.set_arp_tha_masked(arp_tha_bin, mask_bin)
        self.add_matches(dp, match)

    def test_rule_set_arp_tha_masked_f0(self, dp):
        dl_type = ether.ETH_TYPE_ARP
        arp_tha = '83:6c:21:52:49:68'
        arp_tha_bin = self.haddr_to_bin(arp_tha)
        mask = 'ff:ff:ff:ff:ff:00'
        mask_bin = self.haddr_to_bin(mask)

        headers = [dp.ofproto.OXM_OF_ARP_THA, dp.ofproto.OXM_OF_ARP_THA_W]
        self._set_verify(headers, arp_tha_bin, mask_bin, type_='mac')

        match = dp.ofproto_parser.OFPMatch()
        match.set_dl_type(dl_type)
        match.set_arp_tha_masked(arp_tha_bin, mask_bin)
        self.add_matches(dp, match)

    def test_rule_set_arp_tha_masked_00(self, dp):
        dl_type = ether.ETH_TYPE_ARP
        arp_tha = '83:6c:21:52:49:68'
        arp_tha_bin = self.haddr_to_bin(arp_tha)
        mask = '00:00:00:00:00:00'
        mask_bin = self.haddr_to_bin(mask)

        headers = [dp.ofproto.OXM_OF_ARP_THA, dp.ofproto.OXM_OF_ARP_THA_W]
        self._set_verify(headers, arp_tha_bin, mask_bin, type_='mac')

        match = dp.ofproto_parser.OFPMatch()
        match.set_dl_type(dl_type)
        match.set_arp_tha_masked(arp_tha_bin, mask_bin)
        self.add_matches(dp, match)

    def test_rule_set_ipv6_src(self, dp):
        dl_type = ether.ETH_TYPE_IPV6
        ipv6_src = '2001:db8:bd05:1d2:288a:1fc0:1:10ee'
        ipv6_src_int = self.ipv6_to_int(ipv6_src)

        headers = [dp.ofproto.OXM_OF_IPV6_SRC, dp.ofproto.OXM_OF_IPV6_SRC_W]
        self._set_verify(headers, ipv6_src_int, type_='ipv6')

        match = dp.ofproto_parser.OFPMatch()
        match.set_dl_type(dl_type)
        match.set_ipv6_src(ipv6_src_int)
        self.add_matches(dp, match)

    def test_rule_set_ipv6_src_masked_ff(self, dp):
        dl_type = ether.ETH_TYPE_IPV6
        ipv6_src = '2001:db8:bd05:1d2:288a:1fc0:1:10ee'
        ipv6_src_int = self.ipv6_to_int(ipv6_src)
        mask = 'ffff:ffff:ffff:ffff:ffff:ffff:ffff:ffff'
        mask_int = self.ipv6_to_int(mask)

        headers = [dp.ofproto.OXM_OF_IPV6_SRC, dp.ofproto.OXM_OF_IPV6_SRC_W]
        self._set_verify(headers, ipv6_src_int, mask_int, True, type_='ipv6')

        match = dp.ofproto_parser.OFPMatch()
        match.set_dl_type(dl_type)
        match.set_ipv6_src_masked(ipv6_src_int, mask_int)
        self.add_matches(dp, match)

    def test_rule_set_ipv6_src_masked_f0(self, dp):
        dl_type = ether.ETH_TYPE_IPV6
        ipv6_src = '2001:db8:bd05:1d2:288a:1fc0:1:10ee'
        ipv6_src_int = self.ipv6_to_int(ipv6_src)
        mask = 'ffff:ffff:ffff:ffff:ffff:ffff:ffff:0'
        mask_int = self.ipv6_to_int(mask)

        headers = [dp.ofproto.OXM_OF_IPV6_SRC, dp.ofproto.OXM_OF_IPV6_SRC_W]
        self._set_verify(headers, ipv6_src_int, mask_int, type_='ipv6')

        match = dp.ofproto_parser.OFPMatch()
        match.set_dl_type(dl_type)
        match.set_ipv6_src_masked(ipv6_src_int, mask_int)
        self.add_matches(dp, match)

    def test_rule_set_ipv6_src_masked_00(self, dp):
        dl_type = ether.ETH_TYPE_IPV6
        ipv6_src = '2001:db8:bd05:1d2:288a:1fc0:1:10ee'
        ipv6_src_int = self.ipv6_to_int(ipv6_src)
        mask = '0:0:0:0:0:0:0:0'
        mask_int = self.ipv6_to_int(mask)

        headers = [dp.ofproto.OXM_OF_IPV6_SRC, dp.ofproto.OXM_OF_IPV6_SRC_W]
        self._set_verify(headers, ipv6_src_int, mask_int, type_='ipv6')

        match = dp.ofproto_parser.OFPMatch()
        match.set_dl_type(dl_type)
        match.set_ipv6_src_masked(ipv6_src_int, mask_int)
        self.add_matches(dp, match)

    def test_rule_set_ipv6_dst(self, dp):
        dl_type = ether.ETH_TYPE_IPV6
        ipv6_dst = 'e9e8:9ea5:7d67:82cc:ca54:1fc0:2d24:f038'
        ipv6_dst_int = self.ipv6_to_int(ipv6_dst)

        headers = [dp.ofproto.OXM_OF_IPV6_DST, dp.ofproto.OXM_OF_IPV6_DST_W]
        self._set_verify(headers, ipv6_dst_int, type_='ipv6')

        match = dp.ofproto_parser.OFPMatch()
        match.set_dl_type(dl_type)
        match.set_ipv6_dst(ipv6_dst_int)
        self.add_matches(dp, match)

    def test_rule_set_ipv6_dst_masked_ff(self, dp):
        dl_type = ether.ETH_TYPE_IPV6
        ipv6_dst = 'e9e8:9ea5:7d67:82cc:ca54:1fc0:2d24:f038'
        ipv6_dst_int = self.ipv6_to_int(ipv6_dst)
        mask = 'ffff:ffff:ffff:ffff:ffff:ffff:ffff:ffff'
        mask_int = self.ipv6_to_int(mask)

        headers = [dp.ofproto.OXM_OF_IPV6_DST, dp.ofproto.OXM_OF_IPV6_DST_W]
        self._set_verify(headers, ipv6_dst_int, mask_int, True, type_='ipv6')

        match = dp.ofproto_parser.OFPMatch()
        match.set_dl_type(dl_type)
        match.set_ipv6_dst_masked(ipv6_dst_int, mask_int)
        self.add_matches(dp, match)

    def test_rule_set_ipv6_dst_masked_f0(self, dp):
        dl_type = ether.ETH_TYPE_IPV6
        ipv6_dst = 'e9e8:9ea5:7d67:82cc:ca54:1fc0:2d24:f038'
        ipv6_dst_int = self.ipv6_to_int(ipv6_dst)
        mask = 'ffff:ffff:ffff:ffff:ffff:ffff:ffff:0'
        mask_int = self.ipv6_to_int(mask)

        headers = [dp.ofproto.OXM_OF_IPV6_DST, dp.ofproto.OXM_OF_IPV6_DST_W]
        self._set_verify(headers, ipv6_dst_int, mask_int, type_='ipv6')

        match = dp.ofproto_parser.OFPMatch()
        match.set_dl_type(dl_type)
        match.set_ipv6_dst_masked(ipv6_dst_int, mask_int)
        self.add_matches(dp, match)

    def test_rule_set_ipv6_dst_masked_00(self, dp):
        dl_type = ether.ETH_TYPE_IPV6
        ipv6_dst = 'e9e8:9ea5:7d67:82cc:ca54:1fc0:2d24:f038'
        ipv6_dst_int = self.ipv6_to_int(ipv6_dst)
        mask = '0:0:0:0:0:0:0:0'
        mask_int = self.ipv6_to_int(mask)

        headers = [dp.ofproto.OXM_OF_IPV6_DST, dp.ofproto.OXM_OF_IPV6_DST_W]
        self._set_verify(headers, ipv6_dst_int, mask_int, type_='ipv6')

        match = dp.ofproto_parser.OFPMatch()
        match.set_dl_type(dl_type)
        match.set_ipv6_dst_masked(ipv6_dst_int, mask_int)
        self.add_matches(dp, match)

    def test_rule_set_ipv6_flabel(self, dp):
        dl_type = ether.ETH_TYPE_IPV6
        ipv6_label = 0xc5384

        headers = [dp.ofproto.OXM_OF_IPV6_FLABEL,
                   dp.ofproto.OXM_OF_IPV6_FLABEL_W]
        self._set_verify(headers, ipv6_label)

        match = dp.ofproto_parser.OFPMatch()
        match.set_dl_type(dl_type)
        match.set_ipv6_flabel(ipv6_label)
        self.add_matches(dp, match)

    def test_rule_set_ipv6_flabel_masked_ff(self, dp):
        dl_type = ether.ETH_TYPE_IPV6
        ipv6_label = 0xc5384
        mask = 0xfffff

        headers = [dp.ofproto.OXM_OF_IPV6_FLABEL,
                   dp.ofproto.OXM_OF_IPV6_FLABEL_W]
        self._set_verify(headers, ipv6_label, mask, True)

        match = dp.ofproto_parser.OFPMatch()
        match.set_dl_type(dl_type)
        match.set_ipv6_flabel_masked(ipv6_label, mask)
        self.add_matches(dp, match)

    def test_rule_set_ipv6_flabel_masked_f0(self, dp):
        dl_type = ether.ETH_TYPE_IPV6
        ipv6_label = 0xc5384
        mask = 0xffff0

        headers = [dp.ofproto.OXM_OF_IPV6_FLABEL,
                   dp.ofproto.OXM_OF_IPV6_FLABEL_W]
        self._set_verify(headers, ipv6_label, mask)

        match = dp.ofproto_parser.OFPMatch()
        match.set_dl_type(dl_type)
        match.set_ipv6_flabel_masked(ipv6_label, mask)
        self.add_matches(dp, match)

    def test_rule_set_ipv6_flabel_masked_00(self, dp):
        dl_type = ether.ETH_TYPE_IPV6
        ipv6_label = 0xc5384
        mask = 0x0

        headers = [dp.ofproto.OXM_OF_IPV6_FLABEL,
                   dp.ofproto.OXM_OF_IPV6_FLABEL_W]
        self._set_verify(headers, ipv6_label, mask)

        match = dp.ofproto_parser.OFPMatch()
        match.set_dl_type(dl_type)
        match.set_ipv6_flabel_masked(ipv6_label, mask)
        self.add_matches(dp, match)

    def test_rule_set_icmpv6_type(self, dp):
        dl_type = ether.ETH_TYPE_IPV6
        ip_proto = inet.IPPROTO_ICMPV6
        icmp_type = 129

        headers = [dp.ofproto.OXM_OF_ICMPV6_TYPE]
        self._set_verify(headers, icmp_type)

        match = dp.ofproto_parser.OFPMatch()
        match.set_dl_type(dl_type)
        match.set_ip_proto(ip_proto)
        match.set_icmpv6_type(icmp_type)
        self.add_matches(dp, match)

    def test_rule_set_icmpv6_code(self, dp):
        dl_type = ether.ETH_TYPE_IPV6
        ip_proto = inet.IPPROTO_ICMPV6
        icmp_type = 138
        icmp_code = 1

        headers = [dp.ofproto.OXM_OF_ICMPV6_CODE]
        self._set_verify(headers, icmp_code)

        match = dp.ofproto_parser.OFPMatch()
        match.set_dl_type(dl_type)
        match.set_ip_proto(ip_proto)
        match.set_icmpv6_type(icmp_type)
        match.set_icmpv6_code(icmp_code)
        self.add_matches(dp, match)

    def test_rule_set_ipv6_nd_target(self, dp):
        dl_type = ether.ETH_TYPE_IPV6
        ip_proto = inet.IPPROTO_ICMPV6
        icmp_type = 135
        target = "5420:db3f:921b:3e33:2791:98f:dd7f:2e19"
        target_int = self.ipv6_to_int(target)

        headers = [dp.ofproto.OXM_OF_IPV6_ND_TARGET]
        self._set_verify(headers, target_int, type_='ipv6')

        match = dp.ofproto_parser.OFPMatch()
        match.set_dl_type(dl_type)
        match.set_ip_proto(ip_proto)
        match.set_icmpv6_type(icmp_type)
        match.set_ipv6_nd_target(target_int)
        self.add_matches(dp, match)

    def test_rule_set_ipv6_nd_sll(self, dp):
        dl_type = ether.ETH_TYPE_IPV6
        ip_proto = inet.IPPROTO_ICMPV6
        icmp_type = 135
        nd_sll = "93:6d:d0:d4:e8:36"
        nd_sll_bin = self.haddr_to_bin(nd_sll)

        headers = [dp.ofproto.OXM_OF_IPV6_ND_SLL]
        self._set_verify(headers, nd_sll_bin, type_='mac')

        match = dp.ofproto_parser.OFPMatch()
        match.set_dl_type(dl_type)
        match.set_ip_proto(ip_proto)
        match.set_icmpv6_type(icmp_type)
        match.set_ipv6_nd_sll(nd_sll_bin)
        self.add_matches(dp, match)

    def test_rule_set_ipv6_nd_tll(self, dp):
        dl_type = ether.ETH_TYPE_IPV6
        ip_proto = inet.IPPROTO_ICMPV6
        icmp_type = 136
        nd_tll = "18:f6:66:b6:f1:b3"
        nd_tll_bin = self.haddr_to_bin(nd_tll)

        headers = [dp.ofproto.OXM_OF_IPV6_ND_TLL]
        self._set_verify(headers, nd_tll_bin, type_='mac')

        match = dp.ofproto_parser.OFPMatch()
        match.set_dl_type(dl_type)
        match.set_ip_proto(ip_proto)
        match.set_icmpv6_type(icmp_type)
        match.set_ipv6_nd_tll(nd_tll_bin)
        self.add_matches(dp, match)

    def test_rule_set_mpls_label(self, dp):
        dl_type = 0x8847
        label = 2144

        headers = [dp.ofproto.OXM_OF_MPLS_LABEL]
        self._set_verify(headers, label)

        match = dp.ofproto_parser.OFPMatch()
        match.set_dl_type(dl_type)
        match.set_mpls_label(label)
        self.add_matches(dp, match)

    def test_rule_set_mpls_tc(self, dp):
        dl_type = 0x8847
        tc = 3

        headers = [dp.ofproto.OXM_OF_MPLS_TC]
        self._set_verify(headers, tc)

        match = dp.ofproto_parser.OFPMatch()
        match.set_dl_type(dl_type)
        match.set_mpls_tc(tc)
        self.add_matches(dp, match)

    def is_supported(self, t):
        # Open vSwitch 1.10 does not support MPLS yet.
        unsupported = [
            'test_rule_set_mpls_label',
            'test_rule_set_mpls_tc',
        ]
        for u in unsupported:
            if t.find(u) != -1:
                return False

        return True

########NEW FILE########
__FILENAME__ = test_of_config
# Copyright (C) 2013 Nippon Telegraph and Telephone Corporation.
# Copyright (C) 2013 Isaku Yamahata <yamahata at private email ne jp>
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""
How to run this test

edit linc config file. LINC-Switch/rel/linc/releases/1.0/sys.config
You can find the sample config I used for the test below

For this following config to work, the network interface
linc-port and linc-port2 must be created before hand.
(Or edit the port name depending on your environment)
An easy way is to create them as follows
# ip link add linc-port type veth peer name linc-port-peer
# ip link set linc-port up
# ip link add linc-port2 type veth peer name linc-port-peer2
# ip link set linc-port2 up

Then run linc
# rel/linc/bin/linc console

Then run ryu
# PYTHONPATH=. ./bin/ryu-manager --verbose \
        ryu/tests/integrated/test_of_config.py


Here is my sys.config used for this test.
-->8-->8-->8-->8-->8-->8-->8-->8-->8-->8-->8-->8-->8---
[
 {linc,
  [
   {of_config, enabled},

   {logical_switches,
    [
     {switch, 0,
      [
       {backend, linc_us4},

       {controllers,
        [
         {"Switch0-DefaultController", "localhost", 6633, tcp}
        ]},

       {ports,
        [
         {port, 1, [{interface, "linc-port"}]},
         {port, 2, [{interface, "linc-port2"}]}
        ]},

       {queues_status, disabled},

       {queues,
        [
        ]}
      ]}
    ]}
  ]},

 {enetconf,
  [
   {capabilities, [{base, {1, 1}},
                   {startup, {1, 0}},
                   {'writable-running', {1, 0}}]},
   {callback_module, linc_ofconfig},
   {sshd_ip, any},
   {sshd_port, 1830},
   {sshd_user_passwords,
    [
     {"linc", "linc"}
    ]}
  ]},

 {lager,
  [
   {handlers,
    [
     {lager_console_backend, info},
     {lager_file_backend,
      [
       {"log/error.log", error, 10485760, "$D0", 5},
       {"log/console.log", info, 10485760, "$D0", 5}
      ]}
    ]}
  ]},

 {sasl,
  [
   {sasl_error_logger, {file, "log/sasl-error.log"}},
   {errlog_type, error},
   {error_logger_mf_dir, "log/sasl"},      % Log directory
   {error_logger_mf_maxbytes, 10485760},   % 10 MB max file size
   {error_logger_mf_maxfiles, 5}           % 5 files max
  ]}
].
-->8-->8-->8-->8-->8-->8-->8-->8-->8-->8-->8-->8-->8--

"""

import traceback

import lxml.etree
import ncclient

from ryu.base import app_manager
from ryu.lib.netconf import constants as nc_consts
from ryu.lib import hub
from ryu.lib import of_config
from ryu.lib.of_config import capable_switch
from ryu.lib.of_config import constants as ofc_consts


# Change those depending on switch configuration
HOST = '127.0.0.1'
PORT = 1830
USERNAME = 'linc'
PASSWORD = 'linc'

CAPABLE_SWITCH_ID = 'CapableSwitch0'
LOGICAL_SWITCH = 'LogicalSwitch0'
PORT_ID = 'LogicalSwitch0-Port2'
CONTROLLER_ID = 'Switch0-DefaultController'

PORT_DICT = {
    'capable_switch': CAPABLE_SWITCH_ID,
    'port_id': PORT_ID,
    'logical_switch': LOGICAL_SWITCH,
    'controller_id': CONTROLLER_ID,
    'ip': HOST,
}

SWITCH_PORT_DOWN = '''
<nc:config xmlns:nc="urn:ietf:params:xml:ns:netconf:base:1.0">
  <capable-switch xmlns="urn:onf:of111:config:yang">
    <id>%(capable_switch)s</id>
    <resources>
      <port>
        <resource-id>%(port_id)s</resource-id>
        <configuration operation="merge">
          <admin-state>down</admin-state>
          <no-receive>false</no-receive>
          <no-forward>false</no-forward>
          <no-packet-in>false</no-packet-in>
        </configuration>
      </port>
    </resources>
  </capable-switch>
</nc:config>
''' % PORT_DICT

SWITCH_ADVERTISED = '''
<nc:config xmlns:nc="urn:ietf:params:xml:ns:netconf:base:1.0">
  <capable-switch xmlns="urn:onf:of111:config:yang">
    <id>%(capable_switch)s</id>
    <resources>
      <port>
        <resource-id>%(port_id)s</resource-id>
        <features>
          <advertised operation="merge">
            <rate>10Mb-FD</rate>
            <auto-negotiate>true</auto-negotiate>
            <medium>copper</medium>
            <pause>unsupported</pause>
          </advertised>
        </features>
      </port>
    </resources>
  </capable-switch>
</nc:config>
''' % PORT_DICT

SWITCH_CONTROLLER = '''
<nc:config xmlns:nc="urn:ietf:params:xml:ns:netconf:base:1.0">
  <capable-switch xmlns="urn:onf:of111:config:yang">
    <id>%(capable_switch)s</id>
    <logical-switches>
      <switch>
        <id>%(logical_switch)s</id>
          <controllers>
            <controller operation="merge">
              <id>%(controller_id)s</id>
              <role>master</role>
              <ip-address>%(ip)s</ip-address>
              <port>6633</port>
              <protocol>tcp</protocol>
            </controller>
          </controllers>
      </switch>
    </logical-switches>
  </capable-switch>
</nc:config>
''' % PORT_DICT


def _get_schema():
    # file_name = of_config.OF_CONFIG_1_0_XSD
    # file_name = of_config.OF_CONFIG_1_1_XSD
    file_name = of_config.OF_CONFIG_1_1_1_XSD
    return lxml.etree.XMLSchema(file=file_name)


class OFConfigClient(app_manager.RyuApp):
    def __init__(self, *args, **kwargs):
        super(OFConfigClient, self).__init__(*args, **kwargs)
        self.switch = capable_switch.OFCapableSwitch(
            host=HOST, port=PORT, username=USERNAME, password=PASSWORD,
            unknown_host_cb=lambda host, fingeprint: True)
        hub.spawn(self._do_of_config)

    def _validate(self, tree):
        xmlschema = _get_schema()
        try:
            xmlschema.assertValid(tree)
        except:
            traceback.print_exc()

    def _do_get(self):
        data_xml = self.switch.get()

        tree = lxml.etree.fromstring(data_xml)
        # print(lxml.etree.tostring(tree, pretty_print=True))
        self._validate(tree)

        name_spaces = set()
        for e in tree.getiterator():
            name_spaces.add(capable_switch.get_ns_tag(e.tag)[0])
        print(name_spaces)

        return tree

    def _do_get_config(self, source):
        print('source = %s' % source)
        config_xml = self.switch.get_config(source)

        tree = lxml.etree.fromstring(config_xml)
        # print(lxml.etree.tostring(tree, pretty_print=True))
        self._validate(tree)

    def _do_edit_config(self, config):
        tree = lxml.etree.fromstring(config)
        self._validate(tree)
        self.switch.edit_config(target='running', config=config)

    def _print_ports(self, tree, ns):
        for port in tree.findall('{%s}%s/{%s}%s' % (ns, ofc_consts.RESOURCES,
                                                    ns, ofc_consts.PORT)):
            print(lxml.etree.tostring(port, pretty_print=True))

    def _set_ports_down(self):
        """try to set all ports down with etree operation"""
        tree = self._do_get()
        print lxml.etree.tostring(tree, pretty_print=True)

        qname = lxml.etree.QName(tree.tag)
        ns = qname.namespace
        self._print_ports(tree, ns)

        switch_id = tree.find('{%s}%s' % (ns, ofc_consts.ID))
        resources = tree.find('{%s}%s' % (ns, ofc_consts.RESOURCES))
        configuration = tree.find(
            '{%s}%s/{%s}%s/{%s}%s' % (ns, ofc_consts.RESOURCES,
                                      ns, ofc_consts.PORT,
                                      ns, ofc_consts.CONFIGURATION))
        admin_state = tree.find(
            '{%s}%s/{%s}%s/{%s}%s/{%s}%s' % (ns, ofc_consts.RESOURCES,
                                             ns, ofc_consts.PORT,
                                             ns, ofc_consts.CONFIGURATION,
                                             ns, ofc_consts.ADMIN_STATE))

        config_ = lxml.etree.Element(
            '{%s}%s' % (ncclient.xml_.BASE_NS_1_0, nc_consts.CONFIG))
        capable_switch_ = lxml.etree.SubElement(config_, tree.tag)
        switch_id_ = lxml.etree.SubElement(capable_switch_, switch_id.tag)
        switch_id_.text = switch_id.text
        resources_ = lxml.etree.SubElement(capable_switch_,
                                           resources.tag)
        for port in tree.findall(
                '{%s}%s/{%s}%s' % (ns, ofc_consts.RESOURCES,
                                   ns, ofc_consts.PORT)):
            resource_id = port.find('{%s}%s' % (ns, ofc_consts.RESOURCE_ID))

            port_ = lxml.etree.SubElement(resources_, port.tag)
            resource_id_ = lxml.etree.SubElement(port_, resource_id.tag)
            resource_id_.text = resource_id.text
            configuration_ = lxml.etree.SubElement(port_, configuration.tag)
            configuration_.set(ofc_consts.OPERATION, nc_consts.MERGE)
            admin_state_ = lxml.etree.SubElement(configuration_,
                                                 admin_state.tag)
            admin_state_.text = ofc_consts.DOWN
        self._do_edit_config(lxml.etree.tostring(config_, pretty_print=True))

        tree = self._do_get()
        self._print_ports(tree, ns)

    def _do_of_config(self):
        self._do_get()
        self._do_get_config('running')
        self._do_get_config('startup')

        # LINC doesn't support 'candidate' datastore
        try:
            self._do_get_config('candidate')
        except ncclient.NCClientError:
            traceback.print_exc()

        # use raw XML format
        self._do_edit_config(SWITCH_PORT_DOWN)
        self._do_edit_config(SWITCH_ADVERTISED)
        self._do_edit_config(SWITCH_CONTROLLER)

        self._set_ports_down()

        self.switch.close_session()

########NEW FILE########
__FILENAME__ = test_request_reply_v12
# Copyright (C) 2012 Nippon Telegraph and Telephone Corporation.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# vim: tabstop=4 shiftwidth=4 softtabstop=4

import time
import logging

from ryu.controller import ofp_event
from ryu.controller.handler import MAIN_DISPATCHER
from ryu.controller.handler import set_ev_cls
from ryu.ofproto import ofproto_v1_2
from ryu.tests.integrated import tester

LOG = logging.getLogger(__name__)


class RunTest(tester.TestFlowBase):
    """ Test case for Request-Reply messages.

        Some tests need attached port to switch.
        If use the OVS, can do it with the following commands.
            # ip link add <port> type dummy
            # ovs-vsctl add-port <bridge> <port>
    """

    OFP_VERSIONS = [ofproto_v1_2.OFP_VERSION]

    def __init__(self, *args, **kwargs):
        super(RunTest, self).__init__(*args, **kwargs)

        self._verify = None
        self.n_tables = ofproto_v1_2.OFPTT_MAX

    def start_next_test(self, dp):
        self._verify = None
        self.delete_all_flows(dp)
        dp.send_barrier()
        if len(self.pending):
            t = self.pending.pop()
            if self.is_supported(t):
                LOG.info(tester.LOG_TEST_START, t)
                self.current = t
                getattr(self, t)(dp)
            else:
                self.results[t] = 'SKIP (unsupported)'
                self.unclear -= 1
                self.start_next_test(dp)
        else:
            self.print_results()

    def run_verify(self, ev):
        msg = ev.msg
        dp = msg.datapath

        verify_func = self.verify_default
        v = "verify" + self.current[4:]
        if v in dir(self):
            verify_func = getattr(self, v)

        result = verify_func(dp, msg)
        if result is True:
            self.unclear -= 1

        self.results[self.current] = result
        self.start_next_test(dp)

    def verify_default(self, dp, msg):
        type_ = self._verify

        if msg.msg_type == dp.ofproto.OFPT_STATS_REPLY:
            return self.verify_stats(dp, msg.body, type_)
        elif msg.msg_type == type_:
            return True
        else:
            return 'Reply msg_type %s expected %s' \
                   % (msg.msg_type, type_)

    def verify_stats(self, dp, stats, type_):
        stats_types = dp.ofproto_parser.OFPStatsReply._STATS_TYPES
        expect = stats_types.get(type_).__name__

        if isinstance(stats, list):
            for s in stats:
                if expect == s.__class__.__name__:
                    return True
        else:
            if expect == stats.__class__.__name__:
                return True
        return 'Reply msg has not \'%s\' class.\n%s' % (expect, stats)

    def mod_flow(self, dp, cookie=0, cookie_mask=0, table_id=0,
                 command=None, idle_timeout=0, hard_timeout=0,
                 priority=0xff, buffer_id=0xffffffff, match=None,
                 actions=None, inst_type=None, out_port=None,
                 out_group=None, flags=0, inst=None):

        if command is None:
            command = dp.ofproto.OFPFC_ADD

        if inst is None:
            if inst_type is None:
                inst_type = dp.ofproto.OFPIT_APPLY_ACTIONS

            inst = []
            if actions is not None:
                inst = [dp.ofproto_parser.OFPInstructionActions(
                        inst_type, actions)]

        if match is None:
            match = dp.ofproto_parser.OFPMatch()

        if out_port is None:
            out_port = dp.ofproto.OFPP_ANY

        if out_group is None:
            out_group = dp.ofproto.OFPG_ANY

        m = dp.ofproto_parser.OFPFlowMod(dp, cookie, cookie_mask,
                                         table_id, command,
                                         idle_timeout, hard_timeout,
                                         priority, buffer_id,
                                         out_port, out_group,
                                         flags, match, inst)

        dp.send_msg(m)

    def get_port(self, dp):
        for port_no, port in dp.ports.items():
            if port_no != dp.ofproto.OFPP_LOCAL:
                return port
        return None

    # Test for Reply message type
    def test_desc_stats_request(self, dp):
        self._verify = dp.ofproto.OFPST_DESC
        m = dp.ofproto_parser.OFPDescStatsRequest(dp)
        dp.send_msg(m)

    def test_flow_stats_request(self, dp):
        self._verify = dp.ofproto.OFPST_FLOW
        self.mod_flow(dp)
        self.send_flow_stats(dp)

    def test_aggregate_stats_request(self, dp):
        self._verify = dp.ofproto.OFPST_AGGREGATE
        match = dp.ofproto_parser.OFPMatch()
        m = dp.ofproto_parser.OFPAggregateStatsRequest(
            dp, dp.ofproto.OFPTT_ALL, dp.ofproto.OFPP_ANY,
            dp.ofproto.OFPG_ANY, 0, 0, match)
        dp.send_msg(m)

    def test_table_stats_request(self, dp):
        self._verify = dp.ofproto.OFPST_TABLE
        m = dp.ofproto_parser.OFPTableStatsRequest(dp)
        dp.send_msg(m)

    def test_port_stats_request(self, dp):
        self._verify = dp.ofproto.OFPST_PORT
        m = dp.ofproto_parser.OFPPortStatsRequest(dp, dp.ofproto.OFPP_ANY)
        dp.send_msg(m)

    def test_echo_request(self, dp):
        self._verify = dp.ofproto.OFPT_ECHO_REPLY
        m = dp.ofproto_parser.OFPEchoRequest(dp)
        dp.send_msg(m)

    def test_features_request(self, dp):
        self._verify = dp.ofproto.OFPT_FEATURES_REPLY
        m = dp.ofproto_parser.OFPFeaturesRequest(dp)
        dp.send_msg(m)

    def test_get_config_request(self, dp):
        self._verify = dp.ofproto.OFPT_GET_CONFIG_REPLY
        m = dp.ofproto_parser.OFPGetConfigRequest(dp)
        dp.send_msg(m)

    def test_barrier_request(self, dp):
        self._verify = dp.ofproto.OFPT_BARRIER_REPLY
        dp.send_barrier()

    def test_error_reply(self, dp):
        ports = [0]
        for p in dp.ports:
            if p != dp.ofproto.OFPP_LOCAL:
                ports.append(p)

        port_no = max(ports) + 1
        self._verify = dp.ofproto.OFPT_ERROR
        m = dp.ofproto_parser.OFPPortMod(
            dp, port_no, 'ff:ff:ff:ff:ff:ff', 0, 0, 0)
        dp.send_msg(m)

    # Test for reply value
    def test_flow_stats_none(self, dp):
        self.send_flow_stats(dp)

    def verify_flow_stats_none(self, dp, msg):
        stats = msg.body
        if len(stats):
            return 'Reply msg has body. %s' % (stats, )
        return True

    def test_flow_stats_reply_value(self, dp):
        self._verify = []
        c = 0
        while c < self.n_tables:
            # value = (talbe_id, cookie, idle_timeout, hard_timeout, priority)
            v = (c, c + 1, c + 2, c + 3, c + 4)
            self._verify.append(v)
            self.mod_flow(dp, table_id=v[0], cookie=v[1],
                          idle_timeout=v[2], hard_timeout=v[3], priority=v[4])
            c += 1
        dp.send_barrier()
        self.send_flow_stats(dp)

    def verify_flow_stats_reply_value(self, dp, msg):
        c = 0
        for f in msg.body:
            f_value = (f.table_id, f.cookie, f.idle_timeout,
                       f.hard_timeout, f.priority, )
            if f_value != self._verify[c]:
                return 'param is mismatched. verify=%s, reply=%s' \
                       % (self._verify[c], f_value,)
            c += 1
        return len(msg.body) == self.n_tables

    def test_echo_request_has_data(self, dp):
        data = 'test'
        self._verify = data
        m = dp.ofproto_parser.OFPEchoRequest(dp)
        m.data = data
        dp.send_msg(m)

    def verify_echo_request_has_data(self, dp, msg):
        data = msg.data
        return self._verify == data

    def test_aggregate_stats_flow_count(self, dp):
        c = 0
        while c < self.n_tables:
            self.mod_flow(dp, table_id=c)
            c += 1
        dp.send_barrier()
        match = dp.ofproto_parser.OFPMatch()
        m = dp.ofproto_parser.OFPAggregateStatsRequest(
            dp, dp.ofproto.OFPTT_ALL, dp.ofproto.OFPP_ANY,
            dp.ofproto.OFPG_ANY, 0, 0, match)
        dp.send_msg(m)

    def verify_aggregate_stats_flow_count(self, dp, msg):
        stats = msg.body
        return stats.flow_count == self.n_tables

    def test_aggregate_stats_flow_count_out_port(self, dp):
        actions = [dp.ofproto_parser.OFPActionOutput(1, 1500)]
        self.mod_flow(dp, table_id=1, actions=actions)

        actions = [dp.ofproto_parser.OFPActionOutput(2, 1500)]
        self.mod_flow(dp, table_id=2, actions=actions)
        dp.send_barrier()

        out_port = 2
        match = dp.ofproto_parser.OFPMatch()
        m = dp.ofproto_parser.OFPAggregateStatsRequest(
            dp, dp.ofproto.OFPTT_ALL, out_port,
            dp.ofproto.OFPG_ANY, 0, 0, match)
        dp.send_msg(m)

    def verify_aggregate_stats_flow_count_out_port(self, dp, msg):
        stats = msg.body
        return stats.flow_count == 1

    def test_aggregate_stats_packet_count(self, dp):
        in_port = 1
        data = 'test'
        self._verify = {'packet_count': 1,
                        'byte_count': len(data)}

        # add flow
        match = dp.ofproto_parser.OFPMatch()
        match.set_in_port(in_port)
        self.mod_flow(dp, table_id=0, match=match)

        # packet out
        output = dp.ofproto.OFPP_TABLE
        actions = [dp.ofproto_parser.OFPActionOutput(output, 0)]
        m = dp.ofproto_parser.OFPPacketOut(dp, 0xffffffff, in_port,
                                           actions, data)
        dp.send_msg(m)
        dp.send_barrier()

        match = dp.ofproto_parser.OFPMatch()
        m = dp.ofproto_parser.OFPAggregateStatsRequest(
            dp, dp.ofproto.OFPTT_ALL, dp.ofproto.OFPP_ANY,
            dp.ofproto.OFPG_ANY, 0, 0, match)
        dp.send_msg(m)

    def verify_aggregate_stats_packet_count(self, dp, msg):
        for name, val in self._verify.items():
            r_val = getattr(msg.body, name)
            if val != r_val:
                return '%s is mismatched. verify=%s, reply=%s' \
                    % (name, val, r_val)
        return True

    def test_set_config_nomal(self, dp):
        flags = dp.ofproto.OFPC_FRAG_NORMAL
        self._verify = flags
        m = dp.ofproto_parser.OFPSetConfig(dp, flags, 0)
        dp.send_msg(m)
        dp.send_barrier()

        m = dp.ofproto_parser.OFPGetConfigRequest(dp)
        dp.send_msg(m)

    def verify_set_config_nomal(self, dp, msg):
        return self._verify == msg.flags

    def test_set_config_drop(self, dp):
        flags = dp.ofproto.OFPC_FRAG_DROP
        self._verify = flags
        m = dp.ofproto_parser.OFPSetConfig(dp, flags, 0)
        dp.send_msg(m)
        dp.send_barrier()

        m = dp.ofproto_parser.OFPGetConfigRequest(dp)
        dp.send_msg(m)

    def verify_set_config_drop(self, dp, msg):
        return self._verify == msg.flags

    def test_set_config_mask(self, dp):
        flags = dp.ofproto.OFPC_FRAG_MASK
        self._verify = flags
        m = dp.ofproto_parser.OFPSetConfig(dp, flags, 0)
        dp.send_msg(m)
        dp.send_barrier()

        m = dp.ofproto_parser.OFPGetConfigRequest(dp)
        dp.send_msg(m)

    def verify_set_config_mask(self, dp, msg):
        return self._verify == msg.flags

    def test_set_config_ttl_to_controller(self, dp):
        flags = dp.ofproto.OFPC_INVALID_TTL_TO_CONTROLLER
        self._verify = flags
        m = dp.ofproto_parser.OFPSetConfig(dp, flags, 0)
        dp.send_msg(m)
        dp.send_barrier()

        m = dp.ofproto_parser.OFPGetConfigRequest(dp)
        dp.send_msg(m)

    def verify_set_config_ttl_to_controller(self, dp, msg):
        return self._verify == msg.flags

    def test_set_config_miss_send_len(self, dp):
        flags = dp.ofproto.OFPC_FRAG_NORMAL
        ms_len = 256
        self._verify = ms_len
        m = dp.ofproto_parser.OFPSetConfig(dp, flags, ms_len)
        dp.send_msg(m)
        dp.send_barrier()

        m = dp.ofproto_parser.OFPGetConfigRequest(dp)
        dp.send_msg(m)

    def verify_set_config_miss_send_len(self, dp, msg):
        return self._verify == msg.miss_send_len

    def test_set_config_miss_send_len_max(self, dp):
        flags = dp.ofproto.OFPC_FRAG_NORMAL
        ms_len = dp.ofproto.OFPCML_MAX
        self._verify = ms_len
        m = dp.ofproto_parser.OFPSetConfig(dp, flags, ms_len)
        dp.send_msg(m)
        dp.send_barrier()

        m = dp.ofproto_parser.OFPGetConfigRequest(dp)
        dp.send_msg(m)

    def verify_set_config_miss_send_len_max(self, dp, msg):
        return self._verify == msg.miss_send_len

    def test_set_config_no_buffer(self, dp):
        flags = dp.ofproto.OFPC_FRAG_NORMAL
        ms_len = dp.ofproto.OFPCML_NO_BUFFER
        self._verify = ms_len
        m = dp.ofproto_parser.OFPSetConfig(dp, flags, ms_len)
        dp.send_msg(m)
        dp.send_barrier()

        m = dp.ofproto_parser.OFPGetConfigRequest(dp)
        dp.send_msg(m)

    def verify_set_config_no_buffer(self, dp, msg):
        return self._verify == msg.miss_send_len

    def _verify_flow_inst_type(self, dp, msg):
        inst_type = self._verify
        stats = msg.body

        for s in stats:
            for i in s.instructions:
                if i.type == inst_type:
                    return True
        return 'not found inst_type[%s]' % (inst_type, )

    def test_flow_add_apply_actions(self, dp):
        inst_type = dp.ofproto.OFPIT_APPLY_ACTIONS
        self._verify = inst_type

        actions = [dp.ofproto_parser.OFPActionOutput(1, 1500)]
        self.mod_flow(dp, actions=actions, inst_type=inst_type)
        self.send_flow_stats(dp)

    def verify_flow_add_apply_actions(self, dp, msg):
        return self._verify_flow_inst_type(dp, msg)

    def test_flow_add_goto_table(self, dp):
        self._verify = dp.ofproto.OFPIT_GOTO_TABLE

        inst = [dp.ofproto_parser.OFPInstructionGotoTable(0), ]
        self.mod_flow(dp, inst=inst)
        self.send_flow_stats(dp)

    def verify_flow_add_goto_table(self, dp, msg):
        return self._verify_flow_inst_type(dp, msg)

    def _verify_flow_value(self, dp, msg):
        stats = msg.body
        verify = self._verify

        if len(verify) != len(stats):
            return 'flow_count is mismatched. verify=%s stats=%s' \
                   % (len(verify), len(stats))

        for s in stats:
            v_port = -1
            v = verify.get(s.table_id, None)
            if v:
                v_port = v[3].port

            s_port = s.instructions[0].actions[0].port

            if v_port != s_port:
                return 'port is mismatched. table_id=%s verify=%s, stats=%s' \
                       % (s.table_id, v_port, s_port)
        return True

    def _add_flow_for_flow_mod_tests(self, dp):
        a1 = dp.ofproto_parser.OFPActionOutput(1, 1500)
        a2 = dp.ofproto_parser.OFPActionOutput(2, 1500)

        # table_id, cookie, priority, dl_dst, action)
        tables = {0: [0xffff, 10, '\xee' * 6, a1],
                  1: [0xff00, 10, '\xee' * 6, a2],
                  2: [0xf000, 100, '\xee' * 6, a1],
                  3: [0x0000, 10, '\xff' * 6, a1]}

        self._verify = tables
        for table_id, val in tables.items():
            match = dp.ofproto_parser.OFPMatch()
            match.set_dl_dst(val[2])
            self.mod_flow(dp, match=match, actions=[val[3]],
                          table_id=table_id, cookie=val[0], priority=val[1])
        dp.send_barrier()

    def test_flow_mod_table_id(self, dp):
        self._add_flow_for_flow_mod_tests(dp)

        # modify flow of table_id=3
        action = dp.ofproto_parser.OFPActionOutput(3, 1500)
        self._verify[3][3] = action

        table_id = 3
        self.mod_flow(dp, command=dp.ofproto.OFPFC_MODIFY,
                      actions=[action], table_id=table_id)

        dp.send_barrier()
        self.send_flow_stats(dp)

    def verify_flow_mod_table_id(self, dp, msg):
        return self._verify_flow_value(dp, msg)

    def test_flow_mod_cookie(self, dp):
        self._add_flow_for_flow_mod_tests(dp)

        # modify flow of table_id=1
        action = dp.ofproto_parser.OFPActionOutput(3, 1500)
        self._verify[1][3] = action

        cookie = 0xff00
        cookie_mask = 0xffff
        self.mod_flow(dp, command=dp.ofproto.OFPFC_MODIFY,
                      actions=[action], table_id=dp.ofproto.OFPTT_ALL,
                      cookie=cookie, cookie_mask=cookie_mask)

        dp.send_barrier()
        self.send_flow_stats(dp)

    def verify_flow_mod_cookie(self, dp, msg):
        return self._verify_flow_value(dp, msg)

    def test_flow_mod_cookie_mask(self, dp):
        self._add_flow_for_flow_mod_tests(dp)

        # modify flow of table_id=0,1
        action = dp.ofproto_parser.OFPActionOutput(3, 1500)
        self._verify[0][3] = action
        self._verify[1][3] = action

        cookie = 0xffff
        cookie_mask = 0xff00
        self.mod_flow(dp, command=dp.ofproto.OFPFC_MODIFY,
                      actions=[action], table_id=dp.ofproto.OFPTT_ALL,
                      cookie=cookie, cookie_mask=cookie_mask)

        dp.send_barrier()
        self.send_flow_stats(dp)

    def verify_flow_mod_cookie_mask(self, dp, msg):
        return self._verify_flow_value(dp, msg)

    def test_flow_mod_match(self, dp):
        self._add_flow_for_flow_mod_tests(dp)

        # modify flow of table_id=3
        action = dp.ofproto_parser.OFPActionOutput(3, 1500)
        self._verify[3][3] = action

        match = dp.ofproto_parser.OFPMatch()
        match.set_dl_dst('\xff' * 6)
        self.mod_flow(dp, command=dp.ofproto.OFPFC_MODIFY,
                      actions=[action], table_id=dp.ofproto.OFPTT_ALL,
                      match=match)

        dp.send_barrier()
        self.send_flow_stats(dp)

    def verify_flow_mod_match(self, dp, msg):
        return self._verify_flow_value(dp, msg)

    def test_flow_mod_strict(self, dp):
        self._add_flow_for_flow_mod_tests(dp)

        # modify flow of table_id=2
        action = dp.ofproto_parser.OFPActionOutput(3, 1500)
        self._verify[2][3] = action

        match = dp.ofproto_parser.OFPMatch()
        match.set_dl_dst('\xee' * 6)
        priority = 100
        self.mod_flow(dp, command=dp.ofproto.OFPFC_MODIFY_STRICT,
                      actions=[action], table_id=dp.ofproto.OFPTT_ALL,
                      match=match, priority=priority)

        dp.send_barrier()
        self.send_flow_stats(dp)

    def verify_flow_mod_strict(self, dp, msg):
        return self._verify_flow_value(dp, msg)

    def test_flow_del_table_id(self, dp):
        self._add_flow_for_flow_mod_tests(dp)

        # delete flow of table_id=3
        del self._verify[3]

        table_id = 3
        self.mod_flow(dp, command=dp.ofproto.OFPFC_DELETE,
                      table_id=table_id)

        dp.send_barrier()
        self.send_flow_stats(dp)

    def verify_flow_del_table_id(self, dp, msg):
        return self._verify_flow_value(dp, msg)

    def test_flow_del_table_id_all(self, dp):
        self._add_flow_for_flow_mod_tests(dp)

        # delete all flows
        self._verify = {}

        self.mod_flow(dp, command=dp.ofproto.OFPFC_DELETE,
                      table_id=dp.ofproto.OFPTT_ALL)

        dp.send_barrier()
        self.send_flow_stats(dp)

    def verify_flow_del_table_id_all(self, dp, msg):
        return self._verify_flow_value(dp, msg)

    def test_flow_del_cookie(self, dp):
        self._add_flow_for_flow_mod_tests(dp)

        # delete flow of table_id=1
        del self._verify[1]

        cookie = 0xff00
        cookie_mask = 0xffff
        self.mod_flow(dp, command=dp.ofproto.OFPFC_DELETE,
                      table_id=dp.ofproto.OFPTT_ALL,
                      cookie=cookie, cookie_mask=cookie_mask)

        dp.send_barrier()
        self.send_flow_stats(dp)

    def verify_flow_del_cookie(self, dp, msg):
        return self._verify_flow_value(dp, msg)

    def test_flow_del_cookie_mask(self, dp):
        self._add_flow_for_flow_mod_tests(dp)

        # delete flow of table_id=0,1
        del self._verify[0]
        del self._verify[1]

        cookie = 0xffff
        cookie_mask = 0xff00
        self.mod_flow(dp, command=dp.ofproto.OFPFC_DELETE,
                      table_id=dp.ofproto.OFPTT_ALL,
                      cookie=cookie, cookie_mask=cookie_mask)

        dp.send_barrier()
        self.send_flow_stats(dp)

    def verify_flow_del_cookie_mask(self, dp, msg):
        return self._verify_flow_value(dp, msg)

    def test_flow_del_match(self, dp):
        self._add_flow_for_flow_mod_tests(dp)

        # delete flow of table_id=3
        del self._verify[3]

        match = dp.ofproto_parser.OFPMatch()
        match.set_dl_dst('\xff' * 6)
        self.mod_flow(dp, command=dp.ofproto.OFPFC_DELETE,
                      table_id=dp.ofproto.OFPTT_ALL, match=match)

        dp.send_barrier()
        self.send_flow_stats(dp)

    def verify_flow_del_match(self, dp, msg):
        return self._verify_flow_value(dp, msg)

    def test_flow_del_out_port(self, dp):
        self._add_flow_for_flow_mod_tests(dp)

        # delete flow of table_id=1
        del self._verify[1]

        out_port = 2
        self.mod_flow(dp, command=dp.ofproto.OFPFC_DELETE,
                      table_id=dp.ofproto.OFPTT_ALL, out_port=out_port)

        dp.send_barrier()
        self.send_flow_stats(dp)

    def verify_flow_del_out_port(self, dp, msg):
        return self._verify_flow_value(dp, msg)

    def test_flow_del_strict(self, dp):
        self._add_flow_for_flow_mod_tests(dp)

        # delete flow of table_id=2
        del self._verify[2]

        match = dp.ofproto_parser.OFPMatch()
        match.set_dl_dst('\xee' * 6)
        priority = 100
        self.mod_flow(dp, command=dp.ofproto.OFPFC_DELETE_STRICT,
                      table_id=dp.ofproto.OFPTT_ALL,
                      match=match, priority=priority)

        dp.send_barrier()
        self.send_flow_stats(dp)

    def verify_flow_del_strict(self, dp, msg):
        return self._verify_flow_value(dp, msg)

    def _send_port_mod(self, dp, config, mask):
        p = self.get_port(dp)
        if not p:
            err = 'need attached port to switch.'
            self.results[self.current] = err
            self.start_next_test(dp)
            return

        self._verify = [p.port_no, config & mask]
        m = dp.ofproto_parser.OFPPortMod(dp, p.port_no, p.hw_addr,
                                         config, mask, 0)
        dp.send_msg(m)
        dp.send_barrier()

        # TODO: waiting to port UP|DOWN.
        time.sleep(1)
        m = dp.ofproto_parser.OFPFeaturesRequest(dp)
        dp.send_msg(m)

    def _verify_port_mod_config(self, dp, msg):
        port_no = self._verify[0]
        config = self._verify[1]

        port = msg.ports[port_no]
        if config != port.config:
            return "config is mismatched. verify=%s, stats=%s" \
                % (bin(config), bin(port.config))
        return True

    def test_port_mod_config_01_all(self, dp):
        config = 0b1100101
        mask = 0b1111111
        self._send_port_mod(dp, config, mask)

    def verify_port_mod_config_01_all(self, dp, msg):
        return self._verify_port_mod_config(dp, msg)

    def test_port_mod_config_02_none(self, dp):
        config = 0
        mask = 0b1111111
        self._send_port_mod(dp, config, mask)

    def verify_port_mod_config_02_none(self, dp, msg):
        return self._verify_port_mod_config(dp, msg)

    def test_port_mod_config_03_mask(self, dp):
        config = 0b1100101
        mask = 0b1111000
        self._send_port_mod(dp, config, mask)

    def verify_port_mod_config_03_mask(self, dp, msg):
        res = self._verify_port_mod_config(dp, msg)
        # reset port config
        port_no = self._verify[0]
        p = msg.ports[port_no]
        m = dp.ofproto_parser.OFPPortMod(dp, p.port_no, p.hw_addr,
                                         0, 0b1111111, 0)
        dp.send_msg(m)
        dp.send_barrier()
        return res

    def test_port_stats_port_no(self, dp):
        p = self.get_port(dp)
        if not p:
            err = 'need attached port to switch.'
            self.results[self.current] = err
            self.start_next_test(dp)
            return

        self._verify = p.port_no
        m = dp.ofproto_parser.OFPPortStatsRequest(dp, p.port_no)
        dp.send_msg(m)

    def verify_port_stats_port_no(self, dp, msg):
        ports = msg.body
        if len(ports) > 1:
            return 'reply some ports.\n%s' % (ports)

        if ports[0].port_no != self._verify:
            return 'port_no is mismatched. request=%s reply=%s' \
                % (self._verify, ports[0].port_no)

        return True

    def _add_flow_flow_removed(self, dp, reason, table_id=0,
                               cookie=0xff, priority=100, in_port=1,
                               idle_timeout=0, hard_timeout=0):
        self._verify = {}
        self._verify['params'] = {'reason': reason,
                                  'table_id': table_id,
                                  'cookie': cookie,
                                  'priority': priority}
        self._verify['in_port'] = in_port
        self._verify['timeout'] = idle_timeout
        if hard_timeout:
            if (idle_timeout == 0 or idle_timeout > hard_timeout):
                self._verify['timeout'] = hard_timeout

        match = dp.ofproto_parser.OFPMatch()
        match.set_in_port(in_port)
        self.mod_flow(dp, match=match, cookie=cookie,
                      priority=priority, table_id=table_id,
                      idle_timeout=idle_timeout, hard_timeout=hard_timeout,
                      flags=dp.ofproto.OFPFF_SEND_FLOW_REM)

    def _verify_flow_removed(self, dp, msg):
        params = self._verify['params']
        in_port = self._verify['in_port']
        timeout = self._verify['timeout']

        if timeout:
            duration_nsec = (msg.duration_sec * 10 ** 9) + msg.duration_nsec
            timeout_nsec = timeout * 10 ** 9

            # grace of -0.5 and +1.5 second to timeout.
            l = (timeout - 0.5) * 10 ** 9
            h = (timeout + 1.5) * 10 ** 9
            if not l < duration_nsec < h:
                return 'bad duration time. set=%s(nsec), duration=%s(nsec)' \
                    % (timeout_nsec, duration_nsec)

        for name, val in params.items():
            r_val = getattr(msg, name)
            if val != r_val:
                return '%s is mismatched. verify=%s, reply=%s' \
                    % (name, val, r_val)

        for f in msg.match.fields:
            if f.header == ofproto_v1_2.OXM_OF_IN_PORT:
                if f.value != in_port:
                    return 'in_port is mismatched. verify=%s, reply=%s' \
                        % (in_port, f.value)
        return True

    def test_flow_removed_idle_timeout(self, dp):
        reason = dp.ofproto.OFPRR_IDLE_TIMEOUT
        idle_timeout = 2
        self._add_flow_flow_removed(dp, reason,
                                    idle_timeout=idle_timeout)

    def verify_flow_removed_idle_timeout(self, dp, msg):
        return self._verify_flow_removed(dp, msg)

    def test_flow_removed_idle_timeout_hit(self, dp):
        reason = dp.ofproto.OFPRR_IDLE_TIMEOUT
        idle_timeout = 5
        in_port = 1
        sleep = 2

        # add target flow
        self._add_flow_flow_removed(dp, reason, in_port=in_port,
                                    idle_timeout=idle_timeout)
        self._verify['timeout'] = idle_timeout + sleep

        # sleep
        time.sleep(sleep)

        # packet out
        output = dp.ofproto.OFPP_TABLE
        actions = [dp.ofproto_parser.OFPActionOutput(output, 0)]
        m = dp.ofproto_parser.OFPPacketOut(dp, 0xffffffff, in_port,
                                           actions, None)
        dp.send_msg(m)

    def verify_flow_removed_idle_timeout_hit(self, dp, msg):
        return self._verify_flow_removed(dp, msg)

    def test_flow_removed_hard_timeout(self, dp):
        reason = dp.ofproto.OFPRR_HARD_TIMEOUT
        hard_timeout = 2
        self._add_flow_flow_removed(dp, reason,
                                    hard_timeout=hard_timeout)

    def verify_flow_removed_hard_timeout(self, dp, msg):
        return self._verify_flow_removed(dp, msg)

    def test_flow_removed_hard_timeout_hit(self, dp):
        reason = dp.ofproto.OFPRR_HARD_TIMEOUT
        hard_timeout = 5
        in_port = 1
        sleep = 2

        self._add_flow_flow_removed(dp, reason, in_port=in_port,
                                    hard_timeout=hard_timeout)
        dp.send_barrier()

        # sleep
        time.sleep(sleep)

        # packet out
        output = dp.ofproto.OFPP_TABLE
        actions = [dp.ofproto_parser.OFPActionOutput(output, 0)]
        m = dp.ofproto_parser.OFPPacketOut(dp, 0xffffffff, in_port,
                                           actions, None)
        dp.send_msg(m)

    def verify_flow_removed_hard_timeout_hit(self, dp, msg):
        return self._verify_flow_removed(dp, msg)

    def test_flow_removed_delete(self, dp):
        reason = dp.ofproto.OFPRR_DELETE
        self._add_flow_flow_removed(dp, reason)
        dp.send_barrier()
        self.delete_all_flows(dp)

    def verify_flow_removed_delete(self, dp, msg):
        return self._verify_flow_removed(dp, msg)

    def test_flow_removed_table_id(self, dp):
        reason = dp.ofproto.OFPRR_DELETE
        table_id = 1
        self._add_flow_flow_removed(dp, reason, table_id=table_id)
        dp.send_barrier()
        self.delete_all_flows(dp)

    def verify_flow_removed_table_id(self, dp, msg):
        return self._verify_flow_removed(dp, msg)

    def _send_packet_out(self, dp, buffer_id=0xffffffff,
                         in_port=None, output=None, data=''):
        if in_port is None:
            in_port = dp.ofproto.OFPP_LOCAL

        if output is None:
            output = dp.ofproto.OFPP_CONTROLLER

        self._verify['buffer_id'] = buffer_id
        self._verify['in_port'] = in_port
        self._verify['data'] = data

        actions = [dp.ofproto_parser.OFPActionOutput(output, len(data))]
        m = dp.ofproto_parser.OFPPacketOut(dp, buffer_id, in_port,
                                           actions, data)
        dp.send_msg(m)

    def _verify_packet_in(self, dp, msg):
        for name, val in self._verify.items():
            if name == 'in_port':
                for f in msg.match.fields:
                    if f.header == ofproto_v1_2.OXM_OF_IN_PORT:
                        r_val = f.value
            else:
                r_val = getattr(msg, name)

            if val != r_val:
                return '%s is mismatched. verify=%s, reply=%s' \
                    % (name, val, r_val)
        return True

    def test_packet_in_action(self, dp):
        self._verify = {}
        self._verify['reason'] = dp.ofproto.OFPR_ACTION
        self._send_packet_out(dp)

    def verify_packet_in_action(self, dp, msg):
        return self._verify_packet_in(dp, msg)

    def test_packet_in_data(self, dp):
        self._verify = {}
        self._verify['reason'] = dp.ofproto.OFPR_ACTION
        data = 'test'
        self._send_packet_out(dp, data=data)

    def verify_packet_in_data(self, dp, msg):
        return self._verify_packet_in(dp, msg)

    def test_packet_in_table_id(self, dp):
        in_port = 1
        table_id = 2
        output = dp.ofproto.OFPP_TABLE

        self._verify = {}
        self._verify['reason'] = dp.ofproto.OFPR_ACTION
        self._verify['table_id'] = table_id

        # add flow (goto_table)
        match = dp.ofproto_parser.OFPMatch()
        match.set_in_port(in_port)
        inst = [dp.ofproto_parser.OFPInstructionGotoTable(table_id)]
        self.mod_flow(dp, inst=inst, match=match)

        # add flow (output)
        match = dp.ofproto_parser.OFPMatch()
        match.set_in_port(in_port)
        out = dp.ofproto.OFPP_CONTROLLER
        actions = [dp.ofproto_parser.OFPActionOutput(out, 0)]
        self.mod_flow(dp, actions=actions, match=match, table_id=table_id)
        dp.send_barrier()

        # packet out
        self._send_packet_out(dp, in_port=in_port, output=output)

    def verify_packet_in_table_id(self, dp, msg):
        return self._verify_packet_in(dp, msg)

    # handler
    @set_ev_cls(ofp_event.EventOFPEchoReply, MAIN_DISPATCHER)
    def echo_replay_handler(self, ev):
        if self.current.find('echo_request') > 0:
            self.run_verify(ev)

    @set_ev_cls(ofp_event.EventOFPStatsReply, MAIN_DISPATCHER)
    def stats_reply_handler(self, ev):
        if self.current is None:
            msg = ev.msg
            dp = msg.datapath
            if self._verify == dp.ofproto.OFPST_TABLE:
                self.table_stats = msg.body
            self.start_next_test(dp)
        else:
            self.run_verify(ev)

    @set_ev_cls(ofp_event.EventOFPSwitchFeatures, MAIN_DISPATCHER)
    def features_replay_handler(self, ev):
        if self.current is None:
            pass
        else:
            self.run_verify(ev)

    @set_ev_cls(ofp_event.EventOFPGetConfigReply, MAIN_DISPATCHER)
    def get_config_replay_handler(self, ev):
        self.run_verify(ev)

    @set_ev_cls(ofp_event.EventOFPBarrierReply, MAIN_DISPATCHER)
    def barrier_replay_handler(self, ev):
        if self.current == 'test_barrier_request':
            self.run_verify(ev)

    @set_ev_cls(ofp_event.EventOFPPortStatus, MAIN_DISPATCHER)
    def port_status_handler(self, ev):
        pass

    @set_ev_cls(ofp_event.EventOFPPacketIn, MAIN_DISPATCHER)
    def packet_in_handler(self, ev):
        if self.current.find('packet_in'):
            self.run_verify(ev)

    @set_ev_cls(ofp_event.EventOFPFlowRemoved, MAIN_DISPATCHER)
    def flow_removed_handler(self, ev):
        if self.current.find('flow_removed') > 0:
            self.run_verify(ev)

    @set_ev_cls(ofp_event.EventOFPErrorMsg, MAIN_DISPATCHER)
    def error_handler(self, ev):
        if self.current.find('error') > 0:
            self.run_verify(ev)

    def is_supported(self, t):
        unsupported = [
        ]
        for u in unsupported:
            if t.find(u) != -1:
                return False

        return True

########NEW FILE########
__FILENAME__ = test_mpls
# Copyright (C) 2012 Nippon Telegraph and Telephone Corporation.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import logging
import struct

from ryu.base import app_manager
from ryu.controller import ofp_event
from ryu.controller import dpset
from ryu.controller.handler import MAIN_DISPATCHER
from ryu.controller.handler import set_ev_cls
from ryu.ofproto import ofproto_v1_2
from ryu.ofproto import ether
from ryu.lib.mac import haddr_to_str


LOG = logging.getLogger(__name__)


class RunTestMininet(app_manager.RyuApp):

    _CONTEXTS = {'dpset': dpset.DPSet}
    OFP_VERSIONS = [ofproto_v1_2.OFP_VERSION]

    def __init__(self, *args, **kwargs):
        super(RunTestMininet, self).__init__(*args, **kwargs)

    def _add_flow(self, dp, match, actions):
        inst = [dp.ofproto_parser.OFPInstructionActions(
            dp.ofproto.OFPIT_APPLY_ACTIONS, actions)]

        mod = dp.ofproto_parser.OFPFlowMod(
            dp, cookie=0, cookie_mask=0, table_id=0,
            command=dp.ofproto.OFPFC_ADD, idle_timeout=0, hard_timeout=0,
            priority=0xff, buffer_id=0xffffffff,
            out_port=dp.ofproto.OFPP_ANY, out_group=dp.ofproto.OFPG_ANY,
            flags=0, match=match, instructions=inst)

        dp.send_msg(mod)

    def _define_flow(self, dp):
        in_port = 1
        out_port = 2

        eth_IP = ether.ETH_TYPE_IP
        eth_MPLS = ether.ETH_TYPE_MPLS

        # MPLS(80) -> PopMPLS
        LOG.debug("--- add_flow PopMPLS")
        m_label = 80
        match = dp.ofproto_parser.OFPMatch()
        match.set_in_port(in_port)
        match.set_dl_type(eth_MPLS)
        match.set_mpls_label(m_label)
        actions = [dp.ofproto_parser.OFPActionPopMpls(eth_IP),
                   dp.ofproto_parser.OFPActionOutput(out_port, 0)]
        self._add_flow(dp, match, actions)

        # IP -> PushMPLS(90)
        LOG.debug("--- add_flow PushMPLS")
        s_label = 90
        match = dp.ofproto_parser.OFPMatch()
        match.set_in_port(in_port)
        match.set_dl_type(eth_IP)
        f = dp.ofproto_parser.OFPMatchField.make(
            dp.ofproto.OXM_OF_MPLS_LABEL, s_label)
        actions = [dp.ofproto_parser.OFPActionPushMpls(eth_MPLS),
                   dp.ofproto_parser.OFPActionSetField(f),
                   dp.ofproto_parser.OFPActionOutput(out_port, 0)]
        self._add_flow(dp, match, actions)

        # MPLS(100) -> PushMPLS(200)
        LOG.debug("--- add_flow PushMPLS")
        m_label = 100
        s_label = 200
        match = dp.ofproto_parser.OFPMatch()
        match.set_in_port(in_port)
        match.set_dl_type(eth_MPLS)
        match.set_mpls_label(m_label)
        f = dp.ofproto_parser.OFPMatchField.make(
            dp.ofproto.OXM_OF_MPLS_LABEL, s_label)
        actions = [dp.ofproto_parser.OFPActionPushMpls(eth_MPLS),
                   dp.ofproto_parser.OFPActionSetField(f),
                   dp.ofproto_parser.OFPActionOutput(out_port, 0)]
        self._add_flow(dp, match, actions)

        # MPLS(1000):MPLS -> PopMPLS
        # LOG.debug("--- add_flow PopMPLS")
        # SKIP: ovs not supported
        m_label = 1000
        match = dp.ofproto_parser.OFPMatch()
        match.set_in_port(in_port)
        match.set_dl_type(eth_MPLS)
        match.set_mpls_label(m_label)
        actions = [dp.ofproto_parser.OFPActionPopMpls(eth_MPLS),
                   dp.ofproto_parser.OFPActionOutput(out_port, 0)]
        # self._add_flow(dp, match, actions)

    @set_ev_cls(dpset.EventDP, dpset.DPSET_EV_DISPATCHER)
    def handler_datapath(self, ev):
        if ev.enter:
            self._define_flow(ev.dp)

    @set_ev_cls(ofp_event.EventOFPPacketIn, MAIN_DISPATCHER)
    def packet_in_handler(self, ev):
        msg = ev.msg
        dst, src, eth_type = struct.unpack_from('!6s6sH', buffer(msg.data), 0)
        in_port = msg.match.fields[0].value

        LOG.info("----------------------------------------")
        LOG.info("* PacketIn")
        LOG.info("in_port=%d, eth_type: %s", in_port, hex(eth_type))
        LOG.info("packet reason=%d buffer_id=%d", msg.reason, msg.buffer_id)
        LOG.info("packet in datapath_id=%s src=%s dst=%s",
                 msg.datapath.id, haddr_to_str(src), haddr_to_str(dst))

########NEW FILE########
__FILENAME__ = test_vlan
# Copyright (C) 2012 Nippon Telegraph and Telephone Corporation.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import logging
import struct

from ryu.base import app_manager
from ryu.controller import ofp_event
from ryu.controller import dpset
from ryu.controller.handler import MAIN_DISPATCHER
from ryu.controller.handler import set_ev_cls
from ryu.ofproto import ofproto_v1_2
from ryu.ofproto import ether
from ryu.ofproto import inet
from ryu.lib.mac import haddr_to_str


LOG = logging.getLogger(__name__)


class RunTestMininet(app_manager.RyuApp):

    _CONTEXTS = {'dpset': dpset.DPSet}
    OFP_VERSIONS = [ofproto_v1_2.OFP_VERSION]

    def __init__(self, *args, **kwargs):
        super(RunTestMininet, self).__init__(*args, **kwargs)

    def _add_flow(self, dp, match, actions):
        inst = [dp.ofproto_parser.OFPInstructionActions(
            dp.ofproto.OFPIT_APPLY_ACTIONS, actions)]

        mod = dp.ofproto_parser.OFPFlowMod(
            dp, cookie=0, cookie_mask=0, table_id=0,
            command=dp.ofproto.OFPFC_ADD, idle_timeout=0, hard_timeout=0,
            priority=0xff, buffer_id=0xffffffff,
            out_port=dp.ofproto.OFPP_ANY, out_group=dp.ofproto.OFPG_ANY,
            flags=0, match=match, instructions=inst)

        dp.send_msg(mod)

    def _define_flow(self, dp):
        in_port = 1
        out_port = 2

        eth_IP = ether.ETH_TYPE_IP
        eth_VLAN = ether.ETH_TYPE_8021Q
        ip_ICMP = inet.IPPROTO_ICMP

        # VLAN(8) -> PopVLAN
        LOG.debug("--- add_flow VLAN(8) to PopVLAN")
        m_vid = 8
        match = dp.ofproto_parser.OFPMatch()
        match.set_in_port(in_port)
        match.set_dl_type(eth_IP)
        match.set_vlan_vid(m_vid)
        actions = [dp.ofproto_parser.OFPActionPopVlan(),
                   dp.ofproto_parser.OFPActionOutput(out_port, 0)]
        self._add_flow(dp, match, actions)

        # ICMP -> PushVLAN(9)
        LOG.debug("--- add_flow ICMP to PushVLAN(9)")
        s_vid = 9
        match = dp.ofproto_parser.OFPMatch()
        match.set_in_port(in_port)
        match.set_dl_type(eth_IP)
        match.set_ip_proto(ip_ICMP)
        f = dp.ofproto_parser.OFPMatchField.make(
            dp.ofproto.OXM_OF_VLAN_VID, s_vid)
        actions = [dp.ofproto_parser.OFPActionPushVlan(eth_VLAN),
                   dp.ofproto_parser.OFPActionSetField(f),
                   dp.ofproto_parser.OFPActionOutput(out_port, 0)]
        self._add_flow(dp, match, actions)

        # VLAN(10) -> PushVLAN(20)
        # LOG.debug("--- add_flow VLAN(10) to PushVLAN(100)")
        # SKIP: ovs not supported
        m_vid = 10
        s_vid = 20
        match = dp.ofproto_parser.OFPMatch()
        match.set_in_port(in_port)
        match.set_dl_type(eth_IP)
        match.set_vlan_vid(m_vid)
        f = dp.ofproto_parser.OFPMatchField.make(
            dp.ofproto.OXM_OF_VLAN_VID, s_vid)
        actions = [dp.ofproto_parser.OFPActionPushVlan(eth_VLAN),
                   dp.ofproto_parser.OFPActionSetField(f),
                   dp.ofproto_parser.OFPActionOutput(out_port, 0)]
        # self._add_flow(dp, match, actions)

        # VLAN(100):VLAN -> PopVLAN
        LOG.debug("--- add_flow VLAN(100):VLAN to PopVLAN")
        m_vid = 100
        match = dp.ofproto_parser.OFPMatch()
        match.set_in_port(in_port)
        match.set_dl_type(eth_VLAN)
        match.set_vlan_vid(m_vid)
        actions = [dp.ofproto_parser.OFPActionPopVlan(),
                   dp.ofproto_parser.OFPActionOutput(out_port, 0)]
        self._add_flow(dp, match, actions)

    @set_ev_cls(dpset.EventDP, dpset.DPSET_EV_DISPATCHER)
    def handler_datapath(self, ev):
        if ev.enter:
            self._define_flow(ev.dp)

    @set_ev_cls(ofp_event.EventOFPPacketIn, MAIN_DISPATCHER)
    def packet_in_handler(self, ev):
        msg = ev.msg
        dst, src, eth_type = struct.unpack_from('!6s6sH', buffer(msg.data), 0)
        in_port = msg.match.fields[0].value

        LOG.info("----------------------------------------")
        LOG.info("* PacketIn")
        LOG.info("in_port=%d, eth_type: %s", in_port, hex(eth_type))
        LOG.info("packet reason=%d buffer_id=%d", msg.reason, msg.buffer_id)
        LOG.info("packet in datapath_id=%s src=%s dst=%s",
                 msg.datapath.id, haddr_to_str(src), haddr_to_str(dst))

########NEW FILE########
__FILENAME__ = test_icmp
# Copyright (C) 2012 Nippon Telegraph and Telephone Corporation.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import logging
import struct

from ryu.base import app_manager
from ryu.controller import ofp_event
from ryu.controller import dpset
from ryu.controller.handler import MAIN_DISPATCHER
from ryu.controller.handler import set_ev_cls
from ryu.ofproto import ofproto_v1_2
from ryu.lib.mac import haddr_to_str


LOG = logging.getLogger(__name__)


class RunTestMininet(app_manager.RyuApp):

    _CONTEXTS = {'dpset': dpset.DPSet}
    OFP_VERSIONS = [ofproto_v1_2.OFP_VERSION]

    def __init__(self, *args, **kwargs):
        super(RunTestMininet, self).__init__(*args, **kwargs)

    def _add_flow(self, dp, match, actions):
        inst = [dp.ofproto_parser.OFPInstructionActions(
            dp.ofproto.OFPIT_APPLY_ACTIONS, actions)]

        mod = dp.ofproto_parser.OFPFlowMod(
            dp, cookie=0, cookie_mask=0, table_id=0,
            command=dp.ofproto.OFPFC_ADD, idle_timeout=0, hard_timeout=0,
            priority=0xff, buffer_id=0xffffffff,
            out_port=dp.ofproto.OFPP_ANY, out_group=dp.ofproto.OFPG_ANY,
            flags=0, match=match, instructions=inst)

        dp.send_msg(mod)

    def _define_flow(self, dp):
        in_port = 1
        out_port = 2

        # port:1 -> port:2
        match = dp.ofproto_parser.OFPMatch()
        match.set_in_port(in_port)
        actions = [dp.ofproto_parser.OFPActionOutput(out_port, 0)]
        self._add_flow(dp, match, actions)

        # port:1 -> port:2
        match = dp.ofproto_parser.OFPMatch()
        match.set_in_port(out_port)
        actions = [dp.ofproto_parser.OFPActionOutput(in_port, 0)]
        self._add_flow(dp, match, actions)

    @set_ev_cls(dpset.EventDP, dpset.DPSET_EV_DISPATCHER)
    def handler_datapath(self, ev):
        if ev.enter:
            self._define_flow(ev.dp)

    @set_ev_cls(ofp_event.EventOFPPacketIn, MAIN_DISPATCHER)
    def packet_in_handler(self, ev):
        msg = ev.msg
        dst, src, eth_type = struct.unpack_from('!6s6sH', buffer(msg.data), 0)
        in_port = msg.match.fields[0].value

        LOG.info("----------------------------------------")
        LOG.info("* PacketIn")
        LOG.info("in_port=%d, eth_type: %s", in_port, hex(eth_type))
        LOG.info("packet reason=%d buffer_id=%d", msg.reason, msg.buffer_id)
        LOG.info("packet in datapath_id=%s src=%s dst=%s",
                 msg.datapath.id, haddr_to_str(src), haddr_to_str(dst))

########NEW FILE########
__FILENAME__ = test_ip_ttl
# Copyright (C) 2012 Nippon Telegraph and Telephone Corporation.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import logging
import struct

from ryu.base import app_manager
from ryu.controller import ofp_event
from ryu.controller import dpset
from ryu.controller.handler import MAIN_DISPATCHER
from ryu.controller.handler import set_ev_cls
from ryu.ofproto import ofproto_v1_2
from ryu.ofproto import ether
from ryu.lib.mac import haddr_to_str


LOG = logging.getLogger(__name__)


class RunTestMininet(app_manager.RyuApp):

    _CONTEXTS = {'dpset': dpset.DPSet}
    OFP_VERSIONS = [ofproto_v1_2.OFP_VERSION]

    def __init__(self, *args, **kwargs):
        super(RunTestMininet, self).__init__(*args, **kwargs)

    def _add_flow(self, dp, match, actions):
        inst = [dp.ofproto_parser.OFPInstructionActions(
            dp.ofproto.OFPIT_APPLY_ACTIONS, actions)]

        mod = dp.ofproto_parser.OFPFlowMod(
            dp, cookie=0, cookie_mask=0, table_id=0,
            command=dp.ofproto.OFPFC_ADD, idle_timeout=0, hard_timeout=0,
            priority=0xff, buffer_id=0xffffffff,
            out_port=dp.ofproto.OFPP_ANY, out_group=dp.ofproto.OFPG_ANY,
            flags=0, match=match, instructions=inst)

        dp.send_msg(mod)

    def _define_flow(self, dp):
        in_port = 1
        out_port = 2

        eth_IP = ether.ETH_TYPE_IP

        # ICMP -> DecNwTtl
        LOG.debug("--- add_flow DecNwTtl")
        match = dp.ofproto_parser.OFPMatch()
        match.set_in_port(in_port)
        match.set_dl_type(eth_IP)
        actions = [dp.ofproto_parser.OFPActionDecNwTtl(),
                   dp.ofproto_parser.OFPActionOutput(out_port, 0)]
        self._add_flow(dp, match, actions)

    @set_ev_cls(dpset.EventDP, dpset.DPSET_EV_DISPATCHER)
    def handler_datapath(self, ev):
        if ev.enter:
            self._define_flow(ev.dp)

    @set_ev_cls(ofp_event.EventOFPPacketIn, MAIN_DISPATCHER)
    def packet_in_handler(self, ev):
        msg = ev.msg
        dst, src, eth_type = struct.unpack_from('!6s6sH', buffer(msg.data), 0)
        in_port = msg.match.fields[0].value

        LOG.info("----------------------------------------")
        LOG.info("* PacketIn")
        LOG.info("in_port=%d, eth_type: %s", in_port, hex(eth_type))
        LOG.info("packet reason=%d buffer_id=%d", msg.reason, msg.buffer_id)
        LOG.info("packet in datapath_id=%s src=%s dst=%s",
                 msg.datapath.id, haddr_to_str(src), haddr_to_str(dst))

########NEW FILE########
__FILENAME__ = test_arp
# Copyright (C) 2012 Nippon Telegraph and Telephone Corporation.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# vim: tabstop=4 shiftwidth=4 softtabstop=4

import logging
import array
import netaddr

from ryu.base import app_manager
from ryu.controller import dpset
from ryu.controller import ofp_event
from ryu.controller import handler
from ryu.ofproto import ofproto_v1_2
from ryu.ofproto import ether
from ryu.ofproto import inet
from ryu.lib import mac
from ryu.lib.packet import packet
from ryu.lib.packet import ethernet
from ryu.lib.packet import arp
from ryu.lib.packet import ipv4
from ryu.lib.packet import icmp


LOG = logging.getLogger(__name__)


class RunTestMininet(app_manager.RyuApp):

    _CONTEXTS = {'dpset': dpset.DPSet}
    OFP_VERSIONS = [ofproto_v1_2.OFP_VERSION]

    ZERO_MAC = mac.haddr_to_bin('00:00:00:00:00:00')
    BROADCAST_MAC = mac.haddr_to_bin('ff:ff:ff:ff:ff:ff')
    RYU_MAC = mac.haddr_to_bin('fe:ee:ee:ee:ee:ef')
    HOST_MAC = mac.haddr_to_bin('00:00:00:00:00:01')
    RYU_IP = int(netaddr.IPAddress('10.0.0.100'))
    HOST_IP = int(netaddr.IPAddress('10.0.0.1'))

    def __init__(self, *args, **kwargs):
        super(RunTestMininet, self).__init__(*args, **kwargs)

    def _send_msg(self, dp, data):
        buffer_id = 0xffffffff
        in_port = dp.ofproto.OFPP_LOCAL
        actions = [dp.ofproto_parser.OFPActionOutput(1, 0)]
        msg = dp.ofproto_parser.OFPPacketOut(
            dp, buffer_id, in_port, actions, data)
        dp.send_msg(msg)

    def _add_flow(self, dp, match, actions):
        inst = [dp.ofproto_parser.OFPInstructionActions(
            dp.ofproto.OFPIT_APPLY_ACTIONS, actions)]
        mod = dp.ofproto_parser.OFPFlowMod(
            dp, cookie=0, cookie_mask=0, table_id=0,
            command=dp.ofproto.OFPFC_ADD, idle_timeout=0, hard_timeout=0,
            priority=0xff, buffer_id=0xffffffff,
            out_port=dp.ofproto.OFPP_ANY, out_group=dp.ofproto.OFPG_ANY,
            flags=0, match=match, instructions=inst)
        dp.send_msg(mod)

    def _find_protocol(self, pkt, name):
        for p in pkt.protocols:
            if hasattr(p, 'protocol_name'):
                if p.protocol_name == name:
                    return p

    def _get_protocols(self, pkt):
        protocols = {}
        for p in pkt:
            if hasattr(p, 'protocol_name'):
                protocols[p.protocol_name] = p
            else:
                protocols['payload'] = p
        return protocols

    def _build_ether(self, ethertype, dst_mac=HOST_MAC):
        e = ethernet.ethernet(dst_mac, self.RYU_MAC, ethertype)
        return e

    def _build_arp(self, opcode, dst_ip=HOST_IP):
        if opcode == arp.ARP_REQUEST:
            _eth_dst_mac = self.BROADCAST_MAC
            _arp_dst_mac = self.ZERO_MAC
        elif opcode == arp.ARP_REPLY:
            _eth_dst_mac = self.HOST_MAC
            _arp_dst_mac = self.HOST_MAC

        e = self._build_ether(ether.ETH_TYPE_ARP, _eth_dst_mac)
        a = arp.arp(hwtype=1, proto=ether.ETH_TYPE_IP, hlen=6, plen=4,
                    opcode=opcode, src_mac=self.RYU_MAC, src_ip=self.RYU_IP,
                    dst_mac=_arp_dst_mac, dst_ip=dst_ip)
        p = packet.Packet()
        p.add_protocol(e)
        p.add_protocol(a)
        p.serialize()

        return p

    def _build_echo(self, _type, echo):
        e = self._build_ether(ether.ETH_TYPE_IP)
        ip = ipv4.ipv4(version=4, header_length=5, tos=0, total_length=84,
                       identification=0, flags=0, offset=0, ttl=64,
                       proto=inet.IPPROTO_ICMP, csum=0,
                       src=self.RYU_IP, dst=self.HOST_IP)
        ping = icmp.icmp(_type, code=0, csum=0, data=echo)

        p = packet.Packet()
        p.add_protocol(e)
        p.add_protocol(ip)
        p.add_protocol(ping)
        p.serialize()
        return p

    def _garp(self):
        p = self._build_arp(arp.ARP_REQUEST, self.RYU_IP)
        return p.data

    def _arp_request(self):
        p = self._build_arp(arp.ARP_REQUEST, self.HOST_IP)
        return p.data

    def _arp_reply(self):
        p = self._build_arp(arp.ARP_REPLY, self.HOST_IP)
        return p.data

    def _echo_request(self, echo):
        p = self._build_echo(icmp.ICMP_ECHO_REQUEST, echo)
        return p.data

    def _echo_reply(self, echo):
        p = self._build_echo(icmp.ICMP_ECHO_REPLY, echo)
        return p.data

    @handler.set_ev_cls(ofp_event.EventOFPPacketIn, handler.MAIN_DISPATCHER)
    def packet_in_handler(self, ev):
        msg = ev.msg
        dp = msg.datapath

        pkt = packet.Packet(array.array('B', msg.data))
        p_arp = self._find_protocol(pkt, "arp")
        p_icmp = self._find_protocol(pkt, "icmp")
        p_ipv4 = self._find_protocol(pkt, "ipv4")

        if p_arp:
            src_ip = str(netaddr.IPAddress(p_arp.src_ip))
            dst_ip = str(netaddr.IPAddress(p_arp.dst_ip))
            if p_arp.opcode == arp.ARP_REQUEST:
                LOG.debug("--- PacketIn: ARP_Request: %s->%s", src_ip, dst_ip)
                if p_arp.dst_ip == self.RYU_IP:
                    LOG.debug("--- send Pkt: ARP_Reply")
                    data = self._arp_reply()
                    self._send_msg(dp, data)
                elif p_arp.dst_ip == self.HOST_IP:
                    LOG.debug("    PacketIn: GARP")
                    LOG.debug("--- send Pkt: ARP_Request")
                    data = self._arp_request()
                    self._send_msg(dp, data)
            elif p_arp.opcode == arp.ARP_REPLY:
                LOG.debug("--- PacketIn: ARP_Reply: %s->%s", src_ip, dst_ip)
                LOG.debug("--- send Pkt: Echo_Request")
                echo = icmp.echo(id_=66, seq=1)
                data = self._echo_request(echo)
                self._send_msg(dp, data)

        if p_icmp:
            src = str(netaddr.IPAddress(p_ipv4.src))
            dst = str(netaddr.IPAddress(p_ipv4.dst))
            if p_icmp.type == icmp.ICMP_ECHO_REQUEST:
                LOG.debug("--- PacketIn: Echo_Request: %s->%s", src, dst)
                if p_ipv4.dst == self.RYU_IP:
                    LOG.debug("--- send Pkt: Echo_Reply")
                    echo = p_icmp.data
                    echo.data = bytearray(echo.data)
                    data = self._echo_reply(echo)
                    self._send_msg(dp, data)
            elif p_icmp.type == icmp.ICMP_ECHO_REPLY:
                LOG.debug("--- PacketIn: Echo_Reply: %s->%s", src, dst)

    @handler.set_ev_cls(dpset.EventDP, dpset.DPSET_EV_DISPATCHER)
    def handler_datapath(self, ev):
        if ev.enter:
            dp = ev.dp

            LOG.debug("--- send Pkt: Gratuitous ARP_Request")
            data = self._garp()
            self._send_msg(dp, data)

########NEW FILE########
__FILENAME__ = run_tests
#!/usr/bin/env python


import os
import sys

from nose import config
from nose import core

sys.path.append(os.getcwd())
sys.path.append(os.path.dirname(__file__))


import ryu.tests.unit
from ryu.tests.test_lib import run_tests


if __name__ == '__main__':
    exit_status = False

    # if a single test case was specified,
    # we should only invoked the tests once
    invoke_once = len(sys.argv) > 1

    cwd = os.getcwd()
    c = config.Config(stream=sys.stdout,
                      env=os.environ,
                      verbosity=3,
                      includeExe=True,
                      traverseNamespace=True,
                      plugins=core.DefaultPluginManager())
    c.configureWhere(ryu.tests.unit.__path__)

    exit_status = run_tests(c)
    sys.exit(exit_status)

########NEW FILE########
__FILENAME__ = test_lib
#!/usr/bin/env python

import gettext
import os
import unittest
import sys
import logging

from nose import result
from nose import core
from nose import config
from nose.plugins.skip import SkipTest


class _AnsiColorizer(object):
    """
    A colorizer is an object that loosely wraps around a stream, allowing
    callers to write text to the stream in a particular color.

    Colorizer classes must implement C{supported()} and C{write(text, color)}.
    """
    _colors = dict(black=30, red=31, green=32, yellow=33,
                   blue=34, magenta=35, cyan=36, white=37)

    def __init__(self, stream):
        self.stream = stream

    def supported(cls, stream=sys.stdout):
        """
        A class method that returns True if the current platform supports
        coloring terminal output using this method. Returns False otherwise.
        """
        if not stream.isatty():
            return False  # auto color only on TTYs
        try:
            import curses
        except ImportError:
            return False
        else:
            try:
                try:
                    return curses.tigetnum("colors") > 2
                except curses.error:
                    curses.setupterm()
                    return curses.tigetnum("colors") > 2
            except:
                raise
                # guess false in case of error
                return False
    supported = classmethod(supported)

    def write(self, text, color):
        """
        Write the given text to the stream in the given color.

        @param text: Text to be written to the stream.

        @param color: A string label for a color. e.g. 'red', 'white'.
        """
        color = self._colors[color]
        self.stream.write('\x1b[%s;1m%s\x1b[0m' % (color, text))


class _Win32Colorizer(object):
    """
    See _AnsiColorizer docstring.
    """
    def __init__(self, stream):
        from win32console import GetStdHandle, STD_OUT_HANDLE
        from win32console import FOREGROUND_RED, FOREGROUND_BLUE
        from win32console import FOREGROUND_GREEN, FOREGROUND_INTENSITY
        red, green, blue, bold = (FOREGROUND_RED, FOREGROUND_GREEN,
                                  FOREGROUND_BLUE, FOREGROUND_INTENSITY)
        self.stream = stream
        self.screenBuffer = GetStdHandle(STD_OUT_HANDLE)
        self._colors = {
            'normal': red | green | blue,
            'red': red | bold,
            'green': green | bold,
            'blue': blue | bold,
            'yellow': red | green | bold,
            'magenta': red | blue | bold,
            'cyan': green | blue | bold,
            'white': red | green | blue | bold}

    def supported(cls, stream=sys.stdout):
        try:
            import win32console
            screenBuffer = win32console.GetStdHandle(
                win32console.STD_OUT_HANDLE)
        except ImportError:
            return False
        import pywintypes
        try:
            screenBuffer.SetConsoleTextAttribute(
                win32console.FOREGROUND_RED |
                win32console.FOREGROUND_GREEN |
                win32console.FOREGROUND_BLUE)
        except pywintypes.error:
            return False
        else:
            return True
    supported = classmethod(supported)

    def write(self, text, color):
        color = self._colors[color]
        self.screenBuffer.SetConsoleTextAttribute(color)
        self.stream.write(text)
        self.screenBuffer.SetConsoleTextAttribute(self._colors['normal'])


class _NullColorizer(object):
    """
    See _AnsiColorizer docstring.
    """
    def __init__(self, stream):
        self.stream = stream

    def supported(cls, stream=sys.stdout):
        return True
    supported = classmethod(supported)

    def write(self, text, color):
        self.stream.write(text)


class RyuTestResult(result.TextTestResult):
    def __init__(self, *args, **kw):
        result.TextTestResult.__init__(self, *args, **kw)
        self._last_case = None
        self.colorizer = None
        # NOTE(vish, tfukushima): reset stdout for the terminal check
        stdout = sys.__stdout__
        sys.stdout = sys.__stdout__
        for colorizer in [_Win32Colorizer, _AnsiColorizer, _NullColorizer]:
            if colorizer.supported():
                self.colorizer = colorizer(self.stream)
                break
        sys.stdout = stdout

    def getDescription(self, test):
        return str(test)

    # NOTE(vish, tfukushima): copied from unittest with edit to add color
    def addSuccess(self, test):
        unittest.TestResult.addSuccess(self, test)
        if self.showAll:
            self.colorizer.write("OK", 'green')
            self.stream.writeln()
        elif self.dots:
            self.stream.write('.')
            self.stream.flush()

    # NOTE(vish, tfukushima): copied from unittest with edit to add color
    def addFailure(self, test, err):
        unittest.TestResult.addFailure(self, test, err)
        if self.showAll:
            self.colorizer.write("FAIL", 'red')
            self.stream.writeln()
        elif self.dots:
            self.stream.write('F')
            self.stream.flush()

    # NOTE(vish, tfukushima): copied from unittest with edit to add color
    def addError(self, test, err):
        """Overrides normal addError to add support for errorClasses.
        If the exception is a registered class, the error will be added
        to the list for that class, not errors.
        """
        stream = getattr(self, 'stream', None)
        ec, ev, tb = err
        try:
            exc_info = self._exc_info_to_string(err, test)
        except TypeError:
            # This is for compatibility with Python 2.3.
            exc_info = self._exc_info_to_string(err)
        for cls, (storage, label, isfail) in self.errorClasses.items():
            if result.isclass(ec) and issubclass(ec, cls):
                if isfail:
                    test.passwd = False
                storage.append((test, exc_info))
                # Might get patched into a streamless result
                if stream is not None:
                    if self.showAll:
                        message = [label]
                        detail = result._exception_detail(err[1])
                        if detail:
                            message.append(detail)
                        stream.writeln(": ".join(message))
                    elif self.dots:
                        stream.write(label[:1])
                return
        self.errors.append((test, exc_info))
        test.passed = False
        if stream is not None:
            if self.showAll:
                self.colorizer.write("ERROR", 'red')
                self.stream.writeln()
            elif self.dots:
                stream.write('E')

    def startTest(self, test):
        unittest.TestResult.startTest(self, test)
        current_case = test.test.__class__.__name__

        if self.showAll:
            if current_case != self._last_case:
                self.stream.writeln(current_case)
                self._last_case = current_case
            #NOTE(salvatore-orlando):
            #slightly changed in order to print test case class
            #together with unit test name
            self.stream.write(
                '    %s' % str(test.test).ljust(60))
            self.stream.flush()


class RyuTestRunner(core.TextTestRunner):
    def _makeResult(self):
        return RyuTestResult(self.stream,
                             self.descriptions,
                             self.verbosity,
                             self.config)


def run_tests(c=None):
    logger = logging.getLogger()
    hdlr = logging.StreamHandler()
    formatter = logging.Formatter('%(asctime)s %(levelname)s %(message)s')
    hdlr.setFormatter(formatter)
    logger.addHandler(hdlr)
    logger.setLevel(logging.DEBUG)

    # NOTE(bgh): I'm not entirely sure why but nose gets confused here when
    # calling run_tests from a plugin directory run_tests.py (instead of the
    # main run_tests.py).  It will call run_tests with no arguments and the
    # testing of run_tests will fail (though the plugin tests will pass).  For
    # now we just return True to let the run_tests test pass.
    if not c:
        return True

    runner = RyuTestRunner(stream=c.stream,
                           verbosity=c.verbosity,
                           config=c)
    return not core.run(config=c, testRunner=runner)

########NEW FILE########
__FILENAME__ = test_wsgi
# Copyright (C) 2013 Stratosphere Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# vim: tabstop=4 shiftwidth=4 softtabstop=4

import unittest
import logging
from nose.tools import *

from ryu.app.wsgi import ControllerBase, WSGIApplication, route
from webob.response import Response
from ryu.lib import dpid as dpidlib

LOG = logging.getLogger('test_wsgi')


class _TestController(ControllerBase):

    def __init__(self, req, link, data, **config):
        super(_TestController, self).__init__(req, link, data, **config)
        eq_(data['test_param'], 'foo')

    @route('test', '/test/{dpid}',
           methods=['GET'], requirements={'dpid': dpidlib.DPID_PATTERN})
    def test_get_dpid(self, req, dpid, **_kwargs):
        return Response(status=200, body=dpid)

    @route('test', '/test')
    def test_root(self, req, **_kwargs):
        return Response(status=200, body='root')


class Test_wsgi(unittest.TestCase):

    """ Test case for wsgi
    """

    def setUp(self):
        controller_data = {
            'test_param': 'foo'
        }
        self.wsgi_app = WSGIApplication()
        self.wsgi_app.register(_TestController, controller_data)

    def tearDown(self):
        pass

    def test_wsgi_decorator_ok(self):
        r = self.wsgi_app({'REQUEST_METHOD': 'GET',
                           'PATH_INFO': '/test/0123456789abcdef'},
                          lambda s, _: eq_(s, '200 OK'))
        eq_(r[0], ('0123456789abcdef'))

    def test_wsgi_decorator_ng_path(self):
        self.wsgi_app({'REQUEST_METHOD': 'GET',
                       'PATH_INFO': '/'},
                      lambda s, _: eq_(s, '404 Not Found'))

    def test_wsgi_decorator_ng_method(self):
        # XXX: If response code is "405 Method Not Allowed", it is better.
        self.wsgi_app({'REQUEST_METHOD': 'PUT',
                       'PATH_INFO': '/test/0123456789abcdef'},
                      lambda s, _: eq_(s, '404 Not Found'))

    def test_wsgi_decorator_ng_requirements(self):
        # XXX: If response code is "400 Bad Request", it is better.
        self.wsgi_app({'REQUEST_METHOD': 'GET',
                       'PATH_INFO': '/test/hogehoge'},
                      lambda s, _: eq_(s, '404 Not Found'))

    def test_wsgi_decorator_ok_any_method(self):
        self.wsgi_app({'REQUEST_METHOD': 'GET',
                       'PATH_INFO': '/test'},
                      lambda s, _: eq_(s, '200 OK'))
        self.wsgi_app({'REQUEST_METHOD': 'POST',
                       'PATH_INFO': '/test'},
                      lambda s, _: eq_(s, '200 OK'))
        self.wsgi_app({'REQUEST_METHOD': 'PUT',
                       'PATH_INFO': '/test'},
                      lambda s, _: eq_(s, '200 OK'))
        r = self.wsgi_app({'REQUEST_METHOD': 'DELETE',
                           'PATH_INFO': '/test'},
                          lambda s, _: eq_(s, '200 OK'))
        eq_(r[0], 'root')

########NEW FILE########
__FILENAME__ = test_addrconv
# Copyright (C) 2013 Nippon Telegraph and Telephone Corporation.
# Copyright (C) 2013 YAMAMOTO Takashi <yamamoto at valinux co jp>
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import unittest
from nose.tools import eq_

import addrconv


class Test_addrconv(unittest.TestCase):
    """ Test case for ryu.lib.addrconv
    """

    def setUp(self):
        pass

    def tearDown(self):
        pass

    @staticmethod
    def _test_conv(conv, text_value, bin_value):
        eq_(conv.text_to_bin(text_value), bin_value)
        eq_(conv.bin_to_text(bin_value), text_value)

    def test_ipv4(self):
        self._test_conv(addrconv.ipv4, '0.0.0.0', '\x00\x00\x00\x00')
        self._test_conv(addrconv.ipv4, '127.0.0.1', '\x7f\x00\x00\x01')
        self._test_conv(addrconv.ipv4, '255.255.0.0', '\xff\xff\x00\x00')

    def test_ipv6(self):
        self._test_conv(addrconv.ipv6, 'ff02::1',
                        ('\xff\x02\x00\x00\x00\x00\x00\x00'
                         '\x00\x00\x00\x00\x00\x00\x00\x01'))
        self._test_conv(addrconv.ipv6, 'fe80::f00b:a4ff:fe7d:f8ea',
                        ('\xfe\x80\x00\x00\x00\x00\x00\x00'
                         '\xf0\x0b\xa4\xff\xfe\x7d\xf8\xea'))
        self._test_conv(addrconv.ipv6, '::',
                        ('\x00\x00\x00\x00\x00\x00\x00\x00'
                         '\x00\x00\x00\x00\x00\x00\x00\x00'))

    def test_mac(self):
        self._test_conv(addrconv.mac, 'f2:0b:a4:01:0a:23',
                        '\xf2\x0b\xa4\x01\x0a\x23')

########NEW FILE########
__FILENAME__ = test_hub
# Copyright (C) 2013 Nippon Telegraph and Telephone Corporation.
# Copyright (C) 2013 YAMAMOTO Takashi <yamamoto at valinux co jp>
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import time
import unittest
from nose.tools import raises

from ryu.lib import hub
hub.patch()


class MyException(BaseException):
    pass


class Test_hub(unittest.TestCase):
    """ Test case for ryu.lib.hub
    """

    def setUp(self):
        pass

    def tearDown(self):
        pass

    # we want to test timeout first because the rest of tests rely on it.
    # thus test_0_ prefix.

    @raises(hub.Timeout)
    def test_0_timeout1(self):
        with hub.Timeout(0.1):
            hub.sleep(1)

    @raises(MyException)
    def test_0_timeout2(self):
        with hub.Timeout(0.1, MyException):
            hub.sleep(1)

    def test_0_timeout3(self):
        with hub.Timeout(1):
            hub.sleep(0.1)
        # sleep some more to ensure timer cancelation
        hub.sleep(2)

    def test_spawn_event1(self):
        def _child(ev, result):
            hub.sleep(1)
            result.append(1)
            ev.set()

        ev = hub.Event()
        result = []
        with hub.Timeout(2):
            hub.spawn(_child, ev, result)
            ev.wait()
        assert len(result) == 1

    def test_spawn_event2(self):
        def _child(ev, result):
            hub.sleep(1)
            result.append(1)
            ev.set()

        ev = hub.Event()
        result = []
        with hub.Timeout(2):
            t = hub.spawn(_child, ev, result)
            ev.wait(timeout=0.5)
        assert len(result) == 0
        ev.wait()
        assert len(result) == 1

    def test_spawn_event3(self):
        def _child(ev, ev2, result):
            ev2.wait()
            hub.sleep(0.5)
            result.append(1)
            ev.set()

        ev = hub.Event()
        ev2 = hub.Event()
        result = []
        with hub.Timeout(2):
            hub.spawn(_child, ev, ev2, result)
            hub.spawn(_child, ev, ev2, result)
            hub.sleep(0.5)
            ev2.set()  # this should wake up the above created two threads
            ev.wait(timeout=1)
        assert len(result) == 2

    def test_spawn_select1(self):
        import select
        import socket

        def _child(s1):
            hub.sleep(0.5)
            s1.send("hoge")

        s1, s2 = socket.socketpair()
        with hub.Timeout(1):
            hub.spawn(_child, s1)
            select.select([s2.fileno()], [], [])
            select.select([s2.fileno()], [], [])  # return immediately

    @raises(MyException)
    def test_select1(self):
        import select
        import socket

        s1, s2 = socket.socketpair()
        with hub.Timeout(1, MyException):
            select.select([s2.fileno()], [], [])

    def test_select2(self):
        import select

        with hub.Timeout(1, MyException):
            select.select([], [], [], 0)  # timeout immediately

    def test_select3(self):
        import select
        import socket

        s1, s2 = socket.socketpair()
        with hub.Timeout(1, MyException):
            list = [s1.fileno(), s2.fileno()]
            rlist, wlist, xlist = select.select(list, list, list)
            assert not s1.fileno() in rlist
            assert not s2.fileno() in rlist
            # the following two assertions are commented out because one of
            # them fails with eventlet-patched select.
            #       assert s1.fileno() in wlist
            #       assert s2.fileno() in wlist
            # note: eventlet-patched select returns at most one file.
            assert (s1.fileno() in wlist) or (s2.fileno() in wlist)
            assert not s1.fileno() in xlist
            assert not s2.fileno() in xlist

    def test_spawn_joinall(self):
        def _child(ev2, result):
            ev2.wait()
            hub.sleep(0.5)
            result.append(1)
            raise BaseException("this exception should not be propagated")

        ev2 = hub.Event()
        threads = []
        result = []
        with hub.Timeout(2):
            threads.append(hub.spawn(_child, ev2, result))
            threads.append(hub.spawn(_child, ev2, result))
            hub.sleep(0.5)
            ev2.set()  # this should wake up the above created two threads
            hub.joinall(threads)
        assert len(result) == 2

    def test_spawn_kill_joinall(self):
        def _child(ev2, result):
            ev2.wait()
            result.append(1)

        ev2 = hub.Event()
        threads = []
        result = []
        with hub.Timeout(2):
            threads.append(hub.spawn(_child, ev2, result))
            threads.append(hub.spawn(_child, ev2, result))
            hub.sleep(0.5)
            for t in threads:
                hub.kill(t)
            hub.joinall(threads)
        assert len(result) == 0

    def test_spawn_kill_nowait_joinall(self):
        # XXX this test relies on the scheduling behaviour.
        # the intention here is, killing threads before they get active.

        def _child(result):
            result.append(1)

        threads = []
        result = []
        with hub.Timeout(2):
            threads.append(hub.spawn(_child, result))
            for t in threads:
                hub.kill(t)
            hub.joinall(threads)
        assert len(result) == 0

    def test_spawn_kill_die_joinall(self):
        def _child(result):
            result.append(1)

        threads = []
        result = []
        with hub.Timeout(2):
            threads.append(hub.spawn(_child, result))
            threads.append(hub.spawn(_child, result))
            hub.sleep(0.5)
            for t in threads:
                hub.kill(t)
            hub.joinall(threads)
        assert len(result) == 2

    def test_spawn_exception_joinall(self):
        def _child():
            raise Exception("hoge")

        threads = []
        with hub.Timeout(2):
            threads.append(hub.spawn(_child))
            threads.append(hub.spawn(_child))
            hub.sleep(0.5)
            hub.joinall(threads)

    def test_event1(self):
        ev = hub.Event()
        ev.set()
        with hub.Timeout(1):
            ev.wait()  # should return immediately

    def test_event2(self):
        ev = hub.Event()
        # allow multiple sets unlike eventlet Event
        ev.set()
        ev.set()

########NEW FILE########
__FILENAME__ = test_import_module
# Copyright (C) 2013 Nippon Telegraph and Telephone Corporation.
# Copyright (C) 2013 YAMAMOTO Takashi <yamamoto at valinux co jp>
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import unittest
from nose.tools import eq_

from ryu.utils import import_module
import ryu.tests.unit.lib.test_mod.fuga.mod


class Test_import_module(unittest.TestCase):
    """ Test case for ryu.utils.import_module
    """

    def setUp(self):
        pass

    def tearDown(self):
        pass

    @staticmethod
    def _my_import(name):
        mod = __import__(name)
        components = name.split('.')
        for c in components[1:]:
            mod = getattr(mod, c)
        return mod

    def test_import_module_with_same_basename(self):
        fuga = import_module('ryu.tests.unit.lib.test_mod.fuga.mod')
        eq_("this is fuga", fuga.name)
        hoge = import_module('ryu.tests.unit.lib.test_mod.hoge.mod')
        eq_("this is hoge", hoge.name)

    def test_import_module_by_filename(self):
        fuga = import_module('./lib/test_mod/fuga/mod.py')
        eq_("this is fuga", fuga.name)
        hoge = import_module('./lib/test_mod/hoge/mod.py')
        eq_("this is hoge", hoge.name)

    def test_import_same_module1(self):
        fuga1 = import_module('./lib/test_mod/fuga/mod.py')
        eq_("this is fuga", fuga1.name)
        eq_(ryu.tests.unit.lib.test_mod.fuga.mod, fuga1)

    def test_import_same_module2(self):
        fuga1 = import_module('./lib/test_mod/fuga/mod.py')
        eq_("this is fuga", fuga1.name)
        fuga2 = import_module('ryu.tests.unit.lib.test_mod.fuga.mod')
        eq_("this is fuga", fuga2.name)
        eq_(fuga1, fuga2)

    def test_import_same_module3(self):
        fuga1 = import_module('./lib/test_mod/fuga/mod.py')
        eq_("this is fuga", fuga1.name)
        fuga3 = self._my_import('ryu.tests.unit.lib.test_mod.fuga.mod')
        eq_("this is fuga", fuga3.name)
        eq_(fuga1, fuga3)

########NEW FILE########
__FILENAME__ = test_ip
import unittest
import logging
import struct
import netaddr
from struct import *
from nose.tools import *
from nose.plugins.skip import Skip, SkipTest

from ryu.lib import ip

LOG = logging.getLogger('test_ip')


class Test_ip(unittest.TestCase):
    '''
        test case for ip address module
    '''

    def setUp(self):
        pass

    def tearDown(self):
        pass

    def test_ipv4_to_bin(self):
        ipv4_str = '10.28.197.1'
        val = 0x0a1cc501

        (res,) = struct.unpack('!I', ip.ipv4_to_bin(ipv4_str))
        eq_(val, res)

    def test_ipv4_to_str(self):
        ipv4_bin = struct.pack('!I', 0x0a1cc501)
        val = '10.28.197.1'

        res = ip.ipv4_to_str(ipv4_bin)
        eq_(val, res)

    def test_ipv6_to_bin(self):
        ipv6_str = '2013:da8:215:8f2:aa20:66ff:fe4c:9c3c'
        val = struct.pack('!8H', 0x2013, 0xda8, 0x215, 0x8f2, 0xaa20, 0x66ff,
                          0xfe4c, 0x9c3c)
        res = ip.ipv6_to_bin(ipv6_str)
        eq_(val, res)

    def test_ipv6_to_bin_with_shortcut(self):
        ipv6_str = '3f:10::1:2'
        val = struct.pack('!8H', 0x3f, 0x10, 0, 0, 0, 0, 0x1, 0x2)

        res = ip.ipv6_to_bin(ipv6_str)
        eq_(val, res)

    def test_ipv6_to_str(self):
        ipv6_bin = struct.pack('!8H', 0x2013, 0xda8, 0x215, 0x8f2, 0xaa20,
                               0x66ff, 0xfe4c, 0x9c3c)
        val = '2013:da8:215:8f2:aa20:66ff:fe4c:9c3c'

        res = ip.ipv6_to_str(ipv6_bin)
        print val, res
        eq_(val, res)

########NEW FILE########
__FILENAME__ = test_mac
# Copyright (C) 2012 Nippon Telegraph and Telephone Corporation.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# vim: tabstop=4 shiftwidth=4 softtabstop=4

import unittest
import logging
import struct
import netaddr
from struct import *
from nose.tools import *
from nose.plugins.skip import Skip, SkipTest

from ryu.lib import mac

LOG = logging.getLogger('test_mac')


class Test_mac(unittest.TestCase):
    """ Test case for mac
    """

    def setUp(self):
        pass

    def tearDown(self):
        pass

    def test_mac_is_multicast(self):
        addr = '\x01\x23\x45\x67\x89\x0a'
        val = True

        res = mac.is_multicast(addr)

        eq_(val, res)

    def test_mac_haddr_to_str(self):
        addr = 'aa:aa:aa:aa:aa:aa'
        val = '\xaa\xaa\xaa\xaa\xaa\xaa'

        res = mac.haddr_to_str(val)

        eq_(addr, res)

    def test_mac_haddr_to_str_none(self):
        """ addr is None
        """
        addr = None
        val = 'None'
        res = mac.haddr_to_str(addr)

        eq_(val, res)

    @raises(AssertionError)
    def test_mac_haddr_to_str_assert(self):
        val = '\xaa\xaa\xaa\xaa\xaa'

        res = mac.haddr_to_str(val)

    def test_mac_haddr_to_bin_false(self):
        """ len(hexes) = 6 (False)
        """
        addr = 'aa:aa:aa:aa:aa:aa'
        val = '\xaa\xaa\xaa\xaa\xaa\xaa'

        res = mac.haddr_to_bin(addr)

        eq_(val, res)

    @raises(ValueError)
    def test_mac_haddr_to_bin_true(self):
        """ len(hexes) != 6 (True)
        """
        addr = 'aa:aa:aa:aa:aa'
        res = mac.haddr_to_bin(addr)

    def test_mac_haddr_bitand(self):
        addr = '\xaa\xaa\xaa\xaa\xaa\xaa'
        mask = '\xff\xff\xff\x00\x00\x00'
        val = '\xaa\xaa\xaa\x00\x00\x00'

        res = mac.haddr_bitand(addr, mask)

        eq_(val, res)

########NEW FILE########
__FILENAME__ = mod
# Copyright (C) 2013 Nippon Telegraph and Telephone Corporation.
# Copyright (C) 2013 YAMAMOTO Takashi <yamamoto at valinux co jp>
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.

name = "this is fuga"

########NEW FILE########
__FILENAME__ = mod
# Copyright (C) 2013 Nippon Telegraph and Telephone Corporation.
# Copyright (C) 2013 YAMAMOTO Takashi <yamamoto at valinux co jp>
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.

name = "this is hoge"

########NEW FILE########
__FILENAME__ = test_ofctl_v1_3
# Copyright (C) 2013 Stratosphere Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# vim: tabstop=4 shiftwidth=4 softtabstop=4

import unittest
import logging
from nose.tools import *

from ryu.lib import ofctl_v1_3
from ryu.ofproto import ofproto_v1_3, ofproto_v1_3_parser
from ryu.ofproto.ofproto_v1_3_parser import OFPActionPopMpls

LOG = logging.getLogger('test_ofctl_v1_3')


class _Datapath(object):
    ofproto = ofproto_v1_3
    ofproto_parser = ofproto_v1_3_parser


class Test_ofctl_v1_3(unittest.TestCase):

    """ Test case for ofctl_v1_3
    """

    def setUp(self):
        pass

    def tearDown(self):
        pass

    def test_to_actions_pop_mpls(self):
        dp = _Datapath()

        acts = [
            {
                'type': 'POP_MPLS',
                'ethertype': 0x0800
            }
        ]
        result = ofctl_v1_3.to_actions(dp, acts)
        insts = result[0]
        act = insts.actions[0]
        ok_(isinstance(act, OFPActionPopMpls))
        eq_(act.ethertype, 0x0800)

########NEW FILE########
__FILENAME__ = test_ofp_pktinfilter
# Copyright (C) 2013 Stratosphere Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# vim: tabstop=4 shiftwidth=4 softtabstop=4

import unittest
import logging

from nose.tools import *

from ryu.base import app_manager
from ryu.controller import ofp_event
from ryu.controller.handler import (
    set_ev_cls,
    MAIN_DISPATCHER,
)
from ryu.lib.packet import vlan, ethernet, ipv4
from ryu.lib.ofp_pktinfilter import packet_in_filter, RequiredTypeFilter
from ryu.lib import mac
from ryu.ofproto import ether, ofproto_v1_3, ofproto_v1_3_parser


LOG = logging.getLogger('test_pktinfilter')


class _Datapath(object):
    ofproto = ofproto_v1_3
    ofproto_parser = ofproto_v1_3_parser


class _PacketInFilterApp(app_manager.RyuApp):

    def __init__(self, *args, **kwargs):
        super(_PacketInFilterApp, self).__init__(*args, **kwargs)

    @set_ev_cls(ofp_event.EventOFPPacketIn, MAIN_DISPATCHER)
    @packet_in_filter(RequiredTypeFilter, {'types': [
        vlan.vlan,
    ]})
    def packet_in_handler(self, ev):
        return True


class Test_packet_in_filter(unittest.TestCase):

    """ Test case for pktinfilter
    """

    def setUp(self):
        self.app = _PacketInFilterApp()

    def tearDown(self):
        pass

    def test_pkt_in_filter_pass(self):
        datapath = _Datapath()
        e = ethernet.ethernet(mac.BROADCAST_STR,
                              mac.BROADCAST_STR,
                              ether.ETH_TYPE_8021Q)
        v = vlan.vlan()
        i = ipv4.ipv4()
        pkt = (e / v / i)
        pkt.serialize()
        pkt_in = ofproto_v1_3_parser.OFPPacketIn(datapath,
                                                 data=buffer(pkt.data))
        ev = ofp_event.EventOFPPacketIn(pkt_in)
        ok_(self.app.packet_in_handler(ev))

    def test_pkt_in_filter_discard(self):
        datapath = _Datapath()
        e = ethernet.ethernet(mac.BROADCAST_STR,
                              mac.BROADCAST_STR,
                              ether.ETH_TYPE_IP)
        i = ipv4.ipv4()
        pkt = (e / i)
        pkt.serialize()
        pkt_in = ofproto_v1_3_parser.OFPPacketIn(datapath,
                                                 data=buffer(pkt.data))
        ev = ofp_event.EventOFPPacketIn(pkt_in)
        ok_(not self.app.packet_in_handler(ev))

    def test_pkt_in_filter_truncated(self):
        datapath = _Datapath()
        truncated_data = buffer('')
        pkt_in = ofproto_v1_3_parser.OFPPacketIn(datapath,
                                                 data=truncated_data)
        ev = ofp_event.EventOFPPacketIn(pkt_in)
        ok_(not self.app.packet_in_handler(ev))

########NEW FILE########
__FILENAME__ = test_stringify
#!/usr/bin/env python
#
# Copyright (C) 2013 Nippon Telegraph and Telephone Corporation.
# Copyright (C) 2013 YAMAMOTO Takashi <yamamoto at valinux co jp>
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import base64
import unittest
from nose.tools import eq_

from ryu.lib import stringify


class C1(stringify.StringifyMixin):
    def __init__(self, a, c):
        print "init", a, c
        self.a = a
        self._b = 'B'
        self.c = c


class Test_stringify(unittest.TestCase):
    """ Test case for ryu.lib.stringify
    """

    def setUp(self):
        pass

    def tearDown(self):
        pass

    def test_jsondict(self):
        j = {'C1': {'a': 'QUFB', 'c': 'Q0ND'}}
        eq_(j['C1']['a'], base64.b64encode('AAA'))
        eq_(j['C1']['c'], base64.b64encode('CCC'))
        c = C1(a='AAA', c='CCC')
        c2 = C1.from_jsondict(j['C1'])
        eq_(c.__class__, c2.__class__)
        eq_(c.__dict__, c2.__dict__)
        eq_(j, c.to_jsondict())

    def test_jsondict2(self):
        import string

        def my_encode(x):
            return string.lower(x)

        def my_decode(x):
            return string.upper(x)

        j = {'C1': {'a': 'aaa', 'c': 'ccc'}}
        eq_(j['C1']['a'], my_encode('AAA'))
        eq_(j['C1']['c'], my_encode('CCC'))
        c = C1(a='AAA', c='CCC')
        c2 = C1.from_jsondict(j['C1'], decode_string=my_decode)
        eq_(c.__class__, c2.__class__)
        eq_(c.__dict__, c2.__dict__)
        eq_(j, c.to_jsondict(encode_string=my_encode))

########NEW FILE########
__FILENAME__ = test_ether
# Copyright (C) 2012 Nippon Telegraph and Telephone Corporation.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# vim: tabstop=4 shiftwidth=4 softtabstop=4

import unittest
import logging
from nose.tools import eq_
from ryu.ofproto.ether import *


LOG = logging.getLogger('test_ether')


class TestInet(unittest.TestCase):
    """ Test case for ether
    """

    def test_ether_type(self):
        eq_(ETH_TYPE_IP, 0x0800)
        eq_(ETH_TYPE_ARP, 0x0806)
        eq_(ETH_TYPE_8021Q, 0x8100)
        eq_(ETH_TYPE_IPV6, 0x86dd)
        eq_(ETH_TYPE_MPLS, 0x8847)
        eq_(ETH_TYPE_SLOW, 0x8809)

########NEW FILE########
__FILENAME__ = test_inet
# Copyright (C) 2012 Nippon Telegraph and Telephone Corporation.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# vim: tabstop=4 shiftwidth=4 softtabstop=4

import unittest
import logging
from nose.tools import eq_
from ryu.ofproto.inet import *


LOG = logging.getLogger('test_inet')


class TestInet(unittest.TestCase):
    """ Test case for inet
    """

    def test_ip_proto(self):
        eq_(IPPROTO_IP, 0)
        eq_(IPPROTO_HOPOPTS, 0)
        eq_(IPPROTO_ICMP, 1)
        eq_(IPPROTO_TCP, 6)
        eq_(IPPROTO_UDP, 17)
        eq_(IPPROTO_ROUTING, 43)
        eq_(IPPROTO_FRAGMENT, 44)
        eq_(IPPROTO_AH, 51)
        eq_(IPPROTO_ICMPV6, 58)
        eq_(IPPROTO_NONE, 59)
        eq_(IPPROTO_DSTOPTS, 60)
        eq_(IPPROTO_SCTP, 132)

########NEW FILE########
__FILENAME__ = test_ofproto
# Copyright (C) 2013 Nippon Telegraph and Telephone Corporation.
# Copyright (C) 2013 Isaku Yamahata <yamahata at private email ne jp>
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# vim: tabstop=4 shiftwidth=4 softtabstop=4

import unittest
import logging
from nose.tools import eq_


LOG = logging.getLogger('test_ofproto')


class TestOfprotCommon(unittest.TestCase):
    """ Test case for ofproto
    """

    def test_ofp_event(self):
        import ryu.ofproto
        reload(ryu.ofproto)
        import ryu.controller.ofp_event
        reload(ryu.controller.ofp_event)

    def test_ofproto(self):
        # When new version of OFP support is added,
        # this test must be updated.
        import ryu.ofproto
        reload(ryu.ofproto)
        ofp_modules = ryu.ofproto.get_ofp_modules()

        import ryu.ofproto.ofproto_v1_0
        import ryu.ofproto.ofproto_v1_2
        import ryu.ofproto.ofproto_v1_3
        eq_(set(ofp_modules.keys()), set([ryu.ofproto.ofproto_v1_0.OFP_VERSION,
                                          ryu.ofproto.ofproto_v1_2.OFP_VERSION,
                                          ryu.ofproto.ofproto_v1_3.OFP_VERSION,
                                          ]))
        consts_mods = set([ofp_mod[0] for ofp_mod in ofp_modules.values()])
        eq_(consts_mods, set([ryu.ofproto.ofproto_v1_0,
                              ryu.ofproto.ofproto_v1_2,
                              ryu.ofproto.ofproto_v1_3,
                              ]))

        parser_mods = set([ofp_mod[1] for ofp_mod in ofp_modules.values()])
        import ryu.ofproto.ofproto_v1_0_parser
        import ryu.ofproto.ofproto_v1_2_parser
        import ryu.ofproto.ofproto_v1_3_parser
        eq_(parser_mods, set([ryu.ofproto.ofproto_v1_0_parser,
                              ryu.ofproto.ofproto_v1_2_parser,
                              ryu.ofproto.ofproto_v1_3_parser,
                              ]))

########NEW FILE########
__FILENAME__ = test_ofproto_common
# Copyright (C) 2012 Nippon Telegraph and Telephone Corporation.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# vim: tabstop=4 shiftwidth=4 softtabstop=4

import unittest
import logging
from nose.tools import eq_
from ryu.ofproto.ofproto_common import *


LOG = logging.getLogger('test_ofproto_common')


class TestOfprotCommon(unittest.TestCase):
    """ Test case for ofproto_common
    """

    def test_struct_ofp_header(self):
        eq_(OFP_HEADER_PACK_STR, '!BBHI')
        eq_(OFP_HEADER_SIZE, 8)

    def test_define_constants(self):
        eq_(OFP_TCP_PORT, 6633)
        eq_(OFP_SSL_PORT, 6633)

########NEW FILE########
__FILENAME__ = test_ofproto_parser
# Copyright (C) 2012 Nippon Telegraph and Telephone Corporation.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# vim: tabstop=4 shiftwidth=4 softtabstop=4

import binascii
import unittest
from nose.tools import *
import struct
from ryu import exception

from ryu.ofproto import ofproto_common, ofproto_parser
from ryu.ofproto import ofproto_v1_0, ofproto_v1_0_parser

import logging
LOG = logging.getLogger(__name__)


class TestOfproto_Parser(unittest.TestCase):
    def setUp(self):
        LOG.debug('setUp')
        self.bufHello = binascii.unhexlify('0100000800000001')

        fr = '010600b0000000020000000000000abc' \
            + '00000100010000000000008700000fff' \
            + '0002aefa39d2b9177472656d61302d30' \
            + '00000000000000000000000000000000' \
            + '000000c0000000000000000000000000' \
            + 'fffe723f9a764cc87673775f30786162' \
            + '63000000000000000000000100000001' \
            + '00000082000000000000000000000000' \
            + '00012200d6c5a1947472656d61312d30' \
            + '00000000000000000000000000000000' \
            + '000000c0000000000000000000000000'
        self.bufFeaturesReply = binascii.unhexlify(fr)

        pi = '010a005200000000000001010040' \
            + '00020000000000000002000000000001' \
            + '080045000032000000004011f967c0a8' \
            + '0001c0a8000200010001001e00000000' \
            + '00000000000000000000000000000000' \
            + '00000000'
        self.bufPacketIn = binascii.unhexlify(pi)

    def tearDown(self):
        LOG.debug('tearDown')
        pass

    def testHello(self):
        (version,
         msg_type,
         msg_len,
         xid) = ofproto_parser.header(self.bufHello)
        eq_(version, 1)
        eq_(msg_type, 0)
        eq_(msg_len, 8)
        eq_(xid, 1)

    def testFeaturesReply(self):
        (version,
         msg_type,
         msg_len,
         xid) = ofproto_parser.header(self.bufFeaturesReply)

        msg = ofproto_parser.msg(self,
                                 version,
                                 msg_type,
                                 msg_len,
                                 xid,
                                 self.bufFeaturesReply)
        LOG.debug(msg)

        ok_(isinstance(msg, ofproto_v1_0_parser.OFPSwitchFeatures))
        LOG.debug(msg.ports[65534])
        ok_(isinstance(msg.ports[1], ofproto_v1_0_parser.OFPPhyPort))
        ok_(isinstance(msg.ports[2], ofproto_v1_0_parser.OFPPhyPort))
        ok_(isinstance(msg.ports[65534], ofproto_v1_0_parser.OFPPhyPort))

    def testPacketIn(self):
        (version,
         msg_type,
         msg_len,
         xid) = ofproto_parser.header(self.bufPacketIn)

        msg = ofproto_parser.msg(self,
                                 version,
                                 msg_type,
                                 msg_len,
                                 xid,
                                 self.bufPacketIn)
        LOG.debug(msg)
        ok_(isinstance(msg, ofproto_v1_0_parser.OFPPacketIn))

    @raises(AssertionError)
    def test_check_msg_len(self):
        (version,
         msg_type,
         msg_len,
         xid) = ofproto_parser.header(self.bufPacketIn)

        msg_len = len(self.bufPacketIn) + 1
        ofproto_parser.msg(self,
                           version,
                           msg_type,
                           msg_len,
                           xid,
                           self.bufPacketIn)

    @raises(exception.OFPUnknownVersion)
    def test_check_msg_parser(self):
        (version,
         msg_type,
         msg_len,
         xid) = ofproto_parser.header(self.bufPacketIn)

        version = 0xff
        ofproto_parser.msg(self,
                           version,
                           msg_type,
                           msg_len,
                           xid,
                           self.bufPacketIn)


class TestMsgBase(unittest.TestCase):
    """ Test case for ofproto_parser.MsgBase
    """

    def setUp(self):
        pass

    def tearDown(self):
        pass

    def test_init(self):
        pass

    def test_set_xid(self):
        xid = 3841413783
        c = ofproto_parser.MsgBase(object)
        c.set_xid(xid)
        eq_(xid, c.xid)

    @raises(AssertionError)
    def test_set_xid_check_xid(self):
        xid = 2160492514
        c = ofproto_parser.MsgBase(object)
        c.xid = xid
        c.set_xid(xid)

    def _test_parser(self, msg_type=ofproto_v1_0.OFPT_HELLO):
        version = ofproto_v1_0.OFP_VERSION
        msg_len = ofproto_v1_0.OFP_HEADER_SIZE
        xid = 2183948390
        data = '\x00\x01\x02\x03'

        fmt = ofproto_v1_0.OFP_HEADER_PACK_STR
        buf = struct.pack(fmt, version, msg_type, msg_len, xid) \
            + data

        res = ofproto_v1_0_parser.OFPHello.parser(
            object, version, msg_type, msg_len, xid, bytearray(buf))

        eq_(version, res.version)
        eq_(msg_type, res.msg_type)
        eq_(msg_len, res.msg_len)
        eq_(xid, res.xid)
        eq_(buffer(buf), res.buf)

        # test __str__()
        list_ = ('version:', 'msg_type', 'xid')
        check = {}
        str_ = str(res)
        str_ = str_.rsplit()

        i = 0
        for s in str_:
            if s in list_:
                check[str_[i]] = str_[i + 1]
            i += 1

        eq_(hex(ofproto_v1_0.OFP_VERSION).find(check['version:']), 0)
        eq_(hex(ofproto_v1_0.OFPT_HELLO).find(check['msg_type']), 0)
        eq_(hex(xid).find(check['xid']), 0)

        return True

    def test_parser(self):
        ok_(self._test_parser())

    @raises(AssertionError)
    def test_parser_check_msg_type(self):
        self._test_parser(ofproto_v1_0.OFPT_ERROR)

    def _test_serialize(self):

        class Datapath(object):
            ofproto = ofproto_v1_0
            ofproto_parser = ofproto_v1_0_parser

        c = ofproto_v1_0_parser.OFPHello(Datapath)

        c.serialize()
        eq_(ofproto_v1_0.OFP_VERSION, c.version)
        eq_(ofproto_v1_0.OFPT_HELLO, c.msg_type)
        eq_(0, c.xid)

        return True

    def test_serialize(self):
        ok_(self._test_serialize())


class TestMsgPackInto(unittest.TestCase):
    """ Test case for ofproto_parser.msg_pack_into
    """

    def _test_msg_pack_into(self, offset_type='e'):
        fmt = '!HH'
        len_ = struct.calcsize(fmt)
        buf = bytearray(len_)
        offset = len_
        arg1 = 1
        arg2 = 2

        if offset_type == 'l':
            offset += 1
        elif offset_type == 'g':
            offset -= 1

        ofproto_parser.msg_pack_into(fmt, buf, offset, arg1, arg2)

        check_offset = len(buf) - len_
        res = struct.unpack_from(fmt, buffer(buf), check_offset)

        eq_(arg1, res[0])
        eq_(arg2, res[1])

        return True

    def test_msg_pack_into(self):
        ok_(self._test_msg_pack_into())

    def test_msg_pack_into_less(self):
        ok_(self._test_msg_pack_into('l'))

    def test_msg_pack_into_greater(self):
        ok_(self._test_msg_pack_into('g'))


class TestMsgStrAttr(unittest.TestCase):
    """ Test case for ofproto_parser.msg_str_attr
    """

    def test_msg_str_attr(self):
        class Check(object):
            check = 'msg_str_attr_test'

        c = Check()
        buf = ''

        res = ofproto_parser.msg_str_attr(c, buf, ('check',))
        str_ = str(res)
        str_ = str_.rsplit()
        eq_('check', str_[0])
        eq_('msg_str_attr_test', str_[1])

########NEW FILE########
__FILENAME__ = test_ofproto_v12
# Copyright (C) 2012 Nippon Telegraph and Telephone Corporation.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# vim: tabstop=4 shiftwidth=4 softtabstop=4

import unittest
import logging
from nose.tools import eq_
from ryu.ofproto.ofproto_v1_2 import *


LOG = logging.getLogger('test_ofproto_v12')


class TestOfprot12(unittest.TestCase):
    """ Test case for ofproto_v1_2
    """

    def test_struct_ofp_header(self):
        eq_(OFP_HEADER_PACK_STR, '!BBHI')
        eq_(OFP_HEADER_SIZE, 8)

    def test_enum_ofp_type(self):
        eq_(OFPT_HELLO, 0)
        eq_(OFPT_ERROR, 1)
        eq_(OFPT_ECHO_REQUEST, 2)
        eq_(OFPT_ECHO_REPLY, 3)
        eq_(OFPT_EXPERIMENTER, 4)
        eq_(OFPT_FEATURES_REQUEST, 5)
        eq_(OFPT_FEATURES_REPLY, 6)
        eq_(OFPT_GET_CONFIG_REQUEST, 7)
        eq_(OFPT_GET_CONFIG_REPLY, 8)
        eq_(OFPT_SET_CONFIG, 9)
        eq_(OFPT_PACKET_IN, 10)
        eq_(OFPT_FLOW_REMOVED, 11)
        eq_(OFPT_PORT_STATUS, 12)
        eq_(OFPT_PACKET_OUT, 13)
        eq_(OFPT_FLOW_MOD, 14)
        eq_(OFPT_GROUP_MOD, 15)
        eq_(OFPT_PORT_MOD, 16)
        eq_(OFPT_TABLE_MOD, 17)
        eq_(OFPT_STATS_REQUEST, 18)
        eq_(OFPT_STATS_REPLY, 19)
        eq_(OFPT_BARRIER_REQUEST, 20)
        eq_(OFPT_BARRIER_REPLY, 21)
        eq_(OFPT_QUEUE_GET_CONFIG_REQUEST, 22)
        eq_(OFPT_QUEUE_GET_CONFIG_REPLY, 23)
        eq_(OFPT_ROLE_REQUEST, 24)
        eq_(OFPT_ROLE_REPLY, 25)

    def test_struct_ofp_port(self):
        eq_(OFP_PORT_PACK_STR, '!I4x6s2x16sIIIIIIII')
        eq_(OFP_PORT_SIZE, 64)

    def test_enum_ofp_port_config(self):
        eq_(OFPPC_PORT_DOWN, 1 << 0)
        eq_(OFPPC_NO_RECV, 1 << 2)
        eq_(OFPPC_NO_FWD, 1 << 5)
        eq_(OFPPC_NO_PACKET_IN, 1 << 6)

    def test_enum_ofp_port_state(self):
        eq_(OFPPS_LINK_DOWN, 1 << 0)
        eq_(OFPPS_BLOCKED, 1 << 1)
        eq_(OFPPS_LIVE, 1 << 2)

    def test_enum_ofp_port_no(self):
        eq_(OFPP_MAX, 0xffffff00)
        eq_(OFPP_IN_PORT, 0xfffffff8)
        eq_(OFPP_TABLE, 0xfffffff9)
        eq_(OFPP_NORMAL, 0xfffffffa)
        eq_(OFPP_FLOOD, 0xfffffffb)
        eq_(OFPP_ALL, 0xfffffffc)
        eq_(OFPP_CONTROLLER, 0xfffffffd)
        eq_(OFPP_LOCAL, 0xfffffffe)
        eq_(OFPP_ANY, 0xffffffff)
        eq_(OFPQ_ALL, 0xffffffff)

    def test_enum_ofp_port_features(self):
        eq_(OFPPF_10MB_HD, 1 << 0)
        eq_(OFPPF_10MB_FD, 1 << 1)
        eq_(OFPPF_100MB_HD, 1 << 2)
        eq_(OFPPF_100MB_FD, 1 << 3)
        eq_(OFPPF_1GB_HD, 1 << 4)
        eq_(OFPPF_1GB_FD, 1 << 5)
        eq_(OFPPF_10GB_FD, 1 << 6)
        eq_(OFPPF_40GB_FD, 1 << 7)
        eq_(OFPPF_100GB_FD, 1 << 8)
        eq_(OFPPF_1TB_FD, 1 << 9)
        eq_(OFPPF_OTHER, 1 << 10)
        eq_(OFPPF_COPPER, 1 << 11)
        eq_(OFPPF_FIBER, 1 << 12)
        eq_(OFPPF_AUTONEG, 1 << 13)
        eq_(OFPPF_PAUSE, 1 << 14)
        eq_(OFPPF_PAUSE_ASYM, 1 << 15)

    def test_struct_ofp_packet_queue(self):
        eq_(OFP_PACKET_QUEUE_PACK_STR, '!IIH6x')
        eq_(OFP_PACKET_QUEUE_SIZE, 16)

    def test_enum_ofp_queue_properties(self):
        eq_(OFPQT_MIN_RATE, 1)
        eq_(OFPQT_MAX_RATE, 2)
        eq_(OFPQT_EXPERIMENTER, 0xffff)

    def test_struct_ofp_queue_prop_header(self):
        eq_(OFP_QUEUE_PROP_HEADER_PACK_STR, '!HH4x')
        eq_(OFP_QUEUE_PROP_HEADER_SIZE, 8)

    def test_struct_ofp_queue_prop_min_rate(self):
        eq_(OFP_QUEUE_PROP_MIN_RATE_PACK_STR, '!H6x')
        eq_(OFP_QUEUE_PROP_MIN_RATE_SIZE, 16)

    def test_struct_ofp_queue_prop_max_rate(self):
        eq_(OFP_QUEUE_PROP_MAX_RATE_PACK_STR, '!H6x')
        eq_(OFP_QUEUE_PROP_MAX_RATE_SIZE, 16)

    def test_struct_ofp_queue_prop_experimenter(self):
        eq_(OFP_QUEUE_PROP_EXPERIMENTER_PACK_STR, '!I4x')
        eq_(OFP_QUEUE_PROP_EXPERIMENTER_SIZE, 16)

    def test_struct_ofp_match(self):
        eq_(OFP_MATCH_PACK_STR, '!HHBBBB')
        eq_(OFP_MATCH_SIZE, 8)

    def test_enum_ofp_match_type(self):
        eq_(OFPMT_STANDARD, 0)
        eq_(OFPMT_OXM, 1)

    def test_enum_ofp_oxm_class(self):
        eq_(OFPXMC_NXM_0, 0x0000)
        eq_(OFPXMC_NXM_1, 0x0001)
        eq_(OFPXMC_OPENFLOW_BASIC, 0x8000)
        eq_(OFPXMC_EXPERIMENTER, 0xFFFF)

    def test_enmu_oxm_ofb_match_fields(self):
        eq_(OFPXMT_OFB_IN_PORT, 0)
        eq_(OFPXMT_OFB_IN_PHY_PORT, 1)
        eq_(OFPXMT_OFB_METADATA, 2)
        eq_(OFPXMT_OFB_ETH_DST, 3)
        eq_(OFPXMT_OFB_ETH_SRC, 4)
        eq_(OFPXMT_OFB_ETH_TYPE, 5)
        eq_(OFPXMT_OFB_VLAN_VID, 6)
        eq_(OFPXMT_OFB_VLAN_PCP, 7)
        eq_(OFPXMT_OFB_IP_DSCP, 8)
        eq_(OFPXMT_OFB_IP_ECN, 9)
        eq_(OFPXMT_OFB_IP_PROTO, 10)
        eq_(OFPXMT_OFB_IPV4_SRC, 11)
        eq_(OFPXMT_OFB_IPV4_DST, 12)
        eq_(OFPXMT_OFB_TCP_SRC, 13)
        eq_(OFPXMT_OFB_TCP_DST, 14)
        eq_(OFPXMT_OFB_UDP_SRC, 15)
        eq_(OFPXMT_OFB_UDP_DST, 16)
        eq_(OFPXMT_OFB_SCTP_SRC, 17)
        eq_(OFPXMT_OFB_SCTP_DST, 18)
        eq_(OFPXMT_OFB_ICMPV4_TYPE, 19)
        eq_(OFPXMT_OFB_ICMPV4_CODE, 20)
        eq_(OFPXMT_OFB_ARP_OP, 21)
        eq_(OFPXMT_OFB_ARP_SPA, 22)
        eq_(OFPXMT_OFB_ARP_TPA, 23)
        eq_(OFPXMT_OFB_ARP_SHA, 24)
        eq_(OFPXMT_OFB_ARP_THA, 25)
        eq_(OFPXMT_OFB_IPV6_SRC, 26)
        eq_(OFPXMT_OFB_IPV6_DST, 27)
        eq_(OFPXMT_OFB_IPV6_FLABEL, 28)
        eq_(OFPXMT_OFB_ICMPV6_TYPE, 29)
        eq_(OFPXMT_OFB_ICMPV6_CODE, 30)
        eq_(OFPXMT_OFB_IPV6_ND_TARGET, 31)
        eq_(OFPXMT_OFB_IPV6_ND_SLL, 32)
        eq_(OFPXMT_OFB_IPV6_ND_TLL, 33)
        eq_(OFPXMT_OFB_MPLS_LABEL, 34)
        eq_(OFPXMT_OFB_MPLS_TC, 35)

    def test_enum_ofp_vlan_id(self):
        eq_(OFPVID_PRESENT, 0x1000)
        eq_(OFPVID_NONE, 0x0000)

    def test_struct_ofp_oxm_experimenter_header(self):
        eq_(OFP_OXM_EXPERIMENTER_HEADER_PACK_STR, '!II')
        eq_(OFP_OXM_EXPERIMENTER_HEADER_SIZE, 8)

    def test_enum_ofp_instruction_type(self):
        eq_(OFPIT_GOTO_TABLE, 1)
        eq_(OFPIT_WRITE_METADATA, 2)
        eq_(OFPIT_WRITE_ACTIONS, 3)
        eq_(OFPIT_APPLY_ACTIONS, 4)
        eq_(OFPIT_CLEAR_ACTIONS, 5)
        eq_(OFPIT_EXPERIMENTER, 0xFFFF)

    def test_struct_ofp_instruction_goto_table(self):
        eq_(OFP_INSTRUCTION_GOTO_TABLE_PACK_STR, '!HHB3x')
        eq_(OFP_INSTRUCTION_GOTO_TABLE_SIZE, 8)

    def test_struct_ofp_instruction_write_metadata(self):
        eq_(OFP_INSTRUCTION_WRITE_METADATA_PACK_STR, '!HH4xQQ')
        eq_(OFP_INSTRUCTION_WRITE_METADATA_SIZE, 24)

    def test_struct_ofp_instaruction_actions(self):
        eq_(OFP_INSTRUCTION_ACTIONS_PACK_STR, '!HH4x')
        eq_(OFP_INSTRUCTION_ACTIONS_SIZE, 8)

    def test_enum_ofp_action_type(self):
        eq_(OFPAT_OUTPUT, 0)
        eq_(OFPAT_COPY_TTL_OUT, 11)
        eq_(OFPAT_COPY_TTL_IN, 12)
        eq_(OFPAT_SET_MPLS_TTL, 15)
        eq_(OFPAT_DEC_MPLS_TTL, 16)
        eq_(OFPAT_PUSH_VLAN, 17)
        eq_(OFPAT_POP_VLAN, 18)
        eq_(OFPAT_PUSH_MPLS, 19)
        eq_(OFPAT_POP_MPLS, 20)
        eq_(OFPAT_SET_QUEUE, 21)
        eq_(OFPAT_GROUP, 22)
        eq_(OFPAT_SET_NW_TTL, 23)
        eq_(OFPAT_DEC_NW_TTL, 24)
        eq_(OFPAT_SET_FIELD, 25)
        eq_(OFPAT_EXPERIMENTER, 0xffff)

    def test_struct_ofp_action_header(self):
        eq_(OFP_ACTION_HEADER_PACK_STR, '!HH4x')
        eq_(OFP_ACTION_HEADER_SIZE, 8)

    def test_struct_ofp_action_output(self):
        eq_(OFP_ACTION_OUTPUT_PACK_STR, '!HHIH6x')
        eq_(OFP_ACTION_OUTPUT_SIZE, 16)

    def test_enum_ofp_controller_max_len(self):
        eq_(OFPCML_MAX, 0xffe5)
        eq_(OFPCML_NO_BUFFER, 0xffff)

    def test_struct_ofp_action_group(self):
        eq_(OFP_ACTION_GROUP_PACK_STR, '!HHI')
        eq_(OFP_ACTION_GROUP_SIZE, 8)

    def test_struct_ofp_action_set_queue(self):
        eq_(OFP_ACTION_SET_QUEUE_PACK_STR, '!HHI')
        eq_(OFP_ACTION_SET_QUEUE_SIZE, 8)

    def test_struct_ofp_aciton_mpls_ttl(self):
        eq_(OFP_ACTION_MPLS_TTL_PACK_STR, '!HHB3x')
        eq_(OFP_ACTION_MPLS_TTL_SIZE, 8)

    def test_struct_ofp_action_nw_ttl(self):
        eq_(OFP_ACTION_NW_TTL_PACK_STR, '!HHB3x')
        eq_(OFP_ACTION_NW_TTL_SIZE, 8)

    def test_struct_ofp_action_push(self):
        eq_(OFP_ACTION_PUSH_PACK_STR, '!HHH2x')
        eq_(OFP_ACTION_PUSH_SIZE, 8)

    def test_struct_ofp_action_pop_mpls(self):
        eq_(OFP_ACTION_POP_MPLS_PACK_STR, '!HHH2x')
        eq_(OFP_ACTION_POP_MPLS_SIZE, 8)

    def test_struct_ofp_action_set_field(self):
        eq_(OFP_ACTION_SET_FIELD_PACK_STR, '!HH4B')
        eq_(OFP_ACTION_SET_FIELD_SIZE, 8)

    def test_struct_ofp_action_experimenter_header(self):
        eq_(OFP_ACTION_EXPERIMENTER_HEADER_PACK_STR, '!HHI')
        eq_(OFP_ACTION_EXPERIMENTER_HEADER_SIZE, 8)

    def test_struct_ofp_switch_feature(self):
        eq_(OFP_SWITCH_FEATURES_PACK_STR, '!QIB3xII')
        eq_(OFP_SWITCH_FEATURES_SIZE, 32)

    def test_enum_ofp_capabilities(self):
        eq_(OFPC_FLOW_STATS, 1 << 0)
        eq_(OFPC_TABLE_STATS, 1 << 1)
        eq_(OFPC_PORT_STATS, 1 << 2)
        eq_(OFPC_GROUP_STATS, 1 << 3)
        eq_(OFPC_IP_REASM, 1 << 5)
        eq_(OFPC_QUEUE_STATS, 1 << 6)
        eq_(OFPC_PORT_BLOCKED, 1 << 8)

    def test_struct_ofp_switch_config(self):
        eq_(OFP_SWITCH_CONFIG_PACK_STR, '!HH')
        eq_(OFP_SWITCH_CONFIG_SIZE, 12)

    def test_enum_ofp_config_flags(self):
        eq_(OFPC_FRAG_NORMAL, 0)
        eq_(OFPC_FRAG_DROP, 1 << 0)
        eq_(OFPC_FRAG_REASM, 1 << 1)
        eq_(OFPC_FRAG_MASK, 3)
        eq_(OFPC_INVALID_TTL_TO_CONTROLLER, 1 << 2)

    def test_enum_ofp_table(self):
        eq_(OFPTT_MAX, 0xfe)
        eq_(OFPTT_ALL, 0xff)

    def test_struct_ofp_table_mod(self):
        eq_(OFP_TABLE_MOD_PACK_STR, '!B3xI')
        eq_(OFP_TABLE_MOD_SIZE, 16)

    def test_enum_ofp_table_config(self):
        eq_(OFPTC_TABLE_MISS_CONTROLLER, 0)
        eq_(OFPTC_TABLE_MISS_CONTINUE, 1 << 0)
        eq_(OFPTC_TABLE_MISS_DROP, 1 << 1)
        eq_(OFPTC_TABLE_MISS_MASK, 3)

    def test_struct_ofp_flow_mod(self):
        eq_(OFP_FLOW_MOD_PACK_STR, '!QQBBHHHIIIH2xHHBBBB')
        eq_(OFP_FLOW_MOD_SIZE, 56)

    def test_enum_ofp_flow_mod_command(self):
        eq_(OFPFC_ADD, 0)
        eq_(OFPFC_MODIFY, 1)
        eq_(OFPFC_MODIFY_STRICT, 2)
        eq_(OFPFC_DELETE, 3)
        eq_(OFPFC_DELETE_STRICT, 4)

    def test_enum_ofp_flow_mod_flags(self):
        eq_(OFPFF_SEND_FLOW_REM, 1 << 0)
        eq_(OFPFF_CHECK_OVERLAP, 1 << 1)
        eq_(OFPFF_RESET_COUNT, 1 << 2)

    def test_struct_ofp_group_mod(self):
        eq_(OFP_GROUP_MOD_PACK_STR, '!HBxI')
        eq_(OFP_GROUP_MOD_SIZE, 16)

    # same to OFPP_*
    def test_enum_ofp_group(self):
        eq_(OFPG_MAX, 0xffffff00)
        eq_(OFPG_ALL, 0xfffffffc)
        eq_(OFPG_ANY, 0xffffffff)

    def test_enum_ofp_group_mod_command(self):
        eq_(OFPGC_ADD, 0)
        eq_(OFPGC_MODIFY, 1)
        eq_(OFPGC_DELETE, 2)

    def test_enum_ofp_group_type(self):
        eq_(OFPGT_ALL, 0)
        eq_(OFPGT_SELECT, 1)
        eq_(OFPGT_INDIRECT, 2)
        eq_(OFPGT_FF, 3)

    def test_struct_ofp_bucket(self):
        eq_(OFP_BUCKET_PACK_STR, '!HHII4x')
        eq_(OFP_BUCKET_SIZE, 16)

    def test_struct_ofp_port_mod(self):
        eq_(OFP_PORT_MOD_PACK_STR, '!I4x6s2xIII4x')
        eq_(OFP_PORT_MOD_SIZE, 40)

    def test_sturct_ofp_stats_request(self):
        eq_(OFP_STATS_REQUEST_PACK_STR, '!HH4x')
        eq_(OFP_STATS_REQUEST_SIZE, 16)

    # OFPSF_REQ_* flags (none yet defined).
    # The only value defined for flags in a reply is whether more
    # replies will follow this one - this has the value 0x0001.
    def test_enum_ofp_stats_reply_flags(self):
        eq_(OFPSF_REPLY_MORE, 0x0001)

    def test_struct_ofp_stats_reply(self):
        eq_(OFP_STATS_REPLY_PACK_STR, '!HH4x')
        eq_(OFP_STATS_REPLY_SIZE, 16)

    def test_enum_ofp_stats_types(self):
        eq_(OFPST_DESC, 0)
        eq_(OFPST_FLOW, 1)
        eq_(OFPST_AGGREGATE, 2)
        eq_(OFPST_TABLE, 3)
        eq_(OFPST_PORT, 4)
        eq_(OFPST_QUEUE, 5)
        eq_(OFPST_GROUP, 6)
        eq_(OFPST_GROUP_DESC, 7)
        eq_(OFPST_GROUP_FEATURES, 8)
        eq_(OFPST_EXPERIMENTER, 0xffff)

    def test_struct_ofp_desc_stats(self):
        eq_(OFP_DESC_STATS_PACK_STR, '!256s256s256s32s256s')
        eq_(OFP_DESC_STATS_SIZE, 1056)

    def test_struct_ofp_flow_stats_request(self):
        eq_(OFP_FLOW_STATS_REQUEST_PACK_STR, '!B3xII4xQQ')
        eq_(OFP_FLOW_STATS_REQUEST_SIZE, 40)

    def test_struct_ofp_flow_stats(self):
        eq_(OFP_FLOW_STATS_PACK_STR, '!HBxIIHHH6xQQQ')
        eq_(OFP_FLOW_STATS_SIZE, 56)

    def test_struct_ofp_aggregate_stats_request(self):
        eq_(OFP_AGGREGATE_STATS_REQUEST_PACK_STR, '!B3xII4xQQ')
        eq_(OFP_AGGREGATE_STATS_REQUEST_SIZE, 40)

    def test_struct_ofp_aggregate_stats_reply(self):
        eq_(OFP_AGGREGATE_STATS_REPLY_PACK_STR, '!QQI4x')
        eq_(OFP_AGGREGATE_STATS_REPLY_SIZE, 24)

    def test_sturct_ofp_table_stats(self):
        eq_(OFP_TABLE_STATS_PACK_STR, '!B7x32sQQIIQQQQIIIIQQ')
        eq_(OFP_TABLE_STATS_SIZE, 128)

    def test_struct_ofp_port_stats_request(self):
        eq_(OFP_PORT_STATS_REQUEST_PACK_STR, '!I4x')
        eq_(OFP_PORT_STATS_REQUEST_SIZE, 8)

    def test_struct_ofp_port_stats(self):
        eq_(OFP_PORT_STATS_PACK_STR, '!I4xQQQQQQQQQQQQ')
        eq_(OFP_PORT_STATS_SIZE, 104)

    def test_struct_ofp_queue_stats_request(self):
        eq_(OFP_QUEUE_STATS_REQUEST_PACK_STR, '!II')
        eq_(OFP_QUEUE_STATS_REQUEST_SIZE, 8)

    def test_struct_ofp_queue_stats(self):
        eq_(OFP_QUEUE_STATS_PACK_STR, '!IIQQQ')
        eq_(OFP_QUEUE_STATS_SIZE, 32)

    def test_struct_ofp_group_stats_request(self):
        eq_(OFP_GROUP_STATS_REQUEST_PACK_STR, '!I4x')
        eq_(OFP_GROUP_STATS_REQUEST_SIZE, 8)

    def test_struct_ofp_group_stats(self):
        eq_(OFP_GROUP_STATS_PACK_STR, '!H2xII4xQQ')
        eq_(OFP_GROUP_STATS_SIZE, 32)

    def test_struct_ofp_bucket_counter(self):
        eq_(OFP_BUCKET_COUNTER_PACK_STR, '!QQ')
        eq_(OFP_BUCKET_COUNTER_SIZE, 16)

    def test_struct_ofp_group_desc_stats(self):
        eq_(OFP_GROUP_DESC_STATS_PACK_STR, '!HBxI')
        eq_(OFP_GROUP_DESC_STATS_SIZE, 8)

    def test_struct_ofp_group_features_stats(self):
        eq_(OFP_GROUP_FEATURES_STATS_PACK_STR, '!II4I4I')
        eq_(OFP_GROUP_FEATURES_STATS_SIZE, 40)

    def test_enmu_ofp_group_capabilities(self):
        eq_(OFPGFC_SELECT_WEIGHT, 1 << 0)
        eq_(OFPGFC_SELECT_LIVENESS, 1 << 1)
        eq_(OFPGFC_CHAINING, 1 << 2)
        eq_(OFPGFC_CHAINING_CHECKS, 1 << 3)

    def test_struct_ofp_experimenter_stats_header(self):
        eq_(OFP_EXPERIMENTER_STATS_HEADER_PACK_STR, '!II')
        eq_(OFP_EXPERIMENTER_STATS_HEADER_SIZE, 8)

    def test_struct_opf_queue_get_config_request(self):
        eq_(OFP_QUEUE_GET_CONFIG_REQUEST_PACK_STR, '!I4x')
        eq_(OFP_QUEUE_GET_CONFIG_REQUEST_SIZE, 16)

    def test_struct_ofp_queue_get_config_reply(self):
        eq_(OFP_QUEUE_GET_CONFIG_REPLY_PACK_STR, '!I4x')
        eq_(OFP_QUEUE_GET_CONFIG_REPLY_SIZE, 16)

    def test_struct_ofp_packet_out(self):
        eq_(OFP_PACKET_OUT_PACK_STR, '!IIH6x')
        eq_(OFP_PACKET_OUT_SIZE, 24)

    def test_struct_ofp_role_request(self):
        eq_(OFP_ROLE_REQUEST_PACK_STR, '!I4xQ')
        eq_(OFP_ROLE_REQUEST_SIZE, 24)

    def test_enum_ofp_controller_role(self):
        eq_(OFPCR_ROLE_NOCHANGE, 0)
        eq_(OFPCR_ROLE_EQUAL, 1)
        eq_(OFPCR_ROLE_MASTER, 2)
        eq_(OFPCR_ROLE_SLAVE, 3)

    def test_struct_ofp_packet_in(self):
        eq_(OFP_PACKET_IN_PACK_STR, '!IHBB')
        eq_(OFP_PACKET_IN_SIZE, 24)

    def test_enum_ofp_packet_in_reason(self):
        eq_(OFPR_NO_MATCH, 0)
        eq_(OFPR_ACTION, 1)
        eq_(OFPR_INVALID_TTL, 2)

    def test_struct_ofp_flow_removed(self):
        eq_(OFP_FLOW_REMOVED_PACK_STR, '!QHBBIIHHQQHHBBBB')
        eq_(OFP_FLOW_REMOVED_PACK_STR0, '!QHBBIIHHQQ')
        eq_(OFP_FLOW_REMOVED_SIZE, 56)

    def test_enum_ofp_flow_removed_reason(self):
        eq_(OFPRR_IDLE_TIMEOUT, 0)
        eq_(OFPRR_HARD_TIMEOUT, 1)
        eq_(OFPRR_DELETE, 2)
        eq_(OFPRR_GROUP_DELETE, 3)

    def test_struct_ofp_port_status(self):
        eq_(OFP_PORT_STATUS_PACK_STR, '!B7xI4x6s2x16sIIIIIIII')
        eq_(OFP_PORT_STATUS_DESC_OFFSET, 16)
        eq_(OFP_PORT_STATUS_SIZE, 80)

    def test_enum_ofp_port_reason(self):
        eq_(OFPPR_ADD, 0)
        eq_(OFPPR_DELETE, 1)
        eq_(OFPPR_MODIFY, 2)

    def test_struct_ofp_error_msg(self):
        eq_(OFP_ERROR_MSG_PACK_STR, '!HH')
        eq_(OFP_ERROR_MSG_SIZE, 12)

    def test_enum_ofp_error_type(self):
        eq_(OFPET_HELLO_FAILED, 0)
        eq_(OFPET_BAD_REQUEST, 1)
        eq_(OFPET_BAD_ACTION, 2)
        eq_(OFPET_BAD_INSTRUCTION, 3)
        eq_(OFPET_BAD_MATCH, 4)
        eq_(OFPET_FLOW_MOD_FAILED, 5)
        eq_(OFPET_GROUP_MOD_FAILED, 6)
        eq_(OFPET_PORT_MOD_FAILED, 7)
        eq_(OFPET_TABLE_MOD_FAILED, 8)
        eq_(OFPET_QUEUE_OP_FAILED, 9)
        eq_(OFPET_SWITCH_CONFIG_FAILED, 10)
        eq_(OFPET_ROLE_REQUEST_FAILED, 11)
        eq_(OFPET_EXPERIMENTER, 0xffff)

    def test_enum_ofp_hello_failed_code(self):
        eq_(OFPHFC_INCOMPATIBLE, 0)
        eq_(OFPHFC_EPERM, 1)

    def test_enum_ofp_bad_request_code(self):
        eq_(OFPBRC_BAD_VERSION, 0)
        eq_(OFPBRC_BAD_TYPE, 1)
        eq_(OFPBRC_BAD_STAT, 2)
        eq_(OFPBRC_BAD_EXPERIMENTER, 3)
        eq_(OFPBRC_BAD_EXP_TYPE, 4)
        eq_(OFPBRC_EPERM, 5)
        eq_(OFPBRC_BAD_LEN, 6)
        eq_(OFPBRC_BUFFER_EMPTY, 7)
        eq_(OFPBRC_BUFFER_UNKNOWN, 8)
        eq_(OFPBRC_BAD_TABLE_ID, 9)
        eq_(OFPBRC_IS_SLAVE, 10)
        eq_(OFPBRC_BAD_PORT, 11)
        eq_(OFPBRC_BAD_PACKET, 12)

    def test_enum_ofp_bad_action_code(self):
        eq_(OFPBAC_BAD_TYPE, 0)
        eq_(OFPBAC_BAD_LEN, 1)
        eq_(OFPBAC_BAD_EXPERIMENTER, 2)
        eq_(OFPBAC_BAD_EXP_TYPE, 3)
        eq_(OFPBAC_BAD_OUT_PORT, 4)
        eq_(OFPBAC_BAD_ARGUMENT, 5)
        eq_(OFPBAC_EPERM, 6)
        eq_(OFPBAC_TOO_MANY, 7)
        eq_(OFPBAC_BAD_QUEUE, 8)
        eq_(OFPBAC_BAD_OUT_GROUP, 9)
        eq_(OFPBAC_MATCH_INCONSISTENT, 10)
        eq_(OFPBAC_UNSUPPORTED_ORDER, 11)
        eq_(OFPBAC_BAD_TAG, 12)
        eq_(OFPBAC_BAD_SET_TYPE, 13)
        eq_(OFPBAC_BAD_SET_LEN, 14)
        eq_(OFPBAC_BAD_SET_ARGUMENT, 15)

    def test_enum_ofp_bad_instruction_code(self):
        eq_(OFPBIC_UNKNOWN_INST, 0)
        eq_(OFPBIC_UNSUP_INST, 1)
        eq_(OFPBIC_BAD_TABLE_ID, 2)
        eq_(OFPBIC_UNSUP_METADATA, 3)
        eq_(OFPBIC_UNSUP_METADATA_MASK, 4)
        eq_(OFPBIC_BAD_EXPERIMENTER, 5)
        eq_(OFPBIC_BAD_EXP_TYPE, 6)
        eq_(OFPBIC_BAD_LEN, 7)
        eq_(OFPBIC_EPERM, 8)

    def test_enum_ofp_bad_match_code(self):
        eq_(OFPBMC_BAD_TYPE, 0)
        eq_(OFPBMC_BAD_LEN, 1)
        eq_(OFPBMC_BAD_TAG, 2)
        eq_(OFPBMC_BAD_DL_ADDR_MASK, 3)
        eq_(OFPBMC_BAD_NW_ADDR_MASK, 4)
        eq_(OFPBMC_BAD_WILDCARDS, 5)
        eq_(OFPBMC_BAD_FIELD, 6)
        eq_(OFPBMC_BAD_VALUE, 7)
        eq_(OFPBMC_BAD_MASK, 8)
        eq_(OFPBMC_BAD_PREREQ, 9)
        eq_(OFPBMC_DUP_FIELD, 10)
        eq_(OFPBMC_EPERM, 11)

    def test_enum_ofp_flow_mod_failed_code(self):
        eq_(OFPFMFC_UNKNOWN, 0)
        eq_(OFPFMFC_TABLE_FULL, 1)
        eq_(OFPFMFC_BAD_TABLE_ID, 2)
        eq_(OFPFMFC_OVERLAP, 3)
        eq_(OFPFMFC_EPERM, 4)
        eq_(OFPFMFC_BAD_TIMEOUT, 5)
        eq_(OFPFMFC_BAD_COMMAND, 6)
        eq_(OFPFMFC_BAD_FLAGS, 7)

    def test_enum_ofp_group_mod_failed_code(self):
        eq_(OFPGMFC_GROUP_EXISTS, 0)
        eq_(OFPGMFC_INVALID_GROUP, 1)
        eq_(OFPGMFC_WEIGHT_UNSUPPORTED, 2)
        eq_(OFPGMFC_OUT_OF_GROUPS, 3)
        eq_(OFPGMFC_OUT_OF_BUCKETS, 4)
        eq_(OFPGMFC_CHAINING_UNSUPPORTED, 5)
        eq_(OFPGMFC_WATCH_UNSUPPORTED, 6)
        eq_(OFPGMFC_LOOP, 7)
        eq_(OFPGMFC_UNKNOWN_GROUP, 8)
        eq_(OFPGMFC_CHAINED_GROUP, 9)
        eq_(OFPGMFC_BAD_TYPE, 10)
        eq_(OFPGMFC_BAD_COMMAND, 11)
        eq_(OFPGMFC_BAD_BUCKET, 12)
        eq_(OFPGMFC_BAD_WATCH, 13)
        eq_(OFPGMFC_EPERM, 14)

    def test_enum_ofp_port_mod_failed_code(self):
        eq_(OFPPMFC_BAD_PORT, 0)
        eq_(OFPPMFC_BAD_HW_ADDR, 1)
        eq_(OFPPMFC_BAD_CONFIG, 2)
        eq_(OFPPMFC_BAD_ADVERTISE, 3)
        eq_(OFPPMFC_EPERM, 4)

    def test_enum_ofp_table_mod_failed_code(self):
        eq_(OFPTMFC_BAD_TABLE, 0)
        eq_(OFPTMFC_BAD_CONFIG, 1)
        eq_(OFPTMFC_EPERM, 2)

    def test_enum_ofp_queue_op_failed_code(self):
        eq_(OFPQOFC_BAD_PORT, 0)
        eq_(OFPQOFC_BAD_QUEUE, 1)
        eq_(OFPQOFC_EPERM, 2)

    def test_enum_ofp_switch_config_failed_code(self):
        eq_(OFPSCFC_BAD_FLAGS, 0)
        eq_(OFPSCFC_BAD_LEN, 1)
        eq_(OFPQCFC_EPERM, 2)

    def test_enum_ofp_role_request_failed_code(self):
        eq_(OFPRRFC_STALE, 0)
        eq_(OFPRRFC_UNSUP, 1)
        eq_(OFPRRFC_BAD_ROLE, 2)

    def test_struct_ofp_error_experimenter_msg(self):
        eq_(OFP_ERROR_EXPERIMENTER_MSG_PACK_STR, '!HHI')
        eq_(OFP_ERROR_EXPERIMENTER_MSG_SIZE, 16)

    def test_struct_ofp_experimenter_header(self):
        eq_(OFP_EXPERIMENTER_HEADER_PACK_STR, '!II')
        eq_(OFP_EXPERIMENTER_HEADER_SIZE, 16)

    # OXM is interpreted as a 32-bit word in network byte order.
    # - oxm_class   17-bit to 32-bit (OFPXMC_*).
    # - oxm_field   10-bit to 16-bit (OFPXMT_OFB_*).
    # - oxm_hasmask  9-bit           (Set if OXM include a bitmask).
    # - oxm_length   1-bit to 8-bit  (Lenght of OXM payload).
    def _test_OXM(self, value, class_, field, hasmask, length):
        virfy = (class_ << 16) | (field << 9) | (hasmask << 8) | length
        eq_(value >> 32, 0)
        eq_(value, virfy)

    def _test_OXM_basic(self, value, field, hasmask, length):
        self._test_OXM(value, OFPXMC_OPENFLOW_BASIC, field, hasmask, length)

    def test_OXM_basic(self):
        self._test_OXM_basic(OXM_OF_IN_PORT, OFPXMT_OFB_IN_PORT, 0, 4)
        self._test_OXM_basic(OXM_OF_IN_PHY_PORT, OFPXMT_OFB_IN_PHY_PORT, 0, 4)
        self._test_OXM_basic(OXM_OF_METADATA, OFPXMT_OFB_METADATA, 0, 8)
        self._test_OXM_basic(OXM_OF_METADATA_W, OFPXMT_OFB_METADATA, 1, 16)
        self._test_OXM_basic(OXM_OF_ETH_DST, OFPXMT_OFB_ETH_DST, 0, 6)
        self._test_OXM_basic(OXM_OF_ETH_DST_W, OFPXMT_OFB_ETH_DST, 1, 12)
        self._test_OXM_basic(OXM_OF_ETH_SRC, OFPXMT_OFB_ETH_SRC, 0, 6)
        self._test_OXM_basic(OXM_OF_ETH_SRC_W, OFPXMT_OFB_ETH_SRC, 1, 12)
        self._test_OXM_basic(OXM_OF_ETH_TYPE, OFPXMT_OFB_ETH_TYPE, 0, 2)
        self._test_OXM_basic(OXM_OF_VLAN_VID, OFPXMT_OFB_VLAN_VID, 0, 2)
        self._test_OXM_basic(OXM_OF_VLAN_VID_W, OFPXMT_OFB_VLAN_VID, 1, 4)
        self._test_OXM_basic(OXM_OF_VLAN_PCP, OFPXMT_OFB_VLAN_PCP, 0, 1)
        self._test_OXM_basic(OXM_OF_IP_DSCP, OFPXMT_OFB_IP_DSCP, 0, 1)
        self._test_OXM_basic(OXM_OF_IP_ECN, OFPXMT_OFB_IP_ECN, 0, 1)
        self._test_OXM_basic(OXM_OF_IP_PROTO, OFPXMT_OFB_IP_PROTO, 0, 1)
        self._test_OXM_basic(OXM_OF_IPV4_SRC, OFPXMT_OFB_IPV4_SRC, 0, 4)
        self._test_OXM_basic(OXM_OF_IPV4_SRC_W, OFPXMT_OFB_IPV4_SRC, 1, 8)
        self._test_OXM_basic(OXM_OF_IPV4_DST, OFPXMT_OFB_IPV4_DST, 0, 4)
        self._test_OXM_basic(OXM_OF_IPV4_DST_W, OFPXMT_OFB_IPV4_DST, 1, 8)
        self._test_OXM_basic(OXM_OF_TCP_SRC, OFPXMT_OFB_TCP_SRC, 0, 2)
        self._test_OXM_basic(OXM_OF_TCP_DST, OFPXMT_OFB_TCP_DST, 0, 2)
        self._test_OXM_basic(OXM_OF_UDP_SRC, OFPXMT_OFB_UDP_SRC, 0, 2)
        self._test_OXM_basic(OXM_OF_UDP_DST, OFPXMT_OFB_UDP_DST, 0, 2)
        self._test_OXM_basic(OXM_OF_SCTP_SRC, OFPXMT_OFB_SCTP_SRC, 0, 2)
        self._test_OXM_basic(OXM_OF_SCTP_DST, OFPXMT_OFB_SCTP_DST, 0, 2)
        self._test_OXM_basic(OXM_OF_ICMPV4_TYPE, OFPXMT_OFB_ICMPV4_TYPE, 0, 1)
        self._test_OXM_basic(OXM_OF_ICMPV4_CODE, OFPXMT_OFB_ICMPV4_CODE, 0, 1)
        self._test_OXM_basic(OXM_OF_ARP_OP, OFPXMT_OFB_ARP_OP, 0, 2)
        self._test_OXM_basic(OXM_OF_ARP_SPA, OFPXMT_OFB_ARP_SPA, 0, 4)
        self._test_OXM_basic(OXM_OF_ARP_SPA_W, OFPXMT_OFB_ARP_SPA, 1, 8)
        self._test_OXM_basic(OXM_OF_ARP_TPA, OFPXMT_OFB_ARP_TPA, 0, 4)
        self._test_OXM_basic(OXM_OF_ARP_TPA_W, OFPXMT_OFB_ARP_TPA, 1, 8)
        self._test_OXM_basic(OXM_OF_ARP_SHA, OFPXMT_OFB_ARP_SHA, 0, 6)
        self._test_OXM_basic(OXM_OF_ARP_SHA_W, OFPXMT_OFB_ARP_SHA, 1, 12)
        self._test_OXM_basic(OXM_OF_ARP_THA, OFPXMT_OFB_ARP_THA, 0, 6)
        self._test_OXM_basic(OXM_OF_ARP_THA_W, OFPXMT_OFB_ARP_THA, 1, 12)
        self._test_OXM_basic(OXM_OF_IPV6_SRC, OFPXMT_OFB_IPV6_SRC, 0, 16)
        self._test_OXM_basic(OXM_OF_IPV6_SRC_W, OFPXMT_OFB_IPV6_SRC, 1, 32)
        self._test_OXM_basic(OXM_OF_IPV6_DST, OFPXMT_OFB_IPV6_DST, 0, 16)
        self._test_OXM_basic(OXM_OF_IPV6_DST_W, OFPXMT_OFB_IPV6_DST, 1, 32)
        self._test_OXM_basic(OXM_OF_IPV6_FLABEL, OFPXMT_OFB_IPV6_FLABEL, 0, 4)
        self._test_OXM_basic(OXM_OF_IPV6_FLABEL_W,
                             OFPXMT_OFB_IPV6_FLABEL, 1, 8)
        self._test_OXM_basic(OXM_OF_ICMPV6_TYPE, OFPXMT_OFB_ICMPV6_TYPE, 0, 1)
        self._test_OXM_basic(OXM_OF_ICMPV6_CODE, OFPXMT_OFB_ICMPV6_CODE, 0, 1)
        self._test_OXM_basic(OXM_OF_IPV6_ND_TARGET,
                             OFPXMT_OFB_IPV6_ND_TARGET, 0, 16)
        self._test_OXM_basic(OXM_OF_IPV6_ND_SLL, OFPXMT_OFB_IPV6_ND_SLL, 0, 6)
        self._test_OXM_basic(OXM_OF_IPV6_ND_TLL, OFPXMT_OFB_IPV6_ND_TLL, 0, 6)
        self._test_OXM_basic(OXM_OF_MPLS_LABEL, OFPXMT_OFB_MPLS_LABEL, 0, 4)
        self._test_OXM_basic(OXM_OF_MPLS_TC, OFPXMT_OFB_MPLS_TC, 0, 1)

    def test_define_constants(self):
        eq_(OFP_VERSION, 0x03)
        eq_(OFP_TCP_PORT, 6633)
        eq_(MAX_XID, 0xffffffff)

########NEW FILE########
__FILENAME__ = test_parser
#!/usr/bin/env python
#
# Copyright (C) 2013 Nippon Telegraph and Telephone Corporation.
# Copyright (C) 2013 YAMAMOTO Takashi <yamamoto at valinux co jp>
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import sys
import unittest
from nose.tools import eq_

from ryu.ofproto import ofproto_parser
from ryu.ofproto import ofproto_v1_0
from ryu.ofproto import ofproto_v1_2
from ryu.ofproto import ofproto_v1_3
from ryu.ofproto import ofproto_v1_0_parser
from ryu.ofproto import ofproto_v1_2_parser
from ryu.ofproto import ofproto_v1_3_parser
import json


# (has_parser, has_serializer)
implemented = {
    1: {
        ofproto_v1_0.OFPT_PACKET_OUT: (False, True),
        ofproto_v1_0.OFPT_FEATURES_REQUEST: (False, True),
        ofproto_v1_0.OFPT_FEATURES_REPLY: (True, False),
        ofproto_v1_0.OFPT_PACKET_IN: (True, False),
        ofproto_v1_0.OFPT_FLOW_MOD: (False, True),
    },
    3: {
        ofproto_v1_2.OFPT_FEATURES_REQUEST: (False, True),
        ofproto_v1_2.OFPT_FEATURES_REPLY: (True, False),
        ofproto_v1_2.OFPT_GET_CONFIG_REQUEST: (False, True),
        ofproto_v1_2.OFPT_GET_CONFIG_REPLY: (True, False),
        ofproto_v1_2.OFPT_SET_CONFIG: (False, True),
        ofproto_v1_2.OFPT_PACKET_IN: (True, False),
        ofproto_v1_2.OFPT_FLOW_REMOVED: (True, False),
        ofproto_v1_2.OFPT_PORT_STATUS: (True, False),
        ofproto_v1_2.OFPT_PACKET_OUT: (False, True),
        ofproto_v1_2.OFPT_FLOW_MOD: (False, True),
        ofproto_v1_2.OFPT_GROUP_MOD: (False, True),
        ofproto_v1_2.OFPT_PORT_MOD: (False, True),
        ofproto_v1_2.OFPT_TABLE_MOD: (False, True),
        ofproto_v1_2.OFPT_STATS_REQUEST: (False, True),
        ofproto_v1_2.OFPT_STATS_REPLY: (True, False),
        ofproto_v1_2.OFPT_BARRIER_REQUEST: (False, True),
        ofproto_v1_2.OFPT_QUEUE_GET_CONFIG_REQUEST: (False, True),
        ofproto_v1_2.OFPT_QUEUE_GET_CONFIG_REPLY: (True, False),
        ofproto_v1_2.OFPT_ROLE_REQUEST: (False, True),
        ofproto_v1_2.OFPT_ROLE_REPLY: (True, False),
    },
    4: {
        ofproto_v1_3.OFPT_HELLO: (True, False),
        ofproto_v1_3.OFPT_FEATURES_REQUEST: (False, True),
        ofproto_v1_3.OFPT_FEATURES_REPLY: (True, False),
        ofproto_v1_3.OFPT_GET_CONFIG_REQUEST: (False, True),
        ofproto_v1_3.OFPT_GET_CONFIG_REPLY: (True, False),
        ofproto_v1_3.OFPT_SET_CONFIG: (False, True),
        ofproto_v1_3.OFPT_PACKET_IN: (True, False),
        ofproto_v1_3.OFPT_FLOW_REMOVED: (True, False),
        ofproto_v1_3.OFPT_PORT_STATUS: (True, False),
        ofproto_v1_3.OFPT_PACKET_OUT: (False, True),
        ofproto_v1_3.OFPT_FLOW_MOD: (False, True),
        ofproto_v1_3.OFPT_GROUP_MOD: (False, True),
        ofproto_v1_3.OFPT_PORT_MOD: (False, True),
        ofproto_v1_3.OFPT_METER_MOD: (False, True),
        ofproto_v1_3.OFPT_TABLE_MOD: (False, True),
        ofproto_v1_3.OFPT_MULTIPART_REQUEST: (False, True),
        ofproto_v1_3.OFPT_MULTIPART_REPLY: (True, False),
        ofproto_v1_3.OFPT_BARRIER_REQUEST: (False, True),
        ofproto_v1_3.OFPT_QUEUE_GET_CONFIG_REQUEST: (False, True),
        ofproto_v1_3.OFPT_QUEUE_GET_CONFIG_REPLY: (True, False),
        ofproto_v1_3.OFPT_ROLE_REQUEST: (False, True),
        ofproto_v1_3.OFPT_ROLE_REPLY: (True, False),
        ofproto_v1_3.OFPT_GET_ASYNC_REQUEST: (False, True),
        ofproto_v1_3.OFPT_GET_ASYNC_REPLY: (True, False),
        ofproto_v1_3.OFPT_SET_ASYNC: (False, True),
    },
}


# XXX dummy dp for testing
class DummyDatapath(object):
    def __init__(self, ofp, ofpp):
        self.ofproto = ofp
        self.ofproto_parser = ofpp


class Test_Parser(unittest.TestCase):
    """ Test case for ryu.ofproto, especially json representation
    """

    _ofp_versions = {
        ofproto_v1_0.OFP_VERSION: (ofproto_v1_0,
                                   ofproto_v1_0_parser),
        ofproto_v1_2.OFP_VERSION: (ofproto_v1_2,
                                   ofproto_v1_2_parser),
        ofproto_v1_3.OFP_VERSION: (ofproto_v1_3,
                                   ofproto_v1_3_parser),
    }

    def __init__(self, methodName):
        print 'init', methodName
        super(Test_Parser, self).__init__(methodName)

    def setUp(self):
        pass

    def tearDown(self):
        pass

    @staticmethod
    def _msg_to_jsondict(msg):
        return msg.to_jsondict()

    @staticmethod
    def _jsondict_to_msg(dp, jsondict):
        return ofproto_parser.ofp_msg_from_jsondict(dp, jsondict)

    def _test_msg(self, name, wire_msg, json_str):
        json_dict = json.loads(json_str)
        # on-wire -> OFPxxx -> json
        (version, msg_type, msg_len, xid) = ofproto_parser.header(wire_msg)
        try:
            has_parser, has_serializer = implemented[version][msg_type]
        except KeyError:
            has_parser = True
            has_serializer = True

        dp = DummyDatapath(*self._ofp_versions[version])
        if has_parser:
            msg = ofproto_parser.msg(dp, version, msg_type, msg_len, xid,
                                     wire_msg)
            json_dict2 = self._msg_to_jsondict(msg)
            # XXXdebug code
            open(('/tmp/%s.json' % name), 'wb').write(json.dumps(json_dict2))
            eq_(json_dict, json_dict2)

        # json -> OFPxxx -> json
        msg2 = self._jsondict_to_msg(dp, json_dict)
        if has_serializer:
            msg2.serialize()
            eq_(self._msg_to_jsondict(msg2), json_dict)
            eq_(wire_msg, msg2.buf)

            # check if "len" "length" fields can be omitted

            def _remove(d, names):
                f = lambda x: _remove(x, names)
                if isinstance(d, list):
                    return map(f, d)
                if isinstance(d, dict):
                    d2 = {}
                    for k, v in d.iteritems():
                        if k in names:
                            continue
                        d2[k] = f(v)
                    return d2
                return d

            json_dict3 = _remove(json_dict, ['len', 'length'])
            msg3 = self._jsondict_to_msg(dp, json_dict3)
            msg3.serialize()
            eq_(wire_msg, msg3.buf)

            msg2.serialize()
            eq_(wire_msg, msg2.buf)


def _add_tests():
    import os
    import fnmatch
    import new
    import functools

    packet_data_dir = '../packet_data'
    json_dir = './ofproto/json'
    ofvers = [
        'of10',
        'of12',
        'of13',
    ]
    for ver in ofvers:
        pdir = packet_data_dir + '/' + ver
        jdir = json_dir + '/' + ver
        for file in os.listdir(pdir):
            if not fnmatch.fnmatch(file, '*.packet'):
                continue
            wire_msg = open(pdir + '/' + file, 'rb').read()
            json_str = open(jdir + '/' + file + '.json', 'rb').read()
            method_name = ('test_' + file).replace('-', '_').replace('.', '_')

            def _run(self, name, wire_msg, json_str):
                print ('processing %s ...' % name)
                self._test_msg(name, wire_msg, json_str)
            print ('adding %s ...' % method_name)
            f = functools.partial(_run, name=method_name, wire_msg=wire_msg,
                                  json_str=json_str)
            f.func_name = method_name
            f.__name__ = method_name
            im = new.instancemethod(f, None, Test_Parser)
            setattr(Test_Parser, method_name, im)

_add_tests()

########NEW FILE########
__FILENAME__ = test_parser_compat
# Copyright (C) 2013 Nippon Telegraph and Telephone Corporation.
# Copyright (C) 2013 YAMAMOTO Takashi <yamamoto at valinux co jp>
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import sys
import unittest
from nose.tools import eq_
from nose.tools import ok_

from ryu.ofproto import ofproto_v1_2
from ryu.ofproto import ofproto_v1_3
from ryu.ofproto import ofproto_v1_2_parser
from ryu.ofproto import ofproto_v1_3_parser

from ryu.lib import addrconv
from struct import unpack


class Test_Parser_Compat(unittest.TestCase):
    def __init__(self, methodName):
        print 'init', methodName
        super(Test_Parser_Compat, self).__init__(methodName)

    def setUp(self):
        pass

    def tearDown(self):
        pass

    def _test(self, name, ofpp):
        ofp = {
            ofproto_v1_2_parser: ofproto_v1_2,
            ofproto_v1_3_parser: ofproto_v1_3,
        }[ofpp]

        in_port = 987654321
        eth_src = 'aa:bb:cc:dd:ee:ff'
        ipv4_src = '192.0.2.9'
        ipv6_src = 'fe80::f00b:a4ff:feef:5d8f'

        old_in_port = in_port
        old_eth_src = addrconv.mac.text_to_bin(eth_src)
        old_ipv4_src = unpack('!I', addrconv.ipv4.text_to_bin(ipv4_src))[0]
        old_ipv6_src = list(unpack('!8H',
                            addrconv.ipv6.text_to_bin(ipv6_src)))

        def check(o):
            check_old(o)
            check_new(o)

        def check_old(o):
            # old api
            def get_field(m, t):
                for f in m.fields:
                    if isinstance(f, t):
                        return f
            get_value = lambda m, t: get_field(m, t).value

            eq_(get_value(o, ofpp.MTInPort), old_in_port)
            eq_(get_value(o, ofpp.MTEthSrc), old_eth_src)
            eq_(get_value(o, ofpp.MTIPV4Src), old_ipv4_src)
            eq_(get_value(o, ofpp.MTIPv6Src), old_ipv6_src)

        def check_new(o):
            # new api
            eq_(o['in_port'], in_port)
            eq_(o['eth_src'], eth_src)
            eq_(o['ipv4_src'], ipv4_src)
            eq_(o['ipv6_src'], ipv6_src)

        # ensure that old and new api produces the same thing

        # old api
        old = ofpp.OFPMatch()
        old.set_in_port(old_in_port)
        old.set_dl_src(old_eth_src)
        old.set_ipv4_src(old_ipv4_src)
        old.set_ipv6_src(old_ipv6_src)

        old_buf = bytearray()
        old.serialize(old_buf, 0)

        # note: you can't inspect an object composed with the old set_XXX api
        # before serialize().
        check_old(old)

        # another variant of old api; originally it was intended to be
        # internal but actually used in the field.  eg. LINC l2_switch_v1_3.py
        old2 = ofpp.OFPMatch()
        old2.append_field(ofp.OXM_OF_IN_PORT, old_in_port)
        old2.append_field(ofp.OXM_OF_ETH_SRC, old_eth_src)
        old2.append_field(ofp.OXM_OF_IPV4_SRC, old_ipv4_src)
        old2.append_field(ofp.OXM_OF_IPV6_SRC, old_ipv6_src)
        check_old(old2)

        old2_buf = bytearray()
        old2.serialize(old2_buf, 0)

        # new api
        new = ofpp.OFPMatch(in_port=in_port, eth_src=eth_src,
                            ipv4_src=ipv4_src, ipv6_src=ipv6_src)
        check_new(new)

        new_buf = bytearray()
        new.serialize(new_buf, 0)
        eq_(new_buf, old_buf)
        eq_(new_buf, old2_buf)

        old_jsondict = old.to_jsondict()
        old2_jsondict = old2.to_jsondict()
        new_jsondict = new.to_jsondict()
        eq_(new_jsondict, old_jsondict)
        eq_(new_jsondict, old2_jsondict)

        eq_(str(new), str(old))
        eq_(str(new), str(old2))

        # a parsed object can be inspected by old and new api

        check(ofpp.OFPMatch.parser(buffer(new_buf), 0))
        check(ofpp.OFPMatch.from_jsondict(new_jsondict.values()[0]))


def _add_tests():
    import new
    import functools
    import itertools

    ofpps = [ofproto_v1_2_parser, ofproto_v1_3_parser]
    for ofpp in ofpps:
                        mod = ofpp.__name__.split('.')[-1]
                        method_name = 'test_' + mod + '_ofpmatch_compat'

                        def _run(self, name, ofpp):
                            print ('processing %s ...' % name)
                            self._test(name, ofpp)
                        print ('adding %s ...' % method_name)
                        f = functools.partial(_run, name=method_name,
                                              ofpp=ofpp)
                        f.func_name = method_name
                        f.__name__ = method_name
                        cls = Test_Parser_Compat
                        im = new.instancemethod(f, None, cls)
                        setattr(cls, method_name, im)

_add_tests()

########NEW FILE########
__FILENAME__ = test_parser_ofpmatch
# Copyright (C) 2013 Nippon Telegraph and Telephone Corporation.
# Copyright (C) 2013 YAMAMOTO Takashi <yamamoto at valinux co jp>
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import sys
import unittest
from nose.tools import eq_
from nose.tools import ok_

from ryu.ofproto import ofproto_v1_2
from ryu.ofproto import ofproto_v1_3
from ryu.ofproto import ofproto_v1_2_parser
from ryu.ofproto import ofproto_v1_3_parser


class Test_Parser_OFPMatch(unittest.TestCase):
    _ofp = {ofproto_v1_2_parser: ofproto_v1_2,
            ofproto_v1_3_parser: ofproto_v1_3}

    def __init__(self, methodName):
        print 'init', methodName
        super(Test_Parser_OFPMatch, self).__init__(methodName)

    def setUp(self):
        pass

    def tearDown(self):
        pass

    def _test(self, name, ofpp, d, domask):
        if domask:
            d = dict(self._ofp[ofpp].oxm_normalize_user(k, uv)
                     for (k, uv)
                     in d.iteritems())
        match = ofpp.OFPMatch(**d)
        b = bytearray()
        match.serialize(b, 0)
        match2 = match.parser(buffer(b), 0)
        for k, v in d.iteritems():
            ok_(k in match)
            ok_(k in match2)
            eq_(match[k], v)
            eq_(match2[k], v)
        for k, v in match.iteritems():
            ok_(k in d)
            eq_(d[k], v)
        for k, v in match2.iteritems():
            ok_(k in d)
            eq_(d[k], v)


def _add_tests():
    import new
    import functools
    import itertools

    class Field(object):
        @classmethod
        def generate_mask(cls):
            return list(cls.generate())[1]

    class Int1(Field):
        @staticmethod
        def generate():
            yield 0
            yield 0xff

    class Int2(Field):
        @staticmethod
        def generate():
            yield 0
            yield 0x1234
            yield 0xffff

    class Int3(Field):
        @staticmethod
        def generate():
            yield 0
            yield 0x123456
            yield 0xffffff

    class Int4(Field):
        @staticmethod
        def generate():
            yield 0
            yield 0x12345678
            yield 0xffffffff

    class Int8(Field):
        @staticmethod
        def generate():
            yield 0
            yield 0x123456789abcdef0
            yield 0xffffffffffffffff

    class Mac(Field):
        @staticmethod
        def generate():
            yield '00:00:00:00:00:00'
            yield 'f2:0b:a4:7d:f8:ea'
            yield 'ff:ff:ff:ff:ff:ff'

    class IPv4(Field):
        @staticmethod
        def generate():
            yield '0.0.0.0'
            yield '192.0.2.1'
            yield '255.255.255.255'

    class IPv6(Field):
        @staticmethod
        def generate():
            yield '::'
            yield 'fe80::f00b:a4ff:fed0:3f70'
            yield 'ffff:ffff:ffff:ffff:ffff:ffff:ffff:ffff'

    class B64(Field):
        @staticmethod
        def generate():
            yield 'aG9nZWhvZ2U='
            yield 'ZnVnYWZ1Z2E='

    ofpps = [ofproto_v1_2_parser, ofproto_v1_3_parser]
    common = [
        ('in_port', Int4),
        ('in_phy_port', Int4),
        ('metadata', Int8),
        ('eth_dst', Mac),
        ('eth_src', Mac),
        ('eth_type', Int2),
        ('vlan_vid', Int2),
        ('vlan_pcp', Int1),
        ('ip_dscp', Int1),
        ('ip_ecn', Int1),
        ('ip_proto', Int1),
        ('ipv4_src', IPv4),
        ('ipv4_dst', IPv4),
        ('tcp_src', Int2),
        ('tcp_dst', Int2),
        ('udp_src', Int2),
        ('udp_dst', Int2),
        ('sctp_src', Int2),
        ('sctp_dst', Int2),
        ('icmpv4_type', Int1),
        ('icmpv4_code', Int1),
        ('arp_op', Int2),
        ('arp_spa', IPv4),
        ('arp_tpa', IPv4),
        ('arp_sha', Mac),
        ('arp_tha', Mac),
        ('ipv6_dst', IPv6),
        ('ipv6_src', IPv6),
        ('ipv6_flabel', Int3),
        ('icmpv6_type', Int1),
        ('icmpv6_code', Int1),
        ('ipv6_nd_target', IPv6),
        ('ipv6_nd_sll', Mac),
        ('ipv6_nd_tll', Mac),
        ('mpls_label', Int3),
        ('mpls_tc', Int1),
        ('field_100', B64),
    ]
    L = {}
    L[ofproto_v1_2_parser] = common + [
        # OF1.2 doesn't have OXM_OF_PBB_ISID.
        #    OFPXMC_OPENFLOW_BASIC = 0x8000
        #    OXM_OF_PBB_ISID = 37
        #    (OFPXMC_OPENFLOW_BASIC << 7) + OXM_OF_PBB_ISID == 4194341
        ('field_4194341', B64),
    ]
    L[ofproto_v1_3_parser] = common + [
        ('pbb_isid', Int3),
        ('tunnel_id', Int8),
        ('ipv6_exthdr', Int2),
    ]

    def flatten_one(l, i):
        if isinstance(i, tuple):
            return l + flatten(i)
        else:
            return l + [i]
    flatten = lambda l: reduce(flatten_one, l, [])

    for ofpp in ofpps:
        for n in xrange(1, 3):
            for C in itertools.combinations(L[ofpp], n):
                l = [1]
                keys = []
                clss = []
                for (k, cls) in C:
                    l = itertools.product(l, cls.generate())
                    keys.append(k)
                    clss.append(cls)
                l = map(lambda x: flatten(x)[1:], l)
                for domask in [True, False]:
                    for values in l:
                        if domask:
                            values = [(value, cls.generate_mask())
                                      for (cls, value)
                                      in itertools.izip(clss, values)]
                        d = dict(itertools.izip(keys, values))
                        mod = ofpp.__name__.split('.')[-1]
                        method_name = 'test_' + mod
                        if domask:
                            method_name += '_mask'
                        for k in sorted(dict(d).keys()):
                            method_name += '_' + str(k)
                            method_name += '_' + str(d[k])
                        method_name = method_name.replace(':', '_')
                        method_name = method_name.replace('.', '_')
                        method_name = method_name.replace('(', '_')
                        method_name = method_name.replace(')', '_')
                        method_name = method_name.replace(',', '_')
                        method_name = method_name.replace("'", '_')
                        method_name = method_name.replace(' ', '_')

                        def _run(self, name, ofpp, d, domask):
                            print ('processing %s ...' % name)
                            self._test(name, ofpp, d, domask)
                        print ('adding %s ...' % method_name)
                        f = functools.partial(_run, name=method_name,
                                              ofpp=ofpp, d=d, domask=domask)
                        f.func_name = method_name
                        f.__name__ = method_name
                        cls = Test_Parser_OFPMatch
                        im = new.instancemethod(f, None, cls)
                        setattr(cls, method_name, im)

_add_tests()

########NEW FILE########
__FILENAME__ = test_parser_v10
# Copyright (C) 2012 Nippon Telegraph and Telephone Corporation.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# vim: tabstop=4 shiftwidth=4 softtabstop=4

import unittest
import logging
from nose.tools import *
from ryu.ofproto.ofproto_v1_0_parser import *
from ryu.ofproto import ofproto_v1_0_parser
from ryu.lib import addrconv


LOG = logging.getLogger('test_ofproto_v10')


class TestOFPPhyPort(unittest.TestCase):
    """ Test case for ofproto_v1_0_parser.OFPPhyPort
    """

    # OFP_PHY_PORT_PACK_STR
    # '!H6s16sIIIIII'... port_no, hw_addr, name, config, state
    #                    curr, advertised, supported, peer
    port_no = {'buf': '\xe7\x6b', 'val': 59243}
    hw_addr = '52:54:54:10:20:99'
    name = 'name'.ljust(16)
    config = {'buf': '\x84\xb6\x8c\x53', 'val': 2226555987}
    state = {'buf': '\x64\x07\xfb\xc9', 'val': 1678244809}
    curr = {'buf': '\xa9\xe8\x0a\x2b', 'val': 2850556459}
    advertised = {'buf': '\x78\xb9\x7b\x72', 'val': 2025421682}
    supported = {'buf': '\x7e\x65\x68\xad', 'val': 2120575149}
    peer = {'buf': '\xa4\x5b\x8b\xed', 'val': 2757463021}

    buf = port_no['buf'] \
        + addrconv.mac.text_to_bin(hw_addr) \
        + name \
        + config['buf'] \
        + state['buf'] \
        + curr['buf'] \
        + advertised['buf'] \
        + supported['buf'] \
        + peer['buf']

    c = OFPPhyPort(port_no['val'],
                   hw_addr,
                   name,
                   config['val'],
                   state['val'],
                   curr['val'],
                   advertised['val'],
                   supported['val'],
                   peer['val'])

    def setUp(self):
        pass

    def tearDown(self):
        pass

    def test_init(self):
        eq_(self.port_no['val'], self.c.port_no)
        eq_(self.hw_addr, self.c.hw_addr)
        eq_(self.name, self.c.name)
        eq_(self.config['val'], self.c.config)
        eq_(self.state['val'], self.c.state)
        eq_(self.curr['val'], self.c.curr)
        eq_(self.advertised['val'], self.c.advertised)
        eq_(self.supported['val'], self.c.supported)
        eq_(self.peer['val'], self.c.peer)

    def test_parser(self):
        res = self.c.parser(self.buf, 0)

        eq_(self.port_no['val'], res.port_no)
        eq_(self.hw_addr, res.hw_addr)
        eq_(self.name, res.name)
        eq_(self.config['val'], res.config)
        eq_(self.state['val'], res.state)
        eq_(self.curr['val'], res.curr)
        eq_(self.advertised['val'], res.advertised)
        eq_(self.supported['val'], res.supported)
        eq_(self.peer['val'], res.peer)


class TestOFPMatch(unittest.TestCase):
    """ Test case for ofproto_v1_0_parser.OFPMatch
    """

    # OFP_MATCH_PACK_STR
    # '!IH6s6sHBxHBB2xIIHH'...wildcards, in_port, dl_src, dl_dst, dl_vlan,
    #                         dl_vlan_pcp, dl_type, nw_tos, nw_proto,
    #                         nw_src, nw_dst, tp_src, tp_dst
    wildcards = {'buf': '\xd2\x71\x25\x23', 'val': 3530630435}
    in_port = {'buf': '\x37\x8b', 'val': 14219}
    dl_src = '\x52\x54\x54\x10\x20\x99'
    dl_dst = '\x61\x31\x50\x6d\xc9\xe5'
    dl_vlan = {'buf': '\xc1\xf9', 'val': 49657}
    dl_vlan_pcp = {'buf': '\x79', 'val': 121}
    zfill0 = '\x00'
    dl_type = {'buf': '\xa6\x9e', 'val': 42654}
    nw_tos = {'buf': '\xde', 'val': 222}
    nw_proto = {'buf': '\xe5', 'val': 229}
    zfil11 = '\x00' * 2
    nw_src = {'buf': '\x1b\x6d\x8d\x4b', 'val': 460164427}
    nw_dst = {'buf': '\xab\x25\xe1\x20', 'val': 2871386400}
    tp_src = {'buf': '\xd5\xc3', 'val': 54723}
    tp_dst = {'buf': '\x78\xb9', 'val': 30905}

    buf = wildcards['buf'] \
        + in_port['buf'] \
        + dl_src \
        + dl_dst \
        + dl_vlan['buf'] \
        + dl_vlan_pcp['buf'] \
        + zfill0 \
        + dl_type['buf'] \
        + nw_tos['buf'] \
        + nw_proto['buf'] \
        + zfil11 \
        + nw_src['buf'] \
        + nw_dst['buf'] \
        + tp_src['buf'] \
        + tp_dst['buf']

    def _get_obj(self, dl_src, dl_dst):
        c = OFPMatch(self.wildcards['val'],
                     self.in_port['val'],
                     dl_src,
                     dl_dst,
                     self.dl_vlan['val'],
                     self.dl_vlan_pcp['val'],
                     self.dl_type['val'],
                     self.nw_tos['val'],
                     self.nw_proto['val'],
                     self.nw_src['val'],
                     self.nw_dst['val'],
                     self.tp_src['val'],
                     self.tp_dst['val'])
        return c

    def setUp(self):
        pass

    def tearDown(self):
        pass

    def test_init(self):
        c = self._get_obj(self.dl_src, self.dl_dst)

        eq_(self.wildcards['val'], c.wildcards)
        eq_(self.in_port['val'], c.in_port)
        eq_(self.dl_src, c.dl_src)
        eq_(self.dl_dst, c.dl_dst)
        eq_(self.dl_vlan['val'], c.dl_vlan)
        eq_(self.dl_vlan_pcp['val'], c.dl_vlan_pcp)
        eq_(self.dl_type['val'], c.dl_type)
        eq_(self.nw_tos['val'], c.nw_tos)
        eq_(self.nw_proto['val'], c.nw_proto)
        eq_(self.nw_src['val'], c.nw_src)
        eq_(self.nw_dst['val'], c.nw_dst)
        eq_(self.tp_src['val'], c.tp_src)
        eq_(self.tp_dst['val'], c.tp_dst)

    def test_init_zero(self):
        c = self._get_obj(0, 0)
        eq_(mac.DONTCARE, c.dl_src)
        eq_(mac.DONTCARE, c.dl_dst)

    def test_parse(self):
        c = self._get_obj(self.dl_src, self.dl_dst)
        res = c.parse(self.buf, 0)

        eq_(self.wildcards['val'], res.wildcards)
        eq_(self.in_port['val'], res.in_port)
        eq_(self.dl_src, res.dl_src)
        eq_(self.dl_dst, res.dl_dst)
        eq_(self.dl_vlan['val'], res.dl_vlan)
        eq_(self.dl_vlan_pcp['val'], res.dl_vlan_pcp)
        eq_(self.dl_type['val'], res.dl_type)
        eq_(self.nw_tos['val'], res.nw_tos)
        eq_(self.nw_proto['val'], res.nw_proto)
        eq_(self.nw_src['val'], res.nw_src)
        eq_(self.nw_dst['val'], res.nw_dst)
        eq_(self.tp_src['val'], res.tp_src)
        eq_(self.tp_dst['val'], res.tp_dst)

    def test_serialize(self):
        buf = bytearray()
        c = self._get_obj(self.dl_src, self.dl_dst)

        c.serialize(buf, 0)

        fmt = ofproto_v1_0.OFP_MATCH_PACK_STR
        res = struct.unpack_from(fmt, buffer(buf))

        eq_(self.wildcards['val'], res[0])
        eq_(self.in_port['val'], res[1])
        eq_(self.dl_src, res[2])
        eq_(self.dl_dst, res[3])
        eq_(self.dl_vlan['val'], res[4])
        eq_(self.dl_vlan_pcp['val'], res[5])
        eq_(self.dl_type['val'], res[6])
        eq_(self.nw_tos['val'], res[7])
        eq_(self.nw_proto['val'], res[8])
        eq_(self.nw_src['val'], res[9])
        eq_(self.nw_dst['val'], res[10])
        eq_(self.tp_src['val'], res[11])
        eq_(self.tp_dst['val'], res[12])


class TestOFPActionHeader(unittest.TestCase):
    """ Test case for ofproto_v1_0_parser.OFPActionHeader
    """

    # OFP_ACTION_HEADER_PACK_STR
    # '!HH4x'...type, len, zfill
    type = {'buf': '\x00\x02', 'val': ofproto_v1_0.OFPAT_SET_VLAN_PCP}
    len = {'buf': '\x00\x08', 'val': ofproto_v1_0.OFP_ACTION_HEADER_SIZE}
    zfill = '\x00' * 4

    buf = type['buf'] \
        + len['buf'] \
        + zfill

    c = OFPActionHeader(type['val'], len['val'])

    def setUp(self):
        pass

    def tearDown(self):
        pass

    def test_init(self):
        eq_(self.type['val'], self.c.type)
        eq_(self.len['val'], self.c.len)

    def test_serialize(self):
        buf = bytearray()
        self.c.serialize(buf, 0)

        fmt = ofproto_v1_0.OFP_ACTION_HEADER_PACK_STR
        res = struct.unpack(fmt, buffer(buf))

        eq_(self.type['val'], res[0])
        eq_(self.len['val'], res[1])


class TestOFPActionOutput(unittest.TestCase):
    """ Test case for ofproto_v1_0_parser.OFPActionOutput
    """

    # OFP_ACTION_OUTPUT_PACK_STR
    # '!HHHH'...type, len, port, max_len
    type_ = {'buf': '\x00\x00', 'val': ofproto_v1_0.OFPAT_OUTPUT}
    len_ = {'buf': '\x00\x08', 'val': ofproto_v1_0.OFP_ACTION_OUTPUT_SIZE}
    port = {'buf': '\x19\xce', 'val': 6606}
    max_len = {'buf': '\x00\x08', 'val': ofproto_v1_0.OFP_ACTION_OUTPUT_SIZE}

    buf = type_['buf'] \
        + len_['buf'] \
        + port['buf'] \
        + max_len['buf']

    c = OFPActionOutput(port['val'], max_len['val'])

    def setUp(self):
        pass

    def tearDown(self):
        pass

    def test_init(self):
        eq_(self.port['val'], self.c.port)
        eq_(self.max_len['val'], self.c.max_len)

    def test_parser(self):
        res = self.c.parser(self.buf, 0)

        eq_(self.port['val'], res.port)
        eq_(self.max_len['val'], res.max_len)

    @raises(AssertionError)
    def test_parser_check_type(self):
        type_ = {'buf': '\x00\x01', 'val': 1}

        buf = type_['buf'] \
            + self.len_['buf'] \
            + self.port['buf'] \
            + self.max_len['buf']

        self.c.parser(buf, 0)

    @raises(AssertionError)
    def test_parser_check_len(self):
        len_ = {'buf': '\x00\x07', 'val': 7}

        buf = self.type_['buf'] \
            + len_['buf'] \
            + self.port['buf'] \
            + self.max_len['buf']

        self.c.parser(buf, 0)

    def test_serialize(self):
        buf = bytearray()
        self.c.serialize(buf, 0)

        fmt = ofproto_v1_0.OFP_ACTION_OUTPUT_PACK_STR
        res = struct.unpack(fmt, buffer(buf))

        eq_(self.type_['val'], res[0])
        eq_(self.len_['val'], res[1])
        eq_(self.port['val'], res[2])
        eq_(self.max_len['val'], res[3])


class TestOFPActionVlanVid(unittest.TestCase):
    """ Test case for ofproto_v1_0_parser.OFPActionVlanVid
    """

    # OFP_ACTION_VLAN_VID_PACK_STR
    # '!HHH2x'...type, len, vlan_vid, zfill
    type_ = {'buf': '\x00\x01', 'val': ofproto_v1_0.OFPAT_SET_VLAN_VID}
    len_ = {'buf': '\x00\x08', 'val': ofproto_v1_0.OFP_ACTION_VLAN_VID_SIZE}
    vlan_vid = {'buf': '\x3c\x0e', 'val': 15374}
    zfill = '\x00' * 2

    buf = type_['buf'] \
        + len_['buf'] \
        + vlan_vid['buf'] \
        + zfill

    c = OFPActionVlanVid(vlan_vid['val'])

    def setUp(self):
        pass

    def tearDown(self):
        pass

    def test_init(self):
        eq_(self.vlan_vid['val'], self.c.vlan_vid)

    def test_parser(self):
        res = self.c.parser(self.buf, 0)

        eq_(self.vlan_vid['val'], res.vlan_vid)

    @raises(AssertionError)
    def test_parser_check_type(self):
        type_ = {'buf': '\x00\x02', 'val': 2}

        buf = type_['buf'] \
            + self.len_['buf'] \
            + self.vlan_vid['buf'] \
            + self.zfill

        self.c.parser(buf, 0)

    @raises(AssertionError)
    def test_parser_check_len(self):
        len_ = {'buf': '\x00\x07', 'val': 7}

        buf = self.type_['buf'] \
            + len_['buf'] \
            + self.vlan_vid['buf'] \
            + self.zfill

        self.c.parser(buf, 0)

    def test_serialize(self):
        buf = bytearray()
        self.c.serialize(buf, 0)

        fmt = ofproto_v1_0.OFP_ACTION_VLAN_VID_PACK_STR
        res = struct.unpack(fmt, buffer(buf))

        eq_(self.type_['val'], res[0])
        eq_(self.len_['val'], res[1])
        eq_(self.vlan_vid['val'], res[2])


class TestOFPActionVlanPcp(unittest.TestCase):
    """ Test case for ofproto_v1_0_parser.OFPActionVlanPcp
    """

    # OFP_ACTION_VLAN_PCP_PACK_STR
    # '!HHB3x'...type, len, vlan_pcp, zfill
    type_ = {'buf': '\x00\x02', 'val': ofproto_v1_0.OFPAT_SET_VLAN_PCP}
    len_ = {'buf': '\x00\x08', 'val': ofproto_v1_0.OFP_ACTION_VLAN_PCP_SIZE}
    vlan_pcp = {'buf': '\x1c', 'val': 28}
    zfill = '\x00' * 3

    buf = type_['buf'] \
        + len_['buf'] \
        + vlan_pcp['buf'] \
        + zfill

    c = OFPActionVlanPcp(vlan_pcp['val'])

    def setUp(self):
        pass

    def tearDown(self):
        pass

    def test_init(self):
        eq_(self.vlan_pcp['val'], self.c.vlan_pcp)

    def test_parser(self):
        res = self.c.parser(self.buf, 0)
        eq_(self.vlan_pcp['val'], res.vlan_pcp)

    @raises(AssertionError)
    def test_parser_check_type(self):
        type_ = {'buf': '\x00\x01', 'val': 1}

        buf = type_['buf'] \
            + self.len_['buf'] \
            + self.vlan_pcp['buf'] \
            + self.zfill

        self.c.parser(buf, 0)

    @raises(AssertionError)
    def test_parser_check_len(self):
        len_ = {'buf': '\x00\x07', 'val': 7}

        buf = self.type_['buf'] \
            + len_['buf'] \
            + self.vlan_pcp['buf'] \
            + self.zfill

        self.c.parser(buf, 0)

    def test_serialize(self):
        buf = bytearray()
        self.c.serialize(buf, 0)

        fmt = ofproto_v1_0.OFP_ACTION_VLAN_PCP_PACK_STR
        res = struct.unpack(fmt, buffer(buf))

        eq_(self.type_['val'], res[0])
        eq_(self.len_['val'], res[1])
        eq_(self.vlan_pcp['val'], res[2])


class TestOFPActionStripVlan(unittest.TestCase):
    """ Test case for ofproto_v1_0_parser.OFPActionStripVlan
    """

    # OFP_ACTION_HEADER_PACK_STR
    # '!HH4x'...type, len, zfill
    type_ = {'buf': '\x00\x03', 'val': ofproto_v1_0.OFPAT_STRIP_VLAN}
    len_ = {'buf': '\x00\x08', 'val': ofproto_v1_0.OFP_ACTION_HEADER_SIZE}
    zfill = '\x00' * 4

    buf = type_['buf'] \
        + len_['buf'] \
        + zfill

    c = OFPActionStripVlan()

    def setUp(self):
        pass

    def tearDown(self):
        pass

    def test_init(self):
        pass

    def test_parser(self):
        ok_(self.c.parser(self.buf, 0))

    @raises(AssertionError)
    def test_parser_check_type(self):
        type_ = {'buf': '\x00\x01', 'val': 1}

        buf = type_['buf'] \
            + self.len_['buf'] \
            + self.zfill

        self.c.parser(buf, 0)

    @raises(AssertionError)
    def test_parser_check_len(self):
        len_ = {'buf': '\x00\x07', 'val': 7}

        buf = self.type_['buf'] \
            + len_['buf'] \
            + self.zfill

        self.c.parser(buf, 0)


class TestOFPActionSetDlSrc(unittest.TestCase):
    """ Test case for ofproto_v1_0_parser.OFPActionSetDlSrc
    """

    # OFP_ACTION_DL_ADDR_PACK_STR
    # '!HH6s6x'...type, len, dl_addr, zfill
    type_ = {'buf': '\x00\x04', 'val': ofproto_v1_0.OFPAT_SET_DL_SRC}
    len_ = {'buf': '\x00\x10', 'val': ofproto_v1_0.OFP_ACTION_DL_ADDR_SIZE}
    dl_addr = '\x0e\xde\x27\xce\xc6\xcf'
    zfill = '\x00' * 6

    buf = type_['buf'] \
        + len_['buf'] \
        + dl_addr \
        + zfill

    c = OFPActionSetDlSrc(dl_addr)

    def setUp(self):
        pass

    def tearDown(self):
        pass

    def test_init(self):
        eq_(self.dl_addr, self.c.dl_addr)

    def test_parser_type_src(self):
        res = self.c.parser(self.buf, 0)
        eq_(self.dl_addr, res.dl_addr)

    def test_parser_type_dst(self):
        type_ = {'buf': '\x00\x05', 'val': ofproto_v1_0.OFPAT_SET_DL_DST}
        buf = type_['buf'] \
            + self.len_['buf'] \
            + self.dl_addr \
            + self.zfill

        res = self.c.parser(buf, 0)

        eq_(self.dl_addr, res.dl_addr)

    @raises(AssertionError)
    def test_parser_check_type(self):
        type_ = {'buf': '\x00\x06', 'val': 6}
        buf = type_['buf'] \
            + self.len_['buf'] \
            + self.dl_addr \
            + self.zfill

        res = self.c.parser(buf, 0)

    @raises(AssertionError)
    def test_parser_check_len(self):
        len_ = {'buf': '\x00\x07', 'val': 7}
        buf = self.type_['buf'] \
            + len_['buf'] \
            + self.dl_addr \
            + self.zfill

        res = self.c.parser(buf, 0)

    def test_serialize(self):
        buf = bytearray()
        self.c.serialize(buf, 0)

        fmt = ofproto_v1_0.OFP_ACTION_DL_ADDR_PACK_STR
        res = struct.unpack(fmt, buffer(buf))

        eq_(self.type_['val'], res[0])
        eq_(self.len_['val'], res[1])
        eq_(self.dl_addr, res[2])


class TestOFPActionSetDlDst(unittest.TestCase):
    """ Test case for ofproto_v1_0_parser.OFPActionSetDlDst
    """

    # OFP_ACTION_DL_ADDR_PACK_STR
    # '!HH6s6x'...type, len, dl_addr, zfill
    type_ = {'buf': '\x00\x05', 'val': ofproto_v1_0.OFPAT_SET_DL_DST}
    len_ = {'buf': '\x00\x10', 'val': ofproto_v1_0.OFP_ACTION_DL_ADDR_SIZE}
    dl_addr = '\x37\x48\x38\x9a\xf4\x28'
    zfill = '\x00' * 6

    buf = type_['buf'] \
        + len_['buf'] \
        + dl_addr \
        + zfill

    c = OFPActionSetDlDst(dl_addr)

    def setUp(self):
        pass

    def tearDown(self):
        pass

    def test_init(self):
        eq_(self.dl_addr, self.c.dl_addr)

    def test_parser_type_dst(self):
        res = self.c.parser(self.buf, 0)
        eq_(self.dl_addr, res.dl_addr)

    def test_parser_type_src(self):
        type_ = {'buf': '\x00\x04', 'val': ofproto_v1_0.OFPAT_SET_DL_SRC}
        buf = type_['buf'] \
            + self.len_['buf'] \
            + self.dl_addr \
            + self.zfill

        res = self.c.parser(buf, 0)

        eq_(self.dl_addr, res.dl_addr)

    @raises(AssertionError)
    def test_parser_check_type(self):
        type_ = {'buf': '\x00\x06', 'val': 6}
        buf = type_['buf'] \
            + self.len_['buf'] \
            + self.dl_addr \
            + self.zfill

        res = self.c.parser(buf, 0)

    @raises(AssertionError)
    def test_parser_check_len(self):
        len_ = {'buf': '\x00\x07', 'val': 7}
        buf = self.type_['buf'] \
            + len_['buf'] \
            + self.dl_addr \
            + self.zfill

        res = self.c.parser(buf, 0)

    def test_serialize(self):
        buf = bytearray()
        self.c.serialize(buf, 0)

        fmt = ofproto_v1_0.OFP_ACTION_DL_ADDR_PACK_STR
        res = struct.unpack(fmt, buffer(buf))

        eq_(self.type_['val'], res[0])
        eq_(self.len_['val'], res[1])
        eq_(self.dl_addr, res[2])


class TestOFPActionSetNwSrc(unittest.TestCase):
    """ Test case for ofproto_v1_0_parser.OFPActionSetNwSrc
    """

    # OFP_ACTION_NW_ADDR_PACK_STR
    # '!HHI'...type, len, nw_addr
    type_ = {'buf': '\x00\x06', 'val': ofproto_v1_0.OFPAT_SET_NW_SRC}
    len_ = {'buf': '\x00\x08', 'val': ofproto_v1_0.OFP_ACTION_NW_ADDR_SIZE}
    nw_addr = {'buf': '\xc0\xa8\x7a\x0a', 'val': 3232266762}

    buf = type_['buf'] \
        + len_['buf'] \
        + nw_addr['buf']

    c = OFPActionSetNwSrc(nw_addr['val'])

    def setUp(self):
        pass

    def tearDown(self):
        pass

    def test_init(self):
        eq_(self.nw_addr['val'], self.c.nw_addr)

    def test_parser_src(self):
        res = self.c.parser(self.buf, 0)
        eq_(self.nw_addr['val'], res.nw_addr)

    def test_parser_dst(self):
        type_ = {'buf': '\x00\x07', 'val': ofproto_v1_0.OFPAT_SET_NW_DST}

        buf = type_['buf'] \
            + self.len_['buf'] \
            + self.nw_addr['buf']

        res = self.c.parser(buf, 0)
        eq_(self.nw_addr['val'], res.nw_addr)

    @raises(AssertionError)
    def test_parser_check_type(self):
        type_ = {'buf': '\x00\x05', 'val': 5}

        buf = type_['buf'] \
            + self.len_['buf'] \
            + self.nw_addr['buf']

        self.c.parser(buf, 0)

    @raises(AssertionError)
    def test_parser_check_len(self):
        len_ = {'buf': '\x00\x10', 'val': 16}

        buf = self.type_['buf'] \
            + len_['buf'] \
            + self.nw_addr['buf']

        self.c.parser(buf, 0)

    def test_serialize(self):
        buf = bytearray()
        self.c.serialize(buf, 0)

        fmt = ofproto_v1_0.OFP_ACTION_NW_ADDR_PACK_STR
        res = struct.unpack(fmt, buffer(buf))

        eq_(self.type_['val'], res[0])
        eq_(self.len_['val'], res[1])
        eq_(self.nw_addr['val'], res[2])


class TestOFPActionSetNwDst(unittest.TestCase):
    """ Test case for ofproto_v1_0_parser.OFPActionSetNwDst
    """

    # OFP_ACTION_NW_ADDR_PACK_STR
    # '!HHI'...type, len, nw_addr
    type_ = {'buf': '\x00\x07', 'val': ofproto_v1_0.OFPAT_SET_NW_DST}
    len_ = {'buf': '\x00\x08', 'val': ofproto_v1_0.OFP_ACTION_NW_ADDR_SIZE}
    nw_addr = {'buf': '\xc0\xa8\x7a\x0a', 'val': 3232266762}

    buf = type_['buf'] \
        + len_['buf'] \
        + nw_addr['buf']

    c = OFPActionSetNwDst(nw_addr['val'])

    def setUp(self):
        pass

    def tearDown(self):
        pass

    def test_init(self):
        eq_(self.nw_addr['val'], self.c.nw_addr)

    def test_parser_dst(self):
        res = self.c.parser(self.buf, 0)
        eq_(self.nw_addr['val'], res.nw_addr)

    def test_parser_src(self):
        type_ = {'buf': '\x00\x06', 'val': ofproto_v1_0.OFPAT_SET_NW_SRC}

        buf = type_['buf'] \
            + self.len_['buf'] \
            + self.nw_addr['buf']

        res = self.c.parser(buf, 0)
        eq_(self.nw_addr['val'], res.nw_addr)

    @raises(AssertionError)
    def test_parser_check_type(self):
        type_ = {'buf': '\x00\x05', 'val': 5}

        buf = type_['buf'] \
            + self.len_['buf'] \
            + self.nw_addr['buf']

        self.c.parser(buf, 0)

    @raises(AssertionError)
    def test_parser_check_len(self):
        len_ = {'buf': '\x00\x10', 'val': 16}

        buf = self.type_['buf'] \
            + len_['buf'] \
            + self.nw_addr['buf']

        self.c.parser(buf, 0)

    def test_serialize(self):
        buf = bytearray()
        self.c.serialize(buf, 0)

        fmt = ofproto_v1_0.OFP_ACTION_NW_ADDR_PACK_STR
        res = struct.unpack(fmt, buffer(buf))

        eq_(self.type_['val'], res[0])
        eq_(self.len_['val'], res[1])
        eq_(self.nw_addr['val'], res[2])


class TestOFPActionSetNwTos(unittest.TestCase):
    """ Test case for ofproto_v1_0_parser.OFPActionSetNwTos
    """

    # OFP_ACTION_NW_TOS_PACK_STR
    # '!HHB3x'...type, len, tos, zfill
    type_ = {'buf': '\x00\x08', 'val': ofproto_v1_0.OFPAT_SET_NW_TOS}
    len_ = {'buf': '\x00\x08', 'val': ofproto_v1_0.OFP_ACTION_NW_TOS_SIZE}
    tos = {'buf': '\xb6', 'val': 182}
    zfill = '\x00' * 3

    buf = type_['buf'] \
        + len_['buf'] \
        + tos['buf'] \
        + zfill

    c = OFPActionSetNwTos(tos['val'])

    def setUp(self):
        pass

    def tearDown(self):
        pass

    def test_init(self):
        eq_(self.tos['val'], self.c.tos)

    def test_parser(self):
        res = self.c.parser(self.buf, 0)
        eq_(self.tos['val'], res.tos)

    @raises(AssertionError)
    def test_parser_check_type(self):
        type_ = {'buf': '\x00\x05', 'val': 5}

        buf = type_['buf'] \
            + self.len_['buf'] \
            + self.tos['buf'] \
            + self.zfill

        self.c.parser(buf, 0)

    @raises(AssertionError)
    def test_parser_check_len(self):
        len_ = {'buf': '\x00\x07', 'val': 7}

        buf = self.type_['buf'] \
            + len_['buf'] \
            + self.tos['buf'] \
            + self.zfill

        self.c.parser(buf, 0)

    def test_serialize(self):
        buf = bytearray()
        self.c.serialize(buf, 0)

        fmt = ofproto_v1_0.OFP_ACTION_NW_TOS_PACK_STR
        res = struct.unpack(fmt, buffer(buf))

        eq_(self.type_['val'], res[0])
        eq_(self.len_['val'], res[1])
        eq_(self.tos['val'], res[2])


class TestOFPActionSetTpSrc(unittest.TestCase):
    """ Test case for ofproto_v1_0_parser.OFPActionSetTpSrc
    """

    # OFP_ACTION_TP_PORT_PACK_STR
    # '!HHH2x'...type, len, tp, zfill
    type_ = {'buf': '\x00\x09', 'val': ofproto_v1_0.OFPAT_SET_TP_SRC}
    len_ = {'buf': '\x00\x08', 'val': ofproto_v1_0.OFP_ACTION_TP_PORT_SIZE}
    tp = {'buf': '\x07\xf1', 'val': 2033}
    zfill = '\x00' * 2

    buf = type_['buf'] \
        + len_['buf'] \
        + tp['buf'] \
        + zfill

    c = OFPActionSetTpSrc(tp['val'])

    def setUp(self):
        pass

    def tearDown(self):
        pass

    def test_init(self):
        eq_(self.tp['val'], self.c.tp)

    def test_parser_src(self):
        res = self.c.parser(self.buf, 0)
        eq_(self.tp['val'], res.tp)

    def test_parser_dst(self):
        type_ = {'buf': '\x00\x0a', 'val': ofproto_v1_0.OFPAT_SET_TP_DST}

        buf = type_['buf'] \
            + self.len_['buf'] \
            + self.tp['buf'] \
            + self.zfill

        res = self.c.parser(self.buf, 0)
        eq_(self.tp['val'], res.tp)

    @raises(AssertionError)
    def test_parser_check_type(self):
        type_ = {'buf': '\x00\x07', 'val': 7}

        buf = type_['buf'] \
            + self.len_['buf'] \
            + self.tp['buf'] \
            + self.zfill

        self.c.parser(buf, 0)

    @raises(AssertionError)
    def test_parser_check_len(self):
        len_ = {'buf': '\x00\x07', 'val': 7}

        buf = self.type_['buf'] \
            + len_['buf'] \
            + self.tp['buf'] \
            + self.zfill

        self.c.parser(buf, 0)

    def test_serialize(self):
        buf = bytearray()
        self.c.serialize(buf, 0)

        fmt = ofproto_v1_0.OFP_ACTION_TP_PORT_PACK_STR
        res = struct.unpack(fmt, buffer(buf))

        eq_(self.type_['val'], res[0])
        eq_(self.len_['val'], res[1])
        eq_(self.tp['val'], res[2])


class TestOFPActionSetTpDst(unittest.TestCase):
    """ Test case for ofproto_v1_0_parser.OFPActionSetTpDst
    """

    # OFP_ACTION_TP_PORT_PACK_STR
    # '!HHH2x'...type, len, tp, zfill
    type_ = {'buf': '\x00\x0a', 'val': ofproto_v1_0.OFPAT_SET_TP_DST}
    len_ = {'buf': '\x00\x08', 'val': ofproto_v1_0.OFP_ACTION_TP_PORT_SIZE}
    tp = {'buf': '\x06\x6d', 'val': 1645}
    zfill = '\x00' * 2

    buf = type_['buf'] \
        + len_['buf'] \
        + tp['buf'] \
        + zfill

    c = OFPActionSetTpDst(tp['val'])

    def setUp(self):
        pass

    def tearDown(self):
        pass

    def test_init(self):
        eq_(self.tp['val'], self.c.tp)

    def test_parser_dst(self):
        res = self.c.parser(self.buf, 0)
        eq_(self.tp['val'], res.tp)

    def test_parser_src(self):
        type_ = {'buf': '\x00\x09', 'val': ofproto_v1_0.OFPAT_SET_TP_SRC}

        buf = type_['buf'] \
            + self.len_['buf'] \
            + self.tp['buf'] \
            + self.zfill

        res = self.c.parser(buf, 0)
        eq_(self.tp['val'], res.tp)

    @raises(AssertionError)
    def test_parser_check_type(self):
        type_ = {'buf': '\x00\x10', 'val': 16}

        buf = type_['buf'] \
            + self.len_['buf'] \
            + self.tp['buf'] \
            + self.zfill

        self.c.parser(buf, 0)

    @raises(AssertionError)
    def test_parser_check_len(self):
        len_ = {'buf': '\x00\x07', 'val': 7}

        buf = self.type_['buf'] \
            + len_['buf'] \
            + self.tp['buf'] \
            + self.zfill

        self.c.parser(buf, 0)

    def test_serialize(self):
        buf = bytearray()
        self.c.serialize(buf, 0)

        fmt = ofproto_v1_0.OFP_ACTION_TP_PORT_PACK_STR
        res = struct.unpack(fmt, buffer(buf))

        eq_(self.type_['val'], res[0])
        eq_(self.len_['val'], res[1])
        eq_(self.tp['val'], res[2])


class TestOFPActionEnqueue(unittest.TestCase):
    """ Test case for ofproto_v1_0_parser.OFPActionEnqueue
    """

    # OFP_ACTION_ENQUEUE_PACK_STR
    # '!HHH6xI'...type_, len_, port, zfill, queue_id
    type_ = {'buf': '\x00\x0b', 'val': ofproto_v1_0.OFPAT_ENQUEUE}
    len_ = {'buf': '\x00\x10', 'val': ofproto_v1_0.OFP_ACTION_ENQUEUE_SIZE}
    port = {'buf': '\x04\x55', 'val': 1109}
    zfill = '\x00' * 6
    queue_id = {'buf': '\x0a\x5b\x03\x5e', 'val': 173736798}

    buf = type_['buf'] \
        + len_['buf'] \
        + port['buf'] \
        + zfill \
        + queue_id['buf']

    c = OFPActionEnqueue(port['val'], queue_id['val'])

    def setUp(self):
        pass

    def tearDown(self):
        pass

    def test_init(self):
        eq_(self.port['val'], self.c.port)
        eq_(self.queue_id['val'], self.c.queue_id)

    def test_parser(self):
        res = self.c.parser(self.buf, 0)

        eq_(self.port['val'], res.port)
        eq_(self.queue_id['val'], res.queue_id)

    @raises(AssertionError)
    def test_parser_check_type(self):
        type_ = {'buf': '\x00\x0a', 'val': 10}

        buf = type_['buf'] \
            + self.len_['buf'] \
            + self.port['buf'] \
            + self.zfill \
            + self.queue_id['buf']

        self.c.parser(buf, 0)

    @raises(AssertionError)
    def test_parser_check_len(self):
        len_ = {'buf': '\x00\x05', 'val': 5}

        buf = self.type_['buf'] \
            + len_['buf'] \
            + self.port['buf'] \
            + self.zfill \
            + self.queue_id['buf']

        self.c.parser(buf, 0)

    def test_serialize(self):
        buf = bytearray()
        self.c.serialize(buf, 0)

        fmt = ofproto_v1_0.OFP_ACTION_ENQUEUE_PACK_STR
        res = struct.unpack(fmt, buffer(buf))

        eq_(self.type_['val'], res[0])
        eq_(self.len_['val'], res[1])
        eq_(self.port['val'], res[2])
        eq_(self.queue_id['val'], res[3])


class TestNXActionResubmit(unittest.TestCase):
    """ Test case for ofproto_v1_0_parser.NXActionResubmit
    """

    # NX_ACTION_RESUBMIT_PACK_STR
    # '!HHIHHB3x'...type, len, vendor, subtype, in_port, table, zfill
    type_ = {'buf': '\xff\xff', 'val': ofproto_v1_0.OFPAT_VENDOR}
    len_ = {'buf': '\x00\x10', 'val': ofproto_v1_0.NX_ACTION_RESUBMIT_SIZE}
    vendor = {'buf': '\x00\x00\x23\x20', 'val': 8992}
    subtype = {'buf': '\x00\x01', 'val': 1}
    in_port = {'buf': '\x0a\x4c', 'val': 2636}
    table = {'buf': '\x52', 'val': 82}
    zfill = '\x00' * 3

    buf = type_['buf'] \
        + len_['buf'] \
        + vendor['buf'] \
        + subtype['buf'] \
        + in_port['buf'] \
        + table['buf'] \
        + zfill

    c = NXActionResubmit(in_port['val'])

    def setUp(self):
        pass

    def tearDown(self):
        pass

    def test_init(self):
        eq_(self.type_['val'], self.c.type)
        eq_(self.len_['val'], self.c.len)
        eq_(self.vendor['val'], self.c.vendor)
        eq_(self.subtype['val'], self.c.subtype)
        eq_(self.in_port['val'], self.c.in_port)

    def test_parser(self):
        res = self.c.parser(self.buf, 0)

        eq_(self.in_port['val'], res.in_port)

    def test_serialize(self):
        buf = bytearray()
        self.c.serialize(buf, 0)

        fmt = ofproto_v1_0.NX_ACTION_RESUBMIT_PACK_STR
        res = struct.unpack(fmt, buffer(buf))

        eq_(self.type_['val'], res[0])
        eq_(self.len_['val'], res[1])
        eq_(self.vendor['val'], res[2])
        eq_(self.subtype['val'], res[3])
        eq_(self.in_port['val'], res[4])


class TestNXActionResubmitTable(unittest.TestCase):
    """ Test case for ofproto_v1_0_parser.NXActionResubmitTable
    """

    # NX_ACTION_RESUBMIT_PACK_STR
    # '!HHIHHB3x'...type, len, vendor, subtype, in_port, table, zfill
    type_ = {'buf': '\xff\xff', 'val': ofproto_v1_0.OFPAT_VENDOR}
    len_ = {'buf': '\x00\x10', 'val': ofproto_v1_0.NX_ACTION_RESUBMIT_SIZE}
    vendor = {'buf': '\x00\x00\x23\x20', 'val': 8992}
    subtype = {'buf': '\x00\x0e', 'val': 14}
    in_port = {'buf': '\x0a\x4c', 'val': 2636}
    table = {'buf': '\x52', 'val': 82}
    zfill = '\x00' * 3

    buf = type_['buf'] \
        + len_['buf'] \
        + vendor['buf'] \
        + subtype['buf'] \
        + in_port['buf'] \
        + table['buf'] \
        + zfill

    c = NXActionResubmitTable(in_port['val'], table['val'])

    def setUp(self):
        pass

    def tearDown(self):
        pass

    def test_init(self):
        eq_(self.type_['val'], self.c.type)
        eq_(self.len_['val'], self.c.len)
        eq_(self.vendor['val'], self.c.vendor)
        eq_(self.subtype['val'], self.c.subtype)
        eq_(self.in_port['val'], self.c.in_port)

    def test_parser(self):
        res = self.c.parser(self.buf, 0)

        eq_(self.in_port['val'], res.in_port)
        eq_(self.table['val'], res.table)

    def test_serialize(self):
        buf = bytearray()
        self.c.serialize(buf, 0)

        fmt = ofproto_v1_0.NX_ACTION_RESUBMIT_PACK_STR
        res = struct.unpack(fmt, buffer(buf))

        eq_(self.type_['val'], res[0])
        eq_(self.len_['val'], res[1])
        eq_(self.vendor['val'], res[2])
        eq_(self.subtype['val'], res[3])
        eq_(self.in_port['val'], res[4])


class TestNXActionSetTunnel(unittest.TestCase):
    """ Test case for ofproto_v1_0_parser.NXActionSetTunnel
    """

    # NX_ACTION_SET_TUNNEL_PACK_STR
    # '!HHIH2xI'...type, len, vendor, subtype, zfill, tun_id
    type_ = {'buf': '\xff\xff', 'val': ofproto_v1_0.OFPAT_VENDOR}
    len_ = {'buf': '\x00\x10', 'val': ofproto_v1_0.NX_ACTION_SET_TUNNEL_SIZE}
    vendor = {'buf': '\x00\x00\x23\x20', 'val': 8992}
    subtype = {'buf': '\x00\x02', 'val': 2}
    zfill = '\x00' * 2
    tun_id = {'buf': '\x01\x6f\x01\xd0', 'val': 24052176}

    buf = type_['buf'] \
        + len_['buf'] \
        + vendor['buf'] \
        + subtype['buf'] \
        + zfill \
        + tun_id['buf']

    c = NXActionSetTunnel(tun_id['val'])

    def setUp(self):
        pass

    def tearDown(self):
        pass

    def test_init(self):
        eq_(self.type_['val'], self.c.type)
        eq_(self.len_['val'], self.c.len)
        eq_(self.vendor['val'], self.c.vendor)
        eq_(self.subtype['val'], self.c.subtype)
        eq_(self.tun_id['val'], self.c.tun_id)

    def test_parser(self):
        res = self.c.parser(self.buf, 0)
        eq_(self.tun_id['val'], res.tun_id)

    def test_serialize(self):
        buf = bytearray()
        self.c.serialize(buf, 0)

        fmt = ofproto_v1_0.NX_ACTION_SET_TUNNEL_PACK_STR
        res = struct.unpack(fmt, buffer(buf))

        eq_(self.type_['val'], res[0])
        eq_(self.len_['val'], res[1])
        eq_(self.vendor['val'], res[2])
        eq_(self.subtype['val'], res[3])
        eq_(self.tun_id['val'], res[4])


class TestNXActionSetQueue(unittest.TestCase):
    """ Test case for ofproto_v1_0_parser.NXActionSetQueue
    """

    # NX_ACTION_SET_QUEUE_PACK_STR
    # '!HHIH2xI'...type, len, vendor, subtype, zfill, queue_id
    type_ = {'buf': '\xff\xff', 'val': ofproto_v1_0.OFPAT_VENDOR}
    len_ = {'buf': '\x00\x10', 'val': ofproto_v1_0.NX_ACTION_SET_TUNNEL_SIZE}
    vendor = {'buf': '\x00\x00\x23\x20', 'val': ofproto_v1_0.NX_VENDOR_ID}
    subtype = {'buf': '\x00\x04', 'val': ofproto_v1_0.NXAST_SET_QUEUE}
    zfill = '\x00' * 2
    queue_id = {'buf': '\xde\xbe\xc5\x18', 'val': 3737044248}

    buf = type_['buf'] \
        + len_['buf'] \
        + vendor['buf'] \
        + subtype['buf'] \
        + zfill \
        + queue_id['buf']

    c = NXActionSetQueue(queue_id['val'])

    def setUp(self):
        pass

    def tearDown(self):
        pass

    def test_init(self):
        eq_(self.type_['val'], self.c.type)
        eq_(self.len_['val'], self.c.len)
        eq_(self.vendor['val'], self.c.vendor)
        eq_(self.subtype['val'], self.c.subtype)
        eq_(self.queue_id['val'], self.c.queue_id)

    def test_parser(self):
        res = self.c.parser(self.buf, 0)
        eq_(self.queue_id['val'], res.queue_id)

    def test_serialize(self):
        buf = bytearray()
        self.c.serialize(buf, 0)

        fmt = ofproto_v1_0.NX_ACTION_SET_QUEUE_PACK_STR
        res = struct.unpack(fmt, buffer(buf))

        eq_(self.type_['val'], res[0])
        eq_(self.len_['val'], res[1])
        eq_(self.vendor['val'], res[2])
        eq_(self.subtype['val'], res[3])
        eq_(self.queue_id['val'], res[4])


class TestNXActionPopQueue(unittest.TestCase):
    """ Test case for ofproto_v1_0_parser.NXActionPopQueue
    """

    # NX_ACTION_POP_QUEUE_PACK_STR
    # '!HHIH6x'...type, len, vendor, subtype, zfill
    type_ = {'buf': '\xff\xff', 'val': ofproto_v1_0.OFPAT_VENDOR}
    len_ = {'buf': '\x00\x10', 'val': ofproto_v1_0.NX_ACTION_SET_TUNNEL_SIZE}
    vendor = {'buf': '\x00\x00\x23\x20', 'val': ofproto_v1_0.NX_VENDOR_ID}
    subtype = {'buf': '\x00\x05', 'val': ofproto_v1_0.NXAST_POP_QUEUE}
    zfill = '\x00' * 6

    buf = type_['buf'] \
        + len_['buf'] \
        + vendor['buf'] \
        + subtype['buf'] \
        + zfill

    c = NXActionPopQueue()

    def setUp(self):
        pass

    def tearDown(self):
        pass

    def test_init(self):
        eq_(self.type_['val'], self.c.type)
        eq_(self.len_['val'], self.c.len)
        eq_(self.vendor['val'], self.c.vendor)
        eq_(self.subtype['val'], self.c.subtype)

    def test_parser(self):
        res = self.c.parser(self.buf, 0)
        eq_(self.type_['val'], res.type)
        eq_(self.len_['val'], res.len)
        eq_(self.vendor['val'], res.vendor)
        eq_(self.subtype['val'], res.subtype)

    def test_serialize(self):
        buf = bytearray()
        self.c.serialize(buf, 0)

        fmt = ofproto_v1_0.NX_ACTION_POP_QUEUE_PACK_STR
        res = struct.unpack(fmt, buffer(buf))

        eq_(self.type_['val'], res[0])
        eq_(self.len_['val'], res[1])
        eq_(self.vendor['val'], res[2])
        eq_(self.subtype['val'], res[3])


class TestNXActionRegMove(unittest.TestCase):
    """ Test case for ofproto_v1_0_parser.NXActionRegMove
    """

    # NX_ACTION_REG_MOVE_PACK_STR
    # '!HHIHHHHII'...type_, len_, vendor, subtype, n_bits,
    #                src_ofs, dst_ofs, src, dst
    type_ = {'buf': '\xff\xff', 'val': ofproto_v1_0.OFPAT_VENDOR}
    len_ = {'buf': '\x00\x18', 'val': ofproto_v1_0.NX_ACTION_REG_MOVE_SIZE}
    vendor = {'buf': '\x00\x00\x23\x20', 'val': ofproto_v1_0.NX_VENDOR_ID}
    subtype = {'buf': '\x00\x06', 'val': ofproto_v1_0.NXAST_REG_MOVE}
    n_bits = {'buf': '\x3d\x98', 'val': 15768}
    src_ofs = {'buf': '\xf3\xa3', 'val': 62371}
    dst_ofs = {'buf': '\xdc\x67', 'val': 56423}
    src = {'buf': '\x15\x68\x60\xfd', 'val': 359162109}
    dst = {'buf': '\x9f\x9f\x88\x26', 'val': 2678032422}

    buf = type_['buf'] \
        + len_['buf'] \
        + vendor['buf'] \
        + subtype['buf'] \
        + n_bits['buf'] \
        + src_ofs['buf'] \
        + dst_ofs['buf'] \
        + src['buf'] \
        + dst['buf']

    c = NXActionRegMove(n_bits['val'],
                        src_ofs['val'],
                        dst_ofs['val'],
                        src['val'],
                        dst['val'])

    def setUp(self):
        pass

    def tearDown(self):
        pass

    def test_init(self):
        eq_(self.type_['val'], self.c.type)
        eq_(self.len_['val'], self.c.len)
        eq_(self.vendor['val'], self.c.vendor)
        eq_(self.subtype['val'], self.c.subtype)
        eq_(self.n_bits['val'], self.c.n_bits)
        eq_(self.src_ofs['val'], self.c.src_ofs)
        eq_(self.dst_ofs['val'], self.c.dst_ofs)
        eq_(self.src['val'], self.c.src)
        eq_(self.dst['val'], self.c.dst)

    def test_parser(self):
        res = self.c.parser(self.buf, 0)
        eq_(self.n_bits['val'], res.n_bits)
        eq_(self.src_ofs['val'], res.src_ofs)
        eq_(self.dst_ofs['val'], res.dst_ofs)
        eq_(self.src['val'], res.src)
        eq_(self.dst['val'], res.dst)

    def test_serialize(self):
        buf = bytearray()
        self.c.serialize(buf, 0)

        fmt = ofproto_v1_0.NX_ACTION_REG_MOVE_PACK_STR
        res = struct.unpack(fmt, buffer(buf))

        eq_(self.type_['val'], res[0])
        eq_(self.len_['val'], res[1])
        eq_(self.vendor['val'], res[2])
        eq_(self.subtype['val'], res[3])
        eq_(self.n_bits['val'], res[4])
        eq_(self.src_ofs['val'], res[5])
        eq_(self.dst_ofs['val'], res[6])
        eq_(self.src['val'], res[7])
        eq_(self.dst['val'], res[8])


class TestNXActionRegLoad(unittest.TestCase):
    """ Test case for ofproto_v1_0_parser.NXActionRegLoad
    """

    # NX_ACTION_REG_LOAD_PACK_STR
    # '!HHIHHIQ'...type_, len_, vendor, subtype,
    #              ofs_nbits, dst, value
    type_ = {'buf': '\xff\xff', 'val': ofproto_v1_0.OFPAT_VENDOR}
    len_ = {'buf': '\x00\x18', 'val': ofproto_v1_0.NX_ACTION_REG_MOVE_SIZE}
    vendor = {'buf': '\x00\x00\x23\x20', 'val': ofproto_v1_0.NX_VENDOR_ID}
    subtype = {'buf': '\x00\x07', 'val': ofproto_v1_0.NXAST_REG_LOAD}
    ofs_nbits = {'buf': '\x3d\x98',  'val': 15768}
    dst = {'buf': '\x9f\x9f\x88\x26',  'val': 2678032422}
    value = {'buf': '\x33\x51\xcd\x43\x25\x28\x18\x99',
             'val': 3697962457317775513}

    buf = type_['buf'] \
        + len_['buf'] \
        + vendor['buf'] \
        + subtype['buf'] \
        + ofs_nbits['buf'] \
        + dst['buf'] \
        + value['buf']

    c = NXActionRegLoad(ofs_nbits['val'],
                        dst['val'],
                        value['val'])

    def setUp(self):
        pass

    def tearDown(self):
        pass

    def test_init(self):
        eq_(self.type_['val'], self.c.type)
        eq_(self.len_['val'], self.c.len)
        eq_(self.vendor['val'], self.c.vendor)
        eq_(self.subtype['val'], self.c.subtype)
        eq_(self.ofs_nbits['val'], self.c.ofs_nbits)
        eq_(self.dst['val'], self.c.dst)
        eq_(self.value['val'], self.c.value)

    def test_parser(self):
        res = self.c.parser(self.buf, 0)
        eq_(self.ofs_nbits['val'], res.ofs_nbits)
        eq_(self.dst['val'], res.dst)
        eq_(self.value['val'], res.value)

    def test_serialize(self):
        buf = bytearray()
        self.c.serialize(buf, 0)

        fmt = ofproto_v1_0.NX_ACTION_REG_LOAD_PACK_STR
        res = struct.unpack(fmt, buffer(buf))

        eq_(self.type_['val'], res[0])
        eq_(self.len_['val'], res[1])
        eq_(self.vendor['val'], res[2])
        eq_(self.subtype['val'], res[3])
        eq_(self.ofs_nbits['val'], res[4])
        eq_(self.dst['val'], res[5])
        eq_(self.value['val'], res[6])


class TestNXActionSetTunnel64(unittest.TestCase):
    """ Test case for ofproto_v1_0_parser.NXActionSetTunnel64
    """

    # NX_ACTION_SET_TUNNEL64_PACK_STR
    # '!HHIH6xQ'...type, len, vendor, subtype, zfill, tun_id
    type_ = {'buf': '\xff\xff', 'val': ofproto_v1_0.OFPAT_VENDOR}
    len_ = {'buf': '\x00\x18', 'val': ofproto_v1_0.NX_ACTION_SET_TUNNEL64_SIZE}
    vendor = {'buf': '\x00\x00\x23\x20', 'val': ofproto_v1_0.NX_VENDOR_ID}
    subtype = {'buf': '\x00\x09', 'val': ofproto_v1_0.NXAST_SET_TUNNEL64}
    zfill = '\x00' * 6
    tun_id = {'buf': '\x6e\x01\xa6\xea\x7e\x36\x1d\xd9',
              'val': 7926800345218817497}

    buf = type_['buf'] \
        + len_['buf'] \
        + vendor['buf'] \
        + subtype['buf'] \
        + zfill \
        + tun_id['buf']

    c = NXActionSetTunnel64(tun_id['val'])

    def setUp(self):
        pass

    def tearDown(self):
        pass

    def test_init(self):
        eq_(self.type_['val'], self.c.type)
        eq_(self.len_['val'], self.c.len)
        eq_(self.vendor['val'], self.c.vendor)
        eq_(self.subtype['val'], self.c.subtype)
        eq_(self.tun_id['val'], self.c.tun_id)

    def test_parser(self):
        res = self.c.parser(self.buf, 0)
        eq_(self.tun_id['val'], self.c.tun_id)

    def test_serialize(self):
        buf = bytearray()
        self.c.serialize(buf, 0)

        fmt = ofproto_v1_0.NX_ACTION_SET_TUNNEL64_PACK_STR
        res = struct.unpack(fmt, buffer(buf))

        eq_(self.type_['val'], res[0])
        eq_(self.len_['val'], res[1])
        eq_(self.vendor['val'], res[2])
        eq_(self.subtype['val'], res[3])
        eq_(self.tun_id['val'], res[4])


class TestNXActionMultipath(unittest.TestCase):
    """ Test case for ofproto_v1_0_parser.NXActionMultipath
    """

    # NX_ACTION_MULTIPATH_PACK_STR
    # '!HHIHHH2xHHI2xHI'...type, len, vendor, subtype, fields, basis, zfill
    #                      algorithm, max_link, arg, zfill, ofs_nbits, dst
    type_ = {'buf': '\xff\xff', 'val': ofproto_v1_0.OFPAT_VENDOR}
    len_ = {'buf': '\x00\x20', 'val': ofproto_v1_0.NX_ACTION_MULTIPATH_SIZE}
    vendor = {'buf': '\x00\x00\x23\x20', 'val': ofproto_v1_0.NX_VENDOR_ID}
    subtype = {'buf': '\x00\x0a', 'val': ofproto_v1_0.NXAST_MULTIPATH}
    fields = {'buf': '\x6d\xf5', 'val': 28149}
    basis = {'buf': '\x7c\x0a', 'val': 31754}
    zfill0 = '\x00' * 2
    algorithm = {'buf': '\x82\x1d', 'val': 33309}
    max_link = {'buf': '\x06\x2b', 'val': 1579}
    arg = {'buf': '\x18\x79\x41\xc8', 'val': 410599880}
    zfill1 = '\x00' * 2
    ofs_nbits = {'buf': '\xa9\x9a', 'val': 43418}
    dst = {'buf': '\xb9\x2f\x16\x64', 'val': 3106870884}

    buf = type_['buf'] \
        + len_['buf'] \
        + vendor['buf'] \
        + subtype['buf'] \
        + fields['buf'] \
        + basis['buf'] \
        + zfill0 \
        + algorithm['buf'] \
        + max_link['buf'] \
        + arg['buf'] \
        + zfill1 \
        + ofs_nbits['buf'] \
        + dst['buf']

    c = NXActionMultipath(fields['val'],
                          basis['val'],
                          algorithm['val'],
                          max_link['val'],
                          arg['val'],
                          ofs_nbits['val'],
                          dst['val'])

    def setUp(self):
        pass

    def tearDown(self):
        pass

    def test_init(self):
        eq_(self.fields['val'], self.c.fields)
        eq_(self.basis['val'], self.c.basis)
        eq_(self.algorithm['val'], self.c.algorithm)
        eq_(self.max_link['val'], self.c.max_link)
        eq_(self.arg['val'], self.c.arg)
        eq_(self.ofs_nbits['val'], self.c.ofs_nbits)
        eq_(self.dst['val'], self.c.dst)

    def test_parser(self):
        res = self.c.parser(self.buf, 0)

        eq_(self.fields['val'], res.fields)
        eq_(self.basis['val'], res.basis)
        eq_(self.algorithm['val'], res.algorithm)
        eq_(self.max_link['val'], res.max_link)
        eq_(self.arg['val'], res.arg)
        eq_(self.ofs_nbits['val'], res.ofs_nbits)
        eq_(self.dst['val'], res.dst)

    def test_serialize(self):
        buf = bytearray()
        self.c.serialize(buf, 0)

        fmt = ofproto_v1_0.NX_ACTION_MULTIPATH_PACK_STR
        res = struct.unpack(fmt, buffer(buf))

        eq_(self.type_['val'], res[0])
        eq_(self.len_['val'], res[1])
        eq_(self.vendor['val'], res[2])
        eq_(self.subtype['val'], res[3])
        eq_(self.fields['val'], res[4])
        eq_(self.basis['val'], res[5])
        eq_(self.algorithm['val'], res[6])
        eq_(self.max_link['val'], res[7])
        eq_(self.arg['val'], res[8])
        eq_(self.ofs_nbits['val'], res[9])
        eq_(self.dst['val'], res[10])


class TestNXActionBundle(unittest.TestCase):
    """ Test case for ofproto_v1_0_parser.NXActionBundle
    """

    # NX_ACTION_BUNDLE_PACK_STR
    # '!HHIHHHHIHHI4x'...type, len, vendor, subtype, algorithm,
    #                    fields, basis, slave_type, n_slaves,
    #                    ofs_nbits, dst, zfill
    type_ = {'buf': '\xff\xff', 'val': ofproto_v1_0.OFPAT_VENDOR}
    len_ = {'buf': '\x00\x20', 'val': ofproto_v1_0.NX_ACTION_BUNDLE_SIZE}
    vendor = {'buf': '\x00\x00\x23\x20', 'val': ofproto_v1_0.NX_VENDOR_ID}
    subtype = {'buf': '\x00\x0c', 'val': ofproto_v1_0.NXAST_BUNDLE}
    algorithm = {'buf': '\x51\xa7', 'val': 20903}
    fields = {'buf': '\xf8\xef', 'val': 63727}
    basis = {'buf': '\xfd\x6f', 'val': 64879}
    slave_type = {'buf': '\x7c\x51\x0f\xe0', 'val': 2085687264}
    n_slaves = {'buf': '\x00\x02', 'val': 2}
    ofs_nbits = {'buf': '\xec\xf7', 'val': 60663}
    dst = {'buf': '\x50\x7c\x75\xfe', 'val': 1350333950}
    zfill = '\x00' * 4

    slaves_buf = ('\x00\x01', '\x00\x02')
    slaves_val = (1, 2)

    _len = len_['val'] + len(slaves_val) * 2
    _len += (_len % 8)

    buf = type_['buf'] \
        + len_['buf'] \
        + vendor['buf'] \
        + subtype['buf'] \
        + algorithm['buf'] \
        + fields['buf'] \
        + basis['buf'] \
        + slave_type['buf'] \
        + n_slaves['buf'] \
        + ofs_nbits['buf'] \
        + dst['buf'] \
        + zfill \
        + slaves_buf[0] \
        + slaves_buf[1]

    c = NXActionBundle(algorithm['val'],
                       fields['val'],
                       basis['val'],
                       slave_type['val'],
                       n_slaves['val'],
                       ofs_nbits['val'],
                       dst['val'],
                       slaves_val)

    def setUp(self):
        pass

    def tearDown(self):
        pass

    def test_init(self):
        eq_(self.type_['val'], self.c.type)
        eq_(self._len, self.c.len)
        eq_(self.vendor['val'], self.c.vendor)
        eq_(self.subtype['val'], self.c.subtype)
        eq_(self.algorithm['val'], self.c.algorithm)
        eq_(self.fields['val'], self.c.fields)
        eq_(self.basis['val'], self.c.basis)
        eq_(self.slave_type['val'], self.c.slave_type)
        eq_(self.n_slaves['val'], self.c.n_slaves)
        eq_(self.ofs_nbits['val'], self.c.ofs_nbits)
        eq_(self.dst['val'], self.c.dst)

        # slaves
        slaves = self.c.slaves
        eq_(self.slaves_val[0], slaves[0])
        eq_(self.slaves_val[1], slaves[1])

    def test_parser(self):
        res = self.c.parser(self.buf, 0)

        eq_(self.type_['val'], res.type)
        eq_(self._len, res.len)
        eq_(self.vendor['val'], res.vendor)
        eq_(self.subtype['val'], res.subtype)
        eq_(self.algorithm['val'], res.algorithm)
        eq_(self.fields['val'], res.fields)
        eq_(self.basis['val'], res.basis)
        eq_(self.slave_type['val'], res.slave_type)
        eq_(self.n_slaves['val'], res.n_slaves)
        eq_(self.ofs_nbits['val'], res.ofs_nbits)
        eq_(self.dst['val'], res.dst)

        # slaves
        slaves = res.slaves
        eq_(self.slaves_val[0], slaves[0])
        eq_(self.slaves_val[1], slaves[1])

    def test_serialize(self):
        buf = bytearray()
        self.c.serialize(buf, 0)

        fmt = '!' \
            + ofproto_v1_0.NX_ACTION_BUNDLE_PACK_STR.replace('!', '') \
            + 'HH4x'

        res = struct.unpack(fmt, buffer(buf))

        eq_(self.type_['val'], res[0])
        eq_(self._len, res[1])
        eq_(self.vendor['val'], res[2])
        eq_(self.subtype['val'], res[3])
        eq_(self.algorithm['val'], res[4])
        eq_(self.fields['val'], res[5])
        eq_(self.basis['val'], res[6])
        eq_(self.slave_type['val'], res[7])
        eq_(self.n_slaves['val'], res[8])
        eq_(self.ofs_nbits['val'], res[9])
        eq_(self.dst['val'], res[10])


class TestNXActionBundleLoad(unittest.TestCase):
    """ Test case for ofproto_v1_0_parser.NXActionBundleLoad
    """

    # NX_ACTION_BUNDLE_PACK_STR
    # '!HHIHHHHIHHI4x'...type, len, vendor, subtype, algorithm,
    #                    fields, basis, slave_type, n_slaves,
    #                    ofs_nbits, dst, zfill
    type_ = {'buf': '\xff\xff', 'val': ofproto_v1_0.OFPAT_VENDOR}
    len_ = {'buf': '\x00\x20', 'val': ofproto_v1_0.NX_ACTION_BUNDLE_SIZE}
    vendor = {'buf': '\x00\x00\x23\x20', 'val': ofproto_v1_0.NX_VENDOR_ID}
    subtype = {'buf': '\x00\x0d', 'val': ofproto_v1_0.NXAST_BUNDLE_LOAD}
    algorithm = {'buf': '\x83\x15', 'val': 33557}
    fields = {'buf': '\xc2\x7a', 'val': 49786}
    basis = {'buf': '\x86\x18', 'val': 34328}
    slave_type = {'buf': '\x18\x42\x0b\x55', 'val': 406981461}
    n_slaves = {'buf': '\x00\x02', 'val': 2}
    ofs_nbits = {'buf': '\xd2\x9d', 'val': 53917}
    dst = {'buf': '\x37\xfe\xb3\x60', 'val': 939438944}
    zfill = '\x00' * 4

    slaves_buf = ('\x00\x01', '\x00\x02')
    slaves_val = (1, 2)

    _len = len_['val'] + len(slaves_val) * 2
    _len += (_len % 8)

    buf = type_['buf'] \
        + len_['buf'] \
        + vendor['buf'] \
        + subtype['buf'] \
        + algorithm['buf'] \
        + fields['buf'] \
        + basis['buf'] \
        + slave_type['buf'] \
        + n_slaves['buf'] \
        + ofs_nbits['buf'] \
        + dst['buf'] \
        + zfill \
        + slaves_buf[0] \
        + slaves_buf[1]

    c = NXActionBundleLoad(algorithm['val'],
                           fields['val'],
                           basis['val'],
                           slave_type['val'],
                           n_slaves['val'],
                           ofs_nbits['val'],
                           dst['val'],
                           slaves_val)

    def setUp(self):
        pass

    def tearDown(self):
        pass

    def test_init(self):
        eq_(self.type_['val'], self.c.type)
        eq_(self._len, self.c.len)
        eq_(self.vendor['val'], self.c.vendor)
        eq_(self.subtype['val'], self.c.subtype)
        eq_(self.algorithm['val'], self.c.algorithm)
        eq_(self.fields['val'], self.c.fields)
        eq_(self.basis['val'], self.c.basis)
        eq_(self.slave_type['val'], self.c.slave_type)
        eq_(self.n_slaves['val'], self.c.n_slaves)
        eq_(self.ofs_nbits['val'], self.c.ofs_nbits)
        eq_(self.dst['val'], self.c.dst)

        # slaves
        slaves = self.c.slaves
        eq_(self.slaves_val[0], slaves[0])
        eq_(self.slaves_val[1], slaves[1])

    def test_parser(self):
        res = self.c.parser(self.buf, 0)

        eq_(self.type_['val'], res.type)
        eq_(self._len, res.len)
        eq_(self.vendor['val'], res.vendor)
        eq_(self.subtype['val'], res.subtype)
        eq_(self.algorithm['val'], res.algorithm)
        eq_(self.fields['val'], res.fields)
        eq_(self.basis['val'], res.basis)
        eq_(self.slave_type['val'], res.slave_type)
        eq_(self.n_slaves['val'], res.n_slaves)
        eq_(self.ofs_nbits['val'], res.ofs_nbits)
        eq_(self.dst['val'], res.dst)

        # slaves
        slaves = res.slaves
        eq_(self.slaves_val[0], slaves[0])
        eq_(self.slaves_val[1], slaves[1])

    def test_serialize(self):
        buf = bytearray()
        self.c.serialize(buf, 0)

        fmt = '!' \
            + ofproto_v1_0.NX_ACTION_BUNDLE_PACK_STR.replace('!', '') \
            + 'HH4x'

        res = struct.unpack(fmt, buffer(buf))

        eq_(self.type_['val'], res[0])
        eq_(self._len, res[1])
        eq_(self.vendor['val'], res[2])
        eq_(self.subtype['val'], res[3])
        eq_(self.algorithm['val'], res[4])
        eq_(self.fields['val'], res[5])
        eq_(self.basis['val'], res[6])
        eq_(self.slave_type['val'], res[7])
        eq_(self.n_slaves['val'], res[8])
        eq_(self.ofs_nbits['val'], res[9])
        eq_(self.dst['val'], res[10])


class TestNXActionAutopath(unittest.TestCase):
    """ Test case for ofproto_v1_0_parser.NXActionAutopath
    """

    # NX_ACTION_AUTOPATH_PACK_STR
    # '!HHIHHII4x'...type, len, vendor, subtype, ofs_nbits,
    #                dst, id_, zfill
    type_ = {'buf': '\xff\xff', 'val': ofproto_v1_0.OFPAT_VENDOR}
    len_ = {'buf': '\x00\x20', 'val': ofproto_v1_0.NX_ACTION_OUTPUT_REG_SIZE}
    vendor = {'buf': '\x00\x00\x23\x20', 'val': ofproto_v1_0.NX_VENDOR_ID}
    subtype = {'buf': '\x00\x0b', 'val': ofproto_v1_0.NXAST_AUTOPATH}
    ofs_nbits = {'buf': '\xfe\x78', 'val': 65144}
    dst = {'buf': '\xf8\x55\x74\x95', 'val': 4166349973}
    id_ = {'buf': '\x02\x2d\x37\xed', 'val': 36517869}
    zfill = '\x00' * 4

    buf = type_['buf'] \
        + len_['buf'] \
        + vendor['buf'] \
        + subtype['buf'] \
        + ofs_nbits['buf'] \
        + dst['buf'] \
        + id_['buf'] \
        + zfill

    c = NXActionAutopath(ofs_nbits['val'],
                         dst['val'],
                         id_['val'])

    def setUp(self):
        pass

    def tearDown(self):
        pass

    def test_init(self):
        eq_(self.type_['val'], self.c.type)
        eq_(self.len_['val'], self.c.len)
        eq_(self.vendor['val'], self.c.vendor)
        eq_(self.subtype['val'], self.c.subtype)
        eq_(self.ofs_nbits['val'], self.c.ofs_nbits)
        eq_(self.dst['val'], self.c.dst)
        eq_(self.id_['val'], self.c.id)

    def test_parser(self):
        res = self.c.parser(self.buf, 0)

        eq_(self.type_['val'], res.type)
        eq_(self.len_['val'], res.len)
        eq_(self.vendor['val'], res.vendor)
        eq_(self.subtype['val'], res.subtype)
        eq_(self.ofs_nbits['val'], res.ofs_nbits)
        eq_(self.dst['val'], res.dst)
        eq_(self.id_['val'], res.id)

    def test_serialize(self):
        buf = bytearray()
        self.c.serialize(buf, 0)

        fmt = ofproto_v1_0.NX_ACTION_AUTOPATH_PACK_STR
        res = struct.unpack(fmt, buffer(buf))

        eq_(self.type_['val'], res[0])
        eq_(self.len_['val'], res[1])
        eq_(self.vendor['val'], res[2])
        eq_(self.subtype['val'], res[3])
        eq_(self.ofs_nbits['val'], res[4])
        eq_(self.dst['val'], res[5])
        eq_(self.id_['val'], res[6])


class TestNXActionOutputReg(unittest.TestCase):
    """ Test case for ofproto_v1_0_parser.NXActionOutputReg
    """

    # NX_ACTION_OUTPUT_REG_PACK_STR
    # '!HHIHHIH6x'...type, len, vendor, subtype, ofs_nbits,
    #                    src, max_len, zfill
    type_ = {'buf': '\xff\xff', 'val': ofproto_v1_0.OFPAT_VENDOR}
    len_ = {'buf': '\x00\x20', 'val': ofproto_v1_0.NX_ACTION_OUTPUT_REG_SIZE}
    vendor = {'buf': '\x00\x00\x23\x20', 'val': ofproto_v1_0.NX_VENDOR_ID}
    subtype = {'buf': '\x00\x0f', 'val': ofproto_v1_0.NXAST_OUTPUT_REG}
    ofs_nbits = {'buf': '\xfe\x78', 'val': 65144}
    src = {'buf': '\x5e\x3a\x04\x26', 'val': 1580860454}
    max_len = {'buf': '\x00\x08', 'val': ofproto_v1_0.OFP_ACTION_OUTPUT_SIZE}
    zfill = '\x00' * 6

    buf = type_['buf'] \
        + len_['buf'] \
        + vendor['buf'] \
        + subtype['buf'] \
        + ofs_nbits['buf'] \
        + src['buf'] \
        + max_len['buf'] \
        + zfill

    c = NXActionOutputReg(ofs_nbits['val'],
                          src['val'],
                          max_len['val'])

    def setUp(self):
        pass

    def tearDown(self):
        pass

    def test_init(self):
        eq_(self.type_['val'], self.c.type)
        eq_(self.len_['val'], self.c.len)
        eq_(self.vendor['val'], self.c.vendor)
        eq_(self.subtype['val'], self.c.subtype)
        eq_(self.ofs_nbits['val'], self.c.ofs_nbits)
        eq_(self.src['val'], self.c.src)
        eq_(self.max_len['val'], self.c.max_len)

    def test_parser(self):
        res = self.c.parser(self.buf, 0)

        eq_(self.type_['val'], res.type)
        eq_(self.len_['val'], res.len)
        eq_(self.vendor['val'], res.vendor)
        eq_(self.subtype['val'], res.subtype)
        eq_(self.ofs_nbits['val'], res.ofs_nbits)
        eq_(self.src['val'], res.src)
        eq_(self.max_len['val'], res.max_len)

    def test_serialize(self):
        buf = bytearray()
        self.c.serialize(buf, 0)

        fmt = ofproto_v1_0.NX_ACTION_OUTPUT_REG_PACK_STR
        res = struct.unpack(fmt, buffer(buf))

        eq_(self.type_['val'], res[0])
        eq_(self.len_['val'], res[1])
        eq_(self.vendor['val'], res[2])
        eq_(self.subtype['val'], res[3])
        eq_(self.ofs_nbits['val'], res[4])
        eq_(self.src['val'], res[5])
        eq_(self.max_len['val'], res[6])


class TestNXActionExit(unittest.TestCase):
    """ Test case for ofproto_v1_0_parser.NXActionExit
    """

    # NX_ACTION_HEADER_PACK_STR
    # '!HHIH'...type, len, vendor, subtype
    type_ = {'buf': '\xff\xff', 'val': ofproto_v1_0.OFPAT_VENDOR}
    len_ = {'buf': '\x00\x10', 'val': ofproto_v1_0.NX_ACTION_HEADER_SIZE}
    vendor = {'buf': '\x00\x00\x23\x20', 'val': ofproto_v1_0.NX_VENDOR_ID}
    subtype = {'buf': '\x00\x11', 'val': ofproto_v1_0.NXAST_EXIT}
    zfill = '\x00' * 6

    buf = type_['buf'] \
        + len_['buf'] \
        + vendor['buf'] \
        + subtype['buf'] \
        + zfill

    c = NXActionExit()

    def setUp(self):
        pass

    def tearDown(self):
        pass

    def test_init(self):
        eq_(self.type_['val'], self.c.type)
        eq_(self.len_['val'], self.c.len)
        eq_(self.vendor['val'], self.c.vendor)
        eq_(self.subtype['val'], self.c.subtype)

    def test_parser(self):
        res = self.c.parser(self.buf, 0)
        eq_(self.type_['val'], res.type)
        eq_(self.len_['val'], res.len)
        eq_(self.vendor['val'], res.vendor)
        eq_(self.subtype['val'], res.subtype)

    def test_serialize(self):
        buf = bytearray()
        self.c.serialize(buf, 0)

        fmt = ofproto_v1_0.NX_ACTION_HEADER_PACK_STR
        res = struct.unpack(fmt, buffer(buf))

        eq_(self.type_['val'], res[0])
        eq_(self.len_['val'], res[1])
        eq_(self.vendor['val'], res[2])
        eq_(self.subtype['val'], res[3])


class TestOFPDescStats(unittest.TestCase):
    """ Test case for ofproto_v1_0_parser.OFPDescStats
    """

    # OFP_DESC_STATS_PACK_STR
    # '!256s256s256s32s256s'...mfr_desc, hw_desc, sw_desc, serial_num, dp_desc
    mfr_desc = 'mfr_desc'.ljust(256)
    hw_desc = 'hw_desc'.ljust(256)
    sw_desc = 'sw_desc'.ljust(256)
    serial_num = 'serial_num'.ljust(32)
    dp_desc = 'dp_desc'.ljust(256)

    buf = mfr_desc \
        + hw_desc \
        + sw_desc \
        + serial_num \
        + dp_desc

    c = OFPDescStats(mfr_desc, hw_desc, sw_desc, serial_num, dp_desc)

    def setUp(self):
        pass

    def tearDown(self):
        pass

    def test_init(self):
        eq_(self.mfr_desc, self.c.mfr_desc)
        eq_(self.hw_desc, self.c.hw_desc)
        eq_(self.sw_desc, self.c.sw_desc)
        eq_(self.serial_num, self.c.serial_num)
        eq_(self.dp_desc, self.c.dp_desc)

    def test_parser(self):
        res = self.c.parser(self.buf, 0)

        eq_(self.mfr_desc, self.mfr_desc)
        eq_(self.hw_desc, self.hw_desc)
        eq_(self.sw_desc, self.sw_desc)
        eq_(self.serial_num, self.serial_num)
        eq_(self.dp_desc, self.dp_desc)


class TestOFPFlowStats(unittest.TestCase):
    """ Test case for ofproto_v1_0_parser.OFPFlowStats
    """

    # OFP_FLOW_STATS_0_PACK_STR
    # '!HBx'...length, table_id, zfill
    length = {'buf': '\x00\x58', 'val': 88}
    length_append_action = {'buf': '\x00\x60', 'val': 96}
    table_id = {'buf': '\x51', 'val': 81}
    zfill_0 = '\x00'

    # OFP_MATCH_PACK_STR
    # '!IH6s6sHBxHBB2xIIHH'...
    match = '\x97\x7c\xa6\x1e' \
        + '\x5e\xa0' \
        + '\x7a\x3e\xed\x30\x4a\x90' \
        + '\x96\x8e\x67\xbe\x2f\xe2' \
        + '\xb1\x81' \
        + '\xbe' \
        + '\x00' \
        + '\x01\xab' \
        + '\x42' \
        + '\xfe' \
        + '\x00\x00' \
        + '\xa4\x5d\x5c\x42' \
        + '\xa2\x5c\x2e\x05' \
        + '\x5a\x94' \
        + '\x64\xd4'

    # OFP_FLOW_STATS_1_PACK_STR
    # '!IIHHH6xQQQ'...duration_sec, duration_nsec, priority,
    #                 idle_timeout, hard_timeout, zfill,
    #                 cookie, packet_count, byte_count
    duration_sec = {'buf': '\x94\x19\xb3\xd2', 'val': 2484712402}
    duration_nsec = {'buf': '\xee\x66\xcf\x7c', 'val': 3999715196}
    priority = {'buf': '\xe1\xc0', 'val': 57792}
    idle_timeout = {'buf': '\x8e\x10', 'val': 36368}
    hard_timeout = {'buf': '\xd4\x99', 'val': 54425}
    zfill_1 = '\x00\x00\x00\x00\x00\x00'
    cookie = {'buf': '\x0b\x01\xe8\xe5\xf0\x84\x8a\xe0',
              'val': 793171083674290912}
    packet_count = {'buf': '\x47\x5c\xc6\x05\x28\xff\x7c\xdb',
                    'val': 5142202600015232219}
    byte_count = {'buf': '\x24\xe9\x4b\xee\xcb\x57\xd9\xc3',
                  'val': 2659740543924820419}

    # <action>_PACK_STR...type_, len_ [others...]
    type = {'buf': '\x00\x00', 'val': ofproto_v1_0.OFPAT_OUTPUT}
    len = {'buf': '\x00\x08', 'val': ofproto_v1_0.OFP_ACTION_OUTPUT_SIZE}
    port = {'buf': '\x59\x2a', 'val': 22826}
    max_len = {'buf': '\x00\x08', 'val': ofproto_v1_0.OFP_ACTION_OUTPUT_SIZE}
    action = (type, len, port, max_len)

    ACTION_TYPE = 0
    ACTION_LEN = 1
    ACTION_PORT = 2
    ACTION_MAX_LEN = 3

    c = OFPFlowStats()

    def setUp(self):
        pass

    def tearDown(self):
        pass

    def test_init(self):
        pass

    def _parser(self, action=None):
        buf = self.table_id['buf'] \
            + self.zfill_0 \
            + self.match \
            + self.duration_sec['buf'] \
            + self.duration_nsec['buf'] \
            + self.priority['buf'] \
            + self.idle_timeout['buf'] \
            + self.hard_timeout['buf'] \
            + self.zfill_1 \
            + self.cookie['buf'] \
            + self.packet_count['buf'] \
            + self.byte_count['buf']

        if not action:
            buf = self.length['buf'] + buf
        else:
            buf = self.length_append_action['buf'] + buf

            for a in self.action:
                buf = buf + a['buf']

        return self.c.parser(buf, 0)

    def test_parser(self):
        res = self._parser()

        eq_(self.length['val'], res.length)
        eq_(self.table_id['val'], res.table_id)
        eq_(self.duration_sec['val'], res.duration_sec)
        eq_(self.duration_nsec['val'], res.duration_nsec)
        eq_(self.priority['val'], res.priority)
        eq_(self.idle_timeout['val'], res.idle_timeout)
        eq_(self.hard_timeout['val'], res.hard_timeout)
        eq_(self.cookie['val'], res.cookie)
        eq_(self.packet_count['val'], res.packet_count)
        eq_(self.byte_count['val'], res.byte_count)

    def test_parser_append_actions(self):
        res = self._parser(True).actions[0]

        eq_(self.action[self.ACTION_TYPE]['val'], res.type)
        eq_(self.action[self.ACTION_LEN]['val'], res.len)
        eq_(self.action[self.ACTION_PORT]['val'], res.port)
        eq_(self.action[self.ACTION_MAX_LEN]['val'], res.max_len)


class TestOFPAggregateStats(unittest.TestCase):
    """ Test case for ofproto_v1_0_parser.OFPAggregateStats
    """

    # OFP_AGGREGATE_STATS_REPLY_PACK_STR
    # '!QQI4x'...packet_count, byte_count, flow_count, zfill
    packet_count = {'buf': '\x43\x95\x1b\xfb\x0f\xf6\xa7\xdd',
                    'val': 4869829337189623773}
    byte_count = {'buf': '\x36\xda\x2d\x80\x2a\x95\x35\xdd',
                  'val': 3952521651464517085}
    flow_count = {'buf': '\xc3\x0d\xc3\xed', 'val': 3272459245}
    zfill = '\x00' * 4

    buf = packet_count['buf'] \
        + byte_count['buf'] \
        + flow_count['buf'] \
        + zfill

    c = OFPAggregateStats(packet_count['val'],
                          byte_count['val'],
                          flow_count['val'])

    def setUp(self):
        pass

    def tearDown(self):
        pass

    def test_init(self):
        eq_(self.packet_count['val'], self.c.packet_count)
        eq_(self.byte_count['val'], self.c.byte_count)
        eq_(self.flow_count['val'], self.c.flow_count)

    def test_parser(self):

        res = self.c.parser(self.buf, 0)

        eq_(self.packet_count['val'], res.packet_count)
        eq_(self.byte_count['val'], res.byte_count)
        eq_(self.flow_count['val'], res.flow_count)


class TestOFPTableStats(unittest.TestCase):
    """ Test case for ofproto_v1_0_parser.OFPTableStats
    """

    # OFP_TABLE_STATS_PACK_STR
    # '!B3x32sIIIQQ'...table_id, zfill, name, wildcards, max_entries,
    #                  active_count, lookup_count, matched_count
    table_id = {'buf': '\x5b', 'val': 91}
    zfill = '\x00' * 3
    name = 'name'.ljust(32)
    wildcards = {'buf': '\xc5\xaf\x6e\x12', 'val': 3316608530}
    max_entries = {'buf': '\x95\x6c\x78\x4d', 'val': 2506913869}
    active_count = {'buf': '\x78\xac\xa8\x1e', 'val': 2024581150}
    lookup_count = {'buf': '\x40\x1d\x9c\x39\x19\xec\xd4\x1c',
                    'val': 4620020561814017052}
    matched_count = {'buf': '\x27\x35\x02\xb6\xc5\x5e\x17\x65',
                     'val': 2825167325263435621}

    buf = table_id['buf'] \
        + zfill \
        + name \
        + wildcards['buf'] \
        + max_entries['buf'] \
        + active_count['buf'] \
        + lookup_count['buf'] \
        + matched_count['buf']

    c = OFPTableStats(table_id['val'],
                      name,
                      wildcards['val'],
                      max_entries['val'],
                      active_count['val'],
                      lookup_count['val'],
                      matched_count['val'])

    def setUp(self):
        pass

    def tearDown(self):
        pass

    def test_init(self):
        eq_(self.table_id['val'], self.c.table_id)
        eq_(self.name, self.c.name)
        eq_(self.wildcards['val'], self.c.wildcards)
        eq_(self.max_entries['val'], self.c.max_entries)
        eq_(self.active_count['val'], self.c.active_count)
        eq_(self.lookup_count['val'], self.c.lookup_count)
        eq_(self.matched_count['val'], self.c.matched_count)

    def test_parser(self):
        res = self.c.parser(self.buf, 0)

        eq_(self.table_id['val'], res.table_id)
        eq_(self.name, res.name)
        eq_(self.wildcards['val'], res.wildcards)
        eq_(self.max_entries['val'], res.max_entries)
        eq_(self.active_count['val'], res.active_count)
        eq_(self.lookup_count['val'], res.lookup_count)
        eq_(self.matched_count['val'], res.matched_count)


class TestOFPPortStats(unittest.TestCase):
    """ Test case for ofproto_v1_0_parser.OFPPortStats
    """

    # OFP_PORT_STATS_PACK_STR
    # '!H6xQQQQQQQQQQQQ'... port_no, zfill, rx_packets, tx_packets,
    #                       rx_bytes, tx_bytes, rx_dropped, tx_dropped,
    #                       rx_errors, tx_errors, rx_frame_err,
    #                       rx_over_err, rx_crc_err, collisions
    port_no = {'buf': '\xe7\x6b', 'val': 59243}
    zfill = '\x00' * 6
    rx_packets = {'buf': '\x53\x44\x36\x61\xc4\x86\xc0\x37',
                  'val': 5999980397101236279}
    tx_packets = {'buf': '\x27\xa4\x41\xd7\xd4\x53\x9e\x42',
                  'val': 2856480458895760962}
    rx_bytes = {'buf': '\x55\xa1\x38\x60\x43\x97\x0d\x89',
                'val': 6170274950576278921}
    tx_bytes = {'buf': '\x77\xe1\xd5\x63\x18\xae\x63\xaa',
                'val': 8638420181865882538}
    rx_dropped = {'buf': '\x60\xe6\x20\x01\x24\xda\x4e\x5a',
                  'val': 6982303461569875546}
    tx_dropped = {'buf': '\x09\x2d\x5d\x71\x71\xb6\x8e\xc7',
                  'val': 661287462113808071}
    rx_errors = {'buf': '\x2f\x7e\x35\xb3\x66\x3c\x19\x0d',
                 'val': 3422231811478788365}
    tx_errors = {'buf': '\x57\x32\x08\x2f\x88\x32\x40\x6b',
                 'val': 6283093430376743019}
    rx_frame_err = {'buf': '\x0c\x28\x6f\xad\xce\x66\x6e\x8b',
                    'val': 876072919806406283}
    rx_over_err = {'buf': '\x5a\x90\x8f\x9b\xfc\x82\x2e\xa0',
                   'val': 6525873760178941600}
    rx_crc_err = {'buf': '\x73\x3a\x71\x17\xd6\x74\x69\x47',
                  'val': 8303073210207070535}
    collisions = {'buf': '\x2f\x52\x0c\x79\x96\x03\x6e\x79',
                  'val': 3409801584220270201}

    buf = port_no['buf'] \
        + zfill \
        + rx_packets['buf'] \
        + tx_packets['buf'] \
        + rx_bytes['buf'] \
        + tx_bytes['buf'] \
        + rx_dropped['buf'] \
        + tx_dropped['buf'] \
        + rx_errors['buf'] \
        + tx_errors['buf'] \
        + rx_frame_err['buf'] \
        + rx_over_err['buf'] \
        + rx_crc_err['buf'] \
        + collisions['buf']

    c = OFPPortStats(port_no['val'],
                     rx_packets['val'],
                     tx_packets['val'],
                     rx_bytes['val'],
                     tx_bytes['val'],
                     rx_dropped['val'],
                     tx_dropped['val'],
                     rx_errors['val'],
                     tx_errors['val'],
                     rx_frame_err['val'],
                     rx_over_err['val'],
                     rx_crc_err['val'],
                     collisions['val'])

    def setUp(self):
        pass

    def tearDown(self):
        pass

    def test_init(self):
        eq_(self.port_no['val'], self.c.port_no)
        eq_(self.rx_packets['val'], self.c.rx_packets)
        eq_(self.tx_packets['val'], self.c.tx_packets)
        eq_(self.rx_bytes['val'], self.c.rx_bytes)
        eq_(self.tx_bytes['val'], self.c.tx_bytes)
        eq_(self.rx_dropped['val'], self.c.rx_dropped)
        eq_(self.tx_dropped['val'], self.c.tx_dropped)
        eq_(self.rx_errors['val'], self.c.rx_errors)
        eq_(self.tx_errors['val'], self.c.tx_errors)
        eq_(self.rx_frame_err['val'], self.c.rx_frame_err)
        eq_(self.rx_over_err['val'], self.c.rx_over_err)
        eq_(self.rx_crc_err['val'], self.c.rx_crc_err)
        eq_(self.collisions['val'], self.c.collisions)

    def test_parser(self):
        res = self.c.parser(self.buf, 0)

        eq_(self.port_no['val'], res.port_no)
        eq_(self.rx_packets['val'], res.rx_packets)
        eq_(self.tx_packets['val'], res.tx_packets)
        eq_(self.rx_bytes['val'], res.rx_bytes)
        eq_(self.tx_bytes['val'], res.tx_bytes)
        eq_(self.rx_dropped['val'], res.rx_dropped)
        eq_(self.tx_dropped['val'], res.tx_dropped)
        eq_(self.rx_errors['val'], res.rx_errors)
        eq_(self.tx_errors['val'], res.tx_errors)
        eq_(self.rx_frame_err['val'], res.rx_frame_err)
        eq_(self.rx_over_err['val'], res.rx_over_err)
        eq_(self.rx_crc_err['val'], res.rx_crc_err)
        eq_(self.collisions['val'], res.collisions)


class TestOFPQueueStats(unittest.TestCase):
    """ Test case for ofproto_v1_0_parser.OFPQueueStats
    """

    # OFP_QUEUE_STATS_PACK_STR
    # '!H2xIQQQ...port_no, queue_id, tx_bytes, tx_packets, tx_errors
    port_no = {'buf': '\xe7\x6b', 'val': 59243}
    zfill = '\x00' * 2
    queue_id = {'buf': '\x2a\xa8\x7f\x32', 'val': 715685682}
    tx_bytes = {'buf': '\x77\xe1\xd5\x63\x18\xae\x63\xaa',
                'val': 8638420181865882538}
    tx_packets = {'buf': '\x27\xa4\x41\xd7\xd4\x53\x9e\x42',
                  'val': 2856480458895760962}
    tx_errors = {'buf': '\x57\x32\x08\x2f\x88\x32\x40\x6b',
                 'val': 6283093430376743019}

    c = OFPQueueStats(port_no['val'],
                      queue_id['val'],
                      tx_bytes['val'],
                      tx_packets['val'],
                      tx_errors['val'])

    buf = port_no['buf'] \
        + zfill \
        + queue_id['buf'] \
        + tx_bytes['buf'] \
        + tx_packets['buf'] \
        + tx_errors['buf']

    def setUp(self):
        pass

    def tearDown(self):
        pass

    def test_init(self):
        eq_(self.port_no['val'], self.c.port_no)
        eq_(self.queue_id['val'], self.c.queue_id)
        eq_(self.tx_bytes['val'], self.c.tx_bytes)
        eq_(self.tx_packets['val'], self.c.tx_packets)
        eq_(self.tx_errors['val'], self.c.tx_errors)

    def test_parser(self):
        res = self.c.parser(self.buf, 0)

        eq_(self.port_no['val'], res.port_no)
        eq_(self.queue_id['val'], res.queue_id)
        eq_(self.tx_bytes['val'], res.tx_bytes)
        eq_(self.tx_packets['val'], res.tx_packets)
        eq_(self.tx_errors['val'], res.tx_errors)


class TestOFPVendorStats(unittest.TestCase):
    """ Test case for ofproto_v1_0_parser.OFPVendorStats
    """

    specific_data = 'specific_data'
    specific_data_after = 'data'
    offset = specific_data.find(specific_data_after)

    c = OFPVendorStats(specific_data)

    def setUp(self):
        pass

    def tearDown(self):
        pass

    def test_init(self):
        eq_(self.specific_data, self.c.specific_data)

    def test_parser(self):
        res = self.c.parser(self.specific_data, self.offset)
        eq_(self.specific_data_after, res.specific_data)


class TestOFPQueuePropNone(unittest.TestCase):
    """ Test case for ofproto_v1_0_parser.OFPQueuePropNone
    """

    # OFP_QUEUE_PROP_HEADER_PACK_STR
    # '!HH4x'...property_, len_
    property = {'buf': '\x00\x00', 'val': ofproto_v1_0.OFPQT_NONE}
    len = {'buf': '\x00\x08', 'val': ofproto_v1_0.OFP_QUEUE_PROP_HEADER_SIZE}
    zfill = '\x00' * 4

    c = OFPQueuePropNone()

    def setUp(self):
        pass

    def tearDown(self):
        pass

    def test_init(self):
        cls = OFPQueuePropHeader._QUEUE_PROPERTIES[self.c.cls_prop_type]

        eq_(self.property['val'], self.c.cls_prop_type)
        eq_(self.property['val'], self.c.property)
        eq_(self.property['val'], cls.cls_prop_type)

        eq_(self.len['val'], self.c.cls_prop_len)
        eq_(self.len['val'], self.c.len)
        eq_(self.len['val'], cls.cls_prop_len)

    def test_parser(self):
        buf = self.property['buf'] \
            + self.len['buf'] \
            + self.zfill

        ok_(self.c.parser(buf, 0))


class TestOFPQueuePropMinRate(unittest.TestCase):
    """ Test case for ofproto_v1_0_parser.OFPQueuePropMinRate
    """

    # OFP_QUEUE_PROP_MIN_RATE_PACK_STR
    # '!H6x'...rate
    rate = {'buf': '\x00\x01', 'val': ofproto_v1_0.OFPQT_MIN_RATE}
    len = {'buf': '\x00\x10', 'val': ofproto_v1_0.OFP_QUEUE_PROP_MIN_RATE_SIZE}
    zfill = '\x00' * 6

    buf = rate['buf'] \
        + zfill

    c = OFPQueuePropMinRate(rate['val'])

    def setUp(self):
        pass

    def tearDown(self):
        pass

    def test_init(self):
        cls = OFPQueuePropHeader._QUEUE_PROPERTIES[self.c.cls_prop_type]

        eq_(self.rate['val'], self.c.cls_prop_type)
        eq_(self.rate['val'], self.c.rate)
        eq_(self.rate['val'], cls.cls_prop_type)

        eq_(self.len['val'], self.c.cls_prop_len)
        eq_(self.len['val'], cls.cls_prop_len)

    def test_parser(self):
        res = self.c.parser(self.buf, 0)
        eq_(self.rate['val'], res.rate)


class TestOFPPacketQueue(unittest.TestCase):
    """ Test case for ofproto_v1_0_parser.OFPPacketQueue
    """

    # OFP_PACKET_QUEUE_PQCK_STR
    # '!IH2x'...queue_id, len_, zfill
    queue_id = {'buf': '\x4d\x4b\x3a\xd1', 'val': 1296775889}
    len_ = {'buf': '\x00\x08',
            'val': ofproto_v1_0.OFP_QUEUE_PROP_HEADER_SIZE}
    zfill = '\x00' * 2

    buf = queue_id['buf'] \
        + len_['buf'] \
        + zfill

    c = OFPPacketQueue(queue_id['val'],
                       len_['val'])

    def setUp(self):
        pass

    def tearDown(self):
        pass

    def test_init(self):
        eq_(self.queue_id['val'], self.c.queue_id)
        eq_(self.len_['val'], self.c.len)

    def test_parser(self):
        res = self.c.parser(self.buf, 0)
        eq_(self.queue_id['val'], res.queue_id)
        eq_(self.len_['val'], res.len)

    def test_parser_append_prop(self):
        # OFP_QUEUE_PROP_HEADER_PACK_STR + OFP_QUEUE_PROP_MIN_RATE_PACK_STR
        # '!HH4xH6x'...type, len, zfill, rate, zfill
        len_ = {'buf': '\x00\x10',
                'val': ofproto_v1_0.OFP_QUEUE_PROP_MIN_RATE_SIZE}
        a_type = {'buf': '\x00\x01', 'val': ofproto_v1_0.OFPQT_MIN_RATE}
        a_len = {'buf': '\x00\x10',
                 'val': ofproto_v1_0.OFP_QUEUE_PROP_MIN_RATE_SIZE}
        a_zfill0 = '\x00' * 4
        a_rate = {'buf': '\x00\x01', 'val': ofproto_v1_0.OFPQT_MIN_RATE}
        a_zfill1 = '\x00' * 6

        buf = self.queue_id['buf'] \
            + len_['buf'] \
            + self.zfill \
            + a_type['buf'] \
            + a_len['buf'] \
            + a_zfill0 \
            + a_rate['buf'] \
            + a_zfill1

        res = self.c.parser(buf, 0)

        eq_(self.queue_id['val'], res.queue_id)
        eq_(len_['val'], res.len)

        append_cls = res.properties[0]

        eq_(a_type['val'], append_cls.property)
        eq_(a_len['val'], append_cls.len)
        eq_(a_rate['val'], append_cls.rate)


class TestOFPHello(unittest.TestCase):
    """ Test case for ofproto_v1_0_parser.OFPHello
    """

    def setUp(self):
        pass

    def tearDown(self):
        pass

    def test_init(self):
        pass

    def test_parser(self):
        version = ofproto_v1_0.OFP_VERSION
        msg_type = ofproto_v1_0.OFPT_HELLO
        msg_len = ofproto_v1_0.OFP_HEADER_SIZE
        xid = 2183948390
        data = '\x00\x01\x02\x03'

        fmt = ofproto_v1_0.OFP_HEADER_PACK_STR
        buf = struct.pack(fmt, version, msg_type, msg_len, xid) \
            + data

        res = OFPHello.parser(object, version, msg_type, msg_len, xid,
                              bytearray(buf))

        eq_(version, res.version)
        eq_(msg_type, res.msg_type)
        eq_(msg_len, res.msg_len)
        eq_(xid, res.xid)
        eq_(buffer(buf), res.buf)

    def test_serialize(self):

        class Datapath(object):
            ofproto = ofproto_v1_0
            ofproto_parser = ofproto_v1_0_parser

        c = OFPHello(Datapath)
        c.serialize()
        eq_(ofproto_v1_0.OFP_VERSION, c.version)
        eq_(ofproto_v1_0.OFPT_HELLO, c.msg_type)
        eq_(0, c.xid)


class TestOFPErrorMsg(unittest.TestCase):
    """ Test case for ofproto_v1_0_parser.OFPErrorMsg
    """

    def setUp(self):
        pass

    def tearDown(self):
        pass

    def test_init(self):
        pass

    def test_parser(self):
        version = {'buf': '\x01', 'val': ofproto_v1_0.OFP_VERSION}
        msg_type = {'buf': '\x01', 'val': ofproto_v1_0.OFPT_ERROR}
        msg_len = {'buf': '\x00\x0c',
                   'val': ofproto_v1_0.OFP_ERROR_MSG_SIZE}
        xid = {'buf': '\x87\x8b\x26\x7c', 'val': 2274043516}
        type = {'buf': '\xab\x3e', 'val': 43838}
        code = {'buf': '\x5d\x3c', 'val': 23868}
        data = 'Error Message.'

        buf = version['buf'] \
            + msg_type['buf'] \
            + msg_len['buf'] \
            + xid['buf'] \
            + type['buf'] \
            + code['buf'] \
            + data

        res = OFPErrorMsg.parser(object,
                                 version['val'],
                                 msg_type['val'],
                                 msg_len['val'],
                                 xid['val'],
                                 buf)

        eq_(version['val'], res.version)
        eq_(msg_type['val'], res.msg_type)
        eq_(msg_len['val'], res.msg_len)
        eq_(xid['val'], res.xid)
        eq_(type['val'], res.type)
        eq_(code['val'], res.code)
        eq_(data, res.data)

    def test_serialize(self):
        class Datapath(object):
            ofproto = ofproto_v1_0
            ofproto_parser = ofproto_v1_0_parser

        type = 1306
        code = 13774
        data = 'Error Message.'

        c = OFPErrorMsg(Datapath)
        c.type = type
        c.code = code
        c.data = data

        c.serialize()

        eq_(ofproto_v1_0.OFP_VERSION, c.version)
        eq_(ofproto_v1_0.OFPT_ERROR, c.msg_type)
        eq_(0, c.xid)

        fmt = '!' \
            + ofproto_v1_0.OFP_HEADER_PACK_STR.replace('!', '') \
            + ofproto_v1_0.OFP_ERROR_MSG_PACK_STR.replace('!', '') \
            + str(len(data)) + 's'

        res = struct.unpack(fmt, str(c.buf))
        eq_(ofproto_v1_0.OFP_VERSION, res[0])
        eq_(ofproto_v1_0.OFPT_ERROR, res[1])
        eq_(len(c.buf), res[2])
        eq_(0, res[3])
        eq_(type, res[4])
        eq_(code, res[5])
        eq_(data, res[6])


class TestOFPEchoRequest(unittest.TestCase):
    """ Test case for ofproto_v1_0_parser.OFPEchoRequest
    """

    def setUp(self):
        pass

    def tearDown(self):
        pass

    def test_init(self):
        pass

    def test_parser(self):
        version = {'buf': '\x01', 'val': ofproto_v1_0.OFP_VERSION}
        msg_type = {'buf': '\x02', 'val': ofproto_v1_0.OFPT_ECHO_REQUEST}
        msg_len = {'buf': '\x00\x08',
                   'val': ofproto_v1_0.OFP_HEADER_SIZE}
        xid = {'buf': '\x84\x47\xef\x3f', 'val': 2219306815}
        data = 'Request Message.'

        buf = version['buf'] \
            + msg_type['buf'] \
            + msg_len['buf'] \
            + xid['buf'] \
            + data

        res = OFPEchoRequest.parser(object,
                                    version['val'],
                                    msg_type['val'],
                                    msg_len['val'],
                                    xid['val'],
                                    buf)

        eq_(version['val'], res.version)
        eq_(msg_type['val'], res.msg_type)
        eq_(msg_len['val'], res.msg_len)
        eq_(xid['val'], res.xid)
        eq_(data, res.data)

    def test_serialize(self):
        class Datapath(object):
            ofproto = ofproto_v1_0
            ofproto_parser = ofproto_v1_0_parser

        data = 'Request Message.'

        c = OFPEchoRequest(Datapath)
        c.data = data

        c.serialize()

        eq_(ofproto_v1_0.OFP_VERSION, c.version)
        eq_(ofproto_v1_0.OFPT_ECHO_REQUEST, c.msg_type)
        eq_(0, c.xid)

        fmt = '!' \
            + ofproto_v1_0.OFP_HEADER_PACK_STR.replace('!', '') \
            + str(len(data)) + 's'

        res = struct.unpack(fmt, str(c.buf))
        eq_(ofproto_v1_0.OFP_VERSION, res[0])
        eq_(ofproto_v1_0.OFPT_ECHO_REQUEST, res[1])
        eq_(len(c.buf), res[2])
        eq_(0, res[3])
        eq_(data, res[4])


class TestOFPEchoReply(unittest.TestCase):
    """ Test case for ofproto_v1_0_parser.OFPEchoReply
    """

    def setUp(self):
        pass

    def tearDown(self):
        pass

    def test_init(self):
        pass

    def test_parser(self):
        version = {'buf': '\x01', 'val': ofproto_v1_0.OFP_VERSION}
        msg_type = {'buf': '\x03', 'val': ofproto_v1_0.OFPT_ECHO_REPLY}
        msg_len = {'buf': '\x00\x08',
                   'val': ofproto_v1_0.OFP_HEADER_SIZE}
        xid = {'buf': '\x6e\x21\x3e\x62', 'val': 1847672418}
        data = 'Reply Message.'

        buf = version['buf'] \
            + msg_type['buf'] \
            + msg_len['buf'] \
            + xid['buf'] \
            + data

        res = OFPEchoReply.parser(object,
                                  version['val'],
                                  msg_type['val'],
                                  msg_len['val'],
                                  xid['val'],
                                  buf)

        eq_(version['val'], res.version)
        eq_(msg_type['val'], res.msg_type)
        eq_(msg_len['val'], res.msg_len)
        eq_(xid['val'], res.xid)
        eq_(data, res.data)

    def test_serialize(self):
        class Datapath(object):
            ofproto = ofproto_v1_0
            ofproto_parser = ofproto_v1_0_parser

        data = 'Reply Message.'

        c = OFPEchoReply(Datapath)
        c.data = data

        c.serialize()

        eq_(ofproto_v1_0.OFP_VERSION, c.version)
        eq_(ofproto_v1_0.OFPT_ECHO_REPLY, c.msg_type)
        eq_(0, c.xid)

        fmt = '!' \
            + ofproto_v1_0.OFP_HEADER_PACK_STR.replace('!', '') \
            + str(len(data)) + 's'

        res = struct.unpack(fmt, str(c.buf))
        eq_(ofproto_v1_0.OFP_VERSION, res[0])
        eq_(ofproto_v1_0.OFPT_ECHO_REPLY, res[1])
        eq_(len(c.buf), res[2])
        eq_(0, res[3])
        eq_(data, res[4])


class TestOFPVendor(unittest.TestCase):
    """ Test case for ofproto_v1_0_parser.OFPVendor
    """

    def setUp(self):
        pass

    def tearDown(self):
        pass

    def test_init(self):
        pass

    def test_parser(self):
        version = {'buf': '\x01', 'val': ofproto_v1_0.OFP_VERSION}
        msg_type = {'buf': '\x04', 'val': ofproto_v1_0.OFPT_VENDOR}
        msg_len = {'buf': '\x00\x0c',
                   'val': ofproto_v1_0.OFP_VENDOR_HEADER_SIZE}
        xid = {'buf': '\x05\x45\xdf\x18', 'val': 88465176}
        vendor = {'buf': '\x53\xea\x25\x3e', 'val': 1407853886}
        data = 'Vendor Message.'

        buf = version['buf'] \
            + msg_type['buf'] \
            + msg_len['buf'] \
            + xid['buf'] \
            + vendor['buf'] \
            + data

        res = OFPVendor.parser(object,
                               version['val'],
                               msg_type['val'],
                               msg_len['val'],
                               xid['val'],
                               buf)

        eq_(version['val'], res.version)
        eq_(msg_type['val'], res.msg_type)
        eq_(msg_len['val'], res.msg_len)
        eq_(xid['val'], res.xid)
        eq_(vendor['val'], res.vendor)
        eq_(data, res.data)

    def test_serialize(self):
        class Datapath(object):
            ofproto = ofproto_v1_0
            ofproto_parser = ofproto_v1_0_parser

        vendor = {'buf': '\x38\x4b\xf9\x6c', 'val': 944503148}
        data = 'Reply Message.'

        c = OFPVendor(Datapath)
        c.vendor = vendor['val']
        c.data = data

        c.serialize()

        eq_(ofproto_v1_0.OFP_VERSION, c.version)
        eq_(ofproto_v1_0.OFPT_VENDOR, c.msg_type)
        eq_(0, c.xid)
        eq_(vendor['val'], c.vendor)

        fmt = '!' \
            + ofproto_v1_0.OFP_HEADER_PACK_STR.replace('!', '') \
            + ofproto_v1_0.OFP_VENDOR_HEADER_PACK_STR.replace('!', '') \
            + str(len(data)) + 's'

        res = struct.unpack(fmt, str(c.buf))
        eq_(ofproto_v1_0.OFP_VERSION, res[0])
        eq_(ofproto_v1_0.OFPT_VENDOR, res[1])
        eq_(len(c.buf), res[2])
        eq_(0, res[3])
        eq_(vendor['val'], res[4])
        eq_(data, res[5])


#class TestNXTRequest(unittest.TestCase):
class TestNiciraHeader(unittest.TestCase):
    """ Test case for ofproto_v1_0_parser.NiciraHeader
    """

    def setUp(self):
        pass

    def tearDown(self):
        pass

    def test_init(self):
        subtype = ofproto_v1_0.NXT_FLOW_MOD_TABLE_ID

        c = NiciraHeader(object, subtype)
        eq_(subtype, c.subtype)

    def test_parser(self):
        # Not used.
        pass

    def test_serialize(self):
        class Datapath(object):
            ofproto = ofproto_v1_0
            ofproto_parser = ofproto_v1_0_parser

        data = 'Reply Message.'
        subtype = ofproto_v1_0.NXT_FLOW_MOD_TABLE_ID

        c = NiciraHeader(Datapath, subtype)
        c.data = data

        c.serialize()

        eq_(ofproto_v1_0.OFP_VERSION, c.version)
        eq_(ofproto_v1_0.OFPT_VENDOR, c.msg_type)
        eq_(0, c.xid)
        eq_(ofproto_v1_0.NX_VENDOR_ID, c.vendor)

        fmt = '!' \
            + ofproto_v1_0.OFP_HEADER_PACK_STR.replace('!', '') \
            + ofproto_v1_0.NICIRA_HEADER_PACK_STR.replace('!', '') \
            + str(len(data)) + 's'

        res = struct.unpack(fmt, str(c.buf))
        eq_(ofproto_v1_0.OFP_VERSION, res[0])
        eq_(ofproto_v1_0.OFPT_VENDOR, res[1])
        eq_(len(c.buf), res[2])
        eq_(0, res[3])
        eq_(ofproto_v1_0.NX_VENDOR_ID, res[4])
        eq_(subtype, res[5])
        eq_(data, res[6])


class TestNXTSetFlowFormat(unittest.TestCase):
    """ Test case for ofproto_v1_0_parser.NXTSetFlowFormat
    """

    def setUp(self):
        pass

    def tearDown(self):
        pass

    def test_init(self):
        flow_format = {'buf': '\xdc\x6b\xf5\x24', 'val': 3698062628}

        c = NXTSetFlowFormat(object, flow_format['val'])
        eq_(flow_format['val'], c.format)

    def test_parser(self):
        # Not used.
        pass

    def test_serialize(self):
        class Datapath(object):
            ofproto = ofproto_v1_0
            ofproto_parser = ofproto_v1_0_parser

        flow_format = {'buf': '\x5a\x4e\x59\xad', 'val': 1515084205}

        c = NXTSetFlowFormat(Datapath, flow_format['val'])
        c.serialize()

        eq_(ofproto_v1_0.OFP_VERSION, c.version)
        eq_(ofproto_v1_0.OFPT_VENDOR, c.msg_type)
        eq_(0, c.xid)
        eq_(ofproto_v1_0.NX_VENDOR_ID, c.vendor)

        fmt = '!' \
            + ofproto_v1_0.OFP_HEADER_PACK_STR.replace('!', '') \
            + ofproto_v1_0.NICIRA_HEADER_PACK_STR.replace('!', '') \
            + ofproto_v1_0.NX_SET_FLOW_FORMAT_PACK_STR.replace('!', '')

        res = struct.unpack(fmt, str(c.buf))
        eq_(ofproto_v1_0.OFP_VERSION, res[0])
        eq_(ofproto_v1_0.OFPT_VENDOR, res[1])
        eq_(len(c.buf), res[2])
        eq_(0, res[3])
        eq_(ofproto_v1_0.NX_VENDOR_ID, res[4])
        eq_(ofproto_v1_0.NXT_SET_FLOW_FORMAT, res[5])
        eq_(flow_format['val'], res[6])


class TestNXTFlowMod(unittest.TestCase):
    """ Test case for ofproto_v1_0_parser.NXTFlowMod
    """

    # NX_FLOW_MOD_PACK_STR
    # '!Q4HI3H6x'...cokkie, command, idle_timeout, head_timeout,
    #               priority, buffer_id, out_port, flags, rule, zfill
    cookie = {'buf': '\x04\x56\x27\xad\xbd\x43\xd6\x83',
              'val': 312480851306993283}
    command = {'buf': '\x61\xaa', 'val': 25002}
    idle_timeout = {'buf': '\x4e\xff', 'val': 20223}
    hard_timeout = {'buf': '\x80\x16', 'val': 32790}
    priority = {'buf': '\x70\x5f', 'val': 28767}
    buffer_id = {'buf': '\x7b\x97\x3a\x09', 'val': 2073508361}
    out_port = {'buf': '\x11\x7d', 'val': 4477}
    flags = {'buf': '\x5c\xb9', 'val': 23737}
    rule = nx_match.ClsRule()
    zfill = '\x00' * 6

    port = {'buf': '\x2a\xe0', 'val': 10976}
    actions = [OFPActionOutput(port['val'])]

    def _get_obj(self, append_action=False):
        class Datapath(object):
            ofproto = ofproto_v1_0
            ofproto_parser = ofproto_v1_0_parser

        actions = None
        if append_action:
            actions = self.actions

        c = NXTFlowMod(Datapath,
                       self.cookie['val'],
                       self.command['val'],
                       self.idle_timeout['val'],
                       self.hard_timeout['val'],
                       self.priority['val'],
                       self.buffer_id['val'],
                       self.out_port['val'],
                       self.flags['val'],
                       self.rule,
                       actions)

        return c

    def setUp(self):
        pass

    def tearDown(self):
        pass

    def test_init(self):
        c = self._get_obj()

        eq_(self.cookie['val'], c.cookie)
        eq_(self.command['val'], c.command)
        eq_(self.idle_timeout['val'], c.idle_timeout)
        eq_(self.hard_timeout['val'], c.hard_timeout)
        eq_(self.priority['val'], c.priority)
        eq_(self.buffer_id['val'], c.buffer_id)
        eq_(self.out_port['val'], c.out_port)
        eq_(self.flags['val'], c.flags)
        eq_(self.rule.__hash__(), c.rule.__hash__())

    def test_init_append_actions(self):
        c = self._get_obj(True)

        action = c.actions[0]
        eq_(ofproto_v1_0.OFPAT_OUTPUT, action.type)
        eq_(ofproto_v1_0.OFP_ACTION_OUTPUT_SIZE, action.len)
        eq_(self.port['val'], action.port)

    def test_parser(self):
        # Not used.
        pass

    def test_serialize(self):
        c = self._get_obj()
        c.serialize()

        eq_(ofproto_v1_0.OFP_VERSION, c.version)
        eq_(ofproto_v1_0.OFPT_VENDOR, c.msg_type)
        eq_(0, c.xid)
        eq_(ofproto_v1_0.NX_VENDOR_ID, c.vendor)

        fmt = '!' \
            + ofproto_v1_0.OFP_HEADER_PACK_STR.replace('!', '') \
            + ofproto_v1_0.NICIRA_HEADER_PACK_STR.replace('!', '') \
            + ofproto_v1_0.NX_FLOW_MOD_PACK_STR.replace('!', '')

        res = struct.unpack(fmt, str(c.buf))
        eq_(ofproto_v1_0.OFP_VERSION, res[0])
        eq_(ofproto_v1_0.OFPT_VENDOR, res[1])
        eq_(len(c.buf), res[2])
        eq_(0, res[3])
        eq_(ofproto_v1_0.NX_VENDOR_ID, res[4])
        eq_(ofproto_v1_0.NXT_FLOW_MOD, res[5])
        eq_(self.cookie['val'], res[6])
        eq_(self.command['val'], res[7])
        eq_(self.idle_timeout['val'], res[8])
        eq_(self.hard_timeout['val'], res[9])
        eq_(self.priority['val'], res[10])
        eq_(self.buffer_id['val'], res[11])
        eq_(self.out_port['val'], res[12])
        eq_(self.flags['val'], res[13])

    def test_serialize_append_actions(self):
        c = self._get_obj(True)
        c.serialize()

        eq_(ofproto_v1_0.OFP_VERSION, c.version)
        eq_(ofproto_v1_0.OFPT_VENDOR, c.msg_type)
        eq_(0, c.xid)
        eq_(ofproto_v1_0.NX_VENDOR_ID, c.vendor)

        fmt = '!' \
            + ofproto_v1_0.OFP_HEADER_PACK_STR.replace('!', '') \
            + ofproto_v1_0.NICIRA_HEADER_PACK_STR.replace('!', '') \
            + ofproto_v1_0.NX_FLOW_MOD_PACK_STR.replace('!', '') \
            + ofproto_v1_0.OFP_ACTION_OUTPUT_PACK_STR.replace('!', '')

        res = struct.unpack(fmt, str(c.buf))
        eq_(ofproto_v1_0.OFP_VERSION, res[0])
        eq_(ofproto_v1_0.OFPT_VENDOR, res[1])
        eq_(len(c.buf), res[2])
        eq_(0, res[3])
        eq_(ofproto_v1_0.NX_VENDOR_ID, res[4])
        eq_(ofproto_v1_0.NXT_FLOW_MOD, res[5])
        eq_(self.cookie['val'], res[6])
        eq_(self.command['val'], res[7])
        eq_(self.idle_timeout['val'], res[8])
        eq_(self.hard_timeout['val'], res[9])
        eq_(self.priority['val'], res[10])
        eq_(self.buffer_id['val'], res[11])
        eq_(self.out_port['val'], res[12])
        eq_(self.flags['val'], res[13])

        # action
        eq_(0, res[14])
        eq_(ofproto_v1_0.OFPAT_OUTPUT, res[15])
        eq_(ofproto_v1_0.OFP_ACTION_OUTPUT_SIZE, res[16])
        eq_(self.port['val'], res[17])
        eq_(0xffe5, res[18])


class TestNXTRoleRequest(unittest.TestCase):
    """ Test case for ofproto_v1_0_parser.NXTRoleRequest
    """

    # NX_ROLE_PACK_STR
    # '!I'...role
    role = {'buf': '\x62\x81\x27\x61', 'val': 1652631393}

    class Datapath(object):
        ofproto = ofproto_v1_0
        ofproto_parser = ofproto_v1_0_parser

    c = NXTRoleRequest(Datapath, role['val'])

    def setUp(self):
        pass

    def tearDown(self):
        pass

    def test_init(self):
        eq_(self.role['val'], self.c.role)

    def test_parser(self):
        # Not used.
        pass

    def test_serialize(self):
        self.c.serialize()

        eq_(ofproto_v1_0.OFP_VERSION, self.c.version)
        eq_(ofproto_v1_0.OFPT_VENDOR, self.c.msg_type)
        eq_(0, self.c.xid)
        eq_(ofproto_v1_0.NX_VENDOR_ID, self.c.vendor)

        fmt = '!' \
            + ofproto_v1_0.OFP_HEADER_PACK_STR.replace('!', '') \
            + ofproto_v1_0.NICIRA_HEADER_PACK_STR.replace('!', '') \
            + ofproto_v1_0.NX_ROLE_PACK_STR.replace('!', '')

        res = struct.unpack(fmt, str(self.c.buf))

        eq_(ofproto_v1_0.OFP_VERSION, res[0])
        eq_(ofproto_v1_0.OFPT_VENDOR, res[1])
        eq_(len(self.c.buf), res[2])
        eq_(0, res[3])
        eq_(ofproto_v1_0.NX_VENDOR_ID, res[4])
        eq_(ofproto_v1_0.NXT_ROLE_REQUEST, res[5])
        eq_(self.role['val'], res[6])


class TestNXTFlowModTableId(unittest.TestCase):
    """ Test case for ofproto_v1_0_parser.NXTFlowModTableId
    """

    # NX_FLOW_MOD_TABLE_ID_PACK_STR
    # '!B7x'...set_, zfill
    set_ = {'buf': '\x71', 'val': 113}
    zfill = '\x00' * 7

    class Datapath(object):
        ofproto = ofproto_v1_0
        ofproto_parser = ofproto_v1_0_parser

    c = NXTFlowModTableId(Datapath, set_['val'])

    def setUp(self):
        pass

    def tearDown(self):
        pass

    def test_init(self):
        eq_(self.set_['val'], self.c.set)

    def test_parser(self):
        # Not used.
        pass

    def test_serialize(self):
        self.c.serialize()

        eq_(ofproto_v1_0.OFP_VERSION, self.c.version)
        eq_(ofproto_v1_0.OFPT_VENDOR, self.c.msg_type)
        eq_(0, self.c.xid)
        eq_(ofproto_v1_0.NX_VENDOR_ID, self.c.vendor)

        fmt = '!' \
            + ofproto_v1_0.OFP_HEADER_PACK_STR.replace('!', '') \
            + ofproto_v1_0.NICIRA_HEADER_PACK_STR.replace('!', '') \
            + ofproto_v1_0.NX_FLOW_MOD_TABLE_ID_PACK_STR.replace('!', '')

        res = struct.unpack(fmt, str(self.c.buf))
        eq_(ofproto_v1_0.OFP_VERSION, res[0])
        eq_(ofproto_v1_0.OFPT_VENDOR, res[1])
        eq_(len(self.c.buf), res[2])
        eq_(0, res[3])
        eq_(ofproto_v1_0.NX_VENDOR_ID, res[4])
        eq_(ofproto_v1_0.NXT_FLOW_MOD_TABLE_ID, res[5])
        eq_(self.set_['val'], res[6])


class TestOFPSwitchFeatures(unittest.TestCase):
    """ Test case for ofproto_v1_0_parser.OFPSwitchFeatures
    """

    class Datapath(object):
        ofproto = ofproto_v1_0
        ofproto_parser = ofproto_v1_0_parser

    c = OFPSwitchFeatures(Datapath)

    def setUp(self):
        pass

    def tearDown(self):
        pass

    def test_init(self):
        pass

    def test_parser(self):
        version = {'buf': '\x01', 'val': ofproto_v1_0.OFP_VERSION}
        msg_type = {'buf': '\x06', 'val': ofproto_v1_0.OFPT_FEATURES_REPLY}
        msg_len_val = ofproto_v1_0.OFP_SWITCH_FEATURES_SIZE \
            + ofproto_v1_0.OFP_PHY_PORT_SIZE
        msg_len = {'buf': '\x00\x4c', 'val': msg_len_val}
        xid = {'buf': '\xcc\x0a\x41\xd4', 'val': 3423224276}

        # OFP_SWITCH_FEATURES_PACK_STR
        # '!QIB3xII'...datapath_id, n_buffers, n_tables,
        #              zfill, capabilities, actions
        datapath_id = {'buf': '\x11\xa3\x72\x63\x61\xde\x39\x81',
                       'val': 1270985291017894273}
        n_buffers = {'buf': '\x80\x14\xd7\xf6', 'val': 2148849654}
        n_tables = {'buf': '\xe4', 'val': 228}
        zfill = '\x00' * 3
        capabilities = {'buf': '\x69\x4f\xe4\xc2', 'val': 1766843586}
        actions = {'buf': '\x78\x06\xd9\x0c', 'val': 2013714700}

        # OFP_PHY_PORT_PACK_STR
        # '!H6s16sIIIIII'... port_no, hw_addr, name, config, state
        #                    curr, advertised, supported, peer
        port_no = {'buf': '\xe7\x6b', 'val': 59243}
        hw_addr = '3c:d1:2b:8d:3f:d6'
        name = 'name'.ljust(16)
        config = {'buf': '\x84\xb6\x8c\x53', 'val': 2226555987}
        state = {'buf': '\x64\x07\xfb\xc9', 'val': 1678244809}
        curr = {'buf': '\xa9\xe8\x0a\x2b', 'val': 2850556459}
        advertised = {'buf': '\x78\xb9\x7b\x72', 'val': 2025421682}
        supported = {'buf': '\x7e\x65\x68\xad', 'val': 2120575149}
        peer = {'buf': '\xa4\x5b\x8b\xed', 'val': 2757463021}

        buf = version['buf'] \
            + msg_type['buf'] \
            + msg_len['buf'] \
            + xid['buf'] \
            + datapath_id['buf'] \
            + n_buffers['buf'] \
            + n_tables['buf'] \
            + zfill \
            + capabilities['buf'] \
            + actions['buf'] \
            + port_no['buf'] \
            + addrconv.mac.text_to_bin(hw_addr) \
            + name \
            + config['buf'] \
            + state['buf'] \
            + curr['buf'] \
            + advertised['buf'] \
            + supported['buf'] \
            + peer['buf']

        res = OFPSwitchFeatures.parser(object,
                                       version['val'],
                                       msg_type['val'],
                                       msg_len['val'],
                                       xid['val'],
                                       buf)

        eq_(version['val'], res.version)
        eq_(msg_type['val'], res.msg_type)
        eq_(msg_len['val'], res.msg_len)
        eq_(xid['val'], res.xid)
        eq_(datapath_id['val'], res.datapath_id)
        eq_(n_buffers['val'], res.n_buffers)
        eq_(n_tables['val'], res.n_tables)
        eq_(capabilities['val'], res.capabilities)
        eq_(actions['val'], res.actions)

        # port
        port = res.ports[port_no['val']]
        eq_(port_no['val'], port.port_no)
        eq_(hw_addr, hw_addr)
        eq_(name, port.name)
        eq_(config['val'], port.config)
        eq_(state['val'], port.state)
        eq_(curr['val'], port.curr)
        eq_(advertised['val'], port.advertised)
        eq_(supported['val'], port.supported)
        eq_(peer['val'], port.peer)

    def test_serialize(self):
        # Not used.
        pass


class TestOFPPortStatus(unittest.TestCase):
    """ Test case for ofproto_v1_0_parser.OFPPortStatus
    """

    class Datapath(object):
        ofproto = ofproto_v1_0
        ofproto_parser = ofproto_v1_0_parser

    c = OFPPortStatus(Datapath)

    def setUp(self):
        pass

    def tearDown(self):
        pass

    def test_init(self):
        pass

    def test_parser(self):
        version = {'buf': '\x01', 'val': ofproto_v1_0.OFP_VERSION}
        msg_type = {'buf': '\x0c', 'val': ofproto_v1_0.OFPT_PORT_STATUS}
        msg_len = {'buf': '\x00\x40',
                   'val': ofproto_v1_0.OFP_PORT_STATUS_SIZE}
        xid = {'buf': '\x06\x27\x8b\x7b', 'val': 103254907}

        # OFP_PORT_STATUS_PACK_STR
        # '!B7xH6s16sIIIIII'...reason, zfill, port_no, hw_addr,
        #                      name, config, state, curr,
        #                      advertised, supported, peer
        reason = {'buf': '\x71', 'val': 113}
        zfill = '\x00' * 7
        port_no = {'buf': '\x48\xd8', 'val': 18648}
        hw_addr = '41:f7:a3:52:8f:6b'
        name = 'name'.ljust(16)
        config = {'buf': '\xae\x73\x90\xec', 'val': 2926809324}
        state = {'buf': '\x41\x37\x32\x1d', 'val': 1094136349}
        curr = {'buf': '\xa9\x47\x13\x2c', 'val': 2840007468}
        advertised = {'buf': '\xce\x6b\x4a\x87', 'val': 3463137927}
        supported = {'buf': '\xb8\x06\x65\xa1', 'val': 3087426977}
        peer = {'buf': '\x6a\x11\x52\x39', 'val': 1779520057}

        buf = version['buf'] \
            + msg_type['buf'] \
            + msg_len['buf'] \
            + xid['buf'] \
            + reason['buf'] \
            + zfill \
            + port_no['buf'] \
            + addrconv.mac.text_to_bin(hw_addr) \
            + name \
            + config['buf'] \
            + state['buf'] \
            + curr['buf'] \
            + advertised['buf'] \
            + supported['buf'] \
            + peer['buf']

        res = OFPPortStatus.parser(object,
                                   version['val'],
                                   msg_type['val'],
                                   msg_len['val'],
                                   xid['val'],
                                   buf)

        eq_(version['val'], res.version)
        eq_(msg_type['val'], res.msg_type)
        eq_(msg_len['val'], res.msg_len)
        eq_(xid['val'], res.xid)
        eq_(reason['val'], res.reason)

        # desc
        desc = res.desc
        eq_(port_no['val'], desc.port_no)
        eq_(hw_addr, desc.hw_addr)
        eq_(name, desc.name)
        eq_(config['val'], desc.config)
        eq_(state['val'], desc.state)
        eq_(curr['val'], desc.curr)
        eq_(advertised['val'], desc.advertised)
        eq_(supported['val'], desc.supported)
        eq_(peer['val'], desc.peer)

    def test_serialize(self):
        # Not used.
        pass


class TestOFPPacketIn(unittest.TestCase):
    """ Test case for ofproto_v1_0_parser.OFPPacketIn
    """

    class Datapath(object):
        ofproto = ofproto_v1_0
        ofproto_parser = ofproto_v1_0_parser

    c = OFPPacketIn(Datapath)

    def setUp(self):
        pass

    def tearDown(self):
        pass

    def test_init(self):
        pass

    def _test_parser(self, padding=False):
        version = {'buf': '\x01', 'val': ofproto_v1_0.OFP_VERSION}
        msg_type = {'buf': '\x0a', 'val': ofproto_v1_0.OFPT_PACKET_IN}
        msg_len = {'buf': '\x00\x14',
                   'val': ofproto_v1_0.OFP_PACKET_IN_SIZE}
        xid = {'buf': '\xd0\x23\x8c\x34', 'val': 3491990580}

        # OFP_PACKET_IN_PACK_STR
        # '!IHHBx2x'...buffer_id, total_len,
        #              in_port, reason, zfill, data
        buffer_id = {'buf': '\xae\x73\x90\xec', 'val': 2926809324}
        total_len = {'buf': '\x00\x10', 'val': 16}
        in_port = {'buf': '\x08\x42', 'val': 2114}
        reason = {'buf': '\x43', 'val': 67}
        zfill = '\x00' * 1
        if padding:
            data = 'PACKET IN'.ljust(20)
        else:
            data = 'PACKET IN'.ljust(16)

        buf = version['buf'] \
            + msg_type['buf'] \
            + msg_len['buf'] \
            + xid['buf'] \
            + buffer_id['buf'] \
            + total_len['buf'] \
            + in_port['buf'] \
            + reason['buf'] \
            + zfill \
            + data

        res = OFPPacketIn.parser(object,
                                 version['val'],
                                 msg_type['val'],
                                 msg_len['val'],
                                 xid['val'],
                                 buf)

        eq_(version['val'], res.version)
        eq_(msg_type['val'], res.msg_type)
        eq_(msg_len['val'], res.msg_len)
        eq_(xid['val'], res.xid)
        eq_(buffer_id['val'], res.buffer_id)
        eq_(total_len['val'], res.total_len)
        eq_(in_port['val'], res.in_port)
        eq_(reason['val'], res.reason)
        eq_(data[0:16], res.data)

        return True

    def test_parser(self):
        ok_(self._test_parser())

    def test_parser_padding(self):
        ok_(self._test_parser(True))

    def test_serialize(self):
        # Not used.
        pass


class TestOFPGetConfigReply(unittest.TestCase):
    """ Test case for ofproto_v1_0_parser.OFPGetConfigReply
    """

    class Datapath(object):
        ofproto = ofproto_v1_0
        ofproto_parser = ofproto_v1_0_parser

    c = OFPGetConfigReply(Datapath)

    def setUp(self):
        pass

    def tearDown(self):
        pass

    def test_init(self):
        pass

    def test_parser(self):
        version = {'buf': '\x01', 'val': ofproto_v1_0.OFP_VERSION}
        msg_type = {'buf': '\x0a', 'val': ofproto_v1_0.OFPT_GET_CONFIG_REPLY}
        msg_len = {'buf': '\x00\x14',
                   'val': ofproto_v1_0.OFP_SWITCH_CONFIG_SIZE}
        xid = {'buf': '\x94\xc4\xd2\xcd', 'val': 2495926989}

        # OFP_SWITCH_CONFIG_PACK_STR
        # '!HH'...flags, miss_send_len
        flags = {'buf': '\xa0\xe2', 'val': 41186}
        miss_send_len = {'buf': '\x36\x0e', 'val': 13838}

        buf = version['buf'] \
            + msg_type['buf'] \
            + msg_len['buf'] \
            + xid['buf'] \
            + flags['buf'] \
            + miss_send_len['buf']

        res = OFPGetConfigReply.parser(object,
                                       version['val'],
                                       msg_type['val'],
                                       msg_len['val'],
                                       xid['val'],
                                       buf)

        eq_(version['val'], res.version)
        eq_(msg_type['val'], res.msg_type)
        eq_(msg_len['val'], res.msg_len)
        eq_(xid['val'], res.xid)
        eq_(flags['val'], res.flags)
        eq_(miss_send_len['val'], res.miss_send_len)

    def test_serialize(self):
        # Not used.
        pass


class TestOFPBarrierReply(unittest.TestCase):
    """ Test case for ofproto_v1_0_parser.OFPBarrierReply
    """

    class Datapath(object):
        ofproto = ofproto_v1_0
        ofproto_parser = ofproto_v1_0_parser

    c = OFPBarrierReply(Datapath)

    def setUp(self):
        pass

    def tearDown(self):
        pass

    def test_init(self):
        pass

    def test_parser(self):
        version = {'buf': '\x01', 'val': ofproto_v1_0.OFP_VERSION}
        msg_type = {'buf': '\x13', 'val': ofproto_v1_0.OFPT_BARRIER_REPLY}
        msg_len = {'buf': '\x00\x08',
                   'val': ofproto_v1_0.OFP_HEADER_SIZE}
        xid = {'buf': '\x66\xc4\xc3\xac', 'val': 1724171180}

        buf = version['buf'] \
            + msg_type['buf'] \
            + msg_len['buf'] \
            + xid['buf']

        res = OFPBarrierReply.parser(object,
                                     version['val'],
                                     msg_type['val'],
                                     msg_len['val'],
                                     xid['val'],
                                     buf)

        eq_(version['val'], res.version)
        eq_(msg_type['val'], res.msg_type)
        eq_(msg_len['val'], res.msg_len)
        eq_(xid['val'], res.xid)

    def test_serialize(self):
        # Not used.
        pass


class TestOFPFlowRemoved(unittest.TestCase):
    """ Test case for ofproto_v1_0_parser.OFPFlowRemoved
    """

    class Datapath(object):
        ofproto = ofproto_v1_0
        ofproto_parser = ofproto_v1_0_parser

    c = OFPFlowRemoved(Datapath)

    def setUp(self):
        pass

    def tearDown(self):
        pass

    def test_init(self):
        pass

    def test_parser(self):
        version = {'buf': '\x01', 'val': ofproto_v1_0.OFP_VERSION}
        msg_type = {'buf': '\x0a', 'val': ofproto_v1_0.OFPT_FLOW_REMOVED}
        msg_len = {'buf': '\x00\x14',
                   'val': ofproto_v1_0.OFP_FLOW_REMOVED_SIZE}
        xid = {'buf': '\x94\xc4\xd2\xcd', 'val': 2495926989}

        buf = version['buf'] \
            + msg_type['buf'] \
            + msg_len['buf'] \
            + xid['buf']

        # OFP_MATCH_PACK_STR
        # '!IH6s6sHBxHBB2xIIHH'...wildcards, in_port, dl_src, dl_dst, dl_vlan,
        #                         dl_vlan_pcp, dl_type, nw_tos, nw_proto,
        #                         nw_src, nw_dst, tp_src, tp_dst
        wildcards = {'buf': '\xd2\x71\x25\x23', 'val': 3530630435}
        in_port = {'buf': '\x37\x8b', 'val': 14219}
        dl_src = '\x7f\x85\xc4\x70\x12\xda'
        dl_dst = '\x0a\x51\x17\x58\xb0\xbb'
        dl_vlan = {'buf': '\xc1\xf9', 'val': 49657}
        dl_vlan_pcp = {'buf': '\x79', 'val': 121}
        zfill0 = '\x00'
        dl_type = {'buf': '\xa6\x9e', 'val': 42654}
        nw_tos = {'buf': '\xde', 'val': 222}
        nw_proto = {'buf': '\xe5', 'val': 229}
        zfil11 = '\x00' * 2
        nw_src = {'buf': '\x1b\x6d\x8d\x4b', 'val': 460164427}
        nw_dst = {'buf': '\xab\x25\xe1\x20', 'val': 2871386400}
        tp_src = {'buf': '\xd5\xc3', 'val': 54723}
        tp_dst = {'buf': '\x78\xb9', 'val': 30905}

        buf += wildcards['buf'] \
            + in_port['buf'] \
            + dl_src \
            + dl_dst \
            + dl_vlan['buf'] \
            + dl_vlan_pcp['buf'] \
            + zfill0 \
            + dl_type['buf'] \
            + nw_tos['buf'] \
            + nw_proto['buf'] \
            + zfil11 \
            + nw_src['buf'] \
            + nw_dst['buf'] \
            + tp_src['buf'] \
            + tp_dst['buf']

        # OFP_FLOW_REMOVED_PACK_STR0
        # '!QHBxIIH2xQQ'...cookie, priority, reason, zfill,
        #                  duration_sec, duration_nsec, idle_timeout,
        #                  zfill, packet_count, byte_count
        cookie = {'buf': '\x02\x79\xba\x00\xef\xab\xee\x44',
                  'val': 178378173441633860}
        priority = {'buf': '\x02\xce', 'val': 718}
        reason = {'buf': '\xa9', 'val': 169}
        zfill0 = '\x00' * 1
        duration_sec = {'buf': '\x86\x24\xa3\xba', 'val': 2250548154}
        duration_nsec = {'buf': '\x94\x94\xc2\x23', 'val': 2492776995}
        idle_timeout = {'buf': '\xeb\x7c', 'val': 60284}
        zfill1 = '\x00' * 2
        packet_count = {'buf': '\x5a\x0d\xf2\x03\x8e\x0a\xbb\x8d',
                        'val': 6489108735192644493}
        byte_count = {'buf': '\x65\xc8\xd3\x72\x51\xb5\xbb\x7c',
                      'val': 7334344481123449724}

        buf += cookie['buf'] \
            + priority['buf'] \
            + reason['buf'] \
            + zfill0 \
            + duration_sec['buf'] \
            + duration_nsec['buf'] \
            + idle_timeout['buf'] \
            + zfill1 \
            + packet_count['buf'] \
            + byte_count['buf']

        res = OFPFlowRemoved.parser(object,
                                    version['val'],
                                    msg_type['val'],
                                    msg_len['val'],
                                    xid['val'],
                                    buf)

        eq_(version['val'], res.version)
        eq_(msg_type['val'], res.msg_type)
        eq_(msg_len['val'], res.msg_len)
        eq_(xid['val'], res.xid)
        eq_(cookie['val'], res.cookie)
        eq_(priority['val'], res.priority)
        eq_(reason['val'], res.reason)
        eq_(duration_sec['val'], res.duration_sec)
        eq_(duration_nsec['val'], res.duration_nsec)
        eq_(idle_timeout['val'], res.idle_timeout)
        eq_(packet_count['val'], res.packet_count)
        eq_(byte_count['val'], res.byte_count)

        # match
        match = res.match
        eq_(wildcards['val'], match.wildcards)
        eq_(in_port['val'], match.in_port)
        eq_(dl_src, match.dl_src)
        eq_(dl_dst, match.dl_dst)
        eq_(dl_vlan['val'], match.dl_vlan)
        eq_(dl_vlan_pcp['val'], match.dl_vlan_pcp)
        eq_(dl_type['val'], match.dl_type)
        eq_(nw_tos['val'], match.nw_tos)
        eq_(nw_proto['val'], match.nw_proto)
        eq_(nw_src['val'], match.nw_src)
        eq_(nw_dst['val'], match.nw_dst)
        eq_(tp_src['val'], match.tp_src)
        eq_(tp_dst['val'], match.tp_dst)

    def test_serialize(self):
        # Not used.
        pass


class TestOFPQueueGetConfigReply(unittest.TestCase):
    """ Test case for ofproto_v1_0_parser.OFPQueueGetConfigReply
    """

    class Datapath(object):
        ofproto = ofproto_v1_0
        ofproto_parser = ofproto_v1_0_parser

    c = OFPQueueGetConfigReply(Datapath)

    def setUp(self):
        pass

    def tearDown(self):
        pass

    def test_init(self):
        pass

    def test_parser(self):
        version = {'buf': '\x01', 'val': ofproto_v1_0.OFP_VERSION}
        msg_type = {'buf': '\x0a',
                    'val': ofproto_v1_0.OFPT_QUEUE_GET_CONFIG_REPLY}
        msg_len_val = ofproto_v1_0.OFP_QUEUE_GET_CONFIG_REPLY_SIZE \
            + ofproto_v1_0.OFP_PACKET_QUEUE_SIZE
        msg_len = {'buf': '\x00\x14', 'val': msg_len_val}
        xid = {'buf': '\x94\xc4\xd2\xcd', 'val': 2495926989}

        buf = version['buf'] \
            + msg_type['buf'] \
            + msg_len['buf'] \
            + xid['buf']

        # OFP_QUEUE_GET_CONFIG_REPLY_PACK_STR
        # '!H6x'...port, zfill
        port = {'buf': '\xfe\x66', 'val': 65126}
        zfill = '\x00' * 6

        buf += port['buf'] \
            + zfill

        # OFP_PACKET_QUEUE_PQCK_STR
        # '!IH2x'...queue_id, len_, zfill
        queue_id = {'buf': '\x4d\x4b\x3a\xd1', 'val': 1296775889}
        len_ = {'buf': '\x00\x08',
                'val': ofproto_v1_0.OFP_QUEUE_PROP_HEADER_SIZE}
        zfill = '\x00' * 2

        buf += queue_id['buf'] \
            + len_['buf'] \
            + zfill

        res = OFPQueueGetConfigReply.parser(object,
                                            version['val'],
                                            msg_type['val'],
                                            msg_len['val'],
                                            xid['val'],
                                            buf)

        eq_(version['val'], res.version)
        eq_(msg_type['val'], res.msg_type)
        eq_(msg_len['val'], res.msg_len)
        eq_(xid['val'], res.xid)
        eq_(port['val'], res.port)

        # queue
        queue = res.queues[0]
        eq_(queue_id['val'], queue.queue_id)
        eq_(len_['val'], queue.len)

    def test_serialize(self):
        # Not used.
        pass


class TestOFPDescStatsReply(unittest.TestCase):
    """ Test case for ofproto_v1_0_parser.OFPDescStatsReply
    """

    class Datapath(object):
        ofproto = ofproto_v1_0
        ofproto_parser = ofproto_v1_0_parser

    c = OFPDescStatsReply(Datapath)

    def setUp(self):
        pass

    def tearDown(self):
        pass

    def test_init(self):
        pass

    def test_parser(self):
        version = {'buf': '\x01', 'val': ofproto_v1_0.OFP_VERSION}
        msg_type = {'buf': '\x11', 'val': ofproto_v1_0.OFPT_STATS_REPLY}
        msg_len_val = ofproto_v1_0.OFP_STATS_MSG_SIZE \
            + ofproto_v1_0.OFP_DESC_STATS_SIZE
        msg_len = {'buf': '\x04\x38', 'val': msg_len_val}
        xid = {'buf': '\x94\xc4\xd2\xcd', 'val': 2495926989}

        buf = version['buf'] \
            + msg_type['buf'] \
            + msg_len['buf'] \
            + xid['buf']

        # OFP_STATS_MSG_PACK_STR
        # '!HH'...type_, flags
        type_ = {'buf': '\x00\x00', 'val': ofproto_v1_0.OFPST_DESC}
        flags = {'buf': '\x30\xd9', 'val': 12505}

        buf += type_['buf'] \
            + flags['buf']

        # stats_type_cls = OFPDescStats
        # OFP_DESC_STATS_PACK_STR
        # '!256s256s256s32s256s'...mfr_desc, hw_desc, sw_desc,
        #                          serial_num, dp_desc
        mfr_desc = 'mfr_desc'.ljust(256)
        hw_desc = 'hw_desc'.ljust(256)
        sw_desc = 'sw_desc'.ljust(256)
        serial_num = 'serial_num'.ljust(32)
        dp_desc = 'dp_desc'.ljust(256)

        buf += mfr_desc \
            + hw_desc \
            + sw_desc \
            + serial_num \
            + dp_desc

        res = OFPDescStatsReply.parser(object,
                                       version['val'],
                                       msg_type['val'],
                                       msg_len['val'],
                                       xid['val'],
                                       buf)

        eq_(version['val'], res.version)
        eq_(msg_type['val'], res.msg_type)
        eq_(msg_len['val'], res.msg_len)
        eq_(xid['val'], res.xid)
        eq_(type_['val'], res.type)
        eq_(flags['val'], res.flags)

        # body
        body = res.body
        eq_(mfr_desc, body.mfr_desc)
        eq_(hw_desc, body.hw_desc)
        eq_(sw_desc, body.sw_desc)
        eq_(serial_num, body.serial_num)
        eq_(dp_desc, body.dp_desc)

    def test_serialize(self):
        # Not used.
        pass


class TestOFPFlowStatsReply(unittest.TestCase):
    """ Test case for ofproto_v1_0_parser.OFPFlowStatsReply
    """

    class Datapath(object):
        ofproto = ofproto_v1_0
        ofproto_parser = ofproto_v1_0_parser

    c = OFPFlowStatsReply(Datapath)

    def setUp(self):
        pass

    def tearDown(self):
        pass

    def test_init(self):
        pass

    def test_parser(self):
        version = {'buf': '\x01', 'val': ofproto_v1_0.OFP_VERSION}
        msg_type = {'buf': '\x11', 'val': ofproto_v1_0.OFPT_STATS_REPLY}
        msg_len_val = ofproto_v1_0.OFP_STATS_MSG_SIZE \
            + ofproto_v1_0.OFP_FLOW_STATS_SIZE
        msg_len = {'buf': '\x00\x64', 'val': msg_len_val}
        xid = {'buf': '\x94\xc4\xd2\xcd', 'val': 2495926989}

        buf = version['buf'] \
            + msg_type['buf'] \
            + msg_len['buf'] \
            + xid['buf']

        # OFP_STATS_MSG_PACK_STR
        # '!HH'...type_, flags
        type_ = {'buf': '\x00\x01', 'val': ofproto_v1_0.OFPST_FLOW}
        flags = {'buf': '\x95\xf4', 'val': 38388}

        buf += type_['buf'] \
            + flags['buf']

        # stats_type_cls = OFPFlowStats
        # OFP_FLOW_STATS_0_PACK_STR
        # '!HBx'...length, table_id, zfill
        length = {'buf': '\x00\x60', 'val': 96}
        table_id = {'buf': '\x51', 'val': 81}
        zfill = '\x00'

        buf += length['buf'] \
            + table_id['buf'] \
            + zfill

        # OFP_MATCH_PACK_STR
        # '!IH6s6sHBxHBB2xIIHH'...
        match = '\x97\x7c\xa6\x1e' \
            + '\x5e\xa0' \
            + '\x70\x17\xdc\x80\x59\x9e' \
            + '\x79\xc6\x56\x87\x92\x28' \
            + '\xb1\x81' \
            + '\xbe' \
            + '\x00' \
            + '\x01\xab' \
            + '\x42' \
            + '\xfe' \
            + '\x00\x00' \
            + '\xa4\x5d\x5c\x42' \
            + '\xa2\x5c\x2e\x05' \
            + '\x5a\x94' \
            + '\x64\xd4'

        buf += match

        # OFP_FLOW_STATS_1_PACK_STR
        # '!IIHHH6xQQQ'...duration_sec, duration_nsec, priority,
        #                 idle_timeout, hard_timeout, zfill,
        #                 cookie, packet_count, byte_count
        duration_sec = {'buf': '\x94\x19\xb3\xd2', 'val': 2484712402}
        duration_nsec = {'buf': '\xee\x66\xcf\x7c', 'val': 3999715196}
        priority = {'buf': '\xe1\xc0', 'val': 57792}
        idle_timeout = {'buf': '\x8e\x10', 'val': 36368}
        hard_timeout = {'buf': '\xd4\x99', 'val': 54425}
        zfill = '\x00' * 6
        cookie = {'buf': '\x0b\x01\xe8\xe5\xf0\x84\x8a\xe0',
                  'val': 793171083674290912}
        packet_count = {'buf': '\x47\x5c\xc6\x05\x28\xff\x7c\xdb',
                        'val': 5142202600015232219}
        byte_count = {'buf': '\x24\xe9\x4b\xee\xcb\x57\xd9\xc3',
                      'val': 2659740543924820419}

        buf += duration_sec['buf']
        buf += duration_nsec['buf']
        buf += priority['buf']
        buf += idle_timeout['buf']
        buf += hard_timeout['buf']
        buf += zfill
        buf += cookie['buf']
        buf += packet_count['buf']
        buf += byte_count['buf']

        # <action>_PACK_STR...type_, len_ [others...]
        type = {'buf': '\x00\x00', 'val': ofproto_v1_0.OFPAT_OUTPUT}
        len = {'buf': '\x00\x08',
               'val': ofproto_v1_0.OFP_ACTION_OUTPUT_SIZE}
        port = {'buf': '\x59\x2a', 'val': 22826}
        max_len = {'buf': '\x00\x08',
                   'val': ofproto_v1_0.OFP_ACTION_OUTPUT_SIZE}

        buf += type['buf'] \
            + len['buf'] \
            + port['buf'] \
            + max_len['buf']

        res = OFPFlowStatsReply.parser(object,
                                       version['val'],
                                       msg_type['val'],
                                       msg_len['val'],
                                       xid['val'],
                                       buf)

        eq_(version['val'], res.version)
        eq_(msg_type['val'], res.msg_type)
        eq_(msg_len['val'], res.msg_len)
        eq_(xid['val'], res.xid)
        eq_(type_['val'], res.type)
        eq_(flags['val'], res.flags)

        # body
        body = res.body[0]
        eq_(length['val'], body.length)
        eq_(table_id['val'], body.table_id)
        eq_(duration_sec['val'], body.duration_sec)
        eq_(duration_nsec['val'], body.duration_nsec)
        eq_(priority['val'], body.priority)
        eq_(idle_timeout['val'], body.idle_timeout)
        eq_(hard_timeout['val'], body.hard_timeout)
        eq_(cookie['val'], body.cookie)
        eq_(packet_count['val'], body.packet_count)
        eq_(byte_count['val'], body.byte_count)

        # action
        action = body.actions[0]
        eq_(type['val'], action.type)
        eq_(len['val'], action.len)
        eq_(port['val'], action.port)
        eq_(max_len['val'], action.max_len)

    def test_serialize(self):
        # Not used.
        pass


class TestOFPAggregateStatsReply(unittest.TestCase):
    """ Test case for ofproto_v1_0_parser.OFPAggregateStatsReply
    """

    class Datapath(object):
        ofproto = ofproto_v1_0
        ofproto_parser = ofproto_v1_0_parser

    c = OFPAggregateStatsReply(Datapath)

    def setUp(self):
        pass

    def tearDown(self):
        pass

    def test_init(self):
        pass

    def test_parser(self):
        version = {'buf': '\x01', 'val': ofproto_v1_0.OFP_VERSION}
        msg_type = {'buf': '\x11', 'val': ofproto_v1_0.OFPT_STATS_REPLY}
        msg_len_val = ofproto_v1_0.OFP_STATS_MSG_SIZE \
            + ofproto_v1_0.OFP_AGGREGATE_STATS_REPLY_SIZE
        msg_len = {'buf': '\x00\x4c', 'val': msg_len_val}
        xid = {'buf': '\xc6\xd6\xce\x38', 'val': 3335966264}

        buf = version['buf'] \
            + msg_type['buf'] \
            + msg_len['buf'] \
            + xid['buf']

        # OFP_STATS_MSG_PACK_STR
        # '!HH'...type_, flags
        type_ = {'buf': '\x00\x02', 'val': ofproto_v1_0.OFPST_AGGREGATE}
        flags = {'buf': '\x65\x66', 'val': 25958}

        buf += type_['buf'] \
            + flags['buf']

        # stats_type_cls = OFPAggregateStats
        # OFP_AGGREGATE_STATS_REPLY_PACK_STR
        # '!QQI4x'...packet_count, byte_count, flow_count, zfill
        packet_count = {'buf': '\x43\x95\x1b\xfb\x0f\xf6\xa7\xdd',
                        'val': 4869829337189623773}
        byte_count = {'buf': '\x36\xda\x2d\x80\x2a\x95\x35\xdd',
                      'val': 3952521651464517085}
        flow_count = {'buf': '\xc3\x0d\xc3\xed', 'val': 3272459245}
        zfill = '\x00' * 4

        buf += packet_count['buf'] \
            + byte_count['buf'] \
            + flow_count['buf'] \
            + zfill

        res = OFPAggregateStatsReply.parser(object,
                                            version['val'],
                                            msg_type['val'],
                                            msg_len['val'],
                                            xid['val'],
                                            buf)

        eq_(version['val'], res.version)
        eq_(msg_type['val'], res.msg_type)
        eq_(msg_len['val'], res.msg_len)
        eq_(xid['val'], res.xid)
        eq_(type_['val'], res.type)
        eq_(flags['val'], res.flags)

        # body
        body = res.body[0]
        eq_(packet_count['val'], body.packet_count)
        eq_(byte_count['val'], body.byte_count)
        eq_(flow_count['val'], body.flow_count)

    def test_serialize(self):
        # Not used.
        pass


class TestOFPTableStatsReply(unittest.TestCase):
    """ Test case for ofproto_v1_0_parser.OFPTableStatsReply
    """

    class Datapath(object):
        ofproto = ofproto_v1_0
        ofproto_parser = ofproto_v1_0_parser

    c = OFPTableStatsReply(Datapath)

    def setUp(self):
        pass

    def tearDown(self):
        pass

    def test_init(self):
        pass

    def test_parser(self):
        version = {'buf': '\x01', 'val': ofproto_v1_0.OFP_VERSION}
        msg_type = {'buf': '\x11', 'val': ofproto_v1_0.OFPT_STATS_REPLY}
        msg_len_val = ofproto_v1_0.OFP_STATS_MSG_SIZE \
            + ofproto_v1_0.OFP_TABLE_STATS_SIZE
        msg_len = {'buf': '\x00\x4c', 'val': msg_len_val}
        xid = {'buf': '\xd6\xb4\x8d\xe6', 'val': 3602157030}

        buf = version['buf'] \
            + msg_type['buf'] \
            + msg_len['buf'] \
            + xid['buf']

        # OFP_STATS_MSG_PACK_STR
        # '!HH'...type_, flags
        type_ = {'buf': '\x00\x03', 'val': ofproto_v1_0.OFPST_TABLE}
        flags = {'buf': '\xb3\xf0', 'val': 46064}

        buf += type_['buf'] \
            + flags['buf']

        # stats_type_cls = OFPTableStats
        # OFP_TABLE_STATS_PACK_STR
        # '!B3x32sIIIQQ'...table_id, zfill, name, wildcards, max_entries,
        #                  active_count, lookup_count, matched_count
        table_id = {'buf': '\x5b', 'val': 91}
        zfill = '\x00' * 3
        name = 'name'.ljust(32)
        wildcards = {'buf': '\xc5\xaf\x6e\x12', 'val': 3316608530}
        max_entries = {'buf': '\x95\x6c\x78\x4d', 'val': 2506913869}
        active_count = {'buf': '\x78\xac\xa8\x1e', 'val': 2024581150}
        lookup_count = {'buf': '\x40\x1d\x9c\x39\x19\xec\xd4\x1c',
                        'val': 4620020561814017052}
        matched_count = {'buf': '\x27\x35\x02\xb6\xc5\x5e\x17\x65',
                         'val': 2825167325263435621}

        buf += table_id['buf'] \
            + zfill \
            + name \
            + wildcards['buf'] \
            + max_entries['buf'] \
            + active_count['buf'] \
            + lookup_count['buf'] \
            + matched_count['buf']

        res = OFPTableStatsReply.parser(object,
                                        version['val'],
                                        msg_type['val'],
                                        msg_len['val'],
                                        xid['val'],
                                        buf)

        eq_(version['val'], res.version)
        eq_(msg_type['val'], res.msg_type)
        eq_(msg_len['val'], res.msg_len)
        eq_(xid['val'], res.xid)
        eq_(type_['val'], res.type)
        eq_(flags['val'], res.flags)

        # body
        body = res.body[0]
        eq_(table_id['val'], body.table_id)
        eq_(name, body.name)
        eq_(wildcards['val'], body.wildcards)
        eq_(max_entries['val'], body.max_entries)
        eq_(active_count['val'], body.active_count)
        eq_(lookup_count['val'], body.lookup_count)
        eq_(matched_count['val'], body.matched_count)

    def test_serialize(self):
        # Not used.
        pass


class TestOFPPortStatsReply(unittest.TestCase):
    """ Test case for ofproto_v1_0_parser.OFPPortStatsReply
    """

    class Datapath(object):
        ofproto = ofproto_v1_0
        ofproto_parser = ofproto_v1_0_parser

    c = OFPPortStatsReply(Datapath)

    def setUp(self):
        pass

    def tearDown(self):
        pass

    def test_init(self):
        pass

    def test_parser(self):
        version = {'buf': '\x01', 'val': ofproto_v1_0.OFP_VERSION}
        msg_type = {'buf': '\x11', 'val': ofproto_v1_0.OFPT_STATS_REPLY}
        msg_len_val = ofproto_v1_0.OFP_STATS_MSG_SIZE \
            + ofproto_v1_0.OFP_PORT_STATS_SIZE
        msg_len = {'buf': '\x00\x74', 'val': msg_len_val}
        xid = {'buf': '\xc2\xaf\x3d\xff', 'val': 3266264575}

        buf = version['buf'] \
            + msg_type['buf'] \
            + msg_len['buf'] \
            + xid['buf']

        # OFP_STATS_MSG_PACK_STR
        # '!HH'...type_, flags
        type_ = {'buf': '\x00\x04', 'val': ofproto_v1_0.OFPST_PORT}
        flags = {'buf': '\xda\xde', 'val': 56030}

        buf += type_['buf'] \
            + flags['buf']

        # stats_type_cls = OFPPortStats
        # OFP_PORT_STATS_PACK_STR
        # '!H6xQQQQQQQQQQQQ'... port_no, zfill, rx_packets, tx_packets,
        #                       rx_bytes, tx_bytes, rx_dropped, tx_dropped,
        #                       rx_errors, tx_errors, rx_frame_err,
        #                       rx_over_err, rx_crc_err, collisions
        port_no = {'buf': '\xe7\x6b', 'val': 59243}
        zfill = '\x00' * 6
        rx_packets = {'buf': '\x53\x44\x36\x61\xc4\x86\xc0\x37',
                      'val': 5999980397101236279}
        tx_packets = {'buf': '\x27\xa4\x41\xd7\xd4\x53\x9e\x42',
                      'val': 2856480458895760962}
        rx_bytes = {'buf': '\x55\xa1\x38\x60\x43\x97\x0d\x89',
                    'val': 6170274950576278921}
        tx_bytes = {'buf': '\x77\xe1\xd5\x63\x18\xae\x63\xaa',
                    'val': 8638420181865882538}
        rx_dropped = {'buf': '\x60\xe6\x20\x01\x24\xda\x4e\x5a',
                      'val': 6982303461569875546}
        tx_dropped = {'buf': '\x09\x2d\x5d\x71\x71\xb6\x8e\xc7',
                      'val': 661287462113808071}
        rx_errors = {'buf': '\x2f\x7e\x35\xb3\x66\x3c\x19\x0d',
                     'val': 3422231811478788365}
        tx_errors = {'buf': '\x57\x32\x08\x2f\x88\x32\x40\x6b',
                     'val': 6283093430376743019}
        rx_frame_err = {'buf': '\x0c\x28\x6f\xad\xce\x66\x6e\x8b',
                        'val': 876072919806406283}
        rx_over_err = {'buf': '\x5a\x90\x8f\x9b\xfc\x82\x2e\xa0',
                       'val': 6525873760178941600}
        rx_crc_err = {'buf': '\x73\x3a\x71\x17\xd6\x74\x69\x47',
                      'val': 8303073210207070535}
        collisions = {'buf': '\x2f\x52\x0c\x79\x96\x03\x6e\x79',
                      'val': 3409801584220270201}

        buf += port_no['buf'] \
            + zfill \
            + rx_packets['buf'] \
            + tx_packets['buf'] \
            + rx_bytes['buf'] \
            + tx_bytes['buf'] \
            + rx_dropped['buf'] \
            + tx_dropped['buf'] \
            + rx_errors['buf'] \
            + tx_errors['buf'] \
            + rx_frame_err['buf'] \
            + rx_over_err['buf'] \
            + rx_crc_err['buf'] \
            + collisions['buf']

        res = OFPPortStatsReply.parser(object,
                                       version['val'],
                                       msg_type['val'],
                                       msg_len['val'],
                                       xid['val'],
                                       buf)

        eq_(version['val'], res.version)
        eq_(msg_type['val'], res.msg_type)
        eq_(msg_len['val'], res.msg_len)
        eq_(xid['val'], res.xid)
        eq_(type_['val'], res.type)
        eq_(flags['val'], res.flags)

        # body
        body = res.body[0]
        eq_(port_no['val'], body.port_no)
        eq_(rx_packets['val'], body.rx_packets)
        eq_(tx_packets['val'], body.tx_packets)
        eq_(rx_bytes['val'], body.rx_bytes)
        eq_(tx_bytes['val'], body.tx_bytes)
        eq_(rx_dropped['val'], body.rx_dropped)
        eq_(tx_dropped['val'], body.tx_dropped)
        eq_(rx_errors['val'], body.rx_errors)
        eq_(tx_errors['val'], body.tx_errors)
        eq_(rx_frame_err['val'], body.rx_frame_err)
        eq_(rx_over_err['val'], body.rx_over_err)
        eq_(rx_crc_err['val'], body.rx_crc_err)
        eq_(collisions['val'], body.collisions)

    def test_serialize(self):
        # Not used.
        pass


class TestOFPQueueStatsReply(unittest.TestCase):
    """ Test case for ofproto_v1_0_parser.OFPQueueStatsReply
    """

    class Datapath(object):
        ofproto = ofproto_v1_0
        ofproto_parser = ofproto_v1_0_parser

    c = OFPQueueStatsReply(Datapath)

    def setUp(self):
        pass

    def tearDown(self):
        pass

    def test_init(self):
        pass

    def test_parser(self):
        version = {'buf': '\x01', 'val': ofproto_v1_0.OFP_VERSION}
        msg_type = {'buf': '\x11', 'val': ofproto_v1_0.OFPT_STATS_REPLY}
        msg_len_val = ofproto_v1_0.OFP_STATS_MSG_SIZE \
            + ofproto_v1_0.OFP_QUEUE_STATS_SIZE
        msg_len = {'buf': '\x00\x2c', 'val': msg_len_val}
        xid = {'buf': '\x19\xfc\x28\x6c', 'val': 435955820}

        buf = version['buf'] \
            + msg_type['buf'] \
            + msg_len['buf'] \
            + xid['buf']

        # OFP_STATS_MSG_PACK_STR
        # '!HH'...type_, flags
        type_ = {'buf': '\x00\x05', 'val': ofproto_v1_0.OFPST_QUEUE}
        flags = {'buf': '\x3b\x2b', 'val': 15147}

        buf += type_['buf'] \
            + flags['buf']

        # stats_type_cls = OFPQueueStats
        # OFP_QUEUE_STATS_PACK_STR
        # '!H2xIQQQ...port_no, queue_id, tx_bytes, tx_packets, tx_errors
        port_no = {'buf': '\xe7\x6b', 'val': 59243}
        zfill = '\x00' * 2
        queue_id = {'buf': '\x2a\xa8\x7f\x32', 'val': 715685682}
        tx_bytes = {'buf': '\x77\xe1\xd5\x63\x18\xae\x63\xaa',
                    'val': 8638420181865882538}
        tx_packets = {'buf': '\x27\xa4\x41\xd7\xd4\x53\x9e\x42',
                      'val': 2856480458895760962}
        tx_errors = {'buf': '\x57\x32\x08\x2f\x88\x32\x40\x6b',
                     'val': 6283093430376743019}

        buf += port_no['buf'] \
            + zfill \
            + queue_id['buf'] \
            + tx_bytes['buf'] \
            + tx_packets['buf'] \
            + tx_errors['buf']

        res = OFPQueueStatsReply.parser(object,
                                        version['val'],
                                        msg_type['val'],
                                        msg_len['val'],
                                        xid['val'],
                                        buf)

        eq_(version['val'], res.version)
        eq_(msg_type['val'], res.msg_type)
        eq_(msg_len['val'], res.msg_len)
        eq_(xid['val'], res.xid)
        eq_(type_['val'], res.type)
        eq_(flags['val'], res.flags)

        # body
        body = res.body[0]
        eq_(port_no['val'], body.port_no)
        eq_(queue_id['val'], body.queue_id)
        eq_(tx_bytes['val'], body.tx_bytes)
        eq_(tx_packets['val'], body.tx_packets)
        eq_(tx_errors['val'], body.tx_errors)

    def test_serialize(self):
        # Not used.
        pass


class TestOFPVendorStatsReply(unittest.TestCase):
    """ Test case for ofproto_v1_0_parser.OFPVendorStatsReply
    """

    class Datapath(object):
        ofproto = ofproto_v1_0
        ofproto_parser = ofproto_v1_0_parser

    c = OFPVendorStatsReply(Datapath)

    def setUp(self):
        pass

    def tearDown(self):
        pass

    def test_init(self):
        pass

    def test_parser(self):
        version = {'buf': '\x01', 'val': ofproto_v1_0.OFP_VERSION}
        msg_type = {'buf': '\x11', 'val': ofproto_v1_0.OFPT_STATS_REPLY}
        # ofproto_v1_0.OFP_STATS_MSG_SIZE + len(specific_data)
        msg_len = {'buf': '\x00\x18',
                   'val': ofproto_v1_0.OFP_STATS_MSG_SIZE + 12}
        xid = {'buf': '\x94\xc4\xd2\xcd', 'val': 2495926989}

        buf = version['buf'] \
            + msg_type['buf'] \
            + msg_len['buf'] \
            + xid['buf']

        # OFP_STATS_MSG_PACK_STR
        # '!HH'...type_, flags
        type_ = {'buf': '\xff\xff', 'val': ofproto_v1_0.OFPST_VENDOR}
        flags = {'buf': '\x30\xd9', 'val': 12505}

        buf += type_['buf'] \
            + flags['buf']

        # stats_type_cls = OFPVendorStats
        specific_data = 'specific_data'

        buf += specific_data

        res = OFPVendorStatsReply.parser(object,
                                         version['val'],
                                         msg_type['val'],
                                         msg_len['val'],
                                         xid['val'],
                                         buf)

        eq_(version['val'], res.version)
        eq_(msg_type['val'], res.msg_type)
        eq_(msg_len['val'], res.msg_len)
        eq_(xid['val'], res.xid)
        eq_(type_['val'], res.type)
        eq_(flags['val'], res.flags)

        # body
        body = res.body[0]
        eq_(specific_data, body)

    def test_serialize(self):
        # Not used.
        pass


class TestOFPFeaturesRequest(unittest.TestCase):
    """ Test case for ofproto_v1_0_parser.OFPFeaturesRequest
    """

    class Datapath(object):
        ofproto = ofproto_v1_0
        ofproto_parser = ofproto_v1_0_parser

    c = OFPFeaturesRequest(Datapath)

    def setUp(self):
        pass

    def tearDown(self):
        pass

    def test_init(self):
        pass

    def test_parser(self):
        # Not used.
        pass

    def test_serialize(self):
        self.c.serialize()

        eq_(ofproto_v1_0.OFP_VERSION, self.c.version)
        eq_(ofproto_v1_0.OFPT_FEATURES_REQUEST, self.c.msg_type)
        eq_(0, self.c.xid)

        fmt = ofproto_v1_0.OFP_HEADER_PACK_STR

        res = struct.unpack(fmt, str(self.c.buf))
        eq_(ofproto_v1_0.OFP_VERSION, res[0])
        eq_(ofproto_v1_0.OFPT_FEATURES_REQUEST, res[1])
        eq_(len(self.c.buf), res[2])
        eq_(0, res[3])


class TestOFPGetConfigRequest(unittest.TestCase):
    """ Test case for ofproto_v1_0_parser.OFPGetConfigRequest
    """

    class Datapath(object):
        ofproto = ofproto_v1_0
        ofproto_parser = ofproto_v1_0_parser

    c = OFPGetConfigRequest(Datapath)

    def setUp(self):
        pass

    def tearDown(self):
        pass

    def test_init(self):
        pass

    def test_parser(self):
        # Not used.
        pass

    def test_serialize(self):
        self.c.serialize()

        eq_(ofproto_v1_0.OFP_VERSION, self.c.version)
        eq_(ofproto_v1_0.OFPT_GET_CONFIG_REQUEST, self.c.msg_type)
        eq_(0, self.c.xid)

        fmt = ofproto_v1_0.OFP_HEADER_PACK_STR

        res = struct.unpack(fmt, str(self.c.buf))
        eq_(ofproto_v1_0.OFP_VERSION, res[0])
        eq_(ofproto_v1_0.OFPT_GET_CONFIG_REQUEST, res[1])
        eq_(len(self.c.buf), res[2])
        eq_(0, res[3])


class TestOFPSetConfig(unittest.TestCase):
    """ Test case for ofproto_v1_0_parser.OFPSetConfig
    """

    class Datapath(object):
        ofproto = ofproto_v1_0
        ofproto_parser = ofproto_v1_0_parser

    # OFP_SWITCH_CONFIG_PACK_STR
    # '!HH'...flags, miss_send_len
    flags = {'buf': '\xa0\xe2', 'val': 41186}
    miss_send_len = {'buf': '\x36\x0e', 'val': 13838}

    c = OFPSetConfig(Datapath,
                     flags['val'],
                     miss_send_len['val'])

    def setUp(self):
        pass

    def tearDown(self):
        pass

    def test_init(self):
        eq_(self.flags['val'], self.c.flags)
        eq_(self.miss_send_len['val'], self.c.miss_send_len)

    def test_parser(self):
        # Not used.
        pass

    def test_serialize(self):
        self.c.serialize()

        eq_(ofproto_v1_0.OFP_VERSION, self.c.version)
        eq_(ofproto_v1_0.OFPT_SET_CONFIG, self.c.msg_type)
        eq_(0, self.c.xid)

        fmt = '!' \
            + ofproto_v1_0.OFP_HEADER_PACK_STR.replace('!', '') \
            + ofproto_v1_0.OFP_SWITCH_CONFIG_PACK_STR.replace('!', '')

        res = struct.unpack(fmt, str(self.c.buf))
        eq_(ofproto_v1_0.OFP_VERSION, res[0])
        eq_(ofproto_v1_0.OFPT_SET_CONFIG, res[1])
        eq_(len(self.c.buf), res[2])
        eq_(0, res[3])
        eq_(self.flags['val'], res[4])
        eq_(self.miss_send_len['val'], res[5])


class TestOFPPacketOut(unittest.TestCase):
    """ Test case for ofproto_v1_0_parser.OFPPacketOut
    """

    port = 0x2ae0
    actions = [OFPActionOutput(port, max_len=0)]

    def setUp(self):
        pass

    def tearDown(self):
        pass

    def _get_obj(self, buffer_id, in_port, data=None):
        class Datapath(object):
            ofproto = ofproto_v1_0
            ofproto_parser = ofproto_v1_0_parser

        c = OFPPacketOut(Datapath,
                         buffer_id,
                         in_port,
                         self.actions,
                         data)
        return c

    def test_init(self):
        buffer_id = 0xffffffff
        in_port = 0x40455
        data = 'Message'

        c = self._get_obj(buffer_id, in_port, data)

        eq_(buffer_id, c.buffer_id)
        eq_(in_port, c.in_port)
        eq_(data, c.data)

    def test_parser(self):
        # Not used.
        pass

    def test_serialize(self):
        buffer_id = 0xffffffff
        in_port = 0x9e07
        data = 'Message'

        c = self._get_obj(buffer_id, in_port, data)
        c.serialize()

        eq_(ofproto_v1_0.OFP_VERSION, c.version)
        eq_(ofproto_v1_0.OFPT_PACKET_OUT, c.msg_type)
        eq_(0, c.xid)

        fmt = '!' \
            + ofproto_v1_0.OFP_HEADER_PACK_STR.replace('!', '') \
            + ofproto_v1_0.OFP_PACKET_OUT_PACK_STR.replace('!', '') \
            + ofproto_v1_0.OFP_ACTION_OUTPUT_PACK_STR.replace('!', '') \
            + str(len(data)) + 's'

        res = struct.unpack(fmt, str(c.buf))

        # OFP_HEADER_PACK_STR
        eq_(ofproto_v1_0.OFP_VERSION, res[0])
        eq_(ofproto_v1_0.OFPT_PACKET_OUT, res[1])
        eq_(len(c.buf), res[2])
        eq_(0, res[3])

        # OFP_PACKET_OUT_PACK_STR
        eq_(buffer_id, res[4])
        eq_(in_port, res[5])
        eq_(ofproto_v1_0.OFP_ACTION_OUTPUT_SIZE, res[6])

        # OFP_ACTION_OUTPUT_PACK_STR
        eq_(ofproto_v1_0.OFPAT_OUTPUT, res[7])
        eq_(ofproto_v1_0.OFP_ACTION_OUTPUT_SIZE, res[8])
        eq_(self.port, res[9])
        eq_(0, res[10])

        # data
        eq_(data, res[11])

    @raises(AssertionError)
    def test_serialize_check_buffer_id(self):
        buffer_id = 0xffffff00
        in_port = 0xaa92
        data = 'Message'

        c = self._get_obj(buffer_id, in_port, data)
        c.serialize()


class TestOFPFlowMod(unittest.TestCase):
    """ Test case for ofproto_v1_0_parser.OFPFlowMod
    """

    # OFP_FLOW_MOD_PACK_STR0
    # '!QHHHHIHH'...cookie, command, idle_timeout, hard_timeout,
    #               priority, buffer_id, out_port, flags
    cookie = {'buf': '\x1d\x86\xce\x6e\x8d\xc0\xbe\xa8',
              'val': 2127614848199081640}
    command = {'buf': '\xe1\x55', 'val': 57685}
    idle_timeout = {'buf': '\xf3\x6d', 'val': 62317}
    hard_timeout = {'buf': '\x1c\xc5', 'val': 7365}
    priority = {'buf': '\x9c\xe3', 'val': 40163}
    buffer_id = {'buf': '\xf0\xa1\x80\x33', 'val': 4037115955}
    out_port = {'buf': '\xfe\x0d', 'val': 65037}
    flags = {'buf': '\x00\x87', 'val': 135}

    # OFP_MATCH_PACK_STR
    # '!IH6s6sHBxHBB2xIIHH'...wildcards, in_port, dl_src, dl_dst, dl_vlan,
    #                         dl_vlan_pcp, dl_type, nw_tos, nw_proto,
    #                         nw_src, nw_dst, tp_src, tp_dst
    wildcards = {'buf': '\xd2\x71\x25\x23', 'val': 3530630435}
    in_port = {'buf': '\x37\x8b', 'val': 14219}
    dl_src = '\xdf\xcf\xe1\x5d\xcf\xc0'
    dl_dst = '\x76\xb3\xfb\xc6\x21\x2f'
    dl_vlan = {'buf': '\xc1\xf9', 'val': 49657}
    dl_vlan_pcp = {'buf': '\x79', 'val': 121}
    zfill0 = '\x00'
    dl_type = {'buf': '\xa6\x9e', 'val': 42654}
    nw_tos = {'buf': '\xde', 'val': 222}
    nw_proto = {'buf': '\xe5', 'val': 229}
    zfil11 = '\x00' * 2
    nw_src = {'buf': '\x1b\x6d\x8d\x4b', 'val': 460164427}
    nw_dst = {'buf': '\xab\x25\xe1\x20', 'val': 2871386400}
    tp_src = {'buf': '\xd5\xc3', 'val': 54723}
    tp_dst = {'buf': '\x78\xb9', 'val': 30905}

    match = OFPMatch(wildcards['val'],
                     in_port['val'],
                     dl_src,
                     dl_dst,
                     dl_vlan['val'],
                     dl_vlan_pcp['val'],
                     dl_type['val'],
                     nw_tos['val'],
                     nw_proto['val'],
                     nw_src['val'],
                     nw_dst['val'],
                     tp_src['val'],
                     tp_dst['val'])

    port = 0x2ae0
    actions = [OFPActionOutput(port, max_len=1000)]

    def setUp(self):
        pass

    def tearDown(self):
        pass

    def _get_obj(self, actions=None):
        class Datapath(object):
            ofproto = ofproto_v1_0
            ofproto_parser = ofproto_v1_0_parser

        c = OFPFlowMod(Datapath,
                       self.match,
                       self.cookie['val'],
                       self.command['val'],
                       self.idle_timeout['val'],
                       self.hard_timeout['val'],
                       self.priority['val'],
                       self.buffer_id['val'],
                       self.out_port['val'],
                       self.flags['val'],
                       actions)

        return c

    def test_init(self):
        c = self._get_obj()

        eq_(self.cookie['val'], c.cookie)
        eq_(self.command['val'], c.command)
        eq_(self.idle_timeout['val'], c.idle_timeout)
        eq_(self.hard_timeout['val'], c.hard_timeout)
        eq_(self.priority['val'], c.priority)
        eq_(self.buffer_id['val'], c.buffer_id)
        eq_(self.out_port['val'], c.out_port)
        eq_(self.flags['val'], c.flags)

    def test_init_actions(self):
        c = self._get_obj(self.actions)
        action = c.actions[0]

        eq_(self.port, action.port)

    def test_parser(self):
        # Not used.
        pass

    def test_serialize(self):
        c = self._get_obj(self.actions)
        c.serialize()

        eq_(ofproto_v1_0.OFP_VERSION, c.version)
        eq_(ofproto_v1_0.OFPT_FLOW_MOD, c.msg_type)
        eq_(0, c.xid)

        fmt = '!' \
            + ofproto_v1_0.OFP_HEADER_PACK_STR.replace('!', '') \
            + ofproto_v1_0.OFP_MATCH_PACK_STR.replace('!', '') \
            + ofproto_v1_0.OFP_FLOW_MOD_PACK_STR0.replace('!', '') \
            + ofproto_v1_0.OFP_ACTION_OUTPUT_PACK_STR.replace('!', '')

        res = struct.unpack(fmt, str(c.buf))

        # OFP_HEADER_PACK_STR
        eq_(ofproto_v1_0.OFP_VERSION, res[0])
        eq_(ofproto_v1_0.OFPT_FLOW_MOD, res[1])
        eq_(len(c.buf), res[2])
        eq_(0, res[3])

        # OFP_MATCH_PACK_STR
        eq_(self.wildcards['val'], res[4])
        eq_(self.in_port['val'], res[5])
        eq_(self.dl_src, res[6])
        eq_(self.dl_dst, res[7])
        eq_(self.dl_vlan['val'], res[8])
        eq_(self.dl_vlan_pcp['val'], res[9])
        eq_(self.dl_type['val'], res[10])
        eq_(self.nw_tos['val'], res[11])
        eq_(self.nw_proto['val'], res[12])
        eq_(self.nw_src['val'], res[13])
        eq_(self.nw_dst['val'], res[14])
        eq_(self.tp_src['val'], res[15])
        eq_(self.tp_dst['val'], res[16])

        # OFP_FLOW_MOD_PACK_STR0
        eq_(self.cookie['val'], res[17])
        eq_(self.command['val'], res[18])
        eq_(self.idle_timeout['val'], res[19])
        eq_(self.hard_timeout['val'], res[20])
        eq_(self.priority['val'], res[21])
        eq_(self.buffer_id['val'], res[22])
        eq_(self.out_port['val'], res[23])
        eq_(self.flags['val'], res[24])

        # OFP_ACTION_OUTPUT_PACK_STR
        eq_(ofproto_v1_0.OFPAT_OUTPUT, res[25])
        eq_(ofproto_v1_0.OFP_ACTION_OUTPUT_SIZE, res[26])
        eq_(self.port, res[27])
        eq_(1000, res[28])


class TestOFPBarrierRequest(unittest.TestCase):
    """ Test case for ofproto_v1_0_parser.OFPBarrierRequest
    """

    class Datapath(object):
        ofproto = ofproto_v1_0
        ofproto_parser = ofproto_v1_0_parser

    c = OFPBarrierRequest(Datapath)

    def setUp(self):
        pass

    def tearDown(self):
        pass

    def test_init(self):
        pass

    def test_parser(self):
        # Not used.
        pass

    def test_serialize(self):
        self.c.serialize()

        eq_(ofproto_v1_0.OFP_VERSION, self.c.version)
        eq_(ofproto_v1_0.OFPT_BARRIER_REQUEST, self.c.msg_type)
        eq_(0, self.c.xid)

        fmt = ofproto_v1_0.OFP_HEADER_PACK_STR

        res = struct.unpack(fmt, str(self.c.buf))
        eq_(ofproto_v1_0.OFP_VERSION, res[0])
        eq_(ofproto_v1_0.OFPT_BARRIER_REQUEST, res[1])
        eq_(len(self.c.buf), res[2])
        eq_(0, res[3])


class TestOFPQueueGetConfigRequest(unittest.TestCase):
    """ Test case for ofproto_v1_0_parser.OFPQueueGetConfigRequest
    """

    class Datapath(object):
        ofproto = ofproto_v1_0
        ofproto_parser = ofproto_v1_0_parser

    # OFP_QUEUE_GET_CONFIG_REQUEST_PACK_STR
    # '!H2x'...port, zfill
    port = {'buf': '\xa0\xe2', 'val': 41186}
    zfill = '\x00' * 2

    c = OFPQueueGetConfigRequest(Datapath,
                                 port['val'])

    def setUp(self):
        pass

    def tearDown(self):
        pass

    def test_init(self):
        eq_(self.port['val'], self.c.port)

    def test_parser(self):
        # Not used.
        pass

    def test_serialize(self):
        self.c.serialize()

        eq_(ofproto_v1_0.OFP_VERSION, self.c.version)
        eq_(ofproto_v1_0.OFPT_QUEUE_GET_CONFIG_REQUEST, self.c.msg_type)
        eq_(0, self.c.xid)

        a = ofproto_v1_0.OFP_HEADER_PACK_STR.replace('!', '')
        b = ofproto_v1_0.OFP_QUEUE_GET_CONFIG_REQUEST_PACK_STR.replace('!', '')
        fmt = '!' + a + b

        res = struct.unpack(fmt, str(self.c.buf))
        eq_(ofproto_v1_0.OFP_VERSION, res[0])
        eq_(ofproto_v1_0.OFPT_QUEUE_GET_CONFIG_REQUEST, res[1])
        eq_(len(self.c.buf), res[2])
        eq_(0, res[3])
        eq_(self.port['val'], res[4])


class TestOFPDescStatsRequest(unittest.TestCase):
    """ Test case for ofproto_v1_0_parser.OFPDescStatsRequest
    """

    class Datapath(object):
        ofproto = ofproto_v1_0
        ofproto_parser = ofproto_v1_0_parser

    flags = {'buf': '\x00\x00', 'val': 0}

    c = OFPDescStatsRequest(Datapath, flags['val'])

    def setUp(self):
        pass

    def tearDown(self):
        pass

    def test_init(self):
        eq_(ofproto_v1_0.OFPST_DESC, self.c.type)
        eq_(self.flags['val'], self.c.flags)

    def test_parser(self):
        # Not used.
        pass

    def test_serialize(self):
        self.c.serialize()

        eq_(ofproto_v1_0.OFP_VERSION, self.c.version)
        eq_(ofproto_v1_0.OFPT_STATS_REQUEST, self.c.msg_type)
        eq_(0, self.c.xid)

        fmt = '!' \
            + ofproto_v1_0.OFP_HEADER_PACK_STR.replace('!', '') \
            + ofproto_v1_0.OFP_STATS_MSG_PACK_STR.replace('!', '')

        res = struct.unpack(fmt, str(self.c.buf))

        # OFP_HEADER_PACK_STR
        eq_(ofproto_v1_0.OFP_VERSION, res[0])
        eq_(ofproto_v1_0.OFPT_STATS_REQUEST, res[1])
        eq_(len(self.c.buf), res[2])
        eq_(0, res[3])

        # OFP_STATS_MSG_PACK_STR
        eq_(ofproto_v1_0.OFPST_DESC, res[4])
        eq_(self.flags['val'], res[5])


class TestOFPFlowStatsRequest(unittest.TestCase):
    """ Test case for ofproto_v1_0_parser.OFPFlowStatsRequest
    """

    class Datapath(object):
        ofproto = ofproto_v1_0
        ofproto_parser = ofproto_v1_0_parser

    flags = {'buf': '\x00\x00', 'val': 0}

    # OFP_MATCH_PACK_STR
    # '!IH6s6sHBxHBB2xIIHH'...wildcards, in_port, dl_src, dl_dst, dl_vlan,
    #                         dl_vlan_pcp, dl_type, nw_tos, nw_proto,
    #                         nw_src, nw_dst, tp_src, tp_dst
    wildcards = {'buf': '\xd2\x71\x25\x23', 'val': 3530630435}
    in_port = {'buf': '\x37\x8b', 'val': 14219}
    dl_src = '\x58\xd0\x8a\x69\xa4\xfc'
    dl_dst = '\xb6\xe2\xef\xb1\xa6\x2d'
    dl_vlan = {'buf': '\xc1\xf9', 'val': 49657}
    dl_vlan_pcp = {'buf': '\x79', 'val': 121}
    zfill0 = '\x00'
    dl_type = {'buf': '\xa6\x9e', 'val': 42654}
    nw_tos = {'buf': '\xde', 'val': 222}
    nw_proto = {'buf': '\xe5', 'val': 229}
    zfil11 = '\x00' * 2
    nw_src = {'buf': '\x1b\x6d\x8d\x4b', 'val': 460164427}
    nw_dst = {'buf': '\xab\x25\xe1\x20', 'val': 2871386400}
    tp_src = {'buf': '\xd5\xc3', 'val': 54723}
    tp_dst = {'buf': '\x78\xb9', 'val': 30905}

    match = OFPMatch(wildcards['val'],
                     in_port['val'],
                     dl_src,
                     dl_dst,
                     dl_vlan['val'],
                     dl_vlan_pcp['val'],
                     dl_type['val'],
                     nw_tos['val'],
                     nw_proto['val'],
                     nw_src['val'],
                     nw_dst['val'],
                     tp_src['val'],
                     tp_dst['val'])

    # OFP_FLOW_STATS_REQUEST_ID_PORT_STR
    # '!BxH'...table_id, zfill, out_port
    table_id = {'buf': '\xd1', 'val': 209}
    zfill = '\x00' * 1
    out_port = {'buf': '\xe4\x9a', 'val': 58522}

    c = OFPFlowStatsRequest(Datapath,
                            flags['val'],
                            match,
                            table_id['val'],
                            out_port['val'])

    def setUp(self):
        pass

    def tearDown(self):
        pass

    def test_init(self):
        eq_(ofproto_v1_0.OFPST_FLOW, self.c.type)
        eq_(self.flags['val'], self.c.flags)
        eq_(self.table_id['val'], self.c.table_id)
        eq_(self.out_port['val'], self.c.out_port)

        # match
        match = self.c.match
        eq_(self.match.__hash__(), match.__hash__())

    def test_parser(self):
        # Not used.
        pass

    def test_serialize(self):
        self.c.serialize()

        eq_(ofproto_v1_0.OFP_VERSION, self.c.version)
        eq_(ofproto_v1_0.OFPT_STATS_REQUEST, self.c.msg_type)
        eq_(0, self.c.xid)

        fmt = '!' \
            + ofproto_v1_0.OFP_HEADER_PACK_STR.replace('!', '') \
            + ofproto_v1_0.OFP_STATS_MSG_PACK_STR.replace('!', '') \
            + ofproto_v1_0.OFP_MATCH_PACK_STR.replace('!', '') \
            + ofproto_v1_0.OFP_FLOW_STATS_REQUEST_ID_PORT_STR.replace('!', '')

        res = struct.unpack(fmt, str(self.c.buf))

        # OFP_HEADER_PACK_STR
        eq_(ofproto_v1_0.OFP_VERSION, res[0])
        eq_(ofproto_v1_0.OFPT_STATS_REQUEST, res[1])
        eq_(len(self.c.buf), res[2])
        eq_(0, res[3])

        # OFP_STATS_MSG_PACK_STR
        eq_(ofproto_v1_0.OFPST_FLOW, res[4])
        eq_(self.flags['val'], res[5])

        # OFP_MATCH_PACK_STR
        eq_(self.wildcards['val'], res[6])
        eq_(self.in_port['val'], res[7])
        eq_(self.dl_src, res[8])
        eq_(self.dl_dst, res[9])
        eq_(self.dl_vlan['val'], res[10])
        eq_(self.dl_vlan_pcp['val'], res[11])
        eq_(self.dl_type['val'], res[12])
        eq_(self.nw_tos['val'], res[13])
        eq_(self.nw_proto['val'], res[14])
        eq_(self.nw_src['val'], res[15])
        eq_(self.nw_dst['val'], res[16])
        eq_(self.tp_src['val'], res[17])
        eq_(self.tp_dst['val'], res[18])

        # OFP_FLOW_STATS_REQUEST_ID_PORT_STR
        eq_(self.table_id['val'], res[19])
        eq_(self.out_port['val'], res[20])


class TestOFPAggregateStatsRequest(unittest.TestCase):
    """ Test case for ofproto_v1_0_parser.OFPAggregateStatsRequest
    """

    class Datapath(object):
        ofproto = ofproto_v1_0
        ofproto_parser = ofproto_v1_0_parser

    flags = {'buf': '\x00\x00', 'val': 0}

    # OFP_MATCH_PACK_STR
    # '!IH6s6sHBxHBB2xIIHH'...wildcards, in_port, dl_src, dl_dst, dl_vlan,
    #                         dl_vlan_pcp, dl_type, nw_tos, nw_proto,
    #                         nw_src, nw_dst, tp_src, tp_dst
    wildcards = {'buf': '\xea\x66\x4a\xd4', 'val': 3932572372}
    in_port = {'buf': '\x64\xac', 'val': 25772}
    dl_src = '\x90\x13\x60\x5e\x20\x4d'
    dl_dst = '\xb5\x5d\x14\x5e\xb9\x22'
    dl_vlan = {'buf': '\x8b\xeb', 'val': 35819}
    dl_vlan_pcp = {'buf': '\xe8', 'val': 232}
    zfill0 = '\x00'
    dl_type = {'buf': '\62\xc9', 'val': 25289}
    nw_tos = {'buf': '\xb5', 'val': 181}
    nw_proto = {'buf': '\xc4', 'val': 196}
    zfil11 = '\x00' * 2
    nw_src = {'buf': '\xb7\xd1\xb7\xef', 'val': 3083974639}
    nw_dst = {'buf': '\x7c\xc6\x18\x15', 'val': 2093357077}
    tp_src = {'buf': '\x26\x9a', 'val': 9882}
    tp_dst = {'buf': '\x7a\x89', 'val': 31369}

    match = OFPMatch(wildcards['val'],
                     in_port['val'],
                     dl_src,
                     dl_dst,
                     dl_vlan['val'],
                     dl_vlan_pcp['val'],
                     dl_type['val'],
                     nw_tos['val'],
                     nw_proto['val'],
                     nw_src['val'],
                     nw_dst['val'],
                     tp_src['val'],
                     tp_dst['val'])

    # OFP_FLOW_STATS_REQUEST_ID_PORT_STR
    # '!BxH'...table_id, zfill, out_port
    table_id = {'buf': '\xd1', 'val': 209}
    zfill = '\x00' * 1
    out_port = {'buf': '\xb5\xe8', 'val': 46568}

    c = OFPAggregateStatsRequest(Datapath,
                                 flags['val'],
                                 match,
                                 table_id['val'],
                                 out_port['val'])

    def setUp(self):
        pass

    def tearDown(self):
        pass

    def test_init(self):
        eq_(ofproto_v1_0.OFPST_AGGREGATE, self.c.type)
        eq_(self.flags['val'], self.c.flags)
        eq_(self.table_id['val'], self.c.table_id)
        eq_(self.out_port['val'], self.c.out_port)

        # match
        match = self.c.match
        eq_(self.match.__hash__(), match.__hash__())

    def test_parser(self):
        # Not used.
        pass

    def test_serialize(self):
        self.c.serialize()

        eq_(ofproto_v1_0.OFP_VERSION, self.c.version)
        eq_(ofproto_v1_0.OFPT_STATS_REQUEST, self.c.msg_type)
        eq_(0, self.c.xid)

        fmt = '!' \
            + ofproto_v1_0.OFP_HEADER_PACK_STR.replace('!', '') \
            + ofproto_v1_0.OFP_STATS_MSG_PACK_STR.replace('!', '') \
            + ofproto_v1_0.OFP_MATCH_PACK_STR.replace('!', '') \
            + ofproto_v1_0.OFP_FLOW_STATS_REQUEST_ID_PORT_STR.replace('!', '')

        res = struct.unpack(fmt, str(self.c.buf))

        # OFP_HEADER_PACK_STR
        eq_(ofproto_v1_0.OFP_VERSION, res[0])
        eq_(ofproto_v1_0.OFPT_STATS_REQUEST, res[1])
        eq_(len(self.c.buf), res[2])
        eq_(0, res[3])

        # OFP_STATS_MSG_PACK_STR
        eq_(ofproto_v1_0.OFPST_AGGREGATE, res[4])
        eq_(self.flags['val'], res[5])

        # OFP_MATCH_PACK_STR
        eq_(self.wildcards['val'], res[6])
        eq_(self.in_port['val'], res[7])
        eq_(self.dl_src, res[8])
        eq_(self.dl_dst, res[9])
        eq_(self.dl_vlan['val'], res[10])
        eq_(self.dl_vlan_pcp['val'], res[11])
        eq_(self.dl_type['val'], res[12])
        eq_(self.nw_tos['val'], res[13])
        eq_(self.nw_proto['val'], res[14])
        eq_(self.nw_src['val'], res[15])
        eq_(self.nw_dst['val'], res[16])
        eq_(self.tp_src['val'], res[17])
        eq_(self.tp_dst['val'], res[18])

        # OFP_FLOW_STATS_REQUEST_ID_PORT_STR
        eq_(self.table_id['val'], res[19])
        eq_(self.out_port['val'], res[20])


class TestOFPTableStatsRequest(unittest.TestCase):
    """ Test case for ofproto_v1_0_parser.OFPTableStatsRequest
    """

    class Datapath(object):
        ofproto = ofproto_v1_0
        ofproto_parser = ofproto_v1_0_parser

    flags = {'buf': '\x00\x00', 'val': 0}

    c = OFPTableStatsRequest(Datapath, flags['val'])

    def setUp(self):
        pass

    def tearDown(self):
        pass

    def test_init(self):
        eq_(ofproto_v1_0.OFPST_TABLE, self.c.type)
        eq_(self.flags['val'], self.c.flags)

    def test_parser(self):
        # Not used.
        pass

    def test_serialize(self):
        self.c.serialize()

        eq_(ofproto_v1_0.OFP_VERSION, self.c.version)
        eq_(ofproto_v1_0.OFPT_STATS_REQUEST, self.c.msg_type)
        eq_(0, self.c.xid)

        fmt = '!' \
            + ofproto_v1_0.OFP_HEADER_PACK_STR.replace('!', '') \
            + ofproto_v1_0.OFP_STATS_MSG_PACK_STR.replace('!', '')

        res = struct.unpack(fmt, str(self.c.buf))

        # OFP_HEADER_PACK_STR
        eq_(ofproto_v1_0.OFP_VERSION, res[0])
        eq_(ofproto_v1_0.OFPT_STATS_REQUEST, res[1])
        eq_(len(self.c.buf), res[2])
        eq_(0, res[3])

        # OFP_STATS_MSG_PACK_STR
        eq_(ofproto_v1_0.OFPST_TABLE, res[4])
        eq_(self.flags['val'], res[5])


class TestOFPPortStatsRequest(unittest.TestCase):
    """ Test case for ofproto_v1_0_parser.OFPPortStatsRequest
    """

    class Datapath(object):
        ofproto = ofproto_v1_0
        ofproto_parser = ofproto_v1_0_parser

    flags = {'buf': '\x00\x00', 'val': 0}

    # OFP_PORT_STATS_REQUEST_PACK_STR
    # '!H6x'...port_no, zfill
    port_no = {'buf': '\x6d\x27', 'val': 27943}

    c = OFPPortStatsRequest(Datapath,
                            flags['val'],
                            port_no['val'])

    def setUp(self):
        pass

    def tearDown(self):
        pass

    def test_init(self):
        eq_(ofproto_v1_0.OFPST_PORT, self.c.type)
        eq_(self.flags['val'], self.c.flags)
        eq_(self.port_no['val'], self.c.port_no)

    def test_parser(self):
        # Not used.
        pass

    def test_serialize(self):
        self.c.serialize()

        eq_(ofproto_v1_0.OFP_VERSION, self.c.version)
        eq_(ofproto_v1_0.OFPT_STATS_REQUEST, self.c.msg_type)
        eq_(0, self.c.xid)

        fmt = '!' \
            + ofproto_v1_0.OFP_HEADER_PACK_STR.replace('!', '') \
            + ofproto_v1_0.OFP_STATS_MSG_PACK_STR.replace('!', '') \
            + ofproto_v1_0.OFP_PORT_STATS_REQUEST_PACK_STR.replace('!', '')

        res = struct.unpack(fmt, str(self.c.buf))

        # OFP_HEADER_PACK_STR
        eq_(ofproto_v1_0.OFP_VERSION, res[0])
        eq_(ofproto_v1_0.OFPT_STATS_REQUEST, res[1])
        eq_(len(self.c.buf), res[2])
        eq_(0, res[3])

        # OFP_STATS_MSG_PACK_STR
        eq_(ofproto_v1_0.OFPST_PORT, res[4])
        eq_(self.flags['val'], res[5])

        # OFP_PORT_STATS_REQUEST_PACK_STR
        eq_(self.port_no['val'], res[6])


class TestOFPQueueStatsRequest(unittest.TestCase):
    """ Test case for ofproto_v1_0_parser.OFPQueueStatsRequest
    """

    class Datapath(object):
        ofproto = ofproto_v1_0
        ofproto_parser = ofproto_v1_0_parser

    flags = {'buf': '\x00\x00', 'val': 0}

    # OFP_QUEUE_STATS_REQUEST_PACK_STR
    # '!HxxI'...port_no, zfill, zfill, queue_id
    port_no = {'buf': '\x0c\x2d', 'val': 3117}
    queue_id = {'buf': '\x1b\xe6\xba\x36', 'val': 468105782}

    c = OFPQueueStatsRequest(Datapath,
                             flags['val'],
                             port_no['val'],
                             queue_id['val'])

    def setUp(self):
        pass

    def tearDown(self):
        pass

    def test_init(self):
        eq_(ofproto_v1_0.OFPST_QUEUE, self.c.type)
        eq_(self.flags['val'], self.c.flags)
        eq_(self.port_no['val'], self.c.port_no)
        eq_(self.queue_id['val'], self.c.queue_id)

    def test_parser(self):
        # Not used.
        pass

    def test_serialize(self):
        self.c.serialize()

        eq_(ofproto_v1_0.OFP_VERSION, self.c.version)
        eq_(ofproto_v1_0.OFPT_STATS_REQUEST, self.c.msg_type)
        eq_(0, self.c.xid)

        fmt = '!' \
            + ofproto_v1_0.OFP_HEADER_PACK_STR.replace('!', '') \
            + ofproto_v1_0.OFP_STATS_MSG_PACK_STR.replace('!', '') \
            + ofproto_v1_0.OFP_QUEUE_STATS_REQUEST_PACK_STR.replace('!', '')

        res = struct.unpack(fmt, str(self.c.buf))

        # OFP_HEADER_PACK_STR
        eq_(ofproto_v1_0.OFP_VERSION, res[0])
        eq_(ofproto_v1_0.OFPT_STATS_REQUEST, res[1])
        eq_(len(self.c.buf), res[2])
        eq_(0, res[3])

        # OFP_STATS_MSG_PACK_STR
        eq_(ofproto_v1_0.OFPST_QUEUE, res[4])
        eq_(self.flags['val'], res[5])

        # OFP_QUEUE_STATS_REQUEST_PACK_STR
        eq_(self.port_no['val'], res[6])
        eq_(self.queue_id['val'], res[7])


class TestOFPVendorStatsRequest(unittest.TestCase):
    """ Test case for ofproto_v1_0_parser.OFPVendorStatsRequest
    """

    class Datapath(object):
        ofproto = ofproto_v1_0
        ofproto_parser = ofproto_v1_0_parser

    flags = {'buf': '\x00\x00', 'val': 0}

    # OFP_VENDOR_STATS_MSG_PACK_STR
    # '!I'...vendor
    vendor = {'buf': '\xff\xff\xff\xff', 'val': ofproto_v1_0.OFPAT_VENDOR}

    specific_data = 'specific_data'

    c = OFPVendorStatsRequest(Datapath,
                              flags['val'],
                              vendor['val'],
                              specific_data)

    def setUp(self):
        pass

    def tearDown(self):
        pass

    def test_init(self):
        eq_(ofproto_v1_0.OFPST_VENDOR, self.c.type)
        eq_(self.flags['val'], self.c.flags)
        eq_(self.vendor['val'], self.c.vendor)
        eq_(self.specific_data, self.c.specific_data)

    def test_parser(self):
        # Not used.
        pass

    def test_serialize(self):
        self.c.serialize()

        eq_(ofproto_v1_0.OFP_VERSION, self.c.version)
        eq_(ofproto_v1_0.OFPT_STATS_REQUEST, self.c.msg_type)
        eq_(0, self.c.xid)

        fmt = '!' \
            + ofproto_v1_0.OFP_HEADER_PACK_STR.replace('!', '') \
            + ofproto_v1_0.OFP_STATS_MSG_PACK_STR.replace('!', '') \
            + ofproto_v1_0.OFP_VENDOR_STATS_MSG_PACK_STR.replace('!', '') \
            + str(len(self.specific_data)) + 's'

        res = struct.unpack(fmt, str(self.c.buf))

        # OFP_HEADER_PACK_STR
        eq_(ofproto_v1_0.OFP_VERSION, res[0])
        eq_(ofproto_v1_0.OFPT_STATS_REQUEST, res[1])
        eq_(len(self.c.buf), res[2])
        eq_(0, res[3])

        # OFP_STATS_MSG_PACK_STR
        eq_(ofproto_v1_0.OFPST_VENDOR, res[4])
        eq_(self.flags['val'], res[5])

        # OFP_VENDOR_STATS_MSG_PACK_STR
        eq_(self.vendor['val'], res[6])

        # specific_data
        eq_(self.specific_data, res[7])

########NEW FILE########
__FILENAME__ = test_parser_v12
# Copyright (C) 2012 Nippon Telegraph and Telephone Corporation.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# vim: tabstop=4 shiftwidth=4 softtabstop=4

import unittest
import logging
import socket
from struct import *
from nose.tools import *
from nose.plugins.skip import Skip, SkipTest
from ryu.ofproto.ofproto_v1_2_parser import *
from ryu.ofproto import ofproto_v1_2_parser
from ryu.ofproto import ether
from ryu.ofproto.ofproto_parser import MsgBase
from ryu import utils
from ryu.lib import addrconv

LOG = logging.getLogger('test_ofproto_v12')


class _Datapath(object):
    ofproto = ofproto_v1_2
    ofproto_parser = ofproto_v1_2_parser


class TestRegisterParser(unittest.TestCase):
    """ Test case for ofproto_v1_2_parser._register_parser
    """

    class _OFPDummy(MsgBase):
        def __init__(self, datapath):
            self.dummy = 'dummy'

        def parser(self):
            return self.dummy

    def test_cls_msg_type(self):
        msg_type = 0xff
        cls = self._OFPDummy(_Datapath)
        cls.cls_msg_type = msg_type

        res = ofproto_v1_2_parser._register_parser(cls)
        res_parser = ofproto_v1_2_parser._MSG_PARSERS[msg_type]
        del ofproto_v1_2_parser._MSG_PARSERS[msg_type]

        eq_(res.cls_msg_type, msg_type)
        ok_(res.dummy)
        eq_(res_parser(), 'dummy')

    @raises(AssertionError)
    def test_cls_msg_type_none(self):
        cls = OFPHello(_Datapath)
        cls.cls_msg_type = None
        ofproto_v1_2_parser._register_parser(cls)

    @raises(AssertionError)
    def test_cls_msg_type_already_registed(self):
        cls = OFPHello(_Datapath)
        ofproto_v1_2_parser._register_parser(cls)


class TestMsgParser(unittest.TestCase):
    """ Test case for ofproto_v1_2_parser.msg_parser
    """

    def _test_msg_parser(self, xid, msg_len):
        # OFP_HEADER_PACK_STR
        # '!BBHI'...version, msg_type, msg_len, xid
        version = ofproto_v1_2.OFP_VERSION
        msg_type = ofproto_v1_2.OFPT_HELLO

        fmt = ofproto_v1_2.OFP_HEADER_PACK_STR
        buf = pack(fmt, version,  msg_type, msg_len, xid)

        c = msg_parser(_Datapath, version, msg_type, msg_len, xid, buf)

        eq_(version, c.version)
        eq_(msg_type, c.msg_type)
        eq_(msg_len, c.msg_len)
        eq_(xid, c.xid)

        # buf
        fmt = ofproto_v1_2.OFP_HEADER_PACK_STR
        res = struct.unpack(fmt, c.buf)

        eq_(version, res[0])
        eq_(msg_type, res[1])
        eq_(msg_len, res[2])
        eq_(xid, res[3])

    def test_parser_mid(self):
        xid = 2147483648
        msg_len = 8
        self._test_msg_parser(xid, msg_len)

    def test_parser_max(self):
        xid = 4294967295
        msg_len = 65535
        self._test_msg_parser(xid, msg_len)

    def test_parser_min(self):
        xid = 0
        msg_len = 0
        self._test_msg_parser(xid, msg_len)


class TestOFPHello(unittest.TestCase):
    """ Test case for ofproto_v1_2_parser.OFPHello
    """

    def _test_parser(self, xid):
        version = ofproto_v1_2.OFP_VERSION
        msg_type = ofproto_v1_2.OFPT_HELLO
        msg_len = ofproto_v1_2.OFP_HEADER_SIZE

        fmt = ofproto_v1_2.OFP_HEADER_PACK_STR
        buf = pack(fmt, version, msg_type, msg_len, xid)

        res = OFPHello.parser(object, version, msg_type, msg_len, xid,
                              bytearray(buf))

        eq_(version, res.version)
        eq_(msg_type, res.msg_type)
        eq_(msg_len, res.msg_len)
        eq_(xid, res.xid)
        eq_(buffer(buf), res.buf)

    def test_parser_xid_min(self):
        xid = 0
        self._test_parser(xid)

    def test_parser_xid_mid(self):
        xid = 2183948390
        self._test_parser(xid)

    def test_parser_xid_max(self):
        xid = 4294967295
        self._test_parser(xid)

    def test_serialize(self):
        c = OFPHello(_Datapath)
        c.serialize()
        eq_(ofproto_v1_2.OFP_VERSION, c.version)
        eq_(ofproto_v1_2.OFPT_HELLO, c.msg_type)
        eq_(0, c.xid)


class TestOFPErrorMsg(unittest.TestCase):
    """ Test case for ofproto_v1_2_parser.OFPErrorMsg
    """

    # OFP_HEADER_PACK_STR
    # '!BBHI'...version, msg_type, msg_len, xid
    version = ofproto_v1_2.OFP_VERSION
    msg_type = ofproto_v1_2.OFPT_ERROR
    msg_len = ofproto_v1_2.OFP_ERROR_MSG_SIZE
    xid = 2495926989

    fmt = ofproto_v1_2.OFP_HEADER_PACK_STR
    buf = pack(fmt, version, msg_type, msg_len, xid)

    def test_init(self):
        c = OFPErrorMsg(_Datapath)
        eq_(c.code, None)
        eq_(c.type, None)
        eq_(c.data, None)

    def _test_parser(self, type_, code, data=None):

        # OFP_ERROR_MSG_PACK_STR = '!HH'
        fmt = ofproto_v1_2.OFP_ERROR_MSG_PACK_STR
        buf = self.buf + pack(fmt, type_, code)

        if data is not None:
            buf += data

        res = OFPErrorMsg.parser(object, self.version, self.msg_type,
                                 self.msg_len, self.xid, buf)

        eq_(res.version, self.version)
        eq_(res.msg_type, self.msg_type)
        eq_(res.msg_len, self.msg_len)
        eq_(res.xid, self.xid)
        eq_(res.type, type_)
        eq_(res.code, code)

        if data is not None:
            eq_(res.data, data)

    def test_parser_mid(self):
        type_ = 32768
        code = 32768
        data = 'Error Message.'
        self._test_parser(type_, code, data)

    def test_parser_max(self):
        type_ = 65534
        code = 65535
        data = 'Error Message.'.ljust(65523)
        self._test_parser(type_, code, data)

    def test_parser_min(self):
        type_ = 0
        code = 0
        data = None
        self._test_parser(type_, code, data)

    def test_parser_p0_1(self):
        type_ = ofproto_v1_2.OFPET_HELLO_FAILED
        code = ofproto_v1_2.OFPHFC_EPERM
        data = 'Error Message.'
        self._test_parser(type_, code, data)

    def test_parser_p1_0(self):
        type_ = ofproto_v1_2.OFPET_BAD_REQUEST
        code = ofproto_v1_2.OFPBRC_BAD_VERSION
        data = 'Error Message.'
        self._test_parser(type_, code, data)

    def test_parser_p1_1(self):
        type_ = ofproto_v1_2.OFPET_BAD_REQUEST
        code = ofproto_v1_2.OFPBRC_BAD_TYPE
        data = 'Error Message.'
        self._test_parser(type_, code, data)

    def test_parser_p1_2(self):
        type_ = ofproto_v1_2.OFPET_BAD_REQUEST
        code = ofproto_v1_2.OFPBRC_BAD_STAT
        data = 'Error Message.'
        self._test_parser(type_, code, data)

    def test_parser_p1_3(self):
        type_ = ofproto_v1_2.OFPET_BAD_REQUEST
        code = ofproto_v1_2.OFPBRC_BAD_EXPERIMENTER
        data = 'Error Message.'
        self._test_parser(type_, code, data)

    def test_parser_p1_4(self):
        type_ = ofproto_v1_2.OFPET_BAD_REQUEST
        code = ofproto_v1_2.OFPBRC_BAD_EXP_TYPE
        data = 'Error Message.'
        self._test_parser(type_, code, data)

    def test_parser_p1_5(self):
        type_ = ofproto_v1_2.OFPET_BAD_REQUEST
        code = ofproto_v1_2.OFPBRC_EPERM
        data = 'Error Message.'
        self._test_parser(type_, code, data)

    def test_parser_p1_6(self):
        type_ = ofproto_v1_2.OFPET_BAD_REQUEST
        code = ofproto_v1_2.OFPBRC_BAD_LEN
        data = 'Error Message.'
        self._test_parser(type_, code, data)

    def test_parser_p1_7(self):
        type_ = ofproto_v1_2.OFPET_BAD_REQUEST
        code = ofproto_v1_2.OFPBRC_BUFFER_EMPTY
        data = 'Error Message.'
        self._test_parser(type_, code, data)

    def test_parser_p1_8(self):
        type_ = ofproto_v1_2.OFPET_BAD_REQUEST
        code = ofproto_v1_2.OFPBRC_BUFFER_UNKNOWN
        data = 'Error Message.'
        self._test_parser(type_, code, data)

    def test_parser_p1_9(self):
        type_ = ofproto_v1_2.OFPET_BAD_REQUEST
        code = ofproto_v1_2.OFPBRC_BAD_TABLE_ID
        data = 'Error Message.'
        self._test_parser(type_, code, data)

    def test_parser_p1_10(self):
        type_ = ofproto_v1_2.OFPET_BAD_REQUEST
        code = ofproto_v1_2.OFPBRC_IS_SLAVE
        data = 'Error Message.'
        self._test_parser(type_, code, data)

    def test_parser_p1_11(self):
        type_ = ofproto_v1_2.OFPET_BAD_REQUEST
        code = ofproto_v1_2.OFPBRC_BAD_PORT
        data = 'Error Message.'
        self._test_parser(type_, code, data)

    def test_parser_p1_12(self):
        type_ = ofproto_v1_2.OFPET_BAD_REQUEST
        code = ofproto_v1_2.OFPBRC_BAD_PACKET
        data = 'Error Message.'
        self._test_parser(type_, code, data)

    def test_parser_p2_0(self):
        type_ = ofproto_v1_2.OFPET_BAD_ACTION
        code = ofproto_v1_2.OFPBAC_BAD_TYPE
        data = 'Error Message.'
        self._test_parser(type_, code, data)

    def test_parser_p2_1(self):
        type_ = ofproto_v1_2.OFPET_BAD_ACTION
        code = ofproto_v1_2.OFPBAC_BAD_LEN
        data = 'Error Message.'
        self._test_parser(type_, code, data)

    def test_parser_p2_2(self):
        type_ = ofproto_v1_2.OFPET_BAD_ACTION
        code = ofproto_v1_2.OFPBAC_BAD_EXPERIMENTER
        data = 'Error Message.'
        self._test_parser(type_, code, data)

    def test_parser_p2_3(self):
        type_ = ofproto_v1_2.OFPET_BAD_ACTION
        code = ofproto_v1_2.OFPBAC_BAD_EXP_TYPE
        data = 'Error Message.'
        self._test_parser(type_, code, data)

    def test_parser_p2_4(self):
        type_ = ofproto_v1_2.OFPET_BAD_ACTION
        code = ofproto_v1_2.OFPBAC_BAD_OUT_PORT
        data = 'Error Message.'
        self._test_parser(type_, code, data)

    def test_parser_p2_5(self):
        type_ = ofproto_v1_2.OFPET_BAD_ACTION
        code = ofproto_v1_2.OFPBAC_BAD_ARGUMENT
        data = 'Error Message.'
        self._test_parser(type_, code, data)

    def test_parser_p2_6(self):
        type_ = ofproto_v1_2.OFPET_BAD_ACTION
        code = ofproto_v1_2.OFPBAC_EPERM
        data = 'Error Message.'
        self._test_parser(type_, code, data)

    def test_parser_p2_7(self):
        type_ = ofproto_v1_2.OFPET_BAD_ACTION
        code = ofproto_v1_2.OFPBAC_TOO_MANY
        data = 'Error Message.'
        self._test_parser(type_, code, data)

    def test_parser_p2_8(self):
        type_ = ofproto_v1_2.OFPET_BAD_ACTION
        code = ofproto_v1_2.OFPBAC_BAD_QUEUE
        data = 'Error Message.'
        self._test_parser(type_, code, data)

    def test_parser_p2_9(self):
        type_ = ofproto_v1_2.OFPET_BAD_ACTION
        code = ofproto_v1_2.OFPBAC_BAD_OUT_GROUP
        data = 'Error Message.'
        self._test_parser(type_, code, data)

    def test_parser_p2_10(self):
        type_ = ofproto_v1_2.OFPET_BAD_ACTION
        code = ofproto_v1_2.OFPBAC_MATCH_INCONSISTENT
        data = 'Error Message.'
        self._test_parser(type_, code, data)

    def test_parser_p2_11(self):
        type_ = ofproto_v1_2.OFPET_BAD_ACTION
        code = ofproto_v1_2.OFPBAC_UNSUPPORTED_ORDER
        data = 'Error Message.'
        self._test_parser(type_, code, data)

    def test_parser_p2_12(self):
        type_ = ofproto_v1_2.OFPET_BAD_ACTION
        code = ofproto_v1_2.OFPBAC_BAD_TAG
        data = 'Error Message.'
        self._test_parser(type_, code, data)

    def test_parser_p2_13(self):
        type_ = ofproto_v1_2.OFPET_BAD_ACTION
        code = ofproto_v1_2.OFPBAC_BAD_SET_TYPE
        data = 'Error Message.'
        self._test_parser(type_, code, data)

    def test_parser_p2_14(self):
        type_ = ofproto_v1_2.OFPET_BAD_ACTION
        code = ofproto_v1_2.OFPBAC_BAD_SET_LEN
        data = 'Error Message.'
        self._test_parser(type_, code, data)

    def test_parser_p2_15(self):
        type_ = ofproto_v1_2.OFPET_BAD_ACTION
        code = ofproto_v1_2.OFPBAC_BAD_SET_ARGUMENT
        data = 'Error Message.'
        self._test_parser(type_, code, data)

    def test_parser_p3_0(self):
        type_ = ofproto_v1_2.OFPET_BAD_INSTRUCTION
        code = ofproto_v1_2.OFPBIC_UNKNOWN_INST
        data = 'Error Message.'
        self._test_parser(type_, code, data)

    def test_parser_p3_1(self):
        type_ = ofproto_v1_2.OFPET_BAD_INSTRUCTION
        code = ofproto_v1_2.OFPBIC_UNSUP_INST
        data = 'Error Message.'
        self._test_parser(type_, code, data)

    def test_parser_p3_2(self):
        type_ = ofproto_v1_2.OFPET_BAD_INSTRUCTION
        code = ofproto_v1_2.OFPBIC_BAD_TABLE_ID
        data = 'Error Message.'
        self._test_parser(type_, code, data)

    def test_parser_p3_3(self):
        type_ = ofproto_v1_2.OFPET_BAD_INSTRUCTION
        code = ofproto_v1_2.OFPBIC_UNSUP_METADATA
        data = 'Error Message.'
        self._test_parser(type_, code, data)

    def test_parser_p3_4(self):
        type_ = ofproto_v1_2.OFPET_BAD_INSTRUCTION
        code = ofproto_v1_2.OFPBIC_UNSUP_METADATA_MASK
        data = 'Error Message.'
        self._test_parser(type_, code, data)

    def test_parser_p3_5(self):
        type_ = ofproto_v1_2.OFPET_BAD_INSTRUCTION
        code = ofproto_v1_2.OFPBIC_BAD_EXPERIMENTER
        data = 'Error Message.'
        self._test_parser(type_, code, data)

    def test_parser_p3_6(self):
        type_ = ofproto_v1_2.OFPET_BAD_INSTRUCTION
        code = ofproto_v1_2.OFPBIC_BAD_EXP_TYPE
        data = 'Error Message.'
        self._test_parser(type_, code, data)

    def test_parser_p3_7(self):
        type_ = ofproto_v1_2.OFPET_BAD_INSTRUCTION
        code = ofproto_v1_2.OFPBIC_BAD_LEN
        data = 'Error Message.'
        self._test_parser(type_, code, data)

    def test_parser_p3_8(self):
        type_ = ofproto_v1_2.OFPET_BAD_INSTRUCTION
        code = ofproto_v1_2.OFPBIC_EPERM
        data = 'Error Message.'
        self._test_parser(type_, code, data)

    def test_parser_p4_0(self):
        type_ = ofproto_v1_2.OFPET_BAD_MATCH
        code = ofproto_v1_2.OFPBMC_BAD_TYPE
        data = 'Error Message.'
        self._test_parser(type_, code, data)

    def test_parser_p4_1(self):
        type_ = ofproto_v1_2.OFPET_BAD_MATCH
        code = ofproto_v1_2.OFPBMC_BAD_LEN
        data = 'Error Message.'
        self._test_parser(type_, code, data)

    def test_parser_p4_2(self):
        type_ = ofproto_v1_2.OFPET_BAD_MATCH
        code = ofproto_v1_2.OFPBMC_BAD_TAG
        data = 'Error Message.'
        self._test_parser(type_, code, data)

    def test_parser_p4_3(self):
        type_ = ofproto_v1_2.OFPET_BAD_MATCH
        code = ofproto_v1_2.OFPBMC_BAD_DL_ADDR_MASK
        data = 'Error Message.'
        self._test_parser(type_, code, data)

    def test_parser_p4_4(self):
        type_ = ofproto_v1_2.OFPET_BAD_MATCH
        code = ofproto_v1_2.OFPBMC_BAD_NW_ADDR_MASK
        data = 'Error Message.'
        self._test_parser(type_, code, data)

    def test_parser_p4_5(self):
        type_ = ofproto_v1_2.OFPET_BAD_MATCH
        code = ofproto_v1_2.OFPBMC_BAD_WILDCARDS
        data = 'Error Message.'
        self._test_parser(type_, code, data)

    def test_parser_p4_6(self):
        type_ = ofproto_v1_2.OFPET_BAD_MATCH
        code = ofproto_v1_2.OFPBMC_BAD_FIELD
        data = 'Error Message.'
        self._test_parser(type_, code, data)

    def test_parser_p4_7(self):
        type_ = ofproto_v1_2.OFPET_BAD_MATCH
        code = ofproto_v1_2.OFPBMC_BAD_VALUE
        data = 'Error Message.'
        self._test_parser(type_, code, data)

    def test_parser_p4_8(self):
        type_ = ofproto_v1_2.OFPET_BAD_MATCH
        code = ofproto_v1_2.OFPBMC_BAD_MASK
        data = 'Error Message.'
        self._test_parser(type_, code, data)

    def test_parser_p4_9(self):
        type_ = ofproto_v1_2.OFPET_BAD_MATCH
        code = ofproto_v1_2.OFPBMC_BAD_PREREQ
        data = 'Error Message.'
        self._test_parser(type_, code, data)

    def test_parser_p4_10(self):
        type_ = ofproto_v1_2.OFPET_BAD_MATCH
        code = ofproto_v1_2.OFPBMC_DUP_FIELD
        data = 'Error Message.'
        self._test_parser(type_, code, data)

    def test_parser_p4_11(self):
        type_ = ofproto_v1_2.OFPET_BAD_MATCH
        code = ofproto_v1_2.OFPBMC_EPERM
        data = 'Error Message.'
        self._test_parser(type_, code, data)

    def test_parser_p5_0(self):
        type_ = ofproto_v1_2.OFPET_FLOW_MOD_FAILED
        code = ofproto_v1_2.OFPFMFC_UNKNOWN
        data = 'Error Message.'
        self._test_parser(type_, code, data)

    def test_parser_p5_1(self):
        type_ = ofproto_v1_2.OFPET_FLOW_MOD_FAILED
        code = ofproto_v1_2.OFPFMFC_TABLE_FULL
        data = 'Error Message.'
        self._test_parser(type_, code, data)

    def test_parser_p5_2(self):
        type_ = ofproto_v1_2.OFPET_FLOW_MOD_FAILED
        code = ofproto_v1_2.OFPFMFC_BAD_TABLE_ID
        data = 'Error Message.'
        self._test_parser(type_, code, data)

    def test_parser_p5_3(self):
        type_ = ofproto_v1_2.OFPET_FLOW_MOD_FAILED
        code = ofproto_v1_2.OFPFMFC_OVERLAP
        data = 'Error Message.'
        self._test_parser(type_, code, data)

    def test_parser_p5_4(self):
        type_ = ofproto_v1_2.OFPET_FLOW_MOD_FAILED
        code = ofproto_v1_2.OFPFMFC_EPERM
        data = 'Error Message.'
        self._test_parser(type_, code, data)

    def test_parser_p5_5(self):
        type_ = ofproto_v1_2.OFPET_FLOW_MOD_FAILED
        code = ofproto_v1_2.OFPFMFC_BAD_TIMEOUT
        data = 'Error Message.'
        self._test_parser(type_, code, data)

    def test_parser_p5_6(self):
        type_ = ofproto_v1_2.OFPET_FLOW_MOD_FAILED
        code = ofproto_v1_2.OFPFMFC_BAD_COMMAND
        data = 'Error Message.'
        self._test_parser(type_, code, data)

    def test_parser_p5_7(self):
        type_ = ofproto_v1_2.OFPET_FLOW_MOD_FAILED
        code = ofproto_v1_2.OFPFMFC_BAD_FLAGS
        data = 'Error Message.'
        self._test_parser(type_, code, data)

    def test_parser_p6_0(self):
        type_ = ofproto_v1_2.OFPET_GROUP_MOD_FAILED
        code = ofproto_v1_2.OFPGMFC_GROUP_EXISTS
        data = 'Error Message.'
        self._test_parser(type_, code, data)

    def test_parser_p6_1(self):
        type_ = ofproto_v1_2.OFPET_GROUP_MOD_FAILED
        code = ofproto_v1_2.OFPGMFC_INVALID_GROUP
        data = 'Error Message.'
        self._test_parser(type_, code, data)

    def test_parser_p6_2(self):
        type_ = ofproto_v1_2.OFPET_GROUP_MOD_FAILED
        code = ofproto_v1_2.OFPGMFC_WEIGHT_UNSUPPORTED
        data = 'Error Message.'
        self._test_parser(type_, code, data)

    def test_parser_p6_3(self):
        type_ = ofproto_v1_2.OFPET_GROUP_MOD_FAILED
        code = ofproto_v1_2.OFPGMFC_OUT_OF_GROUPS
        data = 'Error Message.'
        self._test_parser(type_, code, data)

    def test_parser_p6_4(self):
        type_ = ofproto_v1_2.OFPET_GROUP_MOD_FAILED
        code = ofproto_v1_2.OFPGMFC_OUT_OF_BUCKETS
        data = 'Error Message.'
        self._test_parser(type_, code, data)

    def test_parser_p6_5(self):
        type_ = ofproto_v1_2.OFPET_GROUP_MOD_FAILED
        code = ofproto_v1_2.OFPGMFC_CHAINING_UNSUPPORTED
        data = 'Error Message.'
        self._test_parser(type_, code, data)

    def test_parser_p6_6(self):
        type_ = ofproto_v1_2.OFPET_GROUP_MOD_FAILED
        code = ofproto_v1_2.OFPGMFC_WATCH_UNSUPPORTED
        data = 'Error Message.'
        self._test_parser(type_, code, data)

    def test_parser_p6_7(self):
        type_ = ofproto_v1_2.OFPET_GROUP_MOD_FAILED
        code = ofproto_v1_2.OFPGMFC_LOOP
        data = 'Error Message.'
        self._test_parser(type_, code, data)

    def test_parser_p6_8(self):
        type_ = ofproto_v1_2.OFPET_GROUP_MOD_FAILED
        code = ofproto_v1_2.OFPGMFC_UNKNOWN_GROUP
        data = 'Error Message.'
        self._test_parser(type_, code, data)

    def test_parser_p6_9(self):
        type_ = ofproto_v1_2.OFPET_GROUP_MOD_FAILED
        code = ofproto_v1_2.OFPGMFC_CHAINED_GROUP
        data = 'Error Message.'
        self._test_parser(type_, code, data)

    def test_parser_p6_10(self):
        type_ = ofproto_v1_2.OFPET_GROUP_MOD_FAILED
        code = ofproto_v1_2.OFPGMFC_BAD_TYPE
        data = 'Error Message.'
        self._test_parser(type_, code, data)

    def test_parser_p6_11(self):
        type_ = ofproto_v1_2.OFPET_GROUP_MOD_FAILED
        code = ofproto_v1_2.OFPGMFC_BAD_COMMAND
        data = 'Error Message.'
        self._test_parser(type_, code, data)

    def test_parser_p6_12(self):
        type_ = ofproto_v1_2.OFPET_GROUP_MOD_FAILED
        code = ofproto_v1_2.OFPGMFC_BAD_BUCKET
        data = 'Error Message.'
        self._test_parser(type_, code, data)

    def test_parser_p6_13(self):
        type_ = ofproto_v1_2.OFPET_GROUP_MOD_FAILED
        code = ofproto_v1_2.OFPGMFC_BAD_WATCH
        data = 'Error Message.'
        self._test_parser(type_, code, data)

    def test_parser_p6_14(self):
        type_ = ofproto_v1_2.OFPET_GROUP_MOD_FAILED
        code = ofproto_v1_2.OFPGMFC_EPERM
        data = 'Error Message.'
        self._test_parser(type_, code, data)

    def test_parser_p7_0(self):
        type_ = ofproto_v1_2.OFPET_PORT_MOD_FAILED
        code = ofproto_v1_2.OFPPMFC_BAD_PORT
        data = 'Error Message.'
        self._test_parser(type_, code, data)

    def test_parser_p7_1(self):
        type_ = ofproto_v1_2.OFPET_PORT_MOD_FAILED
        code = ofproto_v1_2.OFPPMFC_BAD_HW_ADDR
        data = 'Error Message.'
        self._test_parser(type_, code, data)

    def test_parser_p7_2(self):
        type_ = ofproto_v1_2.OFPET_PORT_MOD_FAILED
        code = ofproto_v1_2.OFPPMFC_BAD_CONFIG
        data = 'Error Message.'
        self._test_parser(type_, code, data)

    def test_parser_p7_3(self):
        type_ = ofproto_v1_2.OFPET_PORT_MOD_FAILED
        code = ofproto_v1_2.OFPPMFC_BAD_ADVERTISE
        data = 'Error Message.'
        self._test_parser(type_, code, data)

    def test_parser_p7_4(self):
        type_ = ofproto_v1_2.OFPET_PORT_MOD_FAILED
        code = ofproto_v1_2.OFPPMFC_EPERM
        data = 'Error Message.'
        self._test_parser(type_, code, data)

    def test_parser_p8_0(self):
        type_ = ofproto_v1_2.OFPET_TABLE_MOD_FAILED
        code = ofproto_v1_2.OFPTMFC_BAD_TABLE
        data = 'Error Message.'
        self._test_parser(type_, code, data)

    def test_parser_p8_1(self):
        type_ = ofproto_v1_2.OFPET_TABLE_MOD_FAILED
        code = ofproto_v1_2.OFPTMFC_BAD_CONFIG
        data = 'Error Message.'
        self._test_parser(type_, code, data)

    def test_parser_p8_2(self):
        type_ = ofproto_v1_2.OFPET_TABLE_MOD_FAILED
        code = ofproto_v1_2.OFPTMFC_EPERM
        data = 'Error Message.'
        self._test_parser(type_, code, data)

    def test_parser_p9_0(self):
        type_ = ofproto_v1_2.OFPET_QUEUE_OP_FAILED
        code = ofproto_v1_2.OFPQOFC_BAD_PORT
        data = 'Error Message.'
        self._test_parser(type_, code, data)

    def test_parser_p9_1(self):
        type_ = ofproto_v1_2.OFPET_QUEUE_OP_FAILED
        code = ofproto_v1_2.OFPQOFC_BAD_QUEUE
        data = 'Error Message.'
        self._test_parser(type_, code, data)

    def test_parser_p9_2(self):
        type_ = ofproto_v1_2.OFPET_QUEUE_OP_FAILED
        code = ofproto_v1_2.OFPQOFC_EPERM
        data = 'Error Message.'
        self._test_parser(type_, code, data)

    def test_parser_p10_0(self):
        type_ = ofproto_v1_2.OFPET_SWITCH_CONFIG_FAILED
        code = ofproto_v1_2.OFPSCFC_BAD_FLAGS
        data = 'Error Message.'
        self._test_parser(type_, code, data)

    def test_parser_p10_1(self):
        type_ = ofproto_v1_2.OFPET_SWITCH_CONFIG_FAILED
        code = ofproto_v1_2.OFPSCFC_BAD_LEN
        data = 'Error Message.'
        self._test_parser(type_, code, data)

    def test_parser_p10_2(self):
        type_ = ofproto_v1_2.OFPET_SWITCH_CONFIG_FAILED
        code = ofproto_v1_2.OFPQCFC_EPERM
        data = 'Error Message.'
        self._test_parser(type_, code, data)

    def test_parser_p11_0(self):
        type_ = ofproto_v1_2.OFPET_ROLE_REQUEST_FAILED
        code = ofproto_v1_2.OFPRRFC_STALE
        data = 'Error Message.'
        self._test_parser(type_, code, data)

    def test_parser_p11_1(self):
        type_ = ofproto_v1_2.OFPET_ROLE_REQUEST_FAILED
        code = ofproto_v1_2.OFPRRFC_UNSUP
        data = 'Error Message.'
        self._test_parser(type_, code, data)

    def test_parser_p11_2(self):
        type_ = ofproto_v1_2.OFPET_ROLE_REQUEST_FAILED
        code = ofproto_v1_2.OFPRRFC_BAD_ROLE
        data = 'Error Message.'
        self._test_parser(type_, code, data)

    def test_parser_experimenter(self):
        type_ = 0xffff
        exp_type = 1
        experimenter = 1
        data = 'Error Experimenter Message.'

        # OFP_ERROR_EXPERIMENTER_MSG_PACK_STR = '!HHI'
        fmt = ofproto_v1_2.OFP_ERROR_EXPERIMENTER_MSG_PACK_STR
        buf = self.buf + pack(fmt, type_, exp_type, experimenter) \
            + data

        res = OFPErrorMsg.parser(object, self.version, self.msg_type,
                                 self.msg_len, self.xid, buf)

        eq_(res.version, self.version)
        eq_(res.msg_type, self.msg_type)
        eq_(res.msg_len, self.msg_len)
        eq_(res.xid, self.xid)
        eq_(res.type, type_)
        eq_(res.exp_type, exp_type)
        eq_(res.experimenter, experimenter)
        eq_(res.data, data)

    def _test_serialize(self, type_, code, data):
        # OFP_ERROR_MSG_PACK_STR = '!HH'
        fmt = ofproto_v1_2.OFP_ERROR_MSG_PACK_STR
        buf = self.buf + pack(fmt, type_, code) + data

        # initialization
        c = OFPErrorMsg(_Datapath)
        c.type = type_
        c.code = code
        c.data = data

        c.serialize()

        eq_(ofproto_v1_2.OFP_VERSION, c.version)
        eq_(ofproto_v1_2.OFPT_ERROR, c.msg_type)
        eq_(0, c.xid)
        eq_(len(buf), c.msg_len)

        fmt = '!' \
            + ofproto_v1_2.OFP_HEADER_PACK_STR.replace('!', '') \
            + ofproto_v1_2.OFP_ERROR_MSG_PACK_STR.replace('!', '') \
            + str(len(c.data)) + 's'

        res = struct.unpack(fmt, str(c.buf))

        eq_(res[0], ofproto_v1_2.OFP_VERSION)
        eq_(res[1], ofproto_v1_2.OFPT_ERROR)
        eq_(res[2], len(buf))
        eq_(res[3], 0)
        eq_(res[4], type_)
        eq_(res[5], code)
        eq_(res[6], data)

    def test_serialize_mid(self):
        type_ = 32768
        code = 32768
        data = 'Error Message.'
        self._test_serialize(type_, code, data)

    def test_serialize_max(self):
        type_ = 65535
        code = 65535
        data = 'Error Message.'.ljust(65523)
        self._test_serialize(type_, code, data)

    def test_serialize_min_except_data(self):
        type_ = ofproto_v1_2.OFPET_HELLO_FAILED
        code = ofproto_v1_2.OFPHFC_INCOMPATIBLE
        data = 'Error Message.'
        self._test_serialize(type_, code, data)

    @raises(AssertionError)
    def test_serialize_check_data(self):
        c = OFPErrorMsg(_Datapath)
        c.serialize()

    def _test_serialize_p(self, type_, code):
        self._test_serialize(type_, code, 'Error Message.')

    def test_serialize_p0_1(self):
        self._test_serialize_p(ofproto_v1_2.OFPET_HELLO_FAILED,
                               ofproto_v1_2.OFPHFC_EPERM)

    def test_serialize_p1_0(self):
        self._test_serialize_p(ofproto_v1_2.OFPET_BAD_REQUEST,
                               ofproto_v1_2.OFPBRC_BAD_VERSION)

    def test_serialize_p1_1(self):
        self._test_serialize_p(ofproto_v1_2.OFPET_BAD_REQUEST,
                               ofproto_v1_2.OFPBRC_BAD_TYPE)

    def test_serialize_p1_2(self):
        self._test_serialize_p(ofproto_v1_2.OFPET_BAD_REQUEST,
                               ofproto_v1_2.OFPBRC_BAD_STAT)

    def test_serialize_p1_3(self):
        self._test_serialize_p(ofproto_v1_2.OFPET_BAD_REQUEST,
                               ofproto_v1_2.OFPBRC_BAD_EXPERIMENTER)

    def test_serialize_p1_4(self):
        self._test_serialize_p(ofproto_v1_2.OFPET_BAD_REQUEST,
                               ofproto_v1_2.OFPBRC_BAD_EXP_TYPE)

    def test_serialize_p1_5(self):
        self._test_serialize_p(ofproto_v1_2.OFPET_BAD_REQUEST,
                               ofproto_v1_2.OFPBRC_EPERM)

    def test_serialize_p1_6(self):
        self._test_serialize_p(ofproto_v1_2.OFPET_BAD_REQUEST,
                               ofproto_v1_2.OFPBRC_BAD_LEN)

    def test_serialize_p1_7(self):
        self._test_serialize_p(ofproto_v1_2.OFPET_BAD_REQUEST,
                               ofproto_v1_2.OFPBRC_BUFFER_EMPTY)

    def test_serialize_p1_8(self):
        self._test_serialize_p(ofproto_v1_2.OFPET_BAD_REQUEST,
                               ofproto_v1_2.OFPBRC_BUFFER_UNKNOWN)

    def test_serialize_p1_9(self):
        self._test_serialize_p(ofproto_v1_2.OFPET_BAD_REQUEST,
                               ofproto_v1_2.OFPBRC_BAD_TABLE_ID)

    def test_serialize_p1_10(self):
        self._test_serialize_p(ofproto_v1_2.OFPET_BAD_REQUEST,
                               ofproto_v1_2.OFPBRC_IS_SLAVE)

    def test_serialize_p1_11(self):
        self._test_serialize_p(ofproto_v1_2.OFPET_BAD_REQUEST,
                               ofproto_v1_2.OFPBRC_BAD_PORT)

    def test_serialize_p1_12(self):
        self._test_serialize_p(ofproto_v1_2.OFPET_BAD_REQUEST,
                               ofproto_v1_2.OFPBRC_BAD_PACKET)

    def test_serialize_p2_0(self):
        self._test_serialize_p(ofproto_v1_2.OFPET_BAD_ACTION,
                               ofproto_v1_2.OFPBAC_BAD_TYPE)

    def test_serialize_p2_1(self):
        self._test_serialize_p(ofproto_v1_2.OFPET_BAD_ACTION,
                               ofproto_v1_2.OFPBAC_BAD_LEN)

    def test_serialize_p2_2(self):
        self._test_serialize_p(ofproto_v1_2.OFPET_BAD_ACTION,
                               ofproto_v1_2.OFPBAC_BAD_EXPERIMENTER)

    def test_serialize_p2_3(self):
        self._test_serialize_p(ofproto_v1_2.OFPET_BAD_ACTION,
                               ofproto_v1_2.OFPBAC_BAD_EXP_TYPE)

    def test_serialize_p2_4(self):
        self._test_serialize_p(ofproto_v1_2.OFPET_BAD_ACTION,
                               ofproto_v1_2.OFPBAC_BAD_OUT_PORT)

    def test_serialize_p2_5(self):
        self._test_serialize_p(ofproto_v1_2.OFPET_BAD_ACTION,
                               ofproto_v1_2.OFPBAC_BAD_ARGUMENT)

    def test_serialize_p2_6(self):
        self._test_serialize_p(ofproto_v1_2.OFPET_BAD_ACTION,
                               ofproto_v1_2.OFPBAC_EPERM)

    def test_serialize_p2_7(self):
        self._test_serialize_p(ofproto_v1_2.OFPET_BAD_ACTION,
                               ofproto_v1_2.OFPBAC_TOO_MANY)

    def test_serialize_p2_8(self):
        self._test_serialize_p(ofproto_v1_2.OFPET_BAD_ACTION,
                               ofproto_v1_2.OFPBAC_BAD_QUEUE)

    def test_serialize_p2_9(self):
        self._test_serialize_p(ofproto_v1_2.OFPET_BAD_ACTION,
                               ofproto_v1_2.OFPBAC_BAD_OUT_GROUP)

    def test_serialize_p2_10(self):
        self._test_serialize_p(ofproto_v1_2.OFPET_BAD_ACTION,
                               ofproto_v1_2.OFPBAC_MATCH_INCONSISTENT)

    def test_serialize_p2_11(self):
        self._test_serialize_p(ofproto_v1_2.OFPET_BAD_ACTION,
                               ofproto_v1_2.OFPBAC_UNSUPPORTED_ORDER)

    def test_serialize_p2_12(self):
        self._test_serialize_p(ofproto_v1_2.OFPET_BAD_ACTION,
                               ofproto_v1_2.OFPBAC_BAD_TAG)

    def test_serialize_p2_13(self):
        self._test_serialize_p(ofproto_v1_2.OFPET_BAD_ACTION,
                               ofproto_v1_2.OFPBAC_BAD_SET_TYPE)

    def test_serialize_p2_14(self):
        self._test_serialize_p(ofproto_v1_2.OFPET_BAD_ACTION,
                               ofproto_v1_2.OFPBAC_BAD_SET_LEN)

    def test_serialize_p2_15(self):
        self._test_serialize_p(ofproto_v1_2.OFPET_BAD_ACTION,
                               ofproto_v1_2.OFPBAC_BAD_SET_ARGUMENT)

    def test_serialize_p3_0(self):
        self._test_serialize_p(ofproto_v1_2.OFPET_BAD_INSTRUCTION,
                               ofproto_v1_2.OFPBIC_UNKNOWN_INST)

    def test_serialize_p3_1(self):
        self._test_serialize_p(ofproto_v1_2.OFPET_BAD_INSTRUCTION,
                               ofproto_v1_2.OFPBIC_UNSUP_INST)

    def test_serialize_p3_2(self):
        self._test_serialize_p(ofproto_v1_2.OFPET_BAD_INSTRUCTION,
                               ofproto_v1_2.OFPBIC_BAD_TABLE_ID)

    def test_serialize_p3_3(self):
        self._test_serialize_p(ofproto_v1_2.OFPET_BAD_INSTRUCTION,
                               ofproto_v1_2.OFPBIC_UNSUP_METADATA)

    def test_serialize_p3_4(self):
        self._test_serialize_p(ofproto_v1_2.OFPET_BAD_INSTRUCTION,
                               ofproto_v1_2.OFPBIC_UNSUP_METADATA_MASK)

    def test_serialize_p3_5(self):
        self._test_serialize_p(ofproto_v1_2.OFPET_BAD_INSTRUCTION,
                               ofproto_v1_2.OFPBIC_BAD_EXPERIMENTER)

    def test_serialize_p3_6(self):
        self._test_serialize_p(ofproto_v1_2.OFPET_BAD_INSTRUCTION,
                               ofproto_v1_2.OFPBIC_BAD_EXP_TYPE)

    def test_serialize_p3_7(self):
        self._test_serialize_p(ofproto_v1_2.OFPET_BAD_INSTRUCTION,
                               ofproto_v1_2.OFPBIC_BAD_LEN)

    def test_serialize_p3_8(self):
        self._test_serialize_p(ofproto_v1_2.OFPET_BAD_INSTRUCTION,
                               ofproto_v1_2.OFPBIC_EPERM)

    def test_serialize_p4_0(self):
        self._test_serialize_p(ofproto_v1_2.OFPET_BAD_MATCH,
                               ofproto_v1_2.OFPBMC_BAD_TYPE)

    def test_serialize_p4_1(self):
        self._test_serialize_p(ofproto_v1_2.OFPET_BAD_MATCH,
                               ofproto_v1_2.OFPBMC_BAD_LEN)

    def test_serialize_p4_2(self):
        self._test_serialize_p(ofproto_v1_2.OFPET_BAD_MATCH,
                               ofproto_v1_2.OFPBMC_BAD_TAG)

    def test_serialize_p4_3(self):
        self._test_serialize_p(ofproto_v1_2.OFPET_BAD_MATCH,
                               ofproto_v1_2.OFPBMC_BAD_DL_ADDR_MASK)

    def test_serialize_p4_4(self):
        self._test_serialize_p(ofproto_v1_2.OFPET_BAD_MATCH,
                               ofproto_v1_2.OFPBMC_BAD_NW_ADDR_MASK)

    def test_serialize_p4_5(self):
        self._test_serialize_p(ofproto_v1_2.OFPET_BAD_MATCH,
                               ofproto_v1_2.OFPBMC_BAD_WILDCARDS)

    def test_serialize_p4_6(self):
        self._test_serialize_p(ofproto_v1_2.OFPET_BAD_MATCH,
                               ofproto_v1_2.OFPBMC_BAD_FIELD)

    def test_serialize_p4_7(self):
        self._test_serialize_p(ofproto_v1_2.OFPET_BAD_MATCH,
                               ofproto_v1_2.OFPBMC_BAD_VALUE)

    def test_serialize_p4_8(self):
        self._test_serialize_p(ofproto_v1_2.OFPET_BAD_MATCH,
                               ofproto_v1_2.OFPBMC_BAD_MASK)

    def test_serialize_p4_9(self):
        self._test_serialize_p(ofproto_v1_2.OFPET_BAD_MATCH,
                               ofproto_v1_2.OFPBMC_BAD_PREREQ)

    def test_serialize_p4_10(self):
        self._test_serialize_p(ofproto_v1_2.OFPET_BAD_MATCH,
                               ofproto_v1_2.OFPBMC_DUP_FIELD)

    def test_serialize_p4_11(self):
        self._test_serialize_p(ofproto_v1_2.OFPET_BAD_MATCH,
                               ofproto_v1_2.OFPBMC_EPERM)

    def test_serialize_p5_0(self):
        self._test_serialize_p(ofproto_v1_2.OFPET_FLOW_MOD_FAILED,
                               ofproto_v1_2.OFPFMFC_UNKNOWN)

    def test_serialize_p5_1(self):
        self._test_serialize_p(ofproto_v1_2.OFPET_FLOW_MOD_FAILED,
                               ofproto_v1_2.OFPFMFC_TABLE_FULL)

    def test_serialize_p5_2(self):
        self._test_serialize_p(ofproto_v1_2.OFPET_FLOW_MOD_FAILED,
                               ofproto_v1_2.OFPFMFC_BAD_TABLE_ID)

    def test_serialize_p5_3(self):
        self._test_serialize_p(ofproto_v1_2.OFPET_FLOW_MOD_FAILED,
                               ofproto_v1_2.OFPFMFC_OVERLAP)

    def test_serialize_p5_4(self):
        self._test_serialize_p(ofproto_v1_2.OFPET_FLOW_MOD_FAILED,
                               ofproto_v1_2.OFPFMFC_EPERM)

    def test_serialize_p5_5(self):
        self._test_serialize_p(ofproto_v1_2.OFPET_FLOW_MOD_FAILED,
                               ofproto_v1_2.OFPFMFC_BAD_TIMEOUT)

    def test_serialize_p5_6(self):
        self._test_serialize_p(ofproto_v1_2.OFPET_FLOW_MOD_FAILED,
                               ofproto_v1_2.OFPFMFC_BAD_COMMAND)

    def test_serialize_p5_7(self):
        self._test_serialize_p(ofproto_v1_2.OFPET_FLOW_MOD_FAILED,
                               ofproto_v1_2.OFPFMFC_BAD_FLAGS)

    def test_serialize_p6_0(self):
        self._test_serialize_p(ofproto_v1_2.OFPET_GROUP_MOD_FAILED,
                               ofproto_v1_2.OFPGMFC_GROUP_EXISTS)

    def test_serialize_p6_1(self):
        self._test_serialize_p(ofproto_v1_2.OFPET_GROUP_MOD_FAILED,
                               ofproto_v1_2.OFPGMFC_INVALID_GROUP)

    def test_serialize_p6_2(self):
        self._test_serialize_p(ofproto_v1_2.OFPET_GROUP_MOD_FAILED,
                               ofproto_v1_2.OFPGMFC_WEIGHT_UNSUPPORTED)

    def test_serialize_p6_3(self):
        self._test_serialize_p(ofproto_v1_2.OFPET_GROUP_MOD_FAILED,
                               ofproto_v1_2.OFPGMFC_OUT_OF_GROUPS)

    def test_serialize_p6_4(self):
        self._test_serialize_p(ofproto_v1_2.OFPET_GROUP_MOD_FAILED,
                               ofproto_v1_2.OFPGMFC_OUT_OF_BUCKETS)

    def test_serialize_p6_5(self):
        self._test_serialize_p(ofproto_v1_2.OFPET_GROUP_MOD_FAILED,
                               ofproto_v1_2.OFPGMFC_CHAINING_UNSUPPORTED)

    def test_serialize_p6_6(self):
        self._test_serialize_p(ofproto_v1_2.OFPET_GROUP_MOD_FAILED,
                               ofproto_v1_2.OFPGMFC_WATCH_UNSUPPORTED)

    def test_serialize_p6_7(self):
        self._test_serialize_p(ofproto_v1_2.OFPET_GROUP_MOD_FAILED,
                               ofproto_v1_2.OFPGMFC_LOOP)

    def test_serialize_p6_8(self):
        self._test_serialize_p(ofproto_v1_2.OFPET_GROUP_MOD_FAILED,
                               ofproto_v1_2.OFPGMFC_UNKNOWN_GROUP)

    def test_serialize_p6_9(self):
        self._test_serialize_p(ofproto_v1_2.OFPET_GROUP_MOD_FAILED,
                               ofproto_v1_2.OFPGMFC_CHAINED_GROUP)

    def test_serialize_p6_10(self):
        self._test_serialize_p(ofproto_v1_2.OFPET_GROUP_MOD_FAILED,
                               ofproto_v1_2.OFPGMFC_BAD_TYPE)

    def test_serialize_p6_11(self):
        self._test_serialize_p(ofproto_v1_2.OFPET_GROUP_MOD_FAILED,
                               ofproto_v1_2.OFPGMFC_BAD_COMMAND)

    def test_serialize_p6_12(self):
        self._test_serialize_p(ofproto_v1_2.OFPET_GROUP_MOD_FAILED,
                               ofproto_v1_2.OFPGMFC_BAD_BUCKET)

    def test_serialize_p6_13(self):
        self._test_serialize_p(ofproto_v1_2.OFPET_GROUP_MOD_FAILED,
                               ofproto_v1_2.OFPGMFC_BAD_WATCH)

    def test_serialize_p6_14(self):
        self._test_serialize_p(ofproto_v1_2.OFPET_GROUP_MOD_FAILED,
                               ofproto_v1_2.OFPGMFC_EPERM)

    def test_serialize_p7_0(self):
        self._test_serialize_p(ofproto_v1_2.OFPET_PORT_MOD_FAILED,
                               ofproto_v1_2.OFPPMFC_BAD_PORT)

    def test_serialize_p7_1(self):
        self._test_serialize_p(ofproto_v1_2.OFPET_PORT_MOD_FAILED,
                               ofproto_v1_2.OFPPMFC_BAD_HW_ADDR)

    def test_serialize_p7_2(self):
        self._test_serialize_p(ofproto_v1_2.OFPET_PORT_MOD_FAILED,
                               ofproto_v1_2.OFPPMFC_BAD_CONFIG)

    def test_serialize_p7_3(self):
        self._test_serialize_p(ofproto_v1_2.OFPET_PORT_MOD_FAILED,
                               ofproto_v1_2.OFPPMFC_BAD_ADVERTISE)

    def test_serialize_p7_4(self):
        self._test_serialize_p(ofproto_v1_2.OFPET_PORT_MOD_FAILED,
                               ofproto_v1_2.OFPPMFC_EPERM)

    def test_serialize_p8_0(self):
        self._test_serialize_p(ofproto_v1_2.OFPET_TABLE_MOD_FAILED,
                               ofproto_v1_2.OFPTMFC_BAD_TABLE)

    def test_serialize_p8_1(self):
        self._test_serialize_p(ofproto_v1_2.OFPET_TABLE_MOD_FAILED,
                               ofproto_v1_2.OFPTMFC_BAD_CONFIG)

    def test_serialize_p8_2(self):
        self._test_serialize_p(ofproto_v1_2.OFPET_TABLE_MOD_FAILED,
                               ofproto_v1_2.OFPTMFC_EPERM)

    def test_serialize_p9_0(self):
        self._test_serialize_p(ofproto_v1_2.OFPET_QUEUE_OP_FAILED,
                               ofproto_v1_2.OFPQOFC_BAD_PORT)

    def test_serialize_p9_1(self):
        self._test_serialize_p(ofproto_v1_2.OFPET_QUEUE_OP_FAILED,
                               ofproto_v1_2.OFPQOFC_BAD_QUEUE)

    def test_serialize_p9_2(self):
        self._test_serialize_p(ofproto_v1_2.OFPET_QUEUE_OP_FAILED,
                               ofproto_v1_2.OFPQOFC_EPERM)

    def test_serialize_p10_0(self):
        self._test_serialize_p(ofproto_v1_2.OFPET_SWITCH_CONFIG_FAILED,
                               ofproto_v1_2.OFPSCFC_BAD_FLAGS)

    def test_serialize_p10_1(self):
        self._test_serialize_p(ofproto_v1_2.OFPET_SWITCH_CONFIG_FAILED,
                               ofproto_v1_2.OFPSCFC_BAD_LEN)

    def test_serialize_p10_2(self):
        self._test_serialize_p(ofproto_v1_2.OFPET_SWITCH_CONFIG_FAILED,
                               ofproto_v1_2.OFPQCFC_EPERM)

    def test_serialize_p11_0(self):
        self._test_serialize_p(ofproto_v1_2.OFPET_ROLE_REQUEST_FAILED,
                               ofproto_v1_2.OFPRRFC_STALE)

    def test_serialize_p11_1(self):
        self._test_serialize_p(ofproto_v1_2.OFPET_ROLE_REQUEST_FAILED,
                               ofproto_v1_2.OFPRRFC_UNSUP)

    def test_serialize_p11_2(self):
        self._test_serialize_p(ofproto_v1_2.OFPET_ROLE_REQUEST_FAILED,
                               ofproto_v1_2.OFPRRFC_BAD_ROLE)


class TestOFPErrorExperimenterMsg(unittest.TestCase):
    """ Test case for ofproto_v1_2_parser.OFPErrorExperimenterMsg
    """

    def test_init(self):
        c = OFPErrorExperimenterMsg(_Datapath)
        eq_(c.type, 65535)
        eq_(c.exp_type, None)
        eq_(c.experimenter, None)
        eq_(c.data, None)

    def _test_parser(self, exp_type, experimenter, data=None):
        # OFP_HEADER_PACK_STR
        # '!BBHI'...version, msg_type, msg_len, xid
        version = ofproto_v1_2.OFP_VERSION
        msg_type = ofproto_v1_2.OFPT_ERROR
        msg_len = ofproto_v1_2.OFP_ERROR_MSG_SIZE
        xid = 2495926989

        fmt = ofproto_v1_2.OFP_HEADER_PACK_STR
        buf = pack(fmt, version, msg_type, msg_len, xid)

        # OFP_ERROR_EXPERIMENTER_MSG_PACK_STR = '!HHI'
        type_ = 0xffff
        fmt = ofproto_v1_2.OFP_ERROR_EXPERIMENTER_MSG_PACK_STR
        buf += pack(fmt, type_, exp_type, experimenter)

        if data is not None:
            buf += data

        res = OFPErrorExperimenterMsg.parser(
            object, version, msg_type, msg_len, xid, buf)

        eq_(res.version, version)
        eq_(res.msg_type, msg_type)
        eq_(res.msg_len, msg_len)
        eq_(res.xid, xid)
        eq_(res.type, type_)
        eq_(res.exp_type, exp_type)
        eq_(res.experimenter, experimenter)

        if data is not None:
            eq_(res.data, data)

    def test_parser_mid(self):
        exp_type = 32768
        experimenter = 2147483648
        data = 'Error Experimenter Message.'
        self._test_parser(exp_type, experimenter, data)

    def test_parser_max(self):
        exp_type = 65535
        experimenter = 4294967295
        data = 'Error Experimenter Message.'.ljust(65519)
        self._test_parser(exp_type, experimenter, data)

    def test_parser_min(self):
        exp_type = 0
        experimenter = 0
        self._test_parser(exp_type, experimenter)


class TestOFPEchoRequest(unittest.TestCase):
    """ Test case for ofproto_v1_2_parser.OFPEchoRequest
    """
    # OFP_HEADER_PACK_STR
    # '!BBHI'...version, msg_type, msg_len, xid
    version = ofproto_v1_2.OFP_VERSION
    msg_type = ofproto_v1_2.OFPT_ECHO_REQUEST
    msg_len = ofproto_v1_2.OFP_HEADER_SIZE
    xid = 2495926989

    def test_init(self):
        c = OFPEchoRequest(_Datapath)
        eq_(c.data, None)

    def _test_parser(self, data=None):
        fmt = ofproto_v1_2.OFP_HEADER_PACK_STR
        buf = pack(fmt, self.version, self.msg_type,
                   self.msg_len, self.xid)

        if data is not None:
            buf += data

        res = OFPEchoRequest.parser(object, self.version, self.msg_type,
                                    self.msg_len, self.xid, buf)

        eq_(res.version, self.version)
        eq_(res.msg_type, self.msg_type)
        eq_(res.msg_len, self.msg_len)
        eq_(res.xid, self.xid)

        if data is not None:
            eq_(res.data, data)

    def test_parser_mid(self):
        data = 'Request Message.'
        self._test_parser(data)

    def test_parser_max(self):
        data = 'Request Message.'.ljust(65527)
        self._test_parser(data)

    def test_parser_min(self):
        data = None
        self._test_parser(data)

    def _test_serialize(self, data):
        c = OFPEchoRequest(_Datapath)
        c.data = data
        c.serialize()

        eq_(ofproto_v1_2.OFP_VERSION, c.version)
        eq_(ofproto_v1_2.OFPT_ECHO_REQUEST, c.msg_type)
        eq_(0, c.xid)

        fmt = ofproto_v1_2.OFP_HEADER_PACK_STR

        if data is not None:
            fmt += str(len(c.data)) + 's'

        res = struct.unpack(fmt, str(c.buf))

        eq_(res[0], ofproto_v1_2.OFP_VERSION)
        eq_(res[1], ofproto_v1_2.OFPT_ECHO_REQUEST)
        eq_(res[2], len(c.buf))
        eq_(res[3], 0)

        if data is not None:
            eq_(res[4], data)

    def test_serialize_mid(self):
        data = 'Request Message.'
        self._test_serialize(data)

    def test_serialize_max(self):
        data = 'Request Message.'.ljust(65527)
        self._test_serialize(data)

    def test_serialize_min(self):
        data = None
        self._test_serialize(data)


class TestOFPEchoReply(unittest.TestCase):
    """ Test case for ofproto_v1_2_parser.OFPEchoReply
    """

    # OFP_HEADER_PACK_STR
    # '!BBHI'...version, msg_type, msg_len, xid
    version = ofproto_v1_2.OFP_VERSION
    msg_type = ofproto_v1_2.OFPT_ECHO_REPLY
    msg_len = ofproto_v1_2.OFP_HEADER_SIZE
    xid = 2495926989

    def test_init(self):
        c = OFPEchoReply(_Datapath)
        eq_(c.data, None)

    def _test_parser(self, data):
        fmt = ofproto_v1_2.OFP_HEADER_PACK_STR
        buf = pack(fmt, self.version, self.msg_type,
                   self.msg_len, self.xid)

        if data is not None:
            buf += data

        res = OFPEchoReply.parser(object, self.version, self.msg_type,
                                  self.msg_len, self.xid, buf)

        eq_(res.version, self.version)
        eq_(res.msg_type, self.msg_type)
        eq_(res.msg_len, self.msg_len)
        eq_(res.xid, self.xid)

        if data is not None:
            eq_(res.data, data)

    def test_parser_mid(self):
        data = 'Reply Message.'
        self._test_parser(data)

    def test_parser_max(self):
        data = 'Reply Message.'.ljust(65527)
        self._test_parser(data)

    def test_parser_min(self):
        data = None
        self._test_parser(data)

    def _test_serialize(self, data):
        fmt = ofproto_v1_2.OFP_HEADER_PACK_STR
        buf = pack(fmt, self.version, self.msg_type,
                   self.msg_len, self.xid) + data

        c = OFPEchoReply(_Datapath)
        c.data = data
        c.serialize()

        eq_(ofproto_v1_2.OFP_VERSION, c.version)
        eq_(ofproto_v1_2.OFPT_ECHO_REPLY, c.msg_type)
        eq_(0, c.xid)

        fmt = '!' \
            + ofproto_v1_2.OFP_HEADER_PACK_STR.replace('!', '') \
            + str(len(c.data)) + 's'

        res = struct.unpack(fmt, str(c.buf))

        eq_(res[0], ofproto_v1_2.OFP_VERSION)
        eq_(res[1], ofproto_v1_2.OFPT_ECHO_REPLY)
        eq_(res[2], len(buf))
        eq_(res[3], 0)
        eq_(res[4], data)

    def test_serialize_mid(self):
        data = 'Reply Message.'
        self._test_serialize(data)

    def test_serialize_max(self):
        data = 'Reply Message.'.ljust(65527)
        self._test_serialize(data)

    @raises(AssertionError)
    def test_serialize_check_data(self):
        c = OFPEchoReply(_Datapath)
        c.serialize()


class TestOFPExperimenter(unittest.TestCase):
    """ Test case for ofproto_v1_2_parser.OFPExperimenter
    """

    c = OFPExperimenter(_Datapath)

    def _test_parser(self, xid, experimenter, exp_type):
        # OFP_HEADER_PACK_STR
        # '!BBHI'...version, msg_type, msg_len, xid
        version = ofproto_v1_2.OFP_VERSION
        msg_type = ofproto_v1_2.OFPT_EXPERIMENTER
        msg_len = ofproto_v1_2.OFP_EXPERIMENTER_HEADER_SIZE

        fmt = ofproto_v1_2.OFP_HEADER_PACK_STR
        buf = pack(fmt, version,  msg_type, msg_len, xid)

        # OFP_EXPERIMENTER_HEADER_PACK_STR
        # '!II'...experimenter, exp_type
        fmt = ofproto_v1_2.OFP_EXPERIMENTER_HEADER_PACK_STR
        buf += pack(fmt, experimenter, exp_type)

        res = OFPExperimenter.parser(object, version, msg_type,
                                     msg_len, xid, buf)

        eq_(version, res.version)
        eq_(msg_type, res.msg_type)
        eq_(msg_len, res.msg_len)
        eq_(xid, res.xid)
        eq_(experimenter, res.experimenter)
        eq_(exp_type, res.exp_type)

    def test_parser_mid(self):
        xid = 2495926989
        experimenter = 2147483648
        exp_type = 1
        self._test_parser(xid, experimenter, exp_type)

    def test_parser_max(self):
        xid = 4294967295
        experimenter = 4294967295
        exp_type = 65535
        self._test_parser(xid, experimenter, exp_type)

    def test_parser_min(self):
        xid = 0
        experimenter = 0
        exp_type = 0
        self._test_parser(xid, experimenter, exp_type)


class TestOFPPort(unittest.TestCase):
    """ Test case for ofproto_v1_2_parser.OFPPort
    """

    def test_init(self):
        # OFP_PORT_PACK_STR
        # '!I4x6s2x16sIIIIIIII'... port_no, pad(4), hw_addr, pad(2),
        #                          name, config, state, curr, advertised,
        #                          peer, curr_speed, max_speed
        port_no = 1119692796
        hw_addr = 'c0:26:53:c4:29:e2'
        name = 'name'.ljust(16)
        config = 2226555987
        state = 1678244809
        curr = 2850556459
        advertised = 2025421682
        supported = 2120575149
        peer = 2757463021
        curr_speed = 2641353507
        max_speed = 1797291672

        fmt = ofproto_v1_2.OFP_PORT_PACK_STR
        buf = pack(fmt, port_no, hw_addr, name, config, state, curr,
                   advertised, supported, peer, curr_speed, max_speed)

        c = OFPPort(port_no, hw_addr, name, config, state, curr,
                    advertised, supported, peer, curr_speed, max_speed)

        eq_(port_no, c.port_no)
        eq_(hw_addr, c.hw_addr)
        eq_(name, c.name)
        eq_(config, c.config)
        eq_(state, c.state)
        eq_(curr, c.curr)
        eq_(advertised, c.advertised)
        eq_(supported, c.supported)
        eq_(peer, c.peer)
        eq_(curr_speed, c.curr_speed)
        eq_(max_speed, c.max_speed)

    def _test_parser(self, port_no, hw_addr, config, state, curr, advertised,
                     supported, peer, curr_speed, max_speed):
        name = 'name'.ljust(16)
        fmt = ofproto_v1_2.OFP_PORT_PACK_STR
        buf = pack(fmt, port_no, addrconv.mac.text_to_bin(hw_addr), name,
                   config, state, curr,
                   advertised, supported, peer, curr_speed, max_speed)

        res = OFPPort.parser(buf, 0)

        eq_(port_no, res.port_no)
        eq_(hw_addr, res.hw_addr)
        eq_(name, res.name)
        eq_(config, res.config)
        eq_(state, res.state)
        eq_(curr, res.curr)
        eq_(advertised, res.advertised)
        eq_(supported, res.supported)
        eq_(peer, res.peer)
        eq_(curr_speed, res.curr_speed)
        eq_(max_speed, res.max_speed)

    def test_parser_mid(self):
        port_no = 1119692796
        hw_addr = 'c0:26:53:c4:29:e2'
        config = 2226555987
        state = 1678244809
        curr = 2850556459
        advertised = 2025421682
        supported = 2120575149
        peer = 2757463021
        curr_speed = 2641353507
        max_speed = 1797291672
        self._test_parser(port_no, hw_addr, config, state, curr, advertised,
                          supported, peer, curr_speed, max_speed)

    def test_parser_max(self):
        port_no = ofproto_v1_2.OFPP_ANY
        hw_addr = 'ff:ff:ff:ff:ff:ff'
        config = 4294967295
        state = 4294967295
        curr = 4294967295
        advertised = 4294967295
        supported = 4294967295
        peer = 4294967295
        curr_speed = 4294967295
        max_speed = 4294967295
        self._test_parser(port_no, hw_addr, config, state, curr, advertised,
                          supported, peer, curr_speed, max_speed)

    def test_parser_min(self):
        port_no = 0
        hw_addr = '00:00:00:00:00:00'
        config = 0
        state = 0
        curr = 0
        advertised = 0
        supported = 0
        peer = 0
        curr_speed = 0
        max_speed = 0
        self._test_parser(port_no, hw_addr, config, state, curr, advertised,
                          supported, peer, curr_speed, max_speed)

    def test_parser_p1(self):
        port_no = ofproto_v1_2.OFPP_MAX
        hw_addr = 'c0:26:53:c4:29:e2'
        config = ofproto_v1_2.OFPPC_PORT_DOWN
        state = ofproto_v1_2.OFPPS_LINK_DOWN
        curr = advertised = supported \
             = peer = curr_speed = max_speed \
             = ofproto_v1_2.OFPPF_10MB_HD
        self._test_parser(port_no, hw_addr, config, state, curr, advertised,
                          supported, peer, curr_speed, max_speed)

    def test_parser_p2(self):
        port_no = ofproto_v1_2.OFPP_IN_PORT
        hw_addr = 'c0:26:53:c4:29:e2'
        config = ofproto_v1_2.OFPPC_NO_RECV
        state = ofproto_v1_2.OFPPS_BLOCKED
        curr = advertised = supported \
             = peer = curr_speed = max_speed \
             = ofproto_v1_2.OFPPF_10MB_FD
        self._test_parser(port_no, hw_addr, config, state, curr, advertised,
                          supported, peer, curr_speed, max_speed)

    def test_parser_p3(self):
        port_no = ofproto_v1_2.OFPP_TABLE
        hw_addr = 'c0:26:53:c4:29:e2'
        config = ofproto_v1_2.OFPPC_NO_FWD
        state = ofproto_v1_2.OFPPS_LIVE
        curr = advertised = supported \
             = peer = curr_speed = max_speed \
             = ofproto_v1_2.OFPPF_100MB_HD
        self._test_parser(port_no, hw_addr, config, state, curr, advertised,
                          supported, peer, curr_speed, max_speed)

    def test_parser_p4(self):
        port_no = ofproto_v1_2.OFPP_NORMAL
        hw_addr = 'c0:26:53:c4:29:e2'
        config = ofproto_v1_2.OFPPC_NO_PACKET_IN
        state = ofproto_v1_2.OFPPS_LIVE
        curr = advertised = supported \
             = peer = curr_speed = max_speed \
             = ofproto_v1_2.OFPPF_100MB_FD
        self._test_parser(port_no, hw_addr, config, state, curr, advertised,
                          supported, peer, curr_speed, max_speed)

    def test_parser_p5(self):
        port_no = ofproto_v1_2.OFPP_FLOOD
        hw_addr = 'c0:26:53:c4:29:e2'
        config = ofproto_v1_2.OFPPC_NO_PACKET_IN
        state = ofproto_v1_2.OFPPS_LIVE
        curr = advertised = supported \
             = peer = curr_speed = max_speed \
             = ofproto_v1_2.OFPPF_1GB_HD
        self._test_parser(port_no, hw_addr, config, state, curr, advertised,
                          supported, peer, curr_speed, max_speed)

    def test_parser_p6(self):
        port_no = ofproto_v1_2.OFPP_ALL
        hw_addr = 'c0:26:53:c4:29:e2'
        config = ofproto_v1_2.OFPPC_NO_PACKET_IN
        state = ofproto_v1_2.OFPPS_LIVE
        curr = advertised = supported \
             = peer = curr_speed = max_speed \
             = ofproto_v1_2.OFPPF_1GB_FD
        self._test_parser(port_no, hw_addr, config, state, curr, advertised,
                          supported, peer, curr_speed, max_speed)

    def test_parser_p7(self):
        port_no = ofproto_v1_2.OFPP_CONTROLLER
        hw_addr = 'c0:26:53:c4:29:e2'
        config = ofproto_v1_2.OFPPC_NO_PACKET_IN
        state = ofproto_v1_2.OFPPS_LIVE
        curr = advertised = supported \
             = peer = curr_speed = max_speed \
             = ofproto_v1_2.OFPPF_10GB_FD
        self._test_parser(port_no, hw_addr, config, state, curr, advertised,
                          supported, peer, curr_speed, max_speed)

    def test_parser_p8(self):
        port_no = ofproto_v1_2.OFPP_LOCAL
        hw_addr = 'c0:26:53:c4:29:e2'
        config = ofproto_v1_2.OFPPC_NO_PACKET_IN
        state = ofproto_v1_2.OFPPS_LIVE
        curr = advertised = supported \
             = peer = curr_speed = max_speed \
             = ofproto_v1_2.OFPPF_40GB_FD
        self._test_parser(port_no, hw_addr, config, state, curr, advertised,
                          supported, peer, curr_speed, max_speed)

    def test_parser_p9(self):
        port_no = ofproto_v1_2.OFPP_LOCAL
        hw_addr = 'c0:26:53:c4:29:e2'
        config = ofproto_v1_2.OFPPC_NO_PACKET_IN
        state = ofproto_v1_2.OFPPS_LIVE
        curr = advertised = supported \
             = peer = curr_speed = max_speed \
             = ofproto_v1_2.OFPPF_100GB_FD
        self._test_parser(port_no, hw_addr, config, state, curr, advertised,
                          supported, peer, curr_speed, max_speed)

    def test_parser_p10(self):
        port_no = ofproto_v1_2.OFPP_LOCAL
        hw_addr = 'c0:26:53:c4:29:e2'
        config = ofproto_v1_2.OFPPC_NO_PACKET_IN
        state = ofproto_v1_2.OFPPS_LIVE
        curr = advertised = supported \
             = peer = curr_speed = max_speed \
             = ofproto_v1_2.OFPPF_1TB_FD
        self._test_parser(port_no, hw_addr, config, state, curr, advertised,
                          supported, peer, curr_speed, max_speed)

    def test_parser_p11(self):
        port_no = ofproto_v1_2.OFPP_LOCAL
        hw_addr = 'c0:26:53:c4:29:e2'
        config = ofproto_v1_2.OFPPC_NO_PACKET_IN
        state = ofproto_v1_2.OFPPS_LIVE
        curr = advertised = supported \
             = peer = curr_speed = max_speed \
             = ofproto_v1_2.OFPPF_OTHER
        self._test_parser(port_no, hw_addr, config, state, curr, advertised,
                          supported, peer, curr_speed, max_speed)

    def test_parser_p12(self):
        port_no = ofproto_v1_2.OFPP_LOCAL
        hw_addr = 'c0:26:53:c4:29:e2'
        config = ofproto_v1_2.OFPPC_NO_PACKET_IN
        state = ofproto_v1_2.OFPPS_LIVE
        curr = advertised = supported \
             = peer = curr_speed = max_speed \
             = ofproto_v1_2.OFPPF_COPPER
        self._test_parser(port_no, hw_addr, config, state, curr, advertised,
                          supported, peer, curr_speed, max_speed)

    def test_parser_p13(self):
        port_no = ofproto_v1_2.OFPP_LOCAL
        hw_addr = 'c0:26:53:c4:29:e2'
        config = ofproto_v1_2.OFPPC_NO_PACKET_IN
        state = ofproto_v1_2.OFPPS_LIVE
        curr = advertised = supported \
             = peer = curr_speed = max_speed \
             = ofproto_v1_2.OFPPF_FIBER
        self._test_parser(port_no, hw_addr, config, state, curr, advertised,
                          supported, peer, curr_speed, max_speed)

    def test_parser_p14(self):
        port_no = ofproto_v1_2.OFPP_LOCAL
        hw_addr = 'c0:26:53:c4:29:e2'
        config = ofproto_v1_2.OFPPC_NO_PACKET_IN
        state = ofproto_v1_2.OFPPS_LIVE
        curr = advertised = supported \
             = peer = curr_speed = max_speed \
             = ofproto_v1_2.OFPPF_AUTONEG
        self._test_parser(port_no, hw_addr, config, state, curr, advertised,
                          supported, peer, curr_speed, max_speed)

    def test_parser_p15(self):
        port_no = ofproto_v1_2.OFPP_LOCAL
        hw_addr = 'c0:26:53:c4:29:e2'
        config = ofproto_v1_2.OFPPC_NO_PACKET_IN
        state = ofproto_v1_2.OFPPS_LIVE
        curr = advertised = supported \
             = peer = curr_speed = max_speed \
             = ofproto_v1_2.OFPPF_PAUSE
        self._test_parser(port_no, hw_addr, config, state, curr, advertised,
                          supported, peer, curr_speed, max_speed)

    def test_parser_p16(self):
        port_no = ofproto_v1_2.OFPP_LOCAL
        hw_addr = 'c0:26:53:c4:29:e2'
        config = ofproto_v1_2.OFPPC_NO_PACKET_IN
        state = ofproto_v1_2.OFPPS_LIVE
        curr = advertised = supported \
             = peer = curr_speed = max_speed \
             = ofproto_v1_2.OFPPF_PAUSE_ASYM
        self._test_parser(port_no, hw_addr, config, state, curr, advertised,
                          supported, peer, curr_speed, max_speed)


class TestOFPFeaturesRequest(unittest.TestCase):
    """ Test case for ofproto_v1_2_parser.OFPFeaturesRequest
    """

    def test_serialize(self):
        c = OFPFeaturesRequest(_Datapath)
        c.serialize()

        eq_(ofproto_v1_2.OFP_VERSION, c.version)
        eq_(ofproto_v1_2.OFPT_FEATURES_REQUEST, c.msg_type)
        eq_(0, c.xid)

        fmt = ofproto_v1_2.OFP_HEADER_PACK_STR

        res = struct.unpack(fmt, str(c.buf))

        eq_(res[0], ofproto_v1_2.OFP_VERSION)
        eq_(res[1], ofproto_v1_2.OFPT_FEATURES_REQUEST)
        eq_(res[2], len(c.buf))
        eq_(res[3], 0)


class TestOFPSwitchFeatures(unittest.TestCase):
    """ Test case for ofproto_v1_2_parser.OFPSwitchFeatures
    """

    def _test_parser(self, xid, datapath_id, n_buffers,
                     n_tables, capabilities, reserved, port_cnt=0):

        # OFP_HEADER_PACK_STR
        # '!BBHI'...version, msg_type, msg_len, xid
        version = ofproto_v1_2.OFP_VERSION
        msg_type = ofproto_v1_2.OFPT_FEATURES_REPLY
        msg_len = ofproto_v1_2.OFP_SWITCH_FEATURES_SIZE \
            + ofproto_v1_2.OFP_PORT_SIZE * port_cnt

        fmt = ofproto_v1_2.OFP_HEADER_PACK_STR
        buf = pack(fmt, version, msg_type, msg_len, xid)

        # OFP_SWITCH_FEATURES_PACK_STR
        # '!QIB3xII'...datapath_id, n_buffers, n_tables,
        #              pad(3), capabilities, reserved

        fmt = ofproto_v1_2.OFP_SWITCH_FEATURES_PACK_STR
        buf += pack(fmt, datapath_id, n_buffers, n_tables,
                    capabilities, reserved)

        for i in range(port_cnt):
            # OFP_PORT_PACK_STR
            # '!I4x6s2x16sIIIIIIII'... port_no, pad(4), hw_addr, pad(2),
            #                          name, config, state, curr, advertised,
            #                          peer, curr_speed, max_speed
            port_no = i

            fmt = ofproto_v1_2.OFP_PORT_PACK_STR
            buf += pack(fmt, port_no, '\x00' * 6, '\x00' * 16, 0, 0, 0,
                        0, 0, 0, 0, 0)

        res = OFPSwitchFeatures.parser(object, version, msg_type,
                                       msg_len, xid, buf)

        eq_(res.version, version)
        eq_(res.msg_type, msg_type)
        eq_(res.msg_len, msg_len)
        eq_(res.xid, xid)

        eq_(res.datapath_id, datapath_id)
        eq_(res.n_buffers, n_buffers)
        eq_(res.n_tables, n_tables)
        eq_(res.capabilities, capabilities)
        eq_(res._reserved, reserved)

        for i in range(port_cnt):
            eq_(res.ports[i].port_no, i)

    def test_parser_mid(self):
        xid = 2495926989
        datapath_id = 1270985291017894273
        n_buffers = 2148849654
        n_tables = 228
        capabilities = 1766843586
        reserved = 2013714700
        port_cnt = 1

        self._test_parser(xid, datapath_id, n_buffers, n_tables,
                          capabilities, reserved, port_cnt)

    def test_parser_max(self):
        xid = 4294967295
        datapath_id = 18446744073709551615
        n_buffers = 4294967295
        n_tables = 255
        capabilities = 4294967295
        reserved = 4294967295
        port_cnt = 1023

        self._test_parser(xid, datapath_id, n_buffers, n_tables,
                          capabilities, reserved, port_cnt)

    def test_parser_min(self):
        xid = 0
        datapath_id = 0
        n_buffers = 0
        n_tables = 0
        capabilities = 0
        reserved = 0
        port_cnt = 0

        self._test_parser(xid, datapath_id, n_buffers, n_tables,
                          capabilities, reserved, port_cnt)


class TestOFPGetConfigRequest(unittest.TestCase):
    """ Test case for ofproto_v1_2_parser.OFPGetConfigRequest
    """

    def test_serialize(self):
        c = OFPGetConfigRequest(_Datapath)
        c.serialize()

        eq_(ofproto_v1_2.OFP_VERSION, c.version)
        eq_(ofproto_v1_2.OFPT_GET_CONFIG_REQUEST, c.msg_type)
        eq_(0, c.xid)

        fmt = ofproto_v1_2.OFP_HEADER_PACK_STR

        res = struct.unpack(fmt, str(c.buf))
        eq_(res[0], ofproto_v1_2.OFP_VERSION)
        eq_(res[1], ofproto_v1_2.OFPT_GET_CONFIG_REQUEST)
        eq_(res[2], len(c.buf))
        eq_(res[3], 0)


class TestOFPGetConfigReply(unittest.TestCase):
    """ Test case for ofproto_v1_2_parser.OFPGetConfigReply
    """

    def _test_parser(self, xid, flags, miss_send_len):
        # OFP_HEADER_PACK_STR
        # '!BBHI'...version, msg_type, msg_len, xid
        version = ofproto_v1_2.OFP_VERSION
        msg_type = ofproto_v1_2.OFPT_GET_CONFIG_REPLY
        msg_len = ofproto_v1_2.OFP_SWITCH_CONFIG_SIZE

        fmt = ofproto_v1_2.OFP_HEADER_PACK_STR
        buf = pack(fmt, version, msg_type, msg_len, xid)

        # OFP_SWITCH_CONFIG_PACK_STR
        # '!HH'...flags, miss_send_len
        fmt = ofproto_v1_2.OFP_SWITCH_CONFIG_PACK_STR
        buf += pack(fmt, flags, miss_send_len)

        res = OFPGetConfigReply.parser(object, version, msg_type,
                                       msg_len, xid, buf)

        eq_(version, res.version)
        eq_(msg_type, res.msg_type)
        eq_(msg_len, res.msg_len)
        eq_(xid, res.xid)
        eq_(flags, res.flags)
        eq_(miss_send_len, res.miss_send_len)

    def test_parser_mid(self):
        xid = 3423224276
        flags = 41186
        miss_send_len = 13838
        self._test_parser(xid, flags, miss_send_len)

    def test_parser_max(self):
        xid = 4294967295
        flags = 65535
        miss_send_len = 65535
        self._test_parser(xid, flags, miss_send_len)

    def test_parser_min(self):
        xid = 0
        flags = ofproto_v1_2.OFPC_FRAG_NORMAL
        miss_send_len = 0
        self._test_parser(xid, flags, miss_send_len)

    def test_parser_p1(self):
        xid = 3423224276
        flags = ofproto_v1_2.OFPC_FRAG_DROP
        miss_send_len = 13838
        self._test_parser(xid, flags, miss_send_len)

    def test_parser_p2(self):
        xid = 3423224276
        flags = ofproto_v1_2.OFPC_FRAG_REASM
        miss_send_len = 13838
        self._test_parser(xid, flags, miss_send_len)

    def test_parser_p3(self):
        xid = 3423224276
        flags = ofproto_v1_2.OFPC_FRAG_MASK
        miss_send_len = 13838
        self._test_parser(xid, flags, miss_send_len)

    def test_parser_p4(self):
        xid = 3423224276
        flags = ofproto_v1_2.OFPC_INVALID_TTL_TO_CONTROLLER
        miss_send_len = 13838
        self._test_parser(xid, flags, miss_send_len)


class TestOFPSetConfig(unittest.TestCase):
    """ Test case for ofproto_v1_2_parser.OFPSetConfig
    """

    def test_init(self):
        # OFP_SWITCH_CONFIG_PACK_STR
        # '!HH'...flags, miss_send_len
        flags = 41186
        miss_send_len = 13838

        c = OFPSetConfig(_Datapath, flags, miss_send_len)

        eq_(flags, c.flags)
        eq_(miss_send_len, c.miss_send_len)

    def _test_serialize(self, flags, miss_send_len):
        c = OFPSetConfig(_Datapath, flags, miss_send_len)
        c.serialize()

        eq_(ofproto_v1_2.OFP_VERSION, c.version)
        eq_(ofproto_v1_2.OFPT_SET_CONFIG, c.msg_type)
        eq_(0, c.xid)

        fmt = '!' \
            + ofproto_v1_2.OFP_HEADER_PACK_STR.replace('!', '') \
            + ofproto_v1_2.OFP_SWITCH_CONFIG_PACK_STR.replace('!', '')

        res = struct.unpack(fmt, str(c.buf))

        eq_(res[0], ofproto_v1_2.OFP_VERSION)
        eq_(res[1], ofproto_v1_2.OFPT_SET_CONFIG)
        eq_(res[2], len(c.buf))
        eq_(res[3], 0)
        eq_(res[4], flags)
        eq_(res[5], miss_send_len)

    def test_serialize_mid(self):
        flags = 41186
        miss_send_len = 13838
        self._test_serialize(flags, miss_send_len)

    def test_serialize_max(self):
        flags = 65535
        miss_send_len = 65535
        self._test_serialize(flags, miss_send_len)

    def test_serialize_min(self):
        flags = ofproto_v1_2.OFPC_FRAG_NORMAL
        miss_send_len = 0
        self._test_serialize(flags, miss_send_len)

    def test_serialize_p1(self):
        flags = ofproto_v1_2.OFPC_FRAG_DROP
        miss_send_len = 13838
        self._test_serialize(flags, miss_send_len)

    def test_serialize_p2(self):
        flags = ofproto_v1_2.OFPC_FRAG_REASM
        miss_send_len = 13838
        self._test_serialize(flags, miss_send_len)

    def test_serialize_p3(self):
        flags = ofproto_v1_2.OFPC_FRAG_MASK
        miss_send_len = 13838
        self._test_serialize(flags, miss_send_len)

    def test_serialize_p4(self):
        flags = ofproto_v1_2.OFPC_INVALID_TTL_TO_CONTROLLER
        miss_send_len = 13838
        self._test_serialize(flags, miss_send_len)

    @raises(AssertionError)
    def test_serialize_check_flags(self):
        flags = None
        miss_send_len = 13838
        c = OFPSetConfig(_Datapath, flags, miss_send_len)
        c.serialize()

    @raises(AssertionError)
    def test_serialize_check_miss_send_len(self):
        flags = 41186
        miss_send_len = None
        c = OFPSetConfig(_Datapath, flags, miss_send_len)
        c.serialize()


class TestOFPPacketIn(unittest.TestCase):
    """ Test case for ofproto_v1_2_parser.OFPPacketIn
    """

    def _test_parser(self, xid, buffer_id, total_len=0,
                     reason=0, table_id=0, data=None):
        if data is None:
            data = ''

        # OFP_HEADER_PACK_STR
        # '!BBHI'...version, msg_type, msg_len, xid
        version = ofproto_v1_2.OFP_VERSION
        msg_type = ofproto_v1_2.OFPT_PACKET_IN
        msg_len = ofproto_v1_2.OFP_PACKET_IN_SIZE + len(data)

        fmt = ofproto_v1_2.OFP_HEADER_PACK_STR
        buf = pack(fmt, version, msg_type, msg_len, xid)

        # OFP_PACKET_IN_PACK_STR
        fmt = ofproto_v1_2.OFP_PACKET_IN_PACK_STR
        buf += pack(fmt, buffer_id, total_len, reason, table_id)

        # match
        buf_match = bytearray()
        match = OFPMatch()
        match.serialize(buf_match, 0)
        buf += str(buf_match)

        # data
        buf += '\x00' * 2
        buf += data

        res = OFPPacketIn.parser(object, version, msg_type, msg_len,
                                 xid, buf)

        eq_(version, res.version)
        eq_(msg_type, res.msg_type)
        eq_(msg_len, res.msg_len)
        eq_(xid, res.xid)
        eq_(buffer_id, res.buffer_id)
        eq_(total_len, res.total_len)
        eq_(reason, res.reason)
        eq_(table_id, res.table_id)
        ok_(hasattr(res, 'match'))
        eq_(ofproto_v1_2.OFPMT_OXM, res.match.type)

        if data:
            eq_(data[:total_len], res.data)

    def test_data_is_total_len(self):
        xid = 3423224276
        buffer_id = 2926809324
        reason = 128
        table_id = 3
        data = 'PacketIn'
        total_len = len(data)
        self._test_parser(xid, buffer_id, total_len, reason, table_id, data)

    def test_data_is_not_total_len(self):
        xid = 3423224276
        buffer_id = 2926809324
        reason = 128
        table_id = 3
        data = 'PacketIn'
        total_len = len(data) - 1
        self._test_parser(xid, buffer_id, total_len, reason, table_id, data)

    def test_parser_max(self):
        # 65535(!H max) - 24(without data) = 65511
        xid = 4294967295
        buffer_id = 4294967295
        reason = 255
        table_id = 255
        data = 'data'.ljust(65511)
        total_len = len(data)
        self._test_parser(xid, buffer_id, total_len, reason, table_id, data)

    def test_parser_min(self):
        xid = 0
        buffer_id = 0
        reason = ofproto_v1_2.OFPR_NO_MATCH
        table_id = 0
        total_len = 0
        self._test_parser(xid, buffer_id, total_len, reason, table_id)

    def test_parser_p1(self):
        data = 'data'.ljust(8)
        xid = 3423224276
        buffer_id = 2926809324
        total_len = len(data)
        reason = ofproto_v1_2.OFPR_ACTION
        table_id = 3
        self._test_parser(xid, buffer_id, total_len, reason, table_id, data)

    def test_parser_p2(self):
        data = 'data'.ljust(8)
        xid = 3423224276
        buffer_id = 2926809324
        total_len = len(data)
        reason = ofproto_v1_2.OFPR_INVALID_TTL
        table_id = 3
        self._test_parser(xid, buffer_id, total_len, reason, table_id, data)


class TestOFPFlowRemoved(unittest.TestCase):
    """ Test case for ofproto_v1_2_parser.OFPFlowRemoved
    """

    def _test_parser(self, xid, cookie, priority,
                     reason, table_id, duration_sec,
                     duration_nsec, idle_timeout, hard_timeout,
                     packet_count, byte_count):
        # OFP_HEADER_PACK_STR
        # '!BBHI'...version, msg_type, msg_len, xid
        version = ofproto_v1_2.OFP_VERSION
        msg_type = ofproto_v1_2.OFPT_FLOW_REMOVED
        msg_len = ofproto_v1_2.OFP_FLOW_REMOVED_SIZE

        fmt = ofproto_v1_2.OFP_HEADER_PACK_STR
        buf = pack(fmt, version, msg_type, msg_len, xid)

        # OFP_FLOW_REMOVED_PACK_STR0
        # '!QHBBIIHHQQ' ...cookie, priority, reason, table_id,
        #                  duration_sec, duration_nsec, idle_timeout,
        #                  hard_timeout, packet_count, byte_count

        fmt = ofproto_v1_2.OFP_FLOW_REMOVED_PACK_STR0
        buf += pack(fmt, cookie, priority, reason, table_id,
                    duration_sec, duration_nsec, idle_timeout,
                    hard_timeout, packet_count, byte_count)

        # OFP_MATCH_PACK_STR
        match = OFPMatch()
        buf_match = bytearray()
        match.serialize(buf_match, 0)

        buf += str(buf_match)

        res = OFPFlowRemoved.parser(object, version, msg_type,
                                    msg_len, xid, buf)

        eq_(version, res.version)
        eq_(msg_type, res.msg_type)
        eq_(msg_len, res.msg_len)
        eq_(xid, res.xid)
        eq_(cookie, res.cookie)
        eq_(priority, res.priority)
        eq_(reason, res.reason)
        eq_(table_id, res.table_id)
        eq_(duration_sec, res.duration_sec)
        eq_(duration_nsec, res.duration_nsec)
        eq_(idle_timeout, res.idle_timeout)
        eq_(hard_timeout, res.hard_timeout)
        eq_(packet_count, res.packet_count)
        eq_(byte_count, res.byte_count)
        ok_(hasattr(res, 'match'))
        eq_(ofproto_v1_2.OFPMT_OXM, res.match.type)

    def test_parser_mid(self):
        xid = 3423224276
        cookie = 178378173441633860
        priority = 718
        reason = 128
        table_id = 169
        duration_sec = 2250548154
        duration_nsec = 2492776995
        idle_timeout = 60284
        hard_timeout = 60285
        packet_count = 6489108735192644493
        byte_count = 7334344481123449724
        self._test_parser(xid, cookie, priority,
                          reason, table_id, duration_sec,
                          duration_nsec, idle_timeout, hard_timeout,
                          packet_count, byte_count)

    def test_parser_max(self):
        xid = 4294967295
        cookie = 18446744073709551615
        priority = 65535
        reason = 255
        table_id = 255
        duration_sec = 4294967295
        duration_nsec = 4294967295
        idle_timeout = 65535
        hard_timeout = 65535
        packet_count = 18446744073709551615
        byte_count = 18446744073709551615
        self._test_parser(xid, cookie, priority,
                          reason, table_id, duration_sec,
                          duration_nsec, idle_timeout, hard_timeout,
                          packet_count, byte_count)

    def test_parser_min(self):
        xid = 0
        cookie = 0
        priority = 0
        reason = ofproto_v1_2.OFPRR_IDLE_TIMEOUT
        table_id = 0
        duration_sec = 0
        duration_nsec = 0
        idle_timeout = 0
        hard_timeout = 0
        packet_count = 0
        byte_count = 0
        self._test_parser(xid, cookie, priority,
                          reason, table_id, duration_sec,
                          duration_nsec, idle_timeout, hard_timeout,
                          packet_count, byte_count)

    def test_parser_p1(self):
        xid = 3423224276
        cookie = 178378173441633860
        priority = 718
        reason = ofproto_v1_2.OFPRR_HARD_TIMEOUT
        table_id = 169
        duration_sec = 2250548154
        duration_nsec = 2492776995
        idle_timeout = 60284
        hard_timeout = 60285
        packet_count = 6489108735192644493
        byte_count = 7334344481123449724
        self._test_parser(xid, cookie, priority,
                          reason, table_id, duration_sec,
                          duration_nsec, idle_timeout, hard_timeout,
                          packet_count, byte_count)

    def test_parser_p2(self):
        xid = 3423224276
        cookie = 178378173441633860
        priority = 718
        reason = ofproto_v1_2.OFPRR_DELETE
        table_id = 169
        duration_sec = 2250548154
        duration_nsec = 2492776995
        idle_timeout = 60284
        hard_timeout = 60285
        packet_count = 6489108735192644493
        byte_count = 7334344481123449724
        self._test_parser(xid, cookie, priority,
                          reason, table_id, duration_sec,
                          duration_nsec, idle_timeout, hard_timeout,
                          packet_count, byte_count)

    def test_parser_p3(self):
        xid = 3423224276
        cookie = 178378173441633860
        priority = 718
        reason = ofproto_v1_2.OFPRR_GROUP_DELETE
        table_id = 169
        duration_sec = 2250548154
        duration_nsec = 2492776995
        idle_timeout = 60284
        hard_timeout = 60285
        packet_count = 6489108735192644493
        byte_count = 7334344481123449724
        self._test_parser(xid, cookie, priority,
                          reason, table_id, duration_sec,
                          duration_nsec, idle_timeout, hard_timeout,
                          packet_count, byte_count)


class TestOFPPortStatus(unittest.TestCase):
    """ Test case for ofproto_v1_2_parser.OFPPortStatus
    """

    def _test_parser(self, xid, reason,
                     port_no, config, state, curr, advertised,
                     supported, peer, curr_speed, max_speed):

        # OFP_HEADER_PACK_STR
        # '!BBHI'...version, msg_type, msg_len, xid
        version = ofproto_v1_2.OFP_VERSION
        msg_type = ofproto_v1_2.OFPT_PORT_STATUS
        msg_len = ofproto_v1_2.OFP_PORT_STATUS_SIZE

        fmt = ofproto_v1_2.OFP_HEADER_PACK_STR
        buf = pack(fmt, version, msg_type, msg_len, xid)

        # OFP_PORT_STATUS_PACK_STR = '!B7x' + _OFP_PORT_PACK_STR
        # '!B7x'...reason, pad(7)
        # OFP_PORT_PACK_STR
        # '!I4x6s2x16sIIIIIIII'... port_no, pad(4), hw_addr, pad(2),
        #                          name, config, state, curr, advertised,
        #                          peer, curr_speed, max_speed
        hw_addr = '80:ff:9a:e3:72:85'
        name = 'name'.ljust(16)

        fmt = ofproto_v1_2.OFP_PORT_STATUS_PACK_STR
        buf += pack(fmt, reason, port_no, addrconv.mac.text_to_bin(hw_addr),
                    name, config, state, curr, advertised,
                    supported, peer, curr_speed, max_speed)

        res = OFPPortStatus.parser(object, version, msg_type, msg_len,
                                   xid, buf)

        eq_(reason, res.reason)
        eq_(port_no, res.desc.port_no)
        eq_(hw_addr, res.desc.hw_addr)
        eq_(name, res.desc.name)
        eq_(config, res.desc.config)
        eq_(state, res.desc.state)
        eq_(curr, res.desc.curr)
        eq_(advertised, res.desc.advertised)
        eq_(supported, res.desc.supported)
        eq_(peer, res.desc.peer)
        eq_(curr_speed, res.desc.curr_speed)
        eq_(max_speed, res.desc.max_speed)

    def test_parser_mid(self):
        xid = 3423224276
        reason = 128
        port_no = 1119692796
        config = 2226555987
        state = 1678244809
        curr = 2850556459
        advertised = 2025421682
        supported = 2120575149
        peer = 2757463021
        curr_speed = 2641353507
        max_speed = 1797291672
        self._test_parser(xid, reason,
                          port_no, config, state, curr, advertised,
                          supported, peer, curr_speed, max_speed)

    def test_parser_max(self):
        xid = 4294967295
        reason = 255
        port_no = ofproto_v1_2.OFPP_ANY
        config = 4294967295
        state = 4294967295
        curr = 4294967295
        advertised = 4294967295
        supported = 4294967295
        peer = 4294967295
        curr_speed = 4294967295
        max_speed = 4294967295
        self._test_parser(xid, reason,
                          port_no, config, state, curr, advertised,
                          supported, peer, curr_speed, max_speed)

    def test_parser_min(self):
        xid = 0
        reason = 0
        port_no = 0
        config = 0
        state = 0
        curr = 0
        advertised = 0
        supported = 0
        peer = 0
        curr_speed = 0
        max_speed = 0
        self._test_parser(xid, reason,
                          port_no, config, state, curr, advertised,
                          supported, peer, curr_speed, max_speed)

    def test_parser_p1(self):
        xid = 3423224276
        reason = ofproto_v1_2.OFPPR_DELETE
        port_no = ofproto_v1_2.OFPP_MAX
        config = ofproto_v1_2.OFPPC_PORT_DOWN
        state = ofproto_v1_2.OFPPS_LINK_DOWN
        curr = advertised = supported \
             = peer = curr_speed = max_speed \
             = ofproto_v1_2.OFPPF_10MB_HD
        self._test_parser(xid, reason,
                          port_no, config, state, curr, advertised,
                          supported, peer, curr_speed, max_speed)

    def test_parser_p2(self):
        xid = 3423224276
        reason = ofproto_v1_2.OFPPR_MODIFY
        port_no = ofproto_v1_2.OFPP_MAX
        config = ofproto_v1_2.OFPPC_PORT_DOWN
        state = ofproto_v1_2.OFPPS_LINK_DOWN
        curr = advertised = supported \
             = peer = curr_speed = max_speed \
             = ofproto_v1_2.OFPPF_10MB_HD
        self._test_parser(xid, reason,
                          port_no, config, state, curr, advertised,
                          supported, peer, curr_speed, max_speed)


class TestOFPPacketOut(unittest.TestCase):
    """ Test case for ofproto_v1_2_parser.OFPPacketOut
    """

    def _test_init(self, in_port):
        buffer_id = 0xffffffff
        data = 'Message'
        out_port = 0x00002ae0
        actions = [OFPActionOutput(out_port, 0)]

        c = OFPPacketOut(_Datapath, buffer_id, in_port, actions, data)

        eq_(buffer_id, c.buffer_id)
        eq_(in_port, c.in_port)
        eq_(0, c.actions_len)
        eq_(data, c.data)
        eq_(actions, c.actions)

    def test_init(self):
        in_port = 0x00040455
        self._test_init(in_port)

    @raises(AssertionError)
    def test_init_check_in_port(self):
        in_port = None
        self._test_init(in_port)

    def _test_serialize(self, buffer_id, in_port, action_cnt=0, data=None):
        actions = []
        for i in range(action_cnt):
            actions.append(ofproto_v1_2_parser.OFPActionOutput(i, 0))

        c = OFPPacketOut(_Datapath, buffer_id, in_port, actions, data)
        c.serialize()

        eq_(ofproto_v1_2.OFP_VERSION, c.version)
        eq_(ofproto_v1_2.OFPT_PACKET_OUT, c.msg_type)
        eq_(0, c.xid)

        fmt = ofproto_v1_2.OFP_HEADER_PACK_STR \
            + ofproto_v1_2.OFP_PACKET_OUT_PACK_STR[1:] \
            + ofproto_v1_2.OFP_ACTION_OUTPUT_PACK_STR[1:] * action_cnt

        if data is not None:
            fmt += str(len(data)) + 's'

        res = struct.unpack(fmt, str(c.buf))

        eq_(res[0], ofproto_v1_2.OFP_VERSION)
        eq_(res[1], ofproto_v1_2.OFPT_PACKET_OUT)
        eq_(res[2], len(c.buf))
        eq_(res[3], 0)
        eq_(res[4], buffer_id)
        eq_(res[5], in_port)
        eq_(res[6], ofproto_v1_2.OFP_ACTION_OUTPUT_SIZE * action_cnt)

        for i in range(action_cnt):
            index = 7 + i * 4
            eq_(res[index], ofproto_v1_2.OFPAT_OUTPUT)
            eq_(res[index + 1], ofproto_v1_2.OFP_ACTION_OUTPUT_SIZE)
            eq_(res[index + 2], i)
            eq_(res[index + 3], 0)

        if data:
            eq_(res[-1], data)

    def test_serialize_true(self):
        buffer_id = 0xffffffff
        in_port = 0x00040455
        action_cnt = 2
        data = 'Message'
        self._test_serialize(buffer_id, in_port, action_cnt, data)

    def test_serialize_none(self):
        buffer_id = 0xffffffff
        in_port = 0x00040455
        self._test_serialize(buffer_id, in_port)

    def test_serialize_max(self):
        buffer_id = 0xffffffff
        in_port = 4294967295
        action_cnt = 1
        data = "Message".ljust(65495)
        self._test_serialize(buffer_id, in_port, action_cnt, data)

    def test_serialize_min(self):
        buffer_id = 0
        in_port = 0
        self._test_serialize(buffer_id, in_port)

    def test_serialize_p1(self):
        buffer_id = 2147483648
        in_port = ofproto_v1_2.OFPP_CONTROLLER
        self._test_serialize(buffer_id, in_port)

    @raises(AssertionError)
    def test_serialize_check_buffer_id(self):
        buffer_id = 2147483648
        in_port = 1
        action_cnt = 0
        data = 'DATA'
        self._test_serialize(buffer_id, in_port, action_cnt, data)


class TestOFPFlowMod(unittest.TestCase):
    """ Test case for ofproto_v1_2_parser.OFPFlowMod
    """

    def test_init(self):
        # OFP_FLOW_MOD_PACK_STR0
        # '!QQBBHHHIIIH2x'...cookie, cookie_mask, table_id, command,
        #                    idle_timeout, hard_timeout, priority, buffer_id,
        #                    out_port, out_group, flags
        cookie = 2127614848199081640
        cookie_mask = 2127614848199081641
        table_id = 3
        command = 0
        idle_timeout = 62317
        hard_timeout = 7365
        priority = 40163
        buffer_id = 4037115955
        out_port = 65037
        out_group = 6606
        flags = 135
        instructions = [OFPInstructionGotoTable(table_id)]

        in_port = 1
        match = OFPMatch()
        match.set_in_port(in_port)

        c = OFPFlowMod(_Datapath, cookie, cookie_mask, table_id, command,
                       idle_timeout, hard_timeout, priority, buffer_id,
                       out_port, out_group, flags, match, instructions)

        eq_(cookie, c.cookie)
        eq_(cookie_mask, c.cookie_mask)
        eq_(table_id, c.table_id)
        eq_(command, c.command)
        eq_(idle_timeout, c.idle_timeout)
        eq_(hard_timeout, c.hard_timeout)
        eq_(priority, c.priority)
        eq_(buffer_id, c.buffer_id)
        eq_(out_port, c.out_port)
        eq_(out_group, c.out_group)
        eq_(flags, c.flags)
        eq_(in_port, c.match._flow.in_port)
        eq_(instructions[0], c.instructions[0])

    def _test_serialize(self, cookie, cookie_mask, table_id,
                        command, idle_timeout, hard_timeout,
                        priority, buffer_id, out_port,
                        out_group, flags, inst_cnt=0):
        dl_type = 0x0800
        match = OFPMatch()
        match.set_dl_type(dl_type)

        insts = []
        for i in range(inst_cnt):
            insts.append(OFPInstructionGotoTable(i))

        c = OFPFlowMod(_Datapath, cookie, cookie_mask, table_id, command,
                       idle_timeout, hard_timeout, priority, buffer_id,
                       out_port, out_group, flags, match, insts)
        c.serialize()

        eq_(ofproto_v1_2.OFP_VERSION, c.version)
        eq_(ofproto_v1_2.OFPT_FLOW_MOD, c.msg_type)
        eq_(0, c.xid)

        fmt = ofproto_v1_2.OFP_HEADER_PACK_STR \
            + ofproto_v1_2.OFP_FLOW_MOD_PACK_STR0[1:] \
            + 'HHHBB' \
            + MTEthType.pack_str[1:] + '6x' \
            + ofproto_v1_2.OFP_INSTRUCTION_GOTO_TABLE_PACK_STR[1:] * inst_cnt

        res = struct.unpack(fmt, str(c.buf))

        eq_(res[0], ofproto_v1_2.OFP_VERSION)
        eq_(res[1], ofproto_v1_2.OFPT_FLOW_MOD)
        eq_(res[2], len(c.buf))
        eq_(res[3], 0)
        eq_(res[4], cookie)
        eq_(res[5], cookie_mask)
        eq_(res[6], table_id)
        eq_(res[7], command)
        eq_(res[8], idle_timeout)
        eq_(res[9], hard_timeout)
        eq_(res[10], priority)
        eq_(res[11], buffer_id)
        eq_(res[12], out_port)
        eq_(res[13], out_group)
        eq_(res[14], flags)

        # OFP_MATCH (type, length, class, [field, hashmask], n_byte, ip_proto)
        eq_(res[15], ofproto_v1_2.OFPMT_OXM)
        eq_(res[16], 10)  # OFP_MATCH_STR + MTEthType.pack_str
        eq_(res[17], ofproto_v1_2.OFPXMC_OPENFLOW_BASIC)
        eq_(res[18] >> 1, ofproto_v1_2.OFPXMT_OFB_ETH_TYPE)
        eq_(res[18] & 0b0001, 0)
        eq_(res[19], calcsize(MTEthType.pack_str))
        eq_(res[20], dl_type)

        # insts (type, length, table_id)
        for i in range(inst_cnt):
            index = 21 + 3 * i
            eq_(res[index], ofproto_v1_2.OFPIT_GOTO_TABLE)
            eq_(res[index + 1], ofproto_v1_2.OFP_INSTRUCTION_GOTO_TABLE_SIZE)
            eq_(res[index + 2], i)

    def test_serialize_mid(self):
        cookie = 2127614848199081640
        cookie_mask = 2127614848199081641
        table_id = 3
        command = 128
        idle_timeout = 62317
        hard_timeout = 7365
        priority = 40163
        buffer_id = 4037115955
        out_port = 65037
        out_group = 6606
        flags = 135
        inst_cnt = 1
        self._test_serialize(cookie, cookie_mask, table_id,
                             command, idle_timeout, hard_timeout,
                             priority, buffer_id, out_port,
                             out_group, flags, inst_cnt)

    def test_serialize_max(self):
        cookie = 18446744073709551615
        cookie_mask = 18446744073709551615
        table_id = 255
        command = 255
        idle_timeout = 65535
        hard_timeout = 65535
        priority = 65535
        buffer_id = 0xffffffff
        out_port = 0xffffffff
        out_group = 0xffffffff
        flags = 65535
        inst_cnt = 0xff
        self._test_serialize(cookie, cookie_mask, table_id,
                             command, idle_timeout, hard_timeout,
                             priority, buffer_id, out_port,
                             out_group, flags, inst_cnt)

    def test_serialize_min(self):
        cookie = 0
        cookie_mask = 0
        table_id = 0
        command = ofproto_v1_2.OFPFC_ADD
        idle_timeout = 0
        hard_timeout = 0
        priority = 0
        buffer_id = 0
        out_port = 0
        out_group = 0
        flags = 0
        self._test_serialize(cookie, cookie_mask, table_id,
                             command, idle_timeout, hard_timeout,
                             priority, buffer_id, out_port,
                             out_group, flags)

    def test_serialize_p1(self):
        cookie = 2127614848199081640
        cookie_mask = 2127614848199081641
        table_id = 3
        command = 1
        idle_timeout = 62317
        hard_timeout = 7365
        priority = 40163
        buffer_id = 4037115955
        out_port = 65037
        out_group = 6606
        flags = 1 << 0
        self._test_serialize(cookie, cookie_mask, table_id,
                             command, idle_timeout, hard_timeout,
                             priority, buffer_id, out_port,
                             out_group, flags)

    def test_serialize_p2(self):
        cookie = 2127614848199081640
        cookie_mask = 2127614848199081641
        table_id = 3
        command = 2
        idle_timeout = 62317
        hard_timeout = 7365
        priority = 40163
        buffer_id = 4037115955
        out_port = 65037
        out_group = 6606
        flags = 1 << 0
        self._test_serialize(cookie, cookie_mask, table_id,
                             command, idle_timeout, hard_timeout,
                             priority, buffer_id, out_port,
                             out_group, flags)

    def test_serialize_p3(self):
        cookie = 2127614848199081640
        cookie_mask = 2127614848199081641
        table_id = 3
        command = 3
        idle_timeout = 62317
        hard_timeout = 7365
        priority = 40163
        buffer_id = 4037115955
        out_port = 65037
        out_group = 6606
        flags = 1 << 1
        self._test_serialize(cookie, cookie_mask, table_id,
                             command, idle_timeout, hard_timeout,
                             priority, buffer_id, out_port,
                             out_group, flags)

    def test_serialize_p4(self):
        cookie = 2127614848199081640
        cookie_mask = 2127614848199081641
        table_id = 3
        command = 4
        idle_timeout = 62317
        hard_timeout = 7365
        priority = 40163
        buffer_id = 4037115955
        out_port = 65037
        out_group = 6606
        flags = 1 << 2
        self._test_serialize(cookie, cookie_mask, table_id,
                             command, idle_timeout, hard_timeout,
                             priority, buffer_id, out_port,
                             out_group, flags)


class TestOFPInstructionGotoTable(unittest.TestCase):
    """ Test case for ofproto_v1_2_parser.OFPInstructionGotoTable
    """

    # OFP_INSTRUCTION_GOTO_TABLE_PACK_STR
    # '!HHB3x'...type, len, table_id, pad(3)
    type_ = ofproto_v1_2.OFPIT_GOTO_TABLE
    len_ = ofproto_v1_2.OFP_INSTRUCTION_GOTO_TABLE_SIZE

    fmt = ofproto_v1_2.OFP_INSTRUCTION_GOTO_TABLE_PACK_STR

    def test_init(self):
        table_id = 3
        c = OFPInstructionGotoTable(table_id)

        eq_(self.type_, c.type)
        eq_(self.len_, c.len)
        eq_(table_id, c.table_id)

    def _test_parser(self, table_id):
        buf = pack(self.fmt, self.type_, self.len_, table_id)
        res = OFPInstructionGotoTable.parser(buf, 0)

        eq_(res.len, self.len_)
        eq_(res.type, self.type_)
        eq_(res.table_id, table_id)

    def test_parser_mid(self):
        self._test_parser(3)

    def test_parser_max(self):
        self._test_parser(255)

    def test_parser_min(self):
        self._test_parser(0)

    def _test_serialize(self, table_id):
        c = OFPInstructionGotoTable(table_id)

        buf = bytearray()
        c.serialize(buf, 0)

        res = struct.unpack(self.fmt, buffer(buf))
        eq_(res[0], self.type_)
        eq_(res[1], self.len_)
        eq_(res[2], table_id)

    def test_serialize_mid(self):
        self._test_serialize(3)

    def test_serialize_max(self):
        self._test_serialize(255)

    def test_serialize_min(self):
        self._test_serialize(0)


class TestOFPInstructionWriteMetadata(unittest.TestCase):
    """ Test case for ofproto_v1_2_parser.OFPInstructionWriteMetadata
    """

    # OFP_INSTRUCTION_WRITE_METADATA_PACK_STR
    # '!HH4xQQ'...type, len, pad(4), metadata, metadata_mask
    type_ = ofproto_v1_2.OFPIT_WRITE_METADATA
    len_ = ofproto_v1_2.OFP_INSTRUCTION_WRITE_METADATA_SIZE
    metadata = 0x1212121212121212
    metadata_mask = 0xff00ff00ff00ff00

    fmt = ofproto_v1_2.OFP_INSTRUCTION_WRITE_METADATA_PACK_STR

    def test_init(self):
        c = OFPInstructionWriteMetadata(self.metadata,
                                        self.metadata_mask)

        eq_(self.type_, c.type)
        eq_(self.len_, c.len)
        eq_(self.metadata, c.metadata)
        eq_(self.metadata_mask, c.metadata_mask)

    def _test_parser(self, metadata, metadata_mask):
        buf = pack(self.fmt, self.type_, self.len_,
                   metadata, metadata_mask)

        res = OFPInstructionWriteMetadata.parser(buf, 0)
        eq_(res.len, self.len_)
        eq_(res.type, self.type_)
        eq_(res.metadata, metadata)
        eq_(res.metadata_mask, metadata_mask)

    def test_parser_metadata_mid(self):
        self._test_parser(self.metadata, self.metadata_mask)

    def test_parser_metadata_max(self):
        metadata = 0xffffffffffffffff
        self._test_parser(metadata, self.metadata_mask)

    def test_parser_metadata_min(self):
        metadata = 0
        self._test_parser(metadata, self.metadata_mask)

    def test_parser_metadata_mask_max(self):
        metadata_mask = 0xffffffffffffffff
        self._test_parser(self.metadata, metadata_mask)

    def test_parser_metadata_mask_min(self):
        metadata_mask = 0
        self._test_parser(self.metadata, metadata_mask)

    def _test_serialize(self, metadata, metadata_mask):
        c = OFPInstructionWriteMetadata(metadata,
                                        metadata_mask)

        buf = bytearray()
        c.serialize(buf, 0)

        res = struct.unpack(self.fmt, buffer(buf))
        eq_(res[0], self.type_)
        eq_(res[1], self.len_)
        eq_(res[2], metadata)
        eq_(res[3], metadata_mask)

    def test_serialize_metadata_mid(self):
        self._test_serialize(self.metadata, self.metadata_mask)

    def test_serialize_metadata_max(self):
        metadata = 0xffffffffffffffff
        self._test_serialize(metadata, self.metadata_mask)

    def test_serialize_metadata_min(self):
        metadata = 0
        self._test_serialize(metadata, self.metadata_mask)

    def test_serialize_metadata_mask_max(self):
        metadata_mask = 0xffffffffffffffff
        self._test_serialize(self.metadata, metadata_mask)

    def test_serialize_metadata_mask_min(self):
        metadata_mask = 0
        self._test_serialize(self.metadata, metadata_mask)


class TestOFPInstructionActions(unittest.TestCase):
    """ Test case for ofproto_v1_2_parser.OFPInstructionActions
    """
    # OFP_INSTRUCTION_ACTIONS_PACK_STR
    # '!HH4x'...type, len, pad(4)
    type_ = ofproto_v1_2.OFPIT_WRITE_ACTIONS
    len_ = ofproto_v1_2.OFP_INSTRUCTION_ACTIONS_SIZE \
        + ofproto_v1_2.OFP_ACTION_OUTPUT_SIZE

    fmt = ofproto_v1_2.OFP_INSTRUCTION_ACTIONS_PACK_STR
    buf = pack(fmt, type_, len_)

    # OFP_ACTION (OFP_ACTION_OUTPUT)
    port = 0x00002ae0
    max_len = ofproto_v1_2.OFP_ACTION_OUTPUT_SIZE
    actions = [OFPActionOutput(port, max_len)]
    buf_actions = bytearray()
    actions[0].serialize(buf_actions, 0)

    buf += str(buf_actions)

    def test_init(self):
        c = OFPInstructionActions(self.type_, self.actions)

        eq_(self.type_, c.type)
        eq_(self.actions, c.actions)

    def _test_parser(self, action_cnt):
        # OFP_INSTRUCTION_ACTIONS_PACK_STR
        # '!HH4x'...type, len, pad(4)
        len_ = ofproto_v1_2.OFP_INSTRUCTION_ACTIONS_SIZE \
            + (ofproto_v1_2.OFP_ACTION_OUTPUT_SIZE * action_cnt)

        fmt = ofproto_v1_2.OFP_INSTRUCTION_ACTIONS_PACK_STR
        buf = pack(fmt, self.type_, len_)

        actions = []
        for a in range(action_cnt):
            # OFP_ACTION (OFP_ACTION_OUTPUT)
            port = a
            action = OFPActionOutput(port, self.max_len)
            actions.append(action)
            buf_actions = bytearray()
            actions[a].serialize(buf_actions, 0)
            buf += str(buf_actions)

        res = OFPInstructionActions.parser(buf, 0)

        # 8
        eq_(res.len, len_)
        eq_(res.type, self.type_)

        # 8 + 16 * action_cnt < 65535 byte
        # action_cnt <= 4095
        for a in range(action_cnt):
            eq_(res.actions[a].type, actions[a].type)
            eq_(res.actions[a].len, actions[a].len)
            eq_(res.actions[a].port, actions[a].port)
            eq_(res.actions[a].max_len, actions[a].max_len)

    def test_parser_mid(self):
        self._test_parser(2047)

    def test_parser_max(self):
        self._test_parser(4095)

    def test_parser_min(self):
        self._test_parser(0)

    def _test_serialize(self, action_cnt):
        # OFP_INSTRUCTION_ACTIONS_PACK_STR
        # '!HH4x'...type, len, pad(4)
        len_ = ofproto_v1_2.OFP_INSTRUCTION_ACTIONS_SIZE \
            + (ofproto_v1_2.OFP_ACTION_OUTPUT_SIZE * action_cnt)

        actions = []
        for a in range(action_cnt):
            # OFP_ACTION (OFP_ACTION_OUTPUT)
            port = a
            action = OFPActionOutput(port, self.max_len)
            actions.append(action)

        c = OFPInstructionActions(self.type_, actions)

        buf = bytearray()
        c.serialize(buf, 0)

        fmt = '!' \
            + ofproto_v1_2.OFP_INSTRUCTION_ACTIONS_PACK_STR.replace('!', '')

        for a in range(action_cnt):
            fmt += ofproto_v1_2.OFP_ACTION_OUTPUT_PACK_STR.replace('!', '')
        res = struct.unpack(fmt, buffer(buf))

        eq_(res[0], self.type_)
        eq_(res[1], len_)

        for a in range(action_cnt):
            d = 2 + a * 4
            eq_(res[d], actions[a].type)
            eq_(res[d + 1], actions[a].len)
            eq_(res[d + 2], actions[a].port)
            eq_(res[d + 3], actions[a].max_len)

    def test_serialize_mid(self):
        self._test_serialize(2047)

    def test_serialize_max(self):
        self._test_serialize(4095)

    def test_serialize_min(self):
        self._test_serialize(0)


class TestOFPActionHeader(unittest.TestCase):
    """ Test case for ofproto_v1_2_parser.OFPActionHeader
    """

    def test_init(self):
        # OFP_ACTION_HEADER_PACK_STR
        # '!HH4x'...type, len, pad(4)
        type_ = ofproto_v1_2.OFPAT_OUTPUT
        len_ = ofproto_v1_2.OFP_ACTION_HEADER_SIZE

        fmt = ofproto_v1_2.OFP_ACTION_HEADER_PACK_STR
        buf = pack(fmt, type_, len_)

        c = OFPActionHeader(type_, len_)

        eq_(type_, c.type)
        eq_(len_, c.len)

    def _test_serialize(self, type_, len_):
        # OFP_ACTION_HEADER_PACK_STR
        # '!HH4x'...type, len, pad(4)

        fmt = ofproto_v1_2.OFP_ACTION_HEADER_PACK_STR
        buf = pack(fmt, type_, len_)

        c = OFPActionHeader(type_, len_)

        buf = bytearray()
        c.serialize(buf, 0)

        fmt = ofproto_v1_2.OFP_ACTION_HEADER_PACK_STR
        res = struct.unpack(fmt, buffer(buf))

        eq_(res[0], type_)
        eq_(res[1], len_)

    def test_serialize_mid(self):
        type_ = 11
        len_ = 8
        self._test_serialize(type_, len_)

    def test_serialize_max(self):
        type_ = 0xffff
        len_ = 0xffff
        self._test_serialize(type_, len_)

    def test_serialize_min(self):
        type_ = 0
        len_ = 0
        self._test_serialize(type_, len_)


class TestOFPActionOutput(unittest.TestCase):
    """ Test case for ofproto_v1_2_parser.OFPActionOutput
    """

    # OFP_ACTION_OUTPUT_PACK_STR
    # '!HHIH6x'...type, len, port, max_len, pad(6)
    type_ = ofproto_v1_2.OFPAT_OUTPUT
    len_ = ofproto_v1_2.OFP_ACTION_OUTPUT_SIZE

    def test_init(self):
        port = 6606
        max_len = 1500
        fmt = ofproto_v1_2.OFP_ACTION_OUTPUT_PACK_STR
        c = OFPActionOutput(port, max_len)
        eq_(port, c.port)
        eq_(max_len, c.max_len)

    def _test_parser(self, port, max_len):
        fmt = ofproto_v1_2.OFP_ACTION_OUTPUT_PACK_STR
        buf = pack(fmt, self.type_, self.len_, port, max_len)

        c = OFPActionOutput(port, max_len)

        res = c.parser(buf, 0)

        eq_(res.len, self.len_)
        eq_(res.type, self.type_)
        eq_(res.port, port)
        eq_(res.max_len, max_len)

    def test_parser_mid(self):
        port = 6606
        max_len = 16
        self._test_parser(port, max_len)

    def test_parser_max(self):
        port = 4294967295
        max_len = 0xffff
        self._test_parser(port, max_len)

    def test_parser_min(self):
        port = 0
        max_len = 0
        self._test_parser(port, max_len)

    def test_parser_p1(self):
        port = 6606
        max_len = 0xffe5
        self._test_parser(port, max_len)

    def _test_serialize(self, port, max_len):
        c = OFPActionOutput(port, max_len)

        buf = bytearray()
        c.serialize(buf, 0)

        fmt = ofproto_v1_2.OFP_ACTION_OUTPUT_PACK_STR
        res = struct.unpack(fmt, buffer(buf))
        eq_(res[0], self.type_)
        eq_(res[1], self.len_)
        eq_(res[2], port)
        eq_(res[3], max_len)

    def test_serialize_mid(self):
        port = 6606
        max_len = 16
        self._test_serialize(port, max_len)

    def test_serialize_max(self):
        port = 4294967295
        max_len = 0xffff
        self._test_serialize(port, max_len)

    def test_serialize_min(self):
        port = 0
        max_len = 0
        self._test_serialize(port, max_len)

    def test_serialize_p1(self):
        port = 6606
        max_len = 0xffe5
        self._test_serialize(port, max_len)


class TestOFPActionGroup(unittest.TestCase):
    """ Test case for ofproto_v1_2_parser.OFPActionGroup
    """

    # OFP_ACTION_GROUP_PACK_STR
    # '!HHI'...type, len, group_id
    type_ = ofproto_v1_2.OFPAT_GROUP
    len_ = ofproto_v1_2.OFP_ACTION_GROUP_SIZE
    group_id = 6606

    fmt = ofproto_v1_2.OFP_ACTION_GROUP_PACK_STR

    def test_init(self):
        c = OFPActionGroup(self.group_id)
        eq_(self.group_id, c.group_id)

    def _test_parser(self, group_id):
        buf = pack(self.fmt, self.type_, self.len_, group_id)

        res = OFPActionGroup.parser(buf, 0)
        eq_(res.len, self.len_)
        eq_(res.type, self.type_)
        eq_(res.group_id, group_id)

    def test_parser_mid(self):
        self._test_parser(self.group_id)

    def test_parser_max(self):
        self._test_parser(4294967295)

    def test_parser_min(self):
        self._test_parser(0)

    def _test_serialize(self, group_id):
        c = OFPActionGroup(group_id)

        buf = bytearray()
        c.serialize(buf, 0)

        res = struct.unpack(self.fmt, buffer(buf))
        eq_(res[0], self.type_)
        eq_(res[1], self.len_)
        eq_(res[2], group_id)

    def test_serialize_mid(self):
        self._test_serialize(self.group_id)

    def test_serialize_max(self):
        self._test_serialize(4294967295)

    def test_serialize_min(self):
        self._test_serialize(0)


class TestOFPActionSetQueue(unittest.TestCase):
    """ Test case for ofproto_v1_2_parser.OFPActionSetQueue
    """

    # OFP_ACTION_SET_QUEUE_PACK_STR
    # '!HHI'...type, len, queue_id
    type_ = ofproto_v1_2.OFPAT_SET_QUEUE
    len_ = ofproto_v1_2.OFP_ACTION_SET_QUEUE_SIZE
    queue_id = 6606

    fmt = ofproto_v1_2.OFP_ACTION_SET_QUEUE_PACK_STR

    def test_init(self):
        c = OFPActionSetQueue(self.queue_id)
        eq_(self.queue_id, c.queue_id)

    def _test_parser(self, queue_id):
        buf = pack(self.fmt, self.type_, self.len_, queue_id)

        res = OFPActionSetQueue.parser(buf, 0)
        eq_(res.len, self.len_)
        eq_(res.type, self.type_)
        eq_(res.queue_id, queue_id)

    def test_parser_mid(self):
        self._test_parser(self.queue_id)

    def test_parser_max(self):
        self._test_parser(4294967295)

    def test_parser_min(self):
        self._test_parser(0)

    def _test_serialize(self, queue_id):
        c = OFPActionSetQueue(queue_id)

        buf = bytearray()
        c.serialize(buf, 0)

        res = struct.unpack(self.fmt, buffer(buf))
        eq_(res[0], self.type_)
        eq_(res[1], self.len_)
        eq_(res[2], queue_id)

    def test_serialize_mid(self):
        self._test_serialize(self.queue_id)

    def test_serialize_max(self):
        self._test_serialize(4294967295)

    def test_serialize_min(self):
        self._test_serialize(0)


class TestOFPActionSetMplsTtl(unittest.TestCase):
    """ Test case for ofproto_v1_2_parser.OFPActionSetMplsTtl
    """

    # OFP_ACTION_MPLS_TTL_PACK_STR
    # '!HHB3x'...type, len, mpls_ttl, pad(3)
    type_ = ofproto_v1_2.OFPAT_SET_MPLS_TTL
    len_ = ofproto_v1_2.OFP_ACTION_MPLS_TTL_SIZE
    mpls_ttl = 254

    fmt = ofproto_v1_2.OFP_ACTION_MPLS_TTL_PACK_STR

    def test_init(self):
        c = OFPActionSetMplsTtl(self.mpls_ttl)
        eq_(self.mpls_ttl, c.mpls_ttl)

    def _test_parser(self, mpls_ttl):
        buf = pack(self.fmt, self.type_, self.len_, mpls_ttl)

        res = OFPActionSetMplsTtl.parser(buf, 0)
        eq_(res.len, self.len_)
        eq_(res.type, self.type_)
        eq_(res.mpls_ttl, mpls_ttl)

    def test_parser_mid(self):
        self._test_parser(self.mpls_ttl)

    def test_parser_max(self):
        self._test_parser(255)

    def test_parser_min(self):
        self._test_parser(0)

    def _test_serialize(self, mpls_ttl):
        c = OFPActionSetMplsTtl(mpls_ttl)

        buf = bytearray()
        c.serialize(buf, 0)

        res = struct.unpack(self.fmt, buffer(buf))
        eq_(res[0], self.type_)
        eq_(res[1], self.len_)
        eq_(res[2], mpls_ttl)

    def test_serialize_mid(self):
        self._test_serialize(self.mpls_ttl)

    def test_serialize_max(self):
        self._test_serialize(255)

    def test_serialize_min(self):
        self._test_serialize(0)


class TestOFPActionDecMplsTtl(unittest.TestCase):
    """ Test case for ofproto_v1_2_parser.OFPActionDecMplsTtl
    """

    type_ = ofproto_v1_2.OFPAT_DEC_MPLS_TTL
    len_ = ofproto_v1_2.OFP_ACTION_MPLS_TTL_SIZE
    fmt = ofproto_v1_2.OFP_ACTION_HEADER_PACK_STR
    buf = pack(fmt, type_, len_)
    c = OFPActionDecMplsTtl()

    def test_parser(self):
        res = self.c.parser(self.buf, 0)

        eq_(res.len, self.len_)
        eq_(res.type, self.type_)

    def test_serialize(self):
        buf = bytearray()
        self.c.serialize(buf, 0)

        res = struct.unpack(self.fmt, buffer(buf))
        eq_(res[0], self.type_)
        eq_(res[1], self.len_)


class TestOFPActionSetNwTtl(unittest.TestCase):
    """ Test case for ofproto_v1_2_parser.OFPActionSetNwTtl
    """

    # OFP_ACTION_NW_TTL_PACK_STR
    # '!HHB3x'...type, len, nw_ttl, pad(3)
    type_ = ofproto_v1_2.OFPAT_SET_NW_TTL
    len_ = ofproto_v1_2.OFP_ACTION_NW_TTL_SIZE
    nw_ttl = 240

    fmt = ofproto_v1_2.OFP_ACTION_NW_TTL_PACK_STR

    def test_init(self):
        c = OFPActionSetNwTtl(self.nw_ttl)
        eq_(self.nw_ttl, c.nw_ttl)

    def _test_parser(self, nw_ttl):
        buf = pack(self.fmt, self.type_, self.len_, nw_ttl)

        res = OFPActionSetNwTtl.parser(buf, 0)
        eq_(res.type, self.type_)
        eq_(res.len, self.len_)
        eq_(res.nw_ttl, nw_ttl)

    def test_parser_mid(self):
        self._test_parser(self.nw_ttl)

    def test_parser_max(self):
        self._test_parser(255)

    def test_parser_min(self):
        self._test_parser(0)

    def _test_serialize(self, nw_ttl):
        c = OFPActionSetNwTtl(nw_ttl)

        buf = bytearray()
        c.serialize(buf, 0)

        res = struct.unpack(self.fmt, buffer(buf))
        eq_(res[0], self.type_)
        eq_(res[1], self.len_)
        eq_(res[2], nw_ttl)

    def test_serialize_mid(self):
        self._test_serialize(self.nw_ttl)

    def test_serialize_max(self):
        self._test_serialize(255)

    def test_serialize_min(self):
        self._test_serialize(0)


class TestOFPActionDecNwTtl(unittest.TestCase):
    """ Test case for ofproto_v1_2_parser.OFPActionDecNwTtl
    """

    type_ = ofproto_v1_2.OFPAT_DEC_NW_TTL
    len_ = ofproto_v1_2.OFP_ACTION_NW_TTL_SIZE
    fmt = ofproto_v1_2.OFP_ACTION_HEADER_PACK_STR
    buf = pack(fmt, type_, len_)
    c = OFPActionDecNwTtl()

    def test_parser(self):
        res = self.c.parser(self.buf, 0)

        eq_(res.len, self.len_)
        eq_(res.type, self.type_)

    def test_serialize(self):
        buf = bytearray()
        self.c.serialize(buf, 0)

        res = struct.unpack(self.fmt, buffer(buf))
        eq_(res[0], self.type_)
        eq_(res[1], self.len_)


class TestOFPActionCopyTtlOut(unittest.TestCase):
    """ Test case for ofproto_v1_2_parser.OFPActionCopyTtlOut
    """

    type_ = ofproto_v1_2.OFPAT_COPY_TTL_OUT
    len_ = ofproto_v1_2.OFP_ACTION_HEADER_SIZE
    fmt = ofproto_v1_2.OFP_ACTION_HEADER_PACK_STR
    buf = pack(fmt, type_, len_)
    c = OFPActionCopyTtlOut()

    def test_parser(self):
        res = self.c.parser(self.buf, 0)
        eq_(res.len, self.len_)
        eq_(res.type, self.type_)

    def test_serialize(self):
        buf = bytearray()
        self.c.serialize(buf, 0)

        res = struct.unpack(self.fmt, buffer(buf))
        eq_(res[0], self.type_)
        eq_(res[1], self.len_)


class TestOFPActionCopyTtlIn(unittest.TestCase):
    """ Test case for ofproto_v1_2_parser.OFPActionCopyTtlIn
    """

    # OFP_ACTION_HEADER_PACK_STR
    # '!HH'...type, len
    type_ = ofproto_v1_2.OFPAT_COPY_TTL_IN
    len_ = ofproto_v1_2.OFP_ACTION_HEADER_SIZE
    fmt = ofproto_v1_2.OFP_ACTION_HEADER_PACK_STR
    buf = pack(fmt, type_, len_)
    c = OFPActionCopyTtlIn()

    def test_parser(self):
        res = self.c.parser(self.buf, 0)

        eq_(res.len, self.len_)
        eq_(res.type, self.type_)

    def test_serialize(self):
        buf = bytearray()
        self.c.serialize(buf, 0)

        res = struct.unpack(self.fmt, buffer(buf))
        eq_(res[0], self.type_)
        eq_(res[1], self.len_)


class TestOFPActionPushVlan(unittest.TestCase):
    """ Test case for ofproto_v1_2_parser.OFPActionPushVlan
    """

    # OFP_ACTION_PUSH_PACK_STR
    # '!HHH2x'...type, len, ethertype, pad(2)
    type_ = ofproto_v1_2.OFPAT_PUSH_VLAN
    len_ = ofproto_v1_2.OFP_ACTION_PUSH_SIZE
    fmt = ofproto_v1_2.OFP_ACTION_PUSH_PACK_STR

    def test_init(self):
        ethertype = 0x8100
        c = OFPActionPushVlan(ethertype)
        eq_(ethertype, c.ethertype)

    def _test_parser(self, ethertype):
        buf = pack(self.fmt, self.type_, self.len_, ethertype)

        res = OFPActionPushVlan.parser(buf, 0)
        eq_(res.type, self.type_)
        eq_(res.len, self.len_)
        eq_(res.ethertype, ethertype)

    def test_parser_mid(self):
        self._test_parser(0x8100)

    def test_parser_max(self):
        self._test_parser(0xffff)

    def test_parser_min(self):
        self._test_parser(0)

    def _test_serialize(self, ethertype):
        c = OFPActionPushVlan(ethertype)
        buf = bytearray()
        c.serialize(buf, 0)

        res = struct.unpack(self.fmt, buffer(buf))
        eq_(res[0], self.type_)
        eq_(res[1], self.len_)
        eq_(res[2], ethertype)

    def test_serialize_mid(self):
        self._test_serialize(0x8100)

    def test_serialize_max(self):
        self._test_serialize(0xffff)

    def test_serialize_min(self):
        self._test_serialize(0)


class TestOFPActionPushMpls(unittest.TestCase):
    """ Test case for ofproto_v1_2_parser.OFPActionPushMpls
    """

    # OFP_ACTION_PUSH_PACK_STR
    # '!HHH2x'...type, len, ethertype, pad(2)
    type_ = ofproto_v1_2.OFPAT_PUSH_MPLS
    len_ = ofproto_v1_2.OFP_ACTION_PUSH_SIZE
    fmt = ofproto_v1_2.OFP_ACTION_PUSH_PACK_STR

    def test_init(self):
        ethertype = 0x8100
        c = OFPActionPushMpls(ethertype)
        eq_(ethertype, c.ethertype)

    def _test_parser(self, ethertype):
        buf = pack(self.fmt, self.type_, self.len_, ethertype)

        res = OFPActionPushMpls.parser(buf, 0)
        eq_(res.type, self.type_)
        eq_(res.len, self.len_)
        eq_(res.ethertype, ethertype)

    def test_parser_mid(self):
        self._test_parser(0x8100)

    def test_parser_max(self):
        self._test_parser(0xffff)

    def test_parser_min(self):
        self._test_parser(0)

    def _test_serialize(self, ethertype):
        c = OFPActionPushMpls(ethertype)
        buf = bytearray()
        c.serialize(buf, 0)

        res = struct.unpack(self.fmt, buffer(buf))
        eq_(res[0], self.type_)
        eq_(res[1], self.len_)
        eq_(res[2], ethertype)

    def test_serialize_mid(self):
        self._test_serialize(0x8100)

    def test_serialize_max(self):
        self._test_serialize(0xffff)

    def test_serialize_min(self):
        self._test_serialize(0)


class TestOFPActionPopVlan(unittest.TestCase):
    """ Test case for ofproto_v1_2_parser.OFPActionPopVlan
    """

    # OFP_ACTION_HEADER_PACK_STR
    # '!HH'...type, len
    type_ = ofproto_v1_2.OFPAT_POP_VLAN
    len_ = ofproto_v1_2.OFP_ACTION_HEADER_SIZE
    fmt = ofproto_v1_2.OFP_ACTION_HEADER_PACK_STR
    buf = pack(fmt, type_, len_)
    c = OFPActionPopVlan()

    def test_parser(self):
        res = self.c.parser(self.buf, 0)
        eq_(self.type_, res.type)
        eq_(self.len_, res.len)

    def test_serialize(self):
        buf = bytearray()
        self.c.serialize(buf, 0)

        res = struct.unpack(self.fmt, buffer(buf))
        eq_(res[0], self.type_)
        eq_(res[1], self.len_)


class TestOFPActionPopMpls(unittest.TestCase):
    """ Test case for ofproto_v1_2_parser.OFPActionPopMpls
    """

    # OFP_ACTION_POP_MPLS_PACK_STR
    # '!HHH2x'...type, len, ethertype, pad(2)
    type_ = ofproto_v1_2.OFPAT_POP_MPLS
    len_ = ofproto_v1_2.OFP_ACTION_POP_MPLS_SIZE
    fmt = ofproto_v1_2.OFP_ACTION_POP_MPLS_PACK_STR

    def test_init(self):
        ethertype = 0x8100
        c = OFPActionPopMpls(ethertype)
        eq_(ethertype, c.ethertype)

    def _test_parser(self, ethertype):
        buf = pack(self.fmt, self.type_, self.len_, ethertype)

        res = OFPActionPopMpls.parser(buf, 0)
        eq_(res.type, self.type_)
        eq_(res.len, self.len_)
        eq_(res.ethertype, ethertype)

    def test_parser_mid(self):
        self._test_parser(0x8100)

    def test_parser_max(self):
        self._test_parser(0xffff)

    def test_parser_min(self):
        self._test_parser(0)

    def _test_serialize(self, ethertype):
        c = OFPActionPopMpls(ethertype)
        buf = bytearray()
        c.serialize(buf, 0)

        res = struct.unpack(self.fmt, buffer(buf))
        eq_(res[0], self.type_)
        eq_(res[1], self.len_)
        eq_(res[2], ethertype)

    def test_serialize_mid(self):
        self._test_serialize(0x8100)

    def test_serialize_max(self):
        self._test_serialize(0xffff)

    def test_serialize_min(self):
        self._test_serialize(0)


class TestOFPActionSetField(unittest.TestCase):
    """ Test case for ofproto_v1_2_parser.OFPActionSetField
    """

    type_ = ofproto_v1_2.OFPAT_SET_FIELD
    header = ofproto_v1_2.OXM_OF_IN_PORT
    in_port = 6606

    field = MTInPort(header, in_port)
    length = ofproto_v1_2.OFP_ACTION_SET_FIELD_SIZE + field.oxm_len()
    len_ = utils.round_up(length, 8)

    fmt = '!HHII4x'
    buf = pack(fmt, type_, len_, header, in_port)

    c = OFPActionSetField(field)

    def test_init(self):
        eq_(self.field, self.c.field)

    def test_parser(self):
        res = self.c.parser(self.buf, 0)

        eq_(res.type, self.type_)
        eq_(res.len, self.len_)
        eq_(res.field.header, self.header)
        eq_(res.field.value, self.in_port)

    def test_serialize(self):
        buf = bytearray()
        self.c.serialize(buf, 0)

        res = struct.unpack(self.fmt, buffer(buf))

        eq_(res[0], self.type_)
        eq_(res[1], self.len_)
        eq_(res[2], self.header)
        eq_(res[3], self.in_port)


class TestOFPActionExperimenter(unittest.TestCase):
    """ Test case for ofproto_v1_2_parser.OFPActionExperimenter
    """

    # OFP_ACTION_EXPERIMENTER_HEADER_PACK_STR v1.2
    # '!HHI'...type, len, experimenter
    type_ = ofproto_v1_2.OFPAT_EXPERIMENTER
    len_ = ofproto_v1_2.OFP_ACTION_EXPERIMENTER_HEADER_SIZE
    fmt = ofproto_v1_2.OFP_ACTION_EXPERIMENTER_HEADER_PACK_STR

    def test_init(self):
        experimenter = 4294967295
        c = OFPActionExperimenter(experimenter)
        eq_(experimenter, c.experimenter)

    def _test_parser(self, experimenter):
        buf = pack(self.fmt, self.type_, self.len_, experimenter)

        res = OFPActionExperimenter.parser(buf, 0)
        eq_(res.type, self.type_)
        eq_(res.len, self.len_)
        eq_(res.experimenter, experimenter)

    def test_parser_mid(self):
        experimenter = 2147483648
        self._test_parser(experimenter)

    def test_parser_max(self):
        experimenter = 4294967295
        self._test_parser(experimenter)

    def test_parser_min(self):
        experimenter = 0
        self._test_parser(experimenter)

    def _test_serialize(self, experimenter):
        c = OFPActionExperimenter(experimenter)

        buf = bytearray()
        c.serialize(buf, 0)

        res = struct.unpack(self.fmt, buffer(buf))
        eq_(res[0], self.type_)
        eq_(res[1], self.len_)
        eq_(res[2], experimenter)

    def test_serialize_mid(self):
        experimenter = 2147483648
        self._test_serialize(experimenter)

    def test_serialize_max(self):
        experimenter = 4294967295
        self._test_serialize(experimenter)

    def test_serialize_min(self):
        experimenter = 0
        self._test_serialize(experimenter)


class TestOFPBucket(unittest.TestCase):
    """ Test case for ofproto_v1_2_parser.OFPBucket
    """

    def test_init(self):
        # OFP_BUCKET_PACK_STR
        # '!HHII4x'...len, weight, watch_port, watch_group, pad(4)
        weight = 4386
        watch_port = 6606
        watch_group = 3

        # OFP_ACTION (OFP_ACTION_OUTPUT)
        port = 3
        max_len = 1500
        actions = [OFPActionOutput(port, max_len)]

        c = OFPBucket(weight, watch_port, watch_group, actions)
        eq_(weight, c.weight)
        eq_(watch_port, c.watch_port)
        eq_(watch_group, c.watch_group)
        eq_(1, len(c.actions))
        eq_(port, c.actions[0].port)
        eq_(max_len, c.actions[0].max_len)

    def _test_parser(self, weight, watch_port, watch_group, action_cnt):
        # OFP_BUCKET_PACK_STR
        # '!HHII4x'...len, weight, watch_port, watch_group, pad(4)
        len_ = ofproto_v1_2.OFP_BUCKET_SIZE \
            + (ofproto_v1_2.OFP_ACTION_OUTPUT_SIZE * action_cnt)

        fmt = ofproto_v1_2.OFP_BUCKET_PACK_STR
        buf = pack(fmt, len_, weight, watch_port, watch_group)

        actions = []
        for a in range(action_cnt):
            # OFP_ACTION (OFP_ACTION_OUTPUT)
            port = a
            max_len = ofproto_v1_2.OFP_ACTION_OUTPUT_SIZE
            action = OFPActionOutput(port, max_len)
            actions.append(action)
            buf_actions = bytearray()
            actions[a].serialize(buf_actions, 0)
            buf += str(buf_actions)

        res = OFPBucket.parser(buf, 0)

        # 16
        eq_(weight, res.weight)
        eq_(watch_port, res.watch_port)
        eq_(watch_group, res.watch_group)

        # 16 + 16 * action_cnt < 65535 byte
        # action_cnt <= 4094
        for a in range(action_cnt):
            eq_(actions[a].type, res.actions[a].type)
            eq_(actions[a].len, res.actions[a].len)
            eq_(actions[a].port, res.actions[a].port)
            eq_(actions[a].max_len, res.actions[a].max_len)

    def test_parser_mid(self):
        weight = 4386
        watch_port = 6606
        watch_group = 3
        action_cnt = 2047
        self._test_parser(weight, watch_port,
                          watch_group, action_cnt)

    def test_parser_max(self):
        weight = 65535
        watch_port = 4294967295
        watch_group = 4294967295
        action_cnt = 4094
        self._test_parser(weight, watch_port,
                          watch_group, action_cnt)

    def test_parser_min(self):
        weight = 0
        watch_port = 0
        watch_group = 0
        action_cnt = 0
        self._test_parser(weight, watch_port,
                          watch_group, action_cnt)

    def _test_serialize(self, weight, watch_port, watch_group,
                        action_cnt):
        # OFP_BUCKET_PACK_STR
        # '!HHII4x'...len, weight, watch_port, watch_group, pad(4)
        len_ = ofproto_v1_2.OFP_BUCKET_SIZE \
            + (ofproto_v1_2.OFP_ACTION_OUTPUT_SIZE * action_cnt)

        actions = []
        for a in range(action_cnt):
            # OFP_ACTION (OFP_ACTION_OUTPUT)
            port = a
            max_len = ofproto_v1_2.OFP_ACTION_OUTPUT_SIZE
            action = OFPActionOutput(port, max_len)
            actions.append(action)

        c = OFPBucket(weight, watch_port, watch_group, actions)

        buf = bytearray()
        c.serialize(buf, 0)

        fmt = ofproto_v1_2.OFP_BUCKET_PACK_STR
        for a in range(action_cnt):
            fmt += ofproto_v1_2.OFP_ACTION_OUTPUT_PACK_STR[1:]
        res = struct.unpack(fmt, buffer(buf))

        eq_(res[0], len_)
        eq_(res[1], weight)
        eq_(res[2], watch_port)
        eq_(res[3], watch_group)

        for a in range(action_cnt):
            d = 4 + a * 4
            eq_(res[d], actions[a].type)
            eq_(res[d + 1], actions[a].len)
            eq_(res[d + 2], actions[a].port)
            eq_(res[d + 3], actions[a].max_len)

    def test_serialize_mid(self):
        weight = 4386
        watch_port = 6606
        watch_group = 3
        action_cnt = 2047
        self._test_serialize(weight, watch_port,
                             watch_group, action_cnt)

    def test_serialize_max(self):
        weight = 65535
        watch_port = 4294967295
        watch_group = 4294967295
        action_cnt = 4094
        self._test_serialize(weight, watch_port,
                             watch_group, action_cnt)

    def test_serialize_min(self):
        weight = 0
        watch_port = 0
        watch_group = 0
        action_cnt = 0
        self._test_serialize(weight, watch_port,
                             watch_group, action_cnt)


class TestOFPGroupMod(unittest.TestCase):
    """ Test case for ofproto_v1_2_parser.OFPGroupMod
    """

    def test_init(self):
        # OFP_GROUP_MOD_PACK_STR
        # '!HBBI'...command, type, pad, group_id
        command = ofproto_v1_2.OFPFC_ADD
        type_ = ofproto_v1_2.OFPGT_SELECT
        group_id = 6606

        # OFP_BUCKET
        weight = 4386
        watch_port = 8006
        watch_group = 3

        # OFP_ACTION (OFP_ACTION_OUTPUT)
        port = 10
        max_len = 2000
        actions = [OFPActionOutput(port, max_len)]

        buckets = [OFPBucket(weight, watch_port, watch_group, actions)]

        c = OFPGroupMod(_Datapath, command, type_, group_id, buckets)
        eq_(command, c.command)
        eq_(type_, c.type)
        eq_(group_id, c.group_id)
        eq_(1, len(c.buckets))
        eq_(1, len(c.buckets[0].actions))
        eq_(port, c.buckets[0].actions[0].port)
        eq_(max_len, c.buckets[0].actions[0].max_len)

    def _test_serialize(self, command, type_, group_id, bucket_cnt):
        len_ = ofproto_v1_2.OFP_BUCKET_SIZE \
            + ofproto_v1_2.OFP_ACTION_OUTPUT_SIZE

        buckets = []
        for b in range(bucket_cnt):
            # OFP_BUCKET
            weight = watch_port = watch_group = port = b
            actions = [OFPActionOutput(port, 0)]
            bucket = OFPBucket(weight, watch_port, watch_group, actions)
            buckets.append(bucket)

        c = OFPGroupMod(_Datapath, command, type_, group_id, buckets)

        c.serialize()

        eq_(ofproto_v1_2.OFP_VERSION, c.version)
        eq_(ofproto_v1_2.OFPT_GROUP_MOD, c.msg_type)
        eq_(0, c.xid)
        eq_(len(c.buf), c.msg_len)

        # 16 byte
        fmt = ofproto_v1_2.OFP_HEADER_PACK_STR \
            + ofproto_v1_2.OFP_GROUP_MOD_PACK_STR[1:]

        # 16 + (16 + 16) * bucket_cnt < 65535 byte
        # bucket_cnt <= 2047
        for b in range(bucket_cnt):
            fmt += ofproto_v1_2.OFP_BUCKET_PACK_STR[1:] \
                + ofproto_v1_2.OFP_ACTION_OUTPUT_PACK_STR[1:]

        res = struct.unpack(fmt, str(c.buf))

        msg_len = ofproto_v1_2.OFP_GROUP_MOD_SIZE \
            + (len_ * bucket_cnt)

        eq_(res[0], ofproto_v1_2.OFP_VERSION)
        eq_(res[1], ofproto_v1_2.OFPT_GROUP_MOD)
        eq_(res[2], msg_len)
        eq_(res[3], 0)
        eq_(res[4], command)
        eq_(res[5], type_)
        eq_(res[6], group_id)

        for d in range(bucket_cnt):
            e = 7 + d * 8
            eq_(res[e + 1], buckets[d].weight)
            eq_(res[e + 2], buckets[d].watch_port)
            eq_(res[e + 3], buckets[d].watch_group)
            eq_(res[e + 4], buckets[d].actions[0].type)
            eq_(res[e + 5], buckets[d].actions[0].len)
            eq_(res[e + 6], buckets[d].actions[0].port)
            eq_(res[e + 7], buckets[d].actions[0].max_len)

    def test_serialize_mid(self):
        command = 32768
        type_ = 128
        group_id = 6606
        bucket_cnt = 1023
        self._test_serialize(command, type_, group_id, bucket_cnt)

    def test_serialize_max(self):
        command = 65535
        type_ = 255
        group_id = 4294967295
        bucket_cnt = 2047
        self._test_serialize(command, type_, group_id, bucket_cnt)

    def test_serialize_min(self):
        command = 0
        type_ = 0
        group_id = 0
        bucket_cnt = 0
        self._test_serialize(command, type_, group_id, bucket_cnt)

    def test_serialize_p1(self):
        command = 1
        type_ = 1
        group_id = 6606
        bucket_cnt = 1023
        self._test_serialize(command, type_, group_id, bucket_cnt)

    def test_serialize_p2(self):
        command = 1
        type_ = 2
        group_id = 6606
        bucket_cnt = 1023
        self._test_serialize(command, type_, group_id, bucket_cnt)

    def test_serialize_p3(self):
        command = 2
        type_ = 3
        group_id = 6606
        bucket_cnt = 1023
        self._test_serialize(command, type_, group_id, bucket_cnt)


class TestOFPPortMod(unittest.TestCase):
    """ Test case for ofproto_v1_2_parser.OFPPortMod
    """

    # OFP_PORT_MOD_PACK_STR v1.2
    # '!I4xs2xIII4x'...port_no, pad(4), hw_addr, pad(2),
    #                  config, mask, advertise, pad(4)
    port_no = 1119692796
    hw_addr = 'e8:fe:5e:a9:68:6c'
    config = 2226555987
    mask = 1678244809
    advertise = 2025421682

    def test_init(self):
        c = OFPPortMod(_Datapath, self.port_no, self.hw_addr,
                       self.config, self.mask, self.advertise)
        eq_(self.port_no, c.port_no)
        eq_(self.hw_addr, c.hw_addr)
        eq_(self.config, c.config)
        eq_(self.mask, c.mask)
        eq_(self.advertise, c.advertise)

    def _test_serialize(self, port_no, hw_addr, config, mask, advertise):
        c = OFPPortMod(_Datapath, port_no, hw_addr, config,
                       mask, advertise)
        c.serialize()

        eq_(ofproto_v1_2.OFP_VERSION, c.version)
        eq_(ofproto_v1_2.OFPT_PORT_MOD, c.msg_type)
        eq_(0, c.xid)

        fmt = '!' \
            + ofproto_v1_2.OFP_HEADER_PACK_STR.replace('!', '') \
            + ofproto_v1_2.OFP_PORT_MOD_PACK_STR.replace('!', '')

        res = struct.unpack(fmt, str(c.buf))

        eq_(res[0], ofproto_v1_2.OFP_VERSION)
        eq_(res[1], ofproto_v1_2.OFPT_PORT_MOD)
        eq_(res[2], len(c.buf))
        eq_(res[3], 0)
        eq_(res[4], port_no)
        eq_(res[5], addrconv.mac.text_to_bin(hw_addr))
        eq_(res[6], config)
        eq_(res[7], mask)
        eq_(res[8], advertise)

    def test_serialize_mid(self):
        self._test_serialize(self.port_no, self.hw_addr,
                             self.config, self.mask, self.advertise)

    def test_serialize_max(self):
        port_no = ofproto_v1_2.OFPP_ANY
        hw_addr = 'ff:ff:ff:ff:ff:ff'
        config = 0xffffffff
        mask = 0xffffffff
        advertise = 0xffffffff
        self._test_serialize(port_no, hw_addr, config, mask, advertise)

    def test_serialize_min(self):
        port_no = 0
        hw_addr = '00:00:00:00:00:00'
        config = 0
        mask = 0
        advertise = 0
        self._test_serialize(port_no, hw_addr, config, mask, advertise)

    def test_serialize_p1(self):
        port_no = ofproto_v1_2.OFPP_MAX
        hw_addr = self.hw_addr
        config = ofproto_v1_2.OFPPC_PORT_DOWN
        mask = ofproto_v1_2.OFPPC_PORT_DOWN
        advertise = ofproto_v1_2.OFPPF_10MB_HD
        self._test_serialize(port_no, hw_addr, config, mask, advertise)

    def test_serialize_p2(self):
        port_no = ofproto_v1_2.OFPP_IN_PORT
        hw_addr = self.hw_addr
        config = ofproto_v1_2.OFPPC_NO_RECV
        mask = ofproto_v1_2.OFPPC_NO_RECV
        advertise = ofproto_v1_2.OFPPF_10MB_FD
        self._test_serialize(port_no, hw_addr, config, mask, advertise)

    def test_serialize_p3(self):
        port_no = ofproto_v1_2.OFPP_TABLE
        hw_addr = self.hw_addr
        config = ofproto_v1_2.OFPPC_NO_FWD
        mask = ofproto_v1_2.OFPPC_NO_FWD
        advertise = ofproto_v1_2.OFPPF_100MB_HD
        self._test_serialize(port_no, hw_addr, config, mask, advertise)

    def test_serialize_p4(self):
        port_no = ofproto_v1_2.OFPP_NORMAL
        hw_addr = self.hw_addr
        config = ofproto_v1_2.OFPPC_NO_PACKET_IN
        mask = ofproto_v1_2.OFPPC_NO_PACKET_IN
        advertise = ofproto_v1_2.OFPPF_100MB_FD
        self._test_serialize(port_no, hw_addr, config, mask, advertise)

    def test_serialize_p5(self):
        port_no = ofproto_v1_2.OFPP_FLOOD
        hw_addr = self.hw_addr
        config = ofproto_v1_2.OFPPC_NO_PACKET_IN
        mask = ofproto_v1_2.OFPPC_NO_PACKET_IN
        advertise = ofproto_v1_2.OFPPF_1GB_HD
        self._test_serialize(port_no, hw_addr, config, mask, advertise)

    def test_serialize_p6(self):
        port_no = ofproto_v1_2.OFPP_ALL
        hw_addr = self.hw_addr
        config = ofproto_v1_2.OFPPC_NO_PACKET_IN
        mask = ofproto_v1_2.OFPPC_NO_PACKET_IN
        advertise = ofproto_v1_2.OFPPF_1GB_FD
        self._test_serialize(port_no, hw_addr, config, mask, advertise)

    def test_serialize_p7(self):
        port_no = ofproto_v1_2.OFPP_CONTROLLER
        hw_addr = self.hw_addr
        config = ofproto_v1_2.OFPPC_NO_PACKET_IN
        mask = ofproto_v1_2.OFPPC_NO_PACKET_IN
        advertise = ofproto_v1_2.OFPPF_10GB_FD
        self._test_serialize(port_no, hw_addr, config, mask, advertise)

    def test_serialize_p8(self):
        port_no = ofproto_v1_2.OFPP_LOCAL
        hw_addr = self.hw_addr
        config = ofproto_v1_2.OFPPC_NO_PACKET_IN
        mask = ofproto_v1_2.OFPPC_NO_PACKET_IN
        advertise = ofproto_v1_2.OFPPF_40GB_FD
        self._test_serialize(port_no, hw_addr, config, mask, advertise)

    def test_serialize_p9(self):
        port_no = ofproto_v1_2.OFPP_LOCAL
        hw_addr = self.hw_addr
        config = ofproto_v1_2.OFPPC_NO_PACKET_IN
        mask = ofproto_v1_2.OFPPC_NO_PACKET_IN
        advertise = ofproto_v1_2.OFPPF_100GB_FD
        self._test_serialize(port_no, hw_addr, config, mask, advertise)

    def test_serialize_p10(self):
        port_no = ofproto_v1_2.OFPP_LOCAL
        hw_addr = self.hw_addr
        config = ofproto_v1_2.OFPPC_NO_PACKET_IN
        mask = ofproto_v1_2.OFPPC_NO_PACKET_IN
        advertise = ofproto_v1_2.OFPPF_1TB_FD
        self._test_serialize(port_no, hw_addr, config, mask, advertise)

    def test_serialize_p11(self):
        port_no = ofproto_v1_2.OFPP_LOCAL
        hw_addr = self.hw_addr
        config = ofproto_v1_2.OFPPC_NO_PACKET_IN
        mask = ofproto_v1_2.OFPPC_NO_PACKET_IN
        advertise = ofproto_v1_2.OFPPF_OTHER
        self._test_serialize(port_no, hw_addr, config, mask, advertise)

    def test_serialize_p12(self):
        port_no = ofproto_v1_2.OFPP_LOCAL
        hw_addr = self.hw_addr
        config = ofproto_v1_2.OFPPC_NO_PACKET_IN
        mask = ofproto_v1_2.OFPPC_NO_PACKET_IN
        advertise = ofproto_v1_2.OFPPF_COPPER
        self._test_serialize(port_no, hw_addr, config, mask, advertise)

    def test_serialize_p13(self):
        port_no = ofproto_v1_2.OFPP_LOCAL
        hw_addr = self.hw_addr
        config = ofproto_v1_2.OFPPC_NO_PACKET_IN
        mask = ofproto_v1_2.OFPPC_NO_PACKET_IN
        advertise = ofproto_v1_2.OFPPF_FIBER
        self._test_serialize(port_no, hw_addr, config, mask, advertise)

    def test_serialize_p14(self):
        port_no = ofproto_v1_2.OFPP_LOCAL
        hw_addr = self.hw_addr
        config = ofproto_v1_2.OFPPC_NO_PACKET_IN
        mask = ofproto_v1_2.OFPPC_NO_PACKET_IN
        advertise = ofproto_v1_2.OFPPF_AUTONEG
        self._test_serialize(port_no, hw_addr, config, mask, advertise)

    def test_serialize_p15(self):
        port_no = ofproto_v1_2.OFPP_LOCAL
        hw_addr = self.hw_addr
        config = ofproto_v1_2.OFPPC_NO_PACKET_IN
        mask = ofproto_v1_2.OFPPC_NO_PACKET_IN
        advertise = ofproto_v1_2.OFPPF_PAUSE
        self._test_serialize(port_no, hw_addr, config, mask, advertise)

    def test_serialize_p16(self):
        port_no = ofproto_v1_2.OFPP_LOCAL
        hw_addr = self.hw_addr
        config = ofproto_v1_2.OFPPC_NO_PACKET_IN
        mask = ofproto_v1_2.OFPPC_NO_PACKET_IN
        advertise = ofproto_v1_2.OFPPF_PAUSE_ASYM
        self._test_serialize(port_no, hw_addr, config, mask, advertise)


class TestOFPTableMod(unittest.TestCase):
    """ Test case for ofproto_v1_2_parser.OFPTableMod
    """

    # OFP_PORT_TABLE_PACK_STR v1.2
    # '!B3xI'...table_id, pad(3), config
    table_id = 3
    config = 2226555987

    def test_init(self):
        c = OFPTableMod(_Datapath, self.table_id, self.config)
        eq_(self.table_id, c.table_id)
        eq_(self.config, c.config)

    def _test_serialize(self, table_id, config):
        c = OFPTableMod(_Datapath, table_id, config)
        c.serialize()

        eq_(ofproto_v1_2.OFP_VERSION, c.version)
        eq_(ofproto_v1_2.OFPT_TABLE_MOD, c.msg_type)
        eq_(0, c.xid)

        fmt = '!' \
            + ofproto_v1_2.OFP_HEADER_PACK_STR.replace('!', '') \
            + ofproto_v1_2.OFP_TABLE_MOD_PACK_STR.replace('!', '')

        res = struct.unpack(fmt, str(c.buf))

        eq_(res[0], ofproto_v1_2.OFP_VERSION)
        eq_(res[1], ofproto_v1_2.OFPT_TABLE_MOD)
        eq_(res[2], len(c.buf))
        eq_(res[3], 0)
        eq_(res[4], table_id)
        eq_(res[5], config)

    def test_serialize_mid(self):
        self._test_serialize(self.table_id, self.config)

    def test_serialize_max(self):
        table_id = ofproto_v1_2.OFPTT_ALL
        config = 0xffffffff
        self._test_serialize(table_id, config)

    def test_serialize_min(self):
        table_id = 0
        config = 0
        self._test_serialize(table_id, config)

    def test_serialize_p1(self):
        table_id = ofproto_v1_2.OFPTT_MAX
        config = ofproto_v1_2.OFPTC_TABLE_MISS_CONTINUE
        self._test_serialize(table_id, config)

    def test_serialize_p2(self):
        table_id = ofproto_v1_2.OFPTT_MAX
        config = ofproto_v1_2.OFPTC_TABLE_MISS_DROP
        self._test_serialize(table_id, config)

    def test_serialize_p3(self):
        table_id = ofproto_v1_2.OFPTT_MAX
        config = ofproto_v1_2.OFPTC_TABLE_MISS_MASK
        self._test_serialize(table_id, config)


class TestOFPStatsRequest(unittest.TestCase):
    """ Test case for ofproto_v1_2_parser.OFPStatsRequest
    """

    type_ = ofproto_v1_2.OFPST_DESC
    c = OFPStatsRequest(_Datapath, type_)

    def test_init(self):
        eq_(self.type_, self.c.type)
        eq_(0, self.c.flags)

    def test_serialize_body(self):
        len_ = ofproto_v1_2.OFP_HEADER_SIZE \
            + ofproto_v1_2.OFP_STATS_REQUEST_SIZE
        self.c.buf = bytearray(len_)
        self.c._serialize_body()

        fmt = ofproto_v1_2.OFP_STATS_REQUEST_PACK_STR
        res = struct.unpack_from(fmt, str(self.c.buf),
                                 ofproto_v1_2.OFP_HEADER_SIZE)

        eq_(res[0], self.type_)
        eq_(res[1], 0)


class TestOFPStatsReply(unittest.TestCase):
    """ Test case for ofproto_v1_2_parser.OFPStatsReply
    """

    c = OFPStatsReply(_Datapath)

    def test_parser_single_struct_true(self):
        # OFP_HEADER_PACK_STR
        # '!BBHI'...version, msg_type, msg_len, xid
        version = ofproto_v1_2.OFP_VERSION
        msg_type = ofproto_v1_2.OFPT_STATS_REPLY
        msg_len = ofproto_v1_2.OFP_STATS_REPLY_SIZE \
            + ofproto_v1_2.OFP_AGGREGATE_STATS_REPLY_SIZE
        xid = 2495926989

        fmt = ofproto_v1_2.OFP_HEADER_PACK_STR
        buf = pack(fmt, version, msg_type, msg_len, xid)

        # OFP_STATS_REPLY_PACK_STR
        # '!HH4x'...type, flags, pad(4)
        type_ = ofproto_v1_2.OFPST_AGGREGATE
        flags = 41802

        fmt = ofproto_v1_2.OFP_STATS_REPLY_PACK_STR
        buf += pack(fmt, type_, flags)

        # OFP_AGGREGATE_STATS_REPLY_PACK_STR
        packet_count = 5142202600015232219
        byte_count = 2659740543924820419
        flow_count = 1344694860
        body = OFPAggregateStatsReply(packet_count, byte_count, flow_count)

        fmt = ofproto_v1_2.OFP_AGGREGATE_STATS_REPLY_PACK_STR
        buf += pack(fmt, packet_count, byte_count, flow_count)

        res = self.c.parser(object, version, msg_type, msg_len, xid, buf)

        eq_(version, res.version)
        eq_(msg_type, res.msg_type)
        eq_(msg_len, res.msg_len)
        eq_(xid, res.xid)
        eq_(type_, res.type)
        eq_(flags, res.flags)
        eq_(packet_count, res.body.packet_count)
        eq_(byte_count, res.body.byte_count)
        eq_(flow_count, res.body.flow_count)

    def test_parser_single_struct_flase(self):
        # OFP_HEADER_PACK_STR
        # '!BBHI'...version, msg_type, msg_len, xid
        version = ofproto_v1_2.OFP_VERSION
        msg_type = ofproto_v1_2.OFPT_STATS_REPLY
        msg_len = ofproto_v1_2.OFP_STATS_REPLY_SIZE \
            + ofproto_v1_2.OFP_QUEUE_STATS_SIZE
        xid = 2495926989

        fmt = ofproto_v1_2.OFP_HEADER_PACK_STR
        buf = pack(fmt, version, msg_type, msg_len, xid)

        # OFP_STATS_REPLY_PACK_STR
        # '!HH4x'...type, flags, pad(4)
        type_ = ofproto_v1_2.OFPST_QUEUE
        flags = 11884

        fmt = ofproto_v1_2.OFP_STATS_REPLY_PACK_STR
        buf += pack(fmt, type_, flags)

        # OFP_QUEUE_STATS_PACK_STR
        port_no = 41186
        queue_id = 6606
        tx_bytes = 8638420181865882538
        tx_packets = 2856480458895760962
        tx_errors = 6283093430376743019
        body = [OFPQueueStats(port_no, queue_id, tx_bytes, tx_packets,
                              tx_errors)]

        fmt = ofproto_v1_2.OFP_QUEUE_STATS_PACK_STR
        buf += pack(fmt, port_no, queue_id, tx_bytes, tx_packets, tx_errors)

        res = self.c.parser(object, version, msg_type, msg_len, xid, buf)

        eq_(version, res.version)
        eq_(msg_type, res.msg_type)
        eq_(msg_len, res.msg_len)
        eq_(xid, res.xid)
        eq_(type_, res.type)
        eq_(flags, res.flags)
        eq_(port_no, res.body[0].port_no)
        eq_(queue_id, res.body[0].queue_id)
        eq_(tx_bytes, res.body[0].tx_bytes)
        eq_(tx_packets, res.body[0].tx_packets)
        eq_(tx_errors, res.body[0].tx_errors)

    def test_parser_max(self):
        # OFP_HEADER_PACK_STR
        # '!BBHI'...version, msg_type, msg_len, xid
        version = ofproto_v1_2.OFP_VERSION
        msg_type = ofproto_v1_2.OFPT_STATS_REPLY
        msg_len = ofproto_v1_2.OFP_STATS_REPLY_SIZE
        xid = 0xffffffff

        fmt = ofproto_v1_2.OFP_HEADER_PACK_STR
        buf = pack(fmt, version, msg_type, msg_len, xid)

        # OFP_STATS_REPLY_PACK_STR
        # '!HH4x'...type, flags, pad(4)
        type_ = ofproto_v1_2.OFPST_QUEUE
        flags = 0xffff

        fmt = ofproto_v1_2.OFP_STATS_REPLY_PACK_STR
        buf += pack(fmt, type_, flags)
        res = self.c.parser(object, version, msg_type, msg_len, xid, buf)

        eq_(version, res.version)
        eq_(msg_type, res.msg_type)
        eq_(msg_len, res.msg_len)
        eq_(xid, res.xid)
        eq_(type_, res.type)
        eq_(flags, res.flags)

    def test_parser_min(self):
        # OFP_HEADER_PACK_STR
        # '!BBHI'...version, msg_type, msg_len, xid
        version = ofproto_v1_2.OFP_VERSION
        msg_type = ofproto_v1_2.OFPT_STATS_REPLY
        msg_len = ofproto_v1_2.OFP_STATS_REPLY_SIZE
        xid = 0

        fmt = ofproto_v1_2.OFP_HEADER_PACK_STR
        buf = pack(fmt, version, msg_type, msg_len, xid)

        # OFP_STATS_REPLY_PACK_STR
        # '!HH4x'...type, flags, pad(4)
        type_ = ofproto_v1_2.OFPST_QUEUE
        flags = 0

        fmt = ofproto_v1_2.OFP_STATS_REPLY_PACK_STR
        buf += pack(fmt, type_, flags)
        res = self.c.parser(object, version, msg_type, msg_len, xid, buf)

        eq_(version, res.version)
        eq_(msg_type, res.msg_type)
        eq_(msg_len, res.msg_len)
        eq_(xid, res.xid)
        eq_(type_, res.type)
        eq_(flags, res.flags)


class TestOFPDescStatsRequest(unittest.TestCase):
    """ Test case for ofproto_v1_2_parser.OFPDescStatsRequest
    """

    def test_serialize(self):
        c = OFPDescStatsRequest(_Datapath)
        c.serialize()

        fmt = '!' \
            + ofproto_v1_2.OFP_HEADER_PACK_STR.replace('!', '') \
            + ofproto_v1_2.OFP_STATS_REQUEST_PACK_STR.replace('!', '')

        res = struct.unpack(fmt, str(c.buf))

        eq_(res[0], ofproto_v1_2.OFP_VERSION)
        eq_(res[1], ofproto_v1_2.OFPT_STATS_REQUEST)
        eq_(res[2], len(c.buf))
        eq_(res[3], 0)
        eq_(res[4], ofproto_v1_2.OFPST_DESC)
        eq_(res[5], 0)


class TestOFPDescStats(unittest.TestCase):
    """ Test case for ofproto_v1_2_parser.OFPDescStats
    """

    # OFP_DESC_STATS_PACK_STR
    # '!256s256s256s32s256s'...mfr_desc, hw_desc, sw_desc, serial_num, dp_desc
    mfr_desc = 'mfr_desc'.ljust(256)
    hw_desc = 'hw_desc'.ljust(256)
    sw_desc = 'sw_desc'.ljust(256)
    serial_num = 'serial_num'.ljust(32)
    dp_desc = 'dp_desc'.ljust(256)

    buf = mfr_desc \
        + hw_desc \
        + sw_desc \
        + serial_num \
        + dp_desc

    c = OFPDescStats(mfr_desc, hw_desc, sw_desc, serial_num, dp_desc)

    def test_init(self):
        eq_(self.mfr_desc, self.c.mfr_desc)
        eq_(self.hw_desc, self.c.hw_desc)
        eq_(self.sw_desc, self.c.sw_desc)
        eq_(self.serial_num, self.c.serial_num)
        eq_(self.dp_desc, self.c.dp_desc)

    def test_parser(self):
        res = self.c.parser(self.buf, 0)

        eq_(self.mfr_desc, res.mfr_desc)
        eq_(self.hw_desc, res.hw_desc)
        eq_(self.sw_desc, res.sw_desc)
        eq_(self.serial_num, res.serial_num)
        eq_(self.dp_desc, res.dp_desc)


class TestOFPFlowStatsRequest(unittest.TestCase):
    """ Test case for ofproto_v1_2_parser.OFPFlowStatsRequest
    """

    # OFP_FLOW_STATS_REQUEST_PACK_STR
    # '!B3xII4xQQ'...table_id, pad(3), out_port, out_group, pad(4),
    #                cookie, cookie_mask
    table_id = 3
    out_port = 65037
    out_group = 6606
    cookie = 2127614848199081640
    cookie_mask = 2127614848199081641

    def test_init(self):
        match = OFPMatch()
        in_port = 3
        match.set_in_port(in_port)

        c = OFPFlowStatsRequest(_Datapath, self.table_id, self.out_port,
                                self.out_group, self.cookie, self.cookie_mask,
                                match)

        eq_(self.table_id, c.table_id)
        eq_(self.out_port, c.out_port)
        eq_(self.out_group, c.out_group)
        eq_(self.cookie, c.cookie)
        eq_(self.cookie_mask, c.cookie_mask)
        eq_(in_port, c.match._flow.in_port)

    def _test_serialize(self, table_id, out_port, out_group,
                        cookie, cookie_mask):
        match = OFPMatch()
        dl_type = 0x800
        match.set_dl_type(dl_type)

        c = OFPFlowStatsRequest(_Datapath, table_id, out_port,
                                out_group, cookie, cookie_mask, match)
        c.serialize()

        eq_(ofproto_v1_2.OFP_VERSION, c.version)
        eq_(ofproto_v1_2.OFPT_STATS_REQUEST, c.msg_type)
        eq_(0, c.xid)

        fmt = ofproto_v1_2.OFP_HEADER_PACK_STR \
            + ofproto_v1_2.OFP_STATS_REQUEST_PACK_STR[1:] \
            + ofproto_v1_2.OFP_FLOW_STATS_REQUEST_PACK_STR[1:] \
            + 'HHHBB' \
            + MTEthType.pack_str[1:] + '6x'

        res = struct.unpack(fmt, str(c.buf))

        eq_(res[0], ofproto_v1_2.OFP_VERSION)
        eq_(res[1], ofproto_v1_2.OFPT_STATS_REQUEST)
        size = ofproto_v1_2.OFP_STATS_REPLY_SIZE \
            + ofproto_v1_2.OFP_FLOW_STATS_REQUEST_SIZE \
            + calcsize(MTEthType.pack_str + '6x')
        eq_(res[2], size)
        eq_(res[3], 0)
        eq_(res[4], ofproto_v1_2.OFPST_FLOW)
        eq_(res[5], 0)
        eq_(res[6], table_id)
        eq_(res[7], out_port)
        eq_(res[8], out_group)
        eq_(res[9], cookie)
        eq_(res[10], cookie_mask)
        # match
        eq_(res[11], ofproto_v1_2.OFPMT_OXM)
        eq_(res[12], 10)
        eq_(res[13], ofproto_v1_2.OFPXMC_OPENFLOW_BASIC)
        eq_(res[14] >> 1, ofproto_v1_2.OFPXMT_OFB_ETH_TYPE)
        eq_(res[14] & 0b0001, 0)
        eq_(res[15], calcsize(MTEthType.pack_str))
        eq_(res[16], dl_type)

    def test_serialize_mid(self):
        self._test_serialize(self.table_id, self.out_port, self.out_group,
                             self.cookie, self.cookie_mask)

    def test_serialize_max(self):
        table_id = 0xff
        out_port = 0xffff
        out_group = 0xffff
        cookie = 0xffffffff
        cookie_mask = 0xffffffff
        self._test_serialize(table_id, out_port, out_group,
                             cookie, cookie_mask)

    def test_serialize_min(self):
        table_id = 0
        out_port = 0
        out_group = 0
        cookie = 0
        cookie_mask = 0
        self._test_serialize(table_id, out_port, out_group,
                             cookie, cookie_mask)

    def test_serialize_p1(self):
        table_id = ofproto_v1_2.OFPTT_MAX
        self._test_serialize(table_id, self.out_port, self.out_group,
                             self.cookie, self.cookie_mask)


class TestOFPFlowStats(unittest.TestCase):
    """ Test case for ofproto_v1_2_parser.OFPFlowStats
    """

    def test_init(self):
        length = ofproto_v1_2.OFP_FLOW_STATS_SIZE
        table_id = 81
        duration_sec = 2484712402
        duration_nsec = 3999715196
        priority = 57792
        idle_timeout = 36368
        hard_timeout = 54425
        cookie = 793171083674290912
        packet_count = 5142202600015232219
        byte_count = 2659740543924820419

        match = OFPMatch()
        in_port = 2
        match.set_in_port(in_port)

        goto_table = 3
        instructions = [OFPInstructionGotoTable(goto_table)]
        c = OFPFlowStats(table_id, duration_sec, duration_nsec,
                         priority, idle_timeout, hard_timeout, cookie,
                         packet_count, byte_count, match, instructions)

        eq_(table_id, c.table_id)
        eq_(duration_sec, c.duration_sec)
        eq_(duration_nsec, c.duration_nsec)
        eq_(priority, c.priority)
        eq_(idle_timeout, c.idle_timeout)
        eq_(hard_timeout, c.hard_timeout)
        eq_(cookie, c.cookie)
        eq_(packet_count, c.packet_count)
        eq_(byte_count, c.byte_count)
        eq_(in_port, c.match._flow.in_port)
        eq_(goto_table, c.instructions[0].table_id)

    def _test_parser(self, table_id, duration_sec, duration_nsec,
                     priority, idle_timeout, hard_timeout, cookie,
                     packet_count, byte_count, inst_cnt=0):

        length = ofproto_v1_2.OFP_FLOW_STATS_SIZE \
            + calcsize(MTEthType.pack_str[1:] + '6x') \
            + ofproto_v1_2.OFP_INSTRUCTION_GOTO_TABLE_SIZE * inst_cnt

        # OFP_FLOW_STATS_PACK_STR
        buf = pack(ofproto_v1_2.OFP_FLOW_STATS_PACK_STR,
                   length, table_id, duration_sec, duration_nsec,
                   priority, idle_timeout, hard_timeout, cookie,
                   packet_count, byte_count)

        # match
        match = OFPMatch()
        dl_type = 0x0800
        match.set_dl_type(dl_type)
        match_buf = bytearray()
        match.serialize(match_buf, 0)
        buf += str(match_buf)

        # instructions
        # 56 + 8 + 8 * inst_cnt <= 65535
        # inst_cnt <= 8183
        for i in range(inst_cnt):
            inst = OFPInstructionGotoTable(1)
            inst_buf = bytearray()
            inst.serialize(inst_buf, 0)
            buf += str(inst_buf)

        # parse
        res = OFPFlowStats.parser(buf, 0)
        eq_(length, res.length)
        eq_(table_id, res.table_id)
        eq_(duration_sec, res.duration_sec)
        eq_(duration_nsec, res.duration_nsec)
        eq_(priority, res.priority)
        eq_(idle_timeout, res.idle_timeout)
        eq_(hard_timeout, res.hard_timeout)
        eq_(cookie, res.cookie)
        eq_(packet_count, res.packet_count)
        eq_(byte_count, res.byte_count)
        eq_(dl_type, res.match.fields[0].value)
        for i in range(inst_cnt):
            eq_(1, res.instructions[i].table_id)

    def test_parser_mid(self):
        table_id = 81
        duration_sec = 2484712402
        duration_nsec = 3999715196
        priority = 57792
        idle_timeout = 36368
        hard_timeout = 54425
        cookie = 793171083674290912
        packet_count = 5142202600015232219
        byte_count = 2659740543924820419
        inst_cnt = 2

        self._test_parser(table_id, duration_sec, duration_nsec,
                          priority, idle_timeout, hard_timeout, cookie,
                          packet_count, byte_count, inst_cnt)

    def test_parser_max(self):
        table_id = 0xff
        duration_sec = 0xffff
        duration_nsec = 0xffff
        priority = 0xffff
        idle_timeout = 0xff
        hard_timeout = 0xff
        cookie = 0xffffffffffffffff
        packet_count = 0xffffffffffffffff
        byte_count = 0xffffffffffffffff
        inst_cnt = 8183

        self._test_parser(table_id, duration_sec, duration_nsec,
                          priority, idle_timeout, hard_timeout, cookie,
                          packet_count, byte_count, inst_cnt)

    def test_parser_min(self):
        self._test_parser(0, 0, 0, 0, 0, 0, 0, 0, 0)


class TestOFPAggregateStatsRequest(unittest.TestCase):
    """ Test case for ofproto_v1_2_parser.OFPAggregateStatsRequest
    """

    # OFP_AGGREGATE_STATS_REQUEST_PACK_STR
    # '!B3xII4xQQ'...table_id, pad(3), out_port, out_group, pad(4),
    #                cookie, cookie_mask
    table_id = 3
    out_port = 65037
    out_group = 6606
    cookie = 2127614848199081640
    cookie_mask = 2127614848199081641

    def test_init(self):
        match = OFPMatch()
        dl_type = 0x800
        match.set_dl_type(dl_type)
        c = OFPAggregateStatsRequest(_Datapath, self.table_id,
                                     self.out_port, self.out_group,
                                     self.cookie, self.cookie_mask,
                                     match)

        eq_(self.table_id, c.table_id)
        eq_(self.out_port, c.out_port)
        eq_(self.out_group, c.out_group)
        eq_(self.cookie, c.cookie)
        eq_(self.cookie_mask, c.cookie_mask)
        eq_(dl_type, c.match._flow.dl_type)

    def _test_serialize(self, table_id, out_port, out_group,
                        cookie, cookie_mask):
        match = OFPMatch()
        dl_type = 0x800
        match.set_dl_type(dl_type)
        c = OFPAggregateStatsRequest(_Datapath, table_id,
                                     out_port, out_group, cookie,
                                     cookie_mask, match)
        c.serialize()

        eq_(ofproto_v1_2.OFP_VERSION, c.version)
        eq_(ofproto_v1_2.OFPT_STATS_REQUEST, c.msg_type)
        eq_(0, c.xid)

        fmt = ofproto_v1_2.OFP_HEADER_PACK_STR \
            + ofproto_v1_2.OFP_STATS_REQUEST_PACK_STR[1:] \
            + ofproto_v1_2.OFP_AGGREGATE_STATS_REQUEST_PACK_STR[1:] \
            + 'HHHBB' \
            + MTEthType.pack_str[1:] + '6x'

        res = struct.unpack(fmt, str(c.buf))
        eq_(res[0], ofproto_v1_2.OFP_VERSION)
        eq_(res[1], ofproto_v1_2.OFPT_STATS_REQUEST)
        eq_(res[2], len(c.buf))
        eq_(res[3], 0)
        eq_(res[4], ofproto_v1_2.OFPST_AGGREGATE)
        eq_(res[5], 0)
        eq_(res[6], table_id)
        eq_(res[7], out_port)
        eq_(res[8], out_group)
        eq_(res[9], cookie)
        eq_(res[10], cookie_mask)
        # match
        eq_(res[11], ofproto_v1_2.OFPMT_OXM)
        eq_(res[12], 10)
        eq_(res[13], ofproto_v1_2.OFPXMC_OPENFLOW_BASIC)
        eq_(res[14] >> 1, ofproto_v1_2.OFPXMT_OFB_ETH_TYPE)
        eq_(res[14] & 0b0001, 0)
        eq_(res[15], calcsize(MTEthType.pack_str))
        eq_(res[16], dl_type)

    def test_serialize_mid(self):
        self._test_serialize(self.table_id, self.out_port, self.out_group,
                             self.cookie, self.cookie_mask)

    def test_serialize_max(self):
        table_id = 0xff
        out_port = 0xffffffff
        out_group = 0xffffffff
        cookie = 0xffffffff
        cookie_mask = 0xffffffff
        self._test_serialize(table_id, out_port, out_group,
                             cookie, cookie_mask)

    def test_serialize_min(self):
        table_id = 0
        out_port = 0
        out_group = 0
        cookie = 0
        cookie_mask = 0
        self._test_serialize(table_id, out_port, out_group,
                             cookie, cookie_mask)

    def test_serialize_p1(self):
        table_id = ofproto_v1_2.OFPTT_MAX
        self._test_serialize(table_id, self.out_port, self.out_group,
                             self.cookie, self.cookie_mask)


class TestOFPAggregateStatsReply(unittest.TestCase):
    """ Test case for ofproto_v1_2_parser.OFPAggregateStatsReply
    """

    # OFP_AGGREGATE_STATS_REPLY_PACK_STR
    # '!QQI4x'...packet_count, byte_count, flow_count, pad(4)
    packet_count = 5142202600015232219
    byte_count = 2659740543924820419
    flow_count = 1344694860

    def test_init(self):
        c = OFPAggregateStatsReply(self.packet_count, self.byte_count,
                                   self.flow_count)

        eq_(c.packet_count, self.packet_count)
        eq_(c.byte_count, self.byte_count)
        eq_(c.flow_count, self.flow_count)

    def _test_parser(self, packet_count, byte_count, flow_count):
        fmt = ofproto_v1_2.OFP_AGGREGATE_STATS_REPLY_PACK_STR
        buf = pack(fmt, packet_count, byte_count, flow_count)

        res = OFPAggregateStatsReply.parser(buf, 0)
        eq_(packet_count, res.packet_count)
        eq_(byte_count, res.byte_count)
        eq_(flow_count, res.flow_count)

    def test_parser_mid(self):
        self._test_parser(self.packet_count, self.byte_count,
                          self.flow_count)

    def test_parser_max(self):
        packet_count = 18446744073709551615
        byte_count = 18446744073709551615
        flow_count = 4294967295
        self._test_parser(packet_count, byte_count,
                          flow_count)

    def test_parser_min(self):
        packet_count = 0
        byte_count = 0
        flow_count = 0
        self._test_parser(packet_count, byte_count,
                          flow_count)


class TestOFPTableStatsRequest(unittest.TestCase):
    """ Test case for ofproto_v1_2_parser.OFPTableStatsRequest
    """

    def test_serialize(self):
        c = OFPTableStatsRequest(_Datapath)
        c.serialize()

        fmt = '!' \
            + ofproto_v1_2.OFP_HEADER_PACK_STR.replace('!', '') \
            + ofproto_v1_2.OFP_STATS_REQUEST_PACK_STR.replace('!', '')

        res = struct.unpack(fmt, str(c.buf))

        eq_(res[0], ofproto_v1_2.OFP_VERSION)
        eq_(res[1], ofproto_v1_2.OFPT_STATS_REQUEST)
        eq_(res[2], len(c.buf))
        eq_(res[3], 0)
        eq_(res[4], ofproto_v1_2.OFPST_TABLE)
        eq_(res[5], 0)


class TestOFPTableStats(unittest.TestCase):
    """ Test case for ofproto_v1_2_parser.OFPTableStats
    """

    def test_init(self):
        table_id = 91
        name = 'name'
        match = 1270985291017894273
        wildcards = 3316608530
        write_actions = 2484712402
        apply_actions = 3999715196
        write_setfields = 5142202600015232219
        apply_setfields = 2659740543924820419
        metadata_match = 2127614848199081640
        metadata_write = 2127614848199081641
        instructions = 1119692796
        config = 2226555987
        max_entries = 2506913869
        active_count = 2024581150
        lookup_count = 4620020561814017052
        matched_count = 2825167325263435621

        res = OFPTableStats(table_id, name, match, wildcards, write_actions,
                            apply_actions, write_setfields, apply_setfields,
                            metadata_match, metadata_write, instructions,
                            config, max_entries, active_count, lookup_count,
                            matched_count)

        eq_(table_id, res.table_id)
        eq_(name, res.name)
        eq_(match, res.match)
        eq_(wildcards, res.wildcards)
        eq_(write_actions, res.write_actions)
        eq_(apply_actions, res.apply_actions)
        eq_(write_setfields, res.write_setfields)
        eq_(apply_setfields, res.apply_setfields)
        eq_(metadata_match, res.metadata_match)
        eq_(metadata_write, res.metadata_write)
        eq_(instructions, res.instructions)
        eq_(config, res.config)
        eq_(max_entries, res.max_entries)
        eq_(active_count, res.active_count)
        eq_(lookup_count, res.lookup_count)
        eq_(matched_count, res.matched_count)

    def _test_parser(self, table_id, name, match, wildcards, write_actions,
                     apply_actions, write_setfields, apply_setfields,
                     metadata_match, metadata_write, instructions, config,
                     max_entries, active_count, lookup_count, matched_count):
        # OFP_TABLE_STATS_PACK_STR
        # '!B7x32sQQIIQQQQIIIIQQ'
        # ...table_id, name, match, wildcards, write_actions, apply_actions,
        #    write_setfields, apply_setfields', metadata_match, metadata_write,
        #    instructions, config, max_entries,
        #    active_count, lookup_count, matched_count
        fmt = ofproto_v1_2.OFP_TABLE_STATS_PACK_STR
        buf = pack(fmt, table_id, name, match, wildcards, write_actions,
                   apply_actions, write_setfields, apply_setfields,
                   metadata_match, metadata_write, instructions, config,
                   max_entries, active_count, lookup_count, matched_count)

        res = OFPTableStats.parser(buf, 0)

        eq_(table_id, res.table_id)
        eq_(name, res.name.replace('\x00', ''))
        eq_(match, res.match)
        eq_(wildcards, res.wildcards)
        eq_(write_actions, res.write_actions)
        eq_(apply_actions, res.apply_actions)
        eq_(write_setfields, res.write_setfields)
        eq_(apply_setfields, res.apply_setfields)
        eq_(metadata_match, res.metadata_match)
        eq_(metadata_write, res.metadata_write)
        eq_(instructions, res.instructions)
        eq_(config, res.config)
        eq_(max_entries, res.max_entries)
        eq_(active_count, res.active_count)
        eq_(lookup_count, res.lookup_count)
        eq_(matched_count, res.matched_count)

    def test_parser_mid(self):
        table_id = 91
        name = 'name'
        match = 1270985291017894273
        wildcards = 3316608530
        write_actions = 2484712402
        apply_actions = 3999715196
        write_setfields = 5142202600015232219
        apply_setfields = 2659740543924820419
        metadata_match = 2127614848199081640
        metadata_write = 2127614848199081641
        instructions = 1119692796
        config = 2226555987
        max_entries = 2506913869
        active_count = 2024581150
        lookup_count = 4620020561814017052
        matched_count = 2825167325263435621

        self._test_parser(table_id, name, match, wildcards, write_actions,
                          apply_actions, write_setfields, apply_setfields,
                          metadata_match, metadata_write, instructions, config,
                          max_entries, active_count, lookup_count,
                          matched_count)

    def test_parser_max(self):
        # '!B7x32sQQIIQQQQIIIIQQ'
        table_id = 0xff
        name = 'a' * 32
        match = 0xffffffffffffffff
        wildcards = 0xffffffffffffffff
        write_actions = 0xffffffff
        apply_actions = 0xffffffff
        write_setfields = 0xffffffffffffffff
        apply_setfields = 0xffffffffffffffff
        metadata_match = 0xffffffffffffffff
        metadata_write = 0xffffffffffffffff
        instructions = 0xffffffff
        config = 0xffffffff
        max_entries = 0xffffffff
        active_count = 0xffffffff
        lookup_count = 0xffffffffffffffff
        matched_count = 0xffffffffffffffff

        self._test_parser(table_id, name, match, wildcards, write_actions,
                          apply_actions, write_setfields, apply_setfields,
                          metadata_match, metadata_write, instructions, config,
                          max_entries, active_count, lookup_count,
                          matched_count)

    def test_parser_min(self):
        table_id = 0
        name = ''
        match = 0
        wildcards = 0
        write_actions = 0
        apply_actions = 0
        write_setfields = 0
        apply_setfields = 0
        metadata_match = 0
        metadata_write = 0
        instructions = 0
        config = 0
        max_entries = 0
        active_count = 0
        lookup_count = 0
        matched_count = 0

        self._test_parser(table_id, name, match, wildcards, write_actions,
                          apply_actions, write_setfields, apply_setfields,
                          metadata_match, metadata_write, instructions, config,
                          max_entries, active_count, lookup_count,
                          matched_count)

    def _test_parser_p(self, ofpxmt, ofpit, ofptc):
        table_id = 91
        name = 'name'
        match = ofpxmt
        wildcards = ofpxmt
        write_actions = 2484712402
        apply_actions = 3999715196
        write_setfields = ofpxmt
        apply_setfields = ofpxmt
        metadata_match = 2127614848199081640
        metadata_write = 2127614848199081641
        instructions = ofpit
        config = ofptc
        max_entries = 2506913869
        active_count = 2024581150
        lookup_count = 4620020561814017052
        matched_count = 2825167325263435621

        self._test_parser(table_id, name, match, wildcards, write_actions,
                          apply_actions, write_setfields, apply_setfields,
                          metadata_match, metadata_write, instructions, config,
                          max_entries, active_count, lookup_count,
                          matched_count)

    def test_parser_p1(self):
        self._test_parser_p(ofproto_v1_2.OFPXMT_OFB_IN_PORT,
                            ofproto_v1_2.OFPIT_GOTO_TABLE,
                            ofproto_v1_2.OFPTC_TABLE_MISS_CONTINUE)

    def test_parser_p2(self):
        self._test_parser_p(ofproto_v1_2.OFPXMT_OFB_IN_PHY_PORT,
                            ofproto_v1_2.OFPIT_WRITE_METADATA,
                            ofproto_v1_2.OFPTC_TABLE_MISS_DROP)

    def test_parser_p3(self):
        self._test_parser_p(ofproto_v1_2.OFPXMT_OFB_METADATA,
                            ofproto_v1_2.OFPIT_WRITE_ACTIONS,
                            ofproto_v1_2.OFPTC_TABLE_MISS_MASK)

    def test_parser_p4(self):
        self._test_parser_p(ofproto_v1_2.OFPXMT_OFB_ETH_DST,
                            ofproto_v1_2.OFPIT_APPLY_ACTIONS,
                            ofproto_v1_2.OFPTC_TABLE_MISS_MASK)

    def test_parser_p5(self):
        self._test_parser_p(ofproto_v1_2.OFPXMT_OFB_ETH_SRC,
                            ofproto_v1_2.OFPIT_CLEAR_ACTIONS,
                            ofproto_v1_2.OFPTC_TABLE_MISS_MASK)

    def test_parser_p6(self):
        self._test_parser_p(ofproto_v1_2.OFPXMT_OFB_ETH_TYPE,
                            ofproto_v1_2.OFPIT_EXPERIMENTER,
                            ofproto_v1_2.OFPTC_TABLE_MISS_MASK)

    def test_parser_p7(self):
        self._test_parser_p(ofproto_v1_2.OFPXMT_OFB_VLAN_VID,
                            ofproto_v1_2.OFPIT_EXPERIMENTER,
                            ofproto_v1_2.OFPTC_TABLE_MISS_MASK)

    def test_parser_p8(self):
        self._test_parser_p(ofproto_v1_2.OFPXMT_OFB_VLAN_PCP,
                            ofproto_v1_2.OFPIT_EXPERIMENTER,
                            ofproto_v1_2.OFPTC_TABLE_MISS_MASK)

    def test_parser_p9(self):
        self._test_parser_p(ofproto_v1_2.OFPXMT_OFB_IP_DSCP,
                            ofproto_v1_2.OFPIT_EXPERIMENTER,
                            ofproto_v1_2.OFPTC_TABLE_MISS_MASK)

    def test_parser_p10(self):
        self._test_parser_p(ofproto_v1_2.OFPXMT_OFB_IP_ECN,
                            ofproto_v1_2.OFPIT_EXPERIMENTER,
                            ofproto_v1_2.OFPTC_TABLE_MISS_MASK)

    def test_parser_p11(self):
        self._test_parser_p(ofproto_v1_2.OFPXMT_OFB_IP_PROTO,
                            ofproto_v1_2.OFPIT_EXPERIMENTER,
                            ofproto_v1_2.OFPTC_TABLE_MISS_MASK)

    def test_parser_p12(self):
        self._test_parser_p(ofproto_v1_2.OFPXMT_OFB_IPV4_SRC,
                            ofproto_v1_2.OFPIT_EXPERIMENTER,
                            ofproto_v1_2.OFPTC_TABLE_MISS_MASK)

    def test_parser_p13(self):
        self._test_parser_p(ofproto_v1_2.OFPXMT_OFB_IPV4_DST,
                            ofproto_v1_2.OFPIT_EXPERIMENTER,
                            ofproto_v1_2.OFPTC_TABLE_MISS_MASK)

    def test_parser_p14(self):
        self._test_parser_p(ofproto_v1_2.OFPXMT_OFB_TCP_SRC,
                            ofproto_v1_2.OFPIT_EXPERIMENTER,
                            ofproto_v1_2.OFPTC_TABLE_MISS_MASK)

    def test_parser_p15(self):
        self._test_parser_p(ofproto_v1_2.OFPXMT_OFB_TCP_DST,
                            ofproto_v1_2.OFPIT_EXPERIMENTER,
                            ofproto_v1_2.OFPTC_TABLE_MISS_MASK)

    def test_parser_p16(self):
        self._test_parser_p(ofproto_v1_2.OFPXMT_OFB_UDP_SRC,
                            ofproto_v1_2.OFPIT_EXPERIMENTER,
                            ofproto_v1_2.OFPTC_TABLE_MISS_MASK)

    def test_parser_p17(self):
        self._test_parser_p(ofproto_v1_2.OFPXMT_OFB_UDP_DST,
                            ofproto_v1_2.OFPIT_EXPERIMENTER,
                            ofproto_v1_2.OFPTC_TABLE_MISS_MASK)

    def test_parser_p18(self):
        self._test_parser_p(ofproto_v1_2.OFPXMT_OFB_SCTP_SRC,
                            ofproto_v1_2.OFPIT_EXPERIMENTER,
                            ofproto_v1_2.OFPTC_TABLE_MISS_MASK)

    def test_parser_p19(self):
        self._test_parser_p(ofproto_v1_2.OFPXMT_OFB_SCTP_DST,
                            ofproto_v1_2.OFPIT_EXPERIMENTER,
                            ofproto_v1_2.OFPTC_TABLE_MISS_MASK)

    def test_parser_p20(self):
        self._test_parser_p(ofproto_v1_2.OFPXMT_OFB_ICMPV4_TYPE,
                            ofproto_v1_2.OFPIT_EXPERIMENTER,
                            ofproto_v1_2.OFPTC_TABLE_MISS_MASK)

    def test_parser_p21(self):
        self._test_parser_p(ofproto_v1_2.OFPXMT_OFB_ICMPV4_CODE,
                            ofproto_v1_2.OFPIT_EXPERIMENTER,
                            ofproto_v1_2.OFPTC_TABLE_MISS_MASK)

    def test_parser_p22(self):
        self._test_parser_p(ofproto_v1_2.OFPXMT_OFB_ARP_OP,
                            ofproto_v1_2.OFPIT_EXPERIMENTER,
                            ofproto_v1_2.OFPTC_TABLE_MISS_MASK)

    def test_parser_p23(self):
        self._test_parser_p(ofproto_v1_2.OFPXMT_OFB_ARP_SPA,
                            ofproto_v1_2.OFPIT_EXPERIMENTER,
                            ofproto_v1_2.OFPTC_TABLE_MISS_MASK)

    def test_parser_p24(self):
        self._test_parser_p(ofproto_v1_2.OFPXMT_OFB_ARP_TPA,
                            ofproto_v1_2.OFPIT_EXPERIMENTER,
                            ofproto_v1_2.OFPTC_TABLE_MISS_MASK)

    def test_parser_p25(self):
        self._test_parser_p(ofproto_v1_2.OFPXMT_OFB_ARP_SHA,
                            ofproto_v1_2.OFPIT_EXPERIMENTER,
                            ofproto_v1_2.OFPTC_TABLE_MISS_MASK)

    def test_parser_p26(self):
        self._test_parser_p(ofproto_v1_2.OFPXMT_OFB_ARP_THA,
                            ofproto_v1_2.OFPIT_EXPERIMENTER,
                            ofproto_v1_2.OFPTC_TABLE_MISS_MASK)

    def test_parser_p27(self):
        self._test_parser_p(ofproto_v1_2.OFPXMT_OFB_IPV6_SRC,
                            ofproto_v1_2.OFPIT_EXPERIMENTER,
                            ofproto_v1_2.OFPTC_TABLE_MISS_MASK)

    def test_parser_p28(self):
        self._test_parser_p(ofproto_v1_2.OFPXMT_OFB_IPV6_DST,
                            ofproto_v1_2.OFPIT_EXPERIMENTER,
                            ofproto_v1_2.OFPTC_TABLE_MISS_MASK)

    def test_parser_p29(self):
        self._test_parser_p(ofproto_v1_2.OFPXMT_OFB_IPV6_FLABEL,
                            ofproto_v1_2.OFPIT_EXPERIMENTER,
                            ofproto_v1_2.OFPTC_TABLE_MISS_MASK)

    def test_parser_p30(self):
        self._test_parser_p(ofproto_v1_2.OFPXMT_OFB_ICMPV6_TYPE,
                            ofproto_v1_2.OFPIT_EXPERIMENTER,
                            ofproto_v1_2.OFPTC_TABLE_MISS_MASK)

    def test_parser_p31(self):
        self._test_parser_p(ofproto_v1_2.OFPXMT_OFB_ICMPV6_CODE,
                            ofproto_v1_2.OFPIT_EXPERIMENTER,
                            ofproto_v1_2.OFPTC_TABLE_MISS_MASK)

    def test_parser_p32(self):
        self._test_parser_p(ofproto_v1_2.OFPXMT_OFB_IPV6_ND_TARGET,
                            ofproto_v1_2.OFPIT_EXPERIMENTER,
                            ofproto_v1_2.OFPTC_TABLE_MISS_MASK)

    def test_parser_p33(self):
        self._test_parser_p(ofproto_v1_2.OFPXMT_OFB_IPV6_ND_SLL,
                            ofproto_v1_2.OFPIT_EXPERIMENTER,
                            ofproto_v1_2.OFPTC_TABLE_MISS_MASK)

    def test_parser_p34(self):
        self._test_parser_p(ofproto_v1_2.OFPXMT_OFB_IPV6_ND_TLL,
                            ofproto_v1_2.OFPIT_EXPERIMENTER,
                            ofproto_v1_2.OFPTC_TABLE_MISS_MASK)

    def test_parser_p35(self):
        self._test_parser_p(ofproto_v1_2.OFPXMT_OFB_MPLS_LABEL,
                            ofproto_v1_2.OFPIT_EXPERIMENTER,
                            ofproto_v1_2.OFPTC_TABLE_MISS_MASK)

    def test_parser_p36(self):
        self._test_parser_p(ofproto_v1_2.OFPXMT_OFB_MPLS_TC,
                            ofproto_v1_2.OFPIT_EXPERIMENTER,
                            ofproto_v1_2.OFPTC_TABLE_MISS_MASK)


class TestOFPPortStatsRequest(unittest.TestCase):
    """ Test case for ofproto_v1_2_parser.OFPPortStatsRequest
    """

    # OFP_PORT_STATS_REQUEST_PACK_STR
    # '!I4x'...port_no, pad(4)
    port_no = 41186

    def test_init(self):
        c = OFPPortStatsRequest(_Datapath, self.port_no)
        eq_(self.port_no, c.port_no)

    def _test_serialize(self, port_no):
        c = OFPPortStatsRequest(_Datapath, port_no)
        c.serialize()

        eq_(ofproto_v1_2.OFP_VERSION, c.version)
        eq_(ofproto_v1_2.OFPT_STATS_REQUEST, c.msg_type)
        eq_(0, c.xid)

        fmt = '!' \
            + ofproto_v1_2.OFP_HEADER_PACK_STR.replace('!', '') \
            + ofproto_v1_2.OFP_STATS_REQUEST_PACK_STR.replace('!', '') \
            + ofproto_v1_2.OFP_PORT_STATS_REQUEST_PACK_STR.replace('!', '')
        res = struct.unpack(fmt, str(c.buf))

        eq_(res[0], ofproto_v1_2.OFP_VERSION)
        eq_(res[1], ofproto_v1_2.OFPT_STATS_REQUEST)
        eq_(res[2], len(c.buf))
        eq_(res[3], 0)
        eq_(res[4], ofproto_v1_2.OFPST_PORT)
        eq_(res[5], 0)
        eq_(res[6], port_no)

    def test_serialize_mid(self):
        self._test_serialize(self.port_no)

    def test_serialize_max(self):
        self._test_serialize(ofproto_v1_2.OFPP_ANY)

    def test_serialize_min(self):
        self._test_serialize(0)

    def test_serialize_p1(self):
        self._test_serialize(ofproto_v1_2.OFPP_MAX)

    def test_serialize_p2(self):
        self._test_serialize(ofproto_v1_2.OFPP_IN_PORT)

    def test_serialize_p3(self):
        self._test_serialize(ofproto_v1_2.OFPP_TABLE)

    def test_serialize_p4(self):
        self._test_serialize(ofproto_v1_2.OFPP_NORMAL)

    def test_serialize_p5(self):
        self._test_serialize(ofproto_v1_2.OFPP_FLOOD)

    def test_serialize_p6(self):
        self._test_serialize(ofproto_v1_2.OFPP_ALL)

    def test_serialize_p7(self):
        self._test_serialize(ofproto_v1_2.OFPP_CONTROLLER)

    def test_serialize_p8(self):
        self._test_serialize(ofproto_v1_2.OFPP_LOCAL)


class TestOFPPortStats(unittest.TestCase):
    """ Test case for ofproto_v1_2_parser.OFPPortStats
    """

    def test_init(self):
        port_no = 6606
        rx_packets = 5999980397101236279
        tx_packets = 2856480458895760962
        rx_bytes = 6170274950576278921
        tx_bytes = 8638420181865882538
        rx_dropped = 6982303461569875546
        tx_dropped = 661287462113808071
        rx_errors = 3422231811478788365
        tx_errors = 6283093430376743019
        rx_frame_err = 876072919806406283
        rx_over_err = 6525873760178941600
        rx_crc_err = 8303073210207070535
        collisions = 3409801584220270201

        res = OFPPortStats(port_no, rx_packets, tx_packets,
                           rx_bytes, tx_bytes, rx_dropped, tx_dropped,
                           rx_errors, tx_errors, rx_frame_err,
                           rx_over_err, rx_crc_err, collisions)

        eq_(port_no, res.port_no)
        eq_(rx_packets, res.rx_packets)
        eq_(tx_packets, res.tx_packets)
        eq_(rx_bytes, res.rx_bytes)
        eq_(tx_bytes, res.tx_bytes)
        eq_(rx_dropped, res.rx_dropped)
        eq_(tx_dropped, res.tx_dropped)
        eq_(rx_errors, res.rx_errors)
        eq_(tx_errors, res.tx_errors)
        eq_(rx_frame_err, res.rx_frame_err)
        eq_(rx_over_err, res.rx_over_err)
        eq_(rx_crc_err, res.rx_crc_err)
        eq_(collisions, res.collisions)

    def _test_parser(self, port_no, rx_packets, tx_packets,
                     rx_bytes, tx_bytes, rx_dropped, tx_dropped,
                     rx_errors, tx_errors, rx_frame_err,
                     rx_over_err, rx_crc_err, collisions):

        # OFP_PORT_STATS_PACK_STR = '!H6xQQQQQQQQQQQQ'
        fmt = ofproto_v1_2.OFP_PORT_STATS_PACK_STR
        buf = pack(fmt, port_no, rx_packets, tx_packets, rx_bytes, tx_bytes,
                   rx_dropped, tx_dropped, rx_errors, tx_errors, rx_frame_err,
                   rx_over_err, rx_crc_err, collisions)

        res = OFPPortStats.parser(buf, 0)

        eq_(port_no, res.port_no)
        eq_(rx_packets, res.rx_packets)
        eq_(tx_packets, res.tx_packets)
        eq_(rx_bytes, res.rx_bytes)
        eq_(tx_bytes, res.tx_bytes)
        eq_(rx_dropped, res.rx_dropped)
        eq_(tx_dropped, res.tx_dropped)
        eq_(rx_errors, res.rx_errors)
        eq_(tx_errors, res.tx_errors)
        eq_(rx_frame_err, res.rx_frame_err)
        eq_(rx_over_err, res.rx_over_err)
        eq_(rx_crc_err, res.rx_crc_err)
        eq_(collisions, res.collisions)

    def test_parser_mid(self):
        port_no = 6606
        rx_packets = 5999980397101236279
        tx_packets = 2856480458895760962
        rx_bytes = 6170274950576278921
        tx_bytes = 8638420181865882538
        rx_dropped = 6982303461569875546
        tx_dropped = 661287462113808071
        rx_errors = 3422231811478788365
        tx_errors = 6283093430376743019
        rx_frame_err = 876072919806406283
        rx_over_err = 6525873760178941600
        rx_crc_err = 8303073210207070535
        collisions = 3409801584220270201

        self._test_parser(port_no, rx_packets, tx_packets, rx_bytes, tx_bytes,
                          rx_dropped, tx_dropped, rx_errors, tx_errors,
                          rx_frame_err, rx_over_err, rx_crc_err, collisions)

    def test_parser_max(self):
        port_no = 0xffffffff
        rx_packets = 0xffffffffffffffff
        tx_packets = 0xffffffffffffffff
        rx_bytes = 0xffffffffffffffff
        tx_bytes = 0xffffffffffffffff
        rx_dropped = 0xffffffffffffffff
        tx_dropped = 0xffffffffffffffff
        rx_errors = 0xffffffffffffffff
        tx_errors = 0xffffffffffffffff
        rx_frame_err = 0xffffffffffffffff
        rx_over_err = 0xffffffffffffffff
        rx_crc_err = 0xffffffffffffffff
        collisions = 0xffffffffffffffff

        self._test_parser(port_no, rx_packets, tx_packets, rx_bytes, tx_bytes,
                          rx_dropped, tx_dropped, rx_errors, tx_errors,
                          rx_frame_err, rx_over_err, rx_crc_err, collisions)

    def test_parser_min(self):
        port_no = 0
        rx_packets = 0
        tx_packets = 0
        rx_bytes = 0
        tx_bytes = 0
        rx_dropped = 0
        tx_dropped = 0
        rx_errors = 0
        tx_errors = 0
        rx_frame_err = 0
        rx_over_err = 0
        rx_crc_err = 0
        collisions = 0

        self._test_parser(port_no, rx_packets, tx_packets, rx_bytes, tx_bytes,
                          rx_dropped, tx_dropped, rx_errors, tx_errors,
                          rx_frame_err, rx_over_err, rx_crc_err, collisions)

    def _test_parser_p(self, port_no):
        port_no = port_no
        rx_packets = 5999980397101236279
        tx_packets = 2856480458895760962
        rx_bytes = 6170274950576278921
        tx_bytes = 8638420181865882538
        rx_dropped = 6982303461569875546
        tx_dropped = 661287462113808071
        rx_errors = 3422231811478788365
        tx_errors = 6283093430376743019
        rx_frame_err = 876072919806406283
        rx_over_err = 6525873760178941600
        rx_crc_err = 8303073210207070535
        collisions = 3409801584220270201

        self._test_parser(port_no, rx_packets, tx_packets, rx_bytes, tx_bytes,
                          rx_dropped, tx_dropped, rx_errors, tx_errors,
                          rx_frame_err, rx_over_err, rx_crc_err, collisions)

    def test_parser_p1(self):
        self._test_parser_p(ofproto_v1_2.OFPP_MAX)

    def test_parser_p2(self):
        self._test_parser_p(ofproto_v1_2.OFPP_IN_PORT)

    def test_parser_p3(self):
        self._test_parser_p(ofproto_v1_2.OFPP_TABLE)

    def test_parser_p4(self):
        self._test_parser_p(ofproto_v1_2.OFPP_NORMAL)

    def test_parser_p5(self):
        self._test_parser_p(ofproto_v1_2.OFPP_FLOOD)

    def test_parser_p6(self):
        self._test_parser_p(ofproto_v1_2.OFPP_ALL)

    def test_parser_p7(self):
        self._test_parser_p(ofproto_v1_2.OFPP_CONTROLLER)

    def test_parser_p8(self):
        self._test_parser_p(ofproto_v1_2.OFPP_LOCAL)


class TestOFPQueueStatsRequest(unittest.TestCase):
    """ Test case for ofproto_v1_2_parser.OFPQueueStatsRequest
    """

    # OFP_QUEUE_STATS_REQUEST_PACK_STR
    # '!II'...port_no, queue_id
    port_no = 41186
    queue_id = 6606

    def test_init(self):
        c = OFPQueueStatsRequest(_Datapath, self.port_no, self.queue_id)

        eq_(self.port_no, c.port_no)
        eq_(self.queue_id, c.queue_id)

    def _test_serialize(self, port_no, queue_id):
        c = OFPQueueStatsRequest(_Datapath, port_no, queue_id)
        c.serialize()

        eq_(ofproto_v1_2.OFP_VERSION, c.version)
        eq_(ofproto_v1_2.OFPT_STATS_REQUEST, c.msg_type)
        eq_(0, c.xid)

        fmt = '!' \
            + ofproto_v1_2.OFP_HEADER_PACK_STR.replace('!', '') \
            + ofproto_v1_2.OFP_STATS_REQUEST_PACK_STR.replace('!', '') \
            + ofproto_v1_2.OFP_QUEUE_STATS_REQUEST_PACK_STR.replace('!', '')
        res = struct.unpack(fmt, str(c.buf))

        eq_(res[0], ofproto_v1_2.OFP_VERSION)
        eq_(res[1], ofproto_v1_2.OFPT_STATS_REQUEST)
        eq_(res[2], len(c.buf))
        eq_(res[3], 0)
        eq_(res[4], ofproto_v1_2.OFPST_QUEUE)
        eq_(res[5], 0)
        eq_(res[6], port_no)
        eq_(res[7], queue_id)

    def test_serialize_mid(self):
        self._test_serialize(self.port_no, self.queue_id)

    def test_serialize_max(self):
        self._test_serialize(0xffffffff, 0xffffffff)

    def test_serialize_min(self):
        self._test_serialize(0, 0)

    def test_serialize_p1(self):
        self._test_serialize(ofproto_v1_2.OFPP_MAX, self.queue_id)

    def test_serialize_p2(self):
        self._test_serialize(ofproto_v1_2.OFPP_IN_PORT, self.queue_id)

    def test_serialize_p3(self):
        self._test_serialize(ofproto_v1_2.OFPP_NORMAL, self.queue_id)

    def test_serialize_p4(self):
        self._test_serialize(ofproto_v1_2.OFPP_TABLE, self.queue_id)

    def test_serialize_p5(self):
        self._test_serialize(ofproto_v1_2.OFPP_FLOOD, self.queue_id)

    def test_serialize_p6(self):
        self._test_serialize(ofproto_v1_2.OFPP_ALL, self.queue_id)

    def test_serialize_p7(self):
        self._test_serialize(ofproto_v1_2.OFPP_CONTROLLER, self.queue_id)

    def test_serialize_p8(self):
        self._test_serialize(ofproto_v1_2.OFPP_LOCAL, self.queue_id)


class TestOFPQueueStats(unittest.TestCase):
    """ Test case for ofproto_v1_2_parser.OFPQueueStats
    """

    def test_init(self):
        port_no = 41186
        queue_id = 6606
        tx_bytes = 8638420181865882538
        tx_packets = 2856480458895760962
        tx_errors = 6283093430376743019

        res = OFPQueueStats(port_no, queue_id, tx_bytes,
                            tx_packets, tx_errors)

        eq_(port_no, res.port_no)
        eq_(queue_id, res.queue_id)
        eq_(tx_bytes, res.tx_bytes)
        eq_(tx_packets, res.tx_packets)
        eq_(tx_errors, res.tx_errors)

    def _test_parser(self, port_no, queue_id, tx_bytes,
                     tx_packets, tx_errors):

        # OFP_QUEUE_STATS_PACK_STR = '!IIQQQ'
        fmt = ofproto_v1_2.OFP_QUEUE_STATS_PACK_STR
        buf = pack(fmt, port_no, queue_id, tx_bytes, tx_packets, tx_errors)
        res = OFPQueueStats.parser(buf, 0)

        eq_(port_no, res.port_no)
        eq_(queue_id, res.queue_id)
        eq_(tx_bytes, res.tx_bytes)
        eq_(tx_packets, res.tx_packets)
        eq_(tx_errors, res.tx_errors)

    def test_parser_mid(self):
        port_no = 41186
        queue_id = 6606
        tx_bytes = 8638420181865882538
        tx_packets = 2856480458895760962
        tx_errors = 6283093430376743019

        self._test_parser(port_no, queue_id, tx_bytes,
                          tx_packets, tx_errors)

    def test_parser_max(self):
        port_no = 0xffffffff
        queue_id = 0xffffffff
        tx_bytes = 0xffffffffffffffff
        tx_packets = 0xffffffffffffffff
        tx_errors = 0xffffffffffffffff

        self._test_parser(port_no, queue_id, tx_bytes,
                          tx_packets, tx_errors)

    def test_parser_min(self):
        port_no = 0
        queue_id = 0
        tx_bytes = 0
        tx_packets = 0
        tx_errors = 0

        self._test_parser(port_no, queue_id, tx_bytes,
                          tx_packets, tx_errors)

    def _test_parser_p(self, port_no):
        queue_id = 6606
        tx_bytes = 8638420181865882538
        tx_packets = 2856480458895760962
        tx_errors = 6283093430376743019

        self._test_parser(port_no, queue_id, tx_bytes,
                          tx_packets, tx_errors)

    def test_parser_p1(self):
        self._test_parser_p(ofproto_v1_2.OFPP_MAX)

    def test_parser_p2(self):
        self._test_parser_p(ofproto_v1_2.OFPP_IN_PORT)

    def test_parser_p3(self):
        self._test_parser_p(ofproto_v1_2.OFPP_TABLE)

    def test_parser_p4(self):
        self._test_parser_p(ofproto_v1_2.OFPP_NORMAL)

    def test_parser_p5(self):
        self._test_parser_p(ofproto_v1_2.OFPP_FLOOD)

    def test_parser_p6(self):
        self._test_parser_p(ofproto_v1_2.OFPP_ALL)

    def test_parser_p7(self):
        self._test_parser_p(ofproto_v1_2.OFPP_CONTROLLER)

    def test_parser_p8(self):
        self._test_parser_p(ofproto_v1_2.OFPP_LOCAL)


class TestOFPBucketCounter(unittest.TestCase):
    """ Test case for ofproto_v1_2_parser.OFPBucketCounter
    """

    # OFP_BUCKET_COUNTER_PACK_STR = '!QQ'
    packet_count = 6489108735192644493
    byte_count = 7334344481123449724

    def test_init(self):
        c = OFPBucketCounter(self.packet_count, self.byte_count)

        eq_(self.packet_count, c.packet_count)
        eq_(self.byte_count, c.byte_count)

    def _test_parser(self, packet_count, byte_count):
        fmt = ofproto_v1_2.OFP_BUCKET_COUNTER_PACK_STR
        buf = pack(fmt, packet_count, byte_count)

        res = OFPBucketCounter.parser(buf, 0)
        eq_(packet_count, res.packet_count)
        eq_(byte_count, res.byte_count)

    def test_parser_mid(self):
        self._test_parser(self.packet_count, self.byte_count)

    def test_parser_max(self):
        packet_count = 18446744073709551615
        byte_count = 18446744073709551615
        self._test_parser(packet_count, byte_count)

    def test_parser_min(self):
        packet_count = 0
        byte_count = 0
        self._test_parser(packet_count, byte_count)


class TestOFPGroupStatsRequest(unittest.TestCase):
    """ Test case for ofproto_v1_2_parser.OFPGroupStatsRequest
    """

    # OFP_GROUP_STATS_REQUEST_PACK_STR
    # '!I4x'...group_id, pad(4)
    group_id = 6606

    def test_init(self):
        c = OFPGroupStatsRequest(_Datapath, self.group_id)
        eq_(self.group_id, c.group_id)

    def _test_serialize(self, group_id):
        c = OFPGroupStatsRequest(_Datapath, group_id)
        c.serialize()

        eq_(ofproto_v1_2.OFP_VERSION, c.version)
        eq_(ofproto_v1_2.OFPT_STATS_REQUEST, c.msg_type)
        eq_(0, c.xid)

        fmt = '!' \
            + ofproto_v1_2.OFP_HEADER_PACK_STR.replace('!', '') \
            + ofproto_v1_2.OFP_STATS_REQUEST_PACK_STR.replace('!', '') \
            + ofproto_v1_2.OFP_GROUP_STATS_REQUEST_PACK_STR.replace('!', '')
        res = struct.unpack(fmt, str(c.buf))

        eq_(res[0], ofproto_v1_2.OFP_VERSION)
        eq_(res[1], ofproto_v1_2.OFPT_STATS_REQUEST)
        eq_(res[2], len(c.buf))
        eq_(res[3], 0)
        eq_(res[4], ofproto_v1_2.OFPST_GROUP)
        eq_(res[5], 0)
        eq_(res[6], group_id)

    def test_serialize_mid(self):
        self._test_serialize(self.group_id)

    def test_serialize_max(self):
        self._test_serialize(0xffffffff)

    def test_serialize_min(self):
        self._test_serialize(0)

    def test_serialize_p1(self):
        self._test_serialize(ofproto_v1_2.OFPG_MAX)

    def test_serialize_p2(self):
        self._test_serialize(ofproto_v1_2.OFPG_ALL)


class TestOFPGroupStats(unittest.TestCase):
    """ Test case for ofproto_v1_2_parser.OFPGroupStats
    """

    # OFP_GROUP_STATS_PACK_STR = '!H2xII4xQQ'
    length = ofproto_v1_2.OFP_GROUP_STATS_SIZE \
        + ofproto_v1_2.OFP_BUCKET_COUNTER_SIZE
    group_id = 6606
    ref_count = 2102
    packet_count = 6489108735192644493
    byte_count = 7334344481123449724

    # OFP_BUCKET_COUNTER_PACK_STR = '!QQ'
    buck_packet_count = 3519264449364891087
    buck_byte_count = 3123449724733434448
    bucket_counters = [OFPBucketCounter(buck_packet_count, buck_byte_count)]
    buf_bucket_counters = pack(ofproto_v1_2.OFP_BUCKET_COUNTER_PACK_STR,
                               buck_packet_count, buck_byte_count)

    fmt = ofproto_v1_2.OFP_GROUP_STATS_PACK_STR
    buf = pack(fmt, length, group_id, ref_count, packet_count, byte_count) \
        + buf_bucket_counters

    def test_init(self):
        c = OFPGroupStats(self.group_id, self.ref_count,
                          self.packet_count, self.byte_count,
                          self.bucket_counters)

        eq_(self.group_id, c.group_id)
        eq_(self.ref_count, c.ref_count)
        eq_(self.packet_count, c.packet_count)
        eq_(self.byte_count, c.byte_count)
        eq_(self.bucket_counters, c.bucket_counters)

    def _test_parser(self, group_id, ref_count, packet_count,
                     byte_count, bucket_counter_cnt):
        # OFP_GROUP_STATS_PACK_STR = '!H2xII4xQQ'
        length = ofproto_v1_2.OFP_GROUP_STATS_SIZE \
            + (ofproto_v1_2.OFP_BUCKET_COUNTER_SIZE * bucket_counter_cnt)
        fmt = ofproto_v1_2.OFP_GROUP_STATS_PACK_STR
        buf = pack(fmt, length, group_id, ref_count,
                   packet_count, byte_count)

        bucket_counters = []
        for b in range(bucket_counter_cnt):
            # OFP_BUCKET_COUNTER_PACK_STR = '!QQ'
            buck_packet_count = b
            buck_byte_count = b
            bucket_counter = OFPBucketCounter(buck_packet_count,
                                              buck_byte_count)
            bucket_counters.append(bucket_counter)
            buf_bucket_counters = \
                pack(ofproto_v1_2.OFP_BUCKET_COUNTER_PACK_STR,
                     buck_packet_count, buck_byte_count)
            buf += buf_bucket_counters

        res = OFPGroupStats.parser(buf, 0)

        # 32
        eq_(length, res.length)
        eq_(group_id, res.group_id)
        eq_(ref_count, res.ref_count)
        eq_(packet_count, res.packet_count)
        eq_(byte_count, res.byte_count)

        # 32 + 16 * bucket_counter_cnt < 65535 byte
        # bucket_counter_cnt <= 4093
        for b in range(bucket_counter_cnt):
            eq_(bucket_counters[b].packet_count,
                res.bucket_counters[b].packet_count)
            eq_(bucket_counters[b].byte_count,
                res.bucket_counters[b].byte_count)

    def test_parser_mid(self):
        bucket_counter_cnt = 2046
        self._test_parser(self.group_id, self.ref_count,
                          self.packet_count, self.byte_count,
                          bucket_counter_cnt)

    def test_parser_max(self):
        group_id = 4294967295
        ref_count = 4294967295
        packet_count = 18446744073709551615
        byte_count = 18446744073709551615
        bucket_counter_cnt = 4093
        self._test_parser(group_id, ref_count,
                          packet_count, byte_count,
                          bucket_counter_cnt)

    def test_parser_min(self):
        group_id = 0
        ref_count = 0
        packet_count = 0
        byte_count = 0
        bucket_counter_cnt = 0
        self._test_parser(group_id, ref_count,
                          packet_count, byte_count,
                          bucket_counter_cnt)


class TestOFPGroupDescStatsRequest(unittest.TestCase):
    """ Test case for ofproto_v1_2_parser.OFPGroupDescStatsRequest
    """

    def test_serialize(self):
        c = OFPGroupDescStatsRequest(_Datapath)
        c.serialize()

        fmt = '!' \
            + ofproto_v1_2.OFP_HEADER_PACK_STR.replace('!', '') \
            + ofproto_v1_2.OFP_STATS_REQUEST_PACK_STR.replace('!', '')

        res = struct.unpack(fmt, str(c.buf))

        eq_(res[0], ofproto_v1_2.OFP_VERSION)
        eq_(res[1], ofproto_v1_2.OFPT_STATS_REQUEST)
        eq_(res[2], len(c.buf))
        eq_(res[3], 0)
        eq_(res[4], ofproto_v1_2.OFPST_GROUP_DESC)
        eq_(res[5], 0)


class TestOFPGroupDescStats(unittest.TestCase):
    """ Test case for ofproto_v1_2_parser.OFPGroupDescStats
    """

    # OFP_GROUP_DESC_STATS_PACK_STR = '!HBxI'
    length = ofproto_v1_2.OFP_GROUP_DESC_STATS_SIZE \
        + ofproto_v1_2.OFP_BUCKET_SIZE \
        + ofproto_v1_2.OFP_ACTION_OUTPUT_SIZE
    type_ = 128
    group_id = 6606

    # OFP_ACTION (OFP_ACTION_OUTPUT)
    port = 0x00002ae0
    max_len = ofproto_v1_2.OFP_ACTION_OUTPUT_SIZE
    actions = [OFPActionOutput(port, max_len)]
    buf_actions = bytearray()
    actions[0].serialize(buf_actions, 0)

    # OFP_BUCKET
    weight = 4386
    watch_port = 8006
    watch_group = 3
    buckets = [OFPBucket(weight, watch_port, watch_group, actions)]

    bucket_cnt = 1024

    def test_init(self):
        c = OFPGroupDescStats(self.type_, self.group_id, self.buckets)

        eq_(self.type_, c.type)
        eq_(self.group_id, c.group_id)
        eq_(self.buckets, c.buckets)

    def _test_parser(self, type_, group_id, bucket_cnt):
        # OFP_GROUP_DESC_STATS_PACK_STR = '!HBxI'
        length = ofproto_v1_2.OFP_GROUP_DESC_STATS_SIZE \
            + (ofproto_v1_2.OFP_BUCKET_SIZE
               + ofproto_v1_2.OFP_ACTION_OUTPUT_SIZE) * bucket_cnt

        fmt = ofproto_v1_2.OFP_GROUP_DESC_STATS_PACK_STR
        buf = pack(fmt, length, type_, group_id)

        buckets = []
        for b in range(bucket_cnt):
            # OFP_BUCKET
            weight = watch_port = watch_group = b
            bucket = OFPBucket(weight,
                               watch_port, watch_group,
                               self.actions)
            buckets.append(bucket)
            buf_buckets = bytearray()
            buckets[b].serialize(buf_buckets, 0)
            buf += str(buf_buckets)

        res = OFPGroupDescStats.parser(buf, 0)

        # 8 byte
        eq_(type_, res.type)
        eq_(group_id, res.group_id)

        # 8 + ( 16 + 16 ) * b < 65535 byte
        # b <= 2047 byte
        for b in range(bucket_cnt):
            eq_(buckets[b].weight, res.buckets[b].weight)
            eq_(buckets[b].watch_port, res.buckets[b].watch_port)
            eq_(buckets[b].watch_group, res.buckets[b].watch_group)
            eq_(buckets[b].actions[0].port,
                res.buckets[b].actions[0].port)
            eq_(buckets[b].actions[0].max_len,
                res.buckets[b].actions[0].max_len)

    def test_parser_mid(self):
        self._test_parser(self.type_, self.group_id, self.bucket_cnt)

    def test_parser_max(self):
        group_id = 4294967295
        type_ = 255
        bucket_cnt = 2047
        self._test_parser(type_, group_id, bucket_cnt)

    def test_parser_min(self):
        group_id = 0
        type_ = ofproto_v1_2.OFPGT_ALL
        bucket_cnt = 0
        self._test_parser(type_, group_id, bucket_cnt)

    def test_parser_p1(self):
        type_ = ofproto_v1_2.OFPGT_SELECT
        self._test_parser(type_, self.group_id, self.bucket_cnt)

    def test_parser_p2(self):
        type_ = ofproto_v1_2.OFPGT_INDIRECT
        self._test_parser(type_, self.group_id, self.bucket_cnt)

    def test_parser_p3(self):
        type_ = ofproto_v1_2.OFPGT_FF
        self._test_parser(type_, self.group_id, self.bucket_cnt)


class TestOFPGroupFeaturesStatsRequest(unittest.TestCase):
    """ Test case for ofproto_v1_2_parser.OFPGroupFeaturesStatsRequest
    """

    def test_serialize(self):
        c = OFPGroupFeaturesStatsRequest(_Datapath)
        c.serialize()

        fmt = '!' \
            + ofproto_v1_2.OFP_HEADER_PACK_STR.replace('!', '') \
            + ofproto_v1_2.OFP_STATS_REQUEST_PACK_STR.replace('!', '')

        res = struct.unpack(fmt, str(c.buf))

        eq_(res[0], ofproto_v1_2.OFP_VERSION)
        eq_(res[1], ofproto_v1_2.OFPT_STATS_REQUEST)
        eq_(res[2], len(c.buf))
        eq_(res[3], 0)
        eq_(res[4], ofproto_v1_2.OFPST_GROUP_FEATURES)
        eq_(res[5], 0)


class TestOFPGroupFeaturesStats(unittest.TestCase):
    """ Test case for ofproto_v1_2_parser.OFPGroupFeaturesStats
    """

    # OFP_GROUP_FEATURES_STATS_PACK_STR = '!II4I4I'
    types = ofproto_v1_2.OFPGT_ALL
    capabilities = ofproto_v1_2.OFPGFC_SELECT_WEIGHT
    max_groups = [1, 2, 3, 4]
    actions = [1 << ofproto_v1_2.OFPAT_OUTPUT,
               1 << ofproto_v1_2.OFPAT_COPY_TTL_OUT,
               1 << ofproto_v1_2.OFPAT_SET_MPLS_TTL,
               1 << ofproto_v1_2.OFPAT_PUSH_VLAN]

    def test_init(self):
        c = OFPGroupFeaturesStats(self.types, self.capabilities,
                                  self.max_groups, self.actions)
        eq_(self.types, c.types)
        eq_(self.capabilities, c.capabilities)
        eq_(self.max_groups, c.max_groups)
        eq_(self.actions, c.actions)

    def _test_parser(self, types, capabilities, max_groups, actions):

        buf = pack('!I', types) \
            + pack('!I', capabilities) \
            + pack('!I', max_groups[0]) \
            + pack('!I', max_groups[1]) \
            + pack('!I', max_groups[2]) \
            + pack('!I', max_groups[3]) \
            + pack('!I', actions[0]) \
            + pack('!I', actions[1]) \
            + pack('!I', actions[2]) \
            + pack('!I', actions[3])

        res = OFPGroupFeaturesStats.parser(buf, 0)

        # max_groups and actions after the parser is tuple
        eq_(types, res.types)
        eq_(capabilities, res.capabilities)
        eq_(max_groups, res.max_groups)
        eq_(actions, res.actions)

    def test_parser_mid(self):
        self._test_parser(self.types, self.capabilities,
                          self.max_groups, self.actions)

    def test_parser_max(self):
        types = 0b11111111111111111111111111111111
        capabilities = 0b11111111111111111111111111111111
        max_groups = [4294967295] * 4
        actions = [0b11111111111111111111111111111111] * 4
        self._test_parser(types, capabilities,
                          max_groups, actions)

    def test_parser_min(self):
        types = 0b00000000000000000000000000000000
        capabilities = 0b00000000000000000000000000000000
        max_groups = [0] * 4
        actions = [0b00000000000000000000000000000000] * 4
        self._test_parser(types, capabilities,
                          max_groups, actions)

    def _test_parser_p(self, types, capabilities, actions):
        self._test_parser(types, capabilities,
                          self.max_groups, actions)

    def test_parser_p1(self):
        actions = [1 << ofproto_v1_2.OFPAT_COPY_TTL_IN,
                   1 << ofproto_v1_2.OFPAT_DEC_MPLS_TTL,
                   1 << ofproto_v1_2.OFPAT_POP_VLAN,
                   1 << ofproto_v1_2.OFPAT_PUSH_MPLS]
        self._test_parser_p(1 << ofproto_v1_2.OFPGT_ALL,
                            ofproto_v1_2.OFPGFC_CHAINING,
                            actions)

    def test_parser_p2(self):
        actions = [1 << ofproto_v1_2.OFPAT_POP_MPLS,
                   1 << ofproto_v1_2.OFPAT_SET_QUEUE,
                   1 << ofproto_v1_2.OFPAT_GROUP,
                   1 << ofproto_v1_2.OFPAT_SET_NW_TTL]
        self._test_parser_p(1 << ofproto_v1_2.OFPGT_SELECT,
                            ofproto_v1_2.OFPGFC_SELECT_WEIGHT,
                            actions)

    def test_parser_p3(self):
        actions = [1 << ofproto_v1_2.OFPAT_DEC_NW_TTL,
                   1 << ofproto_v1_2.OFPAT_SET_FIELD,
                   1 << ofproto_v1_2.OFPAT_GROUP,
                   1 << ofproto_v1_2.OFPAT_SET_NW_TTL]
        self._test_parser_p(1 << ofproto_v1_2.OFPGT_SELECT,
                            ofproto_v1_2.OFPGFC_SELECT_LIVENESS,
                            actions)

    def test_parser_p4(self):
        self._test_parser_p(1 << ofproto_v1_2.OFPGT_INDIRECT,
                            ofproto_v1_2.OFPGFC_CHAINING,
                            self.actions)

    def test_parser_p5(self):
        self._test_parser_p(1 << ofproto_v1_2.OFPGT_FF,
                            ofproto_v1_2.OFPGFC_CHAINING_CHECKS,
                            self.actions)


class TestOFPQueueGetConfigRequest(unittest.TestCase):
    """ Test case for ofproto_v1_2_parser.OFPQueueGetConfigRequest
    """

    # OFP_QUEUE_GET_CONFIG_REQUEST_PACK_STR v1.2
    # '!I4x'...port, pad(4)
    port = 41186

    def test_init(self):
        c = OFPQueueGetConfigRequest(_Datapath, self.port)
        eq_(self.port, c.port)

    def _test_serialize(self, port):
        c = OFPQueueGetConfigRequest(_Datapath, port)
        c.serialize()

        eq_(ofproto_v1_2.OFP_VERSION, c.version)
        eq_(ofproto_v1_2.OFPT_QUEUE_GET_CONFIG_REQUEST, c.msg_type)
        eq_(0, c.xid)

        fmt = ofproto_v1_2.OFP_HEADER_PACK_STR \
            + ofproto_v1_2.OFP_QUEUE_GET_CONFIG_REQUEST_PACK_STR[1:]

        res = struct.unpack(fmt, str(c.buf))
        eq_(res[0], ofproto_v1_2.OFP_VERSION)
        eq_(res[1], ofproto_v1_2.OFPT_QUEUE_GET_CONFIG_REQUEST)
        eq_(res[2], len(c.buf))
        eq_(res[3], 0)
        eq_(res[4], port)

    def test_serialize_mid(self):
        self._test_serialize(self.port)

    def test_serialize_max(self):
        self._test_serialize(0xffffffff)

    def test_serialize_min(self):
        self._test_serialize(0)

    def test_serialize_p1(self):
        self._test_serialize(ofproto_v1_2.OFPP_MAX)


class TestOFPQueuePropHeader(unittest.TestCase):
    """ Test case for ofproto_v1_2_parser.OFPQueuePropHeader
    """

    # OFP_QUEUE_PROP_HEADER_PACK_STR = '!HH4x'
    property_ = 1
    len_ = 10

    def test_init(self):
        c = OFPQueuePropHeader(self.property_, self.len_)
        eq_(self.property_, c.property)
        eq_(self.len_, c.len)

    def _test_serialize(self, property_, len_):
        c = OFPQueuePropHeader(property_, len_)
        buf = bytearray()
        c.serialize(buf, 0)

        fmt = ofproto_v1_2.OFP_QUEUE_PROP_HEADER_PACK_STR
        res = struct.unpack(fmt, buffer(buf))

        eq_(res[0], property_)
        eq_(res[1], len_)

    def test_serialize_mid(self):
        self._test_serialize(self.property_, self.len_)

    def test_serialize_max(self):
        self._test_serialize(0xffff, 0xffff)

    def test_serialize_min(self):
        self._test_serialize(0, 0)


class TestOFPPacketQueue(unittest.TestCase):
    """ Test case for ofproto_v1_2_parser.OFPPacketQueue
    """

    def test_init(self):
        queue_id = 1
        port = 2
        len_ = 3
        properties = [4, 5, 6]
        c = OFPPacketQueue(queue_id, port, properties)

        eq_(queue_id, c.queue_id)
        eq_(port, c.port)
        eq_(properties, c.properties)

    def _test_parser(self, queue_id, port, prop_cnt):
        # OFP_PACKET_QUEUE_PACK_STR = '!IIH6x'
        fmt = ofproto_v1_2.OFP_PACKET_QUEUE_PACK_STR
        queue_len = ofproto_v1_2.OFP_PACKET_QUEUE_SIZE \
            + ofproto_v1_2.OFP_QUEUE_PROP_MIN_RATE_SIZE * prop_cnt

        buf = pack(fmt, queue_id, port, queue_len)

        for rate in range(prop_cnt):
            # OFP_QUEUE_PROP_HEADER_PACK_STR = '!HH4x'
            fmt = ofproto_v1_2.OFP_QUEUE_PROP_HEADER_PACK_STR
            prop_type = ofproto_v1_2.OFPQT_MIN_RATE
            prop_len = ofproto_v1_2.OFP_QUEUE_PROP_MIN_RATE_SIZE
            buf += pack(fmt, prop_type, prop_len)

            # OFP_QUEUE_PROP_MIN_RATE_PACK_STR = '!H6x'
            fmt = ofproto_v1_2.OFP_QUEUE_PROP_MIN_RATE_PACK_STR
            prop_rate = rate
            buf += pack(fmt, prop_rate)

        res = OFPPacketQueue.parser(buf, 0)

        eq_(queue_id, res.queue_id)
        eq_(port, res.port)
        eq_(queue_len, res.len)
        eq_(prop_cnt, len(res.properties))

        for rate, p in enumerate(res.properties):
            eq_(prop_type, p.property)
            eq_(prop_len, p.len)
            eq_(rate, p.rate)

    def test_parser_mid(self):
        queue_id = 1
        port = 2
        prop_cnt = 2
        self._test_parser(queue_id, port, prop_cnt)

    def test_parser_max(self):
        # queue_len format is 'H' < number 65535
        #
        # queue_len = OFP_PACKET_QUEUE_SIZE(16)
        #     + OFP_QUEUE_PROP_MIN_RATE_SIZE(16) * N
        # max_prop_cnt = (65535 - 16) / 16 = 4094
        queue_id = 0xffffffff
        port = 0xffffffff
        prop_cnt = 4094
        self._test_parser(queue_id, port, prop_cnt)

    def test_parser_min(self):
        queue_id = 0
        port = 0
        prop_cnt = 0
        self._test_parser(queue_id, port, prop_cnt)


class TestOFPQueuePropMinRate(unittest.TestCase):
    """ Test case for ofproto_v1_2_parser.OFPQueuePropMinRate
    """

    def _test_parser(self, rate):
        # OFP_QUEUE_PROP_MIN_RATE_PACK_STR...H6x
        buf = pack(ofproto_v1_2.OFP_QUEUE_PROP_MIN_RATE_PACK_STR, rate)
        res = OFPQueuePropMinRate.parser(buf, 0)
        eq_(rate, res.rate)

    def test_parser_mid(self):
        self._test_parser(32768)

    def test_parser_max(self):
        self._test_parser(0xffff)

    def test_parser_min(self):
        self._test_parser(0)


class TestOFPQueuePropMaxRate(unittest.TestCase):
    """ Test case for ofproto_v1_2_parser.OFPQueuePropMaxRate
    """

    rate = 100
    buf = pack(ofproto_v1_2.OFP_QUEUE_PROP_MAX_RATE_PACK_STR, rate)
    c = OFPQueuePropMaxRate(rate)

    def _test_parser(self, rate):
        # OFP_QUEUE_PROP_MAX_RATE_PACK_STR...H6x
        buf = pack(ofproto_v1_2.OFP_QUEUE_PROP_MAX_RATE_PACK_STR, rate)
        res = OFPQueuePropMaxRate.parser(buf, 0)
        eq_(rate, res.rate)

    def test_parser_mid(self):
        self._test_parser(100)

    def test_parser_max(self):
        self._test_parser(0xffff)

    def test_parser_min(self):
        self._test_parser(0)


class TestOFPQueueGetConfigReply(unittest.TestCase):
    """ Test case for ofproto_v1_2_parser.OFPQueueGetConfigReply
    """

    def _test_parser(self, xid, port, queue_cnt):
        version = ofproto_v1_2.OFP_VERSION
        msg_type = ofproto_v1_2.OFPT_QUEUE_GET_CONFIG_REPLY

        queues_len = 0
        for q in range(queue_cnt):
            queues_len += ofproto_v1_2.OFP_PACKET_QUEUE_SIZE
            queues_len += ofproto_v1_2.OFP_QUEUE_PROP_MIN_RATE_SIZE

        msg_len = ofproto_v1_2.OFP_QUEUE_GET_CONFIG_REPLY_SIZE \
            + queues_len

        # OFP_HEADER_PACK_STR = '!BBHI'
        fmt = ofproto_v1_2.OFP_HEADER_PACK_STR
        buf = pack(fmt, version, msg_type, msg_len, xid)

        # OFP_QUEUE_GET_CONFIG_REPLY_PACK_STR = '!I4x'
        fmt = ofproto_v1_2.OFP_QUEUE_GET_CONFIG_REPLY_PACK_STR
        buf += pack(fmt, port)

        queues = []
        for q in range(1, queue_cnt + 1):
            # OFP_PACKET_QUEUE_PACK_STR = '!IIH6x'
            fmt = ofproto_v1_2.OFP_PACKET_QUEUE_PACK_STR
            queue_id = q * 100
            queue_port = q
            queue_len = ofproto_v1_2.OFP_PACKET_QUEUE_SIZE \
                + ofproto_v1_2.OFP_QUEUE_PROP_MIN_RATE_SIZE
            buf += pack(fmt, queue_id, queue_port, queue_len)

            # OFP_QUEUE_PROP_HEADER_PACK_STR = '!HH4x'
            fmt = ofproto_v1_2.OFP_QUEUE_PROP_HEADER_PACK_STR
            prop_type = ofproto_v1_2.OFPQT_MIN_RATE
            prop_len = ofproto_v1_2.OFP_QUEUE_PROP_MIN_RATE_SIZE
            buf += pack(fmt, prop_type, prop_len)

            # OFP_QUEUE_PROP_MIN_RATE_PACK_STR = '!H6x'
            fmt = ofproto_v1_2.OFP_QUEUE_PROP_MIN_RATE_PACK_STR
            prop_rate = q * 10
            buf += pack(fmt, prop_rate)

            queue = {'queue_id': queue_id, 'queue_port': queue_port,
                     'queue_len': queue_len, 'prop_type': prop_type,
                     'prop_len': prop_len, 'prop_rate': prop_rate}
            queues.append(queue)

        res = OFPQueueGetConfigReply.parser(object, version, msg_type,
                                            msg_len, xid, buf)
        eq_(version, res.version)
        eq_(msg_type, res.msg_type)
        eq_(msg_len, res.msg_len)
        eq_(xid, res.xid)
        eq_(port, res.port)
        eq_(queue_cnt, len(res.queues))

        for i, val in enumerate(res.queues):
            c = queues[i]
            eq_(c['queue_id'], val.queue_id)
            eq_(c['queue_port'], val.port)
            eq_(c['queue_len'], val.len)
            eq_(1, len(val.properties))

            prop = val.properties[0]
            eq_(c['prop_type'], prop.property)
            eq_(c['prop_len'], prop.len)
            eq_(c['prop_rate'], prop.rate)

    def test_parser_mid(self):
        self._test_parser(2495926989, 65037, 2)

    def test_parser_max(self):
        # total msg_len = 65520
        self._test_parser(0xffffffff, 0xffffffff, 2047)

    def test_parser_min(self):
        self._test_parser(0, 0, 0)


class TestOFPBarrierRequest(unittest.TestCase):
    """ Test case for ofproto_v1_2_parser.OFPBarrierRequest
    """
    def test_serialize(self):
        c = OFPBarrierRequest(_Datapath)
        c.serialize()

        eq_(ofproto_v1_2.OFP_VERSION, c.version)
        eq_(ofproto_v1_2.OFPT_BARRIER_REQUEST, c.msg_type)
        eq_(ofproto_v1_2.OFP_HEADER_SIZE, c.msg_len)
        eq_(0, c.xid)

        fmt = ofproto_v1_2.OFP_HEADER_PACK_STR
        res = unpack(fmt, str(c.buf))
        eq_(ofproto_v1_2.OFP_VERSION, res[0])
        eq_(ofproto_v1_2.OFPT_BARRIER_REQUEST, res[1])
        eq_(len(c.buf), res[2])
        eq_(0, c.xid)


class TestOFPBarrierReply(unittest.TestCase):
    """ Test case for ofproto_v1_2_parser.OFPBarrierReply
    """

    def _test_parser(self, xid):
        version = ofproto_v1_2.OFP_VERSION
        msg_type = ofproto_v1_2.OFPT_BARRIER_REPLY
        msg_len = ofproto_v1_2.OFP_HEADER_SIZE

        fmt = ofproto_v1_2.OFP_HEADER_PACK_STR
        buf = pack(fmt, version, msg_type, msg_len, xid)

        res = OFPBarrierReply.parser(object, version, msg_type,
                                     msg_len, xid, buf)
        eq_(version, res.version)
        eq_(msg_type, res.msg_type)
        eq_(msg_len, res.msg_len)
        eq_(xid, res.xid)

    def test_parser_mid(self):
        self._test_parser(2147483648)

    def test_parser_max(self):
        self._test_parser(0xffffffff)

    def test_parser_min(self):
        self._test_parser(0)


class TestOFPRoleRequest(unittest.TestCase):
    """ Test case for ofproto_v1_2_parser.OFPRoleRequest
    """

    # OFP_ROLE_REQUEST_PACK_STR
    # '!I4xQ'...role, pad(4), generation_id
    role = 2147483648
    generation_id = 1270985291017894273

    def test_init(self):
        c = OFPRoleRequest(_Datapath, self.role, self.generation_id)
        eq_(self.role, c.role)
        eq_(self.generation_id, c.generation_id)

    def _test_serialize(self, role, generation_id):
        c = OFPRoleRequest(_Datapath, role, generation_id)
        c.serialize()

        eq_(ofproto_v1_2.OFP_VERSION, c.version)
        eq_(ofproto_v1_2.OFPT_ROLE_REQUEST, c.msg_type)
        eq_(0, c.xid)

        fmt = '!' \
            + ofproto_v1_2.OFP_HEADER_PACK_STR.replace('!', '') \
            + ofproto_v1_2.OFP_ROLE_REQUEST_PACK_STR.replace('!', '')

        res = struct.unpack(fmt, str(c.buf))

        eq_(ofproto_v1_2.OFP_VERSION, res[0])
        eq_(ofproto_v1_2.OFPT_ROLE_REQUEST, res[1])
        eq_(len(c.buf), res[2])
        eq_(0, res[3])
        eq_(role, res[4])
        eq_(generation_id, res[5])

    def test_serialize_mid(self):
        self._test_serialize(self.role, self.generation_id)

    def test_serialize_max(self):
        role = 0xffffffff
        generation_id = 0xffffffffffffffff
        self._test_serialize(role, generation_id)

    def test_serialize_min(self):
        role = 0
        generation_id = 0
        self._test_serialize(role, generation_id)

    def test_serialize_p1(self):
        role = ofproto_v1_2.OFPCR_ROLE_EQUAL
        self._test_serialize(role, self.generation_id)

    def test_serialize_p2(self):
        role = ofproto_v1_2.OFPCR_ROLE_MASTER
        self._test_serialize(role, self.generation_id)

    def test_serialize_p3(self):
        role = ofproto_v1_2.OFPCR_ROLE_SLAVE
        self._test_serialize(role, self.generation_id)


class TestOFPRoleReply(unittest.TestCase):
    """ Test case for ofproto_v1_2_parser.OFPRoleReply
    """

    # OFP_ROLE_REQUEST_PACK_STR
    # '!I4xQ'...role, pad(4), generation_id
    #role = ofproto_v1_2.OFPCR_ROLE_NOCHANGE
    role = 2147483648
    generation_id = 1270985291017894273

    def _test_parser(self, role, generation_id):
        # OFP_HEADER_PACK_STR
        version = ofproto_v1_2.OFP_VERSION
        msg_type = ofproto_v1_2.OFPT_ROLE_REPLY
        msg_len = ofproto_v1_2.OFP_ROLE_REQUEST_SIZE
        xid = 2495926989

        fmt = ofproto_v1_2.OFP_HEADER_PACK_STR
        buf = pack(fmt, version, msg_type, msg_len, xid)

        fmt = ofproto_v1_2.OFP_ROLE_REQUEST_PACK_STR
        buf += pack(fmt, role, generation_id)

        res = OFPRoleReply.parser(object, version, msg_type, msg_len, xid, buf)

        # OFP_HEADER_PACK_STR
        eq_(version, res.version)
        eq_(msg_type, res.msg_type)
        eq_(msg_len, res.msg_len)
        eq_(xid, res.xid)

        # OFP_ROLE_REQUEST_PACK_STR
        eq_(role, res.role)
        eq_(generation_id, res.generation_id)

    def test_parser_mid(self):
        self._test_parser(self.role, self.generation_id)

    def test_parser_max(self):
        role = 0xffffffff
        generation_id = 0xffffffffffffffff
        self._test_parser(role, generation_id)

    def test_parser_min(self):
        role = ofproto_v1_2.OFPCR_ROLE_NOCHANGE
        generation_id = 0
        self._test_parser(role, generation_id)

    def test_parser_p1(self):
        role = ofproto_v1_2.OFPCR_ROLE_EQUAL
        self._test_parser(role, self.generation_id)

    def test_parser_p2(self):
        role = ofproto_v1_2.OFPCR_ROLE_MASTER
        self._test_parser(role, self.generation_id)

    def test_parser_p3(self):
        role = ofproto_v1_2.OFPCR_ROLE_SLAVE
        self._test_parser(role, self.generation_id)


class TestOFPMatch(unittest.TestCase):
    """ Test case for ofproto_v1_2_parser.OFPMatch
    """

    def test_init(self):
        res = OFPMatch()

        # wc check
        eq_(res._wc.metadata_mask, 0)
        eq_(res._wc.dl_dst_mask, 0)
        eq_(res._wc.dl_src_mask, 0)
        eq_(res._wc.vlan_vid_mask, 0)
        eq_(res._wc.ipv4_src_mask, 0)
        eq_(res._wc.ipv4_dst_mask, 0)
        eq_(res._wc.arp_spa_mask, 0)
        eq_(res._wc.arp_tpa_mask, 0)
        eq_(res._wc.arp_sha_mask, 0)
        eq_(res._wc.arp_tha_mask, 0)
        eq_(res._wc.ipv6_src_mask, [])
        eq_(res._wc.ipv6_dst_mask, [])
        eq_(res._wc.ipv6_flabel_mask, 0)
        eq_(res._wc.wildcards, (1 << 64) - 1)

        # flow check
        eq_(res._flow.in_port, 0)
        eq_(res._flow.in_phy_port, 0)
        eq_(res._flow.metadata, 0)
        eq_(res._flow.dl_dst, mac.DONTCARE)
        eq_(res._flow.dl_src, mac.DONTCARE)
        eq_(res._flow.dl_type, 0)
        eq_(res._flow.vlan_vid, 0)
        eq_(res._flow.vlan_pcp, 0)
        eq_(res._flow.ip_dscp, 0)
        eq_(res._flow.ip_ecn, 0)
        eq_(res._flow.ip_proto, 0)
        eq_(res._flow.ipv4_src, 0)
        eq_(res._flow.ipv4_dst, 0)
        eq_(res._flow.tcp_src, 0)
        eq_(res._flow.tcp_dst, 0)
        eq_(res._flow.udp_src, 0)
        eq_(res._flow.udp_dst, 0)
        eq_(res._flow.sctp_src, 0)
        eq_(res._flow.sctp_dst, 0)
        eq_(res._flow.icmpv4_type, 0)
        eq_(res._flow.icmpv4_code, 0)
        eq_(res._flow.arp_op, 0)
        eq_(res._flow.arp_spa, 0)
        eq_(res._flow.arp_tpa, 0)
        eq_(res._flow.arp_sha, 0)
        eq_(res._flow.arp_tha, 0)
        eq_(res._flow.ipv6_src, [])
        eq_(res._flow.ipv6_dst, [])
        eq_(res._flow.ipv6_flabel, 0)
        eq_(res._flow.icmpv6_type, 0)
        eq_(res._flow.icmpv6_code, 0)
        eq_(res._flow.ipv6_nd_target, [])
        eq_(res._flow.ipv6_nd_sll, 0)
        eq_(res._flow.ipv6_nd_tll, 0)
        eq_(res._flow.mpls_label, 0)
        eq_(res._flow.mpls_tc, 0)

        # flow check
        eq_(res.fields, [])

    def _test_serialize_and_parser(self, match, header, value, mask=None):
        cls_ = OFPMatchField._FIELDS_HEADERS.get(header)
        pack_str = cls_.pack_str.replace('!', '')
        fmt = '!HHI' + pack_str

        # serialize
        buf = bytearray()
        length = match.serialize(buf, 0)
        eq_(length, len(buf))
        if mask and len(buf) > calcsize(fmt):
            fmt += pack_str

        res = list(unpack_from(fmt, str(buf), 0)[3:])
        if type(value) is list:
            res_value = res[:calcsize(pack_str) / 2]
            eq_(res_value, value)
            if mask:
                res_mask = res[calcsize(pack_str) / 2:]
                eq_(res_mask, mask)
        else:
            res_value = res.pop(0)
            if cls_.__name__ == 'MTVlanVid':
                eq_(res_value, value | ofproto_v1_2.OFPVID_PRESENT)
            else:
                eq_(res_value, value)
            if mask and res and res[0]:
                res_mask = res[0]
                eq_(res_mask, mask)

        # parser
        res = match.parser(str(buf), 0)
        eq_(res.type, ofproto_v1_2.OFPMT_OXM)
        eq_(res.fields[0].header, header)
        eq_(res.fields[0].value, value)
        if mask and res.fields[0].mask is not None:
            eq_(res.fields[0].mask, mask)

        # to_jsondict
        jsondict = match.to_jsondict()

        # from_jsondict
        match2 = match.from_jsondict(jsondict["OFPMatch"])
        buf2 = bytearray()
        match2.serialize(buf2, 0)
        eq_(str(match), str(match2))
        eq_(buf, buf2)

    def test_parse_unknown_field(self):
        buf = bytearray()
        ofproto_parser.msg_pack_into('!HH', buf, 0, ofproto_v1_2.OFPMT_OXM,
                                     4 + 6)
        header = ofproto_v1_2.oxm_tlv_header(36, 2)
        ofproto_parser.msg_pack_into('!IH', buf, 4, header, 1)
        header = ofproto_v1_2.OXM_OF_ETH_TYPE
        ofproto_v1_2_parser.msg_pack_into('!IH', buf, 10, header, 1)

        match = OFPMatch()
        res = match.parser(str(buf), 0)

    # set_in_port
    def _test_set_in_port(self, in_port):
        header = ofproto_v1_2.OXM_OF_IN_PORT
        match = OFPMatch()
        match.set_in_port(in_port)
        self._test_serialize_and_parser(match, header, in_port)

    def test_set_in_port_mid(self):
        self._test_set_in_port(0xff8)

    def test_set_in_port_max(self):
        self._test_set_in_port(0xffffffff)

    def test_set_in_port_min(self):
        self._test_set_in_port(0)

    # set_in_phy_port
    def _test_set_in_phy_port(self, phy_port):
        header = ofproto_v1_2.OXM_OF_IN_PHY_PORT
        match = OFPMatch()
        match.set_in_phy_port(phy_port)
        self._test_serialize_and_parser(match, header, phy_port)

    def test_set_in_phy_port_mid(self):
        self._test_set_in_phy_port(1)

    def test_set_in_phy_port_max(self):
        self._test_set_in_phy_port(0xffffffff)

    def test_set_in_phy_port_min(self):
        self._test_set_in_phy_port(0)

    # set_metadata
    def _test_set_metadata(self, metadata, mask=None):
        header = ofproto_v1_2.OXM_OF_METADATA
        match = OFPMatch()
        if mask is None:
            match.set_metadata(metadata)
        else:
            if (mask + 1) >> 64 != 1:
                header = ofproto_v1_2.OXM_OF_METADATA_W
            match.set_metadata_masked(metadata, mask)
            metadata &= mask
        self._test_serialize_and_parser(match, header, metadata, mask)

    def test_set_metadata_mid(self):
        self._test_set_metadata(0x1212121212121212)

    def test_set_metadata_max(self):
        self._test_set_metadata(0xffffffffffffffff)

    def test_set_metadata_min(self):
        self._test_set_metadata(0)

    def test_set_metadata_masked_mid(self):
        self._test_set_metadata(0x1212121212121212, 0xff00ff00ff00ff00)

    def test_set_metadata_masked_max(self):
        self._test_set_metadata(0x1212121212121212, 0xffffffffffffffff)

    def test_set_metadata_masked_min(self):
        self._test_set_metadata(0x1212121212121212, 0)

    # set_dl_dst
    def _test_set_dl_dst(self, dl_dst, mask=None):
        header = ofproto_v1_2.OXM_OF_ETH_DST
        match = OFPMatch()
        dl_dst = mac.haddr_to_bin(dl_dst)
        if mask is None:
            match.set_dl_dst(dl_dst)
        else:
            header = ofproto_v1_2.OXM_OF_ETH_DST_W
            mask = mac.haddr_to_bin(mask)
            match.set_dl_dst_masked(dl_dst, mask)
            dl_dst = mac.haddr_bitand(dl_dst, mask)
        self._test_serialize_and_parser(match, header, dl_dst, mask)

    def test_set_dl_dst_mid(self):
        self._test_set_dl_dst('e2:7a:09:79:0b:0f')

    def test_set_dl_dst_max(self):
        self._test_set_dl_dst('ff:ff:ff:ff:ff:ff')

    def test_set_dl_dst_min(self):
        self._test_set_dl_dst('00:00:00:00:00:00')

    def test_set_dl_dst_masked_mid(self):
        self._test_set_dl_dst('e2:7a:09:79:0b:0f', 'ff:00:ff:00:ff:00')

    def test_set_dl_dst_masked_max(self):
        self._test_set_dl_dst('e2:7a:09:79:0b:0f', 'ff:ff:ff:ff:ff:ff')

    def test_set_dl_dst_masked_min(self):
        self._test_set_dl_dst('e2:7a:09:79:0b:0f', '00:00:00:00:00:00')

    # set_dl_src
    def _test_set_dl_src(self, dl_src, mask=None):
        header = ofproto_v1_2.OXM_OF_ETH_SRC
        match = OFPMatch()
        dl_src = mac.haddr_to_bin(dl_src)
        if mask is None:
            match.set_dl_src(dl_src)
        else:
            header = ofproto_v1_2.OXM_OF_ETH_SRC_W
            mask = mac.haddr_to_bin(mask)
            match.set_dl_src_masked(dl_src, mask)
            dl_src = mac.haddr_bitand(dl_src, mask)
        self._test_serialize_and_parser(match, header, dl_src, mask)

    def test_set_dl_src_mid(self):
        self._test_set_dl_src('d0:98:79:b4:75:b5')

    def test_set_dl_src_max(self):
        self._test_set_dl_src('ff:ff:ff:ff:ff:ff')

    def test_set_dl_src_min(self):
        self._test_set_dl_src('00:00:00:00:00:00')

    def test_set_dl_src_masked_mid(self):
        self._test_set_dl_src('d0:98:79:b4:75:b5', 'f0:f0:f0:f0:f0:f0')

    def test_set_dl_src_masked_max(self):
        self._test_set_dl_src('d0:98:79:b4:75:b5', 'ff:ff:ff:ff:ff:ff')

    def test_set_dl_src_masked_min(self):
        self._test_set_dl_src('d0:98:79:b4:75:b5', '00:00:00:00:00:00')

    # set_dl_type
    def _test_set_dl_type(self, value):
        header = ofproto_v1_2.OXM_OF_ETH_TYPE
        match = OFPMatch()
        match.set_dl_type(value)
        self._test_serialize_and_parser(match, header, value)

    def test_set_dl_type_mid(self):
        self._test_set_dl_type(0x7fb6)

    def test_set_dl_type_max(self):
        self._test_set_dl_type(0xffff)

    def test_set_dl_type_min(self):
        self._test_set_dl_type(0)

    def test_set_dl_type_ip(self):
        value = ether.ETH_TYPE_IP
        self._test_set_dl_type(value)

    def test_set_dl_type_arp(self):
        value = ether.ETH_TYPE_ARP
        self._test_set_dl_type(value)

    def test_set_dl_type_ipv6(self):
        value = ether.ETH_TYPE_IPV6
        self._test_set_dl_type(value)

    def test_set_dl_type_slow(self):
        value = ether.ETH_TYPE_SLOW
        self._test_set_dl_type(value)

    # set_vlan_vid
    def _test_set_vlan_vid(self, vid, mask=None):
        header = ofproto_v1_2.OXM_OF_VLAN_VID
        match = OFPMatch()
        if mask is None:
            match.set_vlan_vid(vid)
        else:
            header = ofproto_v1_2.OXM_OF_VLAN_VID_W
            match.set_vlan_vid_masked(vid, mask)
        self._test_serialize_and_parser(match, header, vid, mask)

    def test_set_vlan_vid_mid(self):
        self._test_set_vlan_vid(2047)

    def test_set_vlan_vid_max(self):
        self._test_set_vlan_vid(0xfff)

    def test_set_vlan_vid_min(self):
        self._test_set_vlan_vid(0)

    def test_set_vlan_vid_masked_mid(self):
        self._test_set_vlan_vid(2047, 0xf0f)

    def test_set_vlan_vid_masked_max(self):
        self._test_set_vlan_vid(2047, 0xfff)

    def test_set_vlan_vid_masked_min(self):
        self._test_set_vlan_vid(2047, 0)

    # set_vlan_pcp
    def _test_set_vlan_pcp(self, pcp):
        header = ofproto_v1_2.OXM_OF_VLAN_PCP
        match = OFPMatch()
        match.set_vlan_pcp(pcp)
        self._test_serialize_and_parser(match, header, pcp)

    def test_set_vlan_pcp_mid(self):
        self._test_set_vlan_pcp(5)

    def test_set_vlan_pcp_max(self):
        self._test_set_vlan_pcp(7)

    def test_set_vlan_pcp_min(self):
        self._test_set_vlan_pcp(0)

    # set_ip_dscp
    def _test_set_ip_dscp(self, ip_dscp):
        header = ofproto_v1_2.OXM_OF_IP_DSCP
        match = OFPMatch()
        match.set_ip_dscp(ip_dscp)
        self._test_serialize_and_parser(match, header, ip_dscp)

    def test_set_ip_dscp_mid(self):
        self._test_set_ip_dscp(36)

    def test_set_ip_dscp_max(self):
        self._test_set_ip_dscp(63)

    def test_set_ip_dscp_min(self):
        self._test_set_ip_dscp(0)

    # set_ip_ecn
    def _test_set_ip_ecn(self, ip_ecn):
        header = ofproto_v1_2.OXM_OF_IP_ECN
        match = OFPMatch()
        match.set_ip_ecn(ip_ecn)
        self._test_serialize_and_parser(match, header, ip_ecn)

    def test_set_ip_ecn_mid(self):
        self._test_set_ip_ecn(1)

    def test_set_ip_ecn_max(self):
        self._test_set_ip_ecn(3)

    def test_set_ip_ecn_min(self):
        self._test_set_ip_ecn(0)

    # set_ip_proto
    def _test_set_ip_proto(self, ip_proto):
        header = ofproto_v1_2.OXM_OF_IP_PROTO
        match = OFPMatch()
        match.set_ip_proto(ip_proto)
        self._test_serialize_and_parser(match, header, ip_proto)

    def test_set_ip_proto_mid(self):
        self._test_set_ip_proto(6)

    def test_set_ip_proto_max(self):
        self._test_set_ip_proto(0xff)

    def test_set_ip_proto_min(self):
        self._test_set_ip_proto(0)

    # set_ipv4_src
    def _test_set_ipv4_src(self, ip, mask=None):
        header = ofproto_v1_2.OXM_OF_IPV4_SRC
        match = OFPMatch()
        ip = unpack('!I', socket.inet_aton(ip))[0]
        if mask is None:
            match.set_ipv4_src(ip)
        else:
            mask = unpack('!I', socket.inet_aton(mask))[0]
            if (mask + 1) >> 32 != 1:
                header = ofproto_v1_2.OXM_OF_IPV4_SRC_W
            match.set_ipv4_src_masked(ip, mask)
        self._test_serialize_and_parser(match, header, ip, mask)

    def test_set_ipv4_src_mid(self):
        self._test_set_ipv4_src('192.168.196.250')

    def test_set_ipv4_src_max(self):
        self._test_set_ipv4_src('255.255.255.255')

    def test_set_ipv4_src_min(self):
        self._test_set_ipv4_src('0.0.0.0')

    def test_set_ipv4_src_masked_mid(self):
        self._test_set_ipv4_src('192.168.196.250', '255.255.0.0')

    def test_set_ipv4_src_masked_max(self):
        self._test_set_ipv4_src('192.168.196.250', '255.255.255.255')

    def test_set_ipv4_src_masked_min(self):
        self._test_set_ipv4_src('192.168.196.250', '0.0.0.0')

    # set_ipv4_dst
    def _test_set_ipv4_dst(self, ip, mask=None):
        header = ofproto_v1_2.OXM_OF_IPV4_DST
        match = OFPMatch()
        ip = unpack('!I', socket.inet_aton(ip))[0]
        if mask is None:
            match.set_ipv4_dst(ip)
        else:
            mask = unpack('!I', socket.inet_aton(mask))[0]
            if (mask + 1) >> 32 != 1:
                header = ofproto_v1_2.OXM_OF_IPV4_DST_W
            match.set_ipv4_dst_masked(ip, mask)
        self._test_serialize_and_parser(match, header, ip, mask)

    def test_set_ipv4_dst_mid(self):
        self._test_set_ipv4_dst('192.168.196.250')

    def test_set_ipv4_dst_max(self):
        self._test_set_ipv4_dst('255.255.255.255')

    def test_set_ipv4_dst_min(self):
        self._test_set_ipv4_dst('0.0.0.0')

    def test_set_ipv4_dst_masked_mid(self):
        self._test_set_ipv4_dst('192.168.196.250', '255.255.0.0')

    def test_set_ipv4_dst_masked_max(self):
        self._test_set_ipv4_dst('192.168.196.250', '255.255.255.255')

    def test_set_ipv4_dst_masked_min(self):
        self._test_set_ipv4_dst('192.168.196.250', '0.0.0.0')

    # set_tcp_src
    def _test_set_tcp_src(self, tcp_src):
        header = ofproto_v1_2.OXM_OF_TCP_SRC
        match = OFPMatch()
        match.set_tcp_src(tcp_src)
        self._test_serialize_and_parser(match, header, tcp_src)

    def test_set_tcp_src_mid(self):
        self._test_set_tcp_src(1103)

    def test_set_tcp_src_max(self):
        self._test_set_tcp_src(0xffff)

    def test_set_tcp_src_min(self):
        self._test_set_tcp_src(0)

    # set_tcp_dst
    def _test_set_tcp_dst(self, tcp_dst):
        header = ofproto_v1_2.OXM_OF_TCP_DST
        match = OFPMatch()
        match.set_tcp_dst(tcp_dst)
        self._test_serialize_and_parser(match, header, tcp_dst)

    def test_set_tcp_dst_mid(self):
        self._test_set_tcp_dst(236)

    def test_set_tcp_dst_max(self):
        self._test_set_tcp_dst(0xffff)

    def test_set_tcp_dst_min(self):
        self._test_set_tcp_dst(0)

    # set_udp_src
    def _test_set_udp_src(self, udp_src):
        header = ofproto_v1_2.OXM_OF_UDP_SRC
        match = OFPMatch()
        match.set_udp_src(udp_src)
        self._test_serialize_and_parser(match, header, udp_src)

    def test_set_udp_src_mid(self):
        self._test_set_udp_src(56617)

    def test_set_udp_src_max(self):
        self._test_set_udp_src(0xffff)

    def test_set_udp_src_min(self):
        self._test_set_udp_src(0)

    # set_udp_dst
    def _test_set_udp_dst(self, udp_dst):
        header = ofproto_v1_2.OXM_OF_UDP_DST
        match = OFPMatch()
        match.set_udp_dst(udp_dst)
        self._test_serialize_and_parser(match, header, udp_dst)

    def test_set_udp_dst_mid(self):
        self._test_set_udp_dst(61278)

    def test_set_udp_dst_max(self):
        self._test_set_udp_dst(0xffff)

    def test_set_udp_dst_min(self):
        self._test_set_udp_dst(0)

    # set_sctp_src
    def _test_set_sctp_src(self, sctp_src):
        header = ofproto_v1_2.OXM_OF_SCTP_SRC
        match = OFPMatch()
        match.set_sctp_src(sctp_src)
        self._test_serialize_and_parser(match, header, sctp_src)

    def test_set_sctp_src_mid(self):
        self._test_set_sctp_src(9999)

    def test_set_sctp_src_max(self):
        self._test_set_sctp_src(0xffff)

    def test_set_sctp_src_min(self):
        self._test_set_sctp_src(0)

    # set_sctp_dst
    def _test_set_sctp_dst(self, sctp_dst):
        header = ofproto_v1_2.OXM_OF_SCTP_DST
        match = OFPMatch()
        match.set_sctp_dst(sctp_dst)
        self._test_serialize_and_parser(match, header, sctp_dst)

    def test_set_sctp_dst_mid(self):
        self._test_set_sctp_dst(1234)

    def test_set_sctp_dst_max(self):
        self._test_set_sctp_dst(0xffff)

    def test_set_sctp_dst_min(self):
        self._test_set_sctp_dst(0)

    # set_icmpv4_type
    def _test_set_icmpv4_type(self, icmpv4_type):
        header = ofproto_v1_2.OXM_OF_ICMPV4_TYPE
        match = OFPMatch()
        match.set_icmpv4_type(icmpv4_type)
        self._test_serialize_and_parser(match, header, icmpv4_type)

    def test_set_icmpv4_type_mid(self):
        self._test_set_icmpv4_type(8)

    def test_set_icmpv4_type_max(self):
        self._test_set_icmpv4_type(0xff)

    def test_set_icmpv4_type_min(self):
        self._test_set_icmpv4_type(0)

    # set_icmpv4_code
    def _test_set_icmpv4_code(self, icmpv4_code):
        header = ofproto_v1_2.OXM_OF_ICMPV4_CODE
        match = OFPMatch()
        match.set_icmpv4_code(icmpv4_code)
        self._test_serialize_and_parser(match, header, icmpv4_code)

    def test_set_icmpv4_code_mid(self):
        self._test_set_icmpv4_code(1)

    def test_set_icmpv4_code_max(self):
        self._test_set_icmpv4_code(0xff)

    def test_set_icmpv4_code_min(self):
        self._test_set_icmpv4_code(0)

    # set_arp_opcode
    def _test_set_arp_opcode(self, arp_op):
        header = ofproto_v1_2.OXM_OF_ARP_OP
        match = OFPMatch()
        match.set_arp_opcode(arp_op)
        self._test_serialize_and_parser(match, header, arp_op)

    def test_set_arp_opcode_mid(self):
        self._test_set_arp_opcode(1)

    def test_set_arp_opcode_max(self):
        self._test_set_arp_opcode(0xffff)

    def test_set_arp_opcode_min(self):
        self._test_set_arp_opcode(0)

    # set_arp_spa
    def _test_set_arp_spa(self, ip, mask=None):
        header = ofproto_v1_2.OXM_OF_ARP_SPA
        match = OFPMatch()
        ip = unpack('!I', socket.inet_aton(ip))[0]
        if mask is None:
            match.set_arp_spa(ip)
        else:
            mask = unpack('!I', socket.inet_aton(mask))[0]
            if (mask + 1) >> 32 != 1:
                header = ofproto_v1_2.OXM_OF_ARP_SPA_W
            match.set_arp_spa_masked(ip, mask)
        self._test_serialize_and_parser(match, header, ip, mask)

    def test_set_arp_spa_mid(self):
        self._test_set_arp_spa('192.168.227.57')

    def test_set_arp_spa_max(self):
        self._test_set_arp_spa('255.255.255.255')

    def test_set_arp_spa_min(self):
        self._test_set_arp_spa('0.0.0.0')

    def test_set_arp_spa_masked_mid(self):
        self._test_set_arp_spa('192.168.227.57', '255.255.0.0')

    def test_set_arp_spa_masked_max(self):
        self._test_set_arp_spa('192.168.227.57', '255.255.255.255')

    def test_set_arp_spa_masked_min(self):
        self._test_set_arp_spa('192.168.227.57', '0.0.0.0')

    # set_arp_tpa
    def _test_set_arp_tpa(self, ip, mask=None):
        header = ofproto_v1_2.OXM_OF_ARP_TPA
        match = OFPMatch()
        ip = unpack('!I', socket.inet_aton(ip))[0]
        if mask is None:
            match.set_arp_tpa(ip)
        else:
            mask = unpack('!I', socket.inet_aton(mask))[0]
            if (mask + 1) >> 32 != 1:
                header = ofproto_v1_2.OXM_OF_ARP_TPA_W
            match.set_arp_tpa_masked(ip, mask)
        self._test_serialize_and_parser(match, header, ip, mask)

    def test_set_arp_tpa_mid(self):
        self._test_set_arp_tpa('192.168.227.57')

    def test_set_arp_tpa_max(self):
        self._test_set_arp_tpa('255.255.255.255')

    def test_set_arp_tpa_min(self):
        self._test_set_arp_tpa('0.0.0.0')

    def test_set_arp_tpa_masked_mid(self):
        self._test_set_arp_tpa('192.168.227.57', '255.255.0.0')

    def test_set_arp_tpa_masked_max(self):
        self._test_set_arp_tpa('192.168.227.57', '255.255.255.255')

    def test_set_arp_tpa_masked_min(self):
        self._test_set_arp_tpa('192.168.227.57', '0.0.0.0')

    # set_arp_sha
    def _test_set_arp_sha(self, arp_sha, mask=None):
        header = ofproto_v1_2.OXM_OF_ARP_SHA
        match = OFPMatch()
        arp_sha = mac.haddr_to_bin(arp_sha)
        if mask is None:
            match.set_arp_sha(arp_sha)
        else:
            header = ofproto_v1_2.OXM_OF_ARP_SHA_W
            mask = mac.haddr_to_bin(mask)
            match.set_arp_sha_masked(arp_sha, mask)
            arp_sha = mac.haddr_bitand(arp_sha, mask)
        self._test_serialize_and_parser(match, header, arp_sha, mask)

    def test_set_arp_sha_mid(self):
        self._test_set_arp_sha('3e:ec:13:9b:f3:0b')

    def test_set_arp_sha_max(self):
        self._test_set_arp_sha('ff:ff:ff:ff:ff:ff')

    def test_set_arp_sha_min(self):
        self._test_set_arp_sha('00:00:00:00:00:00')

    def test_set_arp_sha_masked_mid(self):
        self._test_set_arp_sha('3e:ec:13:9b:f3:0b', 'ff:ff:ff:00:00:00')

    def test_set_arp_sha_masked_max(self):
        self._test_set_arp_sha('3e:ec:13:9b:f3:0b', 'ff:ff:ff:ff:ff:ff')

    def test_set_arp_sha_masked_min(self):
        self._test_set_arp_sha('3e:ec:13:9b:f3:0b', '00:00:00:00:00:00')

    # set_arp_tha
    def _test_set_arp_tha(self, arp_tha, mask=None):
        header = ofproto_v1_2.OXM_OF_ARP_THA
        match = OFPMatch()
        arp_tha = mac.haddr_to_bin(arp_tha)
        if mask is None:
            match.set_arp_tha(arp_tha)
        else:
            header = ofproto_v1_2.OXM_OF_ARP_THA_W
            mask = mac.haddr_to_bin(mask)
            match.set_arp_tha_masked(arp_tha, mask)
            arp_tha = mac.haddr_bitand(arp_tha, mask)
        self._test_serialize_and_parser(match, header, arp_tha, mask)

    def test_set_arp_tha_mid(self):
        self._test_set_arp_tha('83:6c:21:52:49:68')

    def test_set_arp_tha_max(self):
        self._test_set_arp_tha('ff:ff:ff:ff:ff:ff')

    def test_set_arp_tha_min(self):
        self._test_set_arp_tha('00:00:00:00:00:00')

    def test_set_arp_tha_masked_mid(self):
        self._test_set_arp_tha('83:6c:21:52:49:68', 'ff:ff:ff:00:00:00')

    def test_set_arp_tha_masked_max(self):
        self._test_set_arp_tha('83:6c:21:52:49:68', 'ff:ff:ff:ff:ff:ff')

    def test_set_arp_tha_masked_min(self):
        self._test_set_arp_tha('83:6c:21:52:49:68', '00:00:00:00:00:00')

    # set_ipv6_src
    def _test_set_ipv6_src(self, ipv6, mask=None):
        header = ofproto_v1_2.OXM_OF_IPV6_SRC
        match = OFPMatch()
        ipv6 = [int(x, 16) for x in ipv6.split(":")]
        if mask is None:
            match.set_ipv6_src(ipv6)
        else:
            header = ofproto_v1_2.OXM_OF_IPV6_SRC_W
            mask = [int(x, 16) for x in mask.split(":")]
            match.set_ipv6_src_masked(ipv6, mask)
            ipv6 = [x & y for (x, y) in itertools.izip(ipv6, mask)]
        self._test_serialize_and_parser(match, header, ipv6, mask)

    def test_set_ipv6_src_mid(self):
        ipv6 = '2001:db8:bd05:1d2:288a:1fc0:1:10ee'
        self._test_set_ipv6_src(ipv6)

    def test_set_ipv6_src_max(self):
        ipv6 = 'ffff:ffff:ffff:ffff:ffff:ffff:ffff:ffff'
        self._test_set_ipv6_src(ipv6)

    def test_set_ipv6_src_min(self):
        ipv6 = '0:0:0:0:0:0:0:0'
        self._test_set_ipv6_src(ipv6)

    def test_set_ipv6_src_masked_mid(self):
        ipv6 = '2001:db8:bd05:1d2:288a:1fc0:1:10ee'
        mask = 'ffff:ffff:ffff:ffff:0:0:0:0'
        self._test_set_ipv6_src(ipv6, mask)

    def test_set_ipv6_src_masked_max(self):
        ipv6 = '2001:db8:bd05:1d2:288a:1fc0:1:10ee'
        mask = 'ffff:ffff:ffff:ffff:ffff:ffff:ffff:ffff'
        self._test_set_ipv6_src(ipv6, mask)

    def test_set_ipv6_src_masked_min(self):
        ipv6 = '2001:db8:bd05:1d2:288a:1fc0:1:10ee'
        mask = '0:0:0:0:0:0:0:0'
        self._test_set_ipv6_src(ipv6, mask)

    # set_ipv6_dst
    def _test_set_ipv6_dst(self, ipv6, mask=None):
        header = ofproto_v1_2.OXM_OF_IPV6_DST
        match = OFPMatch()
        ipv6 = [int(x, 16) for x in ipv6.split(":")]
        if mask is None:
            match.set_ipv6_dst(ipv6)
        else:
            header = ofproto_v1_2.OXM_OF_IPV6_DST_W
            mask = [int(x, 16) for x in mask.split(":")]
            match.set_ipv6_dst_masked(ipv6, mask)
            ipv6 = [x & y for (x, y) in itertools.izip(ipv6, mask)]
        self._test_serialize_and_parser(match, header, ipv6, mask)

    def test_set_ipv6_dst_mid(self):
        ipv6 = 'e9e8:9ea5:7d67:82cc:ca54:1fc0:2d24:f038'
        self._test_set_ipv6_dst(ipv6)

    def test_set_ipv6_dst_max(self):
        ipv6 = ':'.join(['ffff'] * 8)
        self._test_set_ipv6_dst(ipv6)

    def test_set_ipv6_dst_min(self):
        ipv6 = ':'.join(['0'] * 8)
        self._test_set_ipv6_dst(ipv6)

    def test_set_ipv6_dst_mask_mid(self):
        ipv6 = 'e9e8:9ea5:7d67:82cc:ca54:1fc0:2d24:f038'
        mask = ':'.join(['ffff'] * 4 + ['0'] * 4)
        self._test_set_ipv6_dst(ipv6, mask)

    def test_set_ipv6_dst_mask_max(self):
        ipv6 = 'e9e8:9ea5:7d67:82cc:ca54:1fc0:2d24:f038'
        mask = ':'.join(['ffff'] * 8)
        self._test_set_ipv6_dst(ipv6, mask)

    def test_set_ipv6_dst_mask_min(self):
        ipv6 = 'e9e8:9ea5:7d67:82cc:ca54:1fc0:2d24:f038'
        mask = ':'.join(['0'] * 8)
        self._test_set_ipv6_dst(ipv6, mask)

    # set_ipv6_flabel
    def _test_set_ipv6_flabel(self, flabel, mask=None):
        header = ofproto_v1_2.OXM_OF_IPV6_FLABEL
        match = OFPMatch()
        if mask is None:
            match.set_ipv6_flabel(flabel)
        else:
            header = ofproto_v1_2.OXM_OF_IPV6_FLABEL_W
            match.set_ipv6_flabel_masked(flabel, mask)
        self._test_serialize_and_parser(match, header, flabel, mask)

    def test_set_ipv6_flabel_mid(self):
        self._test_set_ipv6_flabel(0xc5384)

    def test_set_ipv6_flabel_max(self):
        self._test_set_ipv6_flabel(0xfffff)

    def test_set_ipv6_flabel_min(self):
        self._test_set_ipv6_flabel(0)

    def test_set_ipv6_flabel_masked_mid(self):
        self._test_set_ipv6_flabel(0xc5384, 0xfff00)

    def test_set_ipv6_flabel_masked_max(self):
        self._test_set_ipv6_flabel(0xc5384, 0xfffff)

    def test_set_ipv6_flabel_masked_min(self):
        self._test_set_ipv6_flabel(0xc5384, 0)

    # set_icmpv6_type
    def _test_set_icmpv6_type(self, icmpv6_type):
        header = ofproto_v1_2.OXM_OF_ICMPV6_TYPE
        match = OFPMatch()
        match.set_icmpv6_type(icmpv6_type)
        self._test_serialize_and_parser(match, header, icmpv6_type)

    def test_set_icmpv6_type_mid(self):
        self._test_set_icmpv6_type(129)

    def test_set_icmpv6_type_max(self):
        self._test_set_icmpv6_type(0xff)

    def test_set_icmpv6_type_min(self):
        self._test_set_icmpv6_type(0)

    # set_icmpv6_code
    def _test_set_icmpv6_code(self, icmpv6_code):
        header = ofproto_v1_2.OXM_OF_ICMPV6_CODE
        match = OFPMatch()
        match.set_icmpv6_code(icmpv6_code)
        self._test_serialize_and_parser(match, header, icmpv6_code)

    def test_set_icmpv6_code_mid(self):
        self._test_set_icmpv6_code(1)

    def test_set_icmpv6_code_max(self):
        self._test_set_icmpv6_code(0xff)

    def test_set_icmpv6_code_min(self):
        self._test_set_icmpv6_code(0)

    # set_ipv6_nd_target
    def _test_set_ipv6_nd_target(self, ipv6):
        header = ofproto_v1_2.OXM_OF_IPV6_ND_TARGET
        match = OFPMatch()
        ipv6 = [int(x, 16) for x in ipv6.split(":")]
        match.set_ipv6_nd_target(ipv6)
        self._test_serialize_and_parser(match, header, ipv6)

    def test_set_ipv6_nd_target_mid(self):
        ip = '5420:db3f:921b:3e33:2791:98f:dd7f:2e19'
        self._test_set_ipv6_nd_target(ip)

    def test_set_ipv6_nd_target_max(self):
        ip = ':'.join(['ffff'] * 8)
        self._test_set_ipv6_nd_target(ip)

    def test_set_ipv6_nd_target_min(self):
        ip = ':'.join(['0'] * 8)
        self._test_set_ipv6_nd_target(ip)

    # set_ipv6_nd_sll
    def _test_set_ipv6_nd_sll(self, nd_sll):
        header = ofproto_v1_2.OXM_OF_IPV6_ND_SLL
        match = OFPMatch()
        nd_sll = mac.haddr_to_bin(nd_sll)
        match.set_ipv6_nd_sll(nd_sll)
        self._test_serialize_and_parser(match, header, nd_sll)

    def test_set_ipv6_nd_sll_mid(self):
        self._test_set_ipv6_nd_sll('93:6d:d0:d4:e8:36')

    def test_set_ipv6_nd_sll_max(self):
        self._test_set_ipv6_nd_sll('ff:ff:ff:ff:ff:ff')

    def test_set_ipv6_nd_sll_min(self):
        self._test_set_ipv6_nd_sll('00:00:00:00:00:00')

    # set_ipv6_nd_tll
    def _test_set_ipv6_nd_tll(self, nd_tll):
        header = ofproto_v1_2.OXM_OF_IPV6_ND_TLL
        match = OFPMatch()
        nd_tll = mac.haddr_to_bin(nd_tll)
        match.set_ipv6_nd_tll(nd_tll)
        self._test_serialize_and_parser(match, header, nd_tll)

    def test_set_ipv6_nd_tll_mid(self):
        self._test_set_ipv6_nd_tll('18:f6:66:b6:f1:b3')

    def test_set_ipv6_nd_tll_max(self):
        self._test_set_ipv6_nd_tll('ff:ff:ff:ff:ff:ff')

    def test_set_ipv6_nd_tll_min(self):
        self._test_set_ipv6_nd_tll('00:00:00:00:00:00')

    # set_mpls_label
    def _test_set_mpls_label(self, mpls_label):
        header = ofproto_v1_2.OXM_OF_MPLS_LABEL
        match = OFPMatch()
        match.set_mpls_label(mpls_label)
        self._test_serialize_and_parser(match, header, mpls_label)

    def test_set_mpls_label_mid(self):
        self._test_set_mpls_label(2144)

    def test_set_mpls_label_max(self):
        self._test_set_mpls_label(0xfffff)

    def test_set_mpls_label_min(self):
        self._test_set_mpls_label(0)

    # set_mpls_tc
    def _test_set_mpls_tc(self, mpls_tc):
        header = ofproto_v1_2.OXM_OF_MPLS_TC
        match = OFPMatch()
        match.set_mpls_tc(mpls_tc)
        self._test_serialize_and_parser(match, header, mpls_tc)

    def test_set_mpls_tc_mid(self):
        self._test_set_mpls_tc(3)

    def test_set_mpls_tc_max(self):
        self._test_set_mpls_tc(7)

    def test_set_mpls_tc_min(self):
        self._test_set_mpls_tc(0)


class TestOFPMatchField(unittest.TestCase):
    """ Test case for ofproto_v1_2_parser.OFPMatchField
    """

    def test_init_hasmask_true(self):
        header = 0x0100

        res = OFPMatchField(header)

        eq_(res.header, header)
        eq_(res.n_bytes, (header & 0xff) / 2)
        eq_(res.length, 0)

    def test_init_hasmask_false(self):
        header = 0x0000

        res = OFPMatchField(header)

        eq_(res.header, header)
        eq_(res.n_bytes, header & 0xff)
        eq_(res.length, 0)

########NEW FILE########
__FILENAME__ = test_arp
# Copyright (C) 2012 Nippon Telegraph and Telephone Corporation.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# vim: tabstop=4 shiftwidth=4 softtabstop=4

import unittest
import logging
import struct
from struct import *
from nose.tools import *
from nose.plugins.skip import Skip, SkipTest
from ryu.ofproto import ether
from ryu.lib.packet.ethernet import ethernet
from ryu.lib.packet.packet import Packet
from ryu.lib.packet.arp import arp
from ryu.lib.packet.vlan import vlan
from ryu.lib import addrconv


LOG = logging.getLogger('test_arp')


class Test_arp(unittest.TestCase):
    """ Test case for arp
    """

    hwtype = 1
    proto = 0x0800
    hlen = 6
    plen = 4
    opcode = 1
    src_mac = '00:07:0d:af:f4:54'
    src_ip = '24.166.172.1'
    dst_mac = '00:00:00:00:00:00'
    dst_ip = '24.166.173.159'

    fmt = arp._PACK_STR
    buf = pack(fmt, hwtype, proto, hlen, plen, opcode,
               addrconv.mac.text_to_bin(src_mac),
               addrconv.ipv4.text_to_bin(src_ip),
               addrconv.mac.text_to_bin(dst_mac),
               addrconv.ipv4.text_to_bin(dst_ip))

    a = arp(hwtype, proto, hlen, plen, opcode, src_mac, src_ip, dst_mac,
            dst_ip)

    def setUp(self):
        pass

    def tearDown(self):
        pass

    def find_protocol(self, pkt, name):
        for p in pkt.protocols:
            if p.protocol_name == name:
                return p

    def test_init(self):
        eq_(self.hwtype, self.a.hwtype)
        eq_(self.proto, self.a.proto)
        eq_(self.hlen, self.a.hlen)
        eq_(self.plen, self.a.plen)
        eq_(self.opcode, self.a.opcode)
        eq_(self.src_mac, self.a.src_mac)
        eq_(self.src_ip, self.a.src_ip)
        eq_(self.dst_mac, self.a.dst_mac)
        eq_(self.dst_ip, self.a.dst_ip)

    def test_parser(self):
        _res = self.a.parser(self.buf)
        if type(_res) is tuple:
            res = _res[0]
        else:
            res = _res

        eq_(res.hwtype, self.hwtype)
        eq_(res.proto, self.proto)
        eq_(res.hlen, self.hlen)
        eq_(res.plen, self.plen)
        eq_(res.opcode, self.opcode)
        eq_(res.src_mac, self.src_mac)
        eq_(res.src_ip, self.src_ip)
        eq_(res.dst_mac, self.dst_mac)
        eq_(res.dst_ip, self.dst_ip)

    def test_serialize(self):
        data = bytearray()
        prev = None
        buf = self.a.serialize(data, prev)

        fmt = arp._PACK_STR
        res = struct.unpack(fmt, buf)

        eq_(res[0], self.hwtype)
        eq_(res[1], self.proto)
        eq_(res[2], self.hlen)
        eq_(res[3], self.plen)
        eq_(res[4], self.opcode)
        eq_(res[5], addrconv.mac.text_to_bin(self.src_mac))
        eq_(res[6], addrconv.ipv4.text_to_bin(self.src_ip))
        eq_(res[7], addrconv.mac.text_to_bin(self.dst_mac))
        eq_(res[8], addrconv.ipv4.text_to_bin(self.dst_ip))

    def _build_arp(self, vlan_enabled):
        if vlan_enabled is True:
            ethertype = ether.ETH_TYPE_8021Q
            v = vlan(1, 1, 3, ether.ETH_TYPE_ARP)
        else:
            ethertype = ether.ETH_TYPE_ARP
        e = ethernet(self.dst_mac, self.src_mac, ethertype)
        p = Packet()

        p.add_protocol(e)
        if vlan_enabled is True:
            p.add_protocol(v)
        p.add_protocol(self.a)
        p.serialize()
        return p

    def test_build_arp_vlan(self):
        p = self._build_arp(True)

        e = self.find_protocol(p, "ethernet")
        ok_(e)
        eq_(e.ethertype, ether.ETH_TYPE_8021Q)

        v = self.find_protocol(p, "vlan")
        ok_(v)
        eq_(v.ethertype, ether.ETH_TYPE_ARP)

        a = self.find_protocol(p, "arp")
        ok_(a)

        eq_(a.hwtype, self.hwtype)
        eq_(a.proto, self.proto)
        eq_(a.hlen, self.hlen)
        eq_(a.plen, self.plen)
        eq_(a.opcode, self.opcode)
        eq_(a.src_mac, self.src_mac)
        eq_(a.src_ip, self.src_ip)
        eq_(a.dst_mac, self.dst_mac)
        eq_(a.dst_ip, self.dst_ip)

    def test_build_arp_novlan(self):
        p = self._build_arp(False)

        e = self.find_protocol(p, "ethernet")
        ok_(e)
        eq_(e.ethertype, ether.ETH_TYPE_ARP)

        a = self.find_protocol(p, "arp")
        ok_(a)

        eq_(a.hwtype, self.hwtype)
        eq_(a.proto, self.proto)
        eq_(a.hlen, self.hlen)
        eq_(a.plen, self.plen)
        eq_(a.opcode, self.opcode)
        eq_(a.src_mac, self.src_mac)
        eq_(a.src_ip, self.src_ip)
        eq_(a.dst_mac, self.dst_mac)
        eq_(a.dst_ip, self.dst_ip)

    @raises(Exception)
    def test_malformed_arp(self):
        m_short_buf = self.buf[1:arp._MIN_LEN]
        arp.parser(m_short_buf)

########NEW FILE########
__FILENAME__ = test_bgp
# Copyright (C) 2013 Nippon Telegraph and Telephone Corporation.
# Copyright (C) 2013 YAMAMOTO Takashi <yamamoto at valinux co jp>
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import unittest
from nose.tools import eq_
from nose.tools import ok_

from ryu.lib.packet import bgp
from ryu.lib.packet import afi
from ryu.lib.packet import safi


class Test_bgp(unittest.TestCase):
    """ Test case for ryu.lib.packet.bgp
    """

    def setUp(self):
        pass

    def tearDown(self):
        pass

    def test_open1(self):
        msg = bgp.BGPOpen(my_as=30000, bgp_identifier='192.0.2.1')
        binmsg = msg.serialize()
        msg2, rest = bgp.BGPMessage.parser(binmsg)
        eq_(str(msg), str(msg2))
        eq_(len(msg), 29)
        eq_(rest, '')

    def test_open2(self):
        opt_param = [bgp.BGPOptParamCapabilityUnknown(cap_code=200,
                                                      cap_value='hoge'),
                     bgp.BGPOptParamCapabilityRouteRefresh(),
                     bgp.BGPOptParamCapabilityMultiprotocol(
                         afi=afi.IP, safi=safi.MPLS_VPN),
                     bgp.BGPOptParamCapabilityFourOctetAsNumber(
                         as_number=1234567),
                     bgp.BGPOptParamUnknown(type_=99, value='fuga')]
        msg = bgp.BGPOpen(my_as=30000, bgp_identifier='192.0.2.2',
                          opt_param=opt_param)
        binmsg = msg.serialize()
        msg2, rest = bgp.BGPMessage.parser(binmsg)
        eq_(str(msg), str(msg2))
        ok_(len(msg) > 29)
        eq_(rest, '')

    def test_update1(self):
        msg = bgp.BGPUpdate()
        binmsg = msg.serialize()
        msg2, rest = bgp.BGPMessage.parser(binmsg)
        eq_(str(msg), str(msg2))
        eq_(len(msg), 23)
        eq_(rest, '')

    def test_update2(self):
        withdrawn_routes = [bgp.BGPWithdrawnRoute(length=0,
                                                  addr='192.0.2.13'),
                            bgp.BGPWithdrawnRoute(length=1,
                                                  addr='192.0.2.13'),
                            bgp.BGPWithdrawnRoute(length=3,
                                                  addr='192.0.2.13'),
                            bgp.BGPWithdrawnRoute(length=7,
                                                  addr='192.0.2.13'),
                            bgp.BGPWithdrawnRoute(length=32,
                                                  addr='192.0.2.13')]
        mp_nlri = [
            bgp._BinAddrPrefix(32, 'efgh\0\0'),
            bgp._BinAddrPrefix(16, 'ij\0\0\0\0'),
        ]
        communities = [
            bgp.BGP_COMMUNITY_NO_EXPORT,
            bgp.BGP_COMMUNITY_NO_ADVERTISE,
        ]
        ecommunities = [
            bgp.BGPTwoOctetAsSpecificExtendedCommunity(subtype=1,
                                                       as_number=65500,
                                                       local_administrator=
                                                       3908876543),
            bgp.BGPFourOctetAsSpecificExtendedCommunity(subtype=2,
                                                        as_number=10000000,
                                                        local_administrator=
                                                        59876),
            bgp.BGPIPv4AddressSpecificExtendedCommunity(subtype=3,
                                                        ipv4_address=
                                                        '192.0.2.1',
                                                        local_administrator=
                                                        65432),
            bgp.BGPOpaqueExtendedCommunity(opaque='abcdefg'),
            bgp.BGPUnknownExtendedCommunity(type_=99, value='abcdefg'),
        ]
        path_attributes = [
            bgp.BGPPathAttributeOrigin(value=1),
            bgp.BGPPathAttributeAsPath(value=[[1000], set([1001, 1002]),
                                              [1003, 1004]]),
            bgp.BGPPathAttributeNextHop(value='192.0.2.199'),
            bgp.BGPPathAttributeMultiExitDisc(value=2000000000),
            bgp.BGPPathAttributeLocalPref(value=1000000000),
            bgp.BGPPathAttributeAtomicAggregate(),
            bgp.BGPPathAttributeAggregator(as_number=40000,
                                           addr='192.0.2.99'),
            bgp.BGPPathAttributeCommunities(communities=communities),
            bgp.BGPPathAttributeExtendedCommunities(communities=ecommunities),
            bgp.BGPPathAttributeAs4Path(value=[[1000000], set([1000001, 1002]),
                                               [1003, 1000004]]),
            bgp.BGPPathAttributeAs4Aggregator(as_number=100040000,
                                              addr='192.0.2.99'),
            bgp.BGPPathAttributeMpReachNLRI(afi=afi.IP, safi=safi.MPLS_VPN,
                                            next_hop='abcd',
                                            nlri=mp_nlri),
            bgp.BGPPathAttributeMpUnreachNLRI(afi=afi.IP, safi=safi.MPLS_VPN,
                                              withdrawn_routes=mp_nlri),
            bgp.BGPPathAttributeUnknown(flags=0, type_=100, value=300*'bar')
        ]
        nlri = [
            bgp.BGPNLRI(length=24, addr='203.0.113.1'),
            bgp.BGPNLRI(length=16, addr='203.0.113.0')
        ]
        msg = bgp.BGPUpdate(withdrawn_routes=withdrawn_routes,
                            path_attributes=path_attributes,
                            nlri=nlri)
        binmsg = msg.serialize()
        msg2, rest = bgp.BGPMessage.parser(binmsg)
        eq_(str(msg), str(msg2))
        ok_(len(msg) > 23)
        eq_(rest, '')

    def test_keepalive(self):
        msg = bgp.BGPKeepAlive()
        binmsg = msg.serialize()
        msg2, rest = bgp.BGPMessage.parser(binmsg)
        eq_(str(msg), str(msg2))
        eq_(len(msg), 19)
        eq_(rest, '')

    def test_notification(self):
        data = "hoge"
        msg = bgp.BGPNotification(error_code=1, error_subcode=2, data=data)
        binmsg = msg.serialize()
        msg2, rest = bgp.BGPMessage.parser(binmsg)
        eq_(str(msg), str(msg2))
        eq_(len(msg), 21 + len(data))
        eq_(rest, '')

    def test_route_refresh(self):
        msg = bgp.BGPRouteRefresh(afi=afi.IP, safi=safi.MPLS_VPN)
        binmsg = msg.serialize()
        msg2, rest = bgp.BGPMessage.parser(binmsg)
        eq_(str(msg), str(msg2))
        eq_(len(msg), 23)
        eq_(rest, '')

    def test_stream_parser(self):
        msgs = [
            bgp.BGPNotification(error_code=1, error_subcode=2, data="foo"),
            bgp.BGPNotification(error_code=3, error_subcode=4, data="bar"),
            bgp.BGPNotification(error_code=5, error_subcode=6, data="baz"),
        ]
        binmsgs = ''.join([bytes(msg.serialize()) for msg in msgs])
        sp = bgp.StreamParser()
        results = []
        for b in binmsgs:
            for m in sp.parse(b):
                results.append(m)
        eq_(str(results), str(msgs))

    def test_parser(self):
        files = [
            'bgp4-open',
            # commented out because
            # 1. we don't support 32 bit AS numbers in AS_PATH
            # 2. quagga always uses EXTENDED for AS_PATH
            # 'bgp4-update',
            'bgp4-keepalive',
        ]
        dir = '../packet_data/bgp4/'

        for f in files:
            print 'testing', f
            binmsg = open(dir + f).read()
            msg, rest = bgp.BGPMessage.parser(binmsg)
            binmsg2 = msg.serialize()
            eq_(binmsg, binmsg2)
            eq_(rest, '')

########NEW FILE########
__FILENAME__ = test_dhcp
# Copyright (C) 2013 Nippon Telegraph and Telephone Corporation.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.


import inspect
import logging
import struct
import unittest
from nose.tools import eq_
from ryu.lib import addrconv
from ryu.lib.packet import dhcp


LOG = logging.getLogger(__name__)


class Test_dhcp_offer(unittest.TestCase):

    op = dhcp.DHCP_BOOT_REPLY
    chaddr = 'aa:aa:aa:aa:aa:aa'
    htype = 1
    hlen = 6
    hops = 0
    xid = 1
    secs = 0
    flags = 1
    ciaddr = '192.168.10.10'
    yiaddr = '192.168.20.20'
    siaddr = '192.168.30.30'
    giaddr = '192.168.40.40'
    sname = 'abc'
    boot_file = ''

    option_list = [
        dhcp.option(dhcp.DHCP_MESSAGE_TYPE_OPT, '\x02', 1),
        dhcp.option(dhcp.DHCP_SUBNET_MASK_OPT, '\xff\xff\xff\x00', 4),
        dhcp.option(dhcp.DHCP_GATEWAY_ADDR_OPT, '\xc0\xa8\x0a\x09', 4),
        dhcp.option(dhcp.DHCP_DNS_SERVER_ADDR_OPT, '\xc0\xa8\x0a\x09', 4),
        dhcp.option(dhcp.DHCP_IP_ADDR_LEASE_TIME_OPT, '\x00\x03\xf4\x80', 4),
        dhcp.option(dhcp.DHCP_RENEWAL_TIME_OPT, '\x00\x01\xfa\x40', 4),
        dhcp.option(dhcp.DHCP_REBINDING_TIME_OPT, '\x00\x03\x75\xf0', 4),
        dhcp.option(dhcp.DHCP_SERVER_IDENTIFIER_OPT, '\xc0\xa8\x0a\x09', 4)]
    magic_cookie = '99.130.83.99'
    options = dhcp.options(option_list=option_list, options_len=50,
                           magic_cookie=magic_cookie)

    dh = dhcp.dhcp(op, chaddr, options, htype=htype, hlen=hlen,
                   hops=hops, xid=xid, secs=secs, flags=flags,
                   ciaddr=ciaddr, yiaddr=yiaddr, siaddr=siaddr,
                   giaddr=giaddr, sname=sname, boot_file=boot_file)

    buf = "\x02\x01\x06\x00\x00\x00\x00\x01\x00\x00\x00\x01\xc0\xa8\x0a\x0a"\
        + "\xc0\xa8\x14\x14\xc0\xa8\x1e\x1e\xc0\xa8\x28\x28\xaa\xaa\xaa\xaa"\
        + "\xaa\xaa\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x61\x62\x63\x00"\
        + "\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00"\
        + "\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00"\
        + "\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00"\
        + "\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00"\
        + "\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00"\
        + "\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00"\
        + "\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00"\
        + "\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00"\
        + "\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00"\
        + "\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00"\
        + "\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00"\
        + "\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x63\x82\x53\x63"\
        + "\x35\x01\x02\x01\x04\xff\xff\xff\x00\x03\x04\xc0\xa8\x0a\x09\x06"\
        + "\x04\xc0\xa8\x0a\x09\x33\x04\x00\x03\xf4\x80\x3a\x04\x00\x01\xfa"\
        + "\x40\x3b\x04\x00\x03\x75\xf0\x36\x04\xc0\xa8\x0a\x09\xff"

    def setUp(self):
        pass

    def tearDown(self):
        pass

    def test_init(self):
        eq_(self.op, self.dh.op)
        eq_(self.htype, self.dh.htype)
        eq_(self.hlen, self.dh.hlen)
        eq_(self.hops, self.dh.hops)
        eq_(self.xid, self.dh.xid)
        eq_(self.secs, self.dh.secs)
        eq_(self.flags, self.dh.flags)
        eq_(self.ciaddr, self.dh.ciaddr)
        eq_(self.yiaddr, self.dh.yiaddr)
        eq_(self.siaddr, self.dh.siaddr)
        eq_(self.giaddr, self.dh.giaddr)
        eq_(self.chaddr, self.dh.chaddr)
        eq_(self.sname, self.dh.sname)
        eq_(self.boot_file, self.dh.boot_file)
        eq_(str(self.options), str(self.dh.options))

    def test_parser(self):
        _res = self.dh.parser(str(self.buf))
        if type(_res) is tuple:
            res = _res[0]
        else:
            res = _res

        eq_(self.op, res.op)
        eq_(self.htype, res.htype)
        eq_(self.hlen, res.hlen)
        eq_(self.hops, res.hops)
        eq_(self.xid, res.xid)
        eq_(self.secs, res.secs)
        eq_(self.flags, res.flags)
        eq_(self.ciaddr, res.ciaddr)
        eq_(self.yiaddr, res.yiaddr)
        eq_(self.siaddr, res.siaddr)
        eq_(self.giaddr, res.giaddr)
        eq_(self.chaddr, res.chaddr)
        # sname is 64 byte length. rest of data is filled by '\x00'.
        eq_(self.sname.ljust(64, '\x00'), res.sname)
        # boof_file is 128 byte length. rest of data is filled by '\x00'.
        eq_(self.boot_file.ljust(128, '\x00'), res.boot_file)
        eq_(str(self.options), str(res.options))

    def test_serialize(self):
        data = bytearray()
        prev = None
        buf = self.dh.serialize(data, prev)

        res = struct.unpack_from(dhcp.dhcp._DHCP_PACK_STR, str(buf))

        eq_(self.op, res[0])
        eq_(self.htype, res[1])
        eq_(self.hlen, res[2])
        eq_(self.hops, res[3])
        eq_(self.xid, res[4])
        eq_(self.secs, res[5])
        eq_(self.flags, res[6])
        eq_(self.ciaddr, addrconv.ipv4.bin_to_text(res[7]))
        eq_(self.yiaddr, addrconv.ipv4.bin_to_text(res[8]))
        eq_(self.siaddr, addrconv.ipv4.bin_to_text(res[9]))
        eq_(self.giaddr, addrconv.ipv4.bin_to_text(res[10]))
        eq_(self.chaddr, addrconv.mac.bin_to_text(res[11][:6]))
        # sname is 64 byte length. rest of data is filled by '\x00'.
        eq_(self.sname.ljust(64, '\x00'), res[12])
        # boof_file is 128 byte length. rest of data is filled by '\x00'.
        eq_(self.boot_file.ljust(128, '\x00'), res[13])
        options = dhcp.options.parser(
            buf[struct.calcsize(dhcp.dhcp._DHCP_PACK_STR):])
        eq_(str(self.options), str(options))

    def test_to_string(self):
        option_values = ['tag', 'length', 'value']
        opt_str_list = []
        for option in self.option_list:
            _opt_str = ','.join(['%s=%s' % (k, repr(getattr(option, k)))
                                 for k, v in inspect.getmembers(option)
                                 if k in option_values])
            opt_str = '%s(%s)' % (dhcp.option.__name__, _opt_str)
            opt_str_list.append(opt_str)
        option_str = '[%s]' % ', '.join(opt_str_list)

        opts_vals = {'magic_cookie': repr(self.magic_cookie),
                     'option_list': option_str,
                     'options_len': repr(self.options.options_len)}
        _options_str = ','.join(['%s=%s' % (k, opts_vals[k])
                                 for k, v in inspect.getmembers(self.options)
                                 if k in opts_vals])
        options_str = '%s(%s)' % (dhcp.options.__name__, _options_str)

        dhcp_values = {'op': repr(self.op),
                       'htype': repr(self.htype),
                       'hlen': repr(self.hlen),
                       'hops': repr(self.hops),
                       'xid': repr(self.xid),
                       'secs': repr(self.secs),
                       'flags': repr(self.flags),
                       'ciaddr': repr(self.ciaddr),
                       'yiaddr': repr(self.yiaddr),
                       'siaddr': repr(self.siaddr),
                       'giaddr': repr(self.giaddr),
                       'chaddr': repr(self.chaddr),
                       'sname': repr(self.sname),
                       'boot_file': repr(self.boot_file),
                       'options': options_str}
        _dh_str = ','.join(['%s=%s' % (k, dhcp_values[k])
                            for k, v in inspect.getmembers(self.dh)
                            if k in dhcp_values])
        dh_str = '%s(%s)' % (dhcp.dhcp.__name__, _dh_str)

        eq_(str(self.dh), dh_str)
        eq_(repr(self.dh), dh_str)

########NEW FILE########
__FILENAME__ = test_ethernet
# Copyright (C) 2012 Nippon Telegraph and Telephone Corporation.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# vim: tabstop=4 shiftwidth=4 softtabstop=4

import unittest
import logging
import struct
import netaddr
from struct import *
from nose.tools import *
from nose.plugins.skip import Skip, SkipTest
from ryu.ofproto import ether, inet
from ryu.lib.packet.ethernet import ethernet
from ryu.lib.packet.packet import Packet
from ryu.lib.packet.arp import arp
from ryu.lib import addrconv


LOG = logging.getLogger('test_ethernet')


class Test_ethernet(unittest.TestCase):
    """ Test case for ethernet
    """

    dst = 'aa:aa:aa:aa:aa:aa'
    src = 'bb:bb:bb:bb:bb:bb'
    ethertype = ether.ETH_TYPE_ARP

    buf = pack(ethernet._PACK_STR,
               addrconv.mac.text_to_bin(dst),
               addrconv.mac.text_to_bin(src), ethertype)

    e = ethernet(dst, src, ethertype)

    def setUp(self):
        pass

    def tearDown(self):
        pass

    def find_protocol(self, pkt, name):
        for p in pkt.protocols:
            if p.protocol_name == name:
                return p

    def test_init(self):
        eq_(self.dst, self.e.dst)
        eq_(self.src, self.e.src)
        eq_(self.ethertype, self.e.ethertype)

    def test_parser(self):
        res, ptype, _ = self.e.parser(self.buf)
        LOG.debug((res, ptype))

        eq_(res.dst, self.dst)
        eq_(res.src, self.src)
        eq_(res.ethertype, self.ethertype)
        eq_(ptype, arp)

    def test_serialize(self):
        data = bytearray()
        prev = None
        buf = self.e.serialize(data, prev)

        fmt = ethernet._PACK_STR
        res = struct.unpack(fmt, buf)

        eq_(res[0], addrconv.mac.text_to_bin(self.dst))
        eq_(res[1], addrconv.mac.text_to_bin(self.src))
        eq_(res[2], self.ethertype)

    @raises(Exception)
    def test_malformed_ethernet(self):
        m_short_buf = self.buf[1:ethernet._MIN_LEN]
        ethernet.parser(m_short_buf)

    def test_default_args(self):
        e = ethernet()
        buf = e.serialize(bytearray(), None)
        res = struct.unpack(e._PACK_STR, str(buf))

        eq_(res[0], addrconv.mac.text_to_bin('ff:ff:ff:ff:ff:ff'))
        eq_(res[1], addrconv.mac.text_to_bin('00:00:00:00:00:00'))
        eq_(res[2], ether.ETH_TYPE_IP)

########NEW FILE########
__FILENAME__ = test_icmp
# Copyright (C) 2013 Nippon Telegraph and Telephone Corporation.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.


import unittest
import inspect
import logging
import struct

from nose.tools import eq_
from ryu.lib.packet import icmp
from ryu.lib.packet import packet_utils


LOG = logging.getLogger(__name__)


class Test_icmp(unittest.TestCase):

    echo_id = None
    echo_seq = None
    echo_data = None

    unreach_mtu = None
    unreach_data = None
    unreach_data_len = None

    te_data = None
    te_data_len = None

    def setUp(self):
        self.type_ = icmp.ICMP_ECHO_REQUEST
        self.code = 0
        self.csum = 0
        self.data = None

        self.ic = icmp.icmp(self.type_, self.code, self.csum, self.data)

        self.buf = bytearray(struct.pack(
            icmp.icmp._PACK_STR, self.type_, self.code, self.csum))
        self.csum_calc = packet_utils.checksum(str(self.buf))
        struct.pack_into('!H', self.buf, 2, self.csum_calc)

    def setUp_with_echo(self):
        self.echo_id = 13379
        self.echo_seq = 1
        self.echo_data = '\x30\x0e\x09\x00\x00\x00\x00\x00' \
            + '\x10\x11\x12\x13\x14\x15\x16\x17' \
            + '\x18\x19\x1a\x1b\x1c\x1d\x1e\x1f' \
            + '\x20\x21\x22\x23\x24\x25\x26\x27' \
            + '\x28\x29\x2a\x2b\x2c\x2d\x2e\x2f' \
            + '\x30\x31\x32\x33\x34\x35\x36\x37'
        self.data = icmp.echo(
            id_=self.echo_id, seq=self.echo_seq, data=self.echo_data)

        self.type_ = icmp.ICMP_ECHO_REQUEST
        self.code = 0
        self.ic = icmp.icmp(self.type_, self.code, self.csum, self.data)

        self.buf = struct.pack(
            icmp.icmp._PACK_STR, self.type_, self.code, self.csum)
        self.buf += self.data.serialize()
        self.csum_calc = packet_utils.checksum(str(self.buf))
        struct.pack_into('!H', self.buf, 2, self.csum_calc)

    def setUp_with_dest_unreach(self):
        self.unreach_mtu = 10
        self.unreach_data = 'abc'
        self.unreach_data_len = len(self.unreach_data)
        self.data = icmp.dest_unreach(
            data_len=self.unreach_data_len, mtu=self.unreach_mtu,
            data=self.unreach_data)

        self.type_ = icmp.ICMP_DEST_UNREACH
        self.code = icmp.ICMP_HOST_UNREACH_CODE
        self.ic = icmp.icmp(self.type_, self.code, self.csum, self.data)

        self.buf = struct.pack(
            icmp.icmp._PACK_STR, self.type_, self.code, self.csum)
        self.buf += self.data.serialize()
        self.csum_calc = packet_utils.checksum(str(self.buf))
        struct.pack_into('!H', self.buf, 2, self.csum_calc)

    def setUp_with_TimeExceeded(self):
        self.te_data = 'abc'
        self.te_data_len = len(self.te_data)
        self.data = icmp.TimeExceeded(
            data_len=self.te_data_len, data=self.te_data)

        self.type_ = icmp.ICMP_TIME_EXCEEDED
        self.code = 0
        self.ic = icmp.icmp(self.type_, self.code, self.csum, self.data)

        self.buf = struct.pack(
            icmp.icmp._PACK_STR, self.type_, self.code, self.csum)
        self.buf += self.data.serialize()
        self.csum_calc = packet_utils.checksum(str(self.buf))
        struct.pack_into('!H', self.buf, 2, self.csum_calc)

    def test_init(self):
        eq_(self.type_, self.ic.type)
        eq_(self.code, self.ic.code)
        eq_(self.csum, self.ic.csum)
        eq_(str(self.data), str(self.ic.data))

    def test_init_with_echo(self):
        self.setUp_with_echo()
        self.test_init()

    def test_init_with_dest_unreach(self):
        self.setUp_with_dest_unreach()
        self.test_init()

    def test_init_with_TimeExceeded(self):
        self.setUp_with_TimeExceeded()
        self.test_init()

    def test_parser(self):
        _res = icmp.icmp.parser(str(self.buf))
        if type(_res) is tuple:
            res = _res[0]
        else:
            res = _res

        eq_(self.type_, res.type)
        eq_(self.code, res.code)
        eq_(self.csum_calc, res.csum)
        eq_(str(self.data), str(res.data))

    def test_parser_with_echo(self):
        self.setUp_with_echo()
        self.test_parser()

    def test_parser_with_dest_unreach(self):
        self.setUp_with_dest_unreach()
        self.test_parser()

    def test_parser_with_TimeExceeded(self):
        self.setUp_with_TimeExceeded()
        self.test_parser()

    def test_serialize(self):
        data = bytearray()
        prev = None
        buf = self.ic.serialize(data, prev)

        res = struct.unpack_from(icmp.icmp._PACK_STR, str(buf))

        eq_(self.type_, res[0])
        eq_(self.code, res[1])
        eq_(self.csum_calc, res[2])

    def test_serialize_with_echo(self):
        self.setUp_with_echo()
        self.test_serialize()

        data = bytearray()
        prev = None
        buf = self.ic.serialize(data, prev)
        echo = icmp.echo.parser(str(buf), icmp.icmp._MIN_LEN)
        eq_(repr(self.data), repr(echo))

    def test_serialize_with_dest_unreach(self):
        self.setUp_with_dest_unreach()
        self.test_serialize()

        data = bytearray()
        prev = None
        buf = self.ic.serialize(data, prev)
        unreach = icmp.dest_unreach.parser(str(buf), icmp.icmp._MIN_LEN)
        eq_(repr(self.data), repr(unreach))

    def test_serialize_with_TimeExceeded(self):
        self.setUp_with_TimeExceeded()
        self.test_serialize()

        data = bytearray()
        prev = None
        buf = self.ic.serialize(data, prev)
        te = icmp.TimeExceeded.parser(str(buf), icmp.icmp._MIN_LEN)
        eq_(repr(self.data), repr(te))

    def test_to_string(self):
        icmp_values = {'type': repr(self.type_),
                       'code': repr(self.code),
                       'csum': repr(self.csum),
                       'data': repr(self.data)}
        _ic_str = ','.join(['%s=%s' % (k, icmp_values[k])
                            for k, v in inspect.getmembers(self.ic)
                            if k in icmp_values])
        ic_str = '%s(%s)' % (icmp.icmp.__name__, _ic_str)

        eq_(str(self.ic), ic_str)
        eq_(repr(self.ic), ic_str)

    def test_to_string_with_echo(self):
        self.setUp_with_echo()
        self.test_to_string()

    def test_to_string_with_dest_unreach(self):
        self.setUp_with_dest_unreach()
        self.test_to_string()

    def test_to_string_with_TimeExceeded(self):
        self.setUp_with_TimeExceeded()
        self.test_to_string()

    def test_default_args(self):
        ic = icmp.icmp()
        buf = ic.serialize(bytearray(), None)
        res = struct.unpack(icmp.icmp._PACK_STR, str(buf[:4]))

        eq_(res[0], 8)
        eq_(res[1], 0)
        eq_(buf[4:], '\x00\x00\x00\x00')

        # with data
        ic = icmp.icmp(type_=icmp.ICMP_DEST_UNREACH, data=icmp.dest_unreach())
        buf = ic.serialize(bytearray(), None)
        res = struct.unpack(icmp.icmp._PACK_STR, str(buf[:4]))

        eq_(res[0], 3)
        eq_(res[1], 0)
        eq_(buf[4:], '\x00\x00\x00\x00')


class Test_echo(unittest.TestCase):

    def setUp(self):
        self.id_ = 13379
        self.seq = 1
        self.data = '\x30\x0e\x09\x00\x00\x00\x00\x00' \
            + '\x10\x11\x12\x13\x14\x15\x16\x17' \
            + '\x18\x19\x1a\x1b\x1c\x1d\x1e\x1f' \
            + '\x20\x21\x22\x23\x24\x25\x26\x27' \
            + '\x28\x29\x2a\x2b\x2c\x2d\x2e\x2f' \
            + '\x30\x31\x32\x33\x34\x35\x36\x37'
        self.echo = icmp.echo(
            self.id_, self.seq, self.data)
        self.buf = struct.pack('!HH', self.id_, self.seq)
        self.buf += self.data

    def test_init(self):
        eq_(self.id_, self.echo.id)
        eq_(self.seq, self.echo.seq)
        eq_(self.data, self.echo.data)

    def test_parser(self):
        _res = icmp.echo.parser(self.buf, 0)
        if type(_res) is tuple:
            res = _res[0]
        else:
            res = _res
        eq_(self.id_, res.id)
        eq_(self.seq, res.seq)
        eq_(self.data, res.data)

    def test_serialize(self):
        buf = self.echo.serialize()
        res = struct.unpack_from('!HH', str(buf))
        eq_(self.id_, res[0])
        eq_(self.seq, res[1])
        eq_(self.data, buf[struct.calcsize('!HH'):])

    def test_default_args(self):
        ec = icmp.echo()
        buf = ec.serialize()
        res = struct.unpack(icmp.echo._PACK_STR, str(buf))

        eq_(res[0], 0)
        eq_(res[1], 0)


class Test_dest_unreach(unittest.TestCase):

    def setUp(self):
        self.mtu = 10
        self.data = 'abc'
        self.data_len = len(self.data)
        self.dest_unreach = icmp.dest_unreach(
            data_len=self.data_len, mtu=self.mtu, data=self.data)
        self.buf = struct.pack('!xBH', self.data_len, self.mtu)
        self.buf += self.data

    def test_init(self):
        eq_(self.data_len, self.dest_unreach.data_len)
        eq_(self.mtu, self.dest_unreach.mtu)
        eq_(self.data, self.dest_unreach.data)

    def test_parser(self):
        _res = icmp.dest_unreach.parser(self.buf, 0)
        if type(_res) is tuple:
            res = _res[0]
        else:
            res = _res
        eq_(self.data_len, res.data_len)
        eq_(self.mtu, res.mtu)
        eq_(self.data, res.data)

    def test_serialize(self):
        buf = self.dest_unreach.serialize()
        res = struct.unpack_from('!xBH', str(buf))
        eq_(self.data_len, res[0])
        eq_(self.mtu, res[1])
        eq_(self.data, buf[struct.calcsize('!xBH'):])

    def test_default_args(self):
        du = icmp.dest_unreach()
        buf = du.serialize()
        res = struct.unpack(icmp.dest_unreach._PACK_STR, str(buf))

        eq_(res[0], 0)
        eq_(res[1], 0)


class Test_TimeExceeded(unittest.TestCase):

    def setUp(self):
        self.data = 'abc'
        self.data_len = len(self.data)
        self.te = icmp.TimeExceeded(
            data_len=self.data_len, data=self.data)
        self.buf = struct.pack('!xBxx', self.data_len)
        self.buf += self.data

    def test_init(self):
        eq_(self.data_len, self.te.data_len)
        eq_(self.data, self.te.data)

    def test_parser(self):
        _res = icmp.TimeExceeded.parser(self.buf, 0)
        if type(_res) is tuple:
            res = _res[0]
        else:
            res = _res
        eq_(self.data_len, res.data_len)
        eq_(self.data, res.data)

    def test_serialize(self):
        buf = self.te.serialize()
        res = struct.unpack_from('!xBxx', str(buf))
        eq_(self.data_len, res[0])
        eq_(self.data, buf[struct.calcsize('!xBxx'):])

    def test_default_args(self):
        te = icmp.TimeExceeded()
        buf = te.serialize()
        res = struct.unpack(icmp.TimeExceeded._PACK_STR, str(buf))

        eq_(res[0], 0)

########NEW FILE########
__FILENAME__ = test_icmpv6
# Copyright (C) 2012 Nippon Telegraph and Telephone Corporation.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# vim: tabstop=4 shiftwidth=4 softtabstop=4

import unittest
import logging
import struct
import inspect

from nose.tools import ok_, eq_, nottest, raises
from nose.plugins.skip import Skip, SkipTest
from ryu.ofproto import ether, inet
from ryu.lib.packet.ethernet import ethernet
from ryu.lib.packet.packet import Packet
from ryu.lib.packet import icmpv6
from ryu.lib.packet.ipv6 import ipv6
from ryu.lib.packet import packet_utils
from ryu.lib import addrconv


LOG = logging.getLogger(__name__)


def icmpv6_csum(prev, buf):
    ph = struct.pack('!16s16sI3xB',
                     addrconv.ipv6.text_to_bin(prev.src),
                     addrconv.ipv6.text_to_bin(prev.dst),
                     prev.payload_length, prev.nxt)
    h = bytearray(buf)
    struct.pack_into('!H', h, 2, 0)

    return packet_utils.checksum(ph + h)


class Test_icmpv6_header(unittest.TestCase):
    type_ = 255
    code = 0
    csum = 207
    buf = '\xff\x00\x00\xcf'
    icmp = icmpv6.icmpv6(type_, code, 0)

    def setUp(self):
        pass

    def tearDown(self):
        pass

    def test_init(self):
        eq_(self.type_, self.icmp.type_)
        eq_(self.code, self.icmp.code)
        eq_(0, self.icmp.csum)

    def test_parser(self):
        msg, n, _ = self.icmp.parser(self.buf)

        eq_(msg.type_, self.type_)
        eq_(msg.code, self.code)
        eq_(msg.csum, self.csum)
        eq_(msg.data, None)
        eq_(n, None)

    def test_serialize(self):
        src_ipv6 = 'fe80::200:ff:fe00:ef'
        dst_ipv6 = 'fe80::200:ff:fe00:1'
        prev = ipv6(6, 0, 0, 4, 58, 255, src_ipv6, dst_ipv6)

        buf = self.icmp.serialize(bytearray(), prev)
        (type_, code, csum) = struct.unpack(self.icmp._PACK_STR, buffer(buf))

        eq_(type_, self.type_)
        eq_(code, self.code)
        eq_(csum, self.csum)

    @raises(Exception)
    def test_malformed_icmpv6(self):
        m_short_buf = self.buf[1:self.icmp._MIN_LEN]
        self.icmp.parser(m_short_buf)

    def test_default_args(self):
        prev = ipv6(nxt=inet.IPPROTO_ICMPV6)
        ic = icmpv6.icmpv6()
        prev.serialize(ic, None)
        buf = ic.serialize(bytearray(), prev)
        res = struct.unpack(icmpv6.icmpv6._PACK_STR, str(buf))

        eq_(res[0], 0)
        eq_(res[1], 0)
        eq_(res[2], icmpv6_csum(prev, buf))


class Test_icmpv6_echo_request(unittest.TestCase):
    type_ = 128
    code = 0
    csum = 0xa572
    id_ = 0x7620
    seq = 0
    data = '\x01\xc9\xe7\x36\xd3\x39\x06\x00'
    buf = '\x80\x00\xa5\x72\x76\x20\x00\x00'

    def setUp(self):
        pass

    def tearDown(self):
        pass

    def test_init(self):
        echo = icmpv6.echo(0, 0)
        eq_(echo.id, 0)
        eq_(echo.seq, 0)
        eq_(echo.data, None)

    def _test_parser(self, data=None):
        buf = self.buf + str(data or '')
        msg, n, _ = icmpv6.icmpv6.parser(buf)

        eq_(msg.type_, self.type_)
        eq_(msg.code, self.code)
        eq_(msg.csum, self.csum)
        eq_(msg.data.id, self.id_)
        eq_(msg.data.seq, self.seq)
        eq_(msg.data.data, data)
        eq_(n, None)

    def test_parser_without_data(self):
        self._test_parser()

    def test_parser_with_data(self):
        self._test_parser(self.data)

    def _test_serialize(self, echo_data=None):
        buf = self.buf + str(echo_data or '')
        src_ipv6 = '3ffe:507:0:1:200:86ff:fe05:80da'
        dst_ipv6 = '3ffe:501:0:1001::2'
        prev = ipv6(6, 0, 0, len(buf), 64, 255, src_ipv6, dst_ipv6)
        echo_csum = icmpv6_csum(prev, buf)

        echo = icmpv6.echo(self.id_, self.seq, echo_data)
        icmp = icmpv6.icmpv6(self.type_, self.code, 0, echo)
        buf = buffer(icmp.serialize(bytearray(), prev))

        (type_, code, csum) = struct.unpack_from(icmp._PACK_STR, buf, 0)
        (id_, seq) = struct.unpack_from(echo._PACK_STR, buf, icmp._MIN_LEN)
        data = buf[(icmp._MIN_LEN + echo._MIN_LEN):]
        data = data if len(data) != 0 else None

        eq_(type_, self.type_)
        eq_(code, self.code)
        eq_(csum, echo_csum)
        eq_(id_, self.id_)
        eq_(seq, self.seq)
        eq_(data, echo_data)

    def test_serialize_without_data(self):
        self._test_serialize()

    def test_serialize_with_data(self):
        self._test_serialize(self.data)

    def test_to_string(self):
        ec = icmpv6.echo(self.id_, self.seq, self.data)
        ic = icmpv6.icmpv6(self.type_, self.code, self.csum, ec)

        echo_values = {'id': self.id_,
                       'seq': self.seq,
                       'data': self.data}
        _echo_str = ','.join(['%s=%s' % (k, repr(echo_values[k]))
                              for k, v in inspect.getmembers(ec)
                              if k in echo_values])
        echo_str = '%s(%s)' % (icmpv6.echo.__name__, _echo_str)

        icmp_values = {'type_': repr(self.type_),
                       'code': repr(self.code),
                       'csum': repr(self.csum),
                       'data': echo_str}
        _ic_str = ','.join(['%s=%s' % (k, icmp_values[k])
                            for k, v in inspect.getmembers(ic)
                            if k in icmp_values])
        ic_str = '%s(%s)' % (icmpv6.icmpv6.__name__, _ic_str)

        eq_(str(ic), ic_str)
        eq_(repr(ic), ic_str)

    def test_default_args(self):
        prev = ipv6(nxt=inet.IPPROTO_ICMPV6)
        ic = icmpv6.icmpv6(
            type_=icmpv6.ICMPV6_ECHO_REQUEST, data=icmpv6.echo())
        prev.serialize(ic, None)
        buf = ic.serialize(bytearray(), prev)
        res = struct.unpack(icmpv6.icmpv6._PACK_STR, str(buf[:4]))

        eq_(res[0], icmpv6.ICMPV6_ECHO_REQUEST)
        eq_(res[1], 0)
        eq_(res[2], icmpv6_csum(prev, buf))

        res = struct.unpack(icmpv6.echo._PACK_STR, str(buf[4:]))

        eq_(res[0], 0)
        eq_(res[1], 0)


class Test_icmpv6_echo_reply(Test_icmpv6_echo_request):
    def setUp(self):
        self.type_ = 129
        self.csum = 0xa472
        self.buf = '\x81\x00\xa4\x72\x76\x20\x00\x00'

    def test_default_args(self):
        prev = ipv6(nxt=inet.IPPROTO_ICMPV6)
        ic = icmpv6.icmpv6(
            type_=icmpv6.ICMPV6_ECHO_REPLY, data=icmpv6.echo())
        prev.serialize(ic, None)
        buf = ic.serialize(bytearray(), prev)
        res = struct.unpack(icmpv6.icmpv6._PACK_STR, str(buf[:4]))

        eq_(res[0], icmpv6.ICMPV6_ECHO_REPLY)
        eq_(res[1], 0)
        eq_(res[2], icmpv6_csum(prev, buf))

        res = struct.unpack(icmpv6.echo._PACK_STR, str(buf[4:]))

        eq_(res[0], 0)
        eq_(res[1], 0)


class Test_icmpv6_neighbor_solicit(unittest.TestCase):
    type_ = 135
    code = 0
    csum = 0x952d
    res = 0
    dst = '3ffe:507:0:1:200:86ff:fe05:80da'
    nd_type = 1
    nd_length = 1
    nd_hw_src = '00:60:97:07:69:ea'
    data = '\x01\x01\x00\x60\x97\x07\x69\xea'
    buf = '\x87\x00\x95\x2d\x00\x00\x00\x00' \
        + '\x3f\xfe\x05\x07\x00\x00\x00\x01' \
        + '\x02\x00\x86\xff\xfe\x05\x80\xda'
    src_ipv6 = '3ffe:507:0:1:200:86ff:fe05:80da'
    dst_ipv6 = '3ffe:501:0:1001::2'

    def setUp(self):
        pass

    def tearDown(self):
        pass

    def test_init(self):
        nd = icmpv6.nd_neighbor(self.res, self.dst)
        eq_(nd.res, self.res)
        eq_(nd.dst, self.dst)
        eq_(nd.option, None)

    def _test_parser(self, data=None):
        buf = self.buf + str(data or '')
        msg, n, _ = icmpv6.icmpv6.parser(buf)

        eq_(msg.type_, self.type_)
        eq_(msg.code, self.code)
        eq_(msg.csum, self.csum)
        eq_(msg.data.res, self.res)
        eq_(addrconv.ipv6.text_to_bin(msg.data.dst),
            addrconv.ipv6.text_to_bin(self.dst))
        eq_(n, None)
        if data:
            nd = msg.data.option
            eq_(nd.length, self.nd_length)
            eq_(nd.hw_src, self.nd_hw_src)
            eq_(nd.data, None)

    def test_parser_without_data(self):
        self._test_parser()

    def test_parser_with_data(self):
        self._test_parser(self.data)

    def test_serialize_without_data(self):
        nd = icmpv6.nd_neighbor(self.res, self.dst)
        prev = ipv6(6, 0, 0, 24, 64, 255, self.src_ipv6, self.dst_ipv6)
        nd_csum = icmpv6_csum(prev, self.buf)

        icmp = icmpv6.icmpv6(self.type_, self.code, 0, nd)
        buf = buffer(icmp.serialize(bytearray(), prev))

        (type_, code, csum) = struct.unpack_from(icmp._PACK_STR, buf, 0)
        (res, dst) = struct.unpack_from(nd._PACK_STR, buf, icmp._MIN_LEN)
        data = buf[(icmp._MIN_LEN + nd._MIN_LEN):]

        eq_(type_, self.type_)
        eq_(code, self.code)
        eq_(csum, nd_csum)
        eq_(res >> 29, self.res)
        eq_(dst, addrconv.ipv6.text_to_bin(self.dst))
        eq_(data, '')

    def test_serialize_with_data(self):
        nd_opt = icmpv6.nd_option_sla(self.nd_length, self.nd_hw_src)
        nd = icmpv6.nd_neighbor(self.res, self.dst, nd_opt)
        prev = ipv6(6, 0, 0, 32, 64, 255, self.src_ipv6, self.dst_ipv6)
        nd_csum = icmpv6_csum(prev, self.buf + self.data)

        icmp = icmpv6.icmpv6(self.type_, self.code, 0, nd)
        buf = buffer(icmp.serialize(bytearray(), prev))

        (type_, code, csum) = struct.unpack_from(icmp._PACK_STR, buf, 0)
        (res, dst) = struct.unpack_from(nd._PACK_STR, buf, icmp._MIN_LEN)
        (nd_type, nd_length, nd_hw_src) = struct.unpack_from(
            nd_opt._PACK_STR, buf, icmp._MIN_LEN + nd._MIN_LEN)
        data = buf[(icmp._MIN_LEN + nd._MIN_LEN + 8):]

        eq_(type_, self.type_)
        eq_(code, self.code)
        eq_(csum, nd_csum)
        eq_(res >> 29, self.res)
        eq_(dst, addrconv.ipv6.text_to_bin(self.dst))
        eq_(nd_type, self.nd_type)
        eq_(nd_length, self.nd_length)
        eq_(nd_hw_src, addrconv.mac.text_to_bin(self.nd_hw_src))

    def test_to_string(self):
        nd_opt = icmpv6.nd_option_sla(self.nd_length, self.nd_hw_src)
        nd = icmpv6.nd_neighbor(self.res, self.dst, nd_opt)
        ic = icmpv6.icmpv6(self.type_, self.code, self.csum, nd)

        nd_opt_values = {'length': self.nd_length,
                         'hw_src': self.nd_hw_src,
                         'data': None}
        _nd_opt_str = ','.join(['%s=%s' % (k, repr(nd_opt_values[k]))
                                for k, v in inspect.getmembers(nd_opt)
                                if k in nd_opt_values])
        nd_opt_str = '%s(%s)' % (icmpv6.nd_option_sla.__name__, _nd_opt_str)

        nd_values = {'res': repr(nd.res),
                     'dst': repr(self.dst),
                     'option': nd_opt_str}
        _nd_str = ','.join(['%s=%s' % (k, nd_values[k])
                            for k, v in inspect.getmembers(nd)
                            if k in nd_values])
        nd_str = '%s(%s)' % (icmpv6.nd_neighbor.__name__, _nd_str)

        icmp_values = {'type_': repr(self.type_),
                       'code': repr(self.code),
                       'csum': repr(self.csum),
                       'data': nd_str}
        _ic_str = ','.join(['%s=%s' % (k, icmp_values[k])
                            for k, v in inspect.getmembers(ic)
                            if k in icmp_values])
        ic_str = '%s(%s)' % (icmpv6.icmpv6.__name__, _ic_str)

        eq_(str(ic), ic_str)
        eq_(repr(ic), ic_str)

    def test_default_args(self):
        prev = ipv6(nxt=inet.IPPROTO_ICMPV6)
        ic = icmpv6.icmpv6(
            type_=icmpv6.ND_NEIGHBOR_SOLICIT, data=icmpv6.nd_neighbor())
        prev.serialize(ic, None)
        buf = ic.serialize(bytearray(), prev)
        res = struct.unpack(icmpv6.icmpv6._PACK_STR, str(buf[:4]))

        eq_(res[0], icmpv6.ND_NEIGHBOR_SOLICIT)
        eq_(res[1], 0)
        eq_(res[2], icmpv6_csum(prev, buf))

        res = struct.unpack(icmpv6.nd_neighbor._PACK_STR, str(buf[4:]))

        eq_(res[0], 0)
        eq_(res[1], addrconv.ipv6.text_to_bin('::'))

        # with nd_option_sla
        prev = ipv6(nxt=inet.IPPROTO_ICMPV6)
        ic = icmpv6.icmpv6(
            type_=icmpv6.ND_NEIGHBOR_SOLICIT,
            data=icmpv6.nd_neighbor(
                option=icmpv6.nd_option_sla()))
        prev.serialize(ic, None)
        buf = ic.serialize(bytearray(), prev)
        res = struct.unpack(icmpv6.icmpv6._PACK_STR, str(buf[:4]))

        eq_(res[0], icmpv6.ND_NEIGHBOR_SOLICIT)
        eq_(res[1], 0)
        eq_(res[2], icmpv6_csum(prev, buf))

        res = struct.unpack(icmpv6.nd_neighbor._PACK_STR, str(buf[4:24]))

        eq_(res[0], 0)
        eq_(res[1], addrconv.ipv6.text_to_bin('::'))

        res = struct.unpack(icmpv6.nd_option_sla._PACK_STR, str(buf[24:]))

        eq_(res[0], icmpv6.ND_OPTION_SLA)
        eq_(res[1], len(icmpv6.nd_option_sla()) / 8)
        eq_(res[2], addrconv.mac.text_to_bin('00:00:00:00:00:00'))


class Test_icmpv6_neighbor_advert(Test_icmpv6_neighbor_solicit):
    def setUp(self):
        self.type_ = 136
        self.csum = 0xb8ba
        self.res = 7
        self.dst = '3ffe:507:0:1:260:97ff:fe07:69ea'
        self.nd_type = 2
        self.nd_length = 1
        self.nd_data = None
        self.nd_hw_src = '00:60:97:07:69:ea'
        self.data = '\x02\x01\x00\x60\x97\x07\x69\xea'
        self.buf = '\x88\x00\xb8\xba\xe0\x00\x00\x00' \
            + '\x3f\xfe\x05\x07\x00\x00\x00\x01' \
            + '\x02\x60\x97\xff\xfe\x07\x69\xea'

    def test_serialize_with_data(self):
        nd_opt = icmpv6.nd_option_tla(self.nd_length, self.nd_hw_src)
        nd = icmpv6.nd_neighbor(self.res, self.dst, nd_opt)
        prev = ipv6(6, 0, 0, 32, 64, 255, self.src_ipv6, self.dst_ipv6)
        nd_csum = icmpv6_csum(prev, self.buf + self.data)

        icmp = icmpv6.icmpv6(self.type_, self.code, 0, nd)
        buf = buffer(icmp.serialize(bytearray(), prev))

        (type_, code, csum) = struct.unpack_from(icmp._PACK_STR, buf, 0)
        (res, dst) = struct.unpack_from(nd._PACK_STR, buf, icmp._MIN_LEN)
        (nd_type, nd_length, nd_hw_src) = struct.unpack_from(
            nd_opt._PACK_STR, buf, icmp._MIN_LEN + nd._MIN_LEN)
        data = buf[(icmp._MIN_LEN + nd._MIN_LEN + 8):]

        eq_(type_, self.type_)
        eq_(code, self.code)
        eq_(csum, nd_csum)
        eq_(res >> 29, self.res)
        eq_(dst, addrconv.ipv6.text_to_bin(self.dst))
        eq_(nd_type, self.nd_type)
        eq_(nd_length, self.nd_length)
        eq_(nd_hw_src, addrconv.mac.text_to_bin(self.nd_hw_src))

    def test_to_string(self):
        nd_opt = icmpv6.nd_option_tla(self.nd_length, self.nd_hw_src)
        nd = icmpv6.nd_neighbor(self.res, self.dst, nd_opt)
        ic = icmpv6.icmpv6(self.type_, self.code, self.csum, nd)

        nd_opt_values = {'length': self.nd_length,
                         'hw_src': self.nd_hw_src,
                         'data': None}
        _nd_opt_str = ','.join(['%s=%s' % (k, repr(nd_opt_values[k]))
                                for k, v in inspect.getmembers(nd_opt)
                                if k in nd_opt_values])
        nd_opt_str = '%s(%s)' % (icmpv6.nd_option_tla.__name__, _nd_opt_str)

        nd_values = {'res': repr(nd.res),
                     'dst': repr(self.dst),
                     'option': nd_opt_str}
        _nd_str = ','.join(['%s=%s' % (k, nd_values[k])
                            for k, v in inspect.getmembers(nd)
                            if k in nd_values])
        nd_str = '%s(%s)' % (icmpv6.nd_neighbor.__name__, _nd_str)

        icmp_values = {'type_': repr(self.type_),
                       'code': repr(self.code),
                       'csum': repr(self.csum),
                       'data': nd_str}
        _ic_str = ','.join(['%s=%s' % (k, icmp_values[k])
                            for k, v in inspect.getmembers(ic)
                            if k in icmp_values])
        ic_str = '%s(%s)' % (icmpv6.icmpv6.__name__, _ic_str)

        eq_(str(ic), ic_str)
        eq_(repr(ic), ic_str)

    def test_default_args(self):
        prev = ipv6(nxt=inet.IPPROTO_ICMPV6)
        ic = icmpv6.icmpv6(
            type_=icmpv6.ND_NEIGHBOR_ADVERT, data=icmpv6.nd_neighbor())
        prev.serialize(ic, None)
        buf = ic.serialize(bytearray(), prev)
        res = struct.unpack(icmpv6.icmpv6._PACK_STR, str(buf[:4]))

        eq_(res[0], icmpv6.ND_NEIGHBOR_ADVERT)
        eq_(res[1], 0)
        eq_(res[2], icmpv6_csum(prev, buf))

        res = struct.unpack(icmpv6.nd_neighbor._PACK_STR, str(buf[4:]))

        eq_(res[0], 0)
        eq_(res[1], addrconv.ipv6.text_to_bin('::'))

        # with nd_option_tla
        prev = ipv6(nxt=inet.IPPROTO_ICMPV6)
        ic = icmpv6.icmpv6(
            type_=icmpv6.ND_NEIGHBOR_ADVERT,
            data=icmpv6.nd_neighbor(
                option=icmpv6.nd_option_tla()))
        prev.serialize(ic, None)
        buf = ic.serialize(bytearray(), prev)
        res = struct.unpack(icmpv6.icmpv6._PACK_STR, str(buf[:4]))

        eq_(res[0], icmpv6.ND_NEIGHBOR_ADVERT)
        eq_(res[1], 0)
        eq_(res[2], icmpv6_csum(prev, buf))

        res = struct.unpack(icmpv6.nd_neighbor._PACK_STR, str(buf[4:24]))

        eq_(res[0], 0)
        eq_(res[1], addrconv.ipv6.text_to_bin('::'))

        res = struct.unpack(icmpv6.nd_option_tla._PACK_STR, str(buf[24:]))

        eq_(res[0], icmpv6.ND_OPTION_TLA)
        eq_(res[1], len(icmpv6.nd_option_tla()) / 8)
        eq_(res[2], addrconv.mac.text_to_bin('00:00:00:00:00:00'))


class Test_icmpv6_router_solicit(unittest.TestCase):
    type_ = 133
    code = 0
    csum = 0x97d9
    res = 0
    nd_type = 1
    nd_length = 1
    nd_hw_src = '12:2d:a5:6d:bc:0f'
    data = '\x00\x00\x00\x00\x01\x01\x12\x2d\xa5\x6d\xbc\x0f'
    buf = '\x85\x00\x97\xd9'
    src_ipv6 = '3ffe:507:0:1:200:86ff:fe05:80da'
    dst_ipv6 = '3ffe:501:0:1001::2'

    def setUp(self):
        pass

    def tearDown(self):
        pass

    def test_init(self):
        rs = icmpv6.nd_router_solicit(self.res)
        eq_(rs.res, self.res)
        eq_(rs.option, None)

    def _test_parser(self, data=None):
        buf = self.buf + str(data or '')
        msg, n, _ = icmpv6.icmpv6.parser(buf)

        eq_(msg.type_, self.type_)
        eq_(msg.code, self.code)
        eq_(msg.csum, self.csum)
        if data is not None:
            eq_(msg.data.res, self.res)
        eq_(n, None)
        if data:
            rs = msg.data.option
            eq_(rs.length, self.nd_length)
            eq_(rs.hw_src, self.nd_hw_src)
            eq_(rs.data, None)

    def test_parser_without_data(self):
        self._test_parser()

    def test_parser_with_data(self):
        self._test_parser(self.data)

    def test_serialize_without_data(self):
        rs = icmpv6.nd_router_solicit(self.res)
        prev = ipv6(6, 0, 0, 8, 64, 255, self.src_ipv6, self.dst_ipv6)
        rs_csum = icmpv6_csum(prev, self.buf)

        icmp = icmpv6.icmpv6(self.type_, self.code, 0, rs)
        buf = buffer(icmp.serialize(bytearray(), prev))

        (type_, code, csum) = struct.unpack_from(icmp._PACK_STR, buf, 0)
        res = struct.unpack_from(rs._PACK_STR, buf, icmp._MIN_LEN)
        data = buf[(icmp._MIN_LEN + rs._MIN_LEN):]

        eq_(type_, self.type_)
        eq_(code, self.code)
        eq_(csum, rs_csum)
        eq_(res[0], self.res)
        eq_(data, '')

    def test_serialize_with_data(self):
        nd_opt = icmpv6.nd_option_sla(self.nd_length, self.nd_hw_src)
        rs = icmpv6.nd_router_solicit(self.res, nd_opt)
        prev = ipv6(6, 0, 0, 16, 64, 255, self.src_ipv6, self.dst_ipv6)
        rs_csum = icmpv6_csum(prev, self.buf + self.data)

        icmp = icmpv6.icmpv6(self.type_, self.code, 0, rs)
        buf = buffer(icmp.serialize(bytearray(), prev))

        (type_, code, csum) = struct.unpack_from(icmp._PACK_STR, buf, 0)
        res = struct.unpack_from(rs._PACK_STR, buf, icmp._MIN_LEN)
        (nd_type, nd_length, nd_hw_src) = struct.unpack_from(
            nd_opt._PACK_STR, buf, icmp._MIN_LEN + rs._MIN_LEN)
        data = buf[(icmp._MIN_LEN + rs._MIN_LEN + 8):]

        eq_(type_, self.type_)
        eq_(code, self.code)
        eq_(csum, rs_csum)
        eq_(res[0], self.res)
        eq_(nd_type, self.nd_type)
        eq_(nd_length, self.nd_length)
        eq_(nd_hw_src, addrconv.mac.text_to_bin(self.nd_hw_src))

    def test_to_string(self):
        nd_opt = icmpv6.nd_option_sla(self.nd_length, self.nd_hw_src)
        rs = icmpv6.nd_router_solicit(self.res, nd_opt)
        ic = icmpv6.icmpv6(self.type_, self.code, self.csum, rs)

        nd_opt_values = {'length': self.nd_length,
                         'hw_src': self.nd_hw_src,
                         'data': None}
        _nd_opt_str = ','.join(['%s=%s' % (k, repr(nd_opt_values[k]))
                                for k, v in inspect.getmembers(nd_opt)
                                if k in nd_opt_values])
        nd_opt_str = '%s(%s)' % (icmpv6.nd_option_sla.__name__, _nd_opt_str)

        rs_values = {'res': repr(rs.res),
                     'option': nd_opt_str}
        _rs_str = ','.join(['%s=%s' % (k, rs_values[k])
                            for k, v in inspect.getmembers(rs)
                            if k in rs_values])
        rs_str = '%s(%s)' % (icmpv6.nd_router_solicit.__name__, _rs_str)

        icmp_values = {'type_': repr(self.type_),
                       'code': repr(self.code),
                       'csum': repr(self.csum),
                       'data': rs_str}
        _ic_str = ','.join(['%s=%s' % (k, icmp_values[k])
                            for k, v in inspect.getmembers(ic)
                            if k in icmp_values])
        ic_str = '%s(%s)' % (icmpv6.icmpv6.__name__, _ic_str)

        eq_(str(ic), ic_str)
        eq_(repr(ic), ic_str)

    def test_default_args(self):
        prev = ipv6(nxt=inet.IPPROTO_ICMPV6)
        ic = icmpv6.icmpv6(
            type_=icmpv6.ND_ROUTER_SOLICIT, data=icmpv6.nd_router_solicit())
        prev.serialize(ic, None)
        buf = ic.serialize(bytearray(), prev)
        res = struct.unpack(icmpv6.icmpv6._PACK_STR, str(buf[:4]))

        eq_(res[0], icmpv6.ND_ROUTER_SOLICIT)
        eq_(res[1], 0)
        eq_(res[2], icmpv6_csum(prev, buf))

        res = struct.unpack(icmpv6.nd_router_solicit._PACK_STR, str(buf[4:]))

        eq_(res[0], 0)

        # with nd_option_sla
        prev = ipv6(nxt=inet.IPPROTO_ICMPV6)
        ic = icmpv6.icmpv6(
            type_=icmpv6.ND_ROUTER_SOLICIT,
            data=icmpv6.nd_router_solicit(
                option=icmpv6.nd_option_sla()))
        prev.serialize(ic, None)
        buf = ic.serialize(bytearray(), prev)
        res = struct.unpack(icmpv6.icmpv6._PACK_STR, str(buf[:4]))

        eq_(res[0], icmpv6.ND_ROUTER_SOLICIT)
        eq_(res[1], 0)
        eq_(res[2], icmpv6_csum(prev, buf))

        res = struct.unpack(icmpv6.nd_router_solicit._PACK_STR, str(buf[4:8]))

        eq_(res[0], 0)

        res = struct.unpack(icmpv6.nd_option_sla._PACK_STR, str(buf[8:]))

        eq_(res[0], icmpv6.ND_OPTION_SLA)
        eq_(res[1], len(icmpv6.nd_option_sla()) / 8)
        eq_(res[2], addrconv.mac.text_to_bin('00:00:00:00:00:00'))


class Test_icmpv6_router_advert(unittest.TestCase):

    def setUp(self):
        pass

    def tearDown(self):
        pass

    def test_default_args(self):
        prev = ipv6(nxt=inet.IPPROTO_ICMPV6)
        ic = icmpv6.icmpv6(
            type_=icmpv6.ND_ROUTER_ADVERT, data=icmpv6.nd_router_advert())
        prev.serialize(ic, None)
        buf = ic.serialize(bytearray(), prev)
        res = struct.unpack(icmpv6.icmpv6._PACK_STR, str(buf[:4]))

        eq_(res[0], icmpv6.ND_ROUTER_ADVERT)
        eq_(res[1], 0)
        eq_(res[2], icmpv6_csum(prev, buf))

        res = struct.unpack(icmpv6.nd_router_advert._PACK_STR, str(buf[4:]))

        eq_(res[0], 0)
        eq_(res[1], 0)
        eq_(res[2], 0)
        eq_(res[3], 0)
        eq_(res[4], 0)

        # with nd_option_sla
        prev = ipv6(nxt=inet.IPPROTO_ICMPV6)
        ic = icmpv6.icmpv6(
            type_=icmpv6.ND_ROUTER_ADVERT,
            data=icmpv6.nd_router_advert(
                options=[icmpv6.nd_option_sla()]))
        prev.serialize(ic, None)
        buf = ic.serialize(bytearray(), prev)
        res = struct.unpack(icmpv6.icmpv6._PACK_STR, str(buf[:4]))

        eq_(res[0], icmpv6.ND_ROUTER_ADVERT)
        eq_(res[1], 0)
        eq_(res[2], icmpv6_csum(prev, buf))

        res = struct.unpack(icmpv6.nd_router_advert._PACK_STR, str(buf[4:16]))

        eq_(res[0], 0)
        eq_(res[1], 0)
        eq_(res[2], 0)
        eq_(res[3], 0)
        eq_(res[4], 0)

        res = struct.unpack(icmpv6.nd_option_sla._PACK_STR, str(buf[16:]))

        eq_(res[0], icmpv6.ND_OPTION_SLA)
        eq_(res[1], len(icmpv6.nd_option_sla()) / 8)
        eq_(res[2], addrconv.mac.text_to_bin('00:00:00:00:00:00'))

        # with nd_option_pi
        prev = ipv6(nxt=inet.IPPROTO_ICMPV6)
        ic = icmpv6.icmpv6(
            type_=icmpv6.ND_ROUTER_ADVERT,
            data=icmpv6.nd_router_advert(
                options=[icmpv6.nd_option_pi()]))
        prev.serialize(ic, None)
        buf = ic.serialize(bytearray(), prev)
        res = struct.unpack(icmpv6.icmpv6._PACK_STR, str(buf[:4]))

        eq_(res[0], icmpv6.ND_ROUTER_ADVERT)
        eq_(res[1], 0)
        eq_(res[2], icmpv6_csum(prev, buf))

        res = struct.unpack(icmpv6.nd_router_advert._PACK_STR, str(buf[4:16]))

        eq_(res[0], 0)
        eq_(res[1], 0)
        eq_(res[2], 0)
        eq_(res[3], 0)
        eq_(res[4], 0)

        res = struct.unpack(icmpv6.nd_option_pi._PACK_STR, str(buf[16:]))

        eq_(res[0], icmpv6.ND_OPTION_PI)
        eq_(res[1], 4)
        eq_(res[2], 0)
        eq_(res[3], 0)
        eq_(res[4], 0)
        eq_(res[5], 0)
        eq_(res[6], 0)
        eq_(res[7], addrconv.ipv6.text_to_bin('::'))

        # with nd_option_sla and nd_option_pi
        prev = ipv6(nxt=inet.IPPROTO_ICMPV6)
        ic = icmpv6.icmpv6(
            type_=icmpv6.ND_ROUTER_ADVERT,
            data=icmpv6.nd_router_advert(
                options=[icmpv6.nd_option_sla(), icmpv6.nd_option_pi()]))
        prev.serialize(ic, None)
        buf = ic.serialize(bytearray(), prev)
        res = struct.unpack(icmpv6.icmpv6._PACK_STR, str(buf[:4]))

        eq_(res[0], icmpv6.ND_ROUTER_ADVERT)
        eq_(res[1], 0)
        eq_(res[2], icmpv6_csum(prev, buf))

        res = struct.unpack(icmpv6.nd_router_advert._PACK_STR, str(buf[4:16]))

        eq_(res[0], 0)
        eq_(res[1], 0)
        eq_(res[2], 0)
        eq_(res[3], 0)
        eq_(res[4], 0)

        res = struct.unpack(icmpv6.nd_option_sla._PACK_STR, str(buf[16:24]))

        eq_(res[0], icmpv6.ND_OPTION_SLA)
        eq_(res[1], len(icmpv6.nd_option_sla()) / 8)
        eq_(res[2], addrconv.mac.text_to_bin('00:00:00:00:00:00'))

        res = struct.unpack(icmpv6.nd_option_pi._PACK_STR, str(buf[24:]))

        eq_(res[0], icmpv6.ND_OPTION_PI)
        eq_(res[1], len(icmpv6.nd_option_pi()) / 8)
        eq_(res[2], 0)
        eq_(res[3], 0)
        eq_(res[4], 0)
        eq_(res[5], 0)
        eq_(res[6], 0)
        eq_(res[7], addrconv.ipv6.text_to_bin('::'))


class Test_icmpv6_nd_option_la(unittest.TestCase):

    def setUp(self):
        pass

    def tearDown(self):
        pass

    def test_default_args(self):
        la = icmpv6.nd_option_sla()
        buf = la.serialize()
        res = struct.unpack(icmpv6.nd_option_sla._PACK_STR, str(buf))

        eq_(res[0], icmpv6.ND_OPTION_SLA)
        eq_(res[1], len(icmpv6.nd_option_sla()) / 8)
        eq_(res[2], addrconv.mac.text_to_bin('00:00:00:00:00:00'))

        # with nd_neighbor
        prev = ipv6(nxt=inet.IPPROTO_ICMPV6)
        ic = icmpv6.icmpv6(
            type_=icmpv6.ND_NEIGHBOR_ADVERT,
            data=icmpv6.nd_neighbor(
                option=icmpv6.nd_option_tla()))
        prev.serialize(ic, None)
        buf = ic.serialize(bytearray(), prev)
        res = struct.unpack(icmpv6.icmpv6._PACK_STR, str(buf[:4]))

        eq_(res[0], icmpv6.ND_NEIGHBOR_ADVERT)
        eq_(res[1], 0)
        eq_(res[2], icmpv6_csum(prev, buf))

        res = struct.unpack(icmpv6.nd_neighbor._PACK_STR, str(buf[4:24]))

        eq_(res[0], 0)
        eq_(res[1], addrconv.ipv6.text_to_bin('::'))

        res = struct.unpack(icmpv6.nd_option_tla._PACK_STR, str(buf[24:]))

        eq_(res[0], icmpv6.ND_OPTION_TLA)
        eq_(res[1], len(icmpv6.nd_option_tla()) / 8)
        eq_(res[2], addrconv.mac.text_to_bin('00:00:00:00:00:00'))

        # with nd_router_solicit
        prev = ipv6(nxt=inet.IPPROTO_ICMPV6)
        ic = icmpv6.icmpv6(
            type_=icmpv6.ND_ROUTER_SOLICIT,
            data=icmpv6.nd_router_solicit(
                option=icmpv6.nd_option_sla()))
        prev.serialize(ic, None)
        buf = ic.serialize(bytearray(), prev)
        res = struct.unpack(icmpv6.icmpv6._PACK_STR, str(buf[:4]))

        eq_(res[0], icmpv6.ND_ROUTER_SOLICIT)
        eq_(res[1], 0)
        eq_(res[2], icmpv6_csum(prev, buf))

        res = struct.unpack(icmpv6.nd_router_solicit._PACK_STR, str(buf[4:8]))

        eq_(res[0], 0)

        res = struct.unpack(icmpv6.nd_option_sla._PACK_STR, str(buf[8:]))

        eq_(res[0], icmpv6.ND_OPTION_SLA)
        eq_(res[1], len(icmpv6.nd_option_sla()) / 8)
        eq_(res[2], addrconv.mac.text_to_bin('00:00:00:00:00:00'))


class Test_icmpv6_nd_option_pi(unittest.TestCase):

    def setUp(self):
        pass

    def tearDown(self):
        pass

    def test_default_args(self):
        pi = icmpv6.nd_option_pi()
        buf = pi.serialize()
        res = struct.unpack(icmpv6.nd_option_pi._PACK_STR, str(buf))

        eq_(res[0], icmpv6.ND_OPTION_PI)
        eq_(res[1], len(icmpv6.nd_option_pi()) / 8)
        eq_(res[2], 0)
        eq_(res[3], 0)
        eq_(res[4], 0)
        eq_(res[5], 0)
        eq_(res[6], 0)
        eq_(res[7], addrconv.ipv6.text_to_bin('::'))

        # with nd_router_advert
        prev = ipv6(nxt=inet.IPPROTO_ICMPV6)
        ic = icmpv6.icmpv6(
            type_=icmpv6.ND_ROUTER_ADVERT,
            data=icmpv6.nd_router_advert(
                options=[icmpv6.nd_option_pi()]))
        prev.serialize(ic, None)
        buf = ic.serialize(bytearray(), prev)
        res = struct.unpack(icmpv6.icmpv6._PACK_STR, str(buf[:4]))

        eq_(res[0], icmpv6.ND_ROUTER_ADVERT)
        eq_(res[1], 0)
        eq_(res[2], icmpv6_csum(prev, buf))

        res = struct.unpack(icmpv6.nd_router_advert._PACK_STR, str(buf[4:16]))

        eq_(res[0], 0)
        eq_(res[1], 0)
        eq_(res[2], 0)
        eq_(res[3], 0)
        eq_(res[4], 0)

        res = struct.unpack(icmpv6.nd_option_pi._PACK_STR, str(buf[16:]))

        eq_(res[0], icmpv6.ND_OPTION_PI)
        eq_(res[1], 4)
        eq_(res[2], 0)
        eq_(res[3], 0)
        eq_(res[4], 0)
        eq_(res[5], 0)
        eq_(res[6], 0)
        eq_(res[7], addrconv.ipv6.text_to_bin('::'))

########NEW FILE########
__FILENAME__ = test_igmp
# Copyright (C) 2013 Nippon Telegraph and Telephone Corporation.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# vim: tabstop=4 shiftwidth=4 softtabstop=4

import unittest
import inspect
import logging

from struct import pack, unpack_from
from nose.tools import ok_, eq_, raises
from ryu.ofproto import ether
from ryu.ofproto import inet
from ryu.lib.packet.ethernet import ethernet
from ryu.lib.packet.ipv4 import ipv4
from ryu.lib.packet.packet import Packet
from ryu.lib.packet.packet_utils import checksum
from ryu.lib import addrconv
from ryu.lib.packet.igmp import igmp
from ryu.lib.packet.igmp import IGMP_TYPE_QUERY

LOG = logging.getLogger(__name__)


class Test_igmp(unittest.TestCase):
    """ Test case for Internet Group Management Protocol
    """
    def setUp(self):
        self.msgtype = IGMP_TYPE_QUERY
        self.maxresp = 100
        self.csum = 0
        self.address = '225.0.0.1'

        self.buf = pack(igmp._PACK_STR, self.msgtype, self.maxresp,
                        self.csum,
                        addrconv.ipv4.text_to_bin(self.address))

        self.g = igmp(self.msgtype, self.maxresp, self.csum,
                      self.address)

    def tearDown(self):
        pass

    def find_protocol(self, pkt, name):
        for p in pkt.protocols:
            if p.protocol_name == name:
                return p

    def test_init(self):
        eq_(self.msgtype, self.g.msgtype)
        eq_(self.maxresp, self.g.maxresp)
        eq_(self.csum, self.g.csum)
        eq_(self.address, self.g.address)

    def test_parser(self):
        _res = self.g.parser(self.buf)
        if type(_res) is tuple:
            res = _res[0]
        else:
            res = _res

        eq_(res.msgtype, self.msgtype)
        eq_(res.maxresp, self.maxresp)
        eq_(res.csum, self.csum)
        eq_(res.address, self.address)

    def test_serialize(self):
        data = bytearray()
        prev = None
        buf = self.g.serialize(data, prev)

        res = unpack_from(igmp._PACK_STR, buffer(buf))

        eq_(res[0], self.msgtype)
        eq_(res[1], self.maxresp)
        eq_(res[2], checksum(self.buf))
        eq_(res[3], addrconv.ipv4.text_to_bin(self.address))

    def _build_igmp(self):
        dl_dst = '11:22:33:44:55:66'
        dl_src = 'aa:bb:cc:dd:ee:ff'
        dl_type = ether.ETH_TYPE_IP
        e = ethernet(dl_dst, dl_src, dl_type)

        total_length = 20 + igmp._MIN_LEN
        nw_proto = inet.IPPROTO_IGMP
        nw_dst = '11.22.33.44'
        nw_src = '55.66.77.88'
        i = ipv4(total_length=total_length, src=nw_src, dst=nw_dst,
                 proto=nw_proto)

        p = Packet()

        p.add_protocol(e)
        p.add_protocol(i)
        p.add_protocol(self.g)
        p.serialize()
        return p

    def test_build_igmp(self):
        p = self._build_igmp()

        e = self.find_protocol(p, "ethernet")
        ok_(e)
        eq_(e.ethertype, ether.ETH_TYPE_IP)

        i = self.find_protocol(p, "ipv4")
        ok_(i)
        eq_(i.proto, inet.IPPROTO_IGMP)

        g = self.find_protocol(p, "igmp")
        ok_(g)

        eq_(g.msgtype, self.msgtype)
        eq_(g.maxresp, self.maxresp)
        eq_(g.csum, checksum(self.buf))
        eq_(g.address, self.address)

    def test_to_string(self):
        igmp_values = {'msgtype': repr(self.msgtype),
                       'maxresp': repr(self.maxresp),
                       'csum': repr(self.csum),
                       'address': repr(self.address)}
        _g_str = ','.join(['%s=%s' % (k, igmp_values[k])
                           for k, v in inspect.getmembers(self.g)
                           if k in igmp_values])
        g_str = '%s(%s)' % (igmp.__name__, _g_str)

        eq_(str(self.g), g_str)
        eq_(repr(self.g), g_str)

    @raises(Exception)
    def test_malformed_igmp(self):
        m_short_buf = self.buf[1:igmp._MIN_LEN]
        igmp.parser(m_short_buf)

########NEW FILE########
__FILENAME__ = test_ipv4
# Copyright (C) 2012 Nippon Telegraph and Telephone Corporation.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# vim: tabstop=4 shiftwidth=4 softtabstop=4

import unittest
import logging
import struct
from struct import *
from nose.tools import *
from nose.plugins.skip import Skip, SkipTest
from ryu.ofproto import ether, inet
from ryu.lib.packet import packet_utils
from ryu.lib.packet.ethernet import ethernet
from ryu.lib.packet.packet import Packet
from ryu.lib.packet.ipv4 import ipv4
from ryu.lib.packet.tcp import tcp
from ryu.lib import addrconv


LOG = logging.getLogger('test_ipv4')


class Test_ipv4(unittest.TestCase):
    """ Test case for ipv4
    """

    version = 4
    header_length = 5 + 10
    ver_hlen = version << 4 | header_length
    tos = 0
    total_length = header_length + 64
    identification = 30774
    flags = 4
    offset = 1480
    flg_off = flags << 13 | offset
    ttl = 64
    proto = inet.IPPROTO_TCP
    csum = 0xadc6
    src = '131.151.32.21'
    dst = '131.151.32.129'
    length = header_length * 4
    option = '\x86\x28\x00\x00\x00\x01\x01\x22' \
        + '\x00\x01\xae\x00\x00\x00\x00\x00' \
        + '\x00\x00\x00\x00\x00\x00\x00\x00' \
        + '\x00\x00\x00\x00\x00\x00\x00\x00' \
        + '\x00\x00\x00\x00\x00\x00\x00\x01'

    buf = pack(ipv4._PACK_STR, ver_hlen, tos, total_length, identification,
               flg_off, ttl, proto, csum,
               addrconv.ipv4.text_to_bin(src),
               addrconv.ipv4.text_to_bin(dst)) \
        + option

    ip = ipv4(version, header_length, tos, total_length, identification,
              flags, offset, ttl, proto, csum, src, dst, option)

    def setUp(self):
        pass

    def tearDown(self):
        pass

    def test_init(self):
        eq_(self.version, self.ip.version)
        eq_(self.header_length, self.ip.header_length)
        eq_(self.tos, self.ip.tos)
        eq_(self.total_length, self.ip.total_length)
        eq_(self.identification, self.ip.identification)
        eq_(self.flags, self.ip.flags)
        eq_(self.offset, self.ip.offset)
        eq_(self.ttl, self.ip.ttl)
        eq_(self.proto, self.ip.proto)
        eq_(self.csum, self.ip.csum)
        eq_(self.src, self.ip.src)
        eq_(self.dst, self.ip.dst)
        eq_(self.length, len(self.ip))
        eq_(self.option, self.ip.option)

    def test_parser(self):
        res, ptype, _ = self.ip.parser(self.buf)

        eq_(res.version, self.version)
        eq_(res.header_length, self.header_length)
        eq_(res.tos, self.tos)
        eq_(res.total_length, self.total_length)
        eq_(res.identification, self.identification)
        eq_(res.flags, self.flags)
        eq_(res.offset, self.offset)
        eq_(res.ttl, self.ttl)
        eq_(res.proto, self.proto)
        eq_(res.csum, self.csum)
        eq_(res.src, self.src)
        eq_(res.dst, self.dst)
        eq_(ptype, tcp)

    def test_serialize(self):
        buf = self.ip.serialize(bytearray(), None)
        res = struct.unpack_from(ipv4._PACK_STR, str(buf))
        option = buf[ipv4._MIN_LEN:ipv4._MIN_LEN + len(self.option)]

        eq_(res[0], self.ver_hlen)
        eq_(res[1], self.tos)
        eq_(res[2], self.total_length)
        eq_(res[3], self.identification)
        eq_(res[4], self.flg_off)
        eq_(res[5], self.ttl)
        eq_(res[6], self.proto)
        eq_(res[8], addrconv.ipv4.text_to_bin(self.src))
        eq_(res[9], addrconv.ipv4.text_to_bin(self.dst))
        eq_(option, self.option)

        # checksum
        csum = packet_utils.checksum(buf)
        eq_(csum, 0)

    @raises(Exception)
    def test_malformed_ipv4(self):
        m_short_buf = self.buf[1:ipv4._MIN_LEN]
        ipv4.parser(m_short_buf)

########NEW FILE########
__FILENAME__ = test_ipv6
# Copyright (C) 2013 Nippon Telegraph and Telephone Corporation.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.


import unittest
import logging
import inspect
import struct

from nose.tools import *
from nose.plugins.skip import Skip, SkipTest
from ryu.lib import addrconv
from ryu.lib import ip
from ryu.lib.packet import ipv6


LOG = logging.getLogger(__name__)


class Test_ipv6(unittest.TestCase):

    def setUp(self):
        self.version = 6
        self.traffic_class = 0
        self.flow_label = 0
        self.payload_length = 817
        self.nxt = 6
        self.hop_limit = 128
        self.src = '2002:4637:d5d3::4637:d5d3'
        self.dst = '2001:4860:0:2001::68'
        self.ext_hdrs = []
        self.ip = ipv6.ipv6(
            self.version, self.traffic_class, self.flow_label,
            self.payload_length, self.nxt, self.hop_limit, self.src,
            self.dst, self.ext_hdrs)

        self.v_tc_flow = (
            self.version << 28 | self.traffic_class << 20 |
            self.flow_label << 12)
        self.buf = struct.pack(
            ipv6.ipv6._PACK_STR, self.v_tc_flow,
            self.payload_length, self.nxt, self.hop_limit,
            addrconv.ipv6.text_to_bin(self.src),
            addrconv.ipv6.text_to_bin(self.dst))

    def setUp_with_hop_opts(self):
        self.opt1_type = 5
        self.opt1_len = 2
        self.opt1_data = '\x00\x00'
        self.opt2_type = 1
        self.opt2_len = 0
        self.opt2_data = None
        self.options = [
            ipv6.option(self.opt1_type, self.opt1_len, self.opt1_data),
            ipv6.option(self.opt2_type, self.opt2_len, self.opt2_data),
        ]
        self.hop_opts_nxt = 6
        self.hop_opts_size = 0
        self.hop_opts = ipv6.hop_opts(
            self.hop_opts_nxt, self.hop_opts_size, self.options)
        self.ext_hdrs = [self.hop_opts]
        self.payload_length += len(self.hop_opts)
        self.nxt = ipv6.hop_opts.TYPE
        self.ip = ipv6.ipv6(
            self.version, self.traffic_class, self.flow_label,
            self.payload_length, self.nxt, self.hop_limit, self.src,
            self.dst, self.ext_hdrs)
        self.buf = struct.pack(
            ipv6.ipv6._PACK_STR, self.v_tc_flow,
            self.payload_length, self.nxt, self.hop_limit,
            addrconv.ipv6.text_to_bin(self.src),
            addrconv.ipv6.text_to_bin(self.dst))
        self.buf += self.hop_opts.serialize()

    def setUp_with_dst_opts(self):
        self.opt1_type = 5
        self.opt1_len = 2
        self.opt1_data = '\x00\x00'
        self.opt2_type = 1
        self.opt2_len = 0
        self.opt2_data = None
        self.options = [
            ipv6.option(self.opt1_type, self.opt1_len, self.opt1_data),
            ipv6.option(self.opt2_type, self.opt2_len, self.opt2_data),
        ]
        self.dst_opts_nxt = 6
        self.dst_opts_size = 0
        self.dst_opts = ipv6.dst_opts(
            self.dst_opts_nxt, self.dst_opts_size, self.options)
        self.ext_hdrs = [self.dst_opts]
        self.payload_length += len(self.dst_opts)
        self.nxt = ipv6.dst_opts.TYPE
        self.ip = ipv6.ipv6(
            self.version, self.traffic_class, self.flow_label,
            self.payload_length, self.nxt, self.hop_limit, self.src,
            self.dst, self.ext_hdrs)
        self.buf = struct.pack(
            ipv6.ipv6._PACK_STR, self.v_tc_flow,
            self.payload_length, self.nxt, self.hop_limit,
            addrconv.ipv6.text_to_bin(self.src),
            addrconv.ipv6.text_to_bin(self.dst))
        self.buf += self.dst_opts.serialize()

    def setUp_with_fragment(self):
        self.fragment_nxt = 6
        self.fragment_offset = 50
        self.fragment_more = 1
        self.fragment_id = 123
        self.fragment = ipv6.fragment(
            self.fragment_nxt, self.fragment_offset, self.fragment_more,
            self.fragment_id)
        self.ext_hdrs = [self.fragment]
        self.payload_length += len(self.fragment)
        self.nxt = ipv6.fragment.TYPE
        self.ip = ipv6.ipv6(
            self.version, self.traffic_class, self.flow_label,
            self.payload_length, self.nxt, self.hop_limit, self.src,
            self.dst, self.ext_hdrs)
        self.buf = struct.pack(
            ipv6.ipv6._PACK_STR, self.v_tc_flow,
            self.payload_length, self.nxt, self.hop_limit,
            addrconv.ipv6.text_to_bin(self.src),
            addrconv.ipv6.text_to_bin(self.dst))
        self.buf += self.fragment.serialize()

    def setUp_with_auth(self):
        self.auth_nxt = 6
        self.auth_size = 4
        self.auth_spi = 256
        self.auth_seq = 1
        self.auth_data = '\xa0\xe7\xf8\xab\xf9\x69\x1a\x8b\xf3\x9f\x7c\xae'
        self.auth = ipv6.auth(
            self.auth_nxt, self.auth_size, self.auth_spi, self.auth_seq,
            self.auth_data)
        self.ext_hdrs = [self.auth]
        self.payload_length += len(self.auth)
        self.nxt = ipv6.auth.TYPE
        self.ip = ipv6.ipv6(
            self.version, self.traffic_class, self.flow_label,
            self.payload_length, self.nxt, self.hop_limit, self.src,
            self.dst, self.ext_hdrs)
        self.buf = struct.pack(
            ipv6.ipv6._PACK_STR, self.v_tc_flow,
            self.payload_length, self.nxt, self.hop_limit,
            addrconv.ipv6.text_to_bin(self.src),
            addrconv.ipv6.text_to_bin(self.dst))
        self.buf += self.auth.serialize()

    def setUp_with_multi_headers(self):
        self.opt1_type = 5
        self.opt1_len = 2
        self.opt1_data = '\x00\x00'
        self.opt2_type = 1
        self.opt2_len = 0
        self.opt2_data = None
        self.options = [
            ipv6.option(self.opt1_type, self.opt1_len, self.opt1_data),
            ipv6.option(self.opt2_type, self.opt2_len, self.opt2_data),
        ]
        self.hop_opts_nxt = ipv6.auth.TYPE
        self.hop_opts_size = 0
        self.hop_opts = ipv6.hop_opts(
            self.hop_opts_nxt, self.hop_opts_size, self.options)
        self.auth_nxt = 6
        self.auth_size = 4
        self.auth_spi = 256
        self.auth_seq = 1
        self.auth_data = '\xa0\xe7\xf8\xab\xf9\x69\x1a\x8b\xf3\x9f\x7c\xae'
        self.auth = ipv6.auth(
            self.auth_nxt, self.auth_size, self.auth_spi, self.auth_seq,
            self.auth_data)
        self.ext_hdrs = [self.hop_opts, self.auth]
        self.payload_length += len(self.hop_opts) + len(self.auth)
        self.nxt = ipv6.hop_opts.TYPE
        self.ip = ipv6.ipv6(
            self.version, self.traffic_class, self.flow_label,
            self.payload_length, self.nxt, self.hop_limit, self.src,
            self.dst, self.ext_hdrs)
        self.buf = struct.pack(
            ipv6.ipv6._PACK_STR, self.v_tc_flow,
            self.payload_length, self.nxt, self.hop_limit,
            addrconv.ipv6.text_to_bin(self.src),
            addrconv.ipv6.text_to_bin(self.dst))
        self.buf += self.hop_opts.serialize()
        self.buf += self.auth.serialize()

    def tearDown(self):
        pass

    def test_init(self):
        eq_(self.version, self.ip.version)
        eq_(self.traffic_class, self.ip.traffic_class)
        eq_(self.flow_label, self.ip.flow_label)
        eq_(self.payload_length, self.ip.payload_length)
        eq_(self.nxt, self.ip.nxt)
        eq_(self.hop_limit, self.ip.hop_limit)
        eq_(self.src, self.ip.src)
        eq_(self.dst, self.ip.dst)
        eq_(str(self.ext_hdrs), str(self.ip.ext_hdrs))

    def test_init_with_hop_opts(self):
        self.setUp_with_hop_opts()
        self.test_init()

    def test_init_with_dst_opts(self):
        self.setUp_with_dst_opts()
        self.test_init()

    def test_init_with_fragment(self):
        self.setUp_with_fragment()
        self.test_init()

    def test_init_with_auth(self):
        self.setUp_with_auth()
        self.test_init()

    def test_init_with_multi_headers(self):
        self.setUp_with_multi_headers()
        self.test_init()

    def test_parser(self):
        _res = self.ip.parser(str(self.buf))
        if type(_res) is tuple:
            res = _res[0]
        else:
            res = _res

        eq_(self.version, res.version)
        eq_(self.traffic_class, res.traffic_class)
        eq_(self.flow_label, res.flow_label)
        eq_(self.payload_length, res.payload_length)
        eq_(self.nxt, res.nxt)
        eq_(self.hop_limit, res.hop_limit)
        eq_(self.src, res.src)
        eq_(self.dst, res.dst)
        eq_(str(self.ext_hdrs), str(res.ext_hdrs))

    def test_parser_with_hop_opts(self):
        self.setUp_with_hop_opts()
        self.test_parser()

    def test_parser_with_dst_opts(self):
        self.setUp_with_dst_opts()
        self.test_parser()

    def test_parser_with_fragment(self):
        self.setUp_with_fragment()
        self.test_parser()

    def test_parser_with_auth(self):
        self.setUp_with_auth()
        self.test_parser()

    def test_parser_with_multi_headers(self):
        self.setUp_with_multi_headers()
        self.test_parser()

    def test_serialize(self):
        data = bytearray()
        prev = None
        buf = self.ip.serialize(data, prev)

        res = struct.unpack_from(ipv6.ipv6._PACK_STR, str(buf))

        eq_(self.v_tc_flow, res[0])
        eq_(self.payload_length, res[1])
        eq_(self.nxt, res[2])
        eq_(self.hop_limit, res[3])
        eq_(self.src, addrconv.ipv6.bin_to_text(res[4]))
        eq_(self.dst, addrconv.ipv6.bin_to_text(res[5]))

    def test_serialize_with_hop_opts(self):
        self.setUp_with_hop_opts()
        self.test_serialize()

        data = bytearray()
        prev = None
        buf = self.ip.serialize(data, prev)
        hop_opts = ipv6.hop_opts.parser(str(buf[ipv6.ipv6._MIN_LEN:]))
        eq_(repr(self.hop_opts), repr(hop_opts))

    def test_serialize_with_dst_opts(self):
        self.setUp_with_dst_opts()
        self.test_serialize()

        data = bytearray()
        prev = None
        buf = self.ip.serialize(data, prev)
        dst_opts = ipv6.dst_opts.parser(str(buf[ipv6.ipv6._MIN_LEN:]))
        eq_(repr(self.dst_opts), repr(dst_opts))

    def test_serialize_with_fragment(self):
        self.setUp_with_fragment()
        self.test_serialize()

        data = bytearray()
        prev = None
        buf = self.ip.serialize(data, prev)
        fragment = ipv6.fragment.parser(str(buf[ipv6.ipv6._MIN_LEN:]))
        eq_(repr(self.fragment), repr(fragment))

    def test_serialize_with_auth(self):
        self.setUp_with_auth()
        self.test_serialize()

        data = bytearray()
        prev = None
        buf = self.ip.serialize(data, prev)
        auth = ipv6.auth.parser(str(buf[ipv6.ipv6._MIN_LEN:]))
        eq_(repr(self.auth), repr(auth))

    def test_serialize_with_multi_headers(self):
        self.setUp_with_multi_headers()
        self.test_serialize()

        data = bytearray()
        prev = None
        buf = self.ip.serialize(data, prev)
        offset = ipv6.ipv6._MIN_LEN
        hop_opts = ipv6.hop_opts.parser(str(buf[offset:]))
        offset += len(hop_opts)
        auth = ipv6.auth.parser(str(buf[offset:]))
        eq_(repr(self.hop_opts), repr(hop_opts))
        eq_(repr(self.auth), repr(auth))

    def test_to_string(self):
        ipv6_values = {'version': self.version,
                       'traffic_class': self.traffic_class,
                       'flow_label': self.flow_label,
                       'payload_length': self.payload_length,
                       'nxt': self.nxt,
                       'hop_limit': self.hop_limit,
                       'src': repr(self.src),
                       'dst': repr(self.dst),
                       'ext_hdrs': self.ext_hdrs}
        _ipv6_str = ','.join(['%s=%s' % (k, ipv6_values[k])
                              for k, v in inspect.getmembers(self.ip)
                              if k in ipv6_values])
        ipv6_str = '%s(%s)' % (ipv6.ipv6.__name__, _ipv6_str)

        eq_(str(self.ip), ipv6_str)
        eq_(repr(self.ip), ipv6_str)

    def test_to_string_with_hop_opts(self):
        self.setUp_with_hop_opts()
        self.test_to_string()

    def test_to_string_with_dst_opts(self):
        self.setUp_with_dst_opts()
        self.test_to_string()

    def test_to_string_with_fragment(self):
        self.setUp_with_fragment()
        self.test_to_string()

    def test_to_string_with_auth(self):
        self.setUp_with_auth()
        self.test_to_string()

    def test_to_string_with_multi_headers(self):
        self.setUp_with_multi_headers()
        self.test_to_string()

    def test_len(self):
        eq_(len(self.ip), 40)

    def test_len_with_hop_opts(self):
        self.setUp_with_hop_opts()
        eq_(len(self.ip), 40 + len(self.hop_opts))

    def test_len_with_dst_opts(self):
        self.setUp_with_dst_opts()
        eq_(len(self.ip), 40 + len(self.dst_opts))

    def test_len_with_fragment(self):
        self.setUp_with_fragment()
        eq_(len(self.ip), 40 + len(self.fragment))

    def test_len_with_auth(self):
        self.setUp_with_auth()
        eq_(len(self.ip), 40 + len(self.auth))

    def test_len_with_multi_headers(self):
        self.setUp_with_multi_headers()
        eq_(len(self.ip), 40 + len(self.hop_opts) + len(self.auth))

    def test_default_args(self):
        ip = ipv6.ipv6()
        buf = ip.serialize(bytearray(), None)
        res = struct.unpack(ipv6.ipv6._PACK_STR, str(buf))

        eq_(res[0], 6 << 28)
        eq_(res[1], 0)
        eq_(res[2], 6)
        eq_(res[3], 255)
        eq_(res[4], addrconv.ipv6.text_to_bin('::'))
        eq_(res[5], addrconv.ipv6.text_to_bin('::'))

        # with extension header
        ip = ipv6.ipv6(
            nxt=0, ext_hdrs=[
                ipv6.hop_opts(58, 0, [
                    ipv6.option(5, 2, '\x00\x00'),
                    ipv6.option(1, 0, None)])])
        buf = ip.serialize(bytearray(), None)
        res = struct.unpack(ipv6.ipv6._PACK_STR + '8s', str(buf))

        eq_(res[0], 6 << 28)
        eq_(res[1], 8)
        eq_(res[2], 0)
        eq_(res[3], 255)
        eq_(res[4], addrconv.ipv6.text_to_bin('::'))
        eq_(res[5], addrconv.ipv6.text_to_bin('::'))
        eq_(res[6], '\x3a\x00\x05\x02\x00\x00\x01\x00')


class Test_hop_opts(unittest.TestCase):

    def setUp(self):
        self.nxt = 0
        self.size = 8
        self.data = [
            ipv6.option(5, 2, '\x00\x00'),
            ipv6.option(1, 0, None),
            ipv6.option(0xc2, 4, '\x00\x01\x00\x00'),
            ipv6.option(1, 0, None),
        ]
        self.hop = ipv6.hop_opts(self.nxt, self.size, self.data)
        self.form = '!BB'
        self.buf = struct.pack(self.form, self.nxt, self.size) \
            + self.data[0].serialize() \
            + self.data[1].serialize() \
            + self.data[2].serialize() \
            + self.data[3].serialize()

    def tearDown(self):
        pass

    def test_init(self):
        eq_(self.nxt, self.hop.nxt)
        eq_(self.size, self.hop.size)
        eq_(self.data, self.hop.data)

    @raises(Exception)
    def test_invalid_size(self):
        ipv6.hop_opts(self.nxt, 1, self.data)

    def test_parser(self):
        _res = ipv6.hop_opts.parser(self.buf)
        if type(_res) is tuple:
            res = _res[0]
        else:
            res = _res
        eq_(self.nxt, res.nxt)
        eq_(self.size, res.size)
        eq_(str(self.data), str(res.data))

    def test_serialize(self):
        buf = self.hop.serialize()
        res = struct.unpack_from(self.form, str(buf))
        eq_(self.nxt, res[0])
        eq_(self.size, res[1])
        offset = struct.calcsize(self.form)
        opt1 = ipv6.option.parser(str(buf[offset:]))
        offset += len(opt1)
        opt2 = ipv6.option.parser(str(buf[offset:]))
        offset += len(opt2)
        opt3 = ipv6.option.parser(str(buf[offset:]))
        offset += len(opt3)
        opt4 = ipv6.option.parser(str(buf[offset:]))
        eq_(5, opt1.type_)
        eq_(2, opt1.len_)
        eq_('\x00\x00', opt1.data)
        eq_(1, opt2.type_)
        eq_(0, opt2.len_)
        eq_(None, opt2.data)
        eq_(0xc2, opt3.type_)
        eq_(4, opt3.len_)
        eq_('\x00\x01\x00\x00', opt3.data)
        eq_(1, opt4.type_)
        eq_(0, opt4.len_)
        eq_(None, opt4.data)

    def test_len(self):
        eq_(16, len(self.hop))

    def test_default_args(self):
        hdr = ipv6.hop_opts()
        buf = hdr.serialize()
        res = struct.unpack('!BB', str(buf[:2]))

        eq_(res[0], 6)
        eq_(res[1], 0)
        opt = ipv6.option(type_=1, len_=6, data='\x00\x00\x00\x00\x00\x00')
        eq_(str(buf[2:]), opt.serialize())


class Test_dst_opts(unittest.TestCase):

    def setUp(self):
        self.nxt = 60
        self.size = 8
        self.data = [
            ipv6.option(5, 2, '\x00\x00'),
            ipv6.option(1, 0, None),
            ipv6.option(0xc2, 4, '\x00\x01\x00\x00'),
            ipv6.option(1, 0, None),
        ]
        self.dst = ipv6.dst_opts(self.nxt, self.size, self.data)
        self.form = '!BB'
        self.buf = struct.pack(self.form, self.nxt, self.size) \
            + self.data[0].serialize() \
            + self.data[1].serialize() \
            + self.data[2].serialize() \
            + self.data[3].serialize()

    def tearDown(self):
        pass

    def test_init(self):
        eq_(self.nxt, self.dst.nxt)
        eq_(self.size, self.dst.size)
        eq_(self.data, self.dst.data)

    @raises(Exception)
    def test_invalid_size(self):
        ipv6.dst_opts(self.nxt, 1, self.data)

    def test_parser(self):
        _res = ipv6.dst_opts.parser(self.buf)
        if type(_res) is tuple:
            res = _res[0]
        else:
            res = _res
        eq_(self.nxt, res.nxt)
        eq_(self.size, res.size)
        eq_(str(self.data), str(res.data))

    def test_serialize(self):
        buf = self.dst.serialize()
        res = struct.unpack_from(self.form, str(buf))
        eq_(self.nxt, res[0])
        eq_(self.size, res[1])
        offset = struct.calcsize(self.form)
        opt1 = ipv6.option.parser(str(buf[offset:]))
        offset += len(opt1)
        opt2 = ipv6.option.parser(str(buf[offset:]))
        offset += len(opt2)
        opt3 = ipv6.option.parser(str(buf[offset:]))
        offset += len(opt3)
        opt4 = ipv6.option.parser(str(buf[offset:]))
        eq_(5, opt1.type_)
        eq_(2, opt1.len_)
        eq_('\x00\x00', opt1.data)
        eq_(1, opt2.type_)
        eq_(0, opt2.len_)
        eq_(None, opt2.data)
        eq_(0xc2, opt3.type_)
        eq_(4, opt3.len_)
        eq_('\x00\x01\x00\x00', opt3.data)
        eq_(1, opt4.type_)
        eq_(0, opt4.len_)
        eq_(None, opt4.data)

    def test_len(self):
        eq_(16, len(self.dst))

    def test_default_args(self):
        hdr = ipv6.dst_opts()
        buf = hdr.serialize()
        res = struct.unpack('!BB', str(buf[:2]))

        eq_(res[0], 6)
        eq_(res[1], 0)
        opt = ipv6.option(type_=1, len_=6, data='\x00\x00\x00\x00\x00\x00')
        eq_(str(buf[2:]), opt.serialize())


class Test_option(unittest.TestCase):

    def setUp(self):
        self.type_ = 5
        self.data = '\x00\x00'
        self.len_ = len(self.data)
        self.opt = ipv6.option(self.type_, self.len_, self.data)
        self.form = '!BB%ds' % self.len_
        self.buf = struct.pack(self.form, self.type_, self.len_, self.data)

    def tearDown(self):
        pass

    def test_init(self):
        eq_(self.type_, self.opt.type_)
        eq_(self.len_, self.opt.len_)
        eq_(self.data, self.opt.data)

    def test_parser(self):
        _res = ipv6.option.parser(self.buf)
        if type(_res) is tuple:
            res = _res[0]
        else:
            res = _res
        eq_(self.type_, res.type_)
        eq_(self.len_, res.len_)
        eq_(self.data, res.data)

    def test_serialize(self):
        buf = self.opt.serialize()
        res = struct.unpack_from(self.form, buf)
        eq_(self.type_, res[0])
        eq_(self.len_, res[1])
        eq_(self.data, res[2])

    def test_len(self):
        eq_(len(self.opt), 2 + self.len_)


class Test_option_pad1(Test_option):

    def setUp(self):
        self.type_ = 0
        self.len_ = -1
        self.data = None
        self.opt = ipv6.option(self.type_, self.len_, self.data)
        self.form = '!B'
        self.buf = struct.pack(self.form, self.type_)

    def test_serialize(self):
        buf = self.opt.serialize()
        res = struct.unpack_from(self.form, buf)
        eq_(self.type_, res[0])

    def test_default_args(self):
        opt = ipv6.option()
        buf = opt.serialize()
        res = struct.unpack('!B', buf)

        eq_(res[0], 0)


class Test_option_padN(Test_option):

    def setUp(self):
        self.type_ = 1
        self.len_ = 0
        self.data = None
        self.opt = ipv6.option(self.type_, self.len_, self.data)
        self.form = '!BB'
        self.buf = struct.pack(self.form, self.type_, self.len_)

    def test_serialize(self):
        buf = self.opt.serialize()
        res = struct.unpack_from(self.form, buf)
        eq_(self.type_, res[0])
        eq_(self.len_, res[1])


class Test_fragment(unittest.TestCase):

    def setUp(self):
        self.nxt = 44
        self.offset = 50
        self.more = 1
        self.id_ = 123
        self.fragment = ipv6.fragment(
            self.nxt, self.offset, self.more, self.id_)

        self.off_m = (self.offset << 3 | self.more)
        self.form = '!BxHI'
        self.buf = struct.pack(self.form, self.nxt, self.off_m, self.id_)

    def test_init(self):
        eq_(self.nxt, self.fragment.nxt)
        eq_(self.offset, self.fragment.offset)
        eq_(self.more, self.fragment.more)
        eq_(self.id_, self.fragment.id_)

    def test_parser(self):
        _res = ipv6.fragment.parser(self.buf)
        if type(_res) is tuple:
            res = _res[0]
        else:
            res = _res
        eq_(self.nxt, res.nxt)
        eq_(self.offset, res.offset)
        eq_(self.more, res.more)
        eq_(self.id_, res.id_)

    def test_serialize(self):
        buf = self.fragment.serialize()
        res = struct.unpack_from(self.form, str(buf))
        eq_(self.nxt, res[0])
        eq_(self.off_m, res[1])
        eq_(self.id_, res[2])

    def test_len(self):
        eq_(8, len(self.fragment))

    def test_default_args(self):
        hdr = ipv6.fragment()
        buf = hdr.serialize()
        res = struct.unpack_from(ipv6.fragment._PACK_STR, buf)

        eq_(res[0], 6)
        eq_(res[1], 0)
        eq_(res[2], 0)


class Test_auth(unittest.TestCase):

    def setUp(self):
        self.nxt = 0
        self.size = 4
        self.spi = 256
        self.seq = 1
        self.data = '\x21\xd3\xa9\x5c\x5f\xfd\x4d\x18\x46\x22\xb9\xf8'
        self.auth = ipv6.auth(
            self.nxt, self.size, self.spi, self.seq, self.data)
        self.form = '!BB2xII12s'
        self.buf = struct.pack(self.form, self.nxt, self.size, self.spi,
                               self.seq, self.data)

    def test_init(self):
        eq_(self.nxt, self.auth.nxt)
        eq_(self.size, self.auth.size)
        eq_(self.spi, self.auth.spi)
        eq_(self.seq, self.auth.seq)
        eq_(self.data, self.auth.data)

    def test_parser(self):
        _res = ipv6.auth.parser(self.buf)
        if type(_res) is tuple:
            res = _res[0]
        else:
            res = _res
        eq_(self.nxt, res.nxt)
        eq_(self.size, res.size)
        eq_(self.spi, res.spi)
        eq_(self.seq, res.seq)
        eq_(self.data, res.data)

    def test_serialize(self):
        buf = self.auth.serialize()
        res = struct.unpack_from(self.form, str(buf))
        eq_(self.nxt, res[0])
        eq_(self.size, res[1])
        eq_(self.spi, res[2])
        eq_(self.seq, res[3])
        eq_(self.data, res[4])

    def test_len(self):
        eq_((4 - 1) * 8, len(self.auth))

    def test_default_args(self):
        hdr = ipv6.auth()
        buf = hdr.serialize()
        LOG.info(repr(buf))
        res = struct.unpack_from(ipv6.auth._PACK_STR, str(buf))
        LOG.info(res)

        eq_(res[0], 6)
        eq_(res[1], 3)
        eq_(res[2], 0)
        eq_(res[3], 0)
        eq_(buf[ipv6.auth._MIN_LEN:], '\x00\x00\x00\x00')

########NEW FILE########
__FILENAME__ = test_lldp
# Copyright (C) 2013 Nippon Telegraph and Telephone Corporation.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# vim: tabstop=4 shiftwidth=4 softtabstop=4

import unittest
import logging
import struct
import inspect
from nose.tools import ok_, eq_, nottest

from ryu.ofproto import ether
from ryu.lib.packet import packet
from ryu.lib.packet import ethernet
from ryu.lib.packet import lldp
from ryu.lib import addrconv

LOG = logging.getLogger(__name__)


class TestLLDPMandatoryTLV(unittest.TestCase):
    def setUp(self):
        # sample data is based on:
        # http://wiki.wireshark.org/LinkLayerDiscoveryProtocol
        #
        # mandatory TLV only
        self.data = '\x01\x80\xc2\x00\x00\x0e\x00\x04' \
                    + '\x96\x1f\xa7\x26\x88\xcc\x02\x07' \
                    + '\x04\x00\x04\x96\x1f\xa7\x26\x04' \
                    + '\x04\x05\x31\x2f\x33\x06\x02\x00' \
                    + '\x78\x00\x00'

    def tearDown(self):
        pass

    def test_get_tlv_type(self):
        buf = str(bytearray('\x02\x07\x04\x00\x04\x96\x1f\xa7\x26'))
        eq_(lldp.LLDPBasicTLV.get_type(buf), lldp.LLDP_TLV_CHASSIS_ID)

    def test_parse_without_ethernet(self):
        buf = self.data[ethernet.ethernet._MIN_LEN:]
        (lldp_pkt, cls, rest_buf) = lldp.lldp.parser(buf)
        eq_(len(rest_buf), 0)

        tlvs = lldp_pkt.tlvs
        eq_(tlvs[0].tlv_type, lldp.LLDP_TLV_CHASSIS_ID)
        eq_(tlvs[0].len, 7)
        eq_(tlvs[0].subtype, lldp.ChassisID.SUB_MAC_ADDRESS)
        eq_(tlvs[0].chassis_id, '\x00\x04\x96\x1f\xa7\x26')
        eq_(tlvs[1].tlv_type, lldp.LLDP_TLV_PORT_ID)
        eq_(tlvs[1].len, 4)
        eq_(tlvs[1].subtype, lldp.PortID.SUB_INTERFACE_NAME)
        eq_(tlvs[1].port_id, '1/3')
        eq_(tlvs[2].tlv_type, lldp.LLDP_TLV_TTL)
        eq_(tlvs[2].len, 2)
        eq_(tlvs[2].ttl, 120)
        eq_(tlvs[3].tlv_type, lldp.LLDP_TLV_END)

    def test_parse(self):
        buf = self.data
        pkt = packet.Packet(buf)

        eq_(type(pkt.next()), ethernet.ethernet)
        eq_(type(pkt.next()), lldp.lldp)

    def test_tlv(self):
        tlv = lldp.ChassisID(subtype=lldp.ChassisID.SUB_MAC_ADDRESS,
                             chassis_id='\x00\x04\x96\x1f\xa7\x26')
        eq_(tlv.tlv_type, lldp.LLDP_TLV_CHASSIS_ID)
        eq_(tlv.len, 7)
        (typelen, ) = struct.unpack('!H', '\x02\x07')
        eq_(tlv.typelen, typelen)

    def test_serialize_without_ethernet(self):
        tlv_chassis_id = lldp.ChassisID(subtype=lldp.ChassisID.SUB_MAC_ADDRESS,
                                        chassis_id='\x00\x04\x96\x1f\xa7\x26')
        tlv_port_id = lldp.PortID(subtype=lldp.PortID.SUB_INTERFACE_NAME,
                                  port_id='1/3')
        tlv_ttl = lldp.TTL(ttl=120)
        tlv_end = lldp.End()
        tlvs = (tlv_chassis_id, tlv_port_id, tlv_ttl, tlv_end)
        lldp_pkt = lldp.lldp(tlvs)

        eq_(lldp_pkt.serialize(None, None),
            self.data[ethernet.ethernet._MIN_LEN:])

    def test_serialize(self):
        pkt = packet.Packet()

        dst = lldp.LLDP_MAC_NEAREST_BRIDGE
        src = '00:04:96:1f:a7:26'
        ethertype = ether.ETH_TYPE_LLDP
        eth_pkt = ethernet.ethernet(dst, src, ethertype)
        pkt.add_protocol(eth_pkt)

        tlv_chassis_id = lldp.ChassisID(subtype=lldp.ChassisID.SUB_MAC_ADDRESS,
                                        chassis_id=addrconv.mac.
                                        text_to_bin(src))
        tlv_port_id = lldp.PortID(subtype=lldp.PortID.SUB_INTERFACE_NAME,
                                  port_id='1/3')
        tlv_ttl = lldp.TTL(ttl=120)
        tlv_end = lldp.End()
        tlvs = (tlv_chassis_id, tlv_port_id, tlv_ttl, tlv_end)
        lldp_pkt = lldp.lldp(tlvs)
        pkt.add_protocol(lldp_pkt)

        eq_(len(pkt.protocols), 2)

        pkt.serialize()
        eq_(pkt.data, self.data)

    def test_to_string(self):
        chassis_id = lldp.ChassisID(subtype=lldp.ChassisID.SUB_MAC_ADDRESS,
                                    chassis_id='\x00\x04\x96\x1f\xa7\x26')
        port_id = lldp.PortID(subtype=lldp.PortID.SUB_INTERFACE_NAME,
                              port_id='1/3')
        ttl = lldp.TTL(ttl=120)
        end = lldp.End()
        tlvs = (chassis_id, port_id, ttl, end)
        lldp_pkt = lldp.lldp(tlvs)

        chassis_id_values = {'subtype': lldp.ChassisID.SUB_MAC_ADDRESS,
                             'chassis_id': '\x00\x04\x96\x1f\xa7\x26',
                             'len': chassis_id.len,
                             'typelen': chassis_id.typelen}
        _ch_id_str = ','.join(['%s=%s' % (k, repr(chassis_id_values[k]))
                               for k, v in inspect.getmembers(chassis_id)
                               if k in chassis_id_values])
        tlv_chassis_id_str = '%s(%s)' % (lldp.ChassisID.__name__, _ch_id_str)

        port_id_values = {'subtype': port_id.subtype,
                          'port_id': port_id.port_id,
                          'len': port_id.len,
                          'typelen': port_id.typelen}
        _port_id_str = ','.join(['%s=%s' % (k, repr(port_id_values[k]))
                                 for k, v in inspect.getmembers(port_id)
                                 if k in port_id_values])
        tlv_port_id_str = '%s(%s)' % (lldp.PortID.__name__, _port_id_str)

        ttl_values = {'ttl': ttl.ttl,
                      'len': ttl.len,
                      'typelen': ttl.typelen}
        _ttl_str = ','.join(['%s=%s' % (k, repr(ttl_values[k]))
                             for k, v in inspect.getmembers(ttl)
                             if k in ttl_values])
        tlv_ttl_str = '%s(%s)' % (lldp.TTL.__name__, _ttl_str)

        end_values = {'len': end.len,
                      'typelen': end.typelen}
        _end_str = ','.join(['%s=%s' % (k, repr(end_values[k]))
                             for k, v in inspect.getmembers(end)
                             if k in end_values])
        tlv_end_str = '%s(%s)' % (lldp.End.__name__, _end_str)

        _tlvs_str = '(%s, %s, %s, %s)'
        tlvs_str = _tlvs_str % (tlv_chassis_id_str,
                                tlv_port_id_str,
                                tlv_ttl_str,
                                tlv_end_str)

        _lldp_str = '%s(tlvs=%s)'
        lldp_str = _lldp_str % (lldp.lldp.__name__,
                                tlvs_str)

        eq_(str(lldp_pkt), lldp_str)
        eq_(repr(lldp_pkt), lldp_str)


class TestLLDPOptionalTLV(unittest.TestCase):
    def setUp(self):
        # sample data is based on:
        # http://wiki.wireshark.org/LinkLayerDiscoveryProtocol
        #
        # include optional TLV
        self.data = '\x01\x80\xc2\x00\x00\x0e\x00\x01' \
                    + '\x30\xf9\xad\xa0\x88\xcc\x02\x07' \
                    + '\x04\x00\x01\x30\xf9\xad\xa0\x04' \
                    + '\x04\x05\x31\x2f\x31\x06\x02\x00' \
                    + '\x78\x08\x17\x53\x75\x6d\x6d\x69' \
                    + '\x74\x33\x30\x30\x2d\x34\x38\x2d' \
                    + '\x50\x6f\x72\x74\x20\x31\x30\x30' \
                    + '\x31\x00\x0a\x0d\x53\x75\x6d\x6d' \
                    + '\x69\x74\x33\x30\x30\x2d\x34\x38' \
                    + '\x00\x0c\x4c\x53\x75\x6d\x6d\x69' \
                    + '\x74\x33\x30\x30\x2d\x34\x38\x20' \
                    + '\x2d\x20\x56\x65\x72\x73\x69\x6f' \
                    + '\x6e\x20\x37\x2e\x34\x65\x2e\x31' \
                    + '\x20\x28\x42\x75\x69\x6c\x64\x20' \
                    + '\x35\x29\x20\x62\x79\x20\x52\x65' \
                    + '\x6c\x65\x61\x73\x65\x5f\x4d\x61' \
                    + '\x73\x74\x65\x72\x20\x30\x35\x2f' \
                    + '\x32\x37\x2f\x30\x35\x20\x30\x34' \
                    + '\x3a\x35\x33\x3a\x31\x31\x00\x0e' \
                    + '\x05\x01\x00\x14\x00\x14\x10\x0e' \
                    + '\x07' \
                    + '\x06\x00\x01\x30\xf9\xad\xa0\x02' \
                    + '\x00\x00\x03\xe9\x00\xfe\x07\x00' \
                    + '\x12\x0f\x02\x07\x01\x00\xfe\x09' \
                    + '\x00\x12\x0f\x01\x03\x6c\x00\x00' \
                    + '\x10\xfe\x09\x00\x12\x0f\x03\x01' \
                    + '\x00\x00\x00\x00\xfe\x06\x00\x12' \
                    + '\x0f\x04\x05\xf2\xfe\x06\x00\x80' \
                    + '\xc2\x01\x01\xe8\xfe\x07\x00\x80' \
                    + '\xc2\x02\x01\x00\x00\xfe\x17\x00' \
                    + '\x80\xc2\x03\x01\xe8\x10\x76\x32' \
                    + '\x2d\x30\x34\x38\x38\x2d\x30\x33' \
                    + '\x2d\x30\x35\x30\x35\x00\xfe\x05' \
                    + '\x00\x80\xc2\x04\x00\x00\x00'

    def tearDown(self):
        pass

    def test_parse(self):
        buf = self.data
        pkt = packet.Packet(buf)

        eq_(type(pkt.next()), ethernet.ethernet)
        lldp_pkt = pkt.next()
        eq_(type(lldp_pkt), lldp.lldp)

        tlvs = lldp_pkt.tlvs

        # Port Description
        eq_(tlvs[3].tlv_type, lldp.LLDP_TLV_PORT_DESCRIPTION)
        eq_(tlvs[3].port_description, 'Summit300-48-Port 1001\x00')

        # System Name
        eq_(tlvs[4].tlv_type, lldp.LLDP_TLV_SYSTEM_NAME)
        eq_(tlvs[4].system_name, 'Summit300-48\x00')

        # System Description

        eq_(tlvs[5].tlv_type, lldp.LLDP_TLV_SYSTEM_DESCRIPTION)
        eq_(tlvs[5].system_description,
            'Summit300-48 - Version 7.4e.1 (Build 5) '
            + 'by Release_Master 05/27/05 04:53:11\x00')

        # SystemCapabilities
        eq_(tlvs[6].tlv_type, lldp.LLDP_TLV_SYSTEM_CAPABILITIES)
        eq_(tlvs[6].subtype, lldp.ChassisID.SUB_CHASSIS_COMPONENT)
        eq_(tlvs[6].system_cap & lldp.SystemCapabilities.CAP_MAC_BRIDGE,
            lldp.SystemCapabilities.CAP_MAC_BRIDGE)
        eq_(tlvs[6].enabled_cap & lldp.SystemCapabilities.CAP_MAC_BRIDGE,
            lldp.SystemCapabilities.CAP_MAC_BRIDGE)
        eq_(tlvs[6].system_cap & lldp.SystemCapabilities.CAP_TELEPHONE, 0)
        eq_(tlvs[6].enabled_cap & lldp.SystemCapabilities.CAP_TELEPHONE, 0)

        # Management Address
        eq_(tlvs[7].tlv_type, lldp.LLDP_TLV_MANAGEMENT_ADDRESS)
        eq_(tlvs[7].addr_len, 7)
        eq_(tlvs[7].addr, '\x00\x01\x30\xf9\xad\xa0')
        eq_(tlvs[7].intf_num, 1001)

        # Organizationally Specific
        eq_(tlvs[8].tlv_type, lldp.LLDP_TLV_ORGANIZATIONALLY_SPECIFIC)
        eq_(tlvs[8].oui, '\x00\x12\x0f')  # IEEE 802.3
        eq_(tlvs[8].subtype, 0x02)  # Power Via MDI

        # End
        eq_(tlvs[16].tlv_type, lldp.LLDP_TLV_END)

    def test_serialize(self):
        pkt = packet.Packet()

        dst = lldp.LLDP_MAC_NEAREST_BRIDGE
        src = '00:01:30:f9:ad:a0'
        ethertype = ether.ETH_TYPE_LLDP
        eth_pkt = ethernet.ethernet(dst, src, ethertype)
        pkt.add_protocol(eth_pkt)

        tlv_chassis_id = lldp.ChassisID(subtype=lldp.ChassisID.SUB_MAC_ADDRESS,
                                        chassis_id=addrconv.mac.
                                        text_to_bin(src))
        tlv_port_id = lldp.PortID(subtype=lldp.PortID.SUB_INTERFACE_NAME,
                                  port_id='1/1')
        tlv_ttl = lldp.TTL(ttl=120)
        tlv_port_description = lldp.PortDescription(
            port_description='Summit300-48-Port 1001\x00')
        tlv_system_name = lldp.SystemName(system_name='Summit300-48\x00')
        tlv_system_description = lldp.SystemDescription(
            system_description='Summit300-48 - Version 7.4e.1 (Build 5) '
                               + 'by Release_Master 05/27/05 04:53:11\x00')
        tlv_system_capabilities = lldp.SystemCapabilities(
            subtype=lldp.ChassisID.SUB_CHASSIS_COMPONENT,
            system_cap=0x14,
            enabled_cap=0x14)
        tlv_management_address = lldp.ManagementAddress(
            addr_subtype=0x06, addr='\x00\x01\x30\xf9\xad\xa0',
            intf_subtype=0x02, intf_num=1001,
            oid='')
        tlv_organizationally_specific = lldp.OrganizationallySpecific(
            oui='\x00\x12\x0f', subtype=0x02, info='\x07\x01\x00')
        tlv_end = lldp.End()
        tlvs = (tlv_chassis_id, tlv_port_id, tlv_ttl, tlv_port_description,
                tlv_system_name, tlv_system_description,
                tlv_system_capabilities, tlv_management_address,
                tlv_organizationally_specific, tlv_end)
        lldp_pkt = lldp.lldp(tlvs)
        pkt.add_protocol(lldp_pkt)

        eq_(len(pkt.protocols), 2)

        pkt.serialize()

        # self.data has many organizationally specific TLVs
        data = str(pkt.data[:-2])
        eq_(data, self.data[:len(data)])

    def test_to_string(self):
        chassis_id = lldp.ChassisID(subtype=lldp.ChassisID.SUB_MAC_ADDRESS,
                                    chassis_id='\x00\x01\x30\xf9\xad\xa0')
        port_id = lldp.PortID(subtype=lldp.PortID.SUB_INTERFACE_NAME,
                              port_id='1/1')
        ttl = lldp.TTL(ttl=120)
        port_desc = lldp.PortDescription(
            port_description='Summit300-48-Port 1001\x00')
        sys_name = lldp.SystemName(system_name='Summit300-48\x00')
        sys_desc = lldp.SystemDescription(
            system_description='Summit300-48 - Version 7.4e.1 (Build 5) '
                               + 'by Release_Master 05/27/05 04:53:11\x00')
        sys_cap = lldp.SystemCapabilities(
            subtype=lldp.ChassisID.SUB_CHASSIS_COMPONENT,
            system_cap=0x14,
            enabled_cap=0x14)
        man_addr = lldp.ManagementAddress(
            addr_subtype=0x06, addr='\x00\x01\x30\xf9\xad\xa0',
            intf_subtype=0x02, intf_num=1001,
            oid='')
        org_spec = lldp.OrganizationallySpecific(
            oui='\x00\x12\x0f', subtype=0x02, info='\x07\x01\x00')
        end = lldp.End()
        tlvs = (chassis_id, port_id, ttl, port_desc, sys_name,
                sys_desc, sys_cap, man_addr, org_spec, end)
        lldp_pkt = lldp.lldp(tlvs)

        # ChassisID string
        chassis_id_values = {'subtype': lldp.ChassisID.SUB_MAC_ADDRESS,
                             'chassis_id': '\x00\x01\x30\xf9\xad\xa0',
                             'len': chassis_id.len,
                             'typelen': chassis_id.typelen}
        _ch_id_str = ','.join(['%s=%s' % (k, repr(chassis_id_values[k]))
                               for k, v in inspect.getmembers(chassis_id)
                               if k in chassis_id_values])
        tlv_chassis_id_str = '%s(%s)' % (lldp.ChassisID.__name__, _ch_id_str)

        # PortID string
        port_id_values = {'subtype': port_id.subtype,
                          'port_id': port_id.port_id,
                          'len': port_id.len,
                          'typelen': port_id.typelen}
        _port_id_str = ','.join(['%s=%s' % (k, repr(port_id_values[k]))
                                 for k, v in inspect.getmembers(port_id)
                                 if k in port_id_values])
        tlv_port_id_str = '%s(%s)' % (lldp.PortID.__name__, _port_id_str)

        # TTL string
        ttl_values = {'ttl': ttl.ttl,
                      'len': ttl.len,
                      'typelen': ttl.typelen}
        _ttl_str = ','.join(['%s=%s' % (k, repr(ttl_values[k]))
                             for k, v in inspect.getmembers(ttl)
                             if k in ttl_values])
        tlv_ttl_str = '%s(%s)' % (lldp.TTL.__name__, _ttl_str)

        # PortDescription string
        port_desc_values = {'tlv_info': port_desc.tlv_info,
                            'len': port_desc.len,
                            'typelen': port_desc.typelen}
        _port_desc_str = ','.join(['%s=%s' % (k, repr(port_desc_values[k]))
                                   for k, v in inspect.getmembers(port_desc)
                                   if k in port_desc_values])
        tlv_port_desc_str = '%s(%s)' % (lldp.PortDescription.__name__,
                                        _port_desc_str)

        # SystemName string
        sys_name_values = {'tlv_info': sys_name.tlv_info,
                           'len': sys_name.len,
                           'typelen': sys_name.typelen}
        _system_name_str = ','.join(['%s=%s' % (k, repr(sys_name_values[k]))
                                     for k, v in inspect.getmembers(sys_name)
                                     if k in sys_name_values])
        tlv_system_name_str = '%s(%s)' % (lldp.SystemName.__name__,
                                          _system_name_str)

        # SystemDescription string
        sys_desc_values = {'tlv_info': sys_desc.tlv_info,
                           'len': sys_desc.len,
                           'typelen': sys_desc.typelen}
        _sys_desc_str = ','.join(['%s=%s' % (k, repr(sys_desc_values[k]))
                                  for k, v in inspect.getmembers(sys_desc)
                                  if k in sys_desc_values])
        tlv_sys_desc_str = '%s(%s)' % (lldp.SystemDescription.__name__,
                                       _sys_desc_str)

        # SystemCapabilities string
        sys_cap_values = {'subtype': lldp.ChassisID.SUB_CHASSIS_COMPONENT,
                          'system_cap': 0x14,
                          'enabled_cap': 0x14,
                          'len': sys_cap.len,
                          'typelen': sys_cap.typelen}
        _sys_cap_str = ','.join(['%s=%s' % (k, repr(sys_cap_values[k]))
                                 for k, v in inspect.getmembers(sys_cap)
                                 if k in sys_cap_values])
        tlv_sys_cap_str = '%s(%s)' % (lldp.SystemCapabilities.__name__,
                                      _sys_cap_str)

        # ManagementAddress string
        man_addr_values = {'addr_subtype': 0x06,
                           'addr': '\x00\x01\x30\xf9\xad\xa0',
                           'addr_len': man_addr.addr_len,
                           'intf_subtype': 0x02,
                           'intf_num': 1001,
                           'oid': '',
                           'oid_len': man_addr.oid_len,
                           'len': man_addr.len,
                           'typelen': man_addr.typelen}
        _man_addr_str = ','.join(['%s=%s' % (k, repr(man_addr_values[k]))
                                  for k, v in inspect.getmembers(man_addr)
                                  if k in man_addr_values])
        tlv_man_addr_str = '%s(%s)' % (lldp.ManagementAddress.__name__,
                                       _man_addr_str)

        # OrganizationallySpecific string
        org_spec_values = {'oui': '\x00\x12\x0f',
                           'subtype': 0x02,
                           'info': '\x07\x01\x00',
                           'len': org_spec.len,
                           'typelen': org_spec.typelen}
        _org_spec_str = ','.join(['%s=%s' % (k, repr(org_spec_values[k]))
                                  for k, v in inspect.getmembers(org_spec)
                                  if k in org_spec_values])
        tlv_org_spec_str = '%s(%s)' % (lldp.OrganizationallySpecific.__name__,
                                       _org_spec_str)

        # End string
        end_values = {'len': end.len,
                      'typelen': end.typelen}
        _end_str = ','.join(['%s=%s' % (k, repr(end_values[k]))
                             for k, v in inspect.getmembers(end)
                             if k in end_values])
        tlv_end_str = '%s(%s)' % (lldp.End.__name__, _end_str)

        # tlvs string
        _tlvs_str = '(%s, %s, %s, %s, %s, %s, %s, %s, %s, %s)'
        tlvs_str = _tlvs_str % (tlv_chassis_id_str,
                                tlv_port_id_str,
                                tlv_ttl_str,
                                tlv_port_desc_str,
                                tlv_system_name_str,
                                tlv_sys_desc_str,
                                tlv_sys_cap_str,
                                tlv_man_addr_str,
                                tlv_org_spec_str,
                                tlv_end_str)

        # lldp string
        _lldp_str = '%s(tlvs=%s)'
        lldp_str = _lldp_str % (lldp.lldp.__name__,
                                tlvs_str)

        eq_(str(lldp_pkt), lldp_str)
        eq_(repr(lldp_pkt), lldp_str)

########NEW FILE########
__FILENAME__ = test_mpls
# Copyright (C) 2013 Nippon Telegraph and Telephone Corporation.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.


import unittest
import logging
import inspect

from nose.tools import *
from nose.plugins.skip import Skip, SkipTest
from ryu.lib.packet import mpls


LOG = logging.getLogger(__name__)


class Test_mpls(unittest.TestCase):

    label = 29
    exp = 6
    bsb = 1
    ttl = 64
    mp = mpls.mpls(label, exp, bsb, ttl)

    def setUp(self):
        pass

    def tearDown(self):
        pass

    def test_to_string(self):
        mpls_values = {'label': self.label,
                       'exp': self.exp,
                       'bsb': self.bsb,
                       'ttl': self.ttl}
        _mpls_str = ','.join(['%s=%s' % (k, repr(mpls_values[k]))
                              for k, v in inspect.getmembers(self.mp)
                              if k in mpls_values])
        mpls_str = '%s(%s)' % (mpls.mpls.__name__, _mpls_str)

        eq_(str(self.mp), mpls_str)
        eq_(repr(self.mp), mpls_str)

########NEW FILE########
__FILENAME__ = test_packet
# Copyright (C) 2012 Nippon Telegraph and Telephone Corporation.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# vim: tabstop=4 shiftwidth=4 softtabstop=4

import unittest
import logging
import struct
import array
import inspect
from nose.tools import *
from nose.plugins.skip import Skip, SkipTest
from ryu.ofproto import ether, inet
from ryu.lib.packet import *
from ryu.lib import addrconv


LOG = logging.getLogger('test_packet')


class TestPacket(unittest.TestCase):
    """ Test case for packet
    """

    dst_mac = 'aa:aa:aa:aa:aa:aa'
    src_mac = 'bb:bb:bb:bb:bb:bb'
    dst_mac_bin = addrconv.mac.text_to_bin(dst_mac)
    src_mac_bin = addrconv.mac.text_to_bin(src_mac)
    dst_ip = '192.168.128.10'
    src_ip = '192.168.122.20'
    dst_ip_bin = addrconv.ipv4.text_to_bin(dst_ip)
    src_port = 50001
    dst_port = 50002
    src_ip_bin = addrconv.ipv4.text_to_bin(src_ip)
    payload = '\x06\x06\x47\x50\x00\x00\x00\x00' \
        + '\xcd\xc5\x00\x00\x00\x00\x00\x00' \
        + '\x10\x11\x12\x13\x14\x15\x16\x17' \
        + '\x18\x19\x1a\x1b\x1c\x1d\x1e\x1f'

    def get_protocols(self, pkt):
        protocols = {}
        for p in pkt:
            if hasattr(p, 'protocol_name'):
                protocols[p.protocol_name] = p
            else:
                protocols['payload'] = p
        return protocols

    def setUp(self):
        pass

    def tearDown(self):
        pass

    def test_arp(self):
        # buid packet
        e = ethernet.ethernet(self.dst_mac, self.src_mac,
                              ether.ETH_TYPE_ARP)
        a = arp.arp(1, ether.ETH_TYPE_IP, 6, 4, 2,
                    self.src_mac, self.src_ip, self.dst_mac,
                    self.dst_ip)
        p = packet.Packet()
        p.add_protocol(e)
        p.add_protocol(a)
        p.serialize()

        # ethernet !6s6sH
        e_buf = self.dst_mac_bin \
            + self.src_mac_bin \
            + '\x08\x06'

        # arp !HHBBH6sI6sI
        a_buf = '\x00\x01' \
            + '\x08\x00' \
            + '\x06' \
            + '\x04' \
            + '\x00\x02' \
            + self.src_mac_bin \
            + self.src_ip_bin \
            + self.dst_mac_bin \
            + self.dst_ip_bin

        buf = e_buf + a_buf
        eq_(buf, p.data)

        # parse
        pkt = packet.Packet(array.array('B', p.data))
        protocols = self.get_protocols(pkt)
        p_eth = protocols['ethernet']
        p_arp = protocols['arp']

        # ethernet
        ok_(p_eth)
        eq_(self.dst_mac, p_eth.dst)
        eq_(self.src_mac, p_eth.src)
        eq_(ether.ETH_TYPE_ARP, p_eth.ethertype)

        # arp
        ok_(p_arp)
        eq_(1, p_arp.hwtype)
        eq_(ether.ETH_TYPE_IP, p_arp.proto)
        eq_(6, p_arp.hlen)
        eq_(4, p_arp.plen)
        eq_(2, p_arp.opcode)
        eq_(self.src_mac, p_arp.src_mac)
        eq_(self.src_ip, p_arp.src_ip)
        eq_(self.dst_mac, p_arp.dst_mac)
        eq_(self.dst_ip, p_arp.dst_ip)

        # to string
        eth_values = {'dst': self.dst_mac,
                      'src': self.src_mac,
                      'ethertype': ether.ETH_TYPE_ARP}
        _eth_str = ','.join(['%s=%s' % (k, repr(eth_values[k]))
                             for k, v in inspect.getmembers(p_eth)
                             if k in eth_values])
        eth_str = '%s(%s)' % (ethernet.ethernet.__name__, _eth_str)

        arp_values = {'hwtype': 1,
                      'proto': ether.ETH_TYPE_IP,
                      'hlen': 6,
                      'plen': 4,
                      'opcode': 2,
                      'src_mac': self.src_mac,
                      'dst_mac': self.dst_mac,
                      'src_ip': self.src_ip,
                      'dst_ip': self.dst_ip}
        _arp_str = ','.join(['%s=%s' % (k, repr(arp_values[k]))
                             for k, v in inspect.getmembers(p_arp)
                             if k in arp_values])
        arp_str = '%s(%s)' % (arp.arp.__name__, _arp_str)

        pkt_str = '%s, %s' % (eth_str, arp_str)

        eq_(eth_str, str(p_eth))
        eq_(eth_str, repr(p_eth))

        eq_(arp_str, str(p_arp))
        eq_(arp_str, repr(p_arp))

        eq_(pkt_str, str(pkt))
        eq_(pkt_str, repr(pkt))

    def test_vlan_arp(self):
        # buid packet
        e = ethernet.ethernet(self.dst_mac, self.src_mac,
                              ether.ETH_TYPE_8021Q)
        v = vlan.vlan(0b111, 0b1, 3, ether.ETH_TYPE_ARP)
        a = arp.arp(1, ether.ETH_TYPE_IP, 6, 4, 2,
                    self.src_mac, self.src_ip, self.dst_mac,
                    self.dst_ip)
        p = packet.Packet()
        p.add_protocol(e)
        p.add_protocol(v)
        p.add_protocol(a)
        p.serialize()

        # ethernet !6s6sH
        e_buf = self.dst_mac_bin \
            + self.src_mac_bin \
            + '\x81\x00'

        # vlan !HH
        v_buf = '\xF0\x03' \
            + '\x08\x06'

        # arp !HHBBH6sI6sI
        a_buf = '\x00\x01' \
            + '\x08\x00' \
            + '\x06' \
            + '\x04' \
            + '\x00\x02' \
            + self.src_mac_bin \
            + self.src_ip_bin \
            + self.dst_mac_bin \
            + self.dst_ip_bin

        buf = e_buf + v_buf + a_buf
        eq_(buf, p.data)

        # parse
        pkt = packet.Packet(array.array('B', p.data))
        protocols = self.get_protocols(pkt)
        p_eth = protocols['ethernet']
        p_vlan = protocols['vlan']
        p_arp = protocols['arp']

        # ethernet
        ok_(p_eth)
        eq_(self.dst_mac, p_eth.dst)
        eq_(self.src_mac, p_eth.src)
        eq_(ether.ETH_TYPE_8021Q, p_eth.ethertype)

        # vlan
        ok_(p_vlan)
        eq_(0b111, p_vlan.pcp)
        eq_(0b1, p_vlan.cfi)
        eq_(3, p_vlan.vid)
        eq_(ether.ETH_TYPE_ARP, p_vlan.ethertype)

        # arp
        ok_(p_arp)
        eq_(1, p_arp.hwtype)
        eq_(ether.ETH_TYPE_IP, p_arp.proto)
        eq_(6, p_arp.hlen)
        eq_(4, p_arp.plen)
        eq_(2, p_arp.opcode)
        eq_(self.src_mac, p_arp.src_mac)
        eq_(self.src_ip, p_arp.src_ip)
        eq_(self.dst_mac, p_arp.dst_mac)
        eq_(self.dst_ip, p_arp.dst_ip)

        # to string
        eth_values = {'dst': self.dst_mac,
                      'src': self.src_mac,
                      'ethertype': ether.ETH_TYPE_8021Q}
        _eth_str = ','.join(['%s=%s' % (k, repr(eth_values[k]))
                             for k, v in inspect.getmembers(p_eth)
                             if k in eth_values])
        eth_str = '%s(%s)' % (ethernet.ethernet.__name__, _eth_str)

        vlan_values = {'pcp': 0b111,
                       'cfi': 0b1,
                       'vid': 3,
                       'ethertype': ether.ETH_TYPE_ARP}
        _vlan_str = ','.join(['%s=%s' % (k, repr(vlan_values[k]))
                             for k, v in inspect.getmembers(p_vlan)
                             if k in vlan_values])
        vlan_str = '%s(%s)' % (vlan.vlan.__name__, _vlan_str)

        arp_values = {'hwtype': 1,
                      'proto': ether.ETH_TYPE_IP,
                      'hlen': 6,
                      'plen': 4,
                      'opcode': 2,
                      'src_mac': self.src_mac,
                      'dst_mac': self.dst_mac,
                      'src_ip': self.src_ip,
                      'dst_ip': self.dst_ip}
        _arp_str = ','.join(['%s=%s' % (k, repr(arp_values[k]))
                             for k, v in inspect.getmembers(p_arp)
                             if k in arp_values])
        arp_str = '%s(%s)' % (arp.arp.__name__, _arp_str)

        pkt_str = '%s, %s, %s' % (eth_str, vlan_str, arp_str)

        eq_(eth_str, str(p_eth))
        eq_(eth_str, repr(p_eth))

        eq_(vlan_str, str(p_vlan))
        eq_(vlan_str, repr(p_vlan))

        eq_(arp_str, str(p_arp))
        eq_(arp_str, repr(p_arp))

        eq_(pkt_str, str(pkt))
        eq_(pkt_str, repr(pkt))

    def test_ipv4_udp(self):
        # buid packet
        e = ethernet.ethernet(self.dst_mac, self.src_mac,
                              ether.ETH_TYPE_IP)
        ip = ipv4.ipv4(4, 5, 1, 0, 3, 1, 4, 64, inet.IPPROTO_UDP, 0,
                       self.src_ip, self.dst_ip)
        u = udp.udp(0x190F, 0x1F90, 0, 0)

        p = packet.Packet()
        p.add_protocol(e)
        p.add_protocol(ip)
        p.add_protocol(u)
        p.add_protocol(self.payload)
        p.serialize()

        # ethernet !6s6sH
        e_buf = self.dst_mac_bin \
            + self.src_mac_bin \
            + '\x08\x00'

        # ipv4 !BBHHHBBHII
        ip_buf = '\x45' \
            + '\x01' \
            + '\x00\x3C' \
            + '\x00\x03' \
            + '\x20\x04' \
            + '\x40' \
            + '\x11' \
            + '\x00\x00' \
            + self.src_ip_bin \
            + self.dst_ip_bin

        # udp !HHHH
        u_buf = '\x19\x0F' \
            + '\x1F\x90' \
            + '\x00\x28' \
            + '\x00\x00'

        buf = e_buf + ip_buf + u_buf + self.payload

        # parse
        pkt = packet.Packet(array.array('B', p.data))
        protocols = self.get_protocols(pkt)
        p_eth = protocols['ethernet']
        p_ipv4 = protocols['ipv4']
        p_udp = protocols['udp']

        # ethernet
        ok_(p_eth)
        eq_(self.dst_mac, p_eth.dst)
        eq_(self.src_mac, p_eth.src)
        eq_(ether.ETH_TYPE_IP, p_eth.ethertype)

        # ipv4
        ok_(p_ipv4)
        eq_(4, p_ipv4.version)
        eq_(5, p_ipv4.header_length)
        eq_(1, p_ipv4.tos)
        l = len(ip_buf) + len(u_buf) + len(self.payload)
        eq_(l, p_ipv4.total_length)
        eq_(3, p_ipv4.identification)
        eq_(1, p_ipv4.flags)
        eq_(64, p_ipv4.ttl)
        eq_(inet.IPPROTO_UDP, p_ipv4.proto)
        eq_(self.src_ip, p_ipv4.src)
        eq_(self.dst_ip, p_ipv4.dst)
        t = bytearray(ip_buf)
        struct.pack_into('!H', t, 10, p_ipv4.csum)
        eq_(packet_utils.checksum(t), 0)

        # udp
        ok_(p_udp)
        eq_(0x190f, p_udp.src_port)
        eq_(0x1F90, p_udp.dst_port)
        eq_(len(u_buf) + len(self.payload), p_udp.total_length)
        eq_(0x77b2, p_udp.csum)
        t = bytearray(u_buf)
        struct.pack_into('!H', t, 6, p_udp.csum)
        ph = struct.pack('!4s4sBBH', self.src_ip_bin, self.dst_ip_bin, 0,
                         17, len(u_buf) + len(self.payload))
        t = ph + t + self.payload
        eq_(packet_utils.checksum(t), 0)

        # payload
        ok_('payload' in protocols)
        eq_(self.payload, protocols['payload'].tostring())

        # to string
        eth_values = {'dst': self.dst_mac,
                      'src': self.src_mac,
                      'ethertype': ether.ETH_TYPE_IP}
        _eth_str = ','.join(['%s=%s' % (k, repr(eth_values[k]))
                             for k, v in inspect.getmembers(p_eth)
                             if k in eth_values])
        eth_str = '%s(%s)' % (ethernet.ethernet.__name__, _eth_str)

        ipv4_values = {'version': 4,
                       'header_length': 5,
                       'tos': 1,
                       'total_length': l,
                       'identification': 3,
                       'flags': 1,
                       'offset': p_ipv4.offset,
                       'ttl': 64,
                       'proto': inet.IPPROTO_UDP,
                       'csum': p_ipv4.csum,
                       'src': self.src_ip,
                       'dst': self.dst_ip,
                       'option': None}
        _ipv4_str = ','.join(['%s=%s' % (k, repr(ipv4_values[k]))
                              for k, v in inspect.getmembers(p_ipv4)
                              if k in ipv4_values])
        ipv4_str = '%s(%s)' % (ipv4.ipv4.__name__, _ipv4_str)

        udp_values = {'src_port': 0x190f,
                      'dst_port': 0x1F90,
                      'total_length': len(u_buf) + len(self.payload),
                      'csum': 0x77b2}
        _udp_str = ','.join(['%s=%s' % (k, repr(udp_values[k]))
                             for k, v in inspect.getmembers(p_udp)
                             if k in udp_values])
        udp_str = '%s(%s)' % (udp.udp.__name__, _udp_str)

        pkt_str = '%s, %s, %s, %s' % (eth_str, ipv4_str, udp_str,
                                      repr(protocols['payload']))

        eq_(eth_str, str(p_eth))
        eq_(eth_str, repr(p_eth))

        eq_(ipv4_str, str(p_ipv4))
        eq_(ipv4_str, repr(p_ipv4))

        eq_(udp_str, str(p_udp))
        eq_(udp_str, repr(p_udp))

        eq_(pkt_str, str(pkt))
        eq_(pkt_str, repr(pkt))

    def test_ipv4_tcp(self):
        # buid packet
        e = ethernet.ethernet(self.dst_mac, self.src_mac,
                              ether.ETH_TYPE_IP)
        ip = ipv4.ipv4(4, 5, 0, 0, 0, 0, 0, 64, inet.IPPROTO_TCP, 0,
                       self.src_ip, self.dst_ip)
        t = tcp.tcp(0x190F, 0x1F90, 0x123, 1, 6, 0b101010, 2048, 0, 0x6f,
                    '\x01\x02')

        p = packet.Packet()
        p.add_protocol(e)
        p.add_protocol(ip)
        p.add_protocol(t)
        p.add_protocol(self.payload)
        p.serialize()

        # ethernet !6s6sH
        e_buf = self.dst_mac_bin \
            + self.src_mac_bin \
            + '\x08\x00'

        # ipv4 !BBHHHBBHII
        ip_buf = '\x45' \
            + '\x00' \
            + '\x00\x4C' \
            + '\x00\x00' \
            + '\x00\x00' \
            + '\x40' \
            + '\x06' \
            + '\x00\x00' \
            + self.src_ip_bin \
            + self.dst_ip_bin

        # tcp !HHIIBBHHH + option
        t_buf = '\x19\x0F' \
            + '\x1F\x90' \
            + '\x00\x00\x01\x23' \
            + '\x00\x00\x00\x01' \
            + '\x60' \
            + '\x2A' \
            + '\x08\x00' \
            + '\x00\x00' \
            + '\x00\x6F' \
            + '\x01\x02\x00\x00'

        buf = e_buf + ip_buf + t_buf + self.payload

        # parse
        pkt = packet.Packet(array.array('B', p.data))
        protocols = self.get_protocols(pkt)
        p_eth = protocols['ethernet']
        p_ipv4 = protocols['ipv4']
        p_tcp = protocols['tcp']

        # ethernet
        ok_(p_eth)
        eq_(self.dst_mac, p_eth.dst)
        eq_(self.src_mac, p_eth.src)
        eq_(ether.ETH_TYPE_IP, p_eth.ethertype)

        # ipv4
        ok_(p_ipv4)
        eq_(4, p_ipv4.version)
        eq_(5, p_ipv4.header_length)
        eq_(0, p_ipv4.tos)
        l = len(ip_buf) + len(t_buf) + len(self.payload)
        eq_(l, p_ipv4.total_length)
        eq_(0, p_ipv4.identification)
        eq_(0, p_ipv4.flags)
        eq_(64, p_ipv4.ttl)
        eq_(inet.IPPROTO_TCP, p_ipv4.proto)
        eq_(self.src_ip, p_ipv4.src)
        eq_(self.dst_ip, p_ipv4.dst)
        t = bytearray(ip_buf)
        struct.pack_into('!H', t, 10, p_ipv4.csum)
        eq_(packet_utils.checksum(t), 0)

        # tcp
        ok_(p_tcp)
        eq_(0x190f, p_tcp.src_port)
        eq_(0x1F90, p_tcp.dst_port)
        eq_(0x123, p_tcp.seq)
        eq_(1, p_tcp.ack)
        eq_(6, p_tcp.offset)
        eq_(0b101010, p_tcp.bits)
        eq_(2048, p_tcp.window_size)
        eq_(0x6f, p_tcp.urgent)
        eq_(len(t_buf), len(p_tcp))
        t = bytearray(t_buf)
        struct.pack_into('!H', t, 16, p_tcp.csum)
        ph = struct.pack('!4s4sBBH', self.src_ip_bin, self.dst_ip_bin, 0,
                         6, len(t_buf) + len(self.payload))
        t = ph + t + self.payload
        eq_(packet_utils.checksum(t), 0)

        # payload
        ok_('payload' in protocols)
        eq_(self.payload, protocols['payload'].tostring())

        # to string
        eth_values = {'dst': self.dst_mac,
                      'src': self.src_mac,
                      'ethertype': ether.ETH_TYPE_IP}
        _eth_str = ','.join(['%s=%s' % (k, repr(eth_values[k]))
                             for k, v in inspect.getmembers(p_eth)
                             if k in eth_values])
        eth_str = '%s(%s)' % (ethernet.ethernet.__name__, _eth_str)

        ipv4_values = {'version': 4,
                       'header_length': 5,
                       'tos': 0,
                       'total_length': l,
                       'identification': 0,
                       'flags': 0,
                       'offset': p_ipv4.offset,
                       'ttl': 64,
                       'proto': inet.IPPROTO_TCP,
                       'csum': p_ipv4.csum,
                       'src': self.src_ip,
                       'dst': self.dst_ip,
                       'option': None}
        _ipv4_str = ','.join(['%s=%s' % (k, repr(ipv4_values[k]))
                              for k, v in inspect.getmembers(p_ipv4)
                              if k in ipv4_values])
        ipv4_str = '%s(%s)' % (ipv4.ipv4.__name__, _ipv4_str)

        tcp_values = {'src_port': 0x190f,
                      'dst_port': 0x1F90,
                      'seq': 0x123,
                      'ack': 1,
                      'offset': 6,
                      'bits': 0b101010,
                      'window_size': 2048,
                      'csum': p_tcp.csum,
                      'urgent': 0x6f,
                      'option': p_tcp.option}
        _tcp_str = ','.join(['%s=%s' % (k, repr(tcp_values[k]))
                             for k, v in inspect.getmembers(p_tcp)
                             if k in tcp_values])
        tcp_str = '%s(%s)' % (tcp.tcp.__name__, _tcp_str)

        pkt_str = '%s, %s, %s, %s' % (eth_str, ipv4_str, tcp_str,
                                      repr(protocols['payload']))

        eq_(eth_str, str(p_eth))
        eq_(eth_str, repr(p_eth))

        eq_(ipv4_str, str(p_ipv4))
        eq_(ipv4_str, repr(p_ipv4))

        eq_(tcp_str, str(p_tcp))
        eq_(tcp_str, repr(p_tcp))

        eq_(pkt_str, str(pkt))
        eq_(pkt_str, repr(pkt))

    def test_ipv4_sctp(self):
        # build packet
        e = ethernet.ethernet()
        ip = ipv4.ipv4(proto=inet.IPPROTO_SCTP)
        s = sctp.sctp(chunks=[sctp.chunk_data(payload_data=self.payload)])

        p = e/ip/s
        p.serialize()

        ipaddr = addrconv.ipv4.text_to_bin('0.0.0.0')

        # ethernet !6s6sH
        e_buf = '\xff\xff\xff\xff\xff\xff' \
            + '\x00\x00\x00\x00\x00\x00' \
            + '\x08\x00'

        # ipv4 !BBHHHBBHII
        ip_buf = '\x45' \
            + '\x00' \
            + '\x00\x50' \
            + '\x00\x00' \
            + '\x00\x00' \
            + '\xff' \
            + '\x84' \
            + '\x00\x00' \
            + ipaddr \
            + ipaddr

        # sctp !HHII + chunk_data !BBHIHHI + payload
        s_buf = '\x00\x00' \
            + '\x00\x00' \
            + '\x00\x00\x00\x00' \
            + '\x00\x00\x00\x00' \
            + '\x00' \
            + '\x00' \
            + '\x00\x00' \
            + '\x00\x00\x00\x00' \
            + '\x00\x00' \
            + '\x00\x00' \
            + '\x00\x00\x00\x00' \
            + self.payload

        buf = e_buf + ip_buf + s_buf

        # parse
        pkt = packet.Packet(array.array('B', p.data))
        protocols = self.get_protocols(pkt)
        p_eth = protocols['ethernet']
        p_ipv4 = protocols['ipv4']
        p_sctp = protocols['sctp']

        # ethernet
        ok_(p_eth)
        eq_('ff:ff:ff:ff:ff:ff', p_eth.dst)
        eq_('00:00:00:00:00:00', p_eth.src)
        eq_(ether.ETH_TYPE_IP, p_eth.ethertype)

        # ipv4
        ok_(p_ipv4)
        eq_(4, p_ipv4.version)
        eq_(5, p_ipv4.header_length)
        eq_(0, p_ipv4.tos)
        l = len(ip_buf) + len(s_buf)
        eq_(l, p_ipv4.total_length)
        eq_(0, p_ipv4.identification)
        eq_(0, p_ipv4.flags)
        eq_(255, p_ipv4.ttl)
        eq_(inet.IPPROTO_SCTP, p_ipv4.proto)
        eq_('0.0.0.0', p_ipv4.src)
        eq_('0.0.0.0', p_ipv4.dst)
        t = bytearray(ip_buf)
        struct.pack_into('!H', t, 10, p_ipv4.csum)
        eq_(packet_utils.checksum(t), 0)

        # sctp
        ok_(p_sctp)
        eq_(0, p_sctp.src_port)
        eq_(0, p_sctp.dst_port)
        eq_(0, p_sctp.vtag)
        assert isinstance(p_sctp.chunks[0], sctp.chunk_data)
        eq_(0, p_sctp.chunks[0]._type)
        eq_(0, p_sctp.chunks[0].unordered)
        eq_(0, p_sctp.chunks[0].begin)
        eq_(0, p_sctp.chunks[0].end)
        eq_(16 + len(self.payload), p_sctp.chunks[0].length)
        eq_(0, p_sctp.chunks[0].tsn)
        eq_(0, p_sctp.chunks[0].sid)
        eq_(0, p_sctp.chunks[0].seq)
        eq_(0, p_sctp.chunks[0].payload_id)
        eq_(self.payload, p_sctp.chunks[0].payload_data)
        eq_(len(s_buf), len(p_sctp))

        # to string
        eth_values = {'dst': 'ff:ff:ff:ff:ff:ff',
                      'src': '00:00:00:00:00:00',
                      'ethertype': ether.ETH_TYPE_IP}
        _eth_str = ','.join(['%s=%s' % (k, repr(eth_values[k]))
                             for k, v in inspect.getmembers(p_eth)
                             if k in eth_values])
        eth_str = '%s(%s)' % (ethernet.ethernet.__name__, _eth_str)

        ipv4_values = {'version': 4,
                       'header_length': 5,
                       'tos': 0,
                       'total_length': l,
                       'identification': 0,
                       'flags': 0,
                       'offset': 0,
                       'ttl': 255,
                       'proto': inet.IPPROTO_SCTP,
                       'csum': p_ipv4.csum,
                       'src': '0.0.0.0',
                       'dst': '0.0.0.0',
                       'option': None}
        _ipv4_str = ','.join(['%s=%s' % (k, repr(ipv4_values[k]))
                              for k, v in inspect.getmembers(p_ipv4)
                              if k in ipv4_values])
        ipv4_str = '%s(%s)' % (ipv4.ipv4.__name__, _ipv4_str)

        data_values = {'unordered': 0,
                       'begin': 0,
                       'end': 0,
                       'length': 16 + len(self.payload),
                       'tsn': 0,
                       'sid': 0,
                       'seq': 0,
                       'payload_id': 0,
                       'payload_data': self.payload}
        _data_str = ','.join(['%s=%s' % (k, repr(data_values[k]))
                             for k in sorted(data_values.keys())])
        data_str = '[%s(%s)]' % (sctp.chunk_data.__name__, _data_str)

        sctp_values = {'src_port': 0,
                       'dst_port': 0,
                       'vtag': 0,
                       'csum': p_sctp.csum,
                       'chunks': data_str}
        _sctp_str = ','.join(['%s=%s' % (k, sctp_values[k])
                             for k, _ in inspect.getmembers(p_sctp)
                             if k in sctp_values])
        sctp_str = '%s(%s)' % (sctp.sctp.__name__, _sctp_str)

        pkt_str = '%s, %s, %s' % (eth_str, ipv4_str, sctp_str)

        eq_(eth_str, str(p_eth))
        eq_(eth_str, repr(p_eth))

        eq_(ipv4_str, str(p_ipv4))
        eq_(ipv4_str, repr(p_ipv4))

        eq_(sctp_str, str(p_sctp))
        eq_(sctp_str, repr(p_sctp))

        eq_(pkt_str, str(pkt))
        eq_(pkt_str, repr(pkt))

    def test_ipv4_icmp(self):
        # buid packet
        e = ethernet.ethernet()
        ip = ipv4.ipv4(proto=inet.IPPROTO_ICMP)
        ic = icmp.icmp()

        p = e/ip/ic
        p.serialize()

        ipaddr = addrconv.ipv4.text_to_bin('0.0.0.0')

        # ethernet !6s6sH
        e_buf = '\xff\xff\xff\xff\xff\xff' \
            + '\x00\x00\x00\x00\x00\x00' \
            + '\x08\x00'

        # ipv4 !BBHHHBBHII
        ip_buf = '\x45' \
            + '\x00' \
            + '\x00\x1c' \
            + '\x00\x00' \
            + '\x00\x00' \
            + '\xff' \
            + '\x01' \
            + '\x00\x00' \
            + ipaddr \
            + ipaddr

        # icmp !BBH + echo !HH
        ic_buf = '\x08' \
            + '\x00' \
            + '\x00\x00' \
            + '\x00\x00' \
            + '\x00\x00'

        buf = e_buf + ip_buf + ic_buf

        # parse
        pkt = packet.Packet(array.array('B', p.data))
        protocols = self.get_protocols(pkt)
        p_eth = protocols['ethernet']
        p_ipv4 = protocols['ipv4']
        p_icmp = protocols['icmp']

        # ethernet
        ok_(p_eth)
        eq_('ff:ff:ff:ff:ff:ff', p_eth.dst)
        eq_('00:00:00:00:00:00', p_eth.src)
        eq_(ether.ETH_TYPE_IP, p_eth.ethertype)

        # ipv4
        ok_(p_ipv4)
        eq_(4, p_ipv4.version)
        eq_(5, p_ipv4.header_length)
        eq_(0, p_ipv4.tos)
        l = len(ip_buf) + len(ic_buf)
        eq_(l, p_ipv4.total_length)
        eq_(0, p_ipv4.identification)
        eq_(0, p_ipv4.flags)
        eq_(255, p_ipv4.ttl)
        eq_(inet.IPPROTO_ICMP, p_ipv4.proto)
        eq_('0.0.0.0', p_ipv4.src)
        eq_('0.0.0.0', p_ipv4.dst)
        t = bytearray(ip_buf)
        struct.pack_into('!H', t, 10, p_ipv4.csum)
        eq_(packet_utils.checksum(t), 0)

        # icmp
        ok_(p_icmp)
        eq_(8, p_icmp.type)
        eq_(0, p_icmp.code)
        eq_(0, p_icmp.data.id)
        eq_(0, p_icmp.data.seq)
        eq_(len(ic_buf), len(p_icmp))
        t = bytearray(ic_buf)
        struct.pack_into('!H', t, 2, p_icmp.csum)
        eq_(packet_utils.checksum(t), 0)

        # to string
        eth_values = {'dst': 'ff:ff:ff:ff:ff:ff',
                      'src': '00:00:00:00:00:00',
                      'ethertype': ether.ETH_TYPE_IP}
        _eth_str = ','.join(['%s=%s' % (k, repr(eth_values[k]))
                             for k, _ in inspect.getmembers(p_eth)
                             if k in eth_values])
        eth_str = '%s(%s)' % (ethernet.ethernet.__name__, _eth_str)

        ipv4_values = {'version': 4,
                       'header_length': 5,
                       'tos': 0,
                       'total_length': l,
                       'identification': 0,
                       'flags': 0,
                       'offset': p_ipv4.offset,
                       'ttl': 255,
                       'proto': inet.IPPROTO_ICMP,
                       'csum': p_ipv4.csum,
                       'src': '0.0.0.0',
                       'dst': '0.0.0.0',
                       'option': None}
        _ipv4_str = ','.join(['%s=%s' % (k, repr(ipv4_values[k]))
                              for k, _ in inspect.getmembers(p_ipv4)
                              if k in ipv4_values])
        ipv4_str = '%s(%s)' % (ipv4.ipv4.__name__, _ipv4_str)

        echo_values = {'id': 0,
                       'seq': 0,
                       'data': None}
        _echo_str = ','.join(['%s=%s' % (k, repr(echo_values[k]))
                              for k in sorted(echo_values.keys())])
        echo_str = '%s(%s)' % (icmp.echo.__name__, _echo_str)
        icmp_values = {'type': 8,
                       'code': 0,
                       'csum': p_icmp.csum,
                       'data': echo_str}
        _icmp_str = ','.join(['%s=%s' % (k, icmp_values[k])
                              for k, _ in inspect.getmembers(p_icmp)
                              if k in icmp_values])
        icmp_str = '%s(%s)' % (icmp.icmp.__name__, _icmp_str)

        pkt_str = '%s, %s, %s' % (eth_str, ipv4_str, icmp_str)

        eq_(eth_str, str(p_eth))
        eq_(eth_str, repr(p_eth))

        eq_(ipv4_str, str(p_ipv4))
        eq_(ipv4_str, repr(p_ipv4))

        eq_(icmp_str, str(p_icmp))
        eq_(icmp_str, repr(p_icmp))

        eq_(pkt_str, str(pkt))
        eq_(pkt_str, repr(pkt))

    def test_ipv6_udp(self):
        # build packet
        e = ethernet.ethernet(ethertype=ether.ETH_TYPE_IPV6)
        ip = ipv6.ipv6(nxt=inet.IPPROTO_UDP)
        u = udp.udp()

        p = e/ip/u/self.payload
        p.serialize()

        ipaddr = addrconv.ipv6.text_to_bin('::')

        # ethernet !6s6sH
        e_buf = '\xff\xff\xff\xff\xff\xff' \
            + '\x00\x00\x00\x00\x00\x00' \
            + '\x86\xdd'

        # ipv6 !IHBB16s16s'
        ip_buf = '\x60\x00\x00\x00' \
            + '\x00\x00' \
            + '\x11' \
            + '\xff' \
            + '\x00\x00' \
            + ipaddr \
            + ipaddr

        # udp !HHHH
        u_buf = '\x00\x00' \
            + '\x00\x00' \
            + '\x00\x28' \
            + '\x00\x00'

        buf = e_buf + ip_buf + u_buf + self.payload

        # parse
        pkt = packet.Packet(array.array('B', p.data))
        protocols = self.get_protocols(pkt)
        p_eth = protocols['ethernet']
        p_ipv6 = protocols['ipv6']
        p_udp = protocols['udp']

        # ethernet
        ok_(p_eth)
        eq_('ff:ff:ff:ff:ff:ff', p_eth.dst)
        eq_('00:00:00:00:00:00', p_eth.src)
        eq_(ether.ETH_TYPE_IPV6, p_eth.ethertype)

        # ipv6
        ok_(p_ipv6)
        eq_(6, p_ipv6.version)
        eq_(0, p_ipv6.traffic_class)
        eq_(0, p_ipv6.flow_label)
        eq_(len(u_buf) + len(self.payload), p_ipv6.payload_length)
        eq_(inet.IPPROTO_UDP, p_ipv6.nxt)
        eq_(255, p_ipv6.hop_limit)
        eq_('::', p_ipv6.src)
        eq_('::', p_ipv6.dst)

        # udp
        ok_(p_udp)
        eq_(0, p_udp.src_port)
        eq_(0, p_udp.dst_port)
        eq_(len(u_buf) + len(self.payload), p_udp.total_length)
        eq_(0x2bc2, p_udp.csum)
        t = bytearray(u_buf)
        struct.pack_into('!H', t, 6, p_udp.csum)
        ph = struct.pack('!16s16sI3xB', ipaddr, ipaddr,
                         len(u_buf) + len(self.payload), 17)
        t = ph + t + self.payload
        eq_(packet_utils.checksum(t), 0)

        # payload
        ok_('payload' in protocols)
        eq_(self.payload, protocols['payload'].tostring())

        # to string
        eth_values = {'dst': 'ff:ff:ff:ff:ff:ff',
                      'src': '00:00:00:00:00:00',
                      'ethertype': ether.ETH_TYPE_IPV6}
        _eth_str = ','.join(['%s=%s' % (k, repr(eth_values[k]))
                             for k, v in inspect.getmembers(p_eth)
                             if k in eth_values])
        eth_str = '%s(%s)' % (ethernet.ethernet.__name__, _eth_str)

        ipv6_values = {'version': 6,
                       'traffic_class': 0,
                       'flow_label': 0,
                       'payload_length': len(u_buf) + len(self.payload),
                       'nxt': inet.IPPROTO_UDP,
                       'hop_limit': 255,
                       'src': '::',
                       'dst': '::',
                       'ext_hdrs': []}
        _ipv6_str = ','.join(['%s=%s' % (k, repr(ipv6_values[k]))
                              for k, v in inspect.getmembers(p_ipv6)
                              if k in ipv6_values])
        ipv6_str = '%s(%s)' % (ipv6.ipv6.__name__, _ipv6_str)

        udp_values = {'src_port': 0,
                      'dst_port': 0,
                      'total_length': len(u_buf) + len(self.payload),
                      'csum': 0x2bc2}
        _udp_str = ','.join(['%s=%s' % (k, repr(udp_values[k]))
                             for k, v in inspect.getmembers(p_udp)
                             if k in udp_values])
        udp_str = '%s(%s)' % (udp.udp.__name__, _udp_str)

        pkt_str = '%s, %s, %s, %s' % (eth_str, ipv6_str, udp_str,
                                      repr(protocols['payload']))

        eq_(eth_str, str(p_eth))
        eq_(eth_str, repr(p_eth))

        eq_(ipv6_str, str(p_ipv6))
        eq_(ipv6_str, repr(p_ipv6))

        eq_(udp_str, str(p_udp))
        eq_(udp_str, repr(p_udp))

        eq_(pkt_str, str(pkt))
        eq_(pkt_str, repr(pkt))

    def test_ipv6_tcp(self):
        # build packet
        e = ethernet.ethernet(ethertype=ether.ETH_TYPE_IPV6)
        ip = ipv6.ipv6()
        t = tcp.tcp(option='\x01\x02')

        p = e/ip/t/self.payload
        p.serialize()

        ipaddr = addrconv.ipv6.text_to_bin('::')

        # ethernet !6s6sH
        e_buf = '\xff\xff\xff\xff\xff\xff' \
            + '\x00\x00\x00\x00\x00\x00' \
            + '\x86\xdd'

        # ipv6 !IHBB16s16s'
        ip_buf = '\x60\x00\x00\x00' \
            + '\x00\x00' \
            + '\x06' \
            + '\xff' \
            + '\x00\x00' \
            + ipaddr \
            + ipaddr

        # tcp !HHIIBBHHH + option
        t_buf = '\x00\x00' \
            + '\x00\x00' \
            + '\x00\x00\x00\x00' \
            + '\x00\x00\x00\x00' \
            + '\x60' \
            + '\x00' \
            + '\x00\x00' \
            + '\x00\x00' \
            + '\x00\x00' \
            + '\x01\x02\x00\x00'

        buf = e_buf + ip_buf + t_buf + self.payload

        # parse
        pkt = packet.Packet(array.array('B', p.data))
        protocols = self.get_protocols(pkt)
        p_eth = protocols['ethernet']
        p_ipv6 = protocols['ipv6']
        p_tcp = protocols['tcp']

        # ethernet
        ok_(p_eth)
        eq_('ff:ff:ff:ff:ff:ff', p_eth.dst)
        eq_('00:00:00:00:00:00', p_eth.src)
        eq_(ether.ETH_TYPE_IPV6, p_eth.ethertype)

        # ipv6
        ok_(p_ipv6)
        eq_(6, p_ipv6.version)
        eq_(0, p_ipv6.traffic_class)
        eq_(0, p_ipv6.flow_label)
        eq_(len(t_buf) + len(self.payload), p_ipv6.payload_length)
        eq_(inet.IPPROTO_TCP, p_ipv6.nxt)
        eq_(255, p_ipv6.hop_limit)
        eq_('::', p_ipv6.src)
        eq_('::', p_ipv6.dst)

        # tcp
        ok_(p_tcp)
        eq_(0, p_tcp.src_port)
        eq_(0, p_tcp.dst_port)
        eq_(0, p_tcp.seq)
        eq_(0, p_tcp.ack)
        eq_(6, p_tcp.offset)
        eq_(0, p_tcp.bits)
        eq_(0, p_tcp.window_size)
        eq_(0, p_tcp.urgent)
        eq_(len(t_buf), len(p_tcp))
        t = bytearray(t_buf)
        struct.pack_into('!H', t, 16, p_tcp.csum)
        ph = struct.pack('!16s16sI3xB', ipaddr, ipaddr,
                         len(t_buf) + len(self.payload), 6)
        t = ph + t + self.payload
        eq_(packet_utils.checksum(t), 0)

        # payload
        ok_('payload' in protocols)
        eq_(self.payload, protocols['payload'].tostring())

        # to string
        eth_values = {'dst': 'ff:ff:ff:ff:ff:ff',
                      'src': '00:00:00:00:00:00',
                      'ethertype': ether.ETH_TYPE_IPV6}
        _eth_str = ','.join(['%s=%s' % (k, repr(eth_values[k]))
                             for k, v in inspect.getmembers(p_eth)
                             if k in eth_values])
        eth_str = '%s(%s)' % (ethernet.ethernet.__name__, _eth_str)

        ipv6_values = {'version': 6,
                       'traffic_class': 0,
                       'flow_label': 0,
                       'payload_length': len(t_buf) + len(self.payload),
                       'nxt': inet.IPPROTO_TCP,
                       'hop_limit': 255,
                       'src': '::',
                       'dst': '::',
                       'ext_hdrs': []}
        _ipv6_str = ','.join(['%s=%s' % (k, repr(ipv6_values[k]))
                              for k, v in inspect.getmembers(p_ipv6)
                              if k in ipv6_values])
        ipv6_str = '%s(%s)' % (ipv6.ipv6.__name__, _ipv6_str)

        tcp_values = {'src_port': 0,
                      'dst_port': 0,
                      'seq': 0,
                      'ack': 0,
                      'offset': 6,
                      'bits': 0,
                      'window_size': 0,
                      'csum': p_tcp.csum,
                      'urgent': 0,
                      'option': p_tcp.option}
        _tcp_str = ','.join(['%s=%s' % (k, repr(tcp_values[k]))
                             for k, v in inspect.getmembers(p_tcp)
                             if k in tcp_values])
        tcp_str = '%s(%s)' % (tcp.tcp.__name__, _tcp_str)

        pkt_str = '%s, %s, %s, %s' % (eth_str, ipv6_str, tcp_str,
                                      repr(protocols['payload']))

        eq_(eth_str, str(p_eth))
        eq_(eth_str, repr(p_eth))

        eq_(ipv6_str, str(p_ipv6))
        eq_(ipv6_str, repr(p_ipv6))

        eq_(tcp_str, str(p_tcp))
        eq_(tcp_str, repr(p_tcp))

        eq_(pkt_str, str(pkt))
        eq_(pkt_str, repr(pkt))

    def test_ipv6_sctp(self):
        # build packet
        e = ethernet.ethernet(ethertype=ether.ETH_TYPE_IPV6)
        ip = ipv6.ipv6(nxt=inet.IPPROTO_SCTP)
        s = sctp.sctp(chunks=[sctp.chunk_data(payload_data=self.payload)])

        p = e/ip/s
        p.serialize()

        ipaddr = addrconv.ipv6.text_to_bin('::')

        # ethernet !6s6sH
        e_buf = '\xff\xff\xff\xff\xff\xff' \
            + '\x00\x00\x00\x00\x00\x00' \
            + '\x86\xdd'

        # ipv6 !IHBB16s16s'
        ip_buf = '\x60\x00\x00\x00' \
            + '\x00\x00' \
            + '\x84' \
            + '\xff' \
            + '\x00\x00' \
            + ipaddr \
            + ipaddr

        # sctp !HHII + chunk_data !BBHIHHI + payload
        s_buf = '\x00\x00' \
            + '\x00\x00' \
            + '\x00\x00\x00\x00' \
            + '\x00\x00\x00\x00' \
            + '\x00' \
            + '\x00' \
            + '\x00\x00' \
            + '\x00\x00\x00\x00' \
            + '\x00\x00' \
            + '\x00\x00' \
            + '\x00\x00\x00\x00' \
            + self.payload

        buf = e_buf + ip_buf + s_buf

        # parse
        pkt = packet.Packet(array.array('B', p.data))
        protocols = self.get_protocols(pkt)
        p_eth = protocols['ethernet']
        p_ipv6 = protocols['ipv6']
        p_sctp = protocols['sctp']

        # ethernet
        ok_(p_eth)
        eq_('ff:ff:ff:ff:ff:ff', p_eth.dst)
        eq_('00:00:00:00:00:00', p_eth.src)
        eq_(ether.ETH_TYPE_IPV6, p_eth.ethertype)

        # ipv6
        ok_(p_ipv6)
        eq_(6, p_ipv6.version)
        eq_(0, p_ipv6.traffic_class)
        eq_(0, p_ipv6.flow_label)
        eq_(len(s_buf), p_ipv6.payload_length)
        eq_(inet.IPPROTO_SCTP, p_ipv6.nxt)
        eq_(255, p_ipv6.hop_limit)
        eq_('::', p_ipv6.src)
        eq_('::', p_ipv6.dst)

        # sctp
        ok_(p_sctp)
        eq_(0, p_sctp.src_port)
        eq_(0, p_sctp.dst_port)
        eq_(0, p_sctp.vtag)
        assert isinstance(p_sctp.chunks[0], sctp.chunk_data)
        eq_(0, p_sctp.chunks[0]._type)
        eq_(0, p_sctp.chunks[0].unordered)
        eq_(0, p_sctp.chunks[0].begin)
        eq_(0, p_sctp.chunks[0].end)
        eq_(16 + len(self.payload), p_sctp.chunks[0].length)
        eq_(0, p_sctp.chunks[0].tsn)
        eq_(0, p_sctp.chunks[0].sid)
        eq_(0, p_sctp.chunks[0].seq)
        eq_(0, p_sctp.chunks[0].payload_id)
        eq_(self.payload, p_sctp.chunks[0].payload_data)
        eq_(len(s_buf), len(p_sctp))

        # to string
        eth_values = {'dst': 'ff:ff:ff:ff:ff:ff',
                      'src': '00:00:00:00:00:00',
                      'ethertype': ether.ETH_TYPE_IPV6}
        _eth_str = ','.join(['%s=%s' % (k, repr(eth_values[k]))
                             for k, v in inspect.getmembers(p_eth)
                             if k in eth_values])
        eth_str = '%s(%s)' % (ethernet.ethernet.__name__, _eth_str)

        ipv6_values = {'version': 6,
                       'traffic_class': 0,
                       'flow_label': 0,
                       'payload_length': len(s_buf),
                       'nxt': inet.IPPROTO_SCTP,
                       'hop_limit': 255,
                       'src': '::',
                       'dst': '::',
                       'ext_hdrs': []}
        _ipv6_str = ','.join(['%s=%s' % (k, repr(ipv6_values[k]))
                              for k, v in inspect.getmembers(p_ipv6)
                              if k in ipv6_values])
        ipv6_str = '%s(%s)' % (ipv6.ipv6.__name__, _ipv6_str)

        data_values = {'unordered': 0,
                       'begin': 0,
                       'end': 0,
                       'length': 16 + len(self.payload),
                       'tsn': 0,
                       'sid': 0,
                       'seq': 0,
                       'payload_id': 0,
                       'payload_data': self.payload}
        _data_str = ','.join(['%s=%s' % (k, repr(data_values[k]))
                             for k in sorted(data_values.keys())])
        data_str = '[%s(%s)]' % (sctp.chunk_data.__name__, _data_str)

        sctp_values = {'src_port': 0,
                       'dst_port': 0,
                       'vtag': 0,
                       'csum': p_sctp.csum,
                       'chunks': data_str}
        _sctp_str = ','.join(['%s=%s' % (k, sctp_values[k])
                             for k, _ in inspect.getmembers(p_sctp)
                             if k in sctp_values])
        sctp_str = '%s(%s)' % (sctp.sctp.__name__, _sctp_str)

        pkt_str = '%s, %s, %s' % (eth_str, ipv6_str, sctp_str)

        eq_(eth_str, str(p_eth))
        eq_(eth_str, repr(p_eth))

        eq_(ipv6_str, str(p_ipv6))
        eq_(ipv6_str, repr(p_ipv6))

        eq_(sctp_str, str(p_sctp))
        eq_(sctp_str, repr(p_sctp))

        eq_(pkt_str, str(pkt))
        eq_(pkt_str, repr(pkt))

    def test_ipv6_icmpv6(self):
        # build packet
        e = ethernet.ethernet(ethertype=ether.ETH_TYPE_IPV6)
        ip = ipv6.ipv6(nxt=inet.IPPROTO_ICMPV6)
        ic = icmpv6.icmpv6()

        p = e/ip/ic
        p.serialize()

        ipaddr = addrconv.ipv6.text_to_bin('::')

        # ethernet !6s6sH
        e_buf = '\xff\xff\xff\xff\xff\xff' \
            + '\x00\x00\x00\x00\x00\x00' \
            + '\x86\xdd'

        # ipv6 !IHBB16s16s'
        ip_buf = '\x60\x00\x00\x00' \
            + '\x00\x00' \
            + '\x3a' \
            + '\xff' \
            + '\x00\x00' \
            + ipaddr \
            + ipaddr

        # icmpv6 !BBH
        ic_buf = '\x00' \
            + '\x00' \
            + '\x00\x00'

        buf = e_buf + ip_buf + ic_buf

        # parse
        pkt = packet.Packet(array.array('B', p.data))
        protocols = self.get_protocols(pkt)
        p_eth = protocols['ethernet']
        p_ipv6 = protocols['ipv6']
        p_icmpv6 = protocols['icmpv6']

        # ethernet
        ok_(p_eth)
        eq_('ff:ff:ff:ff:ff:ff', p_eth.dst)
        eq_('00:00:00:00:00:00', p_eth.src)
        eq_(ether.ETH_TYPE_IPV6, p_eth.ethertype)

        # ipv6
        ok_(p_ipv6)
        eq_(6, p_ipv6.version)
        eq_(0, p_ipv6.traffic_class)
        eq_(0, p_ipv6.flow_label)
        eq_(len(ic_buf), p_ipv6.payload_length)
        eq_(inet.IPPROTO_ICMPV6, p_ipv6.nxt)
        eq_(255, p_ipv6.hop_limit)
        eq_('::', p_ipv6.src)
        eq_('::', p_ipv6.dst)

        # icmpv6
        ok_(p_icmpv6)
        eq_(0, p_icmpv6.type_)
        eq_(0, p_icmpv6.code)
        eq_(len(ic_buf), len(p_icmpv6))
        t = bytearray(ic_buf)
        struct.pack_into('!H', t, 2, p_icmpv6.csum)
        ph = struct.pack('!16s16sI3xB', ipaddr, ipaddr, len(ic_buf), 58)
        t = ph + t
        eq_(packet_utils.checksum(t), 0)

        # to string
        eth_values = {'dst': 'ff:ff:ff:ff:ff:ff',
                      'src': '00:00:00:00:00:00',
                      'ethertype': ether.ETH_TYPE_IPV6}
        _eth_str = ','.join(['%s=%s' % (k, repr(eth_values[k]))
                             for k, _ in inspect.getmembers(p_eth)
                             if k in eth_values])
        eth_str = '%s(%s)' % (ethernet.ethernet.__name__, _eth_str)

        ipv6_values = {'version': 6,
                       'traffic_class': 0,
                       'flow_label': 0,
                       'payload_length': len(ic_buf),
                       'nxt': inet.IPPROTO_ICMPV6,
                       'hop_limit': 255,
                       'src': '::',
                       'dst': '::',
                       'ext_hdrs': []}
        _ipv6_str = ','.join(['%s=%s' % (k, repr(ipv6_values[k]))
                              for k, _ in inspect.getmembers(p_ipv6)
                              if k in ipv6_values])
        ipv6_str = '%s(%s)' % (ipv6.ipv6.__name__, _ipv6_str)

        icmpv6_values = {'type_': 0,
                         'code': 0,
                         'csum': p_icmpv6.csum,
                         'data': None}
        _icmpv6_str = ','.join(['%s=%s' % (k, repr(icmpv6_values[k]))
                                for k, _ in inspect.getmembers(p_icmpv6)
                                if k in icmpv6_values])
        icmpv6_str = '%s(%s)' % (icmpv6.icmpv6.__name__, _icmpv6_str)

        pkt_str = '%s, %s, %s' % (eth_str, ipv6_str, icmpv6_str)

        eq_(eth_str, str(p_eth))
        eq_(eth_str, repr(p_eth))

        eq_(ipv6_str, str(p_ipv6))
        eq_(ipv6_str, repr(p_ipv6))

        eq_(icmpv6_str, str(p_icmpv6))
        eq_(icmpv6_str, repr(p_icmpv6))

        eq_(pkt_str, str(pkt))
        eq_(pkt_str, repr(pkt))

    def test_llc_bpdu(self):
        # buid packet
        e = ethernet.ethernet(self.dst_mac, self.src_mac,
                              ether.ETH_TYPE_IEEE802_3)
        llc_control = llc.ControlFormatU(0, 0, 0)
        l = llc.llc(llc.SAP_BPDU, llc.SAP_BPDU, llc_control)
        b = bpdu.ConfigurationBPDUs(flags=0,
                                    root_priority=32768,
                                    root_system_id_extension=0,
                                    root_mac_address=self.src_mac,
                                    root_path_cost=0,
                                    bridge_priority=32768,
                                    bridge_system_id_extension=0,
                                    bridge_mac_address=self.dst_mac,
                                    port_priority=128,
                                    port_number=4,
                                    message_age=1,
                                    max_age=20,
                                    hello_time=2,
                                    forward_delay=15)

        p = packet.Packet()
        p.add_protocol(e)
        p.add_protocol(l)
        p.add_protocol(b)
        p.serialize()

        # ethernet !6s6sH
        e_buf = self.dst_mac + self.src_mac + '\x05\xdc'

        # llc !BBB
        l_buf = ('\x42'
                 '\x42'
                 '\x03')

        # bpdu !HBBBQIQHHHHH
        b_buf = ('\x00\x00'
                 '\x00'
                 '\x00'
                 '\x00'
                 '\x80\x64\xaa\xaa\xaa\xaa\xaa\xaa'
                 '\x00\x00\x00\x04'
                 '\x80\x64\xbb\xbb\xbb\xbb\xbb\xbb'
                 '\x80\x04'
                 '\x01\x00'
                 '\x14\x00'
                 '\x02\x00'
                 '\x0f\x00')

        buf = e_buf + l_buf + b_buf

        # parse
        pkt = packet.Packet(array.array('B', p.data))
        protocols = self.get_protocols(pkt)
        p_eth = protocols['ethernet']
        p_llc = protocols['llc']
        p_bpdu = protocols['ConfigurationBPDUs']

        # ethernet
        ok_(p_eth)
        eq_(self.dst_mac, p_eth.dst)
        eq_(self.src_mac, p_eth.src)
        eq_(ether.ETH_TYPE_IEEE802_3, p_eth.ethertype)

        # llc
        ok_(p_llc)
        eq_(llc.SAP_BPDU, p_llc.dsap_addr)
        eq_(llc.SAP_BPDU, p_llc.ssap_addr)
        eq_(0, p_llc.control.modifier_function1)
        eq_(0, p_llc.control.pf_bit)
        eq_(0, p_llc.control.modifier_function2)

        # bpdu
        ok_(p_bpdu)
        eq_(bpdu.PROTOCOL_IDENTIFIER, p_bpdu.protocol_id)
        eq_(bpdu.PROTOCOLVERSION_ID_BPDU, p_bpdu.version_id)
        eq_(bpdu.TYPE_CONFIG_BPDU, p_bpdu.bpdu_type)
        eq_(0, p_bpdu.flags)
        eq_(32768, p_bpdu.root_priority)
        eq_(0, p_bpdu.root_system_id_extension)
        eq_(self.src_mac, p_bpdu.root_mac_address)
        eq_(0, p_bpdu.root_path_cost)
        eq_(32768, p_bpdu.bridge_priority)
        eq_(0, p_bpdu.bridge_system_id_extension)
        eq_(self.dst_mac, p_bpdu.bridge_mac_address)
        eq_(128, p_bpdu.port_priority)
        eq_(4, p_bpdu.port_number)
        eq_(1, p_bpdu.message_age)
        eq_(20, p_bpdu.max_age)
        eq_(2, p_bpdu.hello_time)
        eq_(15, p_bpdu.forward_delay)

        # to string
        eth_values = {'dst': self.dst_mac,
                      'src': self.src_mac,
                      'ethertype': ether.ETH_TYPE_IEEE802_3}
        _eth_str = ','.join(['%s=%s' % (k, repr(eth_values[k]))
                             for k, v in inspect.getmembers(p_eth)
                             if k in eth_values])
        eth_str = '%s(%s)' % (ethernet.ethernet.__name__, _eth_str)

        ctrl_values = {'modifier_function1': 0,
                       'pf_bit': 0,
                       'modifier_function2': 0}
        _ctrl_str = ','.join(['%s=%s' % (k, repr(ctrl_values[k]))
                             for k, v in inspect.getmembers(p_llc.control)
                             if k in ctrl_values])
        ctrl_str = '%s(%s)' % (llc.ControlFormatU.__name__, _ctrl_str)

        llc_values = {'dsap_addr': repr(llc.SAP_BPDU),
                      'ssap_addr': repr(llc.SAP_BPDU),
                      'control': ctrl_str}
        _llc_str = ','.join(['%s=%s' % (k, llc_values[k])
                             for k, v in inspect.getmembers(p_llc)
                             if k in llc_values])
        llc_str = '%s(%s)' % (llc.llc.__name__, _llc_str)

        bpdu_values = {'protocol_id': bpdu.PROTOCOL_IDENTIFIER,
                       'version_id': bpdu.PROTOCOLVERSION_ID_BPDU,
                       'bpdu_type': bpdu.TYPE_CONFIG_BPDU,
                       'flags': 0,
                       'root_priority': long(32768),
                       'root_system_id_extension': long(0),
                       'root_mac_address': self.src_mac,
                       'root_path_cost': 0,
                       'bridge_priority': long(32768),
                       'bridge_system_id_extension': long(0),
                       'bridge_mac_address': self.dst_mac,
                       'port_priority': 128,
                       'port_number': 4,
                       'message_age': float(1),
                       'max_age': float(20),
                       'hello_time': float(2),
                       'forward_delay': float(15)}
        _bpdu_str = ','.join(['%s=%s' % (k, repr(bpdu_values[k]))
                             for k, v in inspect.getmembers(p_bpdu)
                             if k in bpdu_values])
        bpdu_str = '%s(%s)' % (bpdu.ConfigurationBPDUs.__name__, _bpdu_str)

        pkt_str = '%s, %s, %s' % (eth_str, llc_str, bpdu_str)

        eq_(eth_str, str(p_eth))
        eq_(eth_str, repr(p_eth))

        eq_(llc_str, str(p_llc))
        eq_(llc_str, repr(p_llc))

        eq_(bpdu_str, str(p_bpdu))
        eq_(bpdu_str, repr(p_bpdu))

        eq_(pkt_str, str(pkt))
        eq_(pkt_str, repr(pkt))

    def test_div_api(self):
        e = ethernet.ethernet(self.dst_mac, self.src_mac, ether.ETH_TYPE_IP)
        i = ipv4.ipv4()
        u = udp.udp(self.src_port, self.dst_port)
        pkt = e/i/u
        ok_(isinstance(pkt, packet.Packet))
        ok_(isinstance(pkt.protocols[0], ethernet.ethernet))
        ok_(isinstance(pkt.protocols[1], ipv4.ipv4))
        ok_(isinstance(pkt.protocols[2], udp.udp))

########NEW FILE########
__FILENAME__ = test_pbb
# Copyright (C) 2013 Nippon Telegraph and Telephone Corporation.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import logging
import struct
import unittest

from nose.tools import eq_
from nose.tools import ok_
from nose.tools import raises
from ryu.ofproto import ether
from ryu.ofproto import inet
from ryu.lib.packet import ethernet
from ryu.lib.packet import packet
from ryu.lib.packet import ipv4
from ryu.lib.packet import vlan
from ryu.lib.packet import pbb


LOG = logging.getLogger(__name__)


class Test_itag(unittest.TestCase):

    pcp = 3
    dei = 0
    uca = 1
    sid = 16770000
    data = pcp << 29 | dei << 28 | uca << 27 | sid
    buf = struct.pack(pbb.itag._PACK_STR, data)
    it = pbb.itag(pcp, dei, uca, sid)

    def setUp(self):
        pass

    def tearDown(self):
        pass

    def test_init(self):
        eq_(self.pcp, self.it.pcp)
        eq_(self.dei, self.it.dei)
        eq_(self.uca, self.it.uca)
        eq_(self.sid, self.it.sid)

    def test_parser(self):
        _res = pbb.itag.parser(self.buf)
        if type(_res) is tuple:
            res = _res[0]
        else:
            res = _res
        eq_(res.pcp, self.pcp)
        eq_(res.dei, self.dei)
        eq_(res.uca, self.uca)
        eq_(res.sid, self.sid)

    def test_serialize(self):
        data = bytearray()
        prev = None
        buf = self.it.serialize(data, prev)
        res = struct.unpack(pbb.itag._PACK_STR, buf)
        eq_(res[0], self.data)

    def _build_itag(self):
        b_src_mac = '00:07:0d:af:f4:54'
        b_dst_mac = '00:00:00:00:00:00'
        b_ethertype = ether.ETH_TYPE_8021AD
        e1 = ethernet.ethernet(b_dst_mac, b_src_mac, b_ethertype)

        b_pcp = 0
        b_cfi = 0
        b_vid = 32
        b_ethertype = ether.ETH_TYPE_8021Q
        bt = vlan.svlan(b_pcp, b_cfi, b_vid, b_ethertype)

        c_src_mac = '11:11:11:11:11:11'
        c_dst_mac = 'aa:aa:aa:aa:aa:aa'
        c_ethertype = ether.ETH_TYPE_8021AD
        e2 = ethernet.ethernet(c_dst_mac, c_src_mac, c_ethertype)

        s_pcp = 0
        s_cfi = 0
        s_vid = 32
        s_ethertype = ether.ETH_TYPE_8021Q
        st = vlan.svlan(s_pcp, s_cfi, s_vid, s_ethertype)

        c_pcp = 0
        c_cfi = 0
        c_vid = 32
        c_ethertype = ether.ETH_TYPE_IP
        ct = vlan.vlan(c_pcp, c_cfi, c_vid, c_ethertype)

        version = 4
        header_length = 20
        tos = 0
        total_length = 24
        identification = 0x8a5d
        flags = 0
        offset = 1480
        ttl = 64
        proto = inet.IPPROTO_ICMP
        csum = 0xa7f2
        src = '131.151.32.21'
        dst = '131.151.32.129'
        option = 'TEST'
        ip = ipv4.ipv4(version, header_length, tos, total_length,
                       identification, flags, offset, ttl, proto, csum,
                       src, dst, option)

        p = packet.Packet()

        p.add_protocol(e1)
        p.add_protocol(bt)
        p.add_protocol(self.it)
        p.add_protocol(e2)
        p.add_protocol(st)
        p.add_protocol(ct)
        p.add_protocol(ip)
        p.serialize()

        return p

    def test_build_itag(self):
        p = self._build_itag()

        e = p.get_protocols(ethernet.ethernet)
        ok_(e)
        ok_(isinstance(e, list))
        eq_(e[0].ethertype, ether.ETH_TYPE_8021AD)
        eq_(e[1].ethertype, ether.ETH_TYPE_8021AD)

        sv = p.get_protocols(vlan.svlan)
        ok_(sv)
        ok_(isinstance(sv, list))
        eq_(sv[0].ethertype, ether.ETH_TYPE_8021Q)
        eq_(sv[1].ethertype, ether.ETH_TYPE_8021Q)

        it = p.get_protocol(pbb.itag)
        ok_(it)

        v = p.get_protocol(vlan.vlan)
        ok_(v)
        eq_(v.ethertype, ether.ETH_TYPE_IP)

        ip = p.get_protocol(ipv4.ipv4)
        ok_(ip)

        eq_(it.pcp, self.pcp)
        eq_(it.dei, self.dei)
        eq_(it.uca, self.uca)
        eq_(it.sid, self.sid)

    @raises(Exception)
    def test_malformed_itag(self):
        m_short_buf = self.buf[1:pbb.itag._MIN_LEN]
        pbb.itag.parser(m_short_buf)

########NEW FILE########
__FILENAME__ = test_sctp
# Copyright (C) 2013 Nippon Telegraph and Telephone Corporation.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.


import inspect
import logging
import struct
import unittest

from nose.tools import eq_
from nose.tools import ok_
from ryu.lib import addrconv
from ryu.lib.packet import packet
from ryu.lib.packet import ethernet
from ryu.lib.packet import ipv4
from ryu.lib.packet import sctp
from ryu.ofproto import ether
from ryu.ofproto import inet


LOG = logging.getLogger(__name__)


class Test_sctp(unittest.TestCase):

    def setUp(self):
        self.chunks = []
        self.csum = 0
        self.dst_port = 1234
        self.src_port = 5678
        self.vtag = 98765432

        self.sc = sctp.sctp(
            self.src_port, self.dst_port, self.vtag, self.csum,
            self.chunks)

        self.buf = '\x16\x2e\x04\xd2\x05\xe3\x0a\x78\x00\x00\x00\x00'

    def setUp_with_data(self):
        self.unordered = 1
        self.begin = 1
        self.end = 1
        self.length = 16 + 10
        self.tsn = 12345
        self.sid = 1
        self.seq = 0
        self.payload_id = 0
        self.payload_data = '\x01\x02\x03\x04\x05\x06\x07\x08\x09\x0a'

        self.data = sctp.chunk_data(
            unordered=self.unordered, begin=self.begin, end=self.end,
            tsn=self.tsn, sid=self.sid, payload_data=self.payload_data)

        self.chunks = [self.data]

        self.sc = sctp.sctp(
            self.src_port, self.dst_port, self.vtag, self.csum,
            self.chunks)

        self.buf += '\x00\x07\x00\x1a\x00\x00\x30\x39\x00\x01\x00\x00' + \
            '\x00\x00\x00\x00\x01\x02\x03\x04\x05\x06\x07\x08\x09\x0a'

    def setUp_with_init(self):
        self.flags = 0
        self.length = 20 + 8 + 20 + 8 + 4 + 16 + 16
        self.init_tag = 123456
        self.a_rwnd = 9876
        self.os = 3
        self.mis = 3
        self.i_tsn = 123456

        self.p_ipv4 = sctp.param_ipv4('192.168.1.1')
        self.p_ipv6 = sctp.param_ipv6('fe80::647e:1aff:fec4:8284')
        self.p_cookie_preserve = sctp.param_cookie_preserve(5000)
        self.p_ecn = sctp.param_ecn()
        self.p_host_addr = sctp.param_host_addr('test host\x00')
        self.p_support_type = sctp.param_supported_addr(
            [sctp.PTYPE_IPV4, sctp.PTYPE_IPV6, sctp.PTYPE_COOKIE_PRESERVE,
             sctp.PTYPE_ECN, sctp.PTYPE_HOST_ADDR])
        self.params = [
            self.p_ipv4, self.p_ipv6, self.p_cookie_preserve,
            self.p_ecn, self.p_host_addr, self.p_support_type]

        self.init = sctp.chunk_init(
            init_tag=self.init_tag, a_rwnd=self.a_rwnd, os=self.os,
            mis=self.mis, i_tsn=self.i_tsn, params=self.params)

        self.chunks = [self.init]

        self.sc = sctp.sctp(
            self.src_port, self.dst_port, self.vtag, self.csum,
            self.chunks)

        self.buf += '\x01\x00\x00\x5c\x00\x01\xe2\x40\x00\x00\x26\x94' + \
            '\x00\x03\x00\x03\x00\x01\xe2\x40' + \
            '\x00\x05\x00\x08\xc0\xa8\x01\x01' + \
            '\x00\x06\x00\x14' + \
            '\xfe\x80\x00\x00\x00\x00\x00\x00' + \
            '\x64\x7e\x1a\xff\xfe\xc4\x82\x84' + \
            '\x00\x09\x00\x08\x00\x00\x13\x88' + \
            '\x80\x00\x00\x04' + \
            '\x00\x0b\x00\x0e' + \
            '\x74\x65\x73\x74\x20\x68\x6f\x73\x74\x00\x00\x00' + \
            '\x00\x0c\x00\x0e\x00\x05\x00\x06\x00\x09\x80\x00' + \
            '\x00\x0b\x00\x00'

    def setUp_with_init_ack(self):
        self.flags = 0
        self.length = 20 + 8 + 8 + 20 + 8 + 4 + 16
        self.init_tag = 123456
        self.a_rwnd = 9876
        self.os = 3
        self.mis = 3
        self.i_tsn = 123456

        self.p_state_cookie = sctp.param_state_cookie('\x01\x02\x03')
        self.p_ipv4 = sctp.param_ipv4('192.168.1.1')
        self.p_ipv6 = sctp.param_ipv6('fe80::647e:1aff:fec4:8284')
        self.p_unrecognized_param = sctp.param_unrecognized_param(
            '\xff\xff\x00\x04')
        self.p_ecn = sctp.param_ecn()
        self.p_host_addr = sctp.param_host_addr('test host\x00')
        self.params = [
            self.p_state_cookie, self.p_ipv4, self.p_ipv6,
            self.p_unrecognized_param, self.p_ecn, self.p_host_addr]

        self.init_ack = sctp.chunk_init_ack(
            init_tag=self.init_tag, a_rwnd=self.a_rwnd, os=self.os,
            mis=self.mis, i_tsn=self.i_tsn, params=self.params)

        self.chunks = [self.init_ack]

        self.sc = sctp.sctp(
            self.src_port, self.dst_port, self.vtag, self.csum,
            self.chunks)

        self.buf += '\x02\x00\x00\x54\x00\x01\xe2\x40\x00\x00\x26\x94' + \
            '\x00\x03\x00\x03\x00\x01\xe2\x40' + \
            '\x00\x07\x00\x07\x01\x02\x03\x00' + \
            '\x00\x05\x00\x08\xc0\xa8\x01\x01' + \
            '\x00\x06\x00\x14' + \
            '\xfe\x80\x00\x00\x00\x00\x00\x00' + \
            '\x64\x7e\x1a\xff\xfe\xc4\x82\x84' + \
            '\x00\x08\x00\x08\xff\xff\x00\x04' + \
            '\x80\x00\x00\x04' + \
            '\x00\x0b\x00\x0e' + \
            '\x74\x65\x73\x74\x20\x68\x6f\x73\x74\x00\x00\x00'

    def setUp_with_sack(self):
        self.flags = 0
        self.length = 16 + 2 * 2 * 5 + 4 * 5
        self.tsn_ack = 123456
        self.a_rwnd = 9876
        self.gapack_num = 5
        self.duptsn_num = 5
        self.gapacks = [[2, 3], [10, 12], [20, 24], [51, 52], [62, 63]]
        self.duptsns = [123458, 123466, 123476, 123507, 123518]

        self.sack = sctp.chunk_sack(
            tsn_ack=self.tsn_ack, a_rwnd=self.a_rwnd,
            gapack_num=self.gapack_num, duptsn_num=self.duptsn_num,
            gapacks=self.gapacks, duptsns=self.duptsns)

        self.chunks = [self.sack]

        self.sc = sctp.sctp(
            self.src_port, self.dst_port, self.vtag, self.csum,
            self.chunks)

        self.buf += '\x03\x00\x00\x38\x00\x01\xe2\x40' + \
            '\x00\x00\x26\x94\x00\x05\x00\x05' + \
            '\x00\x02\x00\x03\x00\x0a\x00\x0c\x00\x14\x00\x18' + \
            '\x00\x33\x00\x34\x00\x3e\x00\x3f' + \
            '\x00\x01\xe2\x42\x00\x01\xe2\x4a\x00\x01\xe2\x54' + \
            '\x00\x01\xe2\x73\x00\x01\xe2\x7e'

    def setUp_with_heartbeat(self):
        self.flags = 0
        self.length = 4 + 8

        self.p_heartbeat = sctp.param_heartbeat('\x01\x02\x03\x04')

        self.heartbeat = sctp.chunk_heartbeat(info=self.p_heartbeat)

        self.chunks = [self.heartbeat]

        self.sc = sctp.sctp(
            self.src_port, self.dst_port, self.vtag, self.csum,
            self.chunks)

        self.buf += '\x04\x00\x00\x0c' + \
            '\x00\x01\x00\x08' + \
            '\x01\x02\x03\x04'

    def setUp_with_heartbeat_ack(self):
        self.flags = 0
        self.length = 4 + 12

        self.p_heartbeat = sctp.param_heartbeat(
            '\xff\xee\xdd\xcc\xbb\xaa\x99\x88')

        self.heartbeat_ack = sctp.chunk_heartbeat_ack(info=self.p_heartbeat)

        self.chunks = [self.heartbeat_ack]

        self.sc = sctp.sctp(
            self.src_port, self.dst_port, self.vtag, self.csum,
            self.chunks)

        self.buf += '\x05\x00\x00\x10' + \
            '\x00\x01\x00\x0c' + \
            '\xff\xee\xdd\xcc\xbb\xaa\x99\x88'

    def setUp_with_abort(self):
        self.tflag = 0
        self.length = 4 + 8 + 16 + 8 + 4 + 20 + 8 + 4 + 8 + 8 + 4 + 12 \
            + 20 + 20

        self.c_invalid_stream_id = sctp.cause_invalid_stream_id(4096)
        self.c_missing_param = sctp.cause_missing_param(
            [sctp.PTYPE_IPV4, sctp.PTYPE_IPV6,
             sctp.PTYPE_COOKIE_PRESERVE, sctp.PTYPE_HOST_ADDR])
        self.c_stale_cookie = sctp.cause_stale_cookie('\x00\x00\x13\x88')
        self.c_out_of_resource = sctp.cause_out_of_resource()
        self.c_unresolvable_addr = sctp.cause_unresolvable_addr(
            sctp.param_host_addr('test host\x00'))
        self.c_unrecognized_chunk = sctp.cause_unrecognized_chunk(
            '\xff\x00\x00\x04')
        self.c_invalid_param = sctp.cause_invalid_param()
        self.c_unrecognized_param = sctp.cause_unrecognized_param(
            '\xff\xff\x00\x04')
        self.c_no_userdata = sctp.cause_no_userdata('\x00\x01\xe2\x40')
        self.c_cookie_while_shutdown = sctp.cause_cookie_while_shutdown()
        self.c_restart_with_new_addr = sctp.cause_restart_with_new_addr(
            sctp.param_ipv4('192.168.1.1'))
        self.c_user_initiated_abort = sctp.cause_user_initiated_abort(
            'Key Interrupt.\x00')
        self.c_protocol_violation = sctp.cause_protocol_violation(
            'Unknown reason.\x00')

        self.causes = [
            self.c_invalid_stream_id, self.c_missing_param,
            self.c_stale_cookie, self.c_out_of_resource,
            self.c_unresolvable_addr, self.c_unrecognized_chunk,
            self.c_invalid_param, self.c_unrecognized_param,
            self.c_no_userdata, self.c_cookie_while_shutdown,
            self.c_restart_with_new_addr, self.c_user_initiated_abort,
            self.c_protocol_violation]

        self.abort = sctp.chunk_abort(causes=self.causes)

        self.chunks = [self.abort]

        self.sc = sctp.sctp(
            self.src_port, self.dst_port, self.vtag, self.csum,
            self.chunks)

        self.buf += '\x06\x00\x00\x90' + \
            '\x00\x01\x00\x08\x10\x00\x00\x00' + \
            '\x00\x02\x00\x10\x00\x00\x00\x04' + \
            '\x00\x05\x00\x06\x00\x09\x00\x0b' + \
            '\x00\x03\x00\x08\x00\x00\x13\x88' + \
            '\x00\x04\x00\x04' + \
            '\x00\x05\x00\x14' + \
            '\x00\x0b\x00\x0e' + \
            '\x74\x65\x73\x74\x20\x68\x6f\x73\x74\x00\x00\x00' + \
            '\x00\x06\x00\x08\xff\x00\x00\x04' + \
            '\x00\x07\x00\x04' + \
            '\x00\x08\x00\x08\xff\xff\x00\x04' + \
            '\x00\x09\x00\x08\x00\x01\xe2\x40' + \
            '\x00\x0a\x00\x04' + \
            '\x00\x0b\x00\x0c' + \
            '\x00\x05\x00\x08\xc0\xa8\x01\x01' + \
            '\x00\x0c\x00\x13' + \
            '\x4b\x65\x79\x20\x49\x6e\x74\x65' + \
            '\x72\x72\x75\x70\x74\x2e\x00\x00' + \
            '\x00\x0d\x00\x14' + \
            '\x55\x6e\x6b\x6e\x6f\x77\x6e\x20' + \
            '\x72\x65\x61\x73\x6f\x6e\x2e\x00'

    def setUp_with_shutdown(self):
        self.flags = 0
        self.length = 8
        self.tsn_ack = 123456

        self.shutdown = sctp.chunk_shutdown(tsn_ack=self.tsn_ack)

        self.chunks = [self.shutdown]

        self.sc = sctp.sctp(
            self.src_port, self.dst_port, self.vtag, self.csum,
            self.chunks)

        self.buf += '\x07\x00\x00\x08\x00\x01\xe2\x40'

    def setUp_with_shutdown_ack(self):
        self.flags = 0
        self.length = 4

        self.shutdown_ack = sctp.chunk_shutdown_ack()

        self.chunks = [self.shutdown_ack]

        self.sc = sctp.sctp(
            self.src_port, self.dst_port, self.vtag, self.csum,
            self.chunks)

        self.buf += '\x08\x00\x00\x04'

    def setUp_with_error(self):
        self.flags = 0
        self.length = 4 + 8 + 16 + 8 + 4 + 20 + 8 + 4 + 8 + 8 + 4 + 12 \
            + 20 + 20

        self.c_invalid_stream_id = sctp.cause_invalid_stream_id(4096)
        self.c_missing_param = sctp.cause_missing_param(
            [sctp.PTYPE_IPV4, sctp.PTYPE_IPV6,
             sctp.PTYPE_COOKIE_PRESERVE, sctp.PTYPE_HOST_ADDR])
        self.c_stale_cookie = sctp.cause_stale_cookie('\x00\x00\x13\x88')
        self.c_out_of_resource = sctp.cause_out_of_resource()
        self.c_unresolvable_addr = sctp.cause_unresolvable_addr(
            sctp.param_host_addr('test host\x00'))
        self.c_unrecognized_chunk = sctp.cause_unrecognized_chunk(
            '\xff\x00\x00\x04')
        self.c_invalid_param = sctp.cause_invalid_param()
        self.c_unrecognized_param = sctp.cause_unrecognized_param(
            '\xff\xff\x00\x04')
        self.c_no_userdata = sctp.cause_no_userdata('\x00\x01\xe2\x40')
        self.c_cookie_while_shutdown = sctp.cause_cookie_while_shutdown()
        self.c_restart_with_new_addr = sctp.cause_restart_with_new_addr(
            sctp.param_ipv4('192.168.1.1'))
        self.c_user_initiated_abort = sctp.cause_user_initiated_abort(
            'Key Interrupt.\x00')
        self.c_protocol_violation = sctp.cause_protocol_violation(
            'Unknown reason.\x00')

        self.causes = [
            self.c_invalid_stream_id, self.c_missing_param,
            self.c_stale_cookie, self.c_out_of_resource,
            self.c_unresolvable_addr, self.c_unrecognized_chunk,
            self.c_invalid_param, self.c_unrecognized_param,
            self.c_no_userdata, self.c_cookie_while_shutdown,
            self.c_restart_with_new_addr, self.c_user_initiated_abort,
            self.c_protocol_violation]

        self.error = sctp.chunk_error(causes=self.causes)

        self.chunks = [self.error]

        self.sc = sctp.sctp(
            self.src_port, self.dst_port, self.vtag, self.csum,
            self.chunks)

        self.buf += '\x09\x00\x00\x90' + \
            '\x00\x01\x00\x08\x10\x00\x00\x00' + \
            '\x00\x02\x00\x10\x00\x00\x00\x04' + \
            '\x00\x05\x00\x06\x00\x09\x00\x0b' + \
            '\x00\x03\x00\x08\x00\x00\x13\x88' + \
            '\x00\x04\x00\x04' + \
            '\x00\x05\x00\x14' + \
            '\x00\x0b\x00\x0e' + \
            '\x74\x65\x73\x74\x20\x68\x6f\x73\x74\x00\x00\x00' + \
            '\x00\x06\x00\x08\xff\x00\x00\x04' + \
            '\x00\x07\x00\x04' + \
            '\x00\x08\x00\x08\xff\xff\x00\x04' + \
            '\x00\x09\x00\x08\x00\x01\xe2\x40' + \
            '\x00\x0a\x00\x04' + \
            '\x00\x0b\x00\x0c' + \
            '\x00\x05\x00\x08\xc0\xa8\x01\x01' + \
            '\x00\x0c\x00\x13' + \
            '\x4b\x65\x79\x20\x49\x6e\x74\x65' + \
            '\x72\x72\x75\x70\x74\x2e\x00\x00' + \
            '\x00\x0d\x00\x14' + \
            '\x55\x6e\x6b\x6e\x6f\x77\x6e\x20' + \
            '\x72\x65\x61\x73\x6f\x6e\x2e\x00'

    def setUp_with_cookie_echo(self):
        self.flags = 0
        self.length = 8
        self.cookie = '\x12\x34\x56\x78'

        self.cookie_echo = sctp.chunk_cookie_echo(cookie=self.cookie)

        self.chunks = [self.cookie_echo]

        self.sc = sctp.sctp(
            self.src_port, self.dst_port, self.vtag, self.csum,
            self.chunks)

        self.buf += '\x0a\x00\x00\x08\x12\x34\x56\x78'

    def setUp_with_cookie_ack(self):
        self.flags = 0
        self.length = 4

        self.cookie_ack = sctp.chunk_cookie_ack()

        self.chunks = [self.cookie_ack]

        self.sc = sctp.sctp(
            self.src_port, self.dst_port, self.vtag, self.csum,
            self.chunks)

        self.buf += '\x0b\x00\x00\x04'

    def setUp_with_ecn_echo(self):
        self.flags = 0
        self.length = 8
        self.low_tsn = 123456

        self.ecn_echo = sctp.chunk_ecn_echo(low_tsn=self.low_tsn)

        self.chunks = [self.ecn_echo]

        self.sc = sctp.sctp(
            self.src_port, self.dst_port, self.vtag, self.csum,
            self.chunks)

        self.buf += '\x0c\x00\x00\x08\x00\x01\xe2\x40'

    def setUp_with_cwr(self):
        self.flags = 0
        self.length = 8
        self.low_tsn = 123456

        self.cwr = sctp.chunk_cwr(low_tsn=self.low_tsn)

        self.chunks = [self.cwr]

        self.sc = sctp.sctp(
            self.src_port, self.dst_port, self.vtag, self.csum,
            self.chunks)

        self.buf += '\x0d\x00\x00\x08\x00\x01\xe2\x40'

    def setUp_with_shutdown_complete(self):
        self.tflag = 0
        self.length = 4

        self.shutdown_complete = sctp.chunk_shutdown_complete()

        self.chunks = [self.shutdown_complete]

        self.sc = sctp.sctp(
            self.src_port, self.dst_port, self.vtag, self.csum,
            self.chunks)

        self.buf += '\x0e\x00\x00\x04'

    def setUp_with_multi_chunks(self):
        self.s_flags = 0
        self.s_length = 16
        self.s_tsn_ack = 123456
        self.s_a_rwnd = 9876
        self.s_gapack_num = 0
        self.s_duptsn_num = 0
        self.s_gapacks = None
        self.s_duptsns = None

        self.sack = sctp.chunk_sack(
            tsn_ack=self.s_tsn_ack, a_rwnd=self.s_a_rwnd)

        self.d1_unordered = 0
        self.d1_begin = 1
        self.d1_end = 0
        self.d1_length = 16 + 10
        self.d1_tsn = 12345
        self.d1_sid = 1
        self.d1_seq = 0
        self.d1_payload_id = 0
        self.d1_payload_data = '\x01\x02\x03\x04\x05\x06\x07\x08\x09\x0a'

        self.data1 = sctp.chunk_data(
            begin=self.d1_begin, tsn=self.d1_tsn, sid=self.d1_sid,
            payload_data=self.d1_payload_data)

        self.d2_unordered = 0
        self.d2_begin = 0
        self.d2_end = 1
        self.d2_length = 16 + 10
        self.d2_tsn = 12346
        self.d2_sid = 1
        self.d2_seq = 1
        self.d2_payload_id = 0
        self.d2_payload_data = '\x11\x12\x13\x14\x15\x16\x17\x18\x19\x1a'

        self.data2 = sctp.chunk_data(
            end=self.d2_end, tsn=self.d2_tsn, sid=self.d2_sid,
            seq=self.d2_seq, payload_data=self.d2_payload_data)

        self.chunks = [self.sack, self.data1, self.data2]

        self.sc = sctp.sctp(
            self.src_port, self.dst_port, self.vtag, self.csum,
            self.chunks)

        self.buf += '\x03\x00\x00\x10\x00\x01\xe2\x40' + \
            '\x00\x00\x26\x94\x00\x00\x00\x00' + \
            '\x00\x02\x00\x1a\x00\x00\x30\x39\x00\x01\x00\x00' + \
            '\x00\x00\x00\x00\x01\x02\x03\x04\x05\x06\x07\x08\x09\x0a' + \
            '\x00\x01\x00\x1a\x00\x00\x30\x3a\x00\x01\x00\x01' + \
            '\x00\x00\x00\x00\x11\x12\x13\x14\x15\x16\x17\x18\x19\x1a'

    def tearDown(self):
        pass

    def test_init(self):
        eq_(self.src_port, self.sc.src_port)
        eq_(self.dst_port, self.sc.dst_port)
        eq_(self.vtag, self.sc.vtag)
        eq_(self.csum, self.sc.csum)
        eq_(self.chunks, self.sc.chunks)

    def test_init_with_data(self):
        self.setUp_with_data()
        self.test_init()

    def test_init_with_init(self):
        self.setUp_with_init()
        self.test_init()

    def test_init_with_init_ack(self):
        self.setUp_with_init_ack()
        self.test_init()

    def test_init_with_sack(self):
        self.setUp_with_sack()
        self.test_init()

    def test_init_with_heartbeat(self):
        self.setUp_with_heartbeat()
        self.test_init()

    def test_init_with_heartbeat_ack(self):
        self.setUp_with_heartbeat_ack()
        self.test_init()

    def test_init_with_abort(self):
        self.setUp_with_abort()
        self.test_init()

    def test_init_with_shutdown(self):
        self.setUp_with_shutdown()
        self.test_init()

    def test_init_with_shutdown_ack(self):
        self.setUp_with_shutdown_ack()
        self.test_init()

    def test_init_with_error(self):
        self.setUp_with_error()
        self.test_init()

    def test_init_with_cookie_echo(self):
        self.setUp_with_cookie_echo()
        self.test_init()

    def test_init_with_cookie_ack(self):
        self.setUp_with_cookie_ack()
        self.test_init()

    def test_init_with_ecn_echo(self):
        self.setUp_with_ecn_echo()
        self.test_init()

    def test_init_with_cwr(self):
        self.setUp_with_cwr()
        self.test_init()

    def test_init_with_shutdown_complete(self):
        self.setUp_with_shutdown_complete()
        self.test_init()

    def test_init_with_multi_chunks(self):
        self.setUp_with_multi_chunks()
        self.test_init()

    def test_parser(self):
        _res = self.sc.parser(str(self.buf))
        if type(_res) is tuple:
            res = _res[0]
        else:
            res = _res
        # to calculate the lengths of parameters.
        self.sc.serialize(None, None)

        eq_(self.src_port, res.src_port)
        eq_(self.dst_port, res.dst_port)
        eq_(self.vtag, res.vtag)
        eq_(self.csum, res.csum)
        eq_(str(self.chunks), str(res.chunks))

    def test_parser_with_data(self):
        self.setUp_with_data()
        self.test_parser()

    def test_parser_with_init(self):
        self.setUp_with_init()
        self.test_parser()

    def test_parser_with_init_ack(self):
        self.setUp_with_init_ack()
        self.test_parser()

    def test_parser_with_sack(self):
        self.setUp_with_sack()
        self.test_parser()

    def test_parser_with_heartbeat(self):
        self.setUp_with_heartbeat()
        self.test_parser()

    def test_parser_with_heartbeat_ack(self):
        self.setUp_with_heartbeat_ack()
        self.test_parser()

    def test_parser_with_abort(self):
        self.setUp_with_abort()
        self.test_parser()

    def test_parser_with_shutdown(self):
        self.setUp_with_shutdown()
        self.test_parser()

    def test_parser_with_shutdown_ack(self):
        self.setUp_with_shutdown_ack()
        self.test_parser()

    def test_parser_with_error(self):
        self.setUp_with_error()
        self.test_parser()

    def test_parser_with_cookie_echo(self):
        self.setUp_with_cookie_echo()
        self.test_parser()

    def test_parser_with_cookie_ack(self):
        self.setUp_with_cookie_ack()
        self.test_parser()

    def test_parser_with_ecn_echo(self):
        self.setUp_with_ecn_echo()
        self.test_parser()

    def test_parser_with_cwr(self):
        self.setUp_with_cwr()
        self.test_parser()

    def test_parser_with_shutdown_complete(self):
        self.setUp_with_shutdown_complete()
        self.test_parser()

    def test_parser_with_multi_chunks(self):
        self.setUp_with_multi_chunks()
        self.test_parser()

    def _test_serialize(self):
        buf = self.sc.serialize(bytearray(), None)
        res = struct.unpack_from(sctp.sctp._PACK_STR, buf)
        eq_(self.src_port, res[0])
        eq_(self.dst_port, res[1])
        eq_(self.vtag, res[2])
        # skip compare checksum
        #eq_(self.csum, res[3])

        return buf[sctp.sctp._MIN_LEN:]

    def test_serialize(self):
        self._test_serialize()

    def test_serialize_with_data(self):
        self.setUp_with_data()
        buf = self._test_serialize()
        res = struct.unpack_from(sctp.chunk_data._PACK_STR, buf)
        eq_(sctp.chunk_data.chunk_type(), res[0])
        flags = (
            (self.unordered << 2) |
            (self.begin << 1) |
            (self.end << 0))
        eq_(flags, res[1])
        eq_(self.length, res[2])
        eq_(self.tsn, res[3])
        eq_(self.sid, res[4])
        eq_(self.seq, res[5])
        eq_(self.payload_id, res[6])
        eq_(self.payload_data, buf[sctp.chunk_data._MIN_LEN:])

    def test_serialize_with_init(self):
        self.setUp_with_init()
        buf = self._test_serialize()
        res = struct.unpack_from(sctp.chunk_init._PACK_STR, buf)
        eq_(sctp.chunk_init.chunk_type(), res[0])
        eq_(self.flags, res[1])
        eq_(self.length, res[2])
        eq_(self.init_tag, res[3])
        eq_(self.a_rwnd, res[4])
        eq_(self.os, res[5])
        eq_(self.mis, res[6])
        eq_(self.i_tsn, res[7])

        buf = buf[sctp.chunk_init._MIN_LEN:]
        res1 = struct.unpack_from(sctp.param_ipv4._PACK_STR, buf)
        eq_(sctp.param_ipv4.param_type(), res1[0])
        eq_(8, res1[1])
        eq_('192.168.1.1', addrconv.ipv4.bin_to_text(
            buf[sctp.param_ipv4._MIN_LEN:sctp.param_ipv4._MIN_LEN + 4]))

        buf = buf[8:]
        res2 = struct.unpack_from(sctp.param_ipv6._PACK_STR, buf)
        eq_(sctp.param_ipv6.param_type(), res2[0])
        eq_(20, res2[1])
        eq_('fe80::647e:1aff:fec4:8284', addrconv.ipv6.bin_to_text(
            buf[sctp.param_ipv6._MIN_LEN:sctp.param_ipv6._MIN_LEN + 16]))

        buf = buf[20:]
        res3 = struct.unpack_from(sctp.param_cookie_preserve._PACK_STR,
                                  buf)
        eq_(sctp.param_cookie_preserve.param_type(), res3[0])
        eq_(8, res3[1])
        eq_(5000, res3[2])

        buf = buf[8:]
        res4 = struct.unpack_from(sctp.param_ecn._PACK_STR, buf)
        eq_(sctp.param_ecn.param_type(), res4[0])
        eq_(4, res4[1])

        buf = buf[4:]
        res5 = struct.unpack_from(sctp.param_host_addr._PACK_STR, buf)
        eq_(sctp.param_host_addr.param_type(), res5[0])
        eq_(14, res5[1])
        eq_('test host\x00',
            buf[sctp.param_host_addr._MIN_LEN:
                sctp.param_host_addr._MIN_LEN + 10])

        buf = buf[16:]
        res6 = struct.unpack_from(sctp.param_supported_addr._PACK_STR, buf)
        res6 = list(res6)
        eq_(sctp.param_supported_addr.param_type(), res6[0])
        eq_(14, res6[1])
        buf = buf[sctp.param_supported_addr._MIN_LEN:]
        offset = 0
        tmplist = []
        while offset < len(buf):
            (tmp, ) = struct.unpack_from('!H', buf, offset)
            tmplist.append(tmp)
            offset += struct.calcsize('!H')
        res6.extend(tmplist)
        eq_(sctp.PTYPE_IPV4, res6[2])
        eq_(sctp.PTYPE_IPV6, res6[3])
        eq_(sctp.PTYPE_COOKIE_PRESERVE, res6[4])
        eq_(sctp.PTYPE_ECN, res6[5])
        eq_(sctp.PTYPE_HOST_ADDR, res6[6])

    def test_serialize_with_init_ack(self):
        self.setUp_with_init_ack()
        buf = self._test_serialize()
        res = struct.unpack_from(sctp.chunk_init_ack._PACK_STR, buf)
        eq_(sctp.chunk_init_ack.chunk_type(), res[0])
        eq_(self.flags, res[1])
        eq_(self.length, res[2])
        eq_(self.init_tag, res[3])
        eq_(self.a_rwnd, res[4])
        eq_(self.os, res[5])
        eq_(self.mis, res[6])
        eq_(self.i_tsn, res[7])

        buf = buf[sctp.chunk_init_ack._MIN_LEN:]
        res1 = struct.unpack_from(sctp.param_state_cookie._PACK_STR, buf)
        eq_(sctp.param_state_cookie.param_type(), res1[0])
        eq_(7, res1[1])
        eq_('\x01\x02\x03',
            buf[sctp.param_state_cookie._MIN_LEN:
                sctp.param_state_cookie._MIN_LEN + 3])

        buf = buf[8:]
        res2 = struct.unpack_from(sctp.param_ipv4._PACK_STR, buf)
        eq_(sctp.param_ipv4.param_type(), res2[0])
        eq_(8, res2[1])
        eq_('192.168.1.1', addrconv.ipv4.bin_to_text(
            buf[sctp.param_ipv4._MIN_LEN:sctp.param_ipv4._MIN_LEN + 4]))

        buf = buf[8:]
        res3 = struct.unpack_from(sctp.param_ipv6._PACK_STR, buf)
        eq_(sctp.param_ipv6.param_type(), res3[0])
        eq_(20, res3[1])
        eq_('fe80::647e:1aff:fec4:8284', addrconv.ipv6.bin_to_text(
            buf[sctp.param_ipv6._MIN_LEN:sctp.param_ipv6._MIN_LEN + 16]))

        buf = buf[20:]
        res4 = struct.unpack_from(
            sctp.param_unrecognized_param._PACK_STR, buf)
        eq_(sctp.param_unrecognized_param.param_type(), res4[0])
        eq_(8, res4[1])
        eq_('\xff\xff\x00\x04',
            buf[sctp.param_unrecognized_param._MIN_LEN:
                sctp.param_unrecognized_param._MIN_LEN + 4])

        buf = buf[8:]
        res5 = struct.unpack_from(sctp.param_ecn._PACK_STR, buf)
        eq_(sctp.param_ecn.param_type(), res5[0])
        eq_(4, res5[1])

        buf = buf[4:]
        res6 = struct.unpack_from(sctp.param_host_addr._PACK_STR, buf)
        eq_(sctp.param_host_addr.param_type(), res6[0])
        eq_(14, res6[1])
        eq_('test host\x00',
            buf[sctp.param_host_addr._MIN_LEN:
                sctp.param_host_addr._MIN_LEN + 10])

    def test_serialize_with_sack(self):
        self.setUp_with_sack()
        buf = self._test_serialize()
        res = struct.unpack_from(sctp.chunk_sack._PACK_STR, buf)
        eq_(sctp.chunk_sack.chunk_type(), res[0])
        eq_(self.flags, res[1])
        eq_(self.length, res[2])
        eq_(self.tsn_ack, res[3])
        eq_(self.a_rwnd, res[4])
        eq_(self.gapack_num, res[5])
        eq_(self.duptsn_num, res[6])

        buf = buf[sctp.chunk_sack._MIN_LEN:]
        gapacks = []
        for _ in range(self.gapack_num):
            (gap_s, gap_e) = struct.unpack_from(
                sctp.chunk_sack._GAPACK_STR, buf)
            one = [gap_s, gap_e]
            gapacks.append(one)
            buf = buf[sctp.chunk_sack._GAPACK_LEN:]
        duptsns = []
        for _ in range(self.duptsn_num):
            (duptsn, ) = struct.unpack_from(
                sctp.chunk_sack._DUPTSN_STR, buf)
            duptsns.append(duptsn)
            buf = buf[sctp.chunk_sack._DUPTSN_LEN:]
        eq_(self.gapacks, gapacks)
        eq_(self.duptsns, duptsns)

    def test_serialize_with_heartbeat(self):
        self.setUp_with_heartbeat()
        buf = self._test_serialize()
        res = struct.unpack_from(sctp.chunk_heartbeat._PACK_STR, buf)
        eq_(sctp.chunk_heartbeat.chunk_type(), res[0])
        eq_(self.flags, res[1])
        eq_(self.length, res[2])

        buf = buf[sctp.chunk_heartbeat._MIN_LEN:]
        res1 = struct.unpack_from(sctp.param_heartbeat._PACK_STR, buf)
        eq_(sctp.param_heartbeat.param_type(), res1[0])
        eq_(8, res1[1])
        eq_('\x01\x02\x03\x04',
            buf[sctp.param_heartbeat._MIN_LEN:
                sctp.param_heartbeat._MIN_LEN + 4])

    def test_serialize_with_heartbeat_ack(self):
        self.setUp_with_heartbeat_ack()
        buf = self._test_serialize()
        res = struct.unpack_from(sctp.chunk_heartbeat_ack._PACK_STR, buf)
        eq_(sctp.chunk_heartbeat_ack.chunk_type(), res[0])
        eq_(self.flags, res[1])
        eq_(self.length, res[2])

        buf = buf[sctp.chunk_heartbeat_ack._MIN_LEN:]
        res1 = struct.unpack_from(sctp.param_heartbeat._PACK_STR, buf)
        eq_(sctp.param_heartbeat.param_type(), res1[0])
        eq_(12, res1[1])
        eq_('\xff\xee\xdd\xcc\xbb\xaa\x99\x88',
            buf[sctp.param_heartbeat._MIN_LEN:
                sctp.param_heartbeat._MIN_LEN + 8])

    def test_serialize_with_abort(self):
        self.setUp_with_abort()
        buf = self._test_serialize()
        res = struct.unpack_from(sctp.chunk_abort._PACK_STR, buf)
        eq_(sctp.chunk_abort.chunk_type(), res[0])
        flags = self.tflag << 0
        eq_(flags, res[1])
        eq_(self.length, res[2])

        buf = buf[sctp.chunk_abort._MIN_LEN:]
        res1 = struct.unpack_from(sctp.cause_invalid_stream_id._PACK_STR, buf)
        eq_(sctp.cause_invalid_stream_id.cause_code(), res1[0])
        eq_(8, res1[1])
        eq_(4096, res1[2])

        buf = buf[8:]
        res2 = struct.unpack_from(sctp.cause_missing_param._PACK_STR, buf)
        eq_(sctp.cause_missing_param.cause_code(), res2[0])
        eq_(16, res2[1])
        eq_(4, res2[2])
        types = []
        for count in range(4):
            (tmp, ) = struct.unpack_from(
                '!H', buf, sctp.cause_missing_param._MIN_LEN + 2 * count)
            types.append(tmp)
        eq_(str([sctp.PTYPE_IPV4, sctp.PTYPE_IPV6,
                 sctp.PTYPE_COOKIE_PRESERVE, sctp.PTYPE_HOST_ADDR]),
            str(types))

        buf = buf[16:]
        res3 = struct.unpack_from(sctp.cause_stale_cookie._PACK_STR, buf)
        eq_(sctp.cause_stale_cookie.cause_code(), res3[0])
        eq_(8, res3[1])
        eq_('\x00\x00\x13\x88',
            buf[sctp.cause_stale_cookie._MIN_LEN:
                sctp.cause_stale_cookie._MIN_LEN + 4])

        buf = buf[8:]
        res4 = struct.unpack_from(sctp.cause_out_of_resource._PACK_STR, buf)
        eq_(sctp.cause_out_of_resource.cause_code(), res4[0])
        eq_(4, res4[1])

        buf = buf[4:]
        res5 = struct.unpack_from(
            sctp.cause_unresolvable_addr._PACK_STR, buf)
        eq_(sctp.cause_unresolvable_addr.cause_code(), res5[0])
        eq_(20, res5[1])
        eq_('\x00\x0b\x00\x0e\x74\x65\x73\x74' +
            '\x20\x68\x6f\x73\x74\x00\x00\x00',
            buf[sctp.cause_unresolvable_addr._MIN_LEN:
                sctp.cause_unresolvable_addr._MIN_LEN + 16])

        buf = buf[20:]
        res6 = struct.unpack_from(
            sctp.cause_unrecognized_chunk._PACK_STR, buf)
        eq_(sctp.cause_unrecognized_chunk.cause_code(), res6[0])
        eq_(8, res6[1])
        eq_('\xff\x00\x00\x04',
            buf[sctp.cause_unrecognized_chunk._MIN_LEN:
                sctp.cause_unrecognized_chunk._MIN_LEN + 4])

        buf = buf[8:]
        res7 = struct.unpack_from(sctp.cause_invalid_param._PACK_STR, buf)
        eq_(sctp.cause_invalid_param.cause_code(), res7[0])
        eq_(4, res7[1])

        buf = buf[4:]
        res8 = struct.unpack_from(
            sctp.cause_unrecognized_param._PACK_STR, buf)
        eq_(sctp.cause_unrecognized_param.cause_code(), res8[0])
        eq_(8, res8[1])
        eq_('\xff\xff\x00\x04',
            buf[sctp.cause_unrecognized_param._MIN_LEN:
                sctp.cause_unrecognized_param._MIN_LEN + 4])

        buf = buf[8:]
        res9 = struct.unpack_from(sctp.cause_no_userdata._PACK_STR, buf)
        eq_(sctp.cause_no_userdata.cause_code(), res9[0])
        eq_(8, res9[1])
        eq_('\x00\x01\xe2\x40',
            buf[sctp.cause_no_userdata._MIN_LEN:
                sctp.cause_no_userdata._MIN_LEN + 4])

        buf = buf[8:]
        res10 = struct.unpack_from(
            sctp.cause_cookie_while_shutdown._PACK_STR, buf)
        eq_(sctp.cause_cookie_while_shutdown.cause_code(), res10[0])
        eq_(4, res10[1])

        buf = buf[4:]
        res11 = struct.unpack_from(
            sctp.cause_restart_with_new_addr._PACK_STR, buf)
        eq_(sctp.cause_restart_with_new_addr.cause_code(), res11[0])
        eq_(12, res11[1])
        eq_('\x00\x05\x00\x08\xc0\xa8\x01\x01',
            buf[sctp.cause_restart_with_new_addr._MIN_LEN:
                sctp.cause_restart_with_new_addr._MIN_LEN + 8])

        buf = buf[12:]
        res12 = struct.unpack_from(
            sctp.cause_user_initiated_abort._PACK_STR, buf)
        eq_(sctp.cause_user_initiated_abort.cause_code(), res12[0])
        eq_(19, res12[1])
        eq_('Key Interrupt.\x00',
            buf[sctp.cause_user_initiated_abort._MIN_LEN:
                sctp.cause_user_initiated_abort._MIN_LEN + 15])

        buf = buf[20:]
        res13 = struct.unpack_from(
            sctp.cause_protocol_violation._PACK_STR, buf)
        eq_(sctp.cause_protocol_violation.cause_code(), res13[0])
        eq_(20, res13[1])
        eq_('Unknown reason.\x00',
            buf[sctp.cause_protocol_violation._MIN_LEN:
                sctp.cause_protocol_violation._MIN_LEN + 16])

    def test_serialize_with_shutdown(self):
        self.setUp_with_shutdown()
        buf = self._test_serialize()
        res = struct.unpack_from(sctp.chunk_shutdown._PACK_STR, buf)
        eq_(sctp.chunk_shutdown.chunk_type(), res[0])
        eq_(self.flags, res[1])
        eq_(self.length, res[2])
        eq_(self.tsn_ack, res[3])

    def test_serialize_with_shutdown_ack(self):
        self.setUp_with_shutdown_ack()
        buf = self._test_serialize()
        res = struct.unpack_from(sctp.chunk_shutdown_ack._PACK_STR, buf)
        eq_(sctp.chunk_shutdown_ack.chunk_type(), res[0])
        eq_(self.flags, res[1])
        eq_(self.length, res[2])

    def test_serialize_with_error(self):
        self.setUp_with_error()
        buf = self._test_serialize()
        res = struct.unpack_from(sctp.chunk_error._PACK_STR, buf)
        eq_(sctp.chunk_error.chunk_type(), res[0])
        eq_(self.flags, res[1])
        eq_(self.length, res[2])

        buf = buf[sctp.chunk_error._MIN_LEN:]
        res1 = struct.unpack_from(sctp.cause_invalid_stream_id._PACK_STR, buf)
        eq_(sctp.cause_invalid_stream_id.cause_code(), res1[0])
        eq_(8, res1[1])
        eq_(4096, res1[2])

        buf = buf[8:]
        res2 = struct.unpack_from(sctp.cause_missing_param._PACK_STR, buf)
        eq_(sctp.cause_missing_param.cause_code(), res2[0])
        eq_(16, res2[1])
        eq_(4, res2[2])
        types = []
        for count in range(4):
            (tmp, ) = struct.unpack_from(
                '!H', buf, sctp.cause_missing_param._MIN_LEN + 2 * count)
            types.append(tmp)
        eq_(str([sctp.PTYPE_IPV4, sctp.PTYPE_IPV6,
                 sctp.PTYPE_COOKIE_PRESERVE, sctp.PTYPE_HOST_ADDR]),
            str(types))

        buf = buf[16:]
        res3 = struct.unpack_from(sctp.cause_stale_cookie._PACK_STR, buf)
        eq_(sctp.cause_stale_cookie.cause_code(), res3[0])
        eq_(8, res3[1])
        eq_('\x00\x00\x13\x88',
            buf[sctp.cause_stale_cookie._MIN_LEN:
                sctp.cause_stale_cookie._MIN_LEN + 4])

        buf = buf[8:]
        res4 = struct.unpack_from(sctp.cause_out_of_resource._PACK_STR, buf)
        eq_(sctp.cause_out_of_resource.cause_code(), res4[0])
        eq_(4, res4[1])

        buf = buf[4:]
        res5 = struct.unpack_from(
            sctp.cause_unresolvable_addr._PACK_STR, buf)
        eq_(sctp.cause_unresolvable_addr.cause_code(), res5[0])
        eq_(20, res5[1])
        eq_('\x00\x0b\x00\x0e\x74\x65\x73\x74' +
            '\x20\x68\x6f\x73\x74\x00\x00\x00',
            buf[sctp.cause_unresolvable_addr._MIN_LEN:
                sctp.cause_unresolvable_addr._MIN_LEN + 16])

        buf = buf[20:]
        res6 = struct.unpack_from(
            sctp.cause_unrecognized_chunk._PACK_STR, buf)
        eq_(sctp.cause_unrecognized_chunk.cause_code(), res6[0])
        eq_(8, res6[1])
        eq_('\xff\x00\x00\x04',
            buf[sctp.cause_unrecognized_chunk._MIN_LEN:
                sctp.cause_unrecognized_chunk._MIN_LEN + 4])

        buf = buf[8:]
        res7 = struct.unpack_from(sctp.cause_invalid_param._PACK_STR, buf)
        eq_(sctp.cause_invalid_param.cause_code(), res7[0])
        eq_(4, res7[1])

        buf = buf[4:]
        res8 = struct.unpack_from(
            sctp.cause_unrecognized_param._PACK_STR, buf)
        eq_(sctp.cause_unrecognized_param.cause_code(), res8[0])
        eq_(8, res8[1])
        eq_('\xff\xff\x00\x04',
            buf[sctp.cause_unrecognized_param._MIN_LEN:
                sctp.cause_unrecognized_param._MIN_LEN + 4])

        buf = buf[8:]
        res9 = struct.unpack_from(sctp.cause_no_userdata._PACK_STR, buf)
        eq_(sctp.cause_no_userdata.cause_code(), res9[0])
        eq_(8, res9[1])
        eq_('\x00\x01\xe2\x40',
            buf[sctp.cause_no_userdata._MIN_LEN:
                sctp.cause_no_userdata._MIN_LEN + 4])

        buf = buf[8:]
        res10 = struct.unpack_from(
            sctp.cause_cookie_while_shutdown._PACK_STR, buf)
        eq_(sctp.cause_cookie_while_shutdown.cause_code(), res10[0])
        eq_(4, res10[1])

        buf = buf[4:]
        res11 = struct.unpack_from(
            sctp.cause_restart_with_new_addr._PACK_STR, buf)
        eq_(sctp.cause_restart_with_new_addr.cause_code(), res11[0])
        eq_(12, res11[1])
        eq_('\x00\x05\x00\x08\xc0\xa8\x01\x01',
            buf[sctp.cause_restart_with_new_addr._MIN_LEN:
                sctp.cause_restart_with_new_addr._MIN_LEN + 8])

        buf = buf[12:]
        res12 = struct.unpack_from(
            sctp.cause_user_initiated_abort._PACK_STR, buf)
        eq_(sctp.cause_user_initiated_abort.cause_code(), res12[0])
        eq_(19, res12[1])
        eq_('Key Interrupt.\x00',
            buf[sctp.cause_user_initiated_abort._MIN_LEN:
                sctp.cause_user_initiated_abort._MIN_LEN + 15])

        buf = buf[20:]
        res13 = struct.unpack_from(
            sctp.cause_protocol_violation._PACK_STR, buf)
        eq_(sctp.cause_protocol_violation.cause_code(), res13[0])
        eq_(20, res13[1])
        eq_('Unknown reason.\x00',
            buf[sctp.cause_protocol_violation._MIN_LEN:
                sctp.cause_protocol_violation._MIN_LEN + 16])

    def test_serialize_with_cookie_echo(self):
        self.setUp_with_cookie_echo()
        buf = self._test_serialize()
        res = struct.unpack_from(sctp.chunk_cookie_echo._PACK_STR, buf)
        eq_(sctp.chunk_cookie_echo.chunk_type(), res[0])
        eq_(self.flags, res[1])
        eq_(self.length, res[2])
        eq_(self.cookie,
            buf[sctp.chunk_cookie_echo._MIN_LEN:
                sctp.chunk_cookie_echo._MIN_LEN + 4])

    def test_serialize_with_cookie_ack(self):
        self.setUp_with_cookie_ack()
        buf = self._test_serialize()
        res = struct.unpack_from(sctp.chunk_cookie_ack._PACK_STR, buf)
        eq_(sctp.chunk_cookie_ack.chunk_type(), res[0])
        eq_(self.flags, res[1])
        eq_(self.length, res[2])

    def test_serialize_with_ecn_echo(self):
        self.setUp_with_ecn_echo()
        buf = self._test_serialize()
        res = struct.unpack_from(sctp.chunk_ecn_echo._PACK_STR, buf)
        eq_(sctp.chunk_ecn_echo.chunk_type(), res[0])
        eq_(self.flags, res[1])
        eq_(self.length, res[2])
        eq_(self.low_tsn, res[3])

    def test_serialize_with_cwr(self):
        self.setUp_with_cwr()
        buf = self._test_serialize()
        res = struct.unpack_from(sctp.chunk_cwr._PACK_STR, buf)
        eq_(sctp.chunk_cwr.chunk_type(), res[0])
        eq_(self.flags, res[1])
        eq_(self.length, res[2])
        eq_(self.low_tsn, res[3])

    def test_serialize_with_shutdown_complete(self):
        self.setUp_with_shutdown_complete()
        buf = self._test_serialize()
        res = struct.unpack_from(
            sctp.chunk_shutdown_complete._PACK_STR, buf)
        eq_(sctp.chunk_shutdown_complete.chunk_type(), res[0])
        flags = self.tflag << 0
        eq_(flags, res[1])
        eq_(self.length, res[2])

    def test_serialize_with_multi_chunks(self):
        self.setUp_with_multi_chunks()
        buf = self._test_serialize()
        res = struct.unpack_from(sctp.chunk_sack._PACK_STR, buf)
        eq_(sctp.chunk_sack.chunk_type(), res[0])
        eq_(self.s_flags, res[1])
        eq_(self.s_length, res[2])
        eq_(self.s_tsn_ack, res[3])
        eq_(self.s_a_rwnd, res[4])
        eq_(self.s_gapack_num, res[5])
        eq_(self.s_duptsn_num, res[6])

        buf = buf[self.s_length:]
        res = struct.unpack_from(sctp.chunk_data._PACK_STR, buf)
        eq_(sctp.chunk_data.chunk_type(), res[0])
        d1_flags = (
            (self.d1_unordered << 2) |
            (self.d1_begin << 1) |
            (self.d1_end << 0))
        eq_(d1_flags, res[1])
        eq_(self.d1_length, res[2])
        eq_(self.d1_tsn, res[3])
        eq_(self.d1_sid, res[4])
        eq_(self.d1_seq, res[5])
        eq_(self.d1_payload_id, res[6])
        eq_(self.d1_payload_data,
            buf[sctp.chunk_data._MIN_LEN:
                sctp.chunk_data._MIN_LEN + 10])

        buf = buf[self.d1_length:]
        res = struct.unpack_from(sctp.chunk_data._PACK_STR, buf)
        eq_(sctp.chunk_data.chunk_type(), res[0])
        d2_flags = (
            (self.d2_unordered << 2) |
            (self.d2_begin << 1) |
            (self.d2_end << 0))
        eq_(d2_flags, res[1])
        eq_(self.d2_length, res[2])
        eq_(self.d2_tsn, res[3])
        eq_(self.d2_sid, res[4])
        eq_(self.d2_seq, res[5])
        eq_(self.d2_payload_id, res[6])
        eq_(self.d2_payload_data,
            buf[sctp.chunk_data._MIN_LEN:
                sctp.chunk_data._MIN_LEN + 10])

    def test_build_sctp(self):
        eth = ethernet.ethernet('00:aa:aa:aa:aa:aa', '00:bb:bb:bb:bb:bb',
                                ether.ETH_TYPE_IP)
        ip4 = ipv4.ipv4(4, 5, 16, 0, 0, 2, 0, 64, inet.IPPROTO_SCTP, 0,
                        '192.168.1.1', '10.144.1.1')
        pkt = eth/ip4/self.sc

        eth = pkt.get_protocol(ethernet.ethernet)
        ok_(eth)
        eq_(eth.ethertype, ether.ETH_TYPE_IP)

        ip4 = pkt.get_protocol(ipv4.ipv4)
        ok_(ip4)
        eq_(ip4.proto, inet.IPPROTO_SCTP)

        sc = pkt.get_protocol(sctp.sctp)
        ok_(sc)
        eq_(sc, self.sc)

    def test_build_sctp_with_data(self):
        self.setUp_with_data()
        self.test_build_sctp()

    def test_build_sctp_with_init(self):
        self.setUp_with_init()
        self.test_build_sctp()

    def test_build_sctp_with_init_ack(self):
        self.setUp_with_init_ack()
        self.test_build_sctp()

    def test_build_sctp_with_sack(self):
        self.setUp_with_sack()
        self.test_build_sctp()

    def test_build_sctp_with_heartbeat(self):
        self.setUp_with_heartbeat()
        self.test_build_sctp()

    def test_build_sctp_with_heartbeat_ack(self):
        self.setUp_with_heartbeat_ack()
        self.test_build_sctp()

    def test_build_sctp_with_abort(self):
        self.setUp_with_abort()
        self.test_build_sctp()

    def test_build_sctp_with_shutdown(self):
        self.setUp_with_shutdown()
        self.test_build_sctp()

    def test_build_sctp_with_shutdown_ack(self):
        self.setUp_with_shutdown_ack()
        self.test_build_sctp()

    def test_build_sctp_with_error(self):
        self.setUp_with_error()
        self.test_build_sctp()

    def test_build_sctp_with_cookie_echo(self):
        self.setUp_with_cookie_echo()
        self.test_build_sctp()

    def test_build_sctp_with_cookie_ack(self):
        self.setUp_with_cookie_ack()
        self.test_build_sctp()

    def test_build_sctp_with_ecn_echo(self):
        self.setUp_with_ecn_echo()
        self.test_build_sctp()

    def test_build_sctp_with_cwr(self):
        self.setUp_with_cwr()
        self.test_build_sctp()

    def test_build_sctp_with_shutdown_complete(self):
        self.setUp_with_shutdown_complete()
        self.test_build_sctp()

    def tset_build_sctp_with_multi_chunks(self):
        self.setUp_with_multi_chunks()
        self.test_build_sctp()

    def test_to_string(self):
        sctp_values = {'src_port': self.src_port,
                       'dst_port': self.dst_port,
                       'vtag': self.vtag,
                       'csum': self.csum,
                       'chunks': self.chunks}
        _sctp_str = ','.join(['%s=%s' % (k, sctp_values[k])
                              for k, _ in inspect.getmembers(self.sc)
                              if k in sctp_values])
        sctp_str = '%s(%s)' % (sctp.sctp.__name__, _sctp_str)

        eq_(str(self.sc), sctp_str)
        eq_(repr(self.sc), sctp_str)

    def test_to_string_with_data(self):
        self.setUp_with_data()
        self.test_to_string()

    def test_to_string_with_init(self):
        self.setUp_with_init()
        self.test_to_string()

    def test_to_string_with_init_ack(self):
        self.setUp_with_init_ack()
        self.test_to_string()

    def test_to_string_with_sack(self):
        self.setUp_with_sack()
        self.test_to_string()

    def test_to_string_with_heartbeat(self):
        self.setUp_with_heartbeat()
        self.test_to_string()

    def test_to_string_with_heartbeat_ack(self):
        self.setUp_with_heartbeat_ack()
        self.test_to_string()

    def test_to_string_with_abort(self):
        self.setUp_with_abort()
        self.test_to_string()

    def test_to_string_with_shutdown(self):
        self.setUp_with_shutdown()
        self.test_to_string()

    def test_to_string_with_shutdown_ack(self):
        self.setUp_with_shutdown_ack()
        self.test_to_string()

    def test_to_string_with_error(self):
        self.setUp_with_error()
        self.test_to_string()

    def test_to_string_with_cookie_echo(self):
        self.setUp_with_cookie_echo()
        self.test_to_string()

    def test_to_string_with_cookie_ack(self):
        self.setUp_with_cookie_ack()
        self.test_to_string()

    def test_to_string_with_ecn_echo(self):
        self.setUp_with_ecn_echo()
        self.test_to_string()

    def test_to_string_with_cwr(self):
        self.setUp_with_cwr()
        self.test_to_string()

    def test_to_string_with_shutdown_complete(self):
        self.setUp_with_shutdown_complete()
        self.test_to_string()

    def test_to_string_with_multi_chunks(self):
        self.setUp_with_multi_chunks()
        self.test_to_string()

########NEW FILE########
__FILENAME__ = test_slow
# Copyright (C) 2013 Nippon Telegraph and Telephone Corporation.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# vim: tabstop=4 shiftwidth=4 softtabstop=4

import unittest
import logging
import copy
from struct import pack, unpack_from
from nose.tools import ok_, eq_, raises
from ryu.ofproto import ether
from ryu.lib.packet.ethernet import ethernet
from ryu.lib.packet.packet import Packet
from ryu.lib import addrconv
from ryu.lib.packet.slow import slow, lacp
from ryu.lib.packet.slow import SLOW_PROTOCOL_MULTICAST
from ryu.lib.packet.slow import SLOW_SUBTYPE_LACP
from ryu.lib.packet.slow import SLOW_SUBTYPE_MARKER

LOG = logging.getLogger(__name__)


class Test_slow(unittest.TestCase):
    """ Test case for Slow Protocol
    """
    def setUp(self):
        self.subtype = SLOW_SUBTYPE_LACP
        self.version = lacp.LACP_VERSION_NUMBER
        self.actor_tag = lacp.LACP_TLV_TYPE_ACTOR
        self.actor_length = 20
        self.actor_system_priority = 65534
        self.actor_system = '00:07:0d:af:f4:54'
        self.actor_key = 1
        self.actor_port_priority = 65535
        self.actor_port = 1
        self.actor_state_activity = lacp.LACP_STATE_ACTIVE
        self.actor_state_timeout = lacp.LACP_STATE_LONG_TIMEOUT
        self.actor_state_aggregation = lacp.LACP_STATE_AGGREGATEABLE
        self.actor_state_synchronization = lacp.LACP_STATE_IN_SYNC
        self.actor_state_collecting = lacp.LACP_STATE_COLLECTING_ENABLED
        self.actor_state_distributing = lacp.LACP_STATE_DISTRIBUTING_ENABLED
        self.actor_state_defaulted = lacp.LACP_STATE_OPERATIONAL_PARTNER
        self.actor_state_expired = lacp.LACP_STATE_EXPIRED
        self.actor_state = (
            (self.actor_state_activity << 0) |
            (self.actor_state_timeout << 1) |
            (self.actor_state_aggregation << 2) |
            (self.actor_state_synchronization << 3) |
            (self.actor_state_collecting << 4) |
            (self.actor_state_distributing << 5) |
            (self.actor_state_defaulted << 6) |
            (self.actor_state_expired << 7))
        self.partner_tag = lacp.LACP_TLV_TYPE_PARTNER
        self.partner_length = 20
        self.partner_system_priority = 0
        self.partner_system = '00:00:00:00:00:00'
        self.partner_key = 0
        self.partner_port_priority = 0
        self.partner_port = 0
        self.partner_state_activity = 0
        self.partner_state_timeout = lacp.LACP_STATE_SHORT_TIMEOUT
        self.partner_state_aggregation = 0
        self.partner_state_synchronization = 0
        self.partner_state_collecting = 0
        self.partner_state_distributing = 0
        self.partner_state_defaulted = 0
        self.partner_state_expired = 0
        self.partner_state = (
            (self.partner_state_activity << 0) |
            (self.partner_state_timeout << 1) |
            (self.partner_state_aggregation << 2) |
            (self.partner_state_synchronization << 3) |
            (self.partner_state_collecting << 4) |
            (self.partner_state_distributing << 5) |
            (self.partner_state_defaulted << 6) |
            (self.partner_state_expired << 7))
        self.collector_tag = lacp.LACP_TLV_TYPE_COLLECTOR
        self.collector_length = 16
        self.collector_max_delay = 0
        self.terminator_tag = lacp.LACP_TLV_TYPE_TERMINATOR
        self.terminator_length = 0

        self.head_fmt = lacp._HLEN_PACK_STR
        self.head_len = lacp._HLEN_PACK_LEN
        self.act_fmt = lacp._ACTPRT_INFO_PACK_STR
        self.act_len = lacp._ACTPRT_INFO_PACK_LEN
        self.prt_fmt = lacp._ACTPRT_INFO_PACK_STR
        self.prt_len = lacp._ACTPRT_INFO_PACK_LEN
        self.col_fmt = lacp._COL_INFO_PACK_STR
        self.col_len = lacp._COL_INFO_PACK_LEN
        self.trm_fmt = lacp._TRM_PACK_STR
        self.trm_len = lacp._TRM_PACK_LEN
        self.length = lacp._ALL_PACK_LEN

        self.head_buf = pack(self.head_fmt,
                             self.subtype,
                             self.version)
        self.act_buf = pack(self.act_fmt,
                            self.actor_tag,
                            self.actor_length,
                            self.actor_system_priority,
                            self.actor_system,
                            self.actor_key,
                            self.actor_port_priority,
                            self.actor_port,
                            self.actor_state)
        self.prt_buf = pack(self.prt_fmt,
                            self.partner_tag,
                            self.partner_length,
                            self.partner_system_priority,
                            self.partner_system,
                            self.partner_key,
                            self.partner_port_priority,
                            self.partner_port,
                            self.partner_state)
        self.col_buf = pack(self.col_fmt,
                            self.collector_tag,
                            self.collector_length,
                            self.collector_max_delay)
        self.trm_buf = pack(self.trm_fmt,
                            self.terminator_tag,
                            self.terminator_length)

        self.buf = self.head_buf + self.act_buf + self.prt_buf + \
            self.col_buf + self.trm_buf

    def tearDown(self):
        pass

    def test_parser(self):
        slow.parser(self.buf)

    def test_not_implemented_subtype(self):
        not_implemented_buf = str(SLOW_SUBTYPE_MARKER) + self.buf[1:]
        (instance, nexttype, last) = slow.parser(not_implemented_buf)
        assert None == instance
        assert None == nexttype
        assert None != last

    def test_invalid_subtype(self):
        invalid_buf = "\xff" + self.buf[1:]
        (instance, nexttype, last) = slow.parser(invalid_buf)
        assert None == instance
        assert None == nexttype
        assert None != last


class Test_lacp(unittest.TestCase):
    """ Test case for lacp
    """

    def setUp(self):
        self.subtype = SLOW_SUBTYPE_LACP
        self.version = lacp.LACP_VERSION_NUMBER
        self.actor_tag = lacp.LACP_TLV_TYPE_ACTOR
        self.actor_length = 20
        self.actor_system_priority = 65534
        self.actor_system = '00:07:0d:af:f4:54'
        self.actor_key = 1
        self.actor_port_priority = 65535
        self.actor_port = 1
        self.actor_state_activity = lacp.LACP_STATE_ACTIVE
        self.actor_state_timeout = lacp.LACP_STATE_LONG_TIMEOUT
        self.actor_state_aggregation = lacp.LACP_STATE_AGGREGATEABLE
        self.actor_state_synchronization = lacp.LACP_STATE_IN_SYNC
        self.actor_state_collecting = lacp.LACP_STATE_COLLECTING_ENABLED
        self.actor_state_distributing = lacp.LACP_STATE_DISTRIBUTING_ENABLED
        self.actor_state_defaulted = lacp.LACP_STATE_OPERATIONAL_PARTNER
        self.actor_state_expired = lacp.LACP_STATE_EXPIRED
        self.actor_state = (
            (self.actor_state_activity << 0) |
            (self.actor_state_timeout << 1) |
            (self.actor_state_aggregation << 2) |
            (self.actor_state_synchronization << 3) |
            (self.actor_state_collecting << 4) |
            (self.actor_state_distributing << 5) |
            (self.actor_state_defaulted << 6) |
            (self.actor_state_expired << 7))
        self.partner_tag = lacp.LACP_TLV_TYPE_PARTNER
        self.partner_length = 20
        self.partner_system_priority = 0
        self.partner_system = '00:00:00:00:00:00'
        self.partner_key = 0
        self.partner_port_priority = 0
        self.partner_port = 0
        self.partner_state_activity = 0
        self.partner_state_timeout = lacp.LACP_STATE_SHORT_TIMEOUT
        self.partner_state_aggregation = 0
        self.partner_state_synchronization = 0
        self.partner_state_collecting = 0
        self.partner_state_distributing = 0
        self.partner_state_defaulted = 0
        self.partner_state_expired = 0
        self.partner_state = (
            (self.partner_state_activity << 0) |
            (self.partner_state_timeout << 1) |
            (self.partner_state_aggregation << 2) |
            (self.partner_state_synchronization << 3) |
            (self.partner_state_collecting << 4) |
            (self.partner_state_distributing << 5) |
            (self.partner_state_defaulted << 6) |
            (self.partner_state_expired << 7))
        self.collector_tag = lacp.LACP_TLV_TYPE_COLLECTOR
        self.collector_length = 16
        self.collector_max_delay = 0
        self.terminator_tag = lacp.LACP_TLV_TYPE_TERMINATOR
        self.terminator_length = 0

        self.head_fmt = lacp._HLEN_PACK_STR
        self.head_len = lacp._HLEN_PACK_LEN
        self.act_fmt = lacp._ACTPRT_INFO_PACK_STR
        self.act_len = lacp._ACTPRT_INFO_PACK_LEN
        self.prt_fmt = lacp._ACTPRT_INFO_PACK_STR
        self.prt_len = lacp._ACTPRT_INFO_PACK_LEN
        self.col_fmt = lacp._COL_INFO_PACK_STR
        self.col_len = lacp._COL_INFO_PACK_LEN
        self.trm_fmt = lacp._TRM_PACK_STR
        self.trm_len = lacp._TRM_PACK_LEN
        self.length = lacp._ALL_PACK_LEN

        self.head_buf = pack(self.head_fmt,
                             self.subtype,
                             self.version)
        self.act_buf = pack(self.act_fmt,
                            self.actor_tag,
                            self.actor_length,
                            self.actor_system_priority,
                            addrconv.mac.text_to_bin(self.actor_system),
                            self.actor_key,
                            self.actor_port_priority,
                            self.actor_port,
                            self.actor_state)
        self.prt_buf = pack(self.prt_fmt,
                            self.partner_tag,
                            self.partner_length,
                            self.partner_system_priority,
                            addrconv.mac.text_to_bin(self.partner_system),
                            self.partner_key,
                            self.partner_port_priority,
                            self.partner_port,
                            self.partner_state)
        self.col_buf = pack(self.col_fmt,
                            self.collector_tag,
                            self.collector_length,
                            self.collector_max_delay)
        self.trm_buf = pack(self.trm_fmt,
                            self.terminator_tag,
                            self.terminator_length)

        self.buf = self.head_buf + self.act_buf + self.prt_buf + \
            self.col_buf + self.trm_buf

        self.l = lacp(self.version,
                      self.actor_system_priority,
                      self.actor_system,
                      self.actor_key,
                      self.actor_port_priority,
                      self.actor_port,
                      self.actor_state_activity,
                      self.actor_state_timeout,
                      self.actor_state_aggregation,
                      self.actor_state_synchronization,
                      self.actor_state_collecting,
                      self.actor_state_distributing,
                      self.actor_state_defaulted,
                      self.actor_state_expired,
                      self.partner_system_priority,
                      self.partner_system,
                      self.partner_key,
                      self.partner_port_priority,
                      self.partner_port,
                      self.partner_state_activity,
                      self.partner_state_timeout,
                      self.partner_state_aggregation,
                      self.partner_state_synchronization,
                      self.partner_state_collecting,
                      self.partner_state_distributing,
                      self.partner_state_defaulted,
                      self.partner_state_expired,
                      self.collector_max_delay)

    def tearDown(self):
        pass

    def find_protocol(self, pkt, name):
        for p in pkt.protocols:
            if p.protocol_name == name:
                return p

    def test_init(self):
        eq_(self.subtype, self.l.subtype)
        eq_(self.version, self.l.version)
        eq_(self.actor_tag, self.l.actor_tag)
        eq_(self.actor_length, self.l.actor_length)
        eq_(self.actor_system_priority, self.l.actor_system_priority)
        eq_(self.actor_system, self.l.actor_system)
        eq_(self.actor_key, self.l.actor_key)
        eq_(self.actor_port_priority, self.l.actor_port_priority)
        eq_(self.actor_port, self.l.actor_port)
        eq_(self.actor_state_activity, self.l.actor_state_activity)
        eq_(self.actor_state_timeout, self.l.actor_state_timeout)
        eq_(self.actor_state_aggregation,
            self.l.actor_state_aggregation)
        eq_(self.actor_state_synchronization,
            self.l.actor_state_synchronization)
        eq_(self.actor_state_collecting,
            self.l.actor_state_collecting)
        eq_(self.actor_state_distributing,
            self.l.actor_state_distributing)
        eq_(self.actor_state_defaulted, self.l.actor_state_defaulted)
        eq_(self.actor_state_expired, self.l.actor_state_expired)
        eq_(self.actor_state, self.l.actor_state)
        eq_(self.partner_tag, self.l.partner_tag)
        eq_(self.partner_length, self.l.partner_length)
        eq_(self.partner_system_priority,
            self.l.partner_system_priority)
        eq_(self.partner_system, self.l.partner_system)
        eq_(self.partner_key, self.l.partner_key)
        eq_(self.partner_port_priority, self.l.partner_port_priority)
        eq_(self.partner_port, self.l.partner_port)
        eq_(self.partner_state_activity, self.l.partner_state_activity)
        eq_(self.partner_state_timeout, self.l.partner_state_timeout)
        eq_(self.partner_state_aggregation,
            self.l.partner_state_aggregation)
        eq_(self.partner_state_synchronization,
            self.l.partner_state_synchronization)
        eq_(self.partner_state_collecting,
            self.l.partner_state_collecting)
        eq_(self.partner_state_distributing,
            self.l.partner_state_distributing)
        eq_(self.partner_state_defaulted,
            self.l.partner_state_defaulted)
        eq_(self.partner_state_expired, self.l.partner_state_expired)
        eq_(self.partner_state, self.l.partner_state)
        eq_(self.collector_tag, self.l.collector_tag)
        eq_(self.collector_length, self.l.collector_length)
        eq_(self.collector_max_delay, self.l.collector_max_delay)
        eq_(self.terminator_tag, self.l.terminator_tag)
        eq_(self.terminator_length, self.l.terminator_length)

    def test_parser(self):
        _res = self.l.parser(self.buf)
        if type(_res) is tuple:
            res = _res[0]
        else:
            res = _res

        eq_(res.subtype, self.subtype)
        eq_(res.version, self.version)
        eq_(res.actor_tag, self.actor_tag)
        eq_(res.actor_length, self.actor_length)
        eq_(res.actor_system_priority, self.actor_system_priority)
        eq_(res.actor_system, self.actor_system)
        eq_(res.actor_key, self.actor_key)
        eq_(res.actor_port_priority, self.actor_port_priority)
        eq_(res.actor_port, self.actor_port)
        eq_(res.actor_state_activity, self.actor_state_activity)
        eq_(res.actor_state_timeout, self.actor_state_timeout)
        eq_(res.actor_state_aggregation, self.actor_state_aggregation)
        eq_(res.actor_state_synchronization,
            self.actor_state_synchronization)
        eq_(res.actor_state_collecting, self.actor_state_collecting)
        eq_(res.actor_state_distributing, self.actor_state_distributing)
        eq_(res.actor_state_defaulted, self.actor_state_defaulted)
        eq_(res.actor_state_expired, self.actor_state_expired)
        eq_(res.actor_state, self.actor_state)
        eq_(res.partner_tag, self.partner_tag)
        eq_(res.partner_length, self.partner_length)
        eq_(res.partner_system_priority, self.partner_system_priority)
        eq_(res.partner_system, self.partner_system)
        eq_(res.partner_key, self.partner_key)
        eq_(res.partner_port_priority, self.partner_port_priority)
        eq_(res.partner_port, self.partner_port)
        eq_(res.partner_state_activity, self.partner_state_activity)
        eq_(res.partner_state_timeout, self.partner_state_timeout)
        eq_(res.partner_state_aggregation,
            self.partner_state_aggregation)
        eq_(res.partner_state_synchronization,
            self.partner_state_synchronization)
        eq_(res.partner_state_collecting, self.partner_state_collecting)
        eq_(res.partner_state_distributing,
            self.partner_state_distributing)
        eq_(res.partner_state_defaulted, self.partner_state_defaulted)
        eq_(res.partner_state_expired, self.partner_state_expired)
        eq_(res.partner_state, self.partner_state)
        eq_(res.collector_tag, self.collector_tag)
        eq_(res.collector_length, self.collector_length)
        eq_(res.collector_max_delay, self.collector_max_delay)
        eq_(res.terminator_tag, self.terminator_tag)
        eq_(res.terminator_length, self.terminator_length)

    def test_serialize(self):
        data = bytearray()
        prev = None
        buf = self.l.serialize(data, prev)

        offset = 0
        head_res = unpack_from(self.head_fmt, buf, offset)
        offset += self.head_len
        act_res = unpack_from(self.act_fmt, buf, offset)
        offset += self.act_len
        prt_res = unpack_from(self.prt_fmt, buf, offset)
        offset += self.prt_len
        col_res = unpack_from(self.col_fmt, buf, offset)
        offset += self.col_len
        trm_res = unpack_from(self.trm_fmt, buf, offset)

        eq_(head_res[0], self.subtype)
        eq_(head_res[1], self.version)

        eq_(act_res[0], self.actor_tag)
        eq_(act_res[1], self.actor_length)
        eq_(act_res[2], self.actor_system_priority)
        eq_(act_res[3], addrconv.mac.text_to_bin(self.actor_system))
        eq_(act_res[4], self.actor_key)
        eq_(act_res[5], self.actor_port_priority)
        eq_(act_res[6], self.actor_port)
        eq_(act_res[7], self.actor_state)

        eq_(prt_res[0], self.partner_tag)
        eq_(prt_res[1], self.partner_length)
        eq_(prt_res[2], self.partner_system_priority)
        eq_(prt_res[3], addrconv.mac.text_to_bin(self.partner_system))
        eq_(prt_res[4], self.partner_key)
        eq_(prt_res[5], self.partner_port_priority)
        eq_(prt_res[6], self.partner_port)
        eq_(prt_res[7], self.partner_state)

        eq_(col_res[0], self.collector_tag)
        eq_(col_res[1], self.collector_length)
        eq_(col_res[2], self.collector_max_delay)

        eq_(trm_res[0], self.terminator_tag)
        eq_(trm_res[1], self.terminator_length)

    def _build_lacp(self):
        ethertype = ether.ETH_TYPE_SLOW
        dst = SLOW_PROTOCOL_MULTICAST
        e = ethernet(dst, self.actor_system, ethertype)
        p = Packet()

        p.add_protocol(e)
        p.add_protocol(self.l)
        p.serialize()
        return p

    def test_build_lacp(self):
        p = self._build_lacp()

        e = self.find_protocol(p, "ethernet")
        ok_(e)
        eq_(e.ethertype, ether.ETH_TYPE_SLOW)

        l = self.find_protocol(p, "lacp")
        ok_(l)

        eq_(l.subtype, self.subtype)
        eq_(l.version, self.version)
        eq_(l.actor_tag, self.actor_tag)
        eq_(l.actor_length, self.actor_length)
        eq_(l.actor_system_priority, self.actor_system_priority)
        eq_(l.actor_system, self.actor_system)
        eq_(l.actor_key, self.actor_key)
        eq_(l.actor_port_priority, self.actor_port_priority)
        eq_(l.actor_port, self.actor_port)
        eq_(l.actor_state_activity, self.actor_state_activity)
        eq_(l.actor_state_timeout, self.actor_state_timeout)
        eq_(l.actor_state_aggregation, self.actor_state_aggregation)
        eq_(l.actor_state_synchronization,
            self.actor_state_synchronization)
        eq_(l.actor_state_collecting, self.actor_state_collecting)
        eq_(l.actor_state_distributing, self.actor_state_distributing)
        eq_(l.actor_state_defaulted, self.actor_state_defaulted)
        eq_(l.actor_state_expired, self.actor_state_expired)
        eq_(l.actor_state, self.actor_state)
        eq_(l.partner_tag, self.partner_tag)
        eq_(l.partner_length, self.partner_length)
        eq_(l.partner_system_priority, self.partner_system_priority)
        eq_(l.partner_system, self.partner_system)
        eq_(l.partner_key, self.partner_key)
        eq_(l.partner_port_priority, self.partner_port_priority)
        eq_(l.partner_port, self.partner_port)
        eq_(l.partner_state_activity, self.partner_state_activity)
        eq_(l.partner_state_timeout, self.partner_state_timeout)
        eq_(l.partner_state_aggregation, self.partner_state_aggregation)
        eq_(l.partner_state_synchronization,
            self.partner_state_synchronization)
        eq_(l.partner_state_collecting, self.partner_state_collecting)
        eq_(l.partner_state_distributing,
            self.partner_state_distributing)
        eq_(l.partner_state_defaulted, self.partner_state_defaulted)
        eq_(l.partner_state_expired, self.partner_state_expired)
        eq_(l.collector_tag, self.collector_tag)
        eq_(l.collector_length, self.collector_length)
        eq_(l.collector_max_delay, self.collector_max_delay)
        eq_(l.terminator_tag, self.terminator_tag)
        eq_(l.terminator_length, self.terminator_length)

    @raises(Exception)
    def test_malformed_lacp(self):
        m_short_buf = self.buf[1:self.length]
        slow.parser(m_short_buf)

    @raises(Exception)
    def test_invalid_subtype(self):
        invalid_lacv = copy.deepcopy(self.l)
        invalid_lacv.subtype = 0xff
        invalid_buf = invalid_lacv.serialize()
        slow.parser(invalid_buf)

    @raises(Exception)
    def test_invalid_version(self):
        invalid_lacv = copy.deepcopy(self.l)
        invalid_lacv.version = 0xff
        invalid_buf = invalid_lacv.serialize()
        slow.parser(invalid_buf)

    @raises(Exception)
    def test_invalid_actor_tag(self):
        invalid_lacv = copy.deepcopy(self.l)
        invalid_lacv.actor_tag = 0x04
        invalid_buf = invalid_lacv.serialize()
        slow.parser(invalid_buf)

    @raises(Exception)
    def test_invalid_actor_length(self):
        invalid_lacv = copy.deepcopy(self.l)
        invalid_lacv.actor_length = 50
        invalid_buf = invalid_lacv.serialize()
        slow.parser(invalid_buf)

    @raises(Exception)
    def test_invalid_partner_tag(self):
        invalid_lacv = copy.deepcopy(self.l)
        invalid_lacv.partner_tag = 0x01
        invalid_buf = invalid_lacv.serialize()
        slow.parser(invalid_buf)

    @raises(Exception)
    def test_invalid_partner_length(self):
        invalid_lacv = copy.deepcopy(self.l)
        invalid_lacv.partner_length = 0
        invalid_buf = invalid_lacv.serialize()
        slow.parser(invalid_buf)

    @raises(Exception)
    def test_invalid_collector_tag(self):
        invalid_lacv = copy.deepcopy(self.l)
        invalid_lacv.collector_tag = 0x00
        invalid_buf = invalid_lacv.serialize()
        slow.parser(invalid_buf)

    @raises(Exception)
    def test_invalid_collector_length(self):
        invalid_lacv = copy.deepcopy(self.l)
        invalid_lacv.collector_length = 20
        invalid_buf = invalid_lacv.serialize()
        slow.parser(invalid_buf)

    @raises(Exception)
    def test_invalid_terminator_tag(self):
        invalid_lacv = copy.deepcopy(self.l)
        invalid_lacv.terminator_tag = 0x04
        invalid_buf = invalid_lacv.serialize()
        slow.parser(invalid_buf)

    @raises(Exception)
    def test_invalid_terminator_length(self):
        invalid_lacv = copy.deepcopy(self.l)
        invalid_lacv.terminator_length = self.trm_len
        invalid_buf = invalid_lacv.serialize()
        slow.parser(invalid_buf)

    @raises(Exception)
    def test_invalid_actor_state_activity(self):
        l = lacp(self.version,
                 self.actor_system_priority,
                 self.actor_system,
                 self.actor_key,
                 self.actor_port_priority,
                 self.actor_port,
                 2,
                 self.actor_state_timeout,
                 self.actor_state_aggregation,
                 self.actor_state_synchronization,
                 self.actor_state_collecting,
                 self.actor_state_distributing,
                 self.actor_state_defaulted,
                 self.actor_state_expired,
                 self.partner_system_priority,
                 self.partner_system,
                 self.partner_key,
                 self.partner_port_priority,
                 self.partner_port,
                 self.partner_state_activity,
                 self.partner_state_timeout,
                 self.partner_state_aggregation,
                 self.partner_state_synchronization,
                 self.partner_state_collecting,
                 self.partner_state_distributing,
                 self.partner_state_defaulted,
                 self.partner_state_expired,
                 self.collector_max_delay)
        l.serialize()

    @raises(Exception)
    def test_invalid_actor_state_timeout(self):
        l = lacp(self.version,
                 self.actor_system_priority,
                 self.actor_system,
                 self.actor_key,
                 self.actor_port_priority,
                 self.actor_port,
                 self.actor_state_activity,
                 2,
                 self.actor_state_aggregation,
                 self.actor_state_synchronization,
                 self.actor_state_collecting,
                 self.actor_state_distributing,
                 self.actor_state_defaulted,
                 self.actor_state_expired,
                 self.partner_system_priority,
                 self.partner_system,
                 self.partner_key,
                 self.partner_port_priority,
                 self.partner_port,
                 self.partner_state_activity,
                 self.partner_state_timeout,
                 self.partner_state_aggregation,
                 self.partner_state_synchronization,
                 self.partner_state_collecting,
                 self.partner_state_distributing,
                 self.partner_state_defaulted,
                 self.partner_state_expired,
                 self.collector_max_delay)
        l.serialize()

    @raises(Exception)
    def test_invalid_actor_state_aggregation(self):
        l = lacp(self.version,
                 self.actor_system_priority,
                 self.actor_system,
                 self.actor_key,
                 self.actor_port_priority,
                 self.actor_port,
                 self.actor_state_activity,
                 self.actor_state_timeout,
                 2,
                 self.actor_state_synchronization,
                 self.actor_state_collecting,
                 self.actor_state_distributing,
                 self.actor_state_defaulted,
                 self.actor_state_expired,
                 self.partner_system_priority,
                 self.partner_system,
                 self.partner_key,
                 self.partner_port_priority,
                 self.partner_port,
                 self.partner_state_activity,
                 self.partner_state_timeout,
                 self.partner_state_aggregation,
                 self.partner_state_synchronization,
                 self.partner_state_collecting,
                 self.partner_state_distributing,
                 self.partner_state_defaulted,
                 self.partner_state_expired,
                 self.collector_max_delay)
        l.serialize()

    @raises(Exception)
    def test_invalid_actor_state_synchronization(self):
        l = lacp(self.version,
                 self.actor_system_priority,
                 self.actor_system,
                 self.actor_key,
                 self.actor_port_priority,
                 self.actor_port,
                 self.actor_state_activity,
                 self.actor_state_timeout,
                 self.actor_state_aggregation,
                 2,
                 self.actor_state_collecting,
                 self.actor_state_distributing,
                 self.actor_state_defaulted,
                 self.actor_state_expired,
                 self.partner_system_priority,
                 self.partner_system,
                 self.partner_key,
                 self.partner_port_priority,
                 self.partner_port,
                 self.partner_state_activity,
                 self.partner_state_timeout,
                 self.partner_state_aggregation,
                 self.partner_state_synchronization,
                 self.partner_state_collecting,
                 self.partner_state_distributing,
                 self.partner_state_defaulted,
                 self.partner_state_expired,
                 self.collector_max_delay)
        l.serialize()

    @raises(Exception)
    def test_invalid_actor_state_collecting(self):
        l = lacp(self.version,
                 self.actor_system_priority,
                 self.actor_system,
                 self.actor_key,
                 self.actor_port_priority,
                 self.actor_port,
                 self.actor_state_activity,
                 self.actor_state_timeout,
                 self.actor_state_aggregation,
                 self.actor_state_synchronization,
                 2,
                 self.actor_state_distributing,
                 self.actor_state_defaulted,
                 self.actor_state_expired,
                 self.partner_system_priority,
                 self.partner_system,
                 self.partner_key,
                 self.partner_port_priority,
                 self.partner_port,
                 self.partner_state_activity,
                 self.partner_state_timeout,
                 self.partner_state_aggregation,
                 self.partner_state_synchronization,
                 self.partner_state_collecting,
                 self.partner_state_distributing,
                 self.partner_state_defaulted,
                 self.partner_state_expired,
                 self.collector_max_delay)
        l.serialize()

    @raises(Exception)
    def test_invalid_actor_state_distributing(self):
        l = lacp(self.version,
                 self.actor_system_priority,
                 self.actor_system,
                 self.actor_key,
                 self.actor_port_priority,
                 self.actor_port,
                 self.actor_state_activity,
                 self.actor_state_timeout,
                 self.actor_state_aggregation,
                 self.actor_state_synchronization,
                 self.actor_state_collecting,
                 2,
                 self.actor_state_defaulted,
                 self.actor_state_expired,
                 self.partner_system_priority,
                 self.partner_system,
                 self.partner_key,
                 self.partner_port_priority,
                 self.partner_port,
                 self.partner_state_activity,
                 self.partner_state_timeout,
                 self.partner_state_aggregation,
                 self.partner_state_synchronization,
                 self.partner_state_collecting,
                 self.partner_state_distributing,
                 self.partner_state_defaulted,
                 self.partner_state_expired,
                 self.collector_max_delay)
        l.serialize()

    @raises(Exception)
    def test_invalid_actor_state_defaulted(self):
        l = lacp(self.version,
                 self.actor_system_priority,
                 self.actor_system,
                 self.actor_key,
                 self.actor_port_priority,
                 self.actor_port,
                 self.actor_state_activity,
                 self.actor_state_timeout,
                 self.actor_state_aggregation,
                 self.actor_state_synchronization,
                 self.actor_state_collecting,
                 self.actor_state_distributing,
                 2,
                 self.actor_state_expired,
                 self.partner_system_priority,
                 self.partner_system,
                 self.partner_key,
                 self.partner_port_priority,
                 self.partner_port,
                 self.partner_state_activity,
                 self.partner_state_timeout,
                 self.partner_state_aggregation,
                 self.partner_state_synchronization,
                 self.partner_state_collecting,
                 self.partner_state_distributing,
                 self.partner_state_defaulted,
                 self.partner_state_expired,
                 self.collector_max_delay)
        l.serialize()

    @raises(Exception)
    def test_invalid_actor_state_expired(self):
        l = lacp(self.version,
                 self.actor_system_priority,
                 self.actor_system,
                 self.actor_key,
                 self.actor_port_priority,
                 self.actor_port,
                 self.actor_state_activity,
                 self.actor_state_timeout,
                 self.actor_state_aggregation,
                 self.actor_state_synchronization,
                 self.actor_state_collecting,
                 self.actor_state_distributing,
                 self.actor_state_defaulted,
                 2,
                 self.partner_system_priority,
                 self.partner_system,
                 self.partner_key,
                 self.partner_port_priority,
                 self.partner_port,
                 self.partner_state_activity,
                 self.partner_state_timeout,
                 self.partner_state_aggregation,
                 self.partner_state_synchronization,
                 self.partner_state_collecting,
                 self.partner_state_distributing,
                 self.partner_state_defaulted,
                 self.partner_state_expired,
                 self.collector_max_delay)
        l.serialize()

    @raises(Exception)
    def test_invalid_partner_state_activity(self):
        l = lacp(self.version,
                 self.actor_system_priority,
                 self.actor_system,
                 self.actor_key,
                 self.actor_port_priority,
                 self.actor_port,
                 self.actor_state_activity,
                 self.actor_state_timeout,
                 self.actor_state_aggregation,
                 self.actor_state_synchronization,
                 self.actor_state_collecting,
                 self.actor_state_distributing,
                 self.actor_state_defaulted,
                 self.actor_state_expired,
                 self.partner_system_priority,
                 self.partner_system,
                 self.partner_key,
                 self.partner_port_priority,
                 self.partner_port,
                 -1,
                 self.partner_state_timeout,
                 self.partner_state_aggregation,
                 self.partner_state_synchronization,
                 self.partner_state_collecting,
                 self.partner_state_distributing,
                 self.partner_state_defaulted,
                 self.partner_state_expired,
                 self.collector_max_delay)
        l.serialize()

    @raises(Exception)
    def test_invalid_partner_state_timeout(self):
        l = lacp(self.version,
                 self.actor_system_priority,
                 self.actor_system,
                 self.actor_key,
                 self.actor_port_priority,
                 self.actor_port,
                 self.actor_state_activity,
                 self.actor_state_timeout,
                 self.actor_state_aggregation,
                 self.actor_state_synchronization,
                 self.actor_state_collecting,
                 self.actor_state_distributing,
                 self.actor_state_defaulted,
                 self.actor_state_expired,
                 self.partner_system_priority,
                 self.partner_system,
                 self.partner_key,
                 self.partner_port_priority,
                 self.partner_port,
                 self.partner_state_activity,
                 -1,
                 self.partner_state_aggregation,
                 self.partner_state_synchronization,
                 self.partner_state_collecting,
                 self.partner_state_distributing,
                 self.partner_state_defaulted,
                 self.partner_state_expired,
                 self.collector_max_delay)
        l.serialize()

    @raises(Exception)
    def test_invalid_partner_state_aggregation(self):
        l = lacp(self.version,
                 self.actor_system_priority,
                 self.actor_system,
                 self.actor_key,
                 self.actor_port_priority,
                 self.actor_port,
                 self.actor_state_activity,
                 self.actor_state_timeout,
                 self.actor_state_aggregation,
                 self.actor_state_synchronization,
                 self.actor_state_collecting,
                 self.actor_state_distributing,
                 self.actor_state_defaulted,
                 self.actor_state_expired,
                 self.partner_system_priority,
                 self.partner_system,
                 self.partner_key,
                 self.partner_port_priority,
                 self.partner_port,
                 self.partner_state_activity,
                 self.partner_state_timeout,
                 -1,
                 self.partner_state_synchronization,
                 self.partner_state_collecting,
                 self.partner_state_distributing,
                 self.partner_state_defaulted,
                 self.partner_state_expired,
                 self.collector_max_delay)
        l.serialize()

    @raises(Exception)
    def test_invalid_partner_state_synchronization(self):
        l = lacp(self.version,
                 self.actor_system_priority,
                 self.actor_system,
                 self.actor_key,
                 self.actor_port_priority,
                 self.actor_port,
                 self.actor_state_activity,
                 self.actor_state_timeout,
                 self.actor_state_aggregation,
                 self.actor_state_synchronization,
                 self.actor_state_collecting,
                 self.actor_state_distributing,
                 self.actor_state_defaulted,
                 self.actor_state_expired,
                 self.partner_system_priority,
                 self.partner_system,
                 self.partner_key,
                 self.partner_port_priority,
                 self.partner_port,
                 self.partner_state_activity,
                 self.partner_state_timeout,
                 self.partner_state_aggregation,
                 -1,
                 self.partner_state_collecting,
                 self.partner_state_distributing,
                 self.partner_state_defaulted,
                 self.partner_state_expired,
                 self.collector_max_delay)
        l.serialize()

    @raises(Exception)
    def test_invalid_partner_state_collecting(self):
        l = lacp(self.version,
                 self.actor_system_priority,
                 self.actor_system,
                 self.actor_key,
                 self.actor_port_priority,
                 self.actor_port,
                 self.actor_state_activity,
                 self.actor_state_timeout,
                 self.actor_state_aggregation,
                 self.actor_state_synchronization,
                 self.actor_state_collecting,
                 self.actor_state_distributing,
                 self.actor_state_defaulted,
                 self.actor_state_expired,
                 self.partner_system_priority,
                 self.partner_system,
                 self.partner_key,
                 self.partner_port_priority,
                 self.partner_port,
                 self.partner_state_activity,
                 self.partner_state_timeout,
                 self.partner_state_aggregation,
                 self.partner_state_synchronization,
                 -1,
                 self.partner_state_distributing,
                 self.partner_state_defaulted,
                 self.partner_state_expired,
                 self.collector_max_delay)
        l.serialize()

    @raises(Exception)
    def test_invalid_partner_state_distributing(self):
        l = lacp(self.version,
                 self.actor_system_priority,
                 self.actor_system,
                 self.actor_key,
                 self.actor_port_priority,
                 self.actor_port,
                 self.actor_state_activity,
                 self.actor_state_timeout,
                 self.actor_state_aggregation,
                 self.actor_state_synchronization,
                 self.actor_state_collecting,
                 self.actor_state_distributing,
                 self.actor_state_defaulted,
                 self.actor_state_expired,
                 self.partner_system_priority,
                 self.partner_system,
                 self.partner_key,
                 self.partner_port_priority,
                 self.partner_port,
                 self.partner_state_activity,
                 self.partner_state_timeout,
                 self.partner_state_aggregation,
                 self.partner_state_synchronization,
                 self.partner_state_collecting,
                 -1,
                 self.partner_state_defaulted,
                 self.partner_state_expired,
                 self.collector_max_delay)
        l.serialize()

    @raises(Exception)
    def test_invalid_partner_state_defaulted(self):
        l = lacp(self.version,
                 self.actor_system_priority,
                 self.actor_system,
                 self.actor_key,
                 self.actor_port_priority,
                 self.actor_port,
                 self.actor_state_activity,
                 self.actor_state_timeout,
                 self.actor_state_aggregation,
                 self.actor_state_synchronization,
                 self.actor_state_collecting,
                 self.actor_state_distributing,
                 self.actor_state_defaulted,
                 self.actor_state_expired,
                 self.partner_system_priority,
                 self.partner_system,
                 self.partner_key,
                 self.partner_port_priority,
                 self.partner_port,
                 self.partner_state_activity,
                 self.partner_state_timeout,
                 self.partner_state_aggregation,
                 self.partner_state_synchronization,
                 self.partner_state_collecting,
                 self.partner_state_distributing,
                 -1,
                 self.partner_state_expired,
                 self.collector_max_delay)
        l.serialize()

    @raises(Exception)
    def test_invalid_partner_state_expired(self):
        l = lacp(self.version,
                 self.actor_system_priority,
                 self.actor_system,
                 self.actor_key,
                 self.actor_port_priority,
                 self.actor_port,
                 self.actor_state_activity,
                 self.actor_state_timeout,
                 self.actor_state_aggregation,
                 self.actor_state_synchronization,
                 self.actor_state_collecting,
                 self.actor_state_distributing,
                 self.actor_state_defaulted,
                 self.actor_state_expired,
                 self.partner_system_priority,
                 self.partner_system,
                 self.partner_key,
                 self.partner_port_priority,
                 self.partner_port,
                 self.partner_state_activity,
                 self.partner_state_timeout,
                 self.partner_state_aggregation,
                 self.partner_state_synchronization,
                 self.partner_state_collecting,
                 self.partner_state_distributing,
                 self.partner_state_defaulted,
                 -1,
                 self.collector_max_delay)
        l.serialize()

########NEW FILE########
__FILENAME__ = test_tcp
# Copyright (C) 2012 Nippon Telegraph and Telephone Corporation.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# vim: tabstop=4 shiftwidth=4 softtabstop=4

import unittest
import logging
import struct
from struct import *
from nose.tools import *
from nose.plugins.skip import Skip, SkipTest
from ryu.ofproto import ether, inet
from ryu.lib.packet.packet import Packet
from ryu.lib.packet.tcp import tcp
from ryu.lib.packet.ipv4 import ipv4
from ryu.lib.packet import packet_utils
from ryu.lib import addrconv


LOG = logging.getLogger('test_tcp')


class Test_tcp(unittest.TestCase):
    """ Test case for tcp
    """
    src_port = 6431
    dst_port = 8080
    seq = 5
    ack = 1
    offset = 6
    bits = 0b101010
    window_size = 2048
    csum = 12345
    urgent = 128
    option = '\x01\x02\x03\x04'

    t = tcp(src_port, dst_port, seq, ack, offset, bits,
            window_size, csum, urgent, option)

    buf = pack(tcp._PACK_STR, src_port, dst_port, seq, ack,
               offset << 4, bits, window_size, csum, urgent)
    buf += option

    def setUp(self):
        pass

    def tearDown(self):
        pass

    def test_init(self):
        eq_(self.src_port, self.t.src_port)
        eq_(self.dst_port, self.t.dst_port)
        eq_(self.seq, self.t.seq)
        eq_(self.ack, self.t.ack)
        eq_(self.offset, self.t.offset)
        eq_(self.bits, self.t.bits)
        eq_(self.window_size, self.t.window_size)
        eq_(self.csum, self.t.csum)
        eq_(self.urgent, self.t.urgent)
        eq_(self.option, self.t.option)

    def test_parser(self):
        r1, r2, _ = self.t.parser(self.buf)

        eq_(self.src_port, r1.src_port)
        eq_(self.dst_port, r1.dst_port)
        eq_(self.seq, r1.seq)
        eq_(self.ack, r1.ack)
        eq_(self.offset, r1.offset)
        eq_(self.bits, r1.bits)
        eq_(self.window_size, r1.window_size)
        eq_(self.csum, r1.csum)
        eq_(self.urgent, r1.urgent)
        eq_(self.option, r1.option)
        eq_(None, r2)

    def test_serialize(self):
        offset = 5
        csum = 0

        src_ip = '192.168.10.1'
        dst_ip = '192.168.100.1'
        prev = ipv4(4, 5, 0, 0, 0, 0, 0, 64,
                    inet.IPPROTO_TCP, 0, src_ip, dst_ip)

        t = tcp(self.src_port, self.dst_port, self.seq, self.ack,
                offset, self.bits, self.window_size, csum, self.urgent)
        buf = t.serialize(bytearray(), prev)
        res = struct.unpack(tcp._PACK_STR, str(buf))

        eq_(res[0], self.src_port)
        eq_(res[1], self.dst_port)
        eq_(res[2], self.seq)
        eq_(res[3], self.ack)
        eq_(res[4], offset << 4)
        eq_(res[5], self.bits)
        eq_(res[6], self.window_size)
        eq_(res[8], self.urgent)

        # checksum
        ph = struct.pack('!4s4sBBH',
                         addrconv.ipv4.text_to_bin(src_ip),
                         addrconv.ipv4.text_to_bin(dst_ip), 0, 6, offset * 4)
        d = ph + buf + bytearray()
        s = packet_utils.checksum(d)
        eq_(0, s)

    def test_serialize_option(self):
        offset = 6
        csum = 0
        option = '\x01\x02'

        src_ip = '192.168.10.1'
        dst_ip = '192.168.100.1'
        prev = ipv4(4, 5, 0, 0, 0, 0, 0, 64,
                    inet.IPPROTO_TCP, 0, src_ip, dst_ip)

        t = tcp(self.src_port, self.dst_port, self.seq, self.ack,
                offset, self.bits, self.window_size, csum, self.urgent,
                option)
        buf = t.serialize(bytearray(), prev)
        r_option = buf[tcp._MIN_LEN:tcp._MIN_LEN + len(option)]
        eq_(option, r_option)

    @raises(Exception)
    def test_malformed_tcp(self):
        m_short_buf = self.buf[1:tcp._MIN_LEN]
        tcp.parser(m_short_buf)

    def test_default_args(self):
        prev = ipv4(proto=inet.IPPROTO_TCP)
        t = tcp()
        buf = t.serialize(bytearray(), prev)
        res = struct.unpack(tcp._PACK_STR, buf)

        eq_(res[0], 0)
        eq_(res[1], 0)
        eq_(res[2], 0)
        eq_(res[3], 0)
        eq_(res[4], 5 << 4)
        eq_(res[5], 0)
        eq_(res[6], 0)
        eq_(res[8], 0)

        # with option, without offset
        t = tcp(option='\x01\x02\x03')
        buf = t.serialize(bytearray(), prev)
        res = struct.unpack(tcp._PACK_STR + '4s', buf)

        eq_(res[0], 0)
        eq_(res[1], 0)
        eq_(res[2], 0)
        eq_(res[3], 0)
        eq_(res[4], 6 << 4)
        eq_(res[5], 0)
        eq_(res[6], 0)
        eq_(res[8], 0)
        eq_(res[9], '\x01\x02\x03\x00')

        # with option, with long offset
        t = tcp(offset=7, option='\x01\x02\x03')
        buf = t.serialize(bytearray(), prev)
        res = struct.unpack(tcp._PACK_STR + '8s', buf)

        eq_(res[0], 0)
        eq_(res[1], 0)
        eq_(res[2], 0)
        eq_(res[3], 0)
        eq_(res[4], 7 << 4)
        eq_(res[5], 0)
        eq_(res[6], 0)
        eq_(res[8], 0)
        eq_(res[9], '\x01\x02\x03\x00\x00\x00\x00\x00')

########NEW FILE########
__FILENAME__ = test_udp
# Copyright (C) 2012 Nippon Telegraph and Telephone Corporation.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# vim: tabstop=4 shiftwidth=4 softtabstop=4

import unittest
import logging
import struct
from struct import *
from nose.tools import *
from nose.plugins.skip import Skip, SkipTest
from ryu.ofproto import ether, inet
from ryu.lib.packet.packet import Packet
from ryu.lib.packet.udp import udp
from ryu.lib.packet.ipv4 import ipv4
from ryu.lib.packet import packet_utils
from ryu.lib import addrconv


LOG = logging.getLogger('test_udp')


class Test_udp(unittest.TestCase):
    """ Test case for udp
    """
    src_port = 6431
    dst_port = 8080
    total_length = 65507
    csum = 12345
    u = udp(src_port, dst_port, total_length, csum)
    buf = pack(udp._PACK_STR, src_port, dst_port, total_length, csum)

    def setUp(self):
        pass

    def tearDown(self):
        pass

    def test_init(self):
        eq_(self.src_port, self.u.src_port)
        eq_(self.dst_port, self.u.dst_port)
        eq_(self.total_length, self.u.total_length)
        eq_(self.csum, self.u.csum)

    def test_parser(self):
        r1, r2, _ = self.u.parser(self.buf)

        eq_(self.src_port, r1.src_port)
        eq_(self.dst_port, r1.dst_port)
        eq_(self.total_length, r1.total_length)
        eq_(self.csum, r1.csum)
        eq_(None, r2)

    def test_serialize(self):
        src_port = 6431
        dst_port = 8080
        total_length = 0
        csum = 0

        src_ip = '192.168.10.1'
        dst_ip = '192.168.100.1'
        prev = ipv4(4, 5, 0, 0, 0, 0, 0, 64,
                    inet.IPPROTO_UDP, 0, src_ip, dst_ip)

        u = udp(src_port, dst_port, total_length, csum)
        buf = u.serialize(bytearray(), prev)
        res = struct.unpack(udp._PACK_STR, buf)

        eq_(res[0], src_port)
        eq_(res[1], dst_port)
        eq_(res[2], struct.calcsize(udp._PACK_STR))

        # checksum
        ph = struct.pack('!4s4sBBH',
                         addrconv.ipv4.text_to_bin(src_ip),
                         addrconv.ipv4.text_to_bin(dst_ip), 0, 17, res[2])
        d = ph + buf + bytearray()
        s = packet_utils.checksum(d)
        eq_(0, s)

    @raises(Exception)
    def test_malformed_udp(self):
        m_short_buf = self.buf[1:udp._MIN_LEN]
        udp.parser(m_short_buf)

    def test_default_args(self):
        prev = ipv4(proto=inet.IPPROTO_UDP)
        u = udp()
        buf = u.serialize(bytearray(), prev)
        res = struct.unpack(udp._PACK_STR, buf)

        eq_(res[0], 0)
        eq_(res[1], 0)
        eq_(res[2], udp._MIN_LEN)

########NEW FILE########
__FILENAME__ = test_vlan
# Copyright (C) 2012 Nippon Telegraph and Telephone Corporation.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# vim: tabstop=4 shiftwidth=4 softtabstop=4

import unittest
import logging
import struct
from struct import *
from nose.tools import *
from nose.plugins.skip import Skip, SkipTest
from ryu.ofproto import ether, inet
from ryu.lib.packet.ethernet import ethernet
from ryu.lib.packet.packet import Packet
from ryu.lib.packet.ipv4 import ipv4
from ryu.lib.packet.vlan import vlan
from ryu.lib.packet.vlan import svlan


LOG = logging.getLogger('test_vlan')


class Test_vlan(unittest.TestCase):
    """ Test case for vlan
    """

    pcp = 0
    cfi = 0
    vid = 32
    tci = pcp << 15 | cfi << 12 | vid
    ethertype = ether.ETH_TYPE_IP

    buf = pack(vlan._PACK_STR, tci, ethertype)

    v = vlan(pcp, cfi, vid, ethertype)

    def setUp(self):
        pass

    def tearDown(self):
        pass

    def find_protocol(self, pkt, name):
        for p in pkt.protocols:
            if p.protocol_name == name:
                return p

    def test_init(self):
        eq_(self.pcp, self.v.pcp)
        eq_(self.cfi, self.v.cfi)
        eq_(self.vid, self.v.vid)
        eq_(self.ethertype, self.v.ethertype)

    def test_parser(self):
        res, ptype, _ = self.v.parser(self.buf)

        eq_(res.pcp, self.pcp)
        eq_(res.cfi, self.cfi)
        eq_(res.vid, self.vid)
        eq_(res.ethertype, self.ethertype)
        eq_(ptype, ipv4)

    def test_serialize(self):
        data = bytearray()
        prev = None
        buf = self.v.serialize(data, prev)

        fmt = vlan._PACK_STR
        res = struct.unpack(fmt, buf)

        eq_(res[0], self.tci)
        eq_(res[1], self.ethertype)

    def _build_vlan(self):
        src_mac = '00:07:0d:af:f4:54'
        dst_mac = '00:00:00:00:00:00'
        ethertype = ether.ETH_TYPE_8021Q
        e = ethernet(dst_mac, src_mac, ethertype)

        version = 4
        header_length = 20
        tos = 0
        total_length = 24
        identification = 0x8a5d
        flags = 0
        offset = 1480
        ttl = 64
        proto = inet.IPPROTO_ICMP
        csum = 0xa7f2
        src = '131.151.32.21'
        dst = '131.151.32.129'
        option = 'TEST'
        ip = ipv4(version, header_length, tos, total_length, identification,
                  flags, offset, ttl, proto, csum, src, dst, option)

        p = Packet()

        p.add_protocol(e)
        p.add_protocol(self.v)
        p.add_protocol(ip)
        p.serialize()

        return p

    def test_build_vlan(self):
        p = self._build_vlan()

        e = self.find_protocol(p, "ethernet")
        ok_(e)
        eq_(e.ethertype, ether.ETH_TYPE_8021Q)

        v = self.find_protocol(p, "vlan")
        ok_(v)
        eq_(v.ethertype, ether.ETH_TYPE_IP)

        ip = self.find_protocol(p, "ipv4")
        ok_(ip)

        eq_(v.pcp, self.pcp)
        eq_(v.cfi, self.cfi)
        eq_(v.vid, self.vid)
        eq_(v.ethertype, self.ethertype)

    @raises(Exception)
    def test_malformed_vlan(self):
        m_short_buf = self.buf[1:vlan._MIN_LEN]
        vlan.parser(m_short_buf)


class Test_svlan(unittest.TestCase):

    pcp = 0
    cfi = 0
    vid = 32
    tci = pcp << 15 | cfi << 12 | vid
    ethertype = ether.ETH_TYPE_8021Q

    buf = pack(svlan._PACK_STR, tci, ethertype)

    sv = svlan(pcp, cfi, vid, ethertype)

    def setUp(self):
        pass

    def tearDown(self):
        pass

    def find_protocol(self, pkt, name):
        for p in pkt.protocols:
            if p.protocol_name == name:
                return p

    def test_init(self):
        eq_(self.pcp, self.sv.pcp)
        eq_(self.cfi, self.sv.cfi)
        eq_(self.vid, self.sv.vid)
        eq_(self.ethertype, self.sv.ethertype)

    def test_parser(self):
        res, ptype, _ = self.sv.parser(self.buf)

        eq_(res.pcp, self.pcp)
        eq_(res.cfi, self.cfi)
        eq_(res.vid, self.vid)
        eq_(res.ethertype, self.ethertype)
        eq_(ptype, vlan)

    def test_serialize(self):
        data = bytearray()
        prev = None
        buf = self.sv.serialize(data, prev)

        fmt = svlan._PACK_STR
        res = struct.unpack(fmt, buf)

        eq_(res[0], self.tci)
        eq_(res[1], self.ethertype)

    def _build_svlan(self):
        src_mac = '00:07:0d:af:f4:54'
        dst_mac = '00:00:00:00:00:00'
        ethertype = ether.ETH_TYPE_8021AD
        e = ethernet(dst_mac, src_mac, ethertype)

        pcp = 0
        cfi = 0
        vid = 32
        tci = pcp << 15 | cfi << 12 | vid
        ethertype = ether.ETH_TYPE_IP
        v = vlan(pcp, cfi, vid, ethertype)

        version = 4
        header_length = 20
        tos = 0
        total_length = 24
        identification = 0x8a5d
        flags = 0
        offset = 1480
        ttl = 64
        proto = inet.IPPROTO_ICMP
        csum = 0xa7f2
        src = '131.151.32.21'
        dst = '131.151.32.129'
        option = 'TEST'
        ip = ipv4(version, header_length, tos, total_length, identification,
                  flags, offset, ttl, proto, csum, src, dst, option)

        p = Packet()

        p.add_protocol(e)
        p.add_protocol(self.sv)
        p.add_protocol(v)
        p.add_protocol(ip)
        p.serialize()

        return p

    def test_build_svlan(self):
        p = self._build_svlan()

        e = self.find_protocol(p, "ethernet")
        ok_(e)
        eq_(e.ethertype, ether.ETH_TYPE_8021AD)

        sv = self.find_protocol(p, "svlan")
        ok_(sv)
        eq_(sv.ethertype, ether.ETH_TYPE_8021Q)

        v = self.find_protocol(p, "vlan")
        ok_(v)
        eq_(v.ethertype, ether.ETH_TYPE_IP)

        ip = self.find_protocol(p, "ipv4")
        ok_(ip)

        eq_(sv.pcp, self.pcp)
        eq_(sv.cfi, self.cfi)
        eq_(sv.vid, self.vid)
        eq_(sv.ethertype, self.ethertype)

    @raises(Exception)
    def test_malformed_svlan(self):
        m_short_buf = self.buf[1:svlan._MIN_LEN]
        svlan.parser(m_short_buf)

########NEW FILE########
__FILENAME__ = test_vrrp
# Copyright (C) 2013 Nippon Telegraph and Telephone Corporation.
# Copyright (C) 2013 Isaku Yamahata <yamahata at private email ne jp>
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# vim: tabstop=4 shiftwidth=4 softtabstop=4

import unittest
import logging
import struct
import inspect

from nose.tools import eq_, ok_
from nose.tools import raises

from ryu.ofproto import inet
from ryu.lib.packet import ipv4
from ryu.lib.packet import ipv6
from ryu.lib.packet import packet
from ryu.lib.packet import packet_utils
from ryu.lib.packet import vrrp
from ryu.lib import addrconv


LOG = logging.getLogger(__name__)


class Test_vrrpv2(unittest.TestCase):
    """ Test case for vrrp v2
    """
    version = vrrp.VRRP_VERSION_V2
    type_ = vrrp.VRRP_TYPE_ADVERTISEMENT
    vrid = 128
    priority = 100
    count_ip = 1
    auth_type = vrrp.VRRP_AUTH_NO_AUTH
    max_adver_int = 100
    checksum = 0
    ip_address = '192.168.0.1'
    auth_data = (0, 0)
    vrrpv2 = vrrp.vrrpv2.create(type_, vrid, priority, max_adver_int,
                                [ip_address])
    buf = struct.pack(vrrp.vrrpv2._PACK_STR + '4sII',
                      vrrp.vrrp_to_version_type(vrrp.VRRP_VERSION_V2, type_),
                      vrid, priority, count_ip,
                      auth_type, max_adver_int, checksum,
                      addrconv.ipv4.text_to_bin(ip_address),
                      auth_data[0], auth_data[1])

    def setUp(self):
        pass

    def tearDown(self):
        pass

    def test_init(self):
        eq_(self.type_, self.vrrpv2.type)
        eq_(self.vrid, self.vrrpv2.vrid)
        eq_(self.priority, self.vrrpv2.priority)
        eq_(self.count_ip, self.vrrpv2.count_ip)
        eq_(self.auth_type, self.vrrpv2.auth_type)
        eq_(1, len(self.vrrpv2.ip_addresses))
        eq_(self.ip_address, self.vrrpv2.ip_addresses[0])
        eq_(self.auth_data, self.vrrpv2.auth_data)

    def test_parser(self):
        vrrpv2, _cls, _ = self.vrrpv2.parser(self.buf)

        eq_(self.version, vrrpv2.version)
        eq_(self.type_, vrrpv2.type)
        eq_(self.vrid, vrrpv2.vrid)
        eq_(self.priority, vrrpv2.priority)
        eq_(self.count_ip, vrrpv2.count_ip)
        eq_(self.auth_type, vrrpv2.auth_type)
        eq_(self.max_adver_int, vrrpv2.max_adver_int)
        eq_(self.checksum, vrrpv2.checksum)
        eq_(1, len(vrrpv2.ip_addresses))
        eq_(str, type(vrrpv2.ip_addresses[0]))
        eq_(self.ip_address, vrrpv2.ip_addresses[0])
        eq_(self.auth_data, vrrpv2.auth_data)

    def test_serialize(self):
        src_ip = '192.168.0.1'
        dst_ip = vrrp.VRRP_IPV4_DST_ADDRESS
        prev = ipv4.ipv4(4, 5, 0, 0, 0, 0, 0, vrrp.VRRP_IPV4_TTL,
                         inet.IPPROTO_VRRP, 0, src_ip, dst_ip)

        type_ = vrrp.VRRP_TYPE_ADVERTISEMENT
        vrid = 5
        priority = 10
        max_adver_int = 30
        ip_address = '192.168.0.2'
        ip_addresses = [ip_address]

        vrrp_ = vrrp.vrrpv2.create(
            type_, vrid, priority, max_adver_int, ip_addresses)

        buf = vrrp_.serialize(bytearray(), prev)
        pack_str = vrrp.vrrpv2._PACK_STR + '4sII'
        pack_len = struct.calcsize(pack_str)
        res = struct.unpack(pack_str, str(buf))
        eq_(res[0], vrrp.vrrp_to_version_type(vrrp.VRRP_VERSION_V2, type_))
        eq_(res[1], vrid)
        eq_(res[2], priority)
        eq_(res[3], len(ip_addresses))
        eq_(res[4], vrrp.VRRP_AUTH_NO_AUTH)
        eq_(res[5], max_adver_int)
        # res[6] is checksum
        eq_(res[7], addrconv.ipv4.text_to_bin(ip_address))
        eq_(res[8], 0)
        eq_(res[9], 0)
        eq_(len(buf), pack_len)

        # checksum
        s = packet_utils.checksum(buf)
        eq_(0, s)

    @raises(Exception)
    def test_malformed_vrrpv2(self):
        m_short_buf = self.buf[1:vrrp.vrrpv2._MIN_LEN]
        vrrp.vrrp.parser(m_short_buf)

    def test_create_packet(self):
        primary_ip = '192.168.0.2'
        p0 = self.vrrpv2.create_packet(primary_ip)
        p0.serialize()
        p1 = packet.Packet(str(p0.data))
        p1.serialize()
        eq_(p0.data, p1.data)

    def _test_is_valid(self, type_=None, vrid=None, priority=None,
                       max_adver_int=None):
        if type_ is None:
            type_ = self.type_
        if vrid is None:
            vrid = self.vrid
        if priority is None:
            priority = self.priority
        if max_adver_int is None:
            max_adver_int = self.max_adver_int

        vrrp_ = vrrp.vrrpv2.create(type_, vrid, priority, max_adver_int,
                                   [self.ip_address])
        return vrrp_.is_valid()

    def test_is_valid_ok(self):
        ok_(self._test_is_valid())

    def test_is_valid_ng_type(self):
        ok_(not self._test_is_valid(type_=15))

    def test_is_valid_ng_vrid_min(self):
        vrid = vrrp.VRRP_VRID_MIN - 1
        ok_(not self._test_is_valid(vrid=vrid))

    def test_is_valid_ng_vrid_max(self):
        vrid = vrrp.VRRP_VRID_MAX + 1
        ok_(not self._test_is_valid(vrid=vrid))

    def test_is_valid_ng_priority_min(self):
        priority = vrrp.VRRP_PRIORITY_MIN - 1
        ok_(not self._test_is_valid(priority=priority))

    def test_is_valid_ng_priority_max(self):
        priority = vrrp.VRRP_PRIORITY_MAX + 1
        ok_(not self._test_is_valid(priority=priority))

    def test_is_valid_ng_adver_min(self):
        max_adver_int = vrrp.VRRP_V2_MAX_ADVER_INT_MIN - 1
        ok_(not self._test_is_valid(max_adver_int=max_adver_int))

    def test_is_valid_ng_adver_max(self):
        max_adver_int = vrrp.VRRP_V2_MAX_ADVER_INT_MAX + 1
        ok_(not self._test_is_valid(max_adver_int=max_adver_int))

    def test_to_string(self):
        vrrpv2_values = {'version': self.version,
                         'type': self.type_,
                         'vrid': self.vrid,
                         'priority': self.priority,
                         'count_ip': self.count_ip,
                         'max_adver_int': self.max_adver_int,
                         'checksum': self.vrrpv2.checksum,
                         'ip_addresses': [self.ip_address],
                         'auth_type': self.auth_type,
                         'auth_data': self.auth_data,
                         'identification': self.vrrpv2.identification}
        _vrrpv2_str = ','.join(['%s=%s' % (k, repr(vrrpv2_values[k]))
                                for k, v in inspect.getmembers(self.vrrpv2)
                                if k in vrrpv2_values])
        vrrpv2_str = '%s(%s)' % (vrrp.vrrpv2.__name__, _vrrpv2_str)

        eq_(str(self.vrrpv2), vrrpv2_str)
        eq_(repr(self.vrrpv2), vrrpv2_str)


class Test_vrrpv3_ipv4(unittest.TestCase):
    """ Test case for vrrp v3 IPv4
    """
    version = vrrp.VRRP_VERSION_V3
    type_ = vrrp.VRRP_TYPE_ADVERTISEMENT
    vrid = 128
    priority = 99
    count_ip = 1
    max_adver_int = 111
    checksum = 0
    ip_address = '192.168.0.1'
    vrrpv3 = vrrp.vrrpv3.create(type_, vrid, priority, max_adver_int,
                                [ip_address])
    buf = struct.pack(vrrp.vrrpv3._PACK_STR + '4s',
                      vrrp.vrrp_to_version_type(vrrp.VRRP_VERSION_V3, type_),
                      vrid, priority, count_ip,
                      max_adver_int, checksum,
                      addrconv.ipv4.text_to_bin(ip_address))

    def setUp(self):
        pass

    def tearDown(self):
        pass

    def test_init(self):
        eq_(self.type_, self.vrrpv3.type)
        eq_(self.vrid, self.vrrpv3.vrid)
        eq_(self.priority, self.vrrpv3.priority)
        eq_(self.count_ip, self.vrrpv3.count_ip)
        eq_(1, len(self.vrrpv3.ip_addresses))
        eq_(self.ip_address, self.vrrpv3.ip_addresses[0])

    def test_parser(self):
        vrrpv3, _cls, _ = self.vrrpv3.parser(self.buf)

        eq_(self.version, vrrpv3.version)
        eq_(self.type_, vrrpv3.type)
        eq_(self.vrid, vrrpv3.vrid)
        eq_(self.priority, vrrpv3.priority)
        eq_(self.count_ip, vrrpv3.count_ip)
        eq_(self.max_adver_int, vrrpv3.max_adver_int)
        eq_(self.checksum, vrrpv3.checksum)
        eq_(1, len(vrrpv3.ip_addresses))
        eq_(str, type(vrrpv3.ip_addresses[0]))
        eq_(self.ip_address, vrrpv3.ip_addresses[0])

    def test_serialize(self):
        src_ip = '192.168.0.1'
        dst_ip = vrrp.VRRP_IPV4_DST_ADDRESS
        prev = ipv4.ipv4(4, 5, 0, 0, 0, 0, 0, vrrp.VRRP_IPV4_TTL,
                         inet.IPPROTO_VRRP, 0, src_ip, dst_ip)

        type_ = vrrp.VRRP_TYPE_ADVERTISEMENT
        vrid = 5
        priority = 10
        max_adver_int = 30
        ip_address = '192.168.0.2'
        ip_addresses = [ip_address]

        vrrp_ = vrrp.vrrpv3.create(
            type_, vrid, priority, max_adver_int, ip_addresses)

        buf = vrrp_.serialize(bytearray(), prev)
        print(len(buf), type(buf), buf)
        pack_str = vrrp.vrrpv3._PACK_STR + '4s'
        pack_len = struct.calcsize(pack_str)
        res = struct.unpack(pack_str, str(buf))
        eq_(res[0], vrrp.vrrp_to_version_type(vrrp.VRRP_VERSION_V3, type_))
        eq_(res[1], vrid)
        eq_(res[2], priority)
        eq_(res[3], len(ip_addresses))
        eq_(res[4], max_adver_int)
        # res[5] is checksum
        eq_(res[6], addrconv.ipv4.text_to_bin(ip_address))
        eq_(len(buf), pack_len)
        print(res)

        # checksum
        ph = struct.pack('!4s4sxBH',
                         addrconv.ipv4.text_to_bin(src_ip),
                         addrconv.ipv4.text_to_bin(dst_ip),
                         inet.IPPROTO_VRRP, pack_len)
        s = packet_utils.checksum(ph + buf)
        eq_(0, s)

    @raises(Exception)
    def test_malformed_vrrpv3(self):
        m_short_buf = self.buf[1:vrrp.vrrpv3._MIN_LEN]
        vrrp.vrrp.parser(m_short_buf)

    def test_create_packet(self):
        primary_ip = '192.168.0.2'
        p0 = self.vrrpv3.create_packet(primary_ip)
        p0.serialize()
        p1 = packet.Packet(str(p0.data))
        p1.serialize()
        eq_(p0.data, p1.data)

    def _test_is_valid(self, type_=None, vrid=None, priority=None,
                       max_adver_int=None):
        if type_ is None:
            type_ = self.type_
        if vrid is None:
            vrid = self.vrid
        if priority is None:
            priority = self.priority
        if max_adver_int is None:
            max_adver_int = self.max_adver_int

        vrrp_ = vrrp.vrrpv3.create(type_, vrid, priority, max_adver_int,
                                   [self.ip_address])
        return vrrp_.is_valid()

    def test_is_valid_ok(self):
        ok_(self._test_is_valid())

    def test_is_valid_ng_type(self):
        ok_(not self._test_is_valid(type_=15))

    def test_is_valid_ng_vrid_min(self):
        vrid = vrrp.VRRP_VRID_MIN - 1
        ok_(not self._test_is_valid(vrid=vrid))

    def test_is_valid_ng_vrid_max(self):
        vrid = vrrp.VRRP_VRID_MAX + 1
        ok_(not self._test_is_valid(vrid=vrid))

    def test_is_valid_ng_priority_min(self):
        priority = vrrp.VRRP_PRIORITY_MIN - 1
        ok_(not self._test_is_valid(priority=priority))

    def test_is_valid_ng_priority_max(self):
        priority = vrrp.VRRP_PRIORITY_MAX + 1
        ok_(not self._test_is_valid(priority=priority))

    def test_is_valid_ng_adver_min(self):
        max_adver_int = vrrp.VRRP_V3_MAX_ADVER_INT_MIN - 1
        ok_(not self._test_is_valid(max_adver_int=max_adver_int))

    def test_is_valid_ng_adver_max(self):
        max_adver_int = vrrp.VRRP_V3_MAX_ADVER_INT_MAX + 1
        ok_(not self._test_is_valid(max_adver_int=max_adver_int))

    def test_to_string(self):
        vrrpv3_values = {'version': self.version,
                         'type': self.type_,
                         'vrid': self.vrid,
                         'priority': self.priority,
                         'count_ip': self.count_ip,
                         'max_adver_int': self.max_adver_int,
                         'checksum': self.vrrpv3.checksum,
                         'ip_addresses': [self.ip_address],
                         'auth_type': None,
                         'auth_data': None,
                         'identification': self.vrrpv3.identification}
        _vrrpv3_str = ','.join(['%s=%s' % (k, repr(vrrpv3_values[k]))
                                for k, v in inspect.getmembers(self.vrrpv3)
                                if k in vrrpv3_values])
        vrrpv3_str = '%s(%s)' % (vrrp.vrrpv3.__name__, _vrrpv3_str)

        eq_(str(self.vrrpv3), vrrpv3_str)
        eq_(repr(self.vrrpv3), vrrpv3_str)


class Test_vrrpv3_ipv6(unittest.TestCase):
    """ Test case for vrrp v3 IPv6
    """
    version = vrrp.VRRP_VERSION_V3
    type_ = vrrp.VRRP_TYPE_ADVERTISEMENT
    vrid = 128
    priority = 99
    count_ip = 1
    max_adver_int = 111
    checksum = 0
    ip_address = '2001:db8:2000::1'
    vrrpv3 = vrrp.vrrpv3.create(type_, vrid, priority, max_adver_int,
                                [ip_address])
    buf = struct.pack(vrrp.vrrpv3._PACK_STR + '16s',
                      vrrp.vrrp_to_version_type(vrrp.VRRP_VERSION_V3, type_),
                      vrid, priority, count_ip,
                      max_adver_int, checksum,
                      addrconv.ipv6.text_to_bin(ip_address))

    def setUp(self):
        pass

    def tearDown(self):
        pass

    def test_init(self):
        eq_(self.type_, self.vrrpv3.type)
        eq_(self.vrid, self.vrrpv3.vrid)
        eq_(self.priority, self.vrrpv3.priority)
        eq_(self.count_ip, self.vrrpv3.count_ip)
        eq_(1, len(self.vrrpv3.ip_addresses))
        eq_(self.ip_address, self.vrrpv3.ip_addresses[0])

    def test_parser(self):
        vrrpv3, _cls, _ = self.vrrpv3.parser(self.buf)

        eq_(self.version, vrrpv3.version)
        eq_(self.type_, vrrpv3.type)
        eq_(self.vrid, vrrpv3.vrid)
        eq_(self.priority, vrrpv3.priority)
        eq_(self.count_ip, vrrpv3.count_ip)
        eq_(self.max_adver_int, vrrpv3.max_adver_int)
        eq_(self.checksum, vrrpv3.checksum)
        eq_(1, len(vrrpv3.ip_addresses))
        eq_(str, type(vrrpv3.ip_addresses[0]))
        eq_(self.ip_address, vrrpv3.ip_addresses[0])

    def test_serialize(self):
        src_ip = '2001:db8:2000::1'
        dst_ip = vrrp.VRRP_IPV6_DST_ADDRESS
        prev = ipv6.ipv6(6, 0, 0, 0, inet.IPPROTO_VRRP,
                         vrrp.VRRP_IPV6_HOP_LIMIT, src_ip, dst_ip)

        type_ = vrrp.VRRP_TYPE_ADVERTISEMENT
        vrid = 5
        priority = 10
        max_adver_int = 30
        ip_address = '2001:db8:2000::2'
        ip_addresses = [ip_address]

        vrrp_ = vrrp.vrrpv3.create(
            type_, vrid, priority, max_adver_int, ip_addresses)

        buf = vrrp_.serialize(bytearray(), prev)
        print(len(buf), type(buf), buf)
        pack_str = vrrp.vrrpv3._PACK_STR + '16s'
        pack_len = struct.calcsize(pack_str)
        res = struct.unpack(pack_str, str(buf))
        eq_(res[0], vrrp.vrrp_to_version_type(vrrp.VRRP_VERSION_V3, type_))
        eq_(res[1], vrid)
        eq_(res[2], priority)
        eq_(res[3], len(ip_addresses))
        eq_(res[4], max_adver_int)
        # res[5] is checksum
        eq_(res[6], addrconv.ipv6.text_to_bin(ip_address))
        eq_(len(buf), pack_len)
        print(res)

        # checksum
        ph = struct.pack('!16s16sI3xB',
                         addrconv.ipv6.text_to_bin(src_ip),
                         addrconv.ipv6.text_to_bin(dst_ip),
                         pack_len, inet.IPPROTO_VRRP)
        s = packet_utils.checksum(ph + buf)
        eq_(0, s)

    @raises(Exception)
    def test_malformed_vrrpv3(self):
        m_short_buf = self.buf[1:vrrp.vrrpv3._MIN_LEN]
        vrrp.vrrp.parser(m_short_buf)

    def test_create_packet(self):
        primary_ip = '2001:db8:2000::3'
        p0 = self.vrrpv3.create_packet(primary_ip)
        p0.serialize()
        print(len(p0.data), p0.data)
        p1 = packet.Packet(str(p0.data))
        p1.serialize()
        print(len(p0.data), p0.data)
        print(len(p1.data), p1.data)
        eq_(p0.data, p1.data)

    def test_to_string(self):
        vrrpv3_values = {'version': self.version,
                         'type': self.type_,
                         'vrid': self.vrid,
                         'priority': self.priority,
                         'count_ip': self.count_ip,
                         'max_adver_int': self.max_adver_int,
                         'checksum': self.vrrpv3.checksum,
                         'ip_addresses': [self.ip_address],
                         'auth_type': None,
                         'auth_data': None,
                         'identification': self.vrrpv3.identification}
        _vrrpv3_str = ','.join(['%s=%s' % (k, repr(vrrpv3_values[k]))
                                for k, v in inspect.getmembers(self.vrrpv3)
                                if k in vrrpv3_values])
        vrrpv3_str = '%s(%s)' % (vrrp.vrrpv3.__name__, _vrrpv3_str)

        eq_(str(self.vrrpv3), vrrpv3_str)
        eq_(repr(self.vrrpv3), vrrpv3_str)

########NEW FILE########
__FILENAME__ = test_sample1
# vim: tabstop=4 shiftwidth=4 softtabstop=4

import unittest
from nose.tools import ok_, eq_
#from ryu.app.simple_switch import SimpleSwitch

import logging


LOG = logging.getLogger('ryu.tests.test_sample1')


class TestSample1(unittest.TestCase):

    def testS1Func1(self):
        LOG.debug('testS1Func1 - START')
        ok_(True)

    def testS1Func2(self):
        ok_(True)

########NEW FILE########
__FILENAME__ = test_sample2
# vim: tabstop=4 shiftwidth=4 softtabstop=4

import unittest
from nose.tools import ok_, eq_
#from ryu.app.simple_switch import SimpleSwitch


class TestSample2(unittest.TestCase):

    def testS2Func1(self):
        ok_(True)

    def testS2Func2(self):
        ok_(True)

########NEW FILE########
__FILENAME__ = dumper
# Copyright (C) 2013 Nippon Telegraph and Telephone Corporation.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.


import logging
import time

from ryu.base import app_manager
from ryu.controller import handler
from ryu.lib import hub
from ryu.topology import event
from ryu.topology import switches

LOG = logging.getLogger(__name__)


class DiscoveryEventDumper(app_manager.RyuApp):
    ''' This app dumps discovery events
    '''
    _CONTEXTS = {
        'switches': switches.Switches,
    }

    def __init__(self, *args, **kwargs):
        super(DiscoveryEventDumper, self).__init__(*args, **kwargs)

        # For testing when sync and async request.
#        self.threads.append(
#            hub.spawn(self._switch_request_sync, 5))
#        self.threads.append(
#            hub.spawn(self._switch_request_async, 10))
#
#        self.threads.append(
#            hub.spawn(self._link_request_sync, 5))
#        self.threads.append(
#            hub.spawn(self._link_request_async, 10))

        self.is_active = True

    @handler.set_ev_cls(event.EventSwitchEnter)
    def switch_enter_handler(self, ev):
        LOG.debug(ev)

    @handler.set_ev_cls(event.EventSwitchLeave)
    def switch_leave_handler(self, ev):
        LOG.debug(ev)

    @handler.set_ev_cls(event.EventPortAdd)
    def port_add_handler(self, ev):
        LOG.debug(ev)

    @handler.set_ev_cls(event.EventPortDelete)
    def port_delete_handler(self, ev):
        LOG.debug(ev)

    @handler.set_ev_cls(event.EventPortModify)
    def port_modify_handler(self, ev):
        LOG.debug(ev)

    @handler.set_ev_cls(event.EventLinkAdd)
    def link_add_handler(self, ev):
        LOG.debug(ev)

    @handler.set_ev_cls(event.EventLinkDelete)
    def link_del_handler(self, ev):
        LOG.debug(ev)

    def _switch_request_sync(self, interval):
        while self.is_active:
            request = event.EventSwitchRequest()
            LOG.debug('switch_request sync %s thread(%s)',
                      request, id(hub.getcurrent()))
            reply = self.send_request(request)
            LOG.debug('switch_reply sync %s', reply)
            if len(reply.switches) > 0:
                for sw in reply.switches:
                    LOG.debug('  %s', sw)
            hub.sleep(interval)

    def _switch_request_async(self, interval):
        while self.is_active:
            request = event.EventSwitchRequest()
            LOG.debug('switch_request async %s thread(%s)',
                      request, id(hub.getcurrent()))
            self.send_event(request.dst, request)

            start = time.time()
            busy = interval / 2
            i = 0
            while i < busy:
                if time.time() > start + i:
                    i += 1
                    LOG.debug('  thread is busy... %s/%s thread(%s)',
                              i, busy, id(hub.getcurrent()))
            LOG.debug('  thread yield to switch_reply handler. thread(%s)',
                      id(hub.getcurrent()))

            # yield
            hub.sleep(0)

            LOG.debug('  thread get back. thread(%s)',
                      id(hub.getcurrent()))
            hub.sleep(interval - busy)

    @handler.set_ev_cls(event.EventSwitchReply)
    def switch_reply_handler(self, reply):
        LOG.debug('switch_reply async %s', reply)
        if len(reply.switches) > 0:
            for sw in reply.switches:
                LOG.debug('  %s', sw)

    def _link_request_sync(self, interval):
        while self.is_active:
            request = event.EventLinkRequest()
            LOG.debug('link_request sync %s thread(%s)',
                      request, id(hub.getcurrent()))
            reply = self.send_request(request)
            LOG.debug('link_reply sync %s', reply)
            if len(reply.links) > 0:
                for link in reply.links:
                    LOG.debug('  %s', link)
            hub.sleep(interval)

    def _link_request_async(self, interval):
        while self.is_active:
            request = event.EventLinkRequest()
            LOG.debug('link_request async %s thread(%s)',
                      request, id(hub.getcurrent()))
            self.send_event(request.dst, request)

            start = time.time()
            busy = interval / 2
            i = 0
            while i < busy:
                if time.time() > start + i:
                    i += 1
                    LOG.debug('  thread is busy... %s/%s thread(%s)',
                              i, busy, id(hub.getcurrent()))
            LOG.debug('  thread yield to link_reply handler. thread(%s)',
                      id(hub.getcurrent()))

            # yield
            hub.sleep(0)

            LOG.debug('  thread get back. thread(%s)',
                      id(hub.getcurrent()))
            hub.sleep(interval - busy)

    @handler.set_ev_cls(event.EventLinkReply)
    def link_reply_handler(self, reply):
        LOG.debug('link_reply async %s', reply)
        if len(reply.links) > 0:
            for link in reply.links:
                LOG.debug('  %s', link)

########NEW FILE########
__FILENAME__ = event
# Copyright (C) 2013 Nippon Telegraph and Telephone Corporation.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import logging
from ryu.controller import event

LOG = logging.getLogger(__name__)


class EventSwitchBase(event.EventBase):
    def __init__(self, switch):
        super(EventSwitchBase, self).__init__()
        self.switch = switch

    def __str__(self):
        return '%s<dpid=%s, %s ports>' % \
            (self.__class__.__name__,
             self.switch.dp.id, len(self.switch.ports))


class EventSwitchEnter(EventSwitchBase):
    def __init__(self, switch):
        super(EventSwitchEnter, self).__init__(switch)


class EventSwitchLeave(EventSwitchBase):
    def __init__(self, switch):
        super(EventSwitchLeave, self).__init__(switch)


class EventPortBase(event.EventBase):
    def __init__(self, port):
        super(EventPortBase, self).__init__()
        self.port = port

    def __str__(self):
        return '%s<%s>' % (self.__class__.__name__, self.port)


class EventPortAdd(EventPortBase):
    def __init__(self, port):
        super(EventPortAdd, self).__init__(port)


class EventPortDelete(EventPortBase):
    def __init__(self, port):
        super(EventPortDelete, self).__init__(port)


class EventPortModify(EventPortBase):
    def __init__(self, port):
        super(EventPortModify, self).__init__(port)


class EventSwitchRequest(event.EventRequestBase):
    # If dpid is None, reply all list
    def __init__(self, dpid=None):
        super(EventSwitchRequest, self).__init__()
        self.dst = 'switches'
        self.dpid = dpid

    def __str__(self):
        return 'EventSwitchRequest<src=%s, dpid=%s>' % \
            (self.src, self.dpid)


class EventSwitchReply(event.EventReplyBase):
    def __init__(self, dst, switches):
        super(EventSwitchReply, self).__init__(dst)
        self.switches = switches

    def __str__(self):
        return 'EventSwitchReply<dst=%s, %s>' % \
            (self.dst, self.switches)


class EventLinkBase(event.EventBase):
    def __init__(self, link):
        super(EventLinkBase, self).__init__()
        self.link = link

    def __str__(self):
        return '%s<%s>' % (self.__class__.__name__, self.link)


class EventLinkAdd(EventLinkBase):
    def __init__(self, link):
        super(EventLinkAdd, self).__init__(link)


class EventLinkDelete(EventLinkBase):
    def __init__(self, link):
        super(EventLinkDelete, self).__init__(link)


class EventLinkRequest(event.EventRequestBase):
    # If dpid is None, reply all list
    def __init__(self, dpid=None):
        super(EventLinkRequest, self).__init__()
        self.dst = 'switches'
        self.dpid = dpid

    def __str__(self):
        return 'EventLinkRequest<src=%s, dpid=%s>' % \
            (self.src, self.dpid)


class EventLinkReply(event.EventReplyBase):
    def __init__(self, dst, dpid, links):
        super(EventLinkReply, self).__init__(dst)
        self.dpid = dpid
        self.links = links

    def __str__(self):
        return 'EventLinkReply<dst=%s, dpid=%s, links=%s>' % \
            (self.dst, self.dpid, len(self.links))

########NEW FILE########
__FILENAME__ = switches
# Copyright (C) 2013 Nippon Telegraph and Telephone Corporation.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import logging
import struct
import time
import json
from oslo.config import cfg

from ryu.topology import event
from ryu.base import app_manager
from ryu.controller import ofp_event
from ryu.controller.handler import set_ev_cls
from ryu.controller.handler import MAIN_DISPATCHER, DEAD_DISPATCHER
from ryu.exception import RyuException
from ryu.lib import addrconv, hub
from ryu.lib.mac import DONTCARE_STR
from ryu.lib.dpid import dpid_to_str, str_to_dpid
from ryu.lib.port_no import port_no_to_str
from ryu.lib.packet import packet, ethernet, lldp
from ryu.ofproto.ether import ETH_TYPE_LLDP
from ryu.ofproto import ofproto_v1_0
from ryu.ofproto import nx_match
from ryu.ofproto import ofproto_v1_2
from ryu.ofproto import ofproto_v1_3


LOG = logging.getLogger(__name__)


CONF = cfg.CONF

CONF.register_cli_opts([
    cfg.BoolOpt('observe-links', default=False,
                help='observe link discovery events.'),
    cfg.BoolOpt('install-lldp-flow', default=True,
                help='link discovery: explicitly install flow entry '
                     'to send lldp packet to controller'),
    cfg.BoolOpt('explicit-drop', default=True,
                help='link discovery: explicitly drop lldp packet in')
])


class Port(object):
    # This is data class passed by EventPortXXX
    def __init__(self, dpid, ofproto, ofpport):
        super(Port, self).__init__()

        self.dpid = dpid
        self._ofproto = ofproto
        self._config = ofpport.config
        self._state = ofpport.state

        self.port_no = ofpport.port_no
        self.hw_addr = ofpport.hw_addr
        self.name = ofpport.name

    def is_reserved(self):
        return self.port_no > self._ofproto.OFPP_MAX

    def is_down(self):
        return (self._state & self._ofproto.OFPPS_LINK_DOWN) > 0 \
            or (self._config & self._ofproto.OFPPC_PORT_DOWN) > 0

    def is_live(self):
        # NOTE: OF1.2 has OFPPS_LIVE state
        #       return (self._state & self._ofproto.OFPPS_LIVE) > 0
        return not self.is_down()

    def to_dict(self):
        return {'dpid': dpid_to_str(self.dpid),
                'port_no': port_no_to_str(self.port_no),
                'hw_addr': self.hw_addr,
                'name': self.name.rstrip('\0')}

    # for Switch.del_port()
    def __eq__(self, other):
        return self.dpid == other.dpid and self.port_no == other.port_no

    def __ne__(self, other):
        return not self.__eq__(other)

    def __hash__(self):
        return hash((self.dpid, self.port_no))

    def __str__(self):
        LIVE_MSG = {False: 'DOWN', True: 'LIVE'}
        return 'Port<dpid=%s, port_no=%s, %s>' % \
            (self.dpid, self.port_no, LIVE_MSG[self.is_live()])


class Switch(object):
    # This is data class passed by EventSwitchXXX
    def __init__(self, dp):
        super(Switch, self).__init__()

        self.dp = dp
        self.ports = []

    def add_port(self, ofpport):
        port = Port(self.dp.id, self.dp.ofproto, ofpport)
        if not port.is_reserved():
            self.ports.append(port)

    def del_port(self, ofpport):
        self.ports.remove(Port(ofpport))

    def to_dict(self):
        d = {'dpid': dpid_to_str(self.dp.id),
             'ports': [port.to_dict() for port in self.ports]}
        return d

    def __str__(self):
        msg = 'Switch<dpid=%s, ' % self.dp.id
        for port in self.ports:
            msg += str(port) + ' '

        msg += '>'
        return msg


class Link(object):
    # This is data class passed by EventLinkXXX
    def __init__(self, src, dst):
        super(Link, self).__init__()
        self.src = src
        self.dst = dst

    def to_dict(self):
        d = {'src': self.src.to_dict(),
             'dst': self.dst.to_dict()}
        return d

    # this type is used for key value of LinkState
    def __eq__(self, other):
        return self.src == other.src and self.dst == other.dst

    def __ne__(self, other):
        return not self.__eq__(other)

    def __hash__(self):
        return hash((self.src, self.dst))

    def __str__(self):
        return 'Link: %s to %s' % (self.src, self.dst)


class PortState(dict):
    # dict: int port_no -> OFPPort port
    # OFPPort is defined in ryu.ofproto.ofproto_v1_X_parser
    def __init__(self):
        super(PortState, self).__init__()

    def add(self, port_no, port):
        self[port_no] = port

    def remove(self, port_no):
        del self[port_no]

    def modify(self, port_no, port):
        self[port_no] = port


class PortData(object):
    def __init__(self, is_down, lldp_data):
        super(PortData, self).__init__()
        self.is_down = is_down
        self.lldp_data = lldp_data
        self.timestamp = None
        self.sent = 0

    def lldp_sent(self):
        self.timestamp = time.time()
        self.sent += 1

    def lldp_received(self):
        self.sent = 0

    def lldp_dropped(self):
        return self.sent

    def clear_timestamp(self):
        self.timestamp = None

    def set_down(self, is_down):
        self.is_down = is_down

    def __str__(self):
        return 'PortData<live=%s, timestamp=%s, sent=%d>' \
            % (not self.is_down, self.timestamp, self.sent)


class PortDataState(dict):
    # dict: Port class -> PortData class
    # slimed down version of OrderedDict as python 2.6 doesn't support it.
    _PREV = 0
    _NEXT = 1
    _KEY = 2

    def __init__(self):
        super(PortDataState, self).__init__()
        self._root = root = []          # sentinel node
        root[:] = [root, root, None]    # [_PREV, _NEXT, _KEY]
                                        # doubly linked list
        self._map = {}

    def _remove_key(self, key):
        link_prev, link_next, key = self._map.pop(key)
        link_prev[self._NEXT] = link_next
        link_next[self._PREV] = link_prev

    def _append_key(self, key):
        root = self._root
        last = root[self._PREV]
        last[self._NEXT] = root[self._PREV] = self._map[key] = [last, root,
                                                                key]

    def _prepend_key(self, key):
        root = self._root
        first = root[self._NEXT]
        first[self._PREV] = root[self._NEXT] = self._map[key] = [root, first,
                                                                 key]

    def _move_last_key(self, key):
        self._remove_key(key)
        self._append_key(key)

    def _move_front_key(self, key):
        self._remove_key(key)
        self._prepend_key(key)

    def add_port(self, port, lldp_data):
        if port not in self:
            self._prepend_key(port)
            self[port] = PortData(port.is_down(), lldp_data)
        else:
            self[port].is_down = port.is_down()

    def lldp_sent(self, port):
        port_data = self[port]
        port_data.lldp_sent()
        self._move_last_key(port)
        return port_data

    def lldp_received(self, port):
        self[port].lldp_received()

    def move_front(self, port):
        port_data = self.get(port, None)
        if port_data is not None:
            port_data.clear_timestamp()
            self._move_front_key(port)

    def set_down(self, port):
        is_down = port.is_down()
        port_data = self[port]
        port_data.set_down(is_down)
        port_data.clear_timestamp()
        if not is_down:
            self._move_front_key(port)
        return is_down

    def get_port(self, port):
        return self[port]

    def del_port(self, port):
        del self[port]
        self._remove_key(port)

    def __iter__(self):
        root = self._root
        curr = root[self._NEXT]
        while curr is not root:
            yield curr[self._KEY]
            curr = curr[self._NEXT]

    def clear(self):
        for node in self._map.itervalues():
            del node[:]
        root = self._root
        root[:] = [root, root, None]
        self._map.clear()
        dict.clear(self)

    def items(self):
        'od.items() -> list of (key, value) pairs in od'
        return [(key, self[key]) for key in self]

    def iteritems(self):
        'od.iteritems -> an iterator over the (key, value) pairs in od'
        for k in self:
            yield (k, self[k])


class LinkState(dict):
    # dict: Link class -> timestamp
    def __init__(self):
        super(LinkState, self).__init__()
        self._map = {}

    def get_peer(self, src):
        return self._map.get(src, None)

    def update_link(self, src, dst):
        link = Link(src, dst)

        self[link] = time.time()
        self._map[src] = dst

        # return if the reverse link is also up or not
        rev_link = Link(dst, src)
        return rev_link in self

    def link_down(self, link):
        del self[link]
        del self._map[link.src]

    def rev_link_set_timestamp(self, rev_link, timestamp):
        # rev_link may or may not in LinkSet
        if rev_link in self:
            self[rev_link] = timestamp

    def port_deleted(self, src):
        dst = self.get_peer(src)
        if dst is None:
            raise KeyError()

        link = Link(src, dst)
        rev_link = Link(dst, src)
        del self[link]
        del self._map[src]
        # reverse link might not exist
        self.pop(rev_link, None)
        rev_link_dst = self._map.pop(dst, None)

        return dst, rev_link_dst


class LLDPPacket(object):
    # make a LLDP packet for link discovery.

    CHASSIS_ID_PREFIX = 'dpid:'
    CHASSIS_ID_PREFIX_LEN = len(CHASSIS_ID_PREFIX)
    CHASSIS_ID_FMT = CHASSIS_ID_PREFIX + '%s'

    PORT_ID_STR = '!I'      # uint32_t
    PORT_ID_SIZE = 4

    class LLDPUnknownFormat(RyuException):
        message = '%(msg)s'

    @staticmethod
    def lldp_packet(dpid, port_no, dl_addr, ttl):
        pkt = packet.Packet()

        dst = lldp.LLDP_MAC_NEAREST_BRIDGE
        src = dl_addr
        ethertype = ETH_TYPE_LLDP
        eth_pkt = ethernet.ethernet(dst, src, ethertype)
        pkt.add_protocol(eth_pkt)

        tlv_chassis_id = lldp.ChassisID(
            subtype=lldp.ChassisID.SUB_LOCALLY_ASSIGNED,
            chassis_id=LLDPPacket.CHASSIS_ID_FMT %
            dpid_to_str(dpid))

        tlv_port_id = lldp.PortID(subtype=lldp.PortID.SUB_PORT_COMPONENT,
                                  port_id=struct.pack(
                                      LLDPPacket.PORT_ID_STR,
                                      port_no))

        tlv_ttl = lldp.TTL(ttl=ttl)
        tlv_end = lldp.End()

        tlvs = (tlv_chassis_id, tlv_port_id, tlv_ttl, tlv_end)
        lldp_pkt = lldp.lldp(tlvs)
        pkt.add_protocol(lldp_pkt)

        pkt.serialize()
        return pkt.data

    @staticmethod
    def lldp_parse(data):
        pkt = packet.Packet(data)
        eth_pkt = pkt.next()
        assert type(eth_pkt) == ethernet.ethernet

        lldp_pkt = pkt.next()
        if type(lldp_pkt) != lldp.lldp:
            raise LLDPPacket.LLDPUnknownFormat()

        tlv_chassis_id = lldp_pkt.tlvs[0]
        if tlv_chassis_id.subtype != lldp.ChassisID.SUB_LOCALLY_ASSIGNED:
            raise LLDPPacket.LLDPUnknownFormat(
                msg='unknown chassis id subtype %d' % tlv_chassis_id.subtype)
        chassis_id = tlv_chassis_id.chassis_id
        if not chassis_id.startswith(LLDPPacket.CHASSIS_ID_PREFIX):
            raise LLDPPacket.LLDPUnknownFormat(
                msg='unknown chassis id format %s' % chassis_id)
        src_dpid = str_to_dpid(chassis_id[LLDPPacket.CHASSIS_ID_PREFIX_LEN:])

        tlv_port_id = lldp_pkt.tlvs[1]
        if tlv_port_id.subtype != lldp.PortID.SUB_PORT_COMPONENT:
            raise LLDPPacket.LLDPUnknownFormat(
                msg='unknown port id subtype %d' % tlv_port_id.subtype)
        port_id = tlv_port_id.port_id
        if len(port_id) != LLDPPacket.PORT_ID_SIZE:
            raise LLDPPacket.LLDPUnknownFormat(
                msg='unknown port id %d' % port_id)
        (src_port_no, ) = struct.unpack(LLDPPacket.PORT_ID_STR, port_id)

        return src_dpid, src_port_no


class Switches(app_manager.RyuApp):
    _EVENTS = [event.EventSwitchEnter, event.EventSwitchLeave,
               event.EventPortAdd, event.EventPortDelete,
               event.EventPortModify,
               event.EventLinkAdd, event.EventLinkDelete]

    DEFAULT_TTL = 120  # unused. ignored.
    LLDP_PACKET_LEN = len(LLDPPacket.lldp_packet(0, 0, DONTCARE_STR, 0))

    LLDP_SEND_GUARD = .05
    LLDP_SEND_PERIOD_PER_PORT = .9
    TIMEOUT_CHECK_PERIOD = 5.
    LINK_TIMEOUT = TIMEOUT_CHECK_PERIOD * 2
    LINK_LLDP_DROP = 5

    def __init__(self, *args, **kwargs):
        super(Switches, self).__init__(*args, **kwargs)

        self.name = 'switches'
        self.dps = {}                 # datapath_id => Datapath class
        self.port_state = {}          # datapath_id => ports
        self.ports = PortDataState()  # Port class -> PortData class
        self.links = LinkState()      # Link class -> timestamp
        self.is_active = True

        self.link_discovery = CONF.observe_links
        if self.link_discovery:
            self.install_flow = CONF.install_lldp_flow
            self.explicit_drop = CONF.explicit_drop
            self.lldp_event = hub.Event()
            self.link_event = hub.Event()
            self.threads.append(hub.spawn(self.lldp_loop))
            self.threads.append(hub.spawn(self.link_loop))

    def close(self):
        self.is_active = False
        if self.link_discovery:
            self.lldp_event.set()
            self.link_event.set()
            hub.joinall(self.threads)

    def _register(self, dp):
        assert dp.id is not None
        assert dp.id not in self.dps

        self.dps[dp.id] = dp
        self.port_state[dp.id] = PortState()
        for port in dp.ports.values():
            self.port_state[dp.id].add(port.port_no, port)

    def _unregister(self, dp):
        if dp.id in self.dps:
            del self.dps[dp.id]
            del self.port_state[dp.id]

    def _get_switch(self, dpid):
        if dpid in self.dps:
            switch = Switch(self.dps[dpid])
            for ofpport in self.port_state[dpid].itervalues():
                switch.add_port(ofpport)
            return switch

    def _get_port(self, dpid, port_no):
        switch = self._get_switch(dpid)
        if switch:
            for p in switch.ports:
                if p.port_no == port_no:
                    return p

    def _port_added(self, port):
        lldp_data = LLDPPacket.lldp_packet(
            port.dpid, port.port_no, port.hw_addr, self.DEFAULT_TTL)
        self.ports.add_port(port, lldp_data)
        # LOG.debug('_port_added dpid=%s, port_no=%s, live=%s',
        #           port.dpid, port.port_no, port.is_live())

    def _link_down(self, port):
        try:
            dst, rev_link_dst = self.links.port_deleted(port)
        except KeyError:
            # LOG.debug('key error. src=%s, dst=%s',
            #           port, self.links.get_peer(port))
            return
        link = Link(port, dst)
        self.send_event_to_observers(event.EventLinkDelete(link))
        if rev_link_dst:
            rev_link = Link(dst, rev_link_dst)
            self.send_event_to_observers(event.EventLinkDelete(rev_link))
        self.ports.move_front(dst)

    @set_ev_cls(ofp_event.EventOFPStateChange,
                [MAIN_DISPATCHER, DEAD_DISPATCHER])
    def state_change_handler(self, ev):
        dp = ev.datapath
        assert dp is not None
        LOG.debug(dp)

        if ev.state == MAIN_DISPATCHER:
            self._register(dp)
            switch = self._get_switch(dp.id)
            LOG.debug('register %s', switch)
            self.send_event_to_observers(event.EventSwitchEnter(switch))

            if not self.link_discovery:
                return

            if self.install_flow:
                ofproto = dp.ofproto
                ofproto_parser = dp.ofproto_parser

                # TODO:XXX need other versions
                if ofproto.OFP_VERSION == ofproto_v1_0.OFP_VERSION:
                    rule = nx_match.ClsRule()
                    rule.set_dl_dst(addrconv.mac.text_to_bin(
                                    lldp.LLDP_MAC_NEAREST_BRIDGE))
                    rule.set_dl_type(ETH_TYPE_LLDP)
                    actions = [ofproto_parser.OFPActionOutput(
                        ofproto.OFPP_CONTROLLER, self.LLDP_PACKET_LEN)]
                    dp.send_flow_mod(
                        rule=rule, cookie=0, command=ofproto.OFPFC_ADD,
                        idle_timeout=0, hard_timeout=0, actions=actions)
                else:
                    LOG.error('cannot install flow. unsupported version. %x',
                              dp.ofproto.OFP_VERSION)

            for port in switch.ports:
                if not port.is_reserved():
                    self._port_added(port)
            self.lldp_event.set()

        elif ev.state == DEAD_DISPATCHER:
            # dp.id is None when datapath dies before handshake
            if dp.id is None:
                return
            switch = self._get_switch(dp.id)
            self._unregister(dp)
            LOG.debug('unregister %s', switch)
            self.send_event_to_observers(event.EventSwitchLeave(switch))

            if not self.link_discovery:
                return

            for port in switch.ports:
                if not port.is_reserved():
                    self.ports.del_port(port)
                    self._link_down(port)
            self.lldp_event.set()

    @set_ev_cls(ofp_event.EventOFPPortStatus, MAIN_DISPATCHER)
    def port_status_handler(self, ev):
        msg = ev.msg
        reason = msg.reason
        dp = msg.datapath
        ofpport = msg.desc

        if reason == dp.ofproto.OFPPR_ADD:
            #LOG.debug('A port was added.' +
            #          '(datapath id = %s, port number = %s)',
            #          dp.id, ofpport.port_no)
            self.port_state[dp.id].add(ofpport.port_no, ofpport)
            self.send_event_to_observers(
                event.EventPortAdd(Port(dp.id, dp.ofproto, ofpport)))

            if not self.link_discovery:
                return

            port = self._get_port(dp.id, ofpport.port_no)
            if port and not port.is_reserved():
                self._port_added(port)
                self.lldp_event.set()

        elif reason == dp.ofproto.OFPPR_DELETE:
            #LOG.debug('A port was deleted.' +
            #          '(datapath id = %s, port number = %s)',
            #          dp.id, ofpport.port_no)
            self.port_state[dp.id].remove(ofpport.port_no)
            self.send_event_to_observers(
                event.EventPortDelete(Port(dp.id, dp.ofproto, ofpport)))

            if not self.link_discovery:
                return

            port = self._get_port(dp.id, ofpport.port_no)
            if port and not port.is_reserved():
                self.ports.del_port(port)
                self._link_down(port)
                self.lldp_event.set()

        else:
            assert reason == dp.ofproto.OFPPR_MODIFY
            #LOG.debug('A port was modified.' +
            #          '(datapath id = %s, port number = %s)',
            #          dp.id, ofpport.port_no)
            self.port_state[dp.id].modify(ofpport.port_no, ofpport)
            self.send_event_to_observers(
                event.EventPortModify(Port(dp.id, dp.ofproto, ofpport)))

            if not self.link_discovery:
                return

            port = self._get_port(dp.id, ofpport.port_no)
            if port and not port.is_reserved():
                if self.ports.set_down(port):
                    self._link_down(port)
                self.lldp_event.set()

    @staticmethod
    def _drop_packet(msg):
        buffer_id = msg.buffer_id
        if buffer_id == msg.datapath.ofproto.OFP_NO_BUFFER:
            return

        dp = msg.datapath
        # TODO:XXX
        if dp.ofproto.OFP_VERSION == ofproto_v1_0.OFP_VERSION:
            dp.send_packet_out(buffer_id, msg.in_port, [])
        else:
            LOG.error('cannot drop_packet. unsupported version. %x',
                      dp.ofproto.OFP_VERSION)

    @set_ev_cls(ofp_event.EventOFPPacketIn, MAIN_DISPATCHER)
    def packet_in_handler(self, ev):
        if not self.link_discovery:
            return

        msg = ev.msg
        try:
            src_dpid, src_port_no = LLDPPacket.lldp_parse(msg.data)
        except LLDPPacket.LLDPUnknownFormat as e:
            # This handler can receive all the packtes which can be
            # not-LLDP packet. Ignore it silently
            return

        dst_dpid = msg.datapath.id
        dst_port_no = msg.in_port

        src = self._get_port(src_dpid, src_port_no)
        if not src or src.dpid == dst_dpid:
            return
        try:
            self.ports.lldp_received(src)
        except KeyError:
            # There are races between EventOFPPacketIn and
            # EventDPPortAdd. So packet-in event can happend before
            # port add event. In that case key error can happend.
            # LOG.debug('lldp_received: KeyError %s', e)
            pass

        dst = self._get_port(dst_dpid, dst_port_no)
        if not dst:
            return

        old_peer = self.links.get_peer(src)
        # LOG.debug("Packet-In")
        # LOG.debug("  src=%s", src)
        # LOG.debug("  dst=%s", dst)
        # LOG.debug("  old_peer=%s", old_peer)
        if old_peer and old_peer != dst:
            old_link = Link(src, old_peer)
            self.send_event_to_observers(event.EventLinkDelete(old_link))

        link = Link(src, dst)
        if not link in self.links:
            self.send_event_to_observers(event.EventLinkAdd(link))

        if not self.links.update_link(src, dst):
            # reverse link is not detected yet.
            # So schedule the check early because it's very likely it's up
            self.ports.move_front(dst)
            self.lldp_event.set()
        if self.explicit_drop:
            self._drop_packet(msg)

    def send_lldp_packet(self, port):
        try:
            port_data = self.ports.lldp_sent(port)
        except KeyError as e:
            # ports can be modified during our sleep in self.lldp_loop()
            # LOG.debug('send_lldp: KeyError %s', e)
            return
        if port_data.is_down:
            return

        dp = self.dps.get(port.dpid, None)
        if dp is None:
            # datapath was already deleted
            return

        # LOG.debug('lldp sent dpid=%s, port_no=%d', dp.id, port.port_no)
        # TODO:XXX
        if dp.ofproto.OFP_VERSION == ofproto_v1_0.OFP_VERSION:
            actions = [dp.ofproto_parser.OFPActionOutput(port.port_no)]
            dp.send_packet_out(actions=actions, data=port_data.lldp_data)
        else:
            LOG.error('cannot send lldp packet. unsupported version. %x',
                      dp.ofproto.OFP_VERSION)

    def lldp_loop(self):
        while self.is_active:
            self.lldp_event.clear()

            now = time.time()
            timeout = None
            ports_now = []
            ports = []
            for (key, data) in self.ports.items():
                if data.timestamp is None:
                    ports_now.append(key)
                    continue

                expire = data.timestamp + self.LLDP_SEND_PERIOD_PER_PORT
                if expire <= now:
                    ports.append(key)
                    continue

                timeout = expire - now
                break

            for port in ports_now:
                self.send_lldp_packet(port)
            for port in ports:
                self.send_lldp_packet(port)
                hub.sleep(self.LLDP_SEND_GUARD)      # don't burst

            if timeout is not None and ports:
                timeout = 0     # We have already slept
            # LOG.debug('lldp sleep %s', timeout)
            self.lldp_event.wait(timeout=timeout)

    def link_loop(self):
        while self.is_active:
            self.link_event.clear()

            now = time.time()
            deleted = []
            for (link, timestamp) in self.links.items():
                # LOG.debug('%s timestamp %d (now %d)', link, timestamp, now)
                if timestamp + self.LINK_TIMEOUT < now:
                    src = link.src
                    if src in self.ports:
                        port_data = self.ports.get_port(src)
                        # LOG.debug('port_data %s', port_data)
                        if port_data.lldp_dropped() > self.LINK_LLDP_DROP:
                            deleted.append(link)

            for link in deleted:
                self.links.link_down(link)
                # LOG.debug('delete %s', link)
                self.send_event_to_observers(event.EventLinkDelete(link))

                dst = link.dst
                rev_link = Link(dst, link.src)
                if rev_link not in deleted:
                    # It is very likely that the reverse link is also
                    # disconnected. Check it early.
                    expire = now - self.LINK_TIMEOUT
                    self.links.rev_link_set_timestamp(rev_link, expire)
                    if dst in self.ports:
                        self.ports.move_front(dst)
                        self.lldp_event.set()

            self.link_event.wait(timeout=self.TIMEOUT_CHECK_PERIOD)

    @set_ev_cls(event.EventSwitchRequest)
    def switch_request_handler(self, req):
        # LOG.debug(req)
        dpid = req.dpid

        switches = []
        if dpid is None:
            # reply all list
            for dp in self.dps.itervalues():
                switches.append(self._get_switch(dp.id))
        elif dpid in self.dps:
            switches.append(self._get_switch(dpid))

        rep = event.EventSwitchReply(req.src, switches)
        self.reply_to_request(req, rep)

    @set_ev_cls(event.EventLinkRequest)
    def link_request_handler(self, req):
        # LOG.debug(req)
        dpid = req.dpid

        if dpid is None:
            links = self.links
        else:
            links = [link for link in self.links if link.src.dpid == dpid]
        rep = event.EventLinkReply(req.src, dpid, links)
        self.reply_to_request(req, rep)


def get_switch(app, dpid=None):
    rep = app.send_request(event.EventSwitchRequest(dpid))
    return rep.switches


def get_all_switch(app):
    return get_switch(app)


def get_link(app, dpid=None):
    rep = app.send_request(event.EventLinkRequest(dpid))
    return rep.links


def get_all_link(app):
    return get_link(app)

########NEW FILE########
__FILENAME__ = utils
# Copyright (C) 2011 Nippon Telegraph and Telephone Corporation.
# Copyright (C) 2011 Isaku Yamahata <yamahata at valinux co jp>
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# Copyright 2011 OpenStack LLC.
# All Rights Reserved.
#
#    Licensed under the Apache License, Version 2.0 (the "License"); you may
#    not use this file except in compliance with the License. You may obtain
#    a copy of the License at
#
#         http://www.apache.org/licenses/LICENSE-2.0
#
#    Unless required by applicable law or agreed to in writing, software
#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
#    License for the specific language governing permissions and limitations
#    under the License.


import inspect
import logging
import os
import sys
import re

LOG = logging.getLogger('ryu.utils')


def chop_py_suffix(p):
    for suf in ['.py', '.pyc', '.pyo']:
        if p.endswith(suf):
            return p[:-len(suf)]
    return p


def _likely_same(a, b):
    try:
        if os.path.samefile(a, b):
            return True
    except OSError:
        # m.__file__ is not always accessible.  eg. egg
        return False
    if chop_py_suffix(a) == chop_py_suffix(b):
        return True
    return False


def _find_loaded_module(modpath):
    # copy() to avoid RuntimeError: dictionary changed size during iteration
    for k, m in sys.modules.copy().iteritems():
        if k == '__main__':
            continue
        if not hasattr(m, '__file__'):
            continue
        if _likely_same(m.__file__, modpath):
            return m
    return None


def import_module(modname):
    try:
        __import__(modname)
    except:
        abspath = os.path.abspath(modname)
        mod = _find_loaded_module(abspath)
        if mod:
            return mod
        opath = sys.path
        sys.path.append(os.path.dirname(abspath))
        name = os.path.basename(modname)
        if name.endswith('.py'):
            name = name[:-3]
        __import__(name)
        sys.path = opath
        return sys.modules[name]
    return sys.modules[modname]


def round_up(x, y):
    return ((x + y - 1) / y) * y


def hex_array(data):
    """Convert string into array of hexes to be printed."""
    return ' '.join(hex(ord(char)) for char in data)


def bytearray_to_hex(data):
    """Convert bytearray into array of hexes to be printed."""
    return ' '.join(hex(byte) for byte in data)


# the following functions are taken from OpenStack
#
# Get requirements from the first file that exists
def get_reqs_from_files(requirements_files):
    for requirements_file in requirements_files:
        if os.path.exists(requirements_file):
            with open(requirements_file, 'r') as fil:
                return fil.read().split('\n')
    return []


def parse_requirements(requirements_files=['requirements.txt',
                                           'tools/pip-requires']):
    requirements = []
    for line in get_reqs_from_files(requirements_files):
        # For the requirements list, we need to inject only the portion
        # after egg= so that distutils knows the package it's looking for
        # such as:
        # -e git://github.com/openstack/nova/master#egg=nova
        if re.match(r'\s*-e\s+', line):
            requirements.append(re.sub(r'\s*-e\s+.*#egg=(.*)$', r'\1',
                                line))
        # such as:
        # http://github.com/openstack/nova/zipball/master#egg=nova
        elif re.match(r'\s*https?:', line):
            requirements.append(re.sub(r'\s*https?:.*#egg=(.*)$', r'\1',
                                line))
        # -f lines are for index locations, and don't get used here
        elif re.match(r'\s*-f\s+', line):
            pass
        else:
            requirements.append(line)

    return requirements

########NEW FILE########
__FILENAME__ = install_venv
#!/usr/bin/env python
# vim: tabstop=4 shiftwidth=4 softtabstop=4

# Copyright 2010 United States Government as represented by the
# Administrator of the National Aeronautics and Space Administration.
# All Rights Reserved.
#
# Copyright 2010 OpenStack LLC.
#
#    Licensed under the Apache License, Version 2.0 (the "License"); you may
#    not use this file except in compliance with the License. You may obtain
#    a copy of the License at
#
#         http://www.apache.org/licenses/LICENSE-2.0
#
#    Unless required by applicable law or agreed to in writing, software
#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
#    License for the specific language governing permissions and limitations
#    under the License.

"""
Installation script for Quantum's development virtualenv
"""

import os
import subprocess
import sys


ROOT = os.path.dirname(os.path.dirname(os.path.realpath(__file__)))
VENV = os.path.join(ROOT, '.venv')
PIP_REQUIRES = os.path.join(ROOT, 'tools', 'pip-requires')
TEST_REQUIRES = os.path.join(ROOT, 'tools', 'test-requires')
PY_VERSION = "python%s.%s" % (sys.version_info[0], sys.version_info[1])

VENV_EXISTS = bool(os.path.exists(VENV))

def die(message, *args):
    print >> sys.stderr, message % args
    sys.exit(1)


def run_command(cmd, redirect_output=True, check_exit_code=True):
    """
    Runs a command in an out-of-process shell, returning the
    output of that command.  Working directory is ROOT.
    """
    if redirect_output:
        stdout = subprocess.PIPE
    else:
        stdout = None
    proc = subprocess.Popen(cmd, cwd=ROOT, stdout=stdout)
    output = proc.communicate()[0]
    if check_exit_code and proc.returncode != 0:
        raise Exception('Command "%s" failed.\n%s' % (' '.join(cmd), output))
    return output


HAS_EASY_INSTALL = bool(run_command(['which', 'easy_install'],
                                    check_exit_code=False).strip())
HAS_VIRTUALENV = bool(run_command(['which', 'virtualenv'],
                                    check_exit_code=False).strip())


def check_dependencies():
    """Make sure virtualenv is in the path."""

    if not HAS_VIRTUALENV:
        raise Exception('Virtualenv not found. ' + \
                         'Try installing python-virtualenv')
    print 'done.'


def create_virtualenv(venv=VENV, install_pip=False):
    """Creates the virtual environment and installs PIP only into the
    virtual environment
    """
    print 'Creating venv...',

    install = ['virtualenv', '-q', venv]
    run_command(install)

    print 'done.'
    print 'Installing pip in virtualenv...',
    if install_pip and \
            not run_command(['tools/with_venv.sh', 'easy_install',
                             'pip>1.0']):
        die("Failed to install pip.")
    print 'done.'


def install_dependencies(venv=VENV):
    print 'Installing dependencies with pip (this can take a while)...'
    run_command(['tools/with_venv.sh', 'pip', 'install', '-r',
                 PIP_REQUIRES], redirect_output=False)
    run_command(['tools/with_venv.sh', 'pip', 'install', '-r',
                 TEST_REQUIRES], redirect_output=False)

    # Tell the virtual env how to "import quantum"
    pthfile = os.path.join(venv, "lib", PY_VERSION, "site-packages",
                                 "quantum.pth")
    f = open(pthfile, 'w')
    f.write("%s\n" % ROOT)


def print_help():
    help = """
 Quantum development environment setup is complete.

 Quantum development uses virtualenv to track and manage Python dependencies
 while in development and testing.

 To activate the Quantum virtualenv for the extent of your current shell
 session you can run:

 $ source .venv/bin/activate

 Or, if you prefer, you can run commands in the virtualenv on a case by case
 basis by running:

 $ tools/with_venv.sh <your command>

 Also, make test will automatically use the virtualenv.
    """
    print help


def main(argv):
    check_dependencies()
    create_virtualenv()
    install_dependencies()
    print_help()

if __name__ == '__main__':
    main(sys.argv)

########NEW FILE########
__FILENAME__ = normalize_json
#! /usr/bin/env python

# Copyright (C) 2013 Nippon Telegraph and Telephone Corporation.
# Copyright (C) 2013 YAMAMOTO Takashi <yamamoto at valinux co jp>
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# usage example:
# for x in ../ryu/tests/unit/ofproto/json/**/*.json;do echo $x;./normalize_json.py < $x > xx&& mv xx $x;done

import json
import sys

j = sys.stdin.read()
d = json.loads(j)
print json.dumps(d, ensure_ascii=True, indent=3, sort_keys=True)

########NEW FILE########
__FILENAME__ = topology_graphviz
#! /usr/bin/env python

# Copyright (C) 2013 Nippon Telegraph and Telephone Corporation.
# Copyright (C) 2013 YAMAMOTO Takashi <yamamoto at valinux co jp>
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# usage example:
# curl http://localhost:8080/v1.0/topology/links|./topology_graphviz.py|neato -Tx11

import json
import sys

j = sys.stdin.read()
l = json.loads(j)

print 'digraph {'
print 'node [shape=box]'
for d in l:
    print '"%s" -> "%s";' % (d['src']['dpid'], d['dst']['dpid'])
print 'overlap=false'
print '}'

########NEW FILE########
__FILENAME__ = pyretic
#!/usr/bin/python

################################################################################
# The Pyretic Project                                                          #
# frenetic-lang.org/pyretic                                                    #
# author: Joshua Reich (jreich@cs.princeton.edu)                               #
################################################################################
# Licensed to the Pyretic Project by one or more contributors. See the         #
# NOTICES file distributed with this work for additional information           #
# regarding copyright and ownership. The Pyretic Project licenses this         #
# file to you under the following license.                                     #
#                                                                              #
# Redistribution and use in source and binary forms, with or without           #
# modification, are permitted provided the following conditions are met:       #
# - Redistributions of source code must retain the above copyright             #
#   notice, this list of conditions and the following disclaimer.              #
# - Redistributions in binary form must reproduce the above copyright          #
#   notice, this list of conditions and the following disclaimer in            #
#   the documentation or other materials provided with the distribution.       #
# - The names of the copyright holds and contributors may not be used to       #
#   endorse or promote products derived from this work without specific        #
#   prior written permission.                                                  #
#                                                                              #
# Unless required by applicable law or agreed to in writing, software          #
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT    #
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the     #
# LICENSE file distributed with this work for specific language governing      #
# permissions and limitations under the License.                               #
################################################################################

from pyretic.core.runtime import Runtime
from pyretic.backend.backend import Backend
import sys
import threading
import signal
import subprocess
from importlib import import_module
from optparse import OptionParser
import re
import os
import logging
from multiprocessing import Queue, Process
import pyretic.core.util as util

of_client = None

def signal_handler(signal, frame):
    print '\n----starting pyretic shutdown------'
    # for thread in threading.enumerate():
    #     print (thread,thread.isAlive())
    print "attempting to kill of_client"
    of_client.kill()
    # print "attempting get output of of_client:"
    # output = of_client.communicate()[0]
    # print output
    print "pyretic.py done"
    sys.exit(0)


def parseArgs():
    """Parse command-line args and return options object.
    returns: opts parse options dict"""
    desc = ( 'Pyretic runtime' )
    usage = ( '%prog [options]\n'
              '(type %prog -h for details)' )
    
    end_args = 0
    for arg in sys.argv[1:]:
        if not re.match('-',arg):
            end_args = sys.argv.index(arg)
    kwargs_to_pass = None
    if end_args > 0:
        kwargs_to_pass = sys.argv[end_args+1:]
        sys.argv = sys.argv[:end_args+1]

    op = OptionParser( description=desc, usage=usage )
    op.add_option( '--frontend-only', '-f', action="store_true", 
                     dest="frontend_only", help = 'only start the frontend'  )
    op.add_option( '--mode', '-m', type='choice',
                     choices=['interpreted','i','reactive0','r0','proactive0','p0','proactive1','p1'], 
                     help = '|'.join( ['interpreted/i','reactive0/r0','proactiveN/pN for N={0,1}'] )  )
    op.add_option( '--verbosity', '-v', type='choice',
                   choices=['low','normal','high','please-make-it-stop'],
                   default = 'low',
                   help = '|'.join( ['low','normal','high','please-make-it-stop'] )  )

    op.set_defaults(frontend_only=False,mode='reactive0')
    options, args = op.parse_args()

    return (op, options, args, kwargs_to_pass)


def main():
    global of_client
    (op, options, args, kwargs_to_pass) = parseArgs()
    if options.mode == 'i':
        options.mode = 'interpreted'
    elif options.mode == 'r0':
        options.mode = 'reactive0'
    elif options.mode == 'p0':
        options.mode = 'proactive0'
    elif options.mode == 'p1':
        options.mode = 'proactive1'
    try:
        module_name = args[0]
    except IndexError:
        print 'Module must be specified'
        print ''
        op.print_usage()
        sys.exit(1)
    try:
        module = import_module(module_name)
    except ImportError, e:
        print 'Must be a valid python module'
        print 'e.g, full module name,'
        print '     no .py suffix,'
        print '     located on the system PYTHONPATH'
        print ''
        print 'Exception message for ImportError was:'
        print e
        sys.exit(1)

    main = module.main
    kwargs = { k : v for [k,v] in [ i.lstrip('--').split('=') for i in kwargs_to_pass ]}

    sys.setrecursionlimit(1500) #INCREASE THIS IF "maximum recursion depth exceeded"

    # Set up multiprocess logging.
    verbosity_map = { 'low' : logging.WARNING,
                      'normal' : logging.INFO,
                      'high' : logging.DEBUG,
                      'please-make-it-stop' : logging.DEBUG }
    logging_queue = Queue()

    # Make a logging process.
    def log_writer(queue, log_level):
        formatter = logging.Formatter('%(levelname)s:%(name)s: %(message)s')
        handler = logging.StreamHandler()
        handler.setFormatter(formatter)
        handler.setLevel(log_level)
        logger = logging.getLogger()
        logger.addHandler(handler)
        logger.setLevel(log_level)
        while(True):
            try:
                to_log = queue.get()
            except KeyboardInterrupt, e:
                print "\nkilling log"
                import sys
                sys.exit(0)
            logger.handle(to_log)
    log_level = verbosity_map.get(options.verbosity, logging.DEBUG)
    log_process = Process(target=log_writer,args=(logging_queue, log_level,))
    log_process.daemon = True
    log_process.start()

    # Set default handler.
    logger = logging.getLogger()
    handler = util.QueueStreamHandler(logging_queue)
    logger.addHandler(handler)
    logger.setLevel(log_level)
    
    runtime = Runtime(Backend(),main,kwargs,options.mode,options.verbosity)
    if not options.frontend_only:
        try:
            output = subprocess.check_output('echo $PYTHONPATH',shell=True).strip()
        except:
            print 'Error: Unable to obtain PYTHONPATH'
            sys.exit(1)
        poxpath = None
        for p in output.split(':'):
             if re.match('.*pox/?$',p):
                 poxpath = os.path.abspath(p)
                 break
        if poxpath is None:
            print 'Error: pox not found in PYTHONPATH'
            sys.exit(1)
        pox_exec = os.path.join(poxpath,'pox.py')
        python=sys.executable
        # TODO(josh): pipe pox_client stdout to subprocess.PIPE or
        # other log file descriptor if necessary
        of_client = subprocess.Popen([python, 
                                      pox_exec,
                                      'of_client.pox_client' ],
                                     stdout=sys.stdout,
                                     stderr=subprocess.STDOUT)
    
    signal.signal(signal.SIGINT, signal_handler)
    signal.pause()

if __name__ == '__main__':
    main()

########NEW FILE########
