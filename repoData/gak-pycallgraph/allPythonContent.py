__FILENAME__ = conf
# -*- coding: utf-8 -*-
#
# Python Call Graph documentation build configuration file, created by
# sphinx-quickstart on Wed Jul 24 17:23:48 2013.
#
# This file is execfile()d with the current directory set to its containing dir.
#
# Note that not all possible configuration values are present in this
# autogenerated file.
#
# All configuration values have a default; values that are commented out
# serve to show the default.

import sys, os

# If extensions (or modules to document with autodoc) are in another directory,
# add these directories to sys.path here. If the directory is relative to the
# documentation root, use os.path.abspath to make it absolute, like shown here.
sys.path.insert(0, os.path.abspath('..'))
import pycallgraph

# -- General configuration -----------------------------------------------------

todo_include_todos = True

# If your documentation needs a minimal Sphinx version, state it here.
#needs_sphinx = '1.0'

# Add any Sphinx extension module names here, as strings. They can be extensions
# coming with Sphinx (named 'sphinx.ext.*') or your custom ones.
extensions = ['sphinx.ext.autodoc', 'sphinx.ext.todo', 'sphinx.ext.coverage', 'sphinx.ext.viewcode']

# Add any paths that contain templates here, relative to this directory.
templates_path = ['_templates']

# The suffix of source filenames.
source_suffix = '.rst'

# The encoding of source files.
#source_encoding = 'utf-8-sig'

# The master toctree document.
master_doc = 'index'

# General information about the project.
project = u'Python Call Graph'
copyright = u'2007-2013 Gerald Kaszuba, et al.'

# The version info for the project you're documenting, acts as replacement for
# |version| and |release|, also used in various other places throughout the
# built documents.
#
# The short X.Y version.
version = pycallgraph.__version__
# The full version, including alpha/beta/rc tags.
release = pycallgraph.__version__

# The language for content autogenerated by Sphinx. Refer to documentation
# for a list of supported languages.
#language = None

# There are two options for replacing |today|: either, you set today to some
# non-false value, then it is used:
#today = ''
# Else, today_fmt is used as the format for a strftime call.
#today_fmt = '%B %d, %Y'

# List of patterns, relative to source directory, that match files and
# directories to ignore when looking for source files.
exclude_patterns = ['_build']

# The reST default role (used for this markup: `text`) to use for all documents.
#default_role = None

# If true, '()' will be appended to :func: etc. cross-reference text.
#add_function_parentheses = True

# If true, the current module name will be prepended to all description
# unit titles (such as .. function::).
#add_module_names = True

# If true, sectionauthor and moduleauthor directives will be shown in the
# output. They are ignored by default.
#show_authors = False

# The name of the Pygments (syntax highlighting) style to use.
pygments_style = 'sphinx'

# A list of ignored prefixes for module index sorting.
#modindex_common_prefix = []

# If true, keep warnings as "system message" paragraphs in the built documents.
#keep_warnings = False


# -- Options for HTML output ---------------------------------------------------

# The theme to use for HTML and HTML Help pages.  See the documentation for
# a list of builtin themes.
html_theme = 'default'

# Theme options are theme-specific and customize the look and feel of a theme
# further.  For a list of options available for each theme, see the
# documentation.
#html_theme_options = {}

# Add any paths that contain custom themes here, relative to this directory.
#html_theme_path = []

# The name for this set of Sphinx documents.  If None, it defaults to
# "<project> v<release> documentation".
#html_title = None

# A shorter title for the navigation bar.  Default is the same as html_title.
#html_short_title = None

# The name of an image file (relative to this directory) to place at the top
# of the sidebar.
#html_logo = None

# The name of an image file (within the static path) to use as favicon of the
# docs.  This file should be a Windows icon file (.ico) being 16x16 or 32x32
# pixels large.
#html_favicon = None

# Add any paths that contain custom static files (such as style sheets) here,
# relative to this directory. They are copied after the builtin static files,
# so a file named "default.css" will overwrite the builtin "default.css".
html_static_path = ['_static']

# If not '', a 'Last updated on:' timestamp is inserted at every page bottom,
# using the given strftime format.
#html_last_updated_fmt = '%b %d, %Y'

# If true, SmartyPants will be used to convert quotes and dashes to
# typographically correct entities.
#html_use_smartypants = True

# Custom sidebar templates, maps document names to template names.
#html_sidebars = {}

# Additional templates that should be rendered to pages, maps page names to
# template names.
#html_additional_pages = {}

# If false, no module index is generated.
#html_domain_indices = True

# If false, no index is generated.
#html_use_index = True

# If true, the index is split into individual pages for each letter.
#html_split_index = False

# If true, links to the reST sources are added to the pages.
#html_show_sourcelink = True

# If true, "Created using Sphinx" is shown in the HTML footer. Default is True.
#html_show_sphinx = True

# If true, "(C) Copyright ..." is shown in the HTML footer. Default is True.
#html_show_copyright = True

# If true, an OpenSearch description file will be output, and all pages will
# contain a <link> tag referring to it.  The value of this option must be the
# base URL from which the finished HTML is served.
#html_use_opensearch = ''

# This is the file name suffix for HTML files (e.g. ".xhtml").
#html_file_suffix = None

# Output file base name for HTML help builder.
htmlhelp_basename = 'PythonCallGraphdoc'


# -- Options for LaTeX output --------------------------------------------------

latex_elements = {
# The paper size ('letterpaper' or 'a4paper').
#'papersize': 'letterpaper',

# The font size ('10pt', '11pt' or '12pt').
#'pointsize': '10pt',

# Additional stuff for the LaTeX preamble.
#'preamble': '',
}

# Grouping the document tree into LaTeX files. List of tuples
# (source start file, target name, title, author, documentclass [howto/manual]).
latex_documents = [
  ('index', 'PythonCallGraph.tex', u'Python Call Graph',
   u'Gerald Kaszuba', 'manual'),
]

# The name of an image file (relative to this directory) to place at the top of
# the title page.
#latex_logo = None

# For "manual" documents, if this is true, then toplevel headings are parts,
# not chapters.
#latex_use_parts = False

# If true, show page references after internal links.
#latex_show_pagerefs = False

# If true, show URL addresses after external links.
#latex_show_urls = False

# Documents to append as an appendix to all manuals.
#latex_appendices = []

# If false, no module index is generated.
#latex_domain_indices = True


# -- Options for manual page output --------------------------------------------

# One entry per manual page. List of tuples
# (source start file, name, description, authors, manual section).
man_pages = [
    ('guide/command_line_usage', 'pycallgraph', u'Python Call Graph',
    	['''pycallgraph was written by Gerald Kaszuba <pycallgraph@slowchop.com>.

This manual page was originally written by Jan Alonzo <jmalonzo@unpluggable.com>, for the Debian GNU/Linux system.
'''], 1)
]

# If true, show URL addresses after external links.
#man_show_urls = False


# -- Options for Texinfo output ------------------------------------------------

# Grouping the document tree into Texinfo files. List of tuples
# (source start file, target name, title, author,
#  dir menu entry, description, category)
texinfo_documents = [
  ('index', 'PythonCallGraph', u'Python Call Graph',
   u'Gerald Kaszuba', 'PythonCallGraph', 'One line description of project.',
   'Miscellaneous'),
]

# Documents to append as an appendix to all manuals.
#texinfo_appendices = []

# If false, no module index is generated.
#texinfo_domain_indices = True

# How to display URL addresses: 'footnote', 'no', or 'inline'.
#texinfo_show_urls = 'footnote'

# If true, do not generate a @detailmenu in the "Top" node's menu.
#texinfo_no_detailmenu = False

########NEW FILE########
__FILENAME__ = basic
../../examples/graphviz/basic.py
########NEW FILE########
__FILENAME__ = generate
#!/usr/bin/env python

import hashlib
import subprocess
import yaml


INDEX_TEMPLATE = '''
Examples
========

.. toctree::
   :maxdepth: 3

   {}
'''


IMAGE_TEMPLATE = '''
.. _{0[name]}_example:

{0[title]}
===================

{0[description]}

Source Code
-----------

.. literalinclude:: {0[script]}

Generated Image
---------------

Below is the generated image from the code above. If you're having issues with the image below, try the :download:`direct link to image <{0[name]}.png>`.

.. container:: example-image

    .. image:: {0[name]}.png
        :target: ../_downloads/{0[name]}.png

'''


index = []
new_yaml = []

for info in yaml.load(open('examples.yml')):
    new_info = info
    new_yaml.append(new_info)

    index.append(info['name'])

    # Generate the rst for this example
    open('{}.rst'.format(info['name']), 'w').write(
        IMAGE_TEMPLATE.format(info).strip()
    )


    print(info['run'])

    # If the hash of the example hasn't changed, don't run again
    filemd5 = hashlib.md5(open(info['script']).read()).hexdigest()
    if filemd5 != info.get('md5'):
        info['md5'] = filemd5

        subprocess.call(info['run'], shell=True)

        if 'execute_after' in info:
            print('Running {}'.format(info['execute_after']))
            subprocess.call(info['execute_after'], shell=True)


open('index.rst', 'w').write(INDEX_TEMPLATE.format('\n   '.join(index)))

out = yaml.dump(new_yaml, default_flow_style=False)
open('examples.yml', 'w').write(out)


########NEW FILE########
__FILENAME__ = regexp
#!/usr/bin/env python
'''
Runs a regular expression over the first few hundred words in a dictionary to
find if any words start and end with the same letter, and having two of the
same letters in a row.
'''
import argparse
import re

from pycallgraph import PyCallGraph
from pycallgraph import Config
from pycallgraph.output import GraphvizOutput


class RegExp(object):

    def main(self):
        parser = argparse.ArgumentParser()
        parser.add_argument('--grouped', action='store_true')
        conf = parser.parse_args()

        if conf.grouped:
            self.run('regexp_grouped.png', Config(groups=True))
        else:
            self.run('regexp_ungrouped.png', Config(groups=False))

    def run(self, output, config):
        graphviz = GraphvizOutput()
        graphviz.output_file = output
        self.expression = r'^([^s]).*(.)\2.*\1$'

        with PyCallGraph(config=config, output=graphviz):
            self.precompiled()
            self.onthefly()

    def words(self):
        a = 200
        for word in open('/usr/share/dict/words'):
            yield word.strip()
            a -= 1
            if not a:
                return


    def precompiled(self):
        reo = re.compile(self.expression)
        for word in self.words():
            reo.match(word)

    def onthefly(self):
        for word in self.words():
            re.match(self.expression, word)


if __name__ == '__main__':
    RegExp().main()

########NEW FILE########
__FILENAME__ = banana
import time


class Banana:

    def __init__(self):
        pass

    def eat(self):
        self.secret_function()
        self.chew()
        self.swallow()

    def secret_function(self):
        time.sleep(0.2)

    def chew(self):
        pass

    def swallow(self):
        pass

########NEW FILE########
__FILENAME__ = filter_exclude
#!/usr/bin/env python

from pycallgraph import PyCallGraph
from pycallgraph import Config
from pycallgraph import GlobbingFilter
from pycallgraph.output import GraphvizOutput

from banana import Banana


config = Config()
config.trace_filter = GlobbingFilter(exclude=[
    'pycallgraph.*',
    '*.secret_function',
])

graphviz = GraphvizOutput(output_file='filter_exclude.png')

with PyCallGraph(output=graphviz, config=config):
    banana = Banana()
    banana.eat()

########NEW FILE########
__FILENAME__ = filter_max_depth
#!/usr/bin/env python

from pycallgraph import PyCallGraph
from pycallgraph import Config
from pycallgraph.output import GraphvizOutput

from banana import Banana


config = Config(max_depth=1)
graphviz = GraphvizOutput(output_file='filter_max_depth.png')

with PyCallGraph(output=graphviz, config=config):
    banana = Banana()
    banana.eat()

########NEW FILE########
__FILENAME__ = filter_none
#!/usr/bin/env python

from pycallgraph import PyCallGraph
from pycallgraph.output import GraphvizOutput

from banana import Banana


graphviz = GraphvizOutput(output_file='filter_none.png')

with PyCallGraph(output=graphviz):
    banana = Banana()
    banana.eat()

########NEW FILE########
__FILENAME__ = generate
#!/usr/bin/env python

import hashlib
import subprocess
import yaml


items = yaml.load(open('examples.yml'))

print(items)

changed = False

for script, save_md5 in items.iteritems():
    new_md5 = hashlib.md5(open(script).read()).hexdigest()
    if new_md5 == save_md5:
        continue
    changed = True
    items[script] = new_md5
    subprocess.call('./{}'.format(script), shell=True)

if changed:
    open('examples.yml', 'w').write(yaml.dump(items))

########NEW FILE########
__FILENAME__ = update_readme
#!/usr/bin/env python
'''
This script copies the index.rst page from the Sphinx documentation, modifies
it slightly so refs point to the correct place.
'''
import re
import os
import sys
import shutil


class GithubReadmeMaker(object):

    def __init__(self):
        self.root = os.path.abspath(os.path.dirname(__file__))
        os.chdir(self.root)

    def run(self):
        self.copy()
        rst = open('../README.rst').read()
        rst = self.fix_links(rst)
        rst = self.fix_index(rst)
        open('../README.rst', 'w').write(rst)

    def copy(self):
        shutil.copy('index.rst', '../README.rst')

    def fix_links(self, rst):
        prefix = 'http://pycallgraph.slowchop.com/en/develop'
        rst = rst.replace(
            ':ref:`command-line interface <command_line_usage>`',
            '`command-line interface <{}/guide/command_line_usage.html>`_'
            .format(prefix)
        )
        rst = rst.replace(
            ':ref:`pycallgraph module <pycallgraph>`',
            '`pycallgraph module <{}/api/pycallgraph.html>`_'.format(prefix)
        )

        # Thumbnail URL
        rst = re.sub(
            r'image:: examples/(.*_thumb)',
            r'image:: {}/_images/\g<1>'.format(prefix),
            rst,
        )
        rst = re.sub(
            r'target: (examples/.*)',
            r'target: {}/\g<1>'.format(prefix),
            rst,
        )

        return rst

    def fix_index(self, rst):
        docidx_offset = rst.find('Documentation Index')
        rst = rst[:docidx_offset]

        rst += open('readme_extras.rst').read()

        return rst


if __name__ == '__main__':
    GithubReadmeMaker().run()

########NEW FILE########
__FILENAME__ = all
../graphviz/all.py
########NEW FILE########
__FILENAME__ = basic
#!/usr/bin/env python
'''
This example demonstrates a simple use of pycallgraph.
'''
from pycallgraph import PyCallGraph
from pycallgraph.output import GephiOutput


class Banana:

    def eat(self):
        pass


class Person:

    def __init__(self):
        self.no_bananas()

    def no_bananas(self):
        self.bananas = []

    def add_banana(self, banana):
        self.bananas.append(banana)

    def eat_bananas(self):
        [banana.eat() for banana in self.bananas]
        self.no_bananas()


def main():
    gephi = GephiOutput()
    gephi.output_file = 'basic.gdf'

    with PyCallGraph(output=gephi):
        person = Person()
        for a in xrange(10):
            person.add_banana(Banana())
        person.eat_bananas()


if __name__ == '__main__':
    main()

########NEW FILE########
__FILENAME__ = large
#!/usr/bin/env python
'''
This example is trying to make a large graph. You'll need some internet access
for this to work.
'''

from pycallgraph import PyCallGraph
from pycallgraph.output import GephiOutput


def main():
    gephi = GephiOutput()
    gephi.output_file = 'large.gdf'

    with PyCallGraph(output=gephi):
        from urllib2 import urlopen
        from xml.dom.minidom import parseString
        parseString(urlopen('http://w3.org/').read())


if __name__ == '__main__':
    main()

########NEW FILE########
__FILENAME__ = all
#!/usr/bin/env python
'''
Execute all pycallgraph examples in this directory.
'''
from glob import glob


examples = glob('*.py')
examples.remove('all.py')
for example in examples:
    print(example)
    execfile(example)

########NEW FILE########
__FILENAME__ = basic
#!/usr/bin/env python
'''
This example demonstrates a simple use of pycallgraph.
'''
from pycallgraph import PyCallGraph
from pycallgraph.output import GraphvizOutput


class Banana:

    def eat(self):
        pass


class Person:

    def __init__(self):
        self.no_bananas()

    def no_bananas(self):
        self.bananas = []

    def add_banana(self, banana):
        self.bananas.append(banana)

    def eat_bananas(self):
        [banana.eat() for banana in self.bananas]
        self.no_bananas()


def main():
    graphviz = GraphvizOutput()
    graphviz.output_file = 'basic.png'

    with PyCallGraph(output=graphviz):
        person = Person()
        for a in xrange(10):
            person.add_banana(Banana())
        person.eat_bananas()


if __name__ == '__main__':
    main()

########NEW FILE########
__FILENAME__ = colors
#!/usr/bin/env python
'''
This example demonstrates several different methods on colouring your graph.

See U{http://www.graphviz.org/doc/info/attrs.html#k:color} for details on
how to return colour formats to Graphviz.
'''
import random

from pycallgraph import PyCallGraph
from pycallgraph import Config
from pycallgraph import Color
from pycallgraph.output import GraphvizOutput


def rainbow(node):
    '''Colour using only changes in hue.

    It will go from 0 to 0.8 which is red, orange, yellow, green, cyan, blue,
    then purple.

    See http://en.wikipedia.org/wiki/Hue for more information on hue.
    '''
    return Color.hsv(node.time.fraction * 0.8, 0.4, 0.9)


def greyscale(node):
    '''Goes from dark grey to a light grey.'''
    return Color.hsv(0, 0, node.time.fraction / 2 + 0.4)


def orange_green(node):
    '''Make a higher total time have an orange colour and a higher number
    of calls have a green colour using RGB.
    '''
    return Color(
        0.2 + node.time.fraction * 0.8,
        0.2 + node.calls.fraction * 0.4 + node.time.fraction * 0.4,
        0.2,
    )


def rand(node):
    return Color.hsv(
        random.random(),
        node.calls.fraction * 0.5 + 0.5,
        node.calls.fraction * 0.5 + 0.5,
    )


def main():
    graphviz = GraphvizOutput()
    pycallgraph = PyCallGraph(
        output=graphviz,
        config=Config(include_stdlib=True)
    )

    pycallgraph.start()
    import HTMLParser  # noqa
    pycallgraph.stop()

    # Set the edge colour to black for all examples
    graphviz.edge_color_func = lambda e: Color(0, 0, 0)

    # Default node colouring
    graphviz.output_file = 'colours-default.png'
    graphviz.done()

    def run(func, output_file):
        graphviz.node_color_func = func
        graphviz.output_file = output_file
        graphviz.done()

    run(rainbow, 'colors-rainbow.png')
    run(greyscale, 'colors-greyscale.png')
    run(orange_green, 'colors-orange-green.png')
    run(rand, 'colors-random.png')


if __name__ == '__main__':
    main()

########NEW FILE########
__FILENAME__ = example_with_submodules
from submodule_one import SubmoduleOne
from submodule_two import SubmoduleTwo


def main():
    s1 = SubmoduleOne()
    s1.report()

    s2 = SubmoduleTwo()
    s2.report()

if __name__ == "__main__":
    main()

########NEW FILE########
__FILENAME__ = helpers
def helper(something):
    return something

########NEW FILE########
__FILENAME__ = submodule_one
class SubmoduleOne(object):
    def __init__(self):
        self.one = 1

    def report(self):
        return self.one

########NEW FILE########
__FILENAME__ = submodule_two
from helpers import helper


class SubmoduleTwo(object):
    def __init__(self):
        self.two = 2

    def report(self):
        return helper(self.two)

########NEW FILE########
__FILENAME__ = filter
#!/usr/bin/env python
'''
This example demonstrates the use of filtering.
'''
import time

from pycallgraph import PyCallGraph
from pycallgraph import Config
from pycallgraph import GlobbingFilter
from pycallgraph.output import GraphvizOutput


class Banana:

    def __init__(self):
        pass

    def eat(self):
        self.secret_function()
        self.chew()
        self.swallow()

    def secret_function(self):
        time.sleep(0.2)

    def chew(self):
        pass

    def swallow(self):
        pass


def run(name, trace_filter=None, config=None, comment=None):
    if not config:
        config = Config()

    if trace_filter:
        config.trace_filter = trace_filter

    graphviz = GraphvizOutput()
    graphviz.output_file = 'filter-{}.png'.format(name)
    if comment:
        graphviz.graph_attributes['graph']['label'] = comment

    with PyCallGraph(config=config, output=graphviz):
        banana = Banana()
        banana.eat()


def filter_none():
    run(
        'none',
        comment='Default filtering.'
    )


def filter_exclude():
    trace_filter = GlobbingFilter(exclude=[
        'pycallgraph.*',
        '*.secret_function',
    ])

    run(
        'exclude',
        trace_filter=trace_filter,
        comment='Should not include secret_function.',
    )


def filter_include():
    trace_filter = GlobbingFilter(include=[
        '*.secret_function',
        'Banana.eat',
    ])

    run(
        'include',
        trace_filter=trace_filter,
        comment='Should show secret_function.'
    )


def filter_depth():
    config = Config()
    config.max_depth = 1

    run(
        'max_depth',
        config=config,
        comment='Should only show a depth of one.'
    )


def filter_pycallgraph():
    trace_filter = GlobbingFilter(exclude=[])

    run(
        'pycallgraph',
        trace_filter=trace_filter,
        comment="Don't filter pycallgraph calls.",
    )


def main():
    filter_none()
    filter_exclude()
    filter_include()
    filter_depth()
    filter_pycallgraph()


if __name__ == '__main__':
    main()

########NEW FILE########
__FILENAME__ = grouper
#!/usr/bin/env python
'''
This example demonstrates the use of grouping.
'''
from pycallgraph import PyCallGraph
from pycallgraph import Config
from pycallgraph import GlobbingFilter
from pycallgraph import Grouper
from pycallgraph.output import GraphvizOutput
import example_with_submodules


def run(name, trace_grouper=None, config=None, comment=None):
    if not config:
        config = Config()

    config.trace_filter = GlobbingFilter()

    if trace_grouper is not None:
        config.trace_grouper = trace_grouper

    graphviz = GraphvizOutput()
    graphviz.output_file = 'grouper-{}.png'.format(name)
    if comment:
        graphviz.graph_attributes['graph']['label'] = comment

    with PyCallGraph(config=config, output=graphviz):
        example_with_submodules.main()


def group_none():
    run(
        'without',
        comment='Default grouping.'
    )


def group_some():
    trace_grouper = Grouper(groups=[
        'example_with_submodules.submodule_one.*',
        'example_with_submodules.submodule_two.*',
        'example_with_submodules.helpers.*',
    ])

    run(
        'with',
        trace_grouper=trace_grouper,
        comment='Should assign groups to the two submodules.',
    )


def group_methods():
    trace_grouper = Grouper(groups=[
        'example_with_submodules.*.report',
        ])

    run(
        'methods',
        trace_grouper=trace_grouper,
        comment='Should assign a group to the report methods.',
    )


def main():
    group_none()
    group_some()
    group_methods()


if __name__ == '__main__':
    main()

########NEW FILE########
__FILENAME__ = import
#!/usr/bin/env python
'''
This example shows the interals of certain Python modules when they are being
imported.
'''
from pycallgraph import PyCallGraph
from pycallgraph import Config
from pycallgraph.output import GraphvizOutput


def main():
    import_list = (
        'pickle',
        'htmllib',
        'urllib2',
    )
    graphviz = GraphvizOutput()
    config = Config(include_stdlib=True)

    for module in import_list:
        graphviz.output_file = 'import-{}.png'.format(module)
        with PyCallGraph(output=graphviz, config=config):
            __import__(module)


if __name__ == '__main__':
    main()

########NEW FILE########
__FILENAME__ = large
#!/usr/bin/env python
'''
This example is trying to make a large graph. You'll need some internet access
for this to work.
'''

from pycallgraph import PyCallGraph
from pycallgraph import Config
from pycallgraph.output import GraphvizOutput


def main():
    graphviz = GraphvizOutput()
    graphviz.output_file = 'large.png'
    config = Config(include_stdlib=True)

    with PyCallGraph(output=graphviz, config=config):
        from urllib2 import urlopen
        from xml.dom.minidom import parseString
        parseString(urlopen('http://w3.org/').read())


if __name__ == '__main__':
    main()

########NEW FILE########
__FILENAME__ = recursive
#!/usr/bin/env python
'''
This example demonstrates a simple recursive call.
'''
from pycallgraph import PyCallGraph
from pycallgraph.output import GraphvizOutput


def factorial(n):
    if n == 1:
        return 1
    return n * factorial(n - 1)


def main():
    graphviz = GraphvizOutput()
    graphviz.output_file = 'recursive.png'

    with PyCallGraph(output=graphviz):
        for a in xrange(1, 10):
            factorial(a)

if __name__ == '__main__':
    main()

########NEW FILE########
__FILENAME__ = regexp
#!/usr/bin/env python
'''
This example demonstrates the internal workings of a regular expression lookup.
'''
import re

from pycallgraph import PyCallGraph
from pycallgraph import Config
from pycallgraph.output import GraphvizOutput


def main():
    graphviz = GraphvizOutput()
    graphviz.output_file = 'regexp.png'
    config = Config(include_stdlib=True)

    with PyCallGraph(output=graphviz, config=config):
        reo = compile()
        match(reo)


def compile():
    return re.compile('^[abetors]*$')


def match(reo):
    [reo.match(a) for a in words()]


def words():
    return [
        'abbreviation',
        'abbreviations',
        'abettor',
        'abettors',
        'abilities',
        'ability',
        'abrasion',
        'abrasions',
        'abrasive',
        'abrasives',
    ]

if __name__ == '__main__':
    main()

########NEW FILE########
__FILENAME__ = color
import colorsys


class ColorException(Exception):
    pass


class Color(object):

    def __init__(self, r, g, b, a=1):
        self.r = r
        self.g = g
        self.b = b
        self.a = a
        self.validate_all()

    @classmethod
    def hsv(cls, h, s, v, a=1):
        r, g, b = colorsys.hsv_to_rgb(h, s, v)
        return cls(r, g, b, a)

    def __str__(self):
        return '<Color {}>'.format(self.rgba_web())

    def validate_all(self):
        self.validate('r')
        self.validate('g')
        self.validate('b')
        self.validate('a')

    def validate(self, attr):
        v = getattr(self, attr)
        if not 0 <= v <= 1:
            raise ColorException('{} out of range 0 to 1: {}'.format(attr, v))

    @property
    def r255(self):
        return int(self.r * 255)

    @property
    def g255(self):
        return int(self.g * 255)

    @property
    def b255(self):
        return int(self.b * 255)

    @property
    def a255(self):
        return int(self.a * 255)

    def rgb_web(self):
        '''Returns a string with the RGB components as a HTML hex string.'''
        return '#{0.r255:02x}{0.g255:02x}{0.b255:02x}'.format(self)

    def rgba_web(self):
        '''Returns a string with the RGBA components as a HTML hex string.'''
        return '{0}{1.a255:02x}'.format(self.rgb_web(), self)

    def rgb_csv(self):
        '''Returns a string with the RGB components as CSV.'''
        return '{0.r255},{0.g255},{0.b255}'.format(self)

########NEW FILE########
__FILENAME__ = config
import argparse
import sys

from .output import outputters
from .globbing_filter import GlobbingFilter
from .grouper import Grouper


class Config(object):
    '''Handles configuration settings for pycallgraph, tracer, and each output
    module.  It also handles command line arguments.
    '''

    def __init__(self, **kwargs):
        '''
        You can set defaults in the constructor, e.g. Config(verbose=True)
        '''
        self.output = None
        self.verbose = False
        self.debug = False
        self.groups = True
        self.threaded = False
        self.memory = False

        # Filtering
        self.include_stdlib = False
        self.include_pycallgraph = False
        self.max_depth = 99999

        self.trace_filter = GlobbingFilter(
            exclude=['pycallgraph.*'],
            include=['*'],
        )

        # Grouping
        self.trace_grouper = Grouper()

        self.did_init = True

        # Update the defaults with anything from kwargs
        [setattr(self, k, v) for k, v in kwargs.iteritems()]

        self.create_parser()

    def log_verbose(self, text):
        if self.verbose:
            print(text)

    def log_debug(self, text):
        if self.debug:
            print(text)

    def add_module_arguments(self, usage):
        subparsers = self.parser.add_subparsers(
            help='OUTPUT_TYPE', dest='output')
        parent_parser = self.create_parent_parser()

        for name, cls in outputters.items():
            cls.add_arguments(subparsers, parent_parser, usage)

    def get_output(self):
        if not self.output:
            return
        output = outputters[self.output]()
        output.set_config(self)
        return output

    def parse_args(self, args=None):
        self.parser.parse_args(args, namespace=self)
        self.convert_filter_args()

    def strip_argv(self):
        sys.argv = [self.command] + self.command_args

    def convert_filter_args(self):
        if not self.include:
            self.include = ['*']

        if not self.include_pycallgraph:
            self.exclude.append('pycallgraph.*')

        self.trace_filter = GlobbingFilter(
            include=self.include,
            exclude=self.exclude,
        )

    def create_parser(self):
        '''Used by the pycallgraph command line interface to parse
        arguments.
        '''
        usage = 'pycallgraph [options] OUTPUT_TYPE [output_options] -- ' \
            'SCRIPT.py [ARG ...]'

        self.parser = argparse.ArgumentParser(
            description='Python Call Graph profiles a Python script and '
            'generates a call graph visualization.', usage=usage,
        )

        self.add_ungrouped_arguments()
        self.add_filter_arguments()
        self.add_module_arguments(usage)

    def create_parent_parser(self):
        '''Mixing subparsers with positional arguments can be done with a
        parents option. Found via: http://stackoverflow.com/a/11109863/11125
        '''
        parent_parser = argparse.ArgumentParser(add_help=False)
        parent_parser.add_argument(
            'command', metavar='SCRIPT',
            help='The Python script file to profile',
        )
        parent_parser.add_argument(
            'command_args', metavar='ARG', nargs='*',
            help='Python script arguments.'
        )
        return parent_parser

    def add_ungrouped_arguments(self):
        self.parser.add_argument(
            '-v', '--verbose', action='store_true', default=self.verbose,
            help='Display informative messages while running')

        self.parser.add_argument(
            '-d', '--debug', action='store_true', default=self.debug,
            help='Display debugging messages while running')

        self.parser.add_argument(
            '-t', '--threaded', action='store_true', default=self.threaded,
            help='Process traces asyncronously (Experimental)')

        self.parser.add_argument(
            '-ng', '--no-groups', dest='groups', action='store_false',
            default=self.groups, help='Do not group functions by module')

        self.parser.add_argument(
            '-s', '--stdlib', dest='include_stdlib', action='store_true',
            default=self.include_stdlib,
            help='Include standard library functions in the trace')

        self.parser.add_argument(
            '-m', '--memory', action='store_true', default=self.memory,
            help='(Experimental) Track memory usage')

    def add_filter_arguments(self):
        group = self.parser.add_argument_group('filtering')
        group.add_argument(
            '-i', '--include', default=[], action='append',
            help='Wildcard pattern of modules to include in the output. '
            'You can have multiple include arguments.'
        )

        group.add_argument(
            '-e', '--exclude', default=[], action='append',
            help='Wildcard pattern of modules to exclude in the output. '
            'You can have multiple exclude arguments.'
        )

        group.add_argument(
            '--include-pycallgraph', default=self.include_pycallgraph,
            action='store_true',
            help='Do not automatically filter out pycallgraph',
        )

        group.add_argument(
            '--max-depth', default=self.max_depth, type=int,
            help='Maximum stack depth to trace',
        )

########NEW FILE########
__FILENAME__ = exceptions
class PyCallGraphException(Exception):
    pass

########NEW FILE########
__FILENAME__ = globbing_filter
from fnmatch import fnmatch


class GlobbingFilter(object):
    '''Filter module names using a set of globs.

    Objects are matched against the exclude list first, then the include list.
    Anything that passes through without matching either, is excluded.
    '''

    def __init__(self, include=None, exclude=None):
        if include is None and exclude is None:
            include = ['*']
            exclude = []
        elif include is None:
            include = ['*']
        elif exclude is None:
            exclude = []

        self.include = include
        self.exclude = exclude

    def __call__(self, full_name=None):
        for pattern in self.exclude:
            if fnmatch(full_name, pattern):
                return False

        for pattern in self.include:
            if fnmatch(full_name, pattern):
                return True

        return False

########NEW FILE########
__FILENAME__ = grouper
from fnmatch import fnmatch


class Grouper(object):
    '''Group module names.

    By default, objects are grouped by their top-level module name. Additional
    groups can be specified with the groups list and all objects will be
    matched against it.
    '''

    def __init__(self, groups=None):
        if groups is None:
            groups = []

        self.groups = groups

    def __call__(self, full_name=None):
        for pattern in self.groups:
            if fnmatch(full_name, pattern):
                if pattern[-2:] == ".*":
                    # a wilcard in the middle is probably meaningful, while at
                    # the end, it's only noise and can be removed
                    return pattern[:-2]
                return pattern
        return full_name.split('.', 1)[0]

########NEW FILE########
__FILENAME__ = memory_profiler
"""Profile the memory usage of a Python program"""

__version__ = '0.25'

_CMD_USAGE = "python -m memory_profiler script_file.py"

import time, sys, os, pdb
import warnings
import linecache
import inspect
import subprocess

# TODO: provide alternative when multprocessing is not available
try:
    from multiprocessing import Process, Pipe
except ImportError:
    from multiprocessing.dummy import Process, Pipe


try:
    import psutil

    def _get_memory(pid):
        process = psutil.Process(pid)
        try:
            mem = float(process.get_memory_info()[0]) / (1024 ** 2)
        except psutil.AccessDenied:
            mem = -1
        return mem


except ImportError:

    warnings.warn("psutil module not found. memory_profiler will be slow")

    if os.name == 'posix':
        def _get_memory(pid):
            # ..
            # .. memory usage in MB ..
            # .. this should work on both Mac and Linux ..
            # .. subprocess.check_output appeared in 2.7, using Popen ..
            # .. for backwards compatibility ..
            out = subprocess.Popen(['ps', 'v', '-p', str(pid)],
                  stdout=subprocess.PIPE).communicate()[0].split(b'\n')
            try:
                vsz_index = out[0].split().index(b'RSS')
                return float(out[1].split()[vsz_index]) / 1024
            except:
                return -1
    else:
        raise NotImplementedError('The psutil module is required for non-unix '
                                  'platforms')


class Timer(Process):
    """
    Fetch memory consumption from over a time interval
    """

    def __init__(self, monitor_pid, interval, pipe, *args, **kw):
        self.monitor_pid = monitor_pid
        self.interval = interval
        self.pipe = pipe
        self.cont = True
        super(Timer, self).__init__(*args, **kw)

    def run(self):
        m = _get_memory(self.monitor_pid)
        timings = [m]
        self.pipe.send(0)  # we're ready
        while not self.pipe.poll(self.interval):
            m = _get_memory(self.monitor_pid)
            timings.append(m)
        self.pipe.send(timings)


def memory_usage(proc=-1, interval=0.0, timeout=None):

    """
    Return the memory usage of a process or piece of code

    Parameters
    ----------
    proc : {int, string, tuple, subprocess.Popen}, optional
        The process to monitor. Can be given by an integer/string
        representing a PID, by a Popen object or by a tuple
        representing a Python function. The tuple contains three
        values (f, args, kw) and specifies to run the function
        f(*args, **kw).
        Set to -1 (default) for current process.

    interval : float, optional
        Interval at which measurements are collected.

    timeout : float, optional
        Maximum amount of time (in seconds) to wait before returning.

    Returns
    -------
    mem_usage : list of floating-poing values
        memory usage, in MB. It's length is always < timeout / interval
    """
    ret = []

    if timeout is not None:
        max_iter = int(timeout / interval)
    elif isinstance(proc, int):
        # external process and no timeout
        max_iter = 1
    else:
        # for a Python function wait until it finishes
        max_iter = float('inf')

    if hasattr(proc, '__call__'):
        proc = (proc, (), {})
    if isinstance(proc, (list, tuple)):
        if len(proc) == 1:
            f, args, kw = (proc[0], (), {})
        elif len(proc) == 2:
            f, args, kw = (proc[0], proc[1], {})
        elif len(proc) == 3:
            f, args, kw = (proc[0], proc[1], proc[2])
        else:
            raise ValueError

        aspec = inspect.getargspec(f)
        n_args = len(aspec.args)
        if aspec.defaults is not None:
            n_args -= len(aspec.defaults)
        if n_args != len(args):
            raise ValueError(
            'Function expects %s value(s) but %s where given'
            % (n_args, len(args)))

        child_conn, parent_conn = Pipe()  # this will store Timer's results
        p = Timer(os.getpid(), interval, child_conn)
        p.start()
        parent_conn.recv()  # wait until we start getting memory
        f(*args, **kw)
        parent_conn.send(0)  # finish timing
        ret = parent_conn.recv()
        p.join(5 * interval)
    elif isinstance(proc, subprocess.Popen):
        # external process, launched from Python
        while True:
            ret.append(_get_memory(proc.pid))
            time.sleep(interval)
            if timeout is not None:
                max_iter -= 1
                if max_iter == 0:
                    break
            if proc.poll() is not None:
                break
    else:
        # external process
        if proc == -1:
            proc = os.getpid()
        if max_iter == -1:
            max_iter = 1
        counter = 0
        while counter < max_iter:
            counter += 1
            ret.append(_get_memory(proc))
            time.sleep(interval)
    return ret

# ..
# .. utility functions for line-by-line ..

def _find_script(script_name):
    """ Find the script.

    If the input is not a file, then $PATH will be searched.
    """
    if os.path.isfile(script_name):
        return script_name
    path = os.getenv('PATH', os.defpath).split(os.pathsep)
    for folder in path:
        if folder == '':
            continue
        fn = os.path.join(folder, script_name)
        if os.path.isfile(fn):
            return fn

    sys.stderr.write('Could not find script {0}\n'.format(script_name))
    raise SystemExit(1)


class LineProfiler:
    """ A profiler that records the amount of memory for each line """

    def __init__(self, **kw):
        self.functions = list()
        self.code_map = {}
        self.enable_count = 0
        self.max_mem = kw.get('max_mem', None)

    def __call__(self, func):
        self.add_function(func)
        f = self.wrap_function(func)
        f.__module__ = func.__module__
        f.__name__ = func.__name__
        f.__doc__ = func.__doc__
        f.__dict__.update(getattr(func, '__dict__', {}))
        return f

    def add_function(self, func):
        """ Record line profiling information for the given Python function.
        """
        try:
            # func_code does not exist in Python3
            code = func.__code__
        except AttributeError:
            import warnings
            warnings.warn("Could not extract a code object for the object %r"
                          % (func,))
            return
        if code not in self.code_map:
            self.code_map[code] = {}
            self.functions.append(func)

    def wrap_function(self, func):
        """ Wrap a function to profile it.
        """

        def f(*args, **kwds):
            self.enable_by_count()
            try:
                result = func(*args, **kwds)
            finally:
                self.disable_by_count()
            return result
        return f

    def run(self, cmd):
        """ Profile a single executable statment in the main namespace.
        """
        import __main__
        main_dict = __main__.__dict__
        return self.runctx(cmd, main_dict, main_dict)

    def runctx(self, cmd, globals, locals):
        """ Profile a single executable statement in the given namespaces.
        """
        self.enable_by_count()
        try:
            exec(cmd, globals, locals)
        finally:
            self.disable_by_count()
        return self

    def runcall(self, func, *args, **kw):
        """ Profile a single function call.
        """
        # XXX where is this used ? can be removed ?
        self.enable_by_count()
        try:
            return func(*args, **kw)
        finally:
            self.disable_by_count()

    def enable_by_count(self):
        """ Enable the profiler if it hasn't been enabled before.
        """
        if self.enable_count == 0:
            self.enable()
        self.enable_count += 1

    def disable_by_count(self):
        """ Disable the profiler if the number of disable requests matches the
        number of enable requests.
        """
        if self.enable_count > 0:
            self.enable_count -= 1
            if self.enable_count == 0:
                self.disable()

    def trace_memory_usage(self, frame, event, arg):
        """Callback for sys.settrace"""
        if event in ('line', 'return') and frame.f_code in self.code_map:
            lineno = frame.f_lineno
            if event == 'return':
                lineno += 1
            entry = self.code_map[frame.f_code].setdefault(lineno, [])
            entry.append(_get_memory(os.getpid()))

        return self.trace_memory_usage

    def trace_max_mem(self, frame, event, arg):
        # run into PDB as soon as memory is higher than MAX_MEM
        if event in ('line', 'return') and frame.f_code in self.code_map:
            c = _get_memory(os.getpid())
            if c >= self.max_mem:
                t = 'Current memory {0:.2f} MB exceeded the maximum '.format(c) + \
                    'of {0:.2f} MB\n'.format(self.max_mem)
                sys.stdout.write(t)
                sys.stdout.write('Stepping into the debugger \n')
                frame.f_lineno -= 2
                p = pdb.Pdb()
                p.quitting = False
                p.stopframe = frame
                p.returnframe = None
                p.stoplineno = frame.f_lineno - 3
                p.botframe = None
                return p.trace_dispatch

        return self.trace_max_mem

    def __enter__(self):
        self.enable_by_count()

    def __exit__(self, exc_type, exc_val, exc_tb):
        self.disable_by_count()

    def enable(self):
        if self.max_mem is not None:
            sys.settrace(self.trace_max_mem)
        else:
            sys.settrace(self.trace_memory_usage)

    def disable(self):
        self.last_time = {}
        sys.settrace(None)


def show_results(prof, stream=None, precision=3):
    if stream is None:
        stream = sys.stdout
    template = '{0:>6} {1:>12} {2:>12}   {3:<}'

    for code in prof.code_map:
        lines = prof.code_map[code]
        if not lines:
            # .. measurements are empty ..
            continue
        filename = code.co_filename
        if filename.endswith((".pyc", ".pyo")):
            filename = filename[:-1]
        stream.write('Filename: ' + filename + '\n\n')
        if not os.path.exists(filename):
            stream.write('ERROR: Could not find file ' + filename + '\n')
            if filename.startswith("ipython-input") or filename.startswith("<ipython-input"):
                print("NOTE: %mprun can only be used on functions defined in "
                      "physical files, and not in the IPython environment.")
            continue
        all_lines = linecache.getlines(filename)
        sub_lines = inspect.getblock(all_lines[code.co_firstlineno - 1:])
        linenos = range(code.co_firstlineno, code.co_firstlineno +
                        len(sub_lines))
        lines_normalized = {}

        header = template.format('Line #', 'Mem usage', 'Increment',
                                 'Line Contents')
        stream.write(header + '\n')
        stream.write('=' * len(header) + '\n')
        # move everything one frame up
        keys = sorted(lines.keys())

        k_old = keys[0] - 1
        lines_normalized[keys[0] - 1] = lines[keys[0]]
        for i in range(1, len(lines_normalized[keys[0] - 1])):
            lines_normalized[keys[0] - 1][i] = -1.
        k = keys.pop(0)
        while keys:
            lines_normalized[k] = lines[keys[0]]
            for i in range(len(lines_normalized[k_old]),
                           len(lines_normalized[k])):
                lines_normalized[k][i] = -1.
            k_old = k
            k = keys.pop(0)

        first_line = sorted(lines_normalized.keys())[0]
        mem_old = max(lines_normalized[first_line])
        precision = int(precision)
        template_mem = '{{0:{0}.{1}'.format(precision + 6, precision) + 'f} MB'
        for i, l in enumerate(linenos):
            mem = ''
            inc = ''
            if l in lines_normalized:
                mem = max(lines_normalized[l])
                inc = mem - mem_old
                mem_old = mem
                mem = template_mem.format(mem)
                inc = template_mem.format(inc)
            stream.write(template.format(l, mem, inc, sub_lines[i]))
        stream.write('\n\n')


# A lprun-style %mprun magic for IPython.
def magic_mprun(self, parameter_s=''):
    """ Execute a statement under the line-by-line memory profiler from the
    memory_profilser module.

    Usage:
      %mprun -f func1 -f func2 <statement>

    The given statement (which doesn't require quote marks) is run via the
    LineProfiler. Profiling is enabled for the functions specified by the -f
    options. The statistics will be shown side-by-side with the code through
    the pager once the statement has completed.

    Options:

    -f <function>: LineProfiler only profiles functions and methods it is told
    to profile.  This option tells the profiler about these functions. Multiple
    -f options may be used. The argument may be any expression that gives
    a Python function or method object. However, one must be careful to avoid
    spaces that may confuse the option parser. Additionally, functions defined
    in the interpreter at the In[] prompt or via %run currently cannot be
    displayed.  Write these functions out to a separate file and import them.

    One or more -f options are required to get any useful results.

    -T <filename>: dump the text-formatted statistics with the code
    side-by-side out to a text file.

    -r: return the LineProfiler object after it has completed profiling.
    """
    try:
        from StringIO import StringIO
    except ImportError: # Python 3.x
        from io import StringIO

    # Local imports to avoid hard dependency.
    from distutils.version import LooseVersion
    import IPython
    ipython_version = LooseVersion(IPython.__version__)
    if ipython_version < '0.11':
        from IPython.genutils import page
        from IPython.ipstruct import Struct
        from IPython.ipapi import UsageError
    else:
        from IPython.core.page import page
        from IPython.utils.ipstruct import Struct
        from IPython.core.error import UsageError

    # Escape quote markers.
    opts_def = Struct(T=[''], f=[])
    parameter_s = parameter_s.replace('"', r'\"').replace("'", r"\'")
    opts, arg_str = self.parse_options(parameter_s, 'rf:T:', list_all=True)
    opts.merge(opts_def)
    global_ns = self.shell.user_global_ns
    local_ns = self.shell.user_ns

    # Get the requested functions.
    funcs = []
    for name in opts.f:
        try:
            funcs.append(eval(name, global_ns, local_ns))
        except Exception as e:
            raise UsageError('Could not find function %r.\n%s: %s' % (name,
                e.__class__.__name__, e))

    profile = LineProfiler()
    for func in funcs:
        profile(func)

    # Add the profiler to the builtins for @profile.
    try:
        import builtins
    except ImportError:  # Python 3x
        import __builtin__ as builtins

    if 'profile' in builtins.__dict__:
        had_profile = True
        old_profile = builtins.__dict__['profile']
    else:
        had_profile = False
        old_profile = None
    builtins.__dict__['profile'] = profile

    try:
        try:
            profile.runctx(arg_str, global_ns, local_ns)
            message = ''
        except SystemExit:
            message = "*** SystemExit exception caught in code being profiled."
        except KeyboardInterrupt:
            message = ("*** KeyboardInterrupt exception caught in code being "
                "profiled.")
    finally:
        if had_profile:
            builtins.__dict__['profile'] = old_profile

    # Trap text output.
    stdout_trap = StringIO()
    show_results(profile, stdout_trap)
    output = stdout_trap.getvalue()
    output = output.rstrip()

    if ipython_version < '0.11':
        page(output, screen_lines=self.shell.rc.screen_length)
    else:
        page(output)
    print(message,)

    text_file = opts.T[0]
    if text_file:
        with open(text_file, 'w') as pfile:
            pfile.write(output)
        print('\n*** Profile printout saved to text file %s. %s' % (text_file,
                                                                    message))

    return_value = None
    if 'r' in opts:
        return_value = profile

    return return_value


def _func_exec(stmt, ns):
    # helper for magic_memit, just a function proxy for the exec
    # statement
    exec(stmt, ns)

# a timeit-style %memit magic for IPython
def magic_memit(self, line=''):
    """Measure memory usage of a Python statement

    Usage, in line mode:
      %memit [-r<R>t<T>] statement

    Options:
    -r<R>: repeat the loop iteration <R> times and take the best result.
    Default: 1

    -t<T>: timeout after <T> seconds. Unused if `-i` is active. Default: None

    Examples
    --------
    ::

      In [1]: import numpy as np

      In [2]: %memit np.zeros(1e7)
      maximum of 1: 76.402344 MB per loop

      In [3]: %memit np.ones(1e6)
      maximum of 1: 7.820312 MB per loop

      In [4]: %memit -r 10 np.empty(1e8)
      maximum of 10: 0.101562 MB per loop

      In [5]: memit -t 3 while True: pass;
      Subprocess timed out.
      Subprocess timed out.
      Subprocess timed out.
      ERROR: all subprocesses exited unsuccessfully. Try again with the `-i`
      option.
      maximum of 1: -inf MB per loop

    """
    opts, stmt = self.parse_options(line, 'r:t:i', posix=False, strict=False)
    repeat = int(getattr(opts, 'r', 1))
    if repeat < 1:
        repeat == 1
    timeout = int(getattr(opts, 't', 0))
    if timeout <= 0:
        timeout = None

    mem_usage = []
    for _ in range(repeat):
        tmp = memory_usage((_func_exec, (stmt, self.shell.user_ns)), timeout=timeout)
        mem_usage.extend(tmp)

    if mem_usage:
        print('maximum of %d: %f MB per loop' % (repeat, max(mem_usage)))
    else:
        print('ERROR: could not read memory usage, try with a lower interval or more iterations')


def load_ipython_extension(ip):
    """This is called to load the module as an IPython extension."""
    ip.define_magic('mprun', magic_mprun)
    ip.define_magic('memit', magic_memit)


def profile(func, stream=None):
    """
    Decorator that will run the function and print a line-by-line profile
    """
    def wrapper(*args, **kwargs):
        prof = LineProfiler()
        val = prof(func)(*args, **kwargs)
        show_results(prof, stream=stream)
        return val
    return wrapper


if __name__ == '__main__':
    from optparse import OptionParser
    parser = OptionParser(usage=_CMD_USAGE, version=__version__)
    parser.disable_interspersed_args()
    parser.add_option("--pdb-mmem", dest="max_mem", metavar="MAXMEM",
        type="float", action="store",
        help="step into the debugger when memory exceeds MAXMEM")
    parser.add_option('--precision', dest="precision", type="int",
        action="store", default=3,
        help="precision of memory output in number of significant digits")

    if not sys.argv[1:]:
        parser.print_help()
        sys.exit(2)

    (options, args) = parser.parse_args()

    prof = LineProfiler(max_mem=options.max_mem)
    __file__ = _find_script(args[0])
    try:
        if sys.version_info[0] < 3:
            import __builtin__
            __builtin__.__dict__['profile'] = prof
            ns = locals()
            ns['profile'] = prof # shadow the profile decorator defined above
            execfile(__file__, ns, ns)
        else:
            import builtins
            builtins.__dict__['profile'] = prof
            ns = locals()
            ns['profile'] = prof # shadow the profile decorator defined above
            exec(compile(open(__file__).read(), __file__, 'exec'), ns,
                                                                   globals())
    finally:
        show_results(prof, precision=options.precision)

########NEW FILE########
__FILENAME__ = metadata
# A different file to pycallgraph.py because of circular import problem

__version__ = '1.0.1'
__copyright__ = 'Copyright Gerald Kaszuba 2007-2013'
__license__ = 'GPLv2'
__author__ = 'Gerald Kaszuba'
__email__ = 'pycallgraph@gakman.com'
__url__ = 'http://pycallgraph.slowchop.com/'
__credits__ = [
    'Gerald Kaszuba',
]

########NEW FILE########
__FILENAME__ = gephi
import math

from .output import Output


class GephiOutput(Output):
    def __init__(self, **kwargs):
        self.fp = None
        self.output_file = 'pycallgraph.gdf'
        Output.__init__(self, **kwargs)

    @classmethod
    def add_arguments(cls, subparsers, parent_parser, usage):
        defaults = cls()

        subparser = subparsers.add_parser(
            'gephi', help='Gephi GDF generation',
            parents=[parent_parser], usage=usage,
        )

        cls.add_output_file(
            subparser, defaults, 'The generated Gephi GDF file'
        )

    def generate(self):
        '''Returns a string with the contents of a GDF file.'''

        return u'\n'.join([
            self.generate_nodes(),
            self.generate_edges(),
        ]) + '\n'

    def generate_nodes(self):
        output = []

        fields = u', '.join([
            u'name VARCHAR',
            u'label VARCHAR',
            u'group VARCHAR',
            u'calls INTEGER',
            u'time DOUBLE',
            u'memory_in INTEGER',
            u'memory_out INTEGER',
            u'color VARCHAR',
            u'width DOUBLE',
        ])
        output.append(u'nodedef> {}'.format(fields))

        for node in self.processor.nodes():
            fields = u','.join([str(a) for a in [
                node.name,
                node.name,
                node.group,
                node.calls.value,
                node.time.value,
                node.memory_in.value,
                node.memory_out.value,
                u"'{}'".format(self.node_color_func(node).rgb_csv()),
                self.node_size(node),
            ]])
            output.append(fields)

        return '\n'.join(output)

    def node_size(self, node):
        return math.log(node.time.fraction * (math.e - 1) + 1) * 2 + 1

    def generate_edges(self):
        output = []

        fields = u', '.join([
            u'node1 VARCHAR',
            u'node2 VARCHAR',
            u'label VARCHAR',
            u'labelvisible VARCHAR',
            u'directed BOOLEAN',
            u'color VARCHAR',
            u'width DOUBLE',
        ])
        output.append(u'edgedef> {}'.format(fields))

        for edge in self.processor.edges():
            fields = u','.join([str(a) for a in [
                edge.src_func,
                edge.dst_func,
                self.edge_label(edge),
                'true',
                'true',
                u"'{}'".format(self.edge_color_func(edge).rgb_csv()),
                edge.calls.fraction * 2,
            ]])
            output.append(fields)

        return '\n'.join(output)

    def done(self):
        source = self.generate()
        f = open(self.output_file, 'w')
        f.write(source)
        f.close()

########NEW FILE########
__FILENAME__ = graphviz
from __future__ import division

import tempfile
import os
import textwrap

from ..metadata import __version__
from ..exceptions import PyCallGraphException
from ..color import Color
from .output import Output


class GraphvizOutput(Output):

    def __init__(self, **kwargs):
        self.tool = 'dot'
        self.output_file = 'pycallgraph.png'
        self.output_type = 'png'
        self.font_name = 'Verdana'
        self.font_size = 7
        self.group_font_size = 10
        self.group_border_color = Color(0, 0, 0, 0.8)

        Output.__init__(self, **kwargs)

        self.prepare_graph_attributes()

    @classmethod
    def add_arguments(cls, subparsers, parent_parser, usage):
        defaults = cls()

        subparser = subparsers.add_parser(
            'graphviz', help='Graphviz generation',
            parents=[parent_parser], usage=usage,
        )

        subparser.add_argument(
            '-l', '--tool', dest='tool', default=defaults.tool,
            help='The tool from Graphviz to use, e.g. dot, neato, etc.',
        )

        cls.add_output_file(
            subparser, defaults, 'The generated Graphviz file'
        )

        subparser.add_argument(
            '-f', '--output-format', type=str, default=defaults.output_type,
            help='Image format to produce, e.g. png, ps, dot, etc. '
            'See http://www.graphviz.org/doc/info/output.html for more.',
        )

        subparser.add_argument(
            '--font-name', type=str, default=defaults.font_name,
            help='Name of the font to be used',
        )

        subparser.add_argument(
            '--font-size', type=int, default=defaults.font_size,
            help='Size of the font to be used',
        )

    def sanity_check(self):
        self.ensure_binary(self.tool)

    def prepare_graph_attributes(self):
        generated_message = '\\n'.join([
            r'Generated by Python Call Graph v%s' % __version__,
            r'http://pycallgraph.slowchop.com',
        ])

        self.graph_attributes = {
            'graph': {
                'overlap': 'scalexy',
                'fontname': self.font_name,
                'fontsize': self.font_size,
                'fontcolor': Color(0, 0, 0, 0.5).rgba_web(),
                'label': generated_message,
            },
            'node': {
                'fontname': self.font_name,
                'fontsize': self.font_size,
                'fontcolor': Color(0, 0, 0).rgba_web(),
                'style': 'filled',
                'shape': 'rect',
            },
            'edge': {
                'fontname': self.font_name,
                'fontsize': self.font_size,
                'fontcolor': Color(0, 0, 0).rgba_web(),
            }
        }

    def done(self):
        source = self.generate()

        self.debug(source)

        fd, temp_name = tempfile.mkstemp()
        with os.fdopen(fd, 'w') as f:
            f.write(source)

        cmd = '{} -T{} -o{} {}'.format(
            self.tool, self.output_type, self.output_file, temp_name
        )

        self.verbose('Executing: {}'.format(cmd))
        try:
            ret = os.system(cmd)
            if ret:
                raise PyCallGraphException(
                    'The command "%(cmd)s" failed with error '
                    'code %(ret)i.' % locals())
        finally:
            os.unlink(temp_name)

        self.verbose('Generated {} with {} nodes.'.format(
            self.output_file, len(self.processor.func_count),
        ))

    def generate(self):
        '''Returns a string with the contents of a DOT file for Graphviz to
        parse.
        '''
        indent_join = '\n' + ' ' * 12

        return textwrap.dedent('''\
        digraph G {{

            // Attributes
            {}

            // Groups
            {}

            // Nodes
            {}

            // Edges
            {}

        }}
        '''.format(
            indent_join.join(self.generate_attributes()),
            indent_join.join(self.generate_groups()),
            indent_join.join(self.generate_nodes()),
            indent_join.join(self.generate_edges()),
        ))

    def attrs_from_dict(self, d):
        output = []
        for attr, val in d.iteritems():
            output.append('%s = "%s"' % (attr, val))
        return ', '.join(output)

    def node(self, key, attr):
        return '"{}" [{}];'.format(
            key, self.attrs_from_dict(attr),
        )

    def edge(self, edge, attr):
        return '"{0.src_func}" -> "{0.dst_func}" [{1}];'.format(
            edge, self.attrs_from_dict(attr),
        )

    def generate_attributes(self):
        output = []
        for section, attrs in self.graph_attributes.iteritems():
            output.append('{} [ {} ];'.format(
                section, self.attrs_from_dict(attrs),
            ))
        return output

    def generate_groups(self):
        if not self.processor.config.groups:
            return ''

        output = []
        for group, nodes in self.processor.groups():
            funcs = [node.name for node in nodes]
            funcs = '" "'.join(funcs)
            group_color = self.group_border_color.rgba_web()
            group_font_size = self.group_font_size
            output.append(
                'subgraph "cluster_{group}" {{ '
                '"{funcs}"; '
                'label = "{group}"; '
                'fontsize = "{group_font_size}"; '
                'fontcolor = "black"; '
                'style = "bold"; '
                'color="{group_color}"; }}'.format(**locals()))
        return output

    def generate_nodes(self):
        output = []
        for node in self.processor.nodes():
            attr = {
                'color': self.node_color_func(node).rgba_web(),
                'label': self.node_label_func(node),
            }
            output.append(self.node(node.name, attr))

        return output

    def generate_edges(self):
        output = []

        for edge in self.processor.edges():
            attr = {
                'color': self.edge_color_func(edge).rgba_web(),
                'label': self.edge_label_func(edge),
            }
            output.append(self.edge(edge, attr))

        return output

########NEW FILE########
__FILENAME__ = output
import re
import os
from distutils.spawn import find_executable

from ..exceptions import PyCallGraphException
from ..color import Color


class Output(object):
    '''Base class for all outputters.'''

    def __init__(self, **kwargs):
        self.node_color_func = self.node_color
        self.edge_color_func = self.edge_color
        self.node_label_func = self.node_label
        self.edge_label_func = self.edge_label

        # Update the defaults with anything from kwargs
        [setattr(self, k, v) for k, v in kwargs.iteritems()]

    def set_config(self, config):
        '''
        This is a quick hack to move the config variables set in Config into
        the output module config variables.
        '''
        for k, v in config.__dict__.iteritems():
            if hasattr(self, k) and \
                    callable(getattr(self, k)):
                continue
            setattr(self, k, v)

    def node_color(self, node):
        value = float(node.time.fraction * 2 + node.calls.fraction) / 3
        return Color.hsv(value / 2 + .5, value, 0.9)

    def edge_color(self, edge):
        value = float(edge.time.fraction * 2 + edge.calls.fraction) / 3
        return Color.hsv(value / 2 + .5, value, 0.7)

    def node_label(self, node):
        parts = [
            '{0.name}',
            'calls: {0.calls.value:n}',
            'time: {0.time.value:f}s',
        ]

        if self.processor.config.memory:
            parts += [
                'memory in: {0.memory_in.value_human_bibyte}',
                'memory out: {0.memory_out.value_human_bibyte}',
            ]

        return r'\n'.join(parts).format(node)

    def edge_label(self, edge):
        return '{}'.format(edge.calls.value)

    def sanity_check(self):
        '''Basic checks for certain libraries or external applications.  Raise
        or warn if there is a problem.
        '''
        pass

    @classmethod
    def add_arguments(cls, subparsers):
        pass

    def reset(self):
        pass

    def set_processor(self, processor):
        self.processor = processor

    def start(self):
        '''Initialise variables after initial configuration.'''
        pass

    def update(self):
        '''Called periodically during a trace, but only when should_update is
        set to True.
        '''
        raise NotImplementedError('update')

    def should_update(self):
        '''Return True if the update method should be called periodically.'''
        return False

    def done(self):
        '''Called when the trace is complete and ready to be saved.'''
        raise NotImplementedError('done')

    def ensure_binary(self, cmd):
        if find_executable(cmd):
            return

        raise PyCallGraphException(
            'The command "{}" is required to be in your path.'.format(cmd))

    def normalize_path(self, path):
        regex_user_expand = re.compile('\A~')
        if regex_user_expand.match(path):
            path = os.path.expanduser(path)
        else:
            path = os.path.expandvars(path)  # expand, just in case
        return path

    def prepare_output_file(self):
        if self.fp is None:
            self.output_file = self.normalize_path(self.output_file)
            self.fp = open(self.output_file, 'wb')

    def verbose(self, text):
        self.processor.config.log_verbose(text)

    def debug(self, text):
        self.processor.config.log_debug(text)

    @classmethod
    def add_output_file(cls, subparser, defaults, help):
        subparser.add_argument(
            '-o', '--output-file', type=str, default=defaults.output_file,
            help=help,
        )

########NEW FILE########
__FILENAME__ = pickle
try:
    import cPickle as pickle
except ImportError:
    import pickle

from .output import Output


class PickleOutput(Output):

    def __init__(self, **kwargs):
        self.fp = None
        self.output_file = 'pycallgraph.dot'
        Output.__init__(self, **kwargs)

    @classmethod
    def add_arguments(cls, subparsers, parent_parser, usage):
        defaults = cls()

        subparser = subparsers.add_parser(
            'pickle',
            help='Dump to a cPickle file for generation later',
            parents=[parent_parser], usage=usage,
        )

        subparser.add_argument(
            '-o', '--output-file', type=str, default=defaults.output_file,
            help='The generated cPickle file',
        )

        return subparser

    def done(self):
        self.prepare_output_file()
        pickle.dump(self.tracer, self.fp, pickle.HIGHEST_PROTOCOL)

########NEW FILE########
__FILENAME__ = ubigraph
try:
    from xmlrpclib import Server
except ImportError:
    from xmlrpc.client import Server


# from ..exceptions import PyCallGraphException
from .output import Output


class UbigraphOutput(Output):

    def __init__(self, **kwargs):
        self.fp = None
        self.server_url = 'http://127.0.0.1:20738/RPC2'
        Output.__init__(self, **kwargs)

    def start(self):
        server = Server(self.server_url)
        self.graph = server.ubigraph

        # Create a graph
        for i in range(0, 10):
            self.graph.new_vertex_w_id(i)

        # Make some edges
        for i in range(0, 10):
            self.graph.new_edge(i, (i + 1) % 10)

    def should_update(self):
        return True

    def update(self):
        pass

    @classmethod
    def add_arguments(cls, subparsers, parent_parser, usage):
        defaults = cls()

        subparser = subparsers.add_parser(
            'ubigraph',
            help='Update an Ubigraph visualization in real time',
            parents=[parent_parser], usage=usage,
        )

        subparser.add_argument(
            '-s', '--server-url', type=str, default=defaults.server_url,
            help='The Ubigraph server',
        )

        return subparser

    def done(self):
        pass

########NEW FILE########
__FILENAME__ = pycallgraph
import locale

from .output import Output
from .config import Config
from .tracer import AsyncronousTracer, SyncronousTracer
from .exceptions import PyCallGraphException


class PyCallGraph(object):

    def __init__(self, output=None, config=None):
        '''output can be a single Output instance or an iterable with many
        of them.  Example usage:

            PyCallGraph(config=Config(), output=GraphvizOutput())
        '''
        locale.setlocale(locale.LC_ALL, '')

        if output is None:
            self.output = []
        elif isinstance(output, Output):
            self.output = [output]
        else:
            self.output = output

        self.config = config or Config()

        configured_ouput = self.config.get_output()
        if configured_ouput:
            self.output.append(configured_ouput)

        self.reset()

    def __enter__(self):
        self.start()

    def __exit__(self, type, value, traceback):
        self.done()

    def get_tracer_class(self):
        if self.config.threaded:
            return AsyncronousTracer
        else:
            return SyncronousTracer

    def reset(self):
        '''Resets all collected statistics.  This is run automatically by
        start(reset=True) and when the class is initialized.
        '''
        self.tracer = self.get_tracer_class()(self.output, config=self.config)

        for output in self.output:
            self.prepare_output(output)

    def start(self, reset=True):
        '''Begins a trace.  Setting reset to True will reset all previously
        recorded trace data.
        '''
        if not self.output:
            raise PyCallGraphException(
                'No outputs declared. Please see the '
                'examples in the online documentation.'
            )

        if reset:
            self.reset()

        for output in self.output:
            output.start()

        self.tracer.start()

    def stop(self):
        '''Stops the currently running trace, if any.'''
        self.tracer.stop()

    def done(self):
        '''Stops the trace and tells the outputters to generate their
        output.
        '''
        self.stop()

        self.generate()

    def generate(self):
        # If in threaded mode, wait for the processor thread to complete
        self.tracer.done()

        for output in self.output:
            output.done()

    def add_output(self, output):
        self.output.append(output)
        self.prepare_output(output)

    def prepare_output(self, output):
        output.sanity_check()
        output.set_processor(self.tracer.processor)
        output.reset()

########NEW FILE########
__FILENAME__ = tracer
from __future__ import division

import inspect
import sys
import os
import time
from distutils import sysconfig
from collections import defaultdict
from threading import Thread
try:
    from Queue import Queue, Empty
except ImportError:
    from queue import Queue, Empty

from .util import Util


class SyncronousTracer(object):

    def __init__(self, outputs, config):
        self.processor = TraceProcessor(outputs, config)
        self.config = config

    def tracer(self, frame, event, arg):
        self.processor.process(frame, event, arg, self.memory())
        return self.tracer

    def memory(self):
        if self.config.memory:
            from .memory_profiler import memory_usage
            return int(memory_usage(-1, 0)[0] * 1000000)

    def start(self):
        sys.settrace(self.tracer)

    def stop(self):
        sys.settrace(None)

    def done(self):
        pass


class AsyncronousTracer(SyncronousTracer):

    def start(self):
        self.processor.start()
        SyncronousTracer.start(self)

    def tracer(self, frame, event, arg):
        self.processor.queue(frame, event, arg, self.memory())
        return self.tracer

    def done(self):
        self.processor.done()
        self.processor.join()


class TraceProcessor(Thread):
    '''
    Contains a callback used by sys.settrace, which collects information about
    function call count, time taken, etc.
    '''

    def __init__(self, outputs, config):
        Thread.__init__(self)
        self.trace_queue = Queue()
        self.keep_going = True
        self.outputs = outputs
        self.config = config
        self.updatables = [a for a in self.outputs if a.should_update()]

        self.init_trace_data()
        self.init_libpath()

    def init_trace_data(self):
        self.previous_event_return = False

        # A mapping of which function called which other function
        self.call_dict = defaultdict(lambda: defaultdict(int))

        # Current call stack
        self.call_stack = ['__main__']

        # Counters for each function
        self.func_count = defaultdict(int)
        self.func_count_max = 0
        self.func_count['__main__'] = 1

        # Accumulative time per function
        self.func_time = defaultdict(float)
        self.func_time_max = 0

        # Accumulative memory addition per function
        self.func_memory_in = defaultdict(int)
        self.func_memory_in_max = 0

        # Accumulative memory addition per function once exited
        self.func_memory_out = defaultdict(int)
        self.func_memory_out_max = 0

        # Keeps track of the start time of each call on the stack
        self.call_stack_timer = []
        self.call_stack_memory_in = []
        self.call_stack_memory_out = []

    def init_libpath(self):
        self.lib_path = sysconfig.get_python_lib()
        path = os.path.split(self.lib_path)
        if path[1] == 'site-packages':
            self.lib_path = path[0]
        self.lib_path = self.lib_path.lower()

    def queue(self, frame, event, arg, memory):
        data = {
            'frame': frame,
            'event': event,
            'arg': arg,
            'memory': memory,
        }
        self.trace_queue.put(data)

    def run(self):
        while self.keep_going:
            try:
                data = self.trace_queue.get(timeout=0.1)
            except Empty:
                pass
            self.process(**data)

    def done(self):
        while not self.trace_queue.empty():
            time.sleep(0.1)
        self.keep_going = False

    def process(self, frame, event, arg, memory=None):
        '''This function processes a trace result. Keeps track of
        relationships between calls.
        '''

        if memory is not None and self.previous_event_return:
            # Deal with memory when function has finished so local variables
            # can be cleaned up
            self.previous_event_return = False

            if self.call_stack_memory_out:
                full_name, m = self.call_stack_memory_out.pop(-1)
            else:
                full_name, m = (None, None)

            # NOTE: Call stack is no longer the call stack that may be
            # expected. Potentially need to store a copy of it.
            if full_name and m:
                call_memory = memory - m

                self.func_memory_out[full_name] += call_memory
                self.func_memory_out_max = max(
                    self.func_memory_out_max, self.func_memory_out[full_name]
                )

        if event == 'call':
            keep = True
            code = frame.f_code

            # Stores all the parts of a human readable name of the current call
            full_name_list = []

            # Work out the module name
            module = inspect.getmodule(code)
            if module:
                module_name = module.__name__
                module_path = module.__file__

                if not self.config.include_stdlib \
                        and self.is_module_stdlib(module_path):
                    keep = False

                if module_name == '__main__':
                    module_name = ''
            else:
                module_name = ''

            if module_name:
                full_name_list.append(module_name)

            # Work out the class name
            try:
                class_name = frame.f_locals['self'].__class__.__name__
                full_name_list.append(class_name)
            except (KeyError, AttributeError):
                class_name = ''

            # Work out the current function or method
            func_name = code.co_name
            if func_name == '?':
                func_name = '__main__'
            full_name_list.append(func_name)

            # Create a readable representation of the current call
            full_name = '.'.join(full_name_list)

            if len(self.call_stack) > self.config.max_depth:
                keep = False

            # Load the trace filter, if any. 'keep' determines if we should
            # ignore this call
            if keep and self.config.trace_filter:
                keep = self.config.trace_filter(full_name)

            # Store the call information
            if keep:

                if self.call_stack:
                    src_func = self.call_stack[-1]
                else:
                    src_func = None

                self.call_dict[src_func][full_name] += 1

                self.func_count[full_name] += 1
                self.func_count_max = max(
                    self.func_count_max, self.func_count[full_name]
                )

                self.call_stack.append(full_name)
                self.call_stack_timer.append(time.time())

                if memory is not None:
                    self.call_stack_memory_in.append(memory)
                    self.call_stack_memory_out.append([full_name, memory])

            else:
                self.call_stack.append('')
                self.call_stack_timer.append(None)

        if event == 'return':

            self.previous_event_return = True

            if self.call_stack:
                full_name = self.call_stack.pop(-1)

                if self.call_stack_timer:
                    start_time = self.call_stack_timer.pop(-1)
                else:
                    start_time = None

                if start_time:
                    call_time = time.time() - start_time

                    self.func_time[full_name] += call_time
                    self.func_time_max = max(
                        self.func_time_max, self.func_time[full_name]
                    )

                if memory is not None:
                    if self.call_stack_memory_in:
                        start_mem = self.call_stack_memory_in.pop(-1)
                    else:
                        start_mem = None

                    if start_mem:
                        call_memory = memory - start_mem
                        self.func_memory_in[full_name] += call_memory

                        self.func_memory_in_max = max(
                            self.func_memory_in_max,
                            self.func_memory_in[full_name],
                        )

    def is_module_stdlib(self, file_name):
        '''
        Returns True if the file_name is in the lib directory. Used to check
        if a function is in the standard library or not.
        '''
        return file_name.lower().startswith(self.lib_path)

    def __getstate__(self):
        '''Used for when creating a pickle. Certain instance variables can't
        pickled and aren't used anyway.
        '''
        odict = self.__dict__.copy()
        dont_keep = [
            'outputs',
            'config',
            'updatables',
            'lib_path',
        ]
        for key in dont_keep:
            del odict[key]

        return odict

    def groups(self):
        grp = defaultdict(list)
        for node in self.nodes():
            grp[node.group].append(node)
        for g in grp.iteritems():
            yield g

    def stat_group_from_func(self, func, calls):
        stat_group = StatGroup()
        stat_group.name = func
        stat_group.group = self.config.trace_grouper(func)
        stat_group.calls = Stat(calls, self.func_count_max)
        stat_group.time = Stat(self.func_time.get(func, 0), self.func_time_max)
        stat_group.memory_in = Stat(
            self.func_memory_in.get(func, 0), self.func_memory_in_max
        )
        stat_group.memory_out = Stat(
            self.func_memory_in.get(func, 0), self.func_memory_in_max
        )
        return stat_group

    def nodes(self):
        for func, calls in self.func_count.iteritems():
            yield self.stat_group_from_func(func, calls)

    def edges(self):
        for src_func, dests in self.call_dict.iteritems():
            if not src_func:
                continue
            for dst_func, calls in dests.iteritems():
                edge = self.stat_group_from_func(dst_func, calls)
                edge.src_func = src_func
                edge.dst_func = dst_func
                yield edge


class Stat(object):
    '''Stores a "statistic" value, e.g. "time taken" along with the maximum
    possible value of the value, which is used to calculate the fraction of 1.
    The fraction is used for choosing colors.
    '''

    def __init__(self, value, total):
        self.value = value
        self.total = total
        try:
            self.fraction = value / total
        except ZeroDivisionError:
            self.fraction = 0

    @property
    def value_human_bibyte(self):
        '''Mebibyte of the value in human readable a form.'''
        return Util.human_readable_bibyte(self.value)


class StatGroup(object):
    pass


def simple_memoize(callable_object):
    '''Simple memoization for functions without keyword arguments.

    This is useful for mapping code objects to module in this context.
    inspect.getmodule() requires a number of system calls, which may slow down
    the tracing considerably. Caching the mapping from code objects (there is
    *one* code object for each function, regardless of how many simultaneous
    activations records there are).

    In this context we can ignore keyword arguments, but a generic memoizer
    ought to take care of that as well.
    '''

    cache = dict()

    def wrapper(*rest):
        if rest not in cache:
            cache[rest] = callable_object(*rest)
        return cache[rest]

    return wrapper

inspect.getmodule = simple_memoize(inspect.getmodule)

########NEW FILE########
__FILENAME__ = util
class Util(object):

    @staticmethod
    def human_readable_bibyte(num):
        num = float(num)
        for x in ['B', 'KiB', 'MiB', 'GiB']:
            if num < 1024 and num > -1024:
                return '{:3.1f}{}'.format(num, x)
            num /= 1024
        return '{:3.1f}{}'.format(num, 'TiB')

########NEW FILE########
__FILENAME__ = calls
def nop():
    pass


def one_nop():
    nop()

########NEW FILE########
__FILENAME__ = conftest
import tempfile

from helpers import *


@pytest.fixture(scope='module')
def pycg():
    return PyCallGraph()


@pytest.fixture(scope='module')
def config():
    return Config()


@pytest.fixture(scope='module')
def temp():
    return tempfile.mkstemp()[1]

########NEW FILE########
__FILENAME__ = fix_path
from os import path
import sys

ROOT = path.join(path.abspath(path.dirname(__file__)), '..')
sys.path.insert(0, ROOT)

########NEW FILE########
__FILENAME__ = helpers
# flake8: noqa
import time

import pytest

import fix_path
from pycallgraph import *
from pycallgraph.tracer import *
from pycallgraph.output import *


def wait_100ms():
    time.sleep(0.1)


def wait_200ms():
    time.sleep(0.2)

########NEW FILE########
__FILENAME__ = test_color
from helpers import *


def test_bad_range():
    with pytest.raises(ColorException):
        Color(0, 5, 0, 0)
    with pytest.raises(ColorException):
        Color(0, 0, -1, 0)


def test_hsv():
    c = Color.hsv(0.1, 0.5, 0.75, 0.25)
    assert c.r is 0.75
    assert abs(c.g - 0.6) < 0.1  # Floating point comparison inaccurate
    assert abs(c.b - 0.375) < 0.1
    assert c.a is 0.25


def test_rgb_csv():
    assert Color(0.3, 0.4, 0.5, 0.6).rgb_csv() == '76,102,127'


def test_str():
    assert str(Color(0.071, 0.204, 0.338, 0.471)) == '<Color #12345678>'

########NEW FILE########
__FILENAME__ = test_config
from helpers import *


def test_init():
    assert Config().groups
    assert Config(groups=False).groups is False

########NEW FILE########
__FILENAME__ = test_gephi
from helpers import *
from calls import *


@pytest.fixture
def gephi(temp):
    g = GephiOutput()
    g.output_file = temp
    return g


def test_simple(gephi):
    with PyCallGraph(output=gephi):
        one_nop()
    generated = open(gephi.output_file).read()
    os.unlink(gephi.output_file)

    assert 'nodedef> name VARCHAR' in generated
    assert 'edgedef> node1 VARCHAR, node2 VARCHAR' in generated
    assert 'calls.one_nop,calls.one_nop,calls,1' in generated
    assert 'calls.one_nop,calls.nop,1' in generated

########NEW FILE########
__FILENAME__ = test_graphviz
from helpers import *
from calls import *


@pytest.fixture
def graphviz(temp):
    g = GraphvizOutput()
    g.output_file = temp
    g.output_type = 'dot'
    return g


def test_simple(graphviz):
    with PyCallGraph(output=graphviz):
        one_nop()
    dot = open(graphviz.output_file).read()
    os.unlink(graphviz.output_file)

    assert 'digraph G' in dot
    assert '__main__ -> "calls.one_nop"' in dot

########NEW FILE########
__FILENAME__ = test_output
from helpers import *


def test_set_config():
    '''Should not raise!'''
    Output().set_config(Config())

########NEW FILE########
__FILENAME__ = test_pycallgraph
from helpers import *


def test_start_no_outputs(pycg):
    with pytest.raises(PyCallGraphException):
        pycg.start()


def test_with_block_no_outputs(pycg):
    with pytest.raises(PyCallGraphException):
        with pycg:
            pass


def test_get_tracer_class(pycg):
    pycg.config.threaded = True
    assert pycg.get_tracer_class() == AsyncronousTracer

    pycg.config.threaded = False
    assert pycg.get_tracer_class() == SyncronousTracer

########NEW FILE########
__FILENAME__ = test_script
import subprocess

from helpers import *


def execute(arguments):
    command = 'PYTHONPATH=. scripts/pycallgraph ' + arguments
    return subprocess.check_output(command, shell=True).decode('utf-8')


def test_help():
    assert 'Python Call Graph' in execute('--help')


def test_graphviz_help():
    assert '--font-name FONT_NAME' in execute('graphviz --help')

########NEW FILE########
__FILENAME__ = test_trace_processor
import re
import sys

from helpers import *
import calls
from pycallgraph.tracer import TraceProcessor


@pytest.fixture
def trace_processor(config):
    return TraceProcessor([], config)


def test_empty(trace_processor):
    sys.settrace(trace_processor.process)
    sys.settrace(None)

    assert trace_processor.call_dict == {}


def test_nop(trace_processor):
    sys.settrace(trace_processor.process)
    calls.nop()
    sys.settrace(None)

    assert trace_processor.call_dict == {
        '__main__': {
            'calls.nop': 1
        }
    }


def test_one_nop(trace_processor):
    sys.settrace(trace_processor.process)
    calls.one_nop()
    sys.settrace(None)

    assert trace_processor.call_dict == {
        '__main__': {'calls.one_nop': 1},
        'calls.one_nop': {'calls.nop': 1},
    }


def stdlib_trace(trace_processor, include_stdlib):
    trace_processor.config = Config(include_stdlib=include_stdlib)
    sys.settrace(trace_processor.process)
    re.match("asdf", "asdf")
    calls.one_nop()
    sys.settrace(None)
    return trace_processor.call_dict


def test_no_stdlib(trace_processor):
    assert 're.match' not in stdlib_trace(trace_processor, False)


def test_yes_stdlib(trace_processor):
    assert 're.match' in stdlib_trace(trace_processor, True)

########NEW FILE########
__FILENAME__ = test_util
from helpers import *


def test_human_readable_biyte():
    hrb = Util.human_readable_bibyte
    assert hrb(0) == '0.0B'
    assert hrb(1024) == '1.0KiB'
    assert hrb(1024 * 5.2) == '5.2KiB'
    assert hrb(1024 * 1024 * 5.2) == '5.2MiB'
    assert hrb(1024 * 1024 * 1024 * 5.2) == '5.2GiB'
    assert hrb(1024 * 1024 * 1024 * 1024 * 5.2) == '5.2TiB'
    assert hrb(1024 * 1024 * 1024 * 1024 * 1024 * 5.2) == '5324.8TiB'
    assert hrb(-1024 * 1024 * 1024 * 5.2) == '-5.2GiB'
    assert hrb(-1024) == '-1.0KiB'

########NEW FILE########
