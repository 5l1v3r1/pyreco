__FILENAME__ = conf
# -*- coding: utf-8 -*-
#
# Gears documentation build configuration file, created by
# sphinx-quickstart on Sat Feb 25 20:20:25 2012.
#
# This file is execfile()d with the current directory set to its containing dir.
#
# Note that not all possible configuration values are present in this
# autogenerated file.
#
# All configuration values have a default; values that are commented out
# serve to show the default.

import sys, os

# If extensions (or modules to document with autodoc) are in another directory,
# add these directories to sys.path here. If the directory is relative to the
# documentation root, use os.path.abspath to make it absolute, like shown here.
#sys.path.insert(0, os.path.abspath('.'))

# -- General configuration -----------------------------------------------------

# If your documentation needs a minimal Sphinx version, state it here.
#needs_sphinx = '1.0'

# Add any Sphinx extension module names here, as strings. They can be extensions
# coming with Sphinx (named 'sphinx.ext.*') or your custom ones.
extensions = ['sphinx.ext.autodoc', 'sphinx.ext.intersphinx']

# Add any paths that contain templates here, relative to this directory.
templates_path = ['_templates']

# The suffix of source filenames.
source_suffix = '.rst'

# The encoding of source files.
#source_encoding = 'utf-8-sig'

# The master toctree document.
master_doc = 'index'

# General information about the project.
project = u'Gears'
copyright = u'2013, Mike Yumatov'

# The version info for the project you're documenting, acts as replacement for
# |version| and |release|, also used in various other places throughout the
# built documents.
#
# The short X.Y version.
version = '0.7'
# The full version, including alpha/beta/rc tags.
release = '0.7.2'

# The language for content autogenerated by Sphinx. Refer to documentation
# for a list of supported languages.
#language = None

# There are two options for replacing |today|: either, you set today to some
# non-false value, then it is used:
#today = ''
# Else, today_fmt is used as the format for a strftime call.
#today_fmt = '%B %d, %Y'

# List of patterns, relative to source directory, that match files and
# directories to ignore when looking for source files.
exclude_patterns = ['_build']

# The reST default role (used for this markup: `text`) to use for all documents.
#default_role = None

# If true, '()' will be appended to :func: etc. cross-reference text.
#add_function_parentheses = True

# If true, the current module name will be prepended to all description
# unit titles (such as .. function::).
#add_module_names = True

# If true, sectionauthor and moduleauthor directives will be shown in the
# output. They are ignored by default.
#show_authors = False

# The name of the Pygments (syntax highlighting) style to use.
pygments_style = 'sphinx'

# A list of ignored prefixes for module index sorting.
#modindex_common_prefix = []


# -- Options for HTML output ---------------------------------------------------

# The theme to use for HTML and HTML Help pages.  See the documentation for
# a list of builtin themes.
html_theme = 'default'

# Theme options are theme-specific and customize the look and feel of a theme
# further.  For a list of options available for each theme, see the
# documentation.
#html_theme_options = {}

# Add any paths that contain custom themes here, relative to this directory.
#html_theme_path = []

# The name for this set of Sphinx documents.  If None, it defaults to
# "<project> v<release> documentation".
#html_title = None

# A shorter title for the navigation bar.  Default is the same as html_title.
#html_short_title = None

# The name of an image file (relative to this directory) to place at the top
# of the sidebar.
#html_logo = None

# The name of an image file (within the static path) to use as favicon of the
# docs.  This file should be a Windows icon file (.ico) being 16x16 or 32x32
# pixels large.
#html_favicon = None

# Add any paths that contain custom static files (such as style sheets) here,
# relative to this directory. They are copied after the builtin static files,
# so a file named "default.css" will overwrite the builtin "default.css".
html_static_path = ['_static']

# If not '', a 'Last updated on:' timestamp is inserted at every page bottom,
# using the given strftime format.
#html_last_updated_fmt = '%b %d, %Y'

# If true, SmartyPants will be used to convert quotes and dashes to
# typographically correct entities.
#html_use_smartypants = True

# Custom sidebar templates, maps document names to template names.
#html_sidebars = {}

# Additional templates that should be rendered to pages, maps page names to
# template names.
#html_additional_pages = {}

# If false, no module index is generated.
#html_domain_indices = True

# If false, no index is generated.
#html_use_index = True

# If true, the index is split into individual pages for each letter.
#html_split_index = False

# If true, links to the reST sources are added to the pages.
#html_show_sourcelink = True

# If true, "Created using Sphinx" is shown in the HTML footer. Default is True.
#html_show_sphinx = True

# If true, "(C) Copyright ..." is shown in the HTML footer. Default is True.
#html_show_copyright = True

# If true, an OpenSearch description file will be output, and all pages will
# contain a <link> tag referring to it.  The value of this option must be the
# base URL from which the finished HTML is served.
#html_use_opensearch = ''

# This is the file name suffix for HTML files (e.g. ".xhtml").
#html_file_suffix = None

# Output file base name for HTML help builder.
htmlhelp_basename = 'Gearsdoc'


# -- Options for LaTeX output --------------------------------------------------

latex_elements = {
# The paper size ('letterpaper' or 'a4paper').
#'papersize': 'letterpaper',

# The font size ('10pt', '11pt' or '12pt').
#'pointsize': '10pt',

# Additional stuff for the LaTeX preamble.
#'preamble': '',
}

# Grouping the document tree into LaTeX files. List of tuples
# (source start file, target name, title, author, documentclass [howto/manual]).
latex_documents = [
  ('index', 'Gears.tex', u'Gears Documentation',
   u'Mike Yumatov', 'manual'),
]

# The name of an image file (relative to this directory) to place at the top of
# the title page.
#latex_logo = None

# For "manual" documents, if this is true, then toplevel headings are parts,
# not chapters.
#latex_use_parts = False

# If true, show page references after internal links.
#latex_show_pagerefs = False

# If true, show URL addresses after external links.
#latex_show_urls = False

# Documents to append as an appendix to all manuals.
#latex_appendices = []

# If false, no module index is generated.
#latex_domain_indices = True


# -- Options for manual page output --------------------------------------------

# One entry per manual page. List of tuples
# (source start file, name, description, authors, manual section).
man_pages = [
    ('index', 'gears', u'Gears Documentation',
     [u'Mike Yumatov'], 1)
]

# If true, show URL addresses after external links.
#man_show_urls = False


# -- Options for Texinfo output ------------------------------------------------

# Grouping the document tree into Texinfo files. List of tuples
# (source start file, target name, title, author,
#  dir menu entry, description, category)
texinfo_documents = [
  ('index', 'Gears', u'Gears Documentation',
   u'Mike Yumatov', 'Gears', 'One line description of project.',
   'Miscellaneous'),
]

# Documents to append as an appendix to all manuals.
#texinfo_appendices = []

# If false, no module index is generated.
#texinfo_domain_indices = True

# How to display URL addresses: 'footnote', 'no', or 'inline'.
#texinfo_show_urls = 'footnote'


# Example configuration for intersphinx: refer to the Python standard library.
intersphinx_mapping = {'http://docs.python.org/': None}

########NEW FILE########
__FILENAME__ = assets
import codecs
import hashlib
import os
import re

from .asset_attributes import AssetAttributes
from .compat import is_py3, str, UnicodeMixin
from .exceptions import GearsUnicodeError
from .utils import cached_property, unique


EXTENSION_RE = re.compile(r'(\.\w+)$')
FINGERPRINT_RE = re.compile(r'(\.[0-9a-f]{40})\.\w+$')


class CircularDependencyError(Exception):

    def __init__(self, absolute_path):
        self.absolute_path = absolute_path

    def __str__(self):
        return '%s has already been required' % self.absolute_path


class Requirements(object):

    def __init__(self, asset):
        self.current = self.before = []
        self.after = []
        self.asset = asset

    def __iter__(self):
        return self._iter_unique()

    def __repr__(self):
        return '<Requirements before=%r after=%r>' % (self.before, self.after)

    @classmethod
    def from_dict(cls, asset, data):
        self = cls(asset)
        for absolute_path, logical_path in data['before']:
            self.add(self._asset_from_paths(absolute_path, logical_path))
        self.add(asset)
        for absolute_path, logical_path in data['after']:
            self.add(self._asset_from_paths(absolute_path, logical_path))
        return self

    @cached_property
    def expired(self):
        return (any(asset.bundle_expired for asset in self.before) or
                any(asset.bundle_expired for asset in self.after))

    def add(self, asset):
        if asset is self.asset:
            self.current = self.after
        else:
            self.current.append(asset)

    def to_dict(self):
        return {'before': [self._paths_from_asset(asset) for asset in self.before],
                'after': [self._paths_from_asset(asset) for asset in self.after]}

    def _iter_requirements(self, assets):
        for asset in assets:
            for requirement in asset.requirements:
                yield requirement

    def _iter_all(self):
        for requirement in self._iter_requirements(self.before):
            yield requirement
        yield self.asset
        for requirement in self._iter_requirements(self.after):
            yield requirement

    def _iter_unique(self):
        return unique(self._iter_all(), key=lambda asset: asset.absolute_path)

    def _asset_from_paths(self, absolute_path, logical_path):
        attributes = AssetAttributes(self.asset.attributes.environment, logical_path)
        return Asset(attributes, absolute_path)

    def _paths_from_asset(self, asset):
        return (asset.absolute_path, asset.attributes.path)


class Dependency(object):

    def __init__(self, environment, absolute_path):
        self.environment = environment
        self.absolute_path = absolute_path
        if self.expired:
            self._save_to_cache()

    def __eq__(self, other):
        return self.absolute_path == other.absolute_path

    def __hash__(self):
        return hash(self.absolute_path)

    @cached_property
    def source(self):
        if os.path.isdir(self.absolute_path):
            source = ', '.join(sorted(os.listdir(self.absolute_path)))
            return source.encode('utf-8') if is_py3 else source
        with open(self.absolute_path, 'rb') as f:
            return f.read()

    @cached_property
    def mtime(self):
        return os.stat(self.absolute_path).st_mtime

    @cached_property
    def hexdigest(self):
        return hashlib.sha1(self.source).hexdigest()

    @cached_property
    def expired(self):
        data = self.environment.cache.get(self._get_cache_key())
        return (data is None or
                self.mtime > data['mtime'] or
                self.hexdigest > data['hexdigest'])

    def to_dict(self):
        return {'mtime': self.mtime, 'hexdigest': self.hexdigest}

    def _save_to_cache(self):
        self.environment.cache.set(self._get_cache_key(), self.to_dict())

    def _get_cache_key(self):
        return 'dependency:%s' % self.absolute_path


class Dependencies(object):

    def __init__(self, environment):
        self.environment = environment
        self._registry = set()

    @classmethod
    def from_list(cls, environment, data):
        self = cls(environment)
        for absolute_path in data:
            self.add(absolute_path)
        return self

    @cached_property
    def expired(self):
        return any(d.expired for d in self._registry)

    @cached_property
    def mtime(self):
        if not self._registry:
            return None
        return max(d.mtime for d in self._registry)

    def add(self, absolute_path):
        self._registry.add(Dependency(self.environment, absolute_path))

    def clear(self):
        self._registry.clear()

    def to_list(self):
        return [d.absolute_path for d in self._registry]


class BaseAsset(object):

    gzippable = True

    def __init__(self, attributes, absolute_path, calls=None):
        self.attributes = attributes
        self.absolute_path = absolute_path

        self.calls = calls.copy() if calls else set()
        if self.absolute_path in self.calls:
            raise CircularDependencyError(self.absolute_path)
        self.calls.add(self.absolute_path)

    def __repr__(self):
        return '<%s absolute_path=%s>' % (self.__class__.__name__, self.absolute_path)

    @cached_property
    def is_public(self):
        environment = self.attributes.environment
        logical_path = os.path.normpath(self.attributes.logical_path)
        return environment.is_public(logical_path) or self.params.get('public')

    @cached_property
    def params(self):
        return {}

    @cached_property
    def hexdigest_path(self):
        return EXTENSION_RE.sub(
            r'.{0}\1'.format(self.final_hexdigest),
            self.attributes.logical_path,
        )


class Asset(UnicodeMixin, BaseAsset):

    def __init__(self, *args, **kwargs):
        super(Asset, self).__init__(*args, **kwargs)
        self.cache = self.attributes.environment.cache
        if self.expired:
            self.params.clear()
            self.dependencies.clear()
            self.requirements = Requirements(self)
            self.processed_source = self.source
            for process in self.attributes.processors:
                process(self)
            self._save_to_cache()
        else:
            self._init_from_cache()

    def __unicode__(self):
        return self.compressed_source

    def __iter__(self):
        return iter(str(self).encode('utf-8'))

    @property
    def cached_data(self):
        return self.cache.get(self._get_cache_key())

    @cached_property
    def params(self):
        if self.cached_data:
            return self.cached_data['params']
        return {}

    @cached_property
    def dependencies(self):
        if self.cached_data:
            data = self.cached_data['dependencies']
            return Dependencies.from_list(self.attributes.environment, data)
        return Dependencies(self.attributes.environment)

    @cached_property
    def source(self):
        try:
            with codecs.open(self.absolute_path, encoding='utf-8') as f:
                return f.read()
        except UnicodeDecodeError as e:
            raise GearsUnicodeError(self.absolute_path, str(e))

    @cached_property
    def bundled_source(self):
        cache_key = self._get_cache_key('bundled_source')
        if not self.bundle_expired:
            bundled_source = self.cache.get(cache_key)
            if bundled_source is not None:
                return bundled_source
        bundled_source = '\n'.join(r.processed_source for r in self.requirements)
        self.cache.set(cache_key, bundled_source)
        return bundled_source

    @cached_property
    def compressed_source(self):
        cache_key = self._get_cache_key('compressed_source')
        if not self.bundle_expired:
            compressed_source = self.cache.get(cache_key)
            if compressed_source is not None:
                return compressed_source
        compressed_source = self.bundled_source
        compress = self.attributes.compressor
        if compress:
            compressed_source = compress(self)
        self.cache.set(cache_key, compressed_source)
        return compressed_source

    @cached_property
    def mtime(self):
        mtime = os.stat(self.absolute_path).st_mtime
        if self.dependencies.mtime is not None:
            return max(mtime, self.dependencies.mtime)
        return mtime

    @cached_property
    def hexdigest(self):
        return hashlib.sha1(self.source.encode('utf-8')).hexdigest()

    @cached_property
    def final_hexdigest(self):
        return hashlib.sha1(self.compressed_source.encode('utf-8')).hexdigest()

    @cached_property
    def expired(self):
        return (self.cached_data is None or
                self.mtime > self.cached_data['mtime'] or
                self.hexdigest > self.cached_data['hexdigest'] or
                self.dependencies.expired)

    @cached_property
    def bundle_expired(self):
        return self.expired or self.requirements.expired

    def to_dict(self):
        return {'processed_source': self.processed_source,
                'requirements': self.requirements.to_dict(),
                'dependencies': self.dependencies.to_list(),
                'params': self.params,
                'hexdigest': self.hexdigest,
                'mtime': self.mtime}

    def _init_from_cache(self):
        self.params = self.cached_data['params']
        self.dependencies = Dependencies.from_list(
            self.attributes.environment,
            self.cached_data['dependencies'])
        self.requirements = Requirements.from_dict(self, self.cached_data['requirements'])
        self.processed_source = self.cached_data['processed_source']

    def _save_to_cache(self):
        self.cache.set(self._get_cache_key(), self.to_dict())

    def _get_cache_key(self, suffix='data'):
        return 'asset:%s:%s' % (self.absolute_path, suffix)


class StaticAsset(BaseAsset):

    gzippable = False

    @cached_property
    def source(self):
        with open(self.absolute_path, 'rb') as f:
            return f.read()

    @cached_property
    def mtime(self):
        return os.stat(self.absolute_path).st_mtime

    @cached_property
    def hexdigest(self):
        return hashlib.sha1(self.source).hexdigest()

    @cached_property
    def final_hexdigest(self):
        return self.hexdigest

    def __iter__(self):
        return iter(self.source)


class CheckAsset(BaseAsset):

    def __init__(self, *args, **kwargs):
        super(CheckAsset, self).__init__(*args, **kwargs)
        self.processed_source = self.source
        for process in self.attributes.processors:
            if getattr(process, 'supports_check_mode', False):
                process(self, check=True)

    @cached_property
    def source(self):
        try:
            with codecs.open(self.absolute_path, encoding='utf-8') as f:
                return f.read()
        except UnicodeDecodeError as e:
            raise GearsUnicodeError(self.absolute_path, str(e))


def build_asset(environment, path, check=False):
    path = strip_fingerprint(path)
    asset_attributes = AssetAttributes(environment, path)
    asset_attributes, absolute_path = environment.find(asset_attributes, True)
    if not asset_attributes.processors:
        return StaticAsset(asset_attributes, absolute_path)
    if check:
        return CheckAsset(asset_attributes, absolute_path)
    return Asset(asset_attributes, absolute_path)


def strip_fingerprint(path):
    match = FINGERPRINT_RE.search(path)
    if not match:
        return path
    fingerprint = match.group(1)
    return path.replace(fingerprint, '')

########NEW FILE########
__FILENAME__ = asset_attributes
# -*- coding: utf-8 -*-

import os
import re
from .utils import cached_property


class AssetAttributes(object):
    """Provides access to asset path properties. The attributes object is
    created with environment object and relative (or logical) asset path.

    Some properties may be useful or not, depending on the type of passed path.
    If it is a relative asset path, you can use all properties except
    :attr:`search_paths`. In case of a logical asset path it makes sense to
    use only those properties that are not related to processors and compressor.

    :param environment: an instance of :class:`~gears.environment.Environment`
                        class.
    :param path: a relative or logical path of the asset.
    """

    def __init__(self, environment, path):
        #: Used to access the registries of compilers, processors, etc.
        #: It can be also used by asset. See
        #: :class:`~gears.environment.Environment` for more information.
        self.environment = environment

        #: The relative (or logical) path to asset.
        self.path = path

        #: The relative path to the directory the asset.
        self.dirname = os.path.dirname(path)

    @cached_property
    def search_paths(self):
        """The list of logical paths which are used to search for an asset.
        This property makes sense only if the attributes was created with
        logical path.

        It is assumed that the logical path can be a directory containing a
        file named ``index`` with the same suffix.

        Example::

            >>> attrs = AssetAttributes(environment, 'js/app.js')
            >>> attrs.search_paths
            ['js/app.js', 'js/app/index.js']

            >>> attrs = AssetAttributes(environment, 'js/app/index.js')
            >>> attrs.search_paths
            ['js/models/index.js']
        """
        paths = [self.path]
        if os.path.basename(self.path_without_suffix) != 'index':
            path = os.path.join(self.path_without_suffix, 'index')
            paths.append(path + ''.join(self.suffix))
        return paths

    @cached_property
    def path_without_suffix(self):
        """The relative path to asset without suffix.
        Example::

            >>> attrs = AssetAttributes(environment, 'js/app.js')
            >>> attrs.path_without_suffix
            'js/app'
        """
        if self.suffix:
            return self.path[:-len(''.join(self.suffix))]
        return self.path

    @property
    def logical_path(self):
        """The logical path to asset.
        Example::

            >>> attrs = AssetAttributes(environment, 'js/models.js.coffee')
            >>> attrs.logical_path
            'js/models.js'
        """
        format_extension = self.format_extension or self.compiler_format_extension
        if format_extension is None:
            return self.path
        return self.path_without_suffix + format_extension

    @cached_property
    def extensions(self):
        """The list of asset extensions.
        Example::

            >>> attrs = AssetAttributes(environment, 'js/models.js.coffee')
            >>> attrs.extensions
            ['.js', '.coffee']

            >>> attrs = AssetAttributes(environment, 'js/lib/external.min.js.coffee')
            >>> attrs.format_extension
            ['.min', '.js', '.coffee']
        """
        return re.findall(r'\.[^.]+', os.path.basename(self.path))

    @cached_property
    def format_extension(self):
        """The format extension of asset.
        Example::

            >>> attrs = AssetAttributes(environment, 'js/models.js.coffee')
            >>> attrs.format_extension
            '.js'

            >>> attrs = AssetAttributes(environment, 'js/lib/external.min.js.coffee')
            >>> attrs.format_extension
            '.js'
        """
        for extension in reversed(self.extensions):
            compiler = self.environment.compilers.get(extension)
            if not compiler and self.environment.mimetypes.get(extension):
                return extension

    @cached_property
    def suffix(self):
        """The list of asset extensions starting from the first known extension.
        Example::

            >>> attrs = AssetAttributes(environment, 'js/lib/external.min.js.coffee')
            >>> attrs.suffix
            ['.js', '.coffee']
        """
        return self.extensions[len(self.unknown_extensions):]

    @cached_property
    def unknown_extensions(self):
        """The list of unknown extensions, which are actually parts of asset
        filename. Example::

            >>> attrs = AssetAttributes(environment, 'js/lib-2.0.min.js')
            >>> attrs.suffix
            ['.0', '.min']
        """
        unknown_extensions = []
        for extension in self.extensions:
            compiler = self.environment.compilers.get(extension)
            if compiler or self.environment.mimetypes.get(extension):
                return unknown_extensions
            unknown_extensions.append(extension)
        return unknown_extensions

    @cached_property
    def compiler_extensions(self):
        """The list of compiler extensions.
        Example::

            >>> attrs = AssetAttributes(environment, 'js/lib/external.min.js.coffee')
            >>> attrs.compiler_extensions
            ['.coffee']
        """
        try:
            index = self.extensions.index(self.format_extension)
        except ValueError:
            index = 0
        extensions = self.extensions[index:]
        return [e for e in extensions if self.environment.compilers.get(e)]

    @cached_property
    def compilers(self):
        """The list of compilers used to build asset."""
        return [self.environment.compilers.get(e) for e in self.compiler_extensions]

    @property
    def preprocessors(self):
        """The list of preprocessors used to build asset."""
        return self.environment.preprocessors.get(self.mimetype)

    @property
    def postprocessors(self):
        """The list of postprocessors used to build asset."""
        return self.environment.postprocessors.get(self.mimetype)

    @property
    def processors(self):
        """The list of all processors (preprocessors, compilers,
        postprocessors) used to build asset.
        """
        return self.preprocessors + list(reversed(self.compilers)) + self.postprocessors

    @property
    def compressor(self):
        """The compressors used to compress the asset."""
        return self.environment.compressors.get(self.mimetype)

    @cached_property
    def mimetype(self):
        """MIME type of the asset."""
        return (self.environment.mimetypes.get(self.format_extension) or
                self.compiler_mimetype or 'application/octet-stream')

    @cached_property
    def compiler_mimetype(self):
        """Implicit MIME type of the asset by its compilers."""
        for compiler in reversed(self.compilers):
            if compiler.result_mimetype:
                return compiler.result_mimetype
        return None

    @cached_property
    def compiler_format_extension(self):
        """Implicit format extension on the asset by its compilers."""
        for extension, mimetype in self.environment.mimetypes.items():
            if mimetype == self.compiler_mimetype:
                return extension
        return None

########NEW FILE########
__FILENAME__ = asset_handler
# -*- coding: utf-8 -*-

from functools import wraps
from subprocess import Popen, PIPE


class AssetHandlerError(Exception):
    pass


class BaseAssetHandler(object):
    """Base class for all asset handlers (processors, compilers and
    compressors). A subclass has to implement :meth:`__call__` which is called
    with asset as argument.
    """

    supports_check_mode = False

    def __call__(self, asset):
        """Subclasses have to override this method to implement the actual
        handler function code. This method is called with asset as argument.
        Depending on the type of the handler, this method must change asset
        state (as it does in :class:`~gears.processors.Directivesprocessor`)
        or return some value (in case of asset compressors).
        """
        raise NotImplementedError

    @classmethod
    def as_handler(cls, **initkwargs):
        """Converts the class into an actual handler function that can be used
        when registering different types of processors in
        :class:`~gears.environment.Environment` class instance.

        The arguments passed to :meth:`as_handler` are forwarded to the
        constructor of the class.
        """
        @wraps(cls, updated=())
        def handler(asset, *args, **kwargs):
            return handler.handler_class(**initkwargs)(asset, *args, **kwargs)
        handler.handler_class = cls
        handler.supports_check_mode = cls.supports_check_mode
        return handler


class ExecMixin(object):
    """Provides the ability to process asset through external command."""

    #: The name of the executable to run. It must be a command name, if it is
    #: available in the PATH environment variable, or a path to the executable.
    executable = None

    #: The list of executable parameters.
    params = []

    def run(self, input):
        """Runs :attr:`executable` with ``input`` as stdin.
        :class:`AssetHandlerError` exception is raised, if execution is failed,
        otherwise stdout is returned.
        """
        p = self.get_process()
        output, errors = p.communicate(input=input.encode('utf-8'))
        if p.returncode != 0:
            raise AssetHandlerError(errors)
        return output.decode('utf-8')

    def get_process(self):
        """Returns :class:`subprocess.Popen` instance with args from
        :meth:`get_args` result and piped stdin, stdout and stderr.
        """
        return Popen(self.get_args(), stdin=PIPE, stdout=PIPE, stderr=PIPE)

    def get_args(self):
        """Returns the list of :class:`subprocess.Popen` arguments."""
        return [self.executable] + self.params

########NEW FILE########
__FILENAME__ = cache
import hashlib
import os
try:
    import cPickle as pickle
except ImportError:
    import pickle


class SimpleCache(dict):

    def set(self, key, value):
        self[key] = value

    def get(self, key):
        return super(SimpleCache, self).get(key)


class FileBasedCache(object):

    def __init__(self, root):
        self.root = root

    def set(self, key, value):
        filepath = self._get_filepath(key)

        dirname = os.path.dirname(filepath)
        if not os.path.exists(dirname):
            try:
                os.makedirs(dirname)
            except OSError:
                return

        try:
            with open(filepath, 'wb') as f:
                pickle.dump(value, f, pickle.HIGHEST_PROTOCOL)
        except IOError:
            pass

    def get(self, key):
        filepath = self._get_filepath(key)
        try:
            with open(filepath, 'rb') as f:
                return pickle.load(f)
        except (IOError, OSError, EOFError, pickle.PickleError):
            return None

    def _get_filepath(self, key):
        relpath = hashlib.sha1(key.encode('utf-8')).hexdigest()
        relpath = os.path.join(relpath[:2], relpath[2:4], relpath[4:])
        return os.path.join(self.root, relpath)

########NEW FILE########
__FILENAME__ = compat
import collections
import sys


is_py2 = (sys.version_info[0] == 2)
is_py3 = (sys.version_info[0] == 3)


class UnicodeMixin(object):
    """Python 3 compatible __str__/__unicode__ support"""

    def __str__(self):
        value = self.__unicode__()
        if is_py2:
            return value.encode('utf-8')
        return value


if is_py2:
    import __builtin__ as builtins
    from StringIO import StringIO

    def bytes(obj):
        if isinstance(obj, collections.Iterable):
            return ''.join(obj)
        return str(obj)

    str = unicode

elif is_py3:
    import builtins
    from io import StringIO

    bytes = bytes
    str = str

########NEW FILE########
__FILENAME__ = base
# -*- coding: utf-8 -*-

from ..asset_handler import BaseAssetHandler, ExecMixin


class BaseCompiler(BaseAssetHandler):
    """Base class for all asset compilers. Subclass's :meth:`__call__` method
    must change asset's :attr:`~gears.assets.Asset.processed_source` attribute.
    """

    #: MIME type of the asset source code after compiling.
    result_mimetype = None

    @classmethod
    def as_handler(cls, **initkwargs):
        handler = super(BaseCompiler, cls).as_handler(**initkwargs)
        handler.result_mimetype = cls.result_mimetype
        return handler


class ExecCompiler(BaseCompiler, ExecMixin):

    def __init__(self, executable=None, **kwargs):
        if executable is not None:
            self.executable = executable

    def __call__(self, asset):
        asset.processed_source = self.run(asset.processed_source)

########NEW FILE########
__FILENAME__ = base
# -*- coding: utf-8 -*-

from ..asset_handler import BaseAssetHandler, ExecMixin


class BaseCompressor(BaseAssetHandler):
    """Base class for all asset compressors. Subclass's :meth:`__call__` method
    must return compressed :attr:`~gears.assets.Asset.bundled_source` attribute.
    """


class ExecCompressor(BaseCompressor, ExecMixin):

    def __init__(self, executable=None):
        if executable is not None:
            self.executable = executable

    def __call__(self, asset):
        return self.run(asset.bundled_source)

########NEW FILE########
__FILENAME__ = cssmin
from __future__ import absolute_import

try:
    from cssmin import cssmin
    cssmin_available = True
except ImportError:
    cssmin_available = False

from .base import BaseCompressor
from ..exceptions import ImproperlyConfigured


class CSSMinCompressor(BaseCompressor):

    def __init__(self):
        if not cssmin_available:
            raise ImproperlyConfigured('cssmin is not available')

    def __call__(self, asset):
        return cssmin(asset.bundled_source)

########NEW FILE########
__FILENAME__ = slimit
from __future__ import absolute_import

try:
    from slimit import minify
    slimit_available = True
except ImportError:
    slimit_available = False

from .base import BaseCompressor
from ..exceptions import ImproperlyConfigured


class SlimItCompressor(BaseCompressor):

    def __init__(self):
        if not slimit_available:
            raise ImproperlyConfigured('Slimit is not available')

    def __call__(self, asset):
        return minify(asset.bundled_source, mangle=True)

########NEW FILE########
__FILENAME__ = directives_parser
import re


class DirectivesParser(object):

    header_re = re.compile(r"""
        ^( \s* (
            ( /\* .*? \*/ ) |  # multiline comment
            ( // [^\n]* )+ |   # slash comment
            ( \# [^\n]* )+     # dash comment
        ) )+
    """, re.S | re.X)

    directive_re = re.compile(r"""
        ^ \s* (?:\*|//|\#) \s* = \s* ( \w+ [=*?\[\]./'"\s\w-]* ) $
    """, re.X)

    def split_source(self, source):
        header_match = self.header_re.match(source)
        if not header_match:
            return '', source
        header = header_match.group(0)
        source = source[len(header):]
        return header, source

    def split_header(self, header):
        directives = []
        header_lines = []
        for line in header.splitlines():
            directive_match = self.directive_re.match(line)
            if directive_match:
                directives.append(directive_match.group(1))
            else:
                header_lines.append(line)
        return directives, '\n'.join(header_lines)

    def parse(self, source):
        header, source = self.split_source(source)
        directives, header = self.split_header(header)
        return directives, ''.join([header, source]).strip() + '\n'

########NEW FILE########
__FILENAME__ = environment
import gzip
import os
from pkg_resources import iter_entry_points
from glob2.fnmatch import fnmatch

from .asset_attributes import AssetAttributes
from .assets import build_asset
from .cache import SimpleCache
from .compat import bytes
from .exceptions import FileNotFound
from .manifest import Manifest
from .processors import (
    DirectivesProcessor,
    HexdigestPathsProcessor,
    SemicolonsProcessor
)
from .utils import get_condition_func, unique


DEFAULT_PUBLIC_ASSETS = (
    lambda path: not any(path.endswith(ext) for ext in ('.css', '.js')),
    r'^css/style\.css$',
    r'^js/script\.js$',
)


class Finders(list):
    """The registry for file finders. This is just a list of finder objects.
    Each finder object must be an instance of any
    :class:`~gears.finders.BaseFinder` subclass. Finders from this registry are
    used by :class:`~gears.environment.Environment` object in the order they
    were added.
    """

    def register(self, finder):
        """Append passed ``finder`` to the list of finders."""
        if finder not in self:
            self.append(finder)

    def unregister(self, finder):
        """Remove passed ``finder`` from the list of finders. If ``finder``
        does not found in the registry, nothing happens.
        """
        if finder in self:
            self.remove(finder)

    def list(self, path):
        for finder in self:
            for item in finder.list(path):
                yield item


class MIMETypes(dict):
    """The registry for MIME types. It acts like a dict with extensions as
    keys and MIME types as values. Every registered extension can have only one
    MIME type.
    """

    def register_defaults(self):
        """Register MIME types for ``.js`` and ``.css`` extensions."""
        self.register('.css', 'text/css')
        self.register('.js', 'application/javascript')

    def register(self, extension, mimetype):
        """Register passed ``mimetype`` MIME type with ``extension`` extension.
        """
        self[extension] = mimetype

    def unregister(self, extension):
        """Remove registered MIME type for passed ``extension`` extension. If
        MIME type for this extension does not found in the registry, nothing
        happens.
        """
        if extension in self:
            del self[extension]


class Compilers(dict):
    """The registry for compilers. It acts like a dict with extensions as keys
    and compilers as values. Every registered extension can have only one
    compiler.
    """

    def register(self, extension, compiler):
        """Register passed `compiler` with passed `extension`."""
        self[extension] = compiler

    def unregister(self, extension):
        """Remove registered compiler for passed `extension`. If compiler for
        this extension does not found in the registry, nothing happens.
        """
        if extension in self:
            del self[extension]


class Processors(dict):
    """Base class for processors registries."""

    def register(self, mimetype, processor):
        """Register passed `processor` for passed `mimetype`."""
        if mimetype not in self or processor not in self[mimetype]:
            self.setdefault(mimetype, []).append(processor)

    def unregister(self, mimetype, processor):
        """Remove passed `processor` for passed `mimetype`. If processor for
        this MIME type does not found in the registry, nothing happens.
        """
        if mimetype in self and processor in self[mimetype]:
            self[mimetype].remove(processor)

    def get(self, mimetype):
        """Return a list of processors, registered for passed `mimetype`. If
        no processors are registered for this MIME type, empty list is
        returned.
        """
        return super(Processors, self).get(mimetype, [])


class Preprocessors(Processors):
    """The registry for asset preprocessors. It acts like a dictionary with
    MIME types as keys and lists of processors as values. Every registered MIME
    type can have many preprocessors. Preprocessors for the MIME type are used
    in the order they were added.
    """

    def register_defaults(self):
        """Register :class:`~gears.processors.DirectivesProcessor` as
        a preprocessor for `text/css` and `application/javascript` MIME types.
        """
        self.register('text/css', DirectivesProcessor.as_handler())
        self.register('application/javascript', DirectivesProcessor.as_handler())


class Postprocessors(Processors):
    """The registry for asset postprocessors. It acts like a dictionary with
    MIME types as keys and lists of processors as values. Every registered MIME
    type can have many postprocessors. Postprocessors for the MIME type are
    used in the order they were added.
    """

    def register_defaults(self):
        self.register('application/javascript', SemicolonsProcessor.as_handler())
        self.register('text/css', HexdigestPathsProcessor.as_handler())


class Compressors(dict):
    """The registry for asset compressors. It acts like a dictionary with
    MIME types as keys and compressors as values. Every registered MIME type
    can have only one compressor.
    """

    def register(self, mimetype, compressor):
        """Register passed `compressor` for passed `mimetype`."""
        self[mimetype] = compressor

    def unregister(self, mimetype):
        """Remove registered compressors for passed `mimetype`. If compressor
        for this MIME type does not found in the registry, nothing happens.
        """
        if mimetype in self:
            del self[mimetype]


class Suffixes(list):
    """The registry for asset suffixes. It acts like a list of dictionaries.
    Every dictionary has three keys: ``extensions``, ``result_mimetype`` and
    ``mimetype``:

    - ``suffix`` is a suffix as a list of extensions (e.g. ``['.js', '.coffee']``);
    - ``result_mimetype`` is a MIME type of a compiled asset with this suffix;
    - ``mimetype`` is a MIME type, for which this suffix is registered.
    """

    def register(self, extension, root=False, to=None, mimetype=None):
        if root:
            self.append({
                'suffix': [extension],
                'full': [extension],
                'result_mimetype': mimetype,
                'mimetype': mimetype,
            })
            return
        new = []
        for item in self:
            if to is not None and item['mimetype'] != to:
                continue
            suffix = list(item['suffix'])
            suffix.append(extension)
            full = list(item['full'])
            full.append(extension)
            new.append({
                'suffix': suffix,
                'full': full,
                'result_mimetype': item['result_mimetype'],
                'mimetype': mimetype,
            })
            if to is not None:
                new.append({
                    'suffix': [extension],
                    'full': full,
                    'result_mimetype': item['result_mimetype'],
                    'mimetype': mimetype,
                })
        self.extend(new)

    def unregister(self, extension):
        for item in list(self):
            if extension in item['full']:
                self.remove(item)

    def find(self, mimetype=None):
        suffixes = []
        for item in self:
            if mimetype is None or item['result_mimetype'] == mimetype:
                suffixes.append(''.join(item['suffix']))
        return suffixes


class Environment(object):
    """This is the central object, that links all Gears parts. It is passed the
    absolute path to the directory where public assets will be saved.
    Environment contains registries for file finders, compilers, compressors,
    processors and supported MIME types.

    :param root: the absolute path to the directory where handled public assets
                 will be saved by :meth:`save` method.
    :param public_assets: a list of public assets paths.
    :param cache: a cache object. It is used by assets and dependencies to
                  store compilation results.
    :param fingerprinting: if set to `True`, fingerprinted versions of assets
                           won't be created.
    """

    def __init__(self, root, public_assets=DEFAULT_PUBLIC_ASSETS,
                 manifest_path=None, cache=None, gzip=False,
                 fingerprinting=True):
        self.root = root
        self.public_assets = [get_condition_func(c) for c in public_assets]

        if manifest_path is not None:
            self.manifest_path = manifest_path
        else:
            self.manifest_path = os.path.join(self.root, '.manifest.json')
        self.manifest = Manifest(self.manifest_path)

        if cache is not None:
            self.cache = cache
        else:
            self.cache = SimpleCache()

        self.gzip = gzip
        self.fingerprinting = fingerprinting

        #: The registry for file finders. See
        #: :class:`~gears.environment.Finders` for more information.
        self.finders = Finders()

        #: The registry for asset compilers. See
        #: :class:`~gears.environment.Compilers` for more information.
        self.compilers = Compilers()

        #: The registry for supported MIME types. See
        #: :class:`~gears.environment.MIMETypes` for more information.
        self.mimetypes = MIMETypes()

        #: The registry for asset compressors. See
        #: :class:`~gears.environment.Compressors` for more information.
        self.compressors = Compressors()

        #: The registry for asset preprocessors. See
        #: :class:`~gears.environment.Preprocessors` for more information.
        self.preprocessors = Preprocessors()

        #: The registry for asset postprocessors. See
        #: :class:`~gears.environment.Postprocessors` for more information.
        self.postprocessors = Postprocessors()

    @property
    def suffixes(self):
        """The registry for supported suffixes of assets. It is built from
        MIME types and compilers registries, and is cached at the first call.
        See :class:`~gears.environment.Suffixes` for more information.
        """
        if not hasattr(self, '_suffixes'):
            suffixes = Suffixes()
            for extension, mimetype in self.mimetypes.items():
                suffixes.register(extension, root=True, mimetype=mimetype)
            for extension, compiler in self.compilers.items():
                suffixes.register(extension, to=compiler.result_mimetype)
            self._suffixes = suffixes
        return self._suffixes

    @property
    def paths(self):
        """The list of search paths. It is built from registered finders, which
        has ``paths`` property. Can be useful for compilers to resolve internal
        dependencies.
        """
        if not hasattr(self, '_paths'):
            paths = []
            for finder in self.finders:
                if hasattr(finder, 'paths'):
                    paths.extend(finder.paths)
            self._paths = paths
        return self._paths

    def register_defaults(self):
        """Register default compilers, preprocessors and MIME types."""
        self.mimetypes.register_defaults()
        self.preprocessors.register_defaults()
        self.postprocessors.register_defaults()

    def register_entry_points(self, exclude=()):
        """Allow Gears plugins to inject themselves to the environment. For
        example, if your plugin's package contains such ``entry_points``
        definition in ``setup.py``, ``gears_plugin.register`` function will be
        called with current environment during ``register_entry_points`` call::

            entry_points = {
                'gears': [
                    'register = gears_plugin:register',
                ],
            }

        Here is an example of such function::

            def register(environment):
                assets_dir = os.path.join(os.path.dirname(__file__), 'assets')
                assets_dir = os.path.absolute_path(assets_dir)
                environment.register(FileSystemFinder([assets_dir]))

        If you want to disable this behavior for some plugins, list their
        packages using ``exclude`` argument::

            environment.register_entry_points(exclude=['plugin'])
        """
        for entry_point in iter_entry_points('gears', 'register'):
            if entry_point.module_name not in exclude:
                register = entry_point.load()
                register(self)

    def find(self, item, logical=False):
        """Find files using :attr:`finders` registry. The ``item`` parameter
        can be an instance of :class:`~gears.asset_attributes.AssetAttributes`
        class, a path to the asset or a logical path to the asset. If ``item``
        is a logical path, `logical` parameter must be set to ``True``.

        Returns a tuple with :class:`~gears.asset_attributes.AssetAttributes`
        instance for found file path as first item, and absolute path to this
        file as second item.

        If nothing is found, :class:`gears.exceptions.FileNotFound` exception
        is rased.
        """
        if isinstance(item, AssetAttributes):
            for path in item.search_paths:
                try:
                    return self.find(path, logical)
                except FileNotFound:
                    continue
            raise FileNotFound(item.path)
        if logical:
            asset_attributes = AssetAttributes(self, item)
            suffixes = self.suffixes.find(asset_attributes.mimetype)
            if not suffixes:
                return self.find(item)
            path = asset_attributes.path_without_suffix
            for suffix in suffixes:
                try:
                    return self.find(path + suffix)
                except FileNotFound:
                    continue
        else:
            for finder in self.finders:
                try:
                    absolute_path = finder.find(item)
                except FileNotFound:
                    continue
                return AssetAttributes(self, item), absolute_path
        raise FileNotFound(item)

    def list(self, path, mimetype=None):
        """Yield two-tuples for all files found in the directory given by
        ``path`` parameter. Result can be filtered by the second parameter,
        ``mimetype``, that must be a MIME type of assets compiled source code.
        Each tuple has :class:`~gears.asset_attributes.AssetAttributes`
        instance for found file path as first item, and absolute path to this
        file as second item.

        Usage example::

            # Yield all files from 'js/templates' directory.
            environment.list('js/templates/*')

            # Yield only files that are in 'js/templates' directory and have
            # 'application/javascript' MIME type of compiled source code.
            environment.list('js/templates/*', mimetype='application/javascript')
        """
        basename_pattern = os.path.basename(path)

        if path.endswith('**'):
            paths = [path]
        else:
            paths = AssetAttributes(self, path).search_paths
        paths = map(lambda p: p if p.endswith('*') else p + '*', paths)

        results = unique(self._list_paths(paths), lambda x: x[0])
        for logical_path, absolute_path in results:
            asset_attributes = AssetAttributes(self, logical_path)
            if mimetype is not None and asset_attributes.mimetype != mimetype:
                continue

            basename = os.path.basename(asset_attributes.path_without_suffix)
            if not fnmatch(basename, basename_pattern) and basename != 'index':
                continue

            yield asset_attributes, absolute_path

    def _list_paths(self, paths):
        for path in paths:
            for result in self.finders.list(path):
                yield result

    def save(self):
        """Save handled public assets to :attr:`root` directory."""
        for asset_attributes, absolute_path in self.list('**'):
            logical_path = os.path.normpath(asset_attributes.logical_path)
            check_asset = build_asset(self, logical_path, check=True)
            if check_asset.is_public:
                asset = build_asset(self, logical_path)
                source = bytes(asset)
                self.save_file(logical_path, source, asset.gzippable)
                if self.fingerprinting:
                    self.save_file(asset.hexdigest_path, source, asset.gzippable)
                    self.manifest.files[logical_path] = asset.hexdigest_path
        self.manifest.dump()

    def save_file(self, path, source, gzippable=False):
        filename = os.path.join(self.root, path)
        path = os.path.dirname(filename)
        if not os.path.exists(path):
            os.makedirs(path)
        elif not os.path.isdir(path):
            raise OSError("%s exists and is not a directory." % path)
        with open(filename, 'wb') as f:
            f.write(source)
        if self.gzip and gzippable:
            with gzip.open('{}.gz'.format(filename), 'wb') as f:
                f.write(source)

    def is_public(self, logical_path):
        return any(condition(logical_path) for condition in self.public_assets)

########NEW FILE########
__FILENAME__ = exceptions
class ImproperlyConfigured(Exception):
    pass


class FileNotFound(Exception):
    pass


class GearsUnicodeError(Exception):

    def __init__(self, path, msg):
        self.path = path
        self.msg = msg

    def __str__(self):
        return '%s: %s' % (self.path, self.msg)

########NEW FILE########
__FILENAME__ = finders
import os
import glob2
from .exceptions import ImproperlyConfigured, FileNotFound
from .utils import safe_join


class BaseFinder(object):

    def find(self, path):
        raise NotImplementedError()


class FileSystemFinder(BaseFinder):

    def __init__(self, directories):
        self.locations = []
        if not isinstance(directories, (list, tuple)):
            raise ImproperlyConfigured(
                "FileSystemFinder's 'directories' parameter is not a "
                "tuple or list; perhaps you forgot a trailing comma?")
        for directory in directories:
            if directory not in self.locations:
                self.locations.append(directory)

    @property
    def paths(self):
        return self.locations

    def find(self, path):
        for matched_path in self.find_all(path):
            return matched_path
        raise FileNotFound(path)

    def find_all(self, path):
        for root in self.locations:
            matched_path = self.find_location(root, path)
            if matched_path:
                yield matched_path

    def find_location(self, root, path):
        path = safe_join(root, path)
        if os.path.exists(path):
            return path

    def list(self, path):
        for root in self.locations:
            for absolute_path in glob2.iglob(safe_join(root, path)):
                if os.path.isfile(absolute_path):
                    logical_path = os.path.relpath(absolute_path, root)
                    yield logical_path, absolute_path

########NEW FILE########
__FILENAME__ = manifest
import os
import errno
import json


class Manifest(object):

    def __init__(self, path):
        self.path = path
        self.data = {}
        if self.path:
            self.load()

    @property
    def files(self):
        return self.data.setdefault('files', {})

    def load(self):
        try:
            with open(self.path) as f:
                self.data = json.load(f)
        except IOError as e:
            if e.errno != errno.ENOENT:
                raise

    def dump(self):
        if not self.path:
            return
        dirpath = os.path.dirname(self.path)
        if not os.path.exists(dirpath):
            os.makedirs(dirpath)
        with open(self.path, 'w') as f:
            json.dump(self.data, f, indent=2)

########NEW FILE########
__FILENAME__ = base
# -*- coding: utf-8 -*-

from ..asset_handler import BaseAssetHandler


class BaseProcessor(BaseAssetHandler):
    """Base class for all asset processors. Subclass's :meth:`__call__` method
    must change asset's :attr:`~gears.assets.Asset.processed_source` attribute.
    """

########NEW FILE########
__FILENAME__ = directives
import os
import shlex
import sys

from .base import BaseProcessor
from ..asset_attributes import AssetAttributes
from ..assets import Asset
from ..directives_parser import DirectivesParser
from ..exceptions import FileNotFound


class DirectivesProcessor(BaseProcessor):

    supports_check_mode = True

    def __init__(self):
        self.types = {
            'public': self.process_public_directive,
            'params': self.process_params_directive,
            'require': self.process_require_directive,
            'require_directory': self.process_require_directory_directive,
            'require_tree': self.process_require_tree_directive,
            'require_self': self.process_require_self_directive,
            'depend_on': self.process_depend_on_directive,
        }

    def __call__(self, asset, check=False):
        self.asset = asset
        self.check = check
        self.parse()
        self.process_directives()

    def parse(self):
        directives, source = DirectivesParser().parse(self.asset.processed_source)
        self.directives = directives
        self.asset.processed_source = source

    def process_directives(self):
        for directive in self.directives:
            # shlex didn't support Unicode prior to 2.7.3
            if sys.version_info < (2, 7, 3):
                directive = directive.encode('utf-8')
            args = shlex.split(directive)
            self.types[args[0]](*args[1:])

    def process_public_directive(self):
        self.asset.params['public'] = True

    def process_params_directive(self, *params):
        for param in params:
            if '=' in param:
                key, value = param.split('=', 1)
                self.asset.params[key] = value

    def process_require_directive(self, path):
        if self.check:
            return

        found = False
        path = self.get_relative_path(path)
        list = self.asset.attributes.environment.list(path, self.asset.attributes.mimetype)
        for asset_attributes, absolute_path in sorted(list, key=lambda x: x[0].path.split('/')):
            self.asset.requirements.add(self.get_asset(asset_attributes, absolute_path))
            self.asset.dependencies.add(os.path.dirname(absolute_path))
            found = True
        if not found:
            raise FileNotFound(path)

    def process_require_directory_directive(self, path):
        if self.check:
            return
        self.process_require_directive(os.path.join(path, '*'))

    def process_require_tree_directive(self, path):
        if self.check:
            return
        self.process_require_directive(os.path.join(path, '**'))

    def process_require_self_directive(self):
        if self.check:
            return
        self.asset.requirements.add(self.asset)

    def process_depend_on_directive(self, path):
        if self.check:
            return

        found = False
        path = self.get_relative_path(path)
        list = self.asset.attributes.environment.list(path, self.asset.attributes.mimetype)
        for asset_attributes, absolute_path in list:
            self.asset.dependencies.add(absolute_path)
            found = True
        if not found:
            raise FileNotFound(path)

    def get_relative_path(self, require_path, is_directory=False):
        require_path = os.path.join(self.asset.attributes.dirname, require_path)
        return os.path.normpath(require_path)

    def get_asset(self, asset_attributes, absolute_path):
        return Asset(asset_attributes, absolute_path, self.asset.calls)

########NEW FILE########
__FILENAME__ = hexdigest_paths
import os
import re
from ..assets import build_asset
from ..exceptions import FileNotFound
from .base import BaseProcessor
from ..compat import is_py3, is_py2


URL_RE = re.compile(r"""url\((['"]?)\s*(.*?)\s*\1\)""")


def rewrite_paths(source, func):
    repl = lambda match: 'url({quote}{path}{quote})'.format(
        quote=match.group(1),
        path=func(match.group(2)),
    )
    return URL_RE.sub(repl, source)


class HexdigestPathsProcessor(BaseProcessor):

    url_re = re.compile(r"""url\((['"]?)\s*(.*?)\s*\1\)""")

    def __call__(self, asset):
        self.asset = asset
        self.environment = self.asset.attributes.environment
        self.current_dir = self.asset.attributes.dirname
        self.process()

    def process(self):
        if self.environment.fingerprinting:
            self.asset.processed_source = rewrite_paths(
                self.asset.processed_source,
                self.rewrite_path,
            )

    def rewrite_path(self, path):
        logical_path = os.path.normpath(os.path.join(self.current_dir, path))
        try:
            asset = build_asset(self.environment, logical_path)
        except FileNotFound:
            return path
        self.asset.dependencies.add(asset.absolute_path)
        relpath = str(os.path.relpath(asset.hexdigest_path, self.current_dir))
        if is_py2:
            return relpath.encode('string-escape')
        elif is_py3:
            return relpath.encode('unicode-escape').decode()

########NEW FILE########
__FILENAME__ = semicolons
import re
from .base import BaseProcessor


BLANK_RE = re.compile(r'\A\s*\Z', re.M)
SEMICOLON_RE = re.compile(r';\s*\Z', re.M)


def needs_semicolon(source):
    return (BLANK_RE.search(source) is None and
            SEMICOLON_RE.search(source) is None)


class SemicolonsProcessor(BaseProcessor):

    def __call__(self, asset):
        if needs_semicolon(asset.processed_source):
            asset.processed_source += ';\n'

########NEW FILE########
__FILENAME__ = utils
import os
import re
from collections import Callable


missing = object()


class cached_property(object):

    def __init__(self, func):
        self.func = func
        self.__name__ = func.__name__
        self.__doc__ = func.__doc__
        self.__module__ = func.__module__

    def __get__(self, obj, type=None):
        if obj is None:
            return self
        value = obj.__dict__.get(self.__name__, missing)
        if value is missing:
            value = self.func(obj)
            obj.__dict__[self.__name__] = value
        return value


def safe_join(base, *paths):
    if not os.path.isabs(base):
        raise ValueError("%r is not an absolute path." % base)
    base = os.path.normpath(base)
    path = os.path.normpath(os.path.join(base, *paths))
    if not path.startswith(base):
        raise ValueError("Path %r is outside of %r" % (path, base))
    return path


def unique(iterable, key=lambda x: x):
    yielded = set()
    for item in iterable:
        keyitem = key(item)
        if keyitem not in yielded:
            yielded.add(keyitem)
            yield item


def get_condition_func(condition):
    if isinstance(condition, Callable):
        return condition
    if isinstance(condition, str):
        condition = re.compile(condition)
    return lambda path: condition.search(path)

########NEW FILE########
__FILENAME__ = helpers
import codecs
import os
import unittest2

from gears.asset_attributes import AssetAttributes
from gears.assets import Asset, StaticAsset
from gears.environment import Environment
from gears.finders import FileSystemFinder


TESTS_DIR = os.path.dirname(__file__)
FIXTURES_DIR = os.path.join(TESTS_DIR, 'fixtures')


def read(path, encoding='utf-8', mode='r'):
    with codecs.open(path, encoding=encoding, mode=mode) as file:
        return file.read()


class GearsTestCase(unittest2.TestCase):

    fixtures_root = None

    def get_fixture_path(self, fixture):
        return os.path.join(FIXTURES_DIR, self.fixtures_root, fixture)

    def find_fixture_file(self, fixture, name):
        fixture_path = self.get_fixture_path(fixture)
        for dirpath, dirnames, filenames in os.walk(fixture_path):
            for filename in filenames:
                if filename.split('.')[0] == name:
                    return os.path.join(dirpath, filename)
        return None

    def get_source_path(self, fixture):
        return self.find_fixture_file(fixture, 'source')

    def get_source(self, fixture):
        return read(self.get_source_path(fixture))

    def get_output(self, fixture, name='output'):
        return read(self.find_fixture_file(fixture, name))

    def get_finder(self, fixture):
        fixture_path = self.get_fixture_path(fixture)
        return FileSystemFinder([fixture_path])

    def get_environment(self, fixture):
        finder = self.get_finder(fixture)
        environment = Environment(os.path.join(TESTS_DIR, 'static'))
        environment.finders.register(finder)
        environment.register_defaults()
        return environment

    def get_asset(self, fixture, environment=None, asset_class=Asset):
        source_path = self.get_source_path(fixture)
        if environment is None:
            environment = self.get_environment(fixture)

        fixture_path = self.get_fixture_path(fixture)
        logical_path = os.path.relpath(source_path, fixture_path)
        asset_attributes = AssetAttributes(environment, logical_path)

        return asset_class(asset_attributes, source_path)

    def get_static_asset(self, fixture, environment=None):
        return self.get_asset(fixture, environment, asset_class=StaticAsset)

########NEW FILE########
__FILENAME__ = test_assets
from gears.assets import (
    CircularDependencyError, BaseAsset, Asset, StaticAsset, build_asset,
    strip_fingerprint
)
from gears.compat import str, bytes

from mock import sentinel, Mock
from unittest2 import TestCase
from .helpers import GearsTestCase


class AssetTests(GearsTestCase):

    fixtures_root = 'assets'

    def test_circular_dependency(self):
        with self.assertRaises(CircularDependencyError):
            asset = self.get_asset('circular_dependency')

    def test_unicode_support(self):
        asset = self.get_asset('unicode_support')
        output = self.get_output('unicode_support')
        self.assertEqual(str(asset), output)

    def test_is_iterable(self):
        asset = self.get_asset('unicode_support')
        tuple(asset)

    def test_is_convertible_to_bytes(self):
        asset = self.get_asset('unicode_support')
        bytes(asset)


class StaticAssetTests(GearsTestCase):

    fixtures_root = 'assets'

    def test_source(self):
        asset = self.get_static_asset('static_source')
        asset.source

    def test_hexdigest(self):
        asset = self.get_static_asset('static_source')
        self.assertEqual(
            asset.hexdigest,
            'c8a756475599e6e3c904b24077b4b0a31983752c',
        )

    def test_is_iterable(self):
        asset = self.get_static_asset('static_source')
        tuple(asset)

    def test_is_convertible_to_bytes(self):
        asset = self.get_static_asset('static_source')
        bytes(asset)


class HexdigestPathTests(TestCase):

    def get_asset(self, logical_path):
        attributes = Mock(logical_path=logical_path)
        asset = BaseAsset(attributes, sentinel.absolute_path)
        asset.final_hexdigest = '123456'
        return asset

    def test_hexdigest_path(self):
        def check(logical_path, result):
            asset = self.get_asset(logical_path)
            self.assertEqual(asset.hexdigest_path, result)

        check('css/style.css', 'css/style.123456.css')
        check('css/style.min.css', 'css/style.min.123456.css')


class BuildAssetTests(GearsTestCase):

    fixtures_root = 'assets'

    def setUp(self):
        self.environment = self.get_environment('build_asset')

    def test_has_processors(self):
        asset = build_asset(self.environment, 'source.js')
        self.assertIsInstance(asset, Asset)

    def test_has_no_processors(self):
        asset = build_asset(self.environment, 'source.md')
        self.assertIsInstance(asset, StaticAsset)

    def test_strips_fingerprint(self):
        path = 'source.38976434f000bf447d2dc6980894986aaf4e82d0.js'
        asset = build_asset(self.environment, path)
        self.assertEqual(asset.attributes.logical_path, 'source.js')


class StripFingerprintTests(TestCase):

    def test_strips_fingerprint(self):
        path = 'source.38976434f000bf447d2dc6980894986aaf4e82d0.js'
        self.assertEqual(strip_fingerprint(path), 'source.js')

    def test_skips_paths_without_fingerprint(self):
        self.assertEqual(strip_fingerprint('source.js'), 'source.js')

########NEW FILE########
__FILENAME__ = test_asset_attributes
from gears.asset_attributes import AssetAttributes
from gears.compilers import BaseCompiler
from gears.environment import Environment

from mock import Mock
from unittest2 import TestCase


class StylusCompiler(BaseCompiler):

    result_mimetype = 'text/css'

    def __call__(self, asset):
        pass


class CoffeeScriptCompiler(BaseCompiler):

    result_mimetype = 'application/javascript'

    def __call__(self, asset):
        pass


class TemplateCompiler(BaseCompiler):

    def __call__(self, asset):
        pass


class AssetAttributesTests(TestCase):

    def setUp(self):
        self.environment = Environment('assets')
        self.coffee_script_compiler = CoffeeScriptCompiler.as_handler()
        self.stylus_compiler = StylusCompiler.as_handler()
        self.template_compiler = TemplateCompiler.as_handler()

    def create_attributes(self, path):
        return AssetAttributes(self.environment, path)

    def test_extensions(self):

        def check(path, expected_result):
            extensions = self.create_attributes(path).extensions
            self.assertEqual(extensions, expected_result)

        check('js/readme', [])
        check('js/script.js', ['.js'])
        check('js/script.js.coffee', ['.js', '.coffee'])
        check('js/script.coffee', ['.coffee'])
        check('js/app.min.js.coffee', ['.min', '.js', '.coffee'])
        check('js/.htaccess', ['.htaccess'])

    def test_path_without_suffix(self):
        self.environment.mimetypes.register('.js', 'application/javascript')
        self.environment.compilers.register('.coffee', self.coffee_script_compiler)

        def check(path, expected_result):
            attributes = self.create_attributes(path)
            path_without_suffix = attributes.path_without_suffix
            self.assertEqual(path_without_suffix, expected_result)

        check('js/.htaccess', 'js/.htaccess')
        check('js/readme', 'js/readme')
        check('js/app.min.js.coffee', 'js/app.min')
        check('js/script.coffee', 'js/script')

        self.environment.mimetypes.register('.js', 'application/javascript')
        check('js/app.min.js.coffee', 'js/app.min')

    def test_logical_path(self):
        self.environment.mimetypes.register('.js', 'application/javascript')
        self.environment.compilers.register('.coffee', self.coffee_script_compiler)

        def check(path, expected_result):
            logical_path = self.create_attributes(path).logical_path
            self.assertEqual(logical_path, expected_result)

        check('js/script.js', 'js/script.js')
        check('js/script.js.coffee', 'js/script.js')
        check('js/script.coffee', 'js/script.js')
        check('js/script.min.js', 'js/script.min.js')
        check('js/script.min.js.coffee', 'js/script.min.js')
        check('images/logo.png', 'images/logo.png')
        check('file', 'file')

    def test_search_paths(self):
        self.environment.mimetypes.register('.js', 'application/javascript')

        def check(path, expected_result):
            search_paths = self.create_attributes(path).search_paths
            self.assertEqual(search_paths, expected_result)

        check('js/script.js', ['js/script.js', 'js/script/index.js'])
        check('js/app.min.js', ['js/app.min.js', 'js/app.min/index.js'])
        check('js/.htaccess', ['js/.htaccess', 'js/.htaccess/index'])
        check('js/index.js', ['js/index.js'])

    def test_format_extension(self):
        self.environment.mimetypes.register('.css', 'text/css')
        self.environment.mimetypes.register('.js', 'application/javascript')
        self.environment.compilers.register('.coffee', self.coffee_script_compiler)

        def check(path, expected_result):
            format_extension = self.create_attributes(path).format_extension
            self.assertEqual(format_extension, expected_result)

        check('js/script.js', '.js')
        check('js/script.js.coffee', '.js')
        check('js/jquery.min.js', '.js')
        check('js/app.js.min.coffee', '.js')
        check('css/style.js.css', '.css')
        check('js/script.coffee', None)
        check('readme', None)

    def test_suffix(self):
        self.environment.mimetypes.register('.css', 'text/css')
        self.environment.mimetypes.register('.js', 'application/javascript')
        self.environment.compilers.register('.coffee', self.coffee_script_compiler)

        def check(path, expected_result):
            suffix = self.create_attributes(path).suffix
            self.assertEqual(suffix, expected_result)

        check('js/script.js', ['.js'])
        check('js/script.js.coffee', ['.js', '.coffee'])
        check('js/script.coffee', ['.coffee'])
        check('js/script.min.js.coffee', ['.js', '.coffee'])
        check('js/script.js.min.coffee', ['.js', '.min', '.coffee'])
        check('readme', [])

    def test_compiler_extensions(self):
        self.environment.mimetypes.register('.css', 'text/css')
        self.environment.mimetypes.register('.js', 'application/javascript')
        self.environment.compilers.register('.coffee', self.coffee_script_compiler)
        self.environment.compilers.register('.tmpl', self.template_compiler)

        def check(path, expected_result):
            compiler_extensions = self.create_attributes(path).compiler_extensions
            self.assertEqual(compiler_extensions, expected_result)

        check('js/script.js', [])
        check('js/script.js.coffee', ['.coffee'])
        check('js/script.coffee', ['.coffee'])
        check('js/script.js.coffee.tmpl', ['.coffee', '.tmpl'])
        check('js/hot.coffee.js.tmpl', ['.tmpl'])

    def test_compiler_format_extension(self):
        self.environment.mimetypes.register('.css', 'text/css')
        self.environment.mimetypes.register('.js', 'application/javascript')
        self.environment.compilers.register('.coffee', self.coffee_script_compiler)
        self.environment.compilers.register('.styl', self.stylus_compiler)
        self.environment.compilers.register('.tmpl', self.template_compiler)

        def check(path, expected_result):
            format_extension = self.create_attributes(path).compiler_format_extension
            self.assertEqual(format_extension, expected_result)

        check('js/application.coffee', '.js')
        check('css/application.styl', '.css')
        check('application.tmpl', None)

    def test_compilers(self):
        self.environment.mimetypes.register('.css', 'text/css')
        self.environment.mimetypes.register('.js', 'application/javascript')
        self.environment.compilers.register('.coffee', self.coffee_script_compiler)
        self.environment.compilers.register('.tmpl', self.template_compiler)

        def check(path, expected_result):
            compilers = self.create_attributes(path).compilers
            self.assertEqual(compilers, expected_result)

        check('js/script.js', [])
        check('js/script.js.coffee', [self.coffee_script_compiler])
        check('js/script.coffee', [self.coffee_script_compiler])
        check('js/script.js.coffee.tmpl', [self.coffee_script_compiler, self.template_compiler])
        check('js/hot.coffee.js.tmpl', [self.template_compiler])

    def test_mimetype(self):
        self.environment.mimetypes.register('.css', 'text/css')
        self.environment.mimetypes.register('.js', 'application/javascript')
        self.environment.compilers.register('.coffee', self.coffee_script_compiler)
        self.environment.compilers.register('.styl', self.stylus_compiler)

        def check(path, expected_result):
            mimetype = self.create_attributes(path).mimetype
            self.assertEqual(mimetype, expected_result)

        check('js/script.js', 'application/javascript')
        check('js/script.js.coffee', 'application/javascript')
        check('js/script.coffee', 'application/javascript')
        check('css/style.min.css', 'text/css')
        check('readme.txt', 'application/octet-stream')

    def test_preprocessors(self):
        first_processor = Mock()
        second_processor = Mock()
        self.environment.mimetypes.register('.css', 'text/css')
        self.environment.mimetypes.register('.js', 'application/javascript')
        self.environment.compilers.register('.styl', self.stylus_compiler)
        self.environment.preprocessors.register('text/css', first_processor)
        self.environment.preprocessors.register('text/css', second_processor)

        def check(path, expected_result):
            preprocessors = self.create_attributes(path).preprocessors
            self.assertEqual(preprocessors, expected_result)

        check('readme.txt', [])
        check('js/script.js', [])
        check('css/style.css', [first_processor, second_processor])
        check('css/style.css.styl', [first_processor, second_processor])
        check('css/style.styl', [first_processor, second_processor])

    def test_postprocessors(self):
        first_processor = Mock()
        second_processor = Mock()
        self.environment.mimetypes.register('.css', 'text/css')
        self.environment.mimetypes.register('.js', 'application/javascript')
        self.environment.compilers.register('.styl', self.stylus_compiler)
        self.environment.postprocessors.register('text/css', first_processor)
        self.environment.postprocessors.register('text/css', second_processor)

        def check(path, expected_result):
            postprocessors = self.create_attributes(path).postprocessors
            self.assertEqual(postprocessors, expected_result)

        check('readme.txt', [])
        check('js/script.js', [])
        check('css/style.css', [first_processor, second_processor])
        check('css/style.css.styl', [first_processor, second_processor])
        check('css/style.styl', [first_processor, second_processor])

########NEW FILE########
__FILENAME__ = test_asset_dependencies
import os
from gears.assets import Dependencies
from .helpers import GearsTestCase


class AssetDependenciesTests(GearsTestCase):

    fixtures_root = 'asset_dependencies'

    def test_adds_dependency_only_once(self):
        fixture_file = self.find_fixture_file('adds_dependency_only_once', 'dependency')
        dependencies = Dependencies(self.get_environment('adds_dependency_only_once'))
        dependencies.add(fixture_file)
        dependencies.add(fixture_file)
        self.assertEqual(len(dependencies._registry), 1)

########NEW FILE########
__FILENAME__ = test_asset_dependency
import os
from gears.assets import Dependency
from .helpers import GearsTestCase


class AssetDependencyTests(GearsTestCase):

    fixtures_root = 'asset_dependency'

    def test_dependencies_with_the_same_path_are_equal(self):
        fixture = 'dependencies_with_the_same_path_are_equal'
        environment = self.get_environment(fixture)
        fixture_file = self.find_fixture_file(fixture, 'dependency')
        dependency1 = Dependency(environment, fixture_file)
        dependency2 = Dependency(environment, fixture_file)
        self.assertEqual(dependency1, dependency1)

    def test_handles_directories(self):
        fixture = 'handles_directories'
        fixture_path = self.get_fixture_path(fixture)
        environment = self.get_environment(fixture)
        Dependency(environment, os.path.join(fixture_path, 'libs'))

    def test_handles_binary_files(self):
        fixture = 'handles_binary_files'
        fixture_path = self.get_fixture_path(fixture)
        environment = self.get_environment(fixture)
        Dependency(environment, os.path.join(fixture_path, 'image.png'))

########NEW FILE########
__FILENAME__ = test_asset_requirements
from gears.assets import Requirements
from unittest2 import TestCase


class FakeAsset(object):

    def __init__(self):
        self.requirements = Requirements(self)


class AssetRequirementsTests(TestCase):

    def setUp(self):
        self.asset = FakeAsset()

        self.a = FakeAsset()
        self.b = FakeAsset()
        self.c = FakeAsset()
        self.d = FakeAsset()
        self.e = FakeAsset()

        self.asset.requirements.add(self.a)
        self.asset.requirements.add(self.b)
        self.asset.requirements.add(self.c)
        self.asset.requirements.add(self.asset)
        self.asset.requirements.add(self.d)
        self.asset.requirements.add(self.e)

    def test_firstly_adds_before(self):
        self.assertEqual(self.asset.requirements.before, [self.a, self.b, self.c])

    def test_adds_after_in_the_end(self):
        self.assertEqual(self.asset.requirements.after, [self.d, self.e])

########NEW FILE########
__FILENAME__ = test_directives_parser
import os
from gears.directives_parser import DirectivesParser
from unittest2 import TestCase
from .helpers import GearsTestCase


class DirectivesParserTests(GearsTestCase):

    fixtures_root = 'directives_parser'

    def check_asset(self, fixture, directives):
        source = self.get_source(fixture)
        output = self.get_output(fixture)
        result = DirectivesParser().parse(source)
        self.assertEqual(result[0], directives)
        self.assertEqual(result[1], output)

    def test_does_nothing_if_no_directives(self):
        self.check_asset('no_directives', [])

    def test_strips_whitespaces(self):
        self.check_asset('whitespaces', [])

    def test_multiline_comments(self):
        self.check_asset('multiline_comments', [
            'require reset',
            'require base',
        ])

    def test_handles_slash_comments(self):
        self.check_asset('slash_comments', [
            'require jquery',
            'require underscore'
        ])

    def test_handles_dash_comments(self):
        self.check_asset('dash_comments', [
            'require jquery',
            'require_tree .',
        ])

    def test_handle_multiple_comments(self):
        self.check_asset('multiple_comments', [
            'require jquery',
            'require underscore',
            'require backbone',
            'require models',
            'require collections',
            'require views',
        ])

    def test_skips_non_header_comments(self):
        self.check_asset('non_header_comments', ['require jquery'])


class DirectivesParserHeaderPatternTests(TestCase):

    def setUp(self):
        self.re = DirectivesParser().header_re

    def test_matches_multiline_comment(self):
        self.assertTrue(self.re.match('\n\n/*\nmultiline comment\n */'))

    def test_matches_multiple_miltiline_comments(self):
        self.assertTrue(self.re.match('/* comment */\n\n/* comment */'))

    def test_matches_slash_comment(self):
        self.assertTrue(self.re.match('  // this\n\n  // is\n  // comment'))

    def test_matches_dash_comment(self):
        self.assertTrue(self.re.match('  # this\n  \n  # is\n  # comment'))


class DirectivesParserDirectivePatternTests(TestCase):

    def setUp(self):
        self.re = DirectivesParser().directive_re

    def test_matches_directives(self):
        self.assertTrue(self.re.match(' *= require jquery'))
        self.assertTrue(self.re.match(' * =require jquery'))
        self.assertTrue(self.re.match('//= require jquery'))
        self.assertTrue(self.re.match(' #= require jquery'))

########NEW FILE########
__FILENAME__ = test_directives_processor
import os

from gears.compilers import BaseCompiler
from gears.processors import DirectivesProcessor

from .helpers import GearsTestCase


class FakeLessCompiler(BaseCompiler):

    result_mimetype = 'text/css'

    def __call__(self, asset):
        pass


class DirectivesProcessorTests(GearsTestCase):

    fixtures_root = 'directives_processor'

    def check_paths(self, assets, paths):
        self.assertEqual([asset.attributes.path for asset in assets], paths)

    def test_fills_asset_requirements(self):
        asset = self.get_asset('requirements')
        DirectivesProcessor.as_handler()(asset)
        self.check_paths(asset.requirements.before, ['js/external.js'])
        self.check_paths(asset.requirements.after, [
            'js/libs/simple_lib.js',
            'js/libs/useful_lib.js',
            'js/models.js',
            'js/views.js',
            'js/utils/a.js',
            'js/utils/b/a.js',
            'js/utils/b/b.js',
        ])

    def test_modifies_processed_source(self):
        asset = self.get_asset('requirements')
        DirectivesProcessor.as_handler()(asset)
        self.assertEqual(
            asset.processed_source,
            self.get_output('requirements'),
        )

    def test_modifies_bundled_source(self):
        asset = self.get_asset('requirements')
        DirectivesProcessor.as_handler()(asset)
        self.assertEqual(
            asset.bundled_source,
            self.get_output('requirements', 'bundle'),
        )

    def test_requires_asset_only_once(self):
        asset = self.get_asset('require_multiple_times')
        DirectivesProcessor.as_handler()(asset)
        self.check_paths(
            list(asset.requirements),
            'external.js models.js views.js source.js'.split(),
        )

    def test_depend_on_directive(self):
        environment = self.get_environment('depend_on')
        environment.compilers.register('.less', FakeLessCompiler.as_handler())
        asset = self.get_asset('depend_on', environment)
        DirectivesProcessor.as_handler()(asset)
        self.assertItemsEqual(asset.dependencies.to_list(), [
            os.path.join(os.path.dirname(asset.absolute_path), 'mixins/colors.less'),
        ])

########NEW FILE########
__FILENAME__ = test_environment
import os
import shutil
import sys
from contextlib import contextmanager

from gears.asset_attributes import AssetAttributes
from gears.compat import str
from gears.environment import Environment
from gears.exceptions import FileNotFound
from gears.finders import FileSystemFinder

from mock import Mock
from unittest2 import TestCase


ASSETS_DIR = os.path.abspath(os.path.join(os.path.dirname(__file__), 'assets'))
STATIC_DIR = os.path.abspath(os.path.join(os.path.dirname(__file__), 'static'))


class FakeCompiler(object):

    def __init__(self, result_mimetype):
        self.result_mimetype = result_mimetype


class FakeFinder(object):

    paths = (
        'js/script.js',
        'js/app/index.js',
        'js/models.js.coffee',
        'images/logo.png',
    )

    def find(self, path):
        if path in self.paths:
            return '/assets/' + path
        raise FileNotFound(path)


@contextmanager
def remove_static_dir():
    if os.path.exists(STATIC_DIR):
        shutil.rmtree(STATIC_DIR)
    yield
    if os.path.exists(STATIC_DIR):
        shutil.rmtree(STATIC_DIR)


class EnvironmentTests(TestCase):

    def setUp(self):
        self.environment = Environment(STATIC_DIR)

    def test_suffixes(self):
        self.environment.mimetypes.register('.css', 'text/css')
        self.environment.mimetypes.register('.txt', 'text/plain')
        self.environment.compilers.register('.styl', FakeCompiler('text/css'))
        self.assertItemsEqual(self.environment.suffixes.find(), [
            '.css', '.styl', '.css.styl', '.txt',
        ])

    def test_register_defaults(self):
        self.environment.mimetypes = Mock()
        self.environment.preprocessors = Mock()
        self.environment.register_defaults()
        self.environment.mimetypes.register_defaults.assert_called_once_with()
        self.environment.preprocessors.register_defaults.assert_called_once_with()


class EnvironmentFindTests(TestCase):

    def setUp(self):
        self.environment = Environment(STATIC_DIR)
        self.environment.register_defaults()
        self.environment.finders.register(FakeFinder())
        self.environment.compilers.register(
            '.coffee', FakeCompiler('application/javascript'))

    def check_asset_attributes(self, attrs, path):
        self.assertIsInstance(attrs, AssetAttributes)
        self.assertIs(attrs.environment, self.environment)
        self.assertEqual(attrs.path, path)

    def test_find_by_path(self):
        attrs, path = self.environment.find('js/models.js.coffee')
        self.check_asset_attributes(attrs, 'js/models.js.coffee')
        self.assertEqual(path, '/assets/js/models.js.coffee')

    def test_find_nothing_by_path(self):
        with self.assertRaises(FileNotFound):
            self.environment.find('js/models.js')

    def test_find_by_asset_attributes(self):
        attrs = AssetAttributes(self.environment, 'js/app.js')
        attrs, path = self.environment.find(attrs)
        self.check_asset_attributes(attrs, 'js/app/index.js')
        self.assertEqual(path, '/assets/js/app/index.js')

    def test_find_nothing_by_asset_attributes(self):
        attrs = AssetAttributes(self.environment, 'js/models.js')
        with self.assertRaises(FileNotFound):
            self.environment.find(attrs)

    def test_find_by_logical_path(self):
        attrs, path = self.environment.find('js/models.js', logical=True)
        self.check_asset_attributes(attrs, 'js/models.js.coffee')
        self.assertEqual(path, '/assets/js/models.js.coffee')

    def test_find_by_logical_path_with_unrecognized_extension(self):
        attrs, path = self.environment.find('images/logo.png', logical=True)
        self.check_asset_attributes(attrs, 'images/logo.png')
        self.assertEqual(path, '/assets/images/logo.png')

    def test_find_nothing_by_logical_path(self):
        with self.assertRaises(FileNotFound):
            self.environment.find('js/views.js', logical=True)

    def test_save_file(self):
        source = str('hello world').encode('utf-8')
        with remove_static_dir():
            self.environment.save_file('js/script.js', source)
            with open(os.path.join(STATIC_DIR, 'js', 'script.js'), 'rb') as f:
                self.assertEqual(f.read(), source)


class EnvironmentListTests(TestCase):

    def setUp(self):
        self.environment = Environment(STATIC_DIR)
        self.environment.register_defaults()
        self.environment.finders.register(FileSystemFinder([ASSETS_DIR]))

    def test_list(self):
        items = list(self.environment.list('js/templates/*', 'application/javascript'))
        self.assertEqual(len(items), 3)
        for i, item in enumerate(sorted(items, key=lambda x: x[1])):
            path = 'js/templates/%s.js.handlebars' % 'abc'[i]
            asset_attributes, absolute_path = item
            self.assertIsInstance(asset_attributes, AssetAttributes)
            self.assertEqual(asset_attributes.path, path)
            self.assertEqual(absolute_path, os.path.join(ASSETS_DIR, path))

    def test_list_recursively(self):
        items = list(self.environment.list('js/templates/**', 'application/javascript'))
        self.assertEqual(len(items), 4)
        for i, item in enumerate(sorted(items, key=lambda x: x[1])):
            path = 'js/templates/%s.js.handlebars' % ('a', 'b', 'c', 'd/e')[i]
            asset_attributes, absolute_path = item
            self.assertIsInstance(asset_attributes, AssetAttributes)
            self.assertEqual(asset_attributes.path, path)
            self.assertEqual(absolute_path, os.path.join(ASSETS_DIR, path))

########NEW FILE########
__FILENAME__ = test_environment_engines
from gears.environment import Compilers

from mock import Mock
from unittest2 import TestCase


class CompilersTests(TestCase):

    def setUp(self):
        self.compilers = Compilers()
        self.first_compiler = Mock()
        self.second_compiler = Mock()

    def test_register(self):
        self.compilers.register('.css', self.first_compiler)
        self.assertIn('.css', self.compilers)
        self.assertIs(self.compilers['.css'], self.first_compiler)

    def test_register_twice(self):
        self.compilers.register('.css', self.first_compiler)
        self.compilers.register('.css', self.second_compiler)
        self.assertIs(self.compilers['.css'], self.second_compiler)

    def test_unregister(self):
        self.compilers.register('.css', self.first_compiler)
        self.compilers.unregister('.css')
        self.assertNotIn('.css', self.compilers)

    def test_unregister_if_does_not_exist(self):
        self.compilers.unregister('.css')

########NEW FILE########
__FILENAME__ = test_environment_finders
from gears.environment import Finders
from mock import Mock
from unittest2 import TestCase


class FindersTests(TestCase):

    def setUp(self):
        self.finders = Finders()
        self.first_finder = Mock()
        self.second_finder = Mock()

    def test_register(self):
        self.finders.register(self.first_finder)
        self.finders.register(self.second_finder)
        self.assertEqual(self.finders, [self.first_finder, self.second_finder])

    def test_register_twice(self):
        self.finders.register(self.first_finder)
        self.finders.register(self.first_finder)
        self.assertEqual(self.finders, [self.first_finder])

    def test_unregister(self):
        self.finders.register(self.first_finder)
        self.finders.unregister(self.first_finder)
        self.assertEqual(self.finders, [])

########NEW FILE########
__FILENAME__ = test_environment_mimetypes
from gears.environment import MIMETypes
from unittest2 import TestCase


class MIMETypesTests(TestCase):

    def setUp(self):
        self.mimetypes = MIMETypes()
        self.mimetypes.register_defaults()

    def test_register(self):
        self.mimetypes.register('.txt', 'text/plain')
        self.assertIn('.txt', self.mimetypes)
        self.assertEqual(self.mimetypes['.txt'], 'text/plain')

    def test_unregister(self):
        self.assertIn('.css', self.mimetypes)
        self.mimetypes.unregister('.css')
        self.assertNotIn('.css', self.mimetypes)

    def test_get_if_exists(self):
        self.assertEqual(self.mimetypes.get('.css'), 'text/css')

    def test_get_if_does_not_exist(self):
        self.assertIsNone(self.mimetypes.get('.txt'))

########NEW FILE########
__FILENAME__ = test_environment_processors
from gears.environment import Processors, Preprocessors
from gears.processors import DirectivesProcessor

from mock import Mock
from unittest2 import TestCase


class ProcessorsTests(TestCase):

    def setUp(self):
        self.processors = Processors()
        self.first_processor = Mock()
        self.second_processor = Mock()
        self.third_processor = Mock()

    def test_register(self):
        self.processors.register('text/css', self.first_processor)
        self.processors.register('text/css', self.second_processor)
        self.processors.register('text/plain', self.third_processor)
        self.assertIn('text/css', self.processors)
        self.assertEqual(self.processors['text/css'], [self.first_processor, self.second_processor])
        self.assertIn('text/plain', self.processors)
        self.assertEqual(self.processors['text/plain'], [self.third_processor])

    def test_register_twice(self):
        self.processors.register('text/css', self.first_processor)
        self.processors.register('text/css', self.first_processor)
        self.assertEqual(self.processors['text/css'], [self.first_processor])

    def test_unregister(self):
        self.processors.register('text/css', self.first_processor)
        self.processors.register('text/css', self.second_processor)
        self.processors.unregister('text/css', self.first_processor)
        self.assertEqual(self.processors['text/css'], [self.second_processor])

    def test_unregister_if_does_not_exist(self):
        self.processors.unregister('text/css', self.first_processor)

    def test_get_if_exists(self):
        self.processors.register('text/css', self.first_processor)
        self.processors.register('text/css', self.second_processor)
        self.assertEqual(self.processors.get('text/css'), [self.first_processor, self.second_processor])

    def test_get_if_does_not_exist(self):
        self.assertEqual(self.processors.get('text/css'), [])


class PreprocessorsTests(TestCase):

    def setUp(self):
        self.preprocessors = Preprocessors()

    def test_register_defaults(self):
        self.preprocessors.register_defaults()
        self.assertItemsEqual(self.preprocessors.keys(), ['text/css', 'application/javascript'])
        self.assertEqual(
            [p.handler_class for p in self.preprocessors['text/css']],
            [DirectivesProcessor])
        self.assertEqual(
            [p.handler_class for p in self.preprocessors['application/javascript']],
            [DirectivesProcessor])

########NEW FILE########
__FILENAME__ = test_environment_suffixes
from gears.environment import Suffixes
from unittest2 import TestCase


class SuffixesTests(TestCase):

    def setUp(self):
        self.suffixes = Suffixes()
        self.suffixes.register('.css', root=True, mimetype='text/css')
        self.suffixes.register('.txt', root=True, mimetype='text/plain')

    def test_register_root_suffix(self):
        self.assertItemsEqual(self.suffixes, [{
            'suffix': ['.css'],
            'full': ['.css'],
            'result_mimetype': 'text/css',
            'mimetype': 'text/css',
        }, {
            'suffix': ['.txt'],
            'full': ['.txt'],
            'result_mimetype': 'text/plain',
            'mimetype': 'text/plain',
        }])

    def test_register_extension_to_mimetype(self):
        self.suffixes.register('.styl', to='text/css')
        self.assertItemsEqual(self.suffixes, [{
            'suffix': ['.css'],
            'full': ['.css'],
            'result_mimetype': 'text/css',
            'mimetype': 'text/css',
        }, {
            'suffix': ['.txt'],
            'full': ['.txt'],
            'result_mimetype': 'text/plain',
            'mimetype': 'text/plain',
        }, {
            'suffix': ['.styl'],
            'full': ['.css', '.styl'],
            'result_mimetype': 'text/css',
            'mimetype': None,
        }, {
            'suffix': ['.css', '.styl'],
            'full': ['.css', '.styl'],
            'result_mimetype': 'text/css',
            'mimetype': None,
        }])

    def test_register_extension_to_none(self):
        self.suffixes.register('.styl', to='text/css')
        self.suffixes.register('.tmpl')
        self.assertItemsEqual(self.suffixes, [{
            'suffix': ['.css'],
            'full': ['.css'],
            'result_mimetype': 'text/css',
            'mimetype': 'text/css',
        }, {
            'suffix': ['.txt'],
            'full': ['.txt'],
            'result_mimetype': 'text/plain',
            'mimetype': 'text/plain',
        }, {
            'suffix': ['.styl'],
            'full': ['.css', '.styl'],
            'result_mimetype': 'text/css',
            'mimetype': None,
        }, {
            'suffix': ['.css', '.styl'],
            'full': ['.css', '.styl'],
            'result_mimetype': 'text/css',
            'mimetype': None,
        }, {
            'suffix': ['.css', '.tmpl'],
            'full': ['.css', '.tmpl'],
            'result_mimetype': 'text/css',
            'mimetype': None,
        }, {
            'suffix': ['.txt', '.tmpl'],
            'full': ['.txt', '.tmpl'],
            'result_mimetype': 'text/plain',
            'mimetype': None,
        }, {
            'suffix': ['.styl', '.tmpl'],
            'full': ['.css', '.styl', '.tmpl'],
            'result_mimetype': 'text/css',
            'mimetype': None,
        }, {
            'suffix': ['.css', '.styl', '.tmpl'],
            'full': ['.css', '.styl', '.tmpl'],
            'result_mimetype': 'text/css',
            'mimetype': None,
        }])

    def test_unregister_extension(self):
        self.suffixes.register('.styl', to='text/css')
        self.suffixes.register('.tmpl')
        self.suffixes.unregister('.css')
        self.assertItemsEqual(self.suffixes, [{
            'suffix': ['.txt'],
            'full': ['.txt'],
            'result_mimetype': 'text/plain',
            'mimetype': 'text/plain',
        }, {
            'suffix': ['.txt', '.tmpl'],
            'full': ['.txt', '.tmpl'],
            'result_mimetype': 'text/plain',
            'mimetype': None,
        }])

    def test_find_all(self):
        self.suffixes.register('.styl', to='text/css')
        self.assertItemsEqual(self.suffixes.find(), ['.css', '.txt', '.styl', '.css.styl'])

    def test_find_by_mimetype(self):
        self.suffixes.register('.styl', to='text/css')
        self.assertItemsEqual(self.suffixes.find('text/css'), ['.css', '.styl', '.css.styl'])
        self.assertItemsEqual(self.suffixes.find('text/plain'), ['.txt'])

    def test_find_nothing(self):
        self.assertItemsEqual(self.suffixes.find('application/javascript'), [])

########NEW FILE########
__FILENAME__ = test_exec_mixin
from gears.asset_handler import AssetHandlerError, ExecMixin
from mock import patch, Mock
from unittest2 import TestCase


class Exec(ExecMixin):
    executable = 'program'


class ExecMixinTests(TestCase):

    @patch('gears.asset_handler.Popen')
    def test_returns_stdout_on_success(self, Popen):
        result = Mock()
        result.returncode = 0
        result.communicate.return_value = (b'output', b'')
        Popen.return_value = result
        self.assertEqual(Exec().run('input'), 'output')

    @patch('gears.asset_handler.Popen')
    def test_raises_stderr_on_failure(self, Popen):
        result = Mock()
        result.returncode = 1
        result.communicate.return_value = (b'', b'error')
        Popen.return_value = result
        with self.assertRaises(AssetHandlerError):
            Exec().run('input')

########NEW FILE########
__FILENAME__ = test_file_based_cache
import tempfile
import shutil
from gears.cache import FileBasedCache
from unittest2 import TestCase


class FileBasedCacheTests(TestCase):

    def setUp(self):
        self.root = tempfile.mkdtemp()
        self.cache = FileBasedCache(self.root)

    def tearDown(self):
        shutil.rmtree(self.root)

    def test_saves_value_for_key(self):
        self.cache.set('a', 1)
        self.assertEqual(self.cache.get('a'), 1)

    def test_returns_none_if_key_not_found(self):
        self.assertIsNone(self.cache.get('a'))

########NEW FILE########
__FILENAME__ = test_file_system_finder
import os

from gears.exceptions import ImproperlyConfigured, FileNotFound
from gears.finders import FileSystemFinder

from mock import patch, Mock
from unittest2 import TestCase


ASSETS_DIR = os.path.abspath(os.path.join(os.path.dirname(__file__), 'assets'))


class FileSystemFinderTests(TestCase):

    def test_initialization(self):
        finder = FileSystemFinder(('/first', '/second', '/third', '/first'))
        self.assertEqual(finder.locations, ['/first', '/second', '/third'])

    def test_if_directories_is_not_iterable(self):
        with self.assertRaises(ImproperlyConfigured):
            finder = FileSystemFinder('/first')

    @patch('os.path.exists')
    def test_find_location_if_exists(self, exists):
        exists.return_value = True
        finder = FileSystemFinder(('/assets',))
        location = finder.find_location('/assets', 'js/script.js')
        self.assertEqual(location, '/assets/js/script.js')
        exists.assert_called_once_with('/assets/js/script.js')

    @patch('os.path.exists')
    def test_find_location_if_does_not_exist(self, exists):
        exists.return_value = False
        finder = FileSystemFinder(('/assets',))
        self.assertIsNone(finder.find_location('/assets', 'js/script.js'))
        exists.assert_called_once_with('/assets/js/script.js')

    def test_find_if_exists(self):
        finder = FileSystemFinder(('/first', '/second', '/third'))
        finder.find_all = Mock(return_value=(
            '/second/js/script.js', '/third/js/script.js'))
        self.assertEqual(finder.find('js/script.js'), '/second/js/script.js')
        finder.find_all.assert_called_once_with('js/script.js')

    def test_find_if_does_not_exist(self):
        finder = FileSystemFinder(('/first', '/second', '/third'))
        finder.find_all = Mock(return_value=())
        with self.assertRaises(FileNotFound):
            finder.find('js/script.js')
        finder.find_all.assert_called_once_with('js/script.js')

    def test_find_all_if_exists(self):

        def find_location(root, path):
            if root != '/first':
                return os.path.join(root, path)

        finder = FileSystemFinder(('/first', '/second', '/third'))
        finder.find_location = Mock(side_effect=find_location)

        paths = list(finder.find_all('js/script.js'))
        self.assertEqual(paths, ['/second/js/script.js', '/third/js/script.js'])
        self.assertEqual(finder.find_location.call_args_list, [
            (('/first', 'js/script.js'), {}),
            (('/second', 'js/script.js'), {}),
            (('/third', 'js/script.js'), {})])

    def test_find_all_if_does_not_exist(self):
        finder = FileSystemFinder(('/first', '/second', '/third'))
        finder.find_location = Mock(return_value=False)

        self.assertEqual(list(finder.find_all('js/script.js')), [])
        self.assertEqual(finder.find_location.call_args_list, [
            (('/first', 'js/script.js'), {}),
            (('/second', 'js/script.js'), {}),
            (('/third', 'js/script.js'), {})])

    def test_list(self):
        finder = FileSystemFinder([ASSETS_DIR])
        self.assertItemsEqual(finder.list('js/templates/*'), (
            ('js/templates/readme.txt', os.path.join(ASSETS_DIR, 'js/templates/readme.txt')),
            ('js/templates/a.js.handlebars', os.path.join(ASSETS_DIR, 'js/templates/a.js.handlebars')),
            ('js/templates/b.js.handlebars', os.path.join(ASSETS_DIR, 'js/templates/b.js.handlebars')),
            ('js/templates/c.js.handlebars', os.path.join(ASSETS_DIR, 'js/templates/c.js.handlebars')),
        ))

    def test_list_empty_if_path_doesnt_exist(self):
        finder = FileSystemFinder([ASSETS_DIR])
        self.assertItemsEqual(finder.list('js/views/*'), ())

    def test_list_recursively(self):
        finder = FileSystemFinder([ASSETS_DIR])
        self.assertItemsEqual(finder.list('js/templates/**'), (
            ('js/templates/readme.txt', os.path.join(ASSETS_DIR, 'js/templates/readme.txt')),
            ('js/templates/a.js.handlebars', os.path.join(ASSETS_DIR, 'js/templates/a.js.handlebars')),
            ('js/templates/b.js.handlebars', os.path.join(ASSETS_DIR, 'js/templates/b.js.handlebars')),
            ('js/templates/c.js.handlebars', os.path.join(ASSETS_DIR, 'js/templates/c.js.handlebars')),
            ('js/templates/d/e.js.handlebars', os.path.join(ASSETS_DIR, 'js/templates/d/e.js.handlebars')),
        ))

########NEW FILE########
__FILENAME__ = test_hexdigest_paths_processor
from unittest2 import TestCase

from gears.compat import str
from gears.processors.hexdigest_paths import rewrite_paths

from .helpers import GearsTestCase


class RewritePathsTests(TestCase):

    def check(self, source, expected_result):
        result = rewrite_paths(source, lambda path: 'new/path')
        self.assertEqual(result, expected_result)

    def test_single_quotes(self):
        self.check("url('../images/logo.png')", "url('new/path')")

    def test_double_quotes(self):
        self.check('url("../images/logo.png")', 'url("new/path")')

    def test_without_quotes(self):
        self.check('url(../images/logo.png)', 'url(new/path)')


class HexdigestPathsProcessorTests(GearsTestCase):

    fixtures_root = 'hexdigest_paths_processor'

    def test_process(self):
        asset = self.get_asset('process')
        output = self.get_output('process')
        self.assertEqual(str(asset), output)

########NEW FILE########
__FILENAME__ = test_manifest
import errno
import mock

from gears.compat import StringIO
from gears.manifest import Manifest

from unittest2 import TestCase


@mock.patch('gears.compat.builtins.open')
class ManifestTests(TestCase):

    def test_loads_data(self, open):
        open.return_value.__enter__.return_value = StringIO("""{
            "files": {
                "css/style.css": "css/style.123456.css",
                "js/script.js": "js/script.654321.js"
            }
        }""")
        manifest = Manifest('manifest.json')
        self.assertEqual(manifest.files, {
            'css/style.css': 'css/style.123456.css',
            'js/script.js': 'js/script.654321.js',
        })

    def test_fails_silently_if_file_not_found(self, open):
        open.side_effect = IOError(errno.ENOENT, 'No such file or directory')
        manifest = Manifest('manifest.json')

########NEW FILE########
__FILENAME__ = test_semicolons_processor
from unittest2 import TestCase

from gears.compat import str
from gears.processors.semicolons import needs_semicolon

from .helpers import GearsTestCase


class NeedsSemicolonsTests(TestCase):

    def test_blank_source(self):
        self.assertFalse(needs_semicolon(' \t\n'))

    def test_source_with_semicolon(self):
        self.assertFalse(needs_semicolon('x;\n '))

    def test_source_without_semicolon(self):
        self.assertTrue(needs_semicolon('x\n'))


class SemicolonsProcessorTests(GearsTestCase):

    fixtures_root = 'semicolons_processor'

    def test_process(self):
        asset = self.get_asset('process')
        output = self.get_output('process')
        self.assertEqual(str(asset), output)

########NEW FILE########
__FILENAME__ = test_utils
from gears.utils import safe_join
from unittest2 import TestCase


class SafeJoinTests(TestCase):

    def test_if_base_is_not_absolute(self):
        with self.assertRaisesRegexp(ValueError, 'is not an absolute path'):
            safe_join('assets', 'js/script.js')

    def test_if_path_is_outside_of_base(self):
        with self.assertRaisesRegexp(ValueError, 'is outside of'):
            safe_join('/assets', '../js/script.js')

    def test_success(self):
        path = safe_join('/assets', 'js/script.js')
        self.assertEqual(path, '/assets/js/script.js')

########NEW FILE########
