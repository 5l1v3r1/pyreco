__FILENAME__ = conf
# -*- coding: utf-8 -*-
#
# Gruvi documentation build configuration file, created by
# sphinx-quickstart on Sat Apr 20 14:21:55 2013.
#
# This file is execfile()d with the current directory set to its containing dir.
#
# Note that not all possible configuration values are present in this
# autogenerated file.
#
# All configuration values have a default; values that are commented out
# serve to show the default.

import sys, os

# If extensions (or modules to document with autodoc) are in another directory,
# add these directories to sys.path here. If the directory is relative to the
# documentation root, use os.path.abspath to make it absolute, like shown here.
sys.path.insert(0, os.path.abspath('..'))

# Naming conflict with sphinx.
import setup as gruvi_setup

# Allow code to detect if it's running under sphinx
sys.running_under_sphinx = True

# -- General configuration -----------------------------------------------------

# If your documentation needs a minimal Sphinx version, state it here.
#needs_sphinx = '1.0'

# Add any Sphinx extension module names here, as strings. They can be extensions
# coming with Sphinx (named 'sphinx.ext.*') or your custom ones.
extensions = ['sphinx.ext.autodoc', 'sphinx.ext.intersphinx']

# Add any paths that contain templates here, relative to this directory.
templates_path = ['_templates']

# The suffix of source filenames.
source_suffix = '.rst'

# The encoding of source files.
#source_encoding = 'utf-8-sig'

# The master toctree document.
master_doc = 'index'

# General information about the project.
project = u'Gruvi'
copyright = u'2012-2013, Geert Jansen'

# The version info for the project you're documenting, acts as replacement for
# |version| and |release|, also used in various other places throughout the
# built documents.
#
# The short X.Y version.
version = gruvi_setup.version_info['version']
# The full version, including alpha/beta/rc tags.
release = version

# The language for content autogenerated by Sphinx. Refer to documentation
# for a list of supported languages.
#language = None

# There are two options for replacing |today|: either, you set today to some
# non-false value, then it is used:
#today = ''
# Else, today_fmt is used as the format for a strftime call.
#today_fmt = '%B %d, %Y'

# List of patterns, relative to source directory, that match files and
# directories to ignore when looking for source files.
exclude_patterns = ['_build']

# The reST default role (used for this markup: `text`) to use for all documents.
#default_role = None

# If true, '()' will be appended to :func: etc. cross-reference text.
#add_function_parentheses = True

# If true, the current module name will be prepended to all description
# unit titles (such as .. function::).
#add_module_names = True

# If true, sectionauthor and moduleauthor directives will be shown in the
# output. They are ignored by default.
#show_authors = False

# The name of the Pygments (syntax highlighting) style to use.
pygments_style = 'sphinx'

# A list of ignored prefixes for module index sorting.
#modindex_common_prefix = []


# -- Options for HTML output ---------------------------------------------------

# The theme to use for HTML and HTML Help pages.  See the documentation for
# a list of builtin themes.
html_theme = 'pyramid'

# Theme options are theme-specific and customize the look and feel of a theme
# further.  For a list of options available for each theme, see the
# documentation.
#html_theme_options = {}

# Add any paths that contain custom themes here, relative to this directory.
#html_theme_path = []

# The name for this set of Sphinx documents.  If None, it defaults to
# "<project> v<release> documentation".
#html_title = None

# A shorter title for the navigation bar.  Default is the same as html_title.
#html_short_title = None

# The name of an image file (relative to this directory) to place at the top
# of the sidebar.
#html_logo = None

# The name of an image file (within the static path) to use as favicon of the
# docs.  This file should be a Windows icon file (.ico) being 16x16 or 32x32
# pixels large.
#html_favicon = None

# Add any paths that contain custom static files (such as style sheets) here,
# relative to this directory. They are copied after the builtin static files,
# so a file named "default.css" will overwrite the builtin "default.css".
html_static_path = ['_static']

# If not '', a 'Last updated on:' timestamp is inserted at every page bottom,
# using the given strftime format.
#html_last_updated_fmt = '%b %d, %Y'

# If true, SmartyPants will be used to convert quotes and dashes to
# typographically correct entities.
#html_use_smartypants = True

# Custom sidebar templates, maps document names to template names.
#html_sidebars = {}

# Additional templates that should be rendered to pages, maps page names to
# template names.
#html_additional_pages = {}

# If false, no module index is generated.
#html_domain_indices = True

# If false, no index is generated.
#html_use_index = True

# If true, the index is split into individual pages for each letter.
#html_split_index = False

# If true, links to the reST sources are added to the pages.
#html_show_sourcelink = True

# If true, "Created using Sphinx" is shown in the HTML footer. Default is True.
#html_show_sphinx = True

# If true, "(C) Copyright ..." is shown in the HTML footer. Default is True.
#html_show_copyright = True

# If true, an OpenSearch description file will be output, and all pages will
# contain a <link> tag referring to it.  The value of this option must be the
# base URL from which the finished HTML is served.
#html_use_opensearch = ''

# This is the file name suffix for HTML files (e.g. ".xhtml").
#html_file_suffix = None

# Output file base name for HTML help builder.
htmlhelp_basename = 'Gruvidoc'


# -- Options for LaTeX output --------------------------------------------------

latex_elements = {
# The paper size ('letterpaper' or 'a4paper').
#'papersize': 'letterpaper',

# The font size ('10pt', '11pt' or '12pt').
#'pointsize': '10pt',

# Additional stuff for the LaTeX preamble.
#'preamble': '',
}

# Grouping the document tree into LaTeX files. List of tuples
# (source start file, target name, title, author, documentclass [howto/manual]).
latex_documents = [
  ('index', 'Gruvi.tex', u'Gruvi Documentation',
   u'Geert Jansen', 'manual'),
]

# The name of an image file (relative to this directory) to place at the top of
# the title page.
#latex_logo = None

# For "manual" documents, if this is true, then toplevel headings are parts,
# not chapters.
#latex_use_parts = False

# If true, show page references after internal links.
#latex_show_pagerefs = False

# If true, show URL addresses after external links.
#latex_show_urls = False

# Documents to append as an appendix to all manuals.
#latex_appendices = []

# If false, no module index is generated.
#latex_domain_indices = True


# -- Options for manual page output --------------------------------------------

# One entry per manual page. List of tuples
# (source start file, name, description, authors, manual section).
man_pages = [
    ('index', 'gruvi', u'Gruvi Documentation',
     [u'Geert Jansen'], 1)
]

# If true, show URL addresses after external links.
#man_show_urls = False


# -- Options for Texinfo output ------------------------------------------------

# Grouping the document tree into Texinfo files. List of tuples
# (source start file, target name, title, author,
#  dir menu entry, description, category)
texinfo_documents = [
  ('index', 'Gruvi', u'Gruvi Documentation',
   u'Geert Jansen', 'Gruvi', 'One line description of project.',
   'Miscellaneous'),
]

# Documents to append as an appendix to all manuals.
#texinfo_appendices = []

# If false, no module index is generated.
#texinfo_domain_indices = True

# How to display URL addresses: 'footnote', 'no', or 'inline'.
#texinfo_show_urls = 'footnote'

autoclass_content = 'both'
autodoc_member_order = 'bysource'

intersphinx_mapping = {
    'pyuv': ('http://pyuv.readthedocs.org/en/latest', None),
    'fibers': ('http://python-fibers.readthedocs.org/en/latest', None),
    'python': ('http://docs.python.org/3.4', None)
}

########NEW FILE########
__FILENAME__ = curl
# Example: cURL like URL downloader

import sys
import argparse
from gruvi import http

parser = argparse.ArgumentParser()
parser.add_argument('url');
args = parser.parse_args()

url = http.urlsplit2(args.url)
client = http.HttpClient()
client.connect((url.hostname, url.port), ssl=url.scheme == 'https')

client.request('GET', url.path)
response = client.getresponse()

ctype = response.get_header('Content-Type', 'text/plain')
ctype, options = http.split_header_options(ctype)
if not ctype.startswith('text/'):
    print('Refusing to write {} to stdout'.format(ctype))
    sys.exit(0)
charset = options.get('charset', 'iso-8859-1')

while True:
    buf = response.read(4096)
    if not buf:
        break
    sys.stdout.write(buf.decode(charset))

########NEW FILE########
__FILENAME__ = echoserver1
# Example: echo server, using StreamServer

import logging
import argparse

from gruvi import get_hub, util
from gruvi.stream import StreamServer

logging.basicConfig()

parser = argparse.ArgumentParser()
parser.add_argument('port', type=int)
args = parser.parse_args()

def echo_handler(stream, protocol, client):
    peer = client.getpeername()
    print('Connection from {0}'.format(util.saddr(peer)))
    while True:
        buf = stream.read(4096)
        if not buf:
            break
        stream.write(buf)
    print('Connection closed')

server = StreamServer(echo_handler)
server.listen(('0.0.0.0', args.port))

hub = get_hub()
hub.switch(interrupt=True)

########NEW FILE########
__FILENAME__ = echoserver2
#!/usr/bin/env python
#
# Example: echo server, using a new protocol

from __future__ import print_function

import logging
import argparse

import pyuv
from gruvi import switchpoint, get_hub, util
from gruvi.protocols import Protocol

logging.basicConfig()


class EchoServer(Protocol):
    """Echo protocol server."""

    def _on_transport_readable(self, transport, data, error):
        if error == pyuv.errno.UV_EOF:
            self._logger.debug('got EOF from client')
            self._close_transport(transport)
        elif error:
            self._logger.error('got error {0} from client', error)
            self._close_transport(transport)
        else:
            transport.write(data)

    @switchpoint
    def listen(self, address, ssl=False, **transport_args):
        super(EchoServer, self)._listen(address, ssl, **transport_args)


parser = argparse.ArgumentParser()
parser.add_argument('hostname');
parser.add_argument('port', type=int)
args = parser.parse_args()

server = EchoServer()
server.listen((args.hostname, args.port))
addr = server.transport.getsockname()
print('Listening on {0}'.format(util.saddr(addr)))

hub = get_hub()
print('Press CTRL-C to quit')
hub.switch(interrupt=True)

########NEW FILE########
__FILENAME__ = netcat1
#!/usr/bin/env python
#
# Example: a simple nc(1), client only, using the transport API.
# Also shows how to use asynchronous IO with stdin/stdout

from __future__ import absolute_import, print_function

import sys
import argparse
import logging

import pyuv
from gruvi import get_hub, create_connection, saddr
from gruvi.pyuv import TTY

logging.basicConfig()

parser = argparse.ArgumentParser()
parser.add_argument('hostname')
parser.add_argument('port', type=int)
args = parser.parse_args()

conn = util.create_connection((args.hostname, args.port))
peer = conn.getpeername()
print('Connected to {0!s}'.format(util.saddr(peer)), file=sys.stderr)
stdin = TTY(sys.stdin)
stdout = TTY(sys.stdout)


def read_stdin(handle, data, error):
    if error == pyuv.errno.UV_EOF:
        logger.debug('Got EOF from stdin')
        conn.shutdown()
    elif error:
        logger.error('Error {0} in read_stdin()'.format(error))
        hub.parent.switch()
    else:
        conn.write(data)

def read_network(handle, data, error):
    if error == pyuv.errno.UV_EOF:
        logger.debug('Peer closed connection')
        hub.parent.switch()
    elif error:
        logger.error('Error {0} in read_network()'.format(error))
        hub.parent.switch()
    else:
        stdout.write(data)


stdin.start_read(read_stdin)
conn.start_read(read_network)

hub = get_hub()
print('Press CTRL-C to quit (CTRL-D to send EOF)', file=sys.stderr)
hub.switch(interrupt=True)

########NEW FILE########
__FILENAME__ = netcat2
#!/usr/bin/env python
#
# Example: a simple nc(1), client only, using the stream client and greenlets.

from __future__ import absolute_import, print_function

import sys
import argparse
import logging

import pyuv
from gruvi import get_hub, util
from gruvi.pyuv import TTY
from gruvi.stream import StreamClient

logging.basicConfig()

parser = argparse.ArgumentParser()
parser.add_argument('hostname')
parser.add_argument('port', type=int)
args = parser.parse_args()

client = StreamClient()
client.connect((args.hostname, args.port))
peer = client.transport.getpeername()
print('Connected to {0!s}'.format(util.saddr(peer)), file=sys.stderr)

stdin = StreamClient()
stdin.connect(TTY(sys.stdin))
stdout = StreamClient()
stdout.connect(TTY(sys.stdout))


def read_stdin():
    while True:
        buf = stdin.read(4096)
        if not buf:
            logger.debug('Got EOF on stdin')
            client.shutdown()
            break
        client.write(buf)

def read_network():
    while True:
        buf = client.read(4096)
        if not buf:
            logger.debug('Connection closed by peer')
            break
        stdout.write(buf)
    hub.parent.switch()


stdin_reader = gruvi.Greenlet(read_stdin)
stdin_reader.start()
network_reader = gruvi.Greenlet(read_network)
network_reader.start()

hub = get_hub()
print('Press CTRL-C to quit (CTRL-D to send EOF)', file=sys.stderr)
hub.switch(interrupt=True)

########NEW FILE########
__FILENAME__ = webserver
#!/usr/bin/env python
#
# Example: hello world web server

from __future__ import print_function

import logging
import argparse

from gruvi import get_hub
from gruvi.http import HttpServer

logging.basicConfig()

parser = argparse.ArgumentParser()
parser.add_argument('hostname');
parser.add_argument('port', type=int);
args = parser.parse_args()


def hello_app(environ, start_response):
    headers = [('Content-Type', 'text/plain')]
    start_response('200 OK', headers)
    return [b'Hello, world!']


server = HttpServer(hello_app)
server.listen((args.hostname, args.port))

hub = get_hub()
print('Press CTRL-C to exit')
hub.switch(interrupt=True)

########NEW FILE########
__FILENAME__ = compat
#
# This file is part of Gruvi. Gruvi is free software available under the
# terms of the MIT license. See the file "LICENSE" that was provided
# together with this source file for the licensing terms.
#
# Copyright (c) 2012-2014 the Gruvi authors. See the file "AUTHORS" for a
# complete list.

from __future__ import absolute_import, print_function

import sys

# Some compatibility stuff that is not in six.

if sys.version_info[:2] == (2, 6):

    memoryview = buffer   # read-only but close enough for us
    bytes_types = (bytes, bytearray, buffer)

else:

    memoryview = memoryview
    bytes_types = (bytes, bytearray, memoryview)

########NEW FILE########
__FILENAME__ = dbus
#
# This file is part of Gruvi. Gruvi is free software available under the
# terms of the MIT license. See the file "LICENSE" that was provided
# together with this source file for the licensing terms.
#
# Copyright (c) 2012-2014 the Gruvi authors. See the file "AUTHORS" for a
# complete list.

"""
This module implements a D-BUS client and server.

The implementation uses various pieces from Tom Cocagne's excellent `txdbus
<https://github.com/cocagne/txdbus>`_ project. A cut down copy of txdbus,
containing only those parts needed by Gruvi, is available as
:mod:`gruvi.txdbus`. You need this if you are providing a message handler (see
below).

Both a client and a server/bus-side implementation are provided. The bus-side
implementation is very bare bones and apart from the "Hello" message it does
not implement any of the "org.freedestkop.DBus" interface. It also does not
implement any message routing. The server side is provided mostly for testing
purposes (but it could serve as the basis for a real D-BUS server).

The client side of a D-BUS connection is implemented by :class:`DbusClient` and
the server/bus-side by :class:`DbusServer`. Both implement a procedural
interface. Messages can be send using e.g. :meth:`DbusClient.send_message` or
:meth:`DbusClient.call_method`. An object-oriented interface that represents
D-BUS objects as Python objects, like the one txdbus provides, is currently not
available. The procedural interface can be used as a basis for your own
object-oriented interface though.

To receive notifications or to respond to method calls, you need to provide a
*message handler* to the client or the server constructor. The signature of the
message handler is: ``message_handler(message, protocol)``. Here, the *message*
argument is an instance of :class:`gruvi.txdbus.DbusMessage`, and the
*protocol* will be the :class:`DbusProtocol` instance for the current
connection.

Message handlers runs in their own fiber, which allows them to call into
switchpoints. There is one fiber for every connection.
"""

from __future__ import absolute_import, print_function

import os
import struct
import binascii
import codecs
import six

from . import hub, txdbus
from .hub import switchpoint, switch_back
from .sync import Event
from .transports import UvError
from .protocols import ProtocolError, MessageProtocol
from .endpoints import Client, Server, add_protocol_method
from .compat import memoryview

__all__ = ['DbusError', 'DbusMethodCallError', 'DbusProtocol', 'DbusClient', 'DbusServer']


class DbusError(ProtocolError):
    """Exception that is raised in case of D-BUS protocol errors."""


class DbusMethodCallError(DbusError):
    """Exception that is raised when a error reply is received for a D-BUS
    method call."""

    def __init__(self, method, reply):
        message = 'error calling {0!r} method ({1})'.format(method, reply.error_name)
        super(DbusMethodCallError, self).__init__(message)
        self._error = reply.error_name
        self._args = tuple(reply.body) if reply.body else ()

    @property
    def error(self):
        return self._error

    @property
    def args(self):
        return self._args


def parse_dbus_address(address):
    """Parse a D-BUS address string into a list of addresses."""
    if address == 'session':
        address = os.environ.get('DBUS_SESSION_BUS_ADDRESS')
        if not address:
            raise ValueError('$DBUS_SESSION_BUS_ADDRESS not set')
    elif address == 'system':
        address = os.environ.get('DBUS_SYSTEM_BUS_ADDRESS',
                                 'unix:path=/var/run/dbus/system_bus_socket')
    addresses = []
    for addr in address.split(';'):
        p1 = addr.find(':')
        if p1 == -1:
            raise ValueError('illegal address string: {0}'.format(addr))
        kind = addr[:p1]
        args = dict((kv.split('=') for kv in addr[p1+1:].split(',')))
        if kind == 'unix':
            if 'path' in args:
                addr = args['path']
            elif 'abstract' in args:
                addr = '\0' + args['abstract']
            else:
                raise ValueError('require "path" or "abstract" for unix')
        elif kind == 'tcp':
            if 'host' not in args or 'port' not in args:
                raise ValueError('require "host" and "port" for tcp')
            addr = (args['host'], int(args['port']))
        else:
            raise ValueError('unknown transport: {0}'.format(kind))
        addresses.append(addr)
    return addresses


class TxdbusAuthenticator(object):
    """A adapter to use the txdbus client and server authenticators with our
    transports and protocols."""

    # For testing, cookie_dir is set to a temporary path. Otherwise, txdbus
    # uses ~/.dbus-keyrings as specified in the spec.
    cookie_dir = None

    def __init__(self, transport, protocol, server_side, server_guid=None):
        self._transport = transport
        self._protocol = protocol
        self._server_side = server_side
        if self._server_side:
            self._authenticator = txdbus.BusAuthenticator(server_guid)
            self._authenticator.authenticators['DBUS_COOKIE_SHA1'].keyring_dir = self.cookie_dir
        else:
            self._authenticator = txdbus.ClientAuthenticator()
            self._authenticator.cookie_dir = self.cookie_dir
        self._authenticator.beginAuthentication(self)

    def sendAuthMessage(self, message):
        # Called by the txdbus authenticators
        message = message.encode('ascii') + b'\r\n'
        self._protocol._transport.write(message)

    @property
    def _unix_creds(self):
        # Used by txdbus.BusExternalAuthenticator
        return self._transport.get_extra_info('unix_creds')

    def handleAuthMessage(self, line):
        # Called by our protocol
        self._authenticator.handleAuthMessage(line)

    def authenticationSucceeded(self):
        """Return whether the authentication succeeded."""
        return self._authenticator.authenticationSucceeded()

    def getMechanismName(self):
        """Return the authentication mechanism name."""
        if self._server_side:
            mech = self._authenticator.current_mech
            return mech.getMechanismName() if mech else None
        else:
            return getattr(self._authenticator, 'authMech', None)

    def getUserName(self):
        """Return the authenticated user name (server side)."""
        if not self._server_side:
            return
        mech = self._authenticator.current_mech
        return mech.getUserName() if mech else None

    def getGUID(self):
        """Return the GUID of the authenticated server."""
        return self._authenticator.getGUID()


def parse_dbus_header(header):
    """Parse a D-BUS header. Return the message size."""
    if six.indexbytes(header, 0) == ord('l'):
        endian = '<'
    elif six.indexbytes(header, 0) == ord('B'):
        endian = '>'
    else:
        raise ValueError('illegal endianness')
    if not 1 <= six.indexbytes(header, 1) <= 4:
        raise ValueError('illegel message type')
    if struct.unpack(endian + 'I', header[8:12])[0] == 0:
        raise ValueError('illegal serial number')
    harrlen = struct.unpack(endian + 'I', header[12:16])[0]
    padlen = (8 - harrlen) % 8
    bodylen = struct.unpack(endian + 'I', header[4:8])[0]
    return 16 + harrlen + padlen + bodylen


def new_server_guid():
    """Return a new GUID for a server."""
    return binascii.hexlify(os.urandom(16)).decode('ascii')


class DbusProtocol(MessageProtocol):
    """D-BUS Protocol."""

    # According to the D-BUS spec the max message size is 128MB. However since
    # we want to limited memory usage we are much more conservative here.
    read_buffer_size = 128*1024

    # Maximum size for an authentication line
    max_line_size = 1000

    _next_unique_name = 0

    S_CREDS_BYTE, S_AUTHENTICATE, S_MESSAGE_HEADER, S_MESSAGE = range(4)

    def __init__(self, server_side, message_handler=None, server_guid=None, timeout=None):
        super(DbusProtocol, self).__init__(message_handler)
        self._server_side = server_side
        self._name_acquired = Event()
        self._timeout = timeout
        self._buffer = bytearray()
        self._method_calls = {}
        self._authenticator = None
        if self._server_side:
            self._server_guid = server_guid or new_server_guid()
            self._unique_name = ':{0}'.format(self._next_unique_name)
            type(self)._next_unique_name += 1
        else:
            self._server_guid = None
            self._unique_name = None
        self._state = None

    @property
    def server_guid(self):
        return self._server_guid

    def connection_made(self, transport):
        # Protocol callback
        super(DbusProtocol, self).connection_made(transport)
        # The client initiates by sending a '\0' byte, as per the D-BUS spec.
        if self._server_side:
            self._state = self.S_CREDS_BYTE
        else:
            self._state = self.S_AUTHENTICATE
            self._transport.write(b'\0')
        self._authenticator = TxdbusAuthenticator(transport, self, self._server_side,
                                                  self._server_guid)
        self._message_size = 0

    def connection_lost(self, exc):
        # Protocol callback
        super(DbusProtocol, self).connection_lost(exc)
        for notify in self._method_calls.values():
            if hasattr(notify, 'throw'):
                notify.throw(self._error)
        self._method_calls.clear()
        self._name_acquired.set()
        self._authenticator = None  # break cycle

    def get_read_buffer_size(self):
        # Return the size of the read buffer.
        return len(self._buffer) + self._queue.qsize()

    def on_creds_byte(self, byte):
        if byte != 0:
            self._error = DbusError('first byte needs to be zero')
            return False
        self._state = self.S_AUTHENTICATE
        return True

    def on_partial_auth_line(self, line):
        if len(line) > self.max_line_size:
            self._error = DbusError('auth line too long ({0} bytes)'.format(len(line)))
            return False
        return True

    def on_auth_line(self, line):
        if not self.on_partial_auth_line(line):
            return False
        if line[-2:] != b'\r\n':
            self._error = DbusError('auth line does not end with \\r\\n')
            return False
        try:
            line = codecs.decode(line[:-2], 'ascii')  # codecs.decode allows memoryview
        except UnicodeDecodeError as e:
            self._error = DbusError('auth line contain non-ascii chars')
            return False
        try:
            self._authenticator.handleAuthMessage(line)
        except txdbus.DBusAuthenticationFailed as e:
            self._error = DbusError('authentication failed: {0!s}'.format(e))
            return False
        if self._authenticator.authenticationSucceeded():
            if not self._server_side:
                message = txdbus.MethodCallMessage('/org/freedesktop/DBus', 'Hello',
                                    'org.freedesktop.DBus', 'org.freedesktop.DBus')
                self._transport.write(message.rawMessage)
                self._method_calls[message.serial] = self.on_hello_response
            self._state = self.S_MESSAGE_HEADER
            self._server_guid = self._authenticator.getGUID()
        return True

    def on_hello_response(self, message):
        self._unique_name = message.body[0]
        self._name_acquired.set()

    def on_message_header(self, header):
        try:
            size = parse_dbus_header(header)
        except ValueError as e:
            self._error = DbusError('invalid message header')
            return False
        if size > self._read_buffer_high:
            self._error = DbusError('message too large ({0} bytes)'.format(size))
            return False
        self._message_size = size
        self._state = self.S_MESSAGE
        return True

    def on_message(self, message):
        try:
            parsed = txdbus.parseMessage(message)
        except (txdbus.MarshallingError, struct.error) as e:
            self._error = DbusError('parseMessage() error: {0!s}'.format(e))
            return False
        if self._server_side and not self._name_acquired:
            if isinstance(parsed, txdbus.MethodCallMessage) \
                        and parsed.member == 'Hello' \
                        and parsed.path == '/org/freedesktop/DBus' \
                        and parsed.interface == 'org.freedesktop.DBus' \
                        and parsed.destination == 'org.freedesktop.DBus':
                response = txdbus.MethodReturnMessage(parsed.serial, signature='s',
                                                      body=[self._unique_name])
                self._name_acquired.set()
                self._transport.write(response.rawMessage)
            else:
                self._error = DbusError('Hello method not called')
                return False
        elif isinstance(parsed, (txdbus.MethodReturnMessage, txdbus.ErrorMessage)) \
                    and getattr(parsed, 'reply_serial', 0) in self._method_calls:
            notify = self._method_calls.pop(parsed.reply_serial)
            notify(parsed)
        elif self._dispatcher:
            self._queue.put_nowait(parsed, len(message))
        else:
            mtype = type(parsed).__name__[:-7].lower()
            info = ' {0!r}'.format(getattr(parsed, 'member', getattr(parsed, 'error_name', '')))
            self._log.warning('no handler, ignoring inbound {}{}', mtype, info)
        self._state = self.S_MESSAGE_HEADER
        return True

    def prepend_buffer(self, buf):
        if self._buffer:
            self._buffer.extend(buf)
            buf = self._buffer
            self._buffer = bytearray()
        return memoryview(buf)

    def data_received(self, data):
        view = memoryview(data)
        offset = 0
        while offset != len(data):
            if self._state == self.S_CREDS_BYTE:
                credsbyte = six.indexbytes(view, offset)
                offset += 1
                if not self.on_creds_byte(credsbyte):
                    break
            if self._state == self.S_AUTHENTICATE:
                pos = data.find(b'\n', offset)
                if pos == -1:
                    self._buffer.extend(view[offset:])
                    self.on_partial_auth_line(self._buffer)
                    break
                line = self.prepend_buffer(view[offset:pos+1])
                offset = pos+1
                if not self.on_auth_line(line):
                    break
            if self._state == self.S_MESSAGE_HEADER:
                needbytes = 16 - len(self._buffer)
                if len(data) - offset < needbytes:
                    self._buffer.extend(view[offset:])
                    break
                header = self.prepend_buffer(view[offset:offset+needbytes])
                if not self.on_message_header(header):
                    break
                offset += len(header)
                self._buffer.extend(header)
            if self._state == self.S_MESSAGE:
                needbytes = self._message_size - len(self._buffer)
                if len(data) - offset < needbytes:
                    self._buffer.extend(view[offset:])
                    break
                message = self.prepend_buffer(view[offset:offset+needbytes])
                offset += needbytes
                if not self.on_message(message):
                    break
        if self._error:
            self._transport.close()
            return
        self.read_buffer_size_changed()

    @switchpoint
    def get_unique_name(self):
        """Return the unique name of the D-BUS connection."""
        self._name_acquired.wait()
        if self._error:
            raise self._error
        elif self._closing or self._closed:
            raise RuntimeError('protocol is closing/closed')
        return self._unique_name

    @switchpoint
    def send_message(self, message):
        """Send a D-BUS message.

        The *message* argument must be :class:`gruvi.txdbus.DbusMessage`
        instance.
        """
        if not isinstance(message, txdbus.DbusMessage):
            raise TypeError('message: expecting DbusMessage instance (got {0!r})',
                                type(message).__name__)
        self._name_acquired.wait()
        self._may_write.wait()
        if self._error:
            raise self._error
        elif self._closing or self._closed:
            raise RuntimeError('protocol is closing/closed')
        self._transport.write(message.rawMessage)

    @switchpoint
    def call_method(self, service, path, interface, method, signature=None,
                    args=None, no_reply=False, auto_start=False, timeout=-1):
        """Call a D-BUS method and wait for its reply.

        This method calls the D-BUS method with name *method* that resides on
        the object at bus address *service*, at path *path*, on interface
        *interface*.

        The *signature* and *args* are optional arguments that can be used to
        add parameters to the method call. The signature is a D-BUS signature
        string, while *args* must be a sequence of python types that can be
        converted into the types specified by the signature. See the `D-BUS
        specification
        <http://dbus.freedesktop.org/doc/dbus-specification.html>`_ for a
        reference on signature strings.

        The flags *no_reply* and *auto_start* control the NO_REPLY_EXPECTED and
        NO_AUTO_START flags on the D-BUS message.

        The return value is the result of the D-BUS method call. This will be a
        possibly empty sequence of values.
        """
        message = txdbus.MethodCallMessage(path, method, interface=interface,
                                destination=service, signature=signature, body=args,
                                expectReply=not no_reply, autoStart=auto_start)
        serial = message.serial
        if timeout == -1:
            timeout = self._timeout
        try:
            with switch_back(timeout) as switcher:
                self._method_calls[serial] = switcher
                self.send_message(message)
                args, _ = self._hub.switch()
        finally:
            self._method_calls.pop(serial, None)
        response = args[0]
        assert response.reply_serial == serial
        if isinstance(response, txdbus.ErrorMessage):
            raise DbusMethodCallError(method, response)
        args = tuple(response.body) if response.body else ()
        return args


class DbusClient(Client):
    """A D-BUS client."""

    def __init__(self, message_handler=None, timeout=30):
        """
        The *message_handler* argument specifies an optional message handler.

        The optional *timeout* argument specifies a default timeout for
        protocol operations in seconds.
        """
        super(DbusClient, self).__init__(self._create_protocol, timeout)
        self._message_handler = message_handler
 
    @switchpoint
    def connect(self, address='session'):
        """Connect to *address* and wait until the connection is established.

        The *address* argument must be a D-BUS server address, in the format
        described in the D-BUS specification. It may also be one of the special
        addresses ``'session'`` or ``'system'``, to connect to the D-BUS
        session and system bus, respectively.
        """
        if isinstance(address, six.string_types):
            addresses = parse_dbus_address(address)
        else:
            addresses = [address]
        for addr in addresses:
            try:
                super(DbusClient, self).connect(addr)
            except UvError as e:
                continue
            break
        else:
            raise DbusError('could not connect to any address')
        # Wait for authentication to complete
        self.get_unique_name()

    def _create_protocol(self):
        return DbusProtocol(False, self._message_handler, self._timeout)

    add_protocol_method(DbusProtocol.get_unique_name, globals(), locals())
    add_protocol_method(DbusProtocol.send_message, globals(), locals())
    add_protocol_method(DbusProtocol.call_method, globals(), locals())


class DbusServer(Server):
    """A D-BUS server."""

    def __init__(self, message_handler, timeout=30):
        """
        The *message_handler* argument specifies the message handler.

        The optional *timeout* argument specifies a default timeout for
        protocol operations in seconds.
        """
        super(DbusServer, self).__init__(self._create_protocol, timeout)
        self._message_handler = message_handler

    @switchpoint
    def listen(self, address='session'):
        """Start listening on *address* for new connection.

        The *address* argument must be a D-BUS server address, in the format
        described in the D-BUS specification. It may also be one of the special
        addresses ``'session'`` or ``'system'``, to connect to the D-BUS
        session and system bus, respectively.
        """
        if isinstance(address, six.string_types):
            addresses = parse_dbus_address(address)
        else:
            addresses = [address]
        for addr in addresses:
            try:
                super(DbusServer, self).listen(addr)
            except UvError as e:
                self._log.error('skipping address {}', saddr(addr))

    def _create_protocol(self):
        # Protocol factory
        return DbusProtocol(True, self._message_handler, timeout=self._timeout)

########NEW FILE########
__FILENAME__ = endpoints
#
# This file is part of Gruvi. Gruvi is free software available under the
# terms of the MIT license. See the file "LICENSE" that was provided
# together with this source file for the licensing terms.
#
# Copyright (c) 2012-2014 the Gruvi authors. See the file "AUTHORS" for a
# complete list.

from __future__ import absolute_import, print_function

import os
import sys
import socket
import functools
import textwrap
import inspect
import pyuv
import six

from . import logging
from .hub import get_hub, switchpoint, switch_back
from .sync import Event
from .errors import Timeout
from .transports import TransportError, Transport
from .ssl import SslTransport

__all__ = ['saddr', 'paddr', 'getaddrinfo', 'create_ssl_context',
           'create_connection', 'create_server', 'Server']


def saddr(address):
    """Return a family specific string representation for a socket address."""
    if isinstance(address, six.binary_type) and six.PY3:
        return address.decode('utf8')
    elif isinstance(address, six.string_types):
        return address
    elif isinstance(address, tuple) and ':' in address[0]:
        return '[{0}]:{1}'.format(address[0], address[1])
    elif isinstance(address, tuple):
        return '{0}:{1}'.format(*address)
    elif isinstance(address, pyuv.Handle):
        return '{0!r}'.format(address)
    else:
        raise TypeError('illegal address type: {!s}'.format(type(address)))


def paddr(address):
    """The inverse of saddr."""
    if address.startswith('['):
        p1 = address.find(']:')
        if p1 == -1:
            raise ValueError
        return (address[1:p1], int(address[p1+2:]))
    elif ':' in address:
        p1 = address.find(':')
        return (address[:p1], int(address[p1+1:]))
    else:
        return address


@switchpoint
def getaddrinfo(host, port=0, family=0, socktype=0, protocol=0, flags=0, timeout=30):
    """A cooperative version of :py:func:`socket.getaddrinfo`.

    The address resolution is performed in the libuv thread pool. 
    """
    hub = get_hub()
    with switch_back(timeout) as switcher:
        request = pyuv.util.getaddrinfo(hub.loop, switcher, host, port, family,
                                        socktype, protocol, flags)
        result = hub.switch()
    result, error = result[0]
    if error:
        message = pyuv.errno.strerror(error)
        raise pyuv.error.UVError(error, message)
    return result


def create_ssl_context(**sslargs):
    """Create a new SSL context."""
    version = sslargs.get('ssl_version')
    import ssl
    if hasattr(ssl, 'create_default_context') and version is None:
        # Python 3.4+
        context = ssl.create_default_context()
    elif hasattr(ssl, 'SSLContext'):
        # Python 3.3
        context = ssl.SSLContext(version or ssl.PROTOCOL_SSLv23)
    else:
        # Python 2.6/2.7
        from . import sslcompat
        context = sslcompat.SSLContext(version or ssl.PROTOCOL_SSLv23)
    if sslargs.get('certfile'):
        context.load_cert_chain(sslargs['certfile'], sslargs.get('keyfile'))
    if sslargs.get('ca_certs'):
        context.load_verify_locations(sslargs['ca_certs'])
    if sslargs.get('cert_reqs'):
        context.verify_mode = sslargs['cert_reqs']
    if sslargs.get('ciphers'):
        context.set_ciphers(sslargs['ciphers'])
    return context


def _use_af_unix():
    """Return whether to open a :class:`pyuv.Pipe` via an AF_UNIX socket."""
    # Only use on platforms that don't return EAGAIN for AF_UNIX sockets
    return sys.platform in ('linux', 'linux2', 'linux3')

def _af_unix_helper(handle, address, op):
    """Connect or bind a :class:`pyuv.Pipe` to an AF_UNIX socket.

    We use this on Linux to work around certain limitations in the libuv API,
    currently the lack of abstract sockets and SO_PEERCRED.
    """
    sock = socket.socket(socket.AF_UNIX, socket.SOCK_STREAM)
    sock.setblocking(False)
    try:
        if op == 'connect':
            sock.connect(address)
        elif op == 'bind':
            sock.bind(address)
        fd = os.dup(sock.fileno())
    except IOError as e:
        # Connecting to an AF_UNIX socket never gives EAGAIN on Linux.
        assert e.errno != errno.EAGAIN
        # Convert from Unix errno -> libuv errno via the symbolic error name
        errname = 'UV_{0}'.format(errno.errocode.get(e.errno, 'UNKNOWN'))
        errno = getattr(pyuv.errno, errname, UV_UNKNOWN)
        raise pyuv.error.PipeError(errno, os.strerror(e.errno))
    finally:
        sock.close()
    handle.open(fd)


@switchpoint
def create_connection(protocol_factory, address, ssl=False, ssl_args={},
                      family=0, flags=0, local_address=None,
                      timeout=None, interrupt=False):
    """Create a new connection.

    This method creates a stream transport, connects it to *address*, and then
    waits for the connection to be established. When the connection is
    established, a new protocol instance is created by calling
    *protocol_factory*. The protocol is then connected to the transport by
    calling its ``conection_made`` method. Finally the results are returned as
    a ``(transport, protocol)`` tuple.

    The address may be either be a string, a (host, port) tuple, or an already
    connected :class:`pyuv.Stream` handle. If the address is a string, this
    method connects to a named pipe using a :class:`pyuv.Pipe` handle.
    
    If the address is a tuple, this method connects to a TCP/IP service using a
    :class:`pyuv.TCP` handle. The host and port elements of the tuple are the
    DNS and service names respectively, and will be resolved using
    :func:`getaddrinfo`. The *family* and *flags* parameters are also passed to
    :func:`getaddrinfo` and can be used to modify the address resolution.

    The address my also be a :class:`pyuv.Stream` instance. In this case the
    handle must already be connected.

    The *ssl* parameter indicates whether SSL should be used on top of the
    stream transport. If an SSL connection is desired, then *ssl* can be set to
    ``True`` or to an :class:`ssl.SSLContext` instance. In the former case a
    default SSL context is created. In the case of Python 2.x the :mod:`ssl`
    module does not define an SSL context object and you may use the
    :class:`gruvi.sslcompat.SSLContext` class instead. The *ssl_args* argument
    may be used to pass keyword arguments to
    :meth:`ssl.SSLContext.wrap_socket`.

    If an SSL connection was selected, the resulting transport will be a
    :class:`gruvi.SslTransport` instance, otherwise it will be a
    :class:`gruvi.Transport` instance.

    The *local_address* keyword argument is relevant only for AF_INET
    transports. If provided, it specifies the local address to bind to.
    """
    hub = get_hub()
    log = logging.get_logger()
    if isinstance(address, (six.binary_type, six.text_type)):
        handle_type = pyuv.Pipe
        addresses = [address]
    elif isinstance(address, tuple):
        handle_type = pyuv.TCP
        result = getaddrinfo(address[0], address[1], family, socket.SOCK_STREAM,
                             socket.IPPROTO_TCP, flags)
        addresses = [res[4] for res in result]
    elif isinstance(address, pyuv.Stream):
        handle = address
        addresses = []; error = None
    else:
        raise TypeError('expecting a string, tuple, or pyuv.Stream')
    for addr in addresses:
        log.debug('trying address {}', saddr(addr))
        handle = handle_type(hub.loop)
        try:
            if handle_type is pyuv.Pipe and _use_af_unix():
                _af_unix_helper(handle, addr, 'connect')
            else:
                with switch_back(timeout, interrupt) as switcher:
                    handle.connect(addr, switcher)
                    hub.switch()
        except pyuv.error.UVError as e:
            error = e[0]
        except Timeout:
            error = pyuv.errno.UV_ETIMEDOUT
        else:
            error = None
        if not error:
            break
        log.warning('connect() failed with error {}', error)
    if error:
        log.error('all addresses failed')
        raise TransportError.from_errno(error)
    if local_address:
        handle.bind(*local_address)
    protocol = protocol_factory()
    if ssl:
        context = ssl if hasattr(ssl, '_wrap_socket') else create_ssl_context()
        transport = SslTransport(handle, context, False, **ssl_args)
    else:
        transport = Transport(handle)
    transport.start(protocol)
    return (transport, protocol)


class Endpoint(object):
    """A communications endpoint."""

    def __init__(self, protocol_factory, timeout=None):
        self._protocol_factory = protocol_factory
        self._timeout = timeout
        self._hub = get_hub()
        self._log = logging.get_logger(self)

    @property
    def timeout(self):
        return self._timeout


class Client(Endpoint):
    """A client endpoint."""

    def __init__(self, protocol_factory, timeout=None):
        super(Client, self).__init__(protocol_factory, timeout=timeout)
        self._connection = None

    @property
    def connection(self):
        """Return the ``(transport, protocol)`` pair, or None if not connected."""
        return self._connection

    @switchpoint
    def connect(self, address, **kwargs):
        """Connect to *address* and wait for the connection to be established.
        
        See :func:`create_connection` for a description of *address* and the
        supported keyword arguments.
        """
        if self._connection:
            raise RuntimeError('already connected')
        kwargs.setdefault('timeout', self.timeout)
        self._connection = create_connection(self._protocol_factory, address, **kwargs)
        self._connection[0]._log = self._log
        self._connection[1]._log = self._log

    @switchpoint
    def close(self):
        """Close the connection."""
        if not self._connection:
            return
        protocol = self._connection[1]
        protocol.close()
        self._connection = None


class Server(Endpoint):
    """A server endpoint."""

    max_connections = None

    def __init__(self, protocol_factory, timeout=None):
        super(Server, self).__init__(protocol_factory, timeout=timeout)
        self._handles = []
        self._addresses = []
        self._connections = dict()
        self._all_closed = Event()
        self._all_closed.set()

    @property
    def addresses(self):
        """A list of all listen addresses."""
        return self._addresses

    @property
    def connections(self):
        """An iterator yielding the (transport, protocol) pairs for each connection."""
        return self._connections.items()

    def _on_new_connection(self, ssl, ssl_args, handle, error):
        # Callback used with handle.listen().
        assert handle in self._handles
        if error:
            self._log.warning('error {} in listen() callback', error)
            return
        client = type(handle)(self._hub.loop)
        handle.accept(client)
        if self.max_connections is not None and len(self._connections) >= self.max_connections:
            self._log.warning('max connections reached, dropping new connection')
            client.close()
            return
        if ssl:
            context = ssl if hasattr(ssl, '_wrap_socket') else create_ssl_context()
            transport = SslTransport(client, context, True, **ssl_args)
        else:
            transport = Transport(client)
        transport._log = self._log
        self._all_closed.clear()
        self._log.debug('new connection on {}', saddr(client.getsockname()))
        if hasattr(client, 'getpeername'):
            self._log.debug('remote peer is {}', saddr(client.getpeername()))
        protocol = self._protocol_factory()
        protocol._log = self._log
        self._connections[transport] = protocol
        # Chain _on_connection_lost() into protocol.connection_lost()
        protocol.connection_lost = functools.partial(self._on_connection_lost, transport,
                                                     protocol, protocol.connection_lost)
        self.connection_made(transport, protocol)
        transport.start(protocol)

    def _on_connection_lost(self, transport, protocol, connection_lost, *args):
        self.connection_lost(transport, protocol, *args)
        connection_lost(*args)
        self._connections.pop(transport, None)
        if not self._connections:
            self._all_closed.set()

    def connection_made(self, transport, protocol):
        """Callback that is called when a new connection is made."""

    def connection_lost(self, transport, protocol, *args):
        """Callback that is called when a connection is lost."""

    @switchpoint
    def listen(self, address, ssl=False, ssl_args={}, family=0, flags=0, backlog=128):
        """Create a new transport, bind it to *address*, and start listening
        for new connections.

        The address may be either be a string, a (host, port) tuple, or a
        :class:`pyuv.Stream` handle.  If the address is a string, this method
        creates a new :class:`pyuv.Pipe` instance, binds it to *address* and
        will start listening for new connections on it.

        If the address is a tuple, this method creates a new :class:`pyuv.TCP`
        handle. The host and port elements of the tuple are the DNS or IP
        address, and service name or port number respectively. They will be
        resolved resolved using :func:`getaddrinfo()`. The *family* and *flags*
        parameters are also passed to :func:`getaddrinfo` and can be used to
        modify the address resolution. The server will listen on all addresses
        that are resolved. 

        The address may also a :class:`pyuv.Stream` handle. In this case it
        must already be bound to an address.

        The *ssl* parameter indicates whether SSL should be used for accepted
        connections. See :func:`create_connection` for a description of the
        *ssl* and *ssl_args* parameters.

        The *backlog* parameter specifies the listen backlog i.e the maximum
        number of not yet accepted connections to queue.
        """
        handles = []
        if isinstance(address, six.string_types):
            handle_type = pyuv.Pipe
            addresses = [address]
        elif isinstance(address, tuple):
            handle_type = pyuv.TCP
            result = getaddrinfo(address[0], address[1], family, socket.SOCK_STREAM,
                                 socket.IPPROTO_TCP, flags)
            addresses = [res[4] for res in result]
        elif isinstance(address, pyuv.Stream):
            handles.append(address)
            addresses = []
        else:
            raise TypeError('expecting a string, tuple or pyuv.Stream')
        for addr in addresses:
            handle = handle_type(self._hub.loop)
            try:
                if handle_type is pyuv.Pipe and _use_af_unix():
                    _af_unix_helper(handle, addr, 'bind')
                else:
                    handle.bind(addr)
            except pyuv.error.UVError as e:
                self._log.warning('bind error {!r}, skipping {}', e[0], saddr(addr))
                continue
            handles.append(handle)
        addresses = []
        for handle in handles:
            callback = functools.partial(self._on_new_connection, ssl, ssl_args)
            handle.listen(callback, backlog)
            addr = handle.getsockname()
            # pyuv issue #152
            if isinstance(addr, bytes) and six.PY3:
                addr = addr.decode(sys.getfilesystemencoding())
            self._log.debug('listen on {}', saddr(addr))
            addresses.append(addr)
        self._handles += handles
        self._addresses += addresses

    @switchpoint
    def close(self):
        """Close the listening sockets and all accepted connections."""
        for handle in self._handles:
            handle.close()
        del self._handles[:]
        for transport,_ in self.connections:
            transport.close()
        self._all_closed.wait()


@switchpoint
def create_server(protocol_factory, address=None, ssl=False, ssl_args={},
                  family=0, flags=0, backlog=128):
    """Create a new network server.

    This method creates a new :class:`Server` instance and calls
    :meth:`Server.listen` on it to listen for new connections. The server
    instance is returned.

    For a description of the arguments of this function, see
    :meth:`Server.listen`.
    """
    server = Server(protocol_factory)
    server.listen(address, ssl=ssl, ssl_args=ssl_args, family=family,
                  flags=flags, backlog=backlog)
    return server


_protocol_method_template = textwrap.dedent("""\
    def {name}{signature}:
        '''{docstring}'''
        if not self.connection:
            raise RuntimeError('not connected')
        return self.connection[1].{name}{arglist}
    """)

def add_protocol_method(method, moddict, classdict):
    """Import a method from a :class:`Protocol` into a :class:`Client`."""
    name = method.__name__
    doc = method.__doc__ or ''
    argspec = inspect.getargspec(method)
    signature = inspect.formatargspec(*argspec)
    arglist = inspect.formatargspec(argspec[0][1:], *argspec[1:], formatvalue=lambda x: '')
    methoddef = _protocol_method_template.format(name=name, signature=signature,
                                                 docstring=doc, arglist=arglist)
    code = compile(methoddef, moddict['__file__'], 'exec')
    globs = {}
    six.exec_(code, globs)
    wrapped = globs[name]
    if getattr(method, 'switchpoint', False):
        wrapped = switchpoint(wrapped)
    classdict[name] = wrapped

########NEW FILE########
__FILENAME__ = errors
# This file is part of Gruvi. Gruvi is free software available under the
# terms of the MIT license. See the file "LICENSE" that was provided
# together with this source file for the licensing terms.
#
# Copyright (c) 2012-2013 the Gruvi authors. See the file "AUTHORS" for a
# complete list.

from __future__ import absolute_import, print_function

import sys
from pyuv.error import UVError

__all__ = ['Error', 'Timeout', 'Cancelled']

Error = UVError

class Timeout(Error):
    """A timeout has occurred."""

class Cancelled(Error):
    """A fiber or calback was cancelled."""


# The following is a pretty bad hack.. We want to use Sphinx's "automodule" to
# document most of our modules in the API reference section, and we want it to
# show inherited members. The result is that it shows an ugly "with_traceback"
# method for gruvi.Error. We fix that by setting that method to None if and
# only if we are running under Sphinx.

if hasattr(sys, 'running_under_sphinx'):
    Error.with_traceback = None

########NEW FILE########
__FILENAME__ = fibers
#
# This file is part of Gruvi. Gruvi is free software available under the
# terms of the MIT license. See the file "LICENSE" that was provided
# together with this source file for the licensing terms.
#
# Copyright (c) 2012-2013 the Gruvi authors. See the file "AUTHORS" for a
# complete list.

from __future__ import absolute_import, print_function

import fibers
import threading

from . import logging
from .hub import get_hub
from .sync import Event
from .errors import Cancelled

__all__ = ['current_fiber', 'Fiber', 'spawn']


def current_fiber():
    """Return the current fiber."""
    return fibers.current()


class Fiber(fibers.Fiber):
    """An explicitly scheduled execution context aka *co-routine*.

    This class is a very thin layer on top of :class:`fibers.Fiber`. It adds a
    :meth:`start` method that schedules a switch via the hub. It also enforces
    that only the hub may call :meth:`switch`.

    All user created fibers should use this interface. The only fibers in a
    Gruvi application that use the "raw" interface from the :class:`fibers`
    package are the root fiber and the :class:`Hub`.
    """

    __slots__ = ('name', 'context', '_target', '_log', '_thread', '_done')

    def __init__(self, target, args=(), kwargs={}, name=None, hub=None):
        self._hub = hub or get_hub()
        super(Fiber, self).__init__(self.run, args, kwargs, self._hub)
        if name is None:
            fid = self._hub.data.setdefault('next_fiber', 1)
            name = 'Fiber-{0}'.format(fid)
            self._hub.data['next_fiber'] += 1
        self.name = name
        self.context = ''
        self._target = target
        self._log = logging.get_logger()
        self._thread = threading.current_thread()
        self._done = Event()

    def start(self):
        """Schedule the fiber to be started in the next iteration of the
        event loop."""
        target = getattr(self._target, '__qualname__', self._target.__name__)
        self._log.debug('starting fiber {}, target {}', self.name, target)
        self._hub.run_callback(self.switch)

    def switch(self, value=None):
        """Switch to this fiber."""
        if self.current() is not self._hub:
            raise RuntimeError('only the Hub may switch() to a fiber')
        if threading.current_thread() is not self._thread:
            raise RuntimeError('cannot switch from different thread')
        if not self.is_alive():
            self._log.warning('attempt to switch to a dead Fiber')
            return
        return super(Fiber, self).switch(value)

    def cancel(self):
        """Cancel this fiber.
        
        The fiber is cancelled by throwing a :class:`Cancelled` exception
        inside it.
        """
        if not self.is_alive():
            return
        self._hub.run_callback(self.throw, Cancelled('cancelled by Fiber.cancel()'))

    def join(self, timeout=None):
        """Wait until the fiber completes."""
        self._done.wait(timeout)

    def run(self, *args, **kwargs):
        # Target of the first :meth:`switch()` call.
        if self.current() is not self:
            raise RuntimeError('run() may only be called from self')
        value = exc = None
        try:
            value = self._target(*args, **kwargs)
        except Cancelled as e:
            self._log.debug(str(e))
        except Exception as e:
            self._log.exception('uncaught exception in fiber')
            exc = e
        self._done.set()


def spawn(func, *args, **kwargs):
    """Spawn function *func* in a separate greenlet."""
    fiber = Fiber(func, args, kwargs)
    fiber.start()
    return fiber

########NEW FILE########
__FILENAME__ = futures
# This file is part of Gruvi. Gruvi is free software available under the
# terms of the MIT license. See the file "LICENSE" that was provided
# together with this source file for the licensing terms.
#
# Copyright (c) 2012-2013 the Gruvi authors. See the file "AUTHORS" for a
# complete list.

from __future__ import absolute_import, print_function

import sys
import pyuv
import time
import threading

import pyuv
from . import fibers
from .hub import switchpoint
from .sync import Event, Queue

__all__ = ['Future', 'Pool', 'FiberPool', 'ThreadPool', 'get_io_pool',
           'get_cpu_pool', 'blocking']


class Future(object):
    """The result of an asynchronous function call.

    Futures are created by :class:`FiberPool.submit` and :class:`ThreadPool.submit`
    and represent the not-yet-available result of the submitted functions.
    """

    __slots__ = ['_result', '_exception', '_done']

    def __init__(self):
        self._result = None
        self._exception = None
        self._done = Event()

    def done(self):
        """Return whether this future is done."""
        return bool(self._done)

    def result(self):
        """The result of the async function, if available."""
        self._done.wait()
        if self._exception:
            raise self._exception
        return self._result

    def exception(self):
        """The exception that was raised by the async function, if available."""
        self._done.wait()
        return self._exception

    def set_result(self, result):
        """Mark the future as done and set its result."""
        self._result = result
        self._done.set()

    def set_exception(self, exception):
        """Mark the future as done and set an exception."""
        self._exception = exception
        self._done.set()


class PoolBase(object):
    """Base class for the thread and fiber pools."""

    _StopWorker = object()

    def __init__(self, maxsize=None, single_shot=False, name=None):
        self.maxsize = maxsize
        self.single_shot = single_shot
        self.name = name
        self._workers = set()
        self._queue = Queue()
        self._closed = False
        # The lock is short lived so no need for a fiber aware lock.
        self._lock = threading.Lock()

    def _current_worker(self):
        raise NotImplemented

    def _spawn_worker(self):
        raise NotImplemented

    def _worker_main(self):
        # Main function for each worker in the pool.
        while True:
            work = self._queue.get()
            try:
                if work is self._StopWorker:
                    break
                func, args, fut = work
                try:
                    res = func(*args)
                except Exception as e:
                    fut.set_exception(e)
                else:
                    fut.set_result(res)
            finally:
                self._queue.task_done()
            if self.single_shot:
                break
        self._workers.remove(self._current_worker())

    def _spawn_workers(self):
        # Spawn new workers if required.
        with self._lock:
            active = self._queue.unfinished_tasks
            idle = max(0, len(self._workers) - active)
            if self.maxsize is None:
                tospawn = self._queue.qsize() - idle
            else:
                available = max(0, self.maxsize - len(self._workers))
                wanted = max(0, self._queue.qsize() - idle)
                tospawn = min(available, wanted)
            for i in range(tospawn):
                self._spawn_worker()

    def submit(self, func, *args):
        """Submit function *func* to the pool, which will run it asynchronously.
        
        The function is called with positional argument *args*.
        """
        if self._closed:
            raise RuntimeError('pool is closed')
        result = Future()
        self._queue.put((func, args, result))
        self._spawn_workers()
        return result

    @switchpoint
    def map(self, func, *iterables, **kwargs):
        """Apply *func* to the elements of the sequences in *iterables*.

        If multiple iterables are provided, then *func* must take this many
        arguments, and is applied with one element from each iterable. All
        iterables must yield the same number of elements.

        An optional *timeout* keyword argument may be provided to specify a
        timeout.

        This returns a generator yielding the results.
        """
        if self._closed:
            raise RuntimeError('pool is closed')
        timeout = kwargs.pop('timeout', None)
        futures = [self.submit(func, *args) for args in zip(*iterables)]
        for future in futures:
            yield future.result()

    @switchpoint
    def join(self):
        """Wait until all jobs in the pool have completed."""
        self._queue.join()

    @switchpoint
    def close(self):
        """Close the pool.

        New submissions will be blocked. Once all current jobs have finished,
        the workers will be stopped, and this method will return.
        """
        with self._lock:
            if self._closed:
                return
            self._closed = True
        self._queue.join()
        for i in range(len(self._workers)):
            self._queue.put(self._StopWorker)
        self._queue.join()


class FiberPool(PoolBase):
    """Execute functions asynchronously in a pool of fibers."""

    def _current_worker(self):
        return fibers.current_fiber()

    def _spawn_worker(self):
        name = '{0}-{1}'.format(self.name, len(self._workers)) if self.name else None
        fiber = fibers.Fiber(self._worker_main, name=name)
        fiber.start()
        self._workers.add(fiber)

Pool = FiberPool


class ThreadPool(PoolBase):
    """Execute functions asynchronously in a pool of threads."""

    def _current_worker(self):
        return threading.current_thread()

    def _spawn_worker(self):
        name = '{0}-{1}'.format(self.name, len(self._workers)) if self.name else None
        thread = threading.Thread(target=self._worker_main, name=name)
        # Don't block program exit if the user forgot to close() the pool,
        # especially because there's implicitly created pools.
        thread.daemon = True
        thread.start()
        self._workers.add(thread)


# When constructing a pool it doesn't start any workers until they are needed.
# This makes it OK to instantiate the pools ahead of time.

_io_pool = ThreadPool(20, name='Io')
_cpu_pool = ThreadPool(len(pyuv.util.cpu_info()), name='Cpu')

def get_io_pool():
    """Return the thread pool for IO tasks.

    By default there is one IO thread pool that is shared with all threads.
    """
    return _io_pool

def get_cpu_pool():
    """Return the thread pool for CPU intenstive tasks.
    
    By default there is one CPU thread pool that is shared with all threads.
    """
    return _cpu_pool


def blocking(func, *args, **kwargs):
    """Run a function that uses blocking IO.

    The function is run in the IO thread pool. 
    """
    pool = get_io_pool()
    fut = pool.submit(func, *args, **kwargs)
    return fut.result()

########NEW FILE########
__FILENAME__ = http
#
# This file is part of Gruvi. Gruvi is free software available under the
# terms of the MIT license. See the file "LICENSE" that was provided
# together with this source file for the licensing terms.
#
# Copyright (c) 2012-2014 the Gruvi authors. See the file "AUTHORS" for a
# complete list.

"""
The :mod:`gruvi.http` module implements a HTTP client and server.

The client and server are relatively complete implementations of the HTTP
protocol. Some of the supported features are: keepalive, pipelining, chunked
transfers and trailers.

Some general notes about the implementation:

* Both HTTP/1.0 and HTTP/1.1 are supported. The client will by default make
  requests with HTTP/1.1. The server always responds in the same version as the
  request.
* Connections are kept alive by default. This means that you need to make sure
  you close connections when they are no longer needed.
* Any headers that are passed in by application code must not be "Hop by hop"
  headers. These headers may only be used by HTTP implementations themselves,
  such as the client and server in this module.

Some important points about the use of binary versus unicode types in the API:

* Data that is passed into the API that ends up in the HTTP header, such as the
  HTTP version string, method, and headers, must be of the string type. This
  means ``str`` on Python 3, and ``str`` or ``unicode`` on Python 2. However,
  if the string type is unicode aware (all except ``str`` on Python 2), you
  must make sure that it only contains code points that are defined in
  ISO-8859-1, which is the default HTTP encoding specified in RFC2606.
* In theory, HTTP headers can support unicode code points outside ISO-8859-1 if
  encoded according to the scheme in RFC2047. However this method is very
  poorly supported and rarely used, and Gruvi therefore does not offer any
  special support for it. If you must use this feature for some reason, you can
  pre-encode the headers into this encoding and pass them already encoded.
* Data that is passed to the API and ends up in the HTTP body can be either of
  the binary type or of the string type (``bytes``, ``str`` or ``unicode``, the
  latter only on Python 2). If passing a unicode aware type, then the data is
  encoded before adding it to the body. The encoding must be passed into the
  client or server by passing a "Content-Type" header with a "charset"
  parameter. If no encoding is provided, then ISO-8859-1 is assumed. Note that
  ISO-8859-1 is not able to express any code points outside latin1. This means
  that if you pass a body with non-latin1 code points, and you fail to set the
  "charset" parameter, then you will get a ``UnicodeEncodeError`` exception.
"""

from __future__ import absolute_import, print_function

import re
import time
import collections
import six

from . import logging
from .hub import switchpoint
from .util import docfrom
from .errors import Error
from .protocols import MessageProtocol
from .endpoints import Client, Server, add_protocol_method
from .stream import StreamReader
from .http_ffi import lib as _lib, ffi as _ffi
from ._version import version_info

from six.moves import http_client

__all__ = ['HttpError', 'HttpClient', 'HttpServer']


# Export some definitions from  http.client.
for name in dir(http_client):
    value = getattr(http_client, name)
    if name.isupper() and value in http_client.responses:
        globals()[name] = value
for name in ('HTTP_PORT', 'HTTPS_PORT', 'responses'):
    globals()[name] = getattr(http_client, name)


# The "Hop by Hop" headers as defined in RFC 2616. These may not be set by the
# HTTP handler.
hop_by_hop = frozenset(('connection', 'keep-alive', 'proxy-authenticate',
                        'proxy-authorization', 'te', 'trailers',
                        'transfer-encoding', 'upgrade'))


# URL fields as defined by the http-parser URL parser.
_url_fields = (_lib.UF_SCHEMA, _lib.UF_HOST, _lib.UF_PORT, _lib.UF_PATH,
               _lib.UF_QUERY, _lib.UF_FRAGMENT, _lib.UF_USERINFO)


def parse_url(url, is_connect=False):
    """Split a URL into its components.
    
    This function is similar to :func:`urllib.parse.urlsplit` but it uses the
    http-parser URL splitter via CFFI.

    The return value is a sequence: (scheme, host, port, path, query, fragment,
    userinfo).
    """
    if isinstance(url, six.text_type):
        url = url.encode('iso-8859-1')
    elif hasattr(url, 'tobytes'):
        url = url.tobytes()
    elif not isinstance(url, bytes):
        url = bytes(url)
    result = _ffi.new('struct http_parser_url *')
    error = _lib.http_parser_parse_url(url, len(url), is_connect, result)
    if error:
        raise ValueError('http_parser_parse_url(): could not parse')
    parsed = []
    for field in _url_fields:
        if result.field_set & (1 << field):
            span = result.field_data[field]
            comp = url[span.off:span.off+span.len].decode('iso-8859-1')
        else:
            comp = ''
        parsed.append(comp)
    return parsed


# RFC 2626 section 2.2 grammar definitions:
_re_token = re.compile('([!#$%&\'*+-.0-9A-Z^_`a-z|~]+)')

# The regex for "quoted_string" below is not 100% correct. The standard allows
# also LWS and escaped CTL characters. But http-parser has an issue with these
# so we just not allow them.
# Note that the first 256 code points of Unicode are the same as those for
# ISO-8859-1 which is how HTTP headers are encoded. So we can just include the
# valid characters as \x hex references.
# Also note that this does not decode any of the RFC-2047 internationalized
# header values that are allowed in quoted-string (but it will match).
_re_qstring = re.compile('"(([ !\x23-\xff]|\\")*)"')


def parse_option_header(header, sep=';'):
    """Parse a HTTP header with options.

    The header must be of the form "value [; parameters]". This format is used
    by headers like "Content-Type" and "Transfer-Encoding".

    The return value is a (value, params) tuple, with params a dictionary
    containing the parameters.

    This function never raises an error. When a parse error occurs, it returns
    what has been parsed so far.
    """
    options = {}
    p1 = header.find(sep)
    if p1 == -1:
        return header, options
    p2 = p1+1
    while True:
        while p2 < len(header) and header[p2].isspace():
            p2 += 1
        if p2 == len(header):
            break
        mobj = _re_token.match(header, p2)
        if mobj is None:
            break
        name = mobj.group(1)
        p2 = mobj.end(0)
        if p2 > len(header)-2 or header[p2] != '=':
            break
        p2 += 1
        if header[p2] == '"':
            mobj = _re_qstring.match(header, p2)
        else:
            mobj = _re_token.match(header, p2)
        if mobj is None:
            break
        value = mobj.group(1)
        p2 = mobj.end(0)
        options[name] = value
    return header[:p1], options


_weekdays = ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun']
_months = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun',
           'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']
_rfc1123_fmt = '%a, %d %b %Y %H:%M:%S GMT'

def rfc1123_date(timestamp=None):
    """Create a RFC1123 style Date header for *timestamp*.

    If *timestamp* is None, use the current time.
    """
    if timestamp is None:
        timestamp = time.time()
    tm = time.gmtime(timestamp)
    # The time stamp must be GMT, and cannot be localized
    s = _rfc1123_fmt.replace('%a', _weekdays[tm.tm_wday]) \
                    .replace('%b', _months[tm.tm_mon-1])
    return time.strftime(s, tm)


def _s2b(s):
    """Convert a string *s* to bytes in the ISO-8859-1 encoding.
    
    ISO-8859-1 is the default encoding used in HTTP.
    """
    if type(s) is not bytes:
        s = s.encode('iso-8859-1')
    return s

def _ba2s(ba):
    """Convert a byte-array to a "str" type."""
    if six.PY3:
        return ba.decode('iso-8859-1')
    else:
        return bytes(ba)

def _cd2s(cd):
    """Convert a cffi cdata('char *') to a str."""
    s = _ffi.string(cd)
    if six.PY3:
        s = s.decode('iso-8859-1')
    return s


def get_field(headers, name, default=None):
    """Return a field value from a list with (name, value) tuples."""
    name = name.lower()
    for header in headers:
        if header[0].lower() == name:
            return header[1]
    return default


def create_chunk(buf):
    """Create a chunk for the HTTP "chunked" transfer encoding."""
    chunk = bytearray()
    chunk.extend(_s2b('{0:X}\r\n'.format(len(buf))))
    chunk.extend(_s2b(buf))
    chunk.extend(b'\r\n')
    return chunk


def create_chunked_body_end(trailers=None):
    """Create the ending that terminates a chunked body."""
    ending = bytearray()
    ending.extend(b'0\r\n')
    if trailers:
        for name,value in trailers:
            ending.extend(_s2b('{0}: {1}\r\n'.format(name, value)))
    ending.extend(b'\r\n')
    return ending


def create_request(version, method, url, headers):
    """Create a HTTP request header."""
    message = bytearray()
    message.extend(_s2b('{0} {1} HTTP/{2}\r\n'.format(method, url, version)))
    for name,value in headers:
        message.extend(_s2b('{0}: {1}\r\n'.format(name, value)))
    message.extend(b'\r\n')
    return message


def create_response(version, status, headers):
    """Create a HTTP response header."""
    message = bytearray()
    message.extend(_s2b('HTTP/{0} {1}\r\n'.format(version, status)))
    for name,value in headers:
        message.extend(_s2b('{0}: {1}\r\n'.format(name, value)))
    message.extend(b'\r\n')
    return message


class HttpError(Error):
    """Exception that is raised in case of HTTP protocol errors."""


class HttpMessage(object):
    """A HTTP message (request or response).
    
    This is an internal class used by the parser.
    """

    def __init__(self):
        self.message_type = None
        self.version = None
        self.status_code = None
        self.method = None
        self.url = None
        self.is_upgrade = None
        self.should_keep_alive = None
        self.parsed_url = None
        self.headers = []
        self.trailers = []
        self.body = None


class ErrorStream(object):
    """Passed to the WSGI application as environ['wsgi.errors'].

    Forwards messages to the Python logging facility.
    """

    __slots__ = ['_log']

    def __init__(self, log=None):
        self._log = log or logging.get_logger()

    def flush(self):
        pass
    
    def write(self, data):
        self._log.error('wsgi.errors: {}', data)

    def writelines(self, seq):
        for line in seq:
            self.write(line)


class HttpRequest(object):
    """A HTTP request.

    Instances of this class are returned by :meth:`HttpProtocol.request` when
    you set the *body* parameter to ``None``.

    This class allows you to write the request body yourself using the
    :meth:`write` and :meth:`end_request` methods. This can be useful if you
    need to send a large input that cannot be easily presented as as a
    file-like object or a generator, or if you want to use "chunked" encoding
    trailers.
    """

    def __init__(self, transport, protocol):
        self._transport = transport
        self._protocol = protocol
        self._chunked = False
        self._charset = 'ISO-8859-1'
        self._content_length = None
        self._bytes_written = 0

    def start_request(self, method, url, headers=None, body=None):
        """Start a new HTTP request.

        This method is called by :meth:`HttpProtocol.request`. It creates a new
        HTTP request header and sends it to the transport.
        
        The *body* parameter is a hint that specifies the body that will be
        sent in the future, but it will not actually send it. This method tries
        to deduce the Content-Length of the body that follows from it.
        """
        headers = headers[:] if headers is not None else []
        agent = host = clen = ctype = charset = None
        # Ensure that the user doesn't provide any hop-by-hop headers. Only
        # HTTP applications are allowed to set these.
        for name,value in headers:
            name = name.lower()
            if name in hop_by_hop:
                raise ValueError('header {0} is hop-by-hop'.format(name))
            elif name == 'user-agent':
                agent = value
            elif name == 'host':
                host = value
            elif name == 'content-type':
                ctype, params = parse_option_header(value)
                self._charset = params.get('charset')
            elif name == 'content-length':
                clen = int(value)
        # Check that we can support the body type.
        if not isinstance(body, (six.binary_type, six.text_type)) \
                    and not hasattr(body, 'read') \
                    and not hasattr(body, '__iter__') \
                    and not body is None:
            raise TypeError('body: expecting a bytes or str instance, '
                            'a file-like object or an iterable')
        version = self._protocol._version
        # The Host header is mandatory in 1.1. Add it if it's missing.
        server_name = self._protocol.server_name
        if host is None and version == '1.1' and server_name:
            headers.append(('Host', server_name))
        # Identify ourselves.
        if agent is None:
            headers.append(('User-Agent', self._protocol.identifier))
        # Check if we know the body length. If not, then we require "chunked"
        # encoding. Then determine if we can keep the connection alive.
        if isinstance(body, six.text_type):
            body = body.encode(self._charset)
        if clen is None:
            if isinstance(body, six.binary_type):
                clen = len(body)
                if clen > 0:
                    headers.append(('Content-Length', str(clen)))
            elif version == '1.1':
                self._chunked = True
            else:
                raise ValueError('headers: must have "Content-Length" header '
                                 'for HTTP 1.0 when body size unknown')
        self._content_length = clen
        # On HTTP/1.0 we need to specifically indicate we want keep-alive.
        if version == '1.0':
            headers.append(('Connection', 'keep-alive'))
        # If we're doing chunked then we can also do trailers.
        if self._chunked:
            headers.append(('Transfer-Encoding', 'chunked'))
            headers.append(('TE', 'trailers'))
        # Start the request
        header = create_request(version, method, url, headers)
        self._protocol.write(header)

    def write(self, buf):
        """Write *buf* to the request body."""
        if not buf:
            return
        if isinstance(buf, six.text_type):
            buf = buf.encode(self._charset)
        self._bytes_written += len(buf)
        if self._content_length is not None and self._bytes_written > self._content_length:
            raise RuntimeError('wrote too many bytes ({0} > {1})'
                                    .format(self._bytes_written, self._content_length))
        if self._chunked:
            buf = create_chunk(buf)
        self._protocol.write(buf)

    def end_request(self, trailers=None):
        """End the request body.

        The optional *trailers* argument can be used to add trailers. This
        requires "chunked" encoding.
        """
        if trailers and not self._chunked:
            raise RuntimeError('trailers require "chunked" encoding')
        if self._chunked:
            ending = create_chunked_body_end(trailers)
            self._protocol.write(ending)


class HttpResponse(object):
    """An HTTP response as returned by :meth:`HttpClient.get_response`."""

    def __init__(self, message):
        self._message = message

    @property
    def version(self):
        """The HTTP version as a (major, minor) tuple."""
        return self._message.version

    @property
    def status(self):
        """The HTTP status code, as an integer."""
        return self._message.status_code

    @property
    def headers(self):
        """The response headers, as a list of (name, value) pairs."""
        return self._message.headers

    @property
    def trailers(self):
        """The response trailers, as a list of (name, value) pairs.

        The trailers will only be available after the entire response has been
        read. Most servers do not generate trailers.
        """
        return self._message.trailers

    def get_header(self, name, default=None):
        """Return the value of HTTP header *name*.

        If the header does not exist, return *default*.
        """
        return get_field(self._message.headers, name, default)

    def get_trailer(self, name, default=None):
        """Return a the value of a HTTP trailer *name*.

        If the trailer does not exist, return *default*.
        """
        return get_field(self._message.trailers, name, default)

    @switchpoint
    def read(self, size=-1):
        """Read up to *size* bytes from the response body.

        If *size* is not specified or negative, read the entire body.
        """
        return self._message.body.read(size)

    @switchpoint
    def readline(self, limit=-1):
        """Read a single line from the response body.

        If the end of the body is reached before an entire line could be read,
        a partial line is returned. If *limit* is specified, at most this many
        bytes will be read.
        """
        return self._message.body.readline(limit)

    @switchpoint
    @docfrom(StreamReader.readlines)
    def readlines(self, hint=-1):
        """Read the response body and return it as a list of lines.

        If *hint* is specified, then lines will be read until their combined
        size will be equal or larger than *hint*, or until the end of the body
        is reached, whichever happens first.
        """
        return self._message.body.readlines(hint)

    @property
    def __iter__(self):
        """Generate lines from the response body."""
        return self._message.body.__iter__


class WsgiHandler(object):
    """An adapter that runs a WSGI application as a :class:`MessageProtocol`
    message handler.

    This class is used internally by :class:`HttpProtocol`.
    """

    def __init__(self, application):
        """
        The *transport* and *protocol* arguments are the connection's
        transport and protocol respectively.

        The *message* argument must be a :class:`HttpMessage`.
        """
        self._application = application
        self._transport = None
        self._protocol = None
        self._message = None
        self._log = logging.get_logger()
        self._environ = {}
        self._status = None
        self._headers = None
        self._prev_body = None

    def send_headers(self):
        """Send the HTTP headers and start the response body."""
        # We need to figure out the transfer encoding of the body that will
        # follow the header. Here's what we do:
        #  - If there's a content length, don't use any TE.
        #  - Otherwise, if the protocol is HTTP/1.1, use "chunked".
        #  - Otherwise, close the connection after the body is sent.
        clen = get_field(self._headers, 'Content-Length')
        version = self._message.version
        self._chunked = clen is None and version == '1.1'
        if self._chunked:
            self._headers.append(('Transfer-Encoding', 'chunked'))
        # The client may also ask to close the connection (Connection: close)
        self._keepalive = self._message.should_keep_alive and (self._chunked or clen)
        # The default on HTTP/1.1 is keepalive, on HTTP/1.0 it is to close.
        if version == 'HTTP/1.1' and not self._keepalive:
            self._headers.append(('Connection', 'close'))
        elif version == 'HTTP/1.0' and self._keepalive:
            self._headers.append(('Connection', 'keep-alive'))
        server = get_field(self._headers, 'Server')
        if server is None:
            self._headers.append(('Server', self._protocol.identifier))
        date = get_field(self._headers, 'Date')
        if date is None:
            self._headers.append(('Date', rfc1123_date()))
        header = create_response(version, self._status, self._headers)
        self._protocol.write(header)

    def start_response(self, status, headers, exc_info=None):
        """Callable to be passed to the WSGI application."""
        if exc_info:
            try:
                if self._headers_sent:
                    six.reraise(*exc_info)
            finally:
                exc_info = None
        elif self._status is not None:
            raise RuntimeError('response already started')
        for name,value in headers:
            if name.lower() in hop_by_hop:
                raise ValueError('header {0} is hop-by-hop'.format(name))
        self._status = status
        self._headers = headers
        return self.write

    def write(self, data):
        """Callable passed to the WSGI application by :meth:`start_response`."""
        if isinstance(data, six.text_type):
            data = data.encode('iso-8859-1')
        elif not isinstance(data, six.binary_type):
            raise TypeError('data: expecting bytes or str instance')
        elif not data:
            return
        if not self._headers_sent:
            self.send_headers()
            self._headers_sent = True
        if self._chunked:
            data = create_chunk(data)
        self._protocol.write(data)

    def end_response(self):
        """End a response."""
        if not self._headers_sent:
            self.send_headers()
            self._headers_sent = True
        if self._chunked:
            trailers = self._environ.get('gruvi.trailers')
            ending = create_chunked_body_end(trailers)
            self._protocol.write(ending)
        if not self._message.should_keep_alive:
            self._transport.close()

    def __call__(self, transport, protocol, message):
        """Run a WSGI handler."""
        if self._transport is None:
            self._transport = transport
            self._protocol = protocol
        if self._prev_body and not self._prev_body.eof:
            self._log.error('body not fully read pipelined request, closing connection')
            self._transport.close()
            return
        self._status = None
        self._headers = None
        self._headers_sent = False
        self._chunked = False
        self._message = message
        self.create_environ()
        self._log.debug('request: {} {}', message.method, message.url)
        result = None
        try:
            result = self._application(self._environ, self.start_response)
            if not self._status:
                raise HttpError('WSGI handler did not call start_response()')
            for chunk in result:
                self.write(chunk)
            self.end_response()
        finally:
            self._prev_body = self._message.body
            if hasattr(result, 'close'):
                result.close()
        ctype = get_field(self._headers, 'Content-Type', 'unknown')
        clen = get_field(self._headers, 'Content-Length', 'unknown')
        self._log.debug('response: {0} ({1}; {2} bytes)'.format(self._status, ctype, clen))

    def create_environ(self):
        # Initialize the environment with per connection variables.
        m = self._message
        env = self._environ
        # CGI variables
        env['SCRIPT_NAME'] = ''
        sockname = self._transport.get_extra_info('sockname')
        if isinstance(sockname, tuple):
            env['SERVER_NAME'] = self._protocol.server_name or sockname[0]
            env['SERVER_PORT'] = str(sockname[1])
        else:
            env['SERVER_NAME'] = self._protocol.server_name or sockname
            env['SERVER_PORT'] = ''
        env['SERVER_SOFTWARE'] = self._protocol.identifier
        env['SERVER_PROTOCOL'] = 'HTTP/{0}'.format(m.version)
        env['REQUEST_METHOD'] = m.method
        env['PATH_INFO'] = m.parsed_url[3]
        env['QUERY_STRING'] = m.parsed_url[4]
        for field,value in m.headers:
            if field.title() == 'Content-Length':
                env['CONTENT_LENGTH'] = value
            elif field.title() == 'Content-Type':
                env['CONTENT_TYPE'] = value
            else:
                env['HTTP_{0}'.format(field.upper().replace('-', '_'))] = value
        env['REQUEST_URI'] = m.url
        # Support the de-facto X-Forwarded-For and X-Forwarded-Proto headers
        # that are added by reverse proxies.
        remote = env.get('HTTP_X_FORWARDED_FOR')
        peername = self._transport.get_extra_info('peername')
        env['REMOTE_ADDR'] = remote if remote else peername[0] \
                                        if isinstance(peername, tuple) else ''
        # SSL information
        sslinfo = self._transport.get_extra_info('sslinfo')
        cipherinfo = sslinfo.cipher() if sslinfo else None
        if sslinfo and cipherinfo:
            env['HTTPS'] = '1'
            env['SSL_CIPHER'] = cipherinfo[0]
            env['SSL_PROTOCOL'] = cipherinfo[1]
            env['SSL_CIPHER_USEKEYSIZE'] = int(cipherinfo[2])
        # WSGI specific variables
        env['wsgi.version'] = (1, 0)
        env['wsgi.errors'] = ErrorStream(self._log)
        env['wsgi.multithread'] = True
        env['wsgi.multiprocess'] = True
        env['wsgi.run_once'] = False
        env['wsgi.input'] = m.body
        proto = env.get('HTTP_X_FORWARDED_PROTO')
        env['wsgi.url_scheme'] = proto if proto else 'https' \
                                        if env.get('HTTPS') else 'http'
        env['REQUEST_SCHEME'] = env['wsgi.url_scheme']
        # Gruvi specific variables
        env['gruvi.version'] = version_info['version']
        env['gruvi.transport'] = self._transport
        env['gruvi.protocol'] = self._protocol


class HttpProtocol(MessageProtocol):
    """HTTP protocol."""

    identifier = '{0[name]}/{0[version]}'.format(version_info)

    def __init__(self, server_side, application=None, server_name=None, version='1.1',
                 timeout=None):
        """
        The *server_side* argument specifies whether this is a client or server
        side protocol.
        
        If this is a server side protocol, then the *wsgi_application* argument
        must be provided, and it must be a WSGI application callable.

        The *server_name* argument can be used to override the server name for
        server side protocols. If not provided, then the socket name of the
        listening socket will be used.
        """
        if server_side and not application:
            raise ValueError('application is required for server-side protocol')
        message_handler = WsgiHandler(application) if server_side else None
        super(HttpProtocol, self).__init__(message_handler)
        self._server_side = server_side
        self._server_name = server_name
        if version not in ('1.0', '1.1'):
            raise ValueError('version: unsupported version {0!s}'.format(version))
        self._version = version
        self._timeout = timeout
        self._create_parser()
        self._requests = []
        self._header_size = 0
        self._all_body_sizes = 0
        if server_side:
            target = getattr(application, '__qualname__', application.__name__)
            self._log.debug('using wsgi handler {}', target)
        self._response = None

    @property
    def server_side(self):
        """Return whether the protocol is server-side."""
        return self._server_side

    @property
    def server_name(self):
        """Return the server name."""
        return self._server_name

    def _create_parser(self):
        # Create a new CFFI http-parser and settings object that is hooked to
        # our callbacks.
        self._parser = _ffi.new('http_parser *')
        kind = _lib.HTTP_REQUEST if self._server_side else _lib.HTTP_RESPONSE
        _lib.http_parser_init(self._parser, kind)
        settings = _ffi.new('http_parser_settings *')
        refs = {}  # prevent garbage collection of cffi callbacks
        names = [name for name in dir(self) if name.startswith('on_')]
        for name in names:
            cbtype = 'http_cb' if 'complete' in name or 'begin' in name else 'http_data_cb'
            cb = refs[name] = _ffi.callback(cbtype, getattr(self, name))
            setattr(settings, name, cb)
        self._settings = settings
        self._callback_refs = refs

    def _update_header_size(self, length):
        # Add *length* to the size of the current HTTP header. If the size
        # becomes larger than the high-water mark then set an error. This is
        # needed because we cannot consume any of the read buffer until we've
        # got a full header and we can dispatch the message.
        self._header_size += length
        if self._header_size >= self._read_buffer_high:
            self._error = HttpError('HTTP header too large')
            return False
        self.read_buffer_size_changed()
        return True

    def _update_body_size(self, reader, oldsize, newsize):
        # Installed as the "on_buffer_size_changed" callback to the Reader
        # instances of all requests in the queue.
        self._all_body_sizes += (newsize - oldsize)

    def get_read_buffer_size(self):
        return self._header_size + self._queue.qsize() + self._all_body_sizes

    def on_message_begin(self, parser):
        # http-parser callback: prepare for a new message
        self._url = bytearray()
        self._field_name = bytearray()
        self._field_value = bytearray()
        assert self._header_size == 0
        self._message = HttpMessage()
        return 0

    def on_url(self, parser, at, length):
        # http-parser callback: got a piece of the URL
        if not self._update_header_size(length):
            return 1
        self._url.extend(_ffi.buffer(at, length))
        return 0

    def _complete_header_field(self, buf):
        # Add a chunk to a header field. May need to store away a previous
        # (field, value) pair.
        if self._field_value:
            # Store previous field_name, field_value pair
            if not self._message.body:
                self._message.headers.append((_ba2s(self._field_name),
                                              _ba2s(self._field_value)))
            else:
                self._message.trailers.append((_ba2s(self._field_name),
                                               _ba2s(self._field_value)))
            del self._field_name[:]
            del self._field_value[:]
        self._field_name.extend(buf)

    def _complete_header_value(self, buf):
        # Add a chunk to a header value. If buf == b'', then complete any
        # (field, value) pair that is in progress.
        if buf:
            self._field_value.extend(buf)
        elif self._field_name:
            if not self._message.body:
                self._message.headers.append((_ba2s(self._field_name),  
                                              _ba2s(self._field_value)))
            else:
                self._message.trailers.append((_ba2s(self._field_name),
                                               _ba2s(self._field_value)))
            del self._field_name[:]
            del self._field_value[:]

    def on_header_field(self, parser, at, length):
        # http-parser callback: got a piece of a header name
        if not self._update_header_size(length):
            return 1
        buf = _ffi.buffer(at, length)
        self._complete_header_field(buf)
        return 0

    def on_header_value(self, parser, at, length):
        # http-parser callback: got a piece of a header value
        if not self._update_header_size(length):
            return 1
        buf = _ffi.buffer(at, length)
        self._complete_header_value(buf)
        return 0

    def on_headers_complete(self, parser):
        # http-parser callback: the HTTP header is complete. This is the point
        # where we hand off the message to our consumer. Going forward,
        # on_body() will continue to write chunks of the body to message.body.
        self._complete_header_value(b'')
        m = self._message
        m.message_type = _lib.http_message_type(parser)
        m.version = '{0}.{1}'.format(parser.http_major, parser.http_minor)
        if self._server_side:
            m.method = _cd2s(_lib.http_method_str(parser.method))
            m.url = _ba2s(self._url)
            try:
                m.parsed_url = parse_url(self._url)
            except ValueError as e:
                self._error = HttpError('urlsplit(): {0!s}'.format(e))
                return 2  # error
            m.is_upgrade = _lib.http_is_upgrade(parser)
        else:
            m.status_code = parser.status_code
        m.should_keep_alive = _lib.http_should_keep_alive(parser)
        m.body = StreamReader(self._update_body_size)
        # Make the message available. There is no need to call
        # read_buffer_size_change() here as the changes sum up to 0.
        self._queue.put_nowait(m, self._header_size)
        self._header_size = 0
        # Return 1 if this is a HEAD request, 0 otherwise. This instructs the
        # parser whether or not a body follows.
        if not self._requests:
            return 0
        return 1 if self._requests.pop(0) == 'HEAD' else 0

    def on_body(self, parser, at, length):
        # http-parser callback: got a body chunk
        self._message.body.feed(bytes(_ffi.buffer(at, length)))
        return 0

    def on_message_complete(self, parser):
        # http-parser callback: the body ended
        # complete any trailers that might be present
        self._complete_header_value(b'')
        self._message.body.feed_eof()
        return 0

    def data_received(self, data):
        # Protocol callback
        nbytes = _lib.http_parser_execute(self._parser, self._settings, data, len(data))
        if nbytes != len(data):
            msg = _cd2s(_lib.http_errno_name(_lib.http_errno(self._parser)))
            self._log.debug('http_parser_execute(): {0}'.format(msg))
            self._error = HttpError('parse error: {0}'.format(msg))
            self._transport.close()

    def connection_lost(self, exc):
        # Protocol callback
        # Feed the EOF to the parser. It will tell us it if was unexpected.
        nbytes = _lib.http_parser_execute(self._parser, self._settings, b'', 0)
        if nbytes != 0:
            msg = _cd2s(_lib.http_errno_name(_lib.http_errno(self._parser)))
            self._log.debug('http_parser_execute(): {0}'.format(msg))
            if exc is None:
                exc = HttpError('parse error: {0}'.format(msg))
        super(HttpProtocol, self).connection_lost(exc)

    @switchpoint
    def request(self, method, url, headers=[], body=b''):
        """Make a new HTTP request.

        The *method* argument is the HTTP method to be used. It must be
        specified as a string, for example ``'GET'`` or ``'POST'``. The *url*
        argument specifies the URL and must be a string as well.

        The optional *headers* argument specifies extra HTTP headers to use in
        the request. It must be a list of (name, value) tuples, with name and
        value a string.

        The optional *body* argument may be used to specify a body to include
        in the request. It must be a ``bytes`` or ``str`` instance, a file-like
        object, or an iterable producing ``bytes`` or ``str`` instances. The
        default value for the body is the empty string ``b''`` which sends an
        empty body. To send potentially very large bodies, use the file or
        iterator interface. Using these interfaces will send the body under the
        "chunked" transfer encoding. This has the added advantage that the body
        size does not need to be known up front.

        The body may also be the ``None``, which means that you need to send
        the request body yourself. This is explained below.

        This method sends the request header, and if a body was specified, the
        request body as well. It then returns a :class:`HttpRequest` instance.
        
        If however you passsed a *body* of ``None`` then you must use the
        :meth:`HttpRequest.write` and :meth:`HttpRequest.end_request` methods
        if the :class:`HttpRequest` instance to send the request body yourself.
        This functionality is only useful if you want to sent trailers with the
        HTTP "chunked" encoding. Trailers are not normally used.

        The response to the request can be obtained by calling the
        :meth:`get_response` method. 

        You may make multiple requests before reading a response. This is
        called pipelining, and can improve per request latency greatly. For
        every request that you make, you must call :meth:`get-response` exactly
        once. The remote HTTP implementation will send by the responses in the
        same order as the requests.
        """
        if self._error:
            raise self._error
        elif self._closing or self._closed:
            raise HttpError('protocol is closing/closed')
        self._requests.append(method)
        request = HttpRequest(self._transport, self)
        request.start_request(method, url, headers, body)
        if body is None:
            return request
        if isinstance(body, bytes):
            request.write(body)
        elif hasattr(body, 'read'):
            while True:
                chunk = body.read(4096)
                if not chunk:
                    break
                request.write(chunk)
        elif hasattr(body, '__iter__'):
            for chunk in body:
                request.write(chunk)
        request.end_request()

    @switchpoint
    def get_response(self, timeout=-1):
        """Wait for and return a HTTP response.

        The return value is a :class:`HttpResponse` instance. When this method
        returns, only the response header has been read. The response body can
        be read using the :meth:`HttpResponse.read` and similar methods.

        Note that it is requires  that you read the entire body of each
        response if you use HTTP pipelining. Specifically, it is an error to
        call :meth:`get_response` when the body of the response returned by a
        previous invocation has not yet been fully read.
        """
        if self._error:
            raise self._error
        elif self._closed:
            raise HttpError('protocol is closed')
        if not self._requests and not self._queue.qsize():
            raise RuntimeError('there are no outstanding requests')
        if timeout < 0:
            timeout = self._timeout
        if self._response and not self._response.body.eof:
            raise RuntimeError('body of previous response not completely read')
        message = self._queue.get(timeout=timeout)
        self._response = message
        return HttpResponse(message)


class HttpClient(Client):
    """A HTTP client."""

    def __init__(self, timeout=None):
        """The optional *timeout* argument can be used to specify a timeout for
        the various network operations used within the client."""
        super(HttpClient, self).__init__(self._create_protocol, timeout=timeout)
        self._server_name = None

    @docfrom(Client.connect)
    def connect(self, address, **kwargs):
        # Capture the host name that we are connecting to. We need this for
        # generating "Host" headers in HTTP/1.1
        if isinstance(address, tuple):
            host, port = address[:2]  # len(address) == 4 for IPv6
            default_port = (port == HTTP_PORT and 'ssl' not in kwargs) \
                                or (port == HTTPS_PORT and 'ssl' in kwargs)
            if not default_port:
                host = '{0}:{1}'.format(host, port)
            self._server_name = host
        return super(HttpClient, self).connect(address, **kwargs)

    add_protocol_method(HttpProtocol.request, globals(), locals())
    add_protocol_method(HttpProtocol.get_response, globals(), locals())

    def _create_protocol(self):
        return HttpProtocol(False, server_name=self._server_name, timeout=self._timeout)


class HttpServer(Server):
    """A HTTP server."""

    def __init__(self, application, server_name=None, timeout=None):
        """The constructor takes the following arugments.  The *wsgi_handler*
        argument must be a WSGI callable. See `PEP 333
        <http://www.python.org/dev/peps/pep-0333/>`_.

        The optional *server_name* argument can be used to specify a server
        name. This might be needed by the WSGI application to construct
        absolute URLs. If not provided, then the host portion of the address
        passed to :meth:`listen` will be used.

        The optional *timeout* argument can be used to specify a timeout for
        the various network operations used within the server.
        """
        super(HttpServer, self).__init__(self._create_protocol, timeout)
        self._application = application
        self._server_name = server_name

    def _create_protocol(self):
        return HttpProtocol(True, self._application, server_name=self._server_name,
                            timeout=self._timeout)

########NEW FILE########
__FILENAME__ = http_ffi
#
# This file is part of Gruvi. Gruvi is free software available under the
# terms of the MIT license. See the file "LICENSE" that was provided
# together with this source file for the licensing terms.
#
# Copyright (c) 2012-2013 the Gruvi authors. See the file "AUTHORS" for a
# complete list.

from __future__ import absolute_import, print_function

import os.path
from cffi import FFI

__all__ = []


ffi = FFI()
ffi.cdef("""
    typedef struct http_parser http_parser;
    typedef struct http_parser_settings http_parser_settings;

    typedef int (*http_data_cb) (http_parser*, const char *at, size_t length);
    typedef int (*http_cb) (http_parser*);

    enum http_parser_type { HTTP_REQUEST, HTTP_RESPONSE, HTTP_BOTH, ... };
    enum http_parser_url_fields { UF_SCHEMA, UF_HOST, UF_PORT, UF_PATH,
                                  UF_QUERY, UF_FRAGMENT, UF_USERINFO, ... };

    struct http_parser {
      unsigned short http_major;
      unsigned short http_minor;
      unsigned short status_code;
      unsigned char method;
      void *data;
      ...;
    };

    struct http_parser_settings {
      http_cb      on_message_begin;
      http_data_cb on_url;
      http_cb      on_status_complete;
      http_data_cb on_header_field;
      http_data_cb on_header_value;
      http_cb      on_headers_complete;
      http_data_cb on_body;
      http_cb      on_message_complete;
      ...;
    };

    struct http_parser_url {
      uint16_t field_set;
      uint16_t port;
      struct { uint16_t off; uint16_t len; } field_data[];
      ...;
    };

    void http_parser_init(http_parser *parser, enum http_parser_type type);
    size_t http_parser_execute(http_parser *parser,
                               const http_parser_settings *settings,
                               const char *data,
                               size_t len);

    int http_should_keep_alive(const http_parser *parser);
    const char *http_method_str(enum http_method m);

    const char *http_errno_name(enum http_errno err);
    const char *http_errno_description(enum http_errno err);

    int http_parser_parse_url(const char *buf, size_t buflen,
                              int is_connect,
                              struct http_parser_url *u);
    void http_parser_pause(http_parser *parser, int paused);
    int http_body_is_final(const http_parser *parser);

    /* Extra functions to extract bitfields not supported by cffi */
    unsigned char http_message_type(http_parser *parser);
    unsigned char http_errno(http_parser *parser);
    unsigned char http_is_upgrade(http_parser *parser);

""")


parent, _ = os.path.split(os.path.abspath(__file__))
topdir, _ = os.path.split(parent)

lib = ffi.verify("""
    #include <stdlib.h>
    #include "src/http_parser.h"
    #include "src/http_parser.c"

    unsigned char http_message_type(http_parser *p) { return p->type; }
    unsigned char http_errno(http_parser *p) { return p->http_errno; }
    unsigned char http_is_upgrade(http_parser *p) { return p->upgrade; }

    """, modulename='_http_ffi', ext_package='gruvi', include_dirs=[topdir])

########NEW FILE########
__FILENAME__ = hub
#
# This file is part of gruvi. Gruvi is free software available under the
# terms of the MIT license. See the file "LICENSE" that was provided
# together with this source file for the licensing terms.
#
# Copyright (c) 2012-2014 the gruvi authors. See the file "AUTHORS" for a
# complete list.

from __future__ import absolute_import, print_function

import signal
import collections
import threading
import inspect
import textwrap
import itertools
import six

import pyuv
import fibers

from . import logging, util
from .errors import Timeout

__all__ = ['switchpoint', 'assert_no_switchpoints', 'switch_back', 'get_hub',
           'Hub', 'sleep']


# The @switchpoint decorator dynamically compiles the wrapping code at import
# time. The more obvious way of using a closure would result in Sphinx
# documenting the function as having the signature of func(*args, **kwargs).

_switchpoint_template = textwrap.dedent("""\
    def {name}{signature}:
        '''{docstring}'''
        hub = get_hub()
        if getcurrent() is hub:
            raise RuntimeError('cannot call switchpoint "{name}" from the Hub')
        if hub._noswitch_depth:
            raise AssertionError('switchpoint called from no-switch section')
        return _{name}{arglist}
""")

def switchpoint(func):
    """Mark *func* as a switchpoint.

    Use this function as a decorator to mark any method or function that may
    call :meth:`Hub.switch`, as follows::

        @switchpoint
        def myfunc():
            # May call Hub.switch() here
            pass
    
    You only need to mark methods and functions that invoke :meth:`Hub.switch`
    directly, not via intermediate callables.
    """
    name = func.__name__
    doc = func.__doc__ or ''
    if not doc.endswith('*This method is a switchpoint.*\n'):
        indent = [len(list(itertools.takewhile(str.isspace, line)))
                  for line in doc.splitlines() if line and not line.isspace()]
        indent = indent[0] if len(indent) == 1 else min(indent[1:] or [0])
        doc += '\n\n' + ' ' * indent + '*This method is a switchpoint.*\n'
    # Put the entire docstring on one line so that the line numbers in a
    # @switchpoint traceback match thsoe in _switchpoint_template
    doc = doc.replace('\n', '\\n')
    argspec = inspect.getargspec(func)
    signature = inspect.formatargspec(*argspec)
    arglist = inspect.formatargspec(*argspec, formatvalue=lambda x: '')
    funcdef = _switchpoint_template.format(name=name, signature=signature,
                                           docstring=doc, arglist=arglist)
    code = compile(funcdef, '@switchpoint', 'exec')
    globs = {'get_hub': get_hub, 'getcurrent': fibers.current, '_{0}'.format(name): func}
    six.exec_(code, globs)
    wrapped = globs[name]
    wrapped.func = func
    wrapped.switchpoint = True
    return wrapped


class assert_no_switchpoints(object):
    """Context manager to define a block in which no switchpoints may be called.

    Use this method in case you need to modify a shared state in a non-atomic
    way, and where you want to make suresure that you're not incidentally
    calling out indirectly to a switchpoint::

        with assert_no_switchpoints():
            do_something()
            do_something_else()
    
    If a switchpoint is called while the block is active, a ``AssertionError``
    is raised (even if the switchpoint did not switch).

    This context manager should not be overused. Normally you should know which
    functions are switchpoints or may end up calling switchpoints. Or
    alternatively you could refactor your code to make sure that a global state
    modification is done in a single leaf function.
    """

    __slots__ = ('_hub',)

    def __init__(self, hub=None):
        self._hub = hub or get_hub()

    def __enter__(self):
        self._hub._noswitch_depth += 1

    def __exit__(self, *exc_info):
        assert self._hub._noswitch_depth > 0
        self._hub._noswitch_depth -= 1
        self._hub = None


class switch_back(object):
    """A switch back object.

    A switch back object is a callable object that can be used to switch back
    to the current fiber after the latter has switched to the hub via
    :meth:`Hub.switch`.

    Idiomatic use of a switchback object is as follows::

      with switch_back(timeout) as switcher:
          start_async_job(job, callback=switcher)
          hub.switch()

    In this code fragment, ``start_async_job`` is a function that starts an
    asynchronous job that will call the passed callback when it is done.  After
    the job started, the fiber switches to the hub using :meth:`Hub.switch`.
    This causes the event loop to run. Once the asynchronous job is done, the
    switchback instance is called, which schedules a switch back, which in turn
    makes :meth:`Hub.switch` return.
    """

    __slots__ = ('_timeout', '_hub', '_fiber', '_cancelled', '_timer')

    def __init__(self, timeout=None, hub=None):
        """
        The a *timeout* argument of can be used to force a timeout after this
        many seconds. If a timeout happens, :meth:`Hub.switch` will raise a
        :class:`Timeout` exception. The default is None, meaning there is no
        timeout.

        The *hub* argument can be used to specfiy an alternate hub to use.
        By default, the Hub returned by :func:`get_hub` is used.
        """
        self._timeout = timeout
        self._hub = hub or get_hub()
        self._fiber = fibers.current()
        self._cancelled = False

    fiber = property(lambda self: self._fiber)
    timeout = property(lambda self: self._timeout)

    def __enter__(self):
        if self._timeout is not None:
            self._timer = pyuv.Timer(self._hub.loop)
            self._timer.start(self, self._timeout, 0)
        return self

    def __exit__(self, *exc_info):
        if self._timeout is not None:
            if not self._timer.closed:
                self._timer.close()
            self._timer = None
        self._cancelled = True
        self._hub = None
        self._fiber = None

    def throw(self, exc):
        """Cause :meth:`Hub.switch` to raise an exception."""
        if self._cancelled or not self.fiber.is_alive():
            return
        self._hub.run_callback(self.fiber.switch, exc)

    def __call__(self, *args, **kwargs):
        if self._cancelled or not self.fiber.is_alive():
            return
        if self._timeout is not None and args == (self._timer,):
            value = Timeout('Timeout in switch_back() block')
        else:
            value = (args, kwargs)
        self._hub.run_callback(self.fiber.switch, value)


_local = threading.local()

def get_hub():
    """Return the singleton instance of the hub.
    
    By default there is one Hub per thread.
    """
    try:
        hub = _local.hub
    except AttributeError:
        hub = _local.hub = Hub()
    return hub


class Hub(fibers.Fiber):
    """The central fiber scheduler.

    The hub is created automatically the first time it is needed, so it is not
    necessary to instantiate this class yourself.

    By default there is one hub per thread. To access the per thread instance,
    use :func:`get_hub`.

    The hub is used by fibers to pause themselves until a wake-up condition
    becomes true. See the documentation for :class:`switch_back` for details.

    Callbacks can be run in the hub's fiber by using :meth:`run_callback`.
    """

    # By default the Hub honors CTRL-C
    ignore_interrupt = False

    def __init__(self):
        if self.parent is not None:
            raise RuntimeError('Hub must be created in the root fiber')
        super(Hub, self).__init__(target=self.run)
        self.name = 'Hub'
        self.context = ''
        self._loop = pyuv.Loop()
        self._data = {}
        self._noswitch_depth = 0
        self._callbacks = collections.deque()
        # Thread IDs may be recycled when a thread exits. But as long as the
        # hub is alive, it won't be recycled so in that case we can use just
        # the ID as a check whether we are in the same thread or not.
        self._thread = util.get_thread_ident()
        self._stop_loop = pyuv.Async(self._loop, lambda h: self._loop.stop())
        self._term_loop = pyuv.Signal(self._loop)
        self._term_loop.start(self._on_sigint, signal.SIGINT)
        self._log = logging.get_logger()
        self._log.debug('new Hub for {.name}', threading.current_thread())
        self._closing = False
        self._error = None

    @property
    def loop(self):
        """The pyuv event loop used by this hub instance."""
        return self._loop

    @property
    def data(self):
        """A per-hub dict that can be used by applications to store data."""
        return self._data

    def _on_sigint(self, h, signo):
        # SIGINT handler. Terminate the hub and switch back to the root, where
        # a KeyboardInterrupt will be raised.
        if self.ignore_interrupt:
            return
        self._error = KeyboardInterrupt('CTRL-C pressed')
        self.close()

    def _interrupt_loop(self):
        # Interrupt the event loop
        if util.get_thread_ident() == self._thread:
            self._loop.stop()
        else:
            self._stop_loop.send()

    def close(self):
        """Close the hub.

        This stops the event loop, and causes the hub fiber to exit and
        switch back to the root fiber.

        This method is thread-safe. It is allowed call this method from a
        different thread than the one running the Hub.
        """
        if self._loop is None:
            return
        self._closing = True
        self._interrupt_loop()

    def run(self):
        # Target of Hub.switch().
        if self.current() is not self:
            raise RuntimeError('run() may only be called from the Hub')
        self._log.debug('starting hub fiber')
        while True:
            self._run_callbacks()
            if self._closing:
                break
            with assert_no_switchpoints(self):
                self._loop.run()
        # Hub is going to exit at this point. Clean everyting up.
        for handle in self._loop.handles:
            if not handle.closed:
                handle.close()
        # Run the loop until all asynchronous closes are handled.
        # For some reason it appears this needs to be run twice.
        while self._loop.run():
            self._log.debug('run loop another time to close handles')
        if getattr(_local, 'hub', None) is self:
            del _local.hub
        self._loop = None
        self._callbacks.clear()
        self._stop_loop = None
        self._term_loop = None
        self._log.debug('hub fiber terminated')
        if self._error:
            raise self._error

    def switch(self):
        """Switch to the hub.

        This method pauses the current fiber and runs the event loop.

        The caller should ensure that it has set up appropriate switchbacks
        using :class:`switch_back`. If a switchback was called, the return
        value is an ``(args, kwargs)`` tuple containing its arguments.  If a
        timeout or another exception was raised by the switchback, the
        exception is re-raised here.

        If this method is called from the root fiber then there is an
        additional case if the hub exited. If the hub exited due to a call to
        :meth:`close` then this method returns None. And if the hub exited due
        to a exception, that exception is re-raised here.
        """
        if self._loop is None or not self.is_alive():
            raise RuntimeError('hub is closed/dead')
        elif self.current() is self:
            raise RuntimeError('cannot switch to myself')
        elif util.get_thread_ident() != self._thread:
            raise RuntimeError('cannot switch from a different thread')
        value = super(Hub, self).switch()
        if isinstance(value, Exception):
            raise value
        return value

    def _run_callbacks(self):
        """Run registered callbacks."""
        for i in range(len(self._callbacks)):
            callback, args = self._callbacks.popleft()
            try:
                callback(*args)
            except Exception:
                self._log.exception('Uncaught exception in callback.')

    def run_callback(self, callback, *args):
        """Queue a callback to be called when the event loop next runs.

        The *callback* will be called with positional arguments *args* in the
        next iteration of the event loop. If you add multiple callbacks, they
        will be called in the order that you added them. The callback will run
        in the Hub's fiber.

        This method is thread-safe. It is allowed to queue a callback from a
        different thread than the one running the Hub.
        """
        if self._loop is None:
            raise RuntimeError('hub is closed')
        elif not callable(callback):
            raise TypeError('"callback": expecting a callable')
        self._callbacks.append((callback, args))  # atomic
        self._interrupt_loop()


@switchpoint
def sleep(secs):
    """Sleep for *secs* seconds."""
    hub = get_hub()
    try:
        with switch_back(secs):
            hub.switch()
    except Timeout:
        pass

########NEW FILE########
__FILENAME__ = jsonrpc
#
# This file is part of Gruvi. Gruvi is free software available under the
# terms of the MIT license. See the file "LICENSE" that was provided
# together with this source file for the licensing terms.
#
# Copyright (c) 2012-2014 the Gruvi authors. See the file "AUTHORS" for a
# complete list.

"""
This module implements a JSON-RPC client and server.

There are two main version of JSON-RPC: version 1.0 and version 2.0. These
version are not compatible with each other. Fortunately though, it is possible
to distinguish a version 1.0 from a version 2.0 message, and also the RPC model
in both versions is identical. This module therefore implements both versions
at the same time, in the following way:

 * A reply to an incoming message will always be of the same version as the
   incoming message.
 * A message originated by this module will use version 2.0 by default, but
   the default can be changed.

The "batch" feature of version 2.0 is not supported. It more relevant for
JSON-RPC over HTTP rather for that clients and servers that operate directly on
top of a connection.

This module provides to main classes: :class:`JsonRpcClient` and
:class:`JsonRpcServer`. The difference is merely who initiates the connection
at the transport level. The JSON-RPC protocol itself does not distinguish
between clients and servers.

Both the client and the server can get incoming messages. These may be method
calls (more common for servers), or notifications (in both cases). These
incoming messages may be handled by providing a message handler. Providing a
messasge handler is mandatory for a server while it's optional for a client.
Note that for getting regular or error returns to method calls it is not
required to have a message handler. These are taken care of by the protocol
implementation itself.

The signature of the message handler is: ``message_handler(message,
protocol)``.  Here, the *message* argument is a dictionary containing the
parsed JSON-RPC message, while *protocol* is the protocol instance for the
connection. The message handler is entirely responsible for dealing with the
message including sending a response if applicable.

Message handlers run in a separate "distpacher" fiber, one per connection. This
means that a client will have at most one dispatcher fiber, while a server will
have exactly one fiber per connection. The fact that message handlers run in a
separate fiber allows them to call into a switchpoint.
"""

from __future__ import absolute_import, print_function

import json
import six

from .hub import get_hub, switchpoint, switch_back
from .errors import *
from .protocols import ProtocolError, MessageProtocol
from .endpoints import Client, Server, add_protocol_method
from .sync import Queue
from .jsonrpc_ffi import lib as _lib, ffi as _ffi

__all__ = ['JsonRpcError', 'JsonRpcMethodCallError', 'JsonRpcProtocol',
           'JsonRpcClient', 'JsonRpcServer']


# JSON-RPC v2.0 error codes

errorcode = {}
_jsonrpc_errlist = {}

def add_error(code, name, message):
    globals()[name] = code
    errorcode[code] = name
    _jsonrpc_errlist[code] = message

add_error(-32000, 'SERVER_ERROR', 'Server error')
add_error(-32600, 'INVALID_REQUEST', 'Invalid request')
add_error(-32601, 'METHOD_NOT_FOUND', 'Method not found')
add_error(-32602, 'INVALID_PARAMS', 'Invalid parameters')
add_error(-32603, 'INTERNAL_ERROR', 'Internal error')
add_error(-32700, 'PARSE_ERROR', 'Parse error')

del add_error

def strerror( code):
    return _jsonrpc_errlist.get(code, 'No error description available')


class JsonRpcError(ProtocolError):
    """Exception that is raised in case of JSON-RPC protocol errors."""


class JsonRpcMethodCallError(JsonRpcError):
    """Exception that is raised when a error reply is received for a JSON-RPC
    method call."""

    def __init__(self, message, error):
        super(JsonRpcMethodCallError, self).__init__(message)
        self._error = error

    @property
    def error(self):
        return self._error


_request_keys = frozenset(('jsonrpc', 'id', 'method', 'params'))
_response_keys = frozenset(('jsonrpc', 'id', 'result', 'error'))

def check_message(message):
    """Validate a JSON-RPC message.
    
    The message must be a dictionary. Return the detected version number, or
    raise an exception on error.
    """
    if not isinstance(message, dict):
        raise ValueError('message must be an object')
    version = message.get('jsonrpc', '1.0')
    if version not in ('1.0', '2.0'):
        raise ValueError('illegal version: {0!r}'.format(version))
    method = message.get('method')
    if method is not None:
        # Request or notification
        if not isinstance(method, six.string_types):
            raise ValueError('method must be str, got {0!r}'.format(type(method).__name__))
        params = message.get('params')
        # There's annoying differences between v1.0 and v2.0. v2.0 allows
        # params to be absent while v1.0 doesn't. Also v2.0 allows keyword
        # params. Be lenient and allow both absent and none in both cases (but
        # never allow keyword arguments in v1.0).
        if version == '1.0':
            if not isinstance(params, (list, tuple)) and params is not None:
                raise ValueError('params must be list, got {0!r}'.format(type(params).__name__))
        elif version == '2.0':
            if not isinstance(params, (dict, list, tuple)) and params is not None:
                raise ValueError('params must be dict/list, got {0!r}'.format(type(params).__name__))
        allowed_keys = _request_keys
    else:
        # Success or error response
        if message.get('id') is None:
            raise ValueError('null or absent id not allowed in response')
        # There's again annoying differences between v1.0 and v2.0. 
        # v2.0 insists on absent result/error memmbers while v1.0 wants null.
        # Be lenient again and allow both for both versions.
        if message.get('result') and message.get('error'):
            raise ValueError('both result and error cannot be not-null')
        allowed_keys = _response_keys
    extra = set(message) - allowed_keys
    if extra:
        raise ValueError('extra keys: {0}', ', '.join(extra))
    return version


def message_type(message):
    """Return the type of *message*.

    The message must be valid, i.e. it should pass :func:`check_message`.
    """
    version = message.get('jsonrpc', '1.0')
    # JSON-RPC version 2.0 allows (but discourages) a "null" id for request...
    # It's pretty silly especially because null means a notification in version
    # 1.0. But we support it..
    if message.get('method') and 'id' in message and \
                (message['id'] is not None or version == '2.0'):
        return 'request'
    elif message.get('method'):
        return 'notification'
    elif message.get('error'):
        return 'error'
    # Result may be null and it's not an error unless error is not-null
    elif 'result' in message:
        return 'response'
    else:
        raise ValueError('illegal message')


_last_request_id = 0

def _get_request_id():
    global _last_request_id
    _last_request_id += 1
    reqid = 'gruvi.{0}'.format(_last_request_id)
    return reqid


def create_request(method, args=[], version='2.0'):
    """Create a JSON-RPC request."""
    msg = { 'id': _get_request_id(), 'method': method, 'params': args }
    if version == '2.0':
        msg['jsonrpc'] = version
    return msg

def create_response(request, result):
    """Create a JSON-RPC response message."""
    msg = { 'id': request['id'], 'result': result }
    version = request.get('jsonrpc', '1.0')
    if version == '1.0':
        msg['error'] = None
    elif version == '2.0':
        msg['jsonrpc'] = version
    return msg

def create_error(request, code=None, message=None, data=None, error=None):
    """Create a JSON-RPC error response message."""
    if code is None and error is None:
        raise ValueError('either "code" or "error" must be set')
    msg = { 'id': request['id'] }
    if code:
        error = { 'code': code }
        error['message'] = message or strerror(code)
        if data:
            error['data'] = data
    msg['error'] = error
    version = request.get('jsonrpc', '1.0')
    if version == '1.0':
        msg['result'] = None
    elif version == '2.0':
        msg['jsonrpc'] = version
    return msg

def create_notification(method, args=[], version='2.0'):
    """Create a JSON-RPC notification message."""
    msg = { 'method': method, 'params': args }
    if version == '1.0':
        msg['id'] = None
    elif version == '2.0':
        msg['jsonrpc'] = version
    return msg


class JsonRpcProtocol(MessageProtocol):
    """JSON-RPC protocol."""

    # Read buffer size is also the max message size
    # Total buffer size (split buffer + queue) may grow up to high watermark +
    # read_buffer_size.
    read_buffer_size = 65536

    def __init__(self, message_handler=None, version='2.0', timeout=None):
        super(JsonRpcProtocol, self).__init__(message_handler)
        self._version = version
        self._timeout = timeout
        self._buffer = bytearray()
        self._context = _ffi.new('struct split_context *')
        self._method_calls = {}
        self._tracefile = None

    def connection_lost(self, exc):
        # Protocol callback
        super(JsonRpcProtocol, self).connection_lost(exc)
        for switcher in self._method_calls.values():
            switcher.throw(self._error)
        self._method_calls.clear()
        if self._tracefile:
            self._tracefile.close()
            self._tracefile = None

    def get_read_buffer_size(self):
        # Return the size of the read buffer
        return len(self._buffer) + self._queue.qsize()

    def _set_buffer(self, data):
        # Note: "struct split_context" does not keep a reference to its fields!
        # Therefore use a Python variable to keep the cdata object alive
        self._keepalive = self._context.buf = _ffi.new('char[]', data)
        self._context.buflen = len(data)
        self._context.offset = 0

    def data_received(self, data):
        # Protocol callback
        self._set_buffer(data)
        offset = 0
        # Use the CFFI JSON splitter to delineate a single JSON dictionary from
        # the input stream. Then decode, parse and check it.
        while offset != len(data):
            error = _lib.json_split(self._context)
            if error and error != _lib.INCOMPLETE:
                self._error = JsonRpcError('json_split() error: {0}'.format(error))
                break
            size = len(self._buffer) + self._context.offset - offset
            if size > self._read_buffer_high or size == self._read_buffer_high \
                            and error == _lib.INCOMPLETE:
                self._error = JsonRpcError('message too large')
                break
            if error == _lib.INCOMPLETE:
                self._buffer.extend(data[offset:])
                break
            chunk = data[offset:self._context.offset]
            if self._buffer:
                self._buffer.extend(chunk)
                chunk = self._buffer
                self._buffer = bytearray()
            try:
                chunk = chunk.decode('utf8')
                message = json.loads(chunk)
                version = check_message(message)
            except UnicodeDecodeError as e:
                self._error = JsonRpcError('UTF-8 decoding error: {0!s}'.format(e))
                break
            except ValueError as e:
                self._error = JsonRpcError('Illegal JSON-RPC message: {0!s}'.format(e))
                break
            mtype = message_type(message)
            if self._tracefile:
                peername = self._transport.get_extra_info('peername', '(n/a)')
                self._tracefile.write('\n\n/* <- {} ({}; version {})*/\n'
                                       .format(peername, mtype, version))
                self._tracefile.write(serialized)
                self._tracefile.write('\n')
                self._tracefile.flush()
            # Now route the message to its correct destination
            if mtype in ('response', 'error') and message['id'] in self._method_calls:
                # Response to a method call issues through call_method()
                switcher = self._method_calls.pop(message['id'])
                switcher(message)
            elif self._dispatcher:
                # Queue to the dispatcher
                self._queue.put_nowait(message, size=size)
            else:
                self._log.warning('inbound {} but no message handler', mtype)
            offset = self._context.offset
        if self._error:
            self._transport.close()
            return
        self.read_buffer_size_changed()

    def set_trace(self, tracefile):
        """Log protocol exchanges to *tracefile*."""
        if isinstance(tracefile, six.text_types):
            tracefile = open(tracefile, 'w')
        self._tracefile = tracefile

    @switchpoint
    def send_message(self, message):
        """Send a JSON-RPC message.

        The *message* argument must be a dictionary, and must be a valid
        JSON-RPC message.
        """
        if self._error:
            raise self._error
        version = check_message(message)
        serialized = json.dumps(message, indent=2).encode('utf8')
        if self._tracefile:
            mtype = message_type(message)
            peername = self._transport.get_extra_info('peername', '(n/a)')
            self._tracefile.write('\n\n/* -> {} ({}; version {}*/\n'
                                    .format(peername, mtype, version))
            self._tracefile.write(serialized)
            self._tracefile.write('\n')
            self._tracefile.flush()
        self._may_write.wait()
        self._transport.write(serialized)

    @switchpoint
    def send_notification(self, method, *args):
        """Send a JSON-RPC notification.

        The notification *method* is sent with positional arguments *args*.
        """
        if self._error:
            raise self._error
        message = create_notification(method, args, version=self._version)
        self.send_message(message)

    @switchpoint
    def call_method(self, method, *args, **kwargs):
        """Call a JSON-RPC method and wait for its result.

        The method *method* is called with positional arguments *args*. On
        success, the ``'result'`` attribute of the JSON-RPC response is
        returned. On error, an exception is raised.

        This method also takes a an optional *timeout* keyword argument that
        overrides the default :attr:`timeout`.
        """
        if self._error:
            raise self._error
        timeout = kwargs.get('timeout', self._timeout)
        message = create_request(method, args, version=self._version)
        msgid = message['id']
        try:
            with switch_back(timeout) as switcher:
                self._method_calls[msgid] = switcher
                self.send_message(message)
                args, _ = self._hub.switch()
        finally:
            self._method_calls.pop(msgid, None)
        response = args[0]
        assert response['id'] == msgid
        error = response.get('error')
        if error:
            raise JsonRpcMethodCallError('error calling {0!r} method'.format(method), error)
        return response.get('result')


class JsonRpcClient(Client):
    """A JSON-RPC client."""

    def __init__(self, message_handler=None, version='2.0', timeout=30):
        """
        The *message_handler* argument specifies an optional JSON-RPC message
        handler. You need to use a message handler if you want to listen to
        notifications or you want to implement server-to-client method calls.
        If provided, the message handler it must be a callable with signature
        ``message_handler(message, protocol)``.

        The *version* argument specifies the JSON-RPC version to use. The
        *timeout* argument specifies the default timeout in seconds.
        """
        super(JsonRpcClient, self).__init__(self._create_protocol, timeout=timeout)
        self._message_handler = message_handler
        if version not in ('1.0', '2.0'):
            raise ValueError('version: must be "1.0" or "2.0"')
        self._version = version

    def _create_protocol(self):
        # Protocol factory
        return JsonRpcProtocol(self._message_handler, self._version, self._timeout)

    add_protocol_method(JsonRpcProtocol.send_message, globals(), locals())
    add_protocol_method(JsonRpcProtocol.send_notification, globals(), locals())
    add_protocol_method(JsonRpcProtocol.call_method, globals(), locals())


class JsonRpcServer(Server):
    """A JSON-RPC server."""

    max_connections = 1000

    def __init__(self, message_handler, version='2.0', timeout=30):
        """
        The *message_handler* argument specifies the JSON-RPC message handler.
        It must be a callable with signature ``message_handler(message,
        protocol)``. The message handler is called in a separate dispatcher
        fiber (one per connection).

        The *version* argument specifies the default JSON-RPC version. The
        *timeout* argument specifies the default timeout.
        """
        super(JsonRpcServer, self).__init__(self._create_protocol, timeout=timeout)
        self._message_handler = message_handler
        if version not in ('1.0', '2.0'):
            raise ValueError('version: must be "1.0" or "2.0"')
        self._version = version

    def _create_protocol(self):
        # Protocol factory
        return JsonRpcProtocol(self._message_handler, self._version, self._timeout)

########NEW FILE########
__FILENAME__ = jsonrpc_ffi
#
# This file is part of Gruvi. Gruvi is free software available under the
# terms of the MIT license. See the file "LICENSE" that was provided
# together with this source file for the licensing terms.
#
# Copyright (c) 2012-2013 the Gruvi authors. See the file "AUTHORS" for a
# complete list.

from __future__ import absolute_import, print_function

import os.path
from cffi import FFI

__all__ = []


ffi = FFI()
ffi.cdef("""
    #define OK ...
    #define INCOMPLETE ...
    #define ERROR ...

    struct split_context {
        const char *buf;
        int buflen;
        int offset;
        int error;
        ...;
    };

    int json_split(struct split_context *ctx);
""")

parent, _ = os.path.split(os.path.abspath(__file__))
topdir, _ = os.path.split(parent)
lib = ffi.verify("""
        #include "src/json_splitter.c"
        """, modulename='_jsonrpc_ffi', ext_package='gruvi', include_dirs=[topdir])

########NEW FILE########
__FILENAME__ = local
#
# This file is part of Gruvi. Gruvi is free software available under the
# terms of the MIT license. See the file "LICENSE" that was provided
# together with this source file for the licensing terms.
#
# Copyright (c) 2012-2013 the Gruvi authors. See the file "AUTHORS" for a
# complete list.

from __future__ import absolute_import, print_function

import weakref
import fibers

__all__ = ['local']


class local(object):
    """Fiber local storage.
    
    The API for local storage is the same as that of :class:`threading.local`.
    To create a fiber local value, instantiate this class and store attributes
    on it::

        mydata = local()
        mydata.x = 10

    The values of the attributes will be different (or unset) for different
    fibers.
    """

    def __init__(self):
        self.__dict__['_keys'] = weakref.WeakKeyDictionary()

    def __getattr__(self, key):
        current = fibers.current()
        try:
            return self._keys[current][key]
        except KeyError:
            raise AttributeError(key)

    def __setattr__(self, key, value):
        current = fibers.current()
        self._keys.setdefault(current, {})[key] = value

    def __delattr__(self, key):
        current = fibers.current()
        try:
            del self._keys[current][key]
        except KeyError:
            raise AttributeError(key)

########NEW FILE########
__FILENAME__ = logging
#
# This file is part of Gruvi. Gruvi is free software available under the
# terms of the MIT license. See the file "LICENSE" that was provided
# together with this source file for the licensing terms.
#
# Copyright (c) 2012-2014 the Gruvi authors. See the file "AUTHORS" for a
# complete list.

from __future__ import absolute_import, print_function

import os
import sys
import logging
import threading
import fibers
import six

from . import util

__all__ = ['get_logger']


PY26 = sys.version_info[:2] == (2, 6)

_logger_name = 'gruvi'
_logger_dict = {}


def get_logger(context='', name=None):
    """Return a logger for *context*.

    Return a :class:`ContextLogger` instance. The instance implements the
    standard library's :class:`logging.Logger` interface.
    """
    if name is None:
        name = _logger_name
    # To save memory, return a singleton instance for loggers without context.
    if not context:
        logger = _logger_dict.get(name)
        if logger is not None:
            return logger
    elif not isinstance(context, six.string_types):
        context = util.objref(context)
    logger = logging.getLogger(name)
    patch_logger(logger)
    show_stack = os.environ.get('DEBUG', '0') != '0'
    logger = ContextLogger(logger, context, show_stack)
    if not context:
        _logger_dict[name] = logger
    return logger


def patch_logger(logger):
    """Replace the ``findCaller()`` method of *logger* with a nop.

    This method uses :func:`sys._getframe` to look up the name and line number
    of its caller, causing a huge slowdown on PyPy.
    
    This function is used when debugging is not enabled.
    """
    if logger.findCaller is not logging.Logger.findCaller:
        return
    def findCaller(self, stack_info=False):
        return ('(unknown file)', 0, '(unknown function)', None)
    logger.findCaller = findCaller


def get_log_level():
    """Return the logging level based on $DEBUG and $VERBOSE."""
    try:
        verbose = int(os.environ['VERBOSE'])
    except (KeyError, ValueError):
        verbose = 3
    try:
        debug = int(os.environ['DEBUG'])
    except (KeyError, ValueError):
        debug = 0
    if verbose >= 4 or debug:
        level = logging.DEBUG
    elif verbose == 3:
        level = logging.INFO
    elif verbose == 2:
        level = logging.WARNING
    elif verbose == 1:
        level = logging.ERROR
    elif verbose <= 0:
        level = logging.CRITICAL
    return level


class ContextLogger(object):
    """A logger adapter that prepends a context string to log messages.
    
    It also supports passing arguments via '{}' format operations.
    """

    __slots__ = ('logger', 'context', 'show_stack')

    # This is not based on logging.LoggingAdapter because the 2.x and 3.x
    # implementations differ quite a bit, which means we would need to
    # reimplement almost the entire thing anyway.

    def __init__(self, logger, context='', show_stack=False):
        self.logger = logger
        self.context = context
        self.show_stack = show_stack

    def thread_info(self):
        tid = threading.current_thread().name
        if tid == 'MainThread': tid = 'Main'
        current = fibers.current()
        fid = getattr(current, 'name', util.objref(current)) if current.parent else 'Root'
        if tid == 'Main' and fid == 'Root':
            return '@'
        return '{0}:{1}'.format(tid, fid)

    def context_info(self):
        log_context = self.context
        fiber_context = getattr(fibers.current(), 'context', '')
        if not fiber_context:
            return log_context
        return '{0}:{1}'.format(log_context, fiber_context)

    def stack_info(self):
        if not self.show_stack:
            return ''
        f = sys._getframe(3)
        fname = os.path.split(f.f_code.co_filename)[1]
        funcname = f.f_code.co_name
        return '{0}:{1}!{2}()'.format(fname, f.f_lineno, funcname)

    def log(self, level, exc, msg, *args, **kwargs):
        if not self.logger.isEnabledFor(level):
            return
        prefix = [self.thread_info(), self.context_info(), self.stack_info()]
        while not prefix[-1]:
            prefix.pop()
        prefix = '|'.join(prefix)
        if args or kwargs:
            if PY26:
                msg = util.fixup_format_string(msg)
            msg = msg.format(*args, **kwargs)
        msg = '[{0}] {1}'.format(prefix, msg)
        self.logger._log(level, msg, (), exc_info=exc)

    def debug(self, msg, *args, **kwargs):
        self.log(logging.DEBUG, False, msg, *args, **kwargs)

    def info(self, msg, *args, **kwargs):
        self.log(logging.INFO, False, msg, *args, **kwargs)

    def warning(self, msg, *args, **kwargs):
        self.log(logging.WARNING, False, msg, *args, **kwargs)

    def error(self, msg, *args, **kwargs):
        self.log(logging.ERROR, False, msg, *args, **kwargs)

    def critical(self, msg, *args, **kwargs):
        self.log(logging.CRITICAL, False, msg, *args, **kwargs)

    def exception(self, msg, *args, **kwargs):
        self.log(logging.ERROR, True, msg, *args, **kwargs)

########NEW FILE########
__FILENAME__ = protocols
#
# This file is part of Gruvi. Gruvi is free software available under the
# terms of the MIT license. See the file "LICENSE" that was provided
# together with this source file for the licensing terms.
#
# Copyright (c) 2012-2014 the Gruvi authors. See the file "AUTHORS" for a
# complete list.

from __future__ import absolute_import, print_function

from .sync import Event, Queue
from .errors import Error, Cancelled
from .hub import get_hub, switchpoint
from .fibers import Fiber
from . import logging, util

__all__ = ['ProtocolError', 'BaseProtocol', 'Protocol', 'DatagramProtocol']


class ProtocolError(Error):
    """Base class for Protocol errors."""


class BaseProtocol(object):
    """Base class for all protocols."""

    read_buffer_size = 65536

    def __init__(self):
        self._transport = None
        self._log = logging.get_logger()
        self._hub = get_hub()
        self._read_buffer_size = 0
        self._read_buffer_high = self.read_buffer_size
        self._read_buffer_low = self.read_buffer_size // 2
        self._error = None
        self._may_write = Event()
        self._may_write.set()
        self._closing = False
        self._closed = Event()
        self._reading = False

    def connection_made(self, transport):
        """Called when a connection is made."""
        self._transport = transport
        self._reading = True

    def connection_lost(self, exc):
        """Called when a connection is lost."""
        # Unblock everybody who might be waiting.
        if self._error is None:
            self._error = exc
        self._closed.set()
        self._closing = False
        self._may_write.set()
        self._transport = None

    def pause_writing(self):
        """Called when the write buffer in the transport has exceeded the high
        water mark. The protocol should stop writing new data."""
        self._may_write.clear()

    def resume_writing(self):
        """Called when the write buffer in the transport has fallen below the
        low water mark. The protocol can start writing data again."""
        self._may_write.set()

    def get_read_buffer_size(self):
        """Return the current size of the read buffer."""
        return self._read_buffer_size

    def set_read_buffer_limits(self, high=None, low=None):
        """Set the low and high watermark for the read buffer."""
        if high is None:
            high = self.read_buffer_size
        if low is None:
            low = high // 2
        if low > high:
            low = high
        self._read_buffer_high = high
        self._read_buffer_low = low

    def read_buffer_size_changed(self):
        """Notify the protocol that the buffer size has changed."""
        bufsize = self.get_read_buffer_size()
        if bufsize >= self._read_buffer_high and self._reading:
            self._transport.pause_reading()
            self._reading = False
        elif bufsize <= self._read_buffer_low and not self._reading:
            self._transport.resume_reading()
            self._reading = True

    @switchpoint
    def close(self):
        """Close the protocol."""
        if self._closing or self._closed:
            return
        self._closing = True
        self._transport.close()
        self._closed.wait()


class Protocol(BaseProtocol):
    """Base class for stream oriented protocols."""

    def data_received(self, data):
        """A new chunk of data was received."""

    def eof_received(self):
        """An EOF was received."""

    @switchpoint
    def write(self, data):
        """Write *data* to the underlying transport.
        
        If the write bufer is currently above the high-water mark, then this
        method wait until it drops below the low-water mark.
        """
        self._may_write.wait()
        if self._error:
            raise self._error
        elif self._closing or self._closed:
            raise ProtocolError('protocol is closing/closed')
        self._transport.write(data)

    @switchpoint
    def writelines(self, seq):
        """Write all lines in *seq* to the underlying transport."""
        self._may_write.wait()
        if self._error:
            raise self._error
        elif self._closing or self._closed:
            raise ProtocolError('protocol is closing/closed')
        self._transport.writelines(seq)

    @switchpoint
    def write_eof(self):
        """Shut down the write direction."""
        self._may_write.wait()
        if self._error:
            raise self._error
        elif self._closing or self._closed:
            raise ProtocolError('protocol is closing/closed')
        self._transport.write_eof()


class MessageProtocol(Protocol):
    """Base class for message oriented protocols."""

    def __init__(self, message_handler=None):
        super(MessageProtocol, self).__init__()
        self._message_handler = message_handler
        self._queue = Queue()
        if message_handler:
            name = util.split_cap_words(type(self).__name__)[0]
            key = 'next_{0}_dispatcher'.format(name.lower())
            seq = self._hub.data.setdefault(key, 1)
            self._hub.data[key] += 1
            name = '{0}-{1}'.format(name, seq)
            self._dispatcher = Fiber(self._dispatch_loop, name=name)
            self._dispatcher.start()
        else:
            self._dispatcher = None

    def connection_lost(self, exc):
        # Protocol callback.
        # The connection is lost, which means that no requests that is either
        # outstanding or in-progress will be able to send output to the remote
        # peer. Therefore we just to discard everything here.
        super(MessageProtocol, self).connection_lost(exc)
        if self._dispatcher:
            self._dispatcher.cancel()
            self._dispatcher = None

    def message_received(self, message):
        # Protocol callback
        self._message_handler(self._transport, self, message)

    def _dispatch_loop(self):
        # Dispatcher loop: runs in a separate fiber and is only started
        # when there is a message handler.
        self._log.debug('dispatcher starting')
        assert self._message_handler is not None
        try:
            while True:
                message = self._queue.get()
                self.read_buffer_size_changed()
                self.message_received(message)
        except Cancelled as e:
            self._log.debug('dispatcher was canceled')
        except ProtocolError as e:
            self._log.error('{!s}, closing connection', e)
            self._error = e
            self._transport.close()
        except Exception as e:
            self._log.exception('uncaught exception in dispatcher')
            self._error = ProtocolError('uncaught exception in dispatcher')
            self._transport.close()
        self._log.debug('dispatcher exiting')


class DatagramProtocol(BaseProtocol):
    """Base classs for datagram oriented protocols."""

    def datagram_received(self, data, addr):
        """A new datagram was received."""

    def error_received(self, exc):
        """An error was received."""

########NEW FILE########
__FILENAME__ = socketpair
#
# This file is part of Gruvi. Gruvi is free software available under the
# terms of the MIT license. See the file "LICENSE" that was provided
# together with this source file for the licensing terms.
#
# Copyright (c) 2012-2014 the Gruvi authors. See the file "AUTHORS" for a
# complete list.

from __future__ import absolute_import, print_function

import sys
import errno
import socket

__all__ = ['socketpair']


if sys.platform.startswith('win'):
    assert errno.WSAEWOULDBLOCK == errno.EWOULDBLOCK


def socketpair(family=socket.AF_INET, type=socket.SOCK_STREAM, proto=0):
    """Emulate the Unix socketpair() syscall by connecting an AF_INET socket.

    This is useful on platforms like Windows that don't have one.
    """
    # We create a connected TCP socket. Note the trick with setblocking(0)
    # that prevents us from having to create a thread.
    lsock = socket.socket(family, type, proto)
    lsock.bind(('localhost', 0))
    lsock.listen(1)
    addr, port = lsock.getsockname()
    csock = socket.socket(family, type, proto)
    csock.setblocking(False)
    try:
        csock.connect((addr, port))
    except socket.error as e:
        if e.errno not in (errno.EAGAIN, errno.EWOULDBLOCK, errno.EINPROGRESS):
            lsock.close()
            csock.close()
            raise
    ssock, _ = lsock.accept()
    csock.setblocking(True)
    lsock.close()
    return (ssock, csock)

########NEW FILE########
__FILENAME__ = ssl
#
# This file is part of Gruvi. Gruvi is free software available under the
# terms of the MIT license. See the file "LICENSE" that was provided
# together with this source file for the licensing terms.
#
# Copyright (c) 2012-2014 the Gruvi authors. See the file "AUTHORS" for a
# complete list.

from __future__ import absolute_import, print_function

import errno
import socket
import io
import pyuv
import ssl
import six

from .compat import memoryview
from .transports import Transport, TransportError

if hasattr(socket, 'socketpair'):
    socketpair = socket.socketpair
else:
    from .socketpair import socketpair

if six.PY2:
    from . import sslcompat

__all__ = ['SslTransport']


class SslSocketInfo(object):
    """A read-only view of an SSLSocket.

    Instances of this class can be exposed to applications to get information
    about the current state of an SSL connection.
    """

    def __init__(self, sslobj, context):
        self._sslobj = sslobj
        self._context = context

    @property
    def context(self):
        """The SSL context."""
        return self._context

    def cipher(self):
        """The currently selected cipher."""
        return self._sslobj.cipher()

    def compression(self):
        """The currently selected compression algorithm."""
        if hasattr(self._sslobj, 'compression'):
            return self._sslobj.compression()
        return sslcompat.compression(self._sslobj)

    def getpeercert(self, binary_form=False):
        """The certificate of the peer, if any."""
        return self._sslobj.peer_certificate(binary_form)

    def get_channel_binding(self, cb_type='tls-unique'):
        """Channel bindings."""
        if cb_type != 'tls_unique':
            raise ValueError('unknown channel binding: {0}'.format(cb_type))
        if hasattr(self, _sslobj, 'tls_unique_cb'):
            return self._sslobj.tls_unique_cb()
        return sslcompat.tls_unique_sb(self._sslobj)


def write_to_socket(sock, data):
    """Write as much of *data* to the socket as possible, retrying short writes
    due to EINTR only."""
    offset = 0
    while offset != len(data):
        try:
            nbytes = sock.send(data[offset:])
        except (io.BlockingIOError, socket.error) as e:
            if e.errno == errno.EINTR:
                continue
            elif e.errno in (errno.EAGAIN, errno.EWOULDBLOCK):
                break
            raise
        offset += nbytes
    return offset

def read_from_socket(sock, bufsize):
    """Read as much data as possible from *sock*, using *bufsize* sized
    chunks. The result is returned as a list of buffers."""
    chunks = []
    while True:
        try:
            chunk = sock.recv(bufsize)
        except (io.BlockingIOError, socket.error) as e:
            if e.errno == errno.EINTR:
                continue
            elif e.errno in (errno.EAGAIN, errno.EWOULDBLOCK):
                break
            raise
        chunks.append(chunk)
    return chunks


def get_reason(exc):
    """Return the reason code from an SSLError exception."""
    # On Python 3.x the reason is available via exc.reason.
    if hasattr(exc, 'reason'):
        return exc.reason
    # .. but on 2.x we have to parse the error string (fortunately it is there)
    message = exc.args[1]
    p0 = message.find('error:')
    if p0 == -1:
        return
    p0 += 6
    p1 = message.find(':', p0)
    assert p1 != -1
    code = int(message[p0:p1], 16) & 0xfff
    return sslcompat.errorcode.get(code)


class SslPipe(object):
    """An SSL "Pipe".

    An SSL pipe allows you to communicate with an SSL/TLS protocol instance
    through memory buffers. It can be used to implement a security layer for an
    existing connection where you don't have access to the connection's file
    descriptor, or for some reason you don't want to use it.

    An SSL pipe can be in "wrapped" and "unwrapped" mode. In unwrapped mode,
    data is passed through untransformed. In wrapped mode, application level
    data is encrypted to SSL record level data and vice versa. The SSL record
    level is the lowest level in the SSL protocol suite and is what travels
    as-is over the wire.

    An SslPipe initially is in "unwrapped" mode. To start SSL, call
    :meth:`do_handshake`. To shutdown SSL again, call :meth:`unwrap`.
    """

    bufsize = 65536

    # This class uses a socket pair to communicate with the SSL protocol
    # instance. A "Memory BIO" would hav been more efficient, however the _ssl
    # module doesn't support that (as of March 2014 / Python 3.4). See alo:
    # http://mail.python.org/pipermail/python-ideas/2012-November/017686.html

    S_UNWRAPPED, S_DO_HANDSHAKE, S_WRAPPED, S_SHUTDOWN = range(4)

    def __init__(self, context, server_side, server_hostname=None):
        """
        The *context* argument specifies the :class:`ssl.SSLContext` to use.
        In Python 2.x this class isn't available and you can use
        :class:`sslcompat.SSLContext` instead.

        The *server_side* argument indicates whether this is a server side or
        client side socket.
        
        The optional *server_hostname* argument can be used to specify the
        hostname you are connecting to. You may only specify this parameter if
        the _ssl module supports Server Name Indication (SNI).
        """
        self._context = context
        self._server_side = server_side
        self._server_hostname = server_hostname
        self._state = self.S_UNWRAPPED
        self._sockets = socketpair()
        for sock in self._sockets:
            sock.setblocking(False)
        self._sslobj = None
        self._sslinfo = None
        self._need_ssldata = False

    @property
    def sslinfo(self):
        """An SSLSocketInfo instance describing the current SSL state."""
        if self._sslobj is None:
            return
        if self._sslinfo is None:
            self._sslinfo = SslSocketInfo(self._sslobj, self._context)
        return self._sslinfo

    @property
    def need_ssldata(self):
        """Whether more record level data is needed to complete a handshake
        that is currently in progress."""
        return self._need_ssldata

    def do_handshake(self):
        """Start the SSL handshake. Return a list of ssldata."""
        if self._sockets is None:
            raise RuntimeError('pipe was closed')
        if self._sslobj:
            raise RuntimeError('handshake in progress or completed')
        self._sslobj = self._context._wrap_socket(self._sockets[1], self._server_side,
                                                  self._server_hostname)
        self._state = self.S_DO_HANDSHAKE
        ssldata, appdata = self.feed_ssldata(b'')
        assert len(appdata) == 0
        return ssldata

    def shutdown(self):
        """Start the SSL shutdown sequence. Return a list of ssldata."""
        if self._sockets is None:
            raise RuntimeError('pipe was closed')
        if self._sslobj is None:
            raise RuntimeError('no security layer present')
        self._state = self.S_SHUTDOWN
        ssldata, appdata = self.feed_ssldata(b'')
        assert len(appdata) == 0
        return ssldata

    def feed_eof(self):
        """Send a potentially "ragged" EOF.
        
        This method will raise an SSL_ERROR_EOF exception if the EOF is
        unexpected.
        """
        if self._sockets is None:
            raise RuntimeError('pipe was closed')
        try:
            self._sockets[0].shutdown(socket.SHUT_WR)
            ssldata, appdata = self.feed_ssldata(b'')
        finally:
            self.close()
        assert len(ssldata) == 0
        assert appdata == []

    def close(self):
        """Close the SSL pipe."""
        if self._sockets is None:
            return
        self._sslobj = None
        self._sslinfo = None
        for sock in self._sockets:
            sock.close()
        self._sockets = None

    def feed_ssldata(self, data):
        """Feed SSL record level data into the pipe.

        The data must be a bytes instance. It is OK to send an empty bytes
        instance. This can be used to get ssldata for a handshake initiated by
        this endpoint.

        Return a (ssldata, appdata) tuple. The ssldata element is a list of
        buffers containing SSL data that needs to be sent to the remote SSL.

        The appdata element is a list of buffers containing plaintext data that
        needs to be forwarded to the application. The appdata list may contain
        an empty buffer indicating an SSL "close_notify" alert. This alert must
        be acknowledged by calling :meth:`shutdown`.
        """
        if self._sockets is None:
            raise RuntimeError('pipe was closed')
        if self._state == self.S_UNWRAPPED:
            # If unwrapped, pass plaintext data straight through.
            return ([], [data] if data else [])
        view = memoryview(data)
        offset = 0
        ssldata = []; appdata = []
        while True:
            self._need_ssldata = False
            offset += write_to_socket(self._sockets[0], view[offset:])
            try:
                if self._state == self.S_DO_HANDSHAKE:
                    # Call do_handshake() until it doesn't raise anymore.
                    self._sslobj.do_handshake()
                    self._state = self.S_WRAPPED
                if self._state == self.S_WRAPPED:
                    # Main state: read data from SSL until close_notify
                    while True:
                        chunk = self._sslobj.read(self.bufsize)
                        appdata.append(chunk)
                        if not chunk:  # close_notify
                            break
                if self._state == self.S_SHUTDOWN:
                    # Call shutdown() until it doesn't raise anymore.
                    self._sslobj.shutdown()
                    self._sslobj = None
                    self._state = self.S_UNWRAPPED
                if self._state == self.S_UNWRAPPED:
                    # Drain possible plaintext data after close_notify.
                    chunks = read_from_socket(self._sockets[1], self.bufsize)
                    appdata.extend(chunks)
            except ssl.SSLError as e:
                if e.errno not in (ssl.SSL_ERROR_WANT_READ, ssl.SSL_ERROR_WANT_WRITE):
                    raise
                self._need_ssldata = e.errno == ssl.SSL_ERROR_WANT_READ
            # Check for record level data that needs to be sent back.
            # Happens for the initial handshake and renegotiations.
            chunks = read_from_socket(self._sockets[0], self.bufsize)
            ssldata.extend(chunks)
            # We are done if we wrote all data.
            if offset == len(view):
                break
        return (ssldata, appdata)

    def feed_appdata(self, data, offset=0):
        """Feed plaintext data into the pipe.

        Return an (ssldata, offset) tuple. The ssldata element is a list of
        buffers containing record level data that needs to be sent to the
        remote SSL instance. The offset is the number of plaintext bytes that
        were processed, which may be less than the length of data.

        NOTE: In case of short writes, this call MUST be retried with the SAME
        buffer passed into the *data* argument (i.e. the ``id()`` must be the
        same). This is an OpenSSL requirement. A further particularity is that
        a short write will always have offset == 0, because the _ssl module
        does not enable partial writes. And even though the offset is zero,
        there will still be encrypted data in ssldata.
        """
        if self._state == self.S_UNWRAPPED:
            # pass through data in unwrapped mode
            return ([data[offset:]] if offset < len(data) else [], len(data))
        ssldata = []
        view = memoryview(data)
        while True:
            self._need_ssldata = False
            try:
                if offset < len(view):
                    offset += self._sslobj.write(view[offset:])
            except ssl.SSLError as e:
                # It is not allowed to call write() after unwrap() until the
                # close_notify is acknowledged. We return the condition to the
                # caller as a short write.
                if get_reason(e) == 'PROTOCOL_IS_SHUTDOWN':
                    e.errno = ssl.SSL_ERROR_WANT_READ
                if e.errno not in (ssl.SSL_ERROR_WANT_READ, ssl.SSL_ERROR_WANT_WRITE):
                    raise
                self._need_ssldata = e.errno == ssl.SSL_ERROR_WANT_READ
            # See if there's any record level data back for us.
            chunks = read_from_socket(self._sockets[0], self.bufsize)
            ssldata.extend(chunks)
            if offset >= len(view) or self._need_ssldata:
                break
        return (ssldata, offset)


class SslTransport(Transport):
    """An SSL/TLS transport."""

    def __init__(self, handle, context, server_side, server_hostname=None,
                 do_handshake_on_connect=True, close_on_unwrap=True):
        """
        The *context* argument specifies the :class:`ssl.SSLContext` to
        use. In Python 2.x this class isn't available and you can use
        :class:`sslcompat.SSLContext` instead.

        The *server_side* argument specifies whether this is a server side or a
        client side transport.
        
        The optional *server_hostname* argument can be used to specify the
        hostname you are connecting to. You may only specify this parameter if
        your Python version supports SNI.

        The optional *do_handshake_on_connect* argument specifies whether to to
        start the SSL handshake immediately. If False, then the connection will
        be unencrypted until :meth:`do_handshake` is called. The default is to
        start the handshake immediately.

        The optional *close_on_unwrap* argument specifies whether the transport
        should be closed automatically after an SSL "close_notify" alert is
        received. The default is to close the connection.
        """
        super(SslTransport, self).__init__(handle)
        self._sslpipe = SslPipe(context, server_side, server_hostname)
        self._do_handshake_on_connect = do_handshake_on_connect
        self._close_on_unwrap = close_on_unwrap
        self._write_backlog = []

    def start(self, protocol):
        """Bind to *protocol* and start calling callbacks on it."""
        super(SslTransport, self).start(protocol)
        if self._do_handshake_on_connect:
            self.do_handshake()

    def get_extra_info(self, name, default=None):
        """Return transport specific data.

        In addition to the extra info from :class:`Transport`, the SSL
        transport also exposes:

         * ``sslinfo`` - an instance of :class:`SslSocketInfo` describing the
           current SSL status.
        """
        if name == 'sslinfo':
            return self._sslpipe.sslinfo
        else:
            return super(SslTransport, self).get_extra_info(name, default)

    def _on_close_complete(self, handle):
        # Callback used with handle.close() in BaseTransport
        super(SslTransport, self)._on_close_complete(handle)
        self._sslpipe.close()
        self._sslpipe = None

    def write(self, data):
        """Write *data* to the transport."""
        if not isinstance(data, (bytes, bytearray, memoryview)):
            raise TypeError("data: expecting a bytes-like instance, got {0!r}"
                                .format(type(data).__name__))
        if self._error:
            raise self._error
        elif self._closing or self._handle.closed:
            raise TransportError('transport is closing/closed')
        elif len(data) == 0:
            return
        self._write_backlog.append([data, 0])
        self._write_buffer_size += len(data)
        if self._write_buffer_size >= self._write_buffer_high and self._writing:
            self._writing = False
            self._protocol.pause_writing()
        self._process_write_backlog()

    def _process_write_backlog(self):
        # Try to make progress on the write backlog.
        try:
            for i in range(len(self._write_backlog)):
                data, offset = self._write_backlog[0]
                if data:
                    ssldata, offset = self._sslpipe.feed_appdata(data, offset)
                elif offset:
                    ssldata, offset = self._sslpipe.do_handshake(), 1
                else:
                    ssldata, offset = self._sslpipe.shutdown(), 1
                # Temporarily set _closing to False to prevent
                # Transport.write() from raising an error.
                saved, self._closing = self._closing, False
                for chunk in ssldata:
                    super(SslTransport, self).write(chunk)
                self._closing = saved
                if offset < len(data):
                    self._write_backlog[0][1] = offset
                    # A short write means that a write is blocked on a read
                    # We need to enable reading if it is not enabled!!
                    assert self._sslpipe.need_ssldata
                    if not self._reading:
                        self.resume_reading()
                    break
                # An entire chunk from the backlog was processed. We can
                # delete it and reduce the outstanding buffer size.
                del self._write_backlog[0]
                self._write_buffer_size -= offset
        except ssl.SSLError as e:
            self._log.warning('SSL error {} (reason {})', e.errno, e.reason)
            self._error = e
            self.abort()

    def _read_callback(self, handle, data, error):
        # Callback used with handle.start_read().
        assert handle is self._handle
        try:
            if self._error:
                self._log.warning('ignore read status {} after close', error)
            elif error == pyuv.errno.UV_EOF:
                self._sslpipe.feed_eof()  # Raises SSL_ERROR_EOF if unexpected
                if not self._close_on_unwrap and self._protocol.eof_received():
                    self._log.debug('EOF received, protocol wants to continue')
                elif not self._closing:
                    self._log.debug('EOF received, closing transport')
                    self._error = TransportError('connection lost')
                    super(SslTransport, self).close()
            elif error:
                self._log.warning('pyuv error {} in read callback', error)
                self._error = TransportError.from_errno(error)
                self.abort()
            else:
                ssldata, appdata = self._sslpipe.feed_ssldata(data)
                for chunk in ssldata:
                    super(SslTransport, self).write(chunk)
                for chunk in appdata:
                    if chunk and not self._closing:
                        self._protocol.data_received(chunk)
                    elif not chunk and self._close_on_unwrap:
                        self.close()
        except ssl.SSLError as e:
            self._log.warning('SSL error {} (reason {})', e.errno, e.reason)
            self._error = e
            self.abort()
        # Process write backlog. A read could have unblocked a write.
        if not self._error:
            self._process_write_backlog()

    def pause_reading(self):
        """Stop reading data.

        Note that for SSL transports this call may be ignored if a handshake is
        currently going on. And also note that reading can be resumed without
        warning at any future point in time if a handshake occurs.

        The right way to handle this is as follows:
        
         * In :meth:`Transport.data_received` you should set a flag called
           "currently reading" every time the callback is called. Also you
           should call :meth:`pause_reading` if the buffer size is above the
           high-water mark.
         * When you consume data from the protocol, you should check whether
           the "currently reading" flag is set, and whether the current bufer
           size is below or equal to the low-water mark. If both conditions are
           met, you should call :meth:`resume_reading`.
        """
        if self._sslpipe.need_ssldata:
            return
        super(SslTransport, self).pause_reading()

    def do_handshake(self):
        """Start the SSL handshake.

        This method only needs to be called if this transport was created with
        *do_handshake_on_connect* set to False (the default is True).

        The handshake needs to be synchronized between the both endpoints, so
        that SSL record level data is not incidentially interpreted as
        plaintext. Usually this is done by starting the handshake directly
        after a connection is established, but you can also use an application
        level protocol.
        """
        if self._error:
            raise self._error
        elif self._closing or self._handle.closed:
            raise TransportError('SSL transport is closing/closed')
        self._write_backlog.append([b'', True])
        self._write_buffer_size += 1
        self._process_write_backlog()

    def unwrap(self):
        """Remove the security layer.

        Use this method only if you want to send plaintext data on the
        connection after the security layer has been removed. In all other
        cases, use :meth:`close`.

        If the unwrap is initiated by us, then any data sent after it will be
        buffered until the corresponding close_notify response is received from
        our peer.
  
        If the unwrap is initiated by the remote peer, then this method will
        acknowledge it. You need an application level protocol to determine
        when to do this because the receipt of a close_notify is not
        communicated to the application.
        """
        if self._error:
            raise self._error
        elif self._closing or self._handle.closed:
            raise TransportError('SSL transport is closing/closed')
        self._close_on_unwrap = False
        self._write_backlog.append([b'', False])
        self._write_buffer_size += 1
        self._process_write_backlog()

    def can_write_eof(self):
        # SSL/TLS does not support a half close. Theoretically we could return
        # True here when unwrapped.
        return False

    def close(self):
        """Cleanly shut down the SSL protocol and close the socket."""
        if self._closing or self._handle.closed:
            return
        self._closing = True
        self._write_backlog.append([b'', False])
        self._write_buffer_size += 1
        self._process_write_backlog()

########NEW FILE########
__FILENAME__ = sslcompat
#
# This file is part of Gruvi. Gruvi is free software available under the
# terms of the MIT license. See the file "LICENSE" that was provided
# together with this source file for the licensing terms.
#
# Copyright (c) 2012-2014 the Gruvi authors. See the file "AUTHORS" for a
# complete list.

from __future__ import absolute_import, print_function

import sys

if sys.version_info[0] == 3:
    raise ImportError('Only import this module in Python 2.6 or 2.7.')

import ssl, _ssl
from . import _sslcompat

__all__ = []

# Export constants from _sslcompat
for key in dir(_sslcompat):
    if key[:4].isupper():  # also export FOO_BARv1
        value = getattr(_sslcompat, key)
        globals()[key] = value

errorcode = _sslcompat.errorcode

if hasattr(ssl, '_DEFAULT_CIPHERS'):
    DEFAULT_CIPHERS = ssl._DEFAULT_CIPHERS
else:
    DEFAULT_CIPHERS = 'DEFAULT:!aNULL:!eNULL:!LOW:!EXPORT:!SSLv2'


class SSLContext(object):
    """Compatiblity SSLContext object for Python 2.6 and 2.7.

    This isn't a real SSLContext so it doesn't do things like session
    caching. The purpose is to store arguments to :func:`ssl.wrap_socket` in a
    way that is compatible with Py3k.
    """

    def __init__(self, protocol):
        """
        The *protocol* parameter can be used to set the SSL protocol version.
        The default is to use SSLv3 or higher. This is achieved by setting
        protocol to ``PROTOCOL_SSLv23`` and :attr:`options` to ``OP_NO_SSLv2``.
        Note that ``PROTOCOL_SSLv23`` is a bit of a misnomer as it includes any
        supported TLS version as well.
        """
        # [server_side, keyfile, certfile, cert_reqs, ssl_version, ca_certs]
        self._ssl_args = [False, None, None, ssl.CERT_NONE, protocol, None]
        # Implement the same defaults as the Python ssl module
        self._ciphers = DEFAULT_CIPHERS
        self._options = _sslcompat.OP_ALL & _sslcompat.OP_NO_SSLv2
        self._dh_params = None

    def _wrap_socket(self, sock, server_side=False, server_hostname=None):
        # We need to do some magic to support anonymous DH authentication. Anon
        # DH doesn't need a certfile and a keyfile, but the Python 2.x
        # _ssl.sslwrap raises an exception if these are absent for server side
        # sockets. So the workaround is to create the socket as a client-side
        # socket and then flip it afterwards if needed.
        sslobj = _ssl.sslwrap(sock, *self._ssl_args)
        if self._dh_params:
            _sslcompat.load_dh_params(sslobj, self._dh_params)
        if server_side:
            _sslcompat.set_accept_state(sslobj)
        if self._ciphers:
            _sslcompat.set_ciphers(sslobj, self._ciphers)
        _sslcompat.set_options(sslobj, self._options)
        if server_hostname:
            _sslcompat.set_tlsext_host_name(server_hostname)
        return sslobj

    @property
    def protocol(self):
        return self._ssl_args[4]

    @property
    def verify_mode(self):
        return self._ssl_args[3]

    @verify_mode.setter
    def verify_mode(self, cert_reqs):
        self._ssl_args[3] = cert_reqs

    @property
    def options(self):
        return self._options

    @options.setter
    def options(self, options):
        self._options = options

    def load_verify_locations(self, ca_certs):
        self._ssl_args[5] = ca_certs

    def load_cert_chain(self, certfile, keyfile):
        self._ssl_args[1] = certfile
        self._ssl_args[2] = keyfile

    def set_ciphers(self, ciphers):
        self._ciphers = ciphers

    def load_dh_params(self, dh_params):
        self._dh_params = dh_params


def compression(sslobj):
    """Return the current compression method for *sslobj*."""
    if hasattr(sslobj, '_sslobj'):
        sslobj = sslobj._sslobj
    return _sslcompat.compression(_sslobj)


def tls_unique_cb(sslobj):
    """Get the "tls-unique" channel bindings for *sslobj."""
    if hasattr(sslobj, '_sslobj'):
        sslobj = sslobj._sslobj
    return _sslcompat.tls_unique_cb(_sslobj)

########NEW FILE########
__FILENAME__ = stream
#
# This file is part of Gruvi. Gruvi is free software available under the
# terms of the MIT license. See the file "LICENSE" that was provided
# together with this source file for the licensing terms.
#
# Copyright (c) 2012-2014 the Gruvi authors. See the file "AUTHORS" for a
# complete list.

from __future__ import absolute_import, print_function

import sys
import six

import gruvi
from .sync import Event
from .errors import Cancelled
from .protocols import Protocol
from .endpoints import Client, Server, add_protocol_method
from .hub import switchpoint
from .util import docfrom

__all__ = ['StreamReader', 'StreamProtocol', 'StreamClient', 'StreamServer']


class StreamReader(object):
    """A stream reader.

    This is a blocking interface that provides :meth:`read`, :meth:`readline`
    and similar methods on top of a memory buffer.
    """

    def __init__(self, on_buffer_size_change=None):
        self._can_read =  Event()
        self._buffers = []
        self._buffer_size = 0
        self._offset = 0
        self._eof = False
        self._error = None
        self._on_buffer_size_change = on_buffer_size_change

    @property
    def buffer_size(self):
        """Return the amount of bytes currently in the buffer."""
        return self._buffer_size

    @property
    def eof(self):
        """Return whether the stream is currently at end-of-file."""
        return self._eof and self._buffer_size == 0

    def feed(self, data):
        """Add *data* to the buffer."""
        self._buffers.append(data)
        oldsize = self._buffer_size
        self._buffer_size += len(data)
        if self._on_buffer_size_change:
            self._on_buffer_size_change(self, oldsize, self._buffer_size)
        self._can_read.set()

    def feed_eof(self):
        """Set the EOF condition."""
        self._eof = True
        self._can_read.set()

    def feed_error(self, exc):
        """Set the error condition to *exc*."""
        self._error = exc
        self._can_read.set()

    @switchpoint
    def _read_until(self, delim, limit=-1):
        """Read until *delim*, or until EOF if *delim* is not provided.
        If *limit* is positive then read at most this many bytes.
        """
        chunks = []
        bytes_read = 0
        while True:
            # Special case for limit == 0
            if limit != 0:
                self._can_read.wait()
            # _can_read is set: we have data, or there is an EOF of error
            if not self._buffers:
                break
            # Find start and end offset in current buffer (if any)
            pos = self._buffers[0].find(delim, self._offset) if delim else -1
            endpos = len(self._buffers[0]) if pos < 0 else pos + len(delim)
            nbytes = endpos - self._offset
            # Reading too many bytes?
            if limit >= 0 and bytes_read + nbytes > limit:
                nbytes = limit - bytes_read
                endpos = self._offset + nbytes
            # Try to move a buffer instead of copying.
            if self._offset == 0 and endpos == len(self._buffers[0]):
                chunks.append(self._buffers.pop(0))
            else:
                chunks.append(self._buffers[0][self._offset:endpos])
                self._offset = endpos
                if self._offset == len(self._buffers[0]):
                    del self._buffers[0]
                    self._offset = 0
            # Adjust buffer
            bytes_read += nbytes
            oldsize = self._buffer_size
            self._buffer_size -= nbytes
            if self._on_buffer_size_change:
                self._on_buffer_size_change(self, oldsize, self._buffer_size)
            if not self._buffers and not self._eof and not self._error:
                self._can_read.clear()
            # Done? If there is no delimiter, prefer to return only one chunk
            # as a short write to prevent copying.
            if pos >= 0 or bytes_read == limit \
                        or limit >= 0 and not delim \
                        or limit < 0 and (self._eof or self._error) and not self._buffers:
                break
        if len(chunks) == 1:
            return chunks[0]
        elif self._error and not chunks:
            raise self._error
        return b''.join(chunks)

    @switchpoint
    def read(self, size=-1):
        """Read up to *size* bytes.
        
        If *size* is not specified or negative, read until EOF.
        """
        return self._read_until(b'', size)

    @switchpoint
    def readline(self, limit=-1):
        """Read a single line.

        If EOF is reached before a full line can be read, a partial line is
        returned. If *limit* is specified, at most this many bytes will be read.
        """
        return self._read_until(b'\n', limit)

    @switchpoint
    def readlines(self, hint=-1):
        """Read lines until EOF, and return them as a list.

        If *hint* is specified, then lines will be read until their total size
        will be equal to or larger than *hint*, or until EOF occurs.
        """
        lines = []
        bytes_read = 0
        while True:
            try:
                line = self.readline()
            except Exception as e:
                # If there's already some lines read, we return those without
                # an exception first. Future invocatations of methods on
                # StreamReader will raise the exception again.
                if self._error and lines:
                    break
                six.reraise(*sys.exc_info())
            if not line:
                break
            lines.append(line)
            bytes_read += len(line)
            if hint >= 0 and bytes_read > hint:
                break
        if not lines and self._error:
            raise self._error
        return lines

    @switchpoint
    def __iter__(self):
        """Generate lines until EOF is reached."""
        while True:
            line = self.readline()
            if not line:
                break
            yield line


class StreamProtocol(Protocol):
    """Byte stream protocol."""

    def __init__(self):
        super(StreamProtocol, self).__init__()
        self._reader = StreamReader(self._update_read_buffer)

    def data_received(self, data):
        # Protocol callback
        assert self._reading is True
        self._reader.feed(data)

    def eof_received(self):
        # Protocol callback
        self._reader.feed_eof()
        # Always pass the EOF to the handler
        return True

    def connection_lost(self, exc):
        # Protocol callback
        super(StreamProtocol, self).connection_lost(exc)
        if self._error:
            self._reader.feed_error(self._error)

    def _update_read_buffer(self, reader, oldsize, newsize):
        """Update the read buffer size and pause/resume reading."""
        self._read_buffer_size = newsize
        self.read_buffer_size_changed()

    @docfrom(StreamReader.read)
    @switchpoint
    def read(self, size=-1):
        return self._reader.read(size)

    @docfrom(StreamReader.readline)
    @switchpoint
    def readline(self, limit=-1):
        return self._reader.readline(limit)

    @docfrom(StreamReader.readlines)
    @switchpoint
    def readlines(self, hint=-1):
        return self._reader.readlines(hint)

    @docfrom(StreamReader.__iter__)
    @switchpoint
    def __iter__(self):
        return self._reader.__iter__()


class StreamClient(Client):
    """A stream client."""

    def __init__(self, timeout=None):
        super(StreamClient, self).__init__(StreamProtocol)

    add_protocol_method(StreamProtocol.read, globals(), locals())
    add_protocol_method(StreamProtocol.readline, globals(), locals())
    add_protocol_method(StreamProtocol.readlines, globals(), locals())
    add_protocol_method(StreamProtocol.__iter__, globals(), locals())

    add_protocol_method(StreamProtocol.write, globals(), locals())
    add_protocol_method(StreamProtocol.writelines, globals(), locals())
    add_protocol_method(StreamProtocol.write_eof, globals(), locals())
    

class StreamServer(Server):
    """A stream server."""

    def __init__(self, stream_handler, timeout=None):
        super(StreamServer, self).__init__(StreamProtocol)
        self._stream_handler = stream_handler
        self._dispatchers = {}

    def connection_made(self, transport, protocol):
        self._dispatchers[protocol] = gruvi.spawn(self._dispatch_stream, transport, protocol)

    def _dispatch_stream(self, transport, protocol):
        self._log.debug('stream handler started')
        try:
            self._stream_handler(protocol)
        except Cancelled:
            self._log.debug('stream handler cancelled')
        except Exception as e:
            self._log.exception('uncaught exception in stream handler')
        transport.close()
        self._log.debug('stream handler exiting')

    def connection_lost(self, transport, protocol, exc=None):
        dispatcher = self._dispatchers.pop(protocol)
        dispatcher.cancel()

########NEW FILE########
__FILENAME__ = sync
#
# This file is part of Gruvi. Gruvi is free software available under the
# terms of the MIT license. See the file "LICENSE" that was provided
# together with this source file for the licensing terms.
#
# Copyright (c) 2012-2014 the Gruvi authors. See the file "AUTHORS" for a
# complete list.

from __future__ import absolute_import, print_function

import fibers
import threading
import heapq

from .hub import switchpoint, get_hub, switch_back
from .errors import Timeout, Cancelled

__all__ = ['Lock', 'RLock', 'Event', 'Condition', 'QueueEmpty', 'QueueFull',
           'Queue', 'LifoQueue', 'PriorityQueue']


class _Lock(object):
    """Base class for regular and re-entrant locks."""

    __slots__ = ('_reentrant', '_lock', '_locked', '_owner', '_waiters')

    def __init__(self, reentrant):
        # Allocate a new lock
        self._reentrant = reentrant
        self._lock = threading.Lock()
        self._locked = 0
        self._owner = None
        # The _waiters attribute is initialized with a list on first use. We
        # use a list instead of a deque to save on memory, even if a list has
        # worse asymptotic performance. A lock is a very fundamental data
        # structure that should be fast and small. On my 64-bit system, an
        # empty deque is 624 bytes vs just 72 for a list.
        self._waiters = None

    def locked(self):
        """Whether the lock is currently locked."""
        return self._locked

    @switchpoint
    def acquire(self, blocking=True, timeout=None):
        """Acquire the lock.

        If *blocking* is true (the default), then this will block until the
        lock can be acquired. The *timeout* parameter specifies an optional
        timeout in seconds.

        The return value is a boolean indicating whether the lock was acquired.
        """
        hub = get_hub()
        try:
            with switch_back(timeout) as switcher:
                with self._lock:
                    if not self._locked:
                        self._locked = 1
                        self._owner = fibers.current()
                        return True
                    elif self._reentrant and self._owner is fibers.current():
                        self._locked += 1
                        return True
                    elif not blocking:
                        return False
                    if self._waiters is None:
                        self._waiters = []
                    self._waiters.append(switcher)
                # It is safe to call hub.switch() outside the lock. Another
                # thread could have called acquire()+release(), thereby firing
                # the switchback. However the switchback only schedules the
                # switchback in our hub, it won't execute it yet. So the
                # switchback won't actually happen until we switch to the hub.
                hub.switch()
                # Here the lock should be ours
                assert self._owner is fibers.current()
        except Exception as e:
            # Likely a Timeout but could also be e.g. Cancelled
            with self._lock:
                # Search for switcher from the end which is where we're more
                # likely to find it.
                for i in reversed(range(len(self._waiters))):
                    if self._waiters[i] is switcher:
                        del self._waiters[i]
                        break
            if isinstance(e, Timeout):
                return False
            raise
        return True

    def release(self):
        """Release the lock."""
        with self._lock:
            if not self._locked:
                raise RuntimeError('lock not currently held')
            elif self._reentrant and self._owner is not fibers.current():
                raise RuntimeError('lock not owned by this fiber')
            if self._locked > 1:
                self._locked -= 1
            elif not self._waiters:
                self._locked = 0
                self._owner = None
            else:
                # Don't unlock + lock but rather pass the lock directly to the
                # fiber that is next in line.
                switcher = self._waiters.pop(0)
                self._owner = switcher.fiber
                switcher()

    __enter__ = acquire
    __exit__ = lambda self,*exc_info: self.release()

    # Internal API used by Condition instances.

    def _acquire_restore(self, state):
        # Acquire a lock and restore the owner and lock count.
        self.acquire()
        self._owner, self._locked = state

    def _release_save(self):
        # Release a lock even if it is locked multiple times. Return the state.
        state = self._owner, self._locked
        self.release()
        return state


class Lock(_Lock):
    """A lock object.

    The lock is acquired using :meth:`acquire` and released using
    :meth:`release`. A lock can also be used as a context manager.

    A Lock is thread safe. This class is the fiber-aware equivalent of
    :class:`threading.Lock`.
    """

    __slots__ = _Lock.__slots__

    def __init__(self):
        super(Lock, self).__init__(False)


class RLock(_Lock):
    """A re-entrant lock object.

    A re-entrant lock has the notion of a "lock owner" and a "lock count". If a
    re-entrant lock is acquired, and it was already acquired by the current
    fiber, then the lock count is increased and the acquire call will be
    successful. Unlocking a re-entrant lock may only be done by the lock owner.
    The lock becomes unlocked only after it is released as many times as it was
    acquired.

    A RLock is thread safe. This class is the fiber-aware equivalent of
    :class:`threading.RLock`.
    """

    __slots__ = _Lock.__slots__

    def __init__(self):
        super(RLock, self).__init__(True)


# A few words on the use of fiber locks (Lock) vs thread locks (threading.Lock)
# in the code below.
#
# There is no difference between both locks from a safety point of view. Both
# locks are thread-safe (which implies they are fiber-safe as well). The
# difference is who gets blocked when trying to acquire a lock that is already
# locked. With a fiber lock only the current fiber is blocked and other fibers
# in current thread can continue (and fibers in other threads as well, of
# course). With a thread lock the entire current thread is blocked including
# all its fibers.
#
# This means that if we never call hub.switch() when a lock is held, fiber and
# thread locks are completely identical. In this case there's a benefit in
# using thread locks because i) they are smaller and faster, and ii) it makes
# it possible for non-switchpoints to acquire the lock. An example of the
# latter case is Queue.put_nowait().


class Event(object):
    """An Event.

    An event is a synchronization primitive that can make zero or more fibers
    wait for a programmer-raised event.

    An event contains an internal flag that is initially False. The flag can be
    set using the :meth:`set` method and cleared using the :meth:`clear`
    method.  Fibers can wait for the flag to become set using :meth:`wait`.

    Events are level triggered, meaning that the condition set by :meth:`set`
    is "sticky". Setting the event will unblock all current waiters and will
    cause future calls to :meth:`wait` not to block, until :meth:`clear` is
    called again.

    An event is thread safe. This class is the fiber-aware equivalent of
    :class:`threading.Event`.
    """

    __slots__ = ('_flag', '_lock', '_waiters')

    def __init__(self):
        self._flag = False
        self._lock = threading.Lock()
        self._waiters = None

    def __nonzero__(self):
        return self._flag

    __bool__ = __nonzero__
    is_set = __nonzero__

    def set(self):
        """Set the internal flag, and wake up any fibers blocked on :meth:`wait`."""
        with self._lock:
            if self._flag:
                return
            self._flag = True
            if not self._waiters:
                return
            for notify in self._waiters:
                notify()
            del self._waiters[:]

    def clear(self):
        """Clear the internal flag."""
        with self._lock:
            self._flag = False

    @switchpoint
    def wait(self, timeout=None):
        """If the internal flag is set, return immediately. Otherwise block
        until the flag gets set by another fiber calling :meth:`set`."""
        if self._flag:
            return
        hub = get_hub()
        self._lock.acquire()
        try:
            with switch_back(timeout) as switcher:
                if self._waiters is None:
                    self._waiters = []
                self._waiters.append(switcher)
                self._lock.release()
                try:
                    hub.switch()
                finally:
                    self._lock.acquire()
        except Exception as e:
            for i in reversed(range(len(self._waiters))):
                if self._waiters[i] is switcher:
                    del self._waiters[i]
                    break
            raise
        finally:
            self._lock.release()


# Utility functions for a condition to work with both Locks and RLocks.

def is_locked(lock):
    """Return whether a lock is locked.

    Suppors :class:`Lock`, :class:`RLock`, :class:`threading.Lock` and
    :class:`threading.RLock` instances.
    """
    if hasattr(lock, 'locked'):
        return lock.locked()
    elif hasattr(lock, '_is_owned'):
        return lock._is_owned()
    else:
        raise TypeError('expecting Lock/RLock')

def acquire_restore(lock, state):
    """Acquire a lock and restore its state."""
    if hasattr(lock, '_acquire_restore'):
        lock._acquire_restore(state)
    elif hasattr(lock, 'acquire'):
        lock.acquire()
    else:
        raise TypeError('expecting Lock/RLock')

def release_save(lock):
    """Release a lock and return its state."""
    if hasattr(lock, '_release_save'):
        return lock._release_save()
    elif hasattr(lock, 'release'):
        lock.release()
    else:
        raise TypeError('expecting Lock/RLock')


class Condition(object):
    """A condition.

    A condition is a synchronization primitive that can make zero or more
    fibers wait for a programmer-raised event.

    A condition is always associated with a lock. The state of the condition
    may only change when the caller has acquired the lock. While the lock is
    held, a condition can be waited for using :meth:`wait`. The wait method
    will release the lock just before blocking itself, so that another fiber
    can call :meth:`notify` to notify the condition.

    The difference between a condition and an :class:`Event` is that a
    condition is edge-trigerred. This means that when a condition is notified,
    only fibers that are waiting *at that exact time* are unblocked. Any fiber
    that calls :meth:`wait` after the notification, will block until the next
    notification. This also explains why a lock is needed. Without the lock
    there would be a race condition between notification and waiting.

    A condition is thread safe. This class is the fiber-aware equivalent of
    :class:`threading.Condition`.
    """

    __slots__ = ('_lock', '_waiters')

    def __init__(self, lock=None):
        """
        The *lock* argument can be used to share a lock between multiple
        conditions. It must be a :class:`Lock` or :class:`RLock` instance. If
        no lock is provided, a :class:`RLock` is allocated.
        """
        self._lock = lock or RLock()
        self._waiters = []

    acquire = lambda self,*args: self._lock.acquire(*args)
    release = lambda self: self._lock.release()
    __enter__ = lambda self: self._lock.acquire()
    __exit__ = lambda self,*exc_info: self.release()

    def notify(self, n=1):
        """Raise the condition and wake up fibers waiting on it.

        The optional *n* parameter specifies how many fibers will be notified.
        By default, one fiber is notified.
        """
        if not is_locked(self._lock):
            raise RuntimeError('lock is not locked')
        if not self._waiters:
            return
        notified = 0
        for i in range(min(n, len(self._waiters))):
            notify, predicate = self._waiters[i-notified]
            if callable(predicate) and not predicate():
                continue
            notify()
            del self._waiters[i-notified]
            notified += 1

    def notify_all(self):
        """Raise the condition and wake up all fibers waiting on it."""
        self.notify(len(self._waiters))

    @switchpoint
    def wait(self, timeout=None):
        """Wait for the condition to be notified.

        The return value is True, unless a timeout occurred in which case the
        return value is False.

        The lock must be held before calling this method. This method will
        release the lock just before blocking itself, and it will re-acquire it
        before returning. 
        """
        return self.wait_for(None, timeout)

    @switchpoint
    def wait_for(self, predicate, timeout=None):
        """Like :meth:`wait` but additionally for *predicate* to be true.

        The *predicate* argument must be a callable that takes no arguments.
        Its result is interpreted as a boolean value.
        """
        hub = get_hub()
        if not is_locked(self._lock):
            raise RuntimeError('lock is not locked')
        try:
            with switch_back(timeout) as switcher:
                self._waiters.append((switcher, predicate))
                # See the comment in Lock.acquire() why it is OK to release the
                # lock here before calling hub.switch().
                # Also if this is a reentrant lock make sure it is fully released.
                state = release_save(self._lock)
                hub.switch()
        except Exception as e:
            for i in reversed(range(len(self._waiters))):
                if self._waiters[i][0] is switcher:
                    del self._waiters[i]
                    break
            if isinstance(e, Timeout):
                return False
            raise
        finally:
            acquire_restore(self._lock, state)
        return True


class QueueEmpty(Exception):
    """Queue is empty."""

class QueueFull(Exception):
    """Queue is full."""


class Queue(object):
    """A synchronized FIFO queue.

    A queue is thread-safe. This class is the fiber-aware equivalent of
    :class:`queue.Queue`.
    """

    __slots__ = ('_maxsize', '_unfinished_tasks', '_heap', '_size', '_counter',
                 '_lock', '_notempty', '_notfull', '_alldone')

    def __init__(self, maxsize=0):
        """
        The *maxsize* argument specifies the maximum queue size. If it is less
        than or equal to zero, the queue size is infinite.
        """
        self._maxsize = maxsize
        self._unfinished_tasks = 0
        # Use a list/heapq even for a FIFO instead of a deque() because of the
        # latter's high memory use (see comment in Lock). For most protocols
        # there will be one Queue per connection so a low memory footprint is
        # very important.
        self._heap = []
        self._size = 0
        self._counter = 0
        # Use a threading.Lock so that put_nowait() and get_nowait() don't need
        # to be a switchpoint. Also it is more efficient.
        self._lock = threading.Lock()
        self._notempty = Condition(self._lock)
        self._notfull = Condition(self._lock)
        self._alldone = Condition(self._lock)

    def _get_item_priority(self, item):
        # Priority function: FIFO queue by default
        self._counter += 1
        return self._counter

    def qsize(self):
        """Return the size of the queue, which is the sum of the size of all
        its elements."""
        return self._size

    empty = lambda self: self.qsize() == 0
    full = lambda self: self.qsize() >= self.maxsize > 0

    maxsize = property(lambda self: self._maxsize)
    unfinished_tasks = property(lambda self: self._unfinished_tasks)

    @switchpoint
    def put(self, item, block=True, timeout=None, size=None):
        """Put *item* into the queue.

        If the queue is currently full and *block* is True (the default), then
        wait up to *timeout* seconds for space to become available. If no
        timeout is specified, then wait indefinitely.

        If the queue is full and *block* is False or a timeout occurs, then
        raise a :class:`QueueFull` exception.

        The optional *size* argument may be used to specify a custom size for
        the item. The total :meth:`qsize` of the queue is the sum of the sizes
        of all the items. The default size for an item is 1.
        """
        if size is None:
            size = 1
        with self._lock:
            priority = self._get_item_priority(item)
            while self._size + size > self.maxsize > 0:
                if not block:
                    raise QueueFull
                if not self._notfull.wait_for(lambda: self._size+size <= self.maxsize, timeout):
                    raise QueueFull
            heapq.heappush(self._heap, (priority, size, item))
            self._size += size
            self._unfinished_tasks += 1
            self._notempty.notify()

    def put_nowait(self, item, size=None):
        """"Equivalent of ``put(item, False)``."""
        # Don't don't turn this method into a switchpoint as put() will never
        # switch if block is False. This can be done by calling the function
        # wrapped by the @switchpoint wrapper directly.
        return self.put.func(self, item, False, size=size)

    @switchpoint
    def get(self, block=True, timeout=None):
        """Pop an item from the queue.

        If the queue is not empty, an item is returned immediately. Otherwise,
        if *block* is True (the default), wait up to *timeout* seconds for an
        item to become available. If not timeout is provided, then wait
        indefinitely.

        If the queue is empty and *block* is false or a timeout occurs, then
        raise a :class:`QueueEmpty` exception.
        """
        with self._lock:
            while not self._heap:
                if not block:
                    raise QueueEmpty
                if not self._notempty.wait(timeout):
                    raise QueueEmpty
            prio, size, item = heapq.heappop(self._heap)
            self._size -= size
            if 0 <= self._size < self.maxsize:
                self._notfull.notify()
        return item

    def get_nowait(self):
        """"Equivalent of ``get(False)``."""
        # See note in put_nowait()
        return self.get.func(self, False)

    def clear(self):
        """Remove all elements from the queue."""
        with self._lock:
            del self._heap[:]
            self._notfull.notify()

    def task_done(self):
        """Mark a task as done."""
        with self._lock:
            unfinished = self._unfinished_tasks - 1
            if unfinished < 0:
                raise RuntimeError('task_done() called too many times')
            elif unfinished == 0:
                self._alldone.notify()
            self._unfinished_tasks = unfinished

    def join(self):
        """Wait until all tasks are done."""
        with self._lock:
            while self._unfinished_tasks > 0:
                self._alldone.wait()


class LifoQueue(Queue):
    """A queue with LIFO behavior.

    See :class:`Queue` for a description of the API.
    """

    __slots__ = Queue.__slots__

    def _get_item_priority(self, item):
        # Priority function for a LIFO queue
        self._counter += 1
        return -self._counter


class PriorityQueue(Queue):
    """A priority queue.

    Items that are added via :meth:`put` must be ``(priority, item)`` tuples.
    The priority element must be a numeric priority. Lower numerical values
    indicate a higher priority.

    See :class:`Queue` for a description of the API.
    """

    __slots__ = Queue.__slots__

    def _get_item_priority(self, item):
        # Priority function for a priority queue: item should typically be a
        # (priority, item) tuple
        return item

########NEW FILE########
__FILENAME__ = transports
#
# This file is part of Gruvi. Gruvi is free software available under the
# terms of the MIT license. See the file "LICENSE" that was provided
# together with this source file for the licensing terms.
#
# Copyright (c) 2012-2014 the Gruvi authors. See the file "AUTHORS" for a
# complete list.

from __future__ import absolute_import, print_function

import pyuv
import functools
import socket
import struct

from . import logging, compat
from .errors import Error

# Stream is not exposed by pyuv.
Stream = pyuv.TCP.__bases__[0]
UvError = pyuv.error.UVError

__all__ = ['UvError', 'TransportError', 'BaseTransport', 'Transport', 'DatagramTransport']


class TransportError(Error):
    """Transport error."""

    def __init__(self, message, errno=None):
        super(TransportError, self).__init__(message)
        self._errno = errno

    @property
    def errno(self):
        return self._errno

    @classmethod
    def from_errno(cls, errno, message=None):
        if message is None:
            message = '{0}: {1}'.format(pyuv.errno.errorcode.get(errno, errno),
                                        pyuv.errno.strerror(errno))

        return cls(message, errno)


class BaseTransport(object):
    """Base class for :mod:`pyuv` based transports."""

    write_buffer_size = 65536

    def __init__(self, handle):
        self._handle = handle
        self._protocol = None
        self._log = logging.get_logger()
        self._write_buffer_size = 0
        self._write_buffer_high = self.write_buffer_size
        self._write_buffer_low = self.write_buffer_size // 2
        self._closing = False
        self._error = None
        self._reading = False
        self._writing = True
        self._started = False

    def start(self, protocol):
        """Bind to *protocol* and start calling callbacks on it."""
        if self._protocol is not None:
            raise RuntimeError('already started')
        self._protocol = protocol
        self._protocol.connection_made(self)

    def get_extra_info(self, name, default=None):
        """Get transport specific data."""
        if name == 'handle':
            return self._handle
        elif name == 'sockname':
            if not hasattr(self._handle, 'getsockname'):
                return
            return self._handle.getsockname()
        elif name == 'peername':
            if not hasattr(self._handle, 'getpeername'):
                return
            return self._handle.getpeername()
        elif name == 'fd':
            if not hasattr(self._handle, '_fileno'):
                return
            fd = self._handle.f_ileno()
            return fd if fd >= 0 else None
        elif name == 'unix_creds':
            if not hasattr(self._handle, '_fileno'):
                return
            fd = self._handle._fileno()
            if fd < 0 or not isinstance(self._handle, pyuv.Pipe) \
                        or not hasattr(socket, 'AF_UNIX') or not hasattr(socket, 'SO_PEERCRED'):
                return
            sock = socket.fromfd(fd, socket.AF_UNIX, socket.SOCK_DGRAM)  # will dup()
            creds = sock.getsockopt(socket.SOL_SOCKET, socket.SO_PEERCRED, struct.calcsize('3i'))
            sock.close()
            return struct.unpack('3i', creds)
        else:
            return default

    def get_write_buffer_size(self):
        """Return the current write buffer size."""
        return self._write_buffer_size

    def set_write_buffer_limits(self, high=None, low=None):
        """Set the low and high watermark for the write buffer."""
        if high is None:
            high = self.write_buffer_size
        if low is None:
            low = high // 2
        if low > high:
            low = high
        self._write_buffer_high = high
        self._write_buffer_low = low

    def _on_close_complete(self, handle):
        # Callback used with handle.close().
        assert handle is self._handle
        self._protocol.connection_lost(self._error)
        self._protocol = None  # remove cycle to help garbage collection

    def close(self):
        """Close the transport after all oustanding data has been written."""
        if self._closing or self._handle.closed:
            return
        elif self._protocol is None:
            raise RuntimeError('transport not started')
        # If the write buffer is empty, close now. Otherwise defer to
        # _on_write_complete that will close when it's empty.
        if self._write_buffer_size == 0:
            self._handle.close(self._on_close_complete)
            assert self._handle.closed
        else:
            self._closing = True

    def abort(self):
        """Close the transport immediately."""
        if self._handle.closed:
            return
        elif self._protocol is None:
            raise RuntimeError('transport not started')
        self._handle.close(self._on_close_complete)
        assert self._handle.closed


class Transport(BaseTransport):
    """A stream transport.
    
    This is an adapter class that adapts the :class:`pyuv.Stream` API to a
    stream transport as specified in PEP 3156.
    """

    def __init__(self, handle):
        """
        The *handle* argument is the pyuv handle for which to create the
        transport. It must be a :class:`pyuv.Stream` instance.
        """
        if not isinstance(handle, Stream):
            raise TypeError("handle: expecting a 'pyuv.Stream' instance, got {0!r}"
                                .format(type(handle).__name__))
        super(Transport, self).__init__(handle)

    def start(self, protocol):
        """Bind to *protocol* and start calling callbacks on it."""
        super(Transport, self).start(protocol)
        self._handle.start_read(self._read_callback)
        self._reading = True

    def _read_callback(self, handle, data, error):
        # Callback used with handle.start_read().
        assert handle is self._handle
        if self._error:
            self._log.warning('ignore read status {} after close', error)
        elif error == pyuv.errno.UV_EOF:
            if self._protocol.eof_received():
                self._log.debug('EOF received, protocol wants to continue')
            elif not self._closing:
                self._log.debug('EOF received, closing transport')
                self._error = TransportError('connection lost')
                self.close()
        elif error:
            self._log.warning('pyuv error {} in read callback', error)
            self._error = TransportError.from_errno(error)
            self.abort()
        elif not self._closing:
            self._protocol.data_received(data)

    def pause_reading(self):
        """Pause calling callbacks on the protocol."""
        # Note: pause_reading() and resume_reading() are allowed when _closing
        # is true (unlike e.g. write()). This makes it easier for our child
        # class SslTransport to enable reading when it is closing down.
        if self._error:
            raise self._error
        elif self._protocol is None:
            raise RuntimeError('transport not started')
        elif not self._reading:
            raise RuntimeError('not currently reading')
        self._handle.stop_read()
        self._reading = False

    def resume_reading(self):
        """Start calling callbacks on the protocol."""
        if self._error:
            raise self._error
        elif self._protocol is None:
            raise RuntimeError('transport not started')
        elif self._reading:
            raise RuntimeError('already reading')
        self._handle.start_read(self._read_callback)
        self._reading = True

    def _on_write_complete(self, datalen, handle, error):
        # Callback used with handle.write().
        assert handle is self._handle
        self._write_buffer_size -= datalen
        assert self._write_buffer_size >= 0
        if self._error:
            self._log.debug('write status {} after close', error)
        elif error and error != pyuv.errno.UV_ECANCELED:
            self._log.warning('pyuv error {} in write callback', error)
            self._error = TransportError.from_errno(error)
            self.abort()
        if not self._closing and not handle.closed and not self._writing \
                    and self._write_buffer_size <= self._write_buffer_low:
            self._protocol.resume_writing()
            self._writing = True
        if self._closing and self._write_buffer_size == 0:
            if not handle.closed:
                handle.close(self._on_close_complete)
            self._closing = False

    def write(self, data):
        """Write *data* to the transport."""
        if not isinstance(data, compat.bytes_types):
            raise TypeError("data: expecting a bytes-like instance, got {0!r}"
                                .format(type(data).__name__))
        if self._error:
            raise self._error
        elif self._closing or self._handle.closed:
            raise TransportError('transport is closing/closed')
        elif self._protocol is None:
            raise RuntimeError('transport not started')
        elif len(data) == 0:
            return
        self._write_buffer_size += len(data)
        if self._write_buffer_size > self._write_buffer_high:
            self._protocol.pause_writing()
            self._writing = False
        callback = functools.partial(self._on_write_complete, len(data))
        self._handle.write(data, callback)

    def writelines(self, seq):
        """Write all elements from *seq* to the transport."""
        for line in seq:
            self.write(line)

    def write_eof(self):
        """Shut down the write side of the transport."""
        if self._error:
            raise self._error
        elif self._closing or self._handle.closed:
            raise TransportError('transport is closing/closed')
        elif self._protocol is None:
            raise RuntimeError('transport not started')
        self._write_buffer_size += 1
        callback = functools.partial(self._on_write_complete, 1)
        self._handle.shutdown(callback)

    def can_write_eof(self):
        """Wether this transport can close the write direction."""
        return True

 
class DatagramTransport(BaseTransport):
    """A datagram transport.
    
    This is an adapter class that adapts the :class:`pyuv.UDP` API to a
    datagram transport as specified in PEP 3156.
    """

    def __init__(self, handle):
        """
        The *handle* argument is the pyuv handle for which to create the
        transport. It must be a :class:`pyuv.UDP` instance.
        """
        if not isinstance(handle, pyuv.UDP):
            raise TypeError("handle: expecting a 'pyuv.UDP' instance, got {0!r}"
                                .format(type(handle).__name__))
        super(DatagramTransport, self).__init__(handle)

    def start(self, protocol):
        """Bind to *protocol* and start calling callbacks on it."""
        super(DatagramTransport, self).start(protocol)
        self._handle.start_recv(self._recv_callback)

    def _recv_callback(self, handle, addr, flags, data, error):
        """Callback used with handle.start_recv()."""
        assert handle is self._handle
        if error:
            self._log.warning('pyuv error {} in recv callback', error)
            self._protocol.error_received(TransportError.from_errno(error))
        elif flags:
            assert flag & pyuv.UV_UDP_PARTIAL
            self._log.warning('ignoring partial datagram')
        elif data and not self._closing:
            self._protocol.datagram_received(data, addr)

    def _on_send_complete(self, datalen, handle, error):
        """Callback used with handle.send()."""
        assert handle is self._handle
        self._write_buffer_size -= datalen
        assert self._write_buffer_size >= 0
        if error and error != pyuv.errno.UV_ECANCELED:
            self._log.warning('pyuv error {} in sendto callback', error)
            self._protocol.error_received(TransportError.from_errno(error))
        if not self._closing and not self._writing and \
                    self._write_buffer_size <= self._write_buffer_low:
            self._protocol.resume_writing()
            self._writing = True
        if self._closing and self._write_buffer_size == 0:
            if not handle.closed:
                self._handle.close(self._on_close_complete)
            self._closing = False

    def sendto(self, data, addr=None):
        """Send a datagram.

        If *addr* is not specified, the handle must have been bound to a
        default remote address.
        """
        if not isinstance(data, bytes):
            raise TypeError("data: expecting a 'bytes' instance, got {0!r}"
                                .format(type(data).__name__))
        if self._closing or self._handle.closed:
            raise TransportError('transport is closing/closed')
        elif len(data) == 0:
            return
        self._write_buffer_size += len(data)
        if self._write_buffer_size > self._write_buffer_high:
            self._protocol.pause_writing()
            self._writing = False
        callback = functools.partial(self._on_send_complete, len(data))
        self._handle.send(addr, data, callback)

########NEW FILE########
__FILENAME__ = authentication
"""
This module implements DBus authentication mechanisms

@author: Tom Cocagne
"""

from __future__ import absolute_import, print_function

import os
import os.path
import time
import getpass
import hashlib
import binascii
import six

from   .error    import DBusAuthenticationFailed

class log:
    from gruvi.logging import get_logger
    logger = get_logger()
    @classmethod
    def msg(cls, m):
        cls.logger.warning(m)


def hexlify(s):
    # Like binascii.hexlify but returns a str
    if isinstance(s, six.text_type):
        s = s.encode('ascii')
    return binascii.hexlify(s).decode('ascii')


class ClientAuthenticator (object):
    """
    Implements the client-side portion of the DBus authentication protocol.

    @ivar preference: List of authentication mechanisms to try in the preferred order
    @type preference: List of C{string}
    """

    preference = ['EXTERNAL', 'DBUS_COOKIE_SHA1', 'ANONYMOUS']
    cookie_dir    = None # used for testing only
    
    def beginAuthentication(self, protocol):
        self.authenticated = False
        self.protocol      = protocol
        self.guid          = None

        self.authOrder = self.preference[:]
        self.authOrder.reverse()
        
        self.authTryNextMethod()
        

    def handleAuthMessage(self, line):
        if not ' ' in line:
            cmd = line
            args = ''
        else:
            cmd, args = line.split(' ',1)
        m = getattr(self, '_auth_' + cmd, None)
        if m:
            m( args )
        else:
            raise DBusAuthenticationFailed('Invalid DBus authentcation protocol message: ' + line)


    def authenticationSucceeded(self):
        return self.authenticated

    
    def getGUID(self):
        return self.guid
    
    #---------------------------------------------------

    def sendAuthMessage(self, msg):
        self.protocol.sendAuthMessage( msg )
        
            
    def authTryNextMethod(self):
        """
        Tries the next authentication method or raises a failure if all mechanisms
        have been tried.
        """
        if not self.authOrder:
            raise DBusAuthenticationFailed()
        
        self.authMech  = self.authOrder.pop()
            
        if self.authMech == 'DBUS_COOKIE_SHA1':
            self.sendAuthMessage('AUTH ' + self.authMech + ' ' +
                                 hexlify(getpass.getuser()))
        elif self.authMech == 'ANONYMOUS':
            self.sendAuthMessage('AUTH ' + self.authMech + ' ' +
                                 hexlify("txdbus"))
        else:
            self.sendAuthMessage('AUTH ' + self.authMech)

                    
    def _auth_REJECTED(self, line):
        self.authTryNextMethod()

        
    def _auth_OK(self, line):
        line = line.strip()

        if not line:
            raise DBusAuthenticationFailed('Missing guid in OK message')
        
        try:
            self.guid = line
        except:
            raise DBusAuthenticationFailed('Invalid guid in OK message')
        else:
            self.sendAuthMessage('BEGIN')
            self.authenticated = True
        

    def _auth_AGREE_UNIX_FD(self, line):
        log.msg('DBus Auth not implemented AGREE_UNIX_FD')
        
    
    def _auth_DATA(self, line):
        
        if self.authMech == 'EXTERNAL':
            self.sendAuthMessage('DATA')
            
        elif self.authMech == 'DBUS_COOKIE_SHA1':
            try:
                data = binascii.unhexlify( line.strip() ).decode('ascii')
                
                cookie_context, cookie_id, server_challenge = data.split()

                server_cookie = self._authGetDBusCookie(cookie_context, cookie_id)

                client_challenge = hexlify(hashlib.sha1(os.urandom(8)).digest())

                response = '%s:%s:%s' % (server_challenge,
                                         client_challenge,
                                         server_cookie)

                response = hexlify(hashlib.sha1(response.encode('ascii')).digest())

                reply = client_challenge + ' ' + response
                
                self.sendAuthMessage( 'DATA ' + hexlify(reply))
            except Exception as e:
                log.msg('DBUS Cookie authentication failed: ' + str(e))
                self.sendAuthMessage('ERROR ' + str(e))

    def _auth_ERROR(self, line):
        log.msg('Authentication mechanism failed: ' + line)
        self.authTryNextMethod()

    #--------------------------------------------------
    
    def _authGetDBusCookie(self, cookie_context, cookie_id):
        """
        Reads the requested cookie_id from the cookie_context file
        """
        # XXX   Ensure we obtain the correct directory for the
        #       authenticating user and that that user actually
        #       owns the keyrings directory

        if self.cookie_dir is None:
            cookie_dir = os.path.expanduser('~/.dbus-keyrings')
        else:
            cookie_dir = self.cookie_dir

        dstat = os.stat(cookie_dir)

        if dstat.st_mode & 0x36:  # 066
            raise Exception('User keyrings directory is writeable by other users. Aborting authentication')

        import pwd
        if dstat.st_uid != pwd.getpwuid(os.geteuid()).pw_uid:
            raise Exception('Keyrings directory is not owned by the current user. Aborting authentication!')
        
        f = open(os.path.join(cookie_dir, cookie_context), 'r')

        try:
            for line in f:
                try:
                    k_id, k_time, k_cookie_hex = line.split()
                    if k_id == cookie_id:
                        return k_cookie_hex
                except:
                    pass
        finally:
            f.close()


class BusCookieAuthenticator (object):
    """
    Implements the Bus-side portion of the DBUS_COOKIE_SHA1 authentication
    mechanism
    """
    
    cookieContext = 'org_twisteddbus_ctx' + str(os.getpid())
    keyring_dir = None

    
    def __init__(self):
        self.step_num = 0
        self.username = None
        self.cookieId = None

        
    def cancel(self):
        if self.cookieId:
            self._delete_cookie()


    def getMechanismName(self):
        return 'DBUS_COOKIE_SHA1'


    def init(self, protocol):
        pass

    
    def getUserName(self):
        return self.username
    
    
    def step(self, arg):
        s = self.step_num
        self.step_num += 1

        if arg is None:
            return ('REJECTED', None)

        try:
            if s == 0:
                return self._step_one( arg )
            elif s == 1:
                return self._step_two( arg )
            else:
                raise Exception()
        except Exception as e:
            return ('REJECTED', None)

        
    def _step_one(self, username, keyring_dir=None):
        try:
            uid = int(username)
            try:
                import pwd
                username = pwd.getpwuid(uid).pw_name
            except:
                return ('REJECTED', None)
        except ValueError:
            pass
        
        self.username = username
        
        try:
            import pwd
            p = pwd.getpwnam(username)
            self.uid     = p.pw_uid
            self.gid     = p.pw_gid
            self.homedir = p.pw_dir
        except (KeyError, ImportError):
            return ('REJECTED', None) # username not found

        if keyring_dir is None:
            keyring_dir = self.keyring_dir

        if keyring_dir is None:
            dk = os.path.join(self.homedir, '.dbus-keyrings')
        else:
            dk = keyring_dir # for testing only
        
        self.cookie_file = os.path.join(dk, self.cookieContext)
        
        try:
            s = os.lstat(dk)
            if not os.path.isdir(dk) or s.st_mode & 0x36:  # 066
                # Invalid keyrings directory. Something fishy is going on
                return ('REJECTED', None)
        except OSError:
            old_un = os.umask(0x3f)  # 077
            os.mkdir(dk)
            os.umask(old_un)
            if os.geteuid() == 0:
                os.chown(dk, self.uid, self.gid)

        self._create_cookie()

        self.challenge_str = hexlify(hashlib.sha1(os.urandom(8)).digest())
        
        msg = ' '.join( [self.cookieContext,
                         str(self.cookieId),
                         self.challenge_str] )
        
        return ('CONTINUE', msg)

    
    def _step_two(self, response):
        self._delete_cookie()
        hash_str = None
        shash    = 1
        try:
            client_challenge, hash_str = response.split()

            tohash = self.challenge_str + ':' + client_challenge + ':' + self.cookie

            shash = hexlify( hashlib.sha1(tohash.encode('ascii')).digest() )
        except:
            pass

        if shash == hash_str:
            return ('OK', None)
        else:
            return ('REJECTED', None)

        

    def _get_lock(self):
        #
        # Twisted is single-threaded, our context name includes the
        # process id, and we wont be using any deferreds here... so
        # the lock file really isn't needed. We'll go ahead and
        # include a very simple version of it, however, "just to say
        # we did"
        #
        self.lock_file = self.cookie_file + '.lock'
        try:
            lockfd = os.open(self.lock_file, os.O_CREAT | os.O_EXCL
                                             | os.O_WRONLY, 0x180)  # 0600
        except:
            time.sleep(0.01)
            try:
                lockfd = os.open(self.lock_file, os.O_CREAT | os.O_EXCL
                                                 | os.O_WRONLY, 0x180)  # 0600
            except:
                os.unlink(self.lock_file)
                lockfd = os.open(self.lock_file, os.O_CREAT | os.O_EXCL
                                                 | os.O_WRONLY, 0x180)  # 0600

        return lockfd


    def _get_cookies(self,timefunc=time.time):
        cookies = list()
        f = None
        try:
            f = open(self.cookie_file, 'r')
            for line in f:
                k_id, k_time, k_cookie_hex = line.split()

                if abs( timefunc() - int(k_time) ) < 30:
                    cookies.append( line.split() )
        except:
            pass
        finally:
            if f:
                f.close()

        return cookies
    
    
    def _create_cookie(self, timefunc=time.time):
        
        lockfd = self._get_lock()

        cookies = self._get_cookies(timefunc)

        cookie_id = 1
        for tpl in cookies:
            if int(tpl[0]) >= cookie_id:
                cookie_id = int(tpl[0]) + 1

        cookie = hexlify(os.urandom(24))
        
        cookies.append( (str(cookie_id), str(int(timefunc())), cookie) )

        for c in cookies:
            os.write(lockfd, ' '.join(c).encode('ascii') + b'\n')

        os.close(lockfd)
        if os.geteuid() == 0:
            os.chown(self.lock_file, self.uid, self.gid)

        os.rename(self.lock_file, self.cookie_file)

        self.cookieId = cookie_id
        self.cookie   = cookie

    
    def _delete_cookie(self):
        lockfd = self._get_lock()

        cookies = self._get_cookies()

        for i, tpl in enumerate(cookies):
            if int(tpl[0]) == self.cookieId:
                del cookies[i]
                break
            
        if not cookies:
            os.unlink(self.cookie_file)
            os.close(lockfd)
            os.unlink(self.lock_file)
        else:
            for c in cookies:
                os.write(lockfd, ' '.join(c).encode('ascii') + b'\n')

            os.close(lockfd)
            if os.geteuid() == 0:
                os.chown(self.lock_file, self.uid, self.gid)
            
            os.rename(self.lock_file, self.cookie_file) 
        

class BusExternalAuthenticator (object):
    """
    Implements the Bus-side portion of the EXTERNAL authentication
    mechanism
    """

    def __init__(self):
        self.ok = False
        self.creds = None
        
    def getMechanismName(self):
        return 'EXTERNAL'

    def init(self, protocol):
        self.creds = protocol._unix_creds
    
    def step(self, arg):
        if not self.creds:
            return ('REJECT', 'Unix credentials not available')
        if not self.ok:
            self.ok = True
            return ('CONTINUE', '')
        else:
            return ('OK', None)

    def getUserName(self):
        import pwd
        return pwd.getpwuid(self.creds[1]).pw_name
    

    def cancel(self):
        pass


class BusAnonymousAuthenticator (object):
    """
    Implements the Bus-side portion of the ANONYMOUS authentication
    mechanism
    """
    
    def getMechanismName(self):
        return 'ANONYMOUS'

    def init(self, protocol):
        pass
    
    def step(self, arg):
        return ('OK', None)

    def getUserName(self):
        return 'anonymous'

    def cancel(self):
        pass
    

class BusAuthenticator (object):
    """
    Implements the Bus-side portion of the DBus authentication protocol.

    @ivar authenticators: A dictionary of mechanism names to mechanism
                          implementation classes
    @type authenticators: C{dict}
    """

    MAX_REJECTS_ALLOWED = 5

    authenticators = { 'EXTERNAL'         : BusExternalAuthenticator,
                       'DBUS_COOKIE_SHA1' : BusCookieAuthenticator,
                       'ANONYMOUS'        : BusAnonymousAuthenticator }
    
    def __init__(self, server_guid):
        self.server_guid   = server_guid
        self.authenticated = False
        self.mechanisms    = dict()
        self.protocol      = None
        self.guid          = None

        self.reject_count  = 0
        self.state         = None
        self.current_mech  = None

        for n, m in six.iteritems(self.authenticators):
            self.mechanisms[ n ] = m

        mechNames = self.authenticators.keys()
        
        self.reject_msg = 'REJECTED ' + ' '.join(mechNames)


        
    def beginAuthentication(self, protocol):
        self.protocol      = protocol
        self.state         = 'WaitingForAuth'
        

    def handleAuthMessage(self, line):
        #print 'RCV: ', line.rstrip()
        if not ' ' in line:
            cmd = line
            args = ''
        else:
            cmd, args = line.split(' ',1)
        m = getattr(self, '_auth_' + cmd, None)
        if m:
            m( args )
        else:
            self.sendError('"Unknown command"')


    def authenticationSucceeded(self):
        return self.authenticated

    
    def getGUID(self):
        return self.server_guid
    
    #---------------------------------------------------

    def reject(self):
        if self.current_mech:
            self.current_mech.cancel()
            self.current_mech = None
            
        self.reject_count += 1
        if self.reject_count > self.MAX_REJECTS_ALLOWED:
            raise DBusAuthenticationFailed('Client exceeded maximum failed authentication attempts')
        
        self.sendAuthMessage(self.reject_msg)
        self.state = 'WaitingForAuth'
        
    
    def sendAuthMessage(self, msg):
        #print 'SND: ', msg.rstrip()
        self.protocol.sendAuthMessage( msg )

        
    def sendError(self, msg = None):
        if msg:
            self.sendAuthMessage('ERROR ' + msg)
        else:
            self.sendAuthMessage('ERROR')


    def stepAuth(self, response):
        if self.current_mech is None:
            self.reject()
            return

        if response:
            response = binascii.unhexlify( response.strip() ).decode('ascii')

            
        status, challenge = self.current_mech.step(response)


        if status == 'OK':
            self.sendAuthMessage('OK ' + self.server_guid)
            self.state = 'WaitingForBegin'

        elif status == 'CONTINUE':
            self.sendAuthMessage('DATA ' + hexlify(challenge))
            self.state = 'WaitingForData'
            
        else:
            #print 'REJECT: ', status
            self.reject()


    def _auth_AUTH(self, line):
        if self.state == 'WaitingForAuth':
            tpl = line.split()

            if len(tpl) == 0:
                self.reject()
            else:
                mech             = tpl[0]
                initial_response = None
                if len(tpl) > 1:
                    initial_response = tpl[1]
                if mech in self.mechanisms:
                    self.current_mech = self.mechanisms[mech]()
                    self.current_mech.init(self.protocol)
                    self.stepAuth(initial_response)                    
                else:
                    self.reject()

        else:
            self.sendError()
                    
                    
    def _auth_BEGIN(self, line):
        if self.state == 'WaitingForBegin':
            self.authenticated = True
            self.guid          = self.current_mech.getUserName()
        else:
            raise DBusAuthenticationFailed('Protocol violation')
        
        
    def _auth_ERROR(self, line):
        if self.state in ('WaitingForAuth', 'WaitingForData',
                          'WaitingForBegin'):
            self.reject()


    def _auth_DATA(self, line):
        if self.state == 'WaitingForData':
            self.stepAuth(line)
        else:
            self.sendError()


    def _auth_CANCEL(self, line):
        if self.state in ('WaitingForData', 'WaitingForBegin'):
            self.reject()
        else:
            self.sendError()


    def _auth_NEGOTIATE_UNIX_FD(self, line):
        # Only valid in the 'WaitingForBegin' state
        self.sendError()

            

########NEW FILE########
__FILENAME__ = error
"""
DBus errors
@author: Tom Cocagne
"""

class DBusException (Exception):
    """
    Base class for all expected DBus exceptions
    """
    pass


class DBusAuthenticationFailed (DBusException):
    pass


class MarshallingError (DBusException):
    """
    Thrown when errors are encountered by the marshalling/unmarshalling
    code
    """
    pass


class TimeOut (DBusException):
    """
    Used to indicate a timeout for remote DBus method calls that
    request a timeout value
    """
    pass


class IntrospectionFailed (DBusException):
    """
    Thrown if remote object introspection fails
    """
    pass


class RemoteError (DBusException):
    """
    Thrown in response to errors encountered during a remote
    method invocation. 

    @ivar errName: DBus error name
    @type errName: C{string}
    """
    message = ''

    def __init__(self, errName):
        self.errName = errName

    def __str__(self):
        return '%s: %s' % (self.errName, self.message) if self.message else self.errName

        
class FailedToAcquireName(DBusException):
    """
    Indicates a failed attempt to acquire a bus name
    """
    def __init__(self, new_name, returnCode):
        head = 'Failed to acquire bus name "%s": ' % (new_name,)
        if returnCode == 2:
            tail = 'Queued for name acquisition'
        elif returnCode == 3:
            tail = 'Name in use'
        else:
            tail = 'Unknown reason'

        DBusException.__init__(self, head + tail)
        
        self.returnCode = returnCode
        

########NEW FILE########
__FILENAME__ = marshal
"""
Provides data marshalling to and from the DBus wire format

@author: Tom Cocagne
"""

from __future__ import absolute_import, print_function

import struct
import re
import six
import codecs

from .error import MarshallingError


invalid_obj_path_re = re.compile('[^a-zA-Z0-9_/]')
if_re               = re.compile('[^A-Za-z0-9_.]')
bus_re              = re.compile('[^A-Za-z0-9_.\-:]')
mbr_re              = re.compile('[^A-Za-z0-9_]')
dot_digit_re        = re.compile('\.\d')


#                Name      Type code   Alignment
dbus_types = [ ('BYTE',        'y',     1),
               ('BOOLEAN',     'b',     4),
               ('INT16',       'n',     2),
               ('UINT16',      'q',     2),
               ('INT32',       'i',     4),
               ('UINT32',      'u',     4),
               ('INT64',       'x',     8),
               ('UINT64',      't',     8),
               ('DOUBLE',      'd',     8),
               ('STRING',      's',     4), # (4-byte align for length)
               ('OBJECT_PATH', 'o',     4), # (4-byte align for length)
               ('SIGNATURE',   'g',     1),
               ('ARRAY',       'a',     4), # (4-byte align for length)
               ('STRUCT',      '(',     8),
               ('VARIANT',     'v',     1), # (1-byte align for signature)
               ('DICT_ENTRY',  '{',     8),
               ('UNIX_FD',     'h',     4)
               ]


class Byte(int):
    """
    Used during Variant serialization to ensure that this type is
    encoded rather than the generic Python type
    """
    dbusSignature = 'y'
    
class Boolean(int):
    """
    Used during Variant serialization to ensure that this type is
    encoded rather than the generic Python type
    """
    dbusSignature = 'b'
    
class Int16(int):
    """
    Used during Variant serialization to ensure that this type is
    encoded rather than the generic Python type
    """
    dbusSignature = 'n'
    
class UInt16(int):
    """
    Used during Variant serialization to ensure that this type is
    encoded rather than the generic Python type
    """
    dbusSignature = 'q'
    
class Int32(int):
    """
    Used during Variant serialization to ensure that this type is
    encoded rather than the generic Python type
    """
    dbusSignature = 'i'
    
class UInt32(int):
    """
    Used during Variant serialization to ensure that this type is
    encoded rather than the generic Python type
    """
    dbusSignature = 'u'
    
class Int64(int):
    """
    Used during Variant serialization to ensure that this type is
    encoded rather than the generic Python type
    """
    dbusSignature = 'x'
    
class UInt64(int):
    """
    Used during Variant serialization to ensure that this type is
    encoded rather than the generic Python type
    """
    dbusSignature = 't'
    
class Signature (str):
    """
    Used during Variant serialization to ensure that this type is
    encoded rather than the generic Python type
    """
    dbusSignature = 'g'
    
class ObjectPath (str):
    """
    Used during Variant serialization to ensure that this type is
    encoded rather than the generic Python type
    """
    dbusSignature = 'o'


variantClassMap = { 'y' : Byte,
                    'b' : Boolean,
                    'n' : Int16,
                    'q' : UInt16,
                    'i' : Int32,
                    'u' : UInt32,
                    'x' : Int64,
                    't' : UInt64,
                    'g' : Signature,
                    'o' : ObjectPath }

def validateObjectPath(p):
    """
    Ensures that the provided object path conforms to the DBus standard.
    Throws a L{error.MarshallingError} if non-conformant

    @type p: C{string}
    @param p: A DBus object path
    """
    if not p.startswith('/'):
        raise MarshallingError('Object paths must begin with a "/"')
    if len(p) > 1 and p[-1] == '/':
        raise MarshallingError('Object paths may not end with "/"')
    if '//' in p:
        raise MarshallingError('"//" is not allowed in object paths"')
    if invalid_obj_path_re.search(p):
        raise MarshallingError('Invalid characters contained in object path')


def validateInterfaceName( n ):
    """
    Verifies that the supplied name is a valid DBus Interface name. Throws
    an L{error.MarshallingError} if the format is invalid

    @type n: C{string}
    @param n: A DBus interface name
    """
    try:
        if not '.' in n:
            raise Exception('At least two components required')
        if '..' in n:
            raise Exception('".." not allowed in interface names')
        if len(n) > 255:
            raise Exception('Name exceeds maximum length of 255')
        if n[0] == '.':
            raise Exception('Names may not begin with a "."')
        if n[0].isdigit():
            raise Exception('Names may not begin with a digit')
        if if_re.search(n):
            raise Exception('Names contains a character outside the set [A-Za-z0-9_.]')
        if dot_digit_re.search(n):
            raise Exception('No components of an interface name may begin with a digit')
    except Exception as e:
        raise MarshallingError('Invalid interface name "%s": %s' % (n, str(e)))


def validateErrorName( n ):
    try:
        validateInterfaceName( n )
    except MarshallingError as e:
        raise MarshallingError( str(e).replace( 'interface', 'error', 1 ) )

    
def validateBusName( n ):
    """
    Verifies that the supplied name is a valid DBus Bus name. Throws
    an L{error.MarshallingError} if the format is invalid

    @type n: C{string}
    @param n: A DBus bus name
    """
    try:
        if not '.' in n:
            raise Exception('At least two components required')
        if '..' in n:
            raise Exception('".." not allowed in bus names')
        if len(n) > 255:
            raise Exception('Name exceeds maximum length of 255')
        if n[0] == '.':
            raise Exception('Names may not begin with a "."')
        if n[0].isdigit():
            raise Exception('Names may not begin with a digit')
        if bus_re.search(n):
            raise Exception('Names contains a character outside the set [A-Za-z0-9_.\-:]')
        if not n[0] == ':' and dot_digit_re.search(n):
            raise Exception('No coponents of an interface name may begin with a digit')
    except Exception as e:
        raise MarshallingError('Invalid bus name "%s": %s' % (n, str(e)))

    
def validateMemberName( n ):
    """
    Verifies that the supplied name is a valid DBus member name. Throws
    an L{error.MarshallingError} if the format is invalid

    @type n: C{string}
    @param n: A DBus member name
    """
    try:
        if len(n) < 1:
            raise Exception('Name must be at least one byte in length')
        if len(n) > 255:
            raise Exception('Name exceeds maximum length of 255')
        if n[0].isdigit():
            raise Exception('Names may not begin with a digit')
        if mbr_re.search(n):
            raise Exception('Names contains a character outside the set [A-Za-z0-9_]')
    except Exception as e:
        raise MarshallingError('Invalid member name "%s": %s' % (n, str(e)))

    

# XXX: This could be made *much* smarter (handle objects and recursive structures)
def sigFromPy( pobj ):
    """
    Returns the DBus signature type for the argument. If the argument is an
    instance of one of the type wrapper classes, the exact type signature
    corresponding to the wrapper class will be used. If the object has a
    variable named 'dbusSignature', the value of that variable will be
    used. Otherwise, a generic type will be used (i.e "i" for a Python int)

    @rtype: C{string}
    @returns: The DBus signature for the supplied Python object
    """
    sig = getattr(pobj, 'dbusSignature', None)
    
    if sig is not None:
        return sig
    
    elif isinstance(pobj,        int): return 'i'
    elif isinstance(pobj, six.integer_types): return 'x'
    elif isinstance(pobj,      float): return 'd'
    elif isinstance(pobj, six.string_types): return 's'
    
    elif isinstance(pobj,       list):
        vtype = type(pobj[0])
        same = True
        for v in pobj[1:]:
            if not vtype is type(v):
                same = False
        if same:
            return 'a' + sigFromPy(pobj[0])
        else:
            return 'av'
    
    elif isinstance(pobj,       dict):
        same = True
        vtype = None
        for k,v in six.iteritems(pobj):
            if vtype is None:
                vtype = type(v)
            elif not vtype is type(v):
                same = False
        if same:
            return 'a{' + sigFromPy(k) + sigFromPy(v) + '}'
        else:
            return 'a{' + sigFromPy(k) + 'v}'
    
    else:
        raise MarshallingError('Invalid Python type for variant: ' + repr(pobj))

    
#-------------------------------------------------------------------------------
#                          Marshalling Functions
# Padding:
#    - All data types must be padded to the correct alignment
#    - All padding bytes must be nul
#
padding = { 0 : b'\0' * 0,
            1 : b'\0' * 1,
            2 : b'\0' * 2,
            3 : b'\0' * 3,
            4 : b'\0' * 4,
            5 : b'\0' * 5,
            6 : b'\0' * 6,
            7 : b'\0' * 7 }

def genpad( align ):
    return lambda x : padding[ x % align and (align - x%align) or 0 ]

pad = dict()

for name, tcode, align in dbus_types:
    pad[ tcode ] = genpad(align)

pad['header'] = genpad(8)


#-------------------------------------------------------------------------------
#                    Signature Generator/Iterator
#
def genCompleteTypes( compoundSig ):
    """
    Generator function used to iterate over each complete,
    top-level type contained in in a signature. Ex::
      "iii"       => [ 'i', 'i',       'i' ]
      "i(ii)i"    => [ 'i', '(ii)',    'i' ]
      "i(i(ii))i" => [ 'i', '(i(ii))', 'i' ]
    """

    i     = 0
    start = 0
    end   = len(compoundSig)

    def find_end( idx, b, e ):
        depth = 1
        while idx < end:
            subc = compoundSig[idx]
            if subc == b:
                depth += 1
            elif subc == e:
                depth -= 1
                if depth == 0:
                    return idx
            idx += 1
    
    while i < end:
        c = compoundSig[i]
        
        if c == '(':
            x = find_end(i+1, '(', ')')
            yield compoundSig[i:x+1]
            i = x

        elif c == '{':
            x = find_end(i+1, '{', '}')
            yield compoundSig[i:x+1]
            i = x

        elif c == 'a':
            start = i
            g = genCompleteTypes( compoundSig[i+1:] )
            ct = six.next(g)
            i += len(ct)
            yield 'a' + ct
            
        else:
            yield c
        i += 1



#-------------------------------------------------------------------------------
#                          Marshalling Functions
# General:
#    - All values must be padded to proper alignment
#    - Pad bytes must be zero
#
# BOOLEAN:
#    - Only 1 & 0 are valid
#
# DICT_ENTRY:
#    - Identical to STRUCT
#
# Message:
#    - Max length of header, body and all padding is 2^27
#
# Message Header:
#    - Must be padded to a multiple of 8 bytes
#    - Fixed signature: "yyyyuua(yv)"
#        *  1 BYTE:   Endian flag. 'l' for little, 'B' for big
#        *  2 BYTE:   Message type enum
#        *  3 BYTE:   Bit Flags
#        *  4 BYTE:   Major protocol version (1 currently)
#        *  5 UINT32: Body Length (begins after header padding)
#        *  6 UINT32: Message serial number (must not be zero)
#        *  7 Array:  zero or more header fields. Msg type determines
#                     which entries are required
#
# Message Body:
#    - Begins on 8-byte boundary
#    - Not padded to a required byte alignment
#
#

def marshal_byte( ct, var, start_byte, lendian ):
    return 1, [ struct.pack( lendian and '<B' or '>B', var) ]

def marshal_boolean( ct, var, start_byte, lendian ):
    return 4, [ struct.pack( lendian and '<I' or '>I', 1 if var else 0) ]

def marshal_int16( ct, var, start_byte, lendian ):
    return 2, [ struct.pack( lendian and '<h' or '>h', var) ]

def marshal_uint16( ct, var, start_byte, lendian ):
    return 2, [ struct.pack( lendian and '<H' or '>H', var) ]

def marshal_int32( ct, var, start_byte, lendian ):
    return 4, [ struct.pack( lendian and '<i' or '>i', var) ]

def marshal_uint32( ct, var, start_byte, lendian ):
    return 4, [ struct.pack( lendian and '<I' or '>I', var) ]

def marshal_int64( ct, var, start_byte, lendian ):
    return 8, [ struct.pack( lendian and '<q' or '>q', var) ]

def marshal_uint64( ct, var, start_byte, lendian ):
    return 8, [ struct.pack( lendian and '<Q' or '>Q', var) ]

def marshal_double( ct, var, start_byte, lendian ):
    return 8, [ struct.pack( lendian and '<d' or '>d', var) ]


# STRING:
#    - *must* be valid UTF-8, nul terminated with no embedded nuls
#    format:
#       1 - UINT32 length in bytes (excluding terminating nul)
#       2 - string data (no embedded nuls)
#       3 - terminating nul byte
#
def marshal_string( ct, var, start_byte, lendian ):
    if not isinstance(var, six.string_types):
        raise MarshallingError('Required string. Received: ' + repr(var))
    if var.find('\0') != -1:
        raise MarshallingError('Embedded nul characters are not allowed within DBus strings')
    var = codecs.encode(var, 'utf-8')
    return 4 + len(var) + 1, [ struct.pack( lendian and '<I' or '>I', len(var)), var, b'\0' ]


# OBJECT_PATH:
#    - Identical to string
#    
def marshal_object_path( ct, var, start_byte, lendian ):
    validateObjectPath(var)
    return marshal_string( ct, var, start_byte, lendian )


# SIGNATURE:
#    - Ends with nul byte
#    - List of complete types. No partial types permitted
#    - Max signature length is 255
#    format:
#       1 - Single byte length
#       2 - Valid signature string
#       3 - terminating nul byte
def marshal_signature( ct, var, start_byte, lendian ):
    # XXX validate signature
    var = codecs.encode(var, 'ascii')
    return 2 + len(var), [struct.pack(lendian and '<B' or '>B', len(var)), var, b'\0']


# ARRAY:
#    - Max length is 2^26
#    format:
#       1 - UINT32 length of array data (does not include alignment padding)
#       2 - Padding to required alignment of contained data type
#       3 - each array element
def marshal_array( ct, var, start_byte, lendian ):
    chunks   = list()
    data_len = 0
    tsig     = ct[1:]   # strip of leading 'a'
    tcode    = tsig[0] # type of array element

    start_byte += 4 # for array size
    
    initial_padding = pad[tcode]( start_byte )

    if initial_padding:
        start_byte += len(initial_padding)
        chunks.append( initial_padding )

    if isinstance(var, (list, tuple)):
        arr_list = var
    elif isinstance(var, dict):
        arr_list = [ tpl for tpl in six.iteritems(var) ]
    else:
        raise MarshallingError('List, Tuple, or Dictionary required for DBus array. Received: ' + repr(var))

    for item in arr_list:

        padding = pad[tcode]( start_byte )

        if padding:
            start_byte += len(padding)
            data_len   += len(padding)
            chunks.append( padding )
        
        nbytes, vchunks = marshallers[ tcode ]( tsig, item, start_byte, lendian )

        start_byte += nbytes
        data_len   += nbytes
        
        chunks.extend( vchunks )
        

    chunks.insert(0, struct.pack( lendian and '<I' or '>I', data_len))

    return 4 + len(initial_padding) + data_len, chunks
    

# STRUCT:
#    - Must start on 8 byte boundary
#    - Content consists of each field marshaled in sequence
#
def marshal_struct( ct, var, start_byte, lendian ):
    return marshal( ct[1:-1], var, start_byte, lendian )


marshal_dictionary = marshal_struct


# VARIANT:
#    - Signature must contain only a single, complete type
#    format:
#       1 - Marshaled SIGNATURE
#       2 - Any required padding to align the type specified in the signature
#       3 - Marshaled value
def marshal_variant( ct, var, start_byte, lendian ):
    # XXX: ensure only a single, complete type is in the siguature
    bstart = start_byte
    
    vsig = sigFromPy(var)
    
    nbytes, chunks = marshal_signature( ct, sigFromPy(var), start_byte, lendian )

    start_byte += nbytes

    padding = pad[vsig[0]]( start_byte )
        
    if padding:
        start_byte += len(padding)
        chunks.append( padding )
        
    rnbytes, rchunks = marshal( vsig, [var], start_byte, lendian )

    start_byte += rnbytes
    chunks.extend( rchunks )
    
    return start_byte - bstart, chunks



marshallers = { 'y' : marshal_byte,
                'b' : marshal_boolean,
                'n' : marshal_int16,
                'q' : marshal_uint16,
                'i' : marshal_int32,
                'u' : marshal_uint32,
                'x' : marshal_int64,
                't' : marshal_uint64,
                'd' : marshal_double,
                's' : marshal_string,
                'o' : marshal_object_path,
                'g' : marshal_signature,
                'a' : marshal_array,
                '(' : marshal_struct,
                'v' : marshal_variant,
                '{' : marshal_dictionary,
                'h' : marshal_uint32 }


def marshal( compoundSignature, variableList, startByte = 0, lendian=True ):
    """
    Encodes the Python objects in variableList into the DBus wire-format
    matching the supplied compoundSignature. This function retuns a list of
    binary strings is rather than a single string to simplify the recursive
    marshalling algorithm. A single string may be easily obtained from the
    result via: ''.join(list_of_binary_strings)
    
    @type compoundSignature: C{string}
    @param compoundSignature: DBus signature specifying the types of the
                              variables to encode

    @type variableList: C{list}
    @param variableList: List of variables to encode (length of the list
                         must exactly match the number of variables specified
                         in compoundSignature


    @type startByte: C{int}
    @param startByte: Used during recursive marshalling to ensure data
                      alignment requirements are met

    @type lendian: C{bool}
    @param lendian: True if the data should be serialized in
                    little-endian format

    
    @returns: (number_of_encoded_bytes, list_of_binary_strings)
    """
    chunks = list()
    bstart = startByte

    if hasattr(variableList, 'dbusOrder'):
        order = getattr(variableList, 'dbusOrder')
        variableList = [ getattr(variableList, attr_name) for attr_name in order ]

    for ct, var in zip(genCompleteTypes( compoundSignature ), variableList):
        tcode   = ct[0]
        padding = pad[tcode]( startByte )
        
        if padding:
            startByte += len(padding)
            chunks.append( padding )
        
        nbytes, vchunks = marshallers[ tcode ]( ct, var, startByte, lendian )

        startByte += nbytes
        
        chunks.extend( vchunks )
        

    return startByte - bstart, chunks



#-------------------------------------------------------------------------------
#-------------------------------------------------------------------------------
#                         Unmarshalling Functions
#-------------------------------------------------------------------------------
#-------------------------------------------------------------------------------


def unmarshal_byte(ct, data, offset, lendian):
    return 1, struct.unpack_from( lendian and '<B' or '>B', data, offset)[0]

def unmarshal_boolean(ct, data, offset, lendian):
    return 4, struct.unpack_from( lendian and '<I' or '>I', data, offset)[0] != 0

def unmarshal_int16(ct, data, offset, lendian):
    return 2, struct.unpack_from( lendian and '<h' or '>h', data, offset)[0]

def unmarshal_uint16(ct, data, offset, lendian):
    return 2, struct.unpack_from( lendian and '<H' or '>H', data, offset)[0]

def unmarshal_int32(ct, data, offset, lendian):
    return 4, struct.unpack_from( lendian and '<i' or '>i', data, offset)[0]

def unmarshal_uint32(ct, data, offset, lendian):
    return 4, struct.unpack_from( lendian and '<I' or '>I', data, offset)[0]

def unmarshal_int64(ct, data, offset, lendian):
    return 8, struct.unpack_from( lendian and '<q' or '>q', data, offset)[0]

def unmarshal_uint64(ct, data, offset, lendian):
    return 8, struct.unpack_from( lendian and '<Q' or '>Q', data, offset)[0]

def unmarshal_double(ct, data, offset, lendian):
    return 8, struct.unpack_from( lendian and '<d' or '>d', data, offset)[0]


# STRING:
#    - *must* be valid UTF-8, nul terminated with no embedded nuls
#    format:
#       1 - UINT32 length in bytes (excluding terminating nul)
#       2 - string data (no embedded nuls)
#       3 - terminating nul byte
#
def unmarshal_string(ct, data, offset, lendian):
    slen = struct.unpack_from( lendian and '<I' or '>I', data, offset)[0]
    s = codecs.decode(data[ offset + 4 :  offset + 4 + slen ], 'utf-8')
    return 4 + slen + 1, s
    

# OBJECT_PATH:
#    - Identical to string
#    
unmarshal_object_path = unmarshal_string


# SIGNATURE:
#    - Ends with nul byte
#    - List of complete types. No partial types permitted
#    - Max signature length is 255
#    format:
#       1 - Single byte length
#       2 - Valid signature string
#       3 - terminating nul byte
def unmarshal_signature(ct, data, offset, lendian):
    slen = struct.unpack_from( lendian and '<B' or '>B', data, offset)[0]
    s = codecs.decode(data[ offset + 1 : offset + 1 + slen ], 'ascii')
    return 1 + slen + 1, s
    

# ARRAY:
#    - Max length is 2^26
#    format:
#       1 - UINT32 length of array data (does not include alignment padding)
#       2 - Padding to required alignment of contained data type
#       3 - each array element
def unmarshal_array(ct, data, offset, lendian):
    start_offset = offset
    values       = list()
    data_len     = struct.unpack_from( lendian and '<I' or '>I', data, offset)[0]
    tsig         = ct[1:]  # strip of leading 'a'
    tcode        = tsig[0] # type of array element
    
    offset += 4                         # 4-byte data length
    offset += len(pad[tcode]( offset )) # padding length
    
    end_offset = offset + data_len
    
    while offset < end_offset:

        offset += len(pad[tcode](offset))
        
        nbytes, value = unmarshallers[ tcode ]( tsig, data, offset, lendian )

        offset += nbytes
        values.append( value )

    if not offset == end_offset:
        raise MarshallingError('Invalid array encoding')

    if tcode == '{':
        d = dict()
        for item in values:
            d[ item[0] ] = item[1]
        values = d

    return offset - start_offset, values
    

# STRUCT:
#    - Must start on 8 byte boundary
#    - Content consists of each field marshaled in sequence
#
def unmarshal_struct(ct, data, offset, lendian):
    return unmarshal( ct[1:-1], data, offset, lendian )


unmarshal_dictionary = unmarshal_struct


# VARIANT:
#    - Signature must contain only a single, complete type
#    format:
#       1 - Marshaled SIGNATURE
#       2 - Any required padding to align the type specified in the signature
#       3 - Marshaled value
def unmarshal_variant(ct, data, offset, lendian):
    # XXX: ensure only a single, complete type is in the siguature
    start_offset = offset
    nsig, vsig = unmarshal_signature( ct, data, offset, lendian )

    offset += nsig
    
    offset += len(pad[vsig[0]](offset))

    nvar, value = unmarshal( vsig, data, offset, lendian )

    offset += nvar
    
    return offset - start_offset, value[0]




unmarshallers = { 'y' : unmarshal_byte,
                  'b' : unmarshal_boolean,
                  'n' : unmarshal_int16,
                  'q' : unmarshal_uint16,
                  'i' : unmarshal_int32,
                  'u' : unmarshal_uint32,
                  'x' : unmarshal_int64,
                  't' : unmarshal_uint64,
                  'd' : unmarshal_double,
                  's' : unmarshal_string,
                  'o' : unmarshal_object_path,
                  'g' : unmarshal_signature,
                  'a' : unmarshal_array,
                  '(' : unmarshal_struct,
                  'v' : unmarshal_variant,
                  '{' : unmarshal_dictionary,
                  'h' : unmarshal_uint32 }


def unmarshal( compoundSignature, data, offset = 0, lendian = True ):
    """
    Unmarshals DBus encoded data.

    @type compoundSignature: C{string}
    @param compoundSignature: DBus signature specifying the encoded value types

    @type data: C{string}
    @param data: Binary data

    @type offset: C{int}
    @param offset: Offset within data at which data for compoundSignature
                   starts (used during recursion)

    @type lendian: C{bool}
    @param lendian: True if data is encoded in little-endian format
    
    @returns: (number_of_bytes_decoded, list_of_values)
    """
    values       = list()
    start_offset = offset

    for ct in genCompleteTypes( compoundSignature ):
        tcode   = ct[0]
        offset += len(pad[tcode]( offset ))
                
        nbytes, value = unmarshallers[ tcode ]( ct, data, offset, lendian )

        offset += nbytes
        values.append( value )


    return offset - start_offset, values




########NEW FILE########
__FILENAME__ = message
"""
Module to represent DBus Messages

@author: Tom Cocagne
"""
from __future__ import absolute_import, print_function

from . import marshal, error


_headerFormat = 'yyyyuua(yv)'

    
class DBusMessage (object):
    """
    Abstract base class for DBus messages

    @ivar _messageType: C{int} DBus message type
    @ivar expectReply: True if a method return message is expected
    @ivar autoStart: True if a service should be auto started by this message
    @ivar signature: C{str} DBus signature describing the body content
    @ivar endian: C{int} containing endian code: Little endian = ord('l'). Big
                  endian is ord('B'). Defaults to little-endian
    @ivar bodyLength: Length of the body in bytes
    @ivar serial: C{int} message serial number
    @ivar rawMessage: Raw binary message data
    @ivar rawHeader: Raw binary message header
    @ivar rawBody: Raw binary message body
    @ivar interface: C{str} DBus interface name
    @ivar path: C{str} DBus object path
    @ivar sender: C{str} DBus bus name for sending connection
    @ivar destination: C{str} DBus bus name for destination connection
    
    """
    _maxMsgLen         = 2**27
    _nextSerial        = 1
    _protocolVersion   = 1

    # Overriden by subclasses
    _messageType       = 0    
    _headerAttrs       = None # [(attr_name, code, is_required), ...]

    # Set prior to marshal or during/after unmarshalling
    expectReply        = True 
    autoStart          = True
    signature          = None
    body               = None

    # Set during marshalling/unmarshalling
    endian             = ord('l')
    bodyLength         = 0     
    serial             = None
    headers            = None
    rawMessage         = None

    # Required/Optional
    interface          = None
    path               = None
    
    # optional
    sender             = None
    destination        = None


#    def printSelf(self):
#        mtype = { 1 : 'MethodCall',
#                  2 : 'MethodReturn',
#                  3 : 'Error',
#                  4 : 'Signal' }
#        print mtype[self._messageType]
#        keys = self.__dict__.keys()
#        keys.sort()
#        for a in keys:
#            if not a.startswith('raw'):
#                print '    %s = %s' % (a.ljust(15), str(getattr(self,a)))

    
    def _marshal(self, newSerial=True):
        """
        Encodes the message into binary format. The resulting binary message is
        stored in C{self.rawMessage}
        """
        flags = 0

        if not self.expectReply:
            flags |= 0x1

        if not self.autoStart:
            flags |= 0x2
        
        self.headers = list()
        
        for attr_name, code, is_required in self._headerAttrs:
            hval = getattr(self, attr_name, None)
            
            if hval is not None:
                if attr_name == 'path':
                    hval = marshal.ObjectPath(hval)
                elif attr_name == 'signature':
                    hval = marshal.Signature(hval)
                    
                self.headers.append( [code, hval] )

        if self.signature:
            binBody = b''.join( marshal.marshal( self.signature, self.body )[1] )
        else:
            binBody = b''

        self.bodyLength = len(binBody)

        if newSerial:
            self.serial = DBusMessage._nextSerial

            DBusMessage._nextSerial += 1
        
        binHeader = b''.join(marshal.marshal(_headerFormat,
                                            [self.endian,
                                             self._messageType,
                                             flags,
                                             self._protocolVersion,
                                             self.bodyLength,
                                             self.serial,
                                             self.headers],
                                            lendian = self.endian == ord('l') )[1])
        
        headerPadding = marshal.pad['header']( len(binHeader) )

        self.rawHeader  = binHeader
        self.rawPadding = headerPadding
        self.rawBody    = binBody
        
        self.rawMessage = b''.join( [binHeader, headerPadding, binBody] )

        if len(self.rawMessage) > self._maxMsgLen:
            raise error.MarshallingError('Marshalled message exceeds maximum message size of %d' %
                                         (self._maxMsgLen,))



class MethodCallMessage (DBusMessage):
    """
    A DBus Method Call Message
    """
    _messageType = 1
    _headerAttrs = [ ('path',        1, True ),
                     ('interface',   2, False),
                     ('member',      3, True ),
                     ('destination', 6, False),
                     ('sender',      7, False),
                     ('signature',   8, False) ]


    def __init__(self, path, member, interface=None, destination=None,
                 signature=None, body=None,
                 expectReply=True, autoStart=True):
        """
        @param path: C{str} DBus object path
        @param member: C{str} Member name
        @param interface: C{str} DBus interface name or None
        @param destination: C{str} DBus bus name for message destination or
                            None
        @param signature: C{str} DBus signature string for encoding
                          C{self.body}
        @param body: C{list} of python objects to encode. Objects must match
                     the C{self.signature}
        @param expectReply: True if a Method Return message should be sent
                            in reply to this message
        @param autoStart: True if the Bus should auto-start a service to handle
                          this message if the service is not already running.
        """
        
        marshal.validateMemberName( member )
        
        if interface:
            marshal.validateInterfaceName(interface)
            
        if destination:
            marshal.validateBusName(destination)

        if path == '/org/freedesktop/DBus/Local':
            raise error.MarshallingError('/org/freedesktop/DBus/Local is a reserved path')
            
        self.path         = path
        self.member       = member
        self.interface    = interface
        self.destination  = destination
        self.signature    = signature
        self.body         = body
        self.expectReply  = expectReply
        self.autoStart    = autoStart

        self._marshal()
        


class MethodReturnMessage (DBusMessage):
    """
    A DBus Method Return Message
    """
    _messageType = 2
    _headerAttrs = [ ('reply_serial', 5, True ),
                     ('destination',  6, False),
                     ('sender',       7, False),
                     ('signature',    8, False) ]

    def __init__(self, reply_serial, body=None,
                 destination=None, signature=None):
        """
        @param reply_serial: C{int} serial number this message is a reply to
        @param destination: C{str} DBus bus name for message destination or
                            None
        @param signature: C{str} DBus signature string for encoding
                          C{self.body}
        @param body: C{list} of python objects to encode. Objects must match
                     the C{self.signature}
        """
        if destination:
            marshal.validateBusName(destination)

        self.reply_serial = marshal.UInt32(reply_serial)
        self.destination  = destination
        self.signature    = signature
        self.body         = body

        self._marshal()


class ErrorMessage (DBusMessage):
    """
    A DBus Error Message
    """
    _messageType = 3
    _headerAttrs = [ ('error_name',   4, True ),
                     ('reply_serial', 5, True ),
                     ('destination',  6, False),
                     ('sender',       7, False),
                     ('signature',    8, False) ]

    def __init__(self, error_name, reply_serial, destination=None, signature=None,
                 body=None, sender=None):
        """
        @param error_name: C{str} DBus error name
        @param reply_serial: C{int} serial number this message is a reply to
        @param destination: C{str} DBus bus name for message destination or
                            None
        @param signature: C{str} DBus signature string for encoding
                          C{self.body}
        @param body: C{list} of python objects to encode. Objects must match
                     the C{self.signature}
        @param sender: C{str} name of the originating Bus connection
        """
        if destination:
            marshal.validateBusName(destination)

        marshal.validateInterfaceName(error_name)

        self.error_name   = error_name
        self.reply_serial = marshal.UInt32(reply_serial)
        self.destination  = destination
        self.signature    = signature
        self.body         = body
        self.sender       = sender

        self._marshal()


        
class SignalMessage (DBusMessage):
    """
    A DBus Signal Message
    """
    _messageType = 4
    _headerAttrs = [ ('path',        1, True ),
                     ('interface',   2, True ),
                     ('member',      3, True ),
                     ('destination', 6, False),
                     ('sender',      7, False),
                     ('signature',   8, False) ]

    def __init__(self, path, member, interface, destination=None, signature=None,
                 body=None):
        """
        @param path: C{str} DBus object path of the object sending the signal
        @param member: C{str} Member name
        @param interface: C{str} DBus interface name or None
        @param destination: C{str} DBus bus name for message destination or
                            None
        @param signature: C{str} DBus signature string for encoding
                          C{self.body}
        @param body: C{list} of python objects to encode. Objects must match
                     the C{self.signature}
        """
        marshal.validateMemberName( member )
        marshal.validateInterfaceName(interface)
            
        if destination:
            marshal.validateBusName(destination)
            
        self.path        = path
        self.member      = member
        self.interface   = interface
        self.destination = destination
        self.signature   = signature
        self.body        = body

        self._marshal()


_mtype = { 1 : MethodCallMessage,
           2 : MethodReturnMessage,
           3 : ErrorMessage,
           4 : SignalMessage }

_hcode = { 1 : 'path',
           2 : 'interface',
           3 : 'member',
           4 : 'error_name',
           5 : 'reply_serial',
           6 : 'destination',
           7 : 'sender',
           8 : 'signature',
           9 : 'unix_fds' }


def parseMessage( rawMessage ):
    """
    Parses the raw binary message and returns a L{DBusMessage} subclass

    @type rawMessage: C{str}
    @param rawMessage: Raw binary message to parse

    @rtype: L{DBusMessage} subclass
    @returns: The L{DBusMessage} subclass corresponding to the contained
              message
    """

    lendian = rawMessage[0] == b'l'[0]
    
    nheader, hval = marshal.unmarshal(_headerFormat, rawMessage, 0, lendian)

    messageType = hval[1]

    if not messageType in _mtype:
        raise error.MarshallingError('Unknown Message Type: ' + str(messageType))

    m = object.__new__( _mtype[messageType] )

    m.rawHeader = rawMessage[:nheader]

    npad = nheader % 8 and (8 - nheader%8) or 0

    m.rawPadding = rawMessage[nheader: nheader+npad]

    m.rawBody = rawMessage[ nheader + npad: ]

    m.serial = hval[5]
    
    for code, v in hval[6]:
        try:
            setattr(m, _hcode[code], v)
        except KeyError:
            pass
        
    if m.signature:
        nbytes, m.body = marshal.unmarshal(m.signature, m.rawBody, lendian = lendian)

    return m

    
        
        
        
        

########NEW FILE########
__FILENAME__ = util
#
# This file is part of Gruvi. Gruvi is free software available under the
# terms of the MIT license. See the file "LICENSE" that was provided
# together with this source file for the licensing terms.
#
# Copyright (c) 2012-2013 the Gruvi authors. See the file "AUTHORS" for a
# complete list.

from __future__ import absolute_import, print_function

import re
import threading
import six

from weakref import WeakKeyDictionary

__all__ = []


def docfrom(base):
    """Decorator to set a function's docstring from another function."""
    def setdoc(func):
        func.__doc__ = (getattr(base, '__doc__') or '') + (func.__doc__ or '')
        return func
    return setdoc


_objrefs = WeakKeyDictionary()  # obj -> objref
_lastids = {}  # classname -> lastid

def objref(obj):
    """Return a string that uniquely and compactly identifies an object."""
    ref = _objrefs.get(obj)
    if ref is None:
        clsname = obj.__class__.__name__.split('.')[-1]
        seqno = _lastids.setdefault(clsname, 1)
        ref = '{0}-{1}'.format(clsname, seqno)
        _objrefs[obj] = ref
        _lastids[clsname] += 1
    return ref


re_lu = re.compile('[A-Z]+[a-z0-9]+')

def split_cap_words(s):
    """Split the CamelCase string *s* into words."""
    return re_lu.findall(s)


# Support Python 2.7+ implictly indexed positional argument specifiers also on
# Python 2.6. Also remove the non-supported ',' format specifier

# {{ and }} are escape characters. Use negative lookbehind/ahead to ensure
# an odd number of braces on either side.
re_pos_arg = re.compile(r'(?<!\{)((?:\{\{)*\{)([:!][^}]+)?(\}(?:\}\})*)(?!\})')

def fixup_format_string(fmt):
    """Transform a format string with implicitly numbered positional arguments
    so that it will work on Python 2.6."""
    count = [0]
    def replace(mobj):
        field = str(count[0]); count[0] += 1
        spec = (mobj.group(2) or '').replace(',', '')
        return mobj.group(1) + field + spec + mobj.group(3)
    return re_pos_arg.sub(replace, fmt)


# Provide a get_thread_ident() that is the same on Python 2.x and 3.x
if six.PY3:
    get_thread_ident = threading.get_ident
else:
    get_thread_ident = threading._get_ident

########NEW FILE########
__FILENAME__ = runtests
#
# This file is part of Gruvi. Gruvi is free software available under the
# terms of the MIT license. See the file "LICENSE" that was provided
# together with this source file for the licensing terms.
#
# Copyright (c) 2012-2014 the Gruvi authors. See the file "AUTHORS" for a
# complete list.

from __future__ import absolute_import, print_function

import os
import sys

from argparse import ArgumentParser

if sys.version_info[:2] >= (2,7):
    from unittest import TestLoader, TextTestRunner
else:
    from unittest2 import TestLoader, TextTestRunner


parser = ArgumentParser()
parser.add_argument('suite', help='the test suite to run',
                     choices=('unit', 'performance', 'memory', 'documentation'))
args = parser.parse_args()
suite = args.suite

# Change directory to tests/ irrespective of where we're called from.
topdir = os.path.split(os.path.abspath(__file__))[0]
testdir = os.path.join(topdir, 'tests')
os.chdir(testdir)

# If running under tox, replace the entry for the current directory on sys.path
# with the test directory. This prevents the tox runs from running in the
# potentially unclean environment from the checkout our source tree.
# Otherwise, if not running under tox, we want the option to run from the
# current directory, so we add the test directory instead.
if os.environ.get('TOX') == 'yes':
    sys.path[0] = testdir
else:
    sys.path.insert(0, testdir)

from support import *

if suite == 'unit':
    pattern = 'test_*.py'
elif suite == 'performance':
    pattern = 'perf_*.py'
    PerformanceTest.setup_loader()
    PerformanceTest.start_new_results()
elif suite == 'memory':
    pattern = 'memory.py'
    MemoryTest.setup_loader()
    MemoryTest.start_new_results()
elif suite == 'documentation':
    pattern = 'documentation.py'

loader = TestLoader()
tests = loader.discover('.', pattern)

runner = TextTestRunner(verbosity=1, buffer=False)
result = runner.run(tests)
if result.errors or result.failures:
    sys.exit(1)

########NEW FILE########
__FILENAME__ = documentation
#
# This file is part of Gruvi. Gruvi is free software available under the
# terms of the MIT license. See the file "LICENSE" that was provided
# together with this source file for the licensing terms.
#
# Copyright (c) 2012-2014 the Gruvi authors. See the file "AUTHORS" for a
# complete list.

from __future__ import absolute_import, print_function

import os
import sphinx
from support import *


class TestDocumentation(TestCase):

    def test_build_docs(self):
        docdir = os.path.join(self.topdir, 'docs')
        os.chdir(docdir)
        htmldir = self.tempdir
        ret = sphinx.main(['sphinx', '-b', 'html', '-nW', '.', htmldir])
        self.assertEquals(ret, 0)


if __name__ == '__main__':
    unittest.main()

########NEW FILE########
__FILENAME__ = memory
#
# This file is part of Gruvi. Gruvi is free software available under the
# terms of the MIT license. See the file "LICENSE" that was provided
# together with this source file for the licensing terms.
#
# Copyright (c) 2012-2014 the Gruvi authors. See the file "AUTHORS" for a
# complete list.

from __future__ import absolute_import, print_function

import gruvi
from gruvi.logging import get_logger
from support import *


class TestMemory(MemoryTest):

    def mem_fiber(self):
        self.add_result(sizeof(gruvi.Fiber(lambda: None), exclude=('_log', '_hub', '_thread')))

    def mem_switch_back(self):
        self.add_result(sizeof(gruvi.switch_back(), exclude=('_hub', '_fiber')))

    def mem_assert_no_switchpoints(self):
        self.add_result(sizeof(gruvi.assert_no_switchpoints(), exclude=('_hub',)))

    def mem_hub(self):
        self.add_result(sizeof(gruvi.Hub(), exclude=('_log', '_thread')))

    def mem_lock(self):
        self.add_result(sizeof(gruvi.Lock()))

    def mem_rlock(self):
        self.add_result(sizeof(gruvi.RLock()))

    def mem_event(self):
        self.add_result(sizeof(gruvi.Event()))

    def mem_condition(self):
        self.add_result(sizeof(gruvi.Condition()))

    def mem_queue(self):
        # In a Queue there's 2 conditions that share the same lock.
        queue = gruvi.Queue()
        self.add_result(sizeof(queue, exclude=('_lock',)) + sizeof(queue._lock))

    def mem_lifoqueue(self):
        self.add_result(sizeof(gruvi.LifoQueue(), exclude=('_lock',)) + sizeof(gruvi.Lock()))

    def mem_priorityqueue(self):
        self.add_result(sizeof(gruvi.PriorityQueue(), exclude=('_lock',)) + sizeof(gruvi.Lock()))

    def mem_logger(self):
        self.add_result(sizeof(get_logger(), exclude=('logger',)))


if __name__ == '__main__':
    TestMemory.setup_loader()
    unittest.main()

########NEW FILE########
__FILENAME__ = perf_dbus
#
# This file is part of Gruvi. Gruvi is free software available under the
# terms of the MIT license. See the file "LICENSE" that was provided
# together with this source file for the licensing terms.
#
# Copyright (c) 2012-2014 the Gruvi authors. See the file "AUTHORS" for a
# complete list.

from __future__ import absolute_import, print_function, division

import time

from gruvi.dbus import *
from support import *
from test_dbus import echo_app


class PerfDBus(PerformanceTest):

    def perf_message_throughput_pipe(self):
        # Test roundtrips of a simple method call over a Pipe
        server = DbusServer(echo_app)
        addr = 'unix:path=' + self.pipename()
        server.listen(addr)
        client = DbusClient()
        client.connect(addr)
        nmessages = 0
        t0 = t1 = time.time()
        while t1 - t0 < 1:
            client.call_method('bus.name', '/path', 'my.iface', 'Echo')
            t1 = time.time()
            nmessages += 1
        throughput = nmessages / (t1 - t0)
        self.add_result(throughput)

    def perf_message_throughput_tcp(self):
        # Test roundtrips of a simple method call over TCP.
        server = DbusServer(echo_app)
        addr = 'tcp:host=127.0.0.1,port=0'
        server.listen(addr)
        client = DbusClient()
        client.connect(server.addresses[0])
        nmessages = 0
        t0 = t1 = time.time()
        while t1 - t0 < 1:
            client.call_method('bus.name', '/path', 'my.iface', 'Echo')
            t1 = time.time()
            nmessages += 1
        throughput = nmessages / (t1 - t0)
        self.add_result(throughput)


if __name__ == '__main__':
    unittest.defaultTestLoader.testMethodPrefix = 'perf'
    unittest.main()

########NEW FILE########
__FILENAME__ = perf_fibers
#
# This file is part of Gruvi. Gruvi is free software available under the
# terms of the MIT license. See the file "LICENSE" that was provided
# together with this source file for the licensing terms.
#
# Copyright (c) 2012-2014 the Gruvi authors. See the file "AUTHORS" for a
# complete list.

from __future__ import absolute_import, print_function

import time

from gruvi.fibers import *
from support import *


def dummy_main():
    pass

def switch_parent(parent):
    while True:
        parent.switch()


class PerfFiber(PerformanceTest):

    def xperf_spawn_throughput(self):
        t0 = t1 = time.time()
        fibers = []
        while t1 - t0 < 0.2:
            fiber = Fiber(dummy_main)
            fiber._hub = current_fiber()
            fiber.switch()
            fibers.append(fiber)
            t1 = time.time()
        speed = len(fibers) / (t1 - t0)
        self.add_result(speed)

    def perf_switch_throughput(self):
        t0 = t1 = time.time()
        count = 0
        fiber = Fiber(switch_parent, args=(current_fiber(),))
        fiber._hub = current_fiber()
        while t1 - t0 < 0.2:
            fiber.switch()
            count += 1
            t1 = time.time()
        speed = count / (t1 - t0)
        self.add_result(speed)


if __name__ == '__main__':
    unittest.defaultTestLoader.testMethodPrefix = 'perf'
    unittest.main()

########NEW FILE########
__FILENAME__ = perf_http
#
# This file is part of Gruvi. Gruvi is free software available under the
# terms of the MIT license. See the file "LICENSE" that was provided
# together with this source file for the licensing terms.
#
# Copyright (c) 2012-2014 the Gruvi authors. See the file "AUTHORS" for a
# complete list.

from __future__ import absolute_import, print_function, division

import time

from gruvi.http import HttpProtocol
from support import *


class PerfHttp(PerformanceTest):

    def perf_parsing_speed(self):
        transport = MockTransport()
        protocol = HttpProtocol(False)
        transport.start(protocol)
        r = b'HTTP/1.1 200 OK\r\nContent-Length: 1000\r\n\r\n'
        r += b'x' * 1000
        reqs = 10 * r
        nbytes = 0
        t0 = t1 = time.time()
        while t1 - t0 < 1:
            protocol.data_received(reqs)
            protocol._queue.clear()
            nbytes += len(reqs)
            t1 = time.time()
        speed = nbytes / (t1 - t0) / (1024 * 1024)
        self.add_result(speed)


if __name__ == '__main__':
    unittest.defaultTestLoader.testMethodPrefix = 'perf'
    unittest.main()

########NEW FILE########
__FILENAME__ = perf_jsonrpc
#
# This file is part of Gruvi. Gruvi is free software available under the
# terms of the MIT license. See the file "LICENSE" that was provided
# together with this source file for the licensing terms.
#
# Copyright (c) 2012-2014 the Gruvi authors. See the file "AUTHORS" for a
# complete list.

from __future__ import absolute_import, print_function, division

import time

from gruvi.jsonrpc import *
from gruvi import jsonrpc_ffi

from support import *
from test_jsonrpc import set_buffer, echo_app


class PerfJsonRpc(PerformanceTest):

    def perf_split_throughput(self):
        chunk = b'{' + b'x' * 1000 + b'}'
        buf = chunk * 10
        ctx = jsonrpc_ffi.ffi.new('struct split_context *')
        nbytes = 0
        t0 = t1 = time.time()
        while t1 - t0 < 1:
            set_buffer(ctx, buf)
            while ctx.offset != len(buf):
                error = jsonrpc_ffi.lib.json_split(ctx)
                self.assertEqual(error, 0)
            nbytes += len(buf)
            t1 = time.time()
        speed = nbytes / (t1 - t0) / (1024 * 1024)
        self.add_result(speed)

    def perf_message_throughput(self):
        server = JsonRpcServer(echo_app)
        server.listen(('127.0.0.1', 0))
        addr = server.addresses[0]
        client = JsonRpcClient()
        client.connect(addr)
        nrequests = 0
        t0 = t1 = time.time()
        while t1 - t0 < 1:
            result = client.call_method('echo', 'foo')
            self.assertEqual(result, ['foo'])
            nrequests += 1
            t1 = time.time()
        throughput = nrequests / (t1 - t0)
        self.add_result(throughput)


if __name__ == '__main__':
    unittest.defaultTestLoader.testMethodPrefix = 'perf'
    unittest.main()

########NEW FILE########
__FILENAME__ = perf_ssl
#
# This file is part of Gruvi. Gruvi is free software available under the
# terms of the MIT license. See the file "LICENSE" that was provided
# together with this source file for the licensing terms.
#
# Copyright (c) 2012-2014 the Gruvi authors. See the file "AUTHORS" for a
# complete list.

from __future__ import absolute_import, print_function, division

import os
import time
import ssl

import gruvi
from gruvi.ssl import SslPipe
from support import *
from test_ssl import communicate

if hasattr(ssl, 'SSLContext'):
    from ssl import SSLContext
else:
    from gruvi.sslcompat import SSLContext


class PerfSsl(PerformanceTest):

    def setUp(self):
        if not os.access(self.certname, os.R_OK):
            raise SkipTest('no certificate available')
        super(PerfSsl, self).setUp()
        context = SSLContext(ssl.PROTOCOL_SSLv23)
        context.load_cert_chain(self.certname, self.certname)
        self.client = SslPipe(context, False)
        self.server = SslPipe(context, True)

    def perf_throughput(self):
        client, server = self.client, self.server
        buf = b'x' * 65536
        nbytes = 0
        clientssl = client.do_handshake()
        server.do_handshake()
        t0 = t1 = time.time()
        while t1 - t0 < 1:
            received = communicate(buf, client, server, clientssl, [])
            if clientssl:
                clientssl = []
            nbytes += len(received)
            t1 = time.time()
        cipher = server.sslinfo.cipher()[0].lower().replace('-', '_')
        name = 'ssl_throughput_{0}'.format(cipher)
        speed = nbytes / (t1 - t0) / (1024 * 1024)
        self.add_result(speed, name=name)
        client.close()
        server.close()


if __name__ == '__main__':
    unittest.defaultTestLoader.testMethodPrefix = 'perf'
    unittest.main()

########NEW FILE########
__FILENAME__ = support
#
# This file is part of Gruvi. Gruvi is free software available under the
# terms of the MIT license. See the file "LICENSE" that was provided
# together with this source file for the licensing terms.
#
# Copyright (c) 2012-2014 the Gruvi authors. See the file "AUTHORS" for a
# complete list.

from __future__ import absolute_import, print_function

import os
import sys
import shutil
import socket
import tempfile
import logging
import subprocess
import functools
import errno
import ssl
import six

if sys.version_info[:2] >= (2,7):
    import unittest
else:
    import unittest2 as unittest

SkipTest = unittest.SkipTest

from gruvi.logging import get_log_level
from gruvi.util import split_cap_words
from gruvi.endpoints import create_ssl_context


__all__ = ['TestCase', 'UnitTest', 'PerformanceTest', 'MemoryTest', 'SkipTest',
           'unittest', 'sizeof', 'MockTransport']


def setup_logging():
    """Configure a logger to output to stdout."""
    logger = logging.getLogger()
    if logger.handlers:
        return
    logger.setLevel(get_log_level())
    handler = logging.StreamHandler(sys.stdout)
    template = '%(levelname)s %(message)s'
    handler.setFormatter(logging.Formatter(template))
    logger.addHandler(handler)


def create_ssl_certificate(fname):
    """Create a new SSL private key and self-signed certificate, and store
    them both in the file *fname*."""
    try:
        openssl = subprocess.Popen(['openssl', 'req', '-new',
                        '-newkey', 'rsa:1024', '-x509', '-subj', '/CN=test/',
                        '-days', '365', '-nodes', '-batch',
                        '-out', fname, '-keyout', fname],
                        stdout=subprocess.PIPE, stderr=subprocess.PIPE)
    except OSError:
        sys.stderr.write('Error: openssl not found. SSL tests disabled.\n')
        return
    stdout, stderr = openssl.communicate()
    if openssl.returncode:
        sys.stderr.write('Error: key generation failed\n')
        sys.stderr.write('openssl stdout: {0}\n'.format(stdout))
        sys.stderr.write('openssl stderr: {0}\n'.format(stderr))


def sizeof(obj, exclude=None):
    """Return the size in bytes of *obj*."""
    if obj is None or obj is False or obj is True:
        return 0
    size = sys.getsizeof(obj)
    if hasattr(obj, '__dict__'):
        size += sys.getsizeof(obj.__dict__)
        for key,value in obj.__dict__.items():
            if exclude is not None and key in exclude:
                continue
            s = sizeof(key)
            s += sizeof(value, exclude)
            #print('{}.{}: {}'.format(type(obj).__name__, key, s))
            size += s
    elif hasattr(obj, '__slots__'):
        for key in obj.__slots__:
            if hasattr(obj, key):
                if exclude is not None and key in exclude:
                    continue
                s = sizeof(getattr(obj, key), exclude)
                #print('{}.{}: {}'.format(type(obj).__name__, key, s))
                size += s
    return size


class TestCase(unittest.TestCase):
    """Base class for test suites."""

    @classmethod
    def setUpClass(cls):
        setup_logging()
        cls.testdir = os.path.abspath(os.path.split(__file__)[0])
        cls.topdir = os.path.split(cls.testdir)[0]
        os.chdir(cls.testdir)
        certname = 'testcert.pem'
        if not os.access(certname, os.R_OK):
            create_ssl_certificate(certname)
        cls.certname = certname

    def setUp(self):
        self._tmpindex = 1
        self.__tmpdir = tempfile.mkdtemp('gruvi-test')
        self.__tmpinode = os.stat(self.__tmpdir).st_ino

    def tearDown(self):
        # Some paranoia checks to make me feel better before calling
        # shutil.rmtree()..
        assert '/..' not in self.__tmpdir and '\\..' not in self.__tmpdir
        assert os.stat(self.__tmpdir).st_ino == self.__tmpinode
        try:
            shutil.rmtree(self.__tmpdir)
        except OSError:
            # On Windows a WindowsError is raised when files are
            # still open (WindowsError inherits from OSError).
            pass
        self.__tmpdir = None
        self.__tmpinode = None

    @property
    def tempdir(self):
        return self.__tmpdir

    def tempname(self, name=None):
        if name is None:
            name = 'tmpfile-{0}'.format(self._tmpindex)
            self._tmpindex += 1
        return os.path.join(self.__tmpdir, name)

    def pipename(self, name=None, abstract=False):
        if name is None:
            name = 'tmppipe-{0}'.format(self._tmpindex)
            self._tmpindex += 1
        if sys.platform.startswith('win'):
            return r'\\.\pipe\{0}-{1}'.format(name, os.getpid())
        else:
            prefix = '\x00' if sys.platform.startswith('linux') and abstract else ''
            return prefix + self.tempname(name)

    def get_ssl_context(self):
        context = create_ssl_context(certfile=self.certname, keyfile=self.certname)
        if hasattr(context, 'check_hostname'):
            context.check_hostname = None  # Python 3.4+
        context.verify_mode = ssl.CERT_NONE
        return context

    def assertRaises(self, exc, func, *args, **kwargs):
        # Like unittest.assertRaises, but returns the exception.
        try:
            func(*args, **kwargs)
        except exc as e:
            exc = e
        except Exception as e:
            self.fail('Wrong exception raised: {0!s}'.format(e))
        else:
            self.fail('Exception not raised: {0!s}'.format(exc))
        return exc


class UnitTest(TestCase):
    """Base class for unit tests."""


class PerformanceTest(TestCase):
    """Base class for performance tests."""

    results_name = 'performance.txt'
    test_prefix = 'perf'

    def add_result(self, result, params={}, name=None):
        """Add a performance test result."""
        if name is None:
            frame = sys._getframe(1)
            clsname = frame.f_locals.get('self', '').__class__.__name__
            methname = frame.f_code.co_name
            names = split_cap_words(clsname)
            name = '{0}_{1}'.format(''.join(names[1:]), methname[len(self.test_prefix)+1:]).lower()
        if params is not None:
            params = ','.join(['{0}={1}'.format(k, params[k]) for k in params])
        with open(self.results_name, 'a') as fout:
            fout.write('{0:<32s} {1:<16.2f} {2:s}\n'.format(name, result, params))

    @classmethod
    def setup_loader(cls):
        unittest.TestLoader.testMethodPrefix = cls.test_prefix

    @classmethod
    def start_new_results(cls):
        try:
            os.unlink(cls.results_name)
        except OSError:
            pass


class MemoryTest(PerformanceTest):
    """Special case of a performance test that writes to memory.txt."""

    results_name = 'memory.txt'
    test_prefix = 'mem'


class MockTransport(object):
    """A mock transport.

    All writes are redirected to a BytesIO instance.
    """

    write_buffer_size = 65536

    def __init__(self):
        self.buffer = six.BytesIO()
        self.reading = False
        self.writing = True
        self.protocol = None
        self.set_write_buffer_limits()
        self.closed = False
        self.eof = False

    def start(self, protocol):
        self.protocol = protocol
        self.protocol.connection_made(self)
        self.reading = True

    def feed(self, data):
        self.protocol.data_received(data)

    def feed_eof(self):
        self.protocol.eof_received()

    def get_extra_info(self, name, default=None):
        if name == 'unix_creds':
            if hasattr(socket, 'SO_PEERCRED'):
                return (os.getpid(), os.getuid(), os.getgid())
            return default
        else:
            return default

    def set_write_buffer_limits(self, high=None, low=None):
        if high is None:
            high = self.write_buffer_size
        if low is None:
            low = high // 2
        if low > high:
            low = high
        self.write_buffer_high = high
        self.write_buffer_low = low

    def get_write_buffer_size(self):
        return len(self.buffer.getvalue())

    def pause_reading(self):
        if not self.reading:
            raise RuntimeError('not reading')
        self.reading = False

    def resume_reading(self):
        if self.reading:
            raise RuntimeError('already reading')
        self.reading = True

    def write(self, buf):
        self.buffer.write(buf)
        if len(self.buffer.getvalue()) > self.write_buffer_high:
            self.protocol.pause_writing()

    def writelines(self, seq):
        self.buffer.writelines(seq)

    def write_eof(self):
        self.eof = True

    def can_write_eof(self):
        return True

    def close(self):
        self.closed = True

    def abort(self):
        self.closed = True

########NEW FILE########
__FILENAME__ = test_dbus
#
# This file is part of Gruvi. Gruvi is free software available under the
# terms of the MIT license. See the file "LICENSE" that was provided
# together with this source file for the licensing terms.
#
# Copyright (c) 2012-2014 the Gruvi authors. See the file "AUTHORS" for a
# complete list.

from __future__ import absolute_import, print_function

import os
import six
import socket

import gruvi
from gruvi import txdbus
from gruvi.dbus import *
from gruvi.dbus import parse_dbus_header, TxdbusAuthenticator
from gruvi.transports import TransportError

from support import *


class TestParseDbusHeader(UnitTest):

    def test_simple(self):
        m = b'l\1\0\1\0\0\0\0\1\0\0\0\0\0\0\0'
        self.assertEqual(parse_dbus_header(m), len(m))

    def test_big_endian(self):
        m = b'B\1\0\1\0\0\0\0\0\0\0\1\0\0\0\0'
        self.assertEqual(parse_dbus_header(m), len(m))

    def test_header_array(self):
        m = b'l\1\0\1\0\0\0\0\1\0\0\0\10\0\0\0h2345678'
        self.assertEqual(parse_dbus_header(m), len(m))
        for l in range(16, len(m)):
            self.assertEqual(parse_dbus_header(m[:l]), len(m))

    def test_padding(self):
        m = b'l\1\0\1\0\0\0\0\1\0\0\0\11\0\0\0h234567812345678'
        self.assertEqual(parse_dbus_header(m), len(m))
        for l in range(16, len(m)):
            self.assertEqual(parse_dbus_header(m[:l]), len(m))

    def test_body_size(self):
        m = b'l\1\0\1\4\0\0\0\1\0\0\0\0\0\0\0b234'
        self.assertEqual(parse_dbus_header(m), len(m))
        for l in range(16, len(m)):
            self.assertEqual(parse_dbus_header(m[:l]), len(m))

    def test_illegal_endian(self):
        m = b'L\1\0\1\0\0\0\0\1\0\0\0\0\0\0\0'
        self.assertRaises(ValueError, parse_dbus_header, m)
        m = b'b\1\0\1\0\0\0\0\1\0\0\0\0\0\0\0'
        self.assertRaises(ValueError, parse_dbus_header, m)

    def test_illegal_type(self):
        m = b'l\0\0\1\0\0\0\0\1\0\0\0\0\0\0\0'
        self.assertRaises(ValueError, parse_dbus_header, m)
        m = b'l\5\0\1\0\0\0\0\1\0\0\0\0\0\0\0'
        self.assertRaises(ValueError, parse_dbus_header, m)

    def test_illegal_serial(self):
        m = b'l\1\0\1\0\0\0\0\0\0\0\0\0\0\0\0'
        self.assertRaises(ValueError, parse_dbus_header, m)


class TestDbusProtocol(UnitTest):

    def setUp(self):
        super(TestDbusProtocol, self).setUp()
        self.messages = []
        self.protocols = []

    def store_messages(self, transport, protocol, message):
        self.messages.append(message)
        self.protocols.append(protocol)

    def store_and_echo_messages(self, transport, protocol, message):
        self.messages.append(message)
        self.protocols.append(protocol)
        response = txdbus.SignalMessage('/my/path', 'Signal', 'my.iface',
                        signature=message.signature, body=message.body)
        protocol.send_message(response)

    def test_auth_missing_creds_byte(self):
        # The first thing a client should send to the server is a '\0' byte. If
        # not, the server should close the connection.
        transport = MockTransport()
        protocol = DbusProtocol(True, None)
        transport.start(protocol)
        self.assertFalse(transport.closed)
        protocol.data_received(b'\1')
        self.assertIsInstance(protocol._error, DbusError)
        self.assertTrue(transport.closed)

    def test_auth_non_ascii(self):
        # After the '\0' byte, an authentiction phase happens. The
        # authentication protocol is line based and all lines should be ascii.
        transport = MockTransport()
        protocol = DbusProtocol(True, None)
        transport.start(protocol)
        self.assertFalse(transport.closed)
        protocol.data_received(b'\0\xff\r\n')
        self.assertIsInstance(protocol._error, DbusError)
        self.assertTrue(transport.closed)

    def test_auth_long_line(self):
        # An authentication line should not exceed the maximum line size.
        transport = MockTransport()
        protocol = DbusProtocol(True, None, 'foo')
        protocol.max_line_size = 5
        transport.start(protocol)
        self.assertFalse(transport.closed)
        protocol.data_received(b'\0AUTH ANONYMOUS\r\n')
        self.assertIsInstance(protocol._error, DbusError)
        self.assertTrue(transport.closed)

    def test_auth_ok(self):
        # Test anonymous authenication. Ensure that the server GUID is
        # correctly sent back.
        transport = MockTransport()
        protocol = DbusProtocol(True, None, 'foo')
        transport.start(protocol)
        protocol.data_received(b'\0AUTH ANONYMOUS\r\nBEGIN\r\n')
        buf = transport.buffer.getvalue()
        self.assertTrue(buf.startswith(b'OK foo'))
        auth = protocol._authenticator
        self.assertTrue(auth.authenticationSucceeded())
        self.assertTrue(auth.getGUID(), 'foo')
        self.assertFalse(transport.closed)

    def test_missing_hello(self):
        # After authentication, the first message should be a "Hello".
        # Otherwise, the server should close the connection.
        transport = MockTransport()
        protocol = DbusProtocol(True, self.store_messages, 'foo')
        transport.start(protocol)
        protocol.data_received(b'\0AUTH ANONYMOUS\r\nBEGIN\r\n')
        message = txdbus.MethodCallMessage('/my/path', 'Method')
        protocol.data_received(message.rawMessage)
        auth = protocol._authenticator
        self.assertTrue(auth.authenticationSucceeded())
        self.assertIsInstance(protocol._error, DbusError)
        self.assertTrue(transport.closed)

    def test_send_message(self):
        # After the "Hello" message, it should be possible to send other
        # messages.
        transport = MockTransport()
        protocol = DbusProtocol(True, self.store_messages, 'foo')
        transport.start(protocol)
        protocol.data_received(b'\0AUTH ANONYMOUS\r\nBEGIN\r\n')
        auth = protocol._authenticator
        self.assertTrue(auth.authenticationSucceeded())
        message = txdbus.MethodCallMessage('/org/freedesktop/DBus', 'Hello',
                        interface='org.freedesktop.DBus', destination='org.freedesktop.DBus')
        protocol.data_received(message.rawMessage)
        gruvi.sleep(0)
        self.assertIsNone(protocol._error)
        self.assertFalse(transport.closed)
        self.assertTrue(protocol._name_acquired)
        self.assertEqual(len(self.messages), 0)
        message = txdbus.MethodCallMessage('/my/path', 'Method')
        protocol.data_received(message.rawMessage)
        gruvi.sleep(0)
        self.assertIsNone(protocol._error)
        self.assertFalse(transport.closed)
        self.assertEqual(len(self.messages), 1)
        self.assertEqual(self.messages[0].path, '/my/path')
        self.assertEqual(self.messages[0].member, 'Method')
        self.assertEqual(self.protocols, [protocol])

    def test_send_message_incremental(self):
        # Send a message byte by byte. The protocol should be able process it.
        transport = MockTransport()
        protocol = DbusProtocol(True, self.store_messages, 'foo')
        transport.start(protocol)
        authexchange = b'\0AUTH ANONYMOUS\r\nBEGIN\r\n'
        for i in range(len(authexchange)):
            protocol.data_received(authexchange[i:i+1])
        auth = protocol._authenticator
        self.assertTrue(auth.authenticationSucceeded())
        message = txdbus.MethodCallMessage('/org/freedesktop/DBus', 'Hello',
                        interface='org.freedesktop.DBus', destination='org.freedesktop.DBus')
        for i in range(len(message.rawMessage)):
            protocol.data_received(message.rawMessage[i:i+1])
        gruvi.sleep(0)
        self.assertIsNone(protocol._error)
        self.assertFalse(transport.closed)
        self.assertEqual(len(self.messages), 0)
        message = txdbus.MethodCallMessage('/my/path', 'Method')
        for i in range(len(message.rawMessage)):
            protocol.data_received(message.rawMessage[i:i+1])
        gruvi.sleep(0)
        self.assertIsNone(protocol._error)
        self.assertFalse(transport.closed)
        self.assertEqual(len(self.messages), 1)
        self.assertEqual(self.messages[0].path, '/my/path')
        self.assertEqual(self.messages[0].member, 'Method')
        self.assertEqual(self.protocols, [protocol])

    def test_send_message_too_large(self):
        # Send a message that exceeds the maximum message size. The connection
        # should be closed.
        transport = MockTransport()
        protocol = DbusProtocol(True, self.store_messages, 'foo')
        transport.start(protocol)
        protocol.data_received(b'\0AUTH ANONYMOUS\r\nBEGIN\r\n')
        message = txdbus.MethodCallMessage('/org/freedesktop/DBus', 'Hello',
                        interface='org.freedesktop.DBus', destination='org.freedesktop.DBus')
        protocol.data_received(message.rawMessage)
        gruvi.sleep(0)
        self.assertTrue(protocol._name_acquired)
        # Send a signal with a size equal to the high-water mark. This should work.
        message = txdbus.SignalMessage('/my/path', 'Signal', 'my.iface',
                                       signature='s', body=['x'*100])
        msglen = len(message.rawMessage)
        self.assertGreater(msglen, 100)
        protocol.set_read_buffer_limits(msglen)
        protocol.data_received(message.rawMessage)
        gruvi.sleep(0)
        self.assertIsNone(protocol._error)
        self.assertFalse(transport.closed)
        self.assertEqual(len(self.messages), 1)
        # Now send a signal with a size larger than the high-water mark. This should fail.
        message = txdbus.SignalMessage('/my/path', 'Signal', 'my.iface',
                                       signature='s', body=['x'*100])
        msglen = len(message.rawMessage)
        protocol.set_read_buffer_limits(msglen-1)
        protocol.data_received(message.rawMessage)
        gruvi.sleep(0)
        self.assertIsInstance(protocol._error, DbusError)
        self.assertTrue(transport.closed)
        self.assertEqual(len(self.messages), 1)

    def test_read_write_flow_control(self):
        # Send a lot of messages filling up the protocol read buffer.
        transport = MockTransport()
        protocol = DbusProtocol(True, self.store_and_echo_messages)
        transport.start(protocol)
        protocol.data_received(b'\0AUTH ANONYMOUS\r\nBEGIN\r\n')
        auth = protocol._authenticator
        self.assertTrue(auth.authenticationSucceeded())
        message = txdbus.MethodCallMessage('/org/freedesktop/DBus', 'Hello',
                        interface='org.freedesktop.DBus', destination='org.freedesktop.DBus')
        protocol.data_received(message.rawMessage)
        gruvi.sleep(0)
        self.assertTrue(protocol._name_acquired)
        interrupted = 0
        message = txdbus.SignalMessage('/my/path', 'Signal', 'my.iface',
                                       signature='s', body=['x'*100])
        msglen = len(message.rawMessage)
        protocol.set_read_buffer_limits(10*msglen)
        transport.buffer.seek(0)
        transport.buffer.truncate()
        transport.set_write_buffer_limits(7*msglen)
        for i in range(100):
            # Fill up protocol read buffer
            message = txdbus.SignalMessage('/my/path', 'Signal', 'my.iface',
                                           signature='s', body=['x'*100])
            protocol.data_received(message.rawMessage)
            if protocol._reading:
                continue
            interrupted += 1
            self.assertGreater(protocol._queue.qsize(), 0)
            # Run the dispatcher to fill up the transport write buffer
            gruvi.sleep(0)
            # Now the write buffer is full and the read buffer still contains
            # some entries because it is larger.
            self.assertTrue(protocol._reading)
            self.assertGreater(protocol._queue.qsize(), 0)
            self.assertFalse(protocol._may_write)
            # Drain write buffer and resume writing
            transport.buffer.seek(0)
            transport.buffer.truncate()
            protocol.resume_writing()
        # Should be interrupted > 10 times. The write buffer is the limiting factor
        # not the read buffer.
        self.assertGreater(interrupted, 10)


def echo_app(transport, protocol, message):
    # Test application that echos D-Bus arguments
    if not isinstance(message, txdbus.MethodCallMessage):
        return
    if message.member == 'Echo':
        reply = txdbus.MethodReturnMessage(message.serial, signature=message.signature,
                                           body=message.body)
    elif message.member == 'Error':
        reply = txdbus.ErrorMessage('Echo.Error', message.serial, signature=message.signature,
                                    body=message.body)
    else:
        return
    protocol.send_message(reply)


class TestGruviDbus(UnitTest):

    def setUp(self):
        super(TestGruviDbus, self).setUp()
        TxdbusAuthenticator.cookie_dir = self.tempdir

    def test_auth_pipe(self):
        # Test that authentication works over a Pipe.
        server = DbusServer(echo_app)
        addr = 'unix:path=' + self.pipename()
        server.listen(addr)
        client = DbusClient()
        client.connect(addr)
        cproto = client.connection[1]
        cauth = cproto._authenticator
        sproto = list(server.connections)[0][1]
        sauth = sproto._authenticator
        self.assertTrue(cauth.authenticationSucceeded())
        self.assertTrue(sauth.authenticationSucceeded())
        self.assertIsInstance(cproto.server_guid, six.text_type)
        self.assertTrue(cproto.server_guid.isalnum())
        self.assertEqual(cproto.server_guid, cauth.getGUID())
        self.assertEqual(cproto.server_guid, sproto.server_guid)
        self.assertEqual(sproto.server_guid, sauth.getGUID())
        self.assertEqual(cauth.getMechanismName(), sauth.getMechanismName())
        if hasattr(socket, 'SO_PEERCRED'):
            self.assertEqual(cauth.getMechanismName(), 'EXTERNAL')
        else:
            self.assertEqual(cauth.getMechanismName(), 'DBUS_COOKIE_SHA1')
        client.close()
        server.close()

    def test_auth_tcp(self):
        # Test that authentication works over TCP
        server = DbusServer(echo_app)
        addr = 'tcp:host=127.0.0.1,port=0'
        server.listen(addr)
        client = DbusClient()
        client.connect(server.addresses[0])
        cproto = client.connection[1]
        cauth = cproto._authenticator
        sproto = list(server.connections)[0][1]
        sauth = sproto._authenticator
        self.assertTrue(cauth.authenticationSucceeded())
        self.assertTrue(sauth.authenticationSucceeded())
        self.assertIsInstance(cproto.server_guid, six.text_type)
        self.assertTrue(cproto.server_guid.isalnum())
        self.assertEqual(cproto.server_guid, cauth.getGUID())
        self.assertEqual(cproto.server_guid, sproto.server_guid)
        self.assertEqual(sproto.server_guid, sauth.getGUID())
        self.assertEqual(cauth.getMechanismName(), sauth.getMechanismName())
        self.assertEqual(sauth.getMechanismName(), 'DBUS_COOKIE_SHA1')
        client.close()
        server.close()

    def test_get_unique_name(self):
        # Ensure that get_unique_name() works client and server side
        server = DbusServer(echo_app)
        addr = 'unix:path=' + self.pipename()
        server.listen(addr)
        client = DbusClient()
        client.connect(addr)
        unique_name = client.get_unique_name()
        self.assertIsInstance(unique_name, six.text_type)
        self.assertTrue(unique_name.startswith(':'))
        sproto = list(server.connections)[0][1]
        self.assertEqual(unique_name, sproto.get_unique_name())
        server.close()
        client.close()

    def test_call_method(self):
        # Ensure that calling a method over a Unix socket works.
        server = DbusServer(echo_app)
        addr = 'unix:path=' + self.pipename()
        server.listen(addr)
        client = DbusClient()
        client.connect(addr)
        result = client.call_method('bus.name', '/path', 'my.iface', 'Echo')
        self.assertEqual(result, ())
        server.close()
        client.close()

    def test_call_method_tcp(self):
        # Ensure that calling a method over TCP works.
        server = DbusServer(echo_app)
        addr = 'tcp:host=127.0.0.1,port=0'
        server.listen(addr)
        client = DbusClient()
        client.connect(server.addresses[0])
        result = client.call_method('bus.name', '/path', 'my.iface', 'Echo')
        self.assertEqual(result, ())
        server.close()
        client.close()

    def test_call_method_str_args(self):
        # Ensure that calling a method with string arguments works.
        server = DbusServer(echo_app)
        addr = 'unix:path=' + self.pipename()
        server.listen(addr)
        client = DbusClient()
        client.connect(addr)
        result = client.call_method('bus.name', '/path', 'my.iface', 'Echo',
                                    signature='s', args=['foo'])
        self.assertEqual(result, ('foo',))
        result = client.call_method('bus.name', '/path', 'my.iface', 'Echo',
                                    signature='ss', args=['foo', 'bar'])
        self.assertEqual(result, ('foo', 'bar'))
        server.close()
        client.close()

    def test_call_method_int_args(self):
        # Ensure that calling a method with integer arguments works.
        server = DbusServer(echo_app)
        addr = 'unix:path=' + self.pipename()
        server.listen(addr)
        client = DbusClient()
        client.connect(addr)
        result = client.call_method('bus.name', '/path', 'my.iface', 'Echo',
                                    signature='i', args=[1])
        self.assertEqual(result, (1,))
        result = client.call_method('bus.name', '/path', 'my.iface', 'Echo',
                                    signature='ii', args=[1, 2])
        self.assertEqual(result, (1, 2))
        server.close()
        client.close()

    def test_call_method_error(self):
        # Ensure that a method can return an error and that in this case a
        # DbusMethodCallError is raised.
        server = DbusServer(echo_app)
        addr = 'unix:path=' + self.pipename()
        server.listen(addr)
        client = DbusClient()
        client.connect(addr)
        exc = self.assertRaises(DbusMethodCallError, client.call_method,
                               'bus.name', '/path', 'my.iface', 'Error')
        self.assertEqual(exc.error, 'Echo.Error')
        self.assertEqual(exc.args, ())
        server.close()
        client.close()

    def test_call_method_error_args(self):
        # Call a method that will return an error with arguments. The arguments
        # should be available from the exception.
        server = DbusServer(echo_app)
        addr = 'unix:path=' + self.pipename()
        server.listen(addr)
        client = DbusClient()
        client.connect(addr)
        exc = self.assertRaises(DbusMethodCallError, client.call_method,
                               'bus.name', '/path', 'my.iface', 'Error',
                               signature='ss', args=('foo', 'bar'))
        self.assertEqual(exc.error, 'Echo.Error')
        self.assertEqual(exc.args, ('foo', 'bar'))
        server.close()
        client.close()

    def test_send_garbage(self):
        # Send random garbage and ensure the connection gets dropped.
        server = DbusServer(echo_app)
        addr = 'unix:path=' + self.pipename()
        server.listen(addr)
        client = DbusClient()
        client.connect(addr)
        transport = client.connection[0]
        exc = None
        try:
            while True:
                chunk = os.urandom(100)
                transport.write(chunk)
                gruvi.sleep(0)
        except Exception as e:
            exc = e
        self.assertIsInstance(exc, TransportError)
        server.close()
        client.close()

    def test_connection_limit(self):
        # Establish more connections than the DBUS server is willing to accept.
        # The connections should be closed.
        server = DbusServer(echo_app)
        addr = 'unix:path=' + self.pipename()
        server.listen(addr)
        server.max_connections = 10
        clients = []
        exc = None
        try:
            for i in range(15):
                client = DbusClient()
                client.connect(addr)
                clients.append(client)
        except Exception as e:
            exc = e
        self.assertIsInstance(exc, TransportError)
        self.assertLessEqual(len(server.connections), server.max_connections)
        for client in clients:
            client.close()
        server.close()


class TestNativeDbus(UnitTest):

    def setUp(self):
        if not os.environ.get('DBUS_SESSION_BUS_ADDRESS'):
            raise SkipTest('D-BUS session bus not available')
        super(TestNativeDbus, self).setUp()

    def test_get_unique_name(self):
        # Ensure that get_unique_name() works
        client = DbusClient()
        client.connect('session')
        unique_name = client.get_unique_name()
        self.assertIsInstance(unique_name, six.text_type)
        self.assertTrue(unique_name.startswith(':'))
        client.close()

    def test_call_listnames(self):
        # Call the ListNames() bus method and ensure the results are a list of
        # strings.
        client = DbusClient()
        client.connect('session')
        result = client.call_method('org.freedesktop.DBus', '/org/freedesktop/DBus',
                                    'org.freedesktop.DBus', 'ListNames')
        self.assertIsInstance(result, tuple)
        self.assertEqual(len(result), 1)
        names = result[0]
        self.assertIsInstance(names, list)
        self.assertGreater(len(names), 0)
        for name in names:
            self.assertIsInstance(name, six.text_type)
        client.close()


if __name__ == '__main__':
    os.environ.setdefault('VERBOSE', '1')
    unittest.main()

########NEW FILE########
__FILENAME__ = test_fibers
#
# This file is part of gruvi. Gruvi is free software available under the
# terms of the MIT license. See the file "LICENSE" that was provided
# together with this source file for the licensing terms.
#
# Copyright (c) 2012-2014 the gruvi authors. See the file "AUTHORS" for a
# complete list.

from __future__ import absolute_import, print_function

import gruvi
from support import *


class TestFiber(UnitTest):

    def test_spawn(self):
        counter = [0]
        def worker():
            counter[0] += 1
        fibers = []
        for i in range(1000):
            fibers.append(gruvi.spawn(worker))
        for fiber in fibers:
            fiber.join()
        self.assertEqual(counter[0], 1000)

    def test_join(self):
        joined = []
        def spawn_fibers(i):
            if i == 0:
                return
            fiber = gruvi.spawn(spawn_fibers, i-1)
            fiber.join()
            joined.append(i-1)
        fiber = gruvi.spawn(spawn_fibers, 1000)
        fiber.join()
        self.assertEqual(joined, list(range(1000)))

    def test_pass_args(self):
        hub = gruvi.get_hub()
        result = []
        def target1(*args):
            result.append(args)
            gruvi.switch_back()(1, 2, foo='bar')
            result.extend(hub.switch())
        def target2(*args):
            result.append(args)
            gruvi.switch_back()(3, 4, baz='qux')
            result.extend(hub.switch())
        f1 = gruvi.spawn(target1, 'a', 'b')
        f2 = gruvi.spawn(target2, 'c', 'd')
        f1.join(); f2.join()
        self.assertEqual(result, [('a', 'b'), ('c', 'd'), (1, 2), {'foo': 'bar'},
                                  (3, 4), {'baz': 'qux'}])


if __name__ == '__main__':
    unittest.main()

########NEW FILE########
__FILENAME__ = test_futures
#
# This file is part of gruvi. Gruvi is free software available under the
# terms of the MIT license. See the file "LICENSE" that was provided
# together with this source file for the licensing terms.
#
# Copyright (c) 2012-2013 the gruvi authors. See the file "AUTHORS" for a
# complete list.

from __future__ import absolute_import, print_function

import random

import gruvi
from gruvi.futures import *
from support import *


class TestFuture(UnitTest):

    def test_result(self):
        fut = Future()
        fut.set_result(10)
        self.assertEqual(fut.result(), 10)
        self.assertIsNone(fut.exception())
        self.assertEqual(fut.result(), 10)

    def test_exception(self):
        fut = Future()
        fut.set_exception(ValueError())
        self.assertIsInstance(fut.exception(), ValueError)
        self.assertRaises(ValueError, fut.result)

    def test_wait_result(self):
        fut = Future()
        def set_result():
            gruvi.sleep(0.1)
            fut.set_result('foo')
        fib = gruvi.Fiber(set_result)
        fib.start()
        self.assertEqual(fut.result(), 'foo')


class PoolTest(object):

    def setUp(self):
        self.pool = self.Pool()

    def tearDown(self):
        self.pool.close()

    def test_simple(self):
        def func(val):
            return val
        fut = self.pool.submit(func, 'foo')
        self.assertIsInstance(fut, Future)
        self.assertEqual(fut.result(), 'foo')

    def test_submit_sleep(self):
        def func(val):
            gruvi.sleep(0.1)
            return val
        fut = self.pool.submit(func, 'foo')
        self.assertEqual(fut.result(), 'foo')

    def test_submit_many(self):
        def func(val):
            return val
        futures = []
        for i in range(self.count):
            futures.append(self.pool.submit(func, i))
        result = []
        for fut in futures:
            result.append(fut.result())
        result.sort()
        self.assertEqual(result, list(range(self.count)))

    def test_submit_many_sleep(self):
        def func(val):
            gruvi.sleep(0.01)
            return val
        futures = []
        for i in range(self.count):
            futures.append(self.pool.submit(func, i))
        result = []
        for fut in futures:
            result.append(fut.result())
        result.sort()
        self.assertEqual(result, list(range(self.count)))

    def test_submit_exception(self):
        def func():
            raise ValueError()
        fut = self.pool.submit(func)
        self.assertRaises(ValueError, fut.result)

    def test_map(self):
        def double(x):
            return x*2
        result = self.pool.map(double, range(self.count))
        self.assertEqual(list(result), list(range(0, 2*self.count, 2)))

    def test_map_order(self):
        # Make sure that map() respects the order of the input. The random
        # delay in double() will make the results ready out of order, but the
        # return value of map() should be in order nonetheless.
        def double(x):
            gruvi.sleep(random.random() * 0.01)
            return x*2
        result = self.pool.map(double, range(self.count))
        self.assertEqual(list(result), list(range(0, 2*self.count, 2)))

    def test_pool_close(self):
        def func(i):
            return i
        pool = self.Pool()
        futures = []
        for i in range(self.count):
            futures.append(pool.submit(func, i))
        result = [fut.result() for fut in futures]
        result.sort()
        self.assertEqual(result, list(range(self.count)))
        self.assertGreater(len(pool._workers), 0)
        pool.close()
        self.assertEqual(len(pool._workers), 0)
        self.assertRaises(RuntimeError, pool.submit, func, i)


class TestFiberPool(PoolTest, UnitTest):

    count = 500
    Pool = FiberPool


class TestThreadPool(PoolTest, UnitTest):

    count = 5
    Pool = ThreadPool


if __name__ == '__main__':
    unittest.main()

########NEW FILE########
__FILENAME__ = test_http
#
# This file is part of Gruvi. Gruvi is free software available under the
# terms of the MIT license. See the file "LICENSE" that was provided
# together with this source file for the licensing terms.
#
# Copyright (c) 2012-2014 the Gruvi authors. See the file "AUTHORS" for a
# complete list.

from __future__ import absolute_import, print_function

import six

import gruvi
from gruvi.http import *
from gruvi.http import HttpMessage, HttpProtocol, HttpRequest, HttpResponse
from gruvi.http import parse_url, parse_option_header
from gruvi.http_ffi import lib as _lib
from gruvi.stream import StreamReader
from gruvi.compat import memoryview

from support import *


class TestParseUrl(UnitTest):

    def test_basic(self):
        parsed = parse_url('http://foo.org/bar')
        self.assertEqual(parsed, ['http', 'foo.org', '', '/bar', '', '', ''])

    def test_bytes(self):
        parsed = parse_url(b'http://foo.org/bar')
        self.assertEqual(parsed, ['http', 'foo.org', '', '/bar', '', '', ''])

    def test_bytearray(self):
        parsed = parse_url(bytearray(b'http://foo.org/bar'))
        self.assertEqual(parsed, ['http', 'foo.org', '', '/bar', '', '', ''])

    def test_memoryview(self):
        parsed = parse_url(memoryview(b'http://foo.org/bar'))
        self.assertEqual(parsed, ['http', 'foo.org', '', '/bar', '', '', ''])

    def test_full_url(self):
        parsed = parse_url('http://foo.org:80/bar?query#fragment')
        self.assertEqual(parsed, ['http', 'foo.org', '80', '/bar', 'query', 'fragment', ''])


class TestSplitOptionHeader(UnitTest):

    def test_basic(self):
        parsed = parse_option_header('text/plain; charset=foo')
        self.assertIsInstance(parsed, tuple)
        self.assertEqual(len(parsed), 2)
        self.assertEqual(parsed[0], 'text/plain')
        self.assertEqual(parsed[1], {'charset': 'foo'})

    def test_plain(self):
        parsed = parse_option_header('text/plain')
        self.assertEqual(parsed, ('text/plain', {}))

    def test_iso8859_1(self):
        parsed = parse_option_header('text/plain; foo="bar\xfe"')
        self.assertEqual(parsed, ('text/plain', {'foo': 'bar\xfe'}))

    def test_whitespace(self):
        parsed = parse_option_header('text/plain;   charset=foo    ')
        self.assertEqual(parsed, ('text/plain', {'charset': 'foo'}))

    def test_quoted(self):
        parsed = parse_option_header('text/plain; charset="foo bar"')
        self.assertEqual(parsed, ('text/plain', {'charset': 'foo bar'}))

    def test_multiple(self):
        parsed = parse_option_header('text/plain; foo=bar baz=qux')
        self.assertEqual(parsed, ('text/plain', {'foo': 'bar', 'baz': 'qux'}))

    def test_empty(self):
        parsed = parse_option_header('text/plain; charset=""')
        self.assertEqual(parsed, ('text/plain', {'charset': ''}))


class TestHttpProtocol(UnitTest):

    def setUp(self):
        super(TestHttpProtocol, self).setUp()
        self.environs = []

    def store_request(self, environ, start_response):
        environ['test.message'] = start_response.__self__._message
        environ['test.body'] = environ['wsgi.input'].read()
        self.environs.append(environ.copy())
        start_response('200 OK', [])
        return b''

    def parse_request(self, *chunks):
        # Parse the HTTP request made up of *chunks.
        transport = MockTransport()
        protocol = HttpProtocol(True, self.store_request)
        transport.start(protocol)
        for chunk in chunks:
            protocol.data_received(chunk)
        self.assertIsNone(protocol._error)
        self.transport = transport
        self.protocol = protocol

    def get_request(self):
        # Get a parsed request.
        # The sleep here will run the dispatcher.
        gruvi.sleep(0)
        self.assertGreaterEqual(len(self.environs), 1)
        env = self.environs.pop(0)
        self.assertIsInstance(env, dict)
        message = env.get('test.message')
        self.assertIsInstance(message, HttpMessage)
        self.assertEqual(message.message_type, _lib.HTTP_REQUEST)
        body = env.get('test.body')
        self.assertIsInstance(body, six.binary_type)
        return env

    # Tests that parse a request

    def test_simple_request(self):
        r = b'GET / HTTP/1.1\r\nHost: example.com\r\n\r\n'
        self.parse_request(r)
        env = self.get_request()
        m = env['test.message']
        self.assertEqual(m.version, '1.1')
        self.assertIsNone(m.status_code)
        self.assertEqual(m.method, 'GET')
        self.assertEqual(m.url, '/')
        self.assertFalse(m.is_upgrade)
        self.assertTrue(m.should_keep_alive)
        self.assertEqual(m.parsed_url, ['', '', '', '/', '', '', ''])
        self.assertEqual(m.headers, [('Host', 'example.com')])
        self.assertEqual(m.trailers, [])
        self.assertIsInstance(m.body, StreamReader)
        self.assertTrue(m.body.eof)
        self.assertEqual(env['test.body'], b'')

    def test_request_with_body(self):
        r = b'GET / HTTP/1.1\r\nHost: example.com\r\n' \
            b'Content-Length: 3\r\n\r\nFoo'
        self.parse_request(r)
        env = self.get_request()
        m = env['test.message']
        self.assertEqual(m.url, '/')
        self.assertEqual(m.version, '1.1')
        self.assertEqual(m.headers, [('Host', 'example.com'), ('Content-Length', '3')])
        self.assertTrue(m.body.eof)
        self.assertEqual(env['test.body'], b'Foo')

    def test_request_with_body_incremental(self):
        r = b'GET / HTTP/1.1\r\nHost: example.com\r\n' \
            b'Content-Length: 3\r\n\r\nFoo'
        self.parse_request([r[i:i+1] for i in range(len(r))])
        env = self.get_request()
        m = env['test.message']
        self.assertEqual(m.url, '/')
        self.assertEqual(m.version, '1.1')
        self.assertEqual(m.headers, [('Host', 'example.com'), ('Content-Length', '3')])
        self.assertTrue(m.body.eof)
        self.assertEqual(env['test.body'], b'Foo')

    def test_request_with_chunked_body(self):
        r = b'GET / HTTP/1.1\r\nHost: example.com\r\n' \
            b'Transfer-Encoding: chunked\r\n\r\n' \
            b'3\r\nFoo\r\n0\r\n\r\n'
        self.parse_request(r)
        env = self.get_request()
        m = env['test.message']
        self.assertEqual(m.url, '/')
        self.assertEqual(m.version, '1.1')
        self.assertEqual(m.headers, [('Host', 'example.com'),
                                     ('Transfer-Encoding', 'chunked')])
        self.assertTrue(m.body.eof)
        self.assertEqual(env['test.body'], b'Foo')

    def test_request_with_chunked_body_incremental(self):
        r = b'GET / HTTP/1.1\r\nHost: example.com\r\n' \
            b'Transfer-Encoding: chunked\r\n\r\n' \
            b'3\r\nFoo\r\n0\r\n\r\n'
        self.parse_request([r[i:i+1] for i in range(len(r))])
        env = self.get_request()
        m = env['test.message']
        self.assertEqual(m.url, '/')
        self.assertEqual(m.version, '1.1')
        self.assertEqual(m.headers, [('Host', 'example.com'),
                                     ('Transfer-Encoding', 'chunked')])
        self.assertTrue(m.body.eof)
        self.assertEqual(env['test.body'], b'Foo')

    def test_request_with_chunked_body_and_trailers(self):
        r = b'GET / HTTP/1.1\r\nHost: example.com\r\n' \
            b'Transfer-Encoding: chunked\r\n\r\n' \
            b'3\r\nFoo\r\n0\r\nETag: foo\r\n\r\n'
        self.parse_request(r)
        env = self.get_request()
        m = env['test.message']
        self.assertEqual(m.url, '/')
        self.assertEqual(m.version, '1.1')
        self.assertEqual(m.headers, [('Host', 'example.com'),
                                     ('Transfer-Encoding', 'chunked')])
        self.assertEqual(m.trailers, [('ETag', 'foo')])
        self.assertTrue(m.body.eof)
        self.assertEqual(env['test.body'], b'Foo')

    def test_pipelined_requests(self):
        r = b'GET /0 HTTP/1.1\r\nHost: example0.com\r\n\r\n' \
            b'GET /1 HTTP/1.1\r\nHost: example1.com\r\n\r\n'
        self.parse_request(r)
        for i in range(2):
            env = self.get_request()
            m = env['test.message']
            self.assertEqual(m.url, '/{0}'.format(i))
            self.assertEqual(m.version, '1.1')
            self.assertEqual(m.headers, [('Host', 'example{0}.com'.format(i))])
            self.assertTrue(m.body.eof)
            self.assertEqual(env['test.body'], b'')

    def test_pipelined_requests_with_body(self):
        r = b'GET / HTTP/1.1\r\nHost: example.com\r\n' \
            b'Content-Length: 4\r\n\r\nFoo0' \
            b'GET / HTTP/1.1\r\nHost: example.com\r\n' \
            b'Content-Length: 4\r\n\r\nFoo1'
        self.parse_request(r)
        for i in range(2):
            env = self.get_request()
            m = env['test.message']
            self.assertEqual(m.url, '/')
            self.assertEqual(m.version, '1.1')
            self.assertEqual(m.headers, [('Host', 'example.com'), ('Content-Length', '4')])
            self.assertEqual(env['test.body'], 'Foo{0}'.format(i).encode('ascii'))

    def test_request_url(self):
        r = b'GET /foo/bar HTTP/1.1\r\n' \
            b'Host: example.com\r\n\r\n'
        self.parse_request(r)
        env = self.get_request()
        m = env['test.message']
        self.assertEqual(m.parsed_url, ['', '', '', '/foo/bar', '', '', ''])

    def test_long_request_url(self):
        r = b'GET http://user:pass@example.com:80/foo/bar?baz=qux#quux HTTP/1.1\r\n' \
            b'Host: example.com\r\n\r\n'
        self.parse_request(r)
        env = self.get_request()
        m = env['test.message']
        self.assertEqual(m.parsed_url, ['http', 'example.com', '80', '/foo/bar',
                                        'baz=qux', 'quux', 'user:pass'])

    # Tests that parse a response

    def parse_response(self, *chunks, **kwargs):
        # Parse the HTTP resposne made up of *chunks.
        transport = MockTransport()
        protocol = HttpProtocol(False)
        transport.start(protocol)
        methods = kwargs.get('methods', [])
        if methods:
            protocol._requests = methods
        for chunk in chunks:
            protocol.data_received(chunk)
        self.assertIsNone(protocol._error)
        self.transport = transport
        self.protocol = protocol

    def get_response(self):
        # Get a parsed resposne.
        # The sleep here will run the dispatcher.
        response = self.protocol.get_response()
        self.assertIsInstance(response, HttpResponse)
        message = response._message
        self.assertIsInstance(message, HttpMessage)
        self.assertEqual(message.message_type, _lib.HTTP_RESPONSE)
        return response

    def test_simple_response(self):
        r = b'HTTP/1.1 200 OK\r\nContent-Length: 0\r\n\r\n'
        self.parse_response(r)
        ro = self.get_response()
        self.assertEqual(ro.version, '1.1')
        self.assertEqual(ro.status, 200)
        self.assertEqual(ro.headers, [('Content-Length', '0')])
        self.assertEqual(ro.get_header('Content-Length'), '0')
        self.assertEqual(ro.trailers, [])
        self.assertEqual(ro.read(), b'')

    def test_response_with_body(self):
        r = b'HTTP/1.1 200 OK\r\nContent-Length: 3\r\n\r\nFoo'
        self.parse_response(r)
        ro = self.get_response()
        self.assertEqual(ro.version, '1.1')
        self.assertEqual(ro.status, 200)
        self.assertEqual(ro.headers, [('Content-Length', '3')])
        self.assertEqual(ro.get_header('Content-Length'), '3')
        self.assertEqual(ro.trailers, [])
        self.assertEqual(ro.read(), b'Foo')
        self.assertEqual(ro.read(), b'')

    def test_response_with_body_incremental(self):
        r = b'HTTP/1.1 200 OK\r\nContent-Length: 3\r\n\r\nFoo'
        self.parse_response([r[i:i+1] for i in range(len(r))])
        ro = self.get_response()
        self.assertEqual(ro.version, '1.1')
        self.assertEqual(ro.status, 200)
        self.assertEqual(ro.headers, [('Content-Length', '3')])
        self.assertEqual(ro.read(), b'Foo')
        self.assertEqual(ro.read(), b'')

    def test_response_with_chunked_body(self):
        r = b'HTTP/1.1 200 OK\r\nTransfer-Encoding: chunked\r\n\r\n' \
            b'3\r\nFoo\r\n0\r\n\r\n'
        self.parse_response(r)
        ro = self.get_response()
        self.assertEqual(ro.version, '1.1')
        self.assertEqual(ro.status, 200)
        self.assertEqual(ro.headers, [('Transfer-Encoding', 'chunked')])
        self.assertEqual(ro.read(), b'Foo')
        self.assertEqual(ro.read(), b'')

    def test_response_with_chunked_body_incremental(self):
        r = b'HTTP/1.1 200 OK\r\nTransfer-Encoding: chunked\r\n\r\n' \
            b'3\r\nFoo\r\n0\r\n\r\n'
        self.parse_response([r[i:i+1] for i in range(len(r))])
        ro = self.get_response()
        self.assertEqual(ro.version, '1.1')
        self.assertEqual(ro.status, 200)
        self.assertEqual(ro.headers, [('Transfer-Encoding', 'chunked')])
        self.assertEqual(ro.read(), b'Foo')
        self.assertEqual(ro.read(), b'')

    def test_response_with_chunked_body_and_trailers(self):
        r = b'HTTP/1.1 200 OK\r\nTransfer-Encoding: chunked\r\n\r\n' \
            b'3\r\nFoo\r\n0\r\nETag: foo\r\n\r\n'
        self.parse_response(r)
        ro = self.get_response()
        self.assertEqual(ro.version, '1.1')
        self.assertEqual(ro.status, 200)
        self.assertEqual(ro.headers, [('Transfer-Encoding', 'chunked')])
        self.assertEqual(ro.get_header('Transfer-Encoding'), 'chunked')
        self.assertEqual(ro.trailers, [('ETag', 'foo')])
        self.assertEqual(ro.get_trailer('ETag'), 'foo')
        self.assertEqual(ro.read(), b'Foo')
        self.assertEqual(ro.read(), b'')

    def test_pipelined_responses(self):
        r = b'HTTP/1.1 200 OK\r\nContent-Length: 0\r\nSet-Cookie: foo=0\r\n\r\n' \
            b'HTTP/1.1 200 OK\r\nContent-Length: 0\r\nSet-Cookie: foo=1\r\n\r\n'
        self.parse_response(r)
        for i in range(2):
            ro = self.get_response()
            self.assertEqual(ro.version, '1.1')
            self.assertEqual(ro.status, 200)
            cookie = 'foo={0}'.format(i)
            self.assertEqual(ro.headers, [('Content-Length', '0'), ('Set-Cookie', cookie)])
            self.assertEqual(ro.read(), b'')

    def test_pipelined_responses_with_body(self):
        r = b'HTTP/1.1 200 OK\r\nContent-Length: 4\r\n\r\nFoo0' \
            b'HTTP/1.1 200 OK\r\nContent-Length: 4\r\n\r\nFoo1'
        self.parse_response(r)
        for i in range(2):
            ro = self.get_response()
            self.assertEqual(ro.version, '1.1')
            self.assertEqual(ro.status, 200)
            self.assertEqual(ro.headers, [('Content-Length', '4')])
            self.assertEqual(ro.read(), 'Foo{0}'.format(i).encode('ascii'))
            self.assertEqual(ro.read(), b'')

    def test_pipelined_head_responses(self):
        r = b'HTTP/1.1 200 OK\r\nContent-Length: 3\r\n\r\n' \
            b'HTTP/1.1 200 OK\r\nContent-Length: 3\r\n\r\n'
        self.parse_response(r, methods=['HEAD', 'HEAD'])
        for i in range(2):
            ro = self.get_response()
            self.assertEqual(ro.version, '1.1')
            self.assertEqual(ro.status, 200)
            self.assertEqual(ro.headers, [('Content-Length', '3')])
            self.assertEqual(ro.read(), b'')

    def test_pipelined_empty_responses(self):
        r = b'HTTP/1.1 100 OK\r\nCookie: foo0\r\n\r\n' \
            b'HTTP/1.1 204 OK\r\nCookie: foo1\r\n\r\n' \
            b'HTTP/1.1 304 OK\r\nCookie: foo2\r\n\r\n'
        self.parse_response(r)
        for i in range(3):
            ro = self.get_response()
            self.assertEqual(ro.version, '1.1')
            self.assertEqual(ro.headers, [('Cookie', 'foo{0}'.format(i))])
            self.assertEqual(ro.read(), b'')

    def test_pipelined_200_response_eof(self):
        # No content-length so 200 requires and EOF to indicate the end of
        # message. The second request is therefore interpreted as a the body of
        # the first.
        r = b'HTTP/1.1 200 OK\r\nCookie: foo0\r\n\r\nfoo'
        self.parse_response(r)
        ro = self.get_response()
        self.assertEqual(ro.version, '1.1')
        self.assertEqual(ro.headers, [('Cookie', 'foo0')])
        self.assertEqual(ro.read(100), b'foo')
        self.assertFalse(ro._message.body.eof)
        self.protocol.connection_lost(None)
        self.assertTrue(ro._message.body.eof)
        self.assertEqual(ro.read(), b'')

    def test_pipelined_204_response_eof(self):
        # A 204 never has a body so the absence of a Content-Length header
        # still does not require it to see an EOF.
        r = b'HTTP/1.1 204 OK\r\nCookie: foo0\r\n\r\n'
        self.parse_response(r)
        ro = self.get_response()
        self.assertEqual(ro.version, '1.1')
        self.assertEqual(ro.headers, [('Cookie', 'foo0')])
        self.assertEqual(ro.read(), b'')


def hello_app(environ, start_response):
    headers = [('Content-Type', 'text/plain')]
    start_response('200 OK', headers)
    return ['Hello!']


def echo_app(environ, start_response):
    headers = [('Content-Type', 'text/plain')]
    body = environ['wsgi.input'].read()
    start_response('200 OK', headers)
    return [body]


class TestHttp(UnitTest):

    def test_simple(self):
        server = HttpServer(hello_app)
        server.listen(('localhost', 0))
        addr = server.addresses[0]
        client = HttpClient()
        client.connect(addr)
        client.request('GET', '/')
        response = client.get_response()
        self.assertEqual(response.version, '1.1')
        self.assertEqual(response.status, 200)
        ident = response.get_header('Server')
        self.assertTrue(ident.startswith('gruvi'))
        ctype = response.get_header('Content-Type')
        self.assertEqual(ctype, 'text/plain')
        self.assertEqual(response.read(), b'Hello!')

    def test_simple_pipe(self):
        server = HttpServer(hello_app)
        server.listen(self.pipename())
        addr = server.addresses[0]
        client = HttpClient()
        client.connect(addr)
        client.request('GET', '/')
        response = client.get_response()
        self.assertEqual(response.read(), b'Hello!')

    def test_simple_ssl(self):
        server = HttpServer(hello_app)
        context = self.get_ssl_context()
        server.listen(('localhost', 0), ssl=context)
        addr = server.addresses[0]
        client = HttpClient()
        client.connect(addr, ssl=context)
        client.request('GET', '/')
        response = client.get_response()
        self.assertEqual(response.read(), b'Hello!')

    def test_request_body_bytes(self):
        server = HttpServer(echo_app)
        server.listen(('localhost', 0))
        addr = server.addresses[0]
        client = HttpClient()
        client.connect(addr)
        client.request('POST', '/', body=b'foo')
        response = client.get_response()
        body = response.read()
        self.assertEqual(body, b'foo')

    def test_request_body_string(self):
        # When making a request with a string body, it should be encoded as
        # ISO-8859-1.
        server = HttpServer(echo_app)
        server.listen(('localhost', 0))
        addr = server.addresses[0]
        client = HttpClient()
        client.connect(addr)
        client.request('POST', '/', body='foo')
        response = client.get_response()
        body = response.read()
        self.assertEqual(body, b'foo')

    def test_request_body_sequence(self):
        server = HttpServer(echo_app)
        server.listen(('localhost', 0))
        addr = server.addresses[0]
        client = HttpClient()
        client.connect(addr)
        client.request('POST', '/', body=[b'foo', 'bar'])
        response = client.get_response()
        body = response.read()
        self.assertEqual(body, b'foobar')


if __name__ == '__main__':
    unittest.main()

########NEW FILE########
__FILENAME__ = test_hub
#
# This file is part of Gruvi. Gruvi is free software available under the
# terms of the MIT license. See the file "LICENSE" that was provided
# together with this source file for the licensing terms.
#
# Copyright (c) 2012-2014 the Gruvi authors. See the file "AUTHORS" for a
# complete list.

from __future__ import absolute_import, print_function

import os
import gc
import time
import signal
import inspect
import threading
import weakref

import gruvi
from support import *


class TestHub(UnitTest):

    def test_switchpoint(self):
        # Wrapping a function in @switchpoint should return function with
        # proper docs and a proper signature. Calling it should call the
        # underlying function.
        def func(foo, bar, baz=None, *args, **kwargs):
            """Foo bar."""
            return (foo, bar, baz, args, kwargs)
        wrapper = gruvi.switchpoint(func)
        self.assertEqual(wrapper.__name__, 'func')
        self.assertTrue(wrapper.__doc__.endswith('switchpoint.*\n'))
        argspec = inspect.getargspec(wrapper)
        self.assertEqual(argspec.args, ['foo', 'bar', 'baz'])
        self.assertEqual(argspec.varargs, 'args')
        self.assertEqual(argspec.keywords, 'kwargs')
        self.assertEqual(argspec.defaults, (None,))
        result = wrapper(1, 2, qux='foo')
        self.assertEqual(result, (1, 2, None, (), { 'qux': 'foo'}))
        result = wrapper(1, 2, 3, 4, qux='foo')
        self.assertEqual(result, (1, 2, 3, (4,), { 'qux': 'foo'}))

    def test_sigint(self):
        # The Hub should exit on CTRL-C (SIGINT).
        def send_sigint():
            time.sleep(0.01)
            os.kill(os.getpid(), signal.SIGINT)
        t1 = threading.Thread(target=send_sigint)
        t1.start()
        hub = gruvi.get_hub()
        self.assertRaises(KeyboardInterrupt, hub.switch)
        self.assertFalse(hub.is_alive())
        t1.join()

    def test_get_new_hub(self):
        # When the hub is closed, get_hub() should return a new one.
        hub = gruvi.get_hub()
        hub.close()
        hub.switch()
        hub2 = gruvi.get_hub()
        self.assertIsNot(hub, hub2)

    def test_close(self):
        # Calling hub.close() should cause the hub to exit.
        hub = gruvi.Hub()
        hub.run_callback(hub.close)
        self.assertIsNone(hub.switch())
        self.assertFalse(hub.is_alive())

    def test_close_from_thread(self):
        # Calling hub.close() from a thread should cause the hub to exit.
        def close_hub():
            time.sleep(0.01)
            hub.close()
        t1 = threading.Thread(target=close_hub)
        t1.start()
        hub = gruvi.Hub()
        self.assertIsNone(hub.switch())
        self.assertFalse(hub.is_alive())
        t1.join()

    def test_cleanup(self):
        # After we close() a Hub, it should be garbage collectable, including
        # its event loop.
        hub = gruvi.Hub()
        gruvi.sleep(0)
        ref1 = weakref.ref(hub)
        ref2 = weakref.ref(hub.loop)
        hub.close()
        hub.switch()
        del hub
        gc.collect()
        self.assertIsNone(ref1())
        self.assertIsNone(ref2())

    def test_thread_close(self):
        # If we close() a Hub in a thread, it should be garbage collectable.
        refs = []
        def thread_sleep():
            hub = gruvi.get_hub()
            gruvi.sleep(0)
            refs.append(weakref.ref(hub))
            refs.append(weakref.ref(hub.loop))
            hub.close()
            hub.switch()
        t1 = threading.Thread(target=thread_sleep)
        refs.append(weakref.ref(t1))
        t1.start(); t1.join(); del t1
        gc.collect()
        self.assertIsNone(refs[0]())
        self.assertIsNone(refs[1]())
        self.assertIsNone(refs[2]())

    def test_many_hubs(self):
        # Create and close a Hub in many threads. If the hub does not garbage
        # collect, then this will run out of file descriptors.
        for i in range(100):
            hub = gruvi.Hub()
            with gruvi.switch_back(timeout=0, hub=hub):
                self.assertRaises(gruvi.Timeout, hub.switch)
            hub.close()
            hub.switch()
            gc.collect()

    def test_callback_order(self):
        # Callbacks run with run_callback() should be run in the order they
        # were added.
        hub = gruvi.Hub()
        result = []
        for i in range(100):
            hub.run_callback(result.append, i)
        hub.close()
        hub.switch()
        self.assertEqual(len(result), 100)
        self.assertEqual(result, list(range(100)))

    def test_sleep(self):
        # Test that sleep() works
        hub = gruvi.get_hub()
        # use hub.now() as there's slight rounding errors with time.time()
        t0 = hub.loop.now()
        gruvi.sleep(0.01)
        t1 = hub.loop.now()
        self.assertGreaterEqual(t1-t0, 10)
        t0 = hub.loop.now()
        gruvi.sleep(0.1)
        t1 = hub.loop.now()
        self.assertGreaterEqual(t1-t0, 100)


class TestAssertNoSwitchpoints(UnitTest):

    def test_assert_no_switchpoints(self):
        # Calling a switchpoint while in an assert_no_switchpoints block should
        # raise an AssertionError.
        with gruvi.assert_no_switchpoints():
            self.assertRaises(AssertionError, gruvi.sleep, 0)


class TestSwitchBack(UnitTest):

    def test_call(self):
        # Calling a switch_back instance should cause hub.switch() to return
        # with an (args, kwargs) tuple.
        hub = gruvi.get_hub()
        with gruvi.switch_back() as switcher:
            hub.run_callback(lambda: switcher('foo', bar='baz'))
            self.assertEqual(hub.switch(), (('foo',), {'bar': 'baz'}))

    def test_timeout(self):
        # A timeout in a switch_back instance should cause hub.switch() to
        # raise a Timeout exception.
        hub = gruvi.get_hub()
        with gruvi.switch_back(0.01) as switcher:
            self.assertRaises(gruvi.Timeout, hub.switch)

    def test_throw(self):
        # An exception thrown with the throw() method of a switch_back instance
        # should cause hub.switch to raise that exception.
        hub = gruvi.get_hub()
        with gruvi.switch_back() as switcher:
            hub.run_callback(lambda: switcher.throw(ValueError('foo')))
            exc = self.assertRaises(ValueError, hub.switch)
            self.assertEqual(exc.args[0], 'foo')


if __name__ == '__main__':
    unittest.main()

########NEW FILE########
__FILENAME__ = test_jsonrpc
#
# This file is part of Gruvi. Gruvi is free software available under the
# terms of the MIT license. See the file "LICENSE" that was provided
# together with this source file for the licensing terms.
#
# Copyright (c) 2012-2014 the Gruvi authors. See the file "AUTHORS" for a
# complete list.

from __future__ import absolute_import, print_function

import os
import pyuv
import json

import gruvi
from gruvi import jsonrpc
from gruvi.jsonrpc import *
from gruvi.jsonrpc_ffi import ffi as _ffi, lib as _lib
from gruvi.transports import TransportError
from support import *


_keepalive = None

def set_buffer(ctx, buf):
    global _keepalive  # See note in JsonRpcProtocol
    _keepalive = ctx.buf = _ffi.new('char[]', buf)
    ctx.buflen = len(buf)
    ctx.offset = 0

def split_string(s):
    ctx = _ffi.new('struct split_context *')
    set_buffer(ctx, s)
    _lib.json_split(ctx)
    return ctx


class TestJsonRpcFfi(UnitTest):

    def test_simple(self):
        r = b'{ "foo": "bar" }'
        ctx = split_string(r)
        self.assertEqual(ctx.error, 0)
        self.assertEqual(ctx.offset, len(r))

    def test_leading_whitespace(self):
        r = b' { "foo": "bar" }'
        ctx = split_string(r)
        self.assertEqual(ctx.error, 0)
        self.assertEqual(ctx.offset, len(r))
        r = b' \t\n{ "foo": "bar" }'
        ctx = split_string(r)
        self.assertEqual(ctx.error, 0)
        self.assertEqual(ctx.offset, len(r))

    def test_trailing_whitespace(self):
        r = b'{ "foo": "bar" } '
        ctx = split_string(r)
        self.assertEqual(ctx.error, 0)
        self.assertEqual(ctx.offset, len(r)-1)
        error = _lib.json_split(ctx)
        self.assertEqual(error, ctx.error) == _lib.INCOMPLETE
        self.assertEqual(ctx.offset, len(r))

    def test_brace_in_string(self):
        r = b'{ "foo": "b{r" }'
        ctx = split_string(r)
        self.assertEqual(ctx.error, 0)
        self.assertEqual(ctx.offset, len(r))
        r = b'{ "foo": "b}r" }'
        ctx = split_string(r)
        self.assertEqual(ctx.error, 0)
        self.assertEqual(ctx.offset, len(r))

    def test_string_escape(self):
        r = b'{ "foo": "b\\"}" }'
        ctx = split_string(r)
        self.assertEqual(ctx.error, 0)
        self.assertEqual(ctx.offset, len(r))

    def test_error(self):
        r = b' x { "foo": "bar" }'
        ctx = split_string(r)
        self.assertEqual(ctx.error, _lib.ERROR)
        self.assertEqual(ctx.offset, 1)
        r = b'[ { "foo": "bar" } ]'
        ctx = split_string(r)
        self.assertEqual(ctx.error, _lib.ERROR)
        self.assertEqual(ctx.offset, 0)

    def test_multiple(self):
        r = b'{ "foo": "bar" } { "baz": "qux" }'
        ctx = split_string(r)
        self.assertEqual(ctx.error, 0)
        self.assertEqual(ctx.offset, 16)
        error = _lib.json_split(ctx)
        self.assertEqual(error, ctx.error) == 0
        self.assertEqual(ctx.offset, len(r))

    def test_incremental(self):
        r = b'{ "foo": "bar" }'
        state = 0
        ctx = _ffi.new('struct split_context *')
        for i in range(len(r)-1):
            set_buffer(ctx, r[i:i+1])
            error = _lib.json_split(ctx)
            self.assertEqual(error, ctx.error) == _lib.INCOMPLETE
            self.assertEqual(ctx.offset, 1)
        buf = ctx.buf = _ffi.new('char[]', r[-1:])
        ctx.buflen = 1; ctx.offset = 0
        error = _lib.json_split(ctx)
        self.assertEqual(error, ctx.error) == 0
        self.assertEqual(ctx.offset, 1)


class TestJsonRpcProtocol(UnitTest):

    def setUp(self):
        super(TestJsonRpcProtocol, self).setUp()
        self.transport = MockTransport()
        self.protocol = JsonRpcProtocol(self.message_handler)
        self.transport.start(self.protocol)
        self.messages = []
        self.protocols = []

    def message_handler(self, transport, protocol, message):
        self.messages.append(message)
        self.protocols.append(protocol)

    def get_messages(self):
        # run dispatcher thread so that it calls our message handler
        gruvi.sleep(0)
        return self.messages

    def test_simple(self):
        m = b'{ "id": "1", "method": "foo" }'
        proto = self.protocol
        proto.data_received(m)
        mm = self.get_messages()
        self.assertEqual(len(mm), 1)
        self.assertIsInstance(mm[0], dict)
        self.assertEqual(mm[0], { 'id': '1', 'method': 'foo' })
        pp = self.protocols
        self.assertEqual(len(pp), 1)
        self.assertIs(pp[0], proto)

    def test_multiple(self):
        m = b'{ "id": "1", "method": "foo" }' \
            b'{ "id": "2", "method": "bar" }'
        proto = self.protocol
        proto.data_received(m)
        mm = self.get_messages()
        self.assertEqual(len(mm), 2)
        self.assertEqual(mm[0], { 'id': '1', 'method': 'foo' })
        self.assertEqual(mm[1], { 'id': '2', 'method': 'bar' })
        pp = self.protocols
        self.assertEqual(len(pp), 2)
        self.assertIs(pp[0], proto)
        self.assertIs(pp[1], proto)

    def test_whitespace(self):
        m = b'  { "id": "1", "method": "foo" }' \
            b'  { "id": "2", "method": "bar" }'
        proto = self.protocol
        proto.data_received(m)
        mm = self.get_messages()
        self.assertEqual(len(mm), 2)
        self.assertEqual(mm[0], { 'id': '1', 'method': 'foo' })
        self.assertEqual(mm[1], { 'id': '2', 'method': 'bar' })

    def test_incremental(self):
        m = b'{ "id": "1", "method": "foo" }'
        proto = self.protocol
        for i in range(len(m)-1):
            proto.data_received(m[i:i+1])
            self.assertEqual(self.get_messages(), [])
        proto.data_received(m[-1:])
        mm = self.get_messages()
        self.assertEqual(len(mm), 1)
        self.assertEqual(mm[0], { 'id': '1', 'method': 'foo' })

    def test_framing_error(self):
        m = b'xxx'
        proto = self.protocol
        proto.data_received(m)
        self.assertEqual(self.get_messages(), [])
        self.assertIsInstance(proto._error, JsonRpcError)

    def test_encoding_error(self):
        m = b'{ xxx\xff }'
        proto = self.protocol
        proto.data_received(m)
        self.assertEqual(self.get_messages(), [])
        self.assertIsInstance(proto._error, JsonRpcError)

    def test_illegal_json(self):
        m = b'{ "xxxx" }'
        proto = self.protocol
        proto.data_received(m)
        self.assertEqual(self.get_messages(), [])
        self.assertIsInstance(proto._error, JsonRpcError)

    def test_illegal_jsonrpc(self):
        m = b'{ "xxxx": "yyyy" }'
        proto = self.protocol
        proto.data_received(m)
        self.assertEqual(self.get_messages(), [])
        self.assertIsInstance(proto._error, JsonRpcError)
 
    def test_maximum_message_size_exceeded(self):
        proto = self.protocol
        proto.set_read_buffer_limits(100)
        message = {'id': 1, 'method': 'foo', 'params': ['x'*100]}
        self.assertEqual(jsonrpc.check_message(message), '1.0')
        message = json.dumps(message).encode('utf8')
        self.assertGreater(len(message), proto._read_buffer_high)
        proto.data_received(message)
        self.assertEqual(self.get_messages(), [])
        self.assertIsInstance(proto._error, JsonRpcError)

    def test_flow_control(self):
        # Write more bytes than the protocol buffers. Flow control should kick
        # in and alternate scheduling of the producer and the consumer.
        proto = self.protocol
        proto.read_buffer_size = 100
        message = b'{ "id": 1, "method": "foo"}'
        for i in range(1000):
            proto.data_received(message)
            if not proto._reading:
                gruvi.sleep(0)  # run dispatcher
            self.assertTrue(proto._reading)
        mm = self.get_messages()
        self.assertEqual(len(mm), 1000)
        message = json.loads(message.decode('utf8'))
        for m in mm:
            self.assertEqual(m, message)


def echo_app(transport, protocol, message):
    if message.get('method') != 'echo':
        message = jsonrpc.create_error(message, jsonrpc.METHOD_NOT_FOUND)
    else:
        message = jsonrpc.create_response(message, message['params'])
    protocol.send_message(message)

def reflect_app(transport, protocol, message):
    if message.get('method') != 'echo':
        return
    value = protocol.call_method('echo', *message['params'])
    message = jsonrpc.create_response(message, value)
    protocol.send_message(message)

def notification_app():
    notifications = []
    def application(transport, protocol, message):
        if message.get('id') is None:
            notifications.append((message['method'], message['params']))
        elif message['method'] == 'get_notifications':
            message = jsonrpc.create_response(message, notifications)
            protocol.send_message(message)
    return application


class TestJsonRpc(UnitTest):

    def test_errno(self):
        code = jsonrpc.SERVER_ERROR
        self.assertIsInstance(code, int)
        name = jsonrpc.errorcode[code]
        self.assertIsInstance(name, str)
        self.assertEqual(getattr(jsonrpc, name), code)
        desc = jsonrpc.strerror(code)
        self.assertIsInstance(desc, str)

    def test_call_method_tcp(self):
        server = JsonRpcServer(echo_app)
        server.listen(('localhost', 0))
        addr = server.addresses[0]
        client = JsonRpcClient()
        client.connect(addr)
        result = client.call_method('echo', 'foo')
        self.assertEqual(result, ['foo'])

    def test_call_method_pipe(self):
        server = JsonRpcServer(echo_app)
        server.listen(self.pipename(abstract=True))
        addr = server.addresses[0]
        client = JsonRpcClient()
        client.connect(addr)
        result = client.call_method('echo', 'foo')
        self.assertEqual(result, ['foo'])

    def test_call_method_ssl(self):
        server = JsonRpcServer(echo_app)
        context = self.get_ssl_context()
        server.listen(('localhost', 0), ssl=context)
        addr = server.addresses[0]
        client = JsonRpcClient()
        client.connect(addr, ssl=context)
        result = client.call_method('echo', 'foo')
        self.assertEqual(result, ['foo'])

    def test_call_method_no_args(self):
        server = JsonRpcServer(echo_app)
        server.listen(('127.0.0.1', 0))
        addr = server.addresses[0]
        client = JsonRpcClient()
        client.connect(addr)
        result = client.call_method('echo')
        self.assertEqual(result, [])

    def test_call_method_multiple_args(self):
        server = JsonRpcServer(echo_app)
        server.listen(('127.0.0.1', 0))
        addr = server.addresses[0]
        client = JsonRpcClient()
        client.connect(addr)
        result = client.call_method('echo', 'foo', 'bar')
        self.assertEqual(result, ['foo', 'bar'])
    
    def test_call_method_error(self):
        server = JsonRpcServer(echo_app)
        server.listen(('127.0.0.1', 0))
        addr = server.addresses[0]
        client = JsonRpcClient()
        client.connect(addr)
        exc = self.assertRaises(JsonRpcError, client.call_method, 'echo2')
        self.assertIsInstance(exc, JsonRpcMethodCallError)
        self.assertIsInstance(exc.error, dict)
        self.assertEqual(exc.error['code'], jsonrpc.METHOD_NOT_FOUND)
 
    def test_send_notification(self):
        server = JsonRpcServer(notification_app())
        server.listen(('127.0.0.1', 0))
        addr = server.addresses[0]
        client = JsonRpcClient()
        client.connect(addr)
        client.send_notification('notify_foo', 'foo')
        notifications = client.call_method('get_notifications')
        self.assertEqual(notifications, [['notify_foo', ['foo']]])
 
    def test_call_method_ping_pong(self):
        server = JsonRpcServer(reflect_app)
        server.listen(('127.0.0.1', 0))
        addr = server.addresses[0]
        client = JsonRpcClient(echo_app)
        client.connect(addr)
        result = client.call_method('echo', 'foo')
        self.assertEqual(result, ['foo'])

    def test_send_evil(self):
        server = JsonRpcServer(echo_app)
        server.listen(('127.0.0.1', 0))
        addr = server.addresses[0]
        client = JsonRpcClient()
        client.connect(addr)
        transport = client.connection[0]
        exc = None
        try:
            chunk = b'{' * 1024
            while True:
                transport.write(chunk)
                gruvi.sleep(0)
        except Exception as e:
            exc = e
        self.assertIsInstance(exc, TransportError)

    def test_send_whitespace(self):
        server = JsonRpcServer(echo_app)
        server.listen(('127.0.0.1', 0))
        addr = server.addresses[0]
        client = JsonRpcClient()
        client.connect(addr)
        transport = client.connection[0]
        exc = None
        try:
            chunk = b' ' * 1024
            while True:
                transport.write(chunk)
                gruvi.sleep(0)
        except Exception as e:
            exc = e
        self.assertIsInstance(exc, TransportError)

    def test_send_random(self):
        server = JsonRpcServer(echo_app)
        server.listen(('127.0.0.1', 0))
        addr = server.addresses[0]
        client = JsonRpcClient()
        client.connect(addr)
        transport = client.connection[0]
        exc = None
        try:
            while True:
                chunk = os.urandom(1024)
                transport.write(chunk)
                gruvi.sleep(0)
        except Exception as e:
            exc = e
        self.assertIsInstance(exc, TransportError)

    def test_connection_limit(self):
        server = JsonRpcServer(echo_app)
        server.listen(('127.0.0.1', 0))
        addr = server.addresses[0]
        server.max_connections = 10
        clients = []
        exc = None
        try:
            for i in range(15):
                client = JsonRpcClient(timeout=2)
                client.connect(addr)
                client.call_method('echo')
                clients.append(client)
        except Exception as e:
            exc = e
        self.assertIsInstance(exc, TransportError)
        self.assertLessEqual(len(server.connections), server.max_connections)
        for client in clients:
            client.close()
        server.close()


if __name__ == '__main__':
    unittest.main()

########NEW FILE########
__FILENAME__ = test_local
#
# This file is part of gruvi. Gruvi is free software available under the
# terms of the MIT license. See the file "LICENSE" that was provided
# together with this source file for the licensing terms.
#
# Copyright (c) 2012-2014 the gruvi authors. See the file "AUTHORS" for a
# complete list.

from __future__ import absolute_import, print_function

import gc
import gruvi
from support import *


class TestLocal(UnitTest):

    def test_isolation(self):
        local = gruvi.local()
        interleaved = []
        def fiber1():
            local.foo = 10
            interleaved.append(1)
            gruvi.sleep(0)
            self.assertEqual(local.foo, 10)
            local.foo = 30
            interleaved.append(1)
            gruvi.sleep(0)
            self.assertEqual(local.foo, 30)
        def fiber2():
            self.assertFalse(hasattr(local, 'foo'))
            local.foo = 20
            interleaved.append(2)
            gruvi.sleep(0)
            self.assertEqual(local.foo, 20)
            local.foo = 40
            interleaved.append(2)
            gruvi.sleep(0)
            self.assertEqual(local.foo, 40)
        f1 = gruvi.spawn(fiber1)
        f2 = gruvi.spawn(fiber2)
        f1.join(); f2.join()
        self.assertFalse(hasattr(local, 'foo'))
        self.assertEqual(interleaved, [1, 2, 1, 2])

    def test_cleanup_on_fiber_exit(self):
        hub = gruvi.get_hub()
        local = gruvi.local()
        def fiber1():
            local.foo = 10
        f1 = gruvi.spawn(fiber1)
        f1.join()
        # Access the local object as if access was from f1
        self.assertIn('foo', local._keys[f1])
        self.assertEqual(local._keys[f1]['foo'], 10)
        del f1; gc.collect()
        self.assertEqual(len(local._keys), 0)


if __name__ == '__main__':
    unittest.main()

########NEW FILE########
__FILENAME__ = test_ssl
#
# This file is part of Gruvi. Gruvi is free software available under the
# terms of the MIT license. See the file "LICENSE" that was provided
# together with this source file for the licensing terms.
#
# Copyright (c) 2012-2013 the Gruvi authors. See the file "AUTHORS" for a
# complete list.

from __future__ import print_function, absolute_import

import os
import sys
import time
import ssl
import socket
import pyuv

import gruvi
from gruvi.ssl import SslPipe, SslTransport
from support import *
from test_transports import EventLoopTest, TransportTest

if hasattr(ssl, 'SSLContext'):
    from ssl import SSLContext
else:
    from gruvi.sslcompat import SSLContext


def communicate(buf, client, server, clientssl, serverssl):
    """Send *buf* from *client* to *server* over SSL.
    
    The *clientssl* and *serverssl* arguments are potentially empty list of
    initial SSL data. The clientssl list is SSL data from the client to send to
    the server, the serverssl list is SSL data to send from the server to the
    client.
    
    The data that is received on the server is returned.
    """
    received = []
    offset = bytes_received = 0
    while True:
        ssldata, appdata = server.feed_ssldata(b''.join(clientssl))
        serverssl += ssldata
        received += appdata
        for chunk in appdata:
            if not chunk:
                break  # close_notify
            bytes_received += len(chunk)
        clientssl = []
        ssldata, appdata = client.feed_ssldata(b''.join(serverssl))
        clientssl += ssldata
        for chunk in appdata:
            assert len(chunk) == 0
        serverssl = []
        ssldata, offset = client.feed_appdata(buf, offset)
        clientssl += ssldata
        if not clientssl and not serverssl:
            break
    received = b''.join(received)
    return received


class TestSslPipe(UnitTest):
    """Test suite for the SslPipe class."""

    def setUp(self):
        if not os.access(self.certname, os.R_OK):
            raise SkipTest('no certificate available')
        super(TestSslPipe, self).setUp()
        context = SSLContext(ssl.PROTOCOL_SSLv23)
        context.load_cert_chain(self.certname, self.certname)
        self.client = SslPipe(context, False)
        self.server = SslPipe(context, True)

    def test_wrapped(self):
        # Send a simple chunk of data over SSL from client to server.
        buf = b'x' * 1000
        client, server = self.client, self.server
        # The client starts the handshake.
        clientssl = client.do_handshake()
        self.assertEqual(len(clientssl), 1)
        self.assertGreater(len(clientssl[0]), 0)
        # The server waits.
        serverssl = server.do_handshake()
        self.assertEqual(len(serverssl), 0)
        received = communicate(buf, client, server, clientssl, serverssl)
        self.assertEqual(received, buf)
        # This is an unclean shutdown.
        client.close()
        server.close()

    def test_echo(self):
        # Send a chunk from client to server and echo it back.
        buf = b'x' * 1000
        client, server = self.client, self.server
        clientssl = client.do_handshake()
        serverssl = server.do_handshake()
        received = communicate(buf, client, server, clientssl, serverssl)
        self.assertEqual(received, buf)
        received = communicate(buf, server, client, [], [])
        self.assertEqual(received, buf)
        client.close()
        server.close()

    def test_shutdown(self):
        # Test a clean shutdown of the SSL protocol.
        client, server = self.client, self.server
        buf = b'x' * 1000
        clientssl = client.do_handshake()
        serverssl = server.do_handshake()
        received = communicate(buf, client, server, clientssl, serverssl)
        self.assertEqual(received, buf)
        # The client initiates a shutdown.
        clientssl = client.shutdown()
        self.assertEqual(len(clientssl), 1)
        self.assertGreater(len(clientssl[0]), 0)  # the c->s close_notify alert
        # Communicate the close_notify to the server.
        serverssl, appdata = server.feed_ssldata(clientssl[0])
        # b'' means close notify: acknowledge it
        self.assertEqual(serverssl, [])
        self.assertEqual(appdata, [b''])
        serverssl = server.shutdown()
        # Now we should have a close_notify
        self.assertEqual(len(serverssl), 1)
        self.assertGreater(len(serverssl[0]), 0)  # the s->c close_notify
        self.assertEqual(appdata, [b''])
        self.assertIsNone(server.sslinfo)
        # Send back the server response to the client.
        clientssl, appdata = client.feed_ssldata(serverssl[0])
        self.assertEqual(clientssl, [])
        self.assertEqual(appdata, [])
        self.assertIsNone(client.sslinfo)
        client.close()
        server.close()

    def test_unwrapped(self):
        # Send data over an unencrypted channel.
        client, server = self.client, self.server
        buf = b'x' * 1000
        received = communicate(buf, client, server, [], [])
        self.assertEqual(received, buf)
        client.close()
        server.close()

    def test_unwrapped_after_wrapped(self):
        # Send data over SSL, then unwrap, and send data in the clear.
        client, server = self.client, self.server
        buf = b'x' * 1000
        # Send some data in the clear.
        received = communicate(buf, client, server, [], [])
        self.assertEqual(received, buf)
        # Now start the handshake and send some encrypted data.
        clientssl = client.do_handshake()
        server.do_handshake()
        received = communicate(buf, client, server, clientssl, [])
        self.assertEqual(received, buf)
        # Move back to clear again.
        clientssl = client.shutdown()
        received = communicate(buf, client, server, clientssl, [])
        self.assertEqual(received, b'')
        serverssl = server.shutdown()
        received = communicate(buf, client, server, [], serverssl)
        self.assertEqual(received, buf)
        # And back to encrypted again..
        clientssl = client.do_handshake()
        server.do_handshake()
        received = communicate(buf, client, server, clientssl, [])
        self.assertEqual(received, buf)
        client.close()
        server.close()

    def test_simultaneous_shutdown(self):
        # Test a simultaenous shutdown.
        client, server = self.client, self.server
        buf = b'x' * 1000
        # Start an encrypted session.
        clientssl = client.do_handshake()
        server.do_handshake()
        received = communicate(buf, client, server, clientssl, [])
        self.assertEqual(received, buf)
        # Tear it down concurrently.
        clientssl = client.shutdown()
        serverssl = server.shutdown()
        received = communicate(buf, client, server, clientssl, serverssl)
        self.assertIsNone(client.sslinfo)
        self.assertIsNone(server.sslinfo)
        self.assertEqual(received, buf)  # this was sent in the clear
        client.close()
        server.close()


class SslTransportTest(TransportTest):

    def setUp(self):
        if not os.access(self.certname, os.R_OK):
            raise SkipTest('no certificate available')
        super(SslTransportTest, self).setUp()
        self.context = SSLContext(ssl.PROTOCOL_SSLv3)
        self.context.load_cert_chain(self.certname, self.certname)

    def create_transport(self, handle, protocol, server_side):
        transport = SslTransport(handle, self.context, server_side)
        transport.start(protocol)
        return transport


class TestSslTcpTransport(SslTransportTest, EventLoopTest):

    def create_handle(self):
        return pyuv.TCP(self.loop)

    def bind_handle(self, handle):
        host = socket.gethostbyname('localhost')
        handle.bind((host, 0))
        return handle.getsockname()


class TestSslPipeTransport(SslTransportTest, EventLoopTest):

    def create_handle(self):
        return pyuv.Pipe(self.loop)

    def bind_handle(self, handle):
        addr = self.pipename('test-pipe')
        handle.bind(addr)
        return addr


if __name__ == '__main__':
    unittest.main()

########NEW FILE########
__FILENAME__ = test_stream
#
# This file is part of Gruvi. Gruvi is free software available under the
# terms of the MIT license. See the file "LICENSE" that was provided
# together with this source file for the licensing terms.
#
# Copyright (c) 2012-2014 the Gruvi authors. See the file "AUTHORS" for a
# complete list.

from __future__ import absolute_import, print_function

import os
import six
import hashlib

import gruvi
from gruvi.stream import *
from gruvi.transports import TransportError
from support import *


class TestStreamReader(UnitTest):

    def test_read(self):
        reader = StreamReader()
        reader.feed(b'foo')
        self.assertEqual(reader.read(100), b'foo')
        reader.feed(b'foo bar')
        self.assertEqual(reader.read(3), b'foo')
        self.assertEqual(reader.read(10), b' bar')

    def test_read_incr(self):
        reader = StreamReader()
        buf = b'foobar'
        for i in range(len(buf)):
            reader.feed(buf[i:i+1])
        reader.feed_eof()
        self.assertEqual(reader.read(), b'foobar')

    def test_read_eof(self):
        reader = StreamReader()
        reader.feed(b'foo')
        reader.feed_eof()
        self.assertEqual(reader.read(), b'foo')
        self.assertEqual(reader.read(), b'')
        reader.feed_error(RuntimeError)

    def test_read_wait_eof(self):
        reader = StreamReader()
        reader.feed(b'foo')
        def write_more():
            gruvi.sleep(0.01)
            reader.feed(b'bar')
            gruvi.sleep(0.01)
            reader.feed_eof()
        gruvi.spawn(write_more)
        self.assertEqual(reader.read(), b'foobar')
        self.assertEqual(reader.read(), b'')

    def test_read_error(self):
        reader = StreamReader()
        reader.feed(b'foo')
        reader.feed_error(RuntimeError)
        self.assertEqual(reader.read(), b'foo')
        self.assertRaises(RuntimeError, reader.read)

    def test_read_wait_error(self):
        reader = StreamReader()
        reader.feed(b'foo')
        def write_more():
            gruvi.sleep(0.01)
            reader.feed(b'bar')
            gruvi.sleep(0.01)
            reader.feed_error(RuntimeError)
        gruvi.spawn(write_more)
        self.assertEqual(reader.read(), b'foobar')
        self.assertRaises(RuntimeError, reader.read)

    def test_readline(self):
        reader = StreamReader()
        reader.feed(b'foo\n')
        self.assertEqual(reader.readline(), b'foo\n')
        reader.feed(b'bar\nbaz\n')
        self.assertEqual(reader.readline(), b'bar\n')
        self.assertEqual(reader.readline(), b'baz\n')

    def test_readline_incr(self):
        reader = StreamReader()
        buf = b'foo\nbar\n'
        for i in range(len(buf)):
            reader.feed(buf[i:i+1])
        self.assertEqual(reader.readline(), b'foo\n')
        self.assertEqual(reader.readline(), b'bar\n')

    def test_readline_limit(self):
        reader = StreamReader()
        reader.feed(b'foobar\n')
        self.assertEqual(reader.readline(3), b'foo')
        self.assertEqual(reader.readline(), b'bar\n')

    def test_readline_eof(self):
        reader = StreamReader()
        reader.feed(b'foo')
        reader.feed_eof()
        self.assertEqual(reader.readline(), b'foo')
        self.assertEqual(reader.readline(), b'')

    def test_readline_wait_eof(self):
        reader = StreamReader()
        reader.feed(b'foo')
        def write_more():
            gruvi.sleep(0.01)
            reader.feed(b'bar')
            gruvi.sleep(0.01)
            reader.feed_eof()
        gruvi.spawn(write_more)
        self.assertEqual(reader.readline(), b'foobar')
        self.assertEqual(reader.readline(), b'')

    def test_readline_error(self):
        reader = StreamReader()
        reader.feed(b'foo')
        reader.feed_error(RuntimeError)
        self.assertEqual(reader.readline(), b'foo')
        self.assertRaises(RuntimeError, reader.readline)

    def test_readline_wait_error(self):
        reader = StreamReader()
        reader.feed(b'foo')
        def write_more():
            gruvi.sleep(0.01)
            reader.feed(b'bar')
            gruvi.sleep(0.01)
            reader.feed_error(RuntimeError)
        gruvi.spawn(write_more)
        self.assertEqual(reader.readline(), b'foobar')
        self.assertRaises(RuntimeError, reader.readline)

    def test_readlines_limit(self):
        reader = StreamReader()
        reader.feed(b'foo\nbar\n')
        self.assertEqual(reader.readlines(4), [b'foo\n', b'bar\n'])

    def test_readlines_eof(self):
        reader = StreamReader()
        reader.feed(b'foo\nbar\n')
        reader.feed_eof()
        self.assertEqual(reader.readlines(), [b'foo\n', b'bar\n'])
        self.assertEqual(reader.readlines(), [])

    def test_readlines_wait_eof(self):
        reader = StreamReader()
        reader.feed(b'foo\n')
        def write_more():
            gruvi.sleep(0.01)
            reader.feed(b'bar\n')
            gruvi.sleep(0.01)
            reader.feed_eof()
        gruvi.spawn(write_more)
        self.assertEqual(reader.readlines(), [b'foo\n', b'bar\n'])
        self.assertEqual(reader.readlines(), [])
 
    def test_readlines_error(self):
        reader = StreamReader()
        reader.feed(b'foo\nbar\n')
        reader.feed_error(RuntimeError)
        self.assertEqual(reader.readlines(), [b'foo\n', b'bar\n'])
        self.assertRaises(RuntimeError, reader.readlines)

    def test_readlines_wait_error(self):
        reader = StreamReader()
        reader.feed(b'foo\n')
        def write_more():
            gruvi.sleep(0.01)
            reader.feed(b'bar\n')
            gruvi.sleep(0.01)
            reader.feed_error(RuntimeError)
        gruvi.spawn(write_more)
        self.assertEqual(reader.readlines(), [b'foo\n', b'bar\n'])
        self.assertRaises(RuntimeError, reader.readlines)

    def test_iter_eof(self):
        reader = StreamReader()
        reader.feed(b'foo\nbar\n')
        reader.feed_eof()
        it = iter(reader)
        self.assertEqual(six.next(it), b'foo\n')
        self.assertEqual(six.next(it), b'bar\n')
        self.assertRaises(StopIteration, six.next, it)

    def test_iter_wait_eof(self):
        reader = StreamReader()
        reader.feed(b'foo\n')
        def write_more():
            gruvi.sleep(0.01)
            reader.feed(b'bar\n')
            gruvi.sleep(0.01)
            reader.feed_eof()
        gruvi.spawn(write_more)
        it = iter(reader)
        self.assertEqual(six.next(it), b'foo\n')
        self.assertEqual(six.next(it), b'bar\n')
        self.assertRaises(StopIteration, six.next, it)

    def test_iter_error(self):
        reader = StreamReader()
        reader.feed(b'foo\nbar\n')
        reader.feed_error(RuntimeError)
        it = iter(reader)
        self.assertEqual(six.next(it), b'foo\n')
        self.assertEqual(six.next(it), b'bar\n')
        self.assertRaises(RuntimeError, six.next, it)

    def test_iter_wait_error(self):
        reader = StreamReader()
        reader.feed(b'foo\n')
        def write_more():
            gruvi.sleep(0.01)
            reader.feed(b'bar\n')
            gruvi.sleep(0.01)
            reader.feed_error(RuntimeError)
        gruvi.spawn(write_more)
        it = iter(reader)
        self.assertEqual(six.next(it), b'foo\n')
        self.assertEqual(six.next(it), b'bar\n')
        self.assertRaises(RuntimeError, six.next, it)


class TestStreamProtocol(UnitTest):

    def test_read(self):
        # Test that read() works.
        transport = MockTransport()
        protocol = StreamProtocol()
        transport.start(protocol)
        protocol.data_received(b'foo')
        self.assertEqual(protocol.read(100), b'foo')
        protocol.data_received(b'bar')
        protocol.eof_received()
        self.assertEqual(protocol.read(), b'bar')

    def test_read_after_error(self):
        # Test that the buffer can be emptied after an error occurs.
        transport = MockTransport()
        protocol = StreamProtocol()
        transport.start(protocol)
        protocol.data_received(b'foobar')
        protocol.connection_lost(RuntimeError)
        self.assertEqual(protocol.read(3), b'foo')
        self.assertEqual(protocol.read(3), b'bar')
        self.assertRaises(RuntimeError, protocol.read)

    def test_readline(self):
        # Test that readline() works.
        transport = MockTransport()
        protocol = StreamProtocol()
        transport.start(protocol)
        protocol.data_received(b'foo\n')
        self.assertEqual(protocol.readline(), b'foo\n')
 
    def test_readlines(self):
        # Test that readlines() works.
        transport = MockTransport()
        protocol = StreamProtocol()
        transport.start(protocol)
        protocol.data_received(b'foo\nbar\n')
        protocol.eof_received()
        self.assertEqual(protocol.readlines(), [b'foo\n', b'bar\n'])
 
    def test_iter(self):
        # Ensure that iterating over a stream protocol produces lines.
        transport = MockTransport()
        protocol = StreamProtocol()
        transport.start(protocol)
        protocol.data_received(b'foo\nbar\n')
        protocol.eof_received()
        it = iter(protocol)
        self.assertEqual(six.next(it), b'foo\n')
        self.assertEqual(six.next(it), b'bar\n')
        self.assertRaises(StopIteration, six.next, it)

    def test_write(self):
        # Test that write() works.
        transport = MockTransport()
        protocol = StreamProtocol()
        transport.start(protocol)
        protocol.write(b'foo')
        self.assertEqual(transport.buffer.getvalue(), b'foo')

    def test_writelines(self):
        # Test that writelines() works.
        transport = MockTransport()
        protocol = StreamProtocol()
        transport.start(protocol)
        protocol.writelines([b'foo', b'bar'])
        self.assertEqual(transport.buffer.getvalue(), b'foobar')

    def test_write_eof(self):
        # Test that write_eof() works.
        transport = MockTransport()
        protocol = StreamProtocol()
        transport.start(protocol)
        self.assertFalse(transport.eof)
        protocol.write_eof()
        self.assertTrue(transport.eof)

    def test_read_write_flow_control(self):
        # Test the read and write flow control of a stream transport.
        transport = MockTransport()
        protocol = StreamProtocol()
        transport.start(protocol)
        protocol.set_read_buffer_limits(100)
        transport.set_write_buffer_limits(50)
        def reader():
            while True:
                buf = protocol.read(20)
                protocol.write(buf)
        gruvi.spawn(reader)
        buf = b'x' * 20
        interrupted = 0
        for i in range(100):
            protocol.data_received(buf)
            if protocol._reading:
                continue
            interrupted += 1
            self.assertGreater(protocol._read_buffer_size, 0)
            # Switch to the reader() fiber which will fill up the transport
            # write buffer.
            gruvi.sleep(0)
            # The transport write buffer should be full but the protocol read
            # buffer should still contain something.
            self.assertTrue(protocol._reading)
            self.assertGreater(protocol._read_buffer_size, 0)
            self.assertFalse(protocol._may_write)
            # Drain write buffer and resume writing
            transport.buffer.seek(0)
            transport.buffer.truncate()
            protocol.resume_writing()
        self.assertGreater(interrupted, 30)


def echo_handler(protocol):
    while True:
        buf = protocol.read(100)
        if not buf:
            break
        protocol.write(buf)


class TestStream(UnitTest):

    def test_echo_pipe(self):
        server = StreamServer(echo_handler)
        server.listen(self.pipename())
        client = StreamClient()
        client.connect(server.addresses[0])
        client.write(b'foo\n')
        client.write_eof()
        self.assertEqual(client.readline(), b'foo\n')
        self.assertEqual(client.readline(), b'')
        server.close()
        client.close()

    def test_echo_pipe_ssl(self):
        server = StreamServer(echo_handler)
        context = self.get_ssl_context()
        server.listen(self.pipename(), ssl=context)
        client = StreamClient()
        client.connect(server.addresses[0], ssl=context)
        client.write(b'foo\n')
        self.assertEqual(client.readline(), b'foo\n')
        server.close()
        client.close()

    def test_echo_tcp(self):
        server = StreamServer(echo_handler)
        server.listen(('127.0.0.1', 0))
        client = StreamClient()
        client.connect(server.addresses[0])
        client.write(b'foo\n')
        client.write_eof()
        self.assertEqual(client.readline(), b'foo\n')
        server.close()
        client.close()

    def test_echo_tcp_ssl(self):
        server = StreamServer(echo_handler)
        context = self.get_ssl_context()
        server.listen(('127.0.0.1', 0), ssl=context)
        client = StreamClient()
        client.connect(server.addresses[0], ssl=context)
        client.write(b'foo\n')
        self.assertEqual(client.readline(), b'foo\n')
        server.close()
        client.close()

    def test_echo_data(self):
        # Echo a bunch of data and ensure it is echoed identically
        server = StreamServer(echo_handler)
        server.listen(('127.0.0.1', 0))
        client = StreamClient()
        client.connect(server.addresses[0])
        md1 = hashlib.sha256()
        md2 = hashlib.sha256()
        def produce():
            for i in range(1000):
                chunk = os.urandom(1024)
                client.write(chunk)
                md1.update(chunk)
            client.write_eof()
        def consume():
            while True:
                buf = client.read(1024)
                if not buf:
                    break
                md2.update(buf)
        f1 = gruvi.spawn(produce)
        f2 = gruvi.spawn(consume)
        f1.join(); f2.join()
        self.assertEqual(md1.digest(), md2.digest())
        server.close()
        client.close()

    def test_connection_limit(self):
        server = StreamServer(echo_handler)
        server.listen(('127.0.0.1', 0))
        addr = server.addresses[0]
        server.max_connections = 10
        clients = []
        try:
            for i in range(15):
                client = StreamClient()
                client.connect(addr)
                client.write(b'foo\n')
                buf = client.readline()
                if buf == b'':  # conneciton closed: EOF
                    client.close()
                clients.append(client)
        except TransportError as e:
            pass
        self.assertLessEqual(len(server.connections), server.max_connections)
        for client in clients:
            client.close()
        server.close()


if __name__ == '__main__':
    os.environ.setdefault('VERBOSE', '1')
    unittest.main()

########NEW FILE########
__FILENAME__ = test_sync
#
# This file is part of gruvi. Gruvi is free software available under the
# terms of the MIT license. See the file "LICENSE" that was provided
# together with this source file for the licensing terms.
#
# Copyright (c) 2012-2014 the gruvi authors. See the file "AUTHORS" for a
# complete list.

from __future__ import absolute_import, print_function, division

import gc
import time
import random
import threading
import weakref
import random

import gruvi
from gruvi.sync import *
from gruvi.hub import get_hub, switch_back
from gruvi import util
from support import *


def lock_unlock(lock, count=50):
    failed = 0
    for i in range(count):
        # the granularity of libuv's timers is 1ms. the statement below
        # therefore sleeps 0ms 75% of the time, and 1ms 25% of the time.
        gruvi.sleep(random.randint(0, 10)/10000)
        lock.acquire()
        gruvi.sleep(random.randint(0, 10)/10000)
        failed += (1 if lock._locked != 1 else 0)
        lock.release()
    return failed


class TestLock(UnitTest):

    def test_basic(self):
        # Ensure that acquire() and release() works.
        lock = gruvi.Lock()
        self.assertFalse(lock.locked())
        lock.acquire()
        self.assertTrue(lock.locked())
        lock.release()
        self.assertFalse(lock.locked())

    def test_timeout(self):
        # Ensure that the timeout argument to acquire() works.
        hub = get_hub()
        lock = gruvi.Lock()
        lock.acquire()
        t0 = hub.loop.now()
        self.assertFalse(lock.acquire(timeout=0.01))
        t1 = hub.loop.now()
        self.assertGreater(t1-t0, 10)
        self.assertFalse(lock._waiters)

    def test_non_blocking(self):
        # Ensure that the blocking argument to acquire() works.
        hub = get_hub()
        lock = gruvi.Lock()
        lock.acquire()
        self.assertFalse(lock.acquire(blocking=False))
        self.assertFalse(lock._waiters)

    def test_context_manager(self):
        # Ensure that a lock can be used as a context manager.
        lock = gruvi.Lock()
        with lock:
            self.assertTrue(lock.locked())
        self.assertFalse(lock.locked())

    def test_acquire_release_threads(self):
        # Ensure that a lock can be locked and unlocked in different threads.
        lock = gruvi.Lock()
        sync = gruvi.Lock()
        failed = [0]
        def thread_lock():
            lock.acquire()
            failed[0] += (1 if not lock.locked() else 0)
            sync.release()
        def thread_unlock():
            sync.acquire()
            lock.release()
            failed[0] += (1 if lock.locked() else 0)
            sync.release()
        sync.acquire()
        t1 = threading.Thread(target=thread_lock)
        t2 = threading.Thread(target=thread_unlock)
        t1.start(); t2.start()
        t1.join(); t2.join()
        self.assertEqual(failed[0], 0)

    def test_fiber_safety(self):
        # Start a bunch of fibers, each locking the rlock a few times before
        # unlocking it again. Ensure that the locks don't overlap.
        lock = gruvi.Lock()
        failed = [0]
        def run_test():
            failed[0] += lock_unlock(lock, 20)
        fibers = []
        for i in range(20):
            fiber = gruvi.Fiber(run_test)
            fiber.start()
            fibers.append(fiber)
        for fib in fibers:
            fib.join()
        self.assertEqual(failed[0], 0)

    def test_thread_safety(self):
        # Start a bunch of threads, each starting a bunch of fibers. Each fiber
        # will lock the rlock a few times before unlocking it again. Ensure
        # that the locks don't overlap.
        lock = gruvi.Lock()
        failed = [0]
        def run_test():
            failed[0] += lock_unlock(lock, 10)
        def run_thread():
            fibers = []
            for i in range(10):
                fiber = gruvi.Fiber(run_test)
                fiber.start()
                fibers.append(fiber)
            for fib in fibers:
                fib.join()
        threads = []
        for i in range(5):
            thread = threading.Thread(target=run_thread)
            thread.start()
            threads.append(thread)
        for thread in threads:
            thread.join()
        self.assertEqual(failed[0], 0)


def lock_unlock_reentrant(lock, count=10):
    failed = 0
    for i in range(count):
        gruvi.sleep(random.randint(0, 10)/10000)
        lock.acquire()
        gruvi.sleep(random.randint(0, 10)/10000)
        failed += (1 if lock._locked != 1 else 0)
        lock.acquire()
        gruvi.sleep(random.randint(0, 10)/10000)
        failed += (1 if lock._locked != 2 else 0)
        lock.release()
        gruvi.sleep(random.randint(0, 10)/10000)
        failed += (1 if lock._locked != 1 else 0)
        lock.release()
    return failed


class TestRLock(UnitTest):

    def test_basic(self):
        # Lock and unlock the rlock once.
        lock = gruvi.RLock()
        lock.acquire()
        self.assertTrue(lock.locked())
        lock.release()
        self.assertFalse(lock.locked())

    def test_multiple(self):
        # Lock and unlock the rlock a few times
        lock = gruvi.RLock()
        for i in range(5):
            lock.acquire()
            self.assertEqual(lock._locked, i+1)
        self.assertTrue(lock.locked())
        for i in range(5):
            lock.release()
            self.assertEqual(lock._locked, 4-i)
        self.assertFalse(lock.locked())

    def test_timeout(self):
        # Ensure that the timeout argument to acquire() works.
        hub = get_hub()
        lock = gruvi.RLock()
        sync = gruvi.Lock()
        def lock_rlock():
            lock.acquire()
            sync.acquire()
            lock.release()
        # This needs a new fiber, as the same fiber *can* lock the same RLock twice.
        sync.acquire()
        fiber = gruvi.spawn(lock_rlock)
        gruvi.sleep(0)
        self.assertTrue(lock.locked())
        t0 = hub.loop.now()
        self.assertFalse(lock.acquire(timeout=0.01))
        t1 = hub.loop.now()
        # Internally the event loop uses timestamps with a 1ms granularity. So
        # allow for that.
        self.assertGreaterEqual(t1-t0, 10)
        sync.release()
        fiber.join()
        self.assertFalse(lock._waiters)

    def test_non_blocking(self):
        # Ensure that the blocking argument to acquire() works.
        hub = get_hub()
        lock = gruvi.RLock()
        sync = gruvi.Lock()
        def lock_rlock():
            lock.acquire()
            sync.acquire()
            lock.release()
        # This needs a new fiber, as the same fiber *can* lock the same RLock twice.
        sync.acquire()
        fiber = gruvi.spawn(lock_rlock)
        gruvi.sleep(0)
        self.assertTrue(lock.locked())
        self.assertFalse(lock.acquire(blocking=False))
        sync.release()
        fiber.join()
        self.assertFalse(lock._waiters)

    def test_context_manager(self):
        # Ensure that an RLock can be used as a context manager.
        lock = gruvi.RLock()
        with lock:
            self.assertTrue(lock.locked())
        self.assertFalse(lock.locked())

    def test_fiber_safety(self):
        # Start a bunch of fibers, each locking the rlock a few times before
        # unlocking it again. Ensure that the locks don't overlap.
        lock = gruvi.RLock()
        failed = [0]
        def run_test():
            failed[0] += lock_unlock_reentrant(lock, 10)
        fibers = []
        for i in range(20):
            fiber = gruvi.Fiber(run_test)
            fiber.start()
            fibers.append(fiber)
        for fib in fibers:
            fib.join()
        self.assertEqual(failed[0], 0)

    def test_thread_safety(self):
        # Start a bunch of threads, each starting a bunch of fibers. Each fiber
        # will lock the rlock a few times before unlocking it again. Ensure
        # that the locks don't overlap.
        lock = gruvi.RLock()
        failed = [0]
        def run_test():
            failed[0] += lock_unlock_reentrant(lock, 10)
        def run_thread():
            fibers = []
            for i in range(5):
                fiber = gruvi.Fiber(run_test)
                fiber.start()
                fibers.append(fiber)
            for fib in fibers:
                fib.join()
        threads = []
        for i in range(5):
            thread = threading.Thread(target=run_thread)
            thread.start()
            threads.append(thread)
        for thread in threads:
            thread.join()
        self.assertEqual(failed[0], 0)


class TestEvent(UnitTest):

    def test_basic(self):
        # Ensure that an event can be set and cleared
        event = Event()
        self.assertFalse(event)
        self.assertFalse(event._flag)
        event.set()
        self.assertTrue(event)
        self.assertTrue(event._flag)
        event.clear()
        self.assertFalse(event)
        self.assertFalse(event._flag)

    def test_wait(self):
        event = Event()
        done = []
        def waiter():
            done.append(False)
            event.wait()
            done.append(True)
        fiber = gruvi.spawn(waiter)
        gruvi.sleep(0)
        self.assertEqual(done, [False])
        event.set()
        gruvi.sleep(0)
        self.assertEqual(done, [False, True])


class TestCondition(UnitTest):

    def test_basic(self):
        # Ensure that a basic wait/notify works.
        cond = gruvi.Condition()
        waiting = [0]
        def wait_cond():
            with cond:
                waiting[0] += 1
                cond.wait()
                waiting[0] -= 1
        fiber = gruvi.spawn(wait_cond)
        gruvi.sleep(0)
        self.assertEqual(waiting[0], 1)
        with cond:
            cond.notify()
        gruvi.sleep(0)
        self.assertEqual(waiting[0], 0)

    def test_notify_multiple(self):
        # Ensure that multiple fibers can be notified, and that the order in
        # which they are notified is respected.
        cond = gruvi.Condition()
        waiting = [0]
        done = []
        def wait_cond(i):
            with cond:
                waiting[0] += 1
                cond.wait()
                waiting[0] -= 1
                done.append(i)
        fibers = []
        for i in range(10):
            fibers.append(gruvi.spawn(wait_cond, i))
        gruvi.sleep(0)
        self.assertEqual(waiting[0], 10)
        with cond:
            cond.notify(1)
        gruvi.sleep(0)
        self.assertEqual(waiting[0], 9)
        with cond:
            cond.notify(3)
        gruvi.sleep(0)
        self.assertEqual(waiting[0], 6)
        with cond:
            cond.notify_all()
        gruvi.sleep(0)
        self.assertEqual(waiting[0], 0)
        self.assertEqual(done, list(range(10)))

    def test_wait_for(self):
        # Ensure that wait_for can wait for a predicate
        cond = gruvi.Condition()
        waiting = [0]
        unblock = []
        done = []
        def wait_cond(i):
            with cond:
                waiting[0] += 1
                cond.wait_for(lambda: i in unblock)
                waiting[0] -= 1
                done.append(i)
        fibers = []
        for i in range(10):
            fibers.append(gruvi.spawn(wait_cond, i))
        gruvi.sleep(0)
        self.assertEqual(waiting[0], 10)
        with cond:
            cond.notify(1) # no predicate matches
        gruvi.sleep(0)
        self.assertEqual(waiting[0], 10)
        unblock += [0]
        with cond:
            cond.notify(1) # one predicate matches
        gruvi.sleep(0)
        self.assertEqual(waiting[0], 9)
        unblock += [2, 3]
        with cond:
            cond.notify(3)  # two match
        gruvi.sleep(0)
        self.assertEqual(waiting[0], 7)
        unblock += [1]
        with cond:
            cond.notify_all()  # one match
        gruvi.sleep(0)
        self.assertEqual(waiting[0], 6)
        unblock += list(range(10))
        with cond:
            cond.notify_all()  # one match
        gruvi.sleep(0)
        self.assertEqual(waiting[0], 0)
        self.assertEqual(done, [0, 2, 3, 1, 4, 5, 6, 7, 8, 9])

    def test_call_without_lock(self):
        # A RuntimeError should be raised if notify or wait are called without
        # the lock.
        cond = gruvi.Condition()
        self.assertRaises(RuntimeError, cond.wait)
        self.assertRaises(RuntimeError, cond.notify)

    def test_wait_timeout(self):
        # When a timeout occurs, wait() should return False
        cond = gruvi.Condition()
        with cond:
            self.assertFalse(cond.wait(timeout=0.01))
        self.assertFalse(cond._waiters)

    def test_wait_for_timeout(self):
        # When a timeout occurs, wait_for() should return False
        cond = gruvi.Condition()
        waiters = [0]
        def notify_cond():
            with cond:
                waiters[0] += 1
                cond.notify()
                waiters[0] -= 1
        fiber = gruvi.spawn(notify_cond)
        with cond:
            self.assertEqual(waiters[0], 0)
            self.assertFalse(cond.wait_for(lambda: False, timeout=0.1))
            self.assertEqual(waiters[0], 0)


class TestQueue(UnitTest):

    def test_basic(self):
        # What is put in the queue, should come out.
        queue = gruvi.Queue()
        queue.put(10)
        self.assertEqual(queue.get(), 10)

    def test_types(self):
        # Queue should support putting in arbitrary objects.
        queue = gruvi.Queue()
        queue.put('foo')
        self.assertEqual(queue.get(), 'foo')
        queue.put(['foo'])
        self.assertEqual(queue.get(), ['foo'])

    def test_order(self):
        # The behavior of a queue should be FIFO
        queue = gruvi.Queue()
        for i in range(10):
            queue.put(10+i)
        for i in range(10):
            self.assertEqual(queue.get(), 10+i)

    def test_qsize(self):
        # The qsize() of a queue should by default be the number of elements
        queue = gruvi.Queue()
        for i in range(10):
            queue.put(10+i)
            self.assertEqual(queue.qsize(), i+1)
        for i in range(10):
            self.assertEqual(queue.get(), 10+i)
            self.assertEqual(queue.qsize(), 10-i-1)

    def test_qsize_custom_size(self):
        # The put() method has an optional "size" argument that allows you to
        # specify a custom size.
        queue = gruvi.Queue()
        for i in range(10):
            queue.put(10+i, size=2)
            self.assertEqual(queue.qsize(), 2*(i+1))
        for i in range(10):
            self.assertEqual(queue.get(), 10+i)
            self.assertEqual(queue.qsize(), 2*(10-i-1))

    def test_get_wait(self):
        # Queue.get() should wait until an item becomes available.
        queue = gruvi.Queue()
        def put_queue(value):
            gruvi.sleep(0.01)
            queue.put(value)
        fiber = gruvi.spawn(put_queue, 'foo')
        self.assertEqual(queue.get(), 'foo')

    def test_get_timeout(self):
        # Ensure the "timeout" argument to Queue.get() works
        queue = gruvi.Queue()
        hub = get_hub()
        t0 = hub.loop.now()
        self.assertRaises(gruvi.QueueEmpty, queue.get, timeout=0.01)
        t1 = hub.loop.now()
        self.assertGreaterEqual(t1-t0, 10)

    def test_get_non_blocking(self):
        # Ensure the "block" argument to Queue.get() works
        queue = gruvi.Queue()
        self.assertRaises(gruvi.QueueEmpty, queue.get, block=False)
        self.assertRaises(gruvi.QueueEmpty, queue.get_nowait)

    def test_put_timeout(self):
        # Ensure the "timeout" argument to Queue.put() works
        queue = gruvi.Queue(maxsize=10)
        queue.put('foo', size=10)
        hub = get_hub()
        t0 = hub.loop.now()
        self.assertRaises(gruvi.QueueFull, queue.put, 'bar', timeout=0.01)
        t1 = hub.loop.now()
        self.assertGreaterEqual(t1-t0, 10)

    def test_put_non_blocking(self):
        # Ensure the "block" argument to Queue.put() works
        queue = gruvi.Queue(maxsize=10)
        queue.put('foo', size=10)
        self.assertRaises(gruvi.QueueFull, queue.put, 'bar', block=False)
        self.assertRaises(gruvi.QueueFull, queue.put_nowait, 'bar')

    def test_empty(self):
        # Ensure that empty() returns nonzero if the queue is empty.
        queue = gruvi.Queue()
        self.assertTrue(queue.empty())
        queue.put('foo')
        self.assertFalse(queue.empty())

    def test_full(self):
        # Ensure that empty() returns nonzero if the queue is empty.
        queue = gruvi.Queue(maxsize=1)
        self.assertFalse(queue.full())
        queue.put('foo')
        self.assertTrue(queue.full())

    def test_produce_consume(self):
        # Ensure that there's no deadlocks when pushing a large number of items
        # through a queue with a fixed size.
        queue = gruvi.Queue(maxsize=10)
        result = []; sizes = []
        def consumer(n):
            for i in range(n):
                queue.put(i)
                sizes.append(queue.qsize())
        def producer(n):
            for i in range(n):
                result.append(queue.get())
                sizes.append(queue.qsize())
        ni = 2000
        fcons = gruvi.spawn(consumer, ni)
        fprod = gruvi.spawn(producer, ni)
        fcons.join(); fprod.join()
        self.assertEqual(len(result), ni)
        self.assertEqual(result, list(range(ni)))
        self.assertLessEqual(max(sizes), 10)

    def test_thread_safety(self):
        # A Queue should be thread safe. This meanst that all entries that are
        # put in the queue must be returned, that no entry must be returned
        # twice and that the order must be respected. Also no deadlock must
        # ever occur.
        # To test, fire up a bunch of threads which each fire up a bunch of
        # fibers, and have the fibers do some random sleeps. Then let it run
        # and test the result.
        result = []
        reference  = []
        lock = gruvi.Lock()
        def put_queue(tid, fid, count):
            for i in range(count):
                with lock:
                    gruvi.sleep(random.randint(0, 10)/10000)
                    queue.put((tid, fid, count))
                    reference.append((tid, fid, count))
        def get_queue(count):
            for i in range(count):
                with lock:
                    result.append(queue.get())
        def thread_put(tid, nfibers, count):
            fibers = []
            for i in range(nfibers):
                fibers.append(gruvi.spawn(put_queue, tid, i, count))
            for fib in fibers:
                fib.join()
            gruvi.get_hub().close()
        def thread_get(nfibers, count):
            fibers = []
            for i in range(nfibers):
                fibers.append(gruvi.spawn(get_queue, count))
            for fib in fibers:
                fib.join()
            gruvi.get_hub().close()
        queue = gruvi.Queue()
        threads = []
        # 5 procuders and 5 consumers, each with 20 fibers
        for i in range(5):
            thread = threading.Thread(target=thread_put, args=(i,20,5))
            thread.start()
            threads.append(thread)
        for i in range(5):
            thread = threading.Thread(target=thread_get, args=(20,5))
            thread.start()
            threads.append(thread)
        for thread in threads:
            thread.join()
        gruvi.sleep(0)  # run callbacks
        self.assertEqual(len(result), 500)
        self.assertEqual(result, reference)
        # Within a (tid,fid) pair, the counts must be monotonic
        partial_sort = sorted(result, key=lambda el: (el[0], el[1]))
        full_sort = sorted(result, key=lambda el: (el[0], el[1], el[2]))
        self.assertEqual(partial_sort, full_sort)


class TestLifoQueue(UnitTest):

    def test_order(self):
        # The behavior of a queue should be LIFO
        queue = gruvi.LifoQueue()
        for i in range(10):
            queue.put(10+i)
        for i in range(10):
            self.assertEqual(queue.get(), 19-i)


class TestPriorityQueue(UnitTest):

    def test_order(self):
        # The queue should respect the priority we give it.
        queue = gruvi.PriorityQueue()
        items = list(range(100))
        prios = list(range(100))
        random.shuffle(prios)
        items = list(zip(prios, items))
        for item in items:
            queue.put(item)
        result = []
        for i in range(len(items)):
            result.append(queue.get())
        self.assertEqual(sorted(items), result)


if __name__ == '__main__':
    unittest.main()

########NEW FILE########
__FILENAME__ = test_transports
#
# This file is part of Gruvi. Gruvi is free software available under the
# terms of the MIT license. See the file "LICENSE" that was provided
# together with this source file for the licensing terms.
#
# Copyright (c) 2012-2014 the Gruvi authors. See the file "AUTHORS" for a
# complete list.

from __future__ import absolute_import, print_function

import pyuv
import socket

from support import *
from gruvi.transports import *


class ProtocolLogger(object):
    """Utility protocol class that implements both the stream and datagram
    protocols and that logs all callbacks."""

    def __init__(self):
        self.events = []
        self.transport = None
    
    def get_events(self, typ):
        return [ev for ev in self.events if ev[0] == typ]

    def connection_made(self, transport):
        self.events.append(('connection_made', transport))
        self.transport = transport

    def data_received(self, data):
        # collapse data_received for easier verification
        if self.events[-1][0] == 'data_received':
            self.events[-1] = ('data_received', self.events[-1][1] + data)
        else:
            self.events.append(('data_received', data))

    def eof_received(self):
        self.events.append(('eof_received',))

    def connection_lost(self, exc=None):
        self.events.append(('connection_lost', exc))

    def datagram_received(self, data, addr):
        self.events.append(('datagram_received', data, addr))

    def error_received(self, exc):
        self.events.append(('error_received', exc))


class EchoServer(ProtocolLogger):

    def data_received(self, data):
        super(EchoServer, self).data_received(data)
        self.transport.write(data)


class EventLoopTest(UnitTest):

    def setUp(self):
        super(EventLoopTest, self).setUp()
        self.loop = pyuv.Loop()
        self.errors = []

    def catch_errors(self, callback):
        # Run *callback*. If it raises an exception, store it and stop the
        # loop.
        def run_callback(*args):
            try:
                callback(*args)
            except Exception as e:
                self.errors.append(e)
                self.loop.stop()
        return run_callback

    def run_loop(self, timeout):
        # Run the loop for at most *timeout* seconds. Re-raise any exception
        # that was catch by a "catch_errors" callback.
        timer = pyuv.Timer(self.loop)
        def stop_loop(handle):
            self.loop.stop()
        timer.start(stop_loop, timeout, 0)
        self.loop.run()
        if self.errors:
            raise self.errors[0]


class TransportTest(object):

    def create_handle(self):
        raise NotImplementedError

    def bind_handle(self, handle):
        raise NotImplementedError

    def create_transport(self, handle, protocol, server_side):
        transport = Transport(handle)
        transport.start(protocol)
        return transport

    def test_echo(self):
        # Test a simple echo server. The client writes some data end then
        # writes an EOF (if the transport supports writing EOF). The server
        # echos and upon receipt of EOF will close the connection.
        @self.catch_errors
        def echo_server(handle, error):
            if error:
                raise TransportError.from_errno(error)
            client = self.create_handle()
            handle.accept(client)
            protocols[0] = EchoServer()
            transports[0] = self.create_transport(client, protocols[0], True)
        @self.catch_errors
        def echo_client(handle, error):
            if error:
                raise TransportError.from_errno(error)
            protocols[1] = ProtocolLogger()
            trans = transports[1] = self.create_transport(handle, protocols[1], False)
            trans.write(b'foo\n')
            trans.write(b'bar\n')
            trans.writelines([b'qux', b'quux'])
            if trans.can_write_eof():
                trans.write_eof()
        transports = [None, None]
        protocols = [None, None]
        server = self.create_handle()
        addr = self.bind_handle(server)
        server.listen(echo_server)
        client = self.create_handle()
        client.connect(addr, echo_client)
        self.run_loop(0.1)
        strans, ctrans = transports
        sproto, cproto = protocols
        self.assertIsInstance(strans, Transport)
        self.assertIsInstance(ctrans, Transport)
        self.assertIsInstance(sproto, EchoServer)
        self.assertIsInstance(cproto, ProtocolLogger)
        ctrans.close()
        self.run_loop(0.1)
        sevents = sproto.events
        nevents = 4 if strans.can_write_eof() else 3
        self.assertEqual(len(sevents), nevents)
        self.assertEqual(sevents[0], ('connection_made', strans))
        self.assertEqual(sevents[1], ('data_received', b'foo\nbar\nquxquux'))
        if strans.can_write_eof():
            self.assertEqual(sevents[2], ('eof_received',))
        self.assertEqual(sevents[-1][0], 'connection_lost')
        cevents = cproto.events
        self.assertEqual(len(cevents), nevents)
        self.assertEqual(cevents[0], ('connection_made', ctrans))
        self.assertEqual(cevents[1], ('data_received', b'foo\nbar\nquxquux'))
        if ctrans.can_write_eof():
            self.assertEqual(cevents[2], ('eof_received',))
        self.assertEqual(cevents[-1][0], 'connection_lost')


class TestTcpTransport(TransportTest, EventLoopTest):

    def create_handle(self):
        return pyuv.TCP(self.loop)

    def bind_handle(self, handle):
        host = socket.gethostbyname('localhost')
        handle.bind((host, 0))
        return handle.getsockname()


class TestPipeTransport(TransportTest, EventLoopTest):

    def create_handle(self):
        return pyuv.Pipe(self.loop)

    def bind_handle(self, handle):
        addr = self.pipename('test-pipe')
        handle.bind(addr)
        return addr


class TestUdpTransport(EventLoopTest):

    def create_handle(self):
        return pyuv.UDP(self.loop)

    def bind_handle(self, handle):
        host = socket.gethostbyname('localhost')
        handle.bind((host, 0))
        return handle.getsockname()

    def create_transport(self, handle, protocol):
        transport = DatagramTransport(handle)
        transport.start(protocol)
        return transport

    def test_echo(self):
        server = self.create_handle()
        saddr = self.bind_handle(server)
        sproto = ProtocolLogger()
        strans = self.create_transport(server, sproto)
        client = self.create_handle()
        caddr = self.bind_handle(client)
        cproto = ProtocolLogger()
        ctrans = self.create_transport(client, cproto)
        # Try 5 times (since UDP is lossy)
        for i in range(5):
            ctrans.sendto(b'foo', saddr)
        for i in range(5):
            strans.sendto(b'bar', caddr)
        self.run_loop(0.5)
        sevents = sproto.get_events('datagram_received')
        self.assertGreater(len(sevents), 0)
        for event in sevents:
            self.assertEqual(event[1], b'foo')
            self.assertEqual(event[2], caddr)
        cevents = cproto.get_events('datagram_received')
        self.assertGreater(len(cevents), 0)
        for event in cevents:
            self.assertEqual(event[1], b'bar')
            self.assertEqual(event[2], saddr)


if __name__ == '__main__':
    unittest.main()

########NEW FILE########
__FILENAME__ = test_util
#
# This file is part of Gruvi. Gruvi is free software available under the
# terms of the MIT license. See the file "LICENSE" that was provided
# together with this source file for the licensing terms.
#
# Copyright (c) 2012-2014 the Gruvi authors. See the file "AUTHORS" for a
# complete list.

from __future__ import absolute_import, print_function

from support import *
from gruvi.util import fixup_format_string


class TestReplaceFmt(UnitTest):

    def test_basic(self):
        self.assertEqual(fixup_format_string(''), '')
        self.assertEqual(fixup_format_string('{}'), '{0}')
        self.assertEqual(fixup_format_string('{} {}'), '{0} {1}')
        self.assertEqual(fixup_format_string('foo {} {}'), 'foo {0} {1}')

    def test_escaped(self):
        self.assertEqual(fixup_format_string('{{}}'), '{{}}')
        self.assertEqual(fixup_format_string('{{}}{{}}'), '{{}}{{}}')
        self.assertEqual(fixup_format_string('{{{}}}'), '{{{0}}}')
        self.assertEqual(fixup_format_string('{{{}}}{{{}}}'), '{{{0}}}{{{1}}}')

    def test_extended(self):
        self.assertEqual(fixup_format_string('{!s}'), '{0!s}')
        self.assertEqual(fixup_format_string('{:.2f}'), '{0:.2f}')


if __name__ == '__main__':
    unittest.main()

########NEW FILE########
__FILENAME__ = test_marshal
import unittest
from struct import pack

import gruvi.txdbus.marshal as m

#dbus_types = [ ('BYTE',        'y',     1),
#               ('BOOLEAN',     'b',     4),
#               ('INT16',       'n',     2),
#               ('UINT16',      'q',     2),
#               ('INT32',       'i',     4),
#               ('UINT32',      'u',     4),
#               ('INT64',       'x',     8),
#               ('UINT64',      't',     8),
#               ('DOUBLE',      'd',     8),
#               ('STRING',      's',     4), # (4-byte align for length)
#               ('OBJECT_PATH', '4',     4), # (4-byte align for length)
#               ('SIGNATURE',   'g',     1),
#               ('ARRAY',       'a',     4), # (4-byte align for length)
#               ('STRUCT',      '(',     8),
#               ('VARIANT',     'v',     1), # (1-byte align for signature)
#               ('DICT_ENTRY',  '{',     8),
#               ('UNIX_FD',     'h',     4)
#               ]

class SigFromPyTests(unittest.TestCase):

    def t(self, p, s):
        self.assertEquals( m.sigFromPy(p), s )

    def test_int(self):
        self.t(1,'i')

    def test_float(self):
        self.t(1.0,'d')

    def test_string(self):
        self.t('foo','s')

    def test_list(self):
        self.t([1],'ai')

    def test_dict(self):
        self.t(dict(foo=1),'a{si}')

    def test_fail(self):
        class I(object):
            pass
        self.assertRaises(m.MarshallingError, m.sigFromPy, I())

    def test_class(self):
        class V(object):
            dbusSignature = 'ii'
        self.t(V(), 'ii')
        

class AlignmentTests(unittest.TestCase):

    def test_no_padding(self):
        self.assertEquals( m.pad['y']( 1 ), b'' )

    def test_2align(self):
        self.assertEquals( m.pad['n']( 1 ), b'\0')

    def test_8align(self):
        self.assertEquals( m.pad['t']( 1 ), b'\0'*7)

    def test_0align(self):
        self.assertEquals( m.pad['t']( 8 ), b'')

    def test_mid_align(self):
        self.assertEquals( m.pad['t']( 4 ), b'\0'*4)


        
class SignatureIteratorTests(unittest.TestCase):

    def ae(self, sig, expected):
        self.assertEquals( list(m.genCompleteTypes(sig)), expected )
    
    def test_one(self):
        self.ae( 'i', ['i'])

    def test_two(self):
        self.ae( 'ii', ['i', 'i'])

    def test_multi(self):
        self.ae( 'isydnq', ['i', 's', 'y', 'd', 'n', 'q'])

    def test_struct(self):
        self.ae( 'i(ii)i', ['i', '(ii)', 'i'] )

    def test_embedded_struct(self):
        self.ae( 'i(i(ss)i)i', ['i', '(i(ss)i)', 'i'] )

    def test_embedded_array(self):
        self.ae( 'i(iaii)i', ['i', '(iaii)', 'i'] )

    def test_array_of_struct(self):
        self.ae( 'ia(iii)i', ['i', 'a(iii)', 'i'] )

    def test_array_of_dict(self):
        self.ae( 'ia{s(ii)}i', ['i', 'a{s(ii)}', 'i'] )


class TestMarshal(unittest.TestCase):

    def check(self, sig, var_list, expected_encoding, little_endian=True):
        if not isinstance(var_list, list):
            var_list = [var_list]
        nbytes, chunks = m.marshal( sig, var_list, 0, little_endian  )
        bin_str = b''.join(chunks)
        self.assertEquals( nbytes, len(expected_encoding), "Byte length mismatch. Expected %d. Got %d" % (len(expected_encoding), nbytes) )
        self.assertEquals( bin_str, expected_encoding, "Binary encoding differs from expected value" )
        
        

class TestSimpleMarshal(TestMarshal):
    
    def test_byte(self):
        self.check( 'y', 1, b'\1' )

    def test_int16(self):
        self.check( 'n', -1024, pack('h', -1024))

    def test_uint16(self):
        self.check( 'q', 1024, pack('H', 1024))

    def test_int32(self):
        self.check( 'i', -70000, pack('i', -70000))

    def test_uint32(self):
        self.check( 'u', 70000, pack('I', 70000))

    def test_int64(self):
        self.check( 'x', -70000, pack('q', -70000))

    def test_uint64(self):
        self.check( 't', 70000, pack('Q', 70000))

    def test_double(self):
        self.check( 'd', 3.14, pack('d', 3.14))

    def test_boolean(self):
        self.check( 'b', True, pack('i',1))

    def test_string(self):
        self.check( 's', 'Hello World', pack('i12s', 11, b'Hello World'))

    def test_string_wrong_type(self):
        self.assertRaises(m.MarshallingError, self.check, 's', 1, b'')

    def test_string_embedded_null(self):
        self.assertRaises(m.MarshallingError, self.check, 's', b'Hello\0World', b'')

    def test_signature1(self):
        self.check( 'g', 'i', pack('BcB', 1, b'i', 0) )

    def test_signature2(self):
        self.check( 'g', '(ii)', pack('B4sB', 4, b'(ii)', 0) )

    def test_endian(self):
        self.check( 'x', 70000, pack('>q', 70000), False)

        
        

class TestStructMarshal(TestMarshal):

    def test_one(self):
        self.check('(i)', [[1]], pack('i',1))

    def test_two(self):
        self.check('(ii)', [[2,3]], pack('ii',2,3))

    def test_pad(self):
        self.check('(yx)', [[1,70000]], pack('Bxxxxxxxq',1,70000))

    def test_string(self):
        self.check('(ysy)', [[1, 'foo', 2]], pack('Bxxxi3sxB', 1, 3, b'foo', 2))

    def test_substruct(self):
        self.check('(y(ii)y)', [[1, [3,4], 2]], pack('BxxxxxxxiiB', 1, 3, 4, 2))

    def test_substruct_endian(self):
        self.check('(y(ii)y)', [[1, [3,4], 2]], pack('>BxxxxxxxiiB', 1, 3, 4, 2), False)

    def test_custom(self):
        class S:
            dbusOrder  = 'a b'.split()

            def __init__(self):
                self.a = 1
                self.b = 2

        self.check('(ii)', [S()], pack('ii',1,2))




class TestArrayMarshal(TestMarshal):

    def test_byte(self):
        self.check('ay', [[1,2,3,4]], pack('iBBBB', 4, 1,2,3,4))

    def test_string(self):
        self.check('as', [['x', 'foo']], pack('ii2sxxi4s', 16, 1, b'x', 3, b'foo'))

    def test_struct(self):
        self.check('a(ii)', [[[1,2],[3,4]]], pack('ixxxxiiii', 16, 1,2,3,4))

    def test_struct_padding(self):
        self.check('a(yy)', [[[1,2],[3,4]]], pack('ixxxxBBxxxxxxBB', 10, 1,2,3,4))

    def test_dict(self):
        self.check('a{yy}', [{1:2, 3:4}], pack('ixxxxBBxxxxxxBB', 10, 1,2,3,4))

    def test_dict_strings(self):
        self.check('a{ss}',
                   [[('foo','bar'), ('x','y')]],
                   pack('ixxxxi4si4si2sxxi2s', 30, 3, b'foo', 3, b'bar', 1, b'x', 1, b'y'))

    def test_invalid_array(self):
        self.assertRaises(m.MarshallingError, self.check, 'a{yy}', 1, '')
    
                
class TestVariantMarshal(TestMarshal):

    def test_byte(self):
        self.check('v', [1], pack('B2si', 1, b'i', 1))

    def test_struct(self):
        class S:
            dbusSignature = '(ii)'
            dbusOrder     = 'a b'.split()

            def __init__(self):
                self.a = 1
                self.b = 2

        self.check('v', [S()], pack('B5sxxii', 4, b'(ii)', 1,2))


#-------------------------------------------------------------------------------
# Unmarshalling
#-------------------------------------------------------------------------------

def check_equal( a, b ):
    try:
        if isinstance(a, list):
            check_list(a,b)
        elif isinstance(a, dict):
            check_dict(a,b)
        elif not a == b:
            raise Exception()
    except:
        return False

    return True


def check_list( a, b ):
    if not isinstance(b, list):
        raise Exception()
    if len(a) != len(b):
        raise Exception()
    for x,y in zip(a,b):
        check_equal(x,y)

        
def check_dict( a, b ):
    if not isinstance( b, dict ):
        raise Exception()
    if not len(a.keys()) == len(b.keys()):
        raise Exception()
    aset = set(a.keys())
    bset = set(b.keys())
    if aset - bset:
        raise Exception()
    for x in a.keys():
        check_equal( a[x], b[x] )
    
        
class TestUnmarshal(unittest.TestCase):

    def check(self, sig, expected_value, encoding):
        nbytes, value = m.unmarshal( sig, encoding, 0 )
        self.assertEquals( nbytes, len(encoding), "Unmarshalling length mismatch. Expected %d bytes consumed. Got %d" % (len(encoding), nbytes) )        
        self.assertTrue( check_equal([expected_value], value), 'Value mismatch. Expected: "%s". Got: "%s"' % (repr(expected_value), repr(value)))
        
        

class TestSimpleUnmarshal(TestUnmarshal):
    
    def test_byte(self):
        self.check( 'y', 1, b'\1' )

    def test_int16(self):
        self.check( 'n', -1024, pack('h', -1024))

    def test_uint16(self):
        self.check( 'q', 1024, pack('H', 1024))

    def test_int32(self):
        self.check( 'i', -70000, pack('i', -70000))

    def test_uint32(self):
        self.check( 'u', 70000, pack('I', 70000))

    def test_int64(self):
        self.check( 'x', -70000, pack('q', -70000))

    def test_uint64(self):
        self.check( 't', 70000, pack('Q', 70000))

    def test_double(self):
        self.check( 'd', 3.14, pack('d', 3.14))

    def test_boolean(self):
        self.check( 'b', True, pack('i',1))

    def test_string(self):
        self.check( 's', 'Hello World', pack('i12s', 11, b'Hello World'))

    def test_signature1(self):
        self.check( 'g', 'i', pack('BcB', 1, b'i', 0) )

    def test_signature2(self):
        self.check( 'g', '(ii)', pack('B4sB', 4, b'(ii)', 0) )


        
        

class TestStructUnmarshal(TestUnmarshal):

    def test_one(self):
        self.check('(i)', [[1]], pack('i',1))

    def test_two(self):
        self.check('(ii)', [[2,3]], pack('ii',2,3))

    def test_pad(self):
        self.check('(yx)', [[1,70000]], pack('Bxxxxxxxq',1,70000))

    def test_string(self):
        self.check('(ysy)', [[1, 'foo', 2]], pack('Bxxxi3sxB', 1, 3, b'foo', 2))

    def test_substruct(self):
        self.check('(y(ii)y)', [[1, [3,4], 2]], pack('BxxxxxxxiiB', 1, 3, 4, 2))




class TestArrayUnmarshal(TestUnmarshal):

    def test_byte(self):
        self.check('ay', [[1,2,3,4]], pack('iBBBB', 4, 1,2,3,4))

    def test_string(self):
        self.check('as', [['x', 'foo']], pack('ii2sxxi4s', 16, 1, b'x', 3, b'foo'))

    def test_struct(self):
        self.check('a(ii)', [[[1,2],[3,4]]], pack('ixxxxiiii', 16, 1,2,3,4))

    def test_struct_padding(self):
        self.check('a(yy)', [[[1,2],[3,4]]], pack('ixxxxBBxxxxxxBB', 10, 1,2,3,4))

    def test_dict(self):
        self.check('a{yy}', [{1:2, 3:4}], pack('ixxxxBBxxxxxxBB', 10, 1,2,3,4))

    def test_dict_strings(self):
        self.check('a{ss}',
                   [{'foo':'bar', 'x':'y'}],
                   pack('ixxxxi4si4si2sxxi2s', 30, 3, b'foo', 3, b'bar', 1, b'x', 1, b'y'))

    def test_bad_length(self):
        self.assertRaises(m.MarshallingError, self.check, 'a(ii)', [[[1,2],[3,4]]], pack('ixxxxiiii', 15, 1,2,3,4))
    
                
class TestVariantUnmarshal(TestUnmarshal):

    def test_byte(self):
        self.check('v', [1], pack('B2si', 1, b'i', 1))

    def test_struct(self):
        self.check('v', [[1,2]], pack('B5sxxii', 4, b'(ii)', 1,2))

        

if __name__ == '__main__':
    unittest.main()

########NEW FILE########
__FILENAME__ = test_message
import os
import unittest

from gruvi.txdbus import error, message

class MessageTester(unittest.TestCase):
    def test_too_long(self):
        class E(message.ErrorMessage):
            _maxMsgLen         = 1

        def c():
            E('foo.bar', 5)

        self.assertRaises(error.MarshallingError, c)

    def test_reserved_path(self):
        def c():
            message.MethodCallMessage('/org/freedesktop/DBus/Local', 'foo')
        self.assertRaises(error.MarshallingError, c)

    def test_invalid_message_type(self):
        class E(message.ErrorMessage):
            _messageType=99
        try:
            message.parseMessage(E('foo.bar', 5).rawMessage)
            self.assertTrue(False)
        except Exception as e:
            self.assertEquals(str(e), 'Unknown Message Type: 99')
        
    

########NEW FILE########
