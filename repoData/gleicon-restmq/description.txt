Monitoring job producer/consumer using restmq
Author: Eduardo S. Scarpellini, <scarpellini@gmail.com>
Date: 23/12/2009

Depends on statgrab and python-statgrab to collect system information. 
The dummyfunc packages can be easily converted to feed Cacti and check agains stored thresholds to generate alarms.

Open restmq-client.py, configure RESTMQ_HOST and _PORT, and run (no need to be root):

$ python restmq-client.py 

In another terminal/machine, configure and run the consumer:

$ python qconsumer.py



Node.js proxy for restmq
Useful for deploying restmq's websocket endpoint, as of now nginx and other webservers do not offer proxies for it.
http://gist.github.com/488873
older node.js versions: http://gist.github.com/488845


collectd REST Endpoint
======================

Now RestMQ has a collectd rest endpoint to receive and queue messages from collectd and collectd_web
There is an example at examples/test_collectd.py.
Run with: collectd_restmq_server

This is an specialization of RestMQ, that shows how flexible and easy the internals are. The main daemon is not restmq/web.py but restmq/collectd.py, which is using core and dispatch from RestMQ to implement only the necessary frontend using cyclone.

The collectd entrypoint does a vaery simple and basic validation of the data send by the collectd daemon.

* collectd Configuration:

** Data collection:

	RestMQ collectd entrypoint will decide which format to parse based on the 'Content-type' sent by the client.

	* Plain Text

	Use the write_http(http://collectd.org/documentation/manpages/collectd.conf.5.shtml#plugin_write_http) bundled with collectd to pass
	data to the RestMQ server using the Plain Text Protocol (http://collectd.org/wiki/index.php/Plain_text_protocol), RestMQ will
	generated a JSON with the data to be inserted on the RestMQ Queue:

	collectd.conf:
	...
	<Plugin write_http>
	        <URL "http://<collectd_restmq_server>/collectd/data">
	               Format Command
	#               User "collectd"
	#               Password "weCh3ik0"
	        </URL>
	</Plugin>

	Example JSON inserted in the RestMQ:

	[{"host": "collectd_restmq_server", "type_instance": "df-boot", "plugin_instance": "df", "value": "1288548767:116497408.000000:391246848.000000", "interval": "10"}]

	* JSON Generated by collectd

	Use the write_http(http://collectd.org/documentation/manpages/collectd.conf.5.shtml#plugin_write_http) bundled with collectd to pass
	data to the RestMQ server using the the JSON generated by collectd, the collectd endpoint just insert the data in the RestMQ Queue:

	collectd.conf:
	...
	<Plugin write_http>
	        <URL "http://<collectd_restmq_server>/collectd/data">
	               Format JSON
	#               User "collectd"
	#               Password "yerpass"
	        </URL>
	</Plugin>

	Example JSON inserted in the RestMQ:

	[{"values":[1.16497e+08,3.91247e+08],"time":1288625884,"interval":10,"host":"collectd_restmq_server","plugin":"df","plugin_instance":"","type":"df","type_instance":"boot"}]

** Event collection:

	Since the write_http is not yet used for events, you need to create a simple script using CURL to send events to the RestMQ server
	using the Plain Text Protocol (http://collectd.org/wiki/index.php/Plain_text_protocol):

	collectd.conf:
	...
	<Plugin exec>
	#       Exec "user:group" "/path/to/exec"
	        NotificationExec "rgaiser:rgaiser" "/home/rgaiser/event.sh"
	</Plugin>


	event.sh:
	#!/bin/bash

	EVENT=`cat`
	/usr/bin/curl -X POST -d "$EVENT" http://<collectd_restmq_server>/collectd/event

	Example JSON inserted in the RestMQ:

	[{"severity": "WARNING"}, {"time": "1288548727"}, {"host": "collectd_restmq_server"}, {"plugin": "df"}, {"type": "df"}, {"typeinstance": "boot"}, {"datasource": "used"}, {"currentvalue": "1.164974e+08"}, {"warningmin": "nan"}, {"warningmax": "1.000000e+01"}, {"failuremin": "nan"}, {"failuremax": "nan"}, {"event_text": "Host collectd_restmq_server, plugin df type df (instance boot): Data source \\"used\\" is currently 116497408.000000. That is above the warning threshold of 10.000000%."}]

* RestMQ Example

Use the examples/test_collectd.py to get the data from the RestMQ using the Comet consumer.

Author: Roberto Gaiser (http://github.com/rgaiser)

nginx sample config:

server {
    listen   80;
    server_name  your.server.name1 your.server.name2;

    access_log  /var/log/nginx/restmq.access.log;

    location / {
        proxy_pass                  http://127.0.0.1:8888;
        proxy_redirect              off;

        proxy_set_header            Host            $host;
        proxy_set_header            X-Real-IP       $remote_addr;
        proxy_set_header            X-Forwarded-For $proxy_add_x_forwarded_for;

        client_max_body_size        128k;
        client_body_buffer_size     128k;

        proxy_connect_timeout       30;
        proxy_send_timeout          30;
        proxy_read_timeout          30;

        proxy_buffer_size           4k;
        proxy_buffers               4 32k;
        proxy_busy_buffers_size     64k;
        proxy_temp_file_write_size  64k;
    }
}

JSON protocol
For operations using the JSON protocol, a post mus be issued to http://server/queue .
There is a simple html form when you issue a GET /queue. 
This is a simple protocol for queue manipulation, based on my first prototype at http://jsonqueue.appspot.com.


Queue add example:
{
	"cmd":"add", 
	"queue":"test", 
	"value":"oi"
}
- Adds an element to a given queue. If the queue doesn't exists, create it. 

Queue get example:
{
	"cmd":"get", 
	"queue":"test"
}
- Just get the next element from the queue. It increments a reference counter.

Queue del example:
{
	"cmd":"del", 
	"queue":"test", 
	"key":"test:31"
}
- Deletes an element from the queue. Use the key which comes with get

Queue take example:
{
	"cmd":"take", 
	"queue":"test" 
}
- Get and Delete the latest element from the queue.


supported queue policies are:
 1. broadcast - the default behavior of every queue
 2. roundrobin - great for distributing the content of a queue

consider the following:

 1. a producer starts adding content to a queue, let's say "test"
 2. four consumers keep continuously fetching data from the queue
    "test" through the comet api

if the queue policy is "broadcast", each consumer will get exactly
the same result as they are added to the queue.

however, when the policy is set to "roundrobin", the contents added
to that queue will be distributed over the N comet consumers, in a 
round robin fashion.

cute, isn't it?

EXAMPLE:

open two or three terminals and run the following command to start
fetching data from the queue test:

$ curl -D - http://localhost:8888/c/test

on yet another terminal, set the queue policy to "roundrobin":

$ curl -D - -X POST -d "policy=roundrobin" http://localhost:8888/p/test

if you want to make sure what policy is set, use GET:

$ curl http://localhost:8888/p/test

now, add some content into that queue:

for x in {1..1000}; do curl -X POST -d "queue=test&value=foobar" http://localhost:8888/; done

that's it. :)

RestMQ is a queue broker which presents different ways to access its data.
It is based on Redis, python, twisted and the cyclone webserver/framework.
Most of its features were drawn around Redis, which can deal with different types of data.


There goes an sketch of the basic queue algorithm:

The most important method is queue_add:
    Given a queue named QUEUE
    INCR a key named QUEUE:UUID 
    This UUID then is used to create a key QUEUE:UUID
    Check if this queue name is alread in the QUEUESET set. If not, add it. For now it just checks if 
        its the first time the name is used.
    SET QUEUE:UUID with the data
    PUSH QUEUE:UUID in the list QUEUE:queue.

All these data structures are accounted to give how many and which queue exists in the system, ensure that they keys 
wont repeat and that there is an order in which they are retrieved.

GET will just POP a value from QUEUE:queue and GET the value under this key.

Check engine.py for all the logic and examples.

There are a few http routes:

 /q/queuename - entry for a simple REST queue manipulation. POST inserts, GET removes and returns, DELETE disconnects all comet consumers and purgue queue
 /queue - entry point for the JSON protocol (see PROTOCOL). Point your browser to this location for some examples
 /c/queuename - entry point for a experimental COMET light consumer.
 /p/queuename - entry point for queue policy management - see README.qp for details
 /stats/[queuename] - misc statuses and queue list - if queuename is given, shows len and status (paused|started)
 /j/queuename - basic job checking, for those implementing job schedulers. Point your browser here to check data about a queue
 /control/queuename - start/stop consumers (as in pausing them)

The CometQueueHandler is a permanent consumer for objects in a queue.
It must only feed new objects to a permanent http connection. Deletion is not handled here for now.
As each queue object has its own key, it can be done thru /queue interface. 
It also can be changed for a hard consumer, just commenting out the softget inside the method.

There is a Map/Reduce example under /examples which shows implements the cannonical wordcount and wordfreq examples.

The policy management allows for broadcast or roundrobin data distribution between comet subscribers (the consumers using comet route only). see REAME.qp


RestMQ based syslogd daemon - Experimental protocol adapter for receiveing high volume syslog messages

- TCP only
- each posting host has a queue named syslogd:<ip>
- run it in a standalone restmq, for N servers
- consume your results of a restmq instance bound to the same redis database
- default port 25000
- performs lookup of severity and facility


Use syslogd_restmq_server to run the frontend. 

Bind on /c/syslogd:<hostname> for receiving thru the comet endpoint:

- curl http://localhost:8888/c/syslogd:127.0.0.1


Gleicon - 2010

Now that cyclone has websockets support, there is a read-only websocket interface for RestMQ.
Initially it will echoes back any message send to it, and will provide the latest messages to it too.

The url format is http://restmqserver:port/ws/<queuename>

Example: http://localhost:8888/ws/test

To test it, copy contrib/interact.html to your webserver, configure it if necessary (just change websocket url or queue name if you need).
Open it in your browser and execute in console:

python restmq_engine.py -p oi

or

curl -X POST -d "queue=test&value=foobar" http://localhost:8888/q/test



Instant ghetto Map/Reduce with RestMQ


Download a huge text file. E.G: The Bible: http://www.gutenberg.org/dirs/etext90/kjv10.txt or Best Russian Short Stories: http://www.gutenberg.org/files/13437/13437-8.txt

Split it:
    $ mkdir files
    $ split -l 1000 yourebook.txt files/bookfrag-

In another window, run a consumer:

    $ python reduce.py

Now, run the producer:
    $ for a in `ls files`; do python map.py files/$a; done

The producing phase is very quick, depending almost on python's parsing speed. The consuming phase still running at the top speed which the internal task loop runs, but it's being worked on.

To test the word frequence example, just run reduce_keyfreq.py map_keyfreq.py instead of map.py/reduce.py.


======
RESTMQ
======

Redis based message queue.
--------------------------

:Info: See `RestMQ website <http://restmq.com>`_
:Info: See `my blog <http://blog.7co.cc>` for more information.
:Author: `Gleicon Moraes <http://github.com/gleicon>`
:Author: `Alexandre Fiori <http://github.com/fiorix/>`_


About
=====

RestMQ is a message queue which uses HTTP as transport, JSON to format a minimalist protocol and is organized as REST 
resources. It stands on the shoulder of giants, built over Python, Twisted, `Cyclone <http://github.com/fiorix/cyclone>`_ (a Tornado implementation over twisted) and Redis.

Redis is more than just a key/value db, and its data types provided support for this project.

Queues are created on the fly, when a message is sent to them. They are simple to use as a curl request can be. HTTP Comet, websockets and server sent events may be used for data streaming.

This release is a cleanup of the original code, that can also be found on github.

Install
=======

$ python setup.py install
run with bash start_scripts/restmq_server or taylor your own script. Note that currently restmq is presented as a twisted plugin. 

Queue Policy
============

Every queue is created with a default policy, which is `broadcast`. It means that each message
pushed to a queue will be forwarded to all comet and websocket consumers.

The alternative policy is `roundrobin`, which will distribute these messages in a round robin 
fashion to all comet and websocket consumers.

The queue policy won't affect regular GET commands to pop a single message from a queue.

See `README.qp <http://github.com/gleicon/restmq/blob/master/README.qp>`_ for details.


Queue Flow Control
==================

Yes, it does support start and stop. We just need to document it properly.


Example
========
A http client (curl) post to /queue:

Point your browser to http://localhost:8888/c/test

Run $ curl -d "queue=test&value=foobar" http://localhost:8888/ 

Your browser is acting as a consumer to the queue. Using json encoded data it's easy to fit the data into a js based app.

Aside from the COMET consumer, there are xmlrpc methods, rest routes and the JSON protocol to manipulate queue items.


COMET consumer
==============

There is a COMET based consumer, which will bind even if the queue doesn't already exists. 

The main route is thru /c/<queuename>. It can be tested using curl:

$ curl http://localhost:8888/c/test

In another terminal, run $ curl -d "value=foobar" http://localhost:8888/q/test 

This is the basic usage pattern for map/reduce (see examples).

See below on how to purge and disconnect all consumers from a queue, using DELETE.


WebSocket consumer
==================

Now that cyclone has websockets support, check README.websocket to test it. 

If you are using a browser or library which already supports websockets, you may take advantage of this interface.


REST services
=============

A queue can be accessed as /q/<queuename>.

GET requests will dequeue an object.

POST requests inserts an object in the queue

DELETE requests will purgue the queue.

The usual pattern is listen in the COMET consumer (/c/<queuename>) and insert new stuff at the REST route (POST /q/<queuename).


JSON Protocol
=============

The HTTP route /queue/<queuename> uses the JSON protocol. Its the same protocol I've implemented for http://jsonqueue.appspot.com.

::

    {
        "cmd": "add",
        "queue": "genesis",
        "value": "abacab"
    }

Creates the queue named *"genesis"* and inserts the string *"abacab"* as the message.

If we want to take that out of the queue, the payload would be like that:

::

    {
        "cmd": "take",
        "queue": "genesis"
    }


The message can be formatted as a json object, so more complex data can be sent.
It really mimics some of `Amazon SQS <http://aws.amazon.com/sqs/>`_ workings, because it's a simple queue.

For the first release it has:

- Select, EPoll or KQueue concurrency (depends on twisted)
- Persistent storage using Redis
- Can work on pools, N daemons consuming from the same queues.
- Small codebase
- Lightweight
- Cute ?


Dependencies
============
- `cyclone <http://github.com/fiorix/cyclone>`_: 
  git clone git://github.com/fiorix/cyclone.git 


Running
=======

The `redis_server <http://github.com/gleicon/restmq/blob/master/restmq_server>`_ script will start the service. It's a bash script used to both configure and run RestMQ. The default version of the wrapper script will run the server in foreground, and log messages will be written to the standard output.

Editing the script is mandatory for configuring RestMQ for production.

::

    $ ./restmq_server --help
    Usage: twistd [options] restmq [options]
    Options:
          --acl=         acl configuration file for endpoints [default: acl.conf]
          --redis-host=  hostname or ip address of the redis server [default: 127.0.0.1]
          --redis-port=  port number of the redis server [default: 6379]
          --redis-pool=  connection pool size [default: 10]
          --port=        port number to listen on [default: 8888]
          --listen=      interface to listen on [default: 127.0.0.1]
          --version      
          --help         Display this help and exit.


Tests
=====

::

    examples/test_rest.sh
    examples/test_xmlrpc.py
    python examples/test_comet.py
    python examples/twitter_trends.py
    python examples/test_comet_curl.py  
    python restmq_engine.py -h


Files
=====

If you're a developer looking for extending RestMQ's functionality, have a look at these files:

- `restmq/web.py <http://github.com/gleicon/restmq/blob/master/restmq/web.py>`_: the web service code
- `restmq/core.py <http://github.com/gleicon/restmq/blob/master/restmq/core.py>`_: redis/queue operations logic
- `restmq/dispatch.py <http://github.com/gleicon/restmq/blob/master/restmq/dispatch.py>`_: a simple command dispatcher
- `restmq_engine.py <http://github.com/gleicon/restmq/blob/master/restmq_engine.py>`_: the redis abstraction layer to the queue algorithm (command line tool)


Credits
=======
Thanks to (in no particular order):

- Salvatore Sanfilippo for redis and for NoSQL patterns discussion.
- Alexandre Fiori for the redis client enhancement and patches.
- Roberto Gaiser for the collectd daemon
- <put your name here if you happen to send a patch> 

misc performance tests.
TODO: dtrace probes.



