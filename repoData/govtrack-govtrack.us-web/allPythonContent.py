__FILENAME__ = missed_votes
#!script

# Compute missed votes % for Members of Congress and summary
# statistics by chamber.

# To update from scratch:
# for c in {1..112}; do echo $c; python missed_votes.py $c; done

import csv, datetime, glob, os, re, sys
import lxml.etree as lxml
from scipy.stats import percentileofscore, scoreatpercentile

congress = int(sys.argv[1])
datadir = "data/us/%d/" % congress

# UTILS

def parse_datetime(value):
	try:
		return datetime.datetime.strptime(value, '%Y-%m-%d').date()
	except ValueError:
		try:
			return datetime.datetime.strptime(value, '%Y-%m-%dT%H:%M:%S-05:00').date()
		except ValueError:
			return datetime.datetime.strptime(value, '%Y-%m-%dT%H:%M:%S-04:00').date()

# BEGIN

# prepare output data directories
os.system("mkdir -p " + datadir + "stats/person/missedvotes")

# load in the session dates so we know how to break them down into smaller time periods
session_dates = { }
for rec in csv.DictReader(open("../data/us/sessions.tsv"), delimiter="\t"):
	session_dates[(int(rec['congress']), rec['session'])] = (parse_datetime(rec['start']), parse_datetime(rec['end']))

def date_to_month_index(date):
	return date.year*12 + (date.month-1)
	
def get_date_bin(congress, session, date):
	# Bin the dates roughly in three-month periods, but align the bins to sessions of Congress *and* to months.
	d1, d2 = session_dates[(congress, session)]
	if date < d1 or date > d2: raise ValueError("Date out of range!")
	d = date_to_month_index(d2) - date_to_month_index(d1)
	n_periods = d / 3
	if n_periods < 2: return 0
	dp = d / n_periods
	return int((date_to_month_index(date) - date_to_month_index(d1)) / dp)

# GLOB

session_bin_dates = { }
vote_counts = { }
voters_by_chamber = { "h": set(), "s": set() }
person_lifetime_vote_dates = { }
for fn in glob.glob(datadir + "rolls/*.xml"):
	m = re.search(r"/([hs])([^/]+)-\d+.xml$", fn)
	where, session = m.groups()
	
	dom = lxml.parse(fn).getroot()
	date = parse_datetime(dom.get("datetime"))
	bin = (congress, session, where, get_date_bin(congress, session, date))
	
	if not bin in session_bin_dates:
		session_bin_dates[bin] = (date, date)
	else:
		session_bin_dates[bin] = (min(session_bin_dates[bin][0], date), max(session_bin_dates[bin][1], date))
		
	for voter in dom.xpath("voter[@id]"):
		id = int(voter.get("id"))
		if id == "0": raise ValueError()
		ctr = vote_counts.setdefault(id, {}).setdefault(bin, { "total": 0, "missed": 0 })
		ctr['total'] += 1
		if voter.get("vote") == "0": ctr['missed'] += 1
		
		voters_by_chamber[where].add(id)
		
		if not (where, id) in person_lifetime_vote_dates:
			person_lifetime_vote_dates[(where, id)] = (date, date)
		else:
			person_lifetime_vote_dates[(where, id)] = (min(person_lifetime_vote_dates[(where, id)][0], date), max(person_lifetime_vote_dates[(where, id)][1], date))
		
# Stop-gap measure for start of Congress when no votes have occurred in one chamber or the other.
# Get a complete list of Members via the GovTrack API. We need to know who so we bring forward
# any historical data.
if len(voters_by_chamber['h']) == 0 or len(voters_by_chamber['s']) == 0:
	import json, urllib
	voters_by_chamber = { "h": set(), "s": set() }
	for m in json.load(urllib.urlopen("http://www.govtrack.us/api/v1/person/?roles__current=true&limit=600"))["objects"]:
		c = "s" if (m["current_role"]["role_type"] == "senator") else "h"
		voters_by_chamber[c].add( int(m["id"]) ) 
	
if len(voters_by_chamber['h']) == 0 or len(voters_by_chamber['s']) == 0:
	print "missed_votes: There are no voters in one of the chambers. Which means we don't know who is currently serving...."
	sys.exit(0)

# For each Member of Congress, search for the most recent Congress that has their
# statistics, since they might have been in an earlier Congress than the previous,
# and load in the statistics from their stats file, which includes all historical data to
# that point. Also update the person's lifetime vote dates.
for p in voters_by_chamber['h'] | voters_by_chamber['s']:
	for cc in range(congress-1, 0, -1):
		fn = "../data/us/%d/stats/person/missedvotes/%d.csv" % (cc, p)
		if os.path.exists(fn):
			for rec in csv.DictReader(open(fn)):
				# currently serving but has not voted in this chamber in this Congress yet
				if p not in vote_counts: vote_counts[p] = { }
				
				if rec["congress"] == "lifetime":
					# carry forward the whole record. if the member is not currently serving in the chamber,
					# we will not recompute the lifetime total, but we will output it in their individual stats file.
					bin = ('lifetime', rec["chamber"])
					vote_counts[p][bin] = {
						"total": int(rec["total_votes"]),
						"missed": int(rec["missed_votes"]),
						"percent": float(rec["percent"]),
						"percentile": float(rec["percentile"]),
						"pctile25": float(rec["pctile25"]),
						"pctile50": float(rec["pctile50"]),
						"pctile75": float(rec["pctile75"]),
						"pctile90": float(rec["pctile90"]),
						}

					# update the lifetime votes date range
					if (rec["chamber"], p) not in person_lifetime_vote_dates:
						# person served in a different chamber than what he serves in the current congress
						person_lifetime_vote_dates[(rec["chamber"], p)] = (parse_datetime(rec["period_start"]), parse_datetime(rec["period_end"]))
					else:
						person_lifetime_vote_dates[(rec["chamber"], p)] = (min(person_lifetime_vote_dates[(rec["chamber"], p)][0], parse_datetime(rec["period_start"])), max(person_lifetime_vote_dates[(rec["chamber"], p)][1], parse_datetime(rec["period_end"])))
				else:
					bin = (int(rec["congress"]), rec["session"], rec["chamber"], rec["period"])
					session_bin_dates[bin] = (parse_datetime(rec["period_start"]), parse_datetime(rec["period_end"]))
					vote_counts[p][bin] = { "total": int(rec["total_votes"]), "missed": int(rec["missed_votes"]) }
			break # don't look at previous congresses, we have their house and senate records both here

# Compute lifetime missed vote totals by chamber for currently serving members in that chamber.
for where in ('h', 's'):
	for p in voters_by_chamber[where]:
		# currently serving but has not voted in this chamber in this Congress yet
		if p not in vote_counts: vote_counts[p] = { }
			
		vote_counts[p][('lifetime', where)] = {
			"total": sum(bv["total"] for bk, bv in vote_counts[p].items() if bk[0] != "lifetime" and bk[2] == where),
			"missed": sum(bv["missed"] for bk, bv in vote_counts[p].items() if bk[0] != "lifetime" and bk[2] == where),
		}
		if vote_counts[p][('lifetime', where)]['total'] == 0:
			del vote_counts[p][('lifetime', where)]
		
# Compute medians and percentiles.
for bin in [("lifetime", "s"), ("lifetime", "h")] + sorted(session_bin_dates):
	if bin[0] != "lifetime":
		# Get Members of Congress that were present in the bin.
		plist = [p for p in vote_counts if bin in vote_counts[p]]
	else:
		# Get Members of Congress that were present in the chamber this congress.
		# Other Members in Congress this congress may have previously served in this chamber and
		# will have a lifetime record, but we don't want them influencing the current percentiles and
		# we don't want them to appear in output.
		#
		# Filter out individuals who haven't voted yet. They get included if
		# there is no vote in a chamber and we pull the ID list from GovTrack.
		plist = list(voters_by_chamber[bin[1]])
	
	# Compute their % missed votes and store in a flat list.
	values = []
	for p in plist:
		if bin not in vote_counts[p]: continue # when doing lifetime stats, is a member currently serving but has not voted
		binctr = vote_counts[p][bin]
		binctr['percent'] = float(binctr['missed']) / float(binctr['total']) * 100.0
		values.append(binctr['percent'])
		
	# Has there been any votes in the chamber in this period? Only
	# really happens at the start of a Congress. One chamber may
	# not have voted yet.
	if len(values) == 0:
		print "No data for", bin
		continue
		
	# For each of them, store the percentile and the (bin-wide) median.
	bin_percentiles = { "pctile25": scoreatpercentile(values, 25), "pctile50": scoreatpercentile(values, 50), "pctile75": scoreatpercentile(values, 75), "pctile90": scoreatpercentile(values, 90) }
	for p in plist:
		if bin not in vote_counts[p]: continue # when doing lifetime stats, is a member currently serving but has not voted
		binctr = vote_counts[p][bin]
		binctr['percentile'] = percentileofscore(values, binctr['percent'], kind='strict')
		binctr.update(bin_percentiles)
		
	if bin[0] == "lifetime":
		# Write out the lifetime statistics in a main file sorted by percentile.
		# (The user can compute his own median here.)
		
		# filter out MoCs that are currently serving but have not voted yet
		plist = [p for p in plist if bin in vote_counts[p]]
		
		plist.sort(key = lambda p : -vote_counts[p][bin]['percentile'])
		w = csv.writer(open(datadir + "stats/missedvotes_%s.csv" % bin[1], "w"))
		w.writerow(["id", "total_votes", "missed_votes", "percent", "percentile", "first_vote_date", "last_vote_date"])
		for p in plist:
			# when doing lifetime stats, is a member currently serving but has not voted, so omit from stats
			# since it might indicate we included that person in medians, but we didn't.
			v = vote_counts[p][bin]
			w.writerow([p, v['total'], v['missed'], v['percent'], v['percentile'], person_lifetime_vote_dates[(bin[1], p)][0].isoformat(), person_lifetime_vote_dates[(bin[1], p)][1].isoformat()])
		
# Write out statistics by Member of Congress. Although we're only writing out currently serving MoCs,
# include their lifetime records for both the house and senate.
for p in vote_counts:
	w = csv.writer(open(datadir + "stats/person/missedvotes/%d.csv" % p, "w"))
	# columns are tied to how we load in historical data above
	w.writerow(["congress", "session", "chamber", "period", "total_votes", "missed_votes", "percent", "percentile", "period_start", "period_end", "pctile25", "pctile50", "pctile75", "pctile90"])
	for bin in sorted(vote_counts[p]):
		v = vote_counts[p][bin]
		if bin[0] == "lifetime":
			dates = person_lifetime_vote_dates[(bin[1], p)]
		else:
			dates = session_bin_dates[bin]
		if len(bin) == 2: bin = [bin[0], None, bin[1], None]
		w.writerow(list(bin) + [v['total'], v['missed'], v['percent'], v['percentile'], dates[0].isoformat(), dates[1].isoformat(), v['pctile25'], v['pctile50'], v['pctile75'], v['pctile90']])
		

########NEW FILE########
__FILENAME__ = productivity
#!script

from datetime import datetime
import csv, sys

from django.db.models import Count

from us import get_congress_dates
from settings import CURRENT_CONGRESS

from bill.models import Bill, BillStatus
from bill.billtext import load_bill_text
from vote.models import Vote, CongressChamber
from person.models import PersonRole, RoleType

party_control = { }
for row in csv.reader(open("analysis/party_control.tsv"), delimiter='\t'):
	if row[0].startswith("#") or row[0] == 'Congress': continue
	party_control[int(row[0])] = (row[3], row[9], row[15]) # senate, house, presidency

W = csv.writer(sys.stdout)

def compute_productivity(congress, days_in):
	corresponding_day = get_congress_dates(congress)[0] + days_in

	# laws

	enacted_bills = list(Bill.objects.filter(
		congress=congress,
		current_status__in=BillStatus.final_status_passed_bill,
		current_status_date__lte=corresponding_day))
	enacted_bills_count = len(enacted_bills)

	enacted_bill_pages = 0
	enacted_bill_pages_missing = 0
	for b in enacted_bills:
		pp = load_bill_text(b, None, mods_only=True).get("numpages")
		if pp is None:
			enacted_bill_pages_missing += 1
			continue
		pp = int(pp.replace(" pages", ""))
		enacted_bill_pages += pp
	if congress < 103: enacted_bill_pages = "(no data)"

	# votes

	house_votes = Vote.objects.filter(
		congress=congress,
		created__lte=corresponding_day,
		chamber=CongressChamber.house).count()
	senate_votes = Vote.objects.filter(
		congress=congress,
		created__lte=corresponding_day,
		chamber=CongressChamber.senate).count()

	# power

	congress_same_party = party_control[congress][0] == party_control[congress][1]
	branches_same_party = (party_control[congress][0] == party_control[congress][1]) and (party_control[congress][0] == party_control[congress][2])

	#

	timespan = "%d (%d-%d)" % (congress, get_congress_dates(congress)[0].year, get_congress_dates(congress)[1].year-1)
	row = [timespan, enacted_bills_count, enacted_bill_pages, house_votes, senate_votes, "Yes" if congress_same_party else "No", "Yes" if branches_same_party else "No"]
	#W.writerow(row)
	print("<tr>%s</tr>" % "".join( "<td>%s</td> " % td for td in row) )


days_in = (datetime.now().date() - get_congress_dates(CURRENT_CONGRESS)[0])
print("We are %d days into the %d Congress" % (days_in.days, CURRENT_CONGRESS))

for c in range(93, 113+1):
	compute_productivity(c, days_in)

########NEW FILE########
__FILENAME__ = session_stats
#!script

# Compute a year-end report for Members of Congress.
#
# Generate a bunch of statistics for each Member and then
# rank the results across subsets of Members to contextualize
# the information.

import sys, json, re

import us
import datetime # implicitly used in eval()'ing dates inside major_actions

from person.models import Person, PersonRole, RoleType
from bill.models import Cosponsor, Bill, BillStatus, RelatedBill, BillType
from vote.models import Vote, Voter, CongressChamber
from committee.models import CommitteeMemberRole

competitive_seats = None

def get_cohorts(person, role, congress, session, committee_membership):
	cohorts = []

	# chamber
	chamber = RoleType.by_value(role.role_type).congress_chamber.lower()
	cohorts.append({ "key": chamber })

	# party
	cohorts.append({ "key": "party-%s-%s" % (chamber, role.party.lower()), "chamber": chamber, "party": role.party })

	# state delegation
	if role.role_type == RoleType.representative:
		cohorts.append({ "key": "house-state-delegation-" + role.state.lower(), "state": role.state })

	# chamber leadership position
	if role.leadership_title:
		cohorts.append({ "key": chamber + "-leadership", "position": role.leadership_title })

	# freshmen/sophomores
	min_start_date = None
	prev_congresses_served = set()
	# use enddate__lte=endate to include the current role itself since for
	# senators their current role may span previous congresses
	for r in PersonRole.objects.filter(person=person, role_type=role.role_type, enddate__lte=role.enddate):
		if not min_start_date or r.startdate < min_start_date: min_start_date = r.startdate
		for c in r.congress_numbers():
			if c < congress:
				prev_congresses_served.add(c)
	if len(prev_congresses_served) == 0: cohorts.append({ "key": chamber + "-freshmen", "chamber": chamber })
	if len(prev_congresses_served) == 1: cohorts.append({ "key": chamber + "-sophomores", "chamber": chamber })
	if min_start_date and (role.enddate - min_start_date).days > 365.25*10: cohorts.append({ "key": chamber + "-tenyears", "chamber": chamber, "first_date": min_start_date.isoformat()  })

	# committee leadership positions
	committee_positions = []
	for committee, committee_role in committee_membership.get(person.id, {}).items():
		if len(committee) != 4: continue # exclude subcommittees
		if committee_role in (CommitteeMemberRole.ranking_member, CommitteeMemberRole.vice_chairman, CommitteeMemberRole.chairman):
			committee_positions.append( (committee, committee_role) )
	if len(committee_positions) > 0:
		cohorts.append({ "key": chamber + "-committee-leaders", "chamber": chamber, "positions": committee_positions })

	# safe vs competitive seats
	if role.role_type == RoleType.representative:
		global competitive_seats
		if competitive_seats is None:
			competitive_seats = set()
			for line in open("analysis/cook_competitive_seats-%s.txt" % session):
				if line[0] == "#": continue
				(state, district) = line.split(" ")[0].split("-")
				competitive_seats.add( (state, int(district)) )
		if (role.state, role.district) in competitive_seats:
			cohorts.append({ "key": chamber + "-competitive-seat" })
		else:
			cohorts.append({ "key": chamber + "-safe-seat" })

	return cohorts


def get_vote_stats(person, role, stats, votes_this_year):
	# Missed vote % in the chamber that the Member is currently serving in.
	if role.leadership_title == "Speaker": return
	votes_elligible = Voter.objects.filter(person=person, vote__in=votes_this_year[role.role_type])
	votes_missed = votes_elligible.filter(option__key="0")
	v1 = votes_elligible.count()
	v2 = votes_missed.count()
	stats["missed-votes"] = {
		"value": 100.0*float(v2)/float(v1) if v1 > 0 else None,
		"elligible": v1,
		"missed": v2,
		"role": RoleType.by_value(role.role_type).key,
	}

def was_bill_enacted(b, startdate, enddate, recurse=True):
	# Our status code is currently tied to the assignment of a slip
	# law number, which isn't what we mean exactly.
	#
	# (Additionally, we should count a bill as enacted if any identified companion
	# bill is enacted.)

	# TODO: See new function in the Bill model.

	# If it *was* assigned a slip law number, which in the future might
	# be useful for veto overrides, then OK.
	if b.current_status in BillStatus.final_status_passed_bill and \
		startdate <= b.current_status_date <= enddate:
		return True

	# Otherwise, check the actions for a <signed> action.
	fn = "data/congress/%s/bills/%s/%s%d/data.json" % (
    	b.congress,
        BillType.by_value(b.bill_type).slug,
        BillType.by_value(b.bill_type).slug,
        b.number)
	bj = json.load(open(fn))
	for axn in bj["actions"]:
		if axn["type"] == "signed" and startdate.isoformat() <= axn["acted_at"] <= enddate.isoformat():
			return True

	# Otherwise check companion bills.
	#if recurse:
	#	for rb in RelatedBill.objects.filter(bill=b, relation="identical").select_related("related_bill"):
	#		if was_bill_enacted(rb.related_bill, startdate, enddate, recurse=False):
	#			return True
			
	return False

def get_sponsor_stats(person, role, stats, congress, startdate, enddate, committee_membership):
	# How many bills did the Member introduce during this time window?
	bills = Bill.objects.filter(sponsor=person, congress=congress,
		introduced_date__gte=startdate, introduced_date__lte=enddate)
	stats["bills-introduced"] = {
		"value": bills.count(),
	}

	# How many bills were enacted within this time window?
	#bills_enacted = bills.filter(current_status__in=BillStatus.final_status_passed_bill,
	#	current_status_date__gte=startdate, current_status_date__lte=enddate)
	bills_enacted = [b for b in bills if was_bill_enacted(b, startdate, enddate)]
	stats["bills-enacted"] = {
		"value": len(bills_enacted),
		"bills": make_bill_entries(bills_enacted),
	}

	bills = list(bills)
	was_reported = []
	has_cmte_leaders = []
	has_cosponsors_both_parties = 0
	has_companion = []
	for bill in bills:
		# In order to test these remaining factors, we have to look more closely
		# at the bill because we can only use activities that ocurred during the
		# time window so that if we re-run this script on the same window at a
		# later date nothing changes -- i.e. future activitiy on bills should
		# not affect 1st Session statistics.

		# Check if the bill was reported during this time period.
		for datestr, st, text, srcxml in bill.major_actions:
			date = eval(datestr)
			if isinstance(date, datetime.datetime): date = date.date()
			if date >= startdate and date <= enddate and st == BillStatus.reported:
				was_reported.append(bill)
				break # make sure not to double-count any bills in case of data errors

		# Check whether any cosponsors are on relevant committees.
		cosponsors = list(Cosponsor.objects.filter(bill=bill, joined__gte=startdate, joined__lte=enddate).select_related("person", "role"))
		x = False
		for committee in list(bill.committees.all()):
			for cosponsor in cosponsors:
				if committee_membership.get(cosponsor.person.id, {}).get(committee.code) in (CommitteeMemberRole.ranking_member, CommitteeMemberRole.vice_chairman, CommitteeMemberRole.chairman):
					x = True
		if x: has_cmte_leaders.append(bill)

		# Check whether there's a cosponsor from both parties.
		co_d = False
		co_r = False
		for cosponsor in cosponsors:
			if cosponsor.role.party == "Democrat": co_d = True
			if cosponsor.role.party == "Republican": co_r = True
		if co_d and co_r:
			has_cosponsors_both_parties += 1

        # Check if a companion bill was introduced during the time period.
		if RelatedBill.objects.filter(bill=bill, relation="identical", related_bill__introduced_date__gte=startdate, related_bill__introduced_date__lte=enddate).exists():
			has_companion.append(bill)


	stats["bills-reported"] = {
		"value": len(was_reported),
		"bills": make_bill_entries(was_reported),
	}

	stats["bills-with-committee-leaders"] = {
		"value": len(has_cmte_leaders),
		"bills": make_bill_entries(has_cmte_leaders),
	}

	if len(bills) > 10:
		stats["bills-with-cosponsors-both-parties"] = {
			"value": 100.0*float(has_cosponsors_both_parties)/float(len(bills)),
			"num_bills": len(bills),
		}

	stats["bills-with-companion"] = {
		"value": len(has_companion),
		"other_chamber": RoleType.by_value(role.role_type).congress_chamber_other,
		"bills": make_bill_entries(has_companion),
	}

def get_cosponsor_stats(person, role, stats, congress, startdate, enddate):
	# Count of cosponsors on the Member's bills with a join date in this session.
	cosponsors = Cosponsor.objects.filter(bill__sponsor=person, bill__congress=congress, joined__gte=startdate, joined__lte=enddate)
	stats["cosponsors"] = {
		"value": cosponsors.count(),
	}

def get_cosponsored_stats(person, role, stats, congress, startdate, enddate):
	# Count of bills this person cosponsored.
	cosponsored = Cosponsor.objects.filter(person=person, bill__congress=congress, joined__gte=startdate, joined__lte=enddate)
	stats["cosponsored"] = {
		"value": cosponsored.count(),
	}

	# Of those bills, how many sponsored by a member of the other party.
	if role.party in ("Democrat", "Republican") and cosponsored.count() > 10:
		cosponsored_bi = cosponsored.exclude(bill__sponsor_role__party=role.party)
		stats["cosponsored-other-party"] = {
			"value": 100.0 * float(cosponsored_bi.count()) / float(cosponsored.count()),
			"cosponsored": cosponsored.count(),
			"cosponsored_other_party": cosponsored_bi.count(),
		}


def run_sponsorship_analysis(people, congress, startdate, enddate):
	# Run our own ideology and leadership analysis. While the chart we show on
	# people pages looks over the last several years of activity, for the year-end
	# stats we just want to look at activity during this year. This puts freshmen
	# Members on a more equal footing.
	global sponsorship_analysis_data
	from analysis.sponsorship_analysis import *
	sponsorship_analysis_data = { }
	peoplemap, people_list = get_people([role for (person,role) in people])
	for chamber, role_type in (('h', RoleType.representative), ('s', RoleType.senator)):
		bills_start_date, bills_end_date, rep_to_row, nreps, P = build_matrix(
			congress, congress, chamber, peoplemap, people_list,
			filter_startdate=startdate.isoformat(), filter_enddate=enddate.isoformat())
		smooth_matrix(nreps, P)
		parties = build_party_list(rep_to_row, peoplemap, nreps)
		spectrum = ideology_analysis(nreps, parties, P)
		pagerank = leadership_analysis(nreps, P)
		for id, index in rep_to_row.items():
			sponsorship_analysis_data[ (role_type, id) ] = (spectrum[index], pagerank[index])

def get_sponsorship_analysis_stats(person, role, stats):
	global sponsorship_analysis_data
	s = sponsorship_analysis_data.get( (role.role_type, person.id) )
	stats["ideology"] = {
		"value": s[0] if s else None,
		"role": RoleType.by_value(role.role_type).key,
	}
	stats["leadership"] = {
		"value": s[1] if s else None,
		"role": RoleType.by_value(role.role_type).key,
	}

def get_committee_stats(person, role, stats, committee_membership):
	chair_list = [] # chair, vicechair, or ranking member
	subchair_list = []
	for committee, role_type in committee_membership.get(person.id, {}).items():
		if role_type not in (CommitteeMemberRole.ranking_member, CommitteeMemberRole.vice_chairman, CommitteeMemberRole.chairman):
			continue
		if len(committee) == 4:
			# full committee
			chair_list.append( (committee, role_type) )
		else:
			subchair_list.append( (committee, role_type) )

	stats["committee-positions"] = {
		"value": 5*len(chair_list) + len(subchair_list),
		"committees": chair_list,
		"subcommittees": subchair_list,
	}

transparency_bills = None
def get_transparency_stats(person, role, stats, congress, startdate, enddate):
	global transparency_bills
	if not transparency_bills:
		transparency_bills = []
		for line in open("analysis/transparency-bills.txt"):
			bill = Bill.from_congressproject_id(re.split("\s", line)[0])
			transparency_bills.append(bill)

	# which bills are in the right chamber?
	plausible_bills = []
	for bill in transparency_bills:
		if BillType.by_value(bill.bill_type).chamber == RoleType.by_value(role.role_type).congress_chamber:
			plausible_bills.append(bill)

	# did person sponsor any of these within this session?
	sponsored = []
	for bill in transparency_bills:
		if startdate <= bill.introduced_date <= enddate and bill.sponsor == person:
			sponsored.append(bill)

	# did person cosponsor any of these within this session?
	cosponsored = []
	for cosp in Cosponsor.objects.filter(person=person, bill__in=transparency_bills, joined__gte=startdate, joined__lte=enddate):
		cosponsored.append(cosp.bill)

	stats["transparency-bills"] = {
		"value": len(sponsored)*3 + len(cosponsored),
		"sponsored": make_bill_entries(sponsored),
		"cosponsored": make_bill_entries(cosponsored),
		"num_bills": len(plausible_bills),
		"chamber": RoleType.by_value(role.role_type).congress_chamber,
	}

def make_bill_entries(bills):
	return [make_bill_entry(b) for b in bills]
def make_bill_entry(bill):
	return (unicode(bill), bill.get_absolute_url())

def collect_stats(session):
	# Get the congress and start/end dates of the session that this corresponds to.
	for congress, s, startdate, enddate in us.get_all_sessions():
		if s == session:
			break
	else:
		raise ValueError("Invalid session: " + session)

	# Who was serving on the last day of the session?
	people = [(r.person, r) for r in PersonRole.objects
		.filter(
			role_type__in=(RoleType.representative, RoleType.senator),
			startdate__lt=enddate, # use __lt and not __lte in case of multiple roles on the same day
			enddate__gte=enddate, # use __lte in case anyone's term ended exactly on this day
			)
		.select_related("person")]

	# Do a sponsorship analysis for bills in this session only.
	run_sponsorship_analysis(people, congress, startdate, enddate)

	# Get the committee members.
	from bill.prognosis import load_committee_membership
	committee_membership = load_committee_membership(congress)

	# Pre-fetch all of the votes in this session.
	votes_this_year = Vote.objects.filter(congress=congress, session=session)
	votes_this_year = {
		RoleType.representative: set(votes_this_year.filter(chamber=CongressChamber.house).values_list("id", flat=True)),
		RoleType.senator: set(votes_this_year.filter(chamber=CongressChamber.senate).values_list("id", flat=True)),
	}


	# Generate raw statistics.
	AllStats = { }
	for person, role in people:
		AllStats[person.id] = {
			"id": person.id,

			"role_id": role.id,
			"role_type": role.role_type,
			"role_start": role.startdate.isoformat(),
			"role_end": role.enddate.isoformat(),

			"stats": { },
			"cohorts": get_cohorts(person, role, congress, session, committee_membership),
		}

		stats = AllStats[person.id]["stats"]
		get_vote_stats(person, role, stats, votes_this_year)
		get_sponsor_stats(person, role, stats, congress, startdate, enddate, committee_membership)
		get_cosponsor_stats(person, role, stats, congress, startdate, enddate)
		get_cosponsored_stats(person, role, stats, congress, startdate, enddate)
		get_sponsorship_analysis_stats(person, role, stats)
		get_committee_stats(person, role, stats, committee_membership)
		get_transparency_stats(person, role, stats, congress, startdate, enddate)

	return AllStats

def contextualize(stats):
	# For each statistic compute ranks and percentiles within
	# each cohort.

	# collect all of the data
	population = { }
	for id, moc in stats.items():
		## TODO: remove
		#from bill.prognosis import load_committee_membership
		#committee_membership = load_committee_membership(113)
		#moc["cohorts"] = get_cohorts(Person.objects.get(id=id), PersonRole.objects.get(person__id=id, current=True), 113, committee_membership)

		# what cohots is the member a member of?
		for cohort in moc["cohorts"]:
			for stat in moc["stats"]:
				value = moc["stats"][stat].get("value")
				if value is not None:
					population.setdefault( (cohort["key"], stat), [] ).append(value)

	# now go back over it and for each statistic gathered paste
	# in the context by cohort
	for moc in stats.values():
		for statname, statinfo in moc["stats"].items():
			value = statinfo.get("value")
			if value is None: continue
			statinfo["context"] = { }
			for cohort in moc["cohorts"]:
				pop = population[(cohort["key"], statname)]

				# don't bother with context for very small cohorts
				if len(pop) < 6: continue

				context = statinfo["context"].setdefault(cohort["key"], { })

				# count individuals in the cohort population with a lower value
				num_ties = sum(1 if v == value else 0 for v in pop) - 1 # minus himself
				context["rank_ascending"] = sum(1 if v < value else 0 for v in pop) + 1
				context["rank_descending"] = sum(1 if v > value else 0 for v in pop) + 1
				context["rank_ties"] = num_ties
				context["percentile"] = int(round(100 * sum(1 if v < value else 0 for v in pop) / float(len(pop))))
				context["N"] = len(pop)
				context["min"] = min(pop)
				context["max"] = max(pop)



if __name__ == "__main__":
	# What session?
	session = sys.argv[1]
	stats = collect_stats(session)
	#stats = json.load(sys.stdin)
	contextualize(stats)
	stats = {
		"meta": {
			"as-of": datetime.datetime.now().isoformat(),
		},
		"people": stats,
	}
	json.dump(stats, sys.stdout, indent=2, sort_keys=True)


########NEW FILE########
__FILENAME__ = session_stats_leaders
#!script

import sys, json

from us import statenames
from person.models import Person, PersonRole

# adapted from views.py to be more suitable for twitter
def get_cohort_name(key):
    if key == "house": return "in the House"
    if key == "senate": return "in the Senate"
    if key == "party-house-democrat": return "of House Dems"
    if key == "party-house-republican": return "of House GOP"
    if key == "party-house-independent": return "of House Independents"
    if key == "party-senate-democrat": return "of Sen Dems"
    if key == "party-senate-republican": return "of Sen GOP"
    if key == "party-senate-independent": return "of Senate Independents"
    if key.startswith("house-state-delegation-"): return "of " + statenames[key[23:25].upper()] + " Delegation"
    if key == "house-leadership": return "of House Party Leaders"
    if key == "senate-leadership": return "of Senate Party Leaders"
    if key == "house-freshmen": return "of freshmen reps"
    if key == "senate-freshmen": return "of Senate freshmen"
    if key == "house-sophomores": return "of sophomore reps"
    if key == "senate-sophomores": return "of Senate sophomores"
    if key == "house-tenyears": return "of reps Serving 10+ Years"
    if key == "senate-tenyears": return "of sens Serving 10+ Years"
    if key == "house-committee-leaders": return "of House Cmte. Chairs/RkMembs"
    if key == "senate-committee-leaders": return "of Senate Cmte. Chairs/RkMembs"
    if key == "house-competitive-seat": return "of competitive House seats"
    if key == "house-safe-seat": return "of safe House seats"
    raise ValueError(key)

allstats = json.load(sys.stdin)
collected_stats = []
for id, stats in allstats["people"].items():
	person = Person.objects.get(id=id)
	role = PersonRole.objects.get(id=stats["role_id"])
	for statname, statinfo in stats["stats"].items():
		if statname in ("bills-with-committee-leaders", "bills-with-companion", "committee-positions", "cosponsored-other-party"): continue

		if statname == "ideology" and (stats["stats"]["bills-introduced"]["value"] < 10 or stats["stats"]["leadership"]["value"] < .25): continue
		if statname == "leadership" and stats["stats"]["bills-introduced"]["value"] < 10: continue

		for cohortname, groupinfo in statinfo.get("context", {}).items():
			if cohortname in ("house-safe-seat", "house-tenyears", "senate-tenyears", "house-leadership", "senate-leadership", "house-committee-leaders", "senate-committee-leaders") or "delegation" in cohortname: continue
			if groupinfo["rank_ties"] > 1: continue
			if min(groupinfo["rank_ascending"], groupinfo["rank_descending"]) == 1:
				collected_stats.append( (person, role, statname, cohortname, groupinfo) )

collected_stats.sort(key = lambda x : (min(x[4]["rank_ascending"], x[4]["rank_descending"]) - x[4]["rank_ties"], x[4]["N"]), reverse=True)

seen = set()
for person, role, statname, cohortname, groupinfo in collected_stats:
	if (person, statname) in seen: continue
	seen.add( (person, statname) )

	tweet = ""

	if person.twitterid:
		if person.twitterid.startswith("Rep") or person.twitterid.startswith("Sep"):
			tweet += ".@" + person.twitterid + " "
		else:
			tweet +=  role.get_title_abbreviated() + " @" + person.twitterid + " "
	else:
		tweet += person.name_lastonly().encode("utf8") + " "

	if statname == "ideology":
		if groupinfo["rank_ascending"] == 1 and role.party == "Republican":
			tweet += "was the most moderate Repub"
		elif groupinfo["rank_ascending"] == 1:
			tweet += "was the most liberal"
		elif groupinfo["rank_descending"] == 1 and role.party == "Democrat":
			tweet += "was the most moderate Dem"
		elif groupinfo["rank_descending"] == 1:
			tweet += "was the most conservative"
		else:
			raise ValueError()

	elif statname == "leadership":
		if groupinfo["rank_ascending"] == 1:
			continue
		elif groupinfo["rank_descending"] == 1:
			tweet += "got our highest leadership score"

	elif statname == "cosponsors":
		if groupinfo["rank_ascending"] == 1:
			continue
		elif groupinfo["rank_descending"] == 1:
			tweet += "got the most cosponsors"

	elif statname == "bills-introduced":
		if groupinfo["rank_ascending"] == 1:
			continue
		elif groupinfo["rank_descending"] == 1:
			tweet += "wrote the most bills"

	elif statname == "bills-reported":
		if groupinfo["rank_ascending"] == 1:
			continue
		elif groupinfo["rank_descending"] == 1:
			tweet += "got the most bills out of committee"

	elif statname == "bills-enacted":
		if groupinfo["rank_ascending"] == 1:
			continue
		elif groupinfo["rank_descending"] == 1:
			tweet += "wrote the most new laws"

	elif statname == "bills-with-cosponsors-both-parties":
		if groupinfo["rank_ascending"] == 1:
			continue
		elif groupinfo["rank_descending"] == 1:
			tweet += "wrote the most bipartisan bills"

	elif statname == "cosponsored":
		if groupinfo["rank_ascending"] == 1:
			tweet += "cosponsored the fewest bills"
		elif groupinfo["rank_descending"] == 1:
			tweet += "cosponsored the most bills"

	elif statname == "missed-votes":
		if groupinfo["rank_ascending"] == 1:
			tweet += "missed the fewest votes"
		elif groupinfo["rank_descending"] == 1:
			tweet += "missed the most votes"

	elif statname == "transparency-bills":
		if groupinfo["rank_ascending"] == 1:
			continue
		elif groupinfo["rank_descending"] == 1:
			tweet += "got our highest #transparency score"

	else:
		superlative = "lowest" if groupinfo["rank_ascending"] == 1 else "highest"
		tweet += "has the " + superlative + " " + statname
	tweet += " "

	tweet += get_cohort_name(cohortname) + " in 2013"
	if groupinfo["rank_ties"] > 0:
		tweet += " (tied w/ %d)" % groupinfo["rank_ties"]

	tweet += ". More in our #reportcard: "
	if len(tweet) > 120: print "TOO LONG:", # url below counts as 20 chars

	tweet += "https://www.govtrack.us" + person.get_absolute_url() + "/report-card/2013"

	print tweet
	print

########NEW FILE########
__FILENAME__ = sponsorship_analysis
#!script

# Compute a Markov transition matrix representing the cosponsorship patterns
# of representatives and (separately) senators for a given time period.
# Each transition is from a Member of Congress to another Member of Congress
# if the former cosponsors a bill of the latter. The matrix is constructed so that
# the columns represent the transition probabilities (i.e. columns sum to 1).
#
# From the transition matrix we compute "PageRanks", which are essentially
# implicit leadership scores based on Member cosponsorship behavior, and
# an ideological score based on a singular value decomposition of the matrix
# rank reduction, using the 2nd dimension.
#
# Finally, plot these two dimensions.
#
# To update historical data:
# for c in {93..112}; do echo $c; analysis/sponsorship_analysis.py $c; done

import sys
import os
import glob
import math
import numpy
import scipy.stats
import lxml.etree as lxml

from person.models import PersonRole
from person.types import RoleType
from bill.models import Bill, Cosponsor
from us import get_congress_dates

import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt

# CONFIGURATION

datadir = "data"
matplotlib.rcParams["font.size"] = 9.0
matplotlib.rcParams["lines.markersize"] = 3

# GLOBAL FUNCTIONS

def onenorm(u):
	# The one-norm.
	return sum(abs(u))

def rescale(u, log=False):
	# Re-scale the vector to range from 0 to 1, and convert it out of
	# numpy data format.
	u = (u - min(u)) / (max(u) - min(u))
	
	# If log is True, then rescale the values on an essentially logarithmic
	# axis, such that the median value comes out as linearly halfway
	# between the min and maximum values. Note that the unscaled
	# min and max are 0 and 1, respectively, since we already rescaled
	# above. Thus:
	#    1/2*(log(0 + s) + log(1 + s)) = log(median + s)
	# Wolfram|Alpha says the solution is:
	#    s = -m^2/(2m-1)
	if log:
		m = numpy.median(u)
		s = -m**2/(2*m - 1)
		u = numpy.log(u + s)
		u = (u - min(u)) / (max(u) - min(u))
	return [float(v) for v in u]

# BEGIN

def get_roles_of_people(congressnumber):
	congress_dates = get_congress_dates(congressnumber)
	return PersonRole.objects.filter(
		role_type__in=(RoleType.senator, RoleType.representative),
		startdate__lt=congress_dates[1], # start dates of next congress are on this day too
		enddate__gt=congress_dates[0] # end dates from previous congress are on this day too
		).select_related("person")\
		.order_by('-startdate')  # so we put people in the right list by their most recent term

def get_people(roles):
	# Put each person only in the House or Senate output, even if they served in both,
	# according to their most recent role. We want to include everyone who served
	# during the Congress, even if they are not now serving.
	people = { }
	people_list = { 'h': set(), 's': set() }

	for person_role in roles:
		pid = person_role.person_id
		if pid in people: continue # saw a more recent term for this person
		people[pid] = person_role
		people_list["h" if person_role.role_type == RoleType.representative else "s"].add(pid)

	return people, people_list

def attach_other_stats(congressnumber, person_role):
	# A staffer tells me they're interested in the number of unique/total cosponsors to their
	# bills in the current Congress. We'll compute that here too. For historical data, compute for
	# bills up to the end of the Congress.
	bills = person_role.person.sponsored_bills.filter(congress=congressnumber)
	cosp = Cosponsor.objects.filter(bill__in=list(bills)).values_list('person', flat=True)
	person_role.total_cosponsors = len(cosp)
	person_role.unique_cosponsors = len(set(cosp))

	# ...and the number of other people's bills the member has cosponsored this Congress.
	person_role.total_cosponsored_bills = Cosponsor.objects.filter(person=person_role.person, bill__congress=congressnumber).count()

	# ...and the number of bills the Member introduced this Congress
	person_role.total_introduced_bills = Bill.objects.filter(sponsor=person_role.person, congress=congressnumber).count()


def build_matrix(congressnumber, starting_congress, house_or_senate, people, people_list, filter_startdate=None, filter_enddate=None):
	start_date = None
	end_date = None
	
	# Map GovTrack person IDs to rows (or columns) of the matrix.
	rep_to_row = { }
	def rownum(id):
		if not id in rep_to_row:
			rep_to_row[id] = len(rep_to_row)
		return rep_to_row[id]
		
	# Store a flat (i.e. sparse) list of all cells that have the value 1. Note that
	# we will get duplicates here! Scan the indicated and the previous congress,
	# but include only those Members of Congress that served in the indicated
	# Congress.
	cells = []
	for cn in xrange(starting_congress, congressnumber+1):
		for billfilename in glob.glob(datadir + "/us/" + str(cn) + "/bills/" + house_or_senate + "*.xml"):
			xml = lxml.parse(billfilename)
			
			# get the sponsor
			spx = xml.xpath("sponsor/@id")
			if len(spx) == 0: # e.g. debt limit with no sponsor
				continue
			if not int(spx[0]) in people_list[house_or_senate]:
				continue
			sponsor = rownum(int(spx[0]))

			# loop through the cosponsors
			has_entry = False
			for cosponsor_node in xml.xpath("cosponsors/cosponsor"):
				# get the cosponsor's ID
				cosponsor_id = int(cosponsor_node.xpath("string(@id)"))
				if cosponsor_id not in people_list[house_or_senate]: continue

				# if a date filter is specified, only take cosponsors that joined within
				# the date range (inclusive)
				if filter_startdate:
					join_date = cosponsor_node.xpath("string(@joined)")
					if join_date < filter_startdate or join_date > filter_enddate:
						continue

				# add an entry to the flat list of sponsor-cosponsor pairs
				cosponsor = rownum(cosponsor_id)
				cells.append( (sponsor, cosponsor) )
				has_entry = True

			# if there was a sponsor/cosponsor pair from this bill, extend the
			# start_date/end_date range to cover the introduced date of this bill.
			if has_entry:
				date = xml.xpath("introduced/@datetime")[0]
				start_date = min(start_date, date) if start_date else date
				end_date = max(end_date, date)
	
	# In the event a member of congress neither sponsored nor cosponsored
	# a bill, just give them an empty slot.
	for person in people_list[house_or_senate]:
		rownum(person)

	# Get total number of members of congress seen.
	nreps = len(rep_to_row)
	
	# Turn this into a dense numpy array with cells flagged as 1 if there is such
	# a transition. Keep adding 1s... Start with the identity matrix because
	# every rep should be counted as sponsoring his own bills.
	P = numpy.identity(nreps, numpy.float) # numpy.zeros( (nreps,nreps) )
	for sponsor, cosponsor in cells:
		P[sponsor, cosponsor] += 1.0

	return start_date, end_date, rep_to_row, nreps, P

def smooth_matrix(nreps, P):
	# Take the square root of each cell to flatten out outliers where one person
	# cosponsors a lot of other people's bills.
	for i in xrange(nreps):
		for j in xrange(nreps):
			P[i,j] = math.sqrt(P[i,j])

def build_party_list(rep_to_row, people, nreps):
	parties = [None for i in xrange(nreps)]
	for k, v in rep_to_row.items():
		parties[v] = people[k].party
	return parties

def ideology_analysis(nreps, parties, P):
	# Ideology (formerly "Political Spectrum") Analysis
	###################################################

	# Run a singular value decomposition to get a rank-reduction, one dimension
	# of which should separate representatives on a liberal-conservative scale.
	# In practice it looks like the second dimension works best. Also, this works
	# best before we normalize columns to sum to one. That is, we want cells
	# to be 1 when the column person cosponsors a bill of the row person.
	u, s, vh = numpy.linalg.svd(P)
	spectrum = vh[1,:]
	
	# To make the spectrum left-right, we'll multiply the scores by the sign of
	# the mean score of the Republicans to put them on the right.
	# Actually, since scale doesn't matter, just multiply it by the mean.
	R_scores = [spectrum[i] for i in xrange(nreps) if parties[i] == "Republican"]
	R_score_mean = sum(R_scores)/len(R_scores)
	spectrum = spectrum * R_score_mean

	# Scale the values from 0 to 1.
	spectrum = rescale(spectrum)
	
	return spectrum
	
def leadership_analysis(nreps, P):
	# Leadership Analysis based on the Google PageRank Algorithm
	############################################################

	# For each column, normalize so the sum is one. We started with an
	# identity matrix so even MoCs that only cosponsor their own bills
	# have some data. But if they have so little data, we should fudge
	# it because if they only 'cosponsor' their own bills they will get
	# leadership scores of 0.5.
	for col in xrange(nreps):
		s = sum(P[:,col])
		if s == 0: raise ValueError()
		if s < 10: # min number of cosponsorship data per person
			P[:,col] += (10.0-s)/nreps
			s = 10
		P[:,col] = P[:,col] / s
		
	# Create a random transition vector.
	v = numpy.ones( (nreps, 1) ) / float(nreps)
	
	# This is one minus the weight we give to the random transition probability
	# added into each column.
	c = 0.85
	
	# Create an initial choice for x, another random transition vector.
	x = numpy.ones( (nreps, 1) ) / float(nreps)
	
	# Run the Power Method to compute the principal eigenvector for the matrix,
	# which is, after all, the PageRank.
	
	while True:
		# Compute y = Ax where A is P plus some perturbation with magnitude
		# 1-c that ensures that A is a valid aperiodic, irreducible Markov transition matrix.
		y = c * numpy.dot(P, x)
		w = onenorm(x) - onenorm(y)
		y = y + w*v
		
		# Check the error and terminate if we are within tolerance.
		err = onenorm(y-x)
		if err < .00000000001:
			break
	
		x = y
		
	# Scale the values from 0 to 1 on a logarithmic scale.
	x = rescale(x, log=True)

	return x # this is the pagerank
	
def build_output_columns(rep_to_row, people):
	# Create a list of names in row order.
	ids = [None for k in rep_to_row]
	names = [None for k in rep_to_row]
	other_cols = [None for k in rep_to_row]
	usednames = { }
	for k, v in rep_to_row.items():
		ids[v] = k
		names[v] = people[k].person.lastname
		
		# Check that the name is not a dup of someone else, and if so,
		# append a state (and district) to each.
		if names[v] in usednames:
			k2 = usednames[names[v]]
			
			d = str(people[k].district) if people[k].district is not None else ""
			d2 = str(people[k2].district) if people[k2].district is not None else ""
			names[v] = people[k].person.lastname + " [" + people[k].state  + d + "]"
			names[rep_to_row[k2]] = people[k2].person.lastname + " [" + people[k2].state  + d2 + "]"
		else:
			usednames[names[v]] = k

		other_cols[v] = [people[k].total_introduced_bills, people[k].total_cosponsored_bills, people[k].unique_cosponsors, people[k].total_cosponsors]
	return ids, names, other_cols

def draw_figure(congressnumber, house_or_senate, start_date, end_date, nreps, parties, spectrum, pagerank, names):
	for figsize, figsizedescr in ((1.0, ""), (1.5 if house_or_senate == "s" else 3.0, "_large")):
		fig = plt.figure()
		plt.title(("House of Representatives" if house_or_senate == "h" else "Senate") + ", " + start_date + " to " + end_date)
		plt.xlabel("Ideology")
		plt.ylabel("Leadership")
		plt.xticks([])
		plt.yticks([])	
		
		for party, color in (("Republican", "r"), ("Democrat", "b"), ("Independent", "k")):
			for i in xrange(nreps):
				if parties[i] == party:
					plt.text(spectrum[i], pagerank[i], names[i], color=color, ha="left", weight="light", size=(8 if house_or_senate == "s" else 6)/figsize)
					#print spectrum[i], pagerank[i], names[i].encode("utf8")
			
			ss = [spectrum[i] for i in xrange(nreps) if parties[i] == party]
			pp = [pagerank[i] for i in xrange(nreps) if parties[i] == party]
			plt.plot(ss, pp, "." + color, markersize=3/figsize)
	
		plt.savefig(datadir + "/us/" + str(congressnumber) + "/stats/sponsorshipanalysis_" + house_or_senate + figsizedescr + ".png", dpi=120*figsize, bbox_inches="tight", pad_inches=.02)

def describe_members(nreps, parties, spectrum, pagerank):
	# Describe what kind of person each is....
	descr = [None for x in xrange(nreps)] # allocate some space
	for party in ("Republican", "Democrat", "Independent"):
		ss = [spectrum[i] for i in xrange(nreps) if parties[i] == party]
		pp = [pagerank[i] for i in xrange(nreps) if parties[i] == party]
		
		if party != "Independent": # not enough to actually perform the computation, even if we don't want to use it anyway
			ss_20 = scipy.stats.scoreatpercentile(ss, 20)
			ss_80 = scipy.stats.scoreatpercentile(ss, 80)
			
			pp_20 = scipy.stats.scoreatpercentile(pp, 20)
			pp_80 = scipy.stats.scoreatpercentile(pp, 80)
		
		if party == "Democrat":
			descr_table = [
				["far-left Democratic leader", "moderate Democratic leader", "centrist Democratic leader"],
				["far-left Democrat", "rank-and-file Democrat", "centrist Democrat"],
				["lonely far-left Democratic ", "moderate Democratic follower", "centrist Democratic follower"],
				]
		elif party == "Republican":
			descr_table = [
				["centrist Republican leader", "moderate Republican leader", "far-right Republican leader"],
				["centrist Republican", "rank-and-file Republican", "far-right Republican"],
				["centrist Republican follower ", "moderate Republican follower", "lonley far-right Republican follower"],
				]
				
		else:
			# for independents, score according to the whole chamber
			ss_20 = scipy.stats.scoreatpercentile(spectrum, 20)
			ss_80 = scipy.stats.scoreatpercentile(spectrum, 80)
			
			pp_20 = scipy.stats.scoreatpercentile(pagerank, 20)
			pp_80 = scipy.stats.scoreatpercentile(pagerank, 80)
			
			descr_table = [ # no damn commas
				["left-leaning Independent leader", "moderate Independent leader", "right-leaning Independent leader"],
				["left-leaning Independent", "centrist Independent", "right-leaning Independent"],
				["lonely left-leaning Independent", "lonely centrist Independent", "lonely right-leaning Independent"],
				]
				
		for i in xrange(nreps):
			if parties[i] == party:
				descr[i] = descr_table[2 if pagerank[i] < pp_20 else 1 if pagerank[i] < pp_80 else 0][0 if spectrum[i] < ss_20 else 1 if spectrum[i] < ss_80 else 2]

	return descr
		
def write_stats_to_disk(congressnumber, house_or_senate, nreps, ids, parties, names, spectrum, pagerank, descr, other_cols):
	w = open(datadir + "/us/" + str(congressnumber) + "/stats/sponsorshipanalysis_" + house_or_senate + ".txt", "w")
	w.write("ID, ideology, leadership, name, party, description, introduced_bills_%d, cosponsored_bills_%d, unique_cosponsors_%d, total_cosponsors_%d\n" % tuple([congressnumber]*4))
	for i in xrange(nreps):
		w.write(", ".join( [unicode(d).encode("utf8") for d in
			[ids[i], spectrum[i], pagerank[i], names[i], parties[i], descr[i]] + other_cols[i]
			]) + "\n" )
	w.close()
	
def write_metadata_to_disk(congressnumber, house_or_senate, start_date, end_date):
	w = open(datadir + "/us/" + str(congressnumber) + "/stats/sponsorshipanalysis_" + house_or_senate + "_meta.txt", "w")
	w.write('{\n')
	w.write(' "start_date": "' + start_date + '",\n')
	w.write(' "end_date": "' + end_date + '"\n')
	w.write('}\n')
	w.close()

def create_member_images():
		# We no longer need this as the site displays Javascript-based graphs. So this is here
		# archivally and is no longer used.

		# Create an image for each person.
		for j in xrange(nreps):
			fig = plt.figure()
			plt.xlabel("Ideology", size="x-large") # size not working, ugh
			plt.ylabel("Leadership", size="x-large")
			plt.xticks([])
			plt.yticks([])	
			for party, color in (("Republican", "r"), ("Democrat", "b"), ("Independent", "k")):
				ss = [spectrum[i] for i in xrange(nreps) if parties[i] == party]
				pp = [pagerank[i] for i in xrange(nreps) if parties[i] == party]
				plt.plot(ss, pp, "." + color, markersize=7)
			plt.plot(spectrum[j], pagerank[j], "ok", markersize=20)
			plt.savefig(datadir + "/us/" + str(congressnumber) + "/stats/person/sponsorshipanalysis/" + str(ids[j]) + ".png", dpi=25, bbox_inches="tight", pad_inches=.05)

def do_analysis(congressnumber, starting_congress, house_or_senate, people, people_list):
	start_date, end_date, rep_to_row, nreps, P = build_matrix(congressnumber, starting_congress, house_or_senate, people, people_list)
	smooth_matrix(nreps, P)
	parties = build_party_list(rep_to_row, people, nreps)
	spectrum = ideology_analysis(nreps, parties, P)
	pagerank = leadership_analysis(nreps, P)
	ids, names, other_cols = build_output_columns(rep_to_row, people)
	draw_figure(congressnumber, house_or_senate, start_date, end_date, nreps, parties, spectrum, pagerank, names)
	descr = describe_members(nreps, parties, spectrum, pagerank)
	write_stats_to_disk(congressnumber, house_or_senate, nreps, ids, parties, names, spectrum, pagerank, descr, other_cols)
	write_metadata_to_disk(congressnumber, house_or_senate, start_date, end_date)

			
if __name__ == "__main__":
	congressnumber = int(sys.argv[1])

	os.system("mkdir -p " + datadir + "/us/" + str(congressnumber) + "/stats/person/sponsorshipanalysis")

	people, people_list = get_people(get_roles_of_people(congressnumber))
	for person_role in people.values():
		attach_other_stats(congressnumber, person_role)

	# Perform analysis totally separately for each chamber.
	for house_or_senate in ('h', 's'):
		do_analysis(congressnumber, congressnumber-2, house_or_senate, people, people_list)


########NEW FILE########
__FILENAME__ = admin
# -*- coding: utf-8

from django.contrib import admin
from bill.models import BillTerm, Bill, Cosponsor, BillLink, BillSummary

class BillTermAdmin(admin.ModelAdmin):
    list_display = ['name', 'term_type']
    search_fields = ['name']

class CosponsorInline(admin.TabularInline):
    model = Cosponsor
    extra = 1


class BillAdmin(admin.ModelAdmin):
    list_display = ['title', 'congress', 'number']
    raw_id_fields = ['sponsor', 'cosponsors', 'sponsor_role', 'committees', 'terms']
    inlines = (CosponsorInline,)

class BillLinkAdmin(admin.ModelAdmin):
    list_display = ['created', 'url', 'title', 'approved']
    raw_id_fields = ['bill']
    def make_approved(modeladmin, request, queryset):
        queryset.update(approved=True)
	#make_approved.short_description = "Mark selected links as approved"
    actions = [make_approved]

class BillSummaryAdmin(admin.ModelAdmin):
    list_display = ['created', 'bill']
    raw_id_fields = ['bill']
    change_form_template = 'admin/wysiwyg_billsummary_change_form.html' # for django_wysiwyg
    def save_model(self, request, obj, form, change):
        obj.content = BillSummaryAdmin.sanitize_html(obj.content)
        obj.save()
        obj.bill.create_events()
    def delete_model(self, request, obj):
    	bill = obj.bill
    	obj.delete()
        bill.create_events()
        
    @staticmethod
    def sanitize_html(value):
        # based on http://djangosnippets.org/snippets/205/
        from BeautifulSoup import BeautifulSoup
        valid_tags = 'p i strong b u a h1 h2 h3 pre br img ul ol li span'.split()
        valid_attrs = 'href src'.split()
        soup = BeautifulSoup(value)
        for tag in soup.findAll(True):
            if tag.name not in valid_tags:
                tag.hidden = True
            tag.attrs = [(attr, val) for attr, val in tag.attrs
                         if attr in valid_attrs]
        return soup.renderContents().decode('utf8')

admin.site.register(BillTerm, BillTermAdmin)
admin.site.register(Bill, BillAdmin)
admin.site.register(BillLink, BillLinkAdmin)
admin.site.register(BillSummary, BillSummaryAdmin)


########NEW FILE########
__FILENAME__ = bill_counts_by_session
#!script

import sys, csv, json

from us import get_all_sessions
from bill.models import *
from bill.status import BillStatus
from bill.billtext import load_bill_text

status_names = { }
status_names["MISSING_TEXT"] = "(number of bills that I'm missing text for)"

w = csv.writer(sys.stdout)
w.writerow(["congress", "session", "status code", "status name" "pages"])

for congress, session, startdate, enddate in get_all_sessions():
	# before the 103rd, there's no MODS data
	if congress < 103: continue

	# to get bills in the first session, look for bills that were
	# introduced before the end of the session.
	bills = Bill.objects.filter(
		congress=congress,
		introduced_date__gte=startdate,
		introduced_date__lte=enddate,
		)

	# get page counts by GPO version code
	page_counts = { }
	for b in bills:
		try:
			mods = load_bill_text(b, None, mods_only=True)
		except IOError:
			status = "MISSING_TEXT"
			page_counts[status] = page_counts.get(status, 0) + 1
			continue

		status = mods["doc_version"]
		if status is None or status.strip() == "": status = "UNKNOWN"
		status_names[status] = mods["doc_version_name"]
		pp = int(mods.get("numpages").replace(" pages", ""))
		page_counts[status] = page_counts.get(status, 0) + pp

	for status, page_count in sorted(page_counts.items(), key = lambda kv : -kv[1]):
		w.writerow([str(congress), session, status, status_names[status], str(page_count)])


########NEW FILE########
__FILENAME__ = bill_page_counts
#!script

import csv, sys

from us import get_all_sessions
from bill.models import *
from bill.billtext import load_bill_text

C = csv.writer(sys.stdout)

for congress, session, startdate, enddate in get_all_sessions():
	if congress < 103: continue

	bills = Bill.objects.filter(
		congress=congress,
		introduced_date__gte=startdate,
		introduced_date__lte=enddate,
		).order_by('introduced_date')

	for b in bills:
		try:
			pp = load_bill_text(b, None, mods_only=True).get("numpages")
			pp = int(pp.replace(" pages", ""))
		except IOError:
			pp = "NA"
		
		C.writerow([b.congress, session, BillType.by_value(b.bill_type).slug, str(b.number), str(pp)])


########NEW FILE########
__FILENAME__ = bipartisanness_wsj
#!script

from bill.models import *
from person.util import load_roles_at_date
from datetime import date

for congress in [112]: # range(96, 113):
	total = 0
	has_initial_cosponsors = 0
	bipartisan_cosp = 0
	total_has_companion = 0
	total_companion_bipartisan = 0
	
	for bill in Bill.objects.filter(congress=congress, bill_type__in=(BillType.house_bill, BillType.senate_bill)).select_related("sponsor"):
		#.filter(introduced_date__gte=date(2011, 8, 1)):
		total += 1
		
		# People we care about. Batch load party information for sponsors
		# and cosponsors to be fast. Load roles at the bill introduced date.
		# Only look at cosponsors who joined on the introduced date (otherwise
		# they may have changed party between those two dates).
		persons = []
		if not bill.sponsor: continue
		persons.append(bill.sponsor)
		persons.extend([c.person for c in Cosponsor.objects.filter(bill=bill, joined=bill.introduced_date).select_related("person")])
		load_roles_at_date(persons, bill.introduced_date)
		
		if len(persons) > 1: has_initial_cosponsors += 1
		
		# How bipartisan_cosp is this bill?
		parties = set()
		for p in persons:
			if p.role:
				parties.add(p.role.party)
		if "Democrat" in parties and "Republican" in parties:
			bipartisan_cosp += 1
		
		if bill.bill_type == BillType.senate_bill:
			related_bill = None
			try:
				relation = bill.relatedbills.filter(relation='identical', related_bill__bill_type=BillType.house_bill).select_related("related_bill", "related_bill__sponsor").get()
				related_bill = relation.related_bill
			except Exception as e:
				continue
			if related_bill and related_bill.sponsor:
				total_has_companion += 1
				r = related_bill.sponsor.get_role_at_date(related_bill.introduced_date)
				if r:
					if bill.sponsor.role.party in ("Democrat", "Republican"):
						if r.party in ("Democrat", "Republican"):
							if bill.sponsor.role.party != r.party:
								total_companion_bipartisan += 1
		
	print congress, bipartisan_cosp, has_initial_cosponsors, total_companion_bipartisan, total_has_companion, total
	

########NEW FILE########
__FILENAME__ = compute_how_often_senators_vote_by_party
from vote.models import *
votecount = 0
counts = {False: 0, True: 0}
for y in (2009, 2010, 2011):
 for v in Vote.objects.filter(source=VoteSource.senate, created__year=y, category=VoteCategory.passage):
  if v.related_bill == None or v.related_bill.sponsor == None: continue
  p = v.related_bill.sponsor.get_role_at_date(v.created).party
  if p == "Independent": continue
  votecount += 1
  for vv in v.voters.exclude(person=None):
   r = vv.person.get_role_at_date(v.created)
   if vv.option.key in ("+", "-") and r and r.party != "Independent":
    counts[(r.party == p) ^ (vv.option.key == "-")] += 1
print votecount, "votes"
print float(counts[True])/sum(counts.values())

########NEW FILE########
__FILENAME__ = congress_dates_chart
#!script

# When was Congress in session?
#
# Forgive me for generating SVG without a proper library.

from datetime import date
from us import get_all_sessions

bar_width = 3.5
height = 20.0

print """<svg xmlns="http://www.w3.org/2000/svg" version="1.1">"""

def break_session(s1, s2):
	for y in xrange(s1.year, s2.year+1):
		yield (s1 if y == s1.year else date(y, 1, 1)), (s2 if y == s2.year else date(y, 12, 31))

for cong, sess, s1, s2 in get_all_sessions():
	clr = "rgb(200,200,200)"
	if (cong % 2) == 0: clr = "rgb(100,100,100)"
	
	for startdate, enddate in break_session(s1, s2):
		print """<rect x="%f" y="%f" width="%f" height="%f" style="fill:%s; stroke-width:%f; stroke:rgb(0,0,0)" />""" % (
			(startdate.year - 1789) * bar_width,
			(startdate - date(startdate.year, 1, 1)).days/365.0 * height,
			.5 * bar_width,
			(enddate - startdate).days/365.0*5.0 * height,
			clr,
			bar_width * .05,
			)

print """</svg>"""


########NEW FILE########
__FILENAME__ = lifetime_bill_stats
#!script

import sys, csv, datetime

from bill.models import *
from person.models import *

today = datetime.datetime.now().date()

w = csv.writer(sys.stdout)

w.writerow(["est start", "years served", "name", "introduced", "reported", "enacted", "url"])

def get_first_swearing_in_date(r):
	return PersonRole.objects.filter(person=r.person, role_type=r.role_type).order_by("startdate")[0].startdate

def get_number_of_years_served(r):
	years = 0.0
	for r in PersonRole.objects.filter(person=r.person, role_type=r.role_type):
		years += (min(r.enddate, today) - r.startdate).total_seconds() / 60 / 60 / 24 / 365.25
	return years

cur_roles = list(PersonRole.objects.filter(current=True, role_type=RoleType.representative).select_related("person"))
cur_roles.sort(key = lambda r : -get_number_of_years_served(r))

for r in cur_roles:
	row = [
		get_first_swearing_in_date(r).strftime("%x"),
		str(int(round(get_number_of_years_served(r)))),
		unicode(r.person).encode("utf8"),
	]

	# bills introduced
	bills = list(Bill.objects.filter(sponsor=r.person))
	row.append(str(len(bills)))

	# bills reported
	bills_reported = [b for b in bills if b.current_status not in (BillStatus.introduced, BillStatus.referred)]
	row.append(str(len(bills_reported)))

	# bills enacted
	bills_enacted = [b for b in bills if b.was_enacted_ex() is not None]
	row.append(str(len(bills_enacted)))

	row.append("http://www.govtrack.us" + r.person.get_absolute_url())

	w.writerow(row)

########NEW FILE########
__FILENAME__ = markov_model
#!script

from bill.models import *
from bill.status import BillStatus

class Died:
	label = "Died"
	sort_order = 999
Died = Died()

T = { }
for b in Bill.objects.filter(congress__in=(110,111), bill_type=BillType.house_bill):
	s0 = BillStatus.introduced
	for d, s, t in b.major_actions:
		s = BillStatus.by_value(s)
		if s0:
			if s.key == "referred":
				# data error
				s = BillStatus.introduced # map to introduced next xycle
				pass
			elif s0.key == "pass_over_house" and s.key == "enacted_signed":
				# data error
				T[(s0, BillStatus.passed_bill)] = T.get((s0, BillStatus.passed_bill), 0) + 1
				T[(BillStatus.passed_bill, s)] = T.get((BillStatus.passed_bill, s), 0) + 1
			else:
				T[(s0, s)] = T.get((s0, s), 0) + 1
		s0 = s
	T[(s0, Died)] = T.get((s0, Died), 0) + 1

import pygraphviz as pgv
G = pgv.AGraph(directed=True, dpi=120, overlap=False, splines=True, bgcolor="transparent")
for (s0, s1), n in sorted(T.items(), key=lambda x : (x[0][0].sort_order, x[0][1].sort_order)):
	nn = sum([v[1] for v in T.items() if v[0][0] == s0])
	print s0.label, s1.label, float(n)/float(nn)
	if s1 == Died: continue # don't draw it
	G.add_node(s0.key, fontsize=8)
	G.add_node(s1.key, fontsize=8)
	G.add_edge(s0.key, s1.key, label="%d%%" % (100*float(n)/float(nn)), fontsize=10)
G.layout(prog='neato')
G.draw("static/markov_model.png")


########NEW FILE########
__FILENAME__ = number_sponsored
#!script

import sys, csv

from django.db.models import Count

from us import get_all_sessions
from person.models import *
from bill.models import *

def build(role_type, congress, session, session_start, session_end, people_sort_order, data_matrix):

	# Get all bills introduced in this congress and session by Members of
	# Congress in the desired chamber, aggregated by sponsor role.
	bill_counts = list(Bill.objects.filter(
			sponsor_role__role_type=role_type,
			congress=congress,
			introduced_date__gte=session_start,
			introduced_date__lte=session_end)\
			.values('sponsor_role')\
			.annotate(count=Count('sponsor_role')))

	# Get corresponding people.
	people_map = PersonRole.objects.in_bulk([ bc['sponsor_role'] for bc in bill_counts ])

	# add new people in sorted order by name
	people = list(set([r.person for r in people_map.values()]))
	if len(people_map) != len(people): raise ValueError() # sanity check that there is one role per person in this congress/chamber
	people.sort(key=lambda p : p.sortname)
	for p in people:
		if p not in data_matrix:
			people_sort_order.append(p)

	# build the output matrix
	for bc in bill_counts:
		data_matrix.setdefault(people_map[bc['sponsor_role']].person, {})[(congress, session)] = bc["count"]

	return len(bill_counts) > 0

for role_type in (RoleType.representative, RoleType.senator):
	people_sort_order = []
	data_matrix = { }
	sessions = []

	for congress, session, startdate, enddate in get_all_sessions():
		if congress < 109: continue # make a smaller table

		if build(role_type, congress, session, startdate, enddate, people_sort_order, data_matrix):
			print role_type.congress_chamber, congress, session
			sessions.append((congress, session))

	writer = csv.writer(open("sponsorship_counts_%s.csv" % role_type.congress_chamber.lower()[0], "w"))
	writer.writerow(["id", "name"] + [cs[1] for cs in sessions])

	def zero(value):
		if value is None: return 0
		return value

	for p in people_sort_order:
		writer.writerow(
			[p.id, p.sortname.encode("utf8")] + [str(zero(data_matrix[p].get(cs))) for cs in sessions]
			)

########NEW FILE########
__FILENAME__ = paul_ryan
#!script

from datetime import datetime, date
from numpy import mean, median, percentile
from scipy.stats import percentileofscore

from person.models import Person, PersonRole
from bill.models import Bill, Cosponsor, BillType
from bill.status import BillStatus
from committee.models import CommitteeMember, CommitteeMemberRole
from vote.models import VoteCategory, VoteOption

paul_ryan = Person.objects.get(id=400351)
paul_ryan_role = paul_ryan.roles_condensed()[0]

joe_biden = Person.objects.get(id=300008)
barak_obama = Person.objects.get(id=400629)

#for b1 in (Bill.objects.filter(cosponsors=paul_ryan) | Bill.objects.filter(sponsor=paul_ryan)).distinct():
#	for b2 in b1.get_related_bills():
#		if b2.relation == "identical":
#			if b2.related_bill.sponsor == joe_biden or b2.related_bill.sponsor == barak_obama:
#				# or joe_biden in b2.related_bill.cosponsors.all() or barak_obama in b2.related_bill.cosponsors.all():
#				print b1
#				print b2.related_bill
#				print b1.sponsor, b2.related_bill.sponsor
#				print
#
#results = []
#tot = 0
#for b in Bill.objects.filter(votes__voters__person=paul_ryan, votes__category__in=(VoteCategory.passage, VoteCategory.passage_suspension, VoteCategory.veto_override)).filter(votes__voters__person=joe_biden, votes__category__in=(VoteCategory.passage, VoteCategory.passage_suspension, VoteCategory.veto_override)).distinct():
#	votes = { paul_ryan: set(), joe_biden: set() }
#	for v in b.votes.filter(category__in=(VoteCategory.passage, VoteCategory.passage_suspension, VoteCategory.veto_override)):
#		if v.total_plus == 0 or v.total_minus == 0: continue
#		for vv in v.voters.filter(person__in=(paul_ryan, joe_biden)):
#				votes[vv.person].add(vv.option.key)
#	if len(votes[paul_ryan] & votes[joe_biden]) == 1:
#		results.append( (b, "".join(votes[paul_ryan] & votes[joe_biden])) )
#	tot += 1
#results.sort(key = lambda b : (
#		"Appropriation" in b[0].title or "Authorization" in b[0].title,
#		b[0].current_status != 28,
#		-b[0].proscore() ))
#import csv
#wr = csv.writer(open("veep_common_bills.csv", "w"))
#wr.writerow(("Vote", "Bill Status", "Bill Title", "Link"))
#for r in results:
#	wr.writerow((r[1].replace("+", "Support").replace("-", "Oppose"), r[0].get_current_status_display().replace("Signed by the President", "Enacted"), r[0].title.encode("utf8"), "http://www.govtrack.us" + r[0].get_absolute_url()))
#
#print len(results), tot

#import sys
#sys.exit()

all_congressmen =set([p for p in Person.objects\
	.filter(roles__enddate__gt=datetime.now(), roles__role_type=paul_ryan_role.role_type).distinct()\
	]) 

republican_congresspeeps_serving_as_long = set([p for p in Person.objects\
	.filter(roles__enddate__gt=datetime.now(), roles__role_type=paul_ryan_role.role_type, roles__party=paul_ryan_role.party).distinct()\
	if p.roles_condensed()[0].startdate <= paul_ryan_role.startdate])

republican_congresspeeps = set([p for p in Person.objects\
	.filter(roles__enddate__gt=datetime.now(), roles__role_type=paul_ryan_role.role_type, roles__party=paul_ryan_role.party).distinct()])

republican_new_congresspeeps = set([p for p in Person.objects\
	.filter(roles__enddate__gt=datetime.now(), roles__role_type=paul_ryan_role.role_type, roles__party=paul_ryan_role.party).distinct() if p.roles_condensed()[0].startdate == date(2011, 1, 5)])

republican_non_new_congresspeeps = set([p for p in Person.objects\
	.filter(roles__enddate__gt=datetime.now(), roles__role_type=paul_ryan_role.role_type, roles__party=paul_ryan_role.party).distinct() if p.roles_condensed()[0].startdate < date(2011, 1, 1)])

democratic_congresspeeps = set([p for p in Person.objects\
	.filter(roles__enddate__gt=datetime.now(), roles__role_type=paul_ryan_role.role_type).exclude(roles__party=paul_ryan_role.party).distinct()])

def is_chair(person):
	return 1 if CommitteeMember.objects.filter(person=person, role=CommitteeMemberRole.chairman, committee__committee=None).exists() else 0

def pct_dem_cosponsors(person):
	c = Cosponsor.objects.filter(bill__sponsor=person)
	return float(c.filter(role__party="Democrat").count())/float(c.count())

def pct_dem_bills(person):
	c = Cosponsor.objects.filter(person=person)
	return float(c.filter(bill__sponsor_role__party="Democrat").count())/float(c.count())

def leadership_score(person):
	from person.analysis import load_sponsorship_analysis
	v = load_sponsorship_analysis(person)["leadership"]
	if v == None: return None
	return float(v)
	
def bills_enacted(person):
	return Bill.objects.filter(sponsor=person, bill_type=BillType.house_bill, current_status__in=BillStatus.final_status_passed_bill).count()

def make_stat(descr, pop, stat):
	vals = [stat(p) for p in pop]
	vals = [v for v in vals if v != None]
	v = stat(paul_ryan)
	print descr
	print "value", round(v, 2), "N=", len(vals), "mean", round(mean(vals), 2), "median", round(median(vals), 2), "percentile", round(percentileofscore(vals, v))
	print

make_stat("#enacted; congressmen", all_congressmen, bills_enacted)
make_stat("#enacted; republicans tenure as long", republican_congresspeeps_serving_as_long, bills_enacted)

make_stat("leadership; republican", republican_congresspeeps, leadership_score)
make_stat("leadership; republican tenure as long", republican_congresspeeps_serving_as_long, leadership_score)
make_stat("leadership; republican non-freshmen", republican_non_new_congresspeeps, leadership_score)
make_stat("leadership; republican freshmen", republican_new_congresspeeps, leadership_score)


make_stat("chair; republican", republican_congresspeeps, is_chair)
make_stat("chair; republican tenure as long", republican_congresspeeps_serving_as_long, is_chair)

print "Ryan cosponsored", Cosponsor.objects.filter(person=paul_ryan).count()
make_stat("% dem bills; republican", republican_congresspeeps, pct_dem_bills)
make_stat("% dem bills; republican tenure as long", republican_congresspeeps_serving_as_long, pct_dem_bills)
make_stat("% dem bills; republican non-freshmen", republican_non_new_congresspeeps, pct_dem_bills)
make_stat("% dem bills; republican freshmen", republican_new_congresspeeps, pct_dem_bills)

print "Ryan sponsored", Bill.objects.filter(sponsor=paul_ryan).count()
make_stat("% cosponsors dem; republican", republican_congresspeeps, pct_dem_cosponsors)
make_stat("% cosponsors dem; republican tenure as long", republican_congresspeeps_serving_as_long, pct_dem_cosponsors)
make_stat("% cosponsors dem; republican non-freshmen", republican_non_new_congresspeeps, pct_dem_cosponsors)
make_stat("% cosponsors dem; republican freshmen", republican_new_congresspeeps, pct_dem_cosponsors)


########NEW FILE########
__FILENAME__ = time_to_first_vote
from bill.models import *

delay_times = []

for bill in Bill.objects.filter(congress=111, bill_type=BillType.senate_bill):
	if bill.current_status in (BillStatus.introduced, BillStatus.referred, BillStatus.reported):
		continue
	for d, st, descr in bill.major_actions:
		if st not in (BillStatus.introduced, BillStatus.referred):
			#print BillStatus.by_value(st).label
			delay_times.append( eval(d).date() - bill.introduced_date )
			break
	
print "\n".join([str(d.total_seconds()/60/60/24) for d in delay_times])

########NEW FILE########
__FILENAME__ = todd_akin
#!script

from datetime import datetime, date
from numpy import mean, median, percentile
from scipy.stats import percentileofscore

from person.models import Person, PersonRole
from bill.models import Bill, Cosponsor, BillType
from bill.status import BillStatus
from committee.models import CommitteeMember, CommitteeMemberRole
from vote.models import VoteCategory, VoteOption

todd_akin = Person.objects.get(id=400005)
todd_akin_role = todd_akin.roles_condensed()[0]

all_congressmen =set([p for p in Person.objects\
	.filter(roles__enddate__gt=datetime.now(), roles__role_type=todd_akin_role.role_type).distinct()\
	]) 

republican_congresspeeps_serving_as_long = set([p for p in Person.objects\
	.filter(roles__enddate__gt=datetime.now(), roles__role_type=todd_akin_role.role_type, roles__party=todd_akin_role.party).distinct()\
	if p.roles_condensed()[0].startdate <= todd_akin_role.startdate])

republican_congresspeeps = set([p for p in Person.objects\
	.filter(roles__enddate__gt=datetime.now(), roles__role_type=todd_akin_role.role_type, roles__party=todd_akin_role.party).distinct()])

republican_new_congresspeeps = set([p for p in Person.objects\
	.filter(roles__enddate__gt=datetime.now(), roles__role_type=todd_akin_role.role_type, roles__party=todd_akin_role.party).distinct() if p.roles_condensed()[0].startdate == date(2011, 1, 5)])

republican_non_new_congresspeeps = set([p for p in Person.objects\
	.filter(roles__enddate__gt=datetime.now(), roles__role_type=todd_akin_role.role_type, roles__party=todd_akin_role.party).distinct() if p.roles_condensed()[0].startdate < date(2011, 1, 1)])

democratic_congresspeeps = set([p for p in Person.objects\
	.filter(roles__enddate__gt=datetime.now(), roles__role_type=todd_akin_role.role_type).exclude(roles__party=todd_akin_role.party).distinct()])

def is_chair(person):
	return 1 if CommitteeMember.objects.filter(person=person, role=CommitteeMemberRole.chairman, committee__committee=None).exists() else 0

def pct_dem_cosponsors(person):
	c = Cosponsor.objects.filter(bill__sponsor=person)
	return float(c.filter(role__party="Democrat").count())/float(c.count())

def pct_dem_bills(person):
	c = Cosponsor.objects.filter(person=person)
	return float(c.filter(bill__sponsor_role__party="Democrat").count())/float(c.count())

def leadership_score(person):
	from person.analysis import load_sponsorship_analysis
	v = load_sponsorship_analysis(person)["leadership"]
	if v == None: return None
	return float(v)
	
def bills_enacted(person):
	return Bill.objects.filter(sponsor=person, bill_type=BillType.house_bill, current_status__in=BillStatus.final_status_passed_bill).count()

def make_stat(descr, pop, stat):
	vals = [stat(p) for p in pop]
	vals = [v for v in vals if v != None]
	v = stat(todd_akin)
	print descr
	print "value", round(v, 2), "N=", len(vals), "mean", round(mean(vals), 2), "median", round(median(vals), 2), "percentile", round(percentileofscore(vals, v))
	print

make_stat("#enacted; congressmen", all_congressmen, bills_enacted)
make_stat("#enacted; republicans tenure as long", republican_congresspeeps_serving_as_long, bills_enacted)

make_stat("leadership; republican", republican_congresspeeps, leadership_score)
make_stat("leadership; republican tenure as long", republican_congresspeeps_serving_as_long, leadership_score)
make_stat("leadership; republican non-freshmen", republican_non_new_congresspeeps, leadership_score)
make_stat("leadership; republican freshmen", republican_new_congresspeeps, leadership_score)


make_stat("chair; republican", republican_congresspeeps, is_chair)
make_stat("chair; republican tenure as long", republican_congresspeeps_serving_as_long, is_chair)

print "cosponsored", Cosponsor.objects.filter(person=todd_akin).count()
make_stat("% dem bills; republican", republican_congresspeeps, pct_dem_bills)
make_stat("% dem bills; republican tenure as long", republican_congresspeeps_serving_as_long, pct_dem_bills)
make_stat("% dem bills; republican non-freshmen", republican_non_new_congresspeeps, pct_dem_bills)
make_stat("% dem bills; republican freshmen", republican_new_congresspeeps, pct_dem_bills)

print "sponsored", Bill.objects.filter(sponsor=todd_akin).count()
make_stat("% cosponsors dem; republican", republican_congresspeeps, pct_dem_cosponsors)
make_stat("% cosponsors dem; republican tenure as long", republican_congresspeeps_serving_as_long, pct_dem_cosponsors)
make_stat("% cosponsors dem; republican non-freshmen", republican_non_new_congresspeeps, pct_dem_cosponsors)
make_stat("% cosponsors dem; republican freshmen", republican_new_congresspeeps, pct_dem_cosponsors)


########NEW FILE########
__FILENAME__ = billtext

if __name__ == "__main__":
    import sys, os
    sys.path.insert(0, "..")
    sys.path.insert(0, ".")
    sys.path.insert(0, "lib")
    sys.path.insert(0, ".env/lib/python2.7/site-packages")
    os.environ["DJANGO_SETTINGS_MODULE"] = 'settings'

import datetime, lxml, os.path, re

bill_gpo_status_codes = {
    "ah": "Amendment",
    "ah2": "Amendment",
    "as": "Amendment",
    "as2": "Amendment",
    "ash": "Additional Sponsors",
    "sas": "Additional Sponsors",
    "sc": "Sponsor Change",
    "ath": "Resolution Agreed to",
    "ats": "Resolution Agreed to",
    "cdh": "Committee Discharged",
    "cds": "Committee Discharged",
    "cph": "Considered and Passed by the House",
    "cps": "Considered and Passed by the Senate",
    "eah": "Passed the House (Engrossed) with an Amendment",
    "eas": "Passed the Senate (Engrossed) with an Amendment",
    "eh": "Passed the House (Engrossed)",
    "ehr": "Passed the House (Engrossed)/Reprint",
    "eh_s": "Passed the House (Engrossed)/Star Print",
    "enr": "Passed Congress/Enrolled Bill",
    "renr": "Passed Congress/Re-enrolled",
    "es": "Passed the Senate (Engrossed)",
    "esr": "Passed the Senate (Engrossed)/Reprint",
    "es_s": "Passed the Senate (Engrossed)/Star Print",
    "fah": "Failed Amendment",
    "fps": "Failed Passage",
    "hdh": "Held at Desk in the House",
    "hds": "Held at Desk in the Senate",
    "ih": "Introduced",
    "ihr": "Introduced/Reprint",
    "ih_s": "Introduced/Star Print",
    "is": "Introduced",
    "isr": "Introduced/Reprint",
    "is_s": "Introduced/Star Print",
    "iph": "Indefinitely Postponed in the House",
    "ips": "Indefinitely Postponed in the Senate",
    "lth": "Laid on Table in the House",
    "lts": "Laid on Table in the Senate",
    "oph": "Ordered to be Printed",
    "ops": "Ordered to be Printed",
    "pch": "Placed on Calendar in the House",
    "pcs": "Placed on Calendar in the Senate",
    "pp": "Public Print",
    "rah": "Referred to House Committee (w/ Amendments)",
    "ras": "Referred to Senate Committee (w/ Amendments)",
    "rch": "Reference Change",
    "rcs": "Reference Change",
    "rdh": "Received by the House",
    "rds": "Received by the Senate",
    "reah": "Passed the House (Re-Engrossed) with an Amendment",
    "re": "Reprint of an Amendment",
    "res": "Passed the Senate (Re-Engrossed) with an Amendment",
    "rfh": "Referred to House Committee",
    "rfhr": "Referred to House Committee/Reprint",
    "rfh_s": "Referred to House Committee/Star Print",
    "rfs": "Referred to Senate Committee",
    "rfsr": "Referred to Senate Committee/Reprint",
    "rfs_s": "Referred to Senate Committee/Star Print",
    "rh": "Reported by House Committee",
    "rhr": "Reported by House Committee/Reprint",
    "rh_s": "Reported by House Committee/Star Print",
    "rs": "Reported by Senate Committee",
    "rsr": "Reported by Senate Committee/Reprint",
    "rs_s": "Reported by Senate Committee/Star Print",
    "rih": "Referral Instructions in the House",
    "ris": "Referral Instructions in the Senate",
    "rth": "Referred to House Committee",
    "rts": "Referred to Senate Committee",
    "s_p": "Star Print of an Amendment",
    "fph": "Failed Passage in the House",
    "fps": "Failed Passage in the Senate",
    }

def get_gpo_status_code_name(doc_version):
    # handle e.g. "eas2"
    digit_suffix = ""
    while len(doc_version) > 0 and doc_version[-1].isdigit():
        digit_suffix = doc_version[-1] + digit_suffix
        doc_version = doc_version[:-1]
    
    doc_version_name = bill_gpo_status_codes.get(doc_version, "Unknown Status (%s)" % doc_version)

    if digit_suffix: doc_version_name += " " + digit_suffix

    return doc_version_name
    
def get_current_version(bill):
    return load_bill_text(bill, None, mods_only=True)["doc_version"]
    
def load_bill_mods_metadata(fn):
    mods = lxml.etree.parse(fn)
    ns = { "mods": "http://www.loc.gov/mods/v3" }
    
    docdate = mods.xpath("string(mods:originInfo/mods:dateIssued)", namespaces=ns)
    gpo_url = "http://www.gpo.gov/fdsys/search/pagedetails.action?packageId=" + mods.xpath("string(mods:recordInfo/mods:recordIdentifier[@source='DGPO'])", namespaces=ns)
    #gpo_url = mods.xpath("string(mods:identifier[@type='uri'])", namespaces=ns)
    gpo_pdf_url = mods.xpath("string(mods:location/mods:url[@displayLabel='PDF rendition'])", namespaces=ns)
    doc_version = mods.xpath("string(mods:extension/mods:billVersion)", namespaces=ns)
    numpages = mods.xpath("string(mods:physicalDescription/mods:extent)", namespaces=ns)
    if numpages: numpages = re.sub(r" p\.$", " pages", numpages)
    
    docdate = datetime.date(*(int(d) for d in docdate.split("-")))
    doc_version_name = get_gpo_status_code_name(doc_version)

    # load a list of citations as marked up by GPO
    citations = []
    for cite in mods.xpath("//mods:identifier", namespaces=ns):
        if cite.get("type") == "USC citation":
            citations.append( parse_usc_citation(cite) )
        elif cite.get("type") == "Statute citation":
            citations.append({ "type": "statutes_at_large", "text": cite.text })
        elif cite.get("type") == "public law citation":
            try:
                congress_cite, slip_law_num = re.match(r"Public Law (\d+)-(\d+)$", cite.text).groups()
                citations.append({ "type": "slip_law", "text": cite.text, "congress": int(congress_cite), "number": int(slip_law_num) })
            except:
                citations.append({ "type": "unknown", "text": cite.text })
            
    return {
        "docdate": docdate,
        "gpo_url": gpo_url,
        "gpo_pdf_url": gpo_pdf_url,
        "doc_version": doc_version,
        "doc_version_name": doc_version_name,
        "numpages": numpages,
        "citations": citations,
    }

def parse_usc_citation(cite):
    m = re.match(r"(\d+)\s*U.S.C.(\s*App.)?\s*Chapter\s*(\S+)$", cite.text)
    if m:
        title_cite, title_app_cite, chapter_cite = m.groups()
        if title_app_cite: title_cite += "a"
        return { "type": "usc-chapter", "text": cite.text, "title": title_cite, "chapter": chapter_cite, "key" : "usc/chapter/" + title_cite + "/" + chapter_cite }
    
    m = re.match(r"(\d+\S*)\s*U.S.C.(\s*App.)?\s*([^\s(]+?)?\s*(\(.*|et ?seq\.?|note)?$", cite.text)
    if m:
        title_cite, title_app_cite, sec_cite, para_cite = m.groups()
        if title_app_cite: title_cite += "a"
        if para_cite and para_cite.strip() == "": para_cite = None
        
        # The citation may contain any number of dashes. At most one may indicate
        # a range, and the rest are dashes that appear within section numbers themselves.
        # Loop through all of the dashes and check if it splits the citation into two
        # valid section numbers (i.e. actually appears in the USC) that are also near
        # each other (same parent).
        #
        # A nice example is 16 U.S.C. 3839aa-8, where both "3839aa" and "8" are valid
        # sections but are far apart, so this does not indicate a range.
        #
        # Skip this if there is a paragraph in the citation --- that can't be appended
        # to a range.
        sec_dash_parts = sec_cite.split("-") if not para_cite else []
        for i in xrange(1, len(sec_dash_parts)):
            # Split the citation around the dash to check each half.
            sec_parts = ["-".join(sec_dash_parts[:i]),
                         "-".join(sec_dash_parts[i:])]
            from models import USCSection
            matched_secs = list(USCSection.objects.filter(citation__in = 
                [("usc/" + title_cite + "/" + sec_part) for sec_part in sec_parts]))
            if len(matched_secs) != 2: continue # one or the other was not a valid section number
            if matched_secs[0].parent_section_id != matched_secs[1].parent_section_id: continue # not nearby
            return { "type": "usc", "text": cite.text, "title": title_cite, "section": sec_parts[0], "paragraph": None, "range_to_section": sec_parts[1], "key" : "usc/" + title_cite + "/" + sec_parts[0] }
            
        # Not a range.
        return { "type": "usc-section", "text": cite.text, "title": title_cite, "section": sec_cite, "paragraph" : para_cite, "key" : "usc/" + title_cite + "/" + sec_cite }
        
    return { "type": "unknown", "text": cite.text }

def get_bill_text_metadata(bill, version):
    from bill.models import BillType # has to be here and not module-level to avoid cyclic dependency
    import glob, json

    bt = BillType.by_value(bill.bill_type).slug
    basename = "data/congress/%d/bills/%s/%s%d/text-versions" % (bill.congress, bt, bt, bill.number)
    
    if version == None:
        # Cycle through files to find most recent version by date.
        dat = None
        for versionfile in glob.glob(basename + "/*/data.json"):
            d = json.load(open(versionfile))
            if not dat or d["issued_on"] > dat["issued_on"]:
                dat = d
        if not dat: return None
    else:
        dat = json.load(open(basename + "/%s/data.json" % version))
        
    basename += "/" + dat["version_code"]

    bt2 = BillType.by_value(bill.bill_type).xml_code
    html_fn = "data/us/bills.text/%s/%s/%s%d%s.html" % (bill.congress, bt2, bt2, bill.number, dat["version_code"])

    if os.path.exists(basename + "/mods.xml"):
        dat["mods_file"] = basename + "/mods.xml"

    # get a plain text file if one exists
    if os.path.exists(basename + "/document.txt"):
        dat["text_file"] = basename + "/document.txt"
        dat["has_displayable_text"] = True

        for source in dat.get("sources", []):
            if source["source"] == "statutes":
                dat["text_file_source"] = "statutes"

    # get an HTML file if one exists
    if os.path.exists(html_fn):
        dat["html_file"] = html_fn
        dat["has_displayable_text"] = True

    # get a PDF file if one exists
    pdf_fn = "data/us/bills.text/%s/%s/%s%d%s.pdf" % (bill.congress, bt2, bt2, bill.number, dat["version_code"])
    if os.path.exists(pdf_fn):
        dat["pdf_file"] = pdf_fn
        dat["has_thumbnail"] = True
        dat["thumbnail_path"] = bill.get_absolute_url() + "/_text_image"

    # get an XML file if one exists
    if os.path.exists(basename + "/catoxml.xml"):
        dat["xml_file"] = basename + "/catoxml.xml"
        dat["has_displayable_text"] = True
        dat["xml_file_source"] = "cato-deepbills"
    elif os.path.exists(basename + "/document.xml"):
        dat["xml_file"] = basename + "/document.xml"
        dat["has_displayable_text"] = True

    return dat
        
def load_bill_text(bill, version, plain_text=False, mods_only=False, with_citations=False):
    # Load bill text info from the Congress project data directory.
    # We have JSON files for metadata and plain text files mirrored from GPO
    # containing bill text (either from the Statutes at Large OCR'ed text
    # layers, or from GPO FDSys's BILLS collection).
    
    dat = get_bill_text_metadata(bill, version)
    if not dat:
        # No text is available.
        if plain_text:
            return "" # for indexing, just return empty string if no text is available
        raise IOError("Bill text is not available for this bill.")

    ret = {
        "bill_id": bill.id,
        "bill_name": bill.title,
        "has_displayable_text": dat.get("has_displayable_text"),
    }

    # Load basic metadata from a MODS file if one exists.
    if "mods_file" in dat:
        ret.update(load_bill_mods_metadata(dat["mods_file"]))

    # Otherwise fall back on using the text-versions data.json file. We may have
    # this for historical bills that we don't have a MODS file for.
    else:
        gpo_url = dat["urls"]["pdf"]

        m = re.match(r"http://www.gpo.gov/fdsys/pkg/(STATUTE-\d+)/pdf/(STATUTE-\d+-.*).pdf", gpo_url)
        if m:
            # TODO (but not needed right now): Docs from the BILLS collection.
            gpo_url = "http://www.gpo.gov/fdsys/granule/%s/%s/content-detail.html" % m.groups()

        ret.update({
            "docdate": datetime.date(*(int(d) for d in dat["issued_on"].split("-"))),
            "gpo_url": gpo_url,
            "gpo_pdf_url": dat["urls"]["pdf"],
            "doc_version": dat["version_code"],
            "doc_version_name": get_gpo_status_code_name(dat["version_code"]),
        })

    # Pass through some fields.
    for f in ('html_file', 'pdf_file', 'has_thumbnail', 'thumbnail_path'):
        if f in dat:
            ret[f] = dat[f]

    if with_citations: #and and not settings.DEBUG:
        load_citation_info(ret)

    # If the caller only wants metadata, return it.
    if mods_only:
        return ret

    if "xml_file" in dat and not plain_text:
        # convert XML on the fly to HTML
        import lxml.html, congressxml
        ret.update({
            "text_html": lxml.html.tostring(congressxml.convert_xml(dat["xml_file"])),
            "source": dat.get("xml_file_source"),
        })

    elif "html_file" in dat and not plain_text:
        # This will be for bills around the 103rd-108th Congresses when
        # bill text is available from GPO but not in XML.
        ret.update({
            "text_html": open(dat["html_file"]).read().decode("utf8"),
        })

    elif "text_file" in dat:
        # bill text from the Statutes at Large, or when plain_text is True then from GPO

        bill_text_content = open(dat["text_file"]).read().decode("utf8")

        # In the GPO BILLS collection, there's gunk at the top and bottom that we'd
        # rather just remove: metadata in brackets at the top, and <all> at the end.
        # We remove it because it's not really useful when indexing.
        if bill_text_content:
            bill_text_content = re.sub(r"^\s*(\[[^\n]+\]\s*)*", "", bill_text_content)
            bill_text_content = re.sub(r"\s*<all>\s*$", "", bill_text_content)

        # Caller just wants the plain text?
        if plain_text:
            # replace form feeds (OCR'd layers only) with an indication of the page break
            return bill_text_content.replace(u"\u000C", "\n=============================================\n")
            
        # Return the text wrapped in <pre>, and replace form feeds with an <hr>.
        import cgi
        bill_text_content = "<pre>" + cgi.escape(bill_text_content) + "</pre>"
        bill_text_content = bill_text_content.replace(u"\u000C", "<hr>") # (OCR'd layers only)

        ret.update({
            "text_html": bill_text_content,
            "source": dat.get("text_file_source"),
        })

    return ret

def load_citation_info(metadata):
    if "citations" not in metadata: return

    from models import USCSection
    from search import parse_slip_law_number
    import re

    # gather the citations listed in the MODS file

    slip_laws = []
    statutes = []
    usc_sections = []
    other = []

    usc_other = USCSection(name="Other Citations", ordering=99999)

    for cite in metadata["citations"]:
        if cite["type"] == "slip_law":
            slip_laws.append(cite)
            cite["bill"] = parse_slip_law_number(cite["text"])
        elif cite["type"] == "statutes_at_large":
            statutes.append(cite)
        elif cite["type"] in ("usc-section", "usc-chapter"):
            # Build a tree of title-chapter-...-section nodes so we can
            # display the citations in context.
            try:
                sec_obj = USCSection.objects.get(citation=cite["key"])
            except: # USCSection.DoesNotExist and MultipleObjectsReturned both possible
                # create a fake entry for the sake of output
                # the 'id' field is set to make these objects properly hashable
                sec_obj = USCSection(id=cite["text"], name=cite["text"], parent_section=usc_other)

            if "range_to_section" in cite:
                sec_obj.range_to_section = cite["range_to_section"]

            sec_obj.link = sec_obj.get_cornell_lii_link(cite.get("paragraph"))

            usc_sections.append(sec_obj)
        else:
            other.append(cite)

    # sort slip laws
    slip_laws.sort(key = lambda x : (x["congress"], x["number"]))

    # build a tree for USC citations

    usc = { }
    for sec_obj in usc_sections:
            # recursively go up to the title to find the path from title to this section
            path = [sec_obj]
            so = sec_obj
            while so.parent_section:
                so = so.parent_section
                so.link = so.get_cornell_lii_link()
                path.append(so)

            # now create a tree from the path
            container = usc
            for p in reversed(path):
                container["_count"] = container.get("_count", 0) + 1
                if p not in container: container[p] = { }
                container = container[p]

    # restructure the tree into a flattened list with indentation attributes on each row
    def ucfirst(s): return s[0].upper() + s[1:]
    def rebuild_usc_sec(seclist, indent=0):
        ret = []
        seclist = [kv for kv in seclist.items() if kv[0] != "_count"]
        seclist = sorted(seclist, key=lambda x : x[0].ordering)
        for sec, subparts in seclist:
            ret.append({
                "text": (ucfirst(sec.level_type + ((" " + sec.number) if sec.number else "") + (": " if sec.name else "")) if sec.level_type else "") + (sec.name_recased if sec.name else ""),
                "link": getattr(sec, "link", None),
                "range_to_section": getattr(sec, "range_to_section", None),
                "indent": indent,
            })
            ret.extend(rebuild_usc_sec(subparts, indent=indent+1))
        return ret
    usc = rebuild_usc_sec(usc)

    metadata["citations"] = {
        "slip_laws": slip_laws,
        "statutes": statutes,
        "usc": usc,
        "other": other,
        "count": len(slip_laws)+len(statutes)+len(usc)+len(other)
    }

def compare_xml_text(doc1, doc2, timelimit=10):
    # Compare the text of two XML documents, marking up each document with new
    # <span> tags. The documents are modified in place.
    
    def make_bytes(s):
        if type(s) != str:
            s = s.encode("utf8")
        else:
            pass # assume already utf8
        return s
    
    def serialize_document(doc):
        from StringIO import StringIO
        class State(object):
            pass
        state = State()
        state.text = StringIO()
        state.offsets = list()
        state.charcount = 0
        def append_text(text, node, texttype, state):
            if not text: return
            text = make_bytes(text)
            state.text.write(text)
            state.offsets.append([state.charcount, len(text), node, texttype])
            state.charcount += len(text)
        def recurse_on(node, state):
            # etree handles text oddly: node.text contains the text of the element, but if
            # the element has children then only the text up to its first child, and node.tail
            # contains the text after the element but before the next sibling. To iterate the
            # text in document order, we cannot use node.iter().
            append_text(node.text, node, 0, state) # 0 == .text
            for child in node:
                recurse_on(child, state)
            append_text(node.tail, node, 1, state) # 1 == .tail
        recurse_on(doc.getroot(), state)
        state.text = state.text.getvalue()
        return state
        
    doc1data = serialize_document(doc1)
    doc2data = serialize_document(doc2)
    
    def simplify_diff(diff_iter):
        # Simplify the diff by collapsing any regions with more changes than
        # similarities, so that small unchanged regions appear within the larger
        # set of changes (as changes, not as similarities).
        prev = []
        for op, length in diff_iter:
            if len(prev) < 2:
                prev.append( (op, length) )
            else:
                # If the op two hunks ago is the same as the current hunk and
                # the total lengths of two hunks ago and the current is creater
                # than the length of the hunk in the middle...
                if op in ('-', '+') and prev[0][0] == op and prev[1][0] == '=' \
                    and prev[0][1] + length > (prev[1][1]-1)**1.4:
                    prev.append( (op, prev[0][1] + prev[1][1] + length) )
                    prev.append( ('-' if op == '+' else '+', prev[1][1]) )
                    prev.pop(0)
                    prev.pop(0)
                    
                # If the two hunks differ in op, combine them a different way.
                elif op in ('-', '+') and prev[0][0] in ('-', '+') and prev[1][0] == '=' \
                    and prev[0][1] + length > (prev[1][1]-1)**1.4:
                    prev.append( (prev[0][0], prev[0][1] + prev[1][1]) )
                    prev.append( (op, prev[1][1] + length) )
                    prev.pop(0)
                    prev.pop(0)
                
                else:
                    yield prev.pop(0)
                    prev.append( (op, length) )
        for p in prev:
            yield p
    
    def reformat_diff(diff_iter):
        # Re-format the operations of the diffs to indicate the byte
        # offsets on the left and right.
        left_pos = 0
        right_pos = 0
        for op, length in diff_iter:
            left_len = length if op in ("-", "=") else 0
            right_len = length if op in ("+", "=") else 0
            yield (op, left_pos, left_len, right_pos, right_len)
            left_pos += left_len
            right_pos += right_len
           
    def slice_bytes(text, start, end):
        # Return the range [start:length] from the byte-representation of
        # the text string, returning unicode. If text is unicode, convert to
        # bytes, take the slice, and then convert back from UTF8 as best as
        # possible since we may have messed up the UTF8 encoding.
       return make_bytes(text)[start:end].decode("utf8", "replace")
           
    def mark_text(doc, offsets, pos, length, mode):
       # Wrap the text in doc at position pos and of byte length length
       # with a <span>, and set the class to mode.
       def make_wrapper(label=None):
           wrapper_node = lxml.etree.Element('span')
           wrapper_node.set('class', mode)
           #if label: wrapper_node.set('make_wrapper_label', label)
           return wrapper_node
       for i, (off, offlen, offnode, offtype) in enumerate(offsets):
           # Does the change intersect this span?
           if pos >= off+offlen or pos+length <= off: continue
           
           if pos == off and length >= offlen:
               # The text to mark is the whole part of this span,
               # plus possibly some more.
               if offtype == 0:
                   # It is the node's .text, meaning replace the text
                   # that exists up to the node's first child.
                   w = make_wrapper("A")
                   w.text = offnode.text
                   offnode.text = ""
                   offnode.insert(0, w)
               else:
                   # It is the node's .tail, meaning replace the text
                   # that exists after the element and before the next
                   # sibling.
                   w = make_wrapper("B")
                   offtail = offnode.tail # see below
                   offnode.addnext(w)
                   w.text = offtail
                   w.tail = None
                   offnode.tail = ""
           elif pos == off and length < offlen:
               # The text to mark starts here but ends early.
               if offtype == 0:
                   w = make_wrapper("C")
                   offnode.insert(0, w)
                   w.text = slice_bytes(offnode.text, 0, length)
                   w.set("txt", slice_bytes(offnode.text, 0, length))
                   w.tail = slice_bytes(offnode.text, length, offlen)
                   offnode.text = ""
               else:
                   w = make_wrapper("D")
                   offtail = offnode.tail # get it early to avoid any automatic space normalization
                   offnode.addnext(w) # add it early for the same reason
                   w.text = slice_bytes(offtail, 0, length)
                   w.tail = slice_bytes(offtail, length, offlen)
                   offnode.tail = ""
               # After this point we may come back to edit more text in this
               # node after this point. However, what was in this node at offset
               # x is now in the tail of the new wrapper node at position x-length.
               offsets[i] = (off+length, offlen-length, w, 1)
           elif pos > off and pos+length >= off+offlen:
               # The text to mark starts part way into this span and ends
               # at the end (or beyond).
               if offtype == 0:
                   w = make_wrapper("E")
                   offnode.insert(0, w)
                   w.text = slice_bytes(offnode.text, pos-off, offlen)
                   offnode.text = slice_bytes(offnode.text, 0, pos-off)
               else:
                   w = make_wrapper("F")
                   offtail = offnode.tail # see above
                   offnode.addnext(w) # see above
                   w.text = slice_bytes(offtail, pos-off, offlen)
                   w.tail = None
                   offnode.tail = slice_bytes(offtail, 0, pos-off)
           elif pos > off and pos+length < off+offlen:
               # The text to mark starts part way into this span and ends
               # early.
               if offtype == 0:
                   w = make_wrapper("G")
                   offnode.insert(0, w)
                   w.text = slice_bytes(offnode.text, pos-off, (pos-off)+length)
                   w.tail = slice_bytes(offnode.text, (pos-off)+length, offlen)
                   offnode.text = slice_bytes(offnode.text, 0, pos-off)
               else:
                   #if len(make_bytes(offnode.tail)) != offlen: raise Exception(str(len(make_bytes(offnode.tail))) + "/" + str(offlen) + "/" + lxml.etree.tostring(offnode))
                   w = make_wrapper("H")
                   offtail = offnode.tail # see above
                   offnode.addnext(w) # see above
                   w.text = slice_bytes(offtail, pos-off, (pos-off)+length)
                   w.tail = slice_bytes(offtail, (pos-off)+length, offlen)
                   offnode.tail = slice_bytes(offtail, 0, pos-off)
               # After this point we may come back to edit more text in this
               # node after this point. However, what was in this node at offset
               # x is now in the tail of the new wrapper node at position x-length.
               offsets[i] = (off+(pos-off)+length, offlen-(pos-off)-length, w, 1)
           else:
               raise Exception()
           
           if pos+length > off+offlen:
               d = off+offlen - pos
               pos += d
               length -= d
               if length <= 0: return
           
    def get_bounding_nodes(pos, length, offsets):
       nodes = []
       for off, offlen, offnode, offtype in offsets:
           if off <= pos < off+offlen:
               nodes.append(offnode)
           if off <= pos+length < off+offlen:
               nodes.append(offnode)
       if len(nodes) == 0: return None
       return nodes[0], nodes[-1]
    def mark_correspondence(leftnode, rightnode, idx, ab):
        if not leftnode.get("id"): leftnode.set("id", "left_%d%s" % (idx, ab))
        if not rightnode.get("id"): rightnode.set("id", "right_%d%s" % (idx, ab))
        leftnode.set("cw_" + ab, rightnode.get("id"))
        rightnode.set("cw_" + ab, leftnode.get("id"))
           
    import diff_match_patch
    diff = diff_match_patch.diff(doc1data.text, doc2data.text, timelimit=timelimit)
    diff = reformat_diff(simplify_diff(diff))
    idx = 0
    for op, left_pos, left_len, right_pos, right_len in diff:
        idx += 1
        left_nodes = get_bounding_nodes(left_pos, left_len, doc1data.offsets)
        right_nodes = get_bounding_nodes(right_pos, right_len, doc2data.offsets)
        if left_nodes and right_nodes:
            mark_correspondence(left_nodes[0], right_nodes[0], idx, "top")
            mark_correspondence(left_nodes[1], right_nodes[1], idx, "bot")
        
        if op == "=" and doc1data.text[left_pos:left_pos+left_len] == doc2data.text[right_pos:right_pos+right_len]: continue
        if left_len > 0: mark_text(doc1, doc1data.offsets, left_pos, left_len, "del" if right_len == 0 else "change")
        if right_len > 0: mark_text(doc2, doc2data.offsets, right_pos, right_len, "ins" if left_len == 0 else "change")
    
    return doc1, doc2
    
if __name__ == "__main__":
    from bill.models import Bill, BillType
    load_bill_text(Bill.objects.get(congress=112, bill_type=BillType.house_bill, number=9), None)
    #doc1 = lxml.etree.parse("data/us/bills.text/112/h/h3606ih.html")
    #doc2 = lxml.etree.parse("data/us/bills.text/112/h/h3606eh.html")
    #compare_xml_text(doc1, doc2)
    #print lxml.etree.tostring(doc2)

########NEW FILE########
__FILENAME__ = bill_or_not
#!script

from bill.models import *
from registration.helpers import json_response

from common.decorators import render_to
from twostream.decorators import anonymous_view

import random, codecs

@anonymous_view
@render_to('bill/bill_or_not.html')
def bill_or_not(request):
	return { }

pregen_bill_titles = None
def make_random_bill_title(bill_type):
	# load pregenerated bill titles
	global pregen_bill_titles
	if pregen_bill_titles == None:
		pregen_bill_titles = { "bill": [], "resolution": [] }
		for bill_type, lst in pregen_bill_titles.items():
			with codecs.open("data/misc/april_fools_bill_titles_%s.txt" % bill_type, "r", "utf-8") as f:
				for line in f:
					lst.append(line.strip())

	return random.choice(pregen_bill_titles[bill_type])

@json_response
def load_game(request):
	type_map = { "bill": (BillType.house_bill, BillType.senate_bill),
		"resolution": (BillType.house_resolution, BillType.senate_resolution) }
	
	bill_type = random.choice(["bill", "bill", "resolution"]) # don't do resolutions so much
	qs = Bill.objects.filter(bill_type__in=type_map[bill_type], congress__gt=109)
	actual_bill = qs[random.randint(0, qs.count()-1)]

	return {
		"bill_type": bill_type,
		"bill_number": actual_bill.display_number_no_congress_number,
		"actual_bill_title": actual_bill.title_no_number,
		"actual_bill_link": actual_bill.get_absolute_url(),
		"actual_bill_intro_date": actual_bill.introduced_date.strftime("%b %d, %Y"),
		"fake_bill_title": make_random_bill_title(bill_type),
	}

if __name__ == "__main__":
	
	# Pre-generate 10,000 random bill titles.

	from nltk.model.ngram import NgramModel
	
	import re
	
	corpus = { "bill": [], "resolution": [] }
	for b in Bill.objects.filter(congress__gte=109):
		title = b.title_no_number + " ###"
		if title.startswith("To "): continue
		title = re.sub(r" \d\d\d\d", " 2015", title)
		title = re.sub(r"\.$", "", title)
		corpus[b.noun].append( title.split(" ") )
		
	# Generate a few separate models.
	models = {
		("bill", 2): NgramModel(2, corpus["bill"]),
		("bill", 3): NgramModel(3, corpus["bill"]),
		("resolution", 2): NgramModel(2, corpus["resolution"]),
		("resolution", 3): NgramModel(3, corpus["resolution"]),
	}
	
	def make_random_bill_title(bill_type):
		# Generate a sentence, one word at a time.
		sentence = []
		while True:
			model = models[(bill_type, 2 if (len(sentence) % 2) == 0 else 3)]
			wd = model.choose_random_word(sentence)
			
			if wd == "###":
				if len(sentence) > 6:
					# finished
					break
				else:
					# sentence was too short, try again from scratch
					sentence = []
					continue
					
			sentence.append(wd)
			
			# Are we *too* probable? I don't want to generate actual bill titles!
			# If so, start over.
			if len(sentence) > 4:
				try:
					if model.entropy(sentence) < len(sentence) * 5.0:
						sentence = []
						continue
				except ValueError:
					pass # infinite entropy
			
			if len(sentence) > 25:
				# sentence was too long, try again
				sentence = []
				continue
		
		return " ".join(sentence)
		
	for bill_type in ("bill", "resolution"):
		with codecs.open("data/misc/april_fools_bill_titles_%s.txt" % bill_type, "w", "utf-8") as f:
			for i in xrange(10000):
				f.write( make_random_bill_title(bill_type) + u"\n" )
	

########NEW FILE########
__FILENAME__ = make_markets
from django.core.management.base import BaseCommand, CommandError
from django.conf import settings
from django.contrib.contenttypes.models import ContentType
from django.contrib.auth.models import User
from django.conf import settings

from optparse import make_option

from bill.models import Bill, BillStatus
from predictionmarket.models import Market, Outcome, Trade, TradingAccount
from bill.prognosis import compute_prognosis

from math import log

class Command(BaseCommand):
	args = ''
	help = 'Make and update prediction markets.'
	
	def handle(self, *args, **options):
		bank = TradingAccount.get(User.objects.get(id=settings.PREDICTIONMARKET_BANK_UID))
		bill_ct = ContentType.objects.get_for_model(Bill)
		
		# For every bill, make a market for its next major step and close any other markets.
		for bill in Bill.objects.filter(congress=settings.CURRENT_CONGRESS):
			market_key = None 			# current market to open
			market_name = None			# name of the market to open
			market_outcomes = None 	# dict of outcome names
			market_close = { }				# markets to close, key is market id and value is the key of the winning outcome
			
			if bill.current_status in (BillStatus.introduced, BillStatus.referred, BillStatus.reported):
				market_key = 0
				market_name = "Will %s pass the %s?" % (bill.display_number, bill.originating_chamber)
				market_outcomes = { 0: "No", 1: "Yes" }
				market_close = { }
			elif bill.current_status in (BillStatus.pass_over_house, BillStatus.pass_over_senate):
				market_key = 1
				market_name = "Will %s pass the %s?" % (bill.display_number, bill.opposite_chamber)
				market_outcomes = { 0: "No", 1: "Yes" }
				market_close = { 0: 1 } # originating chamber passed
			elif bill.current_status in (BillStatus.pass_back_house, BillStatus.pass_back_senate):
				market_key = 2
				market_name = "Will %s pass in identical form in the House and Senate?" % bill.display_number
				market_outcomes = { 0: "No", 1: "Yes" }
				market_close = { 0: 1, 1: 1 } # originating chamber passed, other chamber passed
			elif bill.current_status in (BillStatus.fail_originating_house, BillStatus.fail_originating_senate):
				market_close = { 0: 0 } # originating chamber failed
			elif bill.current_status in (BillStatus.fail_second_house, BillStatus.fail_second_senate):
				market_close = { 0: 1, 1: 0 } # originating chamber passed, second chamber failed
			elif bill.current_status in (BillStatus.passed_constamend, BillStatus.passed_concurrentres, BillStatus.passed_bill,
				BillStatus.override_pass_over_house, BillStatus.override_pass_over_senate, BillStatus.vetoed_pocket,
				BillStatus.vetoed_override_fail_originating_house, BillStatus.vetoed_override_fail_originating_senate,
				BillStatus.vetoed_override_fail_second_house, BillStatus.vetoed_override_fail_second_senate,
				BillStatus.enacted_signed, BillStatus.enacted_veto_override):
				market_close = { 0: 1, 1: 1 } # originating chamber passed, other chamber passed
			elif bill.current_status in (BillStatus.passed_simpleres,):
				market_close = { 0: 1 } # originating chamber passed
			else:
				# Don't know what to do in this state, so just keep whatever we had before.
				continue

			did_see_market = False
			for market in Market.objects.filter(owner_content_type=bill_ct, owner_object_id=bill.id, isopen=True):
				if int(market.owner_key) == market_key:
					did_see_market = True
				elif int(market.owner_key) in market_close:
					print "Closing market:", market
					market.close_market() # do this before the next check to make sure no trades slip in at the last moment
					if Trade.objects.filter(outcome__market=market).exclude(account=bank).count() == 0:
						print "\tDeleting market because the only trader was the bank."
						market.delete() # TODO: Leaves the bank's account balance alone, which is not really good.
					else:
						for outcome in market.outcomes.all():
							outcome.liquidate(1.0 if market_close[int(market.owner_key)] == int(outcome.owner_key) else 0.0)
				else:
					print "Don't know what to do with market:", market, market.owner_key
						
			if not did_see_market and market_key != None:
				starting_price = compute_prognosis(bill)["prediction"] / 100.0
				
				# Create the market.
				m = Market()
				m.owner_object = bill
				m.owner_key = market_key
				m.name = market_name
				m.volatility = 200.0 # large enough so that an integer number of shares can yield .01 precision in pricing
				m.save()
				ocmap = { }
				for k, v in market_outcomes.items():
					o = Outcome()
					o.market = m
					o.owner_key = k
					o.name = v
					o.save()
					ocmap[k] = o
					
				# The bank buys enough shares to make the starting price match our bill prognosis.
				# Since we have two outcomes and the yes-price is exp(q1/b) / (exp(q1/b) + exp(q2/b))
				# then....
				if starting_price < .01: starting_price = .01
				if starting_price > .99: starting_price = .99
				shares = int(round(m.volatility * log(starting_price / (1.0 - starting_price))))
				t = None
				if starting_price > .5 and shares > 0:
					t = Trade.place(bank, ocmap[1], shares, check_balance=False)
				elif starting_price < .5 and shares < 0:
					t = Trade.place(bank, ocmap[0], -shares, check_balance=False)
					
				print "Created market", m
				if t:
					print "\twith", t.shares, "of", t.outcome


########NEW FILE########
__FILENAME__ = models
# -*- coding: utf-8 -*-
from django.db import models
from django.template.defaultfilters import slugify
from django.core.urlresolvers import reverse

from common import enum
from json_field import JSONField

from committee.models import Committee, CommitteeMeeting, CommitteeMember, MEMBER_ROLE_WEIGHTS
from bill.status import BillStatus, get_bill_status_string
from bill.title import get_bill_number, get_primary_bill_title
from bill.billtext import load_bill_text
from us import get_congress_dates

from django.conf import settings

import datetime, os.path, re, urlparse
from lxml import etree

"Enums"

class BillType(enum.Enum):
    # slug must match regex for parse_bill_number
    senate_bill = enum.Item(2, 'S.', slug='s', xml_code='s', full_name="Senate bill", search_help_text="Senate bills", chamber="Senate")
    house_bill = enum.Item(3, 'H.R.', slug='hr', xml_code='h', full_name="House of Representatives bill", search_help_text="House bills", chamber="House")
    senate_resolution = enum.Item(4, 'S.Res.', slug='sres', xml_code='sr', full_name="Senate simple resolution", search_help_text="Senate simple resolutions, which do not have the force of law", chamber="Senate")
    house_resolution = enum.Item(1, 'H.Res.', slug='hres', xml_code='hr', full_name="House simple resolution", search_help_text="House simple resolutions, which do not have the force of law", chamber="House")
    senate_concurrent_resolution = enum.Item(6, 'S.Con.Res.', slug='sconres', full_name="Senate concurrent resolution", xml_code='sc', search_help_text="Concurrent resolutions originating in the Senate, which do not have the force of law", chamber="Senate")
    house_concurrent_resolution = enum.Item(5, 'H.Con.Res.', slug='hconres', full_name="House concurrent resolution", xml_code='hc', search_help_text="Concurrent resolutions originating in the House, which do not have the force of law", chamber="House")
    senate_joint_resolution = enum.Item(8, 'S.J.Res.', slug='sjres', xml_code='sj', full_name="Senate joint resolution", search_help_text="Joint resolutions originating in the Senate, which may be used to enact laws or propose constitutional amendments", chamber="Senate")
    house_joint_resolution = enum.Item(7, 'H.J.Res.', slug='hjres', xml_code='hj', full_name="House joint resolution", search_help_text="Joint resolutions originating in the House, which may be used to enact laws or propose constitutional amendments", chamber="House")


class TermType(enum.Enum):
    old = enum.Item(1, 'Old')
    new = enum.Item(2, 'New')

"Models"

class BillTerm(models.Model):
    """
    Bill Term aka Issua Area

    Old terms:
     * http://www.govtrack.us/data/us/liv.xml
    New terms:
     * http://www.govtrack.us/data/us/liv111.xml
     * http://www.govtrack.us/data/us/crsnet.xml
    """
    term_type = models.IntegerField(choices=TermType)
    name = models.CharField(max_length=255)
    subterms = models.ManyToManyField('self', related_name="parents", symmetrical=False, blank=True)

    def __unicode__(self):
        return self.name
    def __repr__(self):
        return "<BillTerm: %s:%s>" % (TermType.by_value(self.term_type).label, self.name)

    class Meta:
        unique_together = ('name', 'term_type')

    def is_top_term(self):
        return self.parents.count() == 0

    def get_absolute_url(self):
        return "/congress/bills/subjects/%s/%d" % (slugify(self.name).replace('-', '_'), self.id)

    def get_feed(self):
        from events.models import Feed
        return Feed.objects.get_or_create(feedname="crs:%d" % self.id)[0]

    @staticmethod
    def from_feed(feed, test=False):
        if not feed.feedname.startswith("crs:"): raise ValueError(feed.feedname)
        try:
           return BillTerm.objects.get(id=feed.feedname.split(":")[1])
        except BillTerm.DoesNotExist:
            if test: return False
            raise ValueError(feed.feedname)

           # For legacy calls to RSS feeds, try to map subject name to object.
           # Many subject names have changed, so this is the best we can do.
           # Only test against new-style subject terms since we don't generate
           # events for old bills with old subject terms.
           #try:
           #    return BillTerm.objects.get(name=feed.feedname.split(":")[1], term_type=TermType.new)
           #except BillTerm.DoesNotExist:
           #    raise ValueError(feed.feedname)

class Cosponsor(models.Model):
    """A (bill, person) pair indicating cosponsorship, with join and withdrawn dates."""

    person = models.ForeignKey('person.Person', db_index=True, on_delete=models.PROTECT, help_text="The cosponsoring person.")
    role = models.ForeignKey('person.PersonRole', db_index=True, on_delete=models.PROTECT, help_text="The role of the cosponsor at the time of cosponsorship.")
    bill = models.ForeignKey('bill.Bill', db_index=True, help_text="The bill being cosponsored.")
    joined = models.DateField(db_index=True, help_text="The date the cosponsor was added. It is always greater than or equal to the bill's introduced_date.")
    withdrawn = models.DateField(blank=True, null=True, help_text="If the cosponsor withdrew his/her support, the date of withdrawl. Otherwise empty.")
    class Meta:
        unique_together = [("bill", "person"),]

    api_example_parameters = { "sort": "-joined" }

    @property
    def person_name(self):
        # don't need title because it's implicit from the bill type
        from person.name import get_person_name
        return get_person_name(self.person, role_date=self.joined, firstname_position="after", show_title=False)

    # role is a new field which I added with (does not take into account people with overlapping roles such as going from House to Senate on the same day):
    #for role in PersonRole.objects.filter(startdate__lte="1970-01-01", startdate__gt="1960-01-01"):
    #    Cosponsor.objects.filter(
    #        person=role.person_id,
    #        joined__gte=role.startdate,
    #        joined__lte=role.enddate).update(role = role)

class Bill(models.Model):
    """A bill represents a bill or resolution introduced in the United States Congress."""

    title = models.CharField(max_length=255, help_text="The bill's primary display title, including its number.")
    titles = JSONField(default=None) # serialized list of all bill titles as (type, as_of, text)
    bill_type = models.IntegerField(choices=BillType, help_text="The bill's type (e.g. H.R., S., H.J.Res. etc.)")
    congress = models.IntegerField(help_text="The number of the Congress in which the bill was introduced. The current Congress is %d." % settings.CURRENT_CONGRESS)
    number = models.IntegerField(help_text="The bill's number (just the integer part).")
    sponsor = models.ForeignKey('person.Person', blank=True, null=True,
                                related_name='sponsored_bills', help_text="The primary sponsor of the bill.", on_delete=models.PROTECT)
    sponsor_role = models.ForeignKey('person.PersonRole', blank=True, null=True, help_text="The role of the primary sponsor of the bill at the time the bill was introduced.", on_delete=models.PROTECT)
    committees = models.ManyToManyField(Committee, related_name='bills', help_text="Committees to which the bill has been referred.")
    terms = models.ManyToManyField(BillTerm, related_name='bills', help_text="Subject areas associated with the bill.")
    current_status = models.IntegerField(choices=BillStatus, help_text="The current status of the bill.")
    current_status_date = models.DateField(help_text="The date of the last major action on the bill corresponding to the current_status.")
    introduced_date = models.DateField(help_text="The date the bill was introduced.")
    cosponsors = models.ManyToManyField('person.Person', blank=True, through='bill.Cosponsor', help_text="The bill's cosponsors.")
    docs_house_gov_postdate = models.DateTimeField(blank=True, null=True, help_text="The date on which the bill was posted to http://docs.house.gov (which is different from the date it was expected to be debated).")
    senate_floor_schedule_postdate = models.DateTimeField(blank=True, null=True, help_text="The date on which the bill was posted on the Senate Floor Schedule (which is different from the date it was expected to be debated).")
    major_actions = JSONField(default=[]) # serialized list of all major actions (date/datetime, BillStatus, description)

    sliplawpubpriv = models.CharField(max_length=3, choices=[("PUB", "Public"), ("PRI", "Private")], blank=True, null=True, help_text="For enacted laws, whether the law is a public (PUB) or private (PRI) law. Unique with congress and sliplawnum.")
    sliplawnum = models.IntegerField(blank=True, null=True, help_text="For enacted laws, the slip law number (i.e. the law number in P.L. XXX-123). Unique with congress and sliplawpublpriv.")
    #statutescite = models.CharField(max_length=16, blank=True, null=True, help_text="For enacted laws, a normalized U.S. Statutes at Large citation. Available only for years in which the Statutes at Large has already been published.")

    source = models.CharField(max_length=16, choices=[("thomas-legacy", "THOMAS.gov (via GovTrack Legacy Scraper)"), ("thomas-congproj", "THOMAS.gov (via Congress Project)"), ("statutesatlarge", "U.S. Statutes at Large"), ("americanmemory", "LoC American Memory Collection")], help_text="The primary source for this bill's metadata.")
    source_link = models.CharField(max_length=256, blank=True, null=True, help_text="When set, a link to the page on the primary source website for this bill. Set when source='americanmemory' only.")

    # role is a new field added with, but might not be perfect for overlapping roles (see Cosponsor)
    #for role in PersonRole.objects.filter(startdate__gt="1960-01-01"):
    #    Bill.objects.filter(
    #        sponsor=role.person_id,
    #        introduced_date__gte=role.startdate,
    #        introduced_date__lte=role.enddate).update(sponsor_role = role)

    class Meta:
        ordering = ('congress', 'bill_type', 'number')
        unique_together = [('congress', 'bill_type', 'number'),
        ('congress', 'sliplawpubpriv', 'sliplawnum')]

    def __unicode__(self):
        return self.title

    @staticmethod
    def from_congressproject_id(bill_id):
        m = re.match("^([a-z]+)(\d+)-(\d+)$", bill_id)
        if not m: raise ValueError("Invalid bill ID: " + bill_id)
        return Bill.objects.get(congress=int(m.group(3)), bill_type=BillType.by_slug(m.group(1)), number=int(m.group(2)))

    #@models.permalink
    def get_absolute_url(self):
        return reverse('bill_details', args=(self.congress, BillType.by_value(self.bill_type).slug, self.number))

    # indexing
    def get_index_text(self):
        bill_text = load_bill_text(self, None, plain_text=True)
        if self.congress >= 82 and not bill_text: print "NO BILL TEXT", self
        return "\n".join([
            self.title,
            self.display_number_no_congress_number.replace(".", ""),
            self.display_number_no_congress_number.replace(".", "").replace(" ", ""),
            ] + [t[2] for t in self.titles]) \
            + "\n\n" + bill_text
    haystack_index = ('bill_type', 'congress', 'number', 'sponsor', 'current_status', 'terms', 'introduced_date', 'current_status_date', 'committees', 'cosponsors')
    haystack_index_extra = (('proscore', 'Float'), ('sponsor_party', 'MultiValue'), ('usc_citations_uptree', 'MultiValue'))
    def get_terms_index_list(self):
        return set([t.id for t in self.terms.all()])
    def get_committees_index_list(self):
        return [c.id for c in self.committees.all()]
    def get_cosponsors_index_list(self):
        return [c.id for c in self.cosponsors.all()]
    def proscore(self):
        """A modified prognosis score that omits factors associated with uninteresting bills, such as naming post offices. Only truly valid for current bills, and useless to compare across Congresses, but returns a value for all bills."""
        # To aid search, especially for non-current bills, add in something to give most recently active bills a boost.

        type_boost = {
           BillType.senate_bill: 1.0, BillType.house_bill: 1.0,
           BillType.senate_resolution: 0.2, BillType.house_resolution: 0.2,
           BillType.senate_concurrent_resolution: 0.3, BillType.house_concurrent_resolution: 0.3,
           BillType.senate_joint_resolution: 0.75, BillType.house_joint_resolution: 0.75,
        }

        cstart, cend = get_congress_dates(self.congress)
        csd = self.current_status_date
        if hasattr(csd, 'date'): csd = csd.date()
        r = (csd - cstart).days / 365.0 # ranges from 0.0 to about 2.0.
        if self.is_current:
            from prognosis import compute_prognosis
            r += compute_prognosis(self, proscore=True)["prediction"]
        r *= type_boost[self.bill_type]
        return r
    def sponsor_party(self):
        if not self.sponsor_role: return None
        mp = getattr(Bill, "_majority_party", { })
        if self.congress not in mp:
            from prognosis import load_majority_party
            mp[self.congress] = load_majority_party(self.congress)
            Bill._majority_party = mp
        p = self.sponsor_role.party
        return (p, "Majority Party" if p == mp[self.congress][self.bill_type] else "Minority Party")
    def usc_citations_uptree(self):
        # Index the list of citation sections (including all higher levels of hierarchy)
        # using the USCSection object IDs.

        # Load citation information from GPO MODS file.
        try:
            metadata = load_bill_text(self, None, mods_only=True)
        except IOError:
            return []
        if "citations" not in metadata: return []

        # For each USC-type citation...
        ret = set()
        for cite in metadata["citations"]:
            # Load the object, if it exists, and go up the TOC hierarchy indexing at every level.
            if cite["type"] not in ("usc-section", "usc-chapter"): continue
            try:
                sec_obj = USCSection.objects.get(citation=cite["key"])
            except: # USCSection.DoesNotExist and MultipleObjectsReturned both possible
                continue
            while sec_obj:
                ret.add(sec_obj.id)
                sec_obj = sec_obj.parent_section
        return ret

    # api
    api_recurse_on = ("sponsor", "sponsor_role")
    api_recurse_on_single = ("committees", "cosponsors", "terms")
    api_additional_fields = {
        "link": lambda obj : settings.SITE_ROOT_URL + obj.get_absolute_url(),
        "display_number": "display_number_no_congress_number",
        "title_without_number": "title_no_number",
        "bill_resolution_type": "noun",
        "current_status_description": "current_status_description",
        "is_current": "is_current",
        "is_alive": "is_alive",
        "thomas_link": "thomas_link",
        "noun": "noun",
    }
    api_example_id = 76416
    api_example_list = { "sort": "-introduced_date" }

    @property
    def display_number(self):
        """The bill's number, suitable for display, e.g. H.R. 1234. If the bill is for a past session of Congress, includes the Congress number."""
        return get_bill_number(self)
    @property
    def display_number_no_congress_number(self):
        """The bill's number, suitable for display, e.g. H.R. 1234."""
        return get_bill_number(self, show_congress_number="NONE")
    @property
    def display_number_with_congress_number(self):
        return get_bill_number(self, show_congress_number="ALL")

    @property
    def title_no_number(self):
        """The title of the bill without the number."""
        return get_primary_bill_title(self, self.titles, with_number=False)

    @property
    def bill_type_slug(self):
        return BillType.by_value(self.bill_type).slug
    @property
    def bill_type_name(self):
        return BillType.by_value(self.bill_type).full_name
    @property
    def bill_type_name_short(self):
        return self.bill_type_name.replace(" of Representatives", "")
    @property
    def noun(self):
        """The appropriate noun to use to refer to this instance, either 'bill' or 'resolution'."""
        return "bill" if self.bill_type in (BillType.house_bill, BillType.senate_bill) else "resolution"
    @property
    def originating_chamber(self):
        # also see current_status_chamber
        return "House" if self.bill_type in (BillType.house_bill, BillType.house_resolution, BillType.house_joint_resolution, BillType.house_concurrent_resolution) else "Senate"
    @property
    def opposite_chamber(self):
        # also see current_status_chamber
        return "Senate" if self.bill_type in (BillType.house_bill, BillType.house_resolution, BillType.house_joint_resolution, BillType.house_concurrent_resolution) else "House"

    @property
    def how_a_bill_text(self):
        if self.bill_type in (BillType.senate_bill, BillType.house_bill):
            return "A bill must be passed by both the House and Senate in identical form and then be signed by the president to become law."
        elif self.bill_type in (BillType.senate_concurrent_resolution, BillType.house_concurrent_resolution):
            return "A concurrent resolution is often used for matters that affect the rules of Congress or to express the sentiment of Congress. It must be agreed to by both the House and Senate in identical form but is not signed by the president and does not carry the force of law."
        elif self.bill_type in (BillType.senate_joint_resolution, BillType.house_joint_resolution):
            return "A joint resolution is often used in the same manner as a bill. If passed by both the House and Senate in identical form and signed by the president, it becomes a law. Joint resolutions are also used to propose amendments to the Constitution."
        elif self.bill_type in (BillType.senate_resolution, BillType.house_resolution):
            return "A simple resolution is used for matters that affect just one chamber of Congress, often to change the rules of the chamber to set the manner of debate for a related bill. It must be agreed to in the chamber in which it was introduced. It is not voted on in the other chamber and does not have the force of law."
        raise ValueError()

    @property
    def slip_law_number(self):
        if not self.sliplawnum: return None
        return ("Pub" if self.sliplawpubpriv == "PUB" else "Pvt") + (".L. %d-%d" % (self.congress, self.sliplawnum))

    @property
    def cosponsor_count(self):
        return self.cosponsor_records.filter(withdrawn=None).count()
    @property
    def cosponsor_records(self):
        return Cosponsor.objects.filter(bill=self).order_by('joined', 'person__lastname', 'person__firstname')
    @property
    def cosponsor_counts_by_party(self):
        counts = { }
        for p in self.cosponsor_records.filter(withdrawn=None).select_related("role").values_list("role__party", flat=True):
            counts[p] = counts.get(p, 0) + 1
        counts = sorted(list(counts.items()), key=lambda kv : -kv[1])
        return counts

    @property
    def current_status_description(self):
        """Descriptive text for the bill's current status."""
        if self.source == "americanmemory": return None # not known
        return self.get_status_text(self.current_status, self.current_status_date)

    @property
    def is_current(self):
        """Whether the bill was introduced in the current session of Congress."""
        return self.congress == settings.CURRENT_CONGRESS
    @property
    def is_alive(self):
        """Whether the bill was introduced in the current session of Congress and the bill's status is not a final status (i.e. can take no more action like a failed vote)."""
        return self.congress == settings.CURRENT_CONGRESS and self.current_status not in BillStatus.final_status
    @property
    def is_final_status(self):
        """Whether the bill's current status is a final status."""
        return self.current_status in BillStatus.final_status
    def is_success(self):
        """Whether the bill was enacted (for bills) or passed (for resolutions)."""
        return self.current_status in BillStatus.final_status_passed
    @property
    def current_status_chamber(self):
        """Returns 'House', 'Senate', 'Unknown', or 'Done' indicating which chamber is currently considering the
        bill. 'Done' means the bill is dead or out of Congress."""
        if not self.is_alive or self.current_status in (BillStatus.passed_bill,):
            return 'Done'
        if self.current_status in (BillStatus.introduced, BillStatus.referred, BillStatus.reported):
            return self.originating_chamber
        if self.current_status in (BillStatus.pass_over_house, BillStatus.pass_back_house, BillStatus.conference_passed_house, BillStatus.prov_kill_cloturefailed, BillStatus.override_pass_over_house):
            return "Senate"
        if self.current_status in (BillStatus.pass_over_senate, BillStatus.pass_back_senate, BillStatus.conference_passed_senate, BillStatus.prov_kill_suspensionfailed, BillStatus.override_pass_over_senate):
            return "House"
        return "Unknown" # prov_kill_pingpongfail, prov_kill_veto

    def get_approved_links(self):
        return self.links.filter(approved=True)

    def get_prognosis(self):
        if self.congress != settings.CURRENT_CONGRESS: return None
        import prognosis
        prog = prognosis.compute_prognosis(self)
        prog["congressdates"] = get_congress_dates(prog["congress"])
        return prog

    def get_formatted_summary(self):
        s = get_formatted_bill_summary(self)
        # this cleanup doesn't always work because sometimes the line is split between <divs>
        s = re.sub(r"(\d+/\d+/\d\d\d\d)--[^\.]+.\s*(\(This measure has not been amended since it was .*\. The summary of that version is repeated here\.\)\s*)?(" + "|".join(re.escape(t[2]) for t in self.titles) + r")\s*-\s*", lambda m : m.group(1) + ". ", s)
        return s

    def get_upcoming_meetings(self):
        return CommitteeMeeting.objects.filter(when__gt=datetime.datetime.now(), bills=self)

    def get_status_text(self, status, date) :
        status = BillStatus.by_value(status).xml_code
        date = date.replace(year=2000).strftime("%B %d, YYYY").replace(" 0", " ").replace("YYYY", str(date.year)) # historical bills < 1900 would otherwise raise an error
        status = get_bill_status_string(self.is_current, status)
        return status % (self.noun, date)

    @property
    def explanatory_text(self):
        if self.title_no_number.startswith("Providing for consideration of the "): # bill, joint resolution, etc.
            return "This resolution sets the rules for debate for another bill, such as limiting who can submit an amendment and setting floor debate time."
        if self.title_no_number.startswith("An original "):
            return "An \"original bill\" is one which is drafted and approved by a committee before it is formally introduced in the House or Senate."
        return None

    def thomas_link(self):
        """Returns the URL for the bill page on http://thomas.loc.gov."""
        return "http://thomas.loc.gov/cgi-bin/bdquery/z?d%03d:%s%d:" \
            % (self.congress, self.bill_type_slug, self.number)

    def popvox_link(self):
        """Returns the URL for the bill page on POPVOX."""
        return "https://www.popvox.com/bills/us/%d/%s%d" \
            % (self.congress, self.bill_type_slug, self.number)

    def get_feed(self):
        from events.models import Feed
        bt = BillType.by_value(self.bill_type)
        return Feed.objects.get_or_create(feedname="bill:" + bt.xml_code + str(self.congress) + "-" + str(self.number))[0]

    @staticmethod
    def from_feed(feed):
        if not feed.feedname.startswith("bill:"): raise ValueError("Not a bill feed.")
        m = re.match(r"([a-z]+)(\d+)-(\d+)", feed.feedname.split(":")[1])
        bill_type = BillType.by_xml_code(m.group(1))
        return Bill.objects.get(congress=m.group(2), bill_type=bill_type, number=m.group(3))

    @staticmethod
    def ActiveBillsFeed():
        from events.models import Feed
        return Feed.get_noarg_feed("misc:activebills")
    
    @staticmethod
    def EnactedBillsFeed():
        from events.models import Feed
        return Feed.get_noarg_feed("misc:enactedbills")
    
    @staticmethod
    def IntroducedBillsFeed():
        from events.models import Feed
        return Feed.get_noarg_feed("misc:introducedbills")
    
    @staticmethod
    def ActiveBillsExceptIntroductionsFeed():
        from events.models import Feed
        return Feed.get_noarg_feed("misc:activebills2")
    
    @staticmethod
    def ComingUpFeed():
        from events.models import Feed
        return Feed.get_noarg_feed("misc:comingup")
    
    def create_events(self):
        if self.congress < 112: return # not interested, creates too much useless data and slow to load
        from events.models import Feed, Event
        with Event.update(self) as E:
            # collect the feeds that we'll add major actions to
            bill_feed = self.get_feed()
            index_feeds = [bill_feed]
            if self.sponsor != None:
                index_feeds.append(self.sponsor.get_feed("ps"))
            index_feeds.extend([ix.get_feed() for ix in self.terms.all()])
            index_feeds.extend([cx.get_feed("bills") for cx in self.committees.all()])
            index_feeds.extend([Feed.objects.get_or_create(feedname="usc:" + str(sec))[0] for sec in self.usc_citations_uptree()])

            # also index into feeds for any related bills and previous versions of this bill
            # that people may still be tracking
            for rb in self.get_related_bills():
                index_feeds.append(rb.related_bill.get_feed())
            for b in self.find_reintroductions():
                index_feeds.append(b.get_feed())

            # generate events for major actions
            E.add("state:" + str(BillStatus.introduced), self.introduced_date, index_feeds + [Bill.ActiveBillsFeed(), Bill.IntroducedBillsFeed()])
            common_feeds = [Bill.ActiveBillsFeed(), Bill.ActiveBillsExceptIntroductionsFeed()]
            enacted_feed = [Bill.EnactedBillsFeed()]
            for datestr, state, text, srcxml in self.major_actions:
                date = eval(datestr)
                if state == BillStatus.introduced:
                    continue # already indexed
                if state == BillStatus.referred and (date.date() - self.introduced_date).days == 0:
                    continue # don't dup these events so close
                E.add("state:" + str(state), date, index_feeds + common_feeds + (enacted_feed if state in BillStatus.final_status_passed_bill else []))

            # generate events for new cosponsors... group by join date, and
            # assume that join dates we've seen don't have new cosponsors
            # added later, or else we may miss that in an email update. we
            # don't actually need the people listed here, just the unique join
            # dates.
            cosponsor_join_dates = set()
            for cosp in Cosponsor.objects.filter(bill=self, withdrawn=None).exclude(joined=self.introduced_date):
                cosponsor_join_dates.add(cosp.joined)
            for joindate in cosponsor_join_dates:
                E.add("cosp:" + joindate.isoformat(), joindate, [bill_feed])

            # generate an event for appearing on docs.house.gov or the senate floor schedule:
            if self.docs_house_gov_postdate:
                E.add("dhg", self.docs_house_gov_postdate, index_feeds + common_feeds + [Bill.ComingUpFeed()])
            if self.senate_floor_schedule_postdate:
                E.add("sfs", self.senate_floor_schedule_postdate, index_feeds + common_feeds + [Bill.ComingUpFeed()])

            # generate an event for each new GPO text availability
            from glob import glob
            from billtext import bill_gpo_status_codes
            bt = BillType.by_value(self.bill_type).xml_code
            for st in bill_gpo_status_codes:
                textfn = "data/us/bills.text/%s/%s/%s%d%s.pdf" % (self.congress, bt, bt, self.number, st) # use pdf since we don't modify it once we download it, and hopefully we actually have a displayable format like HTML
                if os.path.exists(textfn):
                    textmodtime = datetime.datetime.fromtimestamp(os.path.getmtime(textfn))
                    E.add("text:" + st, textmodtime, index_feeds)

            # generate an event for the main summary
            bs = BillSummary.objects.filter(bill=self)
            if len(bs) > 0:
                E.add("summary", bs[0].created, index_feeds + [Feed.from_name("misc:billsummaries")])


    def render_event(self, eventid, feeds):
        if eventid == "dhg":
            return self.render_event_dhg(feeds)
        if eventid == "sfs":
            return self.render_event_sfs(feeds)
        if eventid == "summary":
            return self.render_event_summary(feeds)

        ev_type, ev_code = eventid.split(":")
        if ev_type == "state":
            return self.render_event_state(ev_code, feeds)
        elif ev_type == "cosp":
            return self.render_event_cosp(ev_code, feeds)
        elif ev_type == "text":
            return self.render_event_text(ev_code, feeds)
        else:
            raise Exception()

    def render_event_state(self, ev_code, feeds):
        from status import BillStatus
        status = BillStatus.by_value(int(ev_code))
        date = self.introduced_date
        action = None
        action_type = None
        reps_on_committees = []

        if status == BillStatus.introduced:
            action_type = "introduced"
        else:
            for datestr, st, text, srcxml in self.major_actions:
                if st == status:
                    date = eval(datestr)
                    action = text
                    break
            else:
                raise Exception("Invalid %s event in %s." % (status, str(self)))

        if self.is_current and BillStatus.by_value(status).xml_code == "INTRODUCED":
            cmtes = list(self.committees.all())
            if not cmtes:
                explanation = "This %s is in the first stage of the legislative process. It will typically be considered by committee next." % self.noun
            else:
                def nice_list(items, max_count):
                    if len(items) > max_count:
                        if len(items) == max_count+1:
                            items[max_count:] = ["one other committee"]
                        else:
                            items[max_count:] = [str(len(items)-max_count) + " other committees"]
                    if len(items) == 1:
                        return items[0]
                    elif len(items) == 2:
                        return items[0] + " and " + items[1]
                    else:
                        return ", ".join(items[0:-1]) + ", and " + items[-1]
                explanation = "This %s was referred to the %s which will consider it before sending it to the %s floor for consideration." % (
                    self.noun,
                    nice_list(sorted(c.fullname for c in cmtes), 2),
                    self.originating_chamber)

                # See if any tracked reps are members of the committees. Also
                # check the bill's sponsor, since we display it.
                reps_tracked = set()
                if self.sponsor: reps_tracked.add(self.sponsor)
                from person.models import Person
                for f in (feeds if feeds else []):
                    try:
                        reps_tracked.add(Person.from_feed(f))
                    except ValueError:
                        pass # not a person-related feed
                mbrs = list(CommitteeMember.objects.filter(person__in=reps_tracked, committee__in=cmtes))
                if len(mbrs) > 0:
                    mbrs.sort(key = lambda m : (-MEMBER_ROLE_WEIGHTS[m.role], m.committee.shortname))
                    for m in mbrs:
                        reps_on_committees.append(m.person.name + " is " + m.role_name_2() + " the " + (m.committee.fullname if len(cmtes) > 1 else "committee") + ".")
                else:
                    # Neither the sponsor nor any tracked reps are on those committes.
                    # What about cosponsors?
                    m = CommitteeMember.objects.filter(person__in=self.cosponsors.all(), committee__in=cmtes).count()
                    if m > 0:
                        reps_on_committees.append("%d cosponsor%s on %s." % (
                            m,
                            " is" if m == 1 else "s are",
                            "that committee" if len(cmtes) == 1 else "those committees"))

        else:
            explanation = self.get_status_text(status, date)


        return {
            "type": status.label,
            "date": date,
            "date_has_no_time": isinstance(date, datetime.date) or date.time() == datetime.time.min,
            "title": self.title,
            "url": self.get_absolute_url(),
            "body_text_template":
"""{% if sponsor and action_type == 'introduced' %}Sponsor: {{sponsor|safe}}{% endif %}
{% if action %}Last Action: {{action|safe}}{% endif %}
{% if action %}Explanation: {% endif %}{{summary|safe}}
{% for rep in reps_on_committees %}
{{rep}}{% endfor %}""",
            "body_html_template":
"""{% if sponsor and action_type == 'introduced' %}<p>Sponsor: <a href="{{SITE_ROOT}}{{sponsor.get_absolute_url}}">{{sponsor}}</a></p>{% endif %}
{% if action %}<p>Last Action: {{action}}</p>{% endif %}
<p>{% if action %}Explanation: {% endif %}{{summary}}</p>
{% for rep in reps_on_committees %}<p>{{rep}}</p>{% endfor %}
""",
            "context": {
                "sponsor": self.sponsor,
                "action": action,
                "action_type": action_type,
                "summary": explanation,
                "reps_on_committees": reps_on_committees,
                }
            }

    def render_event_cosp(self, ev_code, feeds):
        cosp = Cosponsor.objects.filter(bill=self, withdrawn=None, joined=ev_code)
        if len(cosp) == 0:
            # What to do if there are no longer new cosponsors on this date?
            # TODO test this.
            return {
                "type": "New Cosponsors",
                "date": datetime.date(*[int(k) for k in ev_code.split('-')]),
                "date_has_no_time": True,
                "title": self.title,
                "url": self.get_absolute_url(),
                "body_text_template": "Event error.",
                "body_html_template": "Event error.",
                "context": {},
                }

        return {
            "type": "New Cosponsor" + ("" if len(cosp) == 1 else "s"),
            "date": cosp[0].joined,
            "date_has_no_time": True,
            "title": self.title,
            "url": self.get_absolute_url(),
            "body_text_template":
"""{% for p in cosponsors %}New Cosponsor: {{ p.person.name }}
{% endfor %}""",
            "body_html_template": """{% for p in cosponsors %}<p>New Cosponsor: <a href="{{SITE_ROOT}}{{p.person.get_absolute_url}}">{{ p.person.name }}</a></p>{% endfor %}""",
            "context": {
                "cosponsors": cosp,
                }
            }

    def render_event_dhg(self, feeds):
        return {
            "type": "Legislation Coming Up",
            "date": self.docs_house_gov_postdate,
            "date_has_no_time": False,
            "title": self.title,
            "url": self.get_absolute_url(),
            "body_text_template": """This {{noun}} has been added to the House's schedule for the coming week, according to the House Majority Leader. More information can be found at http://docs.house.gov.\n\nLast Action: {{current_status}}""",
            "body_html_template": """<p>This {{noun}} has been added to the House&rsquo;s schedule for the coming week, according to the House Majority Leader. See <a href="http://docs.house.gov">the week ahead</a>.</p><p>Last Action: {{current_status}}</p>""",
            "context": { "noun": self.noun, "current_status": self.current_status_description },
            }
    def render_event_sfs(self, feeds):
        return {
            "type": "Legislation Coming Up",
            "date": self.senate_floor_schedule_postdate,
            "date_has_no_time": False,
            "title": self.title,
            "url": self.get_absolute_url(),
            "body_text_template": """This {{noun}} has been added to the Senate's floor schedule for the next legislative day.\n\nnLast Action: {{current_status}}""",
            "body_html_template": """<p>This {{noun}} has been added to the Senate&rsquo;s floor schedule for the next legislative day.</p><p>Last Action: {{current_status}}</p>""",
            "context": { "noun": self.noun, "current_status": self.current_status_description },
            }

    def render_event_text(self, ev_code, feeds):
        from billtext import bill_gpo_status_codes, load_bill_text
        if not ev_code in bill_gpo_status_codes: raise Exception()
        bt = BillType.by_value(self.bill_type).xml_code
        textfn = "data/us/bills.text/%s/%s/%s%d%s.pdf" % (self.congress, bt, bt, self.number, ev_code) # use pdf since we don't modify it once we download it, and hopefully we actually have a displayable format like HTML
        if not os.path.exists(textfn): raise Exception()

        try:
            modsinfo = load_bill_text(self, ev_code, mods_only=True)
        except IOError:
            modsinfo = { "docdate": "Unknown Date", "doc_version_name": "Unknown Version" }

        return {
            "type": "Bill Text",
            "date": datetime.datetime.fromtimestamp(os.path.getmtime(textfn)),
            "date_has_no_time": False,
            "title": self.title,
            "url": self.get_absolute_url() + "/text",
            "body_text_template": """This {{noun}}'s text {% if doc_version_name != "Introduced" %}for status <{{doc_version_name}}> ({{doc_date}}) {% endif %}is now available.""",
            "body_html_template": """<p>This {{noun}}&rsquo;s text {% if doc_version_name != "Introduced" %}for status <i>{{doc_version_name}}</i> ({{doc_date}}) {% endif %}is now available.</p>""",
            "context": { "noun": self.noun, "doc_date": modsinfo["docdate"], "doc_version_name": modsinfo["doc_version_name"] },
            }

    def render_event_summary(self, feeds):
        bs = self.oursummary
        return {
            "type": "Bill Summary",
            "date": bs.created,
            "date_has_no_time": False,
            "title": self.title,
            "url": self.get_absolute_url() + "#summary/oursummary",
            "body_text_template": """{{summary.plain_text|truncatewords:80}}""",
            "body_html_template": """{{summary.content|truncatewords_html:80|safe}}""",
            "context": { "summary": bs },
            }

    def get_major_events(self):
        if self.congress < 93: return []
        ret = []
        saw_intro = False
        for datestr, st, text, srcxml in self.major_actions:
            date = eval(datestr)
            srcnode = etree.fromstring(srcxml) if srcxml else None

            st_key = BillStatus.by_value(st).key
            explanation = BillStatus.by_value(st).explanation
            if callable(explanation): explanation = explanation(self)

            if st == BillStatus.referred: continue # don't care about this
            if st in (BillStatus.passed_bill, BillStatus.passed_concurrentres) and srcnode and srcnode.get("where") in ("h", "s") and srcnode.get("type") in ("vote2", "pingpong", "conference"):
                ch = {"h":"House","s":"Senate"}[srcnode.get("where")]
                # PASSED:BILL only occurs on the second chamber, so indicate both agreed to in text
                if srcnode.get("type") == "vote2":
                    st = ("Passed %s" % ch)
                elif srcnode.get("type") == "pingpong":
                    st = ("%s Agreed to Changes" % ch)
                elif srcnode.get("type") == "conference":
                    st = ("Conference Report Agreed to by %s" % ch)
            else:
                if st == BillStatus.introduced: saw_intro = True
                st = BillStatus.by_value(st)
                try:
                    st = st.simple_label
                except:
                    st = st.label

            ret.append({
                "key": st_key,
                "label": st,
                "date": date,
                "actionline": text,
                "explanation": explanation,
            })
        if not saw_intro: ret.insert(0, { "key": BillStatus.introduced.key, "label": "Introduced", "date": self.introduced_date, "explanation": BillStatus.introduced.explanation })

        if self.docs_house_gov_postdate: ret.append({ "key": "schedule_house", "label": "On House Schedule", "date": self.docs_house_gov_postdate, "explanation": "The House indicated that this %s would be considered in the week ahead." % self.noun })
        if self.senate_floor_schedule_postdate: ret.append({ "key": "schedule_senate","label": "On Senate Schedule", "date": self.senate_floor_schedule_postdate, "explanation": "The Senate indicated that this %s would be considered in the days ahead." % self.noun })
        def as_dt(x):
            if isinstance(x, datetime.datetime): return x
            return datetime.datetime.combine(x, datetime.time.min)
        ret.sort(key = lambda x : as_dt(x["date"])) # only needed because of the previous two

        if self.is_alive:
            for key, label in self.get_future_events():
                ret.append({ "key": key, "label": label })

        return ret

    def get_future_events(self):
        # predict the major actions not yet occurred on the bill, based on its
        # current status.

        # define a state diagram
        common_paths = {
            BillStatus.introduced: BillStatus.reported,
            BillStatus.referred: BillStatus.reported,
        }

        type_specific_paths = {
            BillType.house_bill: {
                BillStatus.reported: BillStatus.pass_over_house,
                BillStatus.pass_over_house: (BillStatus.passed_bill, "Passed Senate"),
                BillStatus.pass_back_house: (BillStatus.passed_bill, "Senate Approves House Changes"),
                BillStatus.pass_back_senate: (BillStatus.passed_bill, "House Approves Senate Changes"),
                BillStatus.conference_passed_house: (BillStatus.passed_bill, "Conference Report Agreed to by Senate"),
                BillStatus.conference_passed_senate: (BillStatus.passed_bill, "Conference Report Agreed to by House"),
                BillStatus.passed_bill: BillStatus.enacted_signed,
                BillStatus.prov_kill_suspensionfailed: BillStatus.pass_over_house,
                BillStatus.prov_kill_cloturefailed: (BillStatus.passed_bill, "Passed Senate"),
                BillStatus.prov_kill_pingpongfail: (BillStatus.passed_bill, "Passed House/Senate"),
                BillStatus.prov_kill_veto: BillStatus.override_pass_over_house,
                BillStatus.override_pass_over_house: BillStatus.enacted_veto_override,
            },
            BillType.senate_bill: {
                BillStatus.reported: BillStatus.pass_over_senate,
                BillStatus.pass_over_senate: (BillStatus.passed_bill, "Passed House"),
                BillStatus.pass_back_house: (BillStatus.passed_bill, "Senate Approves House Changes"),
                BillStatus.pass_back_senate: (BillStatus.passed_bill, "House Approves Senate Changes"),
                BillStatus.conference_passed_house: (BillStatus.passed_bill, "Conference Report Agreed to by Senate"),
                BillStatus.conference_passed_senate: (BillStatus.passed_bill, "Conference Report Agreed to by House"),
                BillStatus.passed_bill: BillStatus.enacted_signed,
                BillStatus.prov_kill_suspensionfailed: (BillStatus.passed_bill, "Passed House"),
                BillStatus.prov_kill_cloturefailed: BillStatus.pass_over_senate,
                BillStatus.prov_kill_pingpongfail: (BillStatus.passed_bill, "Passed Senate/House"),
                BillStatus.prov_kill_veto: BillStatus.override_pass_over_senate,
                BillStatus.override_pass_over_senate: BillStatus.enacted_veto_override,
            },
            BillType.house_resolution:  {
                BillStatus.reported: BillStatus.passed_simpleres,
                BillStatus.prov_kill_suspensionfailed: BillStatus.passed_simpleres,
            },
            BillType.senate_resolution: {
                BillStatus.reported: BillStatus.passed_simpleres,
                BillStatus.prov_kill_cloturefailed: BillStatus.passed_simpleres,
            },
            BillType.house_concurrent_resolution: {
                BillStatus.reported: BillStatus.pass_over_house,
                BillStatus.pass_over_house: (BillStatus.passed_concurrentres, "Passed Senate"),
                BillStatus.pass_back_house: (BillStatus.passed_concurrentres, "Senate Approves House Changes"),
                BillStatus.pass_back_senate: (BillStatus.passed_concurrentres, "House Approves Senate Changes"),
                BillStatus.conference_passed_house: (BillStatus.passed_concurrentres, "Conference Report Agreed to by Senate"),
                BillStatus.conference_passed_senate: (BillStatus.passed_concurrentres, "Conference Report Agreed to by House"),
                BillStatus.prov_kill_suspensionfailed: BillStatus.pass_over_house,
                BillStatus.prov_kill_cloturefailed: BillStatus.passed_concurrentres,
                BillStatus.prov_kill_pingpongfail: BillStatus.passed_concurrentres,
            },
            BillType.senate_concurrent_resolution: {
                BillStatus.reported: BillStatus.pass_over_senate,
                BillStatus.pass_over_senate: (BillStatus.passed_concurrentres, "Passed House"),
                BillStatus.pass_back_house: (BillStatus.passed_concurrentres, "Senate Approves House Changes"),
                BillStatus.pass_back_senate: (BillStatus.passed_concurrentres, "House Approves Senate Changes"),
                BillStatus.conference_passed_house: (BillStatus.passed_concurrentres, "Conference Report Agreed to by Senate"),
                BillStatus.conference_passed_senate: (BillStatus.passed_concurrentres, "Conference Report Agreed to by House"),
                BillStatus.prov_kill_suspensionfailed: BillStatus.passed_concurrentres,
                BillStatus.prov_kill_cloturefailed: BillStatus.pass_over_senate,
                BillStatus.prov_kill_pingpongfail: BillStatus.passed_concurrentres,
            },
            BillType.house_joint_resolution: { # assuming const amend
                BillStatus.reported: BillStatus.pass_over_house,
                BillStatus.pass_over_house: BillStatus.passed_constamend,
                BillStatus.pass_back_house: BillStatus.passed_constamend,
                BillStatus.pass_back_senate: BillStatus.passed_constamend,
                BillStatus.conference_passed_house: BillStatus.passed_constamend,
                BillStatus.conference_passed_senate: BillStatus.passed_constamend,
                BillStatus.prov_kill_suspensionfailed: BillStatus.pass_over_house,
                BillStatus.prov_kill_cloturefailed: BillStatus.passed_constamend,
                BillStatus.prov_kill_pingpongfail: BillStatus.passed_constamend,
            },
            BillType.senate_joint_resolution: { # assuming const amend
                BillStatus.reported: BillStatus.pass_over_senate,
                BillStatus.pass_over_senate: BillStatus.passed_constamend,
                BillStatus.pass_back_house: BillStatus.passed_constamend,
                BillStatus.pass_back_senate: BillStatus.passed_constamend,
                BillStatus.conference_passed_house: BillStatus.passed_constamend,
                BillStatus.conference_passed_senate: BillStatus.passed_constamend,
                BillStatus.prov_kill_suspensionfailed: BillStatus.passed_constamend,
                BillStatus.prov_kill_cloturefailed: BillStatus.pass_over_senate,
                BillStatus.prov_kill_pingpongfail: BillStatus.passed_constamend,
            }
        }

        bt = self.bill_type
        if bt == BillType.house_joint_resolution and not "Proposing an Amendment" in self.title: bt = BillType.house_bill
        if bt == BillType.senate_joint_resolution and not "Proposing an Amendment" in self.title: bt = BillType.senate_bill

        path = { }
        path.update(common_paths)
        path.update(type_specific_paths[bt])

        seq = []
        st = self.current_status
        while st in path:
            st = path[st]
            if type(st) == tuple:
                label = st[1]
                st = st[0]
            else:
                try:
                    label = st.simple_label
                except:
                    label = st.label
            seq.append((st.key, label))

        return seq

    def get_top_term(self):
        try:
            return [t for t in self.terms.all() if t.is_top_term()][0]
        except IndexError:
            return None
    def get_top_term_id(self):
        t = self.get_top_term()
        if t: t = t.id
        return t

    def get_terms_sorted(self):
        terms = list(self.terms.all())
        terms.sort(key = lambda x : (not x.is_top_term(), x.name))
        return terms

    def get_related_bills(self):
        # Gets a unqie list of related bills, sorted by the relation type, whether the titles are
        # the same, and the last action date.
        ret = []
        seen = set()
        bills = list(self.relatedbills.all().select_related("related_bill"))
        bills.sort(key = lambda rb : (
            -RelatedBill.relation_sort_order.get(rb.relation, 999),
            self.title_no_number==rb.related_bill.title_no_number,
            rb.related_bill.current_status_date
            ), reverse=True)
        for rb in bills:
            if not rb.related_bill in seen:
                ret.append(rb)
                seen.add(rb.related_bill)
        return ret

    def get_related_bills_newer(self):
        return [rb for rb in self.get_related_bills()
            if self.title_no_number == rb.related_bill.title_no_number
            and rb.related_bill.current_status_date > self.current_status_date]

    def find_reintroductions(self):
        if self.sponsor == None: return
        def normalize_title(title): # remove anything that looks like a year
            return re.sub(r"of \d\d\d\d$", "", title)
        for reintro in Bill.objects.exclude(congress=self.congress).filter(sponsor=self.sponsor).order_by('congress'):
            if normalize_title(self.title_no_number) != normalize_title(reintro.title_no_number): continue
            yield reintro

    def was_enacted_ex(self, recurse=True, restrict_to_activity_in_date_range=None):
        # Checking if a bill was "enacted" in a popular sense is a little tricky:
        #
        #  * We should count a bill as enacted if any identified companion bill was enacted.
        #
        # Returns the actual bill that was enacted (possibly a companion bill), or None if
        # the bill was not "enacted".
        #
        # Previously, but this has been corrected in the congress project (7b47095d197ad0b9f886a757eabbede95524b174):
        #  1) Our status code is currently tied to the assignment of a slip law number by OFR,
        #     which isn't what we mean exactly. Better to look for a <signed> action in case of
        #     delays at OFR.

        import json

        def date_filter(d):
            if restrict_to_activity_in_date_range is None: return True
            return restrict_to_activity_in_date_range[0] <= d <= restrict_to_activity_in_date_range[1]

        # If we know the bill to have been enacted...
        if self.current_status in BillStatus.final_status_passed_bill and date_filter(self.current_status_date.isoformat()):
            return self

        # Check companion bills...
        if recurse:
            for rb in RelatedBill.objects.filter(bill=self, relation="identical").select_related("related_bill"):
                e = rb.related_bill.was_enacted_ex(recurse=False, restrict_to_activity_in_date_range=restrict_to_activity_in_date_range)
                if e is not None:
                     return e
                
        return None

    def get_open_market(self, user):
        from django.contrib.contenttypes.models import ContentType
        bill_ct = ContentType.objects.get_for_model(Bill)

        import predictionmarket.models
        try:
            m = predictionmarket.models.Market.objects.get(owner_content_type=bill_ct, owner_object_id=self.id, isopen=True)
        except predictionmarket.models.Market.DoesNotExist:
            return None

        for outcome in m.outcomes.all():
            if outcome.owner_key == "1": # "yes"
                m.yes = outcome
                m.yes_price = int(round(outcome.price() * 100.0))
        if user and user.is_authenticated():
            account = predictionmarket.models.TradingAccount.get(user, if_exists=True)
            if account:
                positions, profit = account.position_in_market(m)
                m.user_profit = round(profit, 1)
                m.user_positions = { }
                for outcome in positions:
                    m.user_positions[outcome.owner_key] = positions[outcome]
        return m

    def get_gop_summary(self):
        import urllib, StringIO
        try:
            from django.utils.safestring import mark_safe
            dom = etree.parse(urllib.urlopen("http://www.gop.gov/api/bills.get?congress=%d&number=%s%d" % (self.congress, BillType.by_value(self.bill_type).slug, self.number)))
        except:
            return None
        if dom.getroot().tag == '{http://www.w3.org/1999/xhtml}html': return None
        def sanitize(s, as_text=False):
            if s.strip() == "": return None
            return mark_safe("".join(
                etree.tostring(n, method="html" if not as_text else "text", encoding=unicode)
                for n
                in etree.parse(StringIO.StringIO(s), etree.HTMLParser(remove_comments=True, remove_pis=True)).xpath("body")[0]))
        ret = {
            "link": unicode(dom.xpath("string(bill/permalink)")),
            "summary": sanitize(dom.xpath("string(bill/analysis/bill-summary)")),
            "background": sanitize(dom.xpath("string(bill/analysis/background)")),
            "cost": sanitize(dom.xpath("string(bill/analysis/cost)")),
        }
        if ret["cost"] and "was not available as of press time" in ret["cost"]: ret["cost"] = None
        # floor-situation is also interesting but largely redundant with what we already know
        # take the first of background and bill-summary and make a text-only version
        for f in ("background", "bill-summary"):
            ret["text"] = sanitize(dom.xpath("string(bill/analysis/%s)" % f), as_text=True)
            if ret["text"]: break
        return ret

class RelatedBill(models.Model):
    bill = models.ForeignKey(Bill, related_name="relatedbills")
    related_bill = models.ForeignKey(Bill, related_name="relatedtobills")
    relation = models.CharField(max_length=16)

    relation_sort_order = { "identical": 0 }

def get_formatted_bill_summary(bill):
    sfn = "data/us/%d/bills.summary/%s%d.summary.xml" % (bill.congress, BillType.by_value(bill.bill_type).xml_code, bill.number)
    if not os.path.exists(sfn): return None

    dom = etree.parse(open(sfn))
    xslt_root = etree.XML('''
<xsl:stylesheet version="1.0" xmlns:xsl="http://www.w3.org/1999/XSL/Transform">
    <xsl:output omit-xml-declaration="yes"/>
    <xsl:template match="summary//Paragraph[string(.)!='']">
        <div style="margin-top: .5em; margin-bottom: .5em">
            <xsl:apply-templates/>
        </div>
    </xsl:template>

    <xsl:template match="Division|Title|Subtitle|Part|Chapter|Section">
        <xsl:if test="not(@number='meta')">
        <div>
            <xsl:choose>
            <xsl:when test="@name='' and count(*)=1">
            <div style="margin-top: .75em">
            <span xml:space="preserve" style="font-weight: bold;"><xsl:value-of select="name()"/> <xsl:value-of select="@number"/>.</span>
            <xsl:value-of select="Paragraph"/>
            </div>
            </xsl:when>

            <xsl:otherwise>
            <div style="font-weight: bold; margin-top: .75em" xml:space="preserve">
                <xsl:value-of select="name()"/>
                <xsl:value-of select="@number"/>
                <xsl:if test="not(@name='')"> - </xsl:if>
                <xsl:value-of select="@name"/>
            </div>
            <div style="margin-left: 2em" xml:space="preserve">  <!-- 'preserve' prevents a self-closing tag which breaks HTML parse -->
                <xsl:apply-templates/>
            </div>
            </xsl:otherwise>
            </xsl:choose>
        </div>
        </xsl:if>
    </xsl:template>
</xsl:stylesheet>''')
    transform = etree.XSLT(xslt_root)
    summary = unicode(transform(dom))
    if summary.strip() == "":
        return None
    return summary

class BillLink(models.Model):
    bill = models.ForeignKey(Bill, db_index=True, related_name="links", on_delete=models.PROTECT)
    url = models.CharField(max_length=256)
    title = models.CharField(max_length=256)
    created = models.DateTimeField(auto_now_add=True)
    approved = models.BooleanField(default=False)
    class Meta:
        unique_together = ( ('bill', 'url'), )
        ordering = ('-created',)
    @property
    def hostname(self):
        return urlparse.urlparse(self.url).hostname

class BillTextComparison(models.Model):
    bill1 = models.ForeignKey(Bill, related_name="comparisons1")
    ver1 = models.CharField(max_length=6)
    bill2 = models.ForeignKey(Bill, related_name="comparisons2")
    ver2 = models.CharField(max_length=6)
    data = JSONField()
    class Meta:
        unique_together = ( ('bill1', 'ver1', 'bill2', 'ver2'), )
    def compress(self):
        import bz2, base64
        self.data["left_text_bz2"] = base64.b64encode(bz2.compress(self.data["left_text"]))
        self.data["right_text_bz2"] = base64.b64encode(bz2.compress(self.data["right_text"]))
        del self.data["left_text"]
        del self.data["right_text"]
    def decompress(self):
        import bz2, base64
        self.data["left_text"] = bz2.decompress(base64.b64decode(self.data["left_text_bz2"]))
        self.data["right_text"] = bz2.decompress(base64.b64decode(self.data["right_text_bz2"]))

# Feeds
from events.models import Feed, truncate_words
Feed.register_feed(
    "misc:enactedbills",
    category = "federal-bills",
    description = "You will be alerted every time a law is enacted.",
    title = "New Laws",
    simple = True,
    sort_order = 104,
    single_event_type = True,
    slug = "enacted-bills",
    )
Feed.register_feed(
    "misc:comingup",
    category = "federal-bills",
    description = "You will get updates when any bill is scheduled for debate in the week ahead by the House Majority Leader or in the day ahead according to the Senate Floor Schedule.",
    title = "Legislation Coming Up",
    simple = True,
    sort_order = 102,
    single_event_type = True,
    slug = "coming-up",
    )
Feed.register_feed(
    "misc:activebills2",
    category = "federal-bills",
    description = "Get an update when any bill is scheduled for debate or has major action such as a vote or being enacted.",
    title = "Major Legislative Activity",
    simple = True,
    sort_order = 100,
    slug = "major-bill-activity",
    )
Feed.register_feed(
    "misc:activebills",
    category = "federal-bills",
    description = "Get an update when any bill is introduced, scheduled for debate, or has major action such as a vote or being enacted.",
    title = "All Legislative Activity",
    simple = True,
    sort_order = 105,
    slug = "bill-activity",
    )
Feed.register_feed(
    "misc:introducedbills",
    category = "federal-bills",
    description = "Get an update whenever a new bill or resolution is introduced.",
    title = "New Bills and Resolutions",
    simple = True,
    sort_order = 106,
    single_event_type = True,
    slug = "introduced-bills",
    )
Feed.register_feed(
    "bill:",
    title = lambda feed : truncate_words(Bill.from_feed(feed).title, 12),
    noun = "bill",
    link = lambda feed: Bill.from_feed(feed).get_absolute_url(),
    category = "federal-bills",
    description = "You will get updates when this bill is scheduled for debate, has a major action such as a vote, or gets a new cosponsor, when a committee meeting is scheduled, when bill text becomes available or when we write a bill summary, plus similar events for related bills."
    )
Feed.register_feed(
    "crs:",
    title = lambda feed : BillTerm.from_feed(feed).name,
    noun = "subject area",
    link = lambda feed: BillTerm.from_feed(feed).get_absolute_url(),
    is_valid = lambda feed : BillTerm.from_feed(feed, test=True),
    category = "federal-bills",
    description = "You will get updates about major activity on bills in this subject area including notices of newly introduced bills, updates when a bill is scheduled for debate, has a major action such as a vote, or gets a new cosponsor, when bill text becomes available or when we write a bill summary.",
    )

# Bill search tracker.
def bill_search_feed_title(q):
    from search import bill_search_manager
    return "Bill Search - " + bill_search_manager().describe_qs(q)
def bill_search_feed_execute(q):
    from search import bill_search_manager
    from settings import CURRENT_CONGRESS

    bills = bill_search_manager().execute_qs(q, overrides={'congress': CURRENT_CONGRESS}).order_by("-current_status_date")[0:100] # we have to limit to make this reasonably fast

    def make_feed_name(bill):
        return "bill:" + BillType.by_value(bill.bill_type).xml_code + str(bill.congress) + "-" + str(bill.number)
    return Feed.objects.filter(feedname__in=[make_feed_name(bill) for bill in bills if bill != None]) # batch load
Feed.register_feed(
    "billsearch:",
    title = lambda feed : bill_search_feed_title(feed.feedname.split(":", 1)[1]),
    link = lambda feed : "/congress/bills/browse?" + feed.feedname.split(":", 1)[1],
    includes = lambda feed : bill_search_feed_execute(feed.feedname.split(":", 1)[1]),
    meta = True,
    category = "federal-bills",
    description = "Get updates for all bills matching the keyword search, including major activity, being scheduled for debate, new cosponsors, etc.",
    )

# Summaries
class BillSummary(models.Model):
    bill = models.OneToOneField(Bill, related_name="oursummary", on_delete=models.PROTECT)
    created = models.DateTimeField(auto_now_add=True)
    modified = models.DateTimeField(auto_now=True)
    content = models.TextField(blank=True)

    def plain_text(self):
        import re
        content = re.sub("<br>|<li>", " \n ", self.content, re.I)

        from django.utils.html import strip_tags
        content = strip_tags(content)

        content = content.replace("&nbsp;", " ")

        return content

# USC Citations
class USCSection(models.Model):
    parent_section = models.ForeignKey('self', blank=True, null=True, db_index=True)
    citation = models.CharField(max_length=32, blank=True, null=True, db_index=True)
    level_type = models.CharField(max_length=10, choices=[('title', 'Title'), ('subtitle', 'Subtitle'), ('chapter', 'Chapter'), ('subchapter', 'Subchapter'), ('part', 'Part'), ('subpart', 'Subpart'), ('division', 'Division'), ('heading', 'Heading'), ('section', 'Section')])
    number = models.CharField(max_length=24, blank=True, null=True)
    deambig = models.IntegerField(default=0) # disambiguates two sections with the same parent, level_type, and number by their order in the source file
    name = models.TextField(blank=True, null=True)
    ordering = models.IntegerField()
    update_flag = models.IntegerField(default=0)

    def __unicode__(self):
        return ((unicode(self.parent_section) + " > ") if self.parent_section else "") + self.get_level_type_display() + " "  + (self.number if self.number else "[No Number]")

    @property
    def name_recased(self):
        exceptions = ("and", "of", "the", "a", "an")
        if self.name and self.name == self.name.upper():
            return " ".join([w if i == 0 or w.lower() not in exceptions else w.lower() for i, w in enumerate(self.name.title().split(" "))])
        return self.name

    @property
    def citation_or_id(self):
        if self.citation:
            # check that it is unique
            try:
                USCSection.objects.get(citation=self.citation)
                return self.citation
            except:
                pass # pass through if there are multiple instances
        return self.id

    def get_absolute_url(self):
        return "/congress/bills/uscode/" + str(self.citation_or_id).replace("usc/", "")

    def get_cornell_lii_link(self, subsection=None):
        import re
        if self.level_type == "section":
            uscstring, title, sec = self.citation.split("/")
            return "http://www.law.cornell.edu/uscode/text/" + title + "/" + sec \
                + ( ("#" + "_".join(re.findall(r"\(([^)]+)\)", subsection))) if subsection else "")
        else:
            # path to level through possible subtitles, parts, etc.
            path = [self]
            so = self
            while so.parent_section:
                so = so.parent_section
                path.append(so)
            if not path[-1].citation: return None # not a section actually in the USC
            path.reverse()
            return "http://www.law.cornell.edu/uscode/text/" + "/".join(
                (((so.level_type + "-") if so.level_type not in ("title", None) else "") + so.number) if so.number else "?" for so in path)

    # utility methods to load from the structure.json file created by github:unitedstates/uscode
    # don't forget:
    #   * STOP: The upstream 'citation' key has changed: usc/chapter/x/y is now usc/title/x/chapter/y
    #           And intermediate levels are similar.
    #   * These objects are used in feeds. Delete with care.
    #     After loading, obsoleted entries are left with update_flag=0.
    #     Check if any of those are used in feeds before deleting them.
    #   * After loading, create a fixture to bootstrap local deployments of the website & backups.
    #     ./manage.py dumpdata --format json bill.USCSection > data/db/django-fixture-usc_sections.json
    @staticmethod
    def load_data_new():
        import json
        D = json.load(open("../../uscode/structure_xml.json"))
        D2 = json.load(open("../../uscode/structure_html.json"))
        for t in D2:
         if t["number"].endswith("a"):
          D.append(t)
        D.sort(key = lambda title : (int(title["number"].replace("a", "")), title["number"]))
        USCSection.load_data(D)
        print USCSection.objects.filter(update_flag=0).count(), "deleted sections" # .delete() ?
    @staticmethod
    def load_data(structure_data):
        if isinstance(structure_data, str):
            import json
            structure_data = json.load(open(structure_data))
        USCSection.objects.update(update_flag=0)
        USCSection.load_data2(None, structure_data)
    @staticmethod
    def load_data2(parent, sections):
        ambig = { }

        for i, sec in enumerate(sections):
            # because level/number may be ambiguous, count sequence too
            # this doesn't handle unnumbered headings very nicely, ah well
            deambig = ambig.get((sec["level"], sec.get("number")), 0)
            ambig[(sec["level"], sec.get("number"))] = deambig+1

            fields = {
                "name": sec.get("name"),
                "ordering": i,
                "citation": sec.get("citation"),
                "update_flag": 1,
            }

            ## Force a re-numbering on the deambig field.
            #for i2, s2 in enumerate(USCSection.objects.filter(
            #    parent_section=parent,
            #    level_type=sec["level"],
            #    number=sec.get("number")).order_by("ordering")[1:]):
            #    s2.deambig = i2+1
            #    s2.save()

            obj, is_new = USCSection.objects.get_or_create(
                parent_section=parent,
                level_type=sec["level"],
                number=sec.get("number"),
                deambig=deambig,
                defaults=fields)
            if not is_new:
                # update fields; importantly, set the update_flag
                for k, v in fields.items():
                    setattr(obj, k, v)
                obj.save()
            else:
                print "created", obj
            USCSection.load_data2(obj, sec.get("subparts", []))

Feed.register_feed(
    "usc:",
    title = lambda feed : unicode(USCSection.objects.get(id=feed.feedname.split(":", 1)[1])),
    link = lambda feed : USCSection.objects.get(id=feed.feedname.split(":", 1)[1]).get_absolute_url(),
    category = "federal-bills",
    description = "Get updates for bills citing this part of the U.S. Code, including major activity and when the bill is scheduled for debate.",
    )

Feed.register_feed(
    "misc:billsummaries",
    title = "GovTrack Bill Summaries",
    simple = True,
    slug = "bill-summaries",
    intro_html = """<p>This feed includes all GovTrack original research on legislation.</p>""",
    category = "federal-bills",
    description = "Get an update whenever we post a GovTrack original bill summary.",
    )

class AmendmentType(enum.Enum):
    senate_amendment = enum.Item(1, 'S.Amdt.', slug='s', full_name="Senate Amendment", search_help_text="Senate amendments")
    house_amendment = enum.Item(2, 'H.Amdt.', slug='h', full_name="House Amendment", search_help_text="House amendments")

class Amendment(models.Model):
    """An amendment to a bill."""

    congress = models.IntegerField(help_text="The number of the Congress in which the amendment was offered. The current Congress is %d." % settings.CURRENT_CONGRESS)
    amendment_type = models.IntegerField(choices=AmendmentType, help_text="The amendment's type, indicating the chmaber in which the amendment was offered.")
    number = models.IntegerField(help_text="The amendment's number according to the Library of Congress's H.Amdt and S.Amdt numbering (just the integer part).")
    bill = models.ForeignKey(Bill, help_text="The bill the amendment amends.")
    sequence = models.IntegerField(blank=True, null=True, help_text="For House amendments, the sequence number of the amendment (unique within a bill).")

    title = models.CharField(max_length=255, help_text="A title for the amendment.")

    sponsor = models.ForeignKey('person.Person', blank=True, null=True, related_name='sponsored_amendments', help_text="The sponsor of the amendment.", on_delete=models.PROTECT)
    sponsor_role = models.ForeignKey('person.PersonRole', blank=True, null=True, help_text="The role of the sponsor of the amendment at the time the amendment was offered.", on_delete=models.PROTECT)
    offered_date = models.DateField(help_text="The date the amendment was offered.")

    class Meta:
        unique_together = [('congress', 'amendment_type', 'number'),
            ('bill', 'sequence')]
            # bill+sequence is not unique, see the github thread on amendment numbering --- currently this is manually fixed up in the db as a non-unique index

    def __unicode__(self):
        return self.title


########NEW FILE########
__FILENAME__ = prognosis
#!.env/bin/python

# Compute the success rates of different types of bills with
# different prognosis factors.

if __name__ == "__main__":
	import sys, os
	sys.path.insert(0, "..")
	sys.path.insert(0, ".")
	sys.path.insert(0, "lib")
	sys.path.insert(0, ".env/lib/python2.7/site-packages")
	os.environ["DJANGO_SETTINGS_MODULE"] = 'settings'

import lxml, scipy.stats, numpy, itertools, re, csv
from logistic_regression import *

from bill.models import *
from committee.models import *
from person.models import *
from person.types import RoleType
from person.analysis import load_sponsorship_analysis
from us import get_congress_dates

from django.db.models import Count

# Group BillType types into bill, joint res, concurrent res, and simple res.
bill_type_map = {
	"bill": (BillType.house_bill, BillType.senate_bill),
	"jr": (BillType.house_joint_resolution, BillType.senate_joint_resolution),
	"cr": (BillType.house_concurrent_resolution, BillType.senate_concurrent_resolution),
	"sr": (BillType.house_resolution, BillType.senate_resolution),
}
bill_type_map_inv = { }
for k, v in bill_type_map.items():
	for bt in v:
		bill_type_map_inv[bt] = k
bill_type_names = {
	"bill": "bills",
	"jr": "joint resolutions",
	"cr": "concurrent resolutions",
	"sr": "simple resolutions",
}

def load_majority_party(congress):
	majority_party = { }
	start, end = get_congress_dates(congress)
	
	for rt, bts in (
		(RoleType.senator, (BillType.senate_bill, BillType.senate_resolution, BillType.senate_concurrent_resolution, BillType.senate_joint_resolution)),
		(RoleType.representative, (BillType.house_bill, BillType.house_resolution, BillType.house_concurrent_resolution, BillType.house_joint_resolution))
		):
		p = PersonRole.objects.filter(startdate__lte=end, enddate__gte=start, role_type=rt).values("party").annotate(count=Count("id")).order_by("-count")[0]["party"]
		for bt in bts:
			majority_party[bt] = p
	return majority_party

def load_committee_membership(congress):
	# load archival committee data
	from parser.committee_parser import ROLE_MAPPING
	committee_membership = { }
	for cnode in lxml.etree.parse("data/us/%d/committees.xml" % congress).xpath("committee|committee/subcommittee"):
		code = cnode.get("code")
		if cnode.tag == "subcommittee": code = cnode.getparent().get("code") + code # not working?
		for mnode in cnode.xpath("member"):
			id = int(mnode.get("id"))
			if not id in committee_membership: committee_membership[id] = { }
			committee_membership[id][code] = ROLE_MAPPING[mnode.get("role", "Member")]
	return committee_membership

cached_leadership_scores = { }
def get_leadership_score(person):
	if person.id in cached_leadership_scores: return cached_leadership_scores[person.id]
	sp_ana = load_sponsorship_analysis(person)
	score = float(sp_ana["leadership"]) if sp_ana else None
	cached_leadership_scores[person.id] = score
	return score

def load_lobbying_data(congress):
	return None # otherwise loading bill pages would invoke this and take a long time to load
	# Count up the number of ocurrences of each bill in the CRP lobbying database.
	from numpy import median
	bill_number_re = re.compile(r"^(hr?|s|hconres|hcon|sconres|scon|hjres|hj|sjres|sj|hres|sres|sr)(\d+)$", re.I)
	bill_type_special = { "h": "hr", "sr": "sres", "hj": "hjres", "sj": "sjres", "scon": "sconres", "hcon": "hconres" }
	lob_bills = csv.reader(open("../crp_lob_bills_20120408.txt"), quotechar="|")
	lobbying_data = { }
	for pk, isssue_id, bill_congress, bill_number in lob_bills:
		if bill_congress.strip() == "" or congress != int(bill_congress): continue
		if bill_number.replace(".", "").startswith("HAMDT"): continue
		if bill_number.replace(".", "").startswith("SAMDT"): continue
		m = bill_number_re.match(bill_number.strip().lower().replace(".", ""))
		if m == None:
			print "bad bill in lobbying data %s %s" % (bill_congress, bill_number)
		else:
			bt, bn = m.group(1), m.group(2)
			bt = bill_type_special.get(bt, bt)
			bt = BillType.by_slug(bt)
			bn = int(bn)
			lobbying_data[(bt, bn)] = lobbying_data.get((bt, bn), 0) + 1
	return { "median": median(lobbying_data.values()), "counts": lobbying_data }

def get_bill_factors(bill, pop_title_prefixes, committee_membership, majority_party, lobbying_data, include_related_bills=True):
	factors = list()
	
	# introduced date (idea from Yano, Smith and Wilkerson 2012 paper)
	idate = bill.introduced_date
	if hasattr(idate, 'date'): idate = idate.date() # not sure how this is possible
	if (idate - get_congress_dates(bill.congress)[0]).days < 90:
		factors.append(("introduced_first90days", "The %s was introduced in the first 90 days of the Congress." % bill.noun, "Introduced in the first 90 days of the Congress (incl. companion bills)."))
	if (idate - get_congress_dates(bill.congress)[0]).days < 365:
		factors.append(("introduced_firstyear", "The %s was introduced in the first year of the Congress." % bill.noun, "Introduced in the first year of the Congress (incl. companion bills)."))
	if (get_congress_dates(bill.congress)[1] - idate).days < 90:
		factors.append(("introduced_last90days", "The %s was introduced in the last 90 days of the Congress." % bill.noun, "Introduced in the last 90 days of the Congress (incl. companion bills)."))
	
	# does the bill's title start with a common prefix?
	for prefix in pop_title_prefixes:
		if bill.title_no_number.startswith(prefix + " "):
			factors.append(("startswith:" + prefix, "The %s's title starts with \"%s.\"" % (bill.noun, prefix), "Title starts with \"%s\"." % prefix))
	
	cosponsors = list(Cosponsor.objects.filter(bill=bill, withdrawn=None).select_related("person"))
	committees = list(bill.committees.all())
	
	maj_party = majority_party[bill.bill_type]
	
	if bill.sponsor_role:
		# party of the sponsor
		sponsor_party = bill.sponsor_role.party
		if sponsor_party != maj_party:
			factors.append( ("sponsor_minority", "The sponsor is a member of the minority party.", "Sponsor is a member of the minority party.") )
	
		# is the sponsor a member/chair of a committee to which the bill has
		# been referred?
		for rname, rvalue in (("member", CommitteeMemberRole.member), ("rankingmember", CommitteeMemberRole.ranking_member), ("vicechair", CommitteeMemberRole.vice_chairman), ("chair", CommitteeMemberRole.chairman)):
			for committee in committees:
				if committee_membership.get(bill.sponsor_id, {}).get(committee.code) == rvalue:
					if rvalue != CommitteeMemberRole.member:
						factors.append(("sponsor_committee_%s" % rname, "The sponsor is the %s of a committee to which the %s has been referred." % (CommitteeMemberRole.by_value(rvalue).label.lower(), bill.noun), "Sponsor is a relevant committee %s." % CommitteeMemberRole.by_value(rvalue).label.lower()))
					if sponsor_party == maj_party:
						factors.append(("sponsor_committee_member_majority", "The sponsor is on a committee to which the %s has been referred, and the sponsor is a member of the majority party." % bill.noun, "Sponsor is on a relevant committee & in majority party."))
						
		# leadership score of the sponsor, doesn't actually seem to be helpful,
		# even though leadership score of cosponsors is.
		if get_leadership_score(bill.sponsor) > .8:
			if sponsor_party == maj_party:
				factors.append(("sponsor_leader_majority", "The sponsor is in the majority party and has a high leadership score.", "Sponsor has a high leadership score (majority party)."))
			else:
				factors.append(("sponsor_leader_minority", "The sponsor has a high leadership score but is not in the majority party.", "Sponsor has a high leadership score (minority party)."))
					
	# count cosponsor assignments to committees by committee role and Member party
	for rname, rvalue in (("committeemember", CommitteeMemberRole.member), ("rankingmember", CommitteeMemberRole.ranking_member), ("vicechair", CommitteeMemberRole.vice_chairman), ("chair", CommitteeMemberRole.chairman)):
		num_cosp = 0
		for cosponsor in cosponsors:
			for committee in committees:
				cvalue = committee_membership.get(cosponsor.person.id, {}).get(committee.code)
				if cvalue == rvalue or (rvalue==CommitteeMemberRole.member and cvalue != None):
					num_cosp += 1
					break
		if rvalue == CommitteeMemberRole.member:
			if num_cosp <= 2: # ranges are tweakable...
				num_cosp = str(num_cosp)
			if num_cosp <= 5:
				num_cosp = "3-5"
			else:
				num_cosp = "6+"
			factors.append( ("cosponsor_%s_%s" % (rname, num_cosp), "%s cosponsors serve on a committee to which the %s has been referred." % (num_cosp, bill.noun), "%s cosponsors are on a relevant committee." % num_cosp) )
		elif num_cosp > 0:
			rname2 = CommitteeMemberRole.by_value(rvalue).label.lower()
			factors.append( ("cosponsor_%s" % rname, "A cosponsor is the %s of a committee to which the %s has been referred." % (rname2, bill.noun), "A cosponsor is a relevant committee %s." % rname2))
			
	# what committees is the bill assigned to? only look at committees
	# in the originating chamber, since assignments in the other chamber
	# indicate the bill had at least one successful vote.
	for cm in committees:
		if cm.committee != None: continue # skip subcommittees
		if CommitteeType.by_value(cm.committee_type).label != bill.originating_chamber: continue
		factors.append( ("committee_%s" % cm.code, "The bill was referred to %s." % cm.shortname, "Referred to %s." % cm.shortname))

	# do we have cosponsors on both parties?
	num_cosp_majority = 0
	for cosponsor in cosponsors:
		if cosponsor.role.party == maj_party:
			num_cosp_majority += 1
	if bill.sponsor and sponsor_party == maj_party and len(cosponsors) >= 6 and num_cosp_majority < 2.0*len(cosponsors)/3:
		factors.append(("cosponsors_bipartisan", "The sponsor is in the majority party and at least one third of the %s's cosponsors are from the minority party." % bill.noun, "Sponsor is in majority party and 1/3rd+ of cosponsors are in minority party."))
	if num_cosp_majority > 0 and num_cosp_majority < len(cosponsors):
		factors.append(("cosponsors_crosspartisan", "There is at least one cosponsor from the majority party and one cosponsor outside of the majority party.", "Has cosponsors from both parties."))

	for is_majority in (False, True):
		for cosponsor in cosponsors:
			if (cosponsor.role.party == maj_party) != is_majority: continue
			if get_leadership_score(cosponsor.person) > .85:
				if is_majority:
					factors.append(("cosponsor_leader_majority", "A cosponsor in the majority party has a high leadership score.", "Cosponsor has high leadership score (majority party)."))
				else:
					factors.append(("cosponsor_leader_minority", "A cosponsor in the minority party has a high leadership score.", "Cosponsor has high leadership score (minority party)."))
				break

	# Is this bill a re-intro from last Congress, and if so was that bill reported by committee?
	if bill.sponsor:
		def normalize_title(title):
			# remove anything that looks like a year
			return re.sub(r"of \d\d\d\d$", "", title)
		for reintro in Bill.objects.filter(congress=bill.congress-1, sponsor=bill.sponsor):
			if normalize_title(bill.title_no_number) == normalize_title(reintro.title_no_number):
				if reintro.current_status not in (BillStatus.introduced, BillStatus.referred):
					factors.append(("reintroduced_of_reported", "This %s was reported by committee as %s in the previous session of Congress." % (bill.noun, reintro.display_number), "Got past committee in a previous Congress."))
				else:
					factors.append(("reintroduced", "This %s was a re-introduction of %s from the previous session of Congress." % (bill.noun, reintro.display_number), "Is a bill reintroduced from a previous Congress."))
				break

	if include_related_bills: # prevent infinite recursion
		# Add factors from any CRS-identified identical bill, changing most factors'
		# key into companion_KEY so that they become separate factors to consider.
		# For some specific factors, lump them in with the factor for the bill itself.
		for rb in RelatedBill.objects.filter(bill=bill, relation="identical").select_related("related_bill", "related_bill__sponsor_role"):
			# has a companion
			factors.append(("companion", "The %s has been introduced in both chambers (the other is %s)." % (bill.noun, rb.related_bill.display_number), "Has a companion bill in the other chamber."))
			
			# companion sponsor's party
			if bill.sponsor_role and rb.related_bill.sponsor_role:
				if bill.sponsor_role.party != rb.related_bill.sponsor_role.party:
					factors.append(("companion_bipartisan", "The %s's companion %s was sponsored by a member of the other party." % (bill.noun, rb.related_bill.display_number), "Has a companion bill sponsored by the other party."))
			
			for f in get_bill_factors(rb.related_bill, pop_title_prefixes, committee_membership, majority_party, lobbying_data, include_related_bills=False):
				if "startswith" in f[0]: continue # don't include title factors because the title is probs the same
				if f[0] in ("introduced_first90days", "introduced_last90days", "introduced_firstyear", "reintroduced_of_reported", "reintroduced"):
					f = (f[0], "%s (on companion bill %s)" % (f[1], rb.related_bill.display_number), f[2])
				else:
					f = ("companion__" + f[0], "Companion bill " + rb.related_bill.display_number + ": " + f[1], "On a companion bill: " + f[2])
					
				# Make sure not to duplicate any factors, especially if we are promoting the companion
				# bill factor to a main factor, we don't want to double count or override the description
				# on the main bill.
				if f[0] in set(k[0] for k in factors): continue
				
				factors.append(f)

	# Are lobbyists registering that they are lobbying on this bill? Does this bill
	# have more registered lobbying than the median bill? Overall this picks out
	# bills NOT likely to be enacted.
	#	
	# Two possible explanations: First, lobbying can be to defeat a bill not just
	# pass it. So this would indicate that on balance lobbying is having that effect.
	#
	# Second it could be because lobbyists don't bother with
	# the easy bills that don't need their help. Meaning, they pick out a pool of
	# improbable bllls, and presumably make those bills more likely to be enacted
	# but still not as likely as the easy bills. (If they truly hurt a bill's future, they
	# would presumably know and stop lobbying!)
	#
	# Looking at lobbying might be more useful if we combined it with another
	# factor that could pick out the hard bills, and then this might show that for
	# hard bills, lobbying made the bills more successful. But it's a bit impossible
	# because surely the lobbyists know better than we do which bills are hard,
	# so it would be impossible to factor out "hard bills" entirely.
	if False:
		if lobbying_data["counts"].get( (bill.bill_type, bill.number), 0 ) > lobbying_data["median"]:
			factors.append( ("crp-lobby-many", "The Center for Responsive Politics reports that a large number of organizations are lobbying on this %s." % bill.noun, "Has many lobbyists.") )
		elif lobbying_data["counts"].get( (bill.bill_type, bill.number), 0 ) > 0:
			factors.append( ("crp-lobby", "The Center for Responsive Politics reports that organizations are lobbying on this %s." % bill.noun, "Has lobbyists.") )

	return factors

def is_success(bill, model_type, indexed_paragraphs):
	if model_type == 0:
		return bill.current_status not in BillStatus.introduced_statuses
	else:
		if bill.current_status in BillStatus.final_status_passed:
			return 1.0

		# If the bill wasn't itself enacted, compare its contents to
		# enacted bills.
		hashes = get_bill_paragraphs(bill)
		if not hashes: return 0.0 # text not available
		good_hashes = 0.0
		total_hashes = 0.0
		for h in hashes:
			c = indexed_paragraphs.get(h, 0)
			if c > 1: continue # if it occurs more than once in enacted bills, it's probably boilerplate so skip it
			total_hashes += 1.0
			if c == 1: good_hashes += 1.0
		return good_hashes/total_hashes
					
def build_model(congress):
	majority_party = load_majority_party(congress)
	committee_membership = load_committee_membership(congress)
	indexed_success_text = load_indexed_success_text()
	lobbying_data = None #load_lobbying_data(congress)
	
	# universe
	BILLS = Bill.objects.filter(congress=congress).prefetch_related()
	
	# compute the most frequent first few words of bills. slurp in all of the titles,
	# record the counts of all of the prefixes of the titles, and then take the top few,
	# excluding ones that are prefixes of another popular prefix.
	title_counts = { }
	for bill in BILLS:
		title = bill.title_no_number
		if title.startswith("Providing for consideration of"): continue # hack, add later
		for nwords in xrange(4, 10):
			prefix = " ".join(title.split(" ")[0:nwords])
			title_counts[prefix] = title_counts.get(prefix, 0) + 1
	title_counts = sorted(title_counts.items(), key = lambda kv : kv[1], reverse=True)
	pop_title_prefixes = list()
	for t, c in title_counts:
		seen = False
		for tt in list(pop_title_prefixes):
			if tt.startswith(t + " "):
				seen = True
			elif t.startswith(tt + " "):
				pop_title_prefixes.remove(tt)
		if seen: continue
		pop_title_prefixes.append(t)
		if len(pop_title_prefixes) == 40: break
	pop_title_prefixes.append("A joint resolution proposing an amendment to the Constitution")
	pop_title_prefixes.append("Providing for consideration of")
		
	# We create separate models for bills by the bill type (bill, joint resolution,
	# concurrent resolution, simple resolution) and by whether the bill's status is
	# introduced/referred or has been reported or more.
	#
	# Once a bill has been reported by committee it's chances of success are
	# of course much higher, since the bills that have not been reported by committee
	# in historical data are necessarily failed bills. Also the models change
	# substantially.
		
	MODEL = dict()
	
	for bill_type, model_type in itertools.product(bill_type_map.keys(), (0, 1)):
		# GET LIST OF BILLS
		
		bills = BILLS.filter(bill_type__in=bill_type_map[bill_type])
		if model_type == 1:
			# In model 0, we scan across all bills, because all bills were
			# in the introduced/referred status at one point. If we filter it to bills whose
			# current status is introduced/referred, obviously they will all have been
			# failed bills, which defeats the purpose. In model 1, we
			# only look at bills that have at least gotten reported so that we can see
			# of reported bills which make it to success.
			bills = bills.exclude(current_status__in=BillStatus.introduced_statuses)

		print bill_type, model_type
		
		total = bills.count()
		
		if model_type == 0:
			# for the introduced model, success is getting out of committee
			total_success = bills.exclude(current_status__in=BillStatus.introduced_statuses).count()
		else:
			# for the reported model, success is being enacted (or whatever final status as appropriate for the bill type)
			total_success = bills.filter(current_status__in=BillStatus.final_status_passed).count()
			
		print "\toverall", int(round(100.0*total_success/total)), "%; N=", total
		
		# GET REGRESSION MATRIX INFORMATION
		
		# Build a list of sets, one for each bill, containing the binary
		# factors that apply to the bill. Build a corresponding list of
		# floats (either 1.0, 0.0) indicating whether the bill was successful.
		#
		# Also remember for each binary factor the total count of bills
		# it applied to and the count of those that were successful.
		#
		# And also remember for each binary factor, the short descriptive
		# text for the factor.
		
		factor_success_rate = { }
		regression_outcomes = [ ]
		regression_predictors = [ ]
		factor_descriptions = { }
		#bills = bills[0:100] # REMOVEME
		for bill in bills:
			# What's the measured outcome for this bill? Check if the bill
			# ended in a success state. Allow floating-point values!
			success = is_success(bill, model_type, indexed_success_text[bill_type])
			
			# Get the binary factors that apply to this bill.
			factors = get_bill_factors(bill, pop_title_prefixes, committee_membership, majority_party, lobbying_data)
			
			# maintain a simple list of success percent rates for each factor individually
			for key, descr, general_descr in factors:
				if not key in factor_success_rate: factor_success_rate[key] = [0, 0] # count of total, successful
				factor_success_rate[key][0] += 1
				factor_success_rate[key][1] += success
				factor_descriptions[key] = general_descr
				
			# build data for a regression
			regression_outcomes.append(success)
			regression_predictors.append(set( f[0] for f in factors )) # extract just the key from the (key, descr) tuple
			
		# FIRST PASS SIGNIFICANCE CHECK
		
		# Reduce the complexity of the regression model by filtering out
		# factors that, when considered independently, don't have a success
		# rate that appears to differ from the population success rate.
			
		factor_binomial_sig = dict()
		for key, bill_counts in factor_success_rate.items():
			# If there were very few bills with this factor, do not include it in the model.
			if bill_counts[0] < 15: continue
			
			# Create a binomial distribution with a sample size the same as
			# the number of bills with this factor, and with a probability
			# of heads equal to the population success rate.
			distr = scipy.stats.binom(bill_counts[0], float(total_success)/float(total))
			
			# What is the possibility that we would see as many or as few
			# successes as we do (i.e. two tailed).
			pless = distr.cdf(bill_counts[1]) # as few == P(count <= observed)
			pmore = 1.0-(distr.cdf(bill_counts[1]-1) if bill_counts[1] > 0 else 0.0) # as many == P(count >= observed)
			p = min(pless, pmore)
			if p < .05:
				factor_binomial_sig[key] = p
				
		# LOGISTIC REGRESSION
		
		for trial in xrange(2):
			regression_predictors_map = None
			regression_beta = None
			if len(factor_binomial_sig) > 0:
				# Assign consecutive indices to the remaining factors.
				regression_predictors_map = dict(reversed(e) for e in enumerate(factor_binomial_sig))
				
				# Build a binary matrix indicating which bills have which factors.
				regression_predictors_2 = [ [] for f in regression_predictors_map ]
				for factors in regression_predictors:
					for fname, findex in regression_predictors_map.items():
						regression_predictors_2[findex].append(1.0 if fname in factors else 0.0)
				regression_predictors_2 = numpy.array(regression_predictors_2)
				regression_outcomes = numpy.array(regression_outcomes)
				
				# Perform regression.
				regression_beta, J_bar, l = logistic_regression(regression_predictors_2, regression_outcomes)
				
				# Remove factors that are within 1.75 standard error from zero,
				# and then re-run the regression.
				if trial == 0:
					# Get the standard errors (the logistic_regression module
					# says to do it this way).
					from numpy import sqrt, diag, abs, median
					from numpy.linalg import inv
					try:
						stderrs = sqrt(diag(inv(J_bar))) # [intercept, beta1, beta2, ...]
					except numpy.linalg.linalg.LinAlgError as e:
						print "\t", e
						break
					
					# The standard errors are coming back wacky large for
					# the factors with VERY large beta. Special-case those.
					for fname, findex in regression_predictors_map.items():
						beta = regression_beta[findex+1]
						stderr = stderrs[findex+1]
						if abs(beta/stderr) < 1.75 and abs(beta) < 5.0:
							# This factor's effect is small/non-significant,
							# so remove it from factor_binomial_sig so that on
							# next iteration it is excluded from regression.
							del factor_binomial_sig[fname]
			
		# Generate the model for output.
		model = dict()
		MODEL[(bill_type,model_type == 0)] = model
		if model_type == 0:
			model["success_name"] = "sent out of committee to the floor"
		else:
			if bill_type == "bill":
				model["success_name"] = "enacted"
			elif bill_type == "jr":
				model["success_name"] = "enacted or passed"
			else:
				model["success_name"] = "agreed to"
		model["count"] = total
		model["success_rate"] = 100.0*total_success/total
		model["bill_type"] = bill_type
		model["bill_type_descr"] = bill_type_names[bill_type]
		model["is_introduced_model"] = (model_type == 0)
		model["regression_predictors_map"] = regression_predictors_map
		model["regression_beta"] = list(regression_beta) if regression_beta != None else None
		model_factors = dict()
		model["factors"] = model_factors
		for key, bill_counts in factor_success_rate.items():
			if key not in factor_binomial_sig: continue
			print "\t" + key, \
				int(round(100.0*bill_counts[1]/bill_counts[0])), "%;", \
				"N=", bill_counts[0], \
				"p<", int(round(100*factor_binomial_sig[key])), \
				"B=", regression_beta[regression_predictors_map[key]+1]
			model_factors[key] = dict()
			model_factors[key]["count"] = bill_counts[0]
			model_factors[key]["success_rate"] = 100.0*bill_counts[1]/bill_counts[0]
			model_factors[key]["regression_beta"] = regression_beta[regression_predictors_map[key]+1]
			model_factors[key]["description"] = factor_descriptions[key]
			
	with open("bill/prognosis_model.py", "w") as modelfile:
		modelfile.write("# this file was automatically generated by prognosis.py\n")
		modelfile.write("congress = %d\n" % congress)
		from pprint import pprint
		modelfile.write("pop_title_prefixes = ")
		pprint(pop_title_prefixes, modelfile)
		modelfile.write("factors = ")
		pprint(MODEL, modelfile)

def compute_prognosis_2(bill, committee_membership, majority_party, lobbying_data, proscore=False):
	import prognosis_model
	
	# get a list of (factorkey, descr) tuples of the factors that are true for
	# this bill. use the model to convert these tuples into %'s and descr's.
	factors = get_bill_factors(bill, prognosis_model.pop_title_prefixes, committee_membership, majority_party, lobbying_data)
	
	# There are two models for every bill, one from introduced to reported
	# and the other from reported to success.
	
	model_1 = prognosis_model.factors[(bill_type_map_inv[bill.bill_type], True)]
	model_2 = prognosis_model.factors[(bill_type_map_inv[bill.bill_type], False)]
	
	# Eliminate factors that are not used in either model.
	factors = [f for f in factors if f[0] in model_1["factors"] or f[0] in model_2["factors"]]
	
	# If we are doing a "proscore", remove any startswith factors that increase
	# a bill's prognosis. These are usually indicative of boring bills like renaming a
	# post office. Startswith factors that decrease a bill's prognosis are still good
	# to include.
	if proscore:
		factors = [(key, decr, longdescr) for (key, decr, longdescr) in factors if 
			not key.startswith("startswith:")
			or (key in model_1["factors"] and model_1["factors"][key]["regression_beta"] < 0)
			or (key in model_2["factors"] and model_2["factors"][key]["regression_beta"] < 0)]

	def eval_model(model):
		# make a prediction using the logistic regression model
		if model["regression_beta"] == None:
			return model["success_rate"]
		else:
			factor_keys = set(f[0] for f in factors)
			predictors = [0.0 for f in xrange(len(model["regression_beta"])-1)] # remove the intercept
			for key, index in model["regression_predictors_map"].items():
				predictors[index] = 1.0 if key in factor_keys else 0.0
			return float(calcprob(model["regression_beta"], numpy.transpose(numpy.array([predictors]))))
			
	prediction_1 = eval_model(model_1)
	prediction_2 = eval_model(model_2)
	
	is_introduced = bill.current_status in BillStatus.introduced_statuses
	
	def helps(factor, state1, state2):
		a = model_1["factors"][factor]["regression_beta"] >= 0 if factor in model_1["factors"] else model_2["factors"][factor]["regression_beta"] >= 0
		b = model_2["factors"][factor]["regression_beta"] >= 0 if factor in model_2["factors"] else model_1["factors"][factor]["regression_beta"] >= 0
		return (a==state1) and (b==state2)
	
	return {
		"is_introduced": is_introduced,
		
		"success_name_1": model_1["success_name"],
		"success_name_2": model_2["success_name"],
		"success_rate_1": model_1["success_rate"],
		"success_rate_2": model_2["success_rate"],
		"success_rate": model_1["success_rate"] * model_2["success_rate"] / 100.0,
		
		"prediction_1": prediction_1,
		"prediction_2": prediction_2,
		"prediction": (prediction_1 * prediction_2 / 100.0) if is_introduced else prediction_2,
		"success_name": model_2["success_name"],
		"bill_type_descr": model_2["bill_type_descr"],
		
		"factors_help_help": [descr for key, descr, gen_descr in factors if helps(key, True, True)],
		"factors_hurt_hurt": [descr for key, descr, gen_descr in factors if helps(key, False, False)],
		"factors_help_hurt": [descr for key, descr, gen_descr in factors if helps(key, True, False)],
		"factors_hurt_help": [descr for key, descr, gen_descr in factors if helps(key, False, True)],
	}

def compute_prognosis(bill, proscore=False):
	import prognosis_model
	majority_party = load_majority_party(bill.congress)
	committee_membership = load_committee_membership(bill.congress)
	prog = compute_prognosis_2(bill, committee_membership, majority_party, None, proscore=proscore)
	prog["congress"] = prognosis_model.congress
	return prog
		
def test_prognosis(congress):
	from math import exp
	from numpy import mean, median, std, digitize, percentile, average
	
	import prognosis_model
	
	majority_party = load_majority_party(congress)
	committee_membership = load_committee_membership(congress)
	indexed_success_text = load_indexed_success_text()
	
	test_results = { }
	
	for model_type in (0, 1):
		for bt in bill_type_map:
			print "Testing", model_type, bt, "..."
			
			# What was the success rate in the training data?
			model = prognosis_model.factors[(bt, model_type==0)]
			sr = model["success_rate"]
			if len(model["factors"]) == 0: continue # nothing interesting to test
			
			# store output....
			model_result = { }
			test_results[(bt, model_type)] = model_result
			model_result["overall"] = sr
			
			for key in ("bill_type", "bill_type_descr", "is_introduced_model", "success_name"):
				model_result[key] = model[key]
			
			# Pull in the data as tuples of (prediction, success), each of which is a
			# float in the range of [0,1].
			bills = Bill.objects.filter(congress=congress, bill_type__in=bill_type_map[bt])
			if model_type == 1: bills = bills.exclude(current_status__in=BillStatus.introduced_statuses)
			#bills = bills[0:100] # REMOVEME
			model_result["count"] = bills.count()
			data = []
			for bill in bills.prefetch_related():
				x = compute_prognosis_2(bill, committee_membership, majority_party, None, proscore=False)
				if model_type == 0:
					x = x["prediction_1"]
				else:
					x = x["prediction_2"]
				y = is_success(bill, model_type, indexed_success_text[bt])
				data.append((x, y))
			xdata = [x[0] for x in data]
			
			# Compute %-success for bins each having 10% of the data, to show that as
			# prognosis increases, the %-success increases.
			model_result["bins"] = []
			bins = []
			for p in xrange(0, 100+10, 10):
				b = percentile(xdata, p)
				if len(bins) == 0 or b > bins[-1]:
					bins.append(b)
			bindices = digitize(xdata, bins)
			for b in xrange(len(bins)-1):
				bindata = [data[i] for i in xrange(len(data)) if bindices[i] == b]
				if len(bindata) == 0: continue
				median_prog = median([x for x,y in bindata])
				pct_success = mean([y for x,y in bindata])
				model_result["bins"].append( (median_prog, len(bindata), pct_success) )
			
			# Make a precision-recall chart over various values for a prognosis threshold.
			# This chart doesn't make much sense now that we measure success as a
			# continuous variable. I've adapted the notions of precision and recall so
			# that they are sensible in this case. When the y values are in fact binary
			# (0.0 or 1.0), the result is the traditional definition of precision and
			# recall.
			def compute_scores(T):
				precision = mean([y for (x,y) in data if (x >= T)])
				recall = average([1.0 if x >= T else 0.0 for (x,y) in data], weights=[y for (x,y) in data])
				return {
					"threshold": T,
					"precision": precision,
					"recall": recall,
				}
			model_result["precision_recall"] = []
			for i in range(-18, 0):
				T = 100 * exp(i / 5.0) # threshold data points on a logarithmic scale
				cs = compute_scores(T)
				if cs["precision"]+cs["recall"] == 0: continue # causes weirdness in charts
				model_result["precision_recall"].append(cs)
			

	with open("bill/prognosis_model_test.py", "w") as modelfile:
		modelfile.write("# this file was automatically generated by prognosis.py\n")
		modelfile.write("train_congress = %d\n" % prognosis_model.congress)
		modelfile.write("test_congress = %d\n" % congress)
		from pprint import pprint
		modelfile.write("model_test_results = ")
		pprint(test_results, modelfile)

def top_prognosis(congress, bill_type):
	max_p = None
	max_b = None
	majority_party = load_majority_party(congress)
	committee_membership = load_committee_membership(congress)
	for bill in Bill.objects.filter(congress=congress, bill_type__in=bill_type_map_inv[bill_type]):
		p = compute_prognosis_2(bill, committee_membership, majority_party)
		if not max_p or p["prediction"] > max_p:
			max_p = p["prediction"]
			max_b = bill
	print max_p, max_b

def get_bill_paragraphs(bill):
	from billtext import load_bill_text
	from hashlib import md5
		
	try:
		dom = lxml.etree.fromstring(load_bill_text(bill, None)["text_html"])
	except IOError:
		return None
		
	hashes = { }
		
	for node in dom.xpath("//p"):	
		text = lxml.etree.tostring(node, method="text", encoding="utf8")
		text = text.lower() # normalize case
		text = re.sub("^\(.*?\)\s*", "", text) # remove initial list numbering
		text = re.sub(r"\W+", " ", text).strip() # normalize spaces and other non-word characters
		if text == "": continue
		text = md5(text).hexdigest()
		hashes[text] = hashes.get(text, 0) + 1

	return hashes

def index_successful_paragraphs(congress):
	cache = { bt: {} for bt in bill_type_map }
		
	# For each successful bill, load its text and store hashes of
	# its paragraphs.
	for bill_type in bill_type_map.keys():
		bills = Bill.objects.filter(congress=congress, bill_type__in=bill_type_map[bill_type],
			current_status__in=BillStatus.final_status_passed)
		for bill in bills:
			hashes = get_bill_paragraphs(bill)
			if not hashes: continue
			for h, c in hashes.items():
				cache[bill_type][h] = cache[bill_type].get(h, 0) + c

	# Write out a list of hashes and for each, the number of times
	# the hash occurred in successful bills. Paragraphs that appear
	# more than once won't be counted.
	with open("bill/prognosis_model_paragraphs.txt", "w") as cachefile:
		for bill_type in bill_type_map.keys():
			cachefile.write(bill_type + "\n")
			for k, v in sorted(cache[bill_type].items()):
				cachefile.write(k + " " + str(v) + "\n")
			cachefile.write("\n")
		
def load_indexed_success_text():
	cache = { bt: {} for bt in bill_type_map } 
	bt = None
	with open("bill/prognosis_model_paragraphs.txt") as cachefile:
		for line in cachefile:
			line = line.strip()
			if bt is None:
				bt = line
			elif line == "":
				bt = None # next line is a bill type
			else:
				hashval, count = line.split(" ")
				cache[bt][hashval] = int(count)
	return cache
			
if __name__ == "__main__":
	import sys
	if sys.argv[-1] == "train":
		index_successful_paragraphs(112)
		build_model(112)
	elif sys.argv[-1] == "test":
		index_successful_paragraphs(111)
		build_model(111) # delete the model after if this is for a past Congress!
		index_successful_paragraphs(112)
		test_prognosis(112)
	elif sys.argv[-1] == "index-text":
		index_successful_paragraphs(112)
		

########NEW FILE########
__FILENAME__ = prognosis_model
# this file was automatically generated by prognosis.py
congress = 112
pop_title_prefixes = [u'A bill to extend the temporary suspension of duty',
 u'To suspend temporarily the duty on certain',
 u'To amend the Internal Revenue Code of 1986 to',
 u'Expressing the sense of the House of Representatives that',
 u'To extend the suspension of duty on',
 u'A bill to suspend temporarily the duty on certain',
 u'To designate the facility of the United States Postal',
 u'Proposing an amendment to the Constitution of the United',
 u'To extend the temporary suspension of duty on certain',
 u'A resolution recognizing the',
 u'Expressing support for designation of',
 u'A bill to amend the Internal Revenue Code of',
 u'For the relief of',
 u'To reduce temporarily the duty on',
 u'To extend and modify the temporary',
 u'To direct the Secretary of',
 u'Expressing the sense of Congress that',
 u'A bill for the relief of',
 u'A resolution congratulating the',
 u'To extend the temporary reduction of duty on',
 u'To suspend temporarily the duty on mixtures',
 u'A bill to reduce temporarily the duty on',
 u'A resolution honoring the',
 u'A resolution expressing the sense of the Senate that',
 u'To suspend temporarily the rate of duty on certain',
 u'A bill to amend title 38, United States Code,',
 u'To amend title 38, United States Code, to',
 u'To provide for the',
 u'A resolution designating the week',
 u'A bill to extend and modify the temporary reduction',
 u'A resolution commemorating the',
 u'A bill to require the',
 u'Supporting the goals and ideals of National',
 u'Expressing support for the',
 u'A bill to designate',
 u'A resolution supporting the goals and ideals of',
 u'A bill to renew the temporary suspension of duty',
 u'A bill to provide for',
 u'Bring Jobs Home Act',
 u'A bill to authorize',
 'A joint resolution proposing an amendment to the Constitution',
 'Providing for consideration of']
factors = {('bill', False): {'bill_type': 'bill',
                   'bill_type_descr': 'bills',
                   'count': 1159,
                   'factors': {u'committee_HSAG': {'count': 28,
                                                   'description': u'Referred to House Agriculture.',
                                                   'regression_beta': -1.6460992682865168,
                                                   'success_rate': 7.789747807584258},
                               u'committee_HSBU': {'count': 41,
                                                   'description': u'Referred to House Budget.',
                                                   'regression_beta': 0.97682660369153274,
                                                   'success_rate': 45.938290307700285},
                               u'committee_HSPW': {'count': 64,
                                                   'description': u'Referred to House Transportation and Infrastructure.',
                                                   'regression_beta': 0.72511768732384674,
                                                   'success_rate': 38.08943334605393},
                               u'committee_SSGA': {'count': 42,
                                                   'description': u'Referred to Senate Homeland Security and Governmental Affairs.',
                                                   'regression_beta': 0.81929118636986686,
                                                   'success_rate': 48.090557371296555},
                               'companion_bipartisan': {'count': 78,
                                                        'description': 'Has a companion bill sponsored by the other party.',
                                                        'regression_beta': 1.3644104646958537,
                                                        'success_rate': 55.76395085326663},
                               'cosponsor_committeemember_3-5': {'count': 187,
                                                                 'description': '3-5 cosponsors are on a relevant committee.',
                                                                 'regression_beta': -0.27984732534290846,
                                                                 'success_rate': 31.173096914379364},
                               'cosponsor_committeemember_6+': {'count': 972,
                                                                'description': '6+ cosponsors are on a relevant committee.',
                                                                'regression_beta': -0.33129557164021634,
                                                                'success_rate': 29.225665292784928},
                               'cosponsor_rankingmember': {'count': 177,
                                                           'description': 'A cosponsor is a relevant committee ranking member.',
                                                           'regression_beta': 0.82009590864138882,
                                                           'success_rate': 42.47166328235828},
                               'cosponsors_bipartisan': {'count': 137,
                                                         'description': 'Sponsor is in majority party and 1/3rd+ of cosponsors are in minority party.',
                                                         'regression_beta': 0.67853882448641156,
                                                         'success_rate': 47.95341198733108},
                               'cosponsors_crosspartisan': {'count': 549,
                                                            'description': 'Has cosponsors from both parties.',
                                                            'regression_beta': -0.42616978932970428,
                                                            'success_rate': 31.341344403604108},
                               'introduced_firstyear': {'count': 788,
                                                        'description': 'Introduced in the first year of the Congress (incl. companion bills).',
                                                        'regression_beta': -0.46027243269546614,
                                                        'success_rate': 27.09179611571291},
                               u'startswith:To designate the facility of the United States Postal': {'count': 49,
                                                                                                     'description': u'Title starts with "To designate the facility of the United States Postal".',
                                                                                                     'regression_beta': 3.0667738005186602,
                                                                                                     'success_rate': 83.6734693877551}},
                   'is_introduced_model': False,
                   'regression_beta': [-0.61114289698312507,
                                       1.3644104646958537,
                                       -0.33129557164021634,
                                       0.97682660369153274,
                                       -0.27984732534290846,
                                       -0.46027243269546614,
                                       0.67853882448641156,
                                       0.82009590864138882,
                                       0.81929118636986686,
                                       0.72511768732384674,
                                       -1.6460992682865168,
                                       -0.42616978932970428,
                                       3.0667738005186602],
                   'regression_predictors_map': {u'committee_HSAG': 9,
                                                 u'committee_HSBU': 2,
                                                 u'committee_HSPW': 8,
                                                 u'committee_SSGA': 7,
                                                 'companion_bipartisan': 0,
                                                 'cosponsor_committeemember_3-5': 3,
                                                 'cosponsor_committeemember_6+': 1,
                                                 'cosponsor_rankingmember': 6,
                                                 'cosponsors_bipartisan': 5,
                                                 'cosponsors_crosspartisan': 10,
                                                 'introduced_firstyear': 4,
                                                 u'startswith:To designate the facility of the United States Postal': 11},
                   'success_name': 'enacted',
                   'success_rate': 23.46850733390854},
 ('bill', True): {'bill_type': 'bill',
                  'bill_type_descr': 'bills',
                  'count': 10439,
                  'factors': {u'committee_HSAP': {'count': 112,
                                                  'description': u'Referred to House Appropriations.',
                                                  'regression_beta': 1.112915788324119,
                                                  'success_rate': 24.107142857142858},
                              u'committee_HSAS': {'count': 321,
                                                  'description': u'Referred to House Armed Services.',
                                                  'regression_beta': -1.154356911697463,
                                                  'success_rate': 5.29595015576324},
                              u'committee_HSBU': {'count': 160,
                                                  'description': u'Referred to House Budget.',
                                                  'regression_beta': 0.59605009553384791,
                                                  'success_rate': 25.625},
                              u'committee_HSED': {'count': 552,
                                                  'description': u'Referred to House Education and the Workforce.',
                                                  'regression_beta': -1.138802609716338,
                                                  'success_rate': 3.8043478260869565},
                              u'committee_HSFA': {'count': 264,
                                                  'description': u'Referred to House Foreign Affairs.',
                                                  'regression_beta': -0.47515922155714035,
                                                  'success_rate': 14.772727272727273},
                              u'committee_HSHM': {'count': 134,
                                                  'description': u'Referred to House Homeland Security.',
                                                  'regression_beta': 0.80895559147780183,
                                                  'success_rate': 29.104477611940297},
                              u'committee_HSIF': {'count': 1012,
                                                  'description': u'Referred to House Energy and Commerce.',
                                                  'regression_beta': -0.57161723850150925,
                                                  'success_rate': 8.300395256916996},
                              u'committee_HSII': {'count': 649,
                                                  'description': u'Referred to House Natural Resources.',
                                                  'regression_beta': 0.80002730530110111,
                                                  'success_rate': 24.19106317411402},
                              u'committee_HSWM': {'count': 2530,
                                                  'description': u'Referred to House Ways and Means.',
                                                  'regression_beta': -1.5711827950539237,
                                                  'success_rate': 2.8458498023715415},
                              u'committee_SLIA': {'count': 43,
                                                  'description': u'Referred to Senate Indian Affairs.',
                                                  'regression_beta': 1.0316704178168636,
                                                  'success_rate': 46.51162790697674},
                              u'committee_SSAF': {'count': 74,
                                                  'description': u'Referred to Senate Agriculture, Nutrition, and Forestry.',
                                                  'regression_beta': -1.8038891677447195,
                                                  'success_rate': 4.054054054054054},
                              u'committee_SSAP': {'count': 27,
                                                  'description': u'Referred to Senate Appropriations.',
                                                  'regression_beta': 1.9057514960783573,
                                                  'success_rate': 51.851851851851855},
                              u'committee_SSBK': {'count': 172,
                                                  'description': u'Referred to Senate Banking, Housing, and Urban Affairs.',
                                                  'regression_beta': -1.7078660777783925,
                                                  'success_rate': 5.232558139534884},
                              u'committee_SSBU': {'count': 27,
                                                  'description': u'Referred to Senate Budget.',
                                                  'regression_beta': -31.185010165668782,
                                                  'success_rate': 0.0},
                              u'committee_SSCM': {'count': 187,
                                                  'description': u'Referred to Senate Commerce, Science, and Transportation.',
                                                  'regression_beta': -0.58783756263530129,
                                                  'success_rate': 17.112299465240643},
                              u'committee_SSFI': {'count': 1349,
                                                  'description': u'Referred to Senate Finance.',
                                                  'regression_beta': -2.9359918857882974,
                                                  'success_rate': 0.8895478131949592},
                              u'committee_SSHR': {'count': 383,
                                                  'description': u'Referred to Senate Health, Education, Labor, and Pensions.',
                                                  'regression_beta': -2.3518260591490816,
                                                  'success_rate': 2.6109660574412534},
                              u'committee_SSJU': {'count': 325,
                                                  'description': u'Referred to Senate Judiciary.',
                                                  'regression_beta': -0.42982939665394532,
                                                  'success_rate': 19.384615384615383},
                              u'companion__committee_HSFA': {'count': 16,
                                                             'description': u'On a companion bill: Referred to House Foreign Affairs.',
                                                             'regression_beta': 1.1203866877717061,
                                                             'success_rate': 37.5},
                              u'companion__committee_HSII': {'count': 103,
                                                             'description': u'On a companion bill: Referred to House Natural Resources.',
                                                             'regression_beta': 1.064482476911651,
                                                             'success_rate': 27.184466019417474},
                              u'companion__committee_SSJU': {'count': 58,
                                                             'description': u'On a companion bill: Referred to Senate Judiciary.',
                                                             'regression_beta': 0.59928914338097128,
                                                             'success_rate': 27.586206896551722},
                              'companion__cosponsors_bipartisan': {'count': 141,
                                                                   'description': 'On a companion bill: Sponsor is in majority party and 1/3rd+ of cosponsors are in minority party.',
                                                                   'regression_beta': 0.89134715963954314,
                                                                   'success_rate': 18.43971631205674},
                              'companion__sponsor_committee_chair': {'count': 50,
                                                                     'description': 'On a companion bill: Sponsor is a relevant committee chairman.',
                                                                     'regression_beta': 1.4425988152619207,
                                                                     'success_rate': 32.0},
                              'cosponsor_chair': {'count': 416,
                                                  'description': 'A cosponsor is a relevant committee chairman.',
                                                  'regression_beta': 1.7168583193778078,
                                                  'success_rate': 51.20192307692308},
                              'cosponsor_leader_majority': {'count': 997,
                                                            'description': 'Cosponsor has high leadership score (majority party).',
                                                            'regression_beta': 0.29589973054555208,
                                                            'success_rate': 22.367101303911735},
                              'cosponsor_leader_minority': {'count': 708,
                                                            'description': 'Cosponsor has high leadership score (minority party).',
                                                            'regression_beta': -0.57940848112474541,
                                                            'success_rate': 8.757062146892656},
                              'cosponsor_rankingmember': {'count': 635,
                                                          'description': 'A cosponsor is a relevant committee ranking member.',
                                                          'regression_beta': 0.50567702801486403,
                                                          'success_rate': 27.874015748031496},
                              'cosponsors_crosspartisan': {'count': 2828,
                                                           'description': 'Has cosponsors from both parties.',
                                                           'regression_beta': 0.53655409078523497,
                                                           'success_rate': 19.413012729844414},
                              'reintroduced': {'count': 2108,
                                               'description': 'Is a bill reintroduced from a previous Congress.',
                                               'regression_beta': -0.79971621734106568,
                                               'success_rate': 5.313092979127135},
                              'reintroduced_of_reported': {'count': 294,
                                                           'description': 'Got past committee in a previous Congress.',
                                                           'regression_beta': 1.1279126244837605,
                                                           'success_rate': 40.816326530612244},
                              'sponsor_committee_chair': {'count': 424,
                                                          'description': 'Sponsor is a relevant committee chairman.',
                                                          'regression_beta': 2.0713157506983042,
                                                          'success_rate': 58.72641509433962},
                              'sponsor_committee_member_majority': {'count': 2771,
                                                                    'description': 'Sponsor is on a relevant committee & in majority party.',
                                                                    'regression_beta': 0.81570150577421974,
                                                                    'success_rate': 23.42114760014435},
                              'sponsor_minority': {'count': 4227,
                                                   'description': 'Sponsor is a member of the minority party.',
                                                   'regression_beta': -0.2979210486588853,
                                                   'success_rate': 6.434823752070026},
                              u'startswith:A bill to authorize': {'count': 23,
                                                                  'description': u'Title starts with "A bill to authorize".',
                                                                  'regression_beta': 1.1377648573253902,
                                                                  'success_rate': 30.434782608695652},
                              u'startswith:A bill to designate': {'count': 25,
                                                                  'description': u'Title starts with "A bill to designate".',
                                                                  'regression_beta': 2.2532965441799511,
                                                                  'success_rate': 52.0},
                              u'startswith:A bill to extend and modify the temporary reduction': {'count': 28,
                                                                                                  'description': u'Title starts with "A bill to extend and modify the temporary reduction".',
                                                                                                  'regression_beta': -29.415164052891257,
                                                                                                  'success_rate': 0.0},
                              u'startswith:A bill to extend the temporary suspension of duty': {'count': 231,
                                                                                                'description': u'Title starts with "A bill to extend the temporary suspension of duty".',
                                                                                                'regression_beta': -30.719707131402192,
                                                                                                'success_rate': 0.0},
                              u'startswith:A bill to reduce temporarily the duty on': {'count': 34,
                                                                                       'description': u'Title starts with "A bill to reduce temporarily the duty on".',
                                                                                       'regression_beta': -29.321634422582161,
                                                                                       'success_rate': 0.0},
                              u'startswith:A bill to suspend temporarily the duty on certain': {'count': 80,
                                                                                                'description': u'Title starts with "A bill to suspend temporarily the duty on certain".',
                                                                                                'regression_beta': -29.95158385675084,
                                                                                                'success_rate': 0.0},
                              u'startswith:To designate the facility of the United States Postal': {'count': 71,
                                                                                                    'description': u'Title starts with "To designate the facility of the United States Postal".',
                                                                                                    'regression_beta': 2.8329951586197764,
                                                                                                    'success_rate': 69.01408450704226},
                              u'startswith:To extend and modify the temporary': {'count': 41,
                                                                                 'description': u'Title starts with "To extend and modify the temporary".',
                                                                                 'regression_beta': -29.26372916101743,
                                                                                 'success_rate': 0.0},
                              u'startswith:To extend the suspension of duty on': {'count': 81,
                                                                                  'description': u'Title starts with "To extend the suspension of duty on".',
                                                                                  'regression_beta': -30.805767247557775,
                                                                                  'success_rate': 0.0},
                              u'startswith:To extend the temporary reduction of duty on': {'count': 37,
                                                                                           'description': u'Title starts with "To extend the temporary reduction of duty on".',
                                                                                           'regression_beta': -30.12045705322987,
                                                                                           'success_rate': 0.0},
                              u'startswith:To extend the temporary suspension of duty on certain': {'count': 58,
                                                                                                    'description': u'Title starts with "To extend the temporary suspension of duty on certain".',
                                                                                                    'regression_beta': -30.656131764756175,
                                                                                                    'success_rate': 0.0},
                              u'startswith:To reduce temporarily the duty on': {'count': 41,
                                                                                'description': u'Title starts with "To reduce temporarily the duty on".',
                                                                                'regression_beta': -30.548995959991,
                                                                                'success_rate': 0.0},
                              u'startswith:To suspend temporarily the duty on certain': {'count': 137,
                                                                                         'description': u'Title starts with "To suspend temporarily the duty on certain".',
                                                                                         'regression_beta': -31.190052043095701,
                                                                                         'success_rate': 0.0},
                              u'startswith:To suspend temporarily the duty on mixtures': {'count': 35,
                                                                                          'description': u'Title starts with "To suspend temporarily the duty on mixtures".',
                                                                                          'regression_beta': -29.952576341126356,
                                                                                          'success_rate': 0.0},
                              u'startswith:To suspend temporarily the rate of duty on certain': {'count': 31,
                                                                                                 'description': u'Title starts with "To suspend temporarily the rate of duty on certain".',
                                                                                                 'regression_beta': -29.398822253460999,
                                                                                                 'success_rate': 0.0}},
                  'is_introduced_model': True,
                  'regression_beta': [-2.3574732708450576,
                                      -1.138802609716338,
                                      -2.9359918857882974,
                                      -30.12045705322987,
                                      -31.185010165668782,
                                      -0.79971621734106568,
                                      -30.548995959991,
                                      1.7168583193778078,
                                      -30.805767247557775,
                                      -1.7078660777783925,
                                      -29.398822253460999,
                                      1.1279126244837605,
                                      -29.95158385675084,
                                      1.1203866877717061,
                                      2.2532965441799511,
                                      0.29589973054555208,
                                      0.80895559147780183,
                                      0.89134715963954314,
                                      1.4425988152619207,
                                      0.59928914338097128,
                                      -29.415164052891257,
                                      -0.42982939665394532,
                                      1.064482476911651,
                                      -1.5711827950539237,
                                      -2.3518260591490816,
                                      0.50567702801486403,
                                      0.59605009553384791,
                                      -0.2979210486588853,
                                      -30.656131764756175,
                                      2.0713157506983042,
                                      -0.47515922155714035,
                                      -29.26372916101743,
                                      1.9057514960783573,
                                      -29.952576341126356,
                                      -0.58783756263530129,
                                      -1.8038891677447195,
                                      1.112915788324119,
                                      0.80002730530110111,
                                      -1.154356911697463,
                                      0.81570150577421974,
                                      -30.719707131402192,
                                      1.1377648573253902,
                                      -0.57161723850150925,
                                      -31.190052043095701,
                                      0.53655409078523497,
                                      -29.321634422582161,
                                      2.8329951586197764,
                                      -0.57940848112474541,
                                      1.0316704178168636],
                  'regression_predictors_map': {u'committee_HSAP': 35,
                                                u'committee_HSAS': 37,
                                                u'committee_HSBU': 25,
                                                u'committee_HSED': 0,
                                                u'committee_HSFA': 29,
                                                u'committee_HSHM': 15,
                                                u'committee_HSIF': 41,
                                                u'committee_HSII': 36,
                                                u'committee_HSWM': 22,
                                                u'committee_SLIA': 47,
                                                u'committee_SSAF': 34,
                                                u'committee_SSAP': 31,
                                                u'committee_SSBK': 8,
                                                u'committee_SSBU': 3,
                                                u'committee_SSCM': 33,
                                                u'committee_SSFI': 1,
                                                u'committee_SSHR': 23,
                                                u'committee_SSJU': 20,
                                                u'companion__committee_HSFA': 12,
                                                u'companion__committee_HSII': 21,
                                                u'companion__committee_SSJU': 18,
                                                'companion__cosponsors_bipartisan': 16,
                                                'companion__sponsor_committee_chair': 17,
                                                'cosponsor_chair': 6,
                                                'cosponsor_leader_majority': 14,
                                                'cosponsor_leader_minority': 46,
                                                'cosponsor_rankingmember': 24,
                                                'cosponsors_crosspartisan': 43,
                                                'reintroduced': 4,
                                                'reintroduced_of_reported': 10,
                                                'sponsor_committee_chair': 28,
                                                'sponsor_committee_member_majority': 38,
                                                'sponsor_minority': 26,
                                                u'startswith:A bill to authorize': 40,
                                                u'startswith:A bill to designate': 13,
                                                u'startswith:A bill to extend and modify the temporary reduction': 19,
                                                u'startswith:A bill to extend the temporary suspension of duty': 39,
                                                u'startswith:A bill to reduce temporarily the duty on': 44,
                                                u'startswith:A bill to suspend temporarily the duty on certain': 11,
                                                u'startswith:To designate the facility of the United States Postal': 45,
                                                u'startswith:To extend and modify the temporary': 30,
                                                u'startswith:To extend the suspension of duty on': 7,
                                                u'startswith:To extend the temporary reduction of duty on': 2,
                                                u'startswith:To extend the temporary suspension of duty on certain': 27,
                                                u'startswith:To reduce temporarily the duty on': 5,
                                                u'startswith:To suspend temporarily the duty on certain': 42,
                                                u'startswith:To suspend temporarily the duty on mixtures': 32,
                                                u'startswith:To suspend temporarily the rate of duty on certain': 9},
                  'success_name': 'sent out of committee to the floor',
                  'success_rate': 11.102596034102884},
 ('cr', False): {'bill_type': 'cr',
                 'bill_type_descr': 'concurrent resolutions',
                 'count': 85,
                 'factors': {},
                 'is_introduced_model': False,
                 'regression_beta': None,
                 'regression_predictors_map': None,
                 'success_name': 'agreed to',
                 'success_rate': 58.8235294117647},
 ('cr', True): {'bill_type': 'cr',
                'bill_type_descr': 'concurrent resolutions',
                'count': 212,
                'factors': {u'committee_HSFA': {'count': 35,
                                                'description': u'Referred to House Foreign Affairs.',
                                                'regression_beta': -2.0482202729361054,
                                                'success_rate': 8.571428571428571},
                            u'committee_HSJU': {'count': 15,
                                                'description': u'Referred to House Judiciary.',
                                                'regression_beta': -2.6850321486255497,
                                                'success_rate': 6.666666666666667},
                            'companion': {'count': 47,
                                          'description': 'Has a companion bill in the other chamber.',
                                          'regression_beta': -34.632664134806369,
                                          'success_rate': 19.148936170212767},
                            'companion__cosponsor_committeemember_6+': {'count': 39,
                                                                        'description': 'On a companion bill: 6+ cosponsors are on a relevant committee.',
                                                                        'regression_beta': 33.39906374096487,
                                                                        'success_rate': 23.076923076923077},
                            u'startswith:Expressing the sense of Congress that': {'count': 37,
                                                                                  'description': u'Title starts with "Expressing the sense of Congress that".',
                                                                                  'regression_beta': -36.793158909668264,
                                                                                  'success_rate': 0.0}},
                'is_introduced_model': True,
                'regression_beta': [0.55005116526977382,
                                    -2.0482202729361054,
                                    -36.793158909668264,
                                    -34.632664134806369,
                                    -2.6850321486255497,
                                    33.39906374096487],
                'regression_predictors_map': {u'committee_HSFA': 0,
                                              u'committee_HSJU': 3,
                                              'companion': 2,
                                              'companion__cosponsor_committeemember_6+': 4,
                                              u'startswith:Expressing the sense of Congress that': 1},
                'success_name': 'sent out of committee to the floor',
                'success_rate': 40.094339622641506},
 ('jr', False): {'bill_type': 'jr',
                 'bill_type_descr': 'joint resolutions',
                 'count': 36,
                 'factors': {'companion': {'count': 19,
                                           'description': 'Has a companion bill in the other chamber.',
                                           'regression_beta': -1.3562940294110677,
                                           'success_rate': 6.318058076225046},
                             'companion__cosponsor_committeemember_6+': {'count': 16,
                                                                         'description': 'On a companion bill: 6+ cosponsors are on a relevant committee.',
                                                                         'regression_beta': -1.3562940294110677,
                                                                         'success_rate': 7.502693965517242}},
                 'is_introduced_model': False,
                 'regression_beta': [0.20067069546215099,
                                     -1.3562940294110677,
                                     -1.3562940294110677],
                 'regression_predictors_map': {'companion': 1,
                                               'companion__cosponsor_committeemember_6+': 0},
                 'success_name': 'enacted or passed',
                 'success_rate': 33.333333333333336},
 ('jr', True): {'bill_type': 'jr',
                'bill_type_descr': 'joint resolutions',
                'count': 173,
                'factors': {'companion': {'count': 57,
                                          'description': 'Has a companion bill in the other chamber.',
                                          'regression_beta': -33.237398772858477,
                                          'success_rate': 33.333333333333336},
                            'companion__cosponsor_committeemember_6+': {'count': 44,
                                                                        'description': 'On a companion bill: 6+ cosponsors are on a relevant committee.',
                                                                        'regression_beta': 34.069795165401921,
                                                                        'success_rate': 36.36363636363637},
                            'cosponsor_committeemember_3-5': {'count': 27,
                                                              'description': '3-5 cosponsors are on a relevant committee.',
                                                              'regression_beta': -2.2584146411289732,
                                                              'success_rate': 3.7037037037037037},
                            'cosponsor_leader_minority': {'count': 19,
                                                          'description': 'Cosponsor has high leadership score (minority party).',
                                                          'regression_beta': -33.744631453379235,
                                                          'success_rate': 0.0},
                            'sponsor_committee_member_majority': {'count': 23,
                                                                  'description': 'Sponsor is on a relevant committee & in majority party.',
                                                                  'regression_beta': 2.4032967923655768,
                                                                  'success_rate': 60.869565217391305},
                            u'startswith:Proposing an amendment to the Constitution of the United': {'count': 62,
                                                                                                     'description': u'Title starts with "Proposing an amendment to the Constitution of the United".',
                                                                                                     'regression_beta': -36.975844642493946,
                                                                                                     'success_rate': 0.0}},
                'is_introduced_model': True,
                'regression_beta': [-1.233067185492277,
                                    -2.2584146411289732,
                                    2.4032967923655768,
                                    -33.237398772858477,
                                    34.069795165401921,
                                    -33.744631453379235,
                                    -36.975844642493946],
                'regression_predictors_map': {'companion': 2,
                                              'companion__cosponsor_committeemember_6+': 3,
                                              'cosponsor_committeemember_3-5': 0,
                                              'cosponsor_leader_minority': 4,
                                              'sponsor_committee_member_majority': 1,
                                              u'startswith:Proposing an amendment to the Constitution of the United': 5},
                'success_name': 'sent out of committee to the floor',
                'success_rate': 20.809248554913296},
 ('sr', False): {'bill_type': 'sr',
                 'bill_type_descr': 'simple resolutions',
                 'count': 690,
                 'factors': {u'committee_HSFA': {'count': 18,
                                                 'description': u'Referred to House Foreign Affairs.',
                                                 'regression_beta': -3.5967980402881281,
                                                 'success_rate': 79.34796140678492},
                             u'committee_SSFR': {'count': 34,
                                                 'description': u'Referred to Senate Foreign Relations.',
                                                 'regression_beta': -3.5285772920668013,
                                                 'success_rate': 77.5812194341606},
                             'cosponsor_rankingmember': {'count': 41,
                                                         'description': 'A cosponsor is a relevant committee ranking member.',
                                                         'regression_beta': 0.50719725242033264,
                                                         'success_rate': 90.03334064309675}},
                 'is_introduced_model': False,
                 'regression_beta': [4.6214657378049635,
                                     -3.5967980402881281,
                                     -3.5285772920668013,
                                     0.50719725242033264],
                 'regression_predictors_map': {u'committee_HSFA': 0,
                                               u'committee_SSFR': 1,
                                               'cosponsor_rankingmember': 2},
                 'success_name': 'agreed to',
                 'success_rate': 97.2463768115942},
 ('sr', True): {'bill_type': 'sr',
                'bill_type_descr': 'simple resolutions',
                'count': 1475,
                'factors': {u'committee_HSAS': {'count': 39,
                                                'description': u'Referred to House Armed Services.',
                                                'regression_beta': -2.7658089458979433,
                                                'success_rate': 10.256410256410257},
                            u'committee_HSED': {'count': 82,
                                                'description': u'Referred to House Education and the Workforce.',
                                                'regression_beta': -5.2987355142051573,
                                                'success_rate': 1.2195121951219512},
                            u'committee_HSFA': {'count': 173,
                                                'description': u'Referred to House Foreign Affairs.',
                                                'regression_beta': -3.2527923664967262,
                                                'success_rate': 10.404624277456648},
                            u'committee_HSGO': {'count': 90,
                                                'description': u'Referred to House Oversight and Government Reform.',
                                                'regression_beta': -4.5141591370342153,
                                                'success_rate': 2.2222222222222223},
                            u'committee_HSHA': {'count': 50,
                                                'description': u'Referred to House House Administration.',
                                                'regression_beta': -2.5336271947873863,
                                                'success_rate': 18.0},
                            u'committee_HSIF': {'count': 88,
                                                'description': u'Referred to House Energy and Commerce.',
                                                'regression_beta': -4.4497367597532245,
                                                'success_rate': 1.1363636363636365},
                            u'committee_HSII': {'count': 22,
                                                'description': u'Referred to House Natural Resources.',
                                                'regression_beta': -35.781879261016797,
                                                'success_rate': 0.0},
                            u'committee_HSJU': {'count': 57,
                                                'description': u'Referred to House Judiciary.',
                                                'regression_beta': -3.0625429331386882,
                                                'success_rate': 7.017543859649122},
                            u'committee_HSPW': {'count': 16,
                                                'description': u'Referred to House Transportation and Infrastructure.',
                                                'regression_beta': -1.9308921095069571,
                                                'success_rate': 18.75},
                            u'committee_HSRU': {'count': 168,
                                                'description': u'Referred to House Rules.',
                                                'regression_beta': -1.7754356490673593,
                                                'success_rate': 79.76190476190476},
                            u'committee_HSSY': {'count': 15,
                                                'description': u'Referred to House Science, Space, and Technology.',
                                                'regression_beta': -35.085835377108381,
                                                'success_rate': 0.0},
                            u'committee_HSWM': {'count': 31,
                                                'description': u'Referred to House Ways and Means.',
                                                'regression_beta': -3.0517110290256957,
                                                'success_rate': 3.225806451612903},
                            u'committee_SSRA': {'count': 34,
                                                'description': u'Referred to Senate Rules and Administration.',
                                                'regression_beta': -2.850394719365156,
                                                'success_rate': 11.764705882352942},
                            u'companion__committee_HSIF': {'count': 20,
                                                           'description': u'On a companion bill: Referred to House Energy and Commerce.',
                                                           'regression_beta': -1.8706859996302267,
                                                           'success_rate': 15.0},
                            'cosponsor_chair': {'count': 48,
                                                'description': 'A cosponsor is a relevant committee chairman.',
                                                'regression_beta': 1.9127844476864237,
                                                'success_rate': 60.416666666666664},
                            'cosponsors_bipartisan': {'count': 111,
                                                      'description': 'Sponsor is in majority party and 1/3rd+ of cosponsors are in minority party.',
                                                      'regression_beta': 0.99879256817299289,
                                                      'success_rate': 63.96396396396396},
                            'reintroduced': {'count': 90,
                                             'description': 'Is a bill reintroduced from a previous Congress.',
                                             'regression_beta': -2.3344422957980995,
                                             'success_rate': 4.444444444444445},
                            'reintroduced_of_reported': {'count': 58,
                                                         'description': 'Got past committee in a previous Congress.',
                                                         'regression_beta': 1.9111402823807122,
                                                         'success_rate': 68.96551724137932},
                            'sponsor_committee_rankingmember': {'count': 18,
                                                                'description': 'Sponsor is a relevant committee ranking member.',
                                                                'regression_beta': -2.8729496209069949,
                                                                'success_rate': 16.666666666666668},
                            'sponsor_leader_minority': {'count': 36,
                                                        'description': 'Sponsor has a high leadership score (minority party).',
                                                        'regression_beta': -32.126481467147102,
                                                        'success_rate': 0.0},
                            'sponsor_minority': {'count': 600,
                                                 'description': 'Sponsor is a member of the minority party.',
                                                 'regression_beta': -0.3525991551118528,
                                                 'success_rate': 28.0},
                            u'startswith:A resolution expressing the sense of the Senate that': {'count': 31,
                                                                                                 'description': u'Title starts with "A resolution expressing the sense of the Senate that".',
                                                                                                 'regression_beta': -2.6398279481825164,
                                                                                                 'success_rate': 19.35483870967742},
                            u'startswith:Expressing support for designation of': {'count': 51,
                                                                                  'description': u'Title starts with "Expressing support for designation of".',
                                                                                  'regression_beta': -33.998175490086837,
                                                                                  'success_rate': 0.0},
                            u'startswith:Expressing support for the': {'count': 25,
                                                                       'description': u'Title starts with "Expressing support for the".',
                                                                       'regression_beta': -2.6582391619698149,
                                                                       'success_rate': 4.0},
                            u'startswith:Expressing the sense of the House of Representatives that': {'count': 84,
                                                                                                      'description': u'Title starts with "Expressing the sense of the House of Representatives that".',
                                                                                                      'regression_beta': -2.0246314274862196,
                                                                                                      'success_rate': 2.380952380952381},
                            'startswith:Providing for consideration of': {'count': 121,
                                                                          'description': 'Title starts with "Providing for consideration of".',
                                                                          'regression_beta': 5.2410572452229713,
                                                                          'success_rate': 99.17355371900827},
                            u'startswith:Supporting the goals and ideals of National': {'count': 25,
                                                                                        'description': u'Title starts with "Supporting the goals and ideals of National".',
                                                                                        'regression_beta': -34.28278712726437,
                                                                                        'success_rate': 0.0}},
                'is_introduced_model': True,
                'regression_beta': [1.3253459660271523,
                                    -5.2987355142051573,
                                    -33.998175490086837,
                                    -4.5141591370342153,
                                    -2.3344422957980995,
                                    1.9127844476864237,
                                    -2.6582391619698149,
                                    1.9111402823807122,
                                    -2.5336271947873863,
                                    5.2410572452229713,
                                    -2.0246314274862196,
                                    -3.2527923664967262,
                                    0.99879256817299289,
                                    -3.0517110290256957,
                                    -3.0625429331386882,
                                    -2.6398279481825164,
                                    -32.126481467147102,
                                    -0.3525991551118528,
                                    -2.850394719365156,
                                    -1.8706859996302267,
                                    -35.781879261016797,
                                    -2.8729496209069949,
                                    -2.7658089458979433,
                                    -1.9308921095069571,
                                    -4.4497367597532245,
                                    -1.7754356490673593,
                                    -35.085835377108381,
                                    -34.28278712726437],
                'regression_predictors_map': {u'committee_HSAS': 21,
                                              u'committee_HSED': 0,
                                              u'committee_HSFA': 10,
                                              u'committee_HSGO': 2,
                                              u'committee_HSHA': 7,
                                              u'committee_HSIF': 23,
                                              u'committee_HSII': 19,
                                              u'committee_HSJU': 13,
                                              u'committee_HSPW': 22,
                                              u'committee_HSRU': 24,
                                              u'committee_HSSY': 25,
                                              u'committee_HSWM': 12,
                                              u'committee_SSRA': 17,
                                              u'companion__committee_HSIF': 18,
                                              'cosponsor_chair': 4,
                                              'cosponsors_bipartisan': 11,
                                              'reintroduced': 3,
                                              'reintroduced_of_reported': 6,
                                              'sponsor_committee_rankingmember': 20,
                                              'sponsor_leader_minority': 15,
                                              'sponsor_minority': 16,
                                              u'startswith:A resolution expressing the sense of the Senate that': 14,
                                              u'startswith:Expressing support for designation of': 1,
                                              u'startswith:Expressing support for the': 5,
                                              u'startswith:Expressing the sense of the House of Representatives that': 9,
                                              'startswith:Providing for consideration of': 8,
                                              u'startswith:Supporting the goals and ideals of National': 26},
                'success_name': 'sent out of committee to the floor',
                'success_rate': 46.779661016949156}}

########NEW FILE########
__FILENAME__ = prognosis_model_test
# this file was automatically generated by prognosis.py
train_congress = 111
test_congress = 112
model_test_results = {('bill', 0): {'bill_type': 'bill',
               'bill_type_descr': 'bills',
               'bins': [(4.4395655872421424e-14, 557, 0.014362657091561939),
                        (0.1803703014179332, 1415, 0.0035335689045936395),
                        (1.3403427348303163, 1132, 0.0053003533568904597),
                        (2.7223284235190914, 1047, 0.0076408787010506206),
                        (3.8386129647158409, 1015, 0.043349753694581279),
                        (6.2350353263860745, 998, 0.041082164328657314),
                        (8.3630900690291607, 1140, 0.085964912280701758),
                        (14.162050423497694, 1118, 0.15563506261180679),
                        (23.416886349718478, 973, 0.22507708119218911)],
               'count': 10439,
               'is_introduced_model': True,
               'overall': 13.077429673534668,
               'precision_recall': [{'fscore': 0.21510679464319588,
                                     'fscore_beta': 0.5,
                                     'precision': 0.17999999999999999,
                                     'recall': 0.97842968075927528,
                                     'threshold': 2.7323722447292558},
                                    {'fscore': 0.22293371279497212,
                                     'fscore_beta': 0.5,
                                     'precision': 0.18690969345484673,
                                     'recall': 0.97325280414150128,
                                     'threshold': 3.337326996032608},
                                    {'fscore': 0.23557793161317389,
                                     'fscore_beta': 0.5,
                                     'precision': 0.19809490209913566,
                                     'recall': 0.96893874029335636,
                                     'threshold': 4.076220397836621},
                                    {'fscore': 0.24922977882006714,
                                     'fscore_beta': 0.5,
                                     'precision': 0.21060812123567127,
                                     'recall': 0.93528904227782572,
                                     'threshold': 4.978706836786395},
                                    {'fscore': 0.26354498651630304,
                                     'fscore_beta': 0.5,
                                     'precision': 0.22353919733832397,
                                     'recall': 0.92752372735116484,
                                     'threshold': 6.0810062625217975},
                                    {'fscore': 0.27406173546405704,
                                     'fscore_beta': 0.5,
                                     'precision': 0.23332594726346112,
                                     'recall': 0.908541846419327,
                                     'threshold': 7.427357821433388},
                                    {'fscore': 0.32571428571428568,
                                     'fscore_beta': 0.5,
                                     'precision': 0.28258967629046366,
                                     'recall': 0.83606557377049184,
                                     'threshold': 9.071795328941251},
                                    {'fscore': 0.35169459682873672,
                                     'fscore_beta': 0.5,
                                     'precision': 0.30819888047415211,
                                     'recall': 0.80759275237273509,
                                     'threshold': 11.080315836233387},
                                    {'fscore': 0.36307470111530132,
                                     'fscore_beta': 0.5,
                                     'precision': 0.32024062278839349,
                                     'recall': 0.78084555651423637,
                                     'threshold': 13.53352832366127},
                                    {'fscore': 0.42686365174241564,
                                     'fscore_beta': 0.5,
                                     'precision': 0.39283860923715619,
                                     'recall': 0.65314926660914585,
                                     'threshold': 16.529888822158654},
                                    {'fscore': 0.44907236761272878,
                                     'fscore_beta': 0.5,
                                     'precision': 0.41891117478510026,
                                     'recall': 0.63071613459879206,
                                     'threshold': 20.189651799465537},
                                    {'fscore': 0.47588378417060251,
                                     'fscore_beta': 0.5,
                                     'precision': 0.45641729581331503,
                                     'recall': 0.57377049180327866,
                                     'threshold': 24.659696394160648},
                                    {'fscore': 0.51939694796837654,
                                     'fscore_beta': 0.5,
                                     'precision': 0.5280373831775701,
                                     'recall': 0.48748921484037966,
                                     'threshold': 30.119421191220212},
                                    {'fscore': 0.54345505018150753,
                                     'fscore_beta': 0.5,
                                     'precision': 0.57775255391600455,
                                     'recall': 0.43917169974115616,
                                     'threshold': 36.787944117144235},
                                    {'fscore': 0.54316452374704804,
                                     'fscore_beta': 0.5,
                                     'precision': 0.6244343891402715,
                                     'recall': 0.35720448662640208,
                                     'threshold': 44.932896411722155},
                                    {'fscore': 0.51922444955635882,
                                     'fscore_beta': 0.5,
                                     'precision': 0.6709129511677282,
                                     'recall': 0.27264883520276101,
                                     'threshold': 54.88116360940264},
                                    {'fscore': 0.45881348698250102,
                                     'fscore_beta': 0.5,
                                     'precision': 0.72635135135135132,
                                     'recall': 0.18550474547023296,
                                     'threshold': 67.03200460356393},
                                    {'fscore': 0.22442244224422442,
                                     'fscore_beta': 0.5,
                                     'precision': 0.7640449438202247,
                                     'recall': 0.058671268334771355,
                                     'threshold': 81.87307530779819}],
               'success_name': 'sent out of committee to the floor'},
 ('bill', 1): {'bill_type': 'bill',
               'bill_type_descr': 'bills',
               'bins': [(5.1563689820945235, 95, 0.20549959020378694),
                        (13.493574494084726, 137, 0.21781940588935786),
                        (25.581418740229342, 99, 0.22161969722438166),
                        (26.39976234900276, 468, 0.22286340764036755),
                        (34.678625492745091, 112, 0.37744425578789503),
                        (47.563404160885256, 103, 0.42809900741898727)],
               'count': 1159,
               'is_introduced_model': False,
               'overall': 26.33093525179856,
               'precision_recall': [{'fscore': 0.34385486949685418,
                                     'fscore_beta': 0.5,
                                     'precision': 0.29539875571678931,
                                     'recall': 1.0,
                                     'threshold': 2.7323722447292558},
                                    {'fscore': 0.34385486949685418,
                                     'fscore_beta': 0.5,
                                     'precision': 0.29539875571678931,
                                     'recall': 1.0,
                                     'threshold': 3.337326996032608},
                                    {'fscore': 0.34385486949685418,
                                     'fscore_beta': 0.5,
                                     'precision': 0.29539875571678931,
                                     'recall': 1.0,
                                     'threshold': 4.076220397836621},
                                    {'fscore': 0.34491056075800725,
                                     'fscore_beta': 0.5,
                                     'precision': 0.29637624919654487,
                                     'recall': 0.99984639281969745,
                                     'threshold': 4.978706836786395},
                                    {'fscore': 0.34640302782702259,
                                     'fscore_beta': 0.5,
                                     'precision': 0.29866593181960083,
                                     'recall': 0.9604635940364048,
                                     'threshold': 6.0810062625217975},
                                    {'fscore': 0.34640302782702259,
                                     'fscore_beta': 0.5,
                                     'precision': 0.29866593181960083,
                                     'recall': 0.9604635940364048,
                                     'threshold': 7.427357821433388},
                                    {'fscore': 0.3467065682441185,
                                     'fscore_beta': 0.5,
                                     'precision': 0.29906560969339291,
                                     'recall': 0.9556342349966318,
                                     'threshold': 9.071795328941251},
                                    {'fscore': 0.34903641128155277,
                                     'fscore_beta': 0.5,
                                     'precision': 0.30139955650680428,
                                     'recall': 0.94900668606841276,
                                     'threshold': 11.080315836233387},
                                    {'fscore': 0.36608544376167801,
                                     'fscore_beta': 0.5,
                                     'precision': 0.319535510949847,
                                     'recall': 0.87731364817957991,
                                     'threshold': 13.53352832366127},
                                    {'fscore': 0.3650595939584641,
                                     'fscore_beta': 0.5,
                                     'precision': 0.31889717369283743,
                                     'recall': 0.8671780043101297,
                                     'threshold': 16.529888822158654},
                                    {'fscore': 0.36231655680227542,
                                     'fscore_beta': 0.5,
                                     'precision': 0.31667384864262593,
                                     'recall': 0.8555823864996055,
                                     'threshold': 20.189651799465537},
                                    {'fscore': 0.3596108367307228,
                                     'fscore_beta': 0.5,
                                     'precision': 0.31468843695317938,
                                     'recall': 0.838269232019758,
                                     'threshold': 24.659696394160648},
                                    {'fscore': 0.46724977373584303,
                                     'fscore_beta': 0.5,
                                     'precision': 0.46242639907290262,
                                     'recall': 0.4875932934136662,
                                     'threshold': 30.119421191220212},
                                    {'fscore': 0.47031733240793505,
                                     'fscore_beta': 0.5,
                                     'precision': 0.50059456739060537,
                                     'recall': 0.37869868640033738,
                                     'threshold': 36.787944117144235},
                                    {'fscore': 0.47160607096242602,
                                     'fscore_beta': 0.5,
                                     'precision': 0.53253719345490169,
                                     'recall': 0.32353493520197957,
                                     'threshold': 44.932896411722155},
                                    {'fscore': 0.43703084530077335,
                                     'fscore_beta': 0.5,
                                     'precision': 0.54649968730596898,
                                     'recall': 0.24262827365191289,
                                     'threshold': 54.88116360940264},
                                    {'fscore': 0.4455245238889145,
                                     'fscore_beta': 0.5,
                                     'precision': 0.63629661912544044,
                                     'recall': 0.20257881017267909,
                                     'threshold': 67.03200460356393},
                                    {'fscore': 0.16274307360747825,
                                     'fscore_beta': 0.5,
                                     'precision': 0.57593752748564464,
                                     'recall': 0.042055547256568765,
                                     'threshold': 81.87307530779819}],
               'success_name': 'enacted'},
 ('cr', 0): {'bill_type': 'cr',
             'bill_type_descr': 'concurrent resolutions',
             'bins': [(2.3829339508501996e-14, 22, 0.0),
                      (6.1905085961115667, 20, 0.0),
                      (15.97161092784938, 3, 0.66666666666666663),
                      (22.585006936529432, 30, 0.46666666666666667),
                      (32.642942044639625, 15, 0.26666666666666666),
                      (42.301167143229776, 79, 0.60759493670886078)],
             'count': 212,
             'is_introduced_model': True,
             'overall': 38.16425120772947,
             'precision_recall': [{'fscore': 0.51266586248492152,
                                   'fscore_beta': 0.5,
                                   'precision': 0.45698924731182794,
                                   'recall': 1.0,
                                   'threshold': 2.7323722447292558},
                                  {'fscore': 0.51515151515151514,
                                   'fscore_beta': 0.5,
                                   'precision': 0.45945945945945948,
                                   'recall': 1.0,
                                   'threshold': 3.337326996032608},
                                  {'fscore': 0.52019583843329253,
                                   'fscore_beta': 0.5,
                                   'precision': 0.46448087431693991,
                                   'recall': 1.0,
                                   'threshold': 4.076220397836621},
                                  {'fscore': 0.52533992583436351,
                                   'fscore_beta': 0.5,
                                   'precision': 0.46961325966850831,
                                   'recall': 1.0,
                                   'threshold': 4.978706836786395},
                                  {'fscore': 0.52533992583436351,
                                   'fscore_beta': 0.5,
                                   'precision': 0.46961325966850831,
                                   'recall': 1.0,
                                   'threshold': 6.0810062625217975},
                                  {'fscore': 0.53865652724968316,
                                   'fscore_beta': 0.5,
                                   'precision': 0.48295454545454547,
                                   'recall': 1.0,
                                   'threshold': 7.427357821433388},
                                  {'fscore': 0.53865652724968316,
                                   'fscore_beta': 0.5,
                                   'precision': 0.48295454545454547,
                                   'recall': 1.0,
                                   'threshold': 9.071795328941251},
                                  {'fscore': 0.54980595084087969,
                                   'fscore_beta': 0.5,
                                   'precision': 0.4941860465116279,
                                   'recall': 1.0,
                                   'threshold': 11.080315836233387},
                                  {'fscore': 0.54980595084087969,
                                   'fscore_beta': 0.5,
                                   'precision': 0.4941860465116279,
                                   'recall': 1.0,
                                   'threshold': 13.53352832366127},
                                  {'fscore': 0.55112881806108893,
                                   'fscore_beta': 0.5,
                                   'precision': 0.49700598802395207,
                                   'recall': 0.97647058823529409,
                                   'threshold': 16.529888822158654},
                                  {'fscore': 0.55112881806108893,
                                   'fscore_beta': 0.5,
                                   'precision': 0.49700598802395207,
                                   'recall': 0.97647058823529409,
                                   'threshold': 20.189651799465537},
                                  {'fscore': 0.54160125588697017,
                                   'fscore_beta': 0.5,
                                   'precision': 0.5,
                                   'recall': 0.81176470588235294,
                                   'threshold': 24.659696394160648},
                                  {'fscore': 0.54502369668246453,
                                   'fscore_beta': 0.5,
                                   'precision': 0.5036496350364964,
                                   'recall': 0.81176470588235294,
                                   'threshold': 30.119421191220212},
                                  {'fscore': 0.56719022687609089,
                                   'fscore_beta': 0.5,
                                   'precision': 0.53278688524590168,
                                   'recall': 0.76470588235294112,
                                   'threshold': 36.787944117144235},
                                  {'fscore': 0.34798534798534797,
                                   'fscore_beta': 0.5,
                                   'precision': 0.40425531914893614,
                                   'recall': 0.22352941176470589,
                                   'threshold': 44.932896411722155},
                                  {'fscore': 0.33073929961089488,
                                   'fscore_beta': 0.5,
                                   'precision': 0.39534883720930231,
                                   'recall': 0.20000000000000001,
                                   'threshold': 54.88116360940264},
                                  {'fscore': 0.12396694214876033,
                                   'fscore_beta': 0.5,
                                   'precision': 0.33333333333333331,
                                   'recall': 0.035294117647058823,
                                   'threshold': 67.03200460356393}],
             'success_name': 'sent out of committee to the floor'},
 ('cr', 1): {'bill_type': 'cr',
             'bill_type_descr': 'concurrent resolutions',
             'bins': [(26.713909179481725, 9, 0.2271458628985511)],
             'count': 85,
             'is_introduced_model': False,
             'overall': 51.89873417721519,
             'precision_recall': [{'fscore': 0.68843801505406865,
                                   'fscore_beta': 0.5,
                                   'precision': 0.63869012432876049,
                                   'recall': 1.0,
                                   'threshold': 2.7323722447292558},
                                  {'fscore': 0.68843801505406865,
                                   'fscore_beta': 0.5,
                                   'precision': 0.63869012432876049,
                                   'recall': 1.0,
                                   'threshold': 3.337326996032608},
                                  {'fscore': 0.68843801505406865,
                                   'fscore_beta': 0.5,
                                   'precision': 0.63869012432876049,
                                   'recall': 1.0,
                                   'threshold': 4.076220397836621},
                                  {'fscore': 0.68843801505406865,
                                   'fscore_beta': 0.5,
                                   'precision': 0.63869012432876049,
                                   'recall': 1.0,
                                   'threshold': 4.978706836786395},
                                  {'fscore': 0.68843801505406865,
                                   'fscore_beta': 0.5,
                                   'precision': 0.63869012432876049,
                                   'recall': 1.0,
                                   'threshold': 6.0810062625217975},
                                  {'fscore': 0.68843801505406865,
                                   'fscore_beta': 0.5,
                                   'precision': 0.63869012432876049,
                                   'recall': 1.0,
                                   'threshold': 7.427357821433388},
                                  {'fscore': 0.68843801505406865,
                                   'fscore_beta': 0.5,
                                   'precision': 0.63869012432876049,
                                   'recall': 1.0,
                                   'threshold': 9.071795328941251},
                                  {'fscore': 0.69303003572940614,
                                   'fscore_beta': 0.5,
                                   'precision': 0.64400420090043986,
                                   'recall': 0.99645768213295649,
                                   'threshold': 11.080315836233387},
                                  {'fscore': 0.69303003572940614,
                                   'fscore_beta': 0.5,
                                   'precision': 0.64400420090043986,
                                   'recall': 0.99645768213295649,
                                   'threshold': 13.53352832366127},
                                  {'fscore': 0.69303003572940614,
                                   'fscore_beta': 0.5,
                                   'precision': 0.64400420090043986,
                                   'recall': 0.99645768213295649,
                                   'threshold': 16.529888822158654},
                                  {'fscore': 0.69303003572940614,
                                   'fscore_beta': 0.5,
                                   'precision': 0.64400420090043986,
                                   'recall': 0.99645768213295649,
                                   'threshold': 20.189651799465537},
                                  {'fscore': 0.70224830095442692,
                                   'fscore_beta': 0.5,
                                   'precision': 0.65478429843410424,
                                   'recall': 0.98901523651330947,
                                   'threshold': 24.659696394160648},
                                  {'fscore': 0.72908179286280039,
                                   'fscore_beta': 0.5,
                                   'precision': 0.68742562897181159,
                                   'recall': 0.96234365068689776,
                                   'threshold': 30.119421191220212},
                                  {'fscore': 0.72908179286280039,
                                   'fscore_beta': 0.5,
                                   'precision': 0.68742562897181159,
                                   'recall': 0.96234365068689776,
                                   'threshold': 36.787944117144235},
                                  {'fscore': 0.72908179286280039,
                                   'fscore_beta': 0.5,
                                   'precision': 0.68742562897181159,
                                   'recall': 0.96234365068689776,
                                   'threshold': 44.932896411722155},
                                  {'fscore': 0.69466419937222779,
                                   'fscore_beta': 0.5,
                                   'precision': 0.67545322911181993,
                                   'recall': 0.78383870570516323,
                                   'threshold': 54.88116360940264},
                                  {'fscore': 0.69466419937222779,
                                   'fscore_beta': 0.5,
                                   'precision': 0.67545322911181993,
                                   'recall': 0.78383870570516323,
                                   'threshold': 67.03200460356393}],
             'success_name': 'agreed to'},
 ('jr', 0): {'bill_type': 'jr',
             'bill_type_descr': 'joint resolutions',
             'bins': [],
             'count': 173,
             'is_introduced_model': True,
             'overall': 25.503355704697988,
             'precision_recall': [{'fscore': 0.375,
                                   'fscore_beta': 0.5,
                                   'precision': 0.32432432432432434,
                                   'recall': 1.0,
                                   'threshold': 2.7323722447292558},
                                  {'fscore': 0.375,
                                   'fscore_beta': 0.5,
                                   'precision': 0.32432432432432434,
                                   'recall': 1.0,
                                   'threshold': 3.337326996032608},
                                  {'fscore': 0.375,
                                   'fscore_beta': 0.5,
                                   'precision': 0.32432432432432434,
                                   'recall': 1.0,
                                   'threshold': 4.076220397836621},
                                  {'fscore': 0.375,
                                   'fscore_beta': 0.5,
                                   'precision': 0.32432432432432434,
                                   'recall': 1.0,
                                   'threshold': 4.978706836786395},
                                  {'fscore': 0.375,
                                   'fscore_beta': 0.5,
                                   'precision': 0.32432432432432434,
                                   'recall': 1.0,
                                   'threshold': 6.0810062625217975},
                                  {'fscore': 0.375,
                                   'fscore_beta': 0.5,
                                   'precision': 0.32432432432432434,
                                   'recall': 1.0,
                                   'threshold': 7.427357821433388},
                                  {'fscore': 0.375,
                                   'fscore_beta': 0.5,
                                   'precision': 0.32432432432432434,
                                   'recall': 1.0,
                                   'threshold': 9.071795328941251},
                                  {'fscore': 0.375,
                                   'fscore_beta': 0.5,
                                   'precision': 0.32432432432432434,
                                   'recall': 1.0,
                                   'threshold': 11.080315836233387},
                                  {'fscore': 0.375,
                                   'fscore_beta': 0.5,
                                   'precision': 0.32432432432432434,
                                   'recall': 1.0,
                                   'threshold': 13.53352832366127},
                                  {'fscore': 0.375,
                                   'fscore_beta': 0.5,
                                   'precision': 0.32432432432432434,
                                   'recall': 1.0,
                                   'threshold': 16.529888822158654},
                                  {'fscore': 0.375,
                                   'fscore_beta': 0.5,
                                   'precision': 0.32432432432432434,
                                   'recall': 1.0,
                                   'threshold': 20.189651799465537},
                                  {'fscore': 0.375,
                                   'fscore_beta': 0.5,
                                   'precision': 0.32432432432432434,
                                   'recall': 1.0,
                                   'threshold': 24.659696394160648},
                                  {'fscore': 0.375,
                                   'fscore_beta': 0.5,
                                   'precision': 0.32432432432432434,
                                   'recall': 1.0,
                                   'threshold': 30.119421191220212},
                                  {'fscore': 0.375,
                                   'fscore_beta': 0.5,
                                   'precision': 0.32432432432432434,
                                   'recall': 1.0,
                                   'threshold': 36.787944117144235}],
             'success_name': 'sent out of committee to the floor'},
 ('jr', 1): {'bill_type': 'jr',
             'bill_type_descr': 'joint resolutions',
             'bins': [],
             'count': 36,
             'is_introduced_model': False,
             'overall': 50.0,
             'precision_recall': [{'fscore': 0.39053768781820442,
                                   'fscore_beta': 0.5,
                                   'precision': 0.33890086206896552,
                                   'recall': 1.0,
                                   'threshold': 2.7323722447292558},
                                  {'fscore': 0.39053768781820442,
                                   'fscore_beta': 0.5,
                                   'precision': 0.33890086206896552,
                                   'recall': 1.0,
                                   'threshold': 3.337326996032608},
                                  {'fscore': 0.39053768781820442,
                                   'fscore_beta': 0.5,
                                   'precision': 0.33890086206896552,
                                   'recall': 1.0,
                                   'threshold': 4.076220397836621},
                                  {'fscore': 0.39053768781820442,
                                   'fscore_beta': 0.5,
                                   'precision': 0.33890086206896552,
                                   'recall': 1.0,
                                   'threshold': 4.978706836786395},
                                  {'fscore': 0.39053768781820442,
                                   'fscore_beta': 0.5,
                                   'precision': 0.33890086206896552,
                                   'recall': 1.0,
                                   'threshold': 6.0810062625217975},
                                  {'fscore': 0.39053768781820442,
                                   'fscore_beta': 0.5,
                                   'precision': 0.33890086206896552,
                                   'recall': 1.0,
                                   'threshold': 7.427357821433388},
                                  {'fscore': 0.39053768781820442,
                                   'fscore_beta': 0.5,
                                   'precision': 0.33890086206896552,
                                   'recall': 1.0,
                                   'threshold': 9.071795328941251},
                                  {'fscore': 0.39053768781820442,
                                   'fscore_beta': 0.5,
                                   'precision': 0.33890086206896552,
                                   'recall': 1.0,
                                   'threshold': 11.080315836233387},
                                  {'fscore': 0.39053768781820442,
                                   'fscore_beta': 0.5,
                                   'precision': 0.33890086206896552,
                                   'recall': 1.0,
                                   'threshold': 13.53352832366127},
                                  {'fscore': 0.39053768781820442,
                                   'fscore_beta': 0.5,
                                   'precision': 0.33890086206896552,
                                   'recall': 1.0,
                                   'threshold': 16.529888822158654},
                                  {'fscore': 0.39053768781820442,
                                   'fscore_beta': 0.5,
                                   'precision': 0.33890086206896552,
                                   'recall': 1.0,
                                   'threshold': 20.189651799465537},
                                  {'fscore': 0.39053768781820442,
                                   'fscore_beta': 0.5,
                                   'precision': 0.33890086206896552,
                                   'recall': 1.0,
                                   'threshold': 24.659696394160648},
                                  {'fscore': 0.39053768781820442,
                                   'fscore_beta': 0.5,
                                   'precision': 0.33890086206896552,
                                   'recall': 1.0,
                                   'threshold': 30.119421191220212},
                                  {'fscore': 0.59652649540683955,
                                   'fscore_beta': 0.5,
                                   'precision': 0.55000000000000004,
                                   'recall': 0.90160748984278405,
                                   'threshold': 36.787944117144235},
                                  {'fscore': 0.59652649540683955,
                                   'fscore_beta': 0.5,
                                   'precision': 0.55000000000000004,
                                   'recall': 0.90160748984278405,
                                   'threshold': 44.932896411722155},
                                  {'fscore': 0.59652649540683955,
                                   'fscore_beta': 0.5,
                                   'precision': 0.55000000000000004,
                                   'recall': 0.90160748984278405,
                                   'threshold': 54.88116360940264},
                                  {'fscore': 0.59652649540683955,
                                   'fscore_beta': 0.5,
                                   'precision': 0.55000000000000004,
                                   'recall': 0.90160748984278405,
                                   'threshold': 67.03200460356393}],
             'success_name': 'enacted or passed'},
 ('sr', 0): {'bill_type': 'sr',
             'bill_type_descr': 'simple resolutions',
             'bins': [(1.9490745501913547, 148, 0.027027027027027029),
                      (10.717401905171609, 146, 0.054794520547945202),
                      (22.090536973181635, 125, 0.14399999999999999),
                      (38.126617402838797, 143, 0.1048951048951049),
                      (53.874404577859828, 93, 0.34408602150537637),
                      (62.861059282908975, 227, 0.65198237885462551),
                      (76.614561374063115, 100, 0.56999999999999995),
                      (85.030086091458173, 174, 0.74712643678160917),
                      (94.878348819469323, 171, 0.783625730994152)],
             'count': 1475,
             'is_introduced_model': True,
             'overall': 57.40666399036532,
             'precision_recall': [{'fscore': 0.5585365853658536,
                                   'fscore_beta': 0.5,
                                   'precision': 0.50329670329670328,
                                   'recall': 0.9956521739130435,
                                   'threshold': 2.7323722447292558},
                                  {'fscore': 0.5625614150016377,
                                   'fscore_beta': 0.5,
                                   'precision': 0.50738552437223039,
                                   'recall': 0.9956521739130435,
                                   'threshold': 3.337326996032608},
                                  {'fscore': 0.56441012159053572,
                                   'fscore_beta': 0.5,
                                   'precision': 0.50926612305411412,
                                   'recall': 0.9956521739130435,
                                   'threshold': 4.076220397836621},
                                  {'fscore': 0.56844547563805092,
                                   'fscore_beta': 0.5,
                                   'precision': 0.51347305389221554,
                                   'recall': 0.99420289855072463,
                                   'threshold': 4.978706836786395},
                                  {'fscore': 0.57071547420965074,
                                   'fscore_beta': 0.5,
                                   'precision': 0.51578947368421058,
                                   'recall': 0.99420289855072463,
                                   'threshold': 6.0810062625217975},
                                  {'fscore': 0.57223890557223889,
                                   'fscore_beta': 0.5,
                                   'precision': 0.51734539969834092,
                                   'recall': 0.99420289855072463,
                                   'threshold': 7.427357821433388},
                                  {'fscore': 0.58742700103057388,
                                   'fscore_beta': 0.5,
                                   'precision': 0.5331254871395168,
                                   'recall': 0.99130434782608701,
                                   'threshold': 9.071795328941251},
                                  {'fscore': 0.61392405063291144,
                                   'fscore_beta': 0.5,
                                   'precision': 0.56115702479338847,
                                   'recall': 0.98405797101449277,
                                   'threshold': 11.080315836233387},
                                  {'fscore': 0.62293274531422282,
                                   'fscore_beta': 0.5,
                                   'precision': 0.57070707070707072,
                                   'recall': 0.9826086956521739,
                                   'threshold': 13.53352832366127},
                                  {'fscore': 0.62754535357275087,
                                   'fscore_beta': 0.5,
                                   'precision': 0.57555178268251272,
                                   'recall': 0.9826086956521739,
                                   'threshold': 16.529888822158654},
                                  {'fscore': 0.65167243367935401,
                                   'fscore_beta': 0.5,
                                   'precision': 0.60106382978723405,
                                   'recall': 0.9826086956521739,
                                   'threshold': 20.189651799465537},
                                  {'fscore': 0.66509248327430148,
                                   'fscore_beta': 0.5,
                                   'precision': 0.61566484517304187,
                                   'recall': 0.97971014492753628,
                                   'threshold': 24.659696394160648},
                                  {'fscore': 0.68674447686536055,
                                   'fscore_beta': 0.5,
                                   'precision': 0.64167478091528729,
                                   'recall': 0.95507246376811594,
                                   'threshold': 30.119421191220212},
                                  {'fscore': 0.69652807543934836,
                                   'fscore_beta': 0.5,
                                   'precision': 0.65392354124748486,
                                   'recall': 0.94202898550724634,
                                   'threshold': 36.787944117144235},
                                  {'fscore': 0.73110004526935268,
                                   'fscore_beta': 0.5,
                                   'precision': 0.69313304721030045,
                                   'recall': 0.93623188405797098,
                                   'threshold': 44.932896411722155},
                                  {'fscore': 0.76055312954876275,
                                   'fscore_beta': 0.5,
                                   'precision': 0.73076923076923073,
                                   'recall': 0.90869565217391302,
                                   'threshold': 54.88116360940264},
                                  {'fscore': 0.75333757151938963,
                                   'fscore_beta': 0.5,
                                   'precision': 0.7719869706840391,
                                   'recall': 0.68695652173913047,
                                   'threshold': 67.03200460356393},
                                  {'fscore': 0.7666911225238443,
                                   'fscore_beta': 0.5,
                                   'precision': 0.82121807465618857,
                                   'recall': 0.60579710144927534,
                                   'threshold': 81.87307530779819}],
             'success_name': 'sent out of committee to the floor'},
 ('sr', 1): {'bill_type': 'sr',
             'bill_type_descr': 'simple resolutions',
             'bins': [(81.785101866977342, 37, 0.8965993465993467),
                      (91.55697457063097, 89, 0.95798433775961855),
                      (97.624982041606131, 282, 0.9850238935032426),
                      (99.221133714377999, 65, 0.97267399267399268),
                      (99.255272666495813, 15, 0.8705698005698006)],
             'count': 690,
             'is_introduced_model': False,
             'overall': 96.7132867132867,
             'precision_recall': [{'fscore': 0.97962295361979712,
                                   'fscore_beta': 0.5,
                                   'precision': 0.97465779186239565,
                                   'recall': 1.0,
                                   'threshold': 2.7323722447292558},
                                  {'fscore': 0.97962295361979712,
                                   'fscore_beta': 0.5,
                                   'precision': 0.97465779186239565,
                                   'recall': 1.0,
                                   'threshold': 3.337326996032608},
                                  {'fscore': 0.97962295361979712,
                                   'fscore_beta': 0.5,
                                   'precision': 0.97465779186239565,
                                   'recall': 1.0,
                                   'threshold': 4.076220397836621},
                                  {'fscore': 0.97962295361979712,
                                   'fscore_beta': 0.5,
                                   'precision': 0.97465779186239565,
                                   'recall': 1.0,
                                   'threshold': 4.978706836786395},
                                  {'fscore': 0.97962295361979712,
                                   'fscore_beta': 0.5,
                                   'precision': 0.97465779186239565,
                                   'recall': 1.0,
                                   'threshold': 6.0810062625217975},
                                  {'fscore': 0.97962295361979712,
                                   'fscore_beta': 0.5,
                                   'precision': 0.97465779186239565,
                                   'recall': 1.0,
                                   'threshold': 7.427357821433388},
                                  {'fscore': 0.97962295361979712,
                                   'fscore_beta': 0.5,
                                   'precision': 0.97465779186239565,
                                   'recall': 1.0,
                                   'threshold': 9.071795328941251},
                                  {'fscore': 0.97962295361979712,
                                   'fscore_beta': 0.5,
                                   'precision': 0.97465779186239565,
                                   'recall': 1.0,
                                   'threshold': 11.080315836233387},
                                  {'fscore': 0.97962295361979712,
                                   'fscore_beta': 0.5,
                                   'precision': 0.97465779186239565,
                                   'recall': 1.0,
                                   'threshold': 13.53352832366127},
                                  {'fscore': 0.97962295361979712,
                                   'fscore_beta': 0.5,
                                   'precision': 0.97465779186239565,
                                   'recall': 1.0,
                                   'threshold': 16.529888822158654},
                                  {'fscore': 0.97962295361979712,
                                   'fscore_beta': 0.5,
                                   'precision': 0.97465779186239565,
                                   'recall': 1.0,
                                   'threshold': 20.189651799465537},
                                  {'fscore': 0.97899132634389185,
                                   'fscore_beta': 0.5,
                                   'precision': 0.97458412265269334,
                                   'recall': 0.99702608366871093,
                                   'threshold': 24.659696394160648},
                                  {'fscore': 0.97899132634389185,
                                   'fscore_beta': 0.5,
                                   'precision': 0.97458412265269334,
                                   'recall': 0.99702608366871093,
                                   'threshold': 30.119421191220212},
                                  {'fscore': 0.97899132634389185,
                                   'fscore_beta': 0.5,
                                   'precision': 0.97458412265269334,
                                   'recall': 0.99702608366871093,
                                   'threshold': 36.787944117144235},
                                  {'fscore': 0.97899132634389185,
                                   'fscore_beta': 0.5,
                                   'precision': 0.97458412265269334,
                                   'recall': 0.99702608366871093,
                                   'threshold': 44.932896411722155},
                                  {'fscore': 0.97867440475438772,
                                   'fscore_beta': 0.5,
                                   'precision': 0.97454712719803926,
                                   'recall': 0.99553912550306645,
                                   'threshold': 54.88116360940264},
                                  {'fscore': 0.97835674107139081,
                                   'fscore_beta': 0.5,
                                   'precision': 0.97451002388491692,
                                   'recall': 0.99405216733742197,
                                   'threshold': 67.03200460356393},
                                  {'fscore': 0.97393621506163952,
                                   'fscore_beta': 0.5,
                                   'precision': 0.97914458100897261,
                                   'recall': 0.95364530470100384,
                                   'threshold': 81.87307530779819}],
             'success_name': 'agreed to'}}

########NEW FILE########
__FILENAME__ = search
from django import forms
from django.contrib.humanize.templatetags.humanize import ordinal

from smartsearch.manager import SearchManager

from bill.models import Bill, BillTerm, TermType, BillType, BillStatus, USCSection
from person.models import Person
from us import get_congress_dates
from settings import CURRENT_CONGRESS

import re

subject_choices_data = None
def subject_choices(include_legacy=True):
    global subject_choices_data
    if subject_choices_data == None:
        top_terms = { }
        for t in BillTerm.objects.exclude(parents__id__gt=0):
            x = []
            top_terms[ (-t.term_type, t.name, t.id) ] = x
            for tt in t.subterms.all():
                x.append((tt.id, "-- " + tt.name))
                
        ret0 = [] # all terms
        ret1 = [] # current terms only
        for t, subterms in sorted(top_terms.items(), key = lambda kv : kv[0]):
            for ret in ret0, ret1:
                if -t[0] == TermType.old and ret == ret1: continue
                ret.append((t[2], t[1] + ("" if -t[0] == TermType.new else " (Legacy Subject Code)")))
                for tt in sorted(subterms, key = lambda kv : kv[1]):
                    ret.append(tt)
        
        subject_choices_data = (ret0, ret1)
    
    return subject_choices_data[0 if include_legacy else 1]

def get_terms(terms):
    return sorted([(t.id, t.name + ("" if t.term_type==TermType.new else " (Legacy Subject)")) for t in terms], key = lambda x : ("Legacy Subject" in x[1], x[1]))

def sub_terms(requestargs):
    if "terms" in requestargs:
        return get_terms(BillTerm.objects.filter(parents__id=requestargs["terms"]))
    else:
        return []
def sub_term_filter(qs, form):
    if form.get("terms2", "") not in ("", "__ALL__"):
        # overwrite the terms filter set by the main form field
        return {"terms__in": [form["terms2"]]}
    return None

def format_congress_number(value):
    start, end = get_congress_dates(value)
    end_year = end.year if end.month > 1 else end.year-1 # count January finishes as the prev year
    return '%s Congress: %d-%d' % (ordinal(value), start.year, end.year)

# this regex must match slugs in BillType enum!
bill_number_re = re.compile(r"(hr|s|hconres|sconres|hjres|sjres|hres|sres)(\d+)(/(\d+))?$", re.I)
slip_law_number_re = re.compile(r"(P(?:ub[a-z]*)?|P[rv][a-z]*)L(?:aw)?(\d+)-(\d+)$", re.I)

def parse_bill_citation(q, congress=None):
    b = parse_bill_number(q, congress=congress)
    if not b: b = parse_slip_law_number(q)
    return b
    
def parse_bill_number(q, congress=None):
    m = bill_number_re.match(q.replace(" ", "").replace(".", "").replace("-", ""))
    if m == None: return None
    if m.group(3) != None:
        cn = int(m.group(4))
    elif congress != None:
        try:
            cn = int(congress)
        except:
            cn = CURRENT_CONGRESS
    else:
        cn = CURRENT_CONGRESS
    try:
        return Bill.objects.get(congress=cn, bill_type=BillType.by_slug(m.group(1).lower()), number=int(m.group(2)))
    except Bill.DoesNotExist:
        return None

def parse_slip_law_number(q):
    m = slip_law_number_re.match(q.replace(" ", "").replace(".", "").replace(u"\u2013", "-"))
    if m == None: return None
    pub_priv, cn, ln = m.groups()
    try:
        return Bill.objects.get(
            congress = int(cn),
            sliplawpubpriv = "PUB" if (pub_priv.upper() == "P" or pub_priv.upper().startswith("PUB")) else "PRI",
            sliplawnum = int(ln)
            )
    except Bill.DoesNotExist:
        return None

def similar_to(qs, form):
	if form.get("similar_to", "").strip() != "":
		b = parse_bill_number(form["similar_to"])
		if b:
			return qs.more_like_this(b)
	return None

def usc_cite(qs, form):
	# If the value isn't an integer, map the citation string to an ID.
	v = form.get("usc_cite", "").strip()
	if v != "":
		if not re.match("^\d+$", v):
			v = USCSection.objects.get(citation=v).id
		return qs.filter(usc_citations_uptree=v)
	return None

def bill_search_manager():
    sm = SearchManager(Bill, connection="bill")
    
    sm.add_option('similar_to', type="text", label="similar to (enter bill number)", visible_if=lambda form : False, filter=similar_to)
    sm.add_option('usc_cite', type="text", label="cites", visible_if=lambda form : False, orm_field_name='usc_citations_uptree', filter=usc_cite)
    
    sm.add_option('text', label='search title & full text', type="text", choices="NONE")
    sm.add_option('congress', type="select", formatter=format_congress_number, sort="KEY-REVERSE")
    sm.add_option('sponsor', type="select", sort="LABEL", formatter=lambda p : p.sortname)
    sm.add_option('current_status', label="current status", sort=lambda s : BillStatus.by_value(s).sort_order)
    sm.add_option('cosponsors', label="cosponsor", type="select", sort="LABEL", formatter=lambda p : p.sortname)
    sm.add_option('committees', label="committee", type="select", sort="LABEL", formatter=lambda c : c.shortname)
    sm.add_option('terms', type="select", label="subject", choices=get_terms(BillTerm.objects.exclude(parents__id__gt=0)))
    sm.add_option('terms2', type="select", label="subject 2", choices=sub_terms, visible_if=lambda post:"terms" in post, filter=sub_term_filter)
    sm.add_option('sponsor_party', label="party of sponsor", type="select")
    sm.add_option('bill_type', label="bill or resolution type")
    
    #sm.add_sort("Popularity", "-total_bets", default=True)
    sm.add_sort("Secret Sauce", "-proscore", default=True)
    sm.add_sort("Introduced Date (Newest First)", "-introduced_date")
    sm.add_sort("Introduced Date (Oldest First)", "introduced_date")
    sm.add_sort("Last Major Action (Recent First)", "-current_status_date")

    #def safe_strftime(date, format):
    #    return date.replace(year=3456).strftime(format).replace("3456", str(date.year)).replace(" 12:00AM", "")
    
    sm.set_template("""
    	<a href="{{object.get_absolute_url}}" style="font-size: 15px">{{object|truncatewords_html:50}}</a>
    	{% if object.sponsor %}<div>Sponsor: {{object.sponsor}}</div>{% endif %}
    	{% if object.source != "statutesatlarge" %}<div>Introduced: {{object.introduced_date}}</div>{% endif %}
    	{% if object.source != "americanmemory" %}<div>{% if object.source != "statutesatlarge" %}{{object.get_current_status_display}}{% else %}Enacted/Agreed to{% endif %}: {{object.current_status_date}}</div>{% endif %}
	""")
    
    return sm

########NEW FILE########
__FILENAME__ = search_indexes
from models import Bill
from smartsearch import build_haystack_index

BillIndex = build_haystack_index(Bill)


########NEW FILE########
__FILENAME__ = status
"""
``BillStatus`` - list of possible Bill statuses.

Details: http://www.govtrack.us/developers/datadoc.xpd
"""
from common import enum

class BillStatus(enum.Enum):
    """
    List of bill statuses.
    """

    introduced = enum.Item(1,
        'Introduced',
        xml_code='INTRODUCED',
        search_help_text="Introduced but not yet referred to a committee.",
        explanation="This is the first step in the legislative process.",
        sort_order=(0,0))
    referred = enum.Item(2,
        'Referred to Committee',
        xml_code='REFERRED',
        search_help_text="Referred to a committee in the originating chamber.",
        explanation="Bills and resolutions are referred to committees which debate the bill before possibly sending it on to the whole chamber.",
        sort_order=(0,1))
    reported = enum.Item(3,
        'Reported by Committee',
        xml_code='REPORTED',
        search_help_text="Reported by a committee in the originating chamber.",
        explanation="A committee has issued a report to the full chamber recommending that the bill be considered further. Only about 1 in 4 bills are reported out of committee.",
        sort_order=(0,2))
    pass_over_house = enum.Item(4,
        'Passed House',
        xml_code='PASS_OVER:HOUSE',
        search_help_text="Passed the House, waiting for a Senate vote next.",
        explanation=lambda b : "The %s was passed in a vote in the House. It goes to the Senate next." % b.noun,
        sort_order=(1,0))
    pass_over_senate = enum.Item(5,
        'Passed Senate',
        xml_code='PASS_OVER:SENATE',
        search_help_text="Passed the Senate, waiting for a House vote next.",
        explanation=lambda b : "The %s was passed in a vote in the Senate. It goes to the House next." % b.noun,
        sort_order=(1,1))
    passed_simpleres = enum.Item(6,
        'Agreed To (Simple Resolution)',
        xml_code='PASSED:SIMPLERES',
        search_help_text="The simple resolution was agreed to in the chamber in which it was introduced. This is a simple resolution's final status.",
        simple_label="Agreed To",
        explanation=lambda b : "The resolution was passed in a vote in the %s. A simple resolution is not voted on in the other chamber and does not have the force of law." % b.originating_chamber,
        sort_order=(1,2))
    passed_constamend = enum.Item(7,
        'Agreed To (Constitutional Amendment Proposal)',
        xml_code='PASSED:CONSTAMEND',
        search_help_text="The resolution proposing a constitutional amendment was agreed to by both chambers of Congress and goes on to the states.",
        simple_label="Agreed To",
        explanation="The joint resolution was passed by both chambers in identical form. Since it proposes a constitutional amendment, it goes to the States next.",
        sort_order=(3,0))
    passed_concurrentres = enum.Item(8,
        'Agreed To (Concurrent Resolution)',
        xml_code='PASSED:CONCURRENTRES',
        search_help_text="The concurrent resolution was agreed to by both chambers of Congress. This is the final status for concurrent resolutions.",
        simple_label="Agreed To",
        explanation="The concurrent resolution was passed by both chambers in identical form. A concurrent resolution is not signed by the president and does not carry the force of law.",
        sort_order=(3,1))
    passed_bill = enum.Item(9,
        'Enrolled Bill',
        xml_code='PASSED:BILL',
        search_help_text="The bill passed both chambers of Congress in identical form and goes on to the President for signing next.",
        explanation="The bill was passed by both chambers in identical form. It goes to the President next who may sign or veto the bill.",
        sort_order=(3,2))
    pass_back_house = enum.Item(10,
        'Passed House with Changes',
        xml_code='PASS_BACK:HOUSE',
        search_help_text="The House passed the bill with changes and sent it back to the Senate.",
        explanation="The House passed the bill with changes not in the Senate version and sent it back to the Senate to approve the changes.",
        sort_order=(2,0))
    pass_back_senate = enum.Item(11,
        'Passed Senate with Changes',
        xml_code='PASS_BACK:SENATE',
        search_help_text="The Senate passed the bill with changes and sent it back to the House.",
        explanation="The Senate passed the bill with changes not in the House version and sent it back to the House to approve the changes.",
        sort_order=(2,1))
    conference_passed_house = enum.Item(30,
        'Conference Report Agreed to by House',
        xml_code='CONFERENCE:PASSED:HOUSE',
        search_help_text="The House approved a conference committee report to resolve differences. The Senate must also approve it.",
        explanation="The House approved a conference committee report to resolve differences in each chamber's version of the bill. The Senate must also approve the conference report.",
        sort_order=(2,2))
    conference_passed_senate = enum.Item(31,
        'Conference Report Agreed to by Senate',
        xml_code='CONFERENCE:PASSED:SENATE',
        search_help_text="The Senate approved a conference committee report to resolve differences. The House must also approve it.",
        explanation="The Senate approved a conference committee report to resolve differences in each chamber's version of the bill. The House must also approve the conference report.",
        sort_order=(2,3))
    prov_kill_suspensionfailed = enum.Item(12,
        'Failed Under Suspension',
        xml_code='PROV_KILL:SUSPENSIONFAILED',
        search_help_text="Passage failed under \"suspension of the rules\" but can be voted on again.",
        simple_label="Failed in the House Under Suspension",
        explanation="Passage was attempted under a fast-track procedure called \"suspension of the rules.\" The vote failed, but the bill can be voted on again.",
        sort_order=(4,0))
    prov_kill_cloturefailed = enum.Item(13,
        'Failed Cloture',
        xml_code='PROV_KILL:CLOTUREFAILED',
        search_help_text="Cloture (ending a filibuster) failed but can be tried again.",
        simple_label="Failed Cloture in the Senate",
        explanation="The Senate must often vote to end debate before voting on a bill, called a cloture vote. The vote on cloture failed. This is often considered a filibuster. The Senate may try again.",
        sort_order=(4,1))
    prov_kill_pingpongfail = enum.Item(14,
        'Failed to Resolve Differences',
        xml_code='PROV_KILL:PINGPONGFAIL',
        search_help_text="The House or Senate failed to resolve differences with the other chamber but can try again.",
        explanation="The House or Senate did not approve of changes to the bill made in the other chamber. They can try again.",
        sort_order=(4,2))
    prov_kill_veto = enum.Item(15,
        'Vetoed (No Override Attempt)',
        xml_code='PROV_KILL:VETO',
        search_help_text="Vetoed by the President but the veto can be overridden.",
        simple_label="Vetoed",
        explanation="The President vetoed the bill. Congress may attempt to override the veto.",
        sort_order=(5,4))
    fail_originating_house = enum.Item(16,
        'Failed House',
        xml_code='FAIL:ORIGINATING:HOUSE',
        search_help_text="Failed in the House, its originating chamber",
        explanation=lambda b : "A vote on the %s failed in the House. The %s is now dead." % (b.noun, b.noun),
        sort_order=(5,0))
    fail_originating_senate = enum.Item(17,
        'Failed Senate',
        xml_code='FAIL:ORIGINATING:SENATE',
        search_help_text="Failed in the Senate, its originating chamber",
        explanation=lambda b : "A vote on the %s failed in the Senate. The %s is now dead." % (b.noun, b.noun),
        sort_order=(5,1))
    fail_second_house = enum.Item(19,
        'Passed Senate, Failed House',
        xml_code='FAIL:SECOND:HOUSE',
        search_help_text="Passed the Senate but failed in the House.",
        simple_label="Failed House",
        explanation=lambda b : "A vote on the %s failed in the House. The %s is now dead." % (b.noun, b.noun),
        sort_order=(5,2))
    fail_second_senate = enum.Item(20,
        'Passed House, Failed Senate',
        xml_code='FAIL:SECOND:SENATE',
        search_help_text="Passed the House but failed in the Senate.",
        simple_label="Failed Senate",
        explanation=lambda b : "A vote on the %s failed in the Senate. The %s is now dead." % (b.noun, b.noun),
        sort_order=(5,3))
    override_pass_over_house = enum.Item(21,
        'Vetoed & House Overrides (Senate Next)',
        xml_code='VETOED:OVERRIDE_PASS_OVER:HOUSE',
        search_help_text="The House passed a veto override, sending it to the Senate.",
        simple_label="House Overrides Veto",
        explanation="A vote to override the President's veto succeeded in the House. The Senate must do the same.",
        sort_order=(6,0))
    override_pass_over_senate = enum.Item(22,
        'Vetoed & Senate Overrides (House Next)',
        xml_code='VETOED:OVERRIDE_PASS_OVER:SENATE',
        search_help_text="The Senate passed a veto override, sending it to the House.",
        simple_label="Senate Overrides Veto",
        explanation="A vote to override the President's veto succeeded in the Senate. The House must do the same.",
        sort_order=(6,1))
    vetoed_pocket = enum.Item(23,
        'Pocket Vetoed',
        xml_code='VETOED:POCKET',
        search_help_text="Pocket vetoed by the President.",
        explanation="The President pocked-vetoed the bill, which means the bill is dead and Congress does not have an opportunity to override the veto.",
        sort_order=(5,5))
    vetoed_override_fail_originating_house = enum.Item(24,
        'Vetoed & Override Failed in House',
        xml_code='VETOED:OVERRIDE_FAIL_ORIGINATING:HOUSE',
        search_help_text="The House's attempt to override a veto failed.",
        simple_label="House Override Failed",
        explanation="A vote to override the President's veto failed in the House. The bill is now dead.",
        sort_order=(5,6))
    vetoed_override_fail_originating_senate = enum.Item(25,
        'Vetoed & Override Failed in Senate',
        xml_code='VETOED:OVERRIDE_FAIL_ORIGINATING:SENATE',
        search_help_text="The Senate's attempt to override a veto failed.",
        simple_label="Senate Override Failed",
        explanation="A vote to override the President's veto failed in the Senate. The bill is now dead.",
        sort_order=(5,7))
    vetoed_override_fail_second_house = enum.Item(26,
        'Vetoed & Override Passed Senate, Failed in House',
        xml_code='VETOED:OVERRIDE_FAIL_SECOND:HOUSE',
        search_help_text="The Senate overrode the veto but the House's attempt to override the veto failed.",
        simple_label="House Override Failed",
        explanation="A vote to override the President's veto failed in the House. The bill is now dead.",
        sort_order=(5,8))
    vetoed_override_fail_second_senate = enum.Item(27,
        'Vetoed & Override Passed House, Failed in Senate',
        xml_code='VETOED:OVERRIDE_FAIL_SECOND:SENATE',
        search_help_text="The House overrode the veto but the Senate's attempt to override the veto failed.",
        simple_label="Senate Override Failed",
        explanation="A vote to override the President's veto failed in the Senate. The bill is now dead.",
        sort_order=(5,9))
    enacted_signed = enum.Item(28,
        'Signed by the President',
        xml_code='ENACTED:SIGNED',
        search_help_text="Enacted by a signature of the President.",
        explanation="The President signed the bill and it became law.",
        sort_order=(3,3))
    enacted_veto_override = enum.Item(29,
        'Veto Overridden',
        xml_code='ENACTED:VETO_OVERRIDE',
        search_help_text="Enacted by a veto override.",
        explanation="Congress overrided the veto of the President. The bill became law.",
        sort_order=(3,5))
    enacted_tendayrule = enum.Item(32,
        'Enacted by 10 Day Rule',
        xml_code='ENACTED:TENDAYRULE',
        search_help_text="Enacted by failing to be returned by the President within ten days (Sundays excepted).",
        explanation="The bill was enacted by failing to be signed or vetoed by the President within ten days of receiving the bill from Congress (Sundays excepted).",
        sort_order=(3,4))

    # indicates statuses whose descriptions are clear that the bill is no longer active,
    # other statuses are displayed as "Died: " for bills from previous congresses.
    final_status_obvious = (passed_simpleres, passed_constamend, passed_concurrentres, prov_kill_veto, fail_originating_house, fail_originating_senate, fail_second_house, fail_second_senate, vetoed_pocket, enacted_signed, enacted_veto_override, enacted_tendayrule, vetoed_override_fail_originating_house, vetoed_override_fail_originating_senate, vetoed_override_fail_second_house, vetoed_override_fail_second_senate, passed_bill)

    # indicates a bill at the end of its life cycle and passed
    final_status_passed_bill = (enacted_signed, enacted_veto_override, enacted_tendayrule)
    final_status_passed_resolution = (passed_simpleres, passed_constamend, passed_concurrentres)
    final_status_passed = tuple(list(final_status_passed_bill) + list(final_status_passed_resolution))
    
    # indicates a bill at the end of its life cycle and failed
    final_status_failed = (fail_originating_house, fail_originating_senate, fail_second_house, fail_second_senate, vetoed_pocket, vetoed_override_fail_originating_house, vetoed_override_fail_originating_senate, vetoed_override_fail_second_house, vetoed_override_fail_second_senate)

    # all final statuses
    final_status = tuple(list(final_status_passed_bill) + list(final_status_passed_resolution) + list(final_status_failed))

	# the statuses that are basically just introduction
    introduced_statuses = (introduced, referred)

def get_bill_status_string(is_current, status):
    # Returns a string with two %'s in it, one for the bill noun ("bill"/"resolution")
    # and one for the status date.
    
    # Some status messages depend on whether the bill is current:
    if is_current:
        if status == "INTRODUCED":
            status = "This %s is in the first stage of the legislative process. It was introduced into Congress on %s. It will typically be considered by committee next."
        elif status == "REFERRED":
            status = "This %s was assigned to a congressional committee on %s, which will consider it before possibly sending it on to the House or Senate as a whole."
        elif status == "REPORTED":
            status = "The committees assigned to this %s sent it to the House or Senate as a whole for consideration on %s."
        elif status == "PASS_OVER:HOUSE":
            status = "This %s passed in the House on %s and goes to the Senate next for consideration."
        elif status == "PASS_OVER:SENATE":
            status = "This %s passed in the Senate on %s and goes to the House next for consideration."
        elif status == "PASSED:BILL":
            status = "This %s was passed by Congress on %s and goes to the President next."
        elif status == "PASS_BACK:HOUSE":
            status = "This %s passed in the Senate and the House, but the House made changes and sent it back to the Senate on %s."
        elif status == "PASS_BACK:SENATE":
            status = "This %s has been passed in the House and the Senate, but the Senate made changes and sent it back to the House on %s."
        elif status == "CONFERENCE:PASSED:HOUSE":
            status = "The conference report for this %s was agreed to in the House on %s. The Senate must also approve it. A conference report resolves the differences in the bill in each chamber."
        elif status == "CONFERENCE:PASSED:SENATE":
            status = "The conference report for this %s was agreed to in the Senate on %s. The House must also approve it. A conference report resolves the differences in the bill in each chamber."
        elif status == "PROV_KILL:SUSPENSIONFAILED":
            status = "This %s is provisionally dead due to a failed vote on %s under a fast-track procedure called \"suspension.\" It may or may not get another vote."
        elif status == "PROV_KILL:CLOTUREFAILED":
            status = "This %s is provisionally dead due to a failed vote for cloture on %s. Cloture is required to move past a Senate filibuster or the threat of a filibuster and takes a 3/5ths vote. In practice, most bills must pass cloture to move forward in the Senate."
        elif status == "PROV_KILL:PINGPONGFAIL":
            status = "This %s is provisionally dead due to a failed attempt to resolve differences between the House and Senate versions, on %s."
        elif status == "PROV_KILL:VETO":
            status = "This %s was vetoed by the President on %s. The bill is dead unless Congress can override it."
        elif status == "OVERRIDE_PASS_OVER:HOUSE":
            status = "After a presidential veto of the %s, the House succeeeded in an override on %s. It goes to the Senate next."
        elif status == "OVERRIDE_PASS_OVER:SENATE":
            status = "After a presidential veto of the %s, the Senate succeeded in an override on %s. It goes to the House next."
    
    else: # Bill is not current.
        if status == "INTRODUCED" or status == "REFERRED" or status == "REPORTED":
            status = "This %s was introduced on %s, in a previous session of Congress, but was not enacted."
        elif status == "PASS_OVER:HOUSE":
            status = "This %s was introduced in a previous session of Congress and was passed by the House on %s but was never passed by the Senate."
        elif status == "PASS_OVER:SENATE":
            status = "This %s was introduced in a previous session of Congress and was passed by the Senate on %s but was never passed by the House."
        elif status == "PASSED:BILL":
            status = "This %s was passed by Congress on %s but was not enacted before the end of its Congressional session. (It is possible this bill is waiting for the signature of the President.)"
        elif status in ("PASS_BACK:HOUSE", "PASS_BACK:SENATE"):
            status = "This %s was introduced in a previous session of Congress and though it was passed by both chambers on %s it was passed in non-identical forms and the differences were never resolved."
        elif status in ("CONFERENCE:PASSED:HOUSE", "CONFERENCE:PASSED:SENATE"):
            status = "This %s was introduced in a previous session of Congress and though it was passed by both chambers, it was passed in non-identical form and only one chamber approved a conference report to resolve the differences."
        elif status == "PROV_KILL:SUSPENSIONFAILED" or status == "PROV_KILL:CLOTUREFAILED" or status == "PROV_KILL:PINGPONGFAIL":
            status = "This %s was introduced in a previous session of Congress but was killed due to a failed vote for cloture, under a fast-track vote called \"suspension\", or while resolving differences on %s."
        elif status == "PROV_KILL:VETO":
            status = "This %s was vetoed by the President on %s and Congress did not attempt an override before the end of the Congressional session."
        elif status == "OVERRIDE_PASS_OVER:HOUSE" or status == "OVERRIDE_PASS_OVER:SENATE":
            status = "This %s was vetoed by the President and Congress did not finish an override begun on %s before the end of the Congressional session."
        
    # Some status messages do not depend on whether the bill is current.
    
    if status == "PASSED:SIMPLERES":
        status = "This simple %s was agreed to on %s. That is the end of the legislative process for a simple resolution."
    elif status == "PASSED:CONSTAMEND":
        status = "This %s proposing a constitutional amendment was agreed to by both chambers of Congress on %s and goes to the states for consideration next."
    elif status == "PASSED:CONCURRENTRES":
        status = "This concurrent %s was agreed to by both chambers of Congress on %s. That is the end of the legislative process for concurrent resolutions. They do not have the force of law."
    elif status == "FAIL:ORIGINATING:HOUSE":
        status = "This %s failed in the House on %s."
    elif status == "FAIL:ORIGINATING:SENATE":
        status = "This %s failed in the Senate on %s."
    elif status == "FAIL:SECOND:HOUSE":
        status = "After passing in the Senate, this %s failed in the House on %s."
    elif status == "FAIL:SECOND:SENATE":
        status = "After passing in the House, this %s failed in the Senate on %s."
    elif status == "VETOED:OVERRIDE_FAIL_ORIGINATING:HOUSE" or status == "VETOED:OVERRIDE_FAIL_SECOND:HOUSE":
        status = "This %s was vetoed. The House attempted to override the veto on %s but failed."
    elif status == "VETOED:OVERRIDE_FAIL_ORIGINATING:SENATE" or status == "VETOED:OVERRIDE_FAIL_SECOND:SENATE":
        status = "This %s was vetoed. The Senate attempted to override the veto on %s but failed."
    elif status == "VETOED:POCKET":
        status = "This %s was pocket vetoed on %s."
    elif status == "ENACTED:SIGNED":
        status = "This %s was enacted after being signed by the President on %s."
    elif status == "ENACTED:VETO_OVERRIDE":
        status = "This %s was enacted after a congressional override of the President's veto on %s."
    elif status == "ENACTED:TENDAYRULE":
        status = "This %s became enacted on %s after ten days elapsed after being presented to the President."
    
    return status   


########NEW FILE########
__FILENAME__ = tests
from django.test import TestCase

from bill.models import BillType
from bill.title import get_primary_bill_title, get_secondary_bill_title

class BillMockup(object):
    def __init__(self, **kwargs):
        for key, value in kwargs.items():
            setattr(self, key, value)

class BillTitleTestCase(TestCase):
    def test_title_calculation(self):
        bill = BillMockup(congress=112,
                          bill_type=BillType.house_bill,
                          number=525)
        # Simple test
        titles = (('short', 'abc', 'title1'),)
        self.assertEqual('H.R. 525: title1', get_primary_bill_title(bill, titles))

        # Should be first title amoung titles with as="abc"
        titles = (('short', 'abc', 'title1'),
                  ('short', 'abc', 'title2'))
        self.assertEqual('H.R. 525: title1', get_primary_bill_title(bill, titles))

        # Should be title with short type
        titles = (('popular', 'abc', 'title1'),
                  ('short', 'abc', 'title2'))
        self.assertEqual('H.R. 525: title2', get_primary_bill_title(bill, titles))

        # Should be title with short type
        titles = (('popular', 'abc', 'title1'),
                  ('short', 'abc', 'title2'),
                  ('short', 'abc', 'title3'))
        self.assertEqual('H.R. 525: title2', get_primary_bill_title(bill, titles))

        # Should be first title in group of title with as=abc2
        titles = (('short', 'abc', 'title1'),
                  ('short', 'abc', 'title2'),
                  ('short', 'abc2', 'title3'),
                  ('short', 'abc2', 'title4'))
        self.assertEqual('H.R. 525: title3', get_primary_bill_title(bill, titles))

        # Should be title with official type
        titles = (('short', 'abc', 'title1'),
                  ('official', 'abc', 'title2'))
        self.assertEqual('title2', get_secondary_bill_title(bill, titles))

        # Should be None
        titles = (('official', 'abc', 'title2'),)
        self.assertEqual(None, get_secondary_bill_title(bill, titles))

########NEW FILE########
__FILENAME__ = title
"""
Function which computes Bill title.
"""
import re

from django.conf import settings
from django.contrib.humanize.templatetags.humanize import ordinal

def get_bill_number(bill, show_congress_number="ARCHIVAL"):
    "Compute display form of bill number"
    
    if bill.congress <= 42:
        # This is an American Memory bill. It's number is stored.
        ret = bill.title.split(":")[0]
    else:
        from bill.models import BillType
        ret = '%s %s' % (BillType.by_value(bill.bill_type).label, bill.number)
    if (bill.congress != settings.CURRENT_CONGRESS and show_congress_number == "ARCHIVAL") or show_congress_number == "ALL":
        ret += ' (%s)' % ordinal(bill.congress)
    return ret


def get_primary_bill_title(bill, titles, with_number=True, override_number=None):
    """
    Calculate primary bill title.

    Args:
        bill: ``Bill`` instance
        titles: list of (type, as) values, extracted from the XML
    """

    type_, as_, title  = find_title(titles)
    if title:
        title = normalize_title(title)
    else:
        title = "No Title"
    if with_number:
        return '%s: %s' % (get_bill_number(bill) if not override_number else override_number, title)
    else:
        return title


def get_secondary_bill_title(bill, titles):
    """
    Calculate secondary bill title.

    Return None if calcualated title is the same as primary title.
    """

    type_, as_, primary_title  = find_title(titles)
    type_, as_, official_title = find_title(titles, limit_type='official')
    if primary_title == official_title:
        return None
    else:
        return official_title



def normalize_title(title):
    "replace apostrophes/quotes with curly ones"

    title = re.sub(r"(\S)(''|\")", r"\1" + u"\N{RIGHT DOUBLE QUOTATION MARK}", title)
    title = re.sub(r"(\S)'", r"\1" + u"\N{RIGHT SINGLE QUOTATION MARK}", title)
    title = re.sub(r"(''|\")", u"\N{LEFT DOUBLE QUOTATION MARK}", title)
    title = re.sub(r"'", u"\N{LEFT SINGLE QUOTATION MARK}", title)
    return title


def find_title(titles, limit_type=None):
    """
    Find last unempty title with one of specified types.

    Args:
        titles: list of (type, as, content) tuples.
        limit_type: search only among titles of given type

    Some comments from Josh:

    There are three types of titles: official, short, and popular. The primary display title of a bill is a short title, falling back on a popular title if there are no short titles, and finally falling back on an official title if there are no other title types. To find the title of a given type, you take the *first* title that has the *last* as attribute, i.e. take the one marked:

     ... as="1" ...
     ... as="1" ...
     ... as="2" ... <-- use this one
     ... as="2" ...

    This is because the "as" attributes are given in chronological order, but within each "as" the first one is the most relevant (other titles can be for subparts of bills).
    """
   
    if limit_type:
        types = (limit_type,)
    else:
        types = ('short', 'popular', 'official')

    def weight(type_):
        try:
            return types.index(type_)
        except IndexError:
            return 100

    choice = None

    for type_, as_, content in titles:
        for test_type in types:
            if type_ == test_type and content:
                # If no title found before or
                # Founded title has different "as"
                # Then use the current title
                if (choice is None or
                    choice[0] == type_ and choice[1] != as_ or
                    weight(type_) < weight(choice[0])):
                    choice = (type_, as_, content)
    return choice if choice else (None, None, None)

########NEW FILE########
__FILENAME__ = urls
# -*- coding: utf-8 -*-
from django.conf.urls import *

urlpatterns = patterns('bill.views',
    url(r'^browse$', 'bill_list', name='bill_list'),
    url(r'^(\d+)/([a-z]+)(\d+)$', 'bill_details', name='bill_details'),
    url(r'^(\d+)/([a-z]+)(\d+)/text(?:/([a-z0-9]+))?$', 'bill_text', name='bill_text'),
    url(r'^(\d+)/([a-z]+)(\d+)/widget$', 'bill_widget_info'),
    url(r'^(\d+)/([a-z]+)(\d+)/widget\.html$', 'bill_widget'),
    url(r'^(\d+)/([a-z]+)(\d+)/widget\.js$', 'bill_widget_loader'),
    url(r'^subjects/([^/]+)/(\d+)', 'subject'),
    url(r'^$', 'bill_docket', name='bill_docket'),
    url(r'^statistics$', 'bill_statistics', name='bill_stats'),
    url(r'^uscode(?:/(\d+|.*))?$', 'uscodeindex'),
    url(r'^_ajax/market_test_vote', 'market_test_vote'),
    url(r'^_ajax/load_text', 'bill_text_ajax'),
    url(r'^_ajax/join_community', 'join_community'),
    url(r'^_admin/go_to_summary_admin', 'go_to_summary_admin', name="bill_go_to_summary_admin"),
    url(r'^_redirect/start-poll', 'start_poll', name="bill_start_poll"),
    url(r'^(\d+)/([a-z]+)(\d+)/_text_image$', 'bill_text_image'),
)

urlpatterns += patterns('',
    url(r'^real_or_not', 'bill.bill_or_not.bill_or_not'),
    url(r'^_ajax/bill_or_not', 'bill.bill_or_not.load_game'),
)

########NEW FILE########
__FILENAME__ = views
# -*- coding: utf-8 -*-
from django.shortcuts import redirect, get_object_or_404
from django.core.urlresolvers import reverse
from django.http import Http404, HttpResponseRedirect, HttpResponse
from django.conf import settings
from django.contrib.humanize.templatetags.humanize import ordinal
from django.contrib.auth.decorators import login_required
from django.db.models import Count, F
from django.core.cache import cache

from common.decorators import render_to
from common.pagination import paginate

from bill.models import Bill, BillType, BillStatus, BillTerm, TermType, BillTextComparison, BillSummary
from bill.search import bill_search_manager, parse_bill_citation
from bill.title import get_secondary_bill_title
from committee.util import sort_members
from person.models import Person
from events.models import Feed

from settings import CURRENT_CONGRESS

from us import get_congress_dates

import urllib, urllib2, json, datetime, re
from registration.helpers import json_response
from twostream.decorators import anonymous_view, user_view_for

def load_bill_from_url(congress, type_slug, number):
    # not sure why we were trying this
    #if type_slug.isdigit():
    #    bill_type = type_slug
    try:
        bill_type = BillType.by_slug(type_slug)
    except BillType.NotFound:
        raise Http404("Invalid bill type: " + type_slug)

    return get_object_or_404(Bill, congress=congress, bill_type=bill_type, number=number)

@anonymous_view
@render_to('bill/bill_details.html')
def bill_details(request, congress, type_slug, number):
    bill = load_bill_from_url(congress, type_slug, number)

    # get related bills
    related_bills = []
    reintro_prev = None
    reintro_next = None
    for reintro in bill.find_reintroductions():
        if reintro.congress < bill.congress: reintro_prev = reintro
        if reintro.congress > bill.congress and not reintro_next: reintro_next = reintro
    if reintro_prev: related_bills.append({ "bill": reintro_prev, "note": "was a previous version of this bill.", "show_title": False })
    if reintro_next: related_bills.append({ "bill": reintro_next, "note": "was a re-introduction of this bill in a later Congress.", "show_title": False })
    for rb in bill.get_related_bills():
        if rb.relation in ("identical", "rule"):
            related_bills.append({ "bill": rb.related_bill, "note": "(%s)" % rb.relation, "show_title": False })
        elif rb.relation == "ruled-by":
            related_bills.append({ "bill": rb.related_bill, "prenote": "Debate on", "note": " is governed by these rules.", "show_title": False })
        else:
            related_bills.append({ "bill": rb.related_bill, "note": ("(%s)" % (rb.relation.title() if rb.relation != "unknown" else "Related")), "show_title": True })

    # bill text info and areas of law affected
    from billtext import load_bill_text
    try:
        text_info = load_bill_text(bill, None, mods_only=True, with_citations=True)
    except IOError:
        text_info = None

    return {
        'bill': bill,
        "congressdates": get_congress_dates(bill.congress),
        "subtitle": get_secondary_bill_title(bill, bill.titles),
        "current": bill.congress == CURRENT_CONGRESS,
        "dead": bill.congress != CURRENT_CONGRESS and bill.current_status not in BillStatus.final_status_obvious,
        "feed": bill.get_feed(),
        "text_info": text_info,
        "related": related_bills,
    }

@user_view_for(bill_details)
def bill_details_user_view(request, congress, type_slug, number):
    bill = load_bill_from_url(congress, type_slug, number)

    ret = { }
    if request.user.is_staff:
        admin_panel = """
            {% load humanize %}
            <div class="clear"> </div>
            <div style="margin-top: 1.5em; padding: .5em; background-color: #EEE; ">
                <b>ADMIN</b> - <a href="{% url "bill_go_to_summary_admin" %}?bill={{bill.id}}">Edit Summary</a>
                <br/>Tracked by {{feed.tracked_in_lists.count|intcomma}} users
                ({{feed.tracked_in_lists_with_email.count|intcomma}} w/ email).
                <br/>{{num_issuepos}} poll responses, {{num_calls}} phone calls to Congress.
            </div>
            """

        from poll_and_call.models import RelatedBill as IssueByBill
        try:
            from poll_and_call.models import *
            ix = RelatedBill.objects.get(bill=bill).issue
            num_issuepos = UserPosition.objects.filter(position__issue=ix).count()
            num_calls = len([c for c in CallLog.objects.filter(position__position__issue=ix) if c.is_complete()])
        except IssueByBill.DoesNotExist:
            num_issuepos = 0
            num_calls = 0

        from django.template import Template, Context, RequestContext, loader
        ret["admin_panel"] = Template(admin_panel).render(RequestContext(request, {
            'bill': bill,
            "feed": bill.get_feed(),
            "num_issuepos": num_issuepos,
            "num_calls": num_calls,
            }))

    from person.views import render_subscribe_inline
    ret.update(render_subscribe_inline(request, bill.get_feed()))

    # poll_and_call
    if request.user.is_authenticated():
        from poll_and_call.models import RelatedBill as IssueByBill, UserPosition
        try:
            issue = IssueByBill.objects.get(bill=bill).issue
            try:
                up = UserPosition.objects.get(user=request.user, position__issue=issue)
                targets = up.get_current_targets()
                ret["poll_and_call_position"] =  {
                    "id": up.position.id,
                    "text": up.position.text,
                    "can_change": up.can_change_position(),
                    "can_call": [(t.id, t.person.name) for t in targets] if isinstance(targets, list) else [],
                    "call_url": issue.get_absolute_url() + "/make_call",
                }
            except UserPosition.DoesNotExist:
                pass
        except IssueByBill.DoesNotExist:
            pass
        
    return ret

@anonymous_view
@render_to("bill/bill_widget.html")
def bill_widget(request, congress, type_slug, number):
    bill = load_bill_from_url(congress, type_slug, number)

    from person.name import get_person_name
    sponsor_name = None if not bill.sponsor else \
        get_person_name(bill.sponsor, role_date=bill.introduced_date, firstname_position='before', show_suffix=True)

    def get_text_info():
        from billtext import load_bill_text
        try:
            return load_bill_text(bill, None, mods_only=True)
        except IOError:
            return None

    return {
        "SITE_ROOT_URL": settings.SITE_ROOT_URL,
        "bill": bill,
        "congressdates": get_congress_dates(bill.congress),
        "subtitle": get_secondary_bill_title(bill, bill.titles),
        "sponsor_name": sponsor_name,
        "current": bill.congress == CURRENT_CONGRESS,
        "dead": bill.congress != CURRENT_CONGRESS and bill.current_status not in BillStatus.final_status_obvious,
        "text": get_text_info,
    }

@anonymous_view
def bill_widget_loader(request, congress, type_slug, number):
    bill = load_bill_from_url(congress, type_slug, number)

    # @render_to() doesn't support additional parameters, so we have to render manually.
    from django.shortcuts import render_to_response
    from django.template import RequestContext
    return render_to_response("bill/bill_widget.js", { "bill": bill, "SITE_ROOT_URL": settings.SITE_ROOT_URL }, context_instance=RequestContext(request), content_type="text/javascript" )

@anonymous_view
@render_to("bill/bill_widget_info.html")
def bill_widget_info(request, congress, type_slug, number):
    bill = load_bill_from_url(congress, type_slug, number)
    return {
        "bill": bill,
        "SITE_ROOT_URL": settings.SITE_ROOT_URL,
    }

@json_response
@login_required
def market_test_vote(request):
    bill = get_object_or_404(Bill, id = request.POST.get("bill", "0"))
    prediction = int(request.POST.get("prediction", "0"))
    market = bill.get_open_market(request.user)
    if not market: return { }

    from predictionmarket.models import Trade, TradingAccount
    account = TradingAccount.get(request.user)
    if prediction != 0:
        # Buy shares in one of the outcomes.
        try:
            t = Trade.place(account, market.outcomes.get(owner_key = 1 if prediction == 1 else 0), 10)
        except ValueError as e:
            return { "error": str(e) }

    else:
        # Sell shares.
        positions, pl = account.position_in_market(market)
        for outcome in positions:
            Trade.place(account, outcome, -positions[outcome]["shares"])

    return { "vote": prediction }

@anonymous_view
@render_to('bill/bill_text.html')
def bill_text(request, congress, type_slug, number, version=None):
    if version == "":
        version = None

    try:
        bill_type = BillType.by_slug(type_slug)
    except BillType.NotFound:
        raise Http404("Invalid bill type: " + type_slug)
    bill = get_object_or_404(Bill, congress=congress, bill_type=bill_type, number=number)

    from billtext import load_bill_text, bill_gpo_status_codes
    try:
        textdata = load_bill_text(bill, version)
    except IOError:
        textdata = None

    # Get a list of the alternate versions of this bill.
    alternates = None
    if textdata:
        alternates = []
        for v in bill_gpo_status_codes:
            try:
                alternates.append(load_bill_text(bill, v, mods_only=True))
            except IOError:
                pass
        alternates.sort(key = lambda mods : mods["docdate"])

    # Get a list of related bills.
    from billtext import get_current_version
    related_bills = []
    for rb in list(bill.find_reintroductions()) + [r.related_bill for r in bill.get_related_bills()]:
        try:
            rbv = get_current_version(rb)
            if not (rb, rbv) in related_bills: related_bills.append((rb, rbv))
        except IOError:
            pass # text not available
    for btc in BillTextComparison.objects.filter(bill1=bill).exclude(bill2=bill):
        if not (btc.bill2, btc.ver2) in related_bills: related_bills.append((btc.bill2, btc.ver2))
    for btc in BillTextComparison.objects.filter(bill2=bill).exclude(bill1=bill):
        if not (btc.bill1, btc.ver1) in related_bills: related_bills.append((btc.bill1, btc.ver1))

    return {
        'bill': bill,
        "congressdates": get_congress_dates(bill.congress),
        "textdata": textdata,
        "version": version,
        "alternates": alternates,
        "related_bills": related_bills,
    }

@anonymous_view
@json_response
def bill_text_ajax(request):
    for p in ("left_bill", "left_version", "right_bill", "right_version", "mode"):
        if not p in request.GET:
            raise Http404()

    try:
        return load_comparison(request.GET["left_bill"], request.GET["left_version"], request.GET["right_bill"], request.GET["right_version"])
    except IOError:
        return { "error": "Bill text is not available for those bills." }

def load_comparison(left_bill, left_version, right_bill, right_version, timelimit=10, force=False):
    from billtext import load_bill_text, compare_xml_text, get_current_version
    import lxml

    left_bill = Bill.objects.get(id = left_bill)
    right_bill = Bill.objects.get(id = right_bill)

    if left_version == "": left_version = get_current_version(left_bill)
    if right_version == "": right_version = get_current_version(right_bill)

    btc = None
    try:
        btc = BillTextComparison.objects.get(
            bill1 = left_bill,
            ver1 = left_version,
            bill2 = right_bill,
            ver2 = right_version)
        btc.decompress()
        if not force: return btc.data
    except BillTextComparison.DoesNotExist:
        pass

    # Try with the bills swapped.
    try:
        btc2 = BillTextComparison.objects.get(
            bill2 = left_bill,
            ver2 = left_version,
            bill1 = right_bill,
            ver1 = right_version)
        btc2.decompress()
        data = btc2.data
        return {
            "left_meta": data["right_meta"],
            "right_meta": data["left_meta"],
            "left_text": data["right_text"],
            "right_text": data["left_text"],
        }
    except BillTextComparison.DoesNotExist:
        pass

    left = load_bill_text(left_bill, left_version, mods_only=True)
    right = load_bill_text(right_bill, right_version, mods_only=True)

    try:
        doc1 = lxml.etree.parse(left["html_file"])
        doc2 = lxml.etree.parse(right["html_file"])
    except KeyError:
        raise IOError("The HTML bill text format is not available for one of the bills.")

    compare_xml_text(doc1, doc2, timelimit=timelimit) # revises DOMs in-place

    # dates aren't JSON serializable
    left["docdate"] = left["docdate"].strftime("%x")
    right["docdate"] = right["docdate"].strftime("%x")

    ret = {
        "left_meta": left,
        "right_meta": right,
        "left_text": lxml.etree.tostring(doc1),
        "right_text": lxml.etree.tostring(doc2),
    }

    if not btc:
        btc = BillTextComparison(
            bill1 = left_bill,
            ver1 = left_version,
            bill2 = right_bill,
            ver2 = right_version,
            data = dict(ret)) # clone before compress()
    else:
        btc.data = dict(ret) # clone before compress()

    btc.compress()
    btc.save()

    return ret

def bill_list(request):
    if request.POST.get("allow_redirect", "") == "true":
        bill = parse_bill_citation(request.POST.get("text", ""), congress=request.POST.get("congress", ""))
        if bill:
            @json_response
            def get_redirect_response():
                return { "redirect": bill.get_absolute_url() }
            return get_redirect_response()

    ix1 = None
    ix2 = None
    if "subject" in request.GET:
        ix = BillTerm.objects.get(id=request.GET["subject"])
        if ix.parents.all().count() == 0:
            ix1 = ix
        else:
            ix1 = ix.parents.all()[0]
            ix2 = ix
    return show_bill_browse("bill/bill_list.html", request, ix1, ix2, { })

def show_bill_browse(template, request, ix1, ix2, context):
    return bill_search_manager().view(request, template,
        defaults={
            "congress": request.GET["congress"] if "congress" in request.GET else (CURRENT_CONGRESS if "sponsor" not in request.GET else None), # was Person.objects.get(id=request.GET["sponsor"]).most_recent_role_congress(), but we can just display the whole history which is better at the beginning of a Congress when there are no bills
            "sponsor": request.GET.get("sponsor", None),
            "terms": ix1.id if ix1 else None,
            "terms2": ix2.id if ix2 else None,
            "text": request.GET.get("text", None),
            "current_status": request.GET.get("status").split(",") if "status" in request.GET else None,
            "sort": request.GET.get("sort", None if "sponsor" not in request.GET else "-introduced_date"),
            "usc_cite": request.GET.get("usc_cite"),
        },
        noun = ("bill", "bills"),
        context = context,
        )

def query_popvox(method, args):
    if isinstance(method, (list, tuple)):
        method = "/".join(method)

    _args = { }
    if args != None: _args.update(args)
    _args["api_key"] = settings.POPVOX_API_KEY

    url = "https://www.popvox.com/api/" + method + "?" + urllib.urlencode(_args).encode("utf8")

    req = urllib2.Request(url)
    resp = urllib2.urlopen(req)
    if resp.getcode() != 200:
        raise Exception("Failed to load page: " + url)
    ret = resp.read()
    encoding = resp.info().getparam("charset")
    ret = ret.decode(encoding)
    return json.loads(ret)

subject_choices_data = None
def subject_choices(include_legacy=True):
    global subject_choices_data
    if subject_choices_data == None:
        subject_choices_data = { }
        for t in BillTerm.objects.filter(term_type=TermType.new).exclude(parents__id__gt=0):
            x = []
            subject_choices_data[t] = x
            for tt in t.subterms.all():
                x.append(tt)
        subject_choices_data = sorted(subject_choices_data.items(), key = lambda x : x[0].name)
    return subject_choices_data

# used by bill_docket and bill_statistics
bill_status_groups = [
    ("Enacted Laws",
        "enacted bills and joint resolutions", " so far in this session of Congress", " (both bills and joint resolutions can be enacted as law)",
        BillStatus.final_status_passed_bill), # 2
    ("Passed Resolutions",
        "passed resolutions", " so far in this session of Congress (for joint and concurrent resolutions, passed both chambers)", " (for joint and concurrent resolutions, this means passed both chambers)",
        BillStatus.final_status_passed_resolution), # 3
    ("Got A Vote",
        "bills and joint/concurrent resolutions", " that had a significant vote in one chamber, making them likely to have further action", " that had a significant vote in one chamber",
        (BillStatus.pass_over_house, BillStatus.pass_over_senate, BillStatus.pass_back_senate, BillStatus.pass_back_house, BillStatus.conference_passed_house, BillStatus.conference_passed_senate, BillStatus.passed_bill)), # 7
    ("Failed Legislation",
        "bills and resolutions", " that failed a vote on passage and are now dead or failed a significant vote such as cloture, passage under suspension, or resolving differences", " that failed a vote on passage or failed a significant vote such as cloture, passage under suspension, or resolving differences",
        (BillStatus.fail_originating_house, BillStatus.fail_originating_senate, BillStatus.fail_second_house, BillStatus.fail_second_senate, BillStatus.prov_kill_suspensionfailed, BillStatus.prov_kill_cloturefailed, BillStatus.prov_kill_pingpongfail)), # 7
    ("Vetoed Bills (w/o Override)",
        "bills", " that were vetoed and the veto was not overridden by Congress", " that were vetoed and the veto was not overridden by Congress",
        (BillStatus.prov_kill_veto, BillStatus.override_pass_over_house, BillStatus.override_pass_over_senate, BillStatus.vetoed_pocket, BillStatus.vetoed_override_fail_originating_house, BillStatus.vetoed_override_fail_originating_senate, BillStatus.vetoed_override_fail_second_house, BillStatus.vetoed_override_fail_second_senate)), # 8
    ("Other Legislation",
        "bills and resolutions", " that have been introduced, referred to committee, or reported by committee and await further action", " that were introduced, referred to committee, or reported by committee but had no further action",
        (BillStatus.introduced, BillStatus.referred, BillStatus.reported)), # 3
]

def load_bill_status_qs(statuses, congress=CURRENT_CONGRESS):
    return Bill.objects.filter(congress=congress, current_status__in=statuses)

@anonymous_view
@render_to('bill/bill_docket.html')
def bill_docket(request):
    def build_info():
        feeds = [f for f in Feed.get_simple_feeds() if f.category == "federal-bills"]

        groups = [
            (   g[0], # title
                g[1], # text 1
                g[2], # text 2
                "/congress/bills/browse?status=" + ",".join(str(s) for s in g[4]), # link
               load_bill_status_qs(g[4]).count(), # count in category
               load_bill_status_qs(g[4]).order_by('-current_status_date')[0:6], # top 6 in this category
                )
            for g in bill_status_groups ]

        dhg_bills = Bill.objects.filter(congress=CURRENT_CONGRESS, docs_house_gov_postdate__gt=datetime.datetime.now() - datetime.timedelta(days=10)).filter(docs_house_gov_postdate__gt=F('current_status_date'))
        sfs_bills = Bill.objects.filter(congress=CURRENT_CONGRESS, senate_floor_schedule_postdate__gt=datetime.datetime.now() - datetime.timedelta(days=5)).filter(senate_floor_schedule_postdate__gt=F('current_status_date'))
        coming_up = list(dhg_bills | sfs_bills)
        coming_up.sort(key = lambda b : b.docs_house_gov_postdate if (b.docs_house_gov_postdate and (not b.senate_floor_schedule_postdate or b.senate_floor_schedule_postdate < b.docs_house_gov_postdate)) else b.senate_floor_schedule_postdate, reverse=True)

        start, end = get_congress_dates(CURRENT_CONGRESS)
        end_year = end.year if end.month > 1 else end.year-1 # count January finishes as the prev year
        current_congress_years = '%d-%d' % (start.year, end.year)
        current_congress = ordinal(CURRENT_CONGRESS)

        return {
            "feeds": feeds,

            "total": Bill.objects.filter(congress=CURRENT_CONGRESS).count(),
            "current_congress_years": current_congress_years,
            "current_congress": current_congress,
            "groups": groups,
            "coming_up": coming_up,
            "subjects": subject_choices(),
            "BILL_STATUS_INTRO": (BillStatus.introduced, BillStatus.referred, BillStatus.reported),
        }

    ret = cache.get("bill_docket_info")
    if not ret:
        ret = build_info()
        cache.set("bill_docket_info", ret, 60*60)

    return ret

@anonymous_view
@render_to('bill/bill_statistics.html')
def bill_statistics(request):
    # Get the count of bills by status and by Congress.
    counts_by_congress = []
    for c in xrange(93, CURRENT_CONGRESS+1):
        total = Bill.objects.filter(congress=c).count()
        if total == 0: continue # during transitions between Congresses
        counts_by_congress.append({
            "congress": c,
            "dates": get_congress_dates(c),
            "counts": [ ],
            "total": total,
        })
        for g in bill_status_groups:
            t = load_bill_status_qs(g[4], congress=c).count()
            counts_by_congress[-1]["counts"].append(
                { "count": t,
                  "percent": "%0.0f" % float(100.0*t/total),
                  "link": "/congress/bills/browse?congress=%s&status=%s" % (c, ",".join(str(s) for s in g[4])),
                  } )
    counts_by_congress.reverse()

    # When does activity occur within the session cycle?
    if settings.DATABASES['default']['ENGINE'] != 'django.db.backends.sqlite3':
        from django.db import connection
        cursor = connection.cursor()
        def pull_time_stat(field, where, historical=True):
            cursor.execute("SELECT YEAR(%s) - congress*2 - 1787, MONTH(%s), COUNT(*) FROM bill_bill WHERE congress>=93 AND congress%s%d AND %s GROUP BY YEAR(%s) - congress*2, MONTH(%s)" % (field, field, "<" if historical else "=", CURRENT_CONGRESS, where, field, field))
            activity = [{ "x": r[0]*12 + (r[1]-1), "count": r[2], "year": r[0] } for r in cursor.fetchall()]
            total = sum(m["count"] for m in activity)
            for i, m in enumerate(activity): m["cumulative_count"] = m["count"]/float(total) + (0.0 if i==0 else activity[i-1]["cumulative_count"])
            for m in activity: m["count"] = round(m["count"] / (CURRENT_CONGRESS-96), 1)
            for m in activity: m["cumulative_count"] = round(m["cumulative_count"] * 100.0)
            return activity
        activity_introduced_by_month = pull_time_stat('introduced_date', "1")
        activity_enacted_by_month = pull_time_stat('current_status_date', "current_status IN (%d,%d,%d)" % (int(BillStatus.enacted_signed), int(BillStatus.enacted_veto_override, BillStatus.enacted_tendayrule)))
    else:
        activity_introduced_by_month = []
        activity_enacted_by_month = []

    return {
        "groups2": bill_status_groups,
        "counts_by_congress": counts_by_congress,
        "activity": (("Bills and Resolutions Introduced", activity_introduced_by_month),
         ("Bills and Joint Resolutions Enacted", activity_enacted_by_month) )
    }

@anonymous_view
def subject(request, sluggedname, termid):
    ix = get_object_or_404(BillTerm, id=termid)
    if ix.parents.all().count() == 0:
        ix1 = ix
        ix2 = None
    else:
        ix1 = ix.parents.all()[0]
        ix2 = ix
    return show_bill_browse("bill/subject.html", request, ix1, ix2, { "term": ix, "feed": ix.get_feed() })

@user_view_for(subject)
def subject_user_view(request, sluggedname, termid):
    ix = get_object_or_404(BillTerm, id=termid)
    ret = { }
    from person.views import render_subscribe_inline
    ret.update(render_subscribe_inline(request, ix.get_feed()))
    return ret

import django.contrib.sitemaps
class sitemap_current(django.contrib.sitemaps.Sitemap):
    changefreq = "weekly"
    priority = 1.0
    def items(self):
        return Bill.objects.filter(congress=CURRENT_CONGRESS).only("congress", "bill_type", "number")
class sitemap_archive(django.contrib.sitemaps.Sitemap):
    index_levels = ['congress']
    changefreq = "yearly"
    priority = 0.25
    def items(self):
        return Bill.objects.filter(congress__lt=CURRENT_CONGRESS).only("congress", "bill_type", "number")

@render_to('bill/bill_advocacy_tips.html')
def bill_advocacy_tips(request, congress, type_slug, number):
    try:
        bill_type = BillType.by_slug(type_slug)
    except BillType.NotFound:
        raise Http404("Invalid bill type: " + type_slug)
    bill = get_object_or_404(Bill, congress=congress, bill_type=bill_type, number=number)
    return { "bill": bill }

@json_response
@login_required
def join_community(request):
    from website.models import CommunityInterest
    from bill.models import Bill
    methods = request.POST["methods"].strip()
    if methods == "":
        CommunityInterest.objects.filter(user=request.user, bill=request.POST["bill"]).delete()
    else:
        c, isnew = CommunityInterest.objects.get_or_create(user=request.user, bill=Bill.objects.get(id=request.POST["bill"]))
        c.methods = methods
        c.save()
    return { "status": "OK" }

from django.contrib.auth.decorators import permission_required
@permission_required('bill.change_billsummary')
def go_to_summary_admin(request):
    summary, is_new = BillSummary.objects.get_or_create(bill=get_object_or_404(Bill, id=request.GET["bill"]))
    return HttpResponseRedirect("/admin/bill/billsummary/%d" % summary.id)

@anonymous_view
@render_to('bill/uscode_index.html')
def uscodeindex(request, secid):
    from bill.models import USCSection
    if not secid:
        parent = None
    elif re.match(r"\d+$", secid):
        parent = get_object_or_404(USCSection, id=secid)
    else:
        parent = get_object_or_404(USCSection, citation="usc/" + secid)

    children = USCSection.objects.filter(parent_section=parent).order_by('ordering')

    from haystack.query import SearchQuerySet
    qs = SearchQuerySet().using("bill").filter(indexed_model_name__in=["Bill"])
    qs_current = qs.filter(congress=CURRENT_CONGRESS)

    # How many bills cite this section?
    num_bills = qs_current.filter(usc_citations_uptree=parent.id).count() if parent else qs_current.count()

    # Mark the children if we should allow the user to navigate there.
    # Only let them go to parts of the table of contents where there
    # are lots of bills to potentially track, at least historically.
    has_child_navigation = False
    for c in children:
        c.num_bills = qs.filter(usc_citations_uptree=c.id).count()
        c.allow_navigation = c.num_bills > 5
        has_child_navigation |= c.allow_navigation
    
    return {
        "parent": parent,
        "children": children,
        "has_child_navigation": has_child_navigation,
        "num_bills_here": num_bills,
        "bills_here": (qs_current.filter(usc_citations_uptree=parent.id) if parent else qs) if num_bills < 100 else None,
        "base_template": 'master_c.html' if parent else "master_b.html",
        "feed": (Feed.objects.get_or_create(feedname="usc:" + str(parent.id))[0]) if parent else None,
    }

@anonymous_view
def start_poll(request):
    from poll_and_call.models import Issue, IssuePosition, RelatedBill as IssueByBill

    # get the bill & valence
    bill = get_object_or_404(Bill, id=request.GET.get("bill"))
    valence = (request.GET.get("position") == "support")

    # get the Issue
    try:
        ix = IssueByBill.objects.get(bill=bill).issue
    except IssueByBill.DoesNotExist:
        # no Issue yet, so create
        ix = Issue.objects.create(
            slug = "%d-%s-%d" % (bill.congress, bill.bill_type_slug, bill.number),
            title = "PLACEHOLDER",
            question = "PLACEHOLDER",
            introtext = "Weigh in on %s." % bill.display_number_with_congress_number,
            isopen = True,
            )
        IssueByBill.objects.create(issue=ix, bill=bill, valence=True)

    # update the Issue since the bill title may have changed
    ix.title = bill.title
    ix.question = "What is your position on %s?" % bill.title
    ix.save()

    # how to refer to the bill in the call script
    from django.template.defaultfilters import truncatewords
    title = bill.title_no_number
    if re.match(".* Act( of \d{4})?", title):
        title = "The " + title
    title = bill.display_number + ": " + title
    bt = truncatewords(title, 11)
    if "..." in bt:
        bt = truncatewords(title, 15)
        bt = u"%s (\u201C%s\u201D)" % (bill.display_number, bt.replace(bill.display_number + ": ", ""))

    # create and update the options
    for opt_valence, opt_verb in ((True, "support"), (False, "oppose")):
        try:
            p = ix.positions.get(valence=opt_valence)
        except:
            p = IssuePosition.objects.create(
                    text="PLACEHOLDER",
                    valence=opt_valence,
                    call_script="PLACEHOLDER",
                    )
            ix.positions.add(p)

        p.text = opt_verb.title()
        p.call_script = "I %s %s." % (opt_verb, bt)
        p.save()

    return HttpResponseRedirect(ix.get_absolute_url() + "/join/" + str(ix.positions.get(valence=valence).id))

@anonymous_view
def bill_text_image(request, congress, type_slug, number):
    bill = load_bill_from_url(congress, type_slug, number)
    from billtext import load_bill_text

    # Rasterizes a page of a PDF to a greyscale PIL.Image.
    # Crop out the GPO seal & the vertical margins.
    def pdftopng(pdffile, pagenumber, width=900):
        from PIL import Image
        import subprocess, StringIO
        pngbytes = subprocess.check_output(["/usr/bin/pdftoppm", "-f", str(pagenumber), "-l", str(pagenumber), "-scale-to", str(width), "-png", pdffile])
        im = Image.open(StringIO.StringIO(pngbytes))
        im = im.convert("L")

        # crop out the GPO seal:
        im = im.crop((0, int((.06 if pagenumber==1 else 0) * im.size[0]), im.size[0], im.size[1]))

        # zealous-crop the vertical margins, but at least leaving a little
        # at the bottom so that when we paste the two pages of the two images
        # together they don't get totally scruntched, and put in some padding
        # at the top.
        # (.getbbox() crops out zeroes, so we'll invert the image to make it work with white)
        from PIL import ImageOps
        bbox = ImageOps.invert(im).getbbox()
        vpad = int(.02*im.size[1])
        im = im.crop( (0, max(0, bbox[1]-vpad), im.size[0], min(im.size[1], bbox[3]+vpad) ) )

        return im

    # Find the PDF file and rasterize the first two pages.

    try:
        metadata = load_bill_text(bill, None, mods_only=True)
    except IOError:
        # if bill text metadata isn't available, trap the error
        # and just 404 it
        raise Http404()

    if metadata.get("pdf_file"):
        # Use the PDF files on disk.
        pg1 = pdftopng(metadata.get("pdf_file"), 1)
        try:
            pg2 = pdftopng(metadata.get("pdf_file"), 2)
        except:
            pg2 = pg1.crop((0, 0, pg1.size[0], 0)) # may only be one page!
    elif settings.DEBUG:
        # When debugging in a local environment we may not have bill text available
        # so download the PDF from GPO.
        import os, tempfile, subprocess
        try:
            (fd1, fn1) = tempfile.mkstemp(suffix=".pdf")
            os.close(fd1)
            subprocess.check_call(["/usr/bin/wget", "-O", fn1, "-q", metadata["gpo_pdf_url"]])
            pg1 = pdftopng(fn1, 1)
            pg2 = pdftopng(fn1, 2)
        finally:
            os.unlink(fn1)
    else:
        # No PDF is available.
        raise Http404()

    # Since some bills have big white space at the top of the first page,
    # we'll combine the first two pages and then shift the window down
    # until the real start of the bill.
    
    from PIL import Image
    img = Image.new(pg1.mode, (pg1.size[0], int(pg1.size[1]+pg2.size[1])))
    img.paste(pg1, (0,0))
    img.paste(pg2, (0,pg1.size[1]))

    # Zealous crop the (horizontal) margins. We do this only after the two
    # pages have been combined so that we don't mess up their alignment.
    # Add some padding.
    from PIL import ImageOps
    hpad = int(.02*img.size[0])
    bbox = ImageOps.invert(img).getbbox()
    img = img.crop( (max(0, bbox[0]-hpad), 0, min(img.size[0], bbox[2]+hpad), img.size[1]) )

    # Now take a window from the top matching a particular aspect ratio.
    # We're going to display this next to photos of members of congress,
    # so use that aspect ratio.
    img = img.crop((0,0, img.size[0], int(240.0/200.0*img.size[0])))

    # Resize to requested width.
    if "width" in request.GET:
        img.thumbnail((int(request.GET["width"]), 11.0/8.0*int(request.GET["width"])), Image.ANTIALIAS)

    import StringIO
    imgbytesbuf = StringIO.StringIO()
    img.save(imgbytesbuf, "PNG")
    imgbytes = imgbytesbuf.getvalue()
    imgbytesbuf.close()
    return HttpResponse(imgbytes, mimetype="image/png")

########NEW FILE########
__FILENAME__ = admin
# -*- coding: utf-8

from django.contrib import admin
from committee.models import Committee, CommitteeMember

class CommitteeInline(admin.TabularInline):
    model = Committee

class CommitteeAdmin(admin.ModelAdmin):
    list_display = ['name', 'committee_type', 'code', 'obsolete', 'committee']
    list_filter = ['obsolete']
    inlines = [CommitteeInline]
    search_fields = ['name', 'code']


class CommitteeMemberAdmin(admin.ModelAdmin):
    list_display = ['person', 'committee', 'role']
    raw_id_fields = ['person']
    search_fields = ['person__firstname', 'person__lastname', 'committee__name']

admin.site.register(Committee, CommitteeAdmin)
admin.site.register(CommitteeMember, CommitteeMemberAdmin)

########NEW FILE########
__FILENAME__ = models
# -*- coding: utf-8 -*-
from django.db import models
from django.core.urlresolvers import reverse

from datetime import datetime, timedelta
import re

from common import enum

from settings import CURRENT_CONGRESS

class CommitteeType(enum.Enum):
    senate = enum.Item(1, 'Senate', abbrev="S")
    joint = enum.Item(2, 'Joint', abbrev="J")
    house = enum.Item(3, 'House', abbrev="H")


class Committee(models.Model):
    """Committees and subcommittees in the United States Congress, including historical committees."""

    # committee_type applies to committees but not subcommittees
    committee_type = models.IntegerField(choices=CommitteeType, blank=True, null=True, help_text="Whether this is a House, Senate, or Joint committee.")
    code = models.CharField(max_length=10, help_text="An alphanumeric code used for the committee on THOMAS.gov, House.gov, and Senate.gov.")
    name = models.CharField(max_length=255, help_text="The name of the committee or subcommittee. Committee names typically look like '{House,Senate} Committee on ...', while subcommmittee names look like 'Legislative Branch'.")
    url = models.CharField(max_length=255, blank=True, null=True, help_text="The committee's website.")
    abbrev = models.CharField(max_length=255, blank=True, help_text="A really short abbreviation for the committee. Has no special significance.")
    obsolete = models.BooleanField(blank=True, default=False, db_index=True, help_text="True if this committee no longer exists.")
    committee = models.ForeignKey('self', blank=True, null=True, related_name='subcommittees', on_delete=models.PROTECT, help_text="This field indicates whether the object is a commmittee, in which case the committee field is null, or a subcommittee, in which case this field gives the parent committee.")

    def __unicode__(self):
        return self.name

    class Meta:
        ordering = ['name']

    # api
    api_recurse_on = ("committee",)
    api_example_id = 2650
    api_example_list = { "obsolete": "0" }

    def get_absolute_url(self):
        parent = self.committee
        if parent:
            return reverse('subcommittee_details', args=[parent.code, self.code[4:]])
        else:
            return reverse('committee_details', args=[self.code])

    @property
    def fullname(self):
        if self.committee == None:
            return self.name
        else:
            return self.committee.name + ": Subcommittee on " + self.name

    @property
    def shortname(self):
	    return self.fullname.replace("Committee on the ", "").replace("Committee on ", "")

    def sortname(self, with_chamber=False):
        if self.committee:
            return self.committee.sortname(with_chamber) + ": " + self.name.replace("Subcommittee on the ", "").replace("Subcommittee on ", "")

        m = re.match("(House|Senate|Joint) ((Select|Special|Permanent Select) )?Committee on (the )?(.+)", self.name)
        if not m: return self.name # unrecognized format
        return \
              ((self.committee.sortname + " ") if self.committee else "") \
            + ((m.group(1) + " ") if with_chamber else "") \
            + m.group(5)

    @property
    def name_no_article(self):
            n = self.name
            if n.startswith("the "): n = n[4:]
            return n

    def committee_type_label(self):
        try:
            return CommitteeType.by_value(self.committee_type).label
        except enum.NotFound:
            return ""

    def committee_type_abbrev(self):
        return CommitteeType.by_value(self.committee_type).abbrev

    def current_bills(self):
        return self.bills.filter(congress=CURRENT_CONGRESS)

    def get_feed(self, feed_type=""):
        if feed_type not in ("", "bills", "meetings"): raise ValueError(feed_type)
        from events.models import Feed
        return Feed.objects.get_or_create(feedname="committee%s:%s" % (feed_type, self.code))[0]

    @staticmethod
    def from_feed(feed, test=False):
        if ":" not in feed.feedname or feed.feedname.split(":")[0] not in ("committee", "committeebills", "committeemeetings"): raise ValueError(feed.feedname)
        try:
            return Committee.objects.get(code=feed.feedname.split(":")[1])
        except Committee.DoesNotExist:
            if test: return False
            raise ValueError(feed.feedname)

    @staticmethod
    def AllCommitteesFeed():
        from events.models import Feed
        return Feed.get_noarg_feed("misc:allcommittee")
    
    def create_events(self):
        from events.models import Feed, Event
        feeds = [Committee.AllCommitteesFeed(), self.get_feed("meetings")]
        if self.committee: feeds.append(self.committee.get_feed("meetings")) # add parent committee
        with Event.update(self) as E:
            for meeting in self.meetings.all():
                E.add("mtg_" + str(meeting.id), meeting.when,
                	feeds + [b.get_feed() for b in meeting.bills.all()])

    def render_event(self, eventid, feeds):
        eventinfo = eventid.split("_")
        mtg = CommitteeMeeting.objects.get(id=eventinfo[1])

        return {
            "type": "Committee Meeting",
            "date": mtg.when,
            "title": self.fullname + " Meeting",
            "url": self.get_absolute_url(),
            "body_text_template": """{{subject|safe}}""",
            "body_html_template": """<p>{{subject}}</p> <p><small>Check out our new <a href="https://www.govtrack.us/congress/committees/calendar">committee meeting calendar</a>.</small></p>""",
            "context": {
                "subject": mtg.subject + (" (Location: " + mtg.room + ")" if mtg.room else ""),
                }
            }


class CommitteeMemberRole(enum.Enum):
    exofficio = enum.Item(1, 'Ex Officio')
    chairman = enum.Item(2, 'Chairman')
    ranking_member = enum.Item(3, 'Ranking Member')
    vice_chairman = enum.Item(4, 'Vice Chairman')
    member = enum.Item(5, 'Member')

class CommitteeMember(models.Model):
    """A record indicating the current membership of a Member of Congress on a committee or subcommittee.
    The IDs on these records are not stable (do not use them)."""

    # The parser wipes out this table each time it loads up
    # committee membership, so we should not create any
    # foreign keys to this model.

    person = models.ForeignKey('person.Person', related_name='committeeassignments', help_text="The Member of Congress serving on a committee.")
    committee = models.ForeignKey('committee.Committee', related_name='members', help_text="The committee or subcommittee being served on.")
    role = models.IntegerField(choices=CommitteeMemberRole, default=CommitteeMemberRole.member, help_text="The role of the member on the committee.")

    def __unicode__(self):
        return '%s @ %s as %s' % (self.person, self.committee, self.get_role_display())

    # api
    api_recurse_on = ("committee","person")

    def role_name(self):
        return CommitteeMemberRole.by_value(self.role).label

    def subcommittee_role(self):
        try:
            return CommitteeMember.objects.filter(committee__committee=self.committee, person=self.person, role=CommitteeMemberRole.chairman)[0]
        except IndexError:
            return None

    def role_name_2(self):
        if self.role in (CommitteeMemberRole.member, CommitteeMemberRole.exofficio):
            return "a member of"
        else:
            return "the %s of" % self.role_name().lower()

MEMBER_ROLE_WEIGHTS = {
    CommitteeMemberRole.chairman: 5,
    CommitteeMemberRole.vice_chairman: 4,
    CommitteeMemberRole.ranking_member: 3,
    CommitteeMemberRole.exofficio: 2,
    CommitteeMemberRole.member: 1
}

class CommitteeMeeting(models.Model):
    created = models.DateTimeField(auto_now_add=True)
    committee = models.ForeignKey(Committee, related_name="meetings", db_index=True)
    when = models.DateTimeField()
    subject = models.TextField()
    bills = models.ManyToManyField("bill.Bill", blank=True)
    guid = models.CharField(max_length=36, db_index=True, unique=True)
    room = models.TextField(null=True)

    class Meta:
        ordering = [ "-created" ]

    def __unicode__(self):
        return self.guid

    @property
    def is_recently_added(self):
        return (self.created > (datetime.now() - timedelta(hours=36)))

    def abbrev_committee_name(self):
        return self.committee.sortname(True)

# feeds

from events.models import Feed, truncate_words
Feed.register_feed(
    "misc:allcommittee",
    title = "Committee Meetings",
    link = "/congress/committees",
    simple = True,
    sort_order = 103,
    category = "federal-committees",
    description = "Get an alert whenever a committee hearing or mark-up session is scheduled.",
    )
Feed.register_feed(
    "committee:",
    title = lambda feed : truncate_words(Committee.from_feed(feed).fullname, 12),
    noun = "committee",
    includes = lambda feed : [Committee.from_feed(feed).get_feed("bills"), Committee.from_feed(feed).get_feed("meetings")],
    link = lambda feed: Committee.from_feed(feed).get_absolute_url(),
    scoped_title = lambda feed : "All Events for This Committee",
    is_valid = lambda feed : Committee.from_feed(feed, test=True),
    category = "federal-committees",
    description = "You will get updates about major activity on bills referred to this commmittee plus notices of scheduled hearings and mark-up sessions.",
    )
Feed.register_feed(
    "committeebills:",
    title = lambda feed : "Bills in " + truncate_words(Committee.from_feed(feed).fullname, 12),
    noun = "committee",
    link = lambda feed: Committee.from_feed(feed).get_absolute_url(),
    scoped_title = lambda feed : "Activity on This Committee's Bills",
    category = "federal-committees",
    description = "You will get updates about major activity on bills referred to this commmittee.",
    )
Feed.register_feed(
    "committeemeetings:",
    title = lambda feed : "Meetings for " + truncate_words(Committee.from_feed(feed).fullname, 12),
    noun = "committee",
    link = lambda feed: Committee.from_feed(feed).get_absolute_url(),
    scoped_title = lambda feed : "This Committee's Hearings and Markups",
    single_event_type = True,
    category = "federal-committees",
    description = "You will get notices for this committee's scheduled hearings and mark-up sessions.",
    )

########NEW FILE########
__FILENAME__ = urls
# -*- coding: utf-8 -*-
from django.conf.urls import *

urlpatterns = patterns('committee.views',
    url(r'^$', 'committee_list', name='committee_list'),
    url(r'^calendar$', 'committee_calendar', name='committee_calendar'),
    url(r'^(\w+)$', 'committee_details', name='committee_details'),
    url(r'^(\w+)/(\w+)$', 'committee_details', name='subcommittee_details'),
)

########NEW FILE########
__FILENAME__ = util
from committee.models import MEMBER_ROLE_WEIGHTS

def sort_members(members):
    """
    Commettee members should be displayed in sorted order.
    Sorting is performed with this function.
    """

    return sorted(members, key=lambda c : (-MEMBER_ROLE_WEIGHTS[c.role], not c.subcommittee_role(), c.person.name_no_details_lastfirst(), c.committee.shortname))

########NEW FILE########
__FILENAME__ = views
# -*- coding: utf-8 -*-
from django.shortcuts import redirect, get_object_or_404
from django.core.urlresolvers import reverse

from common.decorators import render_to
from common.pagination import paginate

from committee.models import Committee, CommitteeMemberRole, CommitteeType, CommitteeMeeting
from committee.util import sort_members
from events.models import Feed

from datetime import datetime

@render_to('committee/committee_details.html')
def committee_details(request, parent_code, child_code=None):
    if child_code:
        if len(child_code) == 2:
            obj = get_object_or_404(Committee, code=parent_code+child_code)
        else: # legacy
            obj = get_object_or_404(Committee, code=child_code)
            return redirect(obj, permanent=True)
        parent = obj.committee
    else:
        obj = get_object_or_404(Committee, code=parent_code)
        parent = None
    members = sort_members(obj.members.all())
    subcommittees = sorted(obj.subcommittees.filter(obsolete=False), key=lambda s : s.name_no_article)
    
    party_counts = { }
    for m in members:
        role = m.person.get_current_role()
        if role: # member left congress but is still listed as committee member
            party_counts[role.party] = party_counts.get(role.party, 0) + 1
    party_counts = sorted(party_counts.items(), key = lambda p : -p[1])
    
    return {'committee': obj,
            'parent': parent,
            'subcommittees': subcommittees,
            'members': members,
            'SIMPLE_MEMBER': CommitteeMemberRole.member,
            'TYPE_JOINT': CommitteeType.joint,
            'feed': obj.get_feed(),
            "member_highlights": [m for m in members if m.role in (CommitteeMemberRole.chairman, CommitteeMemberRole.vice_chairman, CommitteeMemberRole.ranking_member)],
            "party_counts": party_counts,
            }

@render_to('committee/committee_list.html')
def committee_list(request):
    from events.models import Feed
    import re

    def getlist(type_):
        items = list(Committee.objects.filter(committee_type=type_, obsolete=False))
        for c in items:
            if c.name.startswith("Joint "):
                c.display_name = c.name
            else:
                c.display_name = c.sortname()
        return sorted(items, key=lambda c : c.display_name)

    return {
        'senate_committees': getlist(CommitteeType.senate),
        'house_committees': getlist(CommitteeType.house),
        'joint_committees': getlist(CommitteeType.joint),
        'feed': Committee.AllCommitteesFeed(),
    }

   
import django.contrib.sitemaps
class sitemap(django.contrib.sitemaps.Sitemap):
    changefreq = "weekly"
    priority = 1.0
    def items(self):
        return Committee.objects.filter(obsolete=False)

@render_to("committee/calendar.html")
def committee_calendar(request):
    committee_meetings = list(CommitteeMeeting.objects.filter(when__gte=datetime.now().date()).order_by()\
        .prefetch_related("committee", "committee__committee"))
    committee_meetings.sort(key = lambda mtg : (mtg.when, mtg.committee.sortname(True)))

    return {
        "committee_meetings": committee_meetings,
        'feed': Committee.AllCommitteesFeed(),
    }

########NEW FILE########
__FILENAME__ = check_email_update
from django.contrib.auth.models import User
from django.core.management.base import BaseCommand, CommandError

from django.core.mail import send_mail, EmailMultiAlternatives
from django.template import Context, Template
from django.template.loader import get_template
from django.conf import settings

from optparse import make_option

from events.models import *
from emailverification.models import Ping, BouncedEmail

from datetime import datetime, timedelta

now = datetime.now()

class Command(BaseCommand):
	args = 'emailaddress'
	help = 'Checks the status of an email update (e.g. for when a user says they are not getting updates.'
	
	def handle(self, *args, **options):
		if len(args) != 1:
			print "Specify an email address."
			return
			
		try:
			user = User.objects.get(email=args[0])
		except User.DoesNotExist:
			print "Not a user."
			return
		
		print "Joined:", user.date_joined
		print "Last Login:", user.last_login
		
		try:
			p = Ping.objects.get(user=user)
			print "Last Ping:", p.pingtime
		except Ping.DoesNotExist:
			print "No Ping"
			
		try:
			b = BouncedEmail.objects.get(user=user)
			print "Bounce:", b.firstbouncetime, "x" + str(b.bounces)
		except BouncedEmail.DoesNotExist:
			print "No Bounces"
			
		for sublist in user.subscription_lists.all():
			print sublist.name,
			if sublist.email == 0:
				print "- Emails Off"
			else:
				print "-", sublist.get_email_display(),
				print "Last Email:", sublist.last_email_sent,
			
				max_id, events = sublist.get_new_events()
				print len(events), "events pending"
			
			for feed in sublist.trackers.all():
				print "\t", feed.title.encode("utf8")

########NEW FILE########
__FILENAME__ = send_email_updates
from django.contrib.auth.models import User
from django.core.management.base import BaseCommand, CommandError

from django.core.mail import send_mail, EmailMultiAlternatives
from django.template import Context, Template
from django.template.loader import get_template
from django.conf import settings

from optparse import make_option

from events.models import *
from emailverification.models import Ping, BouncedEmail

import os
from datetime import datetime, timedelta
import yaml, markdown2

now = datetime.now()

class Command(BaseCommand):
	args = 'daily|weekly|testadmin|testcount'
	help = 'Sends out email updates of events to subscribing users.'
	
	def handle(self, *args, **options):
		if len(args) != 1:
			print "Specify daily or weekly or testadmin or testcount."
			return
		if args[0] not in ('daily', 'weekly', 'testadmin', 'testcount'):
			print "Specify daily or weekly or testadmin or testcount."
			return
			
		verbose = (args[0] not in ('daily', 'weekly',)) or True
		
		# What kind of subscription lists are we processing?
		users = None
		send_mail = True
		mark_lists = True
		send_old_events = False
		if args[0] == "daily":
			list_email_freq = (1,)
		elif args[0] == "weekly":
			list_email_freq = (1,2)
		elif args[0] == "testadmin":
			# test an email to the site administrator only
			list_email_freq = (1,2)
			users = User.objects.filter(email="jt@occams.info")
			send_mail = True
			mark_lists = False
			send_old_events = True
		elif args[0] == "testcount":
			# count up how many daily emails we would send, but don't send any
			list_email_freq = (1,2)
			send_mail = False
			mark_lists = False

		if users == None: # overridden by the testadmin case above
			# Find all users who have a subscription list with email
			# updates turned on to the right daily/weekly setting.
			users = User.objects.filter(subscription_lists__email__in = list_email_freq).distinct()
			
		if os.environ.get("START"):
			users = users.filter(id__gte=int(os.environ["START"]))
				#, id__lt=169660)
			
		total_emails_sent = 0
		total_events_sent = 0
		total_users_skipped_stale = 0
		total_users_skipped_bounced = 0
		for user in list(users.order_by('id')): # clone up front to avoid holding the cursor (?)
			# Check pingback status.
			try:
				p = Ping.objects.get(user=user)
			except Ping.DoesNotExist:
				p = None
				
			if user.last_login < datetime(2009, 4, 1) and p == None:
				# We warned these people on 2012-04-17 that if they didn't log in
				# they might stop getting email updates.
				total_users_skipped_stale += 1
				continue
			elif user.last_login < datetime.now() - timedelta(days=3) \
				and (not p or not p.pingtime or p.pingtime < datetime.now() - timedelta(days=20)) \
				and BouncedEmail.objects.filter(user=user).exists():
				total_users_skipped_bounced += 1
				continue
			
			events_sent = send_email_update(user, list_email_freq, verbose, send_mail, mark_lists, send_old_events)
			if events_sent != None:
				total_emails_sent += 1
				total_events_sent += events_sent
			
			#from django.db import connection
			#for q in connection.queries:
			#	print q["time"], q["sql"]
			from django import db
			db.reset_queries()
				
		print "Sent" if send_mail else "Would send", total_emails_sent, "emails and", total_events_sent, "events"
		print total_users_skipped_stale, "users skipped because they are stale"
		print total_users_skipped_bounced, "users skipped because of a bounced email"
			
def send_email_update(user, list_email_freq, verbose, send_mail, mark_lists, send_old_events):
	global now
	
	# get the email's From: header and return path
	emailfromaddr = getattr(settings, 'EMAIL_UPDATES_FROMADDR',
			getattr(settings, 'SERVER_EMAIL', 'no.reply@example.com'))
	emailreturnpath = emailfromaddr
	if hasattr(settings, 'EMAIL_UPDATES_RETURN_PATH'):
		emailreturnpath = (settings.EMAIL_UPDATES_RETURN_PATH % user.id)

	# get announcement content
	announce = load_markdown_content("website/email/email_update_announcement.md")
		
	emailsubject = "GovTrack Update for %s" % (datetime.now().strftime("%b. %d").replace(" 0", " "))
	if announce["active"] and announce["subject"]:
		emailsubject += "  |  " + announce["subject"]

	send_no_events = send_old_events

	all_trackers = set()

	eventslists = []
	most_recent_event = None
	eventcount = 0
	for sublist in user.subscription_lists.all():
		all_trackers |= set(sublist.trackers.all()) # include trackers for non-email-update list
		if send_old_events: sublist.last_event_mailed = None
		if sublist.email in list_email_freq:
			max_id, events = sublist.get_new_events()
			if len(events) > 0:
				eventslists.append( (sublist, events) )
				eventcount += len(events)
				most_recent_event = max(most_recent_event, max_id)
	
	if len(eventslists) == 0 and not send_no_events:
		return None
		
	if not send_mail:
		# don't email, don't update lists with the last emailed id
		return eventcount
	
	# Add a pingback image into the email to know (with some low accuracy) which
	# email addresses are still valid, for folks that have not logged in recently
	# and did not successfully recently ping back.
	emailpingurl = None
	if user.last_login < datetime.now() - timedelta(days=60) \
		and not Ping.objects.filter(user=user, pingtime__gt=datetime.now() - timedelta(days=60)).exists():
		emailpingurl = Ping.get_ping_url(user)
		
	templ_txt = get_template("events/emailupdate.txt")
	templ_html = get_template("events/emailupdate.html")
	ctx = Context({
		"eventslists": eventslists,
		"feed": all_trackers, # use all trackers in the user's account as context for displaying events
		"emailpingurl": emailpingurl,
		"SITE_ROOT_URL": settings.SITE_ROOT_URL,
		"announcement": announce
	})

	# render text and HTML renditions
	templ_txt = templ_txt.render(ctx)
	templ_html = templ_html.render(ctx)

	# form MIME message
	email = EmailMultiAlternatives(
		emailsubject,
		templ_txt,
		emailreturnpath,
		[user.email],
		headers = {
			'From': emailfromaddr,
			'Auto-Submitted': 'auto-generated',
			'X-Auto-Response-Suppress': 'OOF',
		})
	email.attach_alternative(templ_html, "text/html")
	
	try:
		if verbose:
			print "emailing", user.id, user.email, "x", eventcount, "..."
		email.send(fail_silently=False)
	except Exception as e:
		print user, e
		return None # skip updating what events were sent, False = did not sent
	
	if not mark_lists:
		return eventcount
	
	# mark each list as having mailed events up to the max id found from the
	# events table so that we know not to email those events in a future update.
	for sublist, events in eventslists:
		sublist.last_event_mailed = max(sublist.last_event_mailed, most_recent_event)
		sublist.last_email_sent = now
		sublist.save()
		
	return eventcount # did sent email

def load_markdown_content(template_path, utm=""):
	# Load the Markdown template for the current blast.
	templ = get_template(template_path)
	ctx = Context({ })

	# Get the text-only body content, which also includes some email metadata.
	# Replace Markdown-style [text][href] links with the text plus bracketed href.
	ctx.update({ "format": "text", "utm": "" })
	body_text = templ.render(ctx).strip()
	ctx.pop()
	body_text = re.sub(r"\[(.*?)\]\((.*?)\)", r"\1 at \2", body_text)

	# The top of the text content contains metadata in YAML format,
	# with "id" and "subject" required.
	meta_info, body_text = body_text.split("----------", 1)
	meta_info = yaml.load(meta_info)
	body_text = body_text.strip()

	# Get the HTML body content.
	ctx.update({
		"format": "html",
		"utm": utm,
	})
	body_html = templ.render(ctx).strip()
	body_html = markdown2.markdown(body_html)
	ctx.pop()

	# Store everything in meta_info.
	
	meta_info["body_text"] = body_text
	meta_info["body_html"] = body_html
	
	return meta_info

########NEW FILE########
__FILENAME__ = unsubscribe
from django.contrib.auth.models import User
from django.core.management.base import BaseCommand, CommandError

from django.core.mail import send_mail, EmailMultiAlternatives
from django.template import Context, Template
from django.template.loader import get_template
from django.conf import settings

from optparse import make_option

from events.models import *
from website.models import UserProfile

from datetime import datetime

class Command(BaseCommand):
	args = 'user@email.com'
	help = 'Unsubscribes a user from receiving email updates.'
	
	def handle(self, *args, **options):
		if len(args) != 1:
			print "Specify a user's email address."
			return
		
		try:
			p = UserProfile.objects.get(user__email=args[0])
		except UserProfile.DoesNotExist:
			print "No such user."
			return
		print "Turning off mass email option."
		p.massemail = False
		p.save()
		
		print "Turning off email updates on the following subscription lists..."
		for sublist in SubscriptionList.objects.filter(user__email=args[0]):
			print sublist.user.email, sublist.name, "was", sublist.email
			
			sublist.email = 0
			sublist.save()
			

########NEW FILE########
__FILENAME__ = middleware
from models import SubscriptionList

def template_context_processor(request):
	context = { "subscription_feeds": None }
	
	if request.user.is_authenticated():
		subfeeds = set()
		for x in SubscriptionList.objects.filter(user=request.user):
			subfeeds |= set(x.trackers.all())
		context["subscription_feeds"] = subfeeds
	
	return context


########NEW FILE########
__FILENAME__ = models
# -*- coding: utf-8 -*-
from django.db import models, DatabaseError
from django.core.urlresolvers import reverse
from django.contrib.contenttypes.models import ContentType
from django.contrib.contenttypes import generic
from django.contrib.auth.models import User

import re
import urllib
from datetime import datetime, timedelta

class Feed(models.Model):
    """Each Feed has a code name that can be used to reconstruct information about the feed."""
    feedname = models.CharField(max_length=64, unique=True, db_index=True)
    
    def __unicode__(self):
        return self.feedname
        
    def tracked_in_lists_with_email(self):
        return self.tracked_in_lists.filter(email__gt=0)

    @staticmethod
    def from_name(feedname, must_exist=True):
        if not must_exist:
            # Return fast.
            return Feed(feedname=feedname)
                
        try:
            return Feed.objects.get(feedname=feedname)
        except Feed.DoesNotExist:
            # Certain feeds aren't in the db. Try a db lookup first, then...
            for feedname2, feedmeta in Feed.feed_metadata.items():
                if feedname.startswith(feedname2) and feedmeta.get("meta", False):
                    return Feed(feedname=feedname)
            raise

    @staticmethod
    def get_events_for(feeds, count):
        # This method returns the most recent events matching a set of feeds,
        # or all events if feeds is None. Feeds is an iterable of Feed objects
        # or str's of Feed feednames, which must exist.
        
        source_feed_map = { }
        if feeds != None:
            feeds, source_feed_map = expand_feeds(feeds)
            feeds = [f for f in feeds if f.id] # filter out only feeds that are in the database
            if len(feeds) == 0:
                return []
        
        from django.db import connection, transaction
        cursor = connection.cursor()

        # Our table has multiple entries for each event, one entry for each feed it is a
        # part of. Thus, if we query on no feeds or on multiple feeds, we have to make
        # the results distinct. The Django ORM can't handle generating a nice query for this:
        # It adds joins that ruin indexing. So we handle this by querying in batches until
        # we get 'count' distinct events.
        #
        # Additionally, MySQL doesnt do indexing well if we query on multiple feeds at once.
        # In that case, we take a different code path and find 'count' events from each feed,
        # then put them together, sort, distinct, and take the most recent 'count' items.

        if feeds == None:
            # pull events in batches, eliminating duplicate results (events in multiple feeds),
            # which is done faster here than in MySQL.
            start = 0
            size = count * 2
            ret = []
            seen = set()
            while len(ret) < count:
                cursor.execute("SELECT source_content_type_id, source_object_id, eventid, `when` FROM events_event ORDER BY `when` DESC, source_content_type_id DESC, source_object_id DESC, seq DESC LIMIT %s OFFSET %s ", [size, start])
                
                batch = cursor.fetchall()
                for b in batch:
                    if not b in seen:
                        ret.append( { "source_content_type": b[0], "source_object_id": b[1], "eventid": b[2], "when": b[3] } )
                        seen.add(b)
                if len(batch) < size: break # no more items
                start += size
                size *= 2
            
            return ret
        
        else:
            # pull events by feed. When we query on the 'seq' column, MySQL uses the when-based
            # index rather than the feed-based index, which causes a big problem if there are
            # no recent events.
            ret = []
            seen = { }
            for feed in feeds:
                cursor.execute("SELECT source_content_type_id, source_object_id, eventid, `when`, seq FROM events_event WHERE feed_id = %s ORDER BY `when` DESC, source_content_type_id DESC, source_object_id DESC LIMIT %s", [feed.id, count])
                
                batch = cursor.fetchall()
                for b in batch:
                    key = tuple(b[0:3]) # the unique part for identifying the event
                    if not key in seen:
                        v = { "source_content_type": b[0], "source_object_id": b[1], "eventid": b[2], "when": b[3], "seq": b[4], "feeds": set() }
                        ret.append(v)
                        seen[key] = v
                    seen[key]["feeds"].add(source_feed_map.get(feed, feed))
                        
            ret.sort(key = lambda x : (x["when"], x["source_content_type"], x["source_object_id"], x["seq"]), reverse=True)
            
            return ret[0:count]
        
    def get_events(self, count):
        return Feed.get_events_for((self,), count)

    def get_five_events(self):
        return self.get_events(5)
    def get_ten_events(self):
        return self.get_events(10)

    @staticmethod
    def get_trending_feeds():
        def get_feed_counts(num_days):
            # Get the number of new subscriptions to all feeds in the last some days.
            # We don't have a model for the relationship, but we have a table that
            # adds date_added automatically as a timestamp. If we add a 'through'
            # model, we have to replace .add/.remove on the field with other methods.
            try:
                from django.db import connection
                cursor = connection.cursor()
                cursor.execute("SELECT feed_id, count(*) FROM events_subscriptionlist_trackers WHERE date_added > %s GROUP BY feed_id", [datetime.now() - timedelta(days=num_days)])
                subs = cursor.fetchall()
                return { row[0]: row[1] for row in subs } 
            except DatabaseError as e:
                # The database table hasn't been configured with the date_added column,
                # which is hidden from the Django ORM at the moment.
                print "Database isn't configured with date_added column in events_subscriptionlist_trackers."
                return None
                
        trending = []
        for period in (2, 7, 14):
            # Get the number of times each feed was subscribed to in the last period and 2*period days.
            subs1 = get_feed_counts(period)
            subs2 = get_feed_counts(period*2)
            if subs1 == None or subs2 == None: return [] # database not configured
            
            # Order the mentioned feeds by the ratio of recent subscriptions to less recent subscriptions,
            # but giving a boost for the total number of new subscriptions.
            mv = float(max(subs1.values()))
            feeds = sorted(subs1.keys(), key = lambda f : subs1[f]/subs2.get(f, 1) + 2*(subs1[f]/mv)**.5, reverse=True)
            
            # Take the top trending bill not seen in a previous period.
            for f in feeds:
                if f not in trending:
                    trending.append(f)
                    break
        return trending

    # feed metadata
    feed_metadata = { }
    
    @staticmethod
    def register_feed(prefix, **metadata):
        """Registers a feed with the events module. Keyword arguments must include:
        
              title = string or function (taking the feed object as an argument)
              
          And may include:
          
              noun = string
                       The type of object this feed is about, e.g. "person"
              
              link = string or function (taking the feed object as an argument)
                     If slug is set, then the link is generated automatically.
                     If neither link nor slug is set, then this feed has no link.
                     
              slug = string
                     Used for feeds with no internal parameters that have a dedicated
                     page generated by this module at /events/{slug}.
              
              simple = True
                       Whether this feed's name is exactly the prefix as given (i.e.
                       it has no internal arguments) and should be included in any
                       list of suggested simple trackers.
                       
               includes = function
                        A function from the feed object to an iterable of Feed objects
                        that should also be queried for the events in this feed instead.
                       
               meta = True
                       Set to True if no events are stored in the database for this
                       feeed. It may have an 'includes' to slurp in other feeeds.
                       
               single_event_type = True
                        Set to True if the feed only has events of a single type.
        """
        Feed.feed_metadata[prefix] = metadata
     
        
    def type_metadata(self):
        if self.feedname in Feed.feed_metadata:
            return Feed.feed_metadata[self.feedname]
        if ":" in self.feedname:
            t = self.feedname.split(":")[0]
            if t+":" in Feed.feed_metadata:
                return Feed.feed_metadata[t+":"]
        return None
        
    # constructors for feeds

    @staticmethod # private method
    def get_noarg_feed(feedname):
        feed, is_new = Feed.objects.get_or_create(feedname=feedname)
        return feed

    # iterator methods
    
    @staticmethod
    def get_simple_feeds():
        ret = []
        for fname, fmeta in Feed.feed_metadata.items():
            if fmeta.get("simple", False) == True:
                ret.append((fmeta.get("sort_order", 99999), Feed.objects.get_or_create(feedname=fname)[0]))
        ret.sort(key = lambda x : x[0])
        return [r[1] for r in ret]
    
    # accessor methods
    
    @property
    def isvalid(self):
        m = self.type_metadata()
        if m == None: return False
        if "is_valid" not in m: return True
        return m["is_valid"](self)
    
    @property
    def title(self):
        m = self.type_metadata()
        if "title" not in m: return unicode(self)
        if callable(m["title"]):
            return m["title"](self)
        return m["title"]
        
    @property
    def scoped_title(self):
        m = self.type_metadata()
        if "scoped_title" not in m: return self.title
        if callable(m["scoped_title"]):
            return m["scoped_title"](self)
        return m["scoped_title"]
        
    @property
    def link(self):
        m = self.type_metadata()
        if "slug" in m: return "/events/" + m["slug"]
        if "link" not in m: return None
        if not callable(m["link"]): return m["link"]
        return m["link"](self)
        
    @property
    def view_url(self):
        return "/events?feeds=" + urllib.quote(self.feedname)
    
    @property
    def rss_url(self):
        return "/events/events.rss?feeds=" + urllib.quote(self.feedname)

    def includes_feeds(self):
        m = self.type_metadata()
        if "includes" not in m: return []
        if callable(m["includes"]):
            return m["includes"](self)
        return m["includes"]

    def includes_feeds_and_self(self):
        return [self] + self.includes_feeds()
        
    @property
    def single_event_type(self):
        m = self.type_metadata()
        return m.get("single_event_type", False)

    @property
    def category(self):
        m = self.type_metadata()
        return m.get("category", None)
    @property
    def description(self):
        m = self.type_metadata()
        return m.get("description", None)

class Event(models.Model):
    """
    Holds info about an event in a feed. This record doesn't contain any information about
    the event itself except the date of the event so that records can be efficiently queried by date.
    
    The primary key is used as a monotonically increasing sequence number for all records so that
    we can reliably track which events a user has been notified about by tracking the highest
    primary key the user has seen.
    
    Events are created by source objects. A Vote, for instance, creates an Event record
    for itself, actually multiple Event records one for each feed the event goes into: the
    all votes feed and the votes feeds for each Member of Congress that voted. The Event
    refers back to the Vote via the source generic relationship. Information about the event
    so that it can be displayed is obtained by calling Event.render(), which in turn queries
    the source object for information about the vote.
    
    The source object must have a method render_event(eventid, feeds) which returns
    a dict containing the keys:
        type: a string describing the type of the event, for display purposes
        date: a datetime that the event took place (same as Event.when)
        title: a string
        url: a string giving a link URL for the event, starting with the URL's path (i.e. omit scheme & host)
        body_text_template: a Django template used to render the event for text-only presentation (use "|safe" to prevent autoescaping)
        body_html_template: a Django template used to render the event in HTML
        context: a dict passed as the template context when rendering either of the body templates
    And optionally:
        date_has_no_time: set to True to indicate the date on this event has no time associated with it
        
    Some source objects generate multiple events. In this case, it uses the eventid CharField
    to track which event is which. It can put anything in the CharField up to 32 characters.
    For instance, Committee instances generate events for each CommitteeMeeting and code
    each as mtg_ID where ID is the CommitteeMeeting primary key. When its render_event
    is called, it is passed back the eventid so it knows what event it is rendering.
    
    Since some events are only tied to a date, without a time, yet they may have an order, the seq
    field records the order of related events from a single source. The seq field must be constant
    across event instances in the table in multiple fields, otherwise we have a problem using DISTINCT.
    
    To create events, do something like the following, which begins the update process for
    the source object (self) and adds a single event to multiple feeds. Note that Event.update() will
    clear out any previously created events for the source object if they are not re-added here.
        from events.models import Event
        with Event.update(self) as E:
            E.add("eventcode", self.created, feedinstance1)
            E.add("eventcode", self.created, feedinstance2)
                
    Event.render is optionally passed a keyword argument feeds which is a sequence of
    feed.Feed objects that allow the event's template to be customized depending on which
    feed(s) the event is in.
    """
    
    feed = models.ForeignKey(Feed)

    source_content_type = models.ForeignKey(ContentType)
    source_object_id = models.PositiveIntegerField()
    source = generic.GenericForeignKey('source_content_type', 'source_object_id')
    eventid = models.CharField(max_length=32) # unique w.r.t. the source object 

    when = models.DateTimeField(db_index=True)
    seq = models.IntegerField()
    
    @staticmethod
    def sourcearg(source):
        return {
            "source_content_type": ContentType.objects.get_for_model(source),
            "source_object_id": source.id,
            }

    class Meta:
        ordering = ['-id']
        unique_together = (
             ('source_content_type', 'source_object_id', 'eventid', 'feed'),
             ('feed', 'id'),
             ('feed', 'when', 'source_content_type', 'source_object_id', 'eventid'),
             ('when', 'source_content_type', 'source_object_id', 'seq', 'feed'))
    
    def __unicode__(self):
        return unicode(self.source) + " " + unicode(self.eventid) + " / " + unicode(self.feed)
        
    def render(self, feeds=None):
        return self.source.render_event(self.eventid, feeds)
    
    # This is used to update the events for an object and delete any events that are not updated.
    class update:
        def __init__(self, source):
            self.source = source
            
            # get a list of events previously created for this source so that if they
            # are not updated we can delete them
            self.existing_events = {}
            for event in Event.objects.filter(**Event.sourcearg(source)):
                self.existing_events[event.id] = True
            self.seq = { }

        def __enter__(self):
            return self
            
        def add(self, eventid, when, feed):
            # If feed is a list or tuple, then call this on each item in the list/tuple.
            if isinstance(feed, list) or isinstance(feed, tuple):
                for f in feed:
                    self.add(eventid, when, f)
                return
                
            # Track the sequence number for this eventid, increment in insertion order.
            if not eventid in self.seq: self.seq[eventid] = len(self.seq)
            
            # Create the record for this event for this feed, if it does not exist.
            event, created = Event.objects.get_or_create(
                feed = feed,
                eventid = eventid,
                defaults = {"when": when, "seq": self.seq[eventid]},
                **Event.sourcearg(self.source)
                )
            #print ("[%s] %s event record: %s | %s | %s" % (unicode(self.source)[0:15], "New" if created else "Existing", feed.feedname, repr(self.source), eventid)).encode("utf8")
            if not created and event.id in self.existing_events:
                del self.existing_events[event.id] # i.e. don't delete this event on __exit__
                if event.when != when: # update this if it changed
                    event.when = when
                    event.save()
            
        def __exit__(self, type, value, traceback):
            # Clear out any events that were not updated.
            Event.objects.filter(id__in=self.existing_events).delete()
            return False

class SubscriptionList(models.Model):
    # see send_email_updates.py
    EMAIL_CHOICES = [(0, 'No Email Updates'), (1, 'Daily'), (2, 'Weekly')]
    
    user = models.ForeignKey(User, db_index=True, related_name="subscription_lists")
    name = models.CharField(max_length=64)
    trackers = models.ManyToManyField(Feed, related_name="tracked_in_lists")
    is_default = models.BooleanField(default=False)
    email = models.IntegerField(default=0, choices=EMAIL_CHOICES)
    last_event_mailed = models.IntegerField(blank=True, null=True) # id of last event
    last_email_sent = models.DateTimeField(blank=True, null=True) # date of last email update sent
    public_id = models.CharField(max_length=16, blank=True, null=True, db_index=True)
    
    class Meta:
        unique_together = [('user', 'name')]
        
    @staticmethod
    def create(user, email_rate=None):
        sublist = None
        ctr = 1
        base_name = "My List"
        if email_rate == 1: base_name = "Daily Updates"
        if email_rate == 2: base_name = "Weekly Updates"
        while not sublist and ctr < 1000:
            try:
                sublist = SubscriptionList.objects.create(user=user, name=base_name + (" " + str(ctr) if ctr > 1 else ""))
            except:
                ctr += 1
        if email_rate != None:
            sublist.email = email_rate
        return sublist

    @staticmethod
    def get_for_email_rate(user, email_rate):
        try:
            sublist = SubscriptionList.objects.get(user=user, is_default=True)
            if sublist.email == email_rate:
                return sublist
                
            if sublist.trackers.count() == 0:
                # The default list has a different email rate set, but it's
                # empty so just revise it.
                sublist.email = email_rate
                sublist.save()

                # Also try to rename it, but be careful of the uniqueness
                # constraint on the name.
                try:
                    if sublist.email == 0:
                        sublist.name = "My List"
                    elif sublist.email == 1:
                        sublist.name = "Daily Email Updates"
                    elif sublist.email == 2:
                        sublist.name = "Weekly Email Updates"
                    sublist.save()
                except:
                    pass # uniqueness constraint on name violated, doesn't matter
                return sublist
            else:
                # The default list has something in it at a different email rate,
                # so fall back.
                raise SubscriptionList.DoesNotExist()                    
        except SubscriptionList.DoesNotExist:
            try:
                # If there is a single list with the desired email rate, use that list.
                return SubscriptionList.objects.get(user=user, email=email_rate)
            except SubscriptionList.DoesNotExist:
                # There is no list with the desired email rate, so create a new list.
                return SubscriptionList.create(user, email_rate=email_rate)

    def get_public_id(self):
        if not self.public_id:
            from random import choice
            import string
            self.public_id = ''.join([choice(string.letters + string.digits) for i in range(16)])
            self.save()
        return self.public_id

    def get_new_events(self):
        feeds, source_feed_map = expand_feeds(self.trackers.all())
        if len(feeds) == 0: return None, []
        
        from django.db import connection, transaction
        cursor = connection.cursor()

        # Temporary workaround. Get the maximum id for the event corresponding to
        # last_event_mailed.
        if self.last_event_mailed:
            try:
                e = Event.objects.get(id=self.last_event_mailed)
                e2 = Event.objects.filter(source_content_type=e.source_content_type, source_object_id=e.source_object_id, eventid=e.eventid).order_by('-id')[0]
                self.last_event_mailed = e2.id
            except Event.DoesNotExist:
                pass # hmm, that is odd
        
        # Pull events that this list has not seen yet according to last_event_mailed,
        # but not going back further than a certain period of time, so that if past
        # events are added we don't overflow the user with new events that are actually
        # archival data. Also, the first email update for a user will go back that time
        # period unless we set last_event_mailed.
        
        # The Django ORM can't handle generating a nice query. It adds joins that ruin indexing.
        cursor.execute("SELECT id, source_content_type_id, source_object_id, eventid, `when`, seq, feed_id FROM events_event WHERE id > %s AND `when` > %s AND feed_id IN (" + ",".join(str(f.id) for f in feeds) + ") ORDER BY `when`, source_content_type_id, source_object_id, seq", [self.last_event_mailed if self.last_event_mailed else 0, datetime.now() - timedelta(days=4 if self.email == 1 else 14)])
        
        max_id = None
        ret = []
        seen = { } # uniqify because events are duped for each feed they are in, but track which feeds generated the events
        feedmap = dict((f.id, source_feed_map.get(f, f)) for f in feeds)
        batch = cursor.fetchall()
        for b in batch:
            key = b[1:3] # get the part that uniquely identifies the event, across feeds
            max_id = max(max_id, b[0]) # since we return one event record randomly out of
                                       # all of the dups for the feeds for all records,
                                       # make sure we return the max of the ids, or else
                                       # we might re-send an event in an email.
            if not key in seen:
                v = { "id": b[0], "source_content_type": b[1], "source_object_id": b[2], "eventid": b[3], "when": b[4], "seq": b[5], "feeds": set() }
                ret.append(v)
                seen[key] = v
            v["feeds"].add(feedmap[b[6]])
                
        ret.sort(key = lambda x : (x["when"], x["source_content_type"], x["source_object_id"], x["seq"]))
    
        return max_id, ret
        
def expand_feeds(feeds):
    # Some feeds include the events of other feeds.
    # Tail-recursively expand the feeds.
    feeds = [f if isinstance(f, Feed) else Feed.objects.get(feedname=f) for f in feeds]
    map_to_source = { }
    i = 0
    while i < len(feeds):
        for f in feeds[i].includes_feeds():
            if f not in feeds: # don't include a feed already included, and don't add a mapping for it in map_to_source
                map_to_source[f] = feeds[i]
                feeds.append(f)
        i += 1
    return feeds, map_to_source

def truncate_words(s, num):
    from django.utils.text import Truncator
    return Truncator(s).words(num, truncate=" ...")
    

########NEW FILE########
__FILENAME__ = events_utils
from django import template
from django.template import Context, Template
from django.template.defaultfilters import stringfilter
from django.conf import settings

import events.models

register = template.Library()

@register.filter
def render_event(event, feed):
    if isinstance(event, dict):
        # values() returns the source_content_type's primary key rather than the object itself 
        from django.contrib.contenttypes.models import ContentType
        if type(event["source_content_type"]) != ContentType:
            event["source_content_type"] = ContentType.objects.get(id=event["source_content_type"])
        if "feeds" in event: # Event constructor can't take this arg
            event = dict(event)
            del event["feeds"]
        event = events.models.Event(**event)
        if not event.source: # database inconsistency
            return None
    
    if isinstance(feed, events.models.Feed):
        feeds = (feed,)
    elif feed == "":
        feeds = None
    else:
        feeds = feed
    meta = event.render(feeds=feeds)
    meta["guid"] = "%s:%d:%s" % (event.source_content_type, event.source_object_id, event.eventid)
    
    c = dict()
    c.update(meta["context"])
    c["SITE_ROOT"] = settings.SITE_ROOT_URL
    
    meta["body_html"] = Template(meta["body_html_template"]).render(Context(c))
    meta["body_text"] = Template(meta["body_text_template"]).render(Context(c))
    
    return meta

@register.filter
@stringfilter
def append_qsarg(value, arg):
    if not arg: return value
    if "?" in value:
        value += "&"
    else:
        value += "?"
    return value + unicode(arg)



########NEW FILE########
__FILENAME__ = urls
# -*- coding: utf-8 -*-
from django.conf.urls import *

urlpatterns = patterns('events.views',
    url(r'^accounts/lists', 'edit_subscription_lists'),
    url(r'^events/_edit', 'edit_subscription_list'),
    url('^events/_load_events$', 'events_list_items', name='events_list_items'),
    url('^events/events.rss$', 'events_rss'),
    url('^events/embed_legacy$', 'events_embed_legacy'),
    url('^events/([\w\-]+)$', 'events_show_feed'),
)


########NEW FILE########
__FILENAME__ = views
# -*- coding: utf-8 -*-
from django.shortcuts import redirect, get_object_or_404
from django.core.urlresolvers import reverse
from django.http import HttpResponse, Http404
from django.contrib.auth.decorators import login_required
from django.core.exceptions import ObjectDoesNotExist
from django.conf import settings

from common.decorators import render_to
from common.pagination import paginate

from datetime import datetime, time

from registration.helpers import json_response

from models import *
from website.models import *
from events.templatetags.events_utils import render_event

def get_feed_list(request):
    if "list_id" in request.GET:
        lst = get_object_or_404(SubscriptionList, public_id=request.GET["list_id"])
        return lst.trackers.all(), lst.user.username + "'s " + lst.name
    else:
        # monitors was the old URL parameter, used by events_embed_legacy
        feedlist = request.GET.get('feeds', request.GET.get('monitors', '')).split(',')
        if feedlist == [""]:
            feedlist = []
            feedtitle = "All Events"
        else:
            feedlist2 = []
            for f in feedlist:
                try:
                    feedlist2.append(Feed.from_name(f))
                except Feed.DoesNotExist:
                    f = Feed(feedname=f)
                    if not f.isvalid: raise Http404("Invalid feed name.")
                    feedlist2.append(f)
            feedlist = feedlist2
            feedtitle = ", ".join(f.title for f in feedlist)
        return feedlist, feedtitle

@login_required
@render_to('events/edit_lists.html')
def edit_subscription_lists(request):
    message = None
    sublist = None
    
    if "add" in request.GET:
        # This is a redirect from the add tracker page.

        # Get the list to add the feed into
        if "emailupdates" in request.GET:
            email_rate = int(request.GET["emailupdates"])
            sublist = SubscriptionList.get_for_email_rate(request.user, email_rate)    
        else:
            sublist = request.user.userprofile().lists().get(id=request.GET["listid"])

        feed = Feed.from_name(request.GET["add"])
        # for 'meta' feeds like bill search, we may get back a feed not in the db
        if not feed.id: feed.save()
        
        if not feed in sublist.trackers.all(): sublist.trackers.add(feed)
        sublist.save()
        
        message = feed.title + " was added to your list " + sublist.name + "."
    
    return {
        'default_list': sublist,
        'message': message,
        'no_arg_feeds': Feed.get_simple_feeds(),
            }
            
@login_required
@json_response
def edit_subscription_list(request):
    if not request.user.is_authenticated():
        return { "error": "not logged in" }
        
    if "email_freq" in request.POST:
        # Use the default list, unless a different email update rate is chosen.
        email_rate = int(request.POST["email_freq"])
        sublist = SubscriptionList.get_for_email_rate(request.user, email_rate)
        
    elif not "listid" in request.POST:
        if request.POST["command"] != "remove-from-all":
            return { "error": "missing parameter" }
    elif request.POST["listid"] != "_new_list":
        sublist = get_object_or_404(SubscriptionList, user=request.user, id=request.POST["listid"])
    else:
        sublist = SubscriptionList.create(request.user)
    
    state = None
    
    if request.POST["command"] in ("toggle", "add", "remove"):
        f = get_object_or_404(Feed, feedname=request.POST["feed"])
        
        if "email_freq" in request.POST:
            # Delete the tracker from all other lists.
            for s in SubscriptionList.objects.filter(user=request.user):
                s.trackers.remove(f)
                if not s.is_default and s.trackers.count() == 0: s.delete()
        
        if (request.POST["command"] == "toggle" and f in sublist.trackers.all()) or request.POST["command"] == "remove":
            sublist.trackers.remove(f)
            state = False
        else:
            try:
                sublist.trackers.add(f)
            except:
                # Ignore any uniqueness constraint violation.
                pass
            state = True
    if request.POST["command"] == "remove-from-all":
        f = get_object_or_404(Feed, feedname=request.POST["feed"])
        for s in SubscriptionList.objects.filter(user=request.user):
            s.trackers.remove(f)
            if not s.is_default and s.trackers.count() == 0: s.delete()
        return { "status": "OK" }
    if request.POST["command"] == "rename":
        sublist.name = request.POST["name"]
        sublist.save()
    if request.POST["command"] == "delete" and not sublist.is_default:
        sublist.delete()
    if request.POST["command"] == "set_email_frequency":
        sublist.email = int(request.POST["value"])
        sublist.save()
    
    return {
        "list_id": sublist.id,
        "list_name": sublist.name,
        "list_public_id": sublist.get_public_id(),
        "list_email": sublist.email,
        "list_email_display": sublist.get_email_display(),
        "list_trackers": [
            { "id": f.id, "name": f.feedname, "title": f.title, "link": f.link }
            for f in sublist.trackers.all() ], "state": state }

@render_to('events/events_list_items.html')
def events_list_items(request):
    if "listid" in request.POST:
        sublist = get_object_or_404(SubscriptionList, user=request.user, id=request.POST["listid"])
        feedlist = sublist.trackers.all()
        show_empty = False
    elif "feed" in request.POST:
        sublist = None
        try:
            feedlist = [Feed.from_name(request.POST["feed"])]
            show_empty = True
        except Feed.DoesNotExist:
            feedlist = []
            show_empty = False
    else:
        raise Http404()
        
    if len(feedlist) > 0 or show_empty:
        qs = Feed.get_events_for(feedlist if len(feedlist) > 0 else None, int(request.POST.get('count', '100'))) # get all events
    else:
        qs = []
    page = paginate(qs, request, per_page=50)
    
    # Based on the last 100 events, how often do we expect to get email updates?
    # Compute this using the median time between events, which should give us an
    # idea of how often the events occur in a way that is robust to a few long
    # periods of no events, e.g. which Congress is out of session.
    expected_frequency = None
    if len(qs) > 15:
        # Get the time between consecutive events, in days.
        seps = []
        for i in xrange(1, len(qs)):
            s = (qs[i-1]["when"]-qs[i]["when"]).total_seconds()
            if s == 0: continue # skip things that happen at exactly the same time,
                                # since they probably don't help us understand frequency
            seps.append( s/float(60*60*24) )
        
        # Find the median.
        if len(seps) == 0:
            # everything occurred at the same moment
            days_between_events = 1000
        else:
            seps.sort()
            days_between_events = seps[len(seps)/2]
        
        if not sublist or sublist.email == 0:
            if days_between_events < 1:
                expected_frequency = "Turn on daily email updates if you would like to get these events sent to you each day."
            elif days_between_events < 7:
                expected_frequency = "Turn on daily or weekly email updates if you would like to get these events mailed to you each day or week."
        elif sublist.email == 1:
            if days_between_events < 1:
                expected_frequency = "You can expect an email update roughly every day Congress is in session."
            elif days_between_events < 4:
                expected_frequency = "You can expect an email update every couple of days."
            elif days_between_events < 6:
                expected_frequency = "You can expect an email update every week."
            else:
                expected_frequency = "You will get email updates when more events in Congress occur matching the items you are tracking."
        elif sublist.email == 2:
            if days_between_events < 6:
                expected_frequency = "You can expect an email update every week."
            elif days_between_events < 20:
                expected_frequency = "You can expect an email update every couple of weeks."
            else:
                expected_frequency = "You will get email updates when more events in Congress occur matching the items you are tracking."

    return {
        'page': page,
        'list': sublist,
        'feeds': feedlist,
        'expected_frequency': expected_frequency,
        'simple_mode': len(feedlist) == 1 and feedlist[0].single_event_type,
            }
            
def events_rss(request):
    import django.contrib.syndication.views
    import urllib

    try:
        feedlist, feedtitle = get_feed_list(request)
    except Exception as e:
        raise Http404(unicode(e))
    feedtitle += " - Tracked Events from GovTrack.us"
    
    class DjangoFeed(django.contrib.syndication.views.Feed):
        title = feedtitle
        link = "/" if len(feedlist) != 1 else feedlist[0].link
        description = "GovTrack tracks the activities of the United States Congress."
        
        def items(self):
            events = [render_event(item, feedlist) for item in Feed.get_events_for(feedlist, 20)]
            return [e for e in events if e != None]
            
        def item_title(self, item):
            return item["title"]
        def item_description(self, item):
            return item["type"] + ": " + item["body_text"]
        def item_link(self, item):
            return settings.SITE_ROOT_URL + item["url"] + settings.RSS_CAMPAIGN_QUERYSTRING
        def item_guid(self, item):
            return self.item_link(item) + "#eventid=" + urllib.quote_plus(item["guid"]) 
        def item_pubdate(self, item):
            return item["date"] if (not item["date"] or isinstance(item["date"], datetime)) else datetime.combine(item["date"], time.min)
            
    return DjangoFeed()(request)
    
@render_to('events/showfeed.html')
def events_show_feed(request, feedslug):
    # Map slug to feed internal name, then Feed object.
    for feedname, feedmeta in Feed.feed_metadata.items():
        if feedmeta.get("slug", "") == feedslug:
            feed = Feed.from_name(feedname)
            break
    else:
        if feedslug == "track-something" and "feed" in request.GET:
            try:
                feed = Feed.from_name(request.GET["feed"])
            except:
                raise Http404()
        else:
            raise Http404()
        
    return {
        "feed": feed,
    }

def events_embed_legacy(request):
    # prepare template context
    try:
        feedlist, feedtitle = get_feed_list(request)
    except ObjectDoesNotExist:
        raise Http404()
    try:
        count = int(request.GET.get('count', ''))
    except ValueError:
        count = 10
    events = Feed.get_events_for(feedlist, count)
    context = { "feeds": feedlist, "events": events, "title": feedtitle,
        "link": feedlist[0].link if len(feedlist) == 1 else None }
        
    # render the HTML
    from django.template import Template, Context, RequestContext, loader
    html = loader.get_template("events/events_embed_legacy.html")\
        .render(RequestContext(request, context))
    
    # convert to Javascript document.write statements.
    from django.utils.html import strip_spaces_between_tags
    from django.template.defaultfilters import escapejs
    html = strip_spaces_between_tags(html)
    js = ""
    while len(html) > 0:
        js += "document.write(\"" + escapejs(html[0:128]) + "\");\n"
        html = html[128:]
    return HttpResponse(js, mimetype="application/x-javascript; charset=UTF-8")
    

########NEW FILE########
__FILENAME__ = apachelog
#!/usr/bin/env python
"""Apache Log Parser

Parser for Apache log files. This is a port to python of Peter Hickman's
Apache::LogEntry Perl module:
<http://cpan.uwinnipeg.ca/~peterhi/Apache-LogRegex>

Takes the Apache logging format defined in your httpd.conf and generates
a regular expression which is used to a line from the log file and
return it as a dictionary with keys corresponding to the fields defined
in the log format.

Example:

    import apachelog, sys

    # Format copied and pasted from Apache conf - use raw string + single quotes
    format = r'%h %l %u %t \"%r\" %>s %b \"%{Referer}i\" \"%{User-Agent}i\"'
    
    p = apachelog.parser(format)

    for line in open('/var/apache/access.log'):
        try:
           data = p.parse(line)
        except:
           sys.stderr.write("Unable to parse %s" % line)

The return dictionary from the parse method depends on the input format.
For the above example, the returned dictionary would look like;

    {
    '%>s': '200',
    '%b': '2607',
    '%h': '212.74.15.68',
    '%l': '-',
    '%r': 'GET /images/previous.png HTTP/1.1',
    '%t': '[23/Jan/2004:11:36:20 +0000]',
    '%u': '-',
    '%{Referer}i': 'http://peterhi.dyndns.org/bandwidth/index.html',
    '%{User-Agent}i': 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.2) Gecko/20021202'
    }

...given an access log entry like (split across lines for formatting);

    212.74.15.68 - - [23/Jan/2004:11:36:20 +0000] "GET /images/previous.png HTTP/1.1"
        200 2607 "http://peterhi.dyndns.org/bandwidth/index.html"
        "Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.2) Gecko/20021202"

You can also re-map the field names by subclassing (or re-pointing) the
alias method.

Generally you should be able to copy and paste the format string from
your Apache configuration, but remember to place it in a raw string
using single-quotes, so that backslashes are handled correctly.

This module provides three of the most common log formats in the
formats dictionary;

    # Common Log Format (CLF)
    p = apachelog.parser(apachlog.formats['common'])

    # Common Log Format with Virtual Host
    p = apachelog.parser(apachlog.formats['vhcommon'])

    # NCSA extended/combined log format
    p = apachelog.parser(apachlog.formats['extended'])

For notes regarding performance while reading lines from a file
in Python, see <http://effbot.org/zone/readline-performance.htm>.
Further performance boost can be gained by using psyco
<http://psyco.sourceforge.net/>

On my system, using a loop like;

    for line in open('access.log'):
        p.parse(line)

...was able to parse ~60,000 lines / second. Adding psyco to the mix,
up that to ~75,000 lines / second.

The parse_date function is intended as a fast way to convert a log
date into something useful, without incurring a significant date
parsing overhead - good enough for basic stuff but will be a problem
if you need to deal with log from multiple servers in different
timezones.
"""

__version__ = "1.1"
__license__ = """Released under the same terms as Perl.
See: http://dev.perl.org/licenses/
"""
__author__ = "Harry Fuecks <hfuecks@gmail.com>"
__contributors__ = [
    "Peter Hickman <peterhi@ntlworld.com>",
    "Loic Dachary <loic@dachary.org>"
    ]
    
import re

class ApacheLogParserError(Exception):
    pass

class parser:
    
    def __init__(self, format):
        """
        Takes the log format from an Apache configuration file.

        Best just copy and paste directly from the .conf file
        and pass using a Python raw string e.g.
        
        format = r'%h %l %u %t \"%r\" %>s %b \"%{Referer}i\" \"%{User-Agent}i\"'
        p = apachelog.parser(format)
        """
        self._names = []
        self._regex = None
        self._pattern = ''
        self._parse_format(format)
    
    def _parse_format(self, format):
        """
        Converts the input format to a regular
        expression, as well as extracting fields

        Raises an exception if it couldn't compile
        the generated regex.
        """
        format = format.strip()
        format = re.sub('[ \t]+',' ',format)
        
        subpatterns = []

        findquotes = re.compile(r'^\\"')
        findreferreragent = re.compile('Referer|User-Agent')
        findpercent = re.compile('^%.*t$')
        lstripquotes = re.compile(r'^\\"')
        rstripquotes = re.compile(r'\\"$')
        self._names = []
        
        for element in format.split(' '):

            hasquotes = 0
            if findquotes.search(element): hasquotes = 1

            if hasquotes:
                element = lstripquotes.sub('', element)
                element = rstripquotes.sub('', element)
            
            self._names.append(self.alias(element))
            
            subpattern = '(\S*)'
            
            if hasquotes:
                if element == '%r' or findreferreragent.search(element):
                    subpattern = r'\"([^"\\]*(?:\\.[^"\\]*)*)\"'
                else:
                    subpattern = r'\"([^\"]*)\"'
                
            elif findpercent.search(element):
                subpattern = r'(\[[^\]]+\])'
                
            elif element == '%U':
                subpattern = '(.+?)'
            
            subpatterns.append(subpattern)
        
        self._pattern = '^' + ' '.join(subpatterns) + '$'
        try:
            self._regex = re.compile(self._pattern)
        except Exception, e:
            raise ApacheLogParserError(e)
        
    def parse(self, line):
        """
        Parses a single line from the log file and returns
        a dictionary of it's contents.

        Raises and exception if it couldn't parse the line
        """
        line = line.strip()
        match = self._regex.match(line)
        
        if match:
            data = {}
            for k, v in zip(self._names, match.groups()):
                data[k] = v
            return data
        
        raise ApacheLogParserError("Unable to parse: %s with the %s regular expression" % ( line, self._pattern ) )

    def alias(self, name):
        """
        Override / replace this method if you want to map format
        field names to something else. This method is called
        when the parser is constructed, not when actually parsing
        a log file
        
        Takes and returns a string fieldname
        """
        return name

    def pattern(self):
        """
        Returns the compound regular expression the parser extracted
        from the input format (a string)
        """
        return self._pattern

    def names(self):
        """
        Returns the field names the parser extracted from the
        input format (a list)
        """
        return self._names

months = {
    'Jan':'01',
    'Feb':'02',
    'Mar':'03',
    'Apr':'04',
    'May':'05',
    'Jun':'06',
    'Jul':'07',
    'Aug':'08',
    'Sep':'09',
    'Oct':'10',
    'Nov':'11',
    'Dec':'12'
    }

def parse_date(date):
    """
    Takes a date in the format: [05/Dec/2006:10:51:44 +0000]
    (including square brackets) and returns a two element
    tuple containing first a timestamp of the form
    YYYYMMDDHH24IISS e.g. 20061205105144 and second the
    timezone offset as is e.g.;

    parse_date('[05/Dec/2006:10:51:44 +0000]')  
    >> ('20061205105144', '+0000')

    It does not attempt to adjust the timestamp according
    to the timezone - this is your problem.
    """
    date = date[1:-1]
    elems = [
        date[7:11],
        months[date[3:6]],
        date[0:2],
        date[12:14],
        date[15:17],
        date[18:20],
        ]
    return (''.join(elems),date[21:])


"""
Frequenty used log formats stored here
"""
formats = {
    # Common Log Format (CLF)
    'common':r'%h %l %u %t \"%r\" %>s %b',

    # Common Log Format with Virtual Host
    'vhcommon':r'%v %h %l %u %t \"%r\" %>s %b',

    # NCSA extended/combined log format
    'extended':r'%h %l %u %t \"%r\" %>s %b \"%{Referer}i\" \"%{User-agent}i\"',
    }

if __name__ == '__main__':
    import unittest

    class TestApacheLogParser(unittest.TestCase):

        def setUp(self):
            self.format = r'%h %l %u %t \"%r\" %>s '\
                          r'%b \"%{Referer}i\" \"%{User-Agent}i\"'
            self.fields = '%h %l %u %t %r %>s %b %{Referer}i '\
                          '%{User-Agent}i'.split(' ')
            self.pattern = '^(\\S*) (\\S*) (\\S*) (\\[[^\\]]+\\]) '\
                           '\\\"([^"\\\\]*(?:\\\\.[^"\\\\]*)*)\\\" '\
                           '(\\S*) (\\S*) \\\"([^"\\\\]*(?:\\\\.[^"\\\\]*)*)\\\" '\
                           '\\\"([^"\\\\]*(?:\\\\.[^"\\\\]*)*)\\\"$'
            self.line1  = r'212.74.15.68 - - [23/Jan/2004:11:36:20 +0000] '\
                          r'"GET /images/previous.png HTTP/1.1" 200 2607 '\
                          r'"http://peterhi.dyndns.org/bandwidth/index.html" '\
                          r'"Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.2) '\
                          r'Gecko/20021202"'
            self.line2  = r'212.74.15.68 - - [23/Jan/2004:11:36:20 +0000] '\
                          r'"GET /images/previous.png=\" HTTP/1.1" 200 2607 '\
                          r'"http://peterhi.dyndns.org/bandwidth/index.html" '\
                          r'"Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.2) '\
                          r'Gecko/20021202"'
            self.line3  = r'4.224.234.46 - - [20/Jul/2004:13:18:55 -0700] '\
                          r'"GET /core/listing/pl_boat_detail.jsp?&units=Feet&checked'\
                          r'_boats=1176818&slim=broker&&hosturl=giffordmarine&&ywo='\
                          r'giffordmarine& HTTP/1.1" 200 2888 "http://search.yahoo.com/'\
                          r'bin/search?p=\"grady%20white%20306%20bimini\"" '\
                          r'"Mozilla/4.0 (compatible; MSIE 6.0; Windows 98; '\
                          r'YPC 3.0.3; yplus 4.0.00d)"'
            self.p = parser(self.format)

        def testpattern(self):
            self.assertEqual(self.pattern, self.p.pattern())

        def testnames(self):
            self.assertEqual(self.fields, self.p.names())

        def testline1(self):
            data = self.p.parse(self.line1)
            self.assertEqual(data['%h'], '212.74.15.68', msg = 'Line 1 %h')
            self.assertEqual(data['%l'], '-', msg = 'Line 1 %l')
            self.assertEqual(data['%u'], '-', msg = 'Line 1 %u')
            self.assertEqual(data['%t'], '[23/Jan/2004:11:36:20 +0000]', msg = 'Line 1 %t')
            self.assertEqual(
                data['%r'],
                'GET /images/previous.png HTTP/1.1',
                msg = 'Line 1 %r'
                )
            self.assertEqual(data['%>s'], '200', msg = 'Line 1 %>s')
            self.assertEqual(data['%b'], '2607', msg = 'Line 1 %b')
            self.assertEqual(
                data['%{Referer}i'],
                'http://peterhi.dyndns.org/bandwidth/index.html',
                msg = 'Line 1 %{Referer}i'
                )
            self.assertEqual(
                data['%{User-Agent}i'],
                'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.2) Gecko/20021202',
                msg = 'Line 1 %{User-Agent}i'
                )

        
        def testline2(self):
            data = self.p.parse(self.line2)
            self.assertEqual(data['%h'], '212.74.15.68', msg = 'Line 2 %h')
            self.assertEqual(data['%l'], '-', msg = 'Line 2 %l')
            self.assertEqual(data['%u'], '-', msg = 'Line 2 %u')
            self.assertEqual(
                data['%t'],
                '[23/Jan/2004:11:36:20 +0000]',
                msg = 'Line 2 %t'
                )
            self.assertEqual(
                data['%r'],
                r'GET /images/previous.png=\" HTTP/1.1',
                msg = 'Line 2 %r'
                )
            self.assertEqual(data['%>s'], '200', msg = 'Line 2 %>s')
            self.assertEqual(data['%b'], '2607', msg = 'Line 2 %b')
            self.assertEqual(
                data['%{Referer}i'],
                'http://peterhi.dyndns.org/bandwidth/index.html',
                msg = 'Line 2 %{Referer}i'
                )
            self.assertEqual(
                data['%{User-Agent}i'],
                'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.2) Gecko/20021202',
                msg = 'Line 2 %{User-Agent}i'
                )

        def testline3(self):
            data = self.p.parse(self.line3)
            self.assertEqual(data['%h'], '4.224.234.46', msg = 'Line 3 %h')
            self.assertEqual(data['%l'], '-', msg = 'Line 3 %l')
            self.assertEqual(data['%u'], '-', msg = 'Line 3 %u')
            self.assertEqual(
                data['%t'],
                '[20/Jul/2004:13:18:55 -0700]',
                msg = 'Line 3 %t'
                )
            self.assertEqual(
                data['%r'],
                r'GET /core/listing/pl_boat_detail.jsp?&units=Feet&checked_boats='\
                r'1176818&slim=broker&&hosturl=giffordmarine&&ywo=giffordmarine& '\
                r'HTTP/1.1',
                msg = 'Line 3 %r'
                )
            self.assertEqual(data['%>s'], '200', msg = 'Line 3 %>s')
            self.assertEqual(data['%b'], '2888', msg = 'Line 3 %b')
            self.assertEqual(
                data['%{Referer}i'],
                r'http://search.yahoo.com/bin/search?p=\"grady%20white%20306'\
                r'%20bimini\"',
                msg = 'Line 3 %{Referer}i'
                )
            self.assertEqual(
                data['%{User-Agent}i'],
                'Mozilla/4.0 (compatible; MSIE 6.0; Windows 98; YPC 3.0.3; '\
                'yplus 4.0.00d)',
                msg = 'Line 3 %{User-Agent}i'
                )


        def testjunkline(self):
            self.assertRaises(ApacheLogParserError,self.p.parse,'foobar')

        def testhasquotesaltn(self):
            p = parser(r'%a \"%b\" %c')
            line = r'foo "xyz" bar'
            data = p.parse(line)
            self.assertEqual(data['%a'],'foo', '%a')
            self.assertEqual(data['%b'],'xyz', '%c')
            self.assertEqual(data['%c'],'bar', '%c')

        def testparsedate(self):
            date = '[05/Dec/2006:10:51:44 +0000]'
            self.assertEqual(('20061205105144','+0000'),parse_date(date))

    unittest.main()

########NEW FILE########
__FILENAME__ = dbfUtils
#!/usr/bin/env python

# dbfUtils.py
# By Raymond Hettinger
# http://aspn.activestate.com/ASPN/Cookbook/Python/Recipe/362715

import struct, datetime, decimal, itertools

def dbfreader(f):
	"""Returns an iterator over records in a Xbase DBF file.

	The first row returned contains the field names.
	The second row contains field specs: (type, size, decimal places).
	Subsequent rows contain the data records.
	If a record is marked as deleted, it is skipped.

	File should be opened for binary reads.

	"""
	# See DBF format spec at:
	#     http://www.pgts.com.au/download/public/xbase.htm#DBF_STRUCT

	numrec, lenheader = struct.unpack('<xxxxLH22x', f.read(32))    
	numfields = (lenheader - 33) // 32

	fields = []
	for fieldno in xrange(numfields):
		name, typ, size, deci = struct.unpack('<11sc4xBB14x', f.read(32))
		name = name.replace('\0', '')       # eliminate NULs from string   
		fields.append((name, typ, size, deci))
	yield [field[0] for field in fields]
	yield [tuple(field[1:]) for field in fields]

	terminator = f.read(1)
	assert terminator == '\r'

	fields.insert(0, ('DeletionFlag', 'C', 1, 0))
	fmt = ''.join(['%ds' % fieldinfo[2] for fieldinfo in fields])
	fmtsiz = struct.calcsize(fmt)
	for i in xrange(numrec):
		record = struct.unpack(fmt, f.read(fmtsiz))
		if record[0] != ' ':
			continue                        # deleted record
		result = []
		for (name, typ, size, deci), value in itertools.izip(fields, record):
			if name == 'DeletionFlag':
				continue
			if typ == "N":
				value = value.replace('\0', '').lstrip()
				if value == '':
					value = 0
				elif deci:
					value = decimal.Decimal(value)
				else:
					value = int(value)
			elif typ == 'D':
				y, m, d = int(value[:4]), int(value[4:6]), int(value[6:8])
				value = datetime.date(y, m, d)
			elif typ == 'L':
				value = (value in 'YyTt' and 'T') or (value in 'NnFf' and 'F') or '?'
			result.append(value)
		yield result


def dbfwriter(f, fieldnames, fieldspecs, records):
	""" Return a string suitable for writing directly to a binary dbf file.

	File f should be open for writing in a binary mode.

	Fieldnames should be no longer than ten characters and not include \x00.
	Fieldspecs are in the form (type, size, deci) where
		type is one of:
			C for ascii character data
			M for ascii character memo data (real memo fields not supported)
			D for datetime objects
			N for ints or decimal objects
			L for logical values 'T', 'F', or '?'
		size is the field width
		deci is the number of decimal places in the provided decimal object
	Records can be an iterable over the records (sequences of field values).
	
	"""
	# header info
	ver = 3
	now = datetime.datetime.now()
	yr, mon, day = now.year-1900, now.month, now.day
	numrec = len(records)
	numfields = len(fieldspecs)
	lenheader = numfields * 32 + 33
	lenrecord = sum(field[1] for field in fieldspecs) + 1
	hdr = struct.pack('<BBBBLHH20x', ver, yr, mon, day, numrec, lenheader, lenrecord)
	f.write(hdr)
					  
	# field specs
	for name, (typ, size, deci) in itertools.izip(fieldnames, fieldspecs):
		name = name.ljust(11, '\x00')
		fld = struct.pack('<11sc4xBB14x', name, typ, size, deci)
		f.write(fld)

	# terminator
	f.write('\r')

	# records
	for record in records:
		f.write(' ')                        # deletion flag
		for (typ, size, deci), value in itertools.izip(fieldspecs, record):
			if typ == "N":
				value = str(value).rjust(size, ' ')
			elif typ == 'D':
				value = value.strftime('%Y%m%d')
			elif typ == 'L':
				value = str(value)[0].upper()
			else:
				value = str(value)[:size].ljust(size, ' ')
			assert len(value) == size
			f.write(value)

	# End of file
	f.write('\x1A')

########NEW FILE########
__FILENAME__ = logistic_regression
"""
 Python module for computing Logistic Regression.
 Requires numpy, matplotlib

 Version: 20090622+JT0
 
 Modified by Joshua Tauberer to use numpy.linalg.lstsq rather than inv
 to avoid problems with singular matrices, and use vstack rather than
 assignment to an array slice for clarity.

 Contact:  Jeffrey Whitaker <jeffrey.s.whitaker@noaa.gov>

 copyright (c) by Jeffrey Whitaker.
 
 Permission to use, copy, modify, and distribute this software and its
 documentation for any purpose and without fee is hereby granted,
 provided that the above copyright notice appear in all copies and that
 both the copyright notice and this permission notice appear in
 supporting documentation.
 THE AUTHOR DISCLAIMS ALL WARRANTIES WITH REGARD TO THIS SOFTWARE,
 INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS. IN NO
 EVENT SHALL THE AUTHOR BE LIABLE FOR ANY SPECIAL, INDIRECT OR
 CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER RESULTING FROM LOSS OF
 USE, DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR
 OTHER TORTIOUS ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR
 PERFORMANCE OF THIS SOFTWARE.

"""

import numpy as np

def simple_logistic_regression(x,y,beta_start=None,verbose=False,
                               CONV_THRESH=1.e-3,MAXIT=500):
    """
 Uses the Newton-Raphson algorithm to calculate maximum
 likliehood estimates of a simple logistic regression.  

 Faster than logistic_regression when there is only one predictor.

 x - predictor
 y - binary outcomes (len(y) = len(x))
 beta_start - initial beta (default zero)
 if verbose=True, diagnostics printed for each iteration.
 MAXIT - max number of iterations (default 500)
 CONV_THRESH - convergence threshold (sum of absolute differences
  of beta-beta_old)

 returns beta (the logistic regression coefficients, a 2-element vector),
 J_bar (the 2x2 information matrix), and l (the log-likeliehood).
 J_bar can be used to estimate the covariance matrix and the standard
 error beta.
 l can be used for a chi-squared significance test.

 covmat = inverse(J_bar)     --> covariance matrix
 stderr = sqrt(diag(covmat)) --> standard errors for beta
 deviance = -2l              --> scaled deviance statistic
 chi-squared value for -2l is the model chi-squared test.
    """
    if len(x) != len(y):
        raise ValueError, "x and y should be the same length!"
    if beta_start is None:
        beta_start = np.zeros(2,x.dtype)
    iter = 0; diff = 1.; beta = beta_start  # initial values
    if verbose:
        print 'iteration  beta log-likliehood |beta-beta_old|' 
    while iter < MAXIT:
        beta_old = beta 
        p = np.exp(beta[0]+beta[1]*x)/(1.+np.exp(beta[0]+beta[1]*x))
        l = np.sum(y*np.log(p) + (1.-y)*np.log(1.-p)) # log-likliehood
        s = np.array([np.sum(y-p), np.sum((y-p)*x)])  # scoring function
        # information matrix
        J_bar = np.array([[np.sum(p*(1-p)),np.sum(p*(1-p)*x)],
                          [np.sum(p*(1-p)*x),np.sum(p*(1-p)*x*x)]])
        #beta = beta_old + np.dot(np.linalg.inv(J_bar),s)  # new value of beta
        beta = beta_old + np.linalg.lstsq(J_bar, s)[0]  # new value of beta
        # sum of absolute differences
        diff = np.sum(np.fabs(beta-beta_old))
        if verbose:
            print iter+1, beta, l, diff
        if diff <= CONV_THRESH: break
        iter = iter + 1
    return beta, J_bar, l

def logistic_regression(x,y,beta_start=None,verbose=False,CONV_THRESH=1.e-3,
                        MAXIT=500):
    """
 Uses the Newton-Raphson algorithm to calculate maximum
 likliehood estimates of a logistic regression.

 Can handle multivariate case (more than one predictor).

 x - 2-d array of predictors. Number of predictors = x.shape[0]=N
 y - binary outcomes (len(y) = x.shape[1])
 beta_start - initial beta vector (default zeros(N+1,x.dtype)
 if verbose=True, diagnostics printed for each iteration.
 MAXIT - max number of iterations (default 500)
 CONV_THRESH - convergence threshold (sum of absolute differences
  of beta-beta_old)

 returns beta (the logistic regression coefficients, a N+1 element vector),
 J_bar (the (N+1)x(N=1) information matrix), and l (the log-likeliehood).
 J_bar can be used to estimate the covariance matrix and the standard
 error beta.
 l can be used for a chi-squared significance test.

 covmat = inverse(J_bar)     --> covariance matrix
 stderr = sqrt(diag(covmat)) --> standard errors for beta
 deviance = -2l              --> scaled deviance statistic
 chi-squared value for -2l is the model chi-squared test.
    """
    if x.shape[-1] != len(y):
        raise ValueError, "x.shape[-1] and y should be the same length!"
    try:
        N, npreds = x.shape[1], x.shape[0]
    except: # single predictor, use simple logistic regression routine.
        N, npreds = x.shape[-1], 1
        return simple_logistic_regression(x,y,beta_start=beta_start,
               CONV_THRESH=CONV_THRESH,MAXIT=MAXIT,verbose=verbose)
    if beta_start is None:
        beta_start = np.zeros(npreds+1,x.dtype)
    X = np.vstack((np.ones((1,N), x.dtype), x))
    Xt = np.transpose(X)
    iter = 0; diff = 1.; beta = beta_start  # initial values
    if verbose:
        print 'iteration  beta log-likliehood |beta-beta_old|' 
    while iter < MAXIT:
        beta_old = beta 
        ebx = np.exp(np.dot(beta, X))
        p = ebx/(1.+ebx)
        l = np.sum(y*np.log(p) + (1.-y)*np.log(1.-p)) # log-likeliehood
        s = np.dot(X, y-p)                            # scoring function
        J_bar = np.dot(X*np.multiply(p,1.-p),Xt)      # information matrix
        #beta = beta_old + np.dot(np.linalg.inv(J_bar),s) # new value of beta
        beta = beta_old + np.linalg.lstsq(J_bar, s)[0] # new value of beta
        diff = np.sum(np.fabs(beta-beta_old)) # sum of absolute differences
        if verbose:
            print iter+1, beta, l, diff
        if diff <= CONV_THRESH: break
        iter = iter + 1
    if iter == MAXIT and diff > CONV_THRESH: 
        print 'warning: convergence not achieved with threshold of %s in %s iterations' % (CONV_THRESH,MAXIT)
    return beta, J_bar, l

def calcprob(beta, x):
    """
 calculate probabilities (in percent) given beta and x
    """
    try:
        N, npreds = x.shape[1], x.shape[0]
    except: # single predictor, x is a vector, len(beta)=2.
        N, npreds = len(x), 1
	print len(beta), npreds
    if len(beta) != npreds+1:
        raise ValueError,'sizes of beta and x do not match!'
    if npreds==1: # simple logistic regression
        return 100.*np.exp(beta[0]+beta[1]*x)/(1.+np.exp(beta[0]+beta[1]*x))
    X = np.ones((npreds+1,N), x.dtype)
    X[1:, :] = x
    ebx = np.exp(np.dot(beta, X))
    return 100.*ebx/(1.+ebx)

if __name__ == '__main__':
    from numpy.random import multivariate_normal
    # number of realizations.
    nsamps = 100000
    # correlations
    r12 = 0.5 
    r13 = 0.25
    r23 = 0.125 # correlation between predictors.
    # random draws from trivariate normal distribution
    x = multivariate_normal(np.array([0,0,0]),np.array([[1,r12,r13],[r12,1,r23],[r13,r23,1]]), nsamps)
    x2 = multivariate_normal(np.array([0,0,0]),np.array([[1,r12,r13],[r12,1,r23],[r13,r23,1]]), nsamps)
    print
    print 'correlations (r12,r13,r23) = ',r12,r13,r23
    print 'number of realizations = ',nsamps
    # training data.
    truth = x[:,0]
    thresh = 0. # forecast threshold (0 is climatology)
    climprob = np.sum((truth > thresh).astype('f'))/nsamps
    fcst = np.transpose(x[:,1:]) # 2 predictors.
    # independent data for verification.
    truth2 = x2[:,0]
    fcst2 = np.transpose(x2[:,1:])
    # compute logistic regression.
    obs_binary = truth > thresh
    # using only 1st predictor.
    beta,Jbar,llik = logistic_regression(fcst[0,:],obs_binary,verbose=True)
    covmat = np.linalg.inv(Jbar)
    stderr = np.sqrt(np.diag(covmat))
    print 'using only first predictor:'
    print 'beta =' ,beta
    print 'standard error =',stderr
    # forecasts from independent data.
    prob = calcprob(beta, fcst2[0,:])
    # compute Brier Skill Score
    verif = (truth2 > thresh).astype('f')
    bs = np.mean((0.01*prob - verif)**2)
    bsclim = np.mean((climprob - verif)**2)
    bss = 1.-(bs/bsclim)
    print 'Brier Skill Score = ',bss
    # using only 2nd predictor.
    beta,Jbar,llik = logistic_regression(fcst[1,:],obs_binary,verbose=True)
    covmat = np.linalg.inv(Jbar)
    stderr = np.sqrt(np.diag(covmat))
    print 'using only second predictor:'
    print 'beta =' ,beta
    print 'standard error =',stderr
    # forecasts from independent data.
    prob = calcprob(beta, fcst2[1,:])
    # compute Brier Skill Score
    verif = (truth2 > thresh).astype('f')
    bs = np.mean((0.01*prob - verif)**2)
    bsclim = np.mean((climprob - verif)**2)
    bss = 1.-(bs/bsclim)
    print 'Brier Skill Score = ',bss
    # using both predictors.
    beta,Jbar,llik = logistic_regression(fcst,obs_binary,verbose=True)
    covmat = np.linalg.inv(Jbar)
    stderr = np.sqrt(np.diag(covmat))
    print 'using both predictors:'
    print 'beta =' ,beta
    print 'standard error =',stderr
    # forecasts from independent data.
    prob = calcprob(beta, fcst2)
    # compute Brier Skill Score
    verif = (truth2 > thresh).astype('f')
    bs = np.mean((0.01*prob - verif)**2)
    bsclim = np.mean((climprob - verif)**2)
    bss = 1.-(bs/bsclim)
    print 'Brier Skill Score = ',bss
    print """\n
If Brier Skill Scores within +/- 0.01 of 0.16, 0.04 and 0.18 everything OK\n"""
# calculate reliability.
    print 'reliability:'
    totfreq = np.zeros(10,'f')
    obfreq = np.zeros(10,'f')
    for icat in range(10):
        prob1 = icat*10.
        prob2 = (icat+1)*10.
        test1 = prob > prob1
        test2 = prob <= prob2
        testf = 1.0*test1*test2
        testfv = verif*testf 
        totfreq[icat] = np.sum(testf)
        obfreq[icat] = np.sum(testfv)
    fcstprob = np.zeros(10,'f')
    reliability = np.zeros(10,'f')
    frequse = np.zeros(10,'f')
    totsum = nsamps
    print 'fcst prob, obs frequency, frequency of use'
    for icat in range(10):
        prob1 = icat*10.
        prob2 = (icat+1)*10.
        fcstprob[icat] = 0.5*(prob1+prob2)
        reliability[icat] = 100.*obfreq[icat]/totfreq[icat]
        frequse[icat] = 100.*totfreq[icat]/totsum
        print fcstprob[icat],reliability[icat],frequse[icat]
    # make a reliability diagram
    print 'plotting reliability diagram...'
    import matplotlib.pyplot as plt
    fig=plt.figure(figsize=(8,7))
    ax = fig.add_axes([0.1,0.1,0.8,0.8])
    plt.plot(fcstprob,reliability,'bo-')
    plt.plot(np.arange(0,110,10),np.arange(0,110,10),'r--')
    plt.xlabel('forecast probability')
    plt.ylabel('observed frequency')
    plt.title('Reliability Diagram')
    plt.text(75,15,'BSS = %4.2f' % bss,fontsize=14)
    ax = plt.axes([.25, .6, .2, .2], axisbg='y')
    plt.bar(10*np.arange(10), frequse, width=10)
    plt.xlabel('forecast probability')
    plt.ylabel('percent issued')
    plt.title('Frequency of Use')
    plt.show()

########NEW FILE########
__FILENAME__ = xapian_backend
# Copyright (C) 2009, 2010, 2011, 2012 David Sauve
# Copyright (C) 2009, 2010 Trapeze

__author__ = 'David Sauve'
__version__ = (2, 0, 0, 'beta')

import time
import datetime
import cPickle as pickle
import os
import re
import shutil
import sys

from django.conf import settings
from django.core.exceptions import ImproperlyConfigured
from django.utils.encoding import force_unicode

from haystack import connections
from haystack.backends import BaseEngine, BaseSearchBackend, BaseSearchQuery, SearchNode, log_query
from haystack.constants import ID
from haystack.exceptions import HaystackError, MissingDependency
from haystack.models import SearchResult
from haystack.utils import get_identifier

try:
    import xapian
except ImportError:
    raise MissingDependency("The 'xapian' backend requires the installation of 'xapian'. Please refer to the documentation.")


DOCUMENT_ID_TERM_PREFIX = 'Q'
DOCUMENT_CUSTOM_TERM_PREFIX = 'X'
DOCUMENT_CT_TERM_PREFIX = DOCUMENT_CUSTOM_TERM_PREFIX + 'CONTENTTYPE'

MEMORY_DB_NAME = ':memory:'

DEFAULT_XAPIAN_FLAGS = (
    xapian.QueryParser.FLAG_PHRASE |
    xapian.QueryParser.FLAG_BOOLEAN |
    xapian.QueryParser.FLAG_LOVEHATE |
    xapian.QueryParser.FLAG_WILDCARD |
    xapian.QueryParser.FLAG_PURE_NOT
)


class InvalidIndexError(HaystackError):
    """Raised when an index can not be opened."""
    pass


class XHValueRangeProcessor(xapian.ValueRangeProcessor):
    def __init__(self, backend):
        # FIXME: This needs to get smarter about pulling the right backend.
        self.backend = backend or XapianSearchBackend()
        xapian.ValueRangeProcessor.__init__(self)

    def __call__(self, begin, end):
        """
        Construct a tuple for value range processing.
        `begin` -- a string in the format '<field_name>:[low_range]'
        If 'low_range' is omitted, assume the smallest possible value.
        `end` -- a string in the the format '[high_range|*]'. If '*', assume
        the highest possible value.
        Return a tuple of three strings: (column, low, high)
        """
        colon = begin.find(':')
        field_name = begin[:colon]
        begin = begin[colon + 1:len(begin)]
        for field_dict in self.backend.schema:
            if field_dict['field_name'] == field_name:
                if not begin:
                    if field_dict['type'] == 'text':
                        begin = u'a'  # TODO: A better way of getting a min text value?
                    elif field_dict['type'] == 'long':
                        begin = -sys.maxint - 1
                    elif field_dict['type'] == 'float':
                        begin = float('-inf')
                    elif field_dict['type'] == 'date' or field_dict['type'] == 'datetime':
                        begin = u'00010101000000'
                elif end == '*':
                    if field_dict['type'] == 'text':
                        end = u'z' * 100  # TODO: A better way of getting a max text value?
                    elif field_dict['type'] == 'long':
                        end = sys.maxint
                    elif field_dict['type'] == 'float':
                        end = float('inf')
                    elif field_dict['type'] == 'date' or field_dict['type'] == 'datetime':
                        end = u'99990101000000'
                if field_dict['type'] == 'float':
                    begin = _marshal_value(float(begin))
                    end = _marshal_value(float(end))
                elif field_dict['type'] == 'long':
                    begin = _marshal_value(long(begin))
                    end = _marshal_value(long(end))
                return field_dict['column'], str(begin), str(end)


class XHExpandDecider(xapian.ExpandDecider):
    def __call__(self, term):
        """
        Return True if the term should be used for expanding the search
        query, False otherwise.

        Currently, we only want to ignore terms beginning with `DOCUMENT_CT_TERM_PREFIX`
        """
        if term.startswith(DOCUMENT_CT_TERM_PREFIX):
            return False
        return True


class XapianSearchBackend(BaseSearchBackend):
    """
    `SearchBackend` defines the Xapian search backend for use with the Haystack
    API for Django search.

    It uses the Xapian Python bindings to interface with Xapian, and as
    such is subject to this bug: <http://trac.xapian.org/ticket/364> when
    Django is running with mod_python or mod_wsgi under Apache.

    Until this issue has been fixed by Xapian, it is neccessary to set
    `WSGIApplicationGroup to %{GLOBAL}` when using mod_wsgi, or
    `PythonInterpreter main_interpreter` when using mod_python.

    In order to use this backend, `PATH` must be included in the
    `connection_options`.  This should point to a location where you would your
    indexes to reside.
    """
    inmemory_db = None

    def __init__(self, connection_alias, **connection_options):
        """
        Instantiates an instance of `SearchBackend`.

        Optional arguments:
            `connection_alias` -- The name of the connection
            `language` -- The stemming language (default = 'english')
            `**connection_options` -- The various options needed to setup
              the backend.

        Also sets the stemming language to be used to `language`.
        """
        super(XapianSearchBackend, self).__init__(connection_alias, **connection_options)

        if not 'PATH' in connection_options:
            raise ImproperlyConfigured("You must specify a 'PATH' in your settings for connection '%s'." % connection_alias)

        self.path = connection_options.get('PATH')

        if self.path != MEMORY_DB_NAME and not os.path.exists(self.path):
            os.makedirs(self.path)

        self.flags = connection_options.get('FLAGS', DEFAULT_XAPIAN_FLAGS)
        self.language = getattr(settings, 'HAYSTACK_XAPIAN_LANGUAGE', 'english')
        self._schema = None
        self._content_field_name = None

    @property
    def schema(self):
        if not self._schema:
            self._content_field_name, self._schema = self.build_schema(connections[self.connection_alias].get_unified_index().all_searchfields())
        return self._schema

    @property
    def content_field_name(self):
        if not self._content_field_name:
            self._content_field_name, self._schema = self.build_schema(connections[self.connection_alias].get_unified_index().all_searchfields())
        return self._content_field_name

    def update(self, index, iterable):
        """
        Updates the `index` with any objects in `iterable` by adding/updating
        the database as needed.

        Required arguments:
            `index` -- The `SearchIndex` to process
            `iterable` -- An iterable of model instances to index

        For each object in `iterable`, a document is created containing all
        of the terms extracted from `index.full_prepare(obj)` with field prefixes,
        and 'as-is' as needed.  Also, if the field type is 'text' it will be
        stemmed and stored with the 'Z' prefix as well.

        eg. `content:Testing` ==> `testing, Ztest, ZXCONTENTtest, XCONTENTtest`

        Each document also contains an extra term in the format:

        `XCONTENTTYPE<app_name>.<model_name>`

        As well as a unique identifier in the the format:

        `Q<app_name>.<model_name>.<pk>`

        eg.: foo.bar (pk=1) ==> `Qfoo.bar.1`, `XCONTENTTYPEfoo.bar`

        This is useful for querying for a specific document corresponding to
        a model instance.

        The document also contains a pickled version of the object itself and
        the document ID in the document data field.

        Finally, we also store field values to be used for sorting data.  We
        store these in the document value slots (position zero is reserver
        for the document ID).  All values are stored as unicode strings with
        conversion of float, int, double, values being done by Xapian itself
        through the use of the :method:xapian.sortable_serialise method.
        """
        database = self._database(writable=True)
        try:
            for obj in iterable:
                document = xapian.Document()

                term_generator = xapian.TermGenerator()
                term_generator.set_database(database)
                term_generator.set_stemmer(xapian.Stem(self.language))
                if self.include_spelling is True:
                    term_generator.set_flags(xapian.TermGenerator.FLAG_SPELLING)
                term_generator.set_document(document)

                document_id = DOCUMENT_ID_TERM_PREFIX + get_identifier(obj)
                data = index.full_prepare(obj)
                weights = index.get_field_weights()
                for field in self.schema:
                    if field['field_name'] in data.keys():
                        prefix = DOCUMENT_CUSTOM_TERM_PREFIX + field['field_name'].upper()
                        value = data[field['field_name']]
                        try:
                            weight = int(weights[field['field_name']])
                        except KeyError:
                            weight = 1
                        if field['type'] == 'text':
                            if field['multi_valued'] == 'false':
                                term = _marshal_term(value)
                                term_generator.index_text(term, weight)
                                term_generator.index_text(term, weight, prefix)
                                if len(term.split()) == 1:
                                    document.add_term(term, weight)
                                    document.add_term(prefix + term, weight)
                                document.add_value(field['column'], _marshal_value(value))
                            else:
                                for term in value:
                                    term = _marshal_term(term)
                                    term_generator.index_text(term, weight)
                                    term_generator.index_text(term, weight, prefix)
                                    if len(term.split()) == 1:
                                        document.add_term(term, weight)
                                        document.add_term(prefix + term, weight)
                        else:
                            if field['multi_valued'] == 'false':
                                term = _marshal_term(value)
                                if len(term.split()) == 1:
                                    document.add_term(term, weight)
                                    document.add_term(prefix + term, weight)
                                    document.add_value(field['column'], _marshal_value(value))
                            else:
                                for term in value:
                                    term = _marshal_term(term)
                                    if len(term.split()) == 1:
                                        document.add_term(term, weight)
                                        document.add_term(prefix + term, weight)

                document.set_data(pickle.dumps(
                    (obj._meta.app_label, obj._meta.module_name, obj.pk, data),
                    pickle.HIGHEST_PROTOCOL
                ))
                document.add_term(document_id)
                document.add_term(
                    DOCUMENT_CT_TERM_PREFIX + u'%s.%s' %
                    (obj._meta.app_label, obj._meta.module_name)
                )
                database.replace_document(document_id, document)

        except UnicodeDecodeError:
            sys.stderr.write('Chunk failed.\n')
            pass

        finally:
            database.close()

    def remove(self, obj):
        """
        Remove indexes for `obj` from the database.

        We delete all instances of `Q<app_name>.<model_name>.<pk>` which
        should be unique to this object.
        """
        database = self._database(writable=True)
        database.delete_document(DOCUMENT_ID_TERM_PREFIX + get_identifier(obj))
        database.close()

    def clear(self, models=[]):
        """
        Clear all instances of `models` from the database or all models, if
        not specified.

        Optional Arguments:
            `models` -- Models to clear from the database (default = [])

        If `models` is empty, an empty query is executed which matches all
        documents in the database.  Afterwards, each match is deleted.

        Otherwise, for each model, a `delete_document` call is issued with
        the term `XCONTENTTYPE<app_name>.<model_name>`.  This will delete
        all documents with the specified model type.
        """
        database = self._database(writable=True)
        if not models:
            # Because there does not appear to be a "clear all" method,
            # it's much quicker to remove the contents of the `self.path`
            # folder than it is to remove each document one at a time.
            if os.path.exists(self.path):
                shutil.rmtree(self.path)
        else:
            for model in models:
                database.delete_document(
                    DOCUMENT_CT_TERM_PREFIX + '%s.%s' %
                    (model._meta.app_label, model._meta.module_name)
                )
        database.close()

    def document_count(self):
        try:
            return self._database().get_doccount()
        except InvalidIndexError:
            return 0

    @log_query
    def search(self, query, sort_by=None, start_offset=0, end_offset=None,
               fields='', highlight=False, facets=None, date_facets=None,
               query_facets=None, narrow_queries=None, spelling_query=None,
               limit_to_registered_models=True, result_class=None, **kwargs):
        """
        Executes the Xapian::query as defined in `query`.

        Required arguments:
            `query` -- Search query to execute

        Optional arguments:
            `sort_by` -- Sort results by specified field (default = None)
            `start_offset` -- Slice results from `start_offset` (default = 0)
            `end_offset` -- Slice results at `end_offset` (default = None), if None, then all documents
            `fields` -- Filter results on `fields` (default = '')
            `highlight` -- Highlight terms in results (default = False)
            `facets` -- Facet results on fields (default = None)
            `date_facets` -- Facet results on date ranges (default = None)
            `query_facets` -- Facet results on queries (default = None)
            `narrow_queries` -- Narrow queries (default = None)
            `spelling_query` -- An optional query to execute spelling suggestion on
            `limit_to_registered_models` -- Limit returned results to models registered in the current `SearchSite` (default = True)

        Returns:
            A dictionary with the following keys:
                `results` -- A list of `SearchResult`
                `hits` -- The total available results
                `facets` - A dictionary of facets with the following keys:
                    `fields` -- A list of field facets
                    `dates` -- A list of date facets
                    `queries` -- A list of query facets
            If faceting was not used, the `facets` key will not be present

        If `query` is None, returns no results.

        If `INCLUDE_SPELLING` was enabled in the connection options, the
        extra flag `FLAG_SPELLING_CORRECTION` will be passed to the query parser
        and any suggestions for spell correction will be returned as well as
        the results.
        """
        if xapian.Query.empty(query):
            return {
                'results': [],
                'hits': 0,
            }
            
        database = self._database()

        if result_class is None:
            result_class = SearchResult

        if self.include_spelling is True:
            spelling_suggestion = self._do_spelling_suggestion(database, query, spelling_query)
        else:
            spelling_suggestion = ''

        if narrow_queries is not None:
            query = xapian.Query(
                xapian.Query.OP_AND, query, xapian.Query(
                    xapian.Query.OP_OR, [self.parse_query(narrow_query) for narrow_query in narrow_queries]
                )
            )

        if limit_to_registered_models:
            registered_models = self.build_models_list()

            if len(registered_models) > 0:
                query = xapian.Query(
                    xapian.Query.OP_AND, query,
                    xapian.Query(
                        xapian.Query.OP_OR,  [
                            xapian.Query('%s%s' % (DOCUMENT_CT_TERM_PREFIX, model)) for model in registered_models
                        ]
                    )
                )

        enquire = xapian.Enquire(database)
        if hasattr(settings, 'HAYSTACK_XAPIAN_WEIGHTING_SCHEME'):
            enquire.set_weighting_scheme(xapian.BM25Weight(*settings.HAYSTACK_XAPIAN_WEIGHTING_SCHEME))
        enquire.set_query(query)
        
        # Construct ValueMatchSpy objects for regular field facets, and make a list
        # of facets over multi-value fields which Xapian doesn't support faceting for.
        facets_singlevalued = []
        facet_counters = []
        facets_multivalued = []
        if facets:
            for f in facets:
                if not self._multi_value_field(f):
                    ctr = xapian.ValueCountMatchSpy(self._value_column(f))
                    enquire.add_matchspy(ctr)
                    facets_singlevalued.append(f)
                    facet_counters.append(ctr)
                else:
                    facets_multivalued.append(f)
                
        if sort_by and not facets:
            sorter = xapian.MultiValueSorter()

            for sort_field in sort_by:
                if sort_field.startswith('-'):
                    reverse = True
                    sort_field = sort_field[1:]  # Strip the '-'
                else:
                    reverse = False  # Reverse is inverted in Xapian -- http://trac.xapian.org/ticket/311
                sorter.add(self._value_column(sort_field), reverse)

            enquire.set_sort_by_key_then_relevance(sorter, True)

        results = []
        facets_dict = {
            'fields': {},
            'dates': {},
            'queries': {},
        }

        if not end_offset:
            end_offset = database.get_doccount() - start_offset
        if facets:
            start_offset = 0
            end_offset = database.get_doccount()

        matches = self._get_enquire_mset(database, enquire, start_offset, end_offset)

        if not facets:
            for match in matches:
                app_label, module_name, pk, model_data = pickle.loads(self._get_document_data(database, match.document))
                if highlight:
                    model_data['highlighted'] = {
                        self.content_field_name: self._do_highlight(
                            model_data.get(self.content_field_name), query
                        )
                    }
                results.append(
                    result_class(app_label, module_name, pk, match.percent, **model_data)
                )

        if facets:
            facets_dict['fields'] = { }
            
            # Use the spy object to get the facet counts for single-value fields.
            for i in xrange(len(facets_singlevalued)):
                is_numeric = False
                for field in self.schema:
                    if field['field_name'] == facets_singlevalued[i]:
                        if field['type'] == 'long':
                            is_numeric = True
                        
                itr = facet_counters[i].values()
                facets_dict['fields'][facets_singlevalued[i]] = [
                    (long(t.term) if is_numeric else t.term, t.termfreq)
                    for t in itr ]
                    
            if len(facets_multivalued) > 0:
                # Loop through the result set to query multi-valued facet fields.
                for f in facets_multivalued:
                    facets_dict["fields"][f] = { }
                for match in matches:
                    app_label, module_name, pk, model_data = pickle.loads(self._get_document_data(database, match.document))
                    for f in facets_multivalued:
                        fv = facets_dict["fields"][f]
                        for item in model_data[f]:
                            fv[item] = fv.get(item, 0) + 1
                for f in facets_multivalued:
                    facets_dict["fields"][f] = facets_dict["fields"][f].items()
                # really slow:
                #facets_dict["fields"].update(self._do_field_facets(results, facets_multivalued))
                    
        if date_facets:
            facets_dict['dates'] = self._do_date_facets(results, date_facets)
        if query_facets:
            facets_dict['queries'] = self._do_query_facets(results, query_facets)

        return {
            'results': results,
            'hits': self._get_hit_count(database, enquire),
            'facets': facets_dict,
            'spelling_suggestion': spelling_suggestion,
        }

    def more_like_this(self, model_instance, additional_query=None,
                       start_offset=0, end_offset=None,
                       limit_to_registered_models=True, result_class=None, **kwargs):
        """
        Given a model instance, returns a result set of similar documents.

        Required arguments:
            `model_instance` -- The model instance to use as a basis for
                                retrieving similar documents.

        Optional arguments:
            `additional_query` -- An additional query to narrow results
            `start_offset` -- The starting offset (default=0)
            `end_offset` -- The ending offset (default=None), if None, then all documents
            `limit_to_registered_models` -- Limit returned results to models registered in the current `SearchSite` (default = True)

        Returns:
            A dictionary with the following keys:
                `results` -- A list of `SearchResult`
                `hits` -- The total available results

        Opens a database connection, then builds a simple query using the
        `model_instance` to build the unique identifier.

        For each document retrieved(should always be one), adds an entry into
        an RSet (relevance set) with the document id, then, uses the RSet
        to query for an ESet (A set of terms that can be used to suggest
        expansions to the original query), omitting any document that was in
        the original query.

        Finally, processes the resulting matches and returns.
        """
        database = self._database()

        if result_class is None:
            result_class = SearchResult

        query = xapian.Query(DOCUMENT_ID_TERM_PREFIX + get_identifier(model_instance))

        enquire = xapian.Enquire(database)
        enquire.set_query(query)

        rset = xapian.RSet()

        if not end_offset:
            end_offset = database.get_doccount()

        for match in self._get_enquire_mset(database, enquire, 0, end_offset):
            rset.add_document(match.docid)

        query = xapian.Query(
            xapian.Query.OP_ELITE_SET,
            [expand.term for expand in enquire.get_eset(match.document.termlist_count(), rset, XHExpandDecider())],
            match.document.termlist_count()
        )
        query = xapian.Query(
            xapian.Query.OP_AND_NOT, [query, DOCUMENT_ID_TERM_PREFIX + get_identifier(model_instance)]
        )
        if limit_to_registered_models:
            registered_models = self.build_models_list()

            if len(registered_models) > 0:
                query = xapian.Query(
                    xapian.Query.OP_AND, query,
                    xapian.Query(
                        xapian.Query.OP_OR,  [
                            xapian.Query('%s%s' % (DOCUMENT_CT_TERM_PREFIX, model)) for model in registered_models
                        ]
                    )
                )
        if additional_query:
            query = xapian.Query(
                xapian.Query.OP_AND, query, additional_query
            )

        enquire.set_query(query)

        results = []
        matches = self._get_enquire_mset(database, enquire, start_offset, end_offset)

        for match in matches:
            app_label, module_name, pk, model_data = pickle.loads(self._get_document_data(database, match.document))
            results.append(
                result_class(app_label, module_name, pk, match.percent, **model_data)
            )

        return {
            'results': results,
            'hits': self._get_hit_count(database, enquire),
            'facets': {
                'fields': {},
                'dates': {},
                'queries': {},
            },
            'spelling_suggestion': None,
        }

    def parse_query(self, query_string):
        """
        Given a `query_string`, will attempt to return a xapian.Query

        Required arguments:
            ``query_string`` -- A query string to parse

        Returns a xapian.Query
        """
        if query_string == '*':
            return xapian.Query('')  # Match everything
        elif query_string == '':
            return xapian.Query()  # Match nothing

        qp = xapian.QueryParser()
        qp.set_database(self._database())
        qp.set_stemmer(xapian.Stem(self.language))
        qp.set_stemming_strategy(xapian.QueryParser.STEM_SOME)
        qp.add_boolean_prefix('django_ct', DOCUMENT_CT_TERM_PREFIX)

        for field_dict in self.schema:
            qp.add_prefix(
                field_dict['field_name'],
                DOCUMENT_CUSTOM_TERM_PREFIX + field_dict['field_name'].upper()
            )

        vrp = XHValueRangeProcessor(self)
        qp.add_valuerangeprocessor(vrp)

        return qp.parse_query(query_string, self.flags)

    def build_schema(self, fields):
        """
        Build the schema from fields.

        Required arguments:
            ``fields`` -- A list of fields in the index

        Returns a list of fields in dictionary format ready for inclusion in
        an indexed meta-data.
        """
        content_field_name = ''
        schema_fields = [
            {'field_name': ID, 'type': 'text', 'multi_valued': 'false', 'column': 0},
        ]
        column = len(schema_fields)

        for field_name, field_class in sorted(fields.items(), key=lambda n: n[0]):
            if field_class.document is True:
                content_field_name = field_class.index_fieldname

            if field_class.indexed is True:
                field_data = {
                    'field_name': field_class.index_fieldname,
                    'type': 'text',
                    'multi_valued': 'false',
                    'column': column,
                }

                if field_class.field_type in ['date', 'datetime']:
                    field_data['type'] = 'date'
                elif field_class.field_type == 'integer':
                    field_data['type'] = 'long'
                elif field_class.field_type == 'float':
                    field_data['type'] = 'float'
                elif field_class.field_type == 'boolean':
                    field_data['type'] = 'boolean'

                if field_class.is_multivalued:
                    field_data['multi_valued'] = 'true'

                schema_fields.append(field_data)
                column += 1

        return (content_field_name, schema_fields)

    def _do_highlight(self, content, query, tag='em'):
        """
        Highlight `query` terms in `content` with html `tag`.

        This method assumes that the input text (`content`) does not contain
        any special formatting.  That is, it does not contain any html tags
        or similar markup that could be screwed up by the highlighting.

        Required arguments:
            `content` -- Content to search for instances of `text`
            `text` -- The text to be highlighted
        """
        for term in query:
            for match in re.findall('[^A-Z]+', term):  # Ignore field identifiers
                match_re = re.compile(match, re.I)
                content = match_re.sub('<%s>%s</%s>' % (tag, term, tag), content)

        return content

    def _do_field_facets(self, results, field_facets):
        """
        Private method that facets a document by field name.

        Fields of type MultiValueField will be faceted on each item in the
        (containing) list.

        Required arguments:
            `results` -- A list SearchResults to facet
            `field_facets` -- A list of fields to facet on
        """
        facet_dict = {}

        # DS_TODO: Improve this algorithm.  Currently, runs in O(N^2), ouch.
        for field in field_facets:
            facet_list = {}

            for result in results:
                field_value = getattr(result, field)
                if self._multi_value_field(field):
                    for item in field_value:  # Facet each item in a MultiValueField
                        facet_list[item] = facet_list.get(item, 0) + 1
                else:
                    facet_list[field_value] = facet_list.get(field_value, 0) + 1

            facet_dict[field] = facet_list.items()

        return facet_dict

    def _do_date_facets(self, results, date_facets):
        """
        Private method that facets a document by date ranges

        Required arguments:
            `results` -- A list SearchResults to facet
            `date_facets` -- A dictionary containing facet parameters:
                {'field': {'start_date': ..., 'end_date': ...: 'gap_by': '...', 'gap_amount': n}}
                nb., gap must be one of the following:
                    year|month|day|hour|minute|second

        For each date facet field in `date_facets`, generates a list
        of date ranges (from `start_date` to `end_date` by `gap_by`) then
        iterates through `results` and tallies the count for each date_facet.

        Returns a dictionary of date facets (fields) containing a list with
        entries for each range and a count of documents matching the range.

        eg. {
            'pub_date': [
                ('2009-01-01T00:00:00Z', 5),
                ('2009-02-01T00:00:00Z', 0),
                ('2009-03-01T00:00:00Z', 0),
                ('2009-04-01T00:00:00Z', 1),
                ('2009-05-01T00:00:00Z', 2),
            ],
        }
        """
        facet_dict = {}

        for date_facet, facet_params in date_facets.iteritems():
            gap_type = facet_params.get('gap_by')
            gap_value = facet_params.get('gap_amount', 1)
            date_range = facet_params['start_date']
            facet_list = []
            while date_range < facet_params['end_date']:
                facet_list.append((date_range.isoformat(), 0))
                if gap_type == 'year':
                    date_range = date_range.replace(
                        year=date_range.year + int(gap_value)
                    )
                elif gap_type == 'month':
                    if date_range.month + int(gap_value) > 12:
                        date_range = date_range.replace(
                            month=((date_range.month + int(gap_value)) % 12),
                            year=(date_range.year + (date_range.month + int(gap_value)) / 12)
                        )
                    else:
                        date_range = date_range.replace(
                            month=date_range.month + int(gap_value)
                        )
                elif gap_type == 'day':
                    date_range += datetime.timedelta(days=int(gap_value))
                elif gap_type == 'hour':
                    date_range += datetime.timedelta(hours=int(gap_value))
                elif gap_type == 'minute':
                    date_range += datetime.timedelta(minutes=int(gap_value))
                elif gap_type == 'second':
                    date_range += datetime.timedelta(seconds=int(gap_value))

            facet_list = sorted(facet_list, key=lambda n: n[0], reverse=True)

            for result in results:
                result_date = getattr(result, date_facet)
                if result_date:
                    if not isinstance(result_date, datetime.datetime):
                        result_date = datetime.datetime(
                            year=result_date.year,
                            month=result_date.month,
                            day=result_date.day,
                        )
                    for n, facet_date in enumerate(facet_list):
                        if result_date > datetime.datetime(*(time.strptime(facet_date[0], '%Y-%m-%dT%H:%M:%S')[0:6])):
                            facet_list[n] = (facet_list[n][0], (facet_list[n][1] + 1))
                            break

            facet_dict[date_facet] = facet_list

        return facet_dict

    def _do_query_facets(self, results, query_facets):
        """
        Private method that facets a document by query

        Required arguments:
            `results` -- A list SearchResults to facet
            `query_facets` -- A dictionary containing facet parameters:
                {'field': 'query', [...]}

        For each query in `query_facets`, generates a dictionary entry with
        the field name as the key and a tuple with the query and result count
        as the value.

        eg. {'name': ('a*', 5)}
        """
        facet_dict = {}

        for field, query in query_facets.iteritems():
            facet_dict[field] = (query, self.search(self.parse_query(query))['hits'])

        return facet_dict

    def _do_spelling_suggestion(self, database, query, spelling_query):
        """
        Private method that returns a single spelling suggestion based on
        `spelling_query` or `query`.

        Required arguments:
            `database` -- The database to check spelling against
            `query` -- The query to check
            `spelling_query` -- If not None, this will be checked instead of `query`

        Returns a string with a suggested spelling
        """
        if spelling_query:
            if ' ' in spelling_query:
                return ' '.join([database.get_spelling_suggestion(term) for term in spelling_query.split()])
            else:
                return database.get_spelling_suggestion(spelling_query)

        term_set = set()
        for term in query:
            for match in re.findall('[^A-Z]+', term):  # Ignore field identifiers
                term_set.add(database.get_spelling_suggestion(match))

        return ' '.join(term_set)

    def _database(self, writable=False):
        """
        Private method that returns a xapian.Database for use.

        Optional arguments:
            ``writable`` -- Open the database in read/write mode (default=False)

        Returns an instance of a xapian.Database or xapian.WritableDatabase
        """
        if self.path == MEMORY_DB_NAME:
            if not self.inmemory_db:
                self.inmemory_db = xapian.inmemory_open()
            return self.inmemory_db
        if writable:
            database = xapian.WritableDatabase(self.path, xapian.DB_CREATE_OR_OPEN)
        else:
            try:
                database = xapian.Database(self.path)
            except xapian.DatabaseOpeningError:
                raise InvalidIndexError(u'Unable to open index at %s' % self.path)

        return database

    def _get_enquire_mset(self, database, enquire, start_offset, end_offset):
        """
        A safer version of Xapian.enquire.get_mset

        Simply wraps the Xapian version and catches any `Xapian.DatabaseModifiedError`,
        attempting a `database.reopen` as needed.

        Required arguments:
            `database` -- The database to be read
            `enquire` -- An instance of an Xapian.enquire object
            `start_offset` -- The start offset to pass to `enquire.get_mset`
            `end_offset` -- The end offset to pass to `enquire.get_mset`
        """
        try:
            return enquire.get_mset(start_offset, end_offset)
        except xapian.DatabaseModifiedError:
            database.reopen()
            return enquire.get_mset(start_offset, end_offset)

    def _get_document_data(self, database, document):
        """
        A safer version of Xapian.document.get_data

        Simply wraps the Xapian version and catches any `Xapian.DatabaseModifiedError`,
        attempting a `database.reopen` as needed.

        Required arguments:
            `database` -- The database to be read
            `document` -- An instance of an Xapian.document object
        """
        try:
            return document.get_data()
        except xapian.DatabaseModifiedError:
            database.reopen()
            return document.get_data()

    def _get_hit_count(self, database, enquire):
        """
        Given a database and enquire instance, returns the estimated number
        of matches.

        Required arguments:
            `database` -- The database to be queried
            `enquire` -- The enquire instance
        """
        return self._get_enquire_mset(
            database, enquire, 0, database.get_doccount()
        ).size()

    def _value_column(self, field):
        """
        Private method that returns the column value slot in the database
        for a given field.

        Required arguemnts:
            `field` -- The field to lookup

        Returns an integer with the column location (0 indexed).
        """
        for field_dict in self.schema:
            if field_dict['field_name'] == field:
                return field_dict['column']
        return 0

    def _multi_value_field(self, field):
        """
        Private method that returns `True` if a field is multi-valued, else
        `False`.

        Required arguemnts:
            `field` -- The field to lookup

        Returns a boolean value indicating whether the field is multi-valued.
        """
        for field_dict in self.schema:
            if field_dict['field_name'] == field:
                return field_dict['multi_valued'] == 'true'
        return False


class XapianSearchQuery(BaseSearchQuery):
    """
    This class is the Xapian specific version of the SearchQuery class.
    It acts as an intermediary between the ``SearchQuerySet`` and the
    ``SearchBackend`` itself.
    """
    def build_params(self, *args, **kwargs):
        kwargs = super(XapianSearchQuery, self).build_params(*args, **kwargs)

        if self.end_offset is not None:
            kwargs['end_offset'] = self.end_offset - self.start_offset

        return kwargs

    def build_query(self):
        if not self.query_filter:
            query = xapian.Query('')
        else:
            query = self._query_from_search_node(self.query_filter)

        if self.models:
            subqueries = [
                xapian.Query(
                    xapian.Query.OP_SCALE_WEIGHT, xapian.Query('%s%s.%s' % (
                            DOCUMENT_CT_TERM_PREFIX,
                            model._meta.app_label, model._meta.module_name
                        )
                    ), 0  # Pure boolean sub-query
                ) for model in self.models
            ]
            query = xapian.Query(
                xapian.Query.OP_AND, query,
                xapian.Query(xapian.Query.OP_OR, subqueries)
            )

        if self.boost:
            subqueries = [
                xapian.Query(
                    xapian.Query.OP_SCALE_WEIGHT, self._content_field(term, False), value
                ) for term, value in self.boost.iteritems()
            ]
            query = xapian.Query(
                xapian.Query.OP_AND_MAYBE, query,
                xapian.Query(xapian.Query.OP_OR, subqueries)
            )

        return query

    def _query_from_search_node(self, search_node, is_not=False):
        query_list = []

        for child in search_node.children:
            if isinstance(child, SearchNode):
                query_list.append(
                    self._query_from_search_node(child, child.negated)
                )
            else:
                expression, term = child
                field, filter_type = search_node.split_expression(expression)

                # Handle when we've got a ``ValuesListQuerySet``...
                if hasattr(term, 'values_list'):
                    term = list(term)

                if isinstance(term, (list, tuple)):
                    term = [_marshal_term(t) for t in term]
                else:
                    term = _marshal_term(term)

                # We'll always get no results if there is punctuation in the query, since
                # punctuation is not indexed. Should Xapian handle that??
                if isinstance(term, unicode):
                    from unicodedata import category
                    term = ''.join(ch if category(ch)[0] != 'P' else " " for ch in term)
                    term = re.sub(r"\s+", " ", term) # collapse multiple adjacent spaces?
                elif isinstance(term, str):
                    import string
                    term = re.sub('[ %s]+' % re.escape(string.punctuation), ' ', term)

                if field == 'content':
                    query_list.append(self._content_field(term, is_not))
                else:
                    if filter_type == 'contains':
                        query_list.append(self._filter_contains(term, field, is_not))
                    elif filter_type == 'exact':
                        query_list.append(self._filter_exact(term, field, is_not))
                    elif filter_type == 'gt':
                        query_list.append(self._filter_gt(term, field, is_not))
                    elif filter_type == 'gte':
                        query_list.append(self._filter_gte(term, field, is_not))
                    elif filter_type == 'lt':
                        query_list.append(self._filter_lt(term, field, is_not))
                    elif filter_type == 'lte':
                        query_list.append(self._filter_lte(term, field, is_not))
                    elif filter_type == 'startswith':
                        query_list.append(self._filter_startswith(term, field, is_not))
                    elif filter_type == 'in':
                        query_list.append(self._filter_in(term, field, is_not))

        if search_node.connector == 'OR':
            return xapian.Query(xapian.Query.OP_OR, query_list)
        else:
            return xapian.Query(xapian.Query.OP_AND, query_list)

    def _content_field(self, term, is_not):
        """
        Private method that returns a xapian.Query that searches for `value`
        in all fields.

        Required arguments:
            ``term`` -- The term to search for
            ``is_not`` -- Invert the search results

        Returns:
            A xapian.Query
        """
        if ' ' in term:
            if is_not:
                return xapian.Query(
                    xapian.Query.OP_AND_NOT, self._all_query(), self._phrase_query(
                        term.split(), self.backend.content_field_name
                    )
                )
            else:
                return self._phrase_query(term.split(), self.backend.content_field_name)
        else:
            if is_not:
                return xapian.Query(xapian.Query.OP_AND_NOT, self._all_query(), self._term_query(term))
            else:
                return self._term_query(term)

    def _filter_contains(self, term, field, is_not):
        """
        Private method that returns a xapian.Query that searches for `term`
        in a specified `field`.

        Required arguments:
            ``term`` -- The term to search for
            ``field`` -- The field to search
            ``is_not`` -- Invert the search results

        Returns:
            A xapian.Query
        """
        if ' ' in term:
            return self._filter_exact(term, field, is_not)
        else:
            if is_not:
                return xapian.Query(xapian.Query.OP_AND_NOT, self._all_query(), self._term_query(term, field))
            else:
                return self._term_query(term, field)

    def _filter_exact(self, term, field, is_not):
        """
        Private method that returns a xapian.Query that searches for an exact
        match for `term` in a specified `field`.

        Required arguments:
            ``term`` -- The term to search for
            ``field`` -- The field to search
            ``is_not`` -- Invert the search results

        Returns:
            A xapian.Query
        """
        if is_not:
            return xapian.Query(
                xapian.Query.OP_AND_NOT, self._all_query(), self._phrase_query(term.split(), field)
            )
        else:
            return self._phrase_query(term.split(), field)

    def _filter_in(self, term_list, field, is_not):
        """
        Private method that returns a xapian.Query that searches for any term
        of `value_list` in a specified `field`.

        Required arguments:
            ``term_list`` -- The terms to search for
            ``field`` -- The field to search
            ``is_not`` -- Invert the search results

        Returns:
            A xapian.Query
        """
        query_list = []
        for term in term_list:
            if ' ' in term:
                query_list.append(
                    self._phrase_query(term.split(), field)
                )
            else:
                query_list.append(
                    self._term_query(term, field)
                )
        if is_not:
            return xapian.Query(xapian.Query.OP_AND_NOT, self._all_query(), xapian.Query(xapian.Query.OP_OR, query_list))
        else:
            return xapian.Query(xapian.Query.OP_OR, query_list)

    def _filter_startswith(self, term, field, is_not):
        """
        Private method that returns a xapian.Query that searches for any term
        that begins with `term` in a specified `field`.

        Required arguments:
            ``term`` -- The terms to search for
            ``field`` -- The field to search
            ``is_not`` -- Invert the search results

        Returns:
            A xapian.Query
        """
        if is_not:
            return xapian.Query(
                xapian.Query.OP_AND_NOT,
                self._all_query(),
                self.backend.parse_query('%s:%s*' % (field, term)),
            )
        return self.backend.parse_query('%s:%s*' % (field, term))

    def _filter_gt(self, term, field, is_not):
        return self._filter_lte(term, field, is_not=(is_not != True))

    def _filter_lt(self, term, field, is_not):
        return self._filter_gte(term, field, is_not=(is_not != True))

    def _filter_gte(self, term, field, is_not):
        """
        Private method that returns a xapian.Query that searches for any term
        that is greater than `term` in a specified `field`.
        """
        vrp = XHValueRangeProcessor(self.backend)
        pos, begin, end = vrp('%s:%s' % (field, _marshal_value(term)), '*')
        if is_not:
            return xapian.Query(xapian.Query.OP_AND_NOT,
                self._all_query(),
                xapian.Query(xapian.Query.OP_VALUE_RANGE, pos, begin, end)
            )
        return xapian.Query(xapian.Query.OP_VALUE_RANGE, pos, begin, end)

    def _filter_lte(self, term, field, is_not):
        """
        Private method that returns a xapian.Query that searches for any term
        that is less than `term` in a specified `field`.
        """
        vrp = XHValueRangeProcessor(self.backend)
        pos, begin, end = vrp('%s:' % field, '%s' % _marshal_value(term))
        if is_not:
            return xapian.Query(xapian.Query.OP_AND_NOT,
                self._all_query(),
                xapian.Query(xapian.Query.OP_VALUE_RANGE, pos, begin, end)
            )
        return xapian.Query(xapian.Query.OP_VALUE_RANGE, pos, begin, end)

    def _all_query(self):
        """
        Private method that returns a xapian.Query that returns all documents,

        Returns:
            A xapian.Query
        """
        return xapian.Query('')

    def _term_query(self, term, field=None):
        """
        Private method that returns a term based xapian.Query that searches
        for `term`.

        Required arguments:
            ``term`` -- The term to search for
            ``field`` -- The field to search (If `None`, all fields)

        Returns:
            A xapian.Query
        """
        stem = xapian.Stem(self.backend.language)

        if field == 'id':
            return xapian.Query('%s%s' % (DOCUMENT_ID_TERM_PREFIX, term))
        elif field == 'django_ct':
            return xapian.Query('%s%s' % (DOCUMENT_CT_TERM_PREFIX, term))
        elif field:
            stemmed = 'Z%s%s%s' % (
                DOCUMENT_CUSTOM_TERM_PREFIX, field.upper(), stem(term)
            )
            unstemmed = '%s%s%s' % (
                DOCUMENT_CUSTOM_TERM_PREFIX, field.upper(), term
            )
        else:
            stemmed = 'Z%s' % stem(term)
            unstemmed = term

        return xapian.Query(
            xapian.Query.OP_OR,
            xapian.Query(stemmed),
            xapian.Query(unstemmed)
        )

    def _phrase_query(self, term_list, field=None):
        """
        Private method that returns a phrase based xapian.Query that searches
        for terms in `term_list.

        Required arguments:
            ``term_list`` -- The terms to search for
            ``field`` -- The field to search (If `None`, all fields)

        Returns:
            A xapian.Query
        """
        if field:
            return xapian.Query(
                xapian.Query.OP_PHRASE, [
                    '%s%s%s' % (
                        DOCUMENT_CUSTOM_TERM_PREFIX, field.upper(), term
                    ) for term in term_list
                ]
            )
        else:
            return xapian.Query(xapian.Query.OP_PHRASE, term_list)


def _marshal_value(value):
    """
    Private utility method that converts Python values to a string for Xapian values.
    """
    if isinstance(value, datetime.datetime):
        value = _marshal_datetime(value)
    elif isinstance(value, datetime.date):
        value = _marshal_date(value)
    elif isinstance(value, bool):
        if value:
            value = u't'
        else:
            value = u'f'
    elif isinstance(value, float):
        value = xapian.sortable_serialise(value)
    elif isinstance(value, (int, long)):
        value = u'%012d' % value
    else:
        value = force_unicode(value).lower()
    return value


def _marshal_term(term):
    """
    Private utility method that converts Python terms to a string for Xapian terms.
    """
    if isinstance(term, datetime.datetime):
        term = _marshal_datetime(term)
    elif isinstance(term, datetime.date):
        term = _marshal_date(term)
    else:
        term = force_unicode(term).lower()
    return term


def _marshal_date(d):
    return u'%04d%02d%02d000000' % (d.year, d.month, d.day)


def _marshal_datetime(dt):
    if dt.microsecond:
        return u'%04d%02d%02d%02d%02d%02d%06d' % (
            dt.year, dt.month, dt.day, dt.hour,
            dt.minute, dt.second, dt.microsecond
        )
    else:
        return u'%04d%02d%02d%02d%02d%02d' % (
            dt.year, dt.month, dt.day, dt.hour,
            dt.minute, dt.second
        )


class XapianEngine(BaseEngine):
    backend = XapianSearchBackend
    query = XapianSearchQuery

########NEW FILE########
__FILENAME__ = manage
#!.env/bin/python -R
import os, sys

try:
	import prctl
	prctl.set_name(os.environ["NAME"] + "-django")
except:
	pass

if "runserver" in sys.argv:
	os.environ["DEBUG"] = "1"

if __name__ == "__main__":
    os.environ.setdefault("DJANGO_SETTINGS_MODULE", "settings")
    from django.core.management import execute_from_command_line
    execute_from_command_line(sys.argv)

########NEW FILE########
__FILENAME__ = parse
#!.env/bin/python
from optparse import OptionParser
import sys, os, os.path
import logging

from common.system import setup_django
setup_django(__file__)
from django.conf import settings

# Explicitly set DEBUG to False to avoid memory leak
settings.DEBUG = False

PARSER_USAGE = """Usage: %prog action
Available actions: person, commitee, vote, bill"""

def setup_logging(console_level):
    "Setup logging system"

    if not os.path.exists("log"): os.mkdir("log")

    root = logging.getLogger()
    formatter = logging.Formatter('%(name)s: %(message)s')

    handler = logging.FileHandler('log/parsing.error.log', 'w')
    handler.setLevel(level=logging.ERROR)
    handler.setFormatter(formatter)
    root.addHandler(handler)

    handler = logging.FileHandler('log/parsing.log', 'w')
    handler.setLevel(level=logging.DEBUG)
    handler.setFormatter(formatter)
    root.addHandler(handler)

    handler = logging.StreamHandler()
    handler.setLevel(getattr(logging, console_level.upper()))
    handler.setFormatter(formatter)
    root.addHandler(handler)

    root.setLevel(logging.DEBUG)


def parse_args():
    "Parse command line arguments"

    parser = OptionParser(usage=PARSER_USAGE)
    parser.add_option('-m', '--method', default='main',
                      help='Which parser method should be run')
    parser.add_option('-f', '--force', action="store_true",
                      help='Re-parse all data whether or not it has changed.')
    parser.add_option('-l', '--level', default='info',
                      help='Default logging level')
    parser.add_option('--disable-events', action='store_true', default=False,
                      help='Disable events processing')
    parser.add_option('--disable-indexing', action='store_true', default=False,
                      help='Disable synchronous indexing')
    parser.add_option('--congress',
                      help='Limit parsing to the specified congress')
    parser.add_option('--slow', action='store_true',
                      help='Slow down parsing so we don\'t interfere with other processes.')
    parser.add_option('--filter',
                      help='Only process files matching a regex.')
    kwargs, args = parser.parse_args()
    if not args:
        parser.print_usage()
        sys.exit()
    return kwargs, args


def main():
    kwargs, args = parse_args()
    
    lf = args[0] + "." + kwargs.method
    @SingleRun(lock_file_name="govtrack_parser_" + lf)
    def main2():
        setup_logging(kwargs.level)
        parser = __import__('parser.%s_parser' % args[0], globals(), locals(), ['xxx'])
        getattr(parser, kwargs.method)(kwargs)
        logging.debug('Done')

    try:
        main2()
    except SingleRun.InstanceRunningException as e:
        print "Another %s parser is running with pid %s." % (lf, str(e))
        

# adapted from http://krosinski.blogspot.com/2012/04/preventing-python-script-from-running.html
import os
class SingleRun():
    class InstanceRunningException(Exception):
        pass
    def __init__(self, lock_file_name):
        self.lock_file =  "/tmp/%s.pid" % lock_file_name
    def __call__(self, func):
        def f(*args, **kwargs):
            if os.path.exists(self.lock_file):
                with open(self.lock_file, "rt") as f:
                    pid = f.read()
                if os.path.exists("/proc/%s" % pid):
                    raise self.InstanceRunningException(pid)
                os.unlink(self.lock_file)
            try:
                with open(self.lock_file, "wt") as f:
                    f.write(str(os.getpid()))
                return func(*args,**kwargs)
            finally:
                if os.path.exists(self.lock_file):
                    os.unlink(self.lock_file)
        return f
        
if __name__ == '__main__':
    main()


########NEW FILE########
__FILENAME__ = amendment_parser
"""
Parser for amendments.
 
for x in {82..112}; do echo $x; ./parse.py amendment --congress=$x -l ERROR --force --disable-events --disable-indexing; done
"""
from lxml import etree
import logging
from django.db.utils import IntegrityError
import glob
import re
import time
import urllib
import os.path
from datetime import datetime, timedelta

from parser.progress import Progress
from parser.processor import XmlProcessor
from parser.models import File
from bill.models import Amendment, AmendmentType, Bill, BillType
from vote.models import Vote, CongressChamber
from person.models import Person
from settings import CURRENT_CONGRESS
from us import get_session_from_date

log = logging.getLogger('parser.bill_parser')
PERSON_CACHE = {}

def get_person(pk):
    global PERSON_CACHE
    pk = int(pk)
    if not PERSON_CACHE:
        PERSON_CACHE = dict((x.pk, x) for x in Person.objects.all())
    return PERSON_CACHE[pk]

class AmendmentProcessor(XmlProcessor):
    REQUIRED_ATTRIBUTES = ['session', 'chamber', 'number']
    ATTRIBUTES = ['session', 'chamber', 'number']
    FIELD_MAPPING = {'chamber': 'amendment_type', 'session': 'congress'}

    def process(self, obj, node):
        obj = super(AmendmentProcessor, self).process(obj, node)
        self.process_offered(obj, node)
        self.process_sponsor(obj, node)
        self.process_bill(obj, node)
        self.process_title(obj, node)
        return obj

    def process_offered(self, obj, node):
        elem = node.xpath('offered')[0]
        obj.offered_date = self.parse_datetime(elem.get('datetime')).date()

    def process_title(self, obj, node):
        obj.title = \
             obj.get_amendment_type_display() + " " + str(obj.number) \
             + ((" (" + obj.sponsor.lastname + ")") if obj.sponsor else "") \
             + " to " + obj.bill.display_number
             
        for elem in node.xpath('description|purpose'):
            text = unicode(elem.text) if elem.text else ""
            if text.strip() != "":
                # Clean titles.
                text = re.sub(r"(?i)^(?:An )?(?:substitute )?amendment (?:in the nature of a substitute )?(numbered|No\.) (\d+) printed in (part .* of )?(House Report \d+-\d+|the Congressional Record) to ", "To ", text)
                obj.title += ": " + text
                break

    def process_sponsor(self, obj, node):
        try:
            obj.sponsor = get_person(node.xpath('sponsor')[0].get('id'))
            obj.sponsor_role = obj.sponsor.get_role_at_date(obj.offered_date)
        except IndexError: # no sponsor node
            obj.sponsor = None
        except TypeError: # no id attribute
            obj.sponsor = None

    def session_handler(self, value):
        return int(value)

    def chamber_handler(self, value):
        return AmendmentType.by_slug(value)

    def number_handler(self, value):
        return int(value)

    def process_bill(self, obj, node):
        amends_type = BillType.by_xml_code(node.xpath('string(amends/@type)'))
        amends_number = int(node.xpath('string(amends/@number)'))
        try:
            amends_seq = int(node.xpath('string(amends/@sequence)'))
        except ValueError:
            amends_seq = None
        obj.bill = Bill.objects.get(congress=obj.congress, bill_type=amends_type, number=amends_number)
        obj.sequence = amends_seq

def main(options):
    """
    Process amendments
    """

    if options.congress:
        files = glob.glob('data/us/%s/bills.amdt/*.xml' % options.congress)
        log.info('Parsing amendments of only congress#%s' % options.congress)
    else:
        files = glob.glob('data/us/*/bills.amdt/*.xml')
        
    if options.filter:
        files = [f for f in files if re.match(options.filter, f)]
        
    log.info('Processing amendments: %d files' % len(files))
    total = len(files)
    progress = Progress(total=total, name='files', step=100)

    amendment_processor = AmendmentProcessor()
    seen_amdt_ids = []
    for fname in files:
        progress.tick()
        
        if not File.objects.is_changed(fname) and not options.force:
            m = re.match(r"data/us/(\d+)/bills.amdt/([sh])(\d+).xml", fname)
            if not m:
                print "Invalid file name", fname
            else:
                amdt = Amendment.objects.get(congress=m.group(1), amendment_type=AmendmentType.by_slug(m.group(2)), number=m.group(3))
                seen_amdt_ids.append(amdt.id) # don't delete me later
            continue
            
        tree = etree.parse(fname)
        node = tree.xpath('/amendment')[0]
        
        try:
            amdt = amendment_processor.process(Amendment(), node)
        except:
            print fname
            raise
            
        # update if already in db
        try:
            amdt.id = Amendment.objects.get(congress=amdt.congress, amendment_type=amdt.amendment_type, number=amdt.number).id
        except Amendment.DoesNotExist:
            pass # a new amendment
       
        seen_amdt_ids.append(amdt.id) # don't delete me later
        
        try:
            amdt.save()
        except:
            print amdt
            raise
            
        # For House votes on amendments, the only way to associate the vote with the
        # amendment is to use the THOMAS/Congress.gov action lines. The House vote XML
        # has an amendment-num field but its meaning is ambiguous, so it is useless.
        # When we parse a House amendment with an action line referencing a roll call vote,
        # save this amendment as that vote's related_amendment, then mark the vote as
        # 'missing data' (below) so that on the next parse of votes its title gets updated.
        if amdt.amendment_type == AmendmentType.house_amendment:
            for vote in node.xpath("actions/vote[@how='roll']"):
                v_congress, v_session = get_session_from_date(XmlProcessor.parse_datetime(vote.get('datetime')).date())
                v_roll = int(vote.get("roll"))
                try:
                    vote = Vote.objects.get(congress=v_congress, chamber=CongressChamber.house, session=v_session, number=v_roll)
                    vote.related_amendment = amdt
                    vote.save()
                except Vote.DoesNotExist:
                    print "Missing vote data in", fname
            
        # If this amendment is related to a vote, mark the vote as missing data because
        # we may need to update the vote title if the amendment title has changed.
        Vote.objects.filter(related_amendment=amdt).update(missing_data=True)

        File.objects.save_file(fname)
        
    # Are any amendments in the database no longer on disk?
    if options.congress and not options.filter:
        missing = Amendment.objects.filter(congress=options.congress).exclude(id__in = seen_amdt_ids)
        if missing.exists():
            print "Amendments should be deleted: ", missing


if __name__ == '__main__':
    main()

########NEW FILE########
__FILENAME__ = bill_parser
"""
Parser of:
 * bill terms located in data/us/[liv, liv111, crsnet].xml
 * bills located in data/us/*/bills/*.xml
 
for x in {82..112}; do echo $x; ./parse.py bill --congress=$x -l ERROR --force --disable-events --disable-indexing; done
"""
from lxml import etree
import logging
from django.db.utils import IntegrityError
import glob
import re
import time
import urllib
import os.path
from datetime import datetime, timedelta

from parser.progress import Progress
from parser.processor import XmlProcessor
from parser.models import File
from bill.models import BillTerm, TermType, BillType, Bill, Cosponsor, BillStatus, RelatedBill
from person.models import Person
from bill.title import get_primary_bill_title
from bill.billtext import get_bill_text_metadata
from committee.models import Committee
from settings import CURRENT_CONGRESS

log = logging.getLogger('parser.bill_parser')
PERSON_CACHE = {}
TERM_CACHE = {}

def get_person(pk):
    global PERSON_CACHE
    pk = int(pk)
    if not PERSON_CACHE:
        PERSON_CACHE = dict((x.pk, x) for x in Person.objects.all())
    return PERSON_CACHE[pk]


def normalize_name(name):
    "Convert name to common format."

    name = re.sub(r'\s{2,}', ' ', name)
    return name.lower()


def get_term(name, congress):
    global TERM_CACHE
    if not TERM_CACHE:
        for term in BillTerm.objects.all():
            TERM_CACHE[(term.term_type, normalize_name(term.name))] = term
    return TERM_CACHE[(TermType.new if congress >= 111 else TermType.old, normalize_name(name))]

class TermProcessor(XmlProcessor):
    REQUIRED_ATTRIBUTES = ['value']
    ATTRIBUTES = ['value']
    FIELD_MAPPING = {'value': 'name'}
    

class BillProcessor(XmlProcessor):
    REQUIRED_ATTRIBUTES = ['type', 'session', 'number']
    ATTRIBUTES = ['type', 'session', 'number']
    FIELD_MAPPING = {'type': 'bill_type', 'session': 'congress'}

    def type_handler(self, value):
        return BillType.by_xml_code(value)

    def process(self, obj, node):
        obj = super(BillProcessor, self).process(obj, node)
        self.process_titles(obj, node)
        self.process_introduced(obj, node)
        self.process_sponsor(obj, node)
        self.process_current_status(obj, node)

        # update existing bill record if one exists, otherwise create a new one on save()
        try:
            obj.id = Bill.objects.get(congress=obj.congress, bill_type=obj.bill_type, number=obj.number).id
        except Bill.DoesNotExist:
            pass
            
        obj.save() # save before using m2m relations
        self.process_committees(obj, node)
        if int(obj.congress) >= 93:
            # Bills from the Statutes at Large use some other subject term domain.
            self.process_terms(obj, node, obj.congress)
        self.process_consponsors(obj, node)
        self.process_relatedbills(obj, node)
        return obj

    def process_introduced(self, obj, node):
        elem = node.xpath('./introduced')[0]
        obj.introduced_date = self.parse_datetime(elem.get('datetime')).date()

    def process_current_status(self, obj, node):
        elem = node.xpath('./state')[0]
        obj.current_status_date = self.parse_datetime(elem.get('datetime'))
        obj.current_status = BillStatus.by_xml_code(elem.text)

    def process_titles(self, obj, node):
        titles = []
        for elem in node.xpath('./titles/title'):
            text = unicode(elem.text) if elem.text else None
            titles.append((elem.get('type') + ("-partial" if elem.get("partial") == "1" else ""), elem.get('as'), text))
        obj.titles = titles
        
        # let the XML override the displayed bill number (American Memory bills)
        n = unicode(node.xpath('string(bill-number)'))
        if not n: n = None
        
        obj.title = get_primary_bill_title(obj, titles, override_number=n)

    def process_sponsor(self, obj, node):
        try:
            obj.sponsor = get_person(node.xpath('./sponsor')[0].get('id'))
            obj.sponsor_role = obj.sponsor.get_role_at_date(obj.introduced_date)
        except IndexError: # no sponsor node
            obj.sponsor = None
        except TypeError: # no id attribute
            obj.sponsor = None

    def process_consponsors(self, obj, node):
        for subnode in node.xpath('./cosponsors/cosponsor'):
            try:
                person = get_person(subnode.get('id'))
            except IndexError:
                log.error('Could not find cosponsor %s' % subnode.get('id'))
            else:
                joined = self.parse_datetime(subnode.get('joined'))
                
                role = person.get_role_at_date(joined)
                if not role:
                    log.error('Cosponsor %s did not have a role on %s' % (unicode(person), subnode.get('joined')))
                    continue

                value = subnode.get('withdrawn')
                withdrawn = self.parse_datetime(value) if value else None
                
                ob, isnew = Cosponsor.objects.get_or_create(
                    person=person,
                    bill=obj,
                    defaults={
                        "joined": joined,
                        "withdrawn": withdrawn,
                        "role": role
                    })
                if ob.joined != joined or ob.withdrawn != withdrawn:
                    ob.joined = joined
                    ob.withdrawn = withdrawn
                    ob.save()

    def session_handler(self, value):
        return int(value)

    def number_handler(self, value):
        return int(value)

    def process_committees(self, obj, node):
        comlist = []
        for subnode in node.xpath('./committees/committee'):
            if subnode.get('code') in ("", None):
                if obj.congress >= 93:
                    log.warn("Missing code attribute on committee %s." % subnode.get("name"))
                continue
            try:
                com = Committee.objects.get(code=subnode.get('code'))
            except Committee.DoesNotExist:
                log.error('Could not find committee %s' % subnode.get('code'))
            else:
                comlist.append(com)
        obj.committees = comlist

    def process_terms(self, obj, node, congress):
        termlist = []
        for subnode in node.xpath('./subjects/term'):
            name = subnode.get('name')
            try:
                termlist.append(get_term(name, congress))
            except KeyError:
                log.error('Could not find term [name: %s]' % name)
        obj.terms = termlist

    def process_relatedbills(self, obj, node):
        RelatedBill.objects.filter(bill=obj).delete()
        for subnode in node.xpath('./relatedbills/bill'):
            try:
                related_bill = Bill.objects.get(congress=subnode.get("session"), bill_type=BillType.by_xml_code(subnode.get("type")), number=int(subnode.get("number")))
            except Bill.DoesNotExist:
                continue
            RelatedBill.objects.create(bill=obj, related_bill=related_bill, relation=subnode.get("relation"))
                    


def main(options):
    """
    Process bill terms and bills
    """

    # Terms

    term_processor = TermProcessor()
    terms_parsed = set()
    
    # Cache existing terms. There aren't so many.
    existing_terms = { }
    for term in BillTerm.objects.all():
        existing_terms[(int(term.term_type), term.name)] = term

    log.info('Processing old bill terms')
    TERMS_FILE = 'data/us/liv.xml'
    tree = etree.parse(TERMS_FILE)
    for node in tree.xpath('/liv/top-term'):
        term = term_processor.process(BillTerm(), node)
        term.term_type = TermType.old
        try:
            # No need to update an existing term because there are no other attributes.
            term = existing_terms[(int(term.term_type), term.name)]
            terms_parsed.add(term.id)
        except:
            log.debug("Created %s" % term)
            term.save()
            term.subterms.clear()
            
        for subnode in node.xpath('./term'):
            subterm = term_processor.process(BillTerm(), subnode)
            subterm.term_type = TermType.old
            try:
                # No need to update an existing term because there are no other attributes.
                subterm = existing_terms[(int(subterm.term_type), subterm.name)]
                term.subterms.add(subterm) 
                terms_parsed.add(subterm.id)
            except:
                try:
                    log.debug("Created %s" % subterm)
                    subterm.save()
                    term.subterms.add(subterm)
                    
                    existing_terms[(int(subterm.term_type), subterm.name)] = subterm
                    terms_parsed.add(subterm.id)
                except IntegrityError:
                    log.error('Duplicated term %s' % term_processor.display_node(subnode))

    log.info('Processing new bill terms')
    for FILE in ('data/us/liv111.xml', 'data/us/crsnet.xml'):
        tree = etree.parse(FILE)
        for node in tree.xpath('/liv/top-term'):
            term = term_processor.process(BillTerm(), node)
            term.term_type = TermType.new
            try:
                # No need to update an existing term because there are no other attributes.
                term = existing_terms[(int(term.term_type), term.name)]
                terms_parsed.add(term.id)
            except:
                log.debug("Created %s" % term)
                term.save()
                term.subterms.clear()

            for subnode in node.xpath('./term'):
                subterm = term_processor.process(BillTerm(), subnode)
                subterm.term_type = TermType.new
                try:
                    # No need to update an existing term because there are no other attributes.
                    subterm = existing_terms[(int(subterm.term_type), subterm.name)]
                    terms_parsed.add(subterm.id)
                    term.subterms.add(subterm)
                except:
                    try:
                        log.debug("Created %s" % term)
                        subterm.save()
                        term.subterms.add(subterm)
                        
                        existing_terms[(int(subterm.term_type), subterm.name)] = subterm
                        terms_parsed.add(subterm.id)
                    except IntegrityError:
                        log.error('Duplicated term %s' % term_processor.display_node(subnode))

    for term in existing_terms.values():
        if not term.id in terms_parsed:
            log.debug("Deleted %s" % term)
            term.delete()

    # Bills
    
    bill_index = None
    if not options.disable_indexing:
        from bill.search_indexes import BillIndex
        bill_index = BillIndex()

    if options.congress and int(options.congress) <= 42:
        files = glob.glob('data/congress/%s/bills/*/*/*.xml' % options.congress)
        log.info('Parsing unitedstates/congress bills of only congress#%s' % options.congress)
    elif options.congress:
        files = glob.glob('data/us/%s/bills/*.xml' % options.congress)
        log.info('Parsing bills of only congress#%s' % options.congress)
    else:
        files = glob.glob('data/us/*/bills/*.xml')
        
    if options.filter:
        files = [f for f in files if re.match(options.filter, f)]
        
    log.info('Processing bills: %d files' % len(files))
    total = len(files)
    progress = Progress(total=total, name='files', step=100)

    bill_processor = BillProcessor()
    seen_bill_ids = []
    for fname in files:
        progress.tick()
        
        # With indexing or events enabled, if the bill metadata file hasn't changed check
        # the bill's latest text file for changes so we can create a text-is-available
        # event and so we can index the bill's text.
        if (not options.congress or options.congress>42) and (bill_index and not options.disable_events) and not File.objects.is_changed(fname) and not options.force:
            m = re.search(r"/(\d+)/bills/([a-z]+)(\d+)\.xml$", fname)

            try:
                b = Bill.objects.get(congress=m.group(1), bill_type=BillType.by_xml_code(m.group(2)), number=m.group(3))
                seen_bill_ids.append(b.id)
                
                # Update the index/events for any bill with recently changed text
                textfile = get_bill_text_metadata(b, None)
                if not textfile:
                    if b.congress >= 103 and b.introduced_date < (datetime.now()-timedelta(days=14)).date():
                        print "No bill text?", fname, b.introduced_date
                    continue
                textfile = textfile["text_file"]
                if os.path.exists(textfile) and File.objects.is_changed(textfile):
                    bill_index.update_object(b, using="bill") # index the full text
                    b.create_events() # events for new bill text documents
                    File.objects.save_file(textfile)
                    
                continue
            except Bill.DoesNotExist:
                print "Unchanged metadata file but bill doesn't exist:", fname
                pass # just parse as normal
            
        if options.slow:
            time.sleep(1)
            
        tree = etree.parse(fname)
        for node in tree.xpath('/bill'):
            try:
                bill = bill_processor.process(Bill(), node)
            except:
                print fname
                raise
           
            seen_bill_ids.append(bill.id) # don't delete me later
            
            if bill.congress >= 93:
                bill.source = "thomas-congproj"
            elif bill.congress >= 82:
                bill.source = "statutesatlarge"
            elif bill.congress <= 42:
                bill.source = "americanmemory"
            else:
                raise ValueError()

            # So far this is just for American Memory bills.
            if node.xpath("string(source/@url)"):
                bill.source_link = unicode(node.xpath("string(source/@url)"))
            else:
                bill.source_link = None

            actions = []
            for axn in tree.xpath("actions/*[@state]"):
                actions.append( (
                	repr(bill_processor.parse_datetime(axn.xpath("string(@datetime)"))),
                	BillStatus.by_xml_code(axn.xpath("string(@state)")),
                	axn.xpath("string(text)"),
                    etree.tostring(axn),
                	) )
                
            bill.sliplawpubpriv = None
            bill.sliplawnum = None
            for axn in tree.xpath("actions/enacted"):
                bill.sliplawpubpriv = "PUB" if axn.get("type") == "public" else "PRI"
                bill.sliplawnum = int(axn.get("number").split("-")[1])
                    
            bill.major_actions = actions
            try:
                bill.save()
            except:
                print bill
                raise
            if bill_index: bill_index.update_object(bill, using="bill")
            
            if not options.disable_events:
                bill.create_events()
                
        File.objects.save_file(fname)
        
    # delete bill objects that are no longer represented on disk.... this is too dangerous.
    if options.congress and not options.filter:
        # this doesn't work because seen_bill_ids is too big for sqlite!
        for b in Bill.objects.filter(congress=options.congress).exclude(id__in = seen_bill_ids):
            print "Bill is no longer on disk: ", b.id, b
        
    # The rest is for current only...
    
    if options.congress and int(options.congress) != CURRENT_CONGRESS:
        return
        
    # Parse docs.house.gov for what might be coming up this week.
    import iso8601
    dhg_html = urllib.urlopen("http://docs.house.gov/floor/").read()
    m = re.search(r"class=\"downloadXML\" href=\"(Download.aspx\?file=.*?)\"", dhg_html)
    if not m:
        log.error('No docs.house.gov download link found at http://docs.house.gov.')
    else:
        def bt_re(bt): return re.escape(bt[1]).replace(r"\.", r"\.?\s*")
        try:
            dhg = etree.parse(urllib.urlopen("http://docs.house.gov/floor/" + m.group(1))).getroot()
        except:
            print "http://docs.house.gov/floor/" + m.group(1)
            raise
        # iso8601.parse_date(dhg.get("week-date")+"T00:00:00").date()
        for item in dhg.xpath("category/floor-items/floor-item"):
            billname = item.xpath("legis-num")[0].text
            if billname is None: continue # weird but OK
            m = re.match(r"\s*(?:Concur in the Senate Amendment to |Senate Amendment to )?("
                + "|".join(bt_re(bt) for bt in BillType)
                + r")(\d+)\s*(\[Conference Report\]\s*)?$", billname, re.I)
            if not m:
                if not billname.strip().endswith(" __"):
                    log.error('Could not parse legis-num "%s" in docs.house.gov.' % billname)
            else:
                for bt in BillType:
                    if re.match(bt_re(bt) + "$", m.group(1), re.I):
                        try:
                            bill = Bill.objects.get(congress=CURRENT_CONGRESS, bill_type=bt[0], number=m.group(2))
                            bill.docs_house_gov_postdate = iso8601.parse_date(item.get("add-date")).replace(tzinfo=None)
                            bill.save()
                            if bill_index: bill_index.update_object(bill, using="bill")
                            
                            if not options.disable_events:
                                bill.create_events()
                        except Bill.DoesNotExist:
                            log.error('Could not find bill "%s" in docs.house.gov.' % billname)
                        break
                else:
                    log.error('Could not parse legis-num bill type "%s" in docs.house.gov.' % m.group(1))

    # Parse Senate.gov's "Floor Schedule" blurb for coming up tomorrow.
    now = datetime.now()
    sfs = urllib.urlopen("http://www.senate.gov/pagelayout/legislative/d_three_sections_with_teasers/calendars.htm").read()
    try:
        sfs = re.search(r"Floor Schedule([\w\W]*)Previous Meeting", sfs).group(1)
        for congress, bill_type, number in re.findall(r"http://hdl.loc.gov/loc.uscongress/legislation.(\d+)([a-z]+)(\d+)", sfs):
            bill_type = BillType.by_slug(bill_type)
            bill = Bill.objects.get(congress=congress, bill_type=bill_type, number=number)
            if bill.senate_floor_schedule_postdate == None or now - bill.senate_floor_schedule_postdate > timedelta(days=7):
                bill.senate_floor_schedule_postdate = now
                bill.save()
                if bill_index: bill_index.update_object(bill, using="bill")
                if not options.disable_events:
                    bill.create_events()
    except Exception as e:
        log.error('Could not parse Senate Floor Schedule: ' + repr(e))


if __name__ == '__main__':
    main()

########NEW FILE########
__FILENAME__ = committee_parser
"""
Parse list of committees which ever were in Congress.
Parse members of current congress committees.
"""
from lxml import etree
from datetime import datetime
import logging

from django.conf import settings

from parser.progress import Progress
from parser.processor import YamlProcessor, yaml_load
from parser.models import File
from committee.models import (Committee, CommitteeType, CommitteeMember,
                              CommitteeMemberRole, CommitteeMeeting)
from person.models import Person
from bill.models import Bill, BillType

import json, re
import common.enum

log = logging.getLogger('parser.committee_parser')

TYPE_MAPPING = {'senate': CommitteeType.senate,
                'joint': CommitteeType.joint,
                'house': CommitteeType.house}

ROLE_MAPPING = {
    'Ex Officio': CommitteeMemberRole.exofficio,
    'Chairman': CommitteeMemberRole.chairman,
    'Cochairman': CommitteeMemberRole.chairman, # huh!
    'Co-Chairman': CommitteeMemberRole.chairman, # huh!
    'Chair': CommitteeMemberRole.chairman,
    'Ranking Member': CommitteeMemberRole.ranking_member,
    'Vice Chairman': CommitteeMemberRole.vice_chairman,
    'Vice Chair': CommitteeMemberRole.vice_chairman,
    'Vice Chairwoman': CommitteeMemberRole.vice_chairman,
    'Member': CommitteeMemberRole.member,
}

class CommitteeMeetingProcessor(YamlProcessor):
    """
    Parser of committee meeting JSON files.
    """

    REQUIRED_ATTRIBUTES = ['committee', 'occurs_at', 'topic', 'guid']
    ATTRIBUTES = ['committee', 'subcommittee', 'occurs_at', 'topic', 'guid', 'room']
    FIELD_MAPPING = { 'occurs_at': 'when', 'topic': 'subject' }

    def committee_handler(self, value):
        return Committee.objects.get(code=value)

    def occurs_at_handler(self, value):
        return self.parse_datetime(value)


def main(options):
    """
    Process committees, subcommittees and
    members of current congress committees.
    """

    BASE_PATH = settings.CONGRESS_LEGISLATORS_PATH
    
    meeting_processor = CommitteeMeetingProcessor()

    log.info('Processing committees')
    COMMITTEES_FILE = BASE_PATH + 'committees-current.yaml'

    if not File.objects.is_changed(COMMITTEES_FILE) and not options.force:
        log.info('File %s was not changed' % COMMITTEES_FILE)
    else:
        tree = yaml_load(COMMITTEES_FILE)
        total = len(tree)
        progress = Progress(total=total)
        seen_committees = set()
        for committee in tree:
            try:
                cobj = Committee.objects.get(code=committee["thomas_id"])
            except Committee.DoesNotExist:
                print "New committee:", committee["thomas_id"]
                cobj = Committee(code=committee["thomas_id"])
               
            cobj.committee_type = TYPE_MAPPING[committee["type"]]
            cobj.name = committee["name"]
            cobj.url = committee.get("url", None)
            cobj.obsolete = False
            cobj.committee = None
            cobj.save()
            seen_committees.add(cobj.id)

            for subcom in committee.get('subcommittees', []):
                code = committee["thomas_id"] + subcom["thomas_id"]
                try:
                    sobj = Committee.objects.get(code=code)
                except Committee.DoesNotExist:
                    print "New subcommittee:", code
                    sobj = Committee(code=code)
                
                sobj.name = subcom["name"]
                sobj.url = subcom.get("url", None)
                sobj.type = None
                sobj.committee = cobj
                sobj.obsolete = False
                sobj.save()
                seen_committees.add(sobj.id)
                
            progress.tick()
            
        # Check for non-obsolete committees in the database that aren't in our
        # file.
        other_committees = Committee.objects.filter(obsolete=False).exclude(id__in=seen_committees)
        if len(other_committees) > 0:
            print "Marking obsolete:", ", ".join(c.code for c in other_committees)
            other_committees.update(obsolete=True)

        File.objects.save_file(COMMITTEES_FILE)
        
    log.info('Processing committee members')
    MEMBERS_FILE = BASE_PATH + 'committee-membership-current.yaml'
    file_changed = File.objects.is_changed(MEMBERS_FILE)

    if not file_changed and not options.force:
        log.info('File %s was not changed' % MEMBERS_FILE)
    else:
        # map THOMAS IDs to GovTrack IDs
        y = yaml_load(BASE_PATH + "legislators-current.yaml")
        person_id_map = { }
        for m in y:
            if "id" in m and "govtrack" in m["id"] and "thomas" in m["id"]:
                person_id_map[m["id"]["thomas"]] = m["id"]["govtrack"]
        
        # load committee members
        tree = yaml_load(MEMBERS_FILE)
        total = len(tree)
        progress = Progress(total=total, name='committees')
        
        # We can delete CommitteeMember objects because we don't have
        # any foreign keys to them.
        CommitteeMember.objects.all().delete()

        # Process committee nodes
        for committee, members in tree.items():
            try:
                cobj = Committee.objects.get(code=committee)
            except Committee.DoesNotExist:
                print "Committee not found:", committee
                continue

            # Process members of current committee node
            for member in members:
                mobj = CommitteeMember()
                mobj.person = Person.objects.get(id=person_id_map[member["thomas"]])
                mobj.committee = cobj
                if "title" in member:
                    mobj.role = ROLE_MAPPING[member["title"]]
                mobj.save()
            
            progress.tick()

        File.objects.save_file(MEMBERS_FILE)
        
    log.info('Processing committee schedule')
    for chamber in ("house", "senate"):
		meetings_file = 'data/congress/committee_meetings_%s.json' % chamber
		file_changed = File.objects.is_changed(meetings_file)
	
		if not file_changed and not options.force:
			log.info('File %s was not changed' % meetings_file)
		else:
			meetings = json.load(open(meetings_file))
			
			# Process committee event nodes
			for meeting in meetings:
				try:
					# Associate it with an existing meeting object if GUID is already known.
					# Must get it like this, vs just assigning the ID as we do in other parsers,
					# because of the auto_now_add created field, which otherwise misbehaves.
					try:
						mobj = CommitteeMeeting.objects.get(guid=meeting['guid'])
					except CommitteeMeeting.DoesNotExist:
						mobj = CommitteeMeeting()
					
					# Parse.
					mobj = meeting_processor.process(mobj, meeting)
					
					# Attach the meeting to the subcommittee if set.
					if mobj.subcommittee:
						mobj.committee = Committee.objects.get(code=mobj.committee.code + mobj.subcommittee)
					
					mobj.save()
					
					mobj.bills.clear()
					for bill in meeting["bills"]:
					    try:
					        bill_type, bill_num, bill_cong = re.match(r"([a-z]+)(\d+)-(\d+)$", bill).groups()
					        bill = Bill.objects.get(congress=bill_cong, bill_type=BillType.by_slug(bill_type), number=int(bill_num))
					        mobj.bills.add(bill)
					    except AttributeError:
					        pass # regex failed
					    except common.enum.NotFound:
					        pass # invalid bill type code in source data
					    except Bill.DoesNotExist:
					        pass # we don't know about bill yet
				except Committee.DoesNotExist:
					log.error('Could not load Committee object for meeting %s' % meeting_processor.display_node(meeting))
	
			for committee in Committee.objects.all():
				if not options.disable_events:
					committee.create_events()
				
			File.objects.save_file(meetings_file)
		

if __name__ == '__main__':
    main()

########NEW FILE########
__FILENAME__ = find_parser
"""
Parser of data/us/committees.xml
"""
from lxml import etree
from datetime import datetime
import glob
import re
import logging

from common.progress import Progress
from parser.processor import Processor

def main(options):
    "Method for testing different things"

    vars = set()
    files = glob.glob('data/us/*/bills/*.xml')
    progress = Progress(total=len(files))
    for fname in files:
        progress.tick()
        for event, elem in etree.iterparse(fname, events=('end',), tag='state'):
            vars.add(elem.text)
    for item in vars:
        print item


if __name__ == '__main__':
    main()

########NEW FILE########
__FILENAME__ = models
"""
Internal info about statuses
of previus parsings.
"""
import binascii
from StringIO import StringIO

from django.db import models

def crc(fname, content=None):
    """
    Calculate CRC-32 checksum of the file contents.
    """

    if content is not None:
        fobj = StringIO(content)
    else:
        fobj = open(fname, 'r')
    value = 0
    for line in fobj:
        value = binascii.crc32(line, value)
    value = value & 0xFFFFFFFF
    fobj.close()
    return "%08x" % value


class FileManager(models.Manager):
    def is_changed(self, path, content=None):
        """
        Compare checksum of the file stored in DB and
        the actual file on the disk.
        `is_changed`  is always true if no info about the file
        is stored in DB.
        """
        
        checksum = crc(path, content)
        try:
            fobj = File.objects.get(path=path)
        except File.DoesNotExist:
            return True
        else:
            return str(fobj.checksum) != checksum

    def save_file(self, path, content=None):
        """
        Save checksum of the file.
        """

        checksum = crc(path, content)
        try:
            fobj = File.objects.get(path=path)
        except File.DoesNotExist:
            fobj = File(path=path)
        fobj.checksum = checksum
        fobj.save()


class File(models.Model):
    """
    Store checksum of processed files.
    """

    path = models.CharField(max_length=100, db_index=True)
    checksum = models.CharField(max_length=8)
    processed = models.DateTimeField(auto_now=True)

    def __unicode__(self):
        return self.path

    objects = FileManager()

########NEW FILE########
__FILENAME__ = person_parser
"""
This script parse XML files and fill database
with Person and PersonRole objects.

Person model contains data about all people which were
a membe of Congress at least one time.

PersonRole contains data about role of current congress members.
"""
from datetime import datetime
import logging, pprint

from parser.progress import Progress
from parser.processor import YamlProcessor, yaml_load
from parser.models import File
from person.models import Person, PersonRole, Gender, RoleType, SenatorClass, SenatorRank

from settings import CURRENT_CONGRESS, CONGRESS_LEGISLATORS_PATH

log = logging.getLogger('parser.person_parser')

class PersonProcessor(YamlProcessor):
    """
    Person model contains data about all people which were
    a member of Congress at least one time.
    """

    REQUIRED_ATTRIBUTES = ['id__govtrack', 'name__first', 'name__last']
    ATTRIBUTES = [
        'id__govtrack', 'name__first', 'name__last',
        'name__middle', 'name__suffix', 'name__nickname',
        'id__bioguide', 'id__votesmart', 'id__opensecrets', 'id__cspan',
        'social__youtube', 'social__twitter',
        'bio__birthday', 'bio__gender',
    ]
    GENDER_MAPPING = {'M': Gender.male, 'F': Gender.female}
    FIELD_MAPPING = {
        'id__govtrack': 'id',
        'id__bioguide': 'bioguideid',
        'id__votesmart': 'pvsid',
        'id__opensecrets': 'osid',
        'id__cspan': 'cspanid',
        'social__youtube': 'youtubeid',
        'social__twitter': 'twitterid',
        'name__first': 'firstname',
        'name__last': 'lastname',
        'bio__birthday': 'birthday',
        'bio__gender': 'gender',
        'name__middle': 'middlename',
        'name__suffix': 'namemod',
        'name__nickname': 'nickname',
    }

    def bio__gender_handler(self, value):
        return self.GENDER_MAPPING[value]

    def bio__birthday_handler(self, value):
        return datetime.strptime(value, '%Y-%m-%d')

    def id__govtrack_handler(self, value):
        return int(value)
    def id__cspan_handler(self, value):
        return int(value)


class PersonRoleProcessor(YamlProcessor):
    """
    PersonRole contains data about role of current congress members.
    """

    REQUIRED_ATTRIBUTES = ['type', 'start', 'end']
    ATTRIBUTES = [
        'type', 'start', 'end', 'class', 'state_rank',
        'district', 'state', 'party', 'url', 'phone',
    ]
    FIELD_MAPPING = {
        'type': 'role_type',
        'start': 'startdate',
        'end': 'enddate',
        'class': 'senator_class',
        'state_rank': 'senator_rank',
        'url': 'website'
    }
    ROLE_TYPE_MAPPING = {
        'rep': RoleType.representative,
        'sen': RoleType.senator,
        'prez': RoleType.president,
        'viceprez': RoleType.vicepresident}
    SENATOR_CLASS_MAPPING = {1: SenatorClass.class1, 2: SenatorClass.class2,
                             3: SenatorClass.class3}
    SENATOR_RANK_MAPPING = {'senior': SenatorRank.senior, 'junior': SenatorRank.junior}

    def type_handler(self, value):
        return self.ROLE_TYPE_MAPPING[value]

    def start_handler(self, value):
        return datetime.strptime(value, '%Y-%m-%d').date()

    def end_handler(self, value):
        return datetime.strptime(value, '%Y-%m-%d').date()

    def class_handler(self, value):
        return self.SENATOR_CLASS_MAPPING[value]

    def state_rank_handler(self, value):
        return self.SENATOR_RANK_MAPPING[value]


def main(options):
    """
    Update Person and PersonRole models.
    
    Do safe update: touch only those records
    which have been changed.
    """

    BASE_PATH = CONGRESS_LEGISLATORS_PATH
    SRC_FILES = ['legislators-current', 'legislators-historical', 'legislators-social-media', 'executive'] # order matters

    for p in SRC_FILES:
        f = BASE_PATH + p + ".yaml"
        if not File.objects.is_changed(f) and not options.force:
            log.info('File %s was not changed' % f)
        else:
            # file modified...
            break
    else:
        # no 'break' ==> no files modified
        return

    # Start parsing.
    
    had_error = False

    # Get combined data.
    legislator_data = { }
    leg_id_map = { }
    for p in SRC_FILES:
        log.info('Opening %s...' % p)
        f = BASE_PATH + p + ".yaml"
        y = yaml_load(f)
        for m in y:
            if p != 'legislators-social-media':
                govtrack_id = m["id"].get("govtrack")
                
                # For the benefit of the social media file, make a mapping of IDs.
                for k, v in m["id"].items():
                    if type(v) != list:
                        leg_id_map[(k,v)] = govtrack_id
            else:
                # GovTrack IDs are not always listed in this file.
                govtrack_id = None
                for k, v in m["id"].items():
                    if type(v) != list and (k, v) in leg_id_map:
                        govtrack_id = leg_id_map[(k,v)]
                        break
            
            if not govtrack_id:
                print "No GovTrack ID:"
                pprint.pprint(m)
                had_error = True
                continue
                
            if govtrack_id not in legislator_data:
                legislator_data[govtrack_id] = m
            elif p == "legislators-social-media":
                legislator_data[govtrack_id]["social"] = m["social"]
            elif p == "executive":
                legislator_data[govtrack_id]["terms"].extend( m["terms"] )
            else:
                raise ValueError("Duplication in an unexpected way (%d, %s)." % (govtrack_id, p))
    
    person_processor = PersonProcessor()
    role_processor = PersonRoleProcessor()

    existing_persons = set(Person.objects.values_list('pk', flat=True))
    processed_persons = set()
    created_persons = set()

    progress = Progress(total=len(legislator_data))
    log.info('Processing persons')

    for node in legislator_data.values():
        # Wrap each iteration in try/except
        # so that if some node breaks the parsing process
        # then other nodes could be parsed
        try:
            person = person_processor.process(Person(), node)
            
            # Create cached name strings. This is done again later
            # after the roles are updated.
            person.set_names()

            # Now try to load the person with such ID from
            # database. If found it then just update it
            # else create new Person object
            try:
                ex_person = Person.objects.get(pk=person.pk)
                if person_processor.changed(ex_person, person) or options.force:
                    # If the person has PK of existing record,
                    # coming in via the YAML-specified GovTrack ID,
                    # then Django ORM will update existing record
                    if not options.force:
                        log.warn("Updated %s" % person)
                    person.save()
                    
            except Person.DoesNotExist:
                created_persons.add(person.pk)
                person.save()
                log.warn("Created %s" % person)

            processed_persons.add(person.pk)

            # Process roles of the person
            roles = list(PersonRole.objects.filter(person=person))
            existing_roles = set(PersonRole.objects.filter(person=person).values_list('pk', flat=True))
            processed_roles = set()
            role_list = []
            for role in node['terms']:
                role = role_processor.process(PersonRole(), role)
                role.person = person
                
                role.current = role.startdate <= datetime.now().date() and role.enddate >= datetime.now().date() # \
                        #and CURRENT_CONGRESS in role.congress_numbers()

                # Scan for most recent leadership role within the time period of this term,
                # which isn't great for Senators because it's likely it changed a few times
                # within a term, especially if there was a party switch.
                role.leadership_title = None
                for leadership_node in node.get("leadership_roles", []):
                    # must match on date and chamber
                    if leadership_node["start"] >= role.enddate.isoformat(): continue # might start on the same day but is for the next Congress
                    if "end" in leadership_node and leadership_node["end"] <= role.startdate.isoformat(): continue # might start on the same day but is for the previous Congress
                    if leadership_node["chamber"] != RoleType.by_value(role.role_type).congress_chamber.lower(): continue
                    role.leadership_title = leadership_node["title"]
                
                # Try to match this role with one already in the database.
                # First search for an exact match on type/start/end.
                ex_role = None
                for r in roles:
                    if role.role_type == r.role_type and r.startdate == role.startdate and r.enddate == role.enddate:
                        ex_role = r
                        break
                        
                # Otherwise match on type & either start or end only.
                if not ex_role:
                    for r in roles:
                        if role.role_type == r.role_type and (r.startdate == role.startdate or r.enddate == role.enddate):
                            ex_role = r
                            break

                if ex_role:    
                    # These roles correspond.
                    processed_roles.add(ex_role.id)
                    role.id = ex_role.id
                    if role_processor.changed(ex_role, role) or options.force:
                        role.save()
                        role_list.append(role)
                        if not options.force:
                            log.warn("Updated %s" % role)
                    roles.remove(ex_role) # don't need to try matching this to any other node
                else:
                    # Didn't find a matching role.
                    if len([r for r in roles if r.role_type == role.role_type]) > 0:
                        print role, "is one of these?"
                        for ex_role in roles:
                            print "\t", ex_role
                        raise Exception("There is an unmatched role.")
                    log.warn("Created %s" % role)
                    role.save()
                    role_list.append(role)
                        
            # create the events for the roles after all have been loaded
            # because we don't create events for ends of terms and
            # starts of terms that are adjacent.
            if not options.disable_events:
                for i in xrange(len(role_list)):
                    role_list[i].create_events(
                        role_list[i-1] if i > 0 else None,
                        role_list[i+1] if i < len(role_list)-1 else None
                        )
            
            removed_roles = existing_roles - processed_roles
            for pk in removed_roles:
                pr = PersonRole.objects.get(pk=pk)
                print pr.person.id, pr
                raise ValueError("Deleted role??")
                log.warn("Deleted %s" % pr)
                pr.delete()
            
            # The name can't be determined until all of the roles are set. If
            # it changes, re-save. Unfortunately roles are cached so this actually
            # doesn't work yet. Re-run the parser to fix names.
            nn = (person.name, person.sortname)
            if hasattr(person, "role"): delattr(person, "role") # clear the cached info
            person.set_names()
            if nn != (person.name, person.sortname):
                log.warn("%s is now %s." % (nn[0], person.name))
                person.save()
            
        except Exception, ex:
            # Catch unexpected exceptions and log them
            pprint.pprint(node)
            log.error('', exc_info=ex)
            had_error = True

        progress.tick()

    log.info('Processed persons: %d' % len(processed_persons))
    log.info('Created persons: %d' % len(created_persons))
    
    if not had_error:
        # Remove person which were not found in XML file
        removed_persons = existing_persons - processed_persons
        for pk in removed_persons:
            p = Person.objects.get(pk=pk)
            if p.roles.all().count() > 0:
                log.warn("Missing? Deleted? %d: %s" % (p.id, p))
            else:
                log.warn("Deleting... %d: %s (remember to prune_index!)" % (p.id, p))
                raise Exception("Won't delete!")
                p.delete()
        log.info('Missing/deleted persons: %d' % len(removed_persons))
    
        # Mark the files as processed.
        for p in SRC_FILES:
            f = BASE_PATH + p + ".yaml"
            File.objects.save_file(f)


if __name__ == '__main__':
    main()

########NEW FILE########
__FILENAME__ = processor
from datetime import datetime
from pprint import pformat

class InvalidNode(Exception):
    """
    Raised when XML Node contains invalid data.
    """

class Processor(object):
    REQUIRED_ATTRIBUTES = []
    ATTRIBUTES = []
    REQUIRED_NODES = []
    NODES = []
    FIELD_MAPPING = {}
    DEFAULT_VALUES = {}

    def process_attributes(self, obj, node):
        "Process attributes of XML node"

        attrib = self.get_node_attribute_keys(node)

        for key in self.ATTRIBUTES:
            if key in self.REQUIRED_ATTRIBUTES:
                if not key in attrib:
                    raise InvalidNode('Did not found required attribute %s in record %s' % (
                        key, self.display_node(node)))
            if key in attrib or key in self.DEFAULT_VALUES:
                field_name = self.FIELD_MAPPING.get(key, key)
                if key in attrib:
                    value = self.get_node_attribute_value(node, key)
                else:
                    value = self.DEFAULT_VALUES[key]
                setattr(obj, field_name, self.convert(key, value))

    def process_subnodes(self, obj, node):
        "Process subnodes of XML node"

        for key in self.NODES:
            try:
                subnode = self.get_node_child_value(node, key)
            except IndexError:
                if key in self.REQUIRED_NODES:
                    raise InvalidNode('Did not found required subnode %s in record %s' % (
                        key, self.display_node(node)))
                subnode = None
            if subnode is not None or key in self.DEFAULT_VALUES:
                field_name = self.FIELD_MAPPING.get(key, key)
                if subnode is not None:
                    value = subnode
                else:
                    value = self.DEFAULT_VALUES[key]
                setattr(obj, field_name, self.convert(key, value))

    def process_text(self, obj, node):
        "Process text content of the XML node"
        pass

    def process(self, obj, node):
        self.process_attributes(obj, node)
        self.process_subnodes(obj, node)
        self.process_text(obj, node)
        return obj

    def convert(self, key, value):
        key = key.replace("-", "_")
        if hasattr(self, '%s_handler' % key):
            return getattr(self, '%s_handler' % key)(value)
        else:
            return value

    @staticmethod
    def parse_datetime(value):
        try:
            return datetime.strptime(value, '%Y-%m-%d')
        except ValueError:
            try:
                return datetime.strptime(value, '%Y-%m-%dT%H:%M:%S-05:00')
            except ValueError:
                try:
                    return datetime.strptime(value, '%Y-%m-%dT%H:%M:%S-04:00')
                except ValueError:
                    return datetime.strptime(value, '%Y-%m-%dT%H:%M:%S')

    def is_model_field(self, obj, fieldname):
        from django.db.models import FieldDoesNotExist
        try:
            return obj._meta.get_field(fieldname) is not None # =! None breaks because of operator overloading
        except FieldDoesNotExist:
            return False

    def changed(self, old_value, new_value):
        # Since new_value hasn't been touched except for the fields we've set on it,
        # we can use its __dict__, except Django ORM's _state field, to check if any
        # fields have changed.
        new_value.clean_fields() # normalize field values, like DateTimes that get reduced to Dates
        for k in new_value.__dict__:
            if k != "id" and self.is_model_field(old_value, k):
                v1 = getattr(old_value, k)
                v2 = getattr(new_value, k)
                if v1 != v2:
                    print "Change in", k, "value of", unicode(old_value).encode("utf8"), ":", unicode(v1).encode("utf8"), "=>", unicode(v2).encode("utf8")
                    return True
        return False

class XmlProcessor(Processor):
    def display_node(self, node):
        return '<%s>: ' % node.tag + ', '.join('%s: %s' % x for x in node.attrib.iteritems())
    def get_node_attribute_keys(self, node):
        return node.attrib
    def get_node_attribute_value(self, node, attr):
        return node.get(attr)
    def get_node_child_value(self, node, name):
        # raise IndexError on failure
        subnode = node.xpath('./%s' % name)[0]
        return unicode(subnode.text)

class YamlProcessor(Processor):
    def display_node(self, node):
        return pformat(node)
    def get_node_attribute_keys(self, node):
        # handle a__b path names by scanning node recursively
        ret = set()
        for k, v in node.items():
            ret.add(k)
            if isinstance(v, dict):
                for k2 in self.get_node_attribute_keys(v):
                    ret.add(k + '__' + k2)
        return ret
    def get_node_attribute_value(self, node, attr):
        for k in attr.split('__'):
            node = node.get(k, None)
        return node
    def get_node_child_value(self, node, name):
        raise Exception("Not available for YAML files.")

def yaml_load(path):
    # Loading YAML is ridiculously slow. In congress-legislators's
    # utils, we cache the YAML in a pickled file which is a lot
    # faster. The format of the pickle file is incompatible with
	# what the congress project utils.py does, so use a different filename.

    import cPickle as pickle, os.path, hashlib
    import yaml
    try:
        from yaml import CSafeLoader as Loader, CDumper as Dumper
    except ImportError:
        from yaml import SafeLoader as Loader, Dumper

    # Check if the .pickle file exists and a hash stored inside it
    # matches the hash of the YAML file, and if so unpickle it.
    h = hashlib.sha1(open(path).read()).hexdigest()
    if os.path.exists(path + ".pickle2"):
        store = pickle.load(open(path + ".pickle2"))
        if store["hash"] == h:
            return store["data"]

    # No cached pickled data exists, so load the YAML file.
    data = yaml.load(open(path), Loader=Loader)

    # Store in a pickled file for fast access later.
    pickle.dump({ "hash": h, "data": data }, open(path+".pickle2", "w"))

    return data


########NEW FILE########
__FILENAME__ = progress
import sys
import logging

class Progress(object):
    def __init__(self, step=None, total=None, stop=None, name='items'):
        if not total and not step:
            raise Exception('Both step and total arguments are None')
        if total and not step:
            step = int(total / 20)
        self.step = step
        self.count = 0
        self.total = total
        self.stop = stop
        self.name = name
    
    def tick(self, x=None, y=None):
        self.count += 1
        if not self.count % self.step:
            if self.total:
                percents = ' [%d%%]' % int(round((self.count / float(self.total)) * 100))
            elif x and y:
                percents = ' [%d%%]' % int(round((x / float(y)) * 100))
            else:
                percents = ''
            logging.info('Processed %d %s%s' % (self.count, self.name, percents))
        if self.count == self.stop:
            logging.info('Reached stop value %d' % self.stop)
            sys.exit()

########NEW FILE########
__FILENAME__ = states_parser
"""
Parser of:
 * bill terms located in data/us/[liv, liv111, crsnet].xml
 * bills located in data/us/*/bills/*.xml
"""
import logging
import csv, os, hashlib, random
from datetime import datetime

from parser.progress import Progress
from parser.models import File
from states.models import StateChamberEnum, StateLegislator, StateSubjectTerm, StateSession, StateBill, StateBillAction, StateBillDocument

from django.db.utils import IntegrityError

csv.field_size_limit(1000000000) # _csv.Error: field larger than field limit (131072)

log = logging.getLogger('parser.states_parser')
now = datetime.now()

# Utility functions to cache objects and only save when the objects are popped from the cache.
cached_objs = { }
def cached_objs_pop(haystack_index):
    global cached_objs
    key = random.choice(list(cached_objs))
    obj = cached_objs[key]
    if getattr(obj, "needs_save", False):
        obj.save()
        if isinstance(obj, StateBill):
            obj.create_events()
            if haystack_index: haystack_index.update_object(obj, using="states")
        obj.needs_save = False
    del cached_objs[key]
def cached_objs_gc(haystack_index):
    global cached_objs
    while len(cached_objs) > 128:
        cached_objs_pop(haystack_index)
def cached_objs_clear(haystack_index):
    global cached_objs
    while len(cached_objs) > 0:
        cached_objs_pop(haystack_index)


# Utility class to read non-ASCII CSV files supporting NULL bytes indicating
# NULL values, a separate FD file with column headers, and return a decoded
# (unicode) dict for each row.
def BT50FileReader(stream, headerstream, encoding, **kwargs):
    # Remove null bytes which indicate database NULLs, leaving those fields
    # as just empty strings. NULL bytes make the csv.reader throw.
    def removeNulls(s):
        for line in s:
            yield line.replace("\0" ,"")
    stream = removeNulls(stream)
    
    headers = list(csv.reader(headerstream, delimiter='\t'))[0]
    
    csv_reader = csv.reader(stream, **kwargs)
    rownum = 0
    for values in csv_reader:
        rownum += 1
        if len(headers) != len(values):
            print "Wrong number of fields on line %d" % rownum
            continue
        #yield dict((headers[i], (values[i].decode(encoding, "replace")) if i < len(values) else None) for i in xrange(len(headers)))
        yield rownum, dict((headers[i], values[i].decode(encoding, "replace")) for i in xrange(len(headers)))

# Decorator wraps function in a check for whether the source file has been modified.
def iffilechanged(func):
    def g(options, filename, *args, **kwargs):
        if not File.objects.is_changed(filename) and not options.force:
            return None
        ret = func(options, filename, *args, **kwargs)
        File.objects.save_file(filename)
        return ret
    return g

# Decorator wraps a function to which we pass each row in a CSV file one by one.
def rowbyrow(func):
    def g(options, filename, *args, **kwargs):
        f = open(filename, "rb")
        
        progress = Progress(name='rows [%s]' % filename, step=2000)
        
        f.seek(0, os.SEEK_END)
        total=f.tell()
        f.seek(0, os.SEEK_SET)
        
        fmt = 'tsv'
        if "BillSubject" in filename: fmt = 'csv'

        for rownum, row in BT50FileReader(
            f, open(filename.replace(".txt", "FD.txt"), "rb"),
            "cp1252",
            delimiter = ',' if fmt == 'csv' else '\t',
            quotechar = '"' if fmt == 'csv' else None):
        
            # make a hash of the row so we can tell quickly if it's been changed, but
            # skip the LastUpdated column because it might be spurriously updated and
            # we don't care if the other fields didn't change anyway.
            row["_hash"] = hashlib.sha1(repr(sorted(kv for kv in row.items() if kv[0] != 'LastUpdated'))).hexdigest()
            
            rownum += 1
            progress.tick(x=f.tell(), y=total)
            
            try:
                func(row, options, filename, *args, **kwargs)
            except:
                print "Error in %s line %d." % (filename, rownum)
                raise
        return None
    return g

@iffilechanged
@rowbyrow
def process_legislators(row, options, filename):
    if row["StateCode"] == "US": return # duh, we have federal data already
    
    try:
        p = StateLegislator.objects.get(bt50id = row["LegislatorID"])
    except StateLegislator.DoesNotExist:
        p = StateLegislator()
        p.bt50id = row["LegislatorID"]
        
    if row["SunlightLegislatorID"] not in ("", "0"):
        p.openstatesid = row["SunlightLegislatorID"] # causing uniqueness violation
        StateLegislator.objects.filter(openstatesid=p.openstatesid).update(openstatesid=None)
    else:
        p.openstatesid = None
    if row["LegiScanLegislatorID"] not in ("", "0"):
    	p.legiscanid = row["LegiScanLegislatorID"]
    else:
   	    p.legiscanid = None
    
    p.state = row["StateCode"]
    p.firstname = row["FirstName"]
    p.lastname = row["LastName"]
    p.fullname = row["LegislatorName"]
    p.party = row["LegislatorParty"]
    
    p.save()

@iffilechanged
@rowbyrow
def process_subjects(row, options, filename):
    if row["StateCode"] == "US": return # duh, we have federal data already
    
    if row["StateSubjectID"] == "0":
        # Ignore the "unknown" term.
        return
    
    try:
        s = StateSubjectTerm.objects.get(bt50id = row["StateSubjectID"])
    except StateSubjectTerm.DoesNotExist:
        s = StateSubjectTerm()
        s.bt50id = row["StateSubjectID"]
        
    s.state = row["StateCode"]
    s.name = row["StateSubject"]
    
    s.save()

# TODO: unicameral?
chamber_map = {
	"lower": StateChamberEnum.lower, "upper": StateChamberEnum.upper,
	"initiative petition": StateChamberEnum.unknown,
	"": StateChamberEnum.unknown, "none": StateChamberEnum.unknown,
	"a": StateChamberEnum.unknown,
	"c": StateChamberEnum.unknown,
	}

@iffilechanged
@rowbyrow
def process_bills(row, options, filename, haystack_index):
    if row["StateCode"] == "US": return # duh, we have federal data already
    if row["IntroducedSession"].strip() == "": return # fake bills
    
    # dupes
    if row["BillID"] in ("207399", "207400"): return
    
    try:
        b = StateBill.objects.get(bt50id = row["BillID"])
        if b.srchash == row["_hash"]: return
    except StateBill.DoesNotExist:
        b = StateBill()
        b.bt50id = row["BillID"]
    
    if row["SunlightBillID"] not in ("", "0"):
        b.openstatesid = row["SunlightBillID"]
    else:
        b.openstatesid = None
    if row["LegiScanBillID"] not in ("", "0"):
        b.legiscanid = row["LegiScanBillID"]
    else:
        b.legiscanid = None
    
    session, isnew = StateSession.objects.get_or_create(
        state=row["StateCode"],
        name=row["IntroducedSession"],
        defaults={
            "slug": hashlib.sha1(row["IntroducedSession"]).hexdigest()[0:12]
        })
    b.state_session = session
    b.bill_number = row["StateBillID"]
    b.chamber = chamber_map[row["IntroducedChamber"].lower()]
    if row["StateCode"] in ("NE", "DC"): b.chamber = StateChamberEnum.unicameral # DC not in yet, but later?
    
    b.short_title = row["ShortBillName"]
    b.long_title = row["FullBillName"]
    b.summary = row["BillSummary"]
    
    b.srchash = row["_hash"]
    
    try:
        b.save() # save object instance
        if haystack_index: haystack_index.update_object(b, using="states") # index the full text
        if not options.disable_events: b.create_events() # create events to track
        
    except ValueError:
        import pprint
        pprint.pprint(row)
        #raise
    except IntegrityError as e:
        # For the sake of first import, skip errors.
        print row["BillID"], repr(e)

@iffilechanged
@rowbyrow
def process_bill_actions(row, options, filename, haystack_index):
    if row["StateCode"] == "US": return # duh, we have federal data already
    
    # Because the actions file has many entries for the same bill in a row,
    # try to cache the bill objects from call to call, and try to hold off
    # on saving bill instances until we pop them from the cache.

    global cached_objs

    if "b:" + row["BillID"] in cached_objs:
        b = cached_objs["b:" + row["BillID"]]
    else:
        cached_objs_gc(haystack_index)
        try:
            b = StateBill.objects.get(bt50id = row["BillID"])
        except StateBill.DoesNotExist as e:
            # Ignore parse errors.
            print e
            return
        cached_objs["b:" + row["BillID"]] = b
    
    when = datetime.strptime(row["ActionDate"], '%Y-%m-%d %H:%M:%S')
    if when > now: return # weird stuff
    seq = int(row["ActionOrder"])
    
    if not b.introduced_date or when.date() < b.introduced_date:
        b.introduced_date = when.date()
        b.needs_save = True # will be saved when popped from cache
    if not b.last_action_date or when.date() > b.last_action_date or (when.date() == b.last_action_date and seq > b.last_action_seq):
        b.last_action_date = when.date()
        b.last_action_seq = seq
        b.last_action_text = row["ActionDescription"]
        b.needs_save = True # will be saved when popped from cache

    # # Initialize StateSession start/end dates using bill action dates.
    # if "s:" + str(b.state_session_id) in cached_objs:
        # ss = cached_objs["s:" + str(b.state_session_id)]
    # else:
        # cached_objs_gc(haystack_index)
        # ss = b.state_session
        # cached_objs["s:" + str(ss.id)] = ss
    # if not ss.startdate or when.date() < ss.startdate:
        # ss.startdate = when.date()
        # ss.needs_save = True
    # if not ss.enddate or when.date() > ss.enddate:
        # ss.enddate = when.date()
        # ss.needs_save = True

    try:
        s = StateBillAction.objects.get(bt50id = row["ActionHistoryID"])
        if not options.force: return # assume actions don't change once created, unless --force is used
    except StateBillAction.DoesNotExist:
        s = StateBillAction()
        s.bt50id = row["ActionHistoryID"]
        
    save = not s.id or (s.bill != b or s.seq != seq or s.date != when or s.text != row["ActionDescription"])
        
    s.bill = b
    s.seq = seq
    s.date = when
    s.text = row["ActionDescription"]
    
    if not s.id or save:
        s.save()
        
        # trigger the creation of events, held until bill leaves cache
        b.needs_save = True

@iffilechanged
@rowbyrow
def process_bill_documents(row, options, filename, haystack_index):
    global cached_objs

    if row["StateCode"] == "US": return # duh, we have federal data already
    
    if "b:" + row["BillID"] in cached_objs:
        b = cached_objs["b:" + row["BillID"]]
    else:
        cached_objs_gc(haystack_index)
        try:
            b = StateBill.objects.get(bt50id = row["BillID"])
        except StateBill.DoesNotExist as e:
            # Ignore parse errors.
            print e
            return
        cached_objs["b:" + row["BillID"]] = b
    
    try:
        s = StateBillDocument.objects.get(bt50id = row["DocumentID"])
        if not options.force: return # assume documents don't change once created, unless --force is used
    except StateBillDocument.DoesNotExist:
        s = StateBillDocument()
        s.bt50id = row["DocumentID"]
        
    save = not s.id or(s.bill != b or s.type != row["DocumentName"] or s.url != row["DocumentPath"])
        
    s.bill = b
    s.type = row["DocumentName"]
    s.url = row["DocumentPath"]
    
    if not s.id or save:
        s.save()
    
def main(options):
    """
    Process state legislative data.
    """
    
    # Prepare indexing.
    haystack_index = None
    if not options.disable_indexing:
        from states.search_indexes import StateBillIndex
        haystack_index = StateBillIndex()

    # Load.
    process_legislators(options, "../extdata/billtrack50/tLegislator.txt")
    process_subjects(options, "../extdata/billtrack50/tStateSubject.txt")
    process_bills(options, "../extdata/billtrack50/tBill.txt", haystack_index)
    process_bill_documents(options, "../extdata/billtrack50/tDocument.txt", haystack_index)
    process_bill_actions(options, "../extdata/billtrack50/tActionHistory.txt", haystack_index)

    # Save any objects still in memory.    
    cached_objs_clear(haystack_index)

    # Set some final metadata on sessions.
    for s in StateSession.objects.all(): s.set_date_range()
    for s in StateSession.objects.all(): s.set_is_current()

########NEW FILE########
__FILENAME__ = tests
from django.test import TestCase

from parser.models import File

class FileTestCase(TestCase):
    def test_all_things(self):
        path = '/tmp/abcd_file_module'
        open(path, 'w').write('abc')
        self.assertTrue(File.objects.is_changed(path))
        File.objects.save_file(path=path)
        self.assertFalse(File.objects.is_changed(path))
        open(path, 'w').write('def')
        self.assertTrue(File.objects.is_changed(path))
        File.objects.save_file(path=path)
        self.assertFalse(File.objects.is_changed(path))
        self.assertTrue(File.objects.is_changed(path, content=':-)'))

        File.objects.save_file(path='/mario', content='xyz')
        self.assertFalse(File.objects.is_changed('/mario', content='xyz'))

########NEW FILE########
__FILENAME__ = util

########NEW FILE########
__FILENAME__ = vote_parser
"""
Parser of roll call votes
"""
from lxml import etree
import glob
import re
import logging

from parser.progress import Progress
from parser.processor import XmlProcessor
from person.models import Person, PersonRole
from person.types import RoleType
from parser.models import File
from bill.models import Bill, BillType, Amendment, AmendmentType
from vote.models import (Vote, VoteOption, VoteSource, Voter,
                         CongressChamber, VoteCategory, VoterType)

from django.template.defaultfilters import truncatewords

log = logging.getLogger('parser.vote_parser')

class VoteProcessor(XmlProcessor):
    """
    Parser of /roll records.
    """

    REQUIRED_ATTRIBUTES = ['source', 'datetime']
    ATTRIBUTES = ['source', 'datetime']
    REQUIRED_NODES = ['type', 'question', 'required', 'result']
    NODES = ['type', 'question', 'required', 'result', 'category']
    FIELD_MAPPING = {'datetime': 'created', 'type': 'vote_type'}
    SOURCE_MAPPING = {
        'senate.gov': VoteSource.senate,
        'house.gov': VoteSource.house,
        'keithpoole': VoteSource.keithpoole,
    }
    DEFAULT_VALUES = {'category': 'other'}
    CATEGORY_MAPPING = {
        'amendment': VoteCategory.amendment,
        'passage-suspension': VoteCategory.passage_suspension,
        'passage': VoteCategory.passage,
        'cloture': VoteCategory.cloture,
        'passage-part': VoteCategory.passage_part,
        'nomination': VoteCategory.nomination,
        'procedural': VoteCategory.procedural,
        'other': VoteCategory.other,
        'unknown': VoteCategory.unknown,
        'ratification': VoteCategory.ratification,
        'veto-override': VoteCategory.veto_override,
        'conviction': VoteCategory.conviction,
        'quorum': VoteCategory.procedural,
        'leadership': VoteCategory.procedural,
        'recommit': VoteCategory.procedural,
    }

    def category_handler(self, value):
        return self.CATEGORY_MAPPING[value]

    def source_handler(self, value):
        return self.SOURCE_MAPPING[value]

    def datetime_handler(self, value):
        return self.parse_datetime(value)

class VoteOptionProcessor(XmlProcessor):
    "Parser of /roll/option nodes"

    REQUIRED_ATTRIBUTES = ['key']
    ATTRIBUTES = ['key']

    def process_text(self, obj, node):
        obj.value = node.text


class VoterProcessor(XmlProcessor):
    "Parser of /roll/voter nodes"

    REQUIRED_ATTRIBUTES = ['id', 'vote']
    ATTRIBUTES = ['id', 'vote']
    FIELD_MAPPING = {'id': 'person', 'vote': 'option'}
    PERSON_CACHE = {}

    def process(self, options, obj, node):
        self.options = options
        obj = super(VoterProcessor, self).process(obj, node)

        if node.get('VP') == '1':
            obj.voter_type = VoterType.vice_president
        elif node.get('id') == '0':
            obj.voter_type = VoterType.unknown
        else:
            obj.voter_type = VoterType.member

        return obj


    def id_handler(self, value):
        if int(value):
            return self.PERSON_CACHE[int(value)]
        else:
            return None

    def vote_handler(self, value):
        return self.options[value]


def main(options):
    """
    Parse rolls.
    """
    
    # Setup XML processors
    vote_processor = VoteProcessor()
    option_processor = VoteOptionProcessor()
    voter_processor = VoterProcessor()
    voter_processor.PERSON_CACHE = dict((x.pk, x) for x in Person.objects.all())

    # The pattern which the roll file matches
    # Filename contains info which should be placed to DB
    # along with info extracted from the XML file
    re_path = re.compile('data/us/(\d+)/rolls/([hs])(\w+)-(\d+)\.xml')

    chamber_mapping = {'s': CongressChamber.senate,
                       'h': CongressChamber.house}

    if options.filter:
        files = glob.glob(options.filter)
        log.info('Parsing rolls matching %s' % options.filter)
    elif options.congress:
        files = glob.glob('data/us/%s/rolls/*.xml' % options.congress)
        log.info('Parsing rolls of only congress#%s' % options.congress)
    else:
        files = glob.glob('data/us/*/rolls/*.xml')
    log.info('Processing votes: %d files' % len(files))
    total = len(files)
    progress = Progress(total=total, name='files', step=10)

    def log_delete_qs(qs):
        if qs.count() > 0:
            try:
                print "Deleting: ", qs
            except Exception as e:
                print "Deleting [%s]..." % str(e)
            if qs.count() > 3:
                print "Delete skipped..."
                return
            qs.delete()

    seen_obj_ids = set()
    had_error = False

    for fname in files:
        progress.tick()

        match = re_path.search(fname)
        
        try:
            existing_vote = Vote.objects.get(congress=match.group(1), chamber=chamber_mapping[match.group(2)], session=match.group(3), number=match.group(4))
        except Vote.DoesNotExist:
            existing_vote = None
        
        if not File.objects.is_changed(fname) and not options.force and existing_vote != None and not existing_vote.missing_data:
            seen_obj_ids.add(existing_vote.id)
            continue
            
        try:
            tree = etree.parse(fname)
            
            ## Look for votes with VP tie breakers.
            #if len(tree.xpath("/roll/voter[@VP='1']")) == 0:
            #    had_error = True # prevent delete at the end
            #    continue
            
            # Process role object
            for roll_node in tree.xpath('/roll'):
                vote = vote_processor.process(Vote(), roll_node)
                if existing_vote: vote.id = existing_vote.id
                match = re_path.search(fname)
                vote.congress = int(match.group(1))
                vote.chamber = chamber_mapping[match.group(2)]
                vote.session = match.group(3)
                vote.number = int(match.group(4))
                
                # Get related bill & amendment.
                
                for bill_node in roll_node.xpath("bill"):
                    try:
                        vote.related_bill = Bill.objects.get(congress=bill_node.get("session"), bill_type=BillType.by_xml_code(bill_node.get("type")), number=bill_node.get("number"))
                    except Bill.DoesNotExist:
                        vote.missing_data = True

                for amdt_node in roll_node.xpath("amendment"):
                    if amdt_node.get("ref") == "regular":
                        try:
                            vote.related_amendment = Amendment.objects.get(congress=vote.related_bill.congress, amendment_type=AmendmentType.by_slug(amdt_node.get("number")[0]), number=amdt_node.get("number")[1:])
                        except Amendment.DoesNotExist:
                            print "Missing amendment", fname
                            vote.missing_data = True
                    elif amdt_node.get("ref") == "bill-serial":
                        # It is impossible to associate House votes with amendments just from the House
                        # vote XML because the amendment-num might correspond either with the A___ number
                        # or with the "An amendment, numbered ____" number from the amendment purpose,
                        # and there's really no way to figure out which. Maybe we can use the amendment
                        # sponsor instead?
                        #vote.related_amendment = Amendment.objects.get(bill=vote.related_bill, sequence=amdt_node.get("number"))
                        # Instead, we set related_amendment from the amendment parser. Here, we have to
                        # preserve the related_amendment if it is set.
                        if existing_vote: vote.related_amendment = existing_vote.related_amendment

                # clean up some question text and use the question_details field
                
                if vote.category in (VoteCategory.passage, VoteCategory.passage_suspension, VoteCategory.veto_override) and vote.related_bill:
                    # For passage votes, set the question to the bill title and put the question
                    # details in the details field.
                    vote.question = truncatewords(vote.related_bill.title, 20)
                    vote.question_details = vote.vote_type + " in the " + vote.get_chamber_display()
                    
                elif vote.category == VoteCategory.amendment and vote.related_amendment:
                    # For votes on amendments, make a better title/explanation.
                    vote.question = truncatewords(vote.related_amendment.title, 20)
                    vote.question_details = vote.vote_type + " in the " + vote.get_chamber_display()
                    
                elif vote.related_bill and vote.question.startswith("On the Cloture Motion " + vote.related_bill.display_number):
                    vote.question = "Cloture on " + truncatewords(vote.related_bill.title, 20)
                elif vote.related_bill and vote.question.startswith("On Cloture on the Motion to Proceed " + vote.related_bill.display_number):
                    vote.question = "Cloture on " + truncatewords(vote.related_bill.title, 20)
                    vote.question_details = "On Cloture on the Motion to Proceed in the " + vote.get_chamber_display()
                elif vote.related_bill and vote.question.startswith("On the Motion to Proceed " + vote.related_bill.display_number):
                    vote.question = "Motion to Proceed on " + truncatewords(vote.related_bill.title, 20)
                    
                elif vote.related_amendment and vote.question.startswith("On the Cloture Motion " + vote.related_amendment.get_amendment_type_display() + " " + str(vote.related_amendment.number)):
                    vote.question = "Cloture on " + truncatewords(vote.related_amendment.title, 20)
                    vote.question_details = vote.vote_type + " in the " + vote.get_chamber_display()
                
                # weird House foratting of bill numbers ("H RES 123 Blah blah")
                if vote.related_bill:
                    vote.question = re.sub(
                        "(On [^:]+): " + vote.related_bill.display_number.replace(". ", " ").replace(".", " ").upper() + " .*",
                        r"\1: " + truncatewords(vote.related_bill.title, 15),
                        vote.question)
                    
                vote.save()
                
                seen_obj_ids.add(vote.id) # don't delete me later
                
                # Process roll options, overwrite existing options where possible.
                seen_option_ids = set()
                roll_options = {}
                for option_node in roll_node.xpath('./option'):
                    option = option_processor.process(VoteOption(), option_node)
                    option.vote = vote
                    if existing_vote:
                        try:
                            option.id = VoteOption.objects.filter(vote=vote, key=option.key)[0].id # get is better, but I had the database corruption problem
                        except IndexError:
                            pass
                    option.save()
                    roll_options[option.key] = option
                    seen_option_ids.add(option.id)
                log_delete_qs(VoteOption.objects.filter(vote=vote).exclude(id__in=seen_option_ids)) # may cascade and delete the Voters too?

                # Process roll voters, overwriting existing voters where possible.
                if existing_vote:
                    existing_voters = dict(Voter.objects.filter(vote=vote).values_list("person", "id"))
                seen_voter_ids = set()
                for voter_node in roll_node.xpath('./voter'):
                    voter = voter_processor.process(roll_options, Voter(), voter_node)
                    voter.vote = vote
                    voter.created = vote.created
                        
                    # for VP votes, load the actual person...
                    if voter.voter_type == VoterType.vice_president:
                        try:
                            r = PersonRole.objects.get(role_type=RoleType.vicepresident, startdate__lte=vote.created, enddate__gte=vote.created)
                            voter.person = r.person
                        except:
                            # overlapping roles? missing data?
                            log.error('Could not resolve vice president in %s' % fname, exc_info=ex)
                        
                    if existing_vote and voter.person:
                        try:
                            voter.id = existing_voters[voter.person.id]
                        except KeyError:
                            pass
                        
                    voter.save()
                    
                    if voter.voter_type == VoterType.unknown and not vote.missing_data:
                        vote.missing_data = True
                        vote.save()
                        
                    seen_voter_ids.add(voter.id)
                    
                log_delete_qs(Voter.objects.filter(vote=vote).exclude(id__in=seen_voter_ids)) # possibly already deleted by cascade above

                vote.calculate_totals()

                if not options.disable_events:
                    vote.create_event()
                    
            File.objects.save_file(fname)

        except Exception, ex:
            log.error('Error in processing %s' % fname, exc_info=ex)
            had_error = True
        
    # delete vote objects that are no longer represented on disk
    if options.congress and not options.filter and not had_error:
        log_delete_qs(Vote.objects.filter(congress=options.congress).exclude(id__in = seen_obj_ids))

if __name__ == '__main__':
    main()

########NEW FILE########
__FILENAME__ = admin
# -*- coding: utf-8
from django.contrib import admin

from person.models import Person, PersonRole

class PersonRoleInline(admin.TabularInline):
    model = PersonRole

class PersonAdmin(admin.ModelAdmin):
    list_display = ['name', 'birthday', 'gender', 'bioguideid']
    search_fields = ['id', 'firstname', 'lastname']
    inlines = [PersonRoleInline]

class PersonRoleAdmin(admin.ModelAdmin):
    list_display = ['person', 'role_type', 'startdate', 'enddate', 'current']

admin.site.register(Person, PersonAdmin)
admin.site.register(PersonRole, PersonRoleAdmin)


########NEW FILE########
__FILENAME__ = analysis
import os
import csv, json
from us import parse_govtrack_date
from types import RoleType
from models import Person

from settings import CURRENT_CONGRESS

def load_data(person):
    return {
        "sponsorship": load_sponsorship_analysis(person),
        "missedvotes": load_votes_analysis(person),
        #"influence": load_influence_analysis(person),
    }
    
def load_sponsorship_analysis(person):
    role = person.get_most_recent_congress_role(excl_trivial=True)
    if not role: return None
    
    congressnumber = role.most_recent_congress_number()
    if not congressnumber: return None
    
    return load_sponsorship_analysis2(congressnumber, role.role_type, person)
    
def load_sponsorship_analysis2(congressnumber, role_type, person):
    data = { "congress": congressnumber, "current": congressnumber == CURRENT_CONGRESS }
    
    fname = 'data/us/%d/stats/sponsorshipanalysis' % congressnumber
    if role_type == RoleType.senator:
        fname += "_s.txt"
        data["chamber"] = "Senate"
    elif role_type == RoleType.representative:
        fname += "_h.txt"
        data["chamber"] = "House of Representatives"
    else:
        return None
    if not os.path.exists(fname): return None
    
    all_points = []
    data["all"] = all_points
    
    for line in open(fname).read().splitlines():
        chunks = [x.strip() for x in line.strip().split(',')]
        if chunks[0] == "ID": continue

        # Ignore members with low leadership scores because their ideology scores are inaccurate.
        if float(chunks[2]) < 0.1: continue

        pt = { }
        pt['id'] = int(chunks[0])
        pt['ideology'] = chunks[1]
        pt['leadership'] = chunks[2]
        pt['name'] = chunks[3]
        pt['party'] = chunks[4]
        pt['description'] = chunks[5]
        pt['introduced_bills'] = int(chunks[6])
        pt['cosponsored_bills'] = int(chunks[7])
        pt['unique_cosponsors'] = int(chunks[8])
        pt['total_cosponsors'] = int(chunks[9])
        
        if chunks[4] == "": continue # empty party means... not in office?
        
        if person and chunks[0] == str(person.pk):
            data.update(pt)
        else:
            all_points.append(pt)
            
    # sort, required by regroup tag
    all_points.sort(key = lambda item : item["party"])
            
    if person and not "ideology" in data: return None
    
    try:
        data.update(json.load(open(fname.replace(".txt", "_meta.txt"))))
    except IOError:
        pass # doesn't exist for past congresses
    
    return data
    
def load_votes_analysis(person):
    role = person.get_most_recent_congress_role()
    if not role: return None
    
    congressnumber = role.most_recent_congress_number()
    if not congressnumber: return None
    
    fn = 'data/us/%d/stats/person/missedvotes/%d.csv' % (congressnumber, person.pk)
    if not os.path.exists(fn): return None
    
    lifetime_rec = None
    time_recs = []
    for rec in csv.DictReader(open(fn)):
        # normalize the string CSV fields as we need them for display
        rec = {
            "congress": rec["congress"],
            "session": rec["session"],
            "chamber": rec["chamber"],
            "period": rec["period"],
            "total": int(rec["total_votes"]),
            "missed": int(rec["missed_votes"]),
            "percent": round(float(rec["percent"]), 1),
            "percentile": int(round(float(rec["percentile"]))),
            "firstdate": parse_govtrack_date(rec["period_start"]),
            "lastdate": parse_govtrack_date(rec["period_end"]),
            "pctile25": float(rec["pctile25"]),
            "pctile50": float(rec["pctile50"]),
            "pctile75": float(rec["pctile75"]),
            "pctile90": float(rec["pctile90"]),
        }
        # for historical data, the year is out of range for strftime. but if we replace the year we also have to
        # replace the month because a day may be out of range in Feburary depending on the day.
        if rec["firstdate"].year != rec["lastdate"].year:
            rec["time"] = rec["firstdate"].replace(year=1900, day=1).strftime("%b") + " " + str(rec["firstdate"].year) + "-" + rec["lastdate"].replace(year=1900, day=1).strftime("%b") + " " + str(rec["lastdate"].year)
        else:
            rec["time"] = str(rec["firstdate"].year) + " " + rec["firstdate"].replace(year=1900, day=1).strftime("%b-") + rec["lastdate"].replace(year=1900, day=1).strftime("%b")
        
        if rec["congress"] == "lifetime":
            # Take the "lifetime" record with the most recent period_start, since there may be one
            # record for the House and one record for the Senate.
            if lifetime_rec == None or lifetime_rec["firstdate"] < rec["firstdate"]:
                lifetime_rec = rec
        else:
            time_recs.append(rec)
            
    if lifetime_rec == None: return None
            
    # It's confusing to take records from two chambers, so filter by chamber.
    time_recs = [rec for rec in time_recs if rec["chamber"] == lifetime_rec["chamber"]]
    
    lifetime_rec["data"] = time_recs
    return lifetime_rec

def load_influence_analysis(person):
    influencers = []
    influencees = []
    
    # only the first 100 entries seemed to be helpful
    for line in open("/home/govtrack/scripts/analysis/influence_network_full.csv").readlines()[0:100]:
        influencer, influencee = line.strip().split(",")
        influencer = int(influencer)
        influencee = int(influencee)
        if person.id == influencer: influencees.append(influencee)
        if person.id == influencee: influencers.append(influencer)
    
    return { "influencers": Person.objects.in_bulk(influencers), "influencees": Person.objects.in_bulk(influencees) }
    

########NEW FILE########
__FILENAME__ = models
# -*- coding: utf-8 -*-
from django.db import models
from django.template.defaultfilters import slugify
from django.conf import settings
from django.core.cache import cache

import datetime, json, os.path
from dateutil.relativedelta import relativedelta

from common import enum
from person.types import Gender, RoleType, SenatorClass, SenatorRank, State
from name import get_person_name

from us import stateapportionment, get_congress_dates, statenames, get_congress_from_date, get_all_sessions

import functools
def cache_result(f):
    @functools.wraps(f)
    def g(self):
        if hasattr(self, "role"): return f(self)
        ckey = "cache_result_%s_%s_%d" % (self.__class__.__name__, f.__name__, self.id)
        v = cache.get(ckey)
        if not v:
            v = f(self)
            cache.set(ckey, v)
        return v
    return g

class Person(models.Model):
    """Members of Congress, Presidents, and Vice Presidents since the founding of the nation."""
	
    firstname = models.CharField(max_length=255, help_text="The person's first name or first initial.")
    lastname = models.CharField(max_length=255, help_text="The person's last name.")
    middlename = models.CharField(max_length=255, blank=True, help_text="The person's middle name (optional).")

    # misc
    birthday = models.DateField(blank=True, null=True, help_text="The person's birthday.")
    gender = models.IntegerField(choices=Gender, blank=True, null=True, help_text="The person's gender, if known. For historical data, the gender is sometimes not known.")
    
    # namemod set(['II', 'Jr.', 'Sr.', 'III', 'IV'])
    namemod = models.CharField(max_length=10, blank=True, help_text="The suffix on the person's name usually one of Jr., Sr., I, II, etc.")
    nickname = models.CharField(max_length=255, blank=True, help_text="The person's nickname. If set, the nickname should usually be displayed in quotes where a middle name would go. For instance, Joe \"Buster\" Smith.")

    # links
    bioguideid = models.CharField(max_length=255, blank=True, null=True, help_text="The person's ID on bioguide.congress.gov. May be null if the person served only as a president and not in Congress.")
    pvsid = models.CharField(max_length=255, blank=True, null=True, help_text="The person's ID on vote-smart.org (Project Vote Smart), if known.")
    osid = models.CharField(max_length=255, blank=True, null=True, help_text="The person's ID on opensecrets.org (The Center for Responsive Politics), if known.")
    youtubeid = models.CharField(max_length=255, blank=True, null=True, help_text="The name of the person's official YouTube channel, if known.")
    twitterid = models.CharField(max_length=50, blank=True, null=True, help_text="The name of the person's official Twitter handle, if known.")
    cspanid = models.IntegerField(blank=True, null=True, help_text="The ID of the person on CSPAN websites, if known.")
    
    # cached name info
    name = models.CharField(max_length=96, help_text="The person's full name with title, district, and party information for current Members of Congress, in a typical display format.")
    sortname = models.CharField(max_length=64, help_text="The person's name suitable for sorting lexicographically by last name or for display in a sorted list of names. Title, district, and party information are included for current Members of Congress.")
    

    # indexing
    def get_index_text(self):
        # We need to index the name, and also the name without
        # hard-to-type characters.
        def str2(s): return s if s != None else ""
        import unicodedata
        n = self.name_no_details().replace(u"\u201c", " ").replace(u"\u201d", " ")
        r = n + "\n" + \
            u"".join(c for c in unicodedata.normalize('NFKD', n) if not unicodedata.combining(c)) + "\n" + \
            str2(self.most_recent_role_state()) + " " + str2(statenames.get(self.most_recent_role_state()))
        return r
    haystack_index = ('lastname', 'gender')
    haystack_index_extra = (('most_recent_role_type', 'Char'), ('is_currently_serving', 'Boolean'), ('most_recent_role_state', 'Char'), ('most_recent_role_district', 'Integer'), ('most_recent_role_party', 'Char'), ('was_moc', 'Boolean'), ('is_currently_moc', 'Boolean'))
    #######
    # api
    api_recurse_on_single = ('roles', 'committeeassignments')
    api_additional_fields = {
        "link": lambda obj : settings.SITE_ROOT_URL + obj.get_absolute_url(),
    }
    api_example_id = 400326
    #######

    def __unicode__(self):
        return self.name

    @property
    def fullname(self):
        return u'%s %s' % (self.firstname, self.lastname)

    @cache_result
    def name_no_district(self):
        return get_person_name(self, firstname_position='before', show_suffix=True, role_recent=True, show_district=False)

    @cache_result
    def name_no_details(self):
        """The person's full name (excluding all title details)."""
        return get_person_name(self, firstname_position='before', show_suffix=True)
        
    @cache_result
    def name_no_details_lastfirst(self):
        return get_person_name(self, firstname_position='after')
            
    @cache_result
    def name_lastfirst_short(self):
        return get_person_name(self, firstname_position='after', firstname_style="nickname")
            
    @cache_result
    def name_and_title(self):
        return get_person_name(self, firstname_position='before', show_suffix=True, role_recent=True, show_party=False, show_district=False)

    @cache_result
    def name_lastonly(self):
        return get_person_name(self, firstname_position='none', show_suffix=False, role_recent=True, show_party=True, show_district=True)

    def set_names(self):
        self.sortname = get_person_name(self, firstname_position='after', role_recent=True, show_district=True, show_title=False, show_type=True)
        self.name = get_person_name(self, firstname_position='before', role_recent=True)

        
    @property
    def current_role(self):
        return self.get_current_role()
    def get_current_role(self):
        try:
            if not self.roles.all()._result_cache: # if this has already been feteched by prefetch_related
                return self.roles.get(current=True)
            else:
                return [r for r in self.roles.all() if r.current][0]
        except (PersonRole.DoesNotExist, IndexError):
            return None
    def is_currently_serving(self):
        return self.roles.filter(current=True).exists()

    def get_absolute_url(self):
        name = slugify('%s %s' % (self.firstname if not self.firstname.endswith(".") else self.middlename, self.lastname))
        name = name.replace('-', '_')
        return '/congress/members/%s/%d' % (name, self.pk)

    def get_age(self):
        if not self.birthday:
            return 0
        else:
            today = datetime.date.today()
            return relativedelta(today, self.birthday).years

    def roles_condensed(self):
        ret = []
        for role in self.roles.order_by('startdate'):
            if len(ret) > 0 and role.continues_from(ret[-1]):
                ret[-1].id = None # prevent corruption
                ret[-1].enddate = role.enddate
            else:
                ret.append(role)
        ret.reverse()
        return ret

    def get_role_at_date(self, when):
        if isinstance(when, datetime.datetime):
            when = when.date()
        
        # A person may have two roles on the same date, such as when simultaneously
        # resigning from the House to take office in the Senate. In that case, return the
        # most recent role.
        try:
            return self.roles.filter(startdate__lte=when, enddate__gte=when).order_by("-startdate")[0]
        except IndexError:
            return None

    def get_last_role_at_congress(self, congress):
        start, end = get_congress_dates(congress)
        try:
            return self.roles.filter(startdate__lte=end, enddate__gte=start).order_by('-startdate')[0]
        except IndexError:
            return None
            
    def get_role_at_year(self, year):
        try:
            return self.roles.filter(startdate__lte=("%d-12-31"%year), enddate__gte=("%d-01-01"%year)).order_by('-startdate')[0]
        except IndexError:
            return None
            
    _most_recent_role = None
    def get_most_recent_role(self):
        if self._most_recent_role: return self._most_recent_role
        try:
            if not self.roles.all()._result_cache: # if this has already been feteched by prefetch_related
                r = self.roles.order_by('-startdate')[0]
            else:
                r = sorted(self.roles.all(), key=lambda r : r.startdate, reverse=True)[0]
            self._most_recent_role = r
            return r
        except IndexError:
            return None
    def get_most_recent_congress_role(self, excl_trivial=False):
        for r in self.roles.filter(role_type__in=(RoleType.senator, RoleType.representative)).order_by('-startdate'):
            if excl_trivial and (r.enddate-r.startdate).days < 100: continue
            return r
        return None

    def get_most_recent_role_field(self, fieldname, current=False):
        if not current:
            role = self.get_most_recent_role()
        else:
            role = self.get_current_role()
        if not role: return None
        ret = getattr(role, fieldname)
        if callable(ret): ret = ret()
        return ret
    def most_recent_role_typeid(self, current=False):
        return self.get_most_recent_role_field('role_type', current=current)
    def most_recent_role_type(self, current=False):
        return self.get_most_recent_role_field('get_title', current=current)
    def most_recent_role_state(self, current=False):
        return self.get_most_recent_role_field('state', current=current)
    def most_recent_role_district(self, current=False):
        return self.get_most_recent_role_field('district', current=current)
    def most_recent_role_party(self, current=False):
        return self.get_most_recent_role_field('party', current=current)
    def most_recent_role_congress(self):
        return self.get_most_recent_role_field('most_recent_congress_number')
    def was_moc(self):
        if self.is_currently_moc(): return True # good for caching
        if not self.roles.all()._result_cache: # if this has already been feteched by prefetch_related
            return self.roles.filter(role_type__in=(RoleType.representative, RoleType.senator)).exists() # ability to exclude people who only were president
        else:
            return len([r for r in self.roles.all() if r.role_type in (RoleType.representative, RoleType.senator)])
        
    def is_currently_moc(self):
        r = self.get_most_recent_role() # good for caching
        if not r: return False # not even one role?
        return r.current and r.role_type in (RoleType.representative, RoleType.senator)
        
    def get_photo_url(self, size=100):
        """Return URL of 100px photo, or other specified size."""
        return '/data/photos/%d-%dpx.jpeg' % (self.pk, size)
    def get_photo_url_50(self):
        return self.get_photo_url(size=50)
    def get_photo_url_100(self):
        return self.get_photo_url(size=100)
    def has_photo(self, size=100):
        import os.path
        return os.path.exists("." + self.get_photo_url(size=size))

    class Meta:
        pass # ordering = ['lastname', 'firstname'] # causes prefetch related to be slow

    def vote_sources(self):
        from vote.models import Vote
        sources = set()
        for v in Vote.objects.filter(voters__person=self).values("source").distinct():
            if v["source"] in (1, 2):
                sources.add("congress")
            elif v["source"] == 3:
                sources.add("keithpoole")
        return sources

    def get_photo(self):
        size = 200
        photo_path = 'data/photos/%d-%dpx.jpeg' % (self.pk, size)
        if os.path.exists(photo_path):
            photo_url = '/' + photo_path
            with open(photo_path.replace("-%dpx.jpeg" % size, "-credit.txt"), "r") as f:
                photo_credit = f.read().strip().split(" ", 1)
                return photo_url, photo_credit
        else:
            return None, None

    @staticmethod
    def load_session_stats(session):
      # Which Congress is it?
        for congress, s, sd, ed in get_all_sessions():
            if s == session: break # leaves "congress" variable set
        else:
            raise ValueError("Invalid session: %s" % session)

        fn = "data/us/%d/stats/session-%s.json" % (congress, session)
        try:
            datafile = json.load(open(fn))
            datafile["meta"]["congress"] = congress # save where we got this from
            datafile["meta"]["session"] = session # save where we got this from
            datafile["meta"]["startdate"] = sd
            datafile["meta"]["enddate"] = ed
        except IOError:
            raise ValueError("No statistics are available for session %s." % session)

        return datafile

    def get_session_stats(self, session):
        datafile = Person.load_session_stats(session)
  
        if str(self.id) not in datafile["people"]:
            raise ValueError("No statistics available for person %d in session %s." % (self.id, session))

        stats = datafile["people"][str(self.id)]
        stats["meta"] = datafile["meta"] # copy this over
        return stats

    def get_feed(self, feed_type="p"):
        if feed_type not in ("p", "pv", "ps"): raise ValueError(feed_type)
        from events.models import Feed
        return Feed.objects.get_or_create(feedname="%s:%d" % (feed_type, self.id))[0]

    @staticmethod
    def from_feed(feed):
        if ":" not in feed.feedname or feed.feedname.split(":")[0] not in ("p", "pv", "ps"): raise ValueError(feed.feedname)
        return Person.objects.get(id=feed.feedname.split(":")[1])

class PersonRole(models.Model):
    """Terms held in office by Members of Congress, Presidents, and Vice Presidents. Each term corresponds with an election, meaning each term in the House covers two years (one 'Congress'), as President/Vice President four years, and in the Senate six years (three 'Congresses')."""
	
    person = models.ForeignKey('person.Person', related_name='roles')
    role_type = models.IntegerField(choices=RoleType, db_index=True, help_text="The type of this role: a U.S. senator, a U.S. congressperson, a U.S. president, or a U.S. vice president.")
    current = models.BooleanField(default=False, choices=[(False, "No"), (True, "Yes")], db_index=True, help_text="Whether the role is currently held, or if this is archival information.")
    startdate = models.DateField(db_index=True, help_text="The date the role began (when the person took office).")
    enddate = models.DateField(db_index=True, help_text="The date the role ended (when the person resigned, died, etc.)")
    # http://en.wikipedia.org/wiki/Classes_of_United_States_Senators
    senator_class = models.IntegerField(choices=SenatorClass, blank=True, null=True, db_index=True, help_text="For senators, their election class, which determines which years they are up for election. (It has nothing to do with seniority.)") # None for representatives
    senator_rank = models.IntegerField(choices=SenatorRank, blank=True, null=True, help_text="For senators, their state rank, i.e. junior or senior. For historical data, this is their last known rank.") # None for representatives
    # http://en.wikipedia.org/wiki/List_of_United_States_congressional_districts
    district = models.IntegerField(blank=True, null=True, db_index=True, help_text="For representatives, the number of their congressional district. 0 for at-large districts, -1 in historical data if the district is not known.") # None for senators/presidents
    state = models.CharField(choices=sorted(State, key = lambda x : x[0]), max_length=2, blank=True, db_index=True, help_text="For senators and representatives, the two-letter USPS abbrevation for the state or territory they are serving. Values are the abbreviations for the 50 states (each of which have at least one representative and two senators, assuming no vacancies) plus DC, PR, and the island territories AS, GU, MP, and VI (all of which have a non-voting delegate), and for really old historical data you will also find PI (Philippines, 1907-1946), DK (Dakota Territory, 1861-1889), and OR (Orleans Territory, 1806-1811) for non-voting delegates.")
    party = models.CharField(max_length=255, blank=True, null=True, db_index=True, help_text="The political party of the person. If the person changes party, it is usually the most recent party during this role.")
    website = models.CharField(max_length=255, blank=True, help_text="The URL to the official website of the person during this role, if known.")
    phone = models.CharField(max_length=64, blank=True, null=True, help_text="The last known phone number of the DC congressional office during this role, if known.")
    leadership_title = models.CharField(max_length=255, blank=True, null=True, help_text="The last known leadership role held during this role, if any.")

    # API
    api_recurse_on = ('person',)
    api_additional_fields = {
        "title": "get_title_abbreviated",
        "title_long": "get_title",
        "description": "get_description",
        "congress_numbers": "congress_numbers",
    }
    api_example_parameters = { "current": "true", "sort": "state" }

    class Meta:
        pass # ordering = ['startdate'] # causes prefetch_related to be slow

    def __unicode__(self):
        return '%s / %s to %s / %s' % (self.person.fullname, self.startdate, self.enddate, self.get_role_type_display())
       
    def continues_from(self, prev):
        if self.startdate - prev.enddate > datetime.timedelta(days=120): return False
        if self.role_type != prev.role_type: return False
        if self.senator_class != prev.senator_class: return False
        if self.state != prev.state: return False
        if self.district != prev.district: return False
        return True

    def get_title(self):
        """The long form of the title used to prefix the names of people with this role: Representative, Senator, President, Delegate, or Resident Commissioner."""
        return self.get_title_name(short=False)

    def get_title_abbreviated(self):
        """The title used to prefix the names of people with this role: Rep., Sen., President, Del. (delegate), or Commish. (resident commissioner)."""
        return self.get_title_name(short=True)

    def get_title_name(self, short):
        if self.role_type == RoleType.president:
            return 'President'
        if self.role_type == RoleType.vicepresident:
            return 'Vice President'
        if self.role_type == RoleType.senator:
            return 'Sen.' if short else 'Senator'
        if self.role_type == RoleType.representative:
            if not self.state in stateapportionment:
                return 'Del.' if short else 'Delegate'
            if self.state == 'PR':
                return 'Commish.' if short else 'Resident Commissioner'
            if stateapportionment[self.state] == 'T':
                return 'Del.' if short else 'Delegate'
            return 'Rep.' if short else 'Representative'
            
    def state_name(self):
        return State.by_value(self.state).label
            
    def get_description(self):
        """A description of this role, e.g. Delegate for District of Columbia At Large."""
        
        from django.contrib.humanize.templatetags.humanize import ordinal
        
        if self.role_type == RoleType.president:
            return self.get_title_name(False)
        if self.role_type == RoleType.vicepresident:
            return self.get_title_name(False)
        if self.role_type == RoleType.senator:
            js = ""
            if self.current and self.senator_rank: js = self.get_senator_rank_display() + " "
            return js + self.get_title_name(False) + " from " + statenames[self.state]
        if self.role_type == RoleType.representative:
            if self.district == -1:
                return self.get_title_name(False) + " for " + statenames[self.state]
            elif self.district == 0:
                return self.get_title_name(False) + " for " + statenames[self.state] + " At Large"
            else:
                return self.get_title_name(False) + " for " + statenames[self.state] + "'s " + ordinal(self.district) + " congressional district"

    def congress_numbers(self):
        """The Congressional sessions (Congress numbers) that this role spans, as a list from the starting Congress number through consecutive numbers to the ending Congress number."""
        # Senators can span Congresses, so return a range.
        c1 = get_congress_from_date(self.startdate, range_type="start")
        c2 = get_congress_from_date(self.enddate, range_type="end")
        if not c1 or not c2: return None
        return range(c1, c2+1) # congress number only, not session

    def most_recent_congress_number(self):
        n = self.congress_numbers()
        if not n: return None
        n = n[-1]
        if n > settings.CURRENT_CONGRESS: n = settings.CURRENT_CONGRESS # we don't ever mean to ask for a future one (senators, PR res com)
        return n

    @property
    def leadership_title_full(self):
        if not self.leadership_title: return None
        if self.leadership_title == "Speaker": return "Speaker of the House"
        return RoleType.by_value(self.role_type).congress_chamber + " " + self.leadership_title

    def create_events(self, prev_role, next_role):
        now = datetime.datetime.now().date()
        from events.models import Feed, Event
        with Event.update(self) as E:
            f = self.person.get_feed()
            if not prev_role or not self.continues_from(prev_role):
                E.add("termstart", self.startdate, f)
            if not next_role or not next_role.continues_from(self):
                if self.enddate <= now: # because we're not sure of end date until it happens
                    E.add("termend", self.enddate, f)
        
    def render_event(self, eventid, feeds):
        self.person.role = self # affects name generation
        return {
            "type": "Elections and Offices",
            "date_has_no_time": True,
            "date": self.startdate if eventid == "termstart" else self.enddate,
            "title": self.person.name + (" takes office as " if eventid == "termstart" else " leaves office as ") + self.get_description(),
            "url": self.person.get_absolute_url(),
            "body_text_template": "",
            "body_html_template": "",
            "context": {}
            }

    def logical_dates(self):
        startdate = None
        enddate = None
        prev_role = None
        found_me = False
        for role in self.person.roles.filter(role_type=self.role_type, senator_class=self.senator_class, state=self.state, district=self.district).order_by('startdate'):
            if found_me and not role.continues_from(prev_role):
                break
            if prev_role == None or not role.continues_from(prev_role):
                startdate = role.startdate
            enddate = role.enddate
            prev_role = role
            if role.id == self.id:
                found_me = True
        if not found_me: raise Exception("Didn't find myself?!")
        return (startdate, enddate)

    def next_election_year(self):
        # For current terms, roles end at the end of a Congress on Jan 3.
        # The election occurs in the year before.
        if not self.current: raise ValueError()
        return self.enddate.year-1

    def get_most_recent_session_stats(self):
        # Which Congress and session's end date is the most recently covered by this role?
        errs = []
        congresses = self.congress_numbers()
        for congress, session, sd, ed in reversed(get_all_sessions()):
            if congress not in congresses: continue
            if self.startdate < ed <= self.enddate:
                try:
                    return self.person.get_session_stats(session)
                except ValueError as e:
                    errs.append(unicode(e))
        raise ValueError("No statistics are available for this role: %s" % "; ".join(errs))

    def opposing_party(self):
        if self.party == "Democrat": return "Republican"
        if self.party == "Republican": return "Democrat"
        return None

# Feeds

from events.models import Feed
Feed.register_feed(
    "p:",
    title = lambda feed : Person.from_feed(feed).name,
    noun = "person",
    includes = lambda feed : [Person.from_feed(feed).get_feed("pv"), Person.from_feed(feed).get_feed("ps")],
    link = lambda feed: Person.from_feed(feed).get_absolute_url(),
    scoped_title = lambda feed : "All Events for " + Person.from_feed(feed).lastname,
    category = "federal-other",
    description = "You will get updates about major activity on sponsored bills and how this Member of Congress votes in roll call votes.",
    )
Feed.register_feed(
    "ps:",
    title = lambda feed : Person.from_feed(feed).name + " - Bills Sponsored",
    noun = "person",
    link = lambda feed: Person.from_feed(feed).get_absolute_url(),
    scoped_title = lambda feed : Person.from_feed(feed).lastname + "'s Sponsored Bills",
    category = "federal-bills",
    description = "You will get updates about major activity on bills sponsored by this Member of Congress.",
    )
Feed.register_feed(
    "pv:",
    title = lambda feed : Person.from_feed(feed).name + " - Voting Record",
    noun = "person",
    link = lambda feed: Person.from_feed(feed).get_absolute_url(),
    scoped_title = lambda feed : Person.from_feed(feed).lastname + "'s Voting Record",
    single_event_type = True,
    category = "federal-votes",
    description = "You will get updates on how this Member of Congress votes in roll call votes.",
)

########NEW FILE########
__FILENAME__ = name
from datetime import datetime

from person.models import RoleType

def get_person_name(person,
				firstname_position=None, show_suffix=False, firstname_style=None,
				role_date=None, role_congress=None, role_recent=None, role_year=None,
                show_title=True, show_party=True, show_district=True, show_type=False):
    """
    Args:
        role_date - the date from which the person role should be extracted
        role_congress - the congress number from which the person role should be extracted
    """

    firstname = person.firstname

    if firstname.endswith('.'):
        firstname = person.middlename
        
    if person.nickname:
        if firstname_style == None:
            firstname += u" \u201c%s\u201d" % person.nickname
        elif firstname_style == "nickname" and len(person.nickname) < len(firstname):
            firstname = person.nickname
 
    if firstname_position == 'before':
        name = firstname + ' ' + person.lastname
    elif firstname_position == 'after':
        name = person.lastname + ', ' + firstname
    else:
        name = person.lastname
        
    if show_suffix:
        if person.namemod:
            name += ' ' + person.namemod
    
    if hasattr(person, "role"):
        role = person.role # use this when it is set
        role_recent = False
    if role_congress:
        role = person.get_last_role_at_congress(role_congress)
    elif role_date:
        role = person.get_role_at_date(role_date)
    elif role_year:
    	role = person.get_role_at_year(role_year)
    elif role_recent:
    	role = person.get_most_recent_role()
    else:
    	return name
        
    if role is None:
        return name
 
    if show_title:
        name = role.get_title_abbreviated() + ' ' + name
 
    if show_type:
        name += " (%s)" % role.get_title_abbreviated()
        
    if role and role.role_type in (RoleType.president, RoleType.vicepresident):
        show_district = False
 
    if show_party or show_district:
        name += ' ['
        if show_party:
            name += role.party[0] if role.party else '?'
        if show_party and show_district:
            name += '-'
        if show_district:
            name += role.state
            if role.role_type == RoleType.representative:
                name += str(role.district)
                
        if role_recent and not role.current:
        	a, b = role.logical_dates()
        	name += ", %d-%d" % (a.year, b.year)
        	
        name += ']'
                 
    return name

########NEW FILE########
__FILENAME__ = search
from django import forms
from django.utils.safestring import mark_safe
from django.contrib.humanize.templatetags.humanize import ordinal
from django.template import Context

from smartsearch.manager import SearchManager

from person.models import Person, PersonRole
from person.types import RoleType
from name import get_person_name
from us import statenames

import os.path

years = [(x, str(x)) for x in xrange(2011, 1788, -1)]

def name_filter(qs, form):
    name = form["name"]
    if name.strip() != "":
        qs = qs.filter(lastname__startswith=name.strip())
    return qs

def year_filter(qs, form):
    year = form['roles__year']
    if year != '':
        qs = qs.filter(roles__startdate__lte=("%d-12-31"%int(year)), roles__enddate__gte=("%d-01-01"%int(year)))
    return qs
    
def current_filter(qs, form):
    # since individuals can have both current and non-current roles, the
    # right way to filter when current is false is to exclude anyone
    # with a current role, not to find roles that are not-current.
    if not "roles__current" in form:
        return qs
    elif form["roles__current"] == "true":
        qs = qs.filter(roles__current=True)
    elif form["roles__current"] == "false":
        qs = qs.exclude(roles__current=True)
    return qs
    
def sort_filter(qs, form):
    if form["sort"] == 'name':
        qs = qs.order_by('lastname', 'firstname')
    if form["sort"] == 'district':
        qs = qs.order_by('roles__state', 'roles__district', 'roles__startdate', 'lastname', 'firstname')
    return qs

def template_get_context(obj, form):
    c = Context({ "object": obj, "form": form })
    try:
        if "roles__year" in form:
            c["description"] = obj.get_role_at_year(int(form["roles__year"])).get_description()
        elif form.get("roles__current", "__ALL__") == "true":
            c["description"] = obj.get_current_role().get_description()
        else:
            role = obj.get_most_recent_role()
            a, b = role.logical_dates()
            c["description"] = role.get_description() + ", %d-%d" % (a.year, b.year)
    except Exception as e:
        pass
    return c

def person_search_manager():
    sm = SearchManager(Person, connection="person")
    
    sm.add_filter("was_moc__in", [True]) # exclude presidents/vice presidents
    
    sm.add_option('text', label='name', type="text")
    sm.add_option('is_currently_moc', label="currently serving?", type="radio", choices=[(False, "No"), (True, "Yes")])
    sm.add_option('most_recent_role_type', label="senator or representative", type="radio", formatter = lambda v : v.capitalize())
    sm.add_option('most_recent_role_state', label="state", type="select", formatter = lambda state : statenames[state.upper()], sort="LABEL")
    sm.add_option('most_recent_role_district', label="district", type="select", formatter = lambda v : "At Large" if v == 0 else ordinal(v), visible_if=lambda form:"most_recent_role_state" in form, sort="KEY")
    sm.add_option('most_recent_role_party', label="party", type="select", formatter = lambda v : v.capitalize())
    sm.add_option('gender')
    sm.add_sort("Last Name", "lastname", default=True)
    
    # sm.add_option('name', label='last name', type="text", filter=name_filter, choices="NONE")
    # sm.add_option('roles__current', label="currently serving?", type="radio", filter=current_filter)
    # sm.add_option('roles__year', label="year served", type="select", visible_if=lambda form : form.get("roles__current", "__ALL__") == "false", filter=year_filter, choices=years)
    # sm.add_option('roles__role_type', label="chamber")
    # sm.add_option('roles__state', label='state', sort=False, type="select")
    # sm.add_option('roles__district', label='district', sort=False, choices=[('0', 'At Large')] + [(x, str(x)) for x in xrange(1, 53+1)], type="select", visible_if=lambda form : form.get("roles__state", "__ALL__") != "__ALL__" and unicode(RoleType.representative) in form.getlist("roles__role_type[]"))
    # sm.add_option('roles__party', label='party', type="select")
    # sm.add_option('gender')
    # sm.add_option('sort', label='sort by', choices=[('name', 'name'), ('district', 'state/district, then year')], filter=sort_filter, type="radio", required=True)
    
    sm.set_template("""
    	<div style="float: left; margin-right: 1.5em">
			{% if object.has_photo %}
				<img src="{{object.get_photo_url_50}}" width="50" height="60"/>
			{% else %}
				<div style="border: 1px solid black; width: 50px; height: 60px;"/>
			{% endif %}
		</div>
    	<a href="{{object.get_absolute_url}}" style="margin-top: 4px">{{object.name_no_details_lastfirst}}</a>
    	<div>{{description}}</div>
	""")
    sm.set_template_context_func(template_get_context)

    return sm
    


########NEW FILE########
__FILENAME__ = search_indexes
from models import Person
from smartsearch import build_haystack_index

PersonIndex = build_haystack_index(Person)


########NEW FILE########
__FILENAME__ = persontags
from django import template

from person.types import Gender

register = template.Library()

@register.filter
def hisher(person):
	if person.gender == Gender.male:
		return "his"
	else:
		return "her"


########NEW FILE########
__FILENAME__ = types
from common import enum

class Gender(enum.Enum):
    male = enum.Item(1, 'Male', pronoun="he", pronoun_object="him", pronoun_posessive="his")
    female = enum.Item(2, 'Female', pronoun="she", pronoun_object="her", pronoun_posessive="her")


class RoleType(enum.Enum):
    senator = enum.Item(1, 'Senator', congress_chamber='Senate', congress_chamber_other="House")
    representative = enum.Item(2, 'Representative', congress_chamber='House', congress_chamber_other="Senate")
    president = enum.Item(3, 'President')
    vicepresident = enum.Item(4, 'Vice President')


class SenatorClass(enum.Enum):
    class1 = enum.Item(1, 'Class 1')
    class2 = enum.Item(2, 'Class 2')
    class3 = enum.Item(3, 'Class 3')

class SenatorRank(enum.Enum):
    # the order is used by order_by on the district maps page
    senior = enum.Item(1, 'Senior')
    junior = enum.Item(2, 'Junior')


class State(enum.Enum):
    """
    For senators and representatives, the state attribute gives the USPS state abbreviation of the state or territory they represent. Besides the 50 states, this includes delegates from American Samoa (AS), District of Columbia (DC), Guam (GU), Northern Mariana Islands (MP), Puerto Rico (PR), Virgin Islands (VI), and the former (for historical data) Dakota Territory (DK), Philippines Territory/Commonwealth (PI), and Territory of Orleans (OL).
    """

    # U.S. States
    AL = enum.Item('AL', 'Alabama')
    AK = enum.Item('AK', 'Alaska')
    AZ = enum.Item('AZ', 'Arizona')
    AR = enum.Item('AR', 'Arkansas')
    CA = enum.Item('CA', 'California')
    CO = enum.Item('CO', 'Colorado')
    CT = enum.Item('CT', 'Connecticut')
    DE = enum.Item('DE', 'Delaware')
    DC = enum.Item('DC', 'District of Columbia')
    FL = enum.Item('FL', 'Florida')
    GA = enum.Item('GA', 'Georgia')
    HI = enum.Item('HI', 'Hawaii')
    ID = enum.Item('ID', 'Idaho')
    IL = enum.Item('IL', 'Illinois')
    IN = enum.Item('IN', 'Indiana')
    IA = enum.Item('IA', 'Iowa')
    KS = enum.Item('KS', 'Kansas')
    KY = enum.Item('KY', 'Kentucky')
    LA = enum.Item('LA', 'Louisiana')
    ME = enum.Item('ME', 'Maine')
    MT = enum.Item('MT', 'Montana')
    NE = enum.Item('NE', 'Nebraska')
    NV = enum.Item('NV', 'Nevada')
    NH = enum.Item('NH', 'New Hampshire')
    NJ = enum.Item('NJ', 'New Jersey')
    NM = enum.Item('NM', 'New Mexico')
    NY = enum.Item('NY', 'New York')
    NC = enum.Item('NC', 'North Carolina')
    ND = enum.Item('ND', 'North Dakota')
    OH = enum.Item('OH', 'Ohio')
    OK = enum.Item('OK', 'Oklahoma')
    OR = enum.Item('OR', 'Oregon')
    MD = enum.Item('MD', 'Maryland')
    MA = enum.Item('MA', 'Massachusetts')
    MI = enum.Item('MI', 'Michigan')
    MN = enum.Item('MN', 'Minnesota')
    MS = enum.Item('MS', 'Mississippi')
    MO = enum.Item('MO', 'Missouri')
    PA = enum.Item('PA', 'Pennsylvania')
    RI = enum.Item('RI', 'Rhode Island')
    SC = enum.Item('SC', 'South Carolina')
    SD = enum.Item('SD', 'South Dakota')
    TN = enum.Item('TN', 'Tennessee')
    TX = enum.Item('TX', 'Texas')
    UT = enum.Item('UT', 'Utah')
    VT = enum.Item('VT', 'Vermont')
    VA = enum.Item('VA', 'Virginia')
    WA = enum.Item('WA', 'Washington')
    WV = enum.Item('WV', 'West Virginia')
    WI = enum.Item('WI', 'Wisconsin')
    WY = enum.Item('WY', 'Wyoming')

    # Other
    AS = enum.Item('AS', 'American Samoa')
    GU = enum.Item('GU', 'Guam')
    MP = enum.Item('MP', 'Northern Mariana Islands')
    PR = enum.Item('PR', 'Puerto Rico')
    VI = enum.Item('VI', 'Virgin Islands')
    DK = enum.Item('DK', 'Dakota Territory')
    PI = enum.Item('PI', 'Philippines Territory/Commonwealth')
    OL = enum.Item('OL', 'Territory of Orleans')

########NEW FILE########
__FILENAME__ = urls
# -*- coding: utf-8 -*-
from django.conf.urls import *
from bill.views import bill_details

urlpatterns = patterns('person.views',
    url(r'^$', 'membersoverview'),
    url(r'^map$', 'browse_map', name="person_list"),
	url(r'^(current|all)$', 'searchmembers', name="person_search"),

	# must put things that could look like names of members of congress first
	url(r'^report-cards/(\d{4})(?:/([^/\.]+)(?:/([^/\.]+))?)?$', 'person_session_stats_overview', name='person_session_stats_overview'),
	url(r'^report-cards/(\d{4})/([^/]+)/([^/\.]+).csv$', 'person_session_stats_export', name='person_session_stats_export'),

    url(r'^([A-Za-z]+)/?$', 'browse_state'), # Wikipedia has bad links using state names instead of abbrs, so we support it
    url(r'^([A-Za-z]+)/(\d{1,2})/?$', 'browse_district'), # Wikipedia has bad links using state names instead of abbrs, so we support it

	url(r'^[^/]+/(\d+)$', 'person_details', name='person_details'), # name slug (but it's ignored) "/" ID
    url(r'^([A-Z]?\d+)$', 'person_details', name='person_details'), # allow bioguide ID here
	url(r'^[^/]+/(\d+)/report-card/(\d{4})', 'person_session_stats', name='person_session_stats'), # name slug "/" ID "/year-end/" session name (year)
	
    url(r'^ajax/district_lookup$', 'district_lookup'),
	url(r'^embed/mapframe(?:\.xpd)?$', 'districtmapembed', name='districtmapembed'),
)

########NEW FILE########
__FILENAME__ = util
from datetime import datetime

from committee.util import sort_members
from committee.models import CommitteeMemberRole
from person.models import PersonRole
from person.types import RoleType

def get_committee_assignments(person):
    """
    Find committee assignments for the given person
    in current congress.

    Returns sorted list of CommitteeMemberRole objects where each object is
    committee assinment which could has subcommittee assignments in ``subroles`` attribute.
    """

    roles = person.committeeassignments.all()
    parent_mapping = {}
    for role in roles:
        if role.committee.committee_id:
            parent_mapping.setdefault(role.committee.committee_id, []).append(role)
    role_tree = []
    for role in roles:
        if not role.committee.committee:
            role.subroles = sort_members([x for x in parent_mapping.get(role.committee.pk, [])])
            role_tree.append(role)
    role_tree = sort_members(role_tree)
    return role_tree


def load_roles_at_date(persons, when=datetime.now()):
    """
    Find out representative/senator role of each person at given date.

    This method is optimized for bulk operation.
    """

    roles = PersonRole.objects.filter(startdate__lte=when, enddate__gte=when, role_type__in=(RoleType.representative, RoleType.senator), person__in=persons)
    roles_by_person = {}
    for role in roles:
        roles_by_person[role.person_id] = role
    for person in persons:
        person.role = roles_by_person.get(person.id)
    return None 

########NEW FILE########
__FILENAME__ = video
from datetime import datetime, timedelta
import gdata.youtube.service
import gdata.service
from lxml import etree
import urllib

from cache_utils.decorators import cached
from django.conf import settings

@cached(60 * 30)
def get_youtube_videos(username):
    """
    Fetch latest video from person's youtube channel.

    Documentation:  http://code.google.com/intl/ru/apis/youtube/1.0/developers_guide_python.html
    """

    service = gdata.youtube.service.YouTubeService()
    service.client_id = 'govtrack.us-crawler'
    service.developer_key = settings.YOUTUBE_API_KEY
    uri = 'http://gdata.youtube.com/feeds/api/users/%s/uploads' % username

    response = {
        'url': 'http://www.youtube.com/user/%s' % username,
        'videos': []
    }
    try:
        feed = service.GetYouTubeVideoFeed(uri)
    except gdata.service.RequestError:
        pass
    else:
        if len(feed.entry):
            for entry in feed.entry[:5]:
                thumb = None
                for node in entry.media.thumbnail:
                    if int(node.width) == 120:
                        thumb = node.url
                item = {
                    'title': entry.media.title.text,
                    'published': parse_time(entry.published.text),
                    'url': entry.media.player.url,
                    'thumbnail': thumb,
                }
                response['videos'].append(item)
    return response


@cached(60 * 30)
def get_sunlightlabs_videos(bioguideid):
    """
    Fetch latest video about person from api.realtimecongress.com.

    Documentation:
     * http://services.sunlightlabs.com/docs/Real_Time_Congress_API/
     * http://services.sunlightlabs.com/docs/Real_Time_Congress_API/videos/
    """

    # Fetch 5 latest videos
    response = {'videos': []}

    url = 'http://api.realtimecongress.org/api/v1/videos.xml?apikey=%s&bioguide_ids=%s&per_page=5' % (
        settings.SUNLIGHTLABS_API_KEY, bioguideid)

    @cached(60 * 30)
    def fetch(url):
        return urllib.urlopen(url).read()

    try:
        data = fetch(url)
    except IOError, ex:
        pass
    else:
        tree = etree.fromstring(data)
        for video in tree.xpath('//video'):
            # Find mp4 file. Also there could be mp3 and mms - ignore them.
            # MMS - is sort of playlist and JWPlayer raise an error when
            # tries to play it.
            try:
                url = video.xpath('.//mp4')[0].text
            except IndexError:
                pass
            else:
                # Video node could be split on several clips. Try to find the clip
                # with required bioguidedid. If it found then provide in the response
                # the time offset of this clip
                video_start = parse_time(video.xpath('./pubdate')[0].text)
                try:
                    clip = video.xpath('.//clip//bioguide_id[text()="%s"]/../..' % bioguideid)[0]
                except IndexError, ex:
                    offset = 0
                else:
                    clip_start = parse_time(clip.xpath('./time')[0].text)
                    offset = (clip_start - video_start).seconds
                item = {
                    'title': video_start.strftime('%B %d, %Y'),
                    'published': video_start,
                    'url': url,
                    'offset': offset,
                }
                response['videos'].append(item)
    return response


def parse_time(timestr):
    timestr = timestr.lower()
    try:
        return datetime.strptime(timestr, '%Y-%m-%dt%H:%M:%S:00z') - timedelta(hours=5)
    except ValueError:
        try:
            return datetime.strptime(timestr, '%Y-%m-%dt%H:%Mz') - timedelta(hours=5)
        except ValueError:
            try:
                return datetime.strptime(timestr, '%Y-%m-%dt%H:%M:00z') - timedelta(hours=5)
            except ValueError:
                return datetime.strptime(timestr, '%Y-%m-%dt%H:%M:%S.000z') - timedelta(hours=5)

########NEW FILE########
__FILENAME__ = views
# -*- coding: utf-8 -*-
import os
from datetime import datetime, timedelta
from math import log, sqrt

from django.shortcuts import redirect, get_object_or_404
from django.core.urlresolvers import reverse
from django.db import connection
from django.db.models import Count
from django.http import Http404, HttpResponse
from django.core.cache import cache

from common.decorators import render_to
from common.pagination import paginate

import json, cPickle, base64, re

from us import statelist, statenames, stateapportionment, state_abbr_from_name, stateabbrs, get_congress_dates

from person.models import Person, PersonRole
from person import analysis
from person.types import RoleType
from person.util import get_committee_assignments

from events.models import Feed

from smartsearch.manager import SearchManager
from search import person_search_manager

from registration.helpers import json_response
from twostream.decorators import anonymous_view, user_view_for

from settings import CURRENT_CONGRESS

@anonymous_view
@render_to('person/person_details.html')
def person_details(request, pk):
    def build_info():
        if re.match(r"\d", pk):
            person = get_object_or_404(Person, pk=pk)
        else:
            # support bioguide IDs for me
            person = get_object_or_404(Person, bioguideid=pk)
        
        # current role
        role = person.get_current_role()
        if role:
            active_role = True
        else:
            active_role = False
            try:
                role = person.roles.order_by('-enddate')[0]
            except IndexError:
                role = None
    
        # photo
        photo_url, photo_credit = person.get_photo()
    
        # analysis
        analysis_data = analysis.load_data(person)
        has_session_stats = False
        if role:
            try:
                has_session_stats = role.get_most_recent_session_stats()
            except:
                pass
        
        links = []
        if role.website: links.append(("%s's Official Website" % person.lastname, role.website))
        if person.twitterid: links.append(("@" + person.twitterid, "http://twitter.com/" + person.twitterid))
        if person.osid: links.append(("OpenSecrets", "http://www.opensecrets.org/politicians/summary.php?cid=" + person.osid))
        if person.pvsid: links.append(("VoteSmart", "http://votesmart.org/candidate/" + person.pvsid))
        if person.bioguideid: links.append(("Bioguide", "http://bioguide.congress.gov/scripts/biodisplay.pl?index=" + person.bioguideid))
        if person.cspanid: links.append(("C-SPAN", "http://www.c-spanvideo.org/person/" + str(person.cspanid)))
    
        return {'person': person,
                'role': role,
                'active_role': active_role,
                'active_congressional_role': active_role and role.role_type in (RoleType.senator, RoleType.representative),
                'photo': photo_url,
                'photo_credit': photo_credit,
                'links': links,
                'analysis_data': analysis_data,
                'recent_bills': person.sponsored_bills.all().order_by('-introduced_date')[0:7],
                'committeeassignments': get_committee_assignments(person),
                'feed': person.get_feed(),
                'cities': get_district_cities("%s-%02d" % (role.state.lower(), role.district)) if role and role.district else None,
                'has_session_stats': has_session_stats,
                }

    #ck = "person_details_%s" % pk
    #ret = cache.get(ck)
    #if not ret:
    #    ret = build_info()
    #    cache.set(ck, ret, 600)
    ret = build_info()

    # redirect to canonical URL
    if request.path != ret["person"].get_absolute_url():
        return redirect(ret["person"].get_absolute_url(), permanent=True)
           
    return ret

@user_view_for(person_details)
def person_details_user_view(request, pk):
    person = get_object_or_404(Person, pk=pk)
    return render_subscribe_inline(request, person.get_feed())

def render_subscribe_inline(request, feed):
    # render the event subscribe button, but fake the return path
    # by overwriting our current URL
    from django.template import Template, Context, RequestContext, loader
    request.path = request.GET["path"]
    request.META["QUERY_STRING"] = ""
    events_button = loader.get_template("events/subscribe_inline.html")\
        .render(RequestContext(request, {
				'feed': feed,
				}))
    return { 'events_subscribe_button': events_button }
                
@anonymous_view
def searchmembers(request, initial_mode=None):
    return person_search_manager().view(request, "person/person_list.html",
        defaults = {
            "is_currently_moc": True if initial_mode=="current" else False,
            "text": request.GET["name"] if "name" in request.GET else None,
            },
        noun = ('person', 'people') )

def http_rest_json(url, args=None, method="GET"):
    import urllib, urllib2, json
    if method == "GET" and args != None:
        url += "?" + urllib.urlencode(args).encode("utf8")
    req = urllib2.Request(url)
    r = urllib2.urlopen(req)
    return json.load(r, "utf8")
    
@anonymous_view
@render_to('person/district_map.html')
def browse_map(request):
    return {
        "center_lat": 38, # # center the map on the continental US
        "center_long": -96,
        "center_zoom": 4,
        "statelist": statelist,
    }
    
def normalize_state_arg(state):
    if state.lower() in state_abbr_from_name:
        # Wikipedia links use state names!
        return state_abbr_from_name[state.lower()]
    elif state.upper() not in statenames:
        raise Http404()
    else:
        return state.upper()

def get_senators(state):
    # Load senators for all states that are not territories.
    if stateapportionment[state] == "T":
        return []

    # Order by rank.
    sens = Person.objects.filter(roles__current=True, roles__state=state, roles__role_type=RoleType.senator)\
        .order_by('roles__senator_rank')
    sens = list(sens)

    # Make sure we list at least two slots, filling with Vacant if needed.
    for i in xrange(2-len(sens)):
        sens.append(None)

    return sens

def get_representatives(state):
    # Load representatives for territories and state at-large districts.
    if stateapportionment[state] in ("T", 1):
        dists = [0]
            
    # Load representatives for non-at-large states.
    else:
        dists = xrange(1, stateapportionment[state]+1)
    
    reps = []
    for i in dists:
        cities = get_district_cities("%s-%02d" % (state.lower(), i)) if i > 0 else None
        try:
            reps.append((i, Person.objects.get(roles__current=True, roles__state=state, roles__role_type=RoleType.representative, roles__district=i), cities))
        except Person.DoesNotExist:
            reps.append((i, None, cities))

    return reps

@anonymous_view
@render_to('person/state.html')
def browse_state(request, state):
    state = normalize_state_arg(state)
    center_lat, center_long, center_zoom = get_district_bounds(state, None)
            
    return {
        "state": state,
        "stateapp": stateapportionment[state],
        "statename": statenames[state],
        "senators": get_senators(state),
        "representatives": get_representatives(state),
        "center_lat": center_lat,
        "center_long": center_long,
        "center_zoom": center_zoom,
    }

@anonymous_view
@render_to('person/district_map.html')
def browse_district(request, state, district):
    state = normalize_state_arg(state)

    # make district an integer
    try:
        district = int(district)
    except ValueError:
        raise Http404()

    # check that the district is in range
    if stateapportionment[state] in ("T", 1):
        # territories and state-at large districts have no page here
        raise Http404()
    elif district < 1 or district > stateapportionment[state]:
        # invalid district number
        raise Http404()
    
    # senators and representative
    sens = get_senators(state)
    try:
        reps = [(
            district,
            Person.objects.get(roles__current=True, roles__state=state, roles__role_type=RoleType.representative, roles__district=district),
            None,
            )]
    except Person.DoesNotExist:
        reps = [(district, None, None)] # vacant

    # map center
    center_lat, center_long, center_zoom = get_district_bounds(state, district)
            
    return {
        "center_lat": center_lat,
        "center_long": center_long,
        "center_zoom": center_zoom,
        "state": state,
        "stateapp": stateapportionment[state],
        "statename": statenames[state],
        "district": int(district),
        "district_zero": ("%02d" % int(district)),
        "statelist": statelist,
        "senators": sens,
        "reps": reps,
        "cities": get_district_cities("%s-%02d" % (state.lower(), int(district))),
    }
    
def get_district_bounds(state, district):
    zoom_info_cache_key = "map_zoom_%s-%s" % (state, "" if not district else district)

    if state == "MP":
        return (145.7, 15.1, 11.0)
    elif state == "AS":
        center_long, center_lat, center_zoom = (-170.255127, -14.514462, 8.0)
    elif state == "HI":
        center_long, center_lat, center_zoom = (-155.5, 20, 7.0)
    elif state == "AK":
        # Alaska has a longitude wrap-around problem so it's easier to just specify
        # the coordinates manually than to figure out generically how to do the math
        # of taking the average of the bounding box coordinates.
        center_long, center_lat, center_zoom = (-150, 63, 4.0)
    elif cache.get(zoom_info_cache_key):
        center_lat, center_long, center_zoom = cache.get(zoom_info_cache_key)
    else:
        def get_coords(state, distr):
            import urllib, json
            if not distr:
                url = "http://gis.govtrack.us/boundaries/2012-states/%s/?format=json" % state.lower()
            else:
                url = "http://gis.govtrack.us/boundaries/cd-2012/%s-%02d/?format=json" % (state.lower(), int(distr))
            resp = json.load(urllib.urlopen(url))
            sw_lng, sw_lat, ne_lng, ne_lat = resp["extent"]
            area = (ne_lng-sw_lng)*(ne_lat-sw_lat)
            center_long, center_lat = (sw_lng+ne_lng)/2.0, (sw_lat+ne_lat)/2.0
            center_zoom = round(1.0 - log(sqrt(area)/1000.0))
            return center_lat, center_long, center_zoom
            
        center_lat, center_long, center_zoom = get_coords(state, None)

        # Zoom in to district if it is too small to be seen on a whole-state map.
        if district:
            distr_center_lat, district_center_long, district_center_zoom = get_coords(state, district)
            if district_center_zoom > center_zoom + 1:
                center_lat, center_long, center_zoom = distr_center_lat, district_center_long, district_center_zoom
                
        cache.set(zoom_info_cache_key, (center_lat, center_long, center_zoom) )

    return (center_lat, center_long, center_zoom)

def get_district_cities(district_id):
    district_info = cache.get("district_cities_%s" % district_id)
    if district_info:
        if district_info == "NONE": district_info = None
        return district_info
    
    # When debugging locally, this file may not exist.
    if os.path.exists("data/misc/cd-intersection-data.json"):
        district_info = json.load(open("data/misc/cd-intersection-data.json")).get(district_id)
    else:
        district_info = None
    if district_info:
        locations_1 = [c["name"] for c in sorted(district_info, key=lambda c:-c["pct_of_district"]) if c["pct_of_locality"] > .98][0:8]
        locations_2 = [c["name"] for c in sorted(district_info, key=lambda c:-c["pct_of_locality"]) if c["pct_of_locality"] <= .98][0:8]
        district_info = ", ".join(locations_1)
        if len(locations_2) > 2:
            if len(locations_1) > 0:
                district_info += " and parts of "
                locations_2 = locations_2[0:5]
            else:
                district_info += "Parts of "
            district_info += ", ".join(locations_2)
    
    cache.set("district_cities_%s" % district_id, district_info if district_info != None else "NONE")
    
    return district_info
    
@anonymous_view
@render_to('person/overview.html')
def membersoverview(request):
    def get_current_members(role_type, delegates, by_party):
        qs = PersonRole.objects.filter(
            role_type=role_type,
            current=True,
            state__in=set(s for s, t in stateapportionment.items() if (t != "T") ^ delegates)
            )
        if by_party:
            return qs.values('party').annotate(count=Count('party')).order_by('-count')
        else:
            return qs.count()
    
    congress_current = (CURRENT_CONGRESS, get_congress_dates(CURRENT_CONGRESS)[0])
    congress_previous = (CURRENT_CONGRESS-1, get_congress_dates(CURRENT_CONGRESS-1)[1])
            
    return {
        "statelist": statelist,
        "senate_by_party": get_current_members(RoleType.senator, False, True),
        "senate_vacancies": 100-get_current_members(RoleType.senator, False, False),
        "house_by_party": get_current_members(RoleType.representative, False, True),
        "house_vacancies": 435-get_current_members(RoleType.representative, False, False),
        "house_delegate_vacancies": 6-get_current_members(RoleType.representative, True, False),
        "congress_current": congress_current,
        "congress_previous": congress_previous,
    }

@anonymous_view
@render_to('person/district_map_embed.html')
def districtmapembed(request):
    bounds2 = None
    try:
        bounds2 = get_district_bounds(request.GET.get("state", ""), request.GET.get("district", ""))
    except:
        pass

    return {
        "demo": "demo" in request.GET,
        "hide_footer": "demo" in request.GET or "footer" in request.GET,
        "state": request.GET.get("state", ""),
        "district": request.GET.get("district", ""),
        "bounds": request.GET.get("bounds", None),
        "bounds2": bounds2,
    }
    
@anonymous_view
@json_response
def district_lookup(request):
    lng, lat = float(request.GET.get("lng", "0")), float(request.GET.get("lat", "0"))
    return do_district_lookup(lng, lat)

def do_district_lookup(lng, lat):
    import urllib, json
    url = "http://gis.govtrack.us/boundaries/cd-2012/?contains=%f,%f&format=json" % (lat, lng)
    try:
        resp = json.load(urllib.urlopen(url))
    except Exception as e:
        return { "error": "error loading district data (%s)" % str(e) }
    
    if len(resp["objects"]) == 0:
        return { "error": "point is not within a district" }

    if len(resp["objects"]) > 1:
        return { "error": "point is within multiple districts!" }
        
    d = resp["objects"][0]["external_id"].split("-")
    return { "state": d[0].upper(), "district": int(d[1]) }

import django.contrib.sitemaps
class sitemap_current(django.contrib.sitemaps.Sitemap):
    changefreq = "weekly"
    priority = 1.0
    def items(self):
        return Person.objects.filter(roles__current=True).distinct()
class sitemap_archive(django.contrib.sitemaps.Sitemap):
    changefreq = "yearly"
    priority = 0.25
    def items(self):
        return Person.objects.filter(roles__current=False).distinct()
class sitemap_districts(django.contrib.sitemaps.Sitemap):
    changefreq = "monthly"
    priority = 0.5
    def items(self):
        ret = []
        for state in stateabbrs:
            if state not in stateapportionment: continue
            ret.append( (state, 0) )
            if stateapportionment[state] not in (1, "T"):
                for district in xrange(1, stateapportionment[state]+1):
                    ret.append( (state, district) )
        return ret
    def location(self, item):
        return "/congress/members/" + item[0] + ("/"+str(item[1]) if item[1] else "")
        
@anonymous_view
@render_to('person/person_session_stats.html')
def person_session_stats(request, pk, session):
    # get the person and the statistics
    person = get_object_or_404(Person, pk=pk)
    try:
        stats = person.get_session_stats(session)
    except ValueError:
        # no stats
        raise Http404()

    # get the role as stored in the file
    role = PersonRole.objects.get(id=stats["role_id"])

    # clean and sort the stats for this person so they're ready for display
    from person.views_sessionstats import clean_person_stats
    clean_person_stats(stats)

    # group into an order for navigation
    nav_groups = []
    for stat in stats["stats"]:
        for group in nav_groups:
            if group["icon"] == stat["icon"]:
                group["stats"].append(stat)
                break
        else:
            nav_groups.append({ "icon": stat["icon"], "stats": [stat]  })

    import dateutil
    from person.types import Gender, RoleType

    return {
        "publishdate": dateutil.parser.parse(stats["meta"]["as-of"]),
        "person": person,
        "photo": person.get_photo()[0],
        "himher": Gender.by_value(person.gender).pronoun_object,
        "role": role,
        "class": RoleType.by_value(role.role_type).label.lower() + "s",
        "session": session,
        "meta": stats["meta"],
        "stats": stats["stats"],
        "nav_groups": nav_groups,
    }

@anonymous_view
@render_to('person/person_session_stats_overview.html')
def person_session_stats_overview(request, session, cohort, specific_stat):
    try:
        stats = Person.load_session_stats(session)
    except ValueError:
        # no stats
        raise Http404()

    from person.views_sessionstats import get_cohort_name, stat_titles

    try:
        cohort_title = get_cohort_name(cohort, True) if cohort else None
    except ValueError: 
        # invalid URL
        raise Http404()

    # Get all of the cohorts in the data.
    cohorts = { }
    cohort_keys = set()
    for person in stats["people"].values():
        for c in person["cohorts"]:
            c = c["key"]
            cohorts[c] = cohorts.get(c, 0) + 1
            cohort_keys.add(c)
    cohorts = [ (-v, k, get_cohort_name(k, True), v) for k,v in cohorts.items() if "delegation" not in k and v > 10]
    cohorts = sorted(cohorts)

    # Gather data.
    metrics = { }
    for pid, person in stats["people"].items():
        try:
            personobj = Person.objects.get(id=int(pid))
        except:
            # debugging
            continue

        for stat, statinfo in person["stats"].items():
            if specific_stat is not None and stat != specific_stat: continue

            for cohort_key, context in statinfo.get("context", {}).items():
                # filter by cohort, if we're doing that
                if cohort is not None and cohort != cohort_key: continue
                if cohort is None and cohort_key not in ("house", "senate"): continue

                # create an entry for this statistic
                metrics.setdefault(stat, {
                    "key": stat,
                    "title": stat_titles[stat]["title"],
                    "icon": stat_titles[stat]["icon"],
                    "contexts": { }
                })
                metrics[stat]["title"] = metrics[stat]["title"].replace("{{other_chamber}}", "Other Chamber")
                metrics[stat]["contexts"].setdefault(cohort_key, {
                    "key": cohort_key,
                    "title": get_cohort_name(cohort_key, True),
                    "N": context["N"],
                    "people": ([], []),
                    })

                # if this person ranks #1, #2, #3, fill him in
                c = metrics[stat]["contexts"][cohort_key]["people"]
                if specific_stat is not None:
                    c[0].append( (context["rank_descending"], statinfo["value"], personobj) )
                elif context["rank_ties"] <= 3:
                    if context["rank_ascending"] < 3 and stat in ("ideology", "leadership", "bills-with-cosponsors-both-parties", "cosponsored-other-party", "missed-votes"):
                        c[1].append( (context["rank_descending"], statinfo["value"], personobj) )
                    elif context["rank_descending"] < 3:
                        c[0].append( (context["rank_descending"], statinfo["value"], personobj) )


    metrics = sorted(metrics.values(), key = lambda m : m["title"])

    for m in metrics:
        m["contexts"] = sorted(m["contexts"].values(), key = lambda c : -c["N"])
        for c in m["contexts"]:
            c["people"][0].sort()
            c["people"][1].sort()

    #from person.views_sessionstats import clean_person_stats
    #for pid, personstats in stats["people"].items():
    #    clean_person_stats(personstats)

    import dateutil
    return {
        "session": session,
        "meta": stats["meta"],
        "metrics": metrics,
        "cohorts": cohorts,
        "cohort": cohort,
        "cohort_title": cohort_title,
        "specific_stat": specific_stat,
        "specific_stat_title": stat_titles[specific_stat]["title"].replace("{{other_chamber}}", "Other Chamber") if specific_stat else None,
        "publishdate": dateutil.parser.parse(stats["meta"]["as-of"]),
    }

@anonymous_view
def person_session_stats_export(request, session, cohort, statistic):
    try:
        stats = Person.load_session_stats(session)
    except ValueError:
        # no stats
        raise Http404()

    # collect data
    rows = []
    for person_id, person_stats in stats["people"].items():
        if cohort not in [c["key"] for c in person_stats["cohorts"]]: continue
        if statistic not in person_stats["stats"]: continue
        if "context" not in person_stats["stats"][statistic]: continue
        rows.append([
            person_stats["stats"][statistic]["context"][cohort]["rank_ascending"],
            person_stats["stats"][statistic]["context"][cohort]["rank_descending"],
            person_stats["stats"][statistic]["context"][cohort]["percentile"],
            person_stats["stats"][statistic]["value"],
            int(person_id),
			"", # bioguide ID
            int(person_stats["role_id"]),
            "", # state
            "", # district
            ])
    if len(rows) == 0:
        raise Http404()

    # assign sortname to the 2nd column so we can use it in sorting
    people = Person.objects.in_bulk([r[4] for r in rows])
    roles = PersonRole.objects.in_bulk([r[6] for r in rows])
    for r in rows:
        #if r[4] not in people: continue # database mismatch, happens during testing
        r[5] = people[r[4]].bioguideid
        r[6], r[7] = roles[r[6]].state, roles[r[6]].district if isinstance(roles[r[6]].district, int) else ""
        r[8] = people[r[4]].lastname.encode("utf-8")

    # sort by rank, then by name
    rows.sort(key = lambda r : (r[0], r[8]))

    # format CSV
    import csv, StringIO
    outfile = StringIO.StringIO()
    writer = csv.writer(outfile)
    writer.writerow(["rank_from_low", "rank_from_high", "percentile", statistic, "id", "bioguide_id", "state", "district", "name"])
    for row in rows: writer.writerow(row)
    output = outfile.getvalue()

    # construct response
    if request.GET.get("inline") is None:
        r = HttpResponse(output, content_type='text/csv')
        r['Content-Disposition'] = 'attachment; filename=' + "govtrack-stats-%s-%s-%s.csv" % (session, cohort, statistic)
    else:
        r = HttpResponse(output, content_type='text/plain')
    return r

########NEW FILE########
__FILENAME__ = views_sessionstats
from us import statenames

stat_titles = {
    "missed-votes":  { "title": "Missed Votes", "icon": "voting-records" },
    "bills-introduced":  { "title": "Bills Introduced", "icon": "bills-resolutions" },
    "bills-enacted":  { "title": "Laws Enacted", "icon": "bills-resolutions" },
    "bills-reported":  { "title": "Bills Out of Committee", "icon": "committees" },
    "bills-with-committee-leaders":  { "title": "Powerful Cosponsors", "icon": "committees" },
    "bills-with-cosponsors-both-parties":  { "title": "Writing Bipartisan Bills", "icon": "handshake" },
    "bills-with-companion":  { "title": "Working with the {{other_chamber}}", "icon": "handshake" },
    "cosponsors":  { "title": "Cosponsors", "icon": "congress-members" },
    "cosponsored":  { "title": "Bills Cosponsored", "icon": "bills-resolutions" },
    "cosponsored-other-party":  { "title": "Joining Bipartisan Bills", "icon": "handshake" },
    "ideology": { "title": "Ideology Score", "icon": "congress-members", "superlatives": ("most conservative (by cosponsorship)", "most progressive (by cosponsorship)") },
    "leadership":  { "title": "Leadership Score", "icon": "congress-members" },
    "committee-positions":  { "title": "Committee Positions", "icon": "committees" },
    "transparency-bills":  { "title": "Government Transparency", "icon": "open-government" },
}

def get_cohort_name(key, longform=False):
    if key == "house": return "All Representatives"
    if key == "senate": return "All Senators"
    if key == "party-house-democrat": return "House Democrats"
    if key == "party-house-republican": return "House Republicans"
    if key == "party-house-independent": return "House Independents"
    if key == "party-senate-democrat": return "Senate Democrats"
    if key == "party-senate-republican": return "Senate Republicans"
    if key == "party-senate-independent": return "Senate Independents"
    if key.startswith("house-state-delegation-"): return statenames[key[23:25].upper()] + " Delegation"
    if key == "house-leadership": return "House Party Leaders"
    if key == "senate-leadership": return "Senate Party Leaders"
    if key == "house-freshmen": return "House Freshmen"
    if key == "senate-freshmen": return "Senate Freshmen"
    if key == "house-sophomores": return "House Sophomores"
    if key == "senate-sophomores": return "Senate Sophomores"
    if key == "house-tenyears": return "Serving 10+ Years" + ("" if not longform else " (House)")
    if key == "senate-tenyears": return "Serving 10+ Years" + ("" if not longform else " (Senate)")
    if key == "house-committee-leaders": return "House Cmte. Chairs/RkMembs"
    if key == "senate-committee-leaders": return "Senate Cmte. Chairs/RkMembs"
    if key == "house-competitive-seat": return "Competitive House Seats"
    if key == "house-safe-seat": return "Safe House Seats"
    raise ValueError(key)

def clean_person_stats(stats):
    # Remove ideology if the person has a low leadership score because it indicates bad data.
    # Remove it and leadership if the introduced fewer than ten bills.
    if stats["stats"]["bills-introduced"]["value"] < 10 or stats["stats"]["leadership"]["value"] < .25: del stats["stats"]["ideology"]
    if stats["stats"]["bills-introduced"]["value"] < 10: del stats["stats"]["leadership"]
    for s in list(stats["stats"].keys()):
        if stats["stats"][s]["value"] is None:
            del stats["stats"][s]

    # Delete some dumb other contexts.
    delete = [
        ("committee-positions", "senate-committee-leaders"),
        ("committee-positions", "house-committee-leaders"),
        ("missed-votes", "party-house-democrat"),
        ("missed-votes", "party-house-republican"),
        ("missed-votes", "party-house-independent"),
        ("missed-votes", "party-senate-democrat"),
        ("missed-votes", "party-senate-republican"),
        ("missed-votes", "party-senate-independent"),
        ]
    for statname, stat in stats["stats"].items():
        if "context" not in stat: continue
        for s, c in delete:
            if statname == s and c in stat["context"]:
                del stat["context"][c]

    # put nice names in the context cohorts
    for statname, stat in stats["stats"].items():
        stat["key"] = statname
        stat.update(stat_titles.get(statname, { "title": statname, "icon": "" }))
        stat["title"] = stat["title"].replace("{{other_chamber}}", stat.get("other_chamber",""))

        stat["show_values"] = statname not in ("leadership", "ideology")
        if "superlatives" not in stat: stat["superlatives"] = ("highest", "lowest")

        for cohort, context in stat.get("context", {}).items():
            context["key"] = cohort
            context["name"] = get_cohort_name(cohort)

            # If the person's rank is less than the number of ties, don't use this context
            # for the headline.
            if min(context["rank_ascending"], context["rank_descending"]) < context["rank_ties"]:
                context["use_in_headline"] = False

            # These are never interesting.
            if cohort == "house-safe-seat":
                context["use_in_headline"] = False

            # The percentile we computed off-line is the normal percentile, but it's not good for
            # "Top 20%"-style measures. Re-do it.
            context["percentile2"] = (min(context["rank_ascending"], context["rank_descending"]) + context["rank_ties"])/float(context["N"])

    stats["stats"] = list(stats["stats"].values())

    # Within each statistic, put the context cohorts into the most interesting
    # order for display, which is cohorts from smallest size to largest size.
    #
    # Also choose the context cohort that is best for the statistic's headline,
    # which is the cohort with the most extreme percentile, with ties favoring
    # the larger group.
    def cohort_comparer_for_display(cohort):
        return cohort["N"]
    def cohort_comparer_for_headline(cohort):
        return (min(cohort["percentile"], 100-cohort["percentile"]), -cohort["N"])
    for stat in stats["stats"]:
        if len(stat.get("context", {})) == 0: continue
        stat["context_for_display"] = sorted(stat["context"].values(), key = cohort_comparer_for_display)

        contexts_for_headline = [c for c in stat["context"].values() if c.get("use_in_headline", True)]
        if len(contexts_for_headline) > 0:
            stat["context_for_headline"] = sorted(contexts_for_headline, key = cohort_comparer_for_headline)[0]

    # put the statistics in the most interesting order, which is statistics
    # for which the member has the most extreme values to display.
    def stat_comparer(stat):
        if len(stat.get("context_for_headline", [])) == 0: return (999999, 0) # no contextual info, put last
        c = stat["context_for_headline"]
        return (min(c["rank_ascending"], c["rank_descending"]) + c["rank_ties"]/2.0, -c["N"])
    stats["stats"].sort(key = stat_comparer)

########NEW FILE########
__FILENAME__ = admin
# -*- coding: utf-8

from django.contrib import admin
from poll_and_call.models import Issue, IssuePosition, RelatedBill, UserPosition, CallLog

class IssueAdmin(admin.ModelAdmin):
	prepopulated_fields = {"slug": ("title",)}
	raw_id_fields = ['positions']

class RelatedBillAdmin(admin.ModelAdmin):
    raw_id_fields = ['issue', 'bill']

class UserPositionAdmin(admin.ModelAdmin):
    raw_id_fields = ['user', 'position']

class CallLogAdmin(admin.ModelAdmin):
    raw_id_fields = ['user', 'position', 'target']

admin.site.register(Issue, IssueAdmin)
admin.site.register(IssuePosition)
admin.site.register(RelatedBill, RelatedBillAdmin)
admin.site.register(UserPosition, UserPositionAdmin)
admin.site.register(CallLog, CallLogAdmin)

########NEW FILE########
__FILENAME__ = models
# -*- coding: utf-8 -*-
from django.db import models
from json_field import JSONField

import random

class Issue(models.Model):
	"""An issue is something that users might want to weigh in on."""

	slug = models.SlugField(help_text="The slug for this issue in URLs.")
	title = models.CharField(max_length=255, help_text="The issue's display title.")
	question = models.CharField(max_length=255, help_text="The issue phrased as a question.")
	introtext = models.TextField(help_text="Text introducing the issue.")
	positions = models.ManyToManyField('IssuePosition', db_index=True, related_name="issue", help_text="The positions associated with this issue.")
	created = models.DateTimeField(auto_now_add=True, db_index=True, help_text="The date and time the issue was created.")
	isopen = models.BooleanField(default=False, verbose_name="Open", help_text="Whether users can currently participate in this issue.")

	class Meta:
		ordering = ('-created',)

	def __unicode__(self):
		return self.title + "/" + self.question

	def get_absolute_url(self):
		return "/poll/" + self.slug

	def get_randomized_positions(self):
		# Randomize the positions because that's better for polling.
		p = list(self.positions.all())
		random.shuffle(p)
		return p

class IssuePosition(models.Model):
	"""A position that a user can take on an issue."""

	text = models.CharField(max_length=255, help_text="A description of the position.")
	valence = models.NullBooleanField(blank=True, null=True, help_text="The valence of this position, for linking with bills.")
	created = models.DateTimeField(auto_now_add=True, db_index=True, help_text="The date and time the issue was created.")
	call_script = models.TextField(blank=True, null=True, help_text="What you should say when you call your rep about this issue.")

	class Meta:
		ordering = ('-created',)

	def __unicode__(self):
		i = "?"
		try:
			i = self.issue.all()[0].title
		except:
			pass
		v = ""
		if self.valence is True: v = "(+) "
		if self.valence is False: v = "(-) "
		return v + i + " -- " + self.text

class RelatedBill(models.Model):
	"""A bill related to an issue, and possibly a link between support/oppose for the bill and IssuePositions."""

	issue = models.ForeignKey(Issue, db_index=True, related_name="bills", help_text="The related issue.", on_delete=models.CASCADE)
	bill = models.ForeignKey('bill.Bill', db_index=True, help_text="The related bill.", on_delete=models.PROTECT)
	valence = models.NullBooleanField(blank=True, null=True, help_text="The valence of this bill, for linking with IssuePositions. If not null, a user who supports this bill takes the position of the IssuePosition with the same valence value.")

	def __unicode__(self):
		v = ""
		if self.valence is True: v = "(+) "
		if self.valence is False: v = "(-) "
		return v + self.issue.title + " -- " + unicode(self.bill)

class UserPosition(models.Model):
	"""The position of a user on an issue."""

	user = models.ForeignKey('auth.User', db_index=True, help_text="The user who created this position.", on_delete=models.CASCADE)
	position = models.ForeignKey(IssuePosition, db_index=True, help_text="The position the user choses.", on_delete=models.CASCADE)
	created = models.DateTimeField(auto_now_add=True, db_index=True)

	district = models.CharField(max_length=4, db_index=True, help_text="The state and district, in uppercase without any spaces, of the user at the time the user took this posiiton.")

	metadata = JSONField(help_text="Other information stored with the position.")

	def __unicode__(self):
		return self.created.isoformat() + " " + unicode(self.user) + "/" + unicode(self.position)

	def can_change_position(self):
		# Can the user change his position? Not if he made any calls about it.
		return not CallLog.objects.filter(position=self).exists()

	def get_current_targets(self):
		# Returns either a list of a string with a reason why there are no targets to call.

		# ugh, data collection error when this was first launched
		if len(self.district) <= 2: return "unknown"

		# get all of the chambers any related bills are currently being considered in
		issue = self.position.issue.get()
		chambers = set()
		for rb in RelatedBill.objects.filter(issue=issue).select_related("bill"):
			chambers.add(rb.bill.current_status_chamber)

		# get the represenative or senators as appropriate, and check for various
		# error conditions along the way.
		from person.models import PersonRole, RoleType
		from us import stateapportionment
		targets = []
		if len(chambers) == 0 or "House" in chambers or "Unknown" in chambers:
			targets.extend( PersonRole.objects.filter(current=True, role_type=RoleType.representative, state=self.district[0:2], district=int(self.district[2:])) )
			if len(targets) == 0 and ((len(chambers) == 1 and "House" in chambers) or stateapportionment[self.district[0:2]] == "T"): return "house-vacant"
		if len(chambers) == 0 or "Senate" in chambers or "Unknown" in chambers:
			targets.extend( PersonRole.objects.filter(current=True, role_type=RoleType.senator, state=self.district[0:2]) )
			if len(chambers) == 1 and "Senate" in chambers and len(targets) == 0:
				if stateapportionment[self.district[0:2]] == "T": return "no-senators"
				return "senate-vacant"
		if len(targets) == 0: return "vacant"

		# make sure we have a phone number on file
		def is_valid_phone(phone):
			if not phone: return False
			if len("".join(c for c in phone if unicode.isdigit(c))) != 10: return False
			return True
		targets = [t for t in targets if is_valid_phone(t.phone)]
		if len(targets) == 0: return "no-phone"

		# filter out anyone the user has already called 
		targets = [t for t in targets if not CallLog.has_made_successful_call(self, t)]
		if len(targets) == 0: return "all-calls-made"

		return targets


class CallLog(models.Model):
	"""The log of a call to Congress."""

	user = models.ForeignKey('auth.User', db_index=True, help_text="The user who created this call.", on_delete=models.CASCADE)
	position = models.ForeignKey(UserPosition, db_index=True, help_text="The position this call was communicating.", on_delete=models.CASCADE)
	target = models.ForeignKey('person.PersonRole', db_index=True, help_text="The Member of Congress the user called.", on_delete=models.PROTECT)
	created = models.DateTimeField(auto_now_add=True, db_index=True)

	status = models.CharField(max_length=64) # current status of the call

	log = JSONField(help_text="A dict of TwilML information for different parts of the call.")

	class Meta:
		ordering = ('-created',)

	def __unicode__(self):
		return self.created.isoformat() + " " + unicode(self.user) + " " + unicode(self.position)

	def is_complete(self):
		return isinstance(self.log, dict) and self.log.get("finished", {}).get("RecordingUrl") is not None

	@staticmethod
	def has_made_successful_call(userposition, target):
		for cl in CallLog.objects.filter(position=userposition, target=target):
			if cl.is_complete():
				return True
		return False
	
########NEW FILE########
__FILENAME__ = urls
# -*- coding: utf-8 -*-
from django.conf.urls import *

urlpatterns = patterns('poll_and_call.views',
    url(r'^([a-z0-9\-\_]+)$', 'issue_show'),
    url(r'^([a-z0-9\-\_]+)/join/(\d+)$', 'issue_join'),
    url(r'^([a-z0-9\-\_]+)/make_call$', 'issue_make_call'),
    url(r'^_ajax/start-call$', 'start_call'),
    url(r'^_ajax/poll-call-status$', 'poll_call_status'),
    url(r'^_twilio/call-start/(?P<calllog_id>\d+)$', 'twilio_call_start'),
    url(r'^_twilio/call-input/(?P<calllog_id>\d+)$', 'twilio_call_input'),
    url(r'^_twilio/call-transfer-end/(?P<calllog_id>\d+)$', 'twilio_call_transfer_ended'),
    url(r'^_twilio/call-end/(?P<calllog_id>\d+)$', 'twilio_call_end'),
)


########NEW FILE########
__FILENAME__ = views
# -*- coding: utf-8 -*-
from django.http import Http404, HttpResponseRedirect, HttpResponse
from django.shortcuts import redirect, get_object_or_404
from django.core.urlresolvers import reverse
from django.contrib.auth.decorators import login_required
from django.conf import settings
from django.db.models import Count, F

from common.decorators import render_to

from poll_and_call.models import Issue, IssuePosition, UserPosition, CallLog
from person.models import PersonRole

from twostream.decorators import anonymous_view, user_view_for
from registration.helpers import json_response

from datetime import datetime

@anonymous_view
@render_to('poll_and_call/issue_details.html')
def issue_show(request, issue_slug):
	issue = get_object_or_404(Issue, slug=issue_slug)

	# get the positions, and map ID to the position object
	positions = issue.positions.all()
	pos_map = dict({ p.id: p for p in positions })

	# get the current poll results (set default values first)
	for p in positions:
		p.total_users = 0
		p.percent_users = 0
	results = UserPosition.objects.filter(position__issue=issue).values("position").annotate(count=Count('id'))
	total_users = sum(r["count"] for r in results)
	for r in results:
		p = pos_map[r["position"]]
		p.total_users = r["count"]
		p.percent_users = int(round(100.0*r["count"]/total_users))

	return { "issue": issue, "positions": positions, "total_users": total_users }

@user_view_for(issue_show)
def issue_show_user_view(request, issue_slug):
	issue = get_object_or_404(Issue, slug=issue_slug)
	D = { }
	if request.user.is_authenticated():
		try:
			up = UserPosition.objects.get(user=request.user, position__issue=issue)
			targets = up.get_current_targets()
			D["position"] =  {
				"id": up.position.id,
				"text": up.position.text,
				"can_change": up.can_change_position(),
				"can_call": [(t.id, t.person.name) for t in targets] if isinstance(targets, list) else [],
			}
		except:
			pass
	return D

@login_required
@render_to('poll_and_call/issue_join.html')
def issue_join(request, issue_slug, position_id):
	issue = get_object_or_404(Issue, slug=issue_slug)
	try:
		position = issue.positions.get(id=position_id)
	except IssuePosition.DoesNotExist:
		raise Http404()

	try:
		up = UserPosition.objects.get(user=request.user, position__issue=issue)
		if up.can_change_position():
			# User can change his position. Delete the old position before going on.
			up.delete()
		else:
			# The position is fixed. Go on to making a call.
			return HttpResponseRedirect(issue.get_absolute_url() + "/make_call")
	except UserPosition.DoesNotExist:
		pass

	if request.method == "POST":
		# This is a confirmation.

		# Create the new position.
		UserPosition.objects.create(
			user=request.user,
			position=position,
			district=request.POST.get("district"),
			metadata={
				"choice_display_index": request.GET.get("meta_order"),
			})
		return HttpResponseRedirect(issue.get_absolute_url() + "/make_call")

	return { "issue": issue, "position": position }

@login_required
@render_to('poll_and_call/issue_make_call.html')
def issue_make_call(request, issue_slug):
	issue = get_object_or_404(Issue, slug=issue_slug)
	user_position = get_object_or_404(UserPosition, user=request.user, position__issue=issue)

	# is there a representative to call in the user's district that the user hasn't called?
	targets = user_position.get_current_targets()
	if isinstance(targets, str):
		return HttpResponseRedirect(issue.get_absolute_url() + "#" + targets)

	# choose a target at random
	rep = targets[0]

	# if 'target' is a GET parameter, call that target.
	try:
		rep = [t for t in targets if t.id == int(request.GET['target'])][0]
	except:
		# target is not a parameter, is not an integer, is not one of the targets
		pass

	# is this a good time of day to call?
	#if not ((0 <= datetime.now().weekday() <= 4) and ('09:15' <= datetime.now().time().isoformat() <= '16:45')):
	#	return HttpResponseRedirect(issue.get_absolute_url() + "#hours")

	position = user_position.position
	position.call_script = dynamic_call_script(issue, position, rep.person, rep)

	next_step = issue.get_absolute_url()
	for bill in issue.bills.all():
		next_step = bill.bill.get_absolute_url()

	return {
		"issue": issue,
		"user_position": user_position,
		"position": position,
		"moc": rep,
		"other_targets": [t for t in targets if t != rep],
		"next_step": next_step,
		}

def dynamic_call_script(issue, position, person, role):
	name = role.get_title() + " " + person.lastname

	from person.types import Gender
	pos_pro = Gender.by_value(person.gender).pronoun_posessive

	if issue.slug == "gov-shutdown-2013" and position.valence is True:
		if role.party == "Democrat":
			return position.call_script + " I ask %s to be open to a repeal or delay of the Affordable Care Act." % (name,)
		elif role.party == "Republican":
			return position.call_script + " I ask %s to hold %s ground until the Democrats come to the table to negotiate." % (name, pos_pro)
	elif issue.slug == "gov-shutdown-2013" and position.valence is False:
		if role.party == "Democrat":
			return position.call_script + " I ask %s to hold %s ground until the Republicans agree to fund the government." % (name, pos_pro)
		elif role.party == "Republican":
			return position.call_script + " I ask %s to pass a clean CR." % (name,)
	elif issue.slug == "debt-ceiling-2013":
			return position.call_script % (name,)
	return position.call_script

def twilio_client():
	from twilio.rest import TwilioRestClient
	return TwilioRestClient(settings.TWILIO_ACCOUNT_SID, settings.TWILIO_AUTH_TOKEN)

@login_required
@json_response
def start_call(request):
	user_position = get_object_or_404(UserPosition, id=request.POST["p"], user=request.user)

	# validate the 'target' parameter
	possible_targets = user_position.get_current_targets()
	if isinstance(possible_targets, str): return { "ok": False, "msg": "There is no one for you to call." }
	try:
		target = [t for t in possible_targets if t.id == int(request.POST['target'])][0]
	except:
		return { "ok": False, "msg": "You cannot call that office." }

	# basic phone number validation
	phone_num = "".join(c for c in request.POST["phone_number"] if unicode.isdigit(c)).encode("ascii")
	if len(phone_num) != 10:
		return { "ok": False, "msg": "Enter your area code and phone number." }

	try:
		client = twilio_client()
	except Exception as e:
		return { "ok": False, "msg": "Site error: " + str(e) }

	cl = CallLog.objects.create(
		user=request.user,
		position=user_position,
		target=target,
		status="not-yet-started",
		log={})

	call = client.calls.create(
		to=("+1" + phone_num),
        from_=settings.TWILIO_OUR_NUMBER,
        url=request.build_absolute_uri("/poll/_twilio/call-start/" + str(cl.id)),
        status_callback=request.build_absolute_uri("/poll/_twilio/call-end/" + str(cl.id)),
        )

	cl.log["sid"] = call.sid
	cl.status = "started"
	cl.save()

	return { "ok": True, "call_id": cl.id }
	
#	except Exception as e:
#		return { "ok": False, "msg": "Something went wrong, sorry!", "error": repr(e) }

@login_required
@json_response
def poll_call_status(request):
	call_log = get_object_or_404(CallLog, id=request.POST["id"], user=request.user)

	if call_log.status == "not-yet-started":
		msg = "Something went wrong, sorry!"
	elif call_log.status == "started":
		msg = "We are dialing your number..."
	elif call_log.status == "picked-up":
		msg = "You picked up. Dial 1 to be connected."
	elif call_log.status == "connecting":
		msg = "Connecting you to Congress..."
	elif call_log.status == "connection-ended":
		msg = "Ending the call..."
	elif call_log.status == "ended":
		msg = "Call ended."

	return { "finished": call_log.status == "ended", "msg": msg }

from twilio.twiml import Response as TwilioResponse
from django_twilio.decorators import twilio_view

def get_request_log_info(request):
	log_meta_fields = ('REMOTE_ADDR', 'HTTP_COOKIE')
	ret = { f: request.META.get(f) for f in log_meta_fields }
	ret["time"] = datetime.now().isoformat()
	return ret

@twilio_view
def twilio_call_start(request, calllog_id):
	call_log = get_object_or_404(CallLog, id=int(calllog_id))
	call_log.status = "picked-up"
	call_log.log["start"] = dict(request.POST)
	call_log.log["start"]["_request"] = get_request_log_info(request)
	call_log.save()

	resp = TwilioResponse()
	resp.say("Hello from Gov Track.")
	g = resp.gather(
            action=request.build_absolute_uri("/poll/_twilio/call-input/" + str(call_log.id)),
            numDigits=1,
            timeout=20,
            )
	g.say("Press one to be connected to the office of %s %s. Press two if you did not request this call. Or simply hang up if you do not want your call to be connected." % (
			call_log.target.get_title(),
			call_log.target.person.lastname))
	resp.say("Oooo too slow. We're going to hang up now.")

	return resp

@twilio_view
def twilio_call_input(request, calllog_id):
	call_log = get_object_or_404(CallLog, id=int(calllog_id))
	digit = request.POST["Digits"]

	call_log.log["input"] = dict(request.POST)
	call_log.log["input"]["_request"] = get_request_log_info(request)

	resp = TwilioResponse()

	if digit != "1":
		# basically an abuse report
		call_log.log["input"]["response"] = "did-not-request-call"
		resp.say("We apologize for the inconvenience. Call 202-558-7227 or visit w w w dot gov track dot u s to report abuse. Good bye.")
		resp.hangup()

	elif settings.DEBUG:
		resp.say("Site is in debug mode. Call cancelled.")
		resp.hangup()

	else:
		phone = "+1" + "".join(c for c in call_log.target.phone if unicode.isdigit(c))

		call_log.log["input"]["response"] = "continue"
		call_log.log["input"]["transfer_to"] = phone

		resp.say("Okay. Hold on.")
		resp.dial(
			phone,
            action=request.build_absolute_uri("/poll/_twilio/call-transfer-end/" + str(call_log.id)),
            timeout=30,
            callerId=request.POST["To"],
            record=True,
			)

	call_log.status = "connecting"
	call_log.save()

	return resp

@twilio_view
def twilio_call_transfer_ended(request, calllog_id):
	call_log = get_object_or_404(CallLog, id=int(calllog_id))
	call_log.status = "connection-ended"
	call_log.log["finished"] = dict(request.POST)
	call_log.log["finished"]["_request"] = get_request_log_info(request)
	call_log.save()

	resp = TwilioResponse()
	resp.say("Your call to Congress has ended. Thank you for being a good citizen. Goodbye.")
	return resp

@twilio_view
def twilio_call_end(request, calllog_id):
	call_log = get_object_or_404(CallLog, id=int(calllog_id))
	call_log.status = "ended"
	call_log.log["end"] = dict(request.POST)
	call_log.log["end"]["_request"] = get_request_log_info(request)
	call_log.save()

	# empty response
	resp = TwilioResponse()
	return resp

########NEW FILE########
__FILENAME__ = admin
from models import *
from django.contrib import admin

admin.site.register(TradingAccount)
admin.site.register(Market)
admin.site.register(Outcome)


########NEW FILE########
__FILENAME__ = top_markets
from django.core.management.base import BaseCommand, CommandError
from django.conf import settings
from django.contrib.contenttypes.models import ContentType
from django.contrib.auth.models import User
from django.conf import settings

from optparse import make_option

from predictionmarket.models import Market, Outcome, TradingAccount

class Command(BaseCommand):
	args = ''
	help = 'Shows statistics of the most active markets.'
	
	def handle(self, *args, **options):
		bank = TradingAccount.get(User.objects.get(id=settings.PREDICTIONMARKET_BANK_UID))
		
		for market in Market.objects.order_by('-tradecount')[0:10]:
			print market
			for outcome, price in market.prices().items():
				bank_shares = bank.positions(outcome=outcome).get(outcome, { "shares": 0 })["shares"]
				print round(price*100, 1), outcome, "@", outcome.volume-bank_shares, "outstanding shares"
			print

########NEW FILE########
__FILENAME__ = models
from django.db import models, connection
from django.contrib.auth.models import User
from django.conf import settings
from django.contrib.contenttypes.models import ContentType
from django.contrib.contenttypes import generic

from math import exp, log

class TradingAccount(models.Model):
	"""A user account holding the user's balance (i.e. money remaining)."""
	user = models.OneToOneField(User, db_index=True, related_name="tradingaccount")
	created = models.DateTimeField(db_index=True, auto_now_add=True)
	balance = models.FloatField(default=0) # amount of money in the account
	
	def __unicode__(self):
		return unicode(self.user)
		
	@staticmethod
	def get(user, if_exists=False):
		if not if_exists:
			acct, isnew = TradingAccount.objects.get_or_create(
				user = user,
				defaults = { "balance": settings.PREDICTIONMARKET_SEED_MONEY }
				)
			return acct
		else:
			try:
				return TradingAccount.objects.get(user = user)
			except TradingAccount.DoesNotExist:
				return None
	
	def positions(self, **filters):
		"""Returns a dict from Outcomes to a dict containing shares held of each outcome,
		the principle invested, and current unrealized profit/loss (i.e. if sold now)."""
		def tuple_add(a, b):
			return (a[0]+b[0], a[1]+b[1])
		p = { }
		for trade in Trade.objects.filter(account=self, **filters).select_related("outcome", "outcome__market").order_by('created'):
			p[trade.outcome] = tuple_add(p.get(trade.outcome, (0, 0)), (trade.shares, -trade.value))
			if p[trade.outcome][0] == 0: del p[trade.outcome] # clear when we hit zero so we don't carry forward *realized* profits/losses
		p2 = { }
		for outcome in p:
			if p[outcome][0] != 0:
				p2[outcome] = {
					"shares": p[outcome][0],
					"principle": -p[outcome][1],
					"profitloss": -(outcome.market.transaction_cost({ outcome: -p[outcome][0] }) + p[outcome][1])
				}
		return p2

	def position_in_market(self, market):
		"""Returns a tuple of total number of shares held by this account in an outcome,
		the amount invested, and the current unrealized profit/loss (i.e. if sold now)."""
		positions = self.positions(outcome__market=market)
		pl = 0.0
		for holding in positions.values():
			pl += holding["profitloss"]
		return positions, pl

	def unrealized_profit_loss(self):
		total = 0.0
		for p in self.positions().values():
			total += p["profitloss"]
		return total

class Market(models.Model):
	"""A prediction market comprising two or more outcomes."""
	
	owner_content_type = models.ForeignKey(ContentType)
	owner_object_id = models.PositiveIntegerField()
	owner_object = generic.GenericForeignKey('owner_content_type', 'owner_object_id')
	owner_key = models.CharField(max_length=16)
    
	name = models.CharField(max_length=128)
	created = models.DateTimeField(db_index=True, auto_now_add=True)
	volatility = models.FloatField(default=5.0) # prediction market volatility factor
	volume = models.IntegerField(default=0) # total held shares across all outcomes
	tradecount = models.IntegerField(default=0, db_index=True) # total number of trades across all outcomes
	
	isopen = models.BooleanField(default=True)
	
	def __unicode__(self):
		return self.name
		
	def prices(self):
		"""Returns a dict mapping Outcome instances to floats in the range of 0.0 to 1.0
		indicating the current ('instantaneous') market price of the outcome."""
		
		# Instantaneous prices are based on the same method used by Inkling
		# Markets, i.e. Hanson's Market Maker, according to a blog post by David
		# Pennock at http://blog.oddhead.com/2006/10/30/implementing-hansons-market-maker/.
		# The price for any outcome i is:
		#
		#     exp(q_i/b)
		#     -------------------------
		#     exp(q_1/b) + exp(q_2/b) + ...
		#
		# where q_i is the number of shares outstanding for each outcome and b is the
		# market volatility.
		
		prices = dict( (outcome, None) for outcome in self.outcomes.all() )
		denominator = 0.0
		for outcome in prices:
			v = exp(outcome.volume / self.volatility)
			denominator += v
			prices[outcome] = v
		for outcome in prices:
			prices[outcome] /= denominator
		return prices
		
	def cost_function(self, shares=None, outcomes=None):
		"""Returns the cost function where shares maps Outcome instances to the number of
		outstanding shares for each outcome, or if None then the current outstanding shares
		of each outcome."""
		
		# The cost function, based on the methodology above, is:
		#
		#    b * ln( exp(q_1/b) + exp(q_2/b) + ... )
		#
		# where q_i is the number of shares outstanding for each outcome and b is the
		# market volatility.
		
		
		c = 0.0
		if not outcomes: outcomes = list(self.outcomes.all()) # let the caller cache the objects
		for outcome in outcomes:
			if shares:
				v = shares.get(outcome, 0)
			else:
				v = outcome.volume
			c += exp(v / self.volatility)
		return self.volatility * log(c)
		
	def transaction_cost(self, shares, outcomes=None):
		"""Returns the cost to buy or sell shares of outcomes, where shares is a dict from
		Outcome instances to the number of shares to buy (positive) or sell (negative)."""
		
		# The transaction cost is the cost function after the trade minus the cost function
		# before the trade.
		
		if not outcomes: outcomes = list(self.outcomes.all()) # let the caller cache the objects
		current_shares = dict((outcome, outcome.volume) for outcome in outcomes)
		next_shares = dict((outcome, outcome.volume+shares.get(outcome, 0)) for outcome in outcomes)
		return self.cost_function(next_shares, outcomes) - self.cost_function(current_shares, outcomes)
		
	def close_market(self):
		# Any fields that are used during a trade should be modified synchronously.
		cursor = connection.cursor()
		cursor.execute("LOCK TABLES %s WRITE" % Market._meta.db_table)
		try:
			self.isopen = False
			self.save()
		finally:
			cursor.execute("UNLOCK TABLES")
		
class Outcome(models.Model):
	market = models.ForeignKey(Market, related_name="outcomes")
	owner_key = models.CharField(max_length=16)
	name = models.CharField(max_length=128)
	created = models.DateTimeField(db_index=True, auto_now_add=True)
	volume = models.IntegerField(default=0) # total held shares
	tradecount = models.IntegerField(default=0, db_index=True) # total number of trades
	
	def __unicode__(self):
		return self.name
		
	def price(self):
		return self.market.prices()[self]
		
	def liquidate(self, price):
		"""Forces the sale of all shares at a fixed price. Does not update market or
		outcome volumes or tradecounts, since they are no longer relevant."""
		
		# This method forces everyone to sell remaining shares at a price we set.
		# The difficultly with this function is that the only way to know how many
		# shares to sell for an account is to compute the account's position, which
		# requires summing across all trades.

		cursor = connection.cursor()
		cursor.execute("LOCK TABLES %s WRITE, %s WRITE, %s WRITE, %s WRITE" % (Trade._meta.db_table, Outcome._meta.db_table, Market._meta.db_table, TradingAccount._meta.db_table))
		try:
			if self.market.isopen: raise ValueError("Market is open!")
			
			# Compute the outstanding shares for each account.
			account_positions = { }
			for trade in self.trades.all():
				account_positions[trade.account.id] = account_positions.get(trade.account.id, 0) + trade.shares
				
			for account, shares in account_positions.items():
				if shares == 0: continue
				
				account = TradingAccount.objects.get(id=account)
				
				# Record the transaction.
				trade = Trade()
				trade.account = account
				trade.outcome = self
				trade.shares = -shares
				trade.value = price*shares
				trade.liquidation = True
				trade.save()
				
				# Update the account balance.
				account.balance += price*shares
				account.save()
		finally:
			cursor.execute("UNLOCK TABLES")
		
class Trade(models.Model):
	account = models.ForeignKey(TradingAccount, related_name="trades")
	outcome = models.ForeignKey(Outcome, related_name="trades")
	created = models.DateTimeField(db_index=True, auto_now_add=True)
	shares = models.IntegerField() # shares bought (positive) or sold (negative).
	value = models.FloatField() # monetary value of the transaction, positive means a credit to the account (selling shares), negative means a debit (buying shares)
	liquidation = models.BooleanField() # if true, this is due to the liquidation of a closing market

	def purchase_price(self):
		"""Returns the average purchase price per share."""
		return abs(self.value / self.shares)
		
	@staticmethod
	def place(account, outcome, shares, check_balance=True):
		"""Places a trade on an a market buying (shares>0) or selling (shares<0)
		shares of outcome. Returns the new Trade instance."""
		
		shares = int(shares)
		if shares == 0: raise ValueException("shares must not be zero")
		
		# Trades must be synchronized because each trade affects the price of
		# future trades. We must lock every table we touch during the transaction.
		cursor = connection.cursor()
		cursor.execute("LOCK TABLES %s WRITE, %s WRITE, %s WRITE, %s WRITE" % (Trade._meta.db_table, Outcome._meta.db_table, Market._meta.db_table, TradingAccount._meta.db_table))
		try:
			outcomes = list(outcome.market.outcomes.all())
			
			# Refresh objects now that the lock is held.
			account = TradingAccount.objects.get(id=account.id)
			outcome = Outcome.objects.get(id=outcome.id)
			market = Market.objects.get(id=outcome.market.id)
			
			if not market.isopen: raise ValueError("Market is closed.")
			
			# What will this cost?
			value = outcome.market.transaction_cost({ outcome: shares }, outcomes=outcomes)
			
			if shares > 0:
				# If a buy, check that the account has enough money for this.
				if check_balance and account.balance < value:
					raise ValueError("Account does not have sufficient funds: %f needed." % value)
			else:
				# If a sale, check that the account has enough shares for this. While owning a negative amount of
				# shares doesn't hurt the cost function, it does make an outcome's volume difficult to
				# interpret (0 might mean an equal amount of buying and selling) and makes a market's
				# volume completely nonsensical.
				pos = Trade.objects.filter(account=account, outcome=outcome).aggregate(shares=models.Sum("shares"))
				if pos["shares"] == None or pos["shares"] < shares:
					raise ValueError("Account does not have sufficient shares: %d needed." % shares)
		
			# Record the transaction.
			trade = Trade()
			trade.account = account
			trade.outcome = outcome
			trade.shares = shares
			trade.value = -value
			trade.liquidation = False
			trade.save()
			
			# Update the account balance.
			account.balance -= value
			account.save()
			
			# Update the outcome and market volumes and total trades count.
			outcome.volume += shares
			outcome.tradecount += 1
			outcome.save()
			
			market.volume += shares
			market.tradecount += 1
			market.save()
		finally:
			cursor.execute("UNLOCK TABLES")
			
		return trade
		


########NEW FILE########
__FILENAME__ = tests


########NEW FILE########
__FILENAME__ = urls
# -*- coding: utf-8 -*-
from django.conf.urls import *

urlpatterns = patterns('predictionmarket.views',
    url(r'^account$', 'accountinfo'),
    
)



########NEW FILE########
__FILENAME__ = views
# -*- coding: utf-8 -*-
from django.http import Http404, HttpResponseRedirect
from django.shortcuts import redirect, get_object_or_404, render_to_response
from django.template import RequestContext
from django.core.urlresolvers import reverse
from django.core.cache import cache
from django.contrib.auth.decorators import login_required
from django.contrib.auth.models import User

from common.decorators import render_to

from predictionmarket.models import TradingAccount

@login_required
@render_to('predictionmarket/account.html')
def accountinfo(request):
    user = request.user
    if user.is_superuser and "user" in request.GET: user = get_object_or_404(User, username=request.GET["user"])
    account = TradingAccount.get(user)
    return {
        'account': account,
        'trades': account.trades.order_by("-created").select_related(),
        }
 

########NEW FILE########
__FILENAME__ = urls
# -*- coding: utf-8 -*-
from django.conf.urls import *

urlpatterns = patterns('redirect.views',
    url(r'^congress/person\.xpd$', 'person_redirect', name='person_redirect'),
    url(r'^congress/(?:findyourreps|replookup)\.xpd$', 'district_maps_redirect'),
    url(r'^congress/committee\.xpd$', 'committee_redirect', name='committee_redirect'),
    url(r'^congress/bill(text)?\.xpd$', 'bill_redirect', name='bill_redirect'),
    url(r'^congress/billsearch\.xpd', "bill_search_redirect"),
    url(r'^congress/legislation.xpd', "bill_overview_redirect"),
    url(r'^congress/subjects\.xpd', "subject_redirect"),
    url(r'^congress/vote\.xpd', "vote_redirect"),
    url(r'^congress/votes\.xpd', "votes_redirect"),
)

########NEW FILE########
__FILENAME__ = views
# -*- coding: utf-8 -*-
import re

from django.shortcuts import redirect, get_object_or_404
from django.core.urlresolvers import reverse
from django.http import Http404, HttpResponseRedirect

from common.decorators import render_to
from common.pagination import paginate

from person.models import Person
from committee.models import Committee
from bill.models import Bill, BillType, BillTerm, TermType

BILL_TOKEN_REGEXP = re.compile('^([a-z]+)(\d+)-(\d+)$')

def person_redirect(request):
    try:
        pk = int(request.GET.get('id', ""))
    except ValueError:
        raise Http404()
    person = get_object_or_404(Person, pk=pk)
    return redirect(person, permanent=True)

def district_maps_redirect(request):
    url = "/congress/members"
    if "state" in request.GET: url += "/" + request.GET["state"]
    if "district" in request.GET: url += "/" + request.GET["district"]
    return HttpResponseRedirect(url)
    
def committee_redirect(request):
    pk = request.GET.get('id', None)
    if pk == None:
        return redirect("/congress/committees", permanent=True)
    committee = get_object_or_404(Committee, code=pk)
    return redirect(committee, permanent=True)


def bill_redirect(request, istext=None):
    """
    Redirect requests to obsolete bill urls which look like:

        /congress/bill.xpd?bill=[type_code][congress_number]-[bill_num]
    """

    token = request.GET.get('bill', '')
    match = BILL_TOKEN_REGEXP.search(token)
    if not match:
        raise Http404()
    type_code, congress, number = match.groups()
    try:
        bill_type = BillType.by_xml_code(type_code)
    except BillType.NotFound:
        raise Http404()
    bill = get_object_or_404(Bill, bill_type=bill_type, congress=congress,
                             number=number)
    return redirect(bill.get_absolute_url() + ("" if not istext else "/text"), permanent=True)

def bill_search_redirect(request):
    if "PostFormID" in request.GET: raise Http404()
    qs = request.META.get("QUERY_STRING", "")
    if len(qs) > 0: qs = "?" + qs
    return HttpResponseRedirect("/congress/bills/browse" + qs)

def bill_overview_redirect(request):
    return HttpResponseRedirect("/congress/bills")

def subject_redirect(request):
    if request.GET.get("type", "") != "crs" or "term" not in request.GET:
        return redirect("/congress/bills", permanent=True)
    try:
        term = get_object_or_404(BillTerm, name=request.GET["term"], term_type=TermType.new)
    except:
        term = get_object_or_404(BillTerm, name=request.GET["term"], term_type=TermType.old)
    return redirect(term.get_absolute_url(), permanent=True)

def vote_redirect(request):
    if not "-" in request.GET.get("vote", ""):
        return HttpResponseRedirect("/congress/votes")
    try:
        a, roll = request.GET["vote"].split("-")
    except:
        raise Http404()
    chamber = a[0]
    session = a[1:]
    from us import get_all_sessions
    for cong, sess, start, end in get_all_sessions():
        if sess == session or str(cong) + "_" + sess == session:
            return HttpResponseRedirect("/congress/votes/%s-%s/%s%s" % (cong, sess, chamber, roll))
    raise Http404()
    
def votes_redirect(request):
    return HttpResponseRedirect("/congress/votes") # missing year, chamber, person parameters


########NEW FILE########
__FILENAME__ = run_scrapers
#!script

# ./run_scrapers.py text bills votes stats

import os, os.path, glob, re, hashlib, shutil, sys, datetime

CONGRESS = int(os.environ.get("CONGRESS", "113"))
SCRAPER_PATH = "../scripts/congress"

# UTILS

bill_type_map = { 'hr': 'h', 's': 's', 'hres': 'hr', 'sres': 'sr', 'hjres': 'hj', 'sjres': 'sj', 'hconres': 'hc', 'sconres': 'sc' }

def mkdir(path):
	if not os.path.exists(path):
		os.makedirs(path)

def md5(fn, modulo=None):
	# do an MD5 on the file but run a regex first
	# to remove content we don't want to check for
	# differences.
	
	with open(fn) as fobj:
		data = fobj.read()
	if modulo != None: data = re.sub(modulo, "--", data)
	
	md5 = hashlib.md5()
	md5.update(data)
	return md5.digest()

def copy(fn1, fn2, modulo):
	# Don't copy true unchanged files because we want to keep
	# file contents the same so long as no real data changed.
	# When we load into our db, we use hashes to check if we
	# need to process a file. And for rsync users, don't make
	# them re-download files that have no real changes.
	if os.path.exists(fn2):
		if md5(fn1, modulo) == md5(fn2, modulo):
			return False
	#print fn2
	shutil.copy2(fn1, fn2)
	return True

def make_link(src, dest):
	if not os.path.exists(dest):
		os.link(src, dest)
	elif os.stat(src).st_ino == os.stat(dest).st_ino:
		pass # files are the same (hardlinked)
	else:
		if md5(src) != md5(dest):
			print "replacing", src, dest
		else:
			print "squashing existing file", src, dest
		os.unlink(dest)
		os.link(src, dest)

# MAIN

# Set options.

fetch_mode = "--force --fast"
log_level = "error"

if "full-scan" in sys.argv: fetch_mode = "--force"
if "CACHE" in os.environ: fetch_mode = "--fast"
if "DEBUG" in os.environ: log_level = "info"
	
# Run scrapers and parsers.

if "people" in sys.argv:
	if CONGRESS != 113: raise ValueErrror()
	
	# Pull latest poeple YAML.
	os.system("cd %s/congress-legislators; git fetch -pq" % SCRAPER_PATH)
	os.system("cd %s/congress-legislators; git merge --ff-only -q origin/master" % SCRAPER_PATH)
	
	# Convert people YAML into the legacy format and alternative formats.
	mkdir("data/us/%d" % CONGRESS)
	os.system("python ../scripts/legacy-conversion/convert_people.py %s/congress-legislators/ data/us/people_legacy.xml data/us/people.xml 0" % SCRAPER_PATH)
	os.system("python ../scripts/legacy-conversion/convert_people.py %s/congress-legislators/ data/us/people_legacy.xml data/us/%d/people.xml 1" % (SCRAPER_PATH, CONGRESS))
	os.system("cd %s/congress-legislators/scripts; . .env/bin/activate; python alternate_bulk_formats.py" % SCRAPER_PATH)

	# Copy into our public directory.
	for f in glob.glob("%s/congress-legislators/*.yaml" % SCRAPER_PATH):
		make_link(f, "data/congress-legislators/%s" % os.path.basename(f))
	for f in glob.glob("%s/congress-legislators/alternate_formats/*.csv" % SCRAPER_PATH):
		make_link(f, "data/congress-legislators/%s" % os.path.basename(f))

	# Convert people YAML into alternate formats.
	
	# Load YAML (directly) into db.
	os.system("./parse.py person") #  -l ERROR
	os.system("./manage.py update_index -v 0 -u person person")
	#os.system("./manage.py prune_index -u person person")
	
	# Save a fixture.
	os.system("./manage.py dumpdata --format json person > data/db/django-fixture-people.json")

if "committees" in sys.argv:
	if CONGRESS != 113: raise ValueErrror()
	
	# Committee metadata.
	
	# Pull latest YAML.
	os.system("cd %s/congress-legislators; git fetch -pq" % SCRAPER_PATH)
	os.system("cd %s/congress-legislators; git merge --ff-only -q origin/master" % SCRAPER_PATH)
	
	# Convert committee YAML into the legacy format.
	os.system(". %s/congress-legislators/scripts/.env/bin/activate; python ../scripts/legacy-conversion/convert_committees.py %s %s/congress-legislators/ ../data/us/%d/committees.xml" % (SCRAPER_PATH, SCRAPER_PATH, SCRAPER_PATH, CONGRESS))

	# Committee events.
	os.system("cd %s; . .env/bin/activate; ./run committee_meetings %s --log=%s" % (SCRAPER_PATH, fetch_mode, log_level))
	
	# Load into db.
	os.system("./parse.py -l ERROR committee")

do_bill_parse = False

if "text" in sys.argv:
	# Update the mirror of GPO FDSys.
	os.system("cd %s; . .env/bin/activate; ./run fdsys --collections=BILLS --store=mods,text,xml --log=%s" % (SCRAPER_PATH, log_level))

	# Update the mirror of Cato's deepbills.
	os.system("cd %s; . .env/bin/activate; ./run deepbills --log=%s" % (SCRAPER_PATH, log_level))
	
	# Glob all of the bill text files. Create hard links in the data directory to
	# their locations in the congress project data directoy.
	
	# We should start at 103 in case GPO has made changes to past files,
	# or 82 if we want to start with the statute-extracted text, but it
	# takes so long to go through it all!
	starting_congress = CONGRESS
	for congress in xrange(starting_congress, CONGRESS+1):
		mkdir("data/us/bills.text/%d" % congress)
		for bt in bill_type_map.values():
			mkdir("data/us/bills.text/%d/%s" % (congress, bt))
		
		for bill in sorted(glob.iglob("%s/data/%d/bills/*/*" % (SCRAPER_PATH, congress))):
			bill_type, bill_number = re.match(r"([a-z]+)(\d+)$", os.path.basename(bill)).groups()
			bill_type = bill_type_map[bill_type]
			for ver in sorted(glob.iglob(bill + "/text-versions/*")):
				basename = "../data/us/bills.text/%d/%s/%s%s%s." % (congress, bill_type, bill_type, bill_number, os.path.basename(ver))
				if congress >= 103:
					# Starting with GPO FDSys bill text, we'll pull MODS files
					# into our legacy location.
					make_link(ver + "/mods.xml", basename + "mods.xml")
				else:
					# For older bill text that we got from GPO FDSys Statutes
					# at Large, we don't have MODS but we do have text-only
					# bill text. Statutes only, of course. We have only 'enr'
					# versions, so immediately create the symlink from the
					# unversioned file name (representing most recent status)
					# to the enr version.
					basename2 = "../data/us/bills.text/%d/%s/%s%s." % (congress, bill_type, bill_type, bill_number)
					make_link(ver + "/document.txt", basename + "txt")
					if os.path.exists(basename2 + "txt"): os.unlink(basename2 + "txt")
					os.symlink(os.path.basename(basename + "txt"), basename2 + "txt")
	
	# Now do the old-style scraper (except mods files) because it handles
	# making symlinks to the latest version of each bill. And other data
	# types, like XML.

	# Scrape with legacy scraper.
	# Do this before bills because the process of loading into the db checks for new
	# bill text and generates feed events for text availability.
	os.system("cd ../scripts/gather; perl fetchbilltext.pl FULLTEXT %d" % CONGRESS)
	os.system("cd ../scripts/gather; perl fetchbilltext.pl GENERATE %d" % CONGRESS)
	do_bill_parse = True # don't know if we got any new files
	
if "bills" in sys.argv:
	# Scrape.
	os.system("cd %s; . .env/bin/activate; ./run bills --govtrack %s --congress=%d --log=%s" % (SCRAPER_PATH, fetch_mode, CONGRESS, log_level))
	
	# Copy files into legacy location.
	mkdir("data/us/%d/bills" % CONGRESS)
	bill_type_map = { 'hr': 'h', 's': 's', 'hres': 'hr', 'sres': 'sr', 'hjres': 'hj', 'sjres': 'sj', 'hconres': 'hc', 'sconres': 'sc' }
	for fn in sorted(glob.glob("%s/data/%d/bills/*/*/data.xml" % (SCRAPER_PATH, CONGRESS))):
		congress, bill_type, number = re.match(r".*congress/data/(\d+)/bills/([a-z]+)/(?:[a-z]+)(\d+)/data.xml$", fn).groups()
		if int(congress) != CONGRESS: raise ValueError()
		if bill_type not in bill_type_map: raise ValueError()
		fn2 = "data/us/%d/bills/%s%d.xml" % (CONGRESS, bill_type_map[bill_type], int(number))
		do_bill_parse |= copy(fn, fn2, r'updated="[^"]+"')
	
	# Generate summary files.
	os.system("cd /home/govtrack/scripts/gather; perl parse_status.pl SUMMARIES %d" % CONGRESS)
		
	# TODO: Even if we didn't get any new files, the bills parser also
	# scrapes docs.house.gov and the Senate floor schedule, so we should
	# also periodically make sure we run the scraper for that too.
	
	# os.system("./manage.py dumpdata --format json bill.BillTerm > data/db/django-fixture-billterms.json")

if do_bill_parse:
	# Load into db.
	os.system("./parse.py --congress=%d -l %s bill" % (CONGRESS, log_level))

	# bills and state bills are indexed as they are parsed, but to
	# freshen the index... Because bills index full text and so
	# indexing each time is substantial, set the TIMEOUT and
	# BATCH_SIZE options in the haystack connections appropriately.
	# ./manage.py update_index -v 2 -u bill bill

if "amendments" in sys.argv:
	# Scrape.
	os.system("cd %s; . .env/bin/activate; ./run amendments --govtrack %s --congress=%d --log=%s" % (SCRAPER_PATH, fetch_mode, CONGRESS, log_level))

	# Copy files into legacy location.
	mkdir("data/us/%d/bills.amdt" % CONGRESS)
	for fn in sorted(glob.glob("%s/data/%d/amendments/*/*/data.xml" % (SCRAPER_PATH, CONGRESS))):
		congress, chamber, number = re.match(r".*congress/data/(\d+)/amendments/([hs])amdt/(?:[hs])amdt(\d+)/data.xml$", fn).groups()
		if int(congress) != CONGRESS: raise ValueError()
		fn2 = "data/us/%d/bills.amdt/%s%d.xml" % (CONGRESS, chamber, int(number))
		copy(fn, fn2, r'updated="[^"]+"')
		
	# Load into db.
	os.system("./parse.py --congress=%d -l %s amendment" % (CONGRESS, log_level))

if "votes" in sys.argv:
	# Scrape.
	session = str(datetime.datetime.now().year)
	os.system("cd %s; . .env/bin/activate; ./run votes --govtrack %s --congress=%d --session=%s --log=%s" % (SCRAPER_PATH, fetch_mode, CONGRESS, session, log_level))
	
	# Copy files into legacy location.
	did_any_file_change = False
	mkdir("data/us/%d/rolls" % CONGRESS)
	for fn in sorted(glob.glob("%s/data/%d/votes/*/*/data.xml" % (SCRAPER_PATH, CONGRESS))):
		congress, session, chamber, number = re.match(r".*congress/data/(\d+)/votes/(\d+)/([hs])(\d+)/data.xml$", fn).groups()
		if int(congress) != CONGRESS: raise ValueError()
		fn2 = "data/us/%d/rolls/%s%s-%d.xml" % (CONGRESS, chamber, session, int(number))
		did_any_file_change |= copy(fn, fn2, r'updated="[^"]+"')
		
	# Load into db.
	if did_any_file_change or True: # amendments can mark votes as missing data
		os.system("./parse.py --congress=%d -l %s vote" % (CONGRESS, log_level))

if "stats" in sys.argv:
	os.system("analysis/sponsorship_analysis.py %d" % CONGRESS)
	os.system("analysis/missed_votes.py %d" % CONGRESS)
	
if "am_mem_bills" in sys.argv:
	# American Memory
	os.syste("for c in {6..42}; do echo $c; ./parse.py bill --force --congress=$c --level=warn; done")
	
if "stat_bills" in sys.argv:
	# Pull in statutes from the 85th-92nd Congress
	# via the GPO's Statutes at Large.
	
	os.system("cd %s; . .env/bin/activate; ./run fdsys --collections=STATUTE --store=mods --log=%s" % (SCRAPER_PATH, "warn")) # log_level
	os.system("cd %s; . .env/bin/activate; ./run statutes --volumes=65-86 --log=%s" % (SCRAPER_PATH, "warn")) # log_level
	os.system("cd %s; . .env/bin/activate; ./run statutes --volumes=87-106 --textversions --log=%s" % (SCRAPER_PATH, "warn")) # log_level
	
	# Copy bill metadata into our legacy location.
	# (No need to copy text-versions anywhere: we read it from the congress data directory.)
	for congress in xrange(82, 92+1):
		print congress, "..."
		
		# Copy files into legacy location.
		mkdir("data/us/%d/bills" % congress)
		for fn in sorted(glob.glob("%s/data/%d/bills/*/*/data.xml" % (SCRAPER_PATH, congress))):
			bill_type, number = re.match(r".*congress/data/\d+/bills/([a-z]+)/(?:[a-z]+)(\d+)/data.xml$", fn).groups()
			if bill_type not in bill_type_map: raise ValueError()
			fn2 = "data/us/%d/bills/%s%d.xml" % (congress, bill_type_map[bill_type], int(number))
			copy(fn, fn2, r'updated="[^"]+"')
			
		# Load into db.
		os.system("./parse.py --congress=%d bill" % congress) #  -l ERROR
		
if "photos" in sys.argv:
	# Pull in any new photos from the unitedstates/images repository.

	import person.models, os, shutil, yaml

	os.system("cd ../scripts/congress-images; git pull --rebase")

	src = '../scripts/congress-images/congress/original/'
	dst = 'data/photos/'

	# Get a list of GovTrack IDs and Bioguide IDs for which photos are provided
	# in the unitedstates/images repo. Only import photos of current Members of
	# Congress because I haven't reviewed older photos necessarily.
	bioguide_ids = [f[len(src):-4] for f in glob.glob(src + '*.jpg')]
	id_pairs = person.models.Person.objects.filter(
		bioguideid__in=bioguide_ids,
		roles__current=True)\
		.values_list('id', 'bioguideid')

	for govtrack_id, bioguide_id in id_pairs:
		# source JPEG & sanity check that it exists
		fn1 = src + bioguide_id + ".jpg"
		if not os.path.exists(fn1):
			raise IOError(fn1)

		# get required metadata
		metadata = yaml.load(open(fn1.replace("/original/", "/metadata/").replace(".jpg", ".yaml")))
		if metadata.get("name", "").strip() == "": raise ValueError("Metadata is missing name.")
		if metadata.get("link", "").strip() == "": raise ValueError("Metadata is missing link.")

		# check if the destination JPEG already exists and it has different content
		fn2 = dst + str(govtrack_id) + ".jpeg"
		if os.path.exists(fn2) and md5(fn1) != md5(fn2):
			# Back up the existing files first. If we already have a backed up
			# image, don't overwrite the back up. Figure out what to do another
			# time and just bail now. Check that we won't overwrite any files
			# before we attempt to move them.
			def get_archive_fn(fn):
				return fn.replace("/photos/", "/photos/archive/")
			files_to_archive = [fn2] + glob.glob(fn2.replace(".jpeg", "-*"))
			for fn in files_to_archive:
				if os.path.exists(get_archive_fn(fn)):
				 	raise ValueError("Archived photo already exists: " + fn)

			# Okay now actually do the backup.
			for fn in files_to_archive:
				print fn, "=>", get_archive_fn(fn)
				shutil.move(fn, get_archive_fn(fn))

		# Copy in the file.
		if copy(fn1, fn2, None):
			print fn1, "=>", fn2

			# Write the metadata.
			with open(fn2.replace(".jpeg", "-credit.txt"), "w") as credit_file:
				credit_file.write( (metadata.get("link", "").strip() + " " + metadata.get("name", "").strip() + "\n").encode("utf-8") )
	
			# Generate resized versions.
			for size_width in (50, 100, 200):
				size_height = int(round(size_width * 1.2))
				os.system("convert %s -resize %dx%d^ -gravity center -extent %dx%d %s"
					% (fn2, size_width, size_height, size_width, size_height,
						fn2.replace(".jpeg", ("-%dpx.jpeg" % size_width)) ))

########NEW FILE########
__FILENAME__ = settings
# -*- coding: utf-8 -*-
import os
import os.path
import sys
import re

ROOT = os.path.dirname(os.path.realpath(__file__))
sys.path.insert(0, os.path.join(ROOT, 'lib'))

DEBUG = ("DEBUG" in os.environ)
TEMPLATE_DEBUG = DEBUG
INTERNAL_IPS = ('127.0.0.1',)

ADMINS = []
MANAGERS = ADMINS

if DEBUG and "SSH_CONNECTION" in os.environ:
	# When launched from an SSH session, add the remote host to
	# the list of INTERNAL_IPSs so that he can see the SQL.
	# debugging output.
	INTERNAL_IPS = ('127.0.0.1', os.environ["SSH_CONNECTION"].split(" ")[0])
	if sys.argv == ['./manage.py', 'runserver']: print "Internal IPs:", repr(INTERNAL_IPS)
                                        
# Local time zone for this installation. Choices can be found here:
# http://en.wikipedia.org/wiki/List_of_tz_zones_by_name
# although not all choices may be available on all operating systems.
# If running in a Windows environment this must be set to the same as your
# system time zone.
TIME_ZONE = 'America/New_York'

# Language code for this installation. All choices can be found here:
# http://www.i18nguy.com/unicode/language-identifiers.html
LANGUAGE_CODE = 'en-us'

SITE_ID = 1

# If you set this to False, Django will make some optimizations so as not
# to load the internationalization machinery.
USE_I18N = True

# Absolute path to the directory that holds media.
# Example: "/home/media/media.lawrence.com/"
MEDIA_ROOT = os.path.join(ROOT, 'media')

# URL that handles the media served from MEDIA_ROOT. Make sure to use a
# trailing slash if there is a path component (optional in other cases).
# Examples: "http://media.lawrence.com", "http://example.com/media/"
MEDIA_URL = '/media/'

STATIC_URL = '/static/'
STATICFILES_DIRS = [os.path.join(ROOT, 'static')]

# django-regitration-pv
APP_NICE_SHORT_NAME = "GovTrack" # a short name for your site
SITE_ROOT_URL = "https://www.govtrack.us"
LOGIN_REDIRECT_URL = "/accounts/profile"
SERVER_EMAIL = "GovTrack.us <noreply@mail.GovTrack.us>" # From: address on verification emails
REGISTRATION_ASK_USERNAME = False

SESSION_COOKIE_AGE = 6*604800 # seconds in six weeks
SESSION_COOKIE_SECURE = not DEBUG # send session cookies over SSL only
CSRF_COOKIE_SECURE = not DEBUG # similarly
SESSION_SERIALIZER = 'django.contrib.sessions.serializers.PickleSerializer' # needed by openid login

EMAIL_HOST = 'localhost'
EMAIL_PORT = 587
#EMAIL_HOST_USER = ''
#EMAIL_HOST_PASSWORD = ''

# List of callables that know how to import templates from various sources.
TEMPLATE_LOADERS = (
    'django.template.loaders.filesystem.Loader',
    'django.template.loaders.app_directories.Loader',
)
if not DEBUG:
    TEMPLATE_LOADERS = (
      ('django.template.loaders.cached.Loader', TEMPLATE_LOADERS),
      )

MIDDLEWARE_CLASSES = (
    'django.middleware.common.CommonMiddleware',
    'django.contrib.sessions.middleware.SessionMiddleware',
    'django.contrib.auth.middleware.AuthenticationMiddleware',
    #'debug_toolbar.middleware.DebugToolbarMiddleware',
    'django.contrib.messages.middleware.MessageMiddleware',
    'django.middleware.csrf.CsrfViewMiddleware',
    'twostream.middleware.CacheLogic',
    'website.middleware.GovTrackMiddleware',
)

ROOT_URLCONF = 'urls'

TEMPLATE_DIRS = (
    # Put strings here, like "/home/html/django_templates" or "C:/www/django/templates".
    # Always use forward slashes, even on Windows.
    # Don't forget to use absolute paths, not relative paths.
    os.path.join(ROOT, 'templates'),
)

INSTALLED_APPS = (
    'django.contrib.auth',
    'django.contrib.contenttypes',
    'django.contrib.sessions',
    'django.contrib.sites',
    'django.contrib.admin',
    'django.contrib.humanize',
    'django.contrib.sitemaps',
    'django.contrib.staticfiles',

    # 3rd party libraries
    'common',
    'django_extensions',
    #'south',
    #'debug_toolbar',
    
    'haystack',
    'tastypie',
    'django_wysiwyg',
    'django_twilio',
    
    # project modules
    'twostream',
    'simplegetapi',
    'person',
    'committee',
    'website',
    'vote',
    'parser',
    'events',
    'smartsearch',
    'bill',
    'states',
    'poll_and_call',
    'predictionmarket',

    # for django-registration-pv
    'emailverification',
    'registration',
)

TEMPLATE_CONTEXT_PROCESSORS = (
    'django.contrib.auth.context_processors.auth',
    'django.core.context_processors.debug',
    'django.core.context_processors.i18n',
    'django.core.context_processors.media',
    'django.core.context_processors.request',
    'django.core.context_processors.static',
    'events.middleware.template_context_processor',
    'website.middleware.template_context_processor',
)

TEST_DATABASE_CHARSET = 'utf8'

DATETIME_FORMAT = 'M d, Y P'
DATE_FORMAT = 'M d, Y'

SEND_BROKEN_LINK_EMAILS = False
IGNORABLE_404_ENDS = ('spinner.gif', 'billtext/images/quote.png')
IGNORABLE_404_STARTS = ('/phpmyadmin/',)
import re
IGNORABLE_404_URLS = (
	re.compile(r'^/phpmyadmin/'),
	re.compile(r'spinner\.gif'),
	re.compile(r'billtext/images/quote.png$'),
	)

CURRENT_CONGRESS = 113

EMAIL_UPDATES_FROMADDR = "GovTrack.us Email Updates <noreply@mail.GovTrack.us>"
EMAIL_UPDATES_RETURN_PATH = "bounces+uid=%d@GovTrack.us"
BOUNCES_UID_REGEX = re.compile(r"<?bounces\+uid=(\d+)@GovTrack\.us>?", re.I)

PREDICTIONMARKET_SEED_MONEY = 1000
PREDICTIONMARKET_BANK_UID = 136196

#if DEBUG: # sometimes we debug in a live environment
#	EMAIL_BACKEND = 'django.core.mail.backends.console.EmailBackend'

try:
    from settings_local import *
except ImportError:
    pass

if not SECRET_KEY:
    raise Exception('You must provide SECRET_KEY value in settings_local.py')

# Since we rely on external APIs in a few places, make sure
# that downed APIs elsewhere don't hold us too long. Not
# sure this has any useful effect.
import socket
socket.setdefaulttimeout(10.0)


########NEW FILE########
__FILENAME__ = settings_local.example
import os.path

ALLOWED_HOSTS = ["*"]

DATABASES = {
	'default': {
        'NAME': os.path.dirname(__file__) + '/database.sqlite',
        'ENGINE': 'django.db.backends.sqlite3',
   	}
}

CACHES = {
	'default': {
        'BACKEND': 'django.core.cache.backends.locmem.LocMemCache',
        'LOCATION': 'opendataiscool'
	}
}

HAYSTACK_CONNECTIONS = {
    'default': { # required but not used
        'ENGINE': 'haystack.backends.simple_backend.SimpleEngine',
    },
    'person': {
        'ENGINE': 'haystack.backends.simple_backend.SimpleEngine', # replace this
    },
    'bill': {
        'ENGINE': 'haystack.backends.simple_backend.SimpleEngine', # replace this
    },
    'states': {
        'ENGINE': 'haystack.backends.simple_backend.SimpleEngine', # replace this
    },
}                   

CONGRESS_LEGISLATORS_PATH='../congress-legislators/'
GEOIP_DB_PATH = None
RSS_CAMPAIGN_QUERYSTRING = "?utm_campaign=govtrack_feed&utm_source=govtrack/feed&utm_medium=rss"

SECRET_KEY = 'fill this in'

GOOGLE_ANALYTICS_KEY = 'fill this in' 

SUNLIGHTLABS_API_KEY = 'fill this in'
YOUTUBE_API_KEY = 'fill this in'

# for registration
RECAPTCHA_PUBLIC_KEY = "fill this in"
RECAPTCHA_PRIVATE_KEY = "fill this in"
TWITTER_OAUTH_TOKEN = "fill this in"
TWITTER_OAUTH_TOKEN_SECRET = "fill this in"
FACEBOOK_APP_ID = "fill this in"
FACEBOOK_APP_SECRET = "fill this in"
FACEBOOK_AUTH_SCOPE = "email" # can be an empty string

# The ad-free payment requires something like this:
#import paypalrestsdk
#paypalrestsdk.configure(mode="sandbox", client_id="...", client_secret="...")


########NEW FILE########
__FILENAME__ = manager
"""
"""
from django import forms
from django.shortcuts import redirect, get_object_or_404, render_to_response
from django.template import Template, Context, RequestContext
from django.template.loader import get_template
from django.db.models import Count
from django.http import HttpResponse
from django.core.paginator import Paginator
from django.core.cache import cache

import json, urllib, hashlib

from common.enum import MetaEnum

FACET_CACHE_TIME = 60*60
FACET_OPTIONS = { "limit": -1, "mincount": 1, "sort": "count" } # limits cause problems because the selected option can dissapear!

class SearchManager(object):
    def __init__(self, model, qs=None, connection=None):
        self.model = model
        self.qs = qs
        self.options = []
        self._form = None
        self.col_left = None
        self.col_left_name = None
        self.col_bottom = None
        self.cols = []
        self.colnames = []
        self.sort_options = []
        self.global_filters = { }
        self.connection = connection
        self.template = None
        self.template_context_func = None

    def add_option(self, *args, **kwargs):
        Option(self, *args, **kwargs)
        
    def add_sort(self, sort_name, sort_key, default=False):
        self.sort_options.append( (sort_name, sort_key, default) )
        
    def add_filter(self, key, value):
        self.global_filters[key] = value
        
    def set_template(self, template_data):
        self.template = Template(template_data)
    def set_template_file(self, template_file_name):
        self.template = get_template(template_file_name)
    def set_template_context_func(self, func):
        self.template_context_func = func
        
    def results(self, objects, form):
        if not self.template:
            self.template = get_template("smartsearch/search-result-item.html")
        if not self.template_context_func:
            self.template_context_func = lambda obj, form : Context({ "object": obj, "form": form })
        return [self.template.render(self.template_context_func(obj, form)) for obj in objects]
    
    def view(self, request, template, defaults={}, noun=("item", "items"), context={}, paginate=None):
        if request.META["REQUEST_METHOD"] == "GET" \
        	and request.GET.get('do_search', None) == None:
            c = {
                'form': self.options,
                'sort_options': [(name, key, isdefault if defaults.get("sort", None) == None else defaults.get("sort", None) == key) for name, key, isdefault in self.sort_options],
                'defaults': defaults,
                'noun_singular': noun[0],
                'noun_plural': noun[1],
                }
            c.update(context)
            return render_to_response(template, c, RequestContext(request))
            
        # Get the dict of params. We use .urlencode() on the dict which is available for .GET and .POST
        # but not .REQUEST. We can switch completely to request.GET later, after a transition time
        # which caches expire.
        qsparams = (request.GET if request.META["REQUEST_METHOD"] == "GET" else request.POST)

        # Although we cache some facet queries, also cache the final response.
        m = hashlib.md5()
        m.update(self.model.__name__ + "|" + qsparams.urlencode())
        cachekey = "smartsearch__response__" + m.hexdigest()
        resp = cache.get(cachekey)
        if resp and False:
            resp = HttpResponse(resp, content_type='text/json')
            resp["X-Cached"] = "True"
            return resp

        try:
            qs = self.queryset(qsparams)
            
            # In order to generate the facets, we will call generate_choices on each
            # visible search field. When generating facets with the Django ORM, a
            # separate query is required because only one .annotate() can be used
            # at a time. However, with Haystack we can facet on multiple fields at
            # once efficiently.
            #
            # Still, the underlying queries are different for fields that have values
            # chosen by the user. Each facet shows the counts of matched objects
            # by value, including the filtering set on other fields, but of course not
            # the filtering set on its own field because then it would return just
            # one category.
            #
            # So optimizing the facet query for Haystack can pre-load only the facets
            # that have the same underlying query --- i.e. only the facets that have
            # no value set by the user.
            loaded_facets = None
            if hasattr(qs, 'facet'):
                faceted_qs = qs
                loadable_facets = []
                for option in self.options:
                    if option.filter: continue
                    if option.field_name in qsparams or option.field_name+"[]" in qsparams: continue
                    if option.type == "text": continue
                    if option.type == "select" and qsparams["faceting"]=="false": continue # 2nd phase only
                    loadable_facets.append(option.field_name)
                    faceted_qs = faceted_qs.facet(option.orm_field_name, **FACET_OPTIONS)
                if len(loadable_facets) > 0:
                    cache_key = self.build_cache_key('bulkfaceting__' + ",".join(loadable_facets), qsparams)
                    loaded_facets = cache.get(cache_key)
                    if not loaded_facets:
                        fq = faceted_qs.facet_counts()
                        if "fields" in fq: # don't know why it sometimes gives nothing
                            loaded_facets = fq["fields"]
                            cache.set(cache_key, loaded_facets, FACET_CACHE_TIME)

            # At the moment there's no need to cache the count because we also cache the final response.
            #cache_key = self.build_cache_key('count', qsparams)
            #qs_count = cache.get(cache_key)
            #if qs_count == None:
            #    qs_count = qs.count()
            #    cache.set(cache_key, qs_count, FACET_CACHE_TIME)
            qs_count = qs.count()
                
            def make_simple_choices(option):
                return option.type == "select" and not option.choices

            facets = [(
                option.field_name,
                option.type,
                
                self.generate_choices(qsparams, option, loaded_facets,
                    # In order to speed up the display of results, we query the facet counts
                    # in two phases. The facet counts for select-type fields are delayed
                    # until the second phase (because you can't see them immediately).
                    # In the first phase, we cheat (to be quick) by not omitting the selected
                    # value in the facet counting query, which means we only get back the 
                    # counts for entries that match the currently selected value, which is
                    # all the user can see in the drop-down before the click the select box
                    # anyway. If the select field's value is unset (i.e. all), then we load
                    # all results in both phases.
                    simple=make_simple_choices(option) and qsparams["faceting"]=="false"),
                
                make_simple_choices(option) and qsparams["faceting"]=="false",
                
                option.field_name in qsparams or option.field_name+"[]" in qsparams or option.visible_if(qsparams) if option.visible_if else True
                ) for option in self.options
                    
                    # In the second phase, don't generate facets for options we've already
                    # done in the first phase.
                    if qsparams["faceting"]=="false" or make_simple_choices(option)
                ]

            if qsparams["faceting"] == "false":
                if not paginate or paginate(qsparams):
                    page_number = int(qsparams.get("page", "1"))
                    per_page = 20
                else:
                    page_number = 1
                    per_page = qs_count
                
                page = Paginator(qs, per_page)
                obj_list = page.page(page_number).object_list
            
                ret = {
                    "results": self.results(obj_list, qsparams),
                    "options": facets,
                    "page": page_number,
                    "num_pages": page.num_pages,
                    "per_page": per_page,
                    "total_this_page": len(obj_list),
                    "total": qs_count,
                }
                
                try:
                    ret["description"] = self.describe(dict(qsparams.iterlists()))
                except:
                    pass # self.describe is untested

            else:
                ret = facets

            # Cache the final response for 5 minutes.
            ret = json.dumps(ret)
            cache.set(cachekey, ret, 60*5)
            return HttpResponse(ret, content_type='text/json')
        except Exception as e:
            import traceback
            traceback.print_exc()
            return HttpResponse(json.dumps({
                "error": repr(e),
                "stack": traceback.format_exc().split("\n"),
                }), content_type='text/json')
            
    def queryset(self, postdata, exclude=None):
        """
        Build the `self.model` queryset limited to selected filters.
        """
        
        if not self.qs:
            #qs = self.model.objects.all().select_related()
            from haystack.query import SearchQuerySet
            qs = SearchQuerySet()
            if self.connection: qs = qs.using(self.connection)
            qs = qs.filter(indexed_model_name__in=[self.model.__name__], **self.global_filters)
        else:
            qs = self.qs

        filters = { }
        
        # Then for each filter
        for option in self.options:
            # If filter is not excluded explicitly (used to get counts
            # for choices).
            if option == exclude: continue
            
            # If filter contains valid data, check jQuery style encoding of array params
            if option.field_name not in postdata and option.field_name+"[]" not in postdata: continue
            
            # Do filtering

            if option.filter is not None:
                qs_ = option.filter(qs, postdata)
                
                if isinstance(qs_, dict):
                    filters.update(qs_)
                else:
                    qs = qs_
                
            else:
                values = postdata.getlist(option.field_name)+postdata.getlist(option.field_name+"[]")
                
                if option.type == "text":
                    # For full-text searching, don't use __in so that the search
                    # backend does its usual query operation.
                    values = " ".join(values) # should not really be more than one, but in case the parameter is specified multiple times in the query string
                    if not self.qs:
                       # This is a Haystack search. Handle text a little differently.
                       # Wrap it in an AutoQuery so advanced search options like quoted phrases are used.
                       from haystack.inputs import AutoQuery
                       values = AutoQuery(values)
                    filters[option.orm_field_name] = values
                    
                elif not u'__ALL__' in values:
                    # if __ALL__ value presents in filter values
                    # then do not limit queryset

                    def parse_booleans(x):
                        for y in x:
                            if y in ("true", "on"):
                                yield True
                            elif y == "false":
                                yield False
                            else:                        
                                yield y
                    values = list(parse_booleans(values))

                    filters['%s__in' % option.orm_field_name] = values

        # apply filters simultaneously so that filters on related objects are applied
        # to the same related object. if they were applied chained (i.e. filter().filter())
        # then they could apply to different objects.
        if len(filters) > 0:
            qs = qs.filter(**filters)
            
        for name, key, default in self.sort_options:
            if postdata.get("sort", "") == key:
                qs = qs.order_by(key)
        
        # Django ORM but not Haystack
        if hasattr(qs, 'distinct'):
            return qs.distinct()
            
        # Haystack but not Django ORM
        else:
            # Revise the SearchQuerySet to iterate over model objects
            # rather than SearchResult objects.
            class SR:
                def __init__(self, qs):
                    self.qs = qs
                def facet(self, field, **kwargs):
                    return self.qs.facet(field, **kwargs)
                def count(self):
                    return len(self.qs)
                def order_by(self, field):
                    return SR(self.qs.order_by(field))
                def __len__(self):
                    return len(self.qs)
                def __getitem__(self, index): # slices too
                    return SR(self.qs[index])
                def __iter__(self):
                    for item in self.qs:
                        yield item.object
            return SR(qs)
            
    def build_cache_key(self, prefix, qsparams, omit=None):
        def get_value(f):
            if f in qsparams: return urllib.quote(qsparams[f])
            if f + "[]" in qsparams: return "&".join(urllib.quote(v) for v in sorted(qsparams.getlist(f + "[]")))
            return ""
        return "smartsearch_%s_%s__%s" % (
            self.model.__name__,
            prefix,
            "&".join( unicode(k) + "=" + unicode(v) for k, v in self.global_filters.items() )
            + "&&" +
            "&".join( o.field_name + "=" + get_value(o.field_name) for o in self.options if (o.field_name in qsparams or o.field_name + "[]" in qsparams) and (o != omit) ),
            )        
                        
    def get_model_field(self, option):
        include_counts = True
        choice_label_map = None
        try:
            meta = self.model._meta
            if "__" not in option.orm_field_name:
                fieldname = option.orm_field_name
            else:
                include_counts = False # one-to-many relationships make the aggregation return non-distinct results
                path = option.orm_field_name.split("__")
                fieldname = path.pop()
                for p in path:
                    meta = [f.model._meta for f in meta.get_all_related_objects() if f.get_accessor_name() == p][0]
            field = meta.get_field(fieldname)
            if field.choices:
                choice_label_map = dict(field.choices)
        except:
            # Some fields indexed by Haystack may not be model fields.
            field = None
        return include_counts, field, choice_label_map
                        
    def generate_choices(self, qsparams, option, loaded_facets, simple=False):
        # There are no facets for text-type fields.
        if option.type == "text":
            return None
            
        # Option is not set and we only want simple results.
        if simple and not (option.field_name in qsparams or option.field_name+"[]" in qsparams or option.field_name in self.global_filters):
            return [('__ALL__', 'All', -1, None)]

        cache_key = self.build_cache_key('faceting__' + option.field_name, qsparams, omit=option if not simple else None)
        
        if option.choices:
            if callable(option.choices):
                counts = option.choices(qsparams)
            else:
                counts = list(option.choices)
        else:
            ret = cache.get(cache_key)
            if ret: return ret
           
            # Get the model field metadata object that represents this field. 
            include_counts, field, choice_label_map = self.get_model_field(option)
            
            # Calculate number of possible results for each option, using the current
            # search terms except for this one.
            # Use `form.queryset()` to track already applied options
            
            def get_object_set(ids):
                if not field: return None
                if field.choices: return None
                if field.__class__.__name__ in ('ForeignKey', 'ManyToManyField'):
                    # values+annotate makes the db return an integer rather than an object,
                    # and Haystack always returns integers rather than objects
                    return field.rel.to.objects.in_bulk(ids)
                return None

            def nice_name(value, objs):
                if value == None: return "N/A"
                if option.formatter: return option.formatter(objs[value] if objs and value in objs else value)
                if field and field.choices and value in choice_label_map:
                    return choice_label_map[value]
                if type(value) == bool and value == True: return "Yes"
                if type(value) == bool and value == False: return "No"
                if field and field.__class__.__name__ in ('ForeignKey', 'ManyToManyField'):
                    # values+annotate makes the db return an integer rather than an object
                    if objs and value in objs:
                        return unicode(objs[value])
                    value = field.rel.to.objects.get(id=value)
                return unicode(value)
            
            def fix_value_type(value):
                # Solr and ElasticSearch return strings on integer data types.
                if isinstance(value, (str, unicode)) and field.__class__.__name__ in ('IntegerField', 'ForeignKey', 'ManyToManyField'):
                    return int(value)
                return value

            def build_choice(value, count):
                # (key, label, count, help_text) tuples
                value = fix_value_type(value)
                return (
                    value,
                    nice_name(value, objs),
                    count,
                    getattr(field.choices.by_value(value), "search_help_text", None)
                        if field and field.choices and type(field.choices) == MetaEnum else None)
            
            if loaded_facets and option.field_name in loaded_facets:
                # Facet counts were already loaded.
                facet_counts = loaded_facets[option.field_name]
                objs = get_object_set([opt[0] for opt in facet_counts])
                counts = [build_choice(opt[0], opt[1]) for opt in facet_counts]
            else:
                resp = self.queryset(qsparams, exclude=option if not simple else None)
                
                if hasattr(resp, 'facet'):
                    # Haystack.
                    resp = resp.facet(option.orm_field_name, **FACET_OPTIONS).facet_counts()
                    if len(resp) == 0:
                        return []
                    facet_counts = resp["fields"][option.orm_field_name]
                    objs = get_object_set([opt[0] for opt in facet_counts])
                    counts = [build_choice(opt[0], opt[1]) for opt in facet_counts]
                else:
                    # ORM explanation: do GROUP BY, then COUNT
                    # http://docs.djangoproject.com/en/dev/topics/db/aggregation/#values
                    resp = resp\
                               .values(option.orm_field_name)\
                               .annotate(_count=Count('id'))\
                               .distinct().order_by()
                           
                    objs = get_object_set([x[option.orm_field_name] for x in resp if x[option.orm_field_name] != ""])
                    counts = [ 
                        build_choice(x[option.orm_field_name], x['_count'] if include_counts else None)
                        for x in resp if x[option.orm_field_name] != ""]
                        
            ## Stock Solr returns facets that have 0 count. Filter those out.
            ## Except we're using my fork to unset the facet limit.
            #counts = [c for c in counts if c[2] > 0]
            
            # Sort by count then by label.
            if option.sort == "COUNT":
                counts.sort(key=lambda x: (-x[2] if x[2] != None else None, x[1]))
            elif option.sort == "KEY":
                counts.sort(key=lambda x: x[0])
            elif option.sort == "KEY-REVERSE":
                counts.sort(key=lambda x: x[0], reverse=True)
            elif option.sort == "LABEL":
                counts.sort(key=lambda x: x[1])
            elif option.sort == "LABEL-REVERSE":
                counts.sort(key=lambda x: x[1], reverse=True)
            elif callable(option.sort):
                counts.sort(key=lambda x : option.sort( objs[x[0]] if objs and x[0] in objs else x[0] ))

        if not option.required and counts != "NONE":
            counts.insert(0, ('__ALL__', 'All', -1, None))
            
        cache.set(cache_key, counts, FACET_CACHE_TIME)

        return counts
        
    def execute_qs(self, qs, defaults=None, overrides=None):
        from django.http import QueryDict
        qd = QueryDict(qs).copy() # copy makes mutable
        if defaults:
            for k in defaults:
                qd.setdefault(k, defaults[k])
        if overrides:
            for k in overrides:
                qd[k] = overrides[k]
        return self.queryset(qd)

    def describe_qs(self, qs):
        import urlparse
        return self.describe(urlparse.parse_qs(qs))
        
    def describe(self, qs): # qs is a dict from field names to a list of values, like request.POST
        descr = []
        for option in self.options:
            if option.field_name not in qs: continue
            
            # Get a function to format the value.
            include_counts, field, choice_label_map = self.get_model_field(option)
            if option.type == "text":
                # Pass through text fields.
                formatter = lambda v : v
            elif option.choices or choice_label_map:
                # If choices are specified on the option or on the ORM field, use that.
                choices = choice_label_map
                if option.choices: choices = option.choices
                choices = dict((str(k), v) for k,v in choices) # make sure keys are strings
                formatter = lambda v : choices[v]
            else:
                def formatter(value):
                    # If the ORM field is for objects, map ID to an object value, then apply option formatter. 
                    if field and field.__class__.__name__ in ('ForeignKey', 'ManyToManyField'):
                        value = field.rel.to.objects.get(id=v)
                    if option.formatter: return option.formatter(value)
                    return unicode(value)
                
            vals = []
            for v in qs[option.field_name]:
                vals.append(formatter(v))
            
            if option.type == "text":
                descr.append(", ".join(vals))
            else:
                label = option.label
                if not label: label = option.field_name
                descr.append(label + ": " + ", ".join(vals))
        
        return "; ".join(descr)

class Option(object):
    def __init__(self, manager, field_name, type="checkbox", required=False,
                 filter=None, choices=None, label=None, sort="COUNT",
                 visible_if=None, help=None, formatter=None, orm_field_name=None):
        """
        Args:
            manager: `SearchManager` instance
            field_name: name of model's field for which the filter shoudl be built
            type: text, select, or checkbox
            required: set to True to not include the ALL option
            filter: custom logic for filtering queryset
            choices: override the choices available
            label: override the label
            visible_if: show this option only if a function returns true (passed one arg, the request.POST)
        """

        self.manager = manager
        self.field_name = field_name
        self.type = type
        self.required = required
        self.filter = filter
        self.manager.options.append(self)
        self.choices = choices
        self.label = label
        self.sort = sort
        self.visible_if = visible_if
        self.help = help
        self.formatter = formatter
        self.orm_field_name = orm_field_name if orm_field_name else field_name
        

########NEW FILE########
__FILENAME__ = models

########NEW FILE########
__FILENAME__ = tests
"""
Smartsearch application tests.
"""
from django.test import TestCase
from django.db import models
from django import forms

from smartsearch.manager import SearchManager, Option, SmartChoiceField

RED = 1
GREEN = 2
BLUE = 3

COLORS = (
    (RED, 'Red'),
    (GREEN, 'Green'),
    (BLUE, 'Blue'),
)

COLOR_COUNTS = {
    RED: 1,
    GREEN: 3,
    BLUE: 5
}

class Thing(models.Model):
    color = models.IntegerField(choices=COLORS)

class RequestMockup(object):
    pass

class SearchTestCase(TestCase):
    def setUp(self):
        for color, count in COLOR_COUNTS.items():
            for x in xrange(count):
                Thing.objects.create(color=color)

    def test_setup(self):
        self.assertEqual(Thing.objects.filter(color=RED).count(),
                         COLOR_COUNTS[RED])

    def test_searchmanager(self):
        sm = SearchManager(Thing)
        sm.add_option('color')
        form = sm.form()
        self.assertTrue(
            isinstance(form.fields['color'], SmartChoiceField))
        for key, value in form.fields['color'].choices[1:]:
            value.endswith('(%d)' % COLOR_COUNTS[key])
        req = RequestMockup()
        req.GET = {'color': [str(RED)]}
        form = sm.form(req)
        qs = form.queryset()
        self.assertEqual(len(qs), COLOR_COUNTS[RED])

########NEW FILE########
__FILENAME__ = models
# -*- coding: utf-8 -*-
from django.db import models
from django.template.defaultfilters import slugify
from django.core.urlresolvers import reverse

from common import enum
from json_field import JSONField

from django.conf import settings

import datetime, os.path

import us

"Enums"

class StateChamberEnum(enum.Enum):
	unknown = enum.Item(0, 'Unknown Chamber')
	unicameral = enum.Item(1, 'Unicameral Chamber')
	lower = enum.Item(2, 'Lower Chamber')
	upper = enum.Item(3, 'Upper Chamber')

"Models"

class StateLegislator(models.Model):
	bt50id = models.IntegerField(unique=True, db_index=True)
	openstatesid = models.CharField(max_length=10, unique=True, db_index=True, blank=True, null=True)
	legiscanid = models.IntegerField(db_index=True, blank=True, null=True) # there are dups
	
	state = models.CharField(max_length=2)
	firstname = models.CharField(max_length=24)
	lastname = models.CharField(max_length=32)
	fullname = models.CharField(max_length=58)
	party = models.CharField(max_length=16)
	
class StateSubjectTerm(models.Model):
	bt50id = models.IntegerField(unique=True, db_index=True)
	state = models.CharField(max_length=2)
	name = models.CharField(max_length=128)

	class Meta:
		ordering = ('state', 'name')
		unique_together = [('state', 'name')]

class StateSession(models.Model):
	state = models.CharField(max_length=2)
	startdate = models.DateField(blank=True, null=True)
	enddate = models.DateField(blank=True, null=True)
	name = models.CharField(max_length=64)
	slug = models.CharField(max_length=12)
	current = models.BooleanField(default=True)

	class Meta:
		ordering = ('state', 'startdate')
		unique_together = [('state', 'name'), ('state', 'slug')]

	def __unicode__(self):
		return us.statenames[self.state] + " " + self.name
		
	def set_date_range(self):
	    # Set the start/end date range based on the last action dates of
	    # bills tied to this state session.
	    from django.db.models import Min, Max
	    drange = self.statebill_set.aggregate(Min('last_action_date'), Max('last_action_date'))
	    self.startdate = drange['last_action_date__min']
	    self.enddate = drange['last_action_date__max']
	    self.save()
	    
	def set_is_current(self):
	    # Set current if there is no other state session for this state with
	    # a later date. This is used to know what bills can have further
	    # action. But at least AK's bills dont ever expire, and maybe that's
	    # in other states too, so this would be incorrect for that. But
	    # we'd still like to know what is the current session.
	    if self.enddate == None:
	        # Not sure.
	        self.current = False
	        self.save()
	        return
	    self.current = not StateSession.objects.filter(state=self.state, startdate__gte=self.enddate).exists()
	    self.save()

from events.models import Feed
Feed.register_feed(
	"states_allbills",
	title = "State Legislation: All Activity",
	slug = "states_bills",
	intro_html = """Use this feed to track all legislative events in all United States state legislatures.""",
	simple = True,
	sort_order = 200,
	category = "state-bills",
	description = "Get an update on major activity on all state legislation.",
	)
for st in us.stateabbrs:
	Feed.register_feed(
		"states_%s_bills" % st,
		title = us.statenames[st] + " Legislation",
		link = "/states/%s" % st.lower(),
		category = "state-bills",
		description = "Get an update on major activity on all bills in this state.",
		)
Feed.register_feed(
	"states_bill:",
	title = lambda feed : unicode(StateBill.objects.get(id=feed.feedname.split(":")[1])),
	link = lambda feed : StateBill.objects.get(id=feed.feedname.split(":")[1]).get_absolute_url(),
	category = "state-bills",
	description = "Get an update on major activity on this bill.",
	)

class StateBill(models.Model):
	bt50id = models.IntegerField(unique=True, db_index=True)
	openstatesid = models.CharField(max_length=32, unique=True, db_index=True, blank=True, null=True)
	legiscanid = models.IntegerField(unique=True, db_index=True, blank=True, null=True)
	
	state_session = models.ForeignKey(StateSession)
	bill_number = models.CharField(max_length=16)
	chamber = models.IntegerField(choices=StateChamberEnum)
	
	short_title = models.CharField(max_length=255)
	long_title = models.CharField(max_length=255)
	summary = models.TextField()
	
	introduced_date = models.DateField(blank=True, null=True)
	last_action_date = models.DateField(blank=True, null=True)
	last_action_seq = models.IntegerField(blank=True, null=True)
	last_action_text = models.CharField(max_length=128, blank=True, null=True)

	sponsors = models.ManyToManyField(StateLegislator, blank=True, related_name="sponsored_bills")
	cosponsors = models.ManyToManyField(StateLegislator, blank=True, related_name="cosponsored_bills")
	
	subjects = models.ManyToManyField(StateSubjectTerm, blank=True)
	
	srchash = models.CharField(max_length=40)
	
	class Meta:
		ordering = ('state_session', 'bill_number', 'chamber')
		unique_together = [('state_session', 'bill_number', 'chamber')]
		
	def __unicode__(self):
		return self.short_display_title
		
	def get_absolute_url(self):
		return "/states/%s/bills/%s/%s" % (self.state_session.state.lower(), self.state_session.slug, self.bill_number.lower())
		
	# indexing
	def get_index_text(self):
		return self.long_title + "\n" + self.short_title + "\t" + self.summary
	haystack_index = ('state_session', 'bill_number', 'chamber', 'last_action_date')
	haystack_index_extra = (('state', 'Char'),)

	def state_name(self): return us.statenames[self.state_session.state]

	@property
	def short_display_title(self):
		#return self.state_session.state + " " + self.state_session.slug + " " + self.bill_number + ". " + self.short_title
		return self.bill_number + " (" + self.state_session.state + " " + self.state_session.slug + "): " + self.short_title
		
	@property
	def is_current(self):
		return self.state_session.current
		
	def state(self): return self.state_session.state
	def session(self): return self.state_session.name

	def create_events(self):
		# don't create events too far in the past because they will never be used
		if not self.introduced_date: return
		if self.introduced_date.year < 2012: return
		
		# What feeds will we file events for this bill under?
		#   a) The 50-state-legislation feed.
		#   b) The state-wide legislation feed.
		#   c) The bill's feed.
		
		from events.models import Feed, Event
		
		AllBills, is_new = Feed.objects.get_or_create(feedname="states_allbills")
		StateBills, is_new = Feed.objects.get_or_create(feedname="states_%s_bills" % self.state_session.state)
		ThisBill, is_new = Feed.objects.get_or_create(feedname="states_bill:%d" % self.id)
		our_feeds = [AllBills, StateBills, ThisBill]
		
		with Event.update(self) as E:
			for axn in self.actions.all(): # natural sort order should be preserved
				E.add("axn:" + str(axn.id), axn.date, our_feeds)
	
	def render_event(self, eventid, feeds):
		axn = StateBillAction.objects.get(id=eventid.split(":")[1])
		return {
			"type": "State Legislative Action",
			"date": axn.date,
			"date_has_no_time": True,
			"title": axn.bill,
			"url": axn.bill.get_absolute_url(),
			"body_text_template": "{{event|safe}}",
			"body_html_template": "{{event}}",
			"context": {
				"event": axn.text,
				},
			}
			
			
class StateBillAction(models.Model):
	bt50id = models.IntegerField(unique=True, db_index=True)
	
	bill = models.ForeignKey(StateBill, related_name="actions", db_index=True)
	seq = models.IntegerField()
	date = models.DateTimeField()
	text = models.TextField()

	class Meta:
		ordering = ('bill', 'date', 'seq')
		unique_together = [('bill', 'date', 'seq')] # actually not unique, must update in MySQL
		
			
class StateBillDocument(models.Model):
	bt50id = models.IntegerField(unique=True, db_index=True)
	
	bill = models.ForeignKey(StateBill, related_name="documents", db_index=True)
	type = models.CharField(max_length=16)
	url = models.CharField(max_length=256)

	class Meta:
		ordering = ('bill',)


########NEW FILE########
__FILENAME__ = openstates_metadata
# This file (except this top part) was generated from the Sunlight
# Labs Open States API, using the following code.
#
# from us import statenames
# from settings import SUNLIGHTLABS_API_KEY
# from urllib import urlopen
# import json, pprint
#
# states_metadata = { }
# for state in statenames:
#  try:
#   states_metadata[state] = json.load(urlopen("http://openstates.org/api/v1/metadata/%s?apikey=%s" % (state.lower(), SUNLIGHTLABS_API_KEY)))
#  except ValueError:
#   print state
# pprint.pprint(states_metadata, open("states/openstates_metadata.py", "w")) # warning: overwrites this comment

stata_metadata = \
{'AK': {u'abbreviation': u'ak',
        u'feature_flags': [u'subjects'],
        u'id': u'ak',
        u'latest_csv_date': u'2012-05-01 09:01:22',
        u'latest_csv_url': u'http://static.openstates.org/downloads/2012-05-01-ak-csv.zip',
        u'latest_json_date': u'2012-05-01 15:43:47',
        u'latest_json_url': u'http://static.openstates.org/downloads/2012-05-01-ak-json.zip',
        u'latest_update': u'2012-05-27 00:51:57',
        u'legislature_name': u'The Alaska State Legislature',
        u'level': u'state',
        u'lower_chamber_name': u'House of Representatives',
        u'lower_chamber_term': 2,
        u'lower_chamber_title': u'Representative',
        u'name': u'Alaska',
        u'session_details': {u'26': {u'display_name': u'26th Legislature'},
                             u'27': {u'display_name': u'27th Legislature'}},
        u'terms': [{u'end_year': 2010,
                    u'name': u'26',
                    u'sessions': [u'26'],
                    u'start_year': 2009},
                   {u'end_year': 2012,
                    u'name': u'27',
                    u'sessions': [u'27'],
                    u'start_year': 2011}],
        u'upper_chamber_name': u'Senate',
        u'upper_chamber_term': 4,
        u'upper_chamber_title': u'Senator'},
 'AL': {u'abbreviation': u'al',
        u'feature_flags': [u'subjects'],
        u'id': u'al',
        u'latest_csv_date': u'2012-05-01 09:12:41',
        u'latest_csv_url': u'http://static.openstates.org/downloads/2012-05-01-al-csv.zip',
        u'latest_json_date': u'2012-05-02 00:36:17',
        u'latest_json_url': u'http://static.openstates.org/downloads/2012-05-02-al-json.zip',
        u'latest_update': u'2012-05-27 00:08:07',
        u'legislature_name': u'Alabama Legislature',
        u'level': u'state',
        u'lower_chamber_name': u'House of Representatives',
        u'lower_chamber_term': 4,
        u'lower_chamber_title': u'Representative',
        u'name': u'Alabama',
        u'session_details': {u'2011rs': {u'display_name': u'2011 Regular Session',
                                         u'internal_id': u'1058',
                                         u'type': u'primary'},
                             u'2012rs': {u'display_name': u'2012 Regular Session',
                                         u'internal_id': u'1059',
                                         u'type': u'primary'},
                             u'First Special Session 2012': {u'display_name': u'First Special Session 2012',
                                                             u'internal_id': u'1060',
                                                             u'type': u'special'}},
        u'terms': [{u'end_year': 2014,
                    u'name': u'2011-2014',
                    u'sessions': [u'2011rs',
                                  u'2012rs',
                                  u'First Special Session 2012'],
                    u'start_year': 2011}],
        u'upper_chamber_name': u'Senate',
        u'upper_chamber_term': 4,
        u'upper_chamber_title': u'Senator'},
 'AR': {u'abbreviation': u'ar',
        u'feature_flags': [],
        u'id': u'ar',
        u'latest_csv_date': u'2012-05-01 09:01:32',
        u'latest_csv_url': u'http://static.openstates.org/downloads/2012-05-01-ar-csv.zip',
        u'latest_json_date': u'2012-05-01 15:48:41',
        u'latest_json_url': u'http://static.openstates.org/downloads/2012-05-01-ar-json.zip',
        u'latest_update': u'2012-05-27 02:52:57',
        u'legislature_name': u'Arkansas General Assembly',
        u'level': u'state',
        u'lower_chamber_name': u'House of Representatives',
        u'lower_chamber_term': 2,
        u'lower_chamber_title': u'Representative',
        u'name': u'Arkansas',
        u'session_details': {u'2011': {u'display_name': u'2011 Regular Session',
                                       u'end_date': u'2011-04-27 00:00:00',
                                       u'slug': u'2011R',
                                       u'start_date': u'2011-01-10 00:00:00',
                                       u'type': u'primary'},
                             u'2012F': {u'display_name': u'2012 Fiscal Session',
                                        u'slug': u'2012F',
                                        u'start_date': u'2012-02-13 00:00:00',
                                        u'type': u'special'}},
        u'terms': [{u'end_year': 2012,
                    u'name': u'2011-2012',
                    u'sessions': [u'2011', u'2012F'],
                    u'start_year': 2011}],
        u'upper_chamber_name': u'Senate',
        u'upper_chamber_term': 4,
        u'upper_chamber_title': u'Senator'},
 'AZ': {u'abbreviation': u'az',
        u'feature_flags': [u'events'],
        u'id': u'az',
        u'latest_csv_date': u'2012-05-01 09:01:49',
        u'latest_csv_url': u'http://static.openstates.org/downloads/2012-05-01-az-csv.zip',
        u'latest_json_date': u'2012-05-01 15:58:51',
        u'latest_json_url': u'http://static.openstates.org/downloads/2012-05-01-az-json.zip',
        u'latest_update': u'2012-05-27 03:25:33',
        u'legislature_name': u'Arizona State Legislature',
        u'level': u'state',
        u'lower_chamber_name': u'House of Representatives',
        u'lower_chamber_term': 2,
        u'lower_chamber_title': u'Representative',
        u'name': u'Arizona',
        u'session_details': {u'49th-1st-regular': {u'display_name': u'49th Legislature, 1st Regular Session',
                                                   u'end_date': u'2009-07-01 00:00:00',
                                                   u'session_id': 87,
                                                   u'start_date': u'2009-01-12 00:00:00',
                                                   u'type': u'primary'},
                             u'49th-1st-special': {u'display_name': u'49th Legislature, 1st Special Session',
                                                   u'end_date': u'2009-01-31 00:00:00',
                                                   u'session_id': 89,
                                                   u'start_date': u'2009-01-28 00:00:00',
                                                   u'type': u'special'},
                             u'49th-2nd-regular': {u'display_name': u'49th Legislature, 2nd Regular Session',
                                                   u'end_date': u'2010-04-29 00:00:00',
                                                   u'session_id': 93,
                                                   u'start_date': u'2010-01-11 00:00:00',
                                                   u'type': u'primary'},
                             u'49th-2nd-special': {u'display_name': u'49th Legislature, 2nd Special Session',
                                                   u'end_date': u'2009-05-27 00:00:00',
                                                   u'session_id': 90,
                                                   u'start_date': u'2009-05-21 00:00:00',
                                                   u'type': u'special'},
                             u'49th-3rd-special': {u'display_name': u'49th Legislature, 3rd Special Session',
                                                   u'end_date': u'2009-08-25 00:00:00',
                                                   u'session_id': 91,
                                                   u'start_date': u'2009-07-06 00:00:00',
                                                   u'type': u'special'},
                             u'49th-4th-special': {u'display_name': u'49th Legislature, 4th Special Session',
                                                   u'end_date': u'2009-11-23 00:00:00',
                                                   u'session_id': 92,
                                                   u'start_date': u'2009-11-17 00:00:00',
                                                   u'type': u'special'},
                             u'49th-5th-special': {u'display_name': u'49th Legislature, 5th Special Session',
                                                   u'end_date': u'2009-12-19 00:00:00',
                                                   u'session_id': 94,
                                                   u'start_date': u'2009-12-17 00:00:00',
                                                   u'type': u'special'},
                             u'49th-6th-special': {u'display_name': u'49th Legislature, 6th Special Session',
                                                   u'end_date': u'2010-02-11 00:00:00',
                                                   u'session_id': 95,
                                                   u'start_date': u'2010-02-01 00:00:00',
                                                   u'type': u'special'},
                             u'49th-7th-special': {u'display_name': u'49th Legislature, 7th Special Session',
                                                   u'end_date': u'2010-03-16 00:00:00',
                                                   u'session_id': 96,
                                                   u'start_date': u'2010-03-08 00:00:00',
                                                   u'type': u'special'},
                             u'49th-8th-special': {u'display_name': u'49th Legislature, 8th Special Session',
                                                   u'end_date': u'2010-04-01 00:00:00',
                                                   u'session_id': 101,
                                                   u'start_date': u'2010-03-29 00:00:00',
                                                   u'type': u'special'},
                             u'49th-9th-special': {u'display_name': u'49th Legislature, 9th Special Session',
                                                   u'end_date': u'2010-08-11 00:00:00',
                                                   u'session_id': 103,
                                                   u'start_date': u'2010-08-09 00:00:00',
                                                   u'type': u'special'},
                             u'50th-1st-regular': {u'display_name': u'50th Legislature, 1st Regular Session',
                                                   u'end_date': u'2011-04-20 00:00:00',
                                                   u'session_id': 102,
                                                   u'start_date': u'2011-01-10 00:00:00',
                                                   u'type': u'primary'},
                             u'50th-1st-special': {u'display_name': u'50th Legislature, 1st Special Session',
                                                   u'end_date': u'2011-01-20 00:00:00',
                                                   u'session_id': 104,
                                                   u'start_date': u'2011-01-19 00:00:00',
                                                   u'type': u'special'},
                             u'50th-2nd-regular': {u'display_name': u'50th Legislature, 2nd Regular Session',
                                                   u'session_id': 107,
                                                   u'type': u'primary'},
                             u'50th-2nd-special': {u'display_name': u'50th Legislature, 2nd Special Session',
                                                   u'end_date': u'2011-02-16 00:00:00',
                                                   u'session_id': 105,
                                                   u'start_date': u'2011-02-14 00:00:00',
                                                   u'type': u'special'},
                             u'50th-3rd-special': {u'display_name': u'50th Legislature, 3rd Special Session',
                                                   u'end_date': u'2011-06-13 00:00:00',
                                                   u'session_id': 106,
                                                   u'start_date': u'2011-06-10 00:00:00',
                                                   u'type': u'special'},
                             u'50th-4th-special': {u'display_name': u'50th Legislature, 4th Special Session',
                                                   u'end_date': u'2011-11-01 00:00:00',
                                                   u'session_id': 108,
                                                   u'start_date': u'2011-11-01 00:00:00',
                                                   u'type': u'special'}},
        u'terms': [{u'end_year': 2010,
                    u'name': u'49',
                    u'sessions': [u'49th-1st-special',
                                  u'49th-2nd-special',
                                  u'49th-1st-regular',
                                  u'49th-3rd-special',
                                  u'49th-4th-special',
                                  u'49th-5th-special',
                                  u'49th-6th-special',
                                  u'49th-7th-special',
                                  u'49th-8th-special',
                                  u'49th-2nd-regular',
                                  u'49th-9th-special'],
                    u'start_year': 2009},
                   {u'end_year': 2012,
                    u'name': u'50',
                    u'sessions': [u'50th-1st-special',
                                  u'50th-2nd-special',
                                  u'50th-3rd-special',
                                  u'50th-4th-special',
                                  u'50th-1st-regular',
                                  u'50th-2nd-regular'],
                    u'start_year': 2011}],
        u'upper_chamber_name': u'Senate',
        u'upper_chamber_term': 2,
        u'upper_chamber_title': u'Senator'},
 'CA': {u'abbreviation': u'ca',
        u'feature_flags': [u'subjects'],
        u'id': u'ca',
        u'latest_csv_date': u'2012-05-01 09:11:24',
        u'latest_csv_url': u'http://static.openstates.org/downloads/2012-05-01-ca-csv.zip',
        u'latest_json_date': u'2012-05-02 14:48:22',
        u'latest_json_url': u'http://static.openstates.org/downloads/2012-05-02-ca-json.zip',
        u'latest_update': u'2012-05-26 00:19:04',
        u'legislature_name': u'California State Legislature',
        u'level': u'state',
        u'lower_chamber_name': u'Assembly',
        u'lower_chamber_term': 2,
        u'lower_chamber_title': u'Assemblymember',
        u'name': u'California',
        u'session_details': {u'20092010': {u'display_name': u'2009-2010 Regular Session',
                                           u'start_date': u'2008-12-01 00:00:00',
                                           u'type': u'primary'},
                             u'20092010 Special Session 1': {u'display_name': u'2009-2010, 1st Special Session',
                                                             u'type': u'special'},
                             u'20092010 Special Session 2': {u'display_name': u'2009-2010, 2nd Special Session',
                                                             u'type': u'special'},
                             u'20092010 Special Session 3': {u'display_name': u'2009-2010, 3rd Special Session',
                                                             u'type': u'special'},
                             u'20092010 Special Session 4': {u'display_name': u'2009-2010, 4th Special Session',
                                                             u'type': u'special'},
                             u'20092010 Special Session 5': {u'display_name': u'2009-2010, 5th Special Session',
                                                             u'type': u'special'},
                             u'20092010 Special Session 6': {u'display_name': u'2009-2010, 6th Special Session',
                                                             u'type': u'special'},
                             u'20092010 Special Session 7': {u'display_name': u'2009-2010, 7th Special Session',
                                                             u'type': u'special'},
                             u'20092010 Special Session 8': {u'display_name': u'2009-2010, 8th Special Session',
                                                             u'type': u'special'},
                             u'20112012': {u'display_name': u'2011-2012 Regular Session',
                                           u'start_date': u'2010-12-06 00:00:00',
                                           u'type': u'primary'},
                             u'20112012 Special Session 1': {u'display_name': u'2011-2012, 1st Special Session',
                                                             u'type': u'special'}},
        u'terms': [{u'+start_date': u'2008-12-01 00:00:00',
                    u'end_year': 2010,
                    u'name': u'20092010',
                    u'sessions': [u'20092010',
                                  u'20092010 Special Session 1',
                                  u'20092010 Special Session 2',
                                  u'20092010 Special Session 3',
                                  u'20092010 Special Session 4',
                                  u'20092010 Special Session 5',
                                  u'20092010 Special Session 6',
                                  u'20092010 Special Session 7',
                                  u'20092010 Special Session 8'],
                    u'start_year': 2009},
                   {u'+start_date': u'2010-12-06 00:00:00',
                    u'end_year': 2012,
                    u'name': u'20112012',
                    u'sessions': [u'20112012 Special Session 1',
                                  u'20112012'],
                    u'start_year': 2011}],
        u'upper_chamber_name': u'Senate',
        u'upper_chamber_term': 4,
        u'upper_chamber_title': u'Senator'},
 'CO': {u'abbreviation': u'co',
        u'feature_flags': [],
        u'id': u'co',
        u'latest_csv_date': u'2012-05-01 09:12:44',
        u'latest_csv_url': u'http://static.openstates.org/downloads/2012-05-01-co-csv.zip',
        u'latest_json_date': u'2012-05-02 00:38:51',
        u'latest_json_url': u'http://static.openstates.org/downloads/2012-05-02-co-json.zip',
        u'latest_update': u'2012-05-27 00:59:51',
        u'legislature_name': u'Colorado General Assembly',
        u'level': u'state',
        u'lower_chamber_name': u'House of Representatives',
        u'lower_chamber_term': 2,
        u'lower_chamber_title': u'Representative',
        u'name': u'Colorado',
        u'session_details': {u'2011A': {u'display_name': u'2011 Regular Session',
                                        u'start_date': u'2011-01-26 00:00:00',
                                        u'type': u'primary'},
                             u'2012A': {u'display_name': u'2012 Regular Session',
                                        u'start_date': u'2012-01-11 00:00:00',
                                        u'type': u'primary'}},
        u'terms': [{u'end_year': 2012,
                    u'name': u'2011-2012',
                    u'sessions': [u'2011A', u'2012A'],
                    u'start_year': 2011}],
        u'upper_chamber_name': u'Senate',
        u'upper_chamber_term': 4,
        u'upper_chamber_title': u'Senator'},
 'CT': {u'abbreviation': u'ct',
        u'feature_flags': [u'subjects'],
        u'id': u'ct',
        u'latest_csv_date': u'2012-05-01 09:08:16',
        u'latest_csv_url': u'http://static.openstates.org/downloads/2012-05-01-ct-csv.zip',
        u'latest_json_date': u'2012-05-01 22:15:53',
        u'latest_json_url': u'http://static.openstates.org/downloads/2012-05-01-ct-json.zip',
        u'latest_update': u'2012-05-27 03:29:32',
        u'legislature_name': u'Connecticut General Assembly',
        u'level': u'state',
        u'lower_chamber_name': u'House of Representatives',
        u'lower_chamber_term': 2,
        u'lower_chamber_title': u'Representative',
        u'name': u'Connecticut',
        u'session_details': {u'2011': {u'display_name': u'2011 Regular Session'},
                             u'2012': {u'display_name': u'2012 Regular Session'}},
        u'terms': [{u'end_year': 2012,
                    u'name': u'2011-2012',
                    u'sessions': [u'2011', u'2012'],
                    u'start_year': 2011}],
        u'upper_chamber_name': u'Senate',
        u'upper_chamber_term': 2,
        u'upper_chamber_title': u'Senator'},
 'DC': {u'abbreviation': u'dc',
        u'feature_flags': [],
        u'id': u'dc',
        u'latest_csv_date': u'2012-05-01 09:00:55',
        u'latest_csv_url': u'http://static.openstates.org/downloads/2012-05-01-dc-csv.zip',
        u'latest_json_date': u'2012-05-01 15:24:02',
        u'latest_json_url': u'http://static.openstates.org/downloads/2012-05-01-dc-json.zip',
        u'latest_update': u'2012-05-27 02:36:59',
        u'legislature_name': u'Council of the District of Columbia',
        u'level': u'state',
        u'name': u'District of Columbia',
        u'session_details': {u'19': {u'display_name': u'19th Council Period'}},
        u'terms': [{u'end_year': 2012,
                    u'name': u'2011-2012',
                    u'sessions': [u'19'],
                    u'start_year': 2011}],
        u'upper_chamber_name': u'Council',
        u'upper_chamber_term': 2,
        u'upper_chamber_title': u'Councilmember'},
 'DE': {u'abbreviation': u'de',
        u'feature_flags': [u'events'],
        u'id': u'de',
        u'latest_csv_date': u'2012-05-01 09:12:45',
        u'latest_csv_url': u'http://static.openstates.org/downloads/2012-05-01-de-csv.zip',
        u'latest_json_date': u'2012-05-02 00:40:10',
        u'latest_json_url': u'http://static.openstates.org/downloads/2012-05-02-de-json.zip',
        u'latest_update': u'2012-05-27 01:48:26',
        u'legislature_name': u'Delaware General Assembly',
        u'level': u'state',
        u'lower_chamber_name': u'House of Representatives',
        u'lower_chamber_term': 2,
        u'lower_chamber_title': u'Representative',
        u'name': u'Delaware',
        u'session_details': {u'146': {u'display_name': u'146th General Assembly'}},
        u'terms': [{u'end_year': 2012,
                    u'name': u'2011-2012',
                    u'sessions': [u'146'],
                    u'start_year': 2011}],
        u'upper_chamber_name': u'Senate',
        u'upper_chamber_term': 4,
        u'upper_chamber_title': u'Senator'},
 'FL': {u'abbreviation': u'fl',
        u'feature_flags': [],
        u'id': u'fl',
        u'latest_csv_date': u'2012-05-01 09:01:55',
        u'latest_csv_url': u'http://static.openstates.org/downloads/2012-05-01-fl-csv.zip',
        u'latest_json_date': u'2012-05-01 16:06:37',
        u'latest_json_url': u'http://static.openstates.org/downloads/2012-05-01-fl-json.zip',
        u'latest_update': u'2012-05-27 01:16:30',
        u'legislature_name': u'Florida Legislature',
        u'level': u'state',
        u'lower_chamber_name': u'House of Representatives',
        u'lower_chamber_term': 2,
        u'lower_chamber_title': u'Representative',
        u'name': u'Florida',
        u'session_details': {u'2011': {u'display_name': u'2011 Regular Session'},
                             u'2012': {u'display_name': u'2012 Regular Session'},
                             u'2012B': {u'display_name': u'2012 Extraordinary Apportionment Session'}},
        u'terms': [{u'end_year': 2012,
                    u'name': u'2011-2012',
                    u'sessions': [u'2011', u'2012', u'2012B'],
                    u'start_year': 2011}],
        u'upper_chamber_name': u'Senate',
        u'upper_chamber_term': 4,
        u'upper_chamber_title': u'Senator'},
 'GA': {u'abbreviation': u'ga',
        u'feature_flags': [],
        u'id': u'ga',
        u'latest_csv_date': u'2012-05-01 09:12:07',
        u'latest_csv_url': u'http://static.openstates.org/downloads/2012-05-01-ga-csv.zip',
        u'latest_json_date': u'2012-05-02 00:15:24',
        u'latest_json_url': u'http://static.openstates.org/downloads/2012-05-02-ga-json.zip',
        u'latest_update': u'2012-05-27 00:07:04',
        u'legislature_name': u'Georgia General Assembly',
        u'level': u'state',
        u'lower_chamber_name': u'House of Representatives',
        u'lower_chamber_term': 2,
        u'lower_chamber_title': u'Representative',
        u'name': u'Georgia',
        u'session_details': {u'2011_12': {u'display_name': u'2011-2012 Regular Session'},
                             u'2011_ss': {u'display_name': u'2011 Special Session'}},
        u'terms': [{u'end_year': 2012,
                    u'name': u'2011-2012',
                    u'sessions': [u'2011_12', u'2011_ss'],
                    u'start_year': 2011}],
        u'upper_chamber_name': u'Senate',
        u'upper_chamber_term': 2,
        u'upper_chamber_title': u'Senator'},
 'HI': {u'abbreviation': u'hi',
        u'feature_flags': [u'subjects'],
        u'id': u'hi',
        u'latest_csv_date': u'2012-05-01 09:08:30',
        u'latest_csv_url': u'http://static.openstates.org/downloads/2012-05-01-hi-csv.zip',
        u'latest_json_date': u'2012-05-01 22:26:53',
        u'latest_json_url': u'http://static.openstates.org/downloads/2012-05-01-hi-json.zip',
        u'latest_update': u'2012-05-27 02:20:59',
        u'legislature_name': u'Hawaii State Legislature',
        u'level': u'state',
        u'lower_chamber_name': u'House of Representatives',
        u'lower_chamber_term': 2,
        u'lower_chamber_title': u'Representative',
        u'name': u'Hawaii',
        u'session_details': {u'2011 Regular Session': {u'display_name': u'2011-2012 Regular Session'}},
        u'terms': [{u'end_year': 2012,
                    u'name': u'2011-2012',
                    u'sessions': [u'2011 Regular Session'],
                    u'start_year': 2011}],
        u'upper_chamber_name': u'Senate',
        u'upper_chamber_term': 4,
        u'upper_chamber_title': u'Senator'},
 'IA': {u'abbreviation': u'ia',
        u'feature_flags': [],
        u'id': u'ia',
        u'latest_csv_date': u'2012-05-01 09:11:57',
        u'latest_csv_url': u'http://static.openstates.org/downloads/2012-05-01-ia-csv.zip',
        u'latest_json_date': u'2012-05-02 00:02:54',
        u'latest_json_url': u'http://static.openstates.org/downloads/2012-05-02-ia-json.zip',
        u'latest_update': u'2012-05-27 01:56:24',
        u'legislature_name': u'Iowa General Assembly',
        u'level': u'state',
        u'lower_chamber_name': u'House of Representatives',
        u'lower_chamber_term': 2,
        u'lower_chamber_title': u'Representative',
        u'name': u'Iowa',
        u'session_details': {u'2011-2012': {u'display_name': u'2011-2012 Regular Session',
                                            u'end_date': u'2013-01-13 00:00:00',
                                            u'number': u'84',
                                            u'start_date': u'2011-01-10 00:00:00'}},
        u'terms': [{u'end_year': 2012,
                    u'name': u'2011-2012',
                    u'sessions': [u'2011-2012'],
                    u'start_year': 2011}],
        u'upper_chamber_name': u'Senate',
        u'upper_chamber_term': 4,
        u'upper_chamber_title': u'Senator'},
 'ID': {u'abbreviation': u'id',
        u'feature_flags': [],
        u'id': u'id',
        u'latest_csv_date': u'2012-05-01 09:09:38',
        u'latest_csv_url': u'http://static.openstates.org/downloads/2012-05-01-id-csv.zip',
        u'latest_json_date': u'2012-05-01 23:10:26',
        u'latest_json_url': u'http://static.openstates.org/downloads/2012-05-01-id-json.zip',
        u'latest_update': u'2012-05-27 00:12:31',
        u'legislature_name': u'Idaho State Legislature',
        u'level': u'state',
        u'lower_chamber_name': u'House of Representatives',
        u'lower_chamber_term': 2,
        u'lower_chamber_title': u'Representative',
        u'name': u'Idaho',
        u'session_details': {u'2011': {u'display_name': u'61st Legislature, 1st Regular Session',
                                       u'end_date': u'2011-04-07 00:00:00',
                                       u'start_date': u'2011-01-10 00:00:00',
                                       u'type': u'primary'},
                             u'2012': {u'display_name': u'61st Legislature, 2nd Regular Session',
                                       u'type': u'primary'}},
        u'terms': [{u'end_year': 2012,
                    u'name': u'2011-2012',
                    u'sessions': [u'2011', u'2012'],
                    u'start_year': 2011}],
        u'upper_chamber_name': u'Senate',
        u'upper_chamber_term': 2,
        u'upper_chamber_title': u'Senator'},
 'IL': {u'abbreviation': u'il',
        u'feature_flags': [u'events'],
        u'id': u'il',
        u'latest_csv_date': u'2012-05-01 09:10:38',
        u'latest_csv_url': u'http://static.openstates.org/downloads/2012-05-01-il-csv.zip',
        u'latest_json_date': u'2012-05-01 23:53:43',
        u'latest_json_url': u'http://static.openstates.org/downloads/2012-05-01-il-json.zip',
        u'latest_update': u'2012-05-27 08:23:15',
        u'legislature_name': u'The Illinois General Assembly',
        u'level': u'state',
        u'lower_chamber_name': u'House of Representatives',
        u'lower_chamber_term': 2,
        u'lower_chamber_title': u'Representative',
        u'name': u'Illinois',
        u'session_details': {u'93rd': {u'display_name': u'93rd Regular Session',
                                       u'params': {u'GA': u'93',
                                                   u'SessionId': u'3'},
                                       u'president': u'Jones, E.',
                                       u'speaker': u'Madigan'},
                             u'94th': {u'display_name': u'94th Regular Session',
                                       u'params': {u'GA': u'94',
                                                   u'SessionId': u'50'},
                                       u'president': u'Jones, E.',
                                       u'speaker': u'Madigan'},
                             u'95th': {u'display_name': u'95th Regular Session',
                                       u'params': {u'GA': u'95',
                                                   u'SessionId': u'51'},
                                       u'president': u'Jones, E.',
                                       u'speaker': u'Madigan'},
                             u'96th': {u'display_name': u'96th Regular Session',
                                       u'params': {u'GA': u'96',
                                                   u'SessionId': u'76'},
                                       u'president': u'Cullerton',
                                       u'speaker': u'Madigan'},
                             u'97th': {u'display_name': u'97th Regular Session',
                                       u'params': {u'GA': u'97',
                                                   u'SessionId': u'84'},
                                       u'president': u'Cullerton',
                                       u'speaker': u'Madigan'},
                             u'Special_93rd': {u'display_name': u'93rd Special Session',
                                               u'params': {u'GA': u'93',
                                                           u'SessionID': u'14',
                                                           u'SpecSess': u'1'},
                                               u'president': u'Jones, E.',
                                               u'speaker': u'Madigan'},
                             u'Special_95th': {u'display_name': u'95th Special Session',
                                               u'params': {u'GA': u'95',
                                                           u'SessionId': u'52',
                                                           u'SpecSess': u'1'},
                                               u'president': u'Jones, E.',
                                               u'speaker': u'Madigan'},
                             u'Special_96th': {u'display_name': u'96th Special Session',
                                               u'params': {u'GA': u'96',
                                                           u'SessionId': u'82',
                                                           u'SpecSess': u'1'},
                                               u'president': u'Cullerton',
                                               u'speaker': u'Madigan'}},
        u'terms': [{u'end_year': 2004,
                    u'name': u'93rd',
                    u'sessions': [u'93rd', u'Special_93rd'],
                    u'start_year': 2003},
                   {u'end_year': 2006,
                    u'name': u'94th',
                    u'sessions': [u'94th'],
                    u'start_year': 2005},
                   {u'end_year': 2008,
                    u'name': u'95th',
                    u'sessions': [u'95th', u'Special_95th'],
                    u'start_year': 2007},
                   {u'end_year': 2010,
                    u'name': u'96th',
                    u'sessions': [u'96th', u'Special_96th'],
                    u'start_year': 2009},
                   {u'end_year': 2012,
                    u'name': u'97th',
                    u'sessions': [u'97th'],
                    u'start_year': 2011}],
        u'upper_chamber_name': u'Senate',
        u'upper_chamber_term': 4,
        u'upper_chamber_title': u'Senator'},
 'IN': {u'abbreviation': u'in',
        u'feature_flags': [u'subjects'],
        u'id': u'in',
        u'latest_csv_date': u'2012-05-01 09:08:08',
        u'latest_csv_url': u'http://static.openstates.org/downloads/2012-05-01-in-csv.zip',
        u'latest_json_date': u'2012-05-01 22:08:16',
        u'latest_json_url': u'http://static.openstates.org/downloads/2012-05-01-in-json.zip',
        u'latest_update': u'2012-05-27 01:16:30',
        u'legislature_name': u'Indiana General Assembly',
        u'level': u'state',
        u'lower_chamber_name': u'House of Representatives',
        u'lower_chamber_term': 2,
        u'lower_chamber_title': u'Representative',
        u'name': u'Indiana',
        u'session_details': {u'2011': {u'display_name': u'2011 Regular Session',
                                       u'start_date': u'2011-01-05 00:00:00'},
                             u'2012': {u'display_name': u'2012 Regular Session'}},
        u'terms': [{u'end_year': 2012,
                    u'name': u'2011-2012',
                    u'sessions': [u'2011', u'2012'],
                    u'start_year': 2011}],
        u'upper_chamber_name': u'Senate',
        u'upper_chamber_term': 4,
        u'upper_chamber_title': u'Senator'},
 'KS': {u'abbreviation': u'ks',
        u'feature_flags': [],
        u'id': u'ks',
        u'latest_csv_date': u'2012-05-01 09:12:29',
        u'latest_csv_url': u'http://static.openstates.org/downloads/2012-05-01-ks-csv.zip',
        u'latest_json_date': u'2012-05-02 00:28:36',
        u'latest_json_url': u'http://static.openstates.org/downloads/2012-05-02-ks-json.zip',
        u'latest_update': u'2012-05-04 02:26:02',
        u'legislature_name': u'Kansas State Legislature',
        u'level': u'state',
        u'lower_chamber_name': u'House of Representatives',
        u'lower_chamber_term': 2,
        u'lower_chamber_title': u'Representative',
        u'name': u'Kansas',
        u'session_details': {u'2011-2012': {u'display_name': u'2011-2012 Regular Session',
                                            u'start_date': u'2011-01-12 00:00:00',
                                            u'type': u'primary'}},
        u'terms': [{u'end_year': 2012,
                    u'name': u'2011-2012',
                    u'sessions': [u'2011-2012'],
                    u'start_year': 2011}],
        u'upper_chamber_name': u'Senate',
        u'upper_chamber_term': 4,
        u'upper_chamber_title': u'Senator'},
 'KY': {u'abbreviation': u'ky',
        u'feature_flags': [u'subjects', u'events'],
        u'id': u'ky',
        u'latest_csv_date': u'2012-05-01 09:00:59',
        u'latest_csv_url': u'http://static.openstates.org/downloads/2012-05-01-ky-csv.zip',
        u'latest_json_date': u'2012-05-01 15:28:33',
        u'latest_json_url': u'http://static.openstates.org/downloads/2012-05-01-ky-json.zip',
        u'latest_update': u'2012-05-27 00:06:13',
        u'legislature_name': u'Kentucky General Assembly',
        u'level': u'state',
        u'lower_chamber_name': u'House of Representatives',
        u'lower_chamber_term': 2,
        u'lower_chamber_title': u'Representative',
        u'name': u'Kentucky',
        u'session_details': {u'2011 Regular Session': {u'display_name': u'2011 Regular Session',
                                                       u'type': u'primary'},
                             u'2011SS': {u'display_name': u'2011 Extraordinary Session',
                                         u'type': u'special'},
                             u'2012RS': {u'display_name': u'2012 Regular Session',
                                         u'type': u'primary'},
                             u'2012SS': {u'display_name': u'2012 Extraordinary Session',
                                         u'type': u'special'}},
        u'terms': [{u'end_year': 2011,
                    u'name': u'2011-2012',
                    u'sessions': [u'2011 Regular Session',
                                  u'2011SS',
                                  u'2012RS',
                                  u'2012SS'],
                    u'start_year': 2011}],
        u'upper_chamber_name': u'Senate',
        u'upper_chamber_term': 4,
        u'upper_chamber_title': u'Senator'},
 'LA': {u'abbreviation': u'la',
        u'feature_flags': [u'subjects', u'events'],
        u'id': u'la',
        u'latest_csv_date': u'2012-05-01 09:11:51',
        u'latest_csv_url': u'http://static.openstates.org/downloads/2012-05-01-la-csv.zip',
        u'latest_json_date': u'2012-05-02 15:03:34',
        u'latest_json_url': u'http://static.openstates.org/downloads/2012-05-02-la-json.zip',
        u'latest_update': u'2012-05-25 03:33:56',
        u'legislature_name': u'Louisiana Legislature',
        u'level': u'state',
        u'lower_chamber_name': u'House of Representatives',
        u'lower_chamber_term': 4,
        u'lower_chamber_title': u'Representative',
        u'name': u'Louisiana',
        u'session_details': {u'2009': {u'display_name': u'2009 Regular Session',
                                       u'end_date': u'2010-06-24 00:00:00',
                                       u'start_date': u'2010-04-27 00:00:00',
                                       u'type': u'primary'},
                             u'2010': {u'display_name': u'2010 Regular Session',
                                       u'end_date': u'2010-06-21 00:00:00',
                                       u'start_date': u'2010-03-29 00:00:00',
                                       u'type': u'primary'},
                             u'2011': {u'display_name': u'2011 Regular Session',
                                       u'type': u'primary'},
                             u'2011 1st Extraordinary Session': {u'display_name': u'2011, 1st Extraordinary Session',
                                                                 u'id': u'111es',
                                                                 u'type': u'special'},
                             u'2012': {u'display_name': u'2012 Regular Session',
                                       u'type': u'primary'}},
        u'terms': [{u'end_year': 2011,
                    u'name': u'2008-2011',
                    u'sessions': [u'2009',
                                  u'2010',
                                  u'2011 1st Extraordinary Session',
                                  u'2011'],
                    u'start_year': 2008},
                   {u'end_year': 2015,
                    u'name': u'2012-2015',
                    u'sessions': [u'2012'],
                    u'start_year': 2012}],
        u'upper_chamber_name': u'Senate',
        u'upper_chamber_term': 4,
        u'upper_chamber_title': u'Senator'},
 'MA': {u'abbreviation': u'ma',
        u'feature_flags': [u'events'],
        u'id': u'ma',
        u'latest_csv_date': u'2012-05-01 09:08:49',
        u'latest_csv_url': u'http://static.openstates.org/downloads/2012-05-01-ma-csv.zip',
        u'latest_json_date': u'2012-05-01 22:45:50',
        u'latest_json_url': u'http://static.openstates.org/downloads/2012-05-01-ma-json.zip',
        u'latest_update': u'2012-05-27 03:52:28',
        u'legislature_name': u'Massachusetts General Court',
        u'level': u'state',
        u'lower_chamber_name': u'House of Representatives',
        u'lower_chamber_term': 2,
        u'lower_chamber_title': u'Representative',
        u'name': u'Massachusetts',
        u'session_details': {u'186th': {u'display_name': u'186th Legislature',
                                        u'type': u'primary'},
                             u'187th': {u'display_name': u'187th Legislature',
                                        u'type': u'primary'}},
        u'terms': [{u'end_year': 2010,
                    u'name': u'186',
                    u'sessions': [u'186th'],
                    u'start_year': 2009},
                   {u'end_year': 2012,
                    u'name': u'187',
                    u'sessions': [u'187th'],
                    u'start_year': 2011}],
        u'upper_chamber_name': u'Senate',
        u'upper_chamber_term': 2,
        u'upper_chamber_title': u'Senator'},
 'MD': {u'abbreviation': u'md',
        u'feature_flags': [u'subjects', u'events'],
        u'id': u'md',
        u'latest_csv_date': u'2012-05-01 09:02:55',
        u'latest_csv_url': u'http://static.openstates.org/downloads/2012-05-01-md-csv.zip',
        u'latest_json_date': u'2012-05-01 16:33:34',
        u'latest_json_url': u'http://static.openstates.org/downloads/2012-05-01-md-json.zip',
        u'latest_update': u'2012-05-27 01:28:25',
        u'legislature_name': u'Maryland General Assembly',
        u'level': u'state',
        u'lower_chamber_name': u'House of Delegates',
        u'lower_chamber_term': 4,
        u'lower_chamber_title': u'Delegate',
        u'name': u'Maryland',
        u'session_details': {u'2007': {u'display_name': u'2007 Regular Session',
                                       u'end_date': u'2007-04-10 00:00:00',
                                       u'number': 423,
                                       u'start_date': u'2007-01-10 00:00:00',
                                       u'type': u'primary'},
                             u'2007s1': {u'display_name': u'2007, 1st Special Session',
                                         u'end_date': u'2007-11-19 00:00:00',
                                         u'number': 424,
                                         u'start_date': u'2007-10-29 00:00:00',
                                         u'type': u'special'},
                             u'2008': {u'display_name': u'2008 Regular Session',
                                       u'end_date': u'2008-04-07 00:00:00',
                                       u'number': 425,
                                       u'start_date': u'2008-01-09 00:00:00',
                                       u'type': u'primary'},
                             u'2009': {u'display_name': u'2009 Regular Session',
                                       u'end_date': u'2009-04-13 00:00:00',
                                       u'number': 426,
                                       u'start_date': u'2009-01-14 00:00:00',
                                       u'type': u'primary'},
                             u'2010': {u'display_name': u'2010 Regular Session',
                                       u'end_date': u'2010-04-12 00:00:00',
                                       u'number': 427,
                                       u'start_date': u'2010-01-13 00:00:00',
                                       u'type': u'primary'},
                             u'2011': {u'display_name': u'2011 Regular Session',
                                       u'end_date': u'2011-04-12 00:00:00',
                                       u'number': 428,
                                       u'start_date': u'2011-01-12 00:00:00',
                                       u'type': u'primary'},
                             u'2011s1': {u'display_name': u'2011, 1st Special Session',
                                         u'number': 429,
                                         u'type': u'special'},
                             u'2012': {u'display_name': u'2012 Regular Session',
                                       u'end_date': u'2012-04-09 00:00:00',
                                       u'number': 430,
                                       u'start_date': u'2012-01-11 00:00:00',
                                       u'type': u'primary'}},
        u'terms': [{u'end_year': 2010,
                    u'name': u'2007-2010',
                    u'sessions': [u'2007',
                                  u'2007s1',
                                  u'2008',
                                  u'2009',
                                  u'2010'],
                    u'start_year': 2007},
                   {u'end_year': 2014,
                    u'name': u'2011-2014',
                    u'sessions': [u'2011', u'2011s1', u'2012'],
                    u'start_year': 2011}],
        u'upper_chamber_name': u'Senate',
        u'upper_chamber_term': 4,
        u'upper_chamber_title': u'Senator'},
 'ME': {u'abbreviation': u'me',
        u'feature_flags': [u'subjects'],
        u'id': u'me',
        u'latest_csv_date': u'2012-05-01 09:01:03',
        u'latest_csv_url': u'http://static.openstates.org/downloads/2012-05-01-me-csv.zip',
        u'latest_json_date': u'2012-05-01 15:32:19',
        u'latest_json_url': u'http://static.openstates.org/downloads/2012-05-01-me-json.zip',
        u'latest_update': u'2012-05-27 03:04:27',
        u'legislature_name': u'Maine Legislature',
        u'level': u'state',
        u'lower_chamber_name': u'House of Representatives',
        u'lower_chamber_term': 2,
        u'lower_chamber_title': u'Representative',
        u'name': u'Maine',
        u'session_details': {u'124': {u'display_name': u'124th Legislature'},
                             u'125': {u'display_name': u'125th Legislature'}},
        u'terms': [{u'end_year': 2010,
                    u'name': u'2009-2010',
                    u'sessions': [u'124'],
                    u'start_year': 2009},
                   {u'end_year': 2012,
                    u'name': u'2011-2012',
                    u'sessions': [u'125'],
                    u'start_year': 2011}],
        u'upper_chamber_name': u'Senate',
        u'upper_chamber_term': 2,
        u'upper_chamber_title': u'Senator'},
 'MI': {u'abbreviation': u'mi',
        u'feature_flags': [u'subjects', u'events'],
        u'id': u'mi',
        u'latest_csv_date': u'2012-05-01 09:08:00',
        u'latest_csv_url': u'http://static.openstates.org/downloads/2012-05-01-mi-csv.zip',
        u'latest_json_date': u'2012-05-01 22:03:22',
        u'latest_json_url': u'http://static.openstates.org/downloads/2012-05-01-mi-json.zip',
        u'latest_update': u'2012-05-27 01:47:15',
        u'legislature_name': u'Michigan Legislature',
        u'level': u'state',
        u'lower_chamber_name': u'House of Representatives',
        u'lower_chamber_term': 2,
        u'lower_chamber_title': u'Representative',
        u'name': u'Michigan',
        u'session_details': {u'2011-2012': {u'display_name': u'2011-2012 Regular Session',
                                            u'type': u'primary'}},
        u'terms': [{u'end_year': 2012,
                    u'name': u'2011-2012',
                    u'sessions': [u'2011-2012'],
                    u'start_year': 2011}],
        u'upper_chamber_name': u'Senate',
        u'upper_chamber_term': 4,
        u'upper_chamber_title': u'Senator'},
 'MN': {u'abbreviation': u'mn',
        u'feature_flags': [u'subjects', u'events'],
        u'id': u'mn',
        u'latest_csv_date': u'2012-05-01 09:03:14',
        u'latest_csv_url': u'http://static.openstates.org/downloads/2012-05-01-mn-csv.zip',
        u'latest_json_date': u'2012-05-01 16:56:55',
        u'latest_json_url': u'http://static.openstates.org/downloads/2012-05-01-mn-json.zip',
        u'latest_update': u'2012-05-27 04:08:01',
        u'legislature_name': u'Minnesota State Legislature',
        u'level': u'state',
        u'lower_chamber_name': u'House of Representatives',
        u'lower_chamber_term': 2,
        u'lower_chamber_title': u'Representative',
        u'name': u'Minnesota',
        u'session_details': {u'2009-2010': {u'display_name': u'2009-2010 Regular Session',
                                            u'site_id': u'0862009',
                                            u'type': u'primary',
                                            u'votes_url': u'http://www.house.leg.state.mn.us/votes/getVotesls86.asp'},
                             u'2010 1st Special Session': {u'display_name': u'2010, 1st Special Session',
                                                           u'site_id': u'1862010',
                                                           u'type': u'special',
                                                           u'votes_url': u'http://www.house.leg.state.mn.us/votes/getVotesls8620101.asp'},
                             u'2010 2nd Special Session': {u'display_name': u'2010, 2nd Special Session',
                                                           u'site_id': u'2862010',
                                                           u'type': u'special'},
                             u'2011-2012': {u'display_name': u'2011-2012 Regular Session',
                                            u'site_id': u'0872011',
                                            u'type': u'primary',
                                            u'votes_url': u'http://www.house.leg.state.mn.us/votes/getVotesls87.asp'},
                             u'2011s1': {u'display_name': u'2011, 1st Special Session',
                                         u'site_id': u'1872011',
                                         u'type': u'special',
                                         u'votes_url': u'http://www.house.leg.state.mn.us/votes/getVotesls8720111.asp'}},
        u'terms': [{u'+biennium': u'86',
                    u'end_year': 2010,
                    u'name': u'2009-2010',
                    u'sessions': [u'2009-2010',
                                  u'2010 1st Special Session',
                                  u'2010 2nd Special Session'],
                    u'start_year': 2009},
                   {u'+biennium': u'87',
                    u'end_year': 2012,
                    u'name': u'2011-2012',
                    u'sessions': [u'2011-2012', u'2011s1'],
                    u'start_year': 2011}],
        u'upper_chamber_name': u'Senate',
        u'upper_chamber_term': u'http://en.wikipedia.org/wiki/Minnesota_Senate',
        u'upper_chamber_title': u'Senator'},
 'MO': {u'abbreviation': u'mo',
        u'feature_flags': [u'subjects'],
        u'id': u'mo',
        u'latest_csv_date': u'2012-05-01 09:09:01',
        u'latest_csv_url': u'http://static.openstates.org/downloads/2012-05-01-mo-csv.zip',
        u'latest_json_date': u'2012-05-02 01:01:53',
        u'latest_json_url': u'http://static.openstates.org/downloads/2012-05-02-mo-json.zip',
        u'latest_update': u'2012-05-27 02:03:56',
        u'legislature_name': u'Missouri General Assembly',
        u'level': u'state',
        u'lower_chamber_name': u'House of Representatives',
        u'lower_chamber_term': 2,
        u'lower_chamber_title': u'Representative',
        u'name': u'Missouri',
        u'session_details': {u'2011': {u'display_name': u'2011 Regular Session',
                                       u'start_date': u'2011-01-26 00:00:00',
                                       u'type': u'primary'},
                             u'2012': {u'display_name': u'2012 Regular Session',
                                       u'start_date': u'2012-01-26 00:00:00',
                                       u'type': u'primary'}},
        u'terms': [{u'end_year': 2012,
                    u'name': u'2011-2012',
                    u'sessions': [u'2011', u'2012'],
                    u'start_year': 2011}],
        u'upper_chamber_name': u'Senate',
        u'upper_chamber_term': 4,
        u'upper_chamber_title': u'Senator'},
 'MS': {u'abbreviation': u'ms',
        u'feature_flags': [u'subjects'],
        u'id': u'ms',
        u'latest_csv_date': u'2012-05-01 09:04:00',
        u'latest_csv_url': u'http://static.openstates.org/downloads/2012-05-01-ms-csv.zip',
        u'latest_json_date': u'2012-05-01 17:27:11',
        u'latest_json_url': u'http://static.openstates.org/downloads/2012-05-01-ms-json.zip',
        u'latest_update': u'2012-05-27 00:04:54',
        u'legislature_name': u'Mississippi Legislature',
        u'level': u'state',
        u'lower_chamber_name': u'House of Representatives',
        u'lower_chamber_term': 4,
        u'lower_chamber_title': u'Representative',
        u'name': u'Mississippi',
        u'session_details': {u'2008': {u'display_name': u'2008 Regular Session'},
                             u'2009': {u'display_name': u'2009 Regular Session'},
                             u'20091E': {u'display_name': u'2009, 1st Extraordinary Session'},
                             u'20092E': {u'display_name': u'2009, 2nd Extraordinary Session'},
                             u'20093E': {u'display_name': u'2009, 3rd Extraordinary Session'},
                             u'2010': {u'display_name': u'2010 Regular Session'},
                             u'20101E': {u'display_name': u'2010, 1st Extraordinary Session'},
                             u'20102E': {u'display_name': u'2010, 2nd Extraordinary Session'},
                             u'2011': {u'display_name': u'2011 Regular Session'},
                             u'20111E': {u'display_name': u'2011, 1st Extraordinary Session'},
                             u'2012': {u'display_name': u'2012 Regular Session'}},
        u'terms': [{u'end_year': 2011,
                    u'name': u'2008-2011',
                    u'sessions': [u'2008',
                                  u'2009',
                                  u'20091E',
                                  u'20092E',
                                  u'20093E',
                                  u'20101E',
                                  u'20102E',
                                  u'2010',
                                  u'2011',
                                  u'20111E'],
                    u'start_year': 2008},
                   {u'end_year': 2015,
                    u'name': u'2012-2015',
                    u'sessions': [u'2012'],
                    u'start_year': 2012}],
        u'upper_chamber_name': u'Senate',
        u'upper_chamber_term': 4,
        u'upper_chamber_title': u'Senator'},
 'MT': {u'abbreviation': u'mt',
        u'feature_flags': [],
        u'id': u'mt',
        u'latest_csv_date': u'2012-05-01 09:09:16',
        u'latest_csv_url': u'http://static.openstates.org/downloads/2012-05-01-mt-csv.zip',
        u'latest_json_date': u'2012-05-02 00:58:21',
        u'latest_json_url': u'http://static.openstates.org/downloads/2012-05-02-mt-json.zip',
        u'latest_update': u'2012-05-27 02:09:46',
        u'legislature_name': u'Montana Legislature',
        u'level': u'state',
        u'lower_chamber_name': u'House of Representatives',
        u'lower_chamber_term': 2,
        u'lower_chamber_title': u'Representative',
        u'name': u'Montana',
        u'session_details': {u'2011': {u'display_name': u'2011 Regular Session',
                                       u'years': [2011, 2012]}},
        u'terms': [{u'+session_number': u'62nd',
                    u'end_year': 2012,
                    u'name': u'2011-2012',
                    u'sessions': [u'2011'],
                    u'start_year': 2011}],
        u'upper_chamber_name': u'Senate',
        u'upper_chamber_term': 4,
        u'upper_chamber_title': u'Senator'},
 'NC': {u'abbreviation': u'nc',
        u'feature_flags': [u'subjects'],
        u'id': u'nc',
        u'latest_csv_date': u'2012-05-01 09:04:21',
        u'latest_csv_url': u'http://static.openstates.org/downloads/2012-05-01-nc-csv.zip',
        u'latest_json_date': u'2012-05-01 17:36:42',
        u'latest_json_url': u'http://static.openstates.org/downloads/2012-05-01-nc-json.zip',
        u'latest_update': u'2012-05-27 00:54:27',
        u'legislature_name': u'North Carolina General Assembly',
        u'level': u'state',
        u'lower_chamber_name': u'House of Representatives',
        u'lower_chamber_term': 2,
        u'lower_chamber_title': u'Representative',
        u'name': u'North Carolina',
        u'session_details': {u'2009': {u'display_name': u'2009 Regular Session',
                                       u'start_date': u'2009-01-28 00:00:00',
                                       u'type': u'primary'},
                             u'2011': {u'display_name': u'2011 Regular Session',
                                       u'start_date': u'2011-01-26 00:00:00',
                                       u'type': u'primary'}},
        u'terms': [{u'end_year': 2010,
                    u'name': u'2009-2010',
                    u'sessions': [u'2009'],
                    u'start_year': 2009},
                   {u'end_year': 2012,
                    u'name': u'2011-2012',
                    u'sessions': [u'2011'],
                    u'start_year': 2011}],
        u'upper_chamber_name': u'Senate',
        u'upper_chamber_term': 2,
        u'upper_chamber_title': u'Senator'},
 'ND': {u'abbreviation': u'nd',
        u'feature_flags': [],
        u'id': u'nd',
        u'latest_csv_date': u'2012-05-01 09:12:27',
        u'latest_csv_url': u'http://static.openstates.org/downloads/2012-05-01-nd-csv.zip',
        u'latest_json_date': u'2012-05-02 00:25:42',
        u'latest_json_url': u'http://static.openstates.org/downloads/2012-05-02-nd-json.zip',
        u'latest_update': u'2012-05-27 00:52:49',
        u'legislature_name': u'North Dakota Legislative Assembly',
        u'level': u'state',
        u'lower_chamber_name': u'House of Representatives',
        u'lower_chamber_term': 4,
        u'lower_chamber_title': u'Representative',
        u'name': u'North Dakota',
        u'session_details': {u'62': {u'display_name': u'62nd Legislative Assembly',
                                     u'start_date': u'2011-01-04 00:00:00'}},
        u'terms': [{u'end_year': 2012,
                    u'name': u'62',
                    u'sessions': [u'62'],
                    u'start_year': 2011}],
        u'upper_chamber_name': u'Senate',
        u'upper_chamber_term': 4,
        u'upper_chamber_title': u'Senator'},
 'NE': {u'abbreviation': u'ne',
        u'feature_flags': [],
        u'id': u'ne',
        u'latest_csv_date': u'2012-05-01 09:01:05',
        u'latest_csv_url': u'http://static.openstates.org/downloads/2012-05-01-ne-csv.zip',
        u'latest_json_date': u'2012-05-02 00:04:56',
        u'latest_json_url': u'http://static.openstates.org/downloads/2012-05-02-ne-json.zip',
        u'latest_update': u'2012-05-27 00:41:12',
        u'legislature_name': u'Nebraska Legislature',
        u'level': u'state',
        u'name': u'Nebraska',
        u'session_details': {u'102': {u'display_name': u'102nd Legislature',
                                      u'start_date': u'2011-01-05 00:00:00'},
                             u'102S1': {u'display_name': u'102nd Legislature, 1st Special Session',
                                        u'end_date': u'2011-11-22 00:00:00',
                                        u'start_date': u'2011-11-01 00:00:00'}},
        u'terms': [{u'end_year': 2012,
                    u'name': u'2011-2012',
                    u'sessions': [u'102', u'102S1'],
                    u'start_year': 2011}],
        u'upper_chamber_name': u'The Unicameral',
        u'upper_chamber_term': 2,
        u'upper_chamber_title': u'Senator'},
 'NH': {u'abbreviation': u'nh',
        u'feature_flags': [],
        u'id': u'nh',
        u'latest_csv_date': u'2012-05-01 09:01:13',
        u'latest_csv_url': u'http://static.openstates.org/downloads/2012-05-01-nh-csv.zip',
        u'latest_json_date': u'2012-05-01 15:36:30',
        u'latest_json_url': u'http://static.openstates.org/downloads/2012-05-01-nh-json.zip',
        u'latest_update': u'2012-05-27 00:10:16',
        u'legislature_name': u'New Hampshire General Court',
        u'level': u'state',
        u'lower_chamber_name': u'House of Representatives',
        u'lower_chamber_term': 2,
        u'lower_chamber_title': u'Representative',
        u'name': u'New Hampshire',
        u'session_details': {u'2011': {u'display_name': u'2011 Regular Session',
                                       u'zip_url': u'http://gencourt.state.nh.us/downloads/2011%20Session%20Bill%20Status%20Tables.zip'},
                             u'2012': {u'display_name': u'2012 Regular Session',
                                       u'zip_url': u'http://gencourt.state.nh.us/downloads/2012%20Session%20Bill%20Status%20Tables.zip'}},
        u'terms': [{u'end_year': 2012,
                    u'name': u'2011-2012',
                    u'sessions': [u'2011', u'2012'],
                    u'start_year': 2011}],
        u'upper_chamber_name': u'Senate',
        u'upper_chamber_term': 2,
        u'upper_chamber_title': u'Senator'},
 'NJ': {u'abbreviation': u'nj',
        u'feature_flags': [u'subjects', u'events'],
        u'id': u'nj',
        u'latest_csv_date': u'2012-05-01 09:04:44',
        u'latest_csv_url': u'http://static.openstates.org/downloads/2012-05-01-nj-csv.zip',
        u'latest_json_date': u'2012-05-01 18:12:52',
        u'latest_json_url': u'http://static.openstates.org/downloads/2012-05-01-nj-json.zip',
        u'latest_update': u'2012-05-27 00:13:55',
        u'legislature_name': u'New Jersey Legislature',
        u'level': u'state',
        u'lower_chamber_name': u'General Assembly',
        u'lower_chamber_term': 2,
        u'lower_chamber_title': u'Representative',
        u'name': u'New Jersey',
        u'session_details': {u'213': {u'display_name': u'2008-2009 Regular Session',
                                      u'start_date': u'2008-01-12 00:00:00'},
                             u'214': {u'display_name': u'2010-2011 Regular Session',
                                      u'start_date': u'2010-01-12 00:00:00'},
                             u'215': {u'display_name': u'2012-2013 Regular Session',
                                      u'start_date': u'2012-01-10 00:00:00'}},
        u'terms': [{u'end_year': 2009,
                    u'name': u'2008-2009',
                    u'sessions': [u'213'],
                    u'start_year': 2008},
                   {u'end_year': 2011,
                    u'name': u'2010-2011',
                    u'sessions': [u'214'],
                    u'start_year': 2010},
                   {u'end_year': 2013,
                    u'name': u'2012-2013',
                    u'sessions': [u'215'],
                    u'start_year': 2012}],
        u'upper_chamber_name': u'Senate',
        u'upper_chamber_term': u'http://en.wikipedia.org/wiki/New_Jersey_Legislature#Elections_and_terms',
        u'upper_chamber_title': u'Senator'},
 'NM': {u'abbreviation': u'nm',
        u'feature_flags': [u'subjects'],
        u'id': u'nm',
        u'latest_csv_date': u'2012-05-01 09:11:55',
        u'latest_csv_url': u'http://static.openstates.org/downloads/2012-05-01-nm-csv.zip',
        u'latest_json_date': u'2012-05-01 23:58:38',
        u'latest_json_url': u'http://static.openstates.org/downloads/2012-05-01-nm-json.zip',
        u'latest_update': u'2012-05-27 00:12:48',
        u'legislature_name': u'New Mexico Legislature',
        u'level': u'state',
        u'lower_chamber_name': u'House of Representatives',
        u'lower_chamber_term': 2,
        u'lower_chamber_title': u'Representative',
        u'name': u'New Mexico',
        u'session_details': {u'2011': {u'display_name': u'2011 Regular Session',
                                       u'slug': u'11%20Regular'},
                             u'2011S': {u'display_name': u'2011 Special Session',
                                        u'slug': u'11%20Special'},
                             u'2012': {u'display_name': u'2012 Regular Session',
                                       u'slug': u'12%20Regular'}},
        u'terms': [{u'end_year': 2012,
                    u'name': u'2011-2012',
                    u'sessions': [u'2011', u'2011S', u'2012'],
                    u'start_year': 2011}],
        u'upper_chamber_name': u'Senate',
        u'upper_chamber_term': 4,
        u'upper_chamber_title': u'Senator'},
 'NV': {u'abbreviation': u'nv',
        u'feature_flags': [u'subjects'],
        u'id': u'nv',
        u'latest_csv_date': u'2012-05-01 09:04:50',
        u'latest_csv_url': u'http://static.openstates.org/downloads/2012-05-01-nv-csv.zip',
        u'latest_json_date': u'2012-05-01 18:16:55',
        u'latest_json_url': u'http://static.openstates.org/downloads/2012-05-01-nv-json.zip',
        u'latest_update': u'2012-05-27 00:47:40',
        u'legislature_name': u'Nevada Legislature',
        u'level': u'state',
        u'lower_chamber_name': u'Assembly',
        u'lower_chamber_term': 2,
        u'lower_chamber_title': u'Representative',
        u'name': u'Nevada',
        u'session_details': {u'2010Special26': {u'display_name': u'26th Special Session (2010)',
                                                u'slug': u'26th2010Special',
                                                u'type': u'special'},
                             u'75': {u'display_name': u'2009 Regular Session',
                                     u'slug': u'75th2009',
                                     u'type': u'primary'},
                             u'76': {u'display_name': u'2011 Regular Session',
                                     u'slug': u'76th2011',
                                     u'type': u'primary'}},
        u'terms': [{u'end_year': 2010,
                    u'name': u'2009-2010',
                    u'sessions': [u'2010Special26', u'75'],
                    u'start_year': 2009},
                   {u'end_year': 2012,
                    u'name': u'2011-2012',
                    u'sessions': [u'76'],
                    u'start_year': 2011}],
        u'upper_chamber_name': u'Senate',
        u'upper_chamber_term': 4,
        u'upper_chamber_title': u'Senator'},
 'NY': {u'abbreviation': u'ny',
        u'feature_flags': [u'subjects'],
        u'id': u'ny',
        u'latest_csv_date': u'2012-05-01 09:05:09',
        u'latest_csv_url': u'http://static.openstates.org/downloads/2012-05-01-ny-csv.zip',
        u'latest_json_date': u'2012-05-01 18:59:22',
        u'latest_json_url': u'http://static.openstates.org/downloads/2012-05-01-ny-json.zip',
        u'latest_update': u'2012-05-27 01:06:15',
        u'legislature_name': u'New York Legislature',
        u'level': u'state',
        u'lower_chamber_name': u'Assembly',
        u'lower_chamber_term': 2,
        u'lower_chamber_title': u'Assembly Member',
        u'name': u'New York',
        u'session_details': {u'2011-2012': {u'display_name': u'2011 Regular Session'}},
        u'terms': [{u'end_year': 2012,
                    u'name': u'2011-2012',
                    u'sessions': [u'2011-2012'],
                    u'start_year': 2011}],
        u'upper_chamber_name': u'Senate',
        u'upper_chamber_term': 2,
        u'upper_chamber_title': u'Senator'},
 'OH': {u'abbreviation': u'oh',
        u'feature_flags': [u'events'],
        u'id': u'oh',
        u'latest_csv_date': u'2012-05-01 09:05:11',
        u'latest_csv_url': u'http://static.openstates.org/downloads/2012-05-01-oh-csv.zip',
        u'latest_json_date': u'2012-05-01 19:01:17',
        u'latest_json_url': u'http://static.openstates.org/downloads/2012-05-01-oh-json.zip',
        u'latest_update': u'2012-05-27 01:11:32',
        u'legislature_name': u'Ohio Legislature',
        u'level': u'state',
        u'lower_chamber_name': u'House of Representatives',
        u'lower_chamber_term': 2,
        u'lower_chamber_title': u'Representative',
        u'name': u'Ohio',
        u'session_details': {u'128': {u'display_name': u'128th Legislature'},
                             u'129': {u'display_name': u'129th Legislature',
                                      u'start_date': u'2011-01-03 00:00:00'}},
        u'terms': [{u'end_year': 2010,
                    u'name': u'2009-2010',
                    u'sessions': [u'128'],
                    u'start_year': 2009},
                   {u'end_year': 2012,
                    u'name': u'2011-2012',
                    u'sessions': [u'129'],
                    u'start_year': 2011}],
        u'upper_chamber_name': u'Senate',
        u'upper_chamber_term': 4,
        u'upper_chamber_title': u'Senator'},
 'OK': {u'abbreviation': u'ok',
        u'feature_flags': [u'subjects'],
        u'id': u'ok',
        u'latest_csv_date': u'2012-05-01 09:08:43',
        u'latest_csv_url': u'http://static.openstates.org/downloads/2012-05-01-ok-csv.zip',
        u'latest_json_date': u'2012-05-01 22:34:52',
        u'latest_json_url': u'http://static.openstates.org/downloads/2012-05-01-ok-json.zip',
        u'latest_update': u'2012-05-27 00:46:26',
        u'legislature_name': u'Oklahoma Legislature',
        u'level': u'state',
        u'lower_chamber_name': u'House of Representatives',
        u'lower_chamber_term': 2,
        u'lower_chamber_title': u'Representative',
        u'name': u'Oklahoma',
        u'session_details': {u'2011-2012': {u'display_name': u'2011-2012 Regular Session',
                                            u'session_id': u'1200'},
                             u'2012SS1': {u'display_name': u'2012 Special Session',
                                          u'session_id': u'121X'}},
        u'terms': [{u'end_year': 2012,
                    u'name': u'2011-2012',
                    u'sessions': [u'2011-2012', u'2012SS1'],
                    u'start_year': 2011}],
        u'upper_chamber_name': u'Senate',
        u'upper_chamber_term': 4,
        u'upper_chamber_title': u'Senator'},
 'OR': {u'abbreviation': u'or',
        u'feature_flags': [],
        u'id': u'or',
        u'latest_csv_date': u'2012-05-01 09:01:19',
        u'latest_csv_url': u'http://static.openstates.org/downloads/2012-05-01-or-csv.zip',
        u'latest_json_date': u'2012-05-01 15:42:18',
        u'latest_json_url': u'http://static.openstates.org/downloads/2012-05-01-or-json.zip',
        u'latest_update': u'2012-05-27 00:47:59',
        u'legislature_name': u'Oregon Legislative Assembly',
        u'level': u'state',
        u'lower_chamber_name': u'House of Representatives',
        u'lower_chamber_term': 2,
        u'lower_chamber_title': u'Representative',
        u'name': u'Oregon',
        u'session_details': {u'2011 Regular Session': {u'display_name': u'2011 Regular Session',
                                                       u'slug': u'11reg'},
                             u'2012 Regular Session': {u'display_name': u'2012 Regular Session',
                                                       u'slug': u'12reg'}},
        u'terms': [{u'end_year': 2012,
                    u'name': u'2011-2012',
                    u'sessions': [u'2011 Regular Session',
                                  u'2012 Regular Session'],
                    u'start_year': 2011}],
        u'upper_chamber_name': u'Senate',
        u'upper_chamber_term': 4,
        u'upper_chamber_title': u'Senator'},
 'PA': {u'abbreviation': u'pa',
        u'feature_flags': [u'events', u'events'],
        u'id': u'pa',
        u'latest_csv_date': u'2012-05-01 09:05:40',
        u'latest_csv_url': u'http://static.openstates.org/downloads/2012-05-01-pa-csv.zip',
        u'latest_json_date': u'2012-05-01 19:19:54',
        u'latest_json_url': u'http://static.openstates.org/downloads/2012-05-01-pa-json.zip',
        u'latest_update': u'2012-05-26 09:00:42',
        u'legislature_name': u'Pennsylvania General Assembly',
        u'level': u'state',
        u'lower_chamber_name': u'House of Representatives',
        u'lower_chamber_term': 2,
        u'lower_chamber_title': u'Representative',
        u'name': u'Pennsylvania',
        u'session_details': {u'2009-2010': {u'display_name': u'2009-2010 Regular Session',
                                            u'type': u'primary'},
                             u'2009-2010 Special Session #1 (Transportation)': {u'display_name': u'2009-2010, 1st Special Session',
                                                                                u'type': u'special'},
                             u'2011-2012': {u'display_name': u'2011-2012 Regular Session',
                                            u'type': u'primary'}},
        u'terms': [{u'end_year': 2010,
                    u'name': u'2009-2010',
                    u'sessions': [u'2009-2010',
                                  u'2009-2010 Special Session #1 (Transportation)'],
                    u'start_year': 2009},
                   {u'end_year': 2012,
                    u'name': u'2011-2012',
                    u'sessions': [u'2011-2012'],
                    u'start_year': 2011}],
        u'upper_chamber_name': u'Senate',
        u'upper_chamber_term': 4,
        u'upper_chamber_title': u'Senator'},
 'PR': {u'abbreviation': u'pr',
        u'feature_flags': [],
        u'id': u'pr',
        u'latest_csv_date': u'2012-05-01 09:09:33',
        u'latest_csv_url': u'http://static.openstates.org/downloads/2012-05-01-pr-csv.zip',
        u'latest_json_date': u'2012-05-01 23:08:07',
        u'latest_json_url': u'http://static.openstates.org/downloads/2012-05-01-pr-json.zip',
        u'latest_update': u'2012-05-27 04:39:14',
        u'legislature_name': u'Legislative Assembly of Puerto Rico',
        u'level': u'state',
        u'lower_chamber_name': u'House of Representatives',
        u'lower_chamber_term': 4,
        u'lower_chamber_title': u'Representative',
        u'name': u'Puerto Rico',
        u'session_details': {u'2009-2012': {u'display_name': u'2009-2012 Session'}},
        u'terms': [{u'end_year': 2012,
                    u'name': u'2009-2012',
                    u'sessions': [u'2009-2012'],
                    u'start_year': 2009}],
        u'upper_chamber_name': u'Senate',
        u'upper_chamber_term': 4,
        u'upper_chamber_title': u'Senator'},
 'RI': {u'abbreviation': u'ri',
        u'feature_flags': [u'subjects', u'events'],
        u'id': u'ri',
        u'latest_csv_date': u'2012-05-01 09:12:48',
        u'latest_csv_url': u'http://static.openstates.org/downloads/2012-05-01-ri-csv.zip',
        u'latest_json_date': u'2012-05-02 00:55:40',
        u'latest_json_url': u'http://static.openstates.org/downloads/2012-05-02-ri-json.zip',
        u'latest_update': u'2012-05-25 01:46:38',
        u'legislature_name': u'Rhode Island General Assembly',
        u'level': u'state',
        u'lower_chamber_name': u'House of Representatives',
        u'lower_chamber_term': 2,
        u'lower_chamber_title': u'Representative',
        u'name': u'Rhode Island',
        u'session_details': {u'2012': {u'display_name': u'2012 Regular Session',
                                       u'start_date': u'2012-01-04 00:00:00',
                                       u'type': u'primary'}},
        u'terms': [{u'+start_date': u'2012-01-04 00:00:00',
                    u'end_year': 2012,
                    u'name': u'2012',
                    u'sessions': [u'2012'],
                    u'start_year': 2012}],
        u'upper_chamber_name': u'Senate',
        u'upper_chamber_term': 2,
        u'upper_chamber_title': u'Senator'},
 'SC': {u'abbreviation': u'sc',
        u'feature_flags': [],
        u'id': u'sc',
        u'latest_csv_date': u'2012-05-01 09:12:25',
        u'latest_csv_url': u'http://static.openstates.org/downloads/2012-05-01-sc-csv.zip',
        u'latest_json_date': u'2012-05-02 00:23:48',
        u'latest_json_url': u'http://static.openstates.org/downloads/2012-05-02-sc-json.zip',
        u'latest_update': u'2012-05-27 04:21:13',
        u'legislature_name': u'South Carolina Legislature',
        u'level': u'state',
        u'lower_chamber_name': u'House of Representatives',
        u'lower_chamber_term': 2,
        u'lower_chamber_title': u'Representative',
        u'name': u'South Carolina',
        u'session_details': {u'119': {u'display_name': u'2011-2012 Regular Session',
                                      u'start_date': u'2010-11-17 00:00:00',
                                      u'type': u'primary'}},
        u'terms': [{u'end_year': 2012,
                    u'name': u'119',
                    u'sessions': [u'119'],
                    u'start_year': 2010}],
        u'upper_chamber_name': u'Senate',
        u'upper_chamber_term': 4,
        u'upper_chamber_title': u'Senator'},
 'SD': {u'abbreviation': u'sd',
        u'feature_flags': [u'subjects'],
        u'id': u'sd',
        u'latest_csv_date': u'2012-05-01 09:05:47',
        u'latest_csv_url': u'http://static.openstates.org/downloads/2012-05-01-sd-csv.zip',
        u'latest_json_date': u'2012-05-01 19:23:06',
        u'latest_json_url': u'http://static.openstates.org/downloads/2012-05-01-sd-json.zip',
        u'latest_update': u'2012-05-27 05:59:11',
        u'legislature_name': u'South Dakota State Legislature',
        u'level': u'state',
        u'lower_chamber_name': u'House of Representatives',
        u'lower_chamber_term': 2,
        u'lower_chamber_title': u'Representative',
        u'name': u'South Dakota',
        u'session_details': {u'2009': {u'display_name': u'2009 Regular Session'},
                             u'2010': {u'display_name': u'2010 Regular Session'},
                             u'2011': {u'display_name': u'2011 Regular Session',
                                       u'start_date': u'2011-01-11 00:00:00'},
                             u'2011s': {u'display_name': u'2011 Special Session'},
                             u'2012': {u'display_name': u'2012 Regular Session'}},
        u'terms': [{u'end_year': 2010,
                    u'name': u'2009-2010',
                    u'sessions': [u'2009', u'2010'],
                    u'start_year': 2009},
                   {u'end_year': 2012,
                    u'name': u'2011-2012',
                    u'sessions': [u'2011', u'2011s', u'2012'],
                    u'start_year': 2011}],
        u'upper_chamber_name': u'Senate',
        u'upper_chamber_term': 2,
        u'upper_chamber_title': u'Senator'},
 'TN': {u'abbreviation': u'tn',
        u'feature_flags': [u'events'],
        u'id': u'tn',
        u'latest_csv_date': u'2012-05-01 09:13:13',
        u'latest_csv_url': u'http://static.openstates.org/downloads/2012-05-01-tn-csv.zip',
        u'latest_json_date': u'2012-05-02 00:51:57',
        u'latest_json_url': u'http://static.openstates.org/downloads/2012-05-02-tn-json.zip',
        u'latest_update': u'2012-05-27 06:45:11',
        u'legislature_name': u'Tennessee General Assembly',
        u'level': u'state',
        u'lower_chamber_name': u'House',
        u'lower_chamber_term': 2,
        u'lower_chamber_title': u'Represenative',
        u'name': u'Tennessee',
        u'session_details': {u'106': {u'display_name': u'106th Regular Session',
                                      u'type': u'primary'},
                             u'107': {u'display_name': u'107th Regular Session',
                                      u'end_date': u'2012-01-10 00:00:00',
                                      u'start_date': u'2011-01-11 00:00:00',
                                      u'type': u'primary'}},
        u'terms': [{u'end_year': 2010,
                    u'name': u'106',
                    u'sessions': [u'106'],
                    u'start_year': 2009},
                   {u'end_year': 2011,
                    u'name': u'107',
                    u'sessions': [u'107'],
                    u'start_year': 2010}],
        u'upper_chamber_name': u'Senate',
        u'upper_chamber_term': 4,
        u'upper_chamber_title': u'Senator'},
 'TX': {u'abbreviation': u'tx',
        u'capitol_maps': [{u'name': u'Capitol Complex',
                           u'url': u'http://static.openstates.org/capmaps/tx/Map.CapitolComplex.pdf'},
                          {u'name': u'Floor 1',
                           u'url': u'http://static.openstates.org/capmaps/tx/Map.Floor1.pdf'},
                          {u'name': u'Floor 2',
                           u'url': u'http://static.openstates.org/capmaps/tx/Map.Floor2.pdf'},
                          {u'name': u'Floor 3',
                           u'url': u'http://static.openstates.org/capmaps/tx/Map.Floor3.pdf'},
                          {u'name': u'Floor 4',
                           u'url': u'http://static.openstates.org/capmaps/tx/Map.Floor4.pdf'},
                          {u'name': u'Floor E1',
                           u'url': u'http://static.openstates.org/capmaps/tx/Map.FloorE1.pdf'},
                          {u'name': u'Floor E2',
                           u'url': u'http://static.openstates.org/capmaps/tx/Map.FloorE2.pdf'},
                          {u'name': u'Floor G',
                           u'url': u'http://static.openstates.org/capmaps/tx/Map.FloorG.pdf'},
                          {u'name': u'Monument Guide',
                           u'url': u'http://static.openstates.org/capmaps/tx/Map.MonumentGuide.pdf'},
                          {u'name': u'Sam Houston',
                           u'url': u'http://static.openstates.org/capmaps/tx/Map.SamHoustonLoc.pdf'},
                          {u'name': u'Wheelchair Access',
                           u'url': u'http://static.openstates.org/capmaps/tx/Map.WheelchairAccess.pdf'}],
        u'feature_flags': [u'events', u'subjects', u'capitol_maps'],
        u'id': u'tx',
        u'latest_csv_date': u'2012-05-01 09:06:28',
        u'latest_csv_url': u'http://static.openstates.org/downloads/2012-05-01-tx-csv.zip',
        u'latest_json_date': u'2012-05-01 21:19:37',
        u'latest_json_url': u'http://static.openstates.org/downloads/2012-05-01-tx-json.zip',
        u'latest_update': u'2012-05-27 01:57:22',
        u'legislature_name': u'Texas Legislature',
        u'level': u'state',
        u'lower_chamber_name': u'House of Representatives',
        u'lower_chamber_term': 2,
        u'lower_chamber_title': u'Representative',
        u'name': u'Texas',
        u'session_details': {u'81': {u'display_name': u'81st Legislature',
                                     u'end_date': u'2009-06-01 00:00:00',
                                     u'start_date': u'2009-01-13 00:00:00',
                                     u'type': u'primary'},
                             u'811': {u'display_name': u'81st Legislature, 1st Called Session',
                                      u'end_date': u'2009-07-10 00:00:00',
                                      u'start_date': u'2009-07-01 00:00:00',
                                      u'type': u'special'},
                             u'82': {u'display_name': u'82nd Legislature',
                                     u'start_date': u'2011-01-11 00:00:00',
                                     u'type': u'primary'},
                             u'821': {u'display_name': u'82nd Legislature, 1st Called Session',
                                      u'type': u'special'}},
        u'terms': [{u'+type': u'primary',
                    u'end_year': 2010,
                    u'name': u'81',
                    u'sessions': [u'81', u'811'],
                    u'start_year': 2009},
                   {u'end_year': 2012,
                    u'name': u'82',
                    u'sessions': [u'82', u'821'],
                    u'start_year': 2011}],
        u'upper_chamber_name': u'Senate',
        u'upper_chamber_term': 4,
        u'upper_chamber_title': u'Senator'},
 'UT': {u'abbreviation': u'ut',
        u'feature_flags': [u'events', u'subjects'],
        u'id': u'ut',
        u'latest_csv_date': u'2012-05-01 09:06:36',
        u'latest_csv_url': u'http://static.openstates.org/downloads/2012-05-01-ut-csv.zip',
        u'latest_json_date': u'2012-05-01 21:23:38',
        u'latest_json_url': u'http://static.openstates.org/downloads/2012-05-01-ut-json.zip',
        u'latest_update': u'2012-05-27 01:51:04',
        u'legislature_name': u'Utah State Legislature',
        u'level': u'state',
        u'lower_chamber_name': u'House of Representatives',
        u'lower_chamber_term': 2,
        u'lower_chamber_title': u'Representative',
        u'name': u'Utah',
        u'session_details': {u'2011': {u'display_name': u'2011 Regular Session',
                                       u'start_date': u'2011-01-24 00:00:00'},
                             u'2011S1': {u'display_name': u'2011, 1st Special Session'},
                             u'2011S2': {u'display_name': u'2011, 2nd Special Session'},
                             u'2011S3': {u'display_name': u'2011, 3rd Special Session'},
                             u'2012': {u'display_name': u'2012 General Session'}},
        u'terms': [{u'end_year': 2012,
                    u'name': u'2011-2012',
                    u'sessions': [u'2011',
                                  u'2011S1',
                                  u'2011S2',
                                  u'2011S3',
                                  u'2012'],
                    u'start_year': 2011}],
        u'upper_chamber_name': u'Senate',
        u'upper_chamber_term': 4,
        u'upper_chamber_title': u'Senator'},
 'VA': {u'abbreviation': u'va',
        u'feature_flags': [u'subjects'],
        u'id': u'va',
        u'latest_csv_date': u'2012-05-01 09:07:23',
        u'latest_csv_url': u'http://static.openstates.org/downloads/2012-05-01-va-csv.zip',
        u'latest_json_date': u'2012-05-01 21:44:10',
        u'latest_json_url': u'http://static.openstates.org/downloads/2012-05-01-va-json.zip',
        u'latest_update': u'2012-05-27 07:28:30',
        u'legislature_name': u'Virginia General Assembly',
        u'level': u'state',
        u'lower_chamber_name': u'House of Delegates',
        u'lower_chamber_term': 2,
        u'lower_chamber_title': u'Delegate',
        u'name': u'Virginia',
        u'session_details': {u'2010': {u'display_name': u'2010 Regular Session',
                                       u'site_id': u'101',
                                       u'start_date': u'2010-01-13 00:00:00'},
                             u'2011': {u'site_id': u'111',
                                       u'start_date': u'2011-01-12 00:00:00'},
                             u'2011specialI': {u'site_id': u'112'},
                             u'2012': {u'site_id': u'121',
                                       u'start_date': u'2012-01-11 00:00:00'},
                             u'2012specialI': {u'site_id': u'122',
                                               u'start_date': u'2012-03-11 00:00:00'}},
        u'terms': [{u'end_year': 2011,
                    u'name': u'2009-2011',
                    u'sessions': [u'2010', u'2011', u'2011specialI'],
                    u'start_year': 2010},
                   {u'end_year': 2013,
                    u'name': u'2012-2013',
                    u'sessions': [u'2012', u'2012specialI'],
                    u'start_year': 2012}],
        u'upper_chamber_name': u'Senate',
        u'upper_chamber_term': 4,
        u'upper_chamber_title': u'Senator'},
 'VT': {u'abbreviation': u'vt',
        u'feature_flags': [],
        u'id': u'vt',
        u'latest_csv_date': u'2012-05-01 09:06:41',
        u'latest_csv_url': u'http://static.openstates.org/downloads/2012-05-01-vt-csv.zip',
        u'latest_json_date': u'2012-05-01 21:28:36',
        u'latest_json_url': u'http://static.openstates.org/downloads/2012-05-01-vt-json.zip',
        u'latest_update': u'2012-05-27 01:58:53',
        u'legislature_name': u'Vermont General Assembly',
        u'level': u'state',
        u'lower_chamber_name': u'House of Representatives',
        u'lower_chamber_term': 2,
        u'lower_chamber_title': u'Representative',
        u'name': u'Vermont',
        u'session_details': {u'2009-2010': {u'display_name': u'2009-2010 Regular Session',
                                            u'type': u'primary'},
                             u'2011-2012': {u'display_name': u'2011-2012 Regular Session',
                                            u'type': u'primary'}},
        u'terms': [{u'end_year': 2010,
                    u'name': u'2009-2010',
                    u'sessions': [u'2009-2010'],
                    u'start_year': 2009},
                   {u'end_year': 2012,
                    u'name': u'2011-2012',
                    u'sessions': [u'2011-2012'],
                    u'start_year': 2011}],
        u'upper_chamber_name': u'Senate',
        u'upper_chamber_term': 2,
        u'upper_chamber_title': u'Senator'},
 'WA': {u'abbreviation': u'wa',
        u'feature_flags': [u'events', u'subjects'],
        u'id': u'wa',
        u'latest_csv_date': u'2012-05-01 09:07:37',
        u'latest_csv_url': u'http://static.openstates.org/downloads/2012-05-01-wa-csv.zip',
        u'latest_json_date': u'2012-05-01 21:50:51',
        u'latest_json_url': u'http://static.openstates.org/downloads/2012-05-01-wa-json.zip',
        u'latest_update': u'2012-05-27 06:17:02',
        u'legislature_name': u'Washington State Legislature',
        u'level': u'state',
        u'lower_chamber_name': u'House of Representatives',
        u'lower_chamber_term': 2,
        u'lower_chamber_title': u'Representative',
        u'name': u'Washington',
        u'session_details': {u'2009-2010': {u'display_name': u'2009-2010 Regular Session'},
                             u'2011-2012': {u'display_name': u'2011-2012 Regular Session'}},
        u'terms': [{u'end_year': 2010,
                    u'name': u'2009-2010',
                    u'sessions': [u'2009-2010'],
                    u'start_year': 2009},
                   {u'end_year': 2012,
                    u'name': u'2011-2012',
                    u'sessions': [u'2011-2012'],
                    u'start_year': 2011}],
        u'upper_chamber_name': u'Senate',
        u'upper_chamber_term': 4,
        u'upper_chamber_title': u'Senator'},
 'WI': {u'abbreviation': u'wi',
        u'feature_flags': [u'subjects', u'events'],
        u'id': u'wi',
        u'latest_csv_date': u'2012-05-01 09:07:51',
        u'latest_csv_url': u'http://static.openstates.org/downloads/2012-05-01-wi-csv.zip',
        u'latest_json_date': u'2012-05-01 21:57:33',
        u'latest_json_url': u'http://static.openstates.org/downloads/2012-05-01-wi-json.zip',
        u'latest_update': u'2012-05-26 14:49:03',
        u'legislature_name': u'Wisconsin State Legislature',
        u'level': u'state',
        u'lower_chamber_name': u'Assembly',
        u'lower_chamber_term': 2,
        u'lower_chamber_title': u'Representative',
        u'name': u'Wisconsin',
        u'session_details': {u'2009 Regular Session': {u'display_name': u'2009 Regular Session',
                                                       u'end_date': u'2011-01-03 00:00:00',
                                                       u'start_date': u'2009-01-13 00:00:00',
                                                       u'type': u'primary'},
                             u'2011 Regular Session': {u'display_name': u'2011 Regular Session',
                                                       u'end_date': u'2013-01-07 00:00:00',
                                                       u'start_date': u'2011-01-11 00:00:00',
                                                       u'type': u'primary'},
                             u'December 2009 Special Session': {u'display_name': u'Dec 2009 Special Session',
                                                                u'site_id': u'de9',
                                                                u'type': u'special'},
                             u'January 2011 Special Session': {u'display_name': u'Jan 2011 Special Session',
                                                               u'site_id': u'jr1',
                                                               u'type': u'special'},
                             u'June 2009 Special Session': {u'display_name': u'Jun 2009 Special Session',
                                                            u'site_id': u'jn9',
                                                            u'type': u'special'},
                             u'September 2011 Special Session': {u'display_name': u'Sep 2011 Special Session',
                                                                 u'site_id': u'se1',
                                                                 u'type': u'special'}},
        u'terms': [{u'end_year': 2010,
                    u'name': u'2009-2010',
                    u'sessions': [u'June 2009 Special Session',
                                  u'December 2009 Special Session',
                                  u'2009 Regular Session'],
                    u'start_year': 2009},
                   {u'end_year': 2011,
                    u'name': u'2011-2012',
                    u'sessions': [u'2011 Regular Session',
                                  u'January 2011 Special Session',
                                  u'September 2011 Special Session'],
                    u'start_year': 2011}],
        u'upper_chamber_name': u'Senate',
        u'upper_chamber_term': 4,
        u'upper_chamber_title': u'Senator'},
 'WV': {u'abbreviation': u'wv',
        u'feature_flags': [u'subjects'],
        u'id': u'wv',
        u'latest_csv_date': u'2012-05-01 09:09:46',
        u'latest_csv_url': u'http://static.openstates.org/downloads/2012-05-01-wv-csv.zip',
        u'latest_json_date': u'2012-05-01 22:54:15',
        u'latest_json_url': u'http://static.openstates.org/downloads/2012-05-01-wv-json.zip',
        u'latest_update': u'2012-05-27 02:58:41',
        u'legislature_name': u'West Virginia Legislature',
        u'level': u'state',
        u'lower_chamber_name': u'House of Delegates',
        u'lower_chamber_term': 2,
        u'lower_chamber_title': u'Delegate',
        u'name': u'West Virginia',
        u'session_details': {u'2011': {u'display_name': u'2011 Regular Session'},
                             u'2012': {u'display_name': u'2012 Regular Session'}},
        u'terms': [{u'end_year': 2012,
                    u'name': u'2011-2012',
                    u'sessions': [u'2011', u'2012'],
                    u'start_year': 2011}],
        u'upper_chamber_name': u'Senate',
        u'upper_chamber_term': 4,
        u'upper_chamber_title': u'Senator'},
 'WY': {u'abbreviation': u'wy',
        u'feature_flags': [],
        u'id': u'wy',
        u'latest_csv_date': u'2012-05-01 09:12:10',
        u'latest_csv_url': u'http://static.openstates.org/downloads/2012-05-01-wy-csv.zip',
        u'latest_json_date': u'2012-05-02 00:16:57',
        u'latest_json_url': u'http://static.openstates.org/downloads/2012-05-02-wy-json.zip',
        u'latest_update': u'2012-05-27 01:56:22',
        u'legislature_name': u'Wyoming State Legislature',
        u'level': u'state',
        u'lower_chamber_name': u'House of Representatives',
        u'lower_chamber_term': 2,
        u'lower_chamber_title': u'Representative',
        u'name': u'Wyoming',
        u'session_details': {u'2011': {u'display_name': u'2011 General Session',
                                       u'type': u'primary'},
                             u'2012': {u'display_name': u'2012 Budget Session',
                                       u'type': u'special'}},
        u'terms': [{u'end_year': 2012,
                    u'name': u'2011-2012',
                    u'sessions': [u'2011', u'2012'],
                    u'start_year': 2011}],
        u'upper_chamber_name': u'Senate',
        u'upper_chamber_term': 4,
        u'upper_chamber_title': u'Senator'}}

########NEW FILE########
__FILENAME__ = search_indexes
from models import StateBill
from smartsearch import build_haystack_index

StateBillIndex = build_haystack_index(StateBill)


########NEW FILE########
__FILENAME__ = urls
# -*- coding: utf-8 -*-
from django.conf.urls import *

urlpatterns = patterns('states.views',
    url(r'^([a-z]{2})/bills/([^/]+)/(.+)$', 'state_bill'),
    url(r'^()bills/browse$', 'state_bill_browse'),
    url(r'^([a-z]{2})/bills/browse$', 'state_bill_browse'),
    url(r'^([a-z]{2})$', 'state_overview'),
)


########NEW FILE########
__FILENAME__ = views
from django.shortcuts import redirect, get_object_or_404, Http404
from django.db.models import Count
from cache_utils.decorators import cached
from common.decorators import render_to

import re, json, urllib
from datetime import datetime, timedelta

from events.models import Feed
from states.models import StateBill, StateChamberEnum
import us
import openstates_metadata
from settings import SUNLIGHTLABS_API_KEY

from smartsearch.manager import SearchManager

import django.contrib.sitemaps
class sitemap(django.contrib.sitemaps.Sitemap):
	index_levels = ['state_session']
	changefreq = "yearly"
	priority = 0.15
	
	def items(self):
		return StateBill.objects.select_related('state_session').only('state_session__state', 'state_session__slug', 'bill_number')

def cache_result(f):
	"""A decorator that caches the result of a function with the function so that on further invocations
	it returns the value immediately."""
	def g(*args, **kwargs):
		if hasattr(f, "_cached_result"):
			return f._cached_result
		f._cached_result = f(*args, **kwargs)
		return f._cached_result
	return g

@render_to('states/bill.html')
def state_bill(request, state, session, billnum):
	bill = get_object_or_404(StateBill, state_session__state=state, state_session__slug=session, bill_number=billnum)
	state = bill.state_session.state
	state_metadata = openstates_metadata.stata_metadata[state]
	
	chamber_name = ""
	if bill.chamber == StateChamberEnum.lower:
		chamber_name = state_metadata["lower_chamber_name"]
	if bill.chamber == StateChamberEnum.upper:
		chamber_name = state_metadata["upper_chamber_name"]
		
	@cache_result
	def openstates_api_info():
		try:
			if bill.openstatesid == None: return None
			os_state, os_session, os_bill = bill.openstatesid.split(" ", 2)
			state_chamber = { StateChamberEnum.lower: "lower/", StateChamberEnum.upper: "upper/" }
			url = "http://openstates.org/api/v1/bills/%s/%s/%s%s?apikey=%s" \
				% (os_state, os_session, state_chamber.get(bill.chamber, ""), os_bill, SUNLIGHTLABS_API_KEY)
			print url
			return json.load(urllib.urlopen(url))
		except:
			return None
			
	def get_feed():
		return Feed.objects.get(feedname="states_bill:%d" % bill.id)
			
	return {
		"bill": bill,
		"state_metadata": state_metadata,
		"chamber_name": chamber_name,
		"openstates_api_info": openstates_api_info, # as a function to allow for template-level caching
		"feed": get_feed,
	}

@render_to('states/state.html')
def state_overview(request, state):
	if state.upper() not in us.statenames:
		raise Http404()
		
	try:
		feed = Feed.objects.get(feedname="states_%s_bills" % state)
	except Feed.DoesNotExist:
		feed = None
		
	return {
		"state": state.upper(),
		"state_metadata": openstates_metadata.stata_metadata[state.upper()],
		"feed": feed,
	}

def state_bill_browse(request, state):
	if state != "" and state.upper() not in us.statenames:
		raise Http404()
	
	sm = SearchManager(StateBill, connection="states")

	if state: sm.add_filter('state', state)

	sm.add_option('text', label='search title & summary', type="text", choices="NONE")
	if not state: sm.add_option('state', label="state", type="select", sort="KEY", formatter=lambda k : k.upper())
	sm.add_option('state_session', label="session", type="select", sort=lambda k : (datetime.now().date() - k.startdate) if k.startdate else timedelta(days=0), visible_if=lambda post:state or "state" in post, formatter=lambda k : k.name) # use now to make reverse sort
	sm.add_option('chamber', label="chamber")
	
	sm.add_sort('Last Action', '-last_action_date', default=True)

	sm.set_template("""
    	<a href="{{object.get_absolute_url}}" style="font-size: 15px">{{object|truncatewords_html:50}}</a>
    	<div>{{object.state_session}}</div>
    	<div>{{object.last_action_date}}: {{object.last_action_text}}</div>
	""")

	return sm.view(request, "states/bill_search.html",
		defaults={
			"text": request.GET.get("text", ""),
		},
		noun = ("state bill", "state bills"),
		context = {
			"state": state.upper(),
			"statename": us.statenames.get(state.upper(), None),
			"feed": Feed.objects.get_or_create(feedname="states_allbills" if not state else "states_%s_bills" % state.upper())[0]
		},
		)

_states_with_data = None
def states_with_data():
	global _states_with_data
	if not _states_with_data:
		from states.models import StateSession
		_states_with_data = sorted(set(StateSession.objects.values_list("state", flat=True)))
		#from haystack.query import SearchQuerySet
		#_states_with_data = sorted([
		#	s[0].upper()
		#	for s in SearchQuerySet().using('states').filter(indexed_model_name__in=["StateBill"]).facet('state').facet_counts()['fields']['state']
		#	if s[0].upper() in us.statenames
		#	])
	return _states_with_data


########NEW FILE########
__FILENAME__ = decorators
# Make pages more cachable by splitting user-specific parts of
# a page from anonymous parts.

from functools import wraps

from django.contrib.auth.models import AnonymousUser
from django.views.decorators.cache import cache_control
from django.conf import settings
import django.middleware.csrf

# Inject ourselves into CSRF processing to prevent the generation of CSRF
# tokens on anonymous views.
old_csrf_get_token = django.middleware.csrf.get_token
def new_csrf_get_token(request):
	if getattr(request, "anonymous", False):
		raise Exception("Requests marked 'anonymous' cannot generate CSRF tokens!")
	return old_csrf_get_token(request)
django.middleware.csrf.get_token = new_csrf_get_token

def anonymous_view(view):
	"""Marks a view as an anonymous, meaning this view returns nothing specific
	to the logged in user. In order to enforce this, the user, session, and COOKIES
	attributes of the request are cleared along with some keys in META.
	Additionally it sets cache-control settings on the output of the page and sets
	request.anonymous = True, which can be used in templates."""
	view = cache_control(public=True)(view)
	@wraps(view)
	def g(request, *args, **kwargs):
		request.anonymous = True
		request.COOKIES = { }
		request.user = AnonymousUser()
		if hasattr(request, "session"): request.session = { }

		for header in list(request.META.keys()):
			if header not in ('CONTENT_LENGTH', 'CONTENT_TYPE', 'HTTP_HOST', 'QUERY_STRING', 'REQUEST_METHOD', 'SERVER_NAME', 'SERVER_PORT', 'SERVER_PROTOCOL', 'REMOTE_ADDR'):
				del request.META[header]
				
		# In order for the Django debug template context processor to work, we can't
		# clear REMOTE_ADDR. Clear it if {{debug}} would be false. The resulting page
		# should not be cached since it may depend on REMOTE_ADDR.
		if 'REMOTE_ADDR' in request.META and (not settings.DEBUG or request.META['REMOTE_ADDR'] not in settings.INTERNAL_IPS):
			del request.META['REMOTE_ADDR']
			
		response = view(request, *args, **kwargs)
		response.csrf_processing_done = True # prevent generation of CSRF cookies
		return response
	return g
		
def user_view_for(anon_view_func):
	"""Marks a view as providing user-specific information for a view that the
	anonymous_view decorator has been applied to."""
	def decorator(view):
		anon_view_func.user_func = view
		return view
	return decorator


########NEW FILE########
__FILENAME__ = middleware
from django.conf import settings

class CacheLogic:
	def __init__(self):
		if settings.SESSION_SAVE_EVERY_REQUEST:
			raise Exception("You must set SESSION_SAVE_EVERY_REQUEST to False in order to use twostream.middleware.CacheLogic.")
		
	def process_response(self, request, response):
		if not getattr(request, "anonymous", False)\
			or request.method not in ("GET", "HEAD")\
			or settings.DEBUG:
			# This view does not have the anonymous attribute, or was requested
			# with a method we should not cache, so apply cache-control headers
			# to prevent any upstream caching.
			response['Pragma'] = 'no-cache'
			response["Cache-Control"] = "no-cache, no-store, must-revalidate"
			
		return response
		

########NEW FILE########
__FILENAME__ = urls
# -*- coding: utf-8 -*-
from django.conf.urls import *

urlpatterns = patterns('twostream.views',
    url(r'^/user-head$', 'user_head', name='twostream-views-user-head'),
)


########NEW FILE########
__FILENAME__ = views
# -*- coding: utf-8 -*-
from django.http import HttpResponse, Http404
from django.core.urlresolvers import resolve
from django.template import Template, Context, RequestContext
from django.views.decorators.cache import cache_control

import json

head_template_mime_type = "application/javascript"
head_template = Template("""
$('html').ajaxSend(function(event, xhr, settings) { if (!/^https?:.*/.test(settings.url)) xhr.setRequestHeader("X-CSRFToken", "{{csrf_token|escapejs}}"); });
var the_user = {{user_data|safe}};
var the_page = {{page_data|safe}};
{% include "user_head_script.js" %}
""")

@cache_control(private=True, must_revalidate=True)
def user_head(request):
	m = resolve(request.GET.get("path", request.GET.get("view", "")))
	
	user_data = None
	if request.user.is_authenticated():
		user_data = { "email": request.user.email }
		if hasattr(request.user, 'twostream_data'):
			user_data.update(request.user.twostream_data)
		
	page_data = None
	if hasattr(m.func, 'user_func'):
		try:
			page_data = m.func.user_func(request, *m.args, **m.kwargs)
		except Http404:
			# silently ignore, probably the main page was a 404 too
			pass
	
	return HttpResponse(head_template.render(RequestContext(request, {
				"user_data": json.dumps(user_data),
				"page_data": json.dumps(page_data),
				})), content_type=head_template_mime_type)
	

########NEW FILE########
__FILENAME__ = urls
from django.conf.urls import *
from django.conf import settings
import django.views.static

from django.contrib import admin
admin.autodiscover()

urlpatterns = patterns('',
    url(r'^admin/', include(admin.site.urls)),

	# main URLs
    url(r'', include('redirect.urls')),
    url(r'', include('website.urls')),
    url(r'^congress/members(?:$|/)', include('person.urls')),
    url(r'^congress/committees/', include('committee.urls')),
    url(r'^congress/', include('vote.urls')),
    url(r'^congress/bills/', include('bill.urls')),
    url(r'', include('events.urls')),
    url(r'^market/', include('predictionmarket.urls')),
    url(r'^states(/|$)', include('states.urls')),
    url(r'^poll(/|$)', include('poll_and_call.urls')),
    url(r'^api/v2/([^/]+)(?:/(\d+))?', 'website.api.apiv2'),

    url(r'^_twostream', include('twostream.urls')),

    # django-registration-pv
    (r'^emailverif/', include('emailverification.urls')),
    (r'^registration/', include('registration.urls')),
    (r'^accounts/login/?$', 'registration.views.loginform'), # Django adds a slash when logging out?
    (r'^accounts/logout$', 'django.contrib.auth.views.logout', { "redirect_field_name": "next" }),
    (r'^accounts/profile$', 'registration.views.profile'),
)

# sitemaps
from collections import OrderedDict
import person.views, bill.views, committee.views, vote.views, states.models, states.views
from django.contrib.sitemaps.views import index as sitemap_index_view
from django.contrib.sitemaps.views import sitemap as sitemap_map_view
from twostream.decorators import anonymous_view
sitemaps = OrderedDict([
        ("bills_current", bill.views.sitemap_current),
        #("bills_archive", bill.views.sitemap_archive), # takes too long to load
        ("people_current", person.views.sitemap_current),
        ("people_archive", person.views.sitemap_archive),
        ("districts", person.views.sitemap_districts),
        ("committees", committee.views.sitemap),
        ("votes_current", vote.views.sitemap_current),
        #("votes_archive", vote.views.sitemap_archive), # takes too long to load
	])
urlpatterns += patterns('',
    (r'^sitemap\.xml$', anonymous_view(sitemap_index_view), {'sitemaps': sitemaps, 'sitemap_url_name': 'sitemap_pages'}),
   url(r'^sitemap-(?P<section>.+)\.xml$', anonymous_view(sitemap_map_view), {'sitemaps': sitemaps}, name='sitemap_pages'),
)

# API access points
from website.api import v1_api
urlpatterns += patterns('',
    (r'^api/', include(v1_api.urls)),
)

if settings.DEBUG:
    # serve /static during debugging
    from django.contrib.staticfiles.urls import staticfiles_urlpatterns
    urlpatterns += staticfiles_urlpatterns()
 
    # serve /data during debugging
    from django.conf.urls.static import static
    urlpatterns += static("/data", document_root="data")
########NEW FILE########
__FILENAME__ = us
# TODO: move this module to some package

from datetime import datetime

# Current apportionment to the states, or "T" for territories sending a delegate
# or resident commissioner. This dict is used to filter out the historical territories
# from lists of the current states and territories.
stateapportionment = {'AL': 7, 'AK': 1, 'AS': 'T', 'AZ': 9, 'AR': 4, 'CA': 53, 'CO': 7, 'CT': 5, 'DE': 1, 'DC': 'T', 'FL': 27, 'GA': 14, 'GU': 'T', 'HI': 2, 'ID': 2, 'IL': 18, 'IN': 9, 'IA': 4, 'KS': 4, 'KY': 6, 'LA': 6, 'ME': 2, 'MD': 8, 'MA': 9, 'MI': 14, 'MN': 8, 'MS': 4, 'MO': 8, 'MT': 1, 'NE': 3, 'NV': 4, 'NH': 2, 'NJ': 12, 'NM': 3, 'NY': 27, 'NC': 13, 'ND': 1, 'MP': 'T', 'OH': 16, 'OK': 5, 'OR': 5, 'PA': 18, 'PR': 'T', 'RI': 2, 'SC': 7, 'SD': 1, 'TN': 9, 'TX': 36, 'UT': 4, 'VT': 1, 'VI': 'T', 'VA': 11, 'WA': 10, 'WV': 3, 'WI': 8, 'WY': 1}
#stateapportionment_112 = {'AL': 7, 'AK': 1, 'AS': 'T', 'AZ': 8, 'AR': 4, 'CA': 53, 'CO': 7, 'CT': 5, 'DE': 1, 'DC': 'T', 'FL': 25, 'GA': 13, 'GU': 'T', 'HI': 2, 'ID': 2, 'IL': 19, 'IN': 9, 'IA': 5, 'KS': 4, 'KY': 6, 'LA': 7, 'ME': 2, 'MD': 8, 'MA': 10, 'MI': 15, 'MN': 8, 'MS': 4, 'MO': 9, 'MT': 1, 'NE': 3, 'NV': 3, 'NH': 2, 'NJ': 13, 'NM': 3, 'NY': 29, 'NC': 13, 'ND':  1, 'MP': 'T', 'OH': 18, 'OK': 5, 'OR': 5, 'PA': 19, 'PR': 'T', 'RI': 2, 'SC': 6, 'SD': 1, 'TN': 9, 'TX': 32, 'UT': 3, 'VT': 1, 'VI': 'T', 'VA': 11, 'WA': 9, 'WV': 3, 'WI': 8, 'WY': 1}

# All state abbreviations, including historical territories.
stateabbrs = ["AL", "AK", "AS", "AZ", "AR", "CA", "CO", "CT", "DE", "DC", "FL", "GA", "GU", "HI", "ID", "IL", "IN", "IA", "KS", "KY", "LA", "ME", "MD", "MA", "MI", "MN", "MS", "MO", "MT", "NE", "NV", "NH", "NJ", "NM", "NY", "NC", "ND", "MP", "OH", "OK", "OR", "PA", "PR", "RI", "SC", "SD", "TN", "TX", "UT", "VT", "VI", "VA", "WA", "WV", "WI", "WY", "DK", "PI", "OL"]

# All state names, including historical territories.
statenames = {"AL":"Alabama", "AK":"Alaska", "AS":"American Samoa", "AZ":"Arizona", "AR":"Arkansas", "CA":"California", "CO":"Colorado", "CT":"Connecticut", "DE":"Delaware", "DC":"District of Columbia", "FL":"Florida", "GA":"Georgia", "GU":"Guam", "HI":"Hawaii", "ID":"Idaho", "IL":"Illinois", "IN":"Indiana", "IA":"Iowa", "KS":"Kansas", "KY":"Kentucky", "LA":"Louisiana", "ME":"Maine", "MD":"Maryland", "MA":"Massachusetts", "MI":"Michigan", "MN":"Minnesota", "MS":"Mississippi", "MO":"Missouri", "MT":"Montana", "NE":"Nebraska", "NV":"Nevada", "NH":"New Hampshire", "NJ":"New Jersey", "NM":"New Mexico", "NY":"New York", "NC":"North Carolina", "ND": "North Dakota", "MP":"Northern Mariana Islands", "OH":"Ohio", "OK":"Oklahoma", "OR":"Oregon", "PA":"Pennsylvania", "PR":"Puerto Rico", "RI":"Rhode Island", "SC":"South Carolina", "SD":"South Dakota", "TN":"Tennessee", "TX":"Texas", "UT":"Utah", "VT":"Vermont", "VI":"Virgin Islands", "VA":"Virginia", "WA":"Washington", "WV":"West Virginia", "WI":"Wisconsin", "WY":"Wyoming", "DK": "Dakota Territory", "PI": "Philippines Territory/Commonwealth", "OL": "Territory of Orleans"}
state_abbr_from_name = dict((v.lower(),k) for (k,v) in statenames.items())

# Current states, a list of (abbr, name) tuples in sorted order.
statelist = [s for s in statenames.items() if s[0] in stateapportionment]
statelist.sort(key=lambda x : x[1])

CONGRESS_DATES = {}
SESSION_DATES = []

def parse_govtrack_date(d, as_date=False):
    if as_date:
        return datetime.strptime(d, '%Y-%m-%d').date()
    
    try:
        return datetime.strptime(d, '%Y-%m-%dT%H:%M:%S-04:00')
    except ValueError:
        pass
    try:
        return datetime.strptime(d, '%Y-%m-%dT%H:%M:%S-05:00')
    except ValueError:
        pass
    return datetime.strptime(d, '%Y-%m-%d')


def get_congress_dates(congressnumber):
    global CONGRESS_DATES
    if CONGRESS_DATES == { }:
        cd = {}
        for line in open('data/us/sessions.tsv'):
            cn, sessionname, startdate, enddate = line.strip().split('\t')[0:4]
            if not '-' in startdate: # header
                continue
            cn = int(cn)
            if not cn in cd:
                cd[cn] = [parse_govtrack_date(startdate, as_date=True), None]
            cd[cn][1] = parse_govtrack_date(enddate, as_date=True)
        CONGRESS_DATES.update(cd)
    return CONGRESS_DATES[congressnumber]

def get_session_from_date(when, allow_start_date=True, allow_end_date=True):
    global SESSION_DATES
    if SESSION_DATES == [ ]:
        sd = []
        for line in open('data/us/sessions.tsv'):
            cn, sessionname, startdate, enddate = line.strip().split('\t')[0:4]
            if not '-' in startdate: # header
                continue
            sd.append((int(cn), sessionname, parse_govtrack_date(startdate, as_date=True), parse_govtrack_date(enddate, as_date=True)))
        SESSION_DATES = sd
    
    if when == None:
        return None
        
    if isinstance(when, datetime):
        when = when.date()
    
    for c, s, sd, ed in SESSION_DATES:
        if (sd < when or (allow_start_date and sd == when)) and (when < ed or (allow_end_date and when == ed)):
            return (c, s)
            
    return None

def get_session_ordinal(congress, session):
    get_session_from_date(None) # load data
    
    ordinal = 0
    for c, s, sd, ed in SESSION_DATES:
        if c == congress:
            ordinal += 1
            if s == session: return ordinal
            
    raise ValueError("Congress or session not found.")
    
def get_all_sessions():
    get_session_from_date(None) # load data
    return SESSION_DATES # [(congress, session, startdate, enddate), ...]

def get_congress_from_date(when, range_type=None):
    if when.isoformat() < "1941-01-03":
        # Before this time the dates of Congresses were pretty arbitrary.
        get_congress_dates(1) # load data
        for c, (sd, ed) in CONGRESS_DATES.items():
            if (sd < when or (range_type=='start' and sd == when)) and (when < ed or (range_type=='end' and when == ed)):
                return c
        return None
    else:
        # Since 1941, we can reliably use the Jan 3-Jan 3 rule.
        legislative_year = when.year
        if when.month == 1 and when.day <= 2:
            # Get the "legislative year", which is the same as the calendar year
            # except on Jan 1, 2, and half of 3 which is a part of the previous legislative year.
            legislative_year = when.year - 1
        elif when.month == 1 and when.day == 3:
            # This date is the end of a range, so we'll treat Jan 3 as being before noon.
            if range_type == "end":
                legislative_year = when.year - 1

            # This date is the start of a range, so we'll treat Jan 3 as being after noon.
            elif range_type == "start":
                legislative_year = when.year

            else:
                raise ValueError("Date is ambiguous; must pass range_type='start' or 'end'.")

        # Now do some simple integer math to compute the Congress number.
        return ((legislative_year + 1) // 2) - 894



########NEW FILE########
__FILENAME__ = admin
# -*- coding: utf-8

from django.contrib import admin
from vote.models import Vote, VoteOption, Voter

class VoteOptionInline(admin.TabularInline):
    model = VoteOption

class VoteAdmin(admin.ModelAdmin):
    list_display = ('question' ,'congress', 'session', 'chamber', 'number', 'created')
    inlines = (VoteOptionInline,)

class VoteOptionAdmin(admin.ModelAdmin):
    list_display = ('vote', 'key', 'value')

class VoterAdmin(admin.ModelAdmin):
    list_display = ('vote', 'person', 'option', 'created')

admin.site.register(Vote, VoteAdmin)
admin.site.register(VoteOption, VoteOptionAdmin)
admin.site.register(Voter, VoterAdmin)

########NEW FILE########
__FILENAME__ = forms
from django import forms

from vote.models import Vote, CongressChamber, VoteCategory

YEARS = [('', 'Any')] + [(x, str(x)) for x in xrange(2011, 1788, -1)]
CHAMBERS = [('', 'Any')] + CongressChamber.choices()
CATEGORIES = [('', 'Any')] + VoteCategory.choices()

YEAR_FIELD = forms.ChoiceField(choices=YEARS, required=False)

class VoteFilterForm(forms.Form):
    year = forms.ChoiceField(choices=YEARS, required=False)
    chamber = forms.ChoiceField(choices=CHAMBERS, required=False)
    category = forms.ChoiceField(choices=CATEGORIES, required=False)

    def filter(self, qs):
        data = self.cleaned_data
        if data['year']:
            qs = qs.filter(created__year=data['year'])
        if data['chamber']:
            qs = qs.filter(chamber=data['chamber'])
        if data['category']:
            qs = qs.filter(category=data['category'])
        return qs

########NEW FILE########
__FILENAME__ = models
# -*- coding: utf-8 -*-
import math

from django.db import models
from django.db.models import Q
from django.core.urlresolvers import reverse
from django.conf import settings

from common import enum

from person.util import load_roles_at_date

from us import get_session_ordinal

class CongressChamber(enum.Enum):
    senate = enum.Item(1, 'Senate')
    house = enum.Item(2, 'House')


class VoteSource(enum.Enum):
    senate = enum.Item(1, 'senate.gov')
    house = enum.Item(2, 'house.gov')
    keithpoole = enum.Item(3, 'Professor Keith Poole')


class VoteCategory(enum.Enum):
    amendment = enum.Item(1, 'Amendment', search_help_text="Votes on accepting or rejecting amendments to bills and resolutions.")
    passage_suspension = enum.Item(2, 'Passage under Suspension', search_help_text="Fast-tracked votes on the passage of bills requiring a 2/3rds majority.")
    passage = enum.Item(3, 'Passage', search_help_text="Votes on passing or failing bills and resolutions and on agreeing to conference reports.")
    cloture = enum.Item(4, 'Cloture', search_help_text="Votes to end debate and move to a vote, i.e. to end a filibuster.")
    passage_part = enum.Item(5, 'Passage (Part)', search_help_text="Votes on the passage of parts of legislation.")
    nomination = enum.Item(6, 'Nomination', search_help_text="Senate votes on presidential nominations.")
    procedural = enum.Item(7, 'Procedural', search_help_text="A variety of procedural votes such as quorum calls.")
    other = enum.Item(8, 'Other', search_help_text="A variety of uncategorized votes.")
    unknown = enum.Item(9, 'Unknown Category', search_help_text="A variety of uncategorized votes.")
    ratification = enum.Item(12, 'Treaty Ratification', search_help_text="Senate votes to ratify treaties.")
    veto_override = enum.Item(10, 'Veto Override', search_help_text="Votes to override a presidential veto.")
    conviction = enum.Item(11, 'Impeachment Conviction', search_help_text="'Guilty or Not Guilty' votes in the Senate to convict an office holder of impeachment.")

class VoterType(enum.Enum):
    unknown = enum.Item(1, 'Unknown')
    vice_president = enum.Item(2, 'Vice President')
    member = enum.Item(3, 'Member of Congress')


class Vote(models.Model):
    """Roll call votes in the U.S. Congress since 1789. How people voted is accessed through the Vote_voter API."""
    
    congress = models.IntegerField(help_text="The number of the Congress in which the vote took place. The current Congress is %d. In recent history Congresses are two years; however, this was not always the case." % settings.CURRENT_CONGRESS)
    session = models.CharField(max_length=4, help_text="Within each Congress there are sessions. In recent history the sessions correspond to calendar years and are named accordingly. However, in historical data the sessions may be named in completely other ways, such as with letters A, B, and C. Session names are unique *within* a Congress.")
    chamber = models.IntegerField(choices=CongressChamber, help_text="The chamber in which the vote was held, House or Senate.")
    number = models.IntegerField('Vote Number', help_text="The number of the vote, unique to a Congress, session, and chamber.")
    source = models.IntegerField(choices=VoteSource, help_text="The source of the vote information.")
    created = models.DateTimeField(db_index=True, help_text="The date (and in recent history also time) on which the vote was held.")
    vote_type = models.CharField(max_length=255, help_text="Descriptive text for the type of the vote.")
    category = models.IntegerField(max_length=255, choices=VoteCategory, help_text="The type of the vote.")
    question = models.TextField(help_text="Descriptive text for what the vote was about.")
    required = models.CharField(max_length=10, help_text="A code indicating what number of votes was required for success. Often '1/2' or '3/5'. This field should be interpreted with care. It comes directly from the upstream source and may need some 'unpacking.' For instance, while 1/2 always mean 1/2 of those voting (i.e. excluding absent and abstain), 3/5 in some cases means to include absent/abstain and in other cases to exclude.")
    result = models.TextField(help_text="Descriptive text for the result of the vote.")
    total_plus = models.IntegerField(blank=True, default=0, help_text="The count of positive votes (aye/yea).")
    total_minus = models.IntegerField(blank=True, default=0, help_text="The count of negative votes (nay/no).")
    total_other = models.IntegerField(blank=True, default=0, help_text="The count of abstain or absent voters.")
    
    related_bill = models.ForeignKey('bill.Bill', related_name='votes', blank=True, null=True, help_text="A related bill.", on_delete=models.PROTECT)
    related_amendment = models.ForeignKey('bill.Amendment', related_name='votes', blank=True, null=True, help_text="A related amendment.", on_delete=models.PROTECT)
    missing_data = models.BooleanField(default=False, help_text="If something in the source could be parsed and we should revisit the file.")
    question_details = models.TextField(help_text="Additional descriptive text for what the vote was about.", blank=True, null=True)
    
    class Meta:
        # The ordering makes sure votes are in the right order on bill pages.
        ordering = ["created", "chamber", "number"]
        unique_together = (('congress', 'chamber', 'session', 'number'),)
        
    api_additional_fields = {
        "link": lambda obj : settings.SITE_ROOT_URL + obj.get_absolute_url(),
    }
    api_recurse_on = ('related_bill', 'options')
    api_example_parameters = { "sort": "-created" }

    def __unicode__(self):
        return self.question

    def calculate_totals(self):
        self.total_plus = self.voters.filter(option__key='+').count()
        self.total_minus = self.voters.filter(option__key='-').count()
        self.total_other = self.voters.count() - (self.total_plus + self.total_minus)
        self.save()

    def get_absolute_url(self):
        if self.chamber == CongressChamber.house:
            chamber_code = 'h'
        else:
            chamber_code = 's'
        return reverse('vote_details', args=[self.congress, self.session,
                       chamber_code, self.number])
        
    def get_source_link(self):
        """A link to the website where this vote information was obtained."""
        if self.source == VoteSource.senate:
            return "http://www.senate.gov/legislative/LIS/roll_call_lists/roll_call_vote_cfm.cfm?congress=%d&session=%s&vote=%05d" % (self.congress, get_session_ordinal(self.congress, self.session), self.number)
        elif self.source == VoteSource.house:
            return "http://clerk.house.gov/evs/%d/roll%03d.xml" % (self.created.year, self.number)
        elif self.source == VoteSource.keithpoole:
            return "http://voteview.com/"
        raise ValueError("invalid source: " + str(self.source))
        
    def name(self):
        return CongressChamber.by_value(self.chamber).label + " Vote #" + str(self.number)
        
    @property
    def is_major(self):
        return self.category in (VoteCategory.passage_suspension, VoteCategory.passage, VoteCategory.passage_part, VoteCategory.nomination, VoteCategory.ratification, VoteCategory.veto_override)

    @property
    def is_on_passage(self):
        return self.category in (VoteCategory.passage_suspension, VoteCategory.passage)
        
    def totals(self):
        # If cached value exists then return it
        if hasattr(self, '_cached_totals'):
            return self._cached_totals
        # else do all these things:

        items = []

        # Extract all voters, find their role at the time
        # the vote was
        all_voters = list(self.voters.all().select_related('person', 'option'))
        voters_by_option = {}
        for option in self.options.all():
            voters_by_option[option] = [x for x in all_voters if x.option == option]
        total_count = len(all_voters)

        persons = [x.person for x in all_voters if x.person != None]
        load_roles_at_date(persons, self.created)

        # Find all parties which participated in vote
        # and sort them in order which they should be displayed

        def cmp_party(x):
            """
            Sort the parties by the number of voters in that party.
            """
            return -len([p for p in all_voters if p.person and p.person.role and p.person.role.party == x])
        
        def get_party(voter):
            if voter.voter_type != VoterType.vice_president:
                if voter.person and voter.person.role:
                    return voter.person.role.party
                else:
                    return "Unknown"
            else:
                return "Vice President"
        
        all_parties = list(set(get_party(x) for x in all_voters))
        all_parties.sort(key=cmp_party)
        total_party_stats = dict((x, {'yes': 0, 'no': 0, 'other': 0, 'total': 0})\
                                 for x in all_parties)

        # For each option find party break down,
        # total vote count and percentage in total count
        details = []
        for option in self.options.all():
            voters = voters_by_option.get(option, [])
            percent = round(len(voters) / float(total_count) * 100.0)
            party_stats = dict((x, 0) for x in all_parties)
            for voter in voters:
                party = get_party(voter)
                party_stats[party] += 1
                total_party_stats[party]['total'] += 1
                if option.key == '+':
                    total_party_stats[party]['yes'] += 1
                elif option.key == '-':
                    total_party_stats[party]['no'] += 1
                else:
                    total_party_stats[party]['other'] += 1
            party_counts = [party_stats.get(x, 0) for x in all_parties]
            party_counts = [{"party": all_parties[i], "count": c, 'chart_width': 190 * c / total_count} for i, c in enumerate(party_counts)]
                
            detail = {'option': option, 'count': len(voters),
                'percent': int(percent), 'party_counts': party_counts,
                'chart_width': 190 * int(percent) / 100}
            if option.key == '+':
                detail['yes'] = True
            if option.key == '-':
                detail['no'] = True
            if option.key in ('0', 'P'):
                detail['hide_if_empty'] = True
            details.append(detail)

        party_counts = [total_party_stats[x] for x in all_parties]
        
        # sort options by well-known keys, then by total number of votes
        option_sort_order = {"+":0, "-":1, "P":2, "0":3}
        details.sort(key = lambda d : (option_sort_order.get(d['option'].key, None), -d['count']))
        
        # hide Present/Not Voting if no one voted that way
        details = [d for d in details if d["count"] > 0 or "hide_if_empty" not in d]

        totals = {'options': details, 'total_count': total_count,
                'party_counts': party_counts, 'parties': all_parties,
                }
        self._cached_totals = totals
        return totals

    def summary(self):
        return self.result + " " + str(self.total_plus) + "/" + str(self.total_minus)
        
    def get_options(self):
        """The options available for the voters of this vote. Returned as key/value pairs. The keys correspond to the voter data, and the values are the display text for this option ('aye', 'nay', 'yea', 'no', etc.)"""
        return dict((opt.key, opt.value) for opt in self.options.all())
    def get_voters(self):
        """The way the voters voted in this vote."""
        return [
            { "person": v.person_id, "value": v.option.key } if v.voter_type_is_member else
            { "vice_president": True, "value": v.option.key }
            for v in Voter.objects.filter(vote=self)
        ]

    @staticmethod
    def AllVotesFeed():
        from events.models import Feed
        return Feed.get_noarg_feed("misc:allvotes")
      
    def create_event(self):
        if self.congress < 111: return # not interested, creates too much useless data and slow to load
        from events.models import Feed, Event
        with Event.update(self) as E:
            E.add("vote", self.created, Vote.AllVotesFeed())
            for v in self.voters.all():
                if v.person_id:
                    E.add("vote", self.created, v.person.get_feed("pv"))
    
    def render_event(self, eventid, feeds):
        if feeds:
            from person.models import Person
            my_reps = set()
            for f in feeds:
                try:
                    my_reps.add(Person.from_feed(f))
                except ValueError:
                    pass # not a person-related feed
            my_reps = sorted(my_reps, key = lambda p : p.sortname)
        else:
            my_reps = []
        
        return {
            "type": "Vote",
            "date": self.created,
            "title": self.question,
            "url": self.get_absolute_url(),
            "body_text_template":
"""{{summary|safe}}
{% for voter in voters %}{{voter.name|safe}}: {{voter.vote|safe}}
{% endfor %}""",
            "body_html_template":
"""<p>{{summary}}</p>
{% for voter in voters %}
    <p><a href="{{SITE_ROOT}}{{voter.url}}">{{voter.name}}</a>: {{voter.vote}}</p>
{% endfor %}
""",
            "context": {
                "summary": self.summary(),
                "voters":
                            [
                                { "url": p.get_absolute_url(), "name": p.name_lastonly(), "vote": self.voters.get(person=p).option.value }
                                for p in my_reps if self.voters.filter(person=p).exists()
                            ]
                        if feeds != None else []
                }
            }
            

class VoteOption(models.Model):
    vote = models.ForeignKey('vote.Vote', related_name='options')
    key = models.CharField(max_length=20)
    value = models.CharField(max_length=255)

    def __unicode__(self):
        return self.value
        
    @property
    def alpha_key(self):
        if self.key == "+": return "positive"
        if self.key == "-": return "negative"
        if self.key == "0": return "absent"
        if self.key == "present": return "present"
        return "other"

class Voter(models.Model):
    """How people voted on roll call votes in the U.S. Congress since 1789. See the Vote API. Filter on the vote field to get the results of a particular vote."""
	
    vote = models.ForeignKey('vote.Vote', related_name='voters', help_text="The vote that this record is a part of.")
    person = models.ForeignKey('person.Person', blank=True, null=True, on_delete=models.PROTECT, related_name='votes', help_text="The person who cast this vote. May be null if the information could not be determined.")
    voter_type = models.IntegerField(choices=VoterType, help_text="Whether the voter was a Member of Congress or the Vice President.")
    option = models.ForeignKey('vote.VoteOption', help_text="How the person voted.")
    created = models.DateTimeField(db_index=True, help_text="The date (and in recent history also time) on which the vote was held.") # equal to vote.created
    
    api_recurse_on = ('vote', 'person', 'option')
    api_example_parameters = { "sort": "-created" }
    api_filter_if = { "option__key": ["person"] }
    
    def __unicode__(self):
        return u'%s /%s/ %s' % (unicode(self.person), self.option.key, unicode(self.vote))
        
    def voter_type_is_member(self):
        return self.voter_type == VoterType.member
        
    def get_option_key(self):
        """Returns the way this person voted. The value corresponds to the key of an option on the vote object."""
        return self.option.key
        
    def person_name(self):
        """The name of the voter."""
        return self.person.name if self.person else None
    
    def get_vote_name(self):
        return self.vote.name()

# Feeds
from events.models import Feed
Feed.register_feed(
    "misc:allvotes",
    title = "Roll Call Votes",
    link = "/congress/votes",
    simple = True,
    single_event_type = True,
    sort_order = 101,
    category = "federal-votes",
    description = "You will get an alert for every roll call vote in Congress.",
    )

########NEW FILE########
__FILENAME__ = search
from datetime import datetime

from django import forms
from django.contrib.humanize.templatetags.humanize import ordinal
from django.utils.html import conditional_escape
from django.utils.safestring import mark_safe

from smartsearch.manager import SearchManager

from vote.models import Vote, CongressChamber, VoteCategory
from us import get_all_sessions

def sort_filter(qs, form):
    sort = form['sort']
    if sort != []:
        if sort[0] == "date":
            qs = qs.extra(order_by=["-created"])
        if sort[0] == "spread":
            qs = qs.extra(order_by=["total_plus-total_minus"])
    return qs

def session_filter(qs, form):
	session_index = form["session"]
	if session_index != None:
		s = get_all_sessions()[int(session_index)]
		qs = qs.filter(congress=s[0], session=s[1])
	return qs
	
def vote_search_manager():
    sm = SearchManager(Vote, qs=Vote.objects.order_by('-created'))
    
    # show sessions as year+session for non-year-based sessions,
    # and then just the session number (the year) for year-based
    # sessions.
    def format_session(s):
    	if s[0] >= 77:
    		 # year and congress number in parens
    		return s[1] + " (" + ordinal(s[0]) + " Congress)"
    	else:
    		# date range and congress number in parens
    		if s[2].year == s[3].year:
				# strftime requires year>=1900, so fool it for generating
				# month names by replacing old years with 1900
				if s[2].month == s[3].month:
					return str(s[2].year) + " " + s[2].replace(1900).strftime("%b") + " (" + ordinal(s[0]) + " Congress)"
				else:
					return str(s[2].year) + " " + s[2].replace(1900).strftime("%b-") + s[3].replace(1900).strftime("%b") + " (" + ordinal(s[0]) + " Congress)"
    		else:
    			return str(s[2].year) + "-" + str(s[3].year) + " (" + ordinal(s[0]) + " Congress)"
    	
    session_choices = reversed([(i, format_session(cs)) for (i,cs) in enumerate(get_all_sessions()) if cs[2] <= datetime.now().date()])
    
    sm.add_option('session', type="select", choices=session_choices, filter=session_filter, help="Note: Even-year sessions extend a few days into the next year.")
    sm.add_option('chamber')
    sm.add_option('category')
    
    #def safe_strftime(date, format):
    #    return date.replace(year=3456).strftime(format).replace("3456", str(date.year)).replace(" 12:00AM", "")

    sm.set_template("""
    	<div><a href="{{object.get_absolute_url}}">{{object.question|truncatewords_html:50}}</a></div>
		{% if object.question_details %}<div>{{object.question_details}}</div>{% endif %}
		<div>{{object.name}}</div>
		<div>{{object.created|date}} {{object.created|time|cut:"midnight"}}</div>
    	<div>{{object.summary}}</div>
	""")

    return sm

########NEW FILE########
__FILENAME__ = vote_tags
from django import template

register = template.Library()


########NEW FILE########
__FILENAME__ = tests
from datetime import datetime

from django.test import TestCase

from vote.models import Vote, CongressChamber, VoteSource

class VoteTestCase(TestCase):
    def test_category(self):
        # Check that <category> value which is not
        # listed in VoteCategory enum
        # does not confuse Django ORM

        vote = Vote(congress=2011, session='2011',
                    chamber=CongressChamber.senate,
                    number=10,
                    source=VoteSource.random_value(),
                    created=datetime.now(),
                    vote_type='asdf',
                    category='zzz',
                    question='asdf',
                    required='asdf',
                    result='asdf')
        vote.save()

        self.assertEqual(vote.category, u'zzz')
        self.assertEqual(vote.get_category_display(), u'zzz')

########NEW FILE########
__FILENAME__ = urls
# -*- coding: utf-8 -*-
from django.conf.urls import *

urlpatterns = patterns('vote.views',
    url('^votes$', 'vote_list', name='vote_list'),
    url('^votes/(\d+)-(\w+)/(h|s)(\d+)$', 'vote_details', name='vote_details'),
    url('^votes/(\d+)-(\w+)/(h|s)(\d+)/export/csv$', 'vote_export_csv', name='vote_export_csv'),
    url('^votes/(\d+)-(\w+)/(h|s)(\d+)/export/xml$', 'vote_export_xml', name='vote_export_xml'),
    url('^votes/(\d+)-(\w+)/(h|s)(\d+)/(diagram|thumbnail)$', 'vote_thumbnail_image', name='vote_thumbnail_image'),
    url('^votes/check_thumbnails', 'vote_check_thumbnails'),
)

########NEW FILE########
__FILENAME__ = views
# -*- coding: utf-8 -*-
import csv
from StringIO import StringIO
from datetime import datetime

from django.http import HttpResponse, Http404
from django.shortcuts import redirect, get_object_or_404, render_to_response
from django.template import RequestContext
from django.core.urlresolvers import reverse
from django.views.decorators.cache import cache_page

from common.decorators import render_to

from numpy import median

from vote.models import Vote, CongressChamber, VoterType, VoteCategory
from vote.search import vote_search_manager
from events.models import Feed
from person.util import load_roles_at_date
from us import get_all_sessions

from twostream.decorators import anonymous_view

from settings import CURRENT_CONGRESS

ideology_scores = { }

@anonymous_view
def vote_list(request):
    # Get the default session to show. We may have sessions listed that are
    # in the future, during a transition, so take the most recent that at
    # least has started.
    default_session = None
    for i, (cn, sn, sd, ed) in reversed(list(enumerate(get_all_sessions()))):
        if sd > datetime.now().date(): continue
        if not Vote.objects.filter(congress=cn, session=sn).exists(): continue
        default_session = i
        break
    
    return vote_search_manager().view(request, "vote/vote_list.html",
        defaults = { "session": default_session },
        paginate = lambda form : "session" not in form, # people like to see all votes for a year on one page
        context = { "feed": Feed(feedname="misc:allvotes") })

def load_vote(congress, session, chamber_code, number):
    """
    Helper utility to get `Vote` instance by arguments
    provided in the request.
    """

    if chamber_code == 'h':
        chamber = CongressChamber.house
    else:
        chamber = CongressChamber.senate
    return get_object_or_404(Vote, congress=congress, session=session,
                             chamber=chamber, number=number)

@anonymous_view
@render_to('vote/vote_details.html')
def vote_details(request, congress, session, chamber_code, number):
    vote = load_vote(congress, session, chamber_code, number)
    voters = list(vote.voters.all().select_related('person', 'option'))
    load_roles_at_date([x.person for x in voters if x.person != None], vote.created)
    
    # load the role for the VP, since load_roles_at_date only loads
    # MoC roles
    has_vp_vote = False
    for voter in voters:
        if voter.voter_type == VoterType.vice_president:
            from person.types import RoleType
            has_vp_vote = True
            try:
                voter.person.role = voter.person.roles.get(role_type=RoleType.vicepresident, startdate__lte=vote.created, enddate__gte=vote.created)
            except:
                raise
                pass # wahtever
    
    # Test if we have a diagram for this vote. The only
    # way to test is to try to make it.
    try:
        vote_thumbnail_image(request, congress, session, chamber_code, number, "diagram")
        has_diagram = True
    except Http404:
        has_diagram = False
    
    # sorting by party actually sorts by party first and by ideology score
    # second.
    congress = int(congress)
    global ideology_scores
    load_ideology_scores(congress)
    if ideology_scores[congress]:
        for voter in voters:
            voter.ideolog_score = ideology_scores[congress].get(
            	voter.person.id if voter.person else 0,
            	ideology_scores[congress].get("MEDIAN:" + (voter.person.role.party if voter.person and voter.person.role else ""),
            		ideology_scores[congress]["MEDIAN"]))
        
    # perform an initial sort for display
    voters.sort(key = lambda x : (x.option.key, x.person.role.party if x.person and x.person.role else "", x.person.name_no_details_lastfirst if x.person else x.get_voter_type_display()))
    
    return {'vote': vote,
            'voters': voters,
            'CongressChamber': CongressChamber,
            "VoterType": VoterType,
            "VoteCategory": VoteCategory._items,
            'has_vp_vote': has_vp_vote,
            'has_diagram': has_diagram,
            }

def load_ideology_scores(congress):
    global ideology_scores
    if congress in ideology_scores: return
    ideology_scores[congress] = { }
    for ch in ('h', 's'):
        try:
            scores_by_party = { }
            for ideolog in csv.reader(open("data/us/%d/stats/sponsorshipanalysis_%s.txt" % (congress, ch))):
                if ideolog[0] == "ID": continue # header row
                if float(ideolog[2]) <  .1: continue # very low leadership score, ideology is not reliable
                ideology_scores[congress][int(ideolog[0])] = float(ideolog[1])
                scores_by_party.setdefault(ideolog[4].strip(), []).append(float(ideolog[1]))
            ideology_scores[congress]["MEDIAN"] = median(ideology_scores[congress].values())
            for party in scores_by_party:
                ideology_scores[congress]["MEDIAN:"+party] = median(scores_by_party[party])
        except IOError:
            ideology_scores[congress] = None

@anonymous_view
def vote_export_csv(request, congress, session, chamber_code, number):
    vote = load_vote(congress, session, chamber_code, number)
    voters = vote.voters.all().select_related('person', 'option')
    load_roles_at_date([x.person for x in voters if x.person], vote.created)

    outfile = StringIO()
    writer = csv.writer(outfile)
    for voter in voters:
        writer.writerow([
            voter.person.pk if voter.person else "--",
            voter.person.role.state if voter.person and voter.person.role else "--",
            voter.person.role.district if voter.person and voter.person.role else "--",
            voter.option.value,
            voter.person.name_no_district().encode('utf-8') if voter.person else voter.get_voter_type_display(),
            voter.person.role.party if voter.person and voter.person.role else "--",])
    output = outfile.getvalue()
    firstline = '%s Vote #%d %s - %s\n' % (vote.get_chamber_display(), vote.number,
                                         vote.created.isoformat(), vote.question) # strftime doesn't work on dates before 1900
    firstline = firstline.encode('utf-8')
    r = HttpResponse(firstline + output, content_type='text/csv')
    r['Content-Disposition'] = 'attachment; filename=' + vote.get_absolute_url()[1:].replace("/", "_") + ".csv"
    return r


@anonymous_view
def vote_export_xml(request, congress, session, chamber_code, number):
    vote = load_vote(congress, session, chamber_code, number)
    fobj = open('data/us/%s/rolls/%s%s-%s.xml' % (congress, chamber_code, session, number))
    return HttpResponse(fobj, content_type='text/xml')
    
@anonymous_view
@cache_page(60 * 60 * 6)
def vote_thumbnail_image(request, congress, session, chamber_code, number, image_type):
	vote = load_vote(congress, session, chamber_code, number)
	
	import cairo, re, math
	from StringIO import StringIO
	
	# general image properties
	font_face = "DejaVu Serif Condensed"
	image_width = 300
	image_height = 250 if image_type == "thumbnail" else 170
	
	# format text to print on the image
	vote_title = re.sub(r"^On the Motion to ", "To ", vote.question)
	if re.match(r"Cloture .*Rejected", vote.result):
		vote_result_2 = "Filibustered"
	elif re.match(r"Cloture .*Agreed to", vote.result):
		vote_result_2 = "Proceed"
	else:
		vote_result_2 = re.sub("^(Bill|Amendment|Resolution|Conference Report|Nomination|Motion|Motion to \S+) ", "", vote.result)
	if vote_result_2 == "unknown": vote_result_2 = ""
	vote_date = vote.created.strftime("%x") if vote.created.year > 1900 else vote.created.isoformat().split("T")[0]
	vote_citation = vote.get_chamber_display() + " Vote #" + str(vote.number) + " -- " + vote_date
	
	# get vote totals by option and by party
	totals = vote.totals()
	total_count = 0
	total_counts = { } # key: total ({ "+": 123 }, etc.)
	yea_counts_by_party = [0,0,0] # D, I, R (+ votes totals)
	nay_counts_by_party = [0,0,0] # D, I, R (+/- votes totals)
	nonvoting_members_totals = [0,0,0] # D, I, R
	party_index = { "Democrat": 0, "Republican": 2 }
	for opt in totals["options"]:
		total_counts[opt["option"].key] = opt["count"]
		for i in xrange(len(totals["parties"])):
			j = party_index.get(totals["parties"][i], 1)
			if opt["option"].key not in ("+", "-"):
				# most votes are by proportion of those voting (not some cloture etc.),
				# so put present/not-voting tallies in a separate group
				nonvoting_members_totals[j] += opt["party_counts"][i]["count"]
				continue 
			total_count += opt["party_counts"][i]["count"]
			if opt["option"].key == "+":
				yea_counts_by_party[j] += opt["party_counts"][i]["count"]
			else:
				nay_counts_by_party[j] += opt["party_counts"][i]["count"]
	if total_count == 0 or "+" not in total_counts or "-" not in total_counts: raise Http404() # no thumbnail for other sorts of votes
	vote_result_1 = "%d-%d" % (total_counts["+"], total_counts["-"])
	
	def show_text_centered(ctx, text, max_width=None):
		while True:
			(x_bearing, y_bearing, width, height, x_advance, y_advance) = ctx.text_extents(text)
			if max_width is not None and width > max_width:
				text2 = re.sub(r" \S+(\.\.\.)?$", "...", text)
				if text2 != text:
					text = text2
					continue
			break
			
		ctx.rel_move_to(-width/2, height)
		ctx.show_text(text)
	
	im = cairo.ImageSurface(cairo.FORMAT_ARGB32, image_width, image_height)
	ctx = cairo.Context(im)
	
	ctx.select_font_face(font_face, cairo.FONT_SLANT_NORMAL, cairo.FONT_WEIGHT_BOLD)
	
	# clear background
	ctx.set_source_rgb(1,1,1)
	ctx.new_path()
	ctx.line_to(0, 0)
	ctx.line_to(image_width, 0)
	ctx.line_to(image_width, image_height)
	ctx.line_to(0, image_height)
	ctx.fill()
	
	chart_top = 0
	if image_type == "thumbnail":
		# Title
		ctx.set_font_size(20)
		ctx.set_source_rgb(.2,.2,.2)
		ctx.move_to(150,10)
		show_text_centered(ctx, vote_title, max_width=.95*image_width)
		chart_top = 50
	
	# Vote Tally
	font_size = 26 if len(vote_result_2) < 10 else 22
	ctx.set_font_size(font_size)
	ctx.set_source_rgb(.1, .1, .1)
	ctx.move_to(150,chart_top)
	show_text_centered(ctx, vote_result_1)
	
	# Vote Result
	ctx.move_to(150,chart_top+12+font_size)
	show_text_centered(ctx, vote_result_2) 
	w = max(ctx.text_extents(vote_result_1)[2], ctx.text_extents(vote_result_2)[2])
	
	# Line
	ctx.set_line_width(1)
	ctx.new_path()
	ctx.line_to(150-w/2, chart_top+5+font_size)
	ctx.rel_line_to(w, 0)
	ctx.stroke()
	
	if image_type == "thumbnail":
		# Vote Chamber/Date/Number
		ctx.select_font_face(font_face, cairo.FONT_SLANT_NORMAL, cairo.FONT_WEIGHT_NORMAL)
		ctx.set_font_size(14)
		ctx.move_to(150,image_height-25)
		show_text_centered(ctx, vote_citation, max_width=.98*image_width) 
	
	# Seats
	
	# Construct an array of rows of seats, where each entry maps to a particular
	# voter.
	
	# How many rows of seats? That is hard coded by chamber.
	seating_rows = 8 if vote.chamber == CongressChamber.house else 4
		# 4 for Senate (http://www.senate.gov/artandhistory/art/special/Desks/chambermap.cfm)
		# about 8 for the House
		
	# Long ago Congress had very few people.
	seating_rows = min(total_count / 8 + 1, seating_rows)
		
	# Determine the seating chart dimensions: the radius of the inside row of
	# seats and the radius of the outside row of seats.
	inner_r = w/2 * 1.25 + 5 # wrap closely around the text in the middle
	if seating_rows <= 4: inner_r = max(inner_r, 75) # don't make the inner radius too small
	outer_r = image_width * .45 # end close to the image width
	
	# If we assume the absolute spacing of seats is constant from row to row, then
	# the number of seats per row grows linearly with the radius, following the
	# circumference. If s0 is the number of seats on the inner row, then
	# floor(s0 * outer_r/inner_r) is the number of seats on the outer row. The total
	# number of seats is found by the sum of the arithmetic sequence (n/2 * (a_1+a_n)):
	#  n = (seating_rows/2)*(s0 + s0*outer_r/inner_r)
	# We want exactly total_count seats, so solving for s0...
	seats_per_row = 2.0 * total_count / (seating_rows*(1.0 + outer_r/inner_r))

	# How wide to draw a seat?
	seat_size = min(.8 * (outer_r-inner_r) / seating_rows, .35 * (2*3.14159*inner_r) / seats_per_row)

	# Determine how many seats on each row.
	seats_so_far = 0
	rowcounts = []
	for row in xrange(seating_rows):
		# What's the radius of this row?
		if seating_rows > 1:
			r = inner_r + (outer_r-inner_r) * row / float(seating_rows-1)
		else:
			r = inner_r
		
		# How many seats should we put on this row?
		if row < seating_rows-1:
			# Start with seats_per_row on the inner row and grow linearly.
			# Round to an integer. Alternate rounding down and up.
			n_seats = seats_per_row * r/inner_r
			n_seats = int(math.floor(n_seats) if (row % 2 == 0) else math.ceil(n_seats))
		else:
			# On the outermost row, just put in how many left we need
			# so we always have exactly the right number of seats.
			n_seats = total_count - seats_so_far
		
		rowcounts.append(n_seats)
		seats_so_far += n_seats
		
	# Make a list of all of the seats as a list of tuples of the
	# form (rownum, seatnum) where seatnum is an index from the
	# left side.
	seats = []
	for row, count in enumerate(rowcounts):
		for i in xrange(count):
			seats.append( (row, i) )
			
	# Sort the seats in the order we will fill them from left to right,
	# bottom to top.
	seats.sort(key = lambda seat : (seat[1]/float(rowcounts[seat[0]]), -seat[0]) )
	
	# We can draw in two modes. In one mode, we don't care which actual
	# person corresponds to which seat. We just draw the groups of voters
	# in blocks. Or we can draw the actual people in seats we assign
	# according to their ideology score, from left to right.

    # See if we have ideology scores.
	voter_details = None
	if True:
		global ideology_scores
		load_ideology_scores(vote.congress)
		if ideology_scores[vote.congress]:
			voter_details = [ ]
			
			# Load the voters, getting their role at the time they voted.
			voters = list(vote.voters.all().select_related('person', 'option'))
			load_roles_at_date([x.person for x in voters if x.person != None], vote.created)
			
			# Store ideology scores
			for voter in voters:
				if voter.option.key not in ("+", "-"): continue
				party = party_index.get(voter.person.role.party if voter.person and voter.person.role else "Unknown", 1)
				option = 0 if voter.option.key == "+" else 1
				coord =  ideology_scores[vote.congress].get(voter.person.id if voter.person else "UNKNOWN",
					ideology_scores[vote.congress].get("MEDIAN:" + (voter.person.role.party if voter.person and voter.person.role else ""),
						ideology_scores[vote.congress]["MEDIAN"]))
				voter_details.append( (coord, (party, option)) )
				
			# Sort voters by party, then by ideology score, then by vote.
			voter_details.sort(key = lambda x : (x[1][0], x[0], x[1][1]))
			
			if len(voter_details) != len(seats):
				raise ValueError("Gotta check this.")
				voter_details = None # abort
			
	if not voter_details:
		# Just assign voters to seats in blocks.
		#
		# We're fill the seats from left to right different groups of voters:
		#   D+, D-, I+, I-, R-, R+
		# For each group, for each voter in the group, pop off a seat and
		# draw him in that seat.
	
		# for each group of voters...
		seat_idx = 0
		for (party, vote) in [ (0, 0), (0, 1), (1, 0), (1, 1), (2, 1), (2, 0) ]:
			# how many votes in this group?
			n_voters = (yea_counts_by_party if vote == 0 else nay_counts_by_party)[party]
			# for each voter...
			for i in xrange(n_voters):
				seats[seat_idx] = (seats[seat_idx], (party, vote)) 
				seat_idx += 1
	
	else:
		# Assign voters to seats in order.
		for i in xrange(len(voter_details)):
			seats[i] = (seats[i], voter_details[i][1])

	# Draw the seats.
	
	group_colors = {
		(0, 0): (0.05, 0.24, 0.63), # D+
		(0, 1): (0.85, 0.85, 1.0), # D-
		(1, 0): (0.07, 0.05, 0.07), # I+
		(1, 1): (0.85, 0.85, 0.85), # I-
		(2, 0): (0.90, 0.05, 0.07), # R+
		(2, 1): (1.0, 0.85, 0.85), # R-
	}
	
	for ((row, seat_pos), (party, vote)) in seats:	
		# radius of this row (again, code dup)
		if seating_rows > 1:
			r = inner_r + (outer_r-inner_r) * row / float(seating_rows-1)
		else:
			r = inner_r
		
		# draw
		ctx.set_source_rgb(*group_colors[(party, vote)])
		ctx.identity_matrix()
		ctx.translate(image_width/2, chart_top+25)
		ctx.rotate(3.14159 - 3.14159 * seat_pos/float(rowcounts[row]-1))
		ctx.translate(r, 0)
		ctx.rectangle(-seat_size/2, -seat_size/2, seat_size, seat_size)
		ctx.fill()

	# Convert the image buffer to raw PNG bytes.
	buf = StringIO()
	im.write_to_png(buf)
	v = buf.getvalue()
	
	# Form the response.
	r = HttpResponse(v, content_type='image/png')
	r["Content-Length"] = len(v)
	return r

@anonymous_view
def vote_check_thumbnails(request):
    votes = Vote.objects.filter(congress=CURRENT_CONGRESS)\
        .order_by("congress", "session", "chamber", "number")
    ret = ""
    for v in votes:
        ret += """<div><a href="%s"><img src="%s" style="border: 1px solid #777"/></a></div>\n""" % (v.get_absolute_url(), v.get_absolute_url() + "/thumbnail")
    return HttpResponse(ret, content_type='text/html')
	
import django.contrib.sitemaps
class sitemap_current(django.contrib.sitemaps.Sitemap):
    changefreq = "yearly"
    priority = 1.0
    def items(self):
        return Vote.objects.filter(congress=CURRENT_CONGRESS)
class sitemap_archive(django.contrib.sitemaps.Sitemap):
    index_levels = ['congress', 'session', 'chamber']
    changefreq = "yearly"
    priority = 0.25
    def items(self):
        return Vote.objects.filter(congress__lt=CURRENT_CONGRESS)
    

########NEW FILE########
__FILENAME__ = admin
# -*- coding: utf-8

from django.contrib import admin
from website.models import *

class UserProfileAdmin(admin.ModelAdmin):
    list_display = ['user']
    search_fields = ['user__username', 'user__email']
    readonly_fields = ['user']

admin.site.register(UserProfile, UserProfileAdmin)


########NEW FILE########
__FILENAME__ = api
from django.core.serializers import json as django_json
from django.conf import settings
from tastypie.serializers import Serializer
from tastypie.resources import ModelResource
from tastypie.api import Api
from tastypie import fields
from tastypie.constants import ALL, ALL_WITH_RELATIONS

from common import enum as enummodule

import csv, json, StringIO

from twostream.decorators import anonymous_view

class MySerializer(Serializer):
    def __init__(self, *args, **kwargs):
        Serializer.__init__(self, *args, **kwargs)
        self.formats += ['csv', 'debug_sql']
        self.content_types['csv'] = 'text/csv'
        self.content_types['debug_sql'] = 'text/plain'
    
	# Make JSON output pretty.
    json_indent = 2
    def to_json(self, data, options=None):
        options = options or {}
        data = self.to_simple(data, options)
        return json.dumps(data, cls=django_json.DjangoJSONEncoder,
                sort_keys=True, ensure_ascii=False, indent=self.json_indent)

    # CSV outputter.
    def to_csv(self, data, options=None):
        options = options or {}
        data = self.to_simple(data, options)
        
        data = data.get("objects", [])
        
        # get an (ordered) list of column names from top-level keys, if
        # not specified
        if "columns" in options:
            # This doesn't work. options doesn't seem to have the
            # query string arguments.
            columns = options["columns"].split(",")
        else:
            # Recursively find all keys in the object, making keys like
            # a__b when we dive into dicts within dicts.
            def get_keys(obj, prefix):
                ret = []
                for key in obj.keys():
                    if not isinstance(obj[key], dict):
                        ret.append(prefix + key)
                    else:
                        for inkey in get_keys(obj[key], prefix + key + "__"):
                            ret.append(inkey)
                return ret
            columns = []
            for item in data:
                for key in get_keys(item, ""):
                    if key not in columns:
                        columns.append(key)
            columns.sort()
                    
        # write CSV to buffer
        raw_data = StringIO.StringIO()
        writer = csv.writer(raw_data)
        writer.writerow(columns)
        def get_value_recursively(item, key):
            for k in key.split("__"):
                if not isinstance(item, dict): return None
                item = item.get(k, None)
            return item
        def format_value(v):
            if v != None: v = unicode(v).encode("utf8")
            return v
        for item in data:
            if not isinstance(item, dict): continue
            writer.writerow([format_value(get_value_recursively(item, c)) for c in columns])
            
        return raw_data.getvalue()

    def to_debug_sql(self, data, options=None):
        ret = StringIO.StringIO()
        ret.write("connection\ttime\tquery\n")
        from django.db import connections
        for con in connections:
            for q in connections[con].queries:
                ret.write("%s\t%s\t%s\n" % (con, q["time"], q["sql"]))
        return ret.getvalue()
    	
class GBaseModel(ModelResource):
	
	# Base options.
	class BaseMeta:
		allowed_methods = ['get']
		serializer = MySerializer()
		
	def determine_format(self, request):
		# Make JSON the default output format if not specified.
		if not hasattr(request, 'format') and "format" not in request.GET:
			return "application/json"
		return super(GBaseModel, self).determine_format(request)
	
	def find_field(self, path):
		from tastypie.fields import RelatedField
		if len(path) == 0: raise ValueError("No field specified.") 
		if not path[0] in self.fields: return None, None #raise ValueError("Invalid field '%s' on model '%s'." % (path[0], self.Meta.queryset.model))
		field = self.fields[path[0]]
		if len(path) == 1:
			return (self, field.attribute)
		if not isinstance(field, RelatedField):
			return None, None
			#raise ValueError("Trying to span a relationship that cannot be spanned ('%s')." % (path[0] + LOOKUP_SEP + path[1]))
		if not isinstance(field.to_class(), GBaseModel):
			return None, None
		return field.to_class().find_field(path[1:]) 
	
	@staticmethod
	def is_enum(obj):
		import inspect
		return inspect.isclass(obj) and issubclass(obj, enummodule.Enum)
	
	def build_filters(self, filters=None):
		if not filters: return { }
		# Replace enumeration keys with the right values.
		from django.db.models.sql.constants import QUERY_TERMS
		LOOKUP_SEP = "__"
		f = { }
		for k, v in filters.items():
			path = k.split(LOOKUP_SEP)
			if len(path) and path[-1] in QUERY_TERMS: path.pop()
			model, field = self.find_field(path)
			if model:
				enum = model.Meta.queryset.model._meta.get_field(field).choices
				if GBaseModel.is_enum(enum):
					v = int(enum.by_key(v))
			f[k] = v
		return super(GBaseModel, self).build_filters(filters=f)
	
	def dehydrate(self, bundle):
		# Add additional properties.
		for name, attr in getattr(self.__class__.Meta, "additional_properties", {}).items():
			if callable(attr):
				val = attr(bundle.obj)
			else:
				val = getattr(bundle.obj, attr)
				if callable(val): val = val()
			bundle.data[name] = val
		
		# Replace integer values with their enumeration keys.
		for field in list(bundle.data): # clone the keys before we change the dict
			try:
				enum = self.Meta.queryset.model._meta.get_field(self.fields[field].attribute).choices
				if GBaseModel.is_enum(enum):
					val = enum.by_value(bundle.data[field])
					bundle.data[field] = val.key
					bundle.data[field + "_label"] = val.label
			except:
				# Entry does not correspond to a field with choices.
				pass
		return bundle

	def build_schema(self):
		# Add enumeration values to schema output.
		model = self.Meta.queryset.model
		schema = super(GBaseModel, self).build_schema()
		for field, info in schema["fields"].items():
			try:
				enum = model._meta.get_field(field).choices
				if issubclass(enum, enummodule.Enum):
					info["enum_values"] = dict((v.key, { "label": v.label, "description": getattr(v, "search_help_text", None) } ) for v in enum.values())
			except:
				# Entry does not correspond to a field with choices.
				pass
			
		# Add additional properties fields.
		for name, attr in getattr(self.Meta, "additional_properties", {}).items():
			if not callable(attr):
				val = getattr(model, attr)
				if callable(val) or isinstance(val, property):
					schema["fields"][name] = {
						"help_text": getattr(val, "__doc__", None) 
					}
					
		if "link" in getattr(self.Meta, "additional_properties", {}):
			schema["fields"]["link"] = {
				"help_text": "The URL to the corresponding page on www.GovTrack.us for this resource.",
			}
			
		return schema
		
	@classmethod
	def get_docstring(self):
		return self.__doc__

from person.models import Person, PersonRole
class PersonModel(GBaseModel):
	"""Members of Congress and U.S. Presidents since the founding of the nation."""
	
	canonical_example = 400326
	
	class Meta(GBaseModel.BaseMeta):
		queryset = Person.objects.all()
		resource_name = 'person'
		filtering = {
			"firstname": ('exact,'),
			"gender": ALL,
			"lastname": ('exact,'),
			"middlename": ('exact,'),
			"namemod": ('exact,'),
			"nickname": ('exact,'),
			"osid": ALL,
			"pvsid": ALL,
			"twitterid": ('exact,'),
			"youtubeid": ('exact,'),
			"roles": ALL_WITH_RELATIONS,
		}
		additional_properties = {
			"name_no_details": "name_no_details",
			"link": lambda obj : settings.SITE_ROOT_URL + obj.get_absolute_url(),
		}
	roles = fields.ToManyField('website.api.PersonRoleModel', 'roles', help_text="A list of terms in Congress or as President that this person has been elected to. A list of API resources to query for more information.")
	current_role = fields.ToOneField('website.api.PersonRoleModel', 'current_role', null=True, full=True, help_text="The current term in Congress or as President that this person is currently serving, or null if none.")

class PersonModelSimple(PersonModel):
	# Based on the PersonModel, but avoid fields that require another database call.
	class Meta(PersonModel.Meta):
		additional_properties = {
			"link": lambda obj : settings.SITE_ROOT_URL + obj.get_absolute_url(),
		}
		excludes = ["roles", "current_role"]
	
class PersonRoleModel(GBaseModel):
	"""Terms held in office by Members of Congress and U.S. Presidents. Each term corresponds with an election, meaning each term in the House covers two years (one 'Congress'), as President four years, and in the Senate six years (three 'Congresses')."""
	
	class Meta(GBaseModel.BaseMeta):
		queryset = PersonRole.objects.all()
		resource_name = 'role'
		filtering = {
			"current": ALL,
			"district": ALL,
			"enddate": ALL,
			"party": ('exact',),
			"role_type": ALL,
			"senator_class": ALL,
			"startdate": ALL,
			"state": ('exact,'),
		}
		ordering = ['startdate', 'enddate']
		additional_properties = {
			"title": "get_title_abbreviated",
			"title_long": "get_title",
			"description": "get_description",
			"congress_numbers": "congress_numbers",
		}
	
from bill.models import Bill
class BillModel(GBaseModel):
	"""Bills and resolutions in the U.S. Congress since 1973 (the 93rd Congress)."""
	
	canonical_example = 76416
	
	class Meta(GBaseModel.BaseMeta):
		queryset = Bill.objects.all().prefetch_related("sponsor", "sponsor_role")
		resource_name = 'bill'
		filtering = {
			"bill_type": ('exact',),
			"congress": ALL,
			"number": ALL,
			"sponsor": ALL_WITH_RELATIONS,
			"sponsor_role": ALL_WITH_RELATIONS,
			"committees": ALL_WITH_RELATIONS,
			"terms": ALL_WITH_RELATIONS,
			"current_status": ALL,
			"current_status_date": ALL,
			"introduced_date": ALL,
			#"cosponsors": ALL_WITH_RELATIONS,
			"docs_house_gov_postdate": ALL,
			"senate_floor_schedule_postdate": ALL,
		}
		excludes = ["titles", "major_actions"]
		ordering = ['current_status_date', 'introduced_date', 'docs_house_gov_postdate', 'senate_floor_schedule_postdate']
		additional_properties = {
			"link": lambda obj : settings.SITE_ROOT_URL + obj.get_absolute_url(),
			"display_number": "display_number_no_congress_number",
			"title_without_number": "title_no_number",
			"bill_resolution_type": "noun",
			"current_status_description": "current_status_description",
			"is_current": "is_current",
			"is_alive": "is_alive",
			"thomas_link": "thomas_link",
		}
	sponsor = fields.ToOneField('website.api.PersonModelSimple', 'sponsor', null=True, full=True, help_text="The primary sponsor of the bill (optional).")
	sponsor_role = fields.ToOneField('website.api.PersonRoleModel', 'sponsor_role', null=True, full=True, help_text="The role of the primary sponsor of the bill at the time he/she introduced the bill (optional).")
	#cosponsors = fields.ToManyField('website.api.PersonModelSimple', 'cosponsors', help_text="A list of cosponsors of the bill. A list of API resources to query for more information.")
	# missing: terms, committees
 
from bill.models import Cosponsor
class BillCosponsorModel(GBaseModel):
	"""A (bill, person) pair indicating cosponsorship, with join and withdrawn dates."""
	
	canonical_example = 402
	
	class Meta(GBaseModel.BaseMeta):
		queryset = Cosponsor.objects.all().prefetch_related("bill", "person", "role", "bill__sponsor", "bill__sponsor_role")
		resource_name = 'cosponsorship'
		filtering = {
			"bill": ALL_WITH_RELATIONS,
			"cosponsor": ALL_WITH_RELATIONS,
			"cosponsor_role": ALL_WITH_RELATIONS,
		}
	bill = fields.ToOneField('website.api.BillModel', 'bill', full=True, help_text="The bill.")
	cosponsor = fields.ToOneField('website.api.PersonModelSimple', 'person', full=True, help_text="The cosponsor.")
	cosponsor_role = fields.ToOneField('website.api.PersonRoleModel', 'role', full=True, help_text="The role of the cosponsor at the time he/she became a cosponsor of the bill.")

from vote.models import Vote
class VoteModel(GBaseModel):
	"""Roll call votes in the U.S. Congress since 1789. How people voted is accessed through the Vote_voter API."""
	
	canonical_example = 1
	
	class Meta(GBaseModel.BaseMeta):
		queryset = Vote.objects.all().select_related('options')
		resource_name = 'vote'
		filtering = {
			"congress": ALL,
			"session": ALL,
			"chamber": ('exact',),
			"number": ALL,
			"created": ALL,
			"category": ('exact'),
			"related_bill": ALL_WITH_RELATIONS,
		}
		excludes = ["missing_data"]
		ordering = ['created']
		additional_properties = {
			"link": lambda obj : settings.SITE_ROOT_URL + obj.get_absolute_url(),
			"source_link": "get_source_link",
			"options": "get_options",
			#"voters": "get_voters",
		}
	related_bill = fields.ToOneField('website.api.BillModel', 'related_bill', null=True, full=True, help_text="A bill related to this vote (optional, and possibly present even if this is not a vote on the passage of the bill).")

from vote.models import Voter
class VoteVoterModel(GBaseModel):
	"""How people voted on roll call votes in the U.S. Congress since 1789. See the Vote API. Filter on the vote field to get the results of a particular vote."""
	
	canonical_example = 8248474
	
	class Meta(GBaseModel.BaseMeta):
		queryset = Voter.objects.all().select_related('vote', 'person', 'option')
		resource_name = 'vote_voter'
		filtering = {
			"vote": ALL_WITH_RELATIONS,
			"person": ALL_WITH_RELATIONS,
			"option": ('exact',),
			"created": ALL,
		}
		additional_properties = {
			"option": "get_option_key",
			"person_name": "person_name",
			"vote_description": "get_vote_name",
			"link": lambda obj : settings.SITE_ROOT_URL + obj.vote.get_absolute_url(),
		}
		ordering = ['created']
	vote = fields.ToOneField('website.api.VoteModel', 'vote', help_text="The vote that this was a part of.")
	person = fields.ToOneField('website.api.PersonModel', 'person', help_text="The person making this vote.", blank=True, null=True)
	
	def build_filters(self, filters=None):
		# So that we don't have to create a model for the options, we rewrite
		# the output "option" key with the option's... key. To make it filterable,
		# we have to do a rewrite on the other end (this part).
		extra_filters = { }
		if filters and "option" in filters:
			extra_filters["option__key"] = filters["option"]
			del filters["option"]
		orm_filters = super(VoteVoterModel, self).build_filters(filters=filters)
		orm_filters.update(extra_filters)
		return orm_filters

v1_api = Api(api_name='v1')

v1_api.register(PersonModel())
v1_api.register(PersonRoleModel())
v1_api.register(BillModel())
v1_api.register(BillCosponsorModel())
#v1_api.register(VoteModel())
#v1_api.register(VoteVoterModel())

#### V2 ####

from simplegetapi.views import do_api_call, build_api_documentation

def get_apiv2_model_qs(model):
	from django.http import Http404
	
	def get_haystack_query_set(model, connection):
		from haystack.query import SearchQuerySet
		return SearchQuerySet().using(connection).filter(indexed_model_name__in=[model.__name__])
	
	if model == "bill":
		model = Bill
		qs = get_haystack_query_set(model, "bill")
	elif model == "cosponsorship":
		model = Cosponsor
		qs = Cosponsor.objects.all()
	elif model == "person":
		model = Person
		qs = get_haystack_query_set(model, "person")
	elif model == "role":
		model = PersonRole
		qs = PersonRole.objects.all()
	elif model == "vote":
		model = Vote
		qs = Vote.objects.all()
	elif model in ("vote_voter", "voter"):
		model = Voter
		qs = Voter.objects.all()
	elif model in ("committee"):
		from committee.models import Committee
		model = Committee
		qs = Committee.objects.all()
	elif model in ("committee_member"):
		from committee.models import CommitteeMember
		model = CommitteeMember
		qs = CommitteeMember.objects.all()
	else:
		raise Http404()
		
	return model, qs

@anonymous_view	
def apiv2(request, model, id):
	model, qs = get_apiv2_model_qs(model)
	return do_api_call(request, model, qs, id)
	
from django.shortcuts import render_to_response
from django.template import RequestContext

def api_overview(request):
	baseurl = "https://%s/api/v2/" % request.META["HTTP_HOST"]
	
	endpoints = ("bill", "cosponsorship", "person", "role", "vote", "vote_voter", "committee", "committee_member")
	
	api = [ (model, build_api_documentation(*get_apiv2_model_qs(model))) for model in endpoints ]
	
	return render_to_response('website/developers/api.html', {
		"baseurl": baseurl,
		"api": api,
		},
		RequestContext(request))



########NEW FILE########
__FILENAME__ = community-interest
# Scan the CommunityInterest table for communities we should created.

from django.core.management.base import BaseCommand, CommandError
from django.conf import settings
from django.db.models import Count

from optparse import make_option

from bill.models import Bill, RelatedBill
from website.models import CommunityInterest

class Command(BaseCommand):
	args = ''
	help = 'Checks the CommunityInterest table for new communities we should created.'
	
	def handle(self, *args, **options):
		# Get counts by bill, and load the bills in bulk.
		interests = list(CommunityInterest.objects.values('bill').annotate(count=Count('id')))
		bills = Bill.objects.in_bulk(ik['bill'] for ik in interests)
		for ix in interests:
			ix["bills"] = set()
			ix["bills"].add(bills[ix["bill"]])
				
		# Combine related bills.
		interest_index = dict((x["bill"], i) for i, x in enumerate(interests))
		for b in bills.values():
			for rb in b.get_related_bills():
				rb = rb.related_bill
				if rb.id in interest_index:
					n = interests[interest_index[rb.id]]
					m = interests[interest_index[b.id]]
					m = m.get("map_to", m)
					if m == n: continue
					n["map_to"] = m
					m["count"] += n["count"]
					m["bills"].add(rb)
					n["count"] = 0
		

		
		print "Top Bills"
		interests.sort(key = lambda ix : ix["count"], reverse=True)
		for i in xrange(20):
			for b in interests[i]["bills"]:
				print b
			print "\t", len(set(CommunityInterest.objects.filter(bill__in=interests[i]["bills"]).values_list("user", flat=True))), "distinct users"
			methods = { }
			for ci in CommunityInterest.objects.filter(bill__in=interests[i]["bills"]):
				for m in ci.methods.split(","):
					methods[m] = methods.get(m, 0) + 1
			print "\t", methods
			print

########NEW FILE########
__FILENAME__ = import_mandrill_bounce_list
from django.core.management.base import BaseCommand, CommandError
from django.conf import settings
from django.contrib.auth.models import User

from optparse import make_option

from emailverification.models import BouncedEmail, Record as EVRecord

import sys, csv

class Command(BaseCommand):
	help = 'Creates BouncedMail records for a Mandrill delivery report export piped on standard input.'
	
	def handle(self, *args, **options):
		for rec in csv.DictReader(sys.stdin):
			email = rec["Email Address"]
			
			found = False
			
			for u in User.objects.filter(email=email):
				found = True
				print u
				be, is_new = BouncedEmail.objects.get_or_create(user=u)
				if not is_new:
					be.bounces += 1
					be.save()
			
			for r in EVRecord.objects.filter(email=email):
				found = True
				print r
				r.killed = True
				r.save()
				
			if not found:
				print email, "not found"


########NEW FILE########
__FILENAME__ = publish_to_fb_stream
from django.core.management.base import BaseCommand, CommandError
from django.conf import settings

from optparse import make_option

import sys, re, urlparse, urllib

class AppURLopener(urllib.FancyURLopener):
	version = "GovTrack.us scraper" # else Wikipedia gives 403s
urllib._urlopener = AppURLopener()

class Command(BaseCommand):
	args = 'graphid message'
	help = 'Posts a message to a Facebook page stream.'
	
	def handle(self, *args, **options):
		if len(args) != 2:
			print "Missing arguments."
			return

		# Get an access token.
		ret = urllib.urlopen("https://graph.facebook.com/oauth/access_token?" + 
			urllib.urlencode({
			"grant_type": "client_credentials",
			"client_id": settings.FACEBOOK_APP_ID,
			"client_secret": settings.FACEBOOK_APP_SECRET,
		})).read()
		try:
			access_token = urlparse.parse_qs(ret)['access_token'][0]
		except:
			print ret
			return
			
		# Publish to stream.
		print urllib.urlopen("https://graph.facebook.com/%s/feed" % args[0], 
			urllib.urlencode({
			"message": args[1],
			"access_token": access_token,
		})).read()
 
 		

########NEW FILE########
__FILENAME__ = scan_accesslog
# Scan the access log for who is linking to bills and accumulate
# a list of links by bill, and for search term keywords. You'll
# probably run in a cron job using:
#
# tail -200000 ../logs/access_log|./manage.py scan_accesslog 5

from django.core.management.base import BaseCommand, CommandError
from django.conf import settings

from optparse import make_option

import sys, re, urlparse, urllib, lxml, apachelog

from bill.models import Bill, BillType, BillLink

re_bill = re.compile(r"^/congress/bills/(\d\d\d)/([a-z]+)([0-9]+)")

logformat = r'%h %l %u %t \"%r\" %>s %b \"%{Referer}i\" \"%{User-Agent}i\"'

class AppURLopener(urllib.FancyURLopener):
	version = "GovTrack.us scraper" # else Wikipedia gives 403s
urllib._urlopener = AppURLopener()


class Command(BaseCommand):
	args = 'minhits'
	help = 'Scans the Apache access log for referrer information to create BillLink instances. Send recent access log entries to this script by piping it into standard input.'
	
	def handle(self, *args, **options):
		if len(args) != 1:
			print "Missing argument."
			return

		min_count = int(args[0])

		p = apachelog.parser(logformat)
		
		spider = { }
		
		for line in sys.stdin:
			# Parse the acess log line.
			try:
				data = p.parse(line)
			except:
				continue
			
			# Is it a request to a bill page?
			path = data["%r"].split(" ")[1]
			m = re_bill.match(path)
			if not m: continue
			
			# Who is the referrer?
			ref = data["%{Referer}i"]
			if ref in ("", "-") or "govtrack.us" in ref:
				continue
			
			url = urlparse.urlparse(ref)
			hostname = url.hostname
			qs = urlparse.parse_qs(url.query)
			
			if not hostname: continue
			
			# Filter out known useless domains.
			if hostname in ("t.co", "longurl.org", "ow.ly", "bit.ly", "www.facebook.com", "www.weblinkvalidator.com", "static.ak.facebook.com", "info.com", "altavista.com", "tumblr.com", "www.freerepublic.com", "www.reddit.com"): continue
			if hostname.endswith(".ru"): continue
			
			# For referrals from Google, look at the 'q' argument to see how
			# people are searching for this page.
			if hostname.replace("www.", "").replace("search.", "") in ("google.com", "bing.com", "aol.com", "yahoo.com"):
				# todo, some use q= some use query=
				#print qs.get("q", [""])[0]
				continue
				
			# Filter out other domains if the link has a 'q' argument since it's probs
			# a search engine.
			if "q" in qs or "pid" in qs: continue
			
			# Filter out common paths for message boards.
			if "/threads/" in ref or "/forum/" in ref or "viewtopic.php" in ref: continue
				
			key = (m.groups(), url)
			spider[key] = spider.get(key, 0) + 1
			
		###
		
		first_print = True
		
		spider = spider.items()
		spider.sort(key = lambda kv : kv[1])
		for (bill_info, referral_url), count in spider:
			if count < min_count: continue # filter out referrers that occurred too infrequently
			
			bill_type = BillType.by_slug(bill_info[1])
			bill = Bill.objects.get(congress=bill_info[0], bill_type=bill_type, number=bill_info[2])
			
			lnk, is_new = BillLink.objects.get_or_create(
				bill=bill,
				url=referral_url.geturl(),
				defaults={
					"title": "Title Not Set"
				})
			
			# Additional processing for new entries.
			
			if not is_new: continue
			
			try:
				stream = urllib.urlopen(referral_url.geturl())
				if stream.getcode() != 200: continue
				dom = lxml.etree.parse(stream, lxml.etree.HTMLParser())
			except:
				continue
				
			title = dom.xpath('string(head/title)').strip()
			if title == "": continue
			
			# set the title of the scraped page
			lnk.title = title
			
			# white-list some domains, provided we were able to
			# get a title
			if referral_url.hostname in ("en.wikipedia.org", "www.truthorfiction.com", "www.theatlantic.com", "www.snopes.com", "arstechnica.com"):
				lnk.approved = True
			else:
				if first_print:
					print "Links pending approval:"
					print
					first_print = False
				print referral_url.geturl()
				print title.encode("utf8")
				print unicode(bill).encode("utf8")
				print
			
			lnk.save()


########NEW FILE########
__FILENAME__ = send_site_news_email_blast
from django.core.management.base import BaseCommand, CommandError

from django.core.mail import send_mail, EmailMultiAlternatives
from django.template import Context, Template
from django.template.loader import get_template
from django.conf import settings

from optparse import make_option

from django.contrib.auth.models import User
from website.models import UserProfile
from emailverification.models import BouncedEmail

from datetime import datetime, timedelta

class Command(BaseCommand):
	args = 'daily|weekly|all|test|count'
	help = 'Sends out an email blast to users with a site announcement.'
	
	def handle(self, *args, **options):
		if len(args) != 1 or args[0] not in ('daily', 'weekly', 'all', 'test', 'count'):
			print "Specify daily or weekly or all or test or count."
			return
			
		# Load current email blast.
			
		blast = load_blast()
		
		# Definitions for the four groups of users.
			
		user_groups = {
			"test": UserProfile.objects.filter(user__email="jt@occams.info"),
			"all": UserProfile.objects.all(),
			"daily": UserProfile.objects.filter(user__subscription_lists__email=1).distinct(),
			"weekly": UserProfile.objects.filter(user__subscription_lists__email=2).distinct(),
		}
		
		# also require:
		# * the mass email flag is turned
		# * we haven't sent them this blast already
		# * they don't have a BouncedEmail record
		for ug, qs in user_groups.items():
			user_groups[ug] = qs.filter(
				massemail=True,
				last_mass_email__lt=blast["id"])\
				.exclude(user__bounced_emails__id__gt=0)
			
		if args[0] == "count":
			# Just print counts by group and exit.
			for ug, qs in user_groups.items():
				print ug, qs.count()
			return
			
		# Get the list of user IDs.
			
		users = list(user_groups[args[0]].order_by("user__id").values_list("user", flat=True))
		
		print "Sending to ", args[0], len(users)
			
		total_emails_sent = 0
		for userid in users:
			if send_blast(userid, blast):
				total_emails_sent += 1
			
			from django import db
			db.reset_queries()
			
		print "sent", total_emails_sent, "emails"

	
def load_blast():
	# get the email's From: header and return path
	emailfromaddr = getattr(settings, 'EMAIL_UPDATES_FROMADDR',
			getattr(settings, 'SERVER_EMAIL', 'no.reply@example.com'))
		
	# get plain text, HTML, and metadata for the blast
	from events.management.commands.send_email_updates import load_markdown_content
	content = load_markdown_content("website/email/blast.md", "utm_campaign=govtrack_email_blast&utm_source=govtrack/email_blast&utm_medium=email")

	# put the HTML inside a master layout

	ctx = Context({ })
	ctx.update({ "body": content["body_html"] })

	templ_html_wrapper = get_template("website/email/blast.html")
	body_html = templ_html_wrapper.render(ctx)

	content["from"] = emailfromaddr
	return content
	
def send_blast(user_id, blast):
	user = User.objects.get(id=user_id)

	emailreturnpath = blast["from"]
	if hasattr(settings, 'EMAIL_UPDATES_RETURN_PATH'):
		emailreturnpath = (settings.EMAIL_UPDATES_RETURN_PATH % user.id)

	email = EmailMultiAlternatives(
		blast["subject"],
		blast["body_text"],
		emailreturnpath,
		[user.email],
		headers = {
			'From': blast["from"]
		}
		)
	email.attach_alternative(blast["body_html"], "text/html")
	
	try:
		print "emailing", user.id, user.email
		email.send(fail_silently=False)
	except Exception as e:
		print user, e
		return False
	
	prof = user.userprofile()
	prof.last_mass_email = blast["id"]
	prof.save()
		
	return True # success


########NEW FILE########
__FILENAME__ = top_tracked_bills
from django.core.management.base import BaseCommand, CommandError
from django.conf import settings
from django.db.models import Count

from events.models import Feed
from bill.models import Bill

import datetime

class Command(BaseCommand):
	args = ''
	help = 'Reports top-tracked bills.'
	
	def handle(self, *args, **options):
		print "tracked by users registered in the last two weeks"
		self.show_stats(True)

		print
		print "tracked by all users"
		self.show_stats(False)
	
	def show_stats(self, recent_users_only):
		# get feeds, across all congresses
		top_bills = Feed.objects\
			.filter(feedname__startswith='bill:')\
			.filter(feedname__regex='^bill:[hs][jcr]?%d-' % settings.CURRENT_CONGRESS)
		if recent_users_only:
			top_bills = top_bills.filter(tracked_in_lists__user__date_joined__gt=datetime.datetime.now()-datetime.timedelta(days=14))
		top_bills = top_bills\
			.annotate(count=Count('tracked_in_lists'))\
			.order_by('-count')\
			.values('feedname', 'count')\
			[0:25]

		print "users \t url \t bill title"
		for bf in top_bills:
			b = Bill.from_feed(Feed.from_name(bf["feedname"]))
			print bf["count"], "\t", b.get_absolute_url(), "\t", b
			

########NEW FILE########
__FILENAME__ = warn_inactive_unsubscribe
from django.contrib.auth.models import User
from django.core.management.base import BaseCommand, CommandError

from django.conf import settings

from optparse import make_option

from events.models import SubscriptionList
from emailverification.utils import send_email_verification

from datetime import datetime, timedelta

class Command(BaseCommand):
	args = '[test|send]'
	help = 'Warn users that have not logged in recently that their email updates will be turned off.'
	
	def handle(self, *args, **options):
		cutoff = (datetime.now()-timedelta(days=365*3)).date().replace(day=1)
		users = SubscriptionList.objects\
			.filter(email__gt=0, user__last_login__lt=cutoff)\
			.exclude(user__ping__pingtime__isnull=False)\
			.values_list("user", "user__email", "user__last_login").distinct()
		
		print "Cutoff:", cutoff.isoformat()
		print "Lists:", users.count()
		print "Emailed since 2.0:", users.exclude(last_event_mailed=None).count()

		if len(args) > 0 and args[0] == "send":
			for user in users:
				axn = UserAction()
				axn.uid = user[0]
				print user
				send_email_verification(user[1], None, axn)

class UserAction:
	uid = None
	
	def email_subject(self):
		return "Your GovTrack.us Email Updates May Be Turned Off"
	
	def email_body(self):
		return """Are you still interested in getting email updates from www.GovTrack.us?
		
You registered more than three years ago to get updates by email about what is happening in Congress, but we haven't heard from you in a while. We're cleaning house as we improve GovTrack. Your email updates will be turned off if you do not log in to GovTrack within the next two weeks.

To continue your email updates, just follow this link:

<URL>

Thank you for your interest in GovTrack.

www.govtrack.us"""
	
	def get_response(self, request, vrec):
		from django.contrib.auth import authenticate, login
		from django.http import HttpResponse
		user = User.objects.get(id=self.uid)
		authenticate(user_object = user)
		login(request, user)
		return HttpResponse("""<p>Thank you for confirming you still would like to receive updates from GovTrack.</p><p>Continue on to <a href="/">The New GovTrack</a>.</p>""")



########NEW FILE########
__FILENAME__ = middleware
from models import Req
from django.core.cache import cache
from django.conf import settings
 
import urllib, json, datetime, base64

from emailverification.models import BouncedEmail

import us

if settings.GEOIP_DB_PATH:
    from django.contrib.gis.geoip import GeoIP
    from django.contrib.gis.geos import Point
    geo_ip_db = GeoIP(settings.GEOIP_DB_PATH)
    washington_dc = Point(-77.0300, 38.8900)

# http://whois.arin.net/rest/org/ISUHR/nets
HOUSE_NET_RANGES = (
    ("143.231.0.0", "143.231.255.255"),
    ("137.18.0.0", "137.18.255.255"),
    ("143.228.0.0", "143.228.255.255"),
    ("12.185.56.0", "12.185.56.7"),
    ("12.147.170.144", "12.147.170.159"),
    ("74.119.128.0", "74.119.131.255"),
    )
# http://whois.arin.net/rest/org/USSAA/nets
SENATE_NET_RANGES = (
    ("156.33.0.0", "156.33.255.255"),
    )
# http://whois.arin.net/rest/org/EXOP/nets
EOP_NET_RANGES = (
    ("165.119.0.0", "165.119.255.255"),
    ("198.137.240.0", "198.137.241.255"),
    ("204.68.207.0", "204.68.207.255"),
	)

trending_feeds = None

def template_context_processor(request):
    # These are good to have in a context processor and not middleware
    # because they won't be evaluated until template evaluation, which
    # might have user-info blocked already for caching (a good thing).
    
    context = {
        "SITE_ROOT_URL": settings.SITE_ROOT_URL,
        "GOOGLE_ANALYTICS_KEY": settings.GOOGLE_ANALYTICS_KEY,
        "STATE_CHOICES": sorted([(kv[0], kv[1], us.stateapportionment[kv[0]]) for kv in us.statenames.items() if kv[0] in us.stateapportionment], key = lambda kv : kv[1]),
    }
    
    if request.user.is_authenticated() and BouncedEmail.objects.filter(user=request.user).exists(): context["user_has_bounced_mail"] = True
    
    # Add top-tracked feeds.
    global trending_feeds
    if not trending_feeds or trending_feeds[0] < datetime.datetime.now()-datetime.timedelta(hours=2):
        from events.models import Feed
        trf = cache.get("trending_feeds")
        if not trf:
            trf = Feed.get_trending_feeds()
            cache.set("trending_feeds", trf, 60*60*2)
        trending_feeds = (datetime.datetime.now(), [Feed.objects.get(id=f) for f in trf])
    context["trending_feeds"] = trending_feeds[1]
    
    # Add context variables for whether the user is in the
    # House or Senate netblocks.
    
    def ip_to_quad(ip):
        return [int(s) for s in ip.split(".")]
    def compare_ips(ip1, ip2):
        return cmp(ip_to_quad(ip1), ip_to_quad(ip2))
    def is_ip_in_range(ip, block):
       return compare_ips(ip, block[0]) >= 0 and compare_ips(ip, block[1]) <= 0
    def is_ip_in_any_range(ip, blocks):
       for block in blocks:
           if is_ip_in_range(ip, block):
               return True
       return False
    
    try:
        ip = request.META["REMOTE_ADDR"]
        ip = ip.replace("::ffff:", "") # ipv6 wrapping ipv4
        
        if is_ip_in_any_range(ip, HOUSE_NET_RANGES):
            context["remote_net_house"] = True
            request._track_this_user = True
        if is_ip_in_any_range(ip, SENATE_NET_RANGES):
            context["remote_net_senate"] = True
            request._track_this_user = True
        if is_ip_in_any_range(ip, EOP_NET_RANGES):
            context["remote_net_eop"] = True
            request._track_this_user = True
        
        try:
            cong_dist = json.loads(request.COOKIES["cong_dist"])
        except:
            cong_dist = None
        
        if settings.GEOIP_DB_PATH:
            user_loc = geo_ip_db.geos(ip)
            context["is_dc_local"] = user_loc.distance(washington_dc) < .5
            
            # geolocate to a congressional district if not known
            if not cong_dist and False:
                from person.views import do_district_lookup
                cong_dist = do_district_lookup(*user_loc.coords)
                cong_dist["queried"] = True

        if cong_dist and "error" not in cong_dist:
            from person.models import PersonRole, RoleType, Gender
            import random
            def get_key_vote(p):
                from vote.models import Vote
                
                v = 113340
                descr = "CISPA"
                
                v = Vote.objects.get(id=v)
                try:
                    return {
                        "link": v.get_absolute_url(),
                        "description": descr,
                        "option": p.votes.get(vote=v).option.key,
                    }
                except:
                    return None
            def fmt_role(r):
                return {
                    "id": r.person.id,
                    "name": r.person.name_and_title(),
                    "link": r.person.get_absolute_url(),
                    "type": RoleType.by_value(r.role_type).key,
                    "pronoun": Gender.by_value(r.person.gender).pronoun,
                    "key_vote": get_key_vote(r.person),
                }
            qs = PersonRole.objects.filter(current=True).select_related("person")    
            cong_dist["reps"] = [fmt_role(r) for r in 
                qs.filter(role_type=RoleType.representative, state=cong_dist["state"], district=cong_dist["district"])
                | qs.filter(role_type=RoleType.senator, state=cong_dist["state"])]
                
            if settings.DEBUG:
                # I need to test with more than my rep (just our DC delegate).
                cong_dist["reps"] = [fmt_role(r) for r in random.sample(PersonRole.objects.filter(current=True), 3)]
            
            random.shuffle(cong_dist["reps"]) # for varied output
            
            context["geolocation"] = json.dumps(cong_dist)
        if cong_dist: # whether or not error
            request.cong_dist_info = cong_dist
                
    except:
        pass
    
    return context
  
class GovTrackMiddleware:
    def process_request(self, request):
        if request.user.is_authenticated():
            request.user.twostream_data = {
                'cd': request.user.userprofile().congressionaldistrict or None,
            }
        return None

    def process_response(self, request, response):
        # Save the geolocation info in a cookie so we don't have to
        # query GIS info on each request.
        if hasattr(request, "cong_dist_info"):
            cong_dist_info = request.cong_dist_info
            for k in ("queried", "reps"):
                if k in cong_dist_info: del cong_dist_info[k]
            response.set_cookie("cong_dist", json.dumps(cong_dist_info), max_age=60*60*24*21)

		# log some requets for processing later
        if hasattr(request, "_track_this_user"):
            uid = request.COOKIES.get("uuid")
            if not uid:
                import uuid
                uid = base64.urlsafe_b64encode(uuid.uuid4().bytes).replace('=', '')
            response.set_cookie("uuid", uid, max_age=60*60*24*365*10)
            print "TRACK", uid, datetime.datetime.now().isoformat(), base64.b64encode(repr(request))

        return response


class DebugMiddleware:
    def process_request(self, request):
        r = Req(request=repr(request))
        r.save()
        request._debug_req = r
        return None
    def process_response(self, request, response):
        if getattr(request, "_debug_req", None) != None:
            request._debug_req.delete()
            request._debug_req = None
        return response
    def process_exception(self, request, exception):
        if getattr(request, "_debug_req", None) != None:
            request._debug_req.delete()
            request._debug_req = None
        return None
        

########NEW FILE########
__FILENAME__ = geocode_campaign
#!.env/bin/python

import sys, os, time
sys.path.insert(0, "..")
sys.path.insert(0, ".")
os.environ["DJANGO_SETTINGS_MODULE"] = "settings"

from settings import GEOCODERUS_USERNAME, GEOCODERUS_PASSWORD

from website.models import CampaignSupporter
from person.views import do_district_lookup

def geocode(c):
	import urllib, urllib2, csv, base64
	
	address = "%s, %s, %s %s" % (c.address, c.city, c.state, c.zipcode)
	
	url = "http://geocoder.us/member/service/csv/geocode?" + urllib.urlencode({ "address": address.encode("utf8") })
	req = urllib2.Request(url)
	req.add_header("Authorization", "Basic %s" % base64.encodestring('%s:%s' % (GEOCODERUS_USERNAME, GEOCODERUS_PASSWORD))[:-1])
		
	r = urllib2.urlopen(req)
	for line in csv.reader(r):
		if line[0] == "2: couldn't find this address! sorry":
			return "NOT FOUND"
		return { "lat": float(line[0]), "lng": float(line[1]) }
	return None

for c in CampaignSupporter.objects.all():
	if c.geocode_response == None:
		c.geocode_response = repr(geocode(c))
		c.save()
	if eval(c.geocode_response) not in (None, "NOT FOUND") and c.district == None:
		coord = eval(c.geocode_response)
		distr = do_district_lookup(coord["lng"], coord["lat"])
		if distr != None and "error" not in distr:
			c.state = distr["state"] # people entered the first two letters of the full state name, geocoder is figuring it out
			c.district = distr["district"]
			c.save()


########NEW FILE########
__FILENAME__ = import_old_accounts
#!.env/bin/python

raise Exception("We should not run this again. It destroys data.")

import sys, os
sys.path.insert(0, "..")
sys.path.insert(0, ".")
os.environ["DJANGO_SETTINGS_MODULE"] = "web.settings"

from django.contrib.auth.models import User
from django.core.validators import validate_email
import csv
from datetime import datetime

from events.models import Feed
from bill.models import BillTerm
from committee.models import Committee

committee_map = { }
from lxml import etree
for c in etree.parse("data/us/committees.xml").xpath("committee[not(@obsolete=1)]"):
	for n in c.xpath("thomas-names/name"):
		committee_map[n.text] = c.get("code")
		for s in c.xpath("subcommittee"):
			for n2 in s.xpath("thomas-names/name"):
				committee_map[n.text + " -- " + n2.text] = c.get("code") + s.get("code")

crs_map = {
	"Internet": "Internet and video services",
	"Homosexuality": "Sex, gender, sexual orientation discrimination",
	"Sexual orientation": "Sex, gender, sexual orientation discrimination",
	"Identity theft": "Computer security and identity theft",	
	"Marijuana": "Drug trafficking and controlled substances",
	"Computer crimes and identity theft": "Computer security and identity theft",
	"Financial crises and failures": "Financial crises and stabilization",
	"Health information systems": "Health information and medical records",
	"Methamphetamine": "Drug trafficking and controlled substances",
	"Interest and interest rates": "Interest",
}

feed_cache = { }
missing_feeds = { }

header = None
for line in csv.reader(sys.stdin, delimiter="\t"):
	if not header:
		header = line
		continue
	
	fields = dict(zip(header, line))
	user, isnew = User.objects.get_or_create(
		username=fields["email"].strip()[0:30],
		email=fields["email"].strip(),
		defaults = {
			"date_joined": fields["created"],
			"last_login": fields["last_login"],
		})
	prof = user.userprofile()
	if isnew:
		user.set_password(fields["password"])
		user.save()
		
		prof.old_id = fields["id"]
		prof.massemail = fields["massemail"]
		prof.save()
		
	if fields["monitors"].strip() == "":
		continue
		
	sublist = prof.lists().get(is_default=True)
	sublist.trackers.clear()
	sublist.email = fields["emailupdates"] # happens to be the same coding
	sublist.last_event_mailed = None
	sublist.save()

	for m in fields["monitors"].split(","):
		if m in ("", "option:relatedblogs"): continue
		m = m.replace("%COMMA%", ",");
		m = m.replace("\\;", ";");
		m = m.replace("\\\\", "\\");
		m = m.replace("$/", "\\");
		m = m.replace("$;", ",");
		m = m.replace("$C", ",");
		m = m.replace("$$", "$");
		m = m.replace(r"\\;", ",").replace(r"\;", ",")
		try:
			if m in feed_cache:
				feed = feed_cache[m]
			elif m.startswith("crs:"):
				name = m[4:]
				name = crs_map.get(name, name)
				terms = BillTerm.objects.filter(name=m[4:]).order_by("-term_type") # new first
				if len(terms) > 0:
					feed = Feed.IssueFeed(terms[0])
				else:
					raise ValueError("unknown subject")
			elif m.startswith("committee:"):
				m = m[10:].replace(" Subcommittee", "").replace("  ", " ")
				feed = Feed.CommitteeFeed(Committee.objects.get(code=committee_map[m]))
			else:
				feed = Feed.from_name(m)
			feed_cache[m] = feed
			
			sublist.trackers.add(feed)
			
		except Exception as e:
			#print fields["id"], m, e
			missing_feeds[m] = missing_feeds.get(m, 0) + 1
	
#print sorted((v, k) for k, v in missing_feeds.items())


########NEW FILE########
__FILENAME__ = models
from django.db import models
from django.contrib.auth.models import User

from json_field import JSONField

from events.models import Feed, SubscriptionList

class UserProfile(models.Model):
    user = models.ForeignKey(User, unique=True, db_index=True)
    massemail = models.BooleanField(default=True) # may we send you mail?
    old_id = models.IntegerField(blank=True, null=True) # from the pre-2012 GovTrack database
    last_mass_email = models.IntegerField(default=0)
    congressionaldistrict = models.CharField(max_length=4, blank=True, null=True, db_index=True) # or 'XX00' if the user doesn't want to provide it
    
    # monetization
    paid_features = JSONField(default={}, blank=True, null=True) # maps feature name to tuple (payment ID, sale ID or None if not useful)
    
    def lists(self):
        # make sure the 'default' list exists
        SubscriptionList.objects.get_or_create(
            user = self.user,
            is_default = True,
            defaults = { "name": "Email Updates" , "email": 1 } )
        return SubscriptionList.objects.filter(user=self.user).order_by('name')
    def lists_with_email(self):
        # return lists with trackers with email updates turned on
        return SubscriptionList.objects.filter(user=self.user, email__gt=0, trackers__id__gt=0).distinct().order_by('name')

    def get_ad_free_message(self):
        if not self.paid_features: return False

        from datetime import datetime, timedelta
        
        if self.paid_features.get("ad_free_year"):
            ad_free_pmt = self.paid_features['ad_free_year']
            pmt = PayPalPayment.objects.get(paypal_id = ad_free_pmt[0])
            if pmt.created > (datetime.now() - timedelta(days=0.5)):
                return "Thanks for your one-year subscription to an ad-free GovTrack!"
            else:
                return "You went ad-free on %s. Your subscription expires on %s. Thanks!" % (
                	pmt.created.strftime("%x"),
                	pmt.created.replace(year=pmt.created.year+1).strftime("%x") )
        elif self.paid_features.get("ad_free_life"):
            ad_free_pmt = self.paid_features['ad_free_life']
            pmt = PayPalPayment.objects.get(paypal_id = ad_free_pmt[0])
            if pmt.created > (datetime.now() - timedelta(days=0.5)):
                return "Thanks for your subscription to an ad-free GovTrack for life!"
            else:
                return "You went ad-free for life on %s. Thanks!" % pmt.created.strftime("%x")
        else:
            return False
            


def get_user_profile(user):
    if hasattr(user, "_profile"): return user._profile
    profile, isnew = UserProfile.objects.get_or_create(user = user)
    user._profile = profile
    return profile
User.userprofile = get_user_profile 
    
class CampaignSupporter(models.Model):
    campaign = models.CharField(max_length=96)
    prefix = models.CharField(max_length=96)
    firstname = models.CharField(max_length=96)
    lastname = models.CharField(max_length=96)
    address = models.CharField(max_length=96)
    city = models.CharField(max_length=96)
    state = models.CharField(max_length=96)
    zipcode = models.CharField(max_length=96)
    email = models.CharField(max_length=96)
    message = models.CharField(max_length=256, blank=True)
    created = models.DateTimeField(auto_now_add=True)
    district = models.IntegerField(blank=True, null=True)
    geocode_response = models.TextField(blank=True, null=True)
   
class Req(models.Model):
    created = models.DateTimeField(auto_now_add=True)
    request = models.TextField()

from bill.models import Bill
class CommunityInterest(models.Model):
    user = models.ForeignKey(User)
    bill = models.ForeignKey(Bill)
    methods = models.CharField(max_length=32)
    created = models.DateTimeField(auto_now_add=True)
    class Meta:
        unique_together = ( ('user', 'bill'), )

class PayPalPayment(models.Model):
    paypal_id = models.CharField(max_length=64, db_index=True)
    user = models.ForeignKey(User, db_index=True, on_delete=models.PROTECT)
    response_data = JSONField()
    executed = models.BooleanField(default=False)
    created = models.DateTimeField(auto_now_add=True, db_index=True)
    notes = models.CharField(max_length=64)
    
    class Meta:
        unique_together = ( ('user', 'created'), ) # dangerous?

    @staticmethod
    def from_session(request):
        import paypalrestsdk
        try:
            payment_id = request.session["paypal-payment-to-execute"]
            del request.session["paypal-payment-to-execute"]
        except KeyError:
            raise ValueError("User session lost track of payment object." )

        payment = paypalrestsdk.Payment.find(payment_id)

        try:
            rec = PayPalPayment.objects.get(paypal_id = payment.id)
        except PayPalPayment.DoesNotExist:
            raise ValueError("Trying to complete a payment that does not exist in our database: " + payment.id)
    
        if payment.state != "created" or rec.executed:
            raise ValueError("Trying to complete an already-executed payment: %s, %s (%s)" + (payment.state, str(rec.executed), payment.id))

        return (payment, rec)

    @staticmethod
    def execute(request, notes_must_match):
        # Get object.
        (payment, rec) = PayPalPayment.from_session(request)
        
        # Validate.
        if rec.notes != notes_must_match:
            raise ValueError("Trying to complete the wrong sort of payment: %s" % payment.id)
            
        # Execute.
        if not payment.execute({"payer_id": request.GET["PayerID"]}):
            raise ValueError("Error executing PayPal.Payment (%s): " + (payment.id, repr(payment.error)))
            
        # Update our database record of the payment.
        rec.response_data = payment.to_dict()
        rec.executed = True
        rec.save()
        
        return (payment, rec)
    


########NEW FILE########
__FILENAME__ = govtrack_utils
from django import template
from django.utils.translation import ugettext as _
from django.utils.encoding import force_unicode
from django.utils import safestring
from django.template.defaultfilters import stringfilter
import random, markdown2

register = template.Library()

@register.assignment_tag
def randint(a, b):
	return random.randint(int(a), int(b))

@register.filter
def ordinalhtml(value):
    """
    Converts an integer to its ordinal as HTML. 1 is '1<sup>st</sup>',
    and so on.
    """
    try:
        value = int(value)
    except ValueError:
        return value
    t = (_('th'), _('st'), _('nd'), _('rd'), _('th'), _('th'), _('th'), _('th'), _('th'), _('th'))
    if value % 100 in (11, 12, 13): # special case
        return safestring.mark_safe(u"%d<sup>%s</sup>" % (value, t[0]))
    return safestring.mark_safe(u'%d<sup>%s</sup>' % (value, t[value % 10]))

@register.filter(is_safe=True)
@stringfilter
def markdown(value):
    return safestring.mark_safe(markdown2.markdown(force_unicode(value), safe_mode=True))

########NEW FILE########
__FILENAME__ = urls
# -*- coding: utf-8 -*-
from django.conf.urls import *

urlpatterns = patterns('website.views',
    url(r'^$', 'index', name='index'),
    url(r'^(start|about|press|advertising|legal|developers|developers/downstream|developers/data|developers/license|developers/rsync|developers/people_xml|developers/vote_xml|developers/bill_xml|civicimpulse|blog_template)$', 'staticpage', name='staticpage'),
    url(r'^developers/api$', 'api_overview'),
    url(r'^congress/?$', 'congress_home', name='congress_home'),
    url(r'^congress/live$', 'congress_live', name='congress_live'),
    url(r'^search$', 'search', name='search'),
    #url(r'^campaigns/bulkdata', 'campaign_bulk_data'),
    url(r'^events/syndication-feed', 'push_to_social_media_rss'),
    url(r'^accounts/docket', 'your_docket'),
    url(r'^accounts/update_settings', 'update_account_settings'),
    url(r'^about/analysis', 'analysis_methodology'),
    url(r'^about/financial', 'financial_report'),
    url(r'^accounts/go_ad_free$', 'go_ad_free_start'),
    url(r'^accounts/go_ad_free/start$', 'go_ad_free_redirect'),
    url(r'^accounts/go_ad_free/finish$', 'go_ad_free_finish'),
    url(r'^accounts/_set_district$', 'set_district'),
    url(r'^videos(?:/(?P<video_id>[a-z0-9\-_]+))?', 'videos'),
)


########NEW FILE########
__FILENAME__ = util

########NEW FILE########
__FILENAME__ = views
# -*- coding: utf-8 -*-
from django.http import Http404, HttpResponseRedirect, HttpResponseBadRequest
from django.shortcuts import redirect, get_object_or_404, render_to_response
from django.template import RequestContext
from django.core.urlresolvers import reverse
from django.core.cache import cache
from django.views.decorators.cache import cache_page
from django.contrib.auth.decorators import login_required
from django.conf import settings

from common.decorators import render_to
from common.pagination import paginate

from cache_utils.decorators import cached

from twostream.decorators import anonymous_view
from registration.helpers import json_response

from events.models import Feed
import us

import re
from datetime import datetime, timedelta, time

@anonymous_view
@render_to('website/index.html')
def index(request):
    blog_feed = cache.get("our_blog_feed")
    if not blog_feed:
        blog_feed = get_blog_items()[0:4]
        cache.set("our_blog_feed", blog_feed, 60*30) # 30 min
    
    events_feed = cache.get("frontpage_events_feed")
    if not events_feed:
        events_feed = Feed.get_events_for([fn for fn in ("misc:activebills2", "misc:billsummaries", "misc:allvotes") if Feed.objects.filter(feedname=fn).exists()], 6)
        cache.set("frontpage_events_feed", events_feed, 60*15) # 15 minutes

    return {
        'events': events_feed,
        'blog': blog_feed,
        }
      
@anonymous_view
def staticpage(request, pagename):
    if pagename == "developers": pagename = "developers/index"
    
    ctx = { 'pagename': pagename }
    
    if pagename == "start":
        from us import statenames
        from states.views import states_with_data
        ctx['states'] = ((s, statenames[s]) for s in states_with_data())
    
    return render_to_response('website/' + pagename + '.html', ctx, RequestContext(request))

def get_blog_items():
    # c/o http://stackoverflow.com/questions/1208916/decoding-html-entities-with-python
    import re
    def _callback(matches):
        id = matches.group(1)
        try:
           return unichr(int(id))
        except:
           return id
    def decode_unicode_references(data):
        return re.sub("&#(\d+)(;|(?=\s))", _callback, data)

    import feedparser
    feed = feedparser.parse(settings.SITE_ROOT_URL + "/blog/atom")

    return [{"link":entry.link, "title":decode_unicode_references(entry.title), "date":datetime(*entry.updated_parsed[0:6]), "content":decode_unicode_references(entry.content[0].value)} for entry in feed["entries"][0:4]]

def congress_home(request):
    return HttpResponseRedirect("/start")

def do_site_search(q, allow_redirect=False):
    if q.strip() == "":
        return []
    
    results = []
    
    from bill.models import Bill
    from vote.models import Vote
    if "pass" in q or "fail" in q or "vote" in q:
        results.append({
            "title": "Tracking Federal Legislation",
            "href": "/start",
            "noun": "feeds",
            "results": [
                {"href": f.link,
                 "label": f.title,
                 "obj": f,
                 "feed": f,
                 "secondary": False }
                for f in (
                    Bill.EnactedBillsFeed(), Bill.ActiveBillsExceptIntroductionsFeed(), Bill.ComingUpFeed(), Vote.AllVotesFeed(),
                    )
                ]
            })
    
    from haystack.query import SearchQuerySet
    from events.models import Feed
    
    results.append({
        "title": "Members of Congress, Presidents, and Vice Presidents",
        "href": "/congress/members/all",
        "qsarg": "name",
        "noun": "Members of Congress, Presidents, or Vice Presidents",
        "results": [
            {"href": p.object.get_absolute_url(),
             "label": p.object.name,
             "obj": p.object,
             "feed": p.object.get_feed(),
             "secondary": p.object.get_current_role() == None }
            for p in SearchQuerySet().using("person").filter(indexed_model_name__in=["Person"], content=q).order_by('-is_currently_serving', '-score')[0:9]]
        })
       
    # Skipping states for now because we might want to go to the district maps or to
    # the state's main page for state legislative information.
    #import us
    #results.append(("States", "/congress/members", "most_recent_role_state", "states",
    #    sorted([{"href": "/congress/members/%s" % s, "label": us.statenames[s] }
    #        for s in us.statenames
    #        if us.statenames[s].lower().startswith(q.lower())
    #        ], key=lambda p : p["label"])))
    
    from committee.models import Committee
    results.append({
        "title": "Congressional Committees",
        "href": "/congress/committees",
        "noun": "committees in Congress",
        "results": sorted([
            {"href": c.get_absolute_url(),
             "label": c.fullname,
             "feed": c.get_feed(),
             "obj": c,
             "secondary": c.committee != None}
            for c in Committee.objects.filter(name__icontains=q, obsolete=False)
            ], key=lambda c : c["label"])
        })
       
    from settings import CURRENT_CONGRESS
    from bill.search import parse_bill_citation
    bill = parse_bill_citation(q)
    if not bill or not allow_redirect:
        from haystack.inputs import AutoQuery
        bills = [\
            {"href": b.object.get_absolute_url(),
             "label": b.object.title,
             "obj": b.object,
             "feed": b.object.get_feed() if b.object.is_alive else None,
             "secondary": b.object.congress != CURRENT_CONGRESS }
            for b in SearchQuerySet().using("bill").filter(indexed_model_name__in=["Bill"], content=AutoQuery(q)).order_by('-current_status_date')[0:9]]
    else:
        #bills = [{"href": bill.get_absolute_url(), "label": bill.title, "obj": bill, "secondary": bill.congress != CURRENT_CONGRESS }]
        return HttpResponseRedirect(bill.get_absolute_url())
    results.append({
        "title": "Bills and Resolutions (Federal)",
        "href": "/congress/bills/browse",
        "qsarg": "congress=__ALL__&text",
        "noun": "federal bills or resolutions",
        "results": bills})

    
    results.append({
        "title": "State Legislation",
        "href": "/states/bills/browse",
        "qsarg": "text",
        "noun": "state legislation",
        "results": [
            {"href": p.object.get_absolute_url(),
             "label": p.object.short_display_title,
             "obj": p.object,
             "feed": Feed(feedname="states_bill:%d" % p.object.id),
             "secondary": True }
            for p in SearchQuerySet().using('states').filter(indexed_model_name__in=["StateBill"], content=q)[0:9]]
            })

    # subject terms, but exclude subject terms that look like committee names because
    # that is confusing to also see with committee results
    from bill.models import BillTerm, TermType
    results.append({
        "title": "Subject Areas (Federal Legislation)",
        "href": "/congress/bills",
        "noun": "subject areas",
        "results": [
            {"href": p.get_absolute_url(),
             "label": p.name,
             "obj": p,
             "feed": p.get_feed(),
             "secondary": not p.is_top_term() }
            for p in BillTerm.objects.filter(name__icontains=q, term_type=TermType.new).exclude(name__contains=" Committee on ")[0:9]]
        })
    
    # in each group, make sure the secondary results are placed last, but otherwise preserve order
    for grp in results:
        for i, obj in enumerate(grp["results"]):
           obj["index"] = i
        grp["results"].sort(key = lambda o : (o.get("secondary", False), o["index"]))
    
    # sort categories first by whether all results are secondary results, then by number of matches (fewest first, if greater than zero)
    results.sort(key = lambda c : (
        len([d for d in c["results"] if d.get("secondary", False) == False]) == 0,
        len(c["results"]) == 0,
        len(c["results"])))
        
    return results

@render_to('website/search.html')
def search(request):
    r = do_site_search(request.REQUEST.get("q", ""), allow_redirect=True)
    if not isinstance(r, list): return r
    return { "results": r }

@cache_page(60 * 15)
@render_to('website/campaigns/bulkdata2.html')
def campaign_bulk_data(request):
    return { }

@render_to('website/campaigns/bulkdata.html')
def campaign_bulk_data_old(request):
    prefixes = ("Mr.", "Ms.", "Mrs.", "Dr.")
    
    # Validate.
    if request.method == 'POST':
        from models import CampaignSupporter

        s = CampaignSupporter()
        
        if "sid" in request.POST:
            try:
                s = CampaignSupporter.objects.get(id=request.POST.get("sid"), email=request.POST.get("email", ""))
            except:
                pass
        
        s.campaign = "2012_03_buldata"
        for field in ('prefix', 'firstname', 'lastname', 'address', 'city', 'state', 'zipcode', 'email'):
            if request.POST.get(field, '').strip() == "":
                return { "stage": 1, "error": "All fields are required!", "prefixes": prefixes }
            setattr(s, field, request.POST.get(field, ""))
        s.message = request.POST.get('message', '')
        s.save()

        if "message" not in request.POST:
            return { "stage": 2, "sid": s.id }
        else:
            return { "stage": 3 }
    return { "stage": 1, "prefixes": prefixes }

def push_to_social_media_rss(request):
    import django.contrib.syndication.views
    from events.models import Feed
    from events.templatetags.events_utils import render_event
    import re
    
    feedlist = [Feed.from_name("misc:comingup"), Feed.from_name('misc:enactedbills')]
    
    class DjangoFeed(django.contrib.syndication.views.Feed):
        title = "GovTrack.us Is Tracking Congress"
        link = "/"
        description = "GovTrack tracks the activities of the United States Congress. We push this feed to our Twitter and Facebook accounts."
        
        def items(self):
            events = [render_event(item, feedlist) for item in Feed.get_events_for(feedlist, 25)]
            return [e for e in events if e != None]
            
        def item_title(self, item):
            return re.sub(r"^Legislation ", "", item["type"]) + ": " + item["title"]
        def item_description(self, item):
            return item["body_text"]
        def item_link(self, item):
            return settings.SITE_ROOT_URL + item["url"]# + "?utm_campaign=govtrack_push&utm_source=govtrack_push" 
        def item_guid(self, item):
            return "http://www.govtrack.us/events/guid/" + item["guid"] 
        def item_pubdate(self, item):
            return item["date"] if isinstance(item["date"], datetime) or item["date"] is None else datetime.combine(item["date"], time.min)
            
    return DjangoFeed()(request)


@render_to('website/your_docket.html')
def your_docket(request):
    from bill.models import Bill
    # Pre-load the user's subscription lists and for each list
    # pre-load the list of bills entered into the list.
    lists = []
    if request.user.is_authenticated():
        lists = request.user.subscription_lists.all()
        for lst in lists:
            lst.bills = []
            for trk in lst.trackers.all():
                try:
                    lst.bills.append( Bill.from_feed(trk) )
                except ValueError:
                    pass
    return { "lists": lists }

@login_required
def update_account_settings(request):
    if request.POST.get("action") == "unsubscribe":
        # Turn off all email updates.
        for x in request.user.userprofile().lists_with_email():
            x.email = 0
            x.save()
        
    if request.POST.get("action") == "massemail":
        p = request.user.userprofile()
        p.massemail = True if request.POST.get("massemail", False) else False
        p.save()
            
    return HttpResponseRedirect("/accounts/profile")

from website.api import api_overview

@render_to('website/congress_live.html')
def congress_live(request):

    from cache_utils.decorators import cached
    @cached(60*5)
    def get_loc_streams():
        # Scrape the LoC for live House committee hearings.
        
        import urllib
        cmtelist = urllib.urlopen("http://thomas.loc.gov/video/house-committee").read()
        
        feeds = []
        for m in re.findall(r'<a href="(/video/house-committee/\S*)" class="committee-links"', cmtelist):
            cmtepage = urllib.urlopen("http://thomas.loc.gov" + m).read()
            n = re.search(r'<h3>Live Stream: ([^<]+)</h3><iframe [^>]+src="(http://www.ustream.tv/embed/\d+)"', cmtepage)
            if n:
                feeds.append( { "title": n.group(1), "url": "http://thomas.loc.gov" + m } )
            
        return feeds

    return {
        "housecommittees": get_loc_streams,
    }
    
@render_to('website/analysis.html')
def analysis_methodology(request):
    from settings import CURRENT_CONGRESS
    from person.models import RoleType
    from bill.models import BillType
    from us import get_congress_dates
    import json
    
    from person.analysis import load_sponsorship_analysis2
    def make_chart_series(role_type):
        data = load_sponsorship_analysis2(CURRENT_CONGRESS, role_type, None)
        if not data: return None
        
        ret = { }
        for p in data["all"]:
            ret.setdefault(p["party"], {
                "type": "party",
                "party": p["party"],
                "data": [],
            })["data"].append({
                "x": float(p["ideology"]),
                "y": float(p["leadership"]),
                "name": p["name"],
            })
        ret = list(ret.values())
        ret.sort(key = lambda s : len(s["data"]), reverse=True)
        
        data = dict(data) # clone before modifying, just in case
        data["series"] = json.dumps(ret)
        
        return data
        
    import bill.prognosis
    import bill.prognosis_model
    import bill.prognosis_model_test
    prognosis_factors = sorted([dict(v) for v in bill.prognosis_model.factors.values()],
        key = lambda m : m["count"], reverse=True)
    for v in prognosis_factors:
        v["factors"] = sorted(v["factors"].values(), key = lambda f : f["regression_beta"], reverse=True)
    prognosis_test = sorted(bill.prognosis_model_test.model_test_results.values(),
        key = lambda v : v["count"], reverse=True)
    
    return {
        "ideology": lambda : { # defer until cache miss
            "house": make_chart_series(RoleType.representative), 
            "senate": make_chart_series(RoleType.senator),
        },
        "current_congress": CURRENT_CONGRESS,
        "prognosis_training_congress": bill.prognosis_model.congress,
        "prognosis_training_congress_dates": get_congress_dates(bill.prognosis_model.congress),
        "prognosis_factors": prognosis_factors,
        "prognosis_test": prognosis_test,
        "prognosis_testing_traincongress": bill.prognosis_model_test.train_congress,
        "prognosis_testing_testcongress": bill.prognosis_model_test.test_congress,
    }

@anonymous_view
@cache_page(60*60 * 1)
@render_to('website/financial_report.html')
def financial_report(request):
    categories = {
        "AD": ("Advertising", "Revenue from advertisements displayed on GovTrack.us."),
        "DATALIC": ("Data Licensing", "Revenue from data licensing agreements."),
        "PRIZE": ("Prize Winnings", "Income from prizes."),
        "INFR": ("IT Infrastruture", "IT systems infrastructure including the web server."),
        "LABOR": ("Contract Labor", "Contract labor, such as developers, designers, and    other staff. (Does not count Josh.)"),
        "OFFICE": ("Office Expenses", "Josh's home office."),
        "TRAVEL": ("Conferences and Travel", "Expenses for conferences and other similar travel."),
        "MARKETING": ("Marketing", "Marketing expenses."),
        "PROF": ("Professional Membership", "Membership in the ACM and other professional organizations."),
        "HEALTHINS": ("Health Insurance", "Josh's health insurance."),
        "LEGAL": ("Legal Fees", "Fees related to business filings and legal advice."),
        "MISC": ("Miscellaneous", "Other expenses."),
        "TAX": ("Taxes", "Federal/state/local taxes (see note below)."),
    }
    
    import csv
    rows = []
    for row in csv.DictReader(open("/home/govtrack/extdata/civic_impulse/financial_report.tsv"), delimiter="\t"):
        year = { "year": row["Year"], "items": [] }
        net = 0.0
        for k, v in row.items():
            if k in categories and v.strip() != "":
                amt = float(v.replace("$", "").replace(",", ""))
                net += amt
                amt = int(round(amt))
                year["items"].append({
                    "category": categories[k][0],
                    "description": categories[k][1],
                    "amount": amt,
                    "unsigned_amount": abs(amt)
                })
        year["items"].sort(key = lambda x : (x["amount"] >= 0, abs(x["amount"])), reverse=True)
        rows.append(year)
        year["net"] = int(round(net))
        year["unsigned_net"] = abs(year["net"])
        
    return { "years": reversed(rows) }
    
@render_to('website/ad_free_start.html')
def go_ad_free_start(request):
    # just show the go-ad-free page.
    
    is_ad_free = False
    
    if not request.user.is_anonymous():
        is_ad_free = request.user.userprofile().get_ad_free_message()
        
    return { "is_ad_free": is_ad_free }
    
def go_ad_free_redirect(request):
    # create a Payment and redirect to the approval step, and track this
    
    if request.user.is_anonymous():
        return HttpResponseRedirect(reverse(go_ad_free_start))
        
    if request.user.userprofile().get_ad_free_message():
        raise ValueError("User already has this feature.")
    
    import paypalrestsdk

    sandbox = ""
    if paypalrestsdk.api.default().mode == "sandbox":
        sandbox = "-sandbox"
    
    payment = paypalrestsdk.Payment({
      "intent": "sale",
      "payer": { "payment_method": "paypal" },
      "transactions": [{
        "item_list": {
          "items": [{
            "name": "Ad-Free GovTrack.us for 1 Year",
            "sku": "govtrack-ad-free-for-year" + sandbox,
            "price": "2.00",
            "currency": "USD",
            "quantity": 1 }]
            },
          "amount": {
            "total": "2.00",
            "currency": "USD"
          },
          "description": "Ad-Free%s: GovTrack.us is ad-free for a year while you're logged in." % sandbox }],
      "redirect_urls": {
        "return_url": request.build_absolute_uri(reverse(go_ad_free_finish)),
        "cancel_url": request.build_absolute_uri(reverse(go_ad_free_start)),
      },
    })
    
    if not payment.create():
      raise ValueError("Error creating PayPal.Payment: " + repr(payment.error))
      
    request.session["paypal-payment-to-execute"] = payment.id
      
    from website.models import PayPalPayment
    rec = PayPalPayment(
        paypal_id = payment.id,
        user = request.user,
        response_data = payment.to_dict(),
        notes = "ad-free-year $2")
    rec.save()
  
    for link in payment.links:
        if link.method == "REDIRECT":
            return HttpResponseRedirect(link.href)
    else:
        raise ValueError("No redirect in PayPal.Payment: " + payment.id)
    
def go_ad_free_finish(request):
    if request.user.is_anonymous():
        raise ValueError("User got logged out!")

    # Do as much before we destroy state.
    prof = request.user.userprofile()

    from website.models import PayPalPayment
    (payment, rec) = PayPalPayment.execute(request, "ad-free-year $2")
    
    try:
        # Update the user profile.
        if prof.paid_features == None: prof.paid_features = { }
        prof.paid_features["ad_free_year"] = (payment.id, None)
        prof.save()
      
        # Send user back to the start.
        return HttpResponseRedirect(reverse(go_ad_free_start))
     
    except Exception as e:
        raise ValueError(str(e) + " while processing " + payment.id)

@anonymous_view
def videos(request, video_id=None):
    return render_to_response('website/videos.html', { "video_id": video_id }, RequestContext(request))


@login_required
@json_response
def set_district(request):
    prof = request.user.userprofile()
    if request.POST.get("state") not in list(us.statenames)+["XX"]: return HttpResponseBadRequest(request.POST.get("state") + "|"+str(set(us.statenames)))
    prof.congressionaldistrict = "%s%02d" % (request.POST.get("state"), int(request.POST.get("district")))
    prof.save()
    return { "status": "ok" }

########NEW FILE########
