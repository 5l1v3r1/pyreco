__FILENAME__ = autoproxy2pac
#!/usr/bin/env python
# -*- coding: utf-8 -*-

'''
A tool to automatically download autoproxy's GFW list and convert it to a PAC file
So you can bypass GFW's blockade on almost every browser

@version: 0.1
@requires: python 2.6

@author: Meng Xiangliang @ 9#, Tsinghua University
@contact: 911mxl <AT> gmail (e-mail), mengxl (twitter)

@see: AutoProxy add-on for Firefox (https://addons.mozilla.org/en-US/firefox/addon/11009)

@todo:
- Read parameters from command-line
- Generate PAC file using shExpMatch function instead of regular expression, should be faster,
  but it's already fast enough on Safari 4
'''

from __future__ import with_statement
import logging

# Variable names in the PAC file
proxyVar = "PROXY"
defaultVar = "DEFAULT"

# String constants
rulesBegin = "//-- AUTO-GENERATED RULES, DO NOT MODIFY!"
rulesEnd = "//-- END OF AUTO-GENERATED RULES"

defaultPacTemplate = '''/*
 * Proxy Auto-Config file generated by autoproxy2pac
 *  Rule source: %(ruleListUrl)s
 *  Last update: %(ruleListDate)s
 */
function FindProxyForURL(url, host) {
  var %(proxyVar)s = "%(proxyString)s";
  var %(defaultVar)s = "%(defaultString)s";
%(customCodePre)s
  %(rulesBegin)s
%(ruleListCode)s
  %(rulesEnd)s
%(customCodePost)s
  return %(defaultVar)s;
}
'''

def fetchRuleList(url):
    import urllib, base64
    from contextlib import closing
    with closing(urllib.urlopen(url)) as response:
        list = base64.decodestring(response.read())
        date = response.info().getheader('last-modified')
    return list, date

def rule2js(ruleList):
    import re
    jsCode = []

    # The syntax of the list is based on Adblock Plus filter rules (http://adblockplus.org/en/filters)
    #   Filter options (those parts start with "$") is not supported
    # AutoProxy Add-on for Firefox has a Javascript implementation
    #   http://github.com/lovelywcm/autoproxy/blob/master/chrome/content/filterClasses.js
    for line in ruleList.splitlines()[1:]:
        # Ignore the first line ([AutoProxy x.x]), empty lines and comments
        if line and not line.startswith("!"):
            useProxy = True

            # Exceptions
            if line.startswith("@@"):
                line = line[2:]
                useProxy = False

            # Regular expressions
            if line.startswith("/") and line.endswith("/"):
                jsRegexp = line[1:-1]

            # Other cases
            else:
                # Remove multiple wildcards
                jsRegexp = re.sub(r"\*+", r"*", line)
                # Remove anchors following separator placeholder
                jsRegexp = re.sub(r"\^\|$", r"^", jsRegexp, 1)
                # Escape special symbols
                jsRegexp = re.sub(r"(\W)", r"\\\1", jsRegexp)
                # Replace wildcards by .*
                jsRegexp = re.sub(r"\\\*", r".*", jsRegexp)
                # Process separator placeholders
                jsRegexp = re.sub(r"\\\^", r"(?:[^\w\-.%\u0080-\uFFFF]|$)", jsRegexp)
                # Process extended anchor at expression start
                jsRegexp = re.sub(r"^\\\|\\\|", r"^[\w\-]+:\/+(?!\/)(?:[^\/]+\.)?", jsRegexp, 1)
                # Process anchor at expression start
                jsRegexp = re.sub(r"^\\\|", "^", jsRegexp, 1)
                # Process anchor at expression end
                jsRegexp = re.sub(r"\\\|$", "$", jsRegexp, 1)
                # Remove leading wildcards
                jsRegexp = re.sub(r"^(\.\*)", "", jsRegexp, 1)
                # Remove trailing wildcards
                jsRegexp = re.sub(r"(\.\*)$", "", jsRegexp, 1)

                if jsRegexp == "":
                    jsRegexp = ".*"
                    logging.warning("There is one rule that matches all URL, which is highly *NOT* recommended: %s", line)

            jsLine = "  if(/%s/i.test(url)) return %s;" % (jsRegexp, proxyVar if useProxy else defaultVar)
            if useProxy:
                jsCode.append(jsLine)
            else:
                jsCode.insert(0, jsLine)

    return '\n'.join(jsCode)

def parseTemplate(content):
    import re
    template, n = re.subn(r'(?ms)^(\s*?%s\s*?)^.*$(\s*?%s\s*?)$' % (re.escape(rulesBegin), re.escape(rulesEnd)), r'\1%(ruleListCode)s\2', content)
    if n == 0:
        logging.warning("Can not find auto-generated rule section, user-defined rules will LOST during the update")
        return defaultPacTemplate

    template = re.sub(r'(Rule source: ).+', r'\1%(ruleListUrl)s', template)
    template = re.sub(r'(Last update: ).+', r'\1%(ruleListDate)s', template)
    return template

def generatePac(rules, configs, template=defaultPacTemplate):
    data = { 'proxyVar'   : proxyVar,
             'defaultVar' : defaultVar,
             'rulesBegin' : rulesBegin,
             'rulesEnd'   : rulesEnd,
             'customCodePre'  : '',
             'customCodePost' : '',
           }
    data.update(configs)
    data.update(rules)
    return template % data

if __name__ == '__main__':
    pacFilepath = "fuckgfw.pac"
    ruleListUrl = "http://autoproxy-gfwlist.googlecode.com/svn/trunk/gfwlist.txt"
    proxyString = "PROXY 127.0.0.1:8118"
    defaultString = "DIRECT"

    print("Fetching GFW list from %s ..." % ruleListUrl)
    ruleList, ruleListDate = fetchRuleList(ruleListUrl)

    try:
        # Try to update the old PAC file
        with open(pacFilepath) as f:
            template = parseTemplate(f.read())
        print("Updating %s ..." % pacFilepath)

    except IOError:
        # Generate new PAC file
        template = defaultPacTemplate
        print("Generating %s ..." % pacFilepath)

    rules = { 'ruleListUrl'  : ruleListUrl,
              'ruleListDate' : ruleListDate,
              'ruleListCode' : rule2js(ruleList) }
    configs = { 'proxyString'   : proxyString,
                'defaultString' : defaultString }
    with open(pacFilepath, 'w') as f:
        f.write(generatePac(rules, configs, template))

########NEW FILE########
__FILENAME__ = changelog
# -*- coding: utf-8 -*-

from google.appengine.ext import webapp
from google.appengine.api import memcache
from django.utils.feedgenerator import DefaultFeed as Feed

from models import RuleList, ChangeLog
from util import template, webcached

def getSampleUrlFromRule(rule):
    from urllib import unquote
    rule = unquote(rule.encode())
    try:
        rule = rule.decode('utf-8', 'strict')
    except UnicodeDecodeError:
        rule = rule.decode('gbk', 'ignore')
    if rule.startswith('||'): return 'http://' + rule[2:]
    if rule.startswith('.'): return 'http://' + rule[1:]
    if rule.startswith('|'): return rule[1:]
    rule = rule.replace('wikipedia.org*', 'wikipedia.org/wiki/')
    if not rule.startswith('http'): return 'http://' + rule
    return rule

def generateLogFromDiff(diff):
    from collections import defaultdict
    urlStatus = defaultdict(lambda:{True:[], False:[]})
    log = {'timestamp':diff.date, 'block':[], 'unblock':[], 'rule_adjust':[]}

    for type in ('add', 'remove'):
        blocked = type == 'add'
        for rule in getattr(diff, type):
            if rule.startswith('@@'):
                url = getSampleUrlFromRule(rule[2:])
                log['rule_adjust'].append({'from':(), 'to':(rule,), 'sample_url':url})
            else:
                url = getSampleUrlFromRule(rule)
                urlStatus[url][blocked].append(rule)

    for url, status in urlStatus.items():
        if status[True] and not status[False]:
            log['block'].append({'rules':status[True], 'sample_url':url})
        elif not status[True] and status[False]:
            log['unblock'].append({'rules':status[False], 'sample_url':url})
        else:
            log['rule_adjust'].append({'from':status[False], 'to':status[True], 'sample_url':url})

    return log

class FeedHandler(webapp.RequestHandler):
    @webcached()
    def get(self, name):
        name = name.lower()
        rules = RuleList.getList(name)
        if rules is None:
            self.error(404)
            return

        # Conditional redirect to FeedBurner
        # @see: http://www.google.com/support/feedburner/bin/answer.py?hl=en&answer=78464
        if(self.request.get('raw', None) is None and        # http://host/path/name.rss?raw
           'FeedBurner' not in self.request.user_agent):    # FeedBurner fetcher
            self.redirect('http://feeds.feedburner.com/%s' % name, permanent=False)
            return

        self.lastModified(rules.date)

        start = int(self.request.get('start', 0))
        fetchNum = start + int(self.request.get('num', 20))
        if fetchNum > 1000:
            self.error(412)
            return

        logs = memcache.get('changelog/%s' % name)
        if logs is None or len(logs) < fetchNum:
            diff = ChangeLog.gql("WHERE ruleList = :1 ORDER BY date DESC", rules).fetch(fetchNum)
            logs = map(generateLogFromDiff, diff)
            memcache.add('changelog/%s' % name, logs)

        self.response.headers['Content-Type'] = Feed.mime_type

        f = Feed(title="%s 更新记录" % name,
                 link=self.request.relative_url(name),
                 description="beta",
                 language="zh")

        for item in logs:
            f.add_item(title="%d月%d日 %s 更新: 增加 %d 条, 删除 %d 条" % (item['timestamp'].month, item['timestamp'].day, name, len(item['block']), len(item['unblock'])),
                       link='',
                       description=template.render('changelogRssItem.html', **item),
                       author_name="gfwlist",
                       pubdate=item['timestamp'])

        f.write(self.response.out, 'utf-8')

########NEW FILE########
__FILENAME__ = gfwtest
# -*- coding: utf-8 -*-

from google.appengine.ext import webapp

import autoproxy2pac
from models import RuleList
from util import template, webcached, responsecached

jsFileTemplate = '''/*
 * Provide a javascript function to determine whether a URL is blocked in mainland China
 * You can get this file at http://autoproxy2pac.appspot.com/gfwtest.js
 *
 * Usage: isBlockedByGFW(url), returns true if the URL is blocked
 *
 * Last update: %(ruleListDate)s
 */

// Base64 code from Tyler Akins -- http://rumkin.com
function decode64(_1){var _2="ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/=";var _3="";var _4,_5,_6;var _7,_8,_9,_a;var i=0;_1=_1.replace(/[^A-Za-z0-9\+\/\=]/g,"");do{_7=_2.indexOf(_1.charAt(i++));_8=_2.indexOf(_1.charAt(i++));_9=_2.indexOf(_1.charAt(i++));_a=_2.indexOf(_1.charAt(i++));_4=(_7<<2)|(_8>>4);_5=((_8&15)<<4)|(_9>>2);_6=((_9&3)<<6)|_a;_3=_3+String.fromCharCode(_4);if(_9!=64){_3=_3+String.fromCharCode(_5);}if(_a!=64){_3=_3+String.fromCharCode(_6);}}while(i<_1.length);return _3;};

// Encode the function using Base64 for security purpose
eval(decode64("%(encodedFunc)s"))
'''

jsFuncTemplate = '''function isBlockedByGFW(url) {
  url = encodeURI(url).replace(/%%25/g,'%%');
  var %(proxyVar)s = true;
  var %(defaultVar)s = false;

%(ruleListCode)s

  return %(defaultVar)s;
}
'''

def generateJs(rules):
    import base64
    data = { 'proxyVar'   : autoproxy2pac.proxyVar,
             'defaultVar' : autoproxy2pac.defaultVar }
    data.update(rules)
    data['encodedFunc'] = base64.b64encode(jsFuncTemplate % data)
    return jsFileTemplate % data

class JsLibHandler(webapp.RequestHandler):
    @webcached('public,max-age=600')  # 10min
    @responsecached()
    def get(self):
        rules = RuleList.getList('gfwlist')
        if rules is None:
            self.error(500)
            return

        self.lastModified(rules.date)
        self.response.headers['Content-Type'] = 'application/x-javascript'
        self.response.out.write(generateJs(rules.toDict()))

class TestPageHandler(webapp.RequestHandler):
    @webcached('public,max-age=86400', 'Cookie')  # 24h
    def get(self):
        self.lastModified(template.mtime('gfwtest.html'))
        self.response.out.write(template.render('gfwtest.html'))

########NEW FILE########
__FILENAME__ = pac_config
# -*- coding: utf-8 -*-

from google.appengine.api import users
from google.appengine.ext import webapp

from models import UserSetting
from settings import PAC_URL_PREFIX, PAC_USER_URL_PREFIX, PRESET_PROXIES
from util import template, useragent, webcached

class MainHandler(webapp.RequestHandler):
    @webcached(('public,max-age=3600', 'private,max-age=3600'), 'Cookie')  # 1h
    def get(self):
        user = users.get_current_user()

        self.lastModified(template.mtime('index.html'))
        self.response.out.write(template.render('index.html',
            presetProxies=((k, v[0]) for k, v in PRESET_PROXIES.items()),
            pacUrlPrefix=PAC_URL_PREFIX,
            pacUserUrlPrefix=PAC_USER_URL_PREFIX,
            userSetting=UserSetting.get_by_key_name(user.user_id()) if user else None,
        ))

    def post(self):
        user = users.get_current_user()
        if not user or not self.request.get('customize'): return

        pacName = self.request.get('pacname', '').lower()
        if pacName != user.nickname().lower():
            self.error(400)
            return

        UserSetting(
            key_name=user.user_id(),
            defaultProxy=self.request.get('proxy'),
            pacName=pacName,
            customRules=self.request.get('addrules').splitlines(),
        ).put()

        if self.request.get('usage') != 'online':
            self.redirect('/%s%s%s?download' % (PAC_URL_PREFIX, PAC_USER_URL_PREFIX, pacName), permanent=False)

class UsageHandler(webapp.RequestHandler):
    @webcached('public,max-age=86400')  # 24h
    def get(self):
        self.lastModified(template.mtime('usage.html'))

        url = self.request.get('u')
        if url: url = 'http://%s/%s%s' % (self.request.host, PAC_URL_PREFIX, url)

        self.response.out.write(template.render('usage.html',
            url=url,
            browser=useragent.family(),
        ))

########NEW FILE########
__FILENAME__ = pac_generate
# -*- coding: utf-8 -*-

import logging
import re
from base64 import urlsafe_b64decode, urlsafe_b64encode
from calendar import timegm
from datetime import datetime
from email.utils import formatdate, parsedate
from urllib import unquote
from google.appengine.ext import webapp
from google.appengine.api import memcache

import autoproxy2pac
from models import RuleList, UserSetting
from util import useragent, webcached
from settings import DEBUG, MAIN_SERVER, PRESET_PROXIES, MIRRORS, RATELIMIT_ENABLED, RATELIMIT_DURATION, RATELIMIT_QUOTA, MAX_CUSTOM_RULE_NUMBER_FOR_MIRROR, \
    PAC_USER_URL_PREFIX

privoxyConfCode = '''
  if(host == "p.p" || dnsDomainIs(host, "config.privoxy.org")) return PROXY;
'''

class Handler(webapp.RequestHandler):
    @webcached('public,max-age=600')  # 10min
    def get(self, urlpart):
        download = self.request.get('download', None) is not None

        # Redirect to usage page for visits from links (obviously not a browser PAC fetcher)
        if MAIN_SERVER and not download and 'Referer' in self.request.headers:
            self.redirect("/usage?u=" + urlpart, permanent=False)
            return

        if not self.parseRequest(urlpart):
            self.error(404)
            return

        rules = RuleList.getList('gfwlist')
        if rules is None:
            self.error(500)
            return

        pacTime = formatdate(timegm(max(self.settingTime, datetime(*parsedate(rules.date)[:6])).timetuple()), False, True)
        self.response.headers['ETag'] = '"' + pacTime.replace(',', '').replace(' ', '') + '"'
        self.lastModified(pacTime)

        # Load balance
        if MAIN_SERVER and len(self.customRules) <= MAX_CUSTOM_RULE_NUMBER_FOR_MIRROR:
            mirror = self.pickMirror()
            if mirror:
                query = ['e=' + urlsafe_b64encode(r) for r in self.customRules]
                if download: query.append('download')
                mirror = '%s/%s?%s' % (mirror, self.proxyDict['urlpart'], '&'.join(query))
                logging.debug('Redirect the PAC fetcher to %s', mirror)
                if not DEBUG:
                    # A fixed server for a rate-limiting cycle
                    self.response.headers['Cache-Control'] = 'public,max-age=%d' % (RATELIMIT_DURATION * 3600)
                    self.redirect(mirror, permanent=False)
                    return

        if RATELIMIT_ENABLED and self.isRateLimited(): return

        customJs = autoproxy2pac.rule2js('\n'.join([''] + self.customRules))
        if self.proxyDict['name'] == 'privoxy': customJs = privoxyConfCode + customJs
        configs = {
            'proxyString': self.proxyString,
            'defaultString': 'DIRECT',
            'customCodePre': customJs,
        }
        pac = autoproxy2pac.generatePac(rules.toDict(), configs, autoproxy2pac.defaultPacTemplate)
        import base64
        pac = '''function decode64(_1){var _2="ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/=";var _3="";var _4,_5,_6;var _7,_8,_9,_a;var i=0;_1=_1.replace(/[^A-Za-z0-9\+\/\=]/g,"");do{_7=_2.indexOf(_1.charAt(i++));_8=_2.indexOf(_1.charAt(i++));_9=_2.indexOf(_1.charAt(i++));_a=_2.indexOf(_1.charAt(i++));_4=(_7<<2)|(_8>>4);_5=((_8&15)<<4)|(_9>>2);_6=((_9&3)<<6)|_a;_3=_3+String.fromCharCode(_4);if(_9!=64){_3=_3+String.fromCharCode(_5);}if(_a!=64){_3=_3+String.fromCharCode(_6);}}while(i<_1.length);return _3;}eval(decode64("%s"))''' % base64.b64encode(pac)

        self.response.headers['Content-Type'] = 'application/x-ns-proxy-autoconfig'
        if download: self.response.headers['Content-Disposition'] = 'attachment; filename="autoproxy.pac"'
        self.response.out.write(pac)

    userPacRegxp = re.compile(r'^%s([^/\s]+)(?:/(.+))?$' % PAC_USER_URL_PREFIX)
    proxyRegxp = re.compile(r'''^(?P<urlpart>
        (?P<name> [^/\s]+) |
        (?P<type> proxy|http|socks) / (?P<host> [^/\s]+) / (?P<port> \d+)
    )$''', re.VERBOSE)

    def parseRequest(self, urlpart):
        self.customRules = self.request.get_all('c')
        self.customRules += (urlsafe_b64decode(r.encode('ascii')) for r in self.request.get_all('e'))

        match = self.userPacRegxp.match(unquote(urlpart).strip())
        if match:
            setting = UserSetting.gql('WHERE pacName=:1', match.group(1).lower()).get()
            if setting is None: return

            urlpart = match.group(2) or setting.defaultProxy
            self.customRules += setting.customRules
            self.settingTime = setting.lastModified
        else:
            self.settingTime = datetime.min

        match = self.proxyRegxp.match(urlpart.lower())
        if match is None: return
        self.proxyDict = match.groupdict()

        if self.proxyDict['name']:
            if self.proxyDict['name'] not in PRESET_PROXIES: return
            self.proxyString = PRESET_PROXIES[self.proxyDict['name']][1]
        elif self.proxyDict['type']:
            self.proxyDict['type'] = 'SOCKS' if self.proxyDict['type'] == 'socks' else 'PROXY'
            self.proxyString = '%(type)s %(host)s:%(port)s' % self.proxyDict

        # Chrome expects 'SOCKS5' instead of 'SOCKS', see http://j.mp/pac-test
        if useragent.family() == 'Chrome':
            self.proxyString = self.proxyString.replace('SOCKS ', 'SOCKS5 ')

        return True

    def pickMirror(self):
        return MIRRORS[hash(self.request.remote_addr) % len(MIRRORS)]

    def isRateLimited(self):
        param = {'ip':self.request.remote_addr, 'ua':self.request.user_agent}

        key = '%(ua)s@%(ip)s' % param
        rate = memcache.incr(key, namespace='rate')  # incr won't refresh the expiration time
        if rate is None:
            rate = 1
            memcache.add(key, 1, RATELIMIT_DURATION * 3600, namespace='rate')

        quota = RATELIMIT_QUOTA(**param)
        if rate > quota:
            if rate == quota + 1:
                logging.info('%(ip)s has reached the rate limit (%(qt)d per %(dur)dh), UA="%(ua)s"', dict(qt=quota, dur=RATELIMIT_DURATION, **param))
            logging.debug('%(ip)s is banned on full fetch #%(rt)d, UA="%(ua)s"', dict(rt=rate, **param))
            if not DEBUG:
                self.error(403)
                return True

        return False

########NEW FILE########
__FILENAME__ = feedping
# -*- coding: utf-8 -*-

import logging
import xmlrpclib
from google.appengine.ext import webapp

class FeedBurnerHandler(webapp.RequestHandler):
    '''
    Ping FeedBurner to update the feed immediately
    @see: http://feedburner.google.com/fb/a/ping
    '''
    def post(self):
        url = self.request.get('url')

        try:
            rpc = xmlrpclib.ServerProxy('http://ping.feedburner.google.com/')
            result = rpc.weblogUpdates.ping('', url)

            if result['flerror']: raise xmlrpclib.Fault(1, result['message'])
        except xmlrpclib.Error, e:
            logging.error('Ping FeedBurner for %s failed: %s', url, e)
            self.error(500)
            return

        logging.debug('Pinged FeedBurner for %s', url)

########NEW FILE########
__FILENAME__ = update
# -*- coding: utf-8 -*-

import logging
from google.appengine.ext import webapp
from google.appengine.api import memcache
from google.appengine.api.labs import taskqueue

from models import RuleList
from settings import MAIN_SERVER

class Handler(webapp.RequestHandler):
    def get(self):
        for name, url in (('gfwlist', 'http://autoproxy-gfwlist.googlecode.com/svn/trunk/gfwlist.txt'),):
            r = RuleList.getList(name)
            if r == None:
                r = RuleList(name=name, url=url)

            if r.update():
                logging.info('%s updated to %s' , name, r.date)

                if MAIN_SERVER:
                    if name == 'gfwlist': memcache.delete('/gfwtest.js', namespace='response')
                    memcache.delete('changelog/%s' % name)
                    taskqueue.add(url='/tasks/feed_ping', params={'url':'http://feeds.feedburner.com/%s' % name})

########NEW FILE########
__FILENAME__ = main
# -*- coding: utf-8 -*-

import os
import logging
from google.appengine.ext import webapp
from google.appengine.ext.webapp.util import run_wsgi_app

from settings import DEBUG, MAIN_SERVER, CACHE_ENABLED, RATELIMIT_ENABLED, PAC_URL_PREFIX
from handlers import *

# Log a message each time this module get loaded.
logging.debug(
    'Loading %s %s, MAIN_SERVER = %s, CACHE_ENABLED = %s, RATELIMIT_ENABLED = %s, PAC_URL_PREFIX = "%s"',
    os.getenv('APPLICATION_ID'), os.getenv('CURRENT_VERSION_ID'),
    MAIN_SERVER, CACHE_ENABLED, RATELIMIT_ENABLED, PAC_URL_PREFIX,
)

# A hack to be able to get the status of a Response instance, read-only
webapp.Response.status = property(lambda self: self._Response__status[0])

urlMapping = [
    ('/tasks/update', tasks.update.Handler),
    ('/%s(.+)' % PAC_URL_PREFIX, pac_generate.Handler),
]
if MAIN_SERVER: urlMapping += [
    ('/', pac_config.MainHandler),
    ('/usage', pac_config.UsageHandler),
    ('/gfwtest.js', gfwtest.JsLibHandler),
    ('/gfwtest', gfwtest.TestPageHandler),
    ('/changelog/(.*)\.rss', changelog.FeedHandler),
    ('/tasks/feed_ping', tasks.feedping.FeedBurnerHandler),
]
application = webapp.WSGIApplication(urlMapping, DEBUG)

def main():
    if DEBUG: logging.getLogger().setLevel(logging.DEBUG)

    if os.getenv('AUTH_DOMAIN') != 'gmail.com':
        logging.warn('Fixing auth domain (%r)', os.getenv('AUTH_DOMAIN'))
        os.environ['AUTH_DOMAIN'] = 'gmail.com'

    run_wsgi_app(application)

if __name__ == '__main__':
    main()

########NEW FILE########
__FILENAME__ = usersetting
# -*- coding: utf-8 -*-

from google.appengine.ext import db

class UserSetting(db.Model):
    defaultProxy = db.StringProperty(required=True)
    pacName = db.StringProperty(required=True)
    customRules = db.StringListProperty()
    lastModified = db.DateTimeProperty(required=True, auto_now=True)

########NEW FILE########
__FILENAME__ = settings
# -*- coding: utf-8 -*-

import os

DEBUG = os.getenv('SERVER_SOFTWARE', 'Dev').startswith('Dev')

MAIN_SERVER = os.getenv('APPLICATION_ID', 'autoproxy2pac') == 'autoproxy2pac'

TEMPLATE_DEBUG = DEBUG

TEMPLATE_DIR = os.path.join(os.path.dirname(__file__), 'templates')

MEDIA_URL = '/static/'

CACHE_ENABLED = not DEBUG

RATELIMIT_ENABLED = True

PAC_URL_PREFIX = 'pac/' if MAIN_SERVER else ''

PAC_USER_URL_PREFIX = 'u/'

PRESET_PROXIES = {
    'gappproxy'    : ('GAppProxy', 'PROXY 127.0.0.1:8000'),
    'tor'          : ('Tor', 'PROXY 127.0.0.1:8118; SOCKS 127.0.0.1:9050'),
    'jap'          : ('JAP', 'PROXY 127.0.0.1:4001'),
    'your-freedom' : ('Your Freedom', 'PROXY 127.0.0.1:8080'),
    'wu-jie'       : ('无界', 'PROXY 127.0.0.1:9666'),
    'free-gate'    : ('自由门', 'PROXY 127.0.0.1:8580'),
    'puff'         : ('Puff', 'PROXY 127.0.0.1:1984'),
    'privoxy'      : ('Privoxy + SOCKS', 'PROXY 127.0.0.1:8118'),
    'ssh-d'        : ('ssh -D / MyEnTunnel', 'SOCKS 127.0.0.1:7070'),
}

MAX_CUSTOM_RULE_NUMBER_FOR_MIRROR = 10

try:
    # Settings not under version control
    from settings2 import *
except ImportError:
    # Base URL of the mirrors, None stands for the main server itself
    MIRRORS = (None,)

    # QUOTA times of retrieval per DURATION (unit: hour) is allowed in maximum
    RATELIMIT_DURATION = 0
    RATELIMIT_QUOTA = lambda ip, ua: 0

########NEW FILE########
__FILENAME__ = memcache
# -*- coding: utf-8 -*-

import logging
from functools import wraps
from google.appengine.api import memcache
from google.appengine.api import users

from settings import CACHE_ENABLED

class memcached(object):
    '''
    Decorate any function or method whose return value to keep in memcache

    @param key: Can be a string or a function (takes the same arguments as the
                wrapped function, and returns a string key)
    @param time: Optional expiration time, either relative number of seconds from
                 current time (up to 1 month), or an absolute Unix epoch time
    @param namespace: An optional namespace for the key

    @note: Set CACHE_ENABLED to False to globally disable memcache
    @note: Won't cache if the inner function returns None
    '''
    def __init__(self, key, time=0, namespace=None):
        self.key = key
        self.time = time
        self.namespace = namespace

    def __call__(self, f):
        @wraps(f)
        def wrapped(*args, **kwargs):
            key = self.key(*args, **kwargs) if callable(self.key) else self.key

            data = memcache.get(key, namespace=self.namespace)
            if data is not None: return data

            logging.debug('Memcache for %s missed, key = %s@%s', f.__name__, key, self.namespace)
            data = f(*args, **kwargs)
            if data is not None: memcache.set(key, data, self.time, namespace=self.namespace)
            return data

        return wrapped if CACHE_ENABLED else f

class responsecached(object):
    '''
    Decorate RequestHandler.get/post/etc. to keep the response in memcache
    A convenient wrapper of memcached

    @note: Multiple memcache items may be generated using the default key algorithm
    '''
    def __init__(self, time=0, key=None, namespace='response', cacheableStatus=(200,), onlyAnonymous=False):
        self.time = time
        self.key = key if key else lambda h, *_: h.request.path_qs
        self.namespace = namespace
        self.cacheableStatus = cacheableStatus
        self.onlyAnonymous = onlyAnonymous

    def __call__(self, f):
        @wraps(f)
        def wrapped(handler, *args):
            if self.onlyAnonymous and users.get_current_user():
                f(handler, *args)
                return

            @memcached(self.key, self.time, self.namespace)
            def getResponse(handler, *args):
                f(handler, *args)
                return handler.response if handler.response.status in self.cacheableStatus else None

            # In `WSGIApplication.__call__`, `handler.response` is just a reference
            # of the local variable `response`, whose `wsgi_write` method is called.
            # So just assign a new response object to `handler.response` will not work.
            handler.response.__dict__ = getResponse(handler, *args).__dict__

        return wrapped

########NEW FILE########
__FILENAME__ = template
# -*- coding: utf-8 -*-

import os
from datetime import datetime
from google.appengine.api import users
from google.appengine.ext.webapp import template

import settings

def render(template_, **param):
    currentUrl = os.getenv('PATH_INFO')
    template_path = os.path.join(settings.TEMPLATE_DIR, template_)
    template_dict = {
        'gfwlist_rss': '/changelog/gfwlist.rss',
        'is_dev': settings.DEBUG,
        'language': 'zh-CN',
        'login_url': users.create_login_url(currentUrl),
        'logout_url': users.create_logout_url(currentUrl),
        'media_url': settings.MEDIA_URL,
        'user': users.get_current_user(),
        'url_protocol': 'https://' if os.getenv('HTTPS') == 'on' else 'http://',
    }
    template_dict.update(param)
    return template.render(template_path, template_dict, debug=settings.TEMPLATE_DEBUG)

def mtime(template_):
    return datetime.fromtimestamp(os.stat(os.path.join(settings.TEMPLATE_DIR, template_)).st_mtime)

########NEW FILE########
__FILENAME__ = useragent
# -*- coding: utf-8 -*-

import os

def family():
    ua = os.getenv('HTTP_USER_AGENT')

    if 'MSIE' in ua:
        return 'IE'
    elif 'Chrome' in ua:
        return 'Chrome'
    else:
        return None

########NEW FILE########
__FILENAME__ = webcache
# -*- coding: utf-8 -*-

from calendar import timegm
from datetime import datetime
from email.utils import formatdate
from functools import wraps
from hashlib import md5
from types import MethodType
from google.appengine.api import users

class _ResponseNotModified(Exception):
    pass

def _lastModified(handler, time):
    if isinstance(time, datetime):
        time = formatdate(timegm(time.timetuple()), False, True)
    handler.response.headers['Last-Modified'] = time

    if _validate(handler): raise _ResponseNotModified

def _validate(handler):
    '''
    Validate client cache. Last-Modified and/or ETag headers should be set.

    @return: True if the page is cached (no need to generate the content)
    '''
    if handler.response.status != 200: return False

    # @see: http://tools.ietf.org/html/rfc2616#section-14.25
    ims = handler.request.headers.get('If-Modified-Since')
    if ims:
        lm = handler.response.headers.get('Last-Modified')
        if lm is None or ims != lm: return False

    # @see: http://tools.ietf.org/html/rfc2616#section-14.26
    inm = (t.strip('" ') for t in handler.request.headers.get('If-None-Match', '').split(','))
    if inm:
        et = handler.response.headers.get('ETag', '').strip('"')
        if not et or not (et in inm or '*' in inm): return False

    if ims or inm:
        # @see: http://tools.ietf.org/html/rfc2616#section-10.3.5
        handler.error(304)
        del handler.response.headers['Last-Modified']
        return True
    else:
        return False

class webcached(object):
    '''
    Decorator to enable conditional get. Add a lastModified method to the handler

    @param cacheCtrl: A string or a two-element tuple (CC for anonymous, CC for logged in user)
    '''
    def __init__(self, cacheCtrl='no-cache', vary=None, genEtag=True):
        self.cacheCtrl = (cacheCtrl, cacheCtrl) if isinstance(cacheCtrl, basestring) else cacheCtrl
        self.vary = vary
        self.genEtag = genEtag

    def __call__(self, f):
        @wraps(f)
        def wrapped(handler, *args):
            handler.lastModified = MethodType(_lastModified, handler, handler.__class__)

            try:
                f(handler, *args)
            except _ResponseNotModified:
                self._setHeader(handler)
                return

            if handler.response.status == 200:
                self._setHeader(handler)
                if self.genEtag and handler.response.headers.get('ETag') is None:
                    body = handler.response.out.getvalue()
                    if isinstance(body, unicode): body = body.encode('utf-8')
                    handler.response.headers['ETag'] = '"' + md5(body).hexdigest() + '"'
                _validate(handler)
            else:
                del handler.response.headers['Last-Modified']
                del handler.response.headers['ETag']

        return wrapped

    def _setHeader(self, handler):
        handler.response.headers['Cache-Control'] = self.cacheCtrl[1 if users.get_current_user() else 0]
        if self.vary: handler.response.headers['Vary'] = self.vary

########NEW FILE########
