__FILENAME__ = conf
# -*- coding: utf-8 -*-
#
# FeatureServer documentation build configuration file, created by
# sphinx-quickstart on Sat Dec 27 05:33:35 2008.
#
# This file is execfile()d with the current directory set to its containing dir.
#
# The contents of this file are pickled, so don't put values in the namespace
# that aren't pickleable (module imports are okay, they're removed automatically).
#
# All configuration values have a default; values that are commented out
# serve to show the default.

import sys, os

# If your extensions are in another directory, add it here. If the directory
# is relative to the documentation root, use os.path.abspath to make it
# absolute, like shown here.
#sys.path.append(os.path.abspath('.'))

# General configuration
# ---------------------

# Add any Sphinx extension module names here, as strings. They can be extensions
# coming with Sphinx (named 'sphinx.ext.*') or your custom ones.
extensions = []

# Add any paths that contain templates here, relative to this directory.
templates_path = ['_templates']

# The suffix of source filenames.
source_suffix = '.txt'

# The encoding of source files.
#source_encoding = 'utf-8'

# The master toctree document.
master_doc = 'index'

# General information about the project.
project = u'FeatureServer'
copyright = u'2008, Christopher Schmidt'

# The version info for the project you're documenting, acts as replacement for
# |version| and |release|, also used in various other places throughout the
# built documents.
#
# The short X.Y version.
version = '2.0'
# The full version, including alpha/beta/rc tags.
release = '2.0'

# The language for content autogenerated by Sphinx. Refer to documentation
# for a list of supported languages.
#language = None

# There are two options for replacing |today|: either, you set today to some
# non-false value, then it is used:
#today = ''
# Else, today_fmt is used as the format for a strftime call.
#today_fmt = '%B %d, %Y'

# List of documents that shouldn't be included in the build.
#unused_docs = []

# List of directories, relative to source directory, that shouldn't be searched
# for source files.
exclude_trees = ['_build']

# The reST default role (used for this markup: `text`) to use for all documents.
#default_role = None

# If true, '()' will be appended to :func: etc. cross-reference text.
#add_function_parentheses = True

# If true, the current module name will be prepended to all description
# unit titles (such as .. function::).
#add_module_names = True

# If true, sectionauthor and moduleauthor directives will be shown in the
# output. They are ignored by default.
#show_authors = False

# The name of the Pygments (syntax highlighting) style to use.
pygments_style = 'sphinx'


# Options for HTML output
# -----------------------

# The style sheet to use for HTML and HTML Help pages. A file of that name
# must exist either in Sphinx' static/ path, or in one of the custom paths
# given in html_static_path.
html_style = 'default.css'

# The name for this set of Sphinx documents.  If None, it defaults to
# "<project> v<release> documentation".
#html_title = None

# A shorter title for the navigation bar.  Default is the same as html_title.
#html_short_title = None

# The name of an image file (relative to this directory) to place at the top
# of the sidebar.
#html_logo = None

# The name of an image file (within the static path) to use as favicon of the
# docs.  This file should be a Windows icon file (.ico) being 16x16 or 32x32
# pixels large.
#html_favicon = None

# Add any paths that contain custom static files (such as style sheets) here,
# relative to this directory. They are copied after the builtin static files,
# so a file named "default.css" will overwrite the builtin "default.css".
html_static_path = ['_static']

# If not '', a 'Last updated on:' timestamp is inserted at every page bottom,
# using the given strftime format.
#html_last_updated_fmt = '%b %d, %Y'

# If true, SmartyPants will be used to convert quotes and dashes to
# typographically correct entities.
#html_use_smartypants = True

# Custom sidebar templates, maps document names to template names.
#html_sidebars = {}

# Additional templates that should be rendered to pages, maps page names to
# template names.
#html_additional_pages = {}

# If false, no module index is generated.
#html_use_modindex = True

# If false, no index is generated.
#html_use_index = True

# If true, the index is split into individual pages for each letter.
#html_split_index = False

# If true, the reST sources are included in the HTML build as _sources/<name>.
#html_copy_source = True

# If true, an OpenSearch description file will be output, and all pages will
# contain a <link> tag referring to it.  The value of this option must be the
# base URL from which the finished HTML is served.
#html_use_opensearch = ''

# If nonempty, this is the file name suffix for HTML files (e.g. ".xhtml").
#html_file_suffix = ''

# Output file base name for HTML help builder.
htmlhelp_basename = 'FeatureServerdoc'


# Options for LaTeX output
# ------------------------

# The paper size ('letter' or 'a4').
#latex_paper_size = 'letter'

# The font size ('10pt', '11pt' or '12pt').
#latex_font_size = '10pt'

# Grouping the document tree into LaTeX files. List of tuples
# (source start file, target name, title, author, document class [howto/manual]).
latex_documents = [
  ('index', 'FeatureServer.tex', ur'FeatureServer Documentation',
   ur'Christopher Schmidt', 'manual'),
]

# The name of an image file (relative to this directory) to place at the top of
# the title page.
#latex_logo = None

# For "manual" documents, if this is true, then toplevel headings are parts,
# not chapters.
#latex_use_parts = False

# Additional stuff for the LaTeX preamble.
#latex_preamble = ''

# Documents to append as an appendix to all manuals.
#latex_appendices = []

# If false, no module index is generated.
#latex_use_modindex = True

########NEW FILE########
__FILENAME__ = Simplify
import math

class Simplify(object):
    def __call__(self, features, tolerance=0.001, maxvertices=None):
        tolerance = float(tolerance)
        if not maxvertices is None: maxvertices = int(maxvertices)
        vertices=0
        for i, feature in enumerate(features):
            if feature['geometry']['type'] == "Point": 
                vertices += 1
                continue
            if feature['geometry']['type'] == "LineString":
                line = feature['geometry']['coordinates']
                new_line = simplify_points(line, tolerance)
                vertices += len(new_line)
                feature['geometry']['coordinates'] = new_line
            elif feature['geometry']['type'] == "Polygon":
                line = feature['geometry']['coordinates'][0]
                new_line = simplify_points(line, tolerance)
                vertices += len(new_line)
                feature['geometry']['coordinates'][0] = new_line
            feature.properties['processed_by'] = "Simplify (tolerance=%s, maxvertices=%s)" % (tolerance, maxvertices)
            if not maxvertices is None and vertices > maxvertices: 
                return features[:i + 1]
        return features 

# ported from
#   http://www.3dsoftware.com/Cartography/Programming/PolyLineReduction/
#   By Schuyler Erle
   
def simplify_points (pts, tolerance): 
    """
    >>> line = [[0,0],[1,0],[2,0],[2,1],[2,2],[1,2],[0,2],[0,1],[0,0]]
    >>> simplify_points(line, 1.0)
    [[0, 0], [2, 0], [2, 2], [0, 2], [0, 0]]
    
    >>> line = [[0,0],[0.5,0.5],[1,0],[1.25,-0.25],[1.5,.5]]
    >>> simplify_points(line, 0.25)
    [[0, 0], [0.5, 0.5], [1.25, -0.25], [1.5, 0.5]]
    
    """
    anchor  = 0
    floater = len(pts) - 1
    stack   = []
    keep    = set()

    stack.append((anchor, floater))  
    while stack:
        anchor, floater = stack.pop()
      
        # initialize line segment
        if pts[floater] != pts[anchor]:
            anchorX = float(pts[floater][0] - pts[anchor][0])
            anchorY = float(pts[floater][1] - pts[anchor][1])
            seg_len = math.sqrt(anchorX ** 2 + anchorY ** 2)
            # get the unit vector
            anchorX /= seg_len
            anchorY /= seg_len
        else:
            anchorX = anchorY = seg_len = 0.0
    
        # inner loop:
        max_dist = 0.0
        farthest = anchor + 1
        for i in range(anchor + 1, floater):
            dist_to_seg = 0.0
            # compare to anchor
            vecX = float(pts[i][0] - pts[anchor][0])
            vecY = float(pts[i][1] - pts[anchor][1])
            seg_len = math.sqrt( vecX ** 2 + vecY ** 2 )
            # dot product:
            proj = vecX * anchorX + vecY * anchorY
            if proj < 0.0:
                dist_to_seg = seg_len
            else: 
                # compare to floater
                vecX = float(pts[i][0] - pts[floater][0])
                vecY = float(pts[i][1] - pts[floater][1])
                seg_len = math.sqrt( vecX ** 2 + vecY ** 2 )
                # dot product:
                proj = vecX * (-anchorX) + vecY * (-anchorY)
                if proj < 0.0:
                    dist_to_seg = seg_len
                else:  # calculate perpendicular distance to line (pythagorean theorem):
                    dist_to_seg = math.sqrt(abs(seg_len ** 2 - proj ** 2))
                if max_dist < dist_to_seg:
                    max_dist = dist_to_seg
                    farthest = i

        if max_dist <= tolerance: # use line segment
            keep.add(anchor)
            keep.add(floater)
        else:
            stack.append([anchor, farthest])
            stack.append([farthest, floater])

    keep = list(keep)
    keep.sort()
    return [pts[i] for i in keep]

if __name__ == "__main__":
    import doctest
    doctest.testmod()

########NEW FILE########
__FILENAME__ = AppEngine
from FeatureServer.DataSource import DataSource
from FeatureServer.Service import Action 

from vectorformats.Feature import Feature
from vectorformats.Formats.WKT import to_wkt, from_wkt

from google.appengine.ext import db

geohash_support = False

try:
    from geohash import Geoindex
    geohash_support = True
except:
    pass

class FSModel(db.Expando):
    """Simple expando model for storing features."""
    geometry = db.TextProperty()
    geohash = db.StringProperty()

class AppEngine(DataSource):
    """Start on an AppEngine DataSource. No geographic search allowed.""" 
    
    query_action_types = ['lt', 'gt', 'gte', 'lte']
    
    query_action_string = {'lt': '<', 'gt': '>', 'gte': '>=', 'lte': '<='}

    def __init__(self, name, model = None, **args):
        DataSource.__init__(self, name, **args)
        self.model = model
        if self.model == None:
            self.model = FSModel
    
    def insert(self, action):
        props = {}
        for key, value in action.feature.properties.items():
            props[str(key)] = value
        obj = self.model(**props)
        obj.geometry = to_wkt(action.feature.geometry)
        if geohash_support:
            bbox = action.feature.get_bbox()
            union = Geoindex(bbox[0:2]) + Geoindex(bbox[2:])
            obj.geohash = str(union) 
        obj.save()
        action.id = int(obj.key().id())
        return self.select(action)
    
    def update(self, action):
        obj = self.model.get_by_id(int(action.id))
        obj.geometry = to_wkt(action.feature.geometry)
        for key, value in action.feature.properties.items():
            setattr(obj, str(key), value)
        if geohash_support:
            bbox = action.feature.get_bbox()
            union = Geoindex(bbox[0:2]) + Geoindex(bbox[2:])
            obj.geohash = str(union) 
        obj.save()
        action.id = int(obj.key().id())
        return self.select(action)

    def delete(self, action):
        obj = self.model.get_by_id(int(action.id))
        obj.delete()
        return []
    
    def select(self, action):
        obj_list = []    
        if action.id:
            obj = self.model.get_by_id(action.id)
            if obj:
                obj_list = [obj]
        else:
            obj_list = self.model.all()
            if action.bbox:
                if geohash_support:
                    bbox = action.bbox
                    hash1 = Geoindex(bbox[0:2])
                    hash2 = Geoindex(bbox[2:])
                    obj_list = obj_list.filter("geohash <=", str(hash2)).filter("geohash >=", str(hash1))
                else:
                    raise Exception("No GeoHash support -> No bbox support.")
                    
            if action.attributes:
                current_key = None
                for key, value in action.attributes.items():
                    if isinstance(value, dict):
                        obj_list.filter("%s %s" % (value['column'], self.query_action_string[value['type']]), value['value'])
                    else:
                        obj_list.filter("%s =" % key, value)
        return_list = []
        for obj in obj_list:    
            props = {}
            for key in obj.dynamic_properties():
                props[key] = getattr(obj, key)
            return_list.append(Feature(id=obj.key().id(), geometry=from_wkt(obj.geometry), srs=self.srid_out, props=props))
        return return_list    

########NEW FILE########
__FILENAME__ = AppEngineGeoModel
# Based on using GeoModel / GeoCell for storing locations (Point only!) 
# in appengine.  Has advantage over geohash idea because it doesn't require
# an inequality query, so you can use that on something else.

# requires all the geomodel files: util.py, geocell.py, geomath.py, geomodel.py
# from http://geomodel.googlecode.com/svn/trunk/geo/ - these should be under /geo


from FeatureServer.DataSource import DataSource
from FeatureServer.Service import Action 

from vectorformats.Feature import Feature
from vectorformats.Formats.WKT import to_wkt, from_wkt

from google.appengine.ext import db

from geo.geomodel import GeoModel
import geo.geotypes

import logging

class FSModel(GeoModel):
    """Simple model for storing features."""
    geometry = db.TextProperty()
    #put whatever other stuff you want here, and/or set GeoModel to subclass
    #from db.Expando and upload arbitrary attribs
    foo = db.TextProperty()
    

class AppEngineGeoModel(DataSource):
    """
    Uses GeoCell / GeoModel for location indexing
    """ 
    
    query_action_types = ['lt', 'gt', 'gte', 'lte', 'ne']
    query_action_string = {'lt': '<', 'gt': '>', 'gte': '>=', 'lte': '<=', 'ne' : '!='}

    def __init__(self, name, model = None, **args):
        DataSource.__init__(self, name, **args)
        self.model = model
        if self.model == None:
            self.model = FSModel

        self.excluded_fields = ['geometry','location']
        self.excluded_fields.extend(['location_geocell_' + str(x) for x in range(1,14)])
 
    def get_keyname(self, id):
        return 'kn_' + str(id)
    
    def insert(self, action):
        props = {}
        coords = action.feature.geometry['coordinates']
        for key, value in action.feature.properties.items():
            props[str(key)] = value
        props['location'] = db.GeoPt(coords[1],coords[0])
        obj = self.model(**props)
        obj.geometry = to_wkt(action.feature.geometry)
        try:
            obj.update_location()
        except:
            raise Exception(str([props['location'],obj.location]))
        try: obj.save()
        except: obj.save()
        if not action.id: 
            action.id = obj.key().id()
        return self.select(action)
    
    def update(self, action):
        #obj = self.model.get_by_id(int(action.id))
        kn = self.get_keyname(action.id)
        obj = self.model.get_by_key_name(kn)
        obj.geometry = to_wkt(action.feature.geometry)

        for key, value in action.feature.properties.items():
            setattr(obj, str(key), value)
        obj.update_location()
        try: obj.save()
        except: obj.save()
        #action.id = obj.key().id()
        return self.select(action)

    def delete(self, action):
        #obj = self.model.get_by_id(int(action.id))
        kn = self.get_keyname(action.id)
        obj = self.model.get_by_key_name(kn)
        obj.delete()
        return []
    
    def select(self, action):
        obj_list = []    
        max_features = action.maxfeatures or 1000
        if action.id:
            obj = self.model.get_by_id(action.id)
            if obj:
                obj_list = [obj]
        else:
            obj_list = self.model.all()
            if action.attributes:
                current_key = None
                for key, value in action.attributes.items():
                    if isinstance(value, dict):
                        obj_list = obj_list.filter("%s %s" % (value['column'], self.query_action_string[value['type']]), value['value'])
                    else:
                        try: value = int(value)
                        except: pass
                        obj_list = obj_list.filter("%s =" % key, value)
                        
                        
            if action.bbox: 
                #geocell likes N,E,S,W bbox with 
                W,S,E,N = action.bbox
                #also needs to be valid wgs84 coords
                W = max(W, -180)
                E = min(E, 180)
                S = max(S, -90)
                N = min(N, 90)
                obj_list = self.model.bounding_box_fetch(
                    obj_list, 
                    geotypes.Box(N,E,S,W),
                    max_results=max_features)
                    
        return_list = []
        for obj in obj_list[:max_features]:
            props = {}
            #get attribs for model
            for key in self.model.fields():
                if not key in self.excluded_fields:
                    try: props[key] = getattr(obj, key)
                    except: props[key] = None
            #get additional attribs for expando stuff
            for key in obj.dynamic_properties():
                    try: props[key] = getattr(obj, key)
                    except: props[key] = None
            try: geom = from_wkt(obj.geometry)
            except: 
                logging.error('fail on obj %s' % key)
                continue
            return_list.append(Feature(id=action.id, geometry=from_wkt(obj.geometry), srs=self.srid_out, props=props))
        return return_list    

########NEW FILE########
__FILENAME__ = DBM
__author__  = "MetaCarta"
__copyright__ = "Copyright (c) 2006-2008 MetaCarta"
__license__ = "Clear BSD" 
__version__ = "$Id: DBM.py 444 2008-03-19 01:35:35Z brentp $"

from FeatureServer.DataSource import DataSource
from FeatureServer.DataSource import Lock
from FeatureServer.Service.Action import Action
import anydbm
import UserDict

try:
    import cPickle as pickle
except ImportError:
    import pickle

class DBM (DataSource):
    """Simple datasource using the anydbm module and pickled datastructures."""
    def __init__(self, name, writable = 0, lockfile = None, unique = None, **args):
        DataSource.__init__(self, name, **args)
        self.db = Recno( args["file"] )
        self.append = self.db.append
        self.writable = int(writable)
        self.unique = unique
        if self.writable and lockfile:
            self.lock = Lock(lockfile)
        else:
            self.lock = None

    def __iter__ (self):
        return self.db.__iter__()

    def begin (self):
        if self.lock: return self.lock.lock()

    def commit (self):
        if hasattr(self.db, "sync"): self.db.sync()
        if self.lock: self.lock.unlock()

    def rollback (self):
        if self.lock: self.lock.unlock()

    def insert (self, action):
        if self.unique:
            action.id = self.insertUnique(action.feature)
        else:
            thunk = self.freeze_feature(action.feature)
            action.id = self.append(thunk)
        return self.select(action)
    
    def insertUnique(self, feature):
        if not feature.properties.has_key(self.unique):
           raise Exception("Unique key (%s) missing from feature." % self.unique)
        action = Action()
        action.attributes[self.unique] = feature.properties[self.unique]
        features = self.select(action)
        if len(features) > 1:
            raise Exception("There are two features with the unique key %s. Something's wrong with that." % feature.properties[self.unique])
        thunk = self.freeze_feature(feature)
        if len(features) == 0:
            return self.append(thunk)
        else:
            self.db[features[0].id] = thunk
            return features[0].id
    
    def update (self, action):
        self.db[action.id] = self.freeze_feature(action.feature)
        return self.select(action)
        
    def delete (self, action):
        feature = action.feature
        if action.id:
            del self.db[action.id]
        elif action.attributes:
            for feat in self.select(action):
                del self.db[feat.id]
        return []

    def select (self, action):
        def _overlap (a, b):
            return a[2] >= b[0] and \
                   b[2] >= a[0] and \
                   a[3] >= b[1] and \
                   b[3] >= a[1]

        if action.id is not None:
            feature = self.thaw_feature( self.db[action.id] )
            feature.id = action.id
            return [feature]
        else:
            result = []
            count  = action.maxfeatures
            counter = 0
            for id in self:
                if counter < action.startfeature:
                    counter += 1
                    continue
                thunk = self.db[id]
                feature = self.thaw_feature(thunk)
                feature.id = id
                if action.bbox and not _overlap(action.bbox, feature.bbox):
                    continue
                if action.attributes:
                    props = feature.properties
                    skip  = False
                    for key, val in action.attributes.items():
                        if (key not in props and val is not None) or \
                           (key in props and str(props[key]) != val):
                            skip = True
                            break
                    if skip: continue
                result.append(feature)
                if count is not None:
                    count -= 1
                    if not count: break
            return result

    def freeze_feature (self, feature):
        feature.bbox = feature.get_bbox()
        return pickle.dumps(feature)

    def thaw_feature (self, thunk):
        return pickle.loads(thunk)

class Recno (object):
    """Class to handle managment of the database file.""" 
    class Iterator (object):
        def __init__ (self, recno, idx = 0):
            self.recno = recno
            self.idx = self.recno.max + 1
            self.stopIdx = idx
        
        def __iter__ (self):
            return self

        def next (self):
            while True:
                self.idx -= 1
                if self.idx == 0 or self.idx == self.stopIdx:
                    raise StopIteration
                if not self.recno.has_key(self.idx):
                    continue
                return self.idx

    def __init__(self, file):
        self.file  = file
        self.max   = 0
        self.data  = None
        self.open()

    def __getitem__ (self, key):
        if not self.data:
            self.open()
        return self.data[str(key)]

    def __setitem__ (self, key, val):
        if not self.data:
            self.open()
        self.data[str(key)] = val
        if key > self.max: self.max = key

    def __delitem__ (self, key):
        if not self.data:
            self.open()
        del self.data[str(key)]

    def __len__ (self):
        if not self.data:
            self.open()
        return len(self.data)

    def __iter__ (self):
        return self.Iterator(self)

    def has_key (self, key):
        if not self.data:
            self.open()
        return self.data.has_key(str(key))

    def sync (self, reopen=True):
        if not self.data:
            self.open()
        self.data["_"] = str(self.max)
        del self.data
        self.data = None
        if reopen:
            self.data  = anydbm.open( self.file, "c" )

    def __del__ (self): 
        self.sync(False)

    def append (self, val):
        self.max += 1
        self.__setitem__(self.max, val)
        return self.max
    
    def open(self):
        self.data  = anydbm.open( self.file, "c" )
        if self.data.has_key("_"):
            self.max = int(self.data["_"])

########NEW FILE########
__FILENAME__ = Flickr
from FeatureServer.DataSource import DataSource
from vectorformats.Feature import Feature
from FeatureServer.Exceptions.NoGeometryException import NoGeometryException

import md5
import urllib
from lxml import etree

from StringIO import StringIO

class Flickr (DataSource):

    def __init__(self, name, api_key, api_secret, attributes = "*", srid_out = 4326, **args):
        DataSource.__init__(self, name, **args)
        self.api_key    = api_key
        self.api_secret = api_secret
        self.srid_out   = srid_out
        self.attributes = attributes
        
        self.api        = FlickrAPI(self.api_key, self.api_secret)
    
    def select (self, action):
        features = [] 
        if action.id is not None:
            data = self.api.request({'method':'flickr.photos.getInfo','photo_id':action.id})
            doc = etree.parse(StringIO(data)).getroot()
            photo = doc.xpath('/rsp/photo')[0]
            try:
                features.append(self.convert_photo(photo))
            except Exception as e:
                ''' '''
        
        else:
            params = {'method' : 'flickr.photos.search','extras':'description,owner_name,geo,tags,license'}
            
            if action.bbox:
                params['bbox'] = "%f,%f,%f,%f" % tuple(action.bbox)
            
            if hasattr(self, 'user_id'):
                params['user_id'] = self.user_id
                    
            if hasattr(self, 'tags'):
                params['tags'] = self.tags
                if hasattr(self, 'tag_mode'):
                    params['tag_mode'] = self.tag_mode
                else:
                    params['tag_mode'] = "any"
            
            data = self.api.request(params)
            
            doc = etree.parse(StringIO(data)).getroot()
            photos = [ photo for photo in doc.xpath('/rsp/photos')[0] ]
    
            for photo in photos:
                try:
                    features.append(self.convert_photo(photo))
                except Exception as e:
                    continue
        
        return features

    
    def convert_photo (self, xml):
        node_names = self.get_node_names(xml)
        
        props = {'img_url' : self.get_url(xml)}
        
        owners = xml.xpath('./owner')
        if len(owners) > 0:
            props['owner'] = owners[0].attrib['nsid']
            props['username'] = owners[0].attrib['username']
        for i in node_names:
            if i == "tags":
                tags = [ tag.text for tag in xml.xpath('./%s' % str(i))[0] ]
                props[i] = ",".join(tags)
                
            else:
                nodes = xml.xpath('./%s' % str(i))
                if len(nodes) > 0:
                    if len(list(nodes[0])) == 0:
                        if nodes[0].text is None:
                            props[i] = ""
                        else:
                            props[i] = nodes[0].text
        try:
            coordinates = self.get_coordinates(xml)
        except:
            raise
    
        return Feature(id=xml.attrib["id"], geometry={'type':"Point", 'coordinates':coordinates}, geometry_attr="geometry", srs=self.srid_out, props=props)

    def get_node_names(self, xml):
        if self.attributes == "*":
            props = [ child.tag for child in xml ]
        
            props.remove("location")
            props.remove("owner")
        else:
            props = self.attributes.split(',')
        
        return props

    def get_coordinates(self, xml):
        location = xml.xpath('./location')
        if len(location) > 0:
            loc = location[0]
            return [float(loc.attrib['longitude']), float(loc.attrib['latitude'])]
        
        if "longitude" in xml.attrib and "latitude" in xml.attrib:
            return [float(xml.attrib['longitude']), float(xml.attrib['latitude'])]


        raise NoGeometryException("Twitter", self.name)

    def get_url(self, xml):
        return "http://farm%s.static.flickr.com/%s/%s_%s_b.jpg" % (xml.attrib['farm'], xml.attrib['server'], xml.attrib['id'], xml.attrib['secret'])




class FlickrAPI:
    
    urls = {
        'xml' : 'http://api.flickr.com/services/rest/'
    }
    
    def __init__(self, api_key, api_secret):
        self.api_key    = api_key
        self.api_secret = api_secret

    def request(self, params = {}, format = "rest"):
        params['api_key'] = self.api_key
        params['format'] = format
        params['api_sig'] = self.signature(params)

        return urllib.urlopen(self.urls["xml"], urllib.urlencode(params)).read()


    def signature(self, params):
        items = []
        keys = params.keys()
        keys.sort()
        for key in keys:
            items.append("%s%s" % (key,params[key]))
        sign_string = "%s%s" % (self.api_secret, "".join(items))
        return md5.md5(sign_string).hexdigest()

    
    
########NEW FILE########
__FILENAME__ = GeoAlchemy
from FeatureServer.DataSource import DataSource
from vectorformats.Feature import Feature
from vectorformats.Formats import WKT
from sqlalchemy import create_engine, func
from sqlalchemy.sql import expression, visitors, operators
from sqlalchemy.orm import sessionmaker

import copy
import datetime

try:
    import decimal
except:
    pass
    
class GeoAlchemy (DataSource):
    """GeoAlchemy datasource. Setting up the table is beyond the scope of
       FeatureServer. However, GeoAlchemy supports table creation with
       geometry data types and can be used in a separate creation script."""

    query_action_types = ['eq', 'ne', 'lt', 'gt', 'ilike', 'like', 'gte', 'lte']

    query_operators = {
        'eq': operators.eq,
        'ne': operators.ne,
        'lt': operators.lt,
        'gt': operators.gt,
        'lte': operators.le,
        'gte': operators.ge
    }

    def __init__(self, name, srid=4326, srid_out=4326, fid="gid", geometry="the_geom",
            order="", attribute_cols='*', writable=True, encoding="utf-8",
            geom_cls=None, geom_rel=None, join_condition=None, sql_echo=False,
            session=None, **args):
        DataSource.__init__(self, name, **args)
        self.dburi          = args["dburi"]
        self.sql_echo       = sql_echo
        self.session        = session
        self.model          = args["model"]
        self.cls            = args["cls"]
        self.fid_col        = fid
        self.geom_col       = geometry
        self.geom_rel       = geom_rel
        self.geom_cls       = geom_cls
        self.join_condition = join_condition
        self.order          = order
        self.srid           = srid
        self.srid_out       = srid_out
        self.writable       = writable
        self.encoding       = encoding
        self.attribute_cols = attribute_cols

        if not self.session:
            self.engine = create_engine(self.dburi, echo=self.sql_echo)
            self.session = sessionmaker(bind=self.engine)()

    def feature_predicate(self, key, operator_name, value):
        if operator_name == 'like':
            return key.like('%'+value+'%')
        elif operator_name == 'ilike':
            return key.ilike('%'+value+'%')
        else:
            return self.query_operators[operator_name](key,value)

    def bbox2wkt(self, bbox):
        return "POLYGON((%s %s, %s %s, %s %s, %s %s, %s %s))" % (bbox[1],
        bbox[0],bbox[1],bbox[2],bbox[3],bbox[2],bbox[3],bbox[0],bbox[1],bbox[0])

    def begin (self):
        pass

    def commit (self):
        if self.writable:
            self.session.commit()

    def rollback (self):
        if self.writable:
            self.session.rollback()

    def insert (self, action):
        model = __import__(self.model, fromlist=['*'])
        cls = getattr(model, self.cls)
        feature = action.feature
        obj =  cls()
        for prop in feature.properties.keys():
            setattr(obj, prop, feature.properties[prop])
        if self.geom_rel and self.geom_cls:
            geom_cls = getattr(model, self.geom_cls)
            geom_obj = geom_cls()
            setattr(geom_obj, self.geom_col, WKT.to_wkt(feature.geometry))
            try:
                getattr(obj, self.geom_rel).append(geom_obj)
            except:
                # Handle specific exception
                setattr(obj, self.geom_rel, geom_obj)
            self.session.add(geom_obj)
        elif feature.geometry:
            setattr(obj, self.geom_col, WKT.to_wkt(feature.geometry))
        else:
            pass
        self.session.add(obj)
        return self.select(action)
        

    def update (self, action):
        model = __import__(self.model, fromlist=['*'])
        cls = getattr(model, self.cls)
        feature = action.feature
        obj = self.session.query(cls).get(int(action.id))
        for prop in feature.properties.keys():
            setattr(obj, prop, feature.properties[prop])
        if self.geom_rel and self.geom_cls:
            geom_obj = getattr(obj, self.geom_rel)
            setattr(geom_obj, self.geom_col, WKT.to_wkt(feature.geometry))
            self.session.add(geom_obj)
        elif feature.geometry:
            setattr(obj, self.geom_col, WKT.to_wkt(feature.geometry))
        else:
            pass
        self.session.add(obj)
        return self.select(action)
        
    def delete (self, action):
        model = __import__(self.model, fromlist=['*'])
        cls = getattr(model, self.cls)
        obj = self.session.query(cls).get(action.id)
        if self.geom_rel and self.geom_col:
            geom_obj = getattr(obj, self.geom_rel)
            if isinstance(geom_obj, (tuple, list, dict, set)):
                #TODO Should all related objects be purged
                self.session.delete(geom_obj[-1])
            else:
                self.session.delete(geom_obj)
        self.session.delete(obj)
        return []

    def select (self, action):
        model = __import__(self.model, fromlist=['*'])
        cls = getattr(model, self.cls)
        geom_cls = None
        if self.geom_cls:
            geom_cls = getattr(model, self.geom_cls)
        if action.id is not None:
            result = [self.session.query(cls).get(action.id)]
        else:
            if self.geom_rel and self.geom_cls:
                main_table = cls.__tablename__
                geom_table = geom_cls.__tablename__
                join_condition = self.join_condition or "%s.%s_id=%s.id" % (
			main_table, geom_table, geom_table)
                query = self.session.query(cls, geom_cls).filter(join_condition)
            else:
                query = self.session.query(cls)
            if action.attributes:
                query = query.filter(
                    expression.and_(
                        *[self.feature_predicate(getattr(cls, v['column']), v['type'], v['value'])
                          for k, v in action.attributes.iteritems()]
                    )
                )
            if action.bbox:
                if self.geom_rel and self.geom_cls:
                    geom_element = getattr(geom_cls, self.geom_col)
                else:
                    geom_element = getattr(cls, self.geom_col)
                query = query.filter(geom_element.intersects(
                    self.session.scalar(func.GeomFromText(
                        self.bbox2wkt(action.bbox), self.srid)
                    )
                ))
            if self.order:
                query = query.order_by(getattr(cls, self.order))
            if action.maxfeatures:
                query.limit(action.maxfeatures)
            else:   
                query.limit(1000)
            if action.startfeature:
                query.offset(action.startfeature)
            
            result = query.all()

        features = []
        for row_tuple in result:
            props = {}
            id = None
            geom = None
            if not isinstance(row_tuple, (tuple, list, dict, set)):
                row_tuple = (row_tuple,)
            for  row in row_tuple:
                if isinstance(row, cls):
                    cols = cls.__table__.c.keys()
                    for col in cols:
                        if col == self.fid_col:
                            id = getattr(row, col)
                        elif col == self.geom_col:
                            geom = WKT.from_wkt(self.session.scalar(getattr(row, col).wkt))
                        else:
                            if self.attribute_cols == '*' or col in self.attribute_cols:
                                props[col] = getattr(row, col)
                elif isinstance(row, geom_cls) and geom_cls:
                    cols = geom_cls.__table__.c.keys()
                    for col in cols:
                        if col == self.fid_col:
                            pass
                        elif col == self.geom_col:
                            geom = WKT.from_wkt(self.session.scalar(getattr(row, col).wkt))
                        else:
                            if self.attribute_cols == '*' or col in self.attribute_cols:
                                props[col] = getattr(row, col)
                else:
                    continue

            for key, value in props.items():
                if isinstance(value, str): 
                    props[key] = unicode(value, self.encoding)
                elif isinstance(value, datetime.datetime) or isinstance(value, datetime.date):
                    # stringify datetimes 
                    props[key] = str(value)
                    
                try:
                    if isinstance(value, decimal.Decimal):
                        props[key] = unicode(str(value), self.encoding)
                except:
                    pass
                    
            if (geom):
                features.append( Feature( id=id, geometry=geom, geometry_attr=self.geom_col, srs=self.srid_out, props=props ) ) 
        return features

########NEW FILE########
__FILENAME__ = OGR
__author__  = "MetaCarta"
__copyright__ = "Copyright (c) 2006-2008 MetaCarta"
__license__ = "Clear BSD" 
__version__ = "$Id: OGR.py 617 2009-10-06 18:10:49Z jlivni $"

from FeatureServer.DataSource import DataSource
from FeatureServer.DataSource import Lock
from vectorformats.Feature import Feature

try:
    from osgeo import ogr
    from osgeo import osr
except:
    import ogr
    import osr

class OGR (DataSource):
    """Uses the ogr Python bindings to query/update/delete an OGR 
       datasource. Feature support is limited in the same way as 
       OGR's underlying datasource.""" 
    freeze_type = {
        ogr.wkbPoint            : "Point",
        ogr.wkbLineString       : "LineString",
        ogr.wkbPolygon          : "Polygon",
        ogr.wkbMultiPoint       : "Point",
        ogr.wkbMultiLineString  : "LineString",
        ogr.wkbMultiPolygon     : "Polygon"
    }
    # thaw_type = dict(map(lambda (x,y): (y,x), freeze_type.items()))
    thaw_type = {
        "Point"     : ogr.wkbPoint,
        "LineString": ogr.wkbLineString,
        "Polygon"   : ogr.wkbPolygon
    }
    error_msgs = [
        "OK",
        "Not enough data",
        "Not enough memory",
        "Unsupported geometry type",
        "Unsupported operation",
        "Corrupt data",
        "Unknown failure",
        "Unsupported SRS"
    ]

    def __init__(self, name, writable = 0, lockfile = 0, 
                 dsn = None, layer = None, attribute_cols = '', **args):
        DataSource.__init__(self, name, **args)
        if int(writable) and lockfile: 
            self.lock = Lock(lockfile)
        else:
            self.lock = None
        self.ds     = ogr.Open( dsn, int(writable) )
        if layer:
            self.layer  = self.ds.GetLayerByName(layer)
        else:
            self.layer  = self.ds.GetLayer(0)
        self.defn   = self.layer.GetLayerDefn()
        self.fields = [self.defn.GetFieldDefn(i)
                        for i in range(self.defn.GetFieldCount())]
        if attribute_cols:
            self.attribute_cols = [x.lower() for x in attribute_cols.split(',')]
        else:
            self.attribute_cols = None
    
    def insert (self, action):
        feature = self.thaw_feature(action.feature)
        err = self.layer.CreateFeature(feature)
        if err:
            raise ogr.OGRError("Create error: %s" % self.error_msgs[err])
        action.id = feature.GetFID()
        feature.Destroy()
        if action.id > 0: # because the OGR PostGIS driver sux
            return self.select(action)
        else:
            action.feature.id = action.id
            return [action.feature]

    def update (self, action):
        feature = self.thaw_feature(action.feature)
        feature.SetFID(action.id)
        err = self.layer.SetFeature(feature)
        if err:
            raise ogr.OGRError("Update error on FID %d: %s"
                                % (action.id, self.error_msgs[err]))
        feature.Destroy()
        return self.select(action)
        
    def delete (self, action):
        err = self.layer.DeleteFeature(action.id)
        if err:
            raise ogr.OGRError("Delete error on FID %d: %s"
                                % (action.id, self.error_msgs[err]))
        return []

    def select (self, action):
        result = []
        if action.id is not None:
            feature = self.layer.GetFeature(action.id)
            if not feature:
                raise Exception("No such feature. (%s)" % action.id)
            result.append( feature )
        else:
            if action.bbox:
                self.layer.SetSpatialFilterRect(*action.bbox)
            else:
                self.layer.SetSpatialFilter(None)
            if action.attributes:
                query = []
                for keyval in action.attributes.items():
                    query.append("( %s = '%s' )" % keyval)
                query = " AND ".join(query)
            else:
                query = None
            self.layer.SetAttributeFilter(query)

            feature = True
            count = action.maxfeatures
            if not count:
                count = 1000
            counter = 0
            self.layer.ResetReading()
            while feature:
                feature = self.layer.GetNextFeature()
                if not feature: break
                if counter < action.startfeature:
                    counter += 1
                    continue
                result.append(feature)
                if count is not None:
                    count -= 1
                    if not count: break
                

        return self.freeze_features(result)

    def begin (self):
        if self.lock: return self.lock.lock()

    def commit (self):
        self.layer.SyncToDisk()
        if self.lock: self.lock.unlock()

    def thaw_feature (self, feature):
        def thaw_points (ogrgeom, coords):
            for coord in coords: ogrgeom.AddPoint(*coord)

        geom = feature.geometry
        if geom["type"] not in self.thaw_type:
            raise ogr.OGRError(
                "Geometry type %d not supported by FeatureServer"
                % geom["type"]);

        geomtype = self.thaw_type[geom["type"]]
        ogrgeom = ogr.Geometry( type = geomtype )

        coordinates = geom["coordinates"]
        if geomtype == ogr.wkbPoint:
            thaw_points( ogrgeom, [coordinates] )
        elif geomtype == ogr.wkbLineString:
            thaw_points( ogrgeom, coordinates )
        elif geomtype == ogr.wkbPolygon:
            for coords in coordinates:
                ring = ogr.Geometry( type = ogr.wkbLinearRing )
                thaw_points( ring, coords )
                ogrgeom.AddRingDirectly(ring)
            ogrgeom.closeRings()
        else:
            raise Exception("Unsupported geometry type")
        
        ogrfeature = ogr.Feature(self.defn)
        ogrfeature.SetGeometryDirectly(ogrgeom)
        for key, val in feature.properties.items():
            key = ogrfeature.GetFieldIndex(key)
            ogrfeature.SetField( key, val )

        return ogrfeature

    def _freeze_geometry (self, geom):
        def freeze_points (geom):
            coords = []
            for i in range(geom.GetPointCount()):
                coords.append([geom.GetX(i), geom.GetY(i)])
            return coords
            
        geomtype = geom.GetGeometryType() & ~ogr.wkb25Bit
        # throw away all but the first geometry in a multigeom
        # sorry!
        if geomtype in (ogr.wkbMultiPoint,
                        ogr.wkbMultiLineString,
                        ogr.wkbMultiPolygon):
            geom = geom.GetGeometryRef(0)

        if geomtype not in self.freeze_type:
            raise ogr.OGRError(
                "Geometry type %d not supported by FeatureServer"
                % geomtype);
                
        frozen_type = self.freeze_type[geomtype]
        if frozen_type == "Point":
            points = freeze_points(geom)
            if len(points) == 1:
                coords = points[0]
        elif frozen_type == "LineString":
            coords = freeze_points(geom)
        elif frozen_type == "Polygon":
            coords = []
            for i in range(geom.GetGeometryCount()):
                coords.append( freeze_points( geom.GetGeometryRef(i) ) )

        return {'type': frozen_type, 'coordinates': coords}

    freeze_geometry = classmethod(_freeze_geometry)

    def freeze_features (self, features):
        result = []
        for ogrfeat in features:
            feat = Feature(ogrfeat.GetFID())

            geom = ogrfeat.GetGeometryRef()
            feat.geometry = OGR.freeze_geometry(geom)

            for n, defn in enumerate(self.fields):
                key = defn.GetName()
                if self.attribute_cols and not key.lower() in self.attribute_cols:
                    continue
                value = ogrfeat.GetField(n)
                if isinstance(value, str): value = unicode(value, "utf-8")
                feat.properties[key] = value 

            result.append(feat)
            ogrfeat.Destroy() 

        return result

########NEW FILE########
__FILENAME__ = OSM
__author__  = "MetaCarta"
__copyright__ = "Copyright (c) 2006-2008 MetaCarta"
__license__ = "Clear BSD" 
__version__ = "$Id: Twitter.py 412 2008-01-01 08:15:59Z crschmidt $"

from FeatureServer.DataSource import DataSource
from vectorformats.Feature import Feature

import urllib
import xml.dom.minidom

class OSM (DataSource):
    """Specialized datasource allowing read-only access to OpenStreetMap"""
    
    osmxapi_url = "http://www.informationfreeway.org/api/0.5/"    
    
    def __init__(self, name, osmxapi="false", uninteresting_tags = "attribution,created_by", **args):
        DataSource.__init__(self, name, **args)
        self.uninteresting_tags = uninteresting_tags.split(",")
        self.osmxapi = osmxapi.lower() in ("true", "1", "yes") 
        
    def select (self, action):
        """Load data from one of the OpenStreetMap APIs using urllib.""" 
        if self.osmxapi:
            data = self.select_osmxapi(action)
        else:
            data = self.select_main(action)
        
        doc = xml.dom.minidom.parseString(data)
        nodes = {}
        features = []
        for node in doc.getElementsByTagName("node"):
            properties = {}
            interesting = False
            for tag in node.getElementsByTagName("tag"):
                key = tag.getAttribute("k")
                properties[key] = tag.getAttribute("v")
                if not key in self.uninteresting_tags:
                    interesting = True
                    
            id = int(node.getAttribute("id"))
            nodes[id] = [float(node.getAttribute("lon")), float(node.getAttribute("lat"))]
            if interesting == True:
                geom = {'type':'Point', 'coordinates':nodes[id]}
                features.append(Feature(id=id, geometry=geom, srs=self.srid_out, props=properties))
        
        for way in doc.getElementsByTagName("way"):
            geometry = {'type':'LineString', 'coordinates':[]}
            for nd in way.getElementsByTagName('nd'):
                geometry['coordinates'].append(nodes[int(nd.getAttribute("ref"))])
            properties = {}
            
            for tag in way.getElementsByTagName("tag"):
                key = tag.getAttribute("k")
                properties[key] = tag.getAttribute("v")
            
            features.append(Feature(id=int(way.getAttribute("id")), geometry=geometry, srs=self.srid_out, props=properties))
        
        return features
    
    def select_osmxapi(self, action):
        """Talking to osmxapi, either with an attribute or bbox query (or both)."""
        if action.id:
            return self.select_main(action)
        else:
            predicates = []
            for key, value in action.attributes.items():
                predicates.append("[%s=%s]" % (key, value))
            if action.bbox:
                predicates.append("[bbox=%s]" % ",".join(map(str, action.bbox)))
            
            url = "%sway%s" % (self.osmxapi_url, "".join(predicates))
            return urllib.urlopen(url).read()
            
    def select_main(self, action):
        """Talking to the main API, openstreetmap.org."""
        if action.id:
            urldata = urllib.urlopen("http://openstreetmap.org/api/0.5/way/%s/full" % action.id)
        elif action.bbox: 
            urldata = urllib.urlopen("http://openstreetmap.org/api/0.5/map?bbox=%s" % ",".join(map(str, action.bbox)))
        else:
            raise Exception("Only bounding box queries or queries for way-by-ID are acceptable.")
        data = urldata.read()    
        if len(data) == 1:
            raise Exception("OSM Server Error: %s" % urldata.info().get('error'))
        return data

########NEW FILE########
__FILENAME__ = PostGIS
__author__  = "MetaCarta"
__copyright__ = "Copyright (c) 2006-2008 MetaCarta"
__license__ = "Clear BSD" 
__version__ = "$Id: PostGIS.py 615 2009-09-23 00:47:48Z jlivni $"

from psycopg2 import errorcodes

from FeatureServer.DataSource import DataSource
from vectorformats.Feature import Feature
from vectorformats.Formats import WKT

from FeatureServer.WebFeatureService.Response.InsertResult import InsertResult
from FeatureServer.WebFeatureService.Response.UpdateResult import UpdateResult
from FeatureServer.WebFeatureService.Response.DeleteResult import DeleteResult
from FeatureServer.WebFeatureService.Response.ReplaceResult import ReplaceResult

from FeatureServer.Exceptions.WebFeatureService.InvalidValueException import InvalidValueException
from FeatureServer.Exceptions.ConnectionException import ConnectionException

try:
    import psycopg2 as psycopg
    
except:
    import psycopg

import copy
import re
import datetime

try:
    import decimal
except:
    pass
    
class PostGIS (DataSource):
    """PostGIS datasource. Setting up the table is beyond the scope of
       FeatureServer."""
    
    query_action_types = ['lt', 'gt', 'ilike', 'like', 'gte', 'lte']

    query_action_sql = {'lt': '<', 'gt': '>', 
                        'ilike': 'ilike', 'like':'like',
                        'gte': '>=', 'lte': '<=',
                        'eq': '='}
     
    def __init__(self, name, srid = 4326, srid_out = 4326, fid = "gid", geometry = "the_geom", fe_attributes = 'true', order = "", attribute_cols = '*', writable = True, encoding = "utf-8", hstore = 'false', hstore_attr = "", **args):
        DataSource.__init__(self, name, **args)
        self.table          = args["layer"]
        self.fid_col        = fid
        self.encoding       = encoding
        self.geom_col       = geometry
        self.order          = order
        self.srid           = srid
        self.srid_out       = srid_out
        self.db             = None
        self.dsn            = args["dsn"]
        self.writable       = writable
        self.attribute_cols = attribute_cols
        
        self.fe_attributes = True
        if fe_attributes.lower() == 'false':
            self.fe_attributes  = False

        if hstore.lower() == 'true':
            self.hstore = True
            self.hstoreAttribute = hstore_attr
        else:
            self.hstore = False
            self.hstoreAttribute = "";

    def begin (self):
        try:
            self.db = psycopg.connect(self.dsn)
        except Exception as e:
            raise ConnectionException(**{'dump':str(e),'layer':self.name,'locator':'PostGIS','code':e.pgcode})
    
    def commit (self):
        if self.writable:
            self.db.commit()
        self.db.close()

    def rollback (self):
        if self.writable:
            self.db.rollback()
        self.db.close()

    def column_names (self, feature):
        return feature.properties.keys()

    def value_formats (self, feature):
        values = ["%%(%s)s" % self.geom_col]
        values = []
        for key, val in feature.properties.items():
            valtype = type(val).__name__
            if valtype == "dict":
                val['pred'] = "%%(%s)s" % (key,)
                values.append(val)
            else:
                fmt     = "%%(%s)s" % (key, )
                values.append(fmt)
        return values

    def feature_predicates (self, feature):
        columns = self.column_names(feature)
        values  = self.value_formats(feature)
        predicates = []
        for pair in zip(columns, values):
            if pair[0] != self.geom_col:
                if isinstance(pair[1], dict):
                    # Special Query: pair[0] is 'a', pair[1] is {'type', 'pred', 'value'}
                    # We build a Predicate here, then we replace pair[1] with pair[1] value below
                    if pair[1].has_key('value'):
                        predicates.append("%s %s %s" % (pair[1]['column'], 
                                                        self.query_action_sql[pair[1]['type']],
                                                        pair[1]['pred']))

                else:
                    predicates.append("%s = %s" % pair)
        if feature.geometry and feature.geometry.has_key("coordinates"):
            predicates.append(" %s = ST_SetSRID('%s'::geometry, %s) " % (self.geom_col, WKT.to_wkt(feature.geometry), self.srid))
        return predicates

    def feature_values (self, feature):
        props = copy.deepcopy(feature.properties)
        for key, val in props.iteritems():
            if type(val) is unicode: ### b/c psycopg1 doesn't quote unicode
                props[key] = val.encode(self.encoding)
            if type(val)  is dict:
                props[key] = val['value']
        return props


    def id_sequence (self):
        return self.table + "_" + self.fid_col + "_seq"
    
    def insert (self, action):
        self.begin()
        if action.feature != None:
            feature = action.feature
            columns = ", ".join(self.column_names(feature)+[self.geom_col])
            values = ", ".join(self.value_formats(feature)+["ST_SetSRID('%s'::geometry, %s) " % (WKT.to_wkt(feature.geometry), self.srid)])

            sql = "INSERT INTO \"%s\" (%s) VALUES (%s)" % (self.table, columns, values)

            cursor = self.db.cursor()
            cursor.execute(str(sql), self.feature_values(feature))

            cursor.execute("SELECT currval('%s');" % self.id_sequence())
            action.id = cursor.fetchone()[0]
            
            return InsertResult(action.id, "")
        
        elif action.wfsrequest != None:
            sql = action.wfsrequest.getStatement(self)
            
            cursor = self.db.cursor()
            cursor.execute(str(sql))
            
            cursor.execute("SELECT currval('%s');" % self.id_sequence())
            action.id = cursor.fetchone()[0]
            
            return InsertResult(action.id, "")
                        
        return None
        

    def update (self, action):
        if action.feature != None:
            feature = action.feature
            predicates = ", ".join( self.feature_predicates(feature) )

            sql = "UPDATE \"%s\" SET %s WHERE %s = %d" % ( self.table, predicates, self.fid_col, action.id )

            cursor = self.db.cursor()
            cursor.execute(str(sql), self.feature_values(feature))
            
            return UpdateResult(action.id, "")
        
        elif action.wfsrequest != None:
            sql = action.wfsrequest.getStatement(self)
            
            cursor = self.db.cursor()
            cursor.execute(str(sql))

            return UpdateResult(action.id, "")
            
        return None
        
    def delete (self, action):
        if action.feature != None:
            sql = "DELETE FROM \"%s\" WHERE %s = %%(%s)d" % ( self.table, self.fid_col, self.fid_col )
            cursor = self.db.cursor()
            
            try:
                cursor.execute(str(sql) % {self.fid_col: action.id})
            except:    
                cursor.execute(str(sql), {self.fid_col: action.id})
            
            return DeleteResult(action.id, "")
        
        elif action.wfsrequest != None:
            sql = action.wfsrequest.getStatement(self)
            cursor = self.db.cursor()
            try:
                cursor.execute(str(sql) % {self.fid_col: action.id})
            except:    
                cursor.execute(str(sql), {self.fid_col: action.id})
            
            return DeleteResult(action.id, "")
            
        return None


    def select (self, action):
        cursor = self.db.cursor()

        if action.id is not None:
            sql = "SELECT ST_AsText(ST_Transform(%s, %d)) as fs_text_geom, " % (self.geom_col, int(self.srid_out))
            
            if hasattr(self, 'version'):
                sql += "%s as version, " % self.version
            if hasattr(self, 'ele'):
                sql += "%s as ele, " % self.ele
            
            sql += "\"%s\"" % self.fid_col
            
            if len(self.attribute_cols) > 0:
                sql += ", %s" % self.attribute_cols
            
            if hasattr(self, "additional_cols"):
                cols = self.additional_cols.split(';')
                additional_col = ",".join(cols)
                sql += ", %s" % additional_col

            sql += " FROM \"%s\" WHERE %s = %%(%s)s" % (self.table, self.fid_col, self.fid_col)
            
            #sql = "SELECT ST_AsText(ST_Transform(%s, %d)) as fs_text_geom, %s as ele, %s as version, \"%s, %s FROM \"%s\" WHERE %s = %%(%s)s" % (
            #        self.geom_col, int(self.srid_out), self.ele, self.version, self.fid_col, self.attribute_cols, self.table, self.fid_col, self.fid_col )

            cursor.execute(str(sql), {self.fid_col: str(action.id)})

            result = [cursor.fetchone()]
        else:
            filters = []
            attrs   = {}
            if action.attributes:
                match = Feature(props = action.attributes)
                filters = self.feature_predicates(match)
                for key, value in action.attributes.items():
                    if isinstance(value, dict):
                        attrs[key] = value['value']
                    else:
                        attrs[key] = value
            if action.bbox:
                filters.append( "%s && ST_Transform(ST_SetSRID('BOX3D(%f %f,%f %f)'::box3d, %s), %s) AND ST_Intersects(%s, ST_Transform(ST_SetSRID('BOX3D(%f %f,%f %f)'::box3d, %s), %s))" % (
                                        (self.geom_col,) + tuple(action.bbox) + (self.srid_out,) + (self.srid,) + (self.geom_col,) + (tuple(action.bbox) + (self.srid_out,) + (self.srid,))))
            sql = "SELECT ST_AsText(ST_Transform(%s, %d)) as fs_text_geom, " % (self.geom_col, int(self.srid_out))
            if hasattr(self, 'ele'):
                sql += "%s as ele, " % self.ele
            if hasattr(self, 'version'):
                sql += "%s as version, " % self.version
            sql += "\"%s\"" % self.fid_col
    
            if len(self.attribute_cols) > 0:
                sql += ", %s" % self.attribute_cols
            
            # check OGC FE attributes
            if self.fe_attributes and action.wfsrequest:
                fe_cols = action.wfsrequest.getAttributes()
                ad_cols = self.getColumns()
                
                fe_cols = filter(lambda x: x not in ad_cols, fe_cols)
                
                if len(fe_cols) > 0:
                    sql += ", %s" % ",".join(fe_cols)
    
            if hasattr(self, "additional_cols"):
                cols = self.additional_cols.split(';')
                additional_col = ",".join(cols)
                sql += ", %s" % additional_col


            sql += " FROM \"%s\"" % (self.table)
            
            #sql = "SELECT ST_AsText(Transform(%s, %d)) as fs_text_geom, %s as ele, %s as version, \"%s\", %s FROM \"%s\"" % (self.geom_col, int(self.srid_out), self.ele, self.version, self.fid_col, self.attribute_cols, self.table)
            if filters:
                sql += " WHERE " + " AND ".join(filters)
            if action.wfsrequest:
                if filters:
                    sql += " AND "
                else:
                    sql += " WHERE "
                
                sql += action.wfsrequest.render(self)
                
                
            if self.order:
                sql += " ORDER BY " + self.order
            if action.maxfeatures:
                sql += " LIMIT %d" % action.maxfeatures
            #else:   
            #    sql += " LIMIT 1000"
            if action.startfeature:
                sql += " OFFSET %d" % action.startfeature
                        
            try:
                cursor.execute(str(sql), attrs)
            except Exception, e:
                if e.pgcode[:2] == errorcodes.CLASS_SYNTAX_ERROR_OR_ACCESS_RULE_VIOLATION:
                    raise InvalidValueException(**{'dump':e.pgerror,'layer':self.name,'locator':'PostGIS'})
                
            result = cursor.fetchall() # should use fetchmany(action.maxfeatures)
        
        columns = [desc[0] for desc in cursor.description]
        features = []
        for row in result:
            props = dict(zip(columns, row))
            if not props['fs_text_geom']: continue
            geom  = WKT.from_wkt(props['fs_text_geom'])
            id = props[self.fid_col]
            del props[self.fid_col]
            if self.attribute_cols == '*':
                del props[self.geom_col]
            del props['fs_text_geom']
            for key, value in props.items():
                if isinstance(value, str): 
                        props[key] = unicode(value, self.encoding)
                elif isinstance(value, datetime.datetime) or isinstance(value, datetime.date):
                    # stringify datetimes 
                    props[key] = str(value)
                    
                try:
                    if isinstance(value, decimal.Decimal):
                            props[key] = unicode(str(value), self.encoding)
                except:
                    pass
                    
            if (geom):
                features.append( Feature( id, geom, self.geom_col, self.srid_out, props ) ) 
        return features
            
    def getColumns(self):
        cols = []
        
        if hasattr(self, 'attribute_cols'):
            cols = self.attribute_cols.split(",")
                
        cols.append(self.geom_col)
        cols.append(self.fid_col)
                
        if hasattr(self, 'version'):
            cols.append(self.version)
        if hasattr(self, 'ele'):
            cols.append(self.ele)
                
        return cols

    
    def getAttributeDescription(self, attribute):
        self.begin()
        cursor = self.db.cursor()
        result = []

        sql = "SELECT t.typname AS type, a.attlen AS length FROM pg_class c, pg_attribute a, pg_type t "
        sql += "WHERE c.relname = '%s' and a.attname = '%s' and a.attnum > 0 and a.attrelid = c.oid and a.atttypid = t.oid ORDER BY a.attnum"
        
        try:
            cursor.execute(str(sql)% (self.table, attribute))
            result = [cursor.fetchone()]
            self.db.commit()
        except:
            pass 
        
        type = 'string'
        length = ''
        
        if len(result) > 0:
            if result[0]:
                if str((result[0])[0]).lower().startswith('int'):
                    type = 'integer'
                    if int((result[0])[1]) == 4:
                        length = ''
        
        return (type, length)

########NEW FILE########
__FILENAME__ = SpatialLite
'''
Created on Oct 22, 2012
    
@author: michel
'''

import os

from FeatureServer.DataSource import DataSource
from vectorformats.Feature import Feature
from vectorformats.Formats import WKT

from FeatureServer.WebFeatureService.Response.InsertResult import InsertResult
from FeatureServer.WebFeatureService.Response.UpdateResult import UpdateResult
from FeatureServer.WebFeatureService.Response.DeleteResult import DeleteResult
from FeatureServer.WebFeatureService.Response.ReplaceResult import ReplaceResult


from pyspatialite import dbapi2 as db

import datetime

from FeatureServer.Exceptions.ConnectionException import ConnectionException


class SpatialLite (DataSource):
    
    query_action_types = ['lt', 'gt', 'ilike', 'like', 'gte', 'lte']
    
    query_action_sql = {'lt': '<', 'gt': '>',
        'ilike': 'ilike', 'like':'like',
        'gte': '>=', 'lte': '<='}

    def __init__(self, name, file, fid = "gid", geometry = "geometry", fe_attributes = 'true', order = "", srid = 4326, srid_out = 4326, encoding = "utf-8", writable = True, attribute_cols = "*", **kwargs):
        DataSource.__init__(self, name, **kwargs)
        self.file           = file
        self.table          = kwargs["layer"]
        self.fid_col        = fid
        self.geom_col       = geometry
        self.srid           = srid
        self.srid_out       = srid_out
        self.writable       = writable
        self.attribute_cols = attribute_cols
        self.order          = order
        self.encoding       = encoding

        self.fe_attributes = True
        if fe_attributes.lower() == 'false':
            self.fe_attributes  = False
    

    def column_names (self, feature):
        return feature.properties.keys()
    
    def value_formats (self, feature):
        values = ["%%(%s)s" % self.geom_col]
        values = []
        for key, val in feature.properties.items():
            valtype = type(val).__name__
            if valtype == "dict":
                val['pred'] = "%%(%s)s" % (key,)
                values.append(val)
            else:
                fmt     = "%%(%s)s" % (key, )
                values.append(fmt)
        return values
    
    
    def feature_predicates (self, feature):
        columns = self.column_names(feature)
        values  = self.value_formats(feature)
        predicates = []
        for pair in zip(columns, values):
            if pair[0] != self.geom_col:
                if isinstance(pair[1], dict):
                    # Special Query: pair[0] is 'a', pair[1] is {'type', 'pred', 'value'}
                    # We build a Predicate here, then we replace pair[1] with pair[1] value below
                    if pair[1].has_key('value'):
                        predicates.append("%s %s %s" % (pair[1]['column'],
                                                        self.query_action_sql[pair[1]['type']],
                                                        pair[1]['pred']))
                
                else:
                    predicates.append("%s = %s" % pair)
        if feature.geometry and feature.geometry.has_key("coordinates"):
            predicates.append(" %s = SetSRID('%s'::geometry, %s) " % (self.geom_col, WKT.to_wkt(feature.geometry), self.srid))
        return predicates

    
    def begin(self):
        if not os.path.exists(self.file):
            raise ConnectionException(**{'layer':self.name,'locator':'SpatialLite'})
        self._connection = db.connect(self.file, check_same_thread = False)
    
    def close(self):
        self._connection.close()

    def commit(self):
        if self.writable:
            self._connection.commit()
        self.close()

    def rollback(self):
        if self.writable:
            self._connection.rollback()
        self.close()

    def insert(self, action):
        self.begin()
        if action.feature != None:
            feature = action.feature

            columns = ", ".join(self.column_names(feature)+[self.geom_col])
            values = ", ".join(self.value_formats(feature)+["SetSRID('%s'::geometry, %s) " % (WKT.to_wkt(feature.geometry), self.srid)])

            sql = "INSERT INTO \"%s\" (%s) VALUES (%s)" % (self.table, columns, values)

            cursor = self._connection.cursor()
            cursor.execute(str(sql), self.feature_values(feature))
    
            cursor.execute("SELECT last_insert_rowid()")
            action.id = cursor.fetchone()[0]
    
            return InsertResult(action.id, "")
            
        
        elif action.wfsrequest != None:
            sql = action.wfsrequest.getStatement(self)
            
            cursor = self._connection.cursor()
            cursor.execute(str(sql))
            
            cursor.execute("SELECT last_insert_rowid()")
            action.id =  cursor.fetchone()[0]
            
            return InsertResult(action.id, "")
            
        return None

    def update(self, action):
        self.begin()
        if action.feature != None:
            feature = action.feature
            predicates = ", ".join( self.feature_predicates(feature) )
            sql = "UPDATE \"%s\" SET %s WHERE %s = %d" % (self.table, predicates, self.fid_col, action.id )
            cursor = self._connection.cursor()
            cursor.execute(str(sql), self.feature_values(feature))

            return UpdateResult(action.id, "")
        
        elif action.wfsrequest != None:
            sql = action.wfsrequest.getStatement(self)
            cursor = self._connection.cursor()
            cursor.execute(str(sql))
            
            return UpdateResult(action.id, "")
            
        return None


    def delete(self, action):
        self.begin()
        if action.feature != None:
            sql = "DELETE FROM \"%s\" WHERE %s = %%(%s)d" % (self.table, self.fid_col, self.fid_col )
            cursor = self._connection.cursor()
            try:
                cursor.execute(str(sql) % {self.fid_col: action.id})
            except:
                cursor.execute(str(sql), {self.fid_col: action.id})
                    
            return DeleteResult(action.id, "")
    
        elif action.wfsrequest != None:
            sql = action.wfsrequest.getStatement(self)
            cursor = self._connection.cursor()
            try:
                cursor.execute(str(sql) % {self.fid_col: action.id})
            except:
                cursor.execute(str(sql), {self.fid_col: action.id})
            
            return DeleteResult(action.id, "")
        
        return None
        

    def select(self, action):
        self.begin()
        cursor = self._connection.cursor()
        
        if action.id is not None:
            sql = "SELECT AsText(Transform(%s, %d)) as fs_text_geom, " % (self.geom_col, int(self.srid_out))

            if hasattr(self, 'version'):
                sql += "%s as version, " % self.version
            if hasattr(self, 'ele'):
                sql += "%s as ele, " % self.ele
            
            sql += "\"%s\"" % self.fid_col
        
            if len(self.attribute_cols) > 0:
                sql += ", %s" % self.attribute_cols

            if hasattr(self, "additional_cols"):
                cols = self.additional_cols.split(';')
                additional_col = ",".join(cols)
                sql += ", %s" % additional_col
            
            sql += " FROM \"%s\" WHERE %s = :%s" % (self.table, self.fid_col, self.fid_col)
            cursor.execute(str(sql), {self.fid_col: str(action.id)})
            
            result = [cursor.fetchone()]
            
        else:
            filters = []
            attrs = []
            if action.attributes:
                match = Feature(props = action.attributes)
                filters = self.feature_predicates(match)
                for key, value in action.attributes.items():
                    if isinstance(value, dict):
                        attrs[key] = value['value']
                    else:
                        attrs[key] = value
            if action.bbox:
                filters.append("Intersects(Transform(BuildMBR(%f, %f, %f, %f, %s), %s), geometry)" % (tuple(action.bbox) + (self.srid_out,) + (self.srid,)))


            sql = "SELECT AsText(Transform(%s, %d)) as fs_text_geom, " % (self.geom_col, int(self.srid_out))
            if hasattr(self, 'ele'):
                sql += "%s as ele, " % self.ele
            if hasattr(self, 'version'):
                sql += "%s as version, " % self.version
            sql += "\"%s\"" % self.fid_col
                
            if len(self.attribute_cols) > 0:
                sql += ", %s" % self.attribute_cols
                        
            # check OGC FE attributes
            if self.fe_attributes and action.wfsrequest:
                fe_cols = action.wfsrequest.getAttributes()
                ad_cols = self.getColumns()    
                
                fe_cols = filter(lambda x: x not in ad_cols, fe_cols)
                
                if len(fe_cols) > 0:
                    sql += ", %s" % ",".join(fe_cols)
                
            if hasattr(self, "additional_cols"):
                cols = self.additional_cols.split(';')
                additional_col = ",".join(cols)
                sql += ", %s" % additional_col

            
            sql += " FROM \"%s\"" % (self.table)
            
            if filters:
                sql += " WHERE " + " AND ".join(filters)
            if action.wfsrequest:
                if filters:
                    sql += " AND "
                else:
                    sql += " WHERE "
                sql += action.wfsrequest.render(self)
            
            if self.order:
                sql += " ORDER BY " + self.order
            if action.maxfeatures:
                sql += " LIMIT %d" % action.maxfeatures
            #else:
            #    sql += " LIMIT 1000"
            if action.startfeature:
                sql += " OFFSET %d" % action.startfeature
            
            cursor.execute(str(sql), attrs)

            result = cursor.fetchall()
                
        columns = [desc[0] for desc in cursor.description]
        features = []
        
        for row in result:
            props = dict(zip(columns, row))
            if not props['fs_text_geom']: continue
            geom  = WKT.from_wkt(props['fs_text_geom'])
            id = props[self.fid_col]
            del props[self.fid_col]
            if self.attribute_cols == '*':
                del props[self.geom_col]
            del props['fs_text_geom']
            for key, value in props.items():
                if isinstance(value, str):
                    props[key] = unicode(value, self.encoding)
                elif isinstance(value, datetime.datetime) or isinstance(value, datetime.date):
                    # stringify datetimes
                    props[key] = str(value)

                try:
                    if isinstance(value, decimal.Decimal):
                        props[key] = unicode(str(value), self.encoding)
                except:
                    pass

            if (geom):
                features.append( Feature( id, geom, self.geom_col, self.srid_out, props ) )
        return features

    def getColumns(self):
        cols = []

        if hasattr(self, 'attribute_cols'):
            cols = self.attribute_cols.split(",")
        
        cols.append(self.geom_col)
        cols.append(self.fid_col)
        
        if hasattr(self, 'version'):
            cols.append(self.version)
        if hasattr(self, 'ele'):
            cols.append(self.ele)
        
        return cols
        
    
    def getAttributeDescription(self, attribute):
        self.begin()
        cursor = self._connection.cursor()
        result = []
        
        sql = "PRAGMA table_info(%s)"
        
        try:
            cursor.execute(sql % self.table)
            result = cursor.fetchall()
            self.commit()
        except:
            pass
        
    
        type = 'string'
        length = ''
        
        if len(result) > 0:
            for col in result:
                if col[1] == attribute:
                    if str(col[2]).lower().startswith('int'):
                        type = 'integer'
                        length = ''
                        break
    
        return (type, length)

########NEW FILE########
__FILENAME__ = SQLite
__author__  = "MetaCarta"
__copyright__ = "Copyright (c) 2006-2008 MetaCarta"
__license__ = "Clear BSD" 
__version__ = "$Id: SQLite.py 606 2009-04-24 16:25:41Z brentp $"

import re
import copy
from FeatureServer.DataSource import DataSource
from vectorformats.Feature import Feature
from vectorformats.Formats import WKT
import sys

try:
    import sqlite3
except:
    from pysqlite2 import dbapi2 as sqlite3

class SQLite (DataSource):
    """Similar to the PostGIS datasource. Works with the 
       built in sqlite in Python2.5+, or with pysqlite2."""
    wkt_linestring_match = re.compile(r'\(([^()]+)\)')


    query_action_types = ['lt', 'gt', 'like', 'gte', 'lte']

    query_action_sql = {'lt': '<', 'gt': '>' , 'like':'like'
                        , 'gte': '>=', 'lte': '<='}


    def __init__(self, name, srid = 4326, srid_out = 4326, order=None, writable = True, **args):
        DataSource.__init__(self, name, **args)
        self.table      = args.get("layer") or name
        self.fid_col    = 'feature_id'
        self.geom_col   = 'wkt_geometry'
        self.order      = order
        self.srid       = srid # not used now...
        self.srid_out   = srid_out # not used now...
        self.db         = None
        self.dsn        = args.get("dsn") or args.get("file")
        self.writable   = writable

    def begin (self):
        self.db = sqlite3.connect(self.dsn)
        # allow both dictionary and integer index lookups.
        self.db.row_factory = sqlite3.Row

        # create the table if it doesnt exist.
        if not self.table in self.tables():
            c = self.db.cursor()
            c.executescript(self.schema())
            self.db.commit()

    def tables(self):
        c = self.db.cursor()
        res = c.execute("SELECT name FROM sqlite_master WHERE type='table'").fetchall()
        return [r[0] for r in res]

    def schema(self):
        return """\
CREATE TABLE '%s' (
    feature_id   INTEGER PRIMARY KEY,
    xmin INTEGER,
    ymin INTEGER,
    xmax INTEGER,
    ymax INTEGER,
    date_created DATETIME,
    date_modified DATETIME,
    %s VARCHAR
);
CREATE TABLE '%s_attrs' (
    id     INTEGER PRIMARY KEY,
    feature_id  INTEGER,
    key    VARCHAR(256),
    value TEXT
);    
CREATE INDEX %s_xy_idx ON %s (xmin, xmax, ymin, ymax);
CREATE INDEX %s_attrs_feature_id on %s_attrs (feature_id);
CREATE INDEX %s_attrs_%s_key on %s_attrs (key);

/* automatic timestamp, but dont override if one is sent in */
CREATE TRIGGER %s_insert_date_trigger 
AFTER INSERT ON %s
BEGIN
        UPDATE %s SET date_created = datetime('now', 'localtime')
                WHERE feature_id = NEW.feature_id AND
                NEW.date_created IS NULL;
        UPDATE %s SET date_modified = datetime('now', 'localtime')
                WHERE feature_id = NEW.feature_id;
END; 
CREATE TRIGGER %s_update_date_trigger 
/* update the main table when attrs are modified */
AFTER UPDATE ON %s_attrs
BEGIN
        UPDATE %s SET date_modified = datetime('now', 'localtime')
                WHERE feature_id = NEW.feature_id;
END; 

""" % tuple([self.table, self.geom_col] + list((self.table,) * 15))

    def commit (self):
        if self.writable:
            self.db.commit()
        self.db.close()

    def rollback (self):
        if self.writable:
            self.db.rollback()
        self.db.close()

    def column_names (self, feature):
        return feature.properties.keys()

    def value_formats (self, feature):
        #values = ["%%(%s)s" % self.geom_col]
        values = []
        for key, val in feature.properties.items():
            values.append(":%s" % key)
        return values

    def feature_predicates (self, feature):
        columns = self.column_names(feature)
        values  = self.value_formats(feature)
        predicates = []
        for pair in zip(columns, values):
            if pair[0] != self.geom_col:
                predicates.append(" %s = %s" % pair)
            else:
                predicates.append(" %s = %s " % (self.geom_col, WKT.to_wkt(feature.geometry)))
        return predicates

    def feature_values (self, feature):
        return copy.deepcopy(feature.properties)

    def insert (self, action):
        feature = action.feature
        bbox = feature.get_bbox()

        columns = ", ".join([self.geom_col,'xmin,ymin,xmax,ymax'])
        values = [WKT.to_wkt(feature.geometry)] + list(bbox) 
        sql = "INSERT INTO \"%s\" (%s) VALUES (?,?,?,?,?)" % ( self.table, columns)
        cursor = self.db.cursor()
        res = cursor.execute(str(sql), values)
        action.id = res.lastrowid
        #self.db.commit()

        insert_tuples = [(res.lastrowid, k, v) for k,v in feature.properties.items()]
        sql = "INSERT INTO \"%s_attrs\" (feature_id, key, value) VALUES (?, ?, ?)" % (self.table,) 
        cursor.executemany(sql,insert_tuples)

        #self.db.commit()
        return self.select(action)
        

    def update (self, action):
        feature = action.feature
        bbox = feature.get_bbox()
        predicates =  self.feature_predicates(feature) 

        # this assumes updates can not introduce new attrs.... fix?
        sql = "UPDATE \"%s_attrs\" SET value = :value WHERE key = :key AND %s = %d" % (
                    self.table, self.fid_col, action.id )

        cursor = self.db.cursor()
        predicate_list = []
        for i in range(0, len(predicates) - 1, 2):
            predicate_list.append( dict(key=predicates[i], value=predicates[i+1]) )

        cursor.executemany(str(sql), predicate_list)

        # should check if changed before doing this ...
        geom_sql = "UPDATE %s SET %s = ?, xmin = ?, ymin = ?, xmax = ?, ymax = ? WHERE %s = %d" \
                           % (self.table, self.geom_col, self.fid_col, action.id)
        cursor.execute(geom_sql,  [WKT.to_wkt(feature.geometry)] + list(bbox))

        #self.db.commit()
        return self.select(action)
        
    def delete (self, action):

        sql = "DELETE FROM \"%s\" WHERE %s = :%s" % (
                    self.table, self.fid_col, self.fid_col )
        cursor = self.db.cursor()
        cursor.execute(str(sql), {self.fid_col: action.id})

        sql = "DELETE FROM \"%s_attrs\" WHERE %s = :%s" % (
                    self.table, self.fid_col, self.fid_col )
        cursor.execute(str(sql), {self.fid_col: action.id})
        #self.db.commit()
        return []


    def select (self, action):
        cursor = self.db.cursor()
        features = []
        sql_attrs = "SELECT key, value FROM \"%s_attrs\" WHERE feature_id = :feature_id" % (self.table,)
        selection_dict = {}

        if action.id is not None:
            sql = "SELECT * FROM \"%s\" WHERE %s = ?" % ( self.table,  self.fid_col)
            cursor.execute(str(sql), (action.id,))
            results = [ cursor.fetchone() ]

        else:
            match = Feature(props = action.attributes)
            filters = match.properties.items()
            
            sql = "SELECT DISTINCT(t.feature_id) as feature_id, t.%s as %s,\
            t.%s as %s FROM \"%s\" t LEFT JOIN \"%s_attrs\" a ON a.feature_id =\
            t.feature_id " % ( self.geom_col, self.geom_col, self.fid_col, self.fid_col,  self.table, self.table )
            select_dict = {}
            if filters:
                sql += "WHERE 1 "
                for ii, (key, value) in enumerate(filters):
                    if isinstance(value, dict):

                        select_dict['key%i' % ii] = value['column']
                        select_dict['value%i' % ii] = value['value']
                        sql += (" AND a.key = :key%i AND a.value " + self.query_action_sql[value['type']] + " :value%i") % (ii, ii)


                    else:
                        select_dict['key%i' % ii] = key
                        select_dict['value%i' % ii] = value
                        sql += " AND a.key = :key%i AND a.value = :value%i" % (ii, ii)

            bbox = '' 
            if action.bbox:
                # skip sql interpolation as these are from calculation.
                bbox = " AND %f   > t.xmin \
                     AND t.xmax > %f \
                     AND %f   > t.ymin \
                     AND t.ymax >  %f "\
                     % (action.bbox[2], action.bbox[0], action.bbox[3], action.bbox[1])

            sql += bbox
            sql += self.order or ''
            sql += " LIMIT %d" % (action.maxfeatures or 1000, )

            if action.startfeature:
                sql += " OFFSET %d" % action.startfeature
            cursor.execute(str(sql), select_dict)
            results = cursor.fetchall()

        for row in results:
            attrs = cursor.execute(sql_attrs, dict(feature_id=row['feature_id']) ).fetchall()
            d = {}
            #if attrs == []: continue
            for attr in attrs:
                d[attr[0]] = attr[1]
            geom  = WKT.from_wkt(row[self.geom_col])
            id = row[self.fid_col]

            if (geom):
                features.append( Feature( id, geom, self.geom_col, self.srid_out, d ) ) 
        return features

########NEW FILE########
__FILENAME__ = Twitter
from FeatureServer.DataSource import DataSource
from vectorformats.Feature import Feature
from FeatureServer.Exceptions.NoGeometryException import NoGeometryException

import oauth2 as oauth

import urllib
import urlparse
import simplejson
import math

class Twitter (DataSource):

    api = None
    geo_keys = ['coordinates', 'geo', 'place']
    
    def __init__(self, name, consumer_key, consumer_secret, token_key, token_secret, srid_out = 4326, attributes="*", encoding = "utf-8", **args):
        DataSource.__init__(self, name, **args)
        self.consumer_key       = consumer_key
        self.consumer_secret    = consumer_secret
        self.token_key          = token_key
        self.token_secret       = token_secret
        self.srid_out           = srid_out
        self.encoding           = encoding
        self.attributes         = attributes

        self.api = TwitterAPI(self.consumer_key, self.consumer_secret, self.token_key, self.token_secret)

    def select (self, action):
        features = []
        if action.id is not None:
            content = self.api.request('https://api.twitter.com/1.1/statuses/show.json?include_my_retweet=true&include_entities=true&id=' + str(action.id), "GET")
            try:
                features.append(self.encode_tweet(simplejson.loads(content)))
            except Exception as e:
                ''' '''
        else:
            if hasattr(self, 'screen_name'):
                content = self.api.request('https://api.twitter.com/1.1/statuses/user_timeline.json?screen_name=' + self.screen_name, "GET")
                features = self.encode_user_tweets(simplejson.loads(content))
            elif hasattr(self, 'user_id'):
                content = self.api.request('https://api.twitter.com/1.1/statuses/user_timeline.json?user_id=' + self.user_id, "GET")
                features = self.encode_user_tweets(simplejson.loads(content))
            else:
                params = {'count':'100'}
                geocode = ''
                if action.bbox:
                    # latitude, longitude
                    center = "%f,%f" % tuple([ (action.bbox[1] + action.bbox[3]) / 2, (action.bbox[0] + action.bbox[2]) / 2 ])

                    dLat = math.radians((action.bbox[3] - action.bbox[1]))
                    dLon = math.radians((action.bbox[2] - action.bbox[0]))
                    lat1 = math.radians(action.bbox[1])
                    lat2 = math.radians(action.bbox[3])

                    a = math.sin(dLat/2) * math.sin(dLat/2) + math.sin(dLon/2) * math.sin(dLon/2) * math.cos(lat1) * math.cos(lat2)
                    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1-a))
                    d = 6371 * c

                    radius = "%ikm" % math.ceil(d/2)
                    params['geocode'] = center + ',' + radius
                
                params['q'] = self.query
                query = urllib.urlencode(params)
                        
                content = self.api.request('https://api.twitter.com/1.1/search/tweets.json?' + query, "GET")
                features = self.encode_search_tweets(simplejson.loads(content))
            
        return features

    
    def encode_search_tweets(self, tweets):
        features = []
        
        for tweet in tweets['statuses']:
            try:
                features.append(self.encode_tweet(tweet))
            except Exception as e:
                continue

        return features

    
    def encode_user_tweets(self, tweets):
        features = []
        for tweet in tweets:
            try:
                features.append(self.encode_tweet(tweet))
            except Exception as e:
                continue
        
        return features
    
    
    def encode_tweet(self, tweet):
        try:
            geom = self.get_geometry(tweet)
        except:
            raise
        
        props = {}
        node_names = self.get_node_names(tweet)
        
        for attribute in node_names:
            keys = attribute.split(".")
            value = tweet
            for key in keys:
                
                if value[key] is None:
                    break
                value = value[key]

            if type(value) is not dict and type(value) is not list:
                if type(value) is unicode:
                    props[attribute] = value
                else:
                    props[attribute] = unicode(str(value), self.encoding)
        
        return Feature( id=tweet["id"], geometry=geom, geometry_attr="geometry", srs=self.srid_out, props=props )
    

    def get_geometry(self, tweet):
        if tweet["coordinates"] is not None:
            return tweet["coordinates"]
        # geo field is deprecated. Should be removed
        if tweet["geo"] is not None:
            return tweet["geo"]
        if tweet["place"] is not None:
            if tweet["place"]["bounding_box"] is not None:
                return tweet["place"]["bounding_box"]

        raise NoGeometryException(locator="Twitter", layer=self.name)

    def get_node_names(self, tweet):
        nodes = []
        
        if self.attributes == '*':
            for key in tweet.keys():
                if key not in self.geo_keys:
                    childs = self.get_nodes(key, tweet[key], key)
                    nodes.extend(childs)
        else:
            nodes = self.attributes.split(",")

        return nodes

    def get_nodes(self, key, tweet, path):
        nodes = []
        
        if type(tweet) is dict:
            for key in tweet.keys():
                if key not in self.geo_keys:
                    childs = self.get_nodes(key, tweet[key], "%s.%s" % (path, key))
                    nodes.extend(childs)
        else:
            nodes.append("%s" % path)
        
        
        return nodes




class TwitterAPI(object):
    
    settings = {
        'request_token_url' : 'https://api.twitter.com/oauth/request_token',
        'authorize_url' : 'https://api.twitter.com/oauth/authorize',
        'access_token_url' : 'https://api.twitter.com/oauth/access_token'
    }
    
    client = None
    
    def __init__(self, consumer_key, consumer_secret, token_key, token_secret):
        consumer = oauth.Consumer(key = consumer_key, secret = consumer_secret)
        token = oauth.Token(key = token_key, secret = token_secret)
        
        self.client = oauth.Client(consumer, token)
    
    
    def request(self, url, http_method = "GET", post_body = "", http_headers = {}):
        resp, content = self.client.request(url, method = http_method, body = post_body, headers = http_headers)
        return content



########NEW FILE########
__FILENAME__ = VersionedPostGIS
__author__  = "MetaCarta"
__copyright__ = "Copyright (c) 2006-2008 MetaCarta"
__license__ = "Clear BSD" 
__version__ = "$Id: VersionedPostGIS.py 496 2008-05-18 13:01:13Z crschmidt $"

from FeatureServer.DataSource import DataSource
from vectorformats.Feature import Feature
from FeatureServer.DataSource.PostGIS import PostGIS
from vectorformats.Formats import WKT

try:
    import cPickle
except ImportError:
    import Pickle as cPickle

import uuid

class VersionedPostGIS (PostGIS):
    """A proof of concept for versioned PostGIS-powered geo-database support.
       Allows 'open tagging', and creates transaction logs for looking through
       historical changes to the datastore."""
    def __init__(self, name, srid = 4326, srid_out = 4326, fid = "id", geometry = "shape", order = "", **args):
        DataSource.__init__(self, name, **args)
        self.db         = None
        self.table      = "feature" 
        self.fid_col    = fid
        self.geom_col   = geometry
        self.order      = order
        self.srid       = srid
        self.srid_out   = srid_out
        self.dsn        = args["dsn"]
    
    def begin (self):
        PostGIS.begin(self)
        self.txn_uuid = uuid.uuid1().hex
        sql = """INSERT INTO txn (uuid, actor, message, commit_time)
                        VALUES ('%s', 1, 'message', now());""" % self.txn_uuid
        cursor = self.db.cursor()
        cursor.execute(str(sql))
        
    def commit (self):
        sql = """update txn set bbox = envelope(collect(shape)) from history
                    where history.txn_id = txn.uuid and txn.uuid = '%s'""" \
                    % self.txn_uuid
        cursor = self.db.cursor()
        cursor.execute(str(sql))
        PostGIS.commit(self)

    def insert (self, action):
        feature = action.feature
        values = {'geom' : WKT.to_wkt(feature.geometry),
                  'uuid' : uuid.uuid1().hex,
                  'attrs': self._serializeattrs(feature.properties)}
        sql = """INSERT INTO %s (%s, uuid, attrs)
                    VALUES (SetSRID(%%(geom)s::geometry, %s),
                                %%(uuid)s, %%(attrs)s)""" % (
                                    self.table, self.geom_col, self.srid)
        cursor = self.db.cursor()
        cursor.execute(str(sql), values)
        return {}

    def update (self, action):
        feature = action.feature
        sql = """UPDATE %s SET %s = SetSRID(%%(geom)s::geometry, %s),
                               attrs = %%(attrs)s WHERE %s = %(id)d""" % (
                self.table, self.geom_col, self.srid, self.fid_col )
        values = {'geom' : WKT.to_wkt(feature.geometry),
                  'id'   : action.id,
                  'attrs': self._serializeattrs(feature.properties)}
        cursor = self.db.cursor()
        cursor.execute(str(sql), values)
        return self.select(action)

    def select (self, action):
        cursor = self.db.cursor()

        if action.id is not None:
            sql = "SELECT AsText(%s) as fs_binary_geom_col, * FROM %s WHERE %s = %%(%s)d" % (
                    self.geom_col, self.table, self.fid_col, self.fid_col )
            cursor.execute(str(sql), {self.fid_col: action.id})
            result = [cursor.fetchone()]
        else:
            filters = []
            attrs   = {}
            if action.bbox:
                filters.append( "%s && SetSRID('BOX3D(%f %f,%f %f)'::box3d, %s) and intersects(%s, SetSRID('BOX3D(%f %f,%f %f)'::box3d, %s))" % (
                                        (self.geom_col,) + tuple(action.bbox) + (self.srid,) + (self.geom_col,) + (tuple(action.bbox) + (self.srid,))))
            
            if action.attributes:
                match = Feature(props = action.attributes)
                filters = self.feature_predicates(match)
                attrs = action.attributes

            sql = "SELECT AsText(%s) as fs_binary_geom_col, uuid, id, attrs FROM %s" % (self.geom_col, self.table)
            #if filters:
            #    sql += " WHERE " + " AND ".join(filters)
            
            if self.order:
                sql += self.order
            if action.maxfeatures:
                sql += " LIMIT %d" % action.maxfeatures
            else:   
                sql += " LIMIT 1000"
            if action.startfeature:
                sql += " OFFSET %d" % action.startfeature
            
            cursor.execute(str(sql), attrs)
            result = cursor.fetchall() # should use fetchmany(action.maxfeatures)

        columns = [desc[0] for desc in cursor.description]
        features = []
        for row in result:
            props = dict(zip(columns, row))
            geom  = WKT.from_wkt(props['fs_binary_geom_col'])
            if props.has_key(self.geom_col): del props[self.geom_col]
            del props['fs_binary_geom_col']
            props.update(self._deserializeattrs(props['attrs']))
            del props['attrs']
            fid = props[self.fid_col]
            del props[self.fid_col]
            for key, value in props.items():
                if isinstance(value, str): 
                    props[key] = unicode(value, "utf-8")
            features.append( Feature( fid, geom, self.geom_col, self.srid_out, props ) ) 
        return features
    
    def _serializeattrs(self, properties):
        import sys
        print >>sys.stderr, properties
        return cPickle.dumps(properties)

    def _deserializeattrs(self, attrstr):
        return cPickle.loads(attrstr)

########NEW FILE########
__FILENAME__ = WFS
__author__  = "MetaCarta"
__copyright__ = "Copyright (c) 2006-2008 MetaCarta"
__license__ = "Clear BSD" 
__version__ = "$Id: WFS.py 467 2008-05-18 06:02:16Z crschmidt $"

from FeatureServer.DataSource import DataSource
from FeatureServer.DataSource.OGR import OGR
from vectorformats.Feature import Feature
import urllib
import tempfile
import os

class WFS (DataSource):
    """Talks to a remote WFS instance, then uses the OGR 
       datasource to parse the returned data."""
    def __init__(self, name, url = None, typename = None,
                             version = "1.1.0", **args):
        DataSource.__init__(self, name, **args)
        self.url = url
        self.typename = typename
        self.version = version

    def select (self, action):
        param = {"VERSION"  : self.version,
                 "SERVICE"  : "WFS",
                 "REQUEST"  : "GetFeature",
                 "TYPENAME" : self.typename}

        if action.id is not None:
            param["FEATUREID"] = str(action.id)
        else:
            if action.bbox:
                param["BBOX"] = ",".join(map(str, action.bbox))
            if action.attributes:
                raise NotImplementedError("WFS attribute query")
            if action.maxfeatures:
                param["MAXFEATURES"] = str(action.maxfeatures)

        url = self.url
        if "?" not in url and "&" not in url: url += "?"
        url += urllib.urlencode(param)
        tmpfile, headers = urllib.urlretrieve(url)
        
        import ogr
        try:
            ds = OGR("GML", dsn = tmpfile, writable = 0)
            result = ds.select(action)
        except ogr.OGRError, E:
            raise Exception("OGR could not read the WFS result: %s. Data was: %s" % (E, open(tmpfile).read()))
        os.unlink(tmpfile)
        return result

########NEW FILE########
__FILENAME__ = BaseException
'''
Created on October 15, 2012
    
@author: michel
'''


class BaseException(Exception):
    dump = ""
    code = ""
    locator = ""
    layer = ""

    def __init__(self, message, code, locator, layer, dump):
        Exception.__init__(self, message)
        self.code = code
        self.locator = locator
        self.layer = layer
        self.dump = dump
        
########NEW FILE########
__FILENAME__ = ConnectionException
'''
Created on October 15, 2012
    
@author: michel
'''

from FeatureServer.Exceptions.BaseException import BaseException

class ConnectionException(BaseException):
    
    message="Connection to the layer '%s' could not be established."
    
    def __init__(self, locator, layer, code="", message="", dump = ""):
        self.message = self.message % layer
        if len(message) > 0:
            self.message = message
        BaseException.__init__(self, self.message, self.code, locator, layer, dump)

########NEW FILE########
__FILENAME__ = ExceptionReport
'''
Created on October 15, 2012
    
@author: michel
'''

class ExceptionReport():
    index = 0
    exceptions = []
    
    def add(self, exception):
        self.exceptions.append(exception)
    
    def __len__(self):
        return len(self.exceptions)

    def __iter__(self):
        self.index = 0
        return self
    
    def next(self):
        if self.index >= len(self):
            raise StopIteration
        exception = self.exceptions[self.index]
        self.index += 1
        return exception

    def get(self, index):
        return self.exceptions[index]

########NEW FILE########
__FILENAME__ = LayerNotFoundException
'''
Created on October 15, 2012
    
@author: michel
'''

from FeatureServer.Exceptions.BaseException import BaseException

class LayerNotFoundException(BaseException):
    
    message="Could not find the layer '%s': Check your config file for the missing layer. (Available layers are: %s)."
    
    def __init__(self, locator, layer, layers, code="", message="", dump = ""):
        self.message = self.message % (layer, ", ".join(layers))
        if len(message) > 0:
            self.message = message
        BaseException.__init__(self, self.message, self.code, locator, layer, dump)

########NEW FILE########
__FILENAME__ = MissingParameterException
'''
Created on October 10, 2012
    
@author: michel
'''

from FeatureServer.Exceptions.BaseException import BaseException

class MissingParameterException(BaseException):
    
    argument=""
    message="Argument '%s' is missing in layer '%s'."
    
    def __init__(self, locator, layer, argument, code="", message="", dump = ""):
        self.argument = argument
        self.message = self.message % (self.argument, layer)
        if len(message) > 0:
            self.message = message
        BaseException.__init__(self, self.message, self.code, locator, layer, dump)

########NEW FILE########
__FILENAME__ = NoGeometryException
'''
Created on November 4, 2012
    
@author: michel
'''

from FeatureServer.Exceptions.BaseException import BaseException

class NoGeometryException(BaseException):
    
    message="Geometry could not be found."
    
    def __init__(self, locator, layer, code="", message="", dump = ""):
        if len(message) > 0:
            self.message = message
        BaseException.__init__(self, self.message, self.code, locator, layer, dump)
########NEW FILE########
__FILENAME__ = NoLayerException
'''
Created on October 15, 2012
    
@author: michel
'''

from FeatureServer.Exceptions.BaseException import BaseException

class NoLayerException(BaseException):
    
    message="No Layer is configured."
    
    def __init__(self, locator, layer="", code="", message="", dump = ""):
        if len(message) > 0:
            self.message = message
        BaseException.__init__(self, self.message, self.code, locator, layer, dump)

########NEW FILE########
__FILENAME__ = InvalidValueException
'''
Created on May 24, 2011
    
@author: michel
'''
from FeatureServer.Exceptions.WebFeatureService.WFSException import WFSException

class InvalidValueException(WFSException):
    def __init__(self, **kwargs):
        super(InvalidValueException, self).__init__(code="InvalidParameterValue", message="ValueReference does not exist.", **kwargs)

########NEW FILE########
__FILENAME__ = WFSException
'''
Created on May 24, 2011

@author: michel
'''

from FeatureServer.Exceptions.BaseException import BaseException

class WFSException(BaseException):

    def __init__(self, locator, layer, message, code="", dump = ""):
        BaseException.__init__(self, message, code, locator, layer, dump)
    
########NEW FILE########
__FILENAME__ = Processing
class Processing(object):
    def __init__(self, name, process, **kwargs):
        self.name = name
        self.process = process
        self.config_args = kwargs
        self.dispatch_args = [y[:-8] for y in  self.config_args if y.endswith("_default")]

    def dispatch(self, features=None, params=None):
        if features == None:
            features = []
        if params == None:
            params = {}
        
        kwargs = {}

        for arg in self.dispatch_args:
            if self.config_args.has_key("%s_default" % arg):
                kwargs[arg] = self.config_args['%s_default' % arg]
 
        for arg in self.dispatch_args:
            if self.config_args.has_key("%s_locked" % arg) and self.config_args['%s_locked' % arg].lower() in ['yes', 'y','true', '1']:
                continue
            key = "process_%s_%s" % (self.name, arg)    
            if params.has_key(key):
                kwargs[arg] = params[key]
        return self.process(features, **kwargs)    

def loadFromSection (config, section):
    mod = config.get(section, "module")
    cls = config.get(section, "class")
    mod_name = mod.split(".")[-1]
    module = __import__(mod, globals(), locals(), mod_name)
    action = getattr(module, cls)
    objargs = {}
    for opt in config.options(section):
        if opt not in  ["module", "class"]:
            objargs[opt] = config.get(section, opt)
    name = section[8:]
    p = Processing(name, action(), **objargs)
    return p

########NEW FILE########
__FILENAME__ = Server
#!/usr/bin/python
__author__  = "MetaCarta"
__copyright__ = "Copyright (c) 2006-2008 MetaCarta"
__license__ = "Clear BSD" 
__version__ = "$Id: Server.py 607 2009-04-27 15:53:15Z crschmidt $"

import sys
import time
import os
import traceback
import ConfigParser
from web_request.handlers import wsgi, mod_python, cgi
from lxml import etree
import cgi as cgimod

from FeatureServer.WebFeatureService.Response.TransactionResponse import TransactionResponse
from FeatureServer.WebFeatureService.Response.TransactionSummary import TransactionSummary
from FeatureServer.WebFeatureService.Response.ActionResult import ActionResult

from FeatureServer.Workspace.FileHandler import FileHandler

from FeatureServer.Exceptions.ExceptionReport import ExceptionReport
from FeatureServer.Exceptions.WebFeatureService.InvalidValueException import InvalidValueException
from FeatureServer.Exceptions.ConnectionException import ConnectionException
from FeatureServer.Exceptions.LayerNotFoundException import LayerNotFoundException


import FeatureServer.Processing 
from web_request.response import Response

# First, check explicit FS_CONFIG env var
if 'FS_CONFIG' in os.environ:
    cfgfiles = os.environ['FS_CONFIG'].split(",")

# Otherwise, make some guesses.
else:
    # Windows doesn't always do the 'working directory' check correctly.
    if sys.platform == 'win32':
        workingdir = os.path.abspath(os.path.join(os.getcwd(), os.path.dirname(sys.argv[0])))
        cfgfiles = (os.path.join(workingdir, "featureserver.cfg"), os.path.join(workingdir,"..","featureserver.cfg"))
    else:
        cfgfiles = ("featureserver.cfg", os.path.join("..", "featureserver.cfg"), "/etc/featureserver.cfg")


class Server (object):
    """The server manages the datasource list, and does the management of
       request input/output.  Handlers convert their specific internal
       representation to the parameters that dispatchRequest is expecting,
       then pass off to dispatchRequest. dispatchRequest turns the input 
       parameters into a (content-type, response string) tuple, which the
       servers can then return to clients. It is possible to integrate 
       FeatureServer into another content-serving framework like Django by
       simply creating your own datasources (passed to the init function) 
       and calling the dispatchRequest method. The Server provides a classmethod
       to load datasources from a config file, which is the typical lightweight
       configuration method, but does use some amount of time at script startup.
       """ 
       
    def __init__ (self, datasources, metadata = {}, processes = {}):
        self.datasources   = datasources
        self.metadata      = metadata
        self.processes     = processes 
    
    def _loadFromSection (cls, config, section, module_type, **objargs):
        type  = config.get(section, "type")
        module = __import__("%s.%s" % (module_type, type), globals(), locals(), type)
        objclass = getattr(module, type)
        for opt in config.options(section):
            objargs[opt] = config.get(section, opt)
        if module_type is 'DataSource':
            return objclass(section, **objargs)
        else:
            return objclass(**objargs)
    loadFromSection = classmethod(_loadFromSection)

    def _load (cls, *files):
        """Class method on Service class to load datasources
           and metadata from a configuration file."""
        config = ConfigParser.ConfigParser()
        config.read(files)
        
        metadata = {}
        if config.has_section("metadata"):
            for key in config.options("metadata"):
                metadata[key] = config.get("metadata", key)

        processes = {}
        datasources = {}
        for section in config.sections():
            if section == "metadata": continue
            if section.startswith("process_"):
                try:
                    processes[section[8:]] = FeatureServer.Processing.loadFromSection(config, section)
                except Exception, E:
                    pass 
            else:     
                datasources[section] = cls.loadFromSection(config, section, 'DataSource')

        return cls(datasources, metadata, processes)
    load = classmethod(_load)


    def dispatchRequest (self, base_path="", path_info="/", params={}, request_method = "GET", post_data = None,  accepts = ""):
        """Read in request data, and return a (content-type, response string) tuple. May
           raise an exception, which should be returned as a 500 error to the user."""
        response_code = "200 OK"
        host = base_path
        request = None
        content_types = {
          'application/vnd.google-earth.kml+xml': 'KML',
          'application/json': 'GeoJSON',
          'text/javascript': 'GeoJSON',
          'application/rss+xml': 'GeoRSS',
          'text/html': 'HTML',
          'osm': 'OSM',
          'gml': 'WFS',
          'wfs': 'WFS',
          'kml': 'KML',
          'json': 'GeoJSON',
          'georss': 'GeoRSS',
          'atom': 'GeoRSS',
          'html': 'HTML',
          'geojson':'GeoJSON',
          'shp': 'SHP',
          'csv': 'CSV',
          'gpx': 'GPX',
          'ov2': 'OV2',
          'sqlite': 'SQLite',
          'dxf' : 'DXF'
        }
        
        exceptionReport = ExceptionReport()
        
        path = path_info.split("/")
        
        found = False
        
        format = ""
        
        if params.has_key("format"):
            format = params['format']
            if format.lower() in content_types:
                format = content_types[format.lower()]
                found = True
        
        if not found and len(path) > 1:
            path_pieces = path[-1].split(".")
            if len(path_pieces) > 1:
                format = path_pieces[-1]
                if format.lower() in content_types:
                    format = content_types[format.lower()]
                    found = True
        
        if not found and not params.has_key("service") and post_data:
            try:
                dom = etree.XML(post_data)
                params['service'] = dom.get('service')
            except etree.ParseError: pass

        if not found and not params.has_key("version") and post_data:
            try:
                dom = etree.XML(post_data)
                params['version'] = dom.get('version')
            except etree.ParseError: pass
            
        if not found and not params.has_key("typename") and post_data:
            try:
                dom = etree.XML(post_data)
                for key, value in cgimod.parse_qsl(post_data, keep_blank_values=True):
                    if key.lower() == 'typename':
                        params['typename'] = value
            except etree.ParseError: pass

        if not found and params.has_key("service"):
            format = params['service']
            if format.lower() in content_types:
                format = content_types[format.lower()]
                found = True
        
        if not found and accepts:
            if accepts.lower() in content_types:
                format = content_types[accepts.lower()]
                found = True
        
        if not found and not format:
            if self.metadata.has_key("default_service"):
                format = self.metadata['default_service']
            else:    
                format = "WFS"
        
                
        #===============================================================================
        # (reflection) dynamic load of format class e.g. WFS, KML, etc.
        # for supported format see package 'Service'
        #       -----------           -------
        #       | Request | <|------- | WFS |
        #       -----------           -------
        #===============================================================================
        service_module = __import__("Service.%s" % format, globals(), locals(), format)
        service = getattr(service_module, format)
        request = service(self)
        
        response = []
        
        try:
            request.parse(params, path_info, host, post_data, request_method)
            
            # short circuit datasource where the first action is a metadata request. 
            if len(request.actions) and request.actions[0].method == "metadata": 
                return request.encode_metadata(request.actions[0])

            # short circuit datasource where a OGC WFS request is set
            # processing by service
            if len(request.actions) > 0 and hasattr(request.actions[0], 'request') and request.actions[0].request is not None:
                version = '1.0.0'
                if hasattr(request.actions[0], 'version') and len(request.actions[0].version) > 0:
                    version = request.actions[0].version
                
                if request.actions[0].request.lower() == "getcapabilities":
                    return getattr(request, request.actions[0].request.lower())(version)
                elif request.actions[0].request.lower() == "describefeaturetype":
                    return getattr(request, request.actions[0].request.lower())(version)

            datasource = self.datasources[request.datasources[0]]

            if request_method != "GET" and hasattr(datasource, 'processes'):
                raise Exception("You can't post data to a processed layer.")

        
            try:
                datasource.begin()

                if len(request.actions) > 0 and hasattr(request.actions[0], 'request') and request.actions[0].request is not None:
                    if request.actions[0].request.lower() == "getfeature":
                        ''' '''

                try:
                    transactionResponse = TransactionResponse()
                    transactionResponse.setSummary(TransactionSummary())
                    
                    for action in request.actions:
                        method = getattr(datasource, action.method)
                        try:
                            result = method(action)
                            if isinstance(result, ActionResult):
                                transactionResponse.addResult(result)
                            elif result is not None:
                                response += result
                        except InvalidValueException as e:
                            exceptionReport.add(e)
    
                        datasource.commit()
                except:
                    datasource.rollback()
                    raise

                if hasattr(datasource, 'processes'):
                    for process in datasource.processes.split(","):
                        if not self.processes.has_key(process):
                            raise Exception("Process %s configured incorrectly. Possible processes: \n\n%s" % (process, ",".join(self.processes.keys() )))
                        response = self.processes[process].dispatch(features=response, params=params)
                if transactionResponse.summary.totalDeleted > 0 or transactionResponse.summary.totalInserted > 0 or transactionResponse.summary.totalUpdated > 0 or transactionResponse.summary.totalReplaced > 0:
                    response = transactionResponse

            except ConnectionException as e:
                exceptionReport.add(e)
    
        except LayerNotFoundException as e:
            exceptionReport.add(e)

        if len(exceptionReport) > 0:
            if self.metadata.has_key("default_exception"):
                service_module = __import__("Service.%s" % self.metadata['default_exception'], globals(), locals(), self.metadata['default_exception'])
                service = getattr(service_module, self.metadata['default_exception'])
                default_exception = service(self)
                
                if hasattr(default_exception, "default_exception"):
                    mime, data, headers, encoding = default_exception.encode_exception_report(exceptionReport)
                else:
                    raise Exception("Defined service of key 'default_exception' does not support encoding exception reports. Please use a supported service or disable this key.")
            else:
                # check if service supports exception encoding
                if hasattr(request, "encode_exception_report"):
                    mime, data, headers, encoding = request.encode_exception_report(exceptionReport)
                else:
                    # get default service and instantiate
                    service_module = __import__("Service.%s" % self.metadata['default_service'], globals(), locals(), self.metadata['default_service'])
                    service = getattr(service_module, self.metadata['default_service'])
                    default_service = service(self)
                
                    if hasattr(default_service, "encode_exception_report"):
                        mime, data, headers, encoding = default_service.encode_exception_report(exceptionReport)
                    else:
                        # load WFS for exception handling
                        from FeatureServer.Service.WFS import WFS
                        wfs_service = WFS(self)
                        mime, data, headers, encoding = wfs_service.encode_exception_report(exceptionReport)

        
        else:
            mime, data, headers, encoding = request.encode(response)

        return Response(data=data, content_type=mime, headers=headers, status_code=response_code, encoding=encoding)     

    def dispatchWorkspaceRequest (self, base_path="", path_info="/", params={}, request_method = "GET", post_data = None,  accepts = ""):        
        handler = FileHandler('workspace.db')
        handler.removeExpired()
        
        # create workspace
        if params.has_key("base"):
            if params.has_key("request"):
                
                identifier = ''
                if params.has_key('id'):
                    identifier = params['id']
                    
                short = handler.create(params['base'], params['request'], identifier)
                
                output = ""
                 
                if params.has_key("callback"):
                    output += params["callback"] + '('
                
                output += '{"key":"' + short + '"}'
                
                if params.has_key("callback"):
                    output += ');'
                     
                return Response(data=output.decode("utf-8"), content_type="application/json; charset=utf-8", status_code="200 OK")
            
        
        # handle WFS request
        elif params.has_key('key'):
            
            handler.updateLastAccess(params['key'])
            data = handler.getByKey(params['key'])
            if len(data) > 0:                    
                #generate workspace specific datasource
                for layer in self.datasources:
                    if layer == data[2]:
                        self.datasources = {layer : self.datasources[layer]}
                        self.datasources[layer].abstract += " :: " + str(data[0])
                        break
                        
                if params.has_key('request'):
                    if params['request'].lower() == 'getfeature':
                        if params.has_key('filter') <> True:
                            if post_data == None:
                                params['filter'] = data[3]
                    
                    return self.dispatchRequest(base_path, path_info, params, request_method, post_data, accepts)
        
        # check workspace by id
        elif params.has_key('skey'):
            output = ""
            if params.has_key("callback"):
                output += params["callback"] + '('
            output += '{"workspaces":['
            
            data = handler.getByKey(params['skey'])
            if len(data) > 0:
                date = time.strftime("%a %b %d, %Y  %I:%M:%S %p",time.localtime(float(data[4])))
                output += '{"Workspace":"'+data[0]+'","LastAccess":"' + date  + '"},'
                             
            output += "]}"
            if params.has_key("callback"):
                output += ');'
            
            return Response(data=output.decode("utf-8"), content_type="application/json; charset=utf-8", status_code="200 OK")
        
        # check workspace by email
        elif params.has_key('sid'):
            output = ""
            if params.has_key("callback"):
                output += params["callback"] + '('
            output += '{"workspaces":['
            
            workspaces = handler.getByIdentifier(params['sid'])
            
            for data in workspaces:
            
                date = time.strftime("%a %b %d, %Y  %I:%M:%S %p",time.localtime(float(data[4])))
                output += '{"Workspace":"'+data[0]+'","LastAccess":"' + date  + '"},'
            
            if len(data) > 0:
                output = output[:-1] 
            
            output += "]}"
            if params.has_key("callback"):
                output += ');'
            
            return Response(data=output.decode("utf-8"), content_type="application/json; charset=utf-8", status_code="200 OK")
        
        #TODO: not available
        return None

theServer = None
lastRead = 0

#def handler (apacheReq):
#    global theServer
#    if not theServer:
#        options = apacheReq.get_options()
#        cfgs    = cfgfiles
#        if options.has_key("FeatureServerConfig"):
#            cfgs = (options["FeatureServerConfig"],) + cfgs
#        theServer = Server.load(*cfgs)
#    return mod_python(theServer.dispatchRequest, apacheReq)

def wsgi_app (environ, start_response):
    global theServer, lastRead
    last = 0
    for cfg in cfgfiles:
        try:
            cfgTime = os.stat(cfg)[8]
            if cfgTime > last:
                last = cfgTime
        except:
            pass        
    if not theServer or last > lastRead:
        cfgs      = cfgfiles
        theServer = Server.load(*cfgs)
        lastRead = time.time()
        
    return wsgi(theServer.dispatchRequest, environ, start_response)

def wsgi_app_workspace(environ, start_response):
    global theServer, lastRead
    last = 0
    for cfg in cfgfiles:
        try:
            cfgTime = os.stat(cfg)[8]
            if cfgTime > last:
                last = cfgTime
        except:
            pass        
    if not theServer or last > lastRead:
        cfgs      = cfgfiles
        theServer = Server.load(*cfgs)
        lastRead = time.time()
        
    return wsgi(theServer.dispatchWorkspaceRequest, environ, start_response)


if __name__ == '__main__':
    service = Server.load(*cfgfiles)
    cgi(service)

########NEW FILE########
__FILENAME__ = Action
class Action (object):
    """Encodes information about the request -- each property may be parsed out
        of the request and then passed into a datasource for action. the 'method'
        property should be one of select, insert, update, delete or metadata."""
    def __init__ (self):
        self.method         = None
        self.layer          = None
        self.feature        = None
        self.id             = None
        self.bbox           = None
        self.maxfeatures    = None
        self.startfeature   = 0
        self.attributes     = {}
        self.metadata       = None
        self.wfsrequest     = None
        self.version        = ''
        self.request        = None

########NEW FILE########
__FILENAME__ = CSV
__author__  = "MetaCarta"
__copyright__ = "Copyright (c) 2006-2008 MetaCarta"
__license__ = "Clear BSD" 
__version__ = "$Id: WFS.py 485 2008-05-18 10:51:09Z crschmidt $"

from FeatureServer.Service.Request import Request
import vectorformats.Formats.CSV


class CSV(Request):
    def encode(self, results):
        csv = vectorformats.Formats.CSV.CSV(layername=self.datasources[0])

        output = csv.encode(results)
        
        headers = {
            'Accept': '*/*',
            'Content-Disposition' : 'attachment; filename=poidownload.csv'
        }
        
        return ("application/octet-stream;", output, headers, '')

    def encode_exception_report(self, exceptionReport):
        csv = vectorformats.Formats.CSV.CSV()
        headers = {
            'Accept': '*/*',
            'Content-Disposition' : 'attachment; filename=poidownload.csv'
        }
        return ("application/octet-stream;", csv.encode_exception_report(exceptionReport), headers, '')
########NEW FILE########
__FILENAME__ = DXF
'''
@author: Michel Ott
'''
from FeatureServer.Service.Request import Request
import StringIO
import os
import tempfile
import vectorformats.Formats.DXF

class DXF(Request):
    def encode(self, result):
        dxf = vectorformats.Formats.DXF.DXF(layername=self.datasources[0], datasource=self.service.datasources[self.datasources[0]])
        
        try:
            fd, temp_path = tempfile.mkstemp()
            os.close(fd)
            
            drawing = dxf.encode(result, tmpFile=temp_path)
            
            output = StringIO.StringIO(open(temp_path).read())
        finally:
            os.remove(temp_path)
        
        
        headers = {
            'Accept': '*/*',
            'Content-Disposition' : 'attachment; filename=poidownload.dxf',
            'Content-Transfer-Encoding' : 'binary'
        }
        
        return ("application//octet-stream;", output, headers, '')
########NEW FILE########
__FILENAME__ = GeoJSON
__author__  = "MetaCarta"
__copyright__ = "Copyright (c) 2006-2008 MetaCarta"
__license__ = "Clear BSD" 
__version__ = "$Id: GeoJSON.py 483 2008-05-18 10:38:32Z crschmidt $"

from FeatureServer.Service.Request import Request
from FeatureServer.Service.Action import Action
from vectorformats.Feature import Feature
import vectorformats.Formats.GeoJSON 

try:
    import simplejson
except Exception, E:
    raise Exception("simplejson is required for using the JSON service. (Import failed: %s)" % E)

class GeoJSON(Request):
    def __init__(self, service):
        Request.__init__(self, service)
        self.callback = None
    
    def encode_metadata(self, action):
        layers = self.service.datasources
        metadata = []
        for key in layers.keys():
            metadata.append(
              { 
                'name': key,
                'url': "%s/%s" % (self.host, key)
              }
            )
            
        result_data = {'Layers': metadata}
        
        result = simplejson.dumps(result_data) 
        if self.callback:
            result = "%s(%s);" % (self.callback, result)
        
        return ("text/plain", result, None)
    
    def parse(self, params, path_info, host, post_data, request_method, format_obj=None):
        if 'callback' in params:
            self.callback = params['callback']
        g = vectorformats.Formats.GeoJSON.GeoJSON()
        Request.parse(self, params, path_info, host, post_data, request_method, format_obj=g)     
    
    def encode(self, result):
        g = vectorformats.Formats.GeoJSON.GeoJSON()
        result = g.encode(result)
        
        if self.datasources[0]:
            datasource = self.service.datasources[self.datasources[0]]
        
        if self.callback and datasource and hasattr(datasource, 'gaping_security_hole'):
            return ("text/plain", "%s(%s);" % (self.callback, result), None, 'utf-8')
        else:    
            return ("text/plain", result, None, 'utf-8')

    def encode_exception_report(self, exceptionReport):
        geojson = vectorformats.Formats.GeoJSON.GeoJSON()
        return ("text/plain", geojson.encode_exception_report(exceptionReport), None, 'utf-8')


########NEW FILE########
__FILENAME__ = GeoRSS
__author__  = "MetaCarta"
__copyright__ = "Copyright (c) 2006-2008 MetaCarta"
__license__ = "Clear BSD" 
__version__ = "$Id: GeoRSS.py 482 2008-05-18 10:36:44Z crschmidt $"

from FeatureServer.Service.Request import Request
import vectorformats.Formats.GeoRSS

class GeoRSS(Request):
    def encode_metadata(self, action):
        layers = self.service.datasources
        layer_text = []
        for layer in layers.keys():
            layer_text.append("<collection href='%s/%s/all.atom'><atom:title>%s</atom:title></collection>" % (self.host, layer, layer))
            
        action.metadata = """<?xml version="1.0" encoding="utf-8"?>
<service xmlns="http://www.w3.org/2007/app" xmlns:atom="http://www.w3.org/2005/Atom">
  <workspace>
    <atom:title>FeatureServer</atom:title>
    %s
  </workspace>
</service>
""" % ("\n".join(layer_text))
        return ("application/rss+xml", action.metadata, None)
    
    def encode(self, result):
        atom = vectorformats.Formats.GeoRSS.GeoRSS(url=self.host, feedname=self.datasources[0]) 
        results = atom.encode(result)
        return ("application/atom+xml", results, None, 'utf-8')
    
    def parse(self, params, path_info, host, post_data, request_method):
        self.get_layer(path_info, params)

        atom = vectorformats.Formats.GeoRSS.GeoRSS(url=self.host, feedname=self.datasources[0]) 
        Request.parse(self, params, path_info, host, post_data, request_method, format_obj = atom) 
            
    def encode_exception_report(self, exceptionReport):
        atom = vectorformats.Formats.GeoRSS.GeoRSS(url=self.host) 
        return ("application/atom+xml", atom.encode_exception_report(exceptionReport), None, 'utf-8')

########NEW FILE########
__FILENAME__ = GPX
'''
Created on Jul 30, 2011

@author: michel
'''

from FeatureServer.Service.Request import Request
import vectorformats.Formats.GPX

class GPX(Request):
    def encode(self, results):
        gpx = vectorformats.Formats.GPX.GPX(layername=self.datasources[0])
        
        output = gpx.encode(results)
        return ("application/xml", output, None, 'utf-8')
        
########NEW FILE########
__FILENAME__ = HTML
from FeatureServer.Service.Request import Request
import vectorformats.Formats.HTML

class HTML (Request):    
    #def encode_metadata(self, action):
    #    layers = self.service.datasources
    #    if self.service.metadata.has_key("metadata_template"):
    #        self.metadata_template = self.service.metadata['metadata_template']
            
    #    template = file(self.metadata_template).read()
    #    output = Template(template, searchList = [{'layers': layers, 'datasource':self.datasources[0]}, self])
    #    return  "text/html; charset=utf-8", str(output).decode("utf-8")

    def encode(self, result):
        html = vectorformats.Formats.HTML.HTML(datasource=self.service.datasources[self.datasources[0]])
        
        output = html.encode(result)
        
        return ("text/html; charset=utf-8", str(output).decode("utf-8"), None, 'utf-8')
    
    def encode_exception_report(self, exceptionReport):
        html = vectorformats.Formats.HTML.HTML()
        
        output = html.encode_exception_report(exceptionReport)
        
        return ("text/html; charset=utf-8", str(output).decode("utf-8"), None, 'utf-8')
    

########NEW FILE########
__FILENAME__ = KML
__author__  = "MetaCarta"
__copyright__ = "Copyright (c) 2006-2008 MetaCarta"
__license__ = "Clear BSD" 
__version__ = "$Id: KML.py 556 2008-05-21 16:32:45Z crschmidt $"

from FeatureServer.Service.Request import Request
import vectorformats.Formats.KML

class KML(Request):
    mime_type = "application/vnd.google-earth.kml+xml"

    def encode(self, result):
        kml = vectorformats.Formats.KML.KML(url=self.host, layername=self.datasources[0]) 
        results = kml.encode(result)
        return ("application/vnd.google-earth.kml+xml", results, None, 'utf-8')        
    
    def parse(self, params, path_info, host, post_data, request_method):
        self.get_layer(path_info, params)

        kml = vectorformats.Formats.KML.KML(url=self.host, layername=self.datasources[0])
        Request.parse(self, params, path_info, host, post_data, request_method, format_obj=kml) 
    
    def encode_metadata(self, action):
        results = ["""<?xml version="1.0" encoding="UTF-8"?>
<kml xmlns="http://earth.google.com/kml/2.0" xmlns:fs="http://featureserver.com/ns" xmlns:atom="http://www.w3.org/2005/Atom">
<Folder>
<atom:link rel="self" href="%s" type="application/vnd.google-earth.kml+xml" />""" % self.host]

        layers = self.service.datasources
        for key in layers.keys():
            results.append("""<NetworkLink>
        <name>%s</name>
        <open>0</open>
        <Url>
                <href>%s/%s/all.kml?maxfeatures=50</href>
                <viewRefreshMode>onStop</viewRefreshMode>
                <viewRefreshTime>1</viewRefreshTime>
        </Url>
</NetworkLink>""" % (key, self.host, key))
        results.append("</Folder></kml>")     
        
        return (self.mime_type, "\n".join(results), {'Content-Disposition': "attachment; filename=featureserver_networklink.kml"})

########NEW FILE########
__FILENAME__ = OSM
__author__  = "MetaCarta"
__copyright__ = "Copyright (c) 2006-2008 MetaCarta"
__license__ = "Clear BSD" 
__version__ = "$Id: OSM.py 491 2008-05-18 11:28:45Z crschmidt $"

from FeatureServer.Service.Request import Request
import vectorformats.Formats.OSM

class OSM(Request):
    def encode(self, result):
        osm = vectorformats.Formats.OSM.OSM()
        
        results = osm.encode(result)
        
        return ("application/xml", results, None, 'utf-8')
        
########NEW FILE########
__FILENAME__ = OV2
'''
Created on Jul 30, 2011

@author: michel
'''

from FeatureServer.Service.Request import Request
import vectorformats.Formats.OV2

class OV2(Request):
    def encode(self, results):
        ov2 = vectorformats.Formats.OV2.OV2(layername=self.datasources[0])
        
        output = ov2.encode(results)

        headers = {
            'Accept': '*/*',
            'Content-Disposition' : 'attachment; filename=poidownload.ov2',
            'Content-Transfer-Encoding' : 'binary'
        }
        
        return ("application/octet-stream", output, headers, '')
        
########NEW FILE########
__FILENAME__ = Request

import FeatureServer
from FeatureServer.Service.Action import Action
from FeatureServer.WebFeatureService.WFSRequest import WFSRequest
from web_request.handlers import ApplicationException
from FeatureServer.Exceptions.LayerNotFoundException import LayerNotFoundException
from FeatureServer.Exceptions.NoLayerException import NoLayerException

class Request (object):
    
    query_action_types = []
    
    def __init__ (self, service):
        self.service     = service
        #self.datasource  = None
        self.datasources = []
        self.actions     = []
        self.host        = None
    
    def encode_metadata(self, action):
        """Accepts an action, which is of method 'metadata' and
            may have one attribute, 'metadata', which includes
            information parsed by the service parse method. This
            should return a content-type, string tuple to be delivered
            as metadata to the Server for delivery to the client."""
        data = []
        if action.metadata:
            data.append(action.metadata)
        else:
            data.append("The following layers are available:")
            for layer in self.service.datasources:
                data.append(" * %s, %s/%s" % (layer, self.host, layer))
        return ("text/plain", "\n".join(data))

    def parse(self, params, path_info, host, post_data, request_method, format_obj = None):
        """Used by most of the subclasses without changes. Does general
            processing of request information using request method and
            path/parameter information, to build up a list of actions.
            Returns a list of Actions. If the first action in the list is
            of method 'metadata', encode_metadata is called (no datasource
            is touched), and encode_metadata is called. Otherwise, the actions
            are passed onto DataSources to create lists of Features."""
        self.host = host
        
        try:
            self.get_layer(path_info, params)
        except NoLayerException as e:
            a = Action()
            
            if params.has_key('service') and params['service'].lower() == 'wfs':
                for layer in self.service.datasources:
                    self.datasources.append(layer)
                if params.has_key('request'):
                    a.request = params['request']
                else:
                    a.request = "GetCapabilities"
            else:
                a.method = "metadata"
            
            self.actions.append(a)
            return

        for datasource in self.datasources:
            if not self.service.datasources.has_key(datasource):
                raise LayerNotFoundException("Request", datasource, self.service.datasources.keys())

        action = Action()

        if request_method == "GET" or (request_method == "OPTIONS" and (post_data is None or len(post_data) <= 0)):
            action = self.get_select_action(path_info, params)

        elif request_method == "POST" or request_method == "PUT" or (request_method == "OPTIONS" and len(post_data) > 0):
            actions = self.handle_post(params, path_info, host, post_data, request_method, format_obj = format_obj)
            for action in actions:
                self.actions.append(action)
            
            return

        elif request_method == "DELETE":
            id = self.get_id_from_path_info(path_info)
            if id is not False:
                action.id = id
                action.method = "delete"

        self.actions.append(action)

    def get_id_from_path_info(self, path_info):
        """Pull Feature ID from path_info and return it."""
        try:
            path = path_info.split("/")
            path_pieces = path[-1].split(".")
            if len(path_pieces) > 1:
                return int(path_pieces[0])
            if path_pieces[0].isdigit():
                return int(path_pieces[0])
        except:
            return False
        return False

    def get_select_action(self, path_info, params):
        """Generate a select action from a URL. Used unmodified by most
            subclasses. Handles attribute query by following the rules passed in
            the DS or in the request, bbox, maxfeatures, and startfeature by
            looking for the parameters in the params. """
        action = Action()
        action.method = "select"
        
        id = self.get_id_from_path_info(path_info)
        
        if id is not False:
            action.id = id
        
        else:
            import sys
            for ds in self.datasources:
                queryable = []
                #ds = self.service.datasources[self.datasource]
                if hasattr(ds, 'queryable'):
                    queryable = ds.queryable.split(",")
                elif params.has_key("queryable"):
                    queryable = params['queryable'].split(",")
                for key, value in params.items():
                    qtype = None
                    if "__" in key:
                        key, qtype = key.split("__")
                    if key == 'bbox':
                        action.bbox = map(float, value.split(","))
                    elif key == "maxfeatures":
                        action.maxfeatures = int(value)
                    elif key == "startfeature":
                        action.startfeature = int(value)
                    elif key == "request":
                        action.request = value
                    elif key == "version":
                        action.version = value
                    elif key == "filter":
                        action.wfsrequest = WFSRequest()
                        try:
                            action.wfsrequest.parse(value)
                        except Exception, E:
                            ''' '''

                    elif key in queryable or key.upper() in queryable and hasattr(self.service.datasources[ds], 'query_action_types'):
                        if qtype:
                            if qtype in self.service.datasources[ds].query_action_types:
                                action.attributes[key+'__'+qtype] = {'column': key, 'type': qtype, 'value':value}
                            else:
                                raise ApplicationException("%s, %s, %s\nYou can't use %s on this layer. Available query action types are: \n%s" % (self, self.query_action_types, qtype,
                                                                                                                                                   qtype, ",".join(self.service.datasources[ds].query_action_types) or "None"))
                        else:
                            action.attributes[key+'__eq'] = {'column': key, 'type': 'eq', 'value':value}
                            #action.attributes[key] = value
        
        return action
    
    def get_layer(self, path_info, params = {}):
        """Return layer based on path, or raise a NoLayerException."""
        if params.has_key("typename"):
            self.datasources = params["typename"].split(",")
            return
        
        path = path_info.split("/")
        if len(path) > 1 and path_info != '/':
            self.datasources.append(path[1])
        if params.has_key("layer"):
            self.datasources.append(params['layer'])
        
        if len(self.datasources) == 0:
            raise NoLayerException("Request", message="Could not obtain data source from layer parameter or path info.")

    def handle_post(self, params, path_info, host, post_data, request_method, format_obj = None):
        """Read data from the request and turn it into an UPDATE/DELETE action."""
        
        if format_obj:
            actions = []
            
            id = self.get_id_from_path_info(path_info)
            if id is not False:
                action = Action()
                action.method = "update"
                action.id = id
                
                features = format_obj.decode(post_data)
                
                action.feature = features[0]
                actions.append(action)
            
            else:
                if hasattr(format_obj, 'decode'):
                    features = format_obj.decode(post_data)
                    
                    for feature in features:
                        action = Action()
                        action.method = "insert"
                        action.feature = feature
                        actions.append(action)
            
                elif hasattr(format_obj, 'parse'):
                    format_obj.parse(post_data)
                    
                    transactions = format_obj.getActions()
                    if transactions is not None:
                        for transaction in transactions:
                            action = Action()
                            action.method = transaction.__class__.__name__.lower()
                            action.wfsrequest = transaction
                            actions.append(action)
            
            return actions
        else:
            raise Exception("Service type does not support adding features.")

    def encode(self, result):
        """Accepts a list of lists of features. Each list is generated by one datasource
            method call. Must return a (content-type, string) tuple."""
        results = ["Service type doesn't support displaying data, using naive display."""]
        for action in result:
            for i in action:
                data = i.to_dict()
                for key,value in data['properties'].items():
                    if value and isinstance(value, str):
                        data['properties'][key] = unicode(value,"utf-8")
                results.append(" * %s" % data)
        
        return ("text/plain", "\n".join(results), None)
    
    def getcapabilities(self, version): pass
    def describefeaturetype(self, version): pass



########NEW FILE########
__FILENAME__ = SHP
'''
Created on May 18, 2011

@author: michel
'''
from FeatureServer.Service.Request import Request
import vectorformats.Formats.SHP
import zipfile
import StringIO
from lxml import etree

class SHP(Request):
    def encode(self, result):
        shp = vectorformats.Formats.SHP.SHP(layername=self.datasources[0], datasource=self.service.datasources[self.datasources[0]])
        (shpBuffer, shxBuffer, dbfBuffer, prjBuffer)  = shp.encode(result)

        output = StringIO.StringIO()
        
        zip = zipfile.ZipFile(output, "w")
        
        zip.writestr('pois.shp', shpBuffer.getvalue())
        zip.writestr('pois.shx', shxBuffer.getvalue())
        zip.writestr('pois.dbf', dbfBuffer.getvalue())
        zip.writestr('pois.prj', prjBuffer.getvalue())
        
        
        
        readme = """
You have downloaded the POIs from the POI Service with the following Query:\n
%s\n
\n
The downloaded data underlie the OpenStreetMap copyrights and licenses.\n
http://www.openstreetmap.org/copyright
"""
        
        if hasattr(self.actions[0], 'filterEncoding'):
            readme = readme % str(self.actions[0].filterEncoding)
        else:
            if hasattr(self.actions[0], 'wfsrequest'):
                readme = readme % self.actions[0].wfsrequest.data
            else:
                readme = readme % 'unknown'
        
        zip.writestr('README.txt', readme)

        headers = {
            'Accept': '*/*',
            'Content-Disposition' : 'attachment; filename=poidownload.zip',
            'Content-Transfer-Encoding' : 'binary'
        }
        
        return ("application/zip;", output, headers, '')
        
########NEW FILE########
__FILENAME__ = SQLite
'''
Created on Sep 14, 2012

@author: michel
'''
from FeatureServer.Service.Request import Request
import StringIO
import os
import tempfile
import vectorformats.Formats.SQLite

class SQLite(Request):
    def encode(self, result):
        sqlite = vectorformats.Formats.SQLite.SQLite(layername=self.datasources[0], datasource=self.service.datasources[self.datasources[0]])
        
        try:
            fd, temp_path = tempfile.mkstemp()
            os.close(fd)
            
            connection = sqlite.encode(result, tmpFile=temp_path)
        
            output = StringIO.StringIO(open(temp_path).read())
        finally:
            os.remove(temp_path)
            
        
        headers = {
            'Accept': '*/*',
            'Content-Disposition' : 'attachment; filename=poidownload.sqlite3',
            'Content-Transfer-Encoding' : 'binary'
        }
        
        return ("application//octet-stream;", output, headers, '')
########NEW FILE########
__FILENAME__ = WFS
__author__  = "MetaCarta"
__copyright__ = "Copyright (c) 2006-2008 MetaCarta"
__license__ = "Clear BSD" 
__version__ = "$Id: WFS.py 485 2008-05-18 10:51:09Z crschmidt $"

from FeatureServer.Service.Request import Request
from FeatureServer.Service.Action import Action
from FeatureServer.Exceptions.NoLayerException import NoLayerException

import vectorformats.Formats.WFS
from FeatureServer.WebFeatureService.WFSRequest import WFSRequest
from FeatureServer.WebFeatureService.Response.TransactionResponse import TransactionResponse

class WFS(Request):
    def encode(self, results):
        wfs = vectorformats.Formats.WFS.WFS(layername=self.datasources[0])
        
        if isinstance(results, TransactionResponse):
            return ("text/xml", wfs.encode_transaction(results), None, 'utf-8')
        
        output = wfs.encode(results)
        return ("text/xml", output, None, 'utf-8')
    
    def encode_exception_report(self, exceptionReport):
        wfs = vectorformats.Formats.WFS.WFS()
        return ("text/xml", wfs.encode_exception_report(exceptionReport), None, 'utf-8')
        
    def parse(self, params, path_info, host, post_data, request_method):
        self.host = host
        
        try:
            self.get_layer(path_info, params)
        except NoLayerException as e:
            a = Action()
            
            if params.has_key('service') and params['service'].lower() == 'wfs':
                for layer in self.service.datasources:
                    self.datasources.append(layer)
                if params.has_key('request'):
                    a.request = params['request']
                else:
                    a.request = "GetCapabilities"
            else:
                a.method = "metadata"
            
            self.actions.append(a)
            return
        
        wfsrequest = WFSRequest()
        try:
            Request.parse(self, params, path_info, host, post_data, request_method, format_obj=wfsrequest)
        except:
            raise

    def getcapabilities(self, version):
        wfs = vectorformats.Formats.WFS.WFS(layers=self.datasources, datasources=self.service.datasources, host=self.host)
        result = wfs.getcapabilities()
        return ("text/xml", result)
    
    def describefeaturetype(self, version):
        wfs = vectorformats.Formats.WFS.WFS(layers=self.datasources, datasources=self.service.datasources, host=self.host)
        result = wfs.describefeaturetype()
        return ("text/xml; subtype=gml/3.1.1", result)
    
########NEW FILE########
__FILENAME__ = ComparisonOperator
'''
Created on Apr 5, 2011

@author: michel
'''
import os
from lxml import etree
from FeatureServer.WebFeatureService.FilterEncoding.Operator import Operator

class ComparisonOperator(Operator):
    def __init__(self, node):
        super(ComparisonOperator, self).__init__(node)
        self.type = 'ComparisonOperator'
    
    def getValueReference(self): return str(self.node.ValueReference)
    def getPropertyName(self): return str(self.node.PropertyName)
    def getLiteral(self): return str(self.node.Literal)
    def createStatement(self, datasource):
        xslt = etree.parse(os.path.dirname(os.path.abspath(__file__))+"/../../../../resources/filterencoding/comparison_operators.xsl")
        transform = etree.XSLT(xslt)
        
        if hasattr(datasource, 'hstore'):
            result = transform(self.node, datasource="'"+datasource.type+"'", operationType="'"+str(self.node.xpath('local-name()'))+"'", hstore="'"+str(datasource.hstore).lower()+"'", hstoreAttribute="'"+datasource.hstoreAttribute+"'")
        else:
            result = transform(self.node, datasource="'"+datasource.type+"'", operationType="'"+str(self.node.xpath('local-name()'))+"'")

        elements = result.xpath("//Statement")
        if len(elements) > 0:
            self.setStatement(str(elements[0]))
            return
        self.setStatement(None)
    
########NEW FILE########
__FILENAME__ = PropertyIsBetween
'''
Created on Apr 5, 2011

@author: michel
'''

from FeatureServer.WebFeatureService.FilterEncoding.ComparisonOperators.ComparisonOperator import ComparisonOperator

class PropertyIsBetween(ComparisonOperator):
    def getLiteral(self):
        return ""
    def getLowerBoundary(self):
        return str(self.node.LowerBoundary.Literal)
    def getUpperBoundary(self):
        return str(self.node.UpperBoundary.Literal)
    
########NEW FILE########
__FILENAME__ = PropertyIsEqualTo
'''
Created on Apr 5, 2011

@author: michel
'''
from FeatureServer.WebFeatureService.FilterEncoding.ComparisonOperators.ComparisonOperator import ComparisonOperator

class PropertyIsEqualTo(ComparisonOperator):
    ''' '''
    
########NEW FILE########
__FILENAME__ = PropertyIsGreaterThan
'''
Created on Apr 5, 2011

@author: michel
'''

from FeatureServer.WebFeatureService.FilterEncoding.ComparisonOperators.ComparisonOperator import ComparisonOperator

class PropertyIsGreaterThan(ComparisonOperator):
    ''' '''
########NEW FILE########
__FILENAME__ = PropertyIsGreaterThanOrEqualTo
'''
Created on Apr 5, 2011

@author: michel
'''

from FeatureServer.WebFeatureService.FilterEncoding.ComparisonOperators.ComparisonOperator import ComparisonOperator

class PropertyIsGreaterThanOrEqualTo(ComparisonOperator):
    ''' '''
########NEW FILE########
__FILENAME__ = PropertyIsLessThan
'''
Created on Apr 5, 2011

@author: michel
'''

from FeatureServer.WebFeatureService.FilterEncoding.ComparisonOperators.ComparisonOperator import ComparisonOperator

class PropertyIsLessThan(ComparisonOperator):
    ''' '''
########NEW FILE########
__FILENAME__ = PropertyIsLessThanOrEqualTo
'''
Created on Apr 5, 2011

@author: michel
'''

from FeatureServer.WebFeatureService.FilterEncoding.ComparisonOperators.ComparisonOperator import ComparisonOperator

class PropertyIsLessThanOrEqualTo(ComparisonOperator):
    ''' '''
########NEW FILE########
__FILENAME__ = PropertyIsLike
'''
Created on Apr 5, 2011

@author: michel
'''

from FeatureServer.WebFeatureService.FilterEncoding.ComparisonOperators.ComparisonOperator import ComparisonOperator

class PropertyIsLike(ComparisonOperator):
    ''' '''
########NEW FILE########
__FILENAME__ = PropertyIsNil
'''
Created on Apr 5, 2011

@author: michel
'''

from FeatureServer.WebFeatureService.FilterEncoding.ComparisonOperators.ComparisonOperator import ComparisonOperator

class PropertyIsNil(ComparisonOperator):
    ''' '''
########NEW FILE########
__FILENAME__ = PropertyIsNotEqualTo
'''
Created on Apr 5, 2011

@author: michel
'''

from FeatureServer.WebFeatureService.FilterEncoding.ComparisonOperators.ComparisonOperator import ComparisonOperator

class PropertyIsNotEqualTo(ComparisonOperator):
    ''' '''
########NEW FILE########
__FILENAME__ = PropertyIsNull
'''
Created on Apr 5, 2011

@author: michel
'''

from FeatureServer.WebFeatureService.FilterEncoding.ComparisonOperators.ComparisonOperator import ComparisonOperator

class PropertyIsNull(ComparisonOperator):
    ''' '''
    def getPropertyName(self): return str(self.node.PropertyName)
        
########NEW FILE########
__FILENAME__ = FilterAttributes
'''
Created on Nov 3, 2012
    
@author: michel
'''

import os
from lxml import etree

class FilterAttributes(object):
    
    node = None
    
    def __init__(self, node):
        self.node = node
    
    def render(self):
        xslt = etree.parse(os.path.dirname(os.path.abspath(__file__))+"/../../../resources/filterencoding/filter_attributes.xsl")
        transform = etree.XSLT(xslt)
        result = transform(self.node)
        
        elements = result.xpath("//Attributes")
        if len(elements) > 0:
            str_list =  elements[0].text.strip().split(',')
            str_list = filter(None, str_list)
            str_list = filter(lambda x: len(x) > 0, str_list)
            return str_list
        return []


########NEW FILE########
__FILENAME__ = FilterEncoding
'''
Created on Apr 5, 2011

@author: michel
'''

import os
import sys
from lxml import etree
from lxml import objectify

class FilterEncoding (object):
    
    xml = ""
    tree = None
    dom = None
    namespaces = {'gml' : 'http://www.opengis.net/gml'}

    
    def __init__(self, xml):
        self.parser = objectify.makeparser(remove_blank_text=True, ns_clean=True)
        xml = xml.replace('wildCard="*"', 'wildCard="\*"')
        xml = xml.replace('wildCard="?"', 'wildCard="\?"')
        xml = xml.replace('wildCard="."', 'wildCard="\."')

        xml = xml.replace('singleChar="*"', 'singleChar="\*"')
        xml = xml.replace('singleChar="?"', 'singleChar="\?"')
        xml = xml.replace('singleChar="."', 'singleChar="\."')
        
        xml = xml.replace('escapeChar="*"', 'escapeChar="\*"')
        xml = xml.replace('escapeChar="?"', 'escapeChar="\?"')
        xml = xml.replace('escapeChar="."', 'escapeChar="\."')
        
        
        #add global namespaces - duplicate namespaces will be removed by parser.
        nsFilter = '<Filter'
        for key, value in self.namespaces.iteritems():
            nsFilter += ' xmlns:' + key + '="' + value + '"'
        self.xml = xml.replace('<Filter', nsFilter)
        
        self.dom = etree.XML(self.xml, parser=self.parser)
    
    def parse(self, node = None, operator = None):
        if node == None:
            node = self.dom
        
        operator_class = None
        
        for child in node.iterchildren():
            if str(child.xpath('local-name()')) == 'ValueReference' or str(child.xpath('local-name()')) == 'PropertyName'  or str(child.xpath('local-name()')) == 'Literal' or str(child.xpath('local-name()')) == 'Envelope' or str(child.xpath('local-name()')) == 'lowerCorner' or str(child.xpath('local-name()')) == 'upperCorner':
                return
            
            operator_class = self.getFilterInstance(child)
            
            if operator != None:
                operator.appendChild(operator_class)
            
            if len(child) > 0:
                self.parse(node=child, operator=operator_class)
            
                    
        self.tree = operator_class
    
    def getFilterInstance(self, node):
        try:
            sys.path.append(os.path.dirname(os.path.abspath(__file__)))
            sys.path.append(os.path.dirname(os.path.abspath(__file__))+"/ComparisonOperators")
            sys.path.append(os.path.dirname(os.path.abspath(__file__))+"/LogicalOperators")
            sys.path.append(os.path.dirname(os.path.abspath(__file__))+"/ObjectIdentifiers")
            sys.path.append(os.path.dirname(os.path.abspath(__file__))+"/SpatialOperators")
            operator_module = __import__(str(node.xpath('local-name()')), globals(), locals())
        except ImportError:
            raise Exception("Could not find filter for %s" % node.xpath('local-name()'))
        
        operator_func = getattr(operator_module, node.xpath('local-name()'))
        return operator_func(node)

    def render(self, datasource, node = None):
        if node == None:
            node = self.tree
        
        self.create(datasource, node)
        return self.assemble(datasource=datasource, node=node)
            
    def assemble(self, datasource, node, sql = ''):
        
        #node.children.reverse()
        
        for child in node:
            sql += self.assemble(datasource, child, sql)
            
        # assemble statement
        if node.type == 'LogicalOperator':
            node.createStatement(datasource, node.children)
            sql = node.getStatement()
            return sql
        return node.getStatement()
    
    def create(self, datasource, node):
        for child in node:
            self.create(datasource, child)
        
        if node.type != 'LogicalOperator':
            node.createStatement(datasource)

    def getAttributes(self):
        from FilterAttributes import FilterAttributes
        filter = FilterAttributes(self.dom)
        return filter.render()

    def __str__(self):
        return etree.tostring(self.dom, pretty_print = True)
        
########NEW FILE########
__FILENAME__ = And
'''
Created on Apr 5, 2011

@author: michel
'''

from FeatureServer.WebFeatureService.FilterEncoding.LogicalOperators.LogicalOperator import LogicalOperator

class And(LogicalOperator):
    ''' '''
########NEW FILE########
__FILENAME__ = LogicalOperator
'''
Created on Apr 20, 2011

@author: michel
'''
import os
from lxml import etree
from FeatureServer.WebFeatureService.FilterEncoding.Operator import Operator

class LogicalOperator(Operator):
    def __init__(self, node):
        super(LogicalOperator, self).__init__(node)
        self.type = 'LogicalOperator'
        
    def createStatement(self, datasource, operatorList):
        logical = self.addOperators(operatorList)
                
        xslt = etree.parse(os.path.dirname(os.path.abspath(__file__))+"/../../../../resources/filterencoding/logical_operators.xsl")
        transform = etree.XSLT(xslt)
        result = transform(logical, datasource="'"+datasource.type+"'", operationType="'"+str(self.node.xpath('local-name()'))+"'")
        elements = result.xpath("//Statement")
        if len(elements) > 0:
            self.setStatement(str(elements[0].text).strip())
            return
        self.setStatement(None)
        
    def addOperators(self, operatorList):
        logical = etree.Element(self.node.tag)
        
        for operator in operatorList:
            element = etree.Element("Operator")
            element.text = operator.stmt
            logical.append(element)
        
        return logical
    
########NEW FILE########
__FILENAME__ = Not
'''
Created on Apr 5, 2011

@author: michel
'''

from FeatureServer.WebFeatureService.FilterEncoding.LogicalOperators.LogicalOperator import LogicalOperator

class Not(LogicalOperator):
    ''' '''
########NEW FILE########
__FILENAME__ = Or
'''
Created on Apr 5, 2011

@author: michel
'''

from FeatureServer.WebFeatureService.FilterEncoding.LogicalOperators.LogicalOperator import LogicalOperator

class Or(LogicalOperator):
    ''' '''
########NEW FILE########
__FILENAME__ = FeatureId
'''
Created on Apr 5, 2011

@author: michel
'''

from FeatureServer.WebFeatureService.FilterEncoding.ObjectIdentifiers.ObjectIdentifier import ObjectIdentifier

class FeatureId(ObjectIdentifier):
    ''' '''
########NEW FILE########
__FILENAME__ = ObjectIdentifier
'''
Created on Apr 20, 2011

@author: michel
'''
import os
from lxml import etree
from FeatureServer.WebFeatureService.FilterEncoding.Operator import Operator

class ObjectIdentifier(Operator):
    def __init__(self, node):
        super(ObjectIdentifier, self).__init__(node)
        self.type = 'ObjectIndentifier'
    
    def getResourceId(self): return str(self.node.attrib('rid'))
    def createStatement(self, datasource):
        xslt = etree.parse(os.path.dirname(os.path.abspath(__file__))+"/../../../../resources/filterencoding/object_identifiers.xsl")
        transform = etree.XSLT(xslt)
        result = transform(self.node, datasource="'"+datasource.type+"'", operationType="'"+str(self.node.xpath('local-name()'))+"'", attributeIdName="'"+datasource.fid_col+"'")
        elements = result.xpath("//Statement")
        if len(elements) > 0:
            self.setStatement(str(elements[0]))
            return
        self.setStatement(None)
                
########NEW FILE########
__FILENAME__ = ResourceId
'''
Created on Apr 5, 2011

@author: michel
'''

from FeatureServer.WebFeatureService.FilterEncoding.ObjectIdentifiers.ObjectIdentifier import ObjectIdentifier

class ResourceId(ObjectIdentifier):
    ''' '''
########NEW FILE########
__FILENAME__ = Operator
'''
Created on Apr 5, 2011

@author: michel
'''


class Operator(object):
    namespaces = {'ofs' : 'http://www.someserver.com/myns'}
    children = None
    index = 0
    type = ''
    stmt = None
    node = None
    
    def __init__(self, node):
        self.node = node
        self.children = []
        self.type = ''
        self.stmt = None
    
    def getStatement(self, datasource = None):
        if self.stmt == None and datasource != None:
            self.createStatement(datasource)
        return self.stmt
    
    def setStatement(self, stmt):
        self.stmt = stmt
        
    def createStatement(self, datasource): pass
    
    def appendChild(self, node):
        self.children.append(node)
    
    def __len__(self):
        return len(self.children)
    
    def __iter__(self):
        self.index = 0
        return self
    
    def next(self):
        if self.index >= len(self):
            raise StopIteration
        child = self.children[self.index]
        self.index += 1
        return child
        
    def get(self, index):
        return self.children[index]
    
    def hasChildren(self):
        if len(self) > 0:
            return True
    
    def getChildren(self):
        return self.children
       
    def getName(self):
        return str(self.node.tag)
    
########NEW FILE########
__FILENAME__ = Select
'''
Created on Dec 10, 2011

@author: michel
'''
from FeatureServer.WebFeatureService.FilterEncoding.FilterEncoding import FilterEncoding

class Select(object):
    
    data = ""
    filter = None

    def __init__(self, data):
        self.data = data
        self.filter = FilterEncoding(self.data)
        self.filter.parse();
    
    def render(self, datasource):
        return self.filter.render(datasource)

    def getAttributes(self):
        return self.filter.getAttributes()
        
        
########NEW FILE########
__FILENAME__ = BBOX
'''
Created on May 9, 2011

@author: michel
'''

from FeatureServer.WebFeatureService.FilterEncoding.SpatialOperators.SpatialOperator import SpatialOperator

class BBOX(SpatialOperator):
    ''' '''
            
########NEW FILE########
__FILENAME__ = Beyond
'''
Created on May 9, 2011

@author: michel
'''

from FeatureServer.WebFeatureService.FilterEncoding.SpatialOperators.SpatialOperator import SpatialOperator

class Beyond(SpatialOperator):
    ''' '''
            
########NEW FILE########
__FILENAME__ = Contains
'''
Created on May 9, 2011

@author: michel
'''

from FeatureServer.WebFeatureService.FilterEncoding.SpatialOperators.SpatialOperator import SpatialOperator

class Contains(SpatialOperator):
    ''' '''
            
########NEW FILE########
__FILENAME__ = Crosses
'''
Created on May 9, 2011

@author: michel
'''

from FeatureServer.WebFeatureService.FilterEncoding.SpatialOperators.SpatialOperator import SpatialOperator

class Crosses(SpatialOperator):
    ''' '''
            
########NEW FILE########
__FILENAME__ = Disjoint
'''
Created on May 9, 2011

@author: michel
'''

from FeatureServer.WebFeatureService.FilterEncoding.SpatialOperators.SpatialOperator import SpatialOperator

class Disjoint(SpatialOperator):
    ''' '''
            
########NEW FILE########
__FILENAME__ = DWithin
'''
Created on May 9, 2011

@author: michel
'''

from FeatureServer.WebFeatureService.FilterEncoding.SpatialOperators.SpatialOperator import SpatialOperator

class DWithin(SpatialOperator):
    ''' '''
            
########NEW FILE########
__FILENAME__ = Equals
'''
Created on May 9, 2011

@author: michel
'''

from FeatureServer.WebFeatureService.FilterEncoding.SpatialOperators.SpatialOperator import SpatialOperator

class Equals(SpatialOperator):
    ''' '''
            
########NEW FILE########
__FILENAME__ = Intersects
'''
Created on May 9, 2011

@author: michel
'''

from FeatureServer.WebFeatureService.FilterEncoding.SpatialOperators.SpatialOperator import SpatialOperator

class Intersects(SpatialOperator):
    ''' '''
            
########NEW FILE########
__FILENAME__ = Overlaps
'''
Created on May 9, 2011

@author: michel
'''

from FeatureServer.WebFeatureService.FilterEncoding.SpatialOperators.SpatialOperator import SpatialOperator

class Overlaps(SpatialOperator):
    ''' '''
            
########NEW FILE########
__FILENAME__ = SpatialOperator
'''
Created on Apr 5, 2011

@author: michel
'''
import os
from lxml import etree
from FeatureServer.WebFeatureService.FilterEncoding.Operator import Operator

class SpatialOperator(Operator):
    def __init__(self, node):
        super(SpatialOperator, self).__init__(node)
        self.type = 'SpatialOperator'
    
    def getValueReference(self): return str(self.node.ValueReference)
    def getLiteral(self): return str(self.node.Literal)
    def createStatement(self, datasource):
        xslt = etree.parse(os.path.dirname(os.path.abspath(__file__))+"/../../../../resources/filterencoding/spatial_operators.xsl")
        transform = etree.XSLT(xslt_input=xslt)
        result = transform(self.node, datasource="'"+datasource.type+"'", operationType="'"+str(self.node.xpath('local-name()'))+"'", geometryName="'"+datasource.geom_col+"'", srs="'"+str(datasource.srid)+"'")
        
        stmtTxt = ''
        stmtChild = ''
        
        elements = result.xpath("//Statement")
        if len(elements) > 0:
            stmtTxt = elements[0].text
            
            
            elements = result.xpath("//Statement/*")
            if len(elements) > 0:
                stmtChild = etree.tostring(elements[0])
            
            self.setStatement(stmtTxt + stmtChild)
            return
        self.setStatement(None)
    
########NEW FILE########
__FILENAME__ = Touches
'''
Created on May 9, 2011

@author: michel
'''

from FeatureServer.WebFeatureService.FilterEncoding.SpatialOperators.SpatialOperator import SpatialOperator

class Touches(SpatialOperator):
    ''' '''
            
########NEW FILE########
__FILENAME__ = Within
'''
Created on May 9, 2011

@author: michel
'''

from FeatureServer.WebFeatureService.FilterEncoding.SpatialOperators.SpatialOperator import SpatialOperator

class Within(SpatialOperator):
    ''' '''
            
########NEW FILE########
__FILENAME__ = ActionResult
'''
Created on Oct 21, 2011

@author: michel
'''

class ActionResult(object):
    
    def __init__(self, resource, handle):
        self.resource = resource
        self.handle = handle
    
    def getResourceId(self):
        return self.resource
    
    def getHandle(self):
        return self.handle
    
########NEW FILE########
__FILENAME__ = DeleteResult
'''
'''

from FeatureServer.WebFeatureService.Response.ActionResult import ActionResult

class DeleteResult(ActionResult):
    
    def __init__(self, resource, handle):
        ActionResult.__init__(self, resource, handle)
        self.type = 'delete'

########NEW FILE########
__FILENAME__ = InsertResult
'''
'''

from FeatureServer.WebFeatureService.Response.ActionResult import ActionResult

class InsertResult(ActionResult):
    
    def __init__(self, resource, handle):
        ActionResult.__init__(self, resource, handle)
        self.type = 'insert'

########NEW FILE########
__FILENAME__ = ReplaceResult
'''
'''

from FeatureServer.WebFeatureService.Response.ActionResult import ActionResult

class ReplaceResult(ActionResult):
    
    def __init__(self, resource, handle):
        ActionResult.__init__(self, resource, handle)
        self.type = 'replace'
########NEW FILE########
__FILENAME__ = TransactionResponse
'''
Created on Oct 21, 2011

@author: michel
'''
from FeatureServer.WebFeatureService.Response.TransactionSummary import TransactionSummary

from FeatureServer.WebFeatureService.Response.InsertResult import InsertResult
from FeatureServer.WebFeatureService.Response.UpdateResult import UpdateResult
from FeatureServer.WebFeatureService.Response.DeleteResult import DeleteResult
from FeatureServer.WebFeatureService.Response.ReplaceResult import ReplaceResult

class TransactionResponse(object):
    
    summary = None
    insertResults = []
    updateResults = []
    replaceResults = []
    deleteResults = []
    version = '2.0.0'
    
    def setSummary(self, summary):
        self.summary = summary
    
    def getSummary(self):
        return self.summary
    
    def addResult(self, actionResult):
        if type(actionResult) is InsertResult:
            self.addInsertResult(actionResult)
        elif type(actionResult) is UpdateResult:
            self.addUpdateResult(actionResult)
        elif type(actionResult) is DeleteResult:
            self.addDeleteResult(actionResult)
        elif type(actionResult) is ReplaceResult:
            self.addReplaceResult(actionResult)
        
    
    def addInsertResult(self, insertResult):
        self.insertResults.append(insertResult)
        self.getSummary().increaseInserted()
    
    def getInsertResults(self):
        return self.insertResults
    

    def addUpdateResult(self, updateResult):
        self.updateResults.append(updateResult)
        self.getSummary().increaseUpdated()
    
    def getUpdateResults(self):
        return self.updateResults
    

    def addReplaceResult(self, replaceResult):
        self.replaceResults.append(replaceResult)
        self.getSummary().increaseReplaced()
    
    def getReplaceResults(self):
        return self.replaceResults
    
    
    def addDeleteResult(self, deleteResult):
        self.deleteResults.append(deleteResult)
        self.getSummary().increaseDeleted()
    
    def getDeleteResults(self):
        return self.deleteResults


########NEW FILE########
__FILENAME__ = TransactionSummary
'''
Created on Oct 21, 2011

@author: michel
'''

class TransactionSummary(object):
    
    totalInserted = 0
    totalDeleted = 0
    totalUpdated = 0
    totalReplaced = 0
    
    def increaseInserted(self, amount = 1):
        self.totalInserted += amount
    def increaseDeleted(self, amount = 1):
        self.totalDeleted += amount
    def increaseUpdated(self, amount = 1):
        self.totalUpdated += amount
    def increaseReplaced(self, amount = 1):
        self.totalReplaced += amount
    
    def getTotalInserted(self):
        return self.totalInserted
    def getTotalDeleted(self):
        return self.totalDeleted
    def getTotalUpdated(self):
        return self.totalUpdated
    def getTotalReplaced(self):
        return self.totalReplaced
        
########NEW FILE########
__FILENAME__ = UpdateResult
'''
'''

from FeatureServer.WebFeatureService.Response.ActionResult import ActionResult

class UpdateResult(ActionResult):
    
    def __init__(self, resource, handle):
        ActionResult.__init__(self, resource, handle)
        self.type = 'update'
        
########NEW FILE########
__FILENAME__ = Delete
'''
Created on Oct 16, 2011

@author: michel
'''
import os
from FeatureServer.WebFeatureService.Transaction.TransactionAction import TransactionAction
from lxml import etree
import re

class Delete(TransactionAction):
    
    def __init__(self, node):
        super(Delete, self).__init__(node)
        self.type = 'delete'
        
    def createStatement(self, datasource):
        xslt = etree.parse(os.path.dirname(os.path.abspath(__file__))+"/../../../resources/transaction/transactions.xsl")
        transform = etree.XSLT(xslt)
        
        result = transform(self.node,
                           datasource="'"+datasource.type+"'",
                           transactionType="'"+self.type+"'",
                           tableName="'"+datasource.layer+"'",
                           tableId="'"+datasource.fid_col+"'")
        elements = result.xpath("//Statement")
        if len(elements) > 0:
            pattern = re.compile(r'\s+')
            self.setStatement(re.sub(pattern, ' ', str(elements[0])))
            return
        self.setStatement(None)
        
        
########NEW FILE########
__FILENAME__ = Insert
'''
Created on Oct 16, 2011

@author: michel
'''
import os, re
from FeatureServer.WebFeatureService.Transaction.TransactionAction import TransactionAction
from lxml import etree

class Insert(TransactionAction):
    
    def __init__(self, node):
        super(Insert, self).__init__(node)
        self.type = 'insert'
        
    
    def createStatement(self, datasource):
        self.removeAdditionalColumns(datasource)
        
        geom = self.node.xpath("//*[local-name() = '"+datasource.geom_col+"']/*")
        geomData = etree.tostring(geom[0], pretty_print=True)
        xslt = etree.parse(os.path.dirname(os.path.abspath(__file__))+"/../../../resources/transaction/transactions.xsl")
        transform = etree.XSLT(xslt)
        
        result = transform(self.node,
                           datasource="'"+datasource.type+"'",
                           transactionType="'"+self.type+"'",
                           geometryAttribute="'"+datasource.geom_col+"'",
                           geometryData="'"+geomData+"'",
                           tableName="'"+datasource.layer+"'")
        elements = result.xpath("//Statement")
        if len(elements) > 0:
            pattern = re.compile(r'\s+')
            self.setStatement(re.sub(pattern, ' ', str(elements[0])))
            return
        self.setStatement(None)
        
        
########NEW FILE########
__FILENAME__ = Transaction
'''
Created on Oct 16, 2011

@author: michel
'''
import os
import sys
from lxml import etree
from lxml import objectify
from copy import deepcopy
from FeatureServer.WebFeatureService.Transaction.TransactionAction import TransactionAction

class Transaction(object):
    
    tree = None
    namespaces = {'gml' : 'http://www.opengis.net/gml',
                  'fs' : 'http://featureserver.org/fs'}
    
    def getActions(self):
        return self.tree

    def parse(self, xml):
        self.parser = objectify.makeparser(remove_blank_text=True, ns_clean=True)
        
        self.dom = etree.XML(xml, parser=self.parser)
        self.parseDOM()
        
    def parseDOM(self, node = None, transaction = None):
        
        if node == None:
            node = self.dom
            
        if transaction == None:
            transaction = TransactionAction(node)
        
        transaction_class = None
        
        for trans in node.iterchildren():
            if str(trans.xpath('local-name()')) == 'Insert':
                for child in trans.iterchildren():
                    transaction_class = self.getTransactionInstance(str(trans.xpath('local-name()')), deepcopy(child))
                    transaction.appendChild(transaction_class)
            elif str(trans.xpath('local-name()')) == 'Update' or str(trans.xpath('local-name()')) == 'Delete':
                transaction_class = self.getTransactionInstance(str(trans.xpath('local-name()')), deepcopy(trans))
                transaction.appendChild(transaction_class)
            
                    
        self.tree = transaction
            
    def getTransactionInstance(self, transaction, node):
        try:
            sys.path.append(os.path.dirname(os.path.abspath(__file__)))
            transaction_module = __import__(transaction, globals(), locals())
        except ImportError:
            raise Exception("Could not find transaction for %s" % transaction)
        
        transaction_func = getattr(transaction_module, transaction)
        return transaction_func(node)
    
    def render(self, datasource, node = None):
        if node == None:
            node = self.tree
            
        self.create(datasource, node)
    
    def create(self, datasource, node):
        for child in node:
            self.create(datasource, child)
        
        node.createStatement(datasource)
        
    def assemble(self, datasource, node, sql = ''):
        for child in node:
            sql += self.assemble(datasource, child, sql)
        
        return sql
        
    def __str__(self, *args, **kwargs):
        return etree.tostring(self.dom, pretty_print = True)
    
########NEW FILE########
__FILENAME__ = TransactionAction
'''
Created on Oct 16, 2011

@author: michel
'''
import re

class TransactionAction(object):

    def __init__(self, node):
        self.children = []
        self.index = 0
        self.stmt = None
        self.type = ''
        self.node = node
        

    def setStatement(self, stmt):
        self.stmt = stmt
    
    def getStatement(self, datasource = None):
        if self.stmt == None and datasource != None:
            self.createStatement(datasource)
        return self.stmt
    
    def createStatement(self, datasource): pass
    
    def __len__(self):
        return len(self.children)

    def __iter__(self):
        self.index = 0
        return self
    
    def next(self):
        if self.index >= len(self):
            raise StopIteration
        child = self.children[self.index]
        self.index += 1
        return child
        
    def get(self, index):
        return self.children[index]
    
    def hasChildren(self):
        if len(self) > 0:
            return True

    def getChildren(self):
        return self.children
    
    def appendChild(self, node):
        self.children.append(node)
        
    def getName(self):
        return str(self.node.tag)
    
    def removeAdditionalColumns(self, datasource):
        #filter out additional cols (they can not be saved)
        if hasattr(datasource, "additional_cols"):
            for additional_col in datasource.additional_cols.split(';'):            
                name = additional_col
                matches = re.search('(?<=[ ]as[ ])\s*\w+', str(additional_col))
                if matches:
                    name = matches.group(0)
                
                nodes = self.node.xpath("//*[local-name()='"+name+"']")
                if len(nodes) > 0:
                    for node in nodes:
                        self.node.remove(node)


########NEW FILE########
__FILENAME__ = Update
'''
Created on Oct 16, 2011

@author: michel
'''
import os
from FeatureServer.WebFeatureService.Transaction.TransactionAction import TransactionAction
from lxml import etree
import re

class Update(TransactionAction):
    
    def __init__(self, node):
        super(Update, self).__init__(node)
        self.type = 'update'
        
    def createStatement(self, datasource):
        self.removeAdditionalColumns(datasource)
        
        geom = self.node.xpath("//*[local-name() = 'Name' and text()='"+datasource.geom_col+"']/following-sibling::*[1]/*")
        geomData = ''
        if len(geom) > 0:
            geomData = etree.tostring(geom[0], pretty_print=True)
        xslt = etree.parse(os.path.dirname(os.path.abspath(__file__))+"/../../../resources/transaction/transactions.xsl")
        transform = etree.XSLT(xslt)
        
        result = transform(self.node,
                           datasource="'"+datasource.type+"'",
                           transactionType="'"+self.type+"'",
                           geometryAttribute="'"+datasource.geom_col+"'",
                           geometryData="'"+geomData+"'",
                           tableName="'"+datasource.layer+"'",
                           tableId="'"+datasource.fid_col+"'")

        elements = result.xpath("//Statement")
        if len(elements) > 0:
            pattern = re.compile(r'\s+')
            self.setStatement(re.sub(pattern, ' ', str(elements[0])))
            return
        self.setStatement(None)
        
        
########NEW FILE########
__FILENAME__ = WFSRequest
'''
Created on Dec 10, 2011

@author: michel
'''
from lxml import etree
from lxml import objectify
from FeatureServer.WebFeatureService.FilterEncoding.FilterEncoding import FilterEncoding
from FeatureServer.WebFeatureService.Transaction.Transaction import Transaction
from FeatureServer.WebFeatureService.FilterEncoding.Select import Select
from copy import deepcopy

class WFSRequest(object):
    dom     = None
    data    = ""
    parser  = None
    
    transaction = None
    filter = None
    
    def __init__(self):
        self.parser = objectify.makeparser(remove_blank_text=True, ns_clean=True)

    def parse(self, data):
        self.data = data
        #self.data = self.data.replace('wildCard="*"', 'wildCard="\*"')
        #self.data = self.data.replace('wildCard="?"', 'wildCard="\?"')
        #self.data = self.data.replace('singleChar="*"', 'singleChar="\*"')
        #self.data = self.data.replace('singleChar="?"', 'singleChar="\?"')

        try:
            self.dom = etree.XML(self.data, parser=self.parser)
        except Exception as e:
            ''' '''
    
        
    def render(self, datasource):
        '''
        Renders a FilterEncoding to its SQL
        '''
        query = self.dom.xpath("//*[local-name() = 'Query']")
        if len(query) > 0:
            #query - return a dummy select object
            self.filter = FilterEncoding(deepcopy(query[0]).getchildren()[0])
        else:
            self.filter = FilterEncoding(self.data)

        self.filter.parse()
        return self.filter.render(datasource)
    
    def getActions(self):
        '''
        Returns all WFS-T transactions
        '''
        if self.dom is None:
            return None
        
        query = self.dom.xpath("//*[local-name() = 'Query']")
        if len(query) > 0:
            #query - return a dummy select object
            return [Select(etree.tostring(deepcopy(query[0]).getchildren()[0]))]
        else:
            # returning all transaction objects in a array 
            self.transaction = Transaction()
            self.transaction.parse(self.data)
            return self.transaction.getActions()
        
        return None
            
########NEW FILE########
__FILENAME__ = FileHandler
'''
Created on Mar 12, 2012

@author: michel
'''

import shortuuid, time

class FileHandler(object):
    
    __path = ""
    __expiration = float(7776000)

    def __init__(self, path, expiration=float(7776000)):
        self.__path = path
        self.__expiration = expiration
    
    def create(self, layer, filter, identifier=""):
        short = shortuuid.uuid()
        frw = open(self.__path, 'a')
        
        frw.write("%s,%s,%s,%s,%s\n" % (short, identifier, layer, filter, str(time.time())))
        frw.close()
        
        return short
    
    def removeExpired(self):
        now = time.time()
        
        fro = open(self.__path, 'rb')
        seekpoint = 0
        
        # read header line
        line = fro.readline()
        seekpoint = fro.tell()
        
        line = fro.readline()
        while line:
            data = line.split(',')
            
            if (now-float(data[4])) > self.__expiration:
                frw = open(self.__path, 'r+b')
                frw.seek(seekpoint, 0)
                
                chars = fro.readline()
                while chars:
                    frw.writelines(chars)
                    chars = fro.readline()
                
                frw.truncate()
                frw.close()
                fro.seek(seekpoint, 0)
            
            
            seekpoint = fro.tell()
            line = fro.readline()
            
        fro.close()
    
    def remove(self, key):
        fro = open(self.__path, 'rb')
        seekpoint = 0
        
        #read header line
        line = fro.readline()
        seekpoint = fro.tell()
        
        line = fro.readline()
        while line:
            data = line.split(',')
            if data[0] == key:
                frw = open(self.__path, 'r+b')
                frw.seek(seekpoint, 0)
                
                chars = fro.readline()
                while chars:
                    frw.writelines(chars)
                    chars = fro.readline()
                
                frw.truncate()
                frw.close()
            
            seekpoint = fro.tell()
            line = fro.readline()
            
        fro.close()
    
    def updateLastAccess(self, key):
        data = self.getByKey(key)
        if len(data) > 0:
            self.remove(key)
        
            frw = open(self.__path, 'a')
            frw.write("%s,%s,%s,%s,%s\n" % (data[0], data[1], data[2], data[3], str(time.time())))
            frw.close()
    
    def getByKey(self, key):
        fro = open(self.__path, 'r')
        line = fro.readline()
        while line:
            data = line.split(',')
            if data[0] == key:
                fro.close()
                return data
            
            line = fro.readline()
        
        fro.close()
        
        return []
    
    def checkIdentifier(self, identifier):
        workspaces = self.getByIdentifier(identifier)
        if len(workspaces) > 0:
            return False
        return True
    
    def getByIdentifier(self, identifier):
        workspaces = []
        
        fro = open(self.__path, 'r')
        line = fro.readline()
        while line:
            data = line.split(',')
            if data[1] == identifier:
                workspaces.append(data)
            
            line = fro.readline()
        
        fro.close()
        
        return workspaces
        
########NEW FILE########
__FILENAME__ = featureserver_http_server
#!/usr/bin/python

"""A simple, standalone web server that serves FeatureServer requests."""

__author__  = "MetaCarta"
__version__ = "FeatureServer $Id: featureserver_http_server.py 564 2008-05-24 14:32:18Z crschmidt $"
__license__ = "Clear BSD"
__copyright__ = "2006-2008 MetaCarta"

import mimetypes, os
from optparse import OptionParser
from FeatureServer.Server import wsgi_app

local_path_location = None

def local_app(environ, start_response):
    if environ['PATH_INFO'].startswith("/static/"):
        global local_path_location
        path = environ['PATH_INFO'].replace("/static/","")
        path.lstrip("/") 
        mime =  mimetypes.guess_type(path)
        try:
            f = open(os.path.join(local_path_location, path))
            start_response("200 OK", [("Content-Type",mime[0])])
            return [f.read()]
        except Exception, E:
            start_response("404 Not Found", [("Content-Type","text/plain")])
            return ["Not found: %s" % E]
            
    return wsgi_app(environ, start_response)

def run(port=8080, thread=False, local_path=""):
    from wsgiref import simple_server
    if thread:
        from SocketServer import ThreadingMixIn
        class myServer(ThreadingMixIn, simple_server.WSGIServer):
            pass 
    else:
        class myServer(simple_server.WSGIServer):
            pass

    httpd = myServer(('',port), simple_server.WSGIRequestHandler,)
    if local_path:
        global local_path_location
        local_path_location = local_path
        httpd.set_app(local_app)
    else:
        httpd.set_app(wsgi_app)
    
    try:
        print "Listening on port %s" % port
        httpd.serve_forever()
    except KeyboardInterrupt:
        print "Shutting down."

if __name__ == '__main__':
    parser = OptionParser(version=__version__, description=__doc__)
    parser.add_option("-p", "--port", 
        help="port to run webserver on. Default is 8080", 
        dest="port", 
        action='store', 
        type="int", 
        default=8080)
    parser.add_option("-t", help="enable threading in HTTP Server.", dest="thread", action="store_true", default=False)   
    parser.add_option("-l", help="serve files from local disk", dest="local_path")

    (options, args) = parser.parse_args()
    run(options.port, options.thread, options.local_path)



########NEW FILE########
__FILENAME__ = featureserver_install_config
#!/usr/bin/python 

"""Script to install a FeatureServer config from an egg installation."""  

import sys
from optparse import OptionParser

def install(dest):
    try:
        f = open(dest, "w")
    except IOError, E:
        print "Unable to open destination file %s. Perhaps you need permission to write there?\n(Error was: %s)" % (dest, E)
        sys.exit(1)
    
    try:    
        import pkg_resources
        filename = pkg_resources.resource_filename("FeatureServer", "featureserver.cfg")
        cfg = open(filename, "r")
    except Exception, E:
        print "Unable to open source file.\n(Error was: %s)" % (E)
        sys.exit(1)
        
    f.write(cfg.read())
    f.close()
    cfg.close()
    print "Successfully copied file %s to %s." % (filename, dest)
    
if __name__ == "__main__":
    parser = OptionParser(usage="""%prog [options] 

This script is a helper script designed to install the default FeatureServer
configuration when FeatureServer is installed from an egg.""")
    
    parser.add_option('-d', '--dest', dest="dest", help="install to FILE. Default is /etc/featureserver.cfg", default="/etc/featureserver.cfg", metavar="FILE") 
    
    (options, args) = parser.parse_args()
    install(options.dest)

########NEW FILE########
__FILENAME__ = test_cgi
import sys
import operator
import os
import urllib
import simplejson
import random
sys.path.insert(0, os.path.dirname(os.path.dirname(__file__)))
try:
    import cStringIO as StringIO
except:
    import StringIO

from FeatureServer.Server import Server
from FeatureServer.DataSource.SQLite import SQLite


url = len(sys.argv) > 1 and sys.argv[1] or "http://localhost:8080/scribble"




def test_POST():

    data = simplejson.loads('{"crs": {"type": "none", "properties": {"info": "No CRS information has been provided with this data."}}, "type": "FeatureCollection", "features": [{"geometry": {"type": "Point", "coordinates": [-121.232, 42.122999999999998]}, "type": "Feature", "id": 1, "properties": {"strokeColor": "red", "title": "Feature 3", "author": "Your Name Here"}}]}')

    random_x = random.random() * 100
    random_y = random.random() * 10
    data['features'][0]['geometry']['coordinates'] = [random_x, random_x]

    urllib.urlopen(url, simplejson.dumps(data)).read()
    all_data = urllib.urlopen(url).read()
    all_features = simplejson.loads(all_data)
    f = sorted(all_features['features'], key=operator.itemgetter('id'))[-1]
    assert f['geometry']['coordinates'][0] == random_x


def setup():
    pass

def teardown():
    pass



if __name__ == "__main__":
    setup()

    test_POST() 


    teardown()

########NEW FILE########
__FILENAME__ = ComparisionOperatorTest
'''
Created on Apr 12, 2011

@author: michel
'''
import unittest
import FeatureServer.WebFeatureService.FilterEncoding.FilterEncoding as fe
from FeatureServer.Server import Server
from FeatureServer.DataSource.PostGIS import PostGIS

class ComparisonOperatorTestCase(unittest.TestCase):
    datasource = None
    server = None
    params = {'type': 'PostGIS',
              'title': 'All',
              'abstract': 'All',
              'dsn' : 'host=localhost dbname=osm_pg_ch user=gisuser password=gisuser',
              'layer' : 'planet_osm_point',
              'fid': 'osm_id',
              'geometry': 'way',
              'srid' : '4326',
              'attribute_cols' : 'name,amenity,operator,bridge,highway,power,place,route',
              'bbox' : '5.95459 45.75986 10.52490 47.83528'}
    
    def setUp(self):
        self.datasource = PostGIS('all', **self.params)
        self.server = Server({'all': self.datasource})

    def tearDown(self):
        self.datasource = None
        self.server = None
    
    def testComparisonOperators(self):
        filters = {
            "<Filter><PropertyIsEqualTo><ValueReference>highway</ValueReference><Literal>bus_stop</Literal></PropertyIsEqualTo></Filter>" : "\"highway\" = 'bus_stop'",
            "<Filter><PropertyIsNotEqualTo><ValueReference>operator</ValueReference><Literal>UBS</Literal></PropertyIsNotEqualTo></Filter>" : "\"operator\" != 'UBS'",
            "<Filter><PropertyIsLessThan><ValueReference>osm_id</ValueReference><Literal>500000</Literal></PropertyIsLessThan></Filter>" : "\"osm_id\" < '500000'",
            "<Filter><PropertyIsGreaterThan><ValueReference>osm_id</ValueReference><Literal>500000</Literal></PropertyIsGreaterThan></Filter>" : "\"osm_id\" > '500000'",
            "<Filter><PropertyIsLessThanOrEqualTo><ValueReference>osm_id</ValueReference><Literal>500000</Literal></PropertyIsLessThanOrEqualTo></Filter>" : "\"osm_id\" <= '500000'",
            "<Filter><PropertyIsGreaterThanOrEqualTo><ValueReference>osm_id</ValueReference><Literal>500000</Literal></PropertyIsGreaterThanOrEqualTo></Filter>" : "\"osm_id\" >= '500000'",
            "<Filter><PropertyIsBetween><ValueReference>osm_id</ValueReference><LowerBoundary><Literal>1</Literal></LowerBoundary><UpperBoundary><Literal>500000</Literal></UpperBoundary></PropertyIsBetween></Filter>" : "\"osm_id\" BETWEEN '1' AND '500000'",
            '<Filter><PropertyIsLike wildCard="*" singleChar="?" escapeChar="!"><ValueReference>highway</ValueReference><Literal>b?s_sto*</Literal></PropertyIsLike></Filter>' : "\"highway\" LIKE 'b_s_sto%%'"
        }

        for fil, stmt in filters.iteritems():
            filterEncoding = fe.FilterEncoding(fil)
            filterEncoding.parse()
            self.assertEqual(stmt, filterEncoding.render(self.datasource))
    
    def testAndOrCombination(self):
        filters = {
            "<Filter>" +
                "<Or>" +
                    "<And>" +
                        "<PropertyIsEqualTo><ValueReference>operator</ValueReference><Literal>VBZ</Literal></PropertyIsEqualTo>" +
                        "<PropertyIsEqualTo><ValueReference>highway</ValueReference><Literal>bus_stop</Literal></PropertyIsEqualTo>" +
                    "</And>" +
                    "<And>" +
                        "<PropertyIsEqualTo><ValueReference>operator</ValueReference><Literal>BVB</Literal></PropertyIsEqualTo>" +
                        "<PropertyIsEqualTo><ValueReference>highway</ValueReference><Literal>bus_stop</Literal></PropertyIsEqualTo>" +
                    "</And>" +
                "</Or>" + 
            "</Filter>" :
            "((\"operator\" = 'VBZ' AND \"highway\" = 'bus_stop') OR (\"operator\" = 'BVB' AND \"highway\" = 'bus_stop'))",
            "<Filter>" +
               "<And>" +
                  "<PropertyIsEqualTo>" +
                     "<PropertyName>shop</PropertyName>" +
                     "<Literal>supermarket</Literal>" +
                  "</PropertyIsEqualTo>" +
                  "<PropertyIsLike wildCard=\"*\" singleChar=\".\" escapeChar=\"!\">" +
                     "<PropertyName>name</PropertyName>" +
                     "<Literal>.enner*</Literal>" +
                  "</PropertyIsLike>" +
               "</And>" +
            "</Filter>" :
            "(\"shop\" = 'supermarket' AND \"name\" LIKE '_enner%%')"
        }

        for fil, stmt in filters.iteritems():
            filterEncoding = fe.FilterEncoding(fil)
            filterEncoding.parse()
            self.assertEqual(stmt, filterEncoding.render(self.datasource))
       

class ComparisonOperatorTestSuite(unittest.TestSuite):
    def __init__(self):
        unittest.TestSuite.__init__(self,map(ComparisonOperatorTestCase,
                                                     ("testComparisonOperators",
                                                      "testAndOrCombination")))

def suite(): 
    suite = unittest.TestSuite()
    suite.addTest(ComparisonOperatorTestCase('testComparisonOperators'))
    suite.addTest(ComparisonOperatorTestCase('testAndOrCombination'))

if __name__ == "__main__":
    #import sys;sys.argv = ['', 'Test.testName']
    unittest.main()
########NEW FILE########
__FILENAME__ = LogicalOperatorTest
'''
Created on Apr 12, 2011

@author: michel
'''
import unittest
from FeatureServer.FilterEncoding import FilterEncoding as fe
from FeatureServer.Server import Server
from FeatureServer.DataSource.PostGIS import PostGIS

class LogicalOperatorTestCase(unittest.TestCase):
    datasource = None
    server = None
    params = {'type': 'PostGIS',
              'title': 'All',
              'abstract': 'All',
              'dsn' : 'host=localhost dbname=osm_pg_ch user=gisuser password=gisuser',
              'layer' : 'planet_osm_point',
              'fid': 'osm_id',
              'geometry': 'way',
              'srid' : '4326',
              'attribute_cols' : 'name,amenity,operator,bridge,highway,power,place,route',
              'bbox' : '5.95459 45.75986 10.52490 47.83528'}

    def setUp(self):
        self.datasource = PostGIS('all', **self.params)
        self.server = Server({'all': self.datasource})
    
    def tearDown(self):
        self.datasource = None
        self.server = None
    
    def testAndOperator(self):
        filters = {
            "<Filter>" +
                "<And>" + 
                    "<PropertyIsEqualTo>" +
                        "<ValueReference>highway</ValueReference>" +
                        "<Literal>bus_stop</Literal>" +
                    "</PropertyIsEqualTo>" +
                    "<PropertyIsEqualTo>" +
                        "<ValueReference>operator</ValueReference>" +
                        "<Literal>VBZ</Literal>" +
                    "</PropertyIsEqualTo>" +
                "</And>" +
            "</Filter>" :
            "(highway = 'bus_stop' AND operator = 'VBZ')"
        }

        for fil, stmt in filters.iteritems():
            filterEncoding = fe.FilterEncoding(fil)
            filterEncoding.parse()
            self.assertEqual(stmt, filterEncoding.render(self.datasource))

    def testOrOperator(self):
        filters = { 
            "<Filter>" +
                "<And>" + 
                    "<Or>" +
                        "<PropertyIsEqualTo>" +
                            "<ValueReference>FIELD1</ValueReference>" +
                            "<Literal>10</Literal>" +
                        "</PropertyIsEqualTo>" +
                        "<PropertyIsEqualTo>" +
                            "<ValueReference>FIELD1</ValueReference>" +
                            "<Literal>20</Literal>" +
                        "</PropertyIsEqualTo>" +
                    "</Or>" +
                    "<PropertyIsEqualTo>" +
                        "<ValueReference>STATUS</ValueReference>" +
                        "<Literal>VALID</Literal>" +
                    "</PropertyIsEqualTo>" +
                "</And>" +
            "</Filter>" :
            "((FIELD1 = '10' OR FIELD1 = '20') AND STATUS = 'VALID')"
        }

        for fil, stmt in filters.iteritems():
            filterEncoding = fe.FilterEncoding(fil)
            filterEncoding.parse()
            self.assertEqual(stmt, filterEncoding.render(self.datasource))

    def testNotOperator(self):
        filters = { 
            "<Filter>" +
                "<And>" + 
                    "<PropertyIsEqualTo>" +
                        "<ValueReference>highway</ValueReference>" +
                        "<Literal>bus_stop</Literal>" +
                    "</PropertyIsEqualTo>" +
                    "<Not>" +
                        "<PropertyIsEqualTo>" +
                            "<ValueReference>operator</ValueReference>" +
                            "<Literal>VBZ</Literal>" +
                        "</PropertyIsEqualTo>" +
                    "</Not>" +
                "</And>" +
            "</Filter>" :
            "(highway = 'bus_stop' AND NOT operator = 'VBZ')",
            "<Filter>" +
                "<And>" + 
                    "<PropertyIsEqualTo>" +
                        "<ValueReference>highway</ValueReference>" +
                        "<Literal>bus_stop</Literal>" +
                    "</PropertyIsEqualTo>" +
                    "<Not>" +
                        "<PropertyIsEqualTo>" +
                            "<ValueReference>operator</ValueReference>" +
                            "<Literal>VBZ</Literal>" +
                        "</PropertyIsEqualTo>" +
                    "</Not>" +
                    "<Not>" +
                        "<PropertyIsEqualTo>" +
                            "<ValueReference>operator</ValueReference>" +
                            "<Literal>BVB</Literal>" +
                        "</PropertyIsEqualTo>" +
                    "</Not>" +
                "</And>" +
            "</Filter>" :
            "(highway = 'bus_stop' AND NOT operator = 'VBZ' AND NOT operator = 'BVB')"
        }

        for fil, stmt in filters.iteritems():
            filterEncoding = fe.FilterEncoding(fil)
            filterEncoding.parse()
            self.assertEqual(stmt, filterEncoding.render(self.datasource))

class LogicalOperatorTestSuite(unittest.TestSuite):
    def __init__(self):
        unittest.TestSuite.__init__(self,map(LogicalOperatorTestCase,
                                                     ("testAndOperator",
                                                      "testOrOperator",
                                                      "testNotOperator")))

def suite(): 
    suite = unittest.TestSuite()
    suite.addTest(LogicalOperatorTestCase('testAndOperator'))
    suite.addTest(LogicalOperatorTestCase('testOrOperator'))
    return suite

if __name__ == "__main__":
    #import sys;sys.argv = ['', 'Test.testName']
    unittest.main(defaultTest='suite')
########NEW FILE########
__FILENAME__ = ObjectIdentifier
'''
Created on Apr 12, 2011

@author: michel
'''
import unittest
from FeatureServer.FilterEncoding import FilterEncoding as filter
from FeatureServer.Server import Server
from FeatureServer.DataSource.PostGIS import PostGIS

class ObjectIdentifier(unittest.TestCase):
    filters = {'<Filter><ResourceId rid="172251"/></Filter>' : "osm_id = '172251'"}
    
    datasource = None
    server = None
    params = {'type': 'PostGIS',
              'title': 'All',
              'abstract': 'All',
              'dsn' : 'host=localhost dbname=osm_pg_ch user=gisuser password=gisuser',
              'layer' : 'planet_osm_point',
              'fid': 'osm_id',
              'geometry': 'way',
              'srid' : '4326',
              'attribute_cols' : 'name,amenity,operator,bridge,highway,power,place,route',
              'bbox' : '5.95459 45.75986 10.52490 47.83528'}
    
    def testObjectIdentifiers(self):
        self.datasource = PostGIS('all', **self.params)
        self.server = Server({'all': self.datasource})
        
        for fil, stmt in self.filters.iteritems():
            filterEncoding = filter.FilterEncoding(fil)
            filterEncoding.parse()
            self.assertEqual(stmt, filterEncoding.render(self.datasource))

if __name__ == "__main__":
    #import sys;sys.argv = ['', 'Test.testName']
    unittest.main()
########NEW FILE########
__FILENAME__ = regression
'''
Created on May 10, 2011

@author: michel
'''

import unittest

class RegressionTest(unittest.TestCase):
    
    def suite(self):
        modules_to_test = ('SpatialOperatorTest')
        alltests = unittest.TestSuite()
        for module in map(__import__, modules_to_test):
            alltests.addTest(unittest.findTestCases(module))
        return alltests
def suite():
    import tests.FilterEncoding.SpatialOperatorTest as module
    suite = unittest.TestLoader().loadTestsFromModule(module)
    return suite

if __name__ == "__main__":
    #unittest.main(defaultTest='suite')
#    regression = RegressionTest()
#    unittest.main(defaultTest='regression.suite')

    import tests.FilterEncoding.LogicalOperatorTest as lo
    s1 = lo.LogicalOperatorTestSuite()
    import tests.FilterEncoding.SpatialOperatorTest as so
    s2 = so.SpatialOperatorTestSuite()
    import tests.FilterEncoding.ComparisionOperatorTest as co
    s3 = co.ComparisonOperatorTestSuite()

    alltests = unittest.TestSuite([s1, s2, s3])
    unittest.TextTestRunner().run(alltests)
    

########NEW FILE########
__FILENAME__ = SpatialOperatorTest
'''
Created on Apr 12, 2011

@author: michel
'''
import unittest
import FeatureServer.FilterEncoding.FilterEncoding as fe
from FeatureServer.Server import Server
from FeatureServer.DataSource.PostGIS import PostGIS

class SpatialOperatorTestCase(unittest.TestCase):
    datasource = None
    server = None
    params = {'type': 'PostGIS',
              'title': 'All',
              'abstract': 'All',
              'dsn' : 'host=localhost dbname=osm_pg_ch user=gisuser password=gisuser',
              'layer' : 'planet_osm_point',
              'fid': 'osm_id',
              'geometry': 'way',
              'srid' : '4326',
              'attribute_cols' : 'name,amenity,operator,bridge,highway,power,place,route',
              'bbox' : '5.95459 45.75986 10.52490 47.83528'}
    
    def setUp(self):
        self.datasource = PostGIS('all', **self.params)
        self.server = Server({'all': self.datasource})
    def tearDown(self):
        self.datasource = None
        self.server = None
    
    def testEquals(self):
        filters = {
            "<Filter>" +
                "<Equals>" + 
                    "<ValueReference>way</ValueReference>" +
                    "<Literal>" +
                        "<gml:Point srsName=\"EPSG:4326\">" +
                            "<gml:coordinates>5.9656087,46.144381600000003</gml:coordinates>" +
                        "</gml:Point>" +
                    "</Literal>" +
                "</Equals>" +
            "</Filter>" :
            "ST_Equals(way, ST_GeomFromGML('<gml:Point xmlns:gml=\"http://www.opengis.net/gml\" xmlns:regexp=\"http://exslt.org/regular-expressions\" srsName=\"EPSG:4326\"><gml:coordinates>5.9656087,46.144381600000003</gml:coordinates></gml:Point>'))"
        }
    
        for fil, stmt in filters.iteritems():
            filterEncoding = fe.FilterEncoding(fil)
            filterEncoding.parse()
            self.assertEqual(stmt, filterEncoding.render(self.datasource))
            
    def testBBOX(self):
        filters = {
            "<Filter>" +
                "<BBOX>" + 
                    "<ValueReference>way</ValueReference>" +
                    "<gml:Envelope xmlns:gml=\"http://www.opengis.net/gml\" srsName=\"asdf:EPSG:4326\">" +
                        "<gml:lowerCorner>5.95459 45.75986</gml:lowerCorner>" +
                        "<gml:upperCorner>10.52490 47.83528</gml:upperCorner>" + 
                    "</gml:Envelope>" +
                "</BBOX>" +
            "</Filter>" :
            "NOT ST_Disjoint(way, ST_MakeEnvelope(5.95459,45.75986,10.52490,47.83528, 4326))"
        }
        for fil, stmt in filters.iteritems():
            filterEncoding = fe.FilterEncoding(fil)
            filterEncoding.parse()
            self.assertEqual(stmt, filterEncoding.render(self.datasource))

class SpatialOperatorTestSuite(unittest.TestSuite):
    def __init__(self):
        unittest.TestSuite.__init__(self,map(SpatialOperatorTestCase,
                                                     ("testEquals",
                                                      "testBBOX")))

def suite(): 
    suite = unittest.TestSuite()
    suite.addTest(SpatialOperatorTestCase('testEquals'))
    suite.addTest(SpatialOperatorTestCase('testBBOX'))
    return suite

if __name__ == "__main__":
    #import sys;sys.argv = ['', 'Test.testName']
    unittest.main(defaultTest='suite')
    
    
    
########NEW FILE########
__FILENAME__ = geoalchemy_model
from sqlalchemy import *
from sqlalchemy.orm import *
from sqlalchemy.ext.declarative import declarative_base
from geoalchemy import GeometryColumn, LineString, GeometryDDL

engine = create_engine('postgres://michel@localhost/featureserver', echo=False)
session = sessionmaker(bind=engine)()
metadata = MetaData(engine)
Base = declarative_base(metadata=metadata)

class Road(Base):
    __tablename__ = 'fs_alchemy_road'
    id = Column(Integer, primary_key=True)
    name = Column(Unicode, nullable=False)
    width = Column(Integer)
    geom = GeometryColumn(LineString(2))

GeometryDDL(Road.__table__)


########NEW FILE########
__FILENAME__ = ShapeFileTest
'''
Created on May 18, 2011

@author: michel
'''
import unittest
from FeatureServer.Service.SHP import SHP
from FeatureServer.Server import Server
from FeatureServer.DataSource.PostGIS import PostGIS

class ShapeFileTestCase(unittest.TestCase):
    datasource = None
    server = None
    config = {'type': 'PostGIS',
              'title': 'All',
              'abstract': 'All',
              'dsn' : 'host=localhost dbname=test_gis_ch user=gisuser password=gisuser',
              'layer' : 'planet_osm_polygon',
              'fid': 'osm_id',
              'geometry': 'way',
              'srid' : '4326',
              'attribute_cols' : 'boundary,name,landuse',
              'bbox' : '5.95459 45.75986 10.52490 47.83528'}
    service = None

    def setUp(self):
        self.datasource = PostGIS('all', **self.config)
        self.server = Server({'all': self.datasource})
        self.service = SHP(self.server)
        
    def tearDown(self):
        self.service = None
        self.datasource = None
        self.server = None
    
    def testShapeFile(self):
        params = {'filter': '<Filter><Or>' +
                        '<PropertyIsEqualTo><ValueReference>landuse</ValueReference><Literal>vineyard</Literal></PropertyIsEqualTo>' +
                        '<PropertyIsEqualTo><ValueReference>boundary</ValueReference><Literal>administrative</Literal></PropertyIsEqualTo>' +
                    '</Or></Filter>',
                'typename': 'all',
                'version': '1.0.0',
                'request': 'GetFeature', 
                'service': 'WFS'
        }
        path_info = '/'
        host = 'http://localhost:8080'
        post_data = None
        request_method = 'GET'
        
        response = []
        
        self.service.parse(params, path_info, host, post_data, request_method)
        self.datasource.begin()
        for action in self.service.actions:
            method = getattr(self.datasource, action.method)
            result = method(action)
            response += result 
        self.datasource.commit()

        mime, data, headers = self.service.encode(response)
        #data = data.encode("utf-8") 
        

if __name__ == "__main__":
    #import sys;sys.argv = ['', 'Test.testName']
    unittest.main()        
########NEW FILE########
__FILENAME__ = tests
# stolen from shapely
# http://trac.gispython.org/projects/PCL/browser/Shapely/trunk/tests/test_doctests.py
# Copyright (c) 2007, Sean C. Gillies

import doctest
import unittest
import glob
import os

optionflags = (
               doctest.NORMALIZE_WHITESPACE |
               doctest.ELLIPSIS)

def list_doctests():
    return [filename
            for filename
            in glob.glob(os.path.join(os.path.dirname(__file__), '*.txt'))]

def open_file(filename, mode='r'):
    """Helper function to open files from within the tests package."""
    return open(os.path.join(os.path.dirname(__file__), filename), mode)

def setUp(test):
    test.globs.update(dict(
            open_file = open_file,
            ))

def run_doc_tests():
    return unittest.TestSuite(
        [doctest.DocFileSuite(os.path.basename(filename),
                              optionflags=optionflags,
                              setUp=setUp)
         for filename
         in list_doctests()])

if __name__ == "__main__":
    runner = unittest.TextTestRunner()
    runner.run(run_doc_tests())

########NEW FILE########
__FILENAME__ = TransactionTest
'''
Created on Oct 16, 2011

@author: michel
'''
import unittest
import FeatureServer.FilterEncoding.FilterEncoding as fe
from FeatureServer.Server import Server
from FeatureServer.DataSource.PostGIS import PostGIS
from FeatureServer.Transaction.Transaction import Transaction
    
class TransactionTest(unittest.TestCase):
    datasource = None
    server = None
    params = {'type': 'PostGIS',
              'title': 'All',
              'abstract': 'All',
              'dsn' : 'host=localhost dbname=osm_test user=postgres password=4mrafk3',
              'layer' : 'osm_point',
              'fid': 'osm_id',
              'geometry': 'way',
              'version' : 'osm_version',
              'srid' : '4326',
              'srid_out' : '4326',
              'attribute_cols' : 'name,amenity,operator,bridge,highway,power,place,route',
              'bbox' : '5.95459 45.75986 10.52490 47.83528',
              'ele' : 'ele',
              'geometry_type' : 'Point'}

    def setUp(self):
        self.datasource = PostGIS('all', **self.params)
        self.server = Server({'all': self.datasource})

    def tearDown(self):
        self.datasource = None
        self.server = None

    def testInsert(self):
        xml = """<?xml version="1.0"?>
<wfs:Transaction
       version="1.1.0"
       service="WFS"
       xmlns="http://featureserver.org/fs"
       xmlns:gml="http://www.opengis.net/gml"
       xmlns:ogc="http://www.opengis.net/ogc"
       xmlns:wfs="http://www.opengis.net/wfs"
       xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
       xsi:schemaLocation="http://www.opengis.net/wfs http://schemas.opengeospatial.net//wfs/1.0.0/WFS-basic.xsd">
    <wfs:Insert idgen="GenerateNew">
        <osm_point gml:id="1">
            <way>
                <gml:Point srsName="EPSG:4326">
                    <gml:coordinates decimal="." cs="," ts=" ">8.53438799881,47.3187879949</gml:coordinates>
                </gml:Point>
            </way>
            <name>honky1</name>
            <operator>ABC</operator>
            <highway>bus_stop</highway>
        </osm_point>
        
        <osm_point gml:id="2">
            <way>
                <gml:Point srsName="EPSG:4326">
                    <gml:coordinates decimal="." cs="," ts=" ">8.52892699881,47.3221139949</gml:coordinates>
                </gml:Point>
            </way>
            <highway>bus_stop</highway>
        </osm_point>
        
    </wfs:Insert>
</wfs:Transaction>    
            """
        solution = [" INSERT INTO osm_point ( \"way\" , \"name\" , \"operator\" , \"highway\" ) VALUES ( ST_GeomFromGML('<gml:Point xmlns:gml=\"http://www.opengis.net/gml\" xmlns=\"http://featureserver.org/fs\" xmlns:ogc=\"http://www.opengis.net/ogc\" xmlns:wfs=\"http://www.opengis.net/wfs\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" srsName=\"EPSG:4326\"> <gml:coordinates decimal=\".\" cs=\",\" ts=\" \">8.53438799881,47.3187879949</gml:coordinates> </gml:Point> ') , 'honky1' , 'ABC' , 'bus_stop' ); ",
                    " INSERT INTO osm_point ( \"way\" , \"highway\" ) VALUES ( ST_GeomFromGML('<gml:Point xmlns:gml=\"http://www.opengis.net/gml\" xmlns=\"http://featureserver.org/fs\" xmlns:ogc=\"http://www.opengis.net/ogc\" xmlns:wfs=\"http://www.opengis.net/wfs\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" srsName=\"EPSG:4326\"> <gml:coordinates decimal=\".\" cs=\",\" ts=\" \">8.53438799881,47.3187879949</gml:coordinates> </gml:Point> ') , 'bus_stop' ); "]
        result = []
        
        transaction = Transaction()
        transaction.parse(xml)
        transactions = transaction.getActions()
                                                
        for transaction in transactions:
            result.append(transaction.getStatement(self.datasource))
        
        self.assertItemsEqual(solution, result)
        
    def testUpdate(self):
        xml = """<?xml version="1.0"?>
<wfs:Transaction
       version="1.1.0"
       service="WFS"
       xmlns="http://featureserver.org/fs"
       xmlns:gml="http://www.opengis.net/gml"
       xmlns:ogc="http://www.opengis.net/ogc"
       xmlns:wfs="http://www.opengis.net/wfs"
       xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
       xsi:schemaLocation="http://www.opengis.net/wfs http://schemas.opengeospatial.net//wfs/1.0.0/WFS-basic.xsd">
    <wfs:Update typeName="test_point" xmlns:feature="http://opengeo.org">
        <wfs:Property>
            <wfs:Name>way</wfs:Name>
            <wfs:Value>
                <gml:Point srsName="EPSG:4326">
                    <gml:coordinates decimal="." cs="," ts=" ">8.53438799881,47.3187879949</gml:coordinates>
                </gml:Point>
            </wfs:Value>
        </wfs:Property>
        <wfs:Property>
            <wfs:Name>Description</wfs:Name>
            <wfs:Value>abc</wfs:Value>
        </wfs:Property>
        <ogc:Filter xmlns:ogc="http://www.opengis.net/ogc">
            <ogc:FeatureId fid="1"/>
        </ogc:Filter>
    </wfs:Update>
    <wfs:Update typeName="test_point" xmlns:feature="http://opengeo.org">
        <wfs:Property>
            <wfs:Name>way</wfs:Name>
            <wfs:Value>
                <gml:Point srsName="EPSG:4326">
                    <gml:coordinates decimal="." cs="," ts=" ">8.53438799881,47.3187879949</gml:coordinates>
                </gml:Point>
            </wfs:Value>
        </wfs:Property>
        <ogc:Filter xmlns:ogc="http://www.opengis.net/ogc">
            <ogc:FeatureId fid="2"/>
        </ogc:Filter>
    </wfs:Update>
</wfs:Transaction> """         
        solution = [" UPDATE osm_point SET \"way\" = ST_GeomFromGML('<gml:Point xmlns:gml=\"http://www.opengis.net/gml\" xmlns:feature=\"http://opengeo.org\" xmlns=\"http://featureserver.org/fs\" xmlns:ogc=\"http://www.opengis.net/ogc\" xmlns:wfs=\"http://www.opengis.net/wfs\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" srsName=\"EPSG:4326\"> <gml:coordinates decimal=\".\" cs=\",\" ts=\" \">8.53438799881,47.3187879949</gml:coordinates> </gml:Point> ') , \"Description\" = 'abc' WHERE \"osm_id\" = '1'; ",
                    " UPDATE osm_point SET \"way\" = ST_GeomFromGML('<gml:Point xmlns:gml=\"http://www.opengis.net/gml\" xmlns:feature=\"http://opengeo.org\" xmlns=\"http://featureserver.org/fs\" xmlns:ogc=\"http://www.opengis.net/ogc\" xmlns:wfs=\"http://www.opengis.net/wfs\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" srsName=\"EPSG:4326\"> <gml:coordinates decimal=\".\" cs=\",\" ts=\" \">8.53438799881,47.3187879949</gml:coordinates> </gml:Point> ') WHERE \"osm_id\" = '2'; "]
        result = []

        transaction = Transaction()
        transaction.parse(xml)
        transactions = transaction.getActions()
                                                
        for transaction in transactions:
            result.append(transaction.getStatement(self.datasource))
        
        self.assertItemsEqual(solution, result)
            
    def testDelete(self):
        xml = """<?xml version="1.0"?>
<wfs:Transaction
       version="1.1.0"
       service="WFS"
       xmlns="http://featureserver.org/fs"
       xmlns:gml="http://www.opengis.net/gml"
       xmlns:ogc="http://www.opengis.net/ogc"
       xmlns:wfs="http://www.opengis.net/wfs"
       xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
       xsi:schemaLocation="http://www.opengis.net/wfs http://schemas.opengeospatial.net//wfs/1.0.0/WFS-basic.xsd">
    <wfs:Delete typeName="test_point" xmlns:feature="http://opengeo.org">
        <ogc:Filter xmlns:ogc="http://www.opengis.net/ogc">
            <ogc:FeatureId fid="1"/>
        </ogc:Filter>
    </wfs:Delete>
    <wfs:Delete typeName="test_point" xmlns:feature="http://opengeo.org">
        <ogc:Filter xmlns:ogc="http://www.opengis.net/ogc">
            <ogc:FeatureId fid="2"/>
        </ogc:Filter>
    </wfs:Delete>
</wfs:Transaction> """
        solution = [" DELETE FROM osm_point WHERE \"osm_id\" = '1'; ", " DELETE FROM osm_point WHERE \"osm_id\" = '2'; "]
        result = []

        transaction = Transaction()
        transaction.parse(xml)
        transactions = transaction.getActions()
                                                
        for transaction in transactions:
            result.append(transaction.getStatement(self.datasource))
        
        self.assertItemsEqual(solution, result)


if __name__ == "__main__":
    #import sys;sys.argv = ['', 'Test.testName']
    unittest.main()
########NEW FILE########
__FILENAME__ = test_cgi
import sys
import operator
import os
import urllib
import simplejson
import random
sys.path.insert(0, os.path.dirname(os.path.dirname(__file__)))
try:
    import cStringIO as StringIO
except:
    import StringIO

from FeatureServer.Server import Server
from FeatureServer.DataSource.SQLite import SQLite


url = len(sys.argv) > 1 and sys.argv[1] or "http://localhost:8080/scribble"




def test_POST():

    data = simplejson.loads('{"crs": {"type": "none", "properties": {"info": "No CRS information has been provided with this data."}}, "type": "FeatureCollection", "features": [{"geometry": {"type": "Point", "coordinates": [-121.232, 42.122999999999998]}, "type": "Feature", "id": 1, "properties": {"strokeColor": "red", "title": "Feature 3", "author": "Your Name Here"}}]}')

    random_x = random.random() * 100
    random_y = random.random() * 10
    data['features'][0]['geometry']['coordinates'] = [random_x, random_x]

    urllib.urlopen(url, simplejson.dumps(data)).read()
    all_data = urllib.urlopen(url).read()
    all_features = simplejson.loads(all_data)
    f = sorted(all_features['features'], key=operator.itemgetter('id'))[-1]
    assert f['geometry']['coordinates'][0] == random_x


def setup():
    pass

def teardown():
    pass



if __name__ == "__main__":
    setup()

    test_POST() 


    teardown()

########NEW FILE########
__FILENAME__ = test_wsgi
import twill
import twill.commands as tc
from cStringIO import StringIO
#import wsgi_intercept.mechanize_intercept


host = 'localhost'
port = 8081

full_host = '%s:%i' % (host, port)
def setup():
    def create_app():
        import sys, os
        path = os.path.dirname(__file__)
        sys.path.append(path)
        sys.path.insert(0, os.path.abspath("."))
        # add the path to simplify
        sys.path.append(os.path.join(os.path.abspath("."), 'doc/examples'))
        import Simplify

        from FeatureServer.Server import Server, wsgi, cfgfiles
        # make all the paths absolute as well.
        cfgfiles = list(cfgfiles) + [os.path.join(path, f) for f in cfgfiles if not f.startswith('/')]

        service = Server.load(*cfgfiles)

        def app(environ, start_response):
            return wsgi(service.dispatchRequest, environ, start_response)

        return app


    twill.add_wsgi_intercept(host, port, create_app)
    # argh. cant POST with twill...
    # argh wsgi_intercept is broken...
    #wsgi_intercept.add_wsgi_intercept(host, port, create_app)


def teardown():
    pass


def test_connect():
    tc.go('http://%s/' % full_host)
    # this will unless scribble is in the output
    tc.find('scribble')
    
# wsgi-intercept is broken. cant POST
#def test_post():
#    b = wsgi_intercept.mechanize_intercept.Browser()
#    b.open('http://%s/' % full_host)
#    # response.read()


def test_services():
    tc.go('http://%s/scribble/1.geojson' % full_host)
    tc.find('{')

    tc.go('http://%s/scribble/1.wfs' % full_host)
    tc.find('wfs')

    # this may fail because wsgi requires the full
    # path to the template... fix?
    tc.go('http://%s/scribble/1.html' % full_host)
    tc.find('openlayers')

    tc.go('http://%s/scribble/1.georss' % full_host)
    tc.find('<feed')

    tc.go('http://%s/scribble/1.osm' % full_host)
    tc.find('<osm')
    

# this test wont work with relative paths in the .cfg
def test_processing_simplify():
    """cfg:

    [process_simplify]
    module=Simplify
    class=Simplify
    tolerance_default=.1
    tolerance_locked=no

    [scribble]
    type=SQLite
    file=/var/www/ms_tmp/featureserver.scribble
    gaping_security_hole=yes
    template=template/default-withmap.html
    processes=simplify
    """

    s1 = StringIO()
    twill.set_output(s1)
    tc.go('http://%s/scribble/1.geojson?process_simplify_tolerance=0.001' % full_host)
    tc.show()

    s2 = StringIO()
    twill.set_output(s2)
    tc.go('http://%s/scribble/1.geojson?process_simplify_tolerance=100' % full_host)
    tc.show()
    s1 = s1.getvalue()
    s2 = s2.getvalue()
    #import sys 
    #print >>sys.stderr, s1
    #print >>sys.stderr, ''
    #print >>sys.stderr, s2

    assert 'processed_by' in s2
    
    # it's simplified so it should be shorter ... add a better test...
    assert len(s2) <= len(s1)



########NEW FILE########
__FILENAME__ = Feature
class Feature (object):
    """
    >>> f = Feature(1, {"type":"Point", "coordinates": [1.0,0.0]})
    >>> point = f.__geo_interface__
    >>> point
    {'type': 'Point', 'coordinates': [1.0, 0.0]}

    >>> f.__geo_interface__['coordinates'][0] = 2.0 
    >>> f.__geo_interface__
    {'type': 'Point', 'coordinates': [2.0, 0.0]}
    """
    
    def __init__ (self, id = None, geometry = None, geometry_attr=None, srs=None, props = None):
        self.id             = id
        self.geometry       = geometry 
        self.properties     = props or {}
        self.bbox           = None
        self.geometry_attr  = geometry_attr
        self.srs            = srs
    
    def get_geo(self):
        return self.geometry
    
    def set_geo(self, geom):
        self.geometry = geom
    
    __geo_interface__ = property(get_geo, set_geo)

    def __getitem__(self, key):
        if key == "geometry":
            return self.geometry
        elif key == "properties":
            return self.properties
        elif key == "id":
            return self.id
        elif key == "geometry_attr":
            return self.geometry_attr
        elif key == "srs":
            return self.srs
        raise KeyError(key)    
    
    def __setitem__(self, key, value):
        if key == "geometry":
            self.geometry = value
        elif key == "properties":
            self.properties = value
        elif key == "id":
            self.id = value
        elif key == "geometry_attr":
            self.geometry_attr = value
        elif key == "srs":
            self.srs = value
        else:
            raise KeyError(key)
        return     
    
    def get_bbox (self):
        minx = miny = 2**31
        maxx = maxy = -2**31
        try:
            
            coords = self.geometry["coordinates"]
            
            if self.geometry["type"] == "Point":
                minx = coords[0]
                maxx = coords[0]
                miny = coords[1]
                maxy = coords[1]
            
            elif self.geometry["type"] == "LineString":
                for coord in coords:
                    if coord[0] < minx: minx = coord[0]
                    if coord[0] > maxx: maxx = coord[0]
                    if coord[1] < miny: miny = coord[1]
                    if coord[1] > maxy: maxy = coord[1]
            
            elif self.geometry["type"] == "Polygon":
                for ring in coords:
                    for coord in ring:
                        if coord[0] < minx: minx = coord[0]
                        if coord[0] > maxx: maxx = coord[0]
                        if coord[1] < miny: miny = coord[1]
                        if coord[1] > maxy: maxy = coord[1]
            
            return (minx, miny, maxx, maxy)
        
        except Exception, E:
            raise Exception("Unable to determine bounding box for feature: %s. \nGeometry:\n %s" % (E, self.geometry))

    def to_dict (self):
        return {"id": self.id,
                "geometry": self.geometry,
                "geometry_attr" : self.geometry_attr,
                "srs" : self.srs,
                "properties": self.properties}

########NEW FILE########
__FILENAME__ = CSV
from vectorformats.Feature import Feature
from vectorformats.Formats.Format import Format
from vectorformats.Formats.WKT import to_wkt, from_wkt

import csv
import StringIO


class CSV (Format):
    """Encode simple features to CSV; supports only point geometries."""
    
    include_id = True

    def encode(self, features, props = None, fixed_props = False, **kwargs):
        """
        >>> feat = Feature(1, {"type":"Point", "coordinates":[1,1]}, {"a":"b"})
        >>> c = CSV()
        >>> c.encode([feat]).replace("\\r\\n", " ")
        'id,a,geometry 1,b,"1,1" '
        >>> c.encode([feat], ["geometry","a","b","id"]).replace("\\r\\n", " ")
        'geometry,a,b,id "1,1",b,,1 '
        >>> c.encode([feat], props=["geometry","id"],fixed_props=True).replace("\\r\\n", " ")
        'geometry,id "1,1",1 '
        """
        
        s = StringIO.StringIO()
        w = csv.writer(s)
        
        if props == None:
            props = []
        
        if not "id" in props and self.include_id:
            props.append("id")
        
        if not fixed_props:
            for feature in features:
                for key in feature.properties.keys():
                    if not key in props:
                        props.append(key)
        
        if not "geometry" in props:
            props.append("geometry")
        
        w.writerow(props)

        for feature in features:
            #if feature.geometry['type'] != "Point":
            #    continue
            row = []
            for key in props:
                if key == "id":
                    row.append(feature.id)
                elif key == "geometry":
                    geom = to_wkt(feature.geometry)
                    #geom = ",".join(map(str, feature.geometry['coordinates']))
                    row.append(geom)
                elif feature.properties.has_key(key):
                    val = feature.properties[key]
                    if isinstance(val, unicode):
                        val = val.encode("utf-8")
                    row.append(val)
                else:
                    row.append("")
            w.writerow(row)
        s.seek(0)
        return s


    def encode_exception_report(self, exceptionReport):
        s = StringIO.StringIO()
        w = csv.writer(s)
        
        w.writerow(["exceptionCode", "locator", "layer", "ExceptionText", "ExceptionDump"])
        
        
        for exception in exceptionReport:
            w.writerow([str(exception.code), exception.locator, exception.layer, exception.message, exception.dump])
            
        return s
########NEW FILE########
__FILENAME__ = Django
import pickle
from vectorformats.Feature import Feature
from vectorformats.Formats.Format import Format

class Django(Format):
    """ This class is designed to decode a Django QuerySet object into
        Feature.Vector objects. 
        
        Simply pass a query_set to the decode method, and it will return
        a list of Features.

        Example Usage:
        
        >>> from vectorformats.Formats import Django, GeoJSON
        >>> qs = Model.objects.filter(city="Cambridge")
        >>> djf = Django.Django(geodjango="geometry", properties=['city', 'state'])
        >>> geoj = GeoJSON.GeoJSON()
        >>> string = geoj.encode(djf.decode(qs))
        >>> print string 
    """

    geodjango = False 
    """
    If you have GeoDjango geometry columns, set this to the name of the 
    geometry column. 
    """

    pickled_geometry = False
    """If you are not using GeoDjango, but have instead stored your geometry
       as pickled GeoJSON geometries in a column in GeoDjango, set 
       the pickled_geometry=True option in your class constructor. 
    """
    
    pickled_properties = False 
    """A column in the database representing a pickled set of attributes.
    This will be used in addition to any properties in the 'properties' list,
    with the list as a preference.
    """

    properties = []
    """
    List of properties you want copied from the model to the 
    output object.
    """

    def decode(self, query_set, generator = False):
        results = []
        for res in query_set:
            feature = Feature(res.pk)
            
            if self.pickled_geometry:
                feature.geometry = pickle.loads(res.geometry)
            
            elif self.geodjango:
                geometry = None
                geom = getattr(res, self.geodjango)
                if geom:
                    geometry = {}
                    geometry['type'] = geom.geom_type
                    geometry['coordinates'] = geom.coords
                feature.geometry = geometry

            if self.pickled_properties:
                props = getattr(res, self.pickled_properties) 
                feature.properties = pickle.loads(props.encode("utf-8"))
            
            if self.properties:   
                for p in self.properties:
                    feature.properties[p] = getattr(res, p)
            results.append(feature) 
        return results    

########NEW FILE########
__FILENAME__ = DXF

from vectorformats.Formats.Format import Format
import StringIO
from dxfwrite import DXFEngine as dxf

class DXF(Format):
    
    _drawing = None
    
    def encode(self, features, **kwargs):
        tmpFile = kwargs["tmpFile"]
        
        if len(features) > 0:
            self._drawing = dxf.drawing(tmpFile)
            self._drawing.add_layer("featureserver")

            for feature in features:
                self.encode_feature(feature)
    
            self._drawing.save()

        return self._drawing


    def encode_feature(self, feature):
        if feature["geometry"]["type"] == "Point":
            self._drawing.add(dxf.point(point=(feature["geometry"]["coordinates"][0],feature["geometry"]["coordinates"][1])))
        
        elif feature["geometry"]["type"] == "LineString":
            polyline= dxf.polyline()
            coords = feature["geometry"]["coordinates"]
            for coord in coords:
                polyline.add_vertex((coord[0], coord[1]))
            self._drawing.add(polyline)

        elif feature["geometry"]["type"] == "Polygon":
            polygon = dxf.polyline()
            
            coords = feature["geometry"]["coordinates"]
            for coord in coords:
                for point in coord:
                    polygon.add_vertex((point[0], point[1]))
                polygon.close()
            self._drawing.add(polygon)
		

########NEW FILE########
__FILENAME__ = Format
class Format(object):
    """Base Format class. To set properties on your subclasses, you can
       pass them as kwargs to your format constructor."""
    def __init__(self, *args, **kwargs):
        for key, value in kwargs.items():
            setattr(self, key, value)
            
    def getFormatedAttributName(self, name):
        attrib_name = name
        
        attrib_pos = name.find(' as "')
        if attrib_pos >= 0:
            attrib_name = name[attrib_pos+5:-1]
            
        return attrib_name
    
    def escapeSQL(self, value):
        newValue = value
        newValue = value.replace("'", "''")
        
        return newValue 
    
########NEW FILE########
__FILENAME__ = GeoJSON
from vectorformats.Feature import Feature
from vectorformats.Formats.Format import Format

try:
    from cjson import encode as json_dumps
    from cjson import decode as json_loads
except:
    try:
        from simplejson import dumps as json_dumps
        from simplejson import loads as json_loads
    except Exception, E:
        raise Exception("simplejson is required for using the GeoJSON service. (Import failed: %s)" % E)

class GeoJSON(Format):
    """
    The most complete Format in vectorformats library. This class is designed
    to use the fastest available JSON library to encode/decode to/from
    GeoJSON strings.
    """
    
    crs = None
    def _createFeature(self, feature_dict, id = None):
        """Private. Not designed to be used externally."""
        feature = Feature(id)
        if feature_dict.has_key('geometry'):
            feature.geometry = feature_dict['geometry']
        if feature_dict.has_key('properties'):
            feature.properties = feature_dict['properties']
        return feature 
        
    
    def encode(self, features, to_string=True, **kwargs):
        """
        Encode a list of features to a JSON object or string.

        to_string determines whethr it should convert the result to
        a string or leave it as an object to be encoded later
        """
        results = []
        result_data = None
        for feature in features:
            data = self.encode_feature(feature)
            for key,value in data['properties'].items():
                if value and isinstance(value, str): 
                    data['properties'][key] = unicode(value,"utf-8")
            results.append(data)
        
        result_data = {
                       'type':'FeatureCollection',
                       'features': results,
                       'crs': self.crs
                      }
        
        if to_string:
            result = json_dumps(result_data) 
        else:
            result = result_data
        return result
    
    def encode_feature(self, feature):
        return {'type':"Feature", 
            "id": feature.id, 
            "geometry": feature.geometry, 
            "properties": feature.properties}

    def encode_exception_report(self, exceptionReport):
        results = []
        data = {}
        
        for exception in exceptionReport:
            data = {
                "exceptionCode" : str(exception.code),
                "locator" : exception.locator,
                "layer" : exception.layer,
                "ExceptionText" : exception.message,
                "ExceptionDump" : exception.dump
            }
            results.append({"Exception" : data})
    
        return json_dumps({"ExceptionReport" : results})


    def decode(self, data):    
        feature_data = json_loads(data)
        if feature_data.has_key("features"):
            feature_data = feature_data['features']
        elif feature_data.has_key("members"):
            feature_data = feature_data['members']
        elif feature_data.has_key("type") and feature_data['type'] in ['Point', 'LineString', 'Polygon', 'MultiPolygon', 'MultiPoint', 'MultiLineString']:
            feature_data = [{'geometry':feature_data}] 
        else:
            feature_data = [feature_data]
        
        features = []
        for feature in feature_data:
            features.append(self._createFeature(feature))
        
        return features    

########NEW FILE########
__FILENAME__ = GeoRSS
from vectorformats.Feature import Feature
from vectorformats.Formats.Format import Format

from datetime import datetime
import time
import xml.dom.minidom as m 

class GeoRSS(Format):
    """GeoRSS writer."""

    title = "No title"
    """Feed title"""

    url = ""
    """Base URL. Used for feed and for items, with id appended."""

    feedname = "none"
    """Name of feed."""

    edit_link = False
    debug = False
    
    def encode(self, result, **kwargs):
        """Pass a list of Features."""
        timestamp = datetime.fromtimestamp(time.time())
        timestamp = str(timestamp.strftime('%Y-%m-%dT%H:%M:%SZ'))
        results = ["""<feed xmlns="http://www.w3.org/2005/Atom" xmlns:app="http://www.w3.org/2007/app" 
              xmlns:georss="http://www.georss.org/georss">
              <title>%s</title>
              <id>%s</id>
              <link rel="self" href="%s" />
              <author><name>FeatureServer</name></author>
              <updated>%s</updated>
              """ % (self.title, self.url, self.url, timestamp) ]
        
        for action in result:
            results.append( self.encode_feature(action))
        
        results.append("</feed>")  
        return "\n".join(results)
    
    def encode_feature(self, feature):
        import xml.dom.minidom as m
        doc = m.Document()
        entry = doc.createElement("entry")
        
        id_node = doc.createElement("id")
        id_node.appendChild(doc.createTextNode("%s/%s/%s.atom" % (self.url, self.feedname, feature.id)))
        entry.appendChild(id_node)
        
        link_node = doc.createElement("link")
        link_node.setAttribute("href", "%s/%s/%s.atom" % (self.url, self.feedname, feature.id))
        entry.appendChild(link_node)
        
        if self.edit_link:
            link_node = doc.createElement("link")
            link_node.setAttribute("href", "%s/%s/%s.atom" % (self.url, self.feedname, feature.id))
            link_node.setAttribute("rel", "edit")
            entry.appendChild(link_node)
        
        title_node = doc.createElement("title")
        title = None
        if feature.properties.has_key("title"):
            title = doc.createTextNode(feature.properties['title'])
        else:    
            title = doc.createTextNode("Feature #%s" % feature.id)
        title_node.appendChild(title)
        entry.appendChild(title_node)
        
        if feature.properties.has_key('timestamp'):
            timestamp = feature.properties['timestamp']
            del feature.properties['timestamp']
            edited = doc.createElement("app:edited")
            timestamp = datetime.fromtimestamp(timestamp)
            edited.appendChild(doc.createTextNode(str(timestamp.strftime('%Y-%m-%dT%H:%M:%SZ'))))
            entry.appendChild(edited)
            updated = doc.createElement("updated")
            timestamp = datetime.fromtimestamp(timestamp)
            updated.appendChild(doc.createTextNode(str(timestamp.strftime('%Y-%m-%dT%H:%M:%SZ'))))
            entry.appendChild(updated)
        else:
            updated = doc.createElement("updated")
            timestamp = datetime.fromtimestamp(time.time())
            updated.appendChild(doc.createTextNode(str(timestamp.strftime('%Y-%m-%dT%H:%M:%SZ'))))
            entry.appendChild(updated)
            
        desc_node = doc.createElement("content")
        desc_node.setAttribute("type", "html")
        description = ""
            
        if feature.properties.has_key("description"):
            description = feature.properties['description']
        else:
            desc_fields = []
            for key, value in feature.properties.items():
                if isinstance(value, str):
                    value = unicode(value, "utf-8")
                desc_fields.append( "<b>%s</b>: %s" % (key, value) )
            description = "%s" % ("<br />".join(desc_fields)) 
        desc_node.appendChild(doc.createTextNode(description))
        entry.appendChild(desc_node)
        
        if feature.geometry['type'] == "Point": 
            coords = "%s %s" % (feature.geometry['coordinates'][1], feature.geometry['coordinates'][0])
            geo_node = doc.createElement("georss:point")
            geo_node.appendChild(doc.createTextNode(coords))
        
        elif feature.geometry['type'] == "LineString":
            coords = " ".join(map(lambda x: "%s %s" % (x[1], x[0]), feature.geometry['coordinates']))
            geo_node = doc.createElement("georss:line")
            geo_node.appendChild(doc.createTextNode(coords))
        
        else:
            coords = " ".join(map(lambda x: "%s %s" % (x[1], x[0]), feature.geometry['coordinates'][0]))
            geo_node = doc.createElement("georss:polygon")
            geo_node.appendChild(doc.createTextNode(coords))
            
        entry.appendChild(geo_node)
        
        return entry.toxml()

    
    def encode_exception_report(self, exceptionReport):
        timestamp = datetime.fromtimestamp(time.time())
        timestamp = str(timestamp.strftime('%Y-%m-%dT%H:%M:%SZ'))
        results = ["""<feed xmlns="http://www.w3.org/2005/Atom" xmlns:app="http://www.w3.org/2007/app"
            xmlns:georss="http://www.georss.org/georss">
            <title>%s</title>
            <id>%s</id>
            <link rel="self" href="%s" />
            <author><name>FeatureServer</name></author>
            <updated>%s</updated>
            """ % (self.title, self.url, self.url, timestamp) ]
        
        for exception in exceptionReport:
            results.append( self.encode_exception(exception))
        
        results.append("</feed>")
        return "\n".join(results)
    
    def encode_exception(self, exception):
        import xml.dom.minidom as m
        doc = m.Document()
        entry = doc.createElement("Exception")
        
        entry.setAttribute("exceptionCode", str(exception.code))
        entry.setAttribute("locator", exception.locator)
        entry.setAttribute("layer", exception.layer)
            
        message = doc.createElement("ExceptionText")
        message.appendChild(doc.createTextNode(exception.message))
            
        dump = doc.createElement("ExceptionDump")
        dump.appendChild(doc.createTextNode(exception.dump))
        
        entry.appendChild(message)
        entry.appendChild(dump)
        
        return entry.toxml()


    def decode(self, post_data):
        try:
            doc = m.parseString(post_data)
        except Exception, E:
            raise Exception("Unable to parse GeoRSS. (%s)\nContent was: %s" % (E, post_data))
        entries = doc.getElementsByTagName("entry")
        if not entries:
            entries = doc.getElementsByTagName("item")
        entries.reverse()

        features = []
        
        for entry in entries:
            feature_obj = self.entry_to_feature(entry)
            if feature_obj:
                features.append(feature_obj)
        
        return features 
    
    def coordinates_to_geom(self, coordinates, type):
        """Convert a coordinates string from GML or GeoRSS Simple to 
           a FeatureServer internal geometry."""
        coords = coordinates.strip().replace(",", " ").split()
        if type == "LineString":
            coords = [[float(coords[i+1]), float(coords[i])] for i in xrange(0, len(coords), 2)]
            return {'type':'LineString', 'coordinates':coords}
        elif type == "Polygon": 
            coords = [[float(coords[i+1]), float(coords[i])] for i in xrange(0, len(coords), 2)]
            return {'type':'Polygon', 'coordinates':[coords]}
        elif type == "Point":    
            coords.reverse()
            return {'type':'Point', 'coordinates':map(float,coords)}
        elif type == "Box":  
            coords = [[[float(coords[1]), float(coords[0])], 
                       [float(coords[3]), float(coords[0])], 
                       [float(coords[3]), float(coords[2])], 
                       [float(coords[1]), float(coords[2])], 
                       [float(coords[1]), float(coords[0])]]]  
            return {'type':'Polygon', 'coordinates':coords}
    
    def extract_entry_geometry(self, entry_dom):
        """Given an entry, do our best to extract its geometry. This has been
           designed to maximize the potential of finding geometries, but may
           not work on some features, since everyone seems to do geometries
           differently."""
        points = entry_dom.getElementsByTagName("georss:point")
        lines = entry_dom.getElementsByTagName("georss:line")
        polys = entry_dom.getElementsByTagName("georss:polygon")
        box = entry_dom.getElementsByTagName("georss:box")
        
        type = None 
        element = None
        for geom_type in ['Point', 'LineString', 'Polygon']: 
            geom = entry_dom.getElementsByTagName("gml:%s" % geom_type)
            if len(geom):
                type = geom_type
                element = geom[0]
        if type == "Point":
            points = element.getElementsByTagName("gml:pos")
        elif type == "LineString":
            lines = element.getElementsByTagName("gml:posList")
        elif type == "Polygon":
            polys = element.getElementsByTagName("gml:posList")
        
        if len(points):
            coords = points[0].firstChild.nodeValue
            geometry = self.coordinates_to_geom(coords, "Point")
            
        elif len(lines):
            coords = lines[0].firstChild.nodeValue
            geometry = self.coordinates_to_geom(coords, "LineString")
            
        elif len(polys):
            coords = polys[0].firstChild.nodeValue
            geometry = self.coordinates_to_geom(coords, "Polygon")
            
        elif len(box):
            coords = box[0].firstChild.nodeValue
            geometry = self.coordinates_to_geom(coords, "Box")
        
        else:
            error = "Could not find geometry in Feature. XML was: \n\n%s" % entry_dom.toxml()
            if hasattr(self.debug): 
                raise Exception(error)
            return None   
        return geometry    
    
    def entry_to_feature(self, entry_dom):
        id = 1 
        try:
            id = entry_dom.getElementsByTagName("id")[0].firstChild.nodeValue
        except:
            id = 1
        feature = Feature(str(id))
        
        geometry = self.extract_entry_geometry(entry_dom)
        
        if not geometry: return None
        
        feature.geometry = geometry
        
        for node in entry_dom.childNodes:
            try:
                attr_name = node.tagName.split(":")[-1]
                if attr_name not in ['point', 'line', 'polygon', 'id', 'where']:
                    try:
                        feature.properties[attr_name] = node.firstChild.nodeValue
                    except:
                        pass
            except:
                pass
                
        return feature    

########NEW FILE########
__FILENAME__ = GPX
'''
Created on Jul 30, 2011

@author: michel
'''

from vectorformats.Formats.Format import Format
from xml.sax.saxutils import escape
import types

class GPX(Format):
    
    def encode(self, features, **kwargs):
        results = ["""<?xml version="1.0" encoding="UTF-8"?>
        <gpx version="1.0">"""]
        results.append("<name>%s</name>" % self.layername) 
        
        for feature in features:
            results.append(self.encode_feature(feature))
        
        results.append("</gpx>")
        return "\n".join(results)
        
    def encode_feature(self, feature):
        xml = []
        
        if feature.geometry['type'] == 'Point':
            xml.append("""<wpt lon="%s" lat="%s">""" % (str(feature.geometry["coordinates"][0]), str(feature.geometry["coordinates"][1])))
            if feature.properties.has_key('name'):
                if isinstance(feature.properties["name"], types.NoneType):
                    xml.append("""<name>%s</name>""" % str(feature.id))
                else:
                    xml.append("""<name>%s</name>""" % escape(feature.properties["name"]))
            else:
                xml.append("""<name>%s</name>""" % str(feature.id))
            if feature.properties.has_key('ele'):
                xml.append("""<ele>%s</ele>""" % feature.properties["ele"])
            xml.append("""</wpt>""")

        elif feature.geometry['type'] == 'LineString':
            xml.append("<trk>")
            
            if feature.properties.has_key('name'):
                if isinstance(feature.properties["name"], types.NoneType):
                    xml.append("""<name>%s</name>""" % str(feature.id))
                else:
                    xml.append("""<name>%s</name>""" % escape(feature.properties["name"]))
            else:
                xml.append("""<name>%s</name>""" % str(feature.id))

            xml.append("<trkseg>")

            coords = feature["geometry"]["coordinates"]
            for coord in coords:
                xml.append("""<trkpt lon="%s" lat="%s">""" % (str(coord[0]), str(coord[1])))
                
                if feature.properties.has_key('ele'):
                    xml.append("""<ele>%s</ele>""" % feature.properties["ele"])
                
                xml.append("</trkpt>")

            xml.append("</trkseg></trk>")
            
        elif feature.geometry['type'] == 'Polygon':
            xml.append("<trk>")
            
            if feature.properties.has_key('name'):
                if isinstance(feature.properties["name"], types.NoneType):
                    xml.append("""<name>%s</name>""" % str(feature.id))
                else:
                    xml.append("""<name>%s</name>""" % escape(feature.properties["name"]))
            else:
                xml.append("""<name>%s</name>""" % str(feature.id))
            
            xml.append("<trkseg>")
            
            coords = feature["geometry"]["coordinates"][0]
            for coord in coords:
                xml.append("""<trkpt lon="%s" lat="%s">""" % (str(coord[0]), str(coord[1])))
                
                if feature.properties.has_key('ele'):
                    xml.append("""<ele>%s</ele>""" % feature.properties["ele"])
                
                xml.append("</trkpt>")
            
            xml.append("</trkseg></trk>")

        return "\n".join(xml)


########NEW FILE########
__FILENAME__ = HTML
from vectorformats.Feature import Feature
from vectorformats.Formats.Format import Format

from Cheetah.Template import Template

class HTML (Format):
    """Uses Cheetah to format a list of features."""

    default_file = "template/default.html"
    exception_file = "template/exception_report.html"
    """Default template file to use."""

    def encode(self, result, **kwargs):
        template = self.template(self.default_file)

        output = Template(template, searchList = [{'features':result, 'datasource':self.datasource.name}, self])
        
        return str(output)

    def encode_exception_report(self, exceptionReport):
        template = self.template(self.exception_file)
        
        output = Template(template, searchList = [{'exception_report':exceptionReport}, self])
        
        return str(output)
    
    
    def template(self, template_file):
        return file(template_file).read()

########NEW FILE########
__FILENAME__ = KML
from vectorformats.Feature import Feature
from vectorformats.Formats.Format import Format

import re

class KML(Format):
    """KML Writer"""

    url = "/"
    layername = "layer"
    title_property = None
    def encode(self, features, **kwargs):
        url = "%s/%s/%s-data.kml" % (self.url, self.layername, self.layername)
        results = ["""<?xml version="1.0" encoding="UTF-8"?>
<kml xmlns="http://earth.google.com/kml/2.0" xmlns:fs="http://featureserver.com/ns" xmlns:atom="http://www.w3.org/2005/Atom">
<Document>
<atom:link rel="self" href="%s" type="application/vnd.google-earth.kml+xml" /> 
<Style id="allstyle">
    <LineStyle>
        <width>5</width>
        <color>ff0099ee</color>
    </LineStyle>
    <PolyStyle>
        <color>900099ee</color>
    </PolyStyle>
</Style>
        """ % url]
        for feature in features:
            results.append( self.encode_feature(feature))
        results.append("""</Document>
        </kml>""")
        return "\n".join(results)        
    
    def encode_feature(self, feature):
        "Take a feature, and return an XML string for that feature."
        name = ""
        if self.title_property and feature.properties.has_key(self.title_property):
            name = feature.properties[self.title_property]        
        elif "title" in feature.properties:
            name = feature.properties['title']
        description = ""
        if feature.properties.has_key("description"):
            description = "<![CDATA[%s]]>" % feature.properties['description']
        else:    
            desc_fields = ['Properties:'] 
            for key, value in feature.properties.items():
                if key in ["styleUrl", "title"]: continue 
                if isinstance(value, str):
                        value = unicode(value, "utf-8")
                desc_fields.append( "<b>%s</b>: %s" % (key, value) )
            description = "<![CDATA[%s]]>" % ("<br />".join(desc_fields))   
        
        styleUrl = "#allstyle"
        if feature.properties.has_key("styleUrl"):
            styleUrl = feature.properties['styleUrl']
        
        attr_fields = []
        for key, value in feature.properties.items():
            #key = re.sub(r'\W', '_', key)
            if key in ["title", "description", "styleUrl"]: continue
            attr_value = value
            if isinstance(attr_value, str):
                attr_value = unicode(attr_value, "utf-8")
            if hasattr(attr_value,"replace"): 
                attr_value = attr_value.replace("&", "&amp;").replace("<", "&lt;").replace(">", "&gt;")
            attr_fields.append( "<fs:%s>%s</fs:%s>" % (key, attr_value, key) )
        link = "" 
        if self.url is not None:
            edit_url = "%s/%s/%s.kml" % (self.url, self.layername, feature.id)  
            link = """<atom:link href="%s" type="edit" />""" % edit_url
        
        xml = """
        <Placemark id="%s">
        <name>%s</name>
        <description>%s</description>
        <styleUrl>%s</styleUrl>
        %s
        <Metadata>
          %s
        </Metadata>
        %s
        </Placemark>""" % (feature.id, name, description, styleUrl, link, "\n".join(attr_fields), self.geometry_to_place(feature.geometry)) 
        return xml
    
    def geometry_to_place(self, geometry):
        if geometry['type'] == "Point":
            coords = ",".join(map(str, geometry['coordinates']))
            return "<Point><coordinates>%s</coordinates></Point>" % coords
        elif geometry['type'] == "LineString":
            coords = " ".join(map(lambda x: ",".join(map(str, x)), geometry['coordinates']))
            return "<LineString><coordinates>%s</coordinates></LineString>" % coords
        elif geometry['type'] == "Polygon":
            coords = " ".join(map(lambda x: ",".join(map(str, x)), geometry['coordinates'][0]))
            out = """
              <outerBoundaryIs><LinearRing>
              <coordinates>%s</coordinates>
              </LinearRing></outerBoundaryIs>
            """ % coords 
            inner_rings = []
            for inner_ring in geometry['coordinates'][1:]:
                coords = " ".join(map(lambda x: ",".join(map(str, x)), inner_ring))
                inner_rings.append("""
                  <innerBoundaryIs><LinearRing>
                  <coordinates>%s</coordinates>
                  </LinearRing></innerBoundaryIs>
                """ % coords) 
            return """<Polygon>
              %s %s
              </Polygon>""" % (out, "\n".join(inner_rings))
        else:
            raise Exception("Could not convert geometry of type %s." % geometry['type'])  
    
    def decode(self, data):
            import xml.dom.minidom as m
            actions = []
            
            doc = m.parseString(data)
            entries = doc.getElementsByTagName("Placemark")
            entries.reverse()
            for entry in entries:
                feature_obj = self.entry_to_feature(entry)
                actions.append(feature_obj)
            
            return actions

    def entry_to_feature(self, placemark_dom):
        feature = Feature()
        points = placemark_dom.getElementsByTagName("Point")
        lines = placemark_dom.getElementsByTagName("LineString")
        polys = placemark_dom.getElementsByTagName("Polygon")
        if len(points):
            coords = points[0].getElementsByTagName("coordinates")[0].firstChild.nodeValue.strip().split(",")
            feature.geometry = {'type':'Point', 'coordinates':map(float,coords)}
        elif len(lines):
            coordstring = lines[0].getElementsByTagName("coordinates")[0].firstChild.nodeValue.strip()
            coords = coordstring.split(" ")
            coords = map(lambda x: x.split(","), coords)
            feature.geometry = {'type':'LineString', 'coordinates':coords}
        elif len(polys):
            rings = []
            poly = polys[0]
            outer = poly.getElementsByTagName("outerBoundaryIs")[0]
            outer_coordstring = outer.getElementsByTagName("coordinates")[0].firstChild.nodeValue.strip()
            outer_coords = outer_coordstring.split(" ")
            outer_coords = map(lambda x: map(float,x.split(",")), outer_coords)
            rings.append(outer_coords)
            inners = poly.getElementsByTagName("innerBoundaryIs")
            for inner in inners:
                inner_coords = inner.getElementsByTagName("coordinates")[0].firstChild.nodeValue.strip().split(" ")
                inner_coords = map(lambda x: map(float,x.split(",")), inner_coords)
                rings.append(inner_coords)
            
            feature.geometry = {'type':'Polygon', 'coordinates':rings}
            
        else:
            raise Exception("KML parser only understands points and lines, and polys. You seem to be missing something.") 
        nodeList = placemark_dom.childNodes
        if len(placemark_dom.getElementsByTagName("Metadata")):
            nodeList += placemark_dom.getElementsByTagName("Metadata")[0].childNodes
        for node in nodeList:
            try:
                attr_name = node.tagName.split(":")[-1]
                value = node.firstChild.nodeValue
                if node.tagName not in ['Point', 'LineString', 'Polygon', 'name', 'Metadata'] and not value.startswith("Properties:"):
                    feature.properties[attr_name] = value
            except:
                pass
            
            try:
                feature.properties['title'] = placemark_dom.getElementsByTagName("name")[0].firstChild.nodeValue
            except:
                pass
        
        return feature    

########NEW FILE########
__FILENAME__ = OGR
from vectorformats.Feature import Feature
from vectorformats.Formats.Format import Format
import simplejson
try:
    import osgeo.ogr as ogr
except ImportError:
    import ogr
import re, xml.dom.minidom as m

class OGR(Format):
    """OGR reading and writing."""

    ds = None
    driver = "Memory"
    dsname = "vectorformats_output"
    layername = "features"
    save_on_encode = False
    def encode(self, features, **kwargs):
        self.ds = ogr.GetDriverByName(self.driver).CreateDataSource(self.dsname)
        layer = self.ds.CreateLayer(self.layername)
        props = []
        for feature in features:
            for prop, value in feature.properties.items():
                if not prop: continue
                if prop not in props:
                    props.append(prop)
                    prop = str(prop)
                    defn = ogr.FieldDefn(prop)
                    defn.SetWidth(len(value))
                    layer.CreateField(defn)
        for feature in features:
            f = ogr.Feature(feature_def=layer.GetLayerDefn())
            for prop, value in feature.properties.items():
                prop = str(prop)
                if isinstance(value, unicode):
                    value = value.encode("utf-8", "replace")
                f.SetField(prop, value)
            g = self.CreateGeometryFromJson(simplejson.dumps(feature.geometry))
            f.SetGeometryDirectly(g)
            layer.CreateFeature(f)
        if self.save_on_encode:
            layer.SyncToDisk()    
        return layer
    
    def decode(self, layer):
        features = []
        layer.ResetReading()
        feature = layer.GetNextFeature()
        while feature:
            id = feature.GetFID() 
            geometry = self.ExportToJson(feature.GetGeometryRef())
            props = {}
            for i in range(feature.GetFieldCount()):
                props[feature.GetFieldDefnRef(i).GetName()] = feature.GetFieldAsString(i)
            features.append(Feature(id, geometry, props))
            feature = layer.GetNextFeature()
        return features    
    
    def CreateGeometryFromJson(self, input):
        try:
            input['type']
        except TypeError:
            try:
                import simplejson
            except ImportError:
                raise ImportError, "You must have 'simplejson' installed to be able to use this functionality"
            input = simplejson.loads(input)
    
        types = { 'Point': ogr.wkbPoint,
                  'LineString': ogr.wkbLineString,
                  'Polygon': ogr.wkbPolygon,
                  'MultiPoint': ogr.wkbMultiPoint,
                  'MultiLineString': ogr.wkbMultiLineString,
                  'MultiPolygon': ogr.wkbMultiPolygon,
                  'GeometryCollection': ogr.wkbGeometryCollection
        }
       
        type = input['type']
        gtype = types[type]
    
        geometry = ogr.Geometry(type=gtype)
        coordinates = input['coordinates']
       
        if type == 'Point':
            geometry.AddPoint_2D(coordinates[0], coordinates[1])
        
        elif type == 'MultiPoint':
            for point in coordinates:
                gring = ogr.Geometry(type=ogr.wkbPoint)
                gring.AddPoint_2D(point[0], point[1])
                geometry.AddGeometry(gring)
       
        elif type == 'LineString':
            for coordinate in coordinates:
                geometry.AddPoint_2D(coordinate[0], coordinate[1])
        
        elif type == 'MultiLineString':
            for ring in coordinates:
                gring = ogr.Geometry(type=ogr.wkbLineString)
                for coordinate in ring:
                    gring.AddPoint_2D(coordinate[0], coordinate[1])
                geometry.AddGeometry(gring)
    
        
        elif type == 'Polygon':
            for ring in coordinates:
                gring = ogr.Geometry(type=ogr.wkbLinearRing)
                for coordinate in ring:
                    gring.AddPoint_2D(coordinate[0], coordinate[1])
                geometry.AddGeometry(gring)
        
        elif type == 'MultiPolygon':
            for poly in coordinates:
                gpoly = ogr.Geometry(type=ogr.wkbPolygon)
                for ring in poly:
                    gring = ogr.Geometry(type=ogr.wkbLinearRing)
                    for coordinate in ring:
                        gring.AddPoint_2D(coordinate[0], coordinate[1])
                    gpoly.AddGeometry(gring)
                geometry.AddGeometry(gpoly)
        
        return geometry
    
    def ExportToJson(self, geometry):
        def get_coordinates(geometry):
            gtype = geometry.GetGeometryType()
            geom_count = geometry.GetGeometryCount()
            coordinates = []
    
            if gtype == ogr.wkbPoint or gtype == ogr.wkbPoint25D:
                return [geometry.GetX(0), geometry.GetY(0)]
                
            if gtype == ogr.wkbMultiPoint or gtype == ogr.wkbMultiPoint25D:
                geom_count = geometry.GetGeometryCount()
                for g in range(geom_count):
                    geom = geometry.GetGeometryRef(g)
                    coordinates.append(get_coordinates(geom))
                return coordinates
    
            if gtype == ogr.wkbLineString or gtype == ogr.wkbLineString25D:
                points = []
                point_count = geometry.GetPointCount()
                for i in range(point_count):
                    points.append([geometry.GetX(i), geometry.GetY(i)])
                return points
    
            if gtype == ogr.wkbMultiLineString or gtype == ogr.wkbMultiLineString25D:
                coordinates = []
                geom_count = geometry.GetGeometryCount()
                for g in range(geom_count):
                    geom = geometry.GetGeometryRef(g)        
                    coordinates.append(get_coordinates(geom))
                return coordinates
    
            if gtype == ogr.wkbPolygon or gtype == ogr.wkbPolygon25D:
                geom = geometry.GetGeometryRef(0)
                coordinates = get_coordinates(geom)
                return [coordinates]
    
            if gtype == ogr.wkbMultiPolygon or gtype == ogr.wkbMultiPolygon25D:
    
                coordinates = []
                geom_count = geometry.GetGeometryCount()
                for g in range(geom_count):
                    geom = geometry.GetGeometryRef(g)
                    coordinates.append(get_coordinates(geom))
                return coordinates
                
        types = { ogr.wkbPoint:'Point',
                  ogr.wkbLineString: 'LineString',
                  ogr.wkbPolygon: 'Polygon',
                  ogr.wkbMultiPoint: 'MultiPoint',
                  ogr.wkbMultiLineString: 'MultiLineString',
                  ogr.wkbMultiPolygon: 'MultiPolygon',
                  ogr.wkbGeometryCollection: 'GeometryCollection'  
        }
    
        output = {'type': types[geometry.GetGeometryType()],
                  'coordinates': get_coordinates(geometry)}
        return output

########NEW FILE########
__FILENAME__ = OSM
__author__  = "MetaCarta"
__copyright__ = "Copyright (c) 2006-2008 MetaCarta"
__license__ = "Clear BSD" 
__version__ = "$Id: OSM.py 599 2009-04-02 21:35:26Z crschmidt $"

from vectorformats.Formats.Format import Format

class OSM(Format):
    """OSM 0.5 writing."""

    def encode(self, result):
        results = ["""<?xml version="1.0" encoding="UTF-8"?>
<osm version="0.5" generator="FeatureServer">"""]
        
        for action in result:
                results.append( self.encode_feature(action))
        results.append("</osm>")
        return "\n".join(results)
    
    def encode_feature(self, feature):
        import xml.dom.minidom as m
        import types
        doc = m.Document()
        
        if feature.geometry['type'] == "Point":
            version = None
            if feature.properties.has_key('version'):
                version = feature.properties['version']
            node = self.create_node(-feature.id, feature.geometry['coordinates'], version)
            for key, value in feature.properties.items():
                if isinstance(value, types.NoneType):
                    continue
                if isinstance(value, str):
                    value = unicode(value, "utf-8")
                if isinstance(value, int):
                    value = str(value)
                tag = doc.createElement("tag")
                tag.setAttribute("k", key)
                tag.setAttribute("v", value)
                node.appendChild(tag)
            return node.toxml()
        
        elif feature.geometry['type'] == "Line" or feature.geometry['type'] == "LineString" or feature.geometry['type'] == "Polygon":
            xml = ""
            i = 0
            way = doc.createElement("way")
            way.setAttribute("id", str(-feature.id))
            coords = None
            if feature.geometry['type'] == "Line" or feature.geometry['type'] == "LineString":
                coords = feature.geometry['coordinates']
            else:    
                coords = feature.geometry['coordinates'][0]
            for coord in coords:
                i+=1
                version = None
                if feature.properties.has_key('version'):
                    version = feature.properties['version']
                xml += self.create_node("-%s000000%s" % (feature.id, i), coord, version).toxml()
                nd = doc.createElement("nd")
                nd.setAttribute("ref", "-%s000000%s" % (feature.id, i))
                way.appendChild(nd)
            for key, value in feature.properties.items():
                if isinstance(value, types.NoneType):
                    continue
                if isinstance(value, str):
                    value = unicode(value, "utf-8")
                if isinstance(value, int):
                    value = str(value)
                tag = doc.createElement("tag")
                tag.setAttribute("k", key)
                tag.setAttribute("v", value)
                way.appendChild(tag)
            xml += way.toxml()
            return xml    
        return ""
        
        
    def create_node(self, id, geom, version):
        import xml.dom.minidom as m
        doc = m.Document()
        node = doc.createElement("node")
        node.setAttribute("id", str(id)) 
        node.setAttribute("lat", "%s" % geom[1])
        node.setAttribute("lon", "%s" % geom[0])
        if version is None:
            node.setAttribute("version", "0")
        else:
            node.setAttribute("version", "%s" % version)
        return node

########NEW FILE########
__FILENAME__ = OV2
'''
Created on Jul 30, 2011

@author: michel
'''

from vectorformats.Formats.Format import Format
import StringIO
from struct import pack
import types

class OV2(Format):
    
    def encode(self, features, **kwargs):
        ov2Buffer = StringIO.StringIO()
        
        for feature in features:
            self.encode_feature(feature, ov2Buffer)
        
        return ov2Buffer
        
    def encode_feature(self, feature, buffer):
        if feature.properties.has_key('name'):
            if isinstance(feature.properties['name'], types.NoneType):
                buffer.write(self.getBinaryLine(str(feature.id), feature.geometry["coordinates"][0], feature.geometry["coordinates"][1]))
            else:
                buffer.write(self.getBinaryLine(feature.properties['name'].encode('utf-8'), feature.geometry["coordinates"][0], feature.geometry["coordinates"][1]))
        else:
            buffer.write(self.getBinaryLine(str(feature.id), feature.geometry["coordinates"][0], feature.geometry["coordinates"][1]))
            
        
    def getBinaryLine(self, name, lat, lon):
        return chr(0x02) + pack("I", len(bytes(name))+14) + pack("I", int(round(lat*100000))) + pack("I", int(round(lon*100000))) + bytes(name) + chr(0x00)
    
    
########NEW FILE########
__FILENAME__ = SHP
'''
Created on May 18, 2011

@author: michel
'''

from vectorformats.Formats.Format import Format
import vectorformats.lib.shapefile as shapefile 
import StringIO

class SHP(Format):

    def encode(self, features, props = None, fixed_props = False, **kwargs):
        ''' '''
        writer = shapefile.Writer()
        
        if len(features) > 0:
            feature = features[0]
            for key, value in feature.properties.items():
                writer.field(key)
        
        for feature in features:
            self.encode_feature(feature, writer)
        
        shpBuffer = StringIO.StringIO()
        shxBuffer = StringIO.StringIO()
        dbfBuffer = StringIO.StringIO()
        prjBuffer = StringIO.StringIO()
        
        writer.saveShp(shpBuffer)
        writer.saveShx(shxBuffer)
        writer.saveDbf(dbfBuffer)
        
        if hasattr(feature, "geometry_attr"):
            srs = str(feature.srs);
            if 'EPSG' not in srs:
                srs = "EPSG:" + str(feature.srs)
            
            organization = srs[:srs.find(":")]
            number = srs[srs.find(":")+1:]
            
            file = open("resources/projections/" + str(organization).lower() + "/" + str(number) + ".prj")
            prjBuffer.write(file.read())
        
        return (shpBuffer, shxBuffer, dbfBuffer, prjBuffer)
    
    def encode_feature(self, feature, writer):
        
        if feature['geometry']['type'] == 'Point':
            writer.shapeType = shapefile.POINT
            writer.point(feature['geometry']['coordinates'][0], feature['geometry']['coordinates'][1])
        elif feature['geometry']['type'] == 'LineString':
            writer.shapeType = shapefile.POLYLINE
            parts = []
            parts.append(feature['geometry']['coordinates'])
            writer.line(parts=parts)
        elif feature['geometry']['type'] == 'Polygon':
            writer.shapeType = shapefile.POLYGON
            writer.poly(parts=feature['geometry']['coordinates'])
        else:
            raise Exception("Could not convert geometry of type %s." % feature['geometry']['type'])
        
        records = {}
        # TODO: same amount as above
        for key, property in feature.properties.iteritems():
            key = self.getFormatedAttributName(key)
            if property == None:
                records[key] = ' '
            else:
                records[key] = property.encode('utf-8')
        writer.record(**records)
        
########NEW FILE########
__FILENAME__ = SQLite
'''
Created on Sep 14, 2012

@author: michel
'''

from vectorformats.Formats.Format import Format
from vectorformats.Formats import WKT
from pyspatialite import dbapi2 as db

class SQLite(Format):
    
    _connection = None
    _cursor = None
    
    def encode(self, features, **kwargs):
        tmpFile = kwargs["tmpFile"]
        
        if len(features) > 0:
            self._connection = db.connect(tmpFile)
            self._cursor = self._connection.cursor()
            
            self._cursor.execute('SELECT InitSpatialMetadata()')
            
            self.create_table(features[0])
                        
            for feature in features:
                self.encode_feature(feature)
            
            
            self._connection.commit()
            self._cursor.close()
        
        return self._connection
    
    def create_table(self, feature):
        sql = "CREATE TABLE featureserver (fid text, "
        
        for key, value in feature.properties.items():
            if key != "geometry":
                sql += "%s text, " % key
        
        sql = sql[:-2]
        sql += ")"
        
        self._cursor.execute(sql)
        
        if hasattr(self.datasource, 'srid_out') and self.datasource.srid_out is not None:
            srs = self.datasource.srid_out
        else:
            if hasattr(feature, "geometry_attr"):
                srs = str(feature.srs);
                if 'EPSG' in srs:
                    srs = srs[5:]
            else:
                srs = 4326
        
        self._cursor.execute('''SELECT AddGeometryColumn('featureserver', 'geometry', %i, '%s', 2);''' % (int(srs), feature['geometry']['type'].upper()))
        
    
    def encode_feature(self, feature):
        if hasattr(self.datasource, 'srid_out') and self.datasource.srid_out is not None:
            srs = self.datasource.srid_out
        else:
            if hasattr(feature, "geometry_attr"):
                srs = str(feature.srs);
                if 'EPSG' in srs:
                    srs = srs[5:]
            else:
                srs = 4326
        
        wkt = "GeomFromText('" + WKT.to_wkt(feature.geometry) + "', %i)" % int(srs)
        
        sql = "INSERT INTO featureserver (fid, "
        
        for key, value in feature.properties.items():
            if key != "geometry":
                sql += "%s, " % key
        sql += "geometry" 
        sql += ") VALUES ('%s', " % self.escapeSQL(str(feature.id).encode('utf-8'))
        
        for key, value in feature.properties.items():
            #key = self.getFormatedAttributName(key)
            if value == None:
                sql += "null, "
            else:
                sql += "'" + self.escapeSQL(value.encode('utf-8')) + "', "
        sql += wkt
        sql += ");"
        
        self._cursor.execute(sql)
        
########NEW FILE########
__FILENAME__ = WFS
from vectorformats.Formats.Format import Format
import re, xml.dom.minidom as m
from lxml import etree
from xml.sax.saxutils import escape

class WFS(Format):
    """WFS-like GML writer."""
    layername = "layer"
    namespaces = {'fs' : 'http://featureserver.org/fs',
                  'wfs' : 'http://www.opengis.net/wfs',
                  'ogc' : 'http://www.opengis.net/ogc',
                  'xsd' : 'http://www.w3.org/2001/XMLSchema',
                  'gml' : 'http://www.opengis.net/gml',
                  'xsi' : 'http://www.w3.org/2001/XMLSchema-instance'}
    
    def encode(self, features, **kwargs):
        results = ["""<?xml version="1.0" ?><wfs:FeatureCollection
   xmlns:fs="http://featureserver.org/fs"
   xmlns:wfs="http://www.opengis.net/wfs"
   xmlns:gml="http://www.opengis.net/gml"
   xmlns:ogc="http://www.opengis.net/ogc"
   xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
   xsi:schemaLocation="http://www.opengis.net/wfs http://schemas.opengeospatial.net//wfs/1.0.0/WFS-basic.xsd">
        """]
        for feature in features:
            results.append( self.encode_feature(feature))
        results.append("""</wfs:FeatureCollection>""")
        
        return "\n".join(results)        
    
    def encode_feature(self, feature):
        layername = re.sub(r'\W', '_', self.layername)
        
        attr_fields = [] 
        for key, value in feature.properties.items():           
            #key = re.sub(r'\W', '_', key)
            attr_value = value
            if hasattr(attr_value,"replace"): 
                attr_value = attr_value.replace("&", "&amp;").replace("<", "&lt;").replace(">", "&gt;")
            if isinstance(attr_value, str):
                attr_value = unicode(attr_value, "utf-8")
            attr_fields.append( "<fs:%s>%s</fs:%s>" % (key, attr_value, key) )
            
        
        xml = "<gml:featureMember gml:id=\"%s\"><fs:%s fid=\"%s\">" % (str(feature.id), layername, str(feature.id))
        
        if hasattr(feature, "geometry_attr"):
            xml += "<fs:%s>%s</fs:%s>" % (feature.geometry_attr, self.geometry_to_gml(feature.geometry, feature.srs), feature.geometry_attr)
        else:
            xml += self.geometry_to_gml(feature.geometry, feature.srs)
        
        xml += "%s</fs:%s></gml:featureMember>" % ("\n".join(attr_fields), layername)  
        return xml
    
    def geometry_to_gml(self, geometry, srs):
        """
        >>> w = WFS()
        >>> print w.geometry_to_gml({'type':'Point', 'coordinates':[1.0,2.0]})
        <gml:Point><gml:coordinates>1.0,2.0</gml:coordinates></gml:Point>
        >>> w.geometry_to_gml({'type':'LineString', 'coordinates':[[1.0,2.0],[2.0,1.0]]})
        '<gml:LineString><gml:coordinates>1.0,2.0 2.0,1.0</gml:coordinates></gml:LineString>'
        """
        
        if "EPSG" not in str(srs):
            srs = "EPSG:" + str(srs)
        
        if geometry['type'] == "Point":
            coords = ",".join(map(str, geometry['coordinates']))
            return "<gml:Point srsName=\"%s\"><gml:coordinates decimal=\".\" cs=\",\" ts=\" \">%s</gml:coordinates></gml:Point>" % (str(srs), coords)
            #coords = " ".join(map(str, geometry['coordinates']))
            #return "<gml:Point srsDimension=\"2\" srsName=\"%s\"><gml:pos>%s</gml:pos></gml:Point>" % (str(srs), coords)
        elif geometry['type'] == "LineString":
            coords = " ".join(",".join(map(str, coord)) for coord in geometry['coordinates'])
            return "<gml:LineString><gml:coordinates decimal=\".\" cs=\",\" ts=\" \" srsName=\"%s\">%s</gml:coordinates></gml:LineString>" % (str(srs), coords)
            #return "<gml:curveProperty><gml:LineString srsDimension=\"2\" srsName=\"%s\"><gml:coordinates>%s</gml:coordinates></gml:LineString></gml:curveProperty>" % (str(srs), coords)
        elif geometry['type'] == "Polygon":
            coords = " ".join(map(lambda x: ",".join(map(str, x)), geometry['coordinates'][0]))
            #out = """
            #    <gml:exterior>
            #        <gml:LinearRing>
            #            <gml:coordinates decimal=\".\" cs=\",\" ts=\" \">%s</gml:coordinates>
            #        </gml:LinearRing>
            #    </gml:exterior>
            #""" % coords 
            out = """
                <gml:exterior>
                    <gml:LinearRing srsDimension="2">
                        <gml:coordinates>%s</gml:coordinates>
                    </gml:LinearRing>
                </gml:exterior>
            """ % coords 
            
            inner_rings = []
            for inner_ring in geometry['coordinates'][1:]:
                coords = " ".join(map(lambda x: ",".join(map(str, x)), inner_ring))
                #inner_rings.append("""
                #    <gml:interior>
                #        <gml:LinearRing>
                #            <gml:coordinates decimal=\".\" cs=\",\" ts=\" \">%s</gml:coordinates>
                #        </gml:LinearRing>
                #    </gml:interior>
                #""" % coords) 
                inner_rings.append("""
                    <gml:interior>
                        <gml:LinearRing srsDimension="2">
                            <gml:coordinates>%s</gml:coordinates>
                        </gml:LinearRing>
                    </gml:interior>
                """ % coords) 
            
            return """
                            <gml:Polygon srsName="%s">
                                %s %s
                            </gml:Polygon>""" % (srs, out, "".join(inner_rings))
        else:
            raise Exception("Could not convert geometry of type %s." % geometry['type'])
    
    
    def encode_exception_report(self, exceptionReport):
        results = ["""<?xml version="1.0" encoding="UTF-8"?>
        <ExceptionReport xmlns="http://www.opengis.net/ows/1.1"
        xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
        xsi:schemaLocation="http://www.opengis.net/ows/1.1 owsExceptionReport.xsd"
        version="1.0.0"
        xml:lang="en">
        """]
        for exception in exceptionReport:
            results.append("<Exception exceptionCode=\"%s\" locator=\"%s\" layer=\"%s\"><ExceptionText>%s</ExceptionText><ExceptionDump>%s</ExceptionDump></Exception>" % (exception.code, exception.locator, exception.layer, exception.message, exception.dump))
        results.append("""</ExceptionReport>""")
        return "\n".join(results)
    
    def encode_transaction(self, response, **kwargs):
        failedCount = 0
        
        summary = response.getSummary()
        result = """<?xml version="1.0" encoding="UTF-8"?>
        <wfs:TransactionResponse version="1.1.0"
            xsi:schemaLocation='http://www.opengis.net/wfs http://schemas.opengis.net/wfs/1.0.0/WFS-transaction.xsd'
            xmlns:og="http://opengeo.org"
            xmlns:ogc="http://www.opengis.net/ogc"
            xmlns:tiger="http://www.census.gov"
            xmlns:cite="http://www.opengeospatial.net/cite"
            xmlns:nurc="http://www.nurc.nato.int"
            xmlns:sde="http://geoserver.sf.net"
            xmlns:analytics="http://opengeo.org/analytics"
            xmlns:wfs="http://www.opengis.net/wfs"
            xmlns:topp="http://www.openplans.org/topp"
            xmlns:it.geosolutions="http://www.geo-solutions.it"
            xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
            xmlns:sf="http://www.openplans.org/spearfish"
            xmlns:ows="http://www.opengis.net/ows"
            xmlns:gml="http://www.opengis.net/gml"
            xmlns:za="http://opengeo.org/za"
            xmlns:xlink="http://www.w3.org/1999/xlink"
            xmlns:tike="http://opengeo.org/#tike">
                <wfs:TransactionSummary>
                    <wfs:totalInserted>%s</wfs:totalInserted>
                    <wfs:totalUpdated>%s</wfs:totalUpdated>
                    <wfs:totalDeleted>%s</wfs:totalDeleted>
                    <wfs:totalReplaced>%s</wfs:totalReplaced>
                </wfs:TransactionSummary>
            <wfs:TransactionResults/> """ % (str(summary.getTotalInserted()), str(summary.getTotalUpdated()), str(summary.getTotalDeleted()), str(summary.getTotalReplaced()))
        
        insertResult = response.getInsertResults()
        result += "<wfs:InsertResults>"
        for insert in insertResult:
            result += """<wfs:Feature handle="%s">
                    <ogc:ResourceId fid="%s"/>
                </wfs:Feature>""" % (str(insert.getHandle()), str(insert.getResourceId()))
            if len(insert.getHandle()) > 0:
                failedCount += 1
        result += """</wfs:InsertResults>"""

        updateResult = response.getUpdateResults()
        result += "<wfs:UpdateResults>"
        for update in updateResult:
            result += """<wfs:Feature handle="%s">
                    <ogc:ResourceId fid="%s"/>
                </wfs:Feature>""" % (str(update.getHandle()), str(update.getResourceId()))
            if len(update.getHandle()) > 0:
                failedCount += 1

        result += """</wfs:UpdateResults>"""

        replaceResult = response.getReplaceResults()
        result += "<wfs:ReplaceResults>"
        for replace in replaceResult:
            result += """<wfs:Feature handle="%s">
                    <ogc:ResourceId fid="%s"/>
                </wfs:Feature>""" % (str(replace.getHandle()), str(replace.getResourceId()))
            if len(replace.getHandle()) > 0:
                failedCount += 1
        result += """</wfs:ReplaceResults>"""
        
        
        deleteResult = response.getDeleteResults()
        result += "<wfs:DeleteResults>"
        for delete in deleteResult:
            result += """<wfs:Feature handle="%s">
                <ogc:ResourceId fid="%s"/>
                </wfs:Feature>""" % (str(delete.getHandle()), str(delete.getResourceId()))
            if len(delete.getHandle()) > 0:
                failedCount += 1
        result += """</wfs:DeleteResults>"""

        
        result += """<wfs:TransactionResult> 
                        <wfs:Status> """
        
        if (len(insertResult) + len(updateResult) + len(replaceResult)) == failedCount:
            result += "<wfs:FAILED/>"
        elif (len(insertResult) + len(updateResult) + len(replaceResult)) > failedCount and failedCount > 0:
            result += "<wfs:PARTIAL/>"
        else:
            result += "<wfs:SUCCESS/>"
                        
                        
        result += """</wfs:Status>
                </wfs:TransactionResult>""" 


        result += """</wfs:TransactionResponse>"""
        
        return result

    def getcapabilities(self):
        tree = etree.parse("resources/wfs-capabilities.xml")
        root = tree.getroot()
        elements = root.xpath("wfs:Capability/wfs:Request/wfs:GetCapabilities/wfs:DCPType/wfs:HTTP", namespaces = self.namespaces)
        if len(elements) > 0:
            for element in elements:
                for http in element:
                    http.set('onlineResource', self.host + '?')

        elements = root.xpath("wfs:Capability/wfs:Request/wfs:DescribeFeatureType/wfs:DCPType/wfs:HTTP", namespaces = self.namespaces)
        if len(elements) > 0:
            for element in elements:
                for http in element:
                    http.set('onlineResource', self.host + '?')

        elements = root.xpath("wfs:Capability/wfs:Request/wfs:GetFeature/wfs:DCPType/wfs:HTTP", namespaces = self.namespaces)
        if len(elements) > 0:
            for element in elements:
                for http in element:
                    http.set('onlineResource', self.host + '?')
        
        elements = root.xpath("wfs:Capability/wfs:Request/wfs:Transaction/wfs:DCPType/wfs:HTTP", namespaces = self.namespaces)
        if len(elements) > 0:
            for element in elements:
                for http in element:
                    http.set('onlineResource', self.host + '?')


        layers = self.getlayers()
        featureList = root.xpath("wfs:FeatureTypeList", namespaces = self.namespaces)
        if len(featureList) > 0 and len(layers) > 0:
            for layer in layers:
                featureList[0].append(layer)
        
        return etree.tostring(tree, pretty_print=True)
    
    def getlayers(self):
        ''' '''
        featureList = etree.Element('FeatureTypeList')
        operations = etree.Element('Operations')
        operations.append(etree.Element('Query'))
        featureList.append(operations)

        for layer in self.layers:
            type = etree.Element('FeatureType')
            name = etree.Element('Name')
            name.text = layer
            type.append(name)
            
            title = etree.Element('Title')
            if hasattr(self.datasources[layer], 'title'):
                title.text = self.datasources[layer].title
            type.append(title)

            abstract = etree.Element('Abstract')
            if hasattr(self.datasources[layer], 'abstract'):
                abstract.text = self.datasources[layer].abstract
            type.append(abstract)

            
            srs = etree.Element('SRS')
            if hasattr(self.datasources[layer], 'srid_out') and self.datasources[layer].srid_out is not None:
                srs.text = 'EPSG:' + str(self.datasources[layer].srid_out)
            else:
                srs.text = 'EPSG:4326'
            type.append(srs)
            
            featureOperations = etree.Element('Operations')
            featureOperations.append(etree.Element('Insert'))
            featureOperations.append(etree.Element('Update'))
            featureOperations.append(etree.Element('Delete'))
            type.append(featureOperations)
            
            latlong = self.getBBOX(self.datasources[layer])
            type.append(latlong)
            
            featureList.append(type)
            
        return featureList
        
    def describefeaturetype(self):
        tree = etree.parse("resources/wfs-featuretype.xsd")
        root = tree.getroot()
        
        if len(self.layers) == 1:
            ''' special case when only one datasource is requested --> other xml schema '''
            root = self.addDataSourceFeatureType(root, self.datasources[self.layers[0]])
        else:
            ''' loop over all requested datasources '''
            for layer in self.layers:
                root = self.addDataSourceImport(root, self.datasources[layer])
                #root = self.addDataSourceFeatureType(root, self.datasources[layer])
        
        return etree.tostring(tree, pretty_print=True)
    
    def addDataSourceImport(self, root, datasource):
        root.append(
                    etree.Element('import', attrib={'namespace':self.namespaces['fs'],
                                                    'schemaLocation':self.host+'?request=DescribeFeatureType&typeName='+datasource.name})
                    )
        return root
    
    def addDataSourceFeatureType(self, root, datasource):
        
        root.append(etree.Element('element', attrib={'name':datasource.name,
                                                   'type':'fs:'+datasource.name+'_Type',
                                                   'substitutionGroup':'gml:_Feature'}))
        
        complexType = etree.Element('complexType', attrib={'name':datasource.name+'_Type'})
        complexContent = etree.Element('complexContent')
        extension = etree.Element('extension', attrib={'base':'gml:AbstractFeatureType'})
        sequence = etree.Element('sequence')
        
        for attribut_col in datasource.attribute_cols.split(','):
            type, length = datasource.getAttributeDescription(attribut_col)
            
            maxLength = etree.Element('maxLength', attrib={'value':str(length)})
            restriction = etree.Element('restriction', attrib={'base' : type})
            restriction.append(maxLength)
            simpleType = etree.Element('simpleType')
            simpleType.append(restriction)

            attrib_name = attribut_col
            if hasattr(datasource, "hstore"):
                if datasource.hstore:
                    attrib_name = self.getFormatedAttributName(attrib_name)
            
            element = etree.Element('element', attrib={'name' : str(attrib_name),
                                                       'minOccurs' : '0'})
            element.append(simpleType)
            
            sequence.append(element)
            
        if hasattr(datasource, "additional_cols"):
            for additional_col in datasource.additional_cols.split(';'):            
                name = additional_col
                matches = re.search('(?<=[ ]as[ ])\s*\w+', str(additional_col))
                if matches:
                    name = matches.group(0)

                type, length = datasource.getAttributeDescription(name)
                
                maxLength = etree.Element('maxLength', attrib={'value':'0'})
                restriction = etree.Element('restriction', attrib={'base' : type})
                restriction.append(maxLength)
                simpleType = etree.Element('simpleType')
                simpleType.append(restriction)
                element = etree.Element('element', attrib={'name' : name,
                                                           'minOccurs' : '0',
                                                           'maxOccurs' : '0'})
                element.append(simpleType)
                
                sequence.append(element)
        
        
        if hasattr(datasource, 'geometry_type'):
            properties = datasource.geometry_type.split(',')
        else:
            properties = ['Point', 'Line', 'Polygon']
        for property in properties:
            if property == 'Point':
                element = etree.Element('element', attrib={'name' : datasource.geom_col,
                                                           'type' : 'gml:PointPropertyType',
                                                           'minOccurs' : '0'})
                sequence.append(element)
            elif property == 'Line':
                element = etree.Element('element', attrib={'name' : datasource.geom_col,
                                                           'type' : 'gml:LineStringPropertyType',
                                                           #'ref' : 'gml:curveProperty',
                                                           'minOccurs' : '0'})
                sequence.append(element)
            elif property == 'Polygon':
                element = etree.Element('element', attrib={'name' : datasource.geom_col,
                                                           'type' : 'gml:PolygonPropertyType',
                                                           #'substitutionGroup' : 'gml:_Surface',
                                                           'minOccurs' : '0'})
                sequence.append(element)
                    
        
        extension.append(sequence)
        complexContent.append(extension)
        complexType.append(complexContent)
        root.append(complexType)

        return root
        
    def getBBOX(self, datasource):
        if hasattr(datasource, 'bbox'):
            latlong = datasource.bbox
        else:
            latlong = datasource.getBBOX()
        latlongArray = latlong.split(' ')
        
        return etree.Element('bbox', 
                             attrib={'minx':latlongArray[0],
                                     'miny':latlongArray[1],
                                     'maxx':latlongArray[2],
                                     'maxy':latlongArray[3]})

########NEW FILE########
__FILENAME__ = WKT
from vectorformats.Feature import Feature
from vectorformats.Formats.Format import Format

import re

class WKT(Format):
    """Converts a single chunk of WKT to a list of 1 feature."""

    def from_wkt(self, geom):
        return from_wkt(geom)
    
    def decode(self, data):    
        features = [
            Feature(1, self.from_wkt(data))
        ]
        
        return features    


def from_wkt (geom):
    """wkt helper: converts from WKT to a GeoJSON-like geometry."""
    wkt_linestring_match = re.compile(r'\(([^()]+)\)')
    re_space             = re.compile(r"\s+")

    coords = []
    for line in wkt_linestring_match.findall(geom):
        rings = [[]]
        for pair in line.split(","):

            if not pair.strip():
                rings.append([])
                continue
            rings[-1].append(map(float, re.split(re_space, pair.strip())))

        coords.append(rings[0])

    if geom.startswith("MULTIPOINT"):
        geomtype = "MultiPoint"
        coords = coords[0]
    elif geom.startswith("POINT"):
        geomtype = "Point"
        coords = coords[0][0]

    elif geom.startswith("MULTILINESTRING"):
        geomtype = "MultiLineString"
    elif geom.startswith("LINESTRING"):
        geomtype = "LineString"
        coords = coords[0]

    elif geom.startswith("MULTIPOLYGON"):
        geomtype = "MultiPolygon"
    elif geom.startswith("POLYGON"):
        geomtype = "Polygon"
    else:
        geomtype = geom[:geom.index["("]]
        raise Exception("Unsupported geometry type %s" % geomtype)

    return {"type": geomtype, "coordinates": coords}



def to_wkt (geom):
    """Converts a GeoJSON-like geometry to WKT.""" 

    def coords_to_wkt (coords):
        format_str = " ".join(("%f",) * len(coords[0]))
        return ",".join([format_str % tuple(c) for c in coords])

    coords = geom["coordinates"]
    if geom["type"] == "Point":
        return "POINT(%s)" % coords_to_wkt((coords,))
    elif geom["type"] == "LineString":
        return "LINESTRING(%s)" % coords_to_wkt(coords)
    elif geom["type"] == "Polygon":
        rings = ["(" + coords_to_wkt(ring) + ")" for ring in coords]
        rings = ",".join(rings)
        return "POLYGON(%s)" % rings

    elif geom["type"] == "MultiPoint":
        pts = ",".join(coords_to_wkt((ring,)) for ring in coords)
        return "MUTLIPOINT(%s)" % str(pts)

    elif geom["type"] == "MultiLineString":
        pts = ",".join( "(" +  coords_to_wkt(ring) + ")" for ring in coords  )
        return "MultiLineString(%s)" % str(pts)

    elif geom["type"] == "MultiPolygon":
        poly_str = []
        for coord_list in coords:
            poly_str.append( "((" + ",".join( coords_to_wkt((ring,))  for ring in coord_list) + "))" )
        return "MultiPolygon(%s)" % ", ".join(poly_str)


    else:
        raise Exception("Couldn't create WKT from geometry of type %s (%s). Only Point, Line, Polygon are supported." % (geom['type'], geom))





########NEW FILE########
__FILENAME__ = shapefile
"""
shapefile.py
Provides read and write support for ESRI Shapefiles.
author: jlawhead<at>geospatialpython.com
date: 20110927
version: 1.1.4
Compatible with Python versions 2.4-3.x
"""

from struct import pack, unpack, calcsize, error
import os
import sys
import time
import array
#
# Constants for shape types
NULL = 0
POINT = 1
POLYLINE = 3
POLYGON = 5
MULTIPOINT = 8
POINTZ = 11
POLYLINEZ = 13
POLYGONZ = 15
MULTIPOINTZ = 18
POINTM = 21
POLYLINEM = 23
POLYGONM = 25
MULTIPOINTM = 28
MULTIPATCH = 31

PYTHON3 = sys.version_info[0] == 3

def b(v):
    if PYTHON3:
        if isinstance(v, str):
            # For python 3 encode str to bytes.
            return v.encode('utf-8')
        elif isinstance(v, bytes):
            # Already bytes.
            return v
        else:
            # Error.
            raise Exception('Unknown input type')
    else:
        # For python 2 assume str passed in and return str.
        return v

def u(v):
    if PYTHON3:
        if isinstance(v, bytes):
            # For python 3 decode bytes to str.
            return v.decode('utf-8')
        elif isinstance(v, str):
            # Already str.
            return v
        else:
            # Error.
            raise Exception('Unknown input type')
    else:
        # For python 2 assume str passed in and return str.
        return v

def is_string(v):
    if PYTHON3:
        return isinstance(v, str)
    else:
        return isinstance(v, basestring)

class _Array(array.array):
    """Converts python tuples to lits of the appropritate type.
    Used to unpack different shapefile header parts."""
    def __repr__(self):
        return str(self.tolist())

class _Shape:
    def __init__(self, shapeType=None):
        """Stores the geometry of the different shape types
        specified in the Shapefile spec. Shape types are
        usually point, polyline, or polygons. Every shape type
        except the "Null" type contains points at some level for
        example verticies in a polygon. If a shape type has
        multiple shapes containing points within a single
        geometry record then those shapes are called parts. Parts
        are designated by their starting index in geometry record's
        list of shapes."""
        self.shapeType = shapeType
        self.points = []

class _ShapeRecord:
    """A shape object of any type."""
    def __init__(self, shape=None, record=None):
        self.shape = shape
        self.record = record

class ShapefileException(Exception):
    """An exception to handle shapefile specific problems."""
    pass

class Reader:
    """Reads the three files of a shapefile as a unit or
    separately.  If one of the three files (.shp, .shx,
    .dbf) is missing no exception is thrown until you try
    to call a method that depends on that particular file.
    The .shx index file is used if available for efficiency
    but is not required to read the geometry from the .shp
    file. The "shapefile" argument in the constructor is the
    name of the file you want to open.

    You can instantiate a Reader without specifying a shapefile
    and then specify one later with the load() method.

    Only the shapefile headers are read upon loading. Content
    within each file is only accessed when required and as
    efficiently as possible. Shapefiles are usually not large
    but they can be.
    """
    def __init__(self, *args, **kwargs):
        self.shp = None
        self.shx = None
        self.dbf = None
        self.shapeName = "Not specified"
        self._offsets = []
        self.shpLength = None
        self.numRecords = None
        self.fields = []
        self.__dbfHdrLength = 0
        # See if a shapefile name was passed as an argument
        if len(args) > 0:
            if type(args[0]) is type("stringTest"):
                self.load(args[0])
                return
        if "shp" in kwargs.keys():
            if hasattr(kwargs["shp"], "read"):
                self.shp = kwargs["shp"]
                if hasattr(self.shp, "seek"):
                    self.shp.seek(0)
            if "shx" in kwargs.keys():
                if hasattr(kwargs["shx"], "read"):
                    self.shx = kwargs["shx"]
                    if hasattr(self.shx, "seek"):
                        self.shx.seek(0)
        if "dbf" in kwargs.keys():
            if hasattr(kwargs["dbf"], "read"):
                self.dbf = kwargs["dbf"]
                if hasattr(self.dbf, "seek"):
                    self.dbf.seek(0)
        if self.shp or self.dbf:        
            self.load()
        else:
            raise ShapefileException("Shapefile Reader requires a shapefile or file-like object.")

    def load(self, shapefile=None):
        """Opens a shapefile from a filename or file-like
        object. Normally this method would be called by the
        constructor with the file object or file name as an
        argument."""
        if shapefile:
            (shapeName, ext) = os.path.splitext(shapefile)
            self.shapeName = shapeName
            try:
                self.shp = open("%s.shp" % shapeName, "rb")
            except IOError:
                raise ShapefileException("Unable to open %s.shp" % shapeName)
            try:
                self.shx = open("%s.shx" % shapeName, "rb")
            except IOError:
                raise ShapefileException("Unable to open %s.shx" % shapeName)
            try:
                self.dbf = open("%s.dbf" % shapeName, "rb")
            except IOError:
                raise ShapefileException("Unable to open %s.dbf" % shapeName)
        if self.shp:
            self.__shpHeader()
        if self.dbf:
            self.__dbfHeader()

    def __getFileObj(self, f):
        """Checks to see if the requested shapefile file object is
        available. If not a ShapefileException is raised."""
        if not f:
            raise ShapefileException("Shapefile Reader requires a shapefile or file-like object.")
        if self.shp and self.shpLength is None:
            self.load()
        if self.dbf and len(self.fields) == 0:
            self.load()
        return f

    def __restrictIndex(self, i):
        """Provides list-like handling of a record index with a clearer
        error message if the index is out of bounds."""
        if self.numRecords:
            rmax = self.numRecords - 1
            if abs(i) > rmax:
                raise IndexError("Shape or Record index out of range.")
            if i < 0: i = range(self.numRecords)[i]
        return i

    def __shpHeader(self):
        """Reads the header information from a .shp or .shx file."""
        if not self.shp:
            raise ShapefileException("Shapefile Reader requires a shapefile or file-like object. (no shp file found")
        shp = self.shp
        # File length (16-bit word * 2 = bytes)
        shp.seek(24)
        self.shpLength = unpack(">i", shp.read(4))[0] * 2
        # Shape type
        shp.seek(32)
        self.shapeType= unpack("<i", shp.read(4))[0]
        # The shapefile's bounding box (lower left, upper right)
        self.bbox = _Array('d', unpack("<4d", shp.read(32)))
        # Elevation
        self.elevation = _Array('d', unpack("<2d", shp.read(16)))
        # Measure
        self.measure = _Array('d', unpack("<2d", shp.read(16)))

    def __shape(self):
        """Returns the header info and geometry for a single shape."""
        f = self.__getFileObj(self.shp)
        record = _Shape()
        nParts = nPoints = zmin = zmax = mmin = mmax = None
        (recNum, recLength) = unpack(">2i", f.read(8))
        shapeType = unpack("<i", f.read(4))[0]
        record.shapeType = shapeType
        # For Null shapes create an empty points list for consistency
        if shapeType == 0:
            record.points = []
        # All shape types capable of having a bounding box
        elif shapeType in (3,5,8,13,15,18,23,25,28,31):
            record.bbox = _Array('d', unpack("<4d", f.read(32)))
        # Shape types with parts
        if shapeType in (3,5,13,15,23,25,31):
            nParts = unpack("<i", f.read(4))[0]
        # Shape types with points
        if shapeType in (3,5,8,13,15,23,25,31):
            nPoints = unpack("<i", f.read(4))[0]
        # Read parts
        if nParts:
            record.parts = _Array('i', unpack("<%si" % nParts, f.read(nParts * 4)))
        # Read part types for Multipatch - 31
        if shapeType == 31:
            record.partTypes = _Array('i', unpack("<%si" % nParts, f.read(nParts * 4)))
        # Read points - produces a list of [x,y] values
        if nPoints:
            record.points = [_Array('d', unpack("<2d", f.read(16))) for p in range(nPoints)]
        # Read z extremes and values
        if shapeType in (13,15,18,31):
            (zmin, zmax) = unpack("<2d", f.read(16))
            record.z = _Array('d', unpack("<%sd" % nPoints, f.read(nPoints * 8)))
        # Read m extremes and values
        if shapeType in (13,15,18,23,25,28,31):
            (mmin, mmax) = unpack("<2d", f.read(16))
            # Measure values less than -10e38 are nodata values according to the spec
            record.m = []
            for m in _Array('d', unpack("%sd" % nPoints, f.read(nPoints * 8))):
                if m > -10e38:
                    record.m.append(m)
                else:
                    record.m.append(None)
        # Read a single point
        if shapeType in (1,11,21):
            record.points = [_Array('d', unpack("<2d", f.read(16)))]
        # Read a single Z value
        if shapeType == 11:
            record.z = unpack("<d", f.read(8))
        # Read a single M value
        if shapeType in (11,21):
            record.m = unpack("<d", f.read(8))
        return record

    def __shapeIndex(self, i=None):
        """Returns the offset in a .shp file for a shape based on information
        in the .shx index file."""
        shx = self.shx
        if not shx:
            return None
        if not self._offsets:
            # File length (16-bit word * 2 = bytes) - header length
            shx.seek(24)
            shxRecordLength = (unpack(">i", shx.read(4))[0] * 2) - 100
            numRecords = shxRecordLength // 8
            # Jump to the first record.
            shx.seek(100)
            for r in range(numRecords):
                # Offsets are 16-bit words just like the file length
                self._offsets.append(unpack(">i", shx.read(4))[0] * 2)
                shx.seek(shx.tell() + 4)
        if not i == None:
            return self._offsets[i]

    def shape(self, i=0):
        """Returns a shape object for a shape in the the geometry
        record file."""
        shp = self.__getFileObj(self.shp)
        i = self.__restrictIndex(i)
        offset = self.__shapeIndex(i)
        if not offset:
            # Shx index not available so use the full list.
            shapes = self.shapes()
            return shapes[i]
        shp.seek(offset)
        return self.__shape()

    def shapes(self):
        """Returns all shapes in a shapefile."""
        shp = self.__getFileObj(self.shp)
        shp.seek(100)
        shapes = []
        while shp.tell() < self.shpLength:
            shapes.append(self.__shape())
        return shapes

    def __dbfHeaderLength(self):
        """Retrieves the header length of a dbf file header."""
        if not self.__dbfHdrLength:
            if not self.dbf:
                raise ShapefileException("Shapefile Reader requires a shapefile or file-like object. (no dbf file found)")
            dbf = self.dbf
            (self.numRecords, self.__dbfHdrLength) = \
                    unpack("<xxxxLH22x", dbf.read(32))
        return self.__dbfHdrLength

    def __dbfHeader(self):
        """Reads a dbf header. Xbase-related code borrows heavily from ActiveState Python Cookbook Recipe 362715 by Raymond Hettinger"""
        if not self.dbf:
            raise ShapefileException("Shapefile Reader requires a shapefile or file-like object. (no dbf file found)")
        dbf = self.dbf
        headerLength = self.__dbfHeaderLength()
        numFields = (headerLength - 33) // 32
        for field in range(numFields):
            fieldDesc = list(unpack("<11sc4xBB14x", dbf.read(32)))
            name = 0
            idx = 0
            if b("\x00") in fieldDesc[name]:
                idx = fieldDesc[name].index(b("\x00"))
            else:
                idx = len(fieldDesc[name]) - 1
            fieldDesc[name] = fieldDesc[name][:idx]
            fieldDesc[name] = u(fieldDesc[name])
            fieldDesc[name] = fieldDesc[name].lstrip()
            fieldDesc[1] = u(fieldDesc[1])
            self.fields.append(fieldDesc)
        terminator = dbf.read(1)
        assert terminator == b("\r")
        self.fields.insert(0, ('DeletionFlag', 'C', 1, 0))

    def __recordFmt(self):
        """Calculates the size of a .shp geometry record."""
        if not self.numRecords:
            self.__dbfHeader()
        fmt = ''.join(['%ds' % fieldinfo[2] for fieldinfo in self.fields])
        fmtSize = calcsize(fmt)
        return (fmt, fmtSize)

    def __record(self):
        """Reads and returns a dbf record row as a list of values."""
        f = self.__getFileObj(self.dbf)
        recFmt = self.__recordFmt()
        recordContents = unpack(recFmt[0], f.read(recFmt[1]))
        if recordContents[0] != b(' '):
            # deleted record
            return None
        record = []
        for (name, typ, size, deci), value in zip(self.fields,
                                                                                                recordContents):
            if name == 'DeletionFlag':
                continue
            elif not value.strip():
                record.append(value)
                continue
            elif typ == "N":
                value = value.replace(b('\0'), b('')).strip()
                if value == b(''):
                    value = 0
                elif deci:
                    value = float(value)
                else:
                    value = int(value)
            elif typ == b('D'):
                try:
                    y, m, d = int(value[:4]), int(value[4:6]), int(value[6:8])
                    value = [y, m, d]
                except:
                    value = value.strip()
            elif typ == b('L'):
                value = (value in b('YyTt') and b('T')) or \
                                        (value in b('NnFf') and b('F')) or b('?')
            else:
                value = u(value)
                value = value.strip()
            record.append(value)
        return record

    def record(self, i=0):
        """Returns a specific dbf record based on the supplied index."""
        f = self.__getFileObj(self.dbf)
        if not self.numRecords:
            self.__dbfHeader()
        i = self.__restrictIndex(i)
        recSize = self.__recordFmt()[1]
        f.seek(0)
        f.seek(self.__dbfHeaderLength() + (i * recSize))
        return self.__record()

    def records(self):
        """Returns all records in a dbf file."""
        if not self.numRecords:
            self.__dbfHeader()
        records = []
        f = self.__getFileObj(self.dbf)
        f.seek(self.__dbfHeaderLength())
        for i in range(self.numRecords):
            r = self.__record()
            if r:
                records.append(r)
        return records

    def shapeRecord(self, i=0):
        """Returns a combination geometry and attribute record for the
        supplied record index."""
        i = self.__restrictIndex(i)
        return _ShapeRecord(shape=self.shape(i),
                                                        record=self.record(i))

    def shapeRecords(self):
        """Returns a list of combination geometry/attribute records for
        all records in a shapefile."""
        shapeRecords = []
        return [_ShapeRecord(shape=rec[0], record=rec[1]) \
                                for rec in zip(self.shapes(), self.records())]

class Writer:
    """Provides write support for ESRI Shapefiles."""
    def __init__(self, shapeType=None):
        self._shapes = []
        self.fields = []
        self.records = []
        self.shapeType = shapeType
        self.shp = None
        self.shx = None
        self.dbf = None
        # Geometry record offsets and lengths for writing shx file.
        self._offsets = []
        self._lengths = []
        # Use deletion flags in dbf? Default is false (0).
        self.deletionFlag = 0

    def __getFileObj(self, f):
        """Safety handler to verify file-like objects"""
        if not f:
            raise ShapefileException("No file-like object available.")
        elif hasattr(f, "write"):
            return f
        else:
            pth = os.path.split(f)[0]
            if pth and not os.path.exists(pth):
                os.makedirs(pth)
            return open(f, "wb")

    def __shpFileLength(self):
        """Calculates the file length of the shp file."""
        # Start with header length
        size = 100
        # Calculate size of all shapes
        for s in self._shapes:
            # Add in record header and shape type fields
            size += 12
            # nParts and nPoints do not apply to all shapes
            #if self.shapeType not in (0,1):
            #       nParts = len(s.parts)
            #       nPoints = len(s.points)
            if hasattr(s,'parts'):
                nParts = len(s.parts)
            if hasattr(s,'points'):
                nPoints = len(s.points)
            # All shape types capable of having a bounding box
            if self.shapeType in (3,5,8,13,15,18,23,25,28,31):
                size += 32
            # Shape types with parts
            if self.shapeType in (3,5,13,15,23,25,31):
                # Parts count
                size += 4
                # Parts index array
                size += nParts * 4
            # Shape types with points
            if self.shapeType in (3,5,8,13,15,23,25,31):
                # Points count
                size += 4
                # Points array
                size += 16 * nPoints
            # Calc size of part types for Multipatch (31)
            if self.shapeType == 31:
                size += nParts * 4
            # Calc z extremes and values
            if self.shapeType in (13,15,18,31):
                # z extremes
                size += 16
                # z array
                size += 8 * nPoints
            # Calc m extremes and values
            if self.shapeType in (23,25,31):
                # m extremes
                size += 16
                # m array
                size += 8 * nPoints
            # Calc a single point
            if self.shapeType in (1,11,21):
                size += 16
            # Calc a single Z value
            if self.shapeType == 11:
                size += 8
            # Calc a single M value
            if self.shapeType in (11,21):
                size += 8
        # Calculate size as 16-bit words
        size //= 2
        return size

    def __bbox(self, shapes, shapeTypes=[]):
        x = []
        y = []
        for s in shapes:
            shapeType = self.shapeType
            if shapeTypes:
                shapeType = shapeTypes[shapes.index(s)]
            px, py = list(zip(*s.points))[:2]
            x.extend(px)
            y.extend(py)
        return [min(x), min(y), max(x), max(y)]

    def __zbox(self, shapes, shapeTypes=[]):
        z = []
        for s in shapes:
            try:
                for p in s.points:
                    z.append(p[2])
            except IndexError:
                pass
        if not z: z.append(0)
        return [min(z), max(z)]

    def __mbox(self, shapes, shapeTypes=[]):
        m = [0]
        for s in shapes:
            try:
                for p in s.points:
                    m.append(p[3])
            except IndexError:
                pass
        return [min(m), max(m)]

    def bbox(self):
        """Returns the current bounding box for the shapefile which is
        the lower-left and upper-right corners. It does not contain the
        elevation or measure extremes."""
        return self.__bbox(self._shapes)

    def zbox(self):
        """Returns the current z extremes for the shapefile."""
        return self.__zbox(self._shapes)

    def mbox(self):
        """Returns the current m extremes for the shapefile."""
        return self.__mbox(self._shapes)

    def __shapefileHeader(self, fileObj, headerType='shp'):
        """Writes the specified header type to the specified file-like object.
        Several of the shapefile formats are so similar that a single generic
        method to read or write them is warranted."""
        f = self.__getFileObj(fileObj)
        f.seek(0)
        # File code, Unused bytes
        f.write(pack(">6i", 9994,0,0,0,0,0))
        # File length (Bytes / 2 = 16-bit words)
        if headerType == 'shp':
            f.write(pack(">i", self.__shpFileLength()))
        elif headerType == 'shx':
            f.write(pack('>i', ((100 + (len(self._shapes) * 8)) // 2)))
        # Version, Shape type
        f.write(pack("<2i", 1000, self.shapeType))
        # The shapefile's bounding box (lower left, upper right)
        if self.shapeType != 0:
            try:
                f.write(pack("<4d", *self.bbox()))
            except error:
                raise ShapefileException("Failed to write shapefile bounding box. Floats required.")
        else:
            f.write(pack("<4d", 0,0,0,0))
        # Elevation
        z = self.zbox()
        # Measure
        m = self.mbox()
        try:
            f.write(pack("<4d", z[0], z[1], m[0], m[1]))
        except error:
            raise ShapefileException("Failed to write shapefile elevation and measure values. Floats required.")

    def __dbfHeader(self):
        """Writes the dbf header and field descriptors."""
        f = self.__getFileObj(self.dbf)
        f.seek(0)
        version = 3
        year, month, day = time.localtime()[:3]
        year -= 1900
        # Remove deletion flag placeholder from fields
        for field in self.fields:
            if field[0].startswith("Deletion"):
                self.fields.remove(field)
        numRecs = len(self.records)
        numFields = len(self.fields)
        headerLength = numFields * 32 + 33
        recordLength = sum([int(field[2]) for field in self.fields]) + 1
        header = pack('<BBBBLHH20x', version, year, month, day, numRecs,
                headerLength, recordLength)
        f.write(header)
        # Field descriptors
        for field in self.fields:
            name, fieldType, size, decimal = field
            name = b(name)
            name = name.replace(b(' '), b('_'))
            name = name.ljust(11).replace(b(' '), b('\x00'))
            fieldType = b(fieldType)
            size = int(size)
            fld = pack('<11sc4xBB14x', name, fieldType, size, decimal)
            f.write(fld)
        # Terminator
        f.write(b('\r'))

    def __shpRecords(self):
        """Write the shp records"""
        f = self.__getFileObj(self.shp)
        f.seek(100)
        recNum = 1
        for s in self._shapes:
            self._offsets.append(f.tell())
            # Record number, Content length place holder
            f.write(pack(">2i", recNum, 0))
            recNum += 1
            start = f.tell()
            # Shape Type
            f.write(pack("<i", s.shapeType))
            # All shape types capable of having a bounding box
            if s.shapeType in (3,5,8,13,15,18,23,25,28,31):
                try:
                    f.write(pack("<4d", *self.__bbox([s])))
                except error:
                    raise ShapefileException("Falied to write bounding box for record %s. Expected floats." % recNum)
            # Shape types with parts
            if s.shapeType in (3,5,13,15,23,25,31):
                # Number of parts
                f.write(pack("<i", len(s.parts)))
            # Shape types with multiple points per record
            if s.shapeType in (3,5,8,13,15,23,25,31):
                # Number of points
                f.write(pack("<i", len(s.points)))
            # Write part indexes
            if s.shapeType in (3,5,13,15,23,25,31):
                for p in s.parts:
                    f.write(pack("<i", p))
            # Part types for Multipatch (31)
            if s.shapeType == 31:
                for pt in s.partTypes:
                    f.write(pack("<i", pt))
            # Write points for multiple-point records
            if s.shapeType in (3,5,8,13,15,23,25,31):
                try:
                    [f.write(pack("<2d", *p[:2])) for p in s.points]
                except error:
                    raise ShapefileException("Failed to write points for record %s. Expected floats." % recNum)
            # Write z extremes and values
            if s.shapeType in (13,15,18,31):
                try:
                    f.write(pack("<2d", *self.__zbox([s])))
                except error:
                    raise ShapefileException("Failed to write elevation extremes for record %s. Expected floats." % recNum)
                try:
                    [f.write(pack("<d", p[2])) for p in s.points]
                except error:
                    raise ShapefileException("Failed to write elevation values for record %s. Expected floats." % recNum)
            # Write m extremes and values
            if s.shapeType in (23,25,31):
                try:
                    f.write(pack("<2d", *self.__mbox([s])))
                except error:
                    raise ShapefileException("Failed to write measure extremes for record %s. Expected floats" % recNum)
                try:
                    [f.write(pack("<d", p[3])) for p in s.points]
                except error:
                    raise ShapefileException("Failed to write measure values for record %s. Expected floats" % recNum)
            # Write a single point
            if s.shapeType in (1,11,21):
                try:
                    f.write(pack("<2d", s.points[0][0], s.points[0][1]))
                except error:
                    raise ShapefileException("Failed to write point for record %s. Expected floats." % recNum)
            # Write a single Z value
            if s.shapeType == 11:
                try:
                    f.write(pack("<1d", s.points[0][2]))
                except error:
                    raise ShapefileException("Failed to write elevation value for record %s. Expected floats." % recNum)
            # Write a single M value
            if s.shapeType in (11,21):
                try:
                    f.write(pack("<1d", s.points[0][3]))
                except error:
                    raise ShapefileException("Failed to write measure value for record %s. Expected floats." % recNum)
            # Finalize record length as 16-bit words
            finish = f.tell()
            length = (finish - start) // 2
            self._lengths.append(length)
            # start - 4 bytes is the content length field
            f.seek(start-4)
            f.write(pack(">i", length))
            f.seek(finish)

    def __shxRecords(self):
        """Writes the shx records."""
        f = self.__getFileObj(self.shx)
        f.seek(100)
        for i in range(len(self._shapes)):
            f.write(pack(">i", self._offsets[i] // 2))
            f.write(pack(">i", self._lengths[i]))

    def __dbfRecords(self):
        """Writes the dbf records."""
        f = self.__getFileObj(self.dbf)
        for record in self.records:
            if not self.fields[0][0].startswith("Deletion"):
                f.write(b(' ')) # deletion flag
            for (fieldName, fieldType, size, dec), value in zip(self.fields, record):
                fieldType = fieldType.upper()
                size = int(size)
                if fieldType.upper() == "N":
                    value = str(value).rjust(size)
                elif fieldType == 'L':
                    value = str(value)[0].upper()
                else:
                    value = str(value)[:size].ljust(size)
                assert len(value) == size
                value = b(value)
                f.write(value)

    def null(self):
        """Creates a null shape."""
        self._shapes.append(_Shape(NULL))

    def point(self, x, y, z=0, m=0):
        """Creates a point shape."""
        pointShape = _Shape(self.shapeType)
        pointShape.points.append([x, y, z, m])
        self._shapes.append(pointShape)

    def line(self, parts=[], shapeType=POLYLINE):
        """Creates a line shape. This method is just a convienience method
        which wraps 'poly()'.
        """
        self.poly(parts, shapeType, [])

    def poly(self, parts=[], shapeType=POLYGON, partTypes=[]):
        """Creates a shape that has multiple collections of points (parts)
        including lines, polygons, and even multipoint shapes. If no shape type
        is specified it defaults to 'polygon'. If no part types are specified
        (which they normally won't be) then all parts default to the shape type.
        """
        polyShape = _Shape(shapeType)
        polyShape.parts = []
        polyShape.points = []
        for part in parts:
            polyShape.parts.append(len(polyShape.points))
            for point in part:
                # Ensure point is list
                if not isinstance(point, list):
                    point = list(point)
                # Make sure point has z and m values
                while len(point) < 4:
                    point.append(0)
                polyShape.points.append(point)
        if polyShape.shapeType == 31:
            if not partTypes:
                for part in parts:
                    partTypes.append(polyShape.shapeType)
            polyShape.partTypes = partTypes
        self._shapes.append(polyShape)

    def field(self, name, fieldType="C", size="50", decimal=0):
        """Adds a dbf field descriptor to the shapefile."""
        self.fields.append((name, fieldType, size, decimal))

    def record(self, *recordList, **recordDict):
        """Creates a dbf attribute record. You can submit either a sequence of
        field values or keyword arguments of field names and values. Before
        adding records you must add fields for the record values using the
        fields() method. If the record values exceed the number of fields the
        extra ones won't be added. In the case of using keyword arguments to specify
        field/value pairs only fields matching the already registered fields
        will be added."""
        record = []
        fieldCount = len(self.fields)
        # Compensate for deletion flag
        if self.fields[0][0].startswith("Deletion"): fieldCount -= 1
        if recordList:
            [record.append(recordList[i]) for i in range(fieldCount)]
        elif recordDict:
            for field in self.fields:
                if field[0] in recordDict:
                    val = recordDict[field[0]]
                    if val:
                        record.append(val)
                    else:
                        record.append("")
        if record:
            self.records.append(record)

    def shape(self, i):
        return self._shapes[i]

    def shapes(self):
        """Return the current list of shapes."""
        return self._shapes

    def saveShp(self, target):
        """Save an shp file."""
        if not hasattr(target, "write"):
            target = os.path.splitext(target)[0] + '.shp'
        if not self.shapeType:
            self.shapeType = self._shapes[0].shapeType
        self.shp = self.__getFileObj(target)
        self.__shapefileHeader(self.shp, headerType='shp')
        self.__shpRecords()

    def saveShx(self, target):
        """Save an shx file."""
        if not hasattr(target, "write"):
            target = os.path.splitext(target)[0] + '.shx'
        if not self.shapeType:
            self.shapeType = self._shapes[0].shapeType
        self.shx = self.__getFileObj(target)
        self.__shapefileHeader(self.shx, headerType='shx')
        self.__shxRecords()

    def saveDbf(self, target):
        """Save a dbf file."""
        if not hasattr(target, "write"):
            target = os.path.splitext(target)[0] + '.dbf'
        self.dbf = self.__getFileObj(target)
        self.__dbfHeader()
        self.__dbfRecords()

    def save(self, target=None, shp=None, shx=None, dbf=None):
        """Save the shapefile data to three files or
        three file-like objects. SHP and DBF files can also
        be written exclusively using saveShp, saveShx, and saveDbf respectively."""
        # TODO: Create a unique filename for target if None.
        if shp:
            self.saveShp(shp)
        if shx:
            self.saveShx(shx)
        if dbf:
            self.saveDbf(dbf)
        elif target:
            self.saveShp(target)
            self.shp.close()
            self.saveShx(target)
            self.shx.close()
            self.saveDbf(target)
            self.dbf.close()

class Editor(Writer):
    def __init__(self, shapefile=None, shapeType=POINT, autoBalance=1):
        self.autoBalance = autoBalance
        if not shapefile:
            Writer.__init__(self, shapeType)
        elif is_string(shapefile):
            base = os.path.splitext(shapefile)[0]
            if os.path.isfile("%s.shp" % base):
                r = Reader(base)
                Writer.__init__(self, r.shapeType)
                self._shapes = r.shapes()
                self.fields = r.fields
                self.records = r.records()

    def select(self, expr):
        """Select one or more shapes (to be implemented)"""
        # TODO: Implement expressions to select shapes.
        pass

    def delete(self, shape=None, part=None, point=None):
        """Deletes the specified part of any shape by specifying a shape
        number, part number, or point number."""
        # shape, part, point
        if shape and part and point:
            del self._shapes[shape][part][point]
        # shape, part
        elif shape and part and not point:
            del self._shapes[shape][part]
        # shape
        elif shape and not part and not point:
            del self._shapes[shape]
        # point
        elif not shape and not part and point:
            for s in self._shapes:
                if s.shapeType == 1:
                    del self._shapes[point]
                else:
                    for part in s.parts:
                        del s[part][point]
        # part, point
        elif not shape and part and point:
            for s in self._shapes:
                del s[part][point]
        # part
        elif not shape and part and not point:
            for s in self._shapes:
                del s[part]

    def point(self, x=None, y=None, z=None, m=None, shape=None, part=None, point=None, addr=None):
        """Creates/updates a point shape. The arguments allows
        you to update a specific point by shape, part, point of any
        shape type."""
        # shape, part, point
        if shape and part and point:
            try: self._shapes[shape]
            except IndexError: self._shapes.append([])
            try: self._shapes[shape][part]
            except IndexError: self._shapes[shape].append([])
            try: self._shapes[shape][part][point]
            except IndexError: self._shapes[shape][part].append([])
            p = self._shapes[shape][part][point]
            if x: p[0] = x
            if y: p[1] = y
            if z: p[2] = z
            if m: p[3] = m
            self._shapes[shape][part][point] = p
        # shape, part
        elif shape and part and not point:
            try: self._shapes[shape]
            except IndexError: self._shapes.append([])
            try: self._shapes[shape][part]
            except IndexError: self._shapes[shape].append([])
            points = self._shapes[shape][part]
            for i in range(len(points)):
                p = points[i]
                if x: p[0] = x
                if y: p[1] = y
                if z: p[2] = z
                if m: p[3] = m
                self._shapes[shape][part][i] = p
        # shape
        elif shape and not part and not point:
            try: self._shapes[shape]
            except IndexError: self._shapes.append([])

        # point
        # part
        if addr:
            shape, part, point = addr
            self._shapes[shape][part][point] = [x, y, z, m]
        else:
            Writer.point(self, x, y, z, m)
        if self.autoBalance:
            self.balance()

    def validate(self):
        """An optional method to try and validate the shapefile
        as much as possible before writing it (not implemented)."""
        #TODO: Implement validation method
        pass

    def balance(self):
        """Adds a corresponding empty attribute or null geometry record depending
        on which type of record was created to make sure all three files
        are in synch."""
        if len(self.records) > len(self._shapes):
            self.null()
        elif len(self.records) < len(self._shapes):
            self.record()

    def __fieldNorm(self, fieldName):
        """Normalizes a dbf field name to fit within the spec and the
        expectations of certain ESRI software."""
        if len(fieldName) > 11: fieldName = fieldName[:11]
        fieldName = fieldName.upper()
        fieldName.replace(' ', '_')

# Begin Testing
def test():
    import doctest
    doctest.NORMALIZE_WHITESPACE = 1
    doctest.testfile("README.txt", verbose=1)

if __name__ == "__main__":
    """
    Doctests are contained in the module 'pyshp_usage.py'. This library was developed
    using Python 2.3. Python 2.4 and above have some excellent improvements in the built-in
    testing libraries but for now unit testing is done using what's available in
    2.3.
    """
    test()
import sys
import time
import array
#
# Constants for shape types
NULL = 0
POINT = 1
POLYLINE = 3
POLYGON = 5
MULTIPOINT = 8
POINTZ = 11
POLYLINEZ = 13
POLYGONZ = 15
MULTIPOINTZ = 18
POINTM = 21
POLYLINEM = 23
POLYGONM = 25
MULTIPOINTM = 28
MULTIPATCH = 31

PYTHON3 = sys.version_info[0] == 3

def b(v):
    if PYTHON3:
        if isinstance(v, str):
            # For python 3 encode str to bytes.
            return v.encode('utf-8')
        elif isinstance(v, bytes):
            # Already bytes.
            return v
        else:
            # Error.
            raise Exception('Unknown input type')
    else:
        # For python 2 assume str passed in and return str.
        return v

def u(v):
    if PYTHON3:
        if isinstance(v, bytes):
            # For python 3 decode bytes to str.
            return v.decode('utf-8')
        elif isinstance(v, str):
            # Already str.
            return v
        else:
            # Error.
            raise Exception('Unknown input type')
    else:
        # For python 2 assume str passed in and return str.
        return v

def is_string(v):
    if PYTHON3:
        return isinstance(v, str)
    else:
        return isinstance(v, basestring)

class _Array(array.array):
    """Converts python tuples to lits of the appropritate type.
    Used to unpack different shapefile header parts."""
    def __repr__(self):
        return str(self.tolist())

class _Shape:
    def __init__(self, shapeType=None):
        """Stores the geometry of the different shape types
        specified in the Shapefile spec. Shape types are
        usually point, polyline, or polygons. Every shape type
        except the "Null" type contains points at some level for
        example verticies in a polygon. If a shape type has
        multiple shapes containing points within a single
        geometry record then those shapes are called parts. Parts
        are designated by their starting index in geometry record's
        list of shapes."""
        self.shapeType = shapeType
        self.points = []

class _ShapeRecord:
    """A shape object of any type."""
    def __init__(self, shape=None, record=None):
        self.shape = shape
        self.record = record

class ShapefileException(Exception):
    """An exception to handle shapefile specific problems."""
    pass

class Reader:
    """Reads the three files of a shapefile as a unit or
    separately.  If one of the three files (.shp, .shx,
    .dbf) is missing no exception is thrown until you try
    to call a method that depends on that particular file.
    The .shx index file is used if available for efficiency
    but is not required to read the geometry from the .shp
    file. The "shapefile" argument in the constructor is the
    name of the file you want to open.

    You can instantiate a Reader without specifying a shapefile
    and then specify one later with the load() method.

    Only the shapefile headers are read upon loading. Content
    within each file is only accessed when required and as
    efficiently as possible. Shapefiles are usually not large
    but they can be.
    """
    def __init__(self, *args, **kwargs):
        self.shp = None
        self.shx = None
        self.dbf = None
        self.shapeName = "Not specified"
        self._offsets = []
        self.shpLength = None
        self.numRecords = None
        self.fields = []
        self.__dbfHdrLength = 0
        # See if a shapefile name was passed as an argument
        if len(args) > 0:
            if type(args[0]) is type("stringTest"):
                self.load(args[0])
                return
        if "shp" in kwargs.keys():
            if hasattr(kwargs["shp"], "read"):
                self.shp = kwargs["shp"]
                if hasattr(self.shp, "seek"):
                    self.shp.seek(0)
            if "shx" in kwargs.keys():
                if hasattr(kwargs["shx"], "read"):
                    self.shx = kwargs["shx"]
                    if hasattr(self.shx, "seek"):
                        self.shx.seek(0)
        if "dbf" in kwargs.keys():
            if hasattr(kwargs["dbf"], "read"):
                self.dbf = kwargs["dbf"]
                if hasattr(self.dbf, "seek"):
                    self.dbf.seek(0)
        if self.shp or self.dbf:        
            self.load()
        else:
            raise ShapefileException("Shapefile Reader requires a shapefile or file-like object.")

    def load(self, shapefile=None):
        """Opens a shapefile from a filename or file-like
        object. Normally this method would be called by the
        constructor with the file object or file name as an
        argument."""
        if shapefile:
            (shapeName, ext) = os.path.splitext(shapefile)
            self.shapeName = shapeName
            try:
                self.shp = open("%s.shp" % shapeName, "rb")
            except IOError:
                raise ShapefileException("Unable to open %s.shp" % shapeName)
            try:
                self.shx = open("%s.shx" % shapeName, "rb")
            except IOError:
                raise ShapefileException("Unable to open %s.shx" % shapeName)
            try:
                self.dbf = open("%s.dbf" % shapeName, "rb")
            except IOError:
                raise ShapefileException("Unable to open %s.dbf" % shapeName)
        if self.shp:
            self.__shpHeader()
        if self.dbf:
            self.__dbfHeader()

    def __getFileObj(self, f):
        """Checks to see if the requested shapefile file object is
        available. If not a ShapefileException is raised."""
        if not f:
            raise ShapefileException("Shapefile Reader requires a shapefile or file-like object.")
        if self.shp and self.shpLength is None:
            self.load()
        if self.dbf and len(self.fields) == 0:
            self.load()
        return f

    def __restrictIndex(self, i):
        """Provides list-like handling of a record index with a clearer
        error message if the index is out of bounds."""
        if self.numRecords:
            rmax = self.numRecords - 1
            if abs(i) > rmax:
                raise IndexError("Shape or Record index out of range.")
            if i < 0: i = range(self.numRecords)[i]
        return i

    def __shpHeader(self):
        """Reads the header information from a .shp or .shx file."""
        if not self.shp:
            raise ShapefileException("Shapefile Reader requires a shapefile or file-like object. (no shp file found")
        shp = self.shp
        # File length (16-bit word * 2 = bytes)
        shp.seek(24)
        self.shpLength = unpack(">i", shp.read(4))[0] * 2
        # Shape type
        shp.seek(32)
        self.shapeType= unpack("<i", shp.read(4))[0]
        # The shapefile's bounding box (lower left, upper right)
        self.bbox = _Array('d', unpack("<4d", shp.read(32)))
        # Elevation
        self.elevation = _Array('d', unpack("<2d", shp.read(16)))
        # Measure
        self.measure = _Array('d', unpack("<2d", shp.read(16)))

    def __shape(self):
        """Returns the header info and geometry for a single shape."""
        f = self.__getFileObj(self.shp)
        record = _Shape()
        nParts = nPoints = zmin = zmax = mmin = mmax = None
        (recNum, recLength) = unpack(">2i", f.read(8))
        shapeType = unpack("<i", f.read(4))[0]
        record.shapeType = shapeType
        # For Null shapes create an empty points list for consistency
        if shapeType == 0:
            record.points = []
        # All shape types capable of having a bounding box
        elif shapeType in (3,5,8,13,15,18,23,25,28,31):
            record.bbox = _Array('d', unpack("<4d", f.read(32)))
        # Shape types with parts
        if shapeType in (3,5,13,15,23,25,31):
            nParts = unpack("<i", f.read(4))[0]
        # Shape types with points
        if shapeType in (3,5,8,13,15,23,25,31):
            nPoints = unpack("<i", f.read(4))[0]
        # Read parts
        if nParts:
            record.parts = _Array('i', unpack("<%si" % nParts, f.read(nParts * 4)))
        # Read part types for Multipatch - 31
        if shapeType == 31:
            record.partTypes = _Array('i', unpack("<%si" % nParts, f.read(nParts * 4)))
        # Read points - produces a list of [x,y] values
        if nPoints:
            record.points = [_Array('d', unpack("<2d", f.read(16))) for p in range(nPoints)]
        # Read z extremes and values
        if shapeType in (13,15,18,31):
            (zmin, zmax) = unpack("<2d", f.read(16))
            record.z = _Array('d', unpack("<%sd" % nPoints, f.read(nPoints * 8)))
        # Read m extremes and values
        if shapeType in (13,15,18,23,25,28,31):
            (mmin, mmax) = unpack("<2d", f.read(16))
            # Measure values less than -10e38 are nodata values according to the spec
            record.m = []
            for m in _Array('d', unpack("%sd" % nPoints, f.read(nPoints * 8))):
                if m > -10e38:
                    record.m.append(m)
                else:
                    record.m.append(None)
        # Read a single point
        if shapeType in (1,11,21):
            record.points = [_Array('d', unpack("<2d", f.read(16)))]
        # Read a single Z value
        if shapeType == 11:
            record.z = unpack("<d", f.read(8))
        # Read a single M value
        if shapeType in (11,21):
            record.m = unpack("<d", f.read(8))
        return record

    def __shapeIndex(self, i=None):
        """Returns the offset in a .shp file for a shape based on information
        in the .shx index file."""
        shx = self.shx
        if not shx:
            return None
        if not self._offsets:
            # File length (16-bit word * 2 = bytes) - header length
            shx.seek(24)
            shxRecordLength = (unpack(">i", shx.read(4))[0] * 2) - 100
            numRecords = shxRecordLength // 8
            # Jump to the first record.
            shx.seek(100)
            for r in range(numRecords):
                # Offsets are 16-bit words just like the file length
                self._offsets.append(unpack(">i", shx.read(4))[0] * 2)
                shx.seek(shx.tell() + 4)
        if not i == None:
            return self._offsets[i]

    def shape(self, i=0):
        """Returns a shape object for a shape in the the geometry
        record file."""
        shp = self.__getFileObj(self.shp)
        i = self.__restrictIndex(i)
        offset = self.__shapeIndex(i)
        if not offset:
            # Shx index not available so use the full list.
            shapes = self.shapes()
            return shapes[i]
        shp.seek(offset)
        return self.__shape()

    def shapes(self):
        """Returns all shapes in a shapefile."""
        shp = self.__getFileObj(self.shp)
        shp.seek(100)
        shapes = []
        while shp.tell() < self.shpLength:
            shapes.append(self.__shape())
        return shapes

    def __dbfHeaderLength(self):
        """Retrieves the header length of a dbf file header."""
        if not self.__dbfHdrLength:
            if not self.dbf:
                raise ShapefileException("Shapefile Reader requires a shapefile or file-like object. (no dbf file found)")
            dbf = self.dbf
            (self.numRecords, self.__dbfHdrLength) = \
                    unpack("<xxxxLH22x", dbf.read(32))
        return self.__dbfHdrLength

    def __dbfHeader(self):
        """Reads a dbf header. Xbase-related code borrows heavily from ActiveState Python Cookbook Recipe 362715 by Raymond Hettinger"""
        if not self.dbf:
            raise ShapefileException("Shapefile Reader requires a shapefile or file-like object. (no dbf file found)")
        dbf = self.dbf
        headerLength = self.__dbfHeaderLength()
        numFields = (headerLength - 33) // 32
        for field in range(numFields):
            fieldDesc = list(unpack("<11sc4xBB14x", dbf.read(32)))
            name = 0
            idx = 0
            if b("\x00") in fieldDesc[name]:
                idx = fieldDesc[name].index(b("\x00"))
            else:
                idx = len(fieldDesc[name]) - 1
            fieldDesc[name] = fieldDesc[name][:idx]
            fieldDesc[name] = u(fieldDesc[name])
            fieldDesc[name] = fieldDesc[name].lstrip()
            fieldDesc[1] = u(fieldDesc[1])
            self.fields.append(fieldDesc)
        terminator = dbf.read(1)
        assert terminator == b("\r")
        self.fields.insert(0, ('DeletionFlag', 'C', 1, 0))

    def __recordFmt(self):
        """Calculates the size of a .shp geometry record."""
        if not self.numRecords:
            self.__dbfHeader()
        fmt = ''.join(['%ds' % fieldinfo[2] for fieldinfo in self.fields])
        fmtSize = calcsize(fmt)
        return (fmt, fmtSize)

    def __record(self):
        """Reads and returns a dbf record row as a list of values."""
        f = self.__getFileObj(self.dbf)
        recFmt = self.__recordFmt()
        recordContents = unpack(recFmt[0], f.read(recFmt[1]))
        if recordContents[0] != b(' '):
            # deleted record
            return None
        record = []
        for (name, typ, size, deci), value in zip(self.fields,
                                                                                                recordContents):
            if name == 'DeletionFlag':
                continue
            elif not value.strip():
                record.append(value)
                continue
            elif typ == "N":
                value = value.replace(b('\0'), b('')).strip()
                if value == b(''):
                    value = 0
                elif deci:
                    value = float(value)
                else:
                    value = int(value)
            elif typ == b('D'):
                try:
                    y, m, d = int(value[:4]), int(value[4:6]), int(value[6:8])
                    value = [y, m, d]
                except:
                    value = value.strip()
            elif typ == b('L'):
                value = (value in b('YyTt') and b('T')) or \
                                        (value in b('NnFf') and b('F')) or b('?')
            else:
                value = u(value)
                value = value.strip()
            record.append(value)
        return record

    def record(self, i=0):
        """Returns a specific dbf record based on the supplied index."""
        f = self.__getFileObj(self.dbf)
        if not self.numRecords:
            self.__dbfHeader()
        i = self.__restrictIndex(i)
        recSize = self.__recordFmt()[1]
        f.seek(0)
        f.seek(self.__dbfHeaderLength() + (i * recSize))
        return self.__record()

    def records(self):
        """Returns all records in a dbf file."""
        if not self.numRecords:
            self.__dbfHeader()
        records = []
        f = self.__getFileObj(self.dbf)
        f.seek(self.__dbfHeaderLength())
        for i in range(self.numRecords):
            r = self.__record()
            if r:
                records.append(r)
        return records

    def shapeRecord(self, i=0):
        """Returns a combination geometry and attribute record for the
        supplied record index."""
        i = self.__restrictIndex(i)
        return _ShapeRecord(shape=self.shape(i),
                                                        record=self.record(i))

    def shapeRecords(self):
        """Returns a list of combination geometry/attribute records for
        all records in a shapefile."""
        shapeRecords = []
        return [_ShapeRecord(shape=rec[0], record=rec[1]) \
                                for rec in zip(self.shapes(), self.records())]

class Writer:
    """Provides write support for ESRI Shapefiles."""
    def __init__(self, shapeType=None):
        self._shapes = []
        self.fields = []
        self.records = []
        self.shapeType = shapeType
        self.shp = None
        self.shx = None
        self.dbf = None
        # Geometry record offsets and lengths for writing shx file.
        self._offsets = []
        self._lengths = []
        # Use deletion flags in dbf? Default is false (0).
        self.deletionFlag = 0

    def __getFileObj(self, f):
        """Safety handler to verify file-like objects"""
        if not f:
            raise ShapefileException("No file-like object available.")
        elif hasattr(f, "write"):
            return f
        else:
            pth = os.path.split(f)[0]
            if pth and not os.path.exists(pth):
                os.makedirs(pth)
            return open(f, "wb")

    def __shpFileLength(self):
        """Calculates the file length of the shp file."""
        # Start with header length
        size = 100
        # Calculate size of all shapes
        for s in self._shapes:
            # Add in record header and shape type fields
            size += 12
            # nParts and nPoints do not apply to all shapes
            #if self.shapeType not in (0,1):
            #       nParts = len(s.parts)
            #       nPoints = len(s.points)
            if hasattr(s,'parts'):
                nParts = len(s.parts)
            if hasattr(s,'points'):
                nPoints = len(s.points)
            # All shape types capable of having a bounding box
            if self.shapeType in (3,5,8,13,15,18,23,25,28,31):
                size += 32
            # Shape types with parts
            if self.shapeType in (3,5,13,15,23,25,31):
                # Parts count
                size += 4
                # Parts index array
                size += nParts * 4
            # Shape types with points
            if self.shapeType in (3,5,8,13,15,23,25,31):
                # Points count
                size += 4
                # Points array
                size += 16 * nPoints
            # Calc size of part types for Multipatch (31)
            if self.shapeType == 31:
                size += nParts * 4
            # Calc z extremes and values
            if self.shapeType in (13,15,18,31):
                # z extremes
                size += 16
                # z array
                size += 8 * nPoints
            # Calc m extremes and values
            if self.shapeType in (23,25,31):
                # m extremes
                size += 16
                # m array
                size += 8 * nPoints
            # Calc a single point
            if self.shapeType in (1,11,21):
                size += 16
            # Calc a single Z value
            if self.shapeType == 11:
                size += 8
            # Calc a single M value
            if self.shapeType in (11,21):
                size += 8
        # Calculate size as 16-bit words
        size //= 2
        return size

    def __bbox(self, shapes, shapeTypes=[]):
        x = []
        y = []
        for s in shapes:
            shapeType = self.shapeType
            if shapeTypes:
                shapeType = shapeTypes[shapes.index(s)]
            px, py = list(zip(*s.points))[:2]
            x.extend(px)
            y.extend(py)
        return [min(x), min(y), max(x), max(y)]

    def __zbox(self, shapes, shapeTypes=[]):
        z = []
        for s in shapes:
            try:
                for p in s.points:
                    z.append(p[2])
            except IndexError:
                pass
        if not z: z.append(0)
        return [min(z), max(z)]

    def __mbox(self, shapes, shapeTypes=[]):
        m = [0]
        for s in shapes:
            try:
                for p in s.points:
                    m.append(p[3])
            except IndexError:
                pass
        return [min(m), max(m)]

    def bbox(self):
        """Returns the current bounding box for the shapefile which is
        the lower-left and upper-right corners. It does not contain the
        elevation or measure extremes."""
        return self.__bbox(self._shapes)

    def zbox(self):
        """Returns the current z extremes for the shapefile."""
        return self.__zbox(self._shapes)

    def mbox(self):
        """Returns the current m extremes for the shapefile."""
        return self.__mbox(self._shapes)

    def __shapefileHeader(self, fileObj, headerType='shp'):
        """Writes the specified header type to the specified file-like object.
        Several of the shapefile formats are so similar that a single generic
        method to read or write them is warranted."""
        f = self.__getFileObj(fileObj)
        f.seek(0)
        # File code, Unused bytes
        f.write(pack(">6i", 9994,0,0,0,0,0))
        # File length (Bytes / 2 = 16-bit words)
        if headerType == 'shp':
            f.write(pack(">i", self.__shpFileLength()))
        elif headerType == 'shx':
            f.write(pack('>i', ((100 + (len(self._shapes) * 8)) // 2)))
        # Version, Shape type
        f.write(pack("<2i", 1000, self.shapeType))
        # The shapefile's bounding box (lower left, upper right)
        if self.shapeType != 0:
            try:
                f.write(pack("<4d", *self.bbox()))
            except error:
                raise ShapefileException("Failed to write shapefile bounding box. Floats required.")
        else:
            f.write(pack("<4d", 0,0,0,0))
        # Elevation
        z = self.zbox()
        # Measure
        m = self.mbox()
        try:
            f.write(pack("<4d", z[0], z[1], m[0], m[1]))
        except error:
            raise ShapefileException("Failed to write shapefile elevation and measure values. Floats required.")

    def __dbfHeader(self):
        """Writes the dbf header and field descriptors."""
        f = self.__getFileObj(self.dbf)
        f.seek(0)
        version = 3
        year, month, day = time.localtime()[:3]
        year -= 1900
        # Remove deletion flag placeholder from fields
        for field in self.fields:
            if field[0].startswith("Deletion"):
                self.fields.remove(field)
        numRecs = len(self.records)
        numFields = len(self.fields)
        headerLength = numFields * 32 + 33
        recordLength = sum([int(field[2]) for field in self.fields]) + 1
        header = pack('<BBBBLHH20x', version, year, month, day, numRecs,
                headerLength, recordLength)
        f.write(header)
        # Field descriptors
        for field in self.fields:
            name, fieldType, size, decimal = field
            name = b(name)
            name = name.replace(b(' '), b('_'))
            name = name.ljust(11).replace(b(' '), b('\x00'))
            fieldType = b(fieldType)
            size = int(size)
            fld = pack('<11sc4xBB14x', name, fieldType, size, decimal)
            f.write(fld)
        # Terminator
        f.write(b('\r'))

    def __shpRecords(self):
        """Write the shp records"""
        f = self.__getFileObj(self.shp)
        f.seek(100)
        recNum = 1
        for s in self._shapes:
            self._offsets.append(f.tell())
            # Record number, Content length place holder
            f.write(pack(">2i", recNum, 0))
            recNum += 1
            start = f.tell()
            # Shape Type
            f.write(pack("<i", s.shapeType))
            # All shape types capable of having a bounding box
            if s.shapeType in (3,5,8,13,15,18,23,25,28,31):
                try:
                    f.write(pack("<4d", *self.__bbox([s])))
                except error:
                    raise ShapefileException("Falied to write bounding box for record %s. Expected floats." % recNum)
            # Shape types with parts
            if s.shapeType in (3,5,13,15,23,25,31):
                # Number of parts
                f.write(pack("<i", len(s.parts)))
            # Shape types with multiple points per record
            if s.shapeType in (3,5,8,13,15,23,25,31):
                # Number of points
                f.write(pack("<i", len(s.points)))
            # Write part indexes
            if s.shapeType in (3,5,13,15,23,25,31):
                for p in s.parts:
                    f.write(pack("<i", p))
            # Part types for Multipatch (31)
            if s.shapeType == 31:
                for pt in s.partTypes:
                    f.write(pack("<i", pt))
            # Write points for multiple-point records
            if s.shapeType in (3,5,8,13,15,23,25,31):
                try:
                    [f.write(pack("<2d", *p[:2])) for p in s.points]
                except error:
                    raise ShapefileException("Failed to write points for record %s. Expected floats." % recNum)
            # Write z extremes and values
            if s.shapeType in (13,15,18,31):
                try:
                    f.write(pack("<2d", *self.__zbox([s])))
                except error:
                    raise ShapefileException("Failed to write elevation extremes for record %s. Expected floats." % recNum)
                try:
                    [f.write(pack("<d", p[2])) for p in s.points]
                except error:
                    raise ShapefileException("Failed to write elevation values for record %s. Expected floats." % recNum)
            # Write m extremes and values
            if s.shapeType in (23,25,31):
                try:
                    f.write(pack("<2d", *self.__mbox([s])))
                except error:
                    raise ShapefileException("Failed to write measure extremes for record %s. Expected floats" % recNum)
                try:
                    [f.write(pack("<d", p[3])) for p in s.points]
                except error:
                    raise ShapefileException("Failed to write measure values for record %s. Expected floats" % recNum)
            # Write a single point
            if s.shapeType in (1,11,21):
                try:
                    f.write(pack("<2d", s.points[0][0], s.points[0][1]))
                except error:
                    raise ShapefileException("Failed to write point for record %s. Expected floats." % recNum)
            # Write a single Z value
            if s.shapeType == 11:
                try:
                    f.write(pack("<1d", s.points[0][2]))
                except error:
                    raise ShapefileException("Failed to write elevation value for record %s. Expected floats." % recNum)
            # Write a single M value
            if s.shapeType in (11,21):
                try:
                    f.write(pack("<1d", s.points[0][3]))
                except error:
                    raise ShapefileException("Failed to write measure value for record %s. Expected floats." % recNum)
            # Finalize record length as 16-bit words
            finish = f.tell()
            length = (finish - start) // 2
            self._lengths.append(length)
            # start - 4 bytes is the content length field
            f.seek(start-4)
            f.write(pack(">i", length))
            f.seek(finish)

    def __shxRecords(self):
        """Writes the shx records."""
        f = self.__getFileObj(self.shx)
        f.seek(100)
        for i in range(len(self._shapes)):
            f.write(pack(">i", self._offsets[i] // 2))
            f.write(pack(">i", self._lengths[i]))

    def __dbfRecords(self):
        """Writes the dbf records."""
        f = self.__getFileObj(self.dbf)
        for record in self.records:
            if not self.fields[0][0].startswith("Deletion"):
                f.write(b(' ')) # deletion flag
            for (fieldName, fieldType, size, dec), value in zip(self.fields, record):
                fieldType = fieldType.upper()
                size = int(size)
                if fieldType.upper() == "N":
                    value = str(value).rjust(size)
                elif fieldType == 'L':
                    value = str(value)[0].upper()
                else:
                    value = str(value)[:size].ljust(size)
                assert len(value) == size
                value = b(value)
                f.write(value)

    def null(self):
        """Creates a null shape."""
        self._shapes.append(_Shape(NULL))

    def point(self, x, y, z=0, m=0):
        """Creates a point shape."""
        pointShape = _Shape(self.shapeType)
        pointShape.points.append([x, y, z, m])
        self._shapes.append(pointShape)

    def line(self, parts=[], shapeType=POLYLINE):
        """Creates a line shape. This method is just a convienience method
        which wraps 'poly()'.
        """
        self.poly(parts, shapeType, [])

    def poly(self, parts=[], shapeType=POLYGON, partTypes=[]):
        """Creates a shape that has multiple collections of points (parts)
        including lines, polygons, and even multipoint shapes. If no shape type
        is specified it defaults to 'polygon'. If no part types are specified
        (which they normally won't be) then all parts default to the shape type.
        """
        polyShape = _Shape(shapeType)
        polyShape.parts = []
        polyShape.points = []
        for part in parts:
            polyShape.parts.append(len(polyShape.points))
            for point in part:
                # Ensure point is list
                if not isinstance(point, list):
                    point = list(point)
                # Make sure point has z and m values
                while len(point) < 4:
                    point.append(0)
                polyShape.points.append(point)
        if polyShape.shapeType == 31:
            if not partTypes:
                for part in parts:
                    partTypes.append(polyShape.shapeType)
            polyShape.partTypes = partTypes
        self._shapes.append(polyShape)

    def field(self, name, fieldType="C", size="50", decimal=0):
        """Adds a dbf field descriptor to the shapefile."""
        self.fields.append((name, fieldType, size, decimal))

    def record(self, *recordList, **recordDict):
        """Creates a dbf attribute record. You can submit either a sequence of
        field values or keyword arguments of field names and values. Before
        adding records you must add fields for the record values using the
        fields() method. If the record values exceed the number of fields the
        extra ones won't be added. In the case of using keyword arguments to specify
        field/value pairs only fields matching the already registered fields
        will be added."""
        record = []
        fieldCount = len(self.fields)
        # Compensate for deletion flag
        if self.fields[0][0].startswith("Deletion"): fieldCount -= 1
        if recordList:
            [record.append(recordList[i]) for i in range(fieldCount)]
        elif recordDict:
            for field in self.fields:
                if field[0] in recordDict:
                    val = recordDict[field[0]]
                    if val:
                        record.append(val)
                    else:
                        record.append("")
        if record:
            self.records.append(record)

    def shape(self, i):
        return self._shapes[i]

    def shapes(self):
        """Return the current list of shapes."""
        return self._shapes

    def saveShp(self, target):
        """Save an shp file."""
        if not hasattr(target, "write"):
            target = os.path.splitext(target)[0] + '.shp'
        if not self.shapeType:
            self.shapeType = self._shapes[0].shapeType
        self.shp = self.__getFileObj(target)
        self.__shapefileHeader(self.shp, headerType='shp')
        self.__shpRecords()

    def saveShx(self, target):
        """Save an shx file."""
        if not hasattr(target, "write"):
            target = os.path.splitext(target)[0] + '.shx'
        if not self.shapeType:
            self.shapeType = self._shapes[0].shapeType
        self.shx = self.__getFileObj(target)
        self.__shapefileHeader(self.shx, headerType='shx')
        self.__shxRecords()

    def saveDbf(self, target):
        """Save a dbf file."""
        if not hasattr(target, "write"):
            target = os.path.splitext(target)[0] + '.dbf'
        self.dbf = self.__getFileObj(target)
        self.__dbfHeader()
        self.__dbfRecords()

    def save(self, target=None, shp=None, shx=None, dbf=None):
        """Save the shapefile data to three files or
        three file-like objects. SHP and DBF files can also
        be written exclusively using saveShp, saveShx, and saveDbf respectively."""
        # TODO: Create a unique filename for target if None.
        if shp:
            self.saveShp(shp)
        if shx:
            self.saveShx(shx)
        if dbf:
            self.saveDbf(dbf)
        elif target:
            self.saveShp(target)
            self.shp.close()
            self.saveShx(target)
            self.shx.close()
            self.saveDbf(target)
            self.dbf.close()

class Editor(Writer):
    def __init__(self, shapefile=None, shapeType=POINT, autoBalance=1):
        self.autoBalance = autoBalance
        if not shapefile:
            Writer.__init__(self, shapeType)
        elif is_string(shapefile):
            base = os.path.splitext(shapefile)[0]
            if os.path.isfile("%s.shp" % base):
                r = Reader(base)
                Writer.__init__(self, r.shapeType)
                self._shapes = r.shapes()
                self.fields = r.fields
                self.records = r.records()

    def select(self, expr):
        """Select one or more shapes (to be implemented)"""
        # TODO: Implement expressions to select shapes.
        pass

    def delete(self, shape=None, part=None, point=None):
        """Deletes the specified part of any shape by specifying a shape
        number, part number, or point number."""
        # shape, part, point
        if shape and part and point:
            del self._shapes[shape][part][point]
        # shape, part
        elif shape and part and not point:
            del self._shapes[shape][part]
        # shape
        elif shape and not part and not point:
            del self._shapes[shape]
        # point
        elif not shape and not part and point:
            for s in self._shapes:
                if s.shapeType == 1:
                    del self._shapes[point]
                else:
                    for part in s.parts:
                        del s[part][point]
        # part, point
        elif not shape and part and point:
            for s in self._shapes:
                del s[part][point]
        # part
        elif not shape and part and not point:
            for s in self._shapes:
                del s[part]

    def point(self, x=None, y=None, z=None, m=None, shape=None, part=None, point=None, addr=None):
        """Creates/updates a point shape. The arguments allows
        you to update a specific point by shape, part, point of any
        shape type."""
        # shape, part, point
        if shape and part and point:
            try: self._shapes[shape]
            except IndexError: self._shapes.append([])
            try: self._shapes[shape][part]
            except IndexError: self._shapes[shape].append([])
            try: self._shapes[shape][part][point]
            except IndexError: self._shapes[shape][part].append([])
            p = self._shapes[shape][part][point]
            if x: p[0] = x
            if y: p[1] = y
            if z: p[2] = z
            if m: p[3] = m
            self._shapes[shape][part][point] = p
        # shape, part
        elif shape and part and not point:
            try: self._shapes[shape]
            except IndexError: self._shapes.append([])
            try: self._shapes[shape][part]
            except IndexError: self._shapes[shape].append([])
            points = self._shapes[shape][part]
            for i in range(len(points)):
                p = points[i]
                if x: p[0] = x
                if y: p[1] = y
                if z: p[2] = z
                if m: p[3] = m
                self._shapes[shape][part][i] = p
        # shape
        elif shape and not part and not point:
            try: self._shapes[shape]
            except IndexError: self._shapes.append([])

        # point
        # part
        if addr:
            shape, part, point = addr
            self._shapes[shape][part][point] = [x, y, z, m]
        else:
            Writer.point(self, x, y, z, m)
        if self.autoBalance:
            self.balance()

    def validate(self):
        """An optional method to try and validate the shapefile
        as much as possible before writing it (not implemented)."""
        #TODO: Implement validation method
        pass

    def balance(self):
        """Adds a corresponding empty attribute or null geometry record depending
        on which type of record was created to make sure all three files
        are in synch."""
        if len(self.records) > len(self._shapes):
            self.null()
        elif len(self.records) < len(self._shapes):
            self.record()

    def __fieldNorm(self, fieldName):
        """Normalizes a dbf field name to fit within the spec and the
        expectations of certain ESRI software."""
        if len(fieldName) > 11: fieldName = fieldName[:11]
        fieldName = fieldName.upper()
        fieldName.replace(' ', '_')

# Begin Testing
def test():
    import doctest
    doctest.NORMALIZE_WHITESPACE = 1
    doctest.testfile("README.txt", verbose=1)

if __name__ == "__main__":
    """
    Doctests are contained in the module 'pyshp_usage.py'. This library was developed
    using Python 2.3. Python 2.4 and above have some excellent improvements in the built-in
    testing libraries but for now unit testing is done using what's available in
    2.3.
    """
    test()
########NEW FILE########
__FILENAME__ = handlers
#!/usr/bin/python

# BSD Licensed, Copyright (c) 2006-2008 MetaCarta, Inc.

import sys, os, traceback
import cgi as cgimod
from web_request.response import Response
import urllib
import StringIO


class ApplicationException(Exception): 
    """Any application exception should be subclassed from here. """
    status_code = 500
    status_message = "Error"
    def get_error(self):
        """Returns an HTTP Header line: a la '500 Error'""" 
        return "%s %s" % (self.status_code, self.status_message)

def binary_print(binary_data):
    """This function is designed to work around the fact that Python
       in Windows does not handle binary output correctly. This function
       will set the output to binary, and then write to stdout directly
       rather than using print."""
    try:
        import msvcrt
        msvcrt.setmode(sys.__stdout__.fileno(), os.O_BINARY)
    except:
        # No need to do anything if we can't import msvcrt.  
        pass
    sys.stdout.write(binary_data)    

def mod_python (dispatch_function, apache_request):
    """mod_python handler."""    
    from mod_python import apache, util
    
    try:
        if apache_request.headers_in.has_key("X-Forwarded-Host"):
            base_path = "http://" + apache_request.headers_in["X-Forwarded-Host"]
        else:
            base_path = "http://" + apache_request.headers_in["Host"]
            
        base_path += apache_request.uri[:-len(apache_request.path_info)]
        accepts = "" 
        if apache_request.headers_in.has_key("Accept"):
            accepts = apache_request.headers_in["Accept"]
        elif apache_request.headers_in.has_key("Content-Type"):
            accepts = apache_request.headers_in["Content-Type"]
        
        post_data = apache_request.read()
        request_method = apache_request.method

        params = {}
        if request_method != "POST":
            fields = util.FieldStorage(apache_request) 
            for key in fields.keys():
                params[key.lower()] = fields[key] 
         #if post_data:
             #for key, value in cgimod.parse_qsl(post_data, keep_blank_values=True):
                 #params[key.lower()] = value
        returned_data = dispatch_function( 
          base_path = base_path, 
          path_info = apache_request.path_info, 
          params = params, 
          request_method = request_method, 
          post_data = post_data, 
          accepts = accepts )
        
        if isinstance(returned_data, list) or isinstance(returned_data, tuple): 
            format, data = returned_data[0:2]
            if len(returned_data) == 3:
                for key, value in returned_data[2].items():
                    apache_request.headers_out[key] = value

            apache_request.content_type = format
            apache_request.send_http_header()
            apache_request.write(data)
        else:
            obj = returned_data
            if obj.extra_headers:
                for key, value in obj.extra_headers.items():
                    apache_request.headers_out[key] = value

            apache_request.status = obj.status_code
            apache_request.content_type = obj.content_type
            apache_request.send_http_header()
            apache_request.write(obj.getData())

    except ApplicationException, error:
        apache_request.content_type = "text/plain"
        apache_request.status = error.status_code 
        apache_request.send_http_header()
        apache_request.write("An error occurred: %s\n" % (str(error)))
    except Exception, error:
        apache_request.content_type = "text/plain"
        apache_request.status = apache.HTTP_INTERNAL_SERVER_ERROR
        apache_request.send_http_header()
        apache_request.write("An error occurred: %s\n%s\n" % (
            str(error), 
            "".join(traceback.format_tb(sys.exc_traceback))))
    
    return apache.OK

def wsgi (dispatch_function, environ, start_response):
    """handler for wsgiref simple_server"""
    try:
        path_info = base_path = ""

        if "PATH_INFO" in environ: 
            path_info = environ["PATH_INFO"]

        if "HTTP_X_FORWARDED_HOST" in environ:
            base_path      = "http://" + environ["HTTP_X_FORWARDED_HOST"]
        elif "HTTP_HOST" in environ:
            base_path      = "http://" + environ["HTTP_HOST"]

        base_path += environ["SCRIPT_NAME"]
        
        accepts = None 
        if environ.has_key("CONTENT_TYPE"):
            accepts = environ['CONTENT_TYPE']
        else:
            accepts = environ.get('HTTP_ACCEPT', '')

        request_method = environ["REQUEST_METHOD"]
        
        params = {}
        post_data = None
    
        if environ.has_key('CONTENT_LENGTH') and environ['CONTENT_LENGTH']:
            post_data = environ['wsgi.input'].read(int(environ['CONTENT_LENGTH']))
            
            #if post_data:
            #    for key, value in cgimod.parse_qsl(post_data, keep_blank_values=True):
            #        params[key.lower()] = value                
    
        if environ.has_key('QUERY_STRING'):
            for key, value in cgimod.parse_qsl(environ['QUERY_STRING'], keep_blank_values=True):
                params[key.lower()] = value
        
        returned_data = dispatch_function( 
          base_path = base_path, 
          path_info = path_info, 
          params = params, 
          request_method = request_method, 
          post_data = post_data, 
          accepts = accepts )
        
        if isinstance(returned_data, list) or isinstance(returned_data, tuple): 

            format, data = returned_data[0:2]
            headers = {'Content-Type': format}
            if len(returned_data) == 3:
                headers.update(returned_data[2])
                  
            start_response("200 OK", headers.items())
            return [str(data)]
        else:
            # This is a a web_request.Response.Response object
            headers = {'Content-Type': returned_data.content_type}
            if returned_data.extra_headers:
                headers.update(returned_data.extra_headers)
            start_response("%s Message" % returned_data.status_code,
                           headers.items())
            
            return [returned_data.getData()]


    except ApplicationException, error:
        start_response(error.get_error(), [('Content-Type','text/plain')])
        return ["An error occurred: %s" % (str(error))]
    except Exception, error:
        start_response("500 Internal Server Error", [('Content-Type','text/plain')])
        return ["An error occurred: %s\n%s\n" % (
            str(error), 
            "".join(traceback.format_tb(sys.exc_traceback)))]

def cgi (dispatch_function):
    """cgi handler""" 

    try:
        accepts = ""
        if "CONTENT_TYPE" in os.environ:
            accepts = os.environ['CONTENT_TYPE']
        elif "HTTP_ACCEPT" in os.environ:
            accepts = os.environ['HTTP_ACCEPT']
        
        request_method = os.environ["REQUEST_METHOD"]

        post_data = None 
        params = {}
        if request_method != "GET" and request_method != "DELETE":
            post_data = sys.stdin.read()
            
            #if post_data:
            #    for key, value in cgimod.parse_qsl(post_data, keep_blank_values=True):
            #        params[key.lower()] = value
            
            fields = cgimod.FieldStorage()
            if fields <> None:
                for key, value in cgimod.parse_qsl(fields.qs_on_post, keep_blank_values=True):
                    params[key.lower()] = value
                
        else:
            fields = cgimod.FieldStorage()
            try:
                for key in fields.keys(): 
                    params[key.lower()] = urllib.unquote(fields[key].value)
            except TypeError:
                pass
        
        path_info = base_path = ""

        if "PATH_INFO" in os.environ: 
            path_info = os.environ["PATH_INFO"]

        if "HTTP_X_FORWARDED_HOST" in os.environ:
            base_path      = "http://" + os.environ["HTTP_X_FORWARDED_HOST"]
        elif "HTTP_HOST" in os.environ:
            base_path      = "http://" + os.environ["HTTP_HOST"]

        base_path += os.environ["SCRIPT_NAME"]
        
        returned_data = dispatch_function( 
          base_path = base_path, 
          path_info = path_info, 
          params = params, 
          request_method = request_method, 
          post_data = post_data, 
          accepts = accepts )
        
        if isinstance(returned_data, list) or isinstance(returned_data, tuple): 
            format, data = returned_data[0:2]
            
            if len(returned_data) == 3:
                for (key, value) in returned_data[2].items():
                    print "%s: %s" % (key, value)

            print "Content-type: %s\n" % format

            if sys.platform == "win32":
                binary_print(data)
            else:    
                print data 
        
        else:    
            # Returned object is a 'response'
            obj = returned_data
            if obj.extra_headers:
                for (key, value) in obj.extra_headers.items(): 
                    print "%s: %s" % (key, value)

            print "Content-type: %s\n" % obj.content_type

            if sys.platform == "win32":
                binary_print(obj.getData())
            else:    
                print obj.getData()
    
    except ApplicationException, error:
        print "Cache-Control: max-age=10, must-revalidate" # make the client reload        
        print "Content-type: text/plain\n"
        print "An error occurred: %s\n" % (str(error))
    except Exception, error:
        print "Cache-Control: max-age=10, must-revalidate" # make the client reload        
        print "Content-type: text/plain\n"
        print "An error occurred: %s\n%s\n" % (
            str(error), 
            "".join(traceback.format_tb(sys.exc_traceback)))
        print params    


########NEW FILE########
__FILENAME__ = response
import StringIO

class Response(object): 
    status_code = 200
    extra_headers = None
    content_type = "text/plain"
    data = ""
    encoding = 'utf-8'
    def __init__(self, data="", content_type=None, headers = None, status_code=None, encoding='utf-8'):
        self.data = data
        self.content_type = content_type
        self.extra_headers = headers
        self.status_code = status_code
        self.encoding = encoding
    
    def getData(self):
        if isinstance(self.data, StringIO.StringIO):
            return self.data.getvalue()
        if len(self.encoding) > 0:
            return self.data.encode(self.encoding)
        else:
            return str(self.data)
########NEW FILE########
__FILENAME__ = workspace_http_server
#!/usr/bin/python

"""A simple, standalone web server that serves FeatureServer requests."""

__author__  = "MetaCarta"
__version__ = "FeatureServer $Id: featureserver_http_server.py 564 2008-05-24 14:32:18Z crschmidt $"
__license__ = "Clear BSD"
__copyright__ = "2006-2008 MetaCarta"

import mimetypes, os
from optparse import OptionParser
from FeatureServer.Server import wsgi_app_workspace

local_path_location = None

def local_app(environ, start_response):
    if environ['PATH_INFO'].startswith("/static/"):
        global local_path_location
        path = environ['PATH_INFO'].replace("/static/","")
        path.lstrip("/") 
        mime =  mimetypes.guess_type(path)
        try:
            f = open(os.path.join(local_path_location, path))
            start_response("200 OK", [("Content-Type",mime[0])])
            return [f.read()]
        except Exception, E:
            start_response("404 Not Found", [("Content-Type","text/plain")])
            return ["Not found: %s" % E]
            
    return wsgi_app_workspace(environ, start_response)

def run(port=8081, thread=False, local_path=""):
    from wsgiref import simple_server
    if thread:
        from SocketServer import ThreadingMixIn
        class myServer(ThreadingMixIn, simple_server.WSGIServer):
            pass 
    else:
        class myServer(simple_server.WSGIServer):
            pass

    httpd = myServer(('',port), simple_server.WSGIRequestHandler,)
    if local_path:
        global local_path_location
        local_path_location = local_path
        httpd.set_app(local_app)
    else:
        httpd.set_app(wsgi_app_workspace)
    
    try:
        print "Listening on port %s" % port
        httpd.serve_forever()
    except KeyboardInterrupt:
        print "Shutting down."

if __name__ == '__main__':
    parser = OptionParser(version=__version__, description=__doc__)
    parser.add_option("-p", "--port", 
        help="port to run webserver on. Default is 8080", 
        dest="port", 
        action='store', 
        type="int", 
        default=8080)
    parser.add_option("-t", help="enable threading in HTTP Server.", dest="thread", action="store_true", default=False)   
    parser.add_option("-l", help="serve files from local disk", dest="local_path")

    (options, args) = parser.parse_args()
    run(options.port, options.thread, options.local_path)



########NEW FILE########
