## 0.24 / March 24th, 2014 ###
- cache compiled code by hash of generated C source
- tuple slicing
- fixed (or disabled) unreliable optimizations
- casting between array types using map over elements

### 0.23 / November 21st, 2013 ###

- Generalized StrideSpecialization to ValueSpecialization 
- Significantly decreased overhead of calling into Parakeet (though still ~500x slower than a normal Python call)

### 0.22 / November 20th, 2013 ###

- Changed NumPy calls to use newer API, cuts down on number of compile warnings
- If compilation fails, retry using distutils, may help some people on Windows

### 0.21 / November 19th, 2013 ###

- Got rid of testing dependency on SciPy
- Deleted unused and unfinished optimizations
- Small misc. bugs 

### 0.20 / November 19th, 2013 ###

The last release added experimental CUDA support but the performance was terrible. This release includes lots of tweaks and optimizations necessary for getting beneficial speedups on the GPU. However, the default backend remains OpenMP since some program constructs will not work on the GPU and the nvcc compile times are unacceptably slow.

- Expanded and generalized fusion optimization
- Filled in missing methods from shape inference
- Using ShapeElimination on every function (repurposes the shape inference results as a symbolic execution optimization)
- Fixed lots of small bugs in other optimizations exposed by ShapeElimination
- Shaved off small amount of compile time by moving away from Node pseudo-ASTs to regular Python constructors
- Hackishly added int24 just as a sentinel for default values in reductions that need to cast up to int32 from bool, int8, int16.
- Eliminate redundant & constant array operator arguments with SpecializeFnArgs

### 0.19 / November 4th, 2013 ###

- Added experimental CUDA backend (use by passing _backend='cuda' to functions wrapped by @jit)

### 0.18 / October 30th, 2013 ###

- Added OpenMP backend (runs most map-like computations across multiple threads)
- Stack-allocate representations for all structured types in C
- Disabled Flattening -- tricky transform needs careful audit
- Debugged and enabled CopyElimination
- Fixed negative step in slices 
- Added RLock around AST translation to play nice with Python threads (thanks Russell Power)
- Fixed link argument order for building on cygwin in Windows (thanks Yves-RÃ©mi Van Eycke)

### 0.17 / October 9th, 2013 ###

- Added support for binding multiple variables in a for loop (i.e. "for (x,(y,z)) in enumerate(zip(ys,zs)):")
- More array constructors support 'dtype' argument 
- macros can now generate wrapper functions with keyword arguments 
- lib_helpers._get_type can pull element types out of a wider range of values 
- Added more unit tests from Python benchmarks 
- Added option to manually specify compiler in c_backend.config.compiler_path
- Slightly better support for negative indexing but negative step sizes are still mostly broken 
 
### 0.16.2 / October 1st, 2013 ###

- Moved version info into submodule so setup.py can run without full dependencies (thanks rjpower). 
- Fixed support for references to global arrays.
- Make C backend respect runtime changes to config flags. 
- Got rid of unncessary linking against libpython. 

### 0.16.1 / September 30th, 2013 ###

- Fixed bugs in C backend and a several optimizatons.
- Only print stderr if C backend fails to compile.  

### 0.16 / September 27th, 2013 ###

- Added flattening transformation which gets rid of all structures except scalars and pointers.
- Created new C backend which compiles with either gcc or clang.
- Disabled some of the more powerful optimizations (i.e. scalar replacement) which might introduce bugs. 
- Revamped the optimization pipeline to avoid running duplicate transformations and allow for better logging. 
- "Indexify" all adverbs by turning them into ParFor/IndexReduce/IndexScan. 


Parakeet
====

Parakeet is a runtime accelerator for an array-oriented subset of Python. 
If you're doing a lot of number crunching in Python, 
Parakeet may be able to significantly speed up your code. 


To accelerate a function, wrap it with Parakeet's **@jit** decorator:

```python 
import numpy as np 
from parakeet import jit 

alpha = 0.5
beta = 0.3
x = np.array([1,2,3])
y = np.tanh(x * alpha) + beta
   
@jit
def fast(x, alpha = 0.5, beta = 0.3):
  return np.tanh(x * alpha) + beta 
   
@jit 
def loopy(x, alpha = 0.5, beta = 0.3):
  y = np.empty_like(x, dtype = float)
  for i in xrange(len(x)):
    y[i] = np.tanh(x[i] * alpha) + beta
  return y
     
@jit
def comprehension(x, alpha = 0.5, beta = 0.3):
  return np.array([np.tanh(xi*alpha) + beta for xi in x])
  
assert np.allclose(fast(x), y)
assert np.allclose(loopy(x), y)
assert np.allclose(comprehension(x), y)

```



Install
====
You should be able to install Parakeet from its [PyPI package](https://pypi.python.org/pypi/parakeet/) by running:

    pip install parakeet


Dependencies
====

Parakeet is written for Python 2.7 (sorry internet) and depends on:

* [dsltools](https://github.com/iskandr/dsltools)
* [nose](https://nose.readthedocs.org/en/latest/) for unit tests
* [NumPy](http://www.scipy.org/install.html)
* [appdirs](https://pypi.python.org/pypi/appdirs/)

The default backend (which uses OpenMP) requires `gcc` 4.4+. 

*Windows*: If you have a 32-bit Windows install, your compiler should come from [Cygwin](http://cygwin.com/install.html) or [MinGW](http://www.mingw.org/). Getting Parakeet working on 64-bit Windows is non-trivial and seems to require [colossal hacks](http://eli.thegreenplace.net/2008/06/28/compiling-python-extensions-with-distutils-and-mingw/).

*Mac OS X*: By default, your machine probably either has only [clang](http://clang.llvm.org/) or an outdated version of `gcc`. You can get a more recent version using [HomeBrew](http://apple.stackexchange.com/questions/38222/how-do-i-install-gcc-via-homebrew)

If you want to use the CUDA backend, you need to have an NVIDIA graphics card and install both the [CUDA Toolkit](https://developer.nvidia.com/cuda-toolkit) and [PyCUDA](http://mathema.tician.de/software/pycuda/). 


How does it work? 
====
Your untyped function gets used as a template from which multiple *type specializations* are generated 
(for each distinct set of input types). 
These typed functions are then churned through many optimizations before finally getting translated into native code. 

More information
===

  * Read more about Parakeet on the [project website](http://www.parakeetpython.com) 
  * Ask questions on the [discussion group](http://groups.google.com/forum/#!forum/parakeet-python)
  * Watch the [Parakeet presentation](https://vimeo.com/73895275) from this year's [PyData Boston](http://pydata.org/bos2013), look at the [HotPar slides](https://www.usenix.org/conference/hotpar12/parakeet-just-time-parallel-accelerator-python) from last year 
  * Contact the [main developer](http://www.rubinsteyn.com) directly



Supported language features
====

Parakeet cannot accelerate arbitrary Python code, it only supports a limited subset of the language:

  * Scalar operations (i.e. `x + 3 * y`)
  * Control flow (if-statements, loops, etc...)
  * Nested functions and lambdas
  * Tuples
  * Slices
  * NumPy array expressions (i.e. `x[1:, :] + 2 * y[:-1, ::2]`)
  * Some NumPy library functions like `np.ones` and `np.sin` (look at the [mappings](https://github.com/iskandr/parakeet/blob/master/parakeet/mappings.py) module for a full list)
  * List literals (interpreted as array construction)
  * List comprehensions (interpreted as array comprehensions)
  * Parakeet's higher order array operations like `parakeet.imap`, `parakeet.scan`, and `parakeet.allpairs`

Backends
===
Parakeet currently supports compilation to sequential C, multi-core C with OpenMP (default), or LLVM (deprecated). To switch between these options change `parakeet.config.backend` to one of:

  * *"openmp"*: compiles with gcc, parallel operators run across multiple cores (default)
  * *"c"*: lowers all parallel operators to loops, compile sequential code with gcc
  * *"cuda"*: launch parallel operations on the GPU (experimental)
  * *"llvm"*: older backend, has fallen behind and some programs may not work
  * *"interp"* : pure Python intepreter used for debugging optimizations, only try this if you think CPython is about 10,000x too fast for your taste 



