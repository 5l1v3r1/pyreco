__FILENAME__ = extend
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2012 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import os
import sys

# To avoid accidentally creating files owned by root.
sys.dont_write_bytecode = True

# Python version check is done before imports below so that python
# 2.6/2.5 users can see the error message.
import pythonversion
pythonversion.check()

import argparse
import subprocess
import multiprocessing
import tempfile
import pwd

import installation

parser = argparse.ArgumentParser(description="Critic extension support installation script",
                                 epilog="""\
Critic extension support is activated by simply running (as root):

    # python extend.py

For finer control over the script's operation you can invoke it with one
or more of the action arguments:

  --prereqs, --fetch, --build, --install and --enable

This can for instance be used to build the v8-jsshell executable on a
system where Critic has not been installed.""",
                                 formatter_class=argparse.RawDescriptionHelpFormatter)

# Uses default values for everything that has a default value (and isn't
# overridden by other command-line arguments) and signals an error for anything
# that doesn't have a default value and isn't set by a command-line argument.
parser.add_argument("--headless", help=argparse.SUPPRESS, action="store_true")

class DefaultBinDir:
    pass

basic = parser.add_argument_group("basic options")
basic.add_argument("--etc-dir", help="directory where the Critic system configuration is stored [default=/etc/critic]", action="store", default="/etc/critic")
basic.add_argument("--identity", help="system identity to upgrade [default=main]", action="store", default="main")
basic.add_argument("--bin-dir", help="directory where the extension host executable is installed [default=/usr/lib/critic/$IDENTITY/bin]", action="store", default=DefaultBinDir)
basic.add_argument("--no-compiler-check", help="disable compiler version check", action="store_true")
basic.add_argument("--dry-run", "-n", help="produce output but don't modify the system at all", action="store_true")
basic.add_argument("--libcurl-flavor", help="libcurl flavor (openssl, gnutls or nss) or install", choices=["openssl", "gnutls", "nss"])

actions = parser.add_argument_group("actions")
actions.add_argument("--prereqs", help="(check for and) install prerequisite software", action="store_true")
actions.add_argument("--fetch", help="fetch the extension host source code", action="store_true")
actions.add_argument("--build", help="build the extension host executable", action="store_true")
actions.add_argument("--install", help="install the extension host executable", action="store_true")
actions.add_argument("--enable", help="enable extension support in Critic's configuration", action="store_true")

actions.add_argument("--with-v8-jsshell", help="v8-jsshell repository URL [default=../v8-jsshell.git]", metavar="URL")
actions.add_argument("--with-v8", help="v8 repository URL [default=git://github.com/v8/v8.git]", metavar="URL")

# Useful to speed up repeated building from clean repositories; used
# by the testing framework.
actions.add_argument("--export-v8-dependencies", help=argparse.SUPPRESS)
actions.add_argument("--import-v8-dependencies", help=argparse.SUPPRESS)

arguments = parser.parse_args()

if arguments.headless:
    installation.input.headless = True

import installation

is_root = os.getuid() == 0

prereqs = arguments.prereqs
fetch = arguments.fetch
build = arguments.build
install = arguments.install
enable = arguments.enable

if not any([prereqs, fetch, build, install, enable]) \
        and arguments.export_v8_dependencies is None \
        and arguments.import_v8_dependencies is None:
    prereqs = fetch = build = install = enable = True

libcurl = False

if any([prereqs, install, enable]) and not is_root:
    print """
ERROR: You need to run this script as root.
"""
    sys.exit(1)

git = os.environ.get("GIT", "git")

if install or enable:
    data = installation.utils.read_install_data(arguments)

    if data is not None:
        git = data["installation.prereqs.git"]

        installed_sha1 = data["sha1"]
        current_sha1 = installation.utils.run_git([git, "rev-parse", "HEAD"],
                                                  cwd=installation.root_dir).strip()

        if installed_sha1 != current_sha1:
            print """
ERROR: You should to run upgrade.py to upgrade to the current commit before
       using this script to enable extension support.
"""
            sys.exit(1)

if arguments.bin_dir is DefaultBinDir:
    bin_dir = os.path.join("/usr/lib/critic", arguments.identity, "bin")
else:
    bin_dir = arguments.bin_dir

if "CXX" in os.environ:
    compiler = os.environ["CXX"]

    try:
        subprocess.check_output([compiler, "--help"])
    except OSError as error:
        print """
ERROR: %r (from $CXX) does not appear to be a valid compiler.
""" % compiler
        sys.exit(1)
else:
    compiler = "g++"

def check_libcurl():
    fd, empty_cc = tempfile.mkstemp(".cc")
    os.close(fd)

    try:
        subprocess.check_output([compiler, "-include", "curl/curl.h", "-c", empty_cc, "-o", "/dev/null"],
                                stderr=subprocess.STDOUT)
        return True
    except subprocess.CalledProcessError as error:
        if "curl/curl.h" in error.output:
            return False
        raise
    finally:
        os.unlink(empty_cc)

def missing_packages():
    packages = []

    if not installation.prereqs.find_executable("svn"):
        packages.append("subversion")
    if not installation.prereqs.find_executable("make"):
        packages.append("make")
    if "CXX" not in os.environ and not installation.prereqs.find_executable("g++"):
        packages.append("g++")
    pg_config = installation.prereqs.find_executable("pg_config")
    if pg_config:
        try:
            subprocess.check_output(["pg_config"], stderr=subprocess.STDOUT)
        except subprocess.CalledProcessError:
            # Just installing the PostgreSQL database server might install
            # a dummy pg_config that just outputs an error message.
            pg_config = None
    if not pg_config:
        packages.append("libpq-dev")

    return packages

if prereqs:
    packages = missing_packages()

    if packages:
        installation.prereqs.install_packages(arguments, *packages)

    if not check_libcurl():
        if arguments.libcurl_flavor:
            installation.prereqs.install_packages(
                arguments, "libcurl4-%s-dev" % arguments.libcurl_flavor)
        else:
            print """
No version of libcurl-dev appears to be install.  There are usually multiple
versions available to install using different libraries (openssl, gnutls or nss)
for secure communication.  If curl is already installed, you probably need to
install a matching version of libcurl-dev.

This script can install any one of them, or build the extension host executable
without URL loading support ("none").

Available choices are: "openssl", "gnutls", "nss"
Also: "none", "abort"
"""

            def check(string):
                if string not in ("openssl", "gnutls", "nss", "none", "abort"):
                    return 'please answer "openssl", "gnutls", "nss", "none" or "abort"'

            choice = installation.input.string("Install libcurl-dev version?", "none")

            if choice in ("openssl", "gnutls", "nss"):
                installation.prereqs.install_packages(arguments, "libcurl4-%s-dev" % choice)
            elif choice == "abort":
                print """
ERROR: Installation aborted.
"""
                sys.exit(1)

env = os.environ.copy()

if build and not arguments.no_compiler_check:
    version = subprocess.check_output([compiler, "--version"])
    if version.startswith("g++"):
        version = subprocess.check_output([compiler, "-dumpversion"]).strip().split(".")
        if (int(version[0]), int(version[1])) < (4, 7):
            print """
ERROR: GCC version 4.7 or later required to build v8-jsshell.
HINT: Set $CXX to use a different compiler than '%s', or use
  --no-compiler-check to try to build anyway.
""" % compiler
            sys.exit(1)
    else:
        if "clang" in version:
            note_clang = "NOTE: CLang (version 3.2 and earlier) is known not to work.\n"
        else:
            note_clang = ""

        print """
ERROR: GCC (version 4.7 or later) required to build v8-jsshell.
%sHINT: Set $CXX to use a different compiler than '%s', or use
  --no-compiler-check to try to build anyway.
""" % (note_clang, compiler)
        sys.exit(1)

env["compiler"] = compiler
env["v8static"] = "yes"
env["postgresql"] = "yes"

if check_libcurl():
    env["libcurl"] = "yes"

root = os.path.dirname(os.path.abspath(sys.argv[0]))
v8_jsshell = os.path.join(root, "installation/externals/v8-jsshell")

def do_unprivileged_work():
    if is_root:
        stat = os.stat(sys.argv[0])
        os.environ["USER"] = pwd.getpwuid(stat.st_uid).pw_name
        os.environ["HOME"] = pwd.getpwuid(stat.st_uid).pw_dir
        os.setgid(stat.st_gid)
        os.setuid(stat.st_uid)

    if fetch:
        def fetch_submodule(cwd, submodule, url=None):
            subprocess.check_call(
                [git, "submodule", "init", submodule],
                cwd=cwd)
            if url:
                subprocess.check_call(
                    [git, "config", "submodule.%s.url" % submodule, url],
                    cwd=cwd)
            subprocess.check_call(
                [git, "submodule", "update", submodule],
                cwd=cwd)

        fetch_submodule(root, "installation/externals/v8-jsshell",
                        arguments.with_v8_jsshell)
        fetch_submodule(v8_jsshell, "v8", arguments.with_v8)

    if arguments.import_v8_dependencies or arguments.export_v8_dependencies:
        argv = ["make", "v8dependencies"]

        if arguments.import_v8_dependencies:
            argv.append("v8importdepsfrom=" + arguments.import_v8_dependencies)
        if arguments.export_v8_dependencies:
            argv.append("v8exportdepsto=" + arguments.export_v8_dependencies)

        subprocess.check_call(argv, cwd=v8_jsshell)

    if build:
        subprocess.check_call(
            ["make", "-j%d" % multiprocessing.cpu_count()],
            cwd=v8_jsshell, env=env)

if fetch or build \
        or arguments.import_v8_dependencies \
        or arguments.export_v8_dependencies:
    if is_root:
        unprivileged = multiprocessing.Process(target=do_unprivileged_work)
        unprivileged.start()
        unprivileged.join()
    else:
        do_unprivileged_work()

if install or enable:
    etc_path = os.path.join(arguments.etc_dir, arguments.identity)

    sys.path.insert(0, etc_path)

    import configuration

    executable = configuration.extensions.FLAVORS.get("js/v8", {}).get("executable")

    if not executable or not os.access(executable, os.X_OK):
        executable = os.path.join(bin_dir, "v8-jsshell")

if install:
    if not os.path.isdir(os.path.dirname(executable)):
        os.makedirs(os.path.dirname(executable))

    subprocess.check_call(
        ["install", os.path.join(v8_jsshell, "out", "jsshell"), executable])

if enable and not configuration.extensions.ENABLED:
    try:
        subprocess.check_output(
            ["su", "-s", "/bin/bash",
             "-c", "psql -q -c 'SELECT 1 FROM extensions LIMIT 1'",
             configuration.base.SYSTEM_USER_NAME],
            stderr=subprocess.STDOUT)
    except subprocess.CalledProcessError:
        installation.database.psql_import(
            "installation/data/dbschema.extensions.sql",
            configuration.base.SYSTEM_USER_NAME)

    data = { "installation.system.username": configuration.base.SYSTEM_USER_NAME,
             "installation.system.groupname": configuration.base.SYSTEM_GROUP_NAME,
             "installation.extensions.enabled": True,
             "installation.extensions.critic_v8_jsshell": executable,
             "installation.extensions.default_flavor": "js/v8" }

    installation.system.fetch_uid_gid()

    installation.paths.mkdir(configuration.extensions.INSTALL_DIR)
    installation.paths.mkdir(configuration.extensions.WORKCOPY_DIR)

    compilation_failed = []

    if installation.config.update_file(os.path.join(etc_path, "configuration"),
                                       "extensions.py", data, arguments,
                                       compilation_failed):
        if compilation_failed:
            print
            print "ERROR: Update aborted."
            print

            installation.config.undo()
            sys.exit(1)

        installation.initd.restart(arguments.identity)
        installation.apache.restart()

########NEW FILE########
__FILENAME__ = install
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2012 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import os
import sys
import stat
import traceback

# To avoid accidentally creating files owned by root.
sys.dont_write_bytecode = True

# Python version check is done before imports below so
# that python 2.6/2.5 users can see the error message.
import pythonversion
pythonversion.check("""\
NOTE: This script must be run in the Python interpreter that will be
used to run Critic.
""")

if sys.flags.optimize > 0:
    print """
ERROR: Please run this script without -O or -OO options.
"""
    sys.exit(1)

import argparse
import installation

parser = argparse.ArgumentParser(description="Critic installation script")

# Uses default values for everything that has a default value (and isn't
# overridden by other command-line arguments) and signals an error for anything
# that doesn't have a default value and isn't set by a command-line argument.
parser.add_argument("--headless", help=argparse.SUPPRESS, action="store_true")

parser.add_argument("--etc-dir", help="directory where the Critic system configuration is stored", action="store")
parser.add_argument("--install-dir", help="directory where the Critic source code is installed", action="store")
parser.add_argument("--data-dir", help="directory where Critic's persistent data files are stored", action="store")
parser.add_argument("--cache-dir", help="directory where Critic's temporary data files are stored", action="store")
parser.add_argument("--git-dir", help="directory where the main Git repositories are stored", action="store")
parser.add_argument("--log-dir", help="directory where Critic's log files are stored", action="store")
parser.add_argument("--run-dir", help="directory where Critic's runtime files are stored", action="store")

for module in installation.modules:
    if hasattr(module, "add_arguments"):
        module.add_arguments("install", parser)

arguments = parser.parse_args()

if os.getuid() != 0:
    print """
ERROR: This script must be run as root.
"""
    sys.exit(1)

if os.path.exists(os.path.join(installation.root_dir, ".installed")):
    print """
ERROR: Found an .installed file in the directory you're installing from.

This typically means that Critic is already installed on this system, and if so
then the upgrade.py script should be used to upgrade the installation rather than
re-running install.py.
"""
    sys.exit(1)

if arguments.headless:
    installation.input.headless = True

def abort():
    print
    print "ERROR: Installation aborted."
    print

    # for module in reversed(installation.modules):
    #     try:
    #         if hasattr(module, "undo"):
    #             module.undo()
    #     except:
    #         print >>sys.stderr, "FAILED: %s.undo()" % module.__name__
    #         traceback.print_exc()

    sys.exit(1)

try:
    try:
        if not installation.prereqs.check("install", arguments):
            abort()
    except KeyboardInterrupt:
        abort()
    except SystemExit:
        raise
    except:
        print >>sys.stderr, "FAILED: installation.prereqs.check()"
        traceback.print_exc()
        abort()

    git = installation.prereqs.git

    if installation.utils.run_git([git, "status", "--porcelain"],
                                  cwd=installation.root_dir).strip():
        print """
ERROR: This Git repository has local modifications.

Installing from a Git repository with local changes is not supported.
Please commit or stash the changes and then try again.
"""
        sys.exit(1)

    sha1 = installation.utils.run_git([git, "rev-parse", "HEAD"],
                                      cwd=installation.root_dir).strip()
    data = { "sha1": sha1 }

    for module in installation.modules:
        try:
            if hasattr(module, "prepare") and not module.prepare("install", arguments, data):
                abort()
        except KeyboardInterrupt:
            abort()
        except SystemExit:
            raise
        except:
            print >>sys.stderr, "FAILED: %s.prepare()" % module.__name__
            traceback.print_exc()
            abort()

    print

    installed_file = os.path.join(installation.root_dir, ".installed")
    with open(installed_file, "w"):
        pass
    install_py_stat = os.stat(os.path.join(installation.root_dir, "install.py"))
    os.chown(installed_file, install_py_stat.st_uid, install_py_stat.st_gid)

    for module in installation.modules:
        try:
            if hasattr(module, "install") and not module.install(data):
                abort()
        except KeyboardInterrupt:
            abort()
        except SystemExit:
            raise
        except:
            print >>sys.stderr, "FAILED: %s.execute()" % module.__name__
            traceback.print_exc()
            abort()

    for module in installation.modules:
        try:
            if hasattr(module, "finish"):
                module.finish("install", arguments, data)
        except:
            print >>sys.stderr, "WARNING: %s.finish() failed" % module.__name__
            traceback.print_exc()

    installation.utils.write_install_data(arguments, data)
    installation.utils.clean_root_pyc_files()

    print
    print "SUCCESS: Installation complete!"
    print
except SystemExit:
    raise
except:
    traceback.print_exc()
    abort()

########NEW FILE########
__FILENAME__ = admin
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2012 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import subprocess
import email.utils as email_utils

import installation

username = None
email = None
fullname = None
password = None

system_recipients = None

def add_arguments(mode, parser):
    if mode != "install":
        return

    parser.add_argument("--admin-username", action="store",
                        help="name of Critic administrator user")
    parser.add_argument("--admin-email", action="store",
                        help="email address to Critic administrator user")
    parser.add_argument("--admin-fullname", action="store",
                        help="Critic administrator user's full name")
    parser.add_argument("--admin-password", action="store",
                        help="Critic administrator user's password")

def prepare(mode, arguments, data):
    global username, email, fullname, password

    if mode == "install":
        print """
Critic Installation: Administrator
==================================

An administrator user is a Critic user with some special privileges;
they can do various things using the Web interface that other users
are not allowed to do.  Additional administrator users can be added
post-installation using the 'criticctl' utility.

This user does not need to match a system user on this machine.
"""

        if arguments.admin_username: username = arguments.admin_username
        else: username = installation.input.string(prompt="Administrator user name:")

        if arguments.admin_email: email = arguments.admin_email
        else: email = installation.input.string(prompt="Administrator email address:")

        if arguments.admin_fullname: fullname = arguments.admin_fullname
        else: fullname = installation.input.string(prompt="Administrator full name:")

        if installation.config.auth_mode == "critic":
            if arguments.admin_password: password = arguments.admin_password
            else: password = installation.input.password("Password for '%s':" % username)

        print """
Critic Installation: System Messages
====================================

Critic sends out email notifications when unexpected errors (crashes)
occur, and in various other cases when things happen that the system
administrators might need to know about right away.
"""

        if arguments.system_recipients:
            system_recipients = arguments.system_recipients
        else:
            system_recipient = installation.input.string(
                prompt="Where should system messages be sent?",
                default="%s <%s>" % (fullname, email))
            system_recipients = [system_recipient]
    else:
        import configuration

        try:
            system_recipients = configuration.base.SYSTEM_RECIPIENTS
        except AttributeError:
            system_recipients = ["%(fullname)s <%(email)s>" % admin
                                 for admin in configuration.base.ADMINISTRATORS]

        if system_recipients:
            _, email = email_utils.parseaddr(system_recipients[0])

        # The --system-recipients argument, on upgrade, is mostly intended to be
        # used by the testing framework.  It is checked after the code above has
        # run for testing purpose; making sure the code above ever runs while
        # testing is meaningful.
        if arguments.system_recipients:
            system_recipients = arguments.system_recipients

    data["installation.admin.email"] = email
    data["installation.system.recipients"] = system_recipients

    return True

def install(data):
    global password

    try:
        criticctl_argv = [installation.criticctl.criticctl_path, "adduser",
                          "--name", username,
                          "--email", email,
                          "--fullname", fullname]
        if not password:
            criticctl_argv.extend(["--no-password"])
        else:
            criticctl_argv.extend(["--password", password])

        subprocess.check_output(criticctl_argv)

        for role in ["administrator", "repositories", "newswriter"]:
            subprocess.check_output(
                [installation.criticctl.criticctl_path, "addrole",
                 "--name", username,
                 "--role", role])
    except subprocess.CalledProcessError:
        return False

    return True

########NEW FILE########
__FILENAME__ = apache
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2012 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import os
import re
import subprocess
import time

import installation

pass_auth = "Off"
site_suffix = ".conf"
default_site = "000-default"
apache_stopped = False

def get_apache2_version():
    output = subprocess.check_output([installation.prereqs.apache2ctl, "-v"])
    match = re.search("Server version:\s*Apache/([^\s\n]*)", output, re.M)
    if not match:
        return None
    return match.group(1)

def start():
    global apache_stopped
    print
    try:
        subprocess.check_call(["service", "apache2", "start"])
    except subprocess.CalledProcessError:
        print """
WARNING: Apache failed to start.

You can now either abort this Critic installation/upgrade, or you can
go ahead anyway, fix the Apache configuration problem manually (now or
later), and then start Apache yourself using the command

  service apache2 start

Note that if you don't abort, the Critic system will most likely not
be accessible until the Apache configuration has been fixed.
"""
        return not installation.input.yes_or_no(
            "Do you want to abort this Critic installation/upgrade?")
    apache_stopped = False
    return True

def stop():
    global apache_stopped
    apache_stopped = True
    print
    try:
        subprocess.check_call(["service", "apache2", "stop"])
    except subprocess.CalledProcessError:
        return False
    return True

def restart():
    if not stop():
        return False
    time.sleep(1)
    return start()

def prepare(mode, arguments, data):
    global pass_auth, site_suffix, default_site

    if installation.config.auth_mode == "critic":
        pass_auth = "On"

    data["installation.apache.pass_auth"] = pass_auth

    version = get_apache2_version()
    if version and version.startswith("2.2."):
        site_suffix = ""
        default_site = "default"

    return True

created_file = []
renamed = []
site_enabled = False
default_site_disabled = False

def install(data):
    global site_enabled, default_site_disabled

    site = "site.%s" % installation.config.access_scheme

    source_path = os.path.join(installation.root_dir, "installation", "templates", site)
    target_path = os.path.join("/etc", "apache2", "sites-available", "critic-main%s" % site_suffix)

    with open(target_path, "w") as target:
        created_file.append(target_path)

        os.chmod(target_path, 0640)

        with open(source_path, "r") as source:
            target.write((source.read().decode("utf-8") % data).encode("utf-8"))

    if installation.prereqs.a2enmod:
        subprocess.check_call([installation.prereqs.a2enmod, "expires"])
        subprocess.check_call([installation.prereqs.a2enmod, "rewrite"])
        subprocess.check_call([installation.prereqs.a2enmod, "wsgi"])

    if installation.prereqs.a2ensite:
        subprocess.check_call([installation.prereqs.a2ensite, "critic-main"])
        site_enabled = True
    if installation.prereqs.a2dissite:
        output = subprocess.check_output([installation.prereqs.a2dissite, default_site],
                                         env={ "LANG": "C" })
        if "Site default disabled." in output:
            default_site_disabled = True

    return stop() and start()

def upgrade(arguments, data):
    site = "site.%s" % installation.config.access_scheme

    source_path = os.path.join(installation.root_dir, "installation", "templates", site)
    target_path = os.path.join("/etc", "apache2", "sites-available", "critic-main%s" % site_suffix)
    backup_path = os.path.join(os.path.dirname(target_path), "_" + os.path.basename(target_path))

    source = open(source_path, "r").read().decode("utf-8") % data
    target = open(target_path, "r").read().decode("utf-8")

    if source != target:
        def generateVersion(label, path):
            if label == "updated":
                with open(path, "w") as target:
                    target.write(source.encode("utf-8"))

        update_query = installation.utils.UpdateModifiedFile(
            arguments,
            message="""\
The Apache site definition is about to be updated.  Please check that no local
modifications are being overwritten.

  Current version: %(current)s
  Updated version: %(updated)s

Please note that if the modifications are not installed, the system is
likely to break.
""",
            versions={ "current": target_path,
                       "updated": target_path + ".new" },
            options=[ ("i", "install the updated version"),
                      ("k", "keep the current version"),
                      ("d", ("current", "updated")) ],
            generateVersion=generateVersion)

        write_target = update_query.prompt() == "i"
    else:
        write_target = False

    if write_target:
        print "Updated file: %s" % target_path

        if not arguments.dry_run:
            os.rename(target_path, backup_path)
            renamed.append((target_path, backup_path))

            with open(target_path, "w") as target:
                created_file.append(target_path)
                os.chmod(target_path, 0640)
                target.write(source.encode("utf-8"))

    return True

def undo():
    if site_enabled:
        subprocess.check_call([installation.prereqs.a2dissite, "critic-main"])

        if default_site_disabled:
            subprocess.check_call([installation.prereqs.a2ensite, default_site])

        if installation.prereqs.apache2ctl:
            subprocess.check_call([installation.prereqs.apache2ctl, "restart"])

    map(os.unlink, created_file)

    for target, backup in renamed: os.rename(backup, target)

def finish(mode, arguments, data):
    for target, backup in renamed: os.unlink(backup)

########NEW FILE########
__FILENAME__ = config
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2012 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import sys
import os
import os.path
import py_compile
import argparse

import installation

auth_mode = "host"
session_type = None
allow_anonymous_user = None
access_scheme = None
repository_url_types = ["http"]
allow_user_registration = None
verify_email_addresses = True

password_hash_schemes = ["pbkdf2_sha256", "bcrypt"]
default_password_hash_scheme = "pbkdf2_sha256"
minimum_password_hash_time = 0.25
minimum_rounds = {}

is_development = False
is_testing = False
coverage_dir = None

class Provider(object):
    def __init__(self, name):
        self.name = name
        self.enabled = False
        self.allow_user_registration = False
        self.verify_email_addresses = False
        self.client_id = None
        self.client_secret = None
        self.redirect_uri = None
        self.bypass_createuser = False

    def load(self, settings):
        if self.name not in settings:
            return
        settings = settings[self.name]
        self.enabled = settings.get("enabled", self.enabled)
        self.allow_user_registration = settings.get("allow_user_registration",
                                                    self.allow_user_registration)
        self.verify_email_addresses = settings.get("verify_email_addresses",
                                                   self.verify_email_addresses)
        self.client_id = settings.get("client_id", self.client_id)
        self.client_secret = settings.get("client_secret", self.client_secret)
        self.redirect_uri = settings.get("redirect_uri", self.redirect_uri)
        self.bypass_createuser = settings.get("bypass_createuser",
                                              self.bypass_createuser)

    def readargs(self, arguments):
        def getarg(name, default):
            value = getattr(arguments, name, None)
            if value is None:
                return default
            return value

        self.enabled = getarg(
            "provider_%s_enabled" % self.name, self.enabled)
        self.allow_user_registration = getarg(
            "provider_%s_user_registration" % self.name,
            self.allow_user_registration)
        self.verify_email_addresses = getarg(
            "provider_%s_verify_email_addresses" % self.name,
            self.verify_email_addresses)
        self.client_id = getarg(
            "provider_%s_client_id" % self.name, self.client_id)
        self.client_secret = getarg(
            "provider_%s_client_secret" % self.name, self.client_secret)
        self.redirect_uri = getarg(
            "provider_%s_redirect_uri" % self.name, self.redirect_uri)

    def store(self, data):
        base = "installation.config.provider_%s." % self.name

        data[base + "enabled"] = self.enabled
        data[base + "allow_user_registration"] = self.allow_user_registration
        data[base + "verify_email_addresses"] = self.verify_email_addresses
        data[base + "client_id"] = self.client_id
        data[base + "client_secret"] = self.client_secret
        data[base + "redirect_uri"] = self.redirect_uri
        data[base + "bypass_createuser"] = self.bypass_createuser

    def scrub(self, data):
        base = "installation.config.provider_%s." % self.name

        del data[base + "client_id"]
        del data[base + "client_secret"]

providers = []
default_provider_names = ["github", "google"]

def calibrate_minimum_rounds():
    import time
    import passlib.context

    min_rounds_name = "%s__min_rounds" % default_password_hash_scheme
    min_rounds_value = 100

    while True:
        calibration_context = passlib.context.CryptContext(
            schemes=[default_password_hash_scheme],
            default=default_password_hash_scheme,
            **{ min_rounds_name: min_rounds_value })

        before = time.time()

        calibration_context.encrypt("password")

        # It's possible encryption was fast enough to measure as zero, or some
        # other ridiculously small number.  "Round" it up to at least one
        # millisecond for sanity.
        hash_time = max(0.001, time.time() - before)

        if hash_time >= minimum_password_hash_time:
            break

        # Multiplication factor.  Make it at least 1.2, to ensure we actually
        # ever finish this loop, and at most 10, to ensure we don't over-shoot
        # by too much.
        factor = max(1.2, min(10.0, minimum_password_hash_time / hash_time))

        min_rounds_value = int(factor * min_rounds_value)

    # If we're upgrading and have a current calibrated value, only change it if
    # the new value is significantly higher, indicating that the system's
    # performance has increased, or the hash implementation has gotten faster.
    if default_password_hash_scheme in minimum_rounds:
        current_value = minimum_rounds[default_password_hash_scheme]
        if current_value * 1.5 > min_rounds_value:
            return

    minimum_rounds[default_password_hash_scheme] = min_rounds_value

def add_arguments(mode, parser):
    def H(help_string):
        # Wrapper to hide arguments when upgrading, but still supporting them.
        # Primarily we need to support arguments on upgrade for testing, which
        # might upgrade from a commit that doesn't support an argument, and thus
        # needs to provide the argument when upgrading to the tested commit.
        if mode == "install":
            return help_string
        else:
            return argparse.SUPPRESS

    parser.add_argument(
        "--auth-mode", choices=["host", "critic"],
        help=H("user authentication mode"))
    parser.add_argument(
        "--session-type", choices=["httpauth", "cookie"],
        help=H("session type"))
    parser.add_argument(
        "--allow-anonymous-user", dest="anonymous", action="store_const",
        const=True, help=H("allow limited unauthenticated access"))
    parser.add_argument(
        "--no-allow-anonymous-user", dest="anonymous", action="store_const",
        const=False, help=H("do not allow unauthenticated access"))
    parser.add_argument(
        "--allow-user-registration", dest="user_registration",
        action="store_const", const=True,
        help=H("allow unattended user registration"))
    parser.add_argument(
        "--no-allow-user-registration", dest="user_registration",
        action="store_const", const=False,
        help=H("do not allow unattended user registration"))
    parser.add_argument(
        "--access-scheme", choices=["http", "https", "both"],
        help=H("scheme used to access Critic"))
    parser.add_argument(
        "--repository-url-types", default="http",
        help=H("comma-separated list of supported repository URL types "
               "(valid types: git, http, ssh and host)"))

    for provider_name in default_provider_names:
        if mode == "install":
            group = parser.add_argument_group(
                "'%s' authentication provider" % provider_name)
        else:
            group = parser

        group.add_argument(
            "--provider-%s-enabled" % provider_name, action="store_const",
            const=True, help=H("enable authentication provider"))
        group.add_argument(
            "--provider-%s-disabled" % provider_name, action="store_const",
            const=False, dest="provider_%s_enabled" % provider_name,
            help=H("disable authentication provider"))
        group.add_argument(
            "--provider-%s-user-registration" % provider_name,
            action="store_const", const=True,
            help=H("enable new user registration"))
        group.add_argument(
            "--provider-%s-no-user-registration" % provider_name,
            action="store_const", const=False,
            dest="provider_%s_user_registration" % provider_name,
            help=H("disable new user registration"))
        group.add_argument(
            "--provider-%s-client-id" % provider_name, action="store",
            help=H("OAuth2 client id"))
        group.add_argument(
            "--provider-%s-client-secret" % provider_name, action="store",
            help=H("OAuth2 client secret"))
        group.add_argument(
            "--provider-%s-redirect-uri" % provider_name, action="store",
            help=H("OAuth2 authentication callback URI"))

    parser.add_argument(
        "--minimum-password-hash-time",
        help=H("approximate minimum time to spend hashing a single password"))

    # Using argparse.SUPPRESS to not include these in --help output; they are
    # not something a typical installer ought to want to use.
    parser.add_argument(
        "--is-development", action="store_true", help=argparse.SUPPRESS)
    parser.add_argument(
        "--is-testing", action="store_true", help=argparse.SUPPRESS)
    parser.add_argument(
        "--coverage-dir", help=argparse.SUPPRESS)

default_encodings = ["utf-8", "latin-1"]

def prepare(mode, arguments, data):
    global auth_mode, session_type, allow_anonymous_user, access_scheme
    global repository_url_types, default_encodings, allow_user_registration
    global verify_email_addresses
    global password_hash_schemes, default_password_hash_scheme
    global minimum_password_hash_time, minimum_rounds
    global is_development, is_testing, coverage_dir

    header_printed = False

    if mode == "install":
        if arguments.minimum_password_hash_time is not None:
            try:
                minimum_password_hash_time = float(arguments.minimum_password_hash_time)
            except ValueError:
                print ("Invalid --minimum-password-hash-time argument: %s (must be a number)."
                       % arguments.minimum_password_hash_time)
                return False

        if arguments.repository_url_types:
            repository_url_types = filter(
                None, arguments.repository_url_types.split(","))
            invalid_url_types = []
            for url_type in repository_url_types:
                if url_type not in ["git", "http", "ssh", "host"]:
                    invalid_url_types.append(url_type)
            if invalid_url_types or not repository_url_types:
                print ("Invalid --repository-url-types argument: %s"
                       % arguments.repository_url_types)
                if invalid_url_types:
                    print ("These types are invalid: %s"
                           % ",".join(invalid_url_types))
                if not repository_url_types:
                    print "No URL types specified!"
                return False

        if installation.prereqs.passlib_available:
            def check_auth_mode(value):
                if value.strip() not in ("host", "critic"):
                    return "must be one of 'host' and 'critic'"

            if arguments.auth_mode:
                error = check_auth_mode(arguments.auth_mode)
                if error:
                    print "Invalid --auth-mode argument: %s." % arguments.auth_mode
                    return False
                auth_mode = arguments.auth_mode
            else:
                header_printed = True

                print """
Critic Installation: Authentication
===================================

Critic needs to identify (via HTTP authentication) users who access
the Web front-end.  This can be handled in two different ways:

  host    The Web server (Apache) handles authentication and Critic
          only makes use of the user name that it reports via the
          WSGI API.

  critic  Critic implements HTTP authentication itself using passwords
          stored (encrypted) in its database.
"""

                auth_mode = installation.input.string(
                    "Which authentication mode should be used?",
                    default="critic", check=check_auth_mode)

        is_development = arguments.is_development
        is_testing = arguments.is_testing
        coverage_dir = arguments.coverage_dir
    else:
        import configuration

        auth_mode = configuration.base.AUTHENTICATION_MODE

        try: session_type = configuration.base.SESSION_TYPE
        except AttributeError: pass

        try: allow_anonymous_user = configuration.base.ALLOW_ANONYMOUS_USER
        except AttributeError: pass

        try: access_scheme = configuration.base.ACCESS_SCHEME
        except AttributeError: pass

        try: repository_url_types = configuration.base.REPOSITORY_URL_TYPES
        except AttributeError: pass

        try: default_encodings = configuration.base.DEFAULT_ENCODINGS
        except AttributeError: pass

        try:
            password_hash_schemes = configuration.auth.PASSWORD_HASH_SCHEMES
            default_password_hash_scheme = configuration.auth.DEFAULT_PASSWORD_HASH_SCHEME
            minimum_password_hash_time = configuration.auth.MINIMUM_PASSWORD_HASH_TIME
            minimum_rounds = configuration.auth.MINIMUM_ROUNDS
        except AttributeError:
            pass

        try: is_development = configuration.debug.IS_DEVELOPMENT
        except AttributeError:
            # Was moved from configuration.base to configuration.debug.
            try: is_development = configuration.base.IS_DEVELOPMENT
            except AttributeError: pass

        try: is_testing = configuration.debug.IS_TESTING
        except AttributeError: is_testing = arguments.is_testing

        try: coverage_dir = configuration.debug.COVERAGE_DIR
        except AttributeError: pass

        try: allow_user_registration = configuration.base.ALLOW_USER_REGISTRATION
        except AttributeError: pass

        try: verify_email_addresses = configuration.base.VERIFY_EMAIL_ADDRESSES
        except AttributeError: pass

    if auth_mode == "critic":
        if session_type is None:
            def check_session_type(value):
                if value.strip() not in ("httpauth", "cookie"):
                    return "must be one of 'http' and 'cookie'"

            if arguments.session_type:
                error = check_session_type(arguments.session_type)
                if error:
                    print "Invalid --session_type argument: %s." % arguments.session_type
                    return False
                session_type = arguments.session_type
            else:
                if not header_printed:
                    header_printed = True
                    print """
Critic Installation: Authentication
==================================="""

                print """
Critic can authenticate users either via HTTP authentication or via a
"Sign in" form and session cookies.  The major difference is that HTTP
authentication requires a valid login to access any page whereas the
other type of authentication supports limited anonymous access.

  httpauth  Use HTTP authentication.

  cookie    Use session cookie based authentication.
"""

                session_type = installation.input.string(
                    "Which session type should be used?",
                    default="cookie", check=check_session_type)

        if allow_anonymous_user is None:
            if session_type == "httpauth":
                allow_anonymous_user = False
            elif arguments.anonymous is not None:
                allow_anonymous_user = arguments.anonymous
            else:
                if not header_printed:
                    header_printed = True
                    print """
Critic Installation: Authentication
==================================="""

                print """
With cookie based authentication, Critic can support anonymous access.
Users still have to sign in in order to make any changes (such as
write comments in reviews) but will be able to view most information
in the system without signin in.
"""

                allow_anonymous_user = installation.input.yes_or_no(
                    "Do you want to allow anonymous access?", default=True)

        if allow_user_registration is None:
            if session_type == "httpauth":
                allow_user_registration = False
            elif arguments.user_registration is not None:
                allow_user_registration = arguments.user_registration
            else:
                if not header_printed:
                    header_printed = True
                    print """
Critic Installation: Authentication
==================================="""

                print """
With cookie based authentication, Critic can support unattended user
registration.  With this enabled, the "Sign in" page has a link to a
page where a new user can register a Critic user without needing to
contact the system administrator(s).
"""

                allow_user_registration = installation.input.yes_or_no(
                    "Do you want to allow user registration?", default=False)
    else:
        session_type = "cookie"

    if access_scheme is None:
        if arguments.access_scheme:
            access_scheme = arguments.access_scheme
        else:
            print """
Critic Installation: Scheme
===========================

Critic can be set up to be accessed over HTTP, HTTPS, or both.  This
installation script will not do the actual configuration of the host
web server (Apache) necessary for it to support the desired schemes
(in particular HTTPS, which is non-trivial,) but can at least set up
Critic's Apache site declaration appropriately.

You have three choices:

  http   Critic will be accessible only over HTTP.

  https  Critic will be accessible only over HTTPS.

  both   Critic will be accessible over both HTTP and HTTPS.

If you choose "both", Critic will redirect all authenticated accesses
to HTTPS, to avoid sending credentials over plain text connections."""

            if allow_anonymous_user:
                print """\
Anonymous users will be allowed to access the site over HTTP, though.
If this is not desirable, you should select "https" and configure the
web server to redirect all HTTP accesses to HTTPS.
"""
            else:
                print

            def check_access_scheme(value):
                if value not in ("http", "https", "both"):
                    return "must be one of 'http', 'https' and 'both'"

            access_scheme = installation.input.string(
                "How will Critic be accessed?", default="http",
                check=check_access_scheme)

    if mode == "upgrade" \
           and hasattr(configuration, "auth") \
           and hasattr(configuration.auth, "PROVIDERS"):
        for provider_name in configuration.auth.PROVIDERS:
            provider = Provider(provider_name)
            provider.load(configuration.auth.PROVIDERS)
            providers.append(provider)
    else:
        providers.extend(Provider(provider_name)
                         for provider_name in default_provider_names)

    if access_scheme == "http":
        base_url = "http"
    else:
        base_url = "https"

    base_url += "://%s/oauth/" % installation.system.hostname

    for provider in providers:
        provider.readargs(arguments)
        if provider.redirect_uri is None:
            provider.redirect_uri = base_url + provider.name

    data["installation.config.auth_mode"] = auth_mode
    data["installation.config.session_type"] = session_type
    data["installation.config.allow_anonymous_user"] = allow_anonymous_user
    data["installation.config.access_scheme"] = access_scheme
    data["installation.config.repository_url_types"] = repository_url_types
    data["installation.config.default_encodings"] = default_encodings
    data["installation.config.allow_user_registration"] = allow_user_registration
    data["installation.config.verify_email_addresses"] = verify_email_addresses

    calibrate_minimum_rounds()

    data["installation.config.password_hash_schemes"] = password_hash_schemes
    data["installation.config.default_password_hash_scheme"] = default_password_hash_scheme
    data["installation.config.minimum_password_hash_time"] = minimum_password_hash_time
    data["installation.config.minimum_rounds"] = minimum_rounds

    data["installation.config.is_development"] = is_development
    data["installation.config.is_testing"] = is_testing
    data["installation.config.coverage_dir"] = coverage_dir

    for provider in providers:
        provider.store(data)

    return True

created_file = []
created_dir = []
renamed = []
modified_files = 0

def compile_file(filename):
    global created_file
    try:
        path = os.path.join(installation.paths.etc_dir, "main", filename)
        with installation.utils.as_critic_system_user():
            py_compile.compile(path, doraise=True)
    except py_compile.PyCompileError as error:
        print """
ERROR: Failed to compile %s:\n%s
""" % (filename, error)
        return False
    else:
        created_file.append(path + "c")
        return True

def set_file_mode_and_owner(path):
    uid = installation.system.uid
    gid = installation.system.gid

    filename = os.path.basename(path)
    if filename in ("database.py", "auth.py", "smtp-credentials.json"):
        # May contain sensitive information.
        mode = 0600
        if filename == "smtp-credentials.json":
            uid = gid = 0
    else:
        mode = 0640

    os.chmod(path, mode)
    os.chown(path, uid, gid)

def copy_file_mode_and_owner(src_path, dst_path):
    status = os.stat(src_path)

    os.chmod(dst_path, status.st_mode)
    os.chown(dst_path, status.st_uid, status.st_gid)

def install(data):
    source_dir = os.path.join(installation.root_dir, "installation", "templates", "configuration")
    target_dir = os.path.join(installation.paths.etc_dir, "main", "configuration")
    compilation_failed = False

    os.mkdir(target_dir, 0750)
    created_dir.append(target_dir)

    os.chown(target_dir, installation.system.uid, installation.system.gid)

    for entry in os.listdir(source_dir):
        source_path = os.path.join(source_dir, entry)
        target_path = os.path.join(target_dir, entry)

        with open(target_path, "w") as target:
            created_file.append(target_path)

            with open(source_path, "r") as source:
                target.write((source.read().decode("utf-8") % data).encode("utf-8"))

        set_file_mode_and_owner(target_path)

        if entry.endswith(".py"):
            path = os.path.join("configuration", entry)
            if not compile_file(path):
                compilation_failed = True
            else:
                copy_file_mode_and_owner(target_path, target_path + "c")

    if compilation_failed:
        return False

    # Make the newly written 'configuration' module available to the rest of the
    # installation script(s).
    sys.path.insert(0, os.path.join(installation.paths.etc_dir, "main"))

    return True

def update_file(target_dir, entry, data, arguments, compilation_failed):
    global modified_files

    import configuration

    source_dir = os.path.join(installation.root_dir, "installation", "templates", "configuration")
    compilation_failed = False

    source_path = os.path.join(source_dir, entry)
    target_path = os.path.join(target_dir, entry)
    backup_path = os.path.join(target_dir, "_" + entry)

    source = open(source_path, "r").read().decode("utf-8") % data

    if not os.path.isfile(target_path):
        write_target = True
    else:
        if open(target_path).read().decode("utf-8") == source:
            return False

        def generateVersion(label, path):
            if label == "updated":
                with open(path, "w") as target:
                    target.write(source.encode("utf-8"))

        update_query = installation.utils.UpdateModifiedFile(
            arguments,
            message="""\
A configuration file is about to be updated.  Please check that no
local modifications are being overwritten.

Current version: %(current)s
Updated version: %(updated)s

Please note that if any configuration options were added in the
updated version, the system will most likely break if you do not
either install the updated version or manually transfer the new
configuration options to the existing version.
""",
            versions={ "current": target_path,
                       "updated": target_path + ".new" },
            options=[ ("i", "install the updated version"),
                      ("k", "keep the current version"),
                      ("d", ("current", "updated")) ],
            generateVersion=generateVersion)

        write_target = update_query.prompt() == "i"

    if write_target:
        print "Updated file: %s" % target_path

        if not arguments.dry_run:
            if os.path.isfile(target_path):
                os.rename(target_path, backup_path)
                renamed.append((target_path, backup_path))

            with open(target_path, "w") as target:
                created_file.append(target_path)
                target.write(source.encode("utf-8"))

            set_file_mode_and_owner(target_path)

            if target_path.endswith(".py"):
                path = os.path.join("configuration", entry)
                if not compile_file(path):
                    compilation_failed.append(path)
                else:
                    copy_file_mode_and_owner(target_path, target_path + "c")

                    # The module's name (relative the 'configuration' package)
                    # is the base name minus the trailing ".py".
                    module_name = os.path.basename(target_path)[:-3]

                    if module_name != "__init__" \
                            and hasattr(configuration, module_name):
                        # Reload the updated module so that code executing later
                        # sees added configuration options.  (It will also see
                        # removed configuration options, but that is unlikely to
                        # be a problem.)
                        reload(getattr(configuration, module_name))

        modified_files += 1

    return True

def upgrade(arguments, data):
    global modified_files

    import configuration

    source_dir = os.path.join(installation.root_dir, "installation", "templates", "configuration")
    target_dir = os.path.join(data["installation.paths.etc_dir"], arguments.identity, "configuration")
    compilation_failed = []

    no_changes = True

    for entry in os.listdir(source_dir):
        if update_file(target_dir, entry, data, arguments, compilation_failed):
            no_changes = False

    if compilation_failed:
        return False

    if no_changes:
        print "No changed configuration files."

    if modified_files:
        reload(configuration)

    return True

def undo():
    map(os.unlink, reversed(created_file))
    map(os.rmdir, reversed(created_dir))

    for target, backup in renamed: os.rename(backup, target)

def finish(mode, arguments, data):
    for target, backup in renamed: os.unlink(backup)

    for provider in providers:
        provider.scrub(data)

########NEW FILE########
__FILENAME__ = criticctl
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2012 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import installation
import os
import os.path

criticctl_path = None
created_file = []
renamed = []

def install(data):
    global criticctl_path

    source_path = os.path.join(installation.root_dir, "installation", "templates", "criticctl")
    target_path = criticctl_path = os.path.join("/usr", "bin", "criticctl")

    with open(target_path, "w") as target:
        created_file.append(target_path)

        os.chmod(target_path, 0755)

        with open(source_path, "r") as source:
            target.write((source.read().decode("utf-8") % data).encode("utf-8"))

    return True

def upgrade(arguments, data):
    target_path = "/usr/bin/criticctl"
    backup_path = installation.utils.update_from_template(
        arguments, data,
        template_path="installation/templates/criticctl",
        target_path=target_path,
        message="""\
The criticctl utility is about to be updated.  Please check that no local
modifications are being overwritten.

%(versions)s

Please note that if the modifications are not installed, the criticctl utility
is likely to stop working.
""")

    if backup_path:
        created_file.append(target_path)
        renamed.append((target_path, backup_path))

    return True

def undo():
    map(os.unlink, created_file)

    for target, backup in renamed:
        os.rename(backup, target)

def finish(mode, arguments, data):
    for target, backup in renamed:
        os.unlink(backup)

########NEW FILE########
__FILENAME__ = database
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2012 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import tempfile
import shutil
import os
import time
import errno
import subprocess

import installation

user_created = False
database_created = False
language_created = False

def psql_import(sql_file, as_user=None):
    if as_user is None:
        as_user = installation.system.username
    temp_file = tempfile.mkstemp()[1]
    shutil.copy(os.path.join(installation.root_dir, sql_file), temp_file)
    # Make sure file is readable by postgres user
    os.chmod(temp_file, 0644)
    subprocess.check_output(
        ["su", "-s", "/bin/sh", "-c", "psql -v ON_ERROR_STOP=1 -f %s" % temp_file, as_user])
    os.unlink(temp_file)

def add_arguments(mode, parser):
    if mode == "upgrade":
        parser.add_argument("--backup-database", dest="database_backup", action="store_const", const=True,
                            help="backup database to default location without asking")
        parser.add_argument("--no-backup-database", dest="database_backup", action="store_const", const=False,
                            help="do not backup database before upgrading")

def prepare(mode, arguments, data):
    if mode == "upgrade":
        default_path = os.path.join(data["installation.paths.data_dir"],
                                    "backups",
                                    time.strftime("%Y%m%d_%H%M.dump", time.localtime()))

        if arguments.database_backup is False:
            backup_database = False
        elif arguments.database_backup is True:
            backup_database = True
            backup_path = default_path
        else:
            if installation.migrate.will_modify_dbschema(data):
                print """
The database schema will be modified by the upgrade.  Creating a
backup of the database first is strongly recommended.
"""
                default_backup = True
            else:
                default_backup = False

            if installation.input.yes_or_no("Do you want to create a backup of the database?",
                                            default=default_backup):
                backup_database = True
                backup_path = installation.input.string("Where should the backup be stored?",
                                                        default=default_path)
            else:
                backup_database = False

        if backup_database:
            try: os.makedirs(os.path.dirname(backup_path), 0750)
            except OSError as error:
                if error.errno == errno.EEXIST: pass
                else: raise

            print
            print "Dumping database ..."

            with open(backup_path, "w") as output_file:
                subprocess.check_call(
                    ["su", "-s", "/bin/sh", "-c", "pg_dump -Fc critic",
                     data["installation.system.username"]],
                    stdout=output_file)

            print "Compressing database dump ..."
            print

            subprocess.check_call(["bzip2", backup_path])

    return True

def install(data):
    global user_created, database_created, language_created

    print "Creating database ..."

    # Several subsequent commands will run as Critic system user or "postgres" user,
    # and these users typically don't have read access to the installation 'root_dir'
    original_dir = os.getcwd()
    try:
        # Set cwd to something that Critic system / "postgres" users has access to.
        os.chdir(tempfile.gettempdir())

        subprocess.check_output(["su", "-c", "psql -v ON_ERROR_STOP=1 -c 'CREATE USER \"%s\";'" % installation.system.username, "postgres"])
        user_created = True

        subprocess.check_output(["su", "-c", "psql -v ON_ERROR_STOP=1 -c 'CREATE DATABASE \"critic\";'", "postgres"])
        database_created = True

        try:
            subprocess.check_output(["su", "-c", "createlang plpgsql critic", "postgres"],
                                    stderr=subprocess.STDOUT)
            language_created = True
        except subprocess.CalledProcessError:
            # The 'createlang' command fails if the language is already enabled
            # in the database, and we want to ignore such failures.  It might
            # also fail for other reasons, that we really don't mean to ignore,
            # but in that case importing the *.pgsql files below would fail,
            # since they define PL/pgSQL functions.
            pass

        subprocess.check_output(["su", "-c", "psql -v ON_ERROR_STOP=1 -c 'GRANT ALL ON DATABASE \"critic\" TO \"%s\";'" % installation.system.username, "postgres"])

        psql_import("installation/data/dbschema.sql")
        psql_import("installation/data/dbschema.comments.sql")
        psql_import("installation/data/dbschema.extensions.sql")
        psql_import("installation/data/comments.pgsql")
        psql_import("installation/data/roles.sql")

        import psycopg2

        def adapt(value): return psycopg2.extensions.adapt(value).getquoted()

        if installation.config.access_scheme in ("http", "https"):
            anonymous_scheme = authenticated_scheme = installation.config.access_scheme
        else:
            anonymous_scheme = "http"
            authenticated_scheme = "https"

        add_systemidentity_query = (
            """INSERT INTO systemidentities (key, name, anonymous_scheme,
                                             authenticated_scheme, hostname,
                                             description, installed_sha1)
                    VALUES ('main', 'main', %s, %s, %s, 'Main', %s);"""
            % (adapt(anonymous_scheme), adapt(authenticated_scheme),
               adapt(installation.system.hostname), adapt(data["sha1"])))

        installation.process.check_input(
            ["su", "-s", "/bin/sh", "-c", "psql -q -v ON_ERROR_STOP=1 -f -", installation.system.username],
            stdin=add_systemidentity_query)

    finally:
        os.chdir(original_dir)

    return True

def undo():
    if language_created:
        subprocess.check_output(["su", "-c", "droplang plpgsql critic", "postgres"])
    if database_created:
        subprocess.check_output(["su", "-c", "psql -v ON_ERROR_STOP=1 -c 'DROP DATABASE \"critic\";'", "postgres"])
    if user_created:
        subprocess.check_output(["su", "-c", "psql -v ON_ERROR_STOP=1 -c 'DROP USER \"%s\";'" % installation.system.username, "postgres"])

########NEW FILE########
__FILENAME__ = extensions
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2012 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

def prepare(mode, arguments, data):
    data["installation.extensions.enabled"] = False
    data["installation.extensions.critic_v8_jsshell"] = "NOT_INSTALLED"
    data["installation.extensions.default_flavor"] = "js/v8"

    if mode == "upgrade":
        import configuration
        data["installation.extensions.enabled"] = \
            configuration.extensions.ENABLED
        try:
            data["installation.extensions.critic_v8_jsshell"] = \
                configuration.extensions.FLAVORS["js/v8"]["executable"]
        except (KeyError, AttributeError):
            pass
        try:
            data["installation.extensions.default_flavor"] = \
                configuration.extensions.DEFAULT_FLAVOR
        except AttributeError:
            pass

    return True

########NEW FILE########
__FILENAME__ = files
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2012 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import sys
import os
import shutil
import errno
import py_compile

import installation

created_dir = []
created_file = []
renamed = []
copied_files = 0
modified_files = 0
sources_modified = False
resources_modified = False

def compile_file(filename):
    global created_file
    if not filename.endswith(".py"):
        return True
    try:
        path = os.path.join(installation.paths.install_dir, filename)
        with installation.utils.as_critic_system_user():
            py_compile.compile(path, doraise=True)
    except py_compile.PyCompileError as error:
        print """
ERROR: Failed to compile %s:\n%s
""" % (filename, error)
        return False
    else:
        created_file.append(path + "c")
        return True

def copyfile(source, destination):
    if os.path.islink(source):
        if os.path.lexists(destination):
            os.unlink(destination)
        os.symlink(os.readlink(source), destination)
    else:
        shutil.copyfile(source, destination)

def skip(path):
    filename = os.path.basename(path)
    if filename == "unittest.py" or filename.endswith("_unittest.py"):
        return not installation.config.is_testing
    return False

def install(data):
    source_dir = os.path.join(installation.root_dir, "src")
    target_dir = installation.paths.install_dir

    # Note: this is an array since it's modified in a nested scope.
    compilation_failed = []

    def copy(path):
        global copied_files

        source = os.path.join(source_dir, path)
        target = os.path.join(target_dir, path)

        if os.path.isdir(source):
            os.mkdir(target, 0755)
            os.chown(target, installation.system.uid, installation.system.gid)
            created_dir.append(target)
            return True
        else:
            copyfile(source, target)
            created_file.append(target)
            if not os.path.islink(target):
                if path.startswith("hooks/"):
                    mode = 0755
                else:
                    mode = 0644
                os.chmod(target, mode)
            os.lchown(target, installation.system.uid, installation.system.gid)
            copied_files += 1
            if not compile_file(path):
                compilation_failed.append(path)
            return False

    def process(path=""):
        for entry in os.listdir(os.path.join(source_dir, path)):
            name = os.path.join(path, entry)

            if skip(name):
                continue

            if copy(name):
                process(name)

    process()
    sys.path.insert(0, installation.paths.install_dir)

    if compilation_failed:
        return False

    print "Copied %d files into %s ..." % (copied_files, target_dir)

    return True

def upgrade(arguments, data):
    source_dir = installation.root_dir
    target_dir = data["installation.paths.install_dir"]

    # Note: this is an array since it's modified in a nested scope.
    compilation_failed = []

    uid = installation.system.uid
    gid = installation.system.gid

    def chown(directory):
        os.chown(directory, uid, gid)
        for name in os.listdir(directory):
            path = os.path.join(directory, name)
            if os.path.isdir(path):
                chown(path)
            elif path.endswith(".pyc"):
                os.chown(path, uid, gid)
            elif path.endswith(".pyo"):
                os.unlink(path)

    chown(target_dir)

    git = data["installation.prereqs.git"]

    old_sha1 = data["sha1"]
    new_sha1 = installation.utils.run_git([git, "rev-parse", "HEAD"],
                                          cwd=installation.root_dir).strip()

    old_has_src = installation.utils.get_tree_sha1(git, old_sha1, "src")

    def isResource(path):
        return path.endswith(".css") or path.endswith(".js") or path.endswith(".txt")

    def remove(old_source_path, target_path):
        full_target_path = os.path.join(target_dir, target_path)
        backup_path = os.path.join(os.path.dirname(full_target_path),
                                   "_" + os.path.basename(target_path))

        if not os.path.isfile(full_target_path):
            return

        old_file_sha1 = installation.utils.get_file_sha1(
            git, old_sha1, old_source_path)
        current_file_sha1 = installation.utils.hash_file(
            git, full_target_path)

        assert old_file_sha1 is not None

        if old_file_sha1 != current_file_sha1:
            def generateVersion(label, path):
                if label == "installed":
                    source = installation.utils.run_git(
                        [git, "cat-file", "blob", old_file_sha1],
                        cwd=installation.root_dir)
                    with open(path, "w") as target:
                        target.write(source)

            update_query = installation.utils.UpdateModifiedFile(
                arguments,
                message="""\
A source file is about to be removed, but the existing source file
appears to have been edited since it was installed.

  Installed version: %(installed)s
  Current version  : %(current)s

Not removing the file can cause unpredictable results.
""",
                versions={ "installed": full_target_path + ".org",
                           "current": full_target_path },
                options=[ ("r", "remove the file"),
                          ("k", "keep the file"),
                          ("d", ("installed", "current")) ],
                generateVersion=generateVersion)

            if update_query.prompt() == "r":
                remove_file = True
            else:
                remove_file = False
        else:
            remove_file = True

        if remove_file:
            print "Removing file: %s" % target_path
            if not arguments.dry_run:
                os.rename(full_target_path, backup_path)
                renamed.append((full_target_path, backup_path))

                if target_path.endswith(".py"):
                    if os.path.isfile(full_target_path + "c"):
                        os.unlink(full_target_path + "c")
                    if os.path.isfile(full_target_path + "o"):
                        os.unlink(full_target_path + "o")

    def copy(old_source_path, new_source_path, target_path):
        global copied_files, modified_files
        global resources_modified, sources_modified

        full_source_path = os.path.join(source_dir, new_source_path)
        full_target_path = os.path.join(target_dir, target_path)
        backup_path = os.path.join(os.path.dirname(full_target_path),
                                   "_" + os.path.basename(target_path))

        if skip(new_source_path) or not os.path.isfile(full_source_path):
            remove(old_source_path, target_path)
            return

        if os.path.isfile(full_source_path) and os.path.isdir(full_target_path):
            print """
The directory

  %s

is about to be deleted because a file is about to be installed in its
place.  Please make sure it doesn't contain anything that shouldn't be
deleted.
""" % full_target_path

            if not installation.input.yes_or_no("Do you want to delete the directory?", default=False):
                return False

            print "Removing directory: %s" % target_path
            if not arguments.dry_run:
                os.rename(full_target_path, backup_path)
                renamed.append((full_target_path, backup_path))

        if not os.path.isfile(full_target_path):
            print "New file: %s" % target_path
            if not arguments.dry_run:
                try: os.makedirs(os.path.dirname(full_target_path), 0755)
                except OSError as error:
                    if error.errno == errno.EEXIST: pass
                    else: raise
                copyfile(full_source_path, full_target_path)
                created_file.append(full_target_path)
            copied_files += 1
            if isResource(target_path):
                resources_modified = True
            else:
                sources_modified = True
        else:
            old_file_sha1 = installation.utils.get_file_sha1(
                git, old_sha1, old_source_path)
            new_file_sha1 = installation.utils.get_file_sha1(
                git, new_sha1, new_source_path)

            assert old_file_sha1 is not None
            assert new_file_sha1 is not None

            current_file_sha1 = installation.utils.hash_file(
                git, full_target_path)

            if current_file_sha1 != new_file_sha1:
                if current_file_sha1 != old_file_sha1:
                    def generateVersion(label, path):
                        if label == "installed":
                            source = installation.utils.run_git(
                                [git, "cat-file", "blob", old_file_sha1],
                                cwd=installation.root_dir)
                            with open(full_target_path + ".org", "w") as target:
                                target.write(source)
                        elif label == "updated":
                            copyfile(full_source_path,
                                     full_target_path + ".new")

                    update_query = installation.utils.UpdateModifiedFile(
                        arguments,
                        message="""\
A source file is about to be updated, but the existing source file
appears to have been edited since it was installed.

  Installed version: %(installed)s
  Current version  : %(current)s
  Updated version  : %(updated)s

Not installing the updated version can cause unpredictable results.
""",
                        versions={ "installed": full_target_path + ".org",
                                   "current": full_target_path,
                                   "updated": full_target_path + ".new" },
                        options=[ ("i", "install the updated version"),
                                  ("k", "keep the current version"),
                                  ("do", ("installed", "current")),
                                  ("dn", ("current", "updated")) ],
                        generateVersion=generateVersion)

                    install_file = update_query.prompt() == "i"
                else:
                    install_file = True

                if install_file:
                    print "Updated file: %s" % target_path
                    if not arguments.dry_run:
                        os.rename(full_target_path, backup_path)
                        renamed.append((full_target_path, backup_path))
                        copyfile(full_source_path, full_target_path)
                        created_file.append(full_target_path)
                        if not compile_file(target_path):
                            compilation_failed.append(target_path)
                    modified_files += 1
                    if isResource(target_path):
                        resources_modified = True
                    else:
                        sources_modified = True

        if target_path.startswith("hooks/"):
            mode = 0755
        else:
            mode = 0644
        if not arguments.dry_run:
            if not os.path.islink(full_target_path):
                os.chmod(full_target_path, mode)
            os.lchown(full_target_path, installation.system.uid, installation.system.gid)

    differences = installation.utils.run_git(
        [git, "diff", "--numstat", "%s..%s" % (old_sha1, new_sha1)],
        cwd=installation.root_dir)

    changed_paths = set()

    for line in differences.splitlines():
        _, _, path = map(str.strip, line.split(None, 2))
        if path.startswith("src/"):
            changed_paths.add(path[len("src/"):])
        elif not old_has_src:
            if os.path.isfile(os.path.join(target_dir, path)):
                changed_paths.add(path)

    for path in sorted(changed_paths):
        if old_has_src:
            old_source_path = os.path.join("src", path)
        else:
            old_source_path = path
        if copy(old_source_path=old_source_path,
                new_source_path=os.path.join("src", path),
                target_path=path) is False:
            return False

    if compilation_failed:
        return False

    if copied_files == 0 and modified_files == 0:
        print "No new or modified source files."

    return True

def undo():
    map(os.unlink, reversed(created_file))
    map(os.rmdir, reversed(created_dir))

    for target, backup in renamed:
        os.rename(backup, target)

def finish(mode, arguments, data):
    for target, backup in renamed:
        if os.path.isdir(backup): shutil.rmtree(backup)
        else: os.unlink(backup)

########NEW FILE########
__FILENAME__ = git
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2012 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import os
import subprocess

import installation

def install(data):
    socket_path = os.path.join(installation.paths.run_dir, "main", "sockets", "githook.unix")
    subprocess.check_call([installation.prereqs.git, "config", "--system", "critic.socket", socket_path])
    return True

########NEW FILE########
__FILENAME__ = initd
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2012 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import os
import os.path
import pwd
import grp
import subprocess

import installation

created_file = []
renamed = []

rclinks_added = False
servicemanager_started = False
servicemanager_stopped = False

def stop(identity="main"):
    global servicemanager_stopped
    servicemanager_stopped = True
    print
    try:
        subprocess.check_call(["service", "critic-%s" % identity, "stop"])
    except subprocess.CalledProcessError:
        return False

    return True

def start(identity="main"):
    print
    try:
        subprocess.check_call(["service", "critic-%s" % identity, "start"])
    except subprocess.CalledProcessError:
        return False

    return True

def restart(identity="main"):
    print
    try:
        subprocess.check_call(["service", "critic-%s" % identity, "restart"])
    except subprocess.CalledProcessError:
        return False

    return True

def install(data):
    global servicemanager_started, rclinks_added

    source_path = os.path.join(installation.root_dir, "installation", "templates", "initd")
    target_path = os.path.join("/etc", "init.d", "critic-main")

    with open(target_path, "w") as target:
        created_file.append(target_path)

        os.chmod(target_path, 0755)
        os.chown(target_path, installation.system.uid, installation.system.gid)

        with open(source_path, "r") as source:
            target.write((source.read().decode("utf-8") % data).encode("utf-8"))

    subprocess.check_call(["update-rc.d", "critic-main", "defaults"])
    rclinks_added = True

    subprocess.check_call([target_path, "start"])
    servicemanager_started = True

    return True

def upgrade(arguments, data):
    source_path = os.path.join(installation.root_dir, "installation", "templates", "initd")
    target_path = os.path.join("/etc", "init.d", "critic-main")
    backup_path = os.path.join(os.path.dirname(target_path), "_" + os.path.basename(target_path))

    source = open(source_path, "r").read().decode("utf-8") % data
    target = open(target_path, "r").read().decode("utf-8")

    system_uid = pwd.getpwnam(data["installation.system.username"]).pw_uid
    system_gid = grp.getgrnam(data["installation.system.groupname"]).gr_gid

    if source != target:
        def generateVersion(label, path):
            if label == "updated":
                with open(path, "w") as target:
                    target.write(source.encode("utf-8"))

        update_query = installation.utils.UpdateModifiedFile(
            arguments,
            message="""\
The SysV init script is about to be updated.  Please check that no local
modifications are being overwritten.

  Current version: %(current)s
  Updated version: %(updated)s

Please note that if the modifications are not installed, the system is
likely to break.
""",
            versions={ "current": target_path,
                       "updated": target_path + ".new" },
            options=[ ("i", "install the updated version"),
                      ("k", "keep the current version"),
                      ("d", ("current", "updated")) ],
            generateVersion=generateVersion)

        write_target = update_query.prompt() == "i"
    else:
        write_target = False

    if write_target:
        print "Updated file: %s" % target_path

        if not arguments.dry_run:
            os.rename(target_path, backup_path)
            renamed.append((target_path, backup_path))

            with open(target_path, "w") as target:
                created_file.append(target_path)
                os.chmod(target_path, 0755)
                os.chown(target_path, system_uid, system_gid)
                target.write(source.encode("utf-8"))

    return True

def undo():
    if servicemanager_started:
        subprocess.check_call([os.path.join("/etc", "init.d", "critic-main"), "stop"])

    map(os.unlink, created_file)

    for target, backup in renamed: os.rename(backup, target)

    if rclinks_added:
        subprocess.check_call(["update-rc.d", "critic-main", "remove"])

def finish(mode, arguments, data):
    for target, backup in renamed: os.unlink(backup)

########NEW FILE########
__FILENAME__ = input
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2012 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import sys

import inpututils

headless = False

def yes_or_no(prompt, default=None):
    if headless:
        if default is None:
            print """
ERROR: yes/no input requested in headless mode!
  Prompt: %s
""" % prompt
            sys.exit(1)
        else:
            print "%s %s" % (prompt, "y" if default else "n")
            return default

    return inpututils.yes_or_no(prompt, default)

def string(prompt, default=None, check=None):
    if headless:
        if default is None:
            print """
ERROR: string input requested in headless mode!
  Prompt: %s
""" % prompt
            sys.exit(1)
        else:
            print "%s %s" % (prompt, default)
            if not check or inpututils.apply_check(check, default):
                return default
            else:
                sys.exit(1)

    return inpututils.string(prompt, default, check)

def password(prompt, default=None, twice=True):
    if headless:
        if default is None:
            print """
ERROR: password input requested in headless mode!
  Prompt: %s
""" % prompt
            sys.exit(1)
        else:
            print "%s %s" % (prompt, "****")
            return default

    return inpututils.password(prompt, default, twice)

########NEW FILE########
__FILENAME__ = migrate
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2012 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import os
import sys
import json

import installation

def scripts_to_run(data):
    git = data["installation.prereqs.git"]
    old_sha1 = data["sha1"]
    performed_migrations = data.get("migrations", [])
    scripts = []

    if os.path.exists("installation/migrations"):
        for script in os.listdir("installation/migrations"):
            if not script.endswith(".py"):
                continue
            if script in performed_migrations:
                continue

            script_path = os.path.join("installation/migrations", script)

            if installation.utils.get_file_sha1(git, old_sha1, script_path) is not None:
                # The migration script already existed when Critic was installed
                # and there's thus no point in running it now.
                continue

            date_added = installation.utils.get_intial_commit_date(git, script_path)

            scripts.append((date_added, script))

    scripts.sort()
    scripts = [script for (date_added, script) in scripts]

    return scripts

def will_modify_dbschema(data):
    for script in scripts_to_run(data):
        if script.startswith("dbschema."):
            return True
    return False

def upgrade(arguments, data):
    if "migrations" not in data:
        data["migrations"] = []

    for script in scripts_to_run(data):
        script_path = os.path.join("installation/migrations", script)

        print
        print "Running %s ..." % script

        if arguments.dry_run:
            continue

        env = os.environ.copy()

        # This is "/etc/critic/main", set by upgrade.py, or something else
        # if the --etc-dir/--identity arguments were used.
        env["PYTHONPATH"] = sys.path[0]

        installation.process.check_input([sys.executable, script_path,
                                          "--uid=%s" % installation.system.uid,
                                          "--gid=%d" % installation.system.gid],
                                         stdin=json.dumps(data), env=env)

        data["migrations"].append(script)

    return True

########NEW FILE########
__FILENAME__ = dbschema.altertable.changesets.parent.dropnotnull
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2012 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import sys
import psycopg2
import json
import argparse
import os

parser = argparse.ArgumentParser()
parser.add_argument("--uid", type=int)
parser.add_argument("--gid", type=int)

arguments = parser.parse_args()

os.setgid(arguments.gid)
os.setuid(arguments.uid)

data = json.load(sys.stdin)

import configuration

db = psycopg2.connect(**configuration.database.PARAMETERS)
cursor = db.cursor()

# This command doesn't fail if the column already doesn't have a NOT
# NULL constraint, so no reason to catch errors or try to determine
# whether the constraint is there.
cursor.execute("ALTER TABLE changesets ALTER parent DROP NOT NULL")

db.commit()
db.close()

########NEW FILE########
__FILENAME__ = dbschema.altertable.commentchainchanges.addressed_by
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2012 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import sys
import psycopg2
import json
import argparse
import os

parser = argparse.ArgumentParser()
parser.add_argument("--uid", type=int)
parser.add_argument("--gid", type=int)

arguments = parser.parse_args()

os.setgid(arguments.gid)
os.setuid(arguments.uid)

data = json.load(sys.stdin)

db = psycopg2.connect(database="critic")
cursor = db.cursor()

try:
    # Make sure the columns don't already exist.
    cursor.execute("SELECT from_addressed_by, to_addressed_by FROM commentchainchanges")

    # Above statement should have thrown a psycopg2.ProgrammingError, but it
    # didn't, so just exit.
    sys.exit(0)
except psycopg2.ProgrammingError:
    db.rollback()
except:
    raise

cursor.execute("""ALTER TABLE commentchainchanges
                          ADD from_addressed_by INTEGER REFERENCES commits,
                          ADD to_addressed_by INTEGER REFERENCES commits""")

db.commit()
db.close()

########NEW FILE########
__FILENAME__ = dbschema.altertable.commentchainlines.drop.commit
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2012 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import sys
import psycopg2
import json
import argparse
import os

parser = argparse.ArgumentParser()
parser.add_argument("--uid", type=int)
parser.add_argument("--gid", type=int)

arguments = parser.parse_args()

os.setgid(arguments.gid)
os.setuid(arguments.uid)

data = json.load(sys.stdin)

db = psycopg2.connect(database="critic")
cursor = db.cursor()

try:
    # Check if the 'commit' column already doesn't exist.
    cursor.execute("SELECT commit FROM commentchainlines")
except psycopg2.ProgrammingError:
    # Seems it doesn't, so just exit.
    sys.exit(0)

cursor.execute("""ALTER TABLE commentchainlines DROP commit""")

db.commit()
db.close()

########NEW FILE########
__FILENAME__ = dbschema.altertable.previousreachable.rebase.ondeletecascade
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2012 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import sys
import psycopg2
import json
import argparse
import os

parser = argparse.ArgumentParser()
parser.add_argument("--uid", type=int)
parser.add_argument("--gid", type=int)

arguments = parser.parse_args()

os.setgid(arguments.gid)
os.setuid(arguments.uid)

data = json.load(sys.stdin)

db = psycopg2.connect(database="critic")
cursor = db.cursor()

# This command doesn't fail if the foreign key constraint already has
# "on delete cascade", and there's really no reason to try to figure
# if it has; easier to just drop it and re-add it.
cursor.execute("""ALTER TABLE previousreachable
                    DROP CONSTRAINT previousreachable_rebase_fkey,
                    ADD FOREIGN KEY (rebase) REFERENCES reviewrebases (id) ON DELETE CASCADE""")

db.commit()
db.close()

########NEW FILE########
__FILENAME__ = dbschema.altertable.repositories.drop.relay
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2013 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import sys
import psycopg2
import argparse
import os
import shutil

parser = argparse.ArgumentParser()
parser.add_argument("--uid", type=int)
parser.add_argument("--gid", type=int)

arguments = parser.parse_args()

os.setgid(arguments.gid)
os.setuid(arguments.uid)

import configuration

db = psycopg2.connect(**configuration.database.PARAMETERS)
cursor = db.cursor()

try:
    # Check if the 'relay' column already doesn't exist (and also fetch all the
    # relay paths for use below.)
    cursor.execute("SELECT relay FROM repositories")
except psycopg2.ProgrammingError:
    # Seems it doesn't exist, so just exit.
    sys.exit(0)

failed = False

for (relay_path,) in cursor:
    try:
        shutil.rmtree(relay_path)
    except OSError as error:
        print ("WARNING: Failed to remove directory: %s\n  Error: %s"
               % (relay_path, error))
        failed = True

if failed:
    print """
Some obsolete directories could not be removed.  They will no longer be used by
Critic, so you probably want to look into deleting them manually.
"""

cursor.execute("ALTER TABLE repositories DROP relay")

db.commit()
db.close()

########NEW FILE########
__FILENAME__ = dbschema.altertable.reviewmergeconfirmations.add.tail
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2013 Jens Lindstr√∂m
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import psycopg2
import argparse
import os

parser = argparse.ArgumentParser()
parser.add_argument("--uid", type=int)
parser.add_argument("--gid", type=int)

arguments = parser.parse_args()

os.setgid(arguments.gid)
os.setuid(arguments.uid)

import configuration

db = psycopg2.connect(**configuration.database.PARAMETERS)
cursor = db.cursor()

try:
    # Check if the 'tail' column already exists.
    cursor.execute("SELECT tail FROM reviewmergeconfirmations")
except psycopg2.ProgrammingError:
    db.rollback()
    cursor.execute("""ALTER TABLE reviewmergeconfirmations
                          ADD tail INTEGER REFERENCES commits ON DELETE CASCADE""")
    db.commit()

db.close()

########NEW FILE########
__FILENAME__ = dbschema.altertable.reviewrecipientfilters.uid-can-be-null
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2012 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import psycopg2
import argparse
import os

parser = argparse.ArgumentParser()
parser.add_argument("--uid", type=int)
parser.add_argument("--gid", type=int)

arguments = parser.parse_args()

os.setgid(arguments.gid)
os.setuid(arguments.uid)

import configuration

db = psycopg2.connect(**configuration.database.PARAMETERS)
cursor = db.cursor()

cursor.execute("""ALTER TABLE reviewrecipientfilters
                      DROP CONSTRAINT IF EXISTS reviewrecipientfilters_pkey,
                      DROP CONSTRAINT IF EXISTS reviewrecipientfilters_review_uid_key,
                      ALTER uid DROP NOT NULL,
                      ADD UNIQUE (review, uid)""")

db.commit()
db.close()

########NEW FILE########
__FILENAME__ = dbschema.altertable.systemidentities.add.installed_sha1.installed_at
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2013 Martin Olsson
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import psycopg2
import argparse
import os

parser = argparse.ArgumentParser()
parser.add_argument("--uid", type=int)
parser.add_argument("--gid", type=int)

arguments = parser.parse_args()

os.setgid(arguments.gid)
os.setuid(arguments.uid)

import configuration

db = psycopg2.connect(**configuration.database.PARAMETERS)
cursor = db.cursor()

try:
    # Check if the 'installed_sha1' column already exists.
    cursor.execute("SELECT installed_sha1 FROM systemidentities")
except psycopg2.ProgrammingError:
    db.rollback()
    cursor.execute("ALTER TABLE systemidentities ADD installed_sha1 CHAR(40)")
    cursor.execute("UPDATE systemidentities SET installed_sha1=''")
    cursor.execute("ALTER TABLE systemidentities ALTER installed_sha1 SET NOT NULL")
    db.commit()

try:
    # Check if the 'installed_at' column already exists.
    cursor.execute("SELECT installed_at FROM systemidentities")
except psycopg2.ProgrammingError:
    db.rollback()
    cursor.execute("ALTER TABLE systemidentities ADD installed_at TIMESTAMP DEFAULT NOW()")
    cursor.execute("ALTER TABLE systemidentities ALTER installed_at SET NOT NULL")
    db.commit()

db.close()

########NEW FILE########
__FILENAME__ = dbschema.altertable.systemidentities.url-prefix
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2013 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import sys
import psycopg2
import argparse
import os

parser = argparse.ArgumentParser()
parser.add_argument("--uid", type=int)
parser.add_argument("--gid", type=int)

arguments = parser.parse_args()

os.setgid(arguments.gid)
os.setuid(arguments.uid)

import configuration

db = psycopg2.connect(**configuration.database.PARAMETERS)
cursor = db.cursor()

try:
    cursor.execute("SELECT key, url_prefix FROM systemidentities")
except psycopg2.ProgrammingError:
    # We seem to have converted the table already, so just exit.
    sys.exit(0)

url_prefixes = cursor.fetchall()

cursor.execute("""ALTER TABLE systemidentities
                      DROP url_prefix,
                      ADD anonymous_scheme VARCHAR(5),
                      ADD authenticated_scheme VARCHAR(5),
                      ADD hostname VARCHAR(256)""")

if configuration.base.ACCESS_SCHEME in ("http", "https"):
    anonymous_scheme = authenticated_scheme = configuration.base.ACCESS_SCHEME
else:
    anonymous_scheme = "http"
    authenticated_scheme = "https"

for key, url_prefix in url_prefixes:
    if url_prefix.lower().startswith("https://"):
        hostname = url_prefix[len("https://"):]
    elif url_prefix.lower().startswith("http://"):
        hostname = url_prefix[len("http://"):]
    else:
        # This would only happen if the system administrator manually
        # modified the 'systemidentities' table, and any URL constructed
        # with this URL prefix in the past would most likely have been
        # broken already.

        print """\
WARNING: System identity %s's URL prefix was not recognized as either
         HTTP or HTTPS.  It's assumed to be a plain hostname.

The URL prefix was: %r""" % (key, url_prefix)

        hostname = url_prefix

    cursor.execute("""UPDATE systemidentities
                         SET anonymous_scheme=%s,
                             authenticated_scheme=%s,
                             hostname=%s
                       WHERE key=%s""",
                   (anonymous_scheme, authenticated_scheme, hostname, key))

cursor.execute("""ALTER TABLE systemidentities
                      ALTER anonymous_scheme SET NOT NULL,
                      ALTER authenticated_scheme SET NOT NULL,
                      ALTER hostname SET NOT NULL""")

db.commit()
db.close()

########NEW FILE########
__FILENAME__ = dbschema.altertable.usergitemails
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2014 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import sys
import psycopg2
import json
import argparse
import os

parser = argparse.ArgumentParser()
parser.add_argument("--uid", type=int)
parser.add_argument("--gid", type=int)

arguments = parser.parse_args()

os.setgid(arguments.gid)
os.setuid(arguments.uid)

data = json.load(sys.stdin)

import configuration

db = psycopg2.connect(**configuration.database.PARAMETERS)
cursor = db.cursor()

# It's tricky to check whether constraints and indexes already exist,
# so this script simply attempts to run commands that won't fail even
# if run multiple times.

cursor.execute("""ALTER TABLE usergitemails
                    DROP CONSTRAINT IF EXISTS usergitemails_pkey,
                    ADD PRIMARY KEY (email, uid)""")

cursor.execute("DROP INDEX IF EXISTS usergitemails_uid")
cursor.execute("CREATE INDEX usergitemails_uid ON usergitemails (uid)")

db.commit()
db.close()

########NEW FILE########
__FILENAME__ = dbschema.createindex.misc
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2012 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import sys
import psycopg2
import json
import argparse
import os

parser = argparse.ArgumentParser()
parser.add_argument("--uid", type=int)
parser.add_argument("--gid", type=int)

arguments = parser.parse_args()

os.setgid(arguments.gid)
os.setuid(arguments.uid)

data = json.load(sys.stdin)

db = psycopg2.connect(database="critic")
cursor = db.cursor()

def create_index(table, columns):
    name = "%s_%s" % (table, "_".join(columns))
    cursor.execute("DROP INDEX IF EXISTS %s" % name)
    cursor.execute("CREATE INDEX %s ON %s (%s)" % (name, table, ", ".join(columns)))

# Replaced by index over 'uid' and 'state'.
cursor.execute("DROP INDEX IF EXISTS reviewfilechanges_uid")

create_index("reviewfiles", ["review", "state"])
create_index("reviewfilechanges", ["uid", "state"])
create_index("commentchains", ["review", "type", "state"])
create_index("comments", ["id", "chain"])

db.commit()
db.close()

########NEW FILE########
__FILENAME__ = dbschema.createtable.knownremotes
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2012 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import sys
import psycopg2
import json
import argparse
import os

parser = argparse.ArgumentParser()
parser.add_argument("--uid", type=int)
parser.add_argument("--gid", type=int)

arguments = parser.parse_args()

os.setgid(arguments.gid)
os.setuid(arguments.uid)

data = json.load(sys.stdin)

db = psycopg2.connect(database="critic")
cursor = db.cursor()

try:
    # Make sure the table doesn't already exist.
    cursor.execute("SELECT 1 FROM knownremotes")

    # Above statement should have thrown a psycopg2.ProgrammingError, but it
    # didn't, so just exit.
    sys.exit(0)
except psycopg2.ProgrammingError:
    db.rollback()
except:
    raise

cursor.execute("""CREATE TABLE knownremotes
                    ( url VARCHAR(256) PRIMARY KEY,
                      pushing BOOLEAN NOT NULL
                    )""")

db.commit()
db.close()

########NEW FILE########
__FILENAME__ = dbschema.createtable.timezones
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2012 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import sys
import psycopg2
import json
import argparse
import os
import datetime

parser = argparse.ArgumentParser()
parser.add_argument("--uid", type=int)
parser.add_argument("--gid", type=int)

arguments = parser.parse_args()

os.setgid(arguments.gid)
os.setuid(arguments.uid)

data = json.load(sys.stdin)

db = psycopg2.connect(database="critic")
cursor = db.cursor()

try:
    # Make sure the table doesn't already exist.
    cursor.execute("SELECT 1 FROM timezones")

    # Above statement should have thrown a psycopg2.ProgrammingError, but it
    # didn't, so just exit.
    sys.exit(0)
except psycopg2.ProgrammingError:
    db.rollback()

cursor.execute("""CREATE TABLE timezones
                    ( name VARCHAR(256) PRIMARY KEY,
                      abbrev VARCHAR(16) NOT NULL,
                      utc_offset INTERVAL NOT NULL )""")

# Additional timezones are copied from 'pg_timezone_names' by the Watchdog
# service on startup.

cursor.execute("INSERT INTO timezones (name, abbrev, utc_offset) VALUES (%s, %s, %s)",
               ("Universal/UTC", "UTC", datetime.timedelta()))

db.commit()
db.close()

########NEW FILE########
__FILENAME__ = dbschema.createtable.useremails
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2014 the Critic contributors, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import sys
import psycopg2
import json
import argparse
import os

parser = argparse.ArgumentParser()
parser.add_argument("--uid", type=int)
parser.add_argument("--gid", type=int)

arguments = parser.parse_args()

os.setgid(arguments.gid)
os.setuid(arguments.uid)

data = json.load(sys.stdin)

import configuration

db = psycopg2.connect(**configuration.database.PARAMETERS)
cursor = db.cursor()

try:
    # Make sure the table doesn't already exist.
    cursor.execute("SELECT 1 FROM useremails")

    # Above statement should have thrown a psycopg2.ProgrammingError, but it
    # didn't, so just exit.
    sys.exit(0)
except psycopg2.ProgrammingError: db.rollback()
except: raise

# Create the table.
cursor.execute("""CREATE TABLE useremails
                    ( id SERIAL PRIMARY KEY,
                      uid INTEGER NOT NULL REFERENCES users ON DELETE CASCADE,
                      email VARCHAR(256) NOT NULL,
                      verified BOOLEAN,
                      verification_token VARCHAR(256),

                      UNIQUE (uid, email) )""")

# Create records for all current email addresses in the system.  Set verified to
# NULL which means the addresses can be used, but that they haven't gone through
# the verification process.
cursor.execute("""INSERT INTO useremails (uid, email)
                       SELECT id, email
                         FROM users
                        WHERE email IS NOT NULL""")

# Drop the old 'users.email' column.
cursor.execute("ALTER TABLE users DROP email")

# And create a new one based on the information we copied over to the new table.
cursor.execute("ALTER TABLE users ADD email INTEGER REFERENCES useremails")
cursor.execute("SELECT id, uid FROM useremails")
cursor.executemany("UPDATE users SET email=%s WHERE id=%s", cursor.fetchall())

db.commit()
db.close()

########NEW FILE########
__FILENAME__ = dbschema.createtable.usersessions
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2012 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import sys
import psycopg2
import json
import argparse
import os

parser = argparse.ArgumentParser()
parser.add_argument("--uid", type=int)
parser.add_argument("--gid", type=int)

arguments = parser.parse_args()

os.setgid(arguments.gid)
os.setuid(arguments.uid)

data = json.load(sys.stdin)

import configuration

db = psycopg2.connect(**configuration.database.PARAMETERS)
cursor = db.cursor()

try:
    # Make sure the table doesn't already exist.
    cursor.execute("SELECT 1 FROM usersessions")

    # Above statement should have thrown a psycopg2.ProgrammingError, but it
    # didn't, so just exit.
    sys.exit(0)
except psycopg2.ProgrammingError: db.rollback()
except: raise

cursor.execute("""CREATE TABLE usersessions
                    ( key CHAR(28) PRIMARY KEY,
                      uid INTEGER NOT NULL REFERENCES users,
                      atime TIMESTAMP DEFAULT NOW() )""")

db.commit()
db.close()

########NEW FILE########
__FILENAME__ = dbschema.droptable.knownhosts
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2013 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import sys
import psycopg2
import argparse
import os

parser = argparse.ArgumentParser()
parser.add_argument("--uid", type=int)
parser.add_argument("--gid", type=int)

arguments = parser.parse_args()

os.setgid(arguments.gid)
os.setuid(arguments.uid)

import configuration

db = psycopg2.connect(**configuration.database.PARAMETERS)
cursor = db.cursor()

try:
    cursor.execute("SELECT 1 FROM knownhosts")
except psycopg2.ProgrammingError:
    # Seems it doesn't exist, so just exit.
    sys.exit(0)

cursor.execute("DROP TABLE knownhosts")

db.commit()
db.close()

########NEW FILE########
__FILENAME__ = dbschema.external-authentication
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2014 the Critic contributors, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import psycopg2
import argparse
import os

parser = argparse.ArgumentParser()
parser.add_argument("--uid", type=int)
parser.add_argument("--gid", type=int)

arguments = parser.parse_args()

os.setgid(arguments.gid)
os.setuid(arguments.uid)

import configuration

db = psycopg2.connect(**configuration.database.PARAMETERS)
cursor = db.cursor()

def create(table_name, statement):
    try:
        # Make sure the table doesn't already exist.
        cursor.execute("SELECT 1 FROM %s" % table_name)

        # Above statement would have thrown a psycopg2.ProgrammingError if the
        # table didn't exist, but it didn't, so assume the table doesn't need to
        # be added.
        return
    except psycopg2.ProgrammingError:
        db.rollback()

    cursor.execute(statement)
    db.commit()

create("externalusers", """

CREATE TABLE externalusers
  ( id SERIAL PRIMARY KEY,
    uid INTEGER REFERENCES users,
    provider VARCHAR(16) NOT NULL,
    account VARCHAR(256) NOT NULL,
    email VARCHAR(256),
    token VARCHAR(256),

    UNIQUE (provider, account) );

""")

create("oauthstates", """

CREATE TABLE oauthstates
  ( state VARCHAR(64) PRIMARY KEY,
    url TEXT,
    time TIMESTAMP NOT NULL DEFAULT NOW() );

""")

db.commit()
db.close()

########NEW FILE########
__FILENAME__ = dbschema.files-and-directories
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2013 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import sys
import psycopg2
import json
import argparse
import os

parser = argparse.ArgumentParser()
parser.add_argument("--uid", type=int)
parser.add_argument("--gid", type=int)

arguments = parser.parse_args()

os.setgid(arguments.gid)
os.setuid(arguments.uid)

data = json.load(sys.stdin)

import configuration

db = psycopg2.connect(**configuration.database.PARAMETERS)
cursor = db.cursor()

def column_exists(table, column):
    try:
        cursor.execute("SELECT %s FROM %s LIMIT 1" % (column, table))
        return True
    except psycopg2.ProgrammingError:
        db.rollback()
        return False

added = [column_exists("files", "path"),
         column_exists("filters", "path"),
         column_exists("reviewfilters", "path")]

removed = [column_exists("files", "directory"),
           column_exists("files", "name"),
           column_exists("filters", "directory"),
           column_exists("filters", "file"),
           column_exists("reviewfilters", "directory"),
           column_exists("reviewfilters", "file"),
           column_exists("directories", "id")]

if all(added) and not any(removed):
    # All expected modifications appear to have taken place already.
    sys.exit(0)
elif any(added) or not all(removed):
    # Some modifications appear to have taken place already, but not
    # all.  This is bad, and possibly unrecoverable.  It's probably
    # not a good idea to just run the commands below.
    sys.stderr.write("""\
The database schema appears to be in an inconsistent state!

Please see installation/migrations/dbschema.files-and-directories.py
and try to figure out which of the commands in it to run.

Alternatively, restore a database backup from before the previous
upgrade attempt, and then try running upgrade.py again.
""")
    sys.exit(1)

# Add 'path' column to 'files' table.
cursor.execute("ALTER TABLE files ADD path TEXT")
cursor.execute("UPDATE files SET path=fullfilename(id)")
cursor.execute("ALTER TABLE files ALTER path SET NOT NULL")
cursor.execute("CREATE UNIQUE INDEX files_path_md5 ON files (MD5(path))")
cursor.execute("CREATE INDEX files_path_gin ON files USING gin (STRING_TO_ARRAY(path, '/'))")

# Modify 'filters' table similarly.
cursor.execute("ALTER TABLE filters ADD path TEXT")
cursor.execute("UPDATE filters SET path=fullfilename(file) WHERE file>0")
cursor.execute("UPDATE filters SET path=COALESCE(NULLIF(fulldirectoryname(directory), ''), '/') WHERE file=0")
cursor.execute("ALTER TABLE filters ALTER path SET NOT NULL")
cursor.execute("CREATE UNIQUE INDEX filters_repository_uid_path_md5 ON filters (repository, uid, MD5(path))")

# Modify 'reviewfilters' table similarly.
cursor.execute("ALTER TABLE reviewfilters ADD path TEXT")
cursor.execute("UPDATE reviewfilters SET path=fullfilename(file) WHERE file>0")
cursor.execute("UPDATE reviewfilters SET path=COALESCE(NULLIF(fulldirectoryname(directory), ''), '/') WHERE file=0")
cursor.execute("ALTER TABLE reviewfilters ALTER path SET NOT NULL")
cursor.execute("CREATE UNIQUE INDEX reviewfilters_review_uid_path_md5 ON reviewfilters (review, uid, MD5(path))")

# Modify 'reviewfilterchanges' table similarly.
cursor.execute("ALTER TABLE reviewfilterchanges ADD path TEXT")
cursor.execute("UPDATE reviewfilterchanges SET path=fullfilename(file) WHERE file>0")
cursor.execute("UPDATE reviewfilterchanges SET path=fulldirectoryname(directory) WHERE file=0")
cursor.execute("ALTER TABLE reviewfilterchanges ALTER path SET NOT NULL")

# Drop the now redundant 'directories' table.
cursor.execute("ALTER TABLE files DROP directory, DROP name")
cursor.execute("ALTER TABLE filters DROP directory, DROP file, DROP specificity")
cursor.execute("ALTER TABLE reviewfilters DROP directory, DROP file")
cursor.execute("ALTER TABLE reviewfilterchanges DROP directory, DROP file")
cursor.execute("DROP TABLE directories")

# Drop various utility functions that are no longer necessary.
cursor.execute("DROP FUNCTION IF EXISTS filepath()")
cursor.execute("DROP FUNCTION IF EXISTS directorypath()")
cursor.execute("DROP FUNCTION IF EXISTS subdirectories()")
cursor.execute("DROP FUNCTION IF EXISTS containedfiles()")
cursor.execute("DROP FUNCTION IF EXISTS fullfilename()")
cursor.execute("DROP FUNCTION IF EXISTS fulldirectoryname()")
cursor.execute("DROP FUNCTION IF EXISTS findfile()")
cursor.execute("DROP FUNCTION IF EXISTS finddirectory()")

db.commit()

# ALTER TYPE ... ADD VALUE cannot be executed inside a transaction block.
db.autocommit = True
# Add filter type "ignored".
cursor.execute("ALTER TYPE filtertype ADD VALUE 'ignored'")

db.close()

########NEW FILE########
__FILENAME__ = dbschema.fixup-extensionroles
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2014 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import sys
import psycopg2
import argparse
import os

parser = argparse.ArgumentParser()
parser.add_argument("--uid", type=int)
parser.add_argument("--gid", type=int)

arguments = parser.parse_args()

os.setgid(arguments.gid)
os.setuid(arguments.uid)

import configuration

db = psycopg2.connect(**configuration.database.PARAMETERS)
cursor = db.cursor()

try:
    # The extensions part of the database schema might not have been loaded at
    # all; it isn't until extend.py is used to enable extensions support.
    cursor.execute("SELECT 1 FROM extensions")
except psycopg2.ProgrammingError:
    sys.exit(0)

cursor.execute("""SELECT id, version, script, function,
                         extensionpageroles.path,
                         extensioninjectroles.path,
                         extensionprocesscommitsroles.role IS NULL
                    FROM extensionroles
         LEFT OUTER JOIN extensionpageroles
                      ON (extensionpageroles.role=id)
         LEFT OUTER JOIN extensioninjectroles
                      ON (extensioninjectroles.role=id)
         LEFT OUTER JOIN extensionprocesscommitsroles
                      ON (extensionprocesscommitsroles.role=id)""")

roles = set()
duplicates = []

for row in cursor:
    role_id = row[0]
    role_key = row[1:]

    if role_key in roles:
        duplicates.append(role_id)
    else:
        roles.add(role_key)

if duplicates:
    print "Removing %d duplicate rows from extensionroles." % len(duplicates)
    cursor.execute("DELETE FROM extensionroles WHERE id=ANY (%s)", (duplicates,))

db.commit()
db.close()

########NEW FILE########
__FILENAME__ = dbschema.per-repository-or-filter-preferences
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2013 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import sys
import psycopg2
import argparse
import os

parser = argparse.ArgumentParser()
parser.add_argument("--uid", type=int)
parser.add_argument("--gid", type=int)

arguments = parser.parse_args()

os.setgid(arguments.gid)
os.setuid(arguments.uid)

import configuration

db = psycopg2.connect(**configuration.database.PARAMETERS)
cursor = db.cursor()

def column_exists(table, column):
    try:
        cursor.execute("SELECT %s FROM %s LIMIT 1" % (column, table))
        return True
    except psycopg2.ProgrammingError:
        db.rollback()
        return False

added = [column_exists("preferences", "per_system"),
         column_exists("preferences", "per_user"),
         column_exists("preferences", "per_repository"),
         column_exists("preferences", "per_filter"),
         column_exists("userpreferences", "repository"),
         column_exists("userpreferences", "filter")]

removed = [column_exists("preferences", "default_string"),
           column_exists("preferences", "default_integer")]

if all(added) and not any(removed):
    # All expected modifications appear to have taken place already.
    sys.exit(0)
elif any(added) or not all(removed):
    # Some modifications appear to have taken place already, but not
    # all.  This is bad, and possibly unrecoverable.  It's probably
    # not a good idea to just run the commands below.
    sys.stderr.write("""\
The database schema appears to be in an inconsistent state!

Please see
  installation/migrations/dbschema.per-repository-or-filter-preferences.py
and try to figure out which of the commands in it to run.

Alternatively, restore a database backup from before the previous
upgrade attempt, and then try running upgrade.py again.
""")
    sys.exit(1)

# Drop the exiting 'userpreferences' PRIMARY KEY, since it conflicts with having
# multiple settings for different repositories and filters.
cursor.execute("""ALTER TABLE userpreferences
                      DROP CONSTRAINT userpreferences_pkey""")

# Add new columns to 'preferences'.
cursor.execute("""ALTER TABLE preferences
                      ADD per_system BOOLEAN NOT NULL DEFAULT TRUE,
                      ADD per_user BOOLEAN NOT NULL DEFAULT TRUE,
                      ADD per_repository BOOLEAN NOT NULL DEFAULT FALSE,
                      ADD per_filter BOOLEAN NOT NULL DEFAULT FALSE""")

# Add new columns to 'userpreferences'.
cursor.execute("""ALTER TABLE userpreferences
                      ALTER uid DROP NOT NULL,
                      ADD repository INTEGER REFERENCES repositories ON DELETE CASCADE,
                      ADD filter INTEGER REFERENCES filters ON DELETE CASCADE""")

# Move current system-wide default values over to the 'userpreferences' table as
# rows with uid=NULL.
cursor.execute("""INSERT INTO userpreferences (item, integer, string)
                       SELECT item, default_integer, default_string
                         FROM preferences""")

# Drop old default value columns from 'preferences'.
cursor.execute("""ALTER TABLE preferences
                      DROP default_string,
                      DROP default_integer""")

# Add new constraints to 'userpreferences'.
cursor.execute("""ALTER TABLE userpreferences
                      ADD CONSTRAINT check_uid_filter
                               CHECK (filter IS NULL OR uid IS NOT NULL),
                      ADD CONSTRAINT check_repository_filter
                               CHECK (repository IS NULL OR filter IS NULL)""")

# Add indexes used to check various uniqueness requirements involving NULL
# values.
cursor.execute("""CREATE UNIQUE INDEX userpreferences_item
                                   ON userpreferences (item)
                                WHERE uid IS NULL
                                  AND repository IS NULL
                                  AND filter IS NULL""")
cursor.execute("""CREATE UNIQUE INDEX userpreferences_item_uid
                                   ON userpreferences (item, uid)
                                WHERE uid IS NOT NULL
                                  AND repository IS NULL
                                  AND filter IS NULL""")
cursor.execute("""CREATE UNIQUE INDEX userpreferences_item_repository
                                   ON userpreferences (item, repository)
                                WHERE uid IS NULL
                                  AND repository IS NOT NULL
                                  AND filter IS NULL""")
cursor.execute("""CREATE UNIQUE INDEX userpreferences_item_uid_repository
                                   ON userpreferences (item, uid, repository)
                                WHERE uid IS NOT NULL
                                  AND repository IS NOT NULL
                                  AND filter IS NULL""")
cursor.execute("""CREATE UNIQUE INDEX userpreferences_item_uid_filter
                                   ON userpreferences (item, uid, filter)
                                WHERE uid IS NOT NULL
                                  AND repository IS NULL
                                  AND filter IS NOT NULL""")

db.commit()
db.close()

########NEW FILE########
__FILENAME__ = dbschema.review-constraints-tweaking
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2013 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import psycopg2
import argparse
import os

parser = argparse.ArgumentParser()
parser.add_argument("--uid", type=int)
parser.add_argument("--gid", type=int)

arguments = parser.parse_args()

os.setgid(arguments.gid)
os.setuid(arguments.uid)

import configuration

db = psycopg2.connect(**configuration.database.PARAMETERS)
cursor = db.cursor()

try:
    cursor.execute("CREATE INDEX reviewmessageids_review ON reviewmessageids (review)")
except psycopg2.ProgrammingError:
    # The index probably already exists.
    db.rollback()
else:
    db.commit()

cursor.execute("""ALTER TABLE branches
                    DROP CONSTRAINT IF EXISTS branches_review_fkey,
                    ADD CONSTRAINT branches_review_fkey
                      FOREIGN KEY (review) REFERENCES reviews ON DELETE CASCADE""")

cursor.execute("""ALTER TABLE checkbranchnotes
                    DROP CONSTRAINT IF EXISTS checkbranchnotes_review_fkey,
                    ADD CONSTRAINT checkbranchnotes_review_fkey
                      FOREIGN KEY (review) REFERENCES reviews ON DELETE CASCADE""")

db.commit()
db.close()

########NEW FILE########
__FILENAME__ = installation.config-pyc-file-permissions
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2013 Martin Olsson
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import os
import argparse

parser = argparse.ArgumentParser()
parser.add_argument("--uid", type=int)
parser.add_argument("--gid", type=int)

arguments = parser.parse_args()

os.setgid(arguments.gid)
os.setuid(arguments.uid)

import configuration

config_dir = os.path.dirname(configuration.__file__)
for entry in os.listdir(config_dir):
    if entry.endswith(".py"):
        if entry.startswith("_") and os.path.exists(os.path.join(config_dir, entry[1:])):
            # If the upgrade modifies a configuration file, say file.py, it
            # will keep a backup of the file stored as _file.py (also in the
            # configuration directory) and there won't be a pyc file for the
            # backup, so skip ahead to avoid unnecessarily printing the below warning.
            continue
        config_file = os.path.join(config_dir, entry)
        pyc_file = config_file + "c"
        try:
            os.chmod(pyc_file, os.stat(config_file).st_mode)
        except Exception as e:
            print("WARNING: installation.config-pyc-file-permissions.py "
                  "failed to restrict file permissions for '%s'. Please make "
                  "sure all .pyc files in the Critic configuration directory "
                  "exists, belongs to critic:critic and are chmod'd similar "
                  "to the corresponding .py file. The specific error "
                  "reported was: %s" % (pyc_file, e))

########NEW FILE########
__FILENAME__ = news.filter-system-rewrite
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2013 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import sys
import psycopg2
import json
import argparse
import os

parser = argparse.ArgumentParser()
parser.add_argument("--uid", type=int)
parser.add_argument("--gid", type=int)

arguments = parser.parse_args()

os.setgid(arguments.gid)
os.setuid(arguments.uid)

data = json.load(sys.stdin)

import configuration

db = psycopg2.connect(**configuration.database.PARAMETERS)
cursor = db.cursor()

text = """\
Improved Filters
================

Critic's Filters mechanism has been improved, in two significant ways:

* filter paths can now contain wildcards, and
* a third filter type, <b>Ignored</b>, has been added, that can be
  used to exclude some files or directories otherwise matched by other
  filters.

For more details, see the (new)
  <a href='/tutorial?item=filters'>tutorial on the subject of filters</a>.

The UI for managing filters on your
  <a href='/home'>Home page</a>
has also been significantly changed; now displaying all filter in all
repositories instead of only filters in a selected repository."""

cursor.execute("SELECT id FROM newsitems WHERE text=%s", (text,))

if cursor.fetchone():
    # Identical news item already exists.
    sys.exit(0)

cursor.execute("INSERT INTO newsitems (text) VALUES (%s)", (text,))

db.commit()
db.close()

########NEW FILE########
__FILENAME__ = news.review-quick-search
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2013 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import sys
import psycopg2
import json
import argparse
import os

parser = argparse.ArgumentParser()
parser.add_argument("--uid", type=int)
parser.add_argument("--gid", type=int)

arguments = parser.parse_args()

os.setgid(arguments.gid)
os.setuid(arguments.uid)

data = json.load(sys.stdin)

import configuration

db = psycopg2.connect(**configuration.database.PARAMETERS)
cursor = db.cursor()

text = """\
Review Quick Search
===================

Critic's mechanism for searching for reviews has been upgraded.  The existing
  <a href=/search>search page</a>
has been made somewhat more user-friendly and capable.

More significantly, a new "quick search" feature has been added, which is a
search dialog activated by pressing the <code>F</code> key on any Critic page
(for instance this one.)  This dialog allows input of a search query and can be
used to perform the same searches as the main search page.

For more details, see the (new)
  <a href='/tutorial?item=search'>tutorial on the subject of searching</a>."""

cursor.execute("SELECT id FROM newsitems WHERE text=%s", (text,))

if cursor.fetchone():
    # Identical news item already exists.
    sys.exit(0)

cursor.execute("INSERT INTO newsitems (text) VALUES (%s)", (text,))

db.commit()
db.close()

########NEW FILE########
__FILENAME__ = preference.commit.diff.rulerColumn
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2013 Rafa≈Ç Ch≈Çodnicki, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import sys
import psycopg2
import json
import argparse
import os

parser = argparse.ArgumentParser()
parser.add_argument("--uid", type=int)
parser.add_argument("--gid", type=int)

arguments = parser.parse_args()

os.setgid(arguments.gid)
os.setuid(arguments.uid)

data = json.load(sys.stdin)

db = psycopg2.connect(database="critic")
cursor = db.cursor()

# Make sure the preference doesn't already exist.
cursor.execute("SELECT 1 FROM preferences WHERE item=%s", ("commit.diff.rulerColumn",))

if cursor.fetchone():
    sys.exit(0)

cursor.execute("INSERT INTO preferences (item, type, default_integer, description) VALUES (%s, %s, %s, %s)",
               ("commit.diff.rulerColumn", "integer", 0,
                "The column at which a ruler is shown. Can be set to 0 to disable the ruler."))

db.commit()
db.close()

########NEW FILE########
__FILENAME__ = paths
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2012 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import os
import shutil

import installation

etc_dir = "/etc/critic"
install_dir = "/usr/share/critic"
data_dir = "/var/lib/critic"
cache_dir = "/var/cache/critic"
git_dir = "/var/git"
log_dir = "/var/log/critic"
run_dir = "/var/run/critic"

def prepare(mode, arguments, data):
    global etc_dir, install_dir, data_dir, cache_dir, git_dir, log_dir, run_dir

    if mode == "install":
        all_ok = True

        print """
Critic Installation: Paths
==========================
"""

        def is_good_dir(path):
            if not path: return "empty path"
            elif not path.startswith("/"): return "must be an absolute path"
            elif os.path.exists(path) and not os.path.isdir(path):
                return "exists and is not a directory"

        def is_new_dir(path):
            error = is_good_dir(path)
            if error: return error
            if os.path.exists(path):
                return "directory already exists (NOTE: if Critic is already " \
                       "installed and you want to upgrade to the latest " \
                       "version of Critic, then run upgrade.py rather than " \
                       "re-running install.py)"

        if arguments.etc_dir:
            error = is_new_dir(arguments.etc_dir)
            if error:
                print "Invalid --etc-dir argument: %s." % error
                return False
            etc_dir = arguments.etc_dir
        else:
            all_ok = False
            etc_dir = installation.input.string(prompt="Where should Critic's configuration files be installed?",
                                                default=etc_dir,
                                                check=is_new_dir)

        if arguments.install_dir:
            error = is_new_dir(arguments.install_dir)
            if error:
                print "Invalid --install-dir argument: %s." % error
                return False
            install_dir = arguments.install_dir
        else:
            all_ok = False
            install_dir = installation.input.string(prompt="Where should Critic's source code be installed?",
                                                    default=install_dir,
                                                    check=is_new_dir)

        if arguments.data_dir:
            error = is_new_dir(arguments.data_dir)
            if error:
                print "Invalid --data-dir argument: %s." % error
                return False
            data_dir = arguments.data_dir
        else:
            all_ok = False
            data_dir = installation.input.string(prompt="Where should Critic's persistent data files live?",
                                                 default=data_dir,
                                                 check=is_new_dir)

        if arguments.cache_dir:
            error = is_new_dir(arguments.cache_dir)
            if error:
                print "Invalid --cache-dir argument: %s." % error
                return False
            cache_dir = arguments.cache_dir
        else:
            all_ok = False
            cache_dir = installation.input.string(prompt="Where should Critic's temporary data files live?",
                                                  default=cache_dir,
                                                  check=is_new_dir)

        if arguments.git_dir:
            error = is_new_dir(arguments.git_dir)
            if error:
                print "Invalid --git-dir argument: %s." % error
                return False
            git_dir = arguments.git_dir
        else:
            all_ok = False
            git_dir = installation.input.string(prompt="Where should Critic's Git repositories live?",
                                                default=git_dir,
                                                check=is_new_dir)

        if arguments.log_dir:
            error = is_new_dir(arguments.log_dir)
            if error:
                print "Invalid --log-dir argument: %s." % error
                return False
            log_dir = arguments.log_dir
        else:
            all_ok = False
            log_dir = installation.input.string(prompt="Where should Critic's log files live?",
                                                default=log_dir,
                                                check=is_good_dir)

        if arguments.run_dir:
            error = is_new_dir(arguments.run_dir)
            if error:
                print "Invalid --run-dir argument: %s." % error
                return False
            run_dir = arguments.run_dir
        else:
            all_ok = False
            run_dir = installation.input.string(prompt="Where should Critic's runtime files live?",
                                                default=run_dir,
                                                check=is_good_dir)

        if all_ok: print "All okay."
    else:
        import configuration

        def strip_identity(path):
            if os.path.basename(path) == configuration.base.SYSTEM_IDENTITY:
                return os.path.dirname(path)
            else:
                return path

        etc_dir = strip_identity(configuration.paths.CONFIG_DIR)
        install_dir = configuration.paths.INSTALL_DIR
        data_dir = configuration.paths.DATA_DIR
        cache_dir = strip_identity(configuration.paths.CACHE_DIR)
        git_dir = configuration.paths.GIT_DIR
        log_dir = strip_identity(configuration.paths.LOG_DIR)
        run_dir = strip_identity(configuration.paths.RUN_DIR)

    data["installation.paths.etc_dir"] = etc_dir
    data["installation.paths.install_dir"] = install_dir
    data["installation.paths.data_dir"] = data_dir
    data["installation.paths.cache_dir"] = cache_dir
    data["installation.paths.git_dir"] = git_dir
    data["installation.paths.log_dir"] = log_dir
    data["installation.paths.run_dir"] = run_dir

    return True

created = []

def mkdir(path, mode=0750):
    global created
    if not os.path.isdir(path):
        if not os.path.isdir(os.path.dirname(path)):
            mkdir(os.path.dirname(path), mode)

        print "Creating directory '%s' ..." % path
        os.mkdir(path, mode)
        created.append(path)
        os.chown(path, installation.system.uid, installation.system.gid)

def mkdirs():
    import stat

    mkdir(os.path.join(etc_dir, "main"))
    mkdir(install_dir, 0755)
    mkdir(os.path.join(data_dir, "relay"))
    mkdir(os.path.join(data_dir, "temporary"))
    mkdir(os.path.join(data_dir, "outbox", "sent"), mode=0700)
    mkdir(os.path.join(cache_dir, "main", "highlight"))
    mkdir(git_dir)
    mkdir(os.path.join(log_dir, "main"))
    mkdir(os.path.join(run_dir, "main", "sockets"))
    mkdir(os.path.join(run_dir, "main", "wsgi"))

    if installation.config.coverage_dir:
        mkdir(installation.config.coverage_dir)

    os.chmod(git_dir, 0770 | stat.S_ISUID | stat.S_ISGID)

def install(data):
    mkdirs()
    return True

def upgrade(arguments, data):
    mkdirs()
    return True

def undo():
    map(shutil.rmtree, reversed(created))

########NEW FILE########
__FILENAME__ = prefs
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2012 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import os
import json
import textwrap
import subprocess

import installation

def add_preference(db, item, data, silent=False):
    relevance = data.get("relevance", {})

    cursor = db.cursor()
    cursor.execute("""INSERT INTO preferences (item, type, description,
                                               per_system, per_user,
                                               per_repository, per_filter)
                           VALUES (%s, %s, %s, %s, %s, %s, %s)""",
                   (item, data["type"], data["description"],
                    relevance.get("system", True), relevance.get("user", True),
                    relevance.get("repository", False), relevance.get("filter", False)))

    if data["type"] == "string":
        cursor.execute("""INSERT INTO userpreferences (item, string)
                               VALUES (%s, %s)""",
                       (item, data["default"]))
    else:
        cursor.execute("""INSERT INTO userpreferences (item, integer)
                               VALUES (%s, %s)""",
                       (item, int(data["default"])))

    if not silent:
        print "Added preference: '%s'" % item

def update_preference(db, item, data, type_changed):
    relevance = data.get("relevance", {})

    cursor = db.cursor()
    cursor.execute("""UPDATE preferences
                         SET type=%s,
                             description=%s,
                             per_system=%s,
                             per_user=%s,
                             per_repository=%s,
                             per_filter=%s
                       WHERE item=%s""",
                   (data["type"], data["description"],
                    relevance.get("system", True), relevance.get("user", True),
                    relevance.get("repository", False), relevance.get("filter", False),
                    item))

    if data["type"] == "string":
        cursor.execute("""UPDATE userpreferences
                             SET integer=NULL,
                                 string=%s
                           WHERE item=%s
                             AND uid IS NULL
                             AND repository IS NULL""",
                       (data["default"], item))
    else:
        cursor.execute("""UPDATE userpreferences
                             SET integer=%s,
                                 string=NULL
                           WHERE item=%s
                             AND uid IS NULL
                             AND repository IS NULL""",
                       (int(data["default"]), item))

    if type_changed:
        # Delete all per-user or per-repository overrides; they will be of an
        # incorrect type.
        cursor.execute("""DELETE FROM userpreferences
                                WHERE item=%s
                                  AND (uid IS NOT NULL
                                    OR repository IS NOT NULL)""",
                       (item,))

def remove_preference(db, item):
    cursor = db.cursor()
    cursor.execute("DELETE FROM userpreferences WHERE item=%s", (item,))
    cursor.execute("DELETE FROM preferences WHERE item=%s", (item,))

def load_preferences(db):
    cursor = db.cursor()
    cursor.execute("""SELECT preferences.item, type, integer, string, description
                        FROM preferences
                        JOIN userpreferences USING (item)
                       WHERE uid IS NULL
                         AND repository IS NULL""")
    preferences = {}
    for item, item_type, default_integer, default_string, description in cursor:
        data = { "type": item_type,
                 "description": description }
        if item_type == "string":
            data["default"] = default_string
        elif item_type == "boolean":
            data["default"] = bool(default_integer)
        else:
            data["default"] = default_integer
        preferences[item] = data
    return preferences

def install(data):
    path = os.path.join(installation.root_dir, "src", "data",
                        "preferences.json")

    with open(path) as preferences_file:
        preferences = json.load(preferences_file)

    import dbutils

    with installation.utils.as_critic_system_user():
        with dbutils.Database() as db:
            for item in sorted(preferences.keys()):
                add_preference(db, item, preferences[item], silent=True)

            db.commit()

            print "Added %d preferences." % len(preferences)

    return True

def upgrade(arguments, data):
    git = data["installation.prereqs.git"]
    path = "src/data/preferences.json"

    old_sha1 = data["sha1"]
    old_file_sha1 = installation.utils.get_file_sha1(git, old_sha1, path)

    new_sha1 = installation.utils.run_git([git, "rev-parse", "HEAD"],
                                          cwd=installation.root_dir).strip()
    new_file_sha1 = installation.utils.get_file_sha1(git, new_sha1, path)

    if old_file_sha1:
        old_source = installation.utils.run_git([git, "cat-file", "blob", old_file_sha1],
                                                cwd=installation.root_dir)
        old_preferences = json.loads(old_source)
    else:
        old_preferences = {}

    preferences_path = os.path.join(installation.root_dir, path)

    with open(preferences_path) as preferences_file:
        new_preferences = json.load(preferences_file)

    def update_preferences(old_preferences, new_preferences, db_preferences):
        for item in new_preferences.keys():
            if item not in db_preferences:
                add_preference(db, item, new_preferences[item])
            elif db_preferences[item] != new_preferences[item]:
                type_changed = False
                if db_preferences[item]["type"] != new_preferences[item]["type"]:
                    # If the type has changed, we really have to update it; code
                    # will depend on it having the right type.
                    update = True
                    type_changed = True
                elif item in old_preferences \
                        and db_preferences[item] == old_preferences[item]:
                    # The preference in the database is identical to what we
                    # originally installed; there should be no harm in updating
                    # it.
                    update = True
                elif db_preferences[item]["default"] == new_preferences[item]["default"]:
                    # The default value is the same => only description or flags
                    # has changed.  Probably safe to silently update.
                    update = True
                else:
                    if item in old_preferences \
                            and db_preferences[item]["default"] != old_preferences[item]["default"]:
                        # The default value appears to have been changed in the
                        # database.  Ask the user before overwriting it with an
                        # updated default value.
                        print
                        print textwrap.fill(
                            "The default value for the preference '%s' has been "
                            "changed in this version of Critic, but it appears to "
                            "also have been modified in the database."
                            % item)
                        default = False
                    else:
                        # The default value has changed, and we don't know if
                        # the value is what was originally installed, because we
                        # don't know what was originally installed.  Ask the
                        # user before overwriting the current value.
                        print
                        print textwrap.fill(
                            "The default value for the preference '%s' has been "
                            "changed in this version of Critic."
                            % item)
                        default = True

                    print
                    print "  Value in database: %r" % db_preferences[item]["default"]
                    print "  New/updated value: %r" % new_preferences[item]["default"]
                    print

                    update = installation.input.yes_or_no(
                        "Would you like to update the database with the new value?",
                        default=default)

                if update:
                    update_preference(db, item, new_preferences[item], type_changed)

        # Only check for preferences to remove if the preference data has
        # changed.  Otherwise, every upgrade would ask to remove any extra
        # preferences in the database.
        if old_file_sha1 != new_file_sha1:
            for item in db_preferences.keys():
                if item not in new_preferences:
                    if item in old_preferences \
                            and db_preferences[item] == old_preferences[item]:
                        # The preference in the database is identical to what we
                        # originally installed; there should be no harm in
                        # updating it.
                        remove = True
                    else:
                        print
                        print textwrap.fill(
                            "The preference '%s' exists in the database but "
                            "not in the installation data, meaning it would "
                            "not have been added to the database if this "
                            "version of Critic was installed from scratch."
                            % item)
                        print

                        remove = installation.input.yes_or_no(
                            "Would you like to remove it from the database?",
                            default=True)

                    if remove:
                        remove_preference(db, item)

        db.commit()

    import dbutils

    with installation.utils.as_critic_system_user():
        with dbutils.Database() as db:
            update_preferences(old_preferences,
                               new_preferences,
                               load_preferences(db))

    return True

########NEW FILE########
__FILENAME__ = prereqs
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2012 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import sys
import os
import os.path
import re
import subprocess

import installation

def find_executable(name):
    for search_path in os.environ["PATH"].split(":"):
        path = os.path.join(search_path, name)
        if os.path.isfile(path) and os.access(path, os.X_OK):
            return path

python = sys.executable
git = None
tar = None
psql = None
apache2ctl = None
a2enmod = None
a2ensite = None
a2dissite = None

psycopg2_available = False
pygments_available = False
passlib_available = False
requests_available = False

aptget = None
aptget_approved = False
aptget_updated = False

need_blankline = False

def blankline():
    global need_blankline
    if need_blankline:
        print
        need_blankline = False

def install_packages(arguments, *packages):
    global aptget, aptget_approved, aptget_updated, need_blankline, all_ok
    if aptget is None:
        aptget = find_executable("apt-get")
    if aptget and not aptget_approved:
        all_ok = False
        print """\
Found 'apt-get' executable in your $PATH.  This script can attempt to install
missing software using it.
"""
        aptget_approved = installation.input.yes_or_no(
            prompt="Do you want to use 'apt-get' to install missing packages?",
            default=True)
        if not aptget_approved: aptget = False
    if aptget:
        aptget_env = os.environ.copy()
        if arguments.headless:
            aptget_env["DEBIAN_FRONTEND"] = "noninteractive"
        if not aptget_updated:
            subprocess.check_output(
                [aptget, "-qq", "update"],
                env=aptget_env)
            aptget_updated = True
        aptget_output = subprocess.check_output(
            [aptget, "-qq", "-y", "install"] + list(packages),
            env=aptget_env)
        installed = {}
        for line in aptget_output.splitlines():
            match = re.match(r"^Setting up ([^ ]+) \(([^)]+)\) \.\.\.", line)
            if match:
                package_name, version = match.groups()
                if package_name in packages:
                    need_blankline = True
                    installed[package_name] = version
                    print "Installed: %s (%s)" % (package_name, version)
        return installed
    else:
        return False

def check(mode, arguments):
    global git, tar, psql, passlib_available, apache2ctl, a2enmod, a2ensite, a2dissite

    if mode == "install":
        print """
Critic Installation: Prerequisites
==================================
"""

    success = True
    all_ok = True

    git = find_executable("git")
    if not git:
        if aptget_approved and install_packages(arguments, "git-core"):
            git = find_executable("git")
        if not git:
            blankline()
            all_ok = False
            print """\
No 'git' executable found in $PATH.  Make sure the Git version control system
is installed.  Is Debian/Ubuntu the package you need to install is 'git-core'
(or 'git' in newer versions, but 'git-core' typically still works.)  The source
code can be downloaded here:

  https://github.com/git/git
"""
            if not aptget_approved and install_packages(arguments, "git-core"):
                git = find_executable("git")
            if not git: success = False

    tar = find_executable("tar")
    assert tar, "System has no 'tar'?!?"

    psql = find_executable("psql")
    if not psql:
        if aptget_approved and install_packages(arguments, "postgresql", "postgresql-client"):
            psql = find_executable("psql")
        if not psql:
            blankline()
            all_ok = False
            print """\
No 'psql' executable found in $PATH.  Make sure the PostgreSQL database server
and its client utilities are installed.  In Debian/Ubuntu, the packages you need
to install are 'postgresql' and 'postgresql-client'.
"""
            if not aptget_approved and install_packages(arguments, "postgresql", "postgresql-client"):
                psql = find_executable("psql")
            if not psql: success = False

    if psql:
        postgresql_version = subprocess.check_output([psql, "--version"]).splitlines()[0].split()[-1].split(".")

        postgresql_major = postgresql_version[0]
        postgresql_minor = postgresql_version[1]

        if postgresql_major < 9 or (postgresql_major == 9 and postgresql_minor < 1):
            blankline()
            all_ok = False
            print """\
Unsupported PostgreSQL version!  Critic requires PostgreSQL 9.1.x or later.
"""
            sys.exit(1)

    apache2ctl = find_executable("apache2ctl")
    if not apache2ctl:
        if aptget_approved and install_packages(arguments, "apache2"):
            apache2ctl = find_executable("apache2ctl")
        if not apache2ctl:
            blankline()
            all_ok = False
            print """\
No 'apache2ctl' executable found in $PATH.  Make sure the Apache web server is
installed.  In Debian/Ubuntu, the package you need to install is 'apache2'.
"""
            if not aptget_approved and install_packages(arguments, "apache2"):
                apache2ctl = find_executable("apache2ctl")
            if not apache2ctl: success = False

    a2enmod = find_executable("a2enmod")
    if not a2enmod:
        if aptget_approved and install_packages(arguments, "apache2"):
            a2enmod = find_executable("a2enmod")
        if not a2enmod:
            blankline()
            all_ok = False
            print """\
No 'a2enmod' executable found in $PATH.  Make sure the Apache web server is
installed.  In Debian/Ubuntu, the package you need to install is 'apache2'.
"""
            if not aptget_approved and install_packages(arguments, "apache2"):
                a2enmod = find_executable("a2enmod")
            if not a2enmod: success = False

    a2ensite = find_executable("a2ensite")
    if not a2ensite:
        if aptget_approved and install_packages(arguments, "apache2"):
            a2ensite = find_executable("a2ensite")
        if not a2ensite:
            blankline()
            all_ok = False
            print """\
No 'a2ensite' executable found in $PATH.  Make sure the Apache web server is
installed.  In Debian/Ubuntu, the package you need to install is 'apache2'.
"""
            if not aptget_approved and install_packages(arguments, "apache2"):
                a2ensite = find_executable("a2ensite")
            if not a2ensite: success = False

    a2dissite = find_executable("a2dissite")
    if not a2dissite:
        if aptget_approved and install_packages(arguments, "apache2"):
            a2dissite = find_executable("a2dissite")
        if not a2dissite:
            blankline()
            all_ok = False
            print """\
No 'a2dissite' executable found in $PATH.  Make sure the Apache web server is
installed.  In Debian/Ubuntu, the package you need to install is 'apache2'.
"""
            if not aptget_approved and install_packages(arguments, "apache2"):
                a2dissite = find_executable("a2dissite")
            if not a2dissite: success = False

    if not os.path.isdir(os.path.join("/etc", "apache2", "mods-available")):
        print """\
There's no /etc/apache2/mods-available/ directory.  This means I don't know how
to determine whether the 'wsgi' Apache module is available, and will just have
to assume it is.  If you know it *isn't* available, you should install it, or
abort this script now.
"""
        abort = installation.input.yes_or_no(
            prompt="Do you want to abort this script now?",
            default=False)
        if abort: sys.exit(1)
        else: mod_wsgi_available = True
    else:
        mod_wsgi_available_path = os.path.join("/etc", "apache2", "mods-available", "wsgi.load")
        mod_wsgi_available = os.path.isfile(mod_wsgi_available_path)
        if not mod_wsgi_available:
            if aptget_approved and install_packages(arguments, "libapache2-mod-wsgi"):
                mod_wsgi_available = os.path.isfile(mod_wsgi_available_path)
            if not mod_wsgi_available:
                blankline()
                all_ok = False
                print """\
The WSGI Apache module (mod_wsgi) doesn't appear to be installed.  Make sure
it's installed.  In Debian/Ubuntu, the package you need to install is
'libapache2-mod-wsgi'.  The source code can be downloaded here:

  http://code.google.com/p/modwsgi/wiki/DownloadTheSoftware?tm=2
"""
                if not aptget_approved and install_packages(arguments, "libapache2-mod-wsgi"):
                    mod_wsgi_available = os.path.isfile(mod_wsgi_available_path)
                if not mod_wsgi_available: success = False

    def check_psycopg2():
        global psycopg2_available
        try:
            import psycopg2
            psycopg2_available = True
        except ImportError: pass

    check_psycopg2()
    if not psycopg2_available:
        if aptget_approved and install_packages(arguments, "python-psycopg2"):
            check_psycopg2()
        if not psycopg2_available:
            blankline()
            all_ok = False
            print """\
Failed to import the 'psycopg2' module, which is used to access the PostgreSQL
database from Python.  In Debian/Ubuntu, the module is provided by the
'python-psycopg2' package.  The source code can be downloaded here:

  http://www.initd.org/psycopg/download/
"""
        if not aptget_approved and install_packages(arguments, "python-psycopg2"):
            check_psycopg2()
        if not psycopg2_available:
            success = False

    def check_pygments():
        global pygments_available
        try:
            import pygments
            pygments_available = True
        except ImportError: pass

    check_pygments()
    if not pygments_available:
        if aptget_approved and install_packages(arguments, "python-pygments"):
            check_pygments()
        if not pygments_available:
            blankline()
            all_ok = False
            print """\
Failed to import the 'pygments' module, which is used for syntax highlighting.
In Debian/Ubuntu, the module is provided by the 'python-pygments' package.  The
source code can be downloaded here:

  http://pygments.org/download/
"""
        if not aptget_approved and install_packages(arguments, "python-pygments"):
            check_pygments()
        if not pygments_available:
            success = False

    def check_passlib():
        global passlib_available
        try:
            subprocess.check_output(
                [sys.executable, "-c", "import passlib"],
                stderr=subprocess.STDOUT)
            passlib_available = True
        except subprocess.CalledProcessError:
            pass

    global passlib_available

    check_passlib()
    if not passlib_available:
        if mode == "install":
            auth_mode = arguments.auth_mode
        else:
            import configuration
            auth_mode = configuration.base.AUTHENTICATION_MODE

        if auth_mode == "critic":
            install_passlib = True
        else:
            blankline()
            all_ok = False
            print """\
Failed to import the 'passlib' module, which is required if you want Critic to
handle user authentication itself.  If user authentication is to be handled by
Apache instead there is no need to install the passlib module.

In Debian/Ubuntu, the module is provided by the 'python-passlib' package.  The
source code can be downloaded here:

  https://pypi.python.org/pypi/passlib
"""
            install_passlib = installation.input.yes_or_no(
                "Do you want to install the 'passlib' module?",
                default=False)
        if install_passlib:
            if install_packages(arguments, "python-passlib"):
                check_passlib()
                if not passlib_available:
                    print """
Failed to import 'passlib' module!  Installing it appeared to go fine, though,
so you might just need to restart this script."""
        if install_passlib and not passlib_available:
            success = False

    def check_requests():
        global requests_available
        try:
            import requests
            requests_available = True
        except ImportError: pass

    check_requests()
    if not requests_available:
        if aptget_approved and install_packages(arguments, "python-requests"):
            check_requests()
        if not requests_available:
            blankline()
            all_ok = False
            print """\
Failed to import the 'requests' module, which is used to perform URL requests.
In Debian/Ubuntu, the module is provided by the 'python-requests' package.  The
source code can be downloaded here:

  https://github.com/kennethreitz/requests
"""
        if not aptget_approved and install_packages(arguments, "python-requests"):
            check_requests()
        if not requests_available:
            success = False

    if mode == "install" and all_ok:
        print "All prerequisites available."

    return success

def prepare(mode, arguments, data):
    if mode == "install":
        data["installation.prereqs.python"] = python
        data["installation.prereqs.git"] = git
        data["installation.prereqs.tar"] = tar
    else:
        import configuration

        data["installation.prereqs.python"] = configuration.executables.PYTHON
        data["installation.prereqs.git"] = configuration.executables.GIT
        data["installation.prereqs.tar"] = configuration.executables.TAR

    return True

########NEW FILE########
__FILENAME__ = process
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2012 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import subprocess

def check_input(args, stdin, **kwargs):
    assert isinstance(stdin, str)

    child = subprocess.Popen(args, stdin=subprocess.PIPE, **kwargs)
    stdout, stderr = child.communicate(stdin)

    if child.returncode != 0:
        raise subprocess.CalledProcessError(child.returncode, args, None)

    return stdout

########NEW FILE########
__FILENAME__ = smtp
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2012 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import os
import json

import installation

host = None
port = None
username = None
password = None
use_ssl = None
use_starttls = None

def add_arguments(mode, parser):
    if mode == "install":
        parser.add_argument("--smtp-host", help="SMTP server hostname (or IP)")
        parser.add_argument("--smtp-port", help="SMTP server port")
        parser.add_argument("--smtp-no-auth", action="store_true", help="no SMTP authentication required")
        parser.add_argument("--smtp-username", help="SMTP authentication username")
        parser.add_argument("--smtp-password", help="SMTP authentication password")

        # Using smtplib.SMTP_SSL()
        parser.add_argument("--smtp-ssl", dest="smtp_use_ssl", action="store_const", const=True,
                            help="use SSL(/TLS) when connecting to SMTP server")
        parser.add_argument("--smtp-no-ssl-tls", dest="smtp_use_ssl", action="store_const", const=False,
                            help="don't use SSL(/TLS) when connecting to SMTP server")

        # Using smtplib.SMTP() + starttls()
        parser.add_argument("--smtp-starttls", dest="smtp_use_starttls", action="store_const", const=True,
                            help="use STARTTLS when connecting to SMTP server")
        parser.add_argument("--smtp-no-starttls", dest="smtp_use_starttls", action="store_const", const=False,
                            help="don't use STARTTLS when connecting to SMTP server")

        parser.add_argument("--skip-testmail", action="store_true",
                            help="do not send a test e-mail to verify that given SMTP settings actually work")
        parser.add_argument("--skip-testmail-check", action="store_true",
                            help="do not ask whether the test e-mail arrived correctly")

def prepare(mode, arguments, data):
    global host, port, username, password, use_ssl, use_starttls

    if mode == "install" or "installation.smtp.host" not in data:
        print """
Critic Installation: SMTP
=========================

Critic needs an SMTP server to use for outgoing email traffic.  Emails
are sent to regular Critic users to notify about changes in reviews, as
well as to the system administrator to alert about problems.
"""

        host = "localhost"
        use_ssl = False
        use_starttls = False

        def valid_port(value):
            try:
                if not (0 < int(value) < 65536):
                    raise ValueError
            except ValueError:
                return "must be a valid TCP port number"


        if mode == "install":
            if arguments.smtp_use_ssl and arguments.smtp_use_starttls:
                print "Invalid arguments: only one of --smtp-ssl and --smtp-starttls can be enabled."
                return False
            first = True
        else:
            # This case, an upgrade where installation.smtp.host is not recorded
            # in "data"; happens when upgrading from a pre-5f0389f commit to
            # 5f0389f or later.  Since upgrade.py doesn't have --smtp-* command
            # line arguments, ignore "arguments" variable and go straight to
            # manual input.
            first = False

        while True:
            if first and arguments.smtp_use_ssl is not None:
                use_ssl = arguments.smtp_use_ssl
            else:
                use_ssl = installation.input.yes_or_no("Use SSL when connecting to the SMTP server?", default=use_ssl)

            if not use_ssl:
                if first and arguments.smtp_use_starttls is not None:
                    use_starttls = arguments.smtp_use_starttls
                else:
                    use_starttls = installation.input.yes_or_no("Use STARTTLS when connecting to the SMTP server?", default=use_starttls)

            if first and arguments.smtp_host:
                host = arguments.smtp_host
            else:
                host = installation.input.string("SMTP host:", default=host)

            if first and arguments.smtp_port:
                error = valid_port(arguments.smtp_port)
                if error:
                    print "Invalid --smtp-port argument: %s." % error
                    return False

                port = arguments.smtp_port
            else:
                if port is None:
                    if use_ssl: port = "465"
                    else: port = "25"

                port = installation.input.string("SMTP port:", default=port, check=valid_port)

            need_password = False

            if first and arguments.smtp_username:
                username = arguments.smtp_username
                need_password = True
            elif (not first or not arguments.smtp_no_auth) \
                    and installation.input.yes_or_no("Does the SMTP server require authentication?",
                                                     default=username is not None):
                username = installation.input.string("SMTP username:", default=username)
                need_password = True

            if need_password:
                if first and arguments.smtp_password:
                    password = arguments.smtp_password
                else:
                    password = installation.input.password("SMTP password:", default=password, twice=False)

            print

            if (not first or not arguments.skip_testmail) \
                    and installation.input.yes_or_no("Do you want to send a test email to verify the SMTP configuration?",
                                                     default=True if first else None):
                import smtplib
                import email.mime.text
                import email.header

                recipient = installation.input.string("To which email address?", default=installation.admin.email)
                failed = None

                try:
                    try:
                        if use_ssl:
                            connection = smtplib.SMTP_SSL(host, port, timeout=5)
                        else:
                            connection = smtplib.SMTP(host, port, timeout=5)
                    except:
                        failed = "Couldn't connect to the SMTP server."
                        raise

                    if use_starttls:
                        try:
                            connection.starttls()
                        except:
                            failed = "Failed to start TLS."
                            raise

                    if username is not None:
                        try:
                            connection.login(username, password)
                        except:
                            failed = "Failed to login."
                            raise

                    message = email.mime.text.MIMEText("This is the configuration test email from Critic.",
                                                       "plain", "us-ascii")

                    message["From"] = email.header.Header("Critic System <%s>" % installation.system.email)
                    message["To"] = email.header.Header(recipient)
                    message["Subject"] = email.header.Header("Test email from Critic")

                    try:
                        connection.sendmail(installation.system.email, [recipient], message.as_string())
                    except:
                        failed = "Failed to send the email."
                        raise

                    try:
                        connection.quit()
                    except:
                        failed = "Failed to close connection."
                        raise

                    print
                    print "Test email sent to %s." % recipient
                    print
                except Exception as exception:
                    if not failed:
                        failed = str(exception)

                if failed:
                    print """
Couldn't send the test email:

  %s

Please check the configuration!
""" % failed
                elif (first and arguments.skip_testmail_check) \
                         or installation.input.yes_or_no("Did the test email arrive correctly?") \
                         or not installation.input.yes_or_no("Do you want to modify the configuration?", default=True):
                    break
            else:
                break

            first = False

        port = int(port)
    else:
        import configuration

        host = configuration.smtp.HOST
        port = configuration.smtp.PORT
        use_ssl = configuration.smtp.USE_SSL
        use_starttls = configuration.smtp.USE_STARTTLS

        credentials_path = os.path.join(configuration.paths.CONFIG_DIR,
                                        "configuration/smtp-credentials.json")
        try:
            with open(credentials_path) as credentials_file:
                credentials = json.load(credentials_file)

            username = credentials["username"]
            password = credentials["password"]
        except:
            username = getattr(configuration.smtp, "USERNAME")
            password = getattr(configuration.smtp, "PASSWORD")

    data["installation.smtp.host"] = host
    data["installation.smtp.port"] = port
    data["installation.smtp.username"] = json.dumps(username)
    data["installation.smtp.password"] = json.dumps(password)
    data["installation.smtp.use_ssl"] = use_ssl
    data["installation.smtp.use_starttls"] = use_starttls

    return True

def finish(mode, arguments, data):
    del data["installation.smtp.username"]
    del data["installation.smtp.password"]

########NEW FILE########
__FILENAME__ = system
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2012 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import pwd
import grp
import subprocess
import argparse

import installation

hostname = None
username = "critic"
email = None
uid = None

groupname = "critic"
gid = None

create_system_user = None
created_system_user = False
create_system_group = None
created_system_group = False

def fetch_uid_gid():
    global uid, gid

    uid = pwd.getpwnam(username).pw_uid
    gid = grp.getgrnam(groupname).gr_gid

def add_arguments(mode, parser):
    if mode != "install":
        parser.add_argument("--system-recipient", action="append",
                            dest="system_recipients", help=argparse.SUPPRESS)
        return

    parser.add_argument("--system-hostname", action="store",
                        help="FQDN of the system")
    parser.add_argument("--system-username", action="store",
                        help="name of system user to run as")
    parser.add_argument("--force-create-system-user", action="store_true",
                        help=("don't prompt for permission to create a new "
                              "system user if doesn't exist"))
    parser.add_argument("--system-email", action="store",
                        help="address used as sender of emails")
    parser.add_argument("--system-groupname", action="store",
                        help="name of system group to run as")
    parser.add_argument("--force-create-system-group", action="store_true",
                        help=("don't prompt for permission to create a new "
                              "system group if it doesn't exist"))
    parser.add_argument("--system-recipient", action="append",
                        dest="system_recipients", metavar="SYSTEM_RECIPIENT",
                        help=("email recipient of automatic messages from "
                              "the system"))

def prepare(mode, arguments, data):
    global hostname, username, email, create_system_user
    global groupname, create_system_group
    global uid, gid

    if mode == "install":
        print """
Critic Installation: System
===========================
"""

        if arguments.system_hostname: hostname = arguments.system_hostname
        else:
            try: hostname = subprocess.check_output(["hostname", "--fqdn"]).strip()
            except: pass

            hostname = installation.input.string(prompt="What is the machine's FQDN?",
                                                        default=hostname)

        while True:
            if arguments.system_username: username = arguments.system_username
            else:
                username = installation.input.string(prompt="What system user should Critic run as?",
                                                            default=username)

            try:
                pwd.getpwnam(username)
                user_exists = True
            except:
                user_exists = False

            if user_exists:
                print """
The system user '%s' already exists.
""" % username

                if installation.input.yes_or_no(prompt="Use the existing system user '%s'?" % username,
                                                default=True):
                    create_system_user = False
                    break
            else:
                print """
The system user '%s' doesn't exists.
""" % username

                if arguments.force_create_system_user or installation.input.yes_or_no(prompt="Create a system user named '%s'?" % username,
                                                default=True):
                    create_system_user = True
                    break

        while True:
            if arguments.system_groupname: groupname = arguments.system_groupname
            else:
                groupname = installation.input.string(prompt="What system group should Critic run as?",
                                                            default=groupname)

            try:
                grp.getgrnam(groupname)
                group_exists = True
            except:
                group_exists = False

            if group_exists:
                print """
The system group '%s' already exists.
""" % groupname

                if installation.input.yes_or_no(prompt="Use the existing system group '%s'?" % groupname,
                                                default=True):
                    create_system_group = False
                    break
            else:
                print """
The system group '%s' doesn't exists.
""" % groupname

                if arguments.force_create_system_group or installation.input.yes_or_no(prompt="Create a system group named '%s'?" % groupname,
                                                default=True):
                    create_system_group = True
                    break

        if arguments.system_email: email = arguments.system_email
        else:
            email = installation.input.string(prompt="What address should be used as the sender of emails from the system?",
                                              default=("%s@%s" % (username, hostname)))
    else:
        import configuration

        hostname = configuration.base.HOSTNAME
        username = configuration.base.SYSTEM_USER_NAME
        email = configuration.base.SYSTEM_USER_EMAIL

        try: groupname = configuration.base.SYSTEM_GROUP_NAME
        except AttributeError: groupname = data["installation.system.groupname"]

        fetch_uid_gid()

    data["installation.system.hostname"] = hostname
    data["installation.system.username"] = username
    data["installation.system.email"] = email
    data["installation.system.groupname"] = groupname

    return True

def install(data):
    global uid, gid

    if create_system_group:
        print "Creating group '%s' ..." % groupname

        subprocess.check_call(["addgroup", "--quiet", "--system", groupname])

    if create_system_user:
        print "Creating user '%s' ..." % username

        subprocess.check_call(
            ["adduser", "--quiet", "--system", "--ingroup=%s" % groupname,
             "--home=%s" % installation.paths.data_dir, "--disabled-login",
             username])

    uid = pwd.getpwnam(username).pw_uid
    gid = grp.getgrnam(groupname).gr_gid

    return True

def undo():
    if created_system_user:
        print "Deleting user '%s' ..." % username

        subprocess.check_call(["deluser", "--system", username])

    if created_system_group:
        print "Deleting group '%s' ..." % groupname

        subprocess.check_call(["delgroup", "--system", groupname])

########NEW FILE########
__FILENAME__ = auth
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2013 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

# Accepted password hash schemes.  They need to be supported by the passlib
# Python package; see http://packages.python.org/passlib for details.
PASSWORD_HASH_SCHEMES = %(installation.config.password_hash_schemes)r

# Default password hash scheme.  Must be included in PASSWORD_HASH_SCHEMES.
DEFAULT_PASSWORD_HASH_SCHEME = %(installation.config.default_password_hash_scheme)r

# (Approximate) minimum password hash time in seconds.  Higher means safer
# passwords (more difficult to decrypt using brute-force) but slower sign-in
# operation.
MINIMUM_PASSWORD_HASH_TIME = %(installation.config.minimum_password_hash_time)r

# Calibrated minimum rounds per password hash scheme.
MINIMUM_ROUNDS = %(installation.config.minimum_rounds)r

# External authentication providers.
PROVIDERS = {

    # GitHub OAuth-based authentication.
    "github": {
        "enabled": %(installation.config.provider_github.enabled)r,

        # Allow authenticated user to create a Critic user.
        "allow_user_registration": %(installation.config.provider_github.allow_user_registration)r,
        # Verify user email addresses provided by GitHub.
        "verify_email_addresses": %(installation.config.provider_github.verify_email_addresses)r,

        # Client ID and secret.  These are generated by registering an
        # application at https://github.com/settings/applications/new.
        "client_id": %(installation.config.provider_github.client_id)r,
        "client_secret": %(installation.config.provider_github.client_secret)r,

        # Bypass /createuser on first sign in, creating a user automatically.
        "bypass_createuser": %(installation.config.provider_github.bypass_createuser)r,

        # Authentication callback URI.  This same URI must be provided
        # to GitHub when registering the application.  The path
        # component must be "/oauth/github".
        "redirect_uri": %(installation.config.provider_github.redirect_uri)r
    },

    # Google OAuth-based authentication.
    "google": {
        "enabled": %(installation.config.provider_google.enabled)r,

        # Allow authenticated user to create a Critic user.
        "allow_user_registration": %(installation.config.provider_google.allow_user_registration)r,
        # Verify user email addresses provided by Google.
        "verify_email_addresses": %(installation.config.provider_google.verify_email_addresses)r,

        # Client ID and secret.  These are generated by creating a project at
        # https://cloud.google.com/console/project, and then creating an OAuth2
        # client id using the project administration UI.
        "client_id": %(installation.config.provider_google.client_id)r,
        "client_secret": %(installation.config.provider_google.client_secret)r,

        # Bypass /createuser on first sign in, creating a user automatically.
        "bypass_createuser": %(installation.config.provider_google.bypass_createuser)r,

        # Authentication callback URI.  This same URI must be provided
        # to Google when creating the OAuth2 client id.  The path
        # component must be "/oauth/google".
        "redirect_uri": %(installation.config.provider_google.redirect_uri)r
    },

}

########NEW FILE########
__FILENAME__ = base
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2012 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

# The name of the system identity which this configuration applies to.
SYSTEM_IDENTITY = "main"

# The name of the system user that Critic runs as.
SYSTEM_USER_NAME = "%(installation.system.username)s"

# The email address to use in the "Sender:" header in all generated
# emails, and in the "From:" header in emails unless there's a real
# user whose email address it makes sense to use instead.
SYSTEM_USER_EMAIL = "%(installation.system.email)s"

# The name of the system group that Critic runs as.
SYSTEM_GROUP_NAME = "%(installation.system.groupname)s"

# List of recipients of system messages such as automatic error
# reports generated when unexpected errors occur.
SYSTEM_RECIPIENTS = %(installation.system.recipients)r

# The primary FQDN of the server.  This is used when generating message IDs for
# emails, and should *not* be different in different system identities, since
# then email threading will not work properly.
HOSTNAME = "%(installation.system.hostname)s"

# The way Critic identifies/authenticates users: "host", "critic" or the name of
# one of the supported external authentication providers.
AUTHENTICATION_MODE = "%(installation.config.auth_mode)s"

# If AUTHENTICATION_MODE="critic", type of session: "httpauth" or "cookie".  If
# AUTHENTICATION_MODE=<external>, this must be "cookie".
SESSION_TYPE = "%(installation.config.session_type)s"

# If AUTHENTICATION_MODE!="host" and SESSION_TYPE="cookie", maximum age of
# session in seconds.  Zero means no maximum age; session is valid until user
# logs out.
SESSION_MAX_AGE = 0

# Allow (restricted) anonymous access to the system.  Only supported if
# AUTHENTICATION_MODE!="host" and SESSION_TYPE="cookie".
ALLOW_ANONYMOUS_USER = %(installation.config.allow_anonymous_user)r

# Access scheme: "http", "https" or "both".
ACCESS_SCHEME = "%(installation.config.access_scheme)s"

# Supported repository URL types (when displayed in UI and in emails):
#
#  "git"  => "git://hostname/path.git"
#  "http" => "http://hostname/path.git" or "https://hostname/path.git"
#  "ssh"  => "ssh://hostname/path.git"
#  "host" => "hostname:/path.git"
#
# where 'hostname' is the system's FQDN and 'path.git' is the repository's path
# relative configuration.paths.GIT_DIR.
#
# The 'http' choice means HTTP or HTTPS depending on the ACCESS_SCHEME setting
# and whether the user is anonymous or not.
#
# Note: Only 'http' is currently supported natively by Critic.  For 'git' to
# work, the system administrator must configure 'git daemon' to run manually.
# For 'ssh' and 'host' to work (they mean the same thing, only with different
# syntax) system user accounts must be created, and SSH access provided.  See
# the system administration tutorial for more information.
REPOSITORY_URL_TYPES = %(installation.config.repository_url_types)r

# Default encodings to attempt to decode text (such as source code)
# as, in order of decreasing precedence.  The encoding names should be
# valid for use as the encoding argument to Python's str.decode()
# function.
DEFAULT_ENCODINGS = %(installation.config.default_encodings)r

# Allow (unattended) user registration.  If False, user registration can still
# be enabled for a specific external user authentication provider; see auth.py.
ALLOW_USER_REGISTRATION = %(installation.config.allow_user_registration)r

# Regular expression (source) that user names provided by new users must match.
# A None value is equivalent to a pattern that matches all strings.  Empty user
# names or user names containing only white-space characters are not allowed,
# regardless this setting.
#
# Note that users created by the system administrator using criticctl are
# not subjected to this restriction.
USER_NAME_PATTERN = r"^\w[-\._\w]*\w$"

# Description of above pattern, shown to the user if a provided user name fails
# to match the pattern.
USER_NAME_PATTERN_DESCRIPTION = (
    "Must contain only alpha-numerics, periods, underscores or dashes, and "
    "must start and end with alpha-numerics, and be at least two characters "
    "long.")

# Require verification of email addresses provided by users before sending
# emails to them.  This does not affect email addresses set by the system
# administrator via the 'criticctl' utility or via the web interface.
VERIFY_EMAIL_ADDRESSES = %(installation.config.verify_email_addresses)r

########NEW FILE########
__FILENAME__ = database
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2012 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

# Dictionary whose members are passed as keyword arguments to
# psycopg2.connect().
PARAMETERS = { "database": "critic", "user": "%(installation.system.username)s" }

########NEW FILE########
__FILENAME__ = debug
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2013 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

# True if this is a development installation of the system; False if it is a
# production installation.  Causes stack traces from unexpected exceptions to be
# displayed to all users rather than only to those with the "developer" role.
# Also changes the favicon and the color of the "Opera" text in page headers
# from red to black.
IS_DEVELOPMENT = %(installation.config.is_development)r

# True if this is an installation by the automatic testing framework.
IS_TESTING = %(installation.config.is_testing)r

# Directory to write code coverage results to.  If None, code coverage is not
# written, and more importantly, not measured in the first place.
COVERAGE_DIR = %(installation.config.coverage_dir)r

########NEW FILE########
__FILENAME__ = executables
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2012 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

# Python executable.
PYTHON = "%(installation.prereqs.python)s"

# Git executable.
GIT = "%(installation.prereqs.git)s"

# Add these to the environment when running Git commands
GIT_ENV = { }

# Tar executable.
TAR = "%(installation.prereqs.tar)s"

# JSShell executable (only needed for extensions support.)
JSSHELL = None

########NEW FILE########
__FILENAME__ = extensions
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2012 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import configuration
import os.path

# Whether extension support is enabled.  If False, the rest of the
# configuration in this file is irrelevant.
ENABLED = %(installation.extensions.enabled)s

# Where to search for system extensions.
SYSTEM_EXTENSIONS_DIR = os.path.join(configuration.paths.DATA_DIR, "extensions")

# Name of directory under users' $HOME in which to search for user extensions.
# If set to None, user extensions support is disabled.
USER_EXTENSIONS_DIR = "CriticExtensions"

FLAVORS = {
    "js/v8":
        { "executable": "%(installation.extensions.critic_v8_jsshell)s",
          "library": os.path.join(configuration.paths.INSTALL_DIR, "library", "js", "v8") }
    }

DEFAULT_FLAVOR = "%(installation.extensions.default_flavor)s"

# Directory into which extension version snapshots are installed.
INSTALL_DIR = os.path.join(configuration.paths.DATA_DIR, "extension-snapshots")

# Directory into which extension repository work copies are created.
WORKCOPY_DIR = os.path.join(configuration.paths.DATA_DIR, "temporary", "EXTENSIONS")

# Long timeout, in seconds.  Used for extension "Page" roles.
LONG_TIMEOUT = 300
# Short timeout, in seconds.  Used for all other roles.
SHORT_TIMEOUT = 5

########NEW FILE########
__FILENAME__ = limits
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2012 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

# When a file is added, and it has more lines than these limits,
# output a "File was added." placeholder instead of the entire file,
# with an option to fetch all the lines.  The _RECOGNIZED option is
# for a file in a recognized (and syntax highlighted) language, the
# _UNRECOGNIZED option is for other files.
MAXIMUM_ADDED_LINES_RECOGNIZED = 8000
MAXIMUM_ADDED_LINES_UNRECOGNIZED = 2000

# Reject any single ref update that causes more than this many new
# commits to be added to the repository.  The likely cause for hitting
# this limit is pushing a branch to the wrong repository, which just
# causes bloat in the receiving repository.
PUSH_COMMIT_LIMIT = 10000

# For branches containing more commits than this, fall back to simpler
# branch log rendering for performance reasons.
MAXIMUM_REACHABLE_COMMITS = 4000

# Maximum number of commits when /createreview is loaded with the
# 'branch' URI parameter to create a review of all commits on a branch.
MAXIMUM_REVIEW_COMMITS = 2000

########NEW FILE########
__FILENAME__ = mimetypes
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2012 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

MIMETYPES = { "txt": "text/plain",
              "html": "text/html",
              "xml": "application/xml",
              "xsl": "application/xml",
              "svg": "image/svg+xml",
              "css": "text/css",
              "js": "text/javascript",
              "json": "application/json",
              "png": "image/png",
              "gif": "image/gif",
              "jpg": "image/jpeg",
              "ico": "image/vnd.microsoft.icon",
              "bmp": "image/x-bmp" }

########NEW FILE########
__FILENAME__ = paths
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2012 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import configuration
import os.path

# Directory where system configuration is stored.
CONFIG_DIR = os.path.join("%(installation.paths.etc_dir)s", configuration.base.SYSTEM_IDENTITY)

# Directory where the main system is installed.
INSTALL_DIR = "%(installation.paths.install_dir)s"

# Directory under which data files of a more permanent nature are
# stored.
DATA_DIR = "%(installation.paths.data_dir)s"

# Directory under which cache files that can be discarded at any time
# are stored.
CACHE_DIR = os.path.join("%(installation.paths.cache_dir)s", configuration.base.SYSTEM_IDENTITY)

# Directory in which log files are stored.
LOG_DIR = os.path.join("%(installation.paths.log_dir)s", configuration.base.SYSTEM_IDENTITY)

# Directory in which pid files are stored.
RUN_DIR = os.path.join("%(installation.paths.run_dir)s", configuration.base.SYSTEM_IDENTITY)

# Directory in which WSGI daemon process pid files are stored.
WSGI_PIDFILE_DIR = os.path.join(RUN_DIR, "wsgi")

# Directory in which Unix socket files are created.
SOCKETS_DIR = os.path.join(RUN_DIR, "sockets")

# Directory where the main (public) git repositories are stored.
GIT_DIR = "%(installation.paths.git_dir)s"

# Directory in which emails are stored pending delivery.
OUTBOX = os.path.join(DATA_DIR, "outbox")

########NEW FILE########
__FILENAME__ = services
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2012 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import configuration
import os.path

def service(name, address=0, module=0, pidfile_path=0, logfile_path=0, loglevel=0):
    if address      == 0: address      = os.path.join(configuration.paths.SOCKETS_DIR, name + ".unix")
    if module       == 0: module       = "background." + name
    if pidfile_path == 0: pidfile_path = os.path.join(configuration.paths.RUN_DIR, name + ".pid")
    if logfile_path == 0: logfile_path = os.path.join(configuration.paths.LOG_DIR, name + ".log")
    if loglevel     == 0: loglevel     = "info"

    return { "name": name,
             "address": address,
             "module": module,
             "pidfile_path": pidfile_path,
             "logfile_path": logfile_path,
             "loglevel": loglevel }

HIGHLIGHT         = service(name="highlight")
CHANGESET         = service(name="changeset")
GITHOOK           = service(name="githook")
BRANCHTRACKER     = service(name="branchtracker",     address=None)
MAILDELIVERY      = service(name="maildelivery",      address=None)
WATCHDOG          = service(name="watchdog",          address=None)
MAINTENANCE       = service(name="maintenance",       address=None)
SERVICEMANAGER    = service(name="servicemanager")

HIGHLIGHT["cache_dir"] = os.path.join(configuration.paths.CACHE_DIR, "highlight")
HIGHLIGHT["min_context_length"] = 5
HIGHLIGHT["max_context_length"] = 256
HIGHLIGHT["max_workers"] = 4
HIGHLIGHT["compact_at"] = (3, 15)

CHANGESET["max_workers"] = 4
CHANGESET["rss_limit"] = 1024 ** 3
CHANGESET["purge_at"] = (2, 15)

# Timeout (in seconds) passed to smtplib.SMTP().
MAILDELIVERY["timeout"] = 10

WATCHDOG["rss_soft_limit"] = 1024 ** 3
WATCHDOG["rss_hard_limit"] = 2 * WATCHDOG["rss_soft_limit"]

MAINTENANCE["maintenance_at"] = (4, 0)

SERVICEMANAGER["services"] = [HIGHLIGHT,
                              CHANGESET,
                              GITHOOK,
                              BRANCHTRACKER,
                              MAILDELIVERY,
                              WATCHDOG,
                              MAINTENANCE]

########NEW FILE########
__FILENAME__ = smtp
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2012 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

HOST = %(installation.smtp.host)r
PORT = %(installation.smtp.port)r
USE_SSL = %(installation.smtp.use_ssl)r
USE_STARTTLS = %(installation.smtp.use_starttls)r

MAX_ATTEMPTS = 10

########NEW FILE########
__FILENAME__ = utils
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2012 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import os
import sys
import textwrap
import subprocess
import tempfile
import datetime
import hashlib
import contextlib
import json

import installation

class UpdateModifiedFile:
    def __init__(self, arguments, message, versions, options, generateVersion):
        """\
        Constructor.

        Arguments:

          arguments  Command-line arguments.
          message    Printed once.
          versions   Dictionary (label => path) of file versions involved.
          options    List of options to present to the user.
          prompt     Prompt printed when asking what to do.
        """

        self.__arguments = arguments
        self.__message = message
        self.__versions = versions
        self.__options = options
        self.__option_keys = [key for key, action in options]
        self.__option_map = dict((key, action) for key, action in options)
        self.__generateVersion = generateVersion
        self.__generated = []

    def printMessage(self):
        print self.__message % self.__versions

    def printOptions(self):
        alternatives = []

        for key, action in self.__options:
            if isinstance(action, str):
                alternatives.append("'%s' to %s" % (key, action))
            else:
                alternatives.append("'%s' to display the differences between the %s version and the %s version"
                                    % (key, action[0], action[1]))

        print textwrap.fill("Input %s and %s." % (", ".join(alternatives[:-1]), alternatives[-1]))
        print

    def displayDifferences(self, from_version, to_version):
        print
        print "=" * 80

        diff = subprocess.Popen(["diff", "-u", self.__versions[from_version], self.__versions[to_version]])
        diff.wait()

        print "=" * 80
        print

    def prompt(self):
        if self.__arguments.headless:
            # The first choice is typically "install updated version" or "remove
            # (obsolete) file" and is appropriate when --headless was used.
            return self.__options[0][0]

        try:
            for label, path in self.__versions.items():
                if not os.path.exists(path):
                    self.__generateVersion(label, path)
                    self.__generated.append(path)

            self.printMessage()

            while True:
                self.printOptions()

                def validResponse(value):
                    if value not in self.__option_keys:
                        return "please answer %s or %s" % (", ".join(self.__option_keys[:-1]), self.__option_keys[-1])

                response = installation.input.string("What do you want to do?", check=validResponse)
                action = self.__option_map[response]

                if isinstance(action, str):
                    print
                    return response

                from_version, to_version = action

                self.displayDifferences(from_version, to_version)
        finally:
            for path in self.__generated:
                os.unlink(path)

def run_git(args, **kwargs):
    with installation.utils.as_effective_user_from_path(
            os.path.join(installation.root_dir, ".git")):
        return subprocess.check_output(args, **kwargs)

def update_from_template(arguments, data, template_path, target_path, message):
    git = data["installation.prereqs.git"]

    old_commit_sha1 = data["sha1"]
    new_commit_sha1 = run_git([git, "rev-parse", "HEAD"],
                              cwd=installation.root_dir).strip()

    old_template = read_file(git, old_commit_sha1, template_path)
    new_template = read_file(git, new_commit_sha1, template_path)

    old_source = old_template.decode("utf-8") % data
    new_source = new_template.decode("utf-8") % data

    with open(target_path) as target_file:
        current_source = target_file.read().decode("utf-8")

    if current_source == new_source:
        # The current version is what we would install now.  Nothing to do.
        return
    elif old_source == current_source:
        # The current version is what we installed (or would have installed with
        # the old template and current settings.)  Update the target file
        # without asking.
        write_target = True
    else:
        def generate_version(label, path):
            if label == "installed":
                source = old_source
            elif label == "updated":
                source = new_source
            else:
                return
            write_file(path, source.encode("utf-8"))

        versions = """\
  Installed version: %(installed)s
  Current version:   %(current)s
  Updated version:   %(updated)s"""

        update_query = UpdateModifiedFile(
            arguments,
            message=message % { "versions": versions },
            versions={ "installed": target_path + ".org",
                       "current": target_path,
                       "updated": target_path + ".new" },
            options=[ ("i", "install the updated version"),
                      ("k", "keep the current version"),
                      ("do", ("installed", "current")),
                      ("dn", ("current", "updated")) ],
            generateVersion=generate_version)

        write_target = update_query.prompt() == "i"

    if write_target:
        print "Updated file: %s" % target_path

        if not arguments.dry_run:
            backup_path = os.path.join(os.path.dirname(target_path),
                                       ".%s.org" % os.path.basename(target_path))
            copy_file(target_path, backup_path)
            with open(target_path, "w") as target_file:
                target_file.write(new_source.encode("utf-8"))
            return backup_path

def write_file(path, source):
    # Use os.open() with O_EXCL to avoid trampling some existing file.
    fd = os.open(path, os.O_WRONLY | os.O_CREAT | os.O_EXCL)
    with os.fdopen(fd, "w") as target:
        target.write(source)

def copy_file(source_path, target_path):
    with open(source_path) as source:
        stat = os.fstat(source.fileno())
        # Use os.open() with O_EXCL to avoid trampling some existing file.
        fd = os.open(target_path, os.O_WRONLY | os.O_CREAT | os.O_EXCL)
        with os.fdopen(fd, "w") as target:
            target.write(source.read())
            os.fchmod(target.fileno(), stat.st_mode)
            os.fchown(target.fileno(), stat.st_uid, stat.st_gid)

def hash_file(git, path):
    if os.path.islink(path):
        value = os.readlink(path)
    else:
        with open(path) as file:
            value = file.read()
    return hashlib.sha1("blob %d\0%s" % (len(value), value)).hexdigest()

def get_entry_sha1(git, commit_sha1, path, entry_type):
    lstree = run_git([git, "ls-tree", commit_sha1, path],
                     cwd=installation.root_dir).strip()

    if lstree:
        lstree_mode, lstree_type, lstree_sha1, lstree_path = lstree.split()

        assert lstree_type == entry_type
        assert lstree_path == path

        return lstree_sha1
    else:
        return None

def get_file_sha1(git, commit_sha1, path):
    return get_entry_sha1(git, commit_sha1, path, "blob")

def get_tree_sha1(git, commit_sha1, path):
    return get_entry_sha1(git, commit_sha1, path, "tree")

def read_file(git, commit_sha1, path):
    file_sha1 = get_file_sha1(git, commit_sha1, path)
    if file_sha1 is None:
        return None
    return run_git([git, "cat-file", "blob", file_sha1],
                   cwd=installation.root_dir)

def get_intial_commit_date(git, path):
    initial_commit_timestamp = run_git([git, "log", "--oneline",
            "--format=%ct", "--", path], cwd=installation.root_dir).splitlines()[-1]
    return datetime.datetime.fromtimestamp(int(initial_commit_timestamp))

def clean_root_pyc_files():
    print "Cleaning up .pyc files owned by root ..."
    for root, _, files in os.walk(installation.root_dir):
        for file in files:
            file = os.path.join(root, file)
            if file.endswith(".pyc") and os.stat(file).st_uid == 0:
                os.unlink(file)

@contextlib.contextmanager
def as_critic_system_user():
    saved_cwd = os.getcwd()
    os.chdir(tempfile.gettempdir())
    os.setegid(installation.system.gid)
    os.seteuid(installation.system.uid)
    try:
        yield
    finally:
        os.seteuid(os.getresuid()[0])
        os.setegid(os.getresgid()[0])
        os.chdir(saved_cwd)

@contextlib.contextmanager
def as_effective_user_from_path(path):
    stat = os.stat(path)
    os.setegid(stat.st_gid)
    os.seteuid(stat.st_uid)
    try:
        yield
    finally:
        os.seteuid(os.getresuid()[0])
        os.setegid(os.getresgid()[0])

def deunicode(v):
    if type(v) == unicode: return v.encode("utf-8")
    elif type(v) == list: return map(deunicode, v)
    elif type(v) == dict: return dict([(deunicode(a), deunicode(b)) for a, b in v.items()])
    else: return v

def read_install_data(arguments, fail_softly=False):
    etc_path = os.path.join(arguments.etc_dir, arguments.identity)

    if not os.path.isdir(etc_path):
        if fail_softly:
            return None
        print """
ERROR: %s: no such directory
HINT: Make sure the --etc-dir[=%s] and --identity[=%s] options
      correctly define where the installed system's configuration is stored.""" % (etc_path, arguments.etc_dir, arguments.identity)
        sys.exit(1)

    sys.path.insert(0, etc_path)

    try:
        import configuration
    except ImportError:
        if fail_softly:
            return None
        print """
ERROR: Failed to import 'configuration' module.
HINT: Make sure the --etc-dir[=%s] and --identity[=%s] options
      correctly define where the installed system's configuration is stored.""" % (arguments.etc_dir, arguments.identity)
        sys.exit(1)

    install_data_path = os.path.join(configuration.paths.INSTALL_DIR, ".install.data")

    if not os.path.isfile(install_data_path):
        if fail_softly:
            return None
        print """\
%s: no such file

This installation of Critic appears to be incomplete or corrupt.""" % install_data_path
        sys.exit(1)

    try:
        with open(install_data_path, "r") as install_data_file:
            install_data = deunicode(json.load(install_data_file))
            if not isinstance(install_data, dict): raise ValueError
    except ValueError:
        if fail_softly:
            return None
        print """\
%s: failed to parse JSON object to dictionary

This installation of Critic appears to be incomplete or corrupt.""" % install_data_path
        sys.exit(1)

    return install_data

def write_install_data(arguments, install_data):
    install_data_path = os.path.join(installation.paths.install_dir, ".install.data")

    if not getattr(arguments, "dry_run", False):
        with open(install_data_path, "w") as install_data_file:
            json.dump(install_data, install_data_file)

        os.chown(install_data_path, installation.system.uid, installation.system.gid)
        os.chmod(install_data_path, 0640)

########NEW FILE########
__FILENAME__ = pythonversion
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2013 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import sys

def check(message=None):
    if sys.version_info[0] != 2 or sys.version_info[1] < 7:
        print """
ERROR: Unsupported Python version!  Critic requires Python 2.7.x or
later, and does not support Python 3.x.
"""

        if message:
            print message

        sys.exit(2)

########NEW FILE########
__FILENAME__ = oauth
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2014 the Critic contributors, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import urllib

import dbutils
import auth
import textutils

class OAuthProvider(auth.Provider):
    def start(self, db, req, target_url=None):
        cursor = db.cursor()
        state = auth.getToken()

        authorize_url = self.getAuthorizeURL(state)

        if authorize_url is None:
            return False

        if target_url is None:
            target_url = req.getParameter("target", None)

        cursor.execute("""INSERT INTO oauthstates (state, url)
                               VALUES (%s, %s)""",
                       (state, target_url))

        req.setStatus(302)
        req.addResponseHeader("Location", authorize_url)
        req.start()

        db.commit()

        return True

    def finish(self, db, req):
        if req.method != "GET":
            raise auth.InvalidRequest

        code = req.getParameter("code", default=None)
        state = req.getParameter("state", default=None)

        if code is None or state is None:
            raise auth.InvalidRequest("Missing parameter(s)")

        cursor = db.cursor()
        cursor.execute("""SELECT url
                            FROM oauthstates
                           WHERE state=%s""",
                       (state,))

        row = cursor.fetchone()

        if not row:
            raise auth.InvalidRequest("Invalid OAuth state: %s" % state)

        (target_url,) = row

        access_token = self.getAccessToken(code)

        if access_token is None:
            raise auth.Failure("failed to get access token")

        user_data = self.getUserData(access_token)

        if user_data is None:
            raise auth.Failure("failed to get user data")

        account = textutils.encode(user_data["account"])
        username = textutils.encode(user_data["username"])
        email = user_data["email"]
        email = textutils.encode(email) if email else None
        fullname = textutils.encode(user_data.get("fullname", username))

        cursor.execute("""SELECT id, uid
                            FROM externalusers
                           WHERE provider=%s
                             AND account=%s""",
                       (self.name, account))

        row = cursor.fetchone()

        if not row:
            cursor.execute("""INSERT INTO externalusers (provider, account, email)
                                   VALUES (%s, %s, %s)
                                RETURNING id""",
                           (self.name, account, email))

            row = (cursor.fetchone()[0], None)

        external_user_id, user_id = row
        user = None

        if user_id is None:
            if auth.isValidUserName(username) \
                    and self.configuration.get("bypass_createuser"):
                try:
                    dbutils.User.fromName(db, username)
                except dbutils.NoSuchUser:
                    user = dbutils.User.create(db, username, fullname, email, None)
                    cursor.execute("""UPDATE externalusers
                                         SET uid=%s
                                       WHERE id=%s""",
                                   (user.id, external_user_id))
                    user.sendUserCreatedMail("wsgi[oauth/%s]" % self.name,
                                             { "provider": self.name,
                                               "account": account })
        else:
            user = dbutils.User.fromId(db, user_id)

        if user is not None:
            auth.startSession(db, req, user)
        else:
            token = auth.getToken()

            cursor.execute("""UPDATE externalusers
                                 SET token=%s
                               WHERE id=%s""",
                           (token, external_user_id))

            data = { "provider": self.name,
                     "account": account,
                     "token": token }

            if target_url:
                data["target"] = target_url
            if username:
                data["username"] = username
            if email:
                data["email"] = email
            if fullname:
                data["fullname"] = fullname

            target_url = "/createuser?%s" % urllib.urlencode(data)

        req.setStatus(302)
        req.addResponseHeader("Location", target_url or "/")
        req.start()

        db.commit()

        return True

    def validateToken(self, db, account, token):
        cursor = db.cursor()
        cursor.execute("""SELECT token
                            FROM externalusers
                           WHERE provider=%s
                             AND account=%s""",
                       (self.name, account))
        row = cursor.fetchone()
        return row and token == row[0]

########NEW FILE########
__FILENAME__ = provider
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2014 the Critic contributors, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import configuration

class Provider(object):
    def __init__(self, name):
        self.name = name
        self.configuration = configuration.auth.PROVIDERS[name]

    def getTitle(self):
        """Title, suitable as X in 'Sign in using your X'"""
        pass

    def getAccountIdDescription(self):
        """Description of the value used as the account identifier"""
        pass

    def start(self, db, req, target_url=None):
        pass

    def finish(self, db, req):
        pass

########NEW FILE########
__FILENAME__ = dummy
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2014 the Critic contributors, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import hashlib
import urllib

import configuration
import auth

class DummyOAuthProvider(auth.OAuthProvider):
    """Dummy OAuth authentication provider used by automatic tests"""

    def __init__(self, name):
        super(DummyOAuthProvider, self).__init__(name)
        self.access_token = None

    def getTitle(self):
        """Title, suitable as X in 'Sign in using your X'"""
        return self.name.capitalize() + " account"

    def getAccountIdDescription(self):
        return self.name.capitalize() + " username"

    def getAccountURL(self, name):
        return "https://example.com/user/%s" % name

    def getAuthorizeURL(self, state):
        query = urllib.urlencode({ "state": state })
        return "https://example.com/authorize?%s" % query

    def getAccessToken(self, code):
        if code == "incorrect":
            raise auth.Failure("Incorrect code")
        self.access_token = hashlib.sha1(code).hexdigest()
        return self.access_token

    def getUserData(self, access_token):
        if access_token != self.access_token:
            raise auth.Failure("Invalid access token")
        return { "account": "account-" + self.name,
                 "username": self.name,
                 "email": self.name + "@example.org",
                 "fullname": self.name.capitalize() + " von Testing" }

if configuration.debug.IS_TESTING:
    def createProvider(name, allow_user_registration, verify_email_addresses,
                       bypass_createuser):
        configuration.auth.PROVIDERS[name] = {
            "enabled": True,
            "allow_user_registration": allow_user_registration,
            "verify_email_addresses": verify_email_addresses,
            "client_id": "DummyClientId",
            "client_secret": "DummyClientSecret",
            "bypass_createuser": bypass_createuser
        }
        auth.PROVIDERS[name] = DummyOAuthProvider(name)

    createProvider("alice", False, False, False)
    createProvider("carol", True, False, False)
    createProvider("felix", True, False, True)
    createProvider("gina", True, True, False)

########NEW FILE########
__FILENAME__ = github
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2014 the Critic contributors, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import urllib

import urlutils
import configuration
import auth

class GitHubAuthentication(auth.OAuthProvider):
    def __init__(self):
        super(GitHubAuthentication, self).__init__("github")

        self.client_id = self.configuration["client_id"]
        self.client_secret = self.configuration["client_secret"]
        self.redirect_uri = self.configuration["redirect_uri"]

    def getTitle(self):
        """Title, suitable as X in 'Sign in using your X'"""
        return "GitHub account"

    def getAccountIdDescription(self):
        return "GitHub username"

    def getAccountURL(self, name):
        return "https://github.com/%s" % name

    def getAuthorizeURL(self, state):
        query = urllib.urlencode({ "client_id": self.client_id,
                                   "redirect_uri": self.redirect_uri,
                                   "state": state })

        return "https://github.com/login/oauth/authorize?%s" % query

    def getAccessToken(self, code):
        response = urlutils.post(
            "https://github.com/login/oauth/access_token",
            data={ "client_id": self.client_id,
                   "client_secret": self.client_secret,
                   "code": code },
            headers={ "Accept": "application/json" })

        if response.status_code != 200:
            return None

        data = response.json()

        if data is None:
            return None
        elif "error" in data:
            raise auth.Failure(data["error"])
        elif "access_token" not in data:
            return None

        return data["access_token"]

    def getUserData(self, access_token):
        response = urlutils.get(
            "https://api.github.com/user?access_token=%s" % access_token)

        if response.status_code != 200:
            return None

        data = response.json()

        if data is None or "login" not in data:
            return None

        return { "account": data["login"],
                 "username": data["login"],
                 "email": data.get("email"),
                 "fullname": data.get("name") }

if "github" in configuration.auth.PROVIDERS:
    if configuration.auth.PROVIDERS["github"]["enabled"]:
        auth.PROVIDERS["github"] = GitHubAuthentication()

########NEW FILE########
__FILENAME__ = google
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2014 the Critic contributors, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import urllib

import urlutils
import configuration
import auth

class GoogleAuthentication(auth.OAuthProvider):
    def __init__(self):
        super(GoogleAuthentication, self).__init__("google")

        self.client_id = self.configuration["client_id"]
        self.client_secret = self.configuration["client_secret"]
        self.redirect_uri = self.configuration["redirect_uri"]

    def getTitle(self):
        """Title, suitable as X in 'Sign in using your X'"""
        return "Google account"

    def getAccountIdDescription(self):
        return "Google (e.g. GMail) email address"

    def getAccountURL(self, name):
        return None

    def getAuthorizeURL(self, state):
        query = urllib.urlencode({ "client_id": self.client_id,
                                   "response_type": "code",
                                   "scope": "openid email",
                                   "redirect_uri": self.redirect_uri,
                                   "state": state })

        return "https://accounts.google.com/o/oauth2/auth?" + query

    def getAccessToken(self, code):
        response = urlutils.post(
            "https://accounts.google.com/o/oauth2/token",
            data={ "code": code,
                   "client_id": self.client_id,
                   "client_secret": self.client_secret,
                   "redirect_uri": self.redirect_uri,
                   "grant_type": "authorization_code" },
            headers={ "Accept": "application/json" },
            verify=False)

        if response.status_code != 200:
            return None

        data = response.json()

        if data is None:
            return None
        elif "error" in data:
            raise auth.Failure(data["error"])
        elif "access_token" not in data:
            return None

        return data["access_token"]

    def getUserData(self, access_token):
        response = urlutils.get(
            "https://www.googleapis.com/oauth2/v3/userinfo",
            params={ "access_token": access_token },
            verify=False)

        if response.status_code != 200:
            return None

        data = response.json()

        if data is None or "email" not in data:
            return None

        email = data["email"]
        username = email.partition("@")[0]

        return { "account": email,
                 "username": username,
                 "email": email,
                 "fullname": data.get("name", username) }

if "google" in configuration.auth.PROVIDERS:
    if configuration.auth.PROVIDERS["google"]["enabled"]:
        auth.PROVIDERS["google"] = GoogleAuthentication()

########NEW FILE########
__FILENAME__ = branchtracker
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2012 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import sys
import os
import time
import traceback

sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(sys.argv[0]), "..")))

import background.utils
import dbutils
import gitutils
import mailutils
import configuration

class BranchTracker(background.utils.BackgroundProcess):
    def __init__(self):
        super(BranchTracker, self).__init__(service=configuration.services.BRANCHTRACKER)

    def update(self, trackedbranch_id, repository_id, local_name, remote, remote_name, forced):
        repository = gitutils.Repository.fromId(self.db, repository_id)

        try:
            with repository.relaycopy("branchtracker") as relay:
                relay.run("remote", "add", "source", remote)

                current = None
                new = None
                tags = []

                if local_name == "*":
                    output = relay.run("fetch", "source", "refs/tags/*:refs/tags/*", include_stderr=True)
                    for line in output.splitlines():
                        if "[new tag]" in line:
                            tags.append(line.rsplit(" ", 1)[-1])
                else:
                    relay.run("fetch", "--quiet", "--no-tags", "source", "refs/heads/%s:refs/remotes/source/%s" % (remote_name, remote_name))
                    try:
                        current = repository.revparse("refs/heads/%s" % local_name)
                    except gitutils.GitReferenceError:
                        # It's okay if the local branch doesn't exist (yet).
                        pass
                    new = relay.run("rev-parse", "refs/remotes/source/%s" % remote_name).strip()

                if current != new or tags:
                    if local_name == "*":
                        refspecs = [("refs/tags/%s" % tag) for tag in tags]
                    else:
                        refspecs = ["refs/remotes/source/%s:refs/heads/%s"
                                    % (remote_name, local_name)]

                    returncode, stdout, stderr = relay.run(
                        "push", "--force", "origin", *refspecs,
                        env={ "CRITIC_FLAGS": "trackedbranch_id=%d" % trackedbranch_id },
                        check_errors=False)

                    stderr = stderr.replace("\x1b[K", "")

                    if returncode == 0:
                        if local_name == "*":
                            for tag in tags:
                                self.info("  updated tag: %s" % tag)
                        elif current:
                            self.info("  updated branch: %s: %s..%s" % (local_name, current[:8], new[:8]))
                        else:
                            self.info("  created branch: %s: %s" % (local_name, new[:8]))

                        hook_output = ""

                        for line in stderr.splitlines():
                            if line.startswith("remote: "):
                                self.debug("  [hook] " + line[8:])
                                hook_output += line[8:] + "\n"

                        if local_name != "*":
                            cursor = self.db.cursor()
                            cursor.execute("INSERT INTO trackedbranchlog (branch, from_sha1, to_sha1, hook_output, successful) VALUES (%s, %s, %s, %s, %s)",
                                           (trackedbranch_id, current if current else '0' * 40, new if new else '0' * 40, hook_output, True))
                            self.db.commit()
                    else:
                        if local_name == "*":
                            error = "update of tags from %s failed" % remote
                        else:
                            error = "update of branch %s from %s in %s failed" % (local_name, remote_name, remote)

                        hook_output = ""

                        for line in stderr.splitlines():
                            error += "\n    " + line
                            if line.startswith("remote: "):
                                hook_output += line[8:] + "\n"

                        self.error(error)

                        cursor = self.db.cursor()

                        if local_name != "*":
                            cursor.execute("""INSERT INTO trackedbranchlog (branch, from_sha1, to_sha1, hook_output, successful)
                                                   VALUES (%s, %s, %s, %s, %s)""",
                                           (trackedbranch_id, current, new, hook_output, False))
                            self.db.commit()

                        cursor.execute("SELECT uid FROM trackedbranchusers WHERE branch=%s", (trackedbranch_id,))
                        recipients = [dbutils.User.fromId(self.db, user_id) for (user_id,) in cursor]

                        if local_name == "*":
                            mailutils.sendMessage(recipients, "%s: update of tags from %s stopped!" % (repository.name, remote),
                                                  """\
The automatic update of tags in
  %s:%s
from the remote
  %s
failed, and has been disabled.  Manual intervention is required to resume the
automatic updating.

Output from Critic's git hook
-----------------------------

%s""" % (configuration.base.HOSTNAME, repository.path, remote, hook_output))
                        else:
                            mailutils.sendMessage(recipients, "%s: update from %s in %s stopped!" % (local_name, remote_name, remote),
                                                  """\
The automatic update of the branch '%s' in
  %s:%s
from the branch '%s' in
  %s
failed, and has been disabled.  Manual intervention is required to resume the
automatic updating.

Output from Critic's git hook
-----------------------------

%s""" % (local_name, configuration.base.HOSTNAME, repository.path, remote_name, remote, hook_output))

                        # Disable the tracking.
                        return False
                else:
                    self.debug("  fetched %s in %s; no changes" % (remote_name, remote))

            # Everything went well; keep the tracking enabled.
            return True
        except:
            exception = traceback.format_exc()

            if local_name == "*":
                error = "  update of tags from %s failed" % remote
            else:
                error = "  update of branch %s from %s in %s failed" % (local_name, remote_name, remote)

            for line in exception.splitlines():
                error += "\n    " + line

            self.error(error)

            # The expected failure (in case of diverged branches, or review branch
            # irregularities) is a failed "git push" and is handled above.  This is
            # an unexpected failure, so might be intermittent.  Leave the tracking
            # enabled and spam the system administrator(s).
            return True

    def run(self):
        self.db = dbutils.Database()

        while not self.terminated:
            self.interrupted = False

            cursor = self.db.cursor()
            cursor.execute("""SELECT id, repository, local_name, remote, remote_name, forced
                                FROM trackedbranches
                               WHERE NOT disabled
                                 AND (next IS NULL OR next < NOW())
                            ORDER BY next ASC NULLS FIRST""")
            rows = cursor.fetchall()

            for trackedbranch_id, repository_id, local_name, remote, remote_name, forced in rows:
                if local_name == "*":
                    self.info("checking tags in %s" % remote)
                else:
                    self.info("checking %s in %s" % (remote_name, remote))

                cursor.execute("""UPDATE trackedbranches
                                     SET previous=NOW(),
                                         next=NOW() + delay,
                                         updating=TRUE
                                   WHERE repository=%s
                                     AND local_name=%s
                               RETURNING next::text""",
                               (repository_id, local_name))
                next_at = cursor.fetchone()[0]

                self.db.commit()

                if self.update(trackedbranch_id, repository_id, local_name, remote, remote_name, forced):
                    cursor.execute("""UPDATE trackedbranches
                                         SET updating=FALSE
                                       WHERE repository=%s
                                         AND local_name=%s""",
                                   (repository_id, local_name))
                    self.info("  next scheduled update at %s" % next_at)
                else:
                    cursor.execute("""UPDATE trackedbranches
                                         SET updating=FALSE,
                                             disabled=TRUE
                                       WHERE repository=%s
                                         AND local_name=%s""",
                                   (repository_id, local_name))
                    self.info("  tracking disabled")

                self.db.commit()

                if self.terminated: break

            cursor.execute("""SELECT 1
                                FROM trackedbranches
                               WHERE NOT disabled
                                 AND next IS NULL""")

            if not cursor.fetchone():
                cursor.execute("""SELECT 1
                                    FROM trackedbranches
                                   WHERE NOT disabled""")

                if not cursor.fetchone():
                    self.info("nothing to do; sleeping one hour")
                    delay = 3600
                else:
                    cursor.execute("""SELECT EXTRACT('epoch' FROM (MIN(next) - NOW()))
                                        FROM trackedbranches
                                       WHERE NOT disabled""")

                    delay = max(0, int(cursor.fetchone()[0] or 0))

                    if delay: self.debug("sleeping %d seconds" % delay)

                if delay:
                    gitutils.Repository.forEach(self.db, lambda db, repository: repository.stopBatch())

                    self.db.commit()

                    before = time.time()
                    time.sleep(delay)
                    if self.interrupted:
                        self.debug("sleep interrupted after %.2f seconds" % (time.time() - before))

            self.db.commit()

def start_service():
    tracker = BranchTracker()
    tracker.run()

background.utils.call("branchtracker", start_service)

########NEW FILE########
__FILENAME__ = branchtrackerhook
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2012 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import sys
import os
import signal
import time

sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(sys.argv[0]), "..")))

import dbutils
from textutils import json_encode, json_decode

if "--wait-for-update" in sys.argv:
    data = json_decode(sys.stdin.read())

    branch_id = data["branch_id"]
    timeout = data["timeout"]
    log_offset = data["log_offset"]

    db = dbutils.Database()

    cursor = db.cursor()
    cursor.execute("SELECT MAX(time) FROM trackedbranchlog WHERE branch=%s", (branch_id,))
    last_log_entry = cursor.fetchone()[0]

    start = time.time()

    status = None
    output = ""

    while time.time() - start < timeout:
        time.sleep(0.5)

        db.commit()

        cursor = db.cursor()
        cursor.execute("SELECT hook_output FROM trackedbranchlog WHERE branch=%s ORDER BY time ASC OFFSET %s", (branch_id, log_offset))
        rows = cursor.fetchall()

        if rows:
            for (hook_output,) in rows: output += hook_output
            status = "output"
            break

        cursor.execute("SELECT updating FROM trackedbranches WHERE id=%s", (branch_id,))

        if not cursor.fetchone()[0]:
            # Update performed, but no log entries added.
            status = "no-output"
            break
    else:
        status = "timeout"

    sys.stdout.write(json_encode({ "status": status, "output": output or None }))
    sys.stdout.flush()

    db.close()
else:
    import configuration

    from background.utils import PeerServer
    from textutils import json_decode
    from subprocess import STDOUT

    class BranchTrackerHook(PeerServer):
        class WaitForUpdate(PeerServer.ChildProcess):
            def __init__(self, client, branch_id, timeout, log_offset):
                super(BranchTrackerHook.WaitForUpdate, self).__init__(client.server, [sys.executable, sys.argv[0], "--wait-for-update"], stderr=STDOUT)
                self.client = client
                self.client.write("wait\n")
                self.write(json_encode({ "branch_id": branch_id, "timeout": timeout, "log_offset": log_offset }))
                self.close()

            def handle_input(self, data):
                try: data = json_decode(data)
                except ValueError:
                    self.server.error("invalid response from wait-for-update child: %r" % data)
                    self.client.close()

                if data["status"] == "output":
                    self.client.write(data["output"])
                    self.server.debug("  hook output written to client")
                elif data["status"] == "no-output":
                    self.server.debug("  update produced no hook output")
                else:
                    self.server.debug("  timeout")

                self.client.close()

        class Client(PeerServer.SocketPeer):
            def __init__(self, server, peersocket, peeraddress):
                super(BranchTrackerHook.Client, self).__init__(server, peersocket)
                self.__peeraddress = peeraddress

            def handle_input(self, data):
                try: data = json_decode(data)
                except ValueError: return

                message = "connection from %s:%d:" % self.__peeraddress
                message += "\n  repository: %s" % data["repository"]

                if data.has_key("timeout"):
                    message += "\n  timeout:    %d" % data["timeout"]
                if data["branches"]:
                    message += "\n  branches:   %s" % ", ".join(data["branches"])
                if data["tags"]:
                    message += "\n  tags:       %s" % ", ".join(data["tags"])

                self.server.info(message)

                db = dbutils.Database()

                try:
                    cursor = db.cursor()
                    notify_tracker = False
                    wait_for_reply = False

                    # Make sure the 'knownremotes' table has this remote listed
                    # as "pushing" since it obviously is.

                    cursor.execute("""SELECT pushing
                                        FROM knownremotes
                                       WHERE url=%s""",
                                   (data["repository"],))

                    row = cursor.fetchone()

                    if not row:
                        cursor.execute("""INSERT INTO knownremotes (url, pushing)
                                               VALUES (%s, TRUE)""",
                                       (data["repository"],))
                    elif not row[0]:
                        cursor.execute("""UPDATE knownremotes
                                             SET pushing=TRUE
                                           WHERE url=%s""",
                                       (data["repository"],))

                    # If we just recorded this remote as "pushing," adjust the
                    # configured updating frequency of any existing tracked
                    # branches from it.

                    if not row or not row[0]:
                        cursor.execute("""UPDATE trackedbranches
                                             SET delay='1 week'
                                           WHERE remote=%s""",
                                       (data["repository"],))

                    for branch in data["branches"]:
                        cursor.execute("""SELECT id, local_name
                                            FROM trackedbranches
                                           WHERE remote=%s
                                             AND remote_name=%s
                                             AND NOT disabled
                                             AND next IS NOT NULL""",
                                       (data["repository"], branch))

                        row = cursor.fetchone()
                        if row:
                            branch_id, local_name = row

                            cursor.execute("""UPDATE trackedbranches
                                                 SET next=NULL
                                               WHERE id=%s""",
                                           (branch_id,))

                            notify_tracker = True
                            self.server.debug("tracked branch: %s" % local_name)

                            if len(data["branches"]) == 1 and local_name.startswith("r/"):
                                wait_for_reply = (True, branch_id)
                                self.server.debug("  will wait for reply")

                    if data["tags"]:
                        cursor.execute("""SELECT id
                                            FROM trackedbranches
                                           WHERE remote=%s
                                             AND remote_name=%s
                                             AND NOT disabled
                                             AND next IS NOT NULL""",
                                       (data["repository"], "*"))

                        row = cursor.fetchone()
                        if row:
                            branch_id = row[0]

                            cursor.execute("""UPDATE trackedbranches
                                                 SET next=NULL
                                               WHERE id=%s""",
                                           (branch_id,))

                            notify_tracker = True

                    db.commit()

                    if notify_tracker:
                        if wait_for_reply:
                            branch_id = wait_for_reply[1]
                            cursor.execute("SELECT COUNT(*) FROM trackedbranchlog WHERE branch=%s", (branch_id,))
                            log_offset = cursor.fetchone()[0]
                            self.server.add_peer(BranchTrackerHook.WaitForUpdate(self, branch_id, data.get("timeout", 30), log_offset))

                        try:
                            branchtracker_pid = int(open(configuration.services.BRANCHTRACKER["pidfile_path"]).read().strip())
                            os.kill(branchtracker_pid, signal.SIGHUP)
                        except:
                            self.server.exception()
                            return

                        if wait_for_reply:
                            return

                    self.close()
                finally:
                    try: db.close()
                    except: pass

        def __init__(self):
            super(BranchTrackerHook, self).__init__(service=configuration.services.BRANCHTRACKERHOOK)

        def handle_peer(self, peersocket, peeraddress):
            return BranchTrackerHook.Client(self, peersocket, peeraddress)

    server = BranchTrackerHook()
    server.run()

########NEW FILE########
__FILENAME__ = changeset
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2012 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import sys
import os.path

sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(sys.argv[0]), "..")))

import configuration
import dbutils
import background.utils

from textutils import json_decode, json_encode

if "--json-job" in sys.argv[1:]:
    from resource import getrlimit, setrlimit, RLIMIT_RSS
    from traceback import print_exc

    def perform_job():
        soft_limit, hard_limit = getrlimit(RLIMIT_RSS)
        rss_limit = configuration.services.CHANGESET["rss_limit"]
        if soft_limit < rss_limit:
            setrlimit(RLIMIT_RSS, (rss_limit, hard_limit))

        from changeset.create import createChangeset

        request = json_decode(sys.stdin.read())

        try:
            db = dbutils.Database()

            createChangeset(db, request)

            db.close()

            sys.stdout.write(json_encode(request))
        except:
            print "Request:"
            print json_encode(request, indent=2)
            print

            print_exc(file=sys.stdout)

    background.utils.call("changeset_job", perform_job)
else:
    from background.utils import JSONJobServer

    def describeRequest(request):
        if request["changeset_type"] in ("direct", "merge", "conflicts"):
            return "%s (%s)" % (request["changeset_type"], request["child_sha1"][:8])
        else:
            return "custom (%s..%s)" % (request["parent_sha1"][:8], request["child_sha1"][:8])

    class ChangesetServer(JSONJobServer):
        def __init__(self):
            service = configuration.services.CHANGESET

            super(ChangesetServer, self).__init__(service)

            if "purge_at" in service:
                hour, minute = service["purge_at"]
                self.register_maintenance(hour=hour, minute=minute, callback=self.__purge)

        def execute_command(self, client, command):
            if command["command"] == "purge":
                purged_count = self.__purge()

                client.write(json_encode({ "status": "ok",
                                           "purged": purged_count }))
                client.close()
            else:
                super(ChangesetServer, self).execute_command(client, command)

        def request_started(self, job, request):
            super(ChangesetServer, self).request_started(job, request)

            self.debug("started: %s in %s [pid=%d]" % (describeRequest(request), request["repository_name"], job.pid))

        def request_finished(self, job, request, result):
            super(ChangesetServer, self).request_finished(job, request, result)

            if "error" not in result:
                for parent_sha1, changeset_id in result["changeset_ids"].items():
                    self.info("finished: %d for %s (%s..%s) in %s [pid=%d]"
                              % (changeset_id, request["changeset_type"],
                                 parent_sha1[:8], request["child_sha1"][:8],
                                 request["repository_name"], job.pid))

        def __purge(self):
            db = dbutils.Database()
            cursor = db.cursor()

            cursor.execute("""SELECT COUNT(*)
                                FROM changesets
                                JOIN customchangesets ON (customchangesets.changeset=changesets.id)
                               WHERE time < NOW() - INTERVAL '3 months'""")
            npurged = cursor.fetchone()[0]

            if npurged:
                self.info("purging %d old custom changesets" % npurged)

                cursor.execute("DELETE FROM changesets USING customchangesets WHERE id=changeset AND time < NOW() - INTERVAL '3 months'")
                db.commit()

            db.close()

            return npurged

    def start_service():
        server = ChangesetServer()
        server.run()

    background.utils.call("changeset", start_service)

########NEW FILE########
__FILENAME__ = daemon
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2012 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import os
import sys

def detach():
    try:
        if os.fork() != 0:
            # Exit from parent process.
            sys.exit(0)
    except OSError as error:
        print >>sys.stderr, "fork failed: %s" % error.message
        sys.exit(1)

    os.setsid()
    os.umask(0)

    try:
        if os.fork() != 0:
            # Exit from parent process.
            sys.exit(0)
    except OSError as error:
        print >>sys.stderr, "fork failed: %s" % error.message
        sys.exit(1)

    sys.stdout.flush()
    sys.stderr.flush()

    stdin = open("/dev/null", "r")
    stdout = open("/dev/null", "a+")
    stderr = open("/dev/null", "a+")

    os.dup2(stdin.fileno(), sys.stdin.fileno())
    os.dup2(stdout.fileno(), sys.stdout.fileno())
    os.dup2(stderr.fileno(), sys.stderr.fileno())

########NEW FILE########
__FILENAME__ = githook
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2012 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import sys
import os
import os.path

sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(sys.argv[0]), "..")))

import configuration
import background.utils

from textutils import json_decode, json_encode

sys_stdout = sys.stdout

def slave():
    import StringIO
    import traceback

    import index

    def reject(message):
        sys_stdout.write(json_encode({ "status": "reject", "message": message }))
        sys.exit(0)

    def error(message):
        sys_stdout.write(json_encode({ "status": "error", "error": message }))
        sys.exit(0)

    try:
        data = sys.stdin.read()
        request = json_decode(data)

        create_branches = []
        delete_branches = []
        update_branches = []

        create_tags = []
        delete_tags = []
        update_tags = []

        user_name = request["user_name"]
        repository_name = request["repository_name"]

        if request["flags"] and user_name == configuration.base.SYSTEM_USER_NAME:
            flags = dict(flag.split("=", 1) for flag in request["flags"].split(","))
        else:
            flags = {}

        sys.stdout = StringIO.StringIO()

        index.init()

        for ref in request["refs"]:
            name = ref["name"]
            old_sha1 = ref["old_sha1"]
            new_sha1 = ref["new_sha1"]

            if "//" in name: reject("invalid ref name: '%s'" % name)
            if not name.startswith("refs/"): reject("unexpected ref name: '%s'" % name)

            name = name[len("refs/"):]

            if name.startswith("heads/"):
                name = name[len("heads/"):]
                if new_sha1 == '0000000000000000000000000000000000000000':
                    delete_branches.append((name, old_sha1))
                elif old_sha1 == '0000000000000000000000000000000000000000':
                    create_branches.append((name, new_sha1))
                else:
                    update_branches.append((name, old_sha1, new_sha1))
            elif name.startswith("tags/"):
                name = name[len("tags/"):]
                if old_sha1 == '0000000000000000000000000000000000000000':
                    create_tags.append((name, new_sha1))
                elif new_sha1 == '0000000000000000000000000000000000000000':
                    delete_tags.append(name)
                else:
                    update_tags.append((name, old_sha1, new_sha1))
            elif name.startswith("replays/"):
                index.processCommits(repository_name, new_sha1)
            elif name.startswith("keepalive/"):
                name = name[len("keepalive/"):]
                if name != new_sha1: reject("invalid update of '%s'; value is not %s" % (ref["name"], name))
                index.processCommits(repository_name, new_sha1)
            elif name.startswith("temporary/"):
                name = name[len("temporary/"):]
                if new_sha1 != '0000000000000000000000000000000000000000':
                    index.processCommits(repository_name, new_sha1)
            else:
                reject("unexpected ref name: '%s'" % ref["name"])

        multiple = (len(delete_branches) + len(update_branches) + len(create_branches) + len(delete_tags) + len(update_tags) + len(create_tags)) > 1
        info = []

        for name, old in delete_branches:
            index.deleteBranch(user_name, repository_name, name, old)
            info.append("branch deleted: %s" % name)

        for name, old, new in update_branches:
            index.updateBranch(user_name, repository_name, name, old, new, multiple, flags)
            info.append("branch updated: %s (%s..%s)" % (name, old[:8], new[:8]))

        index.createBranches(user_name, repository_name, create_branches, flags)

        for name, new in create_branches:
            info.append("branch created: %s (%s)" % (name, new[:8]))

        for name in delete_tags:
            index.deleteTag(repository_name, name)
            info.append("tag deleted: %s" % name)

        for name, old, new in update_tags:
            index.updateTag(repository_name, name, old, new)
            info.append("tag updated: %s (%s..%s)" % (name, old[:8], new[:8]))

        for name, new in create_tags:
            index.createTag(repository_name, name, new)
            info.append("tag created: %s (%s)" % (name, new[:8]))

        sys_stdout.write(json_encode({ "status": "ok", "accept": True, "output": sys.stdout.getvalue(), "info": info }))

        index.finish()
    except index.IndexException as exception:
        sys_stdout.write(json_encode({ "status": "ok", "accept": False, "output": exception.message, "info": info }))
    except SystemExit:
        raise
    except:
        exception = traceback.format_exc()
        message = """\
%s

Request:
%s

%s""" % (exception.splitlines()[-1], json_encode(request, indent=2), traceback.format_exc())

        sys_stdout.write(json_encode({ "status": "error", "error": message }))
    finally:
        index.abort()

class GitHookServer(background.utils.PeerServer):
    class ChildProcess(background.utils.PeerServer.ChildProcess):
        def __init__(self, server, client):
            super(GitHookServer.ChildProcess, self).__init__(server, [sys.executable, sys.argv[0], "--slave"])
            self.__client = client

        def handle_input(self, data):
            try:
                result = json_decode(data)
            except ValueError:
                result = { "status": "error",
                           "error": ("invalid response:\n" +
                                     background.utils.indent(data)) }
            if result["status"] == "ok":
                for item in result["info"]:
                    self.server.info(item)
                if result["output"]:
                    self.__client.write(result["output"].strip() + "\n")
                if result["accept"]:
                    self.__client.write("ok\n")
            elif result["status"] == "reject":
                self.server.warning(result["message"])
                self.__client.write(result["message"].strip() + "\n")
            else:
                self.server.error(result["error"])
                self.__client.write("""\
An exception was raised while processing the request.  A message has
been sent to the system administrator(s).
""")
            self.__client.close()

    class Client(background.utils.PeerServer.SocketPeer):
        def handle_input(self, data):
            lines = data.splitlines()

            user_name = lines[0]

            # The second line is the value of the REMOTE_USER environment
            # variable (from the environment with which the git hook ran.)
            #
            # We use it as the actual user only if the actual user was the
            # Critic system user, meaning the push was performed by the
            # branch tracker service, the web front-end (for instance via
            # 'git http-backend') or an extension.
            if user_name == configuration.base.SYSTEM_USER_NAME and lines[1]:
                user_name = lines[1]

            self.__request = { "user_name": user_name,
                               "repository_name": lines[2],
                               "flags": lines[3],
                               "refs": [{ "name": name,
                                          "old_sha1": old_sha1,
                                          "new_sha1": new_sha1 }
                                        for old_sha1, new_sha1, name
                                        in map(str.split, lines[4:])] }

            self.server.info("session started: %s / %s"
                             % (self.__request["user_name"],
                                self.__request["repository_name"]))

            child_process = GitHookServer.ChildProcess(self.server, self)
            child_process.write(json_encode(self.__request))
            child_process.close()
            self.server.add_peer(child_process)

        def destroy(self):
            self.server.info("session ended: %s / %s"
                             % (self.__request["user_name"],
                                self.__request["repository_name"]))

    def __init__(self):
        super(GitHookServer, self).__init__(service=configuration.services.GITHOOK)

        os.chmod(configuration.services.GITHOOK["address"], 0770)

    def handle_peer(self, peersocket, peeraddress):
        return GitHookServer.Client(self, peersocket)

def start_service():
    server = GitHookServer()
    server.run()

if "--slave" in sys.argv[1:]:
    background.utils.call("githook", slave)
else:
    background.utils.call("githook", start_service)

########NEW FILE########
__FILENAME__ = highlight
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2012 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import sys
import os
import time
from subprocess import Popen as process

sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(sys.argv[0]), "..")))

import background.utils
from textutils import json_decode, json_encode

if "--json-job" in sys.argv[1:]:
    def perform_job():
        import syntaxhighlight.generate

        request = json_decode(sys.stdin.read())
        request["highlighted"] = syntaxhighlight.generate.generateHighlight(
            repository_path=request["repository_path"],
            sha1=request["sha1"],
            language=request["language"])
        sys.stdout.write(json_encode(request))

    background.utils.call("highlight_job", perform_job)
else:
    import background.utils
    from syntaxhighlight import isHighlighted
    from syntaxhighlight.context import importCodeContexts

    import configuration
    import dbutils

    class HighlightServer(background.utils.JSONJobServer):
        def __init__(self):
            service = configuration.services.HIGHLIGHT

            super(HighlightServer, self).__init__(service)

            self.db = dbutils.Database()

            if "compact_at" in service:
                hour, minute = service["compact_at"]
                self.register_maintenance(hour=hour, minute=minute, callback=self.__compact)

        def request_result(self, request):
            if isHighlighted(request["sha1"], request["language"]):
                result = request.copy()
                result["highlighted"] = True
                return result

        def request_started(self, job, request):
            super(HighlightServer, self).request_started(job, request)

            self.debug("started: %s:%s (%s) in %s [pid=%d]" % (request["path"], request["sha1"][:8], request["language"], request["repository_path"], job.pid))

        def request_finished(self, job, request, result):
            super(HighlightServer, self).request_finished(job, request, result)

            failed = "" if "error" not in result else " (failed!)"
            self.info("finished: %s:%s (%s) in %s [pid=%d]%s" % (request["path"], request["sha1"][:8], request["language"], request["repository_path"], job.pid, failed))

            ncontexts = importCodeContexts(self.db, request["sha1"], request["language"])

            if ncontexts: self.debug("  added %d code contexts" % ncontexts)
            else: self.debug("  no code contexts added")

        def execute_command(self, client, command):
            if command["command"] == "compact":
                uncompressed_count, compressed_count, purged_files_count, purged_contexts_count = self.__compact()

                client.write(json_encode({ "status": "ok",
                                           "uncompressed": uncompressed_count,
                                           "compressed": compressed_count,
                                           "purged_files": purged_files_count,
                                           "purged_contexts": purged_contexts_count }))
                client.close()
            else:
                super(HighlightServer, self).execute_command(client, command)

        def __compact(self):
            import syntaxhighlight

            cache_dir = configuration.services.HIGHLIGHT["cache_dir"]

            if not os.path.isdir(cache_dir):
                # Newly installed system that hasn't highlighted anything.
                return 0, 0, 0, 0

            self.info("cache compacting started")

            now = time.time()

            max_age_uncompressed = 7 * 24 * 60 * 60
            max_age_compressed = 90 * 24 * 60 * 60

            uncompressed_count = 0
            compressed_count = 0

            purged_paths = []

            db = dbutils.Database()
            cursor = db.cursor()

            cursor.execute("CREATE TEMPORARY TABLE purged (sha1 CHAR(40) PRIMARY KEY)")
            cursor.execute("INSERT INTO purged (sha1) SELECT DISTINCT sha1 FROM codecontexts")

            for section in sorted(os.listdir(cache_dir)):
                if len(section) == 2:
                    for filename in os.listdir("%s/%s" % (cache_dir, section)):
                        fullname = "%s/%s/%s" % (cache_dir, section, filename)
                        age = now - os.stat(fullname).st_mtime

                        if len(filename) > 38 and filename[38] == "." and filename[39:] in syntaxhighlight.LANGUAGES:
                            cursor.execute("DELETE FROM purged WHERE sha1=%s", (section + filename[:38],))
                            if age > max_age_uncompressed:
                                self.debug("compressing: %s/%s" % (section, filename))
                                worker = process(["/bin/bzip2", fullname])
                                worker.wait()
                                compressed_count += 1
                            else:
                                uncompressed_count += 1
                        elif len(filename) > 41 and filename[38] == "." and filename[-4] == "." and filename[39:-4] in syntaxhighlight.LANGUAGES:
                            if filename.endswith(".bz2"):
                                if age > max_age_compressed:
                                    self.debug("purging: %s/%s" % (section, filename))
                                    purged_paths.append(fullname)
                                else:
                                    cursor.execute("DELETE FROM purged WHERE sha1=%s", (section + filename[:38],))
                                    compressed_count += 1
                            elif filename.endswith(".ctx"):
                                self.debug("deleting context file: %s/%s" % (section, filename))
                                os.unlink(fullname)
                        else:
                            os.unlink(fullname)

            self.info("cache compacting finished: uncompressed=%d / compressed=%d / purged=%d"
                      % (uncompressed_count, compressed_count, len(purged_paths)))

            if purged_paths:
                for path in purged_paths: os.unlink(path)

            cursor.execute("SELECT COUNT(*) FROM purged")

            purged_contexts = cursor.fetchone()[0]

            cursor.execute("DELETE FROM codecontexts USING purged WHERE codecontexts.sha1=purged.sha1")

            db.commit()
            db.close()

            return uncompressed_count, compressed_count, len(purged_paths), purged_contexts

    def start_service():
        server = HighlightServer()
        server.run()

    background.utils.call("highlight", start_service)

########NEW FILE########
__FILENAME__ = maildelivery
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2012 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import sys
import os
import time
import json

import smtplib
import email.mime.text
import email.header
import email.utils

sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(sys.argv[0]), "..")))

import configuration
import background.utils

class User:
    def __init__(self, *args):
        if len(args) > 1:
            self.email, self.fullname = args[-2:]
        else:
            self.fullname, self.email = email.utils.parseaddr(args[0])

class MailDelivery(background.utils.PeerServer):
    def __init__(self, credentials):
        # We disable the automatic administrator mails (using the
        # 'send_administrator_mails' argument) since
        #
        # 1) it's pretty pointless to report mail delivery problems
        #    via mail, and
        #
        # 2) it can cause runaway mail generation, since failure to
        #    timely deliver the mail delivery problem report emails
        #    would trigger further automatic problem report emails.
        #
        # Instead, we keep track of having encountered any problems,
        # and send a single administrator mail ("check the logs")
        # after having successfully delivered an email.

        service = configuration.services.MAILDELIVERY

        super(MailDelivery, self).__init__(service=service,
                                           send_administrator_mails=False)

        self.__credentials = credentials
        self.__connection = None
        self.__connection_timeout = service.get("timeout")
        self.__has_logged_warning = 0
        self.__has_logged_error = 0

        self.register_maintenance(hour=3, minute=45, callback=self.__cleanup)

    def __sendAdministratorMessage(self):
        from_user = User(configuration.base.SYSTEM_USER_EMAIL, "Critic System")
        recipients = []

        for recipient in configuration.base.SYSTEM_RECIPIENTS:
            recipients.append(User(recipient))

        if self.__has_logged_warning and self.__has_logged_error:
            what = "%d warning%s and %d error%s" % (self.__has_logged_warning,
                                                    "s" if self.__has_logged_warning > 1 else "",
                                                    self.__has_logged_error,
                                                    "s" if self.__has_logged_error > 1 else "")
        elif self.__has_logged_warning:
            what = "%d warning%s" % (self.__has_logged_warning,
                                     "s" if self.__has_logged_warning > 1 else "")
        else:
            what = "%d error%s" % (self.__has_logged_error,
                                     "s" if self.__has_logged_error > 1 else "")

        for to_user in recipients:
            self.__send(message_id=None,
                        parent_message_id=None,
                        headers={},
                        from_user=from_user,
                        to_user=to_user,
                        recipients=recipients,
                        subject="maildelivery: check the logs!",
                        body="%s have been logged.\n\n-- critic\n" % what,
                        try_once=True)

        self.__has_logged_warning = 0
        self.__has_logged_error = 0

    def run(self):
        try:
            sleeptime = 0

            while not self.terminated:
                self.interrupted = False

                filenames = os.listdir(configuration.paths.OUTBOX)
                pending = []

                for filename in filenames:
                    if filename.endswith(".txt"):
                        pending.append("%s/%s" % (configuration.paths.OUTBOX, filename))

                if pending:
                    self.__connect()

                    # We may have been terminated while attempting to connect.
                    if self.terminated:
                        return

                    sleeptime = 0

                    now = time.time()

                    def age(filename):
                        return now - os.stat(filename).st_ctime

                    too_old = len(filter(lambda filename: age(filename) > 60, pending))
                    oldest_age = max(map(age, pending))

                    if too_old > 0:
                        self.warning(("%d files were created more than 60 seconds ago\n"
                                      "  The oldest is %s which is %d seconds old.")
                                     % (too_old, os.path.basename(filename), oldest_age))
                        self.__has_logged_warning += 1

                    for filename in sorted(pending):
                        lines = open(filename).readlines()

                        try:
                            if self.__send(**eval(lines[0])):
                                os.rename(filename, "%s/sent/%s.sent" % (configuration.paths.OUTBOX, os.path.basename(filename)))

                                if self.__has_logged_warning or self.__has_logged_error:
                                    try: self.__sendAdministratorMessage()
                                    except:
                                        self.exception()
                                        self.__has_logged_error += 1

                            # We may have been terminated while attempting to send.
                            if self.terminated:
                                return
                        except:
                            self.exception()
                            self.__has_logged_error += 1
                            os.rename(filename, "%s/%s.invalid" % (configuration.paths.OUTBOX, os.path.basename(filename)))
                            continue
                else:
                    if sleeptime > 25:
                        self.__disconnect()

                    before = time.time()
                    timeout = (30 - sleeptime) if self.__connection else self.run_maintenance()

                    self.debug("sleeping %d seconds" % timeout)

                    time.sleep(timeout)

                    if self.interrupted:
                        self.debug("sleep interrupted after %.2f seconds" % (time.time() - before))

                    sleeptime += (time.time() - before)
        finally:
            self.__disconnect()

    def __connect(self):
        if not self.__connection:
            attempts = 0

            while not self.terminated:
                attempts += 1

                try:
                    if configuration.smtp.USE_SSL:
                        self.__connection = smtplib.SMTP_SSL(timeout=self.__connection_timeout)
                    else:
                        self.__connection = smtplib.SMTP(timeout=self.__connection_timeout)

                    self.__connection.connect(configuration.smtp.HOST, configuration.smtp.PORT)

                    if configuration.smtp.USE_STARTTLS:
                        self.__connection.starttls()

                    if self.__credentials:
                        self.__connection.login(self.__credentials["username"],
                                                self.__credentials["password"])

                    self.debug("connected")
                    return
                except:
                    self.debug("failed to connect to SMTP server")
                    if (attempts % 5) == 0:
                        self.error("Failed to connect to SMTP server %d times.  "
                                   "Will keep retrying." % attempts)
                        self.__has_logged_error += 1
                    self.__connection = None

                seconds = min(60, 2 ** attempts)

                self.debug("sleeping %d seconds" % seconds)

                time.sleep(seconds)

    def __disconnect(self):
        if self.__connection:
            try:
                self.__connection.quit()
                self.debug("disconnected")
            except: pass

            self.__connection = None

    def __send(self, message_id, parent_message_id, headers, from_user, to_user, recipients, subject, body, **kwargs):
        def isascii(s):
            return all(ord(c) < 128 for c in s)

        def usersAsHeader(users, header_name):
            header = email.header.Header(header_name=header_name)

            for index, user in enumerate(users):
                if isascii(user.fullname):
                    header.append(user.fullname, "us-ascii")
                else:
                    header.append(user.fullname, "utf-8")
                if index < len(users) - 1:
                    header.append("<%s>," % user.email, "us-ascii")
                else:
                    header.append("<%s>" % user.email, "us-ascii")

            return header

        def stringAsHeader(s, name):
            if isascii(s): return email.header.Header(s, "us-ascii", header_name=name)
            else: return email.header.Header(s, "utf-8", header_name=name)

        message = email.mime.text.MIMEText(body, "plain", "utf-8")
        recipients = filter(lambda user: bool(user.email), recipients)

        if not to_user.email:
            return True

        if message_id:
            message_id = "<%s@%s>" % (message_id, configuration.base.HOSTNAME)
            message["Message-ID"] = message_id
        else:
            message_id = "N/A"

        if parent_message_id:
            message["In-Reply-To"] = parent_message_id
            message["References"] = parent_message_id

        message["From"] = usersAsHeader([from_user], "From")
        message["To"] = usersAsHeader(recipients, "To")
        message["Subject"] = stringAsHeader(subject, "Subject")

        for name, value in headers.items():
            message[name] = value

        self.debug("%s => %s (%s)" % (from_user.email, to_user.email, message_id))

        # Used from __sendAdministratorMessage(); we'll try once to send it even
        # if self.terminated.
        try_once = kwargs.get("try_once", False)

        attempts = 0

        while try_once or not self.terminated:
            try_once = False

            try:
                self.__connection.sendmail(configuration.base.SYSTEM_USER_EMAIL, [to_user.email], message.as_string())
                return True
            except:
                self.exception()
                self.__has_logged_error += 1

                if self.terminated:
                    return False

                attempts += 1
                sleeptime = min(60, 2 ** attempts)

                self.error("delivery failure: sleeping %d seconds" % sleeptime)

                self.__disconnect()
                time.sleep(sleeptime)
                self.__connect()

        # We were terminated before the mail was sent.  Return false to keep the
        # mail in the outbox for later delivery.
        return False

    def __cleanup(self):
        now = time.time()
        deleted = 0

        for filename in os.listdir(os.path.join(configuration.paths.OUTBOX, "sent")):
            if filename.endswith(".txt.sent"):
                filename = os.path.join(configuration.paths.OUTBOX, "sent", filename)
                age = now - os.stat(filename).st_ctime

                if age > 7 * 24 * 60 * 60:
                    os.unlink(filename)
                    deleted += 1

        if deleted:
            self.info("deleted %d files from %s"
                      % (deleted, os.path.join(configuration.paths.OUTBOX, "sent")))

def start_service():
    stdin_data = sys.stdin.read()

    if stdin_data:
        credentials = json.loads(stdin_data)["credentials"]
        if not credentials.get("username") or not credentials.get("password"):
            credentials = None
    else:
        credentials = None

    maildelivery = MailDelivery(credentials)
    maildelivery.run()

background.utils.call("maildelivery", start_service)

########NEW FILE########
__FILENAME__ = maintenance
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2013 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import sys
import os
import time
import shutil

sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(sys.argv[0]), "..")))

import configuration
import dbutils
import gitutils
import background.utils

class Maintenance(background.utils.BackgroundProcess):
    def __init__(self):
        service = configuration.services.MAINTENANCE

        super(Maintenance, self).__init__(service=service)

        hour, minute = service["maintenance_at"]
        self.register_maintenance(hour=hour, minute=minute, callback=self.__maintenance)

    def run(self):
        with dbutils.Database() as db:
            # Do an initial load/update of timezones.
            #
            # The 'timezones' table initially (post-installation) only contains
            # the Universal/UTC timezone; this call adds all the others that the
            # PostgreSQL database server knows about.
            dbutils.loadTimezones(db)

        super(Maintenance, self).run()

    def __maintenance(self):
        with dbutils.Database() as db:
            cursor = db.cursor()

            # Update the UTC offsets of all timezones.
            #
            # The PostgreSQL database server has accurate (DST-adjusted) values,
            # but is very slow to query, so we cache the UTC offsets in our
            # 'timezones' table.  This call updates that cache every night.
            # (This is obviously a no-op most nights, but we don't want to have
            # to care about which nights it isn't.)
            self.debug("updating timezones")
            dbutils.updateTimezones(db)

            if self.terminated:
                return

            # Run a garbage collect in all Git repositories, to keep them neat
            # and tidy.
            cursor.execute("SELECT name FROM repositories")
            for (repository_name,) in cursor:
                self.debug("repository GC: %s" % repository_name)
                try:
                    repository = gitutils.Repository.fromName(db, repository_name)
                    repository.run("gc", "--prune=1 day", "--quiet")
                    repository.stopBatch()
                except Exception:
                    self.exception("repository GC failed: %s" % repository_name)

                if self.terminated:
                    return

            if configuration.extensions.ENABLED:
                now = time.time()
                max_age = 7 * 24 * 60 * 60

                base_path = os.path.join(configuration.paths.DATA_DIR,
                                         "temporary", "EXTENSIONS")

                for user_name in os.listdir(base_path):
                    user_dir = os.path.join(base_path, user_name)

                    for extension_id in os.listdir(user_dir):
                        extension_dir = os.path.join(user_dir, extension_id)

                        for repository_name in os.listdir(extension_dir):
                            repository_dir = os.path.join(extension_dir,
                                                          repository_name)
                            age = now - os.stat(repository_dir).st_mtime

                            if age > max_age:
                                self.info("Removing repository work copy: %s"
                                          % repository_dir)
                                shutil.rmtree(repository_dir)

def start_service():
    maintenance = Maintenance()
    maintenance.run()

background.utils.call("maintenance", start_service)

########NEW FILE########
__FILENAME__ = servicemanager
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2012 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import sys
import subprocess
import time
import signal
import os
import json

import configuration

if "--slave" in sys.argv:
    import background.utils

    class ServiceManager(background.utils.PeerServer):
        class Service(object):
            class Process(background.utils.PeerServer.ChildProcess):
                def __init__(self, service, input_data):
                    super(ServiceManager.Service.Process, self).__init__(
                        service.manager, [sys.executable, "-m", service.module],
                        stderr=subprocess.STDOUT)

                    self.__service = service
                    self.__output = None
                    if input_data:
                        self.write(json.dumps(input_data))
                    self.close()

                def handle_input(self, data):
                    self.__output = data

                def destroy(self):
                    super(ServiceManager.Service.Process, self).destroy()
                    self.__service.stopped(self.returncode, self.__output)

            def __init__(self, manager, service_data):
                self.manager = manager
                self.name = service_data["name"]
                self.module = service_data["module"]
                self.started = None
                self.process = None
                self.callbacks = []

            def signal_callbacks(self, event):
                self.callbacks = filter(lambda callback: callback(event), self.callbacks)

            def start(self, input_data):
                self.process = ServiceManager.Service.Process(self, input_data)
                self.started = time.time()
                self.manager.add_peer(self.process)
                self.manager.info("%s: started (pid=%d)" % (self.name, self.process.pid))
                self.input_data = input_data
                self.signal_callbacks("started")

            def restart(self, callback=None):
                if callback:
                    self.callbacks.append(callback)
                self.start(self.input_data)

            def stop(self, callback=None):
                if callback:
                    self.callbacks.append(callback)
                if self.process:
                    self.manager.info("%s: sending process SIGTERM" % self.name)
                    self.process.kill(signal.SIGTERM)

            def stopped(self, returncode, output):
                restart = not self.manager.terminated and not self.manager.restart_requested
                if returncode != 0:
                    message = "%s: exited with returncode %d" % (self.name, returncode)
                    if output:
                        message += "\n" + background.utils.indent(output)
                    if time.time() - self.started < 1:
                        message += "\n  Process restarted less than 1 second ago; not restarting."
                        restart = False
                    self.manager.error(message)
                else:
                    self.manager.info("%s: exited normally" % self.name)
                self.process = None
                if restart:
                    self.restart()
                else:
                    self.signal_callbacks("stopped")

        class Client(background.utils.PeerServer.SocketPeer):
            def __init__(self, manager, peersocket):
                super(ServiceManager.Client, self).__init__(manager, peersocket)
                self.__manager = manager

            def send_response(self, value):
                self.write(background.utils.json_encode(value))
                self.close()

            def handle_input(self, data):
                result = self.send_response

                try:
                    request = background.utils.json_decode(data)
                except:
                    return result({ "status": "error",
                                    "error": "invalid input: JSON decode failed" })

                if type(request) is not dict:
                    return result({ "status": "error",
                                    "error": "invalid input: expected object" })

                if request.get("query") == "status":
                    services = { "manager": { "module": "background.servicemanager",
                                              "uptime": time.time() - self.__manager.started,
                                              "pid": os.getpid() }}

                    for service in self.__manager.services:
                        uptime = time.time() - service.started if service.started else -1
                        pid = service.process.pid if service.process else -1
                        services[service.name] = { "module": service.module,
                                                   "uptime": uptime,
                                                   "pid": pid }

                    return result({ "status": "ok", "services": services })
                elif request.get("command") == "restart":
                    if "service" not in request:
                        return result({ "status": "error",
                                        "error": "invalid input: no service specified" })
                    if request["service"] == "manager":
                        self.__manager.info("restart requested")
                        self.__manager.requestRestart()
                        return result({ "status": "ok" })
                    for service in self.__manager.services:
                        if service.name == request.get("service"):
                            self.__manager.info("%s: restart requested" % service.name)
                            def callback(event):
                                self.send_response({ "status": "ok",
                                                     "event": event })
                            if service.process: service.stop(callback)
                            else: service.restart(callback)
                            break
                    else:
                        return result({ "status": "error", "error": "%s: no such service" % request.get("service") })
                else:
                    return result({ "status": "error", "error": "invalid input: unsupported data" })

        def __init__(self, input_data):
            service = configuration.services.SERVICEMANAGER.copy()

            # This is the slave process; the pid file is maintained by the
            # master process.
            del service["pidfile_path"]

            super(ServiceManager, self).__init__(service=service)

            self.input_data = input_data
            self.services = []
            self.started = time.time()

        def handle_peer(self, peersocket, peeraddress):
            return ServiceManager.Client(self, peersocket)

        def startup(self):
            for service_data in configuration.services.SERVICEMANAGER["services"]:
                service = ServiceManager.Service(self, service_data)
                service.start(self.input_data.get(service.name))
                self.services.append(service)

        def shutdown(self):
            for service in self.services:
                service.stop()

        def requestRestart(self):
            super(ServiceManager, self).requestRestart()

            for service in self.services:
                service.stop()

    def start_service():
        stdin_data = sys.stdin.read()

        if stdin_data:
            input_data = json.loads(stdin_data)
        else:
            input_data = {}

        manager = ServiceManager(input_data)
        manager.run()

    background.utils.call("servicemanager", start_service)
else:
    import errno
    import pwd
    import grp
    import stat

    pwentry = pwd.getpwnam(configuration.base.SYSTEM_USER_NAME)
    grentry = grp.getgrnam(configuration.base.SYSTEM_GROUP_NAME)

    uid = pwentry.pw_uid
    gid = grentry.gr_gid
    home = pwentry.pw_dir

    import daemon

    pidfile_path = configuration.services.SERVICEMANAGER["pidfile_path"]

    if os.path.isfile(pidfile_path):
        print >>sys.stderr, "%s: file exists; daemon already running?" % pidfile_path
        sys.exit(1)

    pidfile_dir = os.path.dirname(pidfile_path)
    try:
        # /var/run is typically a tmpfs that gets nuked on reboot,
        # so recreate /var/run/critic/IDENTITY if it doesn't exist.
        os.makedirs(pidfile_dir)
    except OSError as error:
        if error.errno != errno.EEXIST:
            raise
    else:
        os.chown(pidfile_dir, uid, gid)
        os.chmod(pidfile_dir, 0750 | stat.S_ISUID | stat.S_ISGID)

    os.environ["HOME"] = home
    os.chdir(home)

    smtp_credentials_path = os.path.join(configuration.paths.CONFIG_DIR,
                                         "configuration",
                                         "smtp-credentials.json")
    if os.path.isfile(smtp_credentials_path):
        with open(smtp_credentials_path) as smtp_credentials_file:
            smtp_credentials = json.load(smtp_credentials_file)
    else:
        smtp_credentials = None

    input_data = { "maildelivery": { "credentials": smtp_credentials }}

    os.setgid(gid)
    os.setuid(uid)

    with open(pidfile_path, "w") as pidfile:
        daemon.detach()
        pidfile.write("%s\n" % os.getpid())

    was_terminated = False

    def terminated(signum, frame):
        global was_terminated
        was_terminated = True

    signal.signal(signal.SIGTERM, terminated)

    while not was_terminated:
        process = subprocess.Popen(
            [sys.executable, "-m", "background.servicemanager", "--slave"],
            stdin=subprocess.PIPE)

        process.stdin.write(json.dumps(input_data))
        process.stdin.close()

        while not was_terminated:
            try:
                pid, status = os.wait()
                if pid == process.pid:
                    process = None
                    break
            except OSError as error:
                if error.errno == errno.EINTR: continue
                else: break

    if process:
        try:
            process.send_signal(signal.SIGTERM)
            process.wait()
        except:
            pass

    try:
        os.unlink(pidfile_path)
    except:
        pass

########NEW FILE########
__FILENAME__ = utils
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2012 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import sys
import subprocess
import os
import logging
import logging.handlers
import atexit
import socket
import errno
import select
import traceback
import signal
import fcntl
import time
import datetime

import configuration
from textutils import json_encode, json_decode, indent

def freeze(d):
    return tuple(sorted(d.items()))
def thaw(f):
    return dict(f)

class AdministratorMailHandler(logging.Handler):
    def __init__(self, logfile_path):
        super(AdministratorMailHandler, self).__init__()
        self.__logfile_name = os.path.basename(logfile_path)

    def emit(self, record):
        import mailutils
        try:
            import dbutils
            db = dbutils.Database()
        except:
            db = None
        mailutils.sendAdministratorErrorReport(db, self.__logfile_name,
                                                   record.message.splitlines()[0],
                                                   self.formatter.format(record))
        if db:
            db.close()

class BackgroundProcess(object):
    def __init__(self, service, send_administrator_mails=True):
        try: loglevel = getattr(logging, service["loglevel"].upper())
        except: loglevel = logging.INFO

        formatter = logging.Formatter("%(asctime)s - %(levelname)5s - %(message)s")

        file_handler = logging.handlers.RotatingFileHandler(service["logfile_path"], maxBytes=1024**2, backupCount=5)
        file_handler.setFormatter(formatter)
        file_handler.setLevel(loglevel)

        logger = logging.getLogger()
        logger.setLevel(loglevel)
        logger.addHandler(file_handler)

        if send_administrator_mails:
            mail_handler = AdministratorMailHandler(service["logfile_path"])
            mail_handler.setFormatter(formatter)
            mail_handler.setLevel(logging.WARNING)
            logger.addHandler(mail_handler)

        self.terminated = False
        self.interrupted = False
        self.restart_requested = False

        self.__maintenance_hooks = []
        self.__logger = logger
        self.__pidfile_path = service.get("pidfile_path")
        self.__create_pidfile()

        signal.signal(signal.SIGHUP, self.__handle_SIGHUP)
        signal.signal(signal.SIGTERM, self.__handle_SIGTERM)

        self.info("service started")

        atexit.register(self.__stopped)

    def __handle_SIGHUP(self, signum, frame):
        self.interrupted = True
    def __handle_SIGTERM(self, signum, frame):
        self.terminated = True

    def __create_pidfile(self):
        if self.__pidfile_path:
            try: os.makedirs(os.path.dirname(self.__pidfile_path))
            except OSError as error:
                if error.errno == errno.EEXIST: pass
                else: raise
            pidfile = open(self.__pidfile_path, "w")
            pidfile.write(str(os.getpid()) + "\n")
            pidfile.close()

    def __delete_pidfile(self):
        if self.__pidfile_path:
            try: os.unlink(self.__pidfile_path)
            except: pass

    def __stopped(self):
        self.info("service stopped")
        self.__delete_pidfile()

    def error(self, message):
        self.__logger.error(message)

    def warning(self, message):
        self.__logger.warning(message)

    def info(self, message):
        self.__logger.info(message)

    def debug(self, message):
        self.__logger.debug(message)

    def exception(self, message=None):
        backtrace = traceback.format_exc()
        if message is None:
            message = "unhandled exception: " + backtrace.splitlines()[-1]
        self.__logger.error(message + "\n" + indent(backtrace))

    def register_maintenance(self, hour, minute, callback):
        self.__maintenance_hooks.append(
            [hour, minute, callback, datetime.datetime.now()])

    def run_maintenance(self):
        if self.__maintenance_hooks:
            sleep_seconds = 86400

            for hook in self.__maintenance_hooks:
                hour, minute, callback, last = hook
                now = datetime.datetime.now()

                if hour is None:
                    scheduled_at = datetime.time(now.hour, minute)
                    interval = datetime.timedelta(seconds=3600)
                    interval_type = "hourly"
                else:
                    scheduled_at = datetime.time(hour, minute)
                    interval = datetime.timedelta(days=1)
                    interval_type = "daily"

                scheduled_at = datetime.datetime.combine(datetime.date.today(),
                                                         scheduled_at)

                while scheduled_at <= last:
                    # We already ran the callback this hour/day.
                    scheduled_at += interval

                if scheduled_at <= now:
                    self.info("performing %s maintenance task" % interval_type)
                    callback()
                    hook[3] = scheduled_at
                    scheduled_at += interval

                now = datetime.datetime.now()
                seconds_remaining = (scheduled_at - now).total_seconds()

                # Wait at least 60 seconds, even if that would make us over-
                # shoot the deadline slightly.  Maintenance tasks are not really
                # that sensitive.
                seconds_remaining = max(seconds_remaining, 60)

                sleep_seconds = min(sleep_seconds, seconds_remaining)

            return sleep_seconds

    def run(self):
        while not self.terminated:
            timeout = self.run_maintenance()

            if timeout is None:
                # No configured maintenance hooks; nothing to do.  Returning will
                # probably cause service to terminate, and we just started, so the
                # service manager will leave the service not running.
                return

            self.debug("sleeping %d seconds" % timeout)
            time.sleep(timeout)

    def requestRestart(self):
        self.restart_requested = True

class PeerServer(BackgroundProcess):
    class Peer(object):
        def __init__(self, server, writing, reading):
            self.server = server

            self.__writing = writing
            self.__write_data = ""
            self.__write_closed = False

            if writing:
                fcntl.fcntl(writing, fcntl.F_SETFL, fcntl.fcntl(writing, fcntl.F_GETFL) | os.O_NONBLOCK)

            self.__reading = reading
            self.__read_data = ""
            self.__read_closed = False

            if reading and reading.fileno() != writing.fileno():
                fcntl.fcntl(reading, fcntl.F_SETFL, fcntl.fcntl(reading, fcntl.F_GETFL) | os.O_NONBLOCK)

        def is_finished(self):
            return not self.__writing and not self.__reading

        def writing(self):
            if self.__write_data or self.__write_closed: return self.__writing
            else: return None

        def write(self, data):
            assert self.__writing
            assert not self.__write_closed
            self.__write_data += data

        def close(self):
            assert self.__writing
            assert not self.__write_closed
            self.__write_closed = True

        def do_write(self):
            while self.__write_data:
                nwritten = os.write(self.__writing.fileno(), self.__write_data)
                self.__write_data = self.__write_data[nwritten:]
            if self.__write_closed:
                self.writing_done(self.__writing)
                self.__writing = None

        def reading(self):
            if not self.__read_closed: return self.__reading
            else: return None

        def read(self):
            if self.__read_closed: return self.__read_data
            else: return None

        def do_read(self):
            while True:
                read = os.read(self.__reading.fileno(), 4096)
                if not read:
                    self.reading_done(self.__reading)
                    self.__reading = None
                    self.__read_closed = True
                    self.handle_input(self.__read_data)
                    break
                self.__read_data += read

        def writing_done(self, writing):
            writing.close()

        def reading_done(self, reading):
            reading.close()

        def destroy(self):
            pass

    class SocketPeer(Peer):
        def __init__(self, server, clientsocket):
            super(PeerServer.SocketPeer, self).__init__(server, clientsocket, clientsocket)

        def reading_done(self, reading):
            reading.shutdown(socket.SHUT_RD)

        def writing_done(self, writing):
            writing.shutdown(socket.SHUT_WR)

        def handle_input(self, data):
            pass

    class ChildProcess(Peer):
        def __init__(self, server, args, **kwargs):
            self.__process = subprocess.Popen(args, stdin=subprocess.PIPE, stdout=subprocess.PIPE, **kwargs)
            self.pid = self.__process.pid
            super(PeerServer.ChildProcess, self).__init__(server, self.__process.stdin, self.__process.stdout)
            self.server.debug("spawned child process (pid=%d)" % self.__process.pid)

        def kill(self, signal):
            self.__process.send_signal(signal)

        def destroy(self):
            self.__process.wait()
            self.returncode = self.__process.returncode
            if self.returncode:
                self.server.error("child process exited (pid=%d, returncode=%d)" % (self.pid, self.returncode))
            else:
                self.server.debug("child process exited (pid=%d, returncode=0)" % self.pid)

    def __init__(self, service, **kwargs):
        super(PeerServer, self).__init__(service, **kwargs)

        self.__peers = []
        self.__address = service.get("address")
        self.__create_listening_socket()

    def __create_listening_socket(self):
        if type(self.__address) == str:
            try: os.makedirs(os.path.dirname(self.__address))
            except OSError as error:
                if error.errno == errno.EEXIST: pass
                else: raise

            if os.path.exists(self.__address):
                connection = socket.socket(socket.AF_UNIX, socket.SOCK_STREAM)
                try:
                    connection.connect(self.__address)
                    connection.close()

                    print >>sys.stderr, "ERROR: Server already started!"
                    sys.exit(1)
                except socket.error as error:
                    if error[0] == errno.ECONNREFUSED:
                        self.debug("removing stale socket")
                        os.unlink(self.__address)
                    else: raise

            self.__listening_socket = socket.socket(socket.AF_UNIX, socket.SOCK_STREAM)
            self.__listening_socket.setblocking(0)
            self.__listening_socket.bind(self.__address)
            self.__listening_socket.listen(4)

            os.chmod(self.__address, 0700)

            self.debug("listening: %s" % self.__address)
        elif type(self.__address) == tuple:
            host, port = self.__address

            self.__listening_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
            self.__listening_socket.setblocking(0)
            self.__listening_socket.bind((host, port))
            self.__listening_socket.listen(4)

            self.debug("listening: %s:%d" % (host, port))
        elif self.__address is None:
            self.__listening_socket = open("/dev/null", "r")

            self.debug("not listening")
        else:
            raise Exception("invalid address: %r" % self.__address)

        atexit.register(self.__destroy_listening_socket)

    def __destroy_listening_socket(self):
        try: self.__listening_socket.close()
        except: pass

        if type(self.__address) == str:
            try: os.unlink(self.__address)
            except: pass

    def run(self):
        try:
            try:
                self.startup()

                while not self.terminated:
                    self.interrupted = False

                    if self.restart_requested:
                        if not self.__peers: break
                        else: self.debug("restart delayed; have %d peers" % len(self.__peers))

                    poll = select.poll()
                    poll.register(self.__listening_socket, select.POLLIN)

                    for peer in self.__peers:
                        if peer.writing(): poll.register(peer.writing(), select.POLLOUT)
                        if peer.reading(): poll.register(peer.reading(), select.POLLIN)

                    def fileno(file):
                        if file: return file.fileno()
                        else: return None

                    while not self.terminated:
                        timeout = self.run_maintenance()

                        if not (timeout is None or self.__peers):
                            self.debug("next maintenance task check scheduled in %d seconds" % timeout)

                        try:
                            events = poll.poll(timeout * 1000 if timeout else None)
                            break
                        except select.error as error:
                            if error[0] == errno.EINTR: continue
                            else: raise

                    if self.terminated: break

                    def catch_error(fn):
                        try: fn()
                        except socket.error as error:
                            if error[0] not in (errno.EAGAIN, errno.EINTR): raise
                        except OSError as error:
                            if error.errno not in (errno.EAGAIN, errno.EINTR): raise

                    for fd, event in events:
                        if fd == self.__listening_socket.fileno():
                            peersocket, peeraddress = self.__listening_socket.accept()
                            peer = self.handle_peer(peersocket, peeraddress)
                            if peer: self.__peers.append(peer)
                            else:
                                try: peersocket.close()
                                except: pass
                        else:
                            for peer in self.__peers[:]:
                                if fd == fileno(peer.writing()) and event != select.POLLIN:
                                    catch_error(peer.do_write)
                                if fd == fileno(peer.reading()) and event != select.POLLOUT:
                                    catch_error(peer.do_read)
                                if peer.is_finished():
                                    peer.destroy()
                                    self.peer_destroyed(peer)
                                    self.__peers.remove(peer)
            except:
                self.exception()
                self.error("service crashed!")
                sys.exit(1)
            else:
                self.info("service shutting down ...")
        finally:
            try: self.shutdown()
            except: self.exception()

            for peer in self.__peers:
                try: peer.destroy()
                except: self.exception()
                try: self.peer_destroyed(peer)
                except: self.exception()

    def add_peer(self, peer):
        self.__peers.append(peer)

    def handle_peer(self, peersocket, peeraddress):
        pass

    def peer_destroyed(self, peer):
        pass

    def startup(self):
        pass
    def shutdown(self):
        pass

class SlaveProcessServer(PeerServer):
    class SlaveChildProcess(PeerServer.ChildProcess):
        def __init__(self, server, client):
            super(SlaveProcessServer.SlaveChildProcess, self).__init__(server, [sys.executable, sys.argv[0], "--slave"])
            self.__client = client

        def handle_input(self, value):
            self.__client.write(value)
            self.__client.close()

    class SlaveClient(PeerServer.SocketPeer):
        def __init__(self, server, peersocket):
            super(SlaveProcessServer.SlaveClient, self).__init__(server, peersocket)

        def handle_input(self, value):
            if value:
                child_process = SlaveProcessServer.SlaveChildProcess(self.server, self)
                child_process.write(value)
                child_process.close()
                self.server.add_peer(child_process)

    def handle_peer(self, peersocket, peeraddress):
        return SlaveProcessServer.SlaveClient(self, peersocket)

class JSONJobServer(PeerServer):
    class Job(PeerServer.ChildProcess):
        def __init__(self, server, client, request):
            super(JSONJobServer.Job, self).__init__(server, [sys.executable, sys.argv[0], "--json-job"], stderr=subprocess.STDOUT)
            self.clients = [client]
            self.request = request
            self.write(json_encode(request))
            self.close()

        def handle_input(self, value):
            try: result = json_decode(value)
            except ValueError:
                self.server.error("invalid response:\n" + indent(value))
                result = self.request.copy()
                result["error"] = value
            for client in self.clients: client.add_result(result)
            self.server.request_finished(self, self.request, result)

    class JobClient(PeerServer.SocketPeer):
        def handle_input(self, value):
            decoded = json_decode(value)
            if isinstance(decoded, list):
                self.__requests = decoded
                self.__pending_requests = map(freeze, decoded)
                self.__results = []
                self.server.add_requests(self)
            else:
                assert isinstance(decoded, dict)
                self.server.execute_command(self, decoded)

        def has_requests(self):
            return bool(self.__pending_requests)

        def get_request(self):
            return self.__pending_requests.pop()

        def add_result(self, result):
            self.__results.append(result)
            if len(self.__results) == len(self.__requests):
                self.write(json_encode(self.__results))
                self.close()

    def __init__(self, service):
        super(JSONJobServer, self).__init__(service)
        self.__clients_with_requests = []
        self.__started_requests = {}
        self.__max_jobs = service.get("max_jobs", 4)

    def __startJobs(self):
        # Repeat "start a job" while there are jobs to start and we haven't
        # reached the limit on number of concurrent jobs to run.
        while self.__clients_with_requests and len(self.__started_requests) < self.__max_jobs:
            # Fetch next request from first client in list of clients with
            # pending requests.
            client = self.__clients_with_requests.pop(0)
            frozen = client.get_request()

            if client.has_requests():
                # Client has more pending requests, so put it back at the end of
                # the list of clients with pending requests.
                self.__clients_with_requests.append(client)

            if frozen in self.__started_requests:
                # Another client has requested the same thing, piggy-back on
                # that job instead of starting another.
                self.__started_requests[frozen].clients.append(client)
                continue

            request = thaw(frozen)

            # Check if this request is already finished.  Default implementation
            # of this callback always returns None.
            result = self.request_result(request)

            if result:
                # Request is already finished; don't bother starting a child
                # process, just report result directly to the client.
                client.add_result(result)
            else:
                # Start child process.
                job = JSONJobServer.Job(self, client, request)
                self.add_peer(job)
                self.request_started(job, request)

    def add_requests(self, client):
        assert client.has_requests()
        self.__clients_with_requests.append(client)
        self.__startJobs()

    def execute_command(self, client, command):
        client.write(json_encode({ "status": "error", "error": "command not supported" }))
        client.close()

    def handle_peer(self, peersocket, peeraddress):
        return JSONJobServer.JobClient(self, peersocket)

    def peer_destroyed(self, peer):
        if isinstance(peer, JSONJobServer.Job): self.__startJobs()

    def request_result(self, request):
        pass
    def request_started(self, job, request):
        self.__started_requests[freeze(request)] = job
    def request_finished(self, job, request, result):
        del self.__started_requests[freeze(request)]

if configuration.debug.COVERAGE_DIR:
    import coverage
    call = coverage.call
else:
    def call(context, fn, *args, **kwargs):
        return fn(*args, **kwargs)

########NEW FILE########
__FILENAME__ = wait-for-pidfiles
import os
import time

import configuration

start = time.time()
while time.time() - start < 30:
    all_pidfiles_exist = True
    for service in configuration.services.SERVICEMANAGER["services"]:
        if not os.path.exists(service["pidfile_path"]):
            all_pidfiles_exist = False
    if all_pidfiles_exist:
        break
    else:
        time.sleep(0.1)

########NEW FILE########
__FILENAME__ = watchdog
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2012 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import sys
import os
import time
import signal
import errno
import multiprocessing

sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(sys.argv[0]), "..")))

import configuration

import background.utils
import mailutils

def getRSS(pid):
    for line in open("/proc/%d/status" % pid):
        words = line.split()
        if words[0] == "VmRSS:":
            if words[2].lower() == "kb": unit = 1024
            elif words[2].lower() == "mb": unit = 1024 ** 2
            elif words[2].lower() == "gb": unit = 1024 ** 3
            else: raise Exception("unknown unit: %s" % words[2])
            return int(words[1]) * unit
    else: raise Exception("invalid pid")

class Watchdog(background.utils.BackgroundProcess):
    def __init__(self):
        service = configuration.services.WATCHDOG

        super(Watchdog, self).__init__(service=service)

        cpu_count = multiprocessing.cpu_count()

        self.load1_limit = service.get("load1_limit", 0) * cpu_count
        self.load5_limit = service.get("load5_limit", 0) * cpu_count
        self.load15_limit = service.get("load15_limit", 0) * cpu_count

    def run(self):
        soft_restart_attempted = set()
        previous = {}

        getloadavg_failed = False
        load1_has_warned = 0
        load1_last_time = 0
        load5_has_warned = 0
        load5_last_time = 0
        load15_has_warned = 0
        load15_last_time = 0

        while not self.terminated:
            self.interrupted = False

            def sendLoadAverageWarning(interval, limit, load):
                cpu_count = multiprocessing.cpu_count()
                mailutils.sendAdministratorMessage(
                    "watchdog", "%d-minute load average" % interval,
                    ("The current %d-minute load average is %.2f!\n"
                     % (interval, load)) +
                    ("The configured limit is %.2f (%.2f x %d CPUs).\n"
                     % (limit, limit / cpu_count, cpu_count)) +
                    "\n-- critic\n")

            try:
                load1, load5, load15 = os.getloadavg()
                self.debug("load average: %r, %r, %r" % (load1, load5, load15))
            except OSError:
                load1, load5, load15 = 0, 0, 0

                if not getloadavg_failed:
                    self.exception("failed to detect system load average")
                    getloadavg_failed = True

            now = time.time()

            if self.load1_limit and load1 > self.load1_limit:
                if load1 > load1_has_warned * 1.2 or now - load1_last_time > 60:
                    sendLoadAverageWarning(1, self.load1_limit, load1)
                    load1_has_warned = load1
                    load1_last_time = now
            else:
                load1_has_warned = 0
                load1_last_time = 0

                if self.load5_limit and load5 > self.load5_limit:
                    if load5 > load5_has_warned * 1.2 or now - load5_last_time > 5 * 60:
                        sendLoadAverageWarning(5, self.load5_limit, load5)
                        load5_has_warned = load5
                        load5_last_time = now
                else:
                    load5_has_warned = 0
                    load5_last_time = 0

                    if self.load15_limit and load15 > self.load15_limit:
                        if load15 > load15_has_warned * 1.2 or now - load15_last_time > 15 * 60:
                            sendLoadAverageWarning(15, self.load15_limit, load15)
                            load15_has_warned = load15
                            load15_last_time = now
                    else:
                        load15_has_warned = 0
                        load15_last_time = 0

            pidfile_dir = configuration.paths.WSGI_PIDFILE_DIR

            if os.path.isdir(pidfile_dir):
                pids = set(map(int, os.listdir(pidfile_dir)))
            else:
                pids = set()

            for pid in pids:
                try: rss = getRSS(pid)
                except IOError as error:
                    if error.errno == errno.ENOENT:
                        self.warning("unlinking stale pid-file: %s" % os.path.join(pidfile_dir, str(pid)))
                        os.unlink(os.path.join(pidfile_dir, str(pid)))
                        continue
                    else: raise

                if previous.get(pid) != rss:
                    self.debug("pid=%d, rss=%d bytes" % (pid, rss))
                    previous[pid] = rss

                if rss > configuration.services.WATCHDOG["rss_hard_limit"]:
                    mailutils.sendAdministratorMessage(
                        "watchdog", "pid(%d): hard memory limit exceeded" % pid,
                        ("Current RSS: %d kilobytes\nSending process SIGKILL (%d).\n\n-- critic"
                         % (rss, signal.SIGKILL)))
                    self.info("Killing pid(%d): hard memory limit exceeded, RSS: %d kilobytes" % (pid, rss))
                    os.kill(pid, signal.SIGKILL)
                elif rss > configuration.services.WATCHDOG["rss_soft_limit"] and pid not in soft_restart_attempted:
                    mailutils.sendAdministratorMessage(
                        "watchdog", "pid(%d): soft memory limit exceeded" % pid,
                        ("Current RSS: %d kilobytes\nSending process SIGINT (%d).\n\n"
                         % (rss, signal.SIGINT)))
                    self.info("Killing pid(%d): soft memory limit exceeded, RSS: %d kilobytes" % (pid, rss))
                    os.kill(pid, signal.SIGINT)
                    soft_restart_attempted.add(pid)

            for pid in previous.keys():
                if pid not in pids: del previous[pid]

            soft_restart_attempted = soft_restart_attempted & pids

            time.sleep(10)

def start_service():
    watchdog = Watchdog()
    watchdog.run()

background.utils.call("watchdog", start_service)

########NEW FILE########
__FILENAME__ = base
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2012 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

class Error(Exception):
    pass

class ImplementationError(Error):
    pass

########NEW FILE########
__FILENAME__ = base_unittest
import sys

def independence():
    # Simply check that base can be imported.

    import base

if __name__ == "__main__":
    if "independence" in sys.argv[1:]:
        independence()

########NEW FILE########
__FILENAME__ = client
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2012 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import socket

import base
import configuration
from textutils import json_encode, json_decode, indent

class ChangesetBackgroundServiceError(base.ImplementationError):
    def __init__(self, message):
        super(ChangesetBackgroundServiceError, self).__init__(
            "Changeset background service failed: %s" % message)

def requestChangesets(requests):
    try:
        connection = socket.socket(socket.AF_UNIX, socket.SOCK_STREAM)
        connection.connect(configuration.services.CHANGESET["address"])
        connection.send(json_encode(requests))
        connection.shutdown(socket.SHUT_WR)

        data = ""

        while True:
            received = connection.recv(4096)
            if not received: break
            data += received

        connection.close()
    except socket.error as error:
        raise ChangesetBackgroundServiceError(error[1])

    try:
        results = json_decode(data)
    except ValueError:
        raise ChangesetBackgroundServiceError(
            "returned an invalid response: %r" % data)

    if type(results) != list:
        # If not a list, the result is probably an error message.
        raise ChangesetBackgroundServiceError(str(results))

    if len(results) != len(requests):
        raise ChangesetBackgroundServiceError("didn't process all requests")

    errors = []

    for result in results:
        if "error" in result:
            errors.append(result["error"])

    if errors:
        raise ChangesetBackgroundServiceError(
            "one or more requests failed:\n%s" % "\n".join(map(indent, errors)))

########NEW FILE########
__FILENAME__ = create
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2012 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import dbutils
import gitutils
import diff.merge
import diff.parse

def createChangeset(db, request):
    repository_name = request["repository_name"]
    changeset_type = request["changeset_type"]

    repository = gitutils.Repository.fromName(db, repository_name)

    def insertChangeset(db, parent, child, files):
        while True:
            # Inserting new files will often clash when creating multiple
            # related changesets in parallel.  It's a simple operation, so if it
            # fails with an integrity error, just try again until it doesn't
            # fail.  (It will typically succeed the second time because then the
            # new files already exist, and it doesn't need to insert anything.)
            try:
                dbutils.find_files(db, files)
                db.commit()
                break
            except dbutils.IntegrityError:
                db.rollback()

        cursor = db.cursor()
        cursor.execute("INSERT INTO changesets (type, parent, child) VALUES (%s, %s, %s) RETURNING id",
                       (changeset_type, parent.getId(db) if parent else None, child.getId(db)))
        changeset_id = cursor.fetchone()[0]

        fileversions_values = []
        chunks_values = []

        file_ids = set()

        for file in files:
            if file.id in file_ids: raise Exception("duplicate:%d:%s" % (file.id, file.path))
            file_ids.add(file.id)

            fileversions_values.append((changeset_id, file.id, file.old_sha1, file.new_sha1, file.old_mode, file.new_mode))

            for index, chunk in enumerate(file.chunks):
                chunk.analyze(file, index == len(file.chunks) - 1)
                chunks_values.append((changeset_id, file.id, chunk.delete_offset, chunk.delete_count, chunk.insert_offset, chunk.insert_count, chunk.analysis, 1 if chunk.is_whitespace else 0))

            file.clean()

        if fileversions_values:
            cursor.executemany("""INSERT INTO fileversions (changeset, file, old_sha1, new_sha1, old_mode, new_mode)
                                       VALUES (%s, %s, %s, %s, %s, %s)""",
                               fileversions_values)
        if chunks_values:
            cursor.executemany("""INSERT INTO chunks (changeset, file, deleteOffset, deleteCount, insertOffset, insertCount, analysis, whitespace)
                                       VALUES (%s, %s, %s, %s, %s, %s, %s, %s)""",
                               chunks_values)

        return changeset_id

    changeset_ids = request["changeset_ids"] = {}

    child = gitutils.Commit.fromSHA1(db, repository, request["child_sha1"])

    cursor = db.cursor()

    if "parent_sha1" in request:
        assert changeset_type in ("custom", "conflicts")

        parent_sha1 = request["parent_sha1"]

        if parent_sha1 == "0" * 40:
            parent = parent_id = None
        else:
            parent = gitutils.Commit.fromSHA1(db, repository, parent_sha1)
            parent_id = parent.getId(db)

        cursor.execute("""SELECT id, %s
                            FROM changesets
                           WHERE type=%s
                             AND parent=%s
                             AND child=%s""",
                       (parent_sha1, changeset_type, parent_id, child.getId(db)))
    else:
        assert changeset_type in ("direct", "merge")

        cursor.execute("""SELECT changesets.id, commits.sha1
                            FROM changesets
                 LEFT OUTER JOIN commits ON (commits.id=changesets.parent)
                           WHERE type=%s
                             AND child=%s""",
                       (changeset_type, child.getId(db)))

    rows = cursor.fetchall()

    if rows:
        # Changeset(s) already exists in database.

        for changeset_id, parent_sha1 in rows:
            changeset_ids[parent_sha1] = changeset_id
    else:
        # Parse diff and insert changeset(s) into the database.

        if changeset_type == "merge":
            changes = diff.merge.parseMergeDifferences(db, repository, child)
        elif changeset_type == "direct":
            changes = diff.parse.parseDifferences(repository, commit=child)
        else:
            changes = diff.parse.parseDifferences(repository, from_commit=parent, to_commit=child)

        for parent_sha1, files in changes.items():
            if parent_sha1 is None:
                parent = None
            else:
                parent = gitutils.Commit.fromSHA1(db, repository, parent_sha1)
            changeset_ids[parent_sha1] = insertChangeset(db, parent, child, files)

        db.commit()

########NEW FILE########
__FILENAME__ = detectmoves
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2012 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import difflib
import re
import diff
import diff.analyze

re_ws = re.compile("\\s+")

SMALLEST_INSERT = 5
MAXIMUM_GAP = 10

class Line:
    def __init__(self, string):
        self.string = string
        self.wsnorm = re_ws.sub(" ", string.strip())

    def __str__(self):
        return self.string

    def __eq__(self, other):
        return self.wsnorm == other.wsnorm

    def __ne__(self, other):
        return self.wsnorm == other.wsnorm

    def __hash__(self):
        return hash(self.wsnorm)

def compareChunks(source_file, source_chunk, target_file, target_chunk, extra_target_chunks, context_lines=3):
    source_length = source_file.oldCount()
    target_length = target_file.newCount()

    source_lines = map(Line, source_chunk.deleted_lines)
    target_lines = map(Line, target_chunk.inserted_lines)

    sm = difflib.SequenceMatcher(None, source_lines, target_lines)

    blocks = filter(lambda x: x[2], sm.get_matching_blocks())

    if blocks:
        chunks = []

        i, j, n = blocks.pop(0)

        current = [(i, j, n)]
        matched = n

        pi = i + n
        pj = j + n

        for i, j, n in blocks:
            if i - pi > MAXIMUM_GAP or j - pj > MAXIMUM_GAP:
                chunks.append((matched, current))
                current = [(i, j, n)]
                matched = n
            else:
                current.append((i, j, n))
                matched += n
            pi = i + n
            pj = j + n

        chunks.append((matched, current))
        chunks.sort()

        matched, blocks = chunks[-1]

        if matched < SMALLEST_INSERT:
            return None

        source_begin = max(-(source_chunk.delete_offset - 1), blocks[0][0] - context_lines)
        source_end = min(source_length + 1 - source_chunk.delete_offset, blocks[-1][0] + blocks[-1][2] + context_lines)

        target_begin = max(-(target_chunk.insert_offset - 1), blocks[0][1] - context_lines)
        target_end = min(target_length + 1 - target_chunk.insert_offset, blocks[-1][1] + blocks[-1][2] + context_lines)

        new_chunk = diff.Chunk(source_chunk.delete_offset + source_begin,
                               source_end - source_begin,
                               target_chunk.insert_offset + target_begin,
                               target_end - target_begin)

        new_chunk.source_chunk = source_chunk
        new_chunk.source_begin = source_begin
        new_chunk.source_end = source_end
        new_chunk.source_length = source_length

        if blocks[0][1] >= SMALLEST_INSERT and blocks[0][1] < target_chunk.insert_count:
            extra_before = diff.Chunk(0, 0, target_chunk.insert_offset, blocks[0][1])
        else:
            extra_before = None

        match_end = blocks[-1][1] + blocks[-1][2]
        if target_chunk.insert_count - match_end >= SMALLEST_INSERT:
            extra_after = diff.Chunk(0, 0, target_chunk.insert_offset + match_end, target_chunk.insert_count - match_end)
        else:
            extra_after = None

        new_chunk.deleted_lines = source_file.getOldLines(new_chunk)
        new_chunk.inserted_lines = target_file.getNewLines(new_chunk)

        if matched > len(new_chunk.inserted_lines) * 0.25:
            analysis = diff.analyze.analyzeChunk(new_chunk.deleted_lines, new_chunk.inserted_lines, moved=True)

            if matched > len(new_chunk.inserted_lines) * 0.5 or (analysis and len(analysis.split(';')) >= len(new_chunk.inserted_lines) * 0.5):
                new_chunk.analysis = analysis
                if extra_before: extra_target_chunks.append(extra_before)
                if extra_after: extra_target_chunks.append(extra_after)
                return new_chunk

    return None

def findSourceChunk(db, changeset, source_file_ids, target_file, target_chunk, extra_target_chunks):
    for source_file in changeset.files:
        if source_file_ids and not source_file.id in source_file_ids: continue
        if source_file.chunks is None: continue

        for source_chunk in source_file.chunks:
            # Shouldn't compare chunk to itself, of course.
            if target_file == source_file and target_chunk == source_chunk:
                continue

            # Much fewer deleted lines than inserted lines in the target chunk;
            # unlikely to be a relevant source chunk.
            #if source_chunk.delete_count * 1.5 < target_chunk.insert_count:
            #    continue

            if source_chunk.analysis:
                # If more than half the deleted lines are mapped against
                # inserted lines, most likely edited rather than moved code.
                if source_chunk.delete_count < len(source_chunk.analysis.split(";")) * 2:
                    continue

            source_file.loadOldLines()
            source_chunk.deleted_lines = source_file.getOldLines(source_chunk)

            new_chunk = compareChunks(source_file, source_chunk, target_file, target_chunk, extra_target_chunks)

            if new_chunk:
                return source_file, new_chunk

    return None, None

def detectMoves(db, changeset, source_file_ids=None, target_file_ids=None):
    moves = []

    for target_file in changeset.files:
        if target_file_ids and not target_file.id in target_file_ids: continue

        current_chunks = target_file.chunks

        count = 0

        while current_chunks:
            extra_target_chunks = []
            count += 1

            for target_chunk in current_chunks:
                # White-space only changes; unlikely target of moved code.
                if target_chunk.is_whitespace:
                    continue

                # Too few inserted lines; couldn't possibly be an interesting target
                # of moved code.
                if target_chunk.insert_count < 5:
                    continue

                if target_chunk.analysis:
                    # If more than half the inserted lines are mapped against
                    # deleted lines, most likely edited rather than moved code.
                    if target_chunk.insert_count < len(target_chunk.analysis.split(";")) * 2:
                        continue

                target_file.loadNewLines()
                target_chunk.inserted_lines = target_file.getNewLines(target_chunk)

                source_file, chunk = findSourceChunk(db, changeset, source_file_ids, target_file, target_chunk, extra_target_chunks)

                if source_file and chunk:
                    moves.append((source_file, target_file, chunk))
                    continue

            current_chunks = extra_target_chunks

    if moves:
        def orderChunks(a, b):
            a_source_file, a_target_file, a_chunk = a
            b_source_file, b_target_file, b_chunk = b

            c = cmp(a_target_file.path, b_target_file.path)
            if c != 0: return c
            else: return cmp(a_chunk.insert_offset, b_chunk.insert_offset)

        moves.sort(orderChunks)

        move_changeset = diff.Changeset(None, changeset.parent, changeset.child, 'moves', [])

        for source_file, target_file, chunk in moves:
            move_file = diff.File(0, "",
                                  source_file.old_sha1,
                                  target_file.new_sha1,
                                  source_file.repository,
                                  chunks=[chunk],
                                  move_source_file=source_file,
                                  move_target_file=target_file)

            move_changeset.files.append(move_file)

        return move_changeset
    else:
        return None

########NEW FILE########
__FILENAME__ = html
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2012 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import re
import itertools
import urllib

from time import strftime
from bisect import bisect_right

import textutils
import dbutils
import diff
import diff.context
import changeset.utils as changeset_utils
import reviewing.comment as review_comment
import htmlutils
import configuration

from htmlutils import jsify, Generator, Text, HTML, stripStylesheet

re_tag = re.compile("<([bi]) class='?([a-z]+)'?>")
re_tailws = re.compile("^(.*?)(\s+)((?:<[^>]+>)*)$")

class CodeContexts:
    class Context:
        def __init__(self, first_line, last_line, description):
            self.first_line = first_line
            self.last_line = last_line
            self.description = description

        def __cmp__(self, index):
            return cmp(self.first_line, index)

    def __init__(self, db, sha1, first_line, last_line):
        cursor = db.cursor()
        cursor.execute("""SELECT first_line, last_line, context
                            FROM codecontexts
                           WHERE sha1=%s
                             AND first_line<=%s
                             AND last_line>=%s
                        ORDER BY first_line ASC, last_line DESC""",
                       (sha1, last_line, first_line))
        self.contexts = [CodeContexts.Context(first_line, last_line, description) for first_line, last_line, description in cursor]

    def find(self, linenr):
        index = bisect_right(self.contexts, linenr)
        if index:
            context = self.contexts[index - 1]
            if context.last_line >= linenr:
                return context.description
        return None

def expandHTML(db, file, old_offset, new_offset, lines, target):
    if old_offset == 1: where = 'top'
    elif old_offset + lines - 1 == file.oldCount(): where = 'bottom'
    else: where = 'middle'

    select = target.select(onchange=('expand(this, %d, %r, %r, %d, %d, %d);' % (file.id, file.new_sha1, where, old_offset, new_offset, lines)))
    select.option(value='none').text("%s lines not shown" % lines)

    if where == 'middle': actualLines = lines
    else: actualLines = lines * 2

    if actualLines > 20: select.option(value=10).text("Show 10 more")
    if actualLines > 50: select.option(value=25).text("Show 25 more")
    if actualLines > 100: select.option(value=50).text("Show 50 more")

    select.option(value=lines).text("All")

def generateDataScript(db, user, changeset, review, file_id_format, compact, parent_index):
    data = { 'parent_id': changeset.parent.id if changeset.parent else None,
             'parent_sha1': htmlutils.jsify(changeset.parent.sha1) if changeset.parent else None,
             'child_id': changeset.child.id,
             'child_sha1': htmlutils.jsify(changeset.child.sha1),
             'changeset_id': jsify(changeset.id),
             'commit_ids': ", ".join([str(commit.getId(db)) for commit in reversed(changeset.commits(db))]),
             'parent_index': parent_index }

    if parent_index is None:
        commits = changeset.commits(db)

        if review and commits:
            if len(commits) > 1:
                cursor = db.cursor()
                cursor.execute("SELECT id FROM changesets JOIN reviewchangesets ON (changeset=id) WHERE review=%s AND child=ANY (%s)",
                               (review.id, [commit.getId(db) for commit in commits]))

                changeset_ids = [changeset_id for (changeset_id,) in cursor]
            else:
                changeset_ids = [changeset.id]
        else:
            changeset_ids = None

        if changeset_ids is None: changeset_ids = "null"
        else: changeset_ids = "[%s]" % ", ".join(map(str, changeset_ids))

        data["changeset_ids"] = changeset_ids

        if changeset.parent:
            data_script = """
var changeset = { parent: { id: %(parent_id)d, sha1: %(parent_sha1)s },
                  child: { id: %(child_id)d, sha1: %(child_sha1)s },
                  id: %(changeset_id)s,
                  ids: %(changeset_ids)s,
                  commits: [ %(commit_ids)s ] };
var useFiles = files;
""" % data
        else:
            data_script = """
var changeset = { parent: null,
                  child: { id: %(child_id)d, sha1: %(child_sha1)s },
                  id: %(changeset_id)s,
                  ids: %(changeset_ids)s,
                  commits: [ %(commit_ids)s ] };
var useFiles = files;
""" % data
    else:
        data_script = """
var changeset;
var parent_index = %(parent_index)d;

if (!changeset)
  changeset = { commits: [ %(child_id)d ] };

if (!changeset[parent_index])
  changeset[parent_index] = {};

if (!changeset.child)
  changeset.child = { id: %(child_id)d, sha1: %(child_sha1)s };

changeset[parent_index].parent = { id: %(parent_id)d, sha1: %(parent_sha1)s };
changeset[parent_index].child = { id: %(child_id)d, sha1: %(child_sha1)s };
changeset[parent_index].id = %(changeset_id)s;

var useFiles = files[parent_index] = {};
""" % data

    parent_index_property = "parent: %d, " % parent_index if parent_index is not None else ""

    all_files = set()

    for file in changeset.files:
        if file.move_source_file and file.move_target_file:
            all_files.add(file.move_source_file)
            all_files.add(file.move_target_file)
        elif file.hasChanges():
            all_files.add(file)

    for file in all_files:
        data_script += """
useFiles[%d] = { old_sha1: %r,
               %snew_sha1: %r,
               %spath: %s };
""" % (file.id, file.old_sha1, " " * len(str(file.id)), file.new_sha1, " " * len(str(file.id)), jsify(file.path))
        if file.old_sha1 != "0" * 40 and file.new_sha1 != "0" * 40:
            data_script += """files[%r] = { %sid: %d, side: 'o' };
""" % (file.old_sha1, parent_index_property, file.id)
            data_script += """files[%r] = { id: %d, side: 'n' };
""" % (file.new_sha1, file.id)
        elif file.new_sha1 != "0" * 40:
            data_script += """files[%r] = { id: %d, side: 'n' };
""" % (file.new_sha1, file.id)
        else:
            data_script += """files[%r] = { %sid: %d, side: 'o' };
""" % (file.old_sha1, parent_index_property, file.id)

    if review:
        data_script += """
%s
var commentChains;
""" % review.getJS()

        reviewable_files = ", ".join([("%d: %r" % (file_id, state)) for file_id, (is_reviewer, state, reviewers) in changeset.getReviewFiles(db, user, review).items() if is_reviewer])

        if parent_index is None:
            data_script += """
changeset.reviewableFiles = { %s };
""" % reviewable_files
        else:
            data_script += """
changeset[parent_index].reviewableFiles = { %s };
""" % reviewable_files

    if compact: return re.sub(r"\B\s+\B|\b\s+\B|\B\s+\b", "", data_script).strip()
    else: return data_script.strip()

def render(db, target, user, repository, changeset, review=None, review_mode=None,
           context_lines=3, style="horizontal", wrap=True, options={}, parent_index=None):
    addResources(db, user, repository, review, options.get("compact", False),
                 options.get("tabify", False), target)

    compact = options.get("compact", False)

    cursor = db.cursor()

    if options.get("merge"):
        local_comments_only = True
    else:
        local_comments_only = False

    target.script(type='text/javascript').text(generateDataScript(db, user, changeset, review, options.get("file_id_format", "f%d"), compact, parent_index), cdata=True)
    target.addInternalStylesheet("""
table.file > tbody.lines > tr > td.line {
    white-space: pre%s !important
}""" % (wrap and "-wrap" or ""))

    comment_chains_per_file = {}

    if review:
        comment_chain_script = ""

        for file in changeset.files:
            if file.hasChanges() and not file.wasRemoved():
                comment_chains = review_comment.loadCommentChains(db, review, user, file=file, changeset=changeset, local_comments_only=local_comments_only)
                if comment_chains:
                    comment_chains_per_file[file.path] = comment_chains

                    for chain in comment_chains:
                        if file.new_sha1 in chain.lines_by_sha1: sha1 = file.new_sha1
                        else: sha1 = file.old_sha1

                        comment_chain_script += "commentChains.push(%s);\n" % chain.getJSConstructor(sha1)

        if comment_chain_script:
            target.script(type='text/javascript').text(comment_chain_script, cdata=True)

    def join(a, b):
        if a and b: return itertools.chain(a, b)
        elif a: return a
        elif b: return b
        else: return []

    local_options = { "style": style, "count_chunks": True }
    for name, value in options.items():
        local_options[name] = value

    if local_options.get("expand"):
        limit = user.getPreference(db, "commit.expandFilesLimit")
        if limit != 0 and limit < len(changeset.files):
            del local_options["expand"]

    for index, file in enumerate(changeset.files):
        if file.hasChanges():
            if not file.wasRemoved() and not file.isBinaryChanges():
                file.loadOldLines(True, request_highlight=True)
                file.loadNewLines(True, request_highlight=True)

                if not file.isEmptyChanges():
                    lines = diff.context.ContextLines(
                        file, file.chunks, comment_chains_per_file.get(file.path, []),
                        merge=options.get("merge", False), conflicts=changeset.conflicts)
                    file.macro_chunks = lines.getMacroChunks(context_lines, highlight=True)
                else:
                    file.macro_chunks = []
            else:
                file.macro_chunks = []

            renderFile(db, target, user, review, file, first_file=index == 0, options=local_options, conflicts=changeset.conflicts, add_resources=False)

            file.clean()

            yield target

def renderFile(db, target, user, review, file, first_file=False, options={}, conflicts=False, add_resources=True):
    if add_resources:
        addResources(db, user, file.repository, review, options.get("compact", False), options.get("tabify"), target)

    if options.get("count_chunks"):
        deleted = 0
        inserted = 0
        if file.wasRemoved():
            file.loadOldLines(False)
            deleted = file.oldCount()
        else:
            for macro_chunk in file.macro_chunks:
                for chunk in macro_chunk.chunks:
                    deleted += chunk.delete_count
                    inserted += chunk.insert_count
        chunksText = "-%d/+%d lines" % (deleted, inserted)
    else:
        chunksText = ""

    compact = options.get("compact", False)

    file_table_class = "file sourcefont"
    compact = options.get("compact", False)

    if options.get("show"):
        file_table_class += " show"
    if options.get("expand"):
        file_table_class += " expanded"
        compact = False

    if first_file:
        file_table_class += " first"

    file_id = "f%d" % file.id
    customFileId = options.get("file_id")
    if customFileId:
        file_id = customFileId(file_id)

    if options.get("tabify"):
        target.script(type="text/javascript").text("calculateTabWidth();")

    table = target.table(file_table_class, width='100%', cellspacing=0, cellpadding=0, id=file_id, critic_file_id=file.id, critic_parent_index=options.get("parent_index"))

    if not compact:
        columns = table.colgroup()
        columns.col('edge')
        columns.col('linenr')
        columns.col('line')
        columns.col('middle')
        columns.col('middle')
        columns.col('line')
        columns.col('linenr')
        columns.col('edge')

    row = table.thead().tr()

    header_left = options.get("header_left")
    header_right = options.get("header_right")

    def make_url(url_path, path):
        params = { "sha1": commit.sha1, "path": path }
        if review is None:
            params["repository"] = str(file.repository.id)
        else:
            params["review"] = str(review.id)
        return "/%s?%s" % (url_path, urllib.urlencode(params))

    if header_left:
        header_left(db, row.td('left', colspan=4, align='left'), file)
    else:
        cell = row.td('left', colspan=4, align='left')

        commit = options.get("commit")
        if commit:
            cell.a("showtree root", href=make_url("showtree", "/")).text("root")
            cell.span("slash").text('/')

            components = file.path.split("/")
            for index, component in enumerate(components[:-1]):
                cell.a("showtree", href=make_url("showtree", "/".join(components[:index + 1]))).text(component, escape=True)
                cell.span("slash").text('/')

            if not file.wasRemoved():
                cell.a("showtree", href=make_url("showfile", "/".join(components))).text(components[-1], escape=True)
            else:
                cell.text(components[-1], escape=True)
        else:
            cell.text(file.path)

        if not compact:
            cell.comment("sha1: %s to %s" % (file.old_sha1, file.new_sha1))

    if header_right:
        header_right(db, row.td('right', colspan=4, align='right'), file)
    else:
        row.td('right', colspan=4, align='right').text(chunksText)

    next_old_offset = 1
    next_new_offset = 1

    display_type = options.get("display_type", "both")
    deleted_file = False
    added_file = False

    if not file.isBinaryChanges() and not file.isEmptyChanges():
        if file.old_sha1 == 40 * '0':
            display_type = "new"

            if file.getLanguage() is None:
                limit = configuration.limits.MAXIMUM_ADDED_LINES_UNRECOGNIZED
            else:
                limit = configuration.limits.MAXIMUM_ADDED_LINES_RECOGNIZED

            count = file.newCount()
            if count > limit and len(file.macro_chunks) == 1 and len(file.macro_chunks[0].lines) == count:
                added_file = True
        elif file.new_sha1 == 40 * '0':
            display_type = "old"
            deleted_file = not options.get("include_deleted", False)

    def baseFileId(file):
        if file.move_source_file and file.move_target_file:
            return "fm%d_%d" % (file.move_source_file.id, file.move_target_file.id)
        else:
            return "f%d" % file.id

    def baseLineId(file, line, index):
        file_id = fileId(file)
        if line.type == diff.Line.DELETED:
            return "%so%dn0" % (file_id, line.old_offset)
        elif line.type == diff.Line.INSERTED:
            return "%so0n%d" % (file_id, line.new_offset)
        else:
            return "%so%dn%d" % (file_id, line.old_offset, line.new_offset)

    def baseLineCellId(file, version, line):
        if file.move_source_file and file.move_target_file:
            if version == "o": file_id = file.move_source_file.id
            else: file_id = file.move_target_file.id
        else:
            file_id = file.id
        if line: return "f%d%s%d" % (file_id, version, line)
        else: return None

    fileId = baseFileId

    customLineId = options.get("line_id")
    if customLineId:
        lineId = lambda file, line, index: customLineId(baseLineId(file, line, index))
    else:
        lineId = baseLineId

    customLineCellId = options.get("line_cell_id")
    if customLineCellId:
        lineCellId = lambda file, version, line: customLineCellId(baseLineCellId(file, version, line))
    else:
        lineCellId = baseLineCellId

    def lineType(line, index):
        type = line.type
        if type == diff.Line.DELETED: return "deleted"
        elif type == diff.Line.INSERTED: return "inserted"
        elif type == diff.Line.MODIFIED: return "modified whitespace" if line.is_whitespace else "modified"
        elif type == diff.Line.REPLACED: return "replaced"
        else: return "context"

    support_expand = options.get("support_expand", True)
    style = options.get("style", "horizontal")
    collapse_simple_hunks = user.getPreference(db, 'commit.diff.collapseSimpleHunks')

    content_before = options.get("content_before")
    if content_before:
        content = table.tbody('content')

        row = content.tr('content')
        row.td(colspan=2).text()
        content_before(db, row.td(colspan=4))
        row.td(colspan=2).text()

    if added_file or deleted_file:
        table.tbody('spacer').tr('spacer').td(colspan=8).text()

        verb = "added" if added_file else "deleted"
        side = "new" if added_file else "old"

        if added_file: count = file.newCount()
        else: count = file.oldCount()

        tbody = table.tbody('deleted')

        row = tbody.tr('deleted')
        row.td(colspan=2).text()
        row.td(colspan=4).h2().text("File was %s." % verb)
        row.td(colspan=2).text()

        if not file.isEmptyChanges():
            row = tbody.tr('deleted')
            row.td(colspan=2).text()
            parent_index = options.get("parent_index", -1)
            if parent_index != -1:
                fileset = "files[%d]" % parent_index
            else:
                fileset = "files"
            row.td(colspan=4).button(onclick="fetchFile(%s, %d, '%s', event.currentTarget.parentNode.parentNode.parentNode);" % (fileset, file.id, side)).text("Fetch %d %s Lines" % (count, verb.capitalize()))
            row.td(colspan=2).text()

        table.tbody('spacer').tr('spacer').td(colspan=8).text()
    elif file.isBinaryChanges() or file.isEmptyChanges():
        table.tbody('spacer').tr('spacer').td(colspan=8).text()

        if file.isBinaryChanges():
            title = "Binary"
            class_name = "binary"
        else:
            title = "Empty"
            class_name = "empty"

        tbody = table.tbody(class_name)

        if file.wasAdded():
            title += " file added."
        elif file.wasRemoved():
            title += " file removed."
        else:
            title += " file modified."

        row = tbody.tr(class_name)
        row.td(colspan=2).text()
        row.td(colspan=4).h2().text(title)
        row.td(colspan=2).text()

        if file.isBinaryChanges():
            row = tbody.tr('download')
            row.td(colspan=2).text()
            cell = row.td(colspan=4)

            def linkToFile(target, file, sha1):
                is_image = False

                try:
                    base, extension = file.path.rsplit(".")
                    if configuration.mimetypes.MIMETYPES.get(extension, "").startswith("image/"):
                        is_image = True
                except:
                    pass

                url = "/download/%s?sha1=%s&repository=%d" % (file.path, sha1, file.repository.id)
                link = target.a(href=url)

                if is_image: link.img(src=url)
                else: link.text(sha1)

            if file.wasAdded():
                linkToFile(cell, file, file.new_sha1)
            elif file.wasRemoved():
                linkToFile(cell, file, file.old_sha1)
            else:
                linkToFile(cell, file, file.old_sha1)
                cell.innerHTML(" &#8594; ")
                linkToFile(cell, file, file.new_sha1)

            row.td(colspan=2).text()

        table.tbody('spacer').tr('spacer').td(colspan=8).text()
    else:
        if options.get("tabify"):
            tabwidth = file.getTabWidth()
            indenttabsmode = file.getIndentTabsMode()
            tabify = lambda line: htmlutils.tabify(line, tabwidth, indenttabsmode)
        else:
            tabify = lambda line: line

        code_contexts = CodeContexts(db, file.new_sha1,
                                     file.macro_chunks[0].lines[0].new_offset,
                                     file.macro_chunks[-1].lines[-1].new_offset)

        blocks = [("[%d,%d]" % (macro_chunk.lines[0].new_offset, macro_chunk.lines[-1].new_offset))
                  for macro_chunk in file.macro_chunks]

        target.script(type="text/javascript").text("blocks[%d] = [%s];" % (file.id, ",".join(blocks)))

        for index, macro_chunk in enumerate(file.macro_chunks):
            first_line = macro_chunk.lines[0]
            last_line = macro_chunk.lines[-1]

            spacer = table.tbody('spacer')

            if support_expand and next_old_offset < first_line.old_offset and next_new_offset < first_line.new_offset:
                row = spacer.tr('expand').td(colspan='8')
                expandHTML(db, file, next_old_offset, next_new_offset, first_line.old_offset - next_old_offset, row)

            code_context = code_contexts.find(first_line.new_offset)
            if code_context: spacer.tr('context').td(colspan='8').text(code_context)

            spacer.tr('spacer').td(colspan='8').text()

            lines = table.tbody('lines')

            local_display_type = display_type

            for line in macro_chunk.lines:
                if line.type != diff.Line.INSERTED:
                    match = re_tailws.match(line.old_value)
                    if match:
                        line.old_value = match.group(1) + "<i class='tailws'>" + match.group(2) + "</i>" + match.group(3)
                if line.type != diff.Line.DELETED:
                    match = re_tailws.match(line.new_value)
                    if match:
                        line.new_value = match.group(1) + "<i class='tailws'>" + match.group(2) + "</i>" + match.group(3)

                if line.old_value:
                    line.old_value = line.old_value.replace("\r", "<i class='cr'></i>")
                if line.new_value:
                    line.new_value = line.new_value.replace("\r", "<i class='cr'></i>")

            if collapse_simple_hunks:
                if local_display_type == "both":
                    deleted = False
                    inserted = False

                    for line in macro_chunk.lines:
                        if line.type == diff.Line.MODIFIED or line.type == diff.Line.REPLACED:
                            break
                        elif line.type == diff.Line.DELETED:
                            if inserted: break
                            deleted = True
                        elif line.type == diff.Line.INSERTED:
                            if deleted: break
                            inserted = True
                    else:
                        if deleted: local_display_type = "old"
                        if inserted: local_display_type = "new"

            if compact:
                def packSyntaxHighlighting(line):
                    return re_tag.sub(lambda m: "<%s%s>" % (m.group(1), m.group(2)), line)

                items = []
                for line in macro_chunk.lines:
                    if line.type == diff.Line.MODIFIED and line.is_whitespace:
                        line_type = diff.Line.WHITESPACE
                    elif conflicts and line.type == diff.Line.DELETED and line.isConflictMarker():
                        line_type = diff.Line.CONFLICT
                    else:
                        line_type = line.type
                    data = [str(line_type)]
                    if line.type != diff.Line.INSERTED:
                        data.append(jsify(packSyntaxHighlighting(tabify(line.old_value)),
                                          as_json=True))
                    if line.type != diff.Line.DELETED:
                        data.append(jsify(packSyntaxHighlighting(tabify(line.new_value)),
                                          as_json=True))
                    items.append("[%s]" % ",".join(data))
                data = "[%d,%d,%d,%d,%s]" % (file.id,
                                             2 if local_display_type == "both" else 1,
                                             macro_chunk.lines[0].old_offset,
                                             macro_chunk.lines[0].new_offset,
                                             "[%s]" % ",".join(items))
                lines.comment(data.replace("--", "-\u002d"))
            elif style == "vertical" or local_display_type != "both":
                linesIterator = iter(macro_chunk.lines)
                line = linesIterator.next()

                def lineHTML(what, file, line, is_whitespace, target):
                    line_class = what

                    if is_whitespace and line.type == diff.Line.MODIFIED:
                        line_class = "modified"

                    if what == "deleted":
                        linenr = line.old_offset
                    else:
                        linenr = line.new_offset

                    row = target.tr("line single " + line_class, id=lineId(file, line, 0))
                    row.td("edge").text()
                    row.td("linenr old").text(linenr)

                    if what == "deleted" or local_display_type == "old":
                        code = line.old_value
                        lineClass = "old"
                    else:
                        code = line.new_value
                        lineClass = "new"

                    if not code: code = "&nbsp;"

                    row.td('line single ' + lineClass, colspan=4, id=lineCellId(file, lineClass[0], linenr)).innerHTML(tabify(code))
                    row.td('linenr new').text(linenr)

                    row.td("edge").text()

                try:
                    while line:
                        while line.type == diff.Line.CONTEXT:
                            lineHTML("context", file, line, False, lines)
                            line = linesIterator.next()

                        deleted = []
                        inserted = []

                        while line.is_whitespace:
                            lineHTML("modified", file, line, True, lines)
                            line = linesIterator.next()

                        previous_type = diff.Line.DELETED

                        try:
                            while line.type >= previous_type and not line.is_whitespace:
                                if line.type != diff.Line.INSERTED: deleted.append(line)
                                if line.type != diff.Line.DELETED: inserted.append(line)
                                previous_type = line.type
                                line = None
                                line = linesIterator.next()
                        except StopIteration:
                            line = None

                        for deletedLine in deleted:
                            lineHTML("deleted", file, deletedLine, False, lines)
                        for insertedLine in inserted:
                            lineHTML("inserted", file, insertedLine, False, lines)
                except StopIteration:
                    pass
            elif style == "horizontal":
                for line in macro_chunk.lines:
                    old_offset = None
                    new_offset = None
                    old_line = None
                    new_line = None

                    if line.type != diff.Line.INSERTED:
                        old_offset = line.old_offset
                        old_line = tabify(line.old_value)

                    if line.type != diff.Line.DELETED:
                        new_offset = line.new_offset
                        new_line = tabify(line.new_value)

                    if not old_line: old_line = "&nbsp;"
                    if old_line is None: old_offset = None
                    if not new_line: new_line = "&nbsp;"
                    if new_line is None: new_offset = None

                    line_type = lineType(line, 0)

                    if conflicts and line.isConflictMarker():
                        line_type += " conflict"

                    row = ("<tr class='line %s' id='%s'>"
                             "<td class='edge'>&nbsp;</td>"
                             "<td class='linenr old'>%s</td>"
                             "<td class='line old'%s>%s</td>"
                             "<td class='middle' colspan=2>&nbsp;</td>"
                             "<td class='line new'%s>%s</td>"
                             "<td class='linenr new'>%s</td>"
                             "<td class='edge'>&nbsp;</td>"
                           "</tr>\n") % (line_type, lineId(file, line, 0),
                                         str(old_offset) if old_offset else "&nbsp;",
                                         " id='%s'" % lineCellId(file, "o", old_offset) if old_offset else "", old_line,
                                         " id='%s'" % lineCellId(file, "n", new_offset) if new_offset else "", new_line,
                                         str(new_offset) if new_offset else "&nbsp;")

                    lines.innerHTML(row)

            next_old_offset = last_line.old_offset + 1
            next_new_offset = last_line.new_offset + 1

        spacer = table.tbody('spacer')

        if support_expand and next_old_offset < file.oldCount() + 1 and next_new_offset < file.newCount() + 1:
            row = spacer.tr('expand').td(colspan='8')
            expandHTML(db, file, next_old_offset, next_new_offset, 1 + file.oldCount() - next_old_offset, row)

        spacer.tr('spacer').td(colspan='8').text()

    content_after = options.get("content_after")
    if content_after:
        content = table.tbody('content')

        row = content.tr('content')
        row.td(colspan=2).text()
        content_after(db, row.td(colspan=4), file=file)
        row.td(colspan=2).text()

        content.tr('spacer').td(colspan=8).text()

    row = table.tfoot().tr()
    cell = row.td('left', colspan=4)

    commit = options.get("commit")
    if commit:
        cell.a("showtree root", href=make_url("showtree", "/")).text("root")
        cell.span("slash").text('/')

        components = file.path.split("/")
        for index, component in enumerate(components[:-1]):
            cell.a("showtree", href=make_url("showtree", "/".join(components[:index + 1]))).text(component, escape=True)
            cell.span("slash").text('/')

        if not file.wasRemoved():
            cell.a("showtree", href=make_url("showfile", "/".join(components))).text(components[-1], escape=True)
        else:
            cell.text(components[-1], escape=True)
    else:
        cell.text(file.path)

    row.td('right', colspan=4).text(chunksText)

def addResources(db, user, repository, review, compact, tabify, target):
    target.addExternalStylesheet("resource/changeset.css")
    target.addExternalScript("resource/changeset.js")

    target.addInternalStylesheet(stripStylesheet(user.getResource(db, "syntax.css")[1], compact))
    target.addInternalStylesheet(stripStylesheet(user.getResource(db, "diff.css")[1], compact))

    if user.getPreference(db, "commit.diff.highlightIllegalWhitespace"):
        target.addInternalStylesheet(stripStylesheet(user.getResource(db, "whitespace.css")[1], compact))

    ruler_column = user.getPreference(db, "commit.diff.rulerColumn", repository=repository)

    if ruler_column > 0:
        target.addExternalScript("resource/ruler.js")

    # Injected unconditionally (for tests).
    target.addInternalScript("var rulerColumn = %d;" % ruler_column)

    if review:
        target.addExternalStylesheet("resource/comment.css")
        target.addExternalStylesheet("resource/review.css")
        target.addExternalScript("resource/comment.js")
        target.addExternalScript("resource/review.js")

    if tabify:
        target.addExternalScript("resource/tabify.js")

########NEW FILE########
__FILENAME__ = load
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2012 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import diff
import dbutils
import gitutils

def loadChangeset(db, repository, changeset_id, filtered_file_ids=None, load_chunks=True):
    return loadChangesets(db, repository,
                          changesets=[diff.Changeset.fromId(db, repository, changeset_id)],
                          filtered_file_ids=filtered_file_ids,
                          load_chunks=load_chunks)[0]

def loadChangesetsForCommits(db, repository, commits, filtered_file_ids=None, load_chunks=True):
    commit_ids = dict([(commit.getId(db), commit) for commit in commits])

    def getCommit(commit_id):
        return commit_ids.get(commit_id) or gitutils.Commit.fromId(db, repository, commit_id)

    cursor = db.cursor()
    cursor.execute("SELECT id, parent, child FROM changesets WHERE child=ANY (%s) AND type='direct'", (commit_ids.keys(),))

    changesets = []

    for changeset_id, parent_id, child_id in cursor:
        changesets.append(diff.Changeset(changeset_id, getCommit(parent_id), getCommit(child_id), "direct"))

    return loadChangesets(db, repository, changesets, filtered_file_ids=filtered_file_ids, load_chunks=load_chunks)

def loadChangesets(db, repository, changesets, filtered_file_ids=None, load_chunks=True):
    cursor = db.cursor()

    changeset_ids = [changeset.id for changeset in changesets]
    filtered_file_ids = list(filtered_file_ids) if filtered_file_ids else None

    if filtered_file_ids is None:
        cursor.execute("""SELECT changeset, file, path, old_sha1, new_sha1, old_mode, new_mode
                            FROM fileversions
                            JOIN files ON (files.id=fileversions.file)
                           WHERE changeset=ANY (%s)""",
                       (changeset_ids,))
    else:
        cursor.execute("""SELECT changeset, file, path, old_sha1, new_sha1, old_mode, new_mode
                            FROM fileversions
                            JOIN files ON (files.id=fileversions.file)
                           WHERE changeset=ANY (%s)
                             AND file=ANY (%s)""",
                       (changeset_ids, filtered_file_ids))

    files = dict([(changeset.id, {}) for changeset in changesets])

    for changeset_id, file_id, file_path, file_old_sha1, file_new_sha1, file_old_mode, file_new_mode in cursor.fetchall():
        files[changeset_id][file_id] = diff.File(file_id, file_path,
                                                 file_old_sha1, file_new_sha1,
                                                 repository,
                                                 old_mode=file_old_mode,
                                                 new_mode=file_new_mode,
                                                 chunks=[])

    if load_chunks:
        if filtered_file_ids is None:
            cursor.execute("""SELECT id, changeset, file, deleteOffset, deleteCount, insertOffset, insertCount, analysis, whitespace
                                FROM chunks
                                WHERE changeset=ANY (%s)
                                ORDER BY file, deleteOffset ASC""",
                           (changeset_ids,))
        else:
            cursor.execute("""SELECT id, changeset, file, deleteOffset, deleteCount, insertOffset, insertCount, analysis, whitespace
                                FROM chunks
                                WHERE changeset=ANY (%s)
                                  AND file=ANY (%s)
                                ORDER BY file, deleteOffset ASC""",
                           (changeset_ids, filtered_file_ids))

        for chunk_id, changeset_id, file_id, delete_offset, delete_count, insert_offset, insert_count, analysis, is_whitespace in cursor:
            files[changeset_id][file_id].chunks.append(diff.Chunk(delete_offset, delete_count,
                                                                  insert_offset, insert_count,
                                                                  id=chunk_id,
                                                                  is_whitespace=is_whitespace,
                                                                  analysis=analysis))

    for changeset in changesets:
        changeset.files = diff.File.sorted(files[changeset.id].values())

    return changesets

########NEW FILE########
__FILENAME__ = process
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2012 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import gitutils
import stat

def joinPaths(dirname, basename):
    return "%s/%s" % (dirname, basename) if dirname else basename

class ChangedPath:
    def __init__(self, path, oldEntry, newEntry):
        self.path = path
        self.oldEntry = oldEntry
        self.newEntry = newEntry

def removedTree(repository, path, sha1):
    changedPaths = []
    for entry in gitutils.Tree.fromSHA1(repository, sha1):
        changedPaths.extend(
            removedEntry(repository, path, entry))
    return changedPaths

def removedEntry(repository, path, entry):
    path = joinPaths(path, entry.name)

    changedPaths = [ChangedPath(path, entry, None)]
    if stat.S_ISDIR(entry.mode):
        changedPaths.extend(
            removedTree(repository, path, entry.sha1))
    return changedPaths

def addedTree(repository, path, sha1):
    changedPaths = []
    for entry in gitutils.Tree.fromSHA1(repository, sha1):
        changedPaths.extend(
            addedEntry(repository, path, entry))
    return changedPaths

def addedEntry(repository, path, entry):
    path = joinPaths(path, entry.name)

    changedPaths = [ChangedPath(path, None, entry)]
    if stat.S_ISDIR(entry.mode):
        changedPaths.extend(
            addedTree(repository, path, entry.sha1))
    return changedPaths

def diffTrees(repository, path, oldTree, newTree):
    oldNames = set(oldTree.keys())
    newNames = set(newTree.keys())

    commonNames = oldNames & newNames
    removedNames = oldNames - commonNames
    addedNames = newNames - commonNames

    changedPaths = []

    for name in removedNames:
        changedPaths.extend(
            removedEntry(repository, joinPaths(path, name), oldTree[name]))
    for name in addedNames:
        changedPaths.extend(
            addedEntry(repository, joinPaths(path, name), newTree[name]))

    for name in commonNames:
        oldEntry = oldTree[name]
        newEntry = newTree[name]

        if oldEntry.sha1 != newEntry.sha1 or oldEntry.mode != newEntry.mode:
            changedPath = joinPaths(path, name)
            changedPaths.append(ChangedPath(changedPath, oldEntry, newEntry))

            commonMode = oldEntry.mode & newEntry.mode
            removedMode = oldEntry.mode - commonMode
            addedMode = newEntry.mode - commonMode

            if stat.S_ISDIR(removedMode):
                changedPaths.extend(
                    removedTree(repository, changedPath, oldEntry.sha1))
            elif stat.S_ISDIR(addedMode):
                changedPaths.extend(
                    addedTree(repository, changedPath, newEntry.sha1))
            elif stat.S_ISDIR(commonMode) and oldEntry.sha1 != newEntry.sha1:
                changedPaths.extend(
                    diffTrees(repository, changedPath,
                              gitutils.Tree.fromSHA1(repository, oldEntry.sha1),
                              gitutils.Tree.fromSHA1(repository, newEntry.sha1)))

    return changedPaths

def diffCommits(repository, commitA, commitB):
    return diffTrees(repository,
                     None,
                     gitutils.Tree.fromSHA1(repository, commitA.tree),
                     gitutils.Tree.fromSHA1(repository, commitB.tree))

########NEW FILE########
__FILENAME__ = text
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2012 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import diff
import diff.context

from changeset.utils import getCodeContext

def unified(db, changeset, context_lines=3):
    result = ""

    for file in changeset.files:
        file.loadOldLines()
        file.loadNewLines()

        try:
            lines = diff.context.ContextLines(file, file.chunks)

            file.macro_chunks = lines.getMacroChunks(context_lines, highlight=False)

            oldPath = file.path if not file.wasAdded() else "dev/null"
            newPath = file.path if not file.wasRemoved() else "dev/null"

            result += "--- a/%s\n+++ b/%s\n" % (oldPath, newPath)

            if file.isBinaryChanges():
                result += "  Binary file.\n"
                continue

            for chunk in file.macro_chunks:
                deleteOffset = chunk.lines[0].old_offset
                deleteCount = len(filter(lambda line: line.type != diff.Line.INSERTED, chunk.lines))
                insertOffset = chunk.lines[0].new_offset
                insertCount = len(filter(lambda line: line.type != diff.Line.DELETED, chunk.lines))

                chunkHeader = "@@ -%d,%d +%d,%d @@" % (deleteOffset, deleteCount, insertOffset, insertCount)

                if db: codeContext = getCodeContext(db, file.new_sha1, insertOffset, minimized=True)
                else: codeContext = None

                if codeContext: chunkHeader += " %s" % codeContext[:80 - len(chunkHeader)]

                result += chunkHeader + "\n"

                lines = iter(chunk.lines)
                line = lines.next()

                try:
                    while line:
                        while line.type == diff.Line.CONTEXT:
                            result += "  %s\n" % line.new_value
                            line = lines.next()

                        deleted = []
                        inserted = []

                        try:
                            while line.type != diff.Line.CONTEXT:
                                if line.type != diff.Line.INSERTED: deleted.append(line)
                                if line.type != diff.Line.DELETED: inserted.append(line)
                                line = lines.next()
                        except StopIteration:
                            line = None

                        for deletedLine in deleted:
                            result += "- %s\n" % deletedLine.old_value
                        for insertedLine in inserted:
                            result += "+ %s\n" % insertedLine.new_value
                except StopIteration:
                    pass
        finally:
            file.cleanLines()

    return result

########NEW FILE########
__FILENAME__ = utils
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2012 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

from subprocess import Popen as process, PIPE
from sys import argv, stderr, exit
import re
from dbutils import find_file, describe_file
import gitutils
import syntaxhighlight
import syntaxhighlight.request
from diffutils import expandWithContext
from htmlutils import htmlify, jsify
from time import strftime

import diff
import diff.analyze
import diff.parse
import diff.merge

import load
import dbutils
import client

def createFullMergeChangeset(db, user, repository, commit, **kwargs):
    assert len(commit.parents) > 1

    changesets = createChangeset(db, user, repository, commit, **kwargs)

    assert len(changesets) == len(commit.parents)

    replayed = createChangeset(db, user, repository, commit, conflicts=True, **kwargs)

    assert len(replayed) == 1

    changesets.append(replayed[0])

    return changesets

def createChangesets(db, repository, commits):
    cursor = db.cursor()
    requests = []

    for commit in commits:
        if len(commit.parents) > 1: changeset_type = 'merge'
        else: changeset_type = 'direct'

        cursor.execute("SELECT 1 FROM changesets WHERE child=%s AND type=%s", (commit.getId(db), changeset_type))

        if not cursor.fetchone():
            requests.append({ "repository_name": repository.name,
                              "changeset_type": changeset_type,
                              "child_sha1": commit.sha1 })

    if requests:
        client.requestChangesets(requests)

def createChangeset(db, user, repository, commit=None, from_commit=None, to_commit=None, rescan=False, reanalyze=False, conflicts=False, filtered_file_ids=None, review=None, do_highlight=True, load_chunks=True):
    cursor = db.cursor()

    if conflicts:
        if commit:
            assert len(commit.parents) > 1

            cursor.execute("SELECT replay FROM mergereplays WHERE original=%s", (commit.getId(db),))
            row = cursor.fetchone()

            if row:
                replay = gitutils.Commit.fromId(db, repository, row[0])
            else:
                replay = repository.replaymerge(db, user, commit)
                if not replay: return None
                cursor.execute("INSERT INTO mergereplays (original, replay) VALUES (%s, %s)", (commit.getId(db), replay.getId(db)))

            from_commit = replay
            to_commit = commit

            parents = [replay]
        else:
            parents = [from_commit]
            commit = to_commit

        changeset_type = 'conflicts'
    elif commit:
        parents = [gitutils.Commit.fromSHA1(db, repository, sha1) for sha1 in commit.parents] or [None]
        changeset_type = 'merge' if len(parents) > 1 else 'direct'
    else:
        parents = [from_commit]
        commit = to_commit
        changeset_type = 'direct' if len(to_commit.parents) == 1 and from_commit == to_commit.parents[0] else 'custom'

    changesets = []

    thin_diff = False

    changeset_ids = []

    for parent in parents:
        if parent:
            cursor.execute("SELECT id FROM changesets WHERE parent=%s AND child=%s AND type=%s",
                           (parent.getId(db), commit.getId(db), changeset_type))
        else:
            cursor.execute("SELECT id FROM changesets WHERE parent IS NULL AND child=%s AND type=%s",
                           (commit.getId(db), changeset_type))

        row = cursor.fetchone()

        if row: changeset_ids.append(row[0])
        else: break

    assert len(changeset_ids) in (0, len(parents))

    if changeset_ids:
        if rescan and user.hasRole(db, "developer"):
            cursor.executemany("DELETE FROM changesets WHERE id=%s", [(changeset_id,) for changeset_id in changeset_ids])
            db.commit()
            changeset_ids = []
        else:
            for changeset_id in changeset_ids:
                if changeset_type == 'custom':
                    cursor.execute("UPDATE customchangesets SET time=NOW() WHERE changeset=%s", (changeset_id,))

                changeset = load.loadChangeset(db, repository, changeset_id, filtered_file_ids=filtered_file_ids, load_chunks=load_chunks)
                changeset.conflicts = conflicts

                if reanalyze and user.hasRole(db, "developer"):
                    analysis_values = []

                    for file in changeset.files:
                        if not filtered_file_ids or file.id in filtered_file_ids:
                            for index, chunk in enumerate(file.chunks):
                                old_analysis = chunk.analysis
                                chunk.analyze(file, index == len(file.chunks) - 1, True)
                                if old_analysis != chunk.analysis:
                                    analysis_values.append((chunk.analysis, chunk.id))

                    if reanalyze == "commit" and analysis_values:
                        cursor.executemany("UPDATE chunks SET analysis=%s WHERE id=%s", analysis_values)

                changesets.append(changeset)

    if not changesets:
        if len(parents) == 1 and from_commit and to_commit and filtered_file_ids:
            if from_commit.isAncestorOf(to_commit):
                iter_commit = to_commit
                while iter_commit != from_commit:
                    if len(iter_commit.parents) > 1:
                        thin_diff = True
                        break
                    iter_commit = gitutils.Commit.fromSHA1(db, repository, iter_commit.parents[0])
            else:
                thin_diff = True

        if not thin_diff:
            if changeset_type == "direct":
                request = { "changeset_type": "direct",
                            "child_sha1": commit.sha1 }
            elif changeset_type == "custom":
                request = { "changeset_type": "custom",
                            "parent_sha1": from_commit.sha1 if from_commit else "0" * 40,
                            "child_sha1": to_commit.sha1 }
            elif changeset_type == "merge":
                request = { "changeset_type": "merge",
                            "child_sha1": commit.sha1 }
            else:
                request = { "changeset_type": "conflicts",
                            "parent_sha1": from_commit.sha1,
                            "child_sha1": to_commit.sha1 }

            request["repository_name"] = repository.name

            client.requestChangesets([request])

            db.commit()

            for parent in parents:
                if parent:
                    cursor.execute("SELECT id FROM changesets WHERE parent=%s AND child=%s AND type=%s",
                                   (parent.getId(db), commit.getId(db), changeset_type))
                else:
                    cursor.execute("SELECT id FROM changesets WHERE parent IS NULL AND child=%s AND type=%s",
                                   (commit.getId(db), changeset_type))

                changeset_id = cursor.fetchone()[0]
                changeset = load.loadChangeset(db, repository, changeset_id, filtered_file_ids=filtered_file_ids, load_chunks=load_chunks)
                changeset.conflicts = conflicts

                changesets.append(changeset)
        else:
            changes = diff.parse.parseDifferences(repository, from_commit=from_commit, to_commit=to_commit, filter_paths=[describe_file(db, file_id) for file_id in filtered_file_ids])[from_commit.sha1]

            dbutils.find_files(db, changes)

            for file in changes:
                for index, chunk in enumerate(file.chunks):
                    chunk.analyze(file, index == len(file.chunks) - 1)

            changeset = diff.Changeset(None, from_commit, to_commit, changeset_type)
            changeset.conflicts = conflicts
            changeset.files = diff.File.sorted(changes)

            changesets.append(changeset)

    if do_highlight:
        highlights = {}

        for changeset in changesets:
            for file in changeset.files:
                if file.canHighlight():
                    if file.old_sha1 and file.old_sha1 != '0' * 40:
                        highlights[file.old_sha1] = (file.path, file.getLanguage())
                    if file.new_sha1 and file.new_sha1 != '0' * 40:
                        highlights[file.new_sha1] = (file.path, file.getLanguage())

        syntaxhighlight.request.requestHighlights(repository, highlights)

    return changesets

def getCodeContext(db, sha1, line, minimized=False):
    cursor = db.cursor()
    cursor.execute("SELECT context FROM codecontexts WHERE sha1=%s AND first_line<=%s AND last_line>=%s ORDER BY first_line DESC LIMIT 1", [sha1, line, line])
    row = cursor.fetchone()
    if row:
        context = row[0]
        if minimized: context = re.sub("\\(.*(?:\\)|...$)", "(...)", context)
        return context
    else: return None

########NEW FILE########
__FILENAME__ = cli
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2012 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import sys
import traceback

import dbutils
import gitutils
import mailutils
import reviewing.utils
import reviewing.filters
import reviewing.mail

from textutils import json_encode, json_decode

db = None

def init():
    global db

    db = dbutils.Database()

def finish():
    global db

    if db:
        db.commit()
        db.close()
        db = None

def abort():
    global db

    if db:
        db.rollback()
        db.close()
        db = None

def sendCustomMail(from_user, recipients, subject, headers, body, review):
    assert recipients is not None or review is not None

    if review:
        if recipients is None:
            recipients = review.getRecipients(db)

    files = []

    for to_user in recipients:
        if not to_user.getPreference(db, "email.activated") \
               or to_user.status == "retired":
            continue

        if review:
            parent_message_id = reviewing.mail.getReviewMessageId(
                db, to_user, review, files)

        message_id = mailutils.generateMessageId(len(files) + 1)

        if review:
            filename = reviewing.mail.sendMail(
                db, review, message_id, from_user, to_user, recipients, subject,
                body, parent_message_id, headers)
        else:
            filename = mailutils.queueMail(
                from_user, to_user, recipients, subject, body,
                message_id=message_id, headers=headers)

        files.append(filename)

    return files

try:
    if len(sys.argv) > 1:
        init()

        for command in sys.argv[1:]:
            pending_mails = None

            if command == "generate-mails-for-batch":
                data = json_decode(sys.stdin.readline())
                batch_id = data["batch_id"]
                was_accepted = data["was_accepted"]
                is_accepted = data["is_accepted"]
                pending_mails = reviewing.utils.generateMailsForBatch(db, batch_id, was_accepted, is_accepted)
            elif command == "generate-mails-for-assignments-transaction":
                data = json_decode(sys.stdin.readline())
                transaction_id = data["transaction_id"]
                pending_mails = reviewing.utils.generateMailsForAssignmentsTransaction(db, transaction_id)
            elif command == "apply-filters":
                data = json_decode(sys.stdin.readline())
                filters = reviewing.filters.Filters()
                user = dbutils.User.fromId(db, data["user_id"]) if "user_id" in data else None
                if "review_id" in data:
                    review = dbutils.Review.fromId(db, data["review_id"], load_commits=False)
                    filters.setFiles(db, review=review)
                    filters.load(db, review=review, user=user,
                                 added_review_filters=data.get("added_review_filters", []),
                                 removed_review_filters=data.get("removed_review_filters", []))
                else:
                    repository = gitutils.Repository.fromId(db, data["repository_id"])
                    filters.setFiles(db, file_ids=data["file_ids"])
                    filters.load(db, repository=repository, recursive=data.get("recursive", False), user=user)
                sys.stdout.write(json_encode(filters.data) + "\n")
            elif command == "generate-custom-mails":
                pending_mails = []
                for data in json_decode(sys.stdin.readline()):
                    from_user = dbutils.User.fromId(db, data["sender"])
                    if data.get("recipients"):
                        recipients = [dbutils.User.fromId(db, user_id)
                                      for user_id in data["recipients"]]
                    else:
                        recipients = None
                    subject = data["subject"]
                    headers = data.get("headers")
                    body = data["body"]
                    if "review_id" in data:
                        review = dbutils.Review.fromId(db, data["review_id"])
                    else:
                        review = None
                    pending_mails.extend(sendCustomMail(
                        from_user, recipients, subject, headers, body, review))
            else:
                sys.stdout.write(json_encode("unknown command: %s" % command) + "\n")
                sys.exit(0)

            if pending_mails is not None:
                sys.stdout.write(json_encode(pending_mails) + "\n")

        finish()
except Exception:
    sys.stdout.write(json_encode(traceback.format_exc()) + "\n")
finally:
    abort()

########NEW FILE########
__FILENAME__ = communicate
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2012 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import os
import fcntl
import select
import cStringIO
import time
import errno

class ProcessTimeout(Exception):
    pass

class ProcessError(Exception):
    def __init__(self, process, stderr):
        self.returncode = process.returncode
        self.stderr = stderr

def setnonblocking(fd):
    fcntl.fcntl(fd, fcntl.F_SETFL, fcntl.fcntl(fd, fcntl.F_GETFL) | os.O_NONBLOCK)

class Communicate(object):
    def __init__(self, process):
        self.process = process
        self.deadline = None
        self.stdin_data = None
        self.stdout_callbacks = [None, None]
        self.stderr_callbacks = [None, None]
        self.returncode = None

    def setTimeout(self, timeout):
        self.deadline = time.time() + timeout

    def setInput(self, data):
        self.stdin_data = data

    def setCallbacks(self, stdout=None, stdout_line=None, stderr=None, stderr_line=None):
        assert stdout is None or stdout_line is None
        assert stderr is None or stderr_line is None
        self.stdout_callbacks[:] = stdout, stdout_line
        self.stderr_callbacks[:] = stderr, stderr_line

    def __read(self, source, target, callbacks):
        while True:
            cb_data, cb_line = callbacks
            try:
                if cb_line:
                    line = source.readline()
                    if not line:
                        return True
                    cb_line(line)
                else:
                    data = source.read()
                    if not data:
                        return True
                    if cb_data:
                        cb_data(data)
                    else:
                        target.write(data)
            except IOError as error:
                if error.errno == errno.EAGAIN:
                    return False
                raise

    def run(self):
        process = self.process
        poll = select.poll()

        if callable(self.stdin_data):
            stdin_data = ""
        else:
            stdin_data = self.stdin_data
            self.stdin_data = None
        stdin_done = False

        stdout = cStringIO.StringIO()
        stdout_done = False

        stderr = cStringIO.StringIO()
        stderr_done = False

        if process.stdin:
            setnonblocking(process.stdin)
            poll.register(process.stdin, select.POLLOUT)
        else:
            stdin_done = True

        if process.stdout:
            setnonblocking(process.stdout)
            poll.register(process.stdout, select.POLLIN)
        else:
            stdout_done = True

        if process.stderr:
            setnonblocking(process.stderr)
            poll.register(process.stderr, select.POLLIN)
        else:
            stderr_done = True

        while (not stdin_done or not stdout_done or not stderr_done) \
                and (self.deadline is None or time.time() < self.deadline):
            if self.deadline is None:
                timeout = None
            else:
                timeout = 1000 * (self.deadline - time.time())

            for fd, event in poll.poll(timeout):
                if not stdin_done and fd == process.stdin.fileno():
                    if callable(self.stdin_data):
                        data = self.stdin_data()
                        if data is None:
                            self.stdin_data = None
                        else:
                            stdin_data += data

                    if stdin_data:
                        nwritten = os.write(process.stdin.fileno(), stdin_data)
                        stdin_data = stdin_data[nwritten:]

                    if not stdin_data and self.stdin_data is None:
                        process.stdin.close()
                        stdin_done = True
                        poll.unregister(fd)

                if not stdout_done and fd == process.stdout.fileno():
                    stdout_done = self.__read(process.stdout, stdout,
                                              self.stdout_callbacks)
                    if stdout_done:
                        poll.unregister(fd)

                if not stderr_done and fd == process.stderr.fileno():
                    stderr_done = self.__read(process.stderr, stderr,
                                              self.stderr_callbacks)
                    if stderr_done:
                        poll.unregister(fd)

        if stdin_done and stdout_done and stderr_done:
            process.wait()

            stdout_data = stdout.getvalue() if process.stdout else None
            stderr_data = stderr.getvalue() if process.stderr else None

            self.returncode = process.returncode

            if self.returncode == 0:
                return stdout_data, stderr_data
            else:
                raise ProcessError(process, stderr_data)

        process.kill()
        process.wait()

        raise ProcessTimeout

########NEW FILE########
__FILENAME__ = coverage
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2013 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import sys
import os
import trace
import errno
import tempfile
import shutil
import re
import json

def call(context, fn, *args, **kwargs):
    import configuration

    context_dir = os.path.join(configuration.debug.COVERAGE_DIR, context)

    try:
        os.makedirs(context_dir)
    except OSError as error:
        if error.errno != errno.EEXIST:
            raise

    output_dir = tempfile.mkdtemp(dir=context_dir)
    counts = output_dir + ".counts"
    tracer = trace.Trace(count=1, trace=0, outfile=counts)

    try:
        return tracer.runfunc(fn, *args, **kwargs)
    finally:
        results = tracer.results()
        results.write_results(show_missing=False, coverdir=output_dir)
        shutil.rmtree(output_dir)

if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser("Critic Code Coverage Collection")
    parser.add_argument("--coverage-dir")
    parser.add_argument("--critic-dir", action="append")

    arguments = parser.parse_args()

    ignore_dirs = filter(None, sys.path)

    coverage_dir = arguments.coverage_dir
    sys.path[:0] = arguments.critic_dir

    data = { "contexts": [] }

    for context in os.listdir(coverage_dir):
        context_dir = os.path.join(coverage_dir, context)

        if not os.path.isdir(context_dir):
            continue

        context_index = len(data["contexts"])
        data["contexts"].append(context)

        tracer = trace.Trace()
        results = tracer.results()

        for filename in os.listdir(context_dir):
            if filename.endswith(".counts"):
                counts = os.path.join(context_dir, filename)
                results.update(trace.Trace(infile=counts).results())
                os.unlink(counts)

        results.write_results(show_missing=False, coverdir=context_dir)

        for filename in os.listdir(context_dir):
            if filename.endswith(".cover"):
                module_filename = filename[:-6].replace(".", "/") + ".py"
                if os.path.isfile(module_filename):
                    counts = {}
                    with open(os.path.join(context_dir, filename)) as coverage:
                        lines = coverage.read().splitlines()
                    executed = []
                    for index, line in enumerate(lines):
                        match = re.match(" *\d+:", line)
                        if match:
                            executed.append(index)
                    data.setdefault(module_filename, {})[context] = executed

    json.dump(data, sys.stdout)

    print

########NEW FILE########
__FILENAME__ = critic
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2012 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import os
import gitutils
import time
import re
import itertools
import traceback
import cStringIO
import wsgiref.util

from htmlutils import htmlify, Document
from profiling import formatDBProfiling
from textutils import json_encode, reflow

import request
import dbutils
import reviewing.filters as review_filters
import log.commitset as log_commitset
import diff
import mailutils
import configuration
import auth

import operation.createcomment
import operation.createreview
import operation.manipulatecomment
import operation.manipulatereview
import operation.manipulatefilters
import operation.manipulateuser
import operation.manipulateassignments
import operation.fetchlines
import operation.markfiles
import operation.draftchanges
import operation.blame
import operation.trackedbranch
import operation.rebasereview
import operation.recipientfilter
import operation.editresource
import operation.autocompletedata
import operation.servicemanager
import operation.addrepository
import operation.news
import operation.checkrebase
import operation.applyfilters
import operation.savesettings
import operation.searchreview
import operation.registeruser

import page.utils
import page.createreview
import page.branches
import page.showcomment
import page.showcommit
import page.showreview
import page.showreviewlog
import page.showbatch
import page.showbranch
import page.showtree
import page.showfile
import page.config
import page.dashboard
import page.home
import page.managereviewers
import page.filterchanges
import page.tutorial
import page.news
import page.editresource
import page.statistics
import page.confirmmerge
import page.addrepository
import page.checkbranch
import page.search
import page.repositories
import page.services
import page.rebasetrackingreview
import page.createuser
import page.verifyemail
import page.manageextensions

try:
    from customization.email import getUserEmailAddress
except ImportError:
    def getUserEmailAddress(_username):
        return None

if configuration.extensions.ENABLED:
    RE_EXTENSION_RESOURCE = re.compile("^extension-resource/([a-z0-9][-._a-z0-9]+(?:/[a-z0-9][-._a-z0-9]+)+)$", re.IGNORECASE)

from operation import OperationResult, OperationError, OperationFailureMustLogin

def setContentTypeFromPath(req):
    match = re.search("\\.([a-z]+)", req.path)
    if match:
        req.setContentType(configuration.mimetypes.MIMETYPES.get(match.group(1), "text/plain"))
    else:
        req.setContentType("text/plain")

def handleStaticResource(req):
    resource_path = os.path.join(configuration.paths.INSTALL_DIR,
                                 "resources",
                                 req.path.split("/", 1)[1])
    if os.path.abspath(resource_path) != resource_path:
        raise OperationError("invalid path")
    if not os.path.isfile(resource_path):
        req.setStatus(404)
        req.setContentType("text/plain")
        req.start()
        return ["No such resource!"]
    setContentTypeFromPath(req)
    req.start()
    with open(resource_path, "r") as resource_file:
        return [resource_file.read()]

def download(req, db, user):
    sha1 = req.getParameter("sha1")
    repository = gitutils.Repository.fromParameter(db, req.getParameter("repository", user.getPreference(db, "defaultRepository")))

    setContentTypeFromPath(req)

    return repository.fetch(sha1).data

def watchreview(req, db, user):
    review_id = req.getParameter("review", filter=int)
    user_name = req.getParameter("user")

    cursor = db.cursor()

    user = dbutils.User.fromName(db, user_name)

    cursor.execute("SELECT 1 FROM reviewusers WHERE review=%s AND uid=%s", (review_id, user.id))

    if not cursor.fetchone():
        cursor.execute("INSERT INTO reviewusers (review, uid, type) VALUES (%s, %s, 'manual')", (review_id, user.id))

        cursor.execute("""SELECT uid, include
                            FROM reviewrecipientfilters
                           WHERE review=%s
                             AND (uid=%s OR uid IS NULL)""",
                       (review_id, user.id))

        default_include = True
        user_include = None

        for user_id, include in cursor:
            if user_id is None:
                default_include = include
            else:
                user_include = include

        if not default_include and user_include is None:
            cursor.execute("""INSERT INTO reviewrecipientfilters (review, uid, include)
                                   VALUES (%s, %s, true)""",
                           (review_id, user.id))

        db.commit()

    return "ok"

def unwatchreview(req, db, user):
    review_id = req.getParameter("review", filter=int)
    user_name = req.getParameter("user")

    cursor = db.cursor()

    user = dbutils.User.fromName(db, user_name)

    cursor.execute("SELECT 1 FROM fullreviewuserfiles WHERE review=%s AND assignee=%s", (review_id, user.id))

    if cursor.fetchone():
        return "error:isreviewer"

    cursor.execute("DELETE FROM reviewusers WHERE review=%s AND uid=%s", (review_id, user.id))
    db.commit()

    return "ok"

def setfullname(req, db, user):
    fullname = req.getParameter("fullname")

    cursor = db.cursor()
    cursor.execute("UPDATE users SET fullname=%s WHERE id=%s", (fullname, user.id))

    db.commit()

    return "ok"

def showfilters(req, db, user):
    path = req.getParameter("path", "/")
    repo_name = req.getParameter("repository", None)
    if not repo_name:
        user = req.getParameter("user", req.user)
        if not user:
            raise page.utils.DisplayMessage("The URL must contain either a repository or a user parameter or both.")
        repo_name = dbutils.User.fromName(db, user).getPreference(db, "defaultRepository")
    repository = gitutils.Repository.fromParameter(db, repo_name)

    path = path.rstrip("/")

    if repository.getHead(db).isDirectory(path):
        show_path = path + "/"
        path += "/dummy.txt"
    else:
        show_path = path

    file_id = dbutils.find_file(db, path=path)

    filters = review_filters.Filters()
    filters.setFiles(db, [file_id])
    filters.load(db, repository=repository, recursive=True)

    reviewers = []
    watchers = []

    for user_id, (filter_type, _delegate) in filters.listUsers(file_id).items():
        if filter_type == 'reviewer': reviewers.append(user_id)
        else: watchers.append(user_id)

    result = "Path: %s\n" % show_path

    reviewers_found = False
    watchers_found = False

    for reviewer_id in sorted(reviewers):
        if not reviewers_found:
            result += "\nReviewers:\n"
            reviewers_found = True

        reviewer = dbutils.User.fromId(db, reviewer_id)
        result += "  %s <%s>\n" % (reviewer.fullname, reviewer.email)

    for watcher_id in sorted(watchers):
        if not watchers_found:
            result += "\nWatchers:\n"
            watchers_found = True

        watcher = dbutils.User.fromId(db, watcher_id)
        result += "  %s <%s>\n" % (watcher.fullname, watcher.email)

    if not reviewers_found and not watchers_found:
        result += "\nNo matching filters found.\n"

    return result

def rebasebranch(req, db, user):
    repository = gitutils.Repository.fromParameter(db, req.getParameter("repository", user.getPreference(db, "defaultRepository")))

    branch_name = req.getParameter("name")
    base_name = req.getParameter("base")

    branch = dbutils.Branch.fromName(db, repository, branch_name)
    base = dbutils.Branch.fromName(db, repository, base_name)

    branch.rebase(db, base)

    db.commit()

    return "ok"

def checkserial(req, db, user):
    review_id = req.getParameter("review", filter=int)
    check_serial = req.getParameter("serial", filter=int)

    cursor = db.cursor()
    cursor.execute("SELECT serial FROM reviews WHERE id=%s", (review_id,))

    (current_serial,) = cursor.fetchone()

    req.content_type = "text/plain"

    if check_serial == current_serial: return "current:%d" % user.getPreference(db, "review.updateCheckInterval")
    elif check_serial < current_serial: return "old"
    else: return "invalid"

def findreview(req, db, _user):
    sha1 = req.getParameter("sha1")

    try:
        repository = gitutils.Repository.fromSHA1(db, sha1)
        commit = gitutils.Commit.fromSHA1(db, repository, repository.revparse(sha1))
    except gitutils.GitReferenceError as error:
        raise page.utils.DisplayMessage(error.message)

    cursor = db.cursor()
    cursor.execute("""SELECT reviews.id
                        FROM reviews
                        JOIN branches ON (branches.id=reviews.branch)
                        JOIN reachable ON (reachable.branch=branches.id)
                       WHERE reachable.commit=%s""",
                   (commit.getId(db),))

    row = cursor.fetchone()

    if row:
        review_id = row[0]
    else:
        cursor.execute("""SELECT reviewchangesets.review
                            FROM reviewchangesets
                            JOIN changesets ON (changesets.id=reviewchangesets.changeset)
                           WHERE changesets.child=%s""",
                       (commit.getId(db),))

        row = cursor.fetchone()

        if row:
            review_id = row[0]
        else:
            raise page.utils.DisplayMessage("No review found!")

    raise page.utils.MovedTemporarily("/r/%d?highlight=%s#%s" % (review_id, sha1, sha1))

def suggestreview(req, db, _user):
    repository_id = req.getParameter("repository", filter=int)
    sha1 = req.getParameter("sha1")

    repository = gitutils.Repository.fromId(db, repository_id)
    commit = gitutils.Commit.fromSHA1(db, repository, sha1)

    cursor = db.cursor()
    suggestions = {}

    def addSuggestions():
        for review_id, summary in cursor:
            review = dbutils.Review.fromId(db, review_id, load_commits=False)
            if review.state != 'dropped':
                suggestions[str(review_id)] = "(%s) %s" % (review.getReviewState(db), summary)

    summary = commit.summary()
    while True:
        match = re.search("[A-Z][A-Z0-9]*-[0-9]+", summary)
        if match:
            pattern = "r/%" + match.group(0) + "%"
            cursor.execute("""SELECT reviews.id, reviews.summary
                                FROM reviews
                                JOIN branches ON (reviews.branch=branches.id)
                               WHERE branches.name LIKE %s""",
                           (pattern,))
            addSuggestions()

            summary = summary[match.end():]
        else:
            break

    cursor.execute("""SELECT reviews.id, reviews.summary
                        FROM reviews
                       WHERE reviews.summary=%s""",
                   (commit.summary(),))
    addSuggestions()

    return json_encode(suggestions)

def loadmanifest(req, _db, _user):
    key = req.getParameter("key")

    if "/" in key:
        author_name, extension_name = key.split("/", 1)
    else:
        author_name, extension_name = None, key

    try:
        extension = extensions.extension.Extension(author_name, extension_name)
    except extensions.extension.ExtensionError as error:
        return str(error)

    try:
        extension.getManifest()
        return "That's a valid manifest, friend."
    except extensions.manifest.ManifestError as error:
        return str(error)

def processcommits(req, db, user):
    review_id = req.getParameter("review", filter=int)
    commit_ids = map(int, req.getParameter("commits").split(","))

    review = dbutils.Review.fromId(db, review_id)
    all_commits = [gitutils.Commit.fromId(db, review.repository, commit_id) for commit_id in commit_ids]
    commitset = log_commitset.CommitSet(all_commits)

    heads = commitset.getHeads()
    tails = commitset.getTails()

    if len(heads) != 1:
        return "invalid commit-set; multiple heads"
    if len(tails) != 1:
        return "invalid commit-set; multiple tails"

    old_head = gitutils.Commit.fromSHA1(db, review.repository, tails.pop())
    new_head = heads.pop()

    output = cStringIO.StringIO()

    extensions.role.processcommits.execute(db, user, review, all_commits, old_head, new_head, output)

    return output.getvalue()

OPERATIONS = { "fetchlines": operation.fetchlines.FetchLines(),
               "reviewersandwatchers": operation.createreview.ReviewersAndWatchers(),
               "submitreview": operation.createreview.SubmitReview(),
               "fetchremotebranches": operation.createreview.FetchRemoteBranches(),
               "fetchremotebranch": operation.createreview.FetchRemoteBranch(),
               "validatecommentchain": operation.createcomment.ValidateCommentChain(),
               "createcommentchain": operation.createcomment.CreateCommentChain(),
               "createcomment": operation.createcomment.CreateComment(),
               "reopenresolvedcommentchain": operation.manipulatecomment.ReopenResolvedCommentChain(),
               "reopenaddressedcommentchain": operation.manipulatecomment.ReopenAddressedCommentChain(),
               "resolvecommentchain": operation.manipulatecomment.ResolveCommentChain(),
               "morphcommentchain": operation.manipulatecomment.MorphCommentChain(),
               "updatecomment": operation.manipulatecomment.UpdateComment(),
               "deletecomment": operation.manipulatecomment.DeleteComment(),
               "markchainsasread": operation.manipulatecomment.MarkChainsAsRead(),
               "closereview": operation.manipulatereview.CloseReview(),
               "dropreview": operation.manipulatereview.DropReview(),
               "reopenreview": operation.manipulatereview.ReopenReview(),
               "pingreview": operation.manipulatereview.PingReview(),
               "updatereview": operation.manipulatereview.UpdateReview(),
               "setfullname": operation.manipulateuser.SetFullname(),
               "setgitemails": operation.manipulateuser.SetGitEmails(),
               "changepassword": operation.manipulateuser.ChangePassword(),
               "requestverificationemail": operation.manipulateuser.RequestVerificationEmail(),
               "deleteemailaddress": operation.manipulateuser.DeleteEmailAddress(),
               "selectemailaddress": operation.manipulateuser.SelectEmailAddress(),
               "addemailaddress": operation.manipulateuser.AddEmailAddress(),
               "getassignedchanges": operation.manipulateassignments.GetAssignedChanges(),
               "setassignedchanges": operation.manipulateassignments.SetAssignedChanges(),
               "watchreview": watchreview,
               "unwatchreview": unwatchreview,
               "addreviewfilters": operation.manipulatefilters.AddReviewFilters(),
               "removereviewfilter": operation.manipulatefilters.RemoveReviewFilter(),
               "queryglobalfilters": operation.applyfilters.QueryGlobalFilters(),
               "applyglobalfilters": operation.applyfilters.ApplyGlobalFilters(),
               "queryparentfilters": operation.applyfilters.QueryParentFilters(),
               "applyparentfilters": operation.applyfilters.ApplyParentFilters(),
               "suggestupstreams": operation.rebasereview.SuggestUpstreams(),
               "checkrebase": operation.rebasereview.CheckRebase(),
               "preparerebase": operation.rebasereview.PrepareRebase(),
               "cancelrebase": operation.rebasereview.CancelRebase(),
               "rebasereview": operation.rebasereview.RebaseReview(),
               "revertrebase": operation.rebasereview.RevertRebase(),
               "addfilter": operation.manipulatefilters.AddFilter(),
               "deletefilter": operation.manipulatefilters.DeleteFilter(),
               "reapplyfilters": operation.manipulatefilters.ReapplyFilters(),
               "countmatchedpaths": operation.manipulatefilters.CountMatchedPaths(),
               "getmatchedpaths": operation.manipulatefilters.GetMatchedPaths(),
               "markfiles": operation.markfiles.MarkFiles(),
               "submitchanges": operation.draftchanges.SubmitChanges(),
               "abortchanges": operation.draftchanges.AbortChanges(),
               "reviewstatechange": operation.draftchanges.ReviewStateChange(),
               "savesettings": operation.savesettings.SaveSettings(),
               "showfilters": showfilters,
               "rebasebranch": rebasebranch,
               "checkserial": checkserial,
               "suggestreview": suggestreview,
               "blame": operation.blame.Blame(),
               "checkbranchtext": page.checkbranch.renderCheckBranch,
               "addcheckbranchnote": page.checkbranch.addNote,
               "deletecheckbranchnote": page.checkbranch.deleteNote,
               "addrepository": operation.addrepository.AddRepository(),
               "storeresource": operation.editresource.StoreResource(),
               "resetresource": operation.editresource.ResetResource(),
               "restoreresource": operation.editresource.RestoreResource(),
               "addnewsitem": operation.news.AddNewsItem(),
               "editnewsitem": operation.news.EditNewsItem(),
               "getautocompletedata": operation.autocompletedata.GetAutoCompleteData(),
               "getrepositorypaths": operation.autocompletedata.GetRepositoryPaths(),
               "addrecipientfilter": operation.recipientfilter.AddRecipientFilter(),
               "trackedbranchlog": operation.trackedbranch.TrackedBranchLog(),
               "disabletrackedbranch": operation.trackedbranch.DisableTrackedBranch(),
               "triggertrackedbranchupdate": operation.trackedbranch.TriggerTrackedBranchUpdate(),
               "enabletrackedbranch": operation.trackedbranch.EnableTrackedBranch(),
               "deletetrackedbranch": operation.trackedbranch.DeleteTrackedBranch(),
               "addtrackedbranch": operation.trackedbranch.AddTrackedBranch(),
               "restartservice": operation.servicemanager.RestartService(),
               "getservicelog": operation.servicemanager.GetServiceLog(),
               "checkmergestatus": operation.checkrebase.CheckMergeStatus(),
               "checkconflictsstatus": operation.checkrebase.CheckConflictsStatus(),
               "checkhistoryrewritestatus": operation.checkrebase.CheckHistoryRewriteStatus(),
               "searchreview": operation.searchreview.SearchReview(),
               "registeruser": operation.registeruser.RegisterUser() }

PAGES = { "showreview": page.showreview.renderShowReview,
          "showcommit": page.showcommit.renderShowCommit,
          "dashboard": page.dashboard.renderDashboard,
          "showcomment": page.showcomment.renderShowComment,
          "showcomments": page.showcomment.renderShowComments,
          "showfile": page.showfile.renderShowFile,
          "statistics": page.statistics.renderStatistics,
          "home": page.home.renderHome,
          "config": page.config.renderConfig,
          "branches": page.branches.renderBranches,
          "tutorial": page.tutorial.renderTutorial,
          "news": page.news.renderNews,
          "managereviewers": page.managereviewers.renderManageReviewers,
          "log": page.showbranch.renderShowBranch,
          "checkbranch": page.checkbranch.renderCheckBranch,
          "filterchanges": page.filterchanges.renderFilterChanges,
          "showtree": page.showtree.renderShowTree,
          "findreview": findreview,
          "showbatch": page.showbatch.renderShowBatch,
          "showreviewlog": page.showreviewlog.renderShowReviewLog,
          "createreview": page.createreview.renderCreateReview,
          "newrepository": page.addrepository.renderNewRepository,
          "confirmmerge": page.confirmmerge.renderConfirmMerge,
          "editresource": page.editresource.renderEditResource,
          "search": page.search.renderSearch,
          "repositories": page.repositories.renderRepositories,
          "services": page.services.renderServices,
          "rebasetrackingreview": page.rebasetrackingreview.RebaseTrackingReview(),
          "createuser": page.createuser.CreateUser(),
          "verifyemail": page.verifyemail.renderVerifyEmail,
          "manageextensions": page.manageextensions.renderManageExtensions }

if configuration.extensions.ENABLED:
    import extensions
    import extensions.role.page
    import extensions.role.processcommits
    import operation.extensioninstallation

    OPERATIONS["installextension"] = operation.extensioninstallation.InstallExtension()
    OPERATIONS["uninstallextension"] = operation.extensioninstallation.UninstallExtension()
    OPERATIONS["reinstallextension"] = operation.extensioninstallation.ReinstallExtension()
    OPERATIONS["clearextensionstorage"] = operation.extensioninstallation.ClearExtensionStorage()
    OPERATIONS["loadmanifest"] = loadmanifest
    OPERATIONS["processcommits"] = processcommits

if configuration.base.AUTHENTICATION_MODE != "host" and configuration.base.SESSION_TYPE == "cookie":
    import operation.usersession
    import page.login

    if configuration.base.AUTHENTICATION_MODE == "critic":
        OPERATIONS["validatelogin"] = operation.usersession.ValidateLogin()

    OPERATIONS["endsession"] = operation.usersession.EndSession()
    PAGES["login"] = page.login.Login()

def handleException(db, req, user, as_html=False):
    error_message = traceback.format_exc()
    environ = req.getEnvironment()

    environ["wsgi.errors"].write(error_message)

    if not user or not user.hasRole(db, "developer"):
        url = wsgiref.util.request_uri(environ)

        x_forwarded_host = req.getRequestHeader("X-Forwarded-Host")
        if x_forwarded_host:
            original_host = x_forwarded_host.split(",")[0].strip()
            def replace_host(match):
                return match.group(1) + original_host
            url = re.sub("^([a-z]+://)[^/]+", replace_host, url)

        mailutils.sendExceptionMessage(db,
            "wsgi", "\n".join(["User:   %s" % (req.user or "<anonymous>"),
                               "Method: %s" % req.method,
                               "URL:    %s" % url,
                               "",
                               error_message]))

        admin_message_sent = True
    else:
        admin_message_sent = False

    if not user or user.hasRole(db, "developer") \
            or configuration.debug.IS_DEVELOPMENT \
            or configuration.debug.IS_TESTING:
        error_title = "Unexpected error!"
        error_message = error_message.strip()
        if as_html:
            error_message = "<p class='pre inset'>%s</p>" % htmlify(error_message)
        error_body = [error_message]
        if admin_message_sent:
            admin_message_sent = ("A message has been sent to the system "
                                  "administrator(s) with details about the "
                                  "problem.")
            if as_html:
                admin_message_sent = "<p>%s</p>" % admin_message_sent
            error_body.append(admin_message_sent)
    else:
        error_title = "Request failed!"
        error_message = ("An unexpected error occurred while handling the "
                         "request.  A message has been sent to the system "
                         "administrator(s) with details about the problem.  "
                         "Please contact them for further information and/or "
                         "assistance.")
        if as_html:
            error_message = "<p>%s</p>" % error_message
        error_body = [error_message]

    return error_title, error_body

class WrappedResult(object):
    def __init__(self, db, req, user, result):
        self.db = db
        self.req = req
        self.user = user
        self.result = iter(result)
        # Fetch the first block "prematurely," so that errors from it are raised
        # early, and handled by the normal error handling code in main().
        self.first = self.result.next()
        self.failed = False

    def __iter__(self):
        return self

    def next(self):
        if self.failed:
            raise StopIteration

        try:
            if self.first:
                value = self.first
                self.first = None
            else:
                value = self.result.next()

            self.db.rollback()
            return value
        except StopIteration:
            self.db.close()
            raise
        except Exception:
            error_title, error_body = handleException(
                self.db, self.req, self.user)

            self.db.close()

            if self.req.getContentType().startswith("text/html"):
                self.failed = True

                error_body = "".join("<p>%s</p>" % htmlify(part)
                                     for part in error_body)

                # Close a bunch of tables, in case we're in any.  Not
                # pretty, but probably makes the end result prettier.
                return ("</table></table></table></table></div>"
                        "<div class='fatal'><table align=center><tr>"
                        "<td><h1>%s</h1>%s</td></tr></table></div>"
                        % (error_title, error_body))
            else:
                raise StopIteration

def handleRepositoryPath(db, req, user, suffix):
    if "http" not in configuration.base.REPOSITORY_URL_TYPES:
        return False

    components = req.path.split("/")

    for index in range(1, len(components) + 1):
        repository_path = "/".join(components[:index])
        additional_path = "/".join(components[index:])

        if suffix is not None:
            if not repository_path.endswith(suffix):
                continue

        try:
            repository = gitutils.Repository.fromPath(db, repository_path)
        except gitutils.NoSuchRepository:
            continue
        else:
            db.close()

            try:
                repository.invokeGitHttpBackend(req, user, additional_path)
            except gitutils.GitHttpBackendNeedsUser:
                req.requestHTTPAuthentication()

            return True

    return False

def finishOAuth(db, req, provider):
    try:
        return provider.finish(db, req)
    except (auth.InvalidRequest, auth.Failure):
        _, error_body = handleException(
            db, req, dbutils.User.makeAnonymous(), as_html=True)
        raise page.utils.DisplayMessage(
            title="Authentication failed",
            body="".join(error_body),
            html=True)

def process_request(environ, start_response):
    request_start = time.time()

    db = dbutils.Database()
    user = None

    try:
        try:
            req = request.Request(db, environ, start_response)
            req.setUser(db)

            if req.user is None:
                if configuration.base.AUTHENTICATION_MODE == "host":
                    user = dbutils.User.makeAnonymous()
                elif configuration.base.SESSION_TYPE == "httpauth":
                    req.requestHTTPAuthentication()
                    return []
                elif req.path.startswith("externalauth/"):
                    provider_name = req.path[len("externalauth/"):]
                    raise request.DoExternalAuthentication(provider_name)
                elif req.path.startswith("oauth/"):
                    provider_name = req.path[len("oauth/"):]
                    if provider_name in auth.PROVIDERS:
                        provider = auth.PROVIDERS[provider_name]
                        if isinstance(provider, auth.OAuthProvider):
                            if finishOAuth(db, req, provider):
                                return []
                elif configuration.base.SESSION_TYPE == "cookie":
                    if req.cookies.get("has_sid") == "1":
                        req.ensureSecure()
                    if configuration.base.ALLOW_ANONYMOUS_USER \
                            or req.path in request.INSECURE_PATHS \
                            or req.path.startswith("static-resource/"):
                        user = dbutils.User.makeAnonymous()
                    # Don't try to redirect POST requests to the login page.
                    elif req.method == "GET":
                        if configuration.base.AUTHENTICATION_MODE == "critic":
                            raise request.NeedLogin(req)
                        else:
                            raise request.DoExternalAuthentication(
                                configuration.base.AUTHENTICATION_MODE,
                                req.getTargetURL())
                if not user:
                    req.setStatus(403)
                    req.start()
                    return []
            else:
                try:
                    user = dbutils.User.fromName(db, req.user)
                except dbutils.NoSuchUser:
                    if configuration.base.AUTHENTICATION_MODE == "host":
                        email = getUserEmailAddress(req.user)
                        user = dbutils.User.create(
                            db, req.user, req.user, email, email_verified=None)
                        db.commit()
                    else:
                        # This can't really happen.
                        raise

            user.loadPreferences(db)

            if user.status == 'retired':
                cursor = db.cursor()
                cursor.execute("UPDATE users SET status='current' WHERE id=%s", (user.id,))
                user = dbutils.User.fromId(db, user.id)
                db.commit()

            if not user.getPreference(db, "debug.profiling.databaseQueries"):
                db.disableProfiling()

            if not req.path:
                if user.isAnonymous():
                    location = "tutorial"
                else:
                    location = user.getPreference(db, "defaultPage")

                if req.query:
                    location += "?" + req.query

                req.setStatus(307)
                req.addResponseHeader("Location", location)
                req.start()
                return []

            if req.path == "redirect":
                target = req.getParameter("target", "/")

                if req.method == "POST":
                    # Don't use HTTP redirect for POST requests.

                    req.setContentType("text/html")
                    req.start()

                    return ["<meta http-equiv='refresh' content='0; %s'>" % htmlify(target)]
                else:
                    raise request.MovedTemporarily(target)

            # Require a .git suffix on HTTP(S) repository URLs unless the user-
            # agent starts with "git/" (as Git's normally does.)
            #
            # Our objectives are:
            #
            # 1) Not to require Git's user-agent to be its default value, since
            #    the user might have to override it to get through firewalls.
            # 2) Never to send regular user requests to 'git http-backend' by
            #    mistake.
            #
            # This is a compromise.

            if req.getRequestHeader("User-Agent", "").startswith("git/"):
                suffix = None
            else:
                suffix = ".git"

            if handleRepositoryPath(db, req, user, suffix):
                db = None
                return []

            if req.path.startswith("!/"):
                req.path = req.path[2:]
            elif configuration.extensions.ENABLED:
                handled = extensions.role.page.execute(db, req, user)
                if isinstance(handled, basestring):
                    req.start()
                    return [handled]

            if req.path.startswith("static-resource/"):
                return handleStaticResource(req)

            if req.path.startswith("r/"):
                req.query = "id=" + req.path[2:] + ("&" + req.query if req.query else "")
                req.path = "showreview"

            if configuration.extensions.ENABLED:
                match = RE_EXTENSION_RESOURCE.match(req.path)
                if match:
                    content_type, resource = extensions.resource.get(req, db, user, match.group(1))
                    if resource:
                        req.setContentType(content_type)
                        req.start()
                        return [resource]
                    else:
                        req.setStatus(404)
                        req.start()
                        return []

            if req.path.startswith("download/"):
                operationfn = download
            else:
                operationfn = OPERATIONS.get(req.path)

            if operationfn:
                result = operationfn(req, db, user)

                if isinstance(result, (OperationResult, OperationError)):
                    req.setContentType("text/json")

                    if isinstance(result, OperationResult):
                        if db.profiling:
                            result.set("__profiling__", formatDBProfiling(db))
                            result.set("__time__", time.time() - request_start)
                elif not req.hasContentType():
                    req.setContentType("text/plain")

                req.start()

                if isinstance(result, unicode):
                    return [result.encode("utf8")]
                else:
                    return [str(result)]

            override_user = req.getParameter("user", None)

            while True:
                pagefn = PAGES.get(req.path)
                if pagefn:
                    try:
                        if not user.isAnonymous() and override_user:
                            user = dbutils.User.fromName(db, override_user)

                        req.setContentType("text/html")

                        result = pagefn(req, db, user)

                        if isinstance(result, str) or isinstance(result, Document):
                            req.start()
                            result = str(result)
                            result += ("<!-- total request time: %.2f ms -->"
                                       % ((time.time() - request_start) * 1000))
                            if db.profiling:
                                result += ("<!--\n\n%s\n\n -->"
                                           % formatDBProfiling(db))
                            return [result]
                        else:
                            result = WrappedResult(db, req, user, result)
                            req.start()

                            # Prevent the finally clause below from closing the
                            # connection.  WrappedResult does it instead.
                            db = None

                            return result
                    except gitutils.NoSuchRepository as error:
                        raise page.utils.DisplayMessage(
                            title="Invalid URI Parameter!",
                            body=error.message)
                    except gitutils.GitReferenceError as error:
                        if error.ref:
                            raise page.utils.DisplayMessage(
                                title="Specified ref not found",
                                body=("There is no ref named \"%s\" in %s."
                                      % (error.ref, error.repository)))
                        elif error.sha1:
                            raise page.utils.DisplayMessage(
                                title="SHA-1 not found",
                                body=error.message)
                        else:
                            raise
                    except dbutils.NoSuchUser as error:
                        raise page.utils.DisplayMessage(
                            title="Invalid URI Parameter!",
                            body=error.message)
                    except dbutils.NoSuchReview as error:
                        raise page.utils.DisplayMessage(
                            title="Invalid URI Parameter!",
                            body=error.message)

                path = req.path

                if "/" in path:
                    repository = gitutils.Repository.fromName(db, path.split("/", 1)[0])
                    if repository: path = path.split("/", 1)[1]
                else:
                    repository = None

                def revparsePlain(item):
                    try: return gitutils.getTaggedCommit(repository, repository.revparse(item))
                    except: raise
                revparse = revparsePlain

                if repository is None:
                    review_id = req.getParameter("review", None, filter=int)

                    if review_id:
                        cursor = db.cursor()
                        cursor.execute("""SELECT repository
                                            FROM branches
                                            JOIN reviews ON (reviews.branch=branches.id)
                                           WHERE reviews.id=%s""",
                                       (review_id,))
                        row = cursor.fetchone()
                        if row:
                            repository = gitutils.Repository.fromId(db, row[0])
                            def revparseWithReview(item):
                                if re.match("^[0-9a-f]+$", item):
                                    cursor.execute("""SELECT sha1
                                                        FROM commits
                                                        JOIN changesets ON (changesets.child=commits.id)
                                                        JOIN reviewchangesets ON (reviewchangesets.changeset=changesets.id)
                                                       WHERE reviewchangesets.review=%s
                                                         AND commits.sha1 LIKE %s""",
                                                   (review_id, item + "%"))
                                    row = cursor.fetchone()
                                    if row: return row[0]
                                    else: return revparsePlain(item)
                            revparse = revparseWithReview

                if repository is None:
                    repository = gitutils.Repository.fromName(
                        db, user.getPreference(db, "defaultRepository"))

                    if gitutils.re_sha1.match(path):
                        if repository and not repository.iscommit(path):
                            repository = None

                        if not repository:
                            try:
                                repository = gitutils.Repository.fromSHA1(db, path)
                            except gitutils.GitReferenceError:
                                repository = None

                if repository:
                    try:
                        items = filter(None, map(revparse, path.split("..")))
                        query = None

                        if len(items) == 1:
                            query = ("repository=%d&sha1=%s"
                                     % (repository.id, items[0]))
                        elif len(items) == 2:
                            query = ("repository=%d&from=%s&to=%s"
                                     % (repository.id, items[0], items[1]))

                        if query:
                            if req.query:
                                query += "&" + req.query

                            req.query = query
                            req.path = "showcommit"
                            continue
                    except gitutils.GitReferenceError:
                        pass

                break

            req.setStatus(404)
            raise page.utils.DisplayMessage(
                title="Not found!",
                body="Page not handled: /%s" % path)
        except GeneratorExit:
            raise
        except page.utils.NotModified:
            req.setStatus(304)
            req.start()
            return []
        except request.MovedTemporarily as redirect:
            req.setStatus(307)
            req.addResponseHeader("Location", redirect.location)
            if redirect.no_cache:
                req.addResponseHeader("Cache-Control", "no-cache")
            req.start()
            return []
        except request.DoExternalAuthentication as command:
            command.execute(db, req)
            return []
        except request.MissingWSGIRemoteUser as error:
            # req object is not initialized yet.
            start_response("200 OK", [("Content-Type", "text/html")])
            return ["""\
<pre>error: Critic was configured with '--auth-mode host' but there was no
REMOTE_USER variable in the WSGI environ dict provided by the web server.

To fix this you can either reinstall Critic using '--auth-mode critic' (to let
Critic handle user authentication automatically), or you can configure user
authentication properly in the web server.  For apache2, the latter can be done
by adding the something like the following to the apache site configuration for
Critic:

        &lt;Location /&gt;
                AuthType Basic
                AuthName "Authentication Required"
                AuthUserFile "/path/to/critic-main.htpasswd.users"
                Require valid-user
        &lt;/Location&gt;

If you need more dynamic http authentication you can instead setup mod_wsgi with
a custom WSGIAuthUserScript directive.  This will cause the provided credentials
to be passed to a Python function called check_password() that you can implement
yourself.  This way you can validate the user/pass via any existing database or
for example an LDAP server.  For more information on setting up such
authentication in apache2, see:

  <a href="%(url)s">%(url)s</a></pre>""" % { "url": "http://code.google.com/p/modwsgi/wiki/AccessControlMechanisms#Apache_Authentication_Provider" }]
        except page.utils.DisplayMessage as message:
            if user is None:
                user = dbutils.User.makeAnonymous()

            document = page.utils.displayMessage(
                db, req, user, title=message.title, message=message.body,
                review=message.review, is_html=message.html)

            req.setContentType("text/html")
            req.start()

            return [str(document)]
        except:
            # crash might be psycopg2.ProgrammingError so rollback to avoid
            # "InternalError: current transaction is aborted" inside handleException()
            db.rollback()
            error_title, error_body = handleException(db, req, user)
            error_body = reflow("\n\n".join(error_body))
            error_message = "\n".join([error_title,
                                       "=" * len(error_title),
                                       "",
                                       error_body])

            assert not req.isStarted()

            req.setStatus(500)
            req.setContentType("text/plain")
            req.start()

            return [error_message]
    finally:
        if db:
            db.close()

if configuration.debug.COVERAGE_DIR:
    def main(environ, start_response):
        import coverage

        def do_process_request(environ, start_response):
            # Apply list() to force the request to be fully performed by this
            # call.  It might return an iterator whose .next() does all the
            # work, and if we just return that from here, the actual work is not
            # subject to coverage measurement.
            return list(process_request(environ, start_response))

        return coverage.call("wsgi", do_process_request, environ, start_response)
else:
    main = process_request

########NEW FILE########
__FILENAME__ = dbaccess
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2012 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import psycopg2

def connect():
    import configuration
    return psycopg2.connect(**configuration.database.PARAMETERS)

IntegrityError = psycopg2.IntegrityError
ProgrammingError = psycopg2.ProgrammingError
TransactionRollbackError = psycopg2.extensions.TransactionRollbackError

########NEW FILE########
__FILENAME__ = branch
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2012 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

class Branch(object):
    def __init__(self, id, repository, name, head, base, tail, branch_type, review_id):
        self.id = id
        self.repository = repository
        self.name = name
        self.head = head
        self.base = base
        self.tail = tail
        self.type = branch_type
        self.review_id = review_id
        self.review = None
        self.commits = None

    def __eq__(self, other):
        return self.id == other.id

    def __ne__(self, other):
        return self.id != other.id

    def contains(self, db, commit):
        import gitutils
        cursor = db.cursor()
        if isinstance(commit, gitutils.Commit) and commit.id is not None:
            cursor.execute("SELECT 1 FROM reachable WHERE branch=%s AND commit=%s", [self.id, commit.id])
        else:
            cursor.execute("SELECT 1 FROM reachable, commits WHERE branch=%s AND commit=id AND sha1=%s", [self.id, str(commit)])
        return cursor.fetchone() is not None

    def getHead(self, db):
        import gitutils
        if not self.head:
            cursor = db.cursor()
            cursor.execute("""SELECT commits.id, commits.sha1
                                FROM commits
                                JOIN branches ON (commits.id=branches.head)
                               WHERE branches.id=%s""",
                           (self.id,))
            head_id, head_sha1 = cursor.fetchone()
            self.head = gitutils.Commit.fromSHA1(db, self.repository, head_sha1, head_id)
        return self.head

    def getJSConstructor(self):
        from htmlutils import jsify
        if self.base:
            return "new Branch(%d, %s, %s)" % (self.id, jsify(self.name), self.base.getJSConstructor())
        else:
            return "new Branch(%d, %s, null)" % (self.id, jsify(self.name))

    def getJS(self):
        return "var branch = %s;" % self.getJSConstructor()

    def loadCommits(self, db):
        import gitutils
        if self.commits is None:
            cursor = db.cursor()
            cursor.execute("SELECT commits.id, commits.sha1 FROM reachable, commits WHERE reachable.branch=%s AND reachable.commit=commits.id", [self.id])
            self.commits = []
            for commit_id, sha1 in cursor:
                self.commits.append(gitutils.Commit.fromSHA1(db, self.repository, sha1, commit_id=commit_id))
            cursor.execute("SELECT commits.id, commits.sha1 FROM branches, commits WHERE branches.id=%s AND branches.head=commits.id", [self.id])
            commit_id, sha1 = cursor.fetchone()
            self.head = gitutils.Commit.fromSHA1(db, self.repository, sha1, commit_id=commit_id)
            cursor.execute("SELECT commits.id, commits.sha1 FROM branches, commits WHERE branches.id=%s AND branches.tail=commits.id", [self.id])
            row = cursor.fetchone()
            if row:
                commit_id, sha1 = row
                self.tail = gitutils.Commit.fromSHA1(db, self.repository, sha1, commit_id=commit_id)

    def rebase(self, db, base):
        import gitutils

        cursor = db.cursor()

        def findReachable(head, base_branch_id, force_include=set()):
            bases = [base_branch_id]

            while True:
                cursor.execute("SELECT base FROM branches WHERE id=%s", (bases[-1],))
                branch_id = cursor.fetchone()[0]
                if branch_id is None: break
                bases.append(branch_id)

            expression = "SELECT 1 FROM reachable, commits WHERE branch IN (%s) AND commit=id AND sha1=%%s" % ", ".join(["%s"] * len(bases))

            def exclude(sha1):
                cursor.execute(expression, bases + [sha1])
                return cursor.fetchone() is not None

            stack = [head.sha1]
            processed = set()
            values = []

            while stack:
                sha1 = stack.pop(0)

                if sha1 not in processed:
                    processed.add(sha1)

                    commit = gitutils.Commit.fromSHA1(db, self.repository, sha1)

                    if sha1 in force_include or not exclude(sha1):
                        values.append(commit.getId(db))

                        for sha1 in commit.parents:
                            if sha1 not in processed and (sha1 in force_include or not exclude(sha1)):
                                stack.append(sha1)

            return values

        cursor.execute("SELECT COUNT(*) FROM reachable WHERE branch=%s", (self.id,))
        old_count = cursor.fetchone()[0]

        if base.base and base.base.id == self.id:
            self.loadCommits(db)

            cursor.execute("SELECT count(*) FROM reachable WHERE branch=%s", (base.id,))
            base_old_count = cursor.fetchone()[0]

            base_reachable = findReachable(base.head, self.base.id, set([commit.sha1 for commit in self.commits]))
            base_new_count = len(base_reachable)

            cursor.execute("DELETE FROM reachable WHERE branch=%s", [base.id])
            cursor.executemany("INSERT INTO reachable (branch, commit) VALUES (%s, %s)", [(base.id, commit) for commit in base_reachable])
            cursor.execute("UPDATE branches SET base=%s WHERE id=%s", [self.base.id, base.id])

            base.base = self.base
            base.commits = None
        else:
            base_old_count = None
            base_new_count = None

        our_reachable = findReachable(self.head, base.id)
        new_count = len(our_reachable)

        cursor.execute("DELETE FROM reachable WHERE branch=%s", [self.id])
        cursor.executemany("INSERT INTO reachable (branch, commit) VALUES (%s, %s)", [(self.id, commit) for commit in our_reachable])
        cursor.execute("UPDATE branches SET base=%s WHERE id=%s", [base.id, self.id])

        self.base = base
        self.commits = None

        return old_count, new_count, base_old_count, base_new_count

    @staticmethod
    def fromId(db, branch_id, load_review=False, load_commits=True, profiler=None):
        import gitutils

        cursor = db.cursor()
        cursor.execute("SELECT name, repository, head, base, tail, branches.type, review, reviews.id IS NOT NULL FROM branches LEFT OUTER JOIN reviews ON (branches.id=reviews.branch) WHERE branches.id=%s", [branch_id])
        row = cursor.fetchone()

        if not row: return None
        else:
            branch_name, repository_id, head_commit_id, base_branch_id, tail_commit_id, type, review_id, has_review = row

            if profiler: profiler.check("Branch.fromId: basic")

            repository = gitutils.Repository.fromId(db, repository_id)

            if profiler: profiler.check("Branch.fromId: repository")

            if load_commits:
                try: head_commit = gitutils.Commit.fromId(db, repository, head_commit_id)
                except: head_commit = None

                if profiler: profiler.check("Branch.fromId: head")
            else:
                head_commit = None

            if load_commits:
                base_branch = Branch.fromId(db, base_branch_id) if base_branch_id is not None else None

                if profiler: profiler.check("Branch.fromId: base")

                tail_commit = gitutils.Commit.fromId(db, repository, tail_commit_id) if tail_commit_id is not None else None

                if profiler: profiler.check("Branch.fromId: tail")
            else:
                base_branch = None
                tail_commit = None

            branch = Branch(branch_id, repository, branch_name, head_commit, base_branch, tail_commit, type, review_id)

            if has_review and load_review:
                from dbutils import Review

                branch.review = Review.fromBranch(db, branch)

                if profiler: profiler.check("Branch.fromId: review")

            return branch

    @staticmethod
    def fromName(db, repository, name):
        cursor = db.cursor()
        cursor.execute("SELECT id FROM branches WHERE repository=%s AND name=%s", (repository.id, name))
        row = cursor.fetchone()
        if not row: return None
        else: return Branch.fromId(db, row[0])

########NEW FILE########
__FILENAME__ = database
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2012 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import time
import dbaccess

from dbutils.session import Session

class InvalidCursorError(Exception):
    pass

class Database(Session):
    class Cursor(object):
        class Iterator(object):
            def __init__(self, base):
                self.__base = base
                self.__invalid = False

            def next(self):
                if self.__invalid:
                    raise InvalidCursorError("cursor re-used during iteration")
                return self.__base.next()

            def invalidate(self):
                self.__invalid = True

        def __init__(self, db, cursor, profiling):
            self.__db = db
            self.__cursor = cursor
            self.__profiling = profiling is not None
            self.__rows = None
            self.__iterators = []

        def __iter__(self):
            if not self.__profiling:
                return iter(self.__cursor)
            else:
                iterator = Database.Cursor.Iterator(iter(self.__rows))
                self.__iterators.append(iterator)
                return iterator

        def __getitem__(self, index):
            if not self.__profiling:
                return self.__cursor[index]
            else:
                return self.__rows[index]

        def fetchone(self):
            if not self.__profiling:
                return self.__cursor.fetchone()
            elif self.__rows:
                row = self.__rows[0]
                self.__rows = self.__rows[1:]
                return row
            else:
                return None

        def fetchall(self):
            if not self.__profiling:
                return self.__cursor.fetchall()
            else:
                return self.__rows

        def execute(self, query, params=None):
            if not self.__profiling:
                self.__cursor.execute(query, params)
            else:
                map(Database.Cursor.Iterator.invalidate, self.__iterators)
                self.__iterators = []
                before = time.time()
                self.__cursor.execute(query, params)
                try:
                    self.__rows = self.__cursor.fetchall()
                except dbaccess.ProgrammingError:
                    self.__rows = None
                after = time.time()
                self.__db.recordProfiling(query, after - before, rows=len(self.__rows) if self.__rows else 0)

        def executemany(self, query, params):
            if self.__profiling is None:
                self.__cursor.executemany(query, params)
            else:
                before = time.time()
                params = list(params)
                self.__cursor.executemany(query, params)
                after = time.time()
                self.__db.recordProfiling(query, after - before, repetitions=len(params))

        def mogrify(self, *args):
            return self.__cursor.mogrify(*args)

    def __init__(self):
        super(Database, self).__init__()
        self.__connection = dbaccess.connect()

    def cursor(self):
        return Database.Cursor(self, self.__connection.cursor(), self.profiling)

    def commit(self):
        before = time.time()
        self.__connection.commit()
        after = time.time()
        self.recordProfiling("<commit>", after - before, 0)

    def rollback(self):
        before = time.time()
        self.__connection.rollback()
        after = time.time()
        self.recordProfiling("<rollback>", after - before, 0)

    def close(self):
        super(Database, self).close()
        if self.__connection:
            self.__connection.rollback()
            self.__connection.close()
            self.__connection = None

    def __enter__(self):
        return self

    def __exit__(self, *args):
        self.close()
        return False

########NEW FILE########
__FILENAME__ = paths
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2012 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

class InvalidFileId(Exception):
    def __init__(self, file_id):
        super(InvalidFileId, self).__init__("Invalid file id: %d" % file_id)

class InvalidPath(Exception):
    pass

class File(object):
    def __init__(self, file_id, path):
        self.id = file_id
        self.path = path

    def __int__(self):
        return self.id
    def __str__(self):
        return self.path

    @staticmethod
    def fromId(db, file_id):
        return File(file_id, describe_file(db, file_id))

    @staticmethod
    def fromPath(db, path, insert=True):
        file_id = find_file(db, path, insert)
        if file_id is None:
            # Only happens when insert=False.
            raise InvalidPath("Path does not exist: %s" % path)
        return File(file_id, path)

def find_file(db, path, insert=True):
    path = path.lstrip("/")

    if path.endswith("/"):
        raise InvalidPath("Trailing path separator: %r" % path)

    cursor = db.cursor()
    cursor.execute("SELECT id, path FROM files WHERE MD5(path)=MD5(%s)", (path,))

    row = cursor.fetchone()

    if row:
        file_id, found_path = row
        assert path == found_path, "MD5 collision in files table: %r != %r" % (path, found_path)
        return file_id

    if insert:
        cursor.execute("INSERT INTO files (path) VALUES (%s) RETURNING id", (path,))
        return cursor.fetchone()[0]

    return None

def find_files(db, files):
    for file in files:
        file.id = find_file(db, file.path)

def describe_file(db, file_id):
    cursor = db.cursor()
    cursor.execute("SELECT path FROM files WHERE id=%s", (file_id,))
    row = cursor.fetchone()
    if not row:
        raise InvalidFileId(file_id)
    return row[0]

########NEW FILE########
__FILENAME__ = review
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2012 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import time

import base

def countDraftItems(db, user, review):
    cursor = db.cursor()

    cursor.execute("SELECT reviewfilechanges.to, SUM(deleted) + SUM(inserted) FROM reviewfiles JOIN reviewfilechanges ON (reviewfilechanges.file=reviewfiles.id) WHERE reviewfiles.review=%s AND reviewfilechanges.uid=%s AND reviewfilechanges.state='draft' GROUP BY reviewfilechanges.to", (review.id, user.id))

    reviewed = unreviewed = 0

    for to_state, lines in cursor:
        if to_state == "reviewed": reviewed = lines
        else: unreviewed = lines

    cursor.execute("SELECT reviewfilechanges.to, COUNT(*) FROM reviewfiles JOIN reviewfilechanges ON (reviewfilechanges.file=reviewfiles.id) WHERE reviewfiles.review=%s AND reviewfiles.deleted=0 AND reviewfiles.inserted=0 AND reviewfilechanges.uid=%s AND reviewfilechanges.state='draft' GROUP BY reviewfilechanges.to", (review.id, user.id))

    reviewedBinary = unreviewedBinary = 0

    for to_state, lines in cursor:
        if to_state == "reviewed": reviewedBinary = lines
        else: unreviewedBinary = lines

    cursor.execute("SELECT count(*) FROM commentchains, comments WHERE commentchains.review=%s AND comments.chain=commentchains.id AND comments.uid=%s AND comments.state='draft'", [review.id, user.id])
    comments = cursor.fetchone()[0]

    cursor.execute("""SELECT DISTINCT commentchains.id
                        FROM commentchains
                        JOIN commentchainchanges ON (commentchainchanges.chain=commentchains.id)
                       WHERE commentchains.review=%s
                         AND commentchainchanges.uid=%s
                         AND commentchainchanges.state='draft'
                         AND ((commentchains.state=commentchainchanges.from_state
                           AND commentchainchanges.from_state IN ('addressed', 'closed')
                           AND commentchainchanges.to_state='open')
                          OR (commentchainchanges.from_addressed_by IS NOT NULL
                           AND commentchainchanges.to_addressed_by IS NOT NULL))""",
                   [review.id, user.id])
    reopened = len(cursor.fetchall())

    cursor.execute("""SELECT count(*) FROM commentchains, commentchainchanges
                       WHERE commentchains.review=%s
                         AND commentchains.state='open'
                         AND commentchainchanges.chain=commentchains.id
                         AND commentchainchanges.uid=%s
                         AND commentchainchanges.state='draft'
                         AND commentchainchanges.from_state='open'
                         AND commentchainchanges.to_state='closed'""",
                   [review.id, user.id])
    closed = cursor.fetchone()[0]

    cursor.execute("""SELECT count(*) FROM commentchains, commentchainchanges
                       WHERE commentchains.review=%s
                         AND commentchainchanges.chain=commentchains.id
                         AND commentchainchanges.uid=%s
                         AND commentchainchanges.state='draft'
                         AND commentchainchanges.from_type=commentchains.type
                         AND commentchainchanges.to_type!=commentchains.type""",
                   [review.id, user.id])
    morphed = cursor.fetchone()[0]

    return { "reviewedNormal": reviewed,
             "unreviewedNormal": unreviewed,
             "reviewedBinary": reviewedBinary,
             "unreviewedBinary": unreviewedBinary,
             "writtenComments": comments,
             "reopenedIssues": reopened,
             "resolvedIssues": closed,
             "morphedChains": morphed }

class NoSuchReview(base.Error):
    def __init__(self, review_id):
        super(NoSuchReview, self).__init__("No such review: r/%d" % review_id)
        self.id = review_id

class ReviewState(object):
    def __init__(self, review, accepted, pending, reviewed, issues):
        self.review = review
        self.accepted = accepted
        self.pending = pending
        self.reviewed = reviewed
        self.issues = issues

    def getPercentReviewed(self):
        if self.pending + self.reviewed:
            return 100.0 * self.reviewed / (self.pending + self.reviewed)
        else:
            return 50.0

    def getProgress(self):
        if self.pending + self.reviewed == 0:
            return "?? %"
        percent = self.getPercentReviewed()
        if int(percent) > 0 and (percent < 99.0 or percent == 100.0):
            return "%d %%" % int(percent)
        elif percent > 0:
            precision = 1
            while precision < 10:
                progress = ("%%.%df" % precision) % percent
                if progress[-1] != '0': break
                precision += 1
            return progress + " %"
        else:
            return "No progress"

    def getIssues(self):
        if self.issues: return "%d issue%s" % (self.issues, "s" if self.issues > 1 else "")
        else: return ""

    def __str__(self):
        if self.review.state == 'dropped': return "Dropped..."
        elif self.review.state == 'closed': return "Finished!"
        elif self.accepted: return "Accepted!"
        else:
            progress = self.getProgress()
            issues = self.getIssues()
            if issues: return "%s and %s" % (progress, issues)
            else: return progress

class ReviewRebase(object):
    def __init__(self, review, old_head, new_head, old_upstream, new_upstream, user):
        self.review = review
        self.old_head = old_head
        self.new_head = new_head
        self.old_upstream = old_upstream
        self.new_upstream = new_upstream
        self.user = user

class ReviewRebases(list):
    def __init__(self, db, review):
        import gitutils
        from dbutils import User

        self.__old_head_map = {}
        self.__new_head_map = {}

        cursor = db.cursor()
        cursor.execute("""SELECT old_head, new_head, old_upstream, new_upstream, uid
                            FROM reviewrebases
                           WHERE review=%s
                             AND new_head IS NOT NULL""",
                       (review.id,))

        for old_head_id, new_head_id, old_upstream_id, new_upstream_id, user_id in cursor:
            old_head = gitutils.Commit.fromId(db, review.repository, old_head_id)
            new_head = gitutils.Commit.fromId(db, review.repository, new_head_id)

            if old_upstream_id is not None and new_upstream_id is not None:
                old_upstream = gitutils.Commit.fromId(db, review.repository, old_upstream_id)
                new_upstream = gitutils.Commit.fromId(db, review.repository, new_upstream_id)
            else:
                old_upstream = new_upstream = None

            user = User.fromId(db, user_id)
            rebase = ReviewRebase(review, old_head, new_head, old_upstream, new_upstream, user)

            self.append(rebase)
            self.__old_head_map[old_head] = rebase
            self.__new_head_map[new_head] = rebase

        if review.performed_rebase:
            self.__old_head_map[review.performed_rebase.old_head] = review.performed_rebase
            self.__new_head_map[review.performed_rebase.new_head] = review.performed_rebase

    def fromOldHead(self, commit):
        return self.__old_head_map.get(commit)

    def fromNewHead(self, commit):
        return self.__new_head_map.get(commit)

class ReviewTrackedBranch(object):
    def __init__(self, review, trackedbranch_id, remote, name, disabled):
        self.id = trackedbranch_id
        self.review = review
        self.remote = remote
        self.name = name
        self.disabled = disabled

class Review(object):
    def __init__(self, review_id, owners, review_type, branch, state, serial, summary, description, applyfilters, applyparentfilters):
        self.id = review_id
        self.owners = owners
        self.type = review_type
        self.repository = branch.repository
        self.branch = branch
        self.state = state
        self.serial = serial
        self.summary = summary
        self.description = description
        self.reviewers = []
        self.watchers = {}
        self.changesets = []
        self.commentchains = None
        self.applyfilters = applyfilters
        self.applyparentfilters = applyparentfilters
        self.filters = None
        self.relevant_files = None
        self.draft_status = None
        self.performed_rebase = None

    @staticmethod
    def isAccepted(db, review_id):
        cursor = db.cursor()

        cursor.execute("SELECT 1 FROM reviewfiles WHERE review=%s AND state='pending' LIMIT 1", (review_id,))
        if cursor.fetchone(): return False

        cursor.execute("SELECT 1 FROM commentchains WHERE review=%s AND type='issue' AND state='open' LIMIT 1", (review_id,))
        if cursor.fetchone(): return False

        return True

    def accepted(self, db):
        if self.state != 'open': return False
        else: return Review.isAccepted(db, self.id)

    def getReviewState(self, db):
        cursor = db.cursor()

        cursor.execute("""SELECT state, SUM(deleted) + SUM(inserted)
                            FROM reviewfiles
                           WHERE reviewfiles.review=%s
                        GROUP BY state""",
                       (self.id,))

        pending = 0
        reviewed = 0

        for state, count in cursor.fetchall():
            if state == "pending": pending = count
            else: reviewed = count

        cursor.execute("""SELECT count(id)
                            FROM commentchains
                           WHERE review=%s
                             AND type='issue'
                             AND state='open'""",
                       (self.id,))

        issues = cursor.fetchone()[0]

        return ReviewState(self, self.accepted(db), pending, reviewed, issues)

    def setPerformedRebase(self, old_head, new_head, old_upstream, new_upstream, user):
        self.performed_rebase = ReviewRebase(self, old_head, new_head, old_upstream, new_upstream, user)

    def getReviewRebases(self, db):
        return ReviewRebases(db, self)

    def getTrackedBranch(self, db):
        cursor = db.cursor()
        cursor.execute("""SELECT trackedbranches.id, remote, remote_name, disabled
                            FROM trackedbranches
                            JOIN branches ON (trackedbranches.repository=branches.repository
                                          AND trackedbranches.local_name=branches.name)
                            JOIN reviews ON (branches.id=reviews.branch)
                           WHERE reviews.id=%s""",
                       (self.id,))

        for trackedbranch_id, remote, name, disabled in cursor:
            return ReviewTrackedBranch(self, trackedbranch_id, remote, name, disabled)

    def getCommitSet(self, db):
        import gitutils
        import log.commitset

        cursor = db.cursor()
        cursor.execute("""SELECT DISTINCT commits.id, commits.sha1
                            FROM commits
                            JOIN changesets ON (changesets.child=commits.id)
                            JOIN reviewchangesets ON (reviewchangesets.changeset=changesets.id)
                           WHERE reviewchangesets.review=%s""",
                       (self.id,))

        commits = []

        for commit_id, commit_sha1 in cursor:
            commits.append(gitutils.Commit.fromSHA1(db, self.repository, commit_sha1, commit_id))

        return log.commitset.CommitSet(commits)

    def containsCommit(self, db, commit, include_head_and_tails=False, include_actual_log=False):
        import gitutils

        commit_id = None
        commit_sha1 = None

        if isinstance(commit, gitutils.Commit):
            commit_id = commit.id
            commit_sha1 = commit.sha1
        elif isinstance(commit, str):
            commit_sha1 = self.repository.revparse(commit)
            commit = None
        elif isinstance(commit, int):
            commit_id = commit
            commit = None
        else:
            raise TypeError

        cursor = db.cursor()

        if commit_id is not None:
            cursor.execute("""SELECT 1
                                FROM reviewchangesets
                                JOIN changesets ON (id=changeset)
                               WHERE reviewchangesets.review=%s
                                 AND changesets.child=%s
                                 AND changesets.type!='conflicts'""",
                           (self.id, commit_id))
        else:
            cursor.execute("""SELECT 1
                                FROM reviewchangesets
                                JOIN changesets ON (changesets.id=reviewchangesets.changeset)
                                JOIN commits ON (commits.id=changesets.child)
                               WHERE reviewchangesets.review=%s
                                 AND changesets.type!='conflicts'
                                 AND commits.sha1=%s""",
                           (self.id, commit_sha1))

        if cursor.fetchone() is not None:
            return True

        if include_head_and_tails:
            head_and_tails = set([self.branch.head])

            commitset = self.getCommitSet(db)

            if commitset:
                head_and_tails |= commitset.getTails()

            if commit_sha1 is None:
                if commit is None:
                    commit = gitutils.Commit.fromId(db, self.repository, commit_id)
                commit_sha1 = commit.sha1

            if commit_sha1 in head_and_tails:
                return True

        if include_actual_log:
            if commit_id is not None:
                cursor.execute("""SELECT 1
                                    FROM reachable
                                    JOIN branches ON (branches.id=reachable.branch)
                                    JOIN reviews ON (reviews.branch=branches.id)
                                   WHERE reachable.commit=%s
                                     AND reviews.id=%s""",
                               (commit_id, self.id))
            else:
                cursor.execute("""SELECT 1
                                    FROM commits
                                    JOIN reachable ON (reachable.commit=commits.id)
                                    JOIN branches ON (branches.id=reachable.branch)
                                    JOIN reviews ON (reviews.branch=branches.id)
                                   WHERE commits.sha1=%s
                                     AND reviews.id=%s""",
                               (commit_sha1, self.id))

            if cursor.fetchone() is not None:
                return True

        return False

    def getJS(self):
        return "var review = critic.review = { id: %d, branch: { id: %d, name: %r }, owners: [ %s ], serial: %d };" % (self.id, self.branch.id, self.branch.name, ", ".join(owner.getJSConstructor() for owner in self.owners), self.serial)

    def getETag(self, db, user=None):
        import configuration

        cursor = db.cursor()
        etag = ""

        if configuration.debug.IS_DEVELOPMENT:
            cursor.execute("SELECT installed_at FROM systemidentities WHERE name=%s", (configuration.base.SYSTEM_IDENTITY,))
            installed_at = cursor.fetchone()[0]
            etag += "install%s." % time.mktime(installed_at.timetuple())

        if user and not user.isAnonymous():
            etag += "user%d." % user.id

        etag += "review%d.serial%d" % (self.id, self.serial)

        if user:
            items = self.getDraftStatus(db, user)
            if any(items.values()):
                etag += ".draft%d" % hash(tuple(sorted(items.items())))

            cursor.execute("SELECT id FROM reviewrebases WHERE review=%s AND uid=%s AND new_head IS NULL", (self.id, user.id))
            row = cursor.fetchone()
            if row:
                etag += ".rebase%d" % row[0]

        return '"%s"' % etag

    def getURL(self, db, user=None, indent=0, separator="\n"):
        import dbutils

        indent = " " * indent

        if user:
            url_prefixes = user.getCriticURLs(db)
        else:
            url_prefixes = [dbutils.getURLPrefix(db)]

        return separator.join(["%s%s/r/%d" % (indent, url_prefix, self.id) for url_prefix in url_prefixes])

    def getRecipients(self, db):
        from dbutils import User

        cursor = db.cursor()
        cursor.execute("SELECT uid, include FROM reviewrecipientfilters WHERE review=%s", (self.id,))

        default_include = True
        included = set(owner.id for owner in self.owners)
        excluded = set()

        for uid, include in cursor:
            if uid is None:
                default_include = include
            elif include:
                included.add(uid)
            elif uid not in self.owners:
                excluded.add(uid)

        cursor.execute("SELECT uid FROM reviewusers WHERE review=%s", (self.id,))

        recipients = []
        for (user_id,) in cursor:
            if user_id in excluded:
                continue
            elif user_id not in included and not default_include:
                continue

            user = User.fromId(db, user_id)
            if user.status != "retired":
                recipients.append(user)

        return recipients

    def getDraftStatus(self, db, user):
        if self.draft_status is None:
            self.draft_status = countDraftItems(db, user, self)
        return self.draft_status

    def incrementSerial(self, db):
        self.serial += 1
        db.cursor().execute("UPDATE reviews SET serial=%s WHERE id=%s", [self.serial, self.id])

    def close(self, db, user):
        self.serial += 1
        db.cursor().execute("UPDATE reviews SET state='closed', serial=%s, closed_by=%s WHERE id=%s", (self.serial, user.id, self.id))

    def drop(self, db, user):
        self.serial += 1
        db.cursor().execute("UPDATE reviews SET state='dropped', serial=%s, closed_by=%s WHERE id=%s", (self.serial, user.id, self.id))

    def reopen(self, db, user):
        self.serial += 1
        db.cursor().execute("UPDATE reviews SET state='open', serial=%s, closed_by=NULL WHERE id=%s", (self.serial, self.id))

    def disableTracking(self, db):
        db.cursor().execute("UPDATE trackedbranches SET disabled=TRUE WHERE repository=%s AND local_name=%s", (self.repository.id, self.branch.name))

    def setSummary(self, db, summary):
        self.serial += 1
        self.summary = summary
        db.cursor().execute("UPDATE reviews SET summary=%s, serial=%s WHERE id=%s", [self.summary, self.serial, self.id])

    def setDescription(self, db, description):
        self.serial += 1
        self.description = description
        db.cursor().execute("UPDATE reviews SET description=%s, serial=%s WHERE id=%s", [self.description, self.serial, self.id])

    def addOwner(self, db, owner):
        if not owner in self.owners:
            self.serial += 1
            self.owners.append(owner)

            cursor = db.cursor()
            cursor.execute("SELECT 1 FROM reviewusers WHERE review=%s AND uid=%s", (self.id, owner.id))

            if cursor.fetchone():
                cursor.execute("UPDATE reviewusers SET owner=TRUE WHERE review=%s AND uid=%s", (self.id, owner.id))
            else:
                cursor.execute("INSERT INTO reviewusers (review, uid, owner) VALUES (%s, %s, TRUE)", (self.id, owner.id))

            cursor.execute("SELECT id FROM trackedbranches WHERE repository=%s AND local_name=%s", (self.repository.id, self.branch.name))

            row = cursor.fetchone()
            if row:
                trackedbranch_id = row[0]
                cursor.execute("INSERT INTO trackedbranchusers (branch, uid) VALUES (%s, %s)", (trackedbranch_id, owner.id))

    def removeOwner(self, db, owner):
        if owner in self.owners:
            self.serial += 1
            self.owners.remove(owner)

            cursor = db.cursor()
            cursor.execute("UPDATE reviewusers SET owner=FALSE WHERE review=%s AND uid=%s", (self.id, owner.id))
            cursor.execute("SELECT id FROM trackedbranches WHERE repository=%s AND local_name=%s", (self.repository.id, self.branch.name))

            row = cursor.fetchone()
            if row:
                trackedbranch_id = row[0]
                cursor.execute("DELETE FROM trackedbranchusers WHERE branch=%s AND uid=%s", (trackedbranch_id, owner.id))

    def getReviewFilters(self, db):
        cursor = db.cursor()
        cursor.execute("SELECT uid, path, type, NULL FROM reviewfilters WHERE review=%s", (self.id,))
        return cursor.fetchall() or None

    def getFilteredTails(self):
        import log.commitset
        commitset = log.commitset.CommitSet(self.branch.commits)
        return commitset.getFilteredTails(self.branch.repository)

    def getRelevantFiles(self, db, user):
        if not self.filters:
            from reviewing.filters import Filters

            self.filters = Filters()
            self.filters.setFiles(db, review=self)
            self.filters.load(db, review=self)
            self.relevant_files = self.filters.getRelevantFiles()

            cursor = db.cursor()
            cursor.execute("SELECT assignee, file FROM fullreviewuserfiles WHERE review=%s", (self.id,))
            for user_id, file_id in cursor:
                self.relevant_files.setdefault(user_id, set()).add(file_id)

        return self.relevant_files.get(user.id, set())

    def getUserAssociation(self, db, user):
        cursor = db.cursor()

        association = []

        if user in self.owners:
            association.append("owner")

        cursor.execute("""SELECT 1
                            FROM reviewchangesets
                            JOIN changesets ON (changesets.id=reviewchangesets.changeset)
                            JOIN commits ON (commits.id=changesets.child)
                            JOIN gitusers ON (gitusers.id=commits.author_gituser)
                            JOIN usergitemails USING (email)
                           WHERE reviewchangesets.review=%s
                             AND usergitemails.uid=%s""",
                       (self.id, user.id))
        if cursor.fetchone():
            association.append("author")

        cursor.execute("SELECT COUNT(*) FROM fullreviewuserfiles WHERE review=%s AND assignee=%s", (self.id, user.id))
        if cursor.fetchone()[0] != 0:
            association.append("reviewer")
        elif user not in self.owners:
            cursor.execute("SELECT 1 FROM reviewusers WHERE review=%s AND uid=%s", (self.id, user.id))
            if cursor.fetchone():
                association.append("watcher")

        if not association:
            association.append("none")

        return ", ".join(association)

    @staticmethod
    def fromId(db, review_id, branch=None, load_commits=True, profiler=None):
        from dbutils import User

        cursor = db.cursor()
        cursor.execute("SELECT type, branch, state, serial, summary, description, applyfilters, applyparentfilters FROM reviews WHERE id=%s", [review_id])
        row = cursor.fetchone()
        if not row: raise NoSuchReview(review_id)

        type, branch_id, state, serial, summary, description, applyfilters, applyparentfilters = row

        if profiler: profiler.check("Review.fromId: basic")

        if branch is None:
            from dbutils import Branch
            branch = Branch.fromId(db, branch_id, load_review=False, load_commits=load_commits, profiler=profiler)

        cursor.execute("SELECT uid FROM reviewusers WHERE review=%s AND owner", (review_id,))

        owners = User.fromIds(db, [user_id for (user_id,) in cursor])

        if profiler: profiler.check("Review.fromId: owners")

        review = Review(review_id, owners, type, branch, state, serial, summary, description, applyfilters, applyparentfilters)
        branch.review = review

        # Reviewers: all users that have at least one review file assigned to them.
        cursor.execute("""SELECT DISTINCT uid, assignee IS NOT NULL, type
                            FROM reviewusers
                 LEFT OUTER JOIN fullreviewuserfiles ON (fullreviewuserfiles.review=reviewusers.review AND assignee=uid)
                           WHERE reviewusers.review=%s""",
                       (review_id,))

        reviewers = []
        watchers = []
        watcher_types = {}

        for user_id, is_reviewer, user_type in cursor.fetchall():
            if is_reviewer:
                reviewers.append(user_id)
            elif user_id not in review.owners:
                watchers.append(user_id)
                watcher_types[user_id] = user_type

        review.reviewers = User.fromIds(db, reviewers)

        for watcher in User.fromIds(db, watchers):
            review.watchers[watcher] = watcher_types[watcher]

        if profiler: profiler.check("Review.fromId: users")

        if load_commits:
            review.branch.loadCommits(db)

            cursor.execute("""SELECT id
                                FROM reviewchangesets
                                JOIN changesets ON (id=changeset)
                               WHERE review=%s
                                 AND child=ANY (%s)""", (review_id, [commit.id for commit in review.branch.commits]))

            review.changesets = [changeset_id for (changeset_id,) in cursor.fetchall()]

            if profiler: profiler.check("Review.fromId: load commits")

        return review

    @staticmethod
    def fromBranch(db, branch):
        if branch:
            cursor = db.cursor()
            cursor.execute("SELECT id FROM reviews WHERE branch=%s", [branch.id])
            row = cursor.fetchone()
            if not row: return None
            else: return Review.fromId(db, row[0], branch)
        else:
            return None

    @staticmethod
    def fromName(db, repository, name):
        from dbutils import Branch
        return Review.fromBranch(db, Branch.fromName(db, repository, name))

    @staticmethod
    def fromArgument(db, argument):
        try:
            return Review.fromId(db, int(argument))
        except:
            from dbutils import Branch
            branch = Branch.fromName(db, str(argument))
            if not branch: return None
            return Review.fromBranch(db, branch)

########NEW FILE########
__FILENAME__ = session
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2012 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

class Session(object):
    def __init__(self):
        self.__atexit = []
        self.storage = { "Repository": {},
                         "User": {},
                         "Commit": {},
                         "CommitUserTime": {},
                         "Timezones": {} }
        self.profiling = {}

    def atexit(self, fn):
        self.__atexit.append(fn)

    def close(self):
        for fn in self.__atexit:
            try: fn(self)
            except: pass
        self.__atexit = []

    def disableProfiling(self):
        self.profiling = None

    def recordProfiling(self, item, duration, rows=None, repetitions=1):
        if self.profiling is not None:
            count, accumulated_ms, maximum_ms, accumulated_rows, maximum_rows = self.profiling.get(item, (0, 0.0, 0.0, None, None))

            count += repetitions
            accumulated_ms += 1000 * duration
            maximum_ms = max(maximum_ms, 1000 * duration)

            if rows is not None:
                if accumulated_rows is None: accumulated_rows = 0
                if maximum_rows is None: maximum_rows = 0
                accumulated_rows += rows
                maximum_rows = max(maximum_rows, rows)

            self.profiling[item] = count, accumulated_ms, maximum_ms, accumulated_rows, maximum_rows

########NEW FILE########
__FILENAME__ = system
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2013 Martin Olsson
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

def getInstalledSHA1(db):
    import configuration
    cursor = db.cursor()
    cursor.execute("SELECT installed_sha1 FROM systemidentities WHERE name=%s",
                   (configuration.base.SYSTEM_IDENTITY,))
    return cursor.fetchone()[0]

def getURLPrefix(db, user=None):
    import configuration
    cursor = db.cursor()
    cursor.execute("""SELECT anonymous_scheme, authenticated_scheme, hostname
                        FROM systemidentities
                       WHERE name=%s""",
                   (configuration.base.SYSTEM_IDENTITY,))
    anonymous_scheme, authenticated_scheme, hostname = cursor.fetchone()
    if user and not user.isAnonymous():
        scheme = authenticated_scheme
    else:
        scheme = anonymous_scheme
    return "%s://%s" % (scheme, hostname)

def getAdministratorContacts(db, indent=0, as_html=False):
    import dbutils
    administrators = dbutils.User.withRole(db, "administrator")

    # Sort by id, IOW, by user creation time.  Probably gives "primary"
    # administrator first and auxiliary administrators second, but might also
    # just be arbitrary.  If nothing else, it makes the order stable.
    administrators = sorted(administrators, key=lambda user: user.id)

    # Skip administrators with no email addresses, since those are unhelpful in
    # this context.
    administrators = filter(lambda user: user.email, administrators)

    if as_html:
        result = "the system administrator"

        if not administrators:
            return result
        if len(administrators) > 1:
            result += "s"

        result += " (%s)"

        mailto_links = \
            [("<a href='mailto:%(email)s'>%(fullname)s</a>"
              % { "email": user.email, "fullname": user.fullname })
             for user in administrators]

        if len(mailto_links) == 1:
            return result % mailto_links[0]
        else:
            return result % ("one of %s or %s" % (", ".join(mailto_links[:-1]),
                                                  mailto_links[-1]))
    else:
        if not administrators:
            return ""

        administrators = ["%s <%s>" % (user.fullname, user.email)
                          for user in administrators]

        prefix = " " * indent
        return prefix + ("\n" + prefix).join(administrators)

########NEW FILE########
__FILENAME__ = timezones
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2012 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import time
import datetime

def loadTimezones(db):
    """
    Insert (interesting) timezones from 'pg_timezone_names' into 'timezones'

    The 'pg_timezone_names' table contains all the information we want (but
    typically unnecessarily many different timezones) but is very slow to query,
    so can't be used during normal operations.
    """

    cursor = db.cursor()
    cursor.execute("DELETE FROM timezones")

    def add(name, abbrev, utc_offset):
        cursor.execute("""INSERT INTO timezones (name, abbrev, utc_offset)
                               VALUES (%s, %s, %s)""",
                       (name, abbrev, utc_offset))

    add("Universal/UTC", "UTC", datetime.timedelta())

    cursor.execute("SELECT name, abbrev, utc_offset FROM pg_timezone_names")
    for full_name, abbrev, utc_offset in cursor.fetchall():
        region, _, name = full_name.partition("/")
        if region not in ("posix", "Etc") and name and "/" not in name:
            add(full_name, abbrev, utc_offset)

    db.commit()

def updateTimezones(db):
    """
    Update UTC offses in 'timezones' with values in 'pg_timezone_names'

    The UTC offsets in 'pg_timezone_names' are DST adjusted (for the timezones
    we care about) so we need to copy the values regularly to keep the cached
    values in 'timezones' up-to-date.
    """

    cursor = db.cursor()
    cursor.execute("""UPDATE timezones
                         SET utc_offset=pg_timezone_names.utc_offset
                        FROM pg_timezone_names
                       WHERE pg_timezone_names.name=timezones.name""")
    db.commit()

def __fetchTimezones(db):
    groups = db.storage["Timezones"].get(None, {})

    if not groups:
        cursor = db.cursor()
        cursor.execute("SELECT name, abbrev, utc_offset FROM timezones")

        for full_name, abbrev, utc_offset in cursor.fetchall():
            group, name = full_name.split("/")
            groups.setdefault(group, {})[name] = (abbrev, utc_offset)

        db.storage["Timezones"][None] = groups

    return groups

def sortedTimezones(db):
    groups = __fetchTimezones(db)
    result = []

    for key in sorted(groups.keys()):
        result.append((key, sorted([(name, abbrev, utc_offset) for name, (abbrev, utc_offset) in groups[key].items()])))

    return result

def __fetchUTCOffset(db, timezone):
    utc_offset = db.storage["Timezones"].get(timezone)

    if utc_offset is None:
        groups = db.storage["Timezones"].get(None)

        if groups:
            group, name = timezone.split("/")
            utc_offset = groups[group][name][2]
        else:
            cursor = db.cursor()
            cursor.execute("SELECT utc_offset FROM timezones WHERE name=%s", (timezone,))

            row = cursor.fetchone()
            if row:
                utc_offset = row[0]
            else:
                return 0

        db.storage["Timezones"][timezone] = utc_offset

    return utc_offset

def adjustTimestamp(db, timestamp, timezone):
    return timestamp + __fetchUTCOffset(db, timezone)

def formatTimestamp(db, timestamp, timezone):
    utc_offset = __fetchUTCOffset(db, timezone)
    seconds = utc_offset.total_seconds()
    offset = " %s%02d:%02d" % ("-" if seconds < 0 else "+", seconds / 3600, (seconds % 3600) / 60)

    return time.strftime("%Y-%m-%d %H:%M", (timestamp + utc_offset).timetuple()) + offset

def validTimezone(db, timezone):
    cursor = db.cursor()
    cursor.execute("SELECT 1 FROM timezones WHERE name=%s", (timezone,))
    return bool(cursor.fetchone())

########NEW FILE########
__FILENAME__ = unittest
import sys
import os

def independence():
    # Simply check that dbutils can be imported.  This is run in a test flagged
    # as "local" since we want dbutils to be possible to import in standalone
    # unit tests.
    #
    # Hardly anything in dbutils can actually be used, of course, but that's not
    # a problem; the unit tests simply need to make sure not to depend on that.

    import dbutils

if __name__ == "__main__":
    # sys.path[0] is the directory containing this file.
    sys.path[0] = os.path.dirname(sys.path[0])

    if "independence" in sys.argv[1:]:
        independence()

########NEW FILE########
__FILENAME__ = user
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2012 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import os
import base

def _preferenceCacheKey(item, repository, filter_id):
    cache_key = item
    if filter_id is not None:
        cache_key += ":f%d" % filter_id
    if repository is not None:
        cache_key += ":r%d" % repository.id
    return cache_key

class InvalidUserId(base.Error):
    def __init__(self, user_id):
        super(InvalidUserId, self).__init__("Invalid user id: %d" % user_id)
        self.user_id = user_id

class NoSuchUser(base.Error):
    def __init__(self, name):
        super(NoSuchUser, self).__init__("No such user: %s" % name)
        self.name = name

class User(object):
    def __init__(self, user_id, name, fullname, status, email, email_verified):
        self.id = user_id
        self.name = name
        self.email = email
        self.email_verified = email_verified
        self.fullname = fullname
        self.status = status
        self.preferences = {}
        self.__resources = {}

    def __eq__(self, other):
        if self.isAnonymous(): return False
        elif isinstance(other, User):
            if other.isAnonymous(): return False
            else: return self.id == other.id
        elif isinstance(other, int):
            return self.id == other
        elif isinstance(other, basestring):
            return self.name == other
        else:
            raise base.Error("invalid comparison")

    def __ne__(self, other):
        return not (self == other)

    def __int__(self):
        assert not self.isAnonymous()
        return self.id

    def __str__(self):
        assert not self.isAnonymous()
        return self.name

    def __repr__(self):
        return "User(%r, %r, %r, %r)" % (self.id, self.name, self.email, self.fullname)

    def __hash__(self):
        return hash(self.id)

    def isAnonymous(self):
        return self.status == 'anonymous'

    def hasRole(self, db, role):
        cursor = db.cursor()
        cursor.execute("SELECT 1 FROM userroles WHERE uid=%s AND role=%s", (self.id, role))
        return bool(cursor.fetchone())

    def loadPreferences(self, db):
        if not self.preferences:
            cursor = db.cursor()
            cursor.execute("""SELECT item, type, integer, string
                                FROM preferences
                                JOIN userpreferences USING (item)
                               WHERE (uid=%s OR uid IS NULL)
                                 AND repository IS NULL
                                 AND filter IS NULL
                            ORDER BY uid NULLS LAST""",
                           (self.id,))

            for item, preference_type, integer, string in cursor:
                cache_key = _preferenceCacheKey(item, None, None)
                if cache_key not in self.preferences:
                    if preference_type == "boolean":
                        self.preferences[cache_key] = bool(integer)
                    elif preference_type == "integer":
                        self.preferences[cache_key] = integer
                    else:
                        self.preferences[cache_key] = string

    @staticmethod
    def fetchPreference(db, item, user=None, repository=None, filter_id=None):
        cursor = db.cursor()
        cursor.execute("SELECT type FROM preferences WHERE item=%s", (item,))
        row = cursor.fetchone()
        if not row:
            raise base.ImplementationError("invalid preference: %s" % item)
        preference_type = row[0]

        arguments = [item]
        where = ["item=%s"]
        order_by = []

        if preference_type in ("boolean", "integer"):
            value_column = "integer"
        else:
            value_column = "string"

        if user is not None and not user.isAnonymous():
            arguments.append(user.id)
            where.append("uid=%s OR uid IS NULL")
            order_by.append("uid NULLS LAST")
        else:
            where.append("uid IS NULL")

        if repository is not None:
            arguments.append(repository.id)
            where.append("repository=%s OR repository IS NULL")
            order_by.append("repository NULLS LAST")
        else:
            where.append("repository IS NULL")

        if filter_id is not None:
            arguments.append(filter_id)
            where.append("filter=%s OR filter IS NULL")
            order_by.append("filter NULLS LAST")
        else:
            where.append("filter IS NULL")

        query = ("""SELECT %(value_column)s
                      FROM userpreferences
                     WHERE %(where)s"""
                 % { "value_column": value_column,
                     "where": " AND ".join("(%s)" % condition
                                           for condition in where) })

        if order_by:
            query += " ORDER BY " + ", ".join(order_by)

        query += " LIMIT 1"

        cursor.execute(query, arguments)
        row = cursor.fetchone()
        if not row:
            raise base.ImplementationError(
                "invalid preference read: %s (no value found)" % item)
        (value,) = row
        if preference_type == "boolean":
            return bool(value)
        return value

    @staticmethod
    def storePreference(db, item, value, user=None, repository=None, filter_id=None):
        # A preference value can be set for either a repository or a filter, but
        # not for both at the same time.  A filter implies a repository anyway,
        # so there would be no point.
        assert repository is None or filter_id is None
        assert filter_id is None or user is not None

        # If all are None, we'd be deleting the global default and not setting a
        # new one, which would be bad.
        if value is None and user is None \
                and repository is None and filter is None:
            raise base.ImplementationError("attempted to delete global default")

        if User.fetchPreference(db, item, user, repository, filter_id) != value:
            cursor = db.cursor()

            arguments = [item]
            where = ["item=%s"]

            user_id = repository_id = None

            if user is not None:
                user_id = user.id
                arguments.append(user_id)
                where.append("uid=%s")
            else:
                where.append("uid IS NULL")

            if repository is not None:
                repository_id = repository.id
                arguments.append(repository_id)
                where.append("repository=%s")
            else:
                where.append("repository IS NULL")

            if filter_id is not None:
                arguments.append(filter_id)
                where.append("filter=%s")
            else:
                where.append("filter IS NULL")

            query = ("DELETE FROM userpreferences WHERE %s"
                     % (" AND ".join("(%s)" % condition
                                     for condition in where)))

            cursor.execute(query, arguments)

            if value is not None:
                cursor.execute("SELECT type FROM preferences WHERE item=%s", (item,))

                (value_type,) = cursor.fetchone()
                integer = string = None

                if value_type == "boolean":
                    value = bool(value)
                    integer = int(value)
                elif value_type == "integer":
                    integer = int(value)
                else:
                    string = str(value)

                cursor.execute("""INSERT INTO userpreferences (item, uid, repository, filter, integer, string)
                                       VALUES (%s, %s, %s, %s, %s, %s)""",
                               (item, user_id, repository_id, filter_id, integer, string))

            if user is not None:
                cache_key = _preferenceCacheKey(item, repository, filter_id)
                if cache_key in user.preferences:
                    del user.preferences[cache_key]

            return True
        else:
            return False

    def getPreference(self, db, item, repository=None, filter_id=None):
        cache_key = _preferenceCacheKey(item, repository, filter_id)

        if cache_key not in self.preferences:
            self.preferences[cache_key] = User.fetchPreference(
                db, item, self, repository, filter_id)

        return self.preferences[cache_key]

    def setPreference(self, db, item, value, repository=None, filter_id=None):
        return User.storePreference(db, item, value, self, repository, filter_id)

    def getDefaultRepository(self, db):
        import gitutils

        default_repo = self.getPreference(db, "defaultRepository")
        if not default_repo:
            cursor = db.cursor()
            cursor.execute("SELECT COUNT(*) FROM repositories")

            repo_count = cursor.fetchone()[0]
            if repo_count == 1:
                cursor.execute("SELECT name FROM repositories")
                default_repo = cursor.fetchone()[0]

        return gitutils.Repository.fromName(db, default_repo)

    def getResource(self, db, name):
        import configuration

        if name in self.__resources:
            return self.__resources[name]

        cursor = db.cursor()
        cursor.execute("SELECT revision, source FROM userresources WHERE uid=%s AND name=%s ORDER BY revision DESC FETCH FIRST ROW ONLY", (self.id, name))

        row = cursor.fetchone()

        if row and row[1] is not None:
            resource = self.__resources[name] = ("\"critic.rev.%d\"" % row[0], row[1])
            return resource

        path = os.path.join(configuration.paths.INSTALL_DIR, "resources", name)
        mtime = os.stat(path).st_mtime

        resource = self.__resources[name] = ("\"critic.mtime.%d\"" % mtime, open(path).read())
        return resource

    def adjustTimestamp(self, db, timestamp):
        import dbutils.timezones
        return dbutils.timezones.adjustTimestamp(db, timestamp, self.getPreference(db, "timezone"))

    def formatTimestamp(self, db, timestamp):
        import dbutils.timezones
        return dbutils.timezones.formatTimestamp(db, timestamp, self.getPreference(db, "timezone"))

    def getCriticURLs(self, db):
        url_types = self.getPreference(db, 'email.urlType').split(",")

        cursor = db.cursor()
        cursor.execute("""SELECT key, anonymous_scheme, authenticated_scheme, hostname
                            FROM systemidentities""")

        url_prefixes = dict((row[0], row[1:]) for row in cursor)
        urls = []

        for url_type in url_types:
            if url_prefixes.has_key(url_type):
                anonymous_scheme, authenticated_scheme, hostname = url_prefixes[url_type]
                if self.isAnonymous():
                    scheme = anonymous_scheme
                else:
                    scheme = authenticated_scheme
                urls.append("%s://%s" % (scheme, hostname))

        return urls

    def getFirstName(self):
        return self.fullname.split(" ")[0]

    def getJSConstructor(self, db=None):
        from htmlutils import jsify
        if self.isAnonymous():
            return "new User(null, null, null, null, null, { ui: {} })"
        if db:
            options = ("{ ui: { keyboardShortcuts: %s, resolveIssueWarning: %s, convertIssueToNote: %s, asynchronousReviewMarking: %s } }" %
                       ("true" if self.getPreference(db, "ui.keyboardShortcuts") else "false",
                        "true" if self.getPreference(db, "ui.resolveIssueWarning") else "false",
                        "true" if self.getPreference(db, "ui.convertIssueToNote") else "false",
                        "true" if self.getPreference(db, "ui.asynchronousReviewMarking") else "false"))
        else:
            options = "{ ui: {} }"
        return "new User(%d, %s, %s, %s, %s, %s)" % (self.id, jsify(self.name), jsify(self.email), jsify(self.fullname), jsify(self.status), options)

    def getJS(self, db=None, name="user"):
        return "var %s = %s;" % (name, self.getJSConstructor(db))

    def getJSON(self):
        return { "id": self.id,
                 "name": self.name,
                 "email": self.email,
                 "displayName": self.fullname }

    def getAbsence(self, db):
        cursor = db.cursor()
        cursor.execute("SELECT until FROM userabsence WHERE uid=%s", (self.id,))
        row = cursor.fetchone()
        if row[0] is None:
            return "absent"
        else:
            return "absent until %04d-%02d-%02d" % (row[0].year, row[0].month, row[0].day)

    def hasGitEmail(self, db, address):
        cursor = db.cursor()
        cursor.execute("""SELECT 1
                            FROM usergitemails
                           WHERE email=%s
                             AND uid=%s""",
                       (address, self.id))
        return bool(cursor.fetchone())

    @staticmethod
    def cache(db, user):
        storage = db.storage["User"]
        storage[user.id] = user
        if user.name: storage["n:" + user.name] = user
        if user.email: storage["e:" + user.email] = user
        return user

    @staticmethod
    def makeAnonymous():
        return User(None, None, None, 'anonymous', None, None)

    @staticmethod
    def _fromQuery(db, where, *values):
        cursor = db.cursor()
        cursor.execute("""SELECT users.id, name, fullname, status,
                                 useremails.email, verified
                            FROM users
                 LEFT OUTER JOIN useremails ON (useremails.id=users.email)
                           """ + where,
                       values)
        return [User.cache(db, User(*row)) for row in cursor]

    @staticmethod
    def fromId(db, user_id):
        cached_user = db.storage["User"].get(user_id)
        if cached_user:
            return cached_user
        else:
            found = User._fromQuery(db, "WHERE users.id=%s", user_id)
            if not found:
                raise InvalidUserId(user_id)
            return found[0]

    @staticmethod
    def fromIds(db, user_ids):
        need_fetch = []
        cache = db.storage["User"]
        for user_id in user_ids:
            if user_id not in cache:
                need_fetch.append(user_id)
        if need_fetch:
            User._fromQuery(db, "WHERE users.id=ANY (%s)", need_fetch)
        return [cache.get(user_id) for user_id in user_ids]

    @staticmethod
    def fromName(db, name):
        cached_user = db.storage["User"].get("n:" + name)
        if cached_user:
            return cached_user
        else:
            found = User._fromQuery(db, "WHERE users.name=%s", name)
            if not found:
                raise NoSuchUser(name)
            return found[0]

    @staticmethod
    def withRole(db, role):
        cursor = db.cursor()
        cursor.execute("""SELECT uid
                            FROM userroles
                           WHERE role=%s""",
                       (role,))
        return User.fromIds(db, [user_id for user_id, in cursor])

    @staticmethod
    def create(db, name, fullname, email, email_verified, password=None, status="current"):
        cursor = db.cursor()
        cursor.execute("""INSERT INTO users (name, fullname, password, status)
                               VALUES (%s, %s, %s, %s)
                            RETURNING id""",
                       (name, fullname, password, status))
        user_id = cursor.fetchone()[0]
        if email is not None:
            cursor.execute("""INSERT INTO useremails (uid, email, verified)
                                   VALUES (%s, %s, %s)
                                RETURNING id""",
                           (user_id, email, email_verified))
            email_id = cursor.fetchone()[0]
            cursor.execute("UPDATE users SET email=%s WHERE id=%s",
                           (email_id, user_id))
            cursor.execute("""INSERT INTO usergitemails (email, uid)
                                   VALUES (%s, %s)""",
                           (email, user_id))
        return User.fromId(db, user_id)

    def sendUserCreatedMail(self, source, external=None):
        import mailutils

        if self.email_verified is False:
            email_status = " (pending verification)"
        else:
            email_status = ""

        message = """\
A new user has been created:

User name: %(username)r
Full name: %(fullname)r
Email:     %(email)r%(email_status)s
""" % { "username": self.name,
        "fullname": self.fullname,
        "email": self.email,
        "email_status": email_status }

        if external:
            import auth

            provider = auth.PROVIDERS[external["provider"]]
            message += """\

External:  %(provider)s %(account)r
""" % { "provider": provider.getTitle(),
        "account": external["account"] }

        message += """\

-- critic
"""

        mailutils.sendAdministratorMessage(
            source, "User '%s' registered" % self.name, message)

########NEW FILE########
__FILENAME__ = analyze
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2012 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import difflib
import re

import textutils

re_ignore = re.compile("^\\s*(?:[{}*]|else|do|\\*/)?\\s*$")
re_words = re.compile("([0-9]+|[A-Z][a-z]+|[A-Z]+|[a-z]+|[\\[\\]{}()]|\\s+|.)")
re_ws = re.compile("\\s+")
re_conflict = re.compile("^<<<<<<< .*$|^=======$|^>>>>>>> .*$")

def analyzeChunk(deletedLines, insertedLines, moved=False):
    # Pure delete or pure insert, nothing to analyze.
    if not deletedLines or not insertedLines: return None

    deletedLines = map(textutils.decode, deletedLines)
    insertedLines = map(textutils.decode, insertedLines)

    # Large chunk, analysis would be expensive, so skip it.
    if len(deletedLines) * len(insertedLines) <= 10000 and not moved:
        analysis = analyzeChunk1(deletedLines, insertedLines)
    else:
        deletedLinesNoWS = [re_ws.sub(" ", line.strip()) for line in deletedLines]
        insertedLinesNoWS = [re_ws.sub(" ", line.strip()) for line in insertedLines]

        sm = difflib.SequenceMatcher(None, deletedLinesNoWS, insertedLinesNoWS)
        blocks = sm.get_matching_blocks()

        analysis = []

        pi = 0
        pj = 0

        for i, j, n in blocks:
            if not n: continue

            if i > pi and j > pj:
                analysis.append(analyzeChunk1(deletedLines[pi:i], insertedLines[pj:j],
                                              offsetA=pi, offsetB=pj))

            analysis.append(analyzeWhiteSpaceChanges(deletedLines[i:i+n], insertedLines[j:j+n],
                                                     offsetA=i, offsetB=j, full=moved))

            pi = i + n
            pj = j + n

        if pi < len(deletedLines) and pj < len(insertedLines):
            analysis.append(analyzeChunk1(deletedLines[pi:], insertedLines[pj:],
                                          offsetA=pi, offsetB=pj))

        analysis = ";".join(filter(None, analysis))

    if analysis: return analysis
    else: return None

def analyzeChunk1(deletedLines, insertedLines, offsetA=0, offsetB=0):
    matches = []
    equals = []

    if len(deletedLines) * len(insertedLines) > 10000: return ""

    def ratio(sm, a, b, aLength, bLength):
        matching = 0
        for i, j, n in sm.get_matching_blocks():
            matching += sum(map(len, map(unicode.strip, a[i:i+n])))
        if aLength > 5 and len(sm.get_matching_blocks()) == 2:
            return float(matching) / aLength
        else:
            return 2.0 * matching / (aLength + bLength)

    for deletedIndex, deleted in enumerate(deletedLines):
        deletedStripped = deleted.strip()
        deletedNoWS = re_ws.sub("", deletedStripped)

        # Don't match conflict lines against anything.
        if re_conflict.match(deleted): continue

        if not re_ignore.match(deleted):
            deletedWords = re_words.findall(deleted)

            for insertedIndex, inserted in enumerate(insertedLines):
                insertedStripped = inserted.strip()
                insertedNoWS = re_ws.sub("", insertedStripped)

                if not re_ignore.match(inserted):
                    insertedWords = re_words.findall(inserted)
                    sm = difflib.SequenceMatcher(None, deletedWords, insertedWords)
                    r = ratio(sm, deletedWords, insertedWords, len(deletedNoWS), len(insertedNoWS))
                    if r > 0.5: matches.append((r, deletedIndex, insertedIndex, deletedWords, insertedWords, sm))
                elif deletedStripped == insertedStripped:
                    equals.append((deletedIndex, insertedIndex))
        else:
            for insertedIndex, inserted in enumerate(insertedLines):
                if deletedStripped == inserted.strip():
                    equals.append((deletedIndex, insertedIndex))

    if matches:
        matches.sort(key=lambda x: x[0], reverse=True)

        final = []

        while matches:
            r, deletedIndex, insertedIndex, deletedWords, insertedWords, sm = matches.pop(0)
            final.append((deletedIndex, insertedIndex, deletedWords, insertedWords, sm))
            matches = filter(lambda data: data[1] != deletedIndex and data[2] != insertedIndex and (data[1] < deletedIndex) == (data[2] < insertedIndex), matches)
            equals = filter(lambda data: (data[0] < deletedIndex) == (data[1] < insertedIndex), equals)

        final.sort()
        equals.sort()
        result = []

        previousDeletedIndex = -1
        previousInsertedIndex = -1

        final.append((len(deletedLines), len(insertedLines), None, None, None))

        for deletedIndex, insertedIndex, deletedWords, insertedWords, sm in final:
            while equals and (equals[0][0] < deletedIndex or equals[0][1] < insertedIndex):
                di, ii = equals.pop(0)
                if previousDeletedIndex < di < deletedIndex and previousInsertedIndex < ii < insertedIndex:
                    deletedLine = deletedLines[di]
                    insertedLine = insertedLines[ii]
                    lineDiff = analyzeWhiteSpaceLine(deletedLine, insertedLine)
                    if lineDiff: result.append("%d=%d:ws,%s" % (di + offsetA, ii + offsetB, lineDiff))
                    else: result.append("%d=%d" % (di + offsetA, ii + offsetB))
                    previousDeletedIndex = di
                    previousInsertedIndex = ii
                while equals and (di == equals[0][0] or ii == equals[0][1]): equals.pop(0)

            if sm is None: break

            lineDiff = []
            deletedLine = deletedLines[deletedIndex]
            insertedLine = insertedLines[insertedIndex]
            if deletedLine != insertedLine and deletedLine.strip() == insertedLine.strip():
                lineDiff.append("ws")
                lineDiff.append(analyzeWhiteSpaceLine(deletedLine, insertedLine))
            else:
                for tag, i1, i2, j1, j2 in sm.get_opcodes():
                    if tag == 'replace': lineDiff.append("r%d-%d=%d-%d" % (offsetInLine(deletedWords, i1), offsetInLine(deletedWords, i2), offsetInLine(insertedWords, j1), offsetInLine(insertedWords, j2)))
                    elif tag == 'delete': lineDiff.append("d%d-%d" % (offsetInLine(deletedWords, i1), offsetInLine(deletedWords, i2)))
                    elif tag == 'insert': lineDiff.append("i%d-%d" % (offsetInLine(insertedWords, j1), offsetInLine(insertedWords, j2)))
            if lineDiff:
                result.append("%d=%d:%s" % (deletedIndex + offsetA, insertedIndex + offsetB, ",".join(lineDiff)))
            else:
                result.append("%d=%d" % (deletedIndex + offsetA, insertedIndex + offsetB))

            previousDeletedIndex = deletedIndex
            previousInsertedIndex = insertedIndex

        return ";".join(result)
    elif deletedLines[-1] == insertedLines[-1]:
        ndeleted = len(deletedLines)
        ninserted = len(insertedLines)
        result = []
        index = 1

        while index <= ndeleted and index <= ninserted and deletedLines[-index] == insertedLines[-index]:
            result.append("%d=%d" % (ndeleted - index + offsetA, ninserted - index + offsetB))
            index += 1

        return ";".join(reversed(result))
    else:
        return ""

def offsetInLine(words, offset):
    return sum(map(lambda word: len(word.encode("utf-8")), words[0:offset]))

re_ws_words = re.compile("( |\t|\\s+|\\S+)")

def analyzeWhiteSpaceLine(deletedLine, insertedLine):
    deletedLine = textutils.decode(deletedLine)
    insertedLine = textutils.decode(insertedLine)

    deletedWords = filter(None, re_ws_words.findall(deletedLine))
    insertedWords = filter(None, re_ws_words.findall(insertedLine))

    sm = difflib.SequenceMatcher(None, deletedWords, insertedWords)
    lineDiff = []

    for tag, i1, i2, j1, j2 in sm.get_opcodes():
        if tag == 'replace':
            lineDiff.append("r%d-%d=%d-%d" % (offsetInLine(deletedWords, i1),
                                              offsetInLine(deletedWords, i2),
                                              offsetInLine(insertedWords, j1),
                                              offsetInLine(insertedWords, j2)))
        elif tag == 'delete':
            lineDiff.append("d%d-%d" % (offsetInLine(deletedWords, i1),
                                        offsetInLine(deletedWords, i2)))
        elif tag == 'insert':
            lineDiff.append("i%d-%d" % (offsetInLine(insertedWords, j1),
                                        offsetInLine(insertedWords, j2)))

    return ",".join(lineDiff)

def analyzeWhiteSpaceChanges(deletedLines, insertedLines, at_eof=False,
                             offsetA=0, offsetB=0, full=False):
    result = []

    for index, (deletedLine, insertedLine) in enumerate(zip(deletedLines, insertedLines)):
        if deletedLine != insertedLine:
            result.append("%d=%d:%s"
                          % (index + offsetA, index + offsetB,
                             analyzeWhiteSpaceLine(deletedLine, insertedLine)))
        elif index == len(deletedLines) - 1 and at_eof:
            result.append("%d=%d:eol" % (index + offsetA, index + offsetB))
        elif full:
            result.append("%d=%d" % (index + offsetA, index + offsetB))

    if not result and (offsetA or offsetB):
        result.append("%d=%d" % (offsetA, offsetB))

    return ";".join(result)

########NEW FILE########
__FILENAME__ = context
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2012 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import diff
import diff.html

class ContextLines:
    def __init__(self, file, chunks, chains=None, merge=False, conflicts=False):
        self.file = file
        self.chunks = chunks
        self.chains = chains
        self.merge = merge
        self.conflicts = conflicts

    def getMacroChunks(self, context_lines=3, minimum_gap=3, highlight=True, lineFilter=None):
        old_lines = self.file.oldLines(highlight)
        new_lines = self.file.newLines(highlight)

        lines = []

        def addLine(line):
            if not lineFilter or lineFilter(line): lines.append(line)

        for chunk in self.chunks:
            old_offset = chunk.delete_offset
            new_offset = chunk.insert_offset

            if chunk.analysis:
                mappings = chunk.analysis.split(';')

                for mapping in mappings:
                    if ':' in mapping:
                        mapped_lines, ops = mapping.split(':')
                    else:
                        mapped_lines = mapping
                        ops = None

                    old_line, new_line = mapped_lines.split('=')
                    old_line = chunk.delete_offset + int(old_line)
                    new_line = chunk.insert_offset + int(new_line)

                    while old_offset < old_line and new_offset < new_line:
                        if old_lines[old_offset - 1] == new_lines[new_offset - 1]:
                            line_type = diff.Line.CONTEXT
                        else:
                            line_type = diff.Line.REPLACED

                        line = diff.Line(line_type,
                                         old_offset, old_lines[old_offset - 1],
                                         new_offset, new_lines[new_offset - 1],
                                         is_whitespace=chunk.is_whitespace)

                        if self.conflicts and line_type == diff.Line.REPLACED and line.isConflictMarker():
                            addLine(diff.Line(diff.Line.DELETED,
                                              old_offset, old_lines[old_offset - 1],
                                              new_offset, None))
                        else:
                            addLine(line)
                            new_offset += 1

                        old_offset += 1

                    while old_offset < old_line:
                        addLine(diff.Line(diff.Line.DELETED,
                                          old_offset, old_lines[old_offset - 1],
                                          new_offset, None))
                        old_offset += 1

                    while new_offset < new_line:
                        addLine(diff.Line(diff.Line.INSERTED,
                                          old_offset, None,
                                          new_offset, new_lines[new_offset - 1]))
                        new_offset += 1

                    try:
                        deleted_line = old_lines[old_offset - 1]
                        inserted_line = new_lines[new_offset - 1]
                    except:
                        raise repr((self.file.path, self.file.old_sha1, self.file.new_sha1, new_offset, len(new_lines)))

                    if deleted_line == inserted_line:
                        line_type = diff.Line.CONTEXT
                        is_whitespace = False
                    else:
                        if ops and ops.startswith("ws"):
                            is_whitespace = True
                            if ops.startswith("ws,"): ops = ops[3:]
                            else: ops = None
                        else:
                            is_whitespace = False

                        line_type = diff.Line.MODIFIED

                        if highlight and ops:
                            if ops == "eol":
                                line_type = diff.Line.REPLACED
                                if highlight:
                                    if not self.file.old_eof_eol: deleted_line += "<i class='eol'>[missing linebreak]</i>"
                                    if not self.file.new_eof_eol: deleted_line += "<i class='eol'>[missing linebreak]</i>"
                            else:
                                deleted_line, inserted_line = diff.html.lineDiffHTML(ops, deleted_line, inserted_line)

                    addLine(diff.Line(line_type,
                                      old_offset, deleted_line,
                                      new_offset, inserted_line,
                                      is_whitespace=chunk.is_whitespace or is_whitespace))

                    old_offset += 1
                    new_offset += 1

            old_line = chunk.delete_offset + chunk.delete_count
            new_line = chunk.insert_offset + chunk.insert_count

            while old_offset < old_line and new_offset < new_line:
                if old_lines[old_offset - 1] == new_lines[new_offset - 1]:
                    line_type = diff.Line.CONTEXT
                else:
                    line_type = diff.Line.REPLACED

                line = diff.Line(line_type,
                                 old_offset, old_lines[old_offset - 1],
                                 new_offset, new_lines[new_offset - 1],
                                 is_whitespace=chunk.is_whitespace)

                if self.conflicts and line_type == diff.Line.REPLACED and line.isConflictMarker():
                    addLine(diff.Line(diff.Line.DELETED,
                                      old_offset, old_lines[old_offset - 1],
                                      new_offset, None))
                else:
                    addLine(line)
                    new_offset += 1

                old_offset += 1

            while old_offset < old_line:
                try:
                    addLine(diff.Line(diff.Line.DELETED,
                                      old_offset, old_lines[old_offset - 1],
                                      new_offset, None))
                except:
                    addLine(diff.Line(diff.Line.DELETED,
                                      old_offset, "",
                                      new_offset, None))

                old_offset += 1

            while new_offset < new_line:
                try:
                    addLine(diff.Line(diff.Line.INSERTED,
                                      old_offset, None,
                                      new_offset, new_lines[new_offset - 1]))
                except:
                    addLine(diff.Line(diff.Line.INSERTED,
                                      old_offset, None,
                                      new_offset, ""))

                new_offset += 1

        old_table = {}
        new_table = {}

        for line in lines:
            if line.old_value is not None:
                old_table[line.old_offset] = line
            if line.new_value is not None:
                new_table[line.new_offset] = line

        def translateInChunk(chunk, old_delta=None, new_delta=None):
            if chunk.analysis:
                mappings = chunk.analysis.split(';')

                previous_old_line = 0
                previous_new_line = 0

                for mapping in mappings:
                    if ':' in mapping:
                        mapped_lines, ops = mapping.split(':')
                    else:
                        mapped_lines = mapping

                    old_line, new_line = mapped_lines.split('=')
                    old_line = int(old_line)
                    new_line = int(new_line)

                    if old_delta is not None:
                        if old_line == old_delta:
                            return new_line
                        elif old_line > old_delta:
                            return previous_new_line
                    else:
                        if new_line == new_delta:
                            return old_line
                        elif new_line > new_delta:
                            return previous_old_line

                    previous_old_line = old_line
                    previous_new_line = new_line

            if old_delta is not None: return min(old_delta, chunk.insert_count)
            else: return min(new_delta, chunk.delete_count)

        def findMatchingOldOffset(offset):
            precedingChunk = None
            for chunk in self.chunks:
                if chunk.insert_offset + chunk.insert_count > offset:
                    if chunk.insert_offset <= offset:
                        delta = translateInChunk(chunk, new_delta=offset - chunk.insert_offset)
                        offset = chunk.delete_offset + delta
                        return offset
                    break
                precedingChunk = chunk
            if precedingChunk:
                offset -= precedingChunk.insert_offset + precedingChunk.insert_count
                offset += precedingChunk.delete_offset + precedingChunk.delete_count
            return offset

        def findMatchingNewOffset(offset):
            precedingChunk = None
            for chunk in self.chunks:
                if chunk.delete_offset + chunk.delete_count > offset:
                    if chunk.delete_offset <= offset:
                        delta = translateInChunk(chunk, old_delta=offset - chunk.delete_offset)
                        offset = chunk.insert_offset + delta
                        return offset
                    break
                precedingChunk = chunk
            if precedingChunk:
                offset -= precedingChunk.delete_offset + precedingChunk.delete_count
                offset += precedingChunk.insert_offset + precedingChunk.insert_count
            return offset

        if self.chains and not self.merge:
            for chain in self.chains:
                if chain.comments:
                    if self.file.new_sha1 in chain.lines_by_sha1:
                        chain_offset, chain_count = chain.lines_by_sha1[self.file.new_sha1]
                        old_offset = findMatchingOldOffset(chain_offset)
                        new_offset = chain_offset
                        first_line = new_table.get(new_offset)
                    else:
                        chain_offset, chain_count = chain.lines_by_sha1[self.file.old_sha1]
                        old_offset = chain_offset
                        new_offset = findMatchingNewOffset(chain_offset)
                        first_line = old_table.get(old_offset)

                    count = chain_count

                    while count:
                        if old_offset not in old_table and new_offset not in new_table:
                            try:
                                line = diff.Line(diff.Line.CONTEXT,
                                                 old_offset, old_lines[old_offset - 1],
                                                 new_offset, new_lines[new_offset - 1])
                            except IndexError:
                                break
                            if not lineFilter or lineFilter(line):
                                if not first_line: first_line = line
                                old_table[old_offset] = line
                                new_table[new_offset] = line

                        if old_offset in old_table: old_offset += 1
                        if new_offset in new_table: new_offset += 1
                        count -= 1

        class queue:
            def __init__(self, iterable):
                self.__list = list(iterable)
                self.__offset = 0

            def __getitem__(self, index): return self.__list[self.__offset + index]
            def __nonzero__(self): return self.__offset < len(self.__list)
            def __len__(self): return len(self.__list) - self.__offset
            def __str__(self): return str(self.__list[self.__offset:])
            def __repr__(self): return repr(self.__list[self.__offset:])

            def pop(self):
                self.__offset += 1
                return self.__list[self.__offset - 1]

        all_lines = queue(sorted([(key, value.new_offset, value) for key, value in old_table.items()] +
                                 [(value.old_offset, key, value) for key, value in new_table.items() if value.type not in (diff.Line.CONTEXT, diff.Line.MODIFIED, diff.Line.REPLACED)]))
        all_chunks = self.chunks[:]
        all_chains = self.chains and self.chains[:] or None

        macro_chunks = []

        def lineOrNone(lines, index):
            try: return lines[index]
            except IndexError: return None

        while all_lines:
            old_offset, new_offset, first_line = all_lines.pop()

            count = min(context_lines, max(old_offset - 1, new_offset - 1))
            old_offset = max(1, old_offset - count)
            new_offset = max(1, new_offset - count)
            lines = []

            while count:
                if old_offset <= len(old_lines) and new_offset <= len(new_lines):
                    addLine(diff.Line(diff.Line.CONTEXT,
                                      old_offset, old_lines[old_offset - 1],
                                      new_offset, new_lines[new_offset - 1]))
                    old_offset += 1
                    new_offset += 1
                elif old_offset <= len(old_lines):
                    old_offset += 1
                else:
                    new_offset += 1
                count -= 1

            lines.append(first_line)
            if first_line.type != diff.Line.INSERTED: old_offset += 1
            if first_line.type != diff.Line.DELETED: new_offset += 1

            while all_lines:
                while all_lines and (old_offset == all_lines[0][0] or new_offset == all_lines[0][1]):
                    line = all_lines.pop()[2]
                    lines.append(line)
                    if line.type != diff.Line.INSERTED: old_offset += 1
                    if line.type != diff.Line.DELETED: new_offset += 1

                if all_lines and all_lines[0][1] - new_offset <= 2 * context_lines + minimum_gap:
                    while old_offset != all_lines[0][0] and new_offset != all_lines[0][1]:
                        line = diff.Line(diff.Line.CONTEXT,
                                         old_offset, lineOrNone(old_lines, old_offset - 1),
                                         new_offset, lineOrNone(new_lines, new_offset - 1))
                        addLine(line)
                        if line.old_value is not None: old_offset += 1
                        if line.new_value is not None: new_offset += 1
                else: break

            count = context_lines

            while count:
                if old_offset <= len(old_lines) and new_offset <= len(new_lines):
                    addLine(diff.Line(diff.Line.CONTEXT,
                                      old_offset, old_lines[old_offset - 1],
                                      new_offset, new_lines[new_offset - 1]))
                    old_offset += 1
                    new_offset += 1
                elif old_offset <= len(old_lines):
                    old_offset += 1
                else:
                    new_offset += 1
                count -= 1

            chunks = []

            while all_chunks and (all_chunks[0].delete_offset < old_offset or all_chunks[0].insert_offset < new_offset):
                chunks.append(all_chunks.pop(0))

            chains = []

            if all_chains:
                index = 0
                while index < len(all_chains):
                    chain = all_chains[index]

                    if self.file.new_sha1 in chain.lines_by_sha1:
                        chain_offset, chain_count = chain.lines_by_sha1[self.file.new_sha1]
                        compare_offset = new_offset
                    else:
                        chain_offset, chain_count = chain.lines_by_sha1[self.file.old_sha1]
                        compare_offset = old_offset

                    if chain_offset < compare_offset:
                        chains.append(chain)
                        del all_chains[index]
                    else:
                        index += 1

            macro_chunks.append(diff.MacroChunk(chunks, lines))

        if not lineFilter:
            return filter(lambda macro_chunk: bool(macro_chunk.chunks), macro_chunks)
        else:
            return macro_chunks

########NEW FILE########
__FILENAME__ = html
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2012 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import re

import textutils
from htmlutils import htmlify

re_tag = re.compile("(<[^>]*>)")
re_decimal_entity = re.compile("&#([0-9]+);")

class Tag:
    def __init__(self, value): self.value = value
    def __str__(self): return self.value
    def __nonzero__(self): return False
    def __repr__(self): return "Tag(%r)" % self.value

def splitTags(line):
    def process(token):
        if token[0] == '<':
            return Tag(token)
        else:
            def replace_decimal(match):
                return unichr(int(match.group(1)))

            token = textutils.decode(token)
            token = re_decimal_entity.sub(replace_decimal, token)
            token = token.encode("utf-8")

            return token.replace("&lt;", "<").replace("&gt;", ">").replace("&amp;", "&")

    return map(process, filter(None, re_tag.split(line)))

def joinTags(tags):
    def process(token):
        if token: return htmlify(token)
        else: return str(token)

    return "".join(map(process, tags))

def insertTag(tags, offset, newTag):
    newTag = Tag(newTag)
    index = 0
    while index < len(tags):
        tag = tags[index]
        if tag:
            if len(tag) < offset: offset -= len(tag)
            else:
                if len(tag) == offset: tags.insert(index + 1, newTag)
                elif not offset: tags.insert(index, newTag)
                else: tags[index:index+1] = tag[:offset], newTag, tag[offset:]
                return
        index += 1
    tags.append(newTag)

def lineDiffHTML(ops, old, new):
    old = splitTags(old)
    new = splitTags(new)

    for op in ops.split(','):
        old_lines = None
        oldType = None
        new_lines = None
        newType = None

        if op[0] == 'r':
            old_lines, new_lines = op[1:].split('=')
            oldType = 'r'
            newType = 'r'
        elif op[0] == 'd':
            old_lines = op[1:]
            oldType = 'd'
        else:
            new_lines = op[1:]
            newType = 'i'

        if old_lines:
            start, end = old_lines.split('-')
            insertTag(old, int(start), "<i class='%s'>" % oldType)
            insertTag(old, int(end), "</i>")

        if new_lines:
            start, end = new_lines.split('-')
            insertTag(new, int(start), "<i class='%s'>" % newType)
            insertTag(new, int(end), "</i>")

    return joinTags(old), joinTags(new)

########NEW FILE########
__FILENAME__ = merge
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2012 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import diff
import diff.parse
import gitutils

# Maximum number of lines allowed between a two chunks to consider
# them near enough to warrant inclusion.
PROXIMITY_LIMIT = 3

def filterChunks(log, file_on_branch, file_in_merge, path):
    """filterChunks([diff.Chunk, ...], [diff.Chunk, ...]) => [diff.Chunk, ...]

    Filter the second list of chunks to only include chunks that affect lines
    that are within PROXIMITY_LIMIT lines of a chunk in the first list of
    chunks."""

    result = []

    on_branch = iter(file_on_branch.chunks)
    in_merge = iter(file_in_merge.chunks)

    try:
        chunk_on_branch = on_branch.next()
        chunk_in_merge = in_merge.next()

        while True:
            if chunk_in_merge.delete_offset - chunk_on_branch.insertEnd() > PROXIMITY_LIMIT:
                # Chunk_on_branch is significantly earlier than chunk_in_merge,
                # so continue to next one from on_branch.
                chunk_on_branch = on_branch.next()
            elif chunk_on_branch.insert_offset - chunk_in_merge.deleteEnd() > PROXIMITY_LIMIT:
                chunk_in_merge = in_merge.next()
            else:
                # The two chunks are near each other, or intersects, so include
                # the one from the merge
                result.append(chunk_in_merge)

                # ... and continue to the next one from in_merge.
                chunk_in_merge = in_merge.next()
    except StopIteration:
        # We ran out of chunks from either on_branch or in_merge.  If we ran out
        # of chunks from in_merge, we obviously don't need to include any more
        # chunks in the result.  If we ran out of chunks from on_branch, we
        # don't either, because the previous one was apparently significant
        # earlier than the current, and thus all following, chunks from in_merge.
        pass

    return result

def parseMergeDifferences(db, repository, commit):
    mergebase = gitutils.Commit.fromSHA1(db, repository, repository.mergebase(commit, db=db))

    result = {}
    log = [""]

    for parent_sha1 in commit.parents:
        parent = gitutils.Commit.fromSHA1(db, repository, parent_sha1)

        if parent_sha1 == mergebase:
            result[parent_sha1] = diff.parse.parseDifferences(repository, from_commit=parent, to_commit=commit)[parent_sha1]
        else:
            paths_on_branch = set(repository.run('diff', '--name-only', "%s..%s" % (mergebase, parent)).splitlines())
            paths_in_merge = set(repository.run('diff', '--name-only', "%s..%s" % (parent, commit)).splitlines())

            filter_paths = paths_on_branch & paths_in_merge

            on_branch = diff.parse.parseDifferences(repository, from_commit=mergebase, to_commit=parent, filter_paths=filter_paths)[mergebase.sha1]
            in_merge = diff.parse.parseDifferences(repository, from_commit=parent, to_commit=commit, filter_paths=filter_paths)[parent_sha1]

            files_on_branch = dict([(file.path, file) for file in on_branch])

            result_for_parent = []

            for file_in_merge in in_merge:
                file_on_branch = files_on_branch.get(file_in_merge.path)
                if file_on_branch:
                    filtered_chunks = filterChunks(log, file_on_branch, file_in_merge, file_in_merge.path)

                    if filtered_chunks:
                        result_for_parent.append(diff.File(id=None,
                                                           repository=repository,
                                                           path=file_in_merge.path,
                                                           old_sha1=file_in_merge.old_sha1,
                                                           new_sha1=file_in_merge.new_sha1,
                                                           old_mode=file_in_merge.old_mode,
                                                           new_mode=file_in_merge.new_mode,
                                                           chunks=filtered_chunks))

            result[parent_sha1] = result_for_parent

    return result

########NEW FILE########
__FILENAME__ = parse
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2012 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import configuration
import subprocess
import gitutils
import diff
import re
import itertools
import analyze

GIT_EMPTY_TREE = "4b825dc642cb6eb9a060e54bf8d69288fbee4904"

def demunge(path):
    special = { "a": "\a",
                "b": "\b",
                "t": "\t",
                "n": "\n",
                "v": "\v",
                "f": "\f",
                "r": "\r",
                '"': '"',
                "'": "'",
                "/": "/",
                "\\": "\\" }

    def unescape(match):
        escaped = match.group(1)
        if escaped in special:
            return special[escaped]
        else:
            return chr(int(escaped, 8))

    return re.sub(r"""\\([abtnvfr"'/\\]|[0-9]{3})""", unescape, path)

def splitlines(source):
    if not source: return source
    elif source[-1] == "\n": return source[:-1].split("\n")
    else: return source.split("\n")

def detectWhiteSpaceChanges(file, old_lines, begin_old_offset, end_old_offset, old_ending_linebreak, new_lines, begin_new_offset, end_new_offset, new_ending_linebreak):
    start_old_offset = None

    for old_offset, new_offset in itertools.izip(xrange(begin_old_offset, end_old_offset), xrange(begin_new_offset, end_new_offset)):
        if old_lines[old_offset - 1] != new_lines[new_offset - 1] or (old_offset == len(old_lines) and old_ending_linebreak != new_ending_linebreak):
            if start_old_offset is None:
                start_old_offset = old_offset
                start_new_offset = new_offset
        elif start_old_offset is not None:
            assert old_offset - start_old_offset != 0 and new_offset - start_new_offset != 0
            chunk = diff.Chunk(start_old_offset, old_offset - start_old_offset,
                               start_new_offset, new_offset - start_new_offset,
                               is_whitespace=True)
            chunk.is_whitespace = True
            file.chunks.append(chunk)
            start_old_offset = None

    if start_old_offset is not None:
        assert end_old_offset - start_old_offset != 0 and end_new_offset - start_new_offset != 0
        chunk = diff.Chunk(start_old_offset, end_old_offset - start_old_offset,
                           start_new_offset, end_new_offset - start_new_offset,
                           is_whitespace=True)
        chunk.is_whitespace = True
        file.chunks.append(chunk)

ws = re.compile("\\s+")

def isWhitespaceChange(deleted_line, inserted_line):
    return ws.sub(" ", deleted_line.strip()) == ws.sub(" ", inserted_line.strip())

def createChunks(delete_offset, deleted_lines, insert_offset, inserted_lines):
    ws_before = None
    ws_after = None

    if deleted_lines and inserted_lines and isWhitespaceChange(deleted_lines[0], inserted_lines[0]):
        ws_lines = 1
        max_lines = min(len(deleted_lines), len(inserted_lines))

        while ws_lines < max_lines and isWhitespaceChange(deleted_lines[ws_lines], inserted_lines[ws_lines]):
            ws_lines += 1

        ws_before = diff.Chunk(delete_offset, ws_lines, insert_offset, ws_lines, is_whitespace=True)

        delete_offset += ws_lines
        del deleted_lines[:ws_lines]

        insert_offset += ws_lines
        del inserted_lines[:ws_lines]

    if deleted_lines and inserted_lines and isWhitespaceChange(deleted_lines[-1], inserted_lines[-1]):
        ws_lines = 1
        max_lines = min(len(deleted_lines), len(inserted_lines))

        while ws_lines < max_lines and isWhitespaceChange(deleted_lines[-(ws_lines + 1)], inserted_lines[-(ws_lines + 1)]):
            ws_lines += 1

        ws_after = diff.Chunk(delete_offset + len(deleted_lines) - ws_lines, ws_lines,
                              insert_offset + len(inserted_lines) - ws_lines, ws_lines,
                              is_whitespace=True)

        del deleted_lines[-ws_lines:]
        del inserted_lines[-ws_lines:]

    if deleted_lines or inserted_lines:
        chunks = [diff.Chunk(delete_offset, len(deleted_lines), insert_offset, len(inserted_lines))]
    else:
        chunks = []

    if ws_before: chunks.insert(0, ws_before)
    if ws_after: chunks.append(ws_after)

    return chunks

def mergeChunks(file):
    if len(file.chunks) > 1:
        file.loadOldLines(False)
        old_lines = file.oldLines(False)
        file.loadNewLines(False)
        new_lines = file.newLines(False)

        merged = []
        previous = file.chunks[0]

        for chunk in file.chunks[1:]:
            assert previous.delete_count != 0 or previous.insert_count != 0

            offset = previous.delete_offset + previous.delete_count

            while offset < chunk.delete_offset:
                if not analyze.re_ignore.match(old_lines[offset - 1]):
                    break
                offset += 1
            else:
                previous.delete_count = (chunk.delete_offset - previous.delete_offset) + chunk.delete_count
                previous.insert_count = (chunk.insert_offset - previous.insert_offset) + chunk.insert_count

                assert previous.delete_count != 0 or previous.insert_count != 0

                previous.is_whitespace = previous.is_whitespace and chunk.is_whitespace
                continue

            merged.append(previous)
            previous = chunk

        merged.append(previous)

        for chunk in merged:
            while chunk.insert_count > 1 and chunk.delete_count > 1:
                insert_last = new_lines[chunk.insert_offset + chunk.insert_count - 2]
                delete_last = old_lines[chunk.delete_offset + chunk.delete_count - 2]

                if insert_last == delete_last:
                    chunk.delete_count -= 1
                    chunk.insert_count -= 1
                else:
                    break

        file.clean()
        file.chunks = merged

def parseDifferences(repository, commit=None, from_commit=None, to_commit=None, filter_paths=None, selected_path=None, simple=False):
    """parseDifferences(repository, [commit] | [from_commit, to_commit][, selected_path]) =>
         dict(parent_sha1 => [diff.File, ...] (if selected_path is None)
         diff.File                            (if selected_path is not None)"""

    options = []

    if to_commit:
        command = 'diff'
        if from_commit:
            what = [from_commit.sha1 + ".." + to_commit.sha1]
        else:
            what = [GIT_EMPTY_TREE, to_commit.sha1]
    elif not commit.parents:
        # Root commit.

        command = "show"
        what = [commit.sha1]

        options.append("--pretty=format:")
    else:
        assert len(commit.parents) == 1

        command = 'diff'
        what = [commit.parents[0] + '..' + commit.sha1]

    if filter_paths is None and selected_path is None and not simple:
        names = repository.run(command, *(options + ["--name-only"] + what))
        paths = set(filter(None, map(str.strip, names.splitlines())))
    else:
        paths = set()

    if not simple:
        options.append('--ignore-space-change')

    options.extend(what)

    if filter_paths is not None:
        options.append('--')
        options.extend(filter_paths)
    elif selected_path is not None:
        options.append('--')
        options.append(selected_path)

    stdout = repository.run(command, '--full-index', '--unified=1', '--patience', *options)
    selected_file = None

    re_chunk = re.compile('^@@ -(\\d+)(?:,\\d+)? \\+(\\d+)(?:,\\d+)? @@')
    re_binary = re.compile('^Binary files (?:a/(.+)|/dev/null) and (?:b/(.+)|/dev/null) differ')
    re_diff = re.compile("^diff --git ([\"']?)a/(.*)\\1 ([\"']?)b/(.*)\\3$")
    re_old_path = re.compile("--- ([\"']?)a/(.*?)\\1\t?$")
    re_new_path = re.compile("\\+\\+\\+ ([\"']?)b/(.*?)\\1\t?$")

    def isplitlines(text):
        start = 0
        length = len(text)

        while start < length:
            try:
                end = text.index('\n', start)
                yield text[start:end]
                start = end + 1
            except ValueError:
                yield text[start:]
                break

    lines = isplitlines(stdout)

    included = set()
    files = []
    files_by_path = {}

    def addFile(new_file):
        assert new_file.path not in files_by_path, "duplicate path: %s" % new_file.path
        files.append(new_file)
        files_by_path[new_file.path] = new_file
        included.add(new_file.path)

    old_mode = None
    new_mode = None

    try:
        line = lines.next()

        names = None

        while True:
            old_mode = None
            new_mode = None

            # Scan to the 'index <sha1>..<sha1>' line that marks the beginning
            # of the differences in one file.
            while not line.startswith("index "):
                match = re_diff.match(line)
                if match:
                    if old_mode is not None and new_mode is not None:
                        addFile(diff.File(None, names[0], None, None, repository, old_mode=old_mode, new_mode=new_mode, chunks=[]))
                    old_name = match.group(2)
                    if match.group(1):
                        old_name = demunge(old_name)
                    new_name = match.group(4)
                    if match.group(3):
                        new_name = demunge(new_name)
                    names = (old_name, new_name)
                elif line.startswith("old mode "):
                    old_mode = line[9:]
                elif line.startswith("new mode "):
                    new_mode = line[9:]
                elif line.startswith("new file mode "):
                    new_mode = line[14:]
                elif line.startswith("deleted file mode "):
                    old_mode = line[18:]

                line = lines.next()

            is_submodule = False

            try:
                sha1range, mode = line[6:].split(' ', 2)
                if mode == "160000":
                    is_submodule = True
                    old_mode = new_mode = mode
                old_sha1, new_sha1 = sha1range.split('..')
            except:
                old_sha1, new_sha1 = line[6:].split(' ', 1)[0].split("..")

            try: line = lines.next()
            except:
                if old_mode is not None or new_mode is not None:
                    assert names[0] == names[1]

                    addFile(diff.File(None, names[0], old_sha1, new_sha1, repository,
                                      old_mode=old_mode, new_mode=new_mode,
                                      chunks=[diff.Chunk(0, 0, 0, 0)]))

                    old_mode = new_mode = None

            if re_diff.match(line):
                new_file = diff.File(None, names[0] or names[1], old_sha1, new_sha1, repository, old_mode=old_mode, new_mode=new_mode)

                if '0' * 40 == old_sha1 or '0' * 40 == new_sha1:
                    new_file.chunks = [diff.Chunk(0, 0, 0, 0)]
                else:
                    new_file.loadOldLines()
                    new_file.loadNewLines()
                    new_file.chunks = []

                    detectWhiteSpaceChanges(new_file,
                                            new_file.oldLines(False), 1, new_file.oldCount() + 1, True,
                                            new_file.newLines(False), 1, new_file.newCount() + 1, True)


                addFile(new_file)

                old_mode = new_mode = False

                continue

            binary = re_binary.match(line)
            if binary:
                path = (binary.group(1) or binary.group(2)).strip()

                if path in files_by_path:
                    new_file = files_by_path[path]
                    if old_sha1 != '0' * 40:
                        assert new_file.old_sha1 == '0' * 40
                        new_file.old_sha1 = old_sha1
                        new_file.old_mode = old_mode
                    if new_sha1 != '0' * 40:
                        assert new_file.new_sha1 == '0' * 40
                        new_file.new_sha1 = new_sha1
                        new_file.new_mode = new_mode
                    new_file.chunks = [diff.Chunk(0, 0, 0, 0)]
                else:
                    new_file = diff.File(None, path, old_sha1, new_sha1, repository, old_mode=old_mode, new_mode=new_mode)
                    new_file.chunks = [diff.Chunk(0, 0, 0, 0)]
                    addFile(new_file)

                continue

            match = re_old_path.match(line)
            if match:
                old_path = match.group(2)
                if match.group(1):
                    old_path = demunge(old_path)
            else:
                old_path = None

            line = lines.next()

            match = re_new_path.match(line)
            if match:
                new_path = match.group(2)
                if match.group(1):
                    new_path = demunge(new_path)
            else:
                new_path = None

            assert (old_path is None) == ('0' * 40 == old_sha1)
            assert (new_path is None) == ('0' * 40 == new_sha1)

            if old_path:
                path = old_path
            else:
                path = new_path

            if is_submodule:
                line = lines.next()
                match = re_chunk.match(line)
                assert match, repr(line)
                assert match.group(1) == match.group(2) == "1", repr(match.groups())

                line = lines.next()
                assert line == "-Subproject commit %s" % old_sha1, repr(line)

                line = lines.next()
                assert line == "+Subproject commit %s" % new_sha1, repr(line)

                new_file = diff.File(None, path, old_sha1, new_sha1, repository,
                                     old_mode=old_mode, new_mode=new_mode,
                                     chunks=[diff.Chunk(1, 1, 1, 1, analysis="0=0:r18-58=18-58")])

                if path not in files_by_path: addFile(new_file)

                old_mode = new_mode = None

                continue

            try:
                line = lines.next()

                delete_offset = 1
                deleted_lines = []
                insert_offset = 1
                inserted_lines = []

                if old_path and new_path and not simple:
                    old_lines = splitlines(repository.fetch(old_sha1).data)
                    new_lines = splitlines(repository.fetch(new_sha1).data)
                else:
                    old_lines = None
                    new_lines = None

                if path in files_by_path:
                    new_file = files_by_path[path]
                    if old_sha1 != '0' * 40:
                        assert new_file.old_sha1 == '0' * 40
                        new_file.old_sha1 = old_sha1
                        new_file.old_mode = old_mode
                    if new_sha1 != '0' * 40:
                        assert new_file.new_sha1 == '0' * 40
                        new_file.new_sha1 = new_sha1
                        new_file.new_mode = new_mode
                    new_file.chunks = []
                else:
                    new_file = diff.File(None, path, old_sha1, new_sha1, repository, old_mode=old_mode, new_mode=new_mode, chunks=[])

                old_mode = new_mode = None

                if selected_path is not None and selected_path == path:
                    selected_file = new_file

                if path not in files_by_path: addFile(new_file)

                previous_delete_offset = 1
                previous_insert_offset = 1

                while True:
                    match = re_chunk.match(line)

                    if not match: break

                    groups = match.groups()

                    delete_offset = int(groups[0])
                    deleted_lines = []

                    insert_offset = int(groups[1])
                    inserted_lines = []

                    while True:
                        line = lines.next()

                        if line == "\\ No newline at end of file": continue
                        if line[0] not in (' ', '-', '+'): break

                        if line[0] != ' ' and previous_delete_offset is not None and old_lines and new_lines and not simple:
                            detectWhiteSpaceChanges(files[-1], old_lines, previous_delete_offset, delete_offset, True, new_lines, previous_insert_offset, insert_offset, True)
                            previous_delete_offset = None

                        if line[0] == ' ' and previous_delete_offset is None:
                            previous_delete_offset = delete_offset
                            previous_insert_offset = insert_offset

                        type = line[0]

                        if type == '-':
                            delete_offset += 1
                            deleted_lines.append(line[1:])
                        elif type == '+':
                            insert_offset += 1
                            inserted_lines.append(line[1:])
                        else:
                            if deleted_lines or inserted_lines:
                                chunks = createChunks(delete_offset - len(deleted_lines),
                                                      deleted_lines,
                                                      insert_offset - len(inserted_lines),
                                                      inserted_lines)
                                files[-1].chunks.extend(chunks)
                                deleted_lines = []
                                inserted_lines = []

                            delete_offset += 1
                            insert_offset += 1

                    if deleted_lines or inserted_lines:
                        chunks = createChunks(delete_offset - len(deleted_lines),
                                              deleted_lines,
                                              insert_offset - len(inserted_lines),
                                              inserted_lines)
                        files[-1].chunks.extend(chunks)
                        deleted_lines = []
                        inserted_lines = []

                if previous_delete_offset is not None and old_lines and new_lines and not simple:
                    detectWhiteSpaceChanges(files[-1], old_lines, previous_delete_offset, len(old_lines) + 1, True, new_lines, previous_insert_offset, len(new_lines) + 1, True)
                    previous_delete_offset = None
            except StopIteration:
                if deleted_lines or inserted_lines:
                    chunks = createChunks(delete_offset - len(deleted_lines),
                                          deleted_lines,
                                          insert_offset - len(inserted_lines),
                                          inserted_lines)
                    files[-1].chunks.extend(chunks)
                    deleted_lines = []
                    inserted_lines = []

                if previous_delete_offset is not None and old_lines and new_lines and not simple:
                    detectWhiteSpaceChanges(files[-1], old_lines, previous_delete_offset, len(old_lines) + 1, True, new_lines, previous_insert_offset, len(new_lines) + 1, True)

                raise
    except StopIteration:
        if old_mode is not None and new_mode is not None:
            assert names[0] == names[1]

            addFile(diff.File(None, names[0], None, None, repository, old_mode=old_mode, new_mode=new_mode, chunks=[]))

    for path in (paths - included):
        lines = isplitlines(repository.run(command, '--full-index', '--unified=1', *(what + ['--', path])))

        try:
            line = lines.next()

            while not line.startswith("index "): line = lines.next()

            try:
                sha1range, mode = line[6:].split(' ')
                if mode == "160000":
                    continue
                old_sha1, new_sha1 = sha1range.split("..")
            except:
                old_sha1, new_sha1 = line[6:].split(' ', 1)[0].split("..")

            if old_sha1 == '0' * 40 or new_sha1 == '0' * 40:
                # Added or removed empty file.
                continue

            addFile(diff.File(None, path, old_sha1, new_sha1, repository, chunks=[]))

            old_data = repository.fetch(old_sha1).data
            old_lines = splitlines(old_data)
            new_data = repository.fetch(new_sha1).data
            new_lines = splitlines(new_data)

            assert len(old_lines) == len(new_lines), "%s:%d != %s:%d" % (old_sha1, len(old_lines), new_sha1, len(new_lines))

            def endsWithLinebreak(data): return data and data[-1] in "\n\r"

            detectWhiteSpaceChanges(files[-1], old_lines, 1, len(old_lines) + 1, endsWithLinebreak(old_data), new_lines, 1, len(new_lines) + 1, endsWithLinebreak(new_data))
        except StopIteration:
            pass

    if not simple:
        for file in files:
            mergeChunks(file)

    if to_commit:
        if selected_path is not None:
            return selected_file
        elif from_commit:
            return { from_commit.sha1: files }
        else:
            return { None: files }
    elif not commit.parents:
        return { None: files }
    else:
        return { commit.parents[0]: files }

########NEW FILE########
__FILENAME__ = diffutils
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2012 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

from difflib import SequenceMatcher
from itertools import izip, repeat

import diff
import diff.html

def expandWithContext(chunks, old_lines, new_lines, context_lines, highlight=True):
    if not chunks: return []

    groups = []
    group = []

    chunks = iter(chunks)

    try:
        previousChunk = chunks.next()
        group.append(previousChunk)

        while True:
            nextChunk = chunks.next()

            distance = nextChunk.delete_offset - (previousChunk.delete_offset + previousChunk.delete_count)
            gap_between = distance - 2 * context_lines

            if gap_between >= 3:
                groups.append(group)
                group = []

            group.append(nextChunk)
            previousChunk = nextChunk
    except StopIteration:
        pass

    groups.append(group)

    macro_chunks = []

    for group in groups:
        delete_offset = max(1, group[0].delete_offset - context_lines)
        insert_offset = max(1, group[0].insert_offset - context_lines)

        lines = []

        for chunk in group:
            while delete_offset < chunk.delete_offset:
                lines.append(diff.Line(diff.Line.CONTEXT, delete_offset, old_lines[delete_offset - 1], insert_offset, new_lines[insert_offset - 1]))
                delete_offset += 1
                insert_offset += 1

            if chunk.analysis:
                mappings = chunk.analysis.split(';')

                for mapping in mappings:
                    if ':' in mapping:
                        mapped_lines, ops = mapping.split(':')
                    else:
                        mapped_lines = mapping
                        ops = None

                    delete_line, insert_line = mapped_lines.split('=')
                    delete_line = chunk.delete_offset + int(delete_line)
                    insert_line = chunk.insert_offset + int(insert_line)

                    while delete_offset < delete_line and insert_offset < insert_line:
                        lines.append(diff.Line(diff.Line.MODIFIED, delete_offset, old_lines[delete_offset - 1], insert_offset, new_lines[insert_offset - 1], is_whitespace=chunk.is_whitespace))
                        delete_offset += 1
                        insert_offset += 1

                    while delete_offset < delete_line:
                        lines.append(diff.Line(diff.Line.DELETED, delete_offset, old_lines[delete_offset - 1], insert_offset, None))
                        delete_offset += 1

                    while insert_offset < insert_line:
                        lines.append(diff.Line(diff.Line.INSERTED, delete_offset, None, insert_offset, new_lines[insert_offset - 1]))
                        insert_offset += 1

                    deleted_line = old_lines[delete_offset - 1]
                    inserted_line = new_lines[insert_offset - 1]

                    if highlight and ops: deleted_line, inserted_line = diff.html.lineDiffHTML(ops, deleted_line, inserted_line)

                    lines.append(diff.Line(diff.Line.MODIFIED, delete_offset, deleted_line, insert_offset, inserted_line, is_whitespace=chunk.is_whitespace))

                    delete_offset += 1
                    insert_offset += 1

            deleteStop = chunk.delete_offset + chunk.delete_count
            insertStop = chunk.insert_offset + chunk.insert_count

            while delete_offset < deleteStop and insert_offset < insertStop:
                lines.append(diff.Line(diff.Line.REPLACED, delete_offset, old_lines[delete_offset - 1], insert_offset, new_lines[insert_offset - 1], is_whitespace=chunk.is_whitespace))
                delete_offset += 1
                insert_offset += 1

            while delete_offset < deleteStop:
                lines.append(diff.Line(diff.Line.DELETED, delete_offset, old_lines[delete_offset - 1], insert_offset, None))
                delete_offset += 1

            while insert_offset < insertStop:
                lines.append(diff.Line(diff.Line.INSERTED, delete_offset, None, insert_offset, new_lines[insert_offset - 1]))
                insert_offset += 1

        deleteStop = min(len(old_lines) + 1, delete_offset + context_lines)

        while delete_offset < deleteStop:
            lines.append(diff.Line(diff.Line.CONTEXT, delete_offset, old_lines[delete_offset - 1], insert_offset, new_lines[insert_offset - 1]))
            delete_offset += 1
            insert_offset += 1

        macro_chunks.append(diff.MacroChunk(group, lines))

    return macro_chunks

########NEW FILE########
__FILENAME__ = execute
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2012 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import os
import subprocess

import configuration
from textutils import json_encode
from communicate import Communicate

def executeProcess(manifest, role_name, script, function, extension_id, user_id,
                   argv, timeout, stdin=None, rlimit_rss=256):
    flavor = manifest.flavor

    if manifest.flavor not in configuration.extensions.FLAVORS:
        flavor = configuration.extensions.DEFAULT_FLAVOR

    executable = configuration.extensions.FLAVORS[flavor]["executable"]
    library = configuration.extensions.FLAVORS[flavor]["library"]

    process_argv = [executable, os.path.join(library, "critic-launcher.js")]

    stdin_data = "%s\n" % json_encode({
            "criticjs_path": os.path.join(library, "critic.js"),
            "rlimit": { "rss": rlimit_rss },
            "hostname": configuration.base.HOSTNAME,
            "dbname": configuration.database.PARAMETERS["database"],
            "dbuser": configuration.database.PARAMETERS["user"],
            "git": configuration.executables.GIT,
            "python": configuration.executables.PYTHON,
            "python_path": "%s:%s" % (configuration.paths.CONFIG_DIR,
                                      configuration.paths.INSTALL_DIR),
            "repository_work_copy_path": configuration.extensions.WORKCOPY_DIR,
            "changeset_address": configuration.services.CHANGESET["address"],
            "branchtracker_pid_path": configuration.services.BRANCHTRACKER["pidfile_path"],
            "maildelivery_pid_path": configuration.services.MAILDELIVERY["pidfile_path"],
            "is_development": configuration.debug.IS_DEVELOPMENT,
            "extension_path": manifest.path,
            "extension_id": extension_id,
            "user_id": user_id,
            "role": role_name,
            "script_path": script,
            "fn": function,
            "argv": argv })

    if stdin is not None:
        stdin_data += stdin

    process = subprocess.Popen(process_argv, stdin=subprocess.PIPE, stdout=subprocess.PIPE, stderr=subprocess.PIPE, cwd=manifest.path)

    communicate = Communicate(process)
    communicate.setInput(stdin_data)
    communicate.setTimeout(timeout)

    return communicate.run()[0]

########NEW FILE########
__FILENAME__ = extension
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2012 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import os
import subprocess
import pwd

import configuration
import dbutils
import htmlutils

from extensions.manifest import Manifest, ManifestError
from extensions import getExtensionInstallPath

class ExtensionError(Exception):
    def __init__(self, message, extension=None):
        super(ExtensionError, self).__init__(message)
        self.extension = extension

class Extension(object):
    def __init__(self, author_name, extension_name):
        if os.path.sep in extension_name:
            raise ExtensionError(
                "Invalid extension name: %s" % extension_name)

        self.__author_name = author_name
        self.__extension_name = extension_name
        self.__manifest = {}

        if author_name:
            try:
                user_home_dir = pwd.getpwnam(author_name).pw_dir
            except KeyError:
                raise ExtensionError(
                    "No such system user: %s" % author_name,
                    extension=self)

            self.__path = os.path.join(
                user_home_dir,
                configuration.extensions.USER_EXTENSIONS_DIR,
                extension_name)
        else:
            self.__path = os.path.join(
                configuration.extensions.SYSTEM_EXTENSIONS_DIR,
                extension_name)

        if not (os.path.isdir(self.__path) and
                os.access(self.__path, os.R_OK | os.X_OK)):
            raise ExtensionError(
                "Invalid or inaccessible extension dir: %s" % self.__path,
                extension=self)

    def isSystemExtension(self):
        return self.__author_name is None

    def getAuthorName(self):
        if self.isSystemExtension():
            return None
        return self.__author_name

    def getName(self):
        return self.__extension_name

    def getTitle(self, db, html=False):
        if html:
            title = "<b>%s</b>" % htmlutils.htmlify(self.getName())
        else:
            title = self.getName()

        if not self.isSystemExtension():
            author = self.getAuthor(db)

            try:
                manifest = self.getManifest()
            except ManifestError:
                # Can't access information from the manifest, so assume "yes".
                is_author = True
            else:
                is_author = manifest.isAuthor(db, author)

            if is_author:
                title += " by "
            else:
                title += " hosted by "

            if html:
                title += htmlutils.htmlify(author.fullname)
            else:
                title += author.fullname

        return title

    def getKey(self):
        if self.isSystemExtension():
            return self.__extension_name
        else:
            return "%s/%s" % (self.__author_name, self.__extension_name)

    def getPath(self):
        return self.__path

    def getVersions(self):
        try:
            output = subprocess.check_output(
                [configuration.executables.GIT, "for-each-ref",
                 "--format=%(refname)", "refs/heads/version/"],
                stderr=subprocess.STDOUT, cwd=self.__path)
        except subprocess.CalledProcessError:
            # Not a git repository => no versions (except "Live").
            return []

        versions = []
        for ref in output.splitlines():
            if ref.startswith("refs/heads/version/"):
                versions.append(ref[len("refs/heads/version/"):])
        return versions

    def getManifest(self, version=None, sha1=None):
        path = self.__path
        source = None

        if sha1 is not None:
            if sha1 in self.__manifest:
                return self.__manifest[sha1]

            install_path = getExtensionInstallPath(sha1)
            with open(os.path.join(install_path, "MANIFEST")) as manifest_file:
                source = manifest_file.read()

            path = "<snapshot of commit %s>" % sha1[:8]
        elif version in self.__manifest:
            return self.__manifest[version]

        if source is None and version is not None:
            source = subprocess.check_output(
                [configuration.executables.GIT, "cat-file", "blob",
                 "version/%s:MANIFEST" % version],
                cwd=self.__path)

        manifest = Manifest(path, source)
        manifest.read()

        if sha1 is not None:
            self.__manifest[sha1] = manifest
        else:
            self.__manifest[version] = manifest

        return manifest

    def getCurrentSHA1(self, version):
        return subprocess.check_output(
            [configuration.executables.GIT, "rev-parse", "--verify",
             "version/%s" % version],
            cwd=self.__path).strip()

    def prepareVersionSnapshot(self, version):
        sha1 = self.getCurrentSHA1(version)

        if not os.path.isdir(getExtensionInstallPath(sha1)):
            git_archive = subprocess.Popen(
                [configuration.executables.GIT, "archive", "--format=tar",
                 "--prefix=%s/" % sha1, sha1],
                stdout=subprocess.PIPE, cwd=self.__path)
            subprocess.check_call(
                [configuration.executables.TAR, "x"],
                stdin=git_archive.stdout,
                cwd=configuration.extensions.INSTALL_DIR)

        return sha1

    def getAuthor(self, db):
        if self.isSystemExtension():
            return None
        return dbutils.User.fromName(db, self.getAuthorName())

    def getExtensionID(self, db, create=False):
        cursor = db.cursor()

        if self.isSystemExtension():
            author_id = None
            cursor.execute("""SELECT extensions.id
                                FROM extensions
                               WHERE extensions.author IS NULL
                                 AND extensions.name=%s""",
                           (self.__extension_name,))
        else:
            author_id = self.getAuthor(db).id
            cursor.execute("""SELECT extensions.id
                                FROM extensions
                               WHERE extensions.author=%s
                                 AND extensions.name=%s""",
                           (author_id, self.__extension_name))

        row = cursor.fetchone()

        if row:
            return row[0]
        elif create:
            cursor.execute("""INSERT INTO extensions (author, name)
                              VALUES (%s, %s)
                           RETURNING id""",
                           (author_id, self.__extension_name))
            return cursor.fetchone()[0]
        else:
            return None

    def getInstalledVersion(self, db, user):
        """Return (sha1, name) of the version currently installed by the user.

        If the user doesn't have the extension installed, return (False, False).
        If the user has the "live" version installed, return (None, None).
        """

        extension_id = self.getExtensionID(db)

        if extension_id is None:
            # An extension is recorded in the database and assigned an ID the
            # first time it's installed.  If it doesn't have an ID, then no user
            # can have any version of it installed.
            return (False, False)

        cursor = db.cursor()

        if user is None:
            cursor.execute("""SELECT extensionversions.sha1, extensionversions.name
                                FROM extensioninstalls
                     LEFT OUTER JOIN extensionversions ON (extensionversions.id=extensioninstalls.version)
                               WHERE extensioninstalls.uid IS NULL
                                 AND extensioninstalls.extension=%s""",
                           (extension_id,))
        else:
            cursor.execute("""SELECT extensionversions.sha1, extensionversions.name
                                FROM extensioninstalls
                     LEFT OUTER JOIN extensionversions ON (extensionversions.id=extensioninstalls.version)
                               WHERE extensioninstalls.uid=%s
                                 AND extensioninstalls.extension=%s""",
                           (user.id, extension_id))

        row = cursor.fetchone()

        if row:
            return row
        else:
            return (False, False)

    @staticmethod
    def fromId(db, extension_id):
        cursor = db.cursor()
        cursor.execute("""SELECT users.name, extensions.name
                            FROM extensions
                 LEFT OUTER JOIN users ON (users.id=extensions.author)
                           WHERE extensions.id=%s""",
                       (extension_id,))
        author_name, extension_name = cursor.fetchone()
        return Extension(author_name, extension_name)

    @staticmethod
    def getInstalls(db, user):
        """
        Return a list of extension installs in effect for the specified user

        If 'user' is None, all universal extension installs are listed.

        Each install is returned as a tuple containing four elements, the
        extension id, the version id, the version SHA-1 and a boolean which is
        true if the install is universal.  For a LIVE version, the version id
        and the version SHA-1 are None.

        The list of installs is ordered by precedence; most significant install
        first, least significant install last.
        """

        cursor = db.cursor()
        cursor.execute("""SELECT extensioninstalls.id, extensioninstalls.extension,
                                 extensionversions.id, extensionversions.sha1,
                                 extensioninstalls.uid IS NULL
                            FROM extensioninstalls
                 LEFT OUTER JOIN extensionversions ON (extensionversions.id=extensioninstalls.version)
                           WHERE uid=%s OR uid IS NULL
                        ORDER BY uid NULLS FIRST""",
                       (user.id if user else None,))

        install_per_extension = {}

        # Since we ordered by 'uid' with nulls ("universal installs") first,
        # we'll overwrite universal installs with per-user installs, as intended.
        for install_id, extension_id, version_id, version_sha1, is_universal in cursor:
            install_per_extension[extension_id] = (install_id, version_id,
                                                   version_sha1, is_universal)

        installs = [(install_id, extension_id, version_id, version_sha1, is_universal)
                    for extension_id, (install_id, version_id, version_sha1, is_universal)
                    in install_per_extension.items()]

        # Sort installs by install id, higher first.  This means a later install
        # takes precedence over an earlier, if they both handle the same path.
        installs.sort(reverse=True)

        # Drop the install_id; it is not relevant past this point.
        return [(extension_id, version_id, version_sha1, is_universal)
                for _, extension_id, version_id, version_sha1, is_universal
                in installs]

    @staticmethod
    def getUpdatedExtensions(db, user):
        cursor = db.cursor()
        cursor.execute("""SELECT users.name, users.fullname, extensions.name,
                                 extensionversions.name, extensionversions.sha1
                            FROM users
                            JOIN extensions ON (extensions.author=users.id)
                            JOIN extensionversions ON (extensionversions.extension=extensions.id)
                            JOIN extensioninstalls ON (extensioninstalls.version=extensionversions.id)
                           WHERE extensioninstalls.uid=%s""",
                       (user.id,))

        updated = []
        for author_name, author_fullname, extension_name, version_name, version_sha1 in cursor:
            extension = Extension(author_name, extension_name)
            if extension.getCurrentSHA1(version_name) != version_sha1:
                updated.append((author_fullname, extension_name))
        return updated

    @staticmethod
    def find(db):
        def search(user_name, search_dir):
            if not (os.path.isdir(search_dir) and
                    os.access(search_dir, os.X_OK | os.R_OK)):
                return []

            extensions = []

            for extension_name in os.listdir(search_dir):
                extension_dir = os.path.join(search_dir, extension_name)
                manifest_path = os.path.join(extension_dir, "MANIFEST")

                if not (os.path.isdir(extension_dir) and
                        os.access(extension_dir, os.X_OK | os.R_OK) and
                        os.access(manifest_path, os.R_OK)):
                    continue

                extensions.append(Extension(user_name, extension_name))

            return extensions

        extensions = search(None, configuration.extensions.SYSTEM_EXTENSIONS_DIR)

        if configuration.extensions.USER_EXTENSIONS_DIR:
            cursor = db.cursor()
            cursor.execute("SELECT name FROM users ORDER BY name ASC")

            for (user_name,) in cursor:
                try:
                    pwd_entry = pwd.getpwnam(user_name)
                except KeyError:
                    continue

                user_dir = os.path.join(
                    pwd_entry.pw_dir, configuration.extensions.USER_EXTENSIONS_DIR)

                extensions.extend(search(user_name, user_dir))

        return extensions

########NEW FILE########
__FILENAME__ = installation
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2012 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

from extensions.extension import Extension, ExtensionError

class InstallationError(Exception):
    def __init__(self, title, message, is_html=False):
        self.title = title
        self.message = message
        self.is_html = is_html

def doInstallExtension(db, user, extension, version):
    is_universal = user is None
    extension_id = extension.getExtensionID(db, create=True)
    manifest = extension.getManifest(version)

    # Detect conflicting extension installs.
    current_installs = Extension.getInstalls(db, user)
    for current_extension_id, _, _, current_is_universal in current_installs:
        # Two installs never conflict if one is universal and one is not.
        if is_universal != current_is_universal:
            continue

        try:
            current_extension = Extension.fromId(db, current_extension_id)
        except ExtensionError as error:
            # Invalid extension => no conflict.
            #
            # But if there would be a conflict, should the installed extension
            # later become valid again, then delete the installation.
            if extension.getName() == error.extension.getName():
                doUninstallExtension(db, user, error.extension)
            continue

        # Same extension => conflict
        #
        # The web UI will typically not let you try to do this; if the extension
        # is already installed the UI will only let you uninstall or upgrade it.
        # But you never know.  Also, there's a UNIQUE constraint in the database
        # that would prevent this, but with a significantly worse error message,
        # of course.
        if extension_id == current_extension_id:
            raise InstallationError(
                title="Conflicting install",
                message=("The extension <code>%s</code> is already "
                         "%sinstalled."
                         % (current_extension.getTitle(db),
                            "universally " if is_universal else "")),
                is_html=True)

        # Different extensions, same name => also conflict
        #
        # Two extensions with the same name are probably simply two forks of the
        # same extension, and are very likely to have overlapping and
        # conflicting functionality.  Also, extension resource paths only
        # contain the extension name as an identifier, and thus will conflict
        # between the two extensions, even if they are actually completely
        # unrelated.
        if extension.getName() == current_extension.getName():
            raise InstallationError(
                title="Conflicting install",
                message=("The extension <code>%s</code> is already "
                         "%sinstalled, and conflicts with the extension "
                         "<code>%s</code> since they have the same name."
                         % (current_extension.getTitle(db),
                            "universally " if is_universal else "",
                            extension.getTitle(db))),
                is_html=True)

    cursor = db.cursor()

    if is_universal:
        user_id = None
    else:
        user_id = user.id

    if version is not None:
        sha1 = extension.prepareVersionSnapshot(version)

        cursor.execute("""SELECT id
                            FROM extensionversions
                           WHERE extension=%s
                             AND name=%s
                             AND sha1=%s""",
                       (extension_id, version, sha1))
        row = cursor.fetchone()

        if row:
            (version_id,) = row
        else:
            cursor.execute("""INSERT INTO extensionversions (extension, name, sha1)
                                   VALUES (%s, %s, %s)
                                RETURNING id""",
                           (extension_id, version, sha1))
            (version_id,) = cursor.fetchone()

            for role in manifest.roles:
                role.install(db, version_id)
    else:
        version_id = None

    cursor.execute("""INSERT INTO extensioninstalls (uid, extension, version)
                           VALUES (%s, %s, %s)""",
                   (user_id, extension_id, version_id))

def doUninstallExtension(db, user, extension):
    extension_id = extension.getExtensionID(db)

    if extension_id is None:
        return

    cursor = db.cursor()

    if user is not None:
        cursor.execute("""DELETE FROM extensioninstalls
                                WHERE uid=%s
                                  AND extension=%s""",
                       (user.id, extension_id))
    else:
        cursor.execute("""DELETE FROM extensioninstalls
                                WHERE uid IS NULL
                                  AND extension=%s""",
                       (extension_id,))

def getExtension(author_name, extension_name):
    """Create an Extension object ignoring whether it is valid"""
    try:
        return Extension(author_name, extension_name)
    except ExtensionError as error:
        if error.extension is None:
            raise error
        return error.extension

def installExtension(db, user, author_name, extension_name, version):
    doInstallExtension(db, user, Extension(author_name, extension_name), version)
    db.commit()

def uninstallExtension(db, user, author_name, extension_name, version):
    doUninstallExtension(db, user, getExtension(author_name, extension_name))
    db.commit()

def reinstallExtension(db, user, author_name, extension_name, version):
    doUninstallExtension(db, user, getExtension(author_name, extension_name))
    doInstallExtension(db, user, Extension(author_name, extension_name), version)
    db.commit()

########NEW FILE########
__FILENAME__ = manifest
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2012 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import os
import re

import configuration
from textutils import json_decode

RE_ROLE_Page = re.compile(r"^\[Page (.*)\]$", re.IGNORECASE)
RE_ROLE_Inject = re.compile(r"^\[Inject (.*)\]$", re.IGNORECASE)
RE_ROLE_ProcessCommits = re.compile(r"^\[ProcessCommits\]$", re.IGNORECASE)
RE_ROLE_Scheduled = re.compile(r"^\[Scheduled\]$", re.IGNORECASE)

class ManifestError(Exception):
    pass

class Role:
    def __init__(self, location):
        self.script = None
        self.function = None
        self.description = None
        self.location = location

    def install(self, db, version_id):
        cursor = db.cursor()
        cursor.execute("""INSERT INTO extensionroles (version, script, function)
                               VALUES (%s, %s, %s)
                            RETURNING id""",
                       (version_id, self.script, self.function))
        return cursor.fetchone()[0]

    def process(self, name, value, location):
        if name == "description":
            self.description = value
            return True
        elif name == "script":
            self.script = value
            return True
        elif name == "function":
            self.function = value
            return True
        else:
            return False

    def check(self):
        if not self.description:
            raise ManifestError("%s: manifest error: expected role description" % self.location)
        elif not self.script:
            raise ManifestError("%s: manifest error: expected role script" % self.location)
        elif not self.function:
            raise ManifestError("%s: manifest error: expected role function" % self.location)

class URLRole(Role):
    def __init__(self, location, pattern):
        Role.__init__(self, location)
        self.pattern = pattern
        self.regexp = "^" + re.sub(r"[\|\[\](){}^$+]",
                                   lambda match: '\\' + match.group(0),
                                   pattern.replace('.', '\\.').replace('?', '.').replace('*', '.*')) + "$"

    def check(self):
        Role.check(self)
        if self.pattern.startswith("/"):
            raise ManifestError("%s: manifest error: path pattern should not start with a '/'" % self.location)

class PageRole(URLRole):
    def __init__(self, location, pattern):
        URLRole.__init__(self, location, pattern)

    def name(self):
        return "Page"

    def install(self, db, version_id):
        role_id = Role.install(self, db, version_id)
        cursor = db.cursor()
        cursor.execute("""INSERT INTO extensionpageroles (role, path)
                               VALUES (%s, %s)""",
                       (role_id, self.regexp))
        return role_id

class InjectRole(URLRole):
    def __init__(self, location, pattern):
        URLRole.__init__(self, location, pattern)

    def name(self):
        return "Inject"

    def process(self, name, value, location):
        if Role.process(self, name, value, location):
            return True
        if name == "cached":
            # Ignored for compatibility with extensions that use it.
            return True
        return False

    def install(self, db, version_id):
        role_id = Role.install(self, db, version_id)
        cursor = db.cursor()
        cursor.execute("""INSERT INTO extensioninjectroles (role, path)
                               VALUES (%s, %s)""",
                       (role_id, self.regexp))
        return role_id

class ProcessCommitsRole(Role):
    def __init__(self, location):
        Role.__init__(self, location)

    def name(self):
        return "ProcessCommits"

    def install(self, db, version_id):
        role_id = Role.install(self, db, version_id)
        cursor = db.cursor()
        cursor.execute("""INSERT INTO extensionprocesscommitsroles (role)
                               VALUES (%s)""",
                       (role_id,))
        return role_id

class ScheduledRole(Role):
    def __init__(self, location):
        Role.__init__(self, location)
        self.frequency = None
        self.at = None

    def name(self):
        return "Scheduled"

    def install(self, db, version_id):
        role_id = Role.install(self, db, version_id)
        cursor = db.cursor()
        cursor.execute("""INSERT INTO extensionscheduledroles (role, frequency, at)
                               VALUES (%s, %s, %s)""",
                       (role_id, self.frequency, self.at))
        return role_id

    def process(self, name, value, location):
        if Role.process(self, name, value, location):
            return True
        elif name == "frequency":
            if value in ("monthly", "weekly", "daily", "hourly"):
                self.frequency = value.lower()
            else:
                raise ManifestError("%s: invalid frequency: must be one of 'monthly', 'weekly', 'daily' and 'hourly'" % location)
        elif name == "at":
            self.at = value.lower()
        else:
            return False
        return True

    def check(self):
        Role.check(self)

        if not self.frequency:
            raise ManifestError("%s: manifest error: expected role parameter 'frequency'" % self.location)
        if not self.at:
            raise ManifestError("%s: manifest error: expected role parameter 'at'" % self.location)

        if self.frequency == "monthly":
            match = re.match("(\d+) (\d{2}):(\d{2})$", self.at)
            if match:
                date = int(match.group(1).lstrip("0"))
                hour = int(match.group(2).lstrip("0"))
                minute = int(match.group(3).lstrip("0"))
                if (1 <= date <= 31) and (0 <= hour <= 23) and (0 <= minute <= 59):
                    return
            raise ManifestError("invalid at specification for monthly trigger, must be 'D HH:MM' (D = day in month; 1-31), is '%s'" % self.at)
        elif self.frequency == "weekly":
            match = re.match("(?:mon(?:day)?|tue(?:sday)?|wed(?:nesday)?|thu(?:rsday)?|fri(?:day)?|sat(?:urday)?|sun(?:day)?) (\d{2}):(\d{2})$", self.at)
            if match:
                hour = int(match.group(1).lstrip("0"))
                minute = int(match.group(2).lstrip("0"))
                if (0 <= hour <= 23) and (0 <= minute <= 59):
                    return
            raise ManifestError("invalid at specification for weekly trigger, must be 'WEEKDAY HH:MM' (WEEKDAY = mon|tue|wed|thu|fri|sat|sun), is '%s'" % self.at)
        elif self.frequency == "daily":
            match = re.match("(\d{2}):(\d{2})$", self.at)
            if match:
                hour = int(match.group(1).lstrip("0"))
                minute = int(match.group(2).lstrip("0"))
                if (0 <= hour <= 23) and (0 <= minute <= 59):
                    return
            raise ManifestError("invalid at specification for daily trigger, must be 'HH:MM'")
        elif self.frequency == "hourly":
            match = re.match("(\d{2})$", self.at)
            if match:
                minute = int(match.group(1).lstrip("0"))
                if (0 <= minute <= 59):
                    return
            raise ManifestError("invalid at specification for hourly trigger, must be 'MM'")

class Author(object):
    def __init__(self, value):
        match = re.match(r"\s*(.*?)\s+<(.+?)>\s*$", value)
        if match:
            self.name, self.email = match.groups()
        else:
            self.name = value.strip()
            self.email = None

class Manifest(object):
    def __init__(self, path, source=None):
        self.path = path
        self.source = source
        self.authors = []
        self.description = None
        self.flavor = configuration.extensions.DEFAULT_FLAVOR
        self.roles = []
        self.status = None
        self.hidden = False

    def isAuthor(self, db, user):
        for author in self.authors:
            if author.name in (user.name, user.fullname) \
                    or user.hasGitEmail(db, author.email):
                return True
        return False

    def getAuthors(self):
        return self.authors

    def read(self):
        path = os.path.join(self.path, "MANIFEST")

        if self.source:
            lines = self.source.splitlines()
        else:
            try:
                lines = open(path).readlines()
            except IOError:
                raise ManifestError("%s: file not found" % path)

        lines = map(str.strip, lines)

        def process(value):
            value = value.strip()
            if value[0] == '"' == value[-1]:
                return json_decode(value)
            else:
                return value

        role = None

        for index, line in enumerate(lines):
            if not line or line.lstrip().startswith("#"): continue

            location = "%s:%d" % (path, index + 1)

            if not role:
                try:
                    name, value = line.split("=", 1)
                    if name.strip().lower() == "author":
                        for value in process(value).split(","):
                            self.authors.append(Author(value))
                        continue
                    elif name.strip().lower() == "description":
                        self.description = process(value)
                        continue
                    elif name.strip().lower() == "flavor":
                        self.flavor = process(value)
                        if self.flavor not in configuration.extensions.FLAVORS:
                            raise ManifestError("%s: manifest error: unsupported 'flavor', supported values are: %s"
                                                % (location, ", ".join(map(repr, configuration.extensions.FLAVORS.keys()))))
                        continue
                    elif name.strip().lower() == "hidden":
                        value = process(value).lower()
                        if value in ("true", "yes"):
                            self.hidden = True
                        elif value not in ("false", "no"):
                            raise ManifestError("%s: manifest error: valid values for 'hidden' are 'true'/'yes' and 'false'/'no'" % location)
                        continue
                except:
                    pass

                if not self.authors:
                    raise ManifestError("%s: manifest error: expected extension author" % location)
                elif not self.description:
                    raise ManifestError("%s: manifest error: expected extension description" % location)

            if role:
                if "=" in line:
                    name, value = line.split("=", 1)
                    if role.process(name.strip().lower(), process(value), location):
                        continue

                role.check()

                self.roles.append(role)

            match = RE_ROLE_Page.match(line)
            if match:
                role = PageRole(location, match.group(1))
                continue

            match = RE_ROLE_Inject.match(line)
            if match:
                role = InjectRole(location, match.group(1))
                continue

            match = RE_ROLE_ProcessCommits.match(line)
            if match:
                role = ProcessCommitsRole(location)
                continue

            match = RE_ROLE_Scheduled.match(line)
            if match:
                role = ScheduledRole(location)
                continue

            raise ManifestError("%s: manifest error: unexpected line: %r" % (location, line))

        if not self.authors:
            raise ManifestError("%s: manifest error: expected extension author" % path)
        elif not self.description:
            raise ManifestError("%s: manifest error: expected extension description" % path)

        if role:
            role.check()
            self.roles.append(role)

        if not self.roles:
            raise ManifestError("%s: manifest error: no roles defined" % path)

    @staticmethod
    def load(extension_path):
        manifest = Manifest(extension_path)
        manifest.read()
        return manifest

########NEW FILE########
__FILENAME__ = resource
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2012 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import os
import errno

import configuration

from extensions import getExtensionPath, getExtensionInstallPath

def get(req, db, user, path):
    extension_name, resource_path = path.split("/", 1)

    cursor = db.cursor()
    cursor.execute("""SELECT users.name, extensionversions.sha1
                        FROM extensions
                        JOIN extensioninstalls ON (extensioninstalls.extension=extensions.id)
             LEFT OUTER JOIN extensionversions ON (extensionversions.id=extensioninstalls.version)
             LEFT OUTER JOIN users ON (users.id=extensions.author)
                       WHERE extensions.name=%s
                         AND (extensioninstalls.uid=%s OR extensioninstalls.uid IS NULL)
                    ORDER BY extensioninstalls.uid ASC NULLS LAST
                       LIMIT 1""",
                   (extension_name, user.id))

    row = cursor.fetchone()

    if not row:
        return None, None

    author_name, version_sha1 = row

    if version_sha1 is None:
        extension_path = getExtensionPath(author_name, extension_name)
    else:
        extension_path = getExtensionInstallPath(version_sha1)

    resource_path = os.path.join(extension_path, "resources", resource_path)

    def guessContentType(name):
        try:
            name, ext = name.split(".", 1)
            return configuration.mimetypes.MIMETYPES[ext]
        except:
            return "application/octet-stream"

    try:
        with open(resource_path) as resource_file:
            resource = resource_file.read()
    except IOError as error:
        if error.errno in (errno.ENOENT, errno.EACCES):
            return None, None
        raise
    else:
        return guessContentType(resource_path), resource

########NEW FILE########
__FILENAME__ = inject
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2012 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import re
import urlparse

import configuration

from communicate import ProcessTimeout, ProcessError
from htmlutils import jsify
from request import decodeURIComponent
from textutils import json_decode, json_encode

from extensions import getExtensionInstallPath
from extensions.extension import Extension, ExtensionError
from extensions.execute import executeProcess
from extensions.manifest import Manifest, ManifestError, InjectRole

class InjectError(Exception):
    pass

def processLine(paths, line):
    try:
        command, value = line.split(" ", 1)
    except ValueError:
        raise InjectError("Invalid line in output: %r" % line)

    if command not in ("link", "script", "stylesheet", "preference"):
        raise InjectError("Invalid command: %r" % command)

    value = value.strip()

    try:
        value = json_decode(value)
    except ValueError:
        raise InjectError("Invalid JSON: %r" % value)

    def is_string(value):
        return isinstance(value, basestring)

    if command in ("script", "stylesheet") and not is_string(value):
        raise InjectError("Invalid value for %r: %r (expected string)"
                          % (command, value))
    elif command == "link":
        if isinstance(value, dict):
            if "label" not in value or not is_string(value["label"]):
                raise InjectError("Invalid value for %r: %r (expected attribute 'label' of type string)"
                                  % (command, value))
            elif "url" not in value or not is_string(value["url"]) or value["url"] is None:
                raise InjectError("Invalid value for %r: %r (expected attribute 'url' of type string or null)"
                                  % (command, value))
        # Alternatively support [label, url] (backwards compatibility).
        elif not isinstance(value, list) or len(value) != 2:
            raise InjectError("Invalid value for %r: %r (expected object { \"label\": LABEL, \"url\": URL })"
                              % (command, value))
        elif not is_string(value[0]):
            raise InjectError("Invalid value for %r: %r (expected string at array[0])"
                              % (command, value))
        elif not (is_string(value[1]) or value[1] is None):
            raise InjectError("Invalid value for %r: %r (expected string or null at array[1])"
                              % (command, value))
        else:
            value = { "label": value[0], "url": value[1] }
    elif command == "preference":
        if "config" not in paths:
            raise InjectError("Invalid command: %r only valid on /config page"
                              % command)
        elif not isinstance(value, dict):
            raise InjectError("Invalid value for %r: %r (expected object)"
                              % (command, value))

        for name in ("url", "name", "type", "value", "default", "description"):
            if name not in value:
                raise InjectError("Invalid value for %r: %r (missing attribute %r)"
                                  % (command, value, name))

        preference_url = value["url"]
        preference_name = value["name"]
        preference_type = value["type"]
        preference_value = value["value"]
        preference_default = value["default"]
        preference_description = value["description"]

        if not is_string(preference_url):
            raise InjectError("Invalid value for %r: %r (expected attribute 'url' of type string)"
                              % (command, value))
        elif not is_string(preference_name):
            raise InjectError("Invalid value for %r: %r (expected attribute 'name' of type string)"
                              % (command, value))
        elif not is_string(preference_description):
            raise InjectError("Invalid value for %r: %r (expected attribute 'description' of type string)"
                              % (command, value))

        if is_string(preference_type):
            if preference_type not in ("boolean", "integer", "string"):
                raise InjectError("Invalid value for %r: %r (unsupported preference type)"
                                  % (command, value))

            if preference_type == "boolean":
                type_check = lambda value: isinstance(value, bool)
            elif preference_type == "integer":
                type_check = lambda value: isinstance(value, int)
            else:
                type_check = is_string

            if not type_check(preference_value):
                raise InjectError("Invalid value for %r: %r (type mismatch between 'value' and 'type')"
                                  % (command, value))

            if not type_check(preference_default):
                raise InjectError("Invalid value for %r: %r (type mismatch between 'default' and 'type')"
                                  % (command, value))
        else:
            if not isinstance(preference_type, list):
                raise InjectError("Invalid value for %r: %r (invalid 'type', expected string or array)"
                                  % (command, value))

            for index, choice in enumerate(preference_type):
                if not isinstance(choice, dict) \
                        or not isinstance(choice.get("value"), basestring) \
                        or not isinstance(choice.get("title"), basestring):
                    raise InjectError("Invalid value for %r: %r (invalid preference choice: %r)"
                                      % (command, value, choice))

            choices = set([choice["value"] for choice in preference_type])

            if not is_string(preference_value) or preference_value not in choices:
                raise InjectError("Invalid value for %r: %r ('value' not among valid choices)"
                                  % (command, value))

            if not is_string(preference_default) or preference_default not in choices:
                raise InjectError("Invalid value for %r: %r ('default' not among valid choices)"
                                  % (command, value))

    return (command, value)

def execute(db, req, user, document, links, injected, profiler=None):
    cursor = db.cursor()

    installs = Extension.getInstalls(db, user)

    def get_matching_path(path_regexp):
        if re.match(path_regexp, req.path):
            return (req.path, req.query)
        elif re.match(path_regexp, req.original_path):
            return (req.original_path, req.original_query)
        else:
            return None, None

    query = None

    for extension_id, version_id, version_sha1, is_universal in installs:
        handlers = []

        try:
            if version_id is not None:
                cursor.execute("""SELECT script, function, path
                                    FROM extensionroles
                                    JOIN extensioninjectroles ON (role=id)
                                   WHERE version=%s
                                ORDER BY id ASC""",
                               (version_id,))

                for script, function, path_regexp in cursor:
                    path, query = get_matching_path(path_regexp)
                    if path is not None:
                        handlers.append((path, query, script, function))

                if not handlers:
                    continue

                extension = Extension.fromId(db, extension_id)
                manifest = Manifest.load(getExtensionInstallPath(version_sha1))
            else:
                extension = Extension.fromId(db, extension_id)
                manifest = Manifest.load(extension.getPath())

                for role in manifest.roles:
                    if isinstance(role, InjectRole):
                        path, query = get_matching_path(role.regexp)
                        if path is not None:
                            handlers.append((path, query, role.script, role.function))

                if not handlers:
                    continue

            def construct_query(query):
                if not query:
                    return "null"

                params = urlparse.parse_qs(query, keep_blank_values=True)

                for key in params:
                    values = params[key]
                    if len(values) == 1:
                        if not values[0]:
                            params[key] = None
                        else:
                            params[key] = values[0]

                return ("Object.freeze({ raw: %s, params: Object.freeze(%s) })"
                        % (json_encode(query), json_encode(params)))

            preferences = None
            commands = []

            for path, query, script, function in handlers:
                argv = "[%s, %s]" % (jsify(path), construct_query(query))

                try:
                    stdout_data = executeProcess(
                        manifest, "inject", script, function, extension_id, user.id, argv,
                        configuration.extensions.SHORT_TIMEOUT)
                except ProcessTimeout:
                    raise InjectError("Timeout after %d seconds." % configuration.extensions.SHORT_TIMEOUT)
                except ProcessError as error:
                    if error.returncode < 0:
                        raise InjectError("Process terminated by signal %d." % -error.returncode)
                    else:
                        raise InjectError("Process returned %d.\n%s" % (error.returncode, error.stderr))

                for line in stdout_data.splitlines():
                    if line.strip():
                        commands.append(processLine(path, line.strip()))

            for command, value in commands:
                if command == "script":
                    document.addExternalScript(value, use_static=False, order=1)
                elif command == "stylesheet":
                    document.addExternalStylesheet(value, use_static=False, order=1)
                elif command == "link":
                    for index, (_, label, _, _) in enumerate(links):
                        if label == value["label"]:
                            if value["url"] is None:
                                del links[index]
                            else:
                                links[index][0] = value["url"]
                            break
                    else:
                        if value["url"] is not None:
                            links.append([value["url"], value["label"], None, None])
                elif command == "preference":
                    if not preferences:
                        preferences = []
                        injected.setdefault("preferences", []).append(
                            (extension.getName(), extension.getAuthor(db), preferences))
                    preferences.append(value)

            if profiler:
                profiler.check("inject: %s" % extension.getKey())
        except ExtensionError as error:
            document.comment("\n\n[%s] Extension error:\nInvalid extension:\n%s\n\n"
                             % (error.extension.getKey(), error.message))
        except ManifestError as error:
            document.comment("\n\n[%s] Extension error:\nInvalid MANIFEST:\n%s\n\n"
                             % (extension.getKey(), error.message))
        except InjectError as error:
            document.comment("\n\n[%s] Extension error:\n%s\n\n"
                             % (extension.getKey(), error.message))

########NEW FILE########
__FILENAME__ = page
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2012 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import time
import re

import configuration

from communicate import ProcessTimeout, ProcessError
from htmlutils import jsify
from request import decodeURIComponent

from extensions import getExtensionInstallPath
from extensions.extension import Extension, ExtensionError
from extensions.execute import executeProcess
from extensions.manifest import Manifest, ManifestError, PageRole
from extensions.utils import renderTutorial

def execute(db, req, user):
    cursor = db.cursor()

    installs = Extension.getInstalls(db, user)

    argv = None
    stdin_data = None

    for extension_id, version_id, version_sha1, is_universal in installs:
        handlers = []

        if version_id is not None:
            cursor.execute("""SELECT script, function, path
                                FROM extensionroles
                                JOIN extensionpageroles ON (role=id)
                               WHERE version=%s
                            ORDER BY id ASC""",
                           (version_id,))

            for script, function, path_regexp in cursor:
                if re.match(path_regexp, req.path):
                    handlers.append((script, function))

            if not handlers:
                continue

            extension_path = getExtensionInstallPath(version_sha1)
            manifest = Manifest.load(extension_path)
        else:
            try:
                extension = Extension.fromId(db, extension_id)
            except ExtensionError:
                # If the author/hosting user no longer exists, or the extension
                # directory no longer exists or is inaccessible, ignore the
                # extension.
                continue

            try:
                manifest = Manifest.load(extension.getPath())
            except ManifestError:
                # If the MANIFEST is missing or invalid, we can't know whether
                # the extension has a page role handling the path, so assume it
                # doesn't and ignore it.
                continue

            for role in manifest.roles:
                if isinstance(role, PageRole) and re.match(role.regexp, req.path):
                    handlers.append((role.script, role.function))

            if not handlers:
                continue

        if argv is None:
            def param(raw):
                parts = raw.split("=", 1)
                if len(parts) == 1:
                    return "%s: null" % jsify(decodeURIComponent(raw))
                else:
                    return "%s: %s" % (jsify(decodeURIComponent(parts[0])),
                                       jsify(decodeURIComponent(parts[1])))

            if req.query:
                query = ("Object.freeze({ raw: %s, params: Object.freeze({ %s }) })"
                         % (jsify(req.query),
                            ", ".join(map(param, req.query.split("&")))))
            else:
                query = "null"

            headers = ("Object.freeze({ %s })"
                       % ", ".join(("%s: %s" % (jsify(name), jsify(value)))
                                   for name, value in req.getRequestHeaders().items()))

            argv = ("[%(method)s, %(path)s, %(query)s, %(headers)s]"
                    % { 'method': jsify(req.method),
                        'path': jsify(req.path),
                        'query': query,
                        'headers': headers })

        if req.method == "POST":
            if stdin_data is None:
                stdin_data = req.read()

        for script, function in handlers:
            before = time.time()

            try:
                stdout_data = executeProcess(
                    manifest, "page", script, function, extension_id, user.id,
                    argv, configuration.extensions.LONG_TIMEOUT, stdin=stdin_data)
            except ProcessTimeout:
                req.setStatus(500, "Extension Timeout")
                return "Extension timed out!"
            except ProcessError as error:
                req.setStatus(500, "Extension Failure")
                if error.returncode < 0:
                    return ("Extension failure: terminated by signal %d\n"
                            % -error.returncode)
                else:
                    return ("Extension failure: returned %d\n%s"
                            % (error.returncode, error.stderr))

            after = time.time()

            status = None
            headers = {}

            if not stdout_data:
                return False

            while True:
                try: line, stdout_data = stdout_data.split("\n", 1)
                except:
                    req.setStatus(500, "Extension Error")
                    return "Extension error: output format error.\n%r\n" % stdout_data

                if status is None:
                    try: status = int(line.strip())
                    except:
                        req.setStatus(500, "Extension Error")
                        return "Extension error: first line should contain only a numeric HTTP status code.\n%r\n" % line
                elif not line:
                    break
                else:
                    try: name, value = line.split(":", 1)
                    except:
                        req.setStatus(500, "Extension Error")
                        return "Extension error: header line should be on 'name: value' format.\n%r\n" % line
                    headers[name.strip()] = value.strip()

            if status is None:
                req.setStatus(500, "Extension Error")
                return "Extension error: first line should contain only a numeric HTTP status code.\n"

            content_type = "text/plain"

            for name, value in headers.items():
                if name.lower() == "content-type":
                    content_type = value
                    del headers[name]
                else:
                    headers[name] = value

            req.setStatus(status)
            req.setContentType(content_type)

            for name, value in headers.items():
                req.addResponseHeader(name, value)

            if content_type == "text/tutorial":
                req.setContentType("text/html")
                return renderTutorial(db, user, stdout_data)

            if content_type.startswith("text/html"):
                stdout_data += "\n\n<!-- extension execution time: %.2f seconds -->\n" % (after - before)

            return stdout_data

    return False

########NEW FILE########
__FILENAME__ = processcommits
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2012 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import re

import configuration
import gitutils

import log.commitset
import changeset.utils

from communicate import ProcessTimeout, ProcessError

from extensions import getExtensionInstallPath
from extensions.extension import Extension
from extensions.execute import executeProcess
from extensions.manifest import Manifest, ManifestError, ProcessCommitsRole

def execute(db, user, review, all_commits, old_head, new_head, output):
    cursor = db.cursor()

    installs = Extension.getInstalls(db, user)

    data = None

    for extension_id, version_id, version_sha1, is_universal in installs:
        handlers = []

        if version_id is not None:
            cursor.execute("""SELECT script, function
                                FROM extensionroles
                                JOIN extensionprocesscommitsroles ON (role=id)
                               WHERE version=%s
                            ORDER BY id ASC""",
                           (version_id,))

            handlers.extend(cursor)

            if not handlers:
                continue

            extension_path = getExtensionInstallPath(version_sha1)
            manifest = Manifest.load(extension_path)
        else:
            extension = Extension.fromId(db, extension_id)
            manifest = Manifest.load(extension.getPath())

            for role in manifest.roles:
                if isinstance(role, ProcessCommitsRole):
                    handlers.append((role.script, role.function))

            if not handlers:
                continue

        if data is None:
            commitset = log.commitset.CommitSet(all_commits)

            assert old_head is None or old_head in commitset.getTails()
            assert new_head in commitset.getHeads()
            assert len(commitset.getHeads()) == 1

            tails = commitset.getFilteredTails(review.repository)
            if len(tails) == 1:
                tail = gitutils.Commit.fromSHA1(db, review.repository, tails.pop())
                changeset_id = changeset.utils.createChangeset(
                    db, user, review.repository, from_commit=tail, to_commit=new_head)[0].id
                changeset_arg = "repository.getChangeset(%d)" % changeset_id
            else:
                changeset_arg = "null"

            commits_arg = "[%s]" % ",".join(
                [("repository.getCommit(%d)" % commit.getId(db))
                 for commit in all_commits])

            data = { "review_id": review.id,
                     "changeset": changeset_arg,
                     "commits": commits_arg }

        for script, function in handlers:
            class Error(Exception):
                pass

            def print_header():
                header = "%s::%s()" % (script, function)
                print >>output, ("\n[%s] %s\n[%s] %s"
                                 % (extension.getName(), header,
                                    extension.getName(), "=" * len(header)))

            try:
                argv = """

(function ()
 {
   var review = new critic.Review(%(review_id)d);
   var repository = review.repository;
   var changeset = %(changeset)s;
   var commitset = new critic.CommitSet(%(commits)s);

   return [review, changeset, commitset];
 })()

""" % data
                argv = re.sub("[ \n]+", " ", argv.strip())

                try:
                    stdout_data = executeProcess(
                        manifest, "processcommits", script, function, extension_id, user.id,
                        argv, configuration.extensions.SHORT_TIMEOUT)
                except ProcessTimeout:
                    raise Error("Timeout after %d seconds." % configuration.extensions.SHORT_TIMEOUT)
                except ProcessError as error:
                    if error.returncode < 0:
                        raise Error("Process terminated by signal %d." % -error.returncode)
                    else:
                        raise Error("Process returned %d.\n%s" % (error.returncode, error.stderr))

                if stdout_data.strip():
                    print_header()
                    for line in stdout_data.splitlines():
                        print >>output, "[%s] %s" % (extension.getName(), line)
            except Error as error:
                print_header()
                print >>output, "[%s] Extension error: %s" % (extension.getName(), error.message)

########NEW FILE########
__FILENAME__ = utils
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2012 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import htmlutils
import page.utils
import textformatting

def renderTutorial(db, user, source):
    document = htmlutils.Document()

    document.addExternalStylesheet("resource/tutorial.css")
    document.addExternalScript("resource/tutorial.js")
    document.addInternalStylesheet("div.main table td.text { %s }" % user.getPreference(db, "style.tutorialFont"))

    html = document.html()
    head = html.head()
    body = html.body()

    page.utils.generateHeader(body, db, user)

    table = body.div("main").table("paleyellow", align="center")
    textformatting.renderFormatted(db, user, table, source.splitlines(), toc=True)

    return str(document)

########NEW FILE########
__FILENAME__ = gitutils
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2012 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import subprocess
import re
import time
import atexit
import os
import traceback
import threading
import tempfile
import shutil
import stat

import base
import configuration
import textutils
import htmlutils
import communicate
import diff.parse

re_author_committer = re.compile("(.*) <(.*)> ([0-9]+ [-+][0-9]+)")
re_sha1 = re.compile("^[A-Za-z0-9]{40}$")

REPOSITORY_RELAYCOPY_DIR = os.path.join(configuration.paths.DATA_DIR, "relay")
REPOSITORY_WORKCOPY_DIR = os.path.join(configuration.paths.DATA_DIR, "temporary")

def same_filesystem(pathA, pathB):
    return os.stat(pathA).st_dev == os.stat(pathB).st_dev

def getGitEnvironment(author=True, committer=True):
    env = {}
    def name(parameter):
        if parameter is True:
            return "Critic System"
        elif isinstance(parameter, CommitUserTime):
            return parameter.name
        else:
            return parameter.fullname
    def email(parameter):
        if parameter is True or not parameter.email:
            return configuration.base.SYSTEM_USER_EMAIL
        else:
            return parameter.email
    if author:
        env["GIT_AUTHOR_NAME"] = name(author)
        env["GIT_AUTHOR_EMAIL"] = email(author)
    if committer:
        env["GIT_COMMITTER_NAME"] = name(committer)
        env["GIT_COMMITTER_EMAIL"] = email(committer)
    return env

class GitError(base.Error):
    pass

class GitReferenceError(GitError):
    """Exception raised on an invalid SHA-1s or refs."""

    def __init__(self, message, sha1=None, ref=None, repository=None):
        super(GitReferenceError, self).__init__(message)
        self.sha1 = sha1
        self.ref = ref
        self.repository = repository

class GitCommandError(GitError):
    """Exception raised when a Git command fails."""

    def __init__(self, cmdline, output, cwd):
        super(GitCommandError, self).__init__("'%s' failed: %s (in %s)" % (cmdline, output, cwd))
        self.cmdline = cmdline
        self.output = output
        self.cwd = cwd

class GitObject:
    def __init__(self, sha1, type, size, data):
        self.sha1 = sha1
        self.type = type
        self.size = size
        self.data = data

    def __getitem__(self, index):
        if index == 0: return self.type
        elif index == 1: return self.size
        elif index == 2: return self.data
        raise IndexError("GitObject index out of range: %d" % index)

class GitHttpBackendError(GitError):
    def __init__(self, returncode, stderr):
        message = "Git failed!"
        if returncode < 0:
            message = "Git terminated by signal %d!" % -returncode
        elif returncode > 0:
            message = "Git exited with status %d!" % returncode
        if stderr.strip():
            message += "\n" + stderr
        super(GitHttpBackendError, self).__init__(message)
        self.returncode = returncode
        self.stderr = stderr

class GitHttpBackendNeedsUser(GitError):
    pass

class NoSuchRepository(base.Error):
    """Exception raised by Repository.fromName() for invalid names."""

    def __init__(self, value):
        super(NoSuchRepository, self).__init__("No such repository: %s" % str(value))
        self.value = value

class Repository:
    class FromParameter:
        def __init__(self, db): self.db = db
        def __call__(self, value): return Repository.fromParameter(self.db, value)

    def __init__(self, db=None, repository_id=None, parent=None, main_branch_id=None, name=None, path=None):
        assert path

        self.id = repository_id
        self.name = name
        self.path = path
        self.parent = parent

        self.__main_branch = None
        self.__main_branch_id = main_branch_id
        self.__batch = None
        self.__batchCheck = None
        self.__cacheBlobs = False
        self.__cacheDisabled = False

        if db:
            self.__db = db
            db.storage["Repository"][repository_id] = self
            db.storage["Repository"][name] = self
            db.atexit(self.__terminate)
        else:
            self.__db = None
            atexit.register(self.__terminate)

        self.__startBatch()

    def __str__(self):
        return self.path

    def getURL(self, db, user):
        return Repository.constructURL(db, user, self.path)

    @staticmethod
    def constructURL(db, user, path):
        path = os.path.relpath(path, configuration.paths.GIT_DIR)
        url_type = user.getPreference(db, "repository.urlType")

        if url_type == "git":
            url_format = "git://%s/%s"
        elif url_type in ("ssh", "host"):
            if url_type == "ssh":
                prefix = "ssh://%s"
            else:
                prefix = "%s:"
            url_format = prefix + os.path.join(configuration.paths.GIT_DIR, "%s")
        elif configuration.base.ACCESS_SCHEME == "http":
            url_format = "http://%s/%s"
        elif configuration.base.ACCESS_SCHEME == "https":
            url_format = "https://%s/%s"
        elif user.isAnonymous():
            url_format = "http://%s/%s"
        else:
            url_format = "https://%s/%s"

        return url_format % (configuration.base.HOSTNAME, path)

    def enableBlobCache(self):
        assert self.__db
        self.__cacheBlobs = True

    def disableCache(self):
        self.__cacheDisabled = True

    def hasMainBranch(self):
        return self.__main_branch_id is not None

    def getMainBranch(self, db):
        import dbutils
        if not self.__main_branch:
            if self.__main_branch_id is not None:
                self.__main_branch = dbutils.Branch.fromId(db, self.__main_branch_id, load_commits=False)
        return self.__main_branch

    @staticmethod
    def fromId(db, repository_id):
        if repository_id in db.storage["Repository"]:
            return db.storage["Repository"][repository_id]
        else:
            cursor = db.cursor()
            cursor.execute("SELECT parent, branch, name, path FROM repositories WHERE id=%s", (repository_id,))
            try:
                parent_id, main_branch_id, name, path = cursor.fetchone()
                parent = None if parent_id is None else Repository.fromId(db, parent_id)
                return Repository(db, repository_id=repository_id, parent=parent, main_branch_id=main_branch_id, name=name, path=path)
            except:
                return None

    @staticmethod
    def fromName(db, name):
        if name in db.storage["Repository"]:
            return db.storage["Repository"][name]
        else:
            cursor = db.cursor()
            cursor.execute("SELECT id FROM repositories WHERE name=%s", (name,))
            try: return Repository.fromId(db, cursor.fetchone()[0])
            except: return None

    @staticmethod
    def fromParameter(db, parameter):
        try: repository = Repository.fromId(db, int(parameter))
        except: repository = Repository.fromName(db, parameter)
        if repository: return repository
        else: raise NoSuchRepository(parameter)

    @staticmethod
    def fromSHA1(db, sha1):
        cursor = db.cursor()
        cursor.execute("SELECT id FROM repositories ORDER BY id ASC")
        for (repository_id,) in cursor:
            repository = Repository.fromId(db, repository_id)
            if repository.iscommit(sha1): return repository
        raise GitReferenceError(
            "Couldn't find commit %s in any repository." % sha1,
            sha1=sha1)

    @staticmethod
    def fromPath(db, path):
        if not path.startswith(configuration.paths.GIT_DIR):
            path = os.path.join(configuration.paths.GIT_DIR, path)
        if not path.endswith(".git"):
            path += ".git"
        cursor = db.cursor()
        cursor.execute("SELECT id FROM repositories WHERE path=%s", (path,))
        for (repository_id,) in cursor:
            return Repository.fromId(db, repository_id)
        raise NoSuchRepository(path)

    def __terminate(self, db=None):
        self.stopBatch()

    def __startBatch(self):
        if self.__batch is None:
            self.__batch = subprocess.Popen(
                [configuration.executables.GIT, 'cat-file', '--batch'],
                stdin=subprocess.PIPE, stdout=subprocess.PIPE,
                stderr=subprocess.STDOUT, cwd=self.path)

    def __startBatchCheck(self):
        if self.__batchCheck is None:
            self.__batchCheck = subprocess.Popen(
                [configuration.executables.GIT, 'cat-file', '--batch-check'],
                stdin=subprocess.PIPE, stdout=subprocess.PIPE,
                stderr=subprocess.STDOUT, cwd=self.path)

    def stopBatch(self):
        if self.__batch:
            try: os.kill(self.__batch.pid, 9)
            except: pass
            try: self.__batch.wait()
            except: pass
            self.__batch = None
        if self.__batchCheck:
            try: os.kill(self.__batchCheck.pid, 9)
            except: pass
            try: self.__batchCheck.wait()
            except: pass
            self.__batchCheck = None

    @staticmethod
    def forEach(db, fn):
        for key, repository in db.storage["Repository"].items():
            if isinstance(key, int):
                fn(db, repository)

    def getJS(self):
        return "var repository = critic.repository = new Repository(%d, %s, %s);" % (self.id, htmlutils.jsify(self.name), htmlutils.jsify(self.path))

    def getModuleRepository(self, db, commit, path):
        tree = Tree.fromPath(commit, "/")
        source = self.fetch(tree[".gitmodules"].sha1).data
        lines = iter(source.splitlines())

        for line in lines:
            if line == ('[submodule "%s"]' % path): break
        else: return None

        for line in lines:
            line = line.strip()

            if not line or line[0] == "#": continue
            elif line[0] == "[": return None

            key, value = map(str.strip, line.split("="))

            if key == "url":
                path = os.path.abspath(os.path.join(self.path, value))

                cursor = db.cursor()
                cursor.execute("SELECT id FROM repositories WHERE path=%s", (path,))

                row = cursor.fetchone()
                if row:
                    return Repository.fromId(db, row[0])
                else:
                    return None
        else:
            return None

    def fetch(self, sha1, fetchData=True):
        if self.__db:
            cache = self.__db.storage["Repository"]
            cached_object = cache.get("object:" + sha1)
            if cached_object:
                self.__db.recordProfiling("fetch: " + cached_object.type + " (cached)", 0)
                return cached_object

        before = time.time()

        if fetchData:
            self.__startBatch()
            stdin, stdout = self.__batch.stdin, self.__batch.stdout
        else:
            self.__startBatchCheck()
            stdin, stdout = self.__batchCheck.stdin, self.__batchCheck.stdout

        try: stdin.write(sha1 + '\n')
        except: raise GitError("failed when writing to 'git cat-file' stdin: %s" % stdout.read())

        line = stdout.readline()

        if line == ("%s missing\n" % sha1):
            raise GitReferenceError("%s missing from %s" % (sha1[:8], self.path), sha1=sha1, repository=self)

        try: sha1, type, size = line.split()
        except: raise GitError("unexpected output from 'git cat-file --batch': %s" % line)

        size = int(size)

        if fetchData:
            data = stdout.read(size)
            stdout.read(1)
        else:
            data = None

        git_object = GitObject(sha1, type, size, data)

        after = time.time()

        if not self.__cacheDisabled and (type != "blob" or self.__cacheBlobs):
            cache["object:" + sha1] = git_object

        if self.__db:
            self.__db.recordProfiling("fetch: " + type, after - before)

        return git_object

    def run(self, command, *arguments, **kwargs):
        return self.runCustom(self.path, command, *arguments, **kwargs)

    def runCustom(self, cwd, command, *arguments, **kwargs):
        argv = [configuration.executables.GIT, command]
        argv.extend(arguments)
        stdin_data = kwargs.get("input")
        if stdin_data is None: stdin = None
        else: stdin = subprocess.PIPE
        env = {}
        env.update(os.environ)
        env.update(configuration.executables.GIT_ENV)
        env.update(kwargs.get("env", {}))
        if "GIT_DIR" in env: del env["GIT_DIR"]
        git = subprocess.Popen(argv, stdin=stdin, stdout=subprocess.PIPE,
                               stderr=subprocess.PIPE, cwd=cwd, env=env)
        stdout, stderr = git.communicate(stdin_data)
        if kwargs.get("check_errors", True):
            if git.returncode == 0:
                if kwargs.get("include_stderr", False):
                    return stdout + stderr
                else:
                    return stdout
            else:
                cmdline = " ".join(argv)
                output = stderr.strip()
                raise GitCommandError(cmdline, output, cwd)
        else:
            return git.returncode, stdout, stderr

    def createBranch(self, name, startpoint):
        argv = [configuration.executables.GIT, 'branch', name, startpoint]
        git = subprocess.Popen(argv, stdout=subprocess.PIPE,
                               stderr=subprocess.PIPE, cwd=self.path)
        stdout, stderr = git.communicate()
        if git.returncode != 0:
            cmdline = " ".join(argv)
            output = stderr.strip()
            raise GitCommandError(cmdline, output, self.path)

    def deleteBranch(self, name):
        argv = [configuration.executables.GIT, 'branch', '-D', name]
        git = subprocess.Popen(argv, stdout=subprocess.PIPE,
                               stderr=subprocess.PIPE, cwd=self.path)
        stdout, stderr = git.communicate()
        if git.returncode != 0:
            cmdline = " ".join(argv)
            output = stderr.strip()
            raise GitCommandError(cmdline, output, self.path)

    def mergebase(self, commit_or_commits, db=None):
        if db and isinstance(commit_or_commits, Commit):
            cursor = db.cursor()
            cursor.execute("SELECT mergebase FROM mergebases WHERE commit=%s", (commit_or_commits.getId(db),))
            try:
                return cursor.fetchone()[0]
            except:
                result = self.mergebase(commit_or_commits)
                cursor.execute("INSERT INTO mergebases (commit, mergebase) VALUES (%s, %s)", (commit_or_commits.getId(db), result))
                return result

        try: sha1s = commit_or_commits.parents
        except: sha1s = map(str, commit_or_commits)

        assert len(sha1s) >= 2

        argv = [configuration.executables.GIT, 'merge-base'] + sha1s
        git = subprocess.Popen(argv, stdout=subprocess.PIPE,
                               stderr=subprocess.PIPE, cwd=self.path)
        stdout, stderr = git.communicate()
        if git.returncode == 0: return stdout.strip()
        else:
            cmdline = " ".join(argv)
            output = stderr.strip()
            raise GitCommandError(cmdline, output, self.path)

    def getCommonAncestor(self, commit_or_commits):
        try: sha1s = commit_or_commits.parents
        except: sha1s = list(commit_or_commits)

        assert len(sha1s) >= 2

        mergebases = [self.mergebase([sha1s[0], sha1]) for sha1 in sha1s[1:]]

        if len(mergebases) == 1: return mergebases[0]
        else: return self.getCommonAncestor(mergebases)

    def revparse(self, name):
        git = subprocess.Popen(
            [configuration.executables.GIT, 'rev-parse', '--verify', '--quiet', name],
            stdout=subprocess.PIPE, stderr=subprocess.PIPE, cwd=self.path)
        stdout, stderr = git.communicate()
        if git.returncode == 0: return stdout.strip()
        else: raise GitReferenceError("'git rev-parse' failed: %s" % stderr.strip(), ref=name, repository=self)

    def revlist(self, included, excluded, *args, **kwargs):
        args = list(args)
        args.extend([str(ref) for ref in included])
        args.extend(['^' + str(ref) for ref in excluded])
        if "paths" in kwargs:
            args.append("--")
            args.extend(kwargs["paths"])
        return self.run('rev-list', *args).splitlines()

    def iscommit(self, name):
        git = subprocess.Popen(
            [configuration.executables.GIT, 'cat-file', '-t', name],
            stdout=subprocess.PIPE, stderr=subprocess.PIPE, cwd=self.path)
        stdout, stderr = git.communicate()
        if git.returncode == 0: return stdout.strip() == "commit"
        else: return False

    def keepalive(self, commit):
        self.run('update-ref', 'refs/keepalive/%s' % str(commit), str(commit))

    def __copy(self, identifier, flavor):
        base_args = ["clone", "--quiet"]

        if flavor == "relay":
            base_args.append("--bare")
            base_dir = REPOSITORY_RELAYCOPY_DIR
        else:
            assert flavor == "work"
            base_dir = REPOSITORY_WORKCOPY_DIR

        class Copy(object):
            def __init__(self, origin, path, name):
                self.origin = origin
                self.path = path
                self.name = name
            def run(self, *args, **kwargs):
                return self.origin.runCustom(
                    os.path.join(self.path, self.name), *args, **kwargs)
            def __enter__(self):
                return self
            def __exit__(self, *args):
                shutil.rmtree(self.path)
                return False

        path = tempfile.mkdtemp(prefix="%s_%s_" % (self.name, identifier),
                                dir=base_dir)
        name = os.path.basename(self.path)

        local_args = base_args[:]
        if not same_filesystem(self.path, path):
            local_args.append("--shared")
        local_args.extend([self.path, name])

        fallback_args = base_args[:]
        fallback_args.extend(["file://" + os.path.abspath(self.path), name])

        try:
            # Try cloning with --local (implied by using a plain path as the
            # repository URL.)  This may fail due to inaccessible pack-*.keep
            # files in the repository.
            self.runCustom(path, *local_args)
        except GitCommandError:
            try:
                # Try cloning without --local (implied by using a file://
                # repository URL.)  This is slower and uses more disk space, but
                # is immune to the problems with inaccessible pack-*.keep files.
                self.runCustom(path, *fallback_args)
            except GitCommandError:
                shutil.rmtree(path)
                raise

        return Copy(self, path, name)

    def relaycopy(self, identifier):
        return self.__copy(identifier, "relay")

    def workcopy(self, identifier):
        return self.__copy(identifier, "work")

    def replaymerge(self, db, user, commit):
        self.keepalive(commit)

        with self.workcopy(commit.sha1) as workcopy:
            # Then fetch everything from the main repository into the work copy.
            workcopy.run('fetch', 'origin', 'refs/keepalive/%s:refs/heads/merge' % commit.sha1)

            parent_sha1s = commit.parents

            # Create and check out a branch at first parent.
            workcopy.run('checkout', '-b', 'replay', parent_sha1s[0])

            # Then perform the merge with the other parents.
            returncode, stdout, stderr = workcopy.run("merge", *parent_sha1s[1:],
                env=getGitEnvironment(author=commit.author),
                check_errors=False)

            # If the merge produced conflicts, just stage and commit them:
            if returncode != 0:
                # Reset any submodule gitlinks with conflicts: since we don't
                # have the submodules checked out, "git commit --all" below
                # may fail to index them.
                for line in stdout.splitlines():
                    if line.startswith("CONFLICT (submodule):"):
                        submodule_path = line.split()[-1]
                        workcopy.run("reset", "--", submodule_path, check_errors=False)

                # Then stage and commit the result, with conflict markers and all.
                workcopy.run("commit", "--all", "--message=replay of merge that produced %s" % commit.sha1,
                             env=getGitEnvironment(author=commit.author))


            # Then push the branch to the main repository.
            workcopy.run('push', 'origin', 'refs/heads/replay:refs/replays/%s' % commit.sha1)

            # Finally, return the resulting commit.
            return Commit.fromSHA1(db, self, self.run('rev-parse', 'refs/replays/%s' % commit.sha1).strip())

    def getDefaultRemote(self, db):
        cursor = db.cursor()
        cursor.execute("""SELECT remote
                            FROM trackedbranches
                           WHERE repository=%s
                             AND local_name IN ('*', 'master')
                        ORDER BY local_name
                           LIMIT 1""",
                       (self.id,))
        row = cursor.fetchone()
        return row[0] if row else None

    def updateBranchFromRemote(self, db, remote, branch_name):
        cursor = db.cursor()
        cursor.execute("""SELECT 1
                            FROM trackedbranches
                           WHERE repository=%s
                             AND local_name=%s
                             AND NOT disabled""",
                       (self.id, branch_name))
        if cursor.fetchone():
            # Don't update a branch that the branch tracker service owns;
            # instead just assume it's already up-to-date.
            return

        if not branch_name.startswith("refs/"):
            branch_name = "refs/heads/%s" % branch_name

        with self.relaycopy("updateBranchFromRemote") as relay:
            try:
                relay.run("fetch", remote, branch_name)
            except GitCommandError as error:
                if error.output.startswith("fatal: Couldn't find remote ref "):
                    raise GitReferenceError("Couldn't find ref %s in %s." % (branch_name, remote),
                                            ref=branch_name, repository=remote)
                raise

            relay.run("push", "-f", "origin", "FETCH_HEAD:%s" % branch_name)

    def fetchTemporaryFromRemote(self, remote, ref):
        with self.relaycopy("fetchTemporaryFromRemote") as relay:
            try:
                relay.run("fetch", remote, ref)
            except GitCommandError as error:
                if error.output.startswith("fatal: Couldn't find remote ref "):
                    raise GitReferenceError("Couldn't find ref %s in %s." % (ref, remote), ref=ref, repository=remote)
                raise

            sha1 = relay.run("rev-parse", "--verify", "FETCH_HEAD").strip()

            relay.run("push", "-f", "origin", "%s:refs/temporary/%s" % (sha1, sha1))

            return sha1

    @staticmethod
    def readObject(repository_path, object_type, object_sha1):
        argv = [configuration.executables.GIT, 'cat-file', object_type, object_sha1]
        git = subprocess.Popen(argv, stdout=subprocess.PIPE,
                               stderr=subprocess.PIPE, cwd=repository_path)
        stdout, stderr = git.communicate()
        if git.returncode != 0:
            raise GitCommandError(" ".join(argv), stderr.strip(), repository_path)
        return stdout

    @staticmethod
    def lsremote(remote, include_heads=False, include_tags=False, pattern=None, regexp=None):
        if regexp: name_check = lambda item: bool(regexp.match(item[1]))
        else: name_check = lambda item: True

        argv = [configuration.executables.GIT, 'ls-remote']

        if include_heads: argv.append("--heads")
        if include_tags: argv.append("--tags")

        argv.append(remote)

        if pattern: argv.append(pattern)

        git = subprocess.Popen(argv, stdout=subprocess.PIPE,
                               stderr=subprocess.PIPE)
        stdout, stderr = git.communicate()

        if git.returncode == 0:
            return filter(name_check, (line.split() for line in stdout.splitlines()))
        else:
            cmdline = " ".join(argv)
            output = stderr.strip()
            cwd = os.getcwd()
            raise GitCommandError(cmdline, output, cwd)

    def findInterestingTag(self, db, sha1):
        cursor = db.cursor()
        cursor.execute("SELECT name FROM tags WHERE repository=%s AND sha1=%s",
                       (self.id, sha1))

        tags = [tag for (tag,) in cursor]

        try:
            from customization.filtertags import filterTags
            tags = filterTags(self, tags)
        except ImportError:
            pass

        if tags: return tags[0]
        else: return None

    def getHead(self, db):
        return Commit.fromSHA1(db, self, self.revparse("HEAD"))

    def isEmpty(self):
        try:
            self.revparse("HEAD")
            return False
        except GitError:
            return True

    def invokeGitHttpBackend(self, req, user, path):
        request_environ = req.getEnvironment()

        environ = { "GIT_HTTP_EXPORT_ALL": "true",
                    "REMOTE_ADDR": request_environ.get("REMOTE_ADDR", "unknown"),
                    "PATH_TRANSLATED": os.path.join(self.path, path),
                    "REQUEST_METHOD": req.method,
                    "QUERY_STRING": req.query }

        if "CONTENT_TYPE" in request_environ:
            environ["CONTENT_TYPE"] = request_environ["CONTENT_TYPE"]

        for name, value in req.getEnvironment().items():
            if name.startswith("HTTP_"):
                environ[name] = value

        if not user.isAnonymous():
            environ["REMOTE_USER"] = user.name
        elif not configuration.base.ALLOW_ANONYMOUS_USER \
                or path == "git-receive-pack" \
                or req.getParameter("service", None) == "git-receive-pack":
            # The git-receive-pack service fails without a user, so request
            # authorization.
            raise GitHttpBackendNeedsUser

        git_http_backend = communicate.Communicate(subprocess.Popen(
            [configuration.executables.GIT, "http-backend"],
            stdin=subprocess.PIPE, stdout=subprocess.PIPE,
            stderr=subprocess.PIPE, env=environ))

        def produceInput():
            data = req.read(65536)
            if not data:
                return None
            return data

        def handleHeaderLine(line):
            line = line.strip()

            if not line:
                req.start()
                git_http_backend.setCallbacks(stdout=handleOutput)
                return

            name, _, value = line.partition(":")
            name = name.strip()
            value = value.strip()

            if name.lower() == "status":
                status_code, _, status_text = value.partition(" ")
                req.setStatus(int(status_code), status_text.strip())
            elif name.lower() == "content-type":
                req.setContentType(value)
            else:
                req.addResponseHeader(name, value)

        def handleOutput(data):
            req.write(data)

        git_http_backend.setInput(produceInput)
        git_http_backend.setCallbacks(stdout_line=handleHeaderLine)

        try:
            _, stderr = git_http_backend.run()
        except communicate.ProcessError as error:
            raise GitHttpBackendError(error.process.returncode, error.stderr)

    def describe(self, db, sha1):
        tag = self.findInterestingTag(db, sha1)
        if tag: return tag

        cursor = db.cursor()
        cursor.execute("""SELECT branches.name, commits.sha1
                            FROM repositories
                            JOIN branches ON (branches.id=repositories.branch)
                            JOIN commits ON (commits.id=branches.head)
                           WHERE repositories.id=%s""",
                       (self.id,))

        for branch_name, head_sha1 in cursor:
            if sha1 == head_sha1:
                return "tip of " + branch_name
            try:
                if self.mergebase([sha1, head_sha1]) == sha1:
                    return branch_name
            except GitError:
                pass

        cursor.execute("""SELECT branches.name, commits.sha1
                            FROM trackedbranches
                            JOIN branches ON (branches.repository=trackedbranches.repository
                                          AND branches.name=trackedbranches.local_name)
                            JOIN commits ON (commits.id=branches.head)
                           WHERE trackedbranches.repository=%s
                             AND branches.type='normal'""",
                       (self.id,))

        for branch_name, head_sha1 in cursor:
            if sha1 == head_sha1:
                return "tip of " + branch_name
            try:
                if self.mergebase([sha1, head_sha1]) == sha1:
                    return branch_name
            except GitError:
                pass

        return None

class CommitUserTime(object):
    def __init__(self, name, email, time):
        self.name = name
        self.email = email
        self.time = time

    def __getIds(self, db):
        cache = db.storage["CommitUserTime"]
        cache_key = (self.name, self.email)

        if cache_key not in cache:
            cursor = db.cursor()
            cursor.execute("""SELECT id
                                FROM gitusers
                               WHERE fullname=%s
                                 AND email=%s""",
                           (self.name, self.email))
            row = cursor.fetchone()
            if not row:
                cursor.execute("""INSERT INTO gitusers (fullname, email)
                                       VALUES (%s, %s)
                                    RETURNING id""",
                               (self.name, self.email))
                row = cursor.fetchone()
            gituser_id, = row

            cursor.execute("""SELECT uid
                                FROM usergitemails
                               WHERE email=%s""",
                           (self.email,))
            user_ids = frozenset(user_id for user_id, in cursor)

            cache[cache_key] = user_ids, gituser_id

        return cache.get(cache_key)

    def getUserIds(self, db):
        return self.__getIds(db)[0]

    def getGitUserId(self, db):
        return self.__getIds(db)[1]

    def getFullname(self, db):
        user_ids = self.getUserIds(db)
        if len(user_ids) == 1:
            import dbutils
            return dbutils.User.fromId(db, tuple(user_ids)[0]).fullname
        else:
            return self.name

    def __str__(self):
        timestamp = time.strftime("%Y-%m-%d %H:%M:%S", self.time)
        return "%s <%s> at %s" % (self.name, self.email, timestamp)

    @staticmethod
    def fromValue(value):
        match = re_author_committer.match(value)
        return CommitUserTime(textutils.decode(match.group(1)).encode("utf-8"),
                              textutils.decode(match.group(2)).encode("utf-8"),
                              time.gmtime(int(match.group(3).split(" ")[0])))

class Commit:
    def __init__(self, repository, id, sha1, parents, author, committer, message, tree):
        self.repository = repository
        self.id = id
        self.sha1 = sha1
        self.parents = parents
        self.author = author
        self.committer = committer
        self.message = message
        self.tree = tree
        self.__treeCache = {}

    def __cache(self, db):
        cache = db.storage["Commit"]
        if self.id: cache[self.id] = self
        cache[self.sha1] = self

    @staticmethod
    def fromGitObject(db, repository, gitobject, commit_id=None):
        assert gitobject.type == "commit"

        data = gitobject.data
        parents = []

        while True:
            line, data = data.split('\n', 1)

            if not line:
                break

            key, value = line.split(' ', 1)

            if key == 'tree': tree = value
            elif key == 'parent': parents.append(value)
            elif key == 'author': author = CommitUserTime.fromValue(value)
            elif key == 'committer': committer = CommitUserTime.fromValue(value)

        message = textutils.decode(data).encode("utf-8")

        commit = Commit(repository, commit_id, gitobject.sha1, parents, author,
                        committer, message, tree)
        commit.__cache(db)
        return commit

    @staticmethod
    def fromSHA1(db, repository, sha1, commit_id=None):
        return Commit.fromGitObject(db, repository, repository.fetch(sha1), commit_id)

    @staticmethod
    def fromId(db, repository, commit_id):
        commit = db.storage["Commit"].get(commit_id)
        if not commit:
            cursor = db.cursor()
            cursor.execute("SELECT sha1 FROM commits WHERE id=%s", (commit_id,))
            sha1 = cursor.fetchone()[0]
            commit = Commit.fromSHA1(db, repository, sha1, commit_id)
        return commit

    def __hash__(self): return hash(self.sha1)
    def __eq__(self, other): return self.sha1 == str(other)
    def __ne__(self, other): return self.sha1 != str(other)
    def __str__(self): return self.sha1
    def __repr__(self):
        if self.id is None: return "Commit(sha1=%r)" % self.sha1
        else: return "Commit(sha1=%r, id=%d)" % (self.sha1, self.id)

    def summary(self, maxlen=None):
        summary = self.message.split("\n", 1)[0].strip()
        if maxlen and len(summary) > maxlen:
            summary = summary[:maxlen - 3].strip() + "..."
        return summary

    def niceSummary(self, include_tag=True):
        try:
            summary, _, rest = self.message.partition("\n")

            if summary.startswith("fixup! ") or summary.startswith("squash! "):
                fixup_summary = rest.strip().partition("\n")[0].strip()
                if fixup_summary:
                    what = summary[:summary.index("!")]
                    if include_tag:
                        return "[%s] %s" % (what, fixup_summary)
                    else:
                        return fixup_summary

            return summary
        except:
            return self.summary()

    def getId(self, db):
        if self.id is None:
            cursor = db.cursor()
            cursor.execute("SELECT id FROM commits WHERE sha1=%s", (self.sha1,))
            self.id = cursor.fetchone()[0]
            self.__cache(db)
        return self.id

    def findInterestingTag(self, db):
        return self.repository.findInterestingTag(db, self.sha1)

    def describe(self, db):
        if db:
            tag = self.findInterestingTag(db)
            if tag: return tag
        return self.sha1[:8]

    def oneline(self, db, decorate=False):
        line = "%s %s" % (self.sha1[:8], self.niceSummary())
        if decorate:
            decorations = []
            if self == self.repository.getHead(db):
                decorations.append("HEAD")
            cursor = db.cursor()
            cursor.execute("""SELECT branches.name
                                FROM branches
                                JOIN reachable ON (reachable.branch=branches.id)
                                JOIN commits ON (commits.id=reachable.commit)
                               WHERE commits.sha1=%s""",
                           (self.sha1,))
            decorations.extend(branch for (branch,) in cursor)
            if decorations:
                line += " (%s)" % ", ".join(decorations)
        return line

    def isAncestorOf(self, other):
        if isinstance(other, Commit):
            if self.repository != other.repository: return False
            other_sha1 = other.sha1
        else:
            other_sha1 = str(other)

        try:
            mergebase_sha1 = self.repository.mergebase([self.sha1, other_sha1])
        except GitCommandError:
            # Merge-base fails if there is no common ancestor.  And if two
            # commits have no common ancestor, neither can be an ancestor of the
            # other, obviously.
            return False
        else:
            return mergebase_sha1 == self.sha1

    def getTree(self, path):
        path = "/" + path.lstrip("/")
        if path not in self.__treeCache:
            self.__treeCache[path] = Tree.fromPath(self, path)
        return self.__treeCache[path]

    def getFileEntry(self, path):
        tree = self.getTree(os.path.dirname(path))
        if tree is None:
            return None
        return tree.get(os.path.basename(path))

    def getFileSHA1(self, path):
        entry = self.getFileEntry(path)
        if entry is None:
            return None
        return entry.sha1

    def isDirectory(self, path):
        return self.getTree(path) is not None

RE_LSTREE_LINE = re.compile(
    "(?P<mode>[0-9]{6}) (?P<type>blob|tree|commit) (?P<sha1>[0-9a-f]{40}) +"
    "(?P<size>[0-9]+|-)\t(?P<quote>[\"']?)(?P<name>.*)(?P=quote)$")

class Tree:
    class Entry:
        class Mode(int):
            def __new__(cls, value):
                return super(Tree.Entry.Mode, cls).__new__(cls, int(value, 8))

            def __str__(self):
                if stat.S_ISDIR(self):
                    return "d---------"
                elif self == 0160000:
                    return "m---------"
                else:
                    if stat.S_ISLNK(self): string = "l"
                    else: string = "-"

                    flags = ["---", "--x", "-w-", "-wx", "r--", "r-x", "rw-", "rwx"]
                    return string + flags[(self & 0700) >> 6] + flags[(self & 070) >> 3] + flags[self & 07]

        def __init__(self, name, mode, type, sha1, size):
            if len(name) > 2 and name[0] in ('"', "'") and name[-1] == name[0]:
                name = diff.parse.demunge(name[1:-1])

            self.name = name
            self.mode = Tree.Entry.Mode(mode)
            self.type = type
            self.sha1 = sha1
            self.size = size

        def __str__(self):
            return self.name

        def __repr__(self):
            return "[%s %s %s %s%s]" % (self.mode, self.type, self.name, self.sha1[:8], " %d" % self.size if self.size else "")

    def __init__(self, entries, commit=None):
        self.__entries_list = entries
        self.__entries_dict = dict([(entry.name, entry) for entry in entries])

    def __getitem__(self, item):
        if type(item) == int:
            return self.__entries_list[item]
        else:
            return self.__entries_dict[str(item)]

    def __len__(self):
        return len(self.__entries_list)
    def __iter__(self):
        return iter(self.__entries_list)

    def keys(self):
        return self.__entries_dict.keys()
    def items(self):
        return self.__entries_dict.items()
    def values(self):
        return self.__entries_dict.values()
    def get(self, key, default=None):
        return self.__entries_dict.get(key, default)

    @staticmethod
    def fromPath(commit, path):
        assert path[0] == "/"

        if path == "/":
            what = commit.sha1
        else:
            if path[-1] != "/": path += "/"
            what = "%s:%s" % (commit.sha1, path[1:])

        entries = []

        try:
            lstree_output = commit.repository.run("ls-tree", "-l", what)
        except GitCommandError as error:
            if error.output == "fatal: Not a valid object name %s" % what:
                return None
            raise

        for line in lstree_output.splitlines():
            match = RE_LSTREE_LINE.match(line)

            assert match, "Unexpected output from 'git ls-tree': %r" % line

            name = match.group("name")
            if match.group("quote"):
                name = diff.parse.demunge(name)

            if match.group("type") == "blob":
                size = int(match.group("size"))
            else:
                size = None

            entries.append(Tree.Entry(name=name,
                                      mode=match.group("mode"),
                                      type=match.group("type"),
                                      sha1=match.group("sha1"),
                                      size=size))

        return Tree(entries)

    @staticmethod
    def fromSHA1(repository, sha1):
        data = repository.fetch(sha1).data
        entries = []

        while len(data):
            space = data.index(" ")
            null = data.index("\0", space + 1)

            mode = data[:space]
            name = data[space + 1:null]

            sha1_binary = data[null + 1:null + 21]
            sha1 = "".join([("%02x" % ord(c)) for c in sha1_binary])

            entry_object = repository.fetch(sha1, fetchData=False)

            entries.append(Tree.Entry(name, mode, entry_object.type, sha1, entry_object.size))

            data = data[null + 21:]

        return Tree(entries)

def getTaggedCommit(repository, sha1):
    """Returns the SHA-1 of the tagged commit.

       If the supplied SHA-1 sum is a commit object, then it is returned,
       otherwise it must be a tag object, which is parsed to retrieve the
       tagged object SHA-1 sum."""

    while True:
        git_object = repository.fetch(sha1)

        if git_object.type == "commit":
            return sha1
        elif git_object.type != "tag":
            return

        sha1 = git_object.data.split("\n", 1)[0].split(" ", 1)[-1]

class Blame:
    def __init__(self, from_commit, to_commit):
        assert from_commit.repository == to_commit.repository

        self.repository = from_commit.repository
        self.from_commit = from_commit
        self.to_commit = to_commit
        self.commits = []
        self.__commit_ids = {}

    def blame(self, db, path, first_line, last_line):
        output = self.repository.run("blame",
                                     "--porcelain",
                                     "-L", "%d,%d" % (first_line, last_line),
                                     "%s..%s" % (self.from_commit.sha1, self.to_commit.sha1),
                                     "--", path)

        inlines = iter(output.splitlines())
        lines = []

        try:
            while True:
                sha1, original_line, current_line = inlines.next().split(" ")[:3]

                original_line = int(original_line)
                current_line = int(current_line)

                author = None
                author_email = None

                line = inlines.next()
                while not line.startswith("\t"):
                    if line.startswith("author "): author = line[7:]
                    elif line.startswith("author-mail "): author_email = line[13:-1]
                    elif line.startswith("summary "): pass
                    line = inlines.next()

                if sha1 not in self.__commit_ids:
                    commit = Commit.fromSHA1(db, self.repository, sha1)

                    self.__commit_ids[sha1] = len(self.commits)
                    self.commits.append({ "sha1": sha1,
                                          "author_name": author,
                                          "author_email": author_email,
                                          "summary": commit.niceSummary(),
                                          "message": commit.message,
                                          "original": sha1 == self.from_commit.sha1,
                                          "current": sha1 == self.to_commit.sha1 })

                lines.append({ "offset": current_line,
                               "commit": self.__commit_ids[sha1] })
        except StopIteration:
            pass

        return lines

class FetchCommits(threading.Thread):
    def __init__(self, repository, sha1s):
        super(FetchCommits, self).__init__()

        self.repository = repository
        self.sha1s = sha1s
        self.gitobjects = []
        self.commits = None
        self.error = None
        self.joined = False

        self.start()

    def run(self):
        try:
            batch = subprocess.Popen(
                [configuration.executables.GIT, 'cat-file', '--batch'],
                stdin=subprocess.PIPE, stdout=subprocess.PIPE,
                stderr=subprocess.STDOUT, cwd=self.repository.path)

            stdout, stderr = batch.communicate("\n".join(self.sha1s.keys()) + "\n")

            gitobjects = []

            for sha1, commit_id in self.sha1s.items():
                line, stdout = stdout.split("\n", 1)

                try:
                    object_sha1, object_type, object_size = line.split(" ")
                except ValueError:
                    raise SyntaxError("unexpected line: %r" % line)

                assert object_sha1 == sha1, "%s != %s" % (object_sha1, sha1)
                assert object_type == "commit"

                object_size = int(object_size)

                object_data = stdout[:object_size]
                stdout = stdout[object_size + 1:]

                gitobjects.append((GitObject(object_sha1, object_type, object_size, object_data), commit_id))

            self.gitobjects = gitobjects
        except Exception:
            self.error = traceback.format_exc()

    def getCommits(self, db):
        self.join()

        for gitobject, commit_id in self.gitobjects:
            Commit.fromGitObject(db, self.repository, gitobject, commit_id)

########NEW FILE########
__FILENAME__ = htmlutils
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2012 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import re
import time
import os
import json
import urllib

import textutils

from cStringIO import StringIO

from linkify import ALL_LINKTYPES, Context

fragments = []
for linktype in ALL_LINKTYPES:
    if linktype.fragment:
        fragments.append(linktype.fragment)
re_linkify = re.compile("(?:^|\\b|(?=\\W))(" + "|".join(fragments) + ")([.,:;!?)]*(?:\\s|\\b|$))")

re_simple = re.compile("^[^ \t\r\n&<>/=`'\"]+$")
re_nonascii = re.compile("[^\t\n\r -\x7f]")
re_control = re.compile("[\x01-\x1f\x7f]")

def htmlify(text, attributeValue=False, pretty=False):
    if isinstance(text, unicode): text = re_nonascii.sub(lambda x: "&#%d;" % ord(x.group()), text.replace('&', '&amp;').replace('<', '&lt;').replace('>', '&gt;'))
    else: text = str(text).replace('&', '&amp;').replace('<', '&lt;').replace('>', '&gt;')
    if attributeValue:
        if not pretty and re_simple.match(text): return text
        elif "'" in text:
            if '"' not in text: text = '"' + text + '"'
            else: text = "'" + text.replace("'", '&apos;') + "'"
        else: text = "'" + text + "'"
        text = re_control.sub(lambda match: "&#%d;" % ord(match.group()), text)
    return text

def jsify(what, as_json=False):
    if what is None: return "null"
    elif isinstance(what, bool): return "true" if what else "false"
    elif isinstance(what, int) or isinstance(what, long): return str(what)
    else:
        what = textutils.decode(what)
        result = json.dumps(what)
        if not as_json:
            quote = result[0]
            return result.replace("</", "<%s+%s/" % (quote, quote)).replace("<!", "<%s+%s!" % (quote, quote))
        else:
            return result

re_tag = re.compile("<[^>]+>")

def tabify(line, tabwidth=8, indenttabsmode=True):
    index = 0
    length = len(line)
    column = 0
    result = ""

    try:
        leading = True
        while index < length:
            tabindex = line.index("\t", index)
            nontabbed = line[index:tabindex]
            nontabbed_length = len(re_tag.sub("", nontabbed))
            illegal = ""
            if leading:
                if nontabbed_length != 0:
                    leading = False
                elif not indenttabsmode:
                    illegal = " ill"
            width = tabwidth - (column + nontabbed_length) % tabwidth
            result += nontabbed + "<b class='t w%d%s'></b>" % (width, illegal)
            index = tabindex + 1
            column = column + nontabbed_length + width
    except:
        result += line[index:]

    return result

BLOCK_ELEMENTS = set(["html", "head", "body", "section", "table", "thead", "tbody", "tfoot", "tr", "td", "th", "div", "p", "ol", "li", "label", "select", "option", "link", "script"])
EMPTY_ELEMENTS = set(["br", "hr", "input", "link", "base", "col"])

def isBlockElement(name):
    return name in BLOCK_ELEMENTS

def isEmptyElement(name):
    return name in EMPTY_ELEMENTS

def mtime(path):
    try: return long(os.stat(path).st_mtime)
    except: raise

def base36(n):
    s = ""
    while n:
        s = "0123456789abcdefghijklmnopqrstuvwxyz"[n % 36] + s
        n = n // 36
    return s

def getStaticResourceURI(name):
    import configuration
    uri = "/static-resource/" + name
    ts = mtime(os.path.join(configuration.paths.INSTALL_DIR, "resources", name))
    if ts: uri += "?" + base36(ts)
    return uri

class URL(object):
    def __init__(self, path, fragment=None, **query):
        assert path.startswith("/")
        assert "?" not in path
        assert "#" not in path
        self.value = path
        if query:
            self.value += "?" + urllib.urlencode(
                [(name, str(value)) for name, value in query.items()])
        if fragment:
            self.value += "#" + fragment.lstrip("#")
    def __str__(self):
        return self.value

class MetaInformation(object):
    def __init__(self):
        self.__orderIndices = set()
        self.__externalStylesheetList = []
        self.__externalStylesheetSet = set()
        self.__internalStylesheetList = []
        self.__internalStylesheetSet = set()
        self.__externalScriptList = []
        self.__externalScriptSet = set()
        self.__internalScriptList = []
        self.__links = {}
        self.__title = None
        self.__finished = False
        self.__request = None
        self.__base = "/"

    def addExternalStylesheet(self, uri, use_static=True, order=0):
        if use_static:
            uri = getStaticResourceURI(uri.split("/", 1)[1])
        if uri not in self.__externalStylesheetSet:
            self.__orderIndices.add(order)
            self.__externalStylesheetList.append((order, uri))
            self.__externalStylesheetSet.add(uri)

    def addInternalStylesheet(self, text, order=0):
        if text not in self.__internalStylesheetSet:
            self.__orderIndices.add(order)
            self.__internalStylesheetList.append((order, text))
            self.__internalStylesheetSet.add(text)

    def addExternalScript(self, uri, use_static=True, order=0):
        if use_static:
            uri = getStaticResourceURI(uri.split("/", 1)[1])
        if uri not in self.__externalScriptSet:
            self.__orderIndices.add(order)
            self.__externalScriptList.append((order, uri))
            self.__externalScriptSet.add(uri)

    def addInternalScript(self, text, order=0):
        self.__orderIndices.add(order)
        self.__internalScriptList.append((order, text))

    def hasTitle(self):
        return self.__title is not None

    def setTitle(self, title):
        self.__title = title

    def setLink(self, rel, href):
        return self.__links.setdefault(rel, href)

    def setBase(self, base):
        self.__base = base

    def setRequest(self, req):
        self.__request = req

    def getRequest(self):
        return self.__request

    def render(self, target):
        import configuration

        if not self.__finished:
            if self.__title:
                target.title().text(self.__title)
            if self.__base:
                target.base(href=self.__base)
            for rel, href in self.__links.items():
                target.link(rel=rel, href=href)

            for index in sorted(self.__orderIndices):
                def filtered(items): return [data for order, data in items if order==index]

                for uri in filtered(self.__externalStylesheetList):
                    target.link(rel="stylesheet", type="text/css", href=uri)
                for uri in filtered(self.__externalScriptList):
                    target.script(type="text/javascript", src=uri)
                for text in filtered(self.__internalStylesheetList):
                    target.style(type="text/css").text(text.strip(), cdata=True)
                for text in filtered(self.__internalScriptList):
                    target.script(type="text/javascript").text(text.strip(), cdata=True)

            if configuration.debug.IS_DEVELOPMENT:
                favicon = "/static-resource/favicon-dev.png"
            else:
                favicon = "/static-resource/favicon.png"

            target.link(rel="icon", type="image/png", href=favicon)

            self.__finished = True

class PausedRendering: pass

class Fragment(object):
    def __init__(self, is_element=False, req=None):
        self.__children = []
        self.__metaInformation = not is_element and MetaInformation() or None

    def appendChild(self, child):
        self.__children.append(child)
        return child

    def insertChild(self, child, offset=0):
        self.__children.insert(offset, child)
        return child

    def removeChild(self, child):
        assert child in self.__children
        self.__children.remove(child)

    def metaInformation(self):
        return self.__metaInformation

    def __len__(self): return len(self.__children)
    def __getitem__(self, index): return self.__children[index]
    def __str__(self): return "".join(map(str, self.__children))

    def render(self, output, level=0, indent_before=True, stop=None, pretty=True):
        for child in self.__children:
            child.render(output, level, indent_before, stop=stop, pretty=pretty)
            if pretty: output.write("\n")

    def deleteChildren(self, count=None):
        if count is None: self.__children = []
        else: del self.__children[:count]

    def hasChildren(self):
        return bool(self.__children)

class Element(Fragment):
    def __init__(self, name):
        super(Element, self).__init__(True)
        self.__name = name
        self.__attributes = {}
        self.__empty = isEmptyElement(name)
        self.__preformatted = False
        self.__metaInformation = None
        self.__rendered = False
        self.__disabled = False

    def setAttribute(self, name, value):
        self.__attributes[name] = value

    def addClass(self, *names):
        classes = set(self.__attributes.get("class").split())
        classes.update(names)
        self.setAttribute("class", " ".join(classes))

    def setPreFormatted(self):
        self.__preformatted = True

    def setMetaInformation(self, metaInformation):
        self.__metaInformation = metaInformation

    def appendChild(self, child):
        assert not self.__empty
        return Fragment.appendChild(self, child)

    def remove(self):
        self.__disabled = True
    def removeIfEmpty(self):
        self.__disabled = not self.hasChildren()

    def __str__(self):
        attributes = "".join([(" %s=%s" % (name, htmlify(value, True))) for name, value in self.__attributes.items()])
        if isEmptyElement(self.__name):
            return "<%s%s>" % (self.__name, attributes)
        else:
            return "<%s%s>%s</%s>" % (self.__name, attributes, Fragment.__str__(self), self.__name)

    def render(self, output, level=0, indent_before=True, stop=None, pretty=True):
        if self.__disabled: return

        if self.__metaInformation: self.__metaInformation.render(Generator(self, None))

        if pretty: indent = "  " * level
        else: indent = ""

        if indent_before: startindent = indent
        else: startindent = ""

        for child in self:
            if isinstance(child, Element) and isBlockElement(child.__name) or (isinstance(child, Text) or isinstance(child, Comment)) and '\n' in str(child):
                linebreak = "\n"
                endindent = indent
                break
        else:
            indent_before = False
            linebreak = ""
            endindent = ""

        if not pretty or self.__preformatted:
            child_level = 0
            linebreak = ""
            endindent = ""
        else: child_level = level + 1

        attributes = "".join([(" %s=%s" % (name, htmlify(value, True, pretty))) for name, value in self.__attributes.items()])

        if self.__empty:
            if not self.__rendered:
                output.write("%s<%s%s>" % (startindent, self.__name, attributes))
            self.__rendered = True
        else:
            if not self.__rendered:
                output.write("%s<%s%s>%s" % (startindent, self.__name, attributes, linebreak))
            self.__rendered = True

            children_rendered = 0
            for child in self:
                if self.__preformatted: child.setPreFormatted()
                try:
                    child.render(output, child_level, indent_before, stop, pretty)
                    output.write(linebreak)
                    children_rendered += 1
                except PausedRendering:
                    self.deleteChildren(children_rendered)
                    raise

            self.deleteChildren()

            if self == stop: raise PausedRendering
            else: output.write("%s</%s>" % (endindent, self.__name))

    def empty(self):
        self.__empty = True

class Text(object):
    def __init__(self, value, preformatted=False, cdata=False):
        if cdata: self.__value = value
        elif value is None: self.__value = "&nbsp;"
        else: self.__value = htmlify(value)
        self.__preformatted = preformatted

    def setPreFormatted(self):
        self.__preformatted = True

    def render(self, output, level=0, indent_before=True, stop=None, pretty=True):
        if pretty and level and not self.__preformatted and '\n' in self.__value:
            indent = "  " * level
            if indent_before: startindent = indent
            else: startindent = ""
            output.write(startindent + ('\n' + indent).join([line for line in self.__value.strip().splitlines()]))
        else:
            output.write(self.__value)

    def __str__(self):
        return self.__value

class Comment(object):
    def __init__(self, value):
        self.__value = value.replace("--", "- -")

    def setPreFormatted(self):
        pass

    def render(self, output, level=0, indent_before=True, stop=None, pretty=True):
        if pretty and level and '\n' in self.__value:
            indent = "  " * level
            if indent_before: startindent = indent
            else: startindent = ""
            output.write(startindent + "<!-- " + ('\n' + indent + "     ").join(htmlify(self.__value).splitlines()) + " -->")
        else:
            output.write("<!-- " + self.__value + " -->")

    def __str__(self):
        return self.__value

class HTML(object):
    def __init__(self, value):
        self.__value = value

    def setPreFormatted(self):
        pass

    def render(self, output, level=0, indent_before=True, stop=None, pretty=True):
        output.write(self.__value)

    def __str__(self):
        return self.__value

def safestr(value):
    try: return str(value)
    except: return unicode(value)

class Generator(object):
    def __init__(self, target, metaInformation):
        self.__target = target
        self.__metaInformation = metaInformation

    def __enter__(self):
        return self
    def __exit__(self, *args):
        return False

    def __eq__(self, other):
        return other == self.__target

    def __open(self, __name, **attributes):
        target = self.__target.appendChild(Element(__name))
        if "__generator__" in attributes:
            del attributes["__generator__"]
            generator = True
        else:
            generator = __name not in EMPTY_ELEMENTS
        for name, value in attributes.items():
            if value is not None:
                target.setAttribute(name.strip("_").replace("_", "-"), safestr(value))
        if not generator: return self
        else: return Generator(target, self.__metaInformation)

    def __getattr__(self, name):
        def open(*className, **attributes):
            assert len(className) == 0 or len(className) == 1
            if className: return self.__open(name, _class=className[0], **attributes)
            else: return self.__open(name, **attributes)
        return open

    def head(self, **attributes):
        target = self.__target.appendChild(Element("head"))
        for name, value in attributes.items():
            if value is not None:
                target.setAttribute(name.strip("_").replace("_", "-"), safestr(value))
        target.setMetaInformation(self.__metaInformation)
        return Generator(target, self.__metaInformation)

    def append(self, fragment):
        if fragment is not None:
            if isinstance(fragment, Generator): self.__target.appendChild(fragment.__target)
            else: self.__target.appendChild(fragment)

    def remove(self):
        self.__target.remove()
    def removeIfEmpty(self):
        self.__target.removeIfEmpty()

    def text(self, value=None, preformatted=False, cdata=False, linkify=False, repository=None, escape=False):
        if linkify:
            assert not cdata

            if isinstance(linkify, Context):
                context = linkify
            else:
                context = Context(repository=repository)

            for linktype in ALL_LINKTYPES:
                if linktype.match(value):
                    url = linktype.linkify(value, context)
                    if url:
                        self.a(href=url).text(value, escape=escape)
                        break
            else:
                for word in re_linkify.split(value):
                    if word:
                        for linktype in ALL_LINKTYPES:
                            if linktype.match(word):
                                url = linktype.linkify(word, context)
                                if url:
                                    self.a(href=url).text(word, escape=escape)
                                    break
                        else:
                            self.text(word, preformatted, escape=escape)
        else:
            if escape:
                value = textutils.escape(value)
            self.__target.appendChild(Text(value, preformatted, cdata))
        return self

    def comment(self, value):
        self.__target.appendChild(Comment(safestr(value)))
        return self

    def commentFirst(self, value):
        self.__target.insertChild(Comment(safestr(value)), offset=0)
        return self

    def innerHTML(self, value="&nbsp;"):
        self.__target.appendChild(HTML(safestr(value)))
        return self

    def setAttribute(self, name, value):
        self.__target.setAttribute(name, value)
        return self

    def addClass(self, *names):
        self.__target.addClass(*names)
        return self

    def render(self, output, level=0, stop=None, pretty=True):
        self.__target.render(output, level, stop=stop, pretty=pretty)

    def empty(self):
        self.__target.empty()
        return self

    def preformatted(self):
        self.__target.setPreFormatted()
        return self

    def addExternalStylesheet(self, uri, use_static=True, order=0):
        self.__metaInformation.addExternalStylesheet(uri, use_static, order=order)

    def addInternalStylesheet(self, text, order=0):
        self.__metaInformation.addInternalStylesheet(text, order=order)

    def addExternalScript(self, uri, use_static=True, order=0):
        self.__metaInformation.addExternalScript(uri, use_static, order=order)

    def addInternalScript(self, text, here=False, order=0):
        if here:
            self.script(type="text/javascript").text(text.strip().replace("</", "<\/"), cdata=True)
        else:
            self.__metaInformation.addInternalScript(text, order=order)

    def hasTitle(self):
        return self.__metaInformation.hasTitle()

    def setTitle(self, title):
        self.__metaInformation.setTitle(title)

    def setLink(self, rel, href):
        self.__metaInformation.setLink(rel, href)

    def setBase(self, base):
        self.__metaInformation.setBase(base)

    def getRequest(self):
        return self.__metaInformation.getRequest()

class Document(Generator):
    def __init__(self, req=None):
        self.__fragment = Fragment()
        Generator.__init__(self, self.__fragment, self.__fragment.metaInformation())
        self.__start = time.time()
        self.__generation = 0.0
        self.__rendering = 0.0
        self.__doctype = True

        if req: self.__fragment.metaInformation().setRequest(req)

    def render(self, plain=False, stop=None, pretty=True):
        self.__generation += time.time() - self.__start

        output = StringIO()
        if not plain and self.__doctype:
            output.write("<!DOCTYPE html>")
            self.__doctype = False

        before = time.time()
        try:
            Generator.render(self, output, stop=stop, pretty=pretty)
            finished = True
        except PausedRendering:
            finished = False
        after = time.time()

        self.__rendering += after - before

        if not plain and finished:
            output.write("\n<!-- generation: %.2f ms, rendering: %.2f ms -->" % (self.__generation * 1000, self.__rendering * 1000))

        self.__start = time.time()
        return output.getvalue()

    def __str__(self):
        return self.render()

def stripStylesheet(text, compact):
    if compact:
        text = re.sub(r"/\*(?:[^*]|\*[^/])*\*/", "", text)
        text = re.sub(r"\s*([,:;{}])\s*", lambda m: m.group(1), text)
        text = re.sub(r"\s+", " ", text)
    return text

if __name__ == "__main__":
    generator = Document()
    row = generator.html().body().table(border=1).tbody().tr()
    row.td(_class="left").div(id="foo").text("Column 1\nMore text")
    row.td(_class="right").text("text").comment("comment")
    print generator.render()

########NEW FILE########
__FILENAME__ = htmlutils_unittest
import sys

def independence():
    # Simply check that htmlutils can be imported.

    import htmlutils

if __name__ == "__main__":
    if "independence" in sys.argv[1:]:
        independence()

########NEW FILE########
__FILENAME__ = index
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2012 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import sys

from subprocess import Popen as process, PIPE
from re import compile, split
from time import gmtime, strftime
from pwd import getpwuid
from os import getuid

from dbutils import *
import gitutils
from log.commitset import CommitSet

import dbutils
import reviewing.utils
import reviewing.mail
import reviewing.rebase
import configuration
import log.commitset
import textutils

if configuration.extensions.ENABLED:
    import extensions.role.processcommits

try:
    from customization.email import getUserEmailAddress
except ImportError:
    def getUserEmailAddress(_username):
        return None

try:
    from customization.githook import Reject, update
except ImportError:
    class Reject(Exception):
        pass
    def update(_repository, _ref, _old, _new):
        pass

def timestamp(time):
    return strftime("%Y-%m-%d %H:%M:%S", time)

def getUser(db, user_name):
    if user_name == configuration.base.SYSTEM_USER_NAME:
        return user_name
    try:
        return dbutils.User.fromName(db, user_name)
    except dbutils.NoSuchUser:
        if configuration.base.AUTHENTICATION_MODE == "host":
            email = getUserEmailAddress(user_name)
            user = dbutils.User.create(
                db, user_name, user_name, email, email_verified=None)
            db.commit()
            return user
        raise

db = None

class IndexException(Exception):
    pass

def processCommits(repository_name, sha1):
    repository = gitutils.Repository.fromName(db, repository_name)

    if not repository: raise IndexException("No such repository: %r" % repository_name)

    stack = []
    edges_values = []

    cursor = db.cursor()
    cursor.execute("SELECT 1 FROM commits LIMIT 1")
    emptydb = cursor.fetchone() is None

    cursor.execute("""SELECT commits.sha1
                        FROM commits
                        JOIN branches ON (branches.head=commits.id)
                       WHERE branches.repository=%s
                         AND branches.type='normal'
                         AND branches.base IS NULL
                    ORDER BY branches.id ASC""",
                   (repository.id,))

    try:
        base_sha1 = cursor.fetchone()[0]
        count = int(repository.run("rev-list", "--count", "%s..%s" % (base_sha1, sha1)).strip())
    except:
        count = 0

    if count > configuration.limits.PUSH_COMMIT_LIMIT:
        raise IndexException("""\
You're trying to add %d new commits to this repository.  Are you
perhaps pushing to the wrong repository?""" % count)

    commits_values = []
    commits = set()

    while True:
        if sha1 not in commits:
            commit = gitutils.Commit.fromSHA1(db, repository, sha1)

            if commit.author.email: author_id = commit.author.getGitUserId(db)
            else: author_id = 0

            if commit.committer.email: committer_id = commit.committer.getGitUserId(db)
            else: committer_id = 0

            if emptydb: row = None
            else:
                cursor.execute("SELECT id FROM commits WHERE sha1=%s", (commit.sha1,))
                row = cursor.fetchone()
                new_commit = False

            if not row:
                commits_values.append((commit.sha1, author_id, committer_id, timestamp(commit.author.time), timestamp(commit.committer.time)))
                new_commit = True

            commits.add(sha1)

            if new_commit:
                edges_values.extend([(parent_sha1, commit.sha1) for parent_sha1 in set(commit.parents)])
                stack.extend(set(commit.parents))

        if not stack: break

        sha1 = stack.pop(0)

    cursor.executemany("""INSERT INTO commits (sha1, author_gituser, commit_gituser, author_time, commit_time)
                               VALUES (%s, %s, %s, %s, %s)""",
                       commits_values)

    cursor.executemany("""INSERT INTO edges (parent, child)
                               SELECT parents.id, children.id
                                 FROM commits AS parents,
                                      commits AS children
                                WHERE parents.sha1=%s AND children.sha1=%s""",
                       edges_values)

    db.commit()

def init():
    global db

    db = Database()

def finish():
    global db

    if db:
        db.commit()
        db.close()
        db = None

def abort():
    global db

    if db:
        db.rollback()
        db.close()
        db = None

def createBranches(user_name, repository_name, branches, flags):
    user = getUser(db, user_name)
    repository = gitutils.Repository.fromName(db, repository_name)

    for name, head in branches: processCommits(repository_name, head)

    if len(branches) > 1:
        try:
            from customization.branches import compareBranchNames
        except ImportError:
            def compareBranchNames(name1, name2):
                name1 = split("([-_+])", name1)
                name2 = split("([-_+])", name2)

                for name1, name2 in map(None, name1, name2):
                    if name1 is None: return -1
                    elif name2 is None: return 1
                    elif name1 != name2:
                        try: return cmp(int(name1), int(name2))
                        except: return cmp(name1, name2)
                else: return 0

        def compareBranches(branch1, branch2):
            name1, head1 = branch1
            name2, head2 = branch2

            # Same name ought not occur twice, but just to be on the safe side.
            if name1 == name2: return 0

            # Special case for master.  Mostly redundant, because it's quite
            # unlikely that master would be created along with other branches.
            elif name1 == "master": return -1
            elif name2 == "master": return 1

            # Try a natural ordering based on the relationships of the head
            # commits of the two branches, unless the heads are the same:
            if head1 != head2:
                base = repository.mergebase([head1, head2])

                # If either head is an ancestor of the other head, merge-base
                # between them will be the ancestor head, and in that case,
                # process that branch first.  Otherwise, then that would be
                # guaranteed to show up as empty, and that's probably not the
                # intention.
                if base == head1: return -1
                elif base == head2: return 1

            # Two non-taskbranch branches that seem "unrelated".  Process them
            # ordered by name, mostly so that this comparison function is well-
            # behaved.
            return compareBranchNames(name1, name2)

        branches.sort(cmp=compareBranches)

    for name, head in branches: createBranch(user, repository, name, head, flags)

def createBranch(user, repository, name, head, flags):
    processCommits(repository.name, head)

    try:
        update(repository.path, "refs/heads/" + name, None, head)
    except Reject as rejected:
        raise IndexException(str(rejected))
    except Exception:
        pass

    cursor = db.cursor()

    def commit_id(sha1):
        cursor.execute("SELECT id FROM commits WHERE sha1=%s", [sha1])
        return cursor.fetchone()[0]

    components = name.split("/")
    for index in range(1, len(components)):
        try: repository.revparse("refs/heads/%s" % "/".join(components[:index]))
        except: continue

        message = ("Cannot create branch with name '%s' since there is already a branch named '%s' in the repository." %
                   (name, "/".join(components[:index])))
        raise IndexException(textutils.reflow(message, line_length=80 - len("remote: ")))

    if name.startswith("r/"):
        try:
            review_id = int(name[2:])

            cursor.execute("SELECT branches.name FROM reviews JOIN branches ON (branches.id=reviews.branch) WHERE reviews.id=%s", (review_id,))
            row = cursor.fetchone()

            message = "Refusing to create review named as a number."

            if row:
                message += "\nDid you mean to push to the branch '%s', perhaps?" % row[0]

            raise IndexException(message)
        except ValueError:
            pass

        if user.getPreference(db, "review.createViaPush"):
            the_commit = gitutils.Commit.fromSHA1(db, repository, head, commit_id(head))
            all_commits = [the_commit]

            review = reviewing.utils.createReview(
                db, user, repository, all_commits, name,
                the_commit.niceSummary(include_tag=False), None, via_push=True)

            print "Submitted review:"
            print review.getURL(db, user, indent=2)

            if review.reviewers:
                print "  Reviewers:"
                for reviewer in review.reviewers:
                    print "    %s <%s>" % (reviewer.fullname, reviewer.email)

            if review.watchers:
                print "  Watchers:"
                for watcher in review.watchers:
                    print "    %s <%s>" % (watcher.fullname, watcher.email)

            if configuration.extensions.ENABLED:
                if extensions.role.processcommits.execute(db, user, review, all_commits, None, the_commit, sys.stdout):
                    print

            print "Thank you!"
            return True
        else:
            raise IndexException("Refusing to create review; user preference 'review.createViaPush' is not enabled.")

    sha1 = head
    base = None
    tail = None

    cursor.execute("""SELECT 1
                        FROM reachable
                        JOIN branches ON (branches.id=reachable.branch)
                        JOIN repositories ON (repositories.id=branches.repository)
                       WHERE repositories.id=%s
                       LIMIT 1""",
                   (repository.id,))

    if cursor.fetchone():
        def reachable(sha1):
            cursor.execute("""SELECT branches.id
                                FROM branches
                                JOIN reachable ON (reachable.branch=branches.id)
                                JOIN commits ON (commits.id=reachable.commit)
                               WHERE branches.repository=%s
                                 AND branches.type='normal'
                                 AND commits.sha1=%s
                            ORDER BY reachable.branch ASC
                               LIMIT 1""",
                           (repository.id, sha1))
            return cursor.fetchone()
    else:
        def reachable(sha1):
            return None

    commit_map = {}
    commit_list = []

    row = reachable(sha1)
    if row:
        # Head of branch is reachable from an existing branch.  Could be because
        # this branch is actually empty (just created with no "own" commits) or
        # it could have been merged into some other already existing branch.  We
        # can't tell, so we just record it as empty.

        base = row[0]
        tail = sha1
    else:
        stack = []

        while True:
            if sha1 not in commit_map:
                commit = gitutils.Commit.fromSHA1(db, repository, sha1)
                commit_map[sha1] = commit
                commit_list.append(commit)

                for sha1 in commit.parents:
                    if sha1 not in commit_map:
                        row = reachable(sha1)
                        if not row:
                            stack.append(sha1)
                        elif base is None:
                            base = row[0]
                            tail = sha1

                            base_chain = [base]

                            while True:
                                cursor.execute("SELECT base FROM branches WHERE id=%s", (base_chain[-1],))
                                next = cursor.fetchone()[0]
                                if next is None: break
                                else: base_chain.append(next)

                            def reachable(sha1):
                                cursor.execute("""SELECT 1
                                                    FROM reachable
                                                    JOIN commits ON (commits.id=reachable.commit)
                                                   WHERE reachable.branch=ANY (%s)
                                                     AND commits.sha1=%s""",
                                               (base_chain, sha1))
                                return cursor.fetchone()

            if stack: sha1 = stack.pop(0)
            else: break

    if isinstance(user, dbutils.User):
        # Push by regular user.
        user_name = user.name
    else:
        # Push by the Critic system user, i.e. by the branch tracker service or
        # other internal mechanism.
        user_name = user

    if not base:
        cursor.execute("INSERT INTO branches (repository, name, head) VALUES (%s, %s, %s) RETURNING id", (repository.id, name, commit_id(head)))
        branch_id = cursor.fetchone()[0]
    else:
        cursor.execute("INSERT INTO branches (repository, name, head, base, tail) VALUES (%s, %s, %s, %s, %s) RETURNING id", (repository.id, name, commit_id(head), base, commit_id(tail)))
        branch_id = cursor.fetchone()[0]

        # Suppress the "user friendly" feedback if the push is performed by the
        # Critic system user, since there wouldn't be a human being reading it.
        #
        # Also, the calls to user.getCriticURLs() obvious don't work if 'user'
        # isn't a dbutils.User object, which it isn't in that case.
        if user_name != configuration.base.SYSTEM_USER_NAME:
            cursor.execute("SELECT name FROM branches WHERE id=%s", [base])

            print "Added branch based on %s containing %d commit%s:" % (cursor.fetchone()[0], len(commit_list), "s" if len(commit_list) > 1 else "")
            for url_prefix in user.getCriticURLs(db):
                print "  %s/log?repository=%d&branch=%s" % (url_prefix, repository.id, name)
            if len(commit_list) > 1:
                print "To create a review of all %d commits:" % len(commit_list)
            else:
                print "To create a review of the commit:"
            for url_prefix in user.getCriticURLs(db):
                print "  %s/createreview?repository=%d&branch=%s" % (url_prefix, repository.id, name)

    reachable_values = [(branch_id, commit.sha1) for commit in commit_list]
    cursor.executemany("INSERT INTO reachable (branch, commit) SELECT %s, id FROM commits WHERE sha1=%s", reachable_values)

    if not repository.hasMainBranch() and user_name == configuration.base.SYSTEM_USER_NAME:
        cursor.execute("UPDATE repositories SET branch=%s WHERE id=%s", (branch_id, repository.id))

def updateBranch(user_name, repository_name, name, old, new, multiple, flags):
    repository = gitutils.Repository.fromName(db, repository_name)

    processCommits(repository_name, new)

    try:
        update(repository.path, "refs/heads/" + name, old, new)
    except Reject as rejected:
        raise IndexException(str(rejected))
    except Exception:
        pass

    try:
        branch = dbutils.Branch.fromName(db, repository, name)
        base_branch_id = branch.base.id if branch.base else None
    except:
        raise IndexException("The branch '%s' is not in the database!  (This should never happen.)" % name)

    if branch.head.sha1 != old:
        if new == branch.head.sha1:
            # This is what we think the ref ought to be already.  Do nothing,
            # and let the repository "catch up."
            return
        else:
            data = { "name": name,
                     "old": old[:8],
                     "new": new[:8],
                     "current": branch.head.sha1[:8] }

            message = """CONFUSED!  Git thinks %(name)s points to %(old)s, but Critic thinks it points to %(current)s.  Rejecting push since it would only makes matters worse.  To resolve this problem, use

  git push -f critic %(current)s:%(name)s

to resynchronize the Git repository with Critic's database.  Note that 'critic' above must be replaced by the actual name of your Critic remote, if not 'critic'.""" % data

            raise IndexException(textutils.reflow(message, line_length=80 - len("remote: ")))

    cursor = db.cursor()
    cursor.execute("""SELECT id, remote, remote_name, forced, updating
                        FROM trackedbranches
                       WHERE repository=%s
                         AND local_name=%s
                         AND NOT disabled""",
                   (repository.id, name))
    row = cursor.fetchone()

    if row:
        trackedbranch_id, remote, remote_name, forced, updating = row
        tracked_branch = "%s in %s" % (remote_name, remote)

        assert not forced or not name.startswith("r/")

        if user_name != configuration.base.SYSTEM_USER_NAME \
                or flags.get("trackedbranch_id") != str(trackedbranch_id):
            raise IndexException("""\
The branch '%s' is set up to track '%s' in
  %s
Please don't push it manually to this repository.""" % (name, remote_name, remote))

        assert updating

        if not name.startswith("r/"):
            conflicting = repository.revlist([branch.head.sha1], [new])
            added = repository.revlist([new], [branch.head.sha1])

            if conflicting:
                if forced:
                    if branch.base is None:
                        cursor.executemany("""DELETE FROM reachable
                                                    USING commits
                                                    WHERE reachable.branch=%s
                                                      AND reachable.commit=commits.id
                                                      AND commits.sha1=%s""",
                                           [(branch.id, sha1) for sha1 in conflicting])
                    else:
                        print "Non-fast-forward update detected; deleting and recreating branch."

                        deleteBranch(user_name, repository.name, branch.name, old)
                        createBranches(user_name, repository.name, [(branch.name, new)], flags)

                        return
                else:
                    raise IndexException("""\
Rejecting non-fast-forward update of branch.  To perform the update, you
can delete the branch using
  git push critic :%s
first, and then repeat this push.""" % name)

            cursor.executemany("""INSERT INTO reachable (branch, commit)
                                       SELECT %s, commits.id
                                         FROM commits
                                        WHERE sha1=%s""",
                               [(branch.id, sha1) for sha1 in added])

            new_head = gitutils.Commit.fromSHA1(db, repository, new)

            cursor.execute("UPDATE branches SET head=%s WHERE id=%s",
                           (new_head.getId(db), branch.id))

            output = []

            if conflicting:
                output.append("Pruned %d conflicting commits." % len(conflicting))
            if added:
                output.append("Added %d new commits." % len(added))

            if output:
                print "\n".join(output)

            return
    else:
        tracked_branch = False

    user = getUser(db, user_name)

    if isinstance(user, str):
        user = dbutils.User(
            0, configuration.base.SYSTEM_USER_NAME, "Critic System", "current",
            configuration.base.SYSTEM_USER_EMAIL, None)

    cursor.execute("SELECT id FROM reviews WHERE branch=%s", (branch.id,))
    row = cursor.fetchone()

    is_review = bool(row)

    if is_review:
        if multiple:
            raise IndexException("""\
Refusing to update review in push of multiple refs.  Please push one
review branch at a time.""")

        review_id = row[0]

        cursor.execute("""SELECT id, old_head, old_upstream, new_upstream, uid, branch
                            FROM reviewrebases
                           WHERE review=%s AND new_head IS NULL""",
                       (review_id,))
        row = cursor.fetchone()

        if row:
            if tracked_branch:
                raise IndexException("Refusing to perform a review rebase via an automatic update.")

            rebase_id, old_head_id, old_upstream_id, new_upstream_id, rebaser_id, onto_branch = row

            review = dbutils.Review.fromId(db, review_id)
            rebaser = dbutils.User.fromId(db, rebaser_id)

            if rebaser.id != user.id:
                if user_name == configuration.base.SYSTEM_USER_NAME:
                    user = rebaser
                else:
                    raise IndexException("""\
This review is currently being rebased by
  %s <%s>
and can't be otherwise updated right now.""" % (rebaser.fullname, rebaser.email))

            old_head = gitutils.Commit.fromId(db, repository, old_head_id)
            old_commitset = log.commitset.CommitSet(review.branch.commits)

            if old_head.sha1 != old:
                raise IndexException("""\
Unexpected error.  The branch appears to have been updated since your
rebase was prepared.  You need to cancel the rebase via the review
front-page and then try again, and/or report a bug about this error.""")

            if old_upstream_id is not None:
                new_head = gitutils.Commit.fromSHA1(db, repository, new)

                old_upstream = gitutils.Commit.fromId(db, repository, old_upstream_id)

                if new_upstream_id is not None:
                    new_upstream = gitutils.Commit.fromId(db, repository, new_upstream_id)
                else:
                    if len(new_head.parents) != 1:
                        raise IndexException("Invalid rebase: New head can't be a merge commit.")

                    new_upstream = gitutils.Commit.fromSHA1(db, repository, new_head.parents[0])

                    if new_upstream in old_commitset.getTails():
                        old_upstream = new_upstream = None
            else:
                old_upstream = None

            if old_upstream:
                unrelated_move = False

                if not new_upstream.isAncestorOf(new):
                    raise IndexException("""\
Invalid rebase: The new upstream commit you specified when the rebase
was prepared is not an ancestor of the commit now pushed.  You may want
to cancel the rebase via the review front-page, and prepare another one
specifying the correct new upstream commit; or rebase the branch onto
the new upstream specified and then push that instead.""")

                if not old_upstream.isAncestorOf(new_upstream):
                    unrelated_move = True

                if unrelated_move:
                    replayed_rebase = reviewing.rebase.replayRebase(
                        db, review, user, old_head, old_upstream, new_head,
                        new_upstream, onto_branch)
                else:
                    merge = reviewing.rebase.createEquivalentMergeCommit(
                        db, review, user, old_head, old_upstream, new_head,
                        new_upstream, onto_branch)

                new_sha1s = repository.revlist([new_head.sha1], [new_upstream.sha1], '--topo-order')
                rebased_commits = [gitutils.Commit.fromSHA1(db, repository, sha1) for sha1 in new_sha1s]
                reachable_values = [(review.branch.id, sha1) for sha1 in new_sha1s]

                pending_mails = []

                recipients = review.getRecipients(db)
                for to_user in recipients:
                    pending_mails.extend(reviewing.mail.sendReviewRebased(
                            db, user, to_user, recipients, review,
                            new_upstream, rebased_commits, onto_branch))

                print "Rebase performed."

                review.setPerformedRebase(old_head, new_head, old_upstream, new_upstream, user)

                if unrelated_move:
                    reviewing.utils.addCommitsToReview(
                        db, user, review, [replayed_rebase],
                        pending_mails=pending_mails,
                        silent_if_empty=set([replayed_rebase]),
                        replayed_rebases={ replayed_rebase: new_head })

                    repository.keepalive(old_head)
                    repository.keepalive(replayed_rebase)
                else:
                    reviewing.utils.addCommitsToReview(
                        db, user, review, [merge], pending_mails=pending_mails,
                        silent_if_empty=set([merge]), full_merges=set([merge]))

                    repository.keepalive(merge)

                if not unrelated_move:
                    cursor.execute("""UPDATE reviewrebases
                                         SET old_head=%s
                                       WHERE review=%s AND new_head IS NULL""",
                                   (merge.id, review.id))

                cursor.execute("""UPDATE reviewrebases
                                     SET new_head=%s, new_upstream=%s
                                   WHERE review=%s AND new_head IS NULL""",
                               (new_head.getId(db), new_upstream.getId(db), review.id))

                cursor.execute("""INSERT INTO previousreachable (rebase, commit)
                                       SELECT %s, commit
                                         FROM reachable
                                        WHERE branch=%s""",
                               (rebase_id, review.branch.id))
                cursor.execute("DELETE FROM reachable WHERE branch=%s",
                               (review.branch.id,))
                cursor.executemany("""INSERT INTO reachable (branch, commit)
                                           SELECT %s, commits.id
                                             FROM commits
                                            WHERE commits.sha1=%s""",
                                   reachable_values)
                cursor.execute("UPDATE branches SET head=%s WHERE id=%s",
                               (new_head.getId(db), review.branch.id))
            else:
                old_commitset = log.commitset.CommitSet(review.branch.commits)
                new_sha1s = repository.revlist([new], old_commitset.getTails(), '--topo-order')

                if old_head.sha1 in new_sha1s:
                    raise IndexException("""\
Invalid history rewrite: Old head of the branch reachable from the
pushed ref; no history rewrite performed.  (Cancel the rebase via
the review front-page if you've changed your mind.)""")

                for new_sha1 in new_sha1s:
                    new_head = gitutils.Commit.fromSHA1(db, repository, new_sha1)
                    if new_head.tree == old_head.tree: break
                else:
                    raise IndexException("""\
Invalid history rewrite: The rebase introduced unexpected code changes.
Use git diff between the review branch in Critic's repository and
the rebased local branch to see what those changes are.""")

                rebased_commits = [gitutils.Commit.fromSHA1(db, repository, sha1) for sha1 in repository.revlist([new_head], old_commitset.getTails(), '--topo-order')]
                new_commits = [gitutils.Commit.fromSHA1(db, repository, sha1) for sha1 in repository.revlist([new], [new_head], '--topo-order')]
                reachable_values = [(review.branch.id, sha1) for sha1 in new_sha1s]

                pending_mails = []

                recipients = review.getRecipients(db)
                for to_user in recipients:
                    pending_mails.extend(reviewing.mail.sendReviewRebased(db, user, to_user, recipients, review, None, rebased_commits))

                print "History rewrite performed."

                if new_commits:
                    reviewing.utils.addCommitsToReview(db, user, review, new_commits, pending_mails=pending_mails)
                else:
                    reviewing.mail.sendPendingMails(pending_mails)

                cursor.execute("""UPDATE reviewrebases
                                     SET new_head=%s
                                   WHERE review=%s AND new_head IS NULL""",
                               (new_head.getId(db), review.id))

                cursor.execute("""INSERT INTO previousreachable (rebase, commit)
                                       SELECT %s, commit
                                         FROM reachable
                                        WHERE branch=%s""",
                               (rebase_id, review.branch.id))
                cursor.execute("DELETE FROM reachable WHERE branch=%s",
                               (review.branch.id,))
                cursor.executemany("""INSERT INTO reachable (branch, commit)
                                           SELECT %s, commits.id
                                             FROM commits
                                            WHERE commits.sha1=%s""",
                                   reachable_values)
                cursor.execute("UPDATE branches SET head=%s WHERE id=%s",
                               (gitutils.Commit.fromSHA1(db, repository, new).getId(db),
                                review.branch.id))

                repository.run('update-ref', 'refs/keepalive/%s' % old, old)

            review.incrementSerial(db)

            return True
        elif old != repository.mergebase([old, new]):
            raise IndexException("Rejecting non-fast-forward update of review branch.")
    elif old != repository.mergebase([old, new]):
        raise IndexException("""\
Rejecting non-fast-forward update of branch.  To perform the update, you
can delete the branch using
  git push critic :%s
first, and then repeat this push.""" % name)

    cursor.execute("SELECT id FROM branches WHERE repository=%s AND base IS NULL ORDER BY id ASC LIMIT 1", (repository.id,))
    root_branch_id = cursor.fetchone()[0]

    def isreachable(sha1):
        if is_review and sha1 == branch.tail: return True
        if base_branch_id: cursor.execute("SELECT 1 FROM commits, reachable WHERE commits.sha1=%s AND commits.id=reachable.commit AND reachable.branch IN (%s, %s, %s)", [sha1, branch.id, base_branch_id, root_branch_id])
        else: cursor.execute("SELECT 1 FROM commits, reachable WHERE commits.sha1=%s AND commits.id=reachable.commit AND reachable.branch IN (%s, %s)", [sha1, branch.id, root_branch_id])
        return cursor.fetchone() is not None

    stack = [new]
    commits = set()
    commit_list = []
    processed = set()

    while stack:
        sha1 = stack.pop()

        if sha1 not in commits and not isreachable(sha1):
            commits.add(sha1)
            commit_list.append(sha1)

            stack.extend([parent_sha1 for parent_sha1 in gitutils.Commit.fromSHA1(db, repository, sha1).parents if parent_sha1 not in processed])

        processed.add(sha1)

    branch = dbutils.Branch.fromName(db, repository, name)
    review = dbutils.Review.fromBranch(db, branch)

    if review:
        if review.state != "open":
            raise IndexException("""\
The review is closed and can't be extended.  You need to reopen it at
%s
before you can add commits to it.""" % review.getURL(db, user, 2))

        all_commits = [gitutils.Commit.fromSHA1(db, repository, sha1) for sha1 in reversed(commit_list)]

        tails = CommitSet(all_commits).getTails()

        if old not in tails:
            raise IndexException("""\
Push rejected; would break the review.

It looks like some of the pushed commits are reachable from the
repository's main branch, and thus consequently the commits currently
included in the review are too.

Perhaps you should request a new review of the follow-up commits?""")

        reviewing.utils.addCommitsToReview(db, user, review, all_commits, commitset=commits, tracked_branch=tracked_branch)

    reachable_values = [(branch.id, sha1) for sha1 in reversed(commit_list) if sha1 in commits]

    cursor.executemany("INSERT INTO reachable (branch, commit) SELECT %s, commits.id FROM commits WHERE commits.sha1=%s", reachable_values)
    cursor.execute("UPDATE branches SET head=%s WHERE id=%s", (gitutils.Commit.fromSHA1(db, repository, new).getId(db), branch.id))

    db.commit()

    if configuration.extensions.ENABLED and review:
        extensions.role.processcommits.execute(db, user, review, all_commits,
                                               gitutils.Commit.fromSHA1(db, repository, old),
                                               gitutils.Commit.fromSHA1(db, repository, new),
                                               sys.stdout)

def deleteBranch(user_name, repository_name, name, old):
    repository = gitutils.Repository.fromName(db, repository_name)

    try:
        update(repository.path, "refs/heads/" + name, old, None)
    except Reject as rejected:
        raise IndexException(str(rejected))
    except Exception:
        pass

    branch = dbutils.Branch.fromName(db, repository, name)

    if branch:
        review = dbutils.Review.fromBranch(db, branch)

        if review:
            raise IndexException("This is Critic refusing to delete a branch that belongs to a review.")

        cursor = db.cursor()
        cursor.execute("SELECT COUNT(*) FROM reachable WHERE branch=%s", (branch.id,))

        ncommits = cursor.fetchone()[0]

        if branch.base:
            cursor.execute("UPDATE branches SET base=%s WHERE base=%s", (branch.base.id, branch.id))

        cursor.execute("DELETE FROM branches WHERE id=%s", (branch.id,))

        # Suppress the "user friendly" feedback if the push is performed by the
        # Critic system user, since there wouldn't be a human being reading it.
        if user_name != configuration.base.SYSTEM_USER_NAME:
            print "Deleted branch containing %d commit%s." % (ncommits, "s" if ncommits > 1 else "")

def createTag(repository_name, name, sha1):
    repository = gitutils.Repository.fromName(db, repository_name)

    sha1 = gitutils.getTaggedCommit(repository, sha1)

    if sha1:
        processCommits(repository.name, sha1)

        cursor = db.cursor()
        cursor.execute("INSERT INTO tags (name, repository, sha1) VALUES (%s, %s, %s)",
                       (name, repository.id, sha1))

def updateTag(repository_name, name, old_sha1, new_sha1):
    repository = gitutils.Repository.fromName(db, repository_name)

    sha1 = gitutils.getTaggedCommit(repository, new_sha1)
    cursor = db.cursor()

    if sha1:
        processCommits(repository.name, sha1)

        cursor.execute("UPDATE tags SET sha1=%s WHERE name=%s AND repository=%s",
                       (sha1, name, repository.id))
    else:
        cursor.execute("DELETE FROM tags WHERE name=%s AND repository=%s",
                       (name, repository.id))

def deleteTag(repository_name, name):
    repository = gitutils.Repository.fromName(db, repository_name)

    cursor = db.cursor()
    cursor.execute("DELETE FROM tags WHERE name=%s AND repository=%s",
                   (name, repository.id))

########NEW FILE########
__FILENAME__ = inpututils
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2013 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import sys
import os

# Try to import the readline module to augment raw_input(), used below, which
# automatically uses readline for line editing if it has been loaded.  We don't
# really care if it fails; that just means raw_input() is a bit dumber.
try: import readline
except: pass

__doc__ = "Helper functions for prompting for and reading input."

def apply_check(check, input):
    result = check(input)
    if result is None:
        return True
    elif result is True:
        print "Invalid input."
        print
    else:
        print "Invalid input: %s." % result
        print
    return False


def yes_or_no(prompt, default=None):
    prompt = "%s [%s/%s] " % (prompt, "Y" if default is True else "y", "N" if default is False else "n")

    while True:
        try: input = raw_input(prompt)
        except KeyboardInterrupt:
            print
            raise

        if input.lower() in ("y", "yes"):
            return True
        elif input.lower() in ("n", "no"):
            return False
        elif input or default is None:
            print "Please answer 'y'/'yes' or 'n'/'no'."
            print
        else:
            return default

def string(prompt, default=None, check=None):
    prompt = "%s%s " % (prompt, (" [%s]" % default) if default is not None else "")

    while True:
        try: input = raw_input(prompt)
        except KeyboardInterrupt:
            print
            raise

        if default and not input:
            input = default

        if check:
            if apply_check(check, input):
                return input
        elif not input:
            print "Invalid input: empty."
        else:
            return input

def password(prompt, default=None, twice=True):
    import termios

    prompt = "%s%s " % (prompt, " [****]" if default is not None else "")

    def internal(prompt):
        if os.isatty(sys.stdin.fileno()):
            old = termios.tcgetattr(sys.stdin)
            new = old[:]
            new[3] = new[3] & ~termios.ECHO
            try:
                termios.tcsetattr(sys.stdin, termios.TCSADRAIN, new)
                try: password = raw_input(prompt)
                except KeyboardInterrupt:
                    print
                    raise
            finally:
                termios.tcsetattr(sys.stdin, termios.TCSADRAIN, old)
        else:
            password = sys.stdin.readline().rstrip("\n")
        print
        if default and not password: return default
        else: return password

    while True:
        password = internal(prompt)

        if twice:
            andagain = internal("And again: ")

            if password == andagain:
                return password
            else:
                print
                print "Passwords differ.  Please try again."
                print
        else:
            return password

########NEW FILE########
__FILENAME__ = linkify
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2012 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import re

ALL_LINKTYPES = []

class Context(object):
    def __init__(self, db=None, request=None, repository=None, review=None, **kwargs):
        self.db = db
        self.request = request
        self.repository = repository or (review.repository if review else None)
        self.review = review
        self.extra = kwargs

class LinkType(object):
    """
    A link type object is responsible for providing a regexp fragment
    that matches the words (or substrings) that the link type produces
    hyper-links from, and for constructing actual URLs from such
    words.
    """

    def __init__(self, fragment):
        """
        LinkType(regexp) -> link type object

        Create a link type object and add it to the global list of
        link type objects.  The 'fragment' argument should be a string
        containing a regexp fragment without captures suitable to
        insert into the complete regexp

          (?:^|\b)(wordA|wordB|...)(?:\b|$)

        which is then used to split text into "words" which are
        individually turned into links or left as-is.
        """

        self.fragment = fragment
        self.fragment_regexp = re.compile("%s$" % fragment)

        ALL_LINKTYPES.append(self)

    def match(self, word):
        return bool(self.fragment_regexp.match(word))

    def linkify(self, word):
        """
        linkify(word) -> None or a string.

        If the whole word matches what this link type handles,
        constructs a URL to which this word should be made a link,
        otherwise returns None.  Implementations should expect to be
        called with words that don't match what they handle.

        Sub-classes must override this method.
        """
        pass

class SimpleLinkType(LinkType):
    """
    Base class for link type when the word contains the URL.
    """

    def __init__(self, fragment, regexp=None):
        super(SimpleLinkType, self).__init__(fragment)
        if isinstance(regexp, basestring):
            self.regexp = re.compile(regexp)
        else:
            self.regexp = regexp

    def linkify(self, word, context):
        if self.regexp:
            return self.regexp.match(word).group(1)
        else:
            return word

class HTTP(SimpleLinkType):
    """
    Link type "plain URL string".
    """

    def __init__(self):
        super(HTTP, self).__init__("https?://\\S+[^\\s.,:;!?)]")

class URL(SimpleLinkType):
    """
    Link type <URL:...>.
    """

    def __init__(self):
        super(URL, self).__init__("<URL:[^>]+>", "<URL:([^>]+)>$")

class SHA1(LinkType):
    """
    SHA-1 link type.

    Converts SHA-1 sums in text (either full or abbreviated) into
    links to the diff of the referenced commit.  When processed in the
    context of a repository, a matching commit in that repository is
    preferred (assuming it exists.)  When processed in the context of
    a review, a 'review=<id>' parameter is appended to the URL, which
    links to the diff of the referenced commit in the context of the
    review (which includes comments and allows reviewing.)
    """

    def __init__(self):
        super(SHA1, self).__init__("[0-9A-Fa-f]{8,40}")

    def linkify(self, word, context):
        sha1 = word
        if context.repository \
                and context.repository.iscommit(word):
            sha1 = context.repository.revparse(sha1)
            if context.review \
                    and context.review.containsCommit(context.db, sha1):
                return "/%s/%s?review=%d" % (context.repository.name, sha1, context.review.id)
            else:
                return "/%s/%s" % (context.repository.name, sha1)
        else:
            return "/%s" % sha1

class Diff(LinkType):
    """
    Diff link type.

    Like the SHA-1 link type, but with two sums separated by '..', and
    links to the diff between the two referenced commits.
    """

    def __init__(self):
        super(Diff, self).__init__("[0-9A-Fa-f]{8,40}\\.\\.[0-9A-Fa-f]{8,40}")

    def linkify(self, word, context):
        from_sha1, _, to_sha1 = word.partition("..")
        if context.repository \
                and context.repository.iscommit(from_sha1) \
                and context.repository.iscommit(to_sha1):
            from_sha1 = context.repository.revparse(from_sha1)
            to_sha1 = context.repository.revparse(to_sha1)
            if context.review \
                    and context.review.containsCommit(context.db, from_sha1) \
                    and context.review.containsCommit(context.db, to_sha1):
                return "/%s/%s..%s?review=%d" % (context.repository.name, from_sha1, to_sha1, context.review.id)
            else:
                return "/%s/%s..%s" % (context.repository.name, from_sha1, to_sha1)
        else:
            return "/%s..%s" % (from_sha1, to_sha1)

class Review(LinkType):
    """
    Review link type.

    Converts 'r/<id>' in text into a link to the front-page of the
    corresponding review.
    """

    def __init__(self):
        super(Review, self).__init__("r/\\d+")

    def linkify(self, word, context):
        return "/" + word

HTTP()
URL()
Diff()
SHA1()
Review()

try: import customization.linktypes
except ImportError: pass

########NEW FILE########
__FILENAME__ = commitset
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2012 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import gitutils

class CommitSet:
    def __init__(self, commits):
        self.__commits = dict([(str(commit), commit) for commit in commits])
        self.__merges = set()
        self.__children = {}

        parents = set()

        for commit in self.__commits.values():
            for parent in commit.parents:
                parents.add(parent)
                self.__children.setdefault(parent, set()).add(commit)
            if len(commit.parents) > 1:
                self.__merges.add(commit)

        commit_set = set(self.__commits.values())

        # Heads: commits that aren't the parent of a commit in the set.
        self.__heads = commit_set - parents

        # Tails: parent commits not included in the set.
        self.__tails = parents - commit_set

    def __contains__(self, commit):
        return str(commit) in self.__commits

    def __getitem__(self, key):
        return self.__commits[str(key)]

    def __len__(self):
        return len(self.__commits)

    def __iter__(self):
        return iter(self.__commits.values())

    def __repr__(self):
        return repr(self.__commits)

    def get(self, key):
        return self.__commits.get(str(key))

    def getHeads(self):
        return self.__heads.copy()

    def getTails(self):
        return self.__tails.copy()

    def getMerges(self):
        return self.__merges.copy()

    def getChildren(self, commit):
        children = self.__children.get(commit)
        if children: return children.copy()
        else: return set()

    def getParents(self, commit):
        return set([self.__commits[sha1] for sha1 in commit.parents if sha1 in self.__commits])

    def getFilteredTails(self, repository):
        """Return a set containing each tail commit of the set of commits that isn't an
ancestor of another tail commit of the set.  If the tail commits of the set
are all different commits on an upstream branch, then this will return only
the latest one."""

        candidates = self.getTails()
        result = set()

        while candidates:
            tail = candidates.pop()

            eliminated = set()
            for other in candidates:
                base = repository.mergebase([tail, other])
                if base == tail:
                    # Tail is an ancestor of other: tail should not be included
                    # in the returned set.
                    break
                elif base == other:
                    # Other is an ancestor of tail: other should not be included
                    # in the returned set.
                    eliminated.add(other)
            else:
                result.add(tail)
            candidates -= eliminated

        return result

    def getTailsFrom(self, commit):
        """
        Return a set containing the each tail commit of the set of commits that
        are ancestors of 'commit' and that are members of this commit set.

        A tail commit of a set is a commit that is not a member of the set but
        that is a parent of a commit that is a member of the set.
        """

        assert commit in self.__commits

        stack = set([commit.sha1])
        processed = set()
        tails = set()

        while stack:
            commit = self.__commits[stack.pop()]

            if commit not in processed:
                processed.add(commit)

                for sha1 in commit.parents:
                    parent = self.__commits.get(sha1)
                    if parent: stack.add(parent)
                    else: tails.add(sha1)

        return tails

    def getCommonAncestors(self, commit):
        """Return a set of each commit in this set that is an ancestor of each parent of
'commit' (which must be a member of the set) or None if the parents of 'commit'
have no common ancestor within this set."""

        common_ancestors = set()
        branches = []

        for sha1 in commit.parents:
            if sha1 not in self.__commits: return common_ancestors
            branches.append(set())

        for index, sha1 in enumerate(commit.parents):
            stack = set([sha1])
            branch = branches[index]

            while stack:
                commit = self.__commits.get(stack.pop())

                if commit and commit not in branch:
                    branch.add(commit)

                    for other_index, other_branch in enumerate(branches):
                        if commit not in other_branch: break
                    else:
                        common_ancestors.add(commit)
                        continue

                    stack.update(set(commit.parents))

        return common_ancestors

    def filtered(self, commits):
        filtered = set()
        commits = set(commits)

        while commits:
            commit = commits.pop()

            if commit not in filtered:
                filtered.add(commit)
                commits.update(self.getParents(commit))

        return CommitSet(filtered)

    def without(self, commits):
        """
        Return a copy of this commit set without 'commit' and any ancestors of
        'commit' that don't have other descendants in the commit set.
        """

        pending = set(filter(None, (self.__commits.get(str(commit)) for commit in commits)))
        commits = self.__commits.copy()
        children = self.__children.copy()

        while pending:
            commit = pending.pop()

            del commits[commit]
            if commit in children:
                del children[commit]

            for parent_sha1 in commit.parents:
                if parent_sha1 in commits:
                    children0 = children.get(parent_sha1, set())
                    children0 -= set([commit])
                    if not children0:
                        pending.add(commits[parent_sha1])

        return CommitSet(commits.values())

    def isAncestorOf(self, ancestor, commit):
        if ancestor == commit:
            return False
        else:
            descendants = self.__children.get(ancestor, set()).copy()
            pending = descendants.copy()

            while pending and not commit in descendants:
                descendant = pending.pop()
                children = self.__children.get(descendant, set()) - descendants

                descendants.update(children)
                pending.update(children)

            return commit in descendants

    @staticmethod
    def fromRange(db, from_commit, to_commit, commits=None):
        repository = to_commit.repository
        commits = set()

        class NotPossible(Exception): pass

        if commits:
            def getCommit(sha1):
                return commits[sha1]
        else:
            def getCommit(sha1):
                return gitutils.Commit.fromSHA1(db, repository, sha1)

        def process(iter_commit):
            while iter_commit != from_commit and iter_commit not in commits:
                commits.add(iter_commit)

                if len(iter_commit.parents) > 1:
                    # A merge commit.  Check if 'from_commit' is an ancestor of
                    # all its parents.  If not, we don't support constructing a
                    # commit-set from this range of commits (not because it is
                    # particularly difficult, but because such a commit-set
                    # would contain "unexpected" merged-in commits.)

                    if from_commit.isAncestorOf(repository.mergebase(iter_commit)):
                        map(process, [getCommit(sha1) for sha1 in iter_commit.parents])
                        return
                    else:
                        raise NotPossible
                elif iter_commit.parents:
                    iter_commit = getCommit(iter_commit.parents[0])
                else:
                    return

        if from_commit == to_commit:
            return CommitSet([to_commit])

        try:
            process(to_commit)
            return CommitSet(commits)
        except NotPossible:
            return None

########NEW FILE########
__FILENAME__ = html
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2012 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

from gitutils import Commit
from htmlutils import htmlify, jsify
from profiling import Profiler
from time import time, mktime, strftime, localtime

import re
import log.commitset

def formatWhen(when):
    def inner(when):
        delta = int(time() - mktime(when))
        if delta < 60: return "%d seconds ago" % delta
        elif delta < 60 * 60: return "%d minutes ago" % (delta / 60)
        elif delta < 60 * 60 * 24: return "%d hours ago" % (delta / (60 * 60))
        elif delta < 60 * 60 * 24 * 30: return "%d days ago" % (delta / (60 * 60 * 24))
        else: return strftime("%Y-%m-%d", localtime(mktime(when)))
    return inner(when).replace(" ", "&nbsp;")

def renderWhen(target, when):
    target.innerHTML(formatWhen(when))

def linkToCommit(commit, overrides={}):
    return "%s/%s" % (commit.repository.name, commit.sha1)

re_remote_into_local = re.compile("^Merge (?:branch|commit) '([^']+)' of [^ ]+ into \\1$")
re_side_into_main = re.compile("^Merge (?:remote )?(?:branch|commit) '[^']+' into .+$")
re_octopus = re.compile("^Merge ((?:(?:branches|,| and) '[^']+')+) into [^ ]+$")

class WhenColumn:
    def className(self, db, commit):
        return "when"
    def heading(self, target):
        target.text("When")
    def render(self, db, commit, target, overrides={}):
        renderWhen(target, commit.committer.time)

class TypeColumn:
    def className(self, db, commit):
        return "type"
    def heading(self, target):
        target.text()
    def render(self, db, commit, target, overrides={}):
        if "type" in overrides: target.text(overrides["type"])
        if len(commit.parents) > 1: target.text("Merge")
        else: target.text()

class SummaryColumn:
    def __init__(self, linkToCommit=linkToCommit):
        self.linkToCommit = linkToCommit
        self.isFixupOrSquash = None
    def className(self, db, commit):
        return "summary"
    def heading(self, target):
        target.text("Summary")
    def render(self, db, commit, target, overrides={}):
        summary = overrides.get("summary", commit.summary())
        classnames = ["commit"] + overrides.get("summary_classnames", [])

        if self.isFixupOrSquash is not None:
            data = self.isFixupOrSquash(commit)
            if data:
                what, ref = data
                target.span(what, critic_ref=ref).text("[%s] " % what)
                lines = commit.message.splitlines()[1:]
                while lines and not lines[0].strip():
                    lines.pop(0)
                if lines: summary = lines[0]
                else: summary = None
                if not summary:
                    classnames.append("nocomment")
                    summary = "(no comment)"

        url = self.linkToCommit(commit, overrides)

        if summary:
            target.a(" ".join(classnames), href=url).text(summary)

class AuthorColumn:
    def __init__(self):
        self.cache = {}
    def className(self, db, commit):
        return "author"
    def heading(self, target):
        target.text("Author")
    def render(self, db, commit, target, overrides={}):
        if "author" in overrides:
            fullname = overrides["author"].fullname
        else:
            fullname = commit.author.getFullname(db)
        target.text(fullname)

DEFAULT_COLUMNS = [(10, WhenColumn()),
                   (5, TypeColumn()),
                   (65, SummaryColumn()),
                   (20, AuthorColumn())]

def render(db, target, title, branch=None, commits=None, columns=DEFAULT_COLUMNS, title_right=None, listed_commits=None, rebases=None, branch_name=None, bottom_right=None, review=None, highlight=None, profiler=None, collapsable=False, user=None, extra_commits=None, conflicts=set()):
    addResources(target)

    if not profiler: profiler = Profiler()

    profiler.check("log: start")

    if branch is not None:
        repository = branch.repository
        branch.loadCommits(db)
        commits = branch.commits[:]
        commit_set = log.commitset.CommitSet(branch.commits)
    else:
        assert commits is not None
        repository = commits[0].repository if len(commits) else None
        commit_set = log.commitset.CommitSet(commits)

    profiler.check("log: commits")

    heads = commit_set.getHeads()
    tails = commit_set.getTails()

    rebase_old_heads = set()

    if rebases:
        class Rebase(object):
            def __init__(self, rebase_id, old_head, new_head, user,
                         new_upstream, target_branch_name):
                self.id = rebase_id
                self.old_head = Commit.fromId(db, repository, old_head)
                self.new_head = Commit.fromId(db, repository, new_head)
                self.user = user
                self.new_upstream = new_upstream and Commit.fromId(db, repository, new_upstream)
                self.target_branch_name = target_branch_name

        # The first element in the tuples in 'rebases' is the rebase id, which
        # is an ever-increasing serial number that we can use as an indication
        # of the order in which the rebases were made.
        rebases = [Rebase(*rebase) for rebase in sorted(rebases)]
        rebase_old_heads = set(rebase.old_head for rebase in rebases)
        heads -= rebase_old_heads

        assert 0 <= len(heads) <= 1

        if not heads:
            heads = set([rebases[-1].new_head])

    if repository:
        target.addInternalScript(repository.getJS())

    processed = set()
    summaries = {}

    for commit in commits:
        summary = commit.summary().strip()
        summaries[summary] = commit
        summaries[commit.sha1] = commit

    if extra_commits:
        for commit in extra_commits:
            summary = commit.summary().strip()
            summaries[summary] = commit
            summaries[commit.sha1] = commit

    def isFixupOrSquash(commit):
        key, _, summary = commit.summary().partition(" ")

        if key in ("fixup!", "squash!"):
            what = key[:-1]
        else:
            return None

        summary = summary.strip()
        commit = summaries.get(summary)

        if not commit and re.match("[0-9A-Fa-f]{40}$", summary):
            commit = summaries.get(summary)

            if not commit:
                try:
                    sha1 = repository.revparse(summary)
                    commit = Commit.fromSHA1(db, repository, sha1)
                except Exception:
                    pass

            if commit:
                summary = commit.summary()

        return what, summary

    for width, column in columns:
        if isinstance(column, SummaryColumn):
            column.isFixupOrSquash = isFixupOrSquash
            break

    def output(table, commit, overrides={}):
        if commit not in processed:
            classes = ["commit"]
            row_id = None

            if len(commit.parents) > 1:
                classes.append("merge")

            if highlight == commit:
                classes.append("highlight")
                row_id = commit.sha1

            row = table.tr(" ".join(classes), id=row_id)
            profiler.check("log: rendering: row")
            for index, (width, column) in enumerate(columns):
                column.render(db, commit, row.td(column.className(db, commit)), overrides=overrides)
                profiler.check("log: rendering: column %d" % (index + 1))
            processed.add(commit)

            return row
        else:
            return None

    cursor = db.cursor()

    def emptyCommit(commit):
        cursor.execute("""SELECT 1
                            FROM fileversions
                            JOIN changesets ON (changesets.id=fileversions.changeset)
                            JOIN reviewchangesets ON (reviewchangesets.changeset=changesets.id)
                           WHERE changesets.child=%s
                             AND reviewchangesets.review=%s""",
                       (commit.getId(db), review.id))
        return not cursor.fetchone()

    def inner(target, head, tails, align='right', title=None, table=None, silent_if_empty=set(), upstream=None):
        if not table:
            table = target.table('log', align=align, cellspacing=0)

            for width, column in columns: table.col(width=('%d%%' % width))

            if title:
                thead = table.thead()
                row = thead.tr("title")
                header = row.td("h1", colspan=len(columns)).h1()
                header.text(title)
                if callable(title_right):
                    title_right(db, header.span("right"))

                row = thead.tr('headings')
                for width, column in columns:
                    column.heading(row.td(column.className(db, None)))
            elif head is None or head in tails:
                if upstream:
                    tag = upstream.findInterestingTag(db)
                    if tag: what = tag
                    else: what = upstream.sha1[:8]
                    message = "Merged with base branch (%s)." % what
                else: message = "Merged with base branch."

                thead = table.thead()
                row = thead.tr('basemerge')
                row.td(colspan=len(columns), align='center').text(message)
                return (None, None, None, False)

        tbody = table.tbody()
        commit = head

        last_commit = None
        skipped = True

        while commit and commit not in tails:
            suppress = False
            optional_merge = False
            listed = listed_commits is None or commit.getId(db) in listed_commits

            if commit in silent_if_empty and emptyCommit(commit):
                # This is a clean automatically generated merge commit; pretend it isn't here at all.
                suppress = True

            if not suppress and not listed:
                suppress = len(commit.parents) == 1
                optional_merge = not suppress

            if not suppress: commit_tr = output(tbody, commit)
            else: commit_tr = None

            if listed: skipped = False
            last_commit = commit

            if len(commit.parents) == 0:
                break
            elif len(commit.parents) == 1:
                commit = commit_set.get(commit.parents[0])
            elif len(commit.parents) > 1:
                if len(commit.parents) > 2:
                    common_ancestors = commit_set.getCommonAncestors(commit)
                    match = re_octopus.match(commit.message.split("\n", 1)[0])

                    if match:
                        titles = re.findall("'([^']+)'", match.group(1))
                        if len(titles) != len(commit.parents):
                            titles = None
                    else:
                        titles = None

                    for index, sha1 in enumerate(commit.parents):
                        if sha1 in commit_set:
                            sublog = tbody.tr('sublog')
                            inner_last_commit, inner_table, inner_tail, inner_skipped = inner(sublog.td(colspan=len(columns)), commit_set[sha1], common_ancestors, title=titles and titles[index] or None)
                            if inner_skipped:
                                sublog.remove()
                                if optional_merge and commit_tr: commit_tr.remove()

                    if not common_ancestors: return (None, None, None, False)

                    commit = common_ancestors.pop()
                    continue

                parent1_sha1 = commit.parents[0]
                parent2_sha1 = commit.parents[1]

                parent1 = commit_set.get(parent1_sha1)
                parent2 = commit_set.get(parent2_sha1)

                # TODO: Try to remember what this code actually does, and why...
                if parent1_sha1 in rebase_old_heads:
                    if parent2:
                        sublog = tbody.tr('sublog')
                        inner_last_commit, inner_table, inner_tail, inner_skipped = \
                            inner(sublog.td(colspan=len(columns)), parent2, tails)
                        if inner_skipped:
                            sublog.remove()
                            if optional_merge and commit_tr: commit_tr.remove()
                    return (commit, table, parent1_sha1, False)
                elif parent2_sha1 in rebase_old_heads:
                    if parent1:
                        sublog = tbody.tr('sublog')
                        inner_last_commit, inner_table, inner_tail, inner_skipped = \
                            inner(sublog.td(colspan=len(columns)), parent1, tails)
                        if inner_skipped:
                            sublog.remove()
                            if optional_merge and commit_tr: commit_tr.remove()
                    return (commit, table, parent2_sha1, False)

                if parent1 and parent2:
                    common_ancestors = commit_set.getCommonAncestors(commit)

                    merged_remote_into_local = re_remote_into_local.match(commit.summary()) or re_side_into_main.match(commit.summary())

                    def rankPaths(commit, tails):
                        shortest = None
                        shortest_length = len(commit_set)
                        longest = None
                        longest_length = 0

                        for sha1 in commit.parents:
                            parent = commit_set[sha1]

                            counted = set()
                            pending = set([parent])

                            while pending:
                                candidate = pending.pop()

                                if candidate in counted: continue
                                if candidate in tails: continue

                                counted.add(candidate)
                                pending.update(commit_set.getParents(candidate))

                            length = len(counted)

                            if length < shortest_length:
                                shortest = parent
                                shortest_length = length
                            if length >= longest_length:
                                longest = parent
                                longest_length = length

                        return shortest, shortest_length, longest, longest_length

                    show_merged, shortest_length, show_normal, longest_length = rankPaths(commit, common_ancestors | tails)
                    display_parallel = False

                    if merged_remote_into_local and shortest_length * 2 > longest_length:
                        if len(common_ancestors) == 1 and len(commit_set.filtered([commit]).getTails()) == 1:
                            display_parallel = True
                        else:
                            show_merged = parent2
                            show_normal = parent1

                    if display_parallel:
                        all_empty = True

                        for sha1 in commit.parents:
                            sublog = tbody.tr('sublog')
                            inner_last_commit, inner_table, inner_tail, inner_skipped = inner(sublog.td(colspan=len(columns)), commit_set[sha1], common_ancestors | tails)
                            if inner_skipped:
                                sublog.remove()
                            else:
                                all_empty = False

                        if all_empty and optional_merge and commit_tr: commit_tr.remove()

                        commit = common_ancestors.pop()
                    else:
                        sublog = tbody.tr('sublog')
                        inner_last_commit, inner_table, inner_tail, inner_skipped = inner(sublog.td(colspan=len(columns)), show_merged, common_ancestors | tails)
                        if inner_skipped:
                            sublog.remove()
                            if optional_merge and commit_tr: commit_tr.remove()

                        commit = show_normal
                else:
                    if parent1: upstream_sha1 = parent2_sha1
                    else: upstream_sha1 = parent1_sha1

                    if not commit in silent_if_empty:
                        # Merge with the base branch.
                        inner(tbody.tr('sublog').td(colspan=len(columns)), None, None, upstream=Commit.fromSHA1(db, repository, upstream_sha1))

                    if parent1: commit = parent1
                    else: commit = parent2

        return (last_commit, table, last_commit.parents[0] if last_commit and last_commit.parents else None, skipped)

    class_name = "paleyellow log"

    if collapsable:
        class_name += " collapsable"

    table = target.table(class_name, align='center', cellspacing=0)

    for width, column in columns: table.col(width=('%d%%' % width))

    thead = table.thead("title")
    row = thead.tr("title")
    header = row.td("h1", colspan=len(columns)).h1()

    error_message = None

    if len(commit_set) == 0:
        thead = table.thead()
        row = thead.tr('error')
        cell = row.td(colspan=len(columns), align='center')
        cell.text("No commits. ")
        if review:
            review.branch.loadCommits(db)
            cell.a(href="showtree?sha1=%s&review=%d" % (review.branch.head.sha1, review.id)).text("[Browse tree]")
        return
    elif len(heads) > 1:
        error_message = "Invalid commit set: Multiple heads."
    elif len(heads) == 0:
        error_message = "Invalid commit set: No heads."

    if error_message is not None:
        thead = table.thead()
        row = thead.tr('error')
        cell = row.td(colspan=len(columns), align='center')
        cell.text(error_message)
        return

    head = heads.pop() if heads else None

    row = thead.tr('headings')
    for width, column in columns:
        column.heading(row.td(column.className(db, None)))

    first_rebase = True
    silent_if_empty = set()

    if rebases:
        for rebase in rebases:
            if rebase.new_upstream or rebase.target_branch_name:
                silent_if_empty.add(rebase.old_head)

        top_rebases = []

        while rebases and head == rebases[-1].new_head:
            rebase = rebases.pop()
            top_rebases.append((head, rebase))
            head = rebase.old_head

        for rebase_head, rebase in top_rebases:
            thead = table.thead("rebase")
            row = thead.tr('rebase')
            cell = row.td(colspan=len(columns), align='center')

            if rebase.new_upstream is None and not rebase.target_branch_name:
                cell.text("History rewritten")
            else:
                cell.text("Branch rebased onto ")
                if rebase.target_branch_name:
                    anchor = cell.a(href=("/checkbranch?repository=%d&commit=%s"
                                          % (repository.id, rebase.target_branch_name)))
                    anchor.text(rebase.target_branch_name)
                else:
                    upstream_description = repository.describe(db, rebase.new_upstream.sha1)
                    if upstream_description is None:
                        upstream_description = rebase.new_upstream.sha1[:8]
                    anchor = cell.a(href="/%s/%s" % (repository.name, rebase.new_upstream.sha1))
                    anchor.text(upstream_description)

            cell.text(" by %s" % rebase.user.fullname)

            if first_rebase:
                cell.text(": ")
                review_param = "&review=%d" % review.id if review else ""
                cell.a(href="log?repository=%d&branch=%s%s" % (repository.id, branch_name, review_param)).text("[actual log]")

                if user and user == rebase.user:
                    cell.text(" ")
                    cell.a(href="javascript:revertRebase(%d)" % rebase.id).text("[revert]")

                first_rebase = False
            else:
                cell.text(".")

            if rebase.new_head in conflicts and not emptyCommit(rebase.new_head):
                output(table, rebase.new_head,
                       overrides={ "type": "Rebase",
                                   "summary": "Changes introduced by rebase",
                                   "summary_classnames": ["rebase"],
                                   "author": rebase.user,
                                   "rebase_conflicts": conflicts[rebase.new_head] })

    while True:
        # 'local_tails' is the set of commits that, when reached, should make
        # inner() stop outputting commits and instead return.  This set of
        # commits contains all the "tails" of the whole commit-set we're
        # rendering (in the 'tails' set here), as well as the "new head" of the
        # next rebase to be output.

        local_tails = tails.copy()

        if rebases:
            local_tails.add(rebases[-1].new_head)

        last_commit, table, tail, skipped = inner(
            target, head, local_tails, 'center', title, table, silent_if_empty)

        if rebases:
            rebase = rebases.pop()

            assert tail == rebase.new_head, "tail (%s) != rebase.new_head (%s)" % (tail, rebase.new_head)

            while True:
                head = rebase.old_head

                thead = table.thead("rebase")
                row = thead.tr('rebase')
                cell = row.td(colspan=len(columns), align='center')

                if rebase.new_upstream is None and not rebase.target_branch_name:
                    cell.text("History rewritten")
                else:
                    cell.text("Branch rebased onto ")
                    if rebase.target_branch_name:
                        anchor = cell.a(href=("/checkbranch?repository=%d&commit=%s"
                                              % (repository.id, rebase.target_branch_name)))
                        anchor.text(rebase.target_branch_name)
                    else:
                        upstream_description = repository.describe(db, rebase.new_upstream.sha1)
                        if upstream_description is None:
                            upstream_description = rebase.new_upstream.sha1[:8]
                        anchor = cell.a(href="/%s/%s" % (repository.name, rebase.new_upstream.sha1))
                        anchor.text(upstream_description)

                cell.text(" by %s" % rebase.user.fullname)

                if first_rebase:
                    cell.text(": ")
                    review_param = "&review=%d" % review.id if review else ""
                    cell.a(href="log?repository=%d&branch=%s%s" % (repository.id, branch_name, review_param)).text("[actual log]")
                    first_rebase = False
                else:
                    cell.text(".")

                if rebase.new_head in conflicts:
                    if len(rebase.new_head.parents) < 2 and not emptyCommit(rebase.new_head):
                        output(table, rebase.new_head,
                               overrides={ "type": "Rebase",
                                           "summary": "Changes introduced by rebase",
                                           "summary_classnames": ["rebase"],
                                           "author": rebase.user,
                                           "rebase_conflicts": conflicts[rebase.new_head] })

                if rebases and rebases[-1].new_head == head:
                    rebase = rebases.pop()
                else:
                    break

            continue

        if last_commit:
            if len(last_commit.parents) == 1:
                upstream = Commit.fromSHA1(db, repository, last_commit.parents[0])
                upstream_description = repository.describe(db, upstream.sha1)

                if not upstream_description:
                    upstream_description = upstream.sha1[:8]

                row = table.thead("rebase").tr('upstream')
                cell = row.td(colspan=len(columns), align='center')
                cell.text("Based on: ")
                anchor = cell.a(href="/%s/%s" % (repository.name, upstream.sha1))
                anchor.text(upstream_description)

        if callable(bottom_right):
            bottom_right(db, table.tfoot().tr().td(colspan=len(columns)))

        break

    profiler.check("log: rendering")

    if "%d" in title: header.text(title % len(processed))
    else: header.text(title)

    if callable(title_right):
        title_right(db, header.span("right"))

def renderList(db, target, title, commits, columns=DEFAULT_COLUMNS, title_right=None, bottom_right=None, hide_merges=False, className="log"):
    addResources(target)

    table = target.table(className, align="center", cellspacing=0)

    for width, column in columns: table.col(width=("%d%%" % width))

    thead = table.thead()
    title_h1 = None

    if title:
        row = thead.tr("title")
        title_h1 = row.td("h1", colspan=len(columns)).h1()
        title_h1.text(title)

        row = thead.tr("headings")
        for width, column in columns:
            column.heading(row.td(column.className(db, None)))

    tbody = table.tbody()
    merges = 0

    for commit in commits:
        classname = "commit"

        if hide_merges:
            is_merge = len(commit.parents) > 1
            if is_merge:
                classname += " merge"
                merges += 1

        row = tbody.tr(classname, id=commit.sha1)

        for width, column in columns:
            column.render(db, commit, row.td(column.className(db, commit)))

    if merges and title_h1:
        title_h1.a(href="javascript:void(0);", onclick="showRelevantMerges(event);").text("[Show %d merge commits]" % merges)

    if callable(title_right):
        title_right(db, title_h1.span("right"))

    if callable(bottom_right):
        bottom_right(db, table.tfoot().tr().td(colspan=len(columns)))

def addResources(target):
    target.addExternalStylesheet("resource/log.css")
    target.addExternalScript("resource/log.js")

########NEW FILE########
__FILENAME__ = mailutils
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2012 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import time
import os
import signal
import email.utils

import configuration
import dbutils

def generateMessageId(index=1):
    now = time.time()

    timestamp = time.strftime("%Y%m%d%H%M%S", time.gmtime(now))
    timestamp_ms = "%04d" % ((now * 10000) % 10000)

    return "%s.%s.%04d" % (timestamp, timestamp_ms, index)

def queueMail(from_user, to_user, recipients, subject, body, message_id=None,
              parent_message_id=None, headers=None):
    if not message_id:
        message_id = generateMessageId()

    if headers is None:
        headers = {}
    else:
        headers = headers.copy()

    if parent_message_id:
        parent_message_id = "<%s@%s>" % (parent_message_id, configuration.base.HOSTNAME)

    filename = "%s/%s_%s_%s.txt.pending" % (configuration.paths.OUTBOX,
                                            from_user.name, to_user.name,
                                            message_id)

    with open(filename, "w") as file:
        print >> file, repr({ "message_id": message_id,
                              "parent_message_id": parent_message_id,
                              "headers": headers,
                              "from_user": from_user,
                              "to_user": to_user,
                              "recipients": recipients,
                              "subject": subject,
                              "body": body })

    return filename

class User:
    def __init__(self, *args):
        if len(args) == 1:
            self.name = configuration.base.SYSTEM_USER_NAME
            self.fullname, self.email = email.utils.parseaddr(args[0])
        else:
            self.name, self.email, self.fullname = args

    def __repr__(self):
        return "User(%r, %r)" % (self.email, self.fullname)

def sendMessage(recipients, subject, body):
    from_user = User(configuration.base.SYSTEM_USER_NAME, configuration.base.SYSTEM_USER_EMAIL, "Critic System")
    filenames = []

    for to_user in recipients:
        filenames.append(queueMail(from_user, to_user, recipients, subject, body))

    sendPendingMails(filenames)

def sendAdministratorMessage(source, summary, message):
    recipients = []

    for recipient in configuration.base.SYSTEM_RECIPIENTS:
        recipients.append(User(recipient))

    sendMessage(recipients, "%s: %s" % (source, summary), message)

def sendAdministratorErrorReport(db, source, summary, message):
    if db:
        installed_sha1 = dbutils.getInstalledSHA1(db)
    else:
        installed_sha1 = "<unknown>"
    sendAdministratorMessage(source, summary, """\

Critic encountered an unexpected error.  If you know a series of steps that can
reproduce this error it would be very useful if you submitted a bug report
including the steps plus the information below (see bug reporting URL at the
bottom of this e-mail).

%(message)s

Critic version: %(installed_sha1)s
Critic bug reports can be filed here: https://github.com/jensl/critic/issues/new
""" % { "message": message, "installed_sha1": installed_sha1 })

def sendExceptionMessage(db, source, exception):
    lines = exception.splitlines()
    sendAdministratorErrorReport(db, source, lines[-1], exception.rstrip())

def sendPendingMails(filenames):
    for filename in filenames:
        if filename.endswith(".txt.pending"):
            os.rename(filename, filename[:-len(".pending")])

    try:
        pid = int(open(configuration.services.MAILDELIVERY["pidfile_path"]).read().strip())
        os.kill(pid, signal.SIGHUP)
    except:
        pass

########NEW FILE########
__FILENAME__ = check-branches
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2012 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import sys
import os
import os.path
import argparse
import errno

sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(sys.argv[0]), "..")))

import dbutils
import gitutils
import log.commitset
import progress

parser = argparse.ArgumentParser()
parser.add_argument("--exclude", action="append", help="exclude repository")
parser.add_argument("--include", action="append", help="include (only) repository")
parser.add_argument("--dry-run", "-n", action="store_true", help="don't touch the database or repositories")
parser.add_argument("--force", "-f", action="store_true", help="update the database and/or repositories")

arguments = parser.parse_args()

if not arguments.dry_run and not arguments.force:
    print "One of --dry-run/-n and --force/-f must be specified."
    sys.exit(1)
elif arguments.dry_run and arguments.force:
    print "Only one of --dry-run/-n and --force/-f can be specified."
    sys.exit(1)

force = arguments.force

db = dbutils.Database()
cursor = db.cursor()

def getBranchCommits(repository, branch_id):
    cursor = db.cursor()
    cursor.execute("SELECT sha1 FROM commits JOIN reachable ON (commit=id) WHERE branch=%s", (branch_id,))

    return log.commitset.CommitSet(gitutils.Commit.fromSHA1(db, repository, sha1) for (sha1,) in cursor)

def getReview(branch_id):
    cursor = db.cursor()
    cursor.execute("SELECT id FROM reviews WHERE branch=%s", (branch_id,))
    return cursor.fetchone()[0]

def getReviewCommits(repository, review_id):
    review_id = getReview(branch_id)

    cursor.execute("""SELECT changesets.child
                        FROM changesets
                        JOIN reviewchangesets ON (reviewchangesets.changeset=changesets.id)
                       WHERE reviewchangesets.review=%s""",
                   (review_id,))

    return log.commitset.CommitSet(gitutils.Commit.fromId(db, repository, commit_id) for (commit_id,) in cursor)

def getReviewHead(repository, review_id):
    commits = getReviewCommits(repository, review_id)
    heads = commits.getHeads()

    if len(heads) == 1: return heads.pop()

    cursor = db.cursor()
    cursor.execute("""SELECT commits.sha1
                        FROM commits
                        JOIN reviewrebases ON (reviewrebases.old_head=commits.id)
                       WHERE reviewrebases.review=%s""",
                   (review_id,))

    for (sha1,) in cursor: heads.remove(sha1)

    if len(heads) == 1: return heads.pop()
    else: return None

if arguments.include:
    cursor.execute("SELECT id FROM repositories WHERE name=ANY (%s)", (arguments.include,))
else:
    cursor.execute("SELECT id FROM repositories")
repository_ids = cursor.fetchall()

incorrect_reviews = []

for repository_id in repository_ids:
    repository = gitutils.Repository.fromId(db, repository_id)

    if arguments.exclude and repository.name in arguments.exclude:
        print "Repository: %s (skipped)" % repository.name
        continue

    cursor.execute("""SELECT branches.id, branches.name, branches.type, branches.base, commits.sha1
                        FROM branches
                        JOIN commits ON (commits.id=branches.head)
                       WHERE branches.repository=%s""",
                   (repository_id,))

    branches = cursor.fetchall()
    refs = {}
    batch = []

    try:
        for line in open(os.path.join(repository.path, "packed-refs")):
            if not line.startswith("#"):
                try:
                    sha1, ref = line.split()
                    if len(sha1) == 40 and ref.startswith("refs/heads/"):
                        refs[ref[11:]] = sha1
                except ValueError:
                    pass
    except IOError as error:
        if error.errno == errno.ENOENT: pass
        else: raise

    progress.start(len(branches), "Repository: %s" % repository.name)

    heads_path = os.path.join(repository.path, "refs", "heads")

    branches_in_db = set()

    for branch_id, branch_name, branch_type, branch_base_id, branch_sha1 in branches:
        progress.update()

        branches_in_db.add(branch_name)

        try:
            try: repository_sha1 = open(os.path.join(heads_path, branch_name)).read().strip()
            except: repository_sha1 = refs.get(branch_name)

            if repository_sha1 != branch_sha1:
                progress.write("NOTE[%s]: %s differs (db:%s != repo:%s)" % (repository.name, branch_name, branch_sha1[:8], repository_sha1[:8]))

                if branch_type == "review":
                    head = getReviewHead(repository, getReview(branch_id))

                    if not head:
                        progress.write("  invalid review meta-data: r/%d" % getReview(branch_id))
                        continue

                    if head.sha1 == branch_sha1:
                        progress.write("  branches.head matches review meta-data; repository is wrong")
                        if force: repository.run("update-ref", "refs/heads/%s" % branch_name, head.sha1, repository_sha1)
                        progress.write("  repository updated")
                    elif head.sha1 == repository_sha1:
                        progress.write("  repository matches review meta-data; branches.head is wrong")
                        if force: cursor.execute("UPDATE branches SET head=%s WHERE id=%s", (head.getId(db), branch_id))
                        db.commit()
                    else:
                        progress.write("  review meta-data matches neither branches.head nor repository")
                        incorrect_reviews.append((getReview(branch_id), "review meta-data matches neither branches.head nor repository"))
                else:
                    try:
                        gitutils.Commit.fromSHA1(db, repository, branch_sha1)
                        progress.write("  branches.head exists in repository")
                    except KeyboardInterrupt: sys.exit(1)
                    except:
                        progress.write("  branches.head not in repository; updating branches.head")
                        head = gitutils.Commit.fromSHA1(db, repository, repository_sha1)
                        if force: cursor.execute("UPDATE branches SET head=%s WHERE id=%s", (head.getId(db), branch_id))
                        db.commit()
                        continue

                    try:
                        commits = getBranchCommits(repository, branch_id)
                        heads = commits.getHeads()

                        if len(heads) > 1:
                            progress.write("  reachable commit-set has multiple heads")
                            continue

                        head = heads.pop()

                        if head.sha1 == branch_sha1:
                            progress.write("  reachable agrees with branches.head; repository is wrong")
                            if force: repository.run("update-ref", "refs/heads/%s" % branch_name, head.sha1, repository_sha1)
                            progress.write("  repository updated")
                        elif head.sha1 == repository_sha1:
                            progress.write("  reachable agrees with repository; branches.head is wrong")
                            if force: cursor.execute("UPDATE branches SET head=%s WHERE id=%s", (head.getId(db), branch_id))
                            db.commit()
                            continue
                    except KeyboardInterrupt: sys.exit(1)
                    except:
                        progress.write("  reachable contains missing commits")
        except KeyboardInterrupt: sys.exit(1)
        except:
            progress.write("WARNING[%s]: %s missing!" % (repository.name, branch_name))

            if branch_type == "normal":
                cursor.execute("SELECT id FROM branches WHERE base=%s", (branch_id,))

                sub_branches = cursor.fetchall()
                if sub_branches:
                    progress.write("  branch has sub-branches")

                    base_branch = dbutils.Branch.fromId(db, branch_base_id)

                    for (sub_branch_id,) in sub_branches:
                        sub_branch = dbutils.Branch.fromId(db, sub_branch_id)
                        sub_branch.rebase(db, base_branch)
                        progress.write("    rebased sub-branch %s" % sub_branch.name)

                try:
                    if force:
                        cursor.execute("DELETE FROM branches WHERE id=%s", (branch_id,))
                        db.commit()
                    progress.write("  deleted from database")
                except KeyboardInterrupt: sys.exit(1)
                except:
                    progress.write("  failed to delete from database")
                    db.rollback()
            else:
                try: review_id = getReview(branch_id)
                except KeyboardInterrupt: sys.exit(1)
                except:
                    progress.write("  review branch without review; deleting")
                    try:
                        if force: cursor.execute("DELETE FROM branches WHERE id=%s", (branch_id,))
                        db.commit()
                    except KeyboardInterrupt: sys.exit(1)
                    except:
                        progress.write("  failed to delete from database")
                        db.rollback()
                    continue

                try: commits = getReviewCommits(repository, getReview(branch_id))
                except KeyboardInterrupt: sys.exit(1)
                except:
                    progress.write("  review meta-data references missing commits")
                    incorrect_reviews.append((getReview(branch_id), "branches.head = %s" % branch_sha1))
                    continue

                heads = commits.getHeads()

                if len(heads) > 1:
                    progress.write("  multiple heads: r/%d" % review_id)
                    continue

                head = heads.pop()

                try:
                    if force: repository.run("update-ref", "refs/heads/%s" % branch_name, head.sha1, "0" * 40)
                    progress.write("  re-created review branch")
                except KeyboardInterrupt: sys.exit(1)
                except:
                    progress.write("  failed to re-create review branch")
                    incorrect_reviews.append((getReview(branch_id), "failed to re-create review branch"))

    processed = set()

    def exists_in_db(branch_name):
        return branch_name in branches_in_db

    def process(path, prefix=None):
        for entry in os.listdir(path):
            entry_path = os.path.join(path, entry)
            branch_name = os.path.join(prefix, entry) if prefix else entry
            if os.path.isdir(entry_path):
                process(entry_path, branch_name)
            elif not exists_in_db(branch_name):
                progress.write("WARNING[%s]: %s exists in the repository but not in the database!" % (repository.name, branch_name))
                if force: repository.run("update-ref", "-d", "refs/heads/%s" % branch_name)
                progress.write("  deleted from repository")
            processed.add(branch_name)

    for branch_name in refs.keys():
        if branch_name not in processed and not exists_in_db(branch_name):
            progress.write("WARNING[%s]: %s exists in the repository but not in the database!" % (repository.name, branch_name))
            if force: repository.run("update-ref", "-d", "refs/heads/%s" % branch_name)
            progress.write("  deleted from repository")

    process(heads_path)

    progress.end(".")

if incorrect_reviews:
    print "\nReviews that need attention:"

    for review_id, message in incorrect_reviews:
        print "  %5d: %s" % (review_id, message)

########NEW FILE########
__FILENAME__ = check-commits
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2012 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import sys
import os
import cPickle

sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(sys.argv[0]), "..")))

import dbutils
import gitutils
import progress

db = dbutils.Database()
cursor = db.cursor()

commits = {}
pending_commits = set()

cursor.execute("SELECT COUNT(*) FROM commits")

print

progress.start(cursor.fetchone()[0], prefix="Fetching commits ...")

cursor.execute("SELECT id, sha1 FROM commits")

for commit_id, commit_sha1 in cursor:
    commits[commit_id] = commit_sha1
    pending_commits.add(commit_id)

    progress.update()

progress.end(" %d commits." % len(commits))

print

cursor.execute("SELECT MAX(CHARACTER_LENGTH(name)) FROM repositories")

repository_name_length = cursor.fetchone()[0]

cursor.execute("SELECT id FROM repositories ORDER BY id ASC")

repositories = [repository_id for (repository_id,) in cursor]

def processCommits(process_commits):
    global commits

    processed_commits = set()

    for commit_id in process_commits:
        try:
            gitobject = repository.fetch(commits[commit_id])
            if gitobject.type == "commit": processed_commits.add(commit_id)
        except gitutils.GitError:
            pass
        except KeyboardInterrupt:
            sys.exit(1)
        except:
            raise

        progress.update()

    return processed_commits

for repository_id in repositories:
    repository = gitutils.Repository.fromId(db, repository_id)
    repository.disableCache()

    cursor.execute("SELECT commit FROM reachable JOIN branches ON (branch=id) WHERE repository=%s", (repository.id,))
    process_commits = set(commit_id for (commit_id,) in cursor if commit_id in pending_commits)

    progress.start(len(process_commits), "Scanning repository: %-*s" % (repository_name_length, repository.name))

    processed_commits = processCommits(process_commits)

    missing = len(process_commits) - len(processed_commits)
    if missing:
        message = " %d commits found; %d commits missing!" % (len(processed_commits), missing)
    else:
        message = " %d commits found." % len(processed_commits)
    progress.end(message)

    pending_commits -= processed_commits

if pending_commits:
    print
    print "%d commits still unaccounted for.  Re-scanning all repositories." % len(pending_commits)
    print

    for repository_id in repositories:
        repository = gitutils.Repository.fromId(db, repository_id)
        repository.disableCache()

        progress.start(len(pending_commits), "Re-scanning repository: %-*s" % (repository_name_length, repository.name))

        processed_commits = processCommits(pending_commits)
        pending_commits -= processed_commits

        progress.end(" %d commits found, %d remaining." % (len(processed_commits), len(pending_commits)))

        if not pending_commits: break

    if pending_commits:
        cPickle.dump(pending_commits, open("commits-to-purge.pickle", "w"), 2)

        print
        print "%d commits that were not found in any repository should be purged." % len(pending_commits)
        print "Run purge-commits.py to do this."

########NEW FILE########
__FILENAME__ = configtest
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2014 the Critic contributors, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import contextlib
import traceback

def reflow(text, indent):
    try:
        import textutils
        return textutils.reflow(text, indent=indent)
    except Exception:
        # The 'textutils' module depends on 'configuration', so make our
        # dependency on it conditional.
        return text

class ConfigurationValue(object):
    def __init__(self, module, name):
        self.path = module.__file__
        if self.path.endswith(".pyc") or self.path.endswith(".pyo"):
            self.path = self.path[:-1]
        self.name = name

class ConfigurationIssue(object):
    def __init__(self, issue_type, message, values):
        self.type = issue_type
        self.message = message
        self.values = values[:]

    def __str__(self):
        result = self.type.upper() + "\n"
        if self.values:
            result += "  Relating to settings:\n"
            for value in self.values:
                result += "    %s :: %s\n" % (value.path, value.name)
        result += "  Message:\n"
        result += reflow(self.message, indent=4)
        return result

def doTestConfiguration():
    """Do not call directly; call testConfiguration()"""

    import configuration

    errors = []
    warnings = []
    values = []

    def error(message):
        errors.append(ConfigurationIssue("error", message, values))
    def warn(message):
        warnings.append(ConfigurationIssue("warning", message, values))

    class MissingValue(Exception):
        pass

    @contextlib.contextmanager
    def value(module, name):
        values.append(ConfigurationValue(module, name))
        if not hasattr(module, name):
            error("Configuration value missing: %s.%s" % (module.__name__, name))
            raise MissingValue
        try:
            yield getattr(module, name)
        finally:
            del values[-1]

    def checkProvider(providers, name):
        provider = providers[name]
        if provider.get("enabled"):
            if not provider.get("client_id"):
                error("Enabled external authentication provider %r must have "
                      "'client_id' set." % name)
            if not provider.get("client_secret"):
                error("Enabled external authentication provider %r must have "
                      "'client_secret' set." % name)
            if name == "google" and not provider.get("redirect_uri"):
                error("Enabled external authentication provider %r must have "
                      "'redirect_uri' set." % name)
            if provider.get("bypass_createuser") \
                    and provider.get("verify_email_addresses"):
                error("Enabled external authentication provider %r can't have "
                      "both 'bypass_createuser' and 'verify_email_addresses' "
                      "enabled." % name)

    try:
        with value(configuration.base, "AUTHENTICATION_MODE") \
                as authentication_mode:
            if authentication_mode == "critic":
                with value(configuration.base, "SESSION_TYPE") as session_type:
                    if session_type not in ("httpauth", "cookie"):
                        error("Invalid session type: must be one of 'httpauth' "
                              "and 'cookie'.")
            elif authentication_mode != "host":
                # Unconditional external authentication mode
                with value(configuration.base, "SESSION_TYPE") as session_type:
                    if session_type != "cookie":
                        error("Invalid session type: must be 'cookie' (with "
                              "external authentication.)")
                with value(configuration.auth, "PROVIDERS") as providers:
                    if authentication_mode not in providers:
                        error("Authentication mode must be 'host', 'critic' or "
                              "name an external authentication provider.")
                    else:
                        provider = providers[authentication_mode]
                        if not provider.get("enabled"):
                            error("External authentication provider %r must be "
                                  "enabled." % authentication_mode)
                with value(configuration.base, "REPOSITORY_URL_TYPES") \
                        as repository_url_types:
                    if "http" in repository_url_types:
                        warn("HTTP/HTTPS repository URL type is incompatible "
                             "with using an external authentication provider.")
    except MissingValue:
        pass

    try:
        with value(configuration.auth, "PROVIDERS") as providers:
            for name in providers.keys():
                checkProvider(providers, name)
    except MissingValue:
        pass

    return (errors, warnings)

def testConfiguration():
    """Test the system configuration

       Returns a tuple containing two lists of ConfigurationIssue objects.  The
       first list contains errors, the second warnings.  If the first list is
       empty, the configuration should be usable."""

    try:
        return doTestConfiguration()
    except Exception:
        error = ConfigurationIssue(
            "error",
            "FATAL: Failed to test configuration!\n\n" + traceback.format_exc(),
            [])
        return ([error], [])

########NEW FILE########
__FILENAME__ = criticctl
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2013 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import sys
import argparse

import auth
import configuration
import dbutils
import inpututils

db = dbutils.Database()

cursor = db.cursor()
cursor.execute("SELECT name FROM roles")

roles = [role for (role,) in cursor]

def valid_user(name):
    try:
        dbutils.User.fromName(db, name)
    except dbutils.NoSuchUser:
        return "no such user"

def valid_role(role):
    if role not in roles:
        return "invalid role; must be one of %s" % ", ".join(roles)

def invalid_user(name):
    try:
        dbutils.User.fromName(db, name)
        return "user exists"
    except dbutils.NoSuchUser:
        pass

def check_argument(argument, check):
    if argument and check:
        error = check(argument)
        if error:
            print >>sys.stderr, "%s: %s" % (argument, error)
            sys.exit(-1)

def use_argument_or_ask(argument, prompt, check=None):
    if argument:
        check_argument(argument, check)
        return argument
    else:
        return inpututils.string(prompt, check=check)

def listusers(argv):
    formats = {
        "tuples": {
            "pre": "# id, name, email, fullname, status\n[",
            "row": " (%r, %r, %r, %r, %r),",
            "post": "]",
        },
        "dicts":  {
            "pre": "[",
            "row": " {'id': %r, 'name': %r, 'email': %r, 'fullname': %r, 'status': %r},",
            "post": "]",
        },
        "table": {
            "pre": "  id |    name    |              email             |            fullname            | status\n" \
                   "-----+------------+--------------------------------+--------------------------------+--------",
            "row": "%4u | %10s | %30s | %-30s | %s",
            "post": "",
        },
    }

    parser = argparse.ArgumentParser(
        description="Critic administration interface: listusers",
        prog="criticctl [options] listusers")

    parser.add_argument("--format", "-f", choices=formats.keys(), default="table",
                        help='output format (defaults to "table")')

    arguments = parser.parse_args(argv)

    cursor.execute("""SELECT users.id, name, useremails.email, fullname, status
                        FROM users
             LEFT OUTER JOIN useremails ON (useremails.id=users.email)
                    ORDER BY users.id""")

    print formats[arguments.format]["pre"]
    for row in cursor:
        print formats[arguments.format]["row"] % row
    print formats[arguments.format]["post"]

def adduser(argv):
    class NoEmail:
        pass
    class NoPassword:
        pass

    parser = argparse.ArgumentParser(
        description="Critic administration interface: adduser",
        prog="criticctl [options] adduser")

    parser.add_argument("--name", help="user name")
    parser.add_argument("--email", "-e", help="email address")
    parser.add_argument("--no-email", dest="email", action="store_const",
                        const=NoEmail, help="create user without email address")
    parser.add_argument("--fullname", "-f", help="full name")
    parser.add_argument("--password", "-p", help="password")
    parser.add_argument("--no-password", dest="password", action="store_const",
                        const=NoPassword, help="create user without password")

    arguments = parser.parse_args(argv)

    name = use_argument_or_ask(arguments.name, "Username:", check=invalid_user)
    fullname = use_argument_or_ask(arguments.fullname, "Full name:")

    if arguments.email is NoEmail:
        email = None
    else:
        email = use_argument_or_ask(arguments.email, "Email address:")
        if not email.strip():
            email = None

    if arguments.password is NoPassword:
        hashed_password = None
    else:
        if arguments.password is None:
            password = inpututils.password("Password:")
        else:
            password = arguments.password
        hashed_password = auth.hashPassword(password)

    dbutils.User.create(db, name, fullname, email, email_verified=None,
                        password=hashed_password)

    db.commit()

    print "%s: user added" % name

def deluser(argv):
    import reviewing.utils

    parser = argparse.ArgumentParser(
        description="Critic administration interface: deluser",
        prog="criticctl [options] deluser")

    parser.add_argument("--name", help="user name")

    arguments = parser.parse_args(argv)

    name = use_argument_or_ask(arguments.name, "Username:", check=valid_user)

    reviewing.utils.retireUser(db, dbutils.User.fromName(db, name))

    db.commit()

    print "%s: user retired" % name

def role(command, argv):
    parser = argparse.ArgumentParser(
        description="Critic administration interface: %s" % command,
        prog="criticctl [options] %s" % command)

    parser.add_argument("--name", help="user name")
    parser.add_argument("--role", choices=roles, help="role name")

    arguments = parser.parse_args(argv)

    name = use_argument_or_ask(arguments.name, "Username:", check=valid_user)
    role = use_argument_or_ask(arguments.role, "Role:", check=valid_role)

    user = dbutils.User.fromName(db, name)

    cursor.execute("""SELECT 1
                        FROM userroles
                       WHERE uid=%s
                         AND role=%s""",
                   (user.id, role))

    if command == "addrole":
        if cursor.fetchone():
            print "%s: user already has role '%s'" % (name, role)
        else:
            cursor.execute("""INSERT INTO userroles (uid, role)
                                   VALUES (%s, %s)""",
                           (user.id, role))
            db.commit()

            print "%s: role '%s' added" % (name, role)
    else:
        if not cursor.fetchone():
            print "%s: user doesn't have role '%s'" % (name, role)
        else:
            cursor.execute("""DELETE FROM userroles
                                    WHERE uid=%s
                                      AND role=%s""",
                           (user.id, role))

            db.commit()

            print "%s: role '%s' removed" % (name, role)

def passwd(argv):
    parser = argparse.ArgumentParser(
        description="Critic administration interface: passwd",
        prog="criticctl [options] passwd")

    class NoPassword:
        pass

    parser.add_argument("--name", help="user name")
    parser.add_argument("--password", help="password")
    parser.add_argument("--no-password", dest="password", action="store_const",
                        const=NoPassword, help="delete the user's password")

    arguments = parser.parse_args(argv)

    name = use_argument_or_ask(arguments.name, "Username:", check=valid_user)

    if arguments.password is NoPassword:
        hashed_password = None
    else:
        if arguments.password is None:
            password = inpututils.password("Password:")
        else:
            password = arguments.password
        hashed_password = auth.hashPassword(password)

    cursor.execute("""UPDATE users
                         SET password=%s
                       WHERE name=%s""",
                   (hashed_password, name))

    db.commit()

    if hashed_password:
        print "%s: password changed" % name
    else:
        print "%s: password deleted" % name

def connect(command, argv):
    parser = argparse.ArgumentParser(
        description="Critic administration interface: %s" % command,
        prog="criticctl [options] %s" % command)

    providers = sorted(provider_name for provider_name, provider
                       in configuration.auth.PROVIDERS.items()
                       if command == "disconnect" or provider.get("enabled"))

    if len(providers) == 0:
        print >>sys.stderr, "No external authentication providers configured!"
        return 1

    parser.add_argument("--name", help="user name")
    parser.add_argument("--provider", choices=providers,
                        help="external authentication provider name")

    if command == "connect":
        parser.add_argument("--account", help="external account identifier")

    arguments = parser.parse_args(argv)

    def valid_provider(provider):
        if provider not in providers:
            return ("invalid authentication provider; must be one of %s"
                    % ", ".join(providers))

    name = use_argument_or_ask(arguments.name, "Username:", check=valid_user)

    if len(providers) == 1:
        check_argument(arguments.provider, check=valid_provider)
        provider = providers[0]
    else:
        provider = use_argument_or_ask(
            arguments.provider, "Authentication provider:", check=valid_provider)

    user = dbutils.User.fromName(db, name)
    provider = auth.PROVIDERS[provider]

    if command == "connect":
        cursor.execute("""SELECT 1
                            FROM externalusers
                           WHERE uid=%s
                             AND provider=%s""",
                       (user.id, provider.name))

        if cursor.fetchone():
            print >>sys.stderr, ("%s: user already connected to a %s"
                                 % (user.name, provider.getTitle()))
            return 1

        account = use_argument_or_ask(
            arguments.account, provider.getAccountIdDescription() + ":")

        cursor.execute("""SELECT id, uid
                            FROM externalusers
                           WHERE provider=%s
                             AND account=%s""",
                       (provider.name, account))

        row = cursor.fetchone()

        if row:
            external_id, user_id = row

            if user_id is not None:
                user = dbutils.User.fromId(db, user_id)

                print >>sys.stderr, ("%s %r: already connected to local user %s"
                                     % (provider.getTitle(), account, user.name))
                return 1

            cursor.execute("""UPDATE externalusers
                                 SET uid=%s
                               WHERE id=%s""",
                           (user.id, external_id))
        else:
            cursor.execute("""INSERT INTO externalusers (uid, provider, account)
                                   VALUES (%s, %s, %s)""",
                           (user.id, provider.name, account))

        print "%s: connected to %s %r" % (name, provider.getTitle(), account)
    else:
        cursor.execute("""SELECT account
                            FROM externalusers
                           WHERE uid=%s
                             AND provider=%s""",
                       (user.id, provider.name))

        row = cursor.fetchone()

        if not row:
            print >>sys.stderr, ("%s: user not connected to a %s"
                                 % (name, provider.getTitle()))
            return 1

        account, = row

        cursor.execute("""DELETE FROM externalusers
                                WHERE uid=%s
                                  AND provider=%s""",
                       (user.id, provider.name))

        print ("%s: disconnected from %s %r"
               % (name, provider.getTitle(), account))

    db.commit()

    return 0

def configtest(command, argv):
    parser = argparse.ArgumentParser(
        description="Critic administration interface: configtest",
        prog="criticctl [options] configtest")

    parser.add_argument("--quiet", "-q", action="store_true",
                        help="Suppress non-error/warning output")

    arguments = parser.parse_args(argv)

    import maintenance.configtest

    errors, warnings = maintenance.configtest.testConfiguration()

    def printIssue(issue):
        print str(issue)
        print

    for error in errors:
        printIssue(error)
    for warning in warnings:
        printIssue(warning)

    if not errors:
        if not arguments.quiet:
            print "System configuration valid."
        return 0
    else:
        return 1

def restart(command, argv):
    parser = argparse.ArgumentParser(
        description="Critic administration interface: restart",
        prog="criticctl [options] restart")

    parser.parse_args(argv)

    result = configtest("configtest", ["--quiet"])

    if result != 0:
        print >>sys.stderr, "ERROR: System configuration is not valid."
        return result

    import os
    import subprocess

    system_identity = configuration.base.SYSTEM_IDENTITY

    try:
        os.seteuid(0)
        os.setegid(0)
    except OSError:
        print >>sys.stderr, "ERROR: 'criticctl restart' must be run as root."
        return 1

    subprocess.check_call(["service", "apache2", "stop"])
    subprocess.check_call(["service", "critic-" + system_identity, "restart"])
    subprocess.check_call(["service", "apache2", "start"])

    return 0

def main(parser, show_help, command, argv):
    returncode = 0

    if show_help or command is None:
        parser.print_help()
    else:
        if command == "listusers":
            listusers(argv)
            return 0
        elif command == "adduser":
            adduser(argv)
            return 0
        elif command == "deluser":
            deluser(argv)
            return 0
        elif command in ("addrole", "delrole"):
            role(command, argv)
            return 0
        elif command == "passwd":
            passwd(argv)
            return 0
        elif command in ("connect", "disconnect"):
            return connect(command, argv)
        elif command == "configtest":
            return configtest(command, argv)
        elif command == "restart":
            return restart(command, argv)
        else:
            print >>sys.stderr, "ERROR: Invalid command: %s" % command
            returncode = 1

    print """
Available commands are:

  listusers List all users.
  adduser   Add a user.
  deluser   Retire a user.
  addrole   Add a role to a user.
  delrole   Remove a role from a user.
  passwd    Set or delete a user's password.

  connect    Set up connection between user and external authentication
             provider.
  disconnect Remove such connection.

  configtest Test system configuration.
  restart    Restart host web server and Critic's background services.

Use 'criticctl COMMAND --help' to see per command options."""

    return returncode

########NEW FILE########
__FILENAME__ = dumppreferences
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2012 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import sys
import os.path

sys.path.insert(0, os.path.dirname(os.path.dirname(sys.argv[0])))

from dbaccess import connect

db = connect()
cursor = db.cursor()

cursor.execute("SELECT item, type, default_integer, default_string, description FROM preferences")

preferences = cursor.fetchall()

installpreferences_py = open(os.path.join(os.path.dirname(sys.argv[0]), "installpreferences.py"), "w")

print >>installpreferences_py, "PREFERENCES = [ ",

for index, (item, type, default_integer, default_string, description) in enumerate(preferences):
    if index != 0:
        installpreferences_py.write(""",
                """)

    installpreferences_py.write("""{ "item": %r,
                  "type": %r,""" % (item, type))

    if type == "string":
        installpreferences_py.write("""
                  "default_string": %r,""" % default_string)
    else:
        installpreferences_py.write("""
                  "default_integer": %r,""" % default_integer)

    installpreferences_py.write("""
                  "description": %r }""" % description)

print >>installpreferences_py, " ]"
print >>installpreferences_py
print >>installpreferences_py, "def installPreferences(db, quiet):"
print >>installpreferences_py, "    cursor = db.cursor()"
print >>installpreferences_py
print >>installpreferences_py, "    for preference in PREFERENCES:"
print >>installpreferences_py, "        item = preference[\"item\"]"
print >>installpreferences_py, "        type = preference[\"type\"]"
print >>installpreferences_py, "        default_integer = preference.get(\"default_integer\")"
print >>installpreferences_py, "        default_string = preference.get(\"default_string\")"
print >>installpreferences_py, "        description = preference[\"description\"]"
print >>installpreferences_py
print >>installpreferences_py, "        cursor.execute(\"SELECT 1 FROM preferences WHERE item=%s\", (item,))"
print >>installpreferences_py
print >>installpreferences_py, "        if cursor.fetchone():"
print >>installpreferences_py, "            if not quiet: print \"Updating: %s\" % item"
print >>installpreferences_py, "            cursor.execute(\"UPDATE preferences SET type=%s, default_integer=%s, default_string=%s, description=%s WHERE item=%s\", (type, default_integer, default_string, description, item))"
print >>installpreferences_py, "        else:"
print >>installpreferences_py, "            if not quiet: print \"Adding:   %s\" % item"
print >>installpreferences_py, "            cursor.execute(\"INSERT INTO preferences (item, type, default_integer, default_string, description) VALUES (%s, %s, %s, %s, %s)\", (item, type, default_integer, default_string, description))"
print >>installpreferences_py
print >>installpreferences_py, "if __name__ == \"__main__\":"
print >>installpreferences_py, "    import sys"
print >>installpreferences_py, "    import os.path"
print >>installpreferences_py
print >>installpreferences_py, "    sys.path.insert(0, os.path.dirname(os.path.dirname(sys.argv[0])))"
print >>installpreferences_py
print >>installpreferences_py, "    import dbaccess"
print >>installpreferences_py
print >>installpreferences_py, "    db = dbaccess.connect()"
print >>installpreferences_py
print >>installpreferences_py, "    installPreferences(db, \"--quiet\" in sys.argv or \"-q\" in sys.argv)"
print >>installpreferences_py
print >>installpreferences_py, "    db.commit()"

########NEW FILE########
__FILENAME__ = progress
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2012 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import sys

__prefix = ""
__current = 0
__total = 0
__previous = ""

def __output(string=None):
    global __prefix, __current, __total, __previous

    if string is None:
        percent = int(round((100.0 * __current) / __total))
        string = "%s [%3d %%]" % (__prefix, percent)

    if string != __previous:
        sys.stdout.write("\r%s%s" % (string, " " * (len(__previous) - len(string))))
        sys.stdout.flush()

        __previous = string

def start(total, prefix=""):
    global __prefix, __current, __total, __previous

    __prefix = prefix
    __current = 0
    __total = total
    __previous = ""

    if total: __output()

def update(count=1):
    global __current

    __current += count
    __output()

def end(message):
    __output(__prefix + message)
    sys.stdout.write("\n")

def write(string):
    __output(string)
    sys.stdout.write("\n")
    __output()

if __name__ == "__main__":
    import time

    start(1000, prefix="Testing: ")

    for index in range(200):
        time.sleep(0.01)
        update(5)

    end("Finished!")

########NEW FILE########
__FILENAME__ = addrepository
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2012 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import subprocess
import os
import signal

import configuration

import gitutils
import htmlutils
from operation import Operation, OperationResult, OperationFailure, Optional, RestrictedString

class AddRepository(Operation):
    def __init__(self):
        Operation.__init__(self, { "name": RestrictedString(allowed=lambda ch: ch != "/", minlength=1, maxlength=64, ui_name="short name"),
                                   "path": str,
                                   "remote": Optional({ "url": RestrictedString(maxlength=256, ui_name="source repository"),
                                                        "branch": str }) })

    def process(self, db, user, name, path, remote=None):
        if not user.hasRole(db, "repositories"):
            raise OperationFailure(code="notallowed",
                                   title="Not allowed!",
                                   message="Only users with the 'repositories' role can add new repositories.")
        if name.endswith(".git"):
            raise OperationFailure(code="badsuffix_name",
                                   title="Invalid short name",
                                   message="The short name must not end with .git")

        if name == "r":
            raise OperationFailure(code="invalid_name",
                                   title="Invalid short name",
                                   message="The short name 'r' is not allowed since corresponding /REPOSHORTNAME/{SHA1|BRANCH} URLs would conflict with r/REVIEW_ID URLs.")

        path = path.strip("/").rsplit("/", 1)

        if len(path) == 2: base, repository_name = path
        else: base, repository_name = None, path[0]

        if base:
            main_base_path = os.path.join(configuration.paths.GIT_DIR, base)
        else:
            main_base_path = configuration.paths.GIT_DIR

        main_path = os.path.join(main_base_path, repository_name + ".git")

        cursor = db.cursor()
        cursor.execute("""SELECT name FROM repositories WHERE path=%s""", (main_path,))
        row = cursor.fetchone()
        if row:
            raise OperationFailure(code="duplicaterepository",
                                   title="Duplicate repository",
                                   message="The specified path is already used by repository %s" % row[0])
        cursor.execute("""SELECT name FROM repositories WHERE name=%s""", (name,))
        row = cursor.fetchone()
        if row:
            raise OperationFailure(code="duplicateshortname",
                                   title="Duplicate short name",
                                   message="The specified short name is already in use, please select a different short name.")

        if not os.path.isdir(main_base_path):
            os.makedirs(main_base_path, mode=0775)

        def git(arguments, cwd):
            argv = [configuration.executables.GIT] + arguments
            git = subprocess.Popen(argv, stdout=subprocess.PIPE, stderr=subprocess.PIPE, cwd=cwd)
            stdout, stderr = git.communicate()
            if git.returncode != 0:
                raise gitutils.GitError("unexpected output from '%s': %s" % (" ".join(argv), stderr))

        if remote:
            try:
                subprocess.check_output([configuration.executables.GIT, "ls-remote", remote["url"]], stderr=subprocess.STDOUT)
            except subprocess.CalledProcessError as e:
                raise OperationFailure(code="failedreadremote",
                                       title="Failed to read source repository",
                                       message="Critic failed to read from the specified source repository. The error reported from git " +
                                               "(when running as the system user '%s') was: <pre>%s</pre>" % (configuration.base.SYSTEM_USER_NAME, htmlutils.htmlify(e.output)),
                                       is_html=True)

        git(["init", "--bare", "--shared", repository_name + ".git"], cwd=main_base_path)
        git(["config", "receive.denyNonFastforwards", "false"], cwd=main_path)
        git(["config", "critic.name", name], cwd=main_path)

        os.symlink(os.path.join(configuration.paths.INSTALL_DIR, "hooks", "pre-receive"), os.path.join(main_path, "hooks", "pre-receive"))

        cursor.execute("""INSERT INTO repositories (name, path)
                               VALUES (%s, %s)
                            RETURNING id""",
                       (name, main_path))
        repository_id = cursor.fetchone()[0]

        if remote:
            cursor.execute("""INSERT INTO trackedbranches (repository, local_name, remote, remote_name, forced, delay)
                                   VALUES (%s, '*', %s, '*', true, '1 day')""",
                           (repository_id, remote["url"]))
            cursor.execute("""INSERT INTO trackedbranches (repository, local_name, remote, remote_name, forced, delay)
                                   VALUES (%s, %s, %s, %s, true, '1 day')""",
                           (repository_id, remote["branch"], remote["url"], remote["branch"]))

        db.commit()

        if remote:
            pid = int(open(configuration.services.BRANCHTRACKER["pidfile_path"]).read().strip())
            os.kill(pid, signal.SIGHUP)

        return OperationResult()

########NEW FILE########
__FILENAME__ = applyfilters
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2013 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import dbutils
import reviewing.utils

from operation import Operation, OperationResult

class QueryGlobalFilters(Operation):
    def __init__(self):
        Operation.__init__(self, { "review_id": int })

    def process(self, db, user, review_id):
        review = dbutils.Review.fromId(db, review_id)
        reviewers, watchers = reviewing.utils.queryFilters(db, user, review, globalfilters=True)
        return OperationResult(reviewers=[dbutils.User.fromId(db, user_id).getJSON() for user_id in reviewers],
                               watchers=[dbutils.User.fromId(db, user_id).getJSON() for user_id in watchers])

class ApplyGlobalFilters(Operation):
    def __init__(self):
        Operation.__init__(self, { "review_id": int })

    def process(self, db, user, review_id):
        review = dbutils.Review.fromId(db, review_id)
        reviewing.utils.applyFilters(db, user, review, globalfilters=True)
        return OperationResult()

class QueryParentFilters(Operation):
    def __init__(self):
        Operation.__init__(self, { "review_id": int })

    def process(self, db, user, review_id):
        review = dbutils.Review.fromId(db, review_id)
        reviewers, watchers = reviewing.utils.queryFilters(db, user, review, parentfilters=True)
        return OperationResult(reviewers=[dbutils.User.fromId(db, user_id).getJSON() for user_id in reviewers],
                               watchers=[dbutils.User.fromId(db, user_id).getJSON() for user_id in watchers])

class ApplyParentFilters(Operation):
    def __init__(self):
        Operation.__init__(self, { "review_id": int })

    def process(self, db, user, review_id):
        review = dbutils.Review.fromId(db, review_id)
        reviewing.utils.applyFilters(db, user, review, parentfilters=True)
        return OperationResult()

########NEW FILE########
__FILENAME__ = autocompletedata
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2012 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import dbutils
import gitutils
import reviewing.filters

from operation import Operation, OperationResult, OperationError, Optional

class GetAutoCompleteData(Operation):
    def __init__(self):
        Operation.__init__(self, { "values": [set(["users", "paths"])],
                                   "review_id": Optional(int),
                                   "changeset_ids": Optional([int]) })

    def process(self, db, user, values, review_id=None, changeset_ids=None):
        cursor = db.cursor()
        data = {}

        if "users" in values:
            cursor.execute("SELECT name, fullname FROM users WHERE status!='retired'")
            data["users"] = dict(cursor)

        if "paths" in values:
            if review_id is not None:
                cursor.execute("""SELECT files.path, SUM(reviewfiles.deleted), SUM(reviewfiles.inserted)
                                    FROM files
                                    JOIN reviewfiles ON (reviewfiles.file=files.id)
                                   WHERE reviewfiles.review=%s
                                GROUP BY files.id""",
                               (review_id,))
            elif changeset_ids is not None:
                cursor.execute("""SELECT files.path, SUM(chunks.deleteCount), SUM(chunks.insertCount)
                                    FROM files
                                    JOIN chunks ON (chunks.file=files.id)
                                   WHERE chunks.changeset=ANY (%s)
                                GROUP BY files.id""",
                               (changeset_ids,))
            else:
                raise OperationError("paths requested, but neither review_id nor changeset_ids given")

            paths = {}

            for filename, deleted, inserted in cursor:
                paths[filename] = (0, deleted, inserted)

                components = filename.split("/")
                for index in range(len(components) - 1, 0, -1):
                    directory = "/".join(components[:index]) + "/"
                    nfiles, current_deleted, current_inserted = paths.get(directory, (0, 0, 0))
                    paths[directory] = nfiles + 1, current_deleted + deleted, current_inserted + inserted

            data["paths"] = paths

        return OperationResult(**data)

class GetRepositoryPaths(Operation):
    def __init__(self):
        Operation.__init__(self, { "prefix": str,
                                   "repository_id": Optional(int),
                                   "repository_name": Optional(str) })

    def process(self, db, user, prefix, repository_id=None, repository_name=None):
        if reviewing.filters.hasWildcard(prefix):
            return OperationResult(paths={})

        prefix = reviewing.filters.sanitizePath(prefix)

        if repository_id is not None:
            repository = gitutils.Repository.fromId(db, repository_id)
        else:
            repository = gitutils.Repository.fromName(db, repository_name)

        if repository.isEmpty():
            return OperationResult(paths={})

        paths = {}

        use_prefix = prefix.rpartition("/")[0]

        if use_prefix:
            names = repository.run("ls-tree", "-r", "--name-only", "HEAD", use_prefix).splitlines()
        else:
            names = repository.run("ls-tree", "-r", "--name-only", "HEAD").splitlines()

        def add(path):
            if path.endswith("/"):
                if path not in paths:
                    paths[path] = { "files": 0 }
                paths[path]["files"] += 1
            else:
                paths[path] = {}

        for name in names:
            if not name.startswith(prefix):
                continue

            relname = name[len(prefix):]
            use_prefix = prefix
            if prefix.endswith("/"):
                add(prefix)
            elif relname.startswith("/"):
                add(prefix + "/")
                use_prefix = prefix + "/"
                relname = relname[1:]

            localname, pathsep, _ = relname.partition("/")

            add(use_prefix + localname + pathsep)

        return OperationResult(paths=paths)

########NEW FILE########
__FILENAME__ = basictypes
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2014 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import htmlutils
import textutils

class OperationResult:

    """
    Simple container for successful operation result.

    The constructor builds a dictionary from all keyword arguments,
    and adds {"status": "ok"} unless a different "status" is specified
    as a keyword argument.

    Converting an OperationResult object to string converts this
    dictionary to a JSON object literal.
    """

    def __init__(self, **kwargs):
        self.__value = kwargs
        if "status" not in self.__value:
            self.__value["status"] = "ok"
        self.__cookies = {}
    def __str__(self):
        return textutils.json_encode(self.__value)
    def set(self, key, value):
        self.__value[key] = value

class OperationError(Exception):

    """
    Exception class for unexpected operation errors.

    Converting an OperationError object to string produces a JSON
    object literal with the properties status="error" and
    error=<message>.
    """

    def __init__(self, message):
        self.__message = message
    def __str__(self):
        return textutils.json_encode({ "status": "error",
                                       "error": self.__message })

class OperationFailure(Exception):

    """
    Exception class for operation failures caused by invalid input.

    Converting an OperationFailure object to string produces a JSON
    object literal with the properties status="failure", title=<title>
    and message=<message>.
    """

    def __init__(self, code, title, message, is_html=False):
        self.__code = code
        self.__title = htmlutils.htmlify(title)
        self.__message = message if is_html else htmlutils.htmlify(message)
    def __str__(self):
        return textutils.json_encode({ "status": "failure",
                                       "code": self.__code,
                                       "title": self.__title,
                                       "message": self.__message })

class OperationFailureMustLogin(OperationFailure):
    def __init__(self):
        super(OperationFailureMustLogin, self).__init__(
            code="mustlogin",
            title="Login Required",
            message="You have to sign in to perform this operation.")

########NEW FILE########
__FILENAME__ = basictypes_unittest
import sys
import os
import json

def basic():
    from operation.basictypes import (
        OperationResult, OperationError, OperationFailure,
        OperationFailureMustLogin)

    def convert(value):
        return json.loads(str(value))

    #
    # OperationResult
    #

    # OperationResult has status=ok by default.
    assert convert(OperationResult()) == { "status": "ok" }

    # But status can be overridden.
    assert convert(OperationResult(status="bananas")) == { "status": "bananas" }

    # Other values can be set as well.
    assert convert(OperationResult(foo=10)) == { "status": "ok", "foo": 10 }

    # Even to None/null.
    assert convert(OperationResult(foo=None)) == { "status": "ok", "foo": None }

    # And test OperationResult.set().
    result = OperationResult()
    result.set("foo", 10)
    assert convert(result) == { "status": "ok", "foo": 10 }
    result.set("foo", [1, 2, 3])
    assert convert(result) == { "status": "ok", "foo": [1, 2, 3] }
    result.set("foo", None)
    assert convert(result) == { "status": "ok", "foo": None }

    #
    # OperationError
    #

    assert convert(OperationError("wrong!")) == { "status": "error",
                                                  "error": "wrong!" }

    #
    # OperationFailure
    #

    assert (convert(OperationFailure("the code", "the title", "the message"))
            == { "status": "failure", "code": "the code", "title": "the title",
                 "message": "the message" })

    # Check HTML escaping.
    assert (convert(OperationFailure("<code>", "<title>", "<message>"))
            == { "status": "failure", "code": "<code>",
                 "title": "&lt;title&gt;", "message": "&lt;message&gt;" })

    # Check HTML escaping with is_html=True (title still escaped, but not the
    # message.)
    assert (convert(OperationFailure("<code>", "<title>", "<message>", True))
            == { "status": "failure", "code": "<code>",
                 "title": "&lt;title&gt;", "message": "<message>" })


if __name__ == "__main__":
    # sys.path[0] is the directory containing this file.
    sys.path[0] = os.path.dirname(sys.path[0])

    if "basic" in sys.argv[1:]:
        basic()

########NEW FILE########
__FILENAME__ = blame
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2012 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import dbutils
import gitutils
import itertools
import diff

from operation import Operation, OperationResult, OperationError, Optional
from log.commitset import CommitSet
from changeset.utils import createChangeset
from changeset.load import loadChangesetsForCommits

class LineAnnotator:
    class NotSupported: pass

    def __init__(self, db, parent, child, file_ids=None, commits=None, changeset_cache=None):
        self.parent = parent
        self.child = child
        self.commitset = CommitSet.fromRange(db, parent, child, commits=commits)
        self.changesets = {}

        if not self.commitset: raise LineAnnotator.NotSupported

        commits = []

        if not changeset_cache: changeset_cache = {}

        for commit in self.commitset:
            if len(commit.parents) > 1: raise LineAnnotator.NotSupported

            if commit in changeset_cache:
                self.changesets[commit.sha1] = changeset_cache[commit]
            else:
                commits.append(commit)

        for changeset in loadChangesetsForCommits(db, parent.repository, commits, filtered_file_ids=file_ids):
            self.changesets[changeset.child.sha1] = changeset_cache[changeset.child] = changeset

        for commit in set(self.commitset) - set(self.changesets.keys()):
            changesets = createChangeset(db, None, commit.repository, commit=commit, filtered_file_ids=file_ids, do_highlight=False)
            assert len(changesets) == 1
            self.changesets[commit.sha1] = changeset_cache[commit] = changesets[0]

        self.commits = [parent]
        self.commit_index = { parent.sha1: 0 }

        for commit in self.commitset:
            self.commit_index[commit.sha1] = len(self.commits)
            self.commits.append(commit)

    class Line:
        def __init__(self, sha1, primary):
            self.sha1 = sha1
            self.primary = primary
            self.untouched = True
        def touch(self, sha1):
            if self.untouched:
                self.sha1 = sha1
                self.untouched = False
        def __repr__(self):
            return self.sha1[:8]

    def annotate(self, file_id, first, last, check_user=None):
        offset = first
        count = last - first + 1

        initial_lines = [LineAnnotator.Line(sha1, True) for sha1 in itertools.repeat(self.parent.sha1, count)]
        lines = initial_lines[:]
        commit = self.commitset.getHeads().pop()

        while True:
            changeset = self.changesets[commit.sha1]
            changeset_file = changeset.getFile(file_id)

            if changeset_file:
                changeset_file.loadOldLines()
                changeset_file.loadNewLines()

                offset_delta = 0
                modifications = []

                for chunk in changeset_file.chunks:
                    if chunk.insertEnd() < offset:
                        offset_delta -= chunk.delta()
                        continue

                    if chunk.insert_offset < offset + count:
                        if not chunk.deleted_lines: chunk.deleted_lines = changeset_file.getOldLines(chunk)
                        if not chunk.inserted_lines: chunk.inserted_lines = changeset_file.getNewLines(chunk)

                        for line in chunk.getLines():
                            if line.new_offset < offset:
                                if line.type == line.DELETED:
                                    offset_delta += 1
                                elif line.type == line.INSERTED:
                                    offset_delta -= 1
                            elif line.new_offset < offset + count:
                                if line.type == line.CONTEXT:
                                    pass
                                elif line.type == line.DELETED:
                                    modifications.append((line.new_offset, -1))
                                else:
                                    if line.type == line.INSERTED:
                                        modifications.append((line.new_offset, 1))
                                    line = lines[line.new_offset - offset]
                                    if check_user and line.primary and line.untouched and commit.author.email == check_user.email:
                                        return True
                                    line.touch(commit.sha1)
                            else:
                                break

                modification_offset = offset

                for line_offset, delta in modifications:
                    if delta > 0:
                        del lines[line_offset - modification_offset]
                        count -= 1
                        modification_offset += 1
                    else:
                        lines.insert(line_offset - modification_offset, LineAnnotator.Line(None, False))
                        count += 1
                        modification_offset -= 1

                offset += offset_delta

            parents = self.commitset.getParents(commit)

            if len(parents) > 1: raise LineAnnotator.NotSupported

            if parents: commit = parents.pop()
            else: break

        if check_user:
            if self.parent.author.email == check_user.email:
                return any(itertools.imap(lambda line: line.untouched, initial_lines))
            else:
                return False
        else:
            return [(first + index, self.commit_index[line.sha1]) for index, line in enumerate(initial_lines)]

class Blame(Operation):
    def __init__(self):
        Operation.__init__(self, { "repository_id": int,
                                   "changeset_id": int,
                                   "files": [{ "id": int,
                                               "blocks": [{ "first": int,
                                                            "last": int }]
                                               }]
                                   })

    def process(self, db, user, repository_id, changeset_id, files):
        repository = gitutils.Repository.fromId(db, repository_id)

        cursor = db.cursor()
        cursor.execute("SELECT parent, child FROM changesets WHERE id=%s", (changeset_id,))

        parent_id, child_id = cursor.fetchone()
        parent = gitutils.Commit.fromId(db, repository, parent_id)
        child = gitutils.Commit.fromId(db, repository, child_id)

        try:
            annotator = LineAnnotator(db, parent, child)

            for file in files:
                for block in file["blocks"]:
                    lines = annotator.annotate(file["id"], block["first"], block["last"])
                    block["lines"] = [{ "offset": offset, "commit": commit } for offset, commit in lines]

            return OperationResult(commits=[{ "sha1": commit.sha1,
                                              "author_name": commit.author.name,
                                              "author_email": commit.author.email,
                                              "summary": commit.niceSummary(),
                                              "message": commit.message,
                                              "original": commit == parent,
                                              "current": commit == child }
                                            for commit in annotator.commits],
                                   files=files)
        except LineAnnotator.NotSupported:
            blame = gitutils.Blame(parent, child)

            paths = {}

            for file in files:
                file_id = file["id"]

                path = paths.get(file_id)

                if not path:
                    path = paths[file_id] = dbutils.describe_file(db, file_id)

                for block in file["blocks"]:
                    block["lines"] = blame.blame(db, path, block["first"], block["last"])

            return OperationResult(commits=blame.commits, files=files)

########NEW FILE########
__FILENAME__ = checkrebase
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2012 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

from operation import Operation, OperationResult, Optional

import dbutils
import gitutils
import reviewing.rebase
import changeset.utils as changeset_utils
import log.commitset

class CheckMergeStatus(Operation):
    def __init__(self):
        super(CheckMergeStatus, self).__init__({ "review_id": int,
                                                 "new_head_sha1": str,
                                                 "new_upstream_sha1": str })

    def process(self, db, user, review_id, new_head_sha1, new_upstream_sha1):
        review = dbutils.Review.fromId(db, review_id)
        upstreams = log.commitset.CommitSet(review.branch.commits).getFilteredTails(review.repository)

        if len(upstreams) > 1:
            return OperationResult(rebase_supported=False)

        old_head = review.branch.head
        old_upstream = gitutils.Commit.fromSHA1(db, review.repository, upstreams.pop())
        new_head = gitutils.Commit.fromSHA1(db, review.repository, new_head_sha1)
        new_upstream = gitutils.Commit.fromSHA1(db, review.repository, new_upstream_sha1)

        equivalent_merge = reviewing.rebase.createEquivalentMergeCommit(
            db, review, user, old_head, old_upstream, new_head, new_upstream)

        changesets = changeset_utils.createChangeset(
            db, user, review.repository, equivalent_merge, do_highlight=False)

        for changeset in changesets:
            if changeset.files:
                has_conflicts = True
                break
        else:
            has_conflicts = False

        return OperationResult(rebase_supported=True,
                               has_conflicts=has_conflicts,
                               merge_sha1=equivalent_merge.sha1)

class CheckConflictsStatus(Operation):
    def __init__(self):
        super(CheckConflictsStatus, self).__init__({ "review_id": int,
                                                     "merge_sha1": Optional(str),
                                                     "new_head_sha1": Optional(str),
                                                     "new_upstream_sha1": Optional(str) })

    def process(self, db, user, review_id, merge_sha1=None, new_head_sha1=None, new_upstream_sha1=None):
        review = dbutils.Review.fromId(db, review_id)

        if merge_sha1 is not None:
            merge = gitutils.Commit.fromSHA1(db, review.repository, merge_sha1)

            changesets = changeset_utils.createChangeset(
                db, user, review.repository, merge, conflicts=True, do_highlight=False)

            url = "/showcommit?repository=%d&sha1=%s&conflicts=yes" % (review.repository.id, merge.sha1)
        else:
            upstreams = review.getCommitSet(db).getFilteredTails(review.repository)

            if len(upstreams) > 1:
                return OperationResult(rebase_supported=False)

            old_head = review.branch.head
            old_upstream = gitutils.Commit.fromSHA1(db, review.repository, upstreams.pop())
            new_head = gitutils.Commit.fromSHA1(db, review.repository, new_head_sha1)
            new_upstream = gitutils.Commit.fromSHA1(db, review.repository, new_upstream_sha1)

            replay = reviewing.rebase.replayRebase(db, review, user, old_head, old_upstream, new_head, new_upstream)

            changesets = changeset_utils.createChangeset(
                db, user, review.repository, from_commit=replay, to_commit=new_head, conflicts=True, do_highlight=False)

            url = "/showcommit?repository=%d&from=%s&to=%s&conflicts=yes" % (review.repository.id, replay.sha1, new_head.sha1)

        has_changes = False
        has_conflicts = False

        for changed_file in changesets[0].files:
            changed_file.loadOldLines()

            file_has_conflicts = False

            for chunk in changed_file.chunks:
                lines = changed_file.getOldLines(chunk)
                for line in lines:
                    if line.startswith("<<<<<<<"):
                        has_conflicts = file_has_conflicts = True
                        break
                if file_has_conflicts:
                    break

            if not file_has_conflicts:
                has_changes = True

        return OperationResult(has_conflicts=has_conflicts, has_changes=has_changes, url=url)

class CheckHistoryRewriteStatus(Operation):
    def __init__(self):
        super(CheckHistoryRewriteStatus, self).__init__({ "review_id": int,
                                                          "new_head_sha1": str })

    def process(self, db, user, review_id, new_head_sha1):
        review = dbutils.Review.fromId(db, review_id)

        old_head = review.branch.head
        new_head = gitutils.Commit.fromSHA1(db, review.repository, new_head_sha1)

        mergebase = review.repository.mergebase([old_head, new_head])
        sha1s = review.repository.revlist([new_head], [mergebase])

        valid = True

        for sha1 in sha1s:
            commit = gitutils.Commit.fromSHA1(db, review.repository, sha1)
            if commit.tree == old_head.tree:
                break
        else:
            valid = False

        return OperationResult(valid=valid)

########NEW FILE########
__FILENAME__ = createcomment
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2012 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import dbutils

from operation import (Operation, OperationResult, OperationFailure, Optional,
                       NonNegativeInteger, PositiveInteger, Review, Commit, File)

from reviewing.comment import CommentChain, validateCommentChain, createCommentChain, createComment

class ValidateCommentChain(Operation):
    def __init__(self):
        Operation.__init__(self, { "review_id": int,
                                   "origin": set(["old", "new"]),
                                   "parent_id": int,
                                   "child_id": int,
                                   "file_id": int,
                                   "offset": int,
                                   "count": int })

    def process(self, db, user, review_id, origin, parent_id, child_id, file_id, offset, count):
        review = dbutils.Review.fromId(db, review_id)
        verdict, data = validateCommentChain(db, review, origin, parent_id, child_id, file_id, offset, count)
        return OperationResult(verdict=verdict, **data)

def checkComment(text):
    if not text.strip():
        raise OperationFailure(code="emptycomment",
                               title="Empty comment!",
                               message="Creating empty (or white-space only) comments is not allowed.")

class CreateCommentChain(Operation):
    def __init__(self):
        Operation.__init__(self, { "review": Review,
                                   "chain_type": set(["issue", "note"]),
                                   "commit_context": Optional({ "commit": Commit,
                                                                "offset": NonNegativeInteger,
                                                                "count": PositiveInteger }),
                                   "file_context": Optional({ "origin": set(["old", "new"]),
                                                              "parent": Optional(Commit),
                                                              "child": Commit,
                                                              "file": File,
                                                              "offset": PositiveInteger,
                                                              "count": PositiveInteger }),
                                   "text": str })

    def process(self, db, user, review, chain_type, text, commit_context=None, file_context=None):
        checkComment(text)

        if commit_context:
            chain_id = createCommentChain(db, user, review, chain_type, **commit_context)
        elif file_context:
            chain_id = createCommentChain(db, user, review, chain_type, **file_context)
        else:
            chain_id = createCommentChain(db, user, review, chain_type)

        comment_id = createComment(db, user, chain_id, text, first=True)

        db.commit()

        return OperationResult(chain_id=chain_id, comment_id=comment_id, draft_status=review.getDraftStatus(db, user))

class CreateComment(Operation):
    def __init__(self):
        Operation.__init__(self, { "chain_id": int,
                                   "text": str })

    def process(self, db, user, chain_id, text):
        checkComment(text)

        chain = CommentChain.fromId(db, chain_id, user)
        comment_id = createComment(db, user, chain_id, text)

        db.commit()

        return OperationResult(comment_id=comment_id, draft_status=chain.review.getDraftStatus(db, user))

########NEW FILE########
__FILENAME__ = createreview
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2012 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import re
import os
import signal

import dbutils
import gitutils
import htmlutils
import configuration

from operation import (Operation, OperationResult, OperationError, Optional,
                       OperationFailure, Repository)
from reviewing.utils import (parseReviewFilters, parseRecipientFilters,
                             createReview, getReviewersAndWatchers)
from page.createreview import generateReviewersAndWatchersTable
from log.commitset import CommitSet

if configuration.extensions.ENABLED:
    import extensions.role.processcommits

from cStringIO import StringIO

class ReviewersAndWatchers(Operation):
    def __init__(self):
        Operation.__init__(self, { "repository_id": int,
                                   "commit_ids": [int],
                                   "reviewfilters": [{ "username": str,
                                                       "type": set(["reviewer", "watcher"]),
                                                       "path": str }],
                                   "applyfilters": bool,
                                   "applyparentfilters": bool })

    def process(req, db, user, repository_id, commit_ids, reviewfilters, applyfilters, applyparentfilters):
        reviewfilters = parseReviewFilters(db, reviewfilters)

        repository = gitutils.Repository.fromId(db, repository_id)
        commits = [gitutils.Commit.fromId(db, repository, commit_id) for commit_id in commit_ids]

        all_reviewers, all_watchers = getReviewersAndWatchers(db, repository, commits,
                                                              reviewfilters=reviewfilters,
                                                              applyfilters=applyfilters,
                                                              applyparentfilters=applyparentfilters)
        document = htmlutils.Document(req)

        generateReviewersAndWatchersTable(db, repository, document,
                                          all_reviewers, all_watchers,
                                          applyfilters=applyfilters,
                                          applyparentfilters=applyparentfilters)

        return OperationResult(html=document.render(plain=True))

class SubmitReview(Operation):
    def __init__(self):
        Operation.__init__(self, { "repository": Repository,
                                   "branch": str,
                                   "summary": str,
                                   "commit_ids": Optional([int]),
                                   "commit_sha1s": Optional([str]),
                                   "applyfilters": Optional(bool),
                                   "applyparentfilters": Optional(bool),
                                   "reviewfilters": Optional([{ "username": str,
                                                                "type": set(["reviewer", "watcher"]),
                                                                "path": str }]),
                                   "recipientfilters": Optional({ "mode": set(["opt-in", "opt-out"]),
                                                                  "included": Optional([str]),
                                                                  "excluded": Optional([str]) }),
                                   "description": Optional(str),
                                   "frombranch": Optional(str),
                                   "trackedbranch": Optional({ "remote": str,
                                                               "name": str }) })

    def process(self, db, user, repository, branch, summary, commit_ids=None,
                commit_sha1s=None, applyfilters=True, applyparentfilters=True,
                reviewfilters=None, recipientfilters=None, description=None,
                frombranch=None, trackedbranch=None):
        if not branch.startswith("r/"):
            raise OperationFailure(code="invalidbranch",
                                   title="Invalid review branch name",
                                   message="'%s' is not a valid review branch name; it must have a \"r/\" prefix." % branch)

        if reviewfilters is None:
            reviewfilters = []
        if recipientfilters is None:
            recipientfilters = {}

        components = branch.split("/")
        for index in range(1, len(components)):
            try:
                repository.revparse("refs/heads/%s" % "/".join(components[:index]))
            except gitutils.GitReferenceError:
                continue

            message = ("Cannot create branch with name<pre>%s</pre>since there is already a branch named<pre>%s</pre>in the repository." %
                       (htmlutils.htmlify(branch), htmlutils.htmlify("/".join(components[:index]))))
            raise OperationFailure(code="invalidbranch",
                                   title="Invalid review branch name",
                                   message=message,
                                   is_html=True)

        if commit_sha1s is not None:
            commits = [gitutils.Commit.fromSHA1(db, repository, commit_sha1) for commit_sha1 in commit_sha1s]
        elif commit_ids is not None:
            commits = [gitutils.Commit.fromId(db, repository, commit_id) for commit_id in commit_ids]
        else:
            commits = []

        commitset = CommitSet(commits)

        reviewfilters = parseReviewFilters(db, reviewfilters)
        recipientfilters = parseRecipientFilters(db, recipientfilters)

        review = createReview(db, user, repository, commits, branch, summary, description,
                              from_branch_name=frombranch,
                              reviewfilters=reviewfilters,
                              recipientfilters=recipientfilters,
                              applyfilters=applyfilters,
                              applyparentfilters=applyparentfilters)

        extensions_output = StringIO()
        kwargs = {}

        if configuration.extensions.ENABLED:
            if extensions.role.processcommits.execute(db, user, review, commits, None, commitset.getHeads().pop(), extensions_output):
                kwargs["extensions_output"] = extensions_output.getvalue().lstrip()

        if trackedbranch:
            cursor = db.cursor()

            cursor.execute("""SELECT 1
                                FROM knownremotes
                               WHERE url=%s
                                 AND pushing""",
                           (trackedbranch["remote"],))

            if cursor.fetchone():
                delay = "1 week"
            else:
                delay = "1 hour"

            cursor.execute("""INSERT INTO trackedbranches (repository, local_name, remote, remote_name, forced, delay)
                                   VALUES (%s, %s, %s, %s, false, %s)
                                RETURNING id""",
                           (repository.id, branch, trackedbranch["remote"], trackedbranch["name"], delay))

            trackedbranch_id = cursor.fetchone()[0]

            cursor.execute("""INSERT INTO trackedbranchusers (branch, uid)
                                   VALUES (%s, %s)""",
                           (trackedbranch_id, user.id))

            db.commit()

            pid = int(open(configuration.services.BRANCHTRACKER["pidfile_path"]).read().strip())
            os.kill(pid, signal.SIGHUP)

        return OperationResult(review_id=review.id, **kwargs)

class FetchRemoteBranches(Operation):
    def __init__(self):
        Operation.__init__(self, { "remote": str,
                                   "pattern": Optional(str) },
                           accept_anonymous_user=True)

    def process(self, db, user, remote, pattern=None):
        if pattern: regexp = re.compile(pattern.replace("*", ".*"))
        else: regexp = None

        try:
            refs = gitutils.Repository.lsremote(remote, regexp=regexp)
        except gitutils.GitCommandError as error:
            if error.output.splitlines()[0].endswith("does not appear to be a git repository"):
                raise OperationFailure(
                    code="invalidremote",
                    title="Invalid remote!",
                    message=("<code>%s</code> does not appear to be a valid Git repository."
                             % htmlutils.htmlify(remote)),
                    is_html=True)
            else:
                raise
        else:
            branches = dict([(ref[1], ref[0]) for ref in refs])
            return OperationResult(branches=branches)

class FetchRemoteBranch(Operation):
    def __init__(self):
        Operation.__init__(self, { "repository_name": str,
                                   "remote": str,
                                   "branch": str,
                                   "upstream": Optional(str) },
                           accept_anonymous_user=True)

    def process(self, db, user, repository_name, remote, branch, upstream="refs/heads/master"):
        repository = gitutils.Repository.fromName(db, repository_name)

        cursor = db.cursor()

        # Check if any other repository is currently tracking branches from this
        # remote.  If that's the case, then the user most likely either selected
        # the wrong repository or entered the wrong remote.
        cursor.execute("""SELECT repositories.name
                            FROM repositories
                            JOIN trackedbranches ON (trackedbranches.repository=repositories.id)
                           WHERE repositories.id!=%s
                             AND trackedbranches.remote=%s""",
                       (repository.id, remote))
        for (other_name,) in cursor:
            raise OperationFailure(
                code="badremote",
                title="Bad remote!",
                message=("The remote <code>%s</code> appears to be related to "
                         "another repository on this server (<code>%s</code>).  "
                         "You most likely shouldn't be importing branches from "
                         "it into the selected repository (<code>%s</code>)."
                         % (htmlutils.htmlify(remote), htmlutils.htmlify(other_name),
                            htmlutils.htmlify(repository_name))),
                is_html=True)

        if not branch.startswith("refs/"):
            branch = "refs/heads/%s" % branch

        try:
            head_sha1 = repository.fetchTemporaryFromRemote(remote, branch)
        except gitutils.GitReferenceError:
            raise OperationFailure(
                code="refnotfound",
                title="Remote ref not found!",
                message=("Could not find the ref <code>%s</code> in the repository <code>%s</code>."
                         % (htmlutils.htmlify(branch), htmlutils.htmlify(remote))),
                is_html=True)
        except gitutils.GitCommandError as error:
            if error.output.splitlines()[0].endswith("does not appear to be a git repository"):
                raise OperationFailure(
                    code="invalidremote",
                    title="Invalid remote!",
                    message=("<code>%s</code> does not appear to be a valid Git repository."
                             % htmlutils.htmlify(remote)),
                    is_html=True)
            else:
                raise

        if upstream.startswith("refs/"):
            try:
                upstream_sha1 = repository.fetchTemporaryFromRemote(remote, upstream)
            except gitutils.GitReferenceError:
                raise OperationFailure(
                    code="refnotfound",
                    title="Remote ref not found!",
                    message=("Could not find the ref <code>%s</code> in the repository <code>%s</code>."
                             % (htmlutils.htmlify(upstream), htmlutils.htmlify(remote))),
                    is_html=True)
        else:
            try:
                upstream_sha1 = repository.revparse(upstream)
            except gitutils.GitReferenceError:
                raise OperationFailure(
                    code="refnotfound",
                    title="Local ref not found!",
                    message=("Could not find the ref <code>%s</code> in the repository <code>%s</code>."
                             % (htmlutils.htmlify(upstream), htmlutils.htmlify(str(repository)))),
                    is_html=True)

        try:
            resolved_upstream_sha1 = gitutils.getTaggedCommit(repository, upstream_sha1)
        except gitutils.GitReferenceError:
            resolved_upstream_sha1 = None

        if not resolved_upstream_sha1:
            raise OperationFailure(
                code="missingcommit",
                title="Upstream commit is missing!",
                message=("<p>Could not find the commit <code>%s</code> in the "
                         "repository <code>%s</code>.</p>"
                         "<p>Since it would have been fetched along with the "
                         "branch if it actually was a valid upstream commit, "
                         "this means it's not valid.</p>"
                         % (htmlutils.htmlify(upstream_sha1), htmlutils.htmlify(str(repository)))),
                is_html=True)

        commit_sha1s = repository.revlist(included=[head_sha1], excluded=[resolved_upstream_sha1])

        if not commit_sha1s:
            raise OperationFailure(
                code="emptybranch",
                title="Branch contains no commits!",
                message=("All commits referenced by <code>%s</code> are reachable from <code>%s</code>."
                         % (htmlutils.htmlify(branch), htmlutils.htmlify(upstream))),
                is_html=True)

        cursor.execute("SELECT id FROM commits WHERE sha1=ANY (%s)", (commit_sha1s,))

        return OperationResult(commit_ids=[commit_id for (commit_id,) in cursor],
                               head_sha1=head_sha1, upstream_sha1=resolved_upstream_sha1)

########NEW FILE########
__FILENAME__ = draftchanges
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2012 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import dbutils
import profiling

from operation import Operation, OperationResult, Optional
from reviewing.comment import CommentChain, createCommentChain, createComment
from reviewing.mail import sendPendingMails
from reviewing.utils import generateMailsForBatch

class ReviewStateChange(Operation):
    def __init__(self):
        Operation.__init__(self, { "review_id": int })

    def process(self, db, user, review_id):
        cursor = db.cursor()

        def unaccepted():
            # Raised issues.
            cursor.execute("""SELECT 1
                                FROM commentchains
                               WHERE commentchains.review=%s
                                 AND commentchains.uid=%s
                                 AND commentchains.type='issue'
                                 AND commentchains.state='draft'""",
                           (review_id, user.id))
            if cursor.fetchone(): return True

            # Reopened issues.
            cursor.execute("""SELECT 1
                                FROM commentchainchanges
                                JOIN commentchains ON (commentchains.id=commentchainchanges.chain)
                               WHERE commentchains.review=%s
                                 AND commentchains.type='issue'
                                 AND commentchainchanges.uid=%s
                                 AND commentchainchanges.state='draft'
                                 AND commentchainchanges.from_state=commentchains.state
                                 AND commentchainchanges.to_state='open'
                                 AND commentchainchanges.to_type IS NULL""",
                           (review_id, user.id))
            if cursor.fetchone(): return True

            # Note converted into issues.
            cursor.execute("""SELECT 1
                                FROM commentchainchanges
                                JOIN commentchains ON (commentchains.id=commentchainchanges.chain)
                               WHERE commentchains.review=%s
                                 AND commentchains.type='note'
                                 AND commentchainchanges.uid=%s
                                 AND commentchainchanges.state='draft'
                                 AND commentchainchanges.from_type=commentchains.type
                                 AND commentchainchanges.to_type='issue'""",
                           (review_id, user.id))
            if cursor.fetchone(): return True

            # Unreviewed lines.
            cursor.execute("""SELECT 1
                                FROM reviewfilechanges
                                JOIN reviewfiles ON (reviewfiles.id=reviewfilechanges.file)
                               WHERE reviewfiles.review=%s
                                 AND reviewfilechanges.uid=%s
                                 AND reviewfilechanges.state='draft'
                                 AND reviewfilechanges.from=reviewfiles.state
                                 AND reviewfilechanges.to='pending'""",
                           (review_id, user.id))
            if cursor.fetchone(): return True

            # Otherwise still accepted (if accepted before.)
            return False

        def stillOpen():
            if unaccepted(): return True

            # Still open issues.
            cursor.execute("""SELECT 1
                                FROM commentchains
                     LEFT OUTER JOIN commentchainchanges ON (commentchainchanges.chain=commentchains.id
                                                         AND commentchainchanges.uid=%s
                                                         AND commentchainchanges.state='draft'
                                                         AND (commentchainchanges.to_state IN ('closed', 'addressed')
                                                           OR commentchainchanges.to_type='note'))
                               WHERE commentchains.review=%s
                                 AND commentchains.type='issue'
                                 AND commentchains.state='open'
                                 AND commentchainchanges.chain IS NULL""",
                           (user.id, review_id))
            if cursor.fetchone(): return True

            # Still pending lines.
            cursor.execute("""SELECT 1
                                FROM reviewfiles
                     LEFT OUTER JOIN reviewfilechanges ON (reviewfilechanges.file=reviewfiles.id
                                                       AND reviewfilechanges.uid=%s
                                                       AND reviewfilechanges.state='draft'
                                                       AND reviewfilechanges.to='reviewed')
                               WHERE reviewfiles.review=%s
                                 AND reviewfiles.state='pending'
                                 AND reviewfilechanges.file IS NULL""",
                           (user.id, review_id))
            if cursor.fetchone(): return True

            # Otherwise accepted now.
            return False

        if dbutils.Review.isAccepted(db, review_id):
            return OperationResult(current_state="accepted", new_state="open" if unaccepted() else "accepted")
        else:
            return OperationResult(current_state="open", new_state="open" if stillOpen() else "accepted")

class SubmitChanges(Operation):
    def __init__(self):
        Operation.__init__(self, { "review_id": int,
                                   "remark": Optional(str) })

    def process(self, db, user, review_id, remark=None):
        cursor = db.cursor()
        profiler = profiling.Profiler()

        profiler.check("start")

        review = dbutils.Review.fromId(db, review_id, load_commits=False)

        profiler.check("create review")

        was_accepted = review.state == "open" and review.accepted(db)

        profiler.check("accepted before")

        if remark and remark.strip():
            chain_id = createCommentChain(db, user, review, 'note')
            createComment(db, user, chain_id, remark, first=True)
        else:
            chain_id = None

        # Create a batch that groups all submitted changes together.
        cursor.execute("INSERT INTO batches (review, uid, comment) VALUES (%s, %s, %s) RETURNING id", (review.id, user.id, chain_id))
        batch_id = cursor.fetchone()[0]

        profiler.check("batches++")

        # Reject all draft file approvals where the affected review file isn't in
        # the state it was in when the change was drafted.
        cursor.execute("""UPDATE reviewfilechanges
                             SET state='rejected',
                                 time=now()
                            FROM reviewfiles
                           WHERE reviewfiles.review=%s
                             AND reviewfiles.id=reviewfilechanges.file
                             AND reviewfilechanges.uid=%s
                             AND reviewfilechanges.state='draft'
                             AND reviewfilechanges.from!=reviewfiles.state""",
                       (review.id, user.id))

        profiler.check("reviewfilechanges reject state changes")

        # Then perform the remaining draft file approvals by updating the state of
        # the corresponding review file.
        cursor.execute("""UPDATE reviewfiles
                             SET state='reviewed',
                                 reviewer=reviewfilechanges.uid,
                                 time=now()
                            FROM reviewfilechanges
                           WHERE reviewfiles.review=%s
                             AND reviewfilechanges.uid=%s
                             AND reviewfilechanges.state='draft'
                             AND reviewfilechanges.file=reviewfiles.id
                             AND reviewfilechanges.from=reviewfiles.state
                             AND reviewfilechanges.to='reviewed'""",
                       (review.id, user.id))

        profiler.check("reviewfiles pending=>reviewed")

        # Then perform the remaining draft file disapprovals by updating the state
        # of the corresponding review file.
        cursor.execute("""UPDATE reviewfiles
                             SET state='pending',
                                 reviewer=NULL,
                                 time=now()
                            FROM reviewfilechanges
                           WHERE reviewfiles.review=%s
                             AND reviewfilechanges.uid=%s
                             AND reviewfilechanges.state='draft'
                             AND reviewfilechanges.file=reviewfiles.id
                             AND reviewfilechanges.from=reviewfiles.state
                             AND reviewfilechanges.to='pending'""",
                       (review.id, user.id))

        profiler.check("reviewfiles reviewed=>pending")

        # Finally change the state of just performed approvals from draft to
        # 'performed'.
        cursor.execute("""UPDATE reviewfilechanges
                             SET batch=%s,
                                 state='performed',
                                 time=now()
                            FROM reviewfiles
                           WHERE reviewfiles.review=%s
                             AND reviewfiles.id=reviewfilechanges.file
                             AND reviewfilechanges.uid=%s
                             AND reviewfilechanges.state='draft'
                             AND reviewfilechanges.to=reviewfiles.state""",
                       (batch_id, review.id, user.id))

        profiler.check("reviewfilechanges draft=>performed")

        # Find all chains with draft comments being submitted that the current user
        # isn't associated with via the commentchainusers table, and associate the
        # user with them.
        cursor.execute("""SELECT DISTINCT commentchains.id, commentchainusers.uid IS NULL
                            FROM commentchains
                            JOIN comments ON (comments.chain=commentchains.id)
                 LEFT OUTER JOIN commentchainusers ON (commentchainusers.chain=commentchains.id
                                                   AND commentchainusers.uid=comments.uid)
                           WHERE commentchains.review=%s
                             AND comments.uid=%s
                             AND comments.state='draft'""",
                       (review.id, user.id))

        for chain_id, need_associate in cursor.fetchall():
            if need_associate:
                cursor.execute("INSERT INTO commentchainusers (chain, uid) VALUES (%s, %s)", (chain_id, user.id))

        profiler.check("commentchainusers++")

        # Find all chains with draft comments being submitted and add a record for
        # every user associated with the chain to read the comment.
        cursor.execute("""INSERT
                            INTO commentstoread (uid, comment)
                          SELECT commentchainusers.uid, comments.id
                            FROM commentchains, commentchainusers, comments
                           WHERE commentchains.review=%s
                             AND commentchainusers.chain=commentchains.id
                             AND commentchainusers.uid!=comments.uid
                             AND comments.chain=commentchains.id
                             AND comments.uid=%s
                             AND comments.state='draft'""",
                       (review.id, user.id))

        profiler.check("commentstoread++")

        # Associate all users associated with a draft comment chain to
        # the review (if they weren't already.)
        cursor.execute("""SELECT DISTINCT commentchainusers.uid
                            FROM commentchains
                            JOIN commentchainusers ON (commentchainusers.chain=commentchains.id)
                 LEFT OUTER JOIN reviewusers ON (reviewusers.review=commentchains.review AND reviewusers.uid=commentchainusers.uid)
                           WHERE commentchains.review=%s
                             AND commentchains.uid=%s
                             AND commentchains.state='draft'
                             AND reviewusers.uid IS NULL""",
                       (review.id, user.id))

        for (user_id,) in cursor.fetchall():
            cursor.execute("INSERT INTO reviewusers (review, uid) VALUES (%s, %s)", (review.id, user_id))

        # Change state on all draft commentchains by the user in the review to 'open'.
        cursor.execute("""UPDATE commentchains
                             SET batch=%s,
                                 state='open',
                                 time=now()
                           WHERE commentchains.review=%s
                             AND commentchains.uid=%s
                             AND commentchains.state='draft'""",
                       (batch_id, review.id, user.id))

        profiler.check("commentchains draft=>open")

        # Reject all draft comment chain changes where the affected comment
        # chain isn't in the state it was in when the change was drafted, or has
        # been morphed into a note since the change was drafted.
        cursor.execute("""UPDATE commentchainchanges
                             SET state='rejected',
                                 time=now()
                            FROM commentchains
                           WHERE commentchains.review=%s
                             AND commentchainchanges.chain=commentchains.id
                             AND commentchainchanges.uid=%s
                             AND commentchainchanges.state='draft'
                             AND commentchainchanges.from_state IS NOT NULL
                             AND (commentchainchanges.from_state!=commentchains.state
                               OR commentchainchanges.from_last_commit!=commentchains.last_commit
                               OR commentchains.type!='issue')""",
                       (review.id, user.id))

        profiler.check("commentchainchanges reject state changes")

        # Reject all draft comment chain changes where the affected comment chain
        # type isn't what it was in when the change was drafted.
        cursor.execute("""UPDATE commentchainchanges
                             SET state='rejected',
                                 time=now()
                            FROM commentchains
                           WHERE commentchains.review=%s
                             AND commentchainchanges.chain=commentchains.id
                             AND commentchainchanges.uid=%s
                             AND commentchainchanges.state='draft'
                             AND commentchainchanges.from_type IS NOT NULL
                             AND commentchainchanges.from_type!=commentchains.type""",
                       (review.id, user.id))

        profiler.check("commentchainchanges reject type changes")

        # Reject all draft comment chain changes where the affected comment chain
        # addressed_by isn't what it was in when the change was drafted.
        cursor.execute("""UPDATE commentchainchanges
                             SET state='rejected',
                                 time=now()
                            FROM commentchains
                           WHERE commentchains.review=%s
                             AND commentchainchanges.chain=commentchains.id
                             AND commentchainchanges.uid=%s
                             AND commentchainchanges.state='draft'
                             AND commentchainchanges.from_addressed_by IS NOT NULL
                             AND commentchainchanges.from_addressed_by!=commentchains.addressed_by""",
                       (review.id, user.id))

        profiler.check("commentchainchanges reject addressed_by changes")

        # Then perform the remaining draft comment chain changes by updating the
        # state of the corresponding comment chain.

        # Perform open->closed changes, including setting 'closed_by'.
        cursor.execute("""UPDATE commentchains
                             SET state='closed',
                                 closed_by=commentchainchanges.uid
                            FROM commentchainchanges
                           WHERE commentchains.review=%s
                             AND commentchainchanges.chain=commentchains.id
                             AND commentchainchanges.uid=%s
                             AND commentchainchanges.state='draft'
                             AND commentchainchanges.to_state='closed'""",
                       (review.id, user.id))

        profiler.check("commentchains closed")

        # Perform (closed|addressed)->open changes, including resetting 'closed_by' and
        # 'addressed_by' to NULL.
        cursor.execute("""UPDATE commentchains
                             SET state='open',
                                 last_commit=commentchainchanges.to_last_commit,
                                 closed_by=NULL,
                                 addressed_by=NULL
                            FROM commentchainchanges
                           WHERE commentchains.review=%s
                             AND commentchainchanges.chain=commentchains.id
                             AND commentchainchanges.uid=%s
                             AND commentchainchanges.state='draft'
                             AND commentchainchanges.to_state='open'""",
                       (review.id, user.id))

        profiler.check("commentchains reopen")

        # Perform addressed->addressed changes, i.e. updating 'addressed_by'.
        cursor.execute("""UPDATE commentchains
                             SET addressed_by=commentchainchanges.to_addressed_by
                            FROM commentchainchanges
                           WHERE commentchains.review=%s
                             AND commentchainchanges.chain=commentchains.id
                             AND commentchainchanges.uid=%s
                             AND commentchainchanges.state='draft'
                             AND commentchainchanges.to_addressed_by IS NOT NULL""",
                       (review.id, user.id))

        profiler.check("commentchains reopen (partial)")

        # Perform type changes.
        cursor.execute("""UPDATE commentchains
                             SET type=commentchainchanges.to_type
                            FROM commentchainchanges
                           WHERE commentchains.review=%s
                             AND commentchainchanges.chain=commentchains.id
                             AND commentchainchanges.uid=%s
                             AND commentchainchanges.state='draft'
                             AND commentchainchanges.from_type=commentchains.type
                             AND commentchainchanges.to_type IS NOT NULL""",
                       (review.id, user.id))

        profiler.check("commentchains type change")

        # Finally change the state of just performed changes from draft to
        # 'performed'.
        cursor.execute("""UPDATE commentchainchanges
                             SET batch=%s,
                                 state='performed',
                                 time=now()
                            FROM commentchains
                           WHERE commentchains.review=%s
                             AND commentchainchanges.chain=commentchains.id
                             AND commentchainchanges.uid=%s
                             AND commentchainchanges.state='draft'""",
                       (batch_id, review.id, user.id))

        profiler.check("commentchainchanges draft=>performed")

        # Change state on all draft commentchainlines by the user in the review to 'current'.
        cursor.execute("""UPDATE commentchainlines
                             SET state='current',
                                 time=now()
                            FROM commentchains
                           WHERE commentchains.review=%s
                             AND commentchainlines.chain=commentchains.id
                             AND commentchainlines.uid=%s
                             AND commentchainlines.state='draft'""",
                       (review.id, user.id))

        profiler.check("commentchainlines draft=>current")

        # Change state on all draft comments by the user in the review to 'current'.
        cursor.execute("""UPDATE comments
                             SET batch=%s,
                                 state='current',
                                 time=now()
                            FROM commentchains
                           WHERE commentchains.review=%s
                             AND comments.chain=commentchains.id
                             AND comments.uid=%s
                             AND comments.state='draft'""",
                       (batch_id, review.id, user.id))

        profiler.check("comments draft=>current")

        # Associate the submitting user with the review if he isn't already.
        cursor.execute("SELECT 1 FROM reviewusers WHERE review=%s AND uid=%s", (review.id, user.id))
        if not cursor.fetchone():
            cursor.execute("INSERT INTO reviewusers (review, uid) VALUES (%s, %s)", (review.id, user.id))

        generate_emails = profiler.start("generate emails")

        is_accepted = review.state == "open" and review.accepted(db)
        pending_mails = generateMailsForBatch(db, batch_id, was_accepted, is_accepted, profiler=profiler)

        generate_emails.stop()

        review.incrementSerial(db)
        db.commit()

        profiler.check("commit transaction")

        sendPendingMails(pending_mails)

        profiler.check("finished")

        if user.getPreference(db, "debug.profiling.submitChanges"):
            return OperationResult(serial=review.serial, profiling=profiler.output())
        else:
            return OperationResult(serial=review.serial)

class AbortChanges(Operation):
    def __init__(self):
        Operation.__init__(self, { "review_id": int,
                                   "what": { "approval": bool,
                                             "comments": bool,
                                             "metacomments": bool }})

    def process(self, db, user, review_id, what):
        cursor = db.cursor()
        profiler = profiling.Profiler()

        if what["approval"]:
            # Delete all pending review file approvals.
            cursor.execute("""DELETE
                                FROM reviewfilechanges
                               USING reviewfiles
                               WHERE reviewfiles.review=%s
                                 AND reviewfilechanges.file=reviewfiles.id
                                 AND reviewfilechanges.uid=%s
                                 AND reviewfilechanges.state='draft'""",
                           (review_id, user.id))
            profiler.check("approval")

        if what["comments"]:
            # Delete all pending comments chains.  This will, via ON DELETE CASCADE,
            # also delete all related comments and commentchainlines rows.
            cursor.execute("""DELETE
                                FROM commentchains
                               WHERE commentchains.review=%s
                                 AND commentchains.uid=%s
                                 AND commentchains.state='draft'""",
                           (review_id, user.id))
            profiler.check("chains")

            # Delete all still existing draft comments.
            cursor.execute("""DELETE
                                FROM comments
                               USING commentchains
                               WHERE commentchains.review=%s
                                 AND commentchains.id=comments.chain
                                 AND comments.uid=%s
                                 AND comments.state='draft'""",
                           (review_id, user.id))
            profiler.check("replies")

        if what["metacomments"]:
            # Delete all still existing draft comment lines.
            cursor.execute("""DELETE
                                FROM commentchainlines
                               USING commentchains
                               WHERE commentchains.review=%s
                                 AND commentchainlines.chain=commentchains.id
                                 AND commentchainlines.uid=%s
                                 AND commentchainlines.state='draft'
                                 AND commentchains.state!='draft'""",
                           (review_id, user.id))
            profiler.check("comment lines")

            # Delete all still existing draft comment state changes.
            cursor.execute("""DELETE
                                FROM commentchainchanges
                               USING commentchains
                               WHERE commentchains.review=%s
                                 AND commentchainchanges.chain=commentchains.id
                                 AND commentchainchanges.uid=%s
                                 AND commentchainchanges.state='draft'""",
                           (review_id, user.id))
            profiler.check("comment state")

        db.commit()

        if user.getPreference(db, "debug.profiling.abortChanges"):
            return OperationResult(profiling=profiler.output())
        else:
            return OperationResult()

########NEW FILE########
__FILENAME__ = editresource
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2012 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import dbutils
import gitutils

from operation import Operation, OperationResult, OperationError, Optional

class StoreResource(Operation):
    """Store new revision of user-edited resource."""

    def __init__(self):
        Operation.__init__(self, { "name": str,
                                   "source": str })

    def process(self, db, user, name, source):
        cursor = db.cursor()
        cursor.execute("SELECT MAX(revision) FROM userresources WHERE uid=%s AND name=%s", (user.id, name))

        current_revision = cursor.fetchone()[0] or 0
        next_revision = current_revision + 1

        cursor.execute("INSERT INTO userresources (uid, name, revision, source) VALUES (%s, %s, %s, %s)", (user.id, name, next_revision, source))

        db.commit()

        return OperationResult()

class ResetResource(Operation):
    """Reset user-edited resource back to its original."""

    def __init__(self):
        Operation.__init__(self, { "name": str })

    def process(self, db, user, name):
        cursor = db.cursor()
        cursor.execute("SELECT MAX(revision) FROM userresources WHERE uid=%s AND name=%s", (user.id, name))

        current_revision = cursor.fetchone()[0] or 0

        if current_revision > 0:
            cursor.execute("SELECT source FROM userresources WHERE uid=%s AND name=%s AND revision=%s", (user.id, name, current_revision))

            if cursor.fetchone()[0] is not None:
                next_revision = current_revision + 1

                cursor.execute("INSERT INTO userresources (uid, name, revision) VALUES (%s, %s, %s)", (user.id, name, next_revision))

                db.commit()

        return OperationResult()

class RestoreResource(Operation):
    """Restore last user-edited revision of resource after it's been reset."""

    def __init__(self):
        Operation.__init__(self, { "name": str })

    def process(self, db, user, name):
        cursor = db.cursor()
        cursor.execute("SELECT MAX(revision) FROM userresources WHERE uid=%s AND name=%s", (user.id, name))

        current_revision = cursor.fetchone()[0] or 0

        if current_revision > 1:
            cursor.execute("SELECT source FROM userresources WHERE uid=%s AND name=%s AND revision=%s", (user.id, name, current_revision))

            if cursor.fetchone()[0] is None:
                cursor.execute("DELETE FROM userresources WHERE uid=%s AND name=%s AND revision=%s", (user.id, name, current_revision))

                db.commit()

        return OperationResult()

########NEW FILE########
__FILENAME__ = extensioninstallation
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2012 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

from operation import Operation, OperationResult, OperationFailure, \
                      OperationError, Optional
from extensions.installation import installExtension, uninstallExtension, \
                                    reinstallExtension, InstallationError, \
                                    getExtension

class ExtensionOperation(Operation):
    def __init__(self, perform):
        Operation.__init__(self, { "extension_name": str,
                                   "author_name": Optional(str),
                                   "version": Optional(str),
                                   "universal": Optional(bool) })
        self.perform = perform

    def process(self, db, user, extension_name, author_name=None, version=None,
                universal=False):
        if universal:
            if not user.hasRole(db, "administrator"):
                raise OperationFailure(code="notallowed",
                                       title="Not allowed!",
                                       message="Operation not permitted.")
            user = None

        if version is not None:
            if version == "live":
                version = None
            elif version.startswith("version/"):
                version = version[8:]
            else:
                raise OperationError(
                    "invalid version, got '%s', expected 'live' or 'version/*'"
                    % version)

        try:
            self.perform(db, user, author_name, extension_name, version)
        except InstallationError as error:
            raise OperationFailure(code="installationerror",
                                   title=error.title,
                                   message=error.message,
                                   is_html=error.is_html)

        return OperationResult()

class InstallExtension(ExtensionOperation):
    def __init__(self):
        ExtensionOperation.__init__(self, installExtension)

class UninstallExtension(ExtensionOperation):
    def __init__(self):
        ExtensionOperation.__init__(self, uninstallExtension)

class ReinstallExtension(ExtensionOperation):
    def __init__(self):
        ExtensionOperation.__init__(self, reinstallExtension)

class ClearExtensionStorage(Operation):
    def __init__(self):
        Operation.__init__(self, { "extension_name": str,
                                   "author_name": Optional(str) })

    def process(self, db, user, extension_name, author_name=None):
        extension = getExtension(author_name, extension_name)
        extension_id = extension.getExtensionID(db, create=False)

        if extension_id is not None:
            cursor = db.cursor()
            cursor.execute("""DELETE FROM extensionstorage
                                    WHERE extension=%s
                                      AND uid=%s""",
                           (extension_id, user.id))
            db.commit()

        return OperationResult()

########NEW FILE########
__FILENAME__ = fetchlines
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2012 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import gitutils
import htmlutils
import diff

from operation import Operation, OperationResult

class FetchLines(Operation):
    def __init__(self):
        Operation.__init__(self, { "repository_id": int,
                                   "path": str,
                                   "sha1": str,
                                   "ranges": [{ "offset": int,
                                                "count": int,
                                                "context": bool }],
                                   "tabify": bool },
                           accept_anonymous_user=True)

    def process(self, db, user, repository_id, path, sha1, ranges, tabify):
        repository = gitutils.Repository.fromId(db, repository_id)
        cursor = db.cursor()

        def getContext(offset):
            cursor.execute("""SELECT context
                                FROM codecontexts
                               WHERE sha1=%s
                                 AND %s BETWEEN first_line AND last_line
                            ORDER BY first_line DESC
                               LIMIT 1""",
                           (sha1, offset))

            row = cursor.fetchone()

            if row: return row[0]
            else: return None

        file = diff.File(repository=repository, path=path, new_sha1=sha1)
        file.loadNewLines(highlighted=True, request_highlight=True)

        if tabify:
            tabwidth = file.getTabWidth()
            indenttabsmode = file.getIndentTabsMode()

        def processRange(offset, count, context):
            if context: context = getContext(offset)
            else: context = None

            # Offset is a 1-based line number.
            start = offset - 1
            # If count is -1, fetch all lines.
            end = start + count if count > -1 else None

            lines = file.newLines(highlighted=True)[start:end]

            if tabify:
                lines = [htmlutils.tabify(line, tabwidth, indenttabsmode) for line in lines]

            return { "lines": lines, "context": context }

        return OperationResult(ranges=[processRange(**line_range) for line_range in ranges])

########NEW FILE########
__FILENAME__ = manipulateassignments
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2012 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import itertools

import dbutils
import mailutils
import reviewing.utils

from operation import Operation, OperationResult

class GetAssignedChanges(Operation):
    def __init__(self):
        Operation.__init__(self, { "review_id": int,
                                   "user_name": str })

    def process(self, db, user, review_id, user_name):
        reviewer = dbutils.User.fromName(db, user_name)

        cursor = db.cursor()
        cursor.execute("SELECT file FROM fullreviewuserfiles WHERE review=%s AND assignee=%s", (review_id, reviewer.id))

        return OperationResult(files=[file_id for (file_id,) in cursor])

class SetAssignedChanges(Operation):
    def __init__(self):
        Operation.__init__(self, { "review_id": int,
                                   "user_name": str,
                                   "files": [int] })

    def process(self, db, user, review_id, user_name, files):
        reviewer = dbutils.User.fromName(db, user_name)
        new_file_ids = set(files)

        cursor = db.cursor()
        cursor.execute("SELECT 1 FROM reviewusers WHERE review=%s AND uid=%s", (review_id, reviewer.id))

        if not cursor.fetchone():
            cursor.execute("INSERT INTO reviewusers (review, uid) VALUES (%s, %s)", (review_id, reviewer.id))
            current_file_ids = set()
        else:
            cursor.execute("SELECT file FROM fullreviewuserfiles WHERE review=%s AND assignee=%s", (review_id, reviewer.id))
            current_file_ids = set(file_id for (file_id,) in cursor)

        delete_file_ids = current_file_ids - new_file_ids
        new_file_ids -= current_file_ids

        if delete_file_ids or new_file_ids:
            cursor.execute("INSERT INTO reviewassignmentstransactions (review, assigner) VALUES (%s, %s) RETURNING id", (review_id, user.id))
            transaction_id = cursor.fetchone()[0]

        if delete_file_ids:
            cursor.executemany("""INSERT INTO reviewassignmentchanges (transaction, file, uid, assigned)
                                       SELECT %s, reviewfiles.id, reviewuserfiles.uid, false
                                         FROM reviewfiles
                                         JOIN reviewuserfiles ON (reviewuserfiles.file=reviewfiles.id)
                                        WHERE reviewfiles.review=%s
                                          AND reviewfiles.file=%s
                                          AND reviewuserfiles.uid=%s""",
                               itertools.izip(itertools.repeat(transaction_id),
                                              itertools.repeat(review_id),
                                              delete_file_ids,
                                              itertools.repeat(reviewer.id)))

            cursor.executemany("""DELETE FROM reviewuserfiles
                                        USING reviewfiles
                                        WHERE reviewuserfiles.file=reviewfiles.id
                                          AND reviewfiles.review=%s
                                          AND reviewfiles.file=%s
                                          AND reviewuserfiles.uid=%s""",
                               itertools.izip(itertools.repeat(review_id),
                                              delete_file_ids,
                                              itertools.repeat(reviewer.id)))

        if new_file_ids:
            cursor.executemany("""INSERT INTO reviewuserfiles (file, uid)
                                       SELECT reviewfiles.id, %s
                                         FROM reviewfiles
                                        WHERE reviewfiles.review=%s
                                          AND reviewfiles.file=%s""",
                               itertools.izip(itertools.repeat(reviewer.id),
                                              itertools.repeat(review_id),
                                              new_file_ids))

            cursor.executemany("""INSERT INTO reviewassignmentchanges (transaction, file, uid, assigned)
                                       SELECT %s, reviewfiles.id, %s, true
                                         FROM reviewfiles
                                        WHERE reviewfiles.review=%s
                                          AND reviewfiles.file=%s""",
                               itertools.izip(itertools.repeat(transaction_id),
                                              itertools.repeat(reviewer.id),
                                              itertools.repeat(review_id),
                                              new_file_ids))

        if delete_file_ids or new_file_ids:
            cursor.execute("UPDATE reviews SET serial=serial+1 WHERE id=%s", (review_id,))

            pending_mails = reviewing.utils.generateMailsForAssignmentsTransaction(db, transaction_id)

            db.commit()

            mailutils.sendPendingMails(pending_mails)

        return OperationResult()

########NEW FILE########
__FILENAME__ = manipulatecomment
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2012 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import dbutils
import gitutils

from operation import Operation, OperationResult, OperationError, OperationFailure, Optional
from reviewing.comment import Comment, CommentChain, propagate

class SetCommentChainState(Operation):
    def __init__(self, parameters):
        Operation.__init__(self, parameters)

    def setChainState(self, db, user, chain, old_state, new_state, new_last_commit=None):
        review = chain.review

        if chain.state != old_state:
            raise OperationFailure(code="invalidoperation",
                                   title="Invalid operation",
                                   message="The comment chain's state is not '%s'; can't change state to '%s'." % (old_state, new_state))
        elif new_state == "open" and review.state != "open":
            raise OperationFailure(code="invalidoperation",
                                   title="Invalid operation",
                                   message="Can't reopen comment chain in %s review!" % review.state)

        if chain.last_commit:
            old_last_commit = chain.last_commit.id
            if new_last_commit is None:
                new_last_commit = old_last_commit
        else:
            old_last_commit = new_last_commit = None

        cursor = db.cursor()

        if chain.state_is_draft:
            # The user is reverting a draft state change; just undo the draft
            # change.
            cursor.execute("""DELETE FROM commentchainchanges
                               WHERE chain=%s
                                 AND uid=%s
                                 AND to_state IS NOT NULL""",
                           (chain.id, user.id))

        else:
            # Otherwise insert a new row into the commentchainchanges table.
            cursor.execute("""INSERT INTO commentchainchanges (review, uid, chain, from_state, to_state, from_last_commit, to_last_commit)
                              VALUES (%s, %s, %s, %s, %s, %s, %s)""",
                           (review.id, user.id, chain.id, old_state, new_state, old_last_commit, new_last_commit))

        db.commit()

        return OperationResult(old_state=old_state, new_state=new_state,
                               draft_status=review.getDraftStatus(db, user))

class ReopenResolvedCommentChain(SetCommentChainState):
    def __init__(self):
        SetCommentChainState.__init__(self, { "chain_id": int })

    def process(self, db, user, chain_id):
        return self.setChainState(db, user, CommentChain.fromId(db, chain_id, user), "closed", "open")

class ReopenAddressedCommentChain(SetCommentChainState):
    def __init__(self):
        SetCommentChainState.__init__(self, { "chain_id": int,
                                              "commit_id": int,
                                              "sha1": str,
                                              "offset": int,
                                              "count": int })

    def process(self, db, user, chain_id, commit_id, sha1, offset, count):
        chain = CommentChain.fromId(db, chain_id, user)
        existing = chain.lines_by_sha1.get(sha1)

        if chain.state != "addressed":
            raise OperationFailure(code="invalidoperation",
                                   title="Invalid operation",
                                   message="The comment chain is not marked as addressed!")

        if not existing:
            assert commit_id == chain.addressed_by.getId(db)

            chain.review.branch.loadCommits(db)

            commits = chain.review.getCommitSet(db).without(chain.addressed_by.parents)

            propagation = propagate.Propagation(db)
            propagation.setExisting(chain.review, chain.id, chain.addressed_by, chain.file_id, offset, offset + count - 1, True)
            propagation.calculateAdditionalLines(commits, chain.review.branch.head)

            commentchainlines_values = []

            for file_sha1, (first_line, last_line) in propagation.new_lines.items():
                commentchainlines_values.append((chain.id, user.id, file_sha1, first_line, last_line))

            cursor = db.cursor()
            cursor.executemany("""INSERT INTO commentchainlines (chain, uid, sha1, first_line, last_line)
                                  VALUES (%s, %s, %s, %s, %s)""",
                               commentchainlines_values)

            if not propagation.active:
                old_addressed_by_id = chain.addressed_by.getId(db)
                new_addressed_by_id = propagation.addressed_by[0].child.getId(db)

                if chain.addressed_by_is_draft:
                    cursor.execute("""UPDATE commentchainchanges
                                         SET to_addressed_by=%s
                                       WHERE chain=%s
                                         AND uid=%s
                                         AND state='draft'
                                         AND to_addressed_by=%s""",
                                   (new_addressed_by_id, chain.id, user.id, old_addressed_by_id))
                else:
                    cursor.execute("""INSERT INTO commentchainchanges (review, uid, chain, from_addressed_by, to_addressed_by)
                                      VALUES (%s, %s, %s, %s, %s)""",
                                   (chain.review.id, user.id, chain.id, old_addressed_by_id, new_addressed_by_id))

                old_last_commit_id = chain.last_commit.getId(db)
                new_last_commit_id = chain.addressed_by.getId(db)

                if chain.last_commit_is_draft:
                    cursor.execute("""UPDATE commentchainchanges
                                         SET to_last_commit=%s
                                       WHERE chain=%s
                                         AND uid=%s
                                         AND state='draft'
                                         AND to_last_commit=%s""",
                                   (new_last_commit_id, chain.id, user.id, old_last_commit_id))
                else:
                    cursor.execute("""INSERT INTO commentchainchanges (review, uid, chain, from_last_commit, to_last_commit)
                                      VALUES (%s, %s, %s, %s, %s)""",
                                   (chain.review.id, user.id, chain.id, old_last_commit_id, new_last_commit_id))

                db.commit()

                return OperationResult(old_state='addressed', new_state='addressed',
                                       draft_status=chain.review.getDraftStatus(db, user))
        elif offset != existing[0] or count != existing[1]:
            raise OperationFailure(code="invalidoperation",
                                   title="Invalid operation",
                                   message="The comment chain is already present at other lines in same file version")

        return self.setChainState(db, user, chain, "addressed", "open", new_last_commit=commit_id)

class ResolveCommentChain(SetCommentChainState):
    def __init__(self):
        Operation.__init__(self, { "chain_id": int })

    def process(self, db, user, chain_id):
        return self.setChainState(db, user, CommentChain.fromId(db, chain_id, user), "open", "closed")

class MorphCommentChain(Operation):
    def __init__(self):
        Operation.__init__(self, { "chain_id": int,
                                   "new_type": set(["issue", "note"]) })

    def process(self, db, user, chain_id, new_type):
        chain = CommentChain.fromId(db, chain_id, user)
        review = chain.review

        if chain.type == new_type:
            raise OperationError("the comment chain's type is already '%s'" % new_type)
        elif new_type == "note" and chain.state in ("closed", "addressed"):
            raise OperationError("can't convert resolved or addressed issue to a note")

        cursor = db.cursor()

        if chain.state == "draft":
            # The chain is still a draft; just change its type directly.
            cursor.execute("""UPDATE commentchains
                                 SET type=%s
                               WHERE id=%s""",
                           (new_type, chain.id))

        elif chain.type_is_draft:
            # The user is reverting a draft chain type change; just undo the
            # draft change.
            cursor.execute("""DELETE FROM commentchainchanges
                               WHERE chain=%s
                                 AND uid=%s
                                 AND to_type IS NOT NULL""",
                           (chain.id, user.id))

        else:
            # Otherwise insert a new row into the commentchainchanges table.
            cursor.execute("""INSERT INTO commentchainchanges (review, uid, chain, from_type, to_type)
                              VALUES (%s, %s, %s, %s, %s)""",
                           (review.id, user.id, chain.id, chain.type, new_type))

        db.commit()

        return OperationResult(draft_status=review.getDraftStatus(db, user))

class UpdateComment(Operation):
    def __init__(self):
        Operation.__init__(self, { "comment_id": int,
                                   "new_text": str })

    def process(self, db, user, comment_id, new_text):
        comment = Comment.fromId(db, comment_id, user)

        if user != comment.user:
            raise OperationError("can't edit comment written by another user")
        if comment.state != "draft":
            raise OperationError("can't edit comment that has been submitted")
        if not new_text.strip():
            raise OperationError("empty comment")

        cursor = db.cursor()
        cursor.execute("""UPDATE comments
                             SET comment=%s, time=now()
                           WHERE id=%s""",
                       (new_text, comment.id))

        db.commit()

        return OperationResult(draft_status=comment.chain.review.getDraftStatus(db, user))

class DeleteComment(Operation):
    def __init__(self):
        Operation.__init__(self, { "comment_id": int })

    def process(self, db, user, comment_id):
        comment = Comment.fromId(db, comment_id, user)

        if user != comment.user:
            raise OperationError("can't delete comment written by another user")
        if comment.state != "draft":
            raise OperationError("can't delete comment that has been submitted")

        cursor = db.cursor()
        cursor.execute("""UPDATE comments
                             SET state='deleted'
                           WHERE id=%s""",
                       (comment.id,))

        if comment.chain.state == "draft":
            # If the comment chain was a draft, then delete it as well.
            cursor.execute("""UPDATE commentchains
                                 SET state='empty'
                               WHERE id=%s""",
                           (comment.chain.id,))

        db.commit()

        return OperationResult(draft_status=comment.chain.review.getDraftStatus(db, user))

class MarkChainsAsRead(Operation):
    def __init__(self):
        Operation.__init__(self, { "chain_ids": Optional([int]),
                                   "review_ids": Optional([int]) })

    def process(self, db, user, chain_ids=None, review_ids=None):
        cursor = db.cursor()

        if chain_ids:
            cursor.execute("""DELETE FROM commentstoread
                                    USING comments
                                    WHERE commentstoread.uid=%s
                                      AND commentstoread.comment=comments.id
                                      AND comments.chain=ANY (%s)""",
                           (user.id, chain_ids))

        if review_ids:
            cursor.execute("""DELETE FROM commentstoread
                                    USING comments, commentchains
                                    WHERE commentstoread.uid=%s
                                      AND commentstoread.comment=comments.id
                                      AND comments.chain=commentchains.id
                                      AND commentchains.review=ANY (%s)""",
                           (user.id, review_ids))

        db.commit()

        return OperationResult()

########NEW FILE########
__FILENAME__ = manipulatefilters
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2012 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import dbutils
import gitutils
import mailutils
import htmlutils
import reviewing.utils
import reviewing.filters

from operation import Operation, OperationResult, OperationError, \
    OperationFailure, OperationFailureMustLogin, Optional

class AddFilter(Operation):
    def __init__(self):
        Operation.__init__(self, { "filter_type": set(["reviewer", "watcher", "ignored"]),
                                   "path": str,
                                   "delegates": [str],
                                   "repository_id": Optional(int),
                                   "repository_name": Optional(str),
                                   "replaced_filter_id": Optional(int) })

    def process(self, db, user, filter_type, path, delegates, repository_id=None, repository_name=None, replaced_filter_id=None):
        path = reviewing.filters.sanitizePath(path)

        if "*" in path:
            try:
                reviewing.filters.validatePattern(path)
            except reviewing.filters.PatternError as error:
                raise OperationFailure(code="invalidpattern",
                                       title="Invalid path pattern",
                                       message="There are invalid wild-cards in the path: %s" % error.message)

        if filter_type == "reviewer":
            delegates = filter(None, delegates)
            invalid_delegates = []
            for delegate in delegates:
                try:
                    dbutils.User.fromName(db, delegate)
                except dbutils.NoSuchUser:
                    invalid_delegates.append(delegate)
            if invalid_delegates:
                raise OperationFailure(code="invaliduser",
                                       title="Invalid delegate(s)",
                                       message="These user-names are not valid: %s" % ", ".join(invalid_delegates))
        else:
            delegates = []

        cursor = db.cursor()

        if repository_id is None:
            cursor.execute("""SELECT id
                                FROM repositories
                               WHERE name=%s""",
                           (repository_name,))
            repository_id = cursor.fetchone()[0]

        if replaced_filter_id is not None:
            cursor.execute("""SELECT 1
                                FROM filters
                               WHERE id=%s
                                 AND uid=%s""",
                           (replaced_filter_id, user.id))

            if not cursor.fetchone():
                raise OperationFailure(code="invalidoperation",
                                       title="Invalid operation",
                                       message="Filter to replace does not exist or belongs to another user!")

            cursor.execute("""DELETE
                                FROM filters
                               WHERE id=%s""",
                           (replaced_filter_id,))

        cursor.execute("""SELECT 1
                            FROM filters
                           WHERE uid=%s
                             AND repository=%s
                             AND path=%s""",
                       (user.id, repository_id, path))

        if cursor.fetchone():
            raise OperationFailure(code="duplicatefilter",
                                   title="Duplicate filter",
                                   message=("You already have a filter for the path <code>%s</code> in this repository."
                                            % htmlutils.htmlify(path)),
                                   is_html=True)

        cursor.execute("""INSERT INTO filters (uid, repository, path, type, delegate)
                               VALUES (%s, %s, %s, %s, %s)
                            RETURNING id""",
                       (user.id, repository_id, path, filter_type, ",".join(delegates)))

        filter_id = cursor.fetchone()[0]

        db.commit()

        return OperationResult(filter_id=filter_id)

class DeleteFilter(Operation):
    def __init__(self):
        Operation.__init__(self, { "filter_id": int })

    def process(self, db, user, filter_id):
        cursor = db.cursor()
        cursor.execute("""SELECT uid
                            FROM filters
                           WHERE id=%s""",
                       (filter_id,))

        row = cursor.fetchone()
        if row:
            if user.id != row[0] and not user.hasRole(db, "administrator"):
                raise OperationFailure(code="notallowed",
                                       title="Not allowed!",
                                       message="Operation not permitted.")

            cursor.execute("""DELETE
                                FROM filters
                               WHERE id=%s""",
                           (filter_id,))

            db.commit()

        return OperationResult()

class ReapplyFilters(Operation):
    def __init__(self):
        Operation.__init__(self, { "repository_id": Optional(int),
                                   "filter_id": Optional(int) })

    def process(self, db, user, repository_id=None, filter_id=None):
        if user.isAnonymous():
            return OperationFailureMustLogin()

        cursor = db.cursor()

        if filter_id is not None:
            cursor.execute("""SELECT repository, path, type, delegate
                                FROM filters
                               WHERE id=%s""",
                           (filter_id,))
            repository_id, filter_path, filter_type, filter_delegate = cursor.fetchone()

        if repository_id is None:
            cursor.execute("""SELECT reviews.id, applyfilters, applyparentfilters, branches.repository
                                FROM reviews
                                JOIN branches ON (reviews.branch=branches.id)
                               WHERE reviews.state!='closed'""")
        else:
            cursor.execute("""SELECT reviews.id, applyfilters, applyparentfilters, branches.repository
                                FROM reviews
                                JOIN branches ON (reviews.branch=branches.id)
                               WHERE reviews.state!='closed'
                                 AND branches.repository=%s""",
                           (repository_id,))

        repositories = {}

        # list(review_file_id)
        assign_changes = []

        # set(review_id)
        assigned_reviews = set()

        # set(review_id)
        watched_reviews = set()

        for review_id, applyfilters, applyparentfilters, repository_id in cursor.fetchall():
            if repository_id in repositories:
                repository = repositories[repository_id]
            else:
                repository = gitutils.Repository.fromId(db, repository_id)
                repositories[repository_id] = repository

            review = reviewing.filters.Filters.Review(review_id, applyfilters, applyparentfilters, repository)
            filters = reviewing.filters.Filters()

            filters.setFiles(db, review=review)

            if filter_id is not None:
                filters.addFilter(user.id, filter_path, filter_type, filter_delegate, filter_id)
            else:
                filters.load(db, review=review, user=user)

            cursor.execute("""SELECT commits.id, reviewfiles.file, reviewfiles.id
                                FROM commits
                                JOIN gitusers ON (gitusers.id=commits.author_gituser)
                     LEFT OUTER JOIN usergitemails ON (usergitemails.email=gitusers.email
                                                   AND usergitemails.uid=%s)
                                JOIN changesets ON (changesets.child=commits.id)
                                JOIN reviewfiles ON (reviewfiles.changeset=changesets.id)
                     LEFT OUTER JOIN reviewuserfiles ON (reviewuserfiles.file=reviewfiles.id
                                                     AND reviewuserfiles.uid=%s)
                               WHERE reviewfiles.review=%s
                                 AND usergitemails.uid IS NULL
                                 AND reviewuserfiles.uid IS NULL""",
                            (user.id, user.id, review_id))

            for commit_id, file_id, review_file_id in cursor.fetchall():
                association = filters.getUserFileAssociation(user.id, file_id)

                if association == 'reviewer':
                    assign_changes.append(review_file_id)
                    assigned_reviews.add(review_id)
                elif association == 'watcher':
                    watched_reviews.add(review_id)

        cursor.execute("""SELECT reviews.id
                            FROM reviews
                 LEFT OUTER JOIN reviewusers ON (reviewusers.review=reviews.id
                                             AND reviewusers.uid=%s)
                           WHERE reviews.id=ANY (%s)
                             AND reviewusers.uid IS NULL""",
                       (user.id, list(assigned_reviews) + list(watched_reviews)))

        new_reviews = set(review_id for (review_id,) in cursor)

        cursor.executemany("""INSERT INTO reviewusers (review, uid)
                                   VALUES (%s, %s)""",
                           [(review_id, user.id) for review_id in new_reviews])

        cursor.executemany("""INSERT INTO reviewuserfiles (file, uid)
                                   VALUES (%s, %s)""",
                           [(review_file_id, user.id) for review_file_id in assign_changes])

        db.commit()

        watched_reviews &= new_reviews
        watched_reviews -= assigned_reviews

        cursor.execute("""SELECT id, summary
                            FROM reviews
                           WHERE id=ANY (%s)""",
                       (list(assigned_reviews | watched_reviews),))

        return OperationResult(assigned_reviews=sorted(assigned_reviews),
                               watched_reviews=sorted(watched_reviews),
                               summaries=dict(cursor))

class CountMatchedPaths(Operation):
    def __init__(self):
        Operation.__init__(self, { "single": Optional({ "repository_name": str,
                                                        "path": str }),
                                   "multiple": Optional([int]),
                                   "user_id": Optional(int) })

    def process(self, db, user, single=None, multiple=None, user_id=None):
        if user_id is None:
            user_id = user.id

        try:
            if single:
                repository = gitutils.Repository.fromName(db, single["repository_name"])
                path = reviewing.filters.sanitizePath(single["path"])

                cursor = db.cursor()
                cursor.execute("""SELECT path
                                    FROM filters
                                   WHERE repository=%s
                                     AND uid=%s""",
                               (repository.id, user_id,))

                paths = set(filter_path for (filter_path,) in cursor)
                paths.add(path)

                return OperationResult(count=reviewing.filters.countMatchedFiles(repository, list(paths))[path])

            cursor = db.cursor()
            cursor.execute("""SELECT repository, id, path
                                FROM filters
                               WHERE id=ANY (%s)
                            ORDER BY repository""",
                           (multiple,))

            per_repository = {}
            result = []

            for repository_id, filter_id, filter_path in cursor:
                per_repository.setdefault(repository_id, []).append((filter_id, filter_path))

            for repository_id, filters in per_repository.items():
                repository = gitutils.Repository.fromId(db, repository_id)
                counts = reviewing.filters.countMatchedFiles(
                    repository, [filter_path for (filter_id, filter_path) in filters])
                for filter_id, filter_path in filters:
                    result.append({ "id": filter_id,
                                    "count": counts[filter_path] })

            return OperationResult(filters=result)
        except reviewing.filters.PatternError as error:
            return OperationFailure(code="invalidpattern",
                                    title="Invalid pattern!",
                                    message=str(error))

class GetMatchedPaths(Operation):
    def __init__(self):
        Operation.__init__(self, { "repository_name": str,
                                   "path": str,
                                   "user_id": Optional(int) })

    def process(self, db, user, repository_name, path, user_id=None):
        if user_id is None:
            user_id = user.id

        repository = gitutils.Repository.fromName(db, repository_name)
        path = reviewing.filters.sanitizePath(path)

        cursor = db.cursor()
        cursor.execute("""SELECT path
                            FROM filters
                           WHERE repository=%s
                             AND uid=%s""",
                       (repository.id, user_id,))

        paths = set(filter_path for (filter_path,) in cursor)
        paths.add(path)

        return OperationResult(paths=reviewing.filters.getMatchedFiles(repository, list(paths))[path])

class AddReviewFilters(Operation):
    def __init__(self):
        Operation.__init__(self, { "review_id": int,
                                   "filters": [{ "type": set(["reviewer", "watcher"]),
                                                 "user_names": Optional([str]),
                                                 "user_ids": Optional([int]),
                                                 "paths": Optional([str]),
                                                 "file_ids": Optional([int]) }] })

    def process(self, db, creator, review_id, filters):
        review = dbutils.Review.fromId(db, review_id)
        by_user = {}

        for filter in filters:
            if "user_ids" in filter:
                user_ids = set(filter["user_ids"])
            else:
                user_ids = set([])

            if "user_names" in filter:
                for user_name in filter["user_names"]:
                    user_ids.add(dbutils.User.fromName(db, user_name).id)

            if "paths" in filter:
                paths = set(reviewing.filters.sanitizePath(path) for path in filter["paths"])

                for path in paths:
                    try:
                        reviewing.filters.validatePattern(path)
                    except reviewing.filters.PatternError as error:
                        raise OperationFailure(
                            code="invalidpattern",
                            title="Invalid path pattern",
                            message="There are invalid wild-cards in the path: %s" % error.message)
            else:
                paths = set()

            if "file_ids" in filter:
                for file_id in filter["file_ids"]:
                    paths.add(dbutils.describe_file(file_id))

            for user_id in user_ids:
                reviewer_paths, watcher_paths = by_user.setdefault(user_id, (set(), set()))

                if filter["type"] == "reviewer":
                    reviewer_paths |= paths
                else:
                    watcher_paths |= paths

        pending_mails = []

        for user_id, (reviewer_paths, watcher_paths) in by_user.items():
            try:
                user = dbutils.User.fromId(db, user_id)
            except dbutils.InvalidUserId:
                raise OperationFailure(
                    code="invaliduserid",
                    title="Invalid user ID",
                    message="At least one of the specified user IDs was invalid.")
            pending_mails.extend(reviewing.utils.addReviewFilters(
                    db, creator, user, review, reviewer_paths, watcher_paths))

        review = dbutils.Review.fromId(db, review_id)
        review.incrementSerial(db)

        db.commit()

        mailutils.sendPendingMails(pending_mails)

        return OperationResult()

class RemoveReviewFilter(Operation):
    def __init__(self):
        Operation.__init__(self, { "filter_id": int })

    def process(self, db, user, filter_id):
        cursor = db.cursor()

        cursor.execute("SELECT review FROM reviewfilters WHERE id=%s", (filter_id,))
        review_id = cursor.fetchone()
        if not review_id:
            raise OperationFailure(
                code="nosuchfilter",
                title="No such filter!",
                message=("Maybe the filter has been deleted since you "
                         "loaded this page?"))

        cursor.execute("DELETE FROM reviewfilters WHERE id=%s", (filter_id,))

        review = dbutils.Review.fromId(db, review_id)
        review.incrementSerial(db)

        db.commit()

        return OperationResult()

########NEW FILE########
__FILENAME__ = manipulatereview
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2012 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import dbutils
import gitutils

import reviewing.mail as review_mail
import mailutils

from operation import Operation, OperationResult, OperationError, Optional

class CloseReview(Operation):
    def __init__(self):
        Operation.__init__(self, { "review_id": int })

    def process(self, db, user, review_id):
        review = dbutils.Review.fromId(db, review_id)

        if review.state != "open":
            raise OperationError("review not open; can't close")
        if not review.accepted(db):
            raise OperationError("review is not accepted; can't close")

        review.close(db, user)
        review.disableTracking(db)

        db.commit()

        return OperationResult()

class DropReview(Operation):
    def __init__(self):
        Operation.__init__(self, { "review_id": int })

    def process(self, db, user, review_id):
        review = dbutils.Review.fromId(db, review_id)

        if review.state != "open":
            raise OperationError("review not open; can't drop")

        review.drop(db, user)
        review.disableTracking(db)

        db.commit()

        return OperationResult()

class ReopenReview(Operation):
    def __init__(self):
        Operation.__init__(self, { "review_id": int })

    def process(self, db, user, review_id):
        review = dbutils.Review.fromId(db, review_id)

        if review.state == "open":
            raise OperationError("review already open; can't reopen")

        review.reopen(db, user)

        db.commit()

        return OperationResult()

class PingReview(Operation):
    def __init__(self):
        Operation.__init__(self, { "review_id": int,
                                   "note": str })

    def process(self, db, user, review_id, note):
        review = dbutils.Review.fromId(db, review_id)

        cursor = db.cursor()
        cursor.execute("""SELECT DISTINCT uid
                            FROM reviewuserfiles
                            JOIN reviewfiles ON (reviewfiles.id=reviewuserfiles.file)
                            JOIN users ON (users.id=reviewuserfiles.uid)
                           WHERE reviewfiles.review=%s
                             AND reviewfiles.state='pending'
                             AND users.status!='retired'""",
                       (review.id,))

        user_ids = set([user_id for (user_id,) in cursor.fetchall()])

        # Add the pinging user and the owners (they are usually the same.)
        user_ids.add(user.id)

        for owner in review.owners: user_ids.add(owner.id)

        recipients = [dbutils.User.fromId(db, user_id) for user_id in user_ids]

        pending_mails = []
        for recipient in recipients:
            pending_mails.extend(review_mail.sendPing(db, user, recipient, recipients, review, note))
        mailutils.sendPendingMails(pending_mails)

        return OperationResult()

class UpdateReview(Operation):
    def __init__(self):
        Operation.__init__(self, { "review_id": int,
                                   "new_summary": Optional(str),
                                   "new_description": Optional(str),
                                   "new_owners": Optional([str]) })

    def process(self, db, user, review_id, new_summary=None, new_description=None, new_owners=None):
        review = dbutils.Review.fromId(db, review_id)

        if new_summary is not None:
            if not new_summary:
                raise OperationError("invalid new summary")
            review.setSummary(db, new_summary)

        if new_description is not None:
            review.setDescription(db, new_description if new_description else None)

        if new_owners is not None:
            remove_owners = set(review.owners)
            for user_name in new_owners:
                owner = dbutils.User.fromName(db, user_name)
                if owner in remove_owners: remove_owners.remove(owner)
                else: review.addOwner(db, owner)
            for owner in remove_owners:
                review.removeOwner(db, owner)

        review = dbutils.Review.fromId(db, review_id)
        review.incrementSerial(db)

        db.commit()

        return OperationResult()

########NEW FILE########
__FILENAME__ = manipulateuser
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2012 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import re
import base64

import dbutils
import gitutils
import auth
import mailutils
import textutils
import configuration

from operation import (Operation, OperationResult, OperationError,
                       OperationFailure, Optional, User)

class SetFullname(Operation):
    def __init__(self):
        Operation.__init__(self, { "user_id": int,
                                   "value": str })

    def process(self, db, user, user_id, value):
        if user.id != user_id:
            Operation.requireRole(db, "administrator", user)

        if not value.strip():
            raise OperationError("empty display name is not allowed")

        db.cursor().execute("UPDATE users SET fullname=%s WHERE id=%s", (value.strip(), user_id))
        db.commit()

        return OperationResult()

class SetGitEmails(Operation):
    def __init__(self):
        Operation.__init__(self, { "subject": User,
                                   "value": [str] })

    def process(self, db, user, subject, value):
        if user != subject:
            Operation.requireRole(db, "administrator", user)

        for address in value:
            if not address.strip():
                raise OperationError("empty email address is not allowed")
            if address.count("@") != 1:
                raise OperationError("invalid email address")

        cursor = db.cursor()
        cursor.execute("SELECT email FROM usergitemails WHERE uid=%s", (subject.id,))

        current_addresses = set(address for (address,) in cursor)
        new_addresses = set(address.strip() for address in value)

        for address in (current_addresses - new_addresses):
            cursor.execute("DELETE FROM usergitemails WHERE uid=%s AND email=%s",
                           (subject.id, address))
        for address in (new_addresses - current_addresses):
            cursor.execute("INSERT INTO usergitemails (uid, email) VALUES (%s, %s)",
                           (subject.id, address))

        db.commit()

        return OperationResult()

class ChangePassword(Operation):
    def __init__(self):
        Operation.__init__(self, { "subject": Optional(User),
                                   "current_pw": Optional(str),
                                   "new_pw": str })

    def process(self, db, user, new_pw, subject=None, current_pw=None):
        if subject is None:
            subject = user

        cursor = db.cursor()

        if user != subject:
            Operation.requireRole(db, "administrator", user)
        elif current_pw is None:
            cursor.execute("SELECT password FROM users WHERE id=%s", (subject.id,))
            if cursor.fetchone()[0] is not None:
                # This is mostly a sanity check; the only way to trigger this is
                # if the user has no password when he loads /home, sets a
                # password in another tab or using another browser, and then
                # tries to set (rather than change) the password using the old
                # stale /home.
                raise OperationFailure(code="wrongpassword",
                                       title="Wrong password!",
                                       message="No current password provided.")

        if current_pw is not None:
            try: auth.checkPassword(db, subject.name, current_pw)
            except auth.WrongPassword:
                raise OperationFailure(code="wrongpassword",
                                       title="Wrong password!",
                                       message="The provided current password is not correct.")

        if not new_pw:
            raise OperationFailure(code="emptypassword",
                                   title="Empty password!",
                                   message="Setting an empty password is not allowed.")

        cursor.execute("UPDATE users SET password=%s WHERE id=%s",
                       (auth.hashPassword(new_pw), subject.id))

        db.commit()

        return OperationResult()

    def sanitize(self, value):
        sanitized = value.copy()
        if "current_pw" in value:
            sanitized["current_pw"] = "****"
        sanitized["new_pw"] = "****"
        return sanitized

def checkEmailAddressSyntax(address):
    return bool(re.match(r"[^@]+@[^.]+(?:\.[^.]+)*$", address))

def sendVerificationMail(db, user, email_id=None):
    cursor = db.cursor()

    if email_id is None:
        cursor.execute("""SELECT email
                            FROM users
                           WHERE id=%s""",
                       (user.id,))

        email_id, = cursor.fetchone()

    cursor.execute("""SELECT email, verification_token
                        FROM useremails
                       WHERE id=%s""",
                   (email_id,))

    email, verification_token = cursor.fetchone()

    if verification_token is None:
        verification_token = auth.getToken(encode=base64.b16encode)

        cursor.execute("""UPDATE useremails
                             SET verification_token=%s
                           WHERE id=%s""",
                       (verification_token, email_id))

    if configuration.base.ACCESS_SCHEME == "http":
        protocol = "http"
    else:
        protocol = "https"

    administrators = dbutils.getAdministratorContacts(db, indent=2)

    if administrators:
        administrators = ":\n\n%s" % administrators
    else:
        administrators = "."

    recipients = [mailutils.User(user.name, email, user.fullname)]
    subject = "[Critic] Please verify your email: %s" % email
    body = textutils.reflow("""
This is a message from the Critic code review system at %(hostname)s.  The user
'%(username)s' on this system has added this email address to his/her account.
If this is you, please confirm this by following this link:

  %(url_prefix)s/verifyemail?email=%(email)s&token=%(verification_token)s

If this is not you, you can safely ignore this email.  If you wish to report
abuse, please contact the Critic system's administrators%(administrators)s
""" % { "hostname": configuration.base.HOSTNAME,
        "username": user.name,
        "email": email,
        "url_prefix": "%s://%s" % (protocol, configuration.base.HOSTNAME),
        "verification_token": verification_token,
        "administrators": administrators })

    mailutils.sendMessage(recipients, subject, body)

class RequestVerificationEmail(Operation):
    def __init__(self):
        Operation.__init__(self, { "email_id": int })

    def process(self, db, user, email_id):
        cursor = db.cursor()
        cursor.execute("""SELECT uid, email, verified
                            FROM useremails
                           WHERE id=%s""",
                       (email_id,))

        row = cursor.fetchone()

        if not row:
            raise OperationFailure(
                code="invalidemailid",
                title="No such email address",
                message="The address might have been deleted already.")

        user_id, email, verified = row

        if verified is True:
            raise OperationFailure(
                code="alreadyverified",
                title="Address already verified",
                message="This address has already been verified.")

        if user != user_id:
            Operation.requireRole(db, "administrator", user)
            user = dbutils.User.fromId(db, user_id)

        sendVerificationMail(db, user, email_id)

        db.commit()

        return OperationResult()

class DeleteEmailAddress(Operation):
    def __init__(self):
        Operation.__init__(self, { "email_id": int })

    def process(self, db, user, email_id):
        cursor = db.cursor()
        cursor.execute("""SELECT uid
                            FROM useremails
                           WHERE id=%s""",
                       (email_id,))

        row = cursor.fetchone()

        if not row:
            raise OperationFailure(
                code="invalidemailid",
                title="No such email address",
                message="The address might have been deleted already.")

        subject_id, = row

        if user != subject_id:
            Operation.requireRole(db, "administrator", user)

        cursor.execute("""SELECT useremails.id, users.email IS NOT NULL
                            FROM useremails
                 LEFT OUTER JOIN users ON (users.email=useremails.id)
                           WHERE useremails.uid=%s""",
                       (subject_id,))

        emails = dict(cursor)

        # Reject if the user has more than one email address registered and is
        # trying to delete the selected one.  The UI checks this too, but that
        # check is not 100 % reliable since it checks the state at the time the
        # page was loaded, not necessarily the current state.
        if len(emails) > 1 and emails[email_id]:
            raise OperationFailure(
                code="notallowed",
                title="Will not delete current address",
                message=("This email address is your current address.  Please "
                         "select one of the other addresses as your current "
                         "address before deleting it."))

        cursor.execute("""UPDATE users
                             SET email=NULL
                           WHERE id=%s
                             AND email=%s""",
                       (subject_id, email_id))

        cursor.execute("""DELETE FROM useremails
                                WHERE id=%s""",
                       (email_id,))

        db.commit()

        return OperationResult()

class SelectEmailAddress(Operation):
    def __init__(self):
        Operation.__init__(self, { "email_id": int })

    def process(self, db, user, email_id):
        cursor = db.cursor()
        cursor.execute("""SELECT uid
                            FROM useremails
                           WHERE id=%s""",
                       (email_id,))

        row = cursor.fetchone()

        if not row:
            raise OperationFailure(
                code="invalidemailid",
                title="No such email address",
                message="The address might have been deleted already.")

        user_id, = row

        if user != user_id:
            Operation.requireRole(db, "administrator", user)

        cursor.execute("""UPDATE users
                             SET email=%s
                           WHERE id=%s""",
                       (email_id, user_id))

        db.commit()

        return OperationResult()

class AddEmailAddress(Operation):
    def __init__(self):
        Operation.__init__(self, { "subject": User,
                                   "email": str })

    def process(self, db, user, subject, email):
        if not checkEmailAddressSyntax(email):
            raise OperationFailure(
                code="invalidemail",
                title="Invalid email address",
                message="Please provide an address on the form <user>@<host>!")

        if user != subject:
            Operation.requireRole(db, "administrator", user)

        cursor = db.cursor()
        cursor.execute("""SELECT 1
                            FROM useremails
                           WHERE uid=%s
                             AND email=%s""",
                       (subject.id, email))

        if cursor.fetchone():
            raise OperationFailure(
                code="invalidemail",
                title="Duplicate email address",
                message="The exact same address is already registered!")

        if user.hasRole(db, "administrator"):
            verified = None
        elif configuration.base.VERIFY_EMAIL_ADDRESSES:
            verified = False
        else:
            verified = None

        cursor.execute("""INSERT INTO useremails (uid, email, verified)
                               VALUES (%s, %s, %s)
                            RETURNING id""",
                       (subject.id, email, verified))

        email_id, = cursor.fetchone()

        if verified is False:
            sendVerificationMail(db, subject, email_id)

        if subject.email is None:
            cursor.execute("""UPDATE users
                                 SET email=%s
                               WHERE id=%s""",
                           (email_id, subject.id))

        db.commit()

        return OperationResult()

########NEW FILE########
__FILENAME__ = markfiles
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2012 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import dbutils

from operation import Operation, OperationResult

class MarkFiles(Operation):
    def __init__(self):
        Operation.__init__(self, { "review_id": int,
                                   "reviewed": bool,
                                   "changeset_ids": [int],
                                   "file_ids": [int] })

    def process(req, db, user, review_id, reviewed, changeset_ids, file_ids):
        review = dbutils.Review.fromId(db, review_id)

        cursor = db.cursor()

        # Revert any draft changes the user has for the specified files in
        # the specified changesets.
        cursor.execute("""DELETE FROM reviewfilechanges
                                USING reviewfiles
                                WHERE reviewfilechanges.uid=%s
                                  AND reviewfilechanges.state='draft'
                                  AND reviewfilechanges.file=reviewfiles.id
                                  AND reviewfiles.review=%s
                                  AND reviewfiles.changeset=ANY (%s)
                                  AND reviewfiles.file=ANY (%s)""",
                       (user.id, review.id, changeset_ids, file_ids))

        if reviewed:
            from_state, to_state = 'pending', 'reviewed'
        else:
            from_state, to_state = 'reviewed', 'pending'

        # Insert draft changes for every file whose state would be updated.
        cursor.execute("""INSERT INTO reviewfilechanges (file, uid, "from", "to")
                               SELECT reviewfiles.id, reviewuserfiles.uid, reviewfiles.state, %s
                                 FROM reviewfiles
                                 JOIN reviewuserfiles ON (reviewuserfiles.file=reviewfiles.id AND reviewuserfiles.uid=%s)
                                WHERE reviewfiles.review=%s
                                  AND reviewfiles.state=%s
                                  AND reviewfiles.changeset=ANY (%s)
                                  AND reviewfiles.file=ANY (%s)""",
                       (to_state, user.id, review.id, from_state, changeset_ids, file_ids))

        db.commit()

        return OperationResult(draft_status=review.getDraftStatus(db, user))

########NEW FILE########
__FILENAME__ = news
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2012 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

from operation import Operation, OperationResult

class AddNewsItem(Operation):
    """Add news item."""

    def __init__(self):
        Operation.__init__(self, { "text": str })

    def process(self, db, user, text):
        Operation.requireRole(db, "newswriter", user)

        cursor = db.cursor()
        cursor.execute("INSERT INTO newsitems (text) VALUES (%s) RETURNING id", (text,))
        item_id = cursor.fetchone()[0]
        db.commit()

        return OperationResult(item_id=item_id)

class EditNewsItem(Operation):
    """Add news item."""

    def __init__(self):
        Operation.__init__(self, { "item_id": int,
                                   "text": str })

    def process(self, db, user, item_id, text):
        Operation.requireRole(db, "newswriter", user)

        db.cursor().execute("UPDATE newsitems SET text=%s WHERE id=%s", (text, item_id))
        db.commit()

        return OperationResult()

########NEW FILE########
__FILENAME__ = rebasereview
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2012 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import dbutils
import gitutils
import log.commitset

from operation import (Operation, OperationResult, OperationError, Optional,
                       Review)

def doPrepareRebase(db, user, review, new_upstream_arg=None, branch=None):
    commitset = log.commitset.CommitSet(review.branch.commits)
    tails = commitset.getFilteredTails(review.branch.repository)

    cursor = db.cursor()

    cursor.execute("SELECT uid FROM reviewrebases WHERE review=%s AND new_head IS NULL", (review.id,))
    row = cursor.fetchone()
    if row:
        rebaser = dbutils.User.fromId(db, row[0])
        raise OperationError("The review is already being rebased by %s <%s>." % (rebaser.fullname, rebaser.email))

    head = commitset.getHeads().pop()
    head_id = head.getId(db)

    if new_upstream_arg is not None:
        if len(tails) > 1:
            raise OperationError("Rebase to new upstream commit not supported.")

        tail = gitutils.Commit.fromSHA1(db, review.branch.repository, tails.pop())

        old_upstream_id = tail.getId(db)
        if new_upstream_arg == "0" * 40:
            new_upstream_id = None
        else:
            if not gitutils.re_sha1.match(new_upstream_arg):
                cursor.execute("SELECT sha1 FROM tags WHERE repository=%s AND name=%s", (review.branch.repository.id, new_upstream_arg))
                row = cursor.fetchone()
                if row: new_upstream_arg = row[0]
                else: raise OperationError("Specified new upstream is invalid.")

            try: new_upstream = gitutils.Commit.fromSHA1(db, review.branch.repository, new_upstream_arg)
            except: raise OperationError("The specified new upstream commit does not exist in Critic's repository.")

            new_upstream_id = new_upstream.getId(db)
    else:
        old_upstream_id = None
        new_upstream_id = None

    cursor.execute("""INSERT INTO reviewrebases (review, old_head, new_head, old_upstream, new_upstream, uid, branch)
                           VALUES (%s, %s, NULL, %s, %s, %s, %s)""",
                   (review.id, head_id, old_upstream_id, new_upstream_id, user.id, branch))

    review.incrementSerial(db)

    db.commit()

def doCancelRebase(db, user, review):
    review.incrementSerial(db)

    db.cursor().execute("DELETE FROM reviewrebases WHERE review=%s AND new_head IS NULL", (review.id,))
    db.commit()

class CheckRebase(Operation):
    def __init__(self):
        Operation.__init__(self, { "review_id": int })

    def process(self, db, user, review_id):
        review = dbutils.Review.fromId(db, review_id)
        tails = review.getFilteredTails()
        available = "both" if len(tails) == 1 else "inplace"

        return OperationResult(available=available)

class SuggestUpstreams(Operation):
    def __init__(self):
        Operation.__init__(self, { "review_id": int })

    def process(self, db, user, review_id):
        review = dbutils.Review.fromId(db, review_id)
        tails = review.getFilteredTails()

        if len(tails) > 1:
            raise OperationError("Multiple tail commits.")

        try:
            from customization.filtertags import getUpstreamPattern
        except ImportError:
            def getUpstreamTagPattern(review): pass

        tail = tails.pop()
        tags = review.branch.repository.run("tag", "-l", "--contains", tail, getUpstreamTagPattern(review) or "*").splitlines()

        cursor = db.cursor()
        upstreams = []

        for tag in tags:
            cursor.execute("SELECT sha1 FROM tags WHERE repository=%s AND name=%s", (review.branch.repository.id, tag))
            row = cursor.fetchone()
            if row and row[0] != tail:
                upstreams.append(tag)

        return OperationResult(upstreams=upstreams)

class PrepareRebase(Operation):
    def __init__(self):
        Operation.__init__(self, { "review": Review,
                                   "new_upstream": Optional(str),
                                   "branch": Optional(str) })

    def process(self, db, user, review, new_upstream=None, branch=None):
        doPrepareRebase(db, user, review, new_upstream, branch)
        return OperationResult()

class CancelRebase(Operation):
    def __init__(self):
        Operation.__init__(self, { "review_id": int })

    def process(self, db, user, review_id):
        review = dbutils.Review.fromId(db, review_id)
        doCancelRebase(db, user, review)
        return OperationResult()

class RebaseReview(Operation):
    def __init__(self):
        Operation.__init__(self, { "review_id": int,
                                   "new_head_sha1": str,
                                   "new_upstream_sha1": Optional(str),
                                   "branch": Optional(str),
                                   "new_trackedbranch": Optional(str) })

    def process(self, db, user, review_id, new_head_sha1, new_upstream_sha1=None, branch=None, new_trackedbranch=None):
        review = dbutils.Review.fromId(db, review_id)
        new_head = gitutils.Commit.fromSHA1(db, review.repository, new_head_sha1)

        cursor = db.cursor()

        if review.state == 'closed':
            cursor.execute("SELECT closed_by FROM reviews WHERE id=%s", (review.id,))
            closed_by = cursor.fetchone()[0]

            review.serial += 1
            cursor.execute("UPDATE reviews SET state='open', serial=%s, closed_by=NULL WHERE id=%s", (review.serial, review.id))
        else:
            closed_by = None

        trackedbranch = review.getTrackedBranch(db)
        if trackedbranch and not trackedbranch.disabled:
            cursor.execute("UPDATE trackedbranches SET disabled=TRUE WHERE id=%s", (trackedbranch.id,))

        commitset = log.commitset.CommitSet(review.branch.commits)
        tails = commitset.getFilteredTails(review.branch.repository)

        if len(tails) == 1 and tails.pop() == new_upstream_sha1:
            # This appears to be a history rewrite.
            new_upstream_sha1 = None

        doPrepareRebase(db, user, review, new_upstream_sha1, branch)

        try:
            review.repository.run("update-ref", "refs/commit/%s" % new_head.sha1, new_head.sha1)

            with review.repository.relaycopy("RebaseReview") as relay:
                relay.run("fetch", "origin", "refs/commit/%s" % new_head.sha1)
                relay.run("push", "--force", "origin",
                          "%s:refs/heads/%s" % (new_head.sha1, review.branch.name),
                          env={ "REMOTE_USER": user.name })

            if closed_by is not None:
                db.commit()
                state = review.getReviewState(db)
                if state.accepted:
                    review.serial += 1
                    cursor.execute("UPDATE reviews SET state='closed', serial=%s, closed_by=%s WHERE id=%s", (review.serial, closed_by, review.id))

            if trackedbranch and not trackedbranch.disabled:
                cursor.execute("UPDATE trackedbranches SET disabled=FALSE WHERE id=%s", (trackedbranch.id,))
            if new_trackedbranch:
                cursor.execute("UPDATE trackedbranches SET remote_name=%s WHERE id=%s", (new_trackedbranch, trackedbranch.id))

            db.commit()
        except:
            doCancelRebase(db, user, review)
            raise

        return OperationResult()

class RevertRebase(Operation):
    def __init__(self):
        Operation.__init__(self, { "review": Review,
                                   "rebase_id": int })

    def process(self, db, user, review, rebase_id):
        cursor = db.cursor()

        cursor.execute("SELECT old_head, new_head, new_upstream FROM reviewrebases WHERE id=%s", (rebase_id,))
        old_head_id, new_head_id, new_upstream_id = cursor.fetchone()

        cursor.execute("SELECT commit FROM previousreachable WHERE rebase=%s", (rebase_id,))
        reachable = [commit_id for (commit_id,) in cursor]

        if not reachable:
            # Fail if rebase was done before the 'previousreachable' table was
            # added, and we thus don't know what commits the branch contained
            # before the rebase.
            raise OperationError("Automatic revert not supported; rebase is pre-historic.")

        if review.branch.head.getId(db) != new_head_id:
            raise OperationError("Commits added to review after rebase; need to remove them first.")

        old_head = gitutils.Commit.fromId(db, review.repository, old_head_id)
        new_head = gitutils.Commit.fromId(db, review.repository, new_head_id)

        cursor.execute("DELETE FROM reachable WHERE branch=%s", (review.branch.id,))
        cursor.executemany("INSERT INTO reachable (branch, commit) VALUES (%s, %s)", [(review.branch.id, commit_id) for commit_id in reachable])

        if new_upstream_id:
            new_upstream = gitutils.Commit.fromId(db, review.repository, new_upstream_id)

            if len(old_head.parents) == 2 and old_head.parents[1] == new_upstream.sha1:
                # Equivalent merge commit was added; remove it too.

                # Reopen any issues marked as addressed by the merge commit.
                cursor.execute("""UPDATE commentchains
                                     SET state='open', addressed_by=NULL
                                   WHERE review=%s
                                     AND state='addressed'
                                     AND addressed_by=%s""",
                               (review.id, old_head_id))

                # Delete the review changesets (and, via cascade, all related
                # assignments.)
                cursor.execute("""DELETE FROM reviewchangesets
                                        USING changesets
                                        WHERE reviewchangesets.review=%s
                                          AND reviewchangesets.changeset=changesets.id
                                          AND changesets.child=%s""",
                               (review.id, old_head_id))

                old_head = gitutils.Commit.fromSHA1(db, review.repository, old_head.parents[0])
                old_head_id = old_head.getId(db)
            else:
                # Delete the review changesets (and, via cascade, all related
                # assignments.)
                cursor.execute("""DELETE FROM reviewchangesets
                                        USING changesets
                                        WHERE reviewchangesets.review=%s
                                          AND reviewchangesets.changeset=changesets.id
                                          AND changesets.child=%s
                                          AND changesets.type='conflicts'""",
                               (review.id, new_head_id))

        cursor.execute("UPDATE branches SET head=%s WHERE id=%s", (old_head_id, review.branch.id))
        cursor.execute("DELETE FROM reviewrebases WHERE id=%s", (rebase_id,))

        review.incrementSerial(db)
        db.commit()

        review.repository.run("update-ref", "refs/heads/%s" % review.branch.name, old_head.sha1, new_head.sha1)

        return OperationResult()

########NEW FILE########
__FILENAME__ = recipientfilter
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2012 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import dbutils

from operation import Operation, OperationResult

class AddRecipientFilter(Operation):
    def __init__(self):
        Operation.__init__(self, { "review_id": int,
                                   "user_id": int,
                                   "include": bool })

    def process(self, db, user, review_id, user_id, include):
        cursor = db.cursor()
        cursor.execute("SELECT include FROM reviewrecipientfilters WHERE review=%s AND uid=%s", (review_id, user_id))
        row = cursor.fetchone()

        if row:
            if row[0] != include:
                cursor.execute("UPDATE reviewrecipientfilters SET include=%s WHERE review=%s AND uid=%s", (include, review_id, user_id))
        else:
            cursor.execute("INSERT INTO reviewrecipientfilters (review, uid, include) VALUES (%s, %s, %s)", (review_id, user_id, include))

        review = dbutils.Review.fromId(db, review_id)
        review.incrementSerial(db)
        db.commit()

        return OperationResult()

########NEW FILE########
__FILENAME__ = registeruser
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2014 the Critic contributors, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import dbutils
import configuration
import auth

from operation import Operation, OperationResult, Optional, Request
from operation.manipulateuser import sendVerificationMail, checkEmailAddressSyntax

class RegisterUser(Operation):
    def __init__(self):
        super(RegisterUser, self).__init__(
            { "req": Request,
              "username": str,
              "fullname": str,
              "email": str,
              "password": Optional(str),
              "external": Optional({ "provider": set(auth.PROVIDERS.keys()),
                                     "account": str,
                                     "token": str }) },
            accept_anonymous_user=True)

    def process(self, db, user, req, username, fullname, email,
                password=None, external=None):
        cursor = db.cursor()

        if not fullname:
            fullname = username
        if not email:
            email = None
        if not password:
            # Empty password => disabled.
            password = None

        if external:
            provider_config = configuration.auth.PROVIDERS[external["provider"]]
            provider = auth.PROVIDERS[external["provider"]]

        # Check that user registration is actually enabled.  This would also
        # disable the UI for user registration, of course, but the UI could be
        # bypassed, so we should check here as well.
        if not configuration.base.ALLOW_USER_REGISTRATION:
            if not external or not provider_config["allow_user_registration"]:
                return OperationResult(
                    message="User registration is not enabled.")

        # Check that the user name is valid.
        try:
            auth.validateUserName(username)
        except auth.InvalidUserName as error:
            return OperationResult(
                message="<u>Invalid user name</u><br>" + str(error),
                focus="#newusername")

        # Check that the user name is not already taken.
        cursor.execute("SELECT 1 FROM users WHERE name=%s", (username,))
        if cursor.fetchone():
            return OperationResult(
                message="A user named '%s' already exists!" % username,
                focus="#newusername")

        # Check that the email address has some hope of being valid.
        if email and not checkEmailAddressSyntax(email):
            return OperationResult(
                message=("<u>Invalid email address</u><br>"
                         "Please provide an address on the form user@host!"),
                focus="#email")

        # Check that we have either a password or an external authentication
        # provider.  If we have neither, the user wouldn't be able to sign in.
        if password is None and external is None:
            return OperationResult(
                message="Empty password.",
                focus="#password1")

        if password:
            password = auth.hashPassword(password)

        verify_email_address = configuration.base.VERIFY_EMAIL_ADDRESSES

        if external:
            # Check that the external authentication token is valid.
            if not provider.validateToken(db, external["account"],
                                          external["token"]):
                return OperationResult(
                    message="Invalid external authentication state.")

            cursor.execute("""SELECT id, uid, email
                                FROM externalusers
                               WHERE provider=%s
                                 AND account=%s""",
                           (external["provider"], external["account"]))

            # Note: the token validation above implicitly checks that there's a
            # matching row in the 'externalusers' table.
            external_user_id, existing_user_id, external_email = cursor.fetchone()

            # Check that we don't already have a Critic user associated with
            # this external user.
            if existing_user_id is not None:
                existing_user = dbutils.User.fromId(db, existing_user_id)
                return OperationResult(
                    message=("There is already a Critic user ('%s') connected "
                             "to the %s '%s'" % (existing_user.name,
                                                 provider.getTitle(),
                                                 external["account"])))

            if email == external_email:
                verify_email_address = provider.configuration["verify_email_addresses"]

            # Reset 'email' column in 'externalusers': we only need it to detect
            # if the user changed the email address in the "Create user" form.
            # Also reset the 'token' column, which serves no further purpose
            # beyond this point.
            cursor.execute("""UPDATE externalusers
                                 SET email=NULL,
                                     token=NULL
                               WHERE id=%s""",
                           (external_user_id,))

        email_verified = False if email and verify_email_address else None

        user = dbutils.User.create(
            db, username, fullname, email, email_verified, password)

        if external:
            cursor.execute("""UPDATE externalusers
                                 SET uid=%s
                               WHERE id=%s""",
                           (user.id, external_user_id))

        auth.startSession(db, req, user)

        if email_verified is False:
            sendVerificationMail(db, user)

        db.commit()

        user.sendUserCreatedMail("wsgi[registeruser]", external)

        return OperationResult()

########NEW FILE########
__FILENAME__ = savesettings
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2013 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

from operation import Operation, OperationResult, OperationFailure, OperationError, Optional

import dbutils
import gitutils

class SaveSettings(Operation):
    def __init__(self):
        super(SaveSettings, self).__init__(
            { "user_id": Optional(int),
              "repository_id": Optional(int),
              "filter_id": Optional(int),
              "settings": [{ "item": str,
                             "value": Optional(set([bool, int, str])) }] })

    def process(self, db, user, settings, user_id=None, repository_id=None, filter_id=None):
        if repository_id is not None and filter_id is not None:
            raise OperationError("invalid input: both 'repository_id' and 'filter_id' set")

        if user_id is None:
            affected_user = user
        elif user_id != user.id:
            Operation.requireRole(db, "administrator", user)
            if user_id == -1:
                affected_user = None
            else:
                affected_user = dbutils.User.fromId(db, user_id)

        cursor = db.cursor()
        repository = None

        if filter_id is not None:
            # Check that the filter exists and that it's one of the user's
            # filters (or that the user has the administrator role.)
            cursor.execute("SELECT uid FROM filters WHERE id=%s", (filter_id,))
            row = cursor.fetchone()
            if not row:
                raise OperationFailure(
                    code="nosuchfilter",
                    title="No such filter!",
                    message=("Maybe the filter has been deleted since you "
                             "loaded this page?"))
            elif row[0] != affected_user.id:
                raise OperationFailure(
                    code="invalidfilter",
                    title="The filter belongs to someone else!",
                    message=("What are you up to?"))
        elif repository_id is not None:
            repository = gitutils.Repository.fromId(db, repository_id)

        saved_settings = []

        for setting in settings:
            item = setting["item"]
            value = setting.get("value")

            if dbutils.User.storePreference(db, item, value, affected_user,
                                            repository, filter_id):
                saved_settings.append(setting["item"])

        db.commit()

        return OperationResult(saved_settings=sorted(saved_settings))

########NEW FILE########
__FILENAME__ = searchreview
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2013 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import re
import urllib

import dbutils
import gitutils

from operation import Operation, OperationResult, OperationFailure

def globToSQLPattern(glob):
    pattern = glob.replace("\\", "\\\\").replace("%", "\\%").replace("?", "_").replace("*", "%")
    if "?" in glob or "*" in glob:
        return pattern
    return "%" + pattern + "%"

def pathToSQLRegExp(path):
    pattern = ""
    if path.startswith("/"):
        pattern += "^"
        path = path.lstrip("/")
    escaped = re.sub(r"[(){}\[\].\\+^$]", lambda match: "\\" + match.group(), path)
    replacements = { "**/": "(?:[^/]+/)*", "*": "[^/]*", "?": "." }
    pattern += re.sub("\*\*/|\*|\?", lambda match: replacements[match.group()], escaped)
    return pattern

class Query(object):
    def __init__(self, parent=None):
        if not parent:
            self.tables = { "reviews": set() }
            self.arguments = []
        else:
            self.tables = parent.tables
            self.arguments = parent.arguments
        self.conditions = []

    def addTable(self, table, *conditions):
        self.tables.setdefault(table, set()).update(conditions)

class Review(object):
    def __init__(self, review_id, summary):
        self.review_id = review_id
        self.summary = summary
    def json(self):
        return { "id": self.review_id, "summary": self.summary }

class InvalidFilter(Exception):
    def __init__(self, title, message):
        self.title = title
        self.message = message

class Filter(object):
    def __init__(self, db, value):
        self.db = db
        self.value = value
        self.check(db)
    def check(self, db):
        pass
    def filter(self, db, review):
        return True

class SummaryFilter(Filter):
    def contribute(self, query):
        query.conditions.append("reviews.summary LIKE %s")
        query.arguments.append(globToSQLPattern(self.value))

class DescriptionFilter(Filter):
    def contribute(self, query):
        query.conditions.append("reviews.description LIKE %s")
        query.arguments.append(globToSQLPattern(self.value))

class BranchFilter(Filter):
    def contribute(self, query):
        query.addTable("branches", "branches.id=reviews.branch")
        query.conditions.append("branches.name ~ %s")
        query.arguments.append(pathToSQLRegExp(self.value))

class PathFilter(Filter):
    def contribute(self, query):
        query.addTable("reviewfiles", "reviewfiles.review=reviews.id")
        query.addTable("files", "files.id=reviewfiles.file")

        static_components = []
        for component in self.value.split("/"):
            if component and not ("*" in component or "?" in component):
                static_components.append(component)

        if static_components:
            query.conditions.append("%s <@ STRING_TO_ARRAY(path, '/')")
            query.arguments.append(static_components)

        query.conditions.append("files.path ~ %s")
        query.arguments.append(pathToSQLRegExp(self.value))

class UserFilter(Filter):
    def check(self, db):
        self.user = dbutils.User.fromName(db, self.value)
    def contribute(self, query):
        query.addTable("reviewusers", "reviewusers.review=reviews.id")
        query.conditions.append("reviewusers.uid=%s")
        query.arguments.append(self.user.id)

class OwnerFilter(UserFilter):
    def contribute(self, query):
        super(OwnerFilter, self).contribute(query)
        query.conditions.append("reviewusers.owner")

class ReviewerFilter(UserFilter):
    def contribute(self, query):
        query.addTable("reviewfiles", "reviewfiles.review=reviews.id")
        query.addTable("reviewuserfiles", "reviewuserfiles.file=reviewfiles.id")
        query.conditions.append("reviewuserfiles.uid=%s")
        query.arguments.append(self.user.id)

class StateFilter(Filter):
    def check(self, db):
        if self.value not in ("open", "pending", "accepted", "closed", "dropped"):
            raise InvalidFilter(
                title="Invalid review state: %r" % self.value,
                message=("Supported review states are open, pending, accepted, "
                         "closed and dropped."))
    def contribute(self, query):
        state = "open" if self.value in ("pending", "accepted") else self.value
        query.conditions.append("reviews.state=%s")
        query.arguments.append(state)
    def filter(self, db, review):
        if self.value == "pending":
            return not dbutils.Review.isAccepted(db, review.review_id)
        elif self.value == "accepted":
            return dbutils.Review.isAccepted(db, review.review_id)
        return True

class RepositoryFilter(Filter):
    def check(self, db):
        cursor = db.cursor()
        cursor.execute("SELECT id FROM repositories WHERE name=%s", (self.value,))
        row = cursor.fetchone()
        if not row:
            raise gitutils.NoSuchRepository(self.value)
        self.repository_id = row[0]
    def contribute(self, query):
        query.addTable("branches", "branches.id=reviews.branch")
        query.conditions.append("branches.repository=%s")
        query.arguments.append(self.repository_id)

class OrFilter(Filter):
    def __init__(self, filters):
        self.filters = filters
    def contribute(self, query):
        conditions = []
        for search_filter in self.filters:
            subquery = Query(query)
            search_filter.contribute(subquery)
            conditions.append("(%s)" % " AND ".join(subquery.conditions))
        query.conditions.append("(%s)" % " OR ".join(conditions))

class SearchReview(Operation):
    def __init__(self):
        Operation.__init__(self, { "query": str }, accept_anonymous_user=True)

    def process(req, db, user, query):
        terms = re.findall("""((?:"[^"]*"|'[^']*'|[^ "']+)+)""", query)
        url_terms = []
        filters = []

        for term in terms:
            if re.match("[a-z\-]+:", term):
                keyword, _, value = term.partition(":")

                url_terms.append(("q" + keyword, value))

                if keyword == "summary":
                    filter_classes = [SummaryFilter]
                elif keyword == "description":
                    filter_classes = [DescriptionFilter]
                elif keyword == "text":
                    filter_classes = [SummaryFilter, DescriptionFilter]
                elif keyword in ("branch", "b"):
                    filter_classes = [BranchFilter]
                elif keyword in ("path", "p"):
                    filter_classes = [PathFilter]
                elif keyword in ("user", "u"):
                    filter_classes = [UserFilter]
                elif keyword in ("owner", "o"):
                    filter_classes = [OwnerFilter]
                elif keyword == "reviewer":
                    filter_classes = [ReviewerFilter]
                elif keyword == "owner-or-reviewer":
                    filter_classes = [OwnerFilter, ReviewerFilter]
                elif keyword in ("state", "s"):
                    filter_classes = [StateFilter]
                elif keyword in ("repository", "repo", "r"):
                    filter_classes = [RepositoryFilter]
                else:
                    raise OperationFailure(
                        code="invalidkeyword",
                        title="Invalid keyword: %r" % keyword,
                        message=("Supported keywords are summary, description, "
                                 "text, branch, path, user, owner and reviewer."))

                if re.match("([\"']).*\\1$", value):
                    value = value[1:-1]

                try:
                    if len(filter_classes) > 1:
                        keyword_filters = [filter_class(db, value)
                                           for filter_class in filter_classes]
                        filters.append(OrFilter(keyword_filters))
                    else:
                        filters.append(filter_classes[0](db, value))

                except InvalidFilter as error:
                    raise OperationFailure(
                        code="invalidterm",
                        title=error.title,
                        message=error.message)
                except dbutils.NoSuchUser as error:
                    raise OperationFailure(
                        code="invalidterm",
                        title="No such user: %r" % error.name,
                        message=("The search term following %r must be a valid user name."
                                 % (keyword + ":")))
                except gitutils.NoSuchRepository as error:
                    raise OperationFailure(
                        code="invalidterm",
                        title="No such repository: %r" % error.name,
                        message=("The search term following %r must be a valid repository name."
                                 % (keyword + ":")))
            else:
                url_terms.append(("q", term))

                if re.match("([\"']).*\\1$", term):
                    term = term[1:-1]

                auto_filters = []
                auto_filters.append(SummaryFilter(db, term))
                auto_filters.append(DescriptionFilter(db, term))
                if not re.search(r"\s", term):
                    auto_filters.append(BranchFilter(db, term))
                    if re.search(r"\w/\w|\w\.\w+$", term):
                        auto_filters.append(PathFilter(db, term))

                filters.append(OrFilter(auto_filters))

        if not filters:
            raise OperationFailure(
                code="nofilters",
                title="No search filter specified",
                message="Your search would find all reviews.  Please restrict it a bit.")

        query_params = Query()

        for search_filter in filters:
            search_filter.contribute(query_params)

        query_string = """SELECT DISTINCT reviews.id, reviews.summary
                            FROM %s
                           WHERE %s
                        ORDER BY reviews.id DESC"""

        for conditions in query_params.tables.values():
            query_params.conditions[0:0] = conditions

        query = query_string % (", ".join(query_params.tables.keys()),
                                " AND ".join(query_params.conditions))

        cursor = db.cursor()
        cursor.execute(query, query_params.arguments)

        reviews = [Review(review_id, summary) for review_id, summary in cursor]

        for search_filter in filters:
            reviews = filter(lambda review: search_filter.filter(db, review), reviews)

        return OperationResult(
            reviews=map(Review.json, reviews),
            query_string=urllib.urlencode(url_terms))

########NEW FILE########
__FILENAME__ = servicemanager
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2012 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

from operation import Operation, OperationResult, Optional, OperationError

import configuration
import textutils

import os
import socket
import signal

class RestartService(Operation):
    def __init__(self):
        Operation.__init__(self, { "service_name": str })

    def process(self, db, user, service_name):
        Operation.requireRole(db, "administrator", user)

        if service_name == "wsgi":
            for pid in os.listdir(configuration.paths.WSGI_PIDFILE_DIR):
                try: os.kill(int(pid), signal.SIGINT)
                except: pass
            return OperationResult()
        else:
            connection = socket.socket(socket.AF_UNIX, socket.SOCK_STREAM)
            connection.connect(configuration.services.SERVICEMANAGER["address"])
            connection.send(textutils.json_encode({ "command": "restart", "service": service_name }))
            connection.shutdown(socket.SHUT_WR)

            data = ""
            while True:
                received = connection.recv(4096)
                if not received: break
                data += received

            result = textutils.json_decode(data)

            if result["status"] == "ok": return OperationResult()
            else: raise OperationError(result["error"])

class GetServiceLog(Operation):
    def __init__(self):
        Operation.__init__(self, { "service_name": str, "lines": Optional(int) })

    def process(self, db, user, service_name, lines=40):
        logfile_paths = { "manager": configuration.services.SERVICEMANAGER["logfile_path"] }

        for service in configuration.services.SERVICEMANAGER["services"]:
            logfile_paths[service["name"]] = service["logfile_path"]

        logfile_path = logfile_paths.get(service_name)

        if not logfile_path:
            raise OperationError("unknown service: %s" % service_name)

        try: logfile = open(logfile_path)
        except OSError as error:
            raise OperationError("failed to open logfile: %s" % error.message)

        return OperationResult(lines=logfile.read().splitlines()[-lines:])

########NEW FILE########
__FILENAME__ = trackedbranch
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2012 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

from operation import Operation, OperationResult, OperationFailure, OperationError, Optional

import dbutils
import gitutils
import htmlutils
import configuration

import calendar
import os
import signal

def getTrackedBranchReviewState(db, branch_id):
    cursor = db.cursor()
    cursor.execute("""SELECT reviews.state
                        FROM reviews
                        JOIN branches ON (branches.id=reviews.branch)
                        JOIN trackedbranches ON (trackedbranches.repository=branches.repository
                                             AND trackedbranches.local_name=branches.name)
                       WHERE trackedbranches.id=%s""",
                   (branch_id,))

    row = cursor.fetchone()
    return row[0] if row else None

class TrackedBranchLog(Operation):
    def __init__(self):
        Operation.__init__(self, { "branch_id": int })

    def process(self, db, user, branch_id):
        cursor = db.cursor()
        cursor.execute("""SELECT previous, next
                            FROM trackedbranches
                           WHERE id=%s""",
                       (branch_id,))

        previous, next = cursor.fetchone()
        previous = calendar.timegm(previous.utctimetuple()) if previous else None
        next = calendar.timegm(next.utctimetuple()) if next else None

        cursor.execute("""SELECT time, from_sha1, to_sha1, hook_output, successful
                            FROM trackedbranchlog
                           WHERE branch=%s
                        ORDER BY time ASC""",
                       (branch_id,))

        items = []

        for update_time, from_sha1, to_sha1, hook_output, successful in cursor:
            items.append({ "time": calendar.timegm(update_time.utctimetuple()),
                           "from_sha1": from_sha1,
                           "to_sha1": to_sha1,
                           "hook_output": hook_output,
                           "successful": successful })

        cursor.execute("""SELECT repository
                            FROM trackedbranches
                           WHERE id=%s""",
                       (branch_id,))

        repository = gitutils.Repository.fromId(db, cursor.fetchone()[0])

        return OperationResult(previous=previous,
                               next=next,
                               items=items,
                               repository={ "id": repository.id, "name": repository.name })

class DisableTrackedBranch(Operation):
    def __init__(self):
        Operation.__init__(self, { "branch_id": int })

    def process(self, db, user, branch_id):
        cursor = db.cursor()

        if not user.hasRole(db, "administrator"):
            cursor.execute("""SELECT 1
                                FROM trackedbranchusers
                               WHERE branch=%s
                                 AND uid=%s""",
                           (branch_id, user.id))

            if not cursor.fetchone():
                raise OperationFailure(code="notallowed",
                                       title="Not allowed!",
                                       message="Operation not permitted.")

        cursor.execute("""UPDATE trackedbranches
                             SET disabled=TRUE
                           WHERE id=%s""",
                       (branch_id,))

        db.commit()

        return OperationResult()

class TriggerTrackedBranchUpdate(Operation):
    def __init__(self):
        Operation.__init__(self, { "branch_id": int })

    def process(self, db, user, branch_id):
        cursor = db.cursor()

        if not user.hasRole(db, "administrator"):
            cursor.execute("""SELECT 1
                                FROM trackedbranchusers
                               WHERE branch=%s
                                 AND uid=%s""",
                           (branch_id, user.id))

            if not cursor.fetchone():
                raise OperationFailure(code="notallowed",
                                       title="Not allowed!",
                                       message="Operation not permitted.")

        review_state = getTrackedBranchReviewState(db, branch_id)
        if review_state is not None and review_state != "open":
            raise OperationFailure(code="reviewnotopen",
                                   title="The review is not open!",
                                   message="You need to reopen the review before new commits can be added to it.")

        cursor.execute("""UPDATE trackedbranches
                             SET next=NULL
                           WHERE id=%s""",
                       (branch_id,))

        db.commit()

        pid = int(open(configuration.services.BRANCHTRACKER["pidfile_path"]).read().strip())
        os.kill(pid, signal.SIGHUP)

        return OperationResult()

class EnableTrackedBranch(Operation):
    def __init__(self):
        Operation.__init__(self, { "branch_id": int,
                                   "new_remote_name": Optional(str) })

    def process(self, db, user, branch_id, new_remote_name=None):
        cursor = db.cursor()

        if not user.hasRole(db, "administrator"):
            cursor.execute("""SELECT 1
                                FROM trackedbranchusers
                               WHERE branch=%s
                                 AND uid=%s""",
                           (branch_id, user.id))

            if not cursor.fetchone():
                raise OperationFailure(code="notallowed",
                                       title="Not allowed!",
                                       message="Operation not permitted.")

        review_state = getTrackedBranchReviewState(db, branch_id)
        if review_state is not None and review_state != "open":
            raise OperationFailure(code="reviewnotopen",
                                   title="The review is not open!",
                                   message="You need to reopen the review before new commits can be added to it.")

        if new_remote_name is not None:
            cursor.execute("""SELECT remote
                                FROM trackedbranches
                               WHERE id=%s""",
                           (branch_id,))

            remote = cursor.fetchone()[0]

            if not gitutils.Repository.lsremote(remote, pattern="refs/heads/" + new_remote_name):
                raise OperationFailure(
                    code="refnotfound",
                    title="Remote ref not found!",
                    message=("Could not find the ref <code>%s</code> in the repository <code>%s</code>."
                             % (htmlutils.htmlify("refs/heads/" + new_remote_name),
                                htmlutils.htmlify(remote))),
                    is_html=True)

            cursor.execute("""UPDATE trackedbranches
                                 SET remote_name=%s,
                                     disabled=FALSE,
                                     next=NULL
                               WHERE id=%s""",
                           (new_remote_name, branch_id))
        else:
            cursor.execute("""UPDATE trackedbranches
                                 SET disabled=FALSE,
                                     next=NULL
                               WHERE id=%s""",
                           (branch_id,))

        db.commit()

        pid = int(open(configuration.services.BRANCHTRACKER["pidfile_path"]).read().strip())
        os.kill(pid, signal.SIGHUP)

        return OperationResult()

class DeleteTrackedBranch(Operation):
    def __init__(self):
        Operation.__init__(self, { "branch_id": int })

    def process(self, db, user, branch_id):
        cursor = db.cursor()

        if not user.hasRole(db, "administrator"):
            cursor.execute("""SELECT 1
                                FROM trackedbranchusers
                               WHERE branch=%s
                                 AND uid=%s""",
                           (branch_id, user.id))

            if not cursor.fetchone():
                raise OperationFailure(code="notallowed",
                                       title="Not allowed!",
                                       message="Operation not permitted.")

        cursor.execute("""DELETE FROM trackedbranches
                                WHERE id=%s""",
                       (branch_id,))

        db.commit()

        return OperationResult()

class AddTrackedBranch(Operation):
    def __init__(self):
        Operation.__init__(self, { "repository_id": int,
                                   "source_location": str,
                                   "source_name": str,
                                   "target_name": str,
                                   "users": [str],
                                   "forced": Optional(bool) })

    def process(self, db, user, repository_id, source_location, source_name,
                target_name, users, forced=None):
        cursor = db.cursor()
        cursor.execute("""SELECT 1
                            FROM trackedbranches
                           WHERE repository=%s
                             AND local_name=%s""",
                       (repository_id, target_name))

        if cursor.fetchone():
            raise OperationError("branch '%s' already tracks another branch" % target_name)

        users = [dbutils.User.fromName(db, username) for username in users]

        if target_name.startswith("r/"):
            cursor.execute("""SELECT 1
                                FROM reviews
                                JOIN branches ON (branches.id=reviews.branch)
                               WHERE branches.repository=%s
                                 AND branches.name=%s""",
                           (repository_id, target_name))

            if not cursor.fetchone():
                raise OperationError("non-existing review branch can't track another branch")

            if forced is None:
                forced = True
        elif forced is None:
            forced = False

        cursor.execute("""SELECT 1
                            FROM knownremotes
                           WHERE url=%s
                             AND pushing""",
                       (source_location,))

        if cursor.fetchone():
            delay = "1 week"
        else:
            delay = "1 hour"

        cursor.execute("""INSERT INTO trackedbranches (repository, local_name, remote, remote_name, forced, delay)
                               VALUES (%s, %s, %s, %s, %s, %s)
                            RETURNING id""",
                       (repository_id, target_name, source_location, source_name, forced, delay))

        branch_id = cursor.fetchone()[0]

        for user in users:
            cursor.execute("""INSERT INTO trackedbranchusers (branch, uid)
                                   VALUES (%s, %s)""",
                           (branch_id, user.id))

        db.commit()

        pid = int(open(configuration.services.BRANCHTRACKER["pidfile_path"]).read().strip())
        os.kill(pid, signal.SIGHUP)

        return OperationResult(branch_id=branch_id)

########NEW FILE########
__FILENAME__ = typechecker
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2014 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import re

import base
import dbutils

from operation.basictypes import OperationError, OperationFailure

class Optional:

    """Utility class for signaling that a dictionary member is optional."""

    def __init__(self, source):
        self.source = source

class TypeCheckerContext(object):
    def __init__(self, *args):
        self.args = args
        self.req, self.db, self.user = args
        self.repository = None
        self.review = None
        self.__path = ["data"]
    def __str__(self):
        return "".join(self.__path)
    def push(self, name):
        self.__path.append(name)
    def pop(self):
        self.__path.pop()
    def clone(self):
        copy = TypeCheckerContext(*self.args)
        copy.copy_from(self)
        copy.__path = self.__path[:]
        return copy
    def copy_from(self, other):
        self.repository = other.repository
        self.review = other.review

class TypeChecker(object):

    """
    Interface for checking operation input type correctness.

    Sub-classes implement the method __call__(value, context) which raises an
    OperationError if the input is incorrect.

    A type checker structure is created using the static make() function.
    """

    @staticmethod
    def make(source):
        """
        Construct a structure of TypeChecker objects.

        The source argument should be a dict object, single-element list object,
        a set object containing strings, or str, int or bool (the actual type
        objects, not a string, integer or boolean value).

        If the source argument is a dict object, per-element type checkers are
        constructed by calling this function on the value of each item in the
        dictionary.  See DictionaryChecker for details.

        If the source argument is a list object, a per-element type checker is
        constructed by calling this function on the value of the single element
        in the list.

        If the source argument is a set object, all elements in it should be
        strings, and the constructed checker verifies that the value is a string
        that is a member of the set.

        Otherwise the constructed checker verifies that the value is of the type
        of the source argument (or, in the case of source=str, that the value's
        type is either str or unicode).
        """

        if isinstance(source, TypeChecker):
            return source
        elif isinstance(source, dict):
            return DictionaryChecker(source)
        elif isinstance(source, list):
            return ArrayChecker(source)
        elif isinstance(source, set):
            if all(type(x) is str for x in source):
                return EnumerationChecker(source)
            return VariantChecker(source)
        elif source is str:
            return StringChecker()
        elif source is int:
            return IntegerChecker()
        elif source is bool:
            return BooleanChecker()

        try:
            is_type_checker = issubclass(source, TypeChecker)
        except TypeError:
            pass
        else:
            if is_type_checker:
                return source()

        raise base.ImplementationError("invalid source type: %s" % type(source))

    def getSuffixedCheckers(self):
        """
        Return a list of (suffix, checker) tuples.

        A suffixed checker allows a parameter to be specified with an optional
        suffix, that (optionally) restricts the acceptable input values.  For
        instance, a checker that supports either an integer id or a string name
        could return a list

          [("id", id_checker), ("name", name_checker)]

        with the effect that the input can be one of

          { "thing": id-or-name }
          { "thing_id": id }
          { "thing_name": name }

        and the resulting parameter name "thing" in either case.

        A checker can also return [("suffix", None)] to signal that a suffix is
        supported, but that the same checker (not a restricted one) should be
        applied regardless.
        """
        return []

class Implicit(object):

    """
    Mix-in class for implicit parameters.

    An implicit parameter is one we don't expect to receive from the client at
    all, but rather already have.  The use-case is for an operation to request
    additional information passed to it, for instance a reference to the Request
    object.
    """

    pass

class Prioritized(object):

    """
    Mix-in class for prioritized parameters.

    A prioritized parameter is one that stores information in the context that
    might be required for the checkers of other parameters, and thus need to be
    processed first.  DictionaryChecker uses this to control the order in which
    it processes dictionary items.
    """

    pass

class Request(TypeChecker, Implicit):
    def __call__(self, value, context):
        assert value is None
        return context.req

class BooleanChecker(TypeChecker):

    """
    Type checker for booleans.

    Raises an OperationError if the checked value is not a boolean.
    """

    def __call__(self, value, context):
        if not isinstance(value, bool):
            raise OperationError("invalid input: %s is not a boolean" % context)

class StringChecker(TypeChecker):

    """
    Type checker for strings.

    Raises an OperationError if the checked value is not a string.
    """

    def __call__(self, value, context):
        if not isinstance(value, basestring):
            raise OperationError("invalid input: %s is not a string" % context)

class RestrictedString(StringChecker):

    """
    Type checker for restricted strings.

    A restricted string is one that may consist only of certain characters,
    and/or must be of a certain min/max length.

    Raises an OperationFailure if the checked value is not valid.
    """

    def __init__(self, allowed=None, minlength=None, maxlength=None, ui_name=None):
        self.allowed = allowed
        self.minlength = minlength
        self.maxlength = maxlength
        self.ui_name = ui_name

    def __call__(self, value, context):
        super(RestrictedString, self).__call__(value, context)
        if self.ui_name:
            ui_name = self.ui_name
        else:
            ui_name = context
        if self.minlength is not None \
                and len(value) < self.minlength:
            raise OperationFailure(
                code="paramtooshort:%s" % context,
                title="Invalid %s" % ui_name,
                message=("invalid input: %s must be at least %d characters long"
                         % (ui_name, self.minlength)))
        if self.maxlength is not None \
                and len(value) > self.maxlength:
            raise OperationFailure(
                code="paramtoolong:%s" % context,
                title="Invalid %s" % ui_name,
                message=("invalid input: %s must be at most %d characters long"
                         % (ui_name, self.maxlength)))
        if self.allowed:
            disallowed = [ch for ch in sorted(set(value))
                          if not self.allowed(ch)]
            if disallowed:
                raise OperationFailure(
                    code="paramcontainsillegalchar:%s" % context,
                    title="Invalid %s" % ui_name,
                    message=("invalid input: %s may not contain the character%s %s"
                             % (ui_name, "s" if len(disallowed) > 1 else "",
                                ", ".join(repr(ch) for ch in disallowed))))

class SHA1(RestrictedString):
    def __init__(self):
        super(SHA1, self).__init__(minlength=4,
                                   maxlength=40,
                                   allowed=re.compile("[0-9A-Fa-f]$").match)

class IntegerChecker(TypeChecker):

    """
    Type checker for integers.

    Raises an OperationError if the checked value is not an integer.
    """

    def __call__(self, value, context):
        if not isinstance(value, int) or isinstance(value, bool):
            raise OperationError("invalid input: %s is not an integer" % context)

class RestrictedInteger(IntegerChecker):
    def __init__(self, minvalue=None, maxvalue=None, ui_name=None):
        self.minvalue = minvalue
        self.maxvalue = maxvalue
        self.ui_name = ui_name

    def __call__(self, value, context):
        super(RestrictedInteger, self).__call__(value, context)
        if self.ui_name:
            ui_name = self.ui_name
        else:
            ui_name = context
        if self.minvalue is not None \
                and value < self.minvalue:
            raise OperationFailure(
                code="valuetoolow:%s" % context,
                title="Invalid %s parameter" % ui_name,
                message=("invalid input: %s must be %d or higher"
                         % (ui_name, self.minvalue)))
        if self.maxvalue is not None \
                and value > self.maxvalue:
            raise OperationFailure(
                code="valuetoohigh:%s" % context,
                title="Invalid %s parameter" % ui_name,
                message=("invalid input: %s must be %d or lower"
                         % (ui_name, self.maxvalue)))

class NonNegativeInteger(RestrictedInteger):
    def __init__(self):
        super(NonNegativeInteger, self).__init__(minvalue=0)

class PositiveInteger(RestrictedInteger):
    def __init__(self):
        super(PositiveInteger, self).__init__(minvalue=1)

def check(checker, value, context):
    """Apply checker and return converted, or original, value."""
    converted = checker(value, context)
    if converted is None:
        return value
    return converted

class DictionaryChecker(TypeChecker):

    """
    Type checker for dictionary objects.

    Checks two sets of members: required and optional.  Raises an OperationError
    if the checked value is not a dictionary or if any required member is not
    present in it, or if it contains any unexpected members.  Applies
    per-element checkers on all required members and on all present optional
    members.
    """

    def __init__(self, source):
        self.__implicit = []
        self.__prioritized = []
        self.__required = []
        self.__optional = []
        self.__expected = set()

        for name, source_type in source.items():
            if isinstance(source_type, Optional):
                checker = TypeChecker.make(source_type.source)
                if isinstance(checker, (Implicit, Prioritized)):
                    raise base.ImplementationError(
                        "implicit/prioritized parameter cannot be optional: %s"
                        % name)
                self.__optional.append((name, checker))
            else:
                checker = TypeChecker.make(source_type)
                if isinstance(checker, Implicit):
                    self.__implicit.append((name, checker))
                elif isinstance(checker, Prioritized):
                    self.__prioritized.append((name, checker))
                else:
                    self.__required.append((name, checker))
            for suffix, _ in checker.getSuffixedCheckers():
                if name.endswith("_" + suffix):
                    raise base.ImplementationError(
                        "invalid parameter name: %s (includes optional suffix)"
                        % name)

    def __call__(self, value, context):
        if not type(value) is dict:
            raise OperationError("invalid input: %s is not a dictionary" % context)

        specified_names = set(value.keys())

        class Missing:
            pass

        def read_with_suffixes(name, checker):
            try:
                if name in value:
                    specified_names.remove(name)
                    context.push("." + name)
                    return check(checker, value[name], context)
                for suffix, suffixed_checker in checker.getSuffixedCheckers():
                    suffixed_name = "%s_%s" % (name, suffix)
                    if suffixed_name in value:
                        specified_names.remove(suffixed_name)
                        context.push("." + suffixed_name)
                        if suffixed_checker is not None:
                            checker = suffixed_checker
                        return check(checker, value.pop(suffixed_name), context)
                context.push("." + name)
                return Missing
            finally:
                context.pop()

        for name, checker in self.__implicit:
            context.push("." + name)
            if name in value:
                raise OperationError(
                    "invalid input: %s should not be specified" % context)
            value[name] = checker(None, context)
            context.pop()

        def process_members(items, required):
            for name, checker in items:
                converted = read_with_suffixes(name, checker)
                if not converted is Missing:
                    value[name] = converted
                elif required:
                    context.push("." + name)
                    raise OperationError("invalid input: %s missing" % context)

        process_members(self.__prioritized, True)
        process_members(self.__required, True)
        process_members(self.__optional, False)

        if specified_names:
            context.push("." + specified_names.pop())
            raise OperationError("invalid input: %s was not used" % context)

class ArrayChecker(TypeChecker):

    """
    Type checker for arrays.

    Raises an OperationError if the checked value is not an array.  Applies the
    per-element checker on each element in the array.
    """

    def __init__(self, source):
        if len(source) != 1:
            raise base.ImplementationError("invalid source type")
        self.__checker = TypeChecker.make(source[0])

    def __call__(self, value, context):
        if not type(value) is list:
            raise OperationError("%s is not a list" % context)
        for index, item in enumerate(value):
            context.push("[%d]" % index)
            value[index] = check(self.__checker, item, context)
            context.pop()

class VariantChecker(TypeChecker):

    """
    Type checker for variants (values of one of a set of types.)

    Raises an OperationError if the checked value is not one of the permitted
    types (checked by applying a per-type checker on the value.)
    """

    def __init__(self, source):
        self.__checkers = []
        self.__suffixed_checkers = []
        if isinstance(source, dict):
            for suffix, item in source.items():
                checker = TypeChecker.make(item)
                self.__checkers.append(checker)
                self.__suffixed_checkers.append((suffix, checker))
        else:
            self.__checkers.extend(TypeChecker.make(item) for item in source)

    def __call__(self, value, context):
        for checker in self.__checkers:
            try:
                variant_context = context.clone()
                value = checker(value, variant_context)
                context.copy_from(variant_context)
                return value
            except (OperationError, OperationFailure):
                pass
        raise OperationError("%s is of invalid type" % context)

    def getSuffixedCheckers(self):
        return self.__suffixed_checkers

class EnumerationChecker(TypeChecker):

    """
    Type checker for enumerations.

    Raises an OperationError if the checked value is not a string or if the
    string value is not a member of the enumeration.
    """

    def __init__(self, source):
        self.__checker = TypeChecker.make(str)
        for item in source:
            if not type(item) is str:
                raise base.ImplementationError("invalid source type")
        self.__enumeration = source

    def __call__(self, value, context):
        self.__checker(value, context)
        if value not in self.__enumeration:
            raise OperationError("invalid input: %s is not valid" % context)

class Review(PositiveInteger, Prioritized):
    def __call__(self, value, context):
        super(Review, self).__call__(value, context)
        context.review = dbutils.Review.fromId(context.db, value)
        context.repository = context.review.repository
        return context.review

    def getSuffixedCheckers(self):
        return [("id", None)]

class RepositoryId(PositiveInteger):
    def __call__(self, value, context):
        import gitutils
        super(RepositoryId, self).__call__(value, context)
        context.repository = gitutils.Repository.fromId(context.db, value)
        return context.repository

class RepositoryName(StringChecker):
    def __call__(self, value, context):
        import gitutils
        super(RepositoryName, self).__call__(value, context)
        context.repository = gitutils.Repository.fromName(context.db, value)
        return context.repository

class Repository(VariantChecker, Prioritized):
    def __init__(self):
        super(Repository, self).__init__({ "id": RepositoryId,
                                           "name": RepositoryName })

class CommitId(PositiveInteger):
    def __call__(self, value, context):
        import gitutils
        if context.repository is None:
            raise OperationError("missing repository in context")
        super(CommitId, self).__call__(value, context)
        return gitutils.Commit.fromId(context.db, context.repository, value)

class CommitSHA1(SHA1):
    def __call__(self, value, context):
        import gitutils
        if context.repository is None:
            raise OperationError("missing repository in context")
        super(CommitSHA1, self).__call__(value, context)
        return gitutils.Commit.fromSHA1(context.db, context.repository, value)

class Commit(VariantChecker):
    def __init__(self):
        super(Commit, self).__init__({ "id": CommitId,
                                       "sha1": CommitSHA1 })

    def __call__(self, value, context):
        if context.repository is None:
            raise OperationError("missing repository in context")
        return super(Commit, self).__call__(value, context)

class FileId(PositiveInteger):
    def __call__(self, value, context):
        super(FileId, self).__call__(value, context)
        return dbutils.File.fromId(context.db, value)

class FilePath(StringChecker):
    def __call__(self, value, context):
        super(FilePath, self).__call__(value, context)
        return dbutils.File.fromPath(context.db, value, insert=False)

class File(VariantChecker):
    def __init__(self):
        super(File, self).__init__({ "id": FileId,
                                     "path": FilePath })

class UserId(PositiveInteger):
    def __call__(self, value, context):
        super(UserId, self).__call__(value, context)
        return dbutils.User.fromId(context.db, value)

class UserName(StringChecker):
    def __call__(self, value, context):
        super(UserName, self).__call__(value, context)
        return dbutils.User.fromName(context.db, value)

class User(VariantChecker):
    def __init__(self):
        super(User, self).__init__({ "id": UserId,
                                     "name": UserName })

########NEW FILE########
__FILENAME__ = typechecker_unittest
import sys
import os
import copy
import json

def basic():
    import htmlutils

    from operation.basictypes import OperationError, OperationFailure
    from operation.typechecker import (
        Optional, TypeChecker, TypeCheckerContext, BooleanChecker,
        StringChecker, RestrictedString, SHA1, IntegerChecker,
        RestrictedInteger, PositiveInteger, NonNegativeInteger, ArrayChecker,
        EnumerationChecker, VariantChecker, DictionaryChecker)

    # Check TypeChecker.make()'s handling of basic types.
    assert type(TypeChecker.make(bool)) is BooleanChecker
    assert type(TypeChecker.make(str)) is StringChecker
    assert type(TypeChecker.make(int)) is IntegerChecker
    assert type(TypeChecker.make([bool])) is ArrayChecker
    assert type(TypeChecker.make(set(["foo", "bar"]))) is EnumerationChecker
    assert type(TypeChecker.make(set([bool, str, int]))) is VariantChecker
    assert type(TypeChecker.make({ "foo": bool })) is DictionaryChecker

    # Check TypeChecker.make()'s handling of TypeChecker sub-classes and
    # instances thereof.
    assert isinstance(TypeChecker.make(BooleanChecker), BooleanChecker)
    boolean_checker = BooleanChecker()
    assert TypeChecker.make(boolean_checker) is boolean_checker

    def check(checker, *values):
        checker = TypeChecker.make(checker)
        results = []
        for value in values:
            converted = checker(value, TypeCheckerContext(None, None, None))
            results.append(value if converted is None else converted)
        return results

    def should_match(checker, *values, **kwargs):
        results = check(checker, *values)
        if "result" in kwargs:
            expected_result = kwargs["result"]
            for result in results:
                assert result == expected_result, \
                    "%r != %r" % (result, expected_result)

    def should_not_match(checker, *values, **expected):
        for value in values:
            try:
                check(checker, copy.deepcopy(value))
            except (OperationError, OperationFailure) as error:
                error = json.loads(str(error))
                for key, value in expected.items():
                    if isinstance(value, str):
                        value = set([value])
                    assert error.get(key) in value, \
                        ("%s: %r not among %r" % (key, error.get(key), value))
            else:
                assert False, "checker allowed value incorrectly: %r" % value

    # Check some simple things that should be accepted.
    should_match(bool, True, False)
    should_match(str, "", "foo")
    should_match(int, -2**31, -1, 0, 1, 2**31)
    should_match([bool], [], [True, False])
    should_match([str], ["", "foo"])
    should_match([int], [-2**31, -1, 0, 1, 2**31])
    should_match(set(["foo", "bar"]), "foo", "bar")
    should_match(set([bool, str, int]),
                 True, False, "", "foo", -2**31, -1, 0, 1, 2**31)

    # Check some equally simple things that shouldn't be accepted.
    should_not_match(bool, 10, "foo",
                     error="invalid input: data is not a boolean")
    should_not_match(str, True, 10,
                     error="invalid input: data is not a string")
    should_not_match(int, True, "foo", 0.5,
                     error="invalid input: data is not an integer")
    should_not_match([bool], [True, 10], [False, "foo"],
                     error="invalid input: data[1] is not a boolean")
    should_not_match([str], ["", True], ["foo", 10],
                     error="invalid input: data[1] is not a string")
    should_not_match([int], [0, True], [10, "foo"],
                     error="invalid input: data[1] is not an integer")
    should_not_match(set(["foo", "bar"]), "fie",
                     error="invalid input: data is not valid")
    should_not_match(set(["foo", "bar"]), True, 10,
                     error="invalid input: data is not a string")
    should_not_match(set([bool, str, int]), [True], ["foo"], [10],
                     error="data is of invalid type")

    # Check some dictionary checkers.
    should_match({ "b": bool, "s": str, "i": int },
                 { "b": True, "s": "foo", "i": 10 })
    should_match({ "req": bool, "opt": Optional(bool) },
                 { "req": True, "opt": False },
                 { "req": False })
    should_not_match({ "b": bool }, { "b": "foo" }, { "b": 10 },
                     error="invalid input: data.b is not a boolean")
    should_not_match({ "b": bool }, { "i": 10 },
                     error="invalid input: data.b missing")
    should_not_match({ "b": bool }, { "b": True, "i": 10 },
                     error="invalid input: data.i was not used")
    should_not_match({ "b": Optional(bool) }, { "b": "foo" }, { "b": 10 },
                     error="invalid input: data.b is not a boolean")

    # Check suffixed variant checker in dictionary.
    id_or_name = VariantChecker({ "id": int, "name": str })
    should_match({ "thing": id_or_name },
                 { "thing": 10 },
                 { "thing_id": 10 },
                 result={ "thing": 10 })
    should_match({ "thing": id_or_name },
                 { "thing": "foo" },
                 { "thing_name": "foo" },
                 result={ "thing": "foo" })
    should_not_match({ "thing": id_or_name },
                     { "thing_id": "foo" },
                     error="invalid input: data.thing_id is not an integer")
    should_not_match({ "thing": id_or_name },
                     { "thing_name": 10 },
                     error="invalid input: data.thing_name is not a string")
    should_not_match({ "thing": id_or_name },
                     { "thing_id": 10,
                       "thing_name": "foo" },
                     error=("invalid input: data.thing_id was not used",
                            "invalid input: data.thing_name was not used"))

    # Check some RestrictedString types.
    should_match(RestrictedString, "", "foo")
    should_match(RestrictedString(minlength=0), "", "foo")
    should_match(RestrictedString(minlength=3), "foo")
    should_match(RestrictedString(maxlength=0), "")
    should_match(RestrictedString(maxlength=3), "", "foo")
    should_match(RestrictedString(minlength=0, maxlength=3), "", "foo")
    should_match(RestrictedString(allowed=lambda c: False), "")
    should_match(RestrictedString(allowed=lambda c: True), "", "foo")
    should_match(RestrictedString(allowed=lambda c: c in "foo"), "", "foo")
    should_not_match(RestrictedString(), True, 10,
                     error="invalid input: data is not a string")
    should_not_match(
        RestrictedString(minlength=1), "",
        code="paramtooshort:data",
        title="Invalid data",
        message="invalid input: data must be at least 1 characters long")
    should_not_match(
        RestrictedString(maxlength=2), "foo",
        code="paramtoolong:data",
        title="Invalid data",
        message="invalid input: data must be at most 2 characters long")
    should_not_match(
        RestrictedString(allowed=lambda c: False), "foo",
        code="paramcontainsillegalchar:data",
        title="Invalid data",
        message="invalid input: data may not contain the characters 'f', 'o'")
    should_not_match(
        RestrictedString(allowed=lambda c: False, ui_name="gazonk"), "foo",
        code="paramcontainsillegalchar:data",
        title="Invalid gazonk",
        message="invalid input: gazonk may not contain the characters 'f', 'o'")

    # Check SHA1.
    sha1 = "0123456789abcdefABCDEF0123456789abcdefAB"
    should_match(SHA1, *[sha1[:length] for length in range(4, 41)])
    should_not_match(SHA1, True, 10,
                     error="invalid input: data is not a string")
    for ch in range(0, 256):
        ch = chr(ch)
        if ch in sha1:
            continue
        should_not_match(
            SHA1, "012" + ch,
            message=htmlutils.htmlify(
                "invalid input: data may not contain the character %r" % ch))
    should_not_match(
        SHA1, "012",
        message="invalid input: data must be at least 4 characters long")
    should_not_match(
        SHA1, "0" * 41,
        message="invalid input: data must be at most 40 characters long")

    # Check some RestrictedInteger types.
    should_match(RestrictedInteger, -2**31, -1, 0, 1, 2**31)
    should_match(RestrictedInteger(minvalue=-2**31), -2**31, -1, 0, 1, 2**31)
    should_match(RestrictedInteger(minvalue=0), 0, 1, 2**31)
    should_match(RestrictedInteger(maxvalue=0), -2**31, -1, 0)
    should_match(RestrictedInteger(maxvalue=2**31), -2**31, -1, 0, 1, 2**31)
    should_match(RestrictedInteger(minvalue=0, maxvalue=0), 0)
    should_not_match(RestrictedInteger(), True, "foo",
                     error="invalid input: data is not an integer")
    should_not_match(RestrictedInteger(minvalue=0), -2**31, -1,
                     code="valuetoolow:data",
                     title="Invalid data parameter",
                     message="invalid input: data must be 0 or higher")
    should_not_match(RestrictedInteger(maxvalue=0), 1, 2**31,
                     code="valuetoohigh:data",
                     title="Invalid data parameter",
                     message="invalid input: data must be 0 or lower")
    should_not_match(RestrictedInteger(minvalue=1, ui_name="gazonk"), 0,
                     code="valuetoolow:data",
                     title="Invalid gazonk parameter",
                     message="invalid input: gazonk must be 1 or higher")

    # Check NonNegativeInteger.
    should_match(NonNegativeInteger, 0, 1, 2**31)
    should_not_match(NonNegativeInteger, True, "foo",
                     error="invalid input: data is not an integer")
    should_not_match(NonNegativeInteger, -2**31, -1,
                     code="valuetoolow:data",
                     title="Invalid data parameter",
                     message="invalid input: data must be 0 or higher")

    # Check PositiveInteger.
    should_match(PositiveInteger, 1, 2**31)
    should_not_match(PositiveInteger, True, "foo",
                     error="invalid input: data is not an integer")
    should_not_match(PositiveInteger, -2**31, -1, 0,
                     code="valuetoolow:data",
                     title="Invalid data parameter",
                     message="invalid input: data must be 1 or higher")

if __name__ == "__main__":
    # sys.path[0] is the directory containing this file.
    sys.path[0] = os.path.dirname(sys.path[0])

    if "basic" in sys.argv[1:]:
        basic()

########NEW FILE########
__FILENAME__ = unittest
import sys
import os

def independence():
    # Simply check that operation can be imported.

    import operation

if __name__ == "__main__":
    # sys.path[0] is the directory containing this file.
    sys.path[0] = os.path.dirname(sys.path[0])

    if "independence" in sys.argv[1:]:
        independence()

########NEW FILE########
__FILENAME__ = usersession
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2012 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

from operation import Operation, OperationResult, OperationError, Request

import dbutils
import configuration
import auth

class ValidateLogin(Operation):
    def __init__(self):
        Operation.__init__(self, { "req": Request,
                                   "username": str,
                                   "password": str },
                           accept_anonymous_user=True)

    def process(self, db, user, req, username, password):
        if not user.isAnonymous():
            if user.name == username:
                return OperationResult()
            else:
                return OperationResult(message="Already signed as '%s'!" % user.name)

        try:
            user = auth.checkPassword(db, username, password)
        except auth.NoSuchUser:
            return OperationResult(message="No such user!")
        except auth.WrongPassword:
            return OperationResult(message="Wrong password!")

        auth.startSession(db, req, user)

        db.commit()

        return OperationResult()

    def sanitize(self, value):
        sanitized = value.copy()
        sanitized["password"] = "****"
        return sanitized

class EndSession(Operation):
    def __init__(self):
        Operation.__init__(self, { "req": Request })

    def process(self, db, user, req):
        cursor = db.cursor()
        cursor.execute("DELETE FROM usersessions WHERE uid=%s", (user.id,))

        db.commit()

        req.deleteCookie("sid")
        req.deleteCookie("has_sid")

        return OperationResult()

########NEW FILE########
__FILENAME__ = addrepository
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2012 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import page.utils
import configuration
import htmlutils
import dbutils

def renderNewRepository(req, db, user):
    if not user.hasRole(db, "repositories"):
        raise page.utils.DisplayMessage(title="Not allowed!", body="Only users with the 'repositories' role can add new repositories.")

    document = htmlutils.Document(req)

    html = document.html()
    head = html.head()
    body = html.body()

    page.utils.generateHeader(body, db, user)

    document.addExternalStylesheet("resource/newrepository.css")
    document.addExternalScript("resource/newrepository.js")

    target = body.div("main")

    basic = target.table("paleyellow")
    basic.col(width='20%')
    basic.col(width='0')
    basic.col(width='40%')
    basic.col(width='40%')
    h1 = basic.tr().td('h1', colspan=4).h1().text("New Repository")

    row = basic.tr("name")
    row.td("heading").text("Short name:")
    row.td("prefix").text()
    row.td("value").input(name="name")
    row.td("suffix").text()

    row = basic.tr("help")
    row.td(colspan=4).text("Repository short name.")

    row = basic.tr("path")
    row.td("heading").text("Path:")
    row.td("prefix").text("%s:%s/" % (configuration.base.HOSTNAME, configuration.paths.GIT_DIR))
    row.td("value").input(name="path")
    row.td("suffix").text(".git")

    row = basic.tr("help")
    row.td(colspan=4).text("Path of repository on the Critic server.")

    row = basic.tr("remote")
    row.td("heading").text("Source repository:")
    row.td("prefix").text()
    row.td("value").input(name="remote")
    row.td("suffix").text("(optional)")

    row = basic.tr("help")
    row.td(colspan=4).text("Git URL of repository to mirror.")

    row = basic.tr("branch")
    row.td("heading").text("Source branch:")
    row.td("prefix").text()
    row.td("value").input(name="branch", value="master", disabled="disabled")
    row.td("suffix").text()

    row = basic.tr("help")
    row.td(colspan=4).text("This branch in the source repository is automatically mirrored in Critic's repository.")

    row = basic.tr("buttons")
    row.td(colspan=4).button("add").text("Add Repository")

    return document

########NEW FILE########
__FILENAME__ = basic
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2012 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

def generateHeader(target, generate_right=generateEmpty):
    row = target.table(width='100%', style='border-bottom: 3px solid black').tr()
    b = row.td(valign='bottom', align='left').b(style='font-family: sans-serif')
    b.b(style='font-size: 40px; color: #d32226; cursor: pointer', onclick="location.href='/';").text("Opera")
    b.b(style='font-size: 50px; color: #666666; cursor: pointer', onclick="location.href='/';").text("Critic")
    generate_right(row.td(valign='bottom', align='right', style='padding-bottom: 10px'))

########NEW FILE########
__FILENAME__ = branches
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2012 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import itertools

import dbutils
import gitutils
import log.html
import htmlutils
import page.utils

def renderBranches(req, db, user):
    offset = req.getParameter("offset", 0, filter=int)
    count = req.getParameter("count", 50, filter=int)

    document = htmlutils.Document(req)

    html = document.html()
    head = html.head()
    body = html.body()

    page.utils.generateHeader(body, db, user, current_page="branches")

    document.addExternalScript("resource/branches.js")
    document.addExternalStylesheet("resource/branches.css")

    cursor = db.cursor()

    repository = req.getParameter("repository", None, gitutils.Repository.FromParameter(db))

    if not repository:
        repository = user.getDefaultRepository(db)

    if repository:
        title = "Branches in %s" % repository.name
        selected = repository.name
    else:
        title = "Branches"
        selected = None

    document.setTitle(title)

    table = body.div("main").table("paleyellow branches", align="center", cellspacing="0")

    row = table.tr("title")
    row.td("h1", colspan=2).h1().text(title)

    page.utils.generateRepositorySelect(db, user, row.td("repositories", colspan=2), selected=selected)

    if repository:
        document.addInternalScript(repository.getJS())

        cursor.execute("""SELECT branches.id, branches.name, branches.base, branches.review,
                                 branches.commit_time, COUNT(reachable.*)
                            FROM (SELECT branches.id AS id, branches.name AS name, bases.name AS base,
                                         branches.review AS review, commits.commit_time AS commit_time
                                    FROM branches
                                    JOIN commits ON (commits.id=branches.head)
                         LEFT OUTER JOIN branches AS bases ON (branches.base=bases.id)
                                   WHERE branches.type='normal'
                                     AND branches.repository=%s
                                ORDER BY commits.commit_time DESC
                                   LIMIT %s
                                   OFFSET %s) AS branches
                 LEFT OUTER JOIN reachable ON (reachable.branch=branches.id)
                        GROUP BY branches.id, branches.name, branches.base, branches.review,
                                 branches.commit_time
                        ORDER BY branches.commit_time DESC""",
                       (repository.id, count, offset))

        branches_found = False

        for branch_id, branch_name, base_name, review_id, commit_time, count in cursor:
            if not branches_found:
                row = table.tr("headings")
                row.td("name").text("Name")
                row.td("base").text("Base")
                row.td("commits").text("Commits")
                row.td("when").text("When")
                branches_found = True

            row = table.tr("branch")

            def link_to_branch(target, repository, name):
                url = htmlutils.URL("/log", branch=name, repository=repository.id)
                target.a(href=url).text(name)

            td_name = row.td("name")
            link_to_branch(td_name, repository, branch_name)

            if review_id is not None:
                span = td_name.span("review").preformatted()
                span.a(href="r/%d" % review_id).text("r/%d" % review_id)
            elif base_name:
                url = htmlutils.URL("/checkbranch",
                                    repository=repository.id,
                                    commit=branch_name,
                                    upstream=base_name,
                                    fetch="no")
                span = td_name.span("check").preformatted().a(href=url).text("check")

            td_base = row.td("base")
            if base_name:
                link_to_branch(td_base, repository, base_name)

            row.td("commits").text(count)

            log.html.renderWhen(row.td("when"), commit_time.timetuple())

        if not branches_found:
            row = table.tr("nothing")
            row.td("nothing", colspan=4).text("No branches")
    else:
        row = table.tr("nothing")
        row.td("nothing", colspan=4).text("No repository selected")

    return document

########NEW FILE########
__FILENAME__ = checkbranch
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2012 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import dbutils
import htmlutils
import page.utils
import gitutils
import re
import log.commitset

def addNote(req, db, user):
    repository_id = req.getParameter("repository", filter=int)
    branch = req.getParameter("branch")
    upstream = req.getParameter("upstream")
    sha1 = req.getParameter("sha1")
    review_id = req.getParameter("review", None)
    text = req.read().strip()

    if review_id is not None:
        review = dbutils.Review.fromId(db, review_id)
    else:
        review = None

    cursor = db.cursor()
    cursor.execute("DELETE FROM checkbranchnotes WHERE repository=%s AND branch=%s AND upstream=%s AND sha1=%s",
                   (repository_id, branch, upstream, sha1))
    cursor.execute("INSERT INTO checkbranchnotes (repository, branch, upstream, sha1, uid, review, text) VALUES (%s, %s, %s, %s, %s, %s, %s)",
                   (repository_id, branch, upstream, sha1, user.id, review_id, text or None))
    db.commit()

    response = "ok"

    if review and review.repository.id == repository_id:
        repository = gitutils.Repository.fromId(db, repository_id)
        commit = gitutils.Commit.fromSHA1(db, repository, sha1)
        commitset = log.commitset.CommitSet(review.branch.commits)

        upstreams = commitset.getFilteredTails(repository)
        if len(upstreams) == 1:
            upstream = upstreams.pop()
            if repository.mergebase([commit.sha1, upstream]) == upstream:
                response = "rebase"

    return response

def deleteNote(req, db, user):
    repository_id = req.getParameter("repository", filter=int)
    branch = req.getParameter("branch")
    upstream = req.getParameter("upstream")
    sha1 = req.getParameter("sha1")

    cursor = db.cursor()
    cursor.execute("DELETE FROM checkbranchnotes WHERE repository=%s AND branch=%s AND upstream=%s AND sha1=%s",
                   (repository_id, branch, upstream, sha1))
    db.commit()

    return "ok"

def renderCheckBranch(req, db, user):
    mode = "html" if req.path == "checkbranch" else "text"

    repository_arg = req.getParameter("repository", None)

    cursor = db.cursor()
    header_right = []

    if mode == "html":
        document = htmlutils.Document(req)

        html = document.html()
        head = html.head()
        body = html.body()

        def generateRight(target):
            header_right.append(target.div("buttons"))

        page.utils.generateHeader(body, db, user, generate_right=generateRight)

        document.addExternalStylesheet("resource/checkbranch.css")
        document.addExternalScript("resource/checkbranch.js")
        document.addInternalScript(user.getJS())

        target = body.div("main")
    else:
        result = ""

    if repository_arg is not None:
        repository = gitutils.Repository.fromParameter(db, repository_arg)
        branch_arg = commit = req.getParameter("commit")
        fetch = req.getParameter("fetch", "no") == "yes"
        upstream_arg = req.getParameter("upstream", "master")

        if mode == "html":
            header_right[0].a("button", href="tutorial?item=checkbranch").text("Help")
            header_right[0].a("button", href="checkbranchtext?repository=%s&commit=%s&upstream=%s" % (repository_arg, branch_arg, upstream_arg)).text("Get Textual Log")
            header_right[0].span("buttonscope buttonscope-global")
            target.addInternalScript(repository.getJS())
            target.addInternalScript("var branch = %r, upstream = %r;" % (branch_arg, upstream_arg))

        upstream = repository.revparse(upstream_arg)

        if fetch:
            if commit.startswith("r/"):
                raise page.utils.DisplayMessage("Won't fetch review branch from remote!")
            repository.updateBranchFromRemote(db, repository.getDefaultRemote(db), commit)

        try: commit = repository.revparse(commit)
        except: raise page.utils.DisplayMessage("Unable to interpret '%s' as a commit reference." % commit)

        try: gitutils.Commit.fromSHA1(db, repository, commit)
        except: raise page.utils.DisplayMessage("'%s' doesn't exist in the repository." % commit)

        if mode == "html":
            document.setTitle("Branch review status: %s" % branch_arg)

        commits = repository.revlist([commit], [upstream], "--topo-order")

        if not commits:
            try: merge_sha1 = repository.revlist([upstream], [commit], "--topo-order", "--ancestry-path")[-1]
            except: raise page.utils.DisplayMessage("No merged or unmerged commits found.")

            merge = gitutils.Commit.fromSHA1(db, repository, merge_sha1)

            if len(merge.parents) == 1:
                candidate_merges = repository.revlist([commit], [], "--topo-order", "--max-count=256")
                for merge_sha1 in candidate_merges:
                    merge = gitutils.Commit.fromSHA1(db, repository, merge_sha1)
                    if len(merge.parents) > 1:
                        use_upstream = merge.parents[1]
                        break
                else:
                    raise page.utils.DisplayMessage("Merge into upstream was a fast-forward; can't figure out what was merged in.")
            else:
                assert commit in merge.parents

                use_upstream = None
                for parent in merge.parents:
                    if parent != commit:
                        use_upstream = parent
                        break

            commits = repository.revlist([commit], [use_upstream], "--topo-order")
            title = "Merged Commits (%d)" % len(commits)
            display_upstream = gitutils.Commit.fromSHA1(db, repository, use_upstream).describe(db)
        else:
            title = "Unmerged Commits (%d)" % len(commits)
            display_upstream = upstream_arg

        commits = [gitutils.Commit.fromSHA1(db, repository, sha1) for sha1 in commits]

        if mode == "html":
            table = target.table("branchstatus paleyellow", align="center", cellspacing=0)
            table.col(width="10%")
            table.col(width="8%")
            table.col(width="77%")
            table.col(width="5%")

            thead = table.thead()
            h1_cell = thead.tr().td('h1', colspan=4)
            h1_cell.h1().text(title)
            p = h1_cell.p()
            p.text("Commits returned by the command: ")
            p.span("command").text("git rev-list --topo-order %s ^%s" % (branch_arg, display_upstream))

            row = thead.tr("headings")
            row.th("sha1").text("SHA-1")
            row.th("user").text("Committer")
            row.th("summary").text("Summary")
            row.th("Review").text("Review")

        cursor.execute("""SELECT sha1, uid, review, text
                            FROM checkbranchnotes
                           WHERE repository=%s
                             AND branch=%s
                             AND upstream=%s""",
                       (repository.id, branch_arg, upstream_arg))

        notes = {}
        reds = False

        for sha1, user_id, review_id, text in cursor:
            notes[sha1] = dbutils.User.fromId(db, user_id), review_id, text

        if commits:
            merged = set(commits)
            handled = set()

            current_tbody = None
            last_tbody = None

            def nameFromEmail(email):
                offset = email.find("@")
                if offset != -1: return email[:offset]
                else: return email

            review = None
            reviewed_commits = []

            text_items = {}
            text_order = []

            for commit in commits:
                if commit not in handled:
                    cursor.execute("""SELECT reviews.id
                                        FROM reviews
                                        JOIN branches ON (branches.id=reviews.branch)
                                        JOIN commits ON (commits.id=branches.head)
                                       WHERE commits.sha1=%s AND reviews.state!='dropped'""",
                                   (commit.sha1,))

                    if commit not in reviewed_commits:
                        review = None

                    reviewed = set()
                    best = 0

                    for (review_id,) in cursor:
                        candidate_review = dbutils.Review.fromId(db, review_id)
                        candidate_reviewed = filter(lambda commit: commit in merged, candidate_review.branch.commits)

                        if len(candidate_reviewed) > best:
                            review = candidate_review
                            reviewed = candidate_reviewed
                            best = len(reviewed)

                        reviewed_commits = filter(lambda commit: commit in reviewed, commits)

                    if mode == "html":
                        if review:
                            current_tbody = None

                            review_tbody = table.tbody("reviewed" if review.state == 'closed' or review.accepted(db) else "pending")
                            first = True

                            review_tbody.tr("empty").td("empty", colspan=4)

                            for reviewed_commit in reviewed_commits:
                                handled.add(reviewed_commit)

                                row = review_tbody.tr("commit")
                                row.td("sha1", title=commit.sha1).div().text(reviewed_commit.sha1[:8])
                                row.td("user").text(nameFromEmail(reviewed_commit.committer.email))
                                row.td("summary").a(href="%s?review=%d" % (reviewed_commit.sha1, review.id)).text(reviewed_commit.niceSummary())

                                if first:
                                    row.td("review", rowspan=len(reviewed)).a(href="r/%d" % review.id).text("r/%d" % review.id)
                                    first = False

                            last_tbody = review_tbody
                        elif commit.sha1 in notes:
                            note_user, review_id, text = notes[commit.sha1]

                            try: review = dbutils.Review.fromId(db, review_id) if review_id else None
                            except: review = None

                            current_tbody = None

                            note_tbody = table.tbody("note" if (not review_id or (review and (review.state == 'closed' or review.accepted(db)))) else "pending")
                            note_tbody.tr("empty").td("empty", colspan=4)

                            row = note_tbody.tr("commit", id=commit.sha1)
                            row.td("sha1", title=commit.sha1).div().text(commit.sha1[:8])
                            row.td("user").text(nameFromEmail(commit.committer.email))
                            row.td("summary").a(href="%s?repository=%d" % (commit.sha1, repository.id)).text(commit.niceSummary())

                            cell = row.td("review")

                            if review_id is None: cell.text()
                            else: cell.a(href="r/%d" % review_id).text("r/%d" % review_id)

                            row = note_tbody.tr("note")
                            row.td("sha1").text()

                            cell = row.td("note", colspan=2)
                            cell.text("Set by ")
                            cell.span("user").text(note_user.fullname)
                            if text is not None:
                                cell.text(": ")
                                cell.span("text").text(text)

                            row.td("edit").a("edit", href="javascript:editCommit(%r, %d, true%s);" % (commit.sha1, commit.getId(db), (", %d" % review_id) if review_id is not None else "")).text("[edit]")

                            last_tbody = note_tbody
                        else:
                            handled.add(commit)

                            if not current_tbody:
                                current_tbody = table.tbody("unknown")
                                current_tbody.tr("empty").td("empty", colspan=4)
                                last_tbody = current_tbody

                            row = current_tbody.tr("commit%s" % (" own" if commit.author.email == user.email else ""), id=commit.sha1)
                            row.td("sha1", title=commit.sha1).div().text(commit.sha1[:8])
                            row.td("user").text(nameFromEmail(commit.committer.email))
                            row.td("summary").a(href="%s/%s" % (repository.name, commit.sha1)).text(commit.niceSummary())
                            row.td("edit").a("edit", href="javascript:editCommit(%r, %d, false);" % (commit.sha1, commit.getId(db))).text("[edit]")

                            reds = True
                    else:
                        match = re.search("[A-Z][A-Z0-9]*-[0-9]+", commit.summary())

                        if match:
                            title = match.group(0)
                        else:
                            title = commit.summary(maxlen=50)
                            if title.endswith(".") and not title.endswith("..."):
                                title = title[:-1]

                        if commit.sha1 in notes:
                            note_user, review_id, text = notes[commit.sha1]
                            if review_id: review = dbutils.Review.fromId(db, review_id)
                        else:
                            text = None

                        if review:
                            item = review.getURL(db)
                            if review.state != "closed" and not review.accepted(db):
                                item += " (NOT ACCEPTED!)"
                            if text:
                                item += " (%s: %s)" % (note_user.fullname, text)
                        elif text:
                            item = "%s: %s" % (note_user.fullname, text)
                        else:
                            item = "REVIEW STATUS UNKNOWN!"

                        if title in text_items:
                            if item not in text_items[title]:
                                text_items[title].append(item)
                        else:
                            text_items[title] = [item]
                            text_order.append(title)

            if mode == "html":
                last_tbody.tr("empty").td("empty", colspan=4)
            else:
                for title in reversed(text_order):
                    result += "%s: %s\n" % (title, ", ".join(text_items[title]))

        if mode == "html":
            if reds:
                h1_cell.h2().text("There should be no red!")

            legend = target.div("legend")
            legend.text("Color legend: ")
            legend.span("red").text("Status unknown")
            legend.text(" ")
            legend.span("yellow").text("Status set manually")
            legend.text(" ")
            legend.span("green").text("Verified by Critic")

            return document
        else:
            return result
    else:
        header_right[0].a("button", href="tutorial?item=checkbranch").text("Help")

        table = page.utils.PaleYellowTable(target, "Check branch review status")

        def renderRepository(target):
            page.utils.generateRepositorySelect(db, user, target, name="repository")
        def renderBranchName(target):
            target.input(name="commit")
        def renderFetch(target):
            target.input(name="fetch", type="checkbox", value="yes")
        def renderUpstream(target):
            target.input(name="upstream", value="master")

        table.addItem("Repository", renderRepository, description="Repository.")
        table.addItem("Branch name", renderBranchName,
                      description="Branch name, or other reference to a commit.")
        table.addItem("Fetch branch from remote", renderFetch,
                      description=("Fetch named branch from selected repository's "
                                   "primary remote (from whence its 'master' branch "
                                   "is auto-updated.)"))
        table.addItem("Upstream", renderUpstream,
                      description="Name of upstream branch.")

        def renderCheck(target):
            target.button("check").text("Check branch")

        table.addCentered(renderCheck)

        return document

########NEW FILE########
__FILENAME__ = config
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2012 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import os

import configuration
import dbutils
import gitutils
import htmlutils
import textutils
import page.utils

def renderConfig(req, db, user):
    highlight = req.getParameter("highlight", None)
    repository = req.getParameter("repository", None, gitutils.Repository.FromParameter(db))
    filter_id = req.getParameter("filter", None, int)
    defaults = req.getParameter("defaults", "no") == "yes"

    if filter_id is not None:
        # There can't be system-wide defaults for one of a single user's
        # filters.
        defaults = False

    cursor = db.cursor()

    if filter_id is not None:
        cursor.execute("""SELECT filters.path, repositories.name
                            FROM filters
                            JOIN repositories ON (repositories.id=filters.repository)
                           WHERE filters.id=%s""",
                       (filter_id,))
        row = cursor.fetchone()
        if not row:
            raise page.utils.InvalidParameterValue(
                name="filter",
                value=str(filter_id),
                expected="valid filter id")
        title = "Filter preferences: %s in %s" % row
    elif repository is not None:
        title = "Repository preferences: %s" % repository.name
    else:
        title = "User preferences"

    document = htmlutils.Document(req)
    document.setTitle(title)

    html = document.html()
    head = html.head()
    body = html.body()

    if user.isAnonymous():
        disabled = "disabled"
    else:
        disabled = None

    def generate_right(target):
        if defaults:
            url = "/config"
            if repository is not None:
                url += "?repository=%d" % repository.id
            target.a("button", href=url).text("Edit Own")
        elif user.hasRole(db, "administrator"):
            url = "/config?defaults=yes"
            if repository is not None:
                url += "&repository=%d" % repository.id
                what = "Repository Defaults"
            else:
                what = "System Defaults"
            target.a("button", href=url).text("Edit " + what)

    injected = page.utils.generateHeader(body, db, user, current_page="config",
                                         generate_right=generate_right)

    document.addExternalStylesheet("resource/config.css")
    document.addExternalScript("resource/config.js")
    document.addInternalScript(user.getJS())
    document.addInternalScript("var repository_id = %s, filter_id = %s, defaults = %s;"
                               % (htmlutils.jsify(repository.id if repository else None),
                                  htmlutils.jsify(filter_id),
                                  htmlutils.jsify(defaults)))

    target = body.div("main")

    table = target.table('preferences paleyellow', align='center', cellspacing=0)
    h1 = table.tr().td('h1', colspan=3).h1()
    h1.text(title)

    if filter_id is None:
        page.utils.generateRepositorySelect(
            db, user, h1.span("right"), allow_selecting_none=True,
            selected=repository.name if repository else False)

    if filter_id is not None:
        conditional = "per_filter"
    elif repository is not None:
        conditional = "per_repository"
    elif defaults:
        conditional = "per_system"
    else:
        conditional = "per_user"

    cursor = db.cursor()
    cursor.execute("""SELECT item, type, description, per_repository, per_filter
                        FROM preferences
                       WHERE %(conditional)s"""
                   % { "conditional": conditional })

    preferences = dict((item, [preference_type, description, None, None, per_repository, per_filter])
                       for item, preference_type, description, per_repository, per_filter in cursor)

    def set_values(rows, is_overrides):
        index = 3 if is_overrides else 2
        for item, integer, string in rows:
            if preferences[item][0] == "boolean":
                preferences[item][index] = bool(integer)
            elif preferences[item][0] == "integer":
                preferences[item][index] = integer
            else:
                preferences[item][index] = string

    cursor.execute("""SELECT item, integer, string
                        FROM userpreferences
                       WHERE item=ANY (%s)
                         AND uid IS NULL
                         AND repository IS NULL""",
                   (preferences.keys(),))

    set_values(cursor, is_overrides=False)

    if repository is not None:
        cursor.execute("""SELECT item, integer, string
                            FROM userpreferences
                           WHERE item=ANY (%s)
                             AND uid IS NULL
                             AND repository=%s""",
                       (preferences.keys(), repository.id))

        # These are overrides if we're editing the defaults for a specific
        # repository.
        set_values(cursor, is_overrides=defaults)

    if not defaults:
        cursor.execute("""SELECT item, integer, string
                            FROM userpreferences
                           WHERE item=ANY (%s)
                             AND uid=%s
                             AND repository IS NULL
                             AND filter IS NULL""",
                       (preferences.keys(), user.id))

        if filter_id is not None or repository is not None:
            # We're looking at per-filter or per-repository settings, so the
            # user's global settings are defaults, not the overrides.  If a
            # per-filter or per-repository override is deleted, the user's
            # global setting kicks in instead.
            set_values(cursor, is_overrides=False)

            if filter_id is not None:
                cursor.execute("""SELECT item, integer, string
                                    FROM userpreferences
                                   WHERE item=ANY (%s)
                                     AND uid=%s
                                     AND filter=%s""",
                               (preferences.keys(), user.id, filter_id))
            else:
                cursor.execute("""SELECT item, integer, string
                                    FROM userpreferences
                                   WHERE item=ANY (%s)
                                     AND uid=%s
                                     AND repository=%s""",
                               (preferences.keys(), user.id, repository.id))

        # Set the overrides.  This is either the user's global settings, if
        # we're not looking at per-filter or per-repository settings, or the
        # user's per-filter or per-repository settings if we are.
        set_values(cursor, is_overrides=True)
    elif repository is None:
        # When editing global defaults, use the values from preferences.json
        # used when initially installing Critic as the default values.
        defaults_path = os.path.join(configuration.paths.INSTALL_DIR,
                                     "data/preferences.json")
        with open(defaults_path) as defaults_file:
            factory_defaults = textutils.json_decode(defaults_file.read())
        for item, data in preferences.items():
            data[3] = data[2]
            if item in factory_defaults:
                data[2] = factory_defaults[item]["default"]
                if data[2] == data[3]:
                    data[3] = None

    if req.getParameter("recalculate", "no") == "yes":
        for item, data in preferences.items():
            if data[2] == data[3]:
                user.setPreference(db, item, None, repository=repository, filter_id=filter_id)
                data[3] = None
        db.commit()

    debug_enabled = user.getPreference(db, "debug.enabled")

    if highlight:
        document.addInternalScript("$(document).ready(function () { location.hash = 'go'; $('#highlight').focus().select(); });")

    for item, (preference_type, description, default_value, current_value, per_repository, per_filter) in sorted(preferences.items()):
        if item.startswith("debug.") and item != "debug.enabled" and not debug_enabled:
            continue

        line_class_name = "line"
        help_class_name = "help"

        highlight_this = highlight == item
        if highlight_this:
            line_class_name += " highlight"
            help_class_name += " highlight"
            input_id = "highlight"
        else:
            input_id = None

        if current_value is None:
            current_value = default_value
        else:
            line_class_name += " customized"

        row = table.tr(line_class_name)
        heading = row.td("heading")
        if highlight_this: heading = heading.a(name="go")
        heading.text("%s:" % item)
        value = row.td("value", colspan=2)
        value.preformatted()

        options = None
        optgroup = None
        def addOption(value, name, selected=lambda value: value==current_value, **attributes):
            (optgroup or options).option(
                value=value, selected="selected" if selected(value) else None,
                **attributes).text(name)

        if preference_type == "boolean":
            value.input(
                "setting", id=input_id, type="checkbox", name=item,
                checked="checked" if current_value else None, disabled=disabled,
                critic_current=htmlutils.jsify(current_value),
                critic_default=htmlutils.jsify(default_value))
        elif preference_type == "integer":
            value.input(
                "setting", id=input_id, type="number", min=0, max=2**31 - 1,
                name=item, value=current_value, disabled=disabled,
                critic_current=htmlutils.jsify(current_value),
                critic_default=htmlutils.jsify(default_value))
        elif item == "defaultRepository":
            page.utils.generateRepositorySelect(
                db, user, value, allow_selecting_none=True,
                placeholder_text="No default repository", selected=current_value,
                id=input_id, name=item, disabled=disabled,
                critic_current=htmlutils.jsify(current_value),
                critic_default=htmlutils.jsify(default_value))
        elif item == "defaultPage":
            options = value.select(
                "setting", id=input_id, name=item, disabled=disabled,
                critic_current=htmlutils.jsify(current_value),
                critic_default=htmlutils.jsify(default_value))

            addOption("home", "Home")
            addOption("dashboard", "Dashboard")
            addOption("branches", "Branches")
            addOption("config", "Config")
            addOption("tutorial", "Tutorial")
        elif item == "email.urlType":
            cursor2 = db.cursor()
            cursor2.execute("""SELECT key, description, authenticated_scheme, hostname
                                 FROM systemidentities
                             ORDER BY description ASC""")

            identities = cursor2.fetchall()
            selected = set(current_value.split(","))

            options = value.select(
                "setting", id=input_id, name=item, size=len(identities),
                multiple="multiple", disabled=disabled,
                critic_current=htmlutils.jsify(current_value),
                critic_default=htmlutils.jsify(default_value))

            for key, label, authenticated_scheme, hostname in identities:
                prefix = "%s://%s/" % (authenticated_scheme, hostname)
                addOption(key, label, selected=lambda value: value in selected,
                          class_="url-type flex",
                          data_text=label,
                          data_html=("<span class=label>%s</span>"
                                     "<span class=prefix>%s</span>"
                                     % (htmlutils.htmlify(label),
                                        htmlutils.htmlify(prefix))))

        elif item == "email.updatedReview.quotedComments":
            options = value.select(
                "setting", id=input_id, name=item, disabled=disabled,
                critic_current=htmlutils.jsify(current_value),
                critic_default=htmlutils.jsify(default_value))

            addOption("all", "All")
            addOption("first", "First")
            addOption("last", "Last")
            addOption("firstlast", "First & Last")
        elif item == "timezone":
            options = value.select(
                "setting", id=input_id, name=item, disabled=disabled,
                critic_current=htmlutils.jsify(current_value),
                critic_default=htmlutils.jsify(default_value))

            for group, zones in dbutils.timezones.sortedTimezones(db):
                optgroup = options.optgroup(label=group)
                for name, abbrev, utc_offset in zones:
                    seconds = utc_offset.total_seconds()
                    offset = "%s%02d:%02d" % ("-" if seconds < 0 else "+", abs(seconds) / 3600, (abs(seconds) % 3600) / 60)
                    addOption("%s/%s" % (group, name), "%s (%s / UTC%s)" % (name, abbrev, offset))
        elif item == "repository.urlType":
            options = value.select(
                "setting", id=input_id, name=item, disabled=disabled,
                critic_current=htmlutils.jsify(current_value),
                critic_default=htmlutils.jsify(default_value))
            long_path = os.path.join(configuration.paths.GIT_DIR, "<path>.git")

            if "git" in configuration.base.REPOSITORY_URL_TYPES:
                addOption("git", "git://%s/<path>.git" % configuration.base.HOSTNAME)
            if "http" in configuration.base.REPOSITORY_URL_TYPES:
                scheme = configuration.base.ACCESS_SCHEME
                if scheme == "both":
                    if user.isAnonymous():
                        scheme = "http"
                    else:
                        scheme = "https"
                addOption("http", "%s://%s/<path>.git" % (scheme, configuration.base.HOSTNAME))
            if "ssh" in configuration.base.REPOSITORY_URL_TYPES:
                addOption("ssh", "ssh://%s%s" % (configuration.base.HOSTNAME, long_path))
            if "host" in configuration.base.REPOSITORY_URL_TYPES:
                addOption("host", "%s:%s" % (configuration.base.HOSTNAME, long_path))
        else:
            value.input(
                "setting", id=input_id, type="text", size=80, name=item,
                value=current_value, disabled=disabled,
                critic_current=htmlutils.jsify(current_value),
                critic_default=htmlutils.jsify(default_value))

        also_configurable_per = []

        if per_repository and repository is None:
            also_configurable_per.append("repository")
        if per_filter and filter_id is None:
            also_configurable_per.append("filter")

        if also_configurable_per:
            value.span("also-configurable-per").text(
                "Also configurable per: %s" % ", ".join(also_configurable_per))

        reset = value.span("reset")
        reset.a(href="javascript:saveSettings(%s);" % htmlutils.jsify(item)).text("[reset to default]")

        cell = table.tr(help_class_name).td("help", colspan=3)

        index = description.find("format string for subject line")
        if index != -1:
            cell.text(description[:index])
            cell.a(href="/tutorial?item=reconfigure#subject_line_formats").text("format string for subject line")
            cell.text(description[index + len("format string for subject line"):])
        else:
            cell.text(description)

    if injected and injected.has_key("preferences") \
            and not defaults \
            and repository is None \
            and filter_id is None:
        for extension_name, author, preferences in injected["preferences"]:
            h2 = table.tr("extension").td("extension", colspan=3).h2()
            h2.span("name").text(extension_name)
            h2.text(" by ")
            h2.span("author").text(author.fullname)

            for preference in preferences:
                preference_url = preference["url"]
                preference_name = preference["name"]
                preference_type = preference["type"]
                preference_value = preference["value"]
                preference_default = preference["default"]
                preference_description = preference["description"]

                line_class_name = "line"
                help_class_name = "help"

                highlight_this = highlight == ("%s/%s/%s" % (author.name, extension_name, preference_name))
                if highlight_this:
                    line_class_name += " highlight"
                    help_class_name += " highlight"
                    input_id = "highlight"
                else:
                    input_id = None

                if preference_value != preference_default:
                    line_class_name += " customized"

                row = table.tr(line_class_name)
                heading = row.td("heading")
                if highlight_this: heading = heading.a(name="go")
                heading.text("%s:" % preference_name)
                value = row.td("value", colspan=2)
                value.preformatted()

                if preference_type == "boolean":
                    value.input(
                        "setting", id=input_id, type="checkbox",
                        name=preference_name, disabled=disabled,
                        checked="checked" if preference_value else None,
                        critic_url=preference_url,
                        critic_default=htmlutils.jsify(bool(preference_value)),
                        critic_extension=extension_name)
                elif preference_type == "integer":
                    value.input(
                        "setting", id=input_id, type="number", min=0,
                        name=preference_name, value=preference_value,
                        disabled=disabled, critic_url=preference_url,
                        critic_default=htmlutils.jsify(preference_default),
                        critic_extension=extension_name)
                elif preference_type == "string":
                    value.input(
                        "setting", id=input_id, type="text",
                        name=preference_name, value=preference_value,
                        disabled=disabled, critic_url=preference_url,
                        critic_default=htmlutils.jsify(preference_default),
                        critic_extension=extension_name)
                else:
                    select = value.select(
                        "setting", id=input_id, name=preference_name,
                        disabled=disabled, critic_url=preference_url,
                        critic_value=preference_value,
                        critic_default=htmlutils.jsify(preference_default),
                        critic_extension=extension_name)

                    for choice in preference_type:
                        select.option(value=choice["value"], selected="selected" if preference_value == choice["value"] else None).text(choice["title"])

                cell = table.tr(help_class_name).td("help", colspan=3)
                cell.text(preference_description)

    critic_installed_sha1 = dbutils.getInstalledSHA1(db)
    div = body.div("installed_sha1")
    div.text("Critic version: ")
    div.a(href="https://critic-review.org/critic/%s" % critic_installed_sha1).text(critic_installed_sha1)

    return document

########NEW FILE########
__FILENAME__ = confirmmerge
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2012 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import dbutils
import htmlutils
import gitutils

import page.utils
import log.html
import log.commitset

def renderConfirmMerge(req, db, user):
    confirmation_id = req.getParameter("id", filter=int)
    tail_sha1 = req.getParameter("tail", None)
    do_confirm = req.getParameter("confirm", "no") == "yes"
    do_cancel = req.getParameter("cancel", "no") == "yes"

    cursor = db.cursor()

    cursor.execute("SELECT review, uid, merge, confirmed, tail FROM reviewmergeconfirmations WHERE id=%s", (confirmation_id,))
    row = cursor.fetchone()
    if not row:
        raise page.utils.DisplayMessage("No pending merge with that id.")
    review_id, user_id, merge_id, confirmed, tail_id = row

    review = dbutils.Review.fromId(db, review_id)
    merge = gitutils.Commit.fromId(db, review.repository, merge_id)

    if confirmed and tail_id is not None:
        tail_sha1 = gitutils.Commit.fromId(db, review.repository, tail_id).sha1

    cursor.execute("SELECT merged FROM reviewmergecontributions WHERE id=%s", (confirmation_id,))

    merged = [gitutils.Commit.fromId(db, review.repository, merged_id) for (merged_id,) in cursor]
    merged_set = log.commitset.CommitSet(merged)

    if tail_sha1 is not None:
        tail = gitutils.Commit.fromSHA1(db, review.repository, tail_sha1)
        tail_id = tail.getId(db)

        cut = [gitutils.Commit.fromSHA1(db, review.repository, sha1)
               for sha1 in tail.parents if sha1 in merged_set]
        merged_set = merged_set.without(cut)
        merged = list(merged_set)
    else:
        tail_id = None

    if do_confirm:
        cursor.execute("UPDATE reviewmergeconfirmations SET confirmed=TRUE, tail=%s WHERE id=%s", (tail_id, confirmation_id))
        db.commit()
    elif do_cancel:
        cursor.execute("DELETE FROM reviewmergeconfirmations WHERE id=%s", (confirmation_id,))
        db.commit()

    document = htmlutils.Document(req)

    html = document.html()
    head = html.head()
    body = html.body()

    def renderButtons(target):
        if not do_confirm and not do_cancel:
            target.button("confirmAll").text("Confirm (merge + contributed)")
            target.button("confirmNone").text("Confirm (merge only)")
            target.button("cancel").text("Cancel")

    page.utils.generateHeader(body, db, user, renderButtons, extra_links=[("r/%d" % review.id, "Back to Review")])

    document.addExternalStylesheet("resource/confirmmerge.css")
    document.addExternalScript("resource/log.js")
    document.addExternalScript("resource/confirmmerge.js")
    document.addInternalScript(user.getJS())
    document.addInternalScript(review.getJS())
    document.addInternalScript("var confirmation_id = %d;" % confirmation_id)
    document.addInternalScript("var merge_sha1 = %s;" % htmlutils.jsify(merge.sha1))

    if tail_sha1 is not None:
        document.addInternalScript("var tail_sha1 = %s;" % htmlutils.jsify(tail_sha1))

    if not do_confirm and not do_cancel:
        heads = merged_set.getHeads()
        if heads:
            document.addInternalScript("var automaticAnchorCommit = %s;" % htmlutils.jsify(heads.pop().sha1))
        else:
            document.addInternalScript("var automaticAnchorCommit = null;")

    if do_confirm:
        document.addInternalScript("var confirmed = true;")
    else:
        document.addInternalScript("var confirmed = false;")

    target = body.div("main")

    basic = target.table("paleyellow")
    basic.col(width='15%')
    basic.col(width='55%')
    basic.col(width='30%')
    h1 = basic.tr().td('h1', colspan=3).h1()

    if do_confirm:
        h1.text("CONFIRMED MERGE")
    elif do_cancel:
        h1.text("CANCELLED MERGE")
    else:
        h1.text("Confirm Merge")

    row = basic.tr("sha1")
    row.td("heading").text("SHA-1:")
    row.td("value").preformatted().text(merge.sha1)
    row.td().text()

    row = basic.tr("message")
    row.td("heading").text("Message:")
    row.td("value").preformatted().text(merge.message)
    row.td().text()

    if not do_confirm and not do_cancel:
        row = basic.tr("instructions")
        row.td("heading").text("Instructions:")
        row.td("value").preformatted().text("""\
Use the top right buttons to confirm the merge with or without the contributed commits that it brings.

By clicking 'Confirm (merge + contributed)' you will bring the merge commit plus all commits that it contributes into the this code review.

By clicking 'Confirm (merge only)' you will bring only the merge commit itself into the code review and not the contributed commits."

By clicking 'Cancel' you will abort the merge. The code review will not be modified at all from its current state.""")
        row.td().text()


    if merged:
        columns = [(10, log.html.WhenColumn()),
                   (60, log.html.SummaryColumn()),
                   (16, log.html.AuthorColumn())]

        log.html.render(db, target, "Contributed Commits", commits=merged, columns=columns)

    return document

########NEW FILE########
__FILENAME__ = createreview
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2012 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import itertools
import re

import dbutils
import gitutils
import reviewing.utils
import log.html
import htmlutils
import page.utils
import diff
import configuration
import linkify
import changeset.utils as changeset_utils

from textutils import json_decode, json_encode

def generateReviewersAndWatchersTable(db, repository, target, all_reviewers, all_watchers, applyfilters=True, applyparentfilters=False):
    cursor = db.cursor()
    teams = reviewing.utils.collectReviewTeams(all_reviewers)

    reviewers = set()
    watchers = set()

    for file_id, file_reviewers in all_reviewers.items():
        for user_id in file_reviewers:
            reviewers.add(user_id)

    for file_id, file_watchers in all_watchers.items():
        for user_id in file_watchers:
            if user_id not in reviewers:
                watchers.add(user_id)

    table = target.table("filters paleyellow", align="center")
    table.tr().td("h1", colspan=3).h1().text("Reviewers and Watchers")

    row = table.tr("applyfilters")
    row.td("value").input("applyfilters", type="checkbox", checked=("checked" if applyfilters else None))
    row.td("legend", colspan=2).text("Apply global filters. Only disable this in inofficial reviews!")

    table.tr("watchers").td("spacer", colspan=3)

    if repository.parent and applyfilters:
        parent = repository.parent
        parents = []

        while parent:
            parents.append(parent.name)
            parent = parent.parent

        if len(parents) == 1: parents = "repository (%s)" % parents[0]
        else: parents = "repositories (%s)" % ", ".join(parents)

        row = table.tr("applyfilters")
        row.td("value").input("applyparentfilters", type="checkbox", checked=("checked" if applyparentfilters else None))
        row.td("legend", colspan=2).text("Apply global filters from upstream %s." % parents)

        table.tr("watchers").td("spacer", colspan=3)

    def formatFiles(files):
        return diff.File.eliminateCommonPrefixes(sorted([dbutils.describe_file(db, file_id) for file_id in files]))

    for team in teams:
        if team is not None:
            row = table.tr("reviewers")

            cell = row.td("reviewers")
            users = sorted([dbutils.User.fromId(db, user_id).fullname for user_id in team])
            for user in users: cell.text(user).br()
            row.td("willreview").innerHTML("will&nbsp;review")

            cell = row.td("files")
            for file in formatFiles(teams[team]):
                cell.span("file").innerHTML(file).br()

    if None in teams:
        row = table.tr("reviewers")
        row.td("no-one", colspan=2).text("No reviewers found for changes in")

        cell = row.td("files")
        for file in formatFiles(teams[None]):
            cell.span("file").innerHTML(file).br()

    if watchers:
        table.tr("watchers").td("spacer", colspan=3)

        row = table.tr("watchers")
        row.td("heading", colspan=2).text("Watchers")
        cell = row.td("watchers")
        for user_id in watchers: cell.text(dbutils.User.fromId(db, user_id).fullname).br()

    table.tr("buttons").td("spacer", colspan=3)

    buttons = table.tr("buttons").td("buttons", colspan=3)
    buttons.button(onclick="addReviewer();").text("Add Reviewer")
    buttons.button(onclick="addWatcher();").text("Add Watcher")

def renderSelectSource(req, db, user):
    cursor = db.cursor()

    document = htmlutils.Document(req)
    html = document.html()
    head = html.head()
    body = html.body()

    page.utils.generateHeader(body, db, user, current_page="createreview")

    document.addExternalStylesheet("resource/createreview.css")
    document.addExternalScript("resource/createreview.js")
    document.addExternalScript("resource/autocomplete.js")

    document.addInternalScript(user.getJS(db))
    document.setTitle("Create Review")

    target = body.div("main")
    table = page.utils.PaleYellowTable(target, "Create Review")
    table.titleRight.innerHTML("Step 1")

    default_repository = user.getPreference(db, "defaultRepository")
    default_remotes = {}
    default_branches = {}

    def renderLocalRepository(target):
        page.utils.generateRepositorySelect(db, user, target)

        cursor.execute("""SELECT repositories.id, repositories.name, repositories.path, branches.name
                            FROM repositories
                 LEFT OUTER JOIN branches ON (branches.id=repositories.branch)
                        ORDER BY id""")

        for repository_id, name, path, branch_name in cursor.fetchall():
            local_names = ["*"]

            if branch_name:
                local_names.append(branch_name)

            cursor.execute("""SELECT remote
                                FROM trackedbranches
                               WHERE repository=%s
                                 AND local_name=ANY (%s)
                            ORDER BY local_name
                               LIMIT 1""",
                           (repository_id, local_names))

            row = cursor.fetchone()

            if row: default_remotes[name] = row[0]
            else: default_remotes[name] = None

            default_branches[name] = branch_name

        document.addInternalScript("var default_remotes = %s;" % json_encode(default_remotes))
        document.addInternalScript("var default_branches = %s;" % json_encode(default_branches))

    def renderRemoteRepository(target):
        target.input("remote", value=default_remotes.get(default_repository))

    def renderWorkBranch(target):
        target.text("refs/heads/")
        target.input("workbranch")

    def renderUpstreamCommit(target):
        default_branch = default_branches.get(default_repository)
        target.input("upstreamcommit", value=("refs/heads/%s" % default_branch) if default_branch else "")

    table.addItem("Local Repository", renderLocalRepository, "Critic repository to create review in.")
    table.addItem("Remote Repository", renderRemoteRepository, "Remote repository to fetch commits from.")
    table.addItem("Work Branch", renderWorkBranch, "Work branch (in remote repository) containing commits to create review of.")
    table.addItem("Upstream Commit", renderUpstreamCommit, "Upstream commit from which the work branch was branched.")

    def renderButtons(target):
        target.button("fetchbranch").text("Fetch Branch")

    table.addCentered(renderButtons)

    return document

def renderCreateReview(req, db, user):
    if user.isAnonymous(): raise page.utils.NeedLogin(req)

    repository = req.getParameter("repository", filter=gitutils.Repository.FromParameter(db), default=None)
    applyparentfilters = req.getParameter("applyparentfilters", "yes" if user.getPreference(db, 'review.applyUpstreamFilters') else "no") == "yes"

    cursor = db.cursor()

    if req.method == "POST":
        data = json_decode(req.read())

        summary = data.get("summary")
        description = data.get("description")
        review_branch_name = data.get("review_branch_name")
        commit_ids = data.get("commit_ids")
        commit_sha1s = data.get("commit_sha1s")
    else:
        summary = req.getParameter("summary", None)
        description = req.getParameter("description", None)
        review_branch_name = req.getParameter("reviewbranchname", None)

        commit_ids = None
        commit_sha1s = None

        commits_arg = req.getParameter("commits", None)
        remote = req.getParameter("remote", None)
        upstream = req.getParameter("upstream", "master")
        branch_name = req.getParameter("branch", None)

        if commits_arg:
            try: commit_ids = map(int, commits_arg.split(","))
            except: commit_sha1s = [repository.revparse(ref) for ref in commits_arg.split(",")]
        elif branch_name:
            cursor.execute("""SELECT commit
                                FROM reachable
                                JOIN branches ON (branch=id)
                               WHERE repository=%s
                                 AND name=%s""",
                           (repository.id, branch_name))
            commit_ids = [commit_id for (commit_id,) in cursor]

            if len(commit_ids) > configuration.limits.MAXIMUM_REVIEW_COMMITS:
                raise page.utils.DisplayMessage(
                    "Too many commits!",
                    (("<p>The branch <code>%s</code> contains %d commits.  Reviews can"
                      "be created from branches that contain at most %d commits.</p>"
                      "<p>This limit can be adjusted by modifying the system setting"
                      "<code>configuration.limits.MAXIMUM_REVIEW_COMMITS</code>.</p>")
                     % (htmlutils.htmlify(branch_name), len(commit_ids),
                        configuration.limits.MAXIMUM_REVIEW_COMMITS)),
                    html=True)
        else:
            return renderSelectSource(req, db, user)

    req.content_type = "text/html; charset=utf-8"

    if commit_ids:
        commits = [gitutils.Commit.fromId(db, repository, commit_id) for commit_id in commit_ids]
    elif commit_sha1s:
        commits = [gitutils.Commit.fromSHA1(db, repository, commit_sha1) for commit_sha1 in commit_sha1s]
    else:
        commits = []

    if not commit_ids:
        commit_ids = [commit.getId(db) for commit in commits]
    if not commit_sha1s:
        commit_sha1s = [commit.sha1 for commit in commits]

    if summary is None:
        if len(commits) == 1:
            summary = commits[0].summary()
        else:
            summary = ""

    if review_branch_name:
        invalid_branch_name = "false"
        default_branch_name = review_branch_name
    else:
        invalid_branch_name = htmlutils.jsify(user.name + "/")
        default_branch_name = user.name + "/"

        match = re.search("(?:^|[Ff]ix(?:e[ds])?(?: +for)?(?: +bug)? +)([A-Z][A-Z0-9]+-[0-9]+)", summary)
        if match:
            invalid_branch_name = "false"
            default_branch_name = htmlutils.htmlify(match.group(1))

    changesets = []
    changeset_utils.createChangesets(db, repository, commits)
    for commit in commits:
        changesets.extend(changeset_utils.createChangeset(db, None, repository, commit, do_highlight=False))
    changeset_ids = [changeset.id for changeset in changesets]

    all_reviewers, all_watchers = reviewing.utils.getReviewersAndWatchers(
        db, repository, changesets=changesets, applyparentfilters=applyparentfilters)

    document = htmlutils.Document(req)
    html = document.html()
    head = html.head()

    document.addInternalScript(user.getJS(db))

    if branch_name:
        document.addInternalScript("var fromBranch = %s;" % htmlutils.jsify(branch_name))

    if remote:
        document.addInternalScript("var trackedbranch = { remote: %s, name: %s };" % (htmlutils.jsify(remote), htmlutils.jsify(branch_name)))

    head.title().text("Create Review")

    body = html.body(onload="document.getElementById('branch_name').focus()")

    page.utils.generateHeader(body, db, user, lambda target: target.button(onclick="submitReview();").text("Submit Review"))

    document.addExternalStylesheet("resource/createreview.css")
    document.addExternalScript("resource/createreview.js")
    document.addExternalScript("resource/reviewfilters.js")
    document.addExternalScript("resource/autocomplete.js")

    document.addInternalScript("""
var invalid_branch_name = %s;
var review = { commit_ids: %r,
               commit_sha1s: %r,
               changeset_ids: %r };""" % (invalid_branch_name, commit_ids, commit_sha1s, changeset_ids))
    document.addInternalScript(repository.getJS())

    main = body.div("main")

    table = main.table("basic paleyellow", align="center")
    table.tr().td("h1", colspan=3).h1().text("Create Review")

    row = table.tr("line")
    row.td("heading").text("Branch Name:")
    row.td("value").text("r/").input("value", id="branch_name", value=default_branch_name)
    row.td("status")

    row = table.tr()

    if not remote:
        row.td("help", colspan=3).div().text("""\
This is the main identifier of the review.  It will be created in the review
repository to contain the commits below.  Reviewers can fetch it from there, and
additional commits can be added to the review later by pushing them to this
branch in the review repository.""")
    else:
        row.td("help", colspan=3).div().text("""\
This is the main identifier of the review.  It will be created in the review
repository to contain the commits below, and reviewers can fetch it from there.""")

    if remote:
        row = table.tr("line")
        row.td("heading").text("Tracked Branch:")
        value = row.td("value")
        value.code("branch inset").text(branch_name, linkify=linkify.Context(remote=remote))
        value.text(" in ")
        value.code("remote inset").text(remote, linkify=linkify.Context())
        row.td("status")

        row = table.tr()
        row.td("help", colspan=3).div().text("""\
Rather than pushing directly to the review branch in Critic's repository to add
commits to the review, you will be pushing to this branch (in a separate
repository,) from which Critic will fetch commits and add them to the review
automatically.""")

    row = table.tr("line")
    row.td("heading").text("Summary:")
    row.td("value").input("value", id="summary", value=summary)
    row.td("status")

    row = table.tr()
    row.td("help", colspan=3).div().text("""\
The summary should be a short summary of the changes in the review.  It will
appear in the subject of all emails sent about the review.
""")

    row = table.tr("line description")
    row.td("heading").text("Description:")
    textarea = row.td("value").textarea(id="description", rows=12)
    textarea.preformatted()
    if description: textarea.text(description)
    row.td("status")

    row = table.tr()
    row.td("help", colspan=3).div().text("""\
The description should describe the changes to be reviewed.  It is usually fine
to leave the description empty, since the commit messages are also available in
the review.
""")

    generateReviewersAndWatchersTable(db, repository, main, all_reviewers, all_watchers, applyparentfilters=applyparentfilters)

    row = table.tr("line recipients")
    row.td("heading").text("Recipient List:")
    cell = row.td("value", colspan=2).preformatted()
    cell.span("mode").text("Everyone")
    cell.span("users")
    cell.text(".")
    buttons = cell.div("buttons")
    buttons.button(onclick="editRecipientList();").text("Edit Recipient List")

    row = table.tr()
    row.td("help", colspan=3).div().text("""\
The basic recipient list for e-mails sent about the review.
""")

    log.html.render(db, main, "Commits", commits=commits)

    return document

########NEW FILE########
__FILENAME__ = createuser
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2014 the Critic contributors, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import htmlutils
import page
import auth
import dbutils
import configuration

from page.parameters import Optional

class CreateUserHandler(page.Page.Handler):
    def __init__(self, target=None, username=None, email=None, fullname=None,
                 provider=None, account=None, token=None):
        super(CreateUserHandler, self).__init__()

        self.target = target
        self.username = username
        self.email = email
        self.fullname = fullname
        self.provider = provider
        self.account = account
        self.token = token

    def generateHeader(self):
        self.document.addExternalStylesheet("resource/createuser.css")
        self.document.addExternalScript("resource/createuser.js")

        if self.target:
            self.document.addInternalScript(
                "var target = %s;" % htmlutils.jsify(self.target))

    def generateContent(self):
        table = page.utils.PaleYellowTable(self.body, "Create user")

        if self.provider and self.token and self.provider in auth.PROVIDERS:
            provider = auth.PROVIDERS[self.provider]
            if not provider.validateToken(self.db, self.account, self.token):
                raise page.utils.DisplayMessage("Invalid OAuth2 token")
            allow_user_registration = \
                provider.configuration.get("allow_user_registration", False)
        else:
            provider = None
            allow_user_registration = configuration.base.ALLOW_USER_REGISTRATION

        if not allow_user_registration:
            administrators = dbutils.getAdministratorContacts(
                self.db, as_html=True)
            raise page.utils.DisplayMessage(
                title="User registration not enabled",
                body=(("<p>The administrator of this system has not enabled "
                       "registration of new users.</p>"
                       "<p>Contact %s if you want to use this system.</p>")
                      % administrators),
                html=True)

        def render(target):
            table = target.table("createuser", align="center")

            def header(label):
                row = table.tr("header")
                row.td(colspan=2).text(label)

            def item(key):
                row = table.tr("item")
                row.td("key").text("%s:" % key)
                return row.td("value")

            def button(class_name):
                row = table.tr("button")
                return row.td(colspan=2).button(class_name)

            def separator():
                table.tr("separator1").td(colspan=2)
                table.tr("separator2").td(colspan=2)

            if provider:
                self.document.addInternalScript(
                    "var external = { provider: %s, account: %s, token: %s };"
                    % (htmlutils.jsify(self.provider),
                       htmlutils.jsify(self.account),
                       htmlutils.jsify(self.token)))

                url = provider.getAccountURL(self.account)
                item(provider.getTitle()).a("external", href=url).text(self.account)
                separator()
            else:
                self.document.addInternalScript("var external = null;")

            message = table.tr("status disabled").td(colspan=2).div("message")

            if self.username:
                try:
                    dbutils.User.fromName(self.db, self.username)
                except dbutils.NoSuchUser:
                    try:
                        auth.validateUserName(self.username)
                    except auth.InvalidUserName as error:
                        message.u("Invalid user name")
                        message.br()
                        message.text(str(error))
                else:
                    message.text("A user named '%s' already exists!"
                                 % self.username)

            item("New user name").input(id="newusername", value=self.username, size=40)
            item("Display name").input(id="fullname", value=self.fullname, size=40)
            item("Email").input(id="email", value=self.email, size=40)

            if not provider:
                separator()

                item("Password").input(id="password1", type="password", size=40)
                item("Password (again)").input(id="password2", type="password", size=40)

            button("create").text("Create user")

        table.addCentered(render)

class CreateUser(page.Page):
    def __init__(self):
        super(CreateUser, self).__init__("createuser",
                                         { "target": Optional(str),
                                           "username": Optional(str),
                                           "email": Optional(str),
                                           "fullname": Optional(str),
                                           "provider": Optional(str),
                                           "account": Optional(str),
                                           "token": Optional(str) },
                                         CreateUserHandler)

########NEW FILE########
__FILENAME__ = dashboard
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2012 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import dbutils
import gitutils
import htmlutils
import profiling
import page.utils

def renderDashboard(req, db, user):
    if user.isAnonymous(): default_show = "open"
    else: default_show = user.getPreference(db, "dashboard.defaultGroups")

    show = req.getParameter("show", default_show)

    if user.isAnonymous():
        def possible(group):
            return group in ("open", "closed")
    else:
        def possible(group):
            return True

    showlist = filter(possible, show.split(","))
    showset = set(showlist)

    if user.getPreference(db, "commit.diff.compactMode"): default_compact = "yes"
    else: default_compact = "no"

    repository_arg = req.getParameter("repository", None)
    repository = gitutils.Repository.fromParameter(db, repository_arg) if repository_arg else None
    compact = req.getParameter("compact", default_compact) == "yes"

    cursor = db.cursor()

    profiler = profiling.Profiler()
    document = htmlutils.Document(req)

    document.setTitle("Dashboard")

    html = document.html()
    head = html.head()
    body = html.body()

    def generateRight(target):
        def addLink(key, title=None):
            if not title: title = key
            if key not in showset:
                target.text("[")
                target.a(href="dashboard?show=%s" % ",".join(showlist + [key])).text("show %s" % title)
                target.text("]")

        if user.isAnonymous():
            addLink("open", "open")
            addLink("closed")
        else:
            target.text("[")
            target.a(href="config?highlight=dashboard.defaultGroups").text("configure defaults")
            target.text("]")

            addLink("owned")
            addLink("draft")
            addLink("active")
            addLink("watched")
            addLink("open", "other open")
            addLink("closed")

    page.utils.generateHeader(body, db, user, current_page="dashboard", generate_right=generateRight, profiler=profiler)

    document.addExternalStylesheet("resource/dashboard.css")
    document.addExternalScript("resource/dashboard.js")
    document.addInternalScript(user.getJS())

    target = body.div("main")

    def flush(target):
        return document.render(stop=target, pretty=not compact)

    def includeReview(review_id):
        if repository:
            cursor = db.cursor()
            cursor.execute("SELECT branches.repository FROM branches JOIN reviews ON (reviews.branch=branches.id) WHERE reviews.id=%s", (review_id,))
            return cursor.fetchone()[0] == repository.id
        else:
            return True

    def sortedReviews(data):
        reviews = []
        for review_id in sorted(data.keys()):
            reviews.append((review_id, data[review_id]))
        return reviews

    def isAccepted(review_ids):
        cursor.execute("""SELECT reviews.id, COUNT(reviewfiles.id)=0 AND COUNT(commentchains.id)=0
                            FROM reviews
                 LEFT OUTER JOIN reviewfiles ON (reviewfiles.review=reviews.id
                                             AND reviewfiles.state='pending')
                 LEFT OUTER JOIN commentchains ON (commentchains.review=reviews.id
                                               AND commentchains.type='issue'
                                               AND commentchains.state='open')
                           WHERE reviews.id=ANY (%s)
                        GROUP BY reviews.id""",
                       (review_ids,))

        return dict(cursor)

    def renderReviews(target, reviews, lines_and_comments=True, links=True):
        cursor.execute("SELECT id, name FROM branches WHERE id=ANY (%s)",
                       (list(branch_id for _, (_, branch_id, _, _) in reviews),))

        branch_names = dict(cursor)

        for review_id, (summary, branch_id, lines, comments) in reviews:
            row = target.tr("review")
            row.td("name").text(branch_names[branch_id])
            row.td("title").a(href="r/%d" % review_id).text(summary)

            if lines_and_comments:
                if lines:
                    if links:
                        row.td("lines").a(href="showcommit?review=%d&filter=pending" % review_id).text("%d lines" % (sum(lines)))
                    else:
                        row.td("lines").text("%d lines" % (sum(lines)))
                else: row.td("lines").text()
                if comments:
                    if links:
                        row.td("comments").a(href="showcomments?review=%s&filter=toread" % review_id).text("%d comment%s" % (comments, "s" if comments > 1 else ""))
                    else:
                        row.td("comments").text("%d comment%s" % (comments, "s" if comments > 1 else ""))
                else: row.td("comments").text()

    def hidden(what):
        new_show = ",".join(filter(lambda item: item != what, showlist))
        if new_show: return "dashboard?show=%s" % new_show
        else: return "dashboard"

    profiler.check("generate: prologue")

    def renderOwned():
        owned_accepted = []
        owned_open = []

        cursor.execute("""SELECT id, summary, branch
                            FROM reviews
                            JOIN reviewusers ON (review=id AND reviewusers.owner)
                           WHERE state='open'
                             AND uid=%s
                        ORDER BY id DESC""",
                       (user.id,))

        owned = cursor.fetchall()

        profiler.check("query: owned")

        is_accepted = isAccepted(list(review_id for review_id, _, _ in owned))

        for review_id, summary, branch_id in owned:
            if includeReview(review_id):
                if is_accepted[review_id]:
                    owned_accepted.append((review_id, (summary, branch_id, None, None)))
                else:
                    owned_open.append((review_id, (summary, branch_id, None, None)))

        profiler.check("processing: owned")

        if owned_accepted or owned_open:
            table = target.table("paleyellow reviews", id="owned", align="center", cellspacing=0)
            table.col(width="15%")
            table.col(width="55%")
            table.col(width="15%")
            table.col(width="15%")
            header = table.tr().td("h1", colspan=4).h1()
            header.text("Owned By You")
            header.span("right").a(href=hidden("owned")).text("[hide]")

            if owned_accepted:
                table.tr(id="accepted").td("h2", colspan=4).h2().text("Accepted")
                renderReviews(table, owned_accepted)

            if owned_open:
                table.tr(id="open").td("h2", colspan=4).h2().text("Pending")
                renderReviews(table, owned_open)

            profiler.check("generate: owned")
            return True

    def renderDraft():
        draft_changes = {}
        draft_comments = {}
        draft_both = {}

        cursor.execute("""SELECT reviews.id, reviews.summary, reviews.branch, SUM(reviewfiles.deleted), SUM(reviewfiles.inserted)
                            FROM reviews
                            JOIN reviewfiles ON (reviewfiles.review=reviews.id)
                            JOIN reviewfilechanges ON (reviewfilechanges.file=reviewfiles.id)
                           WHERE reviews.state='open'
                             AND reviewfiles.state=reviewfilechanges.from
                             AND reviewfilechanges.state='draft'
                             AND reviewfilechanges.uid=%s
                        GROUP BY reviews.id, reviews.summary, reviews.branch""",
                       (user.id,))

        profiler.check("query: draft lines")

        for review_id, summary, branch_id, deleted_count, inserted_count in cursor:
            if includeReview(review_id):
                draft_changes[review_id] = (summary, branch_id, (deleted_count, inserted_count), None)

        profiler.check("processing: draft lines")

        cursor.execute("""SELECT reviews.id, reviews.summary, reviews.branch, COUNT(comments.id)
                            FROM reviews
                            JOIN commentchains ON (commentchains.review=reviews.id)
                            JOIN comments ON (comments.chain=commentchains.id)
                           WHERE comments.state='draft'
                             AND comments.uid=%s
                        GROUP BY reviews.id, reviews.summary, reviews.branch""",
                       [user.id])

        profiler.check("query: draft comments")

        for review_id, summary, branch_id, comments_count in cursor:
            if includeReview(review_id):
                if draft_changes.has_key(review_id):
                    draft_both[review_id] = (summary, branch_id, draft_changes[review_id][2], comments_count)
                    del draft_changes[review_id]
                else:
                    draft_comments[review_id] = (summary, branch_id, None, comments_count)

        profiler.check("processing: draft comments")

        if draft_both or draft_changes or draft_comments:
            table = target.table("paleyellow reviews", id="draft", align="center", cellspacing=0)
            table.col(width="15%")
            table.col(width="55%")
            table.col(width="15%")
            table.col(width="15%")
            header = table.tr().td("h1", colspan=4).h1()
            header.text("Reviews With Unsubmitted Work")
            header.span("right").a(href=hidden("draft")).text("[hide]")

            if draft_both:
                table.tr(id="draft-changes-comments").td("h2", colspan=4).h2().text("Draft Changes And Comments")
                renderReviews(table, sortedReviews(draft_both), links=False)

            if draft_changes:
                table.tr(id="draft-changes").td("h2", colspan=4).h2().text("Draft Changes")
                renderReviews(table, sortedReviews(draft_changes), links=False)

            if draft_comments:
                table.tr(id="draft-comments").td("h2", colspan=4).h2().text("Draft Comments")
                renderReviews(table, sortedReviews(draft_comments), links=False)

            profiler.check("generate: draft")
            return True

    active = {}

    def fetchActive():
        if not active:
            with_changes = {}
            with_comments = {}
            with_both = {}

            cursor.execute("""SELECT reviews.id, reviews.summary, reviews.branch, SUM(reviewfiles.deleted), SUM(reviewfiles.inserted)
                                FROM reviews
                                JOIN reviewusers ON (reviewusers.review=reviews.id
                                                 AND reviewusers.uid=%s)
                                JOIN reviewfiles ON (reviewfiles.review=reviews.id)
                                JOIN reviewuserfiles ON (reviewuserfiles.file=reviewfiles.id
                                                     AND reviewuserfiles.uid=%s)
                               WHERE reviews.state='open'
                                 AND reviewfiles.state='pending'
                            GROUP BY reviews.id, reviews.summary, reviews.branch""",
                           (user.id, user.id))

            profiler.check("query: active lines")

            for review_id, summary, branch_id, deleted_count, inserted_count in cursor:
                if includeReview(review_id):
                    with_changes[review_id] = (summary, branch_id, (deleted_count, inserted_count), None)

            profiler.check("processing: active lines")

            cursor.execute("""SELECT reviews.id, reviews.summary, reviews.branch, unread.count
                                FROM (SELECT commentchains.review AS review, COUNT(commentstoread.comment) AS count
                                        FROM commentchains
                                        JOIN comments ON (comments.chain=commentchains.id)
                                        JOIN commentstoread ON (commentstoread.comment=comments.id
                                                            AND commentstoread.uid=%s)
                                    GROUP BY commentchains.review) AS unread
                                JOIN reviews ON (reviews.id=unread.review)
                               WHERE reviews.state='open'""",
                           (user.id,))

            profiler.check("query: active comments")

            for review_id, summary, branch_id, comments_count in cursor:
                if includeReview(review_id):
                    if with_changes.has_key(review_id):
                        with_both[review_id] = (summary, branch_id, with_changes[review_id][2], comments_count)
                        del with_changes[review_id]
                    else:
                        with_comments[review_id] = (summary, branch_id, None, comments_count)

            profiler.check("processing: active comments")

            active["changes"] = with_changes
            active["comments"] = with_comments
            active["both"] = with_both

    def renderActive():
        fetchActive()

        if active["both"] or active["changes"] or active["comments"]:
            table = target.table("paleyellow reviews", id="active", align="center", cellspacing=0)
            table.col(width="15%")
            table.col(width="55%")
            table.col(width="15%")
            table.col(width="15%")
            header = table.tr().td("h1", colspan=4).h1()
            header.text("Active Reviews")
            header.span("right").a(href=hidden("active")).text("[hide]")

            if active["both"]:
                review_ids = ",".join(map(str, active["both"].keys()))
                h2 = table.tr(id="active-changes-comments").td("h2", colspan=4).h2().text("Has Changes And Comments")
                h2.a(href="javascript:void(0);", onclick="markChainsAsRead([%s]);" % review_ids).text("[mark all as read]")
                renderReviews(table, sortedReviews(active["both"]))

            if active["changes"]:
                table.tr(id="active-changes").td("h2", colspan=4).h2().text("Has Changes")
                renderReviews(table, sortedReviews(active["changes"]))

            if active["comments"]:
                review_ids = ",".join(map(str, active["comments"].keys()))
                h2 = table.tr(id="active-comments").td("h2", colspan=4).h2().text("Has Comments")
                h2.a(href="javascript:void(0);", onclick="markChainsAsRead([%s]);" % review_ids).text("[mark all as read]")
                renderReviews(table, sortedReviews(active["comments"]))

            profiler.check("generate: active")
            return True

    other = {}

    def fetchWatchedAndClosed():
        if not other:
            if "watched" not in showset:
                state_filter = " AND reviews.state='closed'"
            elif "closed" not in showset:
                state_filter = " AND reviews.state='open'"
            else:
                state_filter = ""

            profiler.check("query: watched/closed")

            watched = {}
            owned_closed = {}
            other_closed = {}

            if "watched" in showset: fetchActive()

            cursor.execute("""SELECT reviews.id, reviews.summary, reviews.branch, reviews.state, reviewusers.owner, reviewusers.uid IS NULL
                                FROM reviews
                     LEFT OUTER JOIN reviewusers ON (reviewusers.review=reviews.id AND reviewusers.uid=%s)
                               WHERE TRUE""" + state_filter,
                           (user.id,))

            for review_id, summary, branch_id, review_state, is_owner, not_associated in cursor:
                if includeReview(review_id):
                    if review_state == 'open':
                        if is_owner or not_associated:
                            continue

                        fetchActive()

                        if active["both"].has_key(review_id) or active["changes"].has_key(review_id) or active["comments"].has_key(review_id):
                            continue

                        watched[review_id] = summary, branch_id, None, None
                    elif is_owner:
                        owned_closed[review_id] = summary, branch_id, None, None
                    else:
                        other_closed[review_id] = summary, branch_id, None, None

            profiler.check("processing: watched/closed")

            other["watched"] = watched
            other["owned-closed"] = owned_closed
            other["other-closed"] = other_closed

    def renderWatched():
        fetchWatchedAndClosed()

        watched = other["watched"]
        accepted = []
        pending = []

        is_accepted = isAccepted(watched.keys())

        for review_id, (summary, branch_id, lines, comments) in sortedReviews(watched):
            if is_accepted[review_id]:
                accepted.append((review_id, (summary, branch_id, lines, comments)))
            else:
                pending.append((review_id, (summary, branch_id, lines, comments)))

        if accepted or pending:
            table = target.table("paleyellow reviews", id="watched", align="center", cellspacing=0)
            table.col(width="30%")
            table.col(width="70%")
            header = table.tr().td("h1", colspan=4).h1()
            header.text("Watched Reviews")
            header.span("right").a(href=hidden("watched")).text("[hide]")

            if accepted:
                table.tr(id="active-changes-comments").td("h2", colspan=4).h2().text("Accepted")
                renderReviews(table, accepted, False)

            if pending:
                table.tr(id="active-changes-comments").td("h2", colspan=4).h2().text("Pending")
                renderReviews(table, pending, False)

            profiler.check("generate: watched")
            return True

    def renderClosed():
        fetchWatchedAndClosed()

        owned_closed = other["owned-closed"]
        other_closed = other["other-closed"]

        if owned_closed or other_closed:
            table = target.table("paleyellow reviews", id="closed", align="center", cellspacing=0)
            table.col(width="30%")
            table.col(width="70%")
            header = table.tr().td("h1", colspan=4).h1()
            header.text("Closed Reviews")
            header.span("right").a(href=hidden("closed")).text("[hide]")

            if not user.isAnonymous():
                if owned_closed:
                    table.tr().td("h2", colspan=4).h2().text("Owned")
                    renderReviews(table, sortedReviews(owned_closed), False)

                if other_closed:
                    table.tr().td("h2", colspan=4).h2().text("Other")
                    renderReviews(table, sortedReviews(other_closed), False)
            else:
                renderReviews(table, sortedReviews(other_closed), False)

            profiler.check("generate: closed")
            return True

    def renderOpen():
        other_open = {}

        cursor.execute("""SELECT reviews.id, reviews.summary, reviews.branch
                            FROM reviews
                 LEFT OUTER JOIN reviewusers ON (reviewusers.review=reviews.id AND reviewusers.uid=%s)
                           WHERE reviews.state='open'
                             AND reviewusers.uid IS NULL""",
                       [user.id])

        profiler.check("query: open")

        for review_id, summary, branch_id in cursor:
            if includeReview(review_id):
                other_open[review_id] = summary, branch_id, None, None

        profiler.check("processing: open")

        if other_open:
            accepted = []
            pending = []

            for review_id, (summary, branch_id, lines, comments) in sortedReviews(other_open):
                if dbutils.Review.isAccepted(db, review_id):
                    accepted.append((review_id, (summary, branch_id, lines, comments)))
                else:
                    pending.append((review_id, (summary, branch_id, lines, comments)))

            table = target.table("paleyellow reviews", id="open", align="center", cellspacing=0)
            table.col(width="30%")
            table.col(width="70%")
            header = table.tr().td("h1", colspan=4).h1()
            header.text("Open Reviews" if user.isAnonymous() else "Other Open Reviews")
            header.span("right").a(href=hidden("open")).text("[hide]")

            if accepted:
                table.tr().td("h2", colspan=4).h2().text("Accepted")
                renderReviews(table, accepted, False)

            if pending:
                table.tr().td("h2", colspan=4).h2().text("Pending")
                renderReviews(table, pending, False)

            profiler.check("generate: open")
            return True

    render = { "owned": renderOwned,
               "draft": renderDraft,
               "active": renderActive,
               "watched": renderWatched,
               "closed": renderClosed,
               "open": renderOpen }

    empty = True

    for item in showlist:
        if item in render:
            target.comment(repr(item))
            if render[item]():
                empty = False
                yield flush(target)

    if empty:
        document.addExternalStylesheet("resource/message.css")
        body.div("message paleyellow").h1("center").text("No reviews!")

    profiler.output(db=db, user=user, target=document)

    yield flush(None)

########NEW FILE########
__FILENAME__ = editresource
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2012 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import dbutils
import htmlutils
import page.utils
import configuration

def renderEditResource(req, db, user):
    name = page.utils.getParameter(req, "name", None)

    document = htmlutils.Document(req)

    html = document.html()
    head = html.head()
    body = html.body()

    page.utils.generateHeader(body, db, user)

    document.addExternalStylesheet("resource/editresource.css")
    document.addExternalScript("resource/editresource.js")

    target = body.div("main")

    table = target.table('paleyellow', align='center')
    table.col(width='10%')
    table.col(width='60%')
    table.tr().td('h1', colspan=2).h1().text("Resource Editor")

    select_row = table.tr('select')
    select_row.td('heading').text('Resource:')
    select = select_row.td('value').select()
    if name is None: select.option(selected="selected").text("Select resource")
    select.option(value="diff.css", selected="selected" if name=="diff.css" else None).text("Diff coloring")
    select.option(value="syntax.css", selected="selected" if name=="syntax.css" else None).text("Syntax highlighting")

    help_row = table.tr('help')
    help_row.td('help', colspan=2).text("Select the resource to edit.")

    is_edited = False
    is_reset = False
    source = None

    if name is None:
        document.addInternalScript("var resource_name = null;");
        source = ""
    else:
        if name not in ("diff.css", "syntax.css"):
            raise page.utils.DisplayMessage("Invalid resource name", body="Must be one of 'diff.css' and 'syntax.css'.")

        document.addInternalScript("var resource_name = %s;" % htmlutils.jsify(name));

        cursor = db.cursor()
        cursor.execute("SELECT source FROM userresources WHERE uid=%s AND name=%s ORDER BY revision DESC FETCH FIRST ROW ONLY", (user.id, name))
        row = cursor.fetchone()

        if row:
            is_edited = True
            source = row[0]

        if source is None:
            is_reset = is_edited
            source = open(configuration.paths.INSTALL_DIR + "/resources/" + name).read()

        document.addInternalScript("var original_source = %s;" % htmlutils.jsify(source));

    table.tr('value').td('value', colspan=2).textarea(rows=source.count("\n") + 10).preformatted().text(source)

    buttons = table.tr('buttons').td('buttons', colspan=2)
    buttons.button('save').text("Save changes")

    if is_edited and not is_reset:
        buttons.button('reset').text("Reset to built-in version")

    if is_reset:
        buttons.button('restore').text("Restore last edited version")

    return document

########NEW FILE########
__FILENAME__ = filterchanges
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2012 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import dbutils
import htmlutils
import gitutils

import page.utils
import reviewing.utils as review_utils
import log.commitset

def renderFilterChanges(req, db, user):
    review_id = page.utils.getParameter(req, "review", filter=int)
    first_sha1 = page.utils.getParameter(req, "first", None)
    last_sha1 = page.utils.getParameter(req, "last", None)

    cursor = db.cursor()

    review = dbutils.Review.fromId(db, review_id)

    root_directories = {}
    root_files = {}

    def processFile(file_id):
        components = dbutils.describe_file(db, file_id).split("/")
        directories, files = root_directories, root_files
        for directory_name in components[:-1]:
            directories, files = directories.setdefault(directory_name, ({}, {}))
        files[components[-1]] = file_id

    if first_sha1 and last_sha1:
        cursor.execute("""SELECT commits.sha1
                            FROM commits
                            JOIN changesets ON (changesets.child=commits.id)
                            JOIN reviewchangesets ON (reviewchangesets.changeset=changesets.id)
                           WHERE reviewchangesets.review=%s""",
                       (review.id,))

        first_commit = gitutils.Commit.fromSHA1(db, review.repository, first_sha1)
        last_commit = gitutils.Commit.fromSHA1(db, review.repository, last_sha1)

        if len(first_commit.parents) > 1:
            raise page.utils.DisplayMessage(
                title="Filtering failed!",
                body=("First selected commit is a merge commit.  Please go back "
                      "and select a different range of commits."),
                review=review)

        if first_commit.parents:
            from_commit = gitutils.Commit.fromSHA1(db, review.repository, first_commit.parents[0])
        else:
            from_commit = None

        to_commit = last_commit
        commits = log.commitset.CommitSet.fromRange(db, from_commit, to_commit)

        if not commits:
            raise page.utils.DisplayMessage(
                title="Filtering failed!",
                body=("The range of commits selected includes merges with "
                      "ancestors not included in the range.  Please go back "
                      "and select a different range of commits."),
                review=review)

        cursor.execute("""SELECT DISTINCT reviewfiles.file
                            FROM reviewfiles
                            JOIN changesets ON (changesets.id=reviewfiles.changeset)
                            JOIN commits ON (commits.id=changesets.child)
                           WHERE reviewfiles.review=%s
                             AND commits.sha1=ANY (%s)""",
                       (review.id, [commit.sha1 for commit in commits]))
    else:
        cursor.execute("SELECT DISTINCT file FROM reviewfiles WHERE review=%s", (review.id,))

    for (file_id,) in cursor:
        processFile(file_id)

    document = htmlutils.Document(req)

    html = document.html()
    head = html.head()
    body = html.body()

    page.utils.generateHeader(body, db, user, lambda target: review_utils.renderDraftItems(db, user, review, target), extra_links=[("r/%d" % review.id, "Back to Review")])

    document.addExternalStylesheet("resource/filterchanges.css")
    document.addExternalScript("resource/filterchanges.js")
    document.addInternalScript(user.getJS())
    document.addInternalScript(review.getJS())

    if first_sha1 and last_sha1:
        document.addInternalScript("var commitRange = { first: %s, last: %s };" % (htmlutils.jsify(first_sha1), htmlutils.jsify(last_sha1)))
    else:
        document.addInternalScript("var commitRange = null;")

    target = body.div("main")

    basic = target.table('filter paleyellow', align='center', cellspacing=0)
    basic.col(width='10%')
    basic.col(width='60%')
    basic.col(width='30%')
    row = basic.tr("header")
    row.td('h1', colspan=2).h1().text("Filter Changes")
    row.td('h1 button').button("display").text("Display Diff")

    row = basic.tr("headings")
    row.td("select").text("Include")
    row.td("path").text("Path")
    row.td().text()

    def outputDirectory(base, name, directories, files):
        if name:
            level = base.count("/")
            row = basic.tr("directory", critic_level=level)
            row.td("select").input(type="checkbox")
            if level > 1:
                row.td("path").preformatted().innerHTML((" " * (len(base) - 2)) + "&#8230;/" + name + "/")
            else:
                row.td("path").preformatted().innerHTML(base + name + "/")
            row.td().text()
        else:
            row = basic.tr("directory", critic_level=-1)
            row.td("select").input(type="checkbox")
            row.td("path").preformatted().i().text("Everything")
            row.td().text()
            level = -1

        for directory_name in sorted(directories.keys()):
            outputDirectory(base + name + "/" if name else "", directory_name, directories[directory_name][0], directories[directory_name][1])

        for file_name in sorted(files.keys()):
            row = basic.tr("file", critic_file_id=files[file_name], critic_level=level + 1)
            row.td("select").input(type="checkbox")
            if level > -1:
                row.td("path").preformatted().innerHTML((" " * (len(base + name) - 1)) + "&#8230;/" + htmlutils.htmlify(file_name))
            else:
                row.td("path").preformatted().innerHTML(htmlutils.htmlify(file_name))
            row.td().text()

    outputDirectory("", "", root_directories, root_files)

    row = basic.tr("footer")
    row.td('spacer', colspan=3)

    row = basic.tr("footer")
    row.td('button', colspan=3).button("display").text("Display Diff")

    if user.getPreference(db, "ui.keyboardShortcuts"):
        page.utils.renderShortcuts(body, "filterchanges")

    return document

########NEW FILE########
__FILENAME__ = home
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2012 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import dbutils
import htmlutils
import page.utils
import gitutils
import configuration
import reviewing.filters
import profiling
import auth

from htmlutils import jsify
from textutils import json_encode

def renderHome(req, db, user):
    if user.isAnonymous(): raise page.utils.NeedLogin(req)

    profiler = profiling.Profiler()

    cursor = db.cursor()

    readonly = req.getParameter("readonly", "yes" if user.name != req.user else "no") == "yes"
    repository = req.getParameter("repository", None, gitutils.Repository.FromParameter(db))
    verified_email_id = req.getParameter("email_verified", None, int)

    if not repository:
        repository = user.getDefaultRepository(db)

    title_fullname = user.fullname

    if title_fullname[-1] == 's': title_fullname += "'"
    else: title_fullname += "'s"

    cursor.execute("SELECT email FROM usergitemails WHERE uid=%s ORDER BY email ASC", (user.id,))
    gitemails = ", ".join([email for (email,) in cursor])

    document = htmlutils.Document(req)

    html = document.html()
    head = html.head()
    body = html.body()

    if user.name == req.user:
        actual_user = None
    else:
        actual_user = req.getUser(db)

    def renderHeaderItems(target):
        if readonly and actual_user and actual_user.hasRole(db, "administrator"):
            target.a("button", href="/home?user=%s&readonly=no" % user.name).text("Edit")

    page.utils.generateHeader(body, db, user, generate_right=renderHeaderItems, current_page="home")

    document.addExternalStylesheet("resource/home.css")
    document.addExternalScript("resource/home.js")
    document.addExternalScript("resource/autocomplete.js")
    if repository: document.addInternalScript(repository.getJS())
    else: document.addInternalScript("var repository = null;")
    if actual_user and actual_user.hasRole(db, "administrator"):
        document.addInternalScript("var administrator = true;")
    else:
        document.addInternalScript("var administrator = false;")
    document.addInternalScript(user.getJS())
    document.addInternalScript("user.gitEmails = %s;" % jsify(gitemails))
    document.addInternalScript("var verifyEmailAddresses = %s;"
                               % jsify(configuration.base.VERIFY_EMAIL_ADDRESSES))
    document.setTitle("%s Home" % title_fullname)

    target = body.div("main")

    basic = target.table('paleyellow basic', align='center')
    basic.tr().td('h1', colspan=3).h1().text("%s Home" % title_fullname)

    def row(heading, value, help=None, extra_class=None):
        if extra_class:
            row_class = "line " + extra_class
        else:
            row_class = "line"
        main_row = basic.tr(row_class)
        main_row.td('heading').text("%s:" % heading)
        value_cell = main_row.td('value', colspan=2)
        if callable(value): value(value_cell)
        else: value_cell.text(value)
        basic.tr('help').td('help', colspan=3).text(help)

    def renderFullname(target):
        if readonly: target.text(user.fullname)
        else:
            target.input("value", id="user_fullname", value=user.fullname)
            target.span("status", id="status_fullname")
            buttons = target.span("buttons")
            buttons.button(onclick="saveFullname();").text("Save")
            buttons.button(onclick="resetFullname();").text("Reset")

    def renderEmail(target):
        if not actual_user or actual_user.hasRole(db, "administrator"):
            cursor.execute("""SELECT id, email, verified
                                FROM useremails
                               WHERE uid=%s
                            ORDER BY id ASC""",
                           (user.id,))
            rows = cursor.fetchall()
            if rows:
                if len(rows) > 1:
                    target.addClass("multiple")
                addresses = target.div("addresses")
                for email_id, email, verified in rows:
                    checked = "checked" if email == user.email else None
                    selected = " selected" if email == user.email else ""

                    label = addresses.label("address inset flex" + selected,
                                            data_email_id=email_id)
                    if len(rows) > 1:
                        label.input(name="email", type="radio", value=email,
                                    checked=checked)
                    label.span("value").text(email)
                    actions = label.span("actions")

                    if verified is False:
                        actions.a("action unverified", href="#").text("[unverified]")
                    elif verified is True:
                        now = " now" if email_id == verified_email_id else ""
                        actions.span("action verified" + now).text("[verified]")
                    actions.a("action delete", href="#").text("[delete]")
            else:
                target.i().text("No email address")
            target.span("buttons").button("addemail").text(
                "Add email address")
        elif user.email is None:
            target.i().text("No email address")
        elif user.email_verified is False:
            # Pending verification: don't show to other users.
            target.i().text("Email address not verified")
        else:
            target.span("inset").text(user.email)

    def renderGitEmails(target):
        if readonly: target.text(gitemails)
        else:
            target.input("value", id="user_gitemails", value=gitemails)
            target.span("status", id="status_gitemails")
            buttons = target.span("buttons")
            buttons.button(onclick="saveGitEmails();").text("Save")
            buttons.button(onclick="resetGitEmails();").text("Reset")

    def renderPassword(target):
        cursor.execute("SELECT password IS NOT NULL FROM users WHERE id=%s", (user.id,))
        has_password = cursor.fetchone()[0]
        if not has_password:
            target.text("not set")
        else:
            target.text("****")
        if not readonly:
            if not has_password or (actual_user and actual_user.hasRole(db, "administrator")):
                target.span("buttons").button(onclick="setPassword();").text("Set password")
            else:
                target.span("buttons").button(onclick="changePassword();").text("Change password")

    row("User ID", str(user.id))
    row("User Name", user.name)
    row("Display Name", renderFullname, "This is the name used when displaying commits or comments.")
    row("Primary Email", renderEmail, "This is the primary email address, to which emails are sent.", extra_class="email")
    row("Git Emails", renderGitEmails, "These email addresses are used to map Git commits to the user.")

    if configuration.base.AUTHENTICATION_MODE == "critic":
        row("Password", renderPassword, extra_class="password")

    cursor.execute("""SELECT provider, account
                        FROM externalusers
                       WHERE uid=%s""",
                   (user.id,))

    external_accounts = [(auth.PROVIDERS[provider_name], account)
                         for provider_name, account in cursor
                         if provider_name in auth.PROVIDERS]

    if external_accounts:
        basic.tr().td('h2', colspan=3).h2().text("External Accounts")

        for provider, account in external_accounts:
            def renderExternalAccount(target):
                url = provider.getAccountURL(account)
                target.a("external", href=url).text(account)

            row(provider.getTitle(), renderExternalAccount)

    profiler.check("user information")

    filters = page.utils.PaleYellowTable(body, "Filters")
    filters.titleRight.a("button", href="/tutorial?item=filters").text("Tutorial")

    cursor.execute("""SELECT repositories.id, repositories.name, repositories.path,
                             filters.id, filters.type, filters.path, filters.delegate
                        FROM repositories
                        JOIN filters ON (filters.repository=repositories.id)
                       WHERE filters.uid=%s
                    ORDER BY repositories.name, filters.type, filters.path""",
                   (user.id,))

    rows = cursor.fetchall()

    if rows:
        repository = None
        repository_filters = None
        tbody_reviewer = None
        tbody_watcher = None
        tbody_ignored = None

        count_matched_files = {}

        for (repository_id, repository_name, repository_path,
             filter_id, filter_type, filter_path, filter_delegates) in rows:
            if not repository or repository.id != repository_id:
                repository = gitutils.Repository.fromId(db, repository_id)
                repository_url = repository.getURL(db, user)
                filters.addSection(repository_name, repository_url)
                repository_filters = filters.addCentered().table("filters callout")
                tbody_reviewer = tbody_watcher = tbody_ignored = None

            if filter_type == "reviewer":
                if not tbody_reviewer:
                    tbody_reviewer = repository_filters.tbody()
                    tbody_reviewer.tr().th(colspan=4).text("Reviewer")
                tbody = tbody_reviewer
            elif filter_type == "watcher":
                if not tbody_watcher:
                    tbody_watcher = repository_filters.tbody()
                    tbody_watcher.tr().th(colspan=4).text("Watcher")
                tbody = tbody_watcher
            else:
                if not tbody_ignored:
                    tbody_ignored = repository_filters.tbody()
                    tbody_ignored.tr().th(colspan=4).text("Ignored")
                tbody = tbody_ignored

            row = tbody.tr()
            row.td("path").text(filter_path)

            delegates = row.td("delegates")
            if filter_delegates:
                delegates.i().text("Delegates: ")
                delegates.span("names").text(", ".join(filter_delegates.split(",")))

            if filter_path == "/":
                row.td("files").text("all files")
            else:
                href = "javascript:void(showMatchedFiles(%s, %s));" % (jsify(repository.name), jsify(filter_path))
                row.td("files").a(href=href, id=("f%d" % filter_id)).text("? files")
                count_matched_files.setdefault(repository_id, []).append(filter_id)

            links = row.td("links")
            arguments = (jsify(repository.name),
                         filter_id,
                         jsify(filter_type),
                         jsify(filter_path),
                         jsify(filter_delegates))
            links.a(href="javascript:void(editFilter(%s, %d, %s, %s, %s));" % arguments).text("[edit]")
            links.a(href="javascript:if (deleteFilterById(%d)) location.reload(); void(0);" % filter_id).text("[delete]")
            links.a(href="javascript:location.href='/config?filter=%d';" % filter_id).text("[preferences]")

        document.addInternalScript("var count_matched_files = %s;" % json_encode(count_matched_files.values()))
    else:
        filters.addCentered().p().b().text("No filters")

        # Additionally check if there are in fact no repositories.
        cursor.execute("SELECT 1 FROM repositories")
        if not cursor.fetchone():
            document.addInternalScript("var no_repositories = true;")

    if not readonly:
        filters.addSeparator()
        filters.addCentered().button(onclick="editFilter();").text("Add filter")

    profiler.check("filters")

    hidden = body.div("hidden", style="display: none")

    with hidden.div("filterdialog") as dialog:
        paragraph = dialog.p()
        paragraph.b().text("Repository:")
        paragraph.br()
        page.utils.generateRepositorySelect(db, user, paragraph, name="repository")

        paragraph = dialog.p()
        paragraph.b().text("Filter type:")
        paragraph.br()
        filter_type = paragraph.select(name="type")
        filter_type.option(value="reviewer").text("Reviewer")
        filter_type.option(value="watcher").text("Watcher")
        filter_type.option(value="ignored").text("Ignored")

        paragraph = dialog.p()
        paragraph.b().text("Path:")
        paragraph.br()
        paragraph.input(name="path", type="text")
        paragraph.span("matchedfiles")

        paragraph = dialog.p()
        paragraph.b().text("Delegates:")
        paragraph.br()
        paragraph.input(name="delegates", type="text")

        paragraph = dialog.p()
        label = paragraph.label()
        label.input(name="apply", type="checkbox", checked="checked")
        label.b().text("Apply to existing reviews")

    profiler.output(db, user, document)

    return document

########NEW FILE########
__FILENAME__ = login
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2012 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import urllib

import page
import page.utils
import auth
import configuration
import request

from page.parameters import Optional

class LoginHandler(page.Page.Handler):
    def __init__(self, target="/", optional="no"):
        super(LoginHandler, self).__init__()
        self.target = target
        self.optional = optional == "yes"

    def generateHeader(self):
        self.document.addExternalStylesheet("resource/login.css")
        self.document.addExternalScript("resource/login.js")

    def generateContent(self):
        if not self.user.isAnonymous():
            raise page.utils.MovedTemporarily(self.target, True)

        self.request.ensureSecure()

        if configuration.base.AUTHENTICATION_MODE != "critic":
            raise request.DoExternalAuthentication(
                configuration.base.AUTHENTICATION_MODE, self.target)

        self.document.setTitle("Sign in")

        def render(target):
            redirect_url = "redirect?" + urllib.urlencode(
                { "target": self.target })

            form = target.form(name="login", method="POST", action=redirect_url)
            table = form.table("login callout", align="center")

            row = table.tr("status disabled")
            row.td(colspan=2).text()

            row = table.tr("username")
            row.td("key").text("Username:")
            row.td("value").input("username", name="username", autofocus="autofocus")

            row = table.tr("password")
            row.td("key").text("Password:")
            row.td("value").input("password", name="password", type="password")

            row = table.tr("login")
            row.td(colspan=2).input("login", type="submit", value="Sign in")

            providers = []

            for name, provider in auth.PROVIDERS.items():
                providers.append((provider.getTitle(), name))

            if providers:
                table.tr("separator1").td(colspan=2)
                table.tr("separator2").td(colspan=2)

                external = table.tr("external").td(colspan=2)
                first = True

                for title, name in sorted(providers):
                    div = external.div("provider")
                    url = "/externalauth/%s?%s" % (name, urllib.urlencode(
                            { "target": self.target }))
                    if first:
                        div.text("Sign in using your ")
                        first = False
                    else:
                        div.text("or ")
                    div.a(href=url).text(title)

            if configuration.base.ALLOW_USER_REGISTRATION:
                table.tr("separator1").td(colspan=2)
                table.tr("separator2").td(colspan=2)

                register = table.tr("register").td(colspan=2)

                register.text("New to this system? ")
                register.a(href="/createuser").text("Create a user")
                register.text(" to start using it.")

            if self.optional:
                table.tr("separator1").td(colspan=2)
                table.tr("separator2").td(colspan=2)

                row = table.tr("continue")
                row.td(colspan=2).a(href=self.target).innerHTML(
                    "&#8230; or, continue anonymously")

        paleyellow = page.utils.PaleYellowTable(self.body, "Sign in")
        paleyellow.addCentered(render)

class Login(page.Page):
    def __init__(self):
        super(Login, self).__init__("login",
                                    { "target": Optional(str),
                                      "optional": Optional(str) },
                                    LoginHandler)

########NEW FILE########
__FILENAME__ = manageextensions
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2012 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import page.utils
import htmlutils
import dbutils
import configuration

from extensions.extension import Extension, ExtensionError
from extensions.manifest import ManifestError, PageRole, InjectRole, ProcessCommitsRole, ScheduledRole

def renderManageExtensions(req, db, user):
    if not configuration.extensions.ENABLED:
        administrators = dbutils.getAdministratorContacts(db, as_html=True)
        raise page.utils.DisplayMessage(
            title="Extension support not enabled",
            body=(("<p>This Critic system does not support extensions.</p>"
                   "<p>Contact %s to have it enabled, or see the "
                   "<a href='/tutorial?item=administration#extensions'>"
                   "section on extensions</a> in the system administration "
                   "tutorial for more information.</p>")
                  % administrators),
            html=True)

    cursor = db.cursor()

    what = page.utils.getParameter(req, "what", "available")
    selected_versions = page.utils.json_decode(page.utils.getParameter(req, "select", "{}"))
    focused = page.utils.getParameter(req, "focus", None)

    if what == "installed":
        title = "Installed Extensions"
        listed_extensions = []
        for extension_id, _, _, _ in Extension.getInstalls(db, user):
            try:
                listed_extensions.append(Extension.fromId(db, extension_id))
            except ExtensionError as error:
                listed_extensions.append(error)
    else:
        title = "Available Extensions"
        listed_extensions = Extension.find(db)

    req.content_type = "text/html; charset=utf-8"

    document = htmlutils.Document(req)
    document.setTitle("Manage Extensions")

    html = document.html()
    head = html.head()
    body = html.body()

    def generateRight(target):
        target.a("button", href="tutorial?item=extensions").text("Tutorial")
        target.text(" ")
        target.a("button", href="tutorial?item=extensions-api").text("API Documentation")

    page.utils.generateHeader(body, db, user, current_page="extensions", generate_right=generateRight)

    document.addExternalStylesheet("resource/manageextensions.css")
    document.addExternalScript("resource/manageextensions.js")
    document.addInternalScript(user.getJS())

    table = page.utils.PaleYellowTable(body, title)

    def addTitleRightLink(url, label):
        if user.name != req.user:
            url += "&user=%s" % user.name
        table.titleRight.text(" ")
        table.titleRight.a(href=url).text("[" + label + " extensions]")

    if what != "installed" or focused:
        addTitleRightLink("/manageextensions?what=installed", "installed")
    if what != "available" or focused:
        addTitleRightLink("/manageextensions?what=available", "available")

    for item in listed_extensions:
        if isinstance(item, ExtensionError):
            extension_error = item
            extension = item.extension
        else:
            extension_error = None
            extension = item

        if focused and extension.getKey() != focused:
            continue

        extension_path = extension.getPath()

        if extension.isSystemExtension():
            hosting_user = None
        else:
            hosting_user = extension.getAuthor(db)

        selected_version = selected_versions.get(extension.getKey(), False)
        installed_sha1, installed_version = extension.getInstalledVersion(db, user)
        universal_sha1, universal_version = extension.getInstalledVersion(db, None)
        installed_upgradeable = universal_upgradeable = False

        if extension_error is None:
            if installed_sha1:
                current_sha1 = extension.getCurrentSHA1(installed_version)
                installed_upgradeable = installed_sha1 != current_sha1
            if universal_sha1:
                current_sha1 = extension.getCurrentSHA1(universal_version)
                universal_upgradeable = universal_sha1 != current_sha1

        def massage_version(version):
            if version is None:
                return "live"
            elif version:
                return "version/%s" % version
            else:
                return None

        if selected_version is False:
            selected_version = installed_version
        if selected_version is False:
            selected_version = universal_version

        install_version = massage_version(selected_version)
        installed_version = massage_version(installed_version)
        universal_version = massage_version(universal_version)

        manifest = None

        if extension_error is None:
            try:
                if selected_version is False:
                    manifest = extension.getManifest()
                else:
                    manifest = extension.getManifest(selected_version)
            except ManifestError as error:
                pass
        elif installed_sha1:
            manifest = extension.getManifest(installed_version, installed_sha1)
        elif universal_sha1:
            manifest = extension.getManifest(universal_version, universal_sha1)

        if manifest:
            if what == "available" and manifest.hidden:
                # Hide from view unless the user is hosting the extension, or is
                # an administrator and the extension is a system extension.
                if extension.isSystemExtension():
                    if not user.hasRole(db, "administrator"):
                        continue
                elif hosting_user != user:
                    continue
        else:
            if hosting_user != user:
                continue

        extension_id = extension.getExtensionID(db, create=False)

        if not user.isAnonymous():
            buttons = []

            if extension_id is not None:
                cursor.execute("""SELECT 1
                                    FROM extensionstorage
                                   WHERE extension=%s
                                     AND uid=%s""",
                               (extension_id, user.id))

                if cursor.fetchone():
                    buttons.append(("Clear storage",
                                    ("clearExtensionStorage(%s, %s)"
                                     % (htmlutils.jsify(extension.getAuthorName()),
                                        htmlutils.jsify(extension.getName())))))

            if not installed_version:
                if manifest and install_version and install_version != universal_version:
                    buttons.append(("Install",
                                    ("installExtension(%s, %s, %s)"
                                     % (htmlutils.jsify(extension.getAuthorName()),
                                        htmlutils.jsify(extension.getName()),
                                        htmlutils.jsify(install_version)))))
            else:
                buttons.append(("Uninstall",
                                ("uninstallExtension(%s, %s)"
                                 % (htmlutils.jsify(extension.getAuthorName()),
                                    htmlutils.jsify(extension.getName())))))

                if manifest and (install_version != installed_version
                                 or (installed_sha1 and installed_upgradeable)):
                    if install_version == installed_version:
                        label = "Upgrade"
                    else:
                        label = "Install"

                    buttons.append(("Upgrade",
                                    ("reinstallExtension(%s, %s, %s)"
                                     % (htmlutils.jsify(extension.getAuthorName()),
                                        htmlutils.jsify(extension.getName()),
                                        htmlutils.jsify(install_version)))))

            if user.hasRole(db, "administrator"):
                if not universal_version:
                    if manifest and install_version:
                        buttons.append(("Install (universal)",
                                        ("installExtension(%s, %s, %s, true)"
                                         % (htmlutils.jsify(extension.getAuthorName()),
                                            htmlutils.jsify(extension.getName()),
                                            htmlutils.jsify(install_version)))))
                else:
                    buttons.append(("Uninstall (universal)",
                                    ("uninstallExtension(%s, %s, true)"
                                     % (htmlutils.jsify(extension.getAuthorName()),
                                        htmlutils.jsify(extension.getName())))))

                    if manifest and (install_version != universal_version
                                     or (universal_sha1 and universal_upgradeable)):
                        if install_version == universal_version:
                            label = "Upgrade (universal)"
                        else:
                            label = "Install (universal)"

                        buttons.append((label,
                                        ("reinstallExtension(%s, %s, %s, true)"
                                         % (htmlutils.jsify(extension.getAuthorName()),
                                            htmlutils.jsify(extension.getName()),
                                            htmlutils.jsify(universal_version)))))
        else:
            buttons = None

        def renderItem(target):
            target.span("name").innerHTML(extension.getTitle(db, html=True))

            if hosting_user:
                is_author = manifest and manifest.isAuthor(db, hosting_user)
                is_sole_author = is_author and len(manifest.authors) == 1
            else:
                is_sole_author = False

            if extension_error is None:
                span = target.span("details")
                span.b().text("Details: ")
                select = span.select("details", critic_author=extension.getAuthorName(), critic_extension=extension.getName())
                select.option(value='', selected="selected" if selected_version is False else None).text("Select version")
                versions = extension.getVersions()
                if versions:
                    optgroup = select.optgroup(label="Official Versions")
                    for version in versions:
                        optgroup.option(value="version/%s" % version, selected="selected" if selected_version == version else None).text("%s" % version.upper())
                optgroup = select.optgroup(label="Development")
                optgroup.option(value='live', selected="selected" if selected_version is None else None).text("LIVE")

            if manifest:
                is_installed = bool(installed_version)

                if is_installed:
                    target.span("installed").text(" [installed]")
                else:
                    is_installed = bool(universal_version)

                    if is_installed:
                        target.span("installed").text(" [installed (universal)]")

                target.div("description").preformatted().text(manifest.description, linkify=True)

                if not is_sole_author:
                    authors = target.div("authors")
                    authors.b().text("Author%s:" % ("s" if len(manifest.authors) > 1 else ""))
                    authors.text(", ".join(author.name for author in manifest.getAuthors()))
            else:
                is_installed = False

                div = target.div("description broken").preformatted()

                if extension_error is None:
                    anchor = div.a(href="loadmanifest?key=%s" % extension.getKey())
                    anchor.text("[This extension has an invalid MANIFEST file]")
                else:
                    div.text("[This extension has been deleted or has become inaccessible]")

            if selected_version is False:
                return

            pages = []
            injects = []
            processcommits = []
            scheduled = []

            if manifest:
                for role in manifest.roles:
                    if isinstance(role, PageRole):
                        pages.append(role)
                    elif isinstance(role, InjectRole):
                        injects.append(role)
                    elif isinstance(role, ProcessCommitsRole):
                        processcommits.append(role)
                    elif isinstance(role, ScheduledRole):
                        scheduled.append(role)

            role_table = target.table("roles")

            if pages:
                role_table.tr().th(colspan=2).text("Pages")

                for role in pages:
                    row = role_table.tr()
                    url = "%s/%s" % (dbutils.getURLPrefix(db, user), role.pattern)
                    if is_installed and "*" not in url:
                        row.td("pattern").a(href=url).text(url)
                    else:
                        row.td("pattern").text(url)
                    td = row.td("description")
                    td.text(role.description)

            if injects:
                role_table.tr().th(colspan=2).text("Page Injections")

                for role in injects:
                    row = role_table.tr()
                    row.td("pattern").text("%s/%s" % (dbutils.getURLPrefix(db, user), role.pattern))
                    td = row.td("description")
                    td.text(role.description)

            if processcommits:
                role_table.tr().th(colspan=2).text("ProcessCommits hooks")
                ul = role_table.tr().td(colspan=2).ul()

                for role in processcommits:
                    li = ul.li()
                    li.text(role.description)

            if scheduled:
                role_table.tr().th(colspan=2).text("Scheduled hooks")

                for role in scheduled:
                    row = role_table.tr()
                    row.td("pattern").text("%s @ %s" % (role.frequency, role.at))
                    td = row.td("description")
                    td.text(role.description)

        installed_by = ""

        if extension_id is not None:
            cursor.execute("""SELECT uid
                                FROM extensioninstalls
                                JOIN extensions ON (extensions.id=extensioninstalls.extension)
                               WHERE extensions.id=%s""",
                           (extension.getExtensionID(db, create=False),))

            user_ids = set(user_id for user_id, in cursor.fetchall())
            if user_ids:
                installed_by = " (installed"
                if None in user_ids:
                    installed_by += " universally"
                    user_ids.remove(None)
                    if user_ids:
                        installed_by += " and"
                if user_ids:
                    installed_by += (" by %d user%s"
                                  % (len(user_ids),
                                     "s" if len(user_ids) > 1 else ""))
                installed_by += ")"

        table.addItem("Extension", renderItem, extension_path + "/" + installed_by, buttons)

    document.addInternalScript("var selected_versions = %s;" % page.utils.json_encode(selected_versions))

    return document

########NEW FILE########
__FILENAME__ = managereviewers
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2012 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import dbutils
import htmlutils

import page.utils
import reviewing.utils as review_utils

def renderManageReviewers(req, db, user):
    review_id = req.getParameter("review", filter=int)

    cursor = db.cursor()

    review = dbutils.Review.fromId(db, review_id)

    root_directories = {}
    root_files = {}

    def processFile(file_id):
        components = dbutils.describe_file(db, file_id).split("/")
        directories, files = root_directories, root_files
        for directory_name in components[:-1]:
            directories, files = directories.setdefault(directory_name, ({}, {}))
        files[components[-1]] = file_id

    cursor.execute("SELECT file FROM reviewfiles WHERE review=%s", (review.id,))

    for (file_id,) in cursor:
        processFile(file_id)

    cursor.execute("SELECT name FROM users WHERE name IS NOT NULL")
    users = [user_name for (user_name,) in cursor if user_name]

    document = htmlutils.Document(req)

    html = document.html()
    head = html.head()
    body = html.body()

    page.utils.generateHeader(body, db, user, lambda target: review_utils.renderDraftItems(db, user, review, target), extra_links=[("r/%d" % review.id, "Back to Review")])

    document.addExternalStylesheet("resource/managereviewers.css")
    document.addExternalScript("resource/managereviewers.js")
    document.addInternalScript(user.getJS());
    document.addInternalScript(review.getJS());
    document.addInternalScript("var users = [ %s ];" % ", ".join([htmlutils.jsify(user_name) for user_name in sorted(users)]))

    target = body.div("main")

    basic = target.table('manage paleyellow', align='center')
    basic.col(width='10%')
    basic.col(width='60%')
    basic.col(width='30%')
    basic.tr().td('h1', colspan=3).h1().text("Manage Reviewers")

    row = basic.tr("current")
    row.td("select").text("Current:")
    cell = row.td("value")
    for index, reviewer in enumerate(review.reviewers):
        if index != 0: cell.text(", ")
        cell.span("reviewer", critic_username=reviewer.name).innerHTML(htmlutils.htmlify(reviewer.fullname).replace(" ", "&nbsp;"))
    row.td("right").text()

    row = basic.tr("reviewer")
    row.td("select").text("Reviewer:")
    row.td("value").input("reviewer").span("message")
    row.td("right").button("save").text("Save")

    row = basic.tr("help")
    row.td("help", colspan=3).text("Enter the name of a current reviewer to edit assignments (or unassign.)  Enter the name of another user to add a new reviewer.")

    row = basic.tr("headings")
    row.td("select").text("Assigned")
    row.td("path").text("Path")
    row.td().text()

    def outputDirectory(base, name, directories, files):
        if name:
            level = base.count("/")
            row = basic.tr("directory", critic_level=level)
            row.td("select").input(type="checkbox")
            if level > 1:
                row.td("path").preformatted().innerHTML((" " * (len(base) - 2)) + "&#8230;/" + name + "/")
            else:
                row.td("path").preformatted().innerHTML(base + name + "/")
            row.td().text()
        else:
            level = 0

        for directory_name in sorted(directories.keys()):
            outputDirectory(base + name + "/" if name else "", directory_name, directories[directory_name][0], directories[directory_name][1])

        for file_name in sorted(files.keys()):
            row = basic.tr("file", critic_file_id=files[file_name], critic_level=level + 1)
            row.td("select").input(type="checkbox")
            row.td("path").preformatted().innerHTML((" " * (len(base + name) - 1)) + "&#8230;/" + htmlutils.htmlify(file_name))
            row.td().text()

    outputDirectory("", "", root_directories, root_files)

    return document

########NEW FILE########
__FILENAME__ = news
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2012 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import page.utils
import textformatting
import htmlutils

def renderNewsItem(db, user, target, text, timestamp):
    table = target.table("paleyellow", align="center")
    textformatting.renderFormatted(db, user, table, text.splitlines(), toc=False,
                                   title_right=timestamp)
    table.tr("back").td("back").div().a("back", href="news").text("Back")

def renderNewsItems(db, user, target, display_unread, display_read):
    target.setTitle("News")

    table = target.table("paleyellow", align="center")
    table.tr("h1").td("h1", colspan=3).h1().text("News")

    cursor = db.cursor()
    cursor.execute("""SELECT id, date, text, uid IS NULL
                        FROM newsitems
             LEFT OUTER JOIN newsread ON (item=id AND uid=%s)
                    ORDER BY date DESC, id DESC""",
                   (user.id,))

    nothing = True

    for item_id, date, text, unread in cursor:
        if (unread and display_unread) or (not unread and display_read):
            row = table.tr("item", critic_item_id=item_id)
            row.td("date").text(date)
            row.td("title").text(text.split("\n", 1)[0])
            row.td("status").text("unread" if unread else None)
            nothing = False

    if nothing:
        row = table.tr("nothing")
        row.td("nothing", colspan=3).text("No %s news!" % "unread" if display_unread else "read")

    if not display_unread or not display_read:
        table.tr("show").td("show", colspan=3).div().a("show", href="news?display=all").text("Show All")

def renderNews(req, db, user):
    item_id = req.getParameter("item", None, filter=int)
    display = req.getParameter("display", "unread")

    document = htmlutils.Document(req)

    html = document.html()
    head = html.head()
    body = html.body()

    cursor = db.cursor()

    def renderButtons(target):
        if user.hasRole(db, "newswriter"):
            if item_id is not None:
                target.button("editnewsitem").text("Edit Item")
            target.button("addnewsitem").text("Add News Item")

    page.utils.generateHeader(body, db, user, current_page="news", generate_right=renderButtons)

    document.addExternalStylesheet("resource/tutorial.css")
    document.addExternalStylesheet("resource/comment.css")
    document.addExternalStylesheet("resource/news.css")
    document.addExternalScript("resource/news.js")
    document.addInternalStylesheet("div.main table td.text { %s }" % user.getPreference(db, "style.tutorialFont"))

    target = body.div("main")

    if item_id:
        cursor.execute("SELECT text, date FROM newsitems WHERE id=%s", (item_id,))

        text, date = cursor.fetchone()

        document.addInternalScript("var news_item_id = %d;" % item_id)
        document.addInternalScript("var news_text = %s;" % htmlutils.jsify(text))

        renderNewsItem(db, user, target, text, date.isoformat())

        if not user.isAnonymous() and user.name == req.user:
            cursor.execute("SELECT 1 FROM newsread WHERE item=%s AND uid=%s", (item_id, user.id))
            if not cursor.fetchone():
                cursor.execute("INSERT INTO newsread (item, uid) VALUES (%s, %s)", (item_id, user.id))
                db.commit()
    else:
        renderNewsItems(db, user, target, display in ("unread", "all"), display in ("read", "all"))

    return document

########NEW FILE########
__FILENAME__ = parameters
import base
import dbutils

class InvalidParameterValue(base.Error):
    def __init__(self, expected):
        self.expected = expected

class Optional(object):
    def __init__(self, actual):
        self.actual = actual

class ListOf(object):
    def __init__(self, actual):
        self.actual = actual

def check_integer(value, what="value"):
    try:
        value = int(value)
    except ValueError:
        raise InvalidParameterValue("an integer %s" % what)
    else:
        return value

class Stateful(object):
    def __init__(self, req, db, user):
        self.req = req
        self.db = db
        self.user = user

class ReviewId(Stateful):
    def __call__(self, value):
        review_id = check_integer(value, "review id")

        try:
            review = dbutils.Review.fromId(self.db, review_id)
        except dbutils.NoSuchReview:
            raise InvalidParameterValue("a valid review id")

        return review

########NEW FILE########
__FILENAME__ = rebasetrackingreview
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2012 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import page
import htmlutils
import gitutils
import request

from page.parameters import Optional, ReviewId

class RebaseTrackingReview(page.Page):
    def __init__(self):
        super(RebaseTrackingReview, self).__init__("rebasetrackingreview",
                                                   { "review": ReviewId,
                                                     "newbranch": Optional(str),
                                                     "upstream": Optional(str),
                                                     "newhead": Optional(str),
                                                     "newupstream": Optional(str) },
                                                   RebaseTrackingReview.Handler)

    class Handler(page.Page.Handler):
        def __init__(self, review, newbranch=None, upstream=None, newhead=None, newupstream=None):
            super(RebaseTrackingReview.Handler, self).__init__(review)
            self.newbranch = newbranch
            self.upstream = upstream
            self.newhead = newhead
            self.newupstream = newupstream

        def generateHeader(self):
            self.document.addExternalStylesheet("resource/rebasetrackingreview.css")
            self.document.addExternalScript("resource/autocomplete.js")
            self.document.addExternalScript("resource/rebasetrackingreview.js")

        def generateContent(self):
            trackedbranch = self.review.getTrackedBranch(self.db)

            if not trackedbranch:
                raise request.DisplayMessage("Not supported!", "The review r/%d is not tracking a remote branch." % self.review.id)

            self.document.addInternalScript(self.review.repository.getJS())
            self.document.addInternalScript(self.review.getJS())
            self.document.addInternalScript("var trackedbranch = { remote: %s, name: %s };"
                                            % (htmlutils.jsify(trackedbranch.remote),
                                               htmlutils.jsify(trackedbranch.name)))

            table = page.utils.PaleYellowTable(self.body, "Rebase tracking review")

            def renderRemote(target):
                target.span("value inset", id="remote").text(trackedbranch.remote)
            def renderCurrentBranch(target):
                target.span("value inset", id="currentbranch").text("refs/heads/" + trackedbranch.name)

            table.addItem("Remote", renderRemote)
            table.addItem("Current branch", renderCurrentBranch)
            table.addSeparator()

            if self.newbranch is not None and self.upstream is not None and self.newhead is not None and self.newupstream is not None:
                import log.html
                import log.commitset

                sha1s = self.review.repository.revlist(included=[self.newhead], excluded=[self.newupstream])
                new_commits = log.commitset.CommitSet(gitutils.Commit.fromSHA1(self.db, self.review.repository, sha1) for sha1 in sha1s)

                new_heads = new_commits.getHeads()
                if len(new_heads) != 1:
                    raise page.utils.DisplayMessage("Invalid commit-set!", "Multiple heads.  (This ought to be impossible...)")
                new_upstreams = new_commits.getFilteredTails(self.review.repository)
                if len(new_upstreams) != 1:
                    raise page.utils.DisplayMessage("Invalid commit-set!", "Multiple upstreams.  (This ought to be impossible...)")

                new_head = new_heads.pop()
                new_upstream_sha1 = new_upstreams.pop()

                old_commits = log.commitset.CommitSet(self.review.branch.commits)
                old_upstreams = old_commits.getFilteredTails(self.review.repository)

                if len(old_upstreams) != 1:
                    raise page.utils.DisplayMessage("Rebase not supported!", "The review has mulitple upstreams and can't be rebased.")

                if len(old_upstreams) == 1 and new_upstream_sha1 in old_upstreams:
                    # This appears to be a history rewrite.
                    new_upstream = None
                    new_upstream_sha1 = None
                    rebase_type = "history"
                else:
                    old_upstream = gitutils.Commit.fromSHA1(self.db, self.review.repository, old_upstreams.pop())
                    new_upstream = gitutils.Commit.fromSHA1(self.db, self.review.repository, new_upstream_sha1)

                    if old_upstream.isAncestorOf(new_upstream):
                        rebase_type = "move:ff"
                    else:
                        rebase_type = "move"

                self.document.addInternalScript("var check = { rebase_type: %s, old_head_sha1: %s, new_head_sha1: %s, new_upstream_sha1: %s, new_trackedbranch: %s };"
                                                % (htmlutils.jsify(rebase_type),
                                                   htmlutils.jsify(self.review.branch.head.sha1),
                                                   htmlutils.jsify(new_head.sha1),
                                                   htmlutils.jsify(new_upstream_sha1),
                                                   htmlutils.jsify(self.newbranch[len("refs/heads/"):])))

                def renderNewBranch(target):
                    target.span("value inset", id="newbranch").text(self.newbranch)
                    target.text(" @ ")
                    target.span("value inset").text(new_head.sha1[:8] + " " + new_head.niceSummary())
                def renderUpstream(target):
                    target.span("value inset", id="upstream").text(self.upstream)
                    target.text(" @ ")
                    target.span("value inset").text(new_upstream.sha1[:8] + " " + new_upstream.niceSummary())

                table.addItem("New branch", renderNewBranch)

                if new_upstream:
                    table.addItem("New upstream", renderUpstream)

                table.addSeparator()

                def renderMergeStatus(target):
                    target.a("status", id="status_merge").text("N/A")
                def renderConflictsStatus(target):
                    target.a("status", id="status_conflicts").text("N/A")
                def renderHistoryRewriteStatus(target):
                    target.a("status", id="status_historyrewrite").text("N/A")

                table.addSection("Status")

                if rebase_type == "history":
                    table.addItem("History rewrite", renderHistoryRewriteStatus)
                else:
                    if rebase_type == "move:ff":
                        table.addItem("Merge", renderMergeStatus)
                    table.addItem("Conflicts", renderConflictsStatus)

                def renderRebaseReview(target):
                    target.button(id="rebasereview", onclick="rebaseReview();", disabled="disabled").text("Rebase Review")

                table.addSeparator()
                table.addCentered(renderRebaseReview)

                log.html.render(self.db, self.body, "Rebased commits", commits=list(new_commits))
            else:
                try:
                    from customization.branches import getRebasedBranchPattern
                except ImportError:
                    def getRebasedBranchPattern(branch_name): return None

                pattern = getRebasedBranchPattern(trackedbranch.name)

                try:
                    from customization.branches import isRebasedBranchCandidate
                except ImportError:
                    isRebasedBranchCandidate = None

                if pattern or isRebasedBranchCandidate:
                    candidates = [name[len("refs/heads/"):]
                                  for sha1, name in gitutils.Repository.lsremote(trackedbranch.remote, pattern=pattern, include_heads=True)
                                  if name.startswith("refs/heads/")]

                    if isRebasedBranchCandidate is not None:
                        def isCandidate(name):
                            return isRebasedBranchCandidate(trackedbranch.name, name)

                        candidates = filter(isCandidate, candidates)
                else:
                    candidates = []

                if len(candidates) > 1:
                    def renderCandidates(target):
                        target.text("refs/heads/")
                        dropdown = target.select(id="newbranch")
                        for name in candidates:
                            dropdown.option(value=name).text(name)

                    table.addItem("New branch", renderCandidates,
                                    buttons=[("Edit", "editNewBranch(this);")])
                else:
                    if len(candidates) == 1:
                        default_value = candidates[0]
                    else:
                        default_value = trackedbranch.name

                    def renderEdit(target):
                        target.text("refs/heads/")
                        target.input(id="newbranch", value=default_value)

                    table.addItem("New branch", renderEdit)

                def renderUpstreamInput(target):
                    target.input(id="upstream", value="refs/heads/master")

                table.addItem("Upstream", renderUpstreamInput)

                def renderFetchBranch(target):
                    target.button(onclick="fetchBranch();").text("Fetch Branch")

                table.addSeparator()
                table.addCentered(renderFetchBranch)


########NEW FILE########
__FILENAME__ = repositories
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2012 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import page.utils
import htmlutils
import dbutils
import gitutils
import configuration

def renderRepositories(req, db, user):
    req.content_type = "text/html; charset=utf-8"

    document = htmlutils.Document(req)
    document.setTitle("Repositories")

    html = document.html()
    head = html.head()
    body = html.body()

    def generateRight(target):
        if user.hasRole(db, "repositories"):
            target.a("button", href="newrepository").text("Add Repository")

    page.utils.generateHeader(body, db, user, current_page="repositories", generate_right=generateRight)

    document.addExternalStylesheet("resource/repositories.css")
    document.addExternalScript("resource/repositories.js")
    document.addInternalScript(user.getJS())

    if user.name == req.user and user.hasRole(db, "administrator"):
        document.addInternalScript("user.administrator = true;")

    cursor = db.cursor()
    cursor.execute("SELECT id, name, path, parent, branch FROM repositories ORDER BY name ASC")

    rows = cursor.fetchall()

    class Repository:
        def __init__(self, repository_id, name, path, parent_id, branch_id):
            self.id = repository_id
            self.name = name
            self.path = path
            self.parent_id = parent_id
            self.branch_id = branch_id
            self.default_remote = None
            self.location = gitutils.Repository.constructURL(db, user, path)

    repositories = list(Repository(*row) for row in rows)
    repository_by_id = dict((repository.id, repository) for repository in repositories)

    def render(target):
        table = target.table("repositories callout")

        headings = table.tr("headings")
        headings.th("name").text("Short name")
        headings.th("location").text("Location")
        headings.th("upstream").text("Upstream")

        table.tr("spacer").td("spacer", colspan=3)

        for repository in repositories:
            row = table.tr("repository %s" % repository.name)
            row.td("name").text(repository.name)
            row.td("location").text(repository.location)

            if repository.parent_id:
                row.td("upstream").text(repository_by_id[repository.parent_id].name)
            else:
                row.td("upstream").text()

            cursor.execute("""SELECT id, local_name, remote, remote_name, disabled
                                FROM trackedbranches
                               WHERE repository=%s
                            ORDER BY id ASC""",
                           (repository.id,))

            details = table.tr("details %s" % repository.name).td(colspan=3)

            branches = [(branch_id, local_name, remote, remote_name, disabled)
                        for branch_id, local_name, remote, remote_name, disabled in cursor
                        if not local_name.startswith("r/")]

            if branches:
                trackedbranches = details.table("trackedbranches", cellspacing=0)
                trackedbranches.tr().th("title", colspan=5).text("Tracked Branches")

                row = trackedbranches.tr("headings")
                row.th("localname").text("Local branch")
                row.th("remote").text("Repository")
                row.th("remotename").text("Remote branch")
                row.th("enabled").text("Enabled")
                row.th("users").text("Users")

                default_remote = ""

                for branch_id, local_name, remote, remote_name, disabled in sorted(branches, key=lambda branch: branch[1]):
                    cursor.execute("SELECT uid FROM trackedbranchusers WHERE branch=%s", (branch_id,))

                    user_ids = [user_id for (user_id,) in cursor.fetchall()]

                    row = trackedbranches.tr("branch", critic_branch_id=branch_id, critic_user_ids=",".join(map(str, user_ids)))

                    if local_name == "*":
                        row.td("localname").i().text("Tags")
                        default_remote = remote
                    else:
                        row.td("localname").text(local_name)
                        if local_name == "master" and not default_remote:
                            default_remote = remote
                    row.td("remote").text(remote)
                    if remote_name == "*":
                        row.td("remotename").i().text("N/A")
                    else:
                        row.td("remotename").text(remote_name)
                    row.td("enabled").text("No" if disabled else "Yes")

                    cell = row.td("users")

                    for index, user_id in enumerate(user_ids):
                        if index: cell.text(", ")
                        trackedbranch_user = dbutils.User.fromId(db, user_id)
                        cell.span("user").text(trackedbranch_user.name)

                if default_remote:
                    repository.default_remote = default_remote

            buttons = details.div("buttons")
            buttons.button(onclick="addTrackedBranch(%d);" % repository.id).text("Add Tracked Branch")

    paleyellow = page.utils.PaleYellowTable(body, "Repositories")
    paleyellow.addCentered(render)

    repositories_js = []

    for repository in repositories:
        name = htmlutils.jsify(repository.name)
        path = htmlutils.jsify(repository.path)
        location = htmlutils.jsify(repository.location)
        default_remote = htmlutils.jsify(repository.default_remote)

        repositories_js.append(("%d: { name: %s, path: %s, location: %s, defaultRemoteLocation: %s }"
                                % (repository.id, name, path, location, default_remote)))

    document.addInternalScript("var repositories = { %s };" % ", ".join(repositories_js))

    return document

########NEW FILE########
__FILENAME__ = search
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2012 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import urlparse

import htmlutils
import textutils
import page.utils

def renderSearch(req, db, user):
    document = htmlutils.Document(req)
    document.setTitle("Review Search")

    html = document.html()
    head = html.head()
    body = html.body()

    page.utils.generateHeader(body, db, user, current_page="search")

    document.addExternalStylesheet("resource/search.css")
    document.addExternalScript("resource/search.js")
    document.addExternalScript("resource/autocomplete.js")
    document.addInternalScript(user.getJS())

    cursor = db.cursor()
    cursor.execute("SELECT name, fullname FROM users")

    users = dict(cursor)

    document.addInternalScript("var users = %s;" % textutils.json_encode(users))

    def renderQuickSearch(target):
        wrap = target.div("quicksearch callout")
        wrap.p().text("""A Quick Search dialog can be opened from any page
                         using the "F" keyboard shortcut.""")
        wrap.p().a(href="/tutorial?item=search").text("More information")

    def renderInput(target, label, name, placeholder=""):
        fieldset = target.fieldset("search-" + name)
        fieldset.label("input-label").text(label)
        fieldset.input(type="text", name=name, placeholder=placeholder)

    def renderInputWithOptions(target, label, name, options, placeholder=""):
        fieldset = target.fieldset("search-" + name)
        fieldset.label("input-label").text(label)
        checkGroup = fieldset.div("input-options checkbox-group")
        for option in options:
            opt_label = checkGroup.label()
            opt_label.input(type="checkbox", name=option["name"],
                            checked="checked" if "checked" in option else None)
            opt_label.text(option["label"])
        fieldset.input(type="text", name=name, placeholder=placeholder)

    def renderFreetext(target):
        options=[{ "name": "freetextSummary", "label": "Summary",
                   "checked": True },
                 { "name": "freetextDescription", "label": "Description",
                   "checked": True }]
        renderInputWithOptions(target, label="Search term", name="freetext",
                               placeholder="free text search", options=options)

    def renderState(target):
        state = target.fieldset("search-state")
        state.label("input-label").text("State")
        select = state.select(name="state")
        select.option(value="", selected="selected").text("Any state")
        select.option(value="open").text("Open")
        select.option(value="pending").text("Pending")
        select.option(value="accepted").text("Accepted")
        select.option(value="closed").text("Finished")
        select.option(value="dropped").text("Dropped")

    def renderUser(target):
        options=[{ "name": "userOwner", "label": "Owner", "checked": True },
                 { "name": "userReviewer", "label": "Reviewer" }]
        renderInputWithOptions(target, label="User", name="user",
                               placeholder="user name(s)", options=options)

    def renderRepository(target):
        fieldset = target.fieldset("search-repository")
        fieldset.label("input-label").text("Repository")
        page.utils.generateRepositorySelect(
            db, user, fieldset, name="repository", selected=False,
            placeholder_text="Any repository", allow_selecting_none=True)

    section = body.section("paleyellow section")
    section.h1("section-heading").text("Review Search")

    url_terms = []

    for name, value in urlparse.parse_qsl(req.query):
        if name == "q":
            url_terms.append(value)
        elif name.startswith("q"):
            url_terms.append("%s:%s" % (name[1:], value))

    wrap = section.div("flex")
    search = wrap.form("search", name="search")

    if url_terms:
        row = search.div("flex")
        query = row.fieldset("search-query")
        query.label("input-label").text("Search query")
        query.input(type="text", name="query", value=" ".join(url_terms))

        result = section.div("search-result", style="display: none")
        result.h2().text("Search result")
        result.div("callout")
    else:
        row = search.div("flex")
        renderFreetext(row)
        renderState(row)

        renderUser(search)

        row = search.div("flex")
        renderRepository(row)
        renderInput(row, "Branch", "branch")

        renderInput(search, "Path", "path")

    buttons = search.div("search-buttons")

    if url_terms:
        buttons.button(type="submit").text("Search again")
        buttons.a("button", href="/search").text("Show full search form")
    else:
        buttons.button(type="submit").text("Search")

    renderQuickSearch(wrap)

    return document

########NEW FILE########
__FILENAME__ = services
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2012 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import os
import socket
import time
import errno

import page.utils
import htmlutils
import dbutils
import configuration
import textutils

def renderServices(req, db, user):
    req.content_type = "text/html; charset=utf-8"

    document = htmlutils.Document(req)
    document.setTitle("Services")

    html = document.html()
    head = html.head()
    body = html.body()

    page.utils.generateHeader(body, db, user, current_page="services")

    document.addExternalStylesheet("resource/services.css")
    document.addExternalScript("resource/services.js")
    document.addInternalScript(user.getJS())

    delay = 0.5
    connected = False

    while not connected and delay <= 10:
        connection = socket.socket(socket.AF_UNIX, socket.SOCK_STREAM)

        # This loop is for the case where we just restarted the service manager
        # via the /services UI.  The client-side script immediately reloads the
        # page after restart, which typically leads to us trying to connect to
        # the service manager while it's in the process of restarting.  So just
        # try a couple of times if at first the connection fails.

        try:
            connection.connect(configuration.services.SERVICEMANAGER["address"])
            connected = True
        except socket.error as error:
            if error[0] in (errno.ENOENT, errno.ECONNREFUSED):
                time.sleep(delay)
                delay += delay
            else: raise

    if not connected:
        raise page.utils.DisplayMessage("Service manager not responding!")

    connection.send(textutils.json_encode({ "query": "status" }))
    connection.shutdown(socket.SHUT_WR)

    data = ""
    while True:
        received = connection.recv(4096)
        if not received: break
        data += received

    result = textutils.json_decode(data)

    if result["status"] == "error":
        raise page.utils.DisplayMessage(result["error"])

    paleyellow = page.utils.PaleYellowTable(body, "Services")

    def render(target):
        table = target.table("services callout")

        headings = table.tr("headings")
        headings.th("name").text("Name")
        headings.th("module").text("Module")
        headings.th("pid").text("PID")
        headings.th("rss").text("RSS")
        headings.th("cpu").text("CPU")
        headings.th("uptime").text("Uptime")
        headings.th("commands").text()

        table.tr("spacer").td("spacer", colspan=4)

        def formatUptime(seconds):
            def inner(seconds):
                if seconds < 60: return "%d seconds" % seconds
                elif seconds < 60 * 60: return "%d minutes" % (seconds / 60)
                elif seconds < 60 * 60 * 24: return "%d hours" % (seconds / (60 * 60))
                else: return "%d days" % (seconds / (60 * 60 * 24))
            return inner(int(seconds)).replace(" ", "&nbsp;")

        def formatRSS(bytes):
            if bytes < 1024: return "%d B" % bytes
            elif bytes < 1024 ** 2: return "%.1f kB" % (float(bytes) / 1024)
            elif bytes < 1024 ** 3: return "%.1f MB" % (float(bytes) / 1024 ** 2)
            else: return "%.1f GB" % (float(bytes) / 1024 ** 3)

        def formatCPU(seconds):
            minutes = int(seconds / 60)
            seconds = seconds - minutes * 60
            seconds = "%2.2f" % seconds
            if seconds.find(".") == 1: seconds = "0" + seconds
            return "%d:%s" % (minutes, seconds)

        def getProcessData(pid):
            try:
                items = open("/proc/%d/stat" % pid).read().split()

                return { "cpu": formatCPU(float(int(items[13]) + int(items[14])) / os.sysconf("SC_CLK_TCK")),
                         "rss": formatRSS(int(items[23]) * os.sysconf("SC_PAGE_SIZE")) }
            except:
                return { "cpu": "N/A",
                         "rss": "N/A" }

        for service_name, service_data in sorted(result["services"].items()):
            process_data = getProcessData(service_data["pid"])

            row = table.tr("service")
            row.td("name").text(service_name)
            row.td("module").text(service_data["module"])
            row.td("pid").text(service_data["pid"] if service_data["pid"] != -1 else "(not running)")
            row.td("rss").text(process_data["rss"])
            row.td("cpu").text(process_data["cpu"])
            row.td("uptime").innerHTML(formatUptime(service_data["uptime"]))

            commands = row.td("commands")
            commands.a(href="javascript:void(restartService(%s));" % htmlutils.jsify(service_name)).text("[restart]")
            commands.a(href="javascript:void(getServiceLog(%s));" % htmlutils.jsify(service_name)).text("[log]")

        for index, pid in enumerate(os.listdir(configuration.paths.WSGI_PIDFILE_DIR)):
            startup = float(open(os.path.join(configuration.paths.WSGI_PIDFILE_DIR, pid)).read())
            uptime = time.time() - startup

            process_data = getProcessData(int(pid))

            row = table.tr("service")
            row.td("name").text("wsgi:%d" % index)
            row.td("module").text()
            row.td("pid").text(pid)
            row.td("rss").text(process_data["rss"])
            row.td("cpu").text(process_data["cpu"])
            row.td("uptime").innerHTML(formatUptime(uptime))

            commands = row.td("commands")
            commands.a(href="javascript:void(restartService('wsgi'));").text("[restart]")

    paleyellow.addCentered(render)

    return document

########NEW FILE########
__FILENAME__ = showbatch
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2012 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import page.utils
import dbutils
import reviewing.comment as review_comment
import reviewing.utils as review_utils
import htmlutils
import diff

from htmlutils import jsify, htmlify

def renderShowBatch(req, db, user):
    batch_id = page.utils.getParameter(req, "batch", None, filter=int)
    review_id = page.utils.getParameter(req, "review", None, filter=int)

    cursor = db.cursor()

    if batch_id is None and review_id is None:
        return page.utils.displayMessage(db, req, user, "Missing argument: 'batch'")

    if batch_id:
        cursor.execute("SELECT review, uid, comment FROM batches WHERE id=%s", (batch_id,))

        row = cursor.fetchone()
        if not row:
            raise page.utils.DisplayMessage("Invalid batch ID: %d" % batch_id)

        review_id, author_id, chain_id = row
        author = dbutils.User.fromId(db, author_id)
    else:
        chain_id = None
        author = user

    review = dbutils.Review.fromId(db, review_id)

    if chain_id:
        batch_chain = review_comment.CommentChain.fromId(db, chain_id, user, review=review)
        batch_chain.loadComments(db, user)
    else:
        batch_chain = None

    document = htmlutils.Document(req)

    html = document.html()
    head = html.head()
    body = html.body()

    page.utils.generateHeader(body, db, user, lambda target: review_utils.renderDraftItems(db, user, review, target), extra_links=[("r/%d" % review.id, "Back to Review")])

    document.addExternalStylesheet("resource/showbatch.css")
    document.addExternalStylesheet("resource/showreview.css")
    document.addExternalStylesheet("resource/review.css")
    document.addExternalStylesheet("resource/comment.css")
    document.addExternalScript("resource/review.js")
    document.addExternalScript("resource/comment.js")
    document.addInternalScript(user.getJS())
    document.addInternalScript(review.getJS())

    if batch_chain:
        document.addInternalScript("commentChainById[%d] = %s;" % (batch_chain.id, batch_chain.getJSConstructor()))

    target = body.div("main")

    basic = target.table('paleyellow basic', align='center')
    basic.col(width='10%')
    basic.col(width='80%')
    basic.col(width='10%')
    basic.tr().td('h1', colspan=3).h1().text("Review by %s" % htmlify(author.fullname))

    if batch_chain:
        batch_chain.loadComments(db, user)

        row = basic.tr("line")
        row.td("heading").text("Comment:")
        row.td("value").preformatted().div("text").text(htmlify(batch_chain.comments[0].comment))
        row.td("status").text()

    def renderFiles(title):
        files = []

        for file_id, delete_count, insert_count in cursor.fetchall():
            files.append((dbutils.describe_file(db, file_id), delete_count, insert_count))

        paths = []
        deleted = []
        inserted = []

        for path, delete_count, insert_count in sorted(files):
            paths.append(path)
            deleted.append(delete_count)
            inserted.append(insert_count)

        if paths:
            diff.File.eliminateCommonPrefixes(paths)

            row = basic.tr("line")
            row.td("heading").text(title)

            table = row.td().table("files callout")
            headers = table.thead().tr()
            headers.th("path").text("Changed Files")
            headers.th(colspan=2).text("Lines")

            files = table.tbody()
            for path, delete_count, insert_count in zip(paths, deleted, inserted):
                file = files.tr()
                file.td("path").preformatted().innerHTML(path)
                file.td().preformatted().text(delete_count and "-%d" % delete_count or "")
                file.td().preformatted().text(delete_count and "+%d" % insert_count or "")

            row.td("status").text()

    def condition(table_name):
        if batch_id:
            return "%s.batch=%d" % (table_name, batch_id)
        else:
            return "review=%d AND %s.batch IS NULL AND %s.uid=%d" % (review.id, table_name, table_name, author.id)

    cursor.execute("""SELECT reviewfiles.file, SUM(deleted), SUM(inserted)
                        FROM reviewfiles
                        JOIN reviewfilechanges ON (reviewfilechanges.file=reviewfiles.id)
                       WHERE %s
                         AND reviewfilechanges.to='reviewed'
                    GROUP BY reviewfiles.file""" % condition("reviewfilechanges"))
    renderFiles("Reviewed:")

    cursor.execute("""SELECT reviewfiles.file, SUM(deleted), SUM(inserted)
                        FROM reviewfiles
                        JOIN reviewfilechanges ON (reviewfilechanges.file=reviewfiles.id)
                       WHERE %s
                         AND reviewfilechanges.to='pending'
                    GROUP BY reviewfiles.file""" % condition("reviewfilechanges"))
    renderFiles("Unreviewed:")

    def renderChains(title, replies):
        all_chains = [review_comment.CommentChain.fromId(db, id, user, review=review) for (id,) in rows]

        for chain in all_chains: chain.loadComments(db, user)

        issue_chains = filter(lambda chain: chain.type == "issue", all_chains)
        draft_issues = filter(lambda chain: chain.state == "draft", issue_chains)
        open_issues = filter(lambda chain: chain.state == "open", issue_chains)
        addressed_issues = filter(lambda chain: chain.state == "addressed", issue_chains)
        closed_issues = filter(lambda chain: chain.state == "closed", issue_chains)
        note_chains = filter(lambda chain: chain.type == "note", all_chains)
        draft_notes = filter(lambda chain: chain.state == "draft" and chain != batch_chain, note_chains)
        open_notes = filter(lambda chain: chain.state == "open" and chain != batch_chain, note_chains)

        def renderChains(target, chains):
            for chain in chains:
                row = target.tr("comment")
                row.td("author").text(chain.user.fullname)
                row.td("title").a(href="showcomment?chain=%d" % chain.id).innerHTML(chain.leader())
                row.td("when").text(chain.when())

        if draft_issues or open_issues or addressed_issues or closed_issues:
            chains = target.table("paleyellow comments", align="center", cellspacing=0)
            chains.tr().td("h1", colspan=3).h1().text(title)

            if draft_issues:
                chains.tr(id="draft-issues").td("h2", colspan=3).h2().text("Draft Issues").a(href="showcomments?review=%d&filter=draft-issues" % review.id).text("[display all]")
                renderChains(chains, draft_issues)

            if batch_id is not None or replies:
                if open_issues:
                    h2 = chains.tr(id="open-issues").td("h2", colspan=3).h2().text("Still Open Issues")
                    if batch_id:
                        h2.a(href="showcomments?review=%d&filter=open-issues&batch=%d" % (review.id, batch_id)).text("[display all]")
                    renderChains(chains, open_issues)

                if addressed_issues:
                    h2 = chains.tr(id="addressed-issues").td("h2", colspan=3).h2().text("Now Addressed Issues")
                    if batch_id:
                        h2.a(href="showcomments?review=%d&filter=addressed-issues&batch=%d" % (review.id, batch_id)).text("[display all]")
                    renderChains(chains, addressed_issues)

                if closed_issues:
                    h2 = chains.tr(id="closed-issues").td("h2", colspan=3).h2().text("Now Closed Issues")
                    if batch_id:
                        h2.a(href="showcomments?review=%d&filter=closed-issues&batch=%d" % (review.id, batch_id)).text("[display all]")
                    renderChains(chains, closed_issues)

        if draft_notes or open_notes:
            chains = target.table("paleyellow comments", align="center", cellspacing=0)
            chains.tr().td("h1", colspan=3).h1().text(title)

            if draft_notes:
                chains.tr(id="draft-notes").td("h2", colspan=3).h2().text("Draft Notes").a(href="showcomments?review=%d&filter=draft-notes" % review.id).text("[display all]")
                renderChains(chains, draft_notes)

            if open_notes:
                h2 = chains.tr(id="notes").td("h2", colspan=3).h2().text("Notes")
                if batch_id:
                    h2.a(href="showcomments?review=%d&filter=open-notes&batch=%d" % (review.id, batch_id)).text("[display all]")
                renderChains(chains, open_notes)

    cursor.execute("SELECT id FROM commentchains WHERE %s AND type='issue'" % condition("commentchains"))
    rows = cursor.fetchall()

    if rows: renderChains("Raised Issues", False)

    cursor.execute("SELECT id FROM commentchains WHERE %s AND type='note'" % condition("commentchains"))
    rows = cursor.fetchall()

    if rows: renderChains("Written Notes", False)

    cursor.execute("""SELECT commentchains.id
                        FROM commentchains
                        JOIN comments ON (comments.chain=commentchains.id)
                       WHERE %s
                         AND comments.id!=commentchains.first_comment""" % condition("comments"))
    rows = cursor.fetchall()

    if rows: renderChains("Replied To", True)

    return document

########NEW FILE########
__FILENAME__ = showbranch
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2012 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import page.utils
import gitutils
import dbutils
import htmlutils
import configuration
import request

import log.html as log_html

def renderShowBranch(req, db, user):
    branch_name = req.getParameter("branch")
    base_name = req.getParameter("base", None)
    review_id = req.getParameter("review", None)

    repository = req.getParameter("repository", user.getPreference(db, "defaultRepository"))
    if not repository:
        raise request.MissingParameter("repository")
    repository = gitutils.Repository.fromParameter(db, repository)

    cursor = db.cursor()

    cursor.execute("SELECT id, type, base, head, tail FROM branches WHERE name=%s AND repository=%s", (branch_name, repository.id))

    try:
        branch_id, branch_type, base_id, head_id, tail_id = cursor.fetchone()
    except:
        return page.utils.displayMessage(db, req, user, "'%s' doesn't name a branch!" % branch_name)

    branch = dbutils.Branch.fromName(db, repository, branch_name)
    rebased = False

    if base_name:
        base = dbutils.Branch.fromName(db, repository, base_name)

        if base is None:
            return page.utils.displayMessage(db, req, user, "'%s' doesn't name a branch!" % base_name)

        old_count, new_count, base_old_count, base_new_count = branch.rebase(db, base)

        if base_old_count is not None:
            new_base_base_name = base.base.name
        else:
            new_base_base_name = None

        rebased = True

    document = htmlutils.Document(req)

    html = document.html()
    head = html.head()
    body = html.body()

    document.addExternalStylesheet("resource/showbranch.css")

    def renderCreateReview(target):
        if not user.isAnonymous() and branch and branch.review is None and not rebased:
            url = htmlutils.URL("/createreview", repository=repository.id, branch=branch_name)
            target.a("button", href=url).text("Create Review")

    if review_id is not None:
        extra_links = [("r/%s" % review_id, "Back to Review")]
    else:
        extra_links = []
    page.utils.generateHeader(body, db, user, renderCreateReview, extra_links=extra_links)

    document.addInternalScript(branch.getJS())

    title_right = None

    if rebased:
        def renderPerformRebase(db, target):
            target.button("perform", onclick="rebase(%s, %s, %s, %s, %s, %s, %s)" % tuple(map(htmlutils.jsify, [branch_name, base_name, new_base_base_name, old_count, new_count, base_old_count, base_new_count]))).text("Perform Rebase")

        title_right = renderPerformRebase
    elif base_id is not None:
        bases = []
        base = branch.base

        if base:
            if base.type == "review":
                bases.append("master")
            else:
                base = base.base
                while base:
                    bases.append(base.name)
                    base = base.base

        cursor.execute("SELECT name FROM branches WHERE base=%s", (branch.id,))

        for (name,) in cursor:
            bases.append(name)

        def renderSelectBase(db, target):
            select = target.select("base")
            select.option(value="*").text("Select new base")
            select.option(value="*").text("---------------")

            for name in bases:
                select.option("base", value=name.split(" ")[0]).text(name)

        if not bases and branch.base:
            cursor.execute("SELECT commit FROM reachable WHERE branch=%s", (branch.id,))

            commit_ids = cursor.fetchall()

            body.comment(repr(commit_ids))

            for commit_id in commit_ids:
                cursor.execute("SELECT 1 FROM reachable WHERE branch=%s AND commit=%s", (branch.base.id, commit_id))
                if cursor.fetchone():
                    bases.append("%s (trim)" % branch.base.name)
                    break

        if bases:
            title_right = renderSelectBase

    target = body.div("main")

    if branch_type == 'normal':
        cursor.execute("SELECT COUNT(*) FROM reachable WHERE branch=%s", (branch_id,))

        commit_count = cursor.fetchone()[0]
        if commit_count > configuration.limits.MAXIMUM_REACHABLE_COMMITS:
            offset = req.getParameter("offset", default=0, filter=int)
            limit = req.getParameter("limit", default=200, filter=int)

            head = gitutils.Commit.fromId(db, repository, head_id)
            tail = gitutils.Commit.fromId(db, repository, tail_id) if tail_id else None

            sha1s = repository.revlist([head], [tail] if tail else [], "--skip=%d" % offset, "--max-count=%d" % limit)
            commits = [gitutils.Commit.fromSHA1(db, repository, sha1) for sha1 in sha1s]

            def moreCommits(db, target):
                target.a(href="/log?branch=%s&offset=%d&limit=%d" % (branch_name, offset + limit, limit)).text("More commits...")

            log_html.renderList(db, target, branch.name, commits, title_right=title_right, bottom_right=moreCommits)

            return document

    branch.loadCommits(db)

    log_html.render(db, target, branch.name, branch=branch, title_right=title_right)

    return document

########NEW FILE########
__FILENAME__ = showcomment
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2012 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import dbutils
import htmlutils
import page.utils
import profiling
import linkify

import reviewing.comment as review_comment
import reviewing.utils as review_utils
import reviewing.html as review_html
import changeset.utils as changeset_utils

import operation.blame
import log.commitset

def renderShowComment(req, db, user):
    chain_id = req.getParameter("chain", filter=int)
    context_lines = req.getParameter("context", user.getPreference(db, "comment.diff.contextLines"), filter=int)

    default_compact = "yes" if user.getPreference(db, "commit.diff.compactMode") else "no"
    compact = req.getParameter("compact", default_compact) == "yes"

    default_tabify = "yes" if user.getPreference(db, "commit.diff.visualTabs") else "no"
    tabify = req.getParameter("tabify", default_tabify) == "yes"

    original = req.getParameter("original", "no") == "yes"

    chain = review_comment.CommentChain.fromId(db, chain_id, user)

    if chain is None or chain.state == "empty":
        raise page.utils.DisplayMessage("Invalid comment chain ID: %d" % chain_id)

    review = chain.review

    document = htmlutils.Document(req)

    html = document.html()
    head = html.head()
    body = html.body()

    document.setTitle("%s in review %s" % (chain.title(False), review.branch.name))

    def renderHeaderItems(target):
        review_utils.renderDraftItems(db, user, review, target)
        target.div("buttons").span("buttonscope buttonscope-global")

    page.utils.generateHeader(body, db, user, renderHeaderItems, extra_links=[("r/%d" % review.id, "Back to Review")])

    document.addExternalScript("resource/showcomment.js")
    document.addInternalScript(user.getJS(db))
    document.addInternalScript(review.repository.getJS())
    document.addInternalScript(review.getJS())
    document.addInternalScript("var contextLines = %d;" % context_lines)
    document.addInternalScript("var keyboardShortcuts = %s;" % (user.getPreference(db, "ui.keyboardShortcuts") and "true" or "false"))

    if not user.isAnonymous() and user.name == req.user:
        document.addInternalScript("$(function () { markChainsAsRead([%d]); });" % chain_id)

    review_html.renderCommentChain(db, body.div("main"), user, review, chain, context_lines=context_lines, compact=compact, tabify=tabify, original=original, linkify=linkify.Context(db=db, request=req, review=review))

    if user.getPreference(db, "ui.keyboardShortcuts"):
        page.utils.renderShortcuts(body, "showcomment")

    yield document.render(pretty=not compact)

def renderShowComments(req, db, user):
    context_lines = req.getParameter("context", user.getPreference(db, "comment.diff.contextLines"), filter=int)

    default_compact = "yes" if user.getPreference(db, "commit.diff.compactMode") else "no"
    compact = req.getParameter("compact", default_compact) == "yes"

    default_tabify = "yes" if user.getPreference(db, "commit.diff.visualTabs") else "no"
    tabify = req.getParameter("tabify", default_tabify) == "yes"

    original = req.getParameter("original", "no") == "yes"

    review_id = req.getParameter("review", filter=int)
    batch_id = req.getParameter("batch", None, filter=int)
    filter = req.getParameter("filter", "all")
    blame = req.getParameter("blame", None)

    profiler = profiling.Profiler()

    review = dbutils.Review.fromId(db, review_id)
    review.repository.enableBlobCache()

    cursor = db.cursor()

    profiler.check("create review")

    if blame is not None:
        blame_user = dbutils.User.fromName(db, blame)

        cursor.execute("""SELECT commentchains.id
                            FROM commentchains
                            JOIN commentchainlines ON (commentchainlines.chain=commentchains.id)
                            JOIN fileversions ON (fileversions.new_sha1=commentchainlines.sha1)
                            JOIN changesets ON (changesets.id=fileversions.changeset)
                            JOIN commits ON (commits.id=changesets.child)
                            JOIN gitusers ON (gitusers.id=commits.author_gituser)
                            JOIN usergitemails USING (email)
                            JOIN reviewchangesets ON (reviewchangesets.changeset=changesets.id AND reviewchangesets.review=commentchains.review)
                           WHERE commentchains.review=%s
                             AND usergitemails.uid=%s
                             AND commentchains.state!='empty'
                             AND (commentchains.state!='draft' OR commentchains.uid=%s)
                        ORDER BY commentchains.file, commentchainlines.first_line""",
                       (review.id, blame_user.id, user.id))

        include_chain_ids = set([chain_id for (chain_id,) in cursor])

        profiler.check("initial blame filtering")
    else:
        include_chain_ids = None

    if filter == "toread":
        query = """SELECT commentchains.id
                     FROM commentchains
                     JOIN comments ON (comments.chain=commentchains.id)
                     JOIN commentstoread ON (commentstoread.comment=comments.id)
          LEFT OUTER JOIN commentchainlines ON (commentchainlines.chain=commentchains.id)
                    WHERE review=%s
                      AND commentstoread.uid=%s
                 ORDER BY file, first_line"""

        cursor.execute(query, (review.id, user.id))
    else:
        query = """SELECT commentchains.id
                     FROM commentchains
          LEFT OUTER JOIN commentchainlines ON (chain=id)
                    WHERE review=%s
                      AND commentchains.state!='empty'"""

        arguments = [review.id]

        if filter == "issues":
            query += " AND type='issue' AND (commentchains.state!='draft' OR commentchains.uid=%s)"
            arguments.append(user.id)
        elif filter == "draft-issues":
            query += " AND type='issue' AND commentchains.state='draft' AND commentchains.uid=%s"
            arguments.append(user.id)
        elif filter == "open-issues":
            query += " AND type='issue' AND commentchains.state='open'"
        elif filter == "addressed-issues":
            query += " AND type='issue' AND commentchains.state='addressed'"
        elif filter == "closed-issues":
            query += " AND type='issue' AND commentchains.state='closed'"
        elif filter == "notes":
            query += " AND type='note' AND (commentchains.state!='draft' OR commentchains.uid=%s)"
            arguments.append(user.id)
        elif filter == "draft-notes":
            query += " AND type='note' AND commentchains.state='draft' AND commentchains.uid=%s"
            arguments.append(user.id)
        elif filter == "open-notes":
            query += " AND type='note' AND commentchains.state='open'"
        else:
            query += " AND (commentchains.state!='draft' OR commentchains.uid=%s)"
            arguments.append(user.id)

        if batch_id is not None:
            query += " AND batch=%s"
            arguments.append(batch_id)

        # This ordering is inaccurate if comments apply to the same file but
        # different commits, but then, in that case there isn't really a
        # well-defined natural order either.  Two comments that apply to the
        # same file and commit will at least be order by line number, and that's
        # better than nothing.
        query += " ORDER BY file, first_line"

        cursor.execute(query, arguments)

    profiler.check("main query")

    if include_chain_ids is None:
        chain_ids = [chain_id for (chain_id,) in cursor]
    else:
        chain_ids = [chain_id for (chain_id,) in cursor if chain_id in include_chain_ids]

    profiler.check("query result")

    document = htmlutils.Document(req)

    html = document.html()
    head = html.head()
    body = html.body()

    document.addInternalScript(user.getJS(db))
    document.addInternalScript(review.getJS())

    page.utils.generateHeader(body, db, user, lambda target: review_utils.renderDraftItems(db, user, review, target), extra_links=[("r/%d" % review.id, "Back to Review")])

    profiler.check("page header")

    target = body.div("main")

    if chain_ids and not user.isAnonymous() and user.name == req.user:
        document.addInternalScript("$(function () { markChainsAsRead([%s]); });" % ", ".join(map(str, chain_ids)))

    if chain_ids:
        processed = set()

        chains = []
        file_ids = set()
        changesets_files = {}
        changesets = {}

        if blame is not None:
            annotators = {}
            review.branch.loadCommits(db)
            commits = log.commitset.CommitSet(review.branch.commits)

        for chain_id in chain_ids:
            if chain_id in processed:
                continue
            else:
                processed.add(chain_id)

                chain = review_comment.CommentChain.fromId(db, chain_id, user, review=review)
                chains.append(chain)

                if chain.file_id is not None:
                    file_ids.add(chain.file_id)
                    parent, child = review_html.getCodeCommentChainChangeset(db, chain, original)
                    if parent and child:
                        changesets_files.setdefault((parent, child), set()).add(chain.file_id)

        profiler.check("load chains")

        changeset_cache = {}

        for (from_commit, to_commit), filtered_file_ids in changesets_files.items():
            changesets[(from_commit, to_commit)] = changeset_utils.createChangeset(db, user, review.repository, from_commit=from_commit, to_commit=to_commit, filtered_file_ids=filtered_file_ids)[0]
            profiler.check("create changesets")

            if blame is not None:
                annotators[(from_commit, to_commit)] = operation.blame.LineAnnotator(db, from_commit, to_commit, file_ids=file_ids, commits=commits, changeset_cache=changeset_cache)
                profiler.check("create annotators")

        for chain in chains:
            if blame is not None and chain.file_id is not None:
                try:
                    changeset = changesets[(chain.first_commit, chain.last_commit)]
                    annotator = annotators[(chain.first_commit, chain.last_commit)]
                except KeyError:
                    # Most likely a comment created via /showfile.  Such a
                    # comment could be in code that 'blame_user' modified in the
                    # review, but for now, let's skip the comment.
                    continue
                else:
                    file_in_changeset = changeset.getFile(chain.file_id)

                    if not file_in_changeset:
                        continue

                    try:
                        offset, count = chain.lines_by_sha1[file_in_changeset.new_sha1]
                    except KeyError:
                        # Probably a chain raised against the "old" side of the diff.
                        continue
                    else:
                        if not annotator.annotate(chain.file_id, offset, offset + count - 1, check_user=blame_user):
                            continue

            profiler.check("detailed blame filtering")

            if chain.file_id is not None:
                from_commit, to_commit = review_html.getCodeCommentChainChangeset(db, chain, original)
                changeset = changesets.get((from_commit, to_commit))
            else:
                changeset = None

            review_html.renderCommentChain(db, target, user, review, chain,
                                           context_lines=context_lines,
                                           compact=compact,
                                           tabify=tabify,
                                           original=original,
                                           changeset=changeset,
                                           linkify=linkify.Context(db=db, request=req, review=review))

            profiler.check("rendering")

            yield document.render(stop=target, pretty=not compact) + "<script>console.log((new Date).toString());</script>"

            profiler.check("transfer")

        page.utils.renderShortcuts(target, "showcomments")
    else:
        target.h1(align="center").text("No comments.")

    profiler.output(db, user, document)

    yield document.render(pretty=not compact)

########NEW FILE########
__FILENAME__ = showcommit
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2012 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import htmlutils
import page.utils
import dbutils
import gitutils
import diff
import changeset.html as changeset_html
import changeset.utils as changeset_utils
import changeset.detectmoves as changeset_detectmoves
import reviewing.utils as review_utils
import reviewing.comment as review_comment
import reviewing.filters as review_filters
import log.html as log_html
from log.commitset import CommitSet
import profiling
import re

def renderCommitInfo(db, target, user, repository, review, commit, conflicts=False, minimal=False):
    cursor = db.cursor()

    msg = commit.message.splitlines()

    commit_info = target.table("commit-info")

    def outputBranches(target, commit):
        cursor.execute("""SELECT branches.name, reviews.id
                            FROM branches
                            JOIN reachable ON (reachable.branch=branches.id)
                            JOIN commits ON (commits.id=reachable.commit)
                 LEFT OUTER JOIN reviews ON (reviews.branch=branches.id)
                           WHERE branches.repository=%s
                             AND commits.sha1=%s""",
                       (repository.id, commit.sha1))

        for branch, review_id in cursor:
            span = cell.span("branch")

            if review_id is None:
                url = htmlutils.URL("/log", repository=repository.id, branch=branch)
                title = branch
            else:
                url = "/r/%d" % review_id
                title = url

            span.text("[")
            span.a("branch", href=url).text(title)
            span.text("]")

    def outputTags(target, commit):
        cursor.execute("SELECT name FROM tags WHERE repository=%s AND sha1=%s",
                       (repository.id, commit.sha1))

        for (tag,) in cursor:
            target.span("tag").text("[%s]" % tag)

    if len(commit.parents) > 1:
        row = commit_info.tr("commit-info")
        row.th(align='right').text("Alternate view:")

        review_arg = "&review=%d" % review.id if review else ""

        if conflicts:
            row.td(align='left').a(href="/showcommit?sha1=%s&repository=%d%s" % (commit.sha1, repository.id, review_arg)).text("display changes relative to parents")
        else:
            row.td(align='left').a(href="/showcommit?sha1=%s&repository=%d%s&conflicts=yes" % (commit.sha1, repository.id, review_arg)).text("display conflict resolution changes")

    row = commit_info.tr("commit-info")
    row.th(align='right').text("SHA-1:")
    cell = row.td(align='left')

    if minimal:
        cell.a(href="/%s/%s?review=%d" % (repository.name, commit.sha1, review.id)).text(commit.sha1)
    else:
        cell.text(commit.sha1)

    if repository.name != user.getPreference(db, "defaultRepository"):
        cell.text(" in ")
        cell.b().text(repository.getURL(db, user))

    if not minimal:
        if review: review_arg = "&review=%d" % review.id
        else: review_arg = ""

        span = cell.span("links").span("link")
        span.text("[")
        span.a("link", href="/showtree?sha1=%s%s" % (commit.sha1, review_arg)).innerHTML("browse&nbsp;tree")
        span.text("]")

    if not review:
        outputBranches(cell.span("branches"), commit)
        outputTags(cell.span("tags"), commit)

    if minimal or commit.author.email != commit.committer.email or commit.author.time != commit.committer.time:
        row = commit_info.tr("commit-info")
        row.th(align='right').text("Author:")
        row.td(align='left').text(str(commit.author))

        if not minimal:
            row = commit_info.tr("commit-info")
            row.th(align='right').text("Commit:")
            row.td(align='left').text(str(commit.committer))
    else:
        row = commit_info.tr("commit-info")
        row.th(align='right').text("Author/Commit:")
        row.td(align='left').text(str(commit.author))

    if not minimal:
        if review: review_url_contribution = "?review=%d" % review.id
        else: review_url_contribution = ""

        for parent_sha1 in commit.parents:
            parent = gitutils.Commit.fromSHA1(db, repository, parent_sha1)

            if not review or review.containsCommit(db, parent):
                parent_href = "/%s/%s%s" % (repository.name, parent.sha1, review_url_contribution)

                row = commit_info.tr("commit-info")
                row.th(align='right').text("Parent:")
                cell = row.td(align='left')
                cell.a(href=parent_href, rel="previous").text("%s" % parent.niceSummary())
                cell.setLink("previous", parent_href)

                if not review:
                    outputBranches(cell.span("branches"), parent)
                    outputTags(cell.span("tags"), parent)

        cursor.execute("SELECT child FROM edges WHERE parent=%s", [commit.id])
        child_ids = cursor.fetchall()

        for (child_id,) in child_ids:
            if not review or review.containsCommit(db, child_id):
                try: child = gitutils.Commit.fromId(db, repository, child_id)
                except: continue

                child_href = "/%s/%s%s" % (repository.name, child.sha1, review_url_contribution)

                row = commit_info.tr("commit-info")
                row.th(align='right').text("Child:")
                cell = row.td(align='left')
                cell.a(href=child_href).text("%s" % child.niceSummary())

                if len(child_ids) == 1: cell.setLink("next", child_href)

                if not review:
                    outputBranches(cell.span("branches"), child)
                    outputTags(cell.span("tags"), child)

    def linkToCommit(commit):
        if review:
            cursor.execute("SELECT 1 FROM commits JOIN changesets ON (child=commits.id) JOIN reviewchangesets ON (changeset=changesets.id) WHERE sha1=%s AND review=%s", (commit.sha1, review.id))
            if cursor.fetchone():
                return "%s/%s?review=%d" % (repository.name, commit.sha1, review.id)
        return "%s/%s" % (repository.name, commit.sha1)

    highlight_index = 0

    if msg[0].startswith("fixup!") or msg[0].startswith("squash!"):
        for candidate_index, line in enumerate(msg[1:]):
            if line.strip():
                highlight_index = candidate_index + 1
                break

    commit_msg = commit_info.tr("commit-msg").td(colspan=2).table("commit-msg", cellspacing=0)
    for index, text in enumerate(msg):
        className = "line single"
        if index == 0: className += " first"
        elif index == len(msg) - 1: className += " last"
        if index < highlight_index or len(commit.parents) > 1:
            lengthLimit = None
        elif index == highlight_index:
            lengthLimit = "60-80"
        else:
            lengthLimit = "70-90"
        if index == highlight_index:
            className += " highlight"
        row = commit_msg.tr(className)
        row.td("edge").text()
        cell = row.td("line single commit-msg", id="msg%d" % index, critic_length_limit=lengthLimit)
        if text: cell.preformatted().text(text, linkify=linkToCommit, repository=repository)
        else: cell.text()
        row.td("edge").text()

    commit_msg.script(type="text/javascript").text("applyLengthLimit($(\"table.commit-msg td.line.commit-msg\"))");

    if review:
        chains = review_comment.loadCommentChains(db, review, user, commit=commit)

        for chain in chains:
            commit_info.addInternalScript("commentChains.push(%s);" % chain.getJSConstructor(commit.sha1))

def renderCommitFiles(db, target, user, repository, review, changeset=None, changesets=None, file_id="f%d", approve_file_id="a%d", parent_index=None, nparents=1, conflicts=False, files=None):
    def countChanges(file):
        delete_count = 0
        insert_count = 0
        if file.chunks:
            for chunk in file.chunks:
                delete_count += chunk.delete_count
                insert_count += chunk.insert_count
        return delete_count, insert_count

    commit_files = target.table("commit-files", cellspacing=0)

    if nparents > 1:
        def getpath(x): return x[1]
        def setpath(x, p): x[1] = p

        diff.File.eliminateCommonPrefixes(files, getpath=getpath, setpath=setpath)

        for data in files:
            in_parent = data[2]
            for index in range(len(in_parent)):
                file_in_parent = in_parent[index]
                if file_in_parent:
                    in_parent[index] = (file_in_parent, countChanges(file_in_parent))
                else:
                    in_parent[index] = (None, None)

        section = commit_files.thead()
        row = section.tr("parents")

        if review:
            row.th("approve").text("Reviewed")

        row.th().text("Changed Files")

        review_files = []

        for index in range(nparents):
            if conflicts and index + 1 == nparents: text = "Conflicts"
            else: text = "Parent %d" % (index + 1)

            row.th("parent", colspan=2).text(text)

            if review:
                review_files.append(changesets[index].getReviewFiles(db, user, review))

        if review:
            row.th("reviewed-by").text("Reviewed By")

        section = commit_files.tbody()

        for file_id, file_path, in_parent in files:
            row = section.tr(critic_file_id=file_id)
            fully_approved = True

            if review:
                approve = row.td("approve file")
                reviewers = {}

                for index, (file, lines) in enumerate(in_parent):
                    if file:
                        span = approve.span("parent%d" % index)

                        if review_files[index].has_key(file.id):
                            review_file = review_files[index][file.id]
                            can_approve = review_file[0]
                            is_approved = review_file[1] == "reviewed"

                            for user_id in review_file[2]:
                                reviewers[user_id] = dbutils.User.fromId(db, user_id)

                            if not is_approved: fully_approved = False
                        else:
                            can_approve = False
                            is_approved = True

                        if can_approve:
                            if is_approved: checked = "checked"
                            else: checked = None
                            input = span.input(type="checkbox", critic_parent_index=index, id="p%da%d" % (index, file.id), checked=checked)
                        elif not is_approved:
                            span.text("pending")

            row.td("path").a(href="#f%d" % file_id).innerHTML(file_path)

            for index, (file, lines) in enumerate(in_parent):
                if file:
                    if file.isBinaryChanges():
                        row.td("parent", colspan=2, critic_parent_index=index).i().text("binary")
                    elif file.isEmptyFile():
                        row.td("parent", colspan=2, critic_parent_index=index).i().text("empty")
                    elif file.old_mode == "160000" and file.new_mode == "160000":
                        if conflicts and index + 1 == nparents:
                            row.td(colspan=2).text()
                        else:
                            module_repository = repository.getModuleRepository(db, changesets[index].child, file.path)
                            if module_repository:
                                url = "/showcommit?repository=%d&from=%s&to=%s" % (module_repository.id, file.old_sha1, file.new_sha1)
                                row.td("parent", critic_parent_index=index, colspan=2).i().a(href=url).text("updated submodule")
                            else:
                                row.td("parent", critic_parent_index=index, colspan=2).i().text("updated submodule")
                    else:
                        row.td("parent", critic_parent_index=index).text(lines[0] and "-%d" % lines[0] or "")
                        row.td("parent", critic_parent_index=index).text(lines[1] and "+%d" % lines[1] or "")
                else:
                    row.td(colspan=2).text()

            if review:
                cell = row.td("reviewed-by")
                names = sorted([user.fullname for user in reviewers.values()])
                if names:
                    if fully_approved: cell.text(", ".join(names))
                    else:  cell.text("( " + ", ".join(names) + " )")
                else: cell.text()

        return

    paths = diff.File.eliminateCommonPrefixes([file.path for file in changeset.files])
    changes = map(countChanges, changeset.files)

    if review:
        review_files = changeset.getReviewFiles(db, user, review)

    additional = False
    for file in changeset.files:
        if (file.old_mode and file.new_mode and file.old_mode != file.new_mode) or (file.wasRemoved() and file.old_mode) or (file.wasAdded() and file.new_mode):
            additional = True
            break
        elif (file.old_mode and file.old_mode == "160000") or (file.new_mode and file.new_mode == "160000"):
            additional = True

    section = commit_files.thead()
    row = section.tr()
    ncolumns = 3

    if review:
        row.th("approve").text("Reviewed")
        ncolumns += 1
    row.th().text("Changed Files")
    row.th(colspan=2).text("Lines")
    if additional:
        row.th().text("Additional")
        ncolumns += 1
    if review:
        row.th().text("Reviewed By")
        ncolumns += 1

    if review:
        for is_reviewer, state, reviewers in review_files.values():
            if is_reviewer:
                can_approve_anything = True
                break
        else:
            can_approve_anything = False

    section = commit_files.tbody()
    if review and can_approve_anything:
        row = section.tr()
        checkbox_everything = row.td("approve everything").input(type="checkbox", __generator__=True)
        row.td(colspan=ncolumns - 1).i().text("Everything")
    else:
        checkbox_everything = None

    all_reviewed = True

    for file, path, lines in zip(changeset.files, paths, changes):
        row = section.tr(critic_file_id=file.id)
        fully_reviewed = True
        if parent_index is not None:
            row.setAttribute("critic-parent-index", parent_index)
        if review:
            if file.id in review_files:
                review_file = review_files[file.id]
                can_review = review_file[0]
                is_reviewed = review_file[1] == "reviewed"
                reviewers = [dbutils.User.fromId(db, user_id) for user_id in review_file[2]]
            else:
                can_review = False
                is_reviewed = True
                reviewers = []

            if not is_reviewed: fully_reviewed = False

            if can_review:
                if is_reviewed: checked = "checked"
                else:
                    checked = None
                    all_reviewed = False
                input = row.td("approve file").input(type="checkbox", critic_parent_index=parent_index, id=approve_file_id % file.id, checked=checked)
            else:
                if is_reviewed:
                    cell = row.td()
                    cell.text()
                else:
                    row.td("approve file").text("pending")

        row.td("path").a(href=("#" + file_id) % file.id).innerHTML(path)
        if file.hasChanges():
            if file.isBinaryChanges():
                row.td(colspan=2).i().text("binary")
            elif file.isEmptyFile():
                row.td(colspan=2).i().text("empty")
            else:
                row.td().text(lines[0] and "-%d" % lines[0] or "")
                row.td().text(lines[1] and "+%d" % lines[1] or "")
        else:
            row.td(colspan=2).i().text("no changes")

        if file.old_mode is not None and file.new_mode is not None and file.old_mode != file.new_mode:
            cell = row.td()
            cell.i().text("mode: ")
            cell.text("%s => %s" % (file.old_mode, file.new_mode))
        elif (file.wasRemoved() and file.old_mode) or (file.wasAdded() and file.new_mode):
            cell = row.td()
            if file.old_mode == "160000" or file.new_mode == "160000":
                cell.i().text("added submodule" if file.wasAdded() else "removed submodule")
            else:
                cell.i().text("added: " if file.wasAdded() else "removed: ")
                cell.text("%s" % file.new_mode if file.wasAdded() else file.old_mode)
        elif file.old_mode == "160000" and file.new_mode == "160000":
            module_repository = repository.getModuleRepository(db, changeset.child, file.path)
            if module_repository:
                url = "/showcommit?repository=%d&from=%s&to=%s" % (module_repository.id, file.old_sha1, file.new_sha1)
                row.td().i().a(href=url).text("updated submodule")
            else:
                row.td().i().text("updated submodule")
        elif additional:
            row.td().text()

        if review:
            cell = row.td("reviewed-by")
            names = sorted([user.fullname for user in reviewers])
            if names:
                if fully_reviewed: cell.text(", ".join(names))
                else: cell.text("( " + ", ".join(names) + " )")
            else: cell.text()

    if all_reviewed and checkbox_everything:
        checkbox_everything.setAttribute("checked", "checked")

    target.script().text("registerPathHandlers();")

def render(db, target, user, repository, review, changesets, commits, listed_commits=None, context_lines=3, is_merge=False, conflicts=False, moves=False, compact=False, wrap=True, tabify=False, profiler=None, rebases=None):
    cursor = db.cursor()

    main = target.div("main")

    options = {}

    if not user.getPreference(db, "ui.keyboardShortcuts"):
        options['show'] = True

    if user.getPreference(db, "commit.expandAllFiles"):
        options['show'] = True
        options['expand'] = True

    if compact:
        options['compact'] = True

    if tabify:
        options['tabify'] = True

    options['commit'] = changesets[0].child

    if len(changesets) == 1:
        if commits and len(commits) > 1:
            def linkToCommit(commit, overrides={}):
                if review: return "%s/%s?review=%d" % (repository.name, commit.sha1, review.id)
                else: return "%s/%s" % (repository.name, commit.sha1)

            columns = [(10, log_html.WhenColumn()),
                       (5, log_html.TypeColumn()),
                       (65, log_html.SummaryColumn(linkToCommit)),
                       (20, log_html.AuthorColumn())]

            log_html.render(db, main, "Squashed History", commits=commits, listed_commits=listed_commits, rebases=rebases, review=review, columns=columns, collapsable=True)
        elif changesets[0].parent is None or (changesets[0].parent.sha1 in changesets[0].child.parents) or conflicts:
            if conflicts and len(changesets[0].child.parents) == 1:
                commit = changesets[0].parent
            else:
                commit = changesets[0].child
            renderCommitInfo(db, main, user, repository, review, commit, conflicts)
        else:
            main.setAttribute("style", "margin-bottom: 20px; padding-bottom: 10px")

        if moves:
            def renderMoveHeaderLeft(db, target, file):
                target.text(file.move_source_file.path)
            def renderMoveHeaderRight(db, target, file):
                target.text(file.move_target_file.path)

            options['show'] = True
            options['expand'] = True
            options['support_expand'] = False
            options['header_left'] = renderMoveHeaderLeft
            options['header_right'] = renderMoveHeaderRight

            context_lines = 0
        else:
            renderCommitFiles(db, target, user, repository, review, changeset=changesets[0])

        yield target

        for stop in changeset_html.render(db, target, user, repository, changesets[0], review, context_lines=context_lines, options=options, wrap=wrap):
            yield stop
    else:
        commit = changesets[0].child

        renderCommitInfo(db, main, user, repository, review, commit)

        if profiler: profiler.check("render commit info")

        nparents = len(changesets)
        target.addInternalScript("var parentsCount = %d;" % nparents)

        files = {}

        for index, changeset in enumerate(changesets):
            for file in changeset.files:
                files.setdefault(file.id, [file.id, file.path, [None] * nparents])[2][index] = file

        renderCommitFiles(db, target, user, repository, review, changesets=changesets, file_id="p%df%%d" % index, approve_file_id="p%da%%d" % index, nparents=nparents, conflicts=changesets[-1].conflicts, files=diff.File.sorted(files.values(), key=lambda x: x[1]))

        if profiler: profiler.check("render commit files")

        mergebase = repository.mergebase(commit, db=db)

        if profiler: profiler.check("merge base")

        yield target

        relevant_commits = []

        cursor.execute("SELECT parent, file, sha1 FROM relevantcommits JOIN commits ON (relevant=id) WHERE commit=%s", (commit.getId(db),))

        rows = cursor.fetchall()

        if rows:
            for index in range(len(changesets)):
                relevant_commits.append({})

            commits_by_sha1 = {}

            for parent_index, file_id, sha1 in rows:
                if sha1 not in commits_by_sha1:
                    commits_by_sha1[sha1] = gitutils.Commit.fromSHA1(db, repository, sha1)
                relevant_commits[parent_index].setdefault(file_id, []).append(commits_by_sha1[sha1])
        else:
            values = []
            commits_by_sha1 = {}

            for index, changeset in enumerate(changesets):
                relevant_files = set([file.path for file in changeset.files])
                files = {}

                if not changeset.conflicts:
                    commit_range = "%s..%s" % (mergebase, changeset.parent.sha1)
                    relevant_lines = repository.run("log", "--name-only", "--full-history", "--format=sha1:%H", commit_range, "--", *relevant_files).splitlines()

                    for line in relevant_lines:
                        if line.startswith("sha1:"):
                            sha1 = line[5:]
                        elif line in relevant_files:
                            if sha1 not in commits_by_sha1:
                                commits_by_sha1[sha1] = gitutils.Commit.fromSHA1(db, repository, sha1)

                            relevant_commit = commits_by_sha1[sha1]
                            file_id = dbutils.find_file(db, path=line)
                            values.append((commit.getId(db), index, file_id, relevant_commit.getId(db)))
                            files.setdefault(file_id, []).append(relevant_commit)

                relevant_commits.append(files)

            cursor.executemany("INSERT INTO relevantcommits (commit, parent, file, relevant) VALUES (%s, %s, %s, %s)", values)

        if profiler: profiler.check("collecting relevant commits")

        if tabify:
            target.script(type="text/javascript").text("calculateTabWidth();")

        for index, changeset in enumerate(changesets):
            parent = target.div("parent", id="p%d" % index)

            options['support_expand'] = bool(changeset.conflicts)
            options['file_id'] = lambda base: "p%d%s" % (index, base)
            options['line_id'] = lambda base: "p%d%s" % (index, base)
            options['line_cell_id'] = lambda base: base is not None and "p%d%s" % (index, base) or None
            options['file_id_format'] = "p%df%%d" % index

            relevant_commits_per_file = {}
            for file in changeset.files:
                relevant_commits_per_file[file.id] = []
                for index1, changeset1 in enumerate(changesets):
                    if index1 != index:
                        relevant_commits_per_file[file.id].extend(relevant_commits[index1].get(file.id, []))

            if changeset.conflicts: text = "Merge conflict resolutions"
            else: text = "Changes relative to %s parent" % ("first", "second", "third", "fourth", "fifth", "seventh", "eight", "ninth")[index]

            parent.h1().text(text)

            def renderRelevantCommits(db, target, file):
                commits = relevant_commits_per_file.get(file.id)
                if commits:
                    def linkToCommit(commit, overrides={}):
                        return "%s/%s?file=%d" % (commit.repository.name, commit.sha1, file.id)

                    columns = [(70, log_html.SummaryColumn(linkToCommit=linkToCommit)),
                               (30, log_html.AuthorColumn())]

                    log_html.renderList(db, target, "Relevant Commits", commits, columns=columns, hide_merges=True, className="log relevant")

            options['content_after'] = renderRelevantCommits
            options['parent_index'] = index
            options['merge'] = True

            for stop in changeset_html.render(db, parent, user, repository, changeset,
                                              review, context_lines=context_lines,
                                              options=options, wrap=wrap, parent_index=index):
                yield stop

        if profiler: profiler.check("render diff")

    if user.getPreference(db, "ui.keyboardShortcuts"):
        page.utils.renderShortcuts(target, "showcommit", merge_parents=len(changesets), squashed_diff=commits and len(commits) > 1)

def commitRangeFromReview(db, user, review, filter_value, file_ids):
    edges = cursor = db.cursor()

    if filter_value == "pending":
        cursor.execute("""SELECT DISTINCT changesets.parent, changesets.child
                            FROM changesets
                            JOIN reviewfiles ON (reviewfiles.changeset=changesets.id)
                            JOIN reviewuserfiles ON (reviewuserfiles.file=reviewfiles.id)
                           WHERE reviewfiles.review=%s
                             AND reviewuserfiles.uid=%s
                             AND reviewfiles.state='pending'""",
                       (review.id, user.id))
    elif filter_value == "reviewable":
        cursor.execute("""SELECT DISTINCT changesets.parent, changesets.child
                            FROM changesets
                            JOIN reviewfiles ON (reviewfiles.changeset=changesets.id)
                            JOIN reviewuserfiles ON (reviewuserfiles.file=reviewfiles.id)
                           WHERE reviewfiles.review=%s
                             AND reviewuserfiles.uid=%s""",
                       (review.id, user.id))
    elif filter_value == "relevant":
        filters = review_filters.Filters()
        filters.setFiles(db, review=review)
        filters.load(db, review=review, user=user)

        cursor.execute("""SELECT DISTINCT changesets.parent, changesets.child, reviewfiles.file, reviewuserfiles.uid IS NOT NULL
                            FROM changesets
                            JOIN reviewfiles ON (reviewfiles.changeset=changesets.id)
                 LEFT OUTER JOIN reviewuserfiles ON (reviewuserfiles.file=reviewfiles.id
                                                 AND reviewuserfiles.uid=%s)
                           WHERE reviewfiles.review=%s""",
                       (user.id, review.id))

        edges = set()

        for parent_id, child_id, file_id, is_reviewer in cursor:
            if is_reviewer or filters.isRelevant(user, file_id):
                edges.add((parent_id, child_id))
    elif filter_value == "files":
        assert len(file_ids) != 0

        cursor.execute("""SELECT DISTINCT changesets.parent, changesets.child
                            FROM changesets
                            JOIN reviewchangesets ON (reviewchangesets.changeset=changesets.id)
                            JOIN fileversions ON (fileversions.changeset=changesets.id)
                           WHERE reviewchangesets.review=%s
                             AND fileversions.file=ANY (%s)""",
                       (review.id, list(file_ids)))
    else:
        raise page.utils.InvalidParameterValue(
            name="filter",
            value=filter_value,
            expected="one of 'pending', 'reviewable', 'relevant' and 'files'")

    listed_commits = set()
    with_pending = set()

    for parent_id, child_id in edges:
        listed_commits.add(child_id)
        with_pending.add((parent_id, child_id))

    if len(listed_commits) == 1:
        commit = gitutils.Commit.fromId(db, review.repository, child_id)
        return commit.sha1, commit.sha1, list(listed_commits), listed_commits

    if filter_value in ("reviewable", "relevant", "files"):
        cursor.execute("SELECT child FROM changesets JOIN reviewchangesets ON (changeset=id) WHERE review=%s", (review.id,))
        all_commits = [gitutils.Commit.fromId(db, review.repository, commit_id) for (commit_id,) in cursor]

        commitset = CommitSet(review.branch.commits)
        tails = commitset.getFilteredTails(review.repository)

        if len(commitset) == 0:
            raise page.utils.DisplayMessage(
                title="Empty review",
                body=("This review contains no commits.  It is thus not "
                      "meaningful to display a filtered view of the changes "
                      "in it."),
                review=review)
        elif len(tails) > 1:
            ancestor = review.repository.getCommonAncestor(tails)
            paths = []

            cursor.execute("SELECT DISTINCT file FROM reviewfiles WHERE review=%s", (review.id,))
            files_in_review = set(file_id for (file_id,) in cursor)

            if filter_value == "files":
                files_in_review &= file_ids

            paths_in_review = set(dbutils.describe_file(db, file_id) for file_id in files_in_review)
            paths_in_upstreams = set()

            for tail in tails:
                paths_in_upstream = set(review.repository.run("diff", "--name-only", "%s..%s" % (ancestor, tail)).splitlines())
                paths_in_upstreams |= paths_in_upstream

                paths.append((tail, paths_in_upstream))

            overlapping_changes = paths_in_review & paths_in_upstreams

            if overlapping_changes:
                candidates = []

                for index1, data in enumerate(paths):
                    for index2, (tail, paths_in_upstream) in enumerate(paths):
                        if index1 != index2 and paths_in_upstream & paths_in_review:
                            break
                    else:
                        candidates.append(data)
            else:
                candidates = paths

            if not candidates:
                paths.sort(cmp=lambda a, b: cmp(len(a[1]), len(b[1])))

                url = "/%s/%s..%s?file=%s" % (review.repository.name, paths[0][0][:8], review.branch.head.sha1[:8], ",".join(map(str, sorted(files_in_review))))

                message = """\
<p>It is not possible to generate a diff of the requested set of
commits that contains only changes from those commits.</p>

<p>The following files would contain unrelated changes:<p>
<pre style='padding-left: 2em'>%s</pre>

<p>You can use the URL below if you want to view this diff anyway,
including the unrelated changes.</p>
<pre style='padding-left: 2em'><a href='%s'>%s%s</a></pre>""" % ("\n".join(sorted(overlapping_changes)), url, dbutils.getURLPrefix(db, user), url)

                raise page.utils.DisplayMessage(title="Impossible Diff",
                                                body=message,
                                                review=review,
                                                html=True)
            else:
                candidates.sort(cmp=lambda a, b: cmp(len(b[1]), len(a[1])))

                return candidates[0][0], review.branch.head.sha1, all_commits, listed_commits

        if tails:
            from_sha1 = tails.pop()
        else:
            # Review starts with the initial commit.
            from_sha1 = None

        return from_sha1, review.branch.head.sha1, all_commits, listed_commits

    if not with_pending:
        if filter_value == "pending":
            raise page.utils.DisplayMessage("Your work here is done!", None, review)
        else:
            assert filter_value != "files"
            raise page.utils.DisplayMessage("No %s changes found." % filter_value, None, review)

    cursor.execute("""SELECT parent, child
                        FROM changesets
                        JOIN reviewchangesets ON (id=changeset)
                       WHERE review=%s""", (review.id,))

    children = set()
    parents = set()
    edges = {}

    for parent_id, child_id in cursor.fetchall():
        children.add(child_id)
        parents.add(parent_id)
        edges.setdefault(child_id, set()).add(parent_id)

    def isAncestorOf(ancestor_id, descendant_id):
        ancestors = edges.get(descendant_id, set()).copy()
        pending = ancestors.copy()
        while pending and ancestor_id not in ancestors:
            commit_id = pending.pop()
            parents = edges.get(commit_id, set())
            pending.update(parents - ancestors)
            ancestors.update(parents)
        return ancestor_id in ancestors

    candidates = listed_commits.copy()
    heads = set()
    tails = set()

    for candidate_id in listed_commits:
        for other_id in candidates:
            if other_id != candidate_id and isAncestorOf(candidate_id, other_id):
                break
        else:
            heads.add(candidate_id)

        for other_id in candidates:
            if other_id != candidate_id and isAncestorOf(other_id, candidate_id):
                break
        else:
            tails.add(candidate_id)

    if len(heads) != 1 or len(tails) != 1:
        raise page.utils.DisplayMessage("Filtered view not possible since it includes a merge commit.")

    head = gitutils.Commit.fromId(db, review.repository, heads.pop())
    tail = gitutils.Commit.fromId(db, review.repository, tails.pop())

    # if tail.parents greater than 1, it means it's a merge commit
    if len(tail.parents) > 1:
        raise page.utils.DisplayMessage("Filtered view not possible since it includes a merge commit.")

    if len(tail.parents) == 0:
        tail = None
    else:
        tail = gitutils.Commit.fromSHA1(db, review.repository, tail.parents[0])

    commits = getCommitList(db, review.repository, tail, head)

    if not commits:
        raise page.utils.DisplayMessage("Filtered view not possible since it includes a merge commit.")

    tail_to_return = tail.sha1 if tail is not None else None
    return tail_to_return, head.sha1, commits, listed_commits

def getCommitList(db, repository, from_commit, to_commit):
    commits = set()

    class NotPossible(Exception): pass

    def process(iter_commit):
        while iter_commit != from_commit and iter_commit not in commits:
            commits.add(iter_commit)

            if len(iter_commit.parents) > 1:
                try:
                    mergebase = repository.mergebase(iter_commit)
                    is_ancestor = from_commit.isAncestorOf(mergebase)
                except gitutils.GitCommandError:
                    raise NotPossible

                if is_ancestor:
                    map(process, [gitutils.Commit.fromSHA1(db, repository, sha1) for sha1 in iter_commit.parents])
                    return
                else:
                    raise NotPossible
            else:
                if from_commit is None and len(iter_commit.parents) == 0:
                    return

                iter_commit = gitutils.Commit.fromSHA1(db, repository, iter_commit.parents[0])

    if from_commit == to_commit:
        return [to_commit]

    try:
        process(to_commit)
        return list(commits)
    except NotPossible:
        return []

def getApproximativeCommitList(db, repository, from_commit, to_commit, paths):
    try:
        ancestor = repository.getCommonAncestor([from_commit, to_commit])
    except gitutils.GitCommandError:
        return [], []

    return ([gitutils.Commit.fromSHA1(db, repository, sha1)
             for sha1 in repository.revlist([to_commit], [ancestor])],
            [gitutils.Commit.fromSHA1(db, repository, sha1).getId(db)
             for sha1 in repository.revlist([to_commit], [ancestor], paths=paths)])

def renderShowCommit(req, db, user):
    profiler = profiling.Profiler()

    files_arg = req.getParameter("file", None)
    if files_arg is None:
        file_ids = None
    else:
        file_ids = set()
        for file_arg in files_arg.split(","):
            try:
                file_id = int(file_arg)
            except ValueError:
                try:
                    file_id = dbutils.find_file(db, file_arg.strip(), insert=False)
                except dbutils.InvalidPath:
                    file_id = None
            if file_id is not None:
                file_ids.add(file_id)

    review_id = req.getParameter("review", None, filter=int)
    review_filter = req.getParameter("filter", None)
    context = req.getParameter("context", None, int)
    style = req.getParameter("style", "horizontal", str)
    rescan = req.getParameter("rescan", "no", str) == "yes"
    reanalyze = req.getParameter("reanalyze", None)
    wrap = req.getParameter("wrap", "yes", str) == "yes"
    conflicts = req.getParameter("conflicts", "no") == "yes"
    moves = req.getParameter("moves", "no") == "yes"
    full = req.getParameter("full", "no") == "yes"

    default_tabify = "yes" if user.getPreference(db, "commit.diff.visualTabs") else "no"
    tabify = req.getParameter("tabify", default_tabify) == "yes"

    if user.getPreference(db, "commit.diff.compactMode"): default_compact = "yes"
    else: default_compact = "no"

    compact = req.getParameter("compact", default_compact) == "yes"

    if moves:
        move_source_file_ids = req.getParameter("sourcefiles", None)
        move_target_file_ids = req.getParameter("targetfiles", None)

        if move_source_file_ids:
            move_source_file_ids = set(map(int, move_source_file_ids.split(",")))
        if move_target_file_ids:
            move_target_file_ids = set(map(int, move_target_file_ids.split(",")))

    all_commits = None
    listed_commits = None
    first_sha1 = None
    last_sha1 = None

    repository = None

    document = htmlutils.Document(req)
    document.setBase(None)

    if review_id is None:
        review = None
    else:
        review = dbutils.Review.fromId(db, review_id)
        if not review: raise page.utils.DisplayMessage("Invalid review ID: %d" % review_id)
        branch = review.branch
        repository = review.repository

    title = ""

    if review:
        title += "[r/%d] " % review.id

        if review_filter == "pending":
            title += "Pending: "
        elif review_filter == "reviewable":
            title += "Reviewable: "
        elif review_filter == "relevant":
            title += "Relevant: "

    if not repository:
        parameter = req.getParameter("repository", None)
        if parameter:
            repository = gitutils.Repository.fromParameter(db, parameter)
            if not repository:
                raise page.utils.DisplayMessage("'%s' is not a valid repository!" % repository.name, review=review)

    cursor = db.cursor()

    def expand_sha1(sha1):
        if review and re.match("^[0-9a-f]+$", sha1):
            cursor.execute("""SELECT sha1
                                FROM commits
                                JOIN changesets ON (changesets.child=commits.id)
                                JOIN reviewchangesets ON (reviewchangesets.changeset=changesets.id)
                               WHERE reviewchangesets.review=%s
                                 AND commits.sha1 LIKE %s""",
                           (review.id, sha1 + "%"))
            try: return cursor.fetchone()[0]
            except: pass

        if len(sha1) == 40: return sha1
        else: return repository.revparse(sha1)

    sha1 = req.getParameter("sha1", None, filter=expand_sha1)

    if sha1 is None:
        from_sha1 = req.getParameter("from", None, filter=expand_sha1)
        to_sha1 = req.getParameter("to", None, filter=expand_sha1)

        if (from_sha1 is None) != (to_sha1 is None):
            raise page.utils.DisplayMessage("invalid parameters; one of 'from'/'to' specified but not both")

        if from_sha1 is None:
            first_sha1 = req.getParameter("first", None, filter=expand_sha1)
            last_sha1 = req.getParameter("last", None, filter=expand_sha1)

            if (first_sha1 is None) != (last_sha1 is None):
                raise page.utils.DisplayMessage("invalid parameters; one of 'first'/'last' specified but not both")

            if first_sha1 is None:
                if review_id and review_filter:
                    from_sha1, to_sha1, all_commits, listed_commits = commitRangeFromReview(db, user, review, review_filter, file_ids)
                    if from_sha1 == to_sha1:
                        sha1 = to_sha1
                        to_sha1 = None
                else:
                    raise page.utils.DisplayMessage("invalid parameters; need 'sha1', 'from'/'to' or 'first'/'last'")
    else:
        from_sha1 = None
        to_sha1 = None

    if context is None: context = user.getPreference(db, "commit.diff.contextLines")

    one_sha1 = filter(None, (sha1, from_sha1, to_sha1, first_sha1, last_sha1))[0]

    if repository:
        if not repository.iscommit(one_sha1):
            raise page.utils.DisplayMessage("'%s' is not a valid commit in the repository '%s'!" % (one_sha1, repository.name), review=review)
    else:
        default = user.getPreference(db, "defaultRepository")
        if default:
            repository = gitutils.Repository.fromName(db, default)
            if repository and not repository.iscommit(one_sha1):
                repository = None
        if not repository:
            repository = gitutils.Repository.fromSHA1(db, one_sha1)

    if first_sha1 is not None:
        try:
            first_commit = gitutils.Commit.fromSHA1(db, repository, first_sha1)
        except gitutils.GitReferenceError as error:
            raise page.utils.DisplayMessage("Invalid SHA-1", "%s is not a commit in %s" % (error.sha1, repository.path))

        if len(first_commit.parents) > 1:
            raise page.utils.DisplayMessage("Invalid parameters; 'first' can not be a merge commit.", review=review)

        from_sha1 = first_commit.parents[0] if first_commit.parents else None
        to_sha1 = last_sha1

    try:
        commit = gitutils.Commit.fromSHA1(db, repository, sha1) if sha1 else None
        from_commit = gitutils.Commit.fromSHA1(db, repository, from_sha1) if from_sha1 else None
        to_commit = gitutils.Commit.fromSHA1(db, repository, to_sha1) if to_sha1 else None
    except gitutils.GitReferenceError as error:
        raise page.utils.DisplayMessage("Invalid SHA-1", "%s is not a commit in %s" % (error.sha1, repository.path))

    if commit:
        title += "%s (%s)" % (commit.niceSummary(), commit.describe(db))
    elif from_commit:
        title += "%s..%s" % (from_commit.describe(db), to_commit.describe(db))
    else:
        title += "..%s" % to_commit.describe(db)

    document.setTitle(title)

    if review_filter == "pending":
        document.setLink("next", "javascript:submitChanges();")

    commits = None
    rebases = None

    profiler.check("prologue")

    if to_commit:
        changesets = changeset_utils.createChangeset(db, user, repository, from_commit=from_commit, to_commit=to_commit, conflicts=conflicts, rescan=rescan, reanalyze=reanalyze, filtered_file_ids=file_ids)
        assert len(changesets) == 1

        if not conflicts:
            if review and (review_filter in ("reviewable", "relevant")
                           or (review_filter == "files" and all_commits)):
                # We're displaying the full changes in the review (possibly
                # filtered by file) => include rebase information when rendering
                # the "Squashed History" log.

                cursor.execute("""SELECT id, old_head, new_head, new_upstream, uid, branch
                                    FROM reviewrebases
                                   WHERE review=%s AND new_head IS NOT NULL""",
                               (review.id,))

                rebases = [(rebase_id,
                            gitutils.Commit.fromId(db, repository, old_head),
                            gitutils.Commit.fromId(db, repository, new_head),
                            dbutils.User.fromId(db, user_id),
                            gitutils.Commit.fromId(db, repository, new_upstream) if new_upstream is not None else None,
                            branch_name)
                           for rebase_id, old_head, new_head, new_upstream, user_id, branch_name in cursor]

            if all_commits:
                commits = all_commits
            else:
                commits = getCommitList(db, repository, from_commit, to_commit)
                if not commits and not review:
                    paths = [changed_file.path for changed_file in changesets[0].files]
                    commits, listed_commits = getApproximativeCommitList(db, repository, from_commit, to_commit, paths)
            if commits:
                changesets[0].setCommits(commits)
    else:
        if len(commit.parents) > 1:
            if review:
                cursor.execute("SELECT COUNT(changeset) FROM reviewchangesets JOIN changesets ON (changeset=id) WHERE review=%s AND child=%s", (review.id, commit.getId(db)))
                if cursor.fetchone()[0] > len(commit.parents):
                    full = True
        else:
            full = False

        if full:
            changesets = changeset_utils.createFullMergeChangeset(db, user, repository, commit, review=review)
            commits = [commit]
        else:
            changesets = changeset_utils.createChangeset(db, user, repository, commit=commit, rescan=rescan, reanalyze=reanalyze, conflicts=conflicts, filtered_file_ids=file_ids, review=review)
            commits = [commit]

    profiler.check("create changeset")

    if review and commits:
        all_files = set()
        pending_files = set()
        reviewable_files = set()

        cursor.execute("""SELECT reviewfiles.file, reviewfiles.state, reviewuserfiles.uid IS NOT NULL
                            FROM commits
                            JOIN changesets ON (changesets.child=commits.id)
                            JOIN reviewfiles ON (reviewfiles.changeset=changesets.id)
                 LEFT OUTER JOIN reviewuserfiles ON (reviewuserfiles.file=reviewfiles.id AND reviewuserfiles.uid=%s)
                           WHERE commits.sha1=ANY (%s)
                             AND reviewfiles.review=%s""",
                       (user.id, [commit.sha1 for commit in commits], review.id))

        for file_id, current_state, is_reviewer in cursor:
            all_files.add(file_id)
            if is_reviewer:
                if current_state == 'pending':
                    pending_files.add(file_id)
                reviewable_files.add(file_id)

        profiler.check("reviewfiles query")

        for changeset in changesets:
            all_files_local = all_files.copy()

            for file in changeset.files:
                if file.id in all_files_local:
                    all_files_local.remove(file.id)

            for file_id in all_files_local:
                if not file_ids or file_id in file_ids:
                    changeset.files.append(diff.File(file_id, dbutils.describe_file(db, file_id), None, None, repository))

            if review_filter == "pending":
                def isPending(file): return file.id in pending_files
                changeset.files = filter(isPending, changeset.files)

            elif review_filter == "reviewable":
                def isReviewable(file): return file.id in reviewable_files
                changeset.files = filter(isReviewable, changeset.files)

            elif review_filter == "relevant":
                filters = review_filters.Filters()
                filters.setFiles(db, review=review)
                filters.load(db, review=review, user=user)

                def isRelevant(file):
                    if file.id in reviewable_files: return True
                    elif filters.isRelevant(user, file): return True
                    else: return False

                changeset.files = filter(isRelevant, changeset.files)

            elif review_filter == "files":
                def isFiltered(file): return file.id in file_ids
                changeset.files = filter(isFiltered, changeset.files)

        profiler.check("review filtering")

    if moves:
        if len(changesets) != 1:
            raise page.utils.DisplayMessage("Can't detect moves in a merge commit!", review=review)

        move_changeset = changeset_detectmoves.detectMoves(db, changesets[0], move_source_file_ids, move_target_file_ids)

        if not move_changeset:
            raise page.utils.DisplayMessage("No moved code found!", review=review)

        changesets = [move_changeset]

        profiler.check("moves detection")

    html = document.html()
    head = html.head()
    body = html.body()

    if review:
        def generateButtons(target):
            review_utils.renderDraftItems(db, user, review, target)
            buttons = target.div("buttons")
            if user.getPreference(db, "debug.extensions.customProcessCommits"):
                buttons.button(onclick='customProcessCommits();').text("Process Commits")
            buttons.span("buttonscope buttonscope-global")
        page.utils.generateHeader(body, db, user, generateButtons, extra_links=[("r/%d" % review.id, "Back to Review")])
    else:
        def generateButtons(target):
            buttons = target.div("buttons")
            if not user.isAnonymous() and (commit or commits):
                buttons.button(onclick='createReview();').text('Create Review')
            buttons.span("buttonscope buttonscope-global")
        page.utils.generateHeader(body, db, user, generateButtons)

    log_html.addResources(document)
    changeset_html.addResources(db, user, repository, review, compact, tabify, document)

    document.addInternalScript(user.getJS(db))
    document.addInternalScript(repository.getJS())
    document.addInternalScript("var keyboardShortcuts = %s;" % (user.getPreference(db, "ui.keyboardShortcuts") and "true" or "false"))

    for stop in render(db, body, user, repository, review, changesets, commits, listed_commits, context_lines=context, conflicts=conflicts, moves=moves, compact=compact, wrap=wrap, tabify=tabify, profiler=profiler, rebases=rebases):
        yield document.render(stop=stop, pretty=not compact)

    profiler.check("rendering")
    profiler.output(db, user, document)

    db.commit()

    yield document.render(pretty=not compact)

########NEW FILE########
__FILENAME__ = showfile
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2012 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import os
import urllib

import dbutils
import gitutils
import page.utils
import htmlutils
import textutils
import diff
import reviewing.utils as review_utils
import reviewing.comment as review_comment

from syntaxhighlight.request import requestHighlights

def renderShowFile(req, db, user):
    cursor = db.cursor()

    sha1 = req.getParameter("sha1")
    path = req.getParameter("path")
    line = req.getParameter("line", None)
    review_id = req.getParameter("review", None, filter=int)

    default_tabify = "yes" if user.getPreference(db, "commit.diff.visualTabs") else "no"
    tabify = req.getParameter("tabify", default_tabify) == "yes"

    if line is None:
        first, last = None, None
    else:
        if "-" in line:
            first, last = map(int, line.split("-"))
        else:
            first = last = int(line)

        context = req.getParameter("context", user.getPreference(db, "commit.diff.contextLines"), int)

        first_with_context = max(1, first - context)
        last_with_context = last + context

    if user.getPreference(db, "commit.diff.compactMode"): default_compact = "yes"
    else: default_compact = "no"

    compact = req.getParameter("compact", default_compact) == "yes"

    if len(path) == 0 or path[-1:] == "/":
        raise page.utils.DisplayMessage(
            title="Invalid path parameter",
            body="<p>The path must be non-empty and must not end with a <code>/</code>.</p>",
            html=True)
    if path[0] == '/':
        full_path = path
        if path != "/": path = path[1:]
    else:
        full_path = "/" + path
        if not path: path = "/"

    if review_id is None:
        review = None
        repository_arg = req.getParameter("repository", "")
        if repository_arg:
            repository = gitutils.Repository.fromParameter(db, repository_arg)
        else:
            repository = gitutils.Repository.fromSHA1(db, sha1)
    else:
        review = dbutils.Review.fromId(db, review_id)
        repository = review.repository

    document = htmlutils.Document(req)

    html = document.html()
    head = html.head()
    body = html.body()

    if review:
        page.utils.generateHeader(body, db, user, lambda target: review_utils.renderDraftItems(db, user, review, target), extra_links=[("r/%d" % review.id, "Back to Review")])
    else:
        page.utils.generateHeader(body, db, user)

    document.addExternalStylesheet("resource/showfile.css")
    document.addInternalStylesheet(htmlutils.stripStylesheet(user.getResource(db, "syntax.css")[1], compact))

    commit = gitutils.Commit.fromSHA1(db, repository, sha1)
    file_sha1 = commit.getFileSHA1(full_path)
    file_id = dbutils.find_file(db, path=path)

    if file_sha1 is None:
        raise page.utils.DisplayMessage(
            title="File does not exist",
            body=("<p>There is no file named <code>%s</code> in the commit "
                  "<a href='/showcommit?repository=%s&amp;sha1=%s'>"
                  "<code>%s</code></a>.</p>"
                  % (htmlutils.htmlify(textutils.escape(full_path)),
                     htmlutils.htmlify(repository.name),
                     htmlutils.htmlify(sha1), htmlutils.htmlify(sha1[:8]))),
            html=True)

    file = diff.File(file_id, path, None, file_sha1, repository)

    # A new file ID might have been added to the database, so need to commit.
    db.commit()

    if file.canHighlight():
        requestHighlights(repository, { file.new_sha1: (file.path, file.getLanguage()) })

    file.loadNewLines(True, request_highlight=True)

    if review:
        document.addInternalScript(user.getJS())
        document.addInternalScript(review.getJS())
        document.addInternalScript("var changeset = { parent: { id: %(id)d, sha1: %(sha1)r }, child: { id: %(id)d, sha1: %(sha1)r } };" % { 'id': commit.getId(db), 'sha1': commit.sha1 })
        document.addInternalScript("var files = { %(id)d: { new_sha1: %(sha1)r }, %(sha1)r: { id: %(id)d, side: 'n' } };" % { 'id': file_id, 'sha1': file_sha1 })
        document.addExternalStylesheet("resource/review.css")
        document.addExternalScript("resource/review.js")

        cursor.execute("""SELECT DISTINCT commentchains.id
                            FROM commentchains
                            JOIN commentchainlines ON (commentchainlines.chain=commentchains.id)
                           WHERE commentchains.review=%s
                             AND commentchains.file=%s
                             AND commentchainlines.sha1=%s
                             AND ((commentchains.state!='draft' OR commentchains.uid=%s)
                              AND commentchains.state!='empty')
                        GROUP BY commentchains.id""",
                       (review.id, file_id, file_sha1, user.id))

        comment_chain_script = ""

        for (chain_id,) in cursor.fetchall():
            chain = review_comment.CommentChain.fromId(db, chain_id, user, review=review)
            chain.loadComments(db, user)

            comment_chain_script += "commentChains.push(%s);\n" % chain.getJSConstructor(file_sha1)

        if comment_chain_script:
            document.addInternalScript(comment_chain_script)

    document.addExternalStylesheet("resource/comment.css")
    document.addExternalScript("resource/comment.js")
    document.addExternalScript("resource/showfile.js")

    if tabify:
        document.addExternalStylesheet("resource/tabify.css")
        document.addExternalScript("resource/tabify.js")
        tabwidth = file.getTabWidth()
        indenttabsmode = file.getIndentTabsMode()

    if user.getPreference(db, "commit.diff.highlightIllegalWhitespace"):
        document.addInternalStylesheet(user.getResource(db, "whitespace.css")[1], compact)

    if first is not None:
        document.addInternalScript("var firstSelectedLine = %d, lastSelectedLine = %d;" % (first, last))

    target = body.div("main")

    if tabify:
        target.script(type="text/javascript").text("calculateTabWidth();")

    table = target.table('file show expanded paleyellow', align='center', cellspacing=0)

    columns = table.colgroup()
    columns.col('edge')
    columns.col('linenr')
    columns.col('line')
    columns.col('middle')
    columns.col('middle')
    columns.col('line')
    columns.col('linenr')
    columns.col('edge')

    thead = table.thead()
    cell = thead.tr().td('h1', colspan=8)
    h1 = cell.h1()

    def make_url(url_path, path):
        params = { "sha1": sha1,
                   "path": path }
        if review is None:
            params["repository"] = str(repository.id)
        else:
            params["review"] = str(review.id)
        return "%s?%s" % (url_path, urllib.urlencode(params))

    h1.a("root", href=make_url("showtree", "/")).text("root")
    h1.span().text('/')

    components = path.split("/")
    for index, component in enumerate(components[:-1]):
        h1.a(href=make_url("showtree", "/".join(components[:index + 1]))).text(component, escape=True)
        h1.span().text('/')

    if first is not None:
        h1.a(href=make_url("showfile", "/".join(components))).text(components[-1], escape=True)
    else:
        h1.text(components[-1], escape=True)

    h1.span("right").a(href=("/download/%s?repository=%s&sha1=%s"
                             % (urllib.quote(path), repository.name, file_sha1)),
                       download=urllib.quote(path)).text("[download]")
    h1.span("right").a(href=("/download/%s?repository=%s&sha1=%s"
                             % (urllib.quote(path), repository.name, file_sha1))).text("[view]")

    table.tbody('spacer top').tr('spacer top').td(colspan=8).text()

    tbody = table.tbody("lines")

    yield document.render(stop=tbody, pretty=not compact)

    for linenr, line in enumerate(file.newLines(True)):
        linenr = linenr + 1
        highlight_class = ""

        if first is not None:
            if not (first_with_context <= linenr <= last_with_context): continue
            if linenr == first:
                highlight_class += " first-selected"
            if linenr == last:
                highlight_class += " last-selected"

        if tabify:
            line = htmlutils.tabify(line, tabwidth, indenttabsmode)

        line = line.replace("\r", "<i class='cr'></i>")

        row = tbody.tr("line context single", id="f%do%dn%d" % (file.id, linenr, linenr))
        row.td("edge").text()
        row.td("linenr old").text(linenr)
        row.td("line single whole%s" % highlight_class, id="f%dn%d" % (file.id, linenr), colspan=4).innerHTML(line)
        row.td("linenr new").text(linenr)
        row.td("edge").text()

        if linenr % 500:
            yield document.render(stop=tbody, pretty=not compact)

    table.tbody('spacer bottom').tr('spacer bottom').td(colspan=8).text()

    yield document.render(pretty=not compact)

########NEW FILE########
__FILENAME__ = showreview
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2012 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import datetime
import calendar
import traceback

import base
import dbutils
import gitutils
import htmlutils
import page.utils
import log.html
import reviewing.utils as review_utils
import reviewing.html as review_html
import reviewing.comment as review_comment
import configuration
import diff
import profiling
import linkify

from textutils import json_encode

try:
    from customization.paths import getModuleFromFile
except:
    def getModuleFromFile(repository, filename):
        try:
            base, rest = filename.split("/", 1)
            return base + "/"
        except:
            return None

class SummaryColumn(log.html.SummaryColumn):
    def __init__(self, review, linkToCommit):
        log.html.SummaryColumn.__init__(self, linkToCommit)
        self.__review = review
        self.__cache = {}

    def fillCache(self, db, review):
        cursor = db.cursor()
        cursor.execute("""SELECT DISTINCT assignee, child
                            FROM fullreviewuserfiles
                            JOIN changesets ON (changesets.id=changeset)
                           WHERE review=%s
                             AND state='pending'""",
                       (review.id,))
        for user_id, commit_id in cursor:
            self.__cache.setdefault(commit_id, set()).add(user_id)

    def render(self, db, commit, target, overrides={}):
        user_ids = self.__cache.get(commit.getId(db))
        if user_ids:
            users = ["%s:%s" % (user.fullname, user.status) for user in dbutils.User.fromIds(db, [user_id for user_id in user_ids])]
            target.setAttribute("critic-reviewers", ",".join(sorted(users)))
        log.html.SummaryColumn.render(self, db, commit, target, overrides=overrides)

class ApprovalColumn:
    APPROVED = 1
    TOTAL = 2

    def __init__(self, user, review, type, cache):
        self.__user = user
        self.__review = review
        self.__type = type
        self.__cache = cache

    @staticmethod
    def fillCache(db, user, review, cache, profiler):
        cursor = db.cursor()

        profiler.check("fillCache")

        cursor.execute("""SELECT child, state, COUNT(*), SUM(deleted), SUM(inserted)
                            FROM changesets
                            JOIN reviewfiles ON (changeset=changesets.id)
                           WHERE review=%s
                        GROUP BY child, state""",
                       (review.id,))

        for commit_id, state, nfiles, deleted, inserted in cursor:
            data = cache.get(commit_id)
            if not data: data = cache[commit_id] = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
            if state == 'reviewed':
                data[3] += nfiles
                data[4] += deleted
                data[5] += inserted
            data[0] += nfiles
            data[1] += deleted
            data[2] += inserted

        profiler.check("fillCache: total")

        cursor.execute("""SELECT child, COALESCE(reviewfilechanges.to, reviewfiles.state) AS effective_state, COUNT(*), SUM(deleted), SUM(inserted)
                            FROM changesets
                            JOIN reviewfiles ON (changeset=changesets.id)
                            JOIN reviewuserfiles ON (reviewuserfiles.file=reviewfiles.id)
                 LEFT OUTER JOIN reviewfilechanges ON (reviewfilechanges.file=reviewfiles.id
                                                   AND reviewfilechanges.uid=reviewuserfiles.uid
                                                   AND reviewfilechanges.state='draft')
                           WHERE review=%s
                             AND reviewuserfiles.uid=%s
                        GROUP BY child, effective_state""",
                       (review.id, user.id))

        for commit_id, state, nfiles, deleted, inserted in cursor:
            data = cache.get(commit_id)
            if state == 'reviewed':
                data[9] += nfiles
                data[10] += deleted
                data[11] += inserted
            data[6] += nfiles
            data[7] += deleted
            data[8] += inserted

        profiler.check("fillCache: user")

    def __calculate(self, db, commit):
        return self.__cache.get(commit.id, [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])

    def className(self, db, commit):
        if commit:
            (total_nfiles, total_deleted, total_inserted,
             approved_nfiles, approved_deleted, approved_inserted,
             user_total_nfiles, user_total_deleted, user_total_inserted,
             user_approved_nfiles, user_approved_deleted, user_approved_inserted) = self.__calculate(db, commit)

            if user_approved_nfiles == user_total_nfiles:
                category = ""
            else:
                category = " user"
        else:
            category = ""

        if self.__type == ApprovalColumn.APPROVED:
            return "approval" + category
        else:
            return "total" + category

    def heading(self, target):
        if self.__type == ApprovalColumn.APPROVED:
            target.text("Pending")
        else:
            target.text("Total")

    def render(self, db, commit, target, overrides={}):
        (total_nfiles, total_deleted, total_inserted,
         approved_nfiles, approved_deleted, approved_inserted,
         user_total_nfiles, user_total_deleted, user_total_inserted,
         user_approved_nfiles, user_approved_deleted, user_approved_inserted) = self.__calculate(db, commit)

        if self.__type == ApprovalColumn.APPROVED:
            if user_approved_nfiles == user_total_nfiles:
                if approved_nfiles == total_nfiles:
                    target.text()
                elif approved_deleted == total_deleted and approved_inserted == total_inserted:
                    target.span().text("?? %")
                else:
                    target.span().text("%d %%" % int(100.0 * ((total_deleted + total_inserted) - (approved_deleted + approved_inserted)) / (total_deleted + total_inserted)))
            elif user_approved_deleted == user_total_deleted and user_approved_inserted == user_total_inserted:
                target.span().text("?? %")
            else:
                target.span().text("%d %%" % int(100.0 * ((user_total_deleted + user_total_inserted) - (user_approved_deleted + user_approved_inserted)) / (user_total_deleted + user_total_inserted)))
        else:
            if user_approved_deleted == user_total_deleted and user_approved_inserted == user_total_inserted:
                target.span().text("-%d/+%d" % (total_deleted, total_inserted))
            else:
                target.span().text("-%d/+%d" % (user_total_deleted, user_total_inserted))

def notModified(req, db, user, review):
    value = req.getRequestHeader("If-None-Match")
    return review.getETag(db, user) == value

def renderShowReview(req, db, user):
    profiler = profiling.Profiler()

    cursor = db.cursor()

    if user.getPreference(db, "commit.diff.compactMode"): default_compact = "yes"
    else: default_compact = "no"

    compact = req.getParameter("compact", default_compact) == "yes"
    highlight = req.getParameter("highlight", None)

    review_id = req.getParameter("id", filter=int)
    review = dbutils.Review.fromId(db, review_id, load_commits=False, profiler=profiler)

    profiler.check("create review")

    if not review:
        raise page.utils.DisplayMessage("Invalid Review ID", "%d is not a valid review ID." % review_id)

    if review.getETag(db, user) == req.getRequestHeader("If-None-Match"):
        raise page.utils.NotModified

    profiler.check("ETag")

    repository = review.repository

    prefetch_commits = {}

    cursor.execute("""SELECT DISTINCT sha1, child
                        FROM changesets
                        JOIN reviewchangesets ON (reviewchangesets.changeset=changesets.id)
                        JOIN commits ON (commits.id=changesets.child)
                       WHERE review=%s""",
                   (review.id,))

    prefetch_commits.update(dict(cursor))

    profiler.check("commits (query)")

    cursor.execute("""SELECT old_head, commits1.sha1, new_head, commits2.sha1, new_upstream, commits3.sha1
                        FROM reviewrebases
             LEFT OUTER JOIN commits AS commits1 ON (commits1.id=old_head)
             LEFT OUTER JOIN commits AS commits2 ON (commits2.id=new_head)
             LEFT OUTER JOIN commits AS commits3 ON (commits3.id=new_upstream)
                       WHERE review=%s""",
                   (review.id,))

    rebases = cursor.fetchall()

    if rebases:
        has_finished_rebases = False

        for old_head_id, old_head_sha1, new_head_id, new_head_sha1, new_upstream_id, new_upstream_sha1 in rebases:
            if old_head_id:
                prefetch_commits[old_head_sha1] = old_head_id
            if new_head_id:
                prefetch_commits[new_head_sha1] = new_head_id
                has_finished_rebases = True
            if new_upstream_id:
                prefetch_commits[new_upstream_sha1] = new_upstream_id

        profiler.check("auxiliary commits (query)")

        if has_finished_rebases:
            cursor.execute("""SELECT commits.sha1, commits.id
                                FROM commits
                                JOIN reachable ON (reachable.commit=commits.id)
                               WHERE branch=%s""",
                           (review.branch.id,))

            prefetch_commits.update(dict(cursor))

            profiler.check("actual commits (query)")

    prefetch_commits = gitutils.FetchCommits(repository, prefetch_commits)

    document = htmlutils.Document(req)

    html = document.html()
    head = html.head()
    body = html.body(onunload="void(0);")

    def flush(target=None):
        return document.render(stop=target, pretty=not compact)

    def renderHeaderItems(target):
        has_draft_items = review_utils.renderDraftItems(db, user, review, target)

        target = target.div("buttons")

        if not has_draft_items:
            if review.state == "open":
                if review.accepted(db):
                    target.button(id="closeReview", onclick="closeReview();").text("Close Review")
                else:
                    if user in review.owners or user.getPreference(db, "review.pingAnyReview"):
                        target.button(id="pingReview", onclick="pingReview();").text("Ping Review")
                    if user in review.owners or user.getPreference(db, "review.dropAnyReview"):
                        target.button(id="dropReview", onclick="dropReview();").text("Drop Review")

                if user in review.owners and not review.description:
                    target.button(id="writeDescription", onclick="editDescription();").text("Write Description")
            else:
                target.button(id="reopenReview", onclick="reopenReview();").text("Reopen Review")

        target.span("buttonscope buttonscope-global")

    profiler.check("prologue")

    page.utils.generateHeader(body, db, user, renderHeaderItems, profiler=profiler)

    cursor.execute("SELECT 1 FROM fullreviewuserfiles WHERE review=%s AND state='pending' AND assignee=%s", (review.id, user.id))
    hasPendingChanges = bool(cursor.fetchone())

    if hasPendingChanges:
        head.setLink("next", "showcommit?review=%d&filter=pending" % review.id)

    profiler.check("header")

    document.addExternalStylesheet("resource/showreview.css")
    document.addExternalStylesheet("resource/review.css")
    document.addExternalStylesheet("resource/comment.css")
    document.addExternalScript("resource/showreview.js")
    document.addExternalScript("resource/review.js")
    document.addExternalScript("resource/comment.js")
    document.addExternalScript("resource/reviewfilters.js")
    document.addExternalScript("resource/autocomplete.js")
    document.addInternalScript(user.getJS())
    document.addInternalScript("var owners = [ %s ];" % ", ".join(owner.getJSConstructor() for owner in review.owners))
    document.addInternalScript("var updateCheckInterval = %d;" % user.getPreference(db, "review.updateCheckInterval"));

    log.html.addResources(document)

    document.addInternalScript(review.getJS())

    target = body.div("main")

    basic = target.table('paleyellow basic', align='center')
    basic.col(width='10%')
    basic.col(width='60%')
    basic.col(width='30%')
    h1 = basic.tr().td('h1', colspan=3).h1()
    h1.text("r/%d: " % review.id)
    h1.span(id="summary").text("%s" % review.summary, linkify=linkify.Context(db=db, review=review))
    h1.a("edit", href="javascript:editSummary();").text("[edit]")

    def linkToCommit(commit):
        cursor.execute("SELECT 1 FROM commits JOIN changesets ON (child=commits.id) JOIN reviewchangesets ON (changeset=changesets.id) WHERE sha1=%s AND review=%s", (commit.sha1, review.id))
        if cursor.fetchone():
            return "%s/%s?review=%d" % (review.repository.name, commit.sha1, review.id)
        return "%s/%s" % (review.repository.name, commit.sha1)

    def row(heading, value, help, right=None, linkify=False, cellId=None):
        main_row = basic.tr('line')
        main_row.td('heading').text("%s:" % heading)
        if right is False: colspan = 2
        else: colspan = None
        if callable(value): value(main_row.td('value', id=cellId, colspan=colspan).preformatted())
        else: main_row.td('value', id=cellId, colspan=colspan).preformatted().text(value, linkify=linkify, repository=review.repository)
        if right is False: pass
        elif callable(right): right(main_row.td('right', valign='bottom'))
        else: main_row.td('right').text()
        if help: basic.tr('help').td('help', colspan=3).text(help)

    def renderBranchName(target):
        target.code("branch inset").text(review.branch.name, linkify=linkify.Context())

        if repository.name != user.getPreference(db, "defaultRepository"):
            target.text(" in ")
            target.code("repository inset").text(repository.getURL(db, user))

        cursor.execute("""SELECT id, remote, remote_name, disabled, previous
                            FROM trackedbranches
                           WHERE repository=%s
                             AND local_name=%s""",
                       (repository.id, review.branch.name))

        row = cursor.fetchone()
        if row:
            trackedbranch_id, remote, remote_name, disabled, previous = row

            target.p("tracking disabled" if disabled else "tracking").text("tracking")

            target.code("branch inset").text(remote_name, linkify=linkify.Context(remote=remote))
            target.text(" in ")
            target.code("repository inset").text(remote, linkify=linkify.Context())

            if previous:
                target.span("lastupdate").script(type="text/javascript").text("document.write('(last fetched: ' + shortDate(new Date(%d)) + ')');" % (calendar.timegm(previous.utctimetuple()) * 1000))

            if user in review.owners or user.hasRole(db, "administrator"):
                buttons = target.div("buttons")

                if review.state == "open":
                    if disabled:
                        button = buttons.button("enabletracking",
                                                onclick=("enableTracking(%d, %s, %s);"
                                                         % (trackedbranch_id,
                                                            htmlutils.jsify(remote),
                                                            htmlutils.jsify(remote_name))))
                        button.text("Enable Tracking")
                    else:
                        buttons.button("disabletracking", onclick="triggerUpdate(%d);" % trackedbranch_id).text("Update Now")
                        buttons.button("disabletracking", onclick="disableTracking(%d);" % trackedbranch_id).text("Disable Tracking")

                    buttons.button("rebasereview", onclick="location.assign('/rebasetrackingreview?review=%d');" % review.id).text("Rebase Review")

    def renderReviewers(target):
        if review.reviewers:
            for index, reviewer in enumerate(review.reviewers):
                if index != 0: target.text(", ")
                span = target.span("user %s" % reviewer.status)
                span.span("name").text(reviewer.fullname)
                if reviewer.status == 'absent':
                    span.span("status").text(" (%s)" % reviewer.getAbsence(db))
                elif reviewer.status == 'retired':
                    span.span("status").text(" (retired)")
        else:
            target.i().text("No reviewers.")

        cursor.execute("""SELECT reviewfilters.id, reviewfilters.uid, reviewfilters.path
                            FROM reviewfilters
                            JOIN users ON (reviewfilters.uid=users.id)
                           WHERE reviewfilters.review=%s
                             AND reviewfilters.type='reviewer'
                             AND users.status!='retired'""",
                       (review.id,))

        rows = cursor.fetchall()
        reviewer_filters_hidden = []

        if rows:
            table = target.table("reviewfilters reviewers")

            row = table.thead().tr("h1")
            row.th("h1", colspan=4).text("Custom filters:")

            filter_data = {}
            reviewfilters = {}

            for filter_id, user_id, path in rows:
                filter_user = dbutils.User.fromId(db, user_id)
                path = path or '/'
                reviewfilters.setdefault(filter_user.fullname, []).append(path)
                filter_data[(filter_user.fullname, path)] = (filter_id, filter_user)

            count = 0
            tbody = table.tbody()

            for fullname in sorted(reviewfilters.keys()):
                original_paths = sorted(reviewfilters[fullname])
                trimmed_paths = diff.File.eliminateCommonPrefixes(original_paths[:])

                first = True

                for original_path, trimmed_path in zip(original_paths, trimmed_paths):
                    row = tbody.tr("filter")

                    if first:
                        row.td("username", rowspan=len(original_paths)).text(fullname)
                        row.td("reviews", rowspan=len(original_paths)).text("reviews")
                        first = False

                    row.td("path").span().innerHTML(trimmed_path)

                    filter_id, filter_user = filter_data[(fullname, original_path)]

                    href = "javascript:removeReviewFilter(%d, %s, 'reviewer', %s, %s);" % (filter_id, filter_user.getJSConstructor(), htmlutils.jsify(original_path), "true" if filter_user != user else "false")
                    row.td("remove").a(href=href).text("[remove]")

                    count += 1

            tfoot = table.tfoot()
            tfoot.tr().td(colspan=4).text("%d line%s hidden" % (count, "s" if count > 1 else ""))

            if count > 10:
                tbody.setAttribute("class", "hidden")
                reviewer_filters_hidden.append(True)
            else:
                tfoot.setAttribute("class", "hidden")
                reviewer_filters_hidden.append(False)

        buttons = target.div("buttons")

        if reviewer_filters_hidden:
            buttons.button("showfilters", onclick="toggleReviewFilters('reviewers', $(this));").text("%s Custom Filters" % ("Show" if reviewer_filters_hidden[0] else "Hide"))

        if not review.applyfilters:
            buttons.button("applyfilters", onclick="applyFilters('global');").text("Apply Global Filters")

        if review.applyfilters and review.repository.parent and not review.applyparentfilters:
            buttons.button("applyparentfilters", onclick="applyFilters('upstream');").text("Apply Upstream Filters")

        buttons.button("addreviewer", onclick="addReviewer();").text("Add Reviewer")
        buttons.button("manage", onclick="location.href='managereviewers?review=%d';" % review.id).text("Manage Assignments")

    def renderWatchers(target):
        if review.watchers:
            for index, watcher in enumerate(review.watchers):
                if index != 0: target.text(", ")
                span = target.span("user %s" % watcher.status)
                span.span("name").text(watcher.fullname)
                if watcher.status == 'absent':
                    span.span("status").text(" (%s)" % watcher.getAbsence(db))
                elif watcher.status == 'retired':
                    span.span("status").text(" (retired)")
        else:
            target.i().text("No watchers.")

        cursor.execute("""SELECT reviewfilters.id, reviewfilters.uid, reviewfilters.path
                            FROM reviewfilters
                            JOIN users ON (reviewfilters.uid=users.id)
                           WHERE reviewfilters.review=%s
                             AND reviewfilters.type='watcher'
                             AND users.status!='retired'""",
                       (review.id,))

        rows = cursor.fetchall()
        watcher_filters_hidden = []

        if rows:
            table = target.table("reviewfilters watchers")

            row = table.thead().tr("h1")
            row.th("h1", colspan=4).text("Custom filters:")

            filter_data = {}
            reviewfilters = {}

            for filter_id, user_id, path in rows:
                filter_user = dbutils.User.fromId(db, user_id)
                path = path or '/'
                reviewfilters.setdefault(filter_user.fullname, []).append(path)
                filter_data[(filter_user.fullname, path)] = (filter_id, filter_user)

            count = 0
            tbody = table.tbody()

            for fullname in sorted(reviewfilters.keys()):
                original_paths = sorted(reviewfilters[fullname])
                trimmed_paths = diff.File.eliminateCommonPrefixes(original_paths[:])

                first = True

                for original_path, trimmed_path in zip(original_paths, trimmed_paths):
                    row = tbody.tr("filter")

                    if first:
                        row.td("username", rowspan=len(original_paths)).text(fullname)
                        row.td("reviews", rowspan=len(original_paths)).text("watches")
                        first = False

                    row.td("path").span().innerHTML(trimmed_path)

                    filter_id, filter_user = filter_data[(fullname, original_path)]

                    href = "javascript:removeReviewFilter(%d, %s, 'watcher', %s, %s);" % (filter_id, filter_user.getJSConstructor(), htmlutils.jsify(original_path), "true" if filter_user != user else "false")
                    row.td("remove").a(href=href).text("[remove]")

                    count += 1

            tfoot = table.tfoot()
            tfoot.tr().td(colspan=4).text("%d line%s hidden" % (count, "s" if count > 1 else ""))

            if count > 10:
                tbody.setAttribute("class", "hidden")
                watcher_filters_hidden.append(True)
            else:
                tfoot.setAttribute("class", "hidden")
                watcher_filters_hidden.append(False)

        buttons = target.div("buttons")

        if watcher_filters_hidden:
            buttons.button("showfilters", onclick="toggleReviewFilters('watchers', $(this));").text("%s Custom Filters" % ("Show" if watcher_filters_hidden[0] else "Hide"))

        buttons.button("addwatcher", onclick="addWatcher();").text("Add Watcher")

        if user not in review.reviewers and user not in review.owners:
            if user not in review.watchers:
                buttons.button("watch", onclick="watchReview();").text("Watch Review")
            elif review.watchers[user] == "manual":
                buttons.button("watch", onclick="unwatchReview();").text("Stop Watching Review")

    def renderEditOwners(target):
        target.button("description", onclick="editOwners();").text("Edit Owners")

    def renderEditDescription(target):
        target.button("description", onclick="editDescription();").text("Edit Description")

    def renderRecipientList(target):
        cursor.execute("""SELECT uid, fullname, include
                            FROM reviewrecipientfilters
                 LEFT OUTER JOIN users ON (uid=id)
                           WHERE review=%s""",
                       (review.id,))

        default_include = True
        included = dict((owner.fullname, owner.id) for owner in review.owners)
        excluded = {}

        for user_id, fullname, include in cursor:
            if user_id is None: default_include = include
            elif include: included[fullname] = user_id
            elif user_id not in review.owners: excluded[fullname] = user_id

        mode = None
        users = None

        buttons = []
        opt_in_button = False
        opt_out_button = False

        if default_include:
            if excluded:
                mode = "Everyone except "
                users = excluded
                opt_out_button = user.fullname not in excluded
                opt_in_button = not opt_out_button
            else:
                mode = "Everyone."
                opt_out_button = True
        else:
            if included:
                mode = "No-one except "
                users = included
                opt_in_button = user.fullname not in included
                opt_out_button = not opt_in_button
            else:
                mode = "No-one at all."
                opt_in_button = True

        if user not in review.owners and (user in review.reviewers or user in review.watchers):
            if opt_in_button:
                buttons.append(("Include me, please!", "includeRecipient(%d);" % user.id))
            if opt_out_button:
                buttons.append(("Exclude me, please!", "excludeRecipient(%d);" % user.id))

        target.span("mode").text(mode)

        if users:
            container = target.span("users")

            first = True
            for fullname in sorted(users.keys()):
                if first: first = False
                else: container.text(", ")

                container.span("user", critic_user_id=users[fullname]).text(fullname)

            container.text(".")

        if buttons:
            container = target.div("buttons")

            for label, onclick in buttons:
                container.button(onclick=onclick).text(label)

    row("Branch", renderBranchName, "The branch containing the commits to review.", right=False)
    row("Owner%s" % ("s" if len(review.owners) > 1 else ""), ", ".join(owner.fullname for owner in review.owners), "The users who created and/or owns the review.", right=renderEditOwners)
    if review.description:
        row("Description", review.description, "A longer description of the changes to be reviewed.", linkify=linkToCommit, cellId="description", right=renderEditDescription)
    row("Reviewers", renderReviewers, "Users responsible for reviewing the changes in this review.", right=False)
    row("Watchers", renderWatchers, "Additional users who receive e-mails about updates to this review.", right=False)
    row("Recipient List", renderRecipientList, "Users (among the reviewers and watchers) who will receive any e-mails about the review.", right=False)

    profiler.check("basic")

    review_state = review.getReviewState(db)

    profiler.check("review state")

    progress = target.table('paleyellow progress', align='center')
    progress_header = progress.tr().td('h1', colspan=3).h1()
    progress_header.text("Review Progress")
    progress_header_right = progress_header.span("right")
    progress_header_right.text("Display log: ")
    progress_header_right.a(href="showreviewlog?review=%d&granularity=module" % review.id).text("[per module]")
    progress_header_right.text()
    progress_header_right.a(href="showreviewlog?review=%d&granularity=file" % review.id).text("[per file]")
    progress_h1 = progress.tr().td('percent', colspan=3).h1()

    title_data = { 'id': 'r/%d' % review.id,
                   'summary': review.summary,
                   'progress': str(review_state) }

    if review.state == "closed":
        progress_h1.img(src=htmlutils.getStaticResourceURI("seal-of-approval-left.png"),
                        style="position: absolute; margin-left: -80px; margin-top: -100px")
        progress_h1.text("Finished!")

        if review.repository.hasMainBranch():
            main_branch = review.repository.getMainBranch(db)
            if review.branch.getHead(db).isAncestorOf(main_branch.getHead(db)):
                remark = progress_h1.div().span("remark")
                remark.text("Merged to ")
                remark.a(href="/log?repository=%s&branch=%s" % (review.repository.name, main_branch.name)).text(main_branch.name)
                remark.text(".")
    elif review.state == "dropped":
        progress_h1.text("Dropped...")
    elif review.state == "open" and review_state.accepted:
        progress_h1.img(src=htmlutils.getStaticResourceURI("seal-of-approval-left.png"),
                        style="position: absolute; margin-left: -80px; margin-top: -100px")
        progress_h1.text("Accepted!")
        progress_h1.div().span("remark").text("Hurry up and close it before anyone has a change of heart.")
    else:
        progress_h1.text(review_state.getProgress())

        if review_state.issues:
            progress_h1.span("comments").text(" and ")
            progress_h1.text("%d" % review_state.issues)
            progress_h1.span("comments").text(" issue%s" % (review_state.issues > 1 and "s" or ""))

        if review_state.getPercentReviewed() != 100.0:
            cursor = db.cursor()
            cursor.execute("""SELECT 1
                                FROM reviewfiles
                     LEFT OUTER JOIN reviewuserfiles ON (reviewuserfiles.file=reviewfiles.id)
                               WHERE reviewfiles.review=%s
                                 AND reviewfiles.state='pending'
                                 AND reviewuserfiles.uid IS NULL""",
                           (review.id,))

            if cursor.fetchone():
                progress.tr().td('stuck', colspan=3).a(href="showreviewlog?review=%d&granularity=file&unassigned=yes" % review.id).text("Not all changes have a reviewer assigned!")

            cursor.execute("""SELECT uid, MIN(reviewuserfiles.time)
                                FROM reviewfiles
                                JOIN reviewuserfiles ON (reviewuserfiles.file=reviewfiles.id)
                               WHERE reviewfiles.review=%s
                                 AND reviewfiles.state='pending'
                            GROUP BY reviewuserfiles.uid""",
                           (review.id,))

            def total_seconds(delta):
                return delta.days * 60 * 60 * 24 + delta.seconds

            now = datetime.datetime.now()
            pending_reviewers = [(dbutils.User.fromId(db, user_id), total_seconds(now - timestamp)) for (user_id, timestamp) in cursor.fetchall() if total_seconds(now - timestamp) > 60 * 60 * 8]

            if pending_reviewers:
                progress.tr().td('stragglers', colspan=3).text("Needs review from")
                for reviewer, seconds in pending_reviewers:
                    if reviewer.status == 'retired': continue
                    elif reviewer.status == 'absent': warning = " absent"
                    elif not reviewer.getPreference(db, "email.activated"): warning = " no-email"
                    else: warning = ""

                    if seconds < 60 * 60 * 24:
                        hours = seconds / (60 * 60)
                        duration = " (%d hour%s)" % (hours, "s" if hours > 1 else "")
                    elif seconds < 60 * 60 * 24 * 7:
                        days = seconds / (60 * 60 * 24)
                        duration = " (%d day%s)" % (days, "s" if days > 1 else "")
                    elif seconds < 60 * 60 * 24 * 30:
                        weeks = seconds / (60 * 60 * 24 * 7)
                        duration = " (%d week%s)" % (weeks, "s" if weeks > 1 else "")
                    else:
                        duration = " (wake up!)"

                    progress.tr().td('straggler' + warning, colspan=3).text("%s%s" % (reviewer.fullname, duration))
                if user in review.owners:
                    progress.tr().td('pinging', colspan=3).span().text("Send a message to these users by pinging the review.")

    title_format = user.getPreference(db, 'ui.title.showReview')

    try:
        document.setTitle(title_format % title_data)
    except Exception as exc:
        document.setTitle(traceback.format_exception_only(type(exc), exc)[0].strip())

    profiler.check("progress")

    check = profiler.start("ApprovalColumn.fillCache")

    def linkToCommit(commit, overrides={}):
        if "rebase_conflicts" in overrides:
            return "%s..%s?review=%d&conflicts=yes" % (overrides["rebase_conflicts"].sha1[:8], commit.sha1[:8], review.id)
        else:
            return "%s?review=%d" % (commit.sha1[:8], review.id)

    approval_cache = {}

    ApprovalColumn.fillCache(db, user, review, approval_cache, profiler)

    check.stop()

    summary_column = SummaryColumn(review, linkToCommit)
    summary_column.fillCache(db, review)

    profiler.check("SummaryColumn.fillCache")

    columns = [(10, log.html.WhenColumn()),
               (60, summary_column),
               (16, log.html.AuthorColumn()),
               (7, ApprovalColumn(user, review, ApprovalColumn.APPROVED, approval_cache)),
               (7, ApprovalColumn(user, review, ApprovalColumn.TOTAL, approval_cache))]

    def renderReviewPending(db, target):
        if not user.isAnonymous():
            target.text("Filter: ")

            if hasPendingChanges:
                target.a(href="showcommit?review=%d&filter=pending" % review.id, title="All changes you need to review.").text("[pending]")
                target.text()
            if user in review.reviewers:
                target.a(href="showcommit?review=%d&filter=reviewable" % review.id, title="All changes you can review, including what you've already reviewed.").text("[reviewable]")
                target.text()

            target.a(href="showcommit?review=%d&filter=relevant" % review.id, title="All changes that match your filters.").text("[relevant]")
            target.text()

        target.text("Manual: ")
        target.a(href="filterchanges?review=%d" % review.id, title="Manually select what files to display of the changes from all commits.").text("[full]")
        target.text()
        target.a(href="javascript:void(filterPartialChanges());", title="Manually select what files to display of the changes in a selection of commits.").text("[partial]")

    req.addResponseHeader("ETag", review.getETag(db, user))

    if user.getPreference(db, "review.useMustRevalidate"):
        req.addResponseHeader("Cache-Control", "must-revalidate")

    yield flush(target)

    try:
        if prefetch_commits.error is not None:
            raise base.ImplementationError(
                "failed to prefetch commits:\n%s" % prefetch_commits.error)

        prefetch_commits.getCommits(db)

        profiler.check("FetchCommits.getCommits()")

        cursor.execute("""SELECT DISTINCT type, parent, child
                            FROM changesets
                            JOIN reviewchangesets ON (reviewchangesets.changeset=changesets.id)
                            JOIN commits ON (commits.id=changesets.child)
                           WHERE review=%s""",
                       (review.id,))

        commits = set()
        conflicts = {}

        for changeset_type, parent_id, child_id in cursor:
            child = gitutils.Commit.fromId(db, repository, child_id)
            if changeset_type == "conflicts":
                conflicts[child] = gitutils.Commit.fromId(db, repository, parent_id)
            else:
                commits.add(child)

        commits = list(commits)

        cursor.execute("""SELECT id, old_head, new_head, new_upstream, uid, branch
                            FROM reviewrebases
                           WHERE review=%s""",
                       (review.id,))

        all_rebases = [(rebase_id,
                        gitutils.Commit.fromId(db, repository, old_head),
                        gitutils.Commit.fromId(db, repository, new_head) if new_head else None,
                        dbutils.User.fromId(db, user_id),
                        gitutils.Commit.fromId(db, repository, new_upstream) if new_upstream is not None else None,
                        branch_name)
                       for rebase_id, old_head, new_head, new_upstream, user_id, branch_name in cursor]

        bottom_right = None

        finished_rebases = filter(lambda item: item[2] is not None, all_rebases)
        current_rebases = filter(lambda item: item[2] is None, all_rebases)

        if current_rebases:
            assert len(current_rebases) == 1

            def renderCancelRebase(db, target):
                target.button("cancelrebase").text("Cancel Rebase")

            if user == current_rebases[0][3]:
                bottom_right = renderCancelRebase
        else:
            def renderPrepareRebase(db, target):
                target.button("preparerebase").text("Prepare Rebase")

            bottom_right = renderPrepareRebase

        if finished_rebases:
            cursor.execute("""SELECT commit
                                FROM reachable
                               WHERE branch=%s""",
                           (review.branch.id,))

            actual_commits = [gitutils.Commit.fromId(db, repository, commit_id) for (commit_id,) in cursor]
        else:
            actual_commits = []

        log.html.render(db, target, "Commits (%d)", commits=commits, columns=columns, title_right=renderReviewPending, rebases=finished_rebases, branch_name=review.branch.name, bottom_right=bottom_right, review=review, highlight=highlight, profiler=profiler, user=user, extra_commits=actual_commits, conflicts=conflicts)

        yield flush(target)

        profiler.check("log")
    except gitutils.GitReferenceError as error:
        div = target.div("error")
        div.h1().text("Error!")
        div.text("The commit %s is missing from the repository." % error.sha1)
    except gitutils.GitError as error:
        div = target.div("error")
        div.h1().text("Error!")
        div.text("Failed to read commits from the repository: %s" % error.message)

    all_chains = review_comment.CommentChain.fromReview(db, review, user)

    profiler.check("chains (load)")

    if all_chains:
        issue_chains = filter(lambda chain: chain.type == "issue", all_chains)
        draft_issues = filter(lambda chain: chain.state == "draft", issue_chains)
        open_issues = filter(lambda chain: chain.state == "open", issue_chains)
        addressed_issues = filter(lambda chain: chain.state == "addressed", issue_chains)
        closed_issues = filter(lambda chain: chain.state == "closed", issue_chains)
        note_chains = filter(lambda chain: chain.type == "note", all_chains)
        draft_notes = filter(lambda chain: chain.state == "draft", note_chains)
        open_notes = filter(lambda chain: chain.state != "draft" and chain.state != "empty", note_chains)
    else:
        open_issues = []
        open_notes = []

    chains = target.table("paleyellow comments", align="center", cellspacing=0)
    h1 = chains.tr("h1").td("h1", colspan=3).h1().text("Comments")
    links = h1.span("links")

    if all_chains:
        links.a(href="showcomments?review=%d&filter=all" % review.id).text("[display all]")

        if not user.isAnonymous():
            links.a(href="showcomments?review=%d&filter=all&blame=%s" % (review.id, user.name)).text("[in my commits]")

            cursor.execute("""SELECT count(commentstoread.comment) > 0
                                FROM commentchains
                                JOIN comments ON (comments.chain=commentchains.id)
                                JOIN commentstoread ON (commentstoread.comment=comments.id)
                               WHERE commentchains.review=%s
                                 AND commentstoread.uid=%s""",
                           [review.id, user.id])

            if cursor.fetchone()[0]:
                links.a(href="showcomments?review=%d&filter=toread" % review.id).text("[display unread]")

        def renderChains(target, chains):
            for chain in chains:
                row = target.tr("comment %s %s" % (chain.type, chain.state))
                row.td("author").text(chain.user.fullname)
                row.td("title").a(href="showcomment?chain=%d" % chain.id).innerHTML(chain.leader())

                ncomments = chain.countComments()
                nunread = chain.countUnread()

                cell = row.td("when")
                if ncomments == 1:
                    if nunread: cell.b().text("Unread")
                    else: cell.text("No replies")
                else:
                    if nunread: cell.b().text("%d of %d unread" % (nunread, ncomments))
                    else: cell.text("%d repl%s" % (ncomments - 1, "ies" if ncomments > 2 else "y"))

        if draft_issues:
            h2 = chains.tr("h2", id="draft-issues").td("h2", colspan=3).h2().text("Draft Issues")
            h2.a(href="showcomments?review=%d&filter=draft-issues" % review.id).text("[display all]")
            h2.a(href="showcomments?review=%d&filter=draft-issues&blame=%s" % (review.id, user.name)).text("[in my commits]")
            renderChains(chains, draft_issues)

        if open_issues:
            h2 = chains.tr("h2", id="open-issues").td("h2", colspan=3).h2().text("Open Issues")
            h2.a(href="showcomments?review=%d&filter=open-issues" % review.id).text("[display all]")
            h2.a(href="showcomments?review=%d&filter=open-issues&blame=%s" % (review.id, user.name)).text("[in my commits]")
            renderChains(chains, open_issues)

        if addressed_issues:
            h2 = chains.tr("h2", id="addressed-issues").td("h2", colspan=3).h2().text("Addressed Issues")
            h2.a(href="showcomments?review=%d&filter=addressed-issues" % review.id).text("[display all]")
            h2.a(href="showcomments?review=%d&filter=addressed-issues&blame=%s" % (review.id, user.name)).text("[in my commits]")
            renderChains(chains, addressed_issues)

        if closed_issues:
            h2 = chains.tr("h2", id="closed-issues").td("h2", colspan=3).h2().text("Resolved Issues")
            h2.a(href="showcomments?review=%d&filter=closed-issues" % review.id).text("[display all]")
            h2.a(href="showcomments?review=%d&filter=closed-issues&blame=%s" % (review.id, user.name)).text("[in my commits]")
            renderChains(chains, closed_issues)

        if draft_notes:
            h2 = chains.tr("h2", id="draft-notes").td("h2", colspan=3).h2().text("Draft Notes")
            h2.a(href="showcomments?review=%d&filter=draft-notes" % review.id).text("[display all]")
            h2.a(href="showcomments?review=%d&filter=draft-notes&blame=%s" % (review.id, user.name)).text("[in my commits]")
            renderChains(chains, draft_notes)

        if open_notes:
            h2 = chains.tr("h2", id="notes").td("h2", colspan=3).h2().text("Notes")
            h2.a(href="showcomments?review=%d&filter=open-notes" % review.id).text("[display all]")
            h2.a(href="showcomments?review=%d&filter=open-notes&blame=%s" % (review.id, user.name)).text("[in my commits]")
            renderChains(chains, open_notes)

    buttons = chains.tr("buttons").td("buttons", colspan=3)
    buttons.button(onclick="CommentChain.create('issue');").text("Raise Issue")
    buttons.button(onclick="CommentChain.create('note');").text("Write Note")

    profiler.check("chains (render)")

    yield flush(target)

    cursor.execute("""SELECT DISTINCT reviewfiles.file, theirs.uid
                        FROM reviewfiles
                        JOIN reviewuserfiles AS yours ON (yours.file=reviewfiles.id)
                        JOIN reviewuserfiles AS theirs ON (theirs.file=yours.file AND theirs.uid!=yours.uid)
                       WHERE reviewfiles.review=%s
                         AND yours.uid=%s""",
                   (review.id, user.id))
    rows = cursor.fetchall()

    profiler.check("shared assignments (query)")

    if rows:
        reviewers = {}

        for file_id, user_id in rows:
            reviewers.setdefault(file_id, {})[user_id] = set()

        shared = target.table('paleyellow shared', align='center', cellspacing=0)
        row = shared.tr('h1')
        shared_header = row.td('h1', colspan=2).h1()
        shared_header.text("Shared Assignments")
        shared_buttons = row.td('buttons', colspan=2).span(style="display: none")
        shared_buttons.button("confirm").text("Confirm")
        shared_buttons.button("cancel").text("Cancel")

        granularity = "module"

        def moduleFromFile(file_id):
            filename = dbutils.describe_file(db, file_id)
            return getModuleFromFile(repository, filename) or filename

        def formatFiles(files):
            paths = sorted([dbutils.describe_file(db, file_id) for file_id in files])
            if granularity == "file":
                return diff.File.eliminateCommonPrefixes(paths)
            else:
                modules = set()
                files = []
                for path in paths:
                    module = getModuleFromFile(path)
                    if module: modules.add(module)
                    else: files.append(path)
                return sorted(modules) + diff.File.eliminateCommonPrefixes(files)

        files_per_team = review_utils.collectReviewTeams(reviewers)
        teams_per_modules = {}

        profiler.check("shared assignments (collect teams)")

        for team, files in files_per_team.items():
            modules = set()
            for file_id in files:
                modules.add(moduleFromFile(file_id))
            teams_per_modules.setdefault(frozenset(modules), set()).update(team)

        for modules, team in teams_per_modules.items():
            row = shared.tr("reviewers")

            cell = row.td("reviewers")
            members = sorted([dbutils.User.fromId(db, user_id).fullname for user_id in team])
            for member in members: cell.text(member).br()
            row.td("willreview").innerHTML("<span class='also'>also</span>&nbsp;review&nbsp;changes&nbsp;in")

            cell = row.td("files")
            for path in diff.File.eliminateCommonPrefixes(sorted(modules)):
                cell.span("file").innerHTML(path).br()

            paths = json_encode(list(modules))
            user_ids = json_encode(list(team))

            cell = row.td("buttons")
            cell.button("accept", critic_paths=paths, critic_user_ids=user_ids).text("I will review this!")
            cell.button("deny", critic_paths=paths, critic_user_ids=user_ids).text("They will review this!")

    yield flush(target)

    profiler.check("shared assignments")

    cursor.execute("SELECT batches.id, users.fullname, batches.comment, batches.time FROM batches JOIN users ON (users.id=batches.uid) WHERE batches.review=%s ORDER BY batches.id DESC", [review.id])
    rows = cursor.fetchall()

    if rows:
        notes = dict([(chain.id, chain) for chain in open_notes])

        batches = target.table("paleyellow batches", align="center", cellspacing=0)
        batches.tr().td("h1", colspan=3).h1().text("Work Log")

        for batch_id, user_fullname, chain_id, when in rows:
            row = batches.tr("batch")
            row.td("author").text(user_fullname)
            title = "<i>No comment</i>"
            if chain_id:
                if chain_id in notes:
                    title = notes[chain_id].leader()
                else:
                    for chain in all_chains:
                        if chain.id == chain_id:
                            title = chain.leader()
                            break
            row.td("title").a(href="showbatch?batch=%d" % batch_id).innerHTML(title)
            row.td("when").text(user.formatTimestamp(db, when))

    profiler.check("batches")
    profiler.output(db, user, target)

    yield flush()

    if review.branch.head:
        try: head_according_to_git = repository.revparse(review.branch.name)
        except: head_according_to_git = None

        head_according_to_us = review.branch.head.sha1

        if head_according_to_git != head_according_to_us:
            # The git repository disagrees with us.  Potentially harmful updates
            # to the branch will be rejected by the git hook while this is the
            # case, but this means that "our" head might not be referenced at
            # all and thus that it might be GC:ed by the git repository at some
            # point.  To avoid that, add a keepalive reference.
            repository.keepalive(head_according_to_us)

            yield "\n<!-- branch head mismatch: git=%s, us=%s (corrected) -->" % (head_according_to_git[:8] if head_according_to_git else "N/A", head_according_to_us[:8])

########NEW FILE########
__FILENAME__ = showreviewlog
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2012 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import dbutils
import htmlutils
import page.utils
import log.html
import reviewing.utils as review_utils
import reviewing.html as review_html
import reviewing.comment as review_comment
import re
import diff

re_module = re.compile("^((?:data|modules|platforms)/[^/]+)/.*$")

def renderShowReviewLog(req, db, user):
    review_id = page.utils.getParameter(req, "review", filter=int)
    granularity = page.utils.getParameter(req, "granularity")
    unassigned = page.utils.getParameter(req, "unassigned", "no") == "yes"

    cursor = db.cursor()

    review = dbutils.Review.fromId(db, review_id)

    document = htmlutils.Document(req)
    html = document.html()
    head = html.head()
    body = html.body()

    head.title("Review Log: %s" % review.branch.name)

    page.utils.generateHeader(body, db, user, lambda target: review_utils.renderDraftItems(db, user, review, target), extra_links=[("r/%d" % review.id, "Back to Review")])

    document.addExternalStylesheet("resource/showreviewlog.css")
    document.addExternalStylesheet("resource/review.css")
    document.addExternalScript("resource/review.js")
    document.addInternalScript(review.getJS())

    target = body.div("main")

    reviewed_reviewers = review_utils.getReviewedReviewers(db, review)

    def formatFiles(files):
        paths = sorted([dbutils.describe_file(db, file_id) for file_id in files])
        if granularity == "file":
            return diff.File.eliminateCommonPrefixes(paths)
        else:
            modules = set()
            files = []
            for path in paths:
                match = re_module.match(path)
                if match: modules.add(match.group(1))
                else: files.append(path)
            return sorted(modules) + diff.File.eliminateCommonPrefixes(files)

    if reviewed_reviewers and not unassigned:
        reviewed = target.table("paleyellow")
        reviewed.col(width="30%")
        reviewed.col(width="10%")
        reviewed.col(width="60%")
        reviewed.tr().td('h1', colspan=3).h1().text("Reviewed Changes")

        teams = review_utils.collectReviewTeams(reviewed_reviewers)

        for team in teams:
            row = reviewed.tr("reviewers")

            cell = row.td("reviewers")
            users = sorted([dbutils.User.fromId(db, user_id).fullname for user_id in team])
            for user in users: cell.text(user).br()
            row.td("willreview").innerHTML("reviewed")

            cell = row.td("files")
            for file in formatFiles(teams[team]):
                cell.span("file").innerHTML(file).br()

    pending_reviewers = review_utils.getPendingReviewers(db, review)

    if pending_reviewers:
        pending = target.table("paleyellow")
        pending.col(width="30%")
        pending.col(width="10%")
        pending.col(width="60%")
        pending.tr().td('h1', colspan=3).h1().text("Pending Changes")

        teams = review_utils.collectReviewTeams(pending_reviewers)

        if not unassigned:
            for team in teams:
                if team is not None:
                    row = pending.tr("reviewers")

                    cell = row.td("reviewers")
                    users = sorted([dbutils.User.fromId(db, user_id).fullname for user_id in team])
                    for user in users: cell.text(user).br()
                    row.td("willreview").innerHTML("should&nbsp;review")

                    cell = row.td("files")
                    for file in formatFiles(teams[team]):
                        cell.span("file").innerHTML(file).br()

        if None in teams:
            row = pending.tr("reviewers")
            row.td("no-one", colspan=2).text("No reviewers found for changes in")

            cell = row.td("files")
            for file in formatFiles(teams[None]):
                cell.span("file").innerHTML(file).br()

    return document

########NEW FILE########
__FILENAME__ = showtree
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2012 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import os
import stat
import urllib

import dbutils
import gitutils
import page.utils
import htmlutils
import textutils

def renderShowTree(req, db, user):
    cursor = db.cursor()

    sha1 = req.getParameter("sha1")
    path = req.getParameter("path", "/")
    review_id = req.getParameter("review", None, filter=int)

    if path[0] == '/':
        full_path = path
        if path != "/": path = path[1:]
    else:
        full_path = "/" + path
        if not path: path = "/"

    if review_id is None:
        review = None
        repository_arg = req.getParameter("repository", "")
        if repository_arg:
            repository = gitutils.Repository.fromParameter(db, repository_arg)
        else:
            repository = gitutils.Repository.fromSHA1(db, sha1)
    else:
        review = dbutils.Review.fromId(db, review_id)
        repository = review.repository

    document = htmlutils.Document(req)

    html = document.html()
    head = html.head()
    body = html.body()

    extra_links = []

    if review:
        extra_links.append(("r/%d" % review.id, "Back to Review"))

    page.utils.generateHeader(body, db, user, extra_links=extra_links)

    document.addExternalStylesheet("resource/showtree.css")

    target = body.div("main")

    table = target.table("tree paleyellow", align="center", cellspacing=0)
    table.col(width="10%")
    table.col(width="60%")
    table.col(width="20%")

    thead = table.thead()
    h1 = thead.tr().td('h1', colspan=3).h1()

    def make_url(url_path, path):
        params = { "sha1": sha1,
                   "path": path }
        if review is None:
            params["repository"] = str(repository.id)
        else:
            params["review"] = str(review.id)
        return "%s?%s" % (url_path, urllib.urlencode(params))

    if path == "/":
        h1.text("/")
    else:
        h1.a("root", href=make_url("showtree", "/")).text("root")
        h1.span().text('/')

        components = path.split("/")
        for index, component in enumerate(components[:-1]):
            h1.a(href=make_url("showtree", "/".join(components[:index + 1]))).text(component, escape=True)
            h1.span().text('/')

        h1.text(components[-1], escape=True)

    row = thead.tr()
    row.td('mode').text("Mode")
    row.td('name').text("Name")
    row.td('size').text("Size")

    tree = gitutils.Tree.fromPath(gitutils.Commit.fromSHA1(db, repository, sha1), full_path)

    if tree is None:
        raise page.utils.DisplayMessage(
            title="Directory does not exist",
            body=("<p>There is no directory named <code>%s</code> in the commit "
                  "<a href='/showcommit?repository=%s&amp;sha1=%s'>"
                  "<code>%s</code></a>.</p>"
                  % (htmlutils.htmlify(textutils.escape(full_path)),
                     htmlutils.htmlify(repository.name),
                     htmlutils.htmlify(sha1), htmlutils.htmlify(sha1[:8]))),
            html=True)

    def compareEntries(a, b):
        if a.type != b.type:
            if a.type == "tree": return -1
            else: return 1
        else:
            return cmp(a.name, b.name)

    tbody = table.tbody()

    for entry in sorted(tree, cmp=compareEntries):
        if entry.type in ("blob", "tree"):
            if entry.type == "blob":
                url_path = "showfile"
            else:
                url_path = "showtree"

            url = make_url(url_path, os.path.join(path, entry.name))
        else:
            url = None

        row = tbody.tr(entry.type)
        row.td('mode').text(str(entry.mode))

        if stat.S_ISLNK(entry.mode):
            cell = row.td('link', colspan=2)
            cell.span('name').text(entry.name, escape=True)
            cell.text(' -> ')
            cell.span('target').text(repository.fetch(entry.sha1).data)
        elif entry.type == "commit":
            row.td('name').text("%s (%s)" % (entry.name, entry.sha1), escape=True)
            row.td('size').text(entry.size)
        else:
            row.td('name').a(href=url).text(entry.name, escape=True)
            row.td('size').text(entry.size)

    return document

########NEW FILE########
__FILENAME__ = statistics
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2012 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import page.utils
import htmlutils
import dbutils

def renderStatistics(req, db, user):
    document = htmlutils.Document(req)

    html = document.html()
    head = html.head()
    body = html.body()

    def flush(stop):
        return document.render(stop=stop)

    page.utils.generateHeader(body, db, user, current_page="statistics")

    document.addExternalStylesheet("resource/statistics.css")

    table = body.div("main").table("paleyellow", align="center", cellspacing=0)

    def commas(number):
        as_string = str(number)
        if number >= 1000000000:
            as_string = as_string[:-9] + "," + as_string[-9:]
        if number >= 1000000:
            as_string = as_string[:-6] + "," + as_string[-6:]
        if number >= 1000:
            as_string = as_string[:-3] + "," + as_string[-3:]
        return as_string

    table.tr("h1").td("h1", colspan=4).h1().text("Most Lines Reviewed")
    table.tr("space").td(colspan=4)

    cursor = db.cursor()

    cursor.execute("CREATE TEMPORARY TABLE reviewers (uid INTEGER, lines INTEGER)")
    cursor.execute("INSERT INTO reviewers (uid, lines) SELECT reviewer, SUM(deleted) + SUM(inserted) FROM reviewfiles WHERE state='reviewed' GROUP BY reviewer")

    cursor.execute("SELECT uid, lines FROM reviewers ORDER BY lines DESC LIMIT 10")

    self_included = False
    for user_id, lines in cursor:
        if user_id == user.id:
            row = table.tr("line self")
            self_included = True
        else:
            row = table.tr("line")

        row.td("left")
        row.td("user").text(dbutils.User.fromId(db, user_id).fullname)
        row.td("value").text("%s lines" % commas(lines))
        row.td("right")

    if not self_included:
        cursor.execute("SELECT lines FROM reviewers WHERE uid=%s", (user.id,))

        data = cursor.fetchone()
        if data and data[0]:
            lines = data[0]

            cursor.execute("SELECT COUNT(*) + 1 FROM reviewers WHERE lines > %s", (lines,))

            table.tr("space").td(colspan=4)

            row = table.tr("line self extra")
            row.td("left")
            row.td("user").text(user.fullname)
            row.td("value").innerHTML("%s lines" % data[0])
            row.td("right").text("(your position: %d)" % cursor.fetchone()[0])

    table.tr("space").td(colspan=4)
    table.tr("space").td(colspan=4)

    table.tr("h1").td("h1", colspan=4).h1().text("Most Lines in Owned Reviews")
    table.tr("space").td(colspan=4)

    cursor.execute("CREATE TEMPORARY TABLE owners (uid INTEGER, lines INTEGER)")
    cursor.execute("INSERT INTO owners (uid, lines) SELECT uid, SUM(deleted) + SUM(inserted) FROM reviewfiles JOIN reviewusers USING (review) JOIN reviews ON (reviewfiles.review=reviews.id) WHERE reviews.state IN ('open', 'closed') AND reviewusers.owner GROUP BY uid")

    cursor.execute("SELECT uid, lines FROM owners ORDER BY lines DESC LIMIT 10")

    self_included = False
    for user_id, lines in cursor:
        if user_id == user.id:
            row = table.tr("line self")
            self_included = True
        else:
            row = table.tr("line")

        row.td("left")
        row.td("user").text(dbutils.User.fromId(db, user_id).fullname)
        row.td("value").innerHTML("%s lines" % commas(lines))
        row.td("right")

    if not self_included:
        cursor.execute("SELECT lines FROM owners WHERE uid=%s", (user.id,))

        data = cursor.fetchone()
        if data and data[0]:
            lines = data[0]

            cursor.execute("SELECT COUNT(*) + 1 FROM owners WHERE lines > %s", (lines,))

            table.tr("space").td(colspan=4)

            row = table.tr("line self extra")
            row.td("left")
            row.td("user").text(user.fullname)
            row.td("value").innerHTML("%s lines" % commas(lines))
            row.td("right").text("(your position: %d)" % cursor.fetchone()[0])

    table.tr("space").td(colspan=4)
    table.tr("space").td(colspan=4)

    table.tr("h1").td("h1", colspan=4).h1().text("Most Issues Raised")
    table.tr("space").td(colspan=4)

    cursor.execute("""SELECT uid, COUNT(type) AS issues
                        FROM commentchains
                       WHERE state IN ('open', 'addressed', 'closed')
                         AND type='issue'
                    GROUP BY uid
                    ORDER BY issues DESC
                       LIMIT 10""")

    def calculateRatio(user_id, issues):
        cursor.execute("""SELECT lines FROM reviewers WHERE uid=%s""", (user_id,))

        row = cursor.fetchone()
        lines = row[0] if row else 0

        return float(issues * 1000) / float(lines) if lines else 0

    self_included = False
    for user_id, issues in cursor.fetchall():
        if user_id == user.id:
            row = table.tr("line self")
            self_included = True
        else:
            row = table.tr("line")

        row.td("left")
        row.td("user").text(dbutils.User.fromId(db, user_id).fullname)
        row.td("value").text("%s issues" % commas(issues))

        ratio = "%.2f" % calculateRatio(user_id, issues)

        if ratio != "0.00": row.td("right").text("(%s issues/kloc)" % ratio)
        else: row.td("right")

    if not self_included:
        cursor.execute("""SELECT COUNT(type)
                            FROM commentchains
                           WHERE state IN ('open', 'addressed', 'closed')
                             AND type='issue'
                             AND uid=%s""",
                       (user.id,))

        data = cursor.fetchone()
        if data and data[0]:
            issues = data[0]

            cursor.execute("""SELECT count(*) + 1
                                FROM (SELECT uid, COUNT(type) AS issues
                                        FROM commentchains
                                       WHERE state IN ('open', 'addressed', 'closed')
                                         AND type='issue'
                                    GROUP BY uid
                                    ORDER BY issues DESC) AS stats
                               WHERE stats.issues > %s""",
                           (issues,))

            table.tr("space").td(colspan=4)

            row = table.tr("line self extra")
            row.td("left")
            row.td("user").text(user.fullname)
            row.td("value").innerHTML("%s issues" % commas(issues))

            right = row.td("right")
            right.text("(your position: %d)" % cursor.fetchone()[0])

            ratio = "%.2f" % calculateRatio(user.id, issues)
            if ratio != "0.00": right.text(" (%s issues/kloc)" % ratio)

    table.tr("space").td(colspan=4)
    table.tr("space").td(colspan=4)

    table.tr("h1").td("h1", colspan=4).h1().text("Most Comments (and Replies) Written")
    table.tr("space").td(colspan=4)

    cursor.execute("""SELECT uid, COUNT(state) AS comments
                        FROM comments
                       WHERE state='current'
                    GROUP BY uid
                    ORDER BY comments DESC
                       LIMIT 10""")

    self_included = False
    for user_id, comments in cursor:
        if user_id == user.id:
            row = table.tr("line self")
            self_included = True
        else:
            row = table.tr("line")

        row.td("left")
        row.td("user").text(dbutils.User.fromId(db, user_id).fullname)
        row.td("value").innerHTML("%s comments" % commas(comments))
        row.td("right")

    if not self_included:
        cursor.execute("""SELECT COUNT(state)
                            FROM comments
                           WHERE state='current'
                             AND uid=%s""",
                       (user.id,))

        data = cursor.fetchone()
        if data and data[0]:
            issues = data[0]

            cursor.execute("""SELECT count(*) + 1
                                FROM (SELECT uid, COUNT(state) AS comments
                                        FROM comments
                                       WHERE state='current'
                                    GROUP BY uid
                                    ORDER BY comments DESC) AS stats
                               WHERE stats.comments > %s""",
                           (issues,))

            table.tr("space").td(colspan=4)

            row = table.tr("line self extra")
            row.td("left")
            row.td("user").text(user.fullname)
            row.td("value").innerHTML("%s comments" % commas(issues))
            row.td("right").text("(your position: %d)" % cursor.fetchone()[0])

    table.tr("space").td(colspan=4)
    table.tr("space").td(colspan=4)

    table.tr("h1").td("h1", colspan=4).h1().text("Most Characters Written")
    table.tr("space").td(colspan=4)

    cursor.execute("""SELECT uid, SUM(CHARACTER_LENGTH(comment)) AS characters
                        FROM comments
                       WHERE state='current'
                    GROUP BY uid
                    ORDER BY characters DESC
                       LIMIT 10""")

    self_included = False
    for user_id, characters in cursor:
        if user_id == user.id:
            row = table.tr("line self")
            self_included = True
        else:
            row = table.tr("line")

        row.td("left")
        row.td("user").text(dbutils.User.fromId(db, user_id).fullname)
        row.td("value").innerHTML("%s characters" % commas(characters))
        row.td("right")

    if not self_included:
        cursor.execute("""SELECT SUM(CHARACTER_LENGTH(comment))
                            FROM comments
                           WHERE state='current'
                             AND uid=%s""",
                       (user.id,))

        data = cursor.fetchone()
        if data and data[0]:
            characters = data[0]

            cursor.execute("""SELECT count(*) + 1
                                FROM (SELECT uid, SUM(CHARACTER_LENGTH(comment)) AS characters
                                        FROM comments
                                       WHERE state='current'
                                    GROUP BY uid
                                    ORDER BY characters DESC) AS stats
                               WHERE stats.characters > %s""",
                           (characters,))

            table.tr("space").td(colspan=4)

            row = table.tr("line self extra")
            row.td("left")
            row.td("user").text(user.fullname)
            row.td("value").innerHTML("%s characters" % commas(characters))
            row.td("right").text("(your position: %d)" % cursor.fetchone()[0])

    db.rollback()

    return document

########NEW FILE########
__FILENAME__ = tutorial
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2012 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import page.utils
import dbutils
import htmlutils
import configuration
import textformatting

def renderFromFile(db, user, target, name):
    lines = open("%s/tutorials/%s.txt" % (configuration.paths.INSTALL_DIR, name)).read().splitlines()

    table = target.table("paleyellow", align="center")
    textformatting.renderFormatted(db, user, table, lines, toc=True)
    table.tr("back").td("back").div().a(href="tutorial").text("Back")

def renderSections(db, user, target):
    table = target.table("paleyellow", align="center")
    table.tr("h1").td("h1").h1().text("Tutorials")

    def section(name, title, description):
        table.tr("h2").td("h2").div().h2().text(title)
        table.tr("text").td("text").div().text(description, cdata=True)
        table.tr("goto").td("goto").div().a(href="tutorial?item=%s" % name).text("Learn More")

    section("request", "Requesting a Review", """\
Introduction to the different ways of requesting a review of changes in
Critic.  You'll be able to request a review of your bug fix in 10 seconds,
using your favorite git client!  (Though it'll take you more than 10
seconds to read all the text&#8230;)""")

    section("review", "Reviewing Changes", """\
Introduction to the process of reviewing changes in Critic.  Covers the
basic concepts, marking changes as reviewed and raising issues, and some
other things.  Useful information both for reviewers and for those
requesting the reviews.""")

    section("filters", "Filters", """\
Information about the Filters mechanism.""")

    section("viewer", "Repository Viewer", """\
Some information about Critic's repository viewers and its peculiarities
compared to \"normal\" git repository viewers such as gitk and cgit.""")

    section("reconfigure", "Reconfiguring Critic", """\
Information about the various per-user configuration options that Critic
supports.""")

    section("rebase", "Rebasing Reviews", """\
Details on what kind of rebase operations are supported on review
branches, how to convince Critic to accept non-fast-forward updates, and
some things you really should make sure not to do.""")

    section("search", "Review Quick Search", """\
Information about the review search facility and the search query syntax.""")

    if configuration.extensions.ENABLED:
        section("extensions", "Critic Extensions", """\
Description of the Critic Extensions mechanism.""")

        section("extensions-api", "Critic Extensions API", """\
Description of the script API available to Critic Extensions.""")

    if user.hasRole(db, "administrator"):
        section("administration", "System Administration", """\
Information about various Critic system administration tasks.""")

        section("customization", "System Customization", """\
Information about Critic system customization hooks.""")

def renderTutorial(req, db, user):
    item = req.getParameter("item", None)

    document = htmlutils.Document(req)
    document.setBase(None)
    document.setTitle("Tutorials")

    html = document.html()
    head = html.head()
    body = html.body()

    page.utils.generateHeader(body, db, user, current_page=None if item else "tutorial")

    document.addExternalStylesheet("resource/tutorial.css")
    document.addExternalScript("resource/tutorial.js")
    document.addInternalStylesheet("div.main table td.text { %s }" % user.getPreference(db, "style.tutorialFont"))

    target = body.div("main")

    items = { "request": "requesting",
              "review": "reviewing",
              "filters": "filters",
              "viewer": "repository",
              "rebase": "rebasing",
              "reconfigure": "reconfiguring",
              "checkbranch": "checkbranch",
              "administration": "administration",
              "customization": "customization",
              "search": "search",
              "external-authentication": "external-authentication",
              "extensions": "extensions",
              "extensions-api": "extensions-api" }

    if item in items:
        renderFromFile(db, user, target, items[item])
    else:
        renderSections(db, user, target)

    return document

########NEW FILE########
__FILENAME__ = utils
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2012 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import re

import htmlutils
import configuration

from request import NoDefault, MovedTemporarily, DisplayMessage, \
                    InvalidParameterValue, decodeURIComponent, Request, \
                    NeedLogin

from textutils import json_encode, json_decode

LINK_RELS = { "Home": "home",
              "Dashboard": "contents",
              "Branches": "index",
              "Tutorial": "help",
              "Back to Review": "up" }

class NotModified:
    pass

def YesOrNo(value):
    if value == "yes": return True
    elif value == "no": return False
    else: raise DisplayMessage("invalid parameter value; expected 'yes' or 'no'")

def generateEmpty(target):
    pass

def generateHeader(target, db, user, generate_right=None, current_page=None, extra_links=[], profiler=None):
    target.addExternalStylesheet("resource/third-party/jquery-ui.css")
    target.addExternalStylesheet("resource/third-party/chosen.css")
    target.addExternalStylesheet("resource/overrides.css")
    target.addExternalStylesheet("resource/basic.css")
    target.addInternalStylesheet(".defaultfont, body { %s }" % user.getPreference(db, "style.defaultFont"))
    target.addInternalStylesheet(".sourcefont { %s }" % user.getPreference(db, "style.sourceFont"))
    target.addExternalScript("resource/third-party/jquery.js")
    target.addExternalScript("resource/third-party/jquery-ui.js")
    target.addExternalScript("resource/third-party/jquery-ui-autocomplete-html.js")
    target.addExternalScript("resource/third-party/chosen.js")
    target.addExternalScript("resource/basic.js")

    target.noscript().h1("noscript").blink().text("Please enable scripting support!")

    row = target.table("pageheader", width='100%').tr()
    left = row.td("left", valign='bottom', align='left')
    b = left.b()

    opera_class = "opera"

    if configuration.debug.IS_DEVELOPMENT:
        opera_class += " development"

    b.b(opera_class, onclick="location.href='/';").text("Opera")
    b.b("critic", onclick="location.href='/';").text("Critic")

    links = []

    if not user.isAnonymous():
        links.append(["home", "Home", None, None])

    links.append(["dashboard", "Dashboard", None, None])
    links.append(["branches", "Branches", None, None])
    links.append(["search", "Search", None, None])

    if user.hasRole(db, "administrator"):
        links.append(["services", "Services", None, None])
    if user.hasRole(db, "repositories"):
        links.append(["repositories", "Repositories", None, None])

    if profiler:
        profiler.check("generateHeader (basic)")

    if configuration.extensions.ENABLED:
        from extensions.extension import Extension

        updated = Extension.getUpdatedExtensions(db, user)

        if updated:
            link_title = "\n".join([("%s by %s can be updated!" % (extension_name, author_fullname)) for author_fullname, extension_name in updated])
            links.append(["manageextensions", "Extensions (%d)" % len(updated), "color: red", link_title])
        else:
            links.append(["manageextensions", "Extensions", None, None])

        if profiler:
            profiler.check("generateHeader (updated extensions)")

    links.append(["config", "Config", None, None])
    links.append(["tutorial", "Tutorial", None, None])

    if user.isAnonymous():
        count = 0
    else:
        cursor = db.cursor()
        cursor.execute("""SELECT COUNT(*)
                            FROM newsitems
                 LEFT OUTER JOIN newsread ON (item=id AND uid=%s)
                           WHERE uid IS NULL""",
                       (user.id,))
        count = cursor.fetchone()[0]

    if count:
        links.append(["news", "News (%d)" % count, "color: red", "There are %d unread news items!" % count])
    else:
        links.append(["news", "News", None, None])

    if profiler:
        profiler.check("generateHeader (news)")

    req = target.getRequest()

    if configuration.base.AUTHENTICATION_MODE != "host" \
           and configuration.base.SESSION_TYPE == "cookie":
        if user.isAnonymous():
            links.append(["javascript:void(location.href='/login?target='+encodeURIComponent(location.href));", "Sign in", None, None])
        elif not req or req.user == user.name:
            links.append(["javascript:signOut();", "Sign out", None, None])

    for url, label in extra_links:
        links.append([url, label, None, None])

    if req and configuration.extensions.ENABLED:
        import extensions.role.inject

        injected = {}

        extensions.role.inject.execute(db, req, user, target, links, injected, profiler=profiler)

        for url in injected.get("stylesheets", []):
            target.addExternalStylesheet(url, use_static=False, order=1)

        for url in injected.get("scripts", []):
            target.addExternalScript(url, use_static=False, order=1)
    else:
        injected = None

    ul = left.ul()

    for index, (url, label, style, title) in enumerate(links):
        if not re.match("[-.a-z]+:|/", url):
            url = "/" + url
        ul.li().a(href=url, style=style, title=title).text(label)

        rel = LINK_RELS.get(label)
        if rel: target.setLink(rel, url)

    right = row.td("right", valign='bottom', align='right')
    if generate_right:
        generate_right(right)
    else:
        right.div("buttons").span("buttonscope buttonscope-global")

    if profiler:
        profiler.check("generateHeader (finish)")

    return injected

def getParameter(req, name, default=NoDefault(), filter=lambda value: value):
    match = re.search("(?:^|&)" + name + "=([^&]*)", str(req.query))
    if match:
        try: return filter(decodeURIComponent(match.group(1)))
        except DisplayMessage: raise
        except: raise DisplayMessage("Invalid parameter value: %s=%r" % (name, match.group(1)))
    elif isinstance(default, NoDefault): raise DisplayMessage("Required parameter missing: %s" % name)
    else: return default

def renderShortcuts(target, page, **kwargs):
    shortcuts = []

    def addShortcut(keyCode, keyName, description):
        shortcuts.append((keyCode, keyName, description))

    if page == "showcommit":
        what = "files"

        merge_parents = kwargs.get("merge_parents")
        if merge_parents > 1:
            for index in range(min(9, merge_parents)):
                order = ("first", "second", "third", "fourth", "fifth", "seventh", "eight", "ninth")[index]
                addShortcut(ord('1') + index, "%d" % (index + 1), " changes relative to %s parent" % order)
    elif page == "showcomments":
        what = "comments"

    if page == "showcommit" or page == "showcomments":
        addShortcut(ord("e"), "e", "expand all %s" % what)
        addShortcut(ord("c"), "c", "collapse all %s" % what)
        addShortcut(ord("s"), "s", "show all %s" % what)
        addShortcut(ord("h"), "h", "hide all %s" % what)

        if page == "showcommit":
            addShortcut(ord("m"), "m", "detect moved code")

            if kwargs.get("squashed_diff"):
                addShortcut(ord("b"), "b", "blame")

            addShortcut(32, "SPACE", "scroll or show/expand next file")

    if page == "showcomment":
        addShortcut(ord("m"), "m", "show more context")
        addShortcut(ord("l"), "l", "show less context")

    if page == "filterchanges":
        addShortcut(ord("a"), "a", "select everything")
        addShortcut(ord("g"), "g", "go / display diff")

    container = target.div("pagefooter shortcuts")

    if shortcuts:
        container.text("Shortcuts: ")

        def renderShortcut(keyCode, ch, text, is_last=False):
            a = container.a("shortcut", href="javascript:void(handleKeyboardShortcut(%d));" % keyCode)
            a.b().text("(%s)" % ch)
            a.text(" %s" % text)
            if not is_last:
                container.text(", ")

        for index, (keyCode, keyName, description) in enumerate(shortcuts):
            renderShortcut(keyCode, keyName, description, index == len(shortcuts) - 1)

def generateFooter(target, db, user, current_page):
    renderShortcuts(target, current_page)

def displayMessage(db, req, user, title, review=None, message=None, page_title=None, is_html=False):
    document = htmlutils.Document(req)

    if page_title:
        document.setTitle(page_title)

    document.addExternalStylesheet("resource/message.css")

    html = document.html()
    head = html.head()
    body = html.body()

    if review:
        import reviewing.utils as review_utils

        def generateRight(target):
            review_utils.renderDraftItems(db, user, review, target)

        back_to_review = ("r/%d" % review.id, "Back to Review")

        generateHeader(body, db, user, generate_right=generateRight, extra_links=[back_to_review])
    else:
        generateHeader(body, db, user)

    target = body.div("message paleyellow")

    if message:
        target.h1("title").text(title)

        if callable(message): message(target)
        elif is_html: target.innerHTML(message)
        else: target.p().text(message)
    else:
        target.h1("center").text(title)

    return document

class PaleYellowTable:
    def __init__(self, target, title, columns=[10, 60, 30]):
        if not target.hasTitle():
            target.setTitle(title)

        self.table = target.div("main").table("paleyellow", align="center").tbody()
        self.columns = columns

        colgroup = self.table.colgroup()
        for column in columns: colgroup.col(width="%d%%" % column)

        h1 = self.table.tr().td("h1", colspan=len(columns)).h1()
        h1.text(title)
        self.titleRight = h1.span("right")

        self.table.tr("spacer").td(colspan=len(self.columns))

    def addSection(self, title, extra=None):
        h2 = self.table.tr().td("h2", colspan=len(self.columns)).h2()
        h2.text(title)
        if extra is not None:
            h2.span().text(extra)

    def addItem(self, heading, value, description=None, buttons=None):
        row = self.table.tr("item")
        row.td("name").innerHTML(htmlutils.htmlify(heading).replace(" ", "&nbsp;") + ":")
        cell = row.td("value", colspan=2).preformatted()
        if callable(value): value(cell)
        else: cell.text(str(value))
        if buttons:
            div = cell.div("buttons")
            for label, onclick in buttons:
                div.button(onclick=onclick).text(label)
        if description is not None:
            self.table.tr("help").td(colspan=len(self.columns)).text(description)

    def addCentered(self, content=None):
        row = self.table.tr("centered")
        cell = row.td(colspan=len(self.columns))
        if callable(content): content(cell)
        elif content: cell.text(str(content))
        return cell

    def addSeparator(self):
        self.table.tr("separator").td(colspan=len(self.columns)).div()

def generateRepositorySelect(db, user, target, allow_selecting_none=False,
                             placeholder_text=None, selected=None, **attributes):
    select = target.select("repository-select", **attributes)

    cursor = db.cursor()
    cursor.execute("""SELECT id, name, path
                        FROM repositories
                    ORDER BY name""")

    rows = cursor.fetchall()

    if not rows:
        # Note: not honoring 'placeholder_text' here; callers typically don't
        # take into account the possibility that there are no repositories.
        select.setAttribute("data-placeholder", "No repositories")
        select.option(value="", selected="selected")
        return

    if selected is None:
        selected = user.getPreference(db, "defaultRepository")

    if not selected or allow_selecting_none:
        if placeholder_text is None:
            placeholder_text = "Select a repository"
        select.setAttribute("data-placeholder", placeholder_text)
        select.option(value="", selected="selected")

    highlighted_ids = set()

    cursor.execute("""SELECT DISTINCT repository
                        FROM filters
                       WHERE uid=%s""",
                   (user.id,))
    highlighted_ids.update(repository_id for (repository_id,) in cursor)

    cursor.execute("""SELECT DISTINCT repository
                        FROM branches
                        JOIN reviews ON (reviews.branch=branches.id)
                        JOIN reviewusers ON (reviewusers.review=reviews.id)
                       WHERE reviewusers.uid=%s
                         AND reviewusers.owner""",
                   (user.id,))
    highlighted_ids.update(repository_id for (repository_id,) in cursor)

    if not highlighted_ids or len(highlighted_ids) == len(rows):
        # Do not group options when there will be only one group.
        highlighted = select
        other = select
    else:
        highlighted = select.optgroup(label="Highlighted")
        other = select.optgroup(label="Other")

    html_format = ("<span class=repository-name>%s</span>"
                   "<span class=repository-path>%s</span>")

    for repository_id, name, path in rows:
        if repository_id in highlighted_ids:
            optgroup = highlighted
        else:
            optgroup = other

        if repository_id == selected or name == selected:
            is_selected = "selected"
        else:
            is_selected = None

        html = html_format % (name, path)

        option = optgroup.option("repository flex",
                                 value=name, selected=is_selected,
                                 data_text=name, data_html=html)
        option.text(name)

########NEW FILE########
__FILENAME__ = verifyemail
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2014 the Critic contributors, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import page.utils

def renderVerifyEmail(req, db, user):
    if user.isAnonymous():
        raise page.utils.NeedLogin(req)
    elif req.user != user.name:
        raise page.utils.DisplayMessage("Invalid use!")

    email = req.getParameter("email")
    verification_token = req.getParameter("token")

    cursor = db.cursor()
    cursor.execute("""SELECT id
                        FROM useremails
                       WHERE uid=%s
                         AND email=%s
                         AND verification_token=%s""",
                   (user.id, email, verification_token))

    row = cursor.fetchone()

    if not row:
        raise page.utils.DisplayMessage("Invalid verification token!")

    email_id = row[0]

    cursor.execute("""UPDATE useremails
                         SET verified=TRUE
                       WHERE id=%s""",
                   (email_id,))

    db.commit()

    raise page.utils.MovedTemporarily("/home?email_verified=%d" % email_id)

########NEW FILE########
__FILENAME__ = profiling
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2012 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import time
import re

class Profiler:
    class Check:
        def __init__(self, profiler, title):
            self.__profiler = profiler
            self.__title = title
            self.__begin = time.time()

        def stop(self):
            self.__profiler.add(self.__title, self.__begin, time.time())

    def __init__(self):
        self.__previous = time.time()
        self.__checks = []
        self.__table = {}

    def add(self, title, begin, end):
        if title not in self.__table:
            self.__checks.append(title)
            self.__table[title] = 0

        self.__table[title] += end - begin
        self.__previous = end

    def start(self, title):
        return Profiler.Check(self, title)

    def check(self, title):
        self.add(title, self.__previous, time.time())

    def output(self, db=None, user=None, target=None):
        log = ""
        total = 0.0

        title_width = max(map(len, self.__checks))
        format = "  %%-%ds : %%8.2f\n" % title_width

        for title, duration in sorted(self.__table.items(), cmp=lambda a, b: cmp(a[1], b[1]), reverse=True):
            log += format % (title, self.__table[title] * 1000)
            total += self.__table[title]

        log += "\n" + format % ("TOTAL", total * 1000)

        if db and user and target and user.getPreference(db, 'debug.profiling.pageGeneration'):
            target.comment("\n\n" + log + "\n")

        return log

def formatDBProfiling(db):
    lines = ["         | TIME (milliseconds)    | ROWS                   |",
             "   Count | Accumulated |  Maximum | Accumulated |  Maximum | Query",
             "  -------|-------------|----------|-------------|----------|-------"]
    items = sorted(db.profiling.items(), key=lambda item: item[1][1], reverse=True)

    total_count = 0
    total_accumulated_ms = 0.0
    total_accumulated_rows = 0

    for item, (count, accumulated_ms, maximum_ms, accumulated_rows, maximum_rows) in items:
        total_count += count
        total_accumulated_ms += accumulated_ms

        if accumulated_rows is None:
            lines.append("  %6d | %11.4f | %8.4f |             |          | %s" %
                         (count, accumulated_ms, maximum_ms, re.sub(r"\s+", " ", item)))
        else:
            total_accumulated_rows += accumulated_rows

            lines.append("  %6d | %11.4f | %8.4f | %11d | %8d | %s" %
                         (count, accumulated_ms, maximum_ms, accumulated_rows, maximum_rows, re.sub(r"\s+", " ", item)))


    lines.insert(3, ("  %6d | %11.4f |          | %11d |          | TOTAL" %
                     (total_count, total_accumulated_ms, total_accumulated_rows)))

    return "\n".join(lines)

########NEW FILE########
__FILENAME__ = request
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2012 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import re
import urllib
import httplib
import wsgiref.util

import base
import configuration

# Paths to which access should be allowed without authentication even if
# anonymous users are not allowed in general.
INSECURE_PATHS = set(["login", "validatelogin",
                      "createuser", "registeruser"])

def decodeURIComponent(text):
    """\
    Replace %HH escape sequences and return the resulting string.
    """

    return urllib.unquote_plus(text)

class NoDefault:
    """\
    Placeholder class to signal that a parameter has no default value.

    An instance of this class is provided to Request.getParameter() as the
    'default' argument to signal that it is an error if the parameter is
    not present.
    """

    pass

class MovedTemporarily(Exception):
    def __init__(self, location, no_cache=False):
        self.location = location
        self.no_cache = no_cache

class NeedLogin(MovedTemporarily):
    def __init__(self, source, optional=False):
        if isinstance(source, Request):
            target = source.getTargetURL()
        else:
            target = str(source)
        location = "/login?target=%s" % urllib.quote(target)
        if optional:
            location += "&optional=yes"
        super(NeedLogin, self).__init__(location, no_cache=True)

class DoExternalAuthentication(Exception):
    def __init__(self, provider_name, target_url=None):
        self.provider_name = provider_name
        self.target_url = target_url
    def execute(self, db, req):
        import auth
        provider = auth.PROVIDERS[self.provider_name]
        if not provider.start(db, req, self.target_url):
            req.setStatus(403)
            req.start()

class DisplayMessage(base.Error):
    """\
    Utility exception raised by pages to display a simply message.
    """

    def __init__(self, title, body=None, review=None, html=False):
        self.title = title
        self.body = body
        self.review = review
        self.html = html

class InvalidParameterValue(DisplayMessage):
    """\
    Exception raised by pages when a query parameter has an invalid value.

    This exception is automatically raised by Request.getParameter() if the
    parameter's value can't be converted as requested.
    """

    def __init__(self, name, value, expected):
        DisplayMessage.__init__(self, "Invalid URI Parameter Value!", "Got '%s=%s', expected %s." % (name, value, expected))

class MissingParameter(DisplayMessage):
    """\
    Exception raised by pages when a required query parameter is missing.

    This exception is automatically raised by Request.getParameter() if the
    parameter is required and missing.
    """

    def __init__(self, name):
        DisplayMessage.__init__(self, "Missing URI Parameter!", "Expected '%s' parameter." % name)

class MissingWSGIRemoteUser(Exception):
    """\
    Exception raised if WSGI environ "REMOTE_USER" is missing.

    This error happens when Critic is running in "host" authentication mode but no
    REMOTE_USER variable was present in the WSGI environ dict provided by the
    web server.
    """
    pass

class Request:
    """\
    WSGI request wrapper class.

    Pages and operations should typically only need to access request parameters
    (via getParameter()) and headers (via getRequestHeader()), and set response
    status (using setStatus()) if not "200 OK" and content-type (using
    setContentType()) if not "text/html".  The start() method must be called
    before any content is returned to the WSGI layer, but this is taken care of
    by the main request handling function (critic.py::main).

    In the case of POST requests, the request body is retrieved using the read()
    method.

    Properties:

    user -- user name from HTTP authentication
    method -- HTTP method ("GET" or "POST", typically)
    path -- URI path component, without leading forward slash
    original_path -- same as 'path', unless the path is a short-hand for another
                     path, in which case 'path' is the resolved path
    query -- URI query component
    original_query == same as 'query', unless the path is a short-hand for
                      another path, in which case 'query' is typically extended
                      with parameters derived from the short-hand path

    Primary methods:

    getParameter(name, default, filter) -- get URI query parameter
    getRequestHeader(name) -- get HTTP request header
    getRequestHeaders(name) -- get all HTTP request headers
    read() -- read HTTP request body
    setStatus(code, message) -- set HTTP response status
    setContentType(content_type) -- set Content-Type response header
    addResponseHeader(name, value) -- add HTTP response header

    Methods used by framework code:

    start() -- call the WSGI layers start_response() callback
    isStarted() -- check if start() has been called
    getContentType() -- get response content type
    """

    def __init__(self, db, environ, start_response):
        """\
        Construct request wrapper.

        The environ and start_response arguments should be the arguments to the
        WSGI application object.
        """

        self.__environ = environ
        self.__start_response = start_response
        self.__status = None
        self.__content_type = None
        self.__response_headers = []
        self.__started = False

        self.server_name = \
            self.getRequestHeader("X-Forwarded-Host") \
            or environ.get("SERVER_NAME") \
            or configuration.base.HOSTNAME

        self.method = environ.get("REQUEST_METHOD", "")
        self.path = environ.get("PATH_INFO", "").lstrip("/")
        self.original_path = self.path
        self.query = environ.get("QUERY_STRING", "")
        self.original_query = self.query
        self.user = None
        self.cookies = {}

        header = self.getRequestHeader("Cookie")
        if header:
            for cookie in map(str.strip, header.split(";")):
                name, _, value = cookie.partition("=")
                if name and value:
                    self.cookies[name] = value

    def setUser(self, db):
        if configuration.base.AUTHENTICATION_MODE == "host":
            try:
                self.user = self.__environ["REMOTE_USER"]
            except KeyError:
                if configuration.base.ALLOW_ANONYMOUS_USER:
                    return
                raise MissingWSGIRemoteUser
        else:
            session_type = configuration.base.SESSION_TYPE

            authorization_header = self.getRequestHeader("Authorization")

            if authorization_header is not None and not self.cookies:
                session_type = "httpauth"

            if session_type == "cookie":
                sid = self.cookies.get("sid")

                if not sid:
                    return

                cursor = db.cursor()
                cursor.execute("""SELECT name, EXTRACT('epoch' FROM NOW() - atime) AS age
                                    FROM usersessions
                                    JOIN users ON (id=uid)
                                   WHERE key=%s""",
                               (sid,))

                row = cursor.fetchone()

                if not row:
                    if self.path != "validatelogin":
                        cookie = "sid=invalid; Expires=Thursday 01-Jan-1970 00:00:00 GMT"
                        self.addResponseHeader("Set-Cookie", cookie)
                    if self.path in INSECURE_PATHS:
                        return
                    raise NeedLogin(self, optional=True)

                user, session_age = row

                if configuration.base.SESSION_MAX_AGE == 0 \
                        or session_age < configuration.base.SESSION_MAX_AGE:
                    self.user = user

                    cursor.execute("""UPDATE usersessions
                                         SET atime=NOW()
                                       WHERE key=%s""",
                                   (sid,))
                    db.commit()
            else:
                import auth
                import base64

                self.user = None

                if not authorization_header: return

                authtype, base64_credentials = authorization_header.split()
                if authtype != "Basic": return

                credentials = base64.b64decode(base64_credentials).split(":")
                if len(credentials) < 2: return

                for index in range(1, len(credentials)):
                    username = ":".join(credentials[:index])
                    password = ":".join(credentials[index:])
                    try:
                        auth.checkPassword(db, username, password)
                        self.user = username
                        return
                    except auth.CheckFailed: pass

    def getTargetURL(self):
        target = "/" + self.path
        if self.query:
            target += "?" + self.query
        return target

    def getRequestURI(self):
        return wsgiref.util.request_uri(self.__environ)

    def getEnvironment(self):
        return self.__environ

    def getUser(self, db):
        import dbutils
        return dbutils.User.fromName(db, self.user)

    def getParameter(self, name, default=NoDefault(), filter=lambda value: value):
        """\
        Get URI query parameter.

        If the requested parameter was not present in the URI query component,
        the supplied default value is returned instead, or, if the supplied
        default value is an instance of the NoDefault class, a MissingParameter
        exception is raised.

        If a filter function is supplied, it is called with a single argument,
        the string value of the URI parameter, and its return value is returned
        from getParameter().  If the filter function raises an exception (other
        than DisplayMessage or sub-classes thereof) an InvalidParameterValue
        exception is raised.  Note: the filter function is not applied to
        default values, meaning that the default value can be of a different
        type than actual parameter values.
        """

        match = re.search("(?:^|&)" + name + "=([^&]*)", str(self.query))
        if match:
            try: return filter(decodeURIComponent(match.group(1)))
            except base.Error: raise
            except:
                if filter is int: expected = "integer"
                else: expected = "something else"
                raise InvalidParameterValue(name, match.group(1), expected)
        elif isinstance(default, NoDefault): raise MissingParameter(name)
        else: return default

    def getRequestHeader(self, name, default=None):
        """\
        Get HTTP request header by name.

        The name is case-insensitive.  If the request header was not present in
        the request, the default value is returned (or None if no default value
        is provided.)  If the request header was present, its value is returned
        as a string.
        """

        return self.__environ.get("HTTP_" + name.upper().replace("-", "_"), default)

    def getRequestHeaders(self):
        """\
        Get a dictionary containing all HTTP request headers.

        The header names are converted to all lower-case, and any underscores
        ('_') in the header name is replaced with a dash ('-').  The reason for
        this name transformation is that the header names are already
        transformed in the WSGI layer from their original form to all
        upper-case, with dashes replaced by underscores, so the original name is
        not available.

        The returned dictionary is a copy of the underlying storage, so the
        caller can modify it without the modifications having any side-effects.
        """

        headers = {}
        for name, value in self.__environ.items():
            if name.startswith("HTTP_"):
                headers[name[5:].lower().replace("_", "-")] = value
        return headers

    def getReferrer(self):
        try: return self.getRequestHeader("Referer")
        except: return "N/A"

    def read(self, *args):
        """\
        Return the HTTP request body, or an empty string if there is none.
        """

        if "wsgi.input" not in self.__environ: return ""
        return self.__environ["wsgi.input"].read(*args)

    def write(self, data):
        """
        Write HTTP response body chunk.
        """

        self.__write(data)

    def setStatus(self, code, message=None):
        """\
        Set the HTTP status code, and optionally the status message.

        If the message argument is None, a default status message for the
        specified HTTP status code is used.  If the specified status code is not
        one included in httplib.responses, an KeyError exception is raised.

        If this method is not called, the HTTP status will be "200 OK".

        This method must be called before the response is started.  (This really
        only matters for incremental pages that returns the response body in
        chunks; they can't call this method once they've yielded the first body
        chunk.)
        """

        assert not self.__started, "Response already started!"
        if message is None: message = httplib.responses[code]
        self.__status = "%d %s" % (code, message)

    def hasContentType(self):
        return self.__content_type is not None

    def setContentType(self, content_type):
        """\
        Set the response content type (the "Content-Type" header).

        If the specified content type doesn't have a "charset=X" addition, the
        string "; charset=utf-8" is appended to the content type.

        If this method is not called, the Content-Type header's value will be
        "text/html; charset=utf-8".

        This function must be used rather than addResponseHeader() to set the
        Content-Type header, and must be called before the response is started.
        """

        assert not self.__started, "Response already started!"
        if content_type.startswith("text/") and "charset=" not in content_type: content_type += "; charset=utf-8"
        self.__content_type = content_type

    def addResponseHeader(self, name, value):
        """\
        Add HTTP response header.

        Append a response header to the list of response headers passed to the
        WSGI start_response() callback when the response is started.

        Note: This function does not replace existing headers or merge headers
        with the same name; calling code has to handle such things.  No headers
        (except Content-Type) are added automatically.

        This function must not be used to add a Content-Type header, and must be
        called before the response is started.
        """

        assert not self.__started, "Response already started!"
        assert name.lower() != "content-type", "Use Request.setContentType() instead!"
        self.__response_headers.append((name, value))

    def setCookie(self, name, value, secure=False):
        if secure and configuration.base.ACCESS_SCHEME != "http":
            modifier = "Secure"
        else:
            modifier = "HttpOnly"
        self.addResponseHeader(
            "Set-Cookie",
            "%s=%s; Max-Age=31536000; Path=/; %s" % (name, value, modifier))

    def deleteCookie(self, name):
        self.addResponseHeader(
            "Set-Cookie",
            "%s=invalid; Path=/; Expires=Thursday 01-Jan-1970 00:00:00 GMT" % name)

    def start(self):
        """\
        Start the response by calling the WSGI start_response() callback.

        This function is called automatically by the main request handling
        function (critic.py::main) and should typically not be called from any
        other code.

        This function can be called multiple times; repeated calls do nothing.
        """

        if not self.__started:
            if self.__status is None:
                self.setStatus(200)
            if self.__content_type is None:
                self.setContentType("text/plain")

            headers = [("Content-Type", self.__content_type)]
            headers.extend(self.__response_headers)

            self.__write = self.__start_response(self.__status, headers)
            self.__started = True

    def isStarted(self):
        """\
        Check if the response has been started.
        """

        return self.__started

    def getContentType(self):
        """\
        Return the currently set response content type.

        The returned value includes the automatically added "charset=utf-8".  If
        the response hasn't been started yet, and setContentType() hasn't been
        called, None is returned.
        """

        return self.__content_type

    def ensureSecure(self):
        if configuration.base.ACCESS_SCHEME != "http":
            current_url = self.getRequestURI()
            secure_url = re.sub("^http:", "https:", current_url)

            if current_url != secure_url:
                raise MovedTemporarily(secure_url, True)

    def requestHTTPAuthentication(self, realm="Critic"):
        self.setStatus(401)
        self.addResponseHeader("WWW-Authenticate", "Basic realm=\"%s\"" % realm)
        self.start()

########NEW FILE########
__FILENAME__ = propagate
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2012 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import dbutils
import diff

from changeset.utils import createChangeset

FORWARD  = 1
BACKWARD = 2

class Location:
    def __init__(self, first_line, last_line, active=True):
        self.first_line = first_line
        self.last_line = last_line
        self.active = active

    def copy(self):
        return Location(self.first_line, self.last_line, self.active)

    def __iadd__(self, delta):
        self.first_line += delta
        self.last_line += delta
        return self

    def __len__(self):
        return 2

    def __getitem__(self, index):
        if index == 0: return self.first_line
        elif index == 1: return self.last_line
        else: raise IndexError

    def __eq__(self, other):
        return tuple(self) == tuple(other)

    def apply(self, changes, direction):
        """
        Apply a set of changes and adjust the location accordingly.

        Process a set of changes in the form of a list of objects with the
        attributes delete_offset, delete_count, insert_offset and insert_count
        (such as diff.Chunk objects) sorted on ascending offsets.  If any of the
        changes overlap this location, the location's 'active' attribute is set
        to False, otherwise the 'first_line' and 'last_line' attributes are
        adjusted to keep the location referencing the same lines.

        If the 'direction' argument is FORWARD, this location is interpreted as
        a location in the old version (before the changes) and is adjusted to a
        location in the new version (after the changes.)  If the argument is
        BACKWARD, this location is interpreted as a location in the new version
        (after the changes) and is adjusted to a location in the old version
        (before the changes.)

        Returns True if the location is still active.
        """

        delta = 0

        # The only difference between the two loops is that uses of
        # delete_offset/delete_count and insert_offset/insert_count are
        # mirrored.
        if direction == FORWARD:
            for change in changes:
                if change.delete_offset + change.delete_count <= self.first_line:
                    # Change is before (and does not overlap) the location.
                    delta += change.insert_count - change.delete_count
                elif change.delete_offset <= self.last_line:
                    # Change overlaps the location.
                    self.active = False
                    break
                else:
                    # Change is after the location, meaning, since changes come
                    # in ascending offset order, that all other changes are also
                    # after the location.
                    break
        else:
            for change in changes:
                if change.insert_offset + change.insert_count <= self.first_line:
                    # Change is before (and does not overlap) the location.
                    delta += change.delete_count - change.insert_count
                elif change.insert_offset <= self.last_line:
                    # Change overlaps the comment chain.
                    self.active = False
                    break
                else:
                    # Change is after the location, meaning, since changes come
                    # in ascending offset order, that all other changes are also
                    # after the location.
                    break

        # Apply 'delta' to the location if it's still active.
        if self.active: self += delta

        return self.active

class AddressedBy(object):
    def __init__(self, parent, child, location):
        self.parent = parent
        self.child = child
        self.location = location

class Propagation:
    def __init__(self, db):
        self.db = db
        self.review = None
        self.head = None
        self.rebases = None
        self.initial_commit = None
        self.file_path = None
        self.file_id = None
        self.location = None
        self.active = None
        self.all_lines = None
        self.new_lines = None

    def setCustom(self, review, commit, file_id, first_line, last_line):
        """
        Initialize for propagation of a custom location.

        This mode of operation is used to propagate a new comment chain to all
        relevant commits current part of the review.

        Returns false if the creating a comment at the specified location is not
        supported, typically because the commit is not being reviewed in the
        review.
        """

        assert first_line > 0
        assert last_line >= first_line

        if not review.containsCommit(self.db, commit, True):
            return False

        self.review = review
        self.rebases = review.getReviewRebases(self.db)
        self.initial_commit = commit
        self.addressed_by = []
        self.file_path = dbutils.describe_file(self.db, file_id)
        self.file_id = file_id
        self.location = Location(first_line, last_line)
        self.active = True

        file_entry = commit.getFileEntry(self.file_path)

        if file_entry is None:
            # File doesn't exist (in the given commit.)
            return False

        diff_file = diff.File(new_sha1=file_entry.sha1,
                              new_mode=file_entry.mode,
                              repository=review.repository)
        diff_file.loadNewLines()

        if last_line > diff_file.newCount():
            # Range of lines is out of bounds.
            return False

        self.all_lines = { file_entry.sha1: (first_line, last_line) }
        self.new_lines = { file_entry.sha1: (first_line, last_line) }

        return True

    def setExisting(self, review, chain_id, commit, file_id, first_line, last_line, reopening=False):
        """
        Initialize for propagation of existing comment chain.

        This initializes the location to where the comment chain is located in
        the most recent commit in the review.  If the comment chain is not
        present in the most recent commit in the review, this function returns
        False.

        This mode of operation is used to update existing comment chains when
        adding new commits to a review.
        """

        self.review = review
        self.rebases = review.getReviewRebases(self.db)
        self.initial_commit = commit
        self.addressed_by = []
        self.file_path = dbutils.describe_file(self.db, file_id)
        self.file_id = file_id
        self.location = Location(first_line, last_line)
        self.active = True
        self.all_lines = {}
        self.new_lines = {}

        cursor = self.db.cursor()
        cursor.execute("""SELECT sha1, first_line, last_line
                            FROM commentchainlines
                           WHERE chain=%s""",
                       (chain_id,))

        for file_sha1, first_line, last_line in cursor:
            self.all_lines[file_sha1] = (first_line, last_line)

        if reopening:
            self.__setLines(commit.getFileSHA1(self.file_path), self.location)

        return True

    def calculateInitialLines(self):
        """
        Calculate the initial set of line mappings for a comment chain.

        Propagates the initial location both backward and forward through all
        current commits in the review.  If, through forward propagation, the
        location becomes inactive, the 'active' attribute is set to False.  In
        any case, the 'lines' attribute will map each file SHA-1 to a pair of
        line numbers (first_line, last_line) for each location found during the
        propagation.

        Returns the value of the 'active' attribute.
        """

        self.review.branch.loadCommits(self.db)
        self.head = self.review.branch.head

        self.__propagate(self.review.getCommitSet(self.db))
        return self.active

    def calculateAdditionalLines(self, commits, head):
        """
        Calculate additional set of line mappings when adding new commits.

        If this propagation object is not active (because the comment chain
        it represents is not present in the most recent commit in the review)
        then nothing happens.

        Returns the value of the 'active' attribute.
        """

        self.head = head

        self.__propagate(commits)
        return self.active

    def __propagate(self, commits):
        cursor = self.db.cursor()

        def propagateBackward(commit, location, processed):
            parents = commits.getParents(commit)
            recurse = []

            if not parents:
                rebase = self.rebases.fromNewHead(commit)
                if rebase:
                    parents.add(rebase.old_head)
                else:
                    for parent_sha1 in commit.parents:
                        rebase = self.rebases.fromNewHead(parent_sha1)
                        if rebase:
                            parents.add(rebase.old_head)

            for parent in parents - processed:
                changes = self.__getChanges(parent, commit)
                if changes:
                    parent_location = location.copy()
                    if parent_location.apply(changes, BACKWARD):
                        file_sha1 = parent.getFileSHA1(self.file_path)
                        assert file_sha1
                        self.__setLines(file_sha1, parent_location)
                        recurse.append((parent, parent_location))
                else:
                    recurse.append((parent, location))

            processed.add(commit)

            for parent, parent_location in recurse:
                propagateBackward(parent, parent_location, processed)

        def propagateForward(commit, location, processed):
            if commit == self.head:
                self.active = True

            children = commits.getChildren(commit)
            recurse = []

            if not children:
                rebase = self.rebases.fromOldHead(commit)
                if rebase:
                    children.update([rebase.new_head])

            if not children:
                assert not commits or commit in commits.getHeads() or self.rebases.fromNewHead(commit)

            for child in children - processed:
                changes = self.__getChanges(commit, child)
                if changes:
                    child_location = location.copy()
                    if child_location.apply(changes, FORWARD):
                        file_sha1 = child.getFileSHA1(self.file_path)
                        assert file_sha1
                        self.__setLines(file_sha1, child_location)
                        recurse.append((child, child_location))
                    else:
                        self.addressed_by.append(AddressedBy(commit, child, location))
                else:
                    recurse.append((child, location))

            processed.add(commit)

            for child, child_location in recurse:
                propagateForward(child, child_location, processed)

            # If we started propagation in the middle of, or at the end of, the
            # commit-set, this call does the main backward propagation.  After
            # that, it will do extra backward propagation via other parents of
            # merge commits encountered during forward propagation.
            #
            # For non-merge commits, 'processed' will always contain the single
            # parent of 'commit', and propagateBackward() will find no parent
            # commits to process, leaving this call a no-op.
            propagateBackward(commit, location, processed)

        # Will be set to True again if propagation reaches the head of the
        # commit-set.
        self.active = False

        propagateForward(self.initial_commit, self.location, set())

    def __getChanges(self, from_commit, to_commit):
        changesets = createChangeset(self.db,
                                     user=None,
                                     repository=self.review.repository,
                                     from_commit=from_commit,
                                     to_commit=to_commit,
                                     filtered_file_ids=set([self.file_id]),
                                     do_highlight=False)

        assert len(changesets) == 1

        if changesets[0].files:
            assert changesets[0].files[0].id == self.file_id
            return changesets[0].files[0].chunks
        else:
            return None

    def __setLines(self, file_sha1, lines):
        if file_sha1 not in self.all_lines:
            self.all_lines[file_sha1] = self.new_lines[file_sha1] = tuple(lines)
        else:
            assert self.all_lines[file_sha1] == tuple(lines)

########NEW FILE########
__FILENAME__ = filters
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2012 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import dbutils
import time
import re

class PatternError(Exception):
    def __init__(self, pattern, message):
        self.pattern = pattern
        self.message = message

    def __str__(self):
        return "%s: %s" % (self.pattern, self.message)

def sanitizePath(path):
    return re.sub("//+", "/", path.strip().lstrip("/")) or "/"

def validatePattern(pattern):
    if re.search(r"[^/]\*\*", pattern):
        raise PatternError(pattern, "** not at beginning of path or path component")
    elif re.search(r"\*\*$", pattern):
        raise PatternError(pattern, "** at end of path")
    elif re.search(r"\*\*[^/]", pattern):
        raise PatternError(pattern, "** not at end of path component")

def validPattern(pattern):
    try:
        validatePattern(pattern)
        return True
    except PatternError:
        return False

def compilePattern(pattern):
    wildcards = { "**/": "(?:[^/]+/)*",
                  "**": "(?:[^/]+(?:/|$))*",
                  "*": "[^/]*",
                  "?": "[^/]" }

    def escape(match):
        return "\\" + match.group(0)

    def replacement(match):
        return wildcards[match.group(0)]

    pattern = re.sub(r"[[{()+^$.\\|]", escape, pattern)

    return re.compile("^" + re.sub("\\*\\*(?:/|$)|\\*|\\?", replacement, pattern) + "$")

def hasWildcard(string):
    return "*" in string or "?" in string

class Path(object):
    def __init__(self, path):
        path = path.lstrip("/")

        self.path = path

        if hasWildcard(path):
            validatePattern(path)

        if path.endswith("/"):
            self.regexp = compilePattern(path + "**/*")
        else:
            self.regexp = compilePattern(path)

        if not path:
            self.dirname, self.filename = "", None
        elif "/" in path:
            self.dirname, self.filename = path.rsplit("/", 1)
            if not self.filename:
                self.filename = None
        else:
            self.dirname, self.filename = "", path

        if hasWildcard(self.dirname):
            components = self.dirname.split("/")
            for index, component in enumerate(components):
                if hasWildcard(component):
                    self.fixedDirname = "/".join(components[:index])
                    self.wildDirname = "/".join(components[index:])
                    self.wildDirnameRegExp = compilePattern(self.wildDirname)
                    break
        else:
            self.fixedDirname = self.dirname
            self.wildDirname = None

        if self.filename and hasWildcard(self.filename):
            self.filenameRegExp = compilePattern(self.filename)
        else:
            self.filenameRegExp = None

    def __repr__(self):
        return "Path(%r)" % self.path

    def match(self, path):
        return bool(self.regexp.match(path))

    @staticmethod
    def cmp(pathA, pathB):
        # Filters that select individual files rank above filters that
        # select directories (even if the actual name of the file contains
        # wildcards.)
        if pathA.endswith("/") and not pathB.endswith("/"):
            return -1
        elif not pathA.endswith("/") and pathB.endswith("/"):
            return 1

        # Filters with more slashes in them rank higher than filters with fewer
        # slashes (but "**/" doesn't count as a slash, since it might match zero
        # slashes in practice.)
        specificityA = pathA.count("/") - len(re.findall(r"\*\*/", pathA))
        specificityB = pathB.count("/") - len(re.findall(r"\*\*/", pathB))
        if specificityA < specificityB:
            return -1
        elif specificityA > specificityB:
            return 1

        # Filters with fewer wildcards in them rank higher than filters with
        # more wildcards.
        wildcardsA = len(re.findall("\\*\\*|\\*|\\?", pathA))
        wildcardsB = len(re.findall("\\*\\*|\\*|\\?", pathB))
        if wildcardsA < wildcardsB:
            return 1
        elif wildcardsA > wildcardsB:
            return -1

        # Fall back to lexicographical ordering.  The filters probably won't
        # match the same files anyway, and if they do, well, at least this
        # way it's stable and predictable.
        return cmp(pathA, pathB)

class Filters:
    def __init__(self):
        # Pseudo-types:
        #   data: dict(user_id -> tuple(filter_type, delegate))
        #   file: tuple(file_id, data)
        #   tree: tuple(dict(dirname -> tree), dict(filename -> file))

        self.files = {}          # dict(path -> file)
        self.directories = {}    # dict(dirname -> tree)
        self.root = ({}, {})     # tree
        self.data = {}           # dict(file_id -> data)
        self.active_filters = {} # dict(user_id -> set(filter_id))

        # Note: The same per-file 'data' objects are referenced by all of
        # 'self.files', 'self.tree' and 'self.data'.

        self.directories[""] = self.root

    def setFiles(self, db, file_ids=None, review=None):
        assert (file_ids is None) != (review is None)

        cursor = db.cursor()

        if file_ids is None:
            cursor.execute("SELECT DISTINCT file FROM reviewfiles WHERE review=%s", (review.id,))
            file_ids = [file_id for (file_id,) in cursor]

        cursor.execute("SELECT id, path FROM files WHERE id=ANY (%s)", (file_ids,))

        for file_id, path in cursor:
            data = {}

            self.files[path] = (file_id, data)
            self.data[file_id] = data

            if "/" in path:
                dirname, filename = path.rsplit("/", 1)

                def find_tree(dirname):
                    tree = self.directories.get(dirname)
                    if tree:
                        return tree
                    tree = self.directories[dirname] = ({}, {})
                    if "/" in dirname:
                        dirname, basename = dirname.rsplit("/", 1)
                        find_tree(dirname)[0][basename] = tree
                    else:
                        self.root[0][dirname] = tree
                    return tree

                tree = find_tree(dirname)
            else:
                filename = path
                tree = self.root

            tree[1][filename] = self.files[path]

    def addFilter(self, user_id, path, filter_type, delegate, filter_id):
        def files_in_tree(components, tree):
            for dirname, child_tree in tree[0].items():
                for f in files_in_tree(components + [dirname], child_tree):
                    yield f
            dirname = "/".join(components) + "/" if components else ""
            for filename, (_, data) in tree[1].items():
                yield dirname, filename, data

        if not path:
            dirname, filename = "", None
            components = []
        elif "/" in path:
            dirname, filename = path.rsplit("/", 1)
            if not dirname:
                dirname = ""
                components = []
            else:
                components = dirname.split("/")
            if not filename:
                filename = None
        else:
            dirname, filename = "", path
            components = []

        def hasWildcard(string):
            return "*" in string or "?" in string

        if hasWildcard(path):
            tree = self.root
            files = []

            for index, component in enumerate(components):
                if hasWildcard(component):
                    wild_dirname = "/".join(components[index:]) + "/"
                    break
                else:
                    tree = tree[0].get(component)
                    if not tree:
                        return
            else:
                wild_dirname = None

            re_filename = compilePattern(filename or "*")

            if wild_dirname:
                re_dirname = compilePattern(wild_dirname)

                for dirname, filename, data in files_in_tree([], tree):
                    if re_dirname.match(dirname) and re_filename.match(filename):
                        files.append(data)
            else:
                for filename, (_, data) in tree[1].items():
                    if re_filename.match(filename):
                        files.append(data)
        else:
            if filename:
                if path in self.files:
                    files = [self.files[path][1]]
                else:
                    return
            else:
                if dirname in self.directories:
                    files = [data for _, _, data in files_in_tree([dirname], self.directories[dirname])]
                else:
                    return

        if filter_type == "ignored":
            for data in files:
                if user_id in data:
                    del data[user_id]
        else:
            if files:
                self.active_filters.setdefault(user_id, set()).add(filter_id)
                for data in files:
                    data[user_id] = (filter_type, delegate)

    def addFilters(self, filters):
        def compareFilters(filterA, filterB):
            return Path.cmp(filterA[1], filterB[1])

        def add_filter_id(filter_data):
            if len(filter_data) == 4:
                return tuple(filter_data) + (None,)
            return filter_data

        sorted_filters = sorted(map(add_filter_id, filters), cmp=compareFilters)

        for user_id, path, filter_type, delegate, filter_id in sorted_filters:
            self.addFilter(user_id, path, filter_type, delegate, filter_id)

    class Review:
        def __init__(self, review_id, applyfilters, applyparentfilters, repository):
            self.id = review_id
            self.applyfilters = applyfilters
            self.applyparentfilters = applyparentfilters
            self.repository = repository

    def load(self, db, repository=None, review=None, recursive=False, user=None,
             added_review_filters=[], removed_review_filters=[]):
        assert (repository is None) != (review is None)

        cursor = db.cursor()

        if user is not None: user_filter = " AND uid=%d" % user.id
        else: user_filter = ""

        def loadGlobal(repository, recursive):
            if recursive and repository.parent:
                loadGlobal(repository.parent, recursive)

            cursor.execute("""SELECT filters.uid, filters.path, filters.type, filters.delegate, filters.id
                                FROM filters
                                JOIN users ON (users.id=filters.uid)
                               WHERE filters.repository=%%s
                                 AND users.status!='retired'
                                     %s""" % user_filter,
                           (repository.id,))
            self.addFilters(cursor)

        def loadReview(review):
            cursor.execute("""SELECT reviewfilters.uid, reviewfilters.path, reviewfilters.type, NULL
                                FROM reviewfilters
                                JOIN users ON (users.id=reviewfilters.uid)
                               WHERE reviewfilters.review=%%s
                                 AND users.status!='retired'
                                     %s""" % user_filter,
                           (review.id,))
            if added_review_filters or removed_review_filters:
                review_filters = set(cursor.fetchall())
                review_filters -= set(map(tuple, removed_review_filters))
                review_filters |= set(map(tuple, added_review_filters))
                self.addFilters(list(review_filters))
            else:
                self.addFilters(cursor)

        if review:
            if review.applyfilters:
                loadGlobal(review.repository, review.applyparentfilters)
            loadReview(review)
        else:
            loadGlobal(repository, recursive)

    def getUserFileAssociation(self, user_id, file_id):
        user_id = int(user_id)
        file_id = int(file_id)

        data = self.data.get(file_id)
        if not data:
            return None

        data = data.get(user_id)
        if not data:
            return None

        return data[0]

    def isReviewer(self, user_id, file_id):
        return self.getUserFileAssociation(user_id, file_id) == 'reviewer'

    def isWatcher(self, user_id, file_id):
        return self.getUserFileAssociation(user_id, file_id) == 'watcher'

    def isRelevant(self, user_id, file_id):
        return self.getUserFileAssociation(user_id, file_id) in ('reviewer', 'watcher')

    def listUsers(self, file_id):
        return self.data.get(file_id, {})

    def getRelevantFiles(self):
        relevant = {}

        for file_id, data in self.data.items():
            for user_id, (filter_type, _) in data.items():
                if filter_type in ('reviewer', 'watcher'):
                    relevant.setdefault(user_id, set()).add(file_id)

        return relevant

    def getActiveFilters(self, user):
        return self.active_filters.get(user.id, set())

def getMatchedFiles(repository, paths):
    paths = [Path(path) for path in sorted(paths, cmp=Path.cmp, reverse=True)]

    common_fixedDirname = None
    for path in paths:
        if path.fixedDirname is None:
            common_fixedDirname = []
            break
        elif common_fixedDirname is None:
            common_fixedDirname = path.fixedDirname.split("/")
        else:
            for index, component in enumerate(path.fixedDirname.split("/")):
                if index == len(common_fixedDirname):
                    break
                elif common_fixedDirname[index] != component:
                    del common_fixedDirname[index:]
                    break
            else:
                del common_fixedDirname[index:]
    common_fixedDirname = "/".join(common_fixedDirname)

    args = ["ls-tree", "-r", "--name-only", "HEAD"]

    if common_fixedDirname:
        args.append(common_fixedDirname + "/")

    matched = dict((path.path, []) for path in paths)

    if repository.isEmpty():
        return matched

    filenames = repository.run(*args).splitlines()

    if len(paths) == 1 and not paths[0].wildDirname and not paths[0].filename:
        return { paths[0].path: filenames }

    for filename in filenames:
        for path in paths:
            if path.match(filename):
                matched[path.path].append(filename)
                break

    return matched

def countMatchedFiles(repository, paths):
    matched = getMatchedFiles(repository, paths)
    return dict((path, len(filenames)) for path, filenames in matched.items())

########NEW FILE########
__FILENAME__ = html
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2012 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import htmlutils
import gitutils
import dbutils
import log.html
import diff
import diff.context
import changeset.html as changeset_html
import changeset.utils as changeset_utils
import page.utils
import page.showcommit
import linkify

def renderComments(db, target, user, chain, position, linkify):
    repository = chain.review.repository

    div_chain = target.div("comments %s" % position)

    for comment in chain.comments:
        div_comment = div_chain.div("comment%s" % (comment.state == "draft" and " draft" or ""), id="c%dc%d" % (chain.id, comment.id))

        div_header = div_comment.div("header")
        div_header.span("author").text("%s <%s>" % (comment.user.fullname, comment.user.email))
        div_header.text(" posted ")
        div_header.span("time").text(comment.when)

        div_text = div_comment.div("text", id="c%dtext" % comment.id).preformatted()
        div_text.text(comment.comment, linkify=linkify, repository=repository)

    if chain.type == "issue" and chain.state not in ("draft", "open"):
        div_resolution = div_chain.div("resolution")

        if chain.state == "addressed":
            div_resolution.text("Addressed by ").a(href="showcommit?review=%d&sha1=%s" % (chain.review.id, chain.addressed_by.sha1)).text(chain.addressed_by.sha1[:8])

            if chain.closed_by:
                div_resolution.text(" (by %s)" % chain.closed_by.fullname)
        else:
            div_resolution.text("Resolved by " + chain.closed_by.fullname)

    div_buttons = div_chain.div("buttons")

    if (chain.state == "closed" or chain.addressed_by) and chain.type == "issue":
        div_buttons.button("reopen", onclick="commentChainById[%d].reopen(true);" % chain.id).text("Reopen Issue")

    if chain.type == "issue":
        if chain.state == "open":
            if not chain.type_is_draft:
                div_buttons.button("resolve", onclick="commentChainById[%d].resolve(null);" % chain.id).text("Resolve Issue")
        if chain.type_is_draft or user.getPreference(db, "ui.convertIssueToNote"):
            div_buttons.button("morph", onclick="commentChainById[%d].morph(null, this);" % chain.id).text("Convert %sto Note" % ("back " if chain.type_is_draft else ""))
    else:
        div_buttons.button("morph", onclick="commentChainById[%d].morph(null, this);" % chain.id).text("Convert %sto Issue" % ("back " if chain.type_is_draft else ""))

    if chain.comments[-1].state == "draft":
        div_buttons.button("edit", onclick="commentChainById[%d].editComment(commentChainById[%d].comments[%d], null);" % (chain.id, chain.id, len(chain.comments) - 1)).text("Edit")
        div_buttons.button("delete", onclick="commentChainById[%d].deleteComment(commentChainById[%d].comments[%d], null);" % (chain.id, chain.id, len(chain.comments) - 1)).text("Delete")
        reply_hidden = " hidden"
    else:
        reply_hidden = ""

    div_buttons.button("reply" + reply_hidden, onclick="commentChainById[%d].reply(null);" % chain.id).text("Reply")

    div_buttons.span("buttonscope buttonscope-comment")

def getCodeCommentChainChangeset(db, chain, original=False):
    if (chain.state != "addressed" or original) and chain.first_commit == chain.last_commit:
        # Comment against a single version of the file, not against a diff.
        return None, None
    elif chain.state == "addressed" and not original:
        parent = gitutils.Commit.fromSHA1(db, chain.review.repository, chain.addressed_by.parents[0])
        child = chain.addressed_by
    else:
        parent = chain.first_commit
        child = chain.last_commit

    return parent, child

def renderCodeCommentChain(db, target, user, review, chain, context_lines=3, compact=False, tabify=False, original=False, changeset=None, linkify=False):
    repository = review.repository

    old_sha1 = None
    new_sha1 = None

    old = 1
    new = 2

    cursor = db.cursor()

    file_id = chain.file_id
    file_path = dbutils.describe_file(db, file_id)

    if (chain.state != "addressed" or original) and chain.first_commit == chain.last_commit:
        sha1 = chain.first_commit.getFileSHA1(file_path)

        cursor.execute("SELECT first_line, last_line FROM commentchainlines WHERE chain=%s AND sha1=%s", (chain.id, sha1))
        first_line, last_line = cursor.fetchone()

        file = diff.File(file_id, file_path, sha1, sha1, review.repository, chunks=[])
        file.loadNewLines(True)

        start = max(1, first_line - context_lines)
        end = min(file.newCount(), last_line + context_lines)
        count = end + 1 - start

        lines = file.newLines(True)
        lines = [diff.Line(diff.Line.CONTEXT, start + index, lines[start + index - 1], start + index, lines[start + index - 1]) for index in range(count)]

        file.macro_chunks = [diff.MacroChunk([], lines)]

        use = new
        display_type = "new"
        commit_url_component = "sha1=%s" % chain.first_commit.sha1
    else:
        if chain.state == "addressed" and not original and review.containsCommit(db, chain.addressed_by):
            parent = gitutils.Commit.fromSHA1(db, review.repository, chain.addressed_by.parents[0])
            child = chain.addressed_by
            use = old
        else:
            parent = chain.first_commit
            child = chain.last_commit

            if parent == child:
                if chain.origin == "old":
                    cursor.execute("""SELECT changesets.child
                                        FROM changesets, reviewchangesets
                                       WHERE changesets.parent=%s
                                         AND reviewchangesets.changeset=changesets.id
                                         AND reviewchangesets.review=%s""",
                                   [child.getId(db), review.id])

                    try:
                        child = gitutils.Commit.fromId(db, repository, cursor.fetchone()[0])
                    except:
                        parent = gitutils.Commit.fromSHA1(db, repository, child.parents[0])
                else:
                    parent = gitutils.Commit.fromSHA1(db, repository, child.parents[0])

            if chain.origin == "old": use = old
            else: use = new

        if parent.sha1 in child.parents and len(child.parents) == 1:
            commit = child
            from_commit = None
            to_commit = None
        else:
            commit = None
            from_commit = parent
            to_commit = child

        if changeset:
            assert ((changeset.parent == from_commit and changeset.child == to_commit)
                    if commit is None else
                    (changeset.parent.sha1 == commit.parents[0] and changeset.child == commit))
            assert changeset.getFile(file_id)
        else:
            changeset = changeset_utils.createChangeset(db, user, repository, commit=commit, from_commit=from_commit, to_commit=to_commit, filtered_file_ids=set((file_id,)))[0]

        file = changeset.getFile(file_id)

        if not file:
            if chain.state == "addressed" and not original:
                renderCodeCommentChain(db, target, user, review, chain, context_lines, compact, tabify, original=True)
                return
            else:
                raise

        # Commit so that the diff and its analysis, written to the database by createChangeset(),
        # can be reused later.
        db.commit()

        old_sha1 = file.old_sha1
        new_sha1 = file.new_sha1

        if use == old and old_sha1 == '0' * 40: use = new
        elif use == new and new_sha1 == '0' * 40: use = old

        if use == old: sha1 = old_sha1
        else: sha1 = new_sha1

        cursor.execute("SELECT first_line, last_line FROM commentchainlines WHERE chain=%s AND sha1=%s", [chain.id, sha1])

        first_line, last_line = cursor.fetchone()

        def readChunks():
            return [diff.Chunk(delete_offset, delete_count, insert_offset, insert_count, analysis=analysis, is_whitespace=is_whitespace)
                    for delete_offset, delete_count, insert_offset, insert_count, analysis, is_whitespace
                    in cursor.fetchall()]

        first_context_line = first_line - context_lines
        last_context_line = last_line + context_lines

        def includeChunk(chunk):
            if use == old: chunk_first_line, chunk_last_line = chunk.delete_offset, chunk.delete_offset + chunk.delete_count - 1
            else: chunk_first_line, chunk_last_line = chunk.insert_offset, chunk.insert_offset + chunk.insert_count - 1

            return chunk_last_line >= first_context_line and chunk_first_line <= last_context_line

        def lineFilter(line):
            if use == old:
                linenr = line.old_offset
                if linenr == first_context_line and line.type == diff.Line.INSERTED:
                    return False
            else:
                linenr = line.new_offset
                if linenr == first_context_line and line.type == diff.Line.DELETED:
                    return False

            return first_context_line <= linenr <= last_context_line

        file.loadOldLines(True)
        file.loadNewLines(True)

        context = diff.context.ContextLines(file, file.chunks, [chain])
        file.macro_chunks = context.getMacroChunks(context_lines, highlight=True, lineFilter=lineFilter)

        try: macro_chunk = file.macro_chunks[0]
        except: raise repr((parent.sha1, child.sha1))

        display_type = "both"

        if chain.state != "addressed":
            first_line_type = macro_chunk.lines[0].type
            if first_line_type == diff.Line.CONTEXT or (use == old and first_line_type == diff.Line.DELETED) or (use == new and first_line_type == diff.Line.INSERTED):
                for line in macro_chunk.lines[1:]:
                    if first_line_type != line.type:
                        break
                else:
                    display_type = "old" if use == old else "new"

        commit_url_component = "from=%s&to=%s" % (parent.sha1, child.sha1)

    def renderHeaderLeft(db, target, file):
        target.span("comment-chain-title").a(href="/showcomment?chain=%d" % chain.id).text(chain.title())

    def renderHeaderRight(db, target, file):
        side = use == old and "o" or "n"
        uri = "showcommit?%s&review=%d&file=%d#f%d%s%d" % (commit_url_component, review.id, file.id, file.id, side, first_line)
        target.span("filename").a(href=uri).text(file.path)

    def renderCommentsLocal(db, target, **kwargs):
        if display_type == "both":
            if use == old: position = "left"
            else: position = "right"
        else:
            position = "center"

        renderComments(db, target, user, chain, position, linkify)

    def lineId(base):
        return "c%d%s" % (chain.id, base)

    def lineCellId(base):
        return "c%d%s" % (chain.id, base)

    target.addInternalScript("commentChainById[%d] = %s;" % (chain.id, chain.getJSConstructor(sha1)), here=True)

    changeset_html.renderFile(db, target, user, review, file, options={ "support_expand": False, "display_type": display_type, "header_left": renderHeaderLeft, "header_right": renderHeaderRight, "content_after": renderCommentsLocal, "show": True, "expand": True, "line_id": lineId, "line_cell_id": lineCellId, "compact": compact, "tabify": tabify, "include_deleted": True })

    data = (chain.id, file_id, use == old and "o" or "n", first_line,
            chain.id, file_id, use == old and "o" or "n", last_line,
            htmlutils.jsify(chain.type), htmlutils.jsify(chain.state),
            chain.id)

    target.addInternalScript("""$(document).ready(function ()
  {
    var markers = new CommentMarkers(null);
    markers.setLines(document.getElementById('c%df%d%s%d'), document.getElementById('c%df%d%s%d'));
    markers.setType(%s, %s);
    commentChainById[%d].markers = markers;
  });""" % data, here=True)

def renderReviewCommentChain(db, target, user, review, chain, linkify=False, message=None):
    target.addInternalScript("commentChainById[%d] = %s;" % (chain.id, chain.getJSConstructor()), here=True)

    table = target.table("file show expanded first", width="60%", align="center", cellspacing=0, cellpadding=0)

    columns = table.colgroup()
    columns.col("edge")
    columns.col("linenr")
    columns.col("line")
    columns.col("middle")
    columns.col("middle")
    columns.col("line")
    columns.col("linenr")
    columns.col("edge")

    table.thead().tr().td("left", colspan=8, align="left").span("comment-chain-title").a(href="/showcomment?chain=%d" % chain.id).text(chain.title())
    table.tbody('spacer').tr('spacer').td(colspan='8').text()

    if message:
        row = table.tbody("content").tr("content")
        row.td(colspan=2).text()
        row.td("excuse", colspan=4).innerHTML(message)
        row.td(colspan=2).text()

    table.tbody('spacer').tr('spacer').td(colspan='8').text()

    row = table.tbody("content").tr("content")
    row.td(colspan=2).text()
    renderComments(db, row.td(colspan=4), user, chain, "center", linkify)
    row.td(colspan=2).text()

    table.tbody('spacer').tr('spacer').td(colspan='8').text()
    table.tfoot().tr().td("left", colspan=8, align="left").text()

def renderCommitCommentChain(db, target, user, review, chain, linkify=False):
    target.addInternalScript("commentChainById[%d] = %s;" % (chain.id, chain.getJSConstructor()), here=True)

    table = target.table("file show expanded first", width="60%", align="center", cellspacing=0, cellpadding=0)

    columns = table.colgroup()
    columns.col("edge")
    columns.col("linenr")
    columns.col("line")
    columns.col("middle")
    columns.col("middle")
    columns.col("line")
    columns.col("linenr")
    columns.col("edge")

    table.thead().tr().td("left", colspan=8, align="left").span("comment-chain-title").a(href="/showcomment?chain=%d" % chain.id).text(chain.title())
    table.tbody('spacer').tr('spacer').td(colspan='8').text()

    row = table.tbody("content").tr("content")
    row.td(colspan=2).text()
    page.showcommit.renderCommitInfo(db, row.td("content", colspan=4), user, review.repository, review, chain.first_commit, minimal=True)
    row.td(colspan=2).text()

    table.tbody('spacer').tr('spacer').td(colspan='8').text()

    row = table.tbody("content").tr("content")
    row.td(colspan=2).text()
    renderComments(db, row.td(colspan=4), user, chain, "center", linkify)
    row.td(colspan=2).text()

    table.tbody('spacer').tr('spacer').td(colspan='8').text()
    table.tfoot().tr().td("left", colspan=8, align="left").text()

def renderCommentChain(db, target, user, review, chain, context_lines=3, compact=False, tabify=False, original=False, changeset=None, linkify=False):
    chain.loadComments(db, user)

    target.addExternalStylesheet("resource/changeset.css")
    target.addExternalStylesheet("resource/comment.css")
    target.addExternalStylesheet("resource/review.css")
    target.addExternalScript("resource/changeset.js")
    target.addExternalScript("resource/comment.js")
    target.addExternalScript("resource/review.js")

    target = target.div("comment-chain", id="c%d" % chain.id)

    if chain.file_id:
        renderCodeCommentChain(db, target, user, review, chain, context_lines, compact, tabify, original, changeset, linkify)
    elif chain.first_commit:
        renderCommitCommentChain(db, target, user, review, chain, linkify)
    else:
        renderReviewCommentChain(db, target, user, review, chain, linkify)

########NEW FILE########
__FILENAME__ = mail
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2012 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import dbutils
import gitutils
import configuration
import textutils
import diff
from mailutils import queueMail, sendPendingMails, generateMessageId

import changeset.text as changeset_text
import changeset.utils as changeset_utils
import changeset.load as changeset_load
import log.commitset as log_commitset

import reviewing.comment as review_comment
import utils as review_utils

import time

def sendMail(db, review, message_id, from_user, to_user, recipients, subject, body,
             parent_message_id=None, headers=None):
    if headers is None:
        headers = {}
    else:
        headers = headers.copy()

    headers["OperaCritic-URL"] = review.getURL(db, to_user, separator=", ")
    headers["OperaCritic-Association"] = review.getUserAssociation(db, to_user)
    headers["OperaCritic-Repository"] = review.repository.getURL(db, to_user)

    return queueMail(from_user, to_user, recipients, subject, body,
                     message_id=message_id,
                     parent_message_id=parent_message_id,
                     headers=headers)

def generateSubjectLine(db, user, review, item):
    format = user.getPreference(db, "email.subjectLine.%s" % item)

    data = { "id": "r/%d" % review.id,
             "summary": review.summary,
             "progress": str(review.getReviewState(db)),
             "branch": review.branch.name }

    try: return format % data
    except Exception as exc: return "%s (format: %r)" % (str(exc), format)

def getReviewMessageId(db, to_user, review, files):
    cursor = db.cursor()
    cursor.execute("""SELECT messageid
                        FROM reviewmessageids
                       WHERE uid=%s
                         AND review=%s""",
                   (to_user.id, review.id))
    for (message_id,) in cursor:
        return message_id
    else:
        filename, message_id = sendReviewPlaceholder(
            db, to_user, review, generateMessageId(len(files) + 1))
        if filename:
            files.append(filename)
        return message_id

def renderChainInMail(db, to_user, chain, focus_comment, new_state, new_type, line_length, context_lines):
    result = ""
    hr = "-" * line_length
    urls = to_user.getCriticURLs(db)
    url = "\n".join(["  %s/showcomment?chain=%d" % (url, chain.id) for url in urls])

    cursor = db.cursor()

    if chain.file_id:
        path = dbutils.describe_file(db, chain.file_id)

        if chain.first_commit == chain.last_commit or chain.origin == 'old':
            entry = chain.first_commit.getFileEntry(path)
        else:
            entry = chain.last_commit.getFileEntry(path)

        sha1 = entry.sha1
        mode = entry.mode

        first_line, count = chain.lines_by_sha1[sha1]

        context = changeset_utils.getCodeContext(db, sha1, first_line, minimized=True)
        if context: result += "%s in %s, %s:\n%s\n%s\n" % (chain.type.capitalize(), path, context, url, hr)
        else: result += "%s in %s:\n%s\n%s\n" % (chain.type.capitalize(), path, url, hr)

        file = diff.File(id=chain.file_id, path=path, new_mode=mode, new_sha1=sha1, repository=chain.review.repository)
        file.loadNewLines()
        lines = file.newLines(False)

        last_line = first_line + count - 1
        first_line = max(1, first_line - context_lines)
        last_line = min(last_line + context_lines, len(lines))
        width = len(str(last_line))

        for offset, line in enumerate(lines[first_line - 1:last_line]):
            result += "%s|%s\n" % (str(first_line + offset).rjust(width), line)

        result += hr + "\n"
    elif chain.first_commit:
        result += "%s in commit %s by %s:\n%s\n%s\n" % (chain.type.capitalize(), chain.first_commit.sha1[:8], chain.first_commit.author.name, url, hr)

        first_line, count = chain.lines_by_sha1[chain.first_commit.sha1]
        last_line = first_line + count - 1
        lines = chain.first_commit.message.splitlines()

        for line in lines[first_line:last_line + 1]:
            result += "  %s\n" % line

        result += hr + "\n"
    else:
        result += "General %s:\n%s\n%s\n" % (chain.type, url, hr)

    mode = to_user.getPreference(db, "email.updatedReview.quotedComments")

    def formatComment(comment):
        return "%s at %s:\n%s\n" % (comment.user.fullname, comment.when, textutils.reflow(comment.comment, line_length, indent=2))

    assert not focus_comment or focus_comment == chain.comments[-1], "focus comment (#%d) is not last in chain (#%d) as expected" % (focus_comment.id, chain.id)

    if not focus_comment or len(chain.comments) > 1:
        if focus_comment: comments = chain.comments[:-1]
        else: comments = chain.comments

        result = "\n".join(["> " + line for line in result.splitlines()]) + "\n"

        quote1 = ""
        notshown = ""
        quote2 = ""

        if mode == "first":
            quote1 = formatComment(comments[0])
            if len(comments) > 1:
                notshown = "[%d comment%s not shown]" % (len(comments) - 1, "s" if len(comments) > 2 else "")
        elif mode == "firstlast":
            quote1 = formatComment(comments[0])
            if len(comments) > 2:
                notshown = "[%d comment%s not shown]" % (len(comments) - 2, "s" if len(comments) > 3 else "")
            if len(comments) > 1:
                quote2 = formatComment(comments[-1])
        elif mode == "last":
            if len(comments) > 1:
                notshown = "[%d comment%s not shown]" % (len(comments) - 1, "s" if len(comments) > 2 else "")
            quote2 = formatComment(comments[-1])
        else:
            for comment in comments:
                quote1 += formatComment(comment)

        if quote1:
            result += "\n".join(["> " + line for line in quote1.splitlines()]) + "\n"
        if notshown:
            result += notshown + "\n"
        if quote2:
            result += "\n".join(["> " + line for line in quote2.splitlines()]) + "\n"

        if focus_comment:
            result += "\n"

    if focus_comment:
        result += formatComment(focus_comment)

    if new_type == "issue":
        result += "\nCONVERTED TO ISSUE!\n"
    elif new_type == "note":
        result += "\nCONVERTED TO NOTE!\n"

    if new_state == "closed":
        result += "\nISSUE RESOLVED!\n"
    elif new_state == "addressed":
        result += "\nISSUE ADDRESSED!\n"
    elif new_state == "open":
        result += "\nISSUE REOPENED!\n"
    elif chain.state == "closed":
        result += "\n(This issue is resolved.)\n"
    elif chain.state == "addressed":
        result += "\n(This issue is addressed.)\n"

    return result

def checkEmailEnabled(db, to_user, check_preference=True):
    """Check whether we should send emails to the user."""
    if to_user.email_verified is False:
        # Email address needs verification before use.
        return False
    if check_preference \
            and not to_user.getPreference(db, "email.activated"):
        # User has requested that no emails be sent.
        return False
    return True

def sendReviewCreated(db, from_user, to_user, recipients, review):
    # First check if we can send emails to the user at all.
    if not checkEmailEnabled(db, to_user):
        return []

    line_length = to_user.getPreference(db, "email.lineLength")
    hr = "-" * line_length

    data = { 'review.id': review.id,
             'review.url': review.getURL(db, to_user, 2),
             'review.owner.fullname': review.owners[0].fullname,
             'review.branch.name': review.branch.name,
             'review.branch.repository': review.repository.getURL(db, to_user),
             'hr': hr }

    body = """%(hr)s
This is an automatic message generated by the review at:
%(review.url)s
%(hr)s


""" % data

    body += """%(review.owner.fullname)s has requested a review of the changes on the branch
  %(review.branch.name)s
in the repository
  %(review.branch.repository)s


""" % data

    all_reviewers = to_user.getPreference(db, "email.newReview.displayReviewers")
    all_watchers = to_user.getPreference(db, "email.newReview.displayWatchers")

    if all_reviewers or all_watchers:
        if all_reviewers:
            if review.reviewers:
                body += "The users assigned to review the changes on the review branch are:\n"

                for reviewer in review.reviewers:
                    body += "  " + reviewer.fullname + "\n"

                body += "\n"
            else:
                body += """No reviewers have been identified for the changes in this review.  This means
the review is currently stuck; it cannot finish unless there are reviewers.

"""

        if all_watchers and review.watchers:
            body += "The following additional users are following the review:\n"

            for watcher in review.watchers:
                body += "  " + watcher.fullname + "\n"

            body += "\n"

        body += "\n"

    if review.description:
        body += """Description:
%s


""" % textutils.reflow(review.description, line_length, indent=2)

    cursor = db.cursor()
    cursor.execute("""SELECT file, SUM(deleted), SUM(inserted)
                        FROM fullreviewuserfiles
                       WHERE review=%s
                         AND assignee=%s
                    GROUP BY file""",
                   (review.id, to_user.id))
    pending_files_lines = cursor.fetchall()

    if pending_files_lines:
        body += renderFiles(db, to_user, review, "These changes were assigned to you:", pending_files_lines, showcommit_link=True)

    all_commits = to_user.getPreference(db, "email.newReview.displayCommits")

    if all_commits:
        body += "The commits requested to be reviewed are:\n\n"

        contextLines = to_user.getPreference(db, "email.newReview.diff.contextLines")
        diffMaxLines = to_user.getPreference(db, "email.newReview.diff.maxLines")

        displayStats = to_user.getPreference(db, "email.newReview.displayStats")
        statsMaxLines = to_user.getPreference(db, "email.newReview.stats.maxLines")

        if contextLines < 0: contextLines = 0

        commits = list(reversed(review.branch.commits))

        if diffMaxLines == 0: diffs = None
        else:
            diffs = {}
            lines = 0

            for commit in commits:
                if len(commit.parents) == 1:
                    cursor.execute("""SELECT id
                                        FROM reviewchangesets
                                        JOIN changesets ON (id=changeset)
                                       WHERE review=%s
                                         AND child=%s""", (review.id, commit.getId(db)))

                    (changeset_id,) = cursor.fetchone()

                    diff = changeset_text.unified(db, changeset_load.loadChangeset(db, review.repository, changeset_id), contextLines)
                    diffs[commit] = diff
                    lines += diff.count("\n")
                    if lines > diffMaxLines:
                        diffs = None
                        break

        if not displayStats or statsMaxLines == 0: stats = None
        else:
            stats = {}
            lines = 0

            for commit in commits:
                commit_stats = review.repository.run("show", "--oneline", "--stat", commit.sha1).split('\n', 1)[1]
                stats[commit] = commit_stats
                lines += commit_stats.count('\n')
                if lines > statsMaxLines:
                    stats = None
                    break

        for index, commit in enumerate(commits):
            if index > 0: body += "\n\n\n"

            body += """Commit: %(sha1)s
Author: %(author.fullname)s <%(author.email)s> at %(author.time)s

%(message)s
""" % { 'sha1': commit.sha1,
        'author.fullname': commit.author.getFullname(db),
        'author.email': commit.author.email,
        'author.time': time.strftime("%Y-%m-%d %H:%M:%S", commit.author.time),
        'message': textutils.reflow(commit.message.strip(), line_length, indent=2) }

            if stats and commit in stats:
                body += "---\n" + stats[commit]

            if diffs and commit in diffs:
                body += "\n" + diffs[commit]

    message_id = generateMessageId()
    subject = generateSubjectLine(db, to_user, review, 'newReview')

    cursor.execute("INSERT INTO reviewmessageids (uid, review, messageid) VALUES (%s, %s, %s)",
                   [to_user.id, review.id, message_id])

    return [sendMail(db, review, message_id, from_user,
                     to_user, recipients, subject, body)]

def renderFiles(db, to_user, review, title, files_lines, commits=None, relevant_only=False, relevant_files=None, showcommit_link=False):
    result = ""
    if files_lines:
        files = []

        for file_id, delete_count, insert_count in files_lines:
            if not relevant_only or file_id in relevant_files:
                files.append((dbutils.describe_file(db, file_id), delete_count, insert_count))

        if files:
            paths = []
            deleted = []
            inserted = []

            for path, delete_count, insert_count in sorted(files):
                paths.append(path)
                deleted.append(delete_count)
                inserted.append(insert_count)

            paths = diff.File.eliminateCommonPrefixes(paths, text=True)

            len_paths = max(map(len, paths))
            len_deleted = max(map(len, map(str, deleted)))
            len_inserted = max(map(len, map(str, inserted)))

            result += title + "\n"

            for path, delete_count, insert_count in zip(paths, deleted, inserted):
                if delete_count == 0 and insert_count == 0:
                    result += "  %s  binary file\n" % path.ljust(len_paths)
                else:
                    delete_field = delete_count > 0 and "-%d" % delete_count or ""
                    insert_field = insert_count > 0 and "+%d" % insert_count or ""
                    result += "  %s  %s %s\n" % (path.ljust(len_paths), delete_field.rjust(len_deleted + 1), insert_field.rjust(len_inserted + 1))

            if commits:
                if len(commits) == 1:
                    result += "from this commit:\n"
                else:
                    result += "from these commits:\n"

                for commit_id in commits:
                    commit = gitutils.Commit.fromId(db, review.repository, commit_id)
                    result += "  %s %s\n" % (commit.sha1[:8], commit.niceSummary())

            if showcommit_link:
                urls = to_user.getCriticURLs(db)

                try:
                    from_sha1, to_sha1 = showcommit_link
                    url_format = "  %%s/showcommit?review=%%d&from=%s&to=%s&filter=pending\n" % (from_sha1, to_sha1)
                except:
                    url_format = "  %s/showcommit?review=%d&filter=pending\n"

                result += "\nTo review all these changes:\n"
                for url in urls:
                    result += url_format % (url, review.id)

            result += "\n\n"
    return result

def sendReviewPlaceholder(db, to_user, review, message_id=None):
    # First check if we can send emails to the user at all.
    if not checkEmailEnabled(db, to_user):
        return []

    line_length = to_user.getPreference(db, "email.lineLength")
    hr = "-" * line_length

    why = "This message is sent to you when you become associated with a review after the review was initially requested.  It is then sent instead of the regular \"New Review\" message, for the purpose of using as the reference/in-reply-to message for other messages sent about this review."

    data = { 'review.id': review.id,
             'review.url': review.getURL(db, to_user, 2),
             'review.owner.fullname': review.owners[0].fullname,
             'review.branch.name': review.branch.name,
             'review.branch.repository': review.repository.getURL(db, to_user),
             'hr': hr,
             'why': textutils.reflow(why, line_length) }

    body = """%(hr)s
This is an automatic message generated by the review at:
%(review.url)s
%(hr)s


%(why)s


%(hr)s


""" % data

    body += """%(review.owner.fullname)s has requested a review of the changes on the branch
  %(review.branch.name)s
in the repository
  %(review.branch.repository)s


""" % data

    all_reviewers = to_user.getPreference(db, "email.newReview.displayReviewers")
    all_watchers = to_user.getPreference(db, "email.newReview.displayWatchers")

    if all_reviewers or all_watchers:
        if all_reviewers:
            if review.reviewers:
                body += "The users assigned to review the changes on the review branch are:\n"

                for reviewer in review.reviewers:
                    body += "  " + reviewer.fullname + "\n"

                body += "\n"
            else:
                body += """No reviewers have been identified for the changes in this review.  This means
the review is currently stuck; it cannot finish unless there are reviewers.

"""

        if all_watchers and review.watchers:
            body += "The following additional users are following the review:\n"

            for watcher in review.watchers:
                body += "  " + watcher.fullname + "\n"

            body += "\n"

        body += "\n"

    if review.description:
        body += """Description:
%s


""" % textutils.reflow(review.description, line_length, indent=2)

    if message_id is None:
        message_id = generateMessageId()
    subject = generateSubjectLine(db, to_user, review, "newishReview")

    cursor = db.cursor()
    cursor.execute("""INSERT INTO reviewmessageids (uid, review, messageid)
                           VALUES (%s, %s, %s)""",
                   (to_user.id, review.id, message_id))

    return (sendMail(db, review, message_id, review.owners[0], to_user, [to_user],
                     subject, body),
            message_id)

def sendReviewBatch(db, from_user, to_user, recipients, review, batch_id, was_accepted, is_accepted, profiler=None):
    if profiler: profiler.check("generate mail: start")

    # First check if we can send emails to the user at all.
    if not checkEmailEnabled(db, to_user):
        return []

    if from_user == to_user and to_user.getPreference(db, "email.ignoreOwnChanges"):
        return []

    cursor = db.cursor()

    line_length = to_user.getPreference(db, "email.lineLength")
    relevant_only = to_user not in review.owners and to_user != from_user and to_user.getPreference(db, "email.updatedReview.relevantChangesOnly")

    if relevant_only:
        cursor.execute("SELECT type FROM reviewusers WHERE review=%s AND uid=%s", (review.id, to_user.id))
        if cursor.fetchone()[0] == 'manual': relevant_only = False

    if profiler: profiler.check("generate mail: prologue")

    if relevant_only:
        relevant_files = review.getRelevantFiles(db, to_user)
    else:
        relevant_files = None

    if profiler: profiler.check("generate mail: get relevant files")

    cursor.execute("SELECT comment FROM batches WHERE id=%s", [batch_id])
    batch_chain_id = cursor.fetchone()[0]

    if profiler: profiler.check("generate mail: batch chain")

    cursor.execute("""SELECT reviewfiles.file, SUM(reviewfiles.deleted), SUM(reviewfiles.inserted)
                        FROM reviewfiles
                        JOIN reviewfilechanges ON (reviewfilechanges.file=reviewfiles.id)
                       WHERE reviewfilechanges.batch=%s
                         AND reviewfilechanges.to='reviewed'
                    GROUP BY reviewfiles.file""",
                       (batch_id,))
    reviewed_files_lines = cursor.fetchall()

    if profiler: profiler.check("generate mail: reviewed files/lines")

    cursor.execute("""SELECT DISTINCT changesets.child
                        FROM reviewfiles
                        JOIN reviewfilechanges ON (reviewfilechanges.file=reviewfiles.id)
                        JOIN changesets ON (changesets.id=reviewfiles.changeset)
                       WHERE reviewfilechanges.batch=%s
                         AND reviewfilechanges.to='reviewed'""",
                       (batch_id,))
    reviewed_commits = cursor.fetchall()

    if profiler: profiler.check("generate mail: reviewed commits")

    cursor.execute("""SELECT reviewfiles.file, SUM(reviewfiles.deleted), SUM(reviewfiles.inserted)
                        FROM reviewfiles
                        JOIN reviewfilechanges ON (reviewfilechanges.file=reviewfiles.id)
                       WHERE reviewfilechanges.batch=%s
                         AND reviewfilechanges.to='pending'
                    GROUP BY reviewfiles.file""",
                   (batch_id,))
    unreviewed_files_lines = cursor.fetchall()

    if profiler: profiler.check("generate mail: unreviewed files/lines")

    cursor.execute("""SELECT DISTINCT changesets.child
                        FROM reviewfiles
                        JOIN reviewfilechanges ON (reviewfilechanges.file=reviewfiles.id)
                        JOIN changesets ON (changesets.id=reviewfiles.changeset)
                       WHERE reviewfilechanges.batch=%s
                         AND reviewfilechanges.to='pending'""",
                       (batch_id,))
    unreviewed_commits = cursor.fetchall()

    if profiler: profiler.check("generate mail: unreviewed commits")

    reviewed_files = renderFiles(db, to_user, review, "Reviewed Files:", reviewed_files_lines, reviewed_commits, relevant_only, relevant_files)
    unreviewed_files = renderFiles(db, to_user, review, "Unreviewed Files:", unreviewed_files_lines, unreviewed_commits, relevant_only, relevant_files)

    if profiler: profiler.check("generate mail: render files")

    context_lines = to_user.getPreference(db, "email.comment.contextLines")

    comment_ids = set()

    def isRelevantComment(chain):
        if chain.file_id is None or chain.file_id in relevant_files: return True

        cursor.execute("SELECT 1 FROM commentchainusers WHERE chain=%s AND uid=%s", (chain.id, to_user.id))
        return cursor.fetchone() is not None

    def fetchNewCommentChains():
        chains = []
        for (chain_id,) in cursor.fetchall():
            if chain_id != batch_chain_id:
                chain = review_comment.CommentChain.fromId(db, chain_id, from_user, review=review)
                if not relevant_only or isRelevantComment(chain):
                    chain.loadComments(db, from_user)
                    chains.append((chain, None, None))
        return chains

    def fetchAdditionalCommentChains():
        chains = []
        for chain_id, comment_id, new_state, new_type in cursor.fetchall():
            if comment_id is not None or new_state is not None or new_type is not None:
                chain = review_comment.CommentChain.fromId(db, chain_id, from_user, review=review)
                if not relevant_only or isRelevantComment(chain):
                    chain.loadComments(db, from_user)
                    chains.append((chain, new_state, new_type))
        return chains

    cursor.execute("SELECT id FROM commentchains WHERE batch=%s AND type='issue' ORDER BY id ASC", [batch_id])
    new_issues = fetchNewCommentChains()

    if profiler: profiler.check("generate mail: new issues")

    cursor.execute("SELECT id FROM commentchains WHERE batch=%s AND type='note' ORDER BY id ASC", [batch_id])
    new_notes = fetchNewCommentChains()

    if profiler: profiler.check("generate mail: new notes")

    cursor.execute("""SELECT commentchains.id, comments.id, commentchainchanges.to_state, commentchainchanges.to_type
                        FROM commentchains
             LEFT OUTER JOIN comments ON (commentchains.id=comments.chain
                                      AND comments.batch=%s)
             LEFT OUTER JOIN commentchainchanges ON (commentchains.id=commentchainchanges.chain
                                                 AND commentchainchanges.batch=%s)
                       WHERE commentchains.review=%s
                         AND commentchains.batch!=%s""",
                   [batch_id, batch_id, review.id, batch_id])
    additional_comments = fetchAdditionalCommentChains()

    if profiler: profiler.check("generate mail: additional comments")

    if is_accepted != was_accepted and not reviewed_files and not unreviewed_files and not new_issues and not new_notes and not additional_comments:
        return []

    data = { 'review.id': review.id,
             'review.url': review.getURL(db, to_user, 2),
             'review.branch.name': review.branch.name,
             'review.branch.repository': review.repository.getURL(db, to_user),
             'hr': "-" * line_length }

    header = """%(hr)s
This is an automatic message generated by the review at:
%(review.url)s
%(hr)s


""" % data

    if batch_chain_id is not None:
        batch_chain = review_comment.CommentChain.fromId(db, batch_chain_id, from_user, review=review)
    else:
        batch_chain = None

    data["batch.author.fullname"] = from_user.fullname

    first_name = from_user.getFirstName()

    if batch_chain is not None:
        batch_chain.loadComments(db, from_user)

        comment_ids.add(batch_chain.comments[0].id)

        remark = """%s'%s comment:
%s


""" % (first_name, first_name[-1] != 's' and 's' or '', textutils.reflow(batch_chain.comments[0].comment, line_length, indent=2))
    else:
        remark = ""

    body = header
    body += textutils.reflow("%(batch.author.fullname)s has submitted a batch of changes to the review." % data, line_length)
    body += "\n\n\n"
    body += remark

    if not was_accepted and is_accepted:
        state_change = textutils.reflow("The review is now ACCEPTED!", line_length) + "\n\n\n"
    elif was_accepted and not is_accepted:
        state_change = textutils.reflow("The review is NO LONGER ACCEPTED!", line_length) + "\n\n\n"
    else:
        state_change = ""

    body += state_change
    body += reviewed_files
    body += unreviewed_files

    subject = generateSubjectLine(db, to_user, review, "updatedReview.submittedChanges")

    def renderCommentChains(chains):
        result = ""
        if chains:
            for chain, new_state, new_type in chains:
                for focus_comment in chain.comments:
                    if focus_comment.batch_id == batch_id:
                        break
                else:
                    focus_comment = None
                if focus_comment is not None or new_state is not None or new_type is not None:
                    result += renderChainInMail(db, to_user, chain, focus_comment, new_state, new_type, line_length, context_lines) + "\n\n"
                if focus_comment is not None:
                    comment_ids.add(focus_comment.id)
        return result

    body += renderCommentChains(new_issues)
    body += renderCommentChains(new_notes)

    if profiler: profiler.check("generate mail: render new comment chains")

    comment_threading = to_user.getPreference(db, "email.updatedReview.commentThreading")

    send_main_mail = state_change or reviewed_files or unreviewed_files or new_issues or new_notes

    if not comment_threading:
        send_main_mail = send_main_mail or additional_comments
        body += renderCommentChains(additional_comments)

        if profiler: profiler.check("generate mail: render additional comments")

    review_message_id = [None]
    files = []

    def localGenerateMessageId():
        return generateMessageId(len(files) + 1)

    def localGetReviewMessageId():
        if review_message_id[0] is None:
            review_message_id[0] = getReviewMessageId(db, to_user, review, files)
        return review_message_id[0]

    if send_main_mail:
        message_id = localGenerateMessageId()

        cursor.executemany("INSERT INTO commentmessageids (uid, comment, messageid) VALUES (%s, %s, %s)",
                           [(to_user.id, comment_id, message_id) for comment_id in comment_ids])

        files.append(sendMail(
            db, review, message_id, from_user, to_user, recipients, subject, body,
            parent_message_id=localGetReviewMessageId()))

    if comment_threading:
        threads = {}

        for chain, new_state, new_type in additional_comments:
            if chain.comments[-1].batch_id == batch_id:
                parent_comment_id = chain.comments[-2].id
            else:
                parent_comment_id = chain.comments[-1].id

            cursor.execute("""SELECT messageid
                                FROM commentmessageids
                               WHERE comment=%s
                                 AND uid=%s""",
                           [parent_comment_id, to_user.id])
            row = cursor.fetchone()

            if row:
                parent_message_id = row[0]
            else:
                parent_message_id = localGetReviewMessageId()

            threads.setdefault(parent_message_id, []).append((chain, new_state, new_type))

        for parent_message_id, chains in threads.items():
            comment_ids = set()

            body = header + remark + renderCommentChains(chains)

            message_id = localGenerateMessageId()

            cursor.executemany("INSERT INTO commentmessageids (uid, comment, messageid) VALUES (%s, %s, %s)",
                               [(to_user.id, comment_id, message_id) for comment_id in comment_ids])

            files.append(sendMail(
                db, review, message_id, from_user, to_user, recipients, subject, body,
                parent_message_id=parent_message_id))

    if profiler: profiler.check("generate mail: finished")

    return files

def sendReviewAddedCommits(db, from_user, to_user, recipients, review, commits, changesets, tracked_branch=False):
    # First check if we can send emails to the user at all.
    if not checkEmailEnabled(db, to_user):
        return []

    if from_user == to_user and to_user.getPreference(db, "email.ignoreOwnChanges"):
        return []

    line_length = to_user.getPreference(db, "email.lineLength")
    hr = "-" * line_length
    relevant_only = to_user not in review.owners and to_user != from_user and to_user.getPreference(db, "email.updatedReview.relevantChangesOnly")

    cursor = db.cursor()

    if relevant_only:
        cursor.execute("SELECT type FROM reviewusers WHERE review=%s AND uid=%s", (review.id, to_user.id))
        if cursor.fetchone()[0] == 'manual': relevant_only = False

    all_commits = dict((commit.sha1, commit) for commit in commits)
    changeset_for_commit = {}

    for changeset in changesets:
        # We don't include diffs for merge commits in mails.
        if len(changeset.child.parents) == 1:
            if changeset.child in all_commits:
                changeset_for_commit[changeset.child] = changeset
            else:
                # An added changeset where the child isn't part of the added
                # commits will be a changeset between a "replayed rebase" commit
                # and the new head commit, generated when doing a non-fast-
                # forward rebase.  The relevant commit from such a changeset is
                # the first (and only) parent.
                changeset_for_commit[changeset.parent] = changeset

    if relevant_only:
        relevant_files = review.getRelevantFiles(db, to_user)
        relevant_commits = set()

        for changeset in changesets:
            for file in changeset.files:
                if file.id in relevant_files:
                    if changeset.child in all_commits:
                        relevant_commits.add(changeset.child)
                    else:
                        # "Replayed rebase" commit; see comment above.
                        relevant_commits.add(all_commits[changeset.parent])
                    break
            else:
                cursor.execute("SELECT id FROM commentchains WHERE review=%s AND state='addressed' AND addressed_by=%s", (review.id, changeset.child.getId(db)))
                for chain_id in cursor.fetchall():
                    cursor.execute("SELECT 1 FROM commentchainusers WHERE chain=%s AND uid=%s", (chain_id, to_user.id))
                    if cursor.fetchone():
                        relevant_commits.add(changeset.child)
                        break

        if not relevant_commits:
            return []
    else:
        relevant_commits = None

    data = { 'review.id': review.id,
             'review.url': review.getURL(db, to_user, 2),
             'review.branch.name': review.branch.name,
             'review.branch.repository': review.repository.getURL(db, to_user),
             'hr': hr }

    body = """%(hr)s
This is an automatic message generated by the review at:
%(review.url)s
%(hr)s


""" % data

    commitset = log_commitset.CommitSet(commits)

    if tracked_branch:
        body += "The automatic tracking of\n  %s\n" % tracked_branch
        body += textutils.reflow("has updated the review by pushing %sadditional commit%s to the branch" % ("an " if len(commits) == 1 else "", "s" if len(commits) > 1 else ""), line_length)
    else:
        body += textutils.reflow("%s has updated the review by pushing %sadditional commit%s to the branch" % (from_user.fullname, "an " if len(commits) == 1 else "", "s" if len(commits) > 1 else ""), line_length)

    body += "\n  %s\n" % review.branch.name
    body += textutils.reflow("in the repository", line_length)
    body += "\n  %s\n\n\n" % review.repository.getURL(db, to_user)

    cursor.execute("""SELECT file, SUM(deleted), SUM(inserted)
                        FROM fullreviewuserfiles
                       WHERE review=%%s
                         AND changeset IN (%s)
                         AND state='pending'
                         AND assignee=%%s
                    GROUP BY file""" % ",".join(["%s"] * len(changesets)),
                   [review.id] + [changeset.id for changeset in changesets] + [to_user.id])
    pending_files_lines = cursor.fetchall()

    if pending_files_lines:
        heads = commitset.getHeads()
        tails = commitset.getFilteredTails(review.repository)

        if len(heads) == 1 and len(tails) == 1:
            showcommit_link = (tails.pop()[:8], heads.pop().sha1[:8])
        else:
            showcommit_link = False

        body += renderFiles(db, to_user, review, "These changes were assigned to you:", pending_files_lines, showcommit_link=showcommit_link)

    all_commits = to_user.getPreference(db, "email.updatedReview.displayCommits")
    context_lines = to_user.getPreference(db, "email.comment.contextLines")

    if all_commits:
        body += "The additional commit%s requested to be reviewed are:\n\n" % ("s" if len(commits) > 1 else "")

        contextLines = to_user.getPreference(db, "email.updatedReview.diff.contextLines")
        diffMaxLines = to_user.getPreference(db, "email.updatedReview.diff.maxLines")

        displayStats = to_user.getPreference(db, "email.updatedReview.displayStats")
        statsMaxLines = to_user.getPreference(db, "email.updatedReview.stats.maxLines")

        if contextLines < 0: contextLines = 0

        if diffMaxLines == 0: diffs = None
        else:
            diffs = {}
            lines = 0

            for commit in commits:
                if commit in changeset_for_commit:
                    diff = changeset_text.unified(db, changeset_for_commit[commit], contextLines)
                    diffs[commit] = diff
                    lines += diff.count("\n")
                    if lines > diffMaxLines:
                        diffs = None
                        break

        if not displayStats or statsMaxLines == 0: stats = None
        else:
            stats = {}
            lines = 0

            for commit in commits:
                commit_stats = review.repository.run("show", "--oneline", "--stat", commit.sha1).split('\n', 1)[1]
                stats[commit] = commit_stats
                lines += commit_stats.count('\n')
                if lines > statsMaxLines:
                    stats = None
                    break

        for index, commit in enumerate(commits):
            if index > 0: body += "\n\n\n"

            body += """Commit: %(sha1)s
Author: %(author.fullname)s <%(author.email)s> at %(author.time)s

%(message)s
""" % { 'sha1': commit.sha1,
        'author.fullname': commit.author.getFullname(db),
        'author.email': commit.author.email,
        'author.time': time.strftime("%Y-%m-%d %H:%M:%S", commit.author.time),
        'message': textutils.reflow(commit.message.strip(), line_length, indent=2) }

            if stats and commit in stats:
                body += "---\n" + stats[commit]

            if diffs and commit in diffs:
                body += "\n" + diffs[commit]

            cursor.execute("SELECT id FROM commentchains WHERE review=%s AND state='addressed' AND addressed_by=%s", (review.id, commit.getId(db)))
            rows = cursor.fetchall()

            if rows:
                for (chain_id,) in rows:
                    chain = review_comment.CommentChain.fromId(db, chain_id, to_user, review=review)
                    chain.loadComments(db, to_user, include_draft_comments=False)
                    body += "\n\n" + renderChainInMail(db, to_user, chain, None, "addressed", None, line_length, context_lines)

    files = []

    parent_message_id = getReviewMessageId(db, to_user, review, files)
    message_id = generateMessageId(len(files) + 1)
    subject = generateSubjectLine(db, to_user, review,
                                  "updatedReview.commitsPushed")

    files.append(sendMail(
        db, review, message_id, from_user, to_user, recipients, subject, body,
        parent_message_id=parent_message_id))

    return files

def sendPing(db, from_user, to_user, recipients, review, note):
    # First check if we can send emails to the user at all.
    if not checkEmailEnabled(db, to_user):
        return []

    line_length = to_user.getPreference(db, "email.lineLength")
    hr = "-" * line_length

    data = { 'review.id': review.id,
             'review.url': review.getURL(db, to_user, 2),
             'review.branch.name': review.branch.name,
             'review.branch.repository': review.repository.getURL(db, to_user),
             'from.fullname': from_user.fullname,
             'hr': hr }

    body = """%(hr)s
This is an automatic message generated by the review at:
%(review.url)s
%(hr)s


""" % data

    body += """%(from.fullname)s has pinged the review!


""" % data

    if note:
        body += """Additional information from %s:
%s


""" % (from_user.getFirstName(), textutils.reflow(note, line_length, indent=2))

    cursor = db.cursor()

    cursor.execute("""SELECT reviewfiles.file, SUM(reviewfiles.deleted), SUM(reviewfiles.inserted)
                        FROM reviewfiles
                        JOIN reviewuserfiles ON (reviewuserfiles.file=reviewfiles.id)
                       WHERE reviewfiles.review=%s
                         AND reviewfiles.state='pending'
                         AND reviewuserfiles.uid=%s
                    GROUP BY reviewfiles.file""",
                   (review.id, to_user.id))
    pending_files_lines = cursor.fetchall()

    cursor.execute("""SELECT DISTINCT changesets.child
                        FROM reviewfiles
                        JOIN reviewuserfiles ON (reviewuserfiles.file=reviewfiles.id)
                        JOIN changesets ON (changesets.id=reviewfiles.changeset)
                       WHERE reviewfiles.review=%s
                         AND reviewfiles.state='pending'
                         AND reviewuserfiles.uid=%s""",
                   (review.id, to_user.id))
    pending_commits = cursor.fetchall()

    body += renderFiles(db, to_user, review, "These pending changes are assigned to you:", pending_files_lines, pending_commits, showcommit_link=True)

    cursor.execute("SELECT messageid FROM reviewmessageids WHERE uid=%s AND review=%s", [to_user.id, review.id])
    row = cursor.fetchone()

    if row: parent_message_id = "<%s@%s>" % (row[0], configuration.base.HOSTNAME)
    else: parent_message_id = None

    files = []

    parent_message_id = getReviewMessageId(db, to_user, review, files)
    message_id = generateMessageId(len(files) + 1)
    subject = generateSubjectLine(db, to_user, review, "pingedReview")

    files.append(sendMail(
        db, review, message_id, from_user, to_user, recipients, subject, body,
        parent_message_id=parent_message_id))

    return files

def sendAssignmentsChanged(db, from_user, to_user, review, added_filters, removed_filters, unassigned, assigned):
    # First check if we can send emails to the user at all.
    if not checkEmailEnabled(db, to_user):
        return []

    line_length = to_user.getPreference(db, "email.lineLength")
    hr = "-" * line_length

    data = { 'review.id': review.id,
             'review.url': review.getURL(db, to_user, 2),
             'review.branch.name': review.branch.name,
             'review.branch.repository': review.repository.getURL(db, to_user),
             'from.fullname': from_user.fullname,
             'hr': hr }

    body = """%(hr)s
This is an automatic message generated by the review at:
%(review.url)s
%(hr)s


""" % data

    body += """%(from.fullname)s has modified the assignments in the review.


""" % data

    def renderPaths(items):
        return "  \n".join(diff.File.eliminateCommonPrefixes(sorted(map(lambda item: item[1], items)), text=True)) + "\n"

    if added_filters or removed_filters:
        if added_filters:
            added_reviewer = filter(lambda item: item[0] == "reviewer", added_filters)
            added_watcher = filter(lambda item: item[0] == "watcher", added_filters)
        else:
            added_reviewer = None
            added_watcher = None

        if removed_filters:
            removed_reviewer = filter(lambda item: item[0] == "reviewer", removed_filters)
            removed_watcher = filter(lambda item: item[0] == "watcher", removed_filters)
        else:
            removed_reviewer = None
            removed_watcher = None

        if added_reviewer:
            body += "You are now reviewing the following paths:\n  %s\n" % renderPaths(added_reviewer)
        if added_watcher:
            body += "You are now watching the following paths:\n  %s\n" % renderPaths(added_watcher)
        if removed_reviewer:
            body += "You are no longer reviewing the following paths:\n  %s\n" % renderPaths(removed_reviewer)
        if removed_watcher:
            body += "You are no longer watching the following paths:\n  %s\n" % renderPaths(removed_watcher)

        body += "\n"

    if unassigned:
        body += renderFiles(db, to_user, review, "The following changes are no longer assigned to you:", unassigned)

    if assigned:
        body += renderFiles(db, to_user, review, "The following changes are now assigned to you:",assigned)

    files = []

    parent_message_id = getReviewMessageId(db, to_user, review, files)
    message_id = generateMessageId(len(files) + 1)
    subject = generateSubjectLine(db, to_user, review,
                                  "updatedReview.assignmentsChanged")

    files.append(sendMail(
        db, review, message_id, from_user, to_user, [to_user], subject, body,
        parent_message_id=parent_message_id))

    return files

def sendFiltersApplied(db, from_user, to_user, review, globalfilters, parentfilters, assigned):
    # First check if we can send emails to the user at all.
    if not checkEmailEnabled(db, to_user):
        return []

    line_length = to_user.getPreference(db, "email.lineLength")
    hr = "-" * line_length

    data = { 'review.id': review.id,
             'review.url': review.getURL(db, to_user, 2),
             'review.branch.name': review.branch.name,
             'review.branch.repository': review.repository.getURL(db, to_user),
             'from.fullname': from_user.fullname,
             'hr': hr }

    body = """%(hr)s
This is an automatic message generated by the review at:
%(review.url)s
%(hr)s


""" % data

    if globalfilters:
        what = "global filters"
    else:
        what = "global filters from upstream repositories"

    text = ("%s has modified the assignments in the review by making %s apply, "
            "which they previously did not.  This had the effect that you are "
            "now a %s the review."
            % (from_user.fullname,
               what,
               "reviewer of changes in" if assigned else "watcher of"))

    body += """%s


""" % textutils.reflow(text, line_length)

    if assigned:
        body += renderFiles(db, to_user, review, "The following changes are now assigned to you:", assigned)

    files = []

    parent_message_id = getReviewMessageId(db, to_user, review, files)
    message_id = generateMessageId(len(files) + 1)
    subject = generateSubjectLine(db, to_user, review,
                                  "updatedReview.parentFiltersApplied")

    files.append(sendMail(
        db, review, message_id, from_user, to_user, [to_user], subject, body,
        parent_message_id=parent_message_id))

    return files

def sendReviewRebased(db, from_user, to_user, recipients, review, new_upstream, rebased_commits, onto_branch=None):
    # First check if we can send emails to the user at all.
    if not checkEmailEnabled(db, to_user):
        return []

    if from_user == to_user and to_user.getPreference(db, "email.ignoreOwnChanges"):
        return []

    line_length = to_user.getPreference(db, "email.lineLength")
    hr = "-" * line_length

    data = { 'review.id': review.id,
             'review.url': review.getURL(db, to_user, 2),
             'review.branch.name': review.branch.name,
             'review.branch.repository': review.repository.getURL(db, to_user),
             'from.fullname': from_user.fullname,
             'hr': hr }

    body = """%(hr)s
This is an automatic message generated by the review at:
%(review.url)s
%(hr)s


""" % data

    if new_upstream:
        data["new_upstream"] = new_upstream.oneline(db, decorate=True)
        text = """\
%(from.fullname)s has rebased the review branch onto:

%(new_upstream)s""" % data
    else:
        text = "%(from.fullname)s has rewritten the history on the review branch." % data

    body += """%s


""" % textutils.reflow(text, line_length)

    body += """The new branch log is:

"""

    for commit in rebased_commits:
        body += commit.oneline(db) + "\n"

    files = []

    parent_message_id = getReviewMessageId(db, to_user, review, files)
    message_id = generateMessageId(len(files) + 1)
    subject = generateSubjectLine(db, to_user, review,
                                  "updatedReview.reviewRebased")

    files.append(sendMail(
        db, review, message_id, from_user, to_user, recipients, subject, body,
        parent_message_id=parent_message_id))

    return files

def sendExtensionOutput(db, user_id, batch_id, output):
    user = dbutils.User.fromId(db, user_id)

    # First check if we can send emails to the user at all.
    if not checkEmailEnabled(db, user):
        return []

    line_length = user.getPreference(db, "email.lineLength")
    hr = "-" * line_length

    cursor = db.cursor()
    cursor.execute("SELECT review, uid FROM batches WHERE id=%s", (batch_id,))

    review_id, batch_user_id = cursor.fetchone()

    review = dbutils.Review.fromId(db, review_id)
    batch_user = dbutils.User.fromId(db, batch_user_id)

    data = { 'review.id': review.id,
             'review.url': review.getURL(db, user, 2),
             'batch.user.fullname': batch_user.fullname,
             'hr': hr }

    body = """%(hr)s
This is an automatic message generated by the review at:
%(review.url)s
%(hr)s


""" % data

    text = "A batch of changes submitted by %(batch.user.fullname)s has been processed by your installed extensions." % data

    body += """%s


""" % textutils.reflow(text, line_length)

    body += "The extensions generated the following output:\n%s" % output

    files = []

    parent_message_id = getReviewMessageId(db, user, review, files)
    message_id = generateMessageId(len(files) + 1)
    subject = generateSubjectLine(db, user, review, "extensionOutput")

    files.append(sendMail(
        db, review, message_id, user, user, [user], subject, body,
        parent_message_id=parent_message_id))

    return files

########NEW FILE########
__FILENAME__ = rebase
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2012 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import time

import configuration
import gitutils

def timestamp(ts):
    return time.strftime("%Y-%m-%d %H:%M:%S", ts)

def createEquivalentMergeCommit(db, review, user, old_head, old_upstream, new_head, new_upstream, onto_branch=None):
    repository = review.repository

    old_upstream_name = repository.findInterestingTag(db, old_upstream.sha1) or old_upstream.sha1
    new_upstream_name = repository.findInterestingTag(db, new_upstream.sha1) or new_upstream.sha1

    if onto_branch:
        merged_thing = "branch '%s'" % onto_branch
    else:
        merged_thing = "commit '%s'" % new_upstream_name

    commit_message = """\
Merge %(merged_thing)s into %(review.branch.name)s

This commit was generated automatically by Critic as an equivalent merge
to the rebase of the commits

  %(old_upstream_name)s..%(old_head.sha1)s

onto the %(merged_thing)s.""" % { "merged_thing": merged_thing,
                                  "review.branch.name": review.branch.name,
                                  "old_upstream_name": old_upstream_name,
                                  "old_head.sha1": old_head.sha1 }

    merge_sha1 = repository.run('commit-tree', new_head.tree, '-p', old_head.sha1, '-p', new_upstream.sha1,
                                input=commit_message,
                                env=gitutils.getGitEnvironment()).strip()

    merge = gitutils.Commit.fromSHA1(db, repository, merge_sha1)
    gituser_id = merge.author.getGitUserId(db)

    cursor = db.cursor()
    cursor.execute("""INSERT INTO commits (sha1, author_gituser, commit_gituser, author_time, commit_time)
                           VALUES (%s, %s, %s, %s, %s)
                        RETURNING id""",
                   (merge.sha1, gituser_id, gituser_id, timestamp(merge.author.time), timestamp(merge.committer.time)))
    merge.id = cursor.fetchone()[0]

    cursor.executemany("INSERT INTO edges (parent, child) VALUES (%s, %s)",
                       [(old_head.getId(db), merge.id),
                        (new_upstream.getId(db), merge.id)])

    # Need to commit the transaction to make the new commit available
    # to other database sessions right away, specifically so that the
    # changeset service can see it.
    db.commit()

    return merge

def replayRebase(db, review, user, old_head, old_upstream, new_head, new_upstream, onto_branch=None):
    repository = review.repository

    old_upstream_name = repository.findInterestingTag(db, old_upstream.sha1) or old_upstream.sha1

    if onto_branch:
        new_upstream_name = "branch '%s'" % onto_branch
    else:
        new_upstream_name = "commit '%s'" % (repository.findInterestingTag(db, new_upstream.sha1) or new_upstream.sha1)

    commit_message = """\
Rebased %(review.branch.name)s onto %(new_upstream_name)s

This commit was generated automatically by Critic to "replay" the
rebase of the commits

  %(old_upstream_name)s..%(old_head.sha1)s

onto the %(new_upstream_name)s.""" % { "review.branch.name": review.branch.name,
                                       "old_head.sha1": old_head.sha1,
                                       "old_upstream_name": old_upstream_name,
                                       "new_upstream_name": new_upstream_name }

    original_sha1 = repository.run(
        'commit-tree', old_head.tree, '-p', old_upstream.sha1,
        env=gitutils.getGitEnvironment(),
        input=commit_message).strip()

    repository.run("update-ref", "refs/commit/%s" % new_upstream.sha1, new_upstream.sha1)
    repository.run("update-ref", "refs/commit/%s" % original_sha1, original_sha1)

    with repository.workcopy(original_sha1) as workcopy:
        workcopy.run("fetch", "--quiet", "origin",
                     "refs/commit/%s:refs/heads/temporary" % new_upstream.sha1,
                     "refs/commit/%s:refs/heads/original" % original_sha1)

        workcopy.run("checkout", "temporary")

        returncode, stdout, stderr = workcopy.run(
            "cherry-pick", "refs/heads/original",
            env=gitutils.getGitEnvironment(),
            check_errors=False)

        # If the rebase produced conflicts, just stage and commit them:
        if returncode != 0:
            # Reset any submodule gitlinks with conflicts: since we don't
            # have the submodules checked out, "git commit --all" below
            # may fail to index them.
            for line in stdout.splitlines():
                if line.startswith("CONFLICT (submodule):"):
                    submodule_path = line.split()[-1]
                    workcopy.run("reset", "--", submodule_path, check_errors=False)

            # Then stage and commit the result, with conflict markers and all.
            workcopy.run("commit", "--all", "--reuse-message=%s" % original_sha1,
                         env=gitutils.getGitEnvironment())

        rebased_sha1 = workcopy.run("rev-parse", "HEAD").strip()

        workcopy.run("push", "origin", "HEAD:refs/keepalive/%s" % rebased_sha1)

    return gitutils.Commit.fromSHA1(db, repository, rebased_sha1)

########NEW FILE########
__FILENAME__ = report
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2012 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

def generateReviewReport(db, review):
    title = "Review Report: %s" % review.summary

    report = "%s\n%s\n\n\n" % (title, "=" * len(title))
    report += "Reviewed Commits\n----------------\n\n"

    commit_map = {}

    for changeset in review.changesets:
        commit_map[changeset.parent.id] = changeset.child.id

########NEW FILE########
__FILENAME__ = utils
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2012 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import dbutils
import gitutils
from dbutils import *
from itertools import izip, repeat, chain
import htmlutils

import mail
import diff
import changeset.utils as changeset_utils
import changeset.load as changeset_load
import reviewing.comment
import reviewing.filters
import log.commitset as log_commitset

from operation import OperationError, OperationFailure
from filters import Filters

def getReviewersAndWatchers(db, repository, commits=None, changesets=None, reviewfilters=None,
                            applyfilters=True, applyparentfilters=False):
    """getReviewersAndWatchers(db, commits=None, changesets=None) -> tuple

Returns a tuple containing two dictionaries, each mapping file IDs to
dictionaries mapping user IDs to sets of changeset IDs.  The first dictionary
defines the reviwers of each file, the second dictionary defines the watchers of
each file.  For any changes in a file for which no reviewer is identified, None
is used as a key in the dictionary instead of a real user ID."""

    if changesets is None:
        changesets = []
        changeset_utils.createChangesets(db, repository, commits)
        for commit in commits:
            changesets.extend(changeset_utils.createChangeset(db, None, repository, commit, do_highlight=False))

    cursor = db.cursor()

    filters = Filters()

    file_ids = set()
    for changeset in changesets:
        for changed_file in changeset.files:
            file_ids.add(changed_file.id)
    filters.setFiles(db, list(file_ids))

    if applyfilters:
        filters.load(db, repository=repository, recursive=applyparentfilters)

    if reviewfilters:
        filters.addFilters(reviewfilters)

    reviewers = {}
    watchers = {}

    for changeset in changesets:
        author_user_ids = changeset.child.author.getUserIds(db) if changeset.child else set()

        cursor.execute("SELECT DISTINCT file FROM fileversions WHERE changeset=%s", (changeset.id,))

        for (file_id,) in cursor:
            reviewers_found = False

            for user_id, (filter_type, delegate) in filters.listUsers(file_id).items():
                if filter_type == 'reviewer':
                    if user_id not in author_user_ids:
                        reviewer_user_ids = [user_id]
                    elif delegate:
                        reviewer_user_ids = []
                        for delegate_user_name in delegate.split(","):
                            delegate_user = dbutils.User.fromName(db, delegate_user_name)
                            reviewer_user_ids.append(delegate_user.id)
                    else:
                        reviewer_user_ids = []

                    for reviewer_user_id in reviewer_user_ids:
                        reviewers.setdefault(file_id, {}).setdefault(reviewer_user_id, set()).add(changeset.id)
                        reviewers_found = True
                else:
                    watchers.setdefault(file_id, {}).setdefault(user_id, set()).add(changeset.id)

            if not reviewers_found:
                reviewers.setdefault(file_id, {}).setdefault(None, set()).add(changeset.id)

    return reviewers, watchers

def getReviewedReviewers(db, review):
    """getReviewedReviewers(db, review) -> dictionary

Returns a dictionary, like the ones returned by getReviewersAndWatchers(), but
with details about all reviewed changes in the review."""

    cursor = db.cursor()

    cursor.execute("""SELECT reviewfiles.reviewer, reviewfiles.changeset, reviewfiles.file
                        FROM reviewfiles
                       WHERE reviewfiles.review=%s
                         AND reviewfiles.state='reviewed'""",
                   (review.id,))

    reviewers = {}

    for user_id, changeset_id, file_id in cursor.fetchall():
        reviewers.setdefault(file_id, {}).setdefault(user_id, set()).add(changeset_id)

    return reviewers

def getPendingReviewers(db, review):
    """getPendingReviewers(db, review) -> dictionary

Returns a dictionary, like the ones returned by getReviewersAndWatchers(), but
with details about remaining unreviewed changes in the review.  Changes not
assigned to a reviewer are handled the same way."""

    cursor = db.cursor()

    cursor.execute("""SELECT reviewuserfiles.uid, reviewfiles.changeset, reviewfiles.file
                        FROM reviewfiles
             LEFT OUTER JOIN reviewuserfiles ON (reviewuserfiles.file=reviewfiles.id)
                       WHERE reviewfiles.review=%s
                         AND reviewfiles.state='pending'""",
                   (review.id,))

    reviewers = {}

    for user_id, changeset_id, file_id in cursor.fetchall():
        reviewers.setdefault(file_id, {}).setdefault(user_id, set()).add(changeset_id)

    return reviewers

def collectReviewTeams(reviewers):
    """collectReviewTeams(reviewers) -> dictionary

Takes a dictionary as returned by getReviewersAndWatchers() or
getPendingReviewers() and transform into a dictionary mapping sets of users to
sets of files that those groups of users share review responsibilities for.  The
same user may appear in number of sets, as may the same file.

If None appears as a key in the returned dictionary, the set of files it is
mapped to have changes in them with no assigned reviewers."""

    teams = {}

    for file_id, file_reviewers in reviewers.items():
        if None in file_reviewers:
            teams.setdefault(None, set()).add(file_id)
        team = frozenset(filter(None, file_reviewers.keys()))
        if team: teams.setdefault(team, set()).add(file_id)

    return teams

def assignChanges(db, user, review, commits=None, changesets=None, update=False):
    cursor = db.cursor()

    if changesets is None:
        assert commits is not None

        changesets = []

        for commit in commits:
            changesets.extend(changeset_utils.createChangeset(db, user, review.repository, commit))

    applyfilters = review.applyfilters
    applyparentfilters = review.applyparentfilters

    reviewers, watchers = getReviewersAndWatchers(db, review.repository, changesets=changesets, reviewfilters=review.getReviewFilters(db),
                                                  applyfilters=applyfilters, applyparentfilters=applyparentfilters)

    cursor.execute("SELECT uid FROM reviewusers WHERE review=%s", (review.id,))

    reviewusers = set([user_id for (user_id,) in cursor])
    reviewusers_values = set()
    reviewuserfiles_values = set()

    reviewuserfiles_existing = {}

    if update:
        cursor.execute("""SELECT reviewuserfiles.uid, reviewfiles.changeset, reviewfiles.file
                            FROM reviewfiles
                            JOIN reviewuserfiles ON (reviewuserfiles.file=reviewfiles.id)
                           WHERE reviewfiles.review=%s""", (review.id,))
        for user_id, changeset_id, file_id in cursor:
            reviewuserfiles_existing[(user_id, changeset_id, file_id)] = True

    new_reviewers = set()
    new_watchers = set()

    cursor.execute("""SELECT DISTINCT uid
                        FROM reviewfiles
                        JOIN reviewuserfiles ON (reviewuserfiles.file=reviewfiles.id)
                       WHERE review=%s""", (review.id,))
    old_reviewers = set([user_id for (user_id,) in cursor])

    for file_id, file_users in reviewers.items():
        for user_id, user_changesets in file_users.items():
            if user_id:
                new_reviewers.add(user_id)

                if user_id not in reviewusers:
                    reviewusers.add(user_id)
                    reviewusers_values.add((review.id, user_id))
                for changeset_id in user_changesets:
                    if (user_id, changeset_id, file_id) not in reviewuserfiles_existing:
                        reviewuserfiles_values.add((user_id, review.id, changeset_id, file_id))

    for file_id, file_users in watchers.items():
        for user_id, user_changesets in file_users.items():
            if user_id:
                if user_id not in reviewusers:
                    new_watchers.add(user_id)
                    reviewusers.add(user_id)
                    reviewusers_values.add((review.id, user_id))

    new_reviewers -= old_reviewers
    new_watchers -= old_reviewers | new_reviewers

    cursor.executemany("INSERT INTO reviewusers (review, uid) VALUES (%s, %s)", reviewusers_values)
    cursor.executemany("INSERT INTO reviewuserfiles (file, uid) SELECT id, %s FROM reviewfiles WHERE review=%s AND changeset=%s AND file=%s", reviewuserfiles_values)

    return new_reviewers, new_watchers

def addCommitsToReview(db, user, review, commits, new_review=False, commitset=None, pending_mails=None, silent_if_empty=set(), full_merges=set(), replayed_rebases={}, tracked_branch=False):
    cursor = db.cursor()

    if not new_review:
        import index

        new_commits = log_commitset.CommitSet(commits)
        old_commits = log_commitset.CommitSet(review.branch.commits)
        merges = new_commits.getMerges()

        for merge in merges:
            # We might have stripped it in a previous pass.
            if not merge in new_commits: continue

            tails = filter(lambda sha1: sha1 not in old_commits and sha1 not in merge.parents, new_commits.getTailsFrom(merge))

            if tails:
                if tracked_branch:
                    raise index.IndexException("""\
Merge %s adds merged-in commits.  Please push the merge manually
and follow the instructions.""" % merge.sha1[:8])

                cursor.execute("SELECT id, confirmed, tail FROM reviewmergeconfirmations WHERE review=%s AND uid=%s AND merge=%s", (review.id, user.id, merge.getId(db)))

                row = cursor.fetchone()

                if not row or not row[1]:
                    if not row:
                        cursor.execute("INSERT INTO reviewmergeconfirmations (review, uid, merge) VALUES (%s, %s, %s) RETURNING id", (review.id, user.id, merge.getId(db)))
                        confirmation_id = cursor.fetchone()[0]

                        merged = set()

                        for tail_sha1 in tails:
                            children = new_commits.getChildren(tail_sha1)

                            while children:
                                child = children.pop()
                                if child not in merged and new_commits.isAncestorOf(child, merge):
                                    merged.add(child)
                                    children.update(new_commits.getChildren(child) - merged)

                        merged_values = [(confirmation_id, commit.getId(db)) for commit in merged]
                        cursor.executemany("INSERT INTO reviewmergecontributions (id, merged) VALUES (%s, %s)", merged_values)
                        db.commit()
                    else:
                        confirmation_id = row[0]

                    message = "Merge %s adds merged-in commits:" % merge.sha1[:8]

                    for tail_sha1 in tails:
                        for parent_sha1 in merge.parents:
                            if parent_sha1 in new_commits:
                                parent = new_commits.get(parent_sha1)
                                if tail_sha1 in new_commits.getTailsFrom(parent):
                                    message += "\n  %s..%s" % (tail_sha1[:8], parent_sha1[:8])

                    message += """
Please confirm that this is intended by loading:
  %s/confirmmerge?id=%d""" % (dbutils.getURLPrefix(db, user), confirmation_id)

                    raise index.IndexException(message)
                elif row[2] is not None:
                    if row[2] == merge.getId(db):
                        cursor.execute("SELECT merged FROM reviewmergecontributions WHERE id=%s",
                                       (row[0],))

                        for (merged_id,) in cursor:
                            merged = gitutils.Commit.fromId(db, review.repository, merged_id)
                            if merged.sha1 in merge.parents:
                                new_commits = new_commits.without([merged])
                                break
                    else:
                        tail = gitutils.Commit.fromId(db, review.repository, row[2])
                        cut = [gitutils.Commit.fromSHA1(db, review.repository, sha1)
                               for sha1 in tail.parents if sha1 in new_commits]
                        new_commits = new_commits.without(cut)

        if commitset:
            commitset &= set(new_commits)
            commits = [commit for commit in commits if commit in commitset]

    changesets = []
    silent_commits = set()
    silent_changesets = set()

    simple_commits = []
    for commit in commits:
        if commit not in full_merges and commit not in replayed_rebases:
            simple_commits.append(commit)
    if simple_commits:
        changeset_utils.createChangesets(db, review.repository, simple_commits)

    for commit in commits:
        if commit in full_merges:
            commit_changesets = changeset_utils.createFullMergeChangeset(
                db, user, review.repository, commit, do_highlight=False)
        elif commit in replayed_rebases:
            commit_changesets = changeset_utils.createChangeset(
                db, user, review.repository,
                from_commit=commit, to_commit=replayed_rebases[commit],
                conflicts=True, do_highlight=False)
        else:
            commit_changesets = changeset_utils.createChangeset(
                db, user, review.repository, commit, do_highlight=False)

        if commit in silent_if_empty:
            for commit_changeset in commit_changesets:
                if commit_changeset.files:
                    break
            else:
                silent_commits.add(commit)
                silent_changesets.update(commit_changesets)

        changesets.extend(commit_changesets)

    if not new_review:
        print "Adding %d commit%s to the review at:\n  %s" % (len(commits), len(commits) > 1 and "s" or "", review.getURL(db))

    reviewchangesets_values = [(review.id, changeset.id) for changeset in changesets]

    cursor.executemany("""INSERT INTO reviewchangesets (review, changeset) VALUES (%s, %s)""", reviewchangesets_values)
    cursor.executemany("""INSERT INTO reviewfiles (review, changeset, file, deleted, inserted)
                               SELECT reviewchangesets.review, reviewchangesets.changeset, fileversions.file,
                                      COALESCE(SUM(chunks.deleteCount), 0), COALESCE(SUM(chunks.insertCount), 0)
                                 FROM reviewchangesets
                                 JOIN fileversions USING (changeset)
                      LEFT OUTER JOIN chunks USING (changeset, file)
                                WHERE reviewchangesets.review=%s
                                  AND reviewchangesets.changeset=%s
                             GROUP BY reviewchangesets.review, reviewchangesets.changeset, fileversions.file""",
                       reviewchangesets_values)

    new_reviewers, new_watchers = assignChanges(db, user, review, changesets=changesets)

    cursor.execute("SELECT include FROM reviewrecipientfilters WHERE review=%s AND uid IS NULL", (review.id,))

    try: opt_out = cursor.fetchone()[0] is True
    except: opt_out = True

    if not new_review:
        for user_id in new_reviewers:
            new_reviewuser = dbutils.User.fromId(db, user_id)
            print "Added reviewer: %s <%s>" % (new_reviewuser.fullname, new_reviewuser.email)

            if opt_out:
                # If the user has opted out from receiving e-mails about this
                # review while only watching it, clear the opt-out now that the
                # user becomes a reviewer.
                cursor.execute("DELETE FROM reviewrecipientfilters WHERE review=%s AND uid=%s AND include=FALSE", (review.id, user_id))

        for user_id in new_watchers:
            new_reviewuser = dbutils.User.fromId(db, user_id)
            print "Added watcher:  %s <%s>" % (new_reviewuser.fullname, new_reviewuser.email)

        review.incrementSerial(db)

        reviewing.comment.propagateCommentChains(db, user, review, new_commits, replayed_rebases)

    if pending_mails is None: pending_mails = []

    notify_commits = filter(lambda commit: commit not in silent_commits, commits)
    notify_changesets = filter(lambda changeset: changeset not in silent_changesets, changesets)

    if not new_review and notify_changesets:
        recipients = review.getRecipients(db)
        for to_user in recipients:
            pending_mails.extend(mail.sendReviewAddedCommits(
                    db, user, to_user, recipients, review, notify_commits,
                    notify_changesets, tracked_branch=tracked_branch))

    mail.sendPendingMails(pending_mails)

    review.reviewers.extend([User.fromId(db, user_id) for user_id in new_reviewers])

    for user_id in new_watchers:
        review.watchers[User.fromId(db, user_id)] = "automatic"

    return True

def createReview(db, user, repository, commits, branch_name, summary, description, from_branch_name=None, via_push=False, reviewfilters=None, applyfilters=True, applyparentfilters=False, recipientfilters=None):
    cursor = db.cursor()

    if via_push:
        applyparentfilters = bool(user.getPreference(db, 'review.applyUpstreamFilters'))

    branch = dbutils.Branch.fromName(db, repository, branch_name)

    if branch is not None:
        raise OperationFailure(
            code="branchexists",
            title="Invalid review branch name",
            message="""\
<p>There is already a branch named <code>%s</code> in the repository.  You have
to select a different name.</p>

<p>If you believe the existing branch was created during an earlier (failed)
attempt to create this review, you can try to delete it from the repository
using the command<p>

<pre>  git push &lt;remote&gt; :%s</pre>

<p>and then press the "Submit Review" button on this page again."""
            % (htmlutils.htmlify(branch_name), htmlutils.htmlify(branch_name)),
            is_html=True)

    if not commits:
        raise OperationFailure(
            code="nocommits",
            title="No commits specified",
            message="You need at least one commit to create a review.")

    commitset = log_commitset.CommitSet(commits)
    heads = commitset.getHeads()

    if len(heads) != 1:
        # There is really no plausible way for this error to occur.
        raise OperationFailure(
            code="disconnectedtree",
            title="Disconnected tree",
            message=("The specified commits do do not form a single connected "
                     "tree.  Creating a review of them is not supported."))

    head = heads.pop()

    if len(commitset.getTails()) != 1:
        tail_id = None
    else:
        tail_id = gitutils.Commit.fromSHA1(db, repository, commitset.getTails().pop()).getId(db)

    if not via_push:
        try:
            repository.createBranch(branch_name, head.sha1)
        except gitutils.GitCommandError as error:
            raise OperationFailure(
                code="branchfailed",
                title="Failed to create review branch",
                message=("<p><b>Output from git:</b></p>"
                         "<code style='padding-left: 1em'>%s</code>"
                         % htmlutils.htmlify(error.output)),
                is_html=True)

    try:
        cursor.execute("INSERT INTO branches (repository, name, head, tail, type) VALUES (%s, %s, %s, %s, 'review') RETURNING id", [repository.id, branch_name, head.getId(db), tail_id])

        branch_id = cursor.fetchone()[0]
        reachable_values = [(branch_id, commit.getId(db)) for commit in commits]

        cursor.executemany("INSERT INTO reachable (branch, commit) VALUES (%s, %s)", reachable_values)

        cursor.execute("INSERT INTO reviews (type, branch, state, summary, description, applyfilters, applyparentfilters) VALUES ('official', %s, 'open', %s, %s, %s, %s) RETURNING id", (branch_id, summary, description, applyfilters, applyparentfilters))

        review = dbutils.Review.fromId(db, cursor.fetchone()[0])

        cursor.execute("INSERT INTO reviewusers (review, uid, owner) VALUES (%s, %s, TRUE)", (review.id, user.id))

        if reviewfilters is not None:
            cursor.executemany("""INSERT INTO reviewfilters (review, uid, path, type, creator)
                                       VALUES (%s, %s, %s, %s, %s)""",
                               [(review.id, filter_user_id, filter_path, filter_type, user.id)
                                for filter_user_id, filter_path, filter_type, filter_delegate in reviewfilters])

        is_opt_in = False

        if recipientfilters is not None:
            cursor.executemany("INSERT INTO reviewrecipientfilters (review, uid, include) VALUES (%s, %s, %s)",
                               [(review.id, filter_user_id, filter_include)
                                for filter_user_id, filter_include in recipientfilters])

            for filter_user_id, filter_include in recipientfilters:
                if filter_user_id is None and not filter_include:
                    is_opt_in = True

        addCommitsToReview(db, user, review, commits, new_review=True)

        if from_branch_name is not None:
            cursor.execute("UPDATE branches SET review=%s WHERE repository=%s AND name=%s", (review.id, repository.id, from_branch_name))

        # Reload to get list of changesets added by addCommitsToReview().
        review = dbutils.Review.fromId(db, review.id)

        pending_mails = []
        recipients = review.getRecipients(db)
        for to_user in recipients:
            pending_mails.extend(mail.sendReviewCreated(db, user, to_user, recipients, review))

        if not is_opt_in:
            recipient_by_id = dict((to_user.id, to_user) for to_user in recipients)

            cursor.execute("""SELECT userpreferences.uid, userpreferences.repository,
                                     userpreferences.filter, userpreferences.integer
                                FROM userpreferences
                     LEFT OUTER JOIN filters ON (filters.id=userpreferences.filter)
                               WHERE userpreferences.item='review.defaultOptOut'
                                 AND userpreferences.uid=ANY (%s)
                                 AND (userpreferences.filter IS NULL
                                   OR filters.repository=%s)
                                 AND (userpreferences.repository IS NULL
                                   OR userpreferences.repository=%s)""",
                           (recipient_by_id.keys(), repository.id, repository.id))

            user_settings = {}
            has_filter_settings = False

            for user_id, repository_id, filter_id, integer in cursor:
                settings = user_settings.setdefault(user_id, [None, None, {}])
                value = bool(integer)

                if repository_id is None and filter_id is None:
                    settings[0] = value
                elif repository_id is not None:
                    settings[1] = value
                else:
                    settings[2][filter_id] = value
                    has_filter_settings = True

            if has_filter_settings:
                filters = Filters()
                filters.setFiles(db, review=review)

            for user_id, (global_default, repository_default, filter_settings) in user_settings.items():
                to_user = recipient_by_id[user_id]
                opt_out = None

                if repository_default is not None:
                    opt_out = repository_default
                elif global_default is not None:
                    opt_out = global_default

                if filter_settings:
                    # Policy:
                    #
                    # If all of the user's filters that matched files in the
                    # review have review.defaultOptOut enabled, then opt out.
                    # When determining this, any review filters of the user's
                    # that match files in the review count as filters that don't
                    # have the review.defaultOptOut enabled.
                    #
                    # If any of the user's filters that matched files in the
                    # review have review.defaultOptOut disabled, then don't opt
                    # out.  When determining this, review filters are ignored.
                    #
                    # Otherwise, ignore the filter settings, and go with either
                    # the user's per-repository or global setting (as set
                    # above.)

                    filters.load(db, review=review, user=to_user)

                    # A set of filter ids.  If None is in the set, the user has
                    # one or more review filters in the review.  (These do not
                    # have ids.)
                    active_filters = filters.getActiveFilters(to_user)

                    for filter_id in active_filters:
                        if filter_id is None:
                            continue
                        elif filter_id in filter_settings:
                            if not filter_settings[filter_id]:
                                opt_out = False
                                break
                        else:
                            break
                    else:
                        if None not in active_filters:
                            opt_out = True

                if opt_out:
                    cursor.execute("""INSERT INTO reviewrecipientfilters (review, uid, include)
                                           VALUES (%s, %s, FALSE)""",
                                   (review.id, to_user.id))

        db.commit()

        mail.sendPendingMails(pending_mails)

        return review
    except:
        if not via_push:
            repository.run("branch", "-D", branch_name)
        raise

def getDraftItems(db, user, review):
    return "approved=%(reviewedNormal)d,disapproved=%(unreviewedNormal)d,approvedBinary=%(reviewedBinary)d,disapprovedBinary=%(unreviewedBinary)d,comments=%(writtenComments)d,reopened=%(reopenedIssues)d,closed=%(resolvedIssues)d,morphed=%(morphedChains)d" % review.getDraftStatus(db, user)

def renderDraftItems(db, user, review, target):
    items = review.getDraftStatus(db, user)

    target.addExternalStylesheet("resource/review.css")
    target.addExternalScript("resource/review.js")

    div = target.div(id='draftStatus')

    if any(items.values()):
        div.span('draft').text("Draft: ")

        approved = items.pop("reviewedNormal", None)
        if approved:
            div.text(' ')
            div.span('approved').text("reviewed %d line%s" % (approved, approved > 1 and "s" or ""))

            if any(items.values()): div.text(',')

        disapproved = items.pop("unreviewedNormal", None)
        if disapproved:
            div.text(' ')
            div.span('disapproved').text("unreviewed %d line%s" % (disapproved, disapproved > 1 and "s" or ""))

            if any(items.values()): div.text(',')

        approved = items.pop("reviewedBinary", None)
        if approved:
            div.text(' ')
            div.span('approved-binary').text("reviewed %d binary file%s" % (approved, approved > 1 and "s" or ""))

            if any(items.values()): div.text(',')

        disapproved = items.pop("unreviewedBinary", None)
        if disapproved:
            div.text(' ')
            div.span('disapproved-binary').text("unreviewed %d binary file%s" % (disapproved, disapproved > 1 and "s" or ""))

            if any(items.values()): div.text(',')

        comments = items.pop("writtenComments", None)
        if comments:
            div.text(' ')
            div.span('comments').text("wrote %d comment%s" % (comments, comments > 1 and "s" or ""))

            if any(items.values()): div.text(',')

        reopened = items.pop("reopenedIssues", None)
        if reopened:
            div.text(' ')
            div.span('reopened').text("reopened %d issue%s" % (reopened, reopened > 1 and "s" or ""))

            if any(items.values()): div.text(',')

        closed = items.pop("resolvedIssues", None)
        if closed:
            div.text(' ')
            div.span('closed').text("resolved %d issue%s" % (closed, closed > 1 and "s" or ""))

            if any(items.values()): div.text(',')

        morphed = items.pop("morphedChains", None)
        if morphed:
            div.text(' ')
            div.span('closed').text("morphed %d comment%s" % (morphed, morphed > 1 and "s" or ""))

            if any(items.values()): div.text(',')

        div.text(' ')
        buttons = div.span("buttons")
        buttons.button(onclick='previewChanges();').text("Preview")
        buttons.button(onclick='submitChanges();').text("Submit")
        buttons.button(onclick='cancelChanges();').text("Abort")

        return True
    else:
        return False

def addReviewFilters(db, creator, user, review, reviewer_paths, watcher_paths):
    cursor = db.cursor()

    cursor.execute("INSERT INTO reviewassignmentstransactions (review, assigner) VALUES (%s, %s) RETURNING id", (review.id, creator.id))
    transaction_id = cursor.fetchone()[0]

    def add(filter_type, paths):
        for path in paths:
            cursor.execute("""SELECT id, type
                                FROM reviewfilters
                               WHERE review=%s
                                 AND uid=%s
                                 AND path=%s""",
                           (review.id, user.id, path))

            row = cursor.fetchone()

            if row:
                old_filter_id, old_filter_type = row

                if old_filter_type == filter_type:
                    continue
                else:
                    cursor.execute("""DELETE FROM reviewfilters
                                            WHERE id=%s""",
                                   (old_filter_id,))
                    cursor.execute("""INSERT INTO reviewfilterchanges (transaction, uid, path, type, created)
                                           VALUES (%s, %s, %s, %s, false)""",
                                   (transaction_id, user.id, path, old_filter_type))

            cursor.execute("""INSERT INTO reviewfilters (review, uid, path, type, creator)
                                   VALUES (%s, %s, %s, %s, %s)""",
                           (review.id, user.id, path, filter_type, creator.id))
            cursor.execute("""INSERT INTO reviewfilterchanges (transaction, uid, path, type, created)
                                   VALUES (%s, %s, %s, %s, true)""",
                           (transaction_id, user.id, path, filter_type))

    add("reviewer", reviewer_paths)
    add("watcher", watcher_paths)

    filters = Filters()
    filters.setFiles(db, review=review)
    filters.load(db, review=review, user=user)

    if user not in review.reviewers and user not in review.watchers and user not in review.owners:
        cursor.execute("""INSERT INTO reviewusers (review, uid, type)
                          VALUES (%s, %s, 'manual')""",
                       (review.id, user.id,))

    delete_files = set()
    insert_files = set()

    if watcher_paths:
        # Unassign changes currently assigned to the affected user.
        cursor.execute("""SELECT reviewfiles.id, reviewfiles.file
                            FROM reviewfiles
                            JOIN reviewuserfiles ON (reviewuserfiles.file=reviewfiles.id)
                           WHERE reviewfiles.review=%s
                             AND reviewuserfiles.uid=%s""",
                       (review.id, user.id))

        for review_file_id, file_id in cursor:
            if not filters.isReviewer(user.id, file_id):
                delete_files.add(review_file_id)

    if reviewer_paths:
        # Assign changes currently not assigned to the affected user.
        cursor.execute("""SELECT reviewfiles.id, reviewfiles.file
                            FROM reviewfiles
                            JOIN changesets ON (changesets.id=reviewfiles.changeset)
                            JOIN commits ON (commits.id=changesets.child)
                            JOIN gitusers ON (gitusers.id=commits.author_gituser)
                 LEFT OUTER JOIN usergitemails ON (usergitemails.email=gitusers.email
                                               AND usergitemails.uid=%s)
                 LEFT OUTER JOIN reviewuserfiles ON (reviewuserfiles.file=reviewfiles.id
                                                 AND reviewuserfiles.uid=%s)
                           WHERE reviewfiles.review=%s
                             AND usergitemails.uid IS NULL
                             AND reviewuserfiles.uid IS NULL""",
                       (user.id, user.id, review.id))

        for review_file_id, file_id in cursor:
            if filters.isReviewer(user.id, file_id):
                insert_files.add(review_file_id)

    if delete_files:
        cursor.executemany("DELETE FROM reviewuserfiles WHERE file=%s AND uid=%s",
                           izip(delete_files, repeat(user.id)))
        cursor.executemany("INSERT INTO reviewassignmentchanges (transaction, file, uid, assigned) VALUES (%s, %s, %s, false)",
                           izip(repeat(transaction_id), delete_files, repeat(user.id)))

    if insert_files:
        cursor.executemany("INSERT INTO reviewuserfiles (file, uid) VALUES (%s, %s)",
                           izip(insert_files, repeat(user.id)))
        cursor.executemany("INSERT INTO reviewassignmentchanges (transaction, file, uid, assigned) VALUES (%s, %s, %s, true)",
                           izip(repeat(transaction_id), insert_files, repeat(user.id)))

    return generateMailsForAssignmentsTransaction(db, transaction_id)

def parseReviewFilters(db, data):
    reviewfilters = []

    for filter_data in data:
        filter_user = dbutils.User.fromName(db, filter_data["username"])
        filter_type = filter_data["type"]
        filter_path = reviewing.filters.sanitizePath(filter_data["path"])

        # Make sure the path doesn't contain any invalid wild-cards.
        try:
            reviewing.filters.validatePattern(filter_path)
        except reviewing.filters.PatternError as error:
            raise OperationFailure(code="invalidpattern",
                                   title="Invalid filter pattern",
                                   message="Problem: %s" % error.message)

        reviewfilters.append((filter_user.id, filter_path, filter_type, None))

    return reviewfilters

def parseRecipientFilters(db, data):
    mode = data.get("mode", "opt-out")
    included = data.get("included", [])
    excluded = data.get("excluded", [])

    recipientfilters = []

    if mode == "opt-in":
        recipientfilters.append((None, False))
        filter_usernames = included
        filter_include = True
    else:
        filter_usernames = excluded
        filter_include = False

    for filter_username in filter_usernames:
        filter_user = dbutils.User.fromName(db, filter_username)
        if not filter_user:
            raise OperationError("no such user: '%s'" % filter_username)
        recipientfilters.append((filter_user.id, filter_include))

    return recipientfilters

def queryFilters(db, user, review, globalfilters=False, parentfilters=False):
    cursor = db.cursor()

    if globalfilters:
        cursor.execute("UPDATE reviews SET applyfilters=TRUE WHERE id=%s", (review.id,))
        review.applyfilters = True
    if parentfilters:
        cursor.execute("UPDATE reviews SET applyparentfilters=TRUE WHERE id=%s", (review.id,))
        review.applyparentfilters = True

    cursor.execute("""SELECT changeset
                        FROM reviewchangesets
                       WHERE review=%s""",
                   (review.id,))

    # TODO: This two-phase creation of Changeset objects is a bit silly.
    changesets = [diff.Changeset.fromId(db, review.repository, changeset_id)
                  for (changeset_id,) in cursor]
    changeset_load.loadChangesets(
        db, review.repository, changesets, load_chunks=False)

    return assignChanges(db, user, review, changesets=changesets, update=True)

def applyFilters(db, user, review, globalfilters=False, parentfilters=False):
    new_reviewers, new_watchers = queryFilters(db, user, review, globalfilters, parentfilters)

    pending_mails = []
    cursor = db.cursor()

    for user_id in new_reviewers:
        new_reviewer = dbutils.User.fromId(db, user_id)

        cursor.execute("""SELECT reviewfiles.file, SUM(reviewfiles.deleted), SUM(reviewfiles.inserted)
                            FROM reviewfiles
                            JOIN reviewuserfiles ON (reviewuserfiles.file=reviewfiles.id)
                           WHERE reviewfiles.review=%s
                             AND reviewuserfiles.uid=%s
                        GROUP BY reviewfiles.file""",
                       (review.id, user_id))

        pending_mails.extend(mail.sendFiltersApplied(
                db, user, new_reviewer, review, globalfilters, parentfilters, cursor.fetchall()))

    for user_id in new_watchers:
        new_watcher = dbutils.User.fromId(db, user_id)
        pending_mails.extend(mail.sendFiltersApplied(
                db, user, new_watcher, review, globalfilters, parentfilters, None))

    review.incrementSerial(db)

    db.commit()

    mail.sendPendingMails(pending_mails)

def generateMailsForBatch(db, batch_id, was_accepted, is_accepted, profiler=None):
    cursor = db.cursor()
    cursor.execute("SELECT review, uid FROM batches WHERE id=%s", (batch_id,))

    review_id, user_id = cursor.fetchone()

    review = dbutils.Review.fromId(db, review_id)
    from_user = dbutils.User.fromId(db, user_id)

    pending_mails = []

    recipients = review.getRecipients(db)
    for to_user in recipients:
        pending_mails.extend(mail.sendReviewBatch(db, from_user, to_user, recipients, review, batch_id, was_accepted, is_accepted, profiler=profiler))

    return pending_mails

def generateMailsForAssignmentsTransaction(db, transaction_id):
    cursor = db.cursor()
    cursor.execute("SELECT review, assigner, note FROM reviewassignmentstransactions WHERE id=%s", (transaction_id,))

    review_id, assigner_id, note = cursor.fetchone()

    review = dbutils.Review.fromId(db, review_id)
    assigner = dbutils.User.fromId(db, assigner_id)

    cursor.execute("""SELECT uid, path, type, created
                        FROM reviewfilterchanges
                       WHERE transaction=%s""",
                   (transaction_id,))

    by_user = {}

    for reviewer_id, path, filter_type, created in cursor:
        added_filters, removed_filters, unassigned, assigned = by_user.setdefault(reviewer_id, ([], [], [], []))
        if created: added_filters.append((filter_type, path or "/"))
        else: removed_filters.append((filter_type, path or "/"))

    cursor.execute("""SELECT reviewassignmentchanges.uid, reviewassignmentchanges.assigned, reviewfiles.file, SUM(reviewfiles.deleted), SUM(reviewfiles.inserted)
                        FROM reviewfiles
                        JOIN reviewassignmentchanges ON (reviewassignmentchanges.file=reviewfiles.id)
                       WHERE reviewassignmentchanges.transaction=%s
                    GROUP BY reviewassignmentchanges.uid, reviewassignmentchanges.assigned, reviewfiles.file""",
                   (transaction_id,))

    for reviewer_id, was_assigned, file_id, deleted, inserted in cursor:
        added_filters, removed_filters, unassigned, assigned = by_user.setdefault(reviewer_id, (None, None, [], []))

        if was_assigned: assigned.append((file_id, deleted, inserted))
        else: unassigned.append((file_id, deleted, inserted))

    pending_mails = []

    for reviewer_id, (added_filters, removed_filters, unassigned, assigned) in by_user.items():
        reviewer = dbutils.User.fromId(db, reviewer_id)
        if assigner != reviewer:
            pending_mails.extend(mail.sendAssignmentsChanged(db, assigner, reviewer, review, added_filters, removed_filters, unassigned, assigned))

    return pending_mails

def retireUser(db, user):
    cursor = db.cursor()

    # Set the user's status to 'retired'.
    cursor.execute("""UPDATE users
                         SET status='retired'
                       WHERE id=%s""",
                   (user.id,))

    # Delete any assignments of unreviewed (pending) changes to the user.  We're
    # leaving assignments of reviewed changes in-place; no particular need to
    # drop historical data.
    #
    # Deleting even this risks dropping some historical data, specifically
    # changes involving files being marked as reviewed, and then unmarked again.
    # But having "active" assignments to users that aren't going to review them
    # complicates a whole bunch of queries, so to keep things simple, we can
    # sacrifice a little history.
    cursor.execute("""DELETE FROM reviewuserfiles
                            USING reviewfiles
                            WHERE reviewuserfiles.uid=%s
                              AND reviewuserfiles.file=reviewfiles.id
                              AND reviewfiles.state='pending'""",
                   (user.id,))

########NEW FILE########
__FILENAME__ = clexer
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2012 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

# Simple C/C++ lexer
#
# Module Contents
# ===============
#
# split(source[, include_ws=True, include_comments=True])
#
#   Returns an iterator that returns the tokens in the C/C++ source as
#   individual strings.  If 'include_ws' is true, sequences of whitespace
#   (including linebreaks) separating tokens are returned as well.  If
#   'include_comments' is true, comments are returned as individual tokens as
#   well.
#
#   Preprocessor lines are returned as single tokens, starting with the first
#   character of the line and ending before the linebreak character that ends
#   the preprocessor directive; including any backslashes and linebreak
#   characters following backslashes.
#
#   Character and string literal tokens are returned exactly as they occurred in
#   the source string, with any escape sequences (including escaped linebreaks)
#   preserved.
#
#   Escaped linebreaks outside of preprocessor directives and string literals
#   are not handled; in practice the backslash will vanish and the linebreak
#   will be returned as a whitespace token (possibly combined with any following
#   whitespace.)  If whitespace preceded the backslash, there will be two
#   separate whitespace tokens, split where the backslash was.
#
# tokenize(tokens[, filename="<unknown>"])
#
#   Returns an iterator that returns each string returned by the iterable
#   'tokens' converted into a Token object.  The token's have line and column
#   numbers calculated assuming that the token sequence contains all tokens and
#   whitespace sequences from a single file.  If not, the line and column
#   numbers will not be correct.  The supplied 'filename' is also stored in each
#   token.
#
# group(tokens[, groups={ '(':')', '{':'}', '[':']' }])
#
#   Returns a list containing all tokens returned by the iterable 'tokens',
#   grouped into sublists according to 'groups', which should be a dictionary
#   mapping group start tokens to group end tokens.
#
#   Each sublist created will start with a token from the set of keys in
#   'groups' and end with the corresponding end token.  Every token returned by
#   the iterable 'tokens' will occur exactly once in the tree of lists returned
#   by this function.
#
#   Throws a CLexerException if an unexpected group end token is encountered, or
#   if the sequence of tokens ends inside a group.
#
# group1(tokens, end[, groups={ '(':')', '{':'}', '[':']' }])
#
#   Like group(), but returns a tuple containing a single group (ending with the
#   token 'end') and the actual token ending the group (since it's not included
#   in the group.)  Typically 'tokens' will be an iterator that has just
#   returned the corresponding start token.  Upon return, if 'tokens' is an
#   iterator, it will just have returned a token identical to 'end'.
#
#   The returned list contains neither the group start or end token, and is
#   grouped as if group() had been used to group that particular sequence of
#   tokens.  (It is necessary to do this grouping anyway to identify the token
#   that actually ends the group while ignoring sub-groupings using the same
#   pair of start/end tokens.)
#
# partition(tokens, separator)
#
#   Splits the sequence of tokens returned by the iterable 'tokens' by the token
#   'separator'.  Normally, the token sequence 'tokens' should be grouped using
#   group() first, so that occurrences of 'separator' inside groups are ignored.
#   The return value is a list of lists of tokens (or lists as created by
#   group()).
#
#   If 'tokens' returns zero tokens, an empty list is returned.
#
# flatten(tokens)
#
#   Returns an iterator that returns each token returned by the iterable
#   'tokens' while reversing the type of grouping done by group()/group1().
#
#   This means that flatten(group(tokens)) is a no-op.
#
# join(tokens[, insertSpaces=True])
#
#   Returns a string produced by concatenating all tokens returned by the
#   iterable 'tokens'.  If 'insertSpaces' is true, a single space is inserted
#   between each token unless there was whitespace strings in the token sequence
#   there already.  Automatically flattens the token sequence first.
#
# CLexerException
#
#   Exception type thrown by the functions group() and group1().  Inherits
#   the built-in Exception type and adds absolutely nothing.
#
# Token Objects
# =============
#
# Token objects are created by the function tokenize(), but can also be
# constructed manually using the constructor
#
# Token(value[, filename="<unknown>", line=0, column=0])
#
# Token instances are comparable, hashable, are true (non-zero) unless they
# represent whitespace or comments, and can be converted back to string form by
# str().  In addition they support the following methods:
#
# filename()
#
#   Returns the filename from which the token stems.  In practice, either the
#   filename passed to tokenize() or to the Token constructor.
#
# line()
#
#   Returns the line number (first line=1) at which the token occurred.
#
# column()
#
#   Returns the column number (first column=0) at which the token occurred.
#
# isidentifier()
#
#   Returns true if the token is an identifier.
#
# isspace()
#
#   Returns true if the token is whitespace.
#
# iscomment()
#
#   Returns true if the token is a comment.
#
# isppdirective()
#
#   Returns true if the token is a preprocessor directive.
#
# reduced()
#
#   Returns a string where special tokens (whitespace, comments and preprocessor
#   directives) are converted to the shortest possible sequence of whitespace
#   that preserves the line and column number of following tokens.

import re
import sys
import itertools
import traceback

def rejoin(items, escape):
    if escape:
        fixed = []
        for item in sorted(items, key=len, reverse=True):
            for ch in "(){}[]*+?|.^$": item = item.replace(ch, "\\" + ch)
            fixed.append(item)
        items = fixed
    return "|".join(items)

OPERATORS_AND_PUNCTUATORS = [ "(", ")", "{", "}", "[", "]", "<", ">", "<=", ">=", "<<", ">>", "<<=", ">>=",
                              "+", "-", "*", "/", "%", "+=", "-=", "*=", "/=", "%=", "&&", "||",
                              "&", "|", "^", "!", ",", ".", "::", ":", ";", "=", "==", "!=",
                              "&=", "|=", "^=", "++", "--", "~", "?", "->", "->*", ".*", "##", "#" ];

KEYWORDS = set([ "asm", "do", "if", "return", "typedef",
                 "auto", "double", "inline", "short", "typeid",
                 "bool", "dynamic_cast", "int", "signed", "typename",
                 "break", "else", "long", "sizeof", "union",
                 "case", "enum", "mutable", "static", "unsigned",
                 "catch", "explicit", "namespace", "static_cast", "using",
                 "char", "export", "new", "struct", "virtual",
                 "class", "extern", "operator", "switch", "void",
                 "const", "false", "private", "template", "volatile",
                 "const_cast", "float", "protected", "this", "wchar_t",
                 "continue", "for", "public", "throw", "while",
                 "default", "friend", "register", "true",
                 "delete", "goto", "reinterpret_cast", "try" ])

CONFLICT_MARKER = "^(?:<<<<<<<|=======|>>>>>>>)[^\n]*$"
INT_LITERAL = "(?:0|[1-9][0-9]*|0x[0-9a-fA-F]+)[lLuU]*(?![0-9a-zA-Z_\\.])"
FLOAT_LITERAL = "(?:(?:[0-9]*\\.[0-9]+|[0-9]+\\.)(?:[eE][+-]?[0-9]+)?|[0-9]+[eE][+-]?[0-9]+)[fFlL]*(?![0-9a-zA-Z_])"
IDENTIFIER = "[a-zA-Z_][a-zA-Z0-9_]*"
MULTILINE_COMMENT = "/\\*.*?\\*/"
SINGLELINE_COMMENT = "//.*?(?=\n|$)"
STRING_LITERAL = '"(?:\\\\.|[^"\n])*"'
CHARACTER_LITERAL = "'(?:\\\\.|[^'\n])*'"
WIDE_STRING_LITERAL = 'L"(?:\\\\.|[^"\n])*"'
WIDE_CHARACTER_LITERAL = "L'(?:\\\\.|[^'\n])*'"
PREPROCESSOR_DIRECTIVE = "^[ \t]*#(?:%s|%s|%s|%s|%s|%s|\\\\\n|[^\n])*" % (MULTILINE_COMMENT, SINGLELINE_COMMENT, STRING_LITERAL, CHARACTER_LITERAL, WIDE_STRING_LITERAL, WIDE_CHARACTER_LITERAL)
OPERATOR_OR_PUNCTUATOR = rejoin(OPERATORS_AND_PUNCTUATORS, escape=True)
WHITESPACE = "\\s+"

SUBPATTERNS = [FLOAT_LITERAL, INT_LITERAL, WIDE_STRING_LITERAL, WIDE_CHARACTER_LITERAL, IDENTIFIER, MULTILINE_COMMENT, SINGLELINE_COMMENT, PREPROCESSOR_DIRECTIVE, STRING_LITERAL, CHARACTER_LITERAL]

RE_CTOKENS = re.compile(rejoin([CONFLICT_MARKER, IDENTIFIER, FLOAT_LITERAL, MULTILINE_COMMENT, SINGLELINE_COMMENT, PREPROCESSOR_DIRECTIVE, OPERATOR_OR_PUNCTUATOR, INT_LITERAL, STRING_LITERAL, CHARACTER_LITERAL, "."], escape=False), re.DOTALL | re.MULTILINE)
RE_CTOKENS_INCLUDE_WS = re.compile(rejoin([CONFLICT_MARKER, IDENTIFIER, FLOAT_LITERAL, MULTILINE_COMMENT, SINGLELINE_COMMENT, PREPROCESSOR_DIRECTIVE, OPERATOR_OR_PUNCTUATOR, INT_LITERAL, STRING_LITERAL, CHARACTER_LITERAL, WHITESPACE, "."], escape=False), re.DOTALL | re.MULTILINE)

RE_IDENTIFIER = re.compile(IDENTIFIER)
RE_INT_LITERAL = re.compile("^" + INT_LITERAL + "$")
RE_FLOAT_LITERAL = re.compile("^" + FLOAT_LITERAL + "$")

class CLexerException(Exception):
    def __init__(self, message):
        Exception.__init__(self, message)

class CLexerGroupingException(Exception):
    def __init__(self, message, tokens):
        Exception.__init__(self, message)
        self.__tokens = tokens

    def tokens(self):
        return self.__tokens

def iskeyword(value): return (str(value)[0].isalpha() or str(value)[0] == "_") and str(value) in KEYWORDS
def isidentifier(value): return (str(value)[0].isalpha() or str(value)[0] == "_") and str(value) not in KEYWORDS
def isspace(value): return str(value).isspace()
def iscomment(value): return str(value)[0:2] in ("/*", "//")
def isppdirective(value): return str(value).lstrip(" \t").startswith("#")
def isconflictmarker(value):
    value = str(value)
    return value.startswith("<<<<<<<") or value.startswith("=======") or value.startswith(">>>>>>>")
def isint(value): return RE_INT_LITERAL.match(str(value)) is not None
def isfloat(value): return RE_FLOAT_LITERAL.match(str(value)) is not None

def split(input, include_ws=True, include_comments=True):
    if include_ws: expression = RE_CTOKENS_INCLUDE_WS
    else: expression = RE_CTOKENS
    tokens = itertools.imap(lambda match: match.group(0), expression.finditer(input))
    if include_comments: return tokens
    else: return itertools.ifilter(lambda token: not iscomment(token), tokens)

class Token:
    def __init__(self, value, filename="<unknown>", line=0, column=0):
        self.__value = value
        self.__filename = filename
        self.__line = line
        self.__column = column

    def __cmp__(self, other):
        return cmp(self.__value, other)

    def __str__(self):
        return self.__value

    def __repr__(self):
        return repr(self.__value)

    def __hash__(self):
        return hash(self.__value)

    def __nonzero__(self):
        return not (self.isspace() or self.iscomment())

    def filename(self): return self.__filename
    def line(self): return self.__line
    def column(self): return self.__column

    def iskeyword(self): return iskeyword(self.__value)
    def isidentifier(self): return isidentifier(self.__value)
    def isspace(self): return isspace(self.__value)
    def iscomment(self): return iscomment(self.__value)
    def isppdirective(self): return isppdirective(self.__value)
    def isconflictmarker(self): return isconflictmarker(self.__value)
    def isstring(self): return self.__value[0] == '"' or self.__value.startswith('L"')
    def ischar(self): return self.__value[0] == "'" or self.__value.startswith("L'")
    def isint(self): return isint(self.__value)
    def isfloat(self): return isfloat(self.__value)

    def reduced(self):
        if self.isspace() or self.iscomment():
            if self.__value.startswith("//"): return ""
            else:
                linebreaks = self.__value.count("\n")
                if linebreaks:
                    last = self.__value.rindex("\n")
                    return "\n" * linebreaks + " " * (len(self.__value) - last - 1)
                else:
                    return " " * len(self.__value)
        elif self.isppdirective():
            return "\n" * self.__value.count("\n")
        else:
            return self.__value

def tokenize(tokens, filename="<unknown>"):
    line = 1
    column = 0

    for token in tokens:
        if isinstance(token, Token):
            yield token
            token = str(token)
        else: yield Token(token, filename, line, column)

        linebreaks = token.count("\n")
        if linebreaks:
            line += linebreaks
            column = len(token) - 1 - token.rindex("\n")
        else:
            column += len(token)

def locate(tokens, index):
    line = 1
    column = 0

    for token_index, token in enumerate(flatten(tokens)):
        if index == token_index: break
        linebreaks = token.count("\n")
        if linebreaks:
            line += linebreaks
            column = len(token) - 1 - token.rindex("\n")
        else:
            column += len(token)

    return line, column

DEFAULT_GROUP = {'(': ')', '{': '}', '[': ']'}
DEFAULT_GROUP_REVERSE = {')': '(', '}': '{', ']': '['}

def group(tokens, groups=None):
    if groups is None:
        groups = DEFAULT_GROUP
        reverse = DEFAULT_GROUP_REVERSE
    else:
        reverse = dict([(end, start) for start, end in groups.items()])

    stack = [('<EOF>', [], -1)]
    currentEnd = stack[-1][0]
    currentList = stack[-1][1]

    for index, token in enumerate(tokens):
        if token in groups:
            stack.append((groups[token], [token], index))
            currentList = stack[-1][1]
            currentEnd = stack[-1][0]
        elif token == currentEnd:
            currentList.append(token)
            stack.pop()
            stack[-1][1].append(currentList)
            currentEnd = stack[-1][0]
            currentList = stack[-1][1]
        elif token in reverse:
            if isinstance(token, Token):
                line, column = token.line(), token.column()
            else:
                line, column = locate(tokens, index)
            raise CLexerException("%d:%d: expected '%s', got '%s'" % (line, column, currentEnd, token))
        else:
            currentList.append(token)

    if len(stack) > 1:
        token = stack[-1][1][0]
        if isinstance(token, Token):
            line, column = token.line(), token.column()
        else:
            line, column = locate(tokens, stack[-1][2])
        raise CLexerException("%d:%d: unmatched group opener '%s'" % (line, column, token))

    return currentList

def group1(iterable, end, groups=None):
    if groups is None:
        groups = DEFAULT_GROUP
        reverse = DEFAULT_GROUP_REVERSE
    else:
        reverse = dict([(end, start) for start, end in groups.items()])

    stack = [('<EOF>', [])]
    currentEnd = stack[-1][0]
    currentList = stack[-1][1]

    for token in iterable:
        if token in groups:
            stack.append((groups[token], [token]))
            currentList = stack[-1][1]
            currentEnd = stack[-1][0]
        elif token == end and len(stack) == 1:
            return currentList, token
        elif token == currentEnd:
            stack.pop()
            currentList.append(token)
            stack[-1][1].append(currentList)
            currentEnd = stack[-1][0]
            currentList = stack[-1][1]
        elif token in reverse:
            currentList.append(token)
            while len(stack) > 1:
                stack.pop()
                stack[-1][1].append(currentList)
                currentList = stack[-1][1]
            raise CLexerGroupingException("expected '%s', got '%s'" % (currentEnd, token), flatten(currentList))
        else:
            currentList.append(token)

    while len(stack) > 1:
        stack.pop()
        stack[-1][1].append(currentList)
        currentList = stack[-1][1]

    token = stack[-1][1][0]

    raise CLexerGroupingException("unmatched group opener '%s'" % token, list(flatten(currentList)))

def partition(tokens, separator):
    current = []
    partitions = [current]
    try:
        tokens = iter(tokens)
        while True:
            token = tokens.next()
            if token == separator:
                current = []
                partitions.append(current)
            else:
                current.append(token)
    except StopIteration:
        if len(partitions) == 1 and not partitions[0]: return []
        else: return partitions

def flatten(tokens):
    tokens = iter(tokens)

    try:
        while True:
            token = tokens.next()
            if isinstance(token, list):
                tokens = itertools.chain(token, tokens)
            else:
                yield token
    except StopIteration:
        pass

def join(tokens, insertSpaces=True):
    if insertSpaces:
        result = ""
        lastWasSpace = True
        for token in flatten(tokens):
            if not lastWasSpace and not token.isspace(): result += " "
            result += str(token)
            lastWasSpace = token.isspace()
        return result
    else:
        return "".join(itertools.imap(str, flatten(tokens)))

# Run regression tests if we're the main script and not being imported as a module.
if __name__ == "__main__":
    # The token expression does not match whitespace.
    assert not RE_CTOKENS.match(" ")
    assert not RE_CTOKENS.match("\t")
    assert not RE_CTOKENS.match("\r")
    assert not RE_CTOKENS.match("\n")

    def testToken(token, subpattern, rest="", isOperator=False):
        wholeMatch = RE_CTOKENS.match(token)
        assert wholeMatch
        assert wholeMatch.group(0) + rest == token

        subMatch = re.match(subpattern, token, re.DOTALL | re.MULTILINE)
        assert subMatch
        assert subMatch.group(0) + rest == token

        for other in SUBPATTERNS:
            if other != subpattern and not (isOperator and other == PREPROCESSOR_DIRECTIVE and (token == "#" or token == "##")):
                assert not re.match(other, token, re.DOTALL | re.MULTILINE)

    for operatorOrPunctuator in OPERATORS_AND_PUNCTUATORS:
        testToken(operatorOrPunctuator, OPERATOR_OR_PUNCTUATOR, isOperator=True)

    testToken("0", INT_LITERAL)
    testToken("0u", INT_LITERAL)
    testToken("0l", INT_LITERAL)
    testToken("0ul", INT_LITERAL)
    testToken("0lu", INT_LITERAL)

    testToken("1", INT_LITERAL)
    testToken("4711", INT_LITERAL)

    testToken("0x0", INT_LITERAL)
    testToken("0xffffu", INT_LITERAL)

    testToken("0.", FLOAT_LITERAL)
    testToken("123.f", FLOAT_LITERAL)
    testToken("123.f", FLOAT_LITERAL)
    testToken("123.l", FLOAT_LITERAL)
    testToken("123.e1", FLOAT_LITERAL)
    testToken("123.e1f", FLOAT_LITERAL)
    testToken("123.e1l", FLOAT_LITERAL)
    testToken(".0", FLOAT_LITERAL)
    testToken(".123", FLOAT_LITERAL)
    testToken(".123f", FLOAT_LITERAL)
    testToken(".123l", FLOAT_LITERAL)
    testToken(".123e1", FLOAT_LITERAL)
    testToken(".123e1f", FLOAT_LITERAL)
    testToken(".123e1l", FLOAT_LITERAL)
    testToken("0.0", FLOAT_LITERAL)
    testToken("123.123", FLOAT_LITERAL)
    testToken("123.123f", FLOAT_LITERAL)
    testToken("123.123l", FLOAT_LITERAL)
    testToken("123.123e1", FLOAT_LITERAL)
    testToken("123.123e1f", FLOAT_LITERAL)
    testToken("123.123e1l", FLOAT_LITERAL)
    testToken("0e1", FLOAT_LITERAL)
    testToken("123e1", FLOAT_LITERAL)
    testToken("123e1f", FLOAT_LITERAL)
    testToken("123e1l", FLOAT_LITERAL)
    testToken("123e100", FLOAT_LITERAL)
    testToken("123e+100", FLOAT_LITERAL)
    testToken("123e-100", FLOAT_LITERAL)

    testToken("i", IDENTIFIER)
    testToken("this_or_that", IDENTIFIER)
    testToken("_", IDENTIFIER)
    testToken("__i", IDENTIFIER)
    testToken("i1", IDENTIFIER)

    testToken("/**/", MULTILINE_COMMENT)
    testToken("/***/", MULTILINE_COMMENT)
    testToken("/****/", MULTILINE_COMMENT)
    testToken("/*****/", MULTILINE_COMMENT)
    testToken("/*foo*/", MULTILINE_COMMENT)
    testToken("/*foo\nfoo\nfoo*/", MULTILINE_COMMENT)

    testToken("//", SINGLELINE_COMMENT)
    testToken("///", SINGLELINE_COMMENT)
    testToken("////", SINGLELINE_COMMENT)
    testToken("//foo", SINGLELINE_COMMENT)
    testToken("//\n", SINGLELINE_COMMENT, "\n")
    testToken("///\n", SINGLELINE_COMMENT, "\n")
    testToken("////\n", SINGLELINE_COMMENT, "\n")
    testToken("//bar\n", SINGLELINE_COMMENT, "\n")

    testToken("#", PREPROCESSOR_DIRECTIVE)
    testToken("#foo", PREPROCESSOR_DIRECTIVE)
    testToken(" #", PREPROCESSOR_DIRECTIVE)
    testToken(" #foo", PREPROCESSOR_DIRECTIVE)
    testToken("#\n", PREPROCESSOR_DIRECTIVE, "\n")
    testToken("#foo\n", PREPROCESSOR_DIRECTIVE, "\n")
    testToken(" #\n", PREPROCESSOR_DIRECTIVE, "\n")
    testToken(" #foo\n", PREPROCESSOR_DIRECTIVE, "\n")

    testToken('""', STRING_LITERAL)
    testToken('"foo"', STRING_LITERAL)
    testToken('"\\"\\"\\""', STRING_LITERAL)

    testToken("''", CHARACTER_LITERAL)
    testToken("'foo'", CHARACTER_LITERAL)
    testToken("'\\'\\'\\''", CHARACTER_LITERAL)

########NEW FILE########
__FILENAME__ = context
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2012 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import os

import syntaxhighlight
import configuration

def importCodeContexts(db, sha1, language):
    codecontexts_path = syntaxhighlight.generateHighlightPath(sha1, language) + ".ctx"

    if os.path.isfile(codecontexts_path):
        contexts_values = []

        for line in open(codecontexts_path):
            line = line.strip()

            first_line, last_line, context = line.split(" ", 2)
            if len(context) > configuration.services.HIGHLIGHT["max_context_length"]:
                context = context[:configuration.services.HIGHLIGHT["max_context_length"] - 3] + "..."
            contexts_values.append((sha1, context, int(first_line), int(last_line)))

        cursor = db.cursor()
        cursor.execute("DELETE FROM codecontexts WHERE sha1=%s", [sha1])
        cursor.executemany("INSERT INTO codecontexts (sha1, context, first_line, last_line) VALUES (%s, %s, %s, %s)", contexts_values)
        db.commit()

        os.unlink(codecontexts_path)

        return len(contexts_values)
    else:
        return 0

########NEW FILE########
__FILENAME__ = cpp
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2012 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import syntaxhighlight
import syntaxhighlight.clexer
import htmlutils
import configuration

class HighlightCPP:
    def highlightToken(self, token):
        if token.iskeyword():
            self.output.write("<b class='kw'>" + str(token) + "</b>")
        elif token.isidentifier():
            self.output.write("<b class='id'>" + str(token) + "</b>")
        elif token.iscomment():
            if str(token)[0:2] == "/*":
                lines = str(token).splitlines()
                self.output.write("\n".join(["<b class='com'>" + htmlutils.htmlify(line) + "</b>" for line in lines]))
            else:
                self.output.write("<b class='com'>" + htmlutils.htmlify(token) + "</b>")
        elif token.isppdirective():
            lines = str(token).split("\n")
            self.output.write("\n".join(["<b class='pp'>" + htmlutils.htmlify(line) + "</b>" for line in lines]))
        elif token.isspace():
            self.output.write(str(token))
        elif token.isconflictmarker():
            self.output.write(htmlutils.htmlify(token))
        else:
            if str(token)[0] == '"':
                self.output.write("<b class='str'>" + htmlutils.htmlify(token) + "</b>")
            elif str(token)[0] == "'":
                self.output.write("<b class='ch'>" + htmlutils.htmlify(token) + "</b>")
            elif token.isfloat():
                self.output.write("<b class='fp'>" + str(token) + "</b>")
            elif token.isint():
                self.output.write("<b class='int'>" + str(token) + "</b>")
            else:
                self.output.write("<b class='op'>" + htmlutils.htmlify(token) + "</b>")

    def outputContext(self, tokens, terminator):
        if not self.contexts: return

        def spaceBetween(first, second):
            # Never insert spaces around the :: operator.
            if first == '::' or second == '::':
                return False

            # Always a space after a comma.
            if first == ',':
                return True

            # Always a space before a keyword or identifier, unless preceded by *, & or (.
            if second.iskeyword() or second.isidentifier():
                return str(first) not in ('*', '&', '(')

            # Always a space before a * or &, unless preceded by (another) *.
            if (second == '*' or second == '&') and first != '*':
                return True

            # Always spaces around equal signs.
            if first == '=' or second == '=':
                return True

            # No spaces between by default.
            return False

        first_line = tokens[-1].line() + 1
        last_line = terminator.line()

        if last_line - first_line >= configuration.services.HIGHLIGHT["min_context_length"]:
            previous = tokens[0]
            context = str(previous)

            for token in tokens[1:]:
                if token.isspace() or token.iscomment(): continue
                if spaceBetween(previous, token): context += " "
                context += str(token)
                previous = token

            self.contexts.write("%d %d %s\n" % (first_line, last_line, context))

    def processTokens(self, tokens):
        currentContexts = []
        nextContext = []
        nextContextClosed = False
        level = 0

        for token in tokens:
            self.highlightToken(token)

            if token.isspace() or token.iscomment() or token.isppdirective() or token.isconflictmarker():
                pass
            elif token.iskeyword():
                if str(token) in ("if", "else", "for", "while", "do", "switch", "return", "break", "continue"):
                    nextContext = None
                    nextContextClosed = True
                elif not nextContextClosed:
                    nextContext.append(token)
            elif token.isidentifier():
                if not nextContextClosed:
                    nextContext.append(token)
            elif token == '{':
                if nextContext:
                    currentContexts.append([nextContext, level])
                    nextContext = []
                    nextContextClosed = False
                level += 1
            elif token == '}':
                level -= 1
                if currentContexts and currentContexts[-1][1] == level:
                    thisContext = currentContexts.pop()
                    self.outputContext(thisContext[0], token)
                nextContext = []
                nextContextClosed = False
            elif nextContext:
                if token == ',' and not nextContextClosed:
                    nextContext = None
                    nextContextClosed = True
                elif token == ':':
                    nextContextClosed = True
                elif token == ';':
                    nextContext = []
                    nextContextClosed = False
                elif token == '(':
                    if not nextContextClosed:
                        nextContext.append(token)
                        try:
                            group, token = syntaxhighlight.clexer.group1(tokens, ')')
                            group = list(syntaxhighlight.clexer.flatten(group)) + [token]
                            nextContext.extend(group)
                            for token in group: self.highlightToken(token)
                        except syntaxhighlight.clexer.CLexerGroupingException as error:
                            for token in error.tokens(): self.highlightToken(token)
                            nextContext = []
                            nextContextClosed = False
                elif not nextContextClosed:
                    nextContext.append(token)

    def __call__(self, source, output, contexts_path):
        source = source.encode("utf-8")
        self.output = output
        if contexts_path: self.contexts = open(contexts_path, "w")
        else: self.contexts = None
        self.processTokens(syntaxhighlight.clexer.tokenize(syntaxhighlight.clexer.split(source)))
        if contexts_path: self.contexts.close()

    @staticmethod
    def create(language):
        if language == "c++": return HighlightCPP()
        else: return None

syntaxhighlight.LANGUAGES.add("c++")

########NEW FILE########
__FILENAME__ = generate
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2012 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import os
import errno

import syntaxhighlight
import gitutils
import textutils

def createHighlighter(language):
    import cpp
    highlighter = cpp.HighlightCPP.create(language)
    if highlighter: return highlighter

    import generic
    highlighter = generic.HighlightGeneric.create(language)
    if highlighter: return highlighter

def generateHighlight(repository_path, sha1, language, output_file=None):
    highlighter = createHighlighter(language)
    if not highlighter: return False

    source = gitutils.Repository.readObject(repository_path, "blob", sha1)
    source = textutils.decode(source)

    if output_file:
        highlighter(source, output_file, None)
    else:
        output_path = syntaxhighlight.generateHighlightPath(sha1, language)

        try: os.makedirs(os.path.dirname(output_path), 0750)
        except OSError as error:
            if error.errno == errno.EEXIST: pass
            else: raise

        output_file = open(output_path + ".tmp", "w")
        contexts_path = output_path + ".ctx"

        highlighter(source, output_file, contexts_path)

        output_file.close()

        os.chmod(output_path + ".tmp", 0660)
        os.rename(output_path + ".tmp", output_path)

    return True

########NEW FILE########
__FILENAME__ = generic
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2012 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import re
import pygments.lexers
import pygments.token

import htmlutils

LANGUAGES = { "python": pygments.lexers.PythonLexer,
              "perl": pygments.lexers.PerlLexer,
              "java": pygments.lexers.JavaLexer,
              "ruby": pygments.lexers.RubyLexer,
              "php": pygments.lexers.PhpLexer,
              "makefile": pygments.lexers.MakefileLexer,
              "javascript": pygments.lexers.JavascriptLexer,
              "sql": pygments.lexers.SqlLexer,
              "objective-c": pygments.lexers.ObjectiveCLexer,
              "xml": pygments.lexers.XmlLexer }

class HighlightGeneric:
    def __init__(self, lexer):
        self.lexer = lexer

    def highlightToken(self, token, value):
        def tag(cls, value): return "<b class='%s'>%s</b>" % (cls, htmlutils.htmlify(value))
        def tagm(cls, value):
            if value == "\n": return value
            else:
                res = []
                for line in value.splitlines():
                    if line: res.append(tag(cls, line))
                    else: res.append(line)
                if value.endswith("\n"): res.append("")
                return "\n".join(res)

        value = value.encode("utf-8")

        if token in pygments.token.Token.Punctuation or token in pygments.token.Token.Operator:
            self.output.write(tag("op", value))
        elif token in pygments.token.Token.Name or token in pygments.token.Token.String.Symbol:
            self.output.write(tag("id", value))
        elif token in pygments.token.Token.Keyword:
            self.output.write(tag("kw", value))
        elif token in pygments.token.Token.String:
            self.output.write(tagm("str", value))
        elif token in pygments.token.Token.Comment:
            self.output.write(tagm("com", value))
        elif token in pygments.token.Token.Number.Integer:
            self.output.write(tag("int", value))
        elif token in pygments.token.Token.Number.Float:
            self.output.write(tag("fp", value))
        else:
            self.output.write(htmlutils.htmlify(value))

    def __call__(self, source, output_file, contexts_path):
        self.output = output_file

        blocks = re.split("^((?:<<<<<<<|>>>>>>>)[^\n]*\n)", source, flags=re.MULTILINE)

        in_conflict = False

        for index, block in enumerate(blocks):
            if (index & 1) == 0:
                if in_conflict:
                    blocks = re.split("^(=======[^\n]*\n)", block, flags=re.MULTILINE)
                else:
                    blocks = [block]

                for index, block in enumerate(blocks):
                    if (index & 1) == 0:
                        if block:
                            for token, value in self.lexer.get_tokens(block):
                                self.highlightToken(token, value)
                    else:
                        assert block[0] == "="
                        self.output.write(htmlutils.htmlify(block))
            else:
                assert block[0] == "<" or block[0] == ">"
                self.output.write(htmlutils.htmlify(block))
                in_conflict = block[0] == "<"

    @staticmethod
    def create(language):
        lexer = LANGUAGES.get(language)
        if lexer: return HighlightGeneric(lexer(stripnl=False))
        else: return None

import syntaxhighlight

syntaxhighlight.LANGUAGES.update(LANGUAGES.keys())

########NEW FILE########
__FILENAME__ = request
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2012 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import socket

import base
import configuration
import syntaxhighlight

from textutils import json_encode, json_decode

class HighlightBackgroundServiceError(base.ImplementationError):
    def __init__(self, message):
        super(HighlightBackgroundServiceError, self).__init__(
            "Highlight background service failed: %s" % message)

def requestHighlights(repository, sha1s):
    requests = [{ "repository_path": repository.path, "sha1": sha1, "path": path, "language": language }
                for sha1, (path, language) in sha1s.items()
                if not syntaxhighlight.isHighlighted(sha1, language)]

    if not requests: return

    try:
        connection = socket.socket(socket.AF_UNIX, socket.SOCK_STREAM)
        connection.connect(configuration.services.HIGHLIGHT["address"])
        connection.send(json_encode(requests))
        connection.shutdown(socket.SHUT_WR)

        data = ""

        while True:
            received = connection.recv(4096)
            if not received: break
            data += received

        connection.close()
    except socket.error as error:
        raise HighlightBackgroundServiceError(error[1])

    try:
        results = json_decode(data)
    except ValueError:
        raise HighlightBackgroundServiceError(
            "returned an invalid response (%r)" % data)

    if type(results) != list:
        # If not a list, the result is probably an error message.
        raise HighlightBackgroundServiceError(str(results))

    if len(results) != len(requests):
        raise HighlightBackgroundServiceError("didn't process all requests")

########NEW FILE########
__FILENAME__ = textformatting
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2012 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import re

import configuration
import dbutils
import gitutils
import htmlutils

def renderFormatted(db, user, table, lines, toc=False, title_right=None):
    re_h1 = re.compile("^=+$")
    re_h2 = re.compile("^-+$")
    data = { "configuration.URL": dbutils.getURLPrefix(db, user),
             "configuration.base.HOSTNAME": configuration.base.HOSTNAME,
             "configuration.base.SYSTEM_USER_NAME": configuration.base.SYSTEM_USER_NAME,
             "configuration.base.SYSTEM_GROUP_NAME": configuration.base.SYSTEM_GROUP_NAME,
             "configuration.paths.CONFIG_DIR": configuration.paths.CONFIG_DIR,
             "configuration.paths.INSTALL_DIR": configuration.paths.INSTALL_DIR,
             "configuration.paths.DATA_DIR": configuration.paths.DATA_DIR,
             "configuration.paths.GIT_DIR": configuration.paths.GIT_DIR }

    references = {}
    blocks = []
    block = []

    for line in lines:
        match = re.match(r'\[(.*?)\]: (.*?)(?: "(.*?)")?$', line)
        if match:
            name, url, title = match.groups()
            references[name] = (url, title)
            continue

        if line.strip():
            block.append(line % data)
        elif block:
            blocks.append(block)
            block = []
    else:
        if block:
            blocks.append(block)

    text = None

    for block in blocks:
        def textToId(text):
            return text.lower().replace(' ', '_')

        if len(block) == 2:
            if re_h1.match(block[1]):
                table.setTitle(block[0])
                h1 = table.tr("h1").td("h1").h1(id=textToId(block[0]))
                h1.text(block[0])
                if title_right:
                    span_right = h1.span("right")
                    if callable(title_right):
                        title_right(span_right)
                    else:
                        span_right.text(title_right)
                text = None
                if toc:
                    toc = table.tr("toc").td("toc").div().table("toc callout")
                    toc.tr("heading").th().text("Table of contents")
                continue
            elif re_h2.match(block[1]):
                if toc: toc.tr("h2").td().a(href="#" + textToId(block[0])).text(block[0])
                table.tr("h2").td("h2").div().h2(id=textToId(block[0])).text(block[0])
                text = None
                continue

        if len(block) == 1 and block[0] == "[repositories]":
            text = None

            repositories = table.tr().td().table("repositories callout")
            headings = repositories.thead().tr()
            headings.th("name").text("Short name")
            headings.th("path").text("Repository path")

            repositories.tr().td(colspan=2)

            cursor = db.cursor()
            cursor.execute("SELECT name, path FROM repositories ORDER BY id ASC")

            for name, path in cursor:
                row = repositories.tr("repository")
                row.td("name").text(name)
                row.td("path").text(gitutils.Repository.constructURL(db, user, path))

            continue

        if not text:
            text = table.tr("text").td("text")

        def translateLinks(text):
            def linkify(match):
                config_item, reference_text, reference_name = match.groups()

                if config_item:
                    url = "/config?highlight=%s" % config_item
                    text = config_item
                    title = None
                else:
                    reference_name = re.sub(r"\s+", " ", reference_name)
                    assert reference_name in references, reference_name
                    url, title = references[reference_name]
                    text = reference_text

                link = "<a href=%s" % htmlutils.htmlify(url, True)

                if title:
                    link += " title=%s" % htmlutils.htmlify(title, True)

                return link + ">%s</a>" % htmlutils.htmlify(text)

            return re.sub(r"CONFIG\(([^)]+)\)|\[(.*?)\]\n?\[(.*?)\]", linkify, text, flags=re.DOTALL)

        def processText(lines):
            if isinstance(lines, basestring):
                lines = [lines]
            for index, line in enumerate(lines):
                if line.startswith("  http"):
                    lines[index] = "<a href='%s'>%s</a>" % (line.strip(), line.strip())
            text = translateLinks("\n".join(lines))

            # Replace double dashes with &mdash;, but only if they are
            # surrounded by either spaces or word characters on both sides.
            #
            # We don't want to translate the double dashes in a
            # --command-line-argument used in the text.
            text = re.sub(r"(^| )--( |$)", r"\1&mdash;\2", text, flags=re.MULTILINE)
            text = re.sub(r"(\w)--(\w)", r"\1&mdash;\2", text)

            return text

        if len(block) > 2 and re_h2.match(block[1]):
            if toc: toc.tr("h3").td().a(href="#" + textToId(block[0])).text(block[0])
            div = text.div()
            div.h3(id=textToId(block[0])).text(block[0])
            block = block[2:]

        if block[0].startswith("|"):
            pre = text.div().table("pre callout").tr().td().preformatted()
            pre.text("\n".join([line[2:] for line in block]))
        elif block[0].startswith("* ") or block[0].startswith("1 "):
            if block[0].startswith("* "):
                items = text.div().ul()
            else:
                items = text.div().ol()
            item = []
            for line in block:
                if line[:2] != '  ':
                    if item:
                        items.li().text(processText(item), cdata=True)
                    item = []
                else:
                    assert line[:2] == "  "
                item.append(line[2:])
            if item:
                items.li().text(processText(item), cdata=True)
        elif block[0].startswith("? "):
            items = text.div().dl()
            term = []
            definition = None
            for line in block:
                if line[:2] == '? ':
                    if definition:
                        items.dt().text(processText(" ".join(term)), cdata=True)
                        items.dd().text(processText(definition), cdata=True)
                        definition = None
                    term = [line[2:]]
                elif line[:2] == '= ':
                    assert term
                    assert definition is None
                    definition = [line[2:]]
                elif definition is None:
                    term.append(line[2:])
                else:
                    definition.append(line[2:])
            items.dt().text(processText(" ".join(term)), cdata=True)
            items.dd().text(processText(definition), cdata=True)
        elif block[0].startswith("  "):
            text_data = translateLinks("\n".join(block))
            if block[0].startswith("  <code>"):
                className = "example"
            else:
                className = "hint"
                text_data = text_data.replace("--", "&mdash;")
            text.div().div(className).text(text_data, cdata=True)
        else:
            text.div().text(processText(block), cdata=True)

########NEW FILE########
__FILENAME__ = textutils
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2012 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import re
import json
import unicodedata

try:
    import configuration

    DEFAULT_ENCODINGS = configuration.base.DEFAULT_ENCODINGS[:]
except ImportError:
    # This is the default set of default encodings.  We could fail to
    # import 'configuration' for two principal reasons:
    #
    #  1) There's some catastrophic problem with the system.  Ignoring
    #     the problem here won't make the least bit of difference.
    #
    #  2) We're trying to run unit tests without an installed system.
    #     This fallback is simply nice in that case.

    DEFAULT_ENCODINGS = ["utf-8"]

def reflow(text, line_length=80, indent=0):
    if line_length == 0: return text

    paragraphs = re.split("\n\n+", text.replace("\r", ""))
    spaces = " " * indent

    for paragraph_index, paragraph in enumerate(paragraphs):
        lines = paragraph.split("\n")
        for line_index, line in enumerate(lines):
            if (line and line[0] in " \t-*") or line_index < len(lines) - 1 and len(line) < 0.5 * line_length:
                if indent:
                    paragraphs[paragraph_index] = "\n".join([spaces + line for line in lines])
                break
        else:
            lines = []
            line = spaces
            words = re.split("(\s+)", paragraph)
            ws = ""
            for word in words:
                if not word.strip():
                    if "\n" in word: ws = " "
                    else: ws = word
                else:
                    if len(line) > indent and len(line) + len(ws) + len(word) > line_length:
                        lines.append(line)
                        line = spaces
                    if len(line) > indent: line += ws
                    line += word
            if line: lines.append(line)
            paragraphs[paragraph_index] = "\n".join(lines)

    text = "\n\n".join(paragraphs)

    if isinstance(text, unicode): return text.encode("utf-8")
    else: return text

def indent(string, width=4):
    prefix = " " * width
    return prefix + ("\n" + prefix).join(string.splitlines())

def escape(text):
    special = { "\a": "a",
                "\b": "b",
                "\t": "t",
                "\n": "n",
                "\v": "v",
                "\f": "f",
                "\r": "r" }

    def escape1(match):
        substring = match.group(0)

        if ord(substring) < 128:
            if substring in special:
                return "\\%s" % special[substring]
            elif ord(substring) < 32:
                return "\\x%02x" % ord(substring)
            else:
                return substring

        category = unicodedata.category(substring)
        if category[0] in "CZ" or category == "So":
            if ord(substring) < 256:
                return "\\x%02x" % ord(substring)
            elif ord(substring) < 65536:
                return "\\u%04x" % ord(substring)
            else:
                return "\\U%08x" % ord(substring)
        else:
            return substring

    text = decode(str(text))
    escaped = re.sub("\W", escape1, text, flags=re.UNICODE)

    return escaped.encode("utf-8")

json_encode = json.dumps

def deunicode(v):
    if type(v) == unicode: return v.encode("utf-8")
    elif type(v) == list: return map(deunicode, v)
    elif type(v) == dict: return dict([(deunicode(a), deunicode(b)) for a, b in v.items()])
    else: return v

def json_decode(s):
    return deunicode(json.loads(s))

def decode(text):
    if isinstance(text, unicode):
        return text

    text = str(text)

    for index, encoding in enumerate(DEFAULT_ENCODINGS):
        try:
            decoded = text.decode(encoding)
        except UnicodeDecodeError:
            continue
        except LookupError:
            del DEFAULT_ENCODINGS[index]
        else:
            # Replace characters in the surrogate pair range with U+FFFD since
            # PostgreSQL's UTF-8 decoder won't accept them.
            return re.sub(u"[\ud800-\udfff]", "\ufffd", decoded)

    return text.decode("ascii", errors="replace")

def encode(text):
    if isinstance(text, unicode):
        return text.encode("utf-8")
    return str(text)

########NEW FILE########
__FILENAME__ = textutils_unittest
import sys

def independence():
    # Simply check that textutils can be imported.

    import textutils

if __name__ == "__main__":
    if "independence" in sys.argv[1:]:
        independence()

########NEW FILE########
__FILENAME__ = urlutils
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2014 the Critic contributors, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import json
import requests

class Response():
    def __init__(self, response):
        self.response = response

    def __getattr__(self, name):
        return getattr(self.response, name)

    def json(self):
        if hasattr(self.response, "json"):
            try:
                if callable(self.response.json):
                    return self.response.json()
                else:
                    return self.response.json
            except Exception:
                return None
        else:
            try:
                return json.loads(self.response.content)
            except ValueError:
                return None

def get(*args, **kwargs):
    return Response(requests.get(*args, **kwargs))

def post(*args, **kwargs):
    return Response(requests.post(*args, **kwargs))

########NEW FILE########
__FILENAME__ = wsgi
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2012 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

try:
    import maintenance.configtest
except ImportError:
    import traceback
    import sys

    exc_info = sys.exc_info()

    def application(environ, start_response):
        start_response("500 Internal Server Error",
                       [("Content-Type", "text/plain")])
        header = "Failed to import 'maintenance.configtest' module"
        return (["%s\n%s\n\n" % (header, "=" * len(header))] +
                traceback.format_exception(*exc_info))
else:
    errors, warnings = maintenance.configtest.testConfiguration()

    if errors:
        def application(environ, start_response):
            start_response("500 Internal Server Error",
                           [("Content-Type", "text/plain")])

            header = "Invalid system configuration"
            result = "%s\n%s\n\n" % (header, "=" * len(header))
            for error in errors:
                result += str(error) + "\n\n"
            for warning in warnings:
                result += str(warning) + "\n\n"

            return [result]
    else:
        try:
            import configuration

            if configuration.debug.COVERAGE_DIR:
                import coverage
                def import_critic():
                    import critic
                coverage.call("wsgi", import_critic)

            import critic
        except ImportError:
            import traceback
            import sys

            exc_info = sys.exc_info()

            def application(environ, start_response):
                start_response("500 Internal Server Error",
                               [("Content-Type", "text/plain")])
                header = "Failed to import 'critic' module"
                return (["%s\n%s\n\n" % (header, "=" * len(header))] +
                        traceback.format_exception(*exc_info))
        else:
            def application(environ, start_response):
                return critic.main(environ, start_response)

########NEW FILE########
__FILENAME__ = wsgistartup
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2012 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

try:
    import os
    import os.path
    import atexit
    import time
    import errno

    # Preload critic.py to reduce initial page load delay.
    import configuration
    if configuration.debug.COVERAGE_DIR:
        import coverage
        def import_critic():
            import critic
        coverage.call("wsgi", import_critic)
    else:
        import critic

    pidfile_path = os.path.join(configuration.paths.WSGI_PIDFILE_DIR, str(os.getpid()))

    def deletePidFile():
        try: os.unlink(pidfile_path)
        except: pass

    try: os.makedirs(os.path.dirname(pidfile_path))
    except OSError as error:
        if error.errno == errno.EEXIST: pass
        else: raise

    open(pidfile_path, "w").write(str(time.time()))

    atexit.register(deletePidFile)
except: pass

########NEW FILE########
__FILENAME__ = expect
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2013 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import re
import traceback

import testing

def extract_text(source):
    result = u""
    if source:
        if isinstance(source, list):
            for element in source:
                result += extract_text(element)
        elif isinstance(source, basestring):
            result += source
        elif getattr(source, "string"):
            result += source.string
        elif getattr(source, "contents"):
            result += extract_text(source.contents)
        else:
            result += "[%r]" % source
    return result

def deunicode(v):
    if type(v) == unicode: return v.encode("utf-8")
    elif type(v) == list: return map(deunicode, v)
    elif type(v) == dict: return dict([(deunicode(a), deunicode(b)) for a, b in v.items()])
    else: return v

class FailedCheck(testing.TestFailure):
    def __init__(self, expected, actual, location=None, message=None):
        if message is None:
            message = "check failed"
        if location is not None:
            message += ":\n At %s:%d" % location[0]
            for filename, linenr in location[1:]:
                message += ",\n   called from %s:%d" % (filename, linenr)
        super(FailedCheck, self).__init__(
            "%s:\n  Expected: %r,\n  Actual:   %r"
            % (message, expected, deunicode(actual)))
        self.expected = expected
        self.actual = actual

def simple_equal(expected, actual):
    return expected == actual

def check(expected, actual, equal=simple_equal, message=None):
    if not equal(expected, actual):
        location = []
        for filename, linenr, _, _ in reversed(traceback.extract_stack()):
            if filename.startswith("testing/tests/"):
                location.append((filename[len("testing/tests/"):], linenr))
            elif location:
                break
        else:
            location = None
        raise FailedCheck(expected, actual, location=location, message=message)

def with_class(*names):
    def check(value):
        if value is None:
            return False
        tokens = set(value.split())
        for name in names:
            if name not in tokens:
                return False
        return True
    return { "class": check }

def find_paleyellow(document, index):
    """Find index:th ".paleyellow" in the document."""
    tables = document.findAll(attrs=with_class("paleyellow"))
    if index >= len(tables):
        raise FailedCheck("<paleyellow: index=%d>" % index,
                          "<no paleyellow: count=%d>" % len(tables))
    return tables[index]

def document_title(expected):
    """Return <title> checker."""
    return lambda document: check(expected, document.title.string)

def paleyellow_title(index, expected):
    """Return index:th ".paleyellow" title checker."""
    def checker(document):
        table = find_paleyellow(document, index)
        actual = "<no title found>"
        h1 = table.find("h1")
        if h1 and h1.contents:
            actual = h1.contents[0]
        return check(expected, actual)
    return checker

def message(expected_title, expected_body, title_equal=simple_equal,
            body_equal=simple_equal):
    """Return <div class="message"> title checker."""
    def checker(document):
        message = document.find(
            "div", attrs={ "class": lambda value: "message" in value.split() })
        actual_title = None
        actual_body = None
        if message:
            title = message.find("h1")
            actual_title = extract_text(title)
            if expected_body is not None:
                body = message.find("p")
                actual_body = extract_text(body)
        if not actual_title:
            actual_title = "<no message title found>"
        check(expected_title, actual_title, equal=title_equal,
              message="title check failed")
        if expected_body is not None:
            if not actual_body:
                actual_body = "<no message body found>"
            check(expected_body, actual_body, equal=body_equal,
                  message="body check failed")
    return checker

def message_title(expected_title):
    return message(expected_title, None)

def no_message():
    """Return negative <div class="message"> checker."""
    def checker(document):
        message = document.find(
            "div", attrs={ "class": lambda value: "message" in value.split() })
        if message:
            actual = "<message: %s>" % message.find("h1").contents[0]
        else:
            actual = "<no message found>"
        return check("<no message found>", actual)
    return checker

def pageheader_links(*scopes):
    scopes = set(scopes)
    expected = []
    for label, scope in [("Home", "authenticated"),
                         ("Dashboard", None),
                         ("Branches", None),
                         ("Search", None),
                         ("Services", "administrator"),
                         ("Repositories", "administrator"),
                         ("Extensions(?: \\(\\d+\\))?", "extensions"),
                         ("Config", None),
                         ("Tutorial", None),
                         ("News(?: \\(\\d+\\))?", None),
                         ("Sign in", "anonymous"),
                         ("Sign out", "authenticated"),
                         ("Back to Review", "review")]:
        if scope is None or scope in scopes:
            expected.append(label)
    def checker(document):
        pageheader = document.find("table", attrs={ "class": "pageheader" })
        actual = []
        for link in pageheader.find("ul").findAll("a"):
            actual.append(link.string)
        return check(",".join(expected), ",".join(actual), equal=re.match)
    return checker

def script_user(username):
    def checker(document):
        for script in document.findAll("script"):
            if script.string:
                match = re.match('var user = new User\\(\d+,\s*"([^"]+)"', script.string)
                if match:
                    return check(username, match.group(1))
        raise FailedCheck(username, "<no user found>")
    return checker

def script_anonymous_user():
    def checker(document):
        for script in document.findAll("script"):
            if script.string and script.string.startswith("var user = new User(null,"):
                return
        raise FailedCheck("<anonymous user>", "<no user found>")
    return checker

def script_no_user():
    def checker(document):
        for script in document.findAll("script"):
            if script.string and script.string.startswith("var user = new User("):
                raise FailedCheck("<no user found>", "<user found>")
    return checker

########NEW FILE########
__FILENAME__ = findtests
import os
import re
import fnmatch

import testing

TESTS = None
TESTS_BY_FILENAME = {}

def automaticDependencies(filename):
    this_dirname = os.path.dirname(filename)
    for test in TESTS:
        other_dirname = os.path.dirname(test.filename)
        if this_dirname.startswith(other_dirname):
            if os.path.sep not in other_dirname \
                    or len(other_dirname) < len(this_dirname):
                yield test

RE_DEPENDENCY = re.compile(r"#\s+@dependency\s+([^\s]+)")
RE_FLAG = re.compile(r"#\s+@flag\s+([-\w]+)")
RE_IGNORE = re.compile(r"(?:\s*#.*)?\s*$")

class Test(object):
    def __init__(self, filename):
        self.filename = filename
        self.groups = []
        dirname = filename
        while True:
            dirname, basename = os.path.split(dirname)
            if not dirname:
                break
            self.groups.insert(0, dirname)
        self.dependencies = set()
        self.flags = set()

        has_dependency_declarations = []

        def process_file(path):
            path = os.path.join("testing", "tests", path)
            if not os.path.isfile(path):
                return
            with open(path) as source_file:
                for index, line in enumerate(source_file):
                    match = RE_DEPENDENCY.match(line)
                    if match:
                        has_dependency_declarations.append(True)
                        dependency = match.group(1)
                        if dependency == "none":
                            pass
                        elif dependency not in TESTS_BY_FILENAME:
                            testing.logger.error(
                                "%s:%d: invalid depdency: %s"
                                % (filename, index + 1, dependency))
                        else:
                            self.dependencies.add(TESTS_BY_FILENAME[dependency])
                        continue
                    match = RE_FLAG.match(line)
                    if match:
                        self.flags.add(match.group(1))
                        continue
                    match = RE_IGNORE.match(line)
                    if not match:
                        break

        process_file(filename)

        dirname = filename
        while True:
            dirname = os.path.dirname(dirname)
            if not dirname:
                break
            process_file(os.path.join(dirname, "__init__.py"))

        if not has_dependency_declarations:
            self.dependencies.update(automaticDependencies(filename))

        TESTS.append(self)
        TESTS_BY_FILENAME[self.filename] = self

    def __str__(self):
        return self.filename
    def __hash__(self):
        return hash(self.filename)
    def __eq__(self, other):
        return self.filename == str(other)

    def __repr__(self):
        return "Test(%r): %r" % (self.filename, sorted([test.filename for test in self.dependencies]))

def findTests():
    global TESTS

    RE_TEST_FILENAME = re.compile(r"/\d\d\d-[^/]*\.py$")
    RE_IGNORE_FILENAME = re.compile(r"(?:/__init__.py|~)$")

    TESTS = []

    def traverse(dirname):
        for filename in sorted(os.listdir(dirname)):
            filename = os.path.join(dirname, filename)
            if os.path.isdir(filename):
                traverse(filename)
            elif RE_TEST_FILENAME.search(filename):
                Test(os.path.relpath(filename, "testing/tests"))
            elif not RE_IGNORE_FILENAME.search(filename):
                testing.logger.warning(
                    "%s: unexpected non-test file under testing/tests/"
                    % filename)

    traverse("testing/tests")

def filterPatterns(patterns):
    RE_LEADING_TESTS = re.compile("^(?:testing/)?tests(?:/|$)")

    patterns = [RE_LEADING_TESTS.sub("", pattern) for pattern in patterns]
    patterns = [pattern.rstrip("/") for pattern in patterns]
    patterns = filter(None, patterns)

    return patterns

def selectTests(patterns, strict, flags_on=set(), flags_off=set()):
    if TESTS is None:
        findTests()

    patterns = filterPatterns(patterns)

    if not patterns and not flags_on and not flags_off:
        return TESTS, set()

    selected = set()
    dependencies = set()

    def select(test, is_dependency=False):
        if test in selected:
            # Test already selected.
            return
        selected.add(test.filename)
        if strict:
            # Don't select dependencies when strict=True.
            return
        if is_dependency:
            dependencies.add(test.filename)
        for dependency in test.dependencies:
            select(dependency, True)

    for test in TESTS:
        if flags_on - test.flags:
            continue
        if flags_off & test.flags:
            continue

        if patterns:
            for pattern in patterns:
                filename = test.filename
                while filename:
                    if fnmatch.fnmatch(filename, pattern):
                        select(test)
                        break
                    if strict:
                        break
                    filename = os.path.dirname(filename)
                if test in selected:
                    break
        else:
            select(test)

    return [test for test in TESTS if test in selected], dependencies

########NEW FILE########
__FILENAME__ = frontend
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2013 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import json
import contextlib

try:
    import requests
    import BeautifulSoup
except ImportError:
    # testing/main.py detects and abort if either of these are missing, so just
    # ignore errors here.
    pass

import testing

class Error(testing.TestFailure):
    def __init__(self, url, message):
        super(Error, self).__init__("page '%s' failed: %s" % (url, message))
        self.url = url

class HTTPError(Error):
    def __init__(self, url, expected, actual, body=None):
        message = "HTTP status differs: expected=%r, actual=%r" % (expected, actual)
        if body:
            message += "\n" + body
        super(HTTPError, self).__init__(url, message)
        self.expected = expected
        self.actual = actual

class PageError(Error):
    def __init__(self, url, key, expected, actual):
        super(PageError, self).__init__(
            url, "%s differs: expected=%r, actual=%r" % (key, expected, actual))
        self.key = key
        self.expected = expected
        self.actual = actual

class OperationError(Error):
    def __init__(self, url, message=None, key=None, expected=None, actual=None):
        if message is None:
            message = ""
        if key:
            message += "%s differs: expected=%r, actual=%r" % (key, expected, actual)
        super(OperationError, self).__init__(url, message)
        self.key = key
        self.expected = expected
        self.actual = actual

class Frontend(object):
    def __init__(self, hostname, http_port=8080):
        self.hostname = hostname
        self.http_port = http_port
        self.session_id = None

    def page(self, url, params={}, expect={},
             expected_content_type="text/html",
             expected_http_status=200,
             disable_redirects=False):
        full_url = "http://%s:%d/%s" % (self.hostname, self.http_port, url)

        testing.logger.debug("Fetching page: %s ..." % full_url)

        headers = {}

        if self.session_id:
            headers["Cookie"] = "sid=%s" % self.session_id

        response = requests.get(full_url,
                                params=params,
                                headers=headers,
                                allow_redirects=not disable_redirects)

        if "sid" in response.cookies:
            testing.logger.debug("Cookie: sid=%s" % response.cookies["sid"])
            self.session_id = response.cookies["sid"]

        def text(response):
            if hasattr(response, "text"):
                if callable(response.text):
                    return response.text()
                else:
                    return response.text
            else:
                return response.content

        if isinstance(expected_http_status, int):
            expected_http_status = [expected_http_status]

        try:
            if response.status_code not in expected_http_status:
                if response.headers["content-type"].startswith("text/plain"):
                    body = text(response)
                else:
                    body = None
                raise HTTPError(url, expected_http_status, response.status_code, body)
        except testing.TestFailure as error:
            testing.logger.error("Page '%s': %s" % (url, error.message))
            raise testing.TestFailure

        if response.status_code >= 400 and 200 in expected_http_status:
            # The caller expected a successful load or an error.  Signal errors
            # by returning None.
            return None

        if response.status_code >= 300 and response.status_code < 400 \
                and disable_redirects:
            # Redirection, and the caller disabled following it.  The caller is
            # interested in the redirect itself, so return the whole response.
            return response

        testing.logger.debug("Fetched page: %s" % full_url)

        document = text(response)

        content_type, _, _ = response.headers["content-type"].partition(";")

        if response.status_code == 200:
            if content_type != expected_content_type:
                testing.logger.error(
                    "Page '%s': wrong content type: %s" % (url, content_type))
                raise testing.TestFailure

        if content_type == "text/html":
            document = BeautifulSoup.BeautifulSoup(document)

            div_fatal = document.find("div", attrs={ "class": "fatal" })
            if div_fatal:
                message = div_fatal.find("pre")
                testing.logger.error(
                    "Page '%s': crash during incremental page generation:\n%s"
                    % (url, message.string if message else "<no message found>"))
                raise testing.TestFailure

        if expect:
            testing.logger.debug("Checking page: %s ..." % full_url)

            failed_checks = False

            for key, check in expect.items():
                try:
                    check(document)
                except testing.expect.FailedCheck as failed_check:
                    testing.logger.error("Page '%s', test '%s': %s"
                                         % (url, key, failed_check.message))
                    failed_checks = True
                except Exception as error:
                    raise Error(url, "'%s' checker failed: %s" % (key, str(error)))

            if failed_checks:
                raise testing.TestFailure

            testing.logger.debug("Checked page: %s ..." % full_url)

        return document

    def operation(self, url, data, expect={}):
        full_url = "http://%s:%d/%s" % (self.hostname, self.http_port, url)

        testing.logger.debug("Executing operation: %s ..." % full_url)

        headers = {}

        if self.session_id:
            headers["Cookie"] = "sid=%s" % self.session_id

        if not isinstance(data, basestring):
            data = json.dumps(data)
            headers["Content-Type"] = "text/json"

        response = requests.post(full_url,
                                 data=data,
                                 headers=headers)

        try:
            if response.status_code != 200:
                raise HTTPError(url, 200, response.status_code)

            if expect is None:
                result = response.content
            elif hasattr(response, "json"):
                if callable(response.json):
                    try:
                        result = response.json()
                    except:
                        raise OperationError(url, message="malformed response (not JSON)")
                else:
                    result = response.json
                    if result is None:
                        raise OperationError(url, message="malformed response (not JSON)")
            else:
                try:
                    result = json.loads(response.content)
                except ValueError:
                    raise OperationError(url, message="malformed response (not JSON)")
        except testing.TestFailure as error:
            testing.logger.error("Operation '%s': %s" % (url, error.message))
            raise testing.TestFailure

        if "sid" in response.cookies:
            testing.logger.debug("Cookie: sid=%s" % response.cookies["sid"])
            self.session_id = response.cookies["sid"]

        testing.logger.debug("Executed operation: %s" % full_url)

        if expect is not None:
            testing.logger.debug("Checking operation: %s" % full_url)

            # Check result["status"] first; if it doesn't have the expected value,
            # it's likely all other expected keys are simply missing from the
            # result, and thus produce rather meaningless errors.
            expected = expect.get("status", "ok")
            actual = result.get("status")
            if actual != expected:
                if actual == "error":
                    extra = "\nError:\n  %s" % "\n  ".join(result.get("error").splitlines())
                elif actual == "failure":
                    extra = " (code=%r)" % result.get("code")
                else:
                    extra = ""
                testing.logger.error(
                    "Operation '%s', key 'status': check failed: "
                    "expected=%r, actual=%r%s"
                    % (url, expected, actual, extra))
                raise testing.TestFailure

            failed_checks = False

            # Then check any other expected keys.
            for key, expected in expect.items():
                if key != "status":
                    actual = result.get(key)
                    if callable(expected):
                        checked = expected(actual)
                        if checked:
                            expected, actual = checked
                        else:
                            continue
                    if expected != actual:
                        testing.logger.error(
                            "Operation '%s', key '%s': check failed: "
                            "expected=%r, actual=%r"
                            % (url, key, expected, actual))
                        failed_checks = True

            if failed_checks:
                raise testing.TestFailure

            testing.logger.debug("Checked operation: %s" % full_url)

        return result

    @contextlib.contextmanager
    def signin(self, username="admin", password="testing"):
        if username is not None:
            self.operation("validatelogin", data={ "username": username,
                                                   "password": password })
        try:
            yield
        finally:
            self.signout()

    def signout(self):
        try:
            self.operation("endsession", data={})
        except testing.TestFailure as failure:
            if failure.message:
                testing.logger.error(failure.message)
        except Exception:
            testing.logger.exception("Failed to sign out!")

        # Resetting the cookie effectively signs out even if the "endsession"
        # operation failed.
        self.session_id = None

    def run_basic_tests(self):
        # The /tutorials page is essentially static content and doesn't require
        # a signed in user, so a good test-case for checking if the site is up
        # and accessible at all.
        self.page("tutorial", expect={ "document_title": testing.expect.document_title(u"Tutorials"),
                                       "content_title": testing.expect.paleyellow_title(0, u"Tutorials") })

        # The /validatelogin operation is a) necessary for most meaningful
        # additional testing, and a simple enough operation to test.
        with self.signin():
            # Load /home to determine whether /validatelogin successfully signed in
            # (and that we stored the session id cookie correctly.)
            self.page("home", expect={ "document_title": testing.expect.document_title(u"Testing Administrator's Home"),
                                       "content_title": testing.expect.paleyellow_title(0, u"Testing Administrator's Home") })

########NEW FILE########
__FILENAME__ = githook
import sys
import json

class Reject(Exception):
    pass

def update(repository_path, ref_name, old_value, new_value):
    data = json.dumps({ "repository_path": repository_path,
                        "ref_name": ref_name,
                        "old_value": old_value,
                        "new_value": new_value })

    if ref_name == "refs/heads/reject-create" and old_value is None:
        raise Reject("REJECT:" + data)
    elif ref_name == "refs/heads/reject-delete" and new_value is None:
        raise Reject("REJECT:" + data)
    elif ref_name == "refs/heads/reject-update" \
            and not (old_value is None or new_value is None):
        raise Reject("REJECT:" + data)
    else:
        sys.stdout.write("ACCEPT:" + data + "\n")

########NEW FILE########
__FILENAME__ = linktypes
import linkify

class IssueLink(linkify.LinkType):
    def __init__(self):
        super(IssueLink, self).__init__("#[0-9]+")
    def linkify(self, word, context):
        return "https://issuetracker.example.com/showIssue?id=" + word[1:]

IssueLink()

########NEW FILE########
__FILENAME__ = local
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2014 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import os
import subprocess

import testing

class CommandError(Exception):
    def __init__(self, stdout, stderr):
        self.stdout = stdout
        self.stderr = stderr

class Instance(testing.Instance):
    def execute(self, args, log_stdout=True, log_stderr=True, **kwargs):
        process = subprocess.Popen(
            args, stdout=subprocess.PIPE, stderr=subprocess.PIPE, **kwargs)
        stdout, stderr = process.communicate()
        if stdout.strip() and log_stdout:
            testing.logger.log(testing.STDOUT, stdout.rstrip("\n"))
        if stderr.strip() and log_stderr:
            testing.logger.log(testing.STDERR, stderr.rstrip("\n"))
        if process.returncode != 0:
            raise CommandError(stdout, stderr)
        return stdout

    def unittest(self, module, tests, args=None):
        testing.logger.info("Running unit tests: %s (%s)"
                             % (module, ",".join(tests)))
        path = self.translateUnittestPath(module)
        if not args:
            args = []
        for test in tests:
            try:
                self.execute(["python", path, test] + args,
                             cwd="src", log_stderr=False)
            except CommandError as error:
                output = "\n  ".join(error.stderr.splitlines())
                testing.logger.error("Unit tests failed: %s: %s\nOutput:\n  %s"
                                     % (module, test, output))

########NEW FILE########
__FILENAME__ = mailbox
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2013 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import socket
import threading
import time
import re
import email
import base64

import testing

class MissingMail(testing.TestFailure):
    def __init__(self, criteria, timeout):
        super(MissingMail, self).__init__(
            "No mail matching %r received in %d seconds" % (criteria, timeout))
        self.criteria = criteria
        self.timeout = timeout

class User(object):
    def __init__(self, name, address):
        self.name = name
        self.address = address

class Mail(object):
    def __init__(self, return_path):
        self.return_path = return_path
        self.recipient = None
        self.headers = {}
        self.lines = []

    def header(self, name, default=None):
        if name.lower() in self.headers:
            return self.headers[name.lower()][0]["value"]
        else:
            return default

    def all_headers(self):
        for header_name in sorted(self.headers.keys()):
            for header in self.headers[header_name]:
                yield (header["name"], header["value"])

    def __str__(self):
        return "%s\n\n%s" % ("\n".join(("%s: %s" % header)
                                       for header in self.all_headers()),
                             "\n".join(self.lines))

class EOF(Exception):
    pass

class Quit(Exception):
    pass

class Error(Exception):
    pass

class ParseError(Error):
    def __init__(self, line):
        super(ParseError, self).__init__("line=%r" % line)
        self.line = line

class Client(threading.Thread):
    def __init__(self, mailbox, client, debug_mails):
        super(Client, self).__init__()
        self.mailbox = mailbox
        self.credentials = mailbox.credentials
        self.client = client
        self.client.settimeout(None)
        self.debug_mails = debug_mails
        self.buffered = ""
        self.start()

    def sendline(self, string):
        self.client.sendall("%s\r\n" % string)

    def recvline(self):
        while "\r\n" not in self.buffered:
            data = self.client.recv(4096)
            if not data:
                raise EOF
            self.buffered += data
        line, self.buffered = self.buffered.split("\r\n", 1)
        return line

    def expectline(self, pattern):
        line = self.recvline()
        match = re.match(pattern, line, re.IGNORECASE)
        if not match:
            raise ParseError(line)
        return match.groups()

    def handshake(self):
        self.sendline("220 critic.example.org I'm the Critic Testing Framework")

        line = self.recvline()
        if re.match(r"helo\s+(\S+)$", line, re.IGNORECASE):
            if self.credentials:
                raise Error
            self.sendline("250 critic.example.org")
        elif re.match(r"ehlo\s+(\S+)$", line, re.IGNORECASE):
            if self.credentials:
                self.sendline("250-critic.example.org")
                self.sendline("250 AUTH LOGIN")

                line = self.recvline()
                match = re.match(r"auth\s+login(?:\s+(.+))?$",
                                 line, re.IGNORECASE)
                if not match:
                    raise ParseError(line)

                (username_b64,) = match.groups()

                if not username_b64:
                    self.sendline("334 %s" % base64.b64encode("Username:"))
                    username_b64 = self.recvline()

                self.sendline("334 %s" % base64.b64encode("Password:"))
                password_b64 = self.recvline()

                try:
                    username = base64.b64decode(username_b64)
                except TypeError:
                    raise Error("Invalid base64: %r" % username_b64)

                try:
                    password = base64.b64decode(password_b64)
                except TypeError:
                    raise Error("Invalid base64: %r" % password_b64)

                if username != self.credentials["username"] \
                        or password != self.credentials["password"]:
                    raise Error("Wrong credentials: %r / %r" % (username, password))

                self.sendline("235 Welcome, %s!" % username)

                testing.logger.debug("Mailbox: Client authenticated.")
            else:
                self.sendline("250 critic.example.org")
        else:
            raise Error

    def receive(self):
        try:
            (return_path,) = self.expectline(r"mail\s+from:<([^>]+)>(?:\s+size=\d+)?$")
        except ParseError as error:
            if error.line.lower() == "quit":
                self.sendline("221 critic.example.org Bye, bye")
                raise Quit
            raise

        self.sendline("250 OK")

        mail = Mail(return_path)

        # For simplicity we only support a single recipient.  Critic (currently)
        # never sends mails with multiple recipients.  (It often sends identical
        # mails to multiple recipients, but on the SMTP level, they are multiple
        # single-recipient mails.)
        (mail.recipient,) = self.expectline(r"rcpt\s+to:<([^>]+)>$")

        testing.logger.debug("Mailbox: Mail to <%s>." % mail.recipient)

        self.sendline("250 OK")
        self.expectline("data")
        self.sendline("354 Right")

        message_source = ""

        while True:
            line = self.recvline()
            if line == ".":
                break
            message_source += line + "\r\n"

        message = email.message_from_string(message_source)

        for name in message.keys():
            headers = mail.headers.setdefault(name.lower(), [])
            for value in message.get_all(name):
                value = re.sub("\r\n[ \t]+", " ", value)
                headers.append({ "name": name, "value": value })

        mail.lines = message.get_payload(decode=True).splitlines()

        testing.logger.debug("Received mail to: <%s> \"%s\""
                             % (mail.recipient, mail.header("Subject")))

        if self.debug_mails:
            source = "--------------------------------------------------\n"
            for name, value in message.items():
                source += "%s: %s\n" % (name, value)
            source += "\n"
            for line in mail.lines:
                source += line + "\n"
            source += "--------------------------------------------------"
            testing.logger.debug(source)

        self.mailbox.add(mail)
        self.sendline("250 OK")

    def run(self):
        try:
            testing.logger.debug("Mailbox: Client connected.")
            self.handshake()
            testing.logger.debug("Mailbox: Client ready.")
            while True:
                self.receive()
        except Error as error:
            testing.logger.error("Mailbox: Client error: %s" % error.message)
        except Quit:
            testing.logger.debug("Mailbox: Client quit.")
        except EOF:
            testing.logger.debug("Mailbox: Client disconnected prematurely.")
        except Exception:
            testing.logger.exception("Mailbox: Client error!")
        self.close()

    def close(self):
        try:
            self.client.close()
        except socket.error:
            pass

class Listener(threading.Thread):
    def __init__(self, mailbox, debug_mails):
        super(Listener, self).__init__()
        self.daemon = True
        self.mailbox = mailbox
        self.debug_mails = debug_mails
        self.socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        self.socket.settimeout(0.1)
        self.socket.bind(("", 0))
        self.socket.listen(1)
        self.stopped = False
        self.start()

    def run(self):
        while not self.stopped:
            try:
                client, _ = self.socket.accept()
            except socket.timeout:
                pass
            else:
                Client(self.mailbox, client, self.debug_mails)

    def stop(self):
        self.stopped = True

class Mailbox(object):
    def __init__(self, credentials=None, debug_mails=False):
        self.credentials = credentials
        self.queued = []
        self.errors = []
        self.condition = threading.Condition()
        self.listener = Listener(self, debug_mails)

    def add(self, mail):
        with self.condition:
            self.queued.append(mail)
            self.condition.notify()

    def pop(self, accept=None, timeout=5):
        def is_accepted(mail):
            if accept is None:
                return True
            if callable(accept):
                return accept(mail)
            for fn in accept:
                if not fn(mail):
                    return False
            return True

        deadline = time.time() + timeout
        with self.condition:
            while True:
                for mail in self.queued:
                    if is_accepted(mail):
                        self.queued.remove(mail)
                        return mail
                use_timeout = deadline - time.time()
                if use_timeout > 0:
                    self.condition.wait(use_timeout)
                else:
                    break
        raise MissingMail(accept, timeout)

    def reset(self):
        with self.condition:
            self.queued = []

    def pop_error(self):
        with self.condition:
            return self.errors.pop(0)

    def stop(self):
        self.listener.stop()

    def check_empty(self):
        while True:
            try:
                unexpected = self.pop(timeout=0)
            except MissingMail:
                break
            else:
                testing.logger.error("Unexpected mail to <%s>:\n%s"
                                     % (unexpected.recipient, unexpected))

    @property
    def port(self):
        return self.listener.socket.getsockname()[1]

    def __enter__(self):
        return self

    def __exit__(self, *args):
        self.stop()
        return False

class WithSubject(object):
    def __init__(self, value):
        self.regexp = re.compile(value)
    def __call__(self, mail):
        return self.regexp.match(mail.header("Subject")) is not None
    def __repr__(self):
        return "subject=%r" % self.regexp.pattern

class ToRecipient(object):
    def __init__(self, address):
        self.address = address
    def __call__(self, mail):
        return mail.recipient == self.address
    def __repr__(self):
        return "recipient=<%s>" % self.address

########NEW FILE########
__FILENAME__ = main
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2013 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import sys
import os
import argparse
import logging
import re
import subprocess
import traceback
import time
import datetime

import testing

class Counters:
    def __init__(self):
        self.tests_run = 0
        self.tests_failed = 0
        self.errors_logged = 0
        self.warnings_logged = 0

counters = Counters()
logger = None

def run():
    global logger

    parser = argparse.ArgumentParser(description="Critic testing framework")

    parser.add_argument("--debug", action="store_true",
                        help="Enable DEBUG level logging")
    parser.add_argument("--debug-mails", action="store_true",
                        help="Log every mail sent by the tested system")
    parser.add_argument("--quiet", action="store_true",
                        help="Disable INFO level logging")

    parser.add_argument("--coverage", action="store_true",
                        help="Enable coverage measurement mode")
    parser.add_argument("--commit",
                        help="Commit (symbolic ref or SHA-1) to test [default=HEAD]")
    parser.add_argument("--upgrade-from",
                        help="Commit (symbolic ref or SHA-1) to install first and upgrade from")
    parser.add_argument("--strict-fs-permissions", action="store_true",
                        help="Set strict file-system permissions in guest OS")
    parser.add_argument("--test-extensions", action="store_true",
                        help="Test extensions")

    parser.add_argument("--local", action="store_true",
                        help="Run local standalone tests only")

    parser.add_argument("--vbox-host", default="host",
                        help="Host that's running VirtualBox [default=host]")
    parser.add_argument("--vm-identifier",
                        help="VirtualBox instance name or UUID")
    parser.add_argument("--vm-hostname",
                        help="VirtualBox instance hostname [default=VM_IDENTIFIER")
    parser.add_argument("--vm-snapshot", default="clean",
                        help="VirtualBox snapshot (name or UUID) to restore [default=clean]")
    parser.add_argument("--vm-ssh-port", type=int, default=22,
                        help="VirtualBox instance SSH port [default=22]")
    parser.add_argument("--vm-http-port", type=int, default=80,
                        help="VirtualBox instance HTTP port [default=80]")

    parser.add_argument("--git-daemon-port", type=int,
                        help="Port to tell 'git daemon' to bind to")
    parser.add_argument("--cache-dir", default="testing/cache",
                        help="Directory where cache files are stored")

    parser.add_argument("--pause-before", action="append",
                        help="Pause testing before specified test(s)")
    parser.add_argument("--pause-after", action="append",
                        help="Pause testing before specified test(s)")
    parser.add_argument("--pause-on-failure", action="store_true",
                        help="Pause testing after each failed test")
    parser.add_argument("--pause-upgrade-loop", action="store_true",
                        help="Support upgrading the tested system while paused")
    parser.add_argument("--pause-upgrade-hook", action="append",
                        help="Command to run (locally) before upgrading")

    parser.add_argument("test", nargs="*",
                        help="Specific tests to run [default=all]")

    arguments = parser.parse_args()

    class CountingLogger(object):
        def __init__(self, real, counters):
            self.real = real
            self.counters = counters

        def log(self, level, message):
            if level == logging.ERROR:
                self.counters.errors_logged += 1
            elif level == logging.WARNING:
                self.counters.warnings_logged += 1
            for line in message.splitlines() or [""]:
                self.real.log(level, line)
        def debug(self, message):
            self.log(logging.DEBUG, message)
        def info(self, message):
            self.log(logging.INFO, message)
        def warning(self, message):
            self.log(logging.WARNING, message)
        def error(self, message):
            self.log(logging.ERROR, message)
        def exception(self, message):
            self.log(logging.ERROR, message + "\n" + traceback.format_exc())

    logger = testing.configureLogging(
        arguments, wrap=lambda logger: CountingLogger(logger, counters))
    logger.info("""\
Critic Testing Framework
========================

""")

    if not arguments.local and not arguments.vm_identifier:
        logger.error("Must specify one of --local and --vm-identifier!")
        return

    if arguments.local:
        incompatible_arguments = []

        # This is not a complete list; just those that are most significantly
        # incompatible or irrelevant with --local.
        if arguments.commit:
            incompatible_arguments.append("--commit")
        if arguments.upgrade_from:
            incompatible_arguments.append("--upgrade-from")
        if arguments.coverage:
            incompatible_arguments.append("--coverage")
        if arguments.test_extensions:
            incompatible_arguments.append("--strict-fs-permissions")
        if arguments.test_extensions:
            incompatible_arguments.append("--test-extensions")
        if arguments.vm_identifier:
            incompatible_arguments.append("--vm-identifier")

        if incompatible_arguments:
            logger.error("These arguments can't be combined with --local:\n  " +
                         "\n  ".join(incompatible_arguments))
            return

    import_errors = False

    try:
        import requests
    except ImportError:
        logger.error("Failed to import 'requests'!")
        import_errors = True

    try:
        import BeautifulSoup
    except ImportError:
        logger.error("Failed to import 'BeautifulSoup'!")
        import_errors = True

    git_version = subprocess.check_output(["git", "--version"]).strip()
    m = re.search("(\d+)\.(\d+)\.(\d+)(?:[^\d]+|$)", git_version)
    if not m:
        logger.warning("Failed to parse host-side git version number: '%s'" % git_version)
    else:
        version_tuple = tuple(map(int, m.groups()))
        if version_tuple >= (1, 8, 5):
            logger.debug("Using Git version %s on host." % git_version)
        else:
            logger.error("Git version on host machine must be version 1.8.5 or above (detected version %s)." % git_version)
            logger.error("Earlier Git versions crashed with SIGBUS causing test suite flakiness.")
            import_errors = True

    if import_errors:
        logger.error("Required software missing; see testing/USAGE.md for details.")
        return

    if arguments.test_extensions:
        # Check that the v8-jsshell submodule is checked out if extension
        # testing was requested.
        output = subprocess.check_output(["git", "submodule", "status",
                                          "installation/externals/v8-jsshell"])
        if output.startswith("-"):
            logger.error("""\
The v8-jsshell submodule must be checked for extension testing.  Please run
  git submodule update --init installation/externals/v8-jsshell
first or run this script without --test-extensions.""")
            return

    if not arguments.local:
        # Note: we are not ignoring typical temporary editor files such as the
        # ".#<name>" files created by Emacs when a buffer has unsaved changes.
        # This is because unsaved changes in an editor is probably also
        # something you don't want to test with.

        locally_modified_paths = []

        status_output = subprocess.check_output(
            ["git", "status", "--porcelain"])

        for line in status_output.splitlines():
            locally_modified_paths.extend(line[3:].split(" -> "))

        tests_modified = []
        input_modified = []
        other_modified = []

        for path in locally_modified_paths:
            if path.startswith("testing/input/"):
                input_modified.append(path)
            elif path.startswith("testing/"):
                tests_modified.append(path)
            else:
                other_modified.append(path)

        if input_modified:
            logger.error("Test input files locally modified:\n  " +
                         "\n  ".join(input_modified))
        if other_modified:
            logger.error("Critic files locally modified:\n  " +
                         "\n  ".join(other_modified))
        if input_modified or other_modified:
            logger.error("Please commit or stash local modifications before "
                         "running tests.")
            return

        if tests_modified:
            logger.warning("Running tests using locally modified files:\n  " +
                           "\n  ".join(tests_modified))

    tested_commit = subprocess.check_output(
        ["git", "rev-parse", "--verify", arguments.commit or "HEAD"]).strip()

    if arguments.upgrade_from:
        install_commit = subprocess.check_output(
            ["git", "rev-parse", "--verify", arguments.upgrade_from]).strip()
        upgrade_commit = tested_commit
    else:
        install_commit = tested_commit
        upgrade_commit = None

    install_commit_description = subprocess.check_output(
        ["git", "log", "--oneline", "-1", install_commit]).strip()

    if upgrade_commit:
        upgrade_commit_description = subprocess.check_output(
            ["git", "log", "--oneline", "-1", upgrade_commit]).strip()
    else:
        upgrade_commit_description = None

    flags_on = set()
    flags_off = set()

    try:
        if arguments.local:
            frontend = None
            instance = testing.local.Instance()
            flags_on.add("local")
        else:
            frontend = testing.frontend.Frontend(
                hostname=arguments.vm_hostname or arguments.vm_identifier,
                http_port=arguments.vm_http_port)

            instance = testing.virtualbox.Instance(
                arguments,
                install_commit=(install_commit, install_commit_description),
                upgrade_commit=(upgrade_commit, upgrade_commit_description),
                frontend=frontend)
    except testing.Error as error:
        logger.error(error.message)
        return

    tests, dependencies = testing.findtests.selectTests(
        arguments.test, strict=False, flags_on=flags_on, flags_off=flags_off)

    if not tests:
        logger.error("No tests selected!")
        return

    def pause():
        if arguments.pause_upgrade_loop:
            print "Testing paused."

            while True:
                testing.pause("Press ENTER to upgrade (to HEAD), CTRL-c to stop: ")

                for command in arguments.pause_upgrade_hook:
                    subprocess.check_call(command, shell=True)

                repository.push("HEAD")

                instance.execute(["git", "fetch", "origin", "master"], cwd="critic")
                instance.upgrade_commit = "FETCH_HEAD"
                instance.upgrade()
        else:
            testing.pause("Testing paused.  Press ENTER to continue: ")

    pause_before = pause_after = set()

    if arguments.pause_before:
        pause_before = testing.findtests.filterPatterns(arguments.pause_before)
        pause_before_tests, _ = testing.findtests.selectTests(pause_before,
                                                              strict=True)
        pause_before_tests = set(pause_before_tests)
        pause_before_groups = set(pause_before)

        def maybe_pause_before(test):
            def do_pause(what):
                logger.info("Pausing before: %s" % what)
                pause()

            if test in pause_before_tests:
                do_pause(test)
            else:
                for group in test.groups:
                    if group in pause_before_groups \
                            and test == all_groups[group][0]:
                        do_pause(group)
                        break
    else:
        def maybe_pause_before(test):
            pass

    if arguments.pause_after:
        pause_after = testing.findtests.filterPatterns(arguments.pause_after)
        pause_after_tests, _ = testing.findtests.selectTests(pause_after,
                                                             strict=True)
        pause_after_tests = set(pause_after_tests)
        pause_after_groups = set(pause_after)

        def maybe_pause_after(test):
            def do_pause(what):
                logger.info("Pausing after: %s" % what)
                pause()

            if test in pause_after_tests:
                do_pause(test)
            else:
                for group in test.groups:
                    if group in pause_after_groups \
                            and test == all_groups[group][-1]:
                        do_pause(group)
                        break
    else:
        def maybe_pause_after(test):
            pass

    root_groups = {}
    all_groups = {}

    for test in tests:
        for group in test.groups:
            all_groups.setdefault(group, []).append(test)
        root_groups.setdefault(test.groups[0], []).append(test)

    failed_tests = set()

    def run_group(group_name, tests):
        scope = { "testing": testing,
                  "logger": logger,
                  "instance": instance }

        if not arguments.local:
            scope.update({ "frontend": frontend,
                           "repository": repository,
                           "mailbox": mailbox })

        try:
            for test in tests:
                if test.dependencies & failed_tests:
                    logger.info("Skipping %s (failed dependency)" % test)
                    continue

                maybe_pause_before(test)

                if test in dependencies:
                    logger.info("Running: %s (dependency)" % test)
                else:
                    logger.info("Running: %s" % test)

                counters.tests_run += 1

                try:
                    errors_before = counters.errors_logged
                    execfile(os.path.join("testing/tests", test.filename),
                             scope.copy())
                    if errors_before < counters.errors_logged:
                        raise testing.TestFailure
                except testing.TestFailure as failure:
                    counters.tests_failed += 1

                    failed_tests.add(test)

                    if failure.message:
                        logger.error(failure.message)

                    if mailbox:
                        while True:
                            try:
                                mail = mailbox.pop(
                                    accept=testing.mailbox.ToRecipient(
                                        "system@example.org"),
                                    timeout=1)
                            except testing.mailbox.MissingMail:
                                break
                            else:
                                logger.error("System message: %s\n  %s"
                                             % (mail.header("Subject"),
                                                "\n  ".join(mail.lines)))

                    if arguments.pause_on_failure:
                        pause()
                except testing.NotSupported as not_supported:
                    failed_tests.add(test)
                    logger.info("Test not supported: %s" % not_supported.message)
                else:
                    maybe_pause_after(test)
        except KeyboardInterrupt:
            logger.error("Testing aborted.")
            return False
        except testing.Error as error:
            if error.message:
                logger.exception(error.message)
            if arguments.pause_on_failure:
                pause()
            return False
        except Exception:
            logger.exception("Unexpected exception!")
            if arguments.pause_on_failure:
                pause()
            return False
        else:
            return True

    for group_name in sorted(root_groups.keys()):
        if arguments.local:
            repository = None
            mailbox = None

            run_group(group_name, all_groups[group_name])
        else:
            repository = testing.repository.Repository(
                arguments.vbox_host,
                arguments.git_daemon_port,
                tested_commit,
                arguments.vm_hostname)
            mailbox = testing.mailbox.Mailbox({ "username": "smtp_username",
                                                "password": "SmTp_PaSsWoRd" },
                                              arguments.debug_mails)

            with repository:
                with mailbox:
                    if not repository.export():
                        return

                    with instance:
                        instance.mailbox = mailbox

                        testing.utils.instance = instance
                        testing.utils.frontend = frontend

                        if run_group(group_name, all_groups[group_name]):
                            instance.finish()

                    mailbox.check_empty()

def main():
    start_time = time.time()

    run()

    time_taken = str(datetime.timedelta(seconds=round(time.time() - start_time)))

    logger.info("""
Test summary
============
Tests run:       %9d
Tests failed:    %9d
Errors logged:   %9d
Warnings logged: %9d
Time taken:      %9s
""" % (counters.tests_run,
       counters.tests_failed,
       counters.errors_logged,
       counters.warnings_logged,
       time_taken))

    if counters.tests_failed or counters.errors_logged:
        sys.exit(1)

if __name__ == "__main__":
    main()

########NEW FILE########
__FILENAME__ = repository
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2013 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import os
import time
import tempfile
import shutil
import subprocess

import testing

class GitCommandError(testing.TestFailure):
    def __init__(self, command, output):
        super(GitCommandError, self).__init__(
            "GitCommandError: %s\nOutput:\n  %s"
            % (command, "\n  ".join(output.strip().splitlines())))
        self.command = command
        self.output = output

def _git(args, **kwargs):
    argv = ["git"] + args
    if "cwd" in kwargs:
        cwd = " (in %s)" % kwargs["cwd"]
    else:
        cwd = ""
    testing.logger.debug("Running: %s%s" % (" ".join(argv), cwd))
    try:
        return subprocess.check_output(
            argv, stdin=open("/dev/null"), stderr=subprocess.STDOUT, **kwargs)
    except subprocess.CalledProcessError as error:
        raise GitCommandError(" ".join(argv), error.output)

class Repository(object):
    def __init__(self, host, port, tested_commit, vm_hostname):
        self.host = host
        self.port = port
        self.base_path = tempfile.mkdtemp()
        self.path = os.path.join(self.base_path, "critic.git")
        self.work = os.path.join(self.base_path, "work")

        if port:
            self.url = "git://%s:%d/critic.git" % (host, port)
        else:
            self.url = "git://%s/critic.git" % host

        testing.logger.debug("Creating temporary repositories in: %s" % self.base_path)

        _git(["clone", "--bare", os.getcwd(), "critic.git"],
             cwd=self.base_path)

        _git(["config", "receive.denyDeletes", "false"],
             cwd=self.path)
        _git(["config", "receive.denyNonFastforwards", "false"],
             cwd=self.path)

        self.push(tested_commit)

        def submodule_sha1(repository_path, parent_sha1, submodule_path):
            try:
                lstree = _git(["ls-tree", parent_sha1, submodule_path],
                              cwd=repository_path)
            except GitCommandError:
                # Sub-module doesn't exist?  Will probably fail later, but
                # doesn't need to fail here.
                return None
            mode, object_type, sha1, path = lstree.strip().split(None, 3)
            if object_type != "commit":
                # Odd.  The repository doesn't look at all like we expect.
                return None
            return sha1

        if os.path.exists("installation/externals/v8-jsshell/.git"):
            v8_jsshell_path = os.path.join(os.getcwd(), "installation/externals/v8-jsshell")
            _git(["clone", "--bare", v8_jsshell_path, "v8-jsshell.git"],
                 cwd=self.base_path)
            self.v8_jsshell_path = os.path.join(self.base_path, "v8-jsshell.git")
            v8_jsshell_sha1 = submodule_sha1(os.getcwd(), tested_commit,
                                             "installation/externals/v8-jsshell")
            if v8_jsshell_sha1:
                _git(["push", "--quiet", "--force", self.v8_jsshell_path,
                      v8_jsshell_sha1 + ":refs/heads/master"],
                     cwd=v8_jsshell_path)
        else:
            self.v8_jsshell_path = None
            v8_jsshell_sha1 = None

        if os.path.exists("installation/externals/v8-jsshell/v8/.git"):
            v8_path = os.path.join(os.getcwd(), "installation/externals/v8-jsshell/v8")
            _git(["clone", "--bare", v8_path, "v8/v8.git"],
                 cwd=self.base_path)
            self.v8_path = os.path.join(self.base_path, "v8/v8.git")
            if port:
                self.v8_url = "git://%s:%d/v8/v8.git" % (host, port)
            else:
                self.v8_url = "git://%s/v8/v8.git" % host
            if v8_jsshell_sha1:
                v8_sha1 = submodule_sha1("installation/externals/v8-jsshell",
                                         v8_jsshell_sha1, "v8")
                if v8_sha1:
                    _git(["push", "--quiet", "--force", self.v8_path,
                          v8_sha1 + ":refs/heads/master"],
                         cwd=v8_path)
        else:
            self.v8_path = None
            self.v8_url = None

    def push(self, commit):
        _git(["push", "--quiet", "--force", self.path,
              "%s:refs/heads/master" % commit])

    def export(self):
        argv = ["git", "daemon", "--reuseaddr", "--export-all",
                "--base-path=%s" % self.base_path]
        if self.port:
            argv.append("--port=%d" % self.port)
        argv.append(self.path)
        if self.v8_jsshell_path:
            argv.append(self.v8_jsshell_path)
        if self.v8_path:
            argv.append(self.v8_path)

        self.daemon = subprocess.Popen(argv)

        time.sleep(1)

        pid, status = os.waitpid(self.daemon.pid, os.WNOHANG)
        if pid != 0:
            self.daemon = None
            testing.logger.error("Failed to export repository!")
            return False

        testing.logger.debug("Exported repository: %s" % self.path)
        if self.v8_jsshell_path:
            testing.logger.debug("Exported repository: %s" % self.v8_jsshell_path)
        if self.v8_path:
            testing.logger.debug("Exported repository: %s" % self.v8_path)
        return True

    def run(self, args):
        return _git(args, cwd=self.path)

    def workcopy(self, name="critic", empty=False):
        class Workcopy(testing.Context):
            def __init__(self, path, start, finish):
                super(Workcopy, self).__init__(start, finish)
                self.path = path

            def run(self, args, **kwargs):
                env = os.environ.copy()
                for name in kwargs.keys():
                    if name.lower() != name == name.upper():
                        env[name] = kwargs[name]
                        del kwargs[name]
                return _git(args, cwd=self.path, env=env, **kwargs)

        path = os.path.join(self.work, name)

        if os.path.exists(path):
            raise testing.InstanceError(
                "Can't create work copy; path already exists!")

        def start():
            if not os.path.isdir(self.work):
                os.mkdir(self.work)
            if not empty:
                _git(["clone", self.path, name], cwd=self.work)
            else:
                os.mkdir(path)
                _git(["init"], cwd=path)

        def finish():
            shutil.rmtree(path)

        return Workcopy(path, start, finish)

    def __enter__(self):
        return self

    def __exit__(self, *args):
        try:
            if self.daemon:
                self.daemon.terminate()
                self.daemon.wait()
        except:
            testing.logger.exception("Repository clean-up failed!")

        try:
            shutil.rmtree(self.base_path)
        except:
            testing.logger.exception("Repository clean-up failed!")

        return False

########NEW FILE########
__FILENAME__ = 000-install
# Start instance and install (and upgrade, optionally) Critic with the default
# arguments.
instance.start()
instance.install(repository)
instance.upgrade()

########NEW FILE########
__FILENAME__ = 001-dashboard
frontend.page("dashboard", expect={ "document_title": testing.expect.document_title(u"Dashboard"),
                                    "message_title": testing.expect.message_title(u"No reviews!"),
                                    "pageheader_links": testing.expect.pageheader_links("anonymous"),
                                    "script_user": testing.expect.script_anonymous_user() })

########NEW FILE########
__FILENAME__ = 002-branches
frontend.page(
    "branches", expect={ "document_title": testing.expect.document_title(u"Branches"),
                         "content_title": testing.expect.paleyellow_title(0, u"Branches"),
                         "pageheader_links": testing.expect.pageheader_links("anonymous"),
                         "script_user": testing.expect.script_no_user() })

########NEW FILE########
__FILENAME__ = 003-search
frontend.page(
    "search",
    expect={ "document_title": testing.expect.document_title(u"Review Search"),
             "content_title": testing.expect.paleyellow_title(0, u"Review Search"),
             "pageheader_links": testing.expect.pageheader_links("anonymous"),
             "script_user": testing.expect.script_anonymous_user() })

########NEW FILE########
__FILENAME__ = 004-config
frontend.page(
    "config",
    expect={ "document_title": testing.expect.document_title(u"User preferences"),
             "content_title": testing.expect.paleyellow_title(0, u"User preferences"),
             "pageheader_links": testing.expect.pageheader_links("anonymous"),
             "script_user": testing.expect.script_anonymous_user() })

########NEW FILE########
__FILENAME__ = 005-tutorial
frontend.page("tutorial",
              expect={ "document_title": testing.expect.document_title(u"Tutorials"),
                       "content_title": testing.expect.paleyellow_title(0, u"Tutorials"),
                       "pageheader_links": testing.expect.pageheader_links("anonymous"),
                       "script_user": testing.expect.script_no_user() })

frontend.page("tutorial",
              params={ "item": "request" },
              expect={ "document_title": testing.expect.document_title(u"Requesting a Review"),
                       "content_title": testing.expect.paleyellow_title(0, u"Requesting a Review"),
                       "pageheader_links": testing.expect.pageheader_links("anonymous"),
                       "script_user": testing.expect.script_no_user() })

frontend.page("tutorial",
              params={ "item": "review" },
              expect={ "document_title": testing.expect.document_title(u"Reviewing Changes"),
                       "content_title": testing.expect.paleyellow_title(0, u"Reviewing Changes"),
                       "pageheader_links": testing.expect.pageheader_links("anonymous"),
                       "script_user": testing.expect.script_no_user() })

frontend.page("tutorial",
              params={ "item": "filters" },
              expect={ "document_title": testing.expect.document_title(u"Filters"),
                       "content_title": testing.expect.paleyellow_title(0, u"Filters"),
                       "pageheader_links": testing.expect.pageheader_links("anonymous"),
                       "script_user": testing.expect.script_no_user() })

frontend.page("tutorial",
              params={ "item": "viewer" },
              expect={ "document_title": testing.expect.document_title(u"Repository Viewer"),
                       "content_title": testing.expect.paleyellow_title(0, u"Repository Viewer"),
                       "pageheader_links": testing.expect.pageheader_links("anonymous"),
                       "script_user": testing.expect.script_no_user() })

frontend.page("tutorial",
              params={ "item": "reconfigure" },
              expect={ "document_title": testing.expect.document_title(u"Reconfiguring Critic"),
                       "content_title": testing.expect.paleyellow_title(0, u"Reconfiguring Critic"),
                       "pageheader_links": testing.expect.pageheader_links("anonymous"),
                       "script_user": testing.expect.script_no_user() })

frontend.page("tutorial",
              params={ "item": "rebase" },
              expect={ "document_title": testing.expect.document_title(u"Rebasing a Review"),
                       "content_title": testing.expect.paleyellow_title(0, u"Rebasing a Review"),
                       "pageheader_links": testing.expect.pageheader_links("anonymous"),
                       "script_user": testing.expect.script_no_user() })

frontend.page("tutorial",
              params={ "item": "administration" },
              expect={ "document_title": testing.expect.document_title(u"System Administration"),
                       "content_title": testing.expect.paleyellow_title(0, u"System Administration"),
                       "pageheader_links": testing.expect.pageheader_links("anonymous"),
                       "script_user": testing.expect.script_no_user() })

frontend.page("tutorial",
              params={ "item": "customization" },
              expect={ "document_title": testing.expect.document_title(u"System Customization"),
                       "content_title": testing.expect.paleyellow_title(0, u"System Customization"),
                       "pageheader_links": testing.expect.pageheader_links("anonymous"),
                       "script_user": testing.expect.script_no_user() })

frontend.page("tutorial",
              params={ "item": "search" },
              expect={ "document_title": testing.expect.document_title(u"Review Quick Search"),
                       "content_title": testing.expect.paleyellow_title(0, u"Review Quick Search"),
                       "pageheader_links": testing.expect.pageheader_links("anonymous"),
                       "script_user": testing.expect.script_no_user() })

# Unknown items are ignored and the main Tutorials page is returned instead.
frontend.page("tutorial",
              params={ "item": "nonexisting" },
              expect={ "document_title": testing.expect.document_title(u"Tutorials"),
                       "content_title": testing.expect.paleyellow_title(0, u"Tutorials"),
                       "pageheader_links": testing.expect.pageheader_links("anonymous"),
                       "script_user": testing.expect.script_no_user() })

########NEW FILE########
__FILENAME__ = 006-news
frontend.page("news", expect={ "document_title": testing.expect.document_title(u"News"),
                               "content_title": testing.expect.paleyellow_title(0, u"News"),
                               "pageheader_links": testing.expect.pageheader_links("anonymous"),
                               "script_user": testing.expect.script_no_user() })

########NEW FILE########
__FILENAME__ = 007-home
# Note: /home redirects to /login for anonymous users.
frontend.page("home", expect={ "document_title": testing.expect.document_title(u"Sign in"),
                               "content_title": testing.expect.paleyellow_title(0, u"Sign in"),
                               "pageheader_links": testing.expect.pageheader_links("anonymous"),
                               "script_user": testing.expect.script_no_user() })

########NEW FILE########
__FILENAME__ = 008-repositories
frontend.page("repositories", expect={ "document_title": testing.expect.document_title(u"Repositories"),
                                       "content_title": testing.expect.paleyellow_title(0, u"Repositories"),
                                       "pageheader_links": testing.expect.pageheader_links("anonymous"),
                                       "script_user": testing.expect.script_anonymous_user() })

########NEW FILE########
__FILENAME__ = 009-services
frontend.page("services", expect={ "document_title": testing.expect.document_title(u"Services"),
                                   "content_title": testing.expect.paleyellow_title(0, u"Services"),
                                   "pageheader_links": testing.expect.pageheader_links("anonymous"),
                                   "script_user": testing.expect.script_anonymous_user() })

########NEW FILE########
__FILENAME__ = 010-createreview
# Note: /createreview redirects to /login for anonymous users.
frontend.page("createreview", expect={ "document_title": testing.expect.document_title(u"Sign in"),
                                       "content_title": testing.expect.paleyellow_title(0, u"Sign in"),
                                       "pageheader_links": testing.expect.pageheader_links("anonymous"),
                                       "script_user": testing.expect.script_no_user() })

########NEW FILE########
__FILENAME__ = 011-manageextensions
# Only available if extension support has been enabled.  (The body of the
# message is quite long, and particularly interesting to check here.)
expected_message = testing.expect.message("Extension support not enabled", None)

frontend.page(
    "manageextensions",
    expect={ "message": expected_message })

########NEW FILE########
__FILENAME__ = 012-statistics
# The /statistics page has no <title>, and has a pale yellow table that doesn't
# have the 'paleyellow' class, and which has five (!) different main headings.
# Its generation should be fixed, but for now, just skip testing the common page
# elements that it's missing.
frontend.page("statistics", expect={ "pageheader_links": testing.expect.pageheader_links("anonymous"),
                                     "script_user": testing.expect.script_no_user() })

########NEW FILE########
__FILENAME__ = 013-static-resource
def check_user_constructor(document):
    expected = "<User constructor found>"
    if "\nfunction User(" in document:
        actual = expected
    else:
        actual = "<no User constructor found>"
    testing.expect.check(expected, actual)

def check_jquery_foundation(document):
    expected = "<jQuery header found>"
    if "jQuery Foundation, Inc" in document:
        actual = expected
    else:
        actual = "<no jQuery header found>"
    testing.expect.check(expected, actual)

# Test a basic regular file.
frontend.page(
    "static-resource/basic.js",
    expected_content_type="application/javascript",
    expect={ "user_constructor": check_user_constructor })

# Test jquery.js, which is a symlink to the current version.
frontend.page(
    "static-resource/third-party/jquery.js",
    expected_content_type="application/javascript",
    expect={ "jquery_foundation": check_jquery_foundation })

# Test a non-existing file.
frontend.page(
    "static-resource/does-not-exist.js",
    expected_http_status=404)

# Test that directory listing is not enabled.
frontend.page(
    "static-resource/",
    expected_http_status=403)

########NEW FILE########
__FILENAME__ = 001-commit.diff.rulerColumn
# Check existence of preference commit.diff.rulerColumn, added by
#
#   http://critic-review.org/r/57

def check_heading(document):
    headings = document.findAll("td", attrs={ "class": "heading" })

    for heading in headings:
        if heading.find(text="commit.diff.rulerColumn:"):
            return

    testing.expect.check("<preference heading>",
                         "<expected content not found>")

def check_input(document):
    input = document.find("input", attrs={ "name": "commit.diff.rulerColumn" })

    if not input:
        testing.expect.check("<preference input>",
                             "<expected content not found>")

    testing.expect.check("number", input["type"])
    testing.expect.check("0", input["value"])
    testing.expect.check("0", input["critic-default"])

frontend.page("config",
              expect={ "preference_heading": check_heading,
                       "preference_input": check_input })

########NEW FILE########
__FILENAME__ = 002-review.defaultOptOut
# Check existence of preference review.defaultOptOut, added by
#
#   http://critic-review.org/r/40

def check_heading(document):
    headings = document.findAll("td", attrs={ "class": "heading" })

    for heading in headings:
        if heading.find(text="review.defaultOptOut:"):
            return

    testing.expect.check("<preference heading>",
                         "<expected content not found>")

def check_input(document):
    input = document.find("input", attrs={ "name": "review.defaultOptOut" })

    if not input:
        testing.expect.check("<preference input>",
                             "<expected content not found>")

    testing.expect.check("checkbox", input["type"])
    testing.expect.check(False, input.has_key("checked"))
    testing.expect.check("false", input["critic-default"])

frontend.page("config",
              expect={ "preference_heading": check_heading,
                       "preference_input": check_input })

########NEW FILE########
__FILENAME__ = 003-timezone
# Check existence of preference review.defaultOptOut, added by
#
#   http://critic-review.org/r/40

def check_heading(document):
    headings = document.findAll("td", attrs={ "class": "heading" })

    for heading in headings:
        if heading.find(text="timezone:"):
            return

    testing.expect.check("<preference heading>",
                         "<expected content not found>")

def check_select(document):
    select = document.find("select", attrs={ "name": "timezone" })

    if not select:
        testing.expect.check("<preference select>",
                             "<expected content not found>")

    testing.expect.check('"Universal/UTC"', select["critic-default"])

    option = select.find("option", attrs={ "selected": "selected" })

    if not option:
        testing.expect.check("<pre-selected option>",
                             "<expected content not found>")

    testing.expect.check("Universal/UTC", option["value"])
    testing.expect.check("UTC (UTC / UTC+00:00)", option.string)

frontend.page("config",
              expect={ "preference_heading": check_heading,
                       "preference_input": check_select })

########NEW FILE########
__FILENAME__ = 001-dashboard
with frontend.signin():
    frontend.page("dashboard", expect={ "document_title": testing.expect.document_title(u"Dashboard"),
                                        "message_title": testing.expect.message_title(u"No reviews!"),
                                        "pageheader_links": testing.expect.pageheader_links("authenticated",
                                                                                            "administrator"),
                                        "script_user": testing.expect.script_user("admin") })

########NEW FILE########
__FILENAME__ = 002-branches
with frontend.signin():
    frontend.page(
        "branches", expect={ "document_title": testing.expect.document_title(u"Branches"),
                             "content_title": testing.expect.paleyellow_title(0, u"Branches"),
                             "pageheader_links": testing.expect.pageheader_links("authenticated",
                                                                                 "administrator"),
                             "script_user": testing.expect.script_no_user() })

########NEW FILE########
__FILENAME__ = 003-search
with frontend.signin():
    frontend.page(
        "search",
        expect={ "document_title": testing.expect.document_title(u"Review Search"),
                 "content_title": testing.expect.paleyellow_title(0, u"Review Search"),
                 "pageheader_links": testing.expect.pageheader_links("authenticated",
                                                                     "administrator"),
                 "script_user": testing.expect.script_user("admin") })

########NEW FILE########
__FILENAME__ = 004-config
with frontend.signin():
    frontend.page(
        "config",
        expect={ "document_title": testing.expect.document_title(u"User preferences"),
                 "content_title": testing.expect.paleyellow_title(0, u"User preferences"),
                 "pageheader_links": testing.expect.pageheader_links("authenticated",
                                                                     "administrator"),
                 "script_user": testing.expect.script_user("admin") })

    frontend.page(
        "config",
        params={ "defaults": "yes" },
        expect={ "document_title": testing.expect.document_title(u"User preferences"),
                 "content_title": testing.expect.paleyellow_title(0, u"User preferences"),
                 "pageheader_links": testing.expect.pageheader_links("authenticated",
                                                                     "administrator"),
                 "script_user": testing.expect.script_user("admin") })

########NEW FILE########
__FILENAME__ = 005-tutorial
with frontend.signin():
    frontend.page("tutorial",
                  expect={ "document_title": testing.expect.document_title(u"Tutorials"),
                           "content_title": testing.expect.paleyellow_title(0, u"Tutorials"),
                           "pageheader_links": testing.expect.pageheader_links("authenticated",
                                                                               "administrator"),
                           "script_user": testing.expect.script_no_user() })

    frontend.page("tutorial",
                  params={ "item": "request" },
                  expect={ "document_title": testing.expect.document_title(u"Requesting a Review"),
                           "content_title": testing.expect.paleyellow_title(0, u"Requesting a Review"),
                           "pageheader_links": testing.expect.pageheader_links("authenticated",
                                                                               "administrator"),
                           "script_user": testing.expect.script_no_user() })

    frontend.page("tutorial",
                  params={ "item": "review" },
                  expect={ "document_title": testing.expect.document_title(u"Reviewing Changes"),
                           "content_title": testing.expect.paleyellow_title(0, u"Reviewing Changes"),
                           "pageheader_links": testing.expect.pageheader_links("authenticated",
                                                                               "administrator"),
                           "script_user": testing.expect.script_no_user() })

    frontend.page("tutorial",
                  params={ "item": "filters" },
                  expect={ "document_title": testing.expect.document_title(u"Filters"),
                           "content_title": testing.expect.paleyellow_title(0, u"Filters"),
                           "pageheader_links": testing.expect.pageheader_links("authenticated",
                                                                               "administrator"),
                           "script_user": testing.expect.script_no_user() })

    frontend.page("tutorial",
                  params={ "item": "viewer" },
                  expect={ "document_title": testing.expect.document_title(u"Repository Viewer"),
                           "content_title": testing.expect.paleyellow_title(0, u"Repository Viewer"),
                           "pageheader_links": testing.expect.pageheader_links("authenticated",
                                                                               "administrator"),
                           "script_user": testing.expect.script_no_user() })

    frontend.page("tutorial",
                  params={ "item": "reconfigure" },
                  expect={ "document_title": testing.expect.document_title(u"Reconfiguring Critic"),
                           "content_title": testing.expect.paleyellow_title(0, u"Reconfiguring Critic"),
                           "pageheader_links": testing.expect.pageheader_links("authenticated",
                                                                               "administrator"),
                           "script_user": testing.expect.script_no_user() })

    frontend.page("tutorial",
                  params={ "item": "rebase" },
                  expect={ "document_title": testing.expect.document_title(u"Rebasing a Review"),
                           "content_title": testing.expect.paleyellow_title(0, u"Rebasing a Review"),
                           "pageheader_links": testing.expect.pageheader_links("authenticated",
                                                                               "administrator"),
                           "script_user": testing.expect.script_no_user() })

    frontend.page("tutorial",
                  params={ "item": "administration" },
                  expect={ "document_title": testing.expect.document_title(u"System Administration"),
                           "content_title": testing.expect.paleyellow_title(0, u"System Administration"),
                           "pageheader_links": testing.expect.pageheader_links("authenticated",
                                                                               "administrator"),
                           "script_user": testing.expect.script_no_user() })

    frontend.page("tutorial",
                  params={ "item": "customization" },
                  expect={ "document_title": testing.expect.document_title(u"System Customization"),
                           "content_title": testing.expect.paleyellow_title(0, u"System Customization"),
                           "pageheader_links": testing.expect.pageheader_links("authenticated",
                                                                               "administrator"),
                           "script_user": testing.expect.script_no_user() })

    frontend.page("tutorial",
                  params={ "item": "search" },
                  expect={ "document_title": testing.expect.document_title(u"Review Quick Search"),
                           "content_title": testing.expect.paleyellow_title(0, u"Review Quick Search"),
                           "pageheader_links": testing.expect.pageheader_links("authenticated",
                                                                               "administrator"),
                           "script_user": testing.expect.script_no_user() })

    # Unknown items are ignored and the main Tutorials page is returned instead.
    frontend.page("tutorial",
                  params={ "item": "nonexisting" },
                  expect={ "document_title": testing.expect.document_title(u"Tutorials"),
                           "content_title": testing.expect.paleyellow_title(0, u"Tutorials"),
                           "pageheader_links": testing.expect.pageheader_links("authenticated",
                                                                               "administrator"),
                           "script_user": testing.expect.script_no_user() })

########NEW FILE########
__FILENAME__ = 006-news
with frontend.signin():
    frontend.page("news", expect={ "document_title": testing.expect.document_title(u"News"),
                                   "content_title": testing.expect.paleyellow_title(0, u"News"),
                                   "pageheader_links": testing.expect.pageheader_links("authenticated",
                                                                                       "administrator"),
                                   "script_user": testing.expect.script_no_user() })

########NEW FILE########
__FILENAME__ = 007-home
with frontend.signin():
    frontend.page(
        "home",
        expect={ "document_title": testing.expect.document_title(u"Testing Administrator's Home"),
                 "content_title": testing.expect.paleyellow_title(0, u"Testing Administrator's Home"),
                 "pageheader_links": testing.expect.pageheader_links("authenticated",
                                                                     "administrator"),
                 "script_user": testing.expect.script_user("admin") })

with frontend.signin("bob"):
    frontend.operation(
        "changepassword",
        data={ "current_pw": "testing",
               "new_pw": "gnitset" })

try:
    frontend.operation(
        "validatelogin",
        data={ "username": "bob",
               "password": "testing" },
        expect={ "message": "Wrong password!" })
except testing.TestFailure:
    # Make sure we don't accidentally stay signed in.
    frontend.signout()

with frontend.signin("bob", "gnitset"):
    pass

with frontend.signin():
    frontend.operation(
        "changepassword",
        data={ "subject": "bob",
               "new_pw": "testing" })

with frontend.signin("bob"):
    pass

########NEW FILE########
__FILENAME__ = 008-repositories
with frontend.signin():
    frontend.page("repositories", expect={ "document_title": testing.expect.document_title(u"Repositories"),
                                           "content_title": testing.expect.paleyellow_title(0, u"Repositories"),
                                           "pageheader_links": testing.expect.pageheader_links("authenticated",
                                                                                               "administrator"),
                                           "script_user": testing.expect.script_user("admin") })

########NEW FILE########
__FILENAME__ = 009-services
import time

services = {}

with_class = testing.expect.with_class
extract_text = testing.expect.extract_text

def check_services(services, restarted=frozenset()):
    if isinstance(restarted, basestring):
        restarted = frozenset([restarted])

    def checker(document):
        expected = set(services.keys())

        for service_tr in document.findAll("tr", attrs=with_class("service")):
            td_name = service_tr.find("td", attrs=with_class("name"))
            td_pid = service_tr.find("td", attrs=with_class("pid"))
            td_rss = service_tr.find("td", attrs=with_class("rss"))

            name = str(extract_text(td_name))
            pid = extract_text(td_pid)
            rss = extract_text(td_rss)

            try:
                pid = int(pid)
            except ValueError:
                if pid == "(not running)":
                    testing.logger.error("Service %r is not running!" % name)
                else:
                    testing.logger.error(
                        "Service %r has unexpected PID value: %r" % (name, pid))
            else:
                if rss == "N/A":
                    testing.logger.error("Service %r is not running "
                                         "(and the PID value is stale...)!"
                                         % name)

            if name in restarted:
                if pid == services[name]:
                    testing.logger.error(
                        "Service %r not restarted as expected!" % name)
            elif name in services:
                testing.expect.check(services[name], pid,
                                     message="service unexpectedly restarted")

            if name in expected:
                expected.remove(name)

            services[name] = pid

        if expected:
            testing.logger.error("Service(s) have gone missing: %r"
                                 % ", ".join(expected))

    return checker

with frontend.signin():
    services = {}

    frontend.page(
        "services",
        expect={ "document_title": testing.expect.document_title(u"Services"),
                 "content_title": testing.expect.paleyellow_title(0, u"Services"),
                 "pageheader_links": testing.expect.pageheader_links("authenticated",
                                                                     "administrator"),
                 "script_user": testing.expect.script_user("admin"),
                 "services": check_services(services) })

    all_services = set(["manager"])

    for service_name in services.keys():
        if service_name != "manager" and not service_name.startswith("wsgi:"):
            all_services.add(service_name)

            frontend.operation(
                "restartservice",
                data={ "service_name": service_name })

            frontend.page(
                "services",
                expect={ "services": check_services(services, service_name) })

    # Need to give the last service(s) restarted some time to actually start up;
    # otherwise they might receive their TERM signal before they register a
    # signal handler.
    time.sleep(0.5)

    frontend.operation(
        "restartservice",
        data={ "service_name": "manager" })

    # Need to give the service manager some time to actually restart.  Or rather
    # time to stop; once it has stopped, the /services page has code that waits
    # (up to 10 seconds) for it to start up again, should it not be up and
    # running already.
    time.sleep(0.5)

    frontend.page(
        "services",
        expect={ "services": check_services(services, all_services) })

########NEW FILE########
__FILENAME__ = 010-createreview
with frontend.signin():
    frontend.page("createreview", expect={ "document_title": testing.expect.document_title(u"Create Review"),
                                           "content_title": testing.expect.paleyellow_title(0, u"Create Review"),
                                           "pageheader_links": testing.expect.pageheader_links("authenticated",
                                                                                               "administrator"),
                                           "script_user": testing.expect.script_user("admin") })

########NEW FILE########
__FILENAME__ = 011-manageextensions
# Only available if extension support has been enabled.  (The body of the
# message is quite long, and particularly interesting to check here.)
expected_message = testing.expect.message("Extension support not enabled", None)

with frontend.signin():
    frontend.page(
        "manageextensions",
        expect={ "message": expected_message })

########NEW FILE########
__FILENAME__ = 012-statistics
# The /statistics page has no <title>, and has a pale yellow table that doesn't
# have the 'paleyellow' class, and which has five (!) different main headings.
# Its generation should be fixed, but for now, just skip testing the common page
# elements that it's missing.
with frontend.signin():
    frontend.page("statistics", expect={ "pageheader_links": testing.expect.pageheader_links("authenticated",
                                                                                             "administrator"),
                                         "script_user": testing.expect.script_no_user() })

########NEW FILE########
__FILENAME__ = 001-commit.diff.rulerColumn
# Check existence of preference commit.diff.rulerColumn, added by
#
#   http://critic-review.org/r/57

def check_heading(document):
    headings = document.findAll("td", attrs={ "class": "heading" })

    for heading in headings:
        if heading.find(text="commit.diff.rulerColumn:"):
            return

    testing.expect.check("<preference heading>",
                         "<expected content not found>")

def check_input(document):
    input = document.find("input", attrs={ "name": "commit.diff.rulerColumn" })

    if not input:
        testing.expect.check("<preference input>",
                             "<expected content not found>")

    testing.expect.check("number", input["type"])
    testing.expect.check("0", input["value"])
    testing.expect.check("0", input["critic-default"])

with frontend.signin():
    frontend.page("config",
                  expect={ "preference_heading": check_heading,
                           "preference_input": check_input })

########NEW FILE########
__FILENAME__ = 002-review.defaultOptOut
# Check existence of preference review.defaultOptOut, added by
#
#   http://critic-review.org/r/40

def check_heading(document):
    headings = document.findAll("td", attrs={ "class": "heading" })

    for heading in headings:
        if heading.find(text="review.defaultOptOut:"):
            return

    testing.expect.check("<preference heading>",
                         "<expected content not found>")

def check_input(document):
    input = document.find("input", attrs={ "name": "review.defaultOptOut" })

    if not input:
        testing.expect.check("<preference input>",
                             "<expected content not found>")

    testing.expect.check("checkbox", input["type"])
    testing.expect.check(False, input.has_key("checked"))
    testing.expect.check("false", input["critic-default"])

with frontend.signin():
    frontend.page("config",
                  expect={ "preference_heading": check_heading,
                           "preference_input": check_input })

########NEW FILE########
__FILENAME__ = 003-timezone
# Check existence of preference review.defaultOptOut, added by
#
#   http://critic-review.org/r/40

def check_heading(document):
    headings = document.findAll("td", attrs={ "class": "heading" })

    for heading in headings:
        if heading.find(text="timezone:"):
            return

    testing.expect.check("<preference heading>",
                         "<expected content not found>")

def check_select(document):
    select = document.find("select", attrs={ "name": "timezone" })

    if not select:
        testing.expect.check("<preference select>",
                             "<expected content not found>")

    testing.expect.check('"Universal/UTC"', select["critic-default"])

    option = select.find("option", attrs={ "selected": "selected" })

    if not option:
        testing.expect.check("<pre-selected option>",
                             "<expected content not found>")

    testing.expect.check("Universal/UTC", option["value"])
    testing.expect.check("UTC (UTC / UTC+00:00)", option.string)

with frontend.signin():
    frontend.page("config",
                  expect={ "preference_heading": check_heading,
                           "preference_input": check_select })

########NEW FILE########
__FILENAME__ = 001-basic
def expect_success(argv, expected_output_lines=[]):
    try:
        output = instance.execute(argv)
    except testing.virtualbox.GuestCommandError as error:
        logger.error("'%s': correct criticctl usage failed:\n%s"
                     % (" ".join(argv), error.stdout))
        return []
    else:
        output_lines = set(map(str.strip, output.splitlines()))
        for line in expected_output_lines:
            if line.strip() not in output_lines:
                logger.error("'%s': Expected output line not found:\n  %r"
                             % (" ".join(argv), line))
        return output_lines

def expect_failure(argv, expected_output_lines=[]):
    try:
        instance.execute(argv)
    except testing.virtualbox.GuestCommandError as error:
        output_lines = set(map(str.strip, error.stderr.splitlines()))
        for line in expected_output_lines:
            if line.strip() not in output_lines:
                logger.error("'%s': Expected output line not found:\n  %r"
                             % (" ".join(argv), line))
        return output_lines
    else:
        logger.error("'%s': incorrect criticctl usage did not fail"
                     % " ".join(argv))
        return []

expect_failure(["criticctl"],
               ["ERROR: Failed to set UID = critic. Run as root?"])

# Test -h/--help argument.
usage_lines = expect_success(["sudo", "criticctl"],
                             ["Critic administration interface",
                              "Available commands are:"])
expect_success(["sudo", "criticctl", "-h"],
               usage_lines)
expect_success(["sudo", "criticctl", "--help"],
               usage_lines)

# Test --etc-dir/-e argument.
expect_success(["sudo", "criticctl", "--etc-dir", "/etc/critic"],
               usage_lines)
expect_success(["sudo", "criticctl", "--etc-dir=/etc/critic"],
               usage_lines)
expect_success(["sudo", "criticctl", "-e", "/etc/critic"],
               usage_lines)
expect_success(["sudo", "criticctl", "-e/etc/critic"],
               usage_lines)
lines = expect_failure(["sudo", "criticctl", "--etc-dir", "/etc/wrong"],
                       ["ERROR: Directory is inaccessible: /etc/wrong"])
expect_failure(["sudo", "criticctl", "-e", "/etc/wrong"],
               lines)
lines = expect_failure(["sudo", "criticctl", "--etc-dir"],
                       ["criticctl: error: argument --etc-dir/-e: "
                        "expected one argument"])
expect_failure(["sudo", "criticctl", "-e"],
               lines)

# Test --identity/-i argument.
expect_success(["sudo", "criticctl", "--identity", "main"],
               usage_lines)
expect_success(["sudo", "criticctl", "--identity=main"],
               usage_lines)
expect_success(["sudo", "criticctl", "-i", "main"],
               usage_lines)
expect_success(["sudo", "criticctl", "-imain"],
               usage_lines)
lines = expect_failure(["sudo", "criticctl", "--identity", "wrong"],
                       ["ERROR: Invalid identity: wrong"])
expect_failure(["sudo", "criticctl", "-i", "wrong"],
               lines)
lines = expect_failure(["sudo", "criticctl", "--identity"],
                       ["criticctl: error: argument --identity/-i: "
                        "expected one argument"])
expect_failure(["sudo", "criticctl", "-i"],
               lines)

# Test unknown arguments.
expect_failure(["sudo", "criticctl", "-x"],
               ["criticctl: error: unrecognized arguments: -x"])
expect_failure(["sudo", "criticctl", "--xxx"],
               ["criticctl: error: unrecognized arguments: --xxx"])

# Test unknown command.
lines = expect_failure(["sudo", "criticctl", "foo"],
                       ["ERROR: Invalid command: foo"])
expect_failure(["sudo", "criticctl", "-e", "/etc/critic", "foo"],
               lines)
expect_failure(["sudo", "criticctl", "-e/etc/critic", "foo"],
               lines)
expect_failure(["sudo", "criticctl", "-i", "main", "foo"],
               lines)
expect_failure(["sudo", "criticctl", "-imain", "foo"],
               lines)
expect_failure(["sudo", "criticctl", "-e", "/etc/critic", "-i", "main", "foo"],
               lines)
expect_failure(["sudo", "criticctl", "-e/etc/critic", "-imain", "foo"],
               lines)
expect_failure(["sudo", "criticctl", "-i", "main", "-e", "/etc/critic", "foo"],
               lines)
expect_failure(["sudo", "criticctl", "-imain", "-e/etc/critic", "foo"],
               lines)

########NEW FILE########
__FILENAME__ = 002-adduser-deluser
# Scenario: Try to add a user 'alice' (already exists).
try:
    instance.execute(
        ["sudo", "criticctl", "adduser",
         "--name", "alice",
         "--email", "alice@example.org",
         "--fullname", "'Alice von Testing'",
         "--password", "testing"])
except testing.virtualbox.GuestCommandError as error:
    if "alice: user exists" not in error.stderr.splitlines():
        logger.error("criticctl failed with unexpected error message:\n%s"
                     % error.stdout)
else:
    logger.error("incorrect criticctl usage did not fail")

# Scenario: Try to delete the user 'nosuchuser' (no such user).
try:
    instance.execute(
        ["sudo", "criticctl", "deluser",
         "--name", "nosuchuser"])
except testing.virtualbox.GuestCommandError as error:
    if "nosuchuser: no such user" not in error.stderr.splitlines():
        logger.error("criticctl failed with unexpected error message:\n%s"
                     % error.stdout)
else:
    logger.error("incorrect criticctl usage did not fail")

# Scenario: Add a user 'extra' and then delete the user again.
try:
    instance.execute(
        ["sudo", "criticctl", "adduser",
         "--name", "extra",
         "--email", "extra@example.org",
         "--fullname", "'Extra von Testing'",
         "--password", "testing"])
except testing.virtualbox.GuestCommandError as error:
    logger.error("correct criticctl usage failed:\n%s"
                 % error.stdout)
else:
    try:
        instance.execute(
            ["sudo", "criticctl", "deluser",
             "--name", "extra"])
    except testing.virtualbox.GuestCommandError as error:
        logger.error("correct criticctl usage failed:\n%s"
                     % error.stdout)

########NEW FILE########
__FILENAME__ = 003-addrole-delrole
ROLES = ["administrator", "developer", "newswriter", "repositories"]

# Scenario: Try to add a role that 'admin' already has.
try:
    output = instance.execute(
        ["sudo", "criticctl", "addrole",
         "--name", "admin",
         "--role", "administrator"])
    expected_output = "admin: user already has role 'administrator'"
    if expected_output not in output.splitlines():
        logger.error("Expected output not found: %r\n%s"
                     % (expected_output, output))
except testing.virtualbox.GuestCommandError as error:
    logger.error("correct criticctl usage failed:\n%s"
                 % error.stdout)

# Scenario: Try to delete a role 'alice' doesn't have.
try:
    output = instance.execute(
        ["sudo", "criticctl", "delrole",
         "--name", "alice",
         "--role", "administrator"])
    expected_output = "alice: user doesn't have role 'administrator'"
    if expected_output not in output.splitlines():
        logger.error("Expected output not found: %r\n%s"
                     % (expected_output, output))
except testing.virtualbox.GuestCommandError as error:
    logger.error("correct criticctl usage failed:\n%s"
                 % error.stdout)

# Scenario: Try to add a role to a non-existing user.
try:
    instance.execute(
        ["sudo", "criticctl", "addrole",
         "--name", "nosuchuser",
         "--role", "administrator"])
except testing.virtualbox.GuestCommandError as error:
    if "nosuchuser: no such user" not in error.stderr.splitlines():
        logger.error("criticctl failed with unexpected error message:\n%s"
                     % error.stdout)
else:
    logger.error("incorrect criticctl usage did not fail: "
                 "addrole, non-existing user")

# Scenario: Try to delete a role from a non-existing user.
try:
    instance.execute(
        ["sudo", "criticctl", "delrole",
         "--name", "nosuchuser",
         "--role", "administrator"])
except testing.virtualbox.GuestCommandError as error:
    if "nosuchuser: no such user" not in error.stderr.splitlines():
        logger.error("criticctl failed with unexpected error message:\n%s"
                     % error.stdout)
else:
    logger.error("incorrect criticctl usage did not fail: "
                 "delrole, non-existing user")

# Scenario: Try to add an invalid role.
try:
    instance.execute(
        ["sudo", "criticctl", "addrole",
         "--name", "alice",
         "--role", "joker"])
except testing.virtualbox.GuestCommandError as error:
    if "invalid choice: 'joker'" not in error.stderr:
        logger.error("criticctl failed with unexpected error message:\n%s"
                     % error.stderr)
else:
    logger.error("incorrect criticctl usage did not fail: "
                 "addrole, invalid role")

# Scenario: Try to delete an invalid role.
try:
    instance.execute(
        ["sudo", "criticctl", "delrole",
         "--name", "alice",
         "--role", "joker"])
except testing.virtualbox.GuestCommandError as error:
    if "invalid choice: 'joker'" not in error.stderr:
        logger.error("criticctl failed with unexpected error message:\n%s"
                     % error.stderr)
else:
    logger.error("incorrect criticctl usage did not fail: "
                 "delrole, invalid role")

# Scenario: Add and then delete each role.
def test_role(role):
    try:
        instance.execute(
            ["sudo", "criticctl", "addrole",
             "--name", "alice",
             "--role", role])
    except testing.virtualbox.GuestCommandError as error:
        logger.error("correct criticctl usage failed:\n%s"
                     % error.stdout)
    else:
        try:
            instance.execute(
                ["sudo", "criticctl", "delrole",
                 "--name", "alice",
                 "--role", role])
        except testing.virtualbox.GuestCommandError as error:
            logger.error("correct criticctl usage failed:\n%s"
                         % error.stdout)
for role in ROLES:
    test_role(role)

########NEW FILE########
__FILENAME__ = 004-listusers
# Scenario: Invalid format.
try:
    instance.execute(
        ["sudo", "criticctl", "listusers", "--format", "oranges"])
except testing.virtualbox.GuestCommandError as error:
    if "invalid choice: 'oranges'" not in error.stderr:
        logger.error("criticctl failed with unexpected error message:\n%s"
                     % error.stderr)
else:
    logger.error("incorrect criticctl usage did not fail")

expected = """\
  id |    name    |              email             |            fullname            | status
-----+------------+--------------------------------+--------------------------------+--------
   1 |      admin |              admin@example.org | Testing Administrator          | current
   2 |      alice |              alice@example.org | Alice von Testing              | current
   3 |        bob |                bob@example.org | Bob von Testing                | current
   4 |       dave |               dave@example.org | Dave von Testing               | current
   5 |       erin |               erin@example.org | Erin von Testing               | current
   6 |     howard |             howard@example.org | Howard von Testing             | current
   7 |      extra |              extra@example.org | Extra von Testing              | retired

"""

# Scenario: Default / human readable format.
try:
    output = instance.execute(["sudo", "criticctl", "listusers"])
except testing.virtualbox.GuestCommandError as error:
    logger.error("correct criticctl usage failed:\n%s"
                 % error.stdout)
else:
    testing.expect.check(expected, output)

try:
    output = instance.execute(["sudo", "criticctl", "listusers",
                               "-f", "table"])
except testing.virtualbox.GuestCommandError as error:
    logger.error("correct criticctl usage failed:\n%s"
                 % error.stdout)
else:
    testing.expect.check(expected, output)

try:
    output = instance.execute(["sudo", "criticctl", "listusers",
                               "--format", "table"])
except testing.virtualbox.GuestCommandError as error:
    logger.error("correct criticctl usage failed:\n%s"
                 % error.stdout)
else:
    testing.expect.check(expected, output)

expected = """\
# id, name, email, fullname, status
[
 (1, 'admin', 'admin@example.org', 'Testing Administrator', 'current'),
 (2, 'alice', 'alice@example.org', 'Alice von Testing', 'current'),
 (3, 'bob', 'bob@example.org', 'Bob von Testing', 'current'),
 (4, 'dave', 'dave@example.org', 'Dave von Testing', 'current'),
 (5, 'erin', 'erin@example.org', 'Erin von Testing', 'current'),
 (6, 'howard', 'howard@example.org', 'Howard von Testing', 'current'),
 (7, 'extra', 'extra@example.org', 'Extra von Testing', 'retired'),
]
"""

# Scenario: Tuples format.
try:
    output = instance.execute(["sudo", "criticctl", "listusers",
                               "-f", "tuples"])
except testing.virtualbox.GuestCommandError as error:
    logger.error("correct criticctl usage failed:\n%s"
                 % error.stdout)
else:
    testing.expect.check(expected, output)

try:
    output = instance.execute(["sudo", "criticctl", "listusers",
                               "--format", "tuples"])
except testing.virtualbox.GuestCommandError as error:
    logger.error("correct criticctl usage failed:\n%s"
                 % error.stdout)
else:
    testing.expect.check(expected, output)

expected = """\
[
 {'id': 1, 'name': 'admin', 'email': 'admin@example.org', 'fullname': 'Testing Administrator', 'status': 'current'},
 {'id': 2, 'name': 'alice', 'email': 'alice@example.org', 'fullname': 'Alice von Testing', 'status': 'current'},
 {'id': 3, 'name': 'bob', 'email': 'bob@example.org', 'fullname': 'Bob von Testing', 'status': 'current'},
 {'id': 4, 'name': 'dave', 'email': 'dave@example.org', 'fullname': 'Dave von Testing', 'status': 'current'},
 {'id': 5, 'name': 'erin', 'email': 'erin@example.org', 'fullname': 'Erin von Testing', 'status': 'current'},
 {'id': 6, 'name': 'howard', 'email': 'howard@example.org', 'fullname': 'Howard von Testing', 'status': 'current'},
 {'id': 7, 'name': 'extra', 'email': 'extra@example.org', 'fullname': 'Extra von Testing', 'status': 'retired'},
]
"""

# Scenario: Dicts format.
try:
    output = instance.execute(["sudo", "criticctl", "listusers",
                               "-f", "dicts"])
except testing.virtualbox.GuestCommandError as error:
    logger.error("correct criticctl usage failed:\n%s"
                 % error.stdout)
else:
    testing.expect.check(expected, output)

try:
    output = instance.execute(["sudo", "criticctl", "listusers",
                               "--format", "dicts"])
except testing.virtualbox.GuestCommandError as error:
    logger.error("correct criticctl usage failed:\n%s"
                 % error.stdout)
else:
    testing.expect.check(expected, output)

########NEW FILE########
__FILENAME__ = 005-configtest
try:
    output = instance.execute(["sudo", "criticctl", "configtest"])
except testing.virtualbox.GuestCommandError as error:
    logger.error("correct criticctl usage failed:\n%s"
                 % error.stdout)
else:
    testing.expect.check("System configuration valid.\n", output)

########NEW FILE########
__FILENAME__ = 006-restart
try:
    output = instance.execute(["sudo", "criticctl", "restart"])
except testing.virtualbox.GuestCommandError as error:
    logger.error("correct criticctl usage failed:\n%s"
                 % error.stdout)
else:
    # Expected output is system dependent, so don't check.
    pass

########NEW FILE########
__FILENAME__ = 001-newswriter
import re

def unread_news_count(document):
    pageheader = document.find("table", attrs={ "class": "pageheader" })
    for link in pageheader.find("ul").findAll("a"):
        m = re.match("News \((\d+)\)", link.string)
        if m:
            return int(m.group(1))
    return 0

NEWSTEXT = "I'm as mad as hell, and I'm not going to take this anymore."

with frontend.signin("alice"):
    dashboard = frontend.page("dashboard", expect={ "document_title": testing.expect.document_title(u"Dashboard") })
    initial_unread = unread_news_count(dashboard)

with frontend.signin("howard"):
    response = frontend.operation(
        "addnewsitem",
        data={ "text": "I'm as mad as hell" })
    newsitem_id = response["item_id"]

    frontend.operation(
        "editnewsitem",
        data={ "item_id": newsitem_id,
               "text": NEWSTEXT })

with frontend.signin("alice"):
    dashboard = frontend.page("dashboard", expect={ "document_title": testing.expect.document_title(u"Dashboard") })
    testing.expect.check(initial_unread + 1, unread_news_count(dashboard))

    newsitem = frontend.page("news", params={ "item": newsitem_id })
    newstext = newsitem.find("td", attrs={ "class": "text" })
    testing.expect.check(NEWSTEXT, testing.expect.extract_text(newstext).strip())

    dashboard = frontend.page("dashboard", expect={ "document_title": testing.expect.document_title(u"Dashboard") })
    testing.expect.check(initial_unread, unread_news_count(dashboard))

    frontend.operation(
        "addnewsitem",
        data={ "text": "Quid quid latine dictum sit, altum viditur." },
        expect={ "status": "failure",
                 "code": "notallowed" })

    frontend.operation(
        "editnewsitem",
        data={ "item_id": newsitem_id,
               "text": "It's all hat, no cattle." },
        expect={ "status": "failure",
                 "code": "notallowed" })

with frontend.signin("bob"):
    # Howard's news item should still be unread by bob.
    dashboard = frontend.page("dashboard", expect={ "document_title": testing.expect.document_title(u"Dashboard") })
    testing.expect.check(initial_unread + 1, unread_news_count(dashboard))

# Anonymous users should not be able to add or edit news items.
frontend.operation(
    "addnewsitem",
    data={ "text": "If you have a lifetime warranty on something, it is also a hammer." },
    expect={ "status": "failure",
             "code": "mustlogin" })

frontend.operation(
    "editnewsitem",
    data={ "item_id": newsitem_id,
           "text": "The only completely consistent people are dead." },
    expect={ "status": "failure",
             "code": "mustlogin" })

########NEW FILE########
__FILENAME__ = 002-email
import re

with_class = testing.expect.with_class
extract_text = testing.expect.extract_text

def extract_addresses(document):
    addresses = []
    for address in document.findAll(attrs=with_class("address")):
        email_id = int(address["data-email-id"])
        selected = "selected" in address["class"].split()
        value = address.find(attrs=with_class("value")).string
        if address.find(attrs=with_class("verified")):
            verified = "verified"
        elif address.find(attrs=with_class("unverified")):
            verified = "unverified"
        else:
            verified = None
        addresses.append((email_id, selected, value, verified))
    return addresses

def emails(expected):
    def check(document):
        actual = [(selected, value, verified)
                  for _, selected, value, verified
                  in extract_addresses(document)]
        testing.expect.check(expected, actual)
    return check

def no_emails(document):
    row = document.find("tr", attrs=with_class("email"))
    testing.expect.check(
        "No email address",
        extract_text(row.find("td", attrs=with_class("value")).find("i")))

ALICE_ID = 2
ALICE_AT_EXAMPLE = "alice@example.org"
ALICE_AT_WONDERLAND = "alice@wonderland.net"
RE_ALICE_AT_WONDERLAND = r"alice@wonderland\.net"

with frontend.signin("alice"):
    # Check initial state.

    frontend.page(
        "home",
        expect={ "addresses": emails([(True, ALICE_AT_EXAMPLE, None)]) })

    # Add another, initially unverified, email address.

    frontend.operation(
        "addemailaddress",
        data={ "subject_id": ALICE_ID,
               "email": "alice@wonderland.net" })

    document = frontend.page(
        "home",
        expect={ "addresses": emails(
                [(True, ALICE_AT_EXAMPLE, None),
                 (False, ALICE_AT_WONDERLAND, "unverified")]) })

    addresses = extract_addresses(document)
    alice_at_example_id = addresses[0][0]
    alice_at_wonderland_id = addresses[1][0]

    # Check that we got a verification mail.

    subject = r"\[Critic\] Please verify your email: " + RE_ALICE_AT_WONDERLAND

    verification_mail = mailbox.pop(
        accept=[testing.mailbox.ToRecipient(ALICE_AT_WONDERLAND),
                testing.mailbox.WithSubject(subject)])

    # Extract the verification link from the verification mail.

    for line in verification_mail.lines:
        match = re.match(
            r"\s+http://[^/]+/verifyemail\?email=([^&]+)&token=([^&]+)", line)
        if match:
            email, token = match.groups()
            testing.expect.check(ALICE_AT_WONDERLAND, email)
            break
    else:
        testing.expect.check(
            "<verification link in verification mail>",
            "<expected content not found>")

    # Request another verification mail.

    frontend.operation(
        "requestverificationemail",
        data={ "email_id": alice_at_wonderland_id })

    mailbox.pop(accept=[testing.mailbox.ToRecipient(ALICE_AT_WONDERLAND),
                        testing.mailbox.WithSubject(subject)])

    # Verify the new email address.

    response = frontend.page(
        "verifyemail",
        params={ "email": ALICE_AT_WONDERLAND,
                 "token": token },
        disable_redirects=True,
        expected_http_status=307)

    testing.expect.check(
        "/home?email_verified=%d" % alice_at_wonderland_id,
        response.headers["Location"])

    # Check that it's now displayed as verified.

    frontend.page(
        "home",
        params={ "email_verified": str(alice_at_wonderland_id) },
        expect={ "addresses": emails(
                [(True, ALICE_AT_EXAMPLE, None),
                 (False, ALICE_AT_WONDERLAND, "verified")]) })

    # Make the new address the selected one.

    frontend.operation(
        "selectemailaddress",
        data={ "email_id": alice_at_wonderland_id })

    frontend.page(
        "home",
        expect={ "addresses": emails(
                [(False, ALICE_AT_EXAMPLE, None),
                 (True, ALICE_AT_WONDERLAND, "verified")]) })

    # Try to delete the now selected address.

    frontend.operation(
        "deleteemailaddress",
        data={ "email_id": alice_at_wonderland_id },
        expect={ "status": "failure",
                 "code": "notallowed" })

    frontend.page(
        "home",
        expect={ "addresses": emails(
                [(False, ALICE_AT_EXAMPLE, None),
                 (True, ALICE_AT_WONDERLAND, "verified")]) })

    # Delete the other address instead.

    frontend.operation(
        "deleteemailaddress",
        data={ "email_id": alice_at_example_id })

    frontend.page(
        "home",
        expect={ "addresses": emails(
                [(True, ALICE_AT_WONDERLAND, "verified")]) })

    # Now delete the single, selected address.

    frontend.operation(
        "deleteemailaddress",
        data={ "email_id": alice_at_wonderland_id })

    frontend.page(
        "home",
        expect={ "addresses": no_emails })

with frontend.signin():
    # Re-add Alice's original address as the system administrator.

    frontend.operation(
        "addemailaddress",
        data={ "subject_id": ALICE_ID,
               "email": ALICE_AT_EXAMPLE })

    frontend.page(
        "home",
        params={ "user": "alice" },
        expect={ "addresses": emails([(True, ALICE_AT_EXAMPLE, None)]) })

########NEW FILE########
__FILENAME__ = 003-oauth
import re
import urllib
import urlparse

def externalauthURL(name):
    return "externalauth/%s?%s" % (name, urllib.urlencode({ "target": "/" }))

with_class = testing.expect.with_class

def isprefix(expected, actual):
    return actual.startswith(expected)
def issuffix(expected, actual):
    return actual.endswith(expected)

def expect_system_mail(subject):
    system_mail = mailbox.pop(testing.mailbox.ToRecipient("system@example.org"))
    testing.expect.check(subject, system_mail.headers["subject"][0]["value"])

def start_externalauth(name):
    response = frontend.page(
        externalauthURL(name),
        disable_redirects=True,
        expected_http_status=302)

    redirect_url = response.headers["Location"]

    testing.expect.check("https://example.com/authorize?",
                         redirect_url,
                         equal=isprefix)

    parsed_url = urlparse.urlparse(redirect_url)
    parsed_query = urlparse.parse_qs(parsed_url.query)
    state = parsed_query.get("state", ["no state received"])[0]

    if state == "no state received":
        testing.expect.check("<state parameter in authorize URI query>",
                             "<no state parameter: %r>" % parsed_url.query)

    return state

def finish_externalauth(name, state):
    response = frontend.page(
        "oauth/" + name,
        params={ "state": state,
                 "code": "correct" },
        disable_redirects=True,
        expected_http_status=302)

    return response.headers["Location"]

# Check that all the expected links to external providers are present
# on the "Sign in" page.

NAMES = ["alice", "carol", "felix", "gina"]

def oauth_links(document):
    providers = document.findAll("div", attrs=with_class("provider"))
    names = set(NAMES)
    expected_text = "Sign in using your "
    for provider in providers:
        testing.expect.check(expected_text, provider.contents[0])
        expected_text = "or "

        link = provider.find("a")
        words = link.string.split()
        testing.expect.check(2, len(words))
        testing.expect.check("account", words[-1], equal=issuffix)

        name = words[0].lower()
        if name in names:
            testing.expect.check("/" + externalauthURL(name), link["href"])
            names.remove(name)
        else:
            testing.logger.error("Unexpected provider: %r" % name)

    if names:
        testing.expect.check("<link to providers: %r>" % names,
                             "<no links found>")

frontend.page(
    "login",
    expect={ "oauth links": oauth_links })

#
# Try to sign in using the 'alice' provider, then connect alice's
# account manually, and try again.  Make some mistakes along the way.
#

state = start_externalauth("alice")

# Try with the wrong state.
frontend.page(
    "oauth/alice",
    params={ "state": "not the right state",
             "code": "irrelevant" },
    expect={ "message": testing.expect.message("Authentication failed",
                                               "Invalid OAuth state",
                                               body_equal=re.search) })
expect_system_mail(
    "wsgi: InvalidRequest: Invalid OAuth state: not the right state")

# Try with the wrong code (the right code is always "correct".)
frontend.page(
    "oauth/alice",
    params={ "state": state,
             "code": "incorrect" },
    expect={ "message": testing.expect.message("Authentication failed",
                                               "Incorrect code",
                                               body_equal=re.search) })
expect_system_mail("wsgi: Failure: Incorrect code")

redirect_url = finish_externalauth("alice", state)
message_check = testing.expect.message("User registration not enabled", None)

frontend.page(
    redirect_url,
    expect={ "message": message_check })

# Connect the account manually.
instance.execute(["sudo", "criticctl", "connect",
                  "--name", "alice",
                  "--provider", "alice",
                  "--account", "account-alice"])

# Sign in for real now.
state = start_externalauth("alice")

with frontend.signin(username=None):
    redirect_url = finish_externalauth("alice", state)
    testing.expect.check("/", redirect_url)

    if not frontend.session_id:
        testing.expect.check("<signed in after /oauth/alice>",
                             "<no session cookie set>")

    document_title_check = testing.expect.document_title(
        "Alice von Testing's Home")

    frontend.page(
        "home",
        expect={ "document title": document_title_check })

#
# Create user 'carol' by signing in using the 'carol' provider.
#

state = start_externalauth("carol")
redirect_url = finish_externalauth("carol", state)

testing.expect.check("/createuser?",
                     redirect_url,
                     equal=isprefix)

parsed_url = urlparse.urlparse(redirect_url)
parsed_query = urlparse.parse_qs(parsed_url.query)

testing.expect.check(["carol"], parsed_query.get("provider"))
testing.expect.check(["account-carol"], parsed_query.get("account"))
testing.expect.check(1, len(parsed_query.get("token")))
testing.expect.check(["/"], parsed_query.get("target"))
testing.expect.check(["carol"], parsed_query.get("username"))
testing.expect.check(["carol@example.org"], parsed_query.get("email"))
testing.expect.check(["Carol von Testing"], parsed_query.get("fullname"))

token = parsed_query.get("token")[0]

# Try with wrong account name.
frontend.operation(
    "registeruser",
    data={ "username": "carol",
           "fullname": "Carol von Testing",
           "email": "carol@example.org",
           "external": { "provider": "carol",
                         "account": "wrong-carol",
                         "token": token }},
    expect={ "message": "Invalid external authentication state." })

# Try with wrong token.
frontend.operation(
    "registeruser",
    data={ "username": "carol",
           "fullname": "Carol von Testing",
           "email": "carol@example.org",
           "external": { "provider": "carol",
                         "account": "account-carol",
                         "token": "wrong token" }},
    expect={ "message": "Invalid external authentication state." })

with frontend.signin(username=None):
    # Use right account and token.  This should leave us signed in as carol.
    frontend.operation(
        "registeruser",
        data={ "username": "carol",
               "fullname": "Carol von Testing",
               "email": "carol@example.org",
               "external": { "provider": "carol",
                             "account": "account-carol",
                             "token": token }})

    if not frontend.session_id:
        testing.expect.check("<signed in after /registeruser>",
                             "<no session cookie set>")

    # Check that the email address isn't unverified.
    def email_not_unverified(document):
        address = document.find(attrs=with_class("address"))
        if address.find(attrs=with_class("unverified")):
            testing.expect.check("<carol's email is not unverified>",
                                 "<carol's email is unverified>")

    document_title_check = testing.expect.document_title(
        "Carol von Testing's Home")

    frontend.page(
        "home",
        expect={ "document title": document_title_check,
                 "email not unverified": email_not_unverified })

    expect_system_mail("wsgi[registeruser]: User 'carol' registered")

#
# Create user 'felix' by signin in using the 'felix' provider, which
# has 'bypass_createuser' set, so this will be quick.
#

state = start_externalauth("felix")

with frontend.signin(username=None):
    redirect_url = finish_externalauth("felix", state)

    if not frontend.session_id:
        testing.expect.check("<signed in after /oauth/felix>",
                             "<no session cookie set>")

    document_title_check = testing.expect.document_title(
        "Felix von Testing's Home")

    frontend.page(
        "home",
        expect={ "document title": document_title_check,
                 "email not unverified": email_not_unverified })

    expect_system_mail("wsgi[oauth/felix]: User 'felix' registered")

#
# Create user 'gina' by signin in using the 'gina' provider, which
# has 'verify_email_addresses' set.
#

state = start_externalauth("gina")
redirect_url = finish_externalauth("gina", state)

testing.expect.check("/createuser?",
                     redirect_url,
                     equal=isprefix)

parsed_url = urlparse.urlparse(redirect_url)
parsed_query = urlparse.parse_qs(parsed_url.query)
token = parsed_query.get("token")[0]

with frontend.signin(username=None):
    # Use right account and token.  This should leave us signed in as carol.
    frontend.operation(
        "registeruser",
        data={ "username": "gina",
               "fullname": "Gina von Testing",
               "email": "gina@example.org",
               "external": { "provider": "gina",
                             "account": "account-gina",
                             "token": token }})

    if not frontend.session_id:
        testing.expect.check("<signed in after /registeruser>",
                             "<no session cookie set>")

    # Check that the email address isn't unverified.
    def email_unverified(document):
        address = document.find(attrs=with_class("address"))
        if not address.find(attrs=with_class("unverified")):
            testing.expect.check("<carol's email unverified>",
                                 "<carol's email is not unverified>")

    document_title_check = testing.expect.document_title(
        "Gina von Testing's Home")

    frontend.page(
        "home",
        expect={ "document title": document_title_check,
                 "email unverified": email_unverified })

    expect_system_mail("wsgi[registeruser]: User 'gina' registered")

    subject = r"\[Critic\] Please verify your email: gina@example\.org"

    mailbox.pop(accept=[testing.mailbox.ToRecipient("gina@example.org"),
                        testing.mailbox.WithSubject(subject)])

########NEW FILE########
__FILENAME__ = 004-password
# Create user 'iris' with no password.

instance.execute(["sudo", "criticctl", "adduser",
                  "--name", "iris",
                  "--email", "iris@example.org",
                  "--fullname", "'Iris von Testing'",
                  "--no-password"])

with_class = testing.expect.with_class

def check_password_ui(expected_value, expected_action):
    def check(document):
        row = document.find("tr", attrs=with_class("password"))
        cell = row.find("td", attrs=with_class("value"))
        button = cell.find("button")

        testing.expect.check(expected_value, cell.contents[0])
        testing.expect.check(
            expected_action, button.string if button else "(no action)")
    return check

with frontend.signin("alice"):
    frontend.page(
        "home",
        params={ "user": "iris" },
        expect={ "password UI": check_password_ui("not set", "(no action)") })

with frontend.signin():
    frontend.page(
        "home",
        params={ "user": "iris",
                 "readonly": "no" },
        expect={ "password UI": check_password_ui("not set", "Set password") })

    frontend.operation(
        "changepassword",
        data={ "subject": "iris",
               "new_pw": "testing" })

    frontend.page(
        "home",
        params={ "user": "iris",
                 "readonly": "no" },
        expect={ "password UI": check_password_ui("****", "Set password") })

with frontend.signin("alice"):
    frontend.page(
        "home",
        params={ "user": "iris" },
        expect={ "password UI": check_password_ui("****", "(no action)") })

with frontend.signin("iris"):
    frontend.page(
        "home",
        expect={ "password UI": check_password_ui("****", "Change password") })

    frontend.operation(
        "changepassword",
        data={ "subject": "alice",
               "new_pw": "custom" },
        expect={ "status": "failure",
                 "code": "notallowed" })

    frontend.operation(
        "changepassword",
        data={ "subject": "iris",
               "new_pw": "custom" },
        expect={ "status": "failure",
                 "message": "No current password provided." })

    frontend.operation(
        "changepassword",
        data={ "subject": "iris",
               "current_pw": "wrong",
               "new_pw": "custom" },
        expect={ "status": "failure",
                 "message": "The provided current password is not correct." })

    frontend.operation(
        "changepassword",
        data={ "subject": "iris",
               "current_pw": "testing",
               "new_pw": "custom" })

    frontend.page(
        "home",
        expect={ "password UI": check_password_ui("****", "Change password") })

with frontend.signin("iris", "custom"):
    instance.execute(["sudo", "criticctl", "passwd",
                      "--name", "iris", "--no-password"])

    frontend.page(
        "home",
        expect={ "password UI": check_password_ui("not set", "Set password") })

    frontend.operation(
        "changepassword",
        data={ "subject": "iris",
               "current_pw": "wrong",
               "new_pw": "testing" },
        expect={ "status": "failure",
                 "message": "The provided current password is not correct." })

    frontend.operation(
        "changepassword",
        data={ "subject": "iris",
               "new_pw": "testing" })

    frontend.page(
        "home",
        expect={ "password UI": check_password_ui("****", "Change password") })

instance.execute(["sudo", "criticctl", "passwd",
                  "--name", "iris", "--password", "other"])

with frontend.signin("iris", "other"):
    frontend.page(
        "home",
        expect={ "password UI": check_password_ui("****", "Change password") })

# Try changing admin's password too.

with frontend.signin():
    frontend.page(
        "home",
        expect={ "password UI": check_password_ui("****", "Change password") })

    frontend.operation(
        "changepassword",
        data={ "new_pw": "custom" },
        expect={ "status": "failure",
                 "message": "No current password provided." })

    frontend.operation(
        "changepassword",
        data={ "current_pw": "wrong",
               "new_pw": "custom" },
        expect={ "status": "failure",
                 "message": "The provided current password is not correct." })

    frontend.operation(
        "changepassword",
        data={ "current_pw": "testing",
               "new_pw": "custom" })

    frontend.page(
        "home",
        expect={ "password UI": check_password_ui("****", "Change password") })

    # Better change it back again, or we'd break lots of following tests...

    frontend.operation(
        "changepassword",
        data={ "current_pw": "custom",
               "new_pw": "testing" })

########NEW FILE########
__FILENAME__ = 002-createrepository
import time

def check_repository(document):
    rows = document.findAll("tr", attrs=testing.expect.with_class("repository"))
    testing.expect.check(1, len(rows))

    def check_cell(row, class_name, expected_string, inline_element_type=None):
        cells = row.findAll("td", attrs=testing.expect.with_class(class_name))
        testing.expect.check(1, len(cells))
        if inline_element_type:
            testing.expect.check(1, len(cells[0].findAll(inline_element_type)))
            string = cells[0].findAll("i")[0].string
        else:
            string = cells[0].string
        if string is None:
            string = ""
        testing.expect.check(expected_string, string)

    check_cell(rows[0], "name", "critic")
    check_cell(rows[0], "location", "http://%s/critic.git" % instance.hostname)
    check_cell(rows[0], "upstream", "&nbsp;")

    rows = document.findAll("tr", attrs=testing.expect.with_class("details"))
    testing.expect.check(1, len(rows))

    tables = rows[0].findAll("table", attrs=testing.expect.with_class("trackedbranches"))
    testing.expect.check(1, len(tables))

    # Would like to use 'tables[0].findAll()' here, but BeautifulSoup apparently
    # doesn't parse nested tables correctly, so these rows aren't actually part
    # of the 'trackedbranches' table according to it.
    rows = document.findAll("tr", attrs=testing.expect.with_class("branch"))
    testing.expect.check(2, len(rows))

    check_cell(rows[0], "localname", "Tags", inline_element_type="i")
    check_cell(rows[0], "remote", repository.url)
    check_cell(rows[0], "remotename", "N/A", inline_element_type="i")
    check_cell(rows[0], "enabled", "Yes")
    check_cell(rows[0], "users", "")

    check_cell(rows[1], "localname", "master")
    check_cell(rows[1], "remote", repository.url)
    check_cell(rows[1], "remotename", "master")
    check_cell(rows[1], "enabled", "Yes")
    check_cell(rows[1], "users", "")

with frontend.signin():
    # Check that this URL isn't handled already.  We're using it later to detect
    # that the repository has been created and the tracked branch fetched, and
    # if it's already handled for some reason, that check won't be reliable.
    frontend.page("critic/master", expected_http_status=404)

    frontend.operation("addrepository",
                       data={ "name": "critic",
                              "path": "critic",
                              "remote": { "url": repository.url,
                                          "branch": "master" }})

    # If it hasn't happened after 30 seconds, something must be wrong.
    deadline = time.time() + 30
    finished = False

    while not finished and time.time() < deadline:
        # The frontend.page() function returns None if the HTTP status was
        # 404, and a BeautifulSoup object if it was 200.
        if frontend.page("critic/master", expected_http_status=[200, 404]) is None:
            time.sleep(0.5)
            try:
                mailbox.pop(
                    accept=testing.mailbox.WithSubject("^branchtracker.log: "),
                    timeout=0)
            except testing.mailbox.MissingMail:
                pass
            else:
                raise testing.TestFailure
        else:
            finished = True

    if not finished:
        logger.error("Repository main branch ('refs/heads/master') not fetched after 30 seconds.")
        raise testing.TestFailure

    # Check that /repositories still loads correctly now that there's a
    # repository in the system.
    frontend.page(
        "repositories",
        expect={ "document_title": testing.expect.document_title(u"Repositories"),
                 "content_title": testing.expect.paleyellow_title(0, u"Repositories"),
                 "repository": check_repository })

    frontend.operation("addrepository",
                       data={ "name": "a" * 65,
                              "path": "validpath2" },
                       expect={ "status": "failure",
                                "code": "paramtoolong:data.name" })

    frontend.operation("addrepository",
                       data={ "name": "",
                              "path": "validpath1" },
                       expect={ "status": "failure",
                                "code": "paramtooshort:data.name" })

    frontend.operation("addrepository",
                       data={ "name": "a/b",
                              "path": "validpath3" },
                       expect={ "status": "failure",
                                "code": "paramcontainsillegalchar:data.name",
                                "message": "invalid input: short name may not contain the character '/'" })

    frontend.operation("addrepository",
                       data={ "name": "critic.git",
                              "path": "validpath3" },
                       expect={ "status": "failure",
                                "code": "badsuffix_name" })

    frontend.operation("addrepository",
                       data={ "name": "r",
                              "path": "validpath" },
                       expect={ "status": "failure",
                                "code": "invalid_name" })

########NEW FILE########
__FILENAME__ = 001-rulerColumn
import re

# This is an arbitrary (and fairly small) commit on master:
COMMIT = "927e2ba833cb0c9ce588b5f59c42bbb246e3e20c"

def check_rulerColumn(document):
    for script in document.findAll("script"):
        # Ignore external scripts.
        if script.has_key("src"):
            continue

        if re.match(r"var\s+rulerColumn\s*=\s*0;", script.string):
            break
    else:
        testing.expect.check("<rulerColumn script>",
                             "<expected content not found>")

frontend.page("critic/%s" % COMMIT,
              expect={ "rulerColumn_script": check_rulerColumn })

########NEW FILE########
__FILENAME__ = 002-emptyfile
# This is the commit that adds testing/input/empty.txt.
COMMIT = "47c6cea51af517107c403d96810fce946825aacc"

def check_description(document):
    actual = "<expected content not found>"

    for row in document.findAll("tr"):
        cells = row.findAll("td")
        if len(cells) >= 2 \
                and cells[0].has_key("class") \
                and cells[0]["class"] == "path" \
                and cells[0].a \
                and cells[0].a.string \
                and cells[0].a.string.endswith("/empty.txt") \
                and cells[1].i \
                and cells[1].i.string:
            actual = cells[1].i.string
            break

    testing.expect.check(u"empty", actual)

with frontend.signin():
    frontend.page("showcommit",
                  params={ "repository": "critic",
                           "sha1": COMMIT },
                  expect={ "description": check_description })

########NEW FILE########
__FILENAME__ = 003-binaryfile
# This is the commit that adds testing/input/binary.
COMMIT = "47c6cea51af517107c403d96810fce946825aacc"

def check_description(document):
    actual = "<expected content not found>"

    for row in document.findAll("tr"):
        cells = row.findAll("td")
        if len(cells) >= 2 \
                and cells[0].has_key("class") \
                and cells[0]["class"] == "path" \
                and cells[0].a \
                and cells[0].a.string \
                and cells[0].a.string.endswith("/binary") \
                and cells[1].i \
                and cells[1].i.string:
            actual = cells[1].i.string
            break

    testing.expect.check(u"binary", actual)

with frontend.signin():
    frontend.page("showcommit",
                  params={ "repository": "critic",
                           "sha1": COMMIT },
                  expect={ "description": check_description })

########NEW FILE########
__FILENAME__ = 004-createreview
# Scenario: Alice creates a review of a single commit with review filters that
# make Bob a reviewer and Dave a watcher, and then pushes a second commit to
# that review.
#
# Checks: Mostly that this doesn't fail completely, and that the expected mails
# appear to be sent.

import re

# Random commit on master:
COMMIT_SHA1 = "f771149aba230c4712c9cb9c6af4ccfea2b7967d"
COMMIT_SUMMARY = "Minor /dashboard query optimizations"

# The next commit on master:
FOLLOWUP_SHA1 = "e0892183f38932cec0d33408bdfebb290a13f8f3"

def check_summary_input(document):
    input = document.find("input", attrs={ "id": "summary" })

    if not input:
        testing.expect.check("<review summary input>",
                             "<expected content not found>")

    testing.expect.check(COMMIT_SUMMARY, input["value"])

with frontend.signin("alice"):
    # Loading /createreview first is not really necessary, but might as well try
    # that as well.

    document = frontend.page(
        "createreview",
        expect={ "document_title": testing.expect.document_title(u"Create Review") })

    document = frontend.page(
        "createreview",
        params={ "repository": "critic",
                 "commits": COMMIT_SHA1 },
        expect={ "document_title": testing.expect.document_title(u"Create Review"),
                 "summary_input": check_summary_input })

    scripts = document.findAll("script")

    for script in scripts:
        if script.has_key("src"):
            continue
        match = re.search(
            r"^\s*var review\s*=\s*\{\s*commit_ids:\s*\[\s*(\d+)\s*\]",
            script.string, re.MULTILINE)
        if match:
            commit_id = int(match.group(1))
            break
    else:
        testing.expect.check("<data script>",
                             "<expected content not found>")

    result = frontend.operation(
        "submitreview",
        data={ "repository_id": 1,
               "commit_ids": [commit_id],
               "branch": "r/004-createreview",
               "summary": COMMIT_SUMMARY,
               "applyfilters": True,
               "applyparentfilters": True,
               "reviewfilters": [{ "username": "bob",
                                   "type": "reviewer",
                                   "path": "/" },
                                 { "username": "dave",
                                   "type": "watcher",
                                   "path": "/" }],
               "recipientfilters": { "mode": "opt-out" }},
        expect={ "review_id": 1 })

    def to(name):
        return testing.mailbox.ToRecipient("%s@example.org" % name)

    def check_initial(mail):
        testing.expect.check("New Review: %s" % COMMIT_SUMMARY,
                             mail.header("Subject"))
        line = "Commit: %s" % COMMIT_SHA1
        if line not in to_alice.lines:
            testing.expect.check("<%r line>" % line,
                                 "<expected content not found>")

    to_alice = mailbox.pop(accept=to("alice"))
    check_initial(to_alice)
    testing.expect.check("owner",
                         to_alice.header("OperaCritic-Association"))

    to_bob = mailbox.pop(accept=to("bob"))
    check_initial(to_bob)
    testing.expect.check("reviewer",
                         to_bob.header("OperaCritic-Association"))

    to_dave = mailbox.pop(accept=to("dave"))
    check_initial(to_dave)
    testing.expect.check("watcher",
                         to_dave.header("OperaCritic-Association"))

    mailbox.check_empty()

    with repository.workcopy() as work:
        work.run(["checkout", "-q", "-b", "r/004-createreview", COMMIT_SHA1])
        work.run(["cherry-pick", FOLLOWUP_SHA1])

        followup_sha1 = work.run(["rev-parse", "HEAD"]).strip()

        work.run([
            "push", "-q", "alice@%s:/var/git/critic.git" % instance.hostname,
            "HEAD:refs/heads/r/004-createreview"])

    def check_followup(mail):
        testing.expect.check("Updated Review: %s" % COMMIT_SUMMARY,
                             mail.header("Subject"))
        line = "Commit: %s" % followup_sha1
        if line not in mail.lines:
            testing.expect.check("<%r line>" % line,
                                 "<expected content not found>")

    to_alice = mailbox.pop(accept=to("alice"))
    check_followup(to_alice)

    to_bob = mailbox.pop(accept=to("bob"))
    check_followup(to_bob)

    to_dave = mailbox.pop(accept=to("dave"))
    check_followup(to_dave)

    mailbox.check_empty()

########NEW FILE########
__FILENAME__ = 001-addreviewfilters-bogus
INVALID_USER_ID = 0

with frontend.signin("alice"):
    frontend.operation(
        "addreviewfilters",
        data={ "review_id": 1,
               "filters": [{ "type": "watcher",
                             "user_ids": [INVALID_USER_ID],
                             "paths": ["/"] }] },
        expect={ "status": "failure",
                 "code": "invaliduserid" })

########NEW FILE########
__FILENAME__ = 005-checkbranch
# Random commit on master:
COMMIT_SHA1 = "bc661163b11234e85ec7b0efe1195cce473f234a"

document_title = testing.expect.document_title("Check branch review status")
content_title = testing.expect.paleyellow_title(0, "Check branch review status")

# First load /checkbranch without parameters; this just returns a form.
frontend.page(
    url="checkbranch",
    expect={ "document_title": document_title,
             "content_title": content_title })

# Create some branches.  The commits on them are not really that relevant, but
# they should not be on master.  We generate some such commits simply by
# reverting some commits that are on master.
#
# One branch is pushed to Critic's repository, but also to "origin" where it
# has one additional commit.
#
# Another branch is not pushed to Critic's repository, only to "origin".
with repository.workcopy() as work:
    work.run(["checkout", "-q", "-b", "005-checkbranch", COMMIT_SHA1])

    first_sha1 = work.run(["rev-parse", "HEAD"]).strip()
    second_sha1 = work.run(["rev-parse", "HEAD^"]).strip()
    third_sha1 = work.run(["rev-parse", "HEAD^^"]).strip()

    work.run(["revert", "--no-edit", first_sha1])
    work.run(["push", "-q", "alice@%s:/var/git/critic.git" % instance.hostname,
              "HEAD:refs/heads/005-checkbranch-1"])

    work.run(["revert", "--no-edit", second_sha1])
    work.run(["push", "-q", "origin", "HEAD:refs/heads/005-checkbranch-1"])

    work.run(["revert", "--no-edit", third_sha1])
    work.run(["push", "-q", "origin", "HEAD:refs/heads/005-checkbranch-2"])

document_title = testing.expect.document_title("Branch review status: 005-checkbranch-1")
content_title = testing.expect.paleyellow_title(0, "Unmerged Commits (1)")

# Load /checkbranch with fetch=no checking the first branch.
frontend.page(
    url="checkbranch",
    params={ "repository": "critic",
             "commit": "005-checkbranch-1",
             "upstream": "master" },
    expect={ "document_title": document_title,
             "content_title": content_title })

content_title = testing.expect.paleyellow_title(0, "Unmerged Commits (2)")

# Load /checkbranch with fetch=yes checking the first branch.
frontend.page(
    url="checkbranch",
    params={ "repository": "critic",
             "commit": "005-checkbranch-1",
             "fetch": "yes",
             "upstream": "master" },
    expect={ "document_title": document_title,
             "content_title": content_title })

message_title = testing.expect.message_title(
    "Unable to interpret '005-checkbranch-2' as a commit reference.")

# Load /checkbranch with fetch=no checking the second branch.  This essentially
# fails, since we didn't push this branch to Critic's repository.
frontend.page(
    url="checkbranch",
    params={ "repository": "critic",
             "commit": "005-checkbranch-2",
             "upstream": "master" },
    expect={ "message_title": message_title })

document_title = testing.expect.document_title("Branch review status: 005-checkbranch-2")
content_title = testing.expect.paleyellow_title(0, "Unmerged Commits (3)")

# Load /checkbranch with fetch=yes checking the second branch.
frontend.page(
    url="checkbranch",
    params={ "repository": "critic",
             "commit": "005-checkbranch-2",
             "fetch": "yes",
             "upstream": "master" },
    expect={ "document_title": document_title,
             "content_title": content_title })

content_title = testing.expect.paleyellow_title(0, "Unmerged Commits (1)")

# Load /checkbranch checking the second branch, using the first branch as the
# upstream instead of master.
frontend.page(
    url="checkbranch",
    params={ "repository": "critic",
             "commit": "005-checkbranch-2",
             "upstream": "005-checkbranch-1" },
    expect={ "document_title": document_title,
             "content_title": content_title })

# Load /checkbranchtext checking the first branch.
document = frontend.page(
    url="checkbranchtext",
    expected_content_type="text/plain",
    params={ "repository": "critic",
             "commit": "005-checkbranch-1",
             "upstream": "master" })

testing.expect.check('Revert "Fix typo s/orderIndeces/orderIndices/": REVIEW STATUS UNKNOWN!\n' +
    'Revert "Delete unused commented out code": REVIEW STATUS UNKNOWN!\n', str(document))

########NEW FILE########
__FILENAME__ = 006-showreview-reviewfilter
# Scenario: Alice creates a review of a single commit with a review filter with
# empty path.  Loading the review front-page after that should not crash, but
# did due to a problem introduced by the filter system rewrite.

import re

# Random commit on master:
COMMIT_SHA1 = "f771149aba230c4712c9cb9c6af4ccfea2b7967d"
REVIEW_SUMMARY = "006-showreview-reviewfilter.py"

with frontend.signin("alice"):
    # Loading /createreview is not really necessary, but might as well try that
    # as well.
    document = frontend.page(
        "createreview",
        params={ "repository": "critic",
                 "commits": COMMIT_SHA1 })

    scripts = document.findAll("script")

    for script in scripts:
        if script.has_key("src"):
            continue
        match = re.search(
            r"^\s*var review\s*=\s*\{\s*commit_ids:\s*\[\s*(\d+)\s*\]",
            script.string, re.MULTILINE)
        if match:
            commit_id = int(match.group(1))
            break
    else:
        testing.expect.check("<data script>",
                             "<expected content not found>")

    result = frontend.operation(
        "submitreview",
        data={ "repository": 1,
               "commit_ids": [commit_id],
               "branch": "r/006-showreview-reviewfilter",
               "summary": REVIEW_SUMMARY,
               "applyfilters": True,
               "applyparentfilters": True,
               "reviewfilters": [{ "username": "bob",
                                   "type": "reviewer",
                                   "path": "" },
                                 { "username": "dave",
                                   "type": "watcher",
                                   "path": "" },
                                 { "username": "erin",
                                   "type": "watcher",
                                   "path": "" } ],
               "recipientfilters": { "mode": "opt-out",
                                     "excluded": ["erin"] }})

    def to(name):
        return testing.mailbox.ToRecipient("%s@example.org" % name)

    mailbox.pop(accept=to("alice"), timeout=30)
    mailbox.pop(accept=to("bob"), timeout=30)
    mailbox.pop(accept=to("dave"), timeout=30)

    mailbox.check_empty()

    review_id = result["review_id"]
    document_title = "r/%d (No progress) - %s - Opera Critic" % (review_id, REVIEW_SUMMARY)

with frontend.signin("admin"):
    frontend.page(
        "r/%d" % review_id,
        expect={ "document_title": testing.expect.document_title(document_title) })

########NEW FILE########
__FILENAME__ = 007-http-backend
import os
import subprocess
import tempfile
import shutil

environ = os.environ.copy()

def git(args, cwd=None):
    argv = ["git"]
    argv.extend(args)

    logger.debug("Running: %s" % " ".join(argv))

    output = subprocess.check_output(
        argv, cwd=cwd, env=environ, stderr=subprocess.STDOUT)

    if output.strip():
        logger.debug("Output:\n%s" % output.rstrip())

work_dir = tempfile.mkdtemp()

try:
    # Set invalid password so that authentication (if required) fails.
    environ["GIT_ASKPASS"] = os.path.abspath("testing/password-invalid")

    # This should not require a password.
    try:
        git(["clone", "--quiet", "--branch", "master",
             "http://alice@%s/critic.git" % instance.hostname],
            cwd=work_dir)
    except subprocess.CalledProcessError as error:
        logger.error("'git clone' failed: %s\n%s"
                     % (str(error), error.output.rstrip()))

    # This should require a password.
    try:
        git(["push", "--quiet", "origin", "HEAD:007-http-backend-1"],
            cwd=os.path.join(work_dir, "critic"))
        logger.error("Unauthenticated push (apparently) accepted!")
    except subprocess.CalledProcessError:
        pass

    # Set valid password so that authentication succeeds.
    environ["GIT_ASKPASS"] = os.path.abspath("testing/password-testing")

    # This should require a password.
    try:
        git(["push", "--quiet", "origin", "HEAD:007-http-backend-2"],
            cwd=os.path.join(work_dir, "critic"))
    except subprocess.CalledProcessError as error:
        logger.error("'git push' failed: %s\n%s"
                     % (str(error), error.output.rstrip()))
finally:
    shutil.rmtree(work_dir)

# Same thing again, only with a repository URL without ".git" suffix.

work_dir = tempfile.mkdtemp()

try:
    # Set invalid password so that authentication (if required) fails.
    environ["GIT_ASKPASS"] = os.path.abspath("testing/password-invalid")

    # This should not require a password.
    try:
        git(["clone", "--quiet", "--branch", "master",
             "http://alice@%s/critic" % instance.hostname],
            cwd=work_dir)
    except subprocess.CalledProcessError as error:
        logger.error("'git clone' failed: %s\n%s"
                     % (str(error), error.output.rstrip()))

    # This should require a password.
    try:
        git(["push", "--quiet", "origin", "HEAD:007-http-backend-3"],
            cwd=os.path.join(work_dir, "critic"))
        logger.error("Unauthenticated push (apparently) accepted!")
    except subprocess.CalledProcessError:
        pass

    # Set valid password so that authentication succeeds.
    environ["GIT_ASKPASS"] = os.path.abspath("testing/password-testing")

    # This should require a password.
    try:
        git(["push", "--quiet", "origin", "HEAD:007-http-backend-4"],
            cwd=os.path.join(work_dir, "critic"))
    except subprocess.CalledProcessError as error:
        logger.error("'git push' failed: %s\n%s"
                     % (str(error), error.output.rstrip()))
finally:
    shutil.rmtree(work_dir)

########NEW FILE########
__FILENAME__ = 008-initial-commit-diff
import os
import re

def to(name):
    return testing.mailbox.ToRecipient("%s@example.org" % name)

def about(subject):
    return testing.mailbox.WithSubject(subject)

FILENAME = "008-root-commit-pending.txt"
SUMMARY = "Added %s" % FILENAME

review_id = None
commits = {}
first_commit = None
second_commit = None
third_commit = None

with frontend.signin("alice"):
    frontend.operation(
        "savesettings",
        data={ "settings": [{ "item": "review.createViaPush",
                              "value": True }] })

    with repository.workcopy(empty=True) as work:
        work.run(["remote", "add", "critic",
                  "alice@%s:/var/git/critic.git" % instance.hostname])

        def commit(fixup_message=None):
            if fixup_message:
                full_message = "fixup! %s\n\n%s" % (SUMMARY, fixup_message)
                message = fixup_message
            else:
                full_message = message = SUMMARY
            work.run(["add", FILENAME])
            work.run(["commit", "-m", full_message],
                     GIT_AUTHOR_NAME="Alice von Testing",
                     GIT_AUTHOR_EMAIL="alice@example.org",
                     GIT_COMMITTER_NAME="Alice von Testing",
                     GIT_COMMITTER_EMAIL="alice@example.org")
            sha1 = work.run(["rev-parse", "HEAD"]).strip()
            commits[sha1] = message
            return sha1

        def push():
            work.run(["push", "-q", "critic",
                      "HEAD:refs/heads/r/008-root-commit-pending"])

        with open(os.path.join(work.path, FILENAME), "w") as text_file:
            print >>text_file, "First line."

        first_commit = commit()

        push()

        to_alice = mailbox.pop(accept=to("alice"), timeout=30)
        testing.expect.check("New Review: %s" % SUMMARY,
                             to_alice.header("Subject"))

        for line in to_alice.lines:
            match = re.search(
                r"\bhttp://[^/]+/r/(\d+)\b", line)
            if match:
                review_id = int(match.group(1))
                break
        else:
            testing.expect.check("<review URL in mail>",
                                 "<expected content not found>")

        with open(os.path.join(work.path, FILENAME), "a") as text_file:
            print >>text_file, "Second line."

        second_commit = commit("Added second line")

        with open(os.path.join(work.path, FILENAME), "a") as text_file:
            print >>text_file, "Third line."

        third_commit = commit("Added third line")

        push()

        to_alice = mailbox.pop(accept=to("alice"), timeout=30)
        testing.expect.check("Updated Review: %s" % SUMMARY,
                             to_alice.header("Subject"))

    frontend.operation(
        "addreviewfilters",
        data={ "review_id": review_id,
               "filters": [{ "type": "reviewer",
                             "user_names": ["bob"],
                             "paths": ["/"] }] })

    mailbox.pop(
        accept=(to("bob"), about(r"New\(ish\) Review: %s" % SUMMARY)),
        timeout=30)
    mailbox.pop(
        accept=(to("bob"), about("Updated Review: %s" % SUMMARY)),
        timeout=30)

def check_squashed_history(sha1s):
    def check(document):
        table = document.find("table", attrs=testing.expect.with_class("log"))

        if not table:
            testing.expect.check("<table class='log'>",
                                 "<expected content not found>")

        links = table.findAll("a", attrs=testing.expect.with_class("commit"))

        for link in links:
            testing.expect.check(
                "critic/%s?review=%d" % (sha1s[-1], review_id), link["href"])
            del sha1s[-1]

        if sha1s:
            logger.error(
                "Commits missing from 'Squashed history':\n  %s"
                % ("\n  ".join(commits[sha1] for sha1 in sha1s)))

    return check

frontend.page("r/%d" % review_id)
frontend.page("showcommit?sha1=%s&review=%d" % (first_commit, review_id))

frontend.page(
    ("showcommit?first=%s&last=%s&review=%d"
     % (first_commit, second_commit, review_id)),
    expect={ "squashed_history": check_squashed_history([first_commit,
                                                         second_commit]) })

frontend.page(
    ("showcommit?first=%s&last=%s&review=%d"
     % (second_commit, third_commit, review_id)),
    expect={ "squashed_history": check_squashed_history([second_commit,
                                                         third_commit]) })

frontend.page(
    ("showcommit?first=%s&last=%s&review=%d"
     % (first_commit, third_commit, review_id)),
    expect={ "squashed_history": check_squashed_history([first_commit,
                                                         second_commit,
                                                         third_commit]) })

def check_path(document):
    table = document.find("table", attrs=testing.expect.with_class("filter"))

    if not table:
        testing.expect.check("<table class='filter'>",
                             "<expected content not found>")

    for cell in table.findAll("td", attrs=testing.expect.with_class("path")):
        if cell.string and cell.string == FILENAME:
            break
    else:
        testing.expect.check("<td class='path'>%s</td>" % FILENAME,
                             "<expected content not found>")

frontend.page(
    "filterchanges?review=%d" % review_id,
    expect={ "path": check_path })

frontend.page(
    ("filterchanges?first=%s&last=%s&review=%d"
     % (first_commit, second_commit, review_id)),
    expect={ "path": check_path })

frontend.page(
    ("filterchanges?first=%s&last=%s&review=%d"
     % (second_commit, third_commit, review_id)),
    expect={ "path": check_path })

frontend.page(
    ("filterchanges?first=%s&last=%s&review=%d"
     % (first_commit, third_commit, review_id)),
    expect={ "path": check_path })

with frontend.signin("bob"):
    frontend.page(
        "showcommit?review=%d&filter=pending" % review_id,
        expect={ "squashed_history": check_squashed_history([first_commit,
                                                             second_commit,
                                                             third_commit]) })

    frontend.page(
        "showcommit?review=%d&filter=reviewable" % review_id,
        expect={ "squashed_history": check_squashed_history([first_commit,
                                                             second_commit,
                                                             third_commit]) })

    frontend.page(
        "showcommit?review=%d&filter=relevant" % review_id,
        expect={ "squashed_history": check_squashed_history([first_commit,
                                                             second_commit,
                                                             third_commit]) })

########NEW FILE########
__FILENAME__ = 009-fetchremotebranch
import os

TESTNAME = "009-fetchremotebranch"
FILENAME = "%s.txt" % TESTNAME

with repository.workcopy() as work:
    upstream_sha1 = work.run(["rev-parse", "HEAD"]).strip()

    work.run(["branch", "%s/upstream" % TESTNAME])
    work.run(["checkout", "-b", "%s/branch" % TESTNAME])

    with open(os.path.join(work.path, FILENAME), "w") as text_file:
        print >>text_file, "This is a text file."

    work.run(["add", FILENAME])
    work.run(["commit", "-m", "Add %s" % FILENAME],
             GIT_AUTHOR_NAME="Alice von Testing",
             GIT_AUTHOR_EMAIL="alice@example.org",
             GIT_COMMITTER_NAME="Alice von Testing",
             GIT_COMMITTER_EMAIL="alice@example.org")

    head_sha1 = work.run(["rev-parse", "HEAD"]).strip()

    work.run(["push", "origin", "%s/upstream" % TESTNAME])
    work.run(["push", "origin", "%s/branch" % TESTNAME])

with frontend.signin("alice"):
    result = frontend.operation(
        "fetchremotebranch",
        data={ "repository_name": "critic",
               "remote": repository.url,
               "branch": "refs/heads/%s/branch" % TESTNAME,
               "upstream": "refs/heads/%s/upstream" % TESTNAME },
        expect={ "head_sha1": head_sha1,
                 "upstream_sha1": upstream_sha1 })

    commit_ids = result["commit_ids"]

    def check_commit_ids(value):
        if set(value) != set(commit_ids):
            return repr(sorted(value)), repr(sorted(commit_ids))

    frontend.operation(
        "fetchremotebranch",
        data={ "repository_name": "critic",
               "remote": repository.url,
               "branch": "%s/branch" % TESTNAME,
               "upstream": "refs/heads/%s/upstream" % TESTNAME },
        expect={ "head_sha1": head_sha1,
                 "upstream_sha1": upstream_sha1,
                 "commit_ids": check_commit_ids })

########NEW FILE########
__FILENAME__ = 010-linkification
import os

TESTNAME = "010-linkification"
FILENAME = "%s.txt" % TESTNAME

LONG_SHA1_1 = "ca89553db7a2ba22fef70535a65beedf33c97216"
SHORT_SHA1_1 = LONG_SHA1_1[:8]

LONG_SHA1_2 = "132dbfb7c2ac0f4333fb483a70f1e8cce0333d11"
SHORT_SHA1_2 = LONG_SHA1_2[:8]

MESSAGE = """\
Add %(FILENAME)s

The rest of this commit message contains various things that should be
turned into links by the automatic linkification.

A plain HTTP URL: http://critic-review.org/tutorials.

A "wrapped" URL: <URL:mailto:jl@critic-review.org>.

A full SHA-1: %(LONG_SHA1_1)s.

A shortened SHA-1: %(SHORT_SHA1_1)s.

A diff (full SHA-1s): %(LONG_SHA1_2)s..%(LONG_SHA1_1)s.

A diff (shortened SHA-1s): %(SHORT_SHA1_2)s..%(SHORT_SHA1_1)s, should work too.

A review link: r/123 (it doesn't matter if the review exists or not.)

No review link: harrharr/1337

No SHA-1: g%(SHORT_SHA1_1)s

Also no SHA-1: %(SHORT_SHA1_1)sg
""" % { "FILENAME": FILENAME,
        "LONG_SHA1_1": LONG_SHA1_1,
        "SHORT_SHA1_1": SHORT_SHA1_1,
        "LONG_SHA1_2": LONG_SHA1_2,
        "SHORT_SHA1_2": SHORT_SHA1_2 }

with repository.workcopy() as work:
    work.run(["checkout", "-b", TESTNAME])

    with open(os.path.join(work.path, FILENAME), "w") as text_file:
        print >>text_file, "This line is not significant."

    work.run(["add", FILENAME])
    work.run(["commit", "-m", MESSAGE])
    work.run(["push", "alice@%s:/var/git/critic.git" % instance.hostname, "HEAD"])

LINKS = { "A plain HTTP URL": ("http://critic-review.org/tutorials",
                               "http://critic-review.org/tutorials" ),
          'A "wrapped" URL': ("mailto:jl@critic-review.org",
                              "&lt;URL:mailto:jl@critic-review.org&gt;"),
          "A full SHA-1": ("/critic/%s" % LONG_SHA1_1, LONG_SHA1_1),
          "A shortened SHA-1": ("/critic/%s" % LONG_SHA1_1, SHORT_SHA1_1),
          "A diff (full SHA-1s)": ("/critic/%s..%s" % (LONG_SHA1_2, LONG_SHA1_1),
                                   "%s..%s" % (LONG_SHA1_2, LONG_SHA1_1)),
          "A diff (shortened SHA-1s)": ("/critic/%s..%s" % (LONG_SHA1_2, LONG_SHA1_1),
                                        "%s..%s" % (SHORT_SHA1_2, SHORT_SHA1_1)),
          "A review link": ("/r/123", "r/123") }

def check_link(label, expected_href, expected_string):
    def check(document):
        line_attrs = testing.expect.with_class("line", "commit-msg")
        for line in document.findAll("td", attrs=line_attrs):
            if not isinstance(line.contents[0], basestring):
                continue
            if not line.contents[0].startswith(label + ": "):
                continue
            if len(line.contents) < 2:
                continue
            link = line.contents[1]
            try:
                if link.name != "a":
                    continue
            except AttributeError:
                continue
            break
        else:
            testing.expect.check("line: '%s: <a ...>...</a>'" % label,
                                 "<expected content not found>")

        testing.expect.check(expected_href, link["href"])
        testing.expect.check(expected_string, link.string)

    return check

def check_nonlink(text):
    def check(document):
        line_attrs = testing.expect.with_class("line", "commit-msg")
        for line in document.findAll("td", attrs=line_attrs):
            if line.string == text:
                break
        else:
            testing.expect.check("line: %r" % text,
                                 "<expected content not found>")

    return check

expect = dict((label, check_link(label, href, string))
              for label, (href, string) in LINKS.items())

expect["No review link"] = check_nonlink("No review link: harrharr/1337")
expect["No SHA-1"] = check_nonlink("No SHA-1: g%s" % SHORT_SHA1_1)
expect["Also no SHA-1"] = check_nonlink("Also no SHA-1: %sg" % SHORT_SHA1_1)

frontend.page(
    "critic/%s" % TESTNAME,
    expect=expect)

########NEW FILE########
__FILENAME__ = 011-linkification-custom
import os

TESTNAME = "010-linkification-custom"
FILENAME = "%s.txt" % TESTNAME

MESSAGE = """\
Add %(FILENAME)s

The rest of this commit message contains some "issue links".

At end of line: #1001
Followed by text: #1002 is fixed!
Followed by a period: #1003.
Followed by a comma: #1004, huh?
Within parentheses: (#1005)

That's all, folks!
""" % { "FILENAME": FILENAME }

with repository.workcopy() as work:
    work.run(["checkout", "-b", TESTNAME])

    with open(os.path.join(work.path, FILENAME), "w") as text_file:
        print >>text_file, "This line is not significant."

    work.run(["add", FILENAME])
    work.run(["commit", "-m", MESSAGE])
    work.run(["push", "alice@%s:/var/git/critic.git" % instance.hostname, "HEAD"])

instance.execute(
    ["sudo", "mkdir", "-p", "/etc/critic/main/customization",
     "&&",
     "sudo", "touch", "/etc/critic/main/customization/__init__.py",
     "&&",
     "sudo", "cp", "critic/testing/input/customization/linktypes.py",
     "/etc/critic/main/customization",
     "&&",
     "sudo", "chown", "-R", "critic.critic", "/etc/critic/main/customization"])

instance.restart()

def issue(number):
    return ("https://issuetracker.example.com/showIssue?id=%d" % number,
            "#%d" % number)

LINKS = { "At end of line": issue(1001),
          "Followed by text": issue(1002),
          "Followed by a period": issue(1003),
          "Followed by a comma": issue(1004),
          "Within parentheses": issue(1005) }

def check_link(label, expected_href, expected_string):
    def check(document):
        line_attrs = testing.expect.with_class("line", "commit-msg")
        for line in document.findAll("td", attrs=line_attrs):
            if not isinstance(line.contents[0], basestring):
                continue
            if not line.contents[0].startswith(label + ": "):
                continue
            if len(line.contents) < 2:
                continue
            link = line.contents[1]
            try:
                if link.name != "a":
                    continue
            except AttributeError:
                continue
            break
        else:
            testing.expect.check("line: '%s: <a ...>...</a>'" % label,
                                 "<expected content not found>")

        testing.expect.check(expected_href, link["href"])
        testing.expect.check(expected_string, link.string)

    return check

frontend.page(
    "critic/%s" % TESTNAME,
    expect=dict((label, check_link(label, href, string))
                for label, (href, string) in LINKS.items()))



########NEW FILE########
__FILENAME__ = 012-createreview-recipients
# Scenario: Alice creates an opt-in review and includes "bob" as a recipient.

import re

# Random commit on master:
COMMIT_SHA1 = "f771149aba230c4712c9cb9c6af4ccfea2b7967d"
COMMIT_SUMMARY = "Minor /dashboard query optimizations"

with frontend.signin("alice"):
    # Load /createreview to get commit_id.
    document = frontend.page(
        "createreview",
        params={ "repository": "critic", "commits": COMMIT_SHA1 })

    scripts = document.findAll("script")

    for script in scripts:
        if script.has_key("src"):
            continue
        match = re.search(
            r"^\s*var review\s*=\s*\{\s*commit_ids:\s*\[\s*(\d+)\s*\]",
            script.string, re.MULTILINE)
        if match:
            commit_id = int(match.group(1))
            break
    else:
        testing.expect.check("<data script>",
                             "<expected content not found>")

    result = frontend.operation(
        "submitreview",
        data={ "repository_name": "critic",
               "commit_ids": [commit_id],
               "branch": "r/012-createreview-recipients",
               "summary": COMMIT_SUMMARY,
               "applyfilters": True,
               "applyparentfilters": True,
               "reviewfilters": [{ "username": "bob",
                                   "type": "reviewer",
                                   "path": "/" },
                                 { "username": "dave",
                                   "type": "watcher",
                                   "path": "/" }],
               "recipientfilters": { "mode": "opt-in",
                                     "included": ["bob"] }})

    def to(name):
        return testing.mailbox.ToRecipient("%s@example.org" % name)

    mailbox.pop(accept=to("alice"), timeout=30)
    mailbox.pop(accept=to("bob"), timeout=30)
    mailbox.check_empty()

########NEW FILE########
__FILENAME__ = 012-replayrebase
import os
import re
import shutil

def to(name):
    return testing.mailbox.ToRecipient("%s@example.org" % name)

def about(subject):
    return testing.mailbox.WithSubject(subject)

# The commit we'll be "reviewing."
COMMIT_SHA1 = "aca57d0899e5193232dbbea726d94a838a4274ed"
# The original parent of that commit.
PARENT_SHA1 = "ca89553db7a2ba22fef70535a65beedf33c97216"
# An ancestor of the original parent, onto which we'll be rebasing the reviewed
# commit.
TARGET_SHA1 = "132dbfb7c2ac0f4333fb483a70f1e8cce0333d11"

# The subject of the reviewed commit.
SUMMARY = "Use temporary clones for relaying instead of temporary remotes"

with frontend.signin("alice"):
    frontend.operation(
        "savesettings",
        data={ "settings": [{ "item": "review.createViaPush",
                              "value": True },
                            { "item": "email.subjectLine.updatedReview.reviewRebased",
                              "value": "Rebased Review: %(summary)s" }] })

    with repository.workcopy() as work:
        work.run(["remote", "add", "critic",
                  "alice@%s:/var/git/critic.git" % instance.hostname])
        work.run(["checkout", "-b", "r/012-checkrebase", PARENT_SHA1])
        work.run(["cherry-pick", COMMIT_SHA1],
                 GIT_COMMITTER_NAME="Alice von Testing",
                 GIT_COMMITTER_EMAIL="alice@example.org")

        output = work.run(["push", "critic", "HEAD"])
        next_is_review_url = False

        for line in output.splitlines():
            if not line.startswith("remote:"):
                continue
            line = line[len("remote:"):].split("\x1b", 1)[0].strip()
            if line == "Submitted review:":
                next_is_review_url = True
            elif next_is_review_url:
                review_id = int(re.search(r"/r/(\d+)$", line).group(1))
                break
        else:
            testing.expect.check("<review URL in git hook output>",
                                 "<expected content not found>")

        mailbox.pop(accept=[to("alice"),
                            about("New Review: %s" % SUMMARY)],
                    timeout=30)

        frontend.operation(
            "preparerebase",
            data={ "review_id": review_id,
                   "new_upstream": TARGET_SHA1 })

        work.run(["rebase", "--onto", TARGET_SHA1, PARENT_SHA1])

        # Create some new files as part of the rebase.  This serves two
        # purposes:
        #
        # 1) Generate some "changes introduced by rebase" for the rebase replay
        #    mechanism to deal with, and
        #
        # 2) make sure the push creates a new pack file (a certain amount of new
        #    objects are required to cause this) so that "git receive-pack"
        #    creates a pack-*.keep file, which creates trouble for "git clone".
        source_path = os.path.join(work.path, "testing")
        for index in range(10):
            destination_path = os.path.join(work.path, "testing%d" % index)
            shutil.copytree(source_path, destination_path)
            for path, _, filenames in os.walk(destination_path):
                for filename in filenames:
                    with open(os.path.join(path, filename), "a") as copied:
                        copied.write("%d\n" % index)
            work.run(["add", "testing%d" % index])
        work.run(["commit", "--amend", "--reuse-message=HEAD"])

        work.run(["push", "--force", "critic", "HEAD"])

        mailbox.pop(accept=[to("alice"),
                            about("Updated Review: %s" % SUMMARY)],
                    timeout=30)

        mailbox.pop(accept=[to("alice"),
                            about("Rebased Review: %s" % SUMMARY)],
                    timeout=30)

########NEW FILE########
__FILENAME__ = 014-non-ascii-filenames
# coding=utf-8

# Scenario: Alice creates a review for a commit where a file that contains
#           non-ascii chars has been added. Critic should not crash.

import os

TC_NAME_PREFIX = "014-non-ascii-filename"
TC_NAME_UTF8 = (u"%s-√•√§√∂\x01\ufffd" % TC_NAME_PREFIX).encode("utf-8")
TC_NAME_ESCAPED = u"%s-√•√§√∂\\x01\\ufffd" % TC_NAME_PREFIX

def check_filename(class_name):
    def check(document):
        cells = document.findAll("td", attrs=testing.expect.with_class(class_name))

        for cell in cells:
            anchor = cell.find("a")
            if not anchor:
                continue
            if anchor.string.startswith(TC_NAME_PREFIX):
                testing.expect.check(TC_NAME_ESCAPED, anchor.string)
                break
        else:
            testing.expect.check("<td class=%s><a>%s" % (class_name, TC_NAME_ESCAPED),
                                 "<expected content not found>")

    return check

with frontend.signin("alice"):
    with repository.workcopy(empty=True) as work:
        work.run(["remote", "add", "critic",
                  "alice@%s:/var/git/critic.git" % instance.hostname])

        def commit():
            work.run(["add", TC_NAME_UTF8])
            work.run(["commit", "-m", TC_NAME_UTF8],
                     GIT_AUTHOR_NAME="Alice von Testing",
                     GIT_AUTHOR_EMAIL="alice@example.org",
                     GIT_COMMITTER_NAME="Alice von Testing",
                     GIT_COMMITTER_EMAIL="alice@example.org")
            return work.run(["rev-parse", "HEAD"]).strip()

        def push():
            work.run(["push", "-q", "critic",
                      "HEAD:refs/heads/" + TC_NAME_PREFIX])

        with open(os.path.join(work.path, TC_NAME_UTF8), "w") as text_file:
            print >>text_file, "Content of file " + TC_NAME_UTF8

        sha1 = commit()
        push()

    frontend.page(
        "showcommit",
        params={ "repository": "critic",
                 "sha1": sha1 },
        expect={ "filename": check_filename("path") })

    frontend.page(
        "showtree",
        params={ "repository": "critic",
                 "sha1": sha1,
                 "path": "/" },
        expect={ "filename": check_filename("name") })

########NEW FILE########
__FILENAME__ = 015-non-ascii-line-diff
import os
import json

import BeautifulSoup

TESTNAME = "015-non-ascii-line-diff"

with repository.workcopy() as work:
    work.run(["remote", "add", "critic",
              "alice@%s:/var/git/critic.git" % instance.hostname])

    def commit(encoding, content, index):
        filename = "%s.%s.txt" % (TESTNAME, encoding)

        with open(os.path.join(work.path, filename), "w") as text_file:
            text_file.write(content.encode(encoding))

        work.run(["add", filename])
        work.run(["commit", "-m", "%s (%s #%d)" % (TESTNAME, encoding, index)],
                 GIT_AUTHOR_NAME="Alice von Testing",
                 GIT_AUTHOR_EMAIL="alice@example.org",
                 GIT_COMMITTER_NAME="Alice von Testing",
                 GIT_COMMITTER_EMAIL="alice@example.org")

        return work.run(["rev-parse", "HEAD"]).strip()

    work.run(["checkout", "-b", TESTNAME])

    utf8_from_sha1 = commit("utf-8", u"Non-ascii: \xf6\n", 1)
    utf8_to_sha1 = commit("utf-8", u"Non-ascii: \xf7\n", 2)

    latin1_from_sha1 = commit("latin-1", u"Non-ascii: \xf6\n", 1)
    latin1_to_sha1 = commit("latin-1", u"Non-ascii: \xf7\n", 2)

    work.run(["push", "critic", "HEAD"])

def check_line_diff(document):
    tbody_lines = document.findAll("tbody", attrs={ "class": "lines" })

    testing.expect.check(1, len(tbody_lines))
    testing.expect.check(1, len(tbody_lines[0].contents))

    comment = tbody_lines[0].contents[0]

    testing.expect.check(BeautifulSoup.Comment, comment.__class__)

    try:
        data = json.loads(comment)
    except ValueError:
        testing.expect.check("<valid JSON>", repr(str(comment)))

    testing.expect.check(5, len(data))

    file_id, sides, old_offset, new_offset, lines = data

    testing.expect.check(2, sides)
    testing.expect.check(1, old_offset)
    testing.expect.check(1, new_offset)
    testing.expect.check(1, len(lines))
    testing.expect.check(3, len(lines[0]))

    line_type, old_line, new_line = lines[0]

    # See diff/__init__.py, class Line
    MODIFIED = 3

    testing.expect.check(MODIFIED, line_type)
    testing.expect.check(u"Non-ascii: <ir>\xf6</i>", old_line)
    testing.expect.check(u"Non-ascii: <ir>\xf7</i>", new_line)

frontend.page(
    "showcommit",
    params={ "repository": "critic",
             "from": utf8_from_sha1,
             "to": utf8_to_sha1 },
    expect={ "line_diff": check_line_diff })

frontend.page(
    "showcommit",
    params={ "repository": "critic",
             "from": latin1_from_sha1,
             "to": latin1_to_sha1 },
    expect={ "line_diff": check_line_diff })

########NEW FILE########
__FILENAME__ = 016-showcommit-ranges
# Scenario: Alice opens the BRANCHES page, switches to the master branch in the
# Critic-inside-Critic repository and selects a range of two adjacent non-merge
# commits and verifies that there is no error. She then selects a range that
# starts with a merge commit and makes sure that the appropriate error message
# is shown.

with frontend.signin("alice"):
    # Two adjacent non-merge commits.
    document = frontend.page(
        "showcommit",
        params={ "first": "016f2149c334ff7dabac98700e74a7e9500e702e",
                 "last": "007b4b53a2a8e9561f5143eff27300ea693ca621" },
        expect={ "document_title": testing.expect.document_title(u"fa686f55..007b4b53"),
                 "content_title": testing.expect.paleyellow_title(0, u"Squashed History") })

    # 57a886e is a merge commit.
    document = frontend.page(
        "showcommit",
        params={ "first": "57a886e6352b229991c81e7ba43244ace7e02d76",
                 "last": "b2b78ca013b49c73231bee11674bcdb3edf6d3f2" },
        expect={ "message": testing.expect.message_title(u"Invalid parameters; 'first' can not be a merge commit.") })

    mailbox.check_empty()

########NEW FILE########
__FILENAME__ = 017-showcommit-merge-replay
# Scenario: Alice opens the BRANCHES page, switches to the master branch in the
# Critic-inside-Critic repository and clicks on the merge commit 8ebec44a.
# Finally, even though the merge is empty she clicks the link "display conflict
# resolution changes" near the top of the page. After that she also views
# 030afecd which had some actual conflicts.

document_title = testing.expect.document_title(u"Merge pull request #30 from rchl/exception-fixes (8ebec44a)")
with frontend.signin("alice"):
    document = frontend.page(
        "showcommit",
        params={ "sha1": "8ebec44af03197c9679f08afc2b19606c839db99",
                 "conflicts": "yes" },
        expect={ "document_title": document_title })

document_title = testing.expect.document_title(u"Merge remote-tracking branch 'github/master' into r/molsson/showcommit_sends_no_data (030afecd)")
frontend.page(
    url="showcommit",
    params={ "sha1": "030afecdfb40235af03faa52a2a193c7d8199b66",
             "conflicts": "yes" },
    expect={ "document_title": document_title })

mailbox.check_empty()

########NEW FILE########
__FILENAME__ = 018-detect-moves-no-moved-code
# Scenario: Bob is viewing a commit that doesn't contain any chunks that Critic
# detects as "moved code". Bob is not sure though, so he hits 'm', selects the
# appropriate filenames and clicks SEARCH. Critic should not crash.

COMMIT_WITH_NO_MOVES = 'cc1c1a25'

with frontend.signin("bob"):
    document = frontend.page(
        "critic/%s" % COMMIT_WITH_NO_MOVES,
        params={ "moves": "yes" },
        expect={ "message": testing.expect.message_title(u"No moved code found!") })

    mailbox.check_empty()

########NEW FILE########
__FILENAME__ = 019-showtree-showfile-bogus
# Scenario: /showtree or /showfile loaded, with or without a repository
# specifier, with a SHA-1 that is or is not present in that/any repository, or a
# path that is or is not valid.

VALID_SHA1 = "378a00935735431d5408dc8acbca77e6887f91c6"
INVALID_SHA1 = "aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa"

VALID_TREE_PATH = "src/page"
INVALID_TREE_PATH = "src/horse"

VALID_FILE_PATH = "src/page/showtree.py"
INVALID_FILE_PATH = "src/page/showpuppy.py"

missing_sha1 = testing.expect.message(
    expected_title="SHA-1 not found",
    expected_body="Couldn't find commit %s in any repository." % INVALID_SHA1)

missing_tree = testing.expect.message(
    expected_title="Directory does not exist",
    expected_body=("There is no directory named /%s in the commit %s."
                   % (INVALID_TREE_PATH, VALID_SHA1[:8])))

missing_file = testing.expect.message(
    expected_title="File does not exist",
    expected_body=("There is no file named /%s in the commit %s."
                   % (INVALID_FILE_PATH, VALID_SHA1[:8])))

invalid_file = testing.expect.message(
    expected_title="Invalid path parameter",
    expected_body="The path must be non-empty and must not end with a /.")

frontend.page(
    "showtree",
    params={ "sha1": VALID_SHA1,
             "path": VALID_TREE_PATH },
    expect={ "message": testing.expect.no_message() })

frontend.page(
    "showtree",
    params={ "sha1": INVALID_SHA1,
             "path": VALID_TREE_PATH },
    expect={ "message": missing_sha1 })

frontend.page(
    "showtree",
    params={ "sha1": VALID_SHA1,
             "path": INVALID_TREE_PATH },
    expect={ "message": missing_tree })

frontend.page(
    "showfile",
    params={ "sha1": VALID_SHA1,
             "path": VALID_FILE_PATH },
    expect={ "message": testing.expect.no_message() })

frontend.page(
    "showfile",
    params={ "sha1": INVALID_SHA1,
             "path": VALID_FILE_PATH },
    expect={ "message": missing_sha1 })

frontend.page(
    "showfile",
    params={ "sha1": VALID_SHA1,
             "path": INVALID_FILE_PATH },
    expect={ "message": missing_file })

frontend.page(
    "showfile",
    params={ "sha1": VALID_SHA1,
             "path": "" },
    expect={ "message": invalid_file })

frontend.page(
    "showfile",
    params={ "sha1": VALID_SHA1,
             "path": VALID_FILE_PATH + "/" },
    expect={ "message": invalid_file })

########NEW FILE########
__FILENAME__ = 020-fixup-review-via-push
import os

def to(name):
    return testing.mailbox.ToRecipient("%s@example.org" % name)

def about(subject):
    return testing.mailbox.WithSubject(subject)

FILENAME = "020-fixup-review-via-push.txt"

with frontend.signin("alice"):
    frontend.operation(
        "savesettings",
        data={ "settings": [{ "item": "review.createViaPush",
                              "value": True }] })

    with repository.workcopy() as work:
        work.run(["remote", "add", "critic",
                  "alice@%s:/var/git/critic.git" % instance.hostname])

        with open(os.path.join(work.path, FILENAME), "w") as text_file:
            print >>text_file, "Some content."

        work.run(["add", FILENAME])
        work.run(["commit", "-m", """\
fixup! Commit reference

Relevant summary
"""],
                 GIT_AUTHOR_NAME="Alice von Testing",
                 GIT_AUTHOR_EMAIL="alice@example.org",
                 GIT_COMMITTER_NAME="Alice von Testing",
                 GIT_COMMITTER_EMAIL="alice@example.org")
        work.run(["push", "-q", "critic",
                  "HEAD:refs/heads/r/020-fixup-review-via-push"])

        mailbox.pop(
            accept=[to("alice"), about("New Review: Relevant summary")],
            timeout=30)

########NEW FILE########
__FILENAME__ = 020-reviewrebase
import os

FILENAME = "020-reviewrebase.txt"
FILENAME_BASE = "020-reviewrebase.base.txt"

NONSENSE = """\
Lorem ipsum dolor sit amet, consectetur adipiscing
elit. Donec ut enim sit amet purus ultricies
lobortis. Pellentesque nisi arcu, convallis sed purus sed,
semper ultrices velit. Ut egestas lorem tortor, vitae
lacinia lorem consectetur nec. Integer tempor ornare ipsum
at viverra. Curabitur nec orci mollis, lacinia sapien eget,
ultricies ipsum. Curabitur a libero tortor. Curabitur
volutpat lacinia erat, ac suscipit enim dignissim nec."""

def lines(*args):
    return "\n".join((line.upper() if index in args else line)
                     for index, line in enumerate(NONSENSE.splitlines()))

def to(name):
    return testing.mailbox.ToRecipient("%s@example.org" % name)

def about(subject):
    return testing.mailbox.WithSubject(subject)

work = repository.workcopy()
signin = frontend.signin("alice")
reviews = []

with work, signin:
    frontend.operation(
        "savesettings",
        data={ "settings": [{ "item": "review.createViaPush",
                              "value": True },
                            { "item": "email.subjectLine.updatedReview.reviewRebased",
                              "value": "Rebased Review: %(summary)s" }] })

    work.run(["remote", "add", "critic",
              "alice@%s:/var/git/critic.git" % instance.hostname])

    def write(*args, **kwargs):
        """Write the file<tm>, optionally with lines upper-cased."""
        filename = kwargs.get("filename", FILENAME)
        with open(os.path.join(work.path, filename), "w") as target:
            print >>target, lines(*args)

    def commit(message_or_ref="HEAD", generate=None, *args, **kwargs):
        """If called with two or more arguments, create a commit and return,
           otherwise return commit referenced by first argument."""
        if generate is not None:
            generate(*args, **kwargs)
            work.run(["add", kwargs.get("filename", FILENAME)])
            work.run(["commit", "-m", message_or_ref])
            message_or_ref = "HEAD"

        oneline = work.run(["log", "--no-abbrev", "--pretty=oneline", "-1",
                            message_or_ref])
        sha1, summary = oneline.strip().split(" ", 1)

        return { "sha1": sha1, "summary": summary }

    def expectmail(title):
        review = reviews[-1]
        mailbox.pop(accept=[to("alice"),
                            about("%s: %s" % (title, review["summary"]))],
                    timeout=30)

    def expecthead(expected):
        """Check that the review branch in Critic's repository is where we want
           it to be."""
        review = reviews[-1]
        actual = work.run(["ls-remote", "critic", review["branch"]]).split()[0]
        testing.expect.check(expected["sha1"], actual)

    def createreview(commits):
        """Create a review of the specified commits."""
        index = len(reviews) + 1
        branch = "020-reviewrebase/%d" % index
        summary = "020-reviewrebase, test %d" % index
        work.run(["push", "critic", "%s:refs/heads/%s" % (commits[-1]["sha1"],
                                                          branch)])
        result = frontend.operation(
            "submitreview",
            data={ "repository": "critic",
                   "commit_sha1s": [commit["sha1"] for commit in commits],
                   "branch": "r/" + branch,
                   "summary": summary })
        reviews.append({ "id": result["review_id"],
                         "branch": "r/" + branch,
                         "summary": summary })
        expectmail("New Review")

    def push(new_head, force=False):
        """Push specified commit to the review branch in Critic's repository,
           optionally forced."""
        review = reviews[-1]
        args = ["push"]
        if force:
            args.append("-f")
        args.extend(["critic", "%s:refs/heads/%s" % (new_head["sha1"],
                                                     review["branch"])])
        work.run(args)
        expecthead(new_head)

    def moverebase(new_upstream, new_head):
        """Perform a move rebase."""
        review = reviews[-1]
        work.run(["reset", "--hard", new_head["sha1"]])
        frontend.operation(
            "preparerebase",
            data={ "review_id": review["id"],
                   "new_upstream": new_upstream["sha1"] })
        push(new_head, force=True)
        expectmail("Rebased Review")

    def historyrewrite(new_head):
        """Perform a history rewrite rebase."""
        review = reviews[-1]
        work.run(["reset", "--hard", new_head["sha1"]])
        frontend.operation(
            "preparerebase",
            data={ "review_id": review["id"] })
        push(new_head, force=True)
        expectmail("Rebased Review")

    def expectlog(expected):
        """Fetch the review front-page and check that the commit log contains
           the expected lines.

           Also fetch a /showcommit page whose 'Squashed History' log lists
           everything in the review and check that it contains the same lines
           too."""

        expected = [(item if isinstance(item, str) else item["summary"])
                    for item in expected]

        def checklog(document):
            with_class = testing.expect.with_class
            actual = []
            for tr in document.findAll("tr"):
                if not tr.has_key("class"):
                    continue
                classes = tr["class"].split()
                if "commit" in classes:
                    td = tr.find("td", attrs=with_class("summary"))
                    a = td.find("a", attrs=with_class("commit"))
                    actual.append(a.string)
                elif "rebase" in classes:
                    td = tr.find("td")
                    if td.contents[0].startswith("Branch rebased"):
                        a = td.find("a")
                        sha1 = a["href"].split("/")[-1]
                        actual.append("rebased onto " + sha1)
                    elif td.contents[0].startswith("History rewritten"):
                        actual.append("history rewritten")
            testing.expect.check(expected, actual)

        review = reviews[-1]

        frontend.page(
            "r/%d" % review["id"],
            expect={ "log": checklog })
        frontend.page(
            "showcommit",
            params={ "review": review["id"],
                     "filter": "files",
                     "file": FILENAME },
            expect={ "log": checklog })

    def revertrebase():
        """Revert the most recent rebase."""
        review = reviews[-1]
        document = frontend.page("r/%d" % review["id"])
        for a in document.findAll("a"):
            if a.string == "[revert]":
                def revertRebase(rebase_id):
                    return rebase_id
                rebase_id = eval(a["href"].split(":", 1)[1])
                break
        else:
            logger.error("No [revert] link found!")
        frontend.operation(
            "revertrebase",
            data={ "review_id": review["id"],
                   "rebase_id": rebase_id })

    start_sha1 = work.run(["rev-parse", "HEAD"]).strip()

    # TEST #1: Create a review with three commits, then history rewrite so that
    # the branch points to the first commit (i.e. remove the second and third
    # commit.)  Then push another pair of commits, and history rewrite back to
    # the first commit again.

    work.run(["checkout", "-b", "020-reviewrebase-1", start_sha1])
    commits = [commit("Test #1, commit 1", write),
               commit("Test #1, commit 2", write, 4, 5),
               commit("Test #1, commit 3", write)]
    createreview(commits)
    historyrewrite(commits[0])
    expectlog(["history rewritten",
               commits[2],
               commits[1],
               commits[0]])
    commits.extend([commit("Test #1, commit 4", write, 3, 4, 5),
                    commit("Test #1, commit 5", write, 4, 5),
                    commit("Test #1, commit 6", write)])
    push(commits[-1])
    expectmail("Updated Review")
    expectlog([commits[5],
               commits[4],
               commits[3],
               "history rewritten",
               commits[2],
               commits[1],
               commits[0]])
    historyrewrite(commits[0])
    expectlog(["history rewritten",
               commits[5],
               commits[4],
               commits[3],
               "history rewritten",
               commits[2],
               commits[1],
               commits[0]])
    revertrebase()
    expectlog([commits[5],
               commits[4],
               commits[3],
               "history rewritten",
               commits[2],
               commits[1],
               commits[0]])

    # Random extra check for crash fixed in http://critic-review.org/r/207:
    # Use the [partial] filter to look at the two last commits in the review.
    # We're only interested in checking that the page loads successfully.
    frontend.page(
        "showcommit",
        params={ "from": commits[3]["sha1"],
                 "to": commits[5]["sha1"],
                 "review": reviews[-1]["id"],
                 "filter": "files",
                 "file": FILENAME })

    # TEST #2: First, set up two different commits that we'll be basing our
    # review branch on.  Then create a review with three commits, move rebase
    # it (ff), rewrite the history, and move rebase it (non-ff) again.

    work.run(["checkout", "-b", "020-reviewrebase-2-base", start_sha1])
    base_commits = [commit("Test #2 base, commit 1", write),
                    commit("Test #2 base, commit 2", write, 0)]
    work.run(["push", "critic", "020-reviewrebase-2-base"])
    work.run(["checkout", "-b", "020-reviewrebase-2", base_commits[0]["sha1"]])
    commits = [commit("Test #2, commit 1", write, 5),
               commit("Test #2, commit 2", write, 5, 6),
               commit("Test #2, commit 3", write, 5, 6, 7)]
    createreview(commits)
    work.run(["reset", "--hard", base_commits[1]["sha1"]])
    commits.extend([commit("Test #2, commit 4", write, 0, 5),
                    commit("Test #2, commit 5", write, 0, 5, 6),
                    commit("Test #2, commit 6", write, 0, 5, 6, 7)])
    moverebase(base_commits[1], commits[-1])
    expectlog(["rebased onto " + base_commits[1]["sha1"],
               commits[2],
               commits[1],
               commits[0]])
    work.run(["reset", "--hard", base_commits[1]["sha1"]])
    commits.append(commit("Test #2, commit 7", write, 0, 5, 6, 7))
    historyrewrite(commits[-1])
    expectlog(["history rewritten",
               "rebased onto " + base_commits[1]["sha1"],
               commits[2],
               commits[1],
               commits[0]])
    work.run(["reset", "--hard", base_commits[0]["sha1"]])
    commits.append(commit("Test #2, commit 8", write, 5, 6, 7))
    moverebase(base_commits[0], commits[-1])
    expectlog(["rebased onto " + base_commits[0]["sha1"],
               "history rewritten",
               "rebased onto " + base_commits[1]["sha1"],
               commits[2],
               commits[1],
               commits[0]])
    revertrebase()
    expectlog(["history rewritten",
               "rebased onto " + base_commits[1]["sha1"],
               commits[2],
               commits[1],
               commits[0]])
    revertrebase()
    expectlog(["rebased onto " + base_commits[1]["sha1"],
               commits[2],
               commits[1],
               commits[0]])
    revertrebase()
    expectlog([commits[2],
               commits[1],
               commits[0]])

    # TEST #3: Like test #2, but the base commits have changes that trigger
    # "conflicts" and thus equivalent merge commits.

    work.run(["checkout", "-b", "020-reviewrebase-3-base", start_sha1])
    base_commits = [commit("Test #3 base, commit 1", write),
                    commit("Test #3 base, commit 2", write, 2)]
    work.run(["push", "critic", "020-reviewrebase-3-base"])
    work.run(["checkout", "-b", "020-reviewrebase-3", base_commits[0]["sha1"]])
    commits = [commit("Test #3, commit 1", write, 5),
               commit("Test #3, commit 2", write, 5, 6),
               commit("Test #3, commit 3", write, 5, 6, 7)]
    createreview(commits)
    work.run(["reset", "--hard", base_commits[1]["sha1"]])
    commits.extend([commit("Test #3, commit 4", write, 2, 5),
                    commit("Test #3, commit 5", write, 2, 5, 6),
                    commit("Test #3, commit 6", write, 2, 5, 6, 7)])
    moverebase(base_commits[1], commits[-1])
    expectmail("Updated Review")
    expectlog(["rebased onto " + base_commits[1]["sha1"],
               "Merge commit '%s' into %s" % (base_commits[1]["sha1"],
                                              reviews[-1]["branch"]),
               commits[2],
               commits[1],
               commits[0]])
    work.run(["reset", "--hard", base_commits[1]["sha1"]])
    commits.append(commit("Test #3, commit 7", write, 2, 5, 6, 7))
    historyrewrite(commits[-1])
    expectlog(["history rewritten",
               "rebased onto " + base_commits[1]["sha1"],
               "Merge commit '%s' into %s" % (base_commits[1]["sha1"],
                                              reviews[-1]["branch"]),
               commits[2],
               commits[1],
               commits[0]])
    work.run(["reset", "--hard", base_commits[0]["sha1"]])
    commits.append(commit("Test #3, commit 8", write, 5, 6, 7))
    moverebase(base_commits[0], commits[-1])
    expectlog(["rebased onto " + base_commits[0]["sha1"],
               "history rewritten",
               "rebased onto " + base_commits[1]["sha1"],
               "Merge commit '%s' into %s" % (base_commits[1]["sha1"],
                                              reviews[-1]["branch"]),
               commits[2],
               commits[1],
               commits[0]])

    # TEST #4: Create a review with three commits based on master~2, then merge
    # master~1 into the review, and then rebase the review onto master.

    work.run(["fetch", "critic", "refs/heads/master"])
    base_commits = [commit("FETCH_HEAD~2"),
                    commit("FETCH_HEAD~1"),
                    commit("FETCH_HEAD")]
    work.run(["checkout", "-b", "020-reviewrebase-4-1",
              base_commits[0]["sha1"]])
    commits = [commit("Test #4, commit 1", write, 7),
               commit("Test #4, commit 2", write, 6, 7),
               commit("Test #4, commit 3", write, 5, 6, 7)]
    createreview(commits)
    work.run(["checkout", "-b", "020-reviewrebase-4-2",
              base_commits[1]["sha1"]])
    work.run(["merge", "020-reviewrebase-4-1"])
    commits.append(commit())
    push(commits[-1])
    expectmail("Updated Review")
    work.run(["reset", "--hard", base_commits[2]["sha1"]])
    commits.extend([commit("Test #4, commit 4", write, 7),
                    commit("Test #4, commit 5", write, 6, 7),
                    commit("Test #4, commit 6", write, 5, 6, 7)])
    moverebase(base_commits[2], commits[-1])
    expectlog(["rebased onto " + base_commits[2]["sha1"],
               commits[3],
               commits[2],
               commits[1],
               commits[0]])
    revertrebase()
    expectlog([commits[3],
               commits[2],
               commits[1],
               commits[0]])

    # TEST #5: First, set up two different commits that we'll be basing our
    # review branch on.  Then create a review with three commits, then history
    # rewrite so that the branch points to the first commit (i.e. remove the
    # second and third commit.)  Then non-ff move-rebase the review.

    work.run(["checkout", "-b", "020-reviewrebase-5-base", start_sha1])
    base_commits = [commit("Test #5 base, commit 1", write, filename=FILENAME_BASE),
                    commit("Test #5 base, commit 2", write, 0, filename=FILENAME_BASE)]
    work.run(["push", "critic", "020-reviewrebase-5-base"])
    work.run(["checkout", "-b", "020-reviewrebase-5", base_commits[1]["sha1"]])
    commits = [commit("Test #5, commit 1", write, 4),
               commit("Test #5, commit 2", write, 4, 5),
               commit("Test #5, commit 3", write, 4)]
    createreview(commits)
    historyrewrite(commits[0])
    expectlog(["history rewritten",
               commits[2],
               commits[1],
               commits[0]])
    work.run(["reset", "--hard", base_commits[0]["sha1"]])
    commits.append(commit("Test #5, commit 4", write, 4))
    moverebase(base_commits[0], commits[-1])
    expectlog(["rebased onto " + base_commits[0]["sha1"],
               "history rewritten",
               commits[2],
               commits[1],
               commits[0]])
    revertrebase()
    expectlog(["history rewritten",
               commits[2],
               commits[1],
               commits[0]])
    revertrebase()
    expectlog([commits[2],
               commits[1],
               commits[0]])

########NEW FILE########
__FILENAME__ = 021-updatereview-bogus
with frontend.signin("alice"):
    frontend.operation(
        "updatereview",
        data={ "review_id": -1,
               "new_owners": ["alice"] },
        expect={ "status": "failure",
                 "code": "nosuchreview" })

########NEW FILE########
__FILENAME__ = 022-removereviewfilter-bogus
with frontend.signin("alice"):
    frontend.operation(
        "removereviewfilter",
        data={ "filter_id": -1 },
        expect={ "status": "failure",
                 "code": "nosuchfilter" })

########NEW FILE########
__FILENAME__ = 024-customizations.githook
import re
import json

# Install the githook customization.
instance.execute(
    ["sudo", "mkdir", "-p", "/etc/critic/main/customization",
     "&&",
     "sudo", "touch", "/etc/critic/main/customization/__init__.py",
     "&&",
     "sudo", "cp", "critic/testing/input/customization/githook.py",
     "/etc/critic/main/customization",
     "&&",
     "sudo", "chown", "-R", "critic.critic", "/etc/critic/main/customization"])

# Note: no need to restart, since the githook background service effectively
# re-imports the 'index' module, which imports the 'customizations.githook'
# module.

with repository.workcopy() as work:
    def lsremote(ref_name):
        try:
            output = work.run(["ls-remote", "--exit-code", "critic", ref_name])
        except testing.repository.GitCommandError:
            return None

        lines = output.splitlines()

        testing.expect.check(1, len(lines))
        testing.expect.check("[0-9a-f]{40}\t" + ref_name, lines[0],
                             equal=re.match)

        return lines[0][:40]

    def push(new_value, ref_name, expected_result):
        old_value = lsremote(ref_name)

        if new_value is not None:
            new_value = work.run(["rev-parse", new_value]).strip()

        try:
            output = work.run(["push", "--quiet", "critic",
                               "%s:%s" % (new_value or "", ref_name)])
            testing.expect.check("ACCEPT", expected_result)
        except testing.repository.GitCommandError as error:
            output = error.output
            testing.expect.check("REJECT", expected_result)

        from_hook = []
        for line in output.splitlines():
            line = line.partition("\x1b")[0]
            if line.startswith("remote: "):
                from_hook.append(line[len("remote: "):].strip())

        testing.expect.check("^%s:" % expected_result, from_hook[0],
                             equal=re.match)
        testing.expect.check({ "repository_path": "/var/git/critic.git",
                               "ref_name": ref_name,
                               "old_value": old_value,
                               "new_value": new_value },
                             json.loads(from_hook[0][7:]))
        if expected_result == "ACCEPT":
            testing.expect.check(new_value, lsremote(ref_name))
        else:
            testing.expect.check(old_value, lsremote(ref_name))

    work.run(["remote", "add", "critic",
              "alice@%s:/var/git/critic.git" % instance.hostname])

    push("HEAD", "refs/heads/reject-create", "REJECT")
    push("HEAD^", "refs/heads/reject-delete", "ACCEPT")
    push("HEAD", "refs/heads/reject-delete", "ACCEPT")
    push(None, "refs/heads/reject-delete", "REJECT")
    push("HEAD^", "refs/heads/reject-update", "ACCEPT")
    push("HEAD", "refs/heads/reject-update", "REJECT")
    push("HEAD^", "refs/heads/reject-nothing", "ACCEPT")
    push("HEAD", "refs/heads/reject-nothing", "ACCEPT")
    push(None, "refs/heads/reject-nothing", "ACCEPT")

# Remove the githook customization again.
instance.execute(
    ["sudo", "rm", "-f",
     "/etc/critic/main/customization/githook.py",
     "/etc/critic/main/customization/githook.pyc"])

# And again, no need to restart.

########NEW FILE########
__FILENAME__ = 025-trackedbranch
import time

BRANCH_NAME = "025-trackedbranch"

with repository.workcopy() as work, frontend.signin():
    def wait_for_branch(branch_name, value):
        # If it hasn't happened after 10 seconds, something must be wrong.
        deadline = time.time() + 10

        while time.time() < deadline:
            try:
                output = work.run(["ls-remote", "--exit-code", "critic",
                                   "refs/heads/" + branch_name])
                if output.startswith(value):
                    break
            except testing.repository.GitCommandError:
                pass
            time.sleep(0.2)
        else:
            logger.error("Tracked branch %s not updated within 10 seconds."
                         % branch_name)
            raise testing.TestFailure

    def get_branch_log(branch_id, expected_length):
        result = frontend.operation(
            "trackedbranchlog",
            data={ "branch_id": branch_id })

        branch_log = result["items"]

        testing.expect.check(expected_length, len(branch_log))

        return branch_log

    def check_log_item(branch_log_item, from_sha1, to_sha1, hook_output,
                       successful):
        testing.expect.check(from_sha1, branch_log_item["from_sha1"])
        testing.expect.check(to_sha1, branch_log_item["to_sha1"])
        testing.expect.check(hook_output, branch_log_item["hook_output"])
        testing.expect.check(successful, branch_log_item["successful"])

    work.run(["remote", "add", "critic",
              "alice@%s:/var/git/critic.git" % instance.hostname])

    work.run(["push", "origin", "HEAD:refs/heads/" + BRANCH_NAME])

    sha1s = { "HEAD": work.run(["rev-parse", "HEAD"]).strip(),
              "HEAD^": work.run(["rev-parse", "HEAD^"]).strip() }

    result = frontend.operation(
        "addtrackedbranch",
        data={ "repository_id": 1,
               "source_location": repository.url,
               "source_name": BRANCH_NAME,
               "target_name": BRANCH_NAME,
               "users": ["alice"],
               "forced": False })

    branch_id = result["branch_id"]

    wait_for_branch(BRANCH_NAME, sha1s["HEAD"])

    branch_log = get_branch_log(branch_id, expected_length=1)

    check_log_item(branch_log[0],
                   from_sha1="0" * 40,
                   to_sha1=sha1s["HEAD"],
                   hook_output="",
                   successful=True)

    work.run(["push", "origin", "-f", "HEAD^:refs/heads/" + BRANCH_NAME])

    frontend.operation(
        "triggertrackedbranchupdate",
        data={ "branch_id": branch_id })

    to_system = testing.mailbox.ToRecipient("system@example.org")
    system_subject = testing.mailbox.WithSubject(
        "branchtracker.log: update of branch %s from %s in %s failed"
        % (BRANCH_NAME, BRANCH_NAME, repository.url))
    mailbox.pop(accept=[to_system, system_subject], timeout=5)

    to_alice = testing.mailbox.ToRecipient("alice@example.org")
    alice_subject = testing.mailbox.WithSubject(
        "%s: update from %s in %s" % (BRANCH_NAME, BRANCH_NAME, repository.url))
    mailbox.pop(accept=[to_alice, alice_subject], timeout=5)

    branch_log = get_branch_log(branch_id, expected_length=2)

    check_log_item(branch_log[0],
                   from_sha1="0" * 40,
                   to_sha1=sha1s["HEAD"],
                   hook_output="",
                   successful=True)
    check_log_item(branch_log[1],
                   from_sha1=sha1s["HEAD"],
                   to_sha1=sha1s["HEAD^"],
                   hook_output="""\
Rejecting non-fast-forward update of branch.  To perform the update, you
can delete the branch using
  git push critic :%s
first, and then repeat this push.
""" % BRANCH_NAME,
                   successful=False)

    work.run(["push", "origin", "HEAD:refs/heads/%s-forced" % BRANCH_NAME])

    result = frontend.operation(
        "addtrackedbranch",
        data={ "repository_id": 1,
               "source_location": repository.url,
               "source_name": BRANCH_NAME + "-forced",
               "target_name": BRANCH_NAME + "-forced",
               "users": ["alice"],
               "forced": True })

    branch_id = result["branch_id"]

    wait_for_branch(BRANCH_NAME + "-forced", sha1s["HEAD"])

    branch_log = get_branch_log(branch_id, expected_length=1)

    check_log_item(branch_log[0],
                   from_sha1="0" * 40,
                   to_sha1=sha1s["HEAD"],
                   hook_output="",
                   successful=True)

    work.run(["push", "origin", "-f", "HEAD^:refs/heads/%s-forced" % BRANCH_NAME])

    frontend.operation(
        "triggertrackedbranchupdate",
        data={ "branch_id": branch_id })

    wait_for_branch(BRANCH_NAME + "-forced", sha1s["HEAD^"])

    branch_log = get_branch_log(branch_id, expected_length=2)

    check_log_item(branch_log[0],
                   from_sha1="0" * 40,
                   to_sha1=sha1s["HEAD"],
                   hook_output="",
                   successful=True)
    check_log_item(branch_log[1],
                   from_sha1=sha1s["HEAD"],
                   to_sha1=sha1s["HEAD^"],
                   hook_output="""\
Non-fast-forward update detected; deleting and recreating branch.
""",
                   successful=True)

    mailbox.check_empty()

########NEW FILE########
__FILENAME__ = 026-searchreview
import re

REVIEWS = { "giraffe": { "sha1": "5360e5d734e3b990c0dc67496c7a83f94013d01d",
                         "branch": "r/026-searchreview/giraffe",
                         "owners": ["alice"],
                         "summary": "Make sure TH element lives inside a TR element",
                         "paths": ["src/page/repositories.py"] },
            "elephant": { "sha1": "18db724faccfb2f8d04c81309feadf05b48ec9e3",
                          "branch": "r/026-searchreview/elephant",
                          "owners": ["alice", "bob"],
                          "reviewers": ["alice"],
                          "watchers": ["erin"],
                          "summary": "URL escape shortname in repository SELECT",
                          "description": """\
Before this fix, a repository shortname such as "a&b" meant that
the user would be forwarded to /branches?repository=a&b and Critic
would say "No such repository: a". Same problem existed for shortname
"a#b". Also shortname "a+b" hit the error "No such repository: a b".""",
                          "paths": ["src/resources/branches.js",
                                    "src/resources/config.js"] },
            "tiger": { "sha1": "95e52c53a4a183c9f0eada7401e1da174353e00e",
                       "branch": "r/026-searchreview/cat",
                       "owners": ["dave"],
                       "reviewers": ["dave", "erin"],
                       "summary": "Extend testing.tools.upgrade: support custom maintenance and reboot",
                       "paths": ["testing/tools/upgrade.py",
                                 "testing/virtualbox.py"] },
            "ashtray": { "sha1": "94391a18858c05b2619dfea4b58507d08d932bd3",
                         "branch": "r/026-searchreview/ashtray",
                         "owners": ["dave", "alice"],
                         "reviewers": ["dave"],
                         "summary": "Add support for installing packages in instance",
                         "description": """\
Extend the testing.tools.upgrade tool to support installing extra
packages in the instance and retake the snapshot afterwards.""",
                         "paths": ["testing/tools/upgrade.py"],
                         "dropped": True } }

FAILED = False

def to(name):
    return testing.mailbox.ToRecipient("%s@example.org" % name)

def about(subject):
    return testing.mailbox.WithSubject(subject)

with repository.workcopy() as work:
    work.run(["remote", "add", "critic",
              "nobody@%s:/var/git/critic.git" % instance.hostname])

    for review in REVIEWS.values():
        primary_owner = review["owners"][0]

        with frontend.signin(primary_owner):
            frontend.operation(
                "savesettings",
                data={ "settings": [{ "item": "review.createViaPush",
                                      "value": True }] })

            work.run(
                ["remote", "set-url", "critic",
                 ("%s@%s:/var/git/critic.git"
                  % (primary_owner, instance.hostname))])

            output = work.run(
                ["push", "critic", "%(sha1)s:refs/heads/%(branch)s" % review])

            next_is_review_url = False

            for line in output.splitlines():
                if not line.startswith("remote:"):
                    continue
                line = line[len("remote:"):].split("\x1b", 1)[0].strip()
                if line == "Submitted review:":
                    next_is_review_url = True
                elif next_is_review_url:
                    logger.debug(line)
                    review["id"] = int(re.search(r"/r/(\d+)$", line).group(1))
                    break
            else:
                testing.expect.check("<review URL in git hook output>",
                                     "<expected content not found>")

            mailbox.pop(
                accept=[to(primary_owner),
                        about("New Review: %s" % review["summary"])],
                timeout=30)

            updatereview_data = {}

            if len(review["owners"]) > 1:
                updatereview_data["new_owners"] = review["owners"]
            if "description" in review:
                updatereview_data["new_description"] = review["description"]

            if updatereview_data:
                updatereview_data["review_id"] = review["id"]
                frontend.operation(
                    "updatereview",
                    data=updatereview_data)

            recipients = set()

            if "reviewers" in review:
                frontend.operation(
                    "addreviewfilters",
                    data={ "review_id": review["id"],
                           "filters": [{ "type": "reviewer",
                                         "user_names": review["reviewers"],
                                         "paths": ["/"] }] })
                recipients.update(review["reviewers"])

            if "watchers" in review:
                frontend.operation(
                    "addreviewfilters",
                    data={ "review_id": review["id"],
                           "filters": [{ "type": "watcher",
                                         "user_names": review["watchers"],
                                         "paths": ["/"] }] })
                recipients.update(review["watchers"])

            for username in recipients:
                if username not in review["owners"]:
                    mailbox.pop(accept=[to(username),
                                        about(r"^New\(ish\) Review:")],
                                timeout=30)
                if username != primary_owner:
                    mailbox.pop(accept=[to(username),
                                        about(r"^Updated Review:")],
                                timeout=30)

            if "closed" in review:
                frontend.operation(
                    "closereview",
                    data={ "review_id": review["id"] })
            if "dropped" in review:
                frontend.operation(
                    "dropreview",
                    data={ "review_id": review["id"] })

def search(query, expected):
    global FAILED

    if isinstance(query, list):
        for q in query:
            search(q, expected)
        return

    try:
        result = frontend.operation(
            "searchreview",
            data={ "query": query })
    except testing.TestFailure:
        # Continue testing instead of aborting.  The error will have
        # been logged by frontend.operation() already.
        FAILED = True
        return

    actual = dict((review["id"], review["summary"])
                  for review in result["reviews"])

    # Note: We only check that reviews we just created are included (or not) in
    # the search result.  We specifically don't check that the search result
    # doesn't contain other reviews (not created above) since that typically
    # depends on which other tests have run, on which we don't want to depend.

    for key in expected:
        expected_review = REVIEWS[key]

        if expected_review["id"] not in actual:
            logger.error("r/<%s>: not found by query %r as expected"
                         % (key, query))
            FAILED = True
        else:
            if actual[expected_review["id"]] != expected_review["summary"]:
                logger.error("r/<%s>: wrong summary %r reported"
                             % (key, actual[expected_review["id"]]))
                FAILED = True

    for key in REVIEWS.keys():
        if key not in expected:
            if REVIEWS[key]["id"] in actual:
                logger.error("r/<%s>: incorrectly found by query %r"
                             % (key, query))
                FAILED = True

def invalid(query, code, title):
    global FAILED

    try:
        frontend.operation(
            "searchreview",
            data={ "query": query },
            expect={ "status": "failure",
                     "code": code,
                     "title": title })
    except testing.TestFailure:
        # Continue testing instead of aborting.  The error will have
        # been logged by frontend.operation() already.
        FAILED = True
        return

search(query="existentialism",
       expected=[])
search(query="support",
       expected=["tiger", "ashtray"])
search(query="support for",
       expected=["ashtray"])
search(query="'support for'",
       expected=["ashtray"])
search(query='"support for"',
       expected=["ashtray"])
search(query="support owner:dave",
       expected=["tiger", "ashtray"])
search(query="support owner:alice",
       expected=["ashtray"])
search(query="support owner:bob",
       expected=[])

search(query="support installing",
       expected=["ashtray"])
search(query="'support installing'",
       expected=["ashtray"])
search(query="summary:'support installing'",
       expected=[])
search(query="description:'support installing'",
       expected=["ashtray"])

search(query="r/026-searchreview/*",
       expected=["giraffe", "elephant", "tiger", "ashtray"])
search(query=["b:r/026-searchreview/*", "branch:r/026-searchreview/*"],
       expected=["giraffe", "elephant", "tiger", "ashtray"])
search(query="path:r/026-searchreview/*",
       expected=[])
search(query="r/026-searchreview/elephant",
       expected=["elephant"])
search(query="r/026-searchreview/* upgrade.py",
       expected=["tiger", "ashtray"])
search(query="branch:r/026-searchreview/* path:upgrade.py",
       expected=["tiger", "ashtray"])
search(query=["p:upgrade.py", "path:upgrade.py"],
       expected=["tiger", "ashtray"])
search(query="branch:upgrade.py",
       expected=[])

search(query="user:alice",
       expected=["giraffe", "elephant", "ashtray"])
search(query="owner:alice",
       expected=["giraffe", "elephant", "ashtray"])
search(query="reviewer:alice",
       expected=["elephant"])

search(query="user:bob",
       expected=["elephant"])
search(query="owner:bob",
       expected=["elephant"])
search(query="reviewer:bob",
       expected=[])

search(query="user:dave",
       expected=["tiger", "ashtray"])
search(query="owner:dave",
       expected=["tiger", "ashtray"])
search(query="reviewer:dave",
       expected=["tiger", "ashtray"])

search(query=["u:erin", "user:erin"],
       expected=["elephant", "tiger"])
search(query=["o:erin", "owner:erin"],
       expected=[])
search(query=["reviewer:erin"],
       expected=["tiger"])

search(query="owner:alice reviewer:bob user:erin",
       expected=[])
search(query="reviewer:alice owner:bob",
       expected=["elephant"])

search(query=["s:open", "state:open"],
       expected=["giraffe", "elephant", "tiger"])
# It would be nice if we could make one of the reviews accepted, but doing that
# is a lot of work.  In practice, a "pending" search is almost the same as an
# "accepted" search; it's just inverted.  So we're at least quite close to
# testing an "accepted" search.
search(query=["s:pending", "state:pending"],
       expected=["giraffe", "elephant", "tiger"])
search(query=["s:accepted", "state:accepted"],
       expected=[])
# It would be nice if we could close a review too, but again, that depends on
# making a review accepted, and that's a lot of work.
search(query=["s:closed", "state:closed"],
       expected=[])
search(query=["s:dropped", "state:dropped"],
       expected=["ashtray"])

# A bit boring since there's only one repository.
search(query=["r:critic", "repo:critic", "repository:critic"],
       expected=["giraffe", "elephant", "tiger", "ashtray"])

invalid(query="overlord:admin",
        code="invalidkeyword",
        title="Invalid keyword: 'overlord'")
invalid(query="user:nosuchuser",
        code="invalidterm",
        title="No such user: 'nosuchuser'")
invalid(query="owner:nosuchuser",
        code="invalidterm",
        title="No such user: 'nosuchuser'")
invalid(query="reviewer:nosuchuser",
        code="invalidterm",
        title="No such user: 'nosuchuser'")
invalid(query="state:limbo",
        code="invalidterm",
        title="Invalid review state: 'limbo'")

if FAILED:
    raise testing.TestFailure

########NEW FILE########
__FILENAME__ = 027-whitespace-filenames
import os

BRANCH = "027-whitespace-filename"
FILENAME = "filename with spaces.txt"

def check_filename(class_name):
    def check(document):
        cells = document.findAll("td", attrs=testing.expect.with_class(class_name))

        for cell in cells:
            anchor = cell.find("a")
            if not anchor:
                continue
            testing.expect.check(FILENAME, anchor.string)
            break
        else:
            testing.expect.check("<td class=%s><a>%s" % (class_name, FILENAME),
                                 "<expected content not found>")

    return check

with frontend.signin("alice"):
    with repository.workcopy(empty=True) as work:
        REMOTE_URL = "alice@%s:/var/git/critic.git" % instance.hostname

        def commit():
            work.run(["add", FILENAME])
            work.run(["commit", "-m", FILENAME],
                     GIT_AUTHOR_NAME="Alice von Testing",
                     GIT_AUTHOR_EMAIL="alice@example.org",
                     GIT_COMMITTER_NAME="Alice von Testing",
                     GIT_COMMITTER_EMAIL="alice@example.org")
            return work.run(["rev-parse", "HEAD"]).strip()

        def push():
            work.run(["push", "-q", REMOTE_URL,
                      "HEAD:refs/heads/" + BRANCH])

        with open(os.path.join(work.path, FILENAME), "w") as text_file:
            print >>text_file, "Content of file " + FILENAME

        sha1 = commit()
        push()

    frontend.page(
        "showcommit",
        params={ "repository": "critic",
                 "sha1": sha1 },
        expect={ "filename": check_filename("path") })

    frontend.page(
        "showtree",
        params={ "repository": "critic",
                 "sha1": sha1,
                 "path": "/" },
        expect={ "filename": check_filename("name") })

########NEW FILE########
__FILENAME__ = 028-gitemails
# Test summary
# ============
#
# Alice, Bob and Dave adds a bunch of filters making them reviewers of
# a directory we add a bunch of different files to.  Alice adds a filter with
# Erin as delegate.
#
# They all also set their Git emails, Alice and Bob sharing common@example.org
# and dave having two different addresses.
#
# Then we make a bunch of commits with different authors (all involved Git email
# addresses, plus nobody@example.org.)  Each commits adds one file.
#
# We then catch the "New Review" and "Updated Review" emails sent, and make sure
# those emails claim that the right set of files is assigned to be reviewed by
# the expected users.

import os
import re

REMOTE_URL = "alice@%s:/var/git/critic.git" % instance.hostname

to_recipient = testing.mailbox.ToRecipient
with_subject = testing.mailbox.WithSubject

with repository.workcopy() as workcopy:
    def commit(filename, author):
        path = os.path.join(workcopy.path, "028-gitemails", filename)
        with open(path, "w") as the_file:
            the_file.write("This is '%s' by %s.\n" % (filename, author))
        workcopy.run(["add", "028-gitemails/" + filename])
        workcopy.run(["commit", "-m", "Edited " + filename],
                     GIT_AUTHOR_NAME="Anonymous Coward",
                     GIT_AUTHOR_EMAIL=author + "@example.org",
                     GIT_COMMITTER_NAME="Anonymous Coward",
                     GIT_COMMITTER_EMAIL=author + "@example.org")
        return workcopy.run(["rev-parse", "HEAD"]).strip()

    def expect_mail(recipient, expected_files):
        mail = mailbox.pop(
            accept=[to_recipient(recipient + "@example.org"),
                    with_subject("(New|Updated) Review: Edited cat.txt")],
            timeout=5)

        assigned_files = []

        try:
            marker_index = mail.lines.index(
                "These changes were assigned to you:")
        except ValueError:
            pass
        else:
            for line in mail.lines[marker_index + 1:]:
                if not line.strip():
                    break
                filename, counts = line.strip().split(None, 1)
                if assigned_files:
                    filename = filename.replace(".../", "028-gitemails/")
                assigned_files.append((filename, counts))

        for filename, counts in assigned_files:
            if not expected_files:
                testing.expect.check("<no more assigned files>", filename)
            else:
                testing.expect.check(
                    "028-gitemails/" + expected_files.pop(0), filename)
                testing.expect.check("+1", counts)

        if expected_files:
            for filename in expected_files:
                testing.expect.check(filename, "<no more assigned files>")

    with frontend.signin("alice"):
        frontend.operation(
            "savesettings",
            data={ "settings": [{ "item": "review.createViaPush",
                                  "value": True }] })
        frontend.operation(
            "addfilter",
            data={ "filter_type": "reviewer",
                   "repository_name": "critic",
                   "path": "028-gitemails/",
                   "delegates": ["erin"] })
        frontend.operation(
            "setgitemails",
            data={ "subject_id": instance.userid("alice"),
                   "value": ["alice@example.org", "common@example.org"] })

    with frontend.signin("bob"):
        frontend.operation(
            "addfilter",
            data={ "filter_type": "reviewer",
                   "repository_name": "critic",
                   "path": "028-gitemails/",
                   "delegates": [] })
        frontend.operation(
            "setgitemails",
            data={ "subject_name": "bob",
                   "value": ["bob@example.org", "common@example.org"] })

    with frontend.signin("dave"):
        frontend.operation(
            "addfilter",
            data={ "filter_type": "reviewer",
                   "repository_name": "critic",
                   "path": "028-gitemails/",
                   "delegates": [] })
        frontend.operation(
            "setgitemails",
            data={ "subject": instance.userid("dave"),
                   "value": ["dave@example.org", "dave@example.com"] })

    workcopy.run(["checkout", "-b", "r/028-gitemails"])

    os.mkdir(os.path.join(workcopy.path, "028-gitemails"))

    commits = []
    commits.append(commit("cat.txt", "alice"))

    workcopy.run(["push", REMOTE_URL, "HEAD"])

    expect_mail("alice", [])
    expect_mail("bob", ["cat.txt"])
    expect_mail("dave", ["cat.txt"])
    expect_mail("erin", ["cat.txt"])

    commits.append(commit("dog.txt", "bob"))
    commits.append(commit("mouse.txt", "dave"))
    commits.append(commit("snake.txt", "dave"))
    commits.append(commit("bird.txt", "common"))
    commits.append(commit("fish.txt", "nobody"))

    workcopy.run(["push", REMOTE_URL, "HEAD"])

    expect_mail("alice", ["dog.txt", "fish.txt", "mouse.txt", "snake.txt"])
    expect_mail("bob", ["fish.txt", "mouse.txt", "snake.txt"])
    expect_mail("dave", ["bird.txt", "dog.txt", "fish.txt"])
    expect_mail("erin", ["bird.txt"])

########NEW FILE########
__FILENAME__ = 029-log-bogus
expected = testing.expect.message("'notabranch' doesn't name a branch!", None)
frontend.page(
    url="log",
    params={ "repository": "critic",
             "branch": "notabranch" },
    expect={ "message": expected })


expected = testing.expect.message("Missing URI Parameter!",
                                  "Expected 'repository' parameter.")
frontend.page(
    url="log",
    params={ "branch": "branch_that_does_not_exist" },
    expect={ "message": expected })


expected = testing.expect.message("'nyetvetka' doesn't name a branch!", None)
frontend.page(
    url="log",
    params={ "repository": "critic",
             "branch": "master",
             "base": "nyetvetka" },
    expect={ "message": expected })

########NEW FILE########
__FILENAME__ = 001-comments.basic
import os
import re
import pprint

def to(name):
    return testing.mailbox.ToRecipient("%s@example.org" % name)

def about(subject):
    return testing.mailbox.WithSubject(subject)

BASE = "100-reviewing/"
TEST = BASE + "001-comment"
BRANCH = "r/" + TEST
FILENAME = TEST + ".txt"
SUMMARY = "Added " + FILENAME

NEW_SUBJECT = "New Review: " + SUMMARY
NEWISH_SUBJECT = r"New\(ish\) Review: " + SUMMARY
UPDATED_SUBJECT = "Updated Review: " + SUMMARY

LINES = ["First line",
         "Second line",
         "Third line",
         "Fourth line",
         "Fifth line",
         "Sixth line",
         "Seventh line",
         "Eighth line",
         "Ninth line",
         "Tenth line"]

################################################################################
#
# Some utility stuff.
#
################################################################################

class CommentChain(object):
    def __init__(self, chain_id, chain_type, author, text, lines=None):
        self.id = chain_id
        self.type = chain_type
        self.author = author
        self.text = text
        self.lines = lines
        self.replies = []

    def add_reply(self, author):
        self.replies.append((author, ("This is a reply from %s."
                                      % author.capitalize())))

def findChainInMail(mail, chain_id):
    chain_type = author = text = lines = trailer = reply_author = None
    replies = []
    last_comment_seen = False

    first_line_index = None

    for index, line in enumerate(mail + [None]):
        if last_comment_seen:
            if line is None or line:
                del mail[first_line_index:index]
                return chain_type, author, text, lines, replies, trailer

        if not line:
            continue

        match = re.match("(?:> )?General (issue|note)", line)
        if match:
            chain_type = "general " + match.group(1)
            continue

        match = re.match("(?:> )?(Issue|Note) in commit", line)
        if match:
            chain_type = "commit " + match.group(1).lower()
            continue

        match = re.match("(?:> )?(Issue|Note) in", line)
        if match:
            chain_type = "file " + match.group(1).lower()
            continue

        if chain_type is None:
            continue

        match = re.match(r"(?:> )?  http://.*/showcomment\?chain=(\d+)", line)
        if match:
            first_line_index = index - 1
            if int(match.group(1)) != chain_id:
                chain_type = None
            continue

        match = re.match("(?:> )?([^ ]+) von Testing at", line)
        if match:
            if author is None:
                author = match.group(1).lower()
            else:
                reply_author = match.group(1).lower()
            continue

        if re.match(r"(?:> )?-+$", line):
            if lines is None and not chain_type.startswith("general "):
                lines = []
            continue

        if lines is not None and author is None:
            if chain_type.startswith("file "):
                match = re.match(r"(?:> )?\s*(\d+)\|(.*)$", line)
                lines.append((int(match.group(1)), match.group(2)))
            else:
                match = re.match(r"(?:> )?  (.*)$", line)
                lines.append((None, match.group(1)))
            continue

        if line and (line.lower() != line == line.upper() or
                     re.match(r"\(.*\)", line)):
            trailer = line
            last_comment_seen = True
            continue

        match = re.match(r"(> )?  (.+)$", line)
        last_comment_seen = match.group(1) is None
        if reply_author:
            replies.append((reply_author, match.group(2)))
        else:
            text = match.group(2)

    testing.expect.check("<chain %d in mail>" % chain_id,
                         "<expected content not found>")

def checkSubmitter(mails, expected_submitter):
    for mail in mails:
        for line in mail:
            match = re.match("(.*) von Testing has submitted", line)
            if match:
                testing.expect.check(expected_submitter, match.group(1).lower())
                return

        testing.expect.check("<'$USER has submitted' line in mail>",
                             "<expected content not found>")

def checkChain(mails, chain, expected_trailer=None):
    for mail in mails:
        (actual_type, actual_author,
         actual_text, actual_lines,
         actual_replies, actual_trailer) = findChainInMail(mail, chain.id)

        testing.expect.check(chain.type, actual_type)
        testing.expect.check(chain.author, actual_author)
        testing.expect.check(chain.text, actual_text)
        testing.expect.check(chain.lines, actual_lines)
        testing.expect.check(chain.replies, actual_replies)

def checkNoMoreChains(mails):
    for mail in mails:
        for index, line in enumerate(mail):
            if re.match("(?:> )?General (issue|note)", line) \
                    or re.match("(?:> )?(Issue|Note) in commit", line) \
                    or re.match("(?:> )?(Issue|Note) in", line):
                testing.logger.error(
                    "Unexpected comment chain mentioned in mail:\n  %s\n  %s"
                    % (mail[index], mail[index + 1]))

def receiveMails(subject):
    return [mailbox.pop(accept=[to(whom), about(subject)]).lines[:]
            for whom in ["alice", "bob", "dave", "erin"]]

def createComment(chain, author):
    frontend.operation(
        "createcomment",
        data={ "chain_id": chain.id,
               "text": "This is a reply from %s." % author.capitalize() })

def resolveCommentChain(chain):
    frontend.operation(
        "resolvecommentchain",
        data={ "chain_id": chain.id })

def reopenResolvedCommentChain(chain):
    frontend.operation(
        "reopenresolvedcommentchain",
        data={ "chain_id": chain.id })

def morphCommentChain(chain, new_type):
    frontend.operation(
        "morphcommentchain",
        data={ "chain_id": chain.id,
               "new_type": new_type })

def submitChanges():
    frontend.operation(
        "submitchanges",
        data={ "review_id": review_id })

with repository.workcopy() as work:
    ############################################################################
    #
    # As Alice, create a commit that adds a file, and a review of that commit,
    # with Bob, Dave and Erin as associated users.
    #
    ############################################################################

    REMOTE_URL = "alice@%s:/var/git/critic.git" % instance.hostname

    parent_sha1 = work.run(["rev-parse", "HEAD"]).strip()

    work.run(["checkout", "-b", BRANCH, "--no-track", "origin/master"])

    os.mkdir(os.path.join(work.path, "100-reviewing"))

    with open(os.path.join(work.path, FILENAME), "w") as review_file:
        review_file.write("\n".join(LINES) + "\n")

    work.run(["add", FILENAME])
    work.run(["commit", "-m", "\n".join([SUMMARY, ""] + LINES[:3])])

    child_sha1 = work.run(["rev-parse", "HEAD"]).strip()

    review_id = testing.utils.createReviewViaPush(work, "alice")

    mailbox.pop(accept=[to("alice"), about(NEW_SUBJECT)])

    with frontend.signin("alice"):
        frontend.operation(
            "addreviewfilters",
            data={ "review_id": review_id,
                   "filters": [{ "type": "reviewer",
                                 "user_names": ["bob"],
                                 "paths": [BASE] },
                               { "type": "watcher",
                                 "user_names": ["dave"],
                                 "paths": ["/"] },
                               { "type": "watcher",
                                 "user_names": ["erin"],
                                 "paths": ["src/"] }]})

        for whom in ["bob", "dave", "erin"]:
            mailbox.pop(accept=[to(whom), about(NEWISH_SUBJECT)])
            mailbox.pop(accept=[to(whom), about(UPDATED_SUBJECT)])

    ############################################################################
    #
    # Create one each of the different types of comment chain:
    #   { general, commit, file } x { issue, note}
    #
    # Submit, and check that everyone involved received a mail with each comment
    # chain included (and correctly rendered.)
    #
    ############################################################################

    with frontend.signin("alice"):
        result = frontend.operation(
            "createcommentchain",
            data={ "review_id": review_id,
                   "chain_type": "issue",
                   "text": "This is a general issue." })

        general_issue = CommentChain(
            chain_id=result["chain_id"],
            chain_type="general issue",
            author="alice",
            text="This is a general issue.")

        result = frontend.operation(
            "createcommentchain",
            data={ "review_id": review_id,
                   "chain_type": "note",
                   "text": "This is a general note." })

        general_note = CommentChain(
            chain_id=result["chain_id"],
            chain_type="general note",
            author="alice",
            text="This is a general note.")

        result = frontend.operation(
            "createcommentchain",
            data={ "review_id": review_id,
                   "chain_type": "issue",
                   "commit_context": { "commit": child_sha1,
                                       "offset": 0,
                                       "count": 3 },
                   "text": "This is a commit issue." })

        commit_issue = CommentChain(
            chain_id=result["chain_id"],
            chain_type="commit issue",
            author="alice",
            text="This is a commit issue.",
            lines=[(None, SUMMARY),
                   (None, ""),
                   (None, "First line")])

        result = frontend.operation(
            "createcommentchain",
            data={ "review_id": review_id,
                   "chain_type": "note",
                   "commit_context": { "commit": child_sha1,
                                       "offset": 4,
                                       "count": 1 },
                   "text": "This is a commit note." })

        commit_note = CommentChain(
            chain_id=result["chain_id"],
            chain_type="commit note",
            author="alice",
            text="This is a commit note.",
            lines=[(None, "Third line")])

        result = frontend.operation(
            "createcommentchain",
            data={ "review_id": review_id,
                   "chain_type": "issue",
                   "file_context": { "origin": "new",
                                     "parent": parent_sha1,
                                     "child": child_sha1,
                                     "file": FILENAME,
                                     "offset": 2,
                                     "count": 3 },
                   "text": "This is a file issue." })

        file_issue = CommentChain(
            chain_id=result["chain_id"],
            chain_type="file issue",
            author="alice",
            text="This is a file issue.",
            lines=[(2, "Second line"),
                   (3, "Third line"),
                   (4, "Fourth line")])

        result = frontend.operation(
            "createcommentchain",
            data={ "review_id": review_id,
                   "chain_type": "note",
                   "file_context": { "origin": "new",
                                     "parent": parent_sha1,
                                     "child": child_sha1,
                                     "file": FILENAME,
                                     "offset": 10,
                                     "count": 1 },
                   "text": "This is a file note." })

        file_note = CommentChain(
            chain_id=result["chain_id"],
            chain_type="file note",
            author="alice",
            text="This is a file note.",
            lines=[(10, "Tenth line")])

        testing.expect.check(6, result["draft_status"]["writtenComments"])

        submitChanges()

    mails = receiveMails(UPDATED_SUBJECT)

    checkSubmitter(mails, "alice")
    checkChain(mails, general_issue)
    checkChain(mails, general_note)
    checkChain(mails, commit_issue)
    checkChain(mails, commit_note)
    checkChain(mails, file_issue)
    checkChain(mails, file_note)
    checkNoMoreChains(mails)

    ############################################################################
    #
    # Verify that we have some basic correctness checks on comment creation,
    # such as the commented lines existing.
    #
    ############################################################################

    with frontend.signin("alice"):
        # These don't work since the comment text is empty or contains only
        # white-space characters.
        for text in ("", " ", "\t", "\n", "\r"):
            frontend.operation(
                "createcommentchain",
                data={ "review_id": review_id,
                       "chain_type": "note",
                       "commit_context": { "commit": parent_sha1,
                                           "offset": 0,
                                           "count": 1 },
                       "text": text },
                expect={ "status": "failure",
                         "title": "Empty comment!" })

        # These don't work since we're trying to comment lines that don't
        # exist in the commit message.  (We tried offset=4/count=1 above.)
        frontend.operation(
            "createcommentchain",
            data={ "review_id": review_id,
                   "chain_type": "note",
                   "commit_context": { "commit": child_sha1,
                                       "offset": 5,
                                       "count": 1 },
                   "text": "This won't stick." },
            expect={ "status": "failure",
                     "message": "It's not possible to create a comment here." })
        frontend.operation(
            "createcommentchain",
            data={ "review_id": review_id,
                   "chain_type": "note",
                   "commit_context": { "commit": child_sha1,
                                       "offset": 4,
                                       "count": 2 },
                   "text": "This won't stick." },
            expect={ "status": "failure",
                     "message": "It's not possible to create a comment here." })

        # This doesn't work since we're trying to comment the "old" side of the
        # commit that added the commented file.
        frontend.operation(
            "createcommentchain",
            data={ "review_id": review_id,
                   "chain_type": "note",
                   "file_context": { "origin": "old",
                                     "parent": parent_sha1,
                                     "child": child_sha1,
                                     "file": FILENAME,
                                     "offset": 3,
                                     "count": 3 },
                   "text": "This won't stick." },
            expect={ "status": "failure",
                     "message": "It's not possible to create a comment here." })

        # These don't work, since we're trying to comment lines that don't
        # exist in the file.  (We tried offset=10/count=1 above.)
        frontend.operation(
            "createcommentchain",
            data={ "review_id": review_id,
                   "chain_type": "note",
                   "file_context": { "origin": "old",
                                     "parent": parent_sha1,
                                     "child": child_sha1,
                                     "file": FILENAME,
                                     "offset": 11,
                                     "count": 1 },
                   "text": "This won't stick." },
            expect={ "status": "failure",
                     "message": "It's not possible to create a comment here." })
        frontend.operation(
            "createcommentchain",
            data={ "review_id": review_id,
                   "chain_type": "note",
                   "file_context": { "origin": "old",
                                     "parent": parent_sha1,
                                     "child": child_sha1,
                                     "file": FILENAME,
                                     "offset": 10,
                                     "count": 2 },
                   "text": "This won't stick." },
            expect={ "status": "failure",
                     "message": "It's not possible to create a comment here." })

    ############################################################################
    #
    # Reply to some of the comment chains, and morph, resolve and reopen them,
    # as multiple users.
    #
    ############################################################################

    # Bob replies to some issues, but before he submits, Dave also replies to
    # one of them, and submits.  Checks that Dave's reply appears before Bob's,
    # even though Bob created his first.

    with frontend.signin("bob"):
        createComment(general_issue, "bob")
        createComment(commit_issue, "bob")
        createComment(file_issue, "bob")

    with frontend.signin("dave"):
        createComment(general_issue, "dave")
        submitChanges()

        general_issue.add_reply("dave")

    mails = receiveMails(UPDATED_SUBJECT)

    checkSubmitter(mails, "dave")
    checkChain(mails, general_issue)
    checkNoMoreChains(mails)

    with frontend.signin("bob"):
        submitChanges()

        general_issue.add_reply("bob")
        commit_issue.add_reply("bob")
        file_issue.add_reply("bob")

    mails = receiveMails(UPDATED_SUBJECT)

    checkSubmitter(mails, "bob")
    checkChain(mails, general_issue)
    checkChain(mails, commit_issue)
    checkChain(mails, file_issue)
    checkNoMoreChains(mails)

    # Erin replies to an issue too.

    with frontend.signin("erin"):
        createComment(commit_issue, "erin")
        submitChanges()

        commit_issue.add_reply("erin")

    mails = receiveMails(UPDATED_SUBJECT)

    checkSubmitter(mails, "erin")
    checkChain(mails, commit_issue)
    checkNoMoreChains(mails)

    # Alice replies to the general note and converts it to an issue (in the same
    # batch.)

    with frontend.signin("alice"):
        createComment(general_note, "alice")
        morphCommentChain(general_note, "issue")
        submitChanges()

        general_note.add_reply("alice")
        general_note.type = "general issue"

    mails = receiveMails(UPDATED_SUBJECT)

    checkSubmitter(mails, "alice")
    checkChain(mails, general_note, "CONVERTED TO ISSUE!")
    checkNoMoreChains(mails)

    # Alice converts the general note back to a note, without replying.

    with frontend.signin("alice"):
        morphCommentChain(general_note, "note")
        submitChanges()

        general_note.type = "general note"

    mails = receiveMails(UPDATED_SUBJECT)

    checkSubmitter(mails, "alice")
    checkChain(mails, general_note, "CONVERTED TO NOTE!")
    checkNoMoreChains(mails)

    # Bob replies to and converts the general note to an issue, but before he
    # submits, Dave also converts it to an issue and submits.  Checks that Bob's
    # converting of the issue has no effect, but his reply remains.

    with frontend.signin("bob"):
        createComment(general_note, "bob")
        morphCommentChain(general_note, "issue")

    with frontend.signin("dave"):
        morphCommentChain(general_note, "issue")
        submitChanges()

        general_note.type = "general issue"

    mails = receiveMails(UPDATED_SUBJECT)

    checkSubmitter(mails, "dave")
    checkChain(mails, general_note, "CONVERTED TO ISSUE!")
    checkNoMoreChains(mails)

    with frontend.signin("bob"):
        submitChanges()

        general_note.add_reply("bob")

    mails = receiveMails(UPDATED_SUBJECT)

    checkSubmitter(mails, "bob")
    checkChain(mails, general_note)
    checkNoMoreChains(mails)

    # Alice resolves the general issue.

    with frontend.signin("alice"):
        resolveCommentChain(general_issue)
        submitChanges()

    mails = receiveMails(UPDATED_SUBJECT)

    checkSubmitter(mails, "alice")
    checkChain(mails, general_issue, "ISSUE RESOLVED!")
    checkNoMoreChains(mails)

    # Erin replies to the now resolved general issue.

    with frontend.signin("erin"):
        createComment(general_issue, "erin")
        submitChanges()

        general_issue.add_reply("erin")

    mails = receiveMails(UPDATED_SUBJECT)

    checkSubmitter(mails, "erin")
    checkChain(mails, general_issue, "(This issue is resolved.)")
    checkNoMoreChains(mails)

    # Alice replies to and reopens the general issue, but before she submits,
    # Bob also replies to and reopens it, and submits.  Checks that Alice's
    # reopening of the issue has no effect, but her reply remains.

    with frontend.signin("alice"):
        createComment(general_issue, "alice")
        reopenResolvedCommentChain(general_issue)

    with frontend.signin("bob"):
        createComment(general_issue, "bob")
        reopenResolvedCommentChain(general_issue)
        submitChanges()

        general_issue.add_reply("bob")

    mails = receiveMails(UPDATED_SUBJECT)

    checkSubmitter(mails, "bob")
    checkChain(mails, general_issue, "ISSUE REOPENED!")
    checkNoMoreChains(mails)

    with frontend.signin("alice"):
        submitChanges()

        general_issue.add_reply("alice")

    mails = receiveMails(UPDATED_SUBJECT)

    checkSubmitter(mails, "alice")
    checkChain(mails, general_issue)
    checkNoMoreChains(mails)

    # Alice replies to and resolved the commit issue, as does Dave, but before
    # either submit, Bob swoops in and converts the issue to a note, and
    # submits.  Then Alice submits, which checks (again) that her resolving of
    # the issue has no effect, but her reply remains.  Then Bob converts the
    # issue back to an issue, and submits.  Finally, Dave submits, which checks
    # that his (old) resolving of the issue still remains and takes effect.

    with frontend.signin("alice"):
        createComment(commit_issue, "alice")
        resolveCommentChain(commit_issue)

    with frontend.signin("dave"):
        resolveCommentChain(commit_issue)

    with frontend.signin("bob"):
        morphCommentChain(commit_issue, "note")
        submitChanges()

        commit_issue.type = "commit note"

    mails = receiveMails(UPDATED_SUBJECT)

    checkSubmitter(mails, "bob")
    checkChain(mails, commit_issue, "CONVERTED TO NOTE!")
    checkNoMoreChains(mails)

    with frontend.signin("alice"):
        submitChanges()

        commit_issue.add_reply("alice")

    mails = receiveMails(UPDATED_SUBJECT)

    checkSubmitter(mails, "alice")
    checkChain(mails, commit_issue)
    checkNoMoreChains(mails)

    with frontend.signin("bob"):
        morphCommentChain(commit_issue, "issue")
        submitChanges()

        commit_issue.type = "commit issue"

    mails = receiveMails(UPDATED_SUBJECT)

    checkSubmitter(mails, "bob")
    checkChain(mails, commit_issue, "CONVERTED TO ISSUE!")
    checkNoMoreChains(mails)

    with frontend.signin("dave"):
        submitChanges()

    mails = receiveMails(UPDATED_SUBJECT)

    checkSubmitter(mails, "dave")
    checkChain(mails, commit_issue, "ISSUE RESOLVED!")
    checkNoMoreChains(mails)

########NEW FILE########
__FILENAME__ = 001-enable
# Enable extensions.
instance.extend(repository)

########NEW FILE########
__FILENAME__ = 001-tutorial
frontend.page("tutorial",
              expect={ "document_title": testing.expect.document_title(u"Tutorials"),
                       "content_title": testing.expect.paleyellow_title(0, u"Tutorials"),
                       "pageheader_links": testing.expect.pageheader_links("anonymous",
                                                                           "extensions"),
                       "script_user": testing.expect.script_no_user() })

frontend.page("tutorial",
              params={ "item": "extensions" },
              expect={ "document_title": testing.expect.document_title(u"Critic Extensions"),
                       "content_title": testing.expect.paleyellow_title(0, u"Critic Extensions"),
                       "pageheader_links": testing.expect.pageheader_links("anonymous",
                                                                           "extensions"),
                       "script_user": testing.expect.script_no_user() })

frontend.page("tutorial",
              params={ "item": "extensions-api" },
              expect={ "document_title": testing.expect.document_title(u"Critic Extensions API"),
                       "content_title": testing.expect.paleyellow_title(0, u"Critic Extensions API"),
                       "pageheader_links": testing.expect.pageheader_links("anonymous",
                                                                           "extensions"),
                       "script_user": testing.expect.script_no_user() })

########NEW FILE########
__FILENAME__ = 002-manageextensions
frontend.page(
    "manageextensions",
    expect={ "document_title": testing.expect.document_title(u"Manage Extensions"),
             "content_title": testing.expect.paleyellow_title(0, u"Available Extensions"),
             "pageheader_links": testing.expect.pageheader_links("anonymous",
                                                                 "extensions"),
             "script_user": testing.expect.script_anonymous_user() })

frontend.page(
    "manageextensions",
    params={ "what": "available" },
    expect={ "document_title": testing.expect.document_title(u"Manage Extensions"),
             "content_title": testing.expect.paleyellow_title(0, u"Available Extensions"),
             "pageheader_links": testing.expect.pageheader_links("anonymous",
                                                                 "extensions"),
             "script_user": testing.expect.script_anonymous_user() })

frontend.page(
    "manageextensions",
    params={ "what": "installed" },
    expect={ "document_title": testing.expect.document_title(u"Manage Extensions"),
             "content_title": testing.expect.paleyellow_title(0, u"Installed Extensions"),
             "pageheader_links": testing.expect.pageheader_links("anonymous",
                                                                 "extensions"),
             "script_user": testing.expect.script_anonymous_user() })

########NEW FILE########
__FILENAME__ = 003-install-TestExtension
def check_extension(installed):
    def check(document):
        tr_item = document.find("tr", attrs={ "class": "item" })

        td_name = tr_item.find("td", attrs={ "class": "name" })
        testing.expect.check("Extension:", td_name.string)

        td_value = tr_item.find("td", attrs={ "class": "value" })

        span_name = td_value.find("span", attrs={ "class": "name" })
        testing.expect.check("TestExtension", span_name.contents[0].string)
        testing.expect.check(" hosted by Alice von Testing", span_name.contents[1])

        span_installed = td_value.find("span", attrs={ "class": "installed" })
        if installed:
            testing.expect.check(" [installed]", span_installed.string)
        elif span_installed:
            testing.expect.check("<no installed indicator>",
                                 "<found installed indicator>")

    return check

try:
    instance.execute(
        ["sudo", "mkdir", "~alice/CriticExtensions",
         "&&",
         "sudo", "cp", "-R", "~/critic/testing/input/TestExtension",
         "~alice/CriticExtensions",
         "&&",
         "sudo", "chown", "-R", "alice.critic", "~alice/CriticExtensions",
         "&&",
         "sudo", "chmod", "-R", "u+rwX,go+rX", "~alice/CriticExtensions"])

    instance.execute(
        ["sudo", "-H", "-u", "alice", "git", "init",
         "&&",
         "sudo", "-H", "-u", "alice", "git", "add", ".",
         "&&",
         "sudo", "-H", "-u", "alice", "git", "commit", "-mInitial",
         "&&",
         "sudo", "-H", "-u", "alice", "git", "checkout", "-b", "version/stable",
         "&&",
         "sudo", "su", "-c", "'echo stable:1 > version.txt'", "alice",
         "&&",
         "sudo", "-H", "-u", "alice", "git", "add", "version.txt",
         "&&",
         "sudo", "-H", "-u", "alice", "git", "commit", "-mStable:1",
         "&&",
         "sudo", "su", "-c", "'echo stable:2 > version.txt'", "alice",
         "&&",
         "sudo", "-H", "-u", "alice", "git", "commit", "-mStable:2", "version.txt",
         "&&",
         "sudo", "-H", "-u", "alice", "git", "checkout", "master",
         "&&",
         "sudo", "su", "-c", "'echo live > version.txt'", "alice"],
        cwd="~alice/CriticExtensions/TestExtension")
except testing.InstanceError as error:
    raise testing.TestFailure(error.message)

with frontend.signin("alice"):
    frontend.page(
        "manageextensions",
        expect={ "test_extension": check_extension(False) })

    frontend.operation(
        "installextension",
        data={ "author_name": "alice",
               "extension_name": "TestExtension" })

    frontend.page(
        "manageextensions",
        expect={ "test_extension": check_extension(True) })

frontend.page(
    "manageextensions",
    expect={ "test_extension": check_extension(False) })

########NEW FILE########
__FILENAME__ = 001-echo
import json

def check_arguments(expected):
    def check(document):
        try:
            result = json.loads(document)
        except ValueError:
            testing.expect.check("<valid json>", repr(document))
        else:
            actual = result["arguments"]
            testing.expect.check(expected, actual)

    return check

def check_json(expected):
    def check(actual):
        try:
            return expected, json.loads(actual)
        except ValueError:
            return "<valid JSON>", actual
    return check

with frontend.signin("alice"):
    frontend.page(
        "echo",
        expected_content_type="text/json",
        expect={ "json": check_arguments(
            ["GET", "echo", None]) })

    frontend.page(
        "echo?foo=bar",
        expected_content_type="text/json",
        expect={ "json": check_arguments(
            ["GET", "echo", { "raw": "foo=bar",
                              "params": { "foo": "bar" }}]) })

    frontend.page(
        "echo?foo=bar&x=10&y=20",
        expected_content_type="text/json",
        expect={ "json": check_arguments(
            ["GET", "echo", { "raw": "foo=bar&x=10&y=20",
                              "params": { "foo": "bar",
                                          "x": "10",
                                          "y": "20" }}]) })

    frontend.operation(
        "echo",
        data={},
        expect={ "arguments": ["POST", "echo", None],
                 "stdin": check_json({}) })

    frontend.operation(
        "echo",
        data={ "foo": "bar",
               "positions": [{ "x": 10, "y": 20 },
                             { "x": 11, "y": 21 }]},
        expect={ "arguments": ["POST", "echo", None],
                 "stdin": check_json({ "foo": "bar",
                                       "positions": [{ "x": 10, "y": 20 },
                                                     { "x": 11, "y": 21 }]}) })

# Verify that Alice's extension install doesn't affect Bob.
with frontend.signin("bob"):
    frontend.page("echo", expected_http_status=404)

########NEW FILE########
__FILENAME__ = 002-nothandled
with frontend.signin("alice"):
    frontend.page("nothandled", expected_http_status=404)

########NEW FILE########
__FILENAME__ = 003-empty
def empty(document):
    if document != "":
        testing.expect.check("<empty string>", document)

with frontend.signin("alice"):
    frontend.page(
        "empty",
        expected_content_type="text/plain",
        expect={ "empty": empty })

########NEW FILE########
__FILENAME__ = 004-Review.list
with frontend.signin("alice"):
    result = frontend.operation("Review.list", data={})

    for failed in result["failed"]:
        logger.error("Review.list: %(test)s: %(message)s" % failed)

    for passed in result["passed"]:
        logger.debug("Review.list: %(test)s: passed (%(result)s)" % passed)

########NEW FILE########
__FILENAME__ = 005-MailTransaction
mailbox.check_empty()

with frontend.signin("alice"):
    to_alice = testing.mailbox.ToRecipient("alice@example.org")
    to_bob = testing.mailbox.ToRecipient("bob@example.org")

    frontend.operation(
        "MailTransaction",
        data={ "mails": [{ "to": ["alice", "bob"],
                           "subject": "MailTransaction test #1",
                           "body": "This is the mail body.\n\nBye, bye." }] },
        expect={ "message": None })

    def recipients_equal(expected, actual):
        return set(expected) == set(map(str.strip, actual.split(",")))

    def check_mail1(mail):
        testing.expect.check("Alice von Testing <alice@example.org>",
                             mail.header("From"))
        testing.expect.check(["Alice von Testing <alice@example.org>",
                              "Bob von Testing <bob@example.org>"],
                             mail.header("To"), equal=recipients_equal)
        testing.expect.check("MailTransaction test #1",
                             mail.header("Subject"))
        testing.expect.check(["This is the mail body.", "", "Bye, bye."],
                             mail.lines)

    check_mail1(mailbox.pop(to_alice))
    check_mail1(mailbox.pop(to_bob))

########NEW FILE########
__FILENAME__ = 006-inject
import json

from BeautifulSoup import Comment

def check_injected(key, expected):
    def check(document):
        comments = document.findAll(text=lambda text: isinstance(text, Comment))

        for comment in comments:
            if comment.strip().startswith("[alice/TestExtension] Extension error:"):
                logger.error(comment.strip())
                return

        for script in document.findAll("script"):
            if script.has_key("src"):
                src = script["src"]
                if src.startswith("data:text/javascript,var %s=" % key) \
                        and src[-1] == ";":
                    injected = src[len("data:text/javascript,var %s=" % key):-1]
                    break
        else:
            testing.expect.check("<injected script>",
                                 "<expected content not found>")

        try:
            actual = json.loads(injected)
        except ValueError:
            testing.expect.check("<valid json>", repr(injected))
        else:
            testing.expect.check(expected, actual)

    return check

def check_not_injected(key):
    def check(document):
        comments = document.findAll(text=lambda text: isinstance(text, Comment))

        for comment in comments:
            if comment.strip().startswith("[alice/TestExtension] Extension error:"):
                logger.error(comment.strip())
                return

        for script in document.findAll("script"):
            if script.has_key("src"):
                src = script["src"]
                if src.startswith("data:text/javascript,var %s=" % key) \
                        and src[-1] == ";":
                    testing.expect.check("<no injected script>",
                                         "<injected script found>")
                    break

    return check

with frontend.signin("alice"):
    frontend.page(
        "home",
        expect={ "injected": check_injected(
                "injected",
                ["home", None]) })

    frontend.page(
        "home?foo=bar",
        expect={ "injected": check_injected(
                "injected",
                ["home", { "raw": "foo=bar",
                           "params": { "foo": "bar" }}]) })

    frontend.page(
        "home?foo=bar&x=10&y=20",
        expect={ "injected": check_injected(
                "injected",
                ["home", { "raw": "foo=bar&x=10&y=20",
                           "params": { "foo": "bar",
                                       "x": "10",
                                       "y": "20" }}]) })

    sha1 = repository.run(["rev-parse", "master"]).strip()

    frontend.page(
        "critic/master",
        expect={ "showcommitShort": check_injected(
                "showcommitShort",
                ["critic/master", None]),
                 "showcommitLong": check_injected(
                "showcommitLong",
                ["showcommit", { "raw": "repository=1&sha1=" + sha1,
                                 "params": { "repository": "1",
                                             "sha1": sha1 }}]) })

    frontend.page(
        "showcommit?repository=critic&sha1=master",
        expect={ "showcommitShort": check_not_injected(
                "showcommitShort"),
                "showcommitLong": check_injected(
                "showcommitLong",
                ["showcommit", { "raw": "repository=critic&sha1=master",
                                 "params": { "repository": "critic",
                                             "sha1": "master" }}]) })

# Verify that Alice's extension install doesn't affect Bob.
with frontend.signin("bob"):
    frontend.page(
        "home",
        expect={ "injected": check_not_injected("injected") })

########NEW FILE########
__FILENAME__ = 007-version
def check_version(expected):
    def check(actual):
        testing.expect.check(expected, actual.strip())
    return check

with frontend.signin("alice"):
    frontend.page(
        "version",
        expected_content_type="text/plain",
        expect={ "version": check_version("live") })

with frontend.signin("bob"):
    frontend.page(
        "version",
        expected_http_status=404)

    frontend.operation(
        "installextension",
        data={ "author_name": "alice",
               "extension_name": "TestExtension",
               "version": "version/stable" })

    frontend.page(
        "version",
        expected_content_type="text/plain",
        expect={ "version": check_version("stable:2") })

    frontend.operation(
        "uninstallextension",
        data={ "author_name": "alice",
               "extension_name": "TestExtension" })

    frontend.operation(
        "installextension",
        data={ "author_name": "alice",
               "extension_name": "TestExtension" })

    frontend.page(
        "version",
        expected_content_type="text/plain",
        expect={ "version": check_version("live") })

    frontend.operation(
        "uninstallextension",
        data={ "author_name": "alice",
               "extension_name": "TestExtension" })

    frontend.operation(
        "installextension",
        data={ "author_name": "alice",
               "extension_name": "TestExtension",
               "version": "version/stable",
               "universal": True },
        expect={ "status": "failure",
                 "code": "notallowed" })

with frontend.signin("admin"):
    frontend.operation(
        "installextension",
        data={ "author_name": "alice",
               "extension_name": "TestExtension",
               "version": "version/stable",
               "universal": True })

with frontend.signin("bob"):
    frontend.page(
        "version",
        expected_content_type="text/plain",
        expect={ "version": check_version("stable:2") })

    frontend.operation(
        "installextension",
        data={ "author_name": "alice",
               "extension_name": "TestExtension" })

    frontend.page(
        "version",
        expected_content_type="text/plain",
        expect={ "version": check_version("live") })

    frontend.operation(
        "uninstallextension",
        data={ "author_name": "alice",
               "extension_name": "TestExtension" })

    frontend.page(
        "version",
        expected_content_type="text/plain",
        expect={ "version": check_version("stable:2") })

with frontend.signin("admin"):
    frontend.operation(
        "uninstallextension",
        data={ "author_name": "alice",
               "extension_name": "TestExtension",
               "universal": True })

########NEW FILE########
__FILENAME__ = 008-processcommits
import os
import re

def to(name):
    return testing.mailbox.ToRecipient("%s@example.org" % name)

def about(subject):
    return testing.mailbox.WithSubject(subject)

FILENAME = "008-processcommits.txt"
SUMMARY = "Added %s" % FILENAME

review_id = None

with frontend.signin("alice"):
    frontend.operation(
        "savesettings",
        data={ "settings": [{ "item": "review.createViaPush",
                              "value": True }] })

    with repository.workcopy() as work:
        base_sha1 = work.run(["rev-parse", "HEAD"]).strip()

        work.run(["remote", "add", "critic",
                  "alice@%s:/var/git/critic.git" % instance.hostname])

        def commit(fixup_message=None):
            if fixup_message:
                full_message = "fixup! %s\n\n%s" % (SUMMARY, fixup_message)
            else:
                full_message = SUMMARY
            work.run(["add", FILENAME])
            work.run(["commit", "-m", full_message],
                     GIT_AUTHOR_NAME="Alice von Testing",
                     GIT_AUTHOR_EMAIL="alice@example.org",
                     GIT_COMMITTER_NAME="Alice von Testing",
                     GIT_COMMITTER_EMAIL="alice@example.org")
            return work.run(["rev-parse", "HEAD"]).strip()

        def push():
            output = work.run(
                ["push", "-q", "critic",
                 "HEAD:refs/heads/r/008-processcommits"])
            all_lines = []
            for line in output.splitlines():
                if not line.startswith("remote:"):
                    continue
                all_lines.append(line[len("remote:"):].split("\x1b", 1)[0].strip())
            extension_lines = []
            for line in all_lines:
                if line.startswith("[TestExtension] "):
                    extension_lines.append(line[len("[TestExtension] "):])
            return all_lines, extension_lines

        with open(os.path.join(work.path, FILENAME), "w") as text_file:
            print >>text_file, "First line."

        first_commit = commit()
        all_lines, extension_lines = push()
        next_is_review_url = False

        for line in all_lines:
            if line == "Submitted review:":
                next_is_review_url = True
            elif next_is_review_url:
                review_id = int(re.search(r"/r/(\d+)$", line).group(1))
                break

        testing.expect.check(["processcommits.js::processcommits()",
                              "===================================",
                              "r/%d" % review_id,
                              "%s..%s" % (base_sha1[:8], first_commit[:8]),
                              "%s" % first_commit[:8]],
                             extension_lines)

        mailbox.pop(accept=[to("alice"),
                            about("New Review: %s" % SUMMARY)],
                    timeout=30)

        with open(os.path.join(work.path, FILENAME), "a") as text_file:
            print >>text_file, "Second line."
        second_commit = commit("Added second line")

        with open(os.path.join(work.path, FILENAME), "a") as text_file:
            print >>text_file, "Third line."
        third_commit = commit("Added third line")

        with open(os.path.join(work.path, FILENAME), "a") as text_file:
            print >>text_file, "Fourth line."
        fourth_commit = commit("Added fourth line")

        all_lines, extension_lines = push()

        testing.expect.check(["processcommits.js::processcommits()",
                              "===================================",
                              "r/%d" % review_id,
                              "%s..%s" % (first_commit[:8], fourth_commit[:8]),
                              "%s,%s,%s" % (fourth_commit[:8],
                                            third_commit[:8],
                                            second_commit[:8])],
                             extension_lines)

        mailbox.pop(accept=[to("alice"),
                            about("Updated Review: %s" % SUMMARY)],
                    timeout=30)

########NEW FILE########
__FILENAME__ = 009-error-messages
import re

def check_compilation(document):
    testing.expect.check(
        expected="""\
Extension failure: returned 1
Failed to load 'error\\.compilation\\.js':
  SyntaxError: Strict mode function may not have duplicate parameter names""",
        actual=document,
        equal=re.match)

def check_runtime(document):
    testing.expect.check(
        expected="""\
Extension failure: returned 1
Failed to call 'error\\.runtime\\.js::test\\(\\)':
  CriticError: nosuchuser: no such user
    new CriticUser\\(\\) at <Library>/critic-user\\.js:\\d+
    test\\(\\) at <Extension>/error\\.runtime\\.js:\\d+
    run\\(\\) at <Library>/critic-launcher\\.js:\\d+
    <program code> at <Library>/critic-launcher\\.js:\\d+""",
        actual=document,
        equal=re.match)

with frontend.signin("alice"):
    frontend.page(
        "error.compilation",
        expected_content_type="text/plain",
        expected_http_status=500,
        expect={ "message": check_compilation })

    frontend.page(
        "error.runtime",
        expected_content_type="text/plain",
        expected_http_status=500,
        expect={ "message": check_runtime })

########NEW FILE########
__FILENAME__ = 010-restrictions
with frontend.signin("alice"):
    frontend.operation(
        "restrictions",
        data={},
        expect={ "database_connection": "PostgreSQL is not defined" })

########NEW FILE########
__FILENAME__ = 011-User
DUMP_USER = """\
var user = %s;
return [user.name, user.email, user.fullname, user.isAnonymous];"""

def dump_user(user):
    return DUMP_USER % user

with frontend.signin("alice"):
    frontend.operation(
        "evaluate",
        data={ "source": dump_user("critic.User.current") },
        expect={ "result": ["alice", "alice@example.org", "Alice von Testing", False] })

    frontend.operation(
        "evaluate",
        data={ "source": dump_user("new critic.User(%d)"
                                   % instance.userid("alice")) },
        expect={ "result": ["alice", "alice@example.org", "Alice von Testing", False] })

    frontend.operation(
        "evaluate",
        data={ "source": dump_user("new critic.User({ id: %d })"
                                   % instance.userid("alice")) },
        expect={ "result": ["alice", "alice@example.org", "Alice von Testing", False] })

    frontend.operation(
        "evaluate",
        data={ "source": dump_user("new critic.User('alice')") },
        expect={ "result": ["alice", "alice@example.org", "Alice von Testing", False] })

    frontend.operation(
        "evaluate",
        data={ "source": dump_user("new critic.User({ name: 'alice' })") },
        expect={ "result": ["alice", "alice@example.org", "Alice von Testing", False] })

    frontend.operation(
        "evaluate",
        data={ "source": dump_user("new critic.User({ id: %d, name: 'alice' })"
                                   % instance.userid("alice")) },
        expect={ "result": ["alice", "alice@example.org", "Alice von Testing", False] })

########NEW FILE########
__FILENAME__ = 012-resources
with frontend.signin("alice"):
    frontend.page(
        "extension-resource/TestExtension/helloworld.html",
        expected_content_type="text/html")

    frontend.page(
        "extension-resource/TestExtension/helloworld.css",
        expected_content_type="text/css")

    frontend.page(
        "extension-resource/TestExtension/helloworld.js",
        expected_content_type="text/javascript")

    frontend.page(
        "extension-resource/TestExtension/helloworld.txt",
        expected_http_status=404)

########NEW FILE########
__FILENAME__ = 013-storage
with frontend.signin("alice"):
    frontend.operation(
        "evaluate",
        data={ "source": "return critic.storage.has('the key');" },
        expect={ "result": False })

    frontend.operation(
        "evaluate",
        data={ "source": "return critic.storage.get('the key');" },
        expect={ "result": None })

    frontend.operation(
        "evaluate",
        data={ "source": "critic.storage.set('the key', 'the value');" },
        expect={ "result": None })

    frontend.operation(
        "evaluate",
        data={ "source": "return critic.storage.has('the key');" },
        expect={ "result": True })

    frontend.operation(
        "evaluate",
        data={ "source": "return critic.storage.has('the other key');" },
        expect={ "result": False })

    frontend.operation(
        "evaluate",
        data={ "source": "return critic.storage.get('the key');" },
        expect={ "result": "the value" })

    frontend.operation(
        "clearextensionstorage",
        data={ "author_name": "alice",
               "extension_name": "TestExtension" })

    frontend.operation(
        "evaluate",
        data={ "source": "return critic.storage.has('the key');" },
        expect={ "result": False })

    frontend.operation(
        "evaluate",
        data={ "source": "return critic.storage.get('the key');" },
        expect={ "result": None })

    frontend.operation(
        "evaluate",
        data={ "source": """
critic.storage.set('a', '1');
critic.storage.set('b', '4');
critic.storage.set('aa', '2');
critic.storage.set('bb', '5');
critic.storage.set('aaa', '3');""" },
        expect={ "result": None })

    frontend.operation(
        "evaluate",
        data={ "source": "return critic.storage.list();" },
        expect={ "result": ["a", "aa", "aaa", "b", "bb"] })

    frontend.operation(
        "evaluate",
        data={ "source": "return critic.storage.list({ like: 'a%' });" },
        expect={ "result": ["a", "aa", "aaa"] })

    frontend.operation(
        "evaluate",
        data={ "source": "return critic.storage.list({ like: 'aa%' });" },
        expect={ "result": ["aa", "aaa"] })

    frontend.operation(
        "evaluate",
        data={ "source": "return critic.storage.list({ regexp: 'a+' });" },
        expect={ "result": ["a", "aa", "aaa"] })

    frontend.operation(
        "evaluate",
        data={ "source": "return critic.storage.list({ regexp: '[ab]*' });" },
        expect={ "result": ["a", "aa", "aaa", "b", "bb"] })

########NEW FILE########
__FILENAME__ = 014-Repository.run
import re

RE_NAME_EMAIL = re.compile(r"(author|committer)\s+(.*?)\s+<(.*?)>")

with frontend.signin("alice"):
    result = frontend.operation(
        "evaluate",
        data={ "source": """\
var repository = new critic.Repository("critic");
var tree_sha1 = repository.revparse("HEAD^{tree}");
var parent_sha1 = repository.revparse("HEAD^");
var workcopy = repository.getWorkCopy();
var sha1 = workcopy.run("commit-tree", tree_sha1, "-p", parent_sha1,
                        { stdin: "Fix some stuff!\\n\\nFTW!\\n",
                          GIT_AUTHOR_NAME: "Bob von Testing",
                          GIT_AUTHOR_EMAIL: "bob@example.com",
                          GIT_COMMITTER_NAME: "Alice von Testing",
                          GIT_COMMITTER_EMAIL: "alice@example.com" });
sha1 = sha1.trim(); // includes a line-break
workcopy.run("push", "origin", sha1 + ":refs/heads/014-Repository.run-1");
return sha1;""" })

    with repository.workcopy() as work:
        REMOTE_URL = "alice@" + instance.hostname + ":/var/git/critic.git"

        work.run(["fetch", REMOTE_URL, "refs/heads/014-Repository.run-1"])

        message = None

        for line in work.run(["cat-file", "commit", "FETCH_HEAD"]).splitlines():
            if message is None:
                if not line:
                    message = []
                    continue

                match = RE_NAME_EMAIL.match(line)
                if match:
                    field, name, email = match.groups()

                    if field == "author":
                        testing.expect.check("Bob von Testing", name)
                        testing.expect.check("bob@example.com", email)
                    else:
                        testing.expect.check("Alice von Testing", name)
                        testing.expect.check("alice@example.com", email)
                elif not (line.startswith("tree") or line.startswith("parent")):
                    testing.logger.error("Unexpected line: %r" % line)
            else:
                message.append(line)

        testing.expect.check(["Fix some stuff!", "", "FTW!"], message)

########NEW FILE########
__FILENAME__ = 999-missing
document_title = testing.expect.document_title

def check_version(expected):
    def check(actual):
        testing.expect.check(expected, actual.strip())
    return check

with frontend.signin("alice"):
    # Check that alice still has the LIVE version installed.
    frontend.page(
        "version",
        expected_content_type="text/plain",
        expect={ "version": check_version("live") })

instance.execute(["sudo", "rm", "-rf", "~alice/CriticExtensions"])

with frontend.signin("alice"):
    # Check that the extension is ignored, and that /version just returns 404.
    frontend.page(
        "version",
        expected_http_status=404)

    # Check that /home, where the extension injects things, loads as expected.
    frontend.page(
        "home",
        expect={ "title": document_title(u"Alice von Testing's Home") })

    # Check that /manageextensions also loads as expected.
    frontend.page(
        "manageextensions",
        expect={ "title": document_title(u"Manage Extensions") })

    # ... even with what=installed.
    frontend.page(
        "manageextensions",
        params={ "what": "installed" },
        expect={ "title": document_title(u"Manage Extensions") })

    # Check that the extension can be uninstalled.
    frontend.operation(
        "uninstallextension",
        data={ "author_name": "alice",
               "extension_name": "TestExtension" })

    # Check that /manageextensions still loads.
    frontend.page(
        "manageextensions",
        params={ "what": "installed" },
        expect={ "title": document_title(u"Manage Extensions") })

########NEW FILE########
__FILENAME__ = 005-install-SystemExtension
def check_extension(installed):
    def check(document):
        tr_items = document.findAll("tr", attrs={ "class": "item" })

        for tr_item in tr_items:
            td_name = tr_item.find("td", attrs={ "class": "name" })
            testing.expect.check("Extension:", td_name.string)

            td_value = tr_item.find("td", attrs={ "class": "value" })
            span_name = td_value.find("span", attrs={ "class": "name" })

            if span_name.contents[0].string != "SystemExtension":
                # Wrong extension.
                continue

            testing.expect.check(1, len(span_name.contents))

            span_installed = td_value.find("span", attrs={ "class": "installed" })
            if installed:
                testing.expect.check(" [installed]", span_installed.string)
            elif span_installed:
                testing.expect.check("<no installed indicator>",
                                     "<found installed indicator>")

            return
        else:
            testing.expect.check("<SystemExtension entry>",
                                 "<expected content not found>")

    return check

def check_helloworld(document):
    testing.expect.check("Hello world!\n", document)

try:
    instance.execute(
        ["sudo", "mkdir", "/var/lib/critic/extensions",
         "&&",
         "sudo", "cp", "-R", "~/critic/testing/input/SystemExtension",
         "/var/lib/critic/extensions",
         "&&",
         "sudo", "chown", "-R", "critic.critic",
         "/var/lib/critic/extensions",
         "&&",
         "sudo", "chmod", "-R", "u+rwX,go+rX",
         "/var/lib/critic/extensions"])
except testing.InstanceError as error:
    raise testing.TestFailure(error.message)

with frontend.signin("alice"):
    frontend.page(
        "manageextensions",
        expect={ "system_extension": check_extension(installed=False) })

    frontend.operation(
        "installextension",
        data={ "extension_name": "SystemExtension" })

    frontend.page(
        "manageextensions",
        expect={ "system_extension": check_extension(installed=True) })

    frontend.operation(
        "check",
        data={})

    frontend.page(
        "extension-resource/SystemExtension/HelloWorld.txt",
        expected_content_type="text/plain",
        expect={ "hello_world": check_helloworld })

frontend.page(
    "manageextensions",
    expect={ "system_extension": check_extension(False) })

########NEW FILE########
__FILENAME__ = 006-manifest-checks
import os
import tempfile

instance.execute(
    ["mkdir", "-p", "~/CriticExtensions/InvalidExtension",
     "&&",
     "chmod", "u+rwX,go+rX", "~/CriticExtensions"],
    as_user="alice")

EXTENSION_PATH = "/home/alice/CriticExtensions/InvalidExtension"
MANIFEST_PATH = os.path.join(EXTENSION_PATH, "MANIFEST")

class TransferredFile(object):
    def __init__(self, target_name, source):
        self.target_path = os.path.join(EXTENSION_PATH, target_name)
        self.source = source
    def __enter__(self, *args):
        source_file = tempfile.NamedTemporaryFile()
        source_file.write(self.source)
        source_file.flush()
        instance.copyto(source_file.name, self.target_path, as_user="alice")
        instance.execute(["chmod", "g+r", self.target_path], as_user="alice")
        source_file.close()
        return self
    def __exit__(self, *args):
        instance.execute(["rm", "-f", self.target_path], as_user="alice")

def error_message(linenr, message):
    expected = "%s:%d: manifest error: %s" % (MANIFEST_PATH, linenr, message)
    def check(actual):
        testing.expect.check(expected, actual)
    return check

def injected_script(document):
    scripts = document.findAll("script")
    expected = "<injected script>"
    actual = "<expected content not found>"
    for script in scripts:
        if script["src"] == "injected":
            actual = expected
    testing.expect.check(expected, actual)

script_js = TransferredFile("script.js", """\
function page(method, path, query) {
  writeln("200");
  writeln("Content-Type: text/json");
  writeln();
  writeln("%r", { status: 'ok', method: method, path: path, query: query });
}

function inject(path, query) {
  writeln("script %r", "injected");
}
""")

with frontend.signin("alice"):
    with TransferredFile("MANIFEST", """\
Author = Alice von Testing <alice@example.org>
Description = Extension with invalid MANIFEST

[Page /foo]
Description = Page role with invalid pattern
Script = script.js
Function = page
"""):
        frontend.page(
            "loadmanifest",
            params={ "key": "alice/InvalidExtension" },
            expected_content_type="text/plain",
            expect={ "error_message": error_message(4, "path pattern should not start with a '/'") })

    with script_js, TransferredFile("MANIFEST", """\
Author = Alice von Testing <alice@example.org>
Description = Extension with soon to be missing MANIFEST

[Page foo]
Description = Dummy page role
Script = script.js
Function = page

[Inject tutorial]
Description = Dummy page role
Script = script.js
Function = inject
"""):
        frontend.operation(
            "installextension",
            data={ "extension_name": "InvalidExtension",
                   "author_name": "alice" })

        frontend.operation(
            "foo",
            data={},
            expect={ "method": "POST",
                     "path": "foo" })

        frontend.page(
            "tutorial",
            expect={ "injected_script": injected_script })

    frontend.page(
        "foo",
        expected_http_status=404)

    frontend.page("tutorial")

    frontend.operation(
        "uninstallextension",
        data={ "extension_name": "InvalidExtension",
               "author_name": "alice" })

    with TransferredFile("MANIFEST", """\
Author = Alice von Testing <alice@example.org>
Description = Soon to be inaccessible extension

[Page foo]
Description = Dummy page role
Script = script.js
Function = page
"""):
        frontend.operation(
            "installextension",
            data={ "extension_name": "InvalidExtension",
                   "author_name": "alice" })

        instance.execute(
            ["chmod", "go-rx", "~/CriticExtensions/InvalidExtension"],
            as_user="alice")

        frontend.page(
            "foo",
            expected_http_status=404)

    frontend.operation(
        "uninstallextension",
        data={ "extension_name": "InvalidExtension",
               "author_name": "alice" })

########NEW FILE########
__FILENAME__ = 001-independence
# These tests simply check that some modules can be imported.

instance.unittest("base", ["independence"])
instance.unittest("dbutils", ["independence"])
instance.unittest("textutils", ["independence"])
instance.unittest("htmlutils", ["independence"])
instance.unittest("operation", ["independence"])

########NEW FILE########
__FILENAME__ = 002-operation
# @dependency 001-main/005-unittests/001-local/001-independence.py
# @flag local

# These tests simply check that some modules can be imported.

instance.unittest("operation.basictypes", ["basic"])
instance.unittest("operation.typechecker", ["basic"])

########NEW FILE########
__FILENAME__ = 900-uninstall-reinstall
# Uninstall Critic.
instance.uninstall()

# Delete the repository clone (the install() call recreates it.)
instance.execute(["rm", "-rf", "critic"])

# Install (and upgrade, optionally) Critic with the default arguments.
instance.install(repository, other_cwd=True)
instance.upgrade()

########NEW FILE########
__FILENAME__ = 001-install
# We don't need to do anything if extension testing is not supported.
instance.check_extend(repository, pre_upgrade=True)

# We also don't need to do anything if there was no --upgrade-from.
instance.check_upgrade()

instance.start()
instance.install(repository)

########NEW FILE########
__FILENAME__ = 001-enable
../../../001-main/004-extensions/001-enable.py
########NEW FILE########
__FILENAME__ = 002-install-TestExtension
../../../001-main/004-extensions/002-tests/003-install-TestExtension.py
########NEW FILE########
__FILENAME__ = 003-version
../../../001-main/004-extensions/002-tests/004-TestExtension/007-version.py
########NEW FILE########
__FILENAME__ = 003-upgrade
instance.upgrade()

########NEW FILE########
__FILENAME__ = 001-version
../../../001-main/004-extensions/002-tests/004-TestExtension/007-version.py
########NEW FILE########
__FILENAME__ = install
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2013 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import argparse
import subprocess

import testing

def main():
    parser = argparse.ArgumentParser(
        description="Critic testing framework: Quick install utility")

    parser.add_argument("--debug",
                        help="Enable DEBUG level logging", action="store_true")
    parser.add_argument("--quiet",
                        help="Disable INFO level logging", action="store_true")

    parser.add_argument("--commit", default="HEAD",
                        help="Commit (symbolic ref or SHA-1) to test [default=HEAD]")
    parser.add_argument("--upgrade-from",
                        help="Commit (symbolic ref or SHA-1) to install first and upgrade from")

    parser.add_argument("--vm-identifier", required=True,
                        help="VirtualBox instance name or UUID")
    parser.add_argument("--vm-hostname",
                        help="VirtualBox instance hostname [default=VM_IDENTIFIER]")
    parser.add_argument("--vm-snapshot", default="clean",
                        help="VirtualBox snapshot (name or UUID) to upgrade [default=clean]")
    parser.add_argument("--vm-ssh-port", type=int, default=22,
                        help="VirtualBox instance SSH port [default=22]")
    parser.add_argument("--git-daemon-port", type=int,
                        help="Port to tell 'git daemon' to bind to")

    parser.add_argument("--interactive", "-i", action="store_true",
                        help="Install interactively (without arguments)")

    arguments = parser.parse_args()

    logger = testing.configureLogging(arguments)
    logger.info("Critic testing framework: Quick install")

    tested_commit = subprocess.check_output(
        ["git", "rev-parse", "--verify", arguments.commit]).strip()

    if arguments.upgrade_from:
        install_commit = subprocess.check_output(
            ["git", "rev-parse", "--verify", arguments.upgrade_from]).strip()
        upgrade_commit = tested_commit
    else:
        install_commit = tested_commit
        upgrade_commit = None

    install_commit_description = subprocess.check_output(
        ["git", "log", "--oneline", "-1", install_commit]).strip()

    if upgrade_commit:
        upgrade_commit_description = subprocess.check_output(
            ["git", "log", "--oneline", "-1", upgrade_commit]).strip()
    else:
        upgrade_commit_description = None

    instance = testing.virtualbox.Instance(
        arguments,
        install_commit=(install_commit, install_commit_description),
        upgrade_commit=(upgrade_commit, upgrade_commit_description))

    repository = testing.repository.Repository(
        arguments.git_daemon_port,
        install_commit,
        arguments.vm_hostname)

    mailbox = testing.mailbox.Mailbox()

    with repository, mailbox, instance:
        if not repository.export():
            return

        instance.mailbox = mailbox
        instance.start()

        if arguments.interactive:
            print """
Note: To use the simple SMTP server built into the Critic testing framework,
      enter "host" as the SMTP host and "%d" as the SMTP port.

Also note: The administrator user's password will be "testing" (password
           input doesn't work over this channel.)""" % mailbox.port

        instance.install(repository, quick=True,
                         interactive=arguments.interactive)
        instance.upgrade(interactive=arguments.interactive)

        testing.pause("Press ENTER to stop VM: ")

        try:
            while True:
                mail = mailbox.pop(timeout=0)
                logger.info("Mail to <%s>:\n%s" % (mail.recipient, mail))
        except testing.mailbox.MissingMail:
            pass

if __name__ == "__main__":
    main()

########NEW FILE########
__FILENAME__ = upgrade
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2013 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import argparse
import time

import testing

def main():
    parser = argparse.ArgumentParser(
        description="Critic testing framework: instance upgrade utility")
    parser.add_argument("--debug", help="Enable DEBUG level logging", action="store_true")
    parser.add_argument("--quiet", help="Disable INFO level logging", action="store_true")
    parser.add_argument("--vm-identifier", help="VirtualBox instance name or UUID", required=True)
    parser.add_argument("--vm-hostname", help="VirtualBox instance hostname [default=VM_IDENTIFIER]")
    parser.add_argument("--vm-snapshot", help="VirtualBox snapshot (name or UUID) to upgrade", default="clean")
    parser.add_argument("--vm-ssh-port", help="VirtualBox instance SSH port [default=22]", type=int, default=22)
    parser.add_argument("--pause-before-upgrade", help="Pause before upgrading", action="store_true")
    parser.add_argument("--pause-after-upgrade", help="Pause after upgrading", action="store_true")
    parser.add_argument("--no-upgrade", action="store_true", help="Do not upgrade installed packages")
    parser.add_argument("--install", action="append", help="Install named package")
    parser.add_argument("--custom", action="store_true",
                        help="Stop for custom maintenance, and always retake snapshot")
    parser.add_argument("--reboot", action="store_true",
                        help="Reboot VM before retaking snapshot")

    arguments = parser.parse_args()

    logger = testing.configureLogging(arguments)
    logger.info("Critic Testing Framework: Instance Upgrade")

    instance = testing.virtualbox.Instance(arguments)

    with instance:
        instance.start()

        if not arguments.no_upgrade:
            logger.debug("Upgrading guest OS ...")

            update_output = instance.execute(
                ["sudo", "DEBIAN_FRONTEND=noninteractive",
                 "apt-get", "-q", "-y", "update"])

            logger.debug("Output from 'apt-get -q -y update':\n" + update_output)

            upgrade_output = instance.execute(
                ["sudo", "DEBIAN_FRONTEND=noninteractive",
                 "apt-get", "-q", "-y", "upgrade"])

            logger.debug("Output from 'apt-get -q -y upgrade':\n" + upgrade_output)

            retake_snapshot = False

            if "The following packages will be upgraded:" in upgrade_output.splitlines():
                retake_snapshot = True

        if arguments.install:
            install_output = instance.execute(
                ["sudo", "DEBIAN_FRONTEND=noninteractive",
                 "apt-get", "-q", "-y", "install"] + arguments.install)

            logger.debug("Output from 'apt-get -q -y install':\n" +
                         install_output)

            retake_snapshot = True

        if arguments.custom:
            testing.pause()
            retake_snapshot = True

        if retake_snapshot:
            if arguments.reboot:
                instance.execute(["sudo", "reboot"])

                logger.debug("Sleeping 10 seconds ...")
                time.sleep(10)

                instance.wait()

                logger.debug("Sleeping 10 seconds ...")
                time.sleep(10)

                logger.info("Rebooted VM: %s" % arguments.vm_identifier)

            logger.info("Upgraded guest OS")
            logger.debug("Retaking snapshot ...")

            instance.retake_snapshot(arguments.vm_snapshot)

            logger.info("Snapshot '%s' upgraded!" % arguments.vm_snapshot)
        else:
            logger.info("No packages upgraded in guest OS")

if __name__ == "__main__":
    main()

########NEW FILE########
__FILENAME__ = utils
import re

instance = None
frontend = None

RE_REVIEW_URL = re.compile(r"^remote:\s+http://.*/r/(\d+)\s*$")

def createReviewViaPush(work, owner, commit="HEAD"):
    with frontend.signin(owner):
        frontend.operation(
            "savesettings",
            data={ "settings": [{ "item": "review.createViaPush",
                                  "value": True }] })

    remote_url = "%s@%s:/var/git/critic.git" % (owner, instance.hostname)
    output = work.run(["push", remote_url, "HEAD"], TERM="dumb")
    for line in output.splitlines():
        match = RE_REVIEW_URL.match(line)
        if match:
            return int(match.group(1))
    else:
        testing.expect.check("<review URL in 'git push' output>",
                             "<no review URL found>")

########NEW FILE########
__FILENAME__ = virtualbox
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2013 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import sys
import os
import subprocess
import time
import fcntl
import select
import errno
import datetime

import testing

def exists_at(commit_sha1, path):
    lstree = subprocess.check_output(["git", "ls-tree", commit_sha1, path])
    return bool(lstree.strip())

def flag(commit_sha1, name):
    return exists_at(commit_sha1, "testing/flags/%s.flag" % name)

def flag_pwd_independence(commit_sha1):
    return flag(commit_sha1, "pwd-independence")

def flag_is_testing(commit_sha1):
    return flag(commit_sha1, "is-testing")

def flag_system_recipients(commit_sha1):
    return flag(commit_sha1, "system-recipients")

def flag_minimum_password_hash_time(commit_sha1):
    try:
        subprocess.check_call(
            ["git", "grep", "--quiet", "-e", "--minimum-password-hash-time",
             commit_sha1, "--", "installation/config.py"])
    except subprocess.CalledProcessError:
        return False
    else:
        return True

# Directory (on guest system) to store coverage data in.
COVERAGE_DIR = "/var/tmp/critic/coverage"

def setnonblocking(fd):
    fcntl.fcntl(fd, fcntl.F_SETFL, fcntl.fcntl(fd, fcntl.F_GETFL) | os.O_NONBLOCK)

class HostCommandError(testing.InstanceError):
    def __init__(self, command, output):
        super(HostCommandError, self).__init__(
            "HostCommandError: %s\nOutput:\n%s" % (command, output))
        self.command = command
        self.output = output

class GuestCommandError(testing.InstanceError):
    def __init__(self, command, stdout, stderr=None):
        super(GuestCommandError, self).__init__(
            "GuestCommandError: %s\nOutput:\n%s" % (command, stderr or stdout))
        self.command = command
        self.stdout = stdout
        self.stderr = stderr

class Instance(testing.Instance):
    def __init__(self, arguments, install_commit=None, upgrade_commit=None,
                 frontend=None):
        self.arguments = arguments
        self.vboxhost = getattr(arguments, "vbox_host", "host")
        self.identifier = arguments.vm_identifier
        self.snapshot = arguments.vm_snapshot
        self.hostname = arguments.vm_hostname or self.identifier
        self.ssh_port = arguments.vm_ssh_port
        if install_commit:
            self.install_commit, self.install_commit_description = install_commit
        if upgrade_commit:
            self.upgrade_commit, self.upgrade_commit_description = upgrade_commit
        self.frontend = frontend
        self.strict_fs_permissions = getattr(arguments, "strict_fs_permissions", False)
        self.coverage = getattr(arguments, "coverage", False)
        self.mailbox = None
        self.__started = False
        self.__installed = False

        # Check that the identified VM actually exists:
        output = subprocess.check_output(
            ["VBoxManage", "list", "vms"],
            stderr=subprocess.STDOUT)
        if not self.__isincluded(output):
            raise testing.Error("Invalid VM identifier: %s" % self.identifier)

        # Check that the identified snapshot actually exists (and that there
        # aren't multiple snapshots with the same name):
        count = self.count_snapshots(self.snapshot)
        if count == 0:
            raise testing.Error("Invalid VM snapshot: %s (not found)"
                                % self.snapshot)
        elif count > 1:
            raise testing.Error("Invalid VM snapshot: %s (matches multiple snapshots)"
                                % self.snapshot)

        self.__users = ["admin"]
        self.__user_ids = { "admin": 1 }

    def __enter__(self):
        return self

    def __exit__(self, *args):
        if self.__started:
            self.stop()
        return False

    def __vmcommand(self, command, *arguments):
        argv = ["VBoxManage", command, self.identifier] + list(arguments)
        try:
            testing.logger.debug("Running: " + " ".join(argv))
            return subprocess.check_output(argv, stderr=subprocess.STDOUT)
        except subprocess.CalledProcessError as error:
            raise HostCommandError(" ".join(argv), error.output)

    def __isincluded(self, output):
        name = '"%s"' % self.identifier
        uuid = '{%s}' % self.identifier

        for line in output.splitlines():
            if name in line or uuid in line:
                return True
        else:
            return False

    def isrunning(self):
        output = subprocess.check_output(
            ["VBoxManage", "list", "runningvms"],
            stderr=subprocess.STDOUT)
        return self.__isincluded(output)

    def state(self):
        output = self.__vmcommand("showvminfo", "--machinereadable")
        for line in output.splitlines():
            if line.startswith("VMState="):
                return eval(line[len("VMState="):])
        return "<not found>"

    def count_snapshots(self, identifier):
        try:
            output = subprocess.check_output(
                ["VBoxManage", "snapshot", self.identifier, "list"],
                stderr=subprocess.STDOUT)
        except subprocess.CalledProcessError:
            # Assuming we've already checked that 'self.identifier' is a valid
            # VM identifier, the most likely cause of this failure is that the
            # VM has no snapshots.
            return 0
        else:
            name = "Name: %s (" % identifier
            uuid = "(UUID: %s)" % identifier
            count = 0
            for line in output.splitlines():
                if name in line or uuid in line:
                    count += 1
            return count

    def wait(self):
        testing.logger.debug("Waiting for VM to come online ...")

        while True:
            try:
                self.execute(["true"], timeout=1)
            except GuestCommandError:
                time.sleep(0.5)
            else:
                break

    def start(self):
        testing.logger.debug("Starting VM: %s ..." % self.identifier)

        self.__vmcommand("snapshot", "restore", self.snapshot)
        self.__vmcommand("startvm", "--type", "headless")
        self.__started = True

        self.wait()

        # Set the guest system's clock to match the host system's.  Since we're
        # restoring the same snapshot over and over, the guest system's clock is
        # probably quite far from the truth.
        now = datetime.datetime.utcnow().strftime("%m%d%H%M%Y.%S")
        self.execute(["sudo", "date", "--utc", now])

        testing.logger.info("Started VM: %s" % self.identifier)

    def stop(self):
        testing.logger.debug("Stopping VM: %s ..." % self.identifier)

        self.__vmcommand("controlvm", "poweroff")

        while self.state() != "poweroff":
            time.sleep(0.1)

        # It appears the VirtualBox "session" can be locked for a while after
        # the "controlvm poweroff" command, and possibly after the VM state
        # changes to "poweroff", so sleep a little longer to avoid problems.
        time.sleep(0.5)

        testing.logger.info("Stopped VM: %s" % self.identifier)

        self.__started = False

    def retake_snapshot(self, name):
        index = 1

        while True:
            temporary_name = "%s-%d" % (name, index)
            if self.count_snapshots(temporary_name) == 0:
                break
            index += 1

        self.__vmcommand("snapshot", "take", temporary_name, "--pause")
        self.__vmcommand("snapshot", "delete", name)
        self.__vmcommand("snapshot", "edit", temporary_name, "--name", name)

    def execute(self, argv, cwd=None, timeout=None, interactive=False,
                as_user=None, log_stdout=True, log_stderr=True):
        guest_argv = list(argv)
        if cwd is not None:
            guest_argv[:0] = ["cd", cwd, "&&"]
        host_argv = ["ssh"]
        if self.ssh_port != 22:
            host_argv.extend(["-p", str(self.ssh_port)])
        if timeout is not None:
            host_argv.extend(["-o", "ConnectTimeout=%d" % timeout])
        if not interactive:
            host_argv.append("-n")
        if as_user is not None:
            host_argv.extend(["-l", as_user])
        host_argv.append(self.hostname)

        testing.logger.debug("Running: " + " ".join(host_argv + guest_argv))

        process = subprocess.Popen(
            host_argv + guest_argv,
            stdout=subprocess.PIPE if not interactive else None,
            stderr=subprocess.PIPE if not interactive else None)

        class BufferedLineReader(object):
            def __init__(self, source):
                self.source = source
                self.buffer = ""

            def readline(self):
                try:
                    while self.source is not None:
                        try:
                            line, self.buffer = self.buffer.split("\n", 1)
                        except ValueError:
                            pass
                        else:
                            return line + "\n"
                        data = self.source.read(1024)
                        if not data:
                            self.source = None
                            break
                        self.buffer += data
                    line = self.buffer
                    self.buffer = ""
                    return line
                except IOError as error:
                    if error.errno == errno.EAGAIN:
                        return None
                    raise

        stdout_data = ""
        stdout_reader = BufferedLineReader(process.stdout)

        stderr_data = ""
        stderr_reader = BufferedLineReader(process.stderr)

        if not interactive:
            setnonblocking(process.stdout)
            setnonblocking(process.stderr)

            poll = select.poll()
            poll.register(process.stdout)
            poll.register(process.stderr)

            stdout_done = False
            stderr_done = False

            while not (stdout_done and stderr_done):
                poll.poll()

                while not stdout_done:
                    line = stdout_reader.readline()
                    if line is None:
                        break
                    elif not line:
                        poll.unregister(process.stdout)
                        stdout_done = True
                        break
                    else:
                        stdout_data += line
                        if log_stdout:
                            testing.logger.log(testing.STDOUT, line.rstrip("\n"))

                while not stderr_done:
                    line = stderr_reader.readline()
                    if line is None:
                        break
                    elif not line:
                        poll.unregister(process.stderr)
                        stderr_done = True
                        break
                    else:
                        stderr_data += line
                        if log_stderr:
                            testing.logger.log(testing.STDERR, line.rstrip("\n"))

        process.wait()

        if process.returncode != 0:
            raise GuestCommandError(" ".join(argv), stdout_data, stderr_data)

        return stdout_data

    def copyto(self, source, target, as_user=None):
        target = "%s:%s" % (self.hostname, target)
        if as_user:
            target = "%s@%s" % (as_user, target)
        argv = ["scp", "-q", "-P", str(self.ssh_port), source, target]
        try:
            testing.logger.debug("Running: " + " ".join(argv))
            return subprocess.check_output(argv, stderr=subprocess.STDOUT)
        except subprocess.CalledProcessError as error:
            raise GuestCommandError(" ".join(argv), error.output)

    def copyfrom(self, source, target, as_user=None):
        source = "%s:%s" % (self.hostname, source)
        if as_user:
            source = "%s@%s" % (as_user, source)
        argv = ["scp", "-q", "-P", str(self.ssh_port), source, target]
        try:
            testing.logger.debug("Running: " + " ".join(argv))
            return subprocess.check_output(argv, stderr=subprocess.STDOUT)
        except subprocess.CalledProcessError as error:
            raise GuestCommandError(" ".join(argv), error.output)

    def adduser(self, name, email=None, fullname=None, password=None):
        if email is None:
            email = "%s@example.org" % name
        if fullname is None:
            fullname = "%s von Testing" % name.capitalize()
        if password is None:
            password = "testing"

        self.execute([
            "sudo", "criticctl", "adduser", "--name", name, "--email", email,
            "--fullname", "'%s'" % fullname, "--password", password,
            "&&",
            "sudo", "adduser", "--ingroup", "critic", "--disabled-password",
            "--gecos", "''", name])

        # Running all commands with a single self.execute() call is just an
        # optimization; SSH sessions are fairly expensive to start.
        self.execute([
            "sudo", "mkdir", ".ssh",
            "&&",
            "sudo", "cp", "$HOME/.ssh/authorized_keys", ".ssh/",
            "&&",
            "sudo", "chown", "-R", name, ".ssh/",
            "&&",
            "sudo", "-H", "-u", name, "git", "config", "--global", "user.name",
            "'%s'" % fullname,
            "&&",
            "sudo", "-H", "-u", name, "git", "config", "--global", "user.email",
            email],
                     cwd="/home/%s" % name)

        self.__users.append(name)
        self.__user_ids[name] = len(self.__users)

    def userid(self, name):
        return self.__user_ids.get(name)

    def restrict_access(self):
        if not self.strict_fs_permissions:
            return

        # Set restrictive access bits on home directory of the installing user
        # and of root, to make sure that no part of Critic's installation
        # process, or the background processes started by it, depend on being
        # able to access them as the Critic system user.
        self.execute(["sudo", "chmod", "-R", "go-rwx", "$HOME", "/root"])

        # Running install.py may have left files owned by root in $HOME.  The
        # command above will have made them inaccessible for sure, so change
        # the ownership back to us.
        self.execute(["sudo", "chown", "-R", "$LOGNAME", "$HOME"])

    def install(self, repository, override_arguments={}, other_cwd=False,
                quick=False, interactive=False):
        testing.logger.debug("Installing Critic ...")

        if not interactive:
            use_arguments = { "--headless": True,
                              "--system-hostname": self.hostname,
                              "--auth-mode": "critic",
                              "--session-type": "cookie",
                              "--admin-username": "admin",
                              "--admin-email": "admin@example.org",
                              "--admin-fullname": "'Testing Administrator'",
                              "--admin-password": "testing",
                              "--smtp-host": self.vboxhost,
                              "--smtp-port": str(self.mailbox.port),
                              "--smtp-no-ssl-tls": True,
                              "--skip-testmail-check": True }

            if self.mailbox.credentials:
                use_arguments["--smtp-username"] = self.mailbox.credentials["username"]
                use_arguments["--smtp-password"] = self.mailbox.credentials["password"]

            if self.coverage:
                use_arguments["--coverage-dir"] = COVERAGE_DIR

            if flag_system_recipients(self.install_commit):
                use_arguments["--system-recipient"] = "system@example.org"
        else:
            use_arguments = { "--admin-password": "testing" }

        if flag_minimum_password_hash_time(self.install_commit):
            use_arguments["--minimum-password-hash-time"] = "0.01"

        if flag_is_testing(self.install_commit):
            use_arguments["--is-testing"] = True

        for name, value in override_arguments.items():
            if value is None:
                if name in use_arguments:
                    del use_arguments[name]
            else:
                use_arguments[name] = value

        arguments = []

        for name, value in use_arguments.items():
            arguments.append(name)
            if value is not True:
                arguments.append(value)

        # First install (if necessary) Git.
        try:
            self.execute(["git", "--version"])
        except GuestCommandError:
            testing.logger.debug("Installing Git ...")

            self.execute(["sudo", "DEBIAN_FRONTEND=noninteractive",
                          "apt-get", "-qq", "update"])

            self.execute(["sudo", "DEBIAN_FRONTEND=noninteractive",
                          "apt-get", "-qq", "-y", "install", "git-core"])

            testing.logger.info("Installed Git: %s" % self.execute(["git", "--version"]).strip())

        self.execute(["git", "clone", repository.url, "critic"])
        self.execute(["git", "fetch", "--quiet", "&&",
                      "git", "checkout", "--quiet", self.install_commit],
                     cwd="critic")

        if self.upgrade_commit:
            output = subprocess.check_output(
                ["git", "log", "--oneline", self.install_commit, "--",
                 "background/servicemanager.py"])

            for line in output.splitlines():
                sha1, subject = line.split(" ", 1)
                if subject == "Make sure background services run with correct $HOME":
                    self.restrict_access()
                    break
        else:
            self.restrict_access()

        if other_cwd and flag_pwd_independence(self.install_commit):
            install_py = "critic/install.py"
            cwd = None
        else:
            install_py = "install.py"
            cwd = "critic"

        self.execute(
            ["sudo", "python", "-u", install_py] + arguments,
            cwd=cwd, interactive="--headless" not in use_arguments)

        if not quick:
            try:
                testmail = self.mailbox.pop(
                    testing.mailbox.WithSubject("Test email from Critic"),
                    timeout=3)

                if not testmail:
                    testing.expect.check("<test email>", "<no test email received>")
                else:
                    testing.expect.check("admin@example.org",
                                         testmail.header("To"))
                    testing.expect.check("This is the configuration test email from Critic.",
                                         "\n".join(testmail.lines))

                self.mailbox.check_empty()
            except testing.TestFailure as error:
                if error.message:
                    testing.logger.error("Basic test: %s" % error.message)

                # If basic tests fail, there's no reason to further test this
                # instance; it seems to be properly broken.
                raise testing.InstanceError

            # Add "developer" role to get stacktraces in error messages.
            self.execute(["sudo", "criticctl", "addrole",
                          "--name", "admin",
                          "--role", "developer"])

            # Add some regular users.
            for name in ("alice", "bob", "dave", "erin"):
                self.adduser(name)

            self.adduser("howard")
            self.execute(["sudo", "criticctl", "addrole",
                          "--name", "howard",
                          "--role", "newswriter"])

            try:
                self.frontend.run_basic_tests()
                self.mailbox.check_empty()
            except testing.TestFailure as error:
                if error.message:
                    testing.logger.error("Basic test: %s" % error.message)

                # If basic tests fail, there's no reason to further test this
                # instance; it seems to be properly broken.
                raise testing.InstanceError

        testing.logger.info("Installed Critic: %s" % self.install_commit_description)

        self.__installed = True

    def check_upgrade(self):
        if not self.upgrade_commit:
            raise testing.NotSupported("--upgrade-from argument not given")

    def upgrade(self, override_arguments={}, other_cwd=False, quick=False,
                interactive=False):
        if self.upgrade_commit:
            testing.logger.debug("Upgrading Critic ...")

            self.restrict_access()

            if not interactive:
                use_arguments = { "--headless": True }
            else:
                use_arguments = {}

            if not flag_minimum_password_hash_time(self.install_commit):
                use_arguments["--minimum-password-hash-time"] = "0.01"

            if not flag_is_testing(self.install_commit):
                use_arguments["--is-testing"] = True

            if not flag_system_recipients(self.install_commit):
                use_arguments["--system-recipient"] = "system@example.org"

            for name, value in override_arguments.items():
                if value is None:
                    if name in use_arguments:
                        del use_arguments[name]
                else:
                    use_arguments[name] = value

            arguments = []

            for name, value in use_arguments.items():
                arguments.append(name)
                if value is not True:
                    arguments.append(value)

            self.execute(["git", "checkout", self.upgrade_commit], cwd="critic")

            if other_cwd and flag_pwd_independence(self.upgrade_commit):
                upgrade_py = "critic/upgrade.py"
                cwd = None
            else:
                upgrade_py = "upgrade.py"
                cwd = "critic"

            self.execute(["sudo", "python", "-u", upgrade_py] + arguments,
                         cwd=cwd, interactive="--headless" not in use_arguments)

            if not quick:
                self.frontend.run_basic_tests()

            testing.logger.info("Upgraded Critic: %s" % self.upgrade_commit_description)

    def check_extend(self, repository, pre_upgrade=False):
        if not exists_at(self.install_commit, "extend.py"):
            raise testing.NotSupported("installed commit lacks extend.py")
        if not self.arguments.test_extensions:
            raise testing.NotSupported("--test-extensions argument not given")
        if not repository.v8_jsshell_path:
            raise testing.NotSupported("v8-jsshell sub-module not initialized")

    def extend(self, repository):
        self.check_extend(repository)

        testing.logger.debug("Extending Critic ...")

        def internal(action, extra_argv=None):
            argv = ["sudo", "python", "-u", "extend.py", "--headless",
                    "--%s" % action]

            if extra_argv:
                argv.extend(extra_argv)

            self.execute(argv, cwd="critic")

        internal("prereqs")

        v8_jsshell_sha1 = subprocess.check_output(
            ["git", "ls-tree", "HEAD:installation/externals", "v8-jsshell"]).split()[2]
        cached_executable = os.path.join(self.arguments.cache_dir,
                                         self.identifier, "v8-jsshell",
                                         v8_jsshell_sha1)

        if os.path.isfile(cached_executable):
            self.execute(["mkdir", "installation/externals/v8-jsshell/out"], cwd="critic")
            self.copyto(cached_executable,
                        "critic/installation/externals/v8-jsshell/out/jsshell")
            testing.logger.debug("Copied cached v8-jsshell executable to instance")
        else:
            if repository.v8_url:
                extra_argv = ["--with-v8=%s" % repository.v8_url]
            else:
                extra_argv = None

            internal("fetch", extra_argv)

            v8_sha1 = subprocess.check_output(
                ["git", "ls-tree", "HEAD", "v8"],
                cwd="installation/externals/v8-jsshell").split()[2]
            cached_v8deps = os.path.join(self.arguments.cache_dir,
                                         "v8-dependencies",
                                         "%s.tar.bz2" % v8_sha1)
            if os.path.isfile(cached_v8deps):
                self.copyto(cached_v8deps, "v8deps.tar.bz2")
                internal("import-v8-dependencies=~/v8deps.tar.bz2")
            else:
                internal("export-v8-dependencies=~/v8deps.tar.bz2")
                if not os.path.isdir(os.path.dirname(cached_v8deps)):
                    os.makedirs(os.path.dirname(cached_v8deps))
                self.copyfrom("v8deps.tar.bz2", cached_v8deps)

            internal("build")
            if not os.path.isdir(os.path.dirname(cached_executable)):
                os.makedirs(os.path.dirname(cached_executable))
            self.copyfrom("critic/installation/externals/v8-jsshell/out/jsshell",
                          cached_executable)
            testing.logger.debug("Copied built v8-jsshell executable from instance")

        internal("install")
        internal("enable")

        self.frontend.run_basic_tests()

        testing.logger.info("Extensions enabled")

    def restart(self):
        self.execute(["sudo", "criticctl", "restart"])

    def uninstall(self):
        self.execute(
            ["sudo", "python", "uninstall.py", "--headless", "--keep-going"],
            cwd="critic")

        # Delete the regular users.
        for name in ("alice", "bob", "dave", "erin"):
            self.execute(["sudo", "deluser", "--remove-home", name])

        self.execute(["sudo", "deluser", "--remove-home", "howard"])

        self.__installed = False

    def finish(self):
        if not self.__started:
            return

        if self.__installed:
            self.execute(["sudo", "service", "critic-main", "stop"])
            self.execute(["sudo", "service", "apache2", "stop"])

        if self.coverage:
            sys.stdout.write(self.execute(
                ["sudo", "python", "coverage.py",
                 "--coverage-dir", COVERAGE_DIR,
                 "--critic-dir", "/etc/critic/main",
                 "--critic-dir", "/usr/share/critic"],
                cwd="/usr/share/critic"))

        # Check that we didn't leave any files owned by root anywhere in the
        # directory we installed from.
        self.execute(["chmod", "-R", "a+r", "critic"])
        self.execute(["rm", "-r", "critic"])

    def unittest(self, module, tests, args=None):
        testing.logger.info("Running unit tests: %s (%s)"
                            % (module, ",".join(tests)))
        path = self.translateUnittestPath(module)
        if not args:
            args = []
        for test in tests:
            try:
                self.execute(["cd", "/usr/share/critic", "&&",
                              "sudo", "-H", "-u", "critic",
                              "PYTHONPATH=/etc/critic/main:/usr/share/critic",
                              "python", path, test] + args,
                             log_stderr=False)
            except GuestCommandError as error:
                output = "\n  ".join(error.stderr.splitlines())
                testing.logger.error("Unit tests failed: %s: %s\nOutput:\n  %s"
                                     % (module, test, output))

########NEW FILE########
__FILENAME__ = __main__
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2013 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import main
main.main()

########NEW FILE########
__FILENAME__ = uninstall
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2012 Martin Olsson
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import os
import grp
import sys
import argparse
import subprocess

import installation

def enum(*sequential, **named):
    enums = dict(zip(sequential, range(len(sequential))), **named)
    return type('Enum', (), enums)

ExitStatus = enum('EXIT_SUCCESS', 'MUST_RUN_AS_ROOT', 'INVALID_ETC_DIR', 'UNEXPECTED_ERROR')

def check(value):
    if value.strip() != "deletemydata":
        return "to continue with uninstall, enter 'deletemydata', to abort uninstall press CTRL-C"

def abort_if_no_keep_going_param(arguments, error_msg):
    if not arguments.keep_going:
        print error_msg
        print "Unexpected error encountered.  Critic uninstall aborted."
        print "Re-run with --keep-going to ignore errors."
        sys.exit(ExitStatus.UNEXPECTED_ERROR)

def get_all_configurations(arguments):
    configurations = []
    etc_dir = arguments.etc_dir
    original_sys_path = list(sys.path)

    for critic_instance in os.listdir(etc_dir):
        etc_path = os.path.join(etc_dir, critic_instance)

        if not os.path.isdir(etc_path):
            abort_if_no_keep_going_param(arguments, "ERROR: %s is not a directory." % etc_path)

        sys.path = list(original_sys_path)
        sys.path.insert(0, etc_path)

        try:
            import configuration
            configurations.append(configuration)
        except ImportError:
            abort_if_no_keep_going_param(arguments, "ERROR: Failed to load Critic instance configuration from %s." % etc_path)

    sys.path = list(original_sys_path)
    return configurations

def run_command(arguments, command_parts):
    try:
        subprocess.check_output(command_parts)
    except:
        abort_if_no_keep_going_param(arguments, "Error while running command: " + ' '.join(command_parts))

def rmdir_if_empty(directories):
    for dir in directories:
        try:
            os.rmdir(dir)
        except OSError:
            pass

def main():
    parser = argparse.ArgumentParser(description="Critic uninstall script")
    parser.add_argument("--headless", help=argparse.SUPPRESS, action="store_true")
    parser.add_argument("--etc-dir", default="/etc/critic", help="root directory for Critic system configurations i.e. specifying /etc/critic will read configuration data from /etc/critic/*/configuration/*.py", action="store")
    parser.add_argument("--keep-going", help="keep going even if errors are encountered (useful for purging broken installations)", action="store_true")
    arguments = parser.parse_args()

    if os.getuid() != 0:
        print """
ERROR: This script must be run as root.
"""
        sys.exit(ExitStatus.MUST_RUN_AS_ROOT)

    if not arguments.headless:
        print """\
!!!! WARNING !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
This uninstall script will delete Critic, all Critic logs, caches and
configuration files, and it will also DELETE ALL DATA related to Critic.
It will drop the entire Critic database from postgresql and it will
permanently delete the Critic git repositories.  If there are multiple
instances of Critic on this system, all of them will be removed.
!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!

This step cannot be undone! To abort the uninstall script, press CTRL-C now.
"""
        installation.input.string("To continue the uninstall script and DELETE ALL YOUR DATA, enter 'deletemydata' here:", default="", check=check)

    if not os.path.isdir(arguments.etc_dir):
        print "%s: no such directory.  Invalid --etc-dir parameter." % arguments.etc_dir
        sys.exit(ExitStatus.INVALID_ETC_DIR)

    run_command(arguments, ["service", "apache2", "stop"])

    # Sets of system users/groups to delete will be collected (to avoid trying to delete the same user/group twice).
    users_to_delete = set()
    groups_to_delete = set()

    for configuration in get_all_configurations(arguments):
        users_to_delete.add(configuration.base.SYSTEM_USER_NAME)
        groups_to_delete.add(configuration.base.SYSTEM_GROUP_NAME)

        run_command(arguments, ["service", "critic-%s" % configuration.base.SYSTEM_IDENTITY, "stop"])
        run_command(arguments, ["rm", "-rf", configuration.paths.DATA_DIR, configuration.paths.LOG_DIR])
        run_command(arguments, ["rm", "-rf", configuration.paths.CACHE_DIR, configuration.paths.RUN_DIR])
        run_command(arguments, ["rm", "-rf", configuration.paths.INSTALL_DIR, configuration.paths.GIT_DIR])
        run_command(arguments, ["rm", "-f", "/etc/apache2/sites-available/critic-%s" % configuration.base.SYSTEM_IDENTITY])
        run_command(arguments, ["rm", "-f", "/etc/apache2/sites-enabled/critic-%s" % configuration.base.SYSTEM_IDENTITY])
        run_command(arguments, ["rm", "-f", "/etc/init.d/critic-%s" % configuration.base.SYSTEM_IDENTITY])
        run_command(arguments, ["update-rc.d", "critic-%s" % configuration.base.SYSTEM_IDENTITY, "remove"])

        # Typically the postgres user does not have access to the cwd during uninstall so we use "-i"
        # with sudo which makes the command run with the postgres user's homedir as cwd instead.
        # This avoids a harmless but pointless error message "could not change directory to X" when the
        # /usr/bin/psql perl script tries to chdir back to the previous cwd after doing some stuff.
        run_command(arguments, ["sudo", "-u", "postgres", "-i", "psql", "-v", "ON_ERROR_STOP=1", "-c", "DROP DATABASE IF EXISTS %s;" % configuration.database.PARAMETERS["database"]])
        run_command(arguments, ["sudo", "-u", "postgres", "-i", "psql", "-v", "ON_ERROR_STOP=1", "-c", "DROP ROLE IF EXISTS %s;" % configuration.database.PARAMETERS["user"]])

    for user in users_to_delete:
        run_command(arguments, ["deluser", "--system", user])

    for group in groups_to_delete:
        try:
            # Revoke push rights for all users that have been added to the Critic system group.
            # delgroup doesn't do this automatically and we want to avoid users gettings errors like:
            # "groups: cannot find name for group ID 132"
            for group_member in grp.getgrnam(group).gr_mem:
                subprocess.check_output(["gpasswd", "-d", group_member, group])
        except KeyError:
            abort_if_no_keep_going_param(arguments, "ERROR: Could not find group '%s'." % group)
        run_command(arguments, ["delgroup", "--system", group])

    # Delete non-instance specific parts.
    run_command(arguments, ["rm", "-rf", arguments.etc_dir, "/usr/bin/criticctl"])
    run_command(arguments, ["service", "apache2", "restart"])

    # When default paths are used in install.py we put some extra effort into
    # completely cleaning the system on uninstall, with custom paths it's
    # trickier to know if the user really wants to delete empty parent dirs.
    rmdir_if_empty(["/var/log/critic", "/var/run/critic", "/var/cache/critic"])

    run_command(arguments, ["rm", "-f", os.path.join(installation.root_dir, ".installed")])

    print
    print "SUCCESS: Uninstall complete."
    print

    return ExitStatus.EXIT_SUCCESS

if __name__ == "__main__":
    sys.exit(main())

########NEW FILE########
__FILENAME__ = upgrade
# -*- mode: python; encoding: utf-8 -*-
#
# Copyright 2012 Jens Lindstr√∂m, Opera Software ASA
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License.  You may obtain a copy of
# the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations under
# the License.

import os
import sys
import traceback
import subprocess

# To avoid accidentally creating files owned by root.
sys.dont_write_bytecode = True

# Python version check is done before imports below so
# that python 2.6/2.5 users can see the error message.
import pythonversion
pythonversion.check()

if sys.flags.optimize > 0:
    print """
ERROR: Please run this script without -O or -OO options.
"""
    sys.exit(1)

import argparse

sys.path.insert(0, os.path.join(os.getcwd(), "src"))

import installation

parser = argparse.ArgumentParser(description="Critic upgrade script")

# Uses default values for everything that has a default value (and isn't
# overridden by other command-line arguments) and signals an error for anything
# that doesn't have a default value and isn't set by a command-line argument.
parser.add_argument("--headless", help=argparse.SUPPRESS, action="store_true")

parser.add_argument("--etc-dir", default="/etc/critic", help="directory where the Critic system configuration is stored", action="store")
parser.add_argument("--identity", "-i", default="main", help="system identity to upgrade", action="store")
parser.add_argument("--dry-run", "-n", help="produce output but don't modify the system at all", action="store_true")

for module in installation.modules:
    if hasattr(module, "add_arguments"):
        module.add_arguments("upgrade", parser)

arguments = parser.parse_args()

if arguments.headless:
    installation.input.headless = True

if os.getuid() != 0:
    print """
ERROR: This script must be run as root.
"""
    sys.exit(1)

def abort():
    print
    print "ERROR: Upgrade aborted."
    print

    for module in reversed(installation.modules):
        try:
            if hasattr(module, "undo"):
                module.undo()
        except:
            print >>sys.stderr, "FAILED: %s.undo()" % module.__name__
            traceback.print_exc()

    if installation.initd.servicemanager_stopped and not installation.initd.start():
        print "WARNING: Undo failed to start Critic background services again..."
    if installation.apache.apache_stopped and not installation.apache.start():
        print "WARNING: Undo failed to start Apache again..."

    sys.exit(1)

data = installation.utils.read_install_data(arguments)

print """
Critic Upgrade
==============
"""

git = data["installation.prereqs.git"]

if "sha1" not in data:
    try:
        guess_sha1 = installation.utils.run_git([git, "rev-parse", "HEAD@{1}"],
                                                cwd=installation.root_dir).strip()
    except:
        guess_sha1 = None

    print """
The SHA-1 of the commit you initially installed was not recorded.  This
means you installed a version before the install.py script was changed
to record the SHA-1 currently checked out."""

    if guess_sha1:
        print """
A reasonable guess is HEAD@{1}, or "where HEAD was before the last
operation that changed HEAD".  Otherwise, please figure out what you
installed.  If you need to guess, guessing on something too old (i.e.
a commit that is an ancestor of the actual commit) is safer than
guessing on something too recent."""
        default = "HEAD@{1}"
    else:
        print """
Please figure out what you installed.  If you need to guess, guessing
on something too old (i.e.  a commit that is an ancestor of the actual
commit) is safer than guessing on something too recent."""
        default = None

    print """
The commit can be specified as a SHA-1 or any symbolic ref understood
by "git rev-parse".
"""

    def revparse(value):
        return installation.utils.run_git([git, "rev-parse", "--verify", value],
                                          cwd=installation.root_dir).strip()

    def valid_commit(value):
        try:
            sha1 = revparse(value)
        except subprocess.CalledProcessError:
            return "not a valid ref (checked with \"git rev-parse --verify\")"

        try:
            installation.utils.run_git([git, "cat-file", "commit", sha1],
                                       cwd=installation.root_dir)
        except subprocess.CalledProcessError:
            return "not a commit"

    sha1 = revparse(installation.input.string(prompt="What commit was originally installed?",
                                              default=default,
                                              check=valid_commit))

    data["sha1"] = sha1

old_critic_sha1 = data["sha1"]
new_critic_sha1 = installation.utils.run_git([git, "rev-parse", "HEAD"],
                                             cwd=installation.root_dir).strip()
print """
Previously installed version: %s
Will now upgrade to version:  %s
""" % (old_critic_sha1, new_critic_sha1)

if old_critic_sha1 == new_critic_sha1:
    print "Old and new commit are the same, nothing to do."
    sys.exit(0)

status_output = installation.utils.run_git([git, "status", "--porcelain"],
                                           cwd=installation.root_dir).strip()

if status_output:
    print """\
ERROR: This Git repository has local modifications."""

    if len(status_output.splitlines()) \
            and "installation/externals/v8-jsshell" in status_output:
        print """\
HINT: You might just need to run "git submodule update --recursive"."""

    print """
Installing from a Git repository with local changes is not supported.
Please commit or stash the changes and then try again.
"""
    sys.exit(1)

try:
    try:
        if not installation.prereqs.check("upgrade", arguments):
            abort()
    except KeyboardInterrupt:
        abort()
    except SystemExit:
        raise
    except:
        print >>sys.stderr, "FAILED: installation.prereqs.check()"
        traceback.print_exc()
        abort()

    for module in installation.modules:
        try:
            if hasattr(module, "prepare") and not module.prepare("upgrade", arguments, data):
                abort()
        except KeyboardInterrupt:
            abort()
        except SystemExit:
            raise
        except:
            print >>sys.stderr, "FAILED: %s.upgrade()" % module.__name__
            traceback.print_exc()
            abort()

    if not arguments.dry_run:
        if not installation.apache.stop():
            abort()
        if not installation.initd.stop():
            abort()

    for module in installation.modules:
        try:
            if hasattr(module, "upgrade") and not module.upgrade(arguments, data):
                abort()
        except KeyboardInterrupt:
            abort()
        except SystemExit:
            raise
        except:
            print >>sys.stderr, "FAILED: %s.upgrade()" % module.__name__
            traceback.print_exc()
            abort()

    import configuration

    if not arguments.dry_run:
        # Before bugfix "Fix recreation of /var/run/critic/IDENTITY after reboot"
        # it was possible that /var/run/critic/IDENTITY was accidentally
        # recreated owned by root:root instead of critic:critic (on reboot).
        # If this had happened the service manager restart that is done during
        # upgrade would fail so upgrades always failed. Further, it was not
        # possible to write a migration script for this because migrations
        # execute after the service manager restart. Because of this the
        # following 3 line workaround was necessary:

        if os.path.exists(configuration.paths.RUN_DIR):
            os.chown(configuration.paths.RUN_DIR, installation.system.uid, installation.system.gid)

        if not installation.initd.start():
            abort()
        if not installation.apache.start():
            abort()

    data["sha1"] = new_critic_sha1

    with installation.utils.as_critic_system_user():
        import dbaccess
        db = dbaccess.connect()
        cursor = db.cursor()
        cursor.execute("UPDATE systemidentities SET installed_sha1=%s, installed_at=NOW() WHERE name=%s", (new_critic_sha1, arguments.identity))
        if not arguments.dry_run:
            db.commit()

    for module in installation.modules:
        try:
            if hasattr(module, "finish"):
                module.finish("upgrade", arguments, data)
        except:
            print >>sys.stderr, "WARNING: %s.finish() failed" % module.__name__
            traceback.print_exc()

    installation.utils.write_install_data(arguments, data)
    installation.utils.clean_root_pyc_files()

    print
    print "SUCCESS: Upgrade complete!"
    print

    if configuration.extensions.ENABLED:
        try:
            installation.utils.run_git(
                [git, "diff", "--quiet",
                 "%s..%s" % (old_critic_sha1, new_critic_sha1),
                 "--", "installation/externals/v8-jsshell"])
        except subprocess.CalledProcessError:
            # Non-zero exit status means there were changes.
            print """
Updated v8-jsshell submodule
============================

The v8-jsshell program used to run extensions has been updated and needs to be
rebuilt.  If this is not done, the extensions mechanism may malfunction.  It can
be done manually later by running this command as root:

  python extend.py
"""

            rebuild_v8_jsshell = installation.input.yes_or_no(
                "Do you want to rebuild the v8-jsshell program now?",
                default=True)

            if rebuild_v8_jsshell:
                try:
                    subprocess.check_call([sys.executable, "extend.py"])
                except subprocess.CalledProcessError:
                    # We have already finished the main upgrade, so just
                    # propagate the exit status if extend.py failed.  It will
                    # have output enough error messages, for sure.
                    sys.exit(1)

except SystemExit:
    raise
except:
    traceback.print_exc()
    abort()

########NEW FILE########
