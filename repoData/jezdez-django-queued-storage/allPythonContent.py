__FILENAME__ = conf
# -*- coding: utf-8 -*-
#
# django-queued-storage documentation build configuration file, created by
# sphinx-quickstart on Sun Sep 18 19:10:44 2011.
#
# This file is execfile()d with the current directory set to its containing dir.
#
# Note that not all possible configuration values are present in this
# autogenerated file.
#
# All configuration values have a default; values that are commented out
# serve to show the default.

import sys, os

# If extensions (or modules to document with autodoc) are in another directory,
# add these directories to sys.path here. If the directory is relative to the
# documentation root, use os.path.abspath to make it absolute, like shown here.
sys.path.insert(0, os.path.abspath('..'))

os.environ['DJANGO_SETTINGS_MODULE'] = 'queued_storage.test_settings'

# -- General configuration -----------------------------------------------------

# If your documentation needs a minimal Sphinx version, state it here.
#needs_sphinx = '1.0'

# Add any Sphinx extension module names here, as strings. They can be extensions
# coming with Sphinx (named 'sphinx.ext.*') or your custom ones.
extensions = ['sphinx.ext.autodoc', 'sphinx.ext.intersphinx']

# Add any paths that contain templates here, relative to this directory.
templates_path = ['_templates']

# The suffix of source filenames.
source_suffix = '.rst'

# The encoding of source files.
#source_encoding = 'utf-8-sig'

# The master toctree document.
master_doc = 'index'

# General information about the project.
project = u'django-queued-storage'
copyright = u'2012-2013, Jannis Leidel and contributors'

# The version info for the project you're documenting, acts as replacement for
# |version| and |release|, also used in various other places throughout the
# built documents.
#
try:
    from queued_storage import __version__
    # The short X.Y version.
    version = '.'.join(__version__.split('.')[:2])
    # The full version, including alpha/beta/rc tags.
    release = __version__
except ImportError:
    version = release = 'dev'

# The language for content autogenerated by Sphinx. Refer to documentation
# for a list of supported languages.
#language = None

# There are two options for replacing |today|: either, you set today to some
# non-false value, then it is used:
#today = ''
# Else, today_fmt is used as the format for a strftime call.
#today_fmt = '%B %d, %Y'

# List of patterns, relative to source directory, that match files and
# directories to ignore when looking for source files.
exclude_patterns = ['_build']

# The reST default role (used for this markup: `text`) to use for all documents.
#default_role = None

# If true, '()' will be appended to :func: etc. cross-reference text.
#add_function_parentheses = True

# If true, the current module name will be prepended to all description
# unit titles (such as .. function::).
#add_module_names = True

# If true, sectionauthor and moduleauthor directives will be shown in the
# output. They are ignored by default.
#show_authors = False

# The name of the Pygments (syntax highlighting) style to use.
pygments_style = 'sphinx'

# A list of ignored prefixes for module index sorting.
#modindex_common_prefix = []


# -- Options for HTML output ---------------------------------------------------

# The theme to use for HTML and HTML Help pages.  See the documentation for
# a list of builtin themes.
html_theme = 'default'

# Theme options are theme-specific and customize the look and feel of a theme
# further.  For a list of options available for each theme, see the
# documentation.
#html_theme_options = {}

# Add any paths that contain custom themes here, relative to this directory.
#html_theme_path = []

# The name for this set of Sphinx documents.  If None, it defaults to
# "<project> v<release> documentation".
#html_title = None

# A shorter title for the navigation bar.  Default is the same as html_title.
#html_short_title = None

# The name of an image file (relative to this directory) to place at the top
# of the sidebar.
#html_logo = None

# The name of an image file (within the static path) to use as favicon of the
# docs.  This file should be a Windows icon file (.ico) being 16x16 or 32x32
# pixels large.
#html_favicon = None

# Add any paths that contain custom static files (such as style sheets) here,
# relative to this directory. They are copied after the builtin static files,
# so a file named "default.css" will overwrite the builtin "default.css".
#html_static_path = ['_static']

# If not '', a 'Last updated on:' timestamp is inserted at every page bottom,
# using the given strftime format.
#html_last_updated_fmt = '%b %d, %Y'

# If true, SmartyPants will be used to convert quotes and dashes to
# typographically correct entities.
#html_use_smartypants = True

# Custom sidebar templates, maps document names to template names.
#html_sidebars = {}

# Additional templates that should be rendered to pages, maps page names to
# template names.
#html_additional_pages = {}

# If false, no module index is generated.
#html_domain_indices = True

# If false, no index is generated.
#html_use_index = True

# If true, the index is split into individual pages for each letter.
#html_split_index = False

# If true, links to the reST sources are added to the pages.
#html_show_sourcelink = True

# If true, "Created using Sphinx" is shown in the HTML footer. Default is True.
#html_show_sphinx = True

# If true, "(C) Copyright ..." is shown in the HTML footer. Default is True.
#html_show_copyright = True

# If true, an OpenSearch description file will be output, and all pages will
# contain a <link> tag referring to it.  The value of this option must be the
# base URL from which the finished HTML is served.
#html_use_opensearch = ''

# This is the file name suffix for HTML files (e.g. ".xhtml").
#html_file_suffix = None

# Output file base name for HTML help builder.
htmlhelp_basename = 'django-queued-storagedoc'


# -- Options for LaTeX output --------------------------------------------------

# The paper size ('letter' or 'a4').
#latex_paper_size = 'letter'

# The font size ('10pt', '11pt' or '12pt').
#latex_font_size = '10pt'

# Grouping the document tree into LaTeX files. List of tuples
# (source start file, target name, title, author, documentclass [howto/manual]).
latex_documents = [
  ('index', 'django-queued-storage.tex', u'django-queued-storage Documentation',
   u'Jannis Leidel', 'manual'),
]

# The name of an image file (relative to this directory) to place at the top of
# the title page.
#latex_logo = None

# For "manual" documents, if this is true, then toplevel headings are parts,
# not chapters.
#latex_use_parts = False

# If true, show page references after internal links.
#latex_show_pagerefs = False

# If true, show URL addresses after external links.
#latex_show_urls = False

# Additional stuff for the LaTeX preamble.
#latex_preamble = ''

# Documents to append as an appendix to all manuals.
#latex_appendices = []

# If false, no module index is generated.
#latex_domain_indices = True


# -- Options for manual page output --------------------------------------------

# One entry per manual page. List of tuples
# (source start file, name, description, authors, manual section).
man_pages = [
    ('index', 'django-queued-storage', u'django-queued-storage Documentation',
     [u'Jannis Leidel'], 1)
]

# Example configuration for intersphinx: refer to the Python standard library.
intersphinx_mapping = {
    'python': ('http://python.readthedocs.org/en/v2.7.2/', None),
    'django': ('http://django.readthedocs.org/en/latest/', None),
    'celery': ('http://celery.readthedocs.org/en/latest/', None),
}

autodoc_member_order = 'bysource'

########NEW FILE########
__FILENAME__ = backends
import six

from django.core.cache import cache
from django.core.exceptions import ImproperlyConfigured
from django.utils.functional import SimpleLazyObject
from django.utils.http import urlquote

from queued_storage.conf import settings
from queued_storage.utils import import_attribute


class LazyBackend(SimpleLazyObject):

    def __init__(self, import_path, options):
        backend = import_attribute(import_path)
        super(LazyBackend, self).__init__(lambda: backend(**options))


class QueuedStorage(object):
    """
    Base class for queued storages. You can use this to specify your own
    backends.

    :param local: local storage class to transfer from
    :type local: str
    :param local_options: options of the local storage class
    :type local_options: dict
    :param remote: remote storage class to transfer to
    :type remote: str
    :param remote_options: options of the remote storage class
    :type remote_options: dict
    :param cache_prefix: prefix to use in the cache key
    :type cache_prefix: str
    :param delayed: whether the transfer task should be executed automatically
    :type delayed: bool
    :param task: Celery task to use for the transfer
    :type task: str
    """
    #: The local storage class to use. A dotted path (e.g.
    #: ``'django.core.files.storage.FileSystemStorage'``).
    local = None

    #: The options of the local storage class, defined as a dictionary.
    local_options = None

    #: The local storage class to use. A dotted path (e.g.
    #: ``'django.core.files.storage.FileSystemStorage'``).
    remote = None

    #: The options of the remote storage class, defined as a dictionary.
    remote_options = None

    #: The Celery task class to use to transfer files from the local
    #: to the remote storage. A dotted path (e.g.
    #: ``'queued_storage.tasks.Transfer'``).
    task = 'queued_storage.tasks.Transfer'

    #: If set to ``True`` the backend will *not* transfer files to the remote
    #: location automatically, but instead requires manual intervention by the
    #: user with the :meth:`~queued_storage.backends.QueuedStorage.transfer`
    #: method.
    #:
    delayed = False

    #: The cache key prefix to use when saving the which storage backend
    #: to use, local or remote (default see
    #: :attr:`~queued_storage.conf.settings.QUEUED_STORAGE_CACHE_PREFIX`)
    cache_prefix = settings.QUEUED_STORAGE_CACHE_PREFIX

    def __init__(self, local=None, remote=None,
                 local_options=None, remote_options=None,
                 cache_prefix=None, delayed=None, task=None):

        self.local_path = local or self.local
        self.local_options = local_options or self.local_options or {}
        self.local = self._load_backend(backend=self.local_path,
                                        options=self.local_options)

        self.remote_path = remote or self.remote
        self.remote_options = remote_options or self.remote_options or {}
        self.remote = self._load_backend(backend=self.remote_path,
                                         options=self.remote_options)

        self.task = self._load_backend(backend=task or self.task,
                                       handler=import_attribute)
        if delayed is not None:
            self.delayed = delayed
        if cache_prefix is not None:
            self.cache_prefix = cache_prefix

    def _load_backend(self, backend=None, options=None, handler=LazyBackend):
        if backend is None:  # pragma: no cover
            raise ImproperlyConfigured("The QueuedStorage class '%s' "
                                       "doesn't define a needed backend." %
                                       (self, backend))
        if not isinstance(backend, six.string_types):
            raise ImproperlyConfigured("The QueuedStorage class '%s' "
                                       "requires its backends to be "
                                       "specified as dotted import paths "
                                       "not instances or classes" % self)
        return handler(backend, options)

    def get_storage(self, name):
        """
        Returns the storage backend instance responsible for the file
        with the given name (either local or remote). This method is
        used in most of the storage API methods.

        :param name: file name
        :type name: str
        :rtype: :class:`~django:django.core.files.storage.Storage`
        """
        cache_result = cache.get(self.get_cache_key(name))
        if cache_result:
            return self.remote
        elif cache_result is None and self.remote.exists(name):
            cache.set(self.get_cache_key(name), True)
            return self.remote
        else:
            return self.local

    def get_cache_key(self, name):
        """
        Returns the cache key for the given file name.

        :param name: file name
        :type name: str
        :rtype: str
        """
        return '%s_%s' % (self.cache_prefix, urlquote(name))

    def using_local(self, name):
        """
        Determines for the file with the given name whether
        the local storage is current used.

        :param name: file name
        :type name: str
        :rtype: bool
        """
        return self.get_storage(name) is self.local

    def using_remote(self, name):
        """
        Determines for the file with the given name whether
        the remote storage is current used.

        :param name: file name
        :type name: str
        :rtype: bool
        """
        return self.get_storage(name) is self.remote

    def open(self, name, mode='rb'):
        """
        Retrieves the specified file from storage.

        :param name: file name
        :type name: str
        :param mode: mode to open the file with
        :type mode: str
        :rtype: :class:`~django:django.core.files.File`
        """
        return self.get_storage(name).open(name, mode)

    def save(self, name, content):
        """
        Saves the given content with the given name using the local
        storage. If the :attr:`~queued_storage.backends.QueuedStorage.delayed`
        attribute is ``True`` this will automatically call the
        :meth:`~queued_storage.backends.QueuedStorage.transfer` method
        queuing the transfer from local to remote storage.

        :param name: file name
        :type name: str
        :param content: content of the file specified by name
        :type content: :class:`~django:django.core.files.File`
        :rtype: str
        """
        cache_key = self.get_cache_key(name)
        cache.set(cache_key, False)
        name = self.local.save(name, content)

        # Pass on the cache key to prevent duplicate cache key creation,
        # we save the result in the storage to be able to test for it
        if not self.delayed:
            self.result = self.transfer(name, cache_key=cache_key)
        return name

    def transfer(self, name, cache_key=None):
        """
        Transfers the file with the given name to the remote storage
        backend by queuing the task.

        :param name: file name
        :type name: str
        :param cache_key: the cache key to set after a successful task run
        :type cache_key: str
        :rtype: task result
        """
        if cache_key is None:
            cache_key = self.get_cache_key(name)
        return self.task.delay(name, cache_key,
                               self.local_path, self.remote_path,
                               self.local_options, self.remote_options)

    def get_valid_name(self, name):
        """
        Returns a filename, based on the provided filename, that's suitable
        for use in the current storage system.

        :param name: file name
        :type name: str
        :rtype: str
        """
        return self.get_storage(name).get_valid_name(name)

    def get_available_name(self, name):
        """
        Returns a filename that's free on the current storage system, and
        available for new content to be written to.

        :param name: file name
        :type name: str
        :rtype: str
        """
        return self.get_storage(name).get_available_name(name)

    def path(self, name):
        """
        Returns a local filesystem path where the file can be retrieved using
        Python's built-in open() function. Storage systems that can't be
        accessed using open() should *not* implement this method.

        :param name: file name
        :type name: str
        :rtype: str
        """
        return self.get_storage(name).path(name)

    def delete(self, name):
        """
        Deletes the specified file from the storage system.

        :param name: file name
        :type name: str
        """
        return self.get_storage(name).delete(name)

    def exists(self, name):
        """
        Returns ``True`` if a file referened by the given name already exists
        in the storage system, or False if the name is available for a new
        file.

        :param name: file name
        :type name: str
        :rtype: bool
        """
        return self.get_storage(name).exists(name)

    def listdir(self, name):
        """
        Lists the contents of the specified path, returning a 2-tuple of lists;
        the first item being directories, the second item being files.

        :param name: file name
        :type name: str
        :rtype: tuple
        """
        return self.get_storage(name).listdir(name)

    def size(self, name):
        """
        Returns the total size, in bytes, of the file specified by name.

        :param name: file name
        :type name: str
        :rtype: int
        """
        return self.get_storage(name).size(name)

    def url(self, name):
        """
        Returns an absolute URL where the file's contents can be accessed
        directly by a Web browser.

        :param name: file name
        :type name: str
        :rtype: str
        """
        return self.get_storage(name).url(name)

    def accessed_time(self, name):
        """
        Returns the last accessed time (as datetime object) of the file
        specified by name.

        :param name: file name
        :type name: str
        :rtype: :class:`~python:datetime.datetime`
        """
        return self.get_storage(name).accessed_time(name)

    def created_time(self, name):
        """
        Returns the creation time (as datetime object) of the file
        specified by name.

        :param name: file name
        :type name: str
        :rtype: :class:`~python:datetime.datetime`
        """
        return self.get_storage(name).created_time(name)

    def modified_time(self, name):
        """
        Returns the last modified time (as datetime object) of the file
        specified by name.

        :param name: file name
        :type name: str
        :rtype: :class:`~python:datetime.datetime`
        """
        return self.get_storage(name).modified_time(name)


class QueuedFileSystemStorage(QueuedStorage):
    """
    A :class:`~queued_storage.backends.QueuedStorage` subclass which
    conveniently uses
    :class:`~django:django.core.files.storage.FileSystemStorage` as the local
    storage.
    """
    def __init__(self, local='django.core.files.storage.FileSystemStorage', *args, **kwargs):
        super(QueuedFileSystemStorage, self).__init__(local=local, *args, **kwargs)


class QueuedS3BotoStorage(QueuedFileSystemStorage):
    """
    A custom :class:`~queued_storage.backends.QueuedFileSystemStorage`
    subclass which uses the ``S3BotoStorage`` storage of the
    `django-storages <http://django-storages.readthedocs.org/>`_ app as
    the remote storage.
    """
    def __init__(self, remote='storages.backends.s3boto.S3BotoStorage', *args, **kwargs):
        super(QueuedS3BotoStorage, self).__init__(remote=remote, *args, **kwargs)


class QueuedCouchDBStorage(QueuedFileSystemStorage):
    """
    A custom :class:`~queued_storage.backends.QueuedFileSystemStorage`
    subclass which uses the ``CouchDBStorage`` storage of the
    `django-storages <http://django-storages.readthedocs.org/>`_ app as
    the remote storage.
    """
    def __init__(self, remote='storages.backends.couchdb.CouchDBStorage', *args, **kwargs):
        super(QueuedCouchDBStorage, self).__init__(remote=remote, *args, **kwargs)


class QueuedDatabaseStorage(QueuedFileSystemStorage):
    """
    A custom :class:`~queued_storage.backends.QueuedFileSystemStorage`
    subclass which uses the ``DatabaseStorage`` storage of the
    `django-storages <http://django-storages.readthedocs.org/>`_ app as
    the remote storage.
    """
    def __init__(self, remote='storages.backends.database.DatabaseStorage', *args, **kwargs):
        super(QueuedDatabaseStorage, self).__init__(remote=remote, *args, **kwargs)


class QueuedFTPStorage(QueuedFileSystemStorage):
    """
    A custom :class:`~queued_storage.backends.QueuedFileSystemStorage`
    subclass which uses the ``FTPStorage`` storage of the
    `django-storages <http://django-storages.readthedocs.org/>`_ app as
    the remote storage.
    """
    def __init__(self, remote='storages.backends.ftp.FTPStorage', *args, **kwargs):
        super(QueuedFTPStorage, self).__init__(remote=remote, *args, **kwargs)


class QueuedMogileFSStorage(QueuedFileSystemStorage):
    """
    A custom :class:`~queued_storage.backends.QueuedFileSystemStorage`
    subclass which uses the ``MogileFSStorage`` storage of the
    `django-storages <http://django-storages.readthedocs.org/>`_ app as
    the remote storage.
    """
    def __init__(self, remote='storages.backends.mogile.MogileFSStorage', *args, **kwargs):
        super(QueuedMogileFSStorage, self).__init__(remote=remote, *args, **kwargs)


class QueuedGridFSStorage(QueuedFileSystemStorage):
    """
    A custom :class:`~queued_storage.backends.QueuedFileSystemStorage`
    subclass which uses the ``GridFSStorage`` storage of the
    `django-storages <http://django-storages.readthedocs.org/>`_ app as
    the remote storage.
    """
    def __init__(self, remote='storages.backends.mongodb.GridFSStorage', *args, **kwargs):
        super(QueuedGridFSStorage, self).__init__(remote=remote, *args, **kwargs)


class QueuedCloudFilesStorage(QueuedFileSystemStorage):
    """
    A custom :class:`~queued_storage.backends.QueuedFileSystemStorage`
    subclass which uses the ``CloudFilesStorage`` storage of the
    `django-storages <http://django-storages.readthedocs.org/>`_ app as
    the remote storage.
    """
    def __init__(self, remote='storages.backends.mosso.CloudFilesStorage', *args, **kwargs):
        super(QueuedCloudFilesStorage, self).__init__(remote=remote, *args, **kwargs)


class QueuedSFTPStorage(QueuedFileSystemStorage):
    """
    A custom :class:`~queued_storage.backends.QueuedFileSystemStorage`
    subclass which uses the ``SFTPStorage`` storage of the
    `django-storages <http://django-storages.readthedocs.org/>`_ app as
    the remote storage.
    """
    def __init__(self, remote='storages.backends.sftpstorage.SFTPStorage', *args, **kwargs):
        super(QueuedSFTPStorage, self).__init__(remote=remote, *args, **kwargs)

########NEW FILE########
__FILENAME__ = conf
from django.conf import settings  # noqa

from appconf import AppConf


class QueuedStorageConf(AppConf):
    RETRIES = 5
    RETRY_DELAY = 60
    CACHE_PREFIX = 'queued_storage'

########NEW FILE########
__FILENAME__ = fields
from django.db.models.fields.files import FileField, FieldFile


class QueuedFieldFile(FieldFile):
    """
    A custom :class:`~django.db.models.fields.files.FieldFile` which has an
    additional method to transfer the file to the remote storage using the
    backend's ``transfer`` method.
    """
    def transfer(self):
        """
        Transfers the file using the storage backend.
        """
        return self.storage.transfer(self.name)


class QueuedFileField(FileField):
    """
    Field to be used together with
    :class:`~queued_storage.backends.QueuedStorage` instances or instances
    of subclasses.

    Tiny wrapper around :class:`~django:django.db.models.FileField`,
    which provides a convenient method to transfer files, using the
    :meth:`~queued_storage.fields.QueuedFieldFile.transfer` method, e.g.:

    .. code-block:: python

        from queued_storage.backends import QueuedS3BotoStorage
        from queued_storage.fields import QueuedFileField

        class MyModel(models.Model):
            image = QueuedFileField(storage=QueuedS3BotoStorage(delayed=True))

        my_obj = MyModel(image=File(open('image.png')))
        # Save locally:
        my_obj.save()
        # Transfer to remote location:
        my_obj.image.transfer()
    """
    attr_class = QueuedFieldFile

########NEW FILE########
__FILENAME__ = models
# This file intentionally left empty (needs to be present for test detection).

########NEW FILE########
__FILENAME__ = signals
"""
django-queued-storage ships with a signal fired after a file was transfered
by the Transfer task. It provides the name of the file, the local and the
remote storage backend instances as arguments to connected signal callbacks.

Imagine you'd want to post-process the file that has been transfered from
the local to the remote storage, e.g. add it to a log model to always know
what exactly happened. All you'd have to do is to connect a callback to
the ``file_transferred`` signal::

    from django.dispatch import receiver
    from django.utils.timezone import now

    from queued_storage.signals import file_transferred

    from mysite.transferlog.models import TransferLogEntry


    @receiver(file_transferred)
    def log_file_transferred(sender, name, local, remote, **kwargs):
        remote_url = remote.url(name)
        TransferLogEntry.objects.create(name=name, remote_url=remote_url, transfer_date=now())

    # Alternatively, you can also use the signal's connect method to connect:
    file_transferred.connect(log_file_transferred)

Note that this signal does **NOT** have access to the calling Model or even
the FileField instance that it relates to, only the name of the file.
As a result, this signal is somewhat limited and may only be of use if you
have a very specific usage of django-queued-storage.
"""
from django.dispatch import Signal

file_transferred = Signal(providing_args=["name", "local", "remote"])

########NEW FILE########
__FILENAME__ = tasks
from django.core.cache import cache

from celery.task import Task
try:
    from celery.utils.log import get_task_logger
except ImportError:
    from celery.log import get_task_logger


from queued_storage.conf import settings
from queued_storage.signals import file_transferred
from queued_storage.utils import import_attribute

logger = get_task_logger(name=__name__)


class Transfer(Task):
    """
    The default task. Transfers a file to a remote location.
    The actual transfer is implemented in the remote backend.

    To use a different task, pass it into the backend:

    .. code-block:: python

        from queued_storage.backends import QueuedS3BotoStorage

        s3_delete_storage = QueuedS3BotoStorage(
            task='queued_storage.tasks.TransferAndDelete')

        # later, in model definition:
        image = models.ImageField(storage=s3_delete_storage)


    The result should be ``True`` if the transfer was successful,
    or ``False`` if unsuccessful. In the latter case the task will be
    retried.

    You can subclass the :class:`~queued_storage.tasks.Transfer` class
    to customize the behaviour, to do something like this:

    .. code-block:: python

        from queued_storage.tasks import Transfer

        class TransferAndNotify(Transfer):
            def transfer(self, *args, **kwargs):
                result = super(TransferAndNotify, self).transfer(*args, **kwargs)
                if result:
                    # call the (imaginary) notify function with the result
                    notify(result)
                return result

    """
    #: The number of retries if unsuccessful (default: see
    #: :attr:`~queued_storage.conf.settings.QUEUED_STORAGE_RETRIES`)
    max_retries = settings.QUEUED_STORAGE_RETRIES

    #: The delay between each retry in seconds (default: see
    #: :attr:`~queued_storage.conf.settings.QUEUED_STORAGE_RETRY_DELAY`)
    default_retry_delay = settings.QUEUED_STORAGE_RETRY_DELAY

    def run(self, name, cache_key,
            local_path, remote_path,
            local_options, remote_options, **kwargs):
        """
        The main work horse of the transfer task. Calls the transfer
        method with the local and remote storage backends as given
        with the parameters.

        :param name: name of the file to transfer
        :type name: str
        :param local_path: local storage class to transfer from
        :type local_path: str
        :param local_options: options of the local storage class
        :type local_options: dict
        :param remote_path: remote storage class to transfer to
        :type remote_path: str
        :param remote_options: options of the remote storage class
        :type remote_options: dict
        :param cache_key: cache key to set after a successful transfer
        :type cache_key: str
        :rtype: task result
        """
        local = import_attribute(local_path)(**local_options)
        remote = import_attribute(remote_path)(**remote_options)
        result = self.transfer(name, local, remote, **kwargs)

        if result is True:
            cache.set(cache_key, True)
            file_transferred.send(sender=self.__class__,
                                  name=name, local=local, remote=remote)
        elif result is False:
            args = [name, cache_key, local_path,
                    remote_path, local_options, remote_options]
            self.retry(args=args, kwargs=kwargs)
        else:
            raise ValueError("Task '%s' did not return True/False but %s" %
                             (self.__class__, result))
        return result

    def transfer(self, name, local, remote, **kwargs):
        """
        Transfers the file with the given name from the local to the remote
        storage backend.

        :param name: The name of the file to transfer
        :param local: The local storage backend instance
        :param remote: The remote storage backend instance
        :returns: `True` when the transfer succeeded, `False` if not. Retries
                  the task when returning `False`
        :rtype: bool
        """
        try:
            remote.save(name, local.open(name))
            return True
        except Exception as e:
            logger.error("Unable to save '%s' to remote storage. "
                         "About to retry." % name)
            logger.exception(e)
            return False


class TransferAndDelete(Transfer):
    """
    A :class:`~queued_storage.tasks.Transfer` subclass which deletes the
    file with the given name using the local storage if the transfer
    was successful.
    """
    def transfer(self, name, local, remote, **kwargs):
        result = super(TransferAndDelete, self).transfer(name, local,
                                                         remote, **kwargs)
        if result:
            local.delete(name)
        return result

########NEW FILE########
__FILENAME__ = celeryconfig
BROKER_TRANSPORT = "memory"
CELERY_IGNORE_RESULT = True
CELERYD_LOG_LEVEL = "DEBUG"
CELERY_DEFAULT_QUEUE = "queued_storage"
CELERY_RESULT_BACKEND = "database"
CELERY_RESULT_DBURI = "sqlite://"

CELERY_ALWAYS_EAGER = True
CELERY_IGNORE_RESULT = True
CELERY_IMPORTS = [
    'queued_storage.tasks',
]

########NEW FILE########
__FILENAME__ = models
from django.db import models

from queued_storage.fields import QueuedFileField


class TestModel(models.Model):
    testfile = models.FileField(upload_to='test', null=True)
    remote = QueuedFileField(upload_to='test', null=True)

    retried = False

########NEW FILE########
__FILENAME__ = tasks
from queued_storage.tasks import Transfer
from queued_storage.utils import import_attribute

from .models import TestModel


def test_task(name, cache_key,
              local_path, remote_path,
              local_options, remote_options):
    local = import_attribute(local_path)(**local_options)
    remote = import_attribute(remote_path)(**remote_options)
    remote.save(name, local.open(name))


def delay(*args, **kwargs):
    test_task(*args, **kwargs)

test_task.delay = delay


class NoneReturningTask(Transfer):
    def transfer(self, *args, **kwargs):
        return None


class RetryingTask(Transfer):
    def transfer(self, *args, **kwargs):
        if TestModel.retried:
            return True
        else:
            TestModel.retried = True
            return False

########NEW FILE########
__FILENAME__ = tests
"""
For simplicity and to avoid requiring a paid-for account on some cloud
storage system testing is conducted against two local storage backends. Since
the QueuedStorage backend is truly agnostic about the local and remote
storage systems, this should work as transparently as using one (or even two!)
remote storage systems.
"""
import os
import shutil
import tempfile
from os import path
from datetime import datetime

from django.core.files.base import File
from django.core.files.storage import FileSystemStorage, Storage
from django.test import TestCase

from queued_storage.backends import QueuedStorage
from queued_storage.conf import settings

from . import models


class StorageTests(TestCase):

    def setUp(self):
        self.old_celery_always_eager = getattr(
            settings, 'CELERY_ALWAYS_EAGER', False)
        settings.CELERY_ALWAYS_EAGER = True
        self.local_dir = tempfile.mkdtemp()
        self.remote_dir = tempfile.mkdtemp()
        tmp_dir = tempfile.mkdtemp()
        self.test_file_name = 'queued_storage.txt'
        self.test_file_path = path.join(tmp_dir, self.test_file_name)
        with open(self.test_file_path, 'a') as test_file:
            test_file.write('test')
        self.test_file = open(self.test_file_path, 'r')
        self.addCleanup(shutil.rmtree, self.local_dir)
        self.addCleanup(shutil.rmtree, self.remote_dir)
        self.addCleanup(shutil.rmtree, tmp_dir)

    def tearDown(self):
        settings.CELERY_ALWAYS_EAGER = self.old_celery_always_eager

    def test_storage_init(self):
        """
        Make sure that creating a QueuedStorage object works
        """
        storage = QueuedStorage(
            'django.core.files.storage.FileSystemStorage',
            'django.core.files.storage.FileSystemStorage')
        self.assertIsInstance(storage, QueuedStorage)
        self.assertEqual(FileSystemStorage, storage.local.__class__)
        self.assertEqual(FileSystemStorage, storage.remote.__class__)

    def test_storage_cache_key(self):
        storage = QueuedStorage(
            'django.core.files.storage.FileSystemStorage',
            'django.core.files.storage.FileSystemStorage',
            cache_prefix='test_cache_key')
        self.assertEqual(storage.cache_prefix, 'test_cache_key')

    def test_storage_methods(self):
        """
        Make sure that QueuedStorage implements all the methods
        """
        storage = QueuedStorage(
            'django.core.files.storage.FileSystemStorage',
            'django.core.files.storage.FileSystemStorage')

        file_storage = Storage()

        for attr in dir(file_storage):
            method = getattr(file_storage, attr)

            if not callable(method):
                continue

            method = getattr(storage, attr, False)
            self.assertTrue(callable(method),
                            "QueuedStorage has no method '%s'" % attr)

    def test_storage_simple_save(self):
        """
        Make sure that saving to remote locations actually works
        """
        storage = QueuedStorage(
            local='django.core.files.storage.FileSystemStorage',
            remote='django.core.files.storage.FileSystemStorage',
            local_options=dict(location=self.local_dir),
            remote_options=dict(location=self.remote_dir),
            task='queued_storage.tests.tasks.test_task')

        field = models.TestModel._meta.get_field('testfile')
        field.storage = storage

        obj = models.TestModel(testfile=File(self.test_file))
        obj.save()

        self.assertTrue(path.isfile(path.join(self.local_dir, obj.testfile.name)))
        self.assertTrue(path.isfile(path.join(self.remote_dir, obj.testfile.name)))

    def test_storage_celery_save(self):
        """
        Make sure it actually works when using Celery as a task queue
        """
        storage = QueuedStorage(
            local='django.core.files.storage.FileSystemStorage',
            remote='django.core.files.storage.FileSystemStorage',
            local_options=dict(location=self.local_dir),
            remote_options=dict(location=self.remote_dir))

        field = models.TestModel._meta.get_field('testfile')
        field.storage = storage

        obj = models.TestModel(testfile=File(self.test_file))
        obj.save()

        self.assertTrue(obj.testfile.storage.result.get())
        self.assertTrue(path.isfile(path.join(self.local_dir, obj.testfile.name)))
        self.assertTrue(
            path.isfile(path.join(self.remote_dir, obj.testfile.name)),
            "Remote file is not available.")
        self.assertFalse(storage.using_local(obj.testfile.name))
        self.assertTrue(storage.using_remote(obj.testfile.name))

        self.assertEqual(self.test_file_name,
                         storage.get_valid_name(self.test_file_name))
        self.assertEqual(self.test_file_name,
                         storage.get_available_name(self.test_file_name))

        subdir_path = os.path.join('test', self.test_file_name)
        self.assertTrue(storage.exists(subdir_path))
        self.assertEqual(storage.path(self.test_file_name),
                         path.join(self.local_dir, self.test_file_name))
        self.assertEqual(storage.listdir('test')[1], [self.test_file_name])
        self.assertEqual(storage.size(subdir_path),
                         os.stat(self.test_file_path).st_size)
        self.assertEqual(storage.url(self.test_file_name), self.test_file_name)
        self.assertIsInstance(storage.accessed_time(subdir_path), datetime)
        self.assertIsInstance(storage.created_time(subdir_path), datetime)
        self.assertIsInstance(storage.modified_time(subdir_path), datetime)

        subdir_name = 'queued_storage_2.txt'
        testfile = storage.open(subdir_name, 'w')
        try:
            testfile.write('test')
        finally:
            testfile.close()
        self.assertTrue(storage.exists(subdir_name))
        storage.delete(subdir_name)
        self.assertFalse(storage.exists(subdir_name))

    def test_transfer_and_delete(self):
        """
        Make sure the TransferAndDelete task does what it says
        """
        storage = QueuedStorage(
            local='django.core.files.storage.FileSystemStorage',
            remote='django.core.files.storage.FileSystemStorage',
            local_options=dict(location=self.local_dir),
            remote_options=dict(location=self.remote_dir),
            task='queued_storage.tasks.TransferAndDelete')

        field = models.TestModel._meta.get_field('testfile')
        field.storage = storage

        obj = models.TestModel(testfile=File(self.test_file))
        obj.save()

        obj.testfile.storage.result.get()

        self.assertFalse(
            path.isfile(path.join(self.local_dir, obj.testfile.name)),
            "Local file is still available")
        self.assertTrue(
            path.isfile(path.join(self.remote_dir, obj.testfile.name)),
            "Remote file is not available.")

    def test_transfer_returns_boolean(self):
        """
        Make sure an exception is thrown when the transfer task does not return
        a boolean. We don't want to confuse Celery.
        """
        storage = QueuedStorage(
            local='django.core.files.storage.FileSystemStorage',
            remote='django.core.files.storage.FileSystemStorage',
            local_options=dict(location=self.local_dir),
            remote_options=dict(location=self.remote_dir),
            task='queued_storage.tests.tasks.NoneReturningTask')

        field = models.TestModel._meta.get_field('testfile')
        field.storage = storage

        obj = models.TestModel(testfile=File(self.test_file))
        obj.save()

        self.assertRaises(ValueError,
                          obj.testfile.storage.result.get, propagate=True)

    def test_transfer_retried(self):
        """
        Make sure the transfer task is retried correctly.
        """
        storage = QueuedStorage(
            local='django.core.files.storage.FileSystemStorage',
            remote='django.core.files.storage.FileSystemStorage',
            local_options=dict(location=self.local_dir),
            remote_options=dict(location=self.remote_dir),
            task='queued_storage.tests.tasks.RetryingTask')
        field = models.TestModel._meta.get_field('testfile')
        field.storage = storage

        self.assertFalse(models.TestModel.retried)

        obj = models.TestModel(testfile=File(self.test_file))
        obj.save()

        self.assertFalse(obj.testfile.storage.result.get())
        self.assertTrue(models.TestModel.retried)

    def test_delayed_storage(self):
        storage = QueuedStorage(
            local='django.core.files.storage.FileSystemStorage',
            remote='django.core.files.storage.FileSystemStorage',
            local_options=dict(location=self.local_dir),
            remote_options=dict(location=self.remote_dir),
            delayed=True)

        field = models.TestModel._meta.get_field('testfile')
        field.storage = storage

        obj = models.TestModel(testfile=File(self.test_file))
        obj.save()

        self.assertIsNone(getattr(obj.testfile.storage, 'result', None))

        self.assertFalse(
            path.isfile(path.join(self.remote_dir, obj.testfile.name)),
            "Remote file should not be transferred automatically.")

        result = obj.testfile.storage.transfer(obj.testfile.name)
        result.get()

        self.assertTrue(
            path.isfile(path.join(self.remote_dir, obj.testfile.name)),
            "Remote file is not available.")

    def test_remote_file_field(self):
        storage = QueuedStorage(
            local='django.core.files.storage.FileSystemStorage',
            remote='django.core.files.storage.FileSystemStorage',
            local_options=dict(location=self.local_dir),
            remote_options=dict(location=self.remote_dir),
            delayed=True)

        field = models.TestModel._meta.get_field('remote')
        field.storage = storage

        obj = models.TestModel(remote=File(self.test_file))
        obj.save()

        self.assertIsNone(getattr(obj.testfile.storage, 'result', None))

        result = obj.remote.transfer()
        self.assertTrue(result)
        self.assertTrue(path.isfile(path.join(self.remote_dir,
                                              obj.remote.name)))

########NEW FILE########
__FILENAME__ = test_settings
SITE_ID = 1

DATABASES = {
    'default': {
        'ENGINE': 'django.db.backends.sqlite3',
        'NAME': ':memory:',
    }
}

INSTALLED_APPS = [
    'queued_storage',
    'queued_storage.tests',
]

TEST_RUNNER = 'discover_runner.DiscoverRunner'

SECRET_KEY = 'top_secret'

########NEW FILE########
__FILENAME__ = utils
from django.core.exceptions import ImproperlyConfigured
from django.utils.importlib import import_module


def import_attribute(import_path=None, options=None):
    if import_path is None:
        raise ImproperlyConfigured("No import path was given.")
    try:
        dot = import_path.rindex('.')
    except ValueError:
        raise ImproperlyConfigured("%s isn't a module." % import_path)
    module, classname = import_path[:dot], import_path[dot + 1:]
    try:
        mod = import_module(module)
    except ImportError as e:
        raise ImproperlyConfigured('Error importing module %s: "%s"' %
                                   (module, e))
    try:
        return getattr(mod, classname)
    except AttributeError:
        raise ImproperlyConfigured(
            'Module "%s" does not define a "%s" class.' % (module, classname))

########NEW FILE########
