__FILENAME__ = conf
# -*- coding: utf-8 -*-
#
# This file is execfile()d with the current directory set to its containing dir.
#
# The contents of this file are pickled, so don't put values in the namespace
# that aren't pickleable (module imports are okay, they're removed automatically).
#
# Note that not all possible configuration values are present in this
# autogenerated file.
#
# All configuration values have a default; values that are commented out
# serve to show the default.

from mahotas import __version__ as mahotas_version

extensions = [
        'sphinx.ext.autodoc',
        'sphinx.ext.pngmath',
        'sphinx.ext.intersphinx',
        'sphinx.ext.coverage',
        'sphinx.ext.doctest',
        'numpydoc',
        'matplotlib.sphinxext.only_directives',
        'matplotlib.sphinxext.plot_directive',
        ]


# General configuration
# ---------------------

# Add any paths that contain templates here, relative to this directory.
templates_path = ['_templates']

# The suffix of source filenames.
source_suffix = '.rst'

# The encoding of source files.
source_encoding = 'utf-8'

# The master toctree document.
master_doc = 'index'

# General information about the project.
project = u'mahotas'
copyright = u'2008-2013, Luis Pedro Coelho'

# The version info for the project you're documenting, acts as replacement for
# |version| and |release|, also used in various other places throughout the
# built documents.
#
# The short X.Y version.
version = mahotas_version[:3]
# The full version, including alpha/beta/rc tags.
release = mahotas_version

# The language for content autogenerated by Sphinx. Refer to documentation
# for a list of supported languages.
language = 'en'

# There are two options for replacing |today|: either, you set today to some
# non-false value, then it is used:
#today = ''
# Else, today_fmt is used as the format for a strftime call.
#today_fmt = '%B %d, %Y'

# List of documents that shouldn't be included in the build.
#unused_docs = []

# List of directories, relative to source directory, that shouldn't be searched
# for source files.
exclude_trees = []

# The reST default role (used for this markup: `text`) to use for all documents.
#default_role = None

# If true, '()' will be appended to :func: etc. cross-reference text.
#add_function_parentheses = True

# If true, the current module name will be prepended to all description
# unit titles (such as .. function::).
#add_module_names = True

# If true, sectionauthor and moduleauthor directives will be shown in the
# output. They are ignored by default.
#show_authors = False

# The name of the Pygments (syntax highlighting) style to use.
pygments_style = 'sphinx'


# Options for HTML output
# -----------------------

# The style sheet to use for HTML and HTML Help pages. A file of that name
# must exist either in Sphinx' static/ path, or in one of the custom paths
# given in html_static_path.
#html_style = 'default.css'
html_theme = 'nature'

# The name for this set of Sphinx documents.  If None, it defaults to
# "<project> v<release> documentation".
#html_title = None

# A shorter title for the navigation bar.  Default is the same as html_title.
#html_short_title = None

# The name of an image file (relative to this directory) to place at the top
# of the sidebar.
#html_logo = None

# The name of an image file (within the static path) to use as favicon of the
# docs.  This file should be a Windows icon file (.ico) being 16x16 or 32x32
# pixels large.
#html_favicon = None

# Add any paths that contain custom static files (such as style sheets) here,
# relative to this directory. They are copied after the builtin static files,
# so a file named "default.css" will overwrite the builtin "default.css".
html_static_path = ['_static']

# If not '', a 'Last updated on:' timestamp is inserted at every page bottom,
# using the given strftime format.
#html_last_updated_fmt = '%b %d, %Y'

# If true, SmartyPants will be used to convert quotes and dashes to
# typographically correct entities.
#html_use_smartypants = True

# Custom sidebar templates, maps document names to template names.
html_sidebars = {
    '*': ['searchbox.html', 'sidebar.html'],
}

# Additional templates that should be rendered to pages, maps page names to
# template names.
#html_additional_pages = {}

# If false, no module index is generated.
#html_use_modindex = True

# If false, no index is generated.
#html_use_index = True

# If true, the index is split into individual pages for each letter.
#html_split_index = False

# If true, the reST sources are included in the HTML build as _sources/<name>.
#html_copy_source = True

# If true, an OpenSearch description file will be output, and all pages will
# contain a <link> tag referring to it.  The value of this option must be the
# base URL from which the finished HTML is served.
#html_use_opensearch = ''

# If nonempty, this is the file name suffix for HTML files (e.g. ".xhtml").
#html_file_suffix = ''

# Output file base name for HTML help builder.
htmlhelp_basename = 'mahotasdoc'


# Options for plot output
# -----------------------
plot_include_source = True
 
# Options for LaTeX output
# ------------------------

# The paper size ('letter' or 'a4').
#latex_paper_size = 'letter'

# The font size ('10pt', '11pt' or '12pt').
#latex_font_size = '10pt'

# Grouping the document tree into LaTeX files. List of tuples
# (source start file, target name, title, author, document class [howto/manual]).
latex_documents = [
  ('index', 'mahotas.tex', ur'mahotas Documentation',
   ur'Luis Pedro Coelho', 'manual'),
]

# The name of an image file (relative to this directory) to place at the top of
# the title page.
#latex_logo = None

# For "manual" documents, if this is true, then toplevel headings are parts,
# not chapters.
#latex_use_parts = False

# Additional stuff for the LaTeX preamble.
#latex_preamble = ''

# Documents to append as an appendix to all manuals.
#latex_appendices = []

# If false, no module index is generated.
#latex_use_modindex = True

########NEW FILE########
__FILENAME__ = distance
import numpy as np
import mahotas
from pylab import imshow, savefig
A = np.zeros((100,100), bool)
A[40:60] = 1
W = mahotas.thin(A)
D = mahotas.distance(~W)
imshow(D)
savefig('distance.png')


########NEW FILE########
__FILENAME__ = bbox
# Copyright (C) 2008-2013, Luis Pedro Coelho <luis@luispedro.org>
# vim: set ts=4 sts=4 sw=4 expandtab smartindent:
# 
# License: MIT (see COPYING file)

from __future__ import division

from . import _bbox
import numpy as np

def bbox(img, border=None, as_slice=False):
    """
    min1,max1,min2,max2 = bbox(img, border={0}, as_slice={False})

    Calculate the bounding box of image img.

    Parameters
    ----------
    img : ndarray
        Any integer image type

    Returns
    -------
    min1,max1,min2,max2 : int,int,int,int
        These are such that ``img[min1:max1, min2:max2]`` contains all non-zero
        pixels
    """
    if not img.shape:
        return np.array([], dtype=np.intp)
    r = _bbox.bbox(img)
    if border:
        min1,max1,min2,max2 = r
        min1 = max(0, min1-border)
        min2 = max(0, min2-border)
        max1 += border
        max2 += border
        r = min1,max1,min2,max2
    if as_slice:
        return (slice(r[0],r[1]),slice(r[2],r[3]))
    return r

def croptobbox(img, border=None):
    """
    nimg = croptobbox(img, border=0)

    Returns a version of img cropped to the image's bounding box

    Parameters
    ----------
    img : ndarray
        Integer image array
    border : int, optional
        whether to add a border (default no border)

    Returns
    -------
    nimg : ndarray
        A subimage of img.

    Bugs
    ----
    Note that the border is on the bounding box, not on the final image! This
    means that if the image has a positive pixel on its margin, it will still
    be on the margin.

    This ensures that the result is always a sub-image of the input.
    """
    min1,max1,min2,max2 = bbox(img, border=border)
    return img[min1:max1,min2:max2]


########NEW FILE########
__FILENAME__ = bwperim
# vim: set ts=4 sts=4 sw=4 expandtab smartindent:
#
# Copyright (C) 2012  Luis Pedro Coelho
# 
# License: MIT (see COPYING file)
import warnings
warnings.warn(
'''Use

from mahotas.labeled import bwperim
''', DeprecationWarning)


from .labeled import bwperim
__all__ = ['bwperim']


########NEW FILE########
__FILENAME__ = center_of_mass
# Copyright (C) 2008-2012, Luis Pedro Coelho <luis@luispedro.org>
# vim: set ts=4 sts=4 sw=4 expandtab smartindent:
# 
# License: MIT (see COPYING file)

from __future__ import division
import numpy as np
from . import _center_of_mass

def center_of_mass(img, labels=None):
    '''
    coords = center_of_mass(img, labels=None)
    x0,x1,... = center_of_mass(img, labels=None)

    Returns the center of mass of img.

    If `labels` is given, then it returns `L` centers of mass, one for each
    region identified by `labels` (including region 0).

    Parameters
    ----------
    img : ndarray
    labels : ndarray
        A labeled array

    Returns
    -------
    coords : ndarray
        if ``not labels``, a 1-ndarray of coordinates (size = len(img.shape)),
        if ``labels``, a 2-ndarray of coordinates (shape = (labels.max()+1) xlen(img.shape))
    '''
    if labels is not None:
        if labels.dtype != np.int32 or \
            not labels.flags['C_CONTIGUOUS']:
            labels = np.ascontiguousarray(labels, np.int32)
        else:
            # This is necessary because it might be of a type that equals
            # NPY_INT32, but is not NPY_INT32
            labels = labels.view(np.int32)
    cm = _center_of_mass.center_of_mass(img, labels)
    if labels is not None:
        return cm.reshape((-1, img.ndim))
    return cm


########NEW FILE########
__FILENAME__ = colors
# Copyright (C) 2012-2013, Luis Pedro Coelho <luis@luispedro.org>
# vim: set ts=4 sts=4 sw=4 expandtab smartindent:
# 
# License: MIT (see COPYING file)

from __future__ import division

import numpy as np
from .internal import _check_3

def rgb2grey(array, dtype=np.float):
    '''
    grey = rgb2grey(rgb_image, dtype=np.float)

    Convert an RGB image to a grayscale image

    The interpretation of RGB and greyscale values is very much object
    dependent (as anyone who has used an overhead projector which mangled their
    colour figures will have experienced). This function uses a typical method
    for conversion and will work acceptably well for typical use cases, but if
    you have strict requirements, consider implementing the conversion by
    yourself for fine control.

    Parameters
    ----------
    array : ndarray of shape (a,b,3)
    dtype : dtype, optional
        dtype of return

    Returns
    -------
    grey : ndarray of ``dtype``
    '''
    _check_3(array, 'rgb2grey')
    transform = np.array([0.30, 0.59, 0.11])
    transformed = np.dot(array, transform)
    return transformed.astype(dtype)
    
rgb2gray = rgb2grey

def _convert(array, matrix, dtype, funcname):
    _check_3(array, funcname)
    h,w,d = array.shape
    array = array.transpose((2,0,1))
    array = array.reshape((3,h*w))
    array = np.dot(matrix, array)
    array = array.reshape((3,h,w))
    array = array.transpose((1,2,0))
    if dtype is not None:
        array = array.astype(dtype)
    return array

def rgb2xyz(rgb, dtype=None):
    '''
    xyz = rgb2xyz(rgb, dtype={float})

    Convert RGB to XYZ coordinates

    The input is interpreted as sRGB. See Wikipedia for more details:

    http://en.wikipedia.org/wiki/SRGB

    Parameters
    ----------
    rgb : ndarray
    dtype : dtype, optional 
        What dtype to return

    Returns
    -------
    xyz : ndarray

    See Also
    --------
    xyz2rgb : function
        The reverse function
    '''
    transformation = np.array([
                [0.4124, 0.3576, 0.1805],
                [0.2126, 0.7152, 0.0722],
                [0.0193, 0.1192, 0.9505],
                ])
    rgb = rgb/255.
    a = 0.055
    rgb_linear_high = np.power( (rgb + a)/(1.+a), 2.4 )
    rgb_linear_low = rgb/12.92
    rgb_linear = np.choose(rgb <= 0.04045, [rgb_linear_low, rgb_linear_high])
    return _convert(rgb_linear, transformation, dtype, 'rgb2xyz')

def xyz2rgb(xyz, dtype=None):
    '''
    rgb = xyz2rgb(xyz, dtype={float})

    Convert XYZ to sRGB coordinates

    The output should be interpreted as sRGB. See Wikipedia for more details:

    http://en.wikipedia.org/wiki/SRGB

    Parameters
    ----------
    xyz : ndarray
    dtype : dtype, optional 
        What dtype to return. Default will be floats

    Returns
    -------
    rgb : ndarray

    See Also
    --------
    rgb2xyz : function
        The reverse function
    '''
    transformation = np.array([
                [ 3.2406, -1.5372, -0.4986],
                [-0.9689,  1.8758,  0.0415],
                [ 0.0557, -0.2040,  1.0570],
                ])
    rgb_linear = _convert(xyz, transformation, dtype, 'xyz2rgb')
    a = 0.055
    srgb_high = (1 + a)*np.power(rgb_linear, 1./2.4)
    srgb_high -= a
    srgb_low = 12.92 * rgb_linear
    srgb = np.choose(rgb_linear <= 0.0031308, [srgb_low, srgb_high])
    srgb *= 255.
    return srgb

def xyz2lab(xyz, dtype=None):
    '''
    lab = xyz2lab(xyz, dtype={float})

    Convert CIE XYZ to L*a*b* coordinates

    http://en.wikipedia.org/wiki/CIELAB

    Parameters
    ----------
    xyz : ndarray
    dtype : dtype, optional 
        What dtype to return. Default will be floats

    Returns
    -------
    lab : ndarray
    '''
    _check_3(xyz, 'xyz2lab')
    x,y,z = xyz.transpose((2,0,1))
    def f(t):
        branch_large = t**(1./3)
        branch_small = ((1/3.)*(29./6)*(29./6))*t + 4/29.
        return np.choose(t <= (6./29)**2, [branch_small, branch_large])
    xn, yn, zn = 0.95047, 1., 1.08883
    fx = f(x/xn)
    fy = f(y/yn)
    fz = f(z/zn)
    L = 116 * fy - 16
    a = 500 * (fx - fy)
    b = 200 * (fy - fz)
    Lab = np.dstack( [L,a,b] )
    if dtype is not None:
        Lab = Lab.astype(dtype)
    return Lab

def rgb2lab(rgb, dtype=None):
    '''
    lab = rgb2lab(rgb, dtype={float})

    Convert sRGB to L*a*b* coordinates

    http://en.wikipedia.org/wiki/CIELAB

    Parameters
    ----------
    rgb : ndarray
        Must be of shape (h,w,3)
    dtype : dtype, optional 
        What dtype to return. Default will be floats

    Returns
    -------
    lab : ndarray
    '''
    return xyz2lab(rgb2xyz(rgb), dtype=dtype)

def rgb2sepia(rgb):
    '''
    sepia = rgb2sepia(rgb)

    Parameters
    ----------
    rgb : ndarray
        Must be of shape (h,w,3)

    Returns
    -------
    sepia : ndarray
        Output is of same shape as ``rgb``
    '''
    rgb2sepia_weights = np.array([
                [.393,.769,.189],
                [.349,.686,.168],
                [.272,.534,.131]])
    sepia = _convert(rgb, rgb2sepia_weights, dtype=np.float32, funcname='rgb2sepia')
    sepia = np.minimum(sepia,255)
    sepia = np.maximum(sepia,0)
    return sepia.astype(np.uint8)


########NEW FILE########
__FILENAME__ = convolve
# Copyright (C) 2010-2014, Luis Pedro Coelho <luis@luispedro.org>
# vim: set ts=4 sts=4 sw=4 expandtab smartindent:
#
# License: MIT (see COPYING file)


import numpy as np
from . import _convolve
from . import morph
from .internal import _get_output, _normalize_sequence, _verify_is_floatingpoint_type, _as_floating_point_array
from ._filters import mode2int, modes, _check_mode

__all__ = [
    'convolve',
    'convolve1d',
    'daubechies',
    'idaubechies',
    'find',
    'haar',
    'ihaar',
    'median_filter',
    'rank_filter',
    'template_match',
    'gaussian_filter1d',
    'gaussian_filter',
    'wavelet_center',
    'wavelet_decenter',
    ]

def convolve(f, weights, mode='reflect', cval=0.0, out=None, output=None):
    '''
    convolved = convolve(f, weights, mode='reflect', cval=0.0, out={new array})

    Convolution of `f` and `weights`

    Convolution is performed in `doubles` to avoid over/underflow, but the
    result is then cast to `f.dtype`.

    Parameters
    ----------
    f : ndarray
        input. Any dimension is supported
    weights : ndarray
        weight filter. If not of the same dtype as `f`, it is cast
    mode : {'reflect' [default], 'nearest', 'wrap', 'mirror', 'constant', 'ignore'}
        How to handle borders
    cval : double, optional
        If `mode` is constant, which constant to use (default: 0.0)
    out : ndarray, optional
        Output array. Must have same shape and dtype as `f` as well as be
        C-contiguous.

    Returns
    -------
    convolved : ndarray of same dtype as `f`
    '''
    if f.dtype != weights.dtype:
        weights = weights.astype(f.dtype)
    if f.ndim != weights.ndim:
        raise ValueError('mahotas.convolve: `f` and `weights` must have the same dimensions')
    output = _get_output(f, out, 'convolve', output=output)
    _check_mode(mode, cval, 'convolve')
    return _convolve.convolve(f, weights, output, mode2int[mode])


def convolve1d(f, weights, axis, mode='reflect', cval=0., out=None, output=None):
    '''
    convolved = convolve1d(f, weights, axis, mode='reflect', cval=0.0, out={new array})

    Convolution of `f` and `weights` along axis `axis`.

    Convolution is performed in `doubles` to avoid over/underflow, but the
    result is then cast to `f.dtype`.

    Parameters
    ----------
    f : ndarray
        input. Any dimension is supported
    weights : 1-D ndarray
        weight filter. If not of the same dtype as `f`, it is cast
    axis : int
        Axis along which to convolve
    mode : {'reflect' [default], 'nearest', 'wrap', 'mirror', 'constant', 'ignore'}
        How to handle borders
    cval : double, optional
        If `mode` is constant, which constant to use (default: 0.0)
    out : ndarray, optional
        Output array. Must have same shape and dtype as `f` as well as be
        C-contiguous.

    Returns
    -------
    convolved : ndarray of same dtype as `f`

    See Also
    --------
    convolve : function
        generic convolution
    '''
    weights = np.asanyarray(weights)
    weights = weights.squeeze()
    if weights.ndim != 1:
        raise ValueError('mahotas.convolve1d: only 1-D sequences allowed')
    _check_mode(mode, cval, 'convolve1d')
    if f.flags.contiguous and len(weights) < f.shape[axis]:
        weights = weights.astype(np.double)
        indices = [a for a in range(f.ndim) if a != axis] + [axis]
        rindices = [indices.index(a) for a in range(f.ndim)]
        oshape = f.shape
        f = f.transpose(indices)
        tshape = f.shape
        f = f.reshape((f.shape[0],-1))

        out = _get_output(f, out, 'convolve1d')
        _convolve.convolve1d(f, weights, out, mode2int[mode])
        out = out.reshape(tshape)
        out = out.transpose(rindices)
        out = out.reshape(oshape)
        return out
    else:
        index = [None] * f.ndim
        index[axis] = slice(0, None)
        weights = weights[tuple(index)]
        return convolve(f, weights, mode=mode, cval=cval, output=output)


def median_filter(f, Bc=None, mode='reflect', cval=0.0, out=None, output=None):
    '''
    median = median_filter(f, Bc={square}, mode='reflect', cval=0.0, out={np.empty(f.shape, f.dtype})

    Median filter

    Parameters
    ----------
    f : ndarray
        input. Any dimension is supported
    Bc : ndarray or int, optional
        Defines the neighbourhood, default is a square of side 3.
    mode : {'reflect' [default], 'nearest', 'wrap', 'mirror', 'constant', 'ignore'}
        How to handle borders
    cval : double, optional
        If `mode` is constant, which constant to use (default: 0.0)
    out : ndarray, optional
        Output array. Must have same shape and dtype as `f` as well as be
        C-contiguous.

    Returns
    -------
    median : ndarray of same type and shape as ``f``
        median[i,j] is the median value of the points in f close to (i,j)
    '''
    if Bc is None:
        Bc = np.ones((3,) * len(f.shape), f.dtype)
    elif f.dtype != Bc.dtype:
        Bc = Bc.astype(f.dtype)
    rank = Bc.sum()//2
    output = _get_output(f, out, 'median_filter', output=output)
    _check_mode(mode, cval, 'median_filter')
    return _convolve.rank_filter(f, Bc, output, int(rank), mode2int[mode])

def mean_filter(f, Bc, mode='ignore', cval=0.0, out=None):
    '''mean = mean_filter(f, Bc, mode='ignore', cval=0.0, out=None)

    Mean filter. The value at ``mean[i,j]`` will be the mean of the values in
    the neighbourhood defined by ``Bc``.

    Parameters
    ----------
    f : ndarray
        input. Any dimension is supported
    Bc : ndarray
        Defines the neighbourhood. Must be explicitly passed, no default.
    mode : {'reflect', 'nearest', 'wrap', 'mirror', 'constant', 'ignore' [ignore]}
        How to handle borders. The default is to ignore points beyond the
        border, so that the means computed near the border include fewer elements.
    cval : double, optional
        If `mode` is constant, which constant to use (default: 0.0)
    out : ndarray, optional
        Output array. Must be a double array with the same shape as `f` as well
        as be C-contiguous.

    Returns
    -------
    mean : ndarray of type double and same shape as ``f``

    See Also
    --------
    median_filter : An alternative filtering method
    '''
    Bc = morph.get_structuring_elem(f, Bc)
    out = _get_output(f, out, 'mean_filter', dtype=np.float64)
    _check_mode(mode, cval, 'mean_filter')
    return _convolve.mean_filter(f, Bc, out, mode2int[mode], cval)


def rank_filter(f, Bc, rank, mode='reflect', cval=0.0, out=None, output=None):
    '''
    ranked = rank_filter(f, Bc, rank, mode='reflect', cval=0.0, out=None)

    Rank filter. The value at ``ranked[i,j]`` will be the ``rank``th largest in
    the neighbourhood defined by ``Bc``.

    Parameters
    ----------
    f : ndarray
        input. Any dimension is supported
    Bc : ndarray
        Defines the neighbourhood. Must be explicitly passed, no default.
    rank : integer
    mode : {'reflect' [default], 'nearest', 'wrap', 'mirror', 'constant', 'ignore'}
        How to handle borders
    cval : double, optional
        If `mode` is constant, which constant to use (default: 0.0)
    out : ndarray, optional
        Output array. Must have same shape and dtype as `f` as well as be
        C-contiguous.

    Returns
    -------
    ranked : ndarray of same type and shape as ``f``
        ranked[i,j] is the ``rank``th value of the points in f close to (i,j)

    See Also
    --------
    median_filter : A special case of rank_filter
    '''
    Bc = morph.get_structuring_elem(f, Bc)
    output = _get_output(f, out, 'rank_filter', output=output)
    _check_mode(mode, cval, 'rank_filter')
    return _convolve.rank_filter(f, Bc, output, rank, mode2int[mode])


def template_match(f, template, mode='reflect', cval=0., out=None, output=None):
    '''Match template to image

    match = template_match(f, template, mode='reflect', cval=0., out={np.empty_like(f)})

    The value at ``match[i,j]`` will be the difference (in squared euclidean
    terms), between `template` and a same sized window on `f` centered on that
    point.

    Note that the computation is performed using the same dtype as ``f``. Thus
    is may overflow if the template is large.

    Parameters
    ----------
    f : ndarray
        input. Any dimension is supported
    template : ndarray
        Template to match. Must be explicitly passed, no default.
    mode : {'reflect' [default], 'nearest', 'wrap', 'mirror', 'constant', 'ignore'}
        How to handle borders
    cval : double, optional
        If `mode` is constant, which constant to use (default: 0.0)
    out : ndarray, optional
        Output array. Must have same shape and dtype as `f` as well as be
        C-contiguous.

    Returns
    -------
    match : ndarray of same type and shape as ``f``
        match[i,j] is the squared euclidean distance between
        ``f[i-s0:i+s0,j-s1:j+s1]`` and ``template`` (for appropriately defined
        ``s0`` and ``s1``).
    '''
    template = template.astype(f.dtype)
    output = _get_output(f, out, 'template_match', output=output)
    _check_mode(mode, cval, 'template_match')
    return _convolve.template_match(f, template, output, mode2int[mode], 0)

def find(f, template):
    '''Match template to image exactly

    coordinates = find(f, template)

    The output is in the same format as the ``np.where`` function.

    Parameters
    ----------
    f : ndarray
        input. Currently, only 2-dimensional images are supported.
    template : ndarray
        Template to match. Must be explicitly passed, no default.

    Returns
    -------
    match : np.array
    coordinates : np.array
        These are the coordinates of the match. The format is similar to the
        output of ``np.where``, but in an ndarray.

    '''
    if f.ndim != 2:
        raise ValueError('mahotas.find: Cannot handle multi-dimensional images')
    template = template.astype(f.dtype)
    out = np.empty(f.shape, bool)
    return _convolve.find2d(f, template, out)


def gaussian_filter1d(array, sigma, axis=-1, order=0, mode='reflect', cval=0., out=None, output=None):
    """
    filtered = gaussian_filter1d(array, sigma, axis=-1, order=0, mode='reflect', cval=0., out={np.empty_like(array)})

    One-dimensional Gaussian filter.

    Parameters
    ----------
    array : ndarray
        input array of a floating-point type

    sigma : float
        standard deviation for Gaussian kernel (in pixel units)
    axis : int, optional
        axis to operate on
    order : {0, 1, 2, 3}, optional
        An order of 0 corresponds to convolution with a Gaussian
        kernel. An order of 1, 2, or 3 corresponds to convolution with
        the first, second or third derivatives of a Gaussian. Higher
        order derivatives are not implemented
    mode : {'reflect' [default], 'nearest', 'wrap', 'mirror', 'constant', 'ignore'}
        How to handle borders
    cval : double, optional
        If `mode` is constant, which constant to use (default: 0.0)
    out : ndarray, optional
        Output array. Must have same shape and dtype as `array` as well as be
        C-contiguous.

    Returns
    -------
    filtered : ndarray
        Filtered version of `array`

    """
    _verify_is_floatingpoint_type(array, 'gaussian_filter1d')
    sigma = float(sigma)
    s2 = sigma*sigma
    # make the length of the filter equal to 4 times the standard
    # deviations:
    lw = int(4.0 * sigma + 0.5)
    if lw <= 0:
        raise ValueError('mahotas.gaussian_filter1d: sigma must be greater or equal to 0.125 [1/8]')
    x = np.arange(2*lw+1, dtype=float)
    x -= lw
    weights = np.exp(x*x/(-2.*s2))
    weights /= np.sum(weights)
    # implement first, second and third order derivatives:
    if order == 0:
        pass
    elif order == 1 : # first derivative
        weights *= -x/s2
    elif order == 2: # second derivative
        weights *= (x*x/s2-1.)/s2
    elif order == 3: # third derivative
        weights *= (3.0 - x*x/s2)*x/(s2*s2)
    else:
        raise ValueError('mahotas.convolve.gaussian_filter1d: Order outside 0..3 not implemented')
    return convolve1d(array, weights, axis, mode, cval, out=output)


def gaussian_filter(array, sigma, order=0, mode='reflect', cval=0., out=None, output=None):
    """
    filtered = gaussian_filter(array, sigma, order=0, mode='reflect', cval=0., out={np.empty_like(array)})

    Multi-dimensional Gaussian filter.

    Parameters
    ----------
    array : ndarray
        input array, any dimension is supported. If the array is an integer
        array, it will be converted to a double array.
    sigma : scalar or sequence of scalars
        standard deviation for Gaussian kernel. The standard
        deviations of the Gaussian filter are given for each axis as a
        sequence, or as a single number, in which case it is equal for
        all axes.
    order : {0, 1, 2, 3} or sequence from same set, optional
        The order of the filter along each axis is given as a sequence
        of integers, or as a single number.  An order of 0 corresponds
        to convolution with a Gaussian kernel. An order of 1, 2, or 3
        corresponds to convolution with the first, second or third
        derivatives of a Gaussian. Higher order derivatives are not
        implemented
    mode : {'reflect' [default], 'nearest', 'wrap', 'mirror', 'constant', 'ignore'}
        How to handle borders
    cval : double, optional
        If `mode` is constant, which constant to use (default: 0.0)
    out : ndarray, optional
        Output array. Must have same shape as `array` as well as be
        C-contiguous. If `array` is an integer array, this must be a double
        array; otherwise, it must have the same type as `array`.

    Returns
    -------
    filtered : ndarray
        Filtered version of `array`

    Notes
    -----
    The multi-dimensional filter is implemented as a sequence of
    one-dimensional convolution filters. The intermediate arrays are
    stored in the same data type as the output. Therefore, for output
    types with a limited precision, the results may be imprecise
    because intermediate results may be stored with insufficient
    precision.
    """
    array = _as_floating_point_array(array)
    output = _get_output(array, out, 'gaussian_filter', output=output)
    orders = _normalize_sequence(array, order, 'gaussian_filter')
    sigmas = _normalize_sequence(array, sigma, 'gaussian_filter')
    output[...] = array[...]
    noutput = None
    for axis in range(array.ndim):
        sigma = sigmas[axis]
        order = orders[axis]
        noutput = gaussian_filter1d(output, sigma, axis, order, mode, cval, noutput)
        output,noutput = noutput,output
    return output

def _wavelet_array(f, inline, func):
    f = _as_floating_point_array(f)
    if f.ndim != 2:
        raise ValueError('mahotas.convolve.%s: Only works for 2D images' % func)
    if not inline:
        return f.copy()
    return f



def _wavelet_center_compute(oshape, border=0, dtype=None, cval=0.0):
    for c in range(1, 16+border):
        nshape = 2**(np.floor(np.log2(oshape))+c)
        delta = nshape - oshape
        delta //= 2
        if np.min(delta) <= border:
            continue
        position = []
        for d,e in zip(delta, oshape):
            position.append( slice(d, d + e) )
        return nshape, position

def wavelet_center(f, border=0, dtype=float, cval=0.0):
    '''
    fc = wavelet_center(f, border=0, dtype=float, cval=0.0)

    ``fc`` is a centered version of ``f`` with a shape that is composed of
    powers of 2.

    Parameters
    ----------
    f : ndarray
        input image
    border : int, optional
        The border to use (default is no border)
    dtype : type, optional
        Type of ``fc``
    cval : float, optional
        Which value to fill the border with (default is 0)

    Returns
    -------
    fc : ndarray

    See Also
    --------
    wavelet_decenter : function
        Reverse function
    '''
    nshape, position = _wavelet_center_compute(f.shape, border)
    nimage = np.zeros(nshape, dtype=dtype)
    nimage += cval
    nimage[position] = f
    return nimage


def wavelet_decenter(w, oshape, border=0):
    '''
    f = wavelet_decenter(w, oshape, border=0)

    Undoes the effect of ``wavelet_center``

    Parameters
    ----------
    w : ndarray
        Wavelet array
    oshape : tuple
        Desired shape
    border : int, optional
        The desired border. This **must** be the same value as was used for
        ``wavelet_center`` 

    Returns
    -------
    f : ndarray
        This will have shape ``oshape``

    See Also
    --------
    wavelet_center : function
        Forward function
    '''
    nshape, position = _wavelet_center_compute(oshape, border)
    return w[position]



def haar(f, preserve_energy=True, inline=False):
    '''
    t = haar(f, preserve_energy=True, inline=False)

    Haar transform

    Parameters
    ----------
    f : 2-D ndarray
        Input image
    preserve_energy : bool, optional
        Whether to normalise the result so that energy is preserved (the
        default).
    inline : bool, optional
        Whether to write the results to the input image. By default, a new
        image is returned. Integer images are always converted to floating
        point and copied.

    See Also
    --------
    ihaar : function
        Reverse Haar transform
    '''
    f = _wavelet_array(f, inline, 'haar')
    _convolve.haar(f)
    _convolve.haar(f.T)
    if preserve_energy:
        f /= 2.0
    return f

_daubechies_codes = [('D%s' % ci) for ci in range(2,21,2)]
def _daubechies_code(c):
    try:
        return _daubechies_codes.index(c)
    except:
        raise ValueError('mahotas.convolve: Known daubechies codes are {0}. You passed in {1}.'.format(_daubechies_codes, c))

def daubechies(f, code, inline=False):
    '''
    filtered = daubechies(f, code, inline=False)

    Daubechies wavelet transform

    This function works best if the image sizes are powers of 2!

    Parameters
    ----------
    f : ndarray
        2-D image
    code : str
        One of 'D2', 'D4', ... 'D20'
    inline : bool, optional
        Whether to write the results to the input image. By default, a new
        image is returned. Integer images are always converted to floating
        point and copied.

    See Also
    --------
    haar : function
        Haar transform (equivalent to D2)
    '''
    f = _wavelet_array(f, inline, 'daubechies')
    code = _daubechies_code(code)
    _convolve.daubechies(f, code)
    _convolve.daubechies(f.T, code)
    return f


def idaubechies(f, code, inline=False):
    '''
    rfiltered = idaubechies(f, code, inline=False)

    Daubechies wavelet inverse transform

    Parameters
    ----------
    f : ndarray
        2-D image
    code : str
        One of 'D2', 'D4', ... 'D20'
    inline : bool, optional
        Whether to write the results to the input image. By default, a new
        image is returned. Integer images are always converted to floating
        point and copied.

    See Also
    --------
    haar : function
        Haar transform (equivalent to D2)
    '''
    f = _wavelet_array(f, inline, 'idaubechies')
    code = _daubechies_code(code)
    _convolve.idaubechies(f.T, code)
    _convolve.idaubechies(f, code)
    return f


def ihaar(f, preserve_energy=True, inline=False):
    '''
    t = ihaar(f, preserve_energy=True, inline=False)

    Reverse Haar transform

    ``ihaar(haar(f))`` is more or less equal to ``f`` (equal, except for
    possible rounding issues).

    Parameters
    ----------
    f : 2-D ndarray
        Input image. If it is an integer image, it is converted to floating
        point (double).
    preserve_energy : bool, optional
        Whether to normalise the result so that energy is preserved (the
        default).
    inline : bool, optional
        Whether to write the results to the input image. By default, a new
        image is returned. Integer images are always converted to floating
        point and copied.

    Returns
    -------
    f : ndarray

    See Also
    --------
    haar : function
        Forward Haar transform
    '''
    f = _wavelet_array(f, inline, 'ihaar')
    _convolve.ihaar(f)
    _convolve.ihaar(f.T)
    if preserve_energy:
        f *= 2.0
    return f

########NEW FILE########
__FILENAME__ = distance
from __future__ import print_function

import pylab as p
import numpy as np
import mahotas

f = np.ones((256,256), bool)
f[200:,240:] = False
f[128:144,32:48] = False
# f is basically True with the exception of two islands: one in the lower-right
# corner, another, middle-left

dmap = mahotas.distance(f)
p.imshow(dmap)
p.show()

########NEW FILE########
__FILENAME__ = morphology
from __future__ import print_function
import mahotas as mh
from pylab import gray, imshow, show
import numpy as np


luispedro = mh.demos.load('luispedro')
luispedro = luispedro.max(2)
T = mh.otsu(luispedro)
lpbin = (luispedro > T)
eye = lpbin[112:180,100:190]
gray()
imshow(eye)
show()
imshow(~mh.morph.close(~eye))
show()
imshow(~mh.morph.open(~eye))
show()

########NEW FILE########
__FILENAME__ = nuclear
import mahotas
import numpy as np
from pylab import imshow, show

f = mahotas.imread('mahotas/demos/data/nuclear.png')
f = f[:,:,0]
imshow(f)
show()

f = mahotas.gaussian_filter(f, 4)
f = (f> f.mean())
imshow(f)
show()

labeled, n_nucleus  = mahotas.label(f)
print('Found {} nuclei.'.format(n_nucleus))
imshow(labeled)
show()
sizes = mahotas.labeled.labeled_size(labeled)
too_big = np.where(sizes > 10000)
labeled = mahotas.labeled.remove_regions(labeled, too_big)
imshow(labeled)
show()

labeled = mahotas.labeled.remove_bordering(labeled)
imshow(labeled)
show()

relabeled, n_left = mahotas.labeled.relabel(labeled)
print('After filtering and relabeling, there are {} nuclei left.'.format(n_left))
imshow(relabeled)
show()

########NEW FILE########
__FILENAME__ = nuclear_distance_watershed
import mahotas
from os import path
import numpy as np
from matplotlib import pyplot as plt

try:
    nuclear_path = path.join(
                    path.dirname(path.abspath(__file__)),
                    'data',
                    'nuclear.png')
except NameError:
    nuclear_path = path.join('data', 'nuclear.png')

nuclear = mahotas.imread(nuclear_path)
nuclear = nuclear[:,:,0]
nuclear = mahotas.gaussian_filter(nuclear, 1.)
threshed  = (nuclear > nuclear.mean())
distances = mahotas.stretch(mahotas.distance(threshed))
Bc = np.ones((9,9))

maxima = mahotas.morph.regmax(distances, Bc=Bc)
spots,n_spots = mahotas.label(maxima, Bc=Bc)
surface = (distances.max() - distances)
areas = mahotas.cwatershed(surface, spots)
areas *= threshed



import random
from matplotlib import colors as c
colors = map(plt.cm.jet,range(0, 256, 4))
random.shuffle(colors)
colors[0] = (0.,0.,0.,1.)
rmap = c.ListedColormap(colors)
plt.imshow(areas, cmap=rmap)
plt.show()

########NEW FILE########
__FILENAME__ = superpixels
import random
import numpy as np
import matplotlib
from matplotlib import pyplot as plt

import mahotas

f = mahotas.imread('mahotas/demos/data/luispedro.jpg')
colors = map(plt.cm.jet, range(256))
random.seed(23)
random.shuffle(colors)
cmap = matplotlib.colors.ListedColormap (colors)

segmented, _ = mahotas.segmentation.slic(f, 16)
plt.imshow(segmented, cmap=cmap)
plt.show()

segmented, _ = mahotas.segmentation.slic(f, 64)
plt.imshow(segmented, cmap=cmap)
plt.show()

segmented, _ = mahotas.segmentation.slic(f, 128)
plt.imshow(segmented, cmap=cmap)
plt.show()


########NEW FILE########
__FILENAME__ = surf_gaussians
from __future__ import print_function
import mahotas.polygon
from pylab import imshow, show
import numpy as np
from mahotas.features import surf

f = np.zeros((1024,1024))
Y,X = np.indices(f.shape)
Y -= 768
X -= 768
f += 120*np.exp(-Y**2/2048.-X**2/480.)
Y += 512
X += 512
rho = .7
f += 120*np.exp(-1./( 2*(1-rho**2)) *( Y**2/32/32.+X**2/24/24. + 2*rho*X*Y/32./24.))
fi = surf.integral(f.copy())
spoints = surf.surf(f, 6, 24, 1)

f2 = surf.show_surf(f, spoints)
imshow(f2)
show()

########NEW FILE########
__FILENAME__ = surf_luispedro
from __future__ import print_function
import numpy as np
import mahotas as mh
from mahotas.features import surf
from pylab import *

from os import path

f = mh.demos.load('luispedro', as_grey=True)
f = f.astype(np.uint8)
spoints = surf.surf(f, 4, 6, 2)
print("Nr points:", len(spoints))

try:
    import milk
    descrs = spoints[:,5:]
    k = 5
    values, _  =milk.kmeans(descrs, k)
    colors = np.array([(255-52*i,25+52*i,37**i % 101) for i in range(k)])
except:
    values = np.zeros(100)
    colors = np.array([(255,0,0)])

f2 = surf.show_surf(f, spoints[:100], values, colors)
imshow(f2)
show()

########NEW FILE########
__FILENAME__ = thresholding
import mahotas
import numpy as np
from pylab import imshow, gray, show, subplot
from os import path

luispedro_image = path.join(
                    path.dirname(path.abspath(__file__)),
                    'data',
                    'luispedro.jpg')

photo = mahotas.imread(luispedro_image, as_grey=True)
photo = photo.astype(np.uint8)

gray()
subplot(131)
imshow(photo)

T_otsu = mahotas.otsu(photo)
print(T_otsu)
subplot(132)
imshow(photo > T_otsu)

T_rc = mahotas.rc(photo)
print(T_rc)
subplot(133)
imshow(photo > T_rc)
show()


########NEW FILE########
__FILENAME__ = wally
from pylab import imshow
import mahotas
wally = mahotas.imread('data/DepartmentStore.jpg')
wfloat = wally.astype(float)
r,g,b = wfloat.transpose((2,0,1))
w = wfloat.mean(2)
pattern = np.ones((24,16), float)
for i in xrange(2):
    pattern[i::4] = -1
v = mahotas.convolve(r-w, pattern)
mask = (v == v.max())
mask = mahotas.dilate(mask, np.ones((48,24)))
wally -= .8*wally * ~mask[:,:,None]
imshow(wally)



########NEW FILE########
__FILENAME__ = wavelet_compress
from __future__ import print_function
import numpy as np
import mahotas
from mahotas.thresholding import soft_threshold
from matplotlib import pyplot as plt
from os import path

# Let us load the data first:
luispedro_image = path.join(
                    path.dirname(path.abspath(__file__)),
                    'data',
                    'luispedro.jpg')

f = mahotas.imread(luispedro_image, as_grey=True)
f = f[:256,:256]
plt.gray()
# Show the data:
plt.imshow(f)
print("Fraction of zeros in original image:", np.mean(f==0))

# A baseline compression method: save every other pixel and only high-order bits:
direct = f[::2,::2].copy()
direct /= 8
direct = direct.astype(np.uint8)
print("Fraction of zeros in original image (after division by 8):", np.mean(direct==0))
plt.imshow(direct)


# Transform using D8 Wavelet to obtain transformed image t:
t = mahotas.daubechies(f,'D8')
plt.imshow(t)

# Discard low-order bits:
t /= 8
t = t.astype(np.int8)
print("Fraction of zeros in transform (after division by 8):", np.mean(t==0))
plt.imshow(t)

# Let us look at what this looks like
r = mahotas.idaubechies(t, 'D8')
plt.imshow(r)

# Go further, discard small values in the transformed space:
tt = soft_threshold(t, 12)
print("Fraction of zeros in transform (after division by 8 & soft thresholding):", np.mean(tt==0))

# Let us look again at what we have:
rt = mahotas.idaubechies(tt, 'D8')
plt.imshow(rt)

########NEW FILE########
__FILENAME__ = distance
# Copyright (C) 2010-2013, Luis Pedro Coelho <luis@luispedro.org>
# vim: set ts=4 sts=4 sw=4 expandtab smartindent:
# 
# License: MIT (see COPYING file)

from . import _distance
from . import _morph
import numpy as np

__all__ = [
    'distance',
    ]

def distance(bw, metric='euclidean2'):
    '''
    dmap = distance(bw, metric='euclidean2')

    Computes the distance transform of image `bw`::

        dmap[i,j] = min_{i', j'} { (i-i')**2 + (j-j')**2 | !bw[i', j'] }

    That is, at each point, compute the distance to the background.

    If there is no background, then a very high value will be returned in all
    pixels (this is a sort of infinity).

    Parameters
    ----------
    bw : ndarray
        If boolean, ``False`` will denote the background and ``True`` the
        foreground. If not boolean, this will be interpreted as ``bw != 0``
        (this way you can use labeled images without any problems).
    metric : str, optional
        one of 'euclidean2' (default) or 'euclidean'

    Returns
    -------
    dmap : ndarray
        distance map

    References
    ----------
    For 2-D images, the following algorithm is used:

    Felzenszwalb P, Huttenlocher D. *Distance transforms of sampled functions.
    Cornell Computing and Information.* 2004.

    Available at:
    http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.88.1647&rep=rep1&type=pdf.

    For n-D images (with n > 2), a slower hand-craft method is used.
    '''
    if bw.dtype != np.bool_:
        bw = (bw != 0)
    f = np.zeros(bw.shape, np.double)
    if bw.ndim == 2:
        f[bw] = len(f.shape)*max(f.shape)**2+1
        _distance.dt(f, None)
    else:
        f.fill(f.size*2)
        Bc = np.ones([3 for _ in bw.shape], bool)
        _morph.distance_multi(f, bw, Bc)
    if metric == 'euclidean':
        np.sqrt(f,f)
    return f



########NEW FILE########
__FILENAME__ = edge
# -*- coding: utf-8 -*-
# Copyright (C) 2008-2013, Luis Pedro Coelho <luis@luispedro.org>
# vim: set ts=4 sts=4 sw=4 expandtab smartindent:
# 
# License: MIT (see COPYING file)

from __future__ import division
import numpy as np
from . import convolve

_hsobel_filter = np.array([
    [-1, 0, 1],
    [-2, 0, 2],
    [-1, 0, 1]])/8.

_vsobel_filter = np.array([
    [-1, -2, -1],
    [ 0,  0,  0],
    [ 1,  2,  1]])/8.

__all__ = ['sobel']

def sobel(img, just_filter=False):
    '''
    edges = sobel(img, just_filter=False)

    Compute edges using Sobel's algorithm

    `edges` is a binary image of edges computed according to Sobel's algorithm.

    This implementation is tuned to match MATLAB's implementation.

    Parameters
    ----------
    img : Any 2D-ndarray
    just_filter : boolean, optional
        If true, then return the result of filtering the image with the sobel
        filters, but do not threashold (default is False).

    Returns
    -------
    edges : ndarray
        Binary image of edges, unless `just_filter`, in which case it will be
        an array of floating point values.
    '''
    # This is based on Octave's implementation,
    # but with some reverse engineering to match Matlab exactly
    img = np.asanyarray(img, dtype=np.float)
    if img.ndim != 2:
        raise ValueError('mahotas.sobel: Only available for 2-dimensional images')
    img -= img.min()
    ptp = img.ptp()
    if ptp == 0:
        return img
    img /= ptp
    # Using 'nearest' seems to be MATLAB's implementation
    vfiltered = convolve(img, _vsobel_filter, mode='nearest')
    hfiltered = convolve(img, _hsobel_filter, mode='nearest')
    vfiltered **= 2
    hfiltered **= 2
    filtered = vfiltered
    filtered += hfiltered
    if just_filter:
        return filtered
    thresh = 2*np.sqrt(filtered.mean())
    filtered *= (np.sqrt(filtered) > thresh)

    r,c = filtered.shape
    x = (filtered > np.hstack((np.zeros((r,1)),filtered[:,:-1]))) & (filtered > np.hstack((filtered[:,1:], np.zeros((r,1)))))
    y = (filtered > np.vstack((np.zeros(c),filtered[:-1,:]))) & (filtered > np.vstack((filtered[1:,:], np.zeros(c))))
    return x | y




########NEW FILE########
__FILENAME__ = euler
# Copyright (C) 2008-2010, Luis Pedro Coelho <luis@luispedro.org>
# vim: set ts=4 sts=4 sw=4 expandtab smartindent:
# License: MIT

import numpy as np
from .convolve import convolve

_euler_lookup4 = np.array([
            0,  1,  1,  0,
            1,  0,  2, -1,
            1,  2,  0, -1,
            0, -1, -1,  0,
            ])/4.
_euler_lookup8 = np.array([
            0,  1,  1,  0,
            1,  0, -2, -1,
            1, -2,  0, -1,
            0, -1, -1,  0,
            ])/4.
_powers = np.array([
    [1, 2],
    [4, 8]
    ])

__all__ = ['euler']

def euler(f, n=8, mode='constant'):
    '''
    euler_nr = euler(f, n=8)

    Compute the Euler number of image f

    The Euler number is also known as the Euler characteristic given that many
    other mathematical objects are also known as Euler numbers.

    Parameters
    ----------
    f : ndarray
        A 2-D binary image
    n : int, optional
        Connectivity, one of (4,8). default: 8
    mode : {'reflect', 'nearest', 'wrap', 'mirror', 'constant' [default]}
        How to handle borders        

    Returns
    -------
    euler_nr : int
        Euler number

    References
    ----------
    http://en.wikipedia.org/wiki/Euler_characteristic

    References
    ----------
    The following algorithm is used:

    *A Fast Algorithm for Computing the Euler Number of an Image and its VLSI
    Implementation*, doi: 10.1109/ICVD.2000.812628
    '''
    if n == 8:
        lookup = _euler_lookup8
    elif n == 4:
        lookup = _euler_lookup4
    else:
        raise ValueError('mahotas.euler: Connectivity must be 4 or 8')
    if f.dtype is not np.bool:
        assert np.all( (f == 0) | (f == 1)), 'mahotas.euler: Non-binary image'
        f = (f != 0)
    value = convolve(f.astype(_powers.dtype), _powers, mode=mode)
    return lookup[value].sum()


########NEW FILE########
__FILENAME__ = lbp
# -*- coding: utf-8 -*-
# Copyright (C) 2008-2009 Robert Webb and Luis Pedro Coelho <luis@luispedro.org>
# Copyright (C) 2011-2013 Luis Pedro Coelho <luis@luispedro.org>
#
# License: MIT (see COPYING file)

import numpy as np
from ..histogram import fullhistogram

__all__ = [
    'lbp',
    'lbp_transform',
    ]

def lbp_transform(image, radius, points, ignore_zeros=False, preserve_shape=True):
    '''
    transformed = lbp(image, radius, points, ignore_zeros=False, preserve_shape=True)

    Compute Linear Binary Pattern Transform

    The return value are the transformed pixel values  **histogram** of feature counts, where position ``i``
    corresponds to the number of pixels that had code ``i``. The codes are
    compressed so that impossible codes are not used. Therefore, this is the
    ``i``th feature, not just the feature with binary code ``i``.

    Parameters
    ----------
    image : ndarray
        input image (2-D numpy ndarray)
    radius : number (integer or floating point)
        radius (in pixels)
    points : integer
        nr of points to consider
    ignore_zeros : boolean, optional
        whether to ignore zeros. Note that if you set this to ``True``, you
        will need to set ``preserve_shape`` to False. (default: False)
    preserve_shape : boolean, optional
        whether to return an array with the same shape as ``image``. (default:
        True)

    Returns
    -------
    features : 1-D numpy ndarray
        histogram of features. See above for a caveat on the interpretation of
        these.

    References
    ----------
    Gray Scale and Rotation Invariant Texture Classification with Local Binary Patterns
        Ojala, T. Pietikainen, M. Maenpaa, T. Lecture Notes in Computer Science (Springer)
        2000, ISSU 1842, pages 404-420
    '''
    from ..interpolate import shift
    from mahotas.features import _lbp

    if ignore_zeros and preserve_shape:
        raise ValueError('mahotas.features.lbp_transform: *ignore_zeros* and *preserve_shape* cannot both be used together')

    image = np.asanyarray(image, dtype=np.float64)
    if image.ndim != 2:
        raise ValueError('mahotas.features.lbp_transform: This function is only defined for two dimensional images')

    if ignore_zeros:
        Y,X = np.nonzero(image)
        def select(im):
            return im[Y,X].ravel()
    else:
        select = np.ravel

    pixels = select(image)
    angles = np.linspace(0, 2*np.pi, points+1)[:-1]
    data = []
    for dy,dx in zip(np.sin(angles), np.cos(angles)):
        data.append(
            select(shift(image, [radius*dy,radius*dx], order=1)))
    data = np.array(data)
    codes = (data > pixels).astype(np.int32)
    codes *= (2**np.arange(points)[:,np.newaxis])
    codes = codes.sum(0)
    codes = _lbp.map(codes.astype(np.uint32), points)
    if preserve_shape:
        codes = codes.reshape(image.shape)
    return codes

def count_binary1s(array):
    '''
    one_count = count_binary1s(array)

    Count the number of 1s in the binary representation of integer values

    Definition::

        one_count.flat[i] == nr_of_1s_in_binary_representation_of(array.flat[i])

    Parameters
    ----------
    array : ndarray
        input array

    Returns
    -------
    one_count : ndarray
        output array of same type & shape as array
    '''
    from ..internal import _verify_is_integer_type
    array = np.array(array)
    _verify_is_integer_type(array, 'mahotas.features.lbp.count_binary1s')
    maxv = 1+int(np.log2(1+array.max()))
    counts = np.zeros_like(array)
    for _ in range(maxv):
        counts += (array & 1)
        array >>= 1
    return counts


def lbp(image, radius, points, ignore_zeros=False):
    '''
    features = lbp(image, radius, points, ignore_zeros=False)

    Compute Linear Binary Patterns

    The return value is a **histogram** of feature counts, where position ``i``
    corresponds to the number of pixels that had code ``i``. The codes are
    compressed so that impossible codes are not used. Therefore, this is the
    ``i``th feature, not just the feature with binary code ``i``.

    Parameters
    ----------
    image : ndarray
        input image (2-D numpy ndarray)
    radius : number (integer or floating point)
        radius (in pixels)
    points : integer
        nr of points to consider
    ignore_zeros : boolean, optional
        whether to ignore zeros (default: False)

    Returns
    -------
    features : 1-D numpy ndarray
        histogram of features. See above for a caveat on the interpretation of
        these.

    Reference
    ---------
    Gray Scale and Rotation Invariant Texture Classification with Local Binary Patterns
        Ojala, T. Pietikainen, M. Maenpaa, T. Lecture Notes in Computer Science (Springer)
        2000, ISSU 1842, pages 404-420
    '''
    from mahotas.features import _lbp
    codes = lbp_transform(image, radius, points, ignore_zeros=ignore_zeros, preserve_shape=False)
    final = fullhistogram(codes.astype(np.uint32))

    codes = np.arange(2**points, dtype=np.uint32)
    iters = codes.copy()
    codes = _lbp.map(codes.astype(np.uint32), points)
    pivots = (codes == iters)
    npivots = np.sum(pivots)
    compressed = final[pivots[:len(final)]]
    compressed = np.append(compressed, np.zeros(npivots - len(compressed)))
    return compressed

########NEW FILE########
__FILENAME__ = moments
# Copyright (C) 2008-2012, Luis Pedro Coelho <luis@luispedro.org>
# vim: set ts=4 sts=4 sw=4 expandtab smartindent:
# 
# License: MIT (see COPYING file)

from __future__ import division
import numpy as np

__all__ = ['moments']
def moments(img, p0, p1, cm=None, convert_to_float=True, normalize=False, normalise=False):
    '''
    m = moments(img, p0, p1, cm=(0, 0), convert_to_float=True)

    Returns the p0-p1 moment of image `img`

    The formula computed is

    \sum_{ij} { img[i,j] (i - c0)**p0 (j - c1)**p1 }

    where cm = (c0,c1). If `cm` is not given, then (0,0) is used.

    If image is of an integer type, then it is internally converted to
    np.float64, unlesss `convert_to_float` is False. The reason is that,
    otherwise, overflow is likely except for small images. Since this
    conversion takes longer than the computation, you can turn it off in case
    you are sure that your images are small enough for overflow to be an issue.
    Note that no conversion is made if `img` is of any floating point type.

    Parameters
    ----------
    img : 2-ndarray
        An 2-d ndarray
    p0 : float
        Power for first dimension
    p1 : float
        Power for second dimension
    cm : (int,int), optional
        center of mass (default: 0,0)
    convert_to_float : boolean, optional
        whether to convert to floating point (default: True)
    normalize : boolean, optional
        whether to normalize to size of image (default: False)

    Returns
    -------
    moment: float
        floating point number

    Bugs
    ----
      It only works for 2-D images
    '''
    if normalise:
        normalize = True
    if not np.issubdtype(img.dtype, float) and convert_to_float:
        img = img.astype(np.float64)
    r,c = img.shape
    p = np.arange(c, dtype=float)
    if cm is not None:
        p -= cm[1]
    p **= p0
    if normalize:
        p /= p.sum()
    inter = np.dot(img, p)
    p = np.arange(r, dtype=float)
    if cm is not None:
        p -= cm[0]
    p **= p1
    if normalize:
        p /= p.sum()
    return np.dot(inter, p)


########NEW FILE########
__FILENAME__ = shape
# -*- coding: utf-8 -*-
# Copyright (C) 2012-2014, Luis Pedro Coelho <luis@luispedro.org>
# vim: set ts=4 sts=4 sw=4 expandtab smartindent:
#
from __future__ import division
import numpy as np
import mahotas as mh
from ..labeled import bwperim
from ..internal import _make_binary

__all__ = [
    'roundness',
    'eccentricity',
    'ellipse_axes',
    ]

def roundness(bw):
    '''
    r = roundness(bw)

    Roundness

    Parameters
    ----------
    bw : ndarray
        Interpreted as a boolean image

    Returns
    -------
    r : float
    '''
    bw = _make_binary(bw)
    area = np.sum(bw)
    perim = np.sum(bwperim(bw))
    if area == 0:
        return 0.
    return float(perim)*perim/4./np.pi/area


def ellipse_axes(bwimage):
    ''' Parameters of the 'image ellipse'

    semimajor,semiminor = ellipse_axes(bwimage)

    Returns the parameters of the constant intensity ellipse with the same mass
    and second order moments as the original image.

    Parameters
    ----------
    bwimage : ndarray
        Interpreted as a boolean image

    Returns
    -------
    semimajor : float
    semiminor : float

    References
    ----------
    Prokop, RJ, and Reeves, AP.  1992. CVGIP: Graphical Models and Image
    Processing 54(5):438-460

    '''
    from .moments import moments
    bwimage = _make_binary(bwimage)

    if not np.any(bwimage):
        return 0.,0.

    cof = mh.center_of_mass(bwimage)
    hull_mu00 = moments(bwimage, 0, 0, cof)
    hull_mu11 = moments(bwimage, 1, 1, cof)
    hull_mu02 = moments(bwimage, 0, 2, cof)
    hull_mu20 = moments(bwimage, 2, 0, cof)

    semimajor = np.sqrt((2 * (hull_mu20 + hull_mu02 + \
                    np.sqrt((hull_mu20 - hull_mu02)**2 + \
                    4 * hull_mu11**2)))/hull_mu00)

    semiminor = np.sqrt((2 * (hull_mu20 + hull_mu02 - \
                    np.sqrt((hull_mu20 - hull_mu02)**2 + \
                    4 * hull_mu11**2)))/hull_mu00)
    return semimajor, semiminor

def eccentricity(bwimage):
    """
    ecc = eccentricity(bwimage)

    Compute eccentricity

    Parameters
    ----------
    bwimage : ndarray
        Interpreted as a boolean image

    Returns
    -------
    r : float
        Eccentricity measure
    """
    semimajor, semiminor = ellipse_axes(bwimage)
    if semimajor == 0.:
        return 0.
    return  np.sqrt(semimajor**2 - semiminor**2) / semimajor


########NEW FILE########
__FILENAME__ = surf
# Copyright (C) 2010-2013, Luis Pedro Coelho <luis@luispedro.org>
# vim: set ts=4 sts=4 sw=4 expandtab smartindent:
#
# License: MIT (see COPYING file)

from __future__ import division
import numpy as np
from . import _surf
from ..internal import _verify_is_integer_type

__all__ = ['integral', 'surf']

def integral(f, in_place=False, dtype=np.double):
    '''
    fi = integral(f, in_place=False, dtype=np.double):

    Compute integral image

    Parameters
    ----------
    f : ndarray
        input image. Only 2-D images are supported.
    in_place : bool, optional
        Whether to overwrite `f` (default: False).
    dtype : dtype, optional
        dtype to use (default: double)

    Returns
    -------
    fi : ndarray of `dtype` of same shape as `f`
        The integral image
    '''
    if f.ndim != 2:
        raise ValueError('mahotas.surf.integral: Can only handle 2D-images (i.e., greyscale images).')
    if not in_place:
        if dtype != f.dtype:
            f = f.astype(dtype)
        else:
            f = f.copy()
    return _surf.integral(f)

def surf(f, nr_octaves=4, nr_scales=6, initial_step_size=1, threshold=0.1, max_points=1024, descriptor_only=False):
    '''
    points = surf(f, nr_octaves=4, nr_scales=6, initial_step_size=1, threshold=0.1, max_points=1024, descriptor_only=False):

    Run SURF detection and descriptor computations

    Speeded-Up Robust Features (SURF) are fast local features computed at
    automatically determined keypoints.

    Reference
    ---------

    Herbert Bay, Andreas Ess, Tinne Tuytelaars, Luc Van Gool "SURF: Speeded Up
    Robust Features", Computer Vision and Image Understanding (CVIU), Vol. 110,
    No. 3, pp. 346--359, 2008

    Parameters
    ----------
    f : ndarray
        input image
    nr_octaves : integer, optional
        Nr of octaves (default: 4)
    nr_scales : integer, optional
        Nr of scales (default: 6)
    initial_step_size : integer, optional
        Initial step size in pixels (default: 1)
    threshold : float, optional
        Threshold of the strength of the interest point (default: 0.1)
    max_points : integer, optional
        Maximum number of points to return. By default, return at most 1024
        points. Note that the number may be smaller even in the case where
        there are that many points. This is a side-effect of the way the
        threshold is implemented: only ``max_points`` are considered, but some
        of those may be filtered out.
    descriptor_only : boolean, optional
        If ``descriptor_only``, then returns only the 64-element descriptors

    Returns
    -------
    points : ndarray of double, shape = (N, 6 + 64)
        `N` is nr of points. Each point is represented as
        *(y,x,scale,score,laplacian,angle, D_0,...,D_63)* where *y,x,scale* is
        the position, *angle* the orientation, *score* and *laplacian* the
        score and sign of the detector; and *D_i* is the descriptor

        If ``descriptor_only``, then only the *D_i*s are returned and the array
        has shape (N, 64)!
    '''
    surfs = _surf.surf(integral(f), nr_octaves, nr_scales, initial_step_size, threshold, max_points)
    if descriptor_only:
        surfs = surfs[:,6:]
    return surfs


def interest_points(f, nr_octaves=4, nr_scales=6, initial_step_size=1, threshold=0.1, max_points=None, is_integral=False):
    '''
    desc_array = interest_points(f, nr_octaves=4, nr_scales=6, initial_step_size=1, threshold=0.1, max_points={all}, is_integral=False)

    SURF Detector

    Parameters
    ----------
    f : ndarray
        input image or integral image (if `is_integral`)
    nr_octaves : integer, optional
        Nr of octaves (default: 4)
    nr_scales : integer, optional
        Nr of scales (default: 6)
    initial_step_size : integer, optional
        Initial step size in pixels (default: 1)
    threshold : float, optional
        Threshold of the strength of the interest point (default: 0.1)
    max_points : integer, optional
        Maximum number of points to return. By default, return all.
    is_integral : boolean, optional
        Whether `f` is an integral image

    Returns
    -------
    points : ndarray of double, shape = (N, 5)
        `N` is nr of points. Each point is represented as
        *(y,x,scale,score,laplacian)* where *y,x,scale* is
        the position, *score* and *laplacian* the score and sign of the
        detector.

    See Also
    --------
    surf : SURF detection and descriptors
    descriptors : SURF descriptors
    '''
    if not is_integral:
        f = integral(f)
    else:
        if f.dtype != np.double:
            raise TypeError('mahotas.surf: integral image must be of dtype double')
    if max_points is None:
        max_points = -1
    return _surf.interest_points(f, nr_octaves, nr_scales, initial_step_size, threshold, max_points)


def descriptors(f, interest_points, is_integral=False, descriptor_only=False):
    '''
    desc_array = descriptors(f, interest_points, is_integral=False, descriptor_only=False)

    Compute SURF descriptors

    Parameters
    ----------
    f : ndarray
        input image or integral image (if `is_integral`)
    interest_points : ndarray
        interest points in the format returned by the ``interest_points()`` function
    is_integral : boolean, optional
        Whether `f` is an integral image
    descriptor_only : boolean, optional
        If ``descriptor_only``, then returns only the 64-element descriptors

    Returns
    -------
    points : ndarray of double, shape = (N, 6 + 64)
        `N` is nr of points. Each point is represented as
        *(y,x,scale,score,laplacian,angle, D_0,...,D_63)* where *y,x,scale* is
        the position, *angle* the orientation, *score* and *laplacian* the
        score and sign of the detector; and *D_i* is the descriptor.
        If ``descriptor_only`` is true, then returns only *(D_0,...,D_63)*
    '''
    if not is_integral:
        f = integral(f)
    else:
        if f.dtype != np.double:
            raise TypeError('mahotas.surf: integral image must be of dtype double')
    interest_points = np.ascontiguousarray(interest_points, dtype=np.float64)
    surfs = _surf.descriptors(f, interest_points)
    if descriptor_only:
        surfs = surfs[:,6:]
    return surfs

def dense(f, spacing, scale=None, is_integral=False, include_interest_point=False):
    '''
    desc_array = dense(f, spacing, scale={np.sqrt(spacing)}, is_integral=False, include_interest_point=False)

    Parameters
    ----------
    f : image
        original image
    spacing : integer
        Distance between points
    scale : float, optional
        Scale of interest points. By default, it is set to ``np.sqrt(spacing)``
    is_integral : boolean, optional
        Whether `f` is an integral image
    include_interest_point : bool, optional
        Whether to return interest point information. Default is False

    Returns
    -------
    descriptors : ndarray
        Descriptors at dense points. Note that the interest point is **not
        returned by default**.

    See Also
    --------
    surf : function
        Find interest points and then compute descriptors
    descriptors : function
        Compute descriptors at user provided interest points
    '''
    if scale is None:
        scale = np.sqrt(spacing)
    s0,s1 = f.shape
    x = np.arange(int(spacing/2), s0, int(spacing))
    y = np.arange(int(spacing/2), s1, int(spacing))
    X,Y = np.meshgrid(x,y)
    S = np.zeros(X.shape, dtype=float)
    S += scale
    ips = np.vstack([X.ravel(), Y.ravel(), S.ravel(), np.ones(X.size), np.ones(X.size)])
    return descriptors(f, ips.T, is_integral=is_integral, descriptor_only=(not include_interest_point))


def show_surf(f, spoints, values=None, colors=None):
    '''
    f2 = show_surf(f, spoints, values=None, colors={[(255,0,0)]}):

    Note that this function does not actually display anything, it just builds
    a colour image for you. In order to visualise the image, you will need to
    use another tool such as ``matplotlib``. Alternatively, you can use
    ``mahotas.imsave`` to save it to a file.

    Parameters
    ----------
    f : image
        original image
    spoints : ndarray
        output of `surf`
    values : ndarray, same length as `spoints`, optional
        You can pass classes for each point here. If it is not used, then all
        the points are displayed the same way (or, equivalently,
        ``values=np.zeros(len(spoints))``).
    colors : ndarray, length must be same as ``values.max()``, optional
        points with values ``vi`` will have colour ``colors[vi]``.

    Returns
    -------
    f2 : ndarray
        Colour (Height x Width x 3-Colours) image
    '''
    import mahotas.polygon
    if values is None:
        values = np.zeros(len(spoints), int)
        if colors is None:
            colors = [(255,0,0)]
    if colors is None:
        raise NotImplementedError('mahotas.surf.show_surf: colors is None, but values is not')
    def rotate(y,x, a):
        sa = np.sin(a)
        ca = np.cos(a)
        return (ca*x-sa*y, sa*x+ca*y)

    f2 = np.dstack([f,f,f])

    for p,vi in zip(spoints, values):
        y = p[0]
        x = p[1]
        scale = p[2]
        angle = p[5]
        size = int(scale*10)
        y0 = int(y) - size//2
        x0 = int(x) - size//2
        x1 = x + size
        y1 = y + size
        def rotate_around(p, c, a):
            p0,p1 = p
            c0,c1 = c
            d0 = p0-c0
            d1 = p1 - c1
            d0,d1 = rotate(d0,d1,a)
            return int(c0+d0), int(c1+d1)
        polygon = [(y0,x0), (y0,x1), (y1,x1), (y1,x0), (y0,x0)]
        polygon = [rotate_around(p, (y,x), angle) for p in polygon]
        for p0,p1 in zip(polygon[:-1], polygon[1:]):
            mahotas.polygon.line(p0,p1, f2, color=colors[vi])
    return f2.astype(np.uint8)

########NEW FILE########
__FILENAME__ = tas
# Copyright (C) 2008-2012, Luis Pedro Coelho <luis@luispedro.org>
# vim: set ts=4 sts=4 sw=4 expandtab smartindent:
# Carnegie Mellon University
#
# License: MIT (see COPYING file)

import numpy as np
from ..convolve import convolve
from ..thresholding import otsu

__all__ = ['pftas', 'tas']

_M2 = np.ones((3, 3))
_M2[1, 1] = 10
_bins2 = np.arange(11)

_M3 = np.ones((3, 3, 3))
_M3[1,1,1] = _M3.sum() + 1
_bins3 = np.arange(28)

def _tas(img, thresh, margin):
    if len(img.shape) == 2:
        M = _M2
        bins = _bins2
        saved = 9
    elif len(img.shape) == 3:
        M = _M3
        bins = _bins3
        saved = 27
    else:
        raise ValueError('mahotas.tas: Cannot compute TAS for image of %s dimensions' % len(img.shape))

    def _ctas(img):
        V = convolve(img.astype(np.uint8), M)
        values,_ = np.histogram(V, bins=bins)
        values = values[:saved]
        s = values.sum()
        if s > 0:
            return values/float(s)
        return values

    def _compute(bimg):
        alltas.append(_ctas(bimg))
        allntas.append(_ctas(~bimg))

    alltas = []
    allntas = []
    total = np.sum(img > thresh)
    mu = ((img > thresh)*img).sum() / (total + 1e-8)
    _compute( (img > mu - margin) * (img < mu + margin) )
    _compute(img > mu - margin)
    _compute(img > mu)

    return np.concatenate(alltas + allntas)

def tas(img):
    '''
    values = tas(img)

    Compute Threshold Adjacency Statistics

    TAS were presented by Hamilton et al.  in "Fast automated cell phenotype
    image classification" (http://www.biomedcentral.com/1471-2105/8/110)

    Also returns a version computed on the negative of the binarisation defined
    by Hamilton et al.

    See also pftas() for a variation without any hardcoded parameters.

    Parameters
    ----------
    img : ndarray, 2D or 3D
        input image

    Returns
    -------
    values : ndarray
        A 1-D ndarray of feature values

    See Also
    --------
    pftas : Parameter free TAS
    '''
    return _tas(img, 30, 30)

def pftas(img, T=None):
    '''
    values = pftas(img, T={mahotas.threshold.otsu(img)})

    Compute parameter free Threshold Adjacency Statistics

    TAS were presented by Hamilton et al.  in "Fast automated cell phenotype
    image classification" (http://www.biomedcentral.com/1471-2105/8/110)

    The current version is an adapted version which is free of parameters. The
    thresholding is done by using Otsu's algorithm (or can be pre-computed and
    passed in by setting `T`), the margin around the mean of pixels to be
    included is the standard deviation. This was first published by Coelho et
    al. in "Structured Literature Image Finder: Extracting Information from
    Text and Images in Biomedical Literature"
    (http://www.springerlink.com/content/60634778710577t0/)

    Also returns a version computed on the negative of the binarisation defined
    by Hamilton et al.

    Use tas() to get the original version of the features.

    Parameters
    ----------
    img : ndarray, 2D or 3D
        input image
    T : integer, optional
        Threshold to use (default: compute with otsu)

    Returns
    -------
    values : ndarray
        A 1-D ndarray of feature values
    '''
    if T is None:
        T = otsu(img)
    pixels = img[img > T].ravel()
    if len(pixels) == 0:
        std = 0
    else:
        std = pixels.std()
    return _tas(img, T, std)


########NEW FILE########
__FILENAME__ = texture
# Copyright (C) 2008-2013, Luis Pedro Coelho <luis@luispedro.org>
# vim: set ts=4 sts=4 sw=4 expandtab smartindent:
#
# License: MIT (see COPYING file)


import numpy as np
from . import _texture
from ..internal import _verify_is_integer_type
import math

__all__ = [
    'haralick',
    'haralick_labels',
    'cooccurence',
    ]

def _entropy(p):
    p = p.ravel()
    return -np.dot(np.log2(p+(p==0)),p)


def haralick(f, ignore_zeros=False, preserve_haralick_bug=False, compute_14th_feature=False):
    '''
    feats = haralick(f, ignore_zeros=False, preserve_haralick_bug=False, compute_14th_feature=False)

    Compute Haralick texture features

    Computes the Haralick texture features for the four 2-D directions or
    thirteen 3-D directions (depending on the dimensions of `f`).

    Notes
    -----
    Haralick's paper has a typo in one of the equations. This function
    implements the correct feature unless `preserve_haralick_bug` is True. The
    only reason why you'd want the buggy behaviour is if you want to match
    another implementation.

    References
    ----------

    Cite the following reference for these features::

        @article{Haralick1973,
            author = {Haralick, Robert M. and Dinstein, Its'hak and Shanmugam, K.},
            journal = {Ieee Transactions On Systems Man And Cybernetics},
            number = {6},
            pages = {610--621},
            publisher = {IEEE},
            title = {Textural features for image classification},
            url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4309314},
            volume = {3},
            year = {1973}
        }

    Parameters
    ----------
    f : ndarray of integer type
        input image. 2-D and 3-D images are supported.
    ignore_zeros : bool, optional
        Whether to ignore zero pixels (default: False).

    Other Parameters
    ----------------
    preserve_haralick_bug : bool, optional
        whether to replicate Haralick's typo (default: False).
        You probably want to always set this to ``False`` unless you want to
        replicate someone else's wrong implementation.
    compute_14th_feature : bool, optional
        whether to compute & return the 14-th feature

    Returns
    -------
    feats : ndarray of np.double
        A 4x13 or 4x14 feature vector (one row per direction) if `f` is 2D,
        13x13 or 13x14 if it is 3D. The exact number of features depends on the
        value of ``compute_14th_feature``
    '''
    _verify_is_integer_type(f, 'mahotas.haralick')

    if len(f.shape) == 2:
        nr_dirs = len(_2d_deltas)
    elif len(f.shape) == 3:
        nr_dirs = len(_3d_deltas)
    else:
        raise ValueError('mahotas.texture.haralick: Can only handle 2D and 3D images.')
    fm1 = f.max() + 1
    cmat = np.empty((fm1, fm1), np.int32)
    def all_cmatrices():
        for dir in range(nr_dirs):
            cooccurence(f, dir, cmat, symmetric=True)
            yield cmat
    return haralick_features(all_cmatrices(), ignore_zeros=ignore_zeros, preserve_haralick_bug=preserve_haralick_bug, compute_14th_feature=compute_14th_feature)

def haralick_features(cmats, ignore_zeros=False, preserve_haralick_bug=False, compute_14th_feature=False):
    '''
    features = haralick_features(cmats, ignore_zeros=False, preserve_haralick_bug=False, compute_14th_feature=False)

    Computers Haralick features for the given cooccurrence matrices.

    This function is not usually necessary, as you can call ``haralick`` with
    an image to obtain features for that image. Use only if you know what you
    are doing.

    Notes
    -----
    Haralick's paper has a typo in one of the equations. This function
    implements the correct feature unless `preserve_haralick_bug` is True. The
    only reason why you'd want the buggy behaviour is if you want to match
    another implementation.

    References
    ----------

    Cite the following reference for these features::

        @article{Haralick1973,
            author = {Haralick, Robert M. and Dinstein, Its'hak and Shanmugam, K.},
            journal = {Ieee Transactions On Systems Man And Cybernetics},
            number = {6},
            pages = {610--621},
            publisher = {IEEE},
            title = {Textural features for image classification},
            url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4309314},
            volume = {3},
            year = {1973}
        }


    Parameters
    ----------
    cmats : sequence of ndarrays
        This should be a sequence of ndarrays, all square and all of the same
        shape.
    ignore_zeros : bool, optional
        Whether to ignore zero pixels (default: False).

    Other Parameters
    ----------------
    preserve_haralick_bug : bool, optional
        whether to replicate Haralick's typo (default: False).
        You probably want to always set this to ``False`` unless you want to
        replicate someone else's wrong implementation.
    compute_14th_feature : bool, optional
        whether to compute & return the 14-th feature

    Returns
    -------
    feats : ndarray of np.double
        A 4x13 or 4x14 feature vector (one row per direction) if `f` is 2D,
        13x13 or 13x14 if it is 3D. The exact number of features depends on the
        value of ``compute_14th_feature``

    See Also
    --------
    haralick : function
        compute Haralick features for an image
    '''
    features = []
    for cmat in cmats:
        feats = np.zeros(13 + bool(compute_14th_feature), np.double)
        if ignore_zeros:
            cmat[0] = 0
            cmat[:,0] = 0
        T = cmat.sum()
        if not T:
            continue
        if not len(features):
            maxv = len(cmat)
            k = np.arange(maxv)
            k2 = k**2
            tk = np.arange(2*maxv)
            tk2 = tk**2
            i,j = np.mgrid[:maxv,:maxv]
            ij = i*j
            i_j2_p1 = (i - j)**2
            i_j2_p1 += 1
            i_j2_p1 = 1. / i_j2_p1
            i_j2_p1 = i_j2_p1.ravel()
            px_plus_y = np.empty(2*maxv, np.double)
            px_minus_y = np.empty(maxv, np.double)
        elif maxv != len(cmat):
            raise ValueError('mahotas.haralick_features: All cmatrices must be of the same size')

        p = cmat / float(T)
        pravel = p.ravel()
        px = p.sum(0)
        py = p.sum(1)

        ux = np.dot(px, k)
        uy = np.dot(py, k)
        vx = np.dot(px, k2) - ux**2
        vy = np.dot(py, k2) - uy**2

        sx = np.sqrt(vx)
        sy = np.sqrt(vy)
        px_plus_y.fill(0)
        px_minus_y.fill(0)
        _texture.compute_plus_minus(p, px_plus_y, px_minus_y)

        feats[0] = np.dot(pravel, pravel)
        feats[1] = np.dot(k2, px_minus_y)

        if sx == 0. or sy == 0.:
            feats[2] = 1.
        else:
            feats[2] = (1. / sx / sy) * (np.dot(ij.ravel(), pravel) - ux * uy)

        feats[3] = vx
        feats[4] = np.dot(i_j2_p1, pravel)
        feats[5] = np.dot(tk, px_plus_y)

        feats[7] = _entropy(px_plus_y)

        # There is some confusion w.r.t. feats[6].
        #
        # Haralick's paper uses feats[7] in its computation, but it is
        # clear that feats[5] should be used (i.e., it computes a
        # variance).
        #
        if preserve_haralick_bug:
            feats[6] = ((tk-feats[7])**2*px_plus_y).sum()
        else:
            feats[6] = np.dot(tk2, px_plus_y) - feats[5]**2

        feats[ 8] = _entropy(pravel)
        feats[ 9] = px_minus_y.var()
        feats[10] = _entropy(px_minus_y)

        HX = _entropy(px)
        HY = _entropy(py)
        crosspxpy = np.outer(px,py)
        crosspxpy += (crosspxpy == 0) # This makes log(0) become log(1), and thus evaluate to zero, such that everything works below:
        crosspxpy = crosspxpy.ravel()
        HXY1 = -np.dot(pravel, np.log2(crosspxpy))
        HXY2 = _entropy(crosspxpy)

        if max(HX, HY) == 0.:
            feats[11] = (feats[8]-HXY1)
        else:
            feats[11] = (feats[8]-HXY1)/max(HX,HY)
        feats[12] = np.sqrt(max(0,1 - np.exp( -2. * (HXY2 - feats[8]))))

        if compute_14th_feature:
            # Square root of the second largest eigenvalue of the correlation matrix
            # Probably the faster way to do this is just SVD the whole (likely rank deficient) matrix
            # grab the second highest singular value . . . Instead, we just amputate the empty rows/cols and move on.
            nzero_rc = px != 0
            nz_pmat = p[nzero_rc,:][:,nzero_rc] # Symmetric, so this is ok!
            if nz_pmat.shape[0] > 2:
                ccm = np.corrcoef(nz_pmat)
                e_vals = np.linalg.eigvalsh(ccm)
                e_vals.sort()
                feats[13] = np.sqrt(e_vals[-2])
            else:
                feats[13] = 0
        features.append(feats)

    return np.array(features)


haralick_labels = ["Angular Second Moment",
                   "Contrast",
                   "Correlation",
                   "Sum of Squares: Variance",
                   "Inverse Difference Moment",
                   "Sum Average",
                   "Sum Variance",
                   "Sum Entropy",
                   "Entropy",
                   "Difference Variance",
                   "Difference Entropy",
                   "Information Measure of Correlation 1",
                   "Information Measure of Correlation 2",
                   "Maximal Correlation Coefficient"]

_2d_deltas= [
    (0,1),
    (1,1),
    (1,0),
    (1,-1)]

_3d_deltas = [
    (1, 0, 0),
    (1, 1, 0),
    (0, 1, 0),
    (1,-1, 0),
    (0, 0, 1),
    (1, 0, 1),
    (0, 1, 1),
    (1, 1, 1),
    (1,-1, 1),
    (1, 0,-1),
    (0, 1,-1),
    (1, 1,-1),
    (1,-1,-1) ]

def cooccurence(f, direction, output=None, symmetric=True):
    '''
    cooccurence_matrix = cooccurence(f, direction, output={new matrix})

    Compute grey-level cooccurence matrix

    Parameters
    ----------
    f : ndarray of integer type
        The input image
    direction : integer
        Direction as index into (horizontal [default], diagonal
        [nw-se], vertical, diagonal [ne-sw])
    output : np.long 2 ndarray, optional
        preallocated result.
    symmetric : boolean, optional
        whether return a symmetric matrix (default: False)

    Returns
    -------
      cooccurence_matrix : cooccurence matrix
    '''
    _verify_is_integer_type(f, 'mahotas.cooccurence')
    if len(f.shape) == 2 and not (0 <= direction < 4):
        raise ValueError('mahotas.texture.cooccurence: `direction` {0} is not in range(4).'.format(direction))
    elif len(f.shape) == 3 and not (0 <= direction < 13):
        raise ValueError('mahotas.texture.cooccurence: `direction` {0} is not in range(13).'.format(direction))
    elif len(f.shape) not in (2,3):
        raise ValueError('mahotas.texture.cooccurence: cannot handle images of %s dimensions.' % len(f.shape))

    if output is None:
        mf = f.max()
        output = np.zeros((mf+1, mf+1), np.int32)
    else:
        assert np.min(output.shape) >= f.max(), 'mahotas.texture.cooccurence: output is not large enough'
        assert output.dtype == np.int32, 'mahotas.texture.cooccurence: output is not of type np.int32'
        output.fill(0)

    if len(f.shape) == 2:
        Bc = np.zeros((3, 3), f.dtype)
        y,x = _2d_deltas[direction]
        Bc[y+1,x+1] = 1
    else:
        Bc = np.zeros((3, 3, 3), f.dtype)
        y,x,z = _3d_deltas[direction]
        Bc[y+1,x+1,z+1] = 1
    _texture.cooccurence(f, output, Bc, symmetric)
    return output


########NEW FILE########
__FILENAME__ = zernike
# -*- coding: utf-8 -*-
# Copyright (C) 2006-2012, Luis Pedro Coelho <luis@luispedro.org>
# vim: set ts=4 sts=4 sw=4 expandtab smartindent:
#
# License: MIT (see COPYING file)

from __future__ import division
import numpy as np

from ..center_of_mass import center_of_mass
from . import _zernike

__all__ = ['zernike', 'zernike_moments']

def zernike(im, degree, radius, cm=None): # pragma: no cover
    """
    zvalues = zernike(im, degree, radius, cm={center_of_mass(im)})
    """
    import warnings
    warnings.warn('mahotas.zernike.zernike: This interface is deprecated. Switch the order of your arguments and use ``zernike_moments``', DeprecationWarning)
    return zernike_moments(im, radius, degree, cm)

def zernike_moments(im, radius, degree=8, cm=None):
    """
    zvalues = zernike_moments(im, radius, degree=8, cm={center_of_mass(im)})

    Zernike moments through ``degree``. These are computed on a circle of
    radius ``radius`` centered around ``cm`` (or the center of mass of the
    image, if the ``cm`` argument is not used).

    Returns a vector of absolute Zernike moments through ``degree`` for the
    image ``im``.

    Parameters
    ----------
    im : 2-ndarray
        input image
    radius : integer
        the maximum radius for the Zernike polynomials, in pixels. Note that
        the area outside the circle (centered on center of mass) defined by
        this radius is ignored.
    degree : integer, optional
        Maximum degree to use (default: 8)
    cm : pair of floats, optional
        the centre of mass to use. By default, uses the image's centre of mass.

    Returns
    -------
    zvalues : 1-ndarray of floats
        Zernike moments

    Reference
    ---------
    Teague, MR. (1980). Image Analysis via the General Theory of Moments.  J.
    Opt. Soc. Am. 70(8):920-930.
    """
    zvalues = []
    if cm is None:
        c0,c1 = center_of_mass(im)
    else:
        c0,c1 = cm

    Y,X = np.mgrid[:im.shape[0],:im.shape[1]]
    P = im.ravel()

    def rescale(C, centre):
        Cn = C.astype(np.double)
        Cn -= centre
        Cn /= radius
        return Cn.ravel()
    Yn = rescale(Y, c0)
    Xn = rescale(X, c1)

    Dn = Xn**2
    Dn += Yn**2
    np.sqrt(Dn, Dn)
    k = (Dn <= 1.)
    k &= (P > 0)

    frac_center = np.array(P[k], np.double)
    frac_center = frac_center.ravel()
    frac_center /= frac_center.sum()
    Yn = Yn[k]
    Xn = Xn[k]
    Dn = Dn[k]
    An = np.empty(Yn.shape, np.complex)
    An.real = (Xn/Dn)
    An.imag = (Yn/Dn)

    Ans = [An**p for p in range(2,degree+2)]
    Ans.insert(0, An) # An**1
    Ans.insert(0, np.ones_like(An)) # An**0
    for n in range(degree+1):
        for l in range(n+1):
            if (n-l)%2 == 0:
                z = _zernike.znl(Dn, Ans[l], frac_center, n, l)
                zvalues.append(abs(z))
    return np.array(zvalues)


########NEW FILE########
__FILENAME__ = freeimage
from .io.freeimage import *

########NEW FILE########
__FILENAME__ = histogram
# -*- coding: utf-8 -*-
# Copyright (C) 2009-2010, Luis Pedro Coelho <luis@luispedro.org>
# vim: set ts=4 sts=4 sw=4 expandtab smartindent:
# 
# Permission is hereby granted, free of charge, to any person obtaining a copy
#  of this software and associated documentation files (the "Software"), to deal
#  in the Software without restriction, including without limitation the rights
#  to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
#  copies of the Software, and to permit persons to whom the Software is
#  furnished to do so, subject to the following conditions:
# 
# The above copyright notice and this permission notice shall be included in
#  all copies or substantial portions of the Software.
# 
# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
#  IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
#  FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
#  AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
#  LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
#  OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
#  THE SOFTWARE.

'''
Histogram

:fullhistogram():
    Compute the full histogram for an image.


'''

from __future__ import division
import numpy as np
from . import _histogram
from .internal import _verify_is_integer_type

__all__ = ['fullhistogram']

def fullhistogram(img):
    """
    hist = fullhistogram(img)

    Return a histogram with bins *0, 1, ..., ``img.max()``*.

    After calling this function, it will be true that
    ``hist[i] == (img == i).sum()``, for all ``i``.

    Limitations
    -----------
    Only handles unsigned integer arrays.

    Parameters
    ----------
    img : array-like of an unsigned type
        input image.

    Returns
    -------
    hist : an dnarray of type np.uint32
        This will be of size ``img.max() + 1``.
    """
    _verify_is_integer_type(img, 'fullhistogram')
    img = np.ascontiguousarray(img)
    if img.dtype == np.bool:
        ones = img.sum()
        zeros = img.size - ones
        return np.array([zeros, ones], np.uintc)

    histogram = np.zeros(img.max() + 1, np.uintc)
    _histogram.histogram(img, histogram)
    return histogram



########NEW FILE########
__FILENAME__ = internal
# Copyright (C) 2011-2012, Luis Pedro Coelho <luis@luispedro.org>
# vim: set ts=4 sts=4 sw=4 expandtab smartindent:
#
# License: MIT (see COPYING file)
import numpy as np

def _get_output(array, out, fname, dtype=None, output=None):
    '''
    output = _get_output(array, out, fname, dtype=None, output=None)

    Implements the mahotas output convention:
        (1) if `out` is None, return np.empty(array.shape, array.dtype)
        (2) else verify that output is of right size, shape, and contiguous

    Parameters
    ----------
    array : ndarray
    out : ndarray or None
    fname : str
        Function name. Used in error messages

    Returns
    -------
    output : ndarray
    '''
    detail = '.\nWhen an output argument is used, the checking is very strict as this is a performance feature.'
    if dtype is None:
        dtype = array.dtype
    if output is not None:
        import warnings
        warnings.warn('Using deprecated `output` argument in function `%s`. Please use `out` in the future. It has exactly the same meaning and it matches what numpy uses.' % fname, DeprecationWarning)
        if out is not None:
            warnings.warn('Using both `out` and `output` in function `%s`.\nMahotas is going to ignore the `output` argument and use the `out` version exclusively.' % fname)
        else:
            out = output
    if out is None:
        return np.empty(array.shape, dtype)
    if out.dtype != dtype:
        raise ValueError(
            'mahotas.%s: `out` has wrong type (out.dtype is %s; expected %s)%s' %
                (fname, out.dtype, dtype, detail))
    if out.shape != array.shape:
        raise ValueError('mahotas.%s: `out` has wrong shape (got %s, while expecting %s)%s' % (fname, out.shape, array.shape, detail))
    if not out.flags.contiguous:
        raise ValueError('mahotas.%s: `out` is not c-array%s' % (fname,detail))
    return out

def _get_axis(array, axis, fname):
    '''
    axis = _get_axis(array, axis, fname)

    Checks that ``axis`` is a valid axis of ``array`` and normalises it.

    Parameters
    ----------
    array : ndarray
    axis : int
    fname : str
        Function name. Used in error messages

    Returns
    -------
    axis : int
        The positive index of the axis to use
    '''
    if axis < 0:
        axis += len(array.shape)
    if not (0 <= axis < len(array.shape)):
        raise ValueError('mahotas.%s: `axis` is out of bounds (maximum was %s, got %s)' % (fname, array.ndim, axis))
    return axis

def _normalize_sequence(array, value, fname):
    '''
    values = _normalize_sequence(array, value, fname)

    If `value` is a sequence, checks that it has an element for each dimension
    of `array`. Otherwise, returns a sequence that repeats `value` once for
    each dimension of array.

    Parameters
    ----------
    array : ndarray
    value : sequence or scalar
    fname : str
        Function name. Used in error messages

    Returns
    -------
    values : sequence
    '''
    try:
        value = list(value)
    except TypeError:
        return [value for s in array.shape]
    if len(value) != array.ndim:
        raise ValueError('mahotas.%s: argument is sequence, but has wrong size (%s for an array of %s dimensions)' % (fname, len(value), array.ndim))
    return value

def _verify_is_floatingpoint_type(A, function_name):
    '''
    _verify_is_integer_type(array, "function")

    Checks that ``A`` is a floating-point array. If it is not, it raises
    ``TypeError``.

    Parameters
    ----------
    A : ndarray
    function_name : str
        Used for error messages
    '''
    if not np.issubdtype(A.dtype, np.float):
        raise TypeError('mahotas.%s: This function only accepts floating-point types (passed array of type %s)' % (function_name, A.dtype))

def _verify_is_integer_type(A, function_name):
    '''
    _verify_is_integer_type(array, "function")

    Checks that ``A`` is an integer array. If it is not, it raises
    ``TypeError``.

    Parameters
    ----------
    A : ndarray
    function_name : str
        Used for error messages
    '''
    int_types=[
                np.bool,
                np.uint8,
                np.int8,
                np.uint16,
                np.int16,
                np.uint32,
                np.int32,
                np.int64,
                np.uint64,
                ]
    if A.dtype not in int_types:
        raise TypeError('mahotas.%s: This function only accepts integer types (passed array of type %s)' % (function_name, A.dtype))

def _make_binary(array):
    '''
    bin = _make_binary(array)

    Returns (possibly a copy) of array as a boolean array
    '''
    array = np.asanyarray(array)
    if array.dtype != bool:
        return (array != 0)
    return array

def _as_floating_point_array(array):
    '''
    array = _as_floating_point_array(array)

    Returns (possibly a copy) of array as a floating-point array
    '''
    array = np.asanyarray(array)
    if not np.issubdtype(array.dtype, np.float_):
        return array.astype(np.double)
    return array


def _check_3(arr, funcname):
    if arr.ndim != 3 or arr.shape[2] != 3:
        raise ValueError('mahotas.%s: this function expects an array of shape (h, w, 3), received an array of shape %s.' % (funcname, arr.shape))


########NEW FILE########
__FILENAME__ = interpolate
# This module was adapted from scipy.ndimage and retains its license
# Copyright (C) 2003-2005 Peter J. Verveer
# Copyright (C) 2011-2014 Luis Pedro Coelho
#
# Redistribution and use in source and binary forms, with or without
# modification, are permitted provided that the following conditions
# are met:
#
# 1. Redistributions of source code must retain the above copyright
#    notice, this list of conditions and the following disclaimer.
#
# 2. Redistributions in binary form must reproduce the above
#    copyright notice, this list of conditions and the following
#    disclaimer in the documentation and/or other materials provided
#    with the distribution.
#
# 3. The name of the author may not be used to endorse or promote
#    products derived from this software without specific prior
#    written permission.
#
# THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS
# OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
# WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
# ARE DISCLAIMED. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY
# DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
# DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE
# GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
# INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY,
# WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
# NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
# SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
'''
Interpolation
-------------

This module was adapted from scipy.ndimage
'''

import numpy as np
from . import internal
from . import _interpolate
from ._filters import mode2int, modes, _check_mode

def _check_interpolate(array, order, funcname):
    if not (0 < order < 5):
        raise ValueError('mahotas.interpolate.%s: spline order not supported' % funcname)

    array = np.asarray(array)
    if np.iscomplexobj(array):
        raise TypeError('mahotas.interpolate.%s: Complex type not supported' % funcname)
    return array

def spline_filter1d(array, order=3, axis=-1, out=None, dtype=np.float64, output=None):
    """
    Calculates a one-dimensional spline filter along the given axis.

    The lines of the array along the given axis are filtered by a
    spline filter. The order of the spline must be >= 2 and <= 5.

    Parameters
    ----------
    array : array_like
        The input array.
    order : int, optional
        The order of the spline, default is 3.
    axis : int, optional
        The axis along which the spline filter is applied. Default is the last
        axis.
    out : ndarray, optional
        The array in which to place the output
    dtype : dtype, optional
        The dtype to use for computation (default: np.float64)

    For compatibility with scipy.ndimage, you can pass a dtype as the
    ``output`` argument. This will work as having passed it as a dtype.
    However, this is deprecated and should not be used in new code.

    Returns
    -------
    return_value : ndarray or None
        The filtered input.
    """
    array = _check_interpolate(array, order, 'spline_filter1d')
    if isinstance(out, type): # pragma: no cover
        import warnings
        warnings.warn('mahotas.interpolate.spline_filter1d: Use `dtype` for type instead of `out`', DeprecationWarning)
        dtype = out
        out = None
    if isinstance(output, type): # pragma: no cover
        import warnings
        warnings.warn('mahotas.interpolate.spline_filter1d: Use `dtype` for type instead of `output`', DeprecationWarning)
        dtype = output
        output = None
    output = internal._get_output(array, out, 'interpolate.spline_filter1d', dtype=dtype, output=output)
    output[...] = array
    axis = internal._get_axis(array, axis, 'interpolate.spline_filter1d')
    _interpolate.spline_filter1d(output, order, axis)
    return output


def spline_filter(array, order=3, out=None, dtype=np.float64, output=None):
    """
    Multi-dimensional spline filter.

    Parameters
    ----------
    array : array_like
        The input array.
    order : int, optional
        The order of the spline, default is 3.
        axis.
    out : ndarray, optional
        The array in which to place the output
    dtype : dtype, optional
        The dtype to use for computation (default: np.float64)

    For compatibility with scipy.ndimage, you can pass a dtype as the
    ``out`` argument. This will work as having passed it as a dtype.  However,
    this is deprecated and should not be used in new code.

    Returns
    -------
    return_value : ndarray or None
        The filtered input.

    See Also
    --------
    spline_filter1d

    Notes
    -----
    The multi-dimensional filter is implemented as a sequence of
    one-dimensional spline filters. The intermediate arrays are stored
    in the same data type as the output. Therefore, for output types
    with a limited precision, the results may be imprecise because
    intermediate results may be stored with insufficient precision.

    """
    array = _check_interpolate(array, order, 'spline_filter')
    if isinstance(out, type): # pragma: no cover
        import warnings
        warnings.warn('mahotas.interpolate.spline_filter: Use `dtype` for type instead of `out`', DeprecationWarning)
        dtype = out
        out = None
    if isinstance(output, type): # pragma: no cover
        import warnings
        warnings.warn('mahotas.interpolate.spline_filter: Use `dtype` for type instead of `output`', DeprecationWarning)
        dtype = output
        output = None
    output = internal._get_output(array, out, 'interpolate.spline_filter', dtype=dtype, output=output)
    output[...] = array
    for axis in range(array.ndim):
        _interpolate.spline_filter1d(output, order, axis)
    return output



def _maybe_filter(array, order, func, prefilter, dtype):
    array = _check_interpolate(array, order, func)
    if array.ndim < 1:
        raise ValueError(func+': array rank must be > 0')
    if prefilter and order > 1:
        return spline_filter(array, order, dtype=dtype)
    else:
        return array.astype(dtype)

def zoom(array, zoom, out=None, order=3, mode='constant', cval=0.0, prefilter=True, output=None):
    """
    Zoom an array.

    The array is zoomed using spline interpolation of the requested order.

    Parameters
    ----------
    array : ndarray
        The input array.
    zoom : float or sequence, optional
        The zoom factor along the axes. If a float, `zoom` is the same for each
        axis. If a sequence, `zoom` should contain one value for each axis.
    out : ndarray or dtype, optional
        The array in which to place the output, or the dtype of the returned
        array.
    order : int, optional
        The order of the spline interpolation, default is 3.
        The order has to be in the range 0-5.
    mode : str, optional
        Points outside the boundaries of the input are filled according
        to the given mode ('constant', 'nearest', 'reflect' or 'wrap').
        Default is 'constant'.
    cval : scalar, optional
        Value used for points outside the boundaries of the input if
        ``mode='constant'``. Default is 0.0
    prefilter : bool, optional
        The parameter prefilter determines if the input is pre-filtered with
        `spline_filter` before interpolation (necessary for spline
        interpolation of order > 1).  If False, it is assumed that the input is
        already filtered. Default is True.

    Returns
    -------
    return_value : ndarray
    """
    array = _maybe_filter(array, order, 'interpolate.zoom', prefilter, dtype=np.float64)
    zoom = np.array(zoom)
    if zoom.ndim == 0:
        zoom = np.array([zoom]*array.ndim)
    elif zoom.ndim != 1:
        raise ValueError('mahotas.interpolation.zoom: zoom should be a 1-d array')
    if len(zoom) != array.ndim:
        raise ValueError('mahotas.interpolation.zoom: zoom should have one element for each dimension of array')

    if out is None and output is not None: # pragma: no cover
        import warnings
        warnings.warn('mahotas.interpolate.zoom: Use `out` for output parameter instead of `output`', DeprecationWarning)
        out = output

    if out is None:
        output_shape = tuple([int(s * z) for s,z in zip(array.shape, zoom)])
        out = np.empty(output_shape, dtype=array.dtype)
    zoom_div = np.array(out.shape, float) - 1
    zoom = (np.array(array.shape) - 1) / zoom_div
    zoom = np.ascontiguousarray(zoom)

    # Zooming to infinity is unpredictable, so just choose
    # zoom factor 1 instead
    zoom[np.isinf(zoom)] = 1

    _check_mode(mode, cval, 'interpolation.zoom')
    _interpolate.zoom_shift(array, zoom, None, out, order, mode2int[mode], cval)
    return out


def shift(array, shift, out=None, order=3, mode='constant', cval=0.0,
          prefilter=True, output=None):
    """
    Shift an array.

    The array is shifted using spline interpolation of the requested order.
    Points outside the boundaries of the input are filled according to the
    given mode.

    Parameters
    ----------
    array : ndarray
        The input array.
    shift : float or sequence, optional
        The shift along the axes. If a float, `shift` is the same for each
        axis. If a sequence, `shift` should contain one value for each axis.
    out : ndarray or dtype, optional
        The array in which to place the output, or the dtype of the returned
        array.
    order : int, optional
        The order of the spline interpolation, default is 3.
        The order has to be in the range 0-5.
    mode : str, optional
        Points outside the boundaries of the input are filled according
        to the given mode ('constant', 'nearest', 'reflect' or 'wrap').
        Default is 'constant'.
    cval : scalar, optional
        Value used for points outside the boundaries of the input if
        ``mode='constant'``. Default is 0.0
    prefilter : bool, optional
        The parameter prefilter determines if the input is pre-filtered with
        `spline_filter` before interpolation (necessary for spline
        interpolation of order > 1).  If False, it is assumed that the input is
        already filtered. Default is True.

    Returns
    -------
    return_value : ndarray
        The shifted input.

    """
    array = _maybe_filter(array, order, 'interpolate.shift', prefilter, dtype=np.float64)
    _check_mode(mode, cval, 'interpolation.shift')
    output = internal._get_output(array, out, 'interpolate.shift', dtype=np.float64, output=output)
    shift = np.ascontiguousarray(shift, dtype=np.float64)
    shift *= -1
    _interpolate.zoom_shift(array, None, shift, output, order, mode2int[mode], cval)
    return output



########NEW FILE########
__FILENAME__ = freeimage
import sys
import os
import ctypes
import ctypes.util

import numpy as np


_API = {
    'FreeImage_AllocateT': (
        ctypes.c_void_p,
        [ctypes.c_int,  # type
         ctypes.c_int,  # width
         ctypes.c_int,  # height
         ctypes.c_int,  # bpp
         ctypes.c_uint,  # red_mask
         ctypes.c_uint,  # green_mask
         ctypes.c_uint]),  # blue_mask
    'FreeImage_Save': (
        ctypes.c_int,
        [ctypes.c_int,  # type
         ctypes.c_void_p,  # bitmap
         ctypes.c_char_p,  # filename
         ctypes.c_int]),  # flags
    'FreeImage_SetOutputMessage': (
        None,
        [ctypes.c_void_p]),  # callback
    'FreeImage_ConvertToGreyscale': (
        ctypes.c_void_p,  # FIBITMAP * new_bitmap
        [ctypes.c_void_p]),  # FIBITMAP* bitmap
    'FreeImage_GetFIFFromFilename': (
        ctypes.c_int,  # FREE_IMAGE_FORMAT
        [ctypes.c_char_p]),  # const char* filename
    'FreeImage_IsLittleEndian': (
        ctypes.c_int,  # BOOL
        []),
    'FreeImage_FIFSupportsExportBPP': (
        ctypes.c_int,  # BOOL
        [ctypes.c_int,  # FREE_IMAGE_FORMAT format
         ctypes.c_int]),  # int bpp
    'FreeImage_FIFSupportsExportType': (
        ctypes.c_int,  # BOOL
        [ctypes.c_int,  # FREE_IMAGE_FORMAT fif
         ctypes.c_int]),  # FREE_IMAGE_TYPE type
    'FreeImage_Load': (
        ctypes.c_void_p,
        [ctypes.c_int, ctypes.c_char_p, ctypes.c_int]),
    'FreeImage_Unload': (
        None,
        [ctypes.c_void_p]),
    'FreeImage_GetWidth': (
        ctypes.c_uint,
        [ctypes.c_void_p]),
    'FreeImage_GetHeight': (
        ctypes.c_uint,
        [ctypes.c_void_p]),
    'FreeImage_GetImageType': (
        ctypes.c_uint,
        [ctypes.c_void_p]),
    'FreeImage_GetFileTypeFromMemory': (
        ctypes.c_int,
        [ctypes.c_void_p, ctypes.c_int]),
    'FreeImage_GetFileType': (
        ctypes.c_int,
        [ctypes.c_char_p, ctypes.c_int]),
    'FreeImage_GetBPP': (
        ctypes.c_uint,
        [ctypes.c_void_p]),
    'FreeImage_GetPitch': (
        ctypes.c_uint,
        [ctypes.c_void_p]),
    'FreeImage_OpenMultiBitmap': (
        ctypes.c_void_p,  # FIMULTIBITMAP*
        [ctypes.c_int,  # FREE_IMAGE_FORMAT format
         ctypes.c_char_p,  # filename
         ctypes.c_int,  # BOOL create_new
         ctypes.c_int,  # BOOL read_only
         ctypes.c_int,  # BOOL keep_cache_in_memory
         ctypes.c_int]),  # int flags
    'FreeImage_GetPageCount': (
        ctypes.c_int,
        [ctypes.c_void_p]),
    'FreeImage_AppendPage': (
        None,
        [ctypes.c_void_p,  # FIMULTIBITMAP*
         ctypes.c_void_p]),  # BITMAP
    'FreeImage_LockPage': (
        ctypes.c_void_p,  # FIBITMAP*
        [ctypes.c_void_p,  # FIMULTIBITMAP
         ctypes.c_int]),  # int page
    'FreeImage_UnlockPage': (
        None,
        [ctypes.c_void_p,  # FIMULTIBITMAP*
         ctypes.c_void_p,  # FIBITMAP* data
         ctypes.c_int]),  # BOOL changed
    'FreeImage_CloseMultiBitmap': (
        ctypes.c_int,  # BOOL
        [ctypes.c_void_p,  # FIMULTIBITMAP* bitmap
         ctypes.c_int]),  # int flags
    'FreeImage_GetBits': (
        ctypes.c_void_p,
        [ctypes.c_void_p]),
    'FreeImage_OpenMemory': (
        ctypes.c_void_p,
        [ctypes.c_void_p, ctypes.c_uint32]),
    'FreeImage_AcquireMemory': (
        ctypes.c_int,
        [ctypes.c_void_p, ctypes.POINTER(ctypes.c_void_p),
         ctypes.POINTER(ctypes.c_int)]),
    'FreeImage_CloseMemory': (
        None,
        [ctypes.c_void_p]),
    'FreeImage_LoadFromMemory': (
        ctypes.c_void_p,
        [ctypes.c_int, ctypes.c_void_p, ctypes.c_int]),
    'FreeImage_SaveToMemory': (
        ctypes.c_int,
        [ctypes.c_int, ctypes.c_void_p, ctypes.c_void_p, ctypes.c_int]),
    }


class _ctypes_wrapper(object):
    pass


# Albert's ctypes pattern
def _register_api(lib, api):
    nlib = _ctypes_wrapper()
    for f, (restype, argtypes) in api.items():
        try:
            func = getattr(lib, f)
            func.restype = restype
            func.argtypes = argtypes
            setattr(nlib, f, func)
        except Exception:

            def error_raise(*args):
                raise RuntimeError(
                    'mahotas.freeimage: Function `%s` not found in your'
                    ' version of FreeImage. It might be an older version' % f)
            setattr(nlib, f, error_raise)
    return nlib

if sys.platform == 'win32':

    def _load_library(dllname, loadfunction, dllpaths=('', )):
        """Load a DLL via ctypes load function. Return None on failure.

        Try loading the DLL from the current package directory first,
        then from the Windows DLL search path.

        """
        try:
            dllpaths = (os.path.abspath(os.path.dirname(__file__)),
                        ) + dllpaths
        except NameError:
            pass  # no __file__ attribute on PyPy and some frozen distributions
        for path in dllpaths:
            if path:
                # temporarily add the path to the PATH environment variable
                # so Windows can find additional DLL dependencies.
                try:
                    oldenv = os.environ['PATH']
                    os.environ['PATH'] = path + ';' + oldenv
                except KeyError:
                    oldenv = None
            try:
                return loadfunction(os.path.join(path, dllname))
            except (WindowsError, OSError):
                pass
            finally:
                if path and oldenv is not None:
                    os.environ['PATH'] = oldenv
        return None

    _FI = _load_library('FreeImage.dll', ctypes.windll.LoadLibrary)
    if not _FI:
        raise OSError("mahotas.freeimage: could not find FreeImage.dll")

else:
    libname = ctypes.util.find_library('freeimage')
    if libname:
        _FI = ctypes.CDLL(libname)
    else:
        _FI = None
        _lib_dirs = os.environ.get('LD_LIBRARY_PATH', '').split(':')
        _lib_dirs = [_f for _f in _lib_dirs if _f]
        _lib_dirs.extend([
            os.path.dirname(__file__),
            '/lib',
            '/usr/lib',
            '/usr/local/lib',
            '/opt/local/lib',
            ])
        _possible_filenames = (
            'libfreeimage',
            'libFreeImage',
            )
        for d in _lib_dirs:
            for libname in _possible_filenames:
                try:
                    _FI = np.ctypeslib.load_library(libname, d)
                except OSError:
                    pass
                else:
                    break
            if _FI is not None:
                break
    if not _FI:
        raise OSError(
            'mahotas.freeimage: could not find libFreeImage in any of the'
            'following directories: \'%s\'' % '\', \''.join(_lib_dirs))

_FI = _register_api(_FI, _API)

if sys.platform == 'win32':
    _functype = ctypes.WINFUNCTYPE
else:
    _functype = ctypes.CFUNCTYPE


@_functype(None, ctypes.c_int, ctypes.c_char_p)
def _error_handler(fif, message):
    raise RuntimeError('mahotas.freeimage: FreeImage error: %s' % message)

_FI.FreeImage_SetOutputMessage(_error_handler)


class FI_TYPES(object):
    FIT_UNKNOWN = 0
    FIT_BITMAP = 1
    FIT_UINT16 = 2
    FIT_INT16 = 3
    FIT_UINT32 = 4
    FIT_INT32 = 5
    FIT_FLOAT = 6
    FIT_DOUBLE = 7
    FIT_COMPLEX = 8
    FIT_RGB16 = 9
    FIT_RGBA16 = 10
    FIT_RGBF = 11
    FIT_RGBAF = 12

    dtypes = {
        FIT_BITMAP: np.uint8,
        FIT_UINT16: np.uint16,
        FIT_INT16: np.int16,
        FIT_UINT32: np.uint32,
        FIT_INT32: np.int32,
        FIT_FLOAT: np.float32,
        FIT_DOUBLE: np.float64,
        FIT_COMPLEX: np.complex128,
        FIT_RGB16: np.uint16,
        FIT_RGBA16: np.uint16,
        FIT_RGBF: np.float32,
        FIT_RGBAF: np.float32}

    fi_types = {
        (np.uint8, 1): FIT_BITMAP,
        (np.uint8, 3): FIT_BITMAP,
        (np.uint8, 4): FIT_BITMAP,
        (np.uint16, 1): FIT_UINT16,
        (np.int16, 1): FIT_INT16,
        (np.uint32, 1): FIT_UINT32,
        (np.int32, 1): FIT_INT32,
        (np.float32, 1): FIT_FLOAT,
        (np.float64, 1): FIT_DOUBLE,
        (np.complex128, 1): FIT_COMPLEX,
        (np.uint16, 3): FIT_RGB16,
        (np.uint16, 4): FIT_RGBA16,
        (np.float32, 3): FIT_RGBF,
        (np.float32, 4): FIT_RGBAF}

    extra_dims = {
        FIT_UINT16: [],
        FIT_INT16: [],
        FIT_UINT32: [],
        FIT_INT32: [],
        FIT_FLOAT: [],
        FIT_DOUBLE: [],
        FIT_COMPLEX: [],
        FIT_RGB16: [3],
        FIT_RGBA16: [4],
        FIT_RGBF: [3],
        FIT_RGBAF: [4]}

    @classmethod
    def get_type_and_shape(cls, bitmap):
        w = _FI.FreeImage_GetWidth(bitmap)
        h = _FI.FreeImage_GetHeight(bitmap)
        fi_type = _FI.FreeImage_GetImageType(bitmap)
        if not fi_type:
            raise ValueError('mahotas.freeimage: unknown image pixel type')
        dtype = cls.dtypes[fi_type]
        if fi_type == cls.FIT_BITMAP:
            bpp = _FI.FreeImage_GetBPP(bitmap)
            if bpp == 1:
                # This is a special case
                return 'bit', None
            elif bpp == 8:
                extra_dims = []
            elif bpp == 16:
                extra_dims = []
                dtype = np.uint16
            elif bpp == 24:
                extra_dims = [3]
            elif bpp == 32:
                extra_dims = [4]
            else:
                raise ValueError(
                    'mahotas.freeimage: cannot convert %d BPP bitmap' % bpp)
        else:
            extra_dims = cls.extra_dims[fi_type]
        return np.dtype(dtype), extra_dims + [w, h]


class IO_FLAGS(object):
    #Bmp
    BMP_DEFAULT = 0
    BMP_SAVE_RLE = 1

    #Png
    PNG_DEFAULT = 0
    PNG_IGNOREGAMMA = 1

    #Gif
    GIF_DEFAULT = 0
    GIF_LOAD256 = 1
    GIF_PLAYBACK = 2

    #Ico
    ICO_DEFAULT = 0
    ICO_MAKEALPHA = 1

    #Tiff
    TIFF_DEFAULT = 0
    TIFF_CMYK = 0x0001
    TIFF_NONE = 0x0800
    TIFF_PACKBITS = 0x0100
    TIFF_DEFLATE = 0x0200
    TIFF_ADOBE_DEFLATE = 0x0400
    TIFF_CCITTFAX3 = 0x1000
    TIFF_CCITTFAX4 = 0x2000
    TIFF_LZW = 0x4000
    TIFF_JPEG = 0x8000

    #Jpeg
    JPEG_DEFAULT = 0
    JPEG_FAST = 1
    JPEG_ACCURATE = 2
    JPEG_QUALITYSUPERB = 0x80
    JPEG_QUALITYGOOD = 0x100
    JPEG_QUALITYNORMAL = 0x200
    JPEG_QUALITYAVERAGE = 0x400
    JPEG_QUALITYBAD = 0x800
    JPEG_CMYK = 0x1000
    JPEG_PROGRESSIVE = 0x2000

    #Others...
    CUT_DEFAULT = 0
    DDS_DEFAULT = 0
    HDR_DEFAULT = 0
    IFF_DEFAULT = 0
    KOALA_DEFAULT = 0
    LBM_DEFAULT = 0
    MNG_DEFAULT = 0
    PCD_DEFAULT = 0
    PCD_BASE = 1
    PCD_BASEDIV4 = 2
    PCD_BASEDIV16 = 3
    PCX_DEFAULT = 0
    PNM_DEFAULT = 0
    PNM_SAVE_RAW = 0
    PNM_SAVE_ASCII = 1
    PSD_DEFAULT = 0
    RAS_DEFAULT = 0
    TARGA_DEFAULT = 0
    TARGA_LOAD_RGB888 = 1
    WBMP_DEFAULT = 0
    XBM_DEFAULT = 0


class METADATA_MODELS(object):
    FIMD_NODATA = -1
    FIMD_COMMENTS = 0
    FIMD_EXIF_MAIN = 1
    FIMD_EXIF_EXIF = 2
    FIMD_EXIF_GPS = 3
    FIMD_EXIF_MAKERNOTE = 4
    FIMD_EXIF_INTEROP = 5
    FIMD_IPTC = 6
    FIMD_XMP = 7
    FIMD_GEOTIFF = 8
    FIMD_ANIMATION = 9
    FIMD_CUSTOM = 10


class FI_FORMAT(object):
    FIF_UNKNOWN = -1
    FIF_BMP = 0
    FIF_ICO = 1
    FIF_JPEG = 2
    FIF_JNG = 3
    FIF_KOALA = 4
    FIF_LBM = 5
    FIF_IFF = FIF_LBM
    FIF_MNG = 6
    FIF_PBM = 7
    FIF_PBMRAW = 8
    FIF_PCD = 9
    FIF_PCX = 10
    FIF_PGM = 11
    FIF_PGMRAW = 12
    FIF_PNG = 13
    FIF_PPM = 14
    FIF_PPMRAW = 15
    FIF_RAS = 16
    FIF_TARGA = 17
    FIF_TIFF = 18
    FIF_WBMP = 19
    FIF_PSD = 20
    FIF_CUT = 21
    FIF_XBM = 22
    FIF_XPM = 23
    FIF_DDS = 24
    FIF_GIF = 25
    FIF_HDR = 26
    FIF_FAXG3 = 27
    FIF_SGI = 28
    FIF_EXR = 29
    FIF_J2K = 30
    FIF_JP2 = 31
    FIF_PFM = 32
    FIF_PICT = 33
    FIF_RAW = 34


def read(filename, flags=0):
    """Read an image to a numpy array of shape (width, height) for
    greyscale images, or shape (width, height, nchannels) for RGB or
    RGBA images.

    """
    bitmap = _read_bitmap(filename, flags)
    try:
        return _array_from_bitmap(bitmap)
    finally:
        _FI.FreeImage_Unload(bitmap)


def read_multipage(filename, flags=0):
    """Read a multipage image to a list of numpy arrays, where each
    array is of shape (width, height) for greyscale images, or shape
    (nchannels, width, height) for RGB or RGBA images.

    """
    ftype = _FI.FreeImage_GetFileType(_bytestr(filename), 0)
    if ftype == -1:
        raise ValueError(
            'mahotas.freeimage: cannot determine type of file %s'%filename)
    create_new = False
    read_only = True
    keep_cache_in_memory = True
    multibitmap = _FI.FreeImage_OpenMultiBitmap(
        ftype, _bytestr(filename), create_new, read_only, keep_cache_in_memory,
        flags)
    if not multibitmap:
        raise ValueError(
            'mahotas.freeimage: could not open %s'
            ' as multi-page image.' % filename)
    try:
        pages = _FI.FreeImage_GetPageCount(multibitmap)
        arrays = []
        for i in range(pages):
            bitmap = _FI.FreeImage_LockPage(multibitmap, i)
            try:
                arrays.append(_array_from_bitmap(bitmap))
            finally:
                _FI.FreeImage_UnlockPage(multibitmap, bitmap, False)
        return arrays
    finally:
        _FI.FreeImage_CloseMultiBitmap(multibitmap, 0)


def _read_bitmap(filename, flags):
    """Load a file to a FreeImage bitmap pointer"""
    ftype = _FI.FreeImage_GetFileType(_bytestr(filename), 0)
    if ftype == -1:
        raise ValueError(
            'mahotas.freeimage: cannot determine type of file %s' % filename)
    bitmap = _FI.FreeImage_Load(ftype, _bytestr(filename), flags)
    if not bitmap:
        raise ValueError(
            'mahotas.freeimage: could not load file %s' % filename)
    return bitmap


def _wrap_bitmap_bits_in_array(bitmap, shape, dtype):
    """Return an ndarray view on the data in a FreeImage bitmap. Only
    valid for as long as the bitmap is loaded (if single page) / locked
    in memory (if multipage).

    """
    pitch = _FI.FreeImage_GetPitch(bitmap)
    itemsize = dtype.itemsize

    if len(shape) == 3:
        strides = (itemsize, shape[0]*itemsize, pitch)
    else:
        strides = (itemsize, pitch)
    bits = _FI.FreeImage_GetBits(bitmap)

    class DummyArray(object):
        __array_interface__ = {
            'data': (bits, False),
            'strides': strides,
            'typestr': dtype.str,
            'shape': tuple(shape),
            'version': 3,
            }

    return np.array(DummyArray(), copy=False)


def _array_from_bitmap(bitmap):
    """Convert a FreeImage bitmap pointer to a numpy array

    """
    dtype, shape = FI_TYPES.get_type_and_shape(bitmap)
    if type(dtype) == str and dtype == 'bit':
        bitmap8 = _FI.FreeImage_ConvertToGreyscale(bitmap)
        try:
            return _array_from_bitmap(bitmap8).astype(np.bool)
        finally:
            _FI.FreeImage_Unload(bitmap8)
    array = _wrap_bitmap_bits_in_array(bitmap, shape, dtype)

    # swizzle the color components and flip the scanlines to go from
    # FreeImage's BGR[A] and upside-down internal memory format to something
    # more normal
    def n(arr):
        return arr[..., ::-1].T

    if (len(shape) == 3 and _FI.FreeImage_IsLittleEndian() and
        dtype.type == np.uint8):
        b = n(array[0])
        g = n(array[1])
        r = n(array[2])
        if shape[0] == 3:
            return np.dstack((r, g, b))
        elif shape[0] == 4:
            a = n(array[3])
            return np.dstack((r, g, b, a))
        else:
            raise ValueError(
                'mahotas.freeimage: cannot handle images of'
                ' this shape (%s)' % shape)

    # We need to copy because array does *not* own its memory
    # after bitmap is freed.
    return n(array).copy()


def string_tag(bitmap, key, model=METADATA_MODELS.FIMD_EXIF_MAIN):
    """Retrieve the value of a metadata tag with the given string key as a
    string."""
    tag = ctypes.c_int()
    if not _FI.FreeImage_GetMetadata(model, bitmap, _bytestr(key),
                                     ctypes.byref(tag)):
        return
    char_ptr = ctypes.c_char * _FI.FreeImage_GetTagLength(tag)
    return char_ptr.from_address(_FI.FreeImage_GetTagValue(tag)).raw()


def write(array, filename, flags=0):
    """Write a (width, height) or (width, height, nchannels) array to
    a greyscale, RGB, or RGBA image, with file type deduced from the
    filename.

    """
    filename = _bytestr(filename)
    ftype = _FI.FreeImage_GetFIFFromFilename(filename)
    if ftype == -1:
        raise ValueError(
            'mahotas.freeimage: cannot determine type for %s' % filename)
    bitmap, fi_type = _array_to_bitmap(array)
    try:
        if fi_type == FI_TYPES.FIT_BITMAP:
            can_write = _FI.FreeImage_FIFSupportsExportBPP(ftype,
                                      _FI.FreeImage_GetBPP(bitmap))
        else:
            can_write = _FI.FreeImage_FIFSupportsExportType(ftype, fi_type)
        if not can_write:
            raise TypeError(
                'mahotas.freeimage: cannot save image of this type (%s) '
                'to this file type' % array.dtype)
        res = _FI.FreeImage_Save(ftype, bitmap, filename, flags)
        if not res:
            raise RuntimeError(
                'mahotas.freeimage: could not save image properly.')
    finally:
        _FI.FreeImage_Unload(bitmap)


def write_multipage(arrays, filename, flags=0):
    """Write a list of (width, height) or (nchannels, width, height)
    arrays to a multipage greyscale, RGB, or RGBA image, with file type
    deduced from the filename.

    """
    ftype = _FI.FreeImage_GetFIFFromFilename(_bytestr(filename))
    if ftype == -1:
        raise ValueError(
            'mahotas.freeimage: cannot determine type of file %s' % filename)
    create_new = True
    read_only = False
    keep_cache_in_memory = True
    multibitmap = _FI.FreeImage_OpenMultiBitmap(
        ftype, _bytestr(filename), create_new, read_only,
        keep_cache_in_memory, 0)
    if not multibitmap:
        raise ValueError(
            'mahotas.freeimage: could not open %s '
            'for writing multi-page image.' % filename)
    try:
        for array in arrays:
            bitmap, _ = _array_to_bitmap(array)
            _FI.FreeImage_AppendPage(multibitmap, bitmap)
    finally:
        _FI.FreeImage_CloseMultiBitmap(multibitmap, flags)


def _array_to_bitmap(array):
    """Allocate a FreeImage bitmap and copy a numpy array into it.

    """
    shape = array.shape
    dtype = array.dtype
    r, c = shape[:2]
    if len(shape) == 2:
        n_channels = 1
        w_shape = (c, r)
    elif len(shape) == 3:
        n_channels = shape[2]
        w_shape = (n_channels, c, r)
    else:
        raise ValueError(
            'mahotas.freeimage: cannot handle image of 4 dimensions')
    try:
        fi_type = FI_TYPES.fi_types[(dtype.type, n_channels)]
    except KeyError:
        raise ValueError(
            'mahotas.freeimage: cannot write arrays of given type and shape.')

    itemsize = array.dtype.itemsize
    bpp = 8 * itemsize * n_channels
    bitmap = _FI.FreeImage_AllocateT(fi_type, c, r, bpp, 0, 0, 0)
    if not bitmap:
        raise RuntimeError(
            'mahotas.freeimage: could not allocate image for storage')
    try:

        def n(arr):  # normalise to freeimage's in-memory format
            return arr.T[:, ::-1]

        wrapped_array = _wrap_bitmap_bits_in_array(bitmap, w_shape, dtype)
        # swizzle the color components and flip the scanlines to go to
        # FreeImage's BGR[A] and upside-down internal memory format
        if (len(shape) == 3 and _FI.FreeImage_IsLittleEndian() and
            dtype.type == np.uint8):
            wrapped_array[0] = n(array[:, :, 2])
            wrapped_array[1] = n(array[:, :, 1])
            wrapped_array[2] = n(array[:, :, 0])
            if shape[2] == 4:
                wrapped_array[3] = n(array[:, :, 3])
        else:
            wrapped_array[:] = n(array)

        return bitmap, fi_type
    except:
        _FI.FreeImage_Unload(bitmap)
        raise


def imsavetoblob(img, filetype, flags=0):
    """
    s = imsavetoblob(img, filetype, flags=0)

    Save `img` to a `str` object

    Parameters
    ----------
    img : ndarray
        input image
    filetype : str or integer
        A file name like string, used only to determine the file type.
        Alternatively, an integer flag (from FI_FORMAT).
    flags : integer, optional

    Returns
    -------
    s : str
        byte representation of `img` in format `filetype`
    """
    if type(filetype) == str:
        ftype = _FI.FreeImage_GetFIFFromFilename(_bytestr(filetype))
    else:
        ftype = filetype
    try:
        bitmap, fi_type = _array_to_bitmap(img)
        mem = _FI.FreeImage_OpenMemory(0, 0)
        if not _FI.FreeImage_SaveToMemory(ftype, bitmap, mem, flags):
            raise IOError(
                'mahotas.freeimage.imsavetoblob: Cannot save to memory.')
        data = ctypes.c_void_p()
        size = ctypes.c_int()
        _FI.FreeImage_AcquireMemory(
            mem, ctypes.byref(data), ctypes.byref(size))
        return ctypes.string_at(data, size)
    finally:
        _FI.FreeImage_CloseMemory(mem)


def imreadfromblob(blob, ftype=None, as_grey=False):
    """
    arr = imreadfromblob(blob, ftype={auto}, as_grey=False)

    Read an image from a blob (string)

    Parameters
    ----------
    blob : str
        Input
    filetype : integer, optional
        input type. By default, infer from image.
    as_grey : boolean, optional
        whether to convert colour images to grey scale

    Returns
    -------
    arr : ndarray
    """
    try:
        mem = _FI.FreeImage_OpenMemory(blob, len(blob))
        if ftype is None:
            ftype = _FI.FreeImage_GetFileTypeFromMemory(mem, 0)
        bitmap = _FI.FreeImage_LoadFromMemory(ftype, mem, 0)
        img = _array_from_bitmap(bitmap)
        if as_grey and len(img.shape) == 3:
            # these are the values that wikipedia says are typical
            transform = np.array([0.30, 0.59, 0.11])
            return np.dot(img, transform)
        return img
    finally:
        _FI.FreeImage_CloseMemory(mem)


def imread(filename, as_grey=False):
    """
    img = imread(filename, as_grey=False)

    Reads an image from file `filename`

    Parameters
    ----------
      filename : file name
      as_grey : Whether to convert to grey scale image (default: no)

    Returns
    -------
      img : ndarray
    """
    img = read(filename)
    if as_grey and len(img.shape) == 3:
        # these are the values that wikipedia says are typical
        transform = np.array([0.30, 0.59, 0.11])
        return np.dot(img, transform)
    return img


def imsave(filename, img):
    """
    imsave(filename, img)

    Save image to disk

    Image type is inferred from filename

    Parameters
    ----------
      filename : file name
      img : image to be saved as nd array
    """
    write(img, filename)


if sys.version_info[0] > 2:
    import locale
    _, _encoding = locale.getdefaultlocale()
    if _encoding is None:
        _encoding = 'UTF-8'
    _bytestr = lambda x: x.encode(_encoding)
else:
    _bytestr = str

########NEW FILE########
__FILENAME__ = matplotlibwrap
# vim: set ts=4 sts=4 sw=4 expandtab smartindent:
#
# Copyright (C) 2013  Luis Pedro Coelho
# 
# License: MIT (see COPYING file)

import numpy as np

# Importing matplotlib checks that it is importable without triggering any
# initialization (unlike importing pyplot)
import matplotlib

def imread(filename, as_grey=False):
    """
    img = imread(filename, as_grey=False)

    Reads an image from file `filename`

    Parameters
    ----------
      filename : file name
      as_grey : Whether to convert to grey scale image (default: no)

    Returns
    -------
      img : ndarray
    """
    from matplotlib import pyplot as plt
    img = plt.imread(filename)
    if as_grey and len(img.shape) == 3:
        # these are the values that wikipedia says are typical
        transform = np.array([0.30, 0.59, 0.11])
        return np.dot(img, transform)
    return img

def imsave(filename, array):
    '''
    imsave(filename, array)

    Writes `array` into file `filename`

    Parameters
    ----------
    filename : str
        path on file system
    array : ndarray-like
    '''
    from matplotlib import pyplot as plt
    import numpy as np
    if len(array.shape) == 2:
        import warnings
        warnings.warn('mahotas.imsave: The `matplotlib` backend does not support saving greyscale images natively.\n'
                    'Emulating by saving in RGB format (with all channels set to same value).\n'
                    'If this is a problem, please use another IO backend\n'
                    '\n'
                    'See http://mahotas.readthedocs.org/en/latest/io.html \n'
                    )
        array = np.dstack([array, array, array])
    plt.imsave(filename, array)


########NEW FILE########
__FILENAME__ = labeled
# Copyright (C) 2008-2014, Luis Pedro Coelho <luis@luispedro.org>
# vim: set ts=4 sts=4 sw=4 expandtab smartindent:
#
# LICENSE: MIT

from __future__ import division
import numpy as np
from .morph import get_structuring_elem
from . import _labeled
from .internal import _get_output
from ._filters import mode2int, modes, _check_mode
import mahotas as mh

__all__ = [
    'borders',
    'border',
    'bwperim',
    'label',
    'labeled_sum',
    'labeled_max',
    'labeled_size',
    'relabel',
    'is_same_labeling',
    'perimeter',
    'remove_bordering',
    'remove_regions',
    'remove_regions_where',
    ]

def label(array, Bc=None, out=None, output=None):
    '''
    labeled, nr_objects = label(array, Bc={3x3 cross}, output={new array})

    Label the array, which is interpreted as a binary array

    This is also called *connected component labeled*, where the connectivity
    is defined by the structuring element ``Bc``.

    See: http://en.wikipedia.org/wiki/Connected-component_labeling

    Parameters
    ----------
    array : ndarray
        This will be interpreted as binary array
    Bc : ndarray, optional
        This is the structuring element to use
    out : ndarray, optional
        Output array. Must be a C-array, of type np.int32

    Returns
    -------
    labeled : ndarray
        Labeled result
    nr_objects : int
        Number of objects
    '''
    output = _get_output(array, out, 'labeled.label', np.int32, output=output)
    output[:] = (array != 0)
    Bc = get_structuring_elem(output, Bc)
    nr_objects = _labeled.label(output, Bc)
    return output, nr_objects

def relabel(labeled, inplace=False):
    '''
    relabeled, nr_objs = relabel(labeled, inplace=False)

    Relabeling ensures that ``relabeled`` is a labeled image such that every
    label from 1 to ``relabeled.max()`` is used (0 is reserved for the
    background and is passed through).

    Example::

        labeled,n = label(some_binary_map)
        for region in xrange(n):
            if not good_region(labeled, region + 1):
                # This deletes the region:
                labeled[labeled == (region + 1)] = 0
        relabel(labeled, inplace=True)

    Parameters
    ----------
    relabeled : ndarray of int
        A labeled array
    inplace : boolean, optional
        Whether to perform relabeling inplace, erasing the values in
        ``labeled`` (default: False)

    Returns
    -------
    relabeled: ndarray
    nr_objs : int
        Number of objects

    See Also
    --------
    label : function
    '''
    labeled = _as_labeled(labeled, labeled, 'relabel', inplace=inplace)
    n = _labeled.relabel(labeled)
    return labeled, n

def is_same_labeling(labeled0, labeled1):
    '''
    same = is_same_labeling(labeled0, labeled1)

    Checks whether ``labeled0`` and ``labeled1`` represent the same labeling
    (i.e., whether they are the same except for a possible change of label
    values).

    Note that the background (value 0) is treated differently. Namely

    is_same_labeling(a, b) implies np.all( (a == 0) == (b == 0) )

    Parameters
    ----------
    labeled0 : ndarray of int
        A labeled array
    labeled1 : ndarray of int
        A labeled array

    Returns
    -------
    same : bool
        Number of objects

    See Also
    --------
    label : function
    relabel : function
    '''
    labeled0 = _convert_labeled(labeled0)
    labeled1 = _convert_labeled(labeled1)
    return _labeled.is_same_labeling(labeled0, labeled1)


def remove_regions(labeled, regions, inplace=False):
    '''
    removed = remove_regions(labeled, regions, inplace=False):

    Removes the regions in ``regions``. If an elementwise ``in`` operator
    existed, this would be equivalent to the following::

        labeled[ labeled element-wise-in regions ] = 0

    This function **does not** relabel its arguments. You can use the
    ``relabel`` function for that::

        removed = relabel(remove_regions(labeled, regions))

    Or, saving one image allocation::

        removed = relabel(remove_regions(labeled, regions), inplace=True)

    This is the same, but reuses the memory in the relabeling operation.

    Parameters
    ----------
    relabeled : ndarray of int
        A labeled array
    regions : sequence of int
        These regions will be removed
    inplace : boolean, optional
        Whether to perform removal inplace, erasing the values in
        ``labeled`` (default: False)

    Returns
    -------
    removed : ndarray

    See Also
    --------
    relabel : function
        After removing unecessary regions, it is often a good idea to relabel
        your label image.
    '''
    labeled = _as_labeled(labeled, labeled, 'remove_regions', inplace=inplace)
    regions = np.asarray(regions, dtype=np.intc)
    regions = np.unique(regions)
    _labeled.remove_regions(labeled, regions)
    return labeled


def remove_regions_where(labeled, conditions, inplace=False):
    '''Remove regions based on a boolean array

    A region is removed if ``conditions[region-id]`` evaluates true.

    This function **does not** relabel its arguments. You can use the
    ``relabel`` function for that::

        removed = relabel(remove_regions_where(labeled, conditions))

    Or, saving one image allocation::

        removed = relabel(remove_regions(labeled, conditions), inplace=True)

    This is the same, but reuses the memory in the relabeling operation.


    See Also
    --------
    remove_regions : function
        Variation of this function which uses integer indexing
    '''
    regions, = np.where(conditions)
    return remove_regions(labeled, regions, inplace=inplace)


def remove_bordering(labeled, rsize=1, out=None, output=None):
    '''
    slabeled = remove_bordering(labeled, rsize=1, out={np.empty_like(im)})

    Remove objects that are touching the border.

    Pass ``labeled`` as ``out`` to achieve in-place operation.

    Parameters
    ----------
    labeled : ndarray
        Labeled array
    rsize : int or tuple, optional
        Minimum distance to the border (in Manhatan distance) to allow an
        object to survive. May be int or tuple with len == labeled.ndim.
    out : ndarray, optional
        If ``im`` is passed as ``out``, then it operates inline.

    Returns
    -------
    slabeled : ndarray
        Subset of ``labeled``
    '''
    im = labeled
    invalid = set()
    index = [slice(None,None,None) for _ in range(im.ndim)]
    if type(rsize) is not tuple:
        rsize = (rsize,)*im.ndim
    for dim in range(im.ndim):
        for bordering in (
                    slice(rsize[dim]),
                    slice(im.shape[dim]-rsize[dim], None)
                        ):
            index[dim] = bordering
            for val in np.unique(im[tuple(index)].ravel()):
                if val != 0:
                    invalid.add(val)
        index[dim] = slice(None,None,None)
    if out is None and output is not None: #pragma: no cover
        import warnings
        warnings.warn('Using deprecated `output` argument in function `%s`. Please use `out` in the future.' % 'remove_bordering', DeprecationWarning)
        out = output
    if out is None:
        out = im.copy()
    elif out is not im:
        out[:] = im
    for val in invalid:
        out *= (im != val)
    return out


def border(labeled, i, j, Bc=None, out=None, always_return=True, output=None):
    '''
    border_img = border(labeled, i, j, Bc={3x3 cross}, out={np.zeros(labeled.shape, bool)}, always_return=True)

    Compute the border region between `i` and `j` regions.

    A pixel is on the border if it has value `i` (or `j`) and a pixel in its
    neighbourhood (defined by `Bc`) has value `j` (or `i`).

    Parameters
    ----------
    labeled : ndarray of integer type
        input labeled array
    i : integer
    j : integer
    Bc : structure element, optional
    out : ndarray of same shape as `labeled`, dtype=bool, optional
        where to store the output. If ``None``, a new array is allocated
    always_return : bool, optional
        if false, then, in the case where there is no pixel on the border,
        returns ``None``. Otherwise (the default), it always returns an array
        even if it is empty.

    Returns
    -------
    border_img : boolean ndarray
        Pixels are True exactly where there is a border between `i` and `j` in `labeled`
    '''
    Bc = get_structuring_elem(labeled, Bc)
    output = _get_output(labeled, out, 'labeled.border', bool, output=output)
    output.fill(False)
    return _labeled.border(labeled, Bc, output, i, j, bool(always_return))

def borders(labeled, Bc=None, out=None, output=None, mode='constant'):
    '''
    border_img = borders(labeled, Bc={3x3 cross}, out={np.zeros(labeled.shape, bool)})

    Compute border pixels

    A pixel is on a border if it has value `i` and a pixel in its neighbourhood
    (defined by `Bc`) has value `j`, with ``i != j``.

    Parameters
    ----------
    labeled : ndarray of integer type
        input labeled array
    Bc : structure element, optional
    out : ndarray of same shape as `labeled`, dtype=bool, optional
        where to store the output. If ``None``, a new array is allocated
    mode : {'reflect', 'nearest', 'wrap', 'mirror', 'constant' [default], 'ignore'}
        How to handle borders

    Returns
    -------
    border_img : boolean ndarray
        Pixels are True exactly where there is a border in `labeled`
    '''
    Bc = get_structuring_elem(labeled, Bc)
    output = _get_output(labeled, out, 'labeled.borders', bool, output=output)
    output.fill(False)
    return _labeled.borders(labeled, Bc, output, mode2int[mode])


def bwperim(bw, n=4, mode="constant"):
    '''
    perim = bwperim(bw, n=4)

    Find the perimeter of objects in binary images.

    A pixel is part of an object perimeter if its value is one and there
    is at least one zero-valued pixel in its neighborhood.

    By default the neighborhood of a pixel is 4 nearest pixels, but
    if `n` is set to 8 the 8 nearest pixels will be considered.

    Parameters
    ----------
    bw : ndarray
        A black-and-white image (any other image will be converted to black & white)
    n : int, optional
        Connectivity. Must be 4 or 8 (default: 4)
    mode : {'reflect', 'nearest', 'wrap', 'mirror', 'constant' [default], 'ignore'}
        How to handle borders

    Returns
    -------
    perim : ndarray
        A boolean image

    See Also
    --------
    borders : function
        This is a more generic function
    '''
    bw = (bw != 0)
    return bw&borders(bw, n, mode=mode)

def _as_labeled(array, labeled, funcname, inplace='unused'):
    '''

    labeled = _as_labeled(array, labeled, funcname, inplace='unused')

    Parameters
    ----------
    array : ndarray
    labeled : ndarray
    funcname : str
    inplace : bool or str, optional
        handles ``inplace`` arguments
    '''
    if inplace == 'unused':
        labeled = np.require(labeled, dtype=np.intc, requirements="CW")
    elif not inplace:
        labeled = np.array(labeled, dtype=np.intc)
    elif labeled.dtype != np.intc or not labeled.flags.carray:
        raise ValueError('mahotas.labeled.%s: labeled must be a C-array of type int' % funcname)

    if array.shape != labeled.shape:
        raise ValueError('mahotas.labeled.%s: `array` is not the same size as `labeled`' % funcname)
    return labeled


def _convert_labeled(labeled):
    return np.require(labeled, dtype=np.intc, requirements="CW")

def labeled_sum(array, labeled):
    '''
    sums = labeled_sum(array, labeled)

    Labeled sum. sum will be an array of size ``labeled.max() + 1``, where
    ``sum[i]`` is equal to ``np.sum(array[labeled == i])``.

    Parameters
    ----------
    array : ndarray of any type
    labeled : int ndarray
        Label map. This is the same type as returned from ``mahotas.label()``

    Returns
    -------
    sums : 1-d ndarray of ``array.dtype``
    '''
    labeled = _as_labeled(array, labeled, 'labeled_sum')
    maxv = labeled.max() + 1
    output = np.empty(maxv, dtype=array.dtype)
    _labeled.labeled_sum(array, labeled, output)
    return output


def labeled_max(array, labeled):
    '''
    mins = labeled_max(array, labeled)

    Labeled minimum. ``mins`` will be an array of size ``labeled.max() + 1``, where
    ``mins[i]`` is equal to ``np.min(array[labeled == i])``.

    Parameters
    ----------
    array : ndarray of any type
    labeled : int ndarray
        Label map. This is the same type as returned from ``mahotas.label()``

    Returns
    -------
    mins : 1-d ndarray of ``array.dtype``
    '''
    labeled = _as_labeled(array, labeled, 'labeled_max')
    maxv = labeled.max() + 1
    output = np.empty(maxv, dtype=array.dtype)
    _labeled.labeled_max_min(array, labeled, output, True)
    return output


def labeled_min(array, labeled):
    '''
    maxs = labeled_min(array, labeled)

    Labeled maximum. ``maxs`` will be an array of size ``labeled.max() + 1``, where
    ``maxs[i]`` is equal to ``np.max(array[labeled == i])``.

    Parameters
    ----------
    array : ndarray of any type
    labeled : int ndarray
        Label map. This is the same type as returned from ``mahotas.label()``

    Returns
    -------
    maxs : 1-d ndarray of ``array.dtype``
    '''
    labeled = _as_labeled(array, labeled, 'labeled_min')
    maxv = labeled.max() + 1
    output = np.empty(maxv, dtype=array.dtype)
    _labeled.labeled_max_min(array, labeled, output, False)
    return output

def labeled_size(labeled):
    '''
    sizes = labeled_size(labeled)

    Equivalent to::

        for i in range(...):
            sizes[i] = np.sum(labeled == i)

    but, naturally, much faster.

    Parameters
    ----------
    labeled : int ndarray

    Returns
    -------
    sizes : 1-d ndarray of int

    See Also
    --------
    mahotas.fullhistogram : almost same function by another name (the only
    difference is that that function only accepts unsigned integer types).
    '''
    from .histogram import fullhistogram
    return fullhistogram(labeled.astype(np.uint32))


_perimeter_magic = np.array([
                [10, 2, 10],
                [ 2, 1,  2],
                [10, 2, 10]], np.uint8)
_perimeter_values = None

# This implementation was adapted from scikit-image's implementation
def perimeter(bwimage, n=4, mode="constant"):
    """
    p = perimeter(bwimage, n=4, mode="constant")

    Calculate total perimeter of all objects in binary image.

    Parameters
    ----------
    bwimage : array
        binary image
    n : int, optional
        passed to ``bwperim`` as is
    mode : str, optional
        passed to ``bwperim`` as is

    Returns
    -------
    p : float
        total perimeter of all objects in binary image

    See Also
    --------
    bwperim : function
        Finds the perimeter region

    References
    ----------
    .. [1] K. Benkrid, D. Crookes. Design and FPGA Implementation of
           a Perimeter Estimator. The Queen's University of Belfast.
           http://www.cs.qub.ac.uk/~d.crookes/webpubs/papers/perimeter.doc
    """
    global _perimeter_values
    perim = bwperim(bwimage, n, mode)
    perim = perim.astype(np.uint8)

    histogram = mh.fullhistogram(
                    mh.convolve(perim, _perimeter_magic))

    if _perimeter_values is None:
        _perimeter_values = np.zeros(34, float)
        _perimeter_values[[5, 7, 15, 17, 25, 27]] = 1
        _perimeter_values[[21, 33]] = np.sqrt(2)
        _perimeter_values[[13, 23]] = (1 + np.sqrt(2)) / 2

    size = min(34, len(histogram))
    return np.dot(histogram[:size], _perimeter_values[:size])

########NEW FILE########
__FILENAME__ = lbp
import warnings
warnings.warn(
'''Use

from mahotas.features import lbp
''', DeprecationWarning)

from mahotas.features.lbp import *

########NEW FILE########
__FILENAME__ = mahotas_version
__version__ = '1.1.0+git'

########NEW FILE########
__FILENAME__ = moments
import warnings
warnings.warn(
'''Use

from mahotas.features import moments
''', DeprecationWarning)

from mahotas.features.moments import *

########NEW FILE########
__FILENAME__ = morph
# Copyright (C) 2008-2014, Luis Pedro Coelho <luis@luispedro.org>
# vim: set ts=4 sts=4 sw=4 expandtab smartindent:
#
# License: MIT

from __future__ import division
import numpy as np

from .internal import _get_output, _verify_is_integer_type
from . import _morph

__all__ = [
        'close',
        'close_holes',
        'cwatershed',
        'cerode',
        'dilate',
        'disk',
        'cdilate',
        'erode',
        'get_structuring_elem',
        'hitmiss',
        'locmax',
        'locmin',
        'majority_filter'
        'open',
        'regmax',
        'regmin',
        'tophat_open',
        'tophat_close',
        'subm',
        ]

def get_structuring_elem(A,Bc):
    '''
    Bc_out = get_structuring_elem(A, Bc)

    Retrieve appropriate structuring element

    Parameters
    ----------
    A : ndarray
        array which will be operated on
    Bc : None, int, or array-like
        :None: Then Bc is taken to be 1
        :An integer: There are two associated semantics:
            connectivity
              ``Bc[y,x] = [[ is |y - 1| + |x - 1| <= Bc_i ]]``
            count
              ``Bc.sum() == Bc_i``
              This is the more traditional meaning (when one writes that
              "4-connected", this is what one has in mind).

          Fortunately, the value itself allows one to distinguish between the
          two semantics and, if used correctly, no ambiguity should ever occur.
        :An array: This should be of the same nr. of dimensions as A and will
            be passed through if of the right type. Otherwise, it will be cast.

    Returns
    -------
    Bc_out : ndarray
        Structuring element. This array will be of the same type as A,
        C-contiguous.

    '''
    translate_sizes = {
            (2, 4) : 1,
            (2, 8) : 2,
            (3, 6) : 1,
    }
    if Bc is None:
        Bc = 1
    elif type(Bc) == int and (len(A.shape), Bc) in translate_sizes:
        Bc = translate_sizes[len(A.shape),Bc]
    elif type(Bc) != int:
        if A.ndim != Bc.ndim:
            raise ValueError('morph.get_structuring_elem: Bc does not have the correct number of dimensions. [array has {} coordinates; Bc has {}.]'.format(A.ndim, Bc.ndim))
        Bc = np.asanyarray(Bc, A.dtype)
        if not Bc.flags.contiguous:
            return Bc.copy()
        return Bc

    # Special case typical case:
    if len(A.shape) == 2 and Bc == 1:
        return np.array([
                [0,1,0],
                [1,1,1],
                [0,1,0]], dtype=A.dtype)
    max1 = Bc
    Bc = np.zeros((3,)*len(A.shape), dtype=A.dtype)
    centre = np.ones(len(A.shape))
    # This is pretty slow, but this should be a tiny array, so who cares
    for i in range(Bc.size):
        pos = np.unravel_index(i, Bc.shape)
        pos -= centre
        if np.sum(np.abs(pos)) <= max1:
            Bc.flat[i] = 1
    return Bc

def disk(radius, dim=2):
    '''
    D = disk(radius, dim=2)

    Return a binary disk structuring element of radius ``radius`` and dimension ``dim``

    Parameters
    ----------
    radius : int
        Radius (in pixels) of returned disk
    dim : int, optional
        Dimension of returned array (default: 2)

    Returns
    -------
    D : boolean ndarray
    '''
    import numpy as np
    if dim <= 0:
        raise ValueError('mahotas.morph.disk: dimension must be positive')
    shape = [(radius*2+1) for _ in range(dim)]
    if dim == 2:
        return _morph.disk_2d(np.zeros(shape, bool), radius)
    indices = np.indices(shape, float)
    indices -= radius
    indices **= 2
    return (indices.sum(0) < (radius**2))

def dilate(A, Bc=None, out=None, output=None):
    '''
    dilated = dilate(A, Bc={3x3 cross}, out={np.empty_like(A)})

    Morphological dilation.

    The type of operation depends on the ``dtype`` of ``A``! If boolean, then
    the dilation is binary, else it is greyscale dilation. In the case of
    greyscale dilation, the smallest value in the domain of ``Bc`` is
    interpreted as +Inf.

    Parameters
    ----------
    A : ndarray of bools
        input array
    Bc : ndarray, optional
        Structuring element. By default, use a cross (see
        ``get_structuring_elem`` for details on the default).

    Returns
    -------
    dilated : ndarray
        dilated version of ``A``

    See Also
    --------
    erode
    '''
    _verify_is_integer_type(A, 'dilate')
    Bc = get_structuring_elem(A,Bc)
    output = _get_output(A, out, 'dilate', output=output)
    return _morph.dilate(A, Bc, output)

def erode(A, Bc=None, out=None, output=None):
    '''
    eroded = erode(A, Bc={3x3 cross}, out={np.empty_as(A)})

    Morphological erosion.

    The type of operation depends on the ``dtype`` of ``A``! If boolean, then
    the erosion is binary, else it is greyscale erosion. In the case of
    greyscale erosion, the smallest value in the domain of ``Bc`` is
    interpreted as -Inf.

    Parameters
    ----------
    A : ndarray
        input image
    Bc : ndarray, optional
        Structuring element. By default, use a cross (see
        ``get_structuring_elem`` for details on the default).
    out : ndarray, optional
        output array. If used, this must be a C-array of the same ``dtype`` as
        ``A``. Otherwise, a new array is allocated.

    Returns
    -------
    erosion : ndarray
        eroded version of ``A``

    See Also
    --------
    dilate
    '''
    _verify_is_integer_type(A,'erode')
    Bc = get_structuring_elem(A,Bc)
    output = _get_output(A, out, 'erode', output=output)
    return _morph.erode(A, Bc, output)


def cerode(f, g, Bc=None, out=None, output=None):
    '''
    conditionally_eroded = cerode(f, g, Bc={3x3 cross}, out={np.empty_as(A)})

    Conditional morphological erosion.

    The type of operation depends on the ``dtype`` of ``A``! If boolean, then
    the erosion is binary, else it is greyscale erosion. In the case of
    greyscale erosion, the smallest value in the domain of ``Bc`` is
    interpreted as -Inf.

    Parameters
    ----------
    f : ndarray
        input image
    g : ndarray
        conditional image
    Bc : ndarray, optional
        Structuring element. By default, use a cross (see
        ``get_structuring_elem`` for details on the default).

    Returns
    -------
    conditionally_eroded : ndarray
        eroded version of ``f`` conditioned on ``g``

    See Also
    --------
    erode : function
        Unconditional version of this function
    dilate
    '''
    f = np.maximum(f, g)
    _verify_is_integer_type(f, 'cerode')
    Bc = get_structuring_elem(f, Bc)
    out = _get_output(f, out, 'cerode', output=output)
    f = _morph.erode(f, Bc, out)
    return np.maximum(f, g, out=f)

def cdilate(f, g, Bc=None, n=1):
    """
    y = cdilate(f, g, Bc={3x3 cross}, n=1)

    Conditional dilation

    `cdilate` creates the image `y` by dilating the image `f` by the
    structuring element `Bc` conditionally to the image `g`. This
    operator may be applied recursively `n` times.

    Parameters
    ----------
    f : Gray-scale (uint8 or uint16) or binary image.
    g : Conditioning image. (Gray-scale or binary).
    Bc : Structuring element (default: 3x3 cross)
    n : Number of iterations (default: 1)

    Returns
    -------
    y : Image
    """
    _verify_is_integer_type(f, 'cdilate')
    Bc = get_structuring_elem(f, Bc)
    f = np.minimum(f, g)
    for i in range(n):
        prev = f
        f = dilate(f, Bc)
        f = np.minimum(f, g)
        if np.all(f == prev):
            break
    return f


def cwatershed(surface, markers, Bc=None, return_lines=False):
    '''
    W = cwatershed(surface, markers, Bc=None, return_lines=False)
    W,WL = cwatershed(surface, markers, Bc=None, return_lines=True)

    Seeded watershed in n-dimensions
    
    This function computes the watershed transform on the input surface (which
    may actually be an n-dimensional volume).
    
    This function requires initial seed points. A traditional way of
    initializing watershed is to use regional minima::

        minima = mh.regmin(f)
        markers,nr_markers = mh.label(minima)
        W = cwatershed(f, minima)

    Parameters
    ----------
    surface : image
    markers : image
        initial markers (must be a labeled image, i.e., one where 0 represents
        the background and higher integers represent different regions)
    Bc : ndarray, optional
        structuring element (default: 3x3 cross)
    return_lines : boolean, optional
        whether to return separating lines (in addition to regions)

    Returns
    -------
    W : integer ndarray (int64 ints)
        Regions image (i.e., W[i,j] == region for pixel (i,j))
    WL : Lines image (`if return_lines==True`)
    '''
    _verify_is_integer_type(surface, 'cwatershed')
    _verify_is_integer_type(markers, 'cwatershed')
    markers = markers.astype(np.int64)
    if surface.shape != markers.shape:
        raise ValueError('morph.cwatershed: Markers array should have the same shape as value array.')
    Bc = get_structuring_elem(surface, Bc)
    return _morph.cwatershed(surface, markers, Bc, bool(return_lines))

def hitmiss(input, Bc, out=None, output=None):
    '''
    filtered = hitmiss(input, Bc, out=np.zeros_like(input))

    Hit & Miss transform

    For a given pixel position, the hit&miss is ``True`` if, when ``Bc`` is
    overlaid on ``input``, centered at that position, the ``1`` values line up
    with ``1``s, while the ``0``s line up with ``0``s (``2``s correspond to
    *don't care*).

    Examples
    --------

    ::

        print(hitmiss(np.array([
                    [0,0,0,0,0],
                    [0,1,1,1,1],
                    [0,0,1,1,1]]),
                np.array([
                    [0,0,0],
                    [2,1,1],
                    [2,1,1]])))

        prints::

            [[0 0 0 0 0]
             [0 0 1 1 0]
             [0 0 0 0 0]]



    Parameters
    ----------
    input : input ndarray
        This is interpreted as a binary array.
    Bc : ndarray
        hit & miss template, values must be one of (0, 1, 2)
    out : output array

    Returns
    -------
    filtered : ndarray
    '''
    _verify_is_integer_type(input, 'hitmiss')
    _verify_is_integer_type(Bc, 'hitmiss')
    if input.dtype != Bc.dtype:
        if input.dtype == np.bool_:
            input = input.view(np.uint8)
            if Bc.dtype == np.bool_:
                Bc = Bc.view(np.uint8)
            else:
                Bc = Bc.astype(np.uint8)
        else:
            Bc = Bc.astype(input.dtype)

    if out is None and output is not None:
        out = output

    if out is None:
        out = np.empty_like(input)
    else:
        if out.shape != input.shape:
            raise ValueError('mahotas.hitmiss: out must be of same shape as input')
        if out.dtype != input.dtype:
            if out.dtype == np.bool_ and input.dtype == np.uint8:
                out = out.view(np.uint8)
            else:
                raise TypeError('mahotas.hitmiss: out must be of same type as input')
    return _morph.hitmiss(input, Bc, out)


def open(f, Bc=None, out=None, output=None):
    """
    y = open(f, Bc={3x3 cross}, out={np.empty_like(f)})

    Morphological opening.

    `open` creates the image y by the morphological opening of the
    image `f` by the structuring element `Bc`.

    In the binary case, the opening by the structuring element `Bc` may be
    interpreted as the union of translations of `b` included in `f`. In the
    gray-scale case, there is a similar interpretation taking the functions
    umbra.

    Parameters
    ----------
    f : ndarray
        Gray-scale (uint8 or uint16) or binary image.
    Bc : ndarray, optional
        Structuring element (default: 3x3 elementary cross).
    out : ndarray, optional
        Output array

    Returns
    -------
    y : ndarray

    See Also
    --------
    open : function
    """
    _verify_is_integer_type(f, 'open')
    Bc = get_structuring_elem(f, Bc)
    eroded = erode(f, Bc, out=out)
    # We need to copy for the simple reason that otherwise, the image will be
    # modified in place, which can mess up the implementation
    return dilate(eroded.copy(), Bc, out=eroded)


def close(f, Bc=None, out=None, output=None):
    """
    y = close(f, Bc={3x3 cross}, out={np.empty_like(f)})

    Morphological closing.

    `close` creates the image `y` by the morphological closing of the
    image `f` by the structuring element `Bc`. In the binary case, the
    closing by a structuring element `Bc` may be interpreted as the
    intersection of all the binary images that contain the image `f`
    and have a hole equal to a translation of `Bc`. In the gray-scale
    case, there is a similar interpretation taking the functions
    umbra.

    Parameters
    ----------
    f : ndarray
        Gray-scale (uint8 or uint16) or binary image.
    Bc : ndarray, optional
        Structuring element. (Default: 3x3 elementary cross).
    out : ndarray, optional
        Output array

    Returns
    -------
    y : ndarray

    See Also
    --------
    open : function
    """
    _verify_is_integer_type(f, 'close')
    Bc = get_structuring_elem(f, Bc)
    dilated = dilate(f, Bc, out=out)
    # We need to copy for the simple reason that otherwise, the image will be
    # modified in place, which can mess up the implementation
    return erode(dilated.copy(), Bc, out=dilated)


def close_holes(ref, Bc=None):
    '''
    closed = close_holes(ref, Bc=None):

    Close Holes

    Parameters
    ----------
    ref : ndarray
        Reference image. This should be a binary image.
    Bc : structuring element, optional
        Default: 3x3 cross

    Returns
    -------
    closed : ndarray
        superset of `ref` (i.e. with closed holes)
    '''
    ref = np.ascontiguousarray(ref, dtype=np.bool_)
    Bc = get_structuring_elem(ref, Bc)
    return _morph.close_holes(ref, Bc)


def majority_filter(img, N=3, out=None, output=None):
    '''
    filtered = majority_filter(img, N=3, out={np.empty(img.shape, np.bool)})

    Majority filter

    filtered[y,x] is positive if the majority of pixels in the squared of size
    `N` centred on (y,x) are positive.

    Parameters
    ----------
    img : ndarray
        input img (currently only 2-D images accepted)
    N : int, optional
        size of filter (must be odd integer), defaults to 3.
    out : ndarray, optional
        Used for output. Must be Boolean ndarray of same size as `img`

    Returns
    -------
    filtered : ndarray
        boolean image of same size as img.
    '''
    img = img.astype(np.bool_)
    output = _get_output(img, out, 'majority_filter', np.bool_, output=output)
    if N <= 1:
        raise ValueError('mahotas.majority_filter: filter size must be positive')
    if not N&1:
        import warnings
        warnings.warn('mahotas.majority_filter: size argument must be odd. Adding 1.')
        N += 1
    return _morph.majority_filter(img, N, output)


def _remove_centre(Bc):
    index = [s//2 for s in Bc.shape]
    Bc[tuple(index)] = False
    return Bc

def locmax(f, Bc=None, out=None, output=None):
    '''
    filtered = locmax(f, Bc={3x3 cross}, out={np.empty(f.shape, bool)})

    Local maxima

    Parameters
    ----------
    f : ndarray
    Bc : ndarray, optional
        structuring element
    out : ndarray, optional
        Used for output. Must be Boolean ndarray of same size as `f`

    Returns
    -------
    filtered : ndarray
        boolean image of same size as f.

    See Also
    --------
    regmax : function
        Regional maxima. This is a stricter criterion than the local maxima as
        it takes the whole object into account and not just the neighbourhood
        defined by ``Bc``::

            0 0 0 0 0
            0 0 2 0 0
            0 0 2 0 0
            0 0 3 0 0
            0 0 3 0 0
            0 0 0 0 0

        The top 2 is a local maximum because it has the maximal value in its
        neighbourhood, but it is not a regional maximum.

    locmin : function
        Local minima
    '''
    Bc = get_structuring_elem(f, Bc)
    output = _get_output(f, out, 'locmax', np.bool_, output=output)
    Bc = _remove_centre(Bc.copy())
    return _morph.locmin_max(f, Bc, output, False)


def locmin(f, Bc=None, out=None, output=None):
    '''
    filtered = locmin(f, Bc={3x3 cross}, out={np.empty(f.shape, bool)})

    Local minima

    Parameters
    ----------
    f : ndarray
    Bc : ndarray, optional
        structuring element
    out : ndarray, optional
        Used for output. Must be Boolean ndarray of same size as `f`

    Returns
    -------
    filtered : ndarray
        boolean image of same size as f.

    See Also
    --------
    locmax : function
        Regional maxima
    '''
    Bc = get_structuring_elem(f, Bc)
    Bc = _remove_centre(Bc.copy())
    output = _get_output(f, out, 'locmin', np.bool_, output=output)
    return _morph.locmin_max(f, Bc, output, True)


def regmin(f, Bc=None, out=None, output=None):
    '''
    filtered = regmin(f, Bc={3x3 cross}, out={np.empty(f.shape, bool)})

    Regional minima. See the documentation for ``regmax`` for more details.

    Parameters
    ----------
    f : ndarray
    Bc : ndarray, optional
        structuring element
    out : ndarray, optional
        Used for output. Must be Boolean ndarray of same size as `f`

    Returns
    -------
    filtered : ndarray
        boolean image of same size as f.

    See Also
    --------
    locmin : function
        Local minima
    '''
    _verify_is_integer_type(f, 'regmin')
    Bc = get_structuring_elem(f, Bc)
    Bc = _remove_centre(Bc.copy())
    output = _get_output(f, out, 'regmin', np.bool_, output=output)
    return _morph.regmin_max(f, Bc, output, True)


def regmax(f, Bc=None, out=None, output=None):
    '''
    filtered = regmax(f, Bc={3x3 cross}, out={np.empty(f.shape, bool)})

    Regional maxima. This is a stricter criterion than the local maxima as
    it takes the whole object into account and not just the neighbourhood
    defined by ``Bc``::

        0 0 0 0 0
        0 0 2 0 0
        0 0 2 0 0
        0 0 3 0 0
        0 0 3 0 0
        0 0 0 0 0

    The top 2 is a local maximum because it has the maximal value in its
    neighbourhood, but it is not a regional maximum.


    Parameters
    ----------
    f : ndarray
    Bc : ndarray, optional
        structuring element
    out : ndarray, optional
        Used for output. Must be Boolean ndarray of same size as `f`

    Returns
    -------
    filtered : ndarray
        boolean image of same size as f.

    See Also
    --------
    locmax : function
        Local maxima. The local maxima are a superset of the regional maxima
    '''
    _verify_is_integer_type(f, 'regmax')
    Bc = get_structuring_elem(f, Bc)
    Bc = _remove_centre(Bc.copy())
    output = _get_output(f, out, 'regmax', np.bool_, output=output)
    return _morph.regmin_max(f, Bc, output, False)

def subm(a, b, out=None):
    '''
    c = subm(a, b, out={None})

    Subtract (with saturation).

    This is similar to:

    c = a - b

    but with saturation instead of underflow.

    Example
    -------

    ::

        a = np.array([10, 10, 10], np.uint8)
        b = np.array([ 5, 10, 15], np.uint8)

        print subm(a,b)

    Prints out::

        [5, 0, 0]

    Parameters
    ----------
    a : ndarray
    b : ndarray
    out : ndarray, optional
        Pass ``a`` as output to subtract in-place.

    Returns
    -------
    c : ndarray
        Result of subtraction
    '''
    if a.dtype != b.dtype:
        raise ValueError('mahotas.subm: This is only well-defined if both arguments are of the same type')
    out = _get_output(a, out, 'subm')
    if out is not a:
        out[:] = a
    return _morph.subm(out, b)


def tophat_close(f, Bc=None, out=None):
    '''
    fclosed = tophat_close(f, Bc={3x3 cross}, out={new array})

    Closed top-hat transform (aka black tophat transform)

    This returns objects that are smaller than ``Bc`` and contain lower values
    than their surroundings.

    See: http://en.wikipedia.org/wiki/Top-hat_transform

    Parameters
    ----------
    f : ndarray
    Bc : ndarray, optional
        structuring element
    out : ndarray, optional
        output array

    Returns
    -------
    fclosed : ndarray
        Of same type and shape as ``f``

    See Also
    --------
    tophat_close : function
        Sister function to this one
    '''
    Bc = get_structuring_elem(f, Bc)
    out = _get_output(f, out, 'tophat_close')
    fc = close(f, Bc)
    return subm(fc, f, out=out)

def tophat_open(f, Bc=None, out=None):
    '''
    fopen = tophat_open(f, Bc={3x3 cross}, out={new array})

    Open top-hat transform (aka white tophat transform)

    This returns objects that are smaller than ``Bc`` and contain higher values
    than their surroundings.

    See: http://en.wikipedia.org/wiki/Top-hat_transform

    Parameters
    ----------
    f : ndarray
    Bc : ndarray, optional
        structuring element
    out : ndarray, optional
        output array

    Returns
    -------
    fopened : ndarray
        Of same type and shape as ``f``

    See Also
    --------
    tophat_close : function
        Sister function to this one
    '''
    Bc = get_structuring_elem(f, Bc)
    out = _get_output(f, out, 'tophat_open')
    fo = open(f,Bc)
    return subm(f, fo, out=out)


def circle_se(radius):
    '''
    circle = circle_se(radius)

    Build a circular structuring element of a given radius

    Parameters
    ----------
    radius : int
        Radius of circle

    Returns
    -------
    circle : boolean ndarray
    '''
    if not (radius > 0):
        raise ValueError('mahotas.morph.circle: radius must be positive')
    X = np.arange(-radius, +radius+1)
    X,Y = np.meshgrid(X,X)
    return (X**2 + Y**2) < radius**2

########NEW FILE########
__FILENAME__ = polygon
# Copyright (C) 2010-2013, Luis Pedro Coelho <luis@luispedro.org>
# vim: set ts=4 sts=4 sw=4 expandtab smartindent:
# 
# License: MIT (see COPYING file)

from __future__ import division
import numpy as np
from . import _convex

__all__ = [
    'line',
    'fill_polygon',
    'convexhull',
    'fill_convexhull',
    ]


def line(p0, p1, canvas, color=1):
    '''
    line((y0,x0), (y1,x1), canvas, color=1)

    Draw a line

    Parameters
    ----------
    p0 : pair of integers
        first point
    p1 : pair of integers
        second point
    canvas : ndarray
        where to draw, will be modified in place
    color : integer, optional
        which value to store on the pixels (default: 1)

    Implementation Reference
    ------------------------

    http://en.wikipedia.org/wiki/Bresenham's_line_algorithm
    '''
    y0,x0 = p0
    y1,x1 = p1
    steep = abs(y1-y0) > abs(x1 -x0)
    if steep:
        x0,y0 = y0,x0
        x1,y1 = y1,x1
    if x0 > x1:
        x0,x1 = x1,x0
        y0,y1 = y1,y0
    dx = x1 - x0
    dy = abs(y1-y0)
    error = dx/2.
    y = y0
    ystep = (+1 if y0 < y1 else -1)
    for x in range(x0,x1+1):
        if steep:
            canvas[x,y] = color
        else:
            canvas[y,x] = color
        error -= dy
        if error < 0:
            y += ystep
            error += dx


def fill_polygon(polygon, canvas, color=1):
    '''
    fill_polygon([(y0,x0), (y1,x1),...], canvas, color=1)

    Draw a filled polygon in canvas

    Parameters
    ----------
    polygon : list of pairs
        a list of (y,x) points
    canvas : ndarray
        where to draw, will be modified in place
    color : integer, optional
        which colour to use (default: 1)
    '''
# algorithm adapted from: http://www.alienryderflex.com/polygon_fill/
    if not len(polygon):
        return
    min_y = min(y for y,x in polygon)
    max_y = max(y for y,x in polygon)
    polygon = [(float(y),float(x)) for y,x in polygon]
    if max_y < canvas.shape[0]:
        max_y += 1
    for y in range(min_y, max_y):
        nodes = []
        j = -1
        for i,p in enumerate(polygon):
            pj = polygon[j]
            if p[0] < y and pj[0] >= y or pj[0] < y and p[0] >= y:
                dy = pj[0] - p[0]
                if dy:
                    nodes.append( (p[1] + (y-p[0])/(pj[0]-p[0])*(pj[1]-p[1])) )
                elif p[0] == y:
                    nodes.append(p[1])
            j = i
        nodes.sort()
        for n,nn in zip(nodes[::2],nodes[1::2]):
            nn += 1
            canvas[y,n:nn] = color

def convexhull(bwimg):
    '''
    hull = convexhull(bwimg)

    Compute the convex hull as a polygon

    This is an implementation of the Graham Scan:
    http://en.wikipedia.org/wiki/Graham_scan

    Parameters
    ----------
    bwimg : ndarray
        input image (interpreted as boolean). Only 2D arrays are supported.

    Returns
    -------
    hull : ndarray
        Set of (y,x) coordinates of hull corners
    '''
    bwimg = np.ascontiguousarray(bwimg, dtype=np.bool_)
    if bwimg.ndim != 2:
        raise ValueError('mahotas.polygon.convexhull: Only two-dimensional images supported')
    return _convex.convexhull(bwimg)

def fill_convexhull(bwimg):
    '''
    hull = fill_convexhull(bwimg)

    Compute the convex hull and return it as a binary mask

    Parameters
    ----------
    bwimage : input image (interpreted as boolean)

    Returns
    -------
    hull : image of same size and dtype as `bwimg` with the hull filled in.
    '''

    points = convexhull(bwimg)
    canvas = np.zeros_like(bwimg)
    black = (1 if bwimg.dtype == np.bool_ else 255)
    fill_polygon(points, canvas, black)
    canvas[bwimg] = black
    return canvas


########NEW FILE########
__FILENAME__ = resize
# Copyright (C) 2010-2013, Luis Pedro Coelho <luis@luispedro.org>
# vim: set ts=4 sts=4 sw=4 expandtab smartindent:
#
# License: MIT (see COPYING file)

from __future__ import division
import numpy as np

__all__ = [
    'imresize',
    'resize_to',
    'resize_rgb_to',
    ]

def resize_to(im, nsize, order=3):
    '''Resize image to a specified new size

    Parameters
    ----------
    im : ndarray
    nsize : sequence of numbers
        Will be the new size of the array
    order : integer, optional
        Spline order to use (default: 3)

    Returns
    -------
    im' : ndarray

    See Also
    --------
    zoom : Similar function
    imresize : A more flexible, but also confusing, version of this function
    resize_rgb_to : A version appropriate for resize RGB images
    '''
    from .interpolate import zoom
    if len(nsize) != im.ndim:
        raise ValueError('mahotas.resize_to: new size does not have the same dimension as old one')
    nsize = np.array(nsize, dtype=float)
    nsize /= im.shape
    return zoom(im, nsize, order=order)


def resize_rgb_to(im, nsize, order=3):
    '''Resize an RGB image to size ``nsize``

    Parameters
    ----------
    im : ndarray
    nsize : sequence of 2 numbers
        if nsize is ``(h,w)``, the new image will be ``(h,w,3)``
    order : integer, optional
        Spline order to use (default: 3)

    Returns
    -------
    im' : ndarray

    See Also
    --------
    zoom : Similar function
    imresize : A more flexible, but also confusing, version of this function
    resize_to : A generic version of this function
    '''
    from .internal import _check_3
    _check_3(im, 'resize_rgb_to')
    return np.dstack([resize_to(ch, nsize, order) for ch in im.transpose((2,0,1))])

def imresize(img, nsize, order=3):
    '''Resizes image

    This function works in two ways: if ``nsize`` is a tuple or list of
    integers, then the result will be of this size; otherwise, this function
    behaves the same as ``mh.interpolate.zoom``

    Parameters
    ----------
    img : ndarray
    nsize : float or tuple(float) or tuple(integers)
        Size of return. Meaning depends on the type
            float: img'.shape[i] = nsize * img.shape[i]
            tuple of float: img'.shape[i] = nsize[i] * img.shape[i]
            tuple of int: img'.shape[i] = nsize[i]
    order : integer, optional
        Spline order to use (default: 3)

    Returns
    -------
    img' : ndarray

    See Also
    --------
    zoom : Similar function
    scipy.misc.pilutil.imresize : Similar function
    '''
    from .interpolate import zoom
    if type(nsize) == tuple or type(nsize) == list:
        if type(nsize[0]) == int:
            nsize = np.array(nsize, dtype=float)
            nsize /= img.shape
    return zoom(img, nsize, order=order)

########NEW FILE########
__FILENAME__ = segmentation
# -*- coding: utf-8 -*-
# Copyright (C) 2008-2013 Luis Pedro Coelho <luis@luispedro.org>
# vim: set ts=4 sts=4 sw=4 expandtab smartindent:
# Carnegie Mellon University
#
# License: MIT (see COPYING file)

from __future__ import division
import numpy as np

from .internal import _check_3
from . import _distance
from . import _labeled

__all__ = [
    'gvoronoi',
    'slic'
    ]

def gvoronoi(labeled):
    '''
    segmented = gvoronoi(labeled)

    Generalised Voronoi Transform.

    The generalised Voronoi diagram assigns to the pixel (i,j) the label of the
    nearest object (i.e., the value of the nearest non-zero pixel in labeled).

    Parameters
    ----------
    labeled : ndarray
        a labeled array, of a form similar to one returned by
        ``mahotas.label()``

    Returns
    -------
    segmented : is of the same size and type as labeled and
                `segmented[y,x]` is the label of the object at position `y,x`.
    '''
    labeled = np.ascontiguousarray(labeled)
    bw = (labeled == 0)
    f = np.zeros(bw.shape, np.double)
    f[bw] = len(f.shape)*max(f.shape)**2+1
    orig = np.arange(f.size, dtype=np.intc).reshape(f.shape)
    _distance.dt(f, orig)
    return labeled.flat[orig]


def slic(array, spacer=16, m=1.0, max_iters=128):
    '''Compute SLIC superpixel oversegmentation

    Note: This function operates on the array values. In the original
    publication, SLIC was applied in L*a*b* space.

    To use the original mode, use::

        rgb = mh.demos.load('lena')
        lab = mh.colors.rgb2lab(rgb)
        superseg,nr = mh.segmentation.slic(lab)

    See the mahotas.color module for color space transformations

    Parameters
    ----------
    array : ndarray
    spacer : int, optional
        x/y spacing between initial seeds. Initial seeds will be placed at
        ``array[spacer/2::spacer,spacer/::spacer]``
    m : float, optional
        tradeoff between colour space and spatial distance.
    max_iters : int, optional
        Maximum number of k-means iterations. Generally this does not need to
        be very large because the search is only local and convergence is
        very fast, in which case, the algorithm will exit early. (default: 128)

    Returns
    -------
    segmented : ndarray
        A segmented area numbered 1..N. The general mahotas convention is that
        region 0 is background. Thus, 1..N is used here.
    n_segments : int
        Number of segments

    References
    ----------
    .. [1] Radhakrishna Achanta, Appu Shaji, Kevin Smith, Aurelien Lucchi,
        Pascal Fua, and Sabine Süsstrunk, SLIC Superpixels Compared to
        State-of-the-art Superpixel Methods, TPAMI, May 2012.
    '''
    array = np.ascontiguousarray(array, dtype=np.float32)
    _check_3(array, 'slic')
    labels = np.zeros((array.shape[0], array.shape[1]), dtype=np.intc)
    labels = labels.copy()
    n = _labeled.slic(array, labels, int(spacer), float(m), int(max_iters))
    return labels, n

########NEW FILE########
__FILENAME__ = stretch
# -*- coding: utf-8 -*-
# Copyright (C) 2009-2013, Luis Pedro Coelho <luis@luispedro.org>
# vim: set ts=4 sts=4 sw=4 expandtab smartindent:
# 
# Permission is hereby granted, free of charge, to any person obtaining a copy
#  of this software and associated documentation files (the "Software"), to deal
#  in the Software without restriction, including without limitation the rights
#  to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
#  copies of the Software, and to permit persons to whom the Software is
#  furnished to do so, subject to the following conditions:
# 
# The above copyright notice and this permission notice shall be included in
#  all copies or substantial portions of the Software.
# 
# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
#  IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
#  FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
#  AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
#  LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
#  OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
#  THE SOFTWARE.

from __future__ import division
import numpy as np

__all__ = ['stretch', 'stretch_rgb', 'as_rgb']

def stretch_rgb(img, arg0=None, arg1=None, dtype=np.uint8):
    '''Variation of stretch() function that works per-channel on an RGB image

    Parameters
    ----------
    img : ndarray
        input image. It is *not modified* by this function
    min : integer, optional
        minimum value for output [default: 0]
    max : integer, optional
        maximum value for output [default: 255]
    dtype : dtype of output,optional
         [default: np.uint8]

    Returns
    -------
    img': ndarray
        resulting image. ndarray of same shape as `img` and type `dtype`.

    See Also
    --------
    stretch : function
    '''
    if img.ndim == 2:
        return stretch(img, arg0, arg1, dtype)
    elif img.ndim == 3:
        return np.dstack([stretch(img[:,:,i], arg0, arg1, dtype) for i in range(img.shape[2])])
    else:
        raise ValueError('mahotas.stretch_rgb: Only works for RGB images')


def stretch(img, arg0=None, arg1=None, dtype=np.uint8):
    '''
    img' = stretch(img, [dtype=np.uint8])
    img' = stretch(img, max, [dtype=np.uint8])
    img' = stretch(img, min, max, [dtype=np.uint8])

    Contrast stretch the image to the range [0, max] (first form) or
        [min, max] (second form).

    Parameters
    ----------
    img : ndarray
        input image. It is *not modified* by this function
    min : integer, optional
        minimum value for output [default: 0]
    max : integer, optional
        maximum value for output [default: 255]
    dtype : dtype of output,optional
         [default: np.uint8]

    Returns
    -------
    img': ndarray
        resulting image. ndarray of same shape as `img` and type `dtype`.

    Bugs
    ----
    If max > 255, then it truncates the values if dtype is not specified.
    '''
    if arg0 is None:
        min = 0
        max = 255
    elif arg1 is None:
        min = 0
        max = arg0
    else:
        min = arg0
        max = arg1
    img = img.astype(np.double)
    img -= img.min()
    ptp = img.ptp()
    if not ptp:
        img = np.zeros(img.shape, dtype)
        if min:
            img += min
        return img
    img *= float(max - min)/ptp
    if min: img += min
    return img.astype(dtype)

def as_rgb(r, g, b):
    '''
    rgb = as_rgb(r, g, b)

    Returns an RGB image with ``r`` in the red channel, ``g`` in the green, and
    ``b`` in the blue. The channels are contrast stretched.

    If any of the channels is `None`, that channel is set to zero. The same can
    be achieved by passing ``0`` as that channels value. In fact, passing a
    number as a channel value will set the whole channel to that value.

    Example
    -------

    This shows a nice looking picture::

        z1 = np.linspace(0, np.pi)
        X,Y = np.meshgrid(z1, z1)
        red = np.sin(X)
        green = np.cos(4*Y)
        blue = X*Y

        plt.imshow(mahotas.as_rgb(red, green, blue))

    Notice that the scaling on the ``blue`` channel is so different from the
    other channels (from 0..2500 compared with 0..1), but ``as_rgb`` stretches
    each channel independently.

    Parameters
    ----------
    r,g,b : array-like or int, optional
        The channels can be of any type or None.
        At least one must be not None and all must have the same shape.

    Returns
    -------
    rgb : ndarray
        RGB ndarray
    '''
    for c in (r,g,b):
        if c is not None:
            c = np.array(c)
            shape = c.shape
            if shape != ():
                break
    else:
        raise ValueError('mahotas.as_rgb: Not all arguments can be None')
    def s(c):
        if c is None:
            return np.zeros(shape, np.uint8)
        c = np.asanyarray(c)
        if c.shape == ():
            c = np.tile(c, shape)
            return c.astype(np.uint8)
        elif c.shape != shape:
            sh = lambda c : (c.shape if c is not None else ' . ')
            raise ValueError('mahotas.as_rgb: Not all arguments have the same shape. Shapes were : %s' % [sh(r), sh(g), sh(b)])
        return stretch(c)
    return np.dstack([s(r), s(g), s(b)])


########NEW FILE########
__FILENAME__ = surf
import warnings
warnings.warn(
'''Use

from mahotas.features import surf
''', DeprecationWarning)

from mahotas.features.surf import *

########NEW FILE########
__FILENAME__ = tas
import warnings
warnings.warn(
'''Use

from mahotas.features import tas
''', DeprecationWarning)

from mahotas.features.tas import *

########NEW FILE########
__FILENAME__ = pymorph_copy
# This is from Pymorph.
# Partial copy
import numpy as np

def add4dilate(f, c):
    from numpy import asarray, minimum, maximum, float64

    if not c:
        return f
    y = asarray(f,float64) + c
    k1,k2 = limits(f)
    y = ((f==k1) * k1) + ((f!=k1) * y)
    y = maximum(minimum(y,k2),k1)
    return y.astype(f.dtype)
def mat2set(A):
    from numpy import take, ravel, nonzero, transpose, newaxis

    if len(A.shape) == 1: A = A[newaxis,:]
    offsets = nonzero(ravel(A) - limits(A)[0])[0]
    if len(offsets) == 0: return ([],[])
    h,w = A.shape
    x = [0,1]
    x[0] = offsets//w - (h-1)//2
    x[1] = offsets%w - (w-1)//2
    x = transpose(x)
    return x,take(ravel(A),offsets)

def dilate(f, B):
    from numpy import maximum, newaxis, ones, int32
    h,w = f.shape
    x,v = mat2set(B)
    mh,mw = max(abs(x)[:,0]),max(abs(x)[:,1])
    y = (ones((h+2*mh,w+2*mw),int32) * limits(f)[0]).astype(f.dtype)
    for i in range(x.shape[0]):
        if v[i] > -2147483647:
            y[mh+x[i,0]:mh+x[i,0]+h, mw+x[i,1]:mw+x[i,1]+w] = maximum(
                y[mh+x[i,0]:mh+x[i,0]+h, mw+x[i,1]:mw+x[i,1]+w], add4dilate(f,v[i]))
    y = y[mh:mh+h, mw:mw+w]
    return y

def sereflect(Bi):
    return Bi[::-1, ::-1]
def limits(f):
    from numpy import array, bool, uint8, uint16, int32, int64
    code = f.dtype
    if code == bool: return 0,1
    if code == uint8: return 0,255
    if code == uint16: return 0,65535
    if code == int32: return -2147483647,2147483647
    if code == int64: return -2**63,2**63-1

    raise ValueError('pymorph.limits: does not accept this typecode: %s' % code)

def neg(f):
    y = limits(f)[0] + limits(f)[1] - f
    return y.astype(f.dtype)

def erode(f, b):
    return neg(dilate(neg(f),sereflect(b)))


def cdilate(f, g, Bc, n=1):
    f = np.minimum(f,g)
    for i in range(n):
        prev = f
        f = np.minimum(dilate(f, Bc), g)
        if np.all(f == prev): break
    return f



########NEW FILE########
__FILENAME__ = test_bbox
import numpy as np
import mahotas
from mahotas import bbox
from nose.tools import raises

def test_croptobbox():
    X,Y = np.meshgrid(np.arange(16)-8,np.arange(16)-8)
    ball = ((X**2+Y**2) < 32).astype(np.uint8)
    assert mahotas.croptobbox(ball).sum() == ball.sum()
    assert mahotas.croptobbox(ball,border=2).sum() == ball.sum()
    assert mahotas.croptobbox(ball,border=256).sum() == ball.sum()
    assert mahotas.croptobbox(ball,border=256).size == ball.size
    assert mahotas.croptobbox(ball.T).sum() == ball.sum()

    assert mahotas.croptobbox(ball[::2]).sum() == ball[::2].sum()
    assert mahotas.croptobbox(ball[::2].T).sum() == ball[::2].sum()
    assert mahotas.croptobbox(ball.T, border=2).sum() == ball.sum()
    assert mahotas.croptobbox(ball.T, border=256).sum() == ball.sum()
    assert mahotas.croptobbox(ball.T, border=256).size == ball.size

def test_bbox_empty():
    assert mahotas.bbox(np.zeros((), np.bool)).shape == (0,)

def test_bbox_3():
    YXZ = np.indices((32,32,64), float)
    YXZ -= 8
    Y,X,Z = YXZ
    ball = ((X**2+Y**2+Z**2) < 64).astype(np.uint8)
    m0,M0,m1,M1,m2,M2 = mahotas.bbox(ball)

    Y,X,Z = np.where(ball)
    assert np.all(m0 <= Y)
    assert np.all(m1 <= X)
    assert np.all(m2 <= Z)
    assert np.all(M0 > Y)
    assert np.all(M1 > X)
    assert np.all(M2 > Z)


def test_bbox():
    img = np.zeros((10,10), np.uint16)
    
    a0,b0,a1,b1 = bbox(img)
    assert a0 == b0
    assert a1 == b1

    img[4,2]=1
    a0,b0,a1,b1=bbox(img)
    assert a0 == 4
    assert b0 == 5
    assert a1 == 2
    assert b1 == 3

    img[6,8]=1
    a0,b0,a1,b1=bbox(img)
    assert a0 == 4 
    assert b0 == 7 
    assert a1 == 2 
    assert b1 == 9 

    img[7,7]=1
    a0,b0,a1,b1=bbox(img)
    assert a0 == 4
    assert b0 == 8
    assert a1 == 2
    assert b1 == 9

    c0,d0,c1,d1=bbox(img, 0)
    assert c0 == a0
    assert b0 == d0
    assert c1 == a1
    assert b1 == d1

    c0,d0,c1,d1=bbox(img, 1)
    assert c0 != a0
    assert b0 != d0
    assert c1 != a1
    assert b1 != d1

def test_as_slice():
    YXZ = np.indices((32,32,64), float)
    YXZ -= 8
    Y,X,Z = YXZ
    ball = ((X**2+Y**2+Z**2) < 64).astype(np.uint8)
    s = bbox(ball, as_slice=True)
    assert ball[s].sum() == ball.sum()

########NEW FILE########
__FILENAME__ = test_bwperim
from mahotas import bwperim
import numpy as np

def _neighbours(bwimg, y, x, n):
    s0 = max(0, y-1)
    e0 = min(y+2, bwimg.shape[0])
    s1 = max(0, x-1)
    e1 = min(x+2, bwimg.shape[1])
    if n == 8:
        return bwimg[s0:e0, s1:e1]
    return np.concatenate([bwimg[s0:e0,x], bwimg[y,s1:e1]])

def _slow_bwperim(bwimg, n=4):
    r,c = bwimg.shape
    res = np.zeros_like(bwimg)
    for y in range(r):
        for x in range(c):
            res[y,x] = bwimg[y,x] and np.any(~_neighbours(bwimg,y,x,n))
    return res

def _compare_slow(img):
    for n in (4,8):
        assert np.all(_slow_bwperim(img, n) == bwperim(img, n))

def test_bwperim():
    img = np.zeros((8,8), np.bool)
    img[3:7,3:7] = 1
    _compare_slow(img)

    assert img[3:7,3:7].all()
    assert img[3:7,3:7].sum() == img.sum()
    img[2,2:4] = 1
    _compare_slow(img)

########NEW FILE########
__FILENAME__ = test_center_of_mass
import numpy as np
from scipy import ndimage
import mahotas.center_of_mass

np.random.seed(2321)
def _mean_out(img, axis):
    if len(img.shape) == 2: return img.mean(1-axis)
    if axis == 0:
        return _mean_out(img.mean(1), 0)
    return _mean_out(img.mean(0), axis - 1)

def slow_center_of_mass(img):
    '''
    Returns the center of mass of img.
    '''
    xs = []
    for axis,si in enumerate(img.shape):
        xs.append(np.mean(_mean_out(img, axis) * np.arange(si)))
    xs = np.array(xs)
    xs /= img.mean()
    return xs


def test_cmp_ndimage():
    R = (255*np.random.rand(128,256)).astype(np.uint16)
    R += np.arange(256, dtype=np.uint16)
    m0,m1 = mahotas.center_of_mass(R)
    n0,n1 = ndimage.center_of_mass(R)
    assert np.abs(n0 - m0) < 1.
    assert np.abs(n1 - m1) < 1.

def test_cmp_ndimage3():
    R = (255*np.random.rand(32,128,8,16)).astype(np.uint16)
    R += np.arange(16, dtype=np.uint16)
    m = mahotas.center_of_mass(R)
    n = ndimage.center_of_mass(R)
    p = slow_center_of_mass(R)
    assert np.abs(n - m).max() < 1.
    assert np.abs(p - m).max() < 1.

def test_simple():
    R = (255*np.random.rand(128,256)).astype(np.uint16)
    R += np.arange(256, dtype=np.uint16)
    m0,m1 = mahotas.center_of_mass(R)

    assert 0 < m0 < 128
    assert 0 < m1 < 256


def test_labels():
    R = (255*np.random.rand(128,256)).astype(np.uint16)
    labels = np.zeros(R.shape, np.intc)
    labels[100:,:] += 1
    labels[100:,100:] += 1
    centres =  mahotas.center_of_mass(R, labels)
    for label,cm in enumerate(centres):
        assert np.all(cm == mahotas.center_of_mass(R * (labels == label)))



def test_labels_not_intc():
    img = np.arange(256).reshape((16,16))
    labels = img.copy()
    labels %= 3
    cm = mahotas.center_of_mass(img, labels)
    assert cm.shape == (3,2)

    labels = labels.T.copy()
    cm = mahotas.center_of_mass(img, labels.T)
    assert cm.shape == (3,2)

    labels = labels.T.copy()
    labels = labels.astype(np.uint16)
    cm = mahotas.center_of_mass(img, labels)
    assert cm.shape == (3,2)


########NEW FILE########
__FILENAME__ = test_citation
import mahotas as mh
def test_citation():
    from sys import stdout
    t = mh.citation(False)
    assert len(stdout.getvalue()) == 0
    t2 = mh.citation(True)
    assert len(stdout.getvalue()) != 0
    assert t == t2

########NEW FILE########
__FILENAME__ = test_close_holes
import numpy as np
import mahotas
import sys

def test_close_holes_simple():
    img = np.zeros((64,64),bool)
    img[16:48,16:48] = True
    holed =  (img - mahotas.erode(mahotas.erode(img)))
    assert np.all( mahotas.close_holes(holed) == img)
    holed[12,12] = True
    img[12,12] = True
    assert np.all( mahotas.close_holes(holed) == img)
    assert sys.getrefcount(holed) == 2

########NEW FILE########
__FILENAME__ = test_colors
import mahotas
import numpy as np
from mahotas.tests.utils import luispedro_jpg
from mahotas.colors import rgb2xyz, rgb2lab, xyz2rgb, rgb2grey, rgb2sepia

def test_colors():
    f = luispedro_jpg()
    lab = rgb2lab(f)
    assert np.max(np.abs(lab)) <= 100.
    assert np.max(np.abs(xyz2rgb(rgb2xyz(f)) - f)) < 1.

    lab8 = rgb2lab(f, dtype=np.uint8)
    assert lab.dtype != np.uint8
    assert lab8.dtype == np.uint8

    xyz = rgb2xyz(f, dtype=np.uint8)
    assert xyz.shape == f.shape
    assert xyz.dtype == np.uint8


def test_rgb2grey():
    f = luispedro_jpg()
    fg = rgb2grey(f)
    fg8 = rgb2grey(f, dtype=np.uint8)
    assert f.ndim == 3
    assert fg.ndim == 2
    assert fg8.ndim == 2
    assert fg.shape[0] == f.shape[0]
    assert fg.shape[1] == f.shape[1]
    assert fg.shape == fg8.shape
    assert fg8.dtype == np.uint8


def test_sepia():
    f = luispedro_jpg()
    sepia= mahotas.colors.rgb2sepia(f)
    assert sepia.shape == f.shape

########NEW FILE########
__FILENAME__ = test_convolve
import numpy as np
import mahotas
import mahotas.convolve
import mahotas as mh
from mahotas.convolve import convolve1d, gaussian_filter
import mahotas._filters
from os import path
from nose.tools import raises
from mahotas.tests.utils import luispedro_jpg

def test_compare_w_ndimage():
    from scipy import ndimage
    A = np.arange(34*340, dtype='float64').reshape((34,340))%3
    B = np.ones((3,3), A.dtype)
    for mode in mahotas._filters.modes:
        if mode == 'ignore':
            continue
        assert np.all(mahotas.convolve(A, B, mode=mode) == ndimage.convolve(A, B, mode=mode))

def test_22():
    A = np.arange(1024).reshape((32,32))
    B = np.array([
        [0,1],
        [2,3],
        ])
    C = np.array([
        [0,1,0],
        [2,3,0],
        [0,0,0],
        ])
    AB = mahotas.convolve(A,B)
    AC = mahotas.convolve(A,C)
    assert AB.shape == AC.shape
    assert np.all(AB == AC)


@raises(ValueError)
def test_mismatched_dims():
    f = np.arange(128*128, dtype=float).reshape((128,128))
    filter = np.arange(17,dtype=float)-8
    filter **= 2
    filter /= -16
    np.exp(filter,filter)
    mahotas.convolve(f,filter)

def test_convolve1d_shape():
    f = np.arange(64*4).reshape((16,-1))
    n = [.5,1.,.5]
    for axis in (0,1):
        g = convolve1d(f, n, axis)
        assert g.shape == f.shape

@raises(ValueError)
def test_convolve1d_2d():
    f = np.arange(64*4).reshape((16,-1))
    n = np.array([[.5,1.,.5],[0.,2.,0.]])
    convolve1d(f, n, 0)


def test_gaussian_filter():
    from scipy import ndimage
    f = luispedro_jpg(1)
    for s in (4.,8.,12.):
        g = gaussian_filter(f, s)
        n = ndimage.gaussian_filter(f, s)
        assert np.max(np.abs(n - g)) < 1.e-5

def test_gaussian_order():
    im = np.arange(64*64).reshape((64,64))
    for order in (1,2,3):
        g_mat = mahotas.gaussian_filter(im, 2., order=order)

def test_gaussian_order_high():
    im = np.arange(64*64).reshape((64,64))
    @raises(ValueError)
    def gaussian_order(order):
        mahotas.gaussian_filter(im, 2., order=order)
    yield gaussian_order, 4
    yield gaussian_order, 5
    yield gaussian_order, -3
    yield gaussian_order, -1
    yield gaussian_order, 1.5

def test_haar():
    image = luispedro_jpg(1)
    image = image[:256,:256]
    wav = mahotas.haar(image)

    assert wav.shape == image.shape
    assert np.allclose((image[0].reshape((-1,2)).mean(1)+image[1].reshape((-1,2)).mean(1))/2, wav[0,:128]/2.)
    assert np.abs(np.mean(image**2) - np.mean(wav**2)) < 1.

    image = luispedro_jpg(1)
    wav =  mahotas.haar(image, preserve_energy=False)
    assert np.abs(np.mean(image**2) - np.mean(wav**2)) > 16.
    wav =  mahotas.haar(image, inline=True)
    assert id(image) == id(wav)

def test_ihaar():
    image = luispedro_jpg(1)
    image = image[:256,:256]
    wav = mahotas.haar(image)
    iwav = mahotas.ihaar(wav)
    assert np.allclose(image, iwav)
    iwav = mahotas.ihaar(wav, preserve_energy=False)
    assert not np.allclose(wav, iwav)
    iwav =  mahotas.ihaar(wav, inline=True)
    assert id(iwav) == id(wav)


def test_daubechies_D2_haar():
    image = luispedro_jpg(1)
    image = image[:256,:256]
    wav = mahotas.haar(image, preserve_energy=False)
    dau = mahotas.daubechies(image, 'D2')

    assert wav.shape == dau.shape
    assert np.allclose(dau, wav)

def test_3d_wavelets_error():
    @raises(ValueError)
    def call_f(f):
        f(np.arange(4*4*4).reshape((4,4,4)))

    yield call_f, mahotas.haar
    yield call_f, mahotas.ihaar
    yield call_f, lambda im: mahotas.daubechies(im, 'D4')

@raises(ValueError)
def test_non_valid_daubechies():
    image = luispedro_jpg()
    mahotas.daubechies(image, 'D-4')

def test_wavelets_inline():
    def inline(f):
        im = np.arange(16, dtype=float).reshape((4,4))
        t = f(im, inline=True)
        assert id(im) == id(t)

    yield inline, mahotas.haar
    yield inline, lambda im,inline: mahotas.daubechies(im, 'D4', inline=inline)

def test_wavelet_iwavelet():
    f = luispedro_jpg(1)
    f = f[:256,:256]
    fo = f.copy()
    D4 = np.array([0.6830127,  1.1830127,  0.3169873, -0.1830127], dtype=np.float32)
    D4_high = D4[::-1].copy()
    D4_high[1::2] *= -1
    f = f[34]
    low = np.convolve(f, D4)
    high = np.convolve(f,D4_high)
    low[::2] = 0
    high[::2] = 0
    rec = (np.convolve(high, D4_high[::-1])+np.convolve(low, D4[::-1]))
    rec /= 2
    f2 = np.array([f])
    mahotas._convolve.wavelet(f2,D4)

    hand = np.concatenate((low[3::2],high[3::2]))
    wav = f2.ravel()
    assert np.allclose(hand,wav)
    mahotas._convolve.iwavelet(f2,D4)
    assert np.allclose(rec[3:-3],f)
    assert np.allclose(f2.ravel()[3:-3],f[3:-3])

    
def test_daubechies_idaubechies():
    f = luispedro_jpg(1)
    f = f[:256,:256]
    fo = f.copy()

    d = mahotas.daubechies(f, 'D8')
    r = mahotas.idaubechies(d, 'D8')
    assert np.mean( (r[4:-4,4:-4] - fo[4:-4,4:-4])**2) < 1.


def _is_power2(x):
    if x in (0,1,2,4,8,16,32,64,128): return True
    if (x & 1) != 0: return False
    return _is_power2(x // 2)

def test_center_decenter():
    from mahotas import wavelet_decenter
    from mahotas import wavelet_center
    np.random.seed(12)
    for border in (0, 1, 17):
        f = np.random.rand(51,100)
        fc = wavelet_center(f, border=border)
        assert all(map(_is_power2, fc.shape))
        
        fd = wavelet_decenter(fc, f.shape, border=border)

        assert fd.shape == f.shape
        assert np.all(fd == f)


def test_center_border():
    from mahotas import wavelet_center
    np.random.seed(12)
    for border in (16, 24):
        f = np.random.rand(51,100)
        fc = wavelet_center(f, border=border)
        assert np.all(fc[:border] == 0)
        assert np.all(fc[-border:] == 0)
        assert np.all(fc.T[:border] == 0)
        assert np.all(fc.T[-border:] == 0)

def test_center_wavelet_iwavelet_decenter():
    from mahotas import wavelet_center, wavelet_decenter
    import mahotas
    import numpy as np

    f = luispedro_jpg(1)
    f = f[:100,:250]
    fo = f.copy()

    for wav in ('D2', 'D4', 'D6', 'D8', 'D10', 'D12', 'D16'):
        fc = mahotas.wavelet_center(fo, border=24)
        t = mahotas.daubechies(fc, wav)
        r = mahotas.idaubechies(t, wav)
        rd = mahotas.wavelet_decenter(r, fo.shape, border=24)
        assert np.allclose(fo, rd)


def test_convolve1d():
    ws = [
        np.array([-.1, .5,.7,.7,.5]),
        np.array([.1,.7,.5]),
        ]
    for i in range(8):
        for w in ws:
            f = np.random.random((128,96))
            ww = np.atleast_2d(w)
            fw = mh.convolve(f, ww)
            fww = mh.convolve(f, ww.T)

            f0w = mh.convolve1d(f, w, 0)
            f1w = mh.convolve1d(f, w, 1)

            assert np.all(fw == f1w)
            assert np.all(fww == f0w)

@raises(ValueError)
def test_gaussian_small_sigma():
    im =  np.arange(128*4).reshape((16,-1))
    mh.gaussian_filter(im, .01)


def test_gaussian_small_image():
    np.random.seed(123)
    f = (np.random.random((10,141))*255).astype(np.uint8)
    ff = mh.gaussian_filter(f, 2.)
    assert f.shape == ff.shape


def test_convolve1d_axis():
    f = np.random.random((128,32))
    w = np.array([.1, .2, .4])
    fw = mh.convolve1d(f, w, 0)
    for i in range(32):
        assert np.allclose(np.correlate(f.T[i], w, 'same')[1:-1], fw[1:-1,i])

def test_convolve_1d_axis_3d():
    f = np.random.random((128,32,6))
    w = np.array([.1, .2, .4])
    fw = mh.convolve1d(f, w, 0)
    for i in range(f.shape[1]):
        for j in range(f.shape[2]):
            assert np.allclose(np.correlate(f[:,i,j], w,'same')[1:-1:] , fw[:,i,j][1:-1])

########NEW FILE########
__FILENAME__ = test_demos
import mahotas.demos
from os import path

def test_image_path():
    assert path.exists(mahotas.demos.image_path('luispedro.jpg'))
    assert not path.exists(mahotas.demos.image_path('something-that-does-not-exist'))


########NEW FILE########
__FILENAME__ = test_dilate_erode
import numpy as np
import mahotas as mh
import mahotas

def test_grey_erode():
    from mahotas.tests.pymorph_copy import erode as slow_erode
    from mahotas.tests.pymorph_copy import dilate as slow_dilate
    np.random.seed(334)
    for i in range(8):
        f = np.random.random_sample((128,128))
        f *= 255
        f = f.astype(np.uint8)
        B = (np.random.random_sample((3,3))*255).astype(np.uint8)
        B //= 4
        fast = mahotas.erode(f,B)
        slow = slow_erode(f,B)
        # mahotas & pymorph use different border conventions.
        assert np.all(fast[1:-1,1:-1] == slow[1:-1,1:-1])

        fast = mahotas.dilate(f,B)
        slow = slow_dilate(f,B)
        # mahotas & pymorph use different border conventions.
        assert np.all(fast[1:-1,1:-1] == slow[1:-1,1:-1])


def test_dilate_erode():
    A = np.zeros((128,128), dtype=bool)
    Bc = np.array([
        [0, 1, 0],
        [1, 1, 1],
        [0, 1, 0]], bool)
    A[32,32] = True
    origs = []
    for i in range(12):
        origs.append(A.copy())
        A = mahotas.dilate(A, Bc)
    for i in range(12):
        A = mahotas.erode(A, Bc)
        assert np.all(A == origs[-i-1])



def test_dilate_1():
    A = np.zeros((16,16), dtype=np.uint8)
    B = np.array([
        [0,1,0],
        [2,2,1],
        [1,3,0]], dtype=np.uint8)
    A[8,8] = 1
    D = mahotas.dilate(A, B)
    assert np.sum(D) == np.sum(B+(B>0))

def test_signed():
    A = np.array([0,0,1,1,1,0,0,0], dtype=np.int32)
    B = np.array([0,1,0])
    assert np.min(mahotas.erode(A,B)) == -1


def test_cerode():
    from mahotas.tests.pymorph_copy import erode as slow_erode
    from mahotas.tests.pymorph_copy import dilate as slow_dilate
    np.random.seed(334)
    f = np.random.random_sample((128,128))
    f = (f > .9)
    assert np.all(mahotas.erode(f) == mahotas.cerode(f, np.zeros_like(f)))

def test_cdilate():
    from mahotas.tests.pymorph_copy import cdilate as slow_cdilate
    np.random.seed(332)
    Bc = np.zeros((3,3),bool)
    Bc[1] = 1
    Bc[:,1] = 1
    for n in range(8):
        f = np.random.random_sample((128,128))
        f = (f > .9)
        g = np.random.random_sample((128,128))
        g = (g > .7)
        assert np.all(mahotas.cdilate(f,g,Bc,n+1) == slow_cdilate(f,g,Bc,n+1))


def test_cdilate_large():
    f = np.zeros((8,8),bool)
    f[4,4] = 1
    assert np.all(mh.cdilate(f, 12))


def test_erode_slice():
    np.random.seed(30)
    for i in range(16):
        f = (np.random.random_sample((256,256))*255).astype(np.uint8)
        assert np.all(mahotas.erode(f[:3,:3]) == mahotas.erode(f[:3,:3].copy()))

def test_dilate_slice():
    np.random.seed(30)
    for i in range(16):
        f = (np.random.random_sample((256,256))*255).astype(np.uint8)
        assert np.all(mahotas.dilate(f[:3,:3]) == mahotas.dilate(f[:3,:3].copy()))

def test_fast_binary():
    # This test is based on an internal code decision: the fast code is only triggered for CARRAYs
    # Therefore, we test to see if both paths lead to the same result
    np.random.seed(34)
    for i in range(8):
        f = np.random.random((128,128)) > .9
        f2 = np.dstack([f,f,f])

        SEs = [
            np.ones((3,3)),
            np.ones((5,5)),
            np.array([
                    [0,1,0],
                    [0,0,0],
                    [0,0,0]]),
            np.array([
                    [0,0,0],
                    [1,0,0],
                    [0,0,0]]),
            np.array([
                    [1,0,0],
                    [1,0,0],
                    [0,0,0]]),
            np.array([
                    [1,1,1],
                    [1,1,1],
                    [1,1,0]]),
            np.array([
                    [1,1,1],
                    [0,1,1],
                    [1,1,0]]),
            ]
        for Bc in SEs:
            assert np.all(mahotas.erode(f,Bc=Bc) == mahotas.erode(f2[:,:,1],Bc=Bc))
            # For dilate, the border conditions are different;
            # This is not great, but it's actually the slow implementation
            # which has the most unsatisfactory behaviour:
            assert np.all(mahotas.dilate(f,Bc=Bc)[1:-1,1:-1] == mahotas.dilate(f2[:,:,1],Bc=Bc)[1:-1,1:-1])

def test_se_zeros():
    np.random.seed(35)
    f = np.random.random((128,128)) > .9
    f2 = np.dstack([f,f,f])
    mahotas.erode(f, np.zeros((3,3)))
    mahotas.dilate(f, np.zeros((3,3)))
    mahotas.erode(f2[:,:,1], np.zeros((3,3)))
    mahotas.dilate(f2[:,:,1], np.zeros((3,3)))

########NEW FILE########
__FILENAME__ = test_distance
from mahotas import distance
import numpy as np
def _slow_dist(bw, metric):
    sd = np.empty(bw.shape, np.double)
    sd.fill(np.inf)
    Y,X = np.indices(bw.shape)
    for y,x in zip(*np.where(~bw)):     
        sd = np.minimum(sd, (Y-y)**2 + (X-x)**2)
    if metric == 'euclidean':
        sd = np.sqrt(sd)
    return sd

def _slow_dist4d(bw, metric):
    sd = np.empty(bw.shape, np.double)
    sd.fill(np.inf)
    Y,X,W,Z = np.indices(bw.shape)
    for y,x,w,z in zip(*np.where(~bw)):     
        sd = np.minimum(sd, (Y-y)**2 + (X-x)**2 + (W-w)**2 + (Z-z)**2)
    if metric == 'euclidean':
        sd = np.sqrt(sd)
    return sd


def compare_slow(bw):
    for metric in ('euclidean', 'euclidean2'):
        f = distance(bw, metric)
        sd = _slow_dist(bw, metric)
        assert np.all(f == sd)

def test_distance():
    bw = np.ones((256, 256), bool)
    bw[100, 100] = 0
    yield compare_slow, bw

    bw[100:110, 100:110] = 0
    yield compare_slow, bw

    bw[200:210, 200:210] = 0
    yield compare_slow, bw


def test_uint8():
    # This did not work correctly in 0.9.5
    a8 = np.zeros((5,5), dtype=np.uint8)
    ab = np.zeros((5,5), dtype=bool)
    assert np.all(distance(a8) == distance(ab))


def test_4d():
    np.random.seed(324)
    for _ in range(16):
        binim = np.random.random((4,8,4,6)) > .5
        dist = distance(binim)
        assert dist.shape == binim.shape
        assert np.all(dist[~binim] == 0)
        assert np.all(dist == _slow_dist4d(binim, 'euclidean2'))

########NEW FILE########
__FILENAME__ = test_edge
from mahotas.edge import sobel
from nose.tools import raises
import numpy as np

def test_sobel_shape():
    A = np.arange(100*100)
    A = (A % 15)
    A = A.reshape((100,100))
    assert sobel(A).shape == A.shape
    assert sobel(A, just_filter=True).shape == A.shape

def test_sobel_zeros():
    A = np.zeros((15,100))
    assert sobel(A).shape == A.shape
    assert sobel(A).sum() == 0

def test_sobel():
    I = np.array([
            [0,0,0,0,0,0],
            [0,0,0,1,0,0],
            [0,0,0,1,0,0],
            [0,0,0,1,0,0],
            [0,0,0,1,0,0],
            [0,0,0,0,0,0]])
    E = sobel(I)
    r,c = I.shape
    for y,x in zip(*np.where(E)):
        N = [I[y,x]]
        if y > 0: N.append(I[y-1,x])
        if x > 0: N.append(I[y,x-1])
        if y < (r-1): N.append(I[y+1,x])
        if x < (c-1): N.append(I[y,x+1])
        assert len(set(N)) > 1

def test_zero_images():
    assert np.isnan(sobel(np.zeros((16,16)))).sum() == 0
    assert sobel(np.zeros((16,16)), just_filter=True).sum() == 0

def test_find_edge():
    import mahotas as mh
    f = np.zeros((32,48))
    f[:,16:] = 255
    f = mh.gaussian_filter(f,4)
    fs = sobel(f)
    assert np.all(fs[:,15] > 0)

@raises(ValueError)
def test_3d_error():
    import mahotas as mh
    f = np.zeros((32,16,3))
    sobel(f)

########NEW FILE########
__FILENAME__ = test_euler
import numpy as np
from mahotas.euler import euler, _euler_lookup4, _euler_lookup8
from nose.tools import raises

def test_lookup():
    Q1 = [np.array(q, np.bool) for q in ([[0,0],[1,0]], [[0,0],[0,1]], [[0,1],[0,0]], [[1,0],[0,0]]) ]
    Q2 =  [(~q) for q in Q1]
    Q3 = [np.array(q, np.bool) for q in ([[0,1],[1,0]], [[1,0],[0,1]]) ]

    def _value(q, lookup):
        q = q.ravel()
        value = np.dot(q, (1,2,4,8))
        return lookup[value]

    for q in Q1:
        assert _value(q, _euler_lookup8) == .25
        assert _value(q, _euler_lookup4) == .25
    for q in Q2:
        assert _value(q, _euler_lookup8) == -.25
        assert _value(q, _euler_lookup4) == -.25
    for q in Q3:
        assert _value(q, _euler_lookup8) == -.5
        assert _value(q, _euler_lookup4) ==  .5

def test_euler():
    f = np.zeros((16,16), np.bool)
    f[4:8,4:8] = 1
    assert euler(f) == 1
    assert euler(f, 4) == 1

    f[6:7,5:7] = 0

    assert euler(f) == 0
    assert euler(f, 4) == 0

@raises(ValueError)
def test_euler7():
    f = np.arange(100)
    f = (f % 5) == 1
    f = f.reshape((10,10))
    euler(f, 7)


########NEW FILE########
__FILENAME__ = test_features_shape
import mahotas.features.shape
import numpy as np
import mahotas as mh
from mahotas.features.shape import roundness, eccentricity

def test_eccentricity():
    D = mh.disk(32, 2)
    ecc = mahotas.features.shape.eccentricity(D)
    assert 0 <= ecc < .01

    Index = np.indices((33,33)).astype(float)
    Index -= 15
    X,Y = Index
    ellipse = ((X**2+2*Y**2) < 12**2)
    assert 0 < mahotas.features.shape.eccentricity(ellipse) < 1

def test_roundness():
    Y,X = -24 + np.indices((48,48)).astype(float)
    r = roundness( (Y ** 2. + X**2.) < 4**2. )
    assert r > 0
    r2 = roundness( (Y ** 2. + 2* X**2.) < 4**2. )
    assert r2 > 0
    assert r2 < r

def test_zeros():
    assert roundness(np.zeros((10,10))) == 0
    assert eccentricity(np.zeros((10,10))) == 0
    I = np.zeros((16,16))
    I[8:4:12] = 1
    assert eccentricity(I) == 0

def test_ellipse_axes():
    Y,X = np.mgrid[:1024,:1024]
    Y = Y/1024.
    X = X/1024.
    im = ((2.*(Y - .5)**2 + (X - .5)**2) < .2)
    maj,min = mh.features.ellipse_axes(im)
    assert np.abs(2 - (maj/min)**2) < .01

    maj2,min2 = mh.features.ellipse_axes(im.T)

    assert np.abs(maj - maj2) < .001
    assert np.abs(min - min2) < .001

    im = (((Y - .5)**2 + (X - .5)**2) < .2)
    maj,min = mh.features.ellipse_axes(im)
    assert np.abs(1 - (maj/min)**2) < .01

########NEW FILE########
__FILENAME__ = test_filters
from mahotas import _filters
from nose.tools import raises

@raises(ValueError)
def test_bad_mode():
    _filters._check_mode('nayrest', 0., 'f')

@raises(NotImplementedError)
def test_cval_not_zero():
    _filters._check_mode('constant', 1.2, 'f')

def test_good_mode():
    for mode in _filters.modes:
        _filters._check_mode(mode, 0., 'f')


########NEW FILE########
__FILENAME__ = test_find
import numpy as np
import mahotas as mh
def test_find():
    for _ in range(16):
        f = np.random.random((128,128))
        c0,c1 = 43,23
        for h,w in [(12,56),
                    (11,7),
                    (12,7)]:
            matches = mh.find(f, f[c0:c0+h, c1:c1+w])
            coords = np.array(np.where(matches))
            assert np.all(coords.T == np.array((c0,c1)), 1).any()

def test_negative():
    f = 255*np.random.random((228,228))
    f = f.astype(np.uint8)
    h,w = 12,6
    t = f[:h,:w]
    matches = mh.find(f, t)
    coords = np.array(np.where(matches))
    for y,x in zip(*coords):
        if y < 0 or x < 0:
            continue
        assert np.all(f[y:y+h, x:x+w] == t)

########NEW FILE########
__FILENAME__ = test_freeimage
import numpy as np
import os
from os import path
from nose.tools import with_setup

_testimgname = '/tmp/mahotas_test.png'

try:
    from mahotas.io import freeimage
except OSError:
    from nose import SkipTest
    raise SkipTest("FreeImage not found")


def _remove_image(filename=_testimgname):
    try:
        os.unlink(filename)
    except OSError:
        pass

@with_setup(teardown=_remove_image)
def test_freeimage():
    img = np.arange(256).reshape((16,16)).astype(np.uint8)

    freeimage.imsave(_testimgname, img)
    img_ = freeimage.imread(_testimgname)
    assert img.shape == img_.shape
    assert np.all(img == img_)


@with_setup(teardown=_remove_image)
def test_as_grey():
    colour = np.arange(16*16*3).reshape((16,16,3))
    freeimage.imsave(_testimgname, colour.astype(np.uint8))
    c2 = freeimage.imread(_testimgname, as_grey=True)
    assert len(c2.shape) == 2
    assert c2.shape == colour.shape[:-1]

def test_rgba():
    rgba = path.join(
                path.dirname(__file__),
                'data',
                'rgba.png')
    rgba = freeimage.imread(rgba)
    assert np.all(np.diff(rgba[:,:,3].mean(1)) < 0 ) # the image contains an alpha gradient


@with_setup(teardown=_remove_image)
def test_save_load_rgba():
    img = np.arange(256).reshape((8,8,4)).astype(np.uint8)
    freeimage.imsave(_testimgname, img)
    img_ = freeimage.imread(_testimgname)
    assert img.shape == img_.shape
    assert np.all(img == img_)

def test_fromblob():
    img = np.arange(100, dtype=np.uint8).reshape((10,10))
    s = freeimage.imsavetoblob(img, 't.png')
    assert np.all(freeimage.imreadfromblob(s) == img)

    s = freeimage.imsavetoblob(img, 't.bmp')
    assert np.all(freeimage.imreadfromblob(s) == img)


def test_1bpp():
    bpp = path.join(
                path.dirname(__file__),
                'data',
                '1bpp.bmp')
    bpp = freeimage.imread(bpp)
    assert bpp.sum()
    assert bpp.sum() < bpp.size


_testtif = '/tmp/mahotas_test.tif'
@with_setup(teardown=lambda: _remove_image(_testtif))
def test_multi():
    f = np.zeros((16,16), np.uint8)
    fs = []
    for t in range(8):
      f[:t,:t] = t
      fs.append(f.copy())
    freeimage.write_multipage(fs, _testtif)
    fs2 = freeimage.read_multipage(_testtif)
    for f,f2 in zip(fs,fs2):
        assert np.all(f == f2)


@with_setup(teardown=_remove_image)
def test_uint16():
    img = np.zeros((32,32), dtype=np.uint16)
    freeimage.imsave(_testimgname, img)
    img_ = freeimage.imread(_testimgname)

    assert img.shape == img_.shape
    assert img.dtype == img_.dtype
    assert np.all(img == img_)


########NEW FILE########
__FILENAME__ = test_gvoronoi
import numpy as np
from mahotas.segmentation import gvoronoi

def scipy_gvoronoi(labeled):
    from scipy import ndimage
    L1,L2 = ndimage.distance_transform_edt(labeled== 0, return_distances=False, return_indices=True)
    return labeled[L1,L2]


def test_compare_w_scipy():
    np.random.seed(2322)
    for i in range(8):
        labeled = np.zeros((128,128))
        for p in range(16):
            y = np.random.randint(128)
            x = np.random.randint(128)
            labeled[y,x] = p+1
        sp = scipy_gvoronoi(labeled)
        mh = gvoronoi(labeled)
        assert np.all(sp == mh)

def test_gvoronoi():
    labeled = np.zeros((128,128))
    labeled[0,0] = 1
    labeled[-1,-1] = 2
    regions = gvoronoi(labeled)
    Y,X = np.where(regions == 1)
    assert np.all(Y+X < 128)


########NEW FILE########
__FILENAME__ = test_histogram
import numpy as np
from mahotas.histogram import fullhistogram
from nose.tools import raises

def test_fullhistogram():
    A100 = np.arange(100).reshape((10,10)).astype(np.uint32)
    assert fullhistogram(A100).shape == (100,)
    assert np.all(fullhistogram(A100) == np.ones(100))

    A1s = np.ones((12,12), np.uint8)
    assert fullhistogram(A1s).shape == (2,)
    assert np.all(fullhistogram(A1s) == np.array([0,144]))

    A1s[0] = 0
    A1s[1] = 2
    assert fullhistogram(A1s).shape == (3,)
    assert np.all(fullhistogram(A1s) == np.array([12,120,12]))

def test_fullhistogram_random():
    np.random.seed(122)
    A = np.random.rand(12,3,44,33)*1000
    A = A.astype(np.uint16)
    hist = fullhistogram(A)
    for i in range(len(hist)):
        assert hist[i] == (A == i).sum()
    assert len(hist.shape) == 1

    A = A[::2,:,2::3,1:-2:2]
    hist = fullhistogram(A)
    for i in range(len(hist)):
        assert hist[i] == (A == i).sum()
    assert hist.sum() == A.size
    assert len(hist.shape) == 1

def test_fullhistogram_boolean():
    np.random.seed(123)
    A = (np.random.rand(128,128) > .5)
    H = fullhistogram(A)
    assert H[0] == (~A).sum()
    assert H[1] == A.sum()

def test_types():
    A100 = np.arange(100).reshape((10,10)).astype(np.uint32)
    assert np.all(fullhistogram(A100.astype(np.uint8)) == fullhistogram(A100))
    assert np.all(fullhistogram(A100.astype(np.uint16)) == fullhistogram(A100))
    assert np.all(fullhistogram(A100.astype(np.uint32)) == fullhistogram(A100))
    assert np.all(fullhistogram(A100.astype(np.uint64)) == fullhistogram(A100))

@raises(TypeError)
def test_float():
    fullhistogram(np.arange(16.*4., dtype=float).reshape((16,4)))


########NEW FILE########
__FILENAME__ = test_hitmiss
import mahotas
import numpy as np


def slow_hitmiss(A, Bc):
    res = np.zeros_like(A)
    for y in range(1,A.shape[0]-1):
        for x in range(1,A.shape[1]-1):
            value = 1
            for dy in (-1,0,1):
                for dx in (-1,0,1):
                    ny = y + dy
                    nx = x + dx
                    if Bc[dy+1, dx + 1] != 2 and Bc[dy+1, dx+1] != A[ny, nx]:
                        value = 0
            res[y,x] = value
    return res

def test_hitmiss():
    A = np.zeros((100,100), np.bool_)
    Bc = np.array([
        [0,1,2],
        [0,1,1],
        [2,1,1]])
    mahotas.morph.hitmiss(A,Bc)
    assert not mahotas.morph.hitmiss(A,Bc).sum()

    A[4:7,4:7] = np.array([
        [0,1,1],
        [0,1,1],
        [0,1,1]])
    assert mahotas.morph.hitmiss(A,Bc).sum() == 1
    assert mahotas.morph.hitmiss(A,Bc)[5,5]


def test_hitmiss_against_slow():
    np.random.seed(222)
    for i in range(4):
        A = np.random.rand(100,100)
        A = (A > .3)
        Bc = np.array([
            [0,1,2],
            [0,1,1],
            [2,1,1]])
        W = mahotas.morph.hitmiss(A,Bc)
        assert np.all(W == slow_hitmiss(A, Bc))


def test_hitmiss_types():
    f = np.zeros((16,16), np.uint8)
    f[8:12,8:12] = 1
    Bc = np.array([[1, 1, 2],[1,1,2],[0,0,0]], dtype=np.int32)
    assert np.sum(mahotas.morph.hitmiss(f,Bc))
    Bc = np.array([[1, 1, 2],[1,1,2],[0,0,0]], dtype=np.int64)
    assert np.sum(mahotas.morph.hitmiss(f,Bc))


########NEW FILE########
__FILENAME__ = test_imresize
import mahotas as mh
from mahotas import imresize
import numpy as np
def test_imresize():
    img = np.repeat(np.arange(100), 10).reshape((100,10))
    assert imresize(img, (1024,104)).shape == (1024,104)
    assert imresize(img, (10.,10.)).shape == (1000,100)
    assert imresize(img, .2,).shape == (20,2)
    assert imresize(img, (10.,2.)).shape == (1000,20)


def test_resize_to():
    lena  = mh.demos.load('lena')
    im = mh.resize.resize_rgb_to(lena, [256,256])
    assert im.shape == (256,256,3)
    im = im.max(2)
    im  = mh.resize.resize_to(im, [512,256])
    assert im.shape == (512,256)

########NEW FILE########
__FILENAME__ = test_internal
import numpy as np
from mahotas.internal import _get_output, _get_axis
from mahotas.internal import _normalize_sequence, _verify_is_integer_type, _verify_is_floatingpoint_type, _as_floating_point_array
from mahotas.internal import _check_3
from nose.tools import raises

def test_get_output():
    f = np.arange(256).reshape((32,8))
    output = _get_output(f, None, 'test')
    assert output.dtype == f.dtype
    assert output.shape == f.shape
    out2 = _get_output(f, output, 'test')
    assert out2 is output

def test_dtype():
    f = np.arange(256).reshape((32,8))
    output = _get_output(f, None, 'test', np.float32)
    assert output.dtype == np.float32

@raises(ValueError)
def test_get_output_bad_shape():
    f = np.arange(256).reshape((32,8))
    output = np.zeros((16,16), f.dtype)
    _get_output(f, output, 'testing')

@raises(ValueError)
def test_get_output_non_contiguous():
    f = np.arange(256).reshape((32,8))
    output = np.zeros((32,16), f.dtype)
    output = output[:,::2]
    assert output.shape == f.shape
    _get_output(f, output, 'testing')

@raises(ValueError)
def test_get_output_explicit_dtype():
    f = np.arange(256).reshape((32,8))
    output = np.zeros_like(f)
    _get_output(f, output, 'testing', bool)


def test_get_axis_good():
    f = np.zeros((3,4,5,3,2,2,5,3,2,4,1))
    for i in range(len(f.shape)):
        assert i == _get_axis(f, i, 'test')
    for i in range(len(f.shape)):
        assert len(f.shape)-1-i == _get_axis(f, -1-i, 'test')

def test_get_axis_off():
    f = np.zeros((3,4,5,3,2,2,5,3,2,4,1))
    @raises(ValueError)
    def index(i):
        _get_axis(f, i, 'test')
    yield index, 12
    yield index, 13
    yield index, 14
    yield index, 67
    yield index, -67
    yield index, -len(f.shape)-1
    yield raises



def test_normalize():
    f = np.arange(64)
    assert len(_normalize_sequence(f, 1, 'test')) == f.ndim
    f = f.reshape((2,2,2,-1))
    assert len(_normalize_sequence(f, 1, 'test')) == f.ndim
    f = f.reshape((2,2,2,1,1,-1))
    assert len(_normalize_sequence(f, 1, 'test')) == f.ndim

def test_normalize_sequence():
    f = np.arange(64)
    assert len(_normalize_sequence(f, [1], 'test')) == f.ndim
    f = f.reshape((16,-1))
    assert _normalize_sequence(f, [2,4], 'test') == [2,4]

def test_normalize_wrong_size():
    @raises(ValueError)
    def check(ns, val):
        _normalize_sequence(f.reshape(ns), val, 'test')
    f = np.arange(64)

    check((64,),[1,2])
    check((64,),[1,1])
    check((64,),[1,2,3,4])
    check((4,-1),[1,2,3,4])
    check((4,-1),[1])
    check((4,2,-1),[1,2])

def test_verify_int():
    @raises(TypeError)
    def check_fp(arr):
        _verify_is_integer_type(arr, 'test')

    def check_int(arr):
        _verify_is_integer_type(arr, 'test')

    yield check_fp, np.arange(1., dtype=np.float)
    yield check_fp, np.arange(1., dtype=np.float32)
    yield check_fp, np.arange(1., dtype=np.float64)

    yield check_int, np.arange(1, dtype=np.int32)
    yield check_int, np.arange(1, dtype=np.uint16)
    yield check_int, np.arange(1, dtype=np.int64)

def test_verify_fp():
    def check_fp(arr):
        _verify_is_floatingpoint_type(arr, 'test')

    @raises(TypeError)
    def check_int(arr):
        _verify_is_floatingpoint_type(arr, 'test')

    yield check_fp, np.arange(1., dtype=np.float)
    yield check_fp, np.arange(1., dtype=np.float32)
    yield check_fp, np.arange(1., dtype=np.float64)

    yield check_int, np.arange(1, dtype=np.int32)
    yield check_int, np.arange(1, dtype=np.uint16)
    yield check_int, np.arange(1, dtype=np.int64)

def test_as_floating_point_array():
    def check_arr(data):
        array = _as_floating_point_array(data)
        assert np.issubdtype(array.dtype, np.float_)

    yield check_arr, np.arange(8, dtype=np.int8)
    yield check_arr, np.arange(8, dtype=np.int16)
    yield check_arr, np.arange(8, dtype=np.uint32)
    yield check_arr, np.arange(8, dtype=np.double)
    yield check_arr, np.arange(8, dtype=np.float32)
    yield check_arr, [1,2,3]
    yield check_arr, [[1,2],[2,3],[3,4]]
    yield check_arr, [[1.,2.],[2.,3.],[3.,4.]]

def test_check_3():
    _check_3(np.zeros((14,24,3), np.uint8), 'testing')

@raises(ValueError)
def test_check_3_dim4():
    _check_3(np.zeros((14,24,3,5), np.uint8), 'testing')

@raises(ValueError)
def test_check_3_not3():
    _check_3(np.zeros((14,24,5), np.uint8), 'testing')

@raises(ValueError)
def test_check_3_not3_dim4():
    _check_3(np.zeros((14,24,5,5), np.uint8), 'testing')


def test_make_binary():
    from mahotas.internal import _make_binary
    np.random.seed(34)
    binim = np.random.random_sample((32,64)) > .25
    assert _make_binary(binim) is binim
    assert np.all( _make_binary(binim.astype(int)) == binim )
    assert np.all( _make_binary(binim.astype(int)*4) == binim )
    assert np.all( _make_binary(binim.astype(float)*3.4) == binim )
    assert np.all( _make_binary(binim* np.random.random_sample(binim.shape)) == binim )


########NEW FILE########
__FILENAME__ = test_interpolate
from mahotas import interpolate
import numpy as np
from nose.tools import raises

def test_spline_filter1d_smoke():
    f  = (np.arange(64*64, dtype=np.intc) % 64).reshape((64,64)).astype(np.float64)
    f2 =interpolate.spline_filter1d(f,2,0)
    assert f.shape == f2.shape

def test_spline_filter_smoke():
    f  = (np.arange(64*64, dtype=np.intc) % 64).reshape((64,64)).astype(np.float64)
    f2 = interpolate.spline_filter(f,3)
    assert f.shape == f2.shape

def test_zoom_ratio():
    f = np.zeros((128,128))
    f[32:64,32:64] = 128
    for z in [.7,.5,.2,.1]:
        output = interpolate.zoom(f,z)
        ratio = output.sum()/f.sum()
        assert np.abs(ratio - z*z) < .1

def test_zoom_ratio_2():
    f = np.zeros((128,128))
    f[32:64,32:64] = 128
    z0,z1  = .7,.5
    output = interpolate.zoom(f,[z0,z1])
    ratio = output.sum()/f.sum()
    assert np.abs(ratio - z0*z1) < .1

def test_shift_ratio():
    f = np.zeros((128,128))
    f[32:64,32:64] = 128
    for s in [0,1,2,3]:
        output = interpolate.shift(f,(s,s))
        ratio = output.sum()/f.sum()
        assert np.abs(ratio - 1.) < .01

def test_order():
    f = np.arange(16*16).reshape((16,16))
    @raises(ValueError)
    def call_f(f, *args):
        f(*args)
    yield call_f, interpolate.spline_filter1d, f, -6
    yield call_f, interpolate.spline_filter1d, f, 6
    yield call_f, interpolate.spline_filter, f, 0

def test_complex():
    f = -np.arange(16.*16).reshape((16,16))
    f = np.lib.scimath.sqrt(f)

    @raises(TypeError)
    def call_f(f, *args):
        f(*args)
    yield call_f, interpolate.spline_filter1d, f, 3
    yield call_f, interpolate.spline_filter, f, 3


@raises(ValueError)
def test_maybe_filter_error():
    interpolate._maybe_filter(np.array(3), 1, 'testing', False, np.float32)

@raises(ValueError)
def test_short_shift():
    im = np.arange(256).reshape((16,4,-1))
    interpolate.shift(im, [1,0])

def test_shift_uint8():
    im = np.arange(256).reshape((16,-1))
    im = im.astype(np.uint8)
    interpolate.shift(im, [0, np.pi/2], order=1)

########NEW FILE########
__FILENAME__ = test_io
import numpy as np
from mahotas.io import error_imread, error_imsave
from nose.tools import raises
from os import path
import mahotas as mh

filename = path.join(
            path.dirname(__file__),
            'data',
            'rgba.png')


def skip_on(etype):
    from functools import wraps
    def skip_on2(test):
        @wraps(test)
        def execute(*args, **kwargs):
            try:
                test(*args, **kwargs)
            except Exception as e:
                if isinstance(e, etype):
                    from nose import SkipTest
                    raise SkipTest
                raise
        return execute
    return skip_on2


@raises(ImportError)
def test_error_imread():
    error_imread(filename)

@raises(ImportError)
def test_error_imsave():
    error_imsave('/tmp/test_mahotas.png', np.arange(16, dtype=np.uint8).reshape((4,4)))

@skip_on(IOError)
def test_as_grey():
    filename = path.join(
            path.dirname(__file__),
            '..',
            'demos',
            'data',
            'luispedro.jpg')
    im = mh.imread(filename, as_grey=1)
    assert im.ndim == 2

@skip_on(ImportError)
def test_matplotlibwrap():
    filename = path.join(
            path.dirname(__file__),
            '..',
            'demos',
            'data',
            'lena.jpg')
    import mahotas.io.matplotlibwrap
    im = mahotas.io.matplotlibwrap.imread(filename)
    assert im.shape == (512,512,3)

########NEW FILE########
__FILENAME__ = test_label
from mahotas import label
import numpy as np
def test_label():
    A = np.zeros((128,128), np.int)
    L,n = label(A)
    assert not L.max()
    assert n == 0

    A[2:5, 2:5] = 34
    A[10:50, 10:50] = 34
    L,n = label(A)
    assert L.max() == 2
    assert L.max() == n
    assert np.sum(L > 0) == (40*40 + 3*3)
    assert np.all( (L > 0) == (A > 0) )
    assert set(L.ravel()) == set([0,1,2])


def test_all_ones():
    labeled, nr = label(np.ones((32,32)))
    assert nr == 1
    assert np.all(labeled == 1)

def test_random():
    np.random.seed(33)
    A = np.random.rand(128,128) > .8
    labeled,nr = label(A)
    assert len(set(labeled.ravel())) == (nr+1)
    assert labeled.max() == nr

########NEW FILE########
__FILENAME__ = test_labeled
import numpy as np
import mahotas as mh
import mahotas.labeled
from nose.tools import raises

def test_border():
    labeled = np.zeros((32,32), np.uint8)
    labeled[8:11] = 1
    labeled[11:14] = 2
    labeled[14:17] = 3
    labeled[10,8:] = 0
    b12 = mahotas.labeled.border(labeled, 1, 2)
    YX = np.where(b12)
    YX = np.array(YX).T
    b13 = mahotas.labeled.border(labeled, 1, 3)

    assert not np.any(b13)
    assert np.any(b12)
    assert (11,0) in YX
    assert (11,1) in YX
    assert (12,1) in YX
    assert (12,9) not in YX

    b13 = mahotas.labeled.border(labeled, 1, 3, always_return=0)
    assert b13 is None

def _included(a,b):
    assert np.sum(a&b) == a.sum()

def test_borders():
    labeled = np.zeros((32,32), np.uint8)
    labeled[8:11] = 1
    labeled[11:14] = 2
    labeled[14:17] = 3
    labeled[10,8:] = 0
    borders = mahotas.labeled.borders(labeled)
    _included(mahotas.labeled.border(labeled,1,2), borders)
    _included(mahotas.labeled.border(labeled,1,23), borders)
    _included(mahotas.labeled.border(labeled,1,3), borders)
    _included(mahotas.labeled.border(labeled,2,3), borders)

    union = np.zeros_like(borders)
    for i in range(4):
        for j in range(4):
            if i != j:
                union |= mahotas.labeled.border(labeled, i, j)

    assert np.all(union == borders)


def slow_labeled_sum(array, labeled):
    return np.array([
            np.sum(array * (labeled == i))
            for i in range(labeled.max()+1)
        ])

def slow_labeled_max(array, labeled):
    return np.array([
            np.max(array * (labeled == i))
            for i in range(labeled.max()+1)
        ])

def slow_labeled_min(array, labeled):
    return np.array([
            np.min(array * (labeled == i))
            for i in range(labeled.max()+1)
        ])

def test_sum_labeled():
    np.random.seed(334)
    for i in range(16):
        f = np.random.random_sample((64,128))
        labeled = np.zeros(f.shape, dtype=np.intc)
        labeled += 8 * np.random.random_sample(labeled.shape).astype(np.intc)
        fast = mahotas.labeled.labeled_sum(f, labeled)
        slow = slow_labeled_sum(f, labeled)
        assert np.allclose(fast, slow)

def test_max_labeled():
    np.random.seed(334)
    for i in range(16):
        f = np.random.random_sample((64,128))
        labeled = np.zeros(f.shape, dtype=np.intc)
        labeled += 8 * np.random.random_sample(labeled.shape).astype(np.intc)
        fast = mahotas.labeled.labeled_max(f, labeled)
        slow = slow_labeled_max(f, labeled)
        assert np.allclose(fast, slow)

def test_min_labeled():
    np.random.seed(334)
    for i in range(16):
        f = np.random.random_sample((64,128))
        labeled = np.zeros(f.shape, dtype=np.intc)
        labeled += 8 * np.random.random_sample(labeled.shape).astype(np.intc)
        fast = mahotas.labeled.labeled_min(f, labeled)
        slow = slow_labeled_min(f, labeled)
        assert np.allclose(fast, slow)

def slow_labeled_size(labeled):
    return np.array([
            np.sum(labeled == i)
            for i in range(labeled.max()+1)
        ])


def test_size_labeled():
    np.random.seed(334)
    for i in range(16):
        labeled = np.zeros((64,125), dtype=np.intc)
        labeled += 8 * np.random.random_sample(labeled.shape).astype(np.intc)
        fast = mahotas.labeled.labeled_size(labeled)
        slow = slow_labeled_size(labeled)
        assert np.all(fast == slow)

def test_remove_bordering():
    np.random.seed(343)
    for i in range(4):
        labeled,_ = mahotas.label(np.random.random_sample((128,64)) > .7)
        removed = mahotas.labeled.remove_bordering(labeled)
        assert np.all(removed[0] == 0)
        assert np.all(removed[-1] == 0)
        assert np.all(removed[:,0] == 0)
        assert np.all(removed[:,-1] == 0)

        removed2 = np.zeros_like(removed)
        mahotas.labeled.remove_bordering(labeled, out=removed2)
        assert np.all(removed2 == removed)

@raises(ValueError)
def test_check_array_labeled_not_same_shape():
    arr = np.zeros((4,7))
    lab = np.zeros((4,3), dtype=np.intc)
    mahotas.labeled._as_labeled(arr, lab, 'testing')

def _nelems(arr):
    return len(set(map(int, arr.ravel())))

def test_relabel():
    np.random.seed(24)
    for i in range(8):
        f = np.random.random_sample((128,128)) > .8
        labeled, n = mahotas.labeled.label(f)
        labeled *= ( (labeled % 7) != 4)
        relabeled,new_n = mahotas.labeled.relabel(labeled)
        assert relabeled.max() == new_n
        assert (relabeled.max()+1) == _nelems(labeled)
        assert np.all( (relabeled > 0) == (labeled > 0) )
        assert not np.all(labeled == relabeled)

        for a in (8, 23, 35, 13, 213):
            assert _nelems(labeled[relabeled == a]) == 1
            assert _nelems(relabeled[labeled == a]) == 1
        mahotas.labeled.relabel(labeled, inplace=True)
        assert np.all( labeled == relabeled )


def test_remove_regions():
    np.random.seed(34)
    f = np.random.random_sample((128,128)) > .92
    labeled, n = mahotas.labeled.label(f)
    regions = [23,55,8]
    removed = mahotas.labeled.remove_regions(labeled, regions)

    for r in regions:
        assert not  np.any(removed == r)
        assert      np.any(labeled == r)
    mahotas.labeled.remove_regions(labeled, regions, inplace=True)
    assert np.all(labeled == removed)
    removed = mahotas.labeled.remove_regions(labeled, [])
    assert np.all(labeled == removed)

def test_is_same_labeling():
    np.random.seed(143)
    ell = (np.random.random((256,256))*16).astype(np.intc)
    order = np.arange(1,16)
    np.random.shuffle(order)
    order = np.insert(order, 0, 0)
    assert mh.labeled.is_same_labeling(ell, order[ell])
    ell2 = order[ell]
    ell2[ell == 0] = 1
    
    assert not mh.labeled.is_same_labeling(ell, ell2)

def test_perimeter():
    for r in (40,80,160):
        disk = mh.disk(r, 2)
        p = mahotas.labeled.perimeter(disk)
        p_exact = r*np.pi*2
        assert .9 < (p/p_exact)  < 1.1



def test_remove_regions_where():
    np.random.seed(34)
    for _ in range(4):
        f = np.random.random_sample((128,128)) > .82
        labeled, n = mh.labeled.label(f)
        relabeled = mh.labeled.remove_regions_where(labeled, mh.labeled.labeled_size(labeled) < 2)
        relabeled,_ = mh.labeled.relabel(relabeled)
        sizes = mh.labeled.labeled_size(relabeled)
        assert sizes[1:].min() >= 2

def test_remove_bordering_tuple():
    import mahotas as mh
    import numpy as np
    f = np.zeros((32,32))
    f[0,0] = 1
    f[2,4] = 2
    f.T[4,2] = 3
    f[8,8] = 4
    assert np.any(mh.labeled.remove_bordering(f) == 3)
    assert np.any(mh.labeled.remove_bordering(f, (2,4)) == 4)
    assert np.any(mh.labeled.remove_bordering(f, (2,4)) == 3)
    assert not np.any(mh.labeled.remove_bordering(f, (4,2)) == 3)

def test_as_labeled():

    from mahotas.labeled import _as_labeled
    arr = np.zeros((64,64))
    labeled = np.zeros((64,64), dtype=np.intc)
    funcname = 'testing'

    assert _as_labeled(arr, labeled, funcname, inplace=True) is labeled
    assert _as_labeled(arr, labeled, funcname) is labeled

    lab2 = _as_labeled(arr, labeled, funcname, inplace=False)
    assert lab2 is not labeled
    assert np.all(labeled == lab2)

    assert _as_labeled(arr[::2], labeled[::2], funcname, inplace=False) is not labeled
    assert _as_labeled(arr[::2], labeled[::2], funcname, inplace=None) is not labeled
    assert _as_labeled(arr[::2], labeled[::2], funcname) is not labeled

    @raises(ValueError)
    def t():
        _as_labeled(arr[::2], labeled[::2], funcname, inplace=True)
    t()

    @raises(ValueError)
    def t():
        _as_labeled(arr[::2], labeled, funcname)
    t()


########NEW FILE########
__FILENAME__ = test_lbp
from nose.tools import raises
import numpy as np
from mahotas.features import _lbp
import mahotas.thresholding
from mahotas.features import lbp
from mahotas.features.lbp import lbp_transform
from mahotas.tests.utils import luispedro_jpg

def test_shape():
    A = np.arange(32*32).reshape((32,32))
    B = np.arange(64*64).reshape((64,64))
    features0 = lbp(A, 3, 12)
    features1 = lbp(B, 3, 12)
    assert features0.shape == features1.shape

def test_nonzero():
    A = np.arange(32*32).reshape((32,32))
    features = lbp(A, 3, 12)
    features_ignore_zeros = lbp(A * (A> 256), 3, 12, ignore_zeros=True)
    assert features.sum() > 0
    assert not np.all(features == features_ignore_zeros)

def test_histogram():
    A = np.arange(32*32).reshape((32,32))
    for r in (2,3,4,5):
        assert lbp(A,r,8).sum() == A.size

def test_histogram_large():
    A = np.arange(32*32).reshape((32,32))
    for r in (2,3,4,5):
        assert lbp(A,r,12).sum() == A.size


def test_map():
    assert len(set(_lbp.map(np.arange(256,dtype=np.uint32), 8))) == 36


def test_positives():
    np.random.seed(23)
    f = np.random.random_sample((256,256))
    lbps = lbp(f, 4, 8)
    assert len(np.where(lbps == 0)[0]) < 2
    assert lbps.sum() == f.size

def test_lbp_transform():

    im = luispedro_jpg().max(2)
    transformed = lbp_transform(im, 8, 4, preserve_shape=True)
    assert transformed.shape == im.shape
    assert transformed.min() >= 0
    assert transformed.max() < 2**4
    transformed = lbp_transform(im, 8, 4, preserve_shape=False)
    assert len(transformed.shape) == 1
    assert transformed.size == im.size

    np.random.seed(234)
    im *= np.random.random(im.shape) > .1
    transformed = lbp_transform(im, 8, 4, preserve_shape=False, ignore_zeros=True)
    assert len(transformed.shape) == 1
    assert transformed.size == (im.size - (im==0).sum())


def test_count_binary1s():
    from mahotas.features.lbp import count_binary1s
    assert np.all(count_binary1s(np.zeros((23,23), np.uint8)) == np.zeros((23,23)))

    np.random.seed(3499)
    arr = np.random.randint(45,size=(23,23))
    c = count_binary1s(arr)
    assert np.all((c == 0) == (arr == 0))
    assert c.shape == arr.shape
    assert np.all(c[arr == 5] == 2)
    assert np.all(c[arr == 7] == 3)
    assert np.all(c[arr == 8] == 1)
    assert np.all(c[arr == 32] == 1)

    assert np.all(count_binary1s([128]) == [1])

@raises(ValueError)
def test_lbp_3d():
    im = np.arange(10*20*3).reshape((10,20,3))
    lbp_transform(im, 1, 8)


########NEW FILE########
__FILENAME__ = test_mahotas
def test_import():
    import mahotas

########NEW FILE########
__FILENAME__ = test_majority
import numpy as np
import mahotas.morph
from scipy import ndimage
from nose.tools import raises

def slow_majority(img, N):
    img = (img > 0)
    r,c = img.shape
    output = np.zeros_like(img)
    for y in range(r-N):
        for x in range(c-N):
            count = 0
            for dy in range(N):
                for dx in range(N):
                    count += img[y+dy, x+dx]
            if count >= (N*N)//2:
                output[y+dy//2,x+dx//2] = 1
    return output

def compare_w_slow(R):
    for N in (3,5,7):
        assert np.all(mahotas.morph.majority_filter(R, N) == slow_majority(R, N))

def test_majority():

    np.random.seed(22)
    R = np.random.rand(64, 64) > .68
    yield compare_w_slow, R

    R = np.random.rand(32, 64) > .68
    yield compare_w_slow, R

    R = np.random.rand(64, 64) > .68
    yield compare_w_slow, R[:32,:]

    R = np.random.rand(64, 64) > .68
    yield compare_w_slow, R[:23,:]


@raises(ValueError)
def test_N0():
    mahotas.morph.majority_filter(np.zeros((20,20), np.bool_), 0)


def test_not_bool():
    np.random.seed(22)
    R = np.random.rand(64, 64) > .68
    yield compare_w_slow, R*24.


########NEW FILE########
__FILENAME__ = test_mean_filter
import numpy as np
import mahotas as mh
from mahotas.convolve import mean_filter
def test_smoke():
    f = np.random.random((512,1024))
    se = np.ones((2,2))
    ff = mean_filter(f, se)
    for _ in range(128):
        a = np.random.randint(1, f.shape[0] - 1)
        b = np.random.randint(1, f.shape[1] - 1)
        assert np.allclose(ff[a,b], np.mean(f[a-1:a+1, b-1:b+1]))

########NEW FILE########
__FILENAME__ = test_median_filter
import numpy as np
from mahotas.convolve import median_filter, rank_filter
def test_median_filter():
    A = np.zeros((128,128), bool)
    A[3::3,3::3] = 1
    Am = median_filter(A)
    assert not Am.any()
    assert Am.shape == A.shape


def _slow_rank_filter(A,r):
    B = np.zeros_like(A)
    for i in range(A.shape[0]):
        for j in range(A.shape[1]):
            s0 = max(0, i - 1)
            s1 = max(0, j - 1)
            e0 = min(A.shape[0], i + 2)
            e1 = min(A.shape[1], j + 2)
            pixels = list(A[s0:e0, s1:e1].ravel())
            pixels.extend([0] * (9-len(pixels)))
            pixels.sort()
            B[i,j] = pixels[r]
    return B

def test_rank_filter():
    np.random.seed(22)
    A = np.random.random_integers(0,255, (32,32))
    Bc = np.ones((3,3))
    for r in range(9):
        B1 = rank_filter(A, Bc, r, mode='constant')
        B2 = _slow_rank_filter(A,r)
        assert np.all(B1 == B2)

def test_uint8():
    # This used to raise an exception in 0.7.1
    f = np.arange(64*4).reshape((16,-1))
    median_filter(f.astype(np.uint8), np.ones((5,5)))


########NEW FILE########
__FILENAME__ = test_moments
import numpy as np
import mahotas as mh
from mahotas.features.moments import moments

def _slow(A, p0, p1, cm):
    c0,c1 = cm
    I,J = np.meshgrid(np.arange(A.shape[1],dtype=float), np.arange(A.shape[0], dtype=float))
    I -= c1
    J -= c0
    I **= p0
    J **= p1
    return (I * J * A).sum()

def test_smoke():
    assert moments(np.zeros((100,23)), 2, 2) == 0.0
    assert moments(np.ones((100,23)), 2, 2) != 0.0
    assert moments(np.ones((100,23)), 0, 0) == 100*23
    assert moments(np.ones((100,23)), 2, 2) != moments(np.ones((100,23)), 2, 2, cm=(50,12))

def test_against_slow():
    def perform(p0, p1, cm, A):
        assert moments(A, p0, p1, cm) == _slow(A, p0,p1,cm)

    A = (np.arange(2048) % 14).reshape((32, -1))
    yield perform, 2, 2, (22, 22), A
    yield perform, 2, 2, (20, 22), A
    yield perform, 2, 2, (0, 0), A
    yield perform, 1, 2, (0, 0), A
    yield perform, 1, 0, (0, 0), A


def test_normalize():
    A,B = np.meshgrid(np.arange(128),np.arange(128))
    for p0,p1 in [(1,1), (1,2), (2,1), (2,2)]:
        def f(im):
            return moments(im, p0, p1, cm=mh.center_of_mass(im), normalize=1)
        im = A+B
        fs = [f(im), f(im[::2]), f(im[:,::2]), f(im[::2, ::2])]
        assert np.var(fs) < np.mean(np.abs(fs))/10

########NEW FILE########
__FILENAME__ = test_morph
import numpy as np
from mahotas.morph import get_structuring_elem, subm, tophat_open, tophat_close
from nose.tools import raises

def test_get_structuring_elem():
    A = np.zeros((10,10), np.bool)
    Bc = np.ones((4,4), dtype=np.bool)
    Bc[0,2] = 0

    assert np.all(get_structuring_elem(A, None) == [[0,1,0],[1,1,1],[0,1,0]])
    assert np.all(get_structuring_elem(A, 4) == [[0,1,0],[1,1,1],[0,1,0]])
    assert np.all(get_structuring_elem(A, 4) == get_structuring_elem(A, 1))
    assert np.all(get_structuring_elem(A, 8) == get_structuring_elem(A, 2))
    assert np.all(get_structuring_elem(A, 8) == np.ones((3,3), dtype=np.bool))
    assert np.all(get_structuring_elem(A, Bc) == Bc)
    assert np.all(get_structuring_elem(A, Bc.T) == Bc.T)
    assert get_structuring_elem(A, Bc.T).flags['C_CONTIGUOUS']
    assert np.all(get_structuring_elem(A, Bc.astype(np.float).T).flags['C_CONTIGUOUS'])
    assert np.all(get_structuring_elem(A, Bc.astype(np.float).T) == Bc.T)

    @raises(ValueError)
    def bad_dims():
        Bc = np.ones((3,3,3), dtype=np.bool)
        get_structuring_elem(A, Bc)

    bad_dims()
        

def test_open():
    from mahotas.morph import open
    np.random.seed(123)
    A = np.random.random_sample((16,16)) > .345
    assert open(A).shape == (16,16)

def test_close():
    from mahotas.morph import close
    np.random.seed(123)
    A = np.random.random_sample((16,16)) > .345
    assert close(A).shape == (16,16)


def slow_reg(A, agg):
    def get(i, j):
        vals = []
        def try_this(i,j):
            if 0 <= i < A.shape[0] and \
                0 <= j < A.shape[1]:
                    vals.append( A[i,j] )
        try_this(i,j)
        try_this(i-1,j)
        try_this(i+1,j)
        try_this(i,j-1)
        try_this(i,j+1)
        return vals


    res = np.zeros(A.shape, bool)
    for i in range(A.shape[0]):
        for j in range(A.shape[0]):
            res[i,j] = (A[i,j] == agg(get(i,j)))
    return res

def test_locmin_max():
    from mahotas.morph import locmax, locmin
    np.random.seed(123)
    for i in range(8):
        A = np.random.random_sample((64,64))
        A *= 255
        if (i % 2) == 0:
            A = A.astype(np.uint8)
        fast = locmax(A)
        assert np.all(fast == slow_reg(A, max))

        fast = locmin(A)
        assert np.all(fast == slow_reg(A, min))


def test_regmax_min():
    from mahotas.morph import locmax, locmin, regmax, regmin
    np.random.seed(123)
    for i in range(4):
        A = np.random.random_sample((64,64))
        A *= 255
        A = A.astype(np.uint8)

        loc = locmax(A)
        reg = regmax(A)
        assert not np.any(reg & ~loc)

        loc = locmin(A)
        reg = regmin(A)
        assert not np.any(reg & ~loc)

def test_dilate_crash():
    # There was a major bug in dilate, that caused this to crash
    from mahotas.morph import dilate
    large = np.random.random_sample((512,512)) > .5
    small = large[128:256,128:256]
    dilate(small)

def slow_subm_uint8(a, b):
    a = a.astype(np.int64)
    b = b.astype(np.int64)
    c = a - b
    return np.clip(c, 0, 255).astype(np.uint8)

def slow_subm_uint16(a, b):
    a = a.astype(np.int64)
    b = b.astype(np.int64)
    c = a - b
    return np.clip(c, 0, 2**16-1).astype(np.uint16)

def slow_subm_int16(a, b):
    a = a.astype(np.int64)
    b = b.astype(np.int64)
    c = a - b
    return np.clip(c, -2**15, 2**15-1).astype(np.int16)

def test_subm():
    np.random.seed(34)
    for j in range(8):
        s = (128, 256)
        a = np.random.randint(0,255, size=s)
        b = np.random.randint(0,255, size=s)
        a = a.astype(np.uint8)
        b = b.astype(np.uint8)
        assert np.all(slow_subm_uint8(a,b) == subm(a,b))

        a = 257*np.random.randint(0,255, size=s)
        b = 257*np.random.randint(0,255, size=s)
        a = a.astype(np.uint16)
        b = b.astype(np.uint16)
        assert np.all(slow_subm_uint16(a,b) == subm(a,b))

        a2 = 257*np.random.randint(0,255, size=s)
        b2 = 257*np.random.randint(0,255, size=s)
        a = a.astype(np.int16)
        b = b.astype(np.int16)
        a -= a2
        b -= b2
        assert np.all(slow_subm_int16(a,b) == subm(a,b))



def test_subm_out():
    np.random.seed(32)
    for j in range(8):
        s = (128, 256)
        a = np.random.randint(0,255, size=s)
        b = np.random.randint(0,255, size=s)

        c = subm(a,b)
        assert c is not a
        assert c is not b
        assert not np.all(c == a)


        c = subm(a,b, out=a)
        assert c is  a
        assert c is not b
        assert np.all(c == a)

def test_tophat():
    np.random.seed(32)
    for j in range(8):
        s = (128, 256)
        f = np.random.randint(0,255, size=s)
        f = f.astype(np.uint8)
        g = tophat_close(f)
        assert f.shape == g.shape

        g = tophat_open(f)
        assert f.shape == g.shape


def test_circle_se():
    from mahotas.morph import circle_se
    for r in (4,5):
        c = circle_se(r)
        assert len(c) == (2*r + 1)
        assert len(c) == len(c.T)
        assert not c.all()
        assert c.any()

    @raises(ValueError)
    def circle_1():
        circle_se(-1)
    circle_1()

def test_distance_multi():
    import mahotas._morph
    np.random.seed(20)
    binim = np.random.random((12,18)) > .1
    f = (binim * 0 + 26 *27).astype(float)
    Bc = np.ones((3,3), bool)
    mahotas._morph.distance_multi(f, binim, Bc)
    f2 = mahotas.distance(binim)
    assert np.all(f == f2)



def test_disk():
    from mahotas.morph import disk
    D2 = disk(2) 
    assert D2.shape[0] == D2.shape[1]
    assert D2.shape == (5,5)
    assert not D2[0,0]
    assert len(D2.shape) == 2
    D3 = disk(2,3)

    assert np.all(D3[2] == D2)

    D3 = disk(4,3)
    assert len(D3.shape) == 3
    assert D3.shape[0] == D3.shape[1]
    assert D3.shape[0] == D3.shape[2]

    # Simple regression
    D = disk(32, 2)
    assert D[32,2]

    @raises(ValueError)
    def test_negative_dim(dim):
        disk(3, dim)

    test_negative_dim(-2)
    test_negative_dim(-1)
    test_negative_dim(0)

########NEW FILE########
__FILENAME__ = test_polygon
import numpy as np
import mahotas as mh
import mahotas.polygon
from mahotas.polygon import fill_polygon, fill_convexhull
from nose.tools import raises

def test_polygon():
    polygon = [(10,10), (10,20), (20,20)]
    canvas = np.zeros((40,40), np.bool)
    fill_polygon(polygon, canvas)
    assert canvas.sum() == (10*10+10)/2
    canvas2 = canvas.copy()
    fill_polygon([], canvas2)
    assert np.all(canvas == canvas2)


def test_convex():
    polygon = [(100,232), (233,222), (234,23), (555,355), (343,345), (1000,800)]
    canvas = np.zeros((1024, 1024), np.bool)
    mahotas.polygon.fill_polygon(polygon, canvas)
    canvas2 = mahotas.polygon.fill_convexhull(canvas)
    # The overlap isn't perfect. There is a slight sliver. Fixing it is not
    # worth the trouble for me (LPC), but I'd take a patch
    assert (canvas & ~canvas2).sum() < 1024

def test_convex3():
    f = np.array([
        [False, False, False, False],
        [False,  True,  True, False],
        [False,  True, False, False],
        [False, False, False, False]], dtype=bool)
    assert np.all(fill_convexhull(f) == f)

def test_fill3():
    canvas = np.zeros((4,4), bool)
    # This polygon also has a horizontal and a vertical edge
    polygon = [(1, 1), (1, 2), (2, 1)]
    mahotas.polygon.fill_polygon(polygon, canvas)
    assert canvas.sum()

def test_line():
    canvas = np.zeros((32,32), int)
    polygon = [(8,8), (8,16),(16,16),(16,8), (8,8)]
    for p0,p1 in zip(polygon[:-1], polygon[1:]):
        mahotas.polygon.line(p0,p1, canvas, color=2)
    assert set(canvas.ravel()) == set([0,2])
    assert canvas.sum() == 2*(8*4) # 8*4 is perim size, 2 is value

def test_line_non_square():
    A = np.zeros((128, 64))
    mahotas.polygon.line((0,0),(127,63), A)
    assert A.sum()



def test_fill_line():
    # This is a regression test
    # https://github.com/luispedro/mahotas/issues/3
    canvas = np.zeros((50,30))
    poly = [( 0,10),
            (10, 0),
            (40,20),
            ( 0,10)]
    fill_polygon(poly, canvas)
    assert np.all(canvas[10,1:10])

@raises(ValueError)
def test_convex_in_3d():
    canvas = np.zeros((12,8,8))
    canvas[3,4,2] = 1
    canvas[5,4,2] = 1
    canvas[3,6,2] = 1
    mahotas.polygon.fill_convexhull(canvas)


def test_border():
    canvas = np.zeros((32,32))
    polygon = np.array([(0,0),(0,32),(32,0)])
    fill_polygon(polygon, canvas)
    assert not np.all(canvas)

########NEW FILE########
__FILENAME__ = test_segmentation
import mahotas.segmentation
import numpy as np
import mahotas
from .utils import luispedro_jpg

def test_slic():
    f = luispedro_jpg()
    segmented, n = mahotas.segmentation.slic(f)
    assert segmented.shape == (f.shape[0], f.shape[1])
    assert segmented.max() == n
    segmented2, n2 = mahotas.segmentation.slic(f, 128)
    assert n2 < n

########NEW FILE########
__FILENAME__ = test_stretch
from mahotas.stretch import stretch
import mahotas
import mahotas as mh
from nose.tools import raises
import numpy as np

def test_stretch():
    np.random.seed(2323)
    A = np.random.random_integers(12, 120, size=(100,100))
    A = stretch(A, 255)
    assert A.max() > 250
    assert A.min() == 0
    A = stretch(A,20)
    assert A.max() <= 20
    A = stretch(A, 10, 20)
    assert A.min() >= 10
    A = stretch(A * 0, 10, 20)
    assert A.min() >= 10

def test_neg_numbers():
    A = np.arange(-10,10)
    scaled = stretch(A, 255)
    assert scaled.shape == A.shape
    assert scaled.min() <= 1
    assert scaled.max() >= 254



def test_as_rgb():
    np.random.seed(2323)
    r = np.random.random_integers(12, 120, size=(8,8))
    g = np.random.random_integers(12, 120, size=(8,8))
    b = np.random.random_integers(12, 120, size=(8,8))
    assert mahotas.as_rgb(r,g,b).max() >= 254
    assert mahotas.as_rgb(r,None,b).shape == (8,8,3)
    assert mahotas.as_rgb(r,None,b)[:,:,1].sum() == 0


@raises(ValueError)
def test_as_rgb_Nones():
    mahotas.as_rgb(None,None,None)

@raises(ValueError)
def test_as_rgb_shape_mismatch():
    np.random.seed(2323)
    r = np.random.random_integers(12, 120, size=(8,8))
    g = np.random.random_integers(12, 120, size=(8,8))
    b = np.random.random_integers(12, 120, size=(8,6))
    mahotas.as_rgb(r,g,b)



def test_as_rgb_integer():
    int_rgb = mh.as_rgb(1,2,np.zeros((8,6)))
    assert int_rgb.dtype == np.uint8
    assert int_rgb.shape == (8,6,3)
    assert np.all( int_rgb[0,0] == (1,2,0) )
    assert np.all( int_rgb[-1,3] == (1,2,0) )
    assert np.all( int_rgb[-2,4] == (1,2,0) )

def test_stretch_rgb():
    r = np.arange(256).reshape((32,-1))
    g = 255-r
    b = r/2
    s = mh.stretch(np.dstack([r,g,b]))
    s_rgb = mh.stretch_rgb(np.dstack([r,g,b]))
    assert not np.all(s == s_rgb)
    assert np.all(s[:,:,0] == s_rgb[:,:,0])
    assert np.all(mh.stretch(b) == mh.stretch_rgb(b))

@raises(ValueError)
def test_stretch_rgb4():
    mh.stretch_rgb(np.zeros((8,8,3,2)))


########NEW FILE########
__FILENAME__ = test_surf
import numpy as np
import mahotas as mh
import mahotas.features.surf as surf
from mahotas.features import _surf
from .utils import luispedro_jpg
from nose.tools import raises

def test_integral():
    f = np.arange(8*16).reshape((8,16)) % 8
    fi = surf.integral(f.copy())
    assert fi[-1,-1] == f.sum()
    for y,x in np.indices(f.shape).reshape((2,-1)).T:
        assert fi[y,x] == f[:y+1,:x+1].sum()

def test_integral2():
    f = np.arange(80*16).reshape((80,16)) % 7
    fi = surf.integral(f.copy())
    assert fi[-1,-1] == f.sum()
    for y,x in np.indices(f.shape).reshape((2,-1)).T:
        assert fi[y,x] == f[:y+1,:x+1].sum()


def test_sum_rect():
    f = np.arange(800*160).reshape((800,160)) % 7
    fi = surf.integral(f.copy()) 

    np.random.seed(22)
    for i in range(100):
        y0 = np.random.randint(1,780)
        y1 = np.random.randint(y0+1,799)
        x0 = np.random.randint(1,150)
        x1 = np.random.randint(x0+1, 159)
        assert _surf.sum_rect(fi, y0, x0, y1, x1) == f[y0:y1, x0:x1].sum()

def test_surf_guassians():
    f = np.zeros((1024,1024))
    Y,X = np.indices(f.shape)
    Y -= 768
    X -= 768
    f += 120*np.exp(-Y**2/2048.-X**2/480.)
    Y += 512
    X += 512
    f += 120*np.exp(-Y**2/2048.-X**2/480.)
    spoints = surf.surf(f, 1, 24, 2)

    YX = np.array([spoints[:,0],spoints[:,1]]).T
    is_256 = False
    is_768 = False
    for y,x in YX:
        if (np.abs(y-256) < 8 and np.abs(x-256) < 8): is_256 = True
        if (np.abs(y-768) < 8 and np.abs(x-768) < 8): is_768 = True
    assert is_256
    assert is_768

def test_interest_points_descriptors():
    np.random.seed(22)
    f = np.random.rand(256,256)*230
    f = f.astype(np.uint8)
    fi = surf.integral(f)
    spoints = surf.surf(f, 6, 24, 1)
    for arr, is_integral in zip([f,fi], [False, True]):
        points = surf.interest_points(arr, 6, 24, 1, is_integral=is_integral)
        points = list(points)
        points.sort(key=(lambda p: -p[3]))
        points = np.array(points, dtype=np.float64)
        descs = surf.descriptors(arr, points, is_integral)
        assert np.all(descs[:len(spoints)] == spoints)


def test_show_surf():
    np.random.seed(22)
    f = np.random.rand(256,256)*230
    f = f.astype(np.uint8)
    spoints = surf.surf(f, 6, 24, 1)
    f2 = surf.show_surf(f, spoints)
    assert f2.shape == (f.shape + (3,))


def test_interest_points_descriptor_only():
    np.random.seed(22)
    f = np.random.rand(256,256)*230
    f = f.astype(np.uint8)
    full = surf.surf(f, 6, 24, 1)
    only = surf.surf(f, 6, 24, 1, descriptor_only=True)
    assert full.size > only.size

def test_descriptors_descriptor_only():
    np.random.seed(22)
    f = np.random.rand(256,256)*230
    f = f.astype(np.uint8)
    points = surf.interest_points(f, 6, 24, 1)
    full = surf.descriptors(f, points)
    only = surf.descriptors(f, points, descriptor_only=True)
    assert full.size > only.size

@raises(ValueError)
def test_3d_image():
    surf.surf(np.arange(8*8*16).reshape((16,8,8)), 6, 24, 1)

@raises(TypeError)
def test_integral_intested_points():
    np.random.seed(22)
    f = np.random.rand(16,16)*230
    f = f.astype(np.uint8)
    f = surf.integral(f)
    surf.interest_points(f.astype(np.int32), is_integral=True)


@raises(TypeError)
def test_integral_descriptors():
    np.random.seed(22)
    f = np.random.rand(16,16)*230
    f = f.astype(np.uint8)
    f = surf.integral(f)
    points = surf.interest_points(f, is_integral=True)
    surf.descriptors(f.astype(np.int32), points, is_integral=True)

def test_dense():
    f = np.arange(280*360).reshape((280,360)) % 25
    d16 = surf.dense(f, 16)
    d16_s = surf.dense(f, 16, 3.)
    d32 = surf.dense(f, 32)

    assert len(d16) > len(d32)
    assert d16.shape[1] == d32.shape[1]
    assert d16.shape[1] == d16_s.shape[1]


def test_dense_scale():
    im = luispedro_jpg(True)
    surf.dense(im, spacing=32)
    s5 = surf.dense(im, spacing=32, scale=5)
    s51 = surf.dense(im, spacing=32, scale=5.1)
    assert not np.all(s5 == s51)

########NEW FILE########
__FILENAME__ = test_surf_regression
import mahotas
import numpy as np
from mahotas.features.surf import surf
from os import path

# Originally, the file `determinant_zero.png` contained a PNG which FreeImage
# was opening incorrectly (it returned the palette instead of mapping through
# to the colours).
#
# If correctly mapped, the image was actually full of zeros (i.e., all colours
# in the palette were (0,0,0)!)
#
# Therefore, there are actually two tests here:
#     with a zero image
#     with the values of the palette in determinant_zero.png
#
# The file `determinant_zero.png` now contains what was originally the palette
# values.

def test_determinant_zero():
    img = mahotas.imread(path.join(
        path.abspath(path.dirname(__file__)),
                    'data',
                    'determinant_zero.png'))
    points = surf(img, threshold=.0)
    assert type(points) == np.ndarray

def test_determinant_zero2():
    img = np.zeros((128,28), np.uint8)
    points = surf(img, threshold=.0)
    assert type(points) == np.ndarray


########NEW FILE########
__FILENAME__ = test_tas
import numpy as np
from mahotas.features import tas, pftas
from nose.tools import raises

def test_tas():
    np.random.seed(22)
    f = np.random.rand(1024, 1024)
    f = (f * 255).astype(np.uint8)
    assert np.abs(tas(f).sum()-6) < 0.0001
    assert np.abs(pftas(f).sum()-6) < 0.0001

def test_tas3d():
    np.random.seed(22)
    f = np.random.rand(512, 512, 8)
    f = (f * 255).astype(np.uint8)
    assert np.abs(tas(f).sum()-6) < 0.0001
    assert np.abs(pftas(f).sum()-6) < 0.0001

def test_regression():
    np.random.seed(220)
    img = np.random.random_sample((1024,1024))
    img *= 255
    img = img.astype(np.uint8)
    features = pftas(img)
    assert not np.any(features == 0.)

def test_zero_image():
    features = pftas(np.zeros((64,64), np.uint8))
    assert not np.any(np.isnan(features))

@raises(ValueError)
def test_4d():
    np.random.seed(22)
    f = np.random.rand(16,16,16,16)
    f = (f * 255).astype(np.uint8)
    tas(f)

########NEW FILE########
__FILENAME__ = test_template_match
import numpy as np
import mahotas.convolve
from mahotas.convolve import template_match

def test_template_match():
    np.random.seed(33)
    A = 255*np.random.random((1024, 512))
    t = A[8:12,8:12]+1
    m = template_match(A, t)

    assert m[10,10] == 16
    # I had tried testing over the whole image, but that took too long.
    for i in range(100):
        y = np.random.randint(m.shape[0]-4)
        x = np.random.randint(m.shape[1]-4)
        assert np.allclose(m[y+2,x+2], np.sum( (A[y:y+4, x:x+4] - t) ** 2))

########NEW FILE########
__FILENAME__ = test_texture
import numpy as np
from mahotas.features import texture
import mahotas as mh
import mahotas.features._texture
from nose.tools import raises

def test__cooccurence():
    cooccurence = mahotas.features._texture.cooccurence
    f = np.array([
          [0,1,1,1],
          [0,0,1,1],
          [2,2,2,2],
        ])
    Bc = np.zeros((3,3), f.dtype)
    Bc[1,2] = 1
    res = np.zeros((5,5), np.int32)
    cooccurence(f, res, Bc, 0)
    assert res[0,0] == 1
    assert res[0,1] == 2
    assert res[1,0] == 0
    assert res[1,1] == 3
    assert res[2,2] == 3
    assert not np.any(res[2,:2])
    assert not np.any(res[:2,2])
    res[:3,:3] = 0
    assert not np.any(res)

    res = np.zeros((5,5), np.int32)
    Bc = np.zeros((3,3), f.dtype)
    Bc[2,2] = 1
    cooccurence(f, res, Bc, 0)
    assert res[0,0] == 1
    assert res[0,1] == 0
    assert res[0,2] == 2
    assert res[1,0] == 0
    assert res[1,1] == 2
    assert res[1,2] == 1
    res[:3,:3] = 0
    assert not np.any(res)

def test_cooccurence_errors():
    f2 = np.zeros((6,6), np.uint8)
    f3 = np.zeros((6,6,6), np.uint8)
    f4 = np.zeros((6,6,6,6), np.uint8)
    @raises(ValueError)
    def c_1():
        texture.cooccurence(f2, -2)
    yield c_1

    @raises(ValueError)
    def c_1():
        texture.cooccurence(f3, -2)
    yield c_1

    @raises(ValueError)
    def c_2_10():
        texture.cooccurence(f2, 10)
    yield c_2_10

    @raises(ValueError)
    def c_3_17():
        texture.cooccurence(f3, 17)
    yield c_3_17

    @raises(ValueError)
    def c_4_1():
        texture.cooccurence(f4, 1)
    yield c_4_1



def brute_force(f, dy, dx):
    res = np.zeros((f.max()+1, f.max() + 1), np.double)
    for y in range(f.shape[0]):
        for x in range(f.shape[1]):
            if 0 <= y + dy < f.shape[0] and \
                0 <= x + dx < f.shape[1]:
                res[f[y,x], f[y +dy,x+dx]] += 1
    return res

def brute_force3(f, dy, dx, dz):
    res = np.zeros((f.max()+1, f.max() + 1), np.double)
    for y in range(f.shape[0]):
        for x in range(f.shape[1]):
            for z in range(f.shape[2]):
                if 0 <= y + dy < f.shape[0] and \
                    0 <= x + dx < f.shape[1] and \
                    0 <= z + dz < f.shape[2]:
                    res[f[y,x,z], f[y +dy,x+dx,z+dz]] += 1
    return res


def brute_force_sym(f, dy, dx):
    cmat = brute_force(f, dy, dx)
    return (cmat + cmat.T)

def test_cooccurence():
    np.random.seed(222)
    f = np.random.rand(32, 32)
    f = (f * 255).astype(np.int32)

    assert np.all(texture.cooccurence(f, 0, symmetric=False) == brute_force(f, 0, 1))
    assert np.all(texture.cooccurence(f, 1, symmetric=False) == brute_force(f, 1, 1))
    assert np.all(texture.cooccurence(f, 2, symmetric=False) == brute_force(f, 1, 0))
    assert np.all(texture.cooccurence(f, 3, symmetric=False) == brute_force(f, 1, -1))

    assert np.all(texture.cooccurence(f, 0, symmetric=1) == brute_force_sym(f, 0, 1))
    assert np.all(texture.cooccurence(f, 1, symmetric=1) == brute_force_sym(f, 1, 1))
    assert np.all(texture.cooccurence(f, 2, symmetric=1) == brute_force_sym(f, 1, 0))
    assert np.all(texture.cooccurence(f, 3, symmetric=1) == brute_force_sym(f, 1, -1))

def test_cooccurence3():
    np.random.seed(222)
    f = np.random.rand(32, 32, 8)
    f = (f * 255).astype(np.int32)

    for di, (d0,d1,d2) in enumerate(texture._3d_deltas):
        assert np.all(texture.cooccurence(f, di, symmetric=False) == brute_force3(f, d0, d1, d2))

def test_haralick():
    np.random.seed(123)
    f = np.random.rand(1024, 1024)
    f = (f * 255).astype(np.int32)
    feats = texture.haralick(f)
    assert not np.any(np.isnan(feats))

def test_haralick3():
    np.random.seed(123)
    f = np.random.rand(34, 12, 8)
    f = (f * 255).astype(np.int32)
    feats = texture.haralick(f)
    assert not np.any(np.isnan(feats))


def test_single_point():
    A = np.zeros((5,5), np.uint8)
    A[2,2]=12
    assert not np.any(np.isnan(texture.cooccurence(A,0)))

@raises(TypeError)
def test_float_cooccurence():
    A = np.zeros((5,5), np.float32)
    A[2,2]=12
    texture.cooccurence(A,0)

@raises(TypeError)
def test_float_haralick():
    A = np.zeros((5,5), np.float32)
    A[2,2]=12
    texture.haralick(A)

def test_haralick3d():
    np.random.seed(22)
    img = mahotas.stretch(255*np.random.rand(20,20,4))
    features = texture.haralick(img)
    assert features.shape == (13,13)

    features = texture.haralick(img[:,:,0])
    assert features.shape == (4,13)

    features = texture.haralick(img.max(0), ignore_zeros=True, preserve_haralick_bug=True, compute_14th_feature=True)
    assert features.shape == (4,14)


def test_zeros():
    zeros = np.zeros((64,64), np.uint8)
    feats = texture.haralick(zeros)
    assert not np.any(np.isnan(feats))

    feats = texture.haralick(zeros, ignore_zeros=True)
    assert not np.any(np.isnan(feats))

@raises(ValueError)
def test_4d_image():
    texture.haralick(np.arange(4**5).reshape((4,4,4,4,4)))


def rand_haralick():
    f = 255*np.random.random((128,128))
    f = f.astype(np.uint8)
    f = mh.features.haralick(f)
    return f.mean(0)
def test_feature_non_zero():
    np.random.seed(23)
    assert any(np.all(rand_haralick() != 0) for i in range(12))

def test_feature_not_same():
    np.random.seed(26)

    multiple = np.array([rand_haralick() for i in range(8)])
    assert np.all(multiple.ptp(0) > 0)

########NEW FILE########
__FILENAME__ = test_thin
import numpy as np
import mahotas.thin

def slow_thin(binimg):
    """
    This was the old implementation
    """
    from mahotas.bbox import bbox
    from mahotas._morph import hitmiss

    _struct_elems = []
    _struct_elems.append([
            [0,0,0],
            [2,1,2],
            [1,1,1]])
    _struct_elems.append([
            [2,0,0],
            [1,1,0],
            [1,1,2]])
    _struct_elems.append([
            [1,2,0],
            [1,1,0],
            [1,2,0]])
    _struct_elems.append([
            [1,1,2],
            [1,1,0],
            [2,0,0]])
    _struct_elems.append([
            [1,1,1],
            [2,1,2],
            [0,0,0]])
    _struct_elems.append([
            [2,1,1],
            [0,1,1],
            [0,0,2]])
    _struct_elems.append([
            [0,2,1],
            [0,1,1],
            [0,2,1]])
    _struct_elems.append([
            [0,0,2],
            [0,1,1],
            [2,1,1]])

    _struct_elems = [np.array(elem, np.uint8) for elem in _struct_elems]
    res = np.zeros_like(binimg)
    min0,max0,min1,max1 = bbox(binimg)

    r,c = (max0-min0,max1-min1)

    image_exp = np.zeros((r+2, c+2), np.uint8)
    imagebuf = np.zeros((r+2,c+2), np.uint8)
    prev = np.zeros((r+2,c+2), np.uint8)
    image_exp[1:r+1, 1:c+1] = binimg[min0:max0,min1:max1]
    while True:
        prev[:] = image_exp[:]
        for elem in _struct_elems:
            newimg = hitmiss(image_exp, elem, imagebuf)
            image_exp -= newimg
        if np.all(prev == image_exp):
            break
    res[min0:max0,min1:max1] = image_exp[1:r+1, 1:c+1]
    return res


def test_thin():
    A = np.zeros((100,100), bool)
    A[20:40] = 1
    W = mahotas.thin(A)
    assert mahotas.erode(W).sum() == 0
    assert (W & A).sum() == W.sum()

def test_compare():
    def compare(A):
        W = mahotas.thin(A)
        W2 = slow_thin(A)
        assert np.all(W == W2)
    A = np.zeros((100,100), bool)
    yield compare, A
    A[20:40] = 1
    yield compare, A
    A[:,20:40] = 1
    yield compare, A

    A[60:80,60:80] = 1
    yield compare, A


########NEW FILE########
__FILENAME__ = test_thresholding
# Copyright 2011-2013 Luis Pedro Coelho <luis@luispedro.org>
# License: MIT

import numpy as np
from mahotas.thresholding import otsu, rc, bernsen, gbernsen
from mahotas.histogram import fullhistogram

def slow_otsu(img, ignore_zeros=False):
    hist = fullhistogram(img)
    hist = hist.astype(np.double)
    Hsum = img.size - hist[0]
    if ignore_zeros:
        hist[0] = 0
    if Hsum == 0:
        return 0
    Ng = len(hist)

    nB = np.cumsum(hist)
    nO = nB[-1]-nB
    mu_B = 0
    mu_O = np.dot(np.arange(Ng), hist)/ Hsum
    best = nB[0]*nO[0]*(mu_B-mu_O)*(mu_B-mu_O)
    bestT = 0

    for T in range(1, Ng):
        if nB[T] == 0: continue
        if nO[T] == 0: break
        mu_B = (mu_B*nB[T-1] + T*hist[T]) / nB[T]
        mu_O = (mu_O*nO[T-1] - T*hist[T]) / nO[T]
        sigma_between = nB[T]*nO[T]*(mu_B-mu_O)*(mu_B-mu_O)
        if sigma_between > best:
            best = sigma_between
            bestT = T
    return bestT

def test_otsu_fast():
    np.random.seed(120)
    for i in range(12):
        A = 32*np.random.rand(128,128)
        A = A.astype(np.uint8)
        fast = otsu(A)
        slow = slow_otsu(A)
        assert fast == slow

def test_thresholding():
    np.random.seed(123)
    A = np.random.rand(128,128)
    A[24:48,24:48] += 4 * np.random.rand(24,24)
    A *= 255//A.max()
    A = A.astype(np.uint8)
    def tm(method):
        T = method(A)
        assert (A > T)[24:48,24:48].mean() > .5
        assert (A > T)[:24,:24].mean() < .5
        assert (A > T)[48:,:].mean() < .5
        assert (A > T)[:,48:].mean() < .5
    yield tm, otsu
    yield tm, rc


def test_nozeros():
    np.seterr(all='raise')
    np.random.seed(22)
    A = (np.random.rand(100,100)*50).astype(np.uint8)+201
    assert rc(A) > 200
    assert otsu(A) > 200

def test_ignore_zeros():
    np.seterr(all='raise')
    np.random.seed(22)
    A = np.zeros((1024,24), np.uint8)
    A[:24,:24] = np.random.random_integers(100, 200, size=(24,24))
    assert rc(A) < 100
    assert otsu(A) < 100
    assert rc(A, ignore_zeros=1) > 100
    assert otsu(A, ignore_zeros=1) > 100

def test_zero_image():
    A = np.zeros((16,16), np.uint8)
    def tm(method):
        assert method(A, ignore_zeros=0) == 0
        assert method(A, ignore_zeros=1) == 0
    yield tm, rc
    yield tm, otsu

def test_soft_threhold():
    from mahotas.thresholding import soft_threshold

    np.random.seed(223)
    for i in range(4):
        f = np.random.randint(-256,256, size=(128,128,4))
        fo = f.copy()
        t = soft_threshold(f, 16)

        assert not np.all(fo == t)
        assert np.all(t[np.abs(f) < 16] == 0)
        assert t.max() == f.max()-16
        assert t.min() == f.min()+16
        assert np.all( (np.abs(f) <= 16) | (np.abs(f)-16 == np.abs(t)))


def test_bernsen():
    np.random.seed(120)
    for i in range(4):
        f = 32*np.random.rand(40,68)
        f = f.astype(np.uint8)
        b = bernsen(f, 8, 15)
        assert f.shape == b.shape
        b = bernsen(f, 8, 15, 34)
        assert f.shape == b.shape

def test_gbernsen():
    np.random.seed(120)
    for i in range(4):
        f = 32*np.random.rand(64,96)
        f = f.astype(np.uint8)
        b = gbernsen(f, np.ones((3,3), bool), 15, 145)
        assert f.shape == b.shape

########NEW FILE########
__FILENAME__ = test_watershed
import numpy as np
import mahotas
import mahotas as mh
import sys
from nose.tools import raises

def test_watershed():
    S = np.array([
        [0,0,0,0],
        [0,1,2,1],
        [1,1,1,1],
        [0,0,1,0],
        [1,1,1,1],
        [1,2,2,1],
        [1,1,2,2]
        ])
    M = np.array([
        [0,0,0,0],
        [0,0,1,0],
        [0,0,0,0],
        [0,0,0,0],
        [0,0,0,0],
        [0,2,0,0],
        [0,0,0,0],
        ])
    def cast_test(M,S,dtype):
        M = M.astype(dtype)
        S = S.astype(dtype)
        W = mahotas.cwatershed(2-S,M)
        assert sys.getrefcount(W) == 2
        assert np.all(W == np.array([[1, 1, 1, 1],
               [1, 1, 1, 1],
               [1, 1, 1, 1],
               [2, 2, 1, 1],
               [2, 2, 2, 2],
               [2, 2, 2, 2],
               [2, 2, 2, 2]]))
    for d in [np.uint8, np.int8, np.uint16, np.int16, np.int32, np.uint32,int]:
        yield cast_test, M, S, d


def test_watershed2():
    S = np.zeros((100,10), np.uint8)
    markers = np.zeros_like(S)
    markers[20,2] = 1
    markers[80,2] = 2
    W = mahotas.cwatershed(S, markers)
    assert np.all( (W == 1) | (W == 2) )

@raises(ValueError)
def test_mismatched_array_markers():
    S = np.zeros((10,12), np.uint8)
    markers = np.zeros((8,12), np.uint8)
    markers[2,2] = 1
    markers[6,2] = 2
    mahotas.cwatershed(S, markers)

def test_mix_types():
    f = np.zeros((64,64), np.uint16)
    f += (np.indices(f.shape)[1]**2).astype(np.uint16)
    f += ((np.indices(f.shape)[0]-23)**2).astype(np.uint16)
    markers = np.zeros((64,64), np.int64)
    markers[32,32] = 1
# Below used to force a crash (at least in debug mode)
    a,b = mahotas.cwatershed(f, markers, return_lines=1)


def test_overflow():
    '''Test whether we can force an overflow in the output of cwatershed

    This was reported as issue #41 on github:

    https://github.com/luispedro/mahotas/issues/41
    '''
    f = np.random.random((128,64))
    f *= 255 
    f = f.astype(np.uint8)
    for max_n in [127, 240, 280]:
        markers = np.zeros(f.shape, np.int)
        for i in range(max_n):
            while True:
                a = np.random.randint(f.shape[0])
                b = np.random.randint(f.shape[1])
                if markers[a,b] == 0:
                    markers[a,b] = i + 1
                    break
                
        r = mh.cwatershed(f, markers)
        assert markers.max() == max_n
        assert r.max() == max_n


def test_watershed_labeled():
    import mahotas as mh
    S = np.array([
        [0,0,0,0],
        [0,1,2,1],
        [1,1,1,1],
        [0,0,1,0],
        [1,1,1,1],
        [1,2,2,1],
        [1,1,2,2]
        ])
    M = np.array([
        [0,0,0,0],
        [0,0,1,0],
        [0,0,0,0],
        [0,0,0,0],
        [0,0,0,0],
        [0,2,0,0],
        [0,0,0,0],
        ])
    labeled = mh.cwatershed(S, M)
    sizes = mh.labeled.labeled_sum(S, labeled)
    assert len(sizes) == labeled.max() + 1

########NEW FILE########
__FILENAME__ = test_zernike
import numpy as np
from mahotas.features import zernike_moments
from mahotas.center_of_mass import center_of_mass
from math import atan2
from numpy import cos, sin, conjugate, pi, sqrt

def _slow_znl(Y,X,P,n,l):
    def _polar(r,theta):
        x = r * cos(theta)
        y = r * sin(theta)
        return 1.*x+1.j*y

    v = 0.+0.j
    def _factorial(n):
        if n == 0: return 1.
        return n * _factorial(n - 1)
    y,x = Y[0],X[0]
    for x,y,p in zip(X,Y,P):
        Vnl = 0.
        for m in range( int( (n-l)//2 ) + 1 ):
            Vnl += (-1.)**m * _factorial(n-m) /  \
                ( _factorial(m) * _factorial((n - 2*m + l) // 2) * _factorial((n - 2*m - l) // 2) ) * \
                ( sqrt(x*x + y*y)**(n - 2*m) * _polar(1.0, l*atan2(y,x)) )
        v += p * conjugate(Vnl)
    v *= (n+1)/pi
    return v 

def _slow_zernike(img, radius, D, cof=None):
    zvalues = []

    Y,X = np.where(img > 0)
    P = img[Y,X].ravel()
    if cof is None:
        cofy,cofx = center_of_mass(img)
    else:
        cofy,cofx = cof
    Yn = ( (Y -cofy)/radius).ravel()
    Xn = ( (X -cofx)/radius).ravel()
    k = (np.sqrt(Xn**2 + Yn**2) <= 1.)
    frac_center = np.array(P[k], np.double)
    frac_center /= frac_center.sum()
    Yn = Yn[k]
    Xn = Xn[k]
    frac_center = frac_center.ravel()

    for n in range(D+1):
        for l in range(n+1):
            if (n-l)%2 == 0:
                z = _slow_znl(Yn, Xn, frac_center, float(n), float(l))
                zvalues.append(abs(z))
    return np.array(zvalues)

def test_zernike():
    A = (np.arange(256) % 14).reshape((16, 16))
    slow = _slow_zernike(A, 8., 12)
    fast = zernike_moments(A, 8., 12)
    delta = np.array(slow) - fast
    assert np.abs(delta).max() < 0.001

def test_zernike_cm():
    A = (np.arange(256) % 14).reshape((16, 16))
    cm = (8.9,12.4)
    slow = _slow_zernike(A, 8., 12, cm)
    fast = zernike_moments(A, 8., 12, cm=cm)
    delta = np.array(slow) - fast
    assert np.abs(delta).max() < 0.001


########NEW FILE########
__FILENAME__ = utils
import mahotas as mh
import numpy as np
def luispedro_jpg(as_grey=False):
    from os import path
    path = path.join(
                path.abspath(path.dirname(__file__)),
                'data',
                'luispedro.npy')
    im = np.load(path)
    if as_grey:
        transform = np.array([0.30, 0.59, 0.11])
        return np.dot(im, transform)
    return im

########NEW FILE########
__FILENAME__ = texture
import warnings
warnings.warn(
'''Use

from mahotas.features import texture
''', DeprecationWarning)

from mahotas.features.texture import *

########NEW FILE########
__FILENAME__ = thin
# -*- coding: utf-8 -*-
# Copyright (C) 2006-2010  Luis Pedro Coelho <luis@luispedro.org>
# vim: set ts=4 sts=4 sw=4 expandtab smartindent:
#
# License: MIT (see COPYING file)

from __future__ import division
import numpy as np

__all__ = ['thin']

def thin(binimg):
    """
    skel = thin(binimg)

    Skeletonisation by thinning

    Parameters
    ----------
    binimg : Binary input image

    Returns
    -------
    skel : Skeletonised version of `binimg`
    """
    from .bbox import bbox
    from ._thin import thin as _thin

    res = np.zeros_like(binimg)
    min0,max0,min1,max1 = bbox(binimg)
    r,c = (max0-min0,max1-min1)

    image_exp = np.zeros((r+2, c+2), bool)
    image_exp[1:r+1, 1:c+1] = binimg[min0:max0,min1:max1]
    imagebuf = np.empty((r+2,c+2), bool)

    _thin(image_exp, imagebuf)
    res[min0:max0,min1:max1] = image_exp[1:r+1, 1:c+1]
    return res


########NEW FILE########
__FILENAME__ = thresholding
# -*- coding: utf-8 -*-
# Copyright (C) 2008-2013, Luis Pedro Coelho <luis@luispedro.org>
# vim: set ts=4 sts=4 sw=4 expandtab smartindent:
#
# Permission is hereby granted, free of charge, to any person obtaining a copy
#  of this software and associated documentation files (the "Software"), to deal
#  in the Software without restriction, including without limitation the rights
#  to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
#  copies of the Software, and to permit persons to whom the Software is
#  furnished to do so, subject to the following conditions:
#
# The above copyright notice and this permission notice shall be included in
#  all copies or substantial portions of the Software.
#
# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
#  IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
#  FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
#  AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
#  LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
#  OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
#  THE SOFTWARE.

'''
Thresholding Module
===================

Thresholding functions.

These functions return **the numeric threshold**. In order to obtain a
*thresholded image*, you can do the following::

    T_otsu = mh.otsu(image)
    binarized_image = (image > T_otsu)

Functions which have an ``ignore_zeros`` parameters will only consider non-zero
pixels when computing the thresholding.

:otsu(): Otsu method
:rc(): Riddler-Calvard's method
:bernsen: Bernsen thresholding
:gbernsen: Generalized Bernsen thresholding
'''

from __future__ import division
import numpy as np
from .histogram import fullhistogram
from . import _histogram
from .internal import _verify_is_integer_type
__all__ = [
        'otsu',
        'rc',
        'soft_threshold',
        'bernsen',
        'gbernsen',
    ]


def otsu(img, ignore_zeros=False):
    """
    T = otsu(img, ignore_zeros=False)

    Calculate a threshold according to the Otsu method.

    Example::

        import mahotas as mh
        import mahotas.demos

        im = mahotas.demos.nuclear_image()
        # im is stored as RGB, let's convert to single 2D format:
        im = im.max(2)

        #Now, we compute Otsu:
        t = mh.otsu(im)

        # finally, we use the value to form a binary image:
        bin = (im > t)

    See Wikipedia for details on methods:
    http://en.wikipedia.org/wiki/Otsu's_method

    Parameters
    ----------
    img : an image as a numpy array.
        This should be of an unsigned integer type.
    ignore_zeros : Boolean
        whether to ignore zero-valued pixels
        (default: False)

    Returns
    -------
    T : integer
        the threshold
    """
    _verify_is_integer_type(img, 'otsu')
    hist = fullhistogram(img)
    hist = hist.astype(np.double)
    if ignore_zeros:
        hist[0] = 0
    return _histogram.otsu(hist)


def rc(img, ignore_zeros=False):
    """
    T = rc(img, ignore_zeros=False)

    Calculate a threshold according to the Riddler-Calvard method.

    Example::

        import mahotas as mh
        import mahotas.demos

        im = mahotas.demos.nuclear_image()
        # im is stored as RGB, let's convert to single 2D format:
        im = im.max(2)

        #Now, we compute a threshold:
        t = mh.rc(im)

        # finally, we use the value to form a binary image:
        bin = (im > t)

    Parameters
    ----------
    img : ndarray
        Image of any type
    ignore_zeros : boolean, optional
        Whether to ignore zero valued pixels (default: False)

    Returns
    -------
    T : float
        threshold
    """
    hist = fullhistogram(img)
    if ignore_zeros:
        if hist[0] == img.size:
            return 0
        hist[0] = 0
    N = hist.size

    # Precompute most of what we need:
    first_moment = np.cumsum(np.arange(N) * hist)
    cumsum = np.cumsum(hist)

    r_first_moment = np.flipud(np.cumsum(np.flipud(np.arange(N) * hist)))
    r_cumsum = np.flipud(np.cumsum(np.flipud(hist)))

    maxt = N-1
    while hist[maxt] == 0:
        maxt -= 1

    res = maxt
    t = 0
    while t < min(maxt, res):
        if cumsum[t] and r_cumsum[t+1]:
            res = (first_moment[t]/cumsum[t] + r_first_moment[t+1]/r_cumsum[t+1])/2
        t += 1
    return res

def soft_threshold(f, tval):
    '''
    thresholded = soft_threshold(f, tval)

    Soft threshold function::

                             ^
                             |           /
                             |          /
                             |         /
                             |        /
                             |       /
         - - - - - - - - - - - - - - - - - ->
                      /      |
                     /       |
                    /        |
                   /         |
                  /          |
                 /           |

    Parameters
    ----------
    f : ndarray
    tval : scalar

    Returns
    -------
    thresholded : ndarray
    '''

    f = f * (np.abs(f) > tval)
    f -= tval * (f > tval)
    f += tval * (f < -tval)
    return f

def bernsen(f, radius, contrast_threshold, gthresh=None):
    '''
    thresholded = bernsen(f, radius, contrast_threshold, gthresh={128})

    Bernsen local thresholding

    Parameters
    ----------
    f : ndarray
        input image
    radius : integer
        radius of circle (to consider "local")
    contrast_threshold : integer
        contrast threshold
    gthresh : numeric, optional
        global threshold to fall back in low contrast regions

    Returns
    -------
    thresholded : binary ndarray

    See Also
    --------
    gbernsen : function
        Generalised Bernsen thresholding
    '''
    from mahotas.morph import circle_se
    if gthresh is None:
        gthresh = 128
    return gbernsen(f, circle_se(radius), contrast_threshold, gthresh)

def gbernsen(f, se, contrast_threshold, gthresh):
    '''
    thresholded = gbernsen(f, se, contrast_threshold, gthresh)

    Generalised Bernsen local thresholding

    Parameters
    ----------
    f : ndarray
        input image
    se : boolean ndarray
        structuring element to use for "locality"
    contrast_threshold : integer
        contrast threshold
    gthresh : numeric, optional
        global threshold to fall back in low contrast regions

    Returns
    -------
    thresholded : binary ndarray

    See Also
    --------
    bernsen : function
        Bernsen thresholding with a circular region
    '''
    from mahotas.convolve import rank_filter
    fmax = rank_filter(f, se, se.sum()-1)
    fmin = rank_filter(f, se, 0)
    fptp = fmax - fmin
    fmean = fmax/.2 + fmin/.2 # Do not use (fmax + fmin) as that may overflow
    return np.choose(fptp < contrast_threshold, (fmean < gthresh, fmean > f))


########NEW FILE########
__FILENAME__ = zernike
import warnings
warnings.warn(
'''Use

from mahotas.features import zernike
''', DeprecationWarning)

from mahotas.features.zernike import *

########NEW FILE########
__FILENAME__ = _filters
# Copyright (C) 2010, Luis Pedro Coelho <luis@luispedro.org>
# vim: set ts=4 sts=4 sw=4 expandtab smartindent:
# 
# License: MIT (see COPYING file)

from __future__ import division

mode2int = {
    'nearest' : 0,
    'wrap' : 1,
    'reflect' : 2,
    'mirror' : 3,
    'constant' : 4,
    'ignore' : 5,
}

modes = frozenset(mode2int.keys())

def _check_mode(mode, cval, fname):
    if mode not in modes:
        raise ValueError('mahotas.%s: `mode` not in %s' % (fname, modes))
    if mode == 'constant' and cval != 0.:
        raise NotImplementedError('Please email mahotas developers to get this implemented.')

########NEW FILE########
