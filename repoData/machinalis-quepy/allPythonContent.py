__FILENAME__ = conf
# -*- coding: utf-8 -*-
#
# Quepy documentation build configuration file, created by
# sphinx-quickstart on Mon Nov  5 14:12:47 2012.
#
# This file is execfile()d with the current directory set to its containing dir.
#
# Note that not all possible configuration values are present in this
# autogenerated file.
#
# All configuration values have a default; values that are commented out
# serve to show the default.

import sys, os

# If extensions (or modules to document with autodoc) are in another directory,
# add these directories to sys.path here. If the directory is relative to the
# documentation root, use os.path.abspath to make it absolute, like shown here.
#sys.path.insert(0, os.path.abspath('.'))

# -- General configuration -----------------------------------------------------

# If your documentation needs a minimal Sphinx version, state it here.
#needs_sphinx = '1.0'

# Add any Sphinx extension module names here, as strings. They can be extensions
# coming with Sphinx (named 'sphinx.ext.*') or your custom ones.
extensions = ['sphinx.ext.autodoc']

# Add any paths that contain templates here, relative to this directory.
templates_path = ['_templates']

# The suffix of source filenames.
source_suffix = '.rst'

# The encoding of source files.
#source_encoding = 'utf-8-sig'

# The master toctree document.
master_doc = 'index'

# General information about the project.
project = u'Quepy'
copyright = u'2012, Machinalis'

# The version info for the project you're documenting, acts as replacement for
# |version| and |release|, also used in various other places throughout the
# built documents.
#
# The short X.Y version.
version = '0.1'
# The full version, including alpha/beta/rc tags.
release = '0.1'

# The language for content autogenerated by Sphinx. Refer to documentation
# for a list of supported languages.
#language = None

# There are two options for replacing |today|: either, you set today to some
# non-false value, then it is used:
#today = ''
# Else, today_fmt is used as the format for a strftime call.
#today_fmt = '%B %d, %Y'

# List of patterns, relative to source directory, that match files and
# directories to ignore when looking for source files.
exclude_patterns = ['_build']

# The reST default role (used for this markup: `text`) to use for all documents.
#default_role = None

# If true, '()' will be appended to :func: etc. cross-reference text.
#add_function_parentheses = True

# If true, the current module name will be prepended to all description
# unit titles (such as .. function::).
#add_module_names = True

# If true, sectionauthor and moduleauthor directives will be shown in the
# output. They are ignored by default.
#show_authors = False

# The name of the Pygments (syntax highlighting) style to use.
pygments_style = 'sphinx'

# A list of ignored prefixes for module index sorting.
#modindex_common_prefix = []


# -- Options for HTML output ---------------------------------------------------

# The theme to use for HTML and HTML Help pages.  See the documentation for
# a list of builtin themes.
html_theme = 'default'

# Theme options are theme-specific and customize the look and feel of a theme
# further.  For a list of options available for each theme, see the
# documentation.
#html_theme_options = {}

# Add any paths that contain custom themes here, relative to this directory.
#html_theme_path = []

# The name for this set of Sphinx documents.  If None, it defaults to
# "<project> v<release> documentation".
#html_title = None

# A shorter title for the navigation bar.  Default is the same as html_title.
#html_short_title = None

# The name of an image file (relative to this directory) to place at the top
# of the sidebar.
#html_logo = None

# The name of an image file (within the static path) to use as favicon of the
# docs.  This file should be a Windows icon file (.ico) being 16x16 or 32x32
# pixels large.
#html_favicon = None

# Add any paths that contain custom static files (such as style sheets) here,
# relative to this directory. They are copied after the builtin static files,
# so a file named "default.css" will overwrite the builtin "default.css".
html_static_path = ['_static']

# If not '', a 'Last updated on:' timestamp is inserted at every page bottom,
# using the given strftime format.
#html_last_updated_fmt = '%b %d, %Y'

# If true, SmartyPants will be used to convert quotes and dashes to
# typographically correct entities.
#html_use_smartypants = True

# Custom sidebar templates, maps document names to template names.
#html_sidebars = {}

# Additional templates that should be rendered to pages, maps page names to
# template names.
#html_additional_pages = {}

# If false, no module index is generated.
#html_domain_indices = True

# If false, no index is generated.
#html_use_index = True

# If true, the index is split into individual pages for each letter.
#html_split_index = False

# If true, links to the reST sources are added to the pages.
#html_show_sourcelink = True

# If true, "Created using Sphinx" is shown in the HTML footer. Default is True.
#html_show_sphinx = True

# If true, "(C) Copyright ..." is shown in the HTML footer. Default is True.
#html_show_copyright = True

# If true, an OpenSearch description file will be output, and all pages will
# contain a <link> tag referring to it.  The value of this option must be the
# base URL from which the finished HTML is served.
#html_use_opensearch = ''

# This is the file name suffix for HTML files (e.g. ".xhtml").
#html_file_suffix = None

# Output file base name for HTML help builder.
htmlhelp_basename = 'Quepydoc'


# -- Options for LaTeX output --------------------------------------------------

latex_elements = {
# The paper size ('letterpaper' or 'a4paper').
#'papersize': 'letterpaper',

# The font size ('10pt', '11pt' or '12pt').
#'pointsize': '10pt',

# Additional stuff for the LaTeX preamble.
#'preamble': '',
}

# Grouping the document tree into LaTeX files. List of tuples
# (source start file, target name, title, author, documentclass [howto/manual]).
latex_documents = [
  ('index', 'Quepy.tex', u'Quepy Documentation',
   u'Machinalis', 'manual'),
]

# The name of an image file (relative to this directory) to place at the top of
# the title page.
#latex_logo = None

# For "manual" documents, if this is true, then toplevel headings are parts,
# not chapters.
#latex_use_parts = False

# If true, show page references after internal links.
#latex_show_pagerefs = False

# If true, show URL addresses after external links.
#latex_show_urls = False

# Documents to append as an appendix to all manuals.
#latex_appendices = []

# If false, no module index is generated.
#latex_domain_indices = True


# -- Options for manual page output --------------------------------------------

# One entry per manual page. List of tuples
# (source start file, name, description, authors, manual section).
man_pages = [
    ('index', 'quepy', u'Quepy Documentation',
     [u'Machinalis'], 1)
]

# If true, show URL addresses after external links.
#man_show_urls = False


# -- Options for Texinfo output ------------------------------------------------

# Grouping the document tree into Texinfo files. List of tuples
# (source start file, target name, title, author,
#  dir menu entry, description, category)
texinfo_documents = [
  ('index', 'Quepy', u'Quepy Documentation',
   u'Machinalis', 'Quepy', 'One line description of project.',
   'Miscellaneous'),
]

# Documents to append as an appendix to all manuals.
#texinfo_appendices = []

# If false, no module index is generated.
#texinfo_domain_indices = True

# How to display URL addresses: 'footnote', 'no', or 'inline'.
#texinfo_show_urls = 'footnote'

########NEW FILE########
__FILENAME__ = basic
# coding: utf-8

# Copyright (c) 2012, Machinalis S.R.L.
# This file is part of quepy and is distributed under the Modified BSD License.
# You should have received a copy of license in the LICENSE file.
#
# Authors: Rafael Carrascosa <rcarrascosa@machinalis.com>
#          Gonzalo Garcia Berrotaran <ggarcia@machinalis.com>

"""
Basic questions for DBpedia.
"""

from refo import Group, Plus, Question
from quepy.parsing import Lemma, Pos, QuestionTemplate, Token, Particle, \
                          Lemmas
from quepy.dsl import HasKeyword, IsRelatedTo, HasType
from dsl import DefinitionOf, LabelOf, IsPlace, \
    UTCof, LocationOf


# Openings
LISTOPEN = Lemma("list") | Lemma("name")


class Thing(Particle):
    regex = Question(Pos("JJ")) + (Pos("NN") | Pos("NNP") | Pos("NNS")) |\
            Pos("VBN")

    def interpret(self, match):
        return HasKeyword(match.words.tokens)


class WhatIs(QuestionTemplate):
    """
    Regex for questions like "What is a blowtorch
    Ex: "What is a car"
        "What is Seinfield?"
    """

    regex = Lemma("what") + Lemma("be") + Question(Pos("DT")) + \
        Thing() + Question(Pos("."))

    def interpret(self, match):
        label = DefinitionOf(match.thing)

        return label, "define"


class ListEntity(QuestionTemplate):
    """
    Regex for questions like "List Microsoft software"
    """

    entity = Group(Pos("NNP"), "entity")
    target = Group(Pos("NN") | Pos("NNS"), "target")
    regex = LISTOPEN + entity + target

    def interpret(self, match):
        entity = HasKeyword(match.entity.tokens)
        target_type = HasKeyword(match.target.lemmas)
        target = HasType(target_type) + IsRelatedTo(entity)
        label = LabelOf(target)

        return label, "enum"


class WhatTimeIs(QuestionTemplate):
    """
    Regex for questions about the time
    Ex: "What time is it in Cordoba"
    """

    nouns = Plus(Pos("NN") | Pos("NNS") | Pos("NNP") | Pos("NNPS"))
    place = Group(nouns, "place")
    openings = (Lemma("what") +
        ((Token("is") + Token("the") + Question(Lemma("current")) +
        Question(Lemma("local")) + Lemma("time")) |
        (Lemma("time") + Token("is") + Token("it")))) | \
               Lemma("time")
    regex = openings + Pos("IN") + place + Question(Pos("."))

    def interpret(self, match):
        place = HasKeyword(match.place.lemmas.title()) + IsPlace()
        utc_offset = UTCof(place)

        return utc_offset, "time"


class WhereIsQuestion(QuestionTemplate):
    """
    Ex: "where in the world is the Eiffel Tower"
    """

    thing = Group(Plus(Pos("IN") | Pos("NP") | Pos("NNP") | Pos("NNPS")),
                  "thing")
    regex = Lemma("where") + Question(Lemmas("in the world")) + Lemma("be") + \
        Question(Pos("DT")) + thing + Question(Pos("."))

    def interpret(self, match):
        thing = HasKeyword(match.thing.tokens)
        location = LocationOf(thing)
        location_name = LabelOf(location)

        return location_name, "enum"

########NEW FILE########
__FILENAME__ = country
# coding: utf-8

# Copyright (c) 2012, Machinalis S.R.L.
# This file is part of quepy and is distributed under the Modified BSD License.
# You should have received a copy of license in the LICENSE file.
#
# Authors: Rafael Carrascosa <rcarrascosa@machinalis.com>
#          Gonzalo Garcia Berrotaran <ggarcia@machinalis.com>

"""
Coutry related regex
"""

from refo import Plus, Question
from quepy.dsl import HasKeyword
from quepy.parsing import Lemma, Pos, QuestionTemplate, Token, Particle
from dsl import IsCountry, IncumbentOf, CapitalOf, \
    LabelOf, LanguageOf, PopulationOf, PresidentOf


class Country(Particle):
    regex = Plus(Pos("DT") | Pos("NN") | Pos("NNS") | Pos("NNP") | Pos("NNPS"))

    def interpret(self, match):
        name = match.words.tokens.title()
        return IsCountry() + HasKeyword(name)


class PresidentOfQuestion(QuestionTemplate):
    """
    Regex for questions about the president of a country.
    Ex: "Who is the president of Argentina?"
    """

    regex = Pos("WP") + Token("is") + Question(Pos("DT")) + \
        Lemma("president") + Pos("IN") + Country() + Question(Pos("."))

    def interpret(self, match):
        president = PresidentOf(match.country)
        incumbent = IncumbentOf(president)
        label = LabelOf(incumbent)

        return label, "enum"


class CapitalOfQuestion(QuestionTemplate):
    """
    Regex for questions about the capital of a country.
    Ex: "What is the capital of Bolivia?"
    """

    opening = Lemma("what") + Token("is")
    regex = opening + Pos("DT") + Lemma("capital") + Pos("IN") + \
        Question(Pos("DT")) + Country() + Question(Pos("."))

    def interpret(self, match):
        capital = CapitalOf(match.country)
        label = LabelOf(capital)
        return label, "enum"


# FIXME: the generated query needs FILTER isLiteral() to the head
# because dbpedia sometimes returns different things
class LanguageOfQuestion(QuestionTemplate):
    """
    Regex for questions about the language spoken in a country.
    Ex: "What is the language of Argentina?"
        "what language is spoken in Argentina?"
    """

    openings = (Lemma("what") + Token("is") + Pos("DT") +
                Question(Lemma("official")) + Lemma("language")) | \
               (Lemma("what") + Lemma("language") + Token("is") +
                Lemma("speak"))

    regex = openings + Pos("IN") + Question(Pos("DT")) + Country() + \
        Question(Pos("."))

    def interpret(self, match):
        language = LanguageOf(match.country)
        return language, "enum"


class PopulationOfQuestion(QuestionTemplate):
    """
    Regex for questions about the population of a country.
    Ex: "What is the population of China?"
        "How many people live in China?"
    """

    openings = (Pos("WP") + Token("is") + Pos("DT") +
                Lemma("population") + Pos("IN")) | \
               (Pos("WRB") + Lemma("many") + Lemma("people") +
                Token("live") + Pos("IN"))
    regex = openings + Question(Pos("DT")) + Country() + Question(Pos("."))

    def interpret(self, match):
        population = PopulationOf(match.country)
        return population, "literal"

########NEW FILE########
__FILENAME__ = dsl
# coding: utf-8

# Copyright (c) 2012, Machinalis S.R.L.
# This file is part of quepy and is distributed under the Modified BSD License.
# You should have received a copy of license in the LICENSE file.
#
# Authors: Rafael Carrascosa <rcarrascosa@machinalis.com>
#          Gonzalo Garcia Berrotaran <ggarcia@machinalis.com>

"""
Domain specific language for DBpedia quepy.
"""

from quepy.dsl import FixedType, HasKeyword, FixedRelation, FixedDataRelation

# Setup the Keywords for this application
HasKeyword.relation = "rdfs:label"
HasKeyword.language = "en"


class IsPerson(FixedType):
    fixedtype = "foaf:Person"


class IsPlace(FixedType):
    fixedtype = "dbpedia:Place"


class IsCountry(FixedType):
    fixedtype = "dbpedia-owl:Country"


class IsBand(FixedType):
    fixedtype = "dbpedia-owl:Band"


class IsAlbum(FixedType):
    fixedtype = "dbpedia-owl:Album"


class IsTvShow(FixedType):
    fixedtype = "dbpedia-owl:TelevisionShow"


class IsMovie(FixedType):
    fixedtype = "dbpedia-owl:Film"


class HasShowName(FixedDataRelation):
    relation = "dbpprop:showName"
    language = "en"


class HasName(FixedDataRelation):
    relation = "dbpprop:name"
    language = "en"


class DefinitionOf(FixedRelation):
    relation = "rdfs:comment"
    reverse = True


class LabelOf(FixedRelation):
    relation = "rdfs:label"
    reverse = True


class UTCof(FixedRelation):
    relation = "dbpprop:utcOffset"
    reverse = True


class PresidentOf(FixedRelation):
    relation = "dbpprop:leaderTitle"
    reverse = True


class IncumbentOf(FixedRelation):
    relation = "dbpprop:incumbent"
    reverse = True


class CapitalOf(FixedRelation):
    relation = "dbpedia-owl:capital"
    reverse = True


class LanguageOf(FixedRelation):
    relation = "dbpprop:officialLanguages"
    reverse = True


class PopulationOf(FixedRelation):
    relation = "dbpprop:populationCensus"
    reverse = True


class IsMemberOf(FixedRelation):
    relation = "dbpedia-owl:bandMember"
    reverse = True


class ActiveYears(FixedRelation):
    relation = "dbpprop:yearsActive"
    reverse = True


class MusicGenereOf(FixedRelation):
    relation = "dbpedia-owl:genre"
    reverse = True


class ProducedBy(FixedRelation):
    relation = "dbpedia-owl:producer"


class BirthDateOf(FixedRelation):
    relation = "dbpprop:birthDate"
    reverse = True


class BirthPlaceOf(FixedRelation):
    relation = "dbpedia-owl:birthPlace"
    reverse = True


class ReleaseDateOf(FixedRelation):
    relation = "dbpedia-owl:releaseDate"
    reverse = True


class StarsIn(FixedRelation):
    relation = "dbpprop:starring"
    reverse = True


class NumberOfEpisodesIn(FixedRelation):
    relation = "dbpedia-owl:numberOfEpisodes"
    reverse = True


class ShowNameOf(FixedRelation):
    relation = "dbpprop:showName"
    reverse = True


class HasActor(FixedRelation):
    relation = "dbpprop:starring"


class CreatorOf(FixedRelation):
    relation = "dbpprop:creator"
    reverse = True


class NameOf(FixedRelation):
    relation = "foaf:name"
    # relation = "dbpprop:name"
    reverse = True


class DirectedBy(FixedRelation):
    relation = "dbpedia-owl:director"


class DirectorOf(FixedRelation):
    relation = "dbpedia-owl:director"
    reverse = True


class DurationOf(FixedRelation):
    # DBpedia throws an error if the relation it's
    # dbpedia-owl:Work/runtime so we expand the prefix
    # by giving the whole URL.
    relation = "<http://dbpedia.org/ontology/Work/runtime>"
    reverse = True


class HasAuthor(FixedRelation):
    relation = "dbpedia-owl:author"


class AuthorOf(FixedRelation):
    relation = "dbpedia-owl:author"
    reverse = True


class IsBook(FixedType):
    fixedtype = "dbpedia-owl:Book"


class LocationOf(FixedRelation):
    relation = "dbpedia-owl:location"
    reverse = True

########NEW FILE########
__FILENAME__ = movies
# coding: utf-8

# Copyright (c) 2012, Machinalis S.R.L.
# This file is part of quepy and is distributed under the Modified BSD License.
# You should have received a copy of license in the LICENSE file.
#
# Authors: Rafael Carrascosa <rcarrascosa@machinalis.com>
#          Gonzalo Garcia Berrotaran <ggarcia@machinalis.com>

"""
Movie related regex.
"""

from refo import Plus, Question
from quepy.dsl import HasKeyword
from quepy.parsing import Lemma, Lemmas, Pos, QuestionTemplate, Particle
from dsl import IsMovie, NameOf, IsPerson, \
    DirectedBy, LabelOf, DurationOf, HasActor, HasName, ReleaseDateOf, \
    DirectorOf, StarsIn, DefinitionOf

nouns = Plus(Pos("NN") | Pos("NNS") | Pos("NNP") | Pos("NNPS"))


class Movie(Particle):
    regex = Question(Pos("DT")) + nouns

    def interpret(self, match):
        name = match.words.tokens
        return IsMovie() + HasName(name)


class Actor(Particle):
    regex = nouns

    def interpret(self, match):
        name = match.words.tokens
        return IsPerson() + HasKeyword(name)


class Director(Particle):
    regex = nouns

    def interpret(self, match):
        name = match.words.tokens
        return IsPerson() + HasKeyword(name)


class ListMoviesQuestion(QuestionTemplate):
    """
    Ex: "list movies"
    """

    regex = Lemma("list") + (Lemma("movie") | Lemma("film"))

    def interpret(self, match):
        movie = IsMovie()
        name = NameOf(movie)
        return name, "enum"


class MoviesByDirectorQuestion(QuestionTemplate):
    """
    Ex: "List movies directed by Quentin Tarantino.
        "movies directed by Martin Scorsese"
        "which movies did Mel Gibson directed"
    """

    regex = (Question(Lemma("list")) + (Lemma("movie") | Lemma("film")) +
             Question(Lemma("direct")) + Lemma("by") + Director()) | \
            (Lemma("which") + (Lemma("movie") | Lemma("film")) + Lemma("do") +
             Director() + Lemma("direct") + Question(Pos(".")))

    def interpret(self, match):
        movie = IsMovie() + DirectedBy(match.director)
        movie_name = LabelOf(movie)

        return movie_name, "enum"


class MovieDurationQuestion(QuestionTemplate):
    """
    Ex: "How long is Pulp Fiction"
        "What is the duration of The Thin Red Line?"
    """

    regex = ((Lemmas("how long be") + Movie()) |
            (Lemmas("what be") + Pos("DT") + Lemma("duration") +
             Pos("IN") + Movie())) + \
            Question(Pos("."))

    def interpret(self, match):
        duration = DurationOf(match.movie)
        return duration, ("literal", "{} minutes long")


class ActedOnQuestion(QuestionTemplate):
    """
    Ex: "List movies with Hugh Laurie"
        "Movies with Matt LeBlanc"
        "In what movies did Jennifer Aniston appear?"
        "Which movies did Mel Gibson starred?"
        "Movies starring Winona Ryder"
    """

    acted_on = (Lemma("appear") | Lemma("act") | Lemma("star"))
    movie = (Lemma("movie") | Lemma("movies") | Lemma("film"))
    regex = (Question(Lemma("list")) + movie + Lemma("with") + Actor()) | \
            (Question(Pos("IN")) + (Lemma("what") | Lemma("which")) +
             movie + Lemma("do") + Actor() + acted_on + Question(Pos("."))) | \
            (Question(Pos("IN")) + Lemma("which") + movie + Lemma("do") +
             Actor() + acted_on) | \
            (Question(Lemma("list")) + movie + Lemma("star") + Actor())

    def interpret(self, match):
        movie = IsMovie() + HasActor(match.actor)
        movie_name = NameOf(movie)
        return movie_name, "enum"


class MovieReleaseDateQuestion(QuestionTemplate):
    """
    Ex: "When was The Red Thin Line released?"
        "Release date of The Empire Strikes Back"
    """

    regex = ((Lemmas("when be") + Movie() + Lemma("release")) |
            (Lemma("release") + Question(Lemma("date")) +
             Pos("IN") + Movie())) + \
            Question(Pos("."))

    def interpret(self, match):
        release_date = ReleaseDateOf(match.movie)
        return release_date, "literal"


class DirectorOfQuestion(QuestionTemplate):
    """
    Ex: "Who is the director of Big Fish?"
        "who directed Pocahontas?"
    """

    regex = ((Lemmas("who be") + Pos("DT") + Lemma("director") +
             Pos("IN") + Movie()) |
             (Lemma("who") + Lemma("direct") + Movie())) + \
            Question(Pos("."))

    def interpret(self, match):
        director = IsPerson() + DirectorOf(match.movie)
        director_name = NameOf(director)
        return director_name, "literal"


class ActorsOfQuestion(QuestionTemplate):
    """
    Ex: "who are the actors of Titanic?"
        "who acted in Alien?"
        "who starred in Depredator?"
        "Actors of Fight Club"
    """

    regex = (Lemma("who") + Question(Lemma("be") + Pos("DT")) +
             (Lemma("act") | Lemma("actor") | Lemma("star")) +
             Pos("IN") + Movie() + Question(Pos("."))) | \
            ((Lemma("actors") | Lemma("actor")) + Pos("IN") + Movie())

    def interpret(self, match):
        actor = NameOf(IsPerson() + StarsIn(match.movie))
        return actor, "enum"


class PlotOfQuestion(QuestionTemplate):
    """
    Ex: "what is Shame about?"
        "plot of Titanic"
    """

    regex = ((Lemmas("what be") + Movie() + Lemma("about")) | \
             (Question(Lemmas("what be the")) + Lemma("plot") +
              Pos("IN") + Movie())) + \
            Question(Pos("."))

    def interpret(self, match):
        definition = DefinitionOf(match.movie)
        return definition, "define"

########NEW FILE########
__FILENAME__ = music
# coding: utf-8

# Copyright (c) 2012, Machinalis S.R.L.
# This file is part of quepy and is distributed under the Modified BSD License.
# You should have received a copy of license in the LICENSE file.
#
# Authors: Rafael Carrascosa <rcarrascosa@machinalis.com>
#          Gonzalo Garcia Berrotaran <ggarcia@machinalis.com>

"""
Music related regex
"""

from refo import Plus, Question
from quepy.dsl import HasKeyword
from quepy.parsing import Lemma, Lemmas, Pos, QuestionTemplate, Particle
from dsl import IsBand, LabelOf, IsMemberOf, ActiveYears, MusicGenereOf, \
    NameOf, IsAlbum, ProducedBy


class Band(Particle):
    regex = Question(Pos("DT")) + Plus(Pos("NN") | Pos("NNP"))

    def interpret(self, match):
        name = match.words.tokens.title()
        return IsBand() + HasKeyword(name)


class BandMembersQuestion(QuestionTemplate):
    """
    Regex for questions about band member.
    Ex: "Radiohead members"
        "What are the members of Metallica?"
    """

    regex1 = Band() + Lemma("member")
    regex2 = Lemma("member") + Pos("IN") + Band()
    regex3 = Pos("WP") + Lemma("be") + Pos("DT") + Lemma("member") + \
        Pos("IN") + Band()

    regex = (regex1 | regex2 | regex3) + Question(Pos("."))

    def interpret(self, match):
        member = IsMemberOf(match.band)
        label = LabelOf(member)
        return label, "enum"


class FoundationQuestion(QuestionTemplate):
    """
    Regex for questions about the creation of a band.
    Ex: "When was Pink Floyd founded?"
        "When was Korn formed?"
    """

    regex = Pos("WRB") + Lemma("be") + Band() + \
        (Lemma("form") | Lemma("found")) + Question(Pos("."))

    def interpret(self, match):
        active_years = ActiveYears(match.band)
        return active_years, "literal"


class GenreQuestion(QuestionTemplate):
    """
    Regex for questions about the genre of a band.
    Ex: "What is the music genre of Gorillaz?"
        "Music genre of Radiohead"
    """

    optional_opening = Question(Pos("WP") + Lemma("be") + Pos("DT"))
    regex = optional_opening + Question(Lemma("music")) + Lemma("genre") + \
        Pos("IN") + Band() + Question(Pos("."))

    def interpret(self, match):
        genere = MusicGenereOf(match.band)
        label = LabelOf(genere)
        return label, "enum"


class AlbumsOfQuestion(QuestionTemplate):
    """
    Ex: "List albums of Pink Floyd"
        "What albums did Pearl Jam record?"
        "Albums by Metallica"
    """

    regex = (Question(Lemma("list")) + (Lemma("album") | Lemma("albums")) + \
             Pos("IN") + Band()) | \
            (Lemmas("what album do") + Band() +
             (Lemma("record") | Lemma("make")) + Question(Pos("."))) | \
            (Lemma("list") + Band() + Lemma("album"))

    def interpret(self, match):
        album = IsAlbum() + ProducedBy(match.band)
        name = NameOf(album)
        return name, "enum"

########NEW FILE########
__FILENAME__ = people
# coding: utf-8

# Copyright (c) 2012, Machinalis S.R.L.
# This file is part of quepy and is distributed under the Modified BSD License.
# You should have received a copy of license in the LICENSE file.
#
# Authors: Rafael Carrascosa <rcarrascosa@machinalis.com>
#          Gonzalo Garcia Berrotaran <ggarcia@machinalis.com>

"""
People related regex
"""

from refo import Plus, Question
from quepy.dsl import HasKeyword
from quepy.parsing import Lemma, Lemmas, Pos, QuestionTemplate, Particle
from dsl import IsPerson, LabelOf, DefinitionOf, BirthDateOf, BirthPlaceOf


class Person(Particle):
    regex = Plus(Pos("NN") | Pos("NNS") | Pos("NNP") | Pos("NNPS"))

    def interpret(self, match):
        name = match.words.tokens
        return IsPerson() + HasKeyword(name)


class WhoIs(QuestionTemplate):
    """
    Ex: "Who is Tom Cruise?"
    """

    regex = Lemma("who") + Lemma("be") + Person() + \
        Question(Pos("."))

    def interpret(self, match):
        definition = DefinitionOf(match.person)
        return definition, "define"


class HowOldIsQuestion(QuestionTemplate):
    """
    Ex: "How old is Bob Dylan".
    """

    regex = Pos("WRB") + Lemma("old") + Lemma("be") + Person() + \
        Question(Pos("."))

    def interpret(self, match):
        birth_date = BirthDateOf(match.person)
        return birth_date, "age"


class WhereIsFromQuestion(QuestionTemplate):
    """
    Ex: "Where is Bill Gates from?"
    """

    regex = Lemmas("where be") + Person() + Lemma("from") + \
        Question(Pos("."))

    def interpret(self, match):
        birth_place = BirthPlaceOf(match.person)
        label = LabelOf(birth_place)

        return label, "enum"

########NEW FILE########
__FILENAME__ = settings
# coding: utf-8

# Copyright (c) 2012, Machinalis S.R.L.
# This file is part of quepy and is distributed under the Modified BSD License.
# You should have received a copy of license in the LICENSE file.
#
# Authors: Rafael Carrascosa <rcarrascosa@machinalis.com>
#          Gonzalo Garcia Berrotaran <ggarcia@machinalis.com>

"""
Settings.
"""

# Generated query language
LANGUAGE = "sparql"

# NLTK config
NLTK_DATA_PATH = []  # List of paths with NLTK data

# Encoding config
DEFAULT_ENCODING = "utf-8"

# Sparql config
SPARQL_PREAMBLE = u"""
PREFIX owl: <http://www.w3.org/2002/07/owl#>
PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>
PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>
PREFIX foaf: <http://xmlns.com/foaf/0.1/>
PREFIX skos: <http://www.w3.org/2004/02/skos/core#>
PREFIX quepy: <http://www.machinalis.com/quepy#>
PREFIX dbpedia: <http://dbpedia.org/ontology/>
PREFIX dbpprop: <http://dbpedia.org/property/>
PREFIX dbpedia-owl: <http://dbpedia.org/ontology/>
"""

########NEW FILE########
__FILENAME__ = tvshows
# coding: utf-8

"""
Tv Shows related regex.
"""

from refo import Plus, Question
from quepy.dsl import HasKeyword
from quepy.parsing import Lemma, Lemmas, Pos, QuestionTemplate, Particle
from dsl import IsTvShow, ReleaseDateOf, IsPerson, StarsIn, LabelOf, \
    HasShowName, NumberOfEpisodesIn, HasActor, ShowNameOf, CreatorOf

nouns = Plus(Pos("NN") | Pos("NNS") | Pos("NNP") | Pos("NNPS"))


class TvShow(Particle):
    regex = Plus(Question(Pos("DT")) + nouns)

    def interpret(self, match):
        name = match.words.tokens
        return IsTvShow() + HasShowName(name)


class Actor(Particle):
    regex = nouns

    def interpret(self, match):
        name = match.words.tokens
        return IsPerson() + HasKeyword(name)


# FIXME: clash with movies release regex
class ReleaseDateQuestion(QuestionTemplate):
    """
    Ex: when was Friends release?
    """

    regex = Lemmas("when be") + TvShow() + Lemma("release") + \
        Question(Pos("."))

    def interpret(self, match):
        release_date = ReleaseDateOf(match.tvshow)
        return release_date, "literal"


class CastOfQuestion(QuestionTemplate):
    """
    Ex: "What is the cast of Friends?"
        "Who works in Breaking Bad?"
        "List actors of Seinfeld"
    """

    regex = (Question(Lemmas("what be") + Pos("DT")) +
             Lemma("cast") + Pos("IN") + TvShow() + Question(Pos("."))) | \
            (Lemmas("who works") + Pos("IN") + TvShow() +
             Question(Pos("."))) | \
            (Lemmas("list actor") + Pos("IN") + TvShow())

    def interpret(self, match):
        actor = IsPerson() + StarsIn(match.tvshow)
        name = LabelOf(actor)
        return name, "enum"


class ListTvShows(QuestionTemplate):
    """
    Ex: "List TV shows"
    """

    regex = Lemmas("list tv show")

    def interpret(self, match):
        show = IsTvShow()
        label = LabelOf(show)
        return label, "enum"


class EpisodeCountQuestion(QuestionTemplate):
    """
    Ex: "How many episodes does Seinfeld have?"
        "Number of episodes of Seinfeld"
    """

    regex = ((Lemmas("how many episode do") + TvShow() + Lemma("have")) |
             (Lemma("number") + Pos("IN") + Lemma("episode") +
              Pos("IN") + TvShow())) + \
            Question(Pos("."))

    def interpret(self, match):
        number_of_episodes = NumberOfEpisodesIn(match.tvshow)
        return number_of_episodes, "literal"


class ShowsWithQuestion(QuestionTemplate):
    """
    Ex: "List shows with Hugh Laurie"
        "In what shows does Jennifer Aniston appears?"
        "Shows with Matt LeBlanc"
    """

    regex = (Lemmas("list show") + Pos("IN") + Actor()) | \
            (Pos("IN") + (Lemma("what") | Lemma("which")) + Lemmas("show do") +
             Actor() + (Lemma("appear") | Lemma("work")) +
             Question(Pos("."))) | \
            ((Lemma("show") | Lemma("shows")) + Pos("IN") + Actor())

    def interpret(self, match):
        show = IsTvShow() + HasActor(match.actor)
        show_name = ShowNameOf(show)
        return show_name, "enum"


class CreatorOfQuestion(QuestionTemplate):
    """
    Ex: "Who is the creator of Breaking Bad?"
    """

    regex = Question(Lemmas("who be") + Pos("DT")) + \
        Lemma("creator") + Pos("IN") + TvShow() + Question(Pos("."))

    def interpret(self, match):
        creator = CreatorOf(match.tvshow)
        label = LabelOf(creator)
        return label, "enum"

########NEW FILE########
__FILENAME__ = writers
# coding: utf-8

# Copyright (c) 2012, Machinalis S.R.L.
# This file is part of quepy and is distributed under the Modified BSD License.
# You should have received a copy of license in the LICENSE file.
#
# Authors: Rafael Carrascosa <rcarrascosa@machinalis.com>
#          Gonzalo Garcia Berrotaran <ggarcia@machinalis.com>

"""
Writers related regex.
"""


from refo import Plus, Question
from quepy.dsl import HasKeyword
from quepy.parsing import Lemma, Lemmas, Pos, QuestionTemplate, Particle
from dsl import IsBook, HasAuthor, AuthorOf, IsPerson, NameOf


nouns = Pos("DT") | Pos("IN") | Pos("NN") | Pos("NNS") | Pos("NNP") | Pos("NNPS")


class Book(Particle):
    regex = Plus(nouns)

    def interpret(self, match):
        name = match.words.tokens
        return IsBook() + HasKeyword(name)


class Author(Particle):
    regex = Plus(nouns | Lemma("."))

    def interpret(self, match):
        name = match.words.tokens
        return IsPerson() + HasKeyword(name)


class WhoWroteQuestion(QuestionTemplate):
    """
    Ex: "who wrote The Little Prince?"
        "who is the author of A Game Of Thrones?"
    """

    regex = ((Lemmas("who write") + Book()) |
             (Question(Lemmas("who be") + Pos("DT")) +
              Lemma("author") + Pos("IN") + Book())) + \
            Question(Pos("."))

    def interpret(self, match):
        author = NameOf(IsPerson() + AuthorOf(match.book))
        return author, "literal"


class BooksByAuthorQuestion(QuestionTemplate):
    """
    Ex: "list books by George Orwell"
        "which books did Suzanne Collins wrote?"
    """

    regex = (Question(Lemma("list")) + Lemmas("book by") + Author()) | \
            ((Lemma("which") | Lemma("what")) + Lemmas("book do") +
             Author() + Lemma("write") + Question(Pos(".")))

    def interpret(self, match):
        book = IsBook() + HasAuthor(match.author)
        book_name = NameOf(book)
        return book_name, "enum"

########NEW FILE########
__FILENAME__ = main
#!/usr/bin/env python
# coding: utf-8

# Copyright (c) 2012, Machinalis S.R.L.
# This file is part of quepy and is distributed under the Modified BSD License.
# You should have received a copy of license in the LICENSE file.
#
# Authors: Rafael Carrascosa <rcarrascosa@machinalis.com>
#          Gonzalo Garcia Berrotaran <ggarcia@machinalis.com>

"""
Main script for DBpedia quepy.
"""

import sys
import time
import random
import datetime

import quepy
from SPARQLWrapper import SPARQLWrapper, JSON

sparql = SPARQLWrapper("http://dbpedia.org/sparql")
dbpedia = quepy.install("dbpedia")

# quepy.set_loglevel("DEBUG")


def print_define(results, target, metadata=None):
    for result in results["results"]["bindings"]:
        if result[target]["xml:lang"] == "en":
            print result[target]["value"]
            print


def print_enum(results, target, metadata=None):
    used_labels = []

    for result in results["results"]["bindings"]:
        if result[target]["type"] == u"literal":
            if result[target]["xml:lang"] == "en":
                label = result[target]["value"]
                if label not in used_labels:
                    used_labels.append(label)
                    print label


def print_literal(results, target, metadata=None):
    for result in results["results"]["bindings"]:
        literal = result[target]["value"]
        if metadata:
            print metadata.format(literal)
        else:
            print literal


def print_time(results, target, metadata=None):
    gmt = time.mktime(time.gmtime())
    gmt = datetime.datetime.fromtimestamp(gmt)

    for result in results["results"]["bindings"]:
        offset = result[target]["value"].replace(u"−", u"-")

        if "to" in offset:
            from_offset, to_offset = offset.split("to")
            from_offset, to_offset = int(from_offset), int(to_offset)

            if from_offset > to_offset:
                from_offset, to_offset = to_offset, from_offset

            from_delta = datetime.timedelta(hours=from_offset)
            to_delta = datetime.timedelta(hours=to_offset)

            from_time = gmt + from_delta
            to_time = gmt + to_delta

            location_string = random.choice(["where you are",
                                             "your location"])

            print "Between %s and %s, depending %s" % \
                  (from_time.strftime("%H:%M"),
                   to_time.strftime("%H:%M on %A"),
                   location_string)

        else:
            offset = int(offset)

            delta = datetime.timedelta(hours=offset)
            the_time = gmt + delta

            print the_time.strftime("%H:%M on %A")


def print_age(results, target, metadata=None):
    assert len(results["results"]["bindings"]) == 1

    birth_date = results["results"]["bindings"][0][target]["value"]
    year, month, days = birth_date.split("-")

    birth_date = datetime.date(int(year), int(month), int(days))

    now = datetime.datetime.utcnow()
    now = now.date()

    age = now - birth_date
    print "{} years old".format(age.days / 365)


def wikipedia2dbpedia(wikipedia_url):
    """
    Given a wikipedia URL returns the dbpedia resource
    of that page.
    """

    query = """
    PREFIX foaf: <http://xmlns.com/foaf/0.1/>
    SELECT * WHERE {
        ?url foaf:isPrimaryTopicOf <%s>.
    }
    """ % wikipedia_url

    sparql.setQuery(query)
    sparql.setReturnFormat(JSON)
    results = sparql.query().convert()

    if not results["results"]["bindings"]:
        print "Snorql URL not found"
        sys.exit(1)
    else:
        return results["results"]["bindings"][0]["url"]["value"]


if __name__ == "__main__":
    default_questions = [
        "What is a car?",
        "Who is Tom Cruise?",
        "Who is George Lucas?",
        "Who is Mirtha Legrand?",
        # "List Microsoft software",
        "Name Fiat cars",
        "time in argentina",
        "what time is it in Chile?",
        "List movies directed by Martin Scorsese",
        "How long is Pulp Fiction",
        "which movies did Mel Gibson starred?",
        "When was Gladiator released?",
        "who directed Pocahontas?",
        "actors of Fight Club",
    ]

    if "-d" in sys.argv:
        quepy.set_loglevel("DEBUG")
        sys.argv.remove("-d")

    if len(sys.argv) > 1:
        question = " ".join(sys.argv[1:])

        if question.count("wikipedia.org"):
            print wikipedia2dbpedia(sys.argv[1])
            sys.exit(0)
        else:
            questions = [question]
    else:
        questions = default_questions

    print_handlers = {
        "define": print_define,
        "enum": print_enum,
        "time": print_time,
        "literal": print_literal,
        "age": print_age,
    }

    for question in questions:
        print question
        print "-" * len(question)

        target, query, metadata = dbpedia.get_query(question)

        if isinstance(metadata, tuple):
            query_type = metadata[0]
            metadata = metadata[1]
        else:
            query_type = metadata
            metadata = None

        if query is None:
            print "Query not generated :(\n"
            continue

        print query

        if target.startswith("?"):
            target = target[1:]
        if query:
            sparql.setQuery(query)
            sparql.setReturnFormat(JSON)
            results = sparql.query().convert()

            if not results["results"]["bindings"]:
                print "No answer found :("
                continue

        print_handlers[query_type](results, target, metadata)
        print

########NEW FILE########
__FILENAME__ = basic
# coding: utf-8

# Copyright (c) 2012, Machinalis S.R.L.
# This file is part of quepy and is distributed under the Modified BSD License.
# You should have received a copy of license in the LICENSE file.
#
# Authors: Rafael Carrascosa <rcarrascosa@machinalis.com>
#          Gonzalo Garcia Berrotaran <ggarcia@machinalis.com>

"""
Basic questions for Freebase.
"""

from refo import Question, Plus
from dsl import DefinitionOf, NameOf, LocationOf
from quepy.dsl import HasKeyword
from quepy.parsing import QuestionTemplate, Particle, Lemma, Pos, Lemmas


class Thing(Particle):
    regex = Plus(Question(Pos("JJ")) + (Pos("NN") | Pos("NNP") | Pos("NNS")) |
            Pos("VBN"))

    def interpret(self, match):
        return HasKeyword(match.words.tokens)


class WhatIs(QuestionTemplate):
    """
    Regex for questions like "What is a blowtorch
    Ex: "What is a car"
        "What is Seinfield?"
    """

    regex = Lemma("what") + Lemma("be") + Question(Pos("DT")) + \
        Thing() + Question(Pos("."))

    def interpret(self, match):
        label = DefinitionOf(match.thing)
        return label


class WhereIsQuestion(QuestionTemplate):
    """
    Ex: "where in the world is the Eiffel Tower"
    """

    regex = Lemma("where") + Question(Lemmas("in the world")) + Lemma("be") + \
        Question(Pos("DT")) + Thing() + Question(Pos("."))

    def interpret(self, match):
        location = LocationOf(match.thing)
        location_name = NameOf(location)
        return location_name

########NEW FILE########
__FILENAME__ = country
# coding: utf-8

# Copyright (c) 2012, Machinalis S.R.L.
# This file is part of quepy and is distributed under the Modified BSD License.
# You should have received a copy of license in the LICENSE file.
#
# Authors: Rafael Carrascosa <rcarrascosa@machinalis.com>
#          Gonzalo Garcia Berrotaran <ggarcia@machinalis.com>

"""
Coutry related regex
"""

from dsl import *
from refo import Plus, Question
from quepy.dsl import HasKeyword
from quepy.parsing import Lemma, Pos, QuestionTemplate, Token, Particle


class Country(Particle):
    regex = Plus(Pos("DT") | Pos("NN") | Pos("NNS") | Pos("NNP") | Pos("NNPS"))

    def interpret(self, match):
        name = match.words.tokens.title()
        return IsCountry() + HasKeyword(name)


class PresidentOfQuestion(QuestionTemplate):
    """
    Ex: "list presidents of Argentina?"
    """

    regex = Question(Lemma("list")) + Lemma("president") + Pos("IN") + \
            Country() + Question(Pos("."))

    def interpret(self, match):
        president = IsPresident() + PresidentOf(match.country)
        name = NameOf(OfficeHolderOf(president))
        return name


class CapitalOfQuestion(QuestionTemplate):
    """
    Regex for questions about the capital of a country.
    Ex: "What is the capital of Bolivia?"
    """

    opening = Lemma("what") + Token("is")
    regex = opening + Pos("DT") + Lemma("capital") + Pos("IN") + \
        Question(Pos("DT")) + Country() + Question(Pos("."))

    def interpret(self, match):
        capital = CapitalOf(match.country)
        label = NameOf(capital)
        return label


class LanguageOfQuestion(QuestionTemplate):
    """
    Regex for questions about the language spoken in a country.
    Ex: "What is the language of Argentina?"
        "what language is spoken in Argentina?"
    """

    openings = (Lemma("what") + Token("is") + Pos("DT") +
                Question(Lemma("official")) + Lemma("language")) | \
               (Lemma("what") + Lemma("language") + Token("is") +
                Lemma("speak"))

    regex = openings + Pos("IN") + Question(Pos("DT")) + Country() + \
        Question(Pos("."))

    def interpret(self, match):
        language = LanguageOf(match.country)
        name = NameOf(language)
        return name


class PopulationOfQuestion(QuestionTemplate):
    """
    Regex for questions about the population of a country.
    Ex: "What is the population of China?"
        "How many people live in China?"
    """

    openings = (Pos("WP") + Token("is") + Pos("DT") +
                Lemma("population") + Pos("IN")) | \
               (Pos("WRB") + Lemma("many") + Lemma("people") +
                Token("live") + Pos("IN"))
    regex = openings + Question(Pos("DT")) + Country() + Question(Pos("."))

    def interpret(self, match):
        population = NumberOf(PopulationOf(match.country))
        return population

########NEW FILE########
__FILENAME__ = dsl
# coding: utf-8

# Copyright (c) 2012, Machinalis S.R.L.
# This file is part of quepy and is distributed under the Modified BSD License.
# You should have received a copy of license in the LICENSE file.
#
# Authors: Rafael Carrascosa <rcarrascosa@machinalis.com>
#          Gonzalo Garcia Berrotaran <ggarcia@machinalis.com>

"""
Domain specific language of freebase app.
"""

from quepy.dsl import FixedType, FixedRelation, FixedDataRelation, HasKeyword

# Setup the Keywords for this application
HasKeyword.relation = "/type/object/name"

# Setup Fixed Type
FixedType.fixedtyperelation = "/type/object/type"


class NameOf(FixedRelation):
    relation = "/type/object/name"
    reverse = True


class HasName(FixedDataRelation):
    relation = "/type/object/name"


class GovernmentPosition(FixedDataRelation):
    relation = "/government/government_position_held/basic_title"


class GovernmentPositionJusridiction(FixedRelation):
    relation = "/government/government_position_held/jurisdiction_of_office"


class IsCountry(FixedType):
    fixedtype = "/location/country"


class HoldsGovernmentPosition(FixedRelation):
    relation = "/government/government_position_held/office_holder"
    reverse = True


class DefinitionOf(FixedRelation):
    relation = "/common/topic/description"
    reverse = True


class IsPerson(FixedType):
    fixedtype = "/people/person"
    fixedtyperelation = "/type/object/type"


class BirthDateOf(FixedRelation):
    relation = "/people/person/date_of_birth"
    reverse = True


class BirthPlaceOf(FixedRelation):
    relation = "/people/person/place_of_birth"
    reverse = True


class IsMovie(FixedType):
    fixedtype = "/film/film"


class DurationOf(FixedRelation):
    relation = "/film/film_cut/runtime"
    reverse = True

class RuntimeOf(FixedRelation):
    relation = "/film/film/runtime"
    reverse = True


class IsActor(FixedType):
    fixedtype = "Actor"
    fixedtyperelation = "/people/person/profession"


class IsDirector(FixedType):
    fixedtype = "Film Director"
    fixedtyperelation = "/people/person/profession"


class HasPerformance(FixedRelation):
    relation = "/film/film/starring"


class PerformsIn(FixedRelation):
    relation = "/film/performance/actor"
    reverse = True


class IsPerformance(FixedType):
    fixedtype = "/film/performance"


class PerformanceOfActor(FixedRelation):
    relation = "/film/performance/actor"


class PerformanceOfMovie(FixedRelation):
    relation = "/film/film/starring"
    reverse = True


class DirectorOf(FixedRelation):
    relation = "/film/film/directed_by"
    reverse = True


class DirectedBy(FixedRelation):
    relation = "/film/film/directed_by"


class ReleaseDateOf(FixedRelation):
    relation = "/film/film/initial_release_date"
    reverse = True


class IsBand(FixedType):
    fixedtype = "/music/musical_group"


class IsMusicArtist(FixedType):
    fixedtype = "/music/artist"


class IsMemberOf(FixedRelation):
    relation = "/music/group_member/membership"


class GroupOf(FixedRelation):
    relation = "/music/group_membership/group"


class ActiveYearsOf(FixedRelation):
    relation = "/music/artist/active_start"
    reverse = True


class IsMusicGenre(FixedType):
    fixedtype = "/music/genre"


class MusicGenreOf(FixedRelation):
    relation = "/music/artist/genre"
    reverse = True


class IsAlbum(FixedType):
    fixedtype = "/music/album"


class ProducedBy(FixedRelation):
    relation = "/music/artist/album"
    reverse = True


class IsCountry(FixedType):
    fixedtype = "/location/country"


class IsPresident(FixedType):
    fixedtype = "President"
    fixedtyperelation = "/government/government_position_held/basic_title"


class OfficeHolderOf(FixedRelation):
    relation = "/government/government_position_held/office_holder"
    reverse = True


class PresidentOf(FixedRelation):
    relation = "/government/government_position_held/jurisdiction_of_office"


class CapitalOf(FixedRelation):
    relation = "/location/country/capital"
    reverse = True


class LanguageOf(FixedRelation):
    relation = "/location/country/official_language"
    reverse = True


class PopulationOf(FixedRelation):
    relation = "/location/statistical_region/population"
    reverse = True


class NumberOf(FixedRelation):
    relation = "/measurement_unit/dated_integer/number"
    reverse = True


class IsTvShow(FixedType):
    fixedtype = "/tv/tv_program"


class CastOf(FixedRelation):
    relation = "/tv/tv_program/regular_cast"
    reverse = True


class IsActorOf(FixedRelation):
    relation = "/tv/regular_tv_appearance/actor"
    reverse = True


class HasActor(FixedRelation):
    relation = "/tv/regular_tv_appearance/actor"


class HasCast(FixedRelation):
    relation = "/tv/tv_program/regular_cast"


class NumberOfEpisodesIn(FixedRelation):
    relation = "/tv/tv_program/number_of_episodes"
    reverse = True


class CreatorOf(FixedRelation):
    relation = "/tv/tv_program/program_creator"
    reverse = True


class IsBook(FixedType):
    fixedtype = "/book/book"


class AuthorOf(FixedRelation):
    relation = "/book/written_work/author"
    reverse = True


class HasAuthor(FixedRelation):
    relation = "/book/written_work/author"


class LocationOf(FixedRelation):
    relation = "/location/location/containedby"
    reverse = True

########NEW FILE########
__FILENAME__ = movies
# coding: utf-8

# Copyright (c) 2012, Machinalis S.R.L.
# This file is part of quepy and is distributed under the Modified BSD License.
# You should have received a copy of license in the LICENSE file.
#
# Authors: Rafael Carrascosa <rcarrascosa@machinalis.com>
#          Gonzalo Garcia Berrotaran <ggarcia@machinalis.com>

"""
Movie related regex.
"""

from refo import Plus, Question
from quepy.dsl import HasKeyword
from quepy.parsing import Lemma, Lemmas, Pos, QuestionTemplate, Particle
from dsl import *

nouns = Plus(Pos("NN") | Pos("NNS") | Pos("NNP") | Pos("NNPS"))


class Movie(Particle):
    regex = Question(Pos("DT")) + nouns

    def interpret(self, match):
        name = match.words.tokens
        return IsMovie() + HasName(name)


class Actor(Particle):
    regex = nouns

    def interpret(self, match):
        name = match.words.tokens
        return IsPerson() + IsActor() + HasKeyword(name)


class Director(Particle):
    regex = nouns

    def interpret(self, match):
        name = match.words.tokens
        return IsPerson() + IsDirector() + HasKeyword(name)


class ListMoviesQuestion(QuestionTemplate):
    """
    Ex: "list movies"
    """

    regex = Lemma("list") + (Lemma("movie") | Lemma("film"))

    def interpret(self, match):
        movie = IsMovie()
        name = NameOf(movie)
        return name


class MoviesByDirectorQuestion(QuestionTemplate):
    """
    Ex: "List movies directed by Quentin Tarantino.
        "movies directed by Martin Scorsese"
        "which movies did Mel Gibson directed"
    """

    regex = (Question(Lemma("list")) + (Lemma("movie") | Lemma("film")) +
             Question(Lemma("direct")) + Lemma("by") + Director()) | \
            (Lemma("which") + (Lemma("movie") | Lemma("film")) + Lemma("do") +
             Director() + Lemma("direct") + Question(Pos(".")))

    def interpret(self, match):
        movie = IsMovie() + DirectedBy(match.director)
        movie_name = NameOf(movie)
        return movie_name


class MovieDurationQuestion(QuestionTemplate):
    """
    Ex: "How long is Pulp Fiction"
        "What is the duration of The Thin Red Line?"
    """

    regex = ((Lemmas("how long be") + Movie()) |
            (Lemmas("what be") + Pos("DT") + Lemma("duration") +
             Pos("IN") + Movie())) + \
            Question(Pos("."))

    def interpret(self, match):
        duration = DurationOf(RuntimeOf(match.movie))
        return duration


class ActedOnQuestion(QuestionTemplate):
    """
    Ex: "List movies with Hugh Laurie"
        "Movies with Matt LeBlanc"
        "In what movies did Jennifer Aniston appear?"
        "Which movies did Mel Gibson starred?"
        "Movies starring Winona Ryder"
    """

    acted_on = (Lemma("appear") | Lemma("act") | Lemma("star"))
    movie = (Lemma("movie") | Lemma("movies") | Lemma("film"))
    regex = (Question(Lemma("list")) + movie + Lemma("with") + Actor()) | \
            (Question(Pos("IN")) + (Lemma("what") | Lemma("which")) +
             movie + Lemma("do") + Actor() + acted_on + Question(Pos("."))) | \
            (Question(Pos("IN")) + Lemma("which") + movie + Lemma("do") +
             Actor() + acted_on) | \
            (Question(Lemma("list")) + movie + Lemma("star") + Actor())

    def interpret(self, match):
        performance = IsPerformance() + PerformanceOfActor(match.actor)
        movie = IsMovie() + HasPerformance(performance)
        movie_name = NameOf(movie)
        return movie_name


class MovieReleaseDateQuestion(QuestionTemplate):
    """
    Ex: "When was The Red Thin Line released?"
        "Release date of The Empire Strikes Back"
    """

    regex = ((Lemmas("when be") + Movie() + Lemma("release")) |
            (Lemma("release") + Question(Lemma("date")) +
             Pos("IN") + Movie())) + \
            Question(Pos("."))

    def interpret(self, match):
        release_date = ReleaseDateOf(match.movie)
        return release_date


class DirectorOfQuestion(QuestionTemplate):
    """
    Ex: "Who is the director of Big Fish?"
        "who directed Pocahontas?"
    """

    regex = ((Lemmas("who be") + Pos("DT") + Lemma("director") +
             Pos("IN") + Movie()) |
             (Lemma("who") + Lemma("direct") + Movie())) + \
            Question(Pos("."))

    def interpret(self, match):
        director = IsPerson() + DirectorOf(match.movie)
        director_name = NameOf(director)
        return director_name


class ActorsOfQuestion(QuestionTemplate):
    """
    Ex: "who are the actors of Titanic?"
        "who acted in Alien?"
        "who starred in Depredator?"
        "Actors of Fight Club"
    """

    regex = (Lemma("who") + Question(Lemma("be") + Pos("DT")) +
             (Lemma("act") | Lemma("actor") | Lemma("star")) +
             Pos("IN") + Movie() + Question(Pos("."))) | \
            ((Lemma("actors") | Lemma("actor")) + Pos("IN") + Movie())

    def interpret(self, match):
        performance = IsPerformance() + PerformanceOfMovie(match.movie)
        actor = IsActor() + PerformsIn(performance)
        name = NameOf(actor)
        return name


class PlotOfQuestion(QuestionTemplate):
    """
    Ex: "what is Shame about?"
        "plot of Titanic"
    """

    regex = ((Lemmas("what be") + Movie() + Lemma("about")) | \
             (Question(Lemmas("what be the")) + Lemma("plot") +
              Pos("IN") + Movie())) + \
            Question(Pos("."))

    def interpret(self, match):
        definition = DefinitionOf(match.movie)
        return definition

########NEW FILE########
__FILENAME__ = music
# coding: utf-8

# Copyright (c) 2012, Machinalis S.R.L.
# This file is part of quepy and is distributed under the Modified BSD License.
# You should have received a copy of license in the LICENSE file.
#
# Authors: Rafael Carrascosa <rcarrascosa@machinalis.com>
#          Gonzalo Garcia Berrotaran <ggarcia@machinalis.com>

"""
Music related regex
"""

from dsl import *
from refo import Plus, Question
from quepy.dsl import HasKeyword
from quepy.parsing import Lemma, Lemmas, Pos, QuestionTemplate, Particle


class Band(Particle):
    regex = Question(Pos("DT")) + Plus(Pos("NN") | Pos("NNP"))

    def interpret(self, match):
        name = match.words.tokens.title()
        return IsBand() + HasKeyword(name)


class BandMembersQuestion(QuestionTemplate):
    """
    Regex for questions about band member.
    Ex: "Radiohead members"
        "What are the members of Metallica?"
    """

    regex1 = Band() + Lemma("member")
    regex2 = Lemma("member") + Pos("IN") + Band()
    regex3 = Pos("WP") + Lemma("be") + Pos("DT") + Lemma("member") + \
        Pos("IN") + Band()

    regex = (regex1 | regex2 | regex3) + Question(Pos("."))

    def interpret(self, match):
        group = GroupOf(match.band)
        member = IsPerson() + IsMusicArtist() + IsMemberOf(group)
        name = NameOf(member)
        return name


class FoundationQuestion(QuestionTemplate):
    """
    Regex for questions about the creation of a band.
    Ex: "When was Pink Floyd founded?"
        "When was Korn formed?"
    """

    regex = Pos("WRB") + Lemma("be") + Band() + \
        (Lemma("form") | Lemma("found")) + Question(Pos("."))

    def interpret(self, match):
        active_years = ActiveYearsOf(match.band)
        return active_years


class GenreQuestion(QuestionTemplate):
    """
    Regex for questions about the genre of a band.
    Ex: "What is the music genre of Gorillaz?"
        "Music genre of Radiohead"
    """

    optional_opening = Question(Pos("WP") + Lemma("be") + Pos("DT"))
    regex = optional_opening + Question(Lemma("music")) + Lemma("genre") + \
        Pos("IN") + Band() + Question(Pos("."))

    def interpret(self, match):
        genre = MusicGenreOf(match.band)
        name = NameOf(genre)
        return name


class AlbumsOfQuestion(QuestionTemplate):
    """
    Ex: "List albums of Pink Floyd"
        "What albums did Pearl Jam record?"
        "Albums by Metallica"
    """

    regex = (Question(Lemma("list")) + (Lemma("album") | Lemma("albums")) + \
             Pos("IN") + Band()) | \
            (Lemmas("what album do") + Band() +
             (Lemma("record") | Lemma("make")) + Question(Pos("."))) | \
            (Lemma("list") + Band() + Lemma("album"))

    def interpret(self, match):
        album = IsAlbum() + ProducedBy(match.band)
        name = NameOf(album)
        return name

########NEW FILE########
__FILENAME__ = people
# -*- coding: utf-8 -*-

# Copyright (c) 2012, Machinalis S.R.L.
# This file is part of quepy and is distributed under the Modified BSD License.
# You should have received a copy of license in the LICENSE file.
#
# Authors: Rafael Carrascosa <rcarrascosa@machinalis.com>
#          Gonzalo Garcia Berrotaran <ggarcia@machinalis.com>

"""
People related regex
"""

from dsl import *
from refo import Plus, Question
from quepy.dsl import HasKeyword
from quepy.parsing import Lemma, Lemmas, Pos, QuestionTemplate, Particle


class Person(Particle):
    regex = Plus(Pos("NN") | Pos("NNS") | Pos("NNP") | Pos("NNPS"))

    def interpret(self, match):
        name = match.words.tokens
        return IsPerson() + HasKeyword(name)


class WhoIs(QuestionTemplate):
    """
    Ex: "Who is Tom Cruise?"
    """

    regex = Lemma("who") + Lemma("be") + Person() + \
        Question(Pos("."))

    def interpret(self, match):
        definition = DefinitionOf(match.person)
        return definition


class HowOldIsQuestion(QuestionTemplate):
    """
    Ex: "How old is Bob Dylan".
    """

    regex = Pos("WRB") + Lemma("old") + Lemma("be") + Person() + \
        Question(Pos("."))

    def interpret(self, match):
        birth_date = BirthDateOf(match.person)
        return birth_date


class WhereIsFromQuestion(QuestionTemplate):
    """
    Ex: "Where is Bill Gates from?"
    """

    regex = Lemmas("where be") + Person() + Lemma("from") + \
        Question(Pos("."))

    def interpret(self, match):
        birth_place = BirthPlaceOf(match.person)
        name = NameOf(birth_place)
        return name

########NEW FILE########
__FILENAME__ = settings
# coding: utf-8

# Copyright (c) 2012, Machinalis S.R.L.
# This file is part of quepy and is distributed under the Modified BSD License.
# You should have received a copy of license in the LICENSE file.
#
# Authors: Rafael Carrascosa <rcarrascosa@machinalis.com>
#          Gonzalo Garcia Berrotaran <ggarcia@machinalis.com>

"""
Settings for freebase app.
"""

# Generated query language
LANGUAGE = "mql"

# NLTK config
NLTK_DATA_PATH = []  # List of paths with NLTK data

# Encoding config
DEFAULT_ENCODING = "utf-8"

########NEW FILE########
__FILENAME__ = tvshows
# coding: utf-8

"""
Tv Shows related regex.
"""

from dsl import *
from refo import Plus, Question
from quepy.dsl import HasKeyword
from quepy.parsing import Lemma, Lemmas, Pos, QuestionTemplate, Particle

nouns = Plus(Pos("NN") | Pos("NNS") | Pos("NNP") | Pos("NNPS"))


class TvShow(Particle):
    regex = Plus(Question(Pos("DT")) + nouns)

    def interpret(self, match):
        name = match.words.tokens
        return IsTvShow() + HasName(name)


class Actor(Particle):
    regex = nouns

    def interpret(self, match):
        name = match.words.tokens
        return IsPerson() + HasName(name)


class CastOfQuestion(QuestionTemplate):
    """
    Ex: "What is the cast of Friends?"
        "Who works in Breaking Bad?"
        "List actors of Seinfeld"
    """

    regex = (Question(Lemmas("what be") + Pos("DT")) +
             Lemma("cast") + Pos("IN") + TvShow() + Question(Pos("."))) | \
            (Lemmas("who works") + Pos("IN") + TvShow() +
             Question(Pos("."))) | \
            (Lemmas("list actor") + Pos("IN") + TvShow())

    def interpret(self, match):
        cast = CastOf(match.tvshow)
        actor = IsPerson() + IsActorOf(cast)
        name = NameOf(actor)
        return name


class ListTvShows(QuestionTemplate):
    """
    Ex: "List TV shows"
    """

    regex = Lemmas("list tv show")

    def interpret(self, match):
        show = IsTvShow()
        label = NameOf(show)
        return label


class EpisodeCountQuestion(QuestionTemplate):
    """
    Ex: "How many episodes does Seinfeld have?"
        "Number of episodes of Seinfeld"
    """

    regex = ((Lemmas("how many episode do") + TvShow() + Lemma("have")) |
             (Lemma("number") + Pos("IN") + Lemma("episode") +
              Pos("IN") + TvShow())) + \
            Question(Pos("."))

    def interpret(self, match):
        number_of_episodes = NumberOfEpisodesIn(match.tvshow)
        return number_of_episodes


class ShowsWithQuestion(QuestionTemplate):
    """
    Ex: "List shows with Hugh Laurie"
        "In what shows does Jennifer Aniston appears?"
        "Shows with Matt LeBlanc"
    """

    regex = (Lemmas("list show") + Pos("IN") + Actor()) | \
            (Pos("IN") + (Lemma("what") | Lemma("which")) + Lemmas("show do") +
             Actor() + (Lemma("appear") | Lemma("work")) +
             Question(Pos("."))) | \
            ((Lemma("show") | Lemma("shows")) + Pos("IN") + Actor())

    def interpret(self, match):
        cast = HasActor(match.actor)
        show = IsTvShow() + HasCast(cast)
        show_name = NameOf(show)
        return show_name


class CreatorOfQuestion(QuestionTemplate):
    """
    Ex: "Who is the creator of Breaking Bad?"
        "Who are the creators of Friends?"
    """

    regex = Question(Lemmas("who be") + Pos("DT")) + \
        Lemma("creator") + Pos("IN") + TvShow() + Question(Pos("."))

    def interpret(self, match):
        creator = CreatorOf(match.tvshow)
        name = NameOf(creator)
        return name

########NEW FILE########
__FILENAME__ = writers
# coding: utf-8

# Copyright (c) 2012, Machinalis S.R.L.
# This file is part of quepy and is distributed under the Modified BSD License.
# You should have received a copy of license in the LICENSE file.
#
# Authors: Rafael Carrascosa <rcarrascosa@machinalis.com>
#          Gonzalo Garcia Berrotaran <ggarcia@machinalis.com>

"""
Writers related regex.
"""


from dsl import *
from refo import Plus, Question
from quepy.dsl import HasKeyword
from quepy.parsing import Lemma, Lemmas, Pos, QuestionTemplate, Particle


nouns = Pos("DT") | Pos("IN") | Pos("NN") | Pos("NNS") | Pos("NNP") | Pos("NNPS")


class Book(Particle):
    regex = Plus(nouns)

    def interpret(self, match):
        name = match.words.tokens
        return IsBook() + HasKeyword(name)


class Author(Particle):
    regex = Plus(nouns | Lemma("."))

    def interpret(self, match):
        name = match.words.tokens
        return IsPerson() + HasKeyword(name)


class WhoWroteQuestion(QuestionTemplate):
    """
    Ex: "who wrote The Little Prince?"
        "who is the author of A Game Of Thrones?"
    """

    regex = ((Lemmas("who write") + Book()) |
             (Question(Lemmas("who be") + Pos("DT")) +
              Lemma("author") + Pos("IN") + Book())) + \
            Question(Pos("."))

    def interpret(self, match):
        author = NameOf(IsPerson() + AuthorOf(match.book))
        return author


class BooksByAuthorQuestion(QuestionTemplate):
    """
    Ex: "list books by George Orwell"
        "which books did Suzanne Collins wrote?"
    """

    regex = (Question(Lemma("list")) + Lemmas("book by") + Author()) | \
            ((Lemma("which") | Lemma("what")) + Lemmas("book do") +
             Author() + Lemma("write") + Question(Pos(".")))

    def interpret(self, match):
        book = IsBook() + HasAuthor(match.author)
        book_name = NameOf(book)
        return book_name

########NEW FILE########
__FILENAME__ = main
#!/usr/bin/env python
# coding: utf-8

"""
Main script for freebase quepy.

Usage:
    main.py [options] <question> ...

Options:
    -r --request     Queries the online database and prints the results
"""

import json
import quepy
import urllib
from docopt import docopt

service_url = 'https://www.googleapis.com/freebase/v1/mqlread'
freebase = quepy.install("freebase")


def request(query):
    params = {'query': query}
    url = service_url + '?' + urllib.urlencode(params)
    responses = json.loads(urllib.urlopen(url).read())
    return responses


def result_from_responses(responses, target):
    if responses:
        to_explore = responses["result"]
        for key in target:
            _to_explore = []
            for elem in to_explore:
                for response in elem[key]:
                    _to_explore.append(response)
            to_explore = _to_explore

        result = []
        for elem in to_explore:
            if isinstance(elem, dict):
                if "lang" in elem:
                    if elem["lang"] == "/lang/en":
                        result.append(elem.get("value", elem))
                else:
                    result.append(elem.get("value", elem))
            else:
                result.append(elem)
        return result


if __name__ == "__main__":
    args = docopt(__doc__)
    question = " ".join(args["<question>"])
    target, query, metadata = freebase.get_query(question)
    print query

    if args["--request"]:
        print
        responses = request(query)
        if "error" in responses:
            print responses
            exit()
        else:
            for response in result_from_responses(responses, target):
                print response

########NEW FILE########
__FILENAME__ = dot_generation
# -*- coding: utf-8 -*-

"""
Dot generation code.
"""

import random
from quepy.expression import isnode
from quepy.dsl import IsRelatedTo, HasKeyword
from quepy.encodingpolicy import assert_valid_encoding


def escape(x, add_quotes=True):
    x = unicode(x)
    x = x.replace(u" ", u"_")
    x = x.replace(u"\n", u"")
    x = x.replace(u"\00", u"")
    x = x.replace(u"[", u"")
    x = x.replace(u"]", u"")
    x = x.replace(u"\\", u"")
    if x.count("\""):
        x = x.replace(u"\"", u"\\\"")
        if add_quotes:
            x = u'"' + x + u'"'
    return x


def adapt(x):
    if isnode(x):
        x = u"x{}".format(x)
        return x
    if isinstance(x, basestring):
        assert_valid_encoding(x)
        x = escape(x)
        if x.startswith(u"\""):
            return x
        return u'"{}"'.format(x)
    return unicode(x)


def expression_to_dot(e):
    d = {u"rdf:type": dot_type,
         HasKeyword.relation: dot_keyword,
         IsRelatedTo: lambda x, y: dot_arc(x, u"", y)}
    s = u"digraph G {{\n{0} [shape=house];\n{1}\n}}\n"
    xs = []
    for node in e.iter_nodes():
        for relation, other in e.iter_edges(node):
            node1 = adapt(node)
            node2 = adapt(other)
            relation = escape(relation, add_quotes=False)

            if relation in d:
                x = d[relation](node1, node2)
            else:
                x = dot_arc(node1, relation, node2)
            xs.append(x)
    return None, s.format(adapt(e.head), u"".join(xs))


def dot_arc(a, label, b):
    assert u" " not in a and u" " not in b
    assert u"\n" not in a + label + b
    return u"{0} -> {1} [label=\"{2}\"];\n".format(a, b, label)


def dot_type(a, t):
    s = u"{0} [shape=box];\n".format(t)
    return s + u"{0} -> {1} [color=red, arrowhead=empty];".format(a, t)


def dot_attribute(a, key):
    blank = id(a)
    s = u"{0} [shape=none label={1}];\n".format(blank, key)
    return s + u"{0} -> {1};".format(a, blank)


def dot_keyword(a, key):
    blank = u"{0:.30f}".format(random.random())
    blank = u"blank" + blank.replace(u".", u"")
    s = u"{0} [shape=none label={1}];\n".format(blank, key)
    return s + u"{0} -> {1} [style=dashed];".format(a, blank)


def dot_fixed_type(a, fixedtype):
    blank = u"{0:.30f}".format(random.random())
    blank = u"blank" + blank.replace(u".", u"")
    s = u"{0} [shape=box label={1}];\n".format(blank, fixedtype)
    return s + u"{0} -> {1} [color=red, arrowhead=empty];".format(a, blank)

########NEW FILE########
__FILENAME__ = dsl
# coding: utf-8
# pylint: disable=C0111

# Copyright (c) 2012, Machinalis S.R.L.
# This file is part of quepy and is distributed under the Modified BSD License.
# You should have received a copy of license in the LICENSE file.
#
# Authors: Rafael Carrascosa <rcarrascosa@machinalis.com>
#          Gonzalo Garcia Berrotaran <ggarcia@machinalis.com>

"""
Domain specific language definitions.
"""

from copy import copy
from quepy.expression import Expression
from quepy.encodingpolicy import encoding_flexible_conversion


class FixedRelation(Expression):
    """
    Expression for a fixed relation. It states that "A is related to B"
    through the relation defined in `relation`.
    """

    relation = None
    reverse = False

    def __init__(self, destination, reverse=None):
        if reverse is None:
            reverse = self.reverse
        super(FixedRelation, self).__init__()
        if self.relation is None:
            raise ValueError("You *must* define the `relation` "
                             "class attribute to use this class.")
        self.nodes = copy(destination.nodes)
        self.head = destination.head
        self.decapitate(self.relation, reverse)


class FixedType(Expression):
    """
    Expression for a fixed type.
    This captures the idea of something having an specific type.
    """

    fixedtype = None
    fixedtyperelation = u"rdf:type"  # FIXME: sparql specific

    def __init__(self):
        super(FixedType, self).__init__()
        if self.fixedtype is None:
            raise ValueError("You *must* define the `fixedtype` "
                             "class attribute to use this class.")
        self.fixedtype = encoding_flexible_conversion(self.fixedtype)
        self.fixedtyperelation = \
            encoding_flexible_conversion(self.fixedtyperelation)
        self.add_data(self.fixedtyperelation, self.fixedtype)


class FixedDataRelation(Expression):
    """
    Expression for a fixed relation. This is
    "A is related to Data" through the relation defined in `relation`.
    """

    relation = None
    language = None

    def __init__(self, data):
        super(FixedDataRelation, self).__init__()
        if self.relation is None:
            raise ValueError("You *must* define the `relation` "
                             "class attribute to use this class.")
        self.relation = encoding_flexible_conversion(self.relation)
        if self.language is not None:
            self.language = encoding_flexible_conversion(self.language)
            data = u"\"{0}\"@{1}".format(data, self.language)
        self.add_data(self.relation, data)


class HasKeyword(FixedDataRelation):
    """
    Abstraction of an information retrival key, something standarized used
    to look up things in the database.
    """
    relation = u"quepy:Keyword"

    def __init__(self, data):
        data = self.sanitize(data)
        super(HasKeyword, self).__init__(data)

    @staticmethod
    def sanitize(text):
        # User can redefine this method if needed
        return text


class HasType(FixedRelation):
    relation = "rdf:type"


class IsRelatedTo(FixedRelation):
    pass
# Looks weird, yes, here I am using `IsRelatedTo` as a unique identifier.
IsRelatedTo.relation = IsRelatedTo

########NEW FILE########
__FILENAME__ = encodingpolicy
# coding: utf-8

# Copyright (c) 2012, Machinalis S.R.L.
# This file is part of quepy and is distributed under the Modified BSD License.
# You should have received a copy of license in the LICENSE file.
#
# Authors: Rafael Carrascosa <rcarrascosa@machinalis.com>
#          Gonzalo Garcia Berrotaran <ggarcia@machinalis.com>

"""
Functions to do encoding checkings.
"""

import logging
from quepy import settings
logger = logging.getLogger("quepy.encodingpolicy")


def encoding_flexible_conversion(string, complain=False):
    """
    Converts string to the proper encoding if it's possible
    and if it's not raises a ValueError exception.

    If complain it's True, it will emit a logging warning about
    converting a string that had to be on the right encoding.
    """

    if isinstance(string, unicode):
        return string
    try:
        ustring = string.decode(settings.DEFAULT_ENCODING)
    except UnicodeError:
        message = u"Argument must be unicode or {}"
        raise ValueError(message.format(settings.DEFAULT_ENCODING))
    if complain:
        logger.warning(u"Forced to guess the encoding of {!r}, please "
                       u"provide a unicode string instead".format(string))
    return ustring


def assert_valid_encoding(string):
    """
    If string it's not in a valid encoding it raises a
    ValueError exception.
    """

    if not isinstance(string, unicode):
        raise ValueError(u"Argument must be unicode")

########NEW FILE########
__FILENAME__ = expression
# coding: utf-8

# Copyright (c) 2012, Machinalis S.R.L.
# This file is part of quepy and is distributed under the Modified BSD License.
# You should have received a copy of license in the LICENSE file.
#
# Authors: Rafael Carrascosa <rcarrascosa@machinalis.com>
#          Gonzalo Garcia Berrotaran <ggarcia@machinalis.com>

"""
This file implements the ``Expression`` class.

``Expression`` is the base class for all the semantic representations in quepy.
It's meant to carry all the information necessary to build a database query in
an abstract form.

By desing it's aimed specifically to represent a SPARQL query, but it should
be able to represent queries in other database languages too.

A (simple) SPARQL query can be thought as a subgraph that has to match into a
larger graph (the database). Each node of the subgraph is a variable and every
edge a relation. So in order to represent a query, ``Expression`` implements a
this subgraph using adjacency lists.

Also, ``Expression`` instances are meant to be combined with each other somehow
to make complex queries out of simple ones (this is one main objectives
of quepy).

To do that, every ``Expression`` has a special node called the ``head``, which
is the target node (variable) of the represented query. All operations over
``Expression`` instances work on the ``head`` node, leaving the rest of the
nodes intact.

So ``Expression`` graphs are not built by explicitly adding nodes and edges
like any other normal graph. Instead they are built by a combination of the
following basic operations:

    - ``__init__``: When a ``Expression`` is instantiated a single solitary
                    node is created in the graph.

    - ``decapitate``: Creates a blank node and makes it the new ``head`` of the
                    ``Expression``. Then it adds an edge (a relation) linking
                    this new head to the old one. So in a single operation a
                    node and an edge are added. Used to represent stuff like
                    ``?x rdf:type ?y``.

    - ``add_data``: Adds a relation into some constant data from the ``head``
                    node of the ``Expression``. Used to represent stuff like
                  ``?x rdf:label "John Von Neumann"``.

    - ``merge``: Given two ``Expressions``, it joins their graphs preserving
                 every node and every edge intact except for their ``head``
                 nodes.
                 The ``head`` nodes are merged into a single node that is the
                 new ``head`` and shares all the edges of the previous heads.
                 This is used to combine two graphs like this:

               ::

                   A = ?x rdf:type ?y
                   B = ?x rdf:label "John Von Neumann"

               Into a new one:

               ::

                   A + B = ?x rdf:type ?y;
                           ?x rdf:label "John Von Neumann"


You might be saying "Why?! oh gosh why you did it like this?!".
The reasons are:

    - It allows other parts of the code to build queries in a super
      intuive language, like ``IsPerson() + HasKeyword("Russell")``.
      Go and see the DBpedia example.

    - You can only build connected graphs (ie, no useless variables in query).

    - You cannot have variable name clashes.

    - You cannot build cycles into the graph (could be a con to some, a
      plus to other(it's a plus to me))

    - There are just 3 really basic operations and their semantics are defined
      consisely without special cases (if you care for that kind of stuff
      (I do)).
"""


from collections import defaultdict
from copy import deepcopy


def isnode(x):
    return isinstance(x, int)


class Expression(object):

    def __init__(self):
        """
        Creates a new graph with a single solitary blank node.
        """
        self.nodes = []
        self.head = self._add_node()

    def _add_node(self):
        """
        Adds a blank node to the graph and returns its index (a unique
        identifier).
        """
        i = len(self.nodes)
        self.nodes.append([])
        return i

    def get_head(self):
        """
        Returns the index (the unique identifier) of the head node.
        """
        return self.head

    def merge(self, other):
        """
        Given other Expression, it joins their graphs preserving every
        node and every edge intact except for the ``head`` nodes.
        The ``head`` nodes are merged into a single node that is the new
        ``head`` and shares all the edges of the previous heads.
        """
        translation = defaultdict(self._add_node)
        translation[other.head] = self.head
        for node in other.iter_nodes():
            for relation, dest in other.iter_edges(node):
                xs = self.nodes[translation[node]]
                if isnode(dest):
                    dest = translation[dest]
                xs.append((relation, dest))

    def decapitate(self, relation, reverse=False):
        """
        Creates a new blank node and makes it the ``head`` of the
        Expression. Then it adds an edge (a ``relation``) linking the
        the new head to the old one. So in a single operation a
        node and an edge are added.
        If ``reverse`` is ``True`` then the ``relation`` links the old head to
        the new head instead of the opposite (some relations are not
        commutative).
        """
        oldhead = self.head
        self.head = self._add_node()
        if reverse:
            self.nodes[oldhead].append((relation, self.head))
        else:
            self.nodes[self.head].append((relation, oldhead))

    def add_data(self, relation, value):
        """
        Adds a ``relation`` to some constant ``value`` to the ``head`` of the
        Expression.
        ``value`` is recommended be of type:
        - ``unicode``
        - ``str`` and can be decoded using the default encoding (settings.py)
        - A custom class that implements a ``__unicode__`` method.
        - It can *NEVER* be an ``int``.

        You should not use this to relate nodes in the graph, only to add
        data fields to a node.
        To relate nodes in a graph use a combination of merge and decapitate.
        """
        assert not isnode(value)
        self.nodes[self.head].append((relation, value))

    def iter_nodes(self):
        """
        Iterates the indexes (the unique identifiers) of the Expression nodes.
        """
        return xrange(len(self.nodes))

    def iter_edges(self, node):
        """
        Iterates over the pairs: ``(relation, index)`` which are the neighbors
        of ``node`` in the expression graph, where:
        - ``node`` is the index of the node (the unique identifier).
        - ``relation`` is the label of the edge between the nodes
        - ``index`` is the index of the neighbor (the unique identifier).
        """
        return iter(self.nodes[node])

    def __add__(self, other):
        """
        Merges ``self`` and ``other`` in a new Expression instance.
        Ie, ``self`` and ``other`` are not modified.
        """
        new = deepcopy(self)
        new.merge(other)
        return new

    def __iadd__(self, other):
        """
        Merges ``self`` and ``other`` into ``self``
        ``other`` is not modified but the original data in ``self`` is lost.
        """
        self.merge(other)
        return self

    def __len__(self):
        """
        Amount of nodes in the graph.
        """
        return len(self.nodes)

########NEW FILE########
__FILENAME__ = generation
# coding: utf-8

# Copyright (c) 2012, Machinalis S.R.L.
# This file is part of quepy and is distributed under the Modified BSD License.
# You should have received a copy of license in the LICENSE file.
#
# Authors: Rafael Carrascosa <rcarrascosa@machinalis.com>
#          Gonzalo Garcia Berrotaran <ggarcia@machinalis.com>

"""
Code generation from an expression to a database language.

The currently supported languages are:
    * MQL
    * Sparql
    * Dot: generation of graph images mainly for debugging.
"""

from quepy.mql_generation import generate_mql
from quepy.dot_generation import expression_to_dot
from quepy.sparql_generation import expression_to_sparql


def get_code(expression, language):
    """
    Given an expression and a supported language, it
    returns the query for that expression on that language.
    """

    if language == "sparql":
        return expression_to_sparql(expression)
    elif language == "dot":
        return expression_to_dot(expression)
    elif language == "mql":
        return generate_mql(expression)
    else:
        message = u"Language '{}' is not supported"
        raise ValueError(message.format(language))

########NEW FILE########
__FILENAME__ = mql_generation
# -*- coding: utf-8 -*-

import re
import json
from quepy.dsl import IsRelatedTo
from quepy.expression import isnode
from quepy.encodingpolicy import encoding_flexible_conversion


def choose_start_node(e):
    """
    Choose a node of the `Expression` such that no property leading to a data
    has to be reversed (with !).
    """
    # Since data "nodes" have no outgoing edges it sufices to find any node
    # with an outgoing edge.
    for node in e.iter_nodes():
        if list(e.iter_edges(node)):
            return node
    return node


def safely_to_unicode(x):
    """
    Given an "edge" (a relation) or "a data" from an `Expression` graph
    transform it into a unicode string fitted for insertion into a MQL query.
    """
    if isinstance(x, unicode):
        return x
    if isinstance(x, str):
        return encoding_flexible_conversion(x)
    if isinstance(x, IsRelatedTo):
        return u"/type/reflect/any_master"
    return unicode(x)  # FIXME: Any object is unicode-able, this is error prone


def to_bidirected_graph(e):
    """
    Rewrite the graph such that there are reversed edges for every forward
    edge.
    If an edge goes into a data, it should not be reversed.
    """
    graph = {node: [] for node in e.iter_nodes()}
    for node in e.iter_nodes():
        for relation, other in e.iter_edges(node):
            relation = safely_to_unicode(relation)
            if isnode(other):
                graph[other].append((u"!" + relation, node))
            else:
                other = safely_to_unicode(other)
            graph[node].append((relation, other))
    assert all(isnode(x) for x in graph) and len(e) == len(graph)
    return graph


def post_order_depth_first(graph, start):
    """
    Iterate over the nodes of the graph (is a tree) in a way such that every
    node is preceded by it's childs.
    `graph` is a dict that represents the `Expression` graph. It's a tree too
    beacuse Expressions are trees.
    `start` is the node to use as the root of the tree.
    """
    q = [start]
    seen = set()
    i = 0
    while i != len(graph):
        node = q[i]
        seen.add(node)
        i += 1
        for _, other in graph[node]:
            if isnode(other) and other not in seen:
                q.append(other)
    assert len(q) == len(graph)
    q.reverse()
    return q


def paths_from_root(graph, start):
    """
    Generates paths from `start` to every other node in `graph` and puts it in
    the returned dictionary `paths`.
    ie.: `paths_from_node(graph, start)[node]` is a list of the edge names used
    to get to `node` form `start`.
    """
    paths = {start: []}
    q = [start]
    seen = set()
    while q:
        node = q.pop()
        seen.add(node)
        for relation, child in graph[node]:
            if isnode(child) and child not in seen:
                q.append(child)
                paths[child] = paths[node] + [relation]
    return paths


def generate_mql(e):
    """
    Generates a MQL query for the `Expression` `e`.
    """
    start = choose_start_node(e)
    graph = to_bidirected_graph(e)
    generated = {}
    for node in post_order_depth_first(graph, start):
        d = {}
        for relation, other in graph[node]:
            if isnode(other):
                try:
                    other = generated[other]
                except KeyError:
                    continue  # other is not in post_order_depth_first order
            d[relation] = other
        generated[node] = [d]

    mql_query = json.dumps(generated[start], sort_keys=True,
                            indent=2, separators=(',', ': '))
    mql_query = _tidy(mql_query)
    target = paths_from_root(graph, start)[e.get_head()]
    return target, mql_query


def _tidy(mql):
    """
    Given a json representing a MQL query it collapses spaces between
    braces and curly braces to make it look tidy.
    """
    def replacement_function(match):
        text = match.group(0)
        if text.startswith("[") and text.endswith("]"):
            return "[{}]"
        elif text.startswith("["):
            return "[{"
        indent = 0
        match = re.search("}[ \t]*\n(\s*?)\]", text)
        if match:
            indent = len(match.group(1))
        return " " * indent + "}]"
    return re.sub("\[\s*{\s*}\s*\]|\[\s+{|[ \t]*}\s+\]",
                  replacement_function, mql)

########NEW FILE########
__FILENAME__ = nltktagger
# coding: utf-8

# Copyright (c) 2012, Machinalis S.R.L.
# This file is part of quepy and is distributed under the Modified BSD License.
# You should have received a copy of license in the LICENSE file.
#
# Authors: Rafael Carrascosa <rcarrascosa@machinalis.com>
#          Gonzalo Garcia Berrotaran <ggarcia@machinalis.com>

"""
Tagging using NLTK.
"""

# Requiered data files are:
#   - "maxent_treebank_pos_tagger" in Models
#   - "wordnet" in Corpora

import nltk
from quepy.tagger import Word
from quepy.encodingpolicy import assert_valid_encoding

_penn_to_morphy_tag = {}


def penn_to_morphy_tag(tag):
    assert_valid_encoding(tag)

    for penn, morphy in _penn_to_morphy_tag.iteritems():
        if tag.startswith(penn):
            return morphy
    return None


def run_nltktagger(string, nltk_data_path=None):
    """
    Runs nltk tagger on `string` and returns a list of
    :class:`quepy.tagger.Word` objects.
    """
    assert_valid_encoding(string)
    global _penn_to_morphy_tag

    if nltk_data_path:
        nltk.data.path = nltk_data_path

    from nltk.corpus import wordnet

    if not _penn_to_morphy_tag:
        _penn_to_morphy_tag = {
            u'NN': wordnet.NOUN,
            u'JJ': wordnet.ADJ,
            u'VB': wordnet.VERB,
            u'RB': wordnet.ADV,
        }

    # Recommended tokenizer doesn't handle non-ascii characters very well
    #tokens = nltk.word_tokenize(string)
    tokens = nltk.wordpunct_tokenize(string)
    tags = nltk.pos_tag(tokens)

    words = []
    for token, pos in tags:
        word = Word(token)
        # Eliminates stuff like JJ|CC
        # decode ascii because they are the penn-like POS tags (are ascii).
        word.pos = pos.split("|")[0].decode("ascii")

        mtag = penn_to_morphy_tag(word.pos)
        # Nice shooting, son. What's your name?
        lemma = wordnet.morphy(word.token, pos=mtag)
        if isinstance(lemma, str):
            # In this case lemma is example-based, because if it's rule based
            # the result should be unicode (input was unicode).
            # Since english is ascii the decoding is ok.
            lemma = lemma.decode("ascii")
        word.lemma = lemma
        if word.lemma is None:
            word.lemma = word.token.lower()

        words.append(word)

    return words

########NEW FILE########
__FILENAME__ = parsing
# coding: utf-8

# Copyright (c) 2012, Machinalis S.R.L.
# This file is part of quepy and is distributed under the Modified BSD License.
# You should have received a copy of license in the LICENSE file.
#
# Authors: Rafael Carrascosa <rcarrascosa@machinalis.com>
#          Gonzalo Garcia Berrotaran <ggarcia@machinalis.com>

import refo
import logging
from refo import Predicate, Literal, Star, Any, Group

from quepy.encodingpolicy import encoding_flexible_conversion

_EOL = None
logger = logging.getLogger("quepy.parsing")


class BadSemantic(Exception):
    """
    Problem with the semantic.
    """


class WordList(list):
    """
    A list of words with some utils for the user.
    """

    def __init__(self, words):
        super(WordList, self).__init__(self)
        # Add the words to the list
        self.extend(words)

    @property
    def tokens(self):
        return " ".join([x.token for x in self])

    @property
    def lemmas(self):
        return " ".join([x.lemma for x in self])


class Match(object):
    """
    Holds the matching of the regex.
    """

    def __init__(self, match, words, i=None, j=None):
        assert isinstance(i, type(j))  # Aprox: Both None or both int
        self._match = match
        self._words = words
        self._i = i
        self._j = j
        self._particles = {particle.name: particle for particle in match
                           if isinstance(particle, Particle)}

    @property
    def words(self):
        i, j = self._match.span()  # Should be (0, n)
        if self._i is not None:
            i, j = self._i, self._j
        return WordList(self._words[i:j])

    def __getattr__(self, attr):
        if attr in self._particles:
            particle = self._particles[attr]
            i, j = self._match[particle]
            self._check_valid_indexes(i, j, attr)
            match = Match(self._match, self._words, i, j)
            return particle.interpret(match)

        try:
            i, j = self._match[attr]
        except KeyError:
            message = "'{}' object has no attribute '{}'"
            raise AttributeError(message.format(self.__class__.__name__, attr))
        self._check_valid_indexes(i, j, attr)
        return WordList(self._words[i:j])

    def _check_valid_indexes(self, i, j, attr):
        if self._i is None:
            return
        if i < self._i or self._j <= j:
            message = "'{}' object has no attribute '{}'"
            raise AttributeError(message.format(self.__class__.__name__, attr))


class QuestionTemplate(object):
    """
    Subclass from this to implement a question handler.
    """

    regex = Star(Any())  # Must define when subclassing
    weight = 1  # Redefine this to give different priorities to your regexes.

    def interpret(self, match):
        """
        Returns the intermediate representation of the regex.
        `match` is of type `quepy.regex.Match` and is analogous to a python re
        match. It contains matched groups in the regular expression.

        When implementing a regex one must fill this method.
        """
        raise NotImplementedError()

    def get_interpretation(self, words):
        rulename = self.__class__.__name__
        logger.debug("Trying to match with regex: {}".format(rulename))

        match = refo.match(self.regex + Literal(_EOL), words + [_EOL])

        if not match:
            logger.debug("No match")
            return None, None

        try:
            match = Match(match, words)
            result = self.interpret(match)
        except BadSemantic as error:
            logger.debug(str(error))
            return None, None
        try:
            expression, userdata = result
        except TypeError:
            expression, userdata = result, None

        expression.rule_used = rulename
        return expression, userdata


class Pos(Predicate):
    """
    Predicate to check if a word has an specific *POS* tag.
    """

    def __init__(self, tag):
        tag = encoding_flexible_conversion(tag)
        self.tag = tag
        super(Pos, self).__init__(self._predicate)
        self.arg = tag

    def _predicate(self, word):
        return word != _EOL and self._check(word)

    def _check(self, word):
        return word.pos == self.tag


class Lemma(Pos):
    """
    Predicate to check if a word has an specific *lemma*.
    """

    def _check(self, word):
        return word.lemma == self.tag


class Token(Pos):
    """
    Predicate to check if a word has an specific *token*.
    """

    def _check(self, word):
        return word.token == self.tag


class Particle(Group):
    regex = None

    def __init__(self, name=None):
        if self.regex is None:
            message = "A regex must be defined for {}"
            raise NotImplementedError(message.format(self.__class__.__name__))
        if name is None:
            name = self.__class__.__name__.lower()
        self.name = name
        super(Particle, self).__init__(self.regex, self)

    def interpret(self, match):
        message = "A interpretation must be defined for {}"
        raise NotImplementedError(message.format(self.__class__.__name__))

    def __str__(self):
        return repr(self)

    def __repr__(self):
        cname = self.__class__.__name__
        if cname.lower() == self.name:
            return "{}()".format(cname)
        else:
            return "{}('{}')".format(cname, self.name)


def _predicate_sum_from_string(string, predicate):
    assert issubclass(predicate, Predicate)

    string = encoding_flexible_conversion(string)
    words = string.split()
    result = None
    for word in words:
        if result is None:
            result = predicate(word)
        else:
            result += predicate(word)

    return result


def Lemmas(string):
    """
    Returns a Predicate that catches strings
    with the lemmas mentioned on `string`.
    """
    return _predicate_sum_from_string(string, Lemma)


def Tokens(string):
    """
    Returns a Predicate that catches strings
    with the tokens mentioned on `string`.
    """
    return _predicate_sum_from_string(string, Token)


def Poss(string):
    """
    Returns a Predicate that catches strings
    with the POS mentioned on `string`.
    """
    return _predicate_sum_from_string(string, Pos)

########NEW FILE########
__FILENAME__ = quepyapp
# coding: utf-8

# Copyright (c) 2012, Machinalis S.R.L.
# This file is part of quepy and is distributed under the Modified BSD License.
# You should have received a copy of license in the LICENSE file.
#
# Authors: Rafael Carrascosa <rcarrascosa@machinalis.com>
#          Gonzalo Garcia Berrotaran <ggarcia@machinalis.com>

"""
Implements the Quepy Application API
"""

import logging
from importlib import import_module
from types import ModuleType

from quepy import settings
from quepy import generation
from quepy.parsing import QuestionTemplate
from quepy.tagger import get_tagger, TaggingError
from quepy.encodingpolicy import encoding_flexible_conversion

logger = logging.getLogger("quepy.quepyapp")


def install(app_name):
    """
    Installs the application and gives an QuepyApp object
    """

    module_paths = {
        u"settings": u"{0}.settings",
        u"parsing": u"{0}",
    }
    modules = {}

    for module_name, module_path in module_paths.iteritems():
        try:
            modules[module_name] = import_module(module_path.format(app_name))
        except ImportError, error:
            message = u"Error importing {0!r}: {1}"
            raise ImportError(message.format(module_name, error))

    return QuepyApp(**modules)


def question_sanitize(question):
    question = question.replace("'", "\'")
    question = question.replace("\"", "\\\"")
    return question


class QuepyApp(object):
    """
    Provides the quepy application API.
    """

    def __init__(self, parsing, settings):
        """
        Creates the application based on `parsing`, `settings` modules.
        """

        assert isinstance(parsing, ModuleType)
        assert isinstance(settings, ModuleType)

        self._parsing_module = parsing
        self._settings_module = settings

        # Save the settings right after loading settings module
        self._save_settings_values()

        self.tagger = get_tagger()
        self.language = getattr(self._settings_module, "LANGUAGE", None)
        if not self.language:
            raise ValueError("Missing configuration for language")

        self.rules = []
        for element in dir(self._parsing_module):
            element = getattr(self._parsing_module, element)

            try:
                if issubclass(element, QuestionTemplate) and \
                        element is not QuestionTemplate:

                    self.rules.append(element())
            except TypeError:
                continue

        self.rules.sort(key=lambda x: x.weight, reverse=True)

    def get_query(self, question):
        """
        Given `question` in natural language, it returns
        three things:

        - the target of the query in string format
        - the query
        - metadata given by the regex programmer (defaults to None)

        The query returned corresponds to the first regex that matches in
        weight order.
        """

        question = question_sanitize(question)
        for target, query, userdata in self.get_queries(question):
            return target, query, userdata
        return None, None, None

    def get_queries(self, question):
        """
        Given `question` in natural language, it returns
        three things:

        - the target of the query in string format
        - the query
        - metadata given by the regex programmer (defaults to None)

        The queries returned corresponds to the regexes that match in
        weight order.
        """
        question = encoding_flexible_conversion(question)
        for expression, userdata in self._iter_compiled_forms(question):
            target, query = generation.get_code(expression, self.language)
            message = u"Interpretation {1}: {0}"
            logger.debug(message.format(str(expression),
                         expression.rule_used))
            logger.debug(u"Query generated: {0}".format(query))
            yield target, query, userdata

    def _iter_compiled_forms(self, question):
        """
        Returns all the compiled form of the question.
        """

        try:
            words = list(self.tagger(question))
        except TaggingError:
            logger.warning(u"Can't parse tagger's output for: '%s'",
                           question)
            return

        logger.debug(u"Tagged question:\n" +
                     u"\n".join(u"\t{}".format(w for w in words)))

        for rule in self.rules:
            expression, userdata = rule.get_interpretation(words)
            if expression:
                yield expression, userdata

    def _save_settings_values(self):
        """
        Persists the settings values of the app to the settings module
        so it can be accesible from another part of the software.
        """

        for key in dir(self._settings_module):
            if key.upper() == key:
                value = getattr(self._settings_module, key)
                if isinstance(value, str):
                    value = encoding_flexible_conversion(value)
                setattr(settings, key, value)

########NEW FILE########
__FILENAME__ = settings
# coding: utf-8

# Copyright (c) 2012, Machinalis S.R.L.
# This file is part of quepy and is distributed under the Modified BSD License.
# You should have received a copy of license in the LICENSE file.
#
# Authors: Rafael Carrascosa <rcarrascosa@machinalis.com>
#          Gonzalo Garcia Berrotaran <ggarcia@machinalis.com>

"""
Settings.
"""

# Generated query language
LANGUAGE = "sparql"

# NLTK config
NLTK_DATA_PATH = []  # List of paths with NLTK data

# Encoding config
DEFAULT_ENCODING = "utf-8"

# Sparql config
SPARQL_PREAMBLE = u"""
PREFIX owl: <http://www.w3.org/2002/07/owl#>
PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>
PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>
PREFIX foaf: <http://xmlns.com/foaf/0.1/>
PREFIX skos: <http://www.w3.org/2004/02/skos/core#>
PREFIX quepy: <http://www.machinalis.com/quepy#>
"""

########NEW FILE########
__FILENAME__ = sparql_generation
# -*- coding: utf-8 -*-

"""
Sparql generation code.
"""

from quepy import settings
from quepy.dsl import IsRelatedTo
from quepy.expression import isnode
from quepy.encodingpolicy import assert_valid_encoding

_indent = u"  "


def escape(string):
    string = unicode(string)
    string = string.replace("\n", "")
    string = string.replace("\r", "")
    string = string.replace("\t", "")
    string = string.replace("\x0b", "")
    if not string or any([x for x in string if 0 < ord(x) < 31]) or \
            string.startswith(":") or string.endswith(":"):
        message = "Unable to generate sparql: invalid nodes or relation"
        raise ValueError(message)
    return string


def adapt(x):
    if isnode(x):
        x = u"?x{}".format(x)
        return x
    if isinstance(x, basestring):
        assert_valid_encoding(x)
        if x.startswith(u"\"") or ":" in x:
            return x
        return u'"{}"'.format(x)
    return unicode(x)


def expression_to_sparql(e, full=False):
    template = u"{preamble}\n" +\
               u"SELECT DISTINCT {select} WHERE {{\n" +\
               u"{expression}\n" +\
               u"}}\n"
    head = adapt(e.get_head())
    if full:
        select = u"*"
    else:
        select = head
    y = 0
    xs = []
    for node in e.iter_nodes():
        for relation, dest in e.iter_edges(node):
            if relation is IsRelatedTo:
                relation = u"?y{}".format(y)
                y += 1
            xs.append(triple(adapt(node), relation, adapt(dest),
                      indentation=1))
    sparql = template.format(preamble=settings.SPARQL_PREAMBLE,
                             select=select,
                             expression=u"\n".join(xs))
    return select, sparql


def triple(a, p, b, indentation=0):
    a = escape(a)
    b = escape(b)
    p = escape(p)
    s = _indent * indentation + u"{0} {1} {2}."
    return s.format(a, p, b)

########NEW FILE########
__FILENAME__ = tagger
# coding: utf-8

# Copyright (c) 2012, Machinalis S.R.L.
# This file is part of quepy and is distributed under the Modified BSD License.
# You should have received a copy of license in the LICENSE file.
#
# Authors: Rafael Carrascosa <rcarrascosa@machinalis.com>
#          Gonzalo Garcia Berrotaran <ggarcia@machinalis.com>

import logging

from quepy import settings
from quepy.encodingpolicy import assert_valid_encoding

logger = logging.getLogger("quepy.tagger")
PENN_TAGSET = set(u"$ `` '' ( ) , -- . : CC CD DT EX FW IN JJ JJR JJS LS MD "
                  "NN NNP NNPS NNS PDT POS PRP PRP$ RB RBR RBS RP SYM TO UH "
                  "VB VBD VBG VBN VBP VBZ WDT WP WP$ WRB".split())


class TaggingError(Exception):
    """
    Error parsing tagger's output.
    """
    pass


class Word(object):
    """
    Representation of a tagged word.
    Contains *token*, *lemma*, *pos tag* and optionally a *probability* of
    that tag.
    """
    _encoding_attrs = u"token lemma pos".split()
    _attrs = _encoding_attrs + [u"prob"]

    def __init__(self, token, lemma=None, pos=None, prob=None):
        self.pos = pos
        self.prob = prob
        self.lemma = lemma
        self.token = token

    def __setattr__(self, name, value):
        if name in self._encoding_attrs and value is not None:
            assert_valid_encoding(value)
        object.__setattr__(self, name, value)

    def __unicode__(self):
        attrs = (getattr(self, name, u"-") for name in self._attrs)
        return u"|".join(str(x) for x in attrs)

    def __repr__(self):
        return unicode(self)


def get_tagger():
    """
    Return a tagging function given some app settings.
    `Settings` is the settings module of an app.
    The returned value is a function that receives a unicode string and returns
    a list of `Word` instances.
    """
    from quepy.nltktagger import run_nltktagger
    tagger_function = lambda x: run_nltktagger(x, settings.NLTK_DATA_PATH)

    def wrapper(string):
        assert_valid_encoding(string)
        words = tagger_function(string)
        for word in words:
            if word.pos not in PENN_TAGSET:
                logger.warning("Tagger emmited a non-penn "
                               "POS tag {!r}".format(word.pos))
        return words
    return wrapper

########NEW FILE########
__FILENAME__ = random_expression
# -*- coding: utf-8 -*-
import random
from quepy.expression import Expression


def random_data(only_ascii=False):
    data = []
    first = True
    while first or 1 / 20.0 < random.random():
        first = False
        if only_ascii:
            c = unichr(random.randint(33, 126))
            data.append(c)
            continue
        x = random.random()
        if 0.1 > x:
            c = random.choice(u" ./\n")
        elif 0.50 > x:
            c = unichr(random.randint(65, 122))
        elif 0.85 > x:
            c = unichr(random.randint(0, 127))
        else:
            c = unichr(random.randint(0, 65535))
        data.append(c)
    return u"".join(data)


def random_relation(only_ascii=False):
    data = random_data(only_ascii)
    data = data.replace(" ", "")
    if random.random() > 0.05:
        return data

    class UnicodeableDummy(object):
        def __unicode__(self):
            return data
    return UnicodeableDummy()


def random_expression(only_ascii=False):
    """
    operations: new node, add data, decapitate, merge
    """
    mean_size = 20
    xs = [40.0, 30.0, 50.0, 20.0]
    xs = [x * (1.0 - random.random()) for x in xs]
    assert all(x != 0 for x in xs)
    new_node, add_data, decapitate, _ = [x / sum(xs) for x in xs]
    expressions = [Expression(), Expression(), Expression(), Expression()]
    while len(expressions) != 1:
        if (1.0 / mean_size) < random.random():
            # Will start to merge more and will not create new nodes
            new_node = 0.0
        # Choose action
        r = random.random()
        if r < new_node:
            # New expression
            expressions.append(Expression())
        elif r < add_data + new_node:
            # Add data
            e = random.choice(expressions)
            e.add_data(random_relation(only_ascii), random_data(only_ascii))
        elif r < decapitate + add_data + new_node:
            # Decapitate
            e = random.choice(expressions)
            e.decapitate(random_relation(only_ascii),
                         reverse=(0.25 < random.random()))
        elif len(expressions) != 1:
            # Merge
            random.shuffle(expressions)
            e2 = expressions.pop()
            e1 = expressions[-1]
            e1 += e2
    return expressions[0]

########NEW FILE########
__FILENAME__ = basic
#!/usr/bin/env python
# coding: utf-8

# Copyright (c) 2012, Machinalis S.R.L.
# This file is part of quepy and is distributed under the Modified BSD License.
# You should have received a copy of license in the LICENSE file.
#
# Authors: Rafael Carrascosa <rcarrascosa@machinalis.com>
#          Gonzalo Garcia Berrotaran <ggarcia@machinalis.com>

"""
Regex for testapp quepy.
"""

from refo import Star, Any
from quepy.dsl import HasKeyword
from quepy.parsing import QuestionTemplate, Token


class LowMatchAny(QuestionTemplate):
    weight = 0.5
    regex = Star(Any())

    def interpret(self, match):
        expr = None

        for word in match.words:
            if expr is not None:
                expr += HasKeyword(word.token)
            else:
                expr = HasKeyword(word.token)

        return expr


class MatchAny(LowMatchAny):
    weight = 0.8

    def interpret(self, match):
        expr = super(MatchAny, self).interpret(match)
        return expr, 42


class UserData(QuestionTemplate):
    weight = 1.0
    regex = Token("user") + Token("data")

    def interpret(self, match):
        return HasKeyword(match.words[0].token), "<user data>"

########NEW FILE########
__FILENAME__ = dsl
#!/usr/bin/env python
# coding: utf-8

# Copyright (c) 2012, Machinalis S.R.L.
# This file is part of quepy and is distributed under the Modified BSD License.
# You should have received a copy of license in the LICENSE file.
#
# Authors: Rafael Carrascosa <rcarrascosa@machinalis.com>
#          Gonzalo Garcia Berrotaran <ggarcia@machinalis.com>

"""
Intermediate representation for testapp quepy.
"""


########NEW FILE########
__FILENAME__ = settings
#!/usr/bin/env python
# coding: utf-8

# Copyright (c) 2012, Machinalis S.R.L.
# This file is part of quepy and is distributed under the Modified BSD License.
# You should have received a copy of license in the LICENSE file.
#
# Authors: Rafael Carrascosa <rcarrascosa@machinalis.com>
#          Gonzalo Garcia Berrotaran <ggarcia@machinalis.com>

"""
Settings for testapp quepy.
"""

LANGUAGE = "sparql"
NLTK_DATA_PATH = []
SPARQL_PREAMBLE = '''
PREFIX owl: <http://www.w3.org/2002/07/owl#>
PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>
PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>
PREFIX foaf: <http://xmlns.com/foaf/0.1/>
PREFIX skos: <http://www.w3.org/2004/02/skos/core#>
PREFIX quepy: <http://www.machinalis.com/quepy#>
PREFIX testapp: <http://www.machinalis.com/testapp#>
'''

########NEW FILE########
__FILENAME__ = test_dot_generation
# -*- coding: utf-8 -*-

# Copyright (c) 2012, Machinalis S.R.L.
# This file is part of quepy and is distributed under the Modified BSD License.
# You should have received a copy of license in the LICENSE file.
#
# Authors: Rafael Carrascosa <rcarrascosa@machinalis.com>
#          Gonzalo Garcia Berrotaran <ggarcia@machinalis.com>

import unittest
import tempfile
import subprocess
from random_expression import random_expression
from random import seed
from quepy.dot_generation import expression_to_dot
from quepy.dsl import FixedRelation, FixedType, \
    FixedDataRelation


def gen_datarel(rel, data):
    class X(FixedDataRelation):
        relation = rel
    return X(data)


def gen_fixedtype(type_):
    class X(FixedType):
        fixedtype = type_
    return X()


def gen_fixedrelation(rel, e):
    class X(FixedRelation):
        relation = rel
    return X(e)


class TestDotGeneration(unittest.TestCase):

    def _standard_check(self, s, e):
        self.assertIsInstance(s, unicode)
        vs = [u"x{}".format(i) for i in xrange(len(e))]
        for var in vs:
            self.assertIn(var, s)

    def test_dot_takes_unicode(self):
        e = gen_fixedtype(u"·̣─@łæßð~¶½")
        e += gen_datarel(u"tµŧurułej€", u"←ðßðæßđæßæđßŋŋæ @~~·ŋŋ·¶·ŋ“¶¬@@")
        _, s = expression_to_dot(e)
        self._standard_check(s, e)

    def test_dot_takes_fails_ascii1(self):
        e = gen_fixedtype("a")
        e += gen_datarel("b", "c")
        e = gen_fixedrelation("d", e)
        self.assertRaises(ValueError, expression_to_dot, e)

    def test_dot_takes_fails_ascii2(self):
        e = gen_fixedtype("·̣─@łæßð~¶½")
        e += gen_datarel("tµŧurułej€", "←ðßðæßđæßæđßŋŋæ @~~·ŋŋ·¶·ŋ“¶¬@@")
        self.assertRaises(ValueError, expression_to_dot, e)

    def test_dot_stress(self):
        seed("I have come here to chew bubblegum and kick ass... "
             "and I'm all out of bubblegum.")
        dot_file = tempfile.NamedTemporaryFile()
        cmdline = "dot %s" % dot_file.name
        msg = "dot returned error code {}, check {} input file."
        for _ in xrange(100):
            expression = random_expression()
            _, dot_string = expression_to_dot(expression)
            with open(dot_file.name, "w") as filehandler:
                filehandler.write(dot_string.encode("utf-8"))

            try:
                retcode = subprocess.call(cmdline.split(),
                                          stdout=tempfile.TemporaryFile())
            except OSError:
                print "Warning: the program 'dot' was not found, tests skipped"
                return
            if retcode != 0:
                dot_file.delete = False
            self.assertEqual(retcode, 0, msg.format(retcode, dot_file.name))


if __name__ == "__main__":
    unittest.main()

########NEW FILE########
__FILENAME__ = test_dsl
# coding: utf-8

# Copyright (c) 2012, Machinalis S.R.L.
# This file is part of quepy and is distributed under the Modified BSD License.
# You should have received a copy of license in the LICENSE file.
#
# Authors: Rafael Carrascosa <rcarrascosa@machinalis.com>
#          Gonzalo Garcia Berrotaran <ggarcia@machinalis.com>

import unittest
from quepy.expression import Expression
from quepy.dsl import HasKeyword, FixedRelation, FixedType, \
    FixedDataRelation


class TestDSL(unittest.TestCase):
    def test_fixed_relation(self):

        class MyFixedRelation(FixedRelation):
            relation = u"uranium:blowtorch"

        empty = Expression()
        fixedinstance = MyFixedRelation(empty)

        head = fixedinstance.get_head()
        relations = [x[0] for x in fixedinstance.iter_edges(head)]

        self.assertIn(u"uranium:blowtorch", relations)

    def test_fixed_type(self):

        class MyFixedType(FixedType):
            fixedtype = u"uranium:blowtorch"
            fixedtyperelation = u"rdf:type"

        fixedinstance = MyFixedType()

        head = fixedinstance.get_head()
        edges = list(fixedinstance.iter_edges(head))

        self.assertEqual(len(edges), 1)
        self.assertIsInstance(edges[0][0], unicode)
        self.assertEqual(edges[0][0], u"rdf:type")
        self.assertIsInstance(edges[0][1], unicode)
        self.assertEqual(edges[0][1], u"uranium:blowtorch")

    def test_fixed_data_relation(self):

        class MyFixedDataRelation(FixedDataRelation):
            relation = u"uranium:blowtorch"

        fixedinstance = MyFixedDataRelation(u"soplete")
        head = fixedinstance.get_head()
        edges = list(fixedinstance.iter_edges(head))

        self.assertEqual(len(edges), 1)
        self.assertIsInstance(edges[0][0], unicode)
        self.assertEqual(edges[0][0], u"uranium:blowtorch")
        self.assertIsInstance(edges[0][1], unicode)
        self.assertEqual(edges[0][1], u"soplete")

    def test_has_keyword(self):

        HasKeyword.relation = u"uranium:keyword"
        keywordinstance = HasKeyword(u"soplete")

        head = keywordinstance.get_head()
        edges = list(keywordinstance.iter_edges(head))
        self.assertEqual(len(edges), 1)
        self.assertIsInstance(edges[0][0], unicode)
        self.assertEqual(edges[0][0], u"uranium:keyword")
        self.assertIsInstance(edges[0][1], unicode)
        self.assertEqual(edges[0][1], u'soplete')

        # With language
        HasKeyword.language = "en"
        keywordinstance = HasKeyword("soplete")

        head = keywordinstance.get_head()
        edges = list(keywordinstance.iter_edges(head))
        self.assertEqual(len(edges), 1)
        self.assertIsInstance(edges[0][1], unicode)
        self.assertEqual(edges[0][1], u'"soplete"@en')

        # With sanitize
        HasKeyword.sanitize = staticmethod(lambda x: x.upper())
        keywordinstance = HasKeyword(u"soplete")

        head = keywordinstance.get_head()
        edges = list(keywordinstance.iter_edges(head))
        self.assertEqual(len(edges), 1)
        self.assertIsInstance(edges[0][1], unicode)
        self.assertEqual(edges[0][1], u'"SOPLETE"@en')


if __name__ == "__main__":
    unittest.main()

########NEW FILE########
__FILENAME__ = test_expressions
#!/usr/bin/env python
# coding: utf-8

# Copyright (c) 2012, Machinalis S.R.L.
# This file is part of quepy and is distributed under the Modified BSD License.
# You should have received a copy of license in the LICENSE file.
#
# Authors: Rafael Carrascosa <rcarrascosa@machinalis.com>
#          Gonzalo Garcia Berrotaran <ggarcia@machinalis.com>

"""
Tests for expressions.
"""

import unittest
from quepy.expression import Expression, isnode


def make_canonical_expression(e):
    i = 0
    q = [e.get_head()]
    seen = set()
    while i != len(q):
        node = q[i]
        i += 1
        assert node not in seen, "Nouuu, expression is cyclic!"
        for relation, child in e.iter_edges(node):
            if isnode(child):
                q.append(child)
    q.reverse()
    canon = {}
    for node in q:
        childs = []
        for label, child in e.iter_edges(node):
            if isnode(child):
                child = canon[child]
            childs.append((label, child))
        childs.sort()
        canon[node] = tuple(childs)
    return canon[e.get_head()]


class ExpressionTests(object):
    def test_acyclic(self):
        head = self.e.get_head()
        q = [head]
        seen = set()
        while q:
            current = q.pop()
            self.assertNotIn(current, seen)
            seen.add(current)
            for relation, child in self.e.iter_edges(current):
                if isnode(child):
                    q.append(child)

    def test_non_empty(self):
        self.assertNotEqual(len(self.e), 0)

    def test_add_data(self):
        rel = u"|@·~½"
        data = "somedata"
        self.e.add_data(rel, data)
        xs = list(self.e.iter_edges(self.e.get_head()))
        self.assertIn((rel, data), xs)

    def test_decapitate(self):
        oldhead = self.e.get_head()
        self.e.decapitate("blabla")
        self.assertNotEqual(oldhead, self.e.get_head())
        xs = list(self.e.iter_edges(self.e.get_head()))
        self.assertEqual(xs, [("blabla", oldhead)])

    def test_merges1(self):
        oldlen = len(self.e)
        oldhead = self.e.get_head()
        other = Expression()
        other.decapitate("blabla")
        self.e.merge(other)
        self.assertEqual(self.e.get_head(), oldhead)
        self.assertEqual(len(self.e), oldlen + len(other) - 1)

    def test_merges2(self):
        other = Expression()
        other.decapitate("blabla")
        oldlen = len(other)
        oldhead = other.get_head()
        other.merge(self.e)
        self.assertEqual(other.get_head(), oldhead)
        self.assertEqual(len(other), oldlen + len(self.e) - 1)

    def test_plus_makes_copy(self):
        other = Expression()
        other.decapitate("blabla")
        a = self.e + other
        self.assertFalse(a is other or self.e is other or a is self.e)

    def test_plus_is_conmutative(self):
        other = Expression()
        other.decapitate("blabla")
        a = self.e + other
        b = other + self.e
        self.assertEqual(make_canonical_expression(a),
                         make_canonical_expression(b))

    def test_plus_is_conmutative2(self):
        other = Expression()
        other.decapitate("blabla")
        a = self.e + other + self.e
        b = other + self.e + self.e
        self.assertEqual(make_canonical_expression(a),
                         make_canonical_expression(b))


class TestExpression1(unittest.TestCase, ExpressionTests):
    def setUp(self):
        self.e = Expression()


class TestExpression2(unittest.TestCase, ExpressionTests):
    def setUp(self):
        self.e = Expression()
        self.e.add_data("key", "1")
        self.e.add_data("key", "2")
        self.e.add_data(u"~·~··@↓", None)
        self.e.add_data(None, None)


class TestExpression3(unittest.TestCase, ExpressionTests):
    def setUp(self):
        self.e = Expression()
        self.e.add_data("key", "1")
        self.e.decapitate(u"µ")
        self.e.add_data("a", "2")
        self.e.add_data("a", "3")
        self.e.add_data(None, None)
        self.e.decapitate(None)
        self.e.add_data(None, None)


class TestExpression4(unittest.TestCase, ExpressionTests):
    def setUp(self):
        self.e = Expression()
        self.e.add_data(123, "456")
        other = Expression()
        other.add_data(0, "1")
        other.add_data(2, "3")
        other.decapitate("iuju")
        for _ in xrange(5):
            self.e.decapitate("nouu")
            self.e += other


class CanonEqualTest(object):
    def test_are_the_same(self):
        a = make_canonical_expression(self.a)
        b = make_canonical_expression(self.b)
        self.assertEqual(a, b)


class CanonNotEqualTest(object):
    def test_are_the_same(self):
        a = make_canonical_expression(self.a)
        b = make_canonical_expression(self.b)
        self.assertNotEqual(a, b)


class TestCanon1(unittest.TestCase, CanonEqualTest):
    def setUp(self):
        self.a = Expression()
        self.b = Expression()


class TestCanon2(unittest.TestCase, CanonEqualTest):
    def setUp(self):
        self.a = Expression()
        self.a.add_data(None, "1")
        self.a.add_data(None, "2")
        self.b = Expression()
        self.b.add_data(None, "2")
        self.b.add_data(None, "1")


class TestCanon3(unittest.TestCase, CanonEqualTest):
    def setUp(self):
        A = Expression()
        A.add_data("bla", "somedata")
        A.decapitate("hier")
        B = Expression()
        B.add_data("ble", "otherdata")
        B.decapitate("hier")
        self.a = A + B
        self.b = B + A


class TestCanon4(unittest.TestCase, CanonEqualTest):
    def setUp(self):
        A = Expression()
        A.add_data("bla", "somedata")
        A.decapitate("hier")
        B = Expression()
        B.add_data("ble", "otherdata")
        B.decapitate("hier")
        C = A + B
        C.decapitate("hier")
        C += B
        C.decapitate("hier")
        self.a = C + A
        D = B + A
        D.decapitate("hier")
        D += B
        D.decapitate("hier")
        self.b = D + A


class TestCanon95(unittest.TestCase, CanonNotEqualTest):
    def setUp(self):
        self.a = Expression()
        self.a.decapitate("onelevel")

        self.b = Expression()
        self.b.decapitate("onelevel", reverse=True)


class TestCanon96(unittest.TestCase, CanonNotEqualTest):
    def setUp(self):
        self.a = Expression()
        self.a.add_data(0, "data")
        self.a.decapitate("onelevel")

        self.b = Expression()
        self.b.add_data(0, "data")
        self.b.decapitate("onelevel", reverse=True)


class TestCanon97(unittest.TestCase, CanonNotEqualTest):
    def setUp(self):
        other = Expression()
        other.decapitate("onelevel")
        self.a = Expression()
        for _ in xrange(5):
            self.a.decapitate("step")
            self.a += other

        other = Expression()
        other.decapitate("onelevel", reverse=True)
        self.b = Expression()
        for _ in xrange(5):
            self.b.decapitate("step")
            self.b += other


class TestCanon98(unittest.TestCase, CanonNotEqualTest):
    def setUp(self):
        other = Expression()
        other.add_data(0, "data")
        other.decapitate("onelevel")
        self.a = Expression()
        for _ in xrange(5):
            self.a.decapitate("step")
            self.a += other

        other = Expression()
        other.add_data(0, "data")
        other.decapitate("onelevel", reverse=True)
        self.b = Expression()
        for _ in xrange(5):
            self.b.decapitate("step")
            self.b += other


class TestCanon99(unittest.TestCase, CanonNotEqualTest):
    def setUp(self):
        self.a = Expression()
        self.b = Expression()
        self.b.decapitate("relation")


if __name__ == "__main__":
    unittest.main()

########NEW FILE########
__FILENAME__ = test_mql_generation
# -*- coding: utf-8 -*-

# Copyright (c) 2012, Machinalis S.R.L.
# This file is part of quepy and is distributed under the Modified BSD License.
# You should have received a copy of license in the LICENSE file.
#
# Authors: Rafael Carrascosa <rcarrascosa@machinalis.com>
#          Gonzalo Garcia Berrotaran <ggarcia@machinalis.com>

import json
from random import seed
import unittest
from random_expression import random_expression
from quepy.mql_generation import generate_mql


class TestMqlGeneration(unittest.TestCase):
    def _get_json(self, query):
        try:
            return json.loads(query)
        except ValueError as e:
            if "Unpaired" in str(e) and "surrogate" in str(e):
                # This is a known issue python's json.
                return None

    def _valid_mql_query(self, query):
        x = self._get_json(query)
        if x is None:
            return
        q = [x]
        while q:
            x = q.pop()
            # Each entry is either a [{...}] or a unicode
            if isinstance(x, list):
                self.assertIsInstance(x[0], dict)
                self.assertEqual(len(x), 1)
                for key, value in x[0].iteritems():
                    self.assertIsInstance(key, unicode)
                    q.append(value)
            else:
                self.assertIsInstance(x, unicode)

    def _valid_target_for_query(self, target, query):
        self.assertIsInstance(target, list)
        for entry in target:
            self.assertIsInstance(entry, unicode)
        x = self._get_json(query)
        if x is None:
            return
        target = list(target)
        while target:
            entry = target.pop(0)
            x = x[0][entry]
        self.assertIsInstance(x, list)
        self.assertEqual(len(x), 1)
        self.assertIsInstance(x[0], dict)
        #self.assertEqual(len(x[0]), 0)  # Too strict?

    def test_mql_stress(self):
        seed("playadito vs amanda... 3 focas")
        for _ in xrange(100):
            expression = random_expression()
            target, mql = generate_mql(expression)
            self._valid_mql_query(mql)
            self._valid_target_for_query(target, mql)

if __name__ == "__main__":
    unittest.main()

########NEW FILE########
__FILENAME__ = test_nltktagger
#!/usr/bin/env python
# coding: utf-8

# Copyright (c) 2012, Machinalis S.R.L.
# This file is part of quepy and is distributed under the Modified BSD License.
# You should have received a copy of license in the LICENSE file.
#
# Authors: Rafael Carrascosa <rcarrascosa@machinalis.com>
#          Gonzalo Garcia Berrotaran <ggarcia@machinalis.com>

"""
Tests for nltktagger.
"""

import unittest
from quepy import nltktagger
from quepy.tagger import Word


class TestNLTKTagger(unittest.TestCase):
    def test_word_output(self):
        output = nltktagger.run_nltktagger(u"this is a test case «¢ðßæŋħħ")

        self.assertIsInstance(output, list)
        for word in output:
            self.assertIsInstance(word, Word)

    def tests_wrong_input(self):
        self.assertRaises(ValueError, nltktagger.run_nltktagger,
                          "this is not unicode")

########NEW FILE########
__FILENAME__ = test_parsing
#!/usr/bin/env python
# coding: utf-8

# Copyright (c) 2012, Machinalis S.R.L.
# This file is part of quepy and is distributed under the Modified BSD License.
# You should have received a copy of license in the LICENSE file.
#
# Authors: Rafael Carrascosa <rcarrascosa@machinalis.com>
#          Gonzalo Garcia Berrotaran <ggarcia@machinalis.com>

"""
Tests for Regex module.
"""

import unittest
from quepy.parsing import QuestionTemplate, Particle, Lemma
from quepy.tagger import Word


class Mockrule(object):
    rulename = "Mock"


class TestQuestionTemplate(unittest.TestCase):
    def setUp(self):
        self.mockrule = Mockrule

        class SomeRegex(QuestionTemplate):
            regex = Lemma(u"hello")

            def interpret(self, match):
                return Mockrule

        class SomeRegexWithData(QuestionTemplate):
            regex = Lemma(u"hello")

            def interpret(self, match):
                return Mockrule, 42

        self.regexinstance = SomeRegex()
        self.regex_with_data = SomeRegexWithData()

    def test_match(self):
        words = [Word(u"hi", u"hello")]
        ir, userdata = self.regexinstance.get_interpretation(words)
        self.assertTrue(ir is self.mockrule)
        self.assertEqual(userdata, None)

    def test_no_match(self):
        words = [Word(u"hi", u"hello"), Word(u"girl", u"girl")]
        ir, userdata = self.regexinstance.get_interpretation(words)
        self.assertEqual(ir, None)
        self.assertEqual(userdata, None)

    def test_user_data(self):
        words = [Word(u"hi", u"hello")]
        _, userdata = self.regex_with_data.get_interpretation(words)
        self.assertEqual(userdata, 42)

    def test_no_ir(self):
        class SomeRegex(QuestionTemplate):
            regex = Lemma(u"hello")

        regexinstance = SomeRegex()
        words = [Word(u"hi", u"hello")]
        self.assertRaises(NotImplementedError,
                          regexinstance.get_interpretation, words)

    def test_regex_empty(self):
        class SomeRegex(QuestionTemplate):
            def interpret(self, match):
                return Mockrule, "YES!"

        regexinstance = SomeRegex()
        words = [Word(u"hi", u"hello")]
        ir, userdata = regexinstance.get_interpretation(words)
        self.assertTrue(ir is Mockrule)
        self.assertEqual(userdata, "YES!")

    def test_match_words(self):
        class SomeRegex(QuestionTemplate):
            def interpret(self, match):
                return match

        words = [Word(u"|@€đ€łł@ð«|µnþ", u"hello"), Word(u"a", u"b", u"c")]
        match, _ = SomeRegex().get_interpretation(words)
        self.assertEqual(words, match.words)


class TestParticle(unittest.TestCase):
    def setUp(self):
        class Person(Particle):
            regex = Lemma(u"Jim") | Lemma(u"Tonny")

            def interpret(self, match):
                return match

        class PersonRegex(QuestionTemplate):
            regex = Person() + Lemma(u"be") + Person(u"another")

            def interpret(self, match):
                return match

        class PersonAsset(Person):
            regex = Person() + Lemma(u"'s") + Lemma(u"car")

        class NestedParticleRegex(PersonRegex):
            regex = PersonAsset() + Lemma(u"be") + Person(u"another")

        self.personregex = PersonRegex()
        self.nestedregex = NestedParticleRegex()

    def test_attrs(self):
        words = [Word(x, x) for x in u"Jim be Tonny".split()]
        match, _ = self.personregex.get_interpretation(words)
        self.assertEqual(match.another.words[0], words[-1])
        self.assertEqual(match.person.words[0], words[0])
        self.assertRaises(AttributeError, lambda: match.pirulo)

    def test_nested_particle(self):
        words = [Word(x, x) for x in u"Jim 's car be Tonny".split()]
        match, _ = self.nestedregex.get_interpretation(words)
        self.assertEqual(match.personasset.words[0], words[0])
        self.assertRaises(AttributeError, lambda: match.personasset.another)


if __name__ == "__main__":
    unittest.main()

########NEW FILE########
__FILENAME__ = test_quepyapp
#!/usr/bin/env python
# coding: utf-8

# Copyright (c) 2012, Machinalis S.R.L.
# This file is part of quepy and is distributed under the Modified BSD License.
# You should have received a copy of license in the LICENSE file.
#
# Authors: Rafael Carrascosa <rcarrascosa@machinalis.com>
#          Gonzalo Garcia Berrotaran <ggarcia@machinalis.com>

"""
Tests for QuepyApp.
"""

import unittest

import quepy


class TestQuepyApp(unittest.TestCase):

    def setUp(self):
        self.app = quepy.install("testapp")

    def test_get_query_types(self):
        question = "What is this?"
        target, query, userdata = self.app.get_query(question)

        self.assertIsInstance(target, unicode)
        self.assertIsInstance(query, unicode)

    def test_get_user_data(self):
        question = "user data"
        target, query, userdata = self.app.get_query(question)
        self.assertEqual(userdata, "<user data>")

    def test_priority(self):
        question = "something something"
        target, query, userdata = self.app.get_query(question)
        self.assertEqual(userdata, 42)

    def test_config_is_saved(self):
        from quepy import settings
        self.assertIn("testapp", settings.SPARQL_PREAMBLE)


if __name__ == "__main__":
    unittest.main()

########NEW FILE########
__FILENAME__ = test_sparql_generation
# -*- coding: utf-8 -*-

# Copyright (c) 2012, Machinalis S.R.L.
# This file is part of quepy and is distributed under the Modified BSD License.
# You should have received a copy of license in the LICENSE file.
#
# Authors: Rafael Carrascosa <rcarrascosa@machinalis.com>
#          Gonzalo Garcia Berrotaran <ggarcia@machinalis.com>

import re
import unittest
from random_expression import random_expression
from random import seed
from quepy.sparql_generation import expression_to_sparql
from quepy.dsl import FixedRelation, FixedType, \
    FixedDataRelation


def gen_datarel(rel, data):
    class X(FixedDataRelation):
        relation = rel
    return X(data)


def gen_fixedtype(type_):
    class X(FixedType):
        fixedtype = type_
    return X()


def gen_fixedrelation(rel, e):
    class X(FixedRelation):
        relation = rel
    return X(e)


class TestSparqlGeneration(unittest.TestCase):

    _sparql_line = re.compile("\?x\d+ \S+ (?:\?x\d+|\".*\"|\S+?:\S+?)"
                              "(?:@\w+)?.", re.DOTALL)
    _sparql_query_start = re.compile("SELECT DISTINCT .+ WHERE {(.+)}",
                                     re.DOTALL)

    def _standard_check(self, s, e):
        self.assertIsInstance(s, unicode)
        vs = [u"x{}".format(i) for i in xrange(len(e))]
        for var in vs:
            self.assertIn(var, s)

    def _sparql_check(self, s):
        m = self._sparql_query_start.search(s)
        self.assertNotEqual(m, None, "Could not find query start ")
        lines = m.group(1).split("\n")
        for line in lines:
            line = line.strip()
            if line:
                s = "Line out of format: {!r}\n".format(line)
                self.assertNotEqual(self._sparql_line.match(line), None, s)

    def test_sparql_takes_unicode(self):
        e = gen_fixedtype(u"·̣─@łæßð~¶½")
        e += gen_datarel(u"tµŧurułej€", u"←ðßðæßđæßæđßŋŋæ @~~·ŋŋ·¶·ŋ“¶¬@@")
        _, s = expression_to_sparql(e)
        self._standard_check(s, e)
        self._sparql_check(s)

    @unittest.skip("should be fixed")
    def test_sparql_ascii_stress(self):
        seed("sacala dunga dunga dunga")
        for _ in xrange(100):
            expression = random_expression(only_ascii=True)
            _, s = expression_to_sparql(expression)
            self._standard_check(s, expression)
            self._sparql_check(s)

    def test_sparql_stress(self):
        seed("sacala dunga dunga dunga")
        for _ in xrange(100):
            expression = random_expression()
            try:
                _, s = expression_to_sparql(expression)
            except ValueError as error:
                if "Unable to generate sparql" in str(error):
                    continue

            self._standard_check(s, expression)
            self._sparql_check(s)

    def test_sparql_takes_fails_ascii1(self):
        e = gen_fixedtype("a")
        e += gen_datarel("b", "c")
        e = gen_fixedrelation("d", e)
        self.assertRaises(ValueError, expression_to_sparql, e)

    def test_sparql_takes_fails_ascii2(self):
        e = gen_fixedtype("·̣─@łæßð~¶½")
        e += gen_datarel("tµŧurułej€", "←ðßðæßđæßæđßŋŋæ @~~·ŋŋ·¶·ŋ“¶¬@@")
        self.assertRaises(ValueError, expression_to_sparql, e)


if __name__ == "__main__":
    unittest.main()

########NEW FILE########
__FILENAME__ = test_tagger
#!/usr/bin/env python
# coding: utf-8

# Copyright (c) 2012, Machinalis S.R.L.
# This file is part of quepy and is distributed under the Modified BSD License.
# You should have received a copy of license in the LICENSE file.
#
# Authors: Rafael Carrascosa <rcarrascosa@machinalis.com>
#          Gonzalo Garcia Berrotaran <ggarcia@machinalis.com>

"""
Tests for tagger.
"""

import unittest
from quepy import tagger


class TestTagger(unittest.TestCase):
    def test_tagset_unicode(self):
        for tag in tagger.PENN_TAGSET:
            self.assertIsInstance(tag, unicode)

    def test_word_encoding(self):
        word = tagger.Word(token=u"æßđħłłþłłł@æµß",
                           lemma=u"ŧłþłßæ#¶ŋħ~#~@",
                           pos=u"øĸŋøħþ€ĸłþ€øæ«»¢")

        self.assertIsInstance(word.token, unicode)
        self.assertEqual(word.token, u"æßđħłłþłłł@æµß")
        self.assertIsInstance(word.lemma, unicode)
        self.assertEqual(word.lemma, u"ŧłþłßæ#¶ŋħ~#~@")
        self.assertIsInstance(word.pos, unicode)
        self.assertEqual(word.pos, u"øĸŋøħþ€ĸłþ€øæ«»¢")

    def test_word_wrong_encoding(self):
        # Token not unicode
        self.assertRaises(ValueError, tagger.Word, "æßđħłłþłłł@æµß",
                          u"ŧłþłßæ#¶ŋħ~#~@", u"øĸŋøħþ€ĸłþ€øæ«»¢")
        # Lemma not unicode
        self.assertRaises(ValueError, tagger.Word, u"æßđħłłþłłł@æµß",
                          "ŧłþłßæ#¶ŋħ~#~@", u"øĸŋøħþ€ĸłþ€øæ«»¢")
        # Pos not unicode
        self.assertRaises(ValueError, tagger.Word, u"æßđħłłþłłł@æµß",
                          u"ŧłþłßæ#¶ŋħ~#~@", "øĸŋøħþ€ĸłþ€øæ«»¢")

    def test_word_attrib_set(self):
        word = tagger.Word(u"æßđħłłþłłł@æµß")
        word.lemma = u"ŧłþłßæ#¶ŋħ~#~@"
        word.pos = u"øĸŋøħþ€ĸłþ€øæ«»¢"

        self.assertIsInstance(word.token, unicode)
        self.assertEqual(word.token, u"æßđħłłþłłł@æµß")
        self.assertIsInstance(word.lemma, unicode)
        self.assertEqual(word.lemma, u"ŧłþłßæ#¶ŋħ~#~@")
        self.assertIsInstance(word.pos, unicode)
        self.assertEqual(word.pos, u"øĸŋøħþ€ĸłþ€øæ«»¢")

    def test_word_wrong_attrib_set(self):
        word = tagger.Word(u"æßđħłłþłłł@æµß")

        # Token not unicode
        self.assertRaises(ValueError, setattr, word, "token", "æßđħłłþłłł@æµß")
        # Lemma not unicode
        self.assertRaises(ValueError, setattr, word, "lemma", "ŧłþłßæ#¶ŋħ~#~@")
        # Pos not unicode
        self.assertRaises(ValueError, setattr, word, "pos", "øĸŋøħþ€ĸłþ€øæ«»¢")

########NEW FILE########
