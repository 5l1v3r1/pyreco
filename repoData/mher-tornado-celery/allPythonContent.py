__FILENAME__ = conf
# -*- coding: utf-8 -*-
#
# tornado-celery documentation build configuration file, created by
# sphinx-quickstart on Sun Apr 20 15:41:22 2014.
#
# This file is execfile()d with the current directory set to its
# containing dir.
#
# Note that not all possible configuration values are present in this
# autogenerated file.
#
# All configuration values have a default; values that are commented out
# serve to show the default.

import os
import sys

sys.path.insert(0, os.path.abspath('..'))
import tcelery

# If extensions (or modules to document with autodoc) are in another directory,
# add these directories to sys.path here. If the directory is relative to the
# documentation root, use os.path.abspath to make it absolute, like shown here.
#sys.path.insert(0, os.path.abspath('.'))

# -- General configuration ------------------------------------------------

# If your documentation needs a minimal Sphinx version, state it here.
#needs_sphinx = '1.0'

# Add any Sphinx extension module names here, as strings. They can be
# extensions coming with Sphinx (named 'sphinx.ext.*') or your custom
# ones.
extensions = [
    'sphinx.ext.intersphinx',
    'sphinxcontrib.fulltoc',
    'sphinxcontrib.httpdomain',
    'sphinxcontrib.autohttp.tornado',
]

# Add any paths that contain templates here, relative to this directory.
templates_path = ['_templates']

# The suffix of source filenames.
source_suffix = '.rst'

# The encoding of source files.
#source_encoding = 'utf-8-sig'

# The master toctree document.
master_doc = 'index'

# General information about the project.
project = u'tornado-celery'
copyright = u'2014, Mher Movsisyan'

# The version info for the project you're documenting, acts as replacement for
# |version| and |release|, also used in various other places throughout the
# built documents.
#
# The short X.Y version.
version = '.'.join(map(str, tcelery.VERSION[0:2]))
# The full version, including alpha/beta/rc tags.
release = tcelery.__version__.rstrip('-dev')

# The language for content autogenerated by Sphinx. Refer to documentation
# for a list of supported languages.
#language = None

# There are two options for replacing |today|: either, you set today to some
# non-false value, then it is used:
#today = ''
# Else, today_fmt is used as the format for a strftime call.
#today_fmt = '%B %d, %Y'

# List of patterns, relative to source directory, that match files and
# directories to ignore when looking for source files.
exclude_patterns = ['_build']

# The reST default role (used for this markup: `text`) to use for all
# documents.
#default_role = None

# If true, '()' will be appended to :func: etc. cross-reference text.
#add_function_parentheses = True

# If true, the current module name will be prepended to all description
# unit titles (such as .. function::).
#add_module_names = True

# If true, sectionauthor and moduleauthor directives will be shown in the
# output. They are ignored by default.
#show_authors = False

# The name of the Pygments (syntax highlighting) style to use.
pygments_style = 'sphinx'

# A list of ignored prefixes for module index sorting.
#modindex_common_prefix = []

# If true, keep warnings as "system message" paragraphs in the built documents.
#keep_warnings = False


# -- Options for HTML output ----------------------------------------------

# The theme to use for HTML and HTML Help pages.  See the documentation for
# a list of builtin themes.
html_theme = 'celery'
html_theme_path = ['_theme']

# Theme options are theme-specific and customize the look and feel of a theme
# further.  For a list of options available for each theme, see the
# documentation.
#html_theme_options = {}

# Add any paths that contain custom themes here, relative to this directory.
#html_theme_path = []

# The name for this set of Sphinx documents.  If None, it defaults to
# "<project> v<release> documentation".
#html_title = None

# A shorter title for the navigation bar.  Default is the same as html_title.
#html_short_title = None

# The name of an image file (relative to this directory) to place at the top
# of the sidebar.
#html_logo = None

# The name of an image file (within the static path) to use as favicon of the
# docs.  This file should be a Windows icon file (.ico) being 16x16 or 32x32
# pixels large.
#html_favicon = None

# Add any paths that contain custom static files (such as style sheets) here,
# relative to this directory. They are copied after the builtin static files,
# so a file named "default.css" will overwrite the builtin "default.css".
html_static_path = ['_static']

# Add any extra paths that contain custom files (such as robots.txt or
# .htaccess) here, relative to this directory. These files are copied
# directly to the root of the documentation.
#html_extra_path = []

# If not '', a 'Last updated on:' timestamp is inserted at every page bottom,
# using the given strftime format.
#html_last_updated_fmt = '%b %d, %Y'

# If true, SmartyPants will be used to convert quotes and dashes to
# typographically correct entities.
#html_use_smartypants = True

# Custom sidebar templates, maps document names to template names.
html_sidebars = {
    'index':    ['sidebarintro.html', 'sourcelink.html', 'searchbox.html'],
    '**':       ['sidebarlogo.html', 'localtoc.html', 'relations.html',
                 'sourcelink.html', 'searchbox.html']
}

# Additional templates that should be rendered to pages, maps page names to
# template names.
#html_additional_pages = {}

# If false, no module index is generated.
#html_domain_indices = True

# If false, no index is generated.
#html_use_index = True

# If true, the index is split into individual pages for each letter.
#html_split_index = False

# If true, links to the reST sources are added to the pages.
#html_show_sourcelink = True

# If true, "Created using Sphinx" is shown in the HTML footer. Default is True.
html_show_sphinx = False

# If true, "(C) Copyright ..." is shown in the HTML footer. Default is True.
#html_show_copyright = True

# If true, an OpenSearch description file will be output, and all pages will
# contain a <link> tag referring to it.  The value of this option must be the
# base URL from which the finished HTML is served.
#html_use_opensearch = ''

# This is the file name suffix for HTML files (e.g. ".xhtml").
#html_file_suffix = None

# Output file base name for HTML help builder.
htmlhelp_basename = 'tornado-celerydoc'


# -- Options for LaTeX output ---------------------------------------------

latex_elements = {
# The paper size ('letterpaper' or 'a4paper').
#'papersize': 'letterpaper',

# The font size ('10pt', '11pt' or '12pt').
#'pointsize': '10pt',

# Additional stuff for the LaTeX preamble.
#'preamble': '',
}

# Grouping the document tree into LaTeX files. List of tuples
# (source start file, target name, title,
#  author, documentclass [howto, manual, or own class]).
latex_documents = [
  ('index', 'tornado-celery.tex', u'tornado-celery Documentation',
   u'Mher Movsisyan', 'manual'),
]

# The name of an image file (relative to this directory) to place at the top of
# the title page.
#latex_logo = None

# For "manual" documents, if this is true, then toplevel headings are parts,
# not chapters.
#latex_use_parts = False

# If true, show page references after internal links.
#latex_show_pagerefs = False

# If true, show URL addresses after external links.
#latex_show_urls = False

# Documents to append as an appendix to all manuals.
#latex_appendices = []

# If false, no module index is generated.
#latex_domain_indices = True


# -- Options for manual page output ---------------------------------------

# One entry per manual page. List of tuples
# (source start file, name, description, authors, manual section).
man_pages = [
    ('index', 'tornado-celery', u'tornado-celery Documentation',
     [u'Mher Movsisyan'], 1)
]

# If true, show URL addresses after external links.
#man_show_urls = False


# -- Options for Texinfo output -------------------------------------------

# Grouping the document tree into Texinfo files. List of tuples
# (source start file, target name, title, author,
#  dir menu entry, description, category)
texinfo_documents = [
  ('index', 'tornado-celery', u'tornado-celery Documentation',
   u'Mher Movsisyan', 'tornado-celery', 'One line description of project.',
   'Miscellaneous'),
]

# Documents to append as an appendix to all manuals.
#texinfo_appendices = []

# If false, no module index is generated.
#texinfo_domain_indices = True

# How to display URL addresses: 'footnote', 'no', or 'inline'.
#texinfo_show_urls = 'footnote'

# If true, do not generate a @detailmenu in the "Top" node's menu.
#texinfo_no_detailmenu = False

########NEW FILE########
__FILENAME__ = tasks
import time
from datetime import datetime

from celery import Celery

celery = Celery("tasks", broker="amqp://guest:guest@localhost:5672")
celery.conf.CELERY_RESULT_BACKEND = "amqp"


@celery.task
def add(x, y):
    return int(x) + int(y)


@celery.task
def sleep(seconds):
    time.sleep(float(seconds))
    return seconds


@celery.task
def echo(msg, timestamp=False):
    return "%s: %s" % (datetime.now(), msg) if timestamp else msg


@celery.task
def error(msg):
    raise Exception(msg)


if __name__ == "__main__":
    celery.start()

########NEW FILE########
__FILENAME__ = tornado_async
from tornado import gen
from tornado import ioloop
from tornado.web import asynchronous, RequestHandler, Application

import tasks

import tcelery
tcelery.setup_nonblocking_producer()


class AsyncHandler(RequestHandler):
    @asynchronous
    def get(self):
        tasks.sleep.apply_async(args=[3], callback=self.on_result)

    def on_result(self, response):
        self.write(str(response.result))
        self.finish()


class GenAsyncHandler(RequestHandler):
    @asynchronous
    @gen.coroutine
    def get(self):
        response = yield gen.Task(tasks.sleep.apply_async, args=[3])
        self.write(str(response.result))
        self.finish()


class GenMultipleAsyncHandler(RequestHandler):
    @asynchronous
    @gen.coroutine
    def get(self):
        r1, r2 = yield [gen.Task(tasks.sleep.apply_async, args=[2]),
                        gen.Task(tasks.add.apply_async, args=[1, 2])]
        self.write(str(r1.result))
        self.write(str(r2.result))
        self.finish()


application = Application([
    (r"/async-sleep", AsyncHandler),
    (r"/gen-async-sleep", GenAsyncHandler),
    (r"/gen-async-sleep-add", GenMultipleAsyncHandler),
])


if __name__ == "__main__":
    application.listen(8887)
    ioloop.IOLoop.instance().start()

########NEW FILE########
__FILENAME__ = tornado_ioloop
import tasks
import tcelery

from tornado import ioloop


def handle_result(result):
    print(result.result)
    ioloop.IOLoop.instance().stop()


def call_task():
    tasks.add.apply_async(args=[1, 2], callback=handle_result)


tcelery.setup_nonblocking_producer(on_ready=call_task)
ioloop.IOLoop.instance().start()

########NEW FILE########
__FILENAME__ = pavement
import sys
from paver.easy import *
from paver import doctools
from paver.setuputils import setup

PYCOMPILE_CACHES = ['*.pyc', '*$py.class']

options(
    sphinx=Bunch(builddir='.build'),
)


def sphinx_builddir(options):
    return path('docs') / options.sphinx.builddir / 'html'


@task
def clean_docs(options):
    sphinx_builddir(options).rmtree()


@task
@needs('clean_docs', 'paver.doctools.html')
def html(options):
    destdir = path('Documentation')
    destdir.rmtree()
    builtdocs = sphinx_builddir(options)
    builtdocs.move(destdir)


@task
@needs('paver.doctools.html')
def qhtml(options):
    destdir = path('Documentation')
    builtdocs = sphinx_builddir(options)
    sh('rsync -az {0}/ {1}'.format(builtdocs, destdir))


@task
@needs('clean_docs', 'paver.doctools.html')
def ghdocs(options):
    builtdocs = sphinx_builddir(options)
    sh("git checkout gh-pages && \
            cp -r {0}/* .    && \
            git commit . -m 'Rendered documentation for Github Pages.' && \
            git push origin gh-pages && \
            git checkout master".format(builtdocs))


@task
@needs('clean_docs', 'paver.doctools.html')
def upload_pypi_docs(options):
    builtdocs = path('docs') / options.builddir / 'html'
    sh("{0} setup.py upload_sphinx --upload-dir='{1}'".format(
        sys.executable, builtdocs))


@task
@needs('upload_pypi_docs', 'ghdocs')
def upload_docs(options):
    pass


@task
def autodoc(options):
    sh('extra/release/doc4allmods tcelery')


@task
def verifyindex(options):
    sh('extra/release/verify-reference-index.sh')


@task
def verifyconfigref(options):
    sh('PYTHONPATH=. {0} extra/release/verify_config_reference.py \
            docs/configuration.rst'.format(sys.executable))


@task
@cmdopts([
    ('noerror', 'E', 'Ignore errors'),
])
def flake8(options):
    noerror = getattr(options, 'noerror', False)
    complexity = getattr(options, 'complexity', 22)
    sh("""flake8 tcelery | perl -mstrict -mwarnings -nle'
        my $ignore = m/too complex \((\d+)\)/ && $1 le {0};
        if (! $ignore) {{ print STDERR; our $FOUND_FLAKE = 1 }}
    }}{{exit $FOUND_FLAKE;
        '""".format(complexity), ignore_error=noerror)


@task
@cmdopts([
    ('noerror', 'E', 'Ignore errors'),
])
def flakeplus(options):
    noerror = getattr(options, 'noerror', False)
    sh('flakeplus tcelery', ignore_error=noerror)


@task
@cmdopts([
    ('noerror', 'E', 'Ignore errors')
])
def flakes(options):
    flake8(options)
    flakeplus(options)


@task
def clean_readme(options):
    path('README').unlink()
    path('README.rst').unlink()


@task
@needs('clean_readme')
def readme(options):
    sh('{0} extra/release/sphinx-to-rst.py docs/templates/readme.txt \
            > README.rst'.format(sys.executable))


@task
def bump(options):
    sh("extra/release/bump_version.py tcelery/__init__.py")


@task
@cmdopts([
    ('coverage', 'c', 'Enable coverage'),
    ('verbose', 'V', 'Make more noise'),
])
def test(options):
    cmd = 'nosetests'
    if getattr(options, 'coverage', False):
        cmd += ' --with-coverage3'
    if getattr(options, 'verbose', False):
        cmd += ' --verbosity=2'
    sh(cmd)


@task
@cmdopts([
    ('noerror', 'E', 'Ignore errors'),
])
def pep8(options):
    noerror = getattr(options, 'noerror', False)
    return sh("""find . -name "*.py" | xargs pep8 | perl -nle'\
            print; $a=1 if $_}{exit($a)'""", ignore_error=noerror)


@task
def removepyc(options):
    sh('find . -type f -a \\( {0} \\) | xargs rm'.format(
        ' -o '.join("-name '{0}'".format(pat) for pat in PYCOMPILE_CACHES)))


@task
@needs('removepyc')
def gitclean(options):
    sh('git clean -xdn')


@task
@needs('removepyc')
def gitcleanforce(options):
    sh('git clean -xdf')


@task
@needs('flakes', 'autodoc', 'verifyindex',
       'verifyconfigref', 'test', 'gitclean')
def releaseok(options):
    pass


@task
@needs('releaseok', 'removepyc', 'upload_docs')
def release(options):
    pass


@task
def verify_authors(options):
    sh('git shortlog -se | cut -f2 | extra/release/attribution.py')

########NEW FILE########
__FILENAME__ = app
from __future__ import absolute_import

import celery

from tornado import web
from tornado.options import define, options

from . import handlers as _ # noqa
from .utils import route


define("debug", type=bool, default=False, help="run in debug mode")


class Application(web.Application):
    def __init__(self, celery_app=None):
        handlers = route.get_routes()
        settings = dict(debug=options.debug)
        super(Application, self).__init__(handlers, **settings)
        self.celery_app = celery_app or celery.Celery()

########NEW FILE########
__FILENAME__ = connection
from __future__ import absolute_import

try:
    from urlparse import urlparse
except ImportError: # py3k
    from urllib.parse import urlparse
from functools import partial
from itertools import cycle
from datetime import timedelta

import pika
import logging

from pika.adapters.tornado_connection import TornadoConnection
from pika.exceptions import AMQPConnectionError

from tornado import ioloop


class Connection(object):

    content_type = 'application/x-python-serialize'

    def __init__(self, io_loop=None):
        self.channel = None
        self.connection = None
        self.url = None
        self.io_loop = io_loop or ioloop.IOLoop.instance()

    def connect(self, url=None, options=None, callback=None):
        if url is not None:
            self.url = url
        purl = urlparse(self.url)
        credentials = pika.PlainCredentials(purl.username, purl.password)
        virtual_host = purl.path[1:]
        host = purl.hostname
        port = purl.port

        options = options or {}
        options = dict([(k.lstrip('DEFAULT_').lower(), v) for k, v in options.items()])
        options.update(host=host, port=port, virtual_host=virtual_host,
                       credentials=credentials)

        params = pika.ConnectionParameters(**options)
        try:
            TornadoConnection(params, stop_ioloop_on_close=False,
                              on_open_callback=partial(self.on_connect, callback),
                              custom_ioloop=self.io_loop)
        except AMQPConnectionError:
            logging.info('Retrying to connect in 2 seconds')
            self.io_loop.add_timeout(
                    timedelta(seconds=2),
                    partial(self.connect, url=url,
                            options=options, callback=callback))

    def on_connect(self, callback, connection):
        self.connection = connection
        self.connection.add_on_close_callback(self.on_closed)
        self.connection.channel(partial(self.on_channel_open, callback))

    def on_channel_open(self, callback, channel):
        self.channel = channel
        if callback:
            callback()

    def on_exchange_declare(self, frame):
        pass

    def on_basic_cancel(self, frame):
        self.connection.close()

    def on_closed(self, connection, reply_code, reply_text):
        """This method is invoked by pika when the connection to RabbitMQ is
        closed unexpectedly. Since it is unexpected, we will reconnect to
        RabbitMQ if it disconnects.

        :param pika.connection.Connection connection: The closed connection obj
        :param int reply_code: The server provided reply_code if given
        :param str reply_text: The server provided reply_text if given

        """
        self._channel = None
        logging.warning('Connection closed, reopening in 5 seconds: (%s) %s',
                        reply_code, reply_text)
        connection.add_timeout(5, self.connect)

    def publish(self, body, exchange=None, routing_key=None,
                mandatory=False, immediate=False, content_type=None,
                content_encoding=None, serializer=None,
                headers=None, compression=None, retry=False,
                retry_policy=None, declare=[], **properties):
        assert self.channel
        content_type = content_type or self.content_type

        properties = pika.BasicProperties(content_type=content_type)

        self.channel.basic_publish(exchange=exchange, routing_key=routing_key, body=body,
                                   properties=properties, mandatory=mandatory,
                                   immediate=immediate)

    def consume(self, queue, callback, x_expires=None):
        assert self.channel
        self.channel.queue_declare(self.on_queue_declared, queue=queue,
                                   exclusive=False, auto_delete=True,
                                   nowait=True, durable=True,
                                   arguments={'x-expires': x_expires})
        self.channel.basic_consume(callback, queue, no_ack=True)

    def on_queue_declared(self, *args, **kwargs):
        pass


class ConnectionPool(object):
    def __init__(self, limit, io_loop=None):
        self._limit = limit
        self._connections = []
        self._connection = None
        self.io_loop = io_loop

    def connect(self, broker_url, options=None, callback=None):
        self._on_ready = callback
        for _ in range(self._limit):
            conn = Connection(io_loop=self.io_loop)
            conn.connect(broker_url, options=options,
                         callback=partial(self._on_connect, conn))

    def _on_connect(self, connection):
        self._connections.append(connection)
        if len(self._connections) == self._limit:
            self._connection = cycle(self._connections)
            if self._on_ready:
                self._on_ready()

    def connection(self):
        assert self._connection is not None
        return next(self._connection)

########NEW FILE########
__FILENAME__ = handlers
from __future__ import absolute_import
from __future__ import with_statement

from datetime import timedelta
from functools import partial

from tornado import web
from tornado import ioloop
from tornado.escape import json_decode

from celery.result import AsyncResult
from celery.task.control import revoke
from celery.utils import uuid

from .utils import route


class ApplyHandlerBase(web.RequestHandler):
    def get_task_args(self):
        "extracts task args from a request"
        try:
            options = json_decode(self.request.body)
        except (TypeError, ValueError):
            raise web.HTTPError(400)
        args = options.pop('args', [])
        kwargs = options.pop('kwargs', {})
        if not isinstance(args, (list, tuple)):
            raise web.HTTPError(400, 'task args must be a list or tuple')

        return args, kwargs, options


@route('/apply-async/(.*)/')
class ApplyAsyncHandler(ApplyHandlerBase):
    def post(self, taskname):
        """
Apply tasks asynchronously by sending a message

**Example request**:

.. sourcecode:: http

    POST /apply-async/examples.tasks.add/ HTTP/1.1
    Accept: application/json
    Accept-Encoding: gzip, deflate, compress
    Content-Length: 16
    Content-Type: application/json; charset=utf-8
    Host: localhost:8888
    User-Agent: HTTPie/0.8.0

    {
        "args": [
            1,
            2
        ]
    }


**Example response**:

.. sourcecode:: http

    HTTP/1.1 200 OK
    Content-Length: 71
    Content-Type: application/json; charset=UTF-8
    Server: TornadoServer/3.2

    {
        "state": "PENDING",
        "task-id": "1c9be31f-3094-4319-8895-ad2f0654c699"
    }

:statuscode 200: no error
:statuscode 400: invalid request
:statuscode 404: unknown task
        """
        try:
            task = self.application.celery_app.tasks[taskname]
        except KeyError:
            raise web.HTTPError(404, "Unknown task '%s'" % taskname)

        args, kwargs, options = self.get_task_args()
        result = task.apply_async(args=args, kwargs=kwargs, **options)
        self.write({'task-id': result.task_id, 'state': result.state})

@route('/tasks/result/(.*)/')
class TaskResultHandler(web.RequestHandler):
    def get(self, task_id):
        """
Get task result by task-id

**Example request**:

.. sourcecode:: http

    GET /tasks/result/9ec42ba0-be59-488f-a445-4a007d83b954/ HTTP/1.1
    Accept: application/json
    Accept-Encoding: gzip, deflate, compress
    Content-Type: application/json; charset=utf-8
    Host: localhost:8888
    User-Agent: HTTPie/0.8.0

**Example response**:

.. sourcecode:: http

    HTTP/1.1 200 OK
    Content-Length: 84
    Content-Type: application/json; charset=UTF-8
    Etag: "0aef8448588cf040f1daa7a0244c0a7b93abfd71"
    Server: TornadoServer/3.2

    {
        "result": 3,
        "state": "SUCCESS",
        "task-id": "9ec42ba0-be59-488f-a445-4a007d83b954"
    }

:statuscode 200: no error
:statuscode 400: invalid request
        """
        result = AsyncResult(task_id, app=self.application.celery_app)
        response = {'task-id': task_id, 'state': result.state}
        if result.ready():
            if result.successful():
                response['result'] = result.result
            else:
                response['traceback'] = result.traceback
                response['error'] = result.result
        self.write(response)


@route('/tasks/revoke/(.*)/')
class TaskRevokeHandler(web.RequestHandler):
    def delete(self, task_id):
        """
Revoke a task

**Example request**:

.. sourcecode:: http

    DELETE /tasks/revoke/d776e835-33ac-447f-b27d-bb8529718ae6/ HTTP/1.1
    Accept: application/json
    Accept-Encoding: gzip, deflate, compress
    Content-Length: 0
    Content-Type: application/json; charset=utf-8
    Host: localhost:8888
    User-Agent: HTTPie/0.8.0

**Example response**:

.. sourcecode:: http

    HTTP/1.1 200 OK
    Content-Length: 51
    Content-Type: application/json; charset=UTF-8
    Server: TornadoServer/3.2

    {
        "task-id": "d776e835-33ac-447f-b27d-bb8529718ae6"
    }

:statuscode 200: no error
:statuscode 400: invalid request
        """
        revoke(task_id)
        self.write({'task-id': task_id})


@route('/apply/(.*)/')
class ApplyHandler(ApplyHandlerBase):
    @web.asynchronous
    def post(self, taskname):
        """
Apply tasks synchronously. Function returns when the task is finished

**Example request**:

.. sourcecode:: http

    POST /apply/examples.tasks.add/ HTTP/1.1
    Accept: application/json
    Accept-Encoding: gzip, deflate, compress
    Content-Length: 16
    Content-Type: application/json; charset=utf-8
    Host: localhost:8888
    User-Agent: HTTPie/0.8.0

    {
        "args": [
            1,
            2
        ]
    }

**Example response**:

.. sourcecode:: http

    HTTP/1.1 200 OK
    Content-Length: 84
    Content-Type: application/json; charset=UTF-8
    Server: TornadoServer/3.2

    {
        "result": 3,
        "state": "SUCCESS",
        "task-id": "2ce70595-a028-4e0d-b906-be2183fc6821"
    }

:statuscode 200: no error
:statuscode 400: invalid request
:statuscode 404: unknown task
        """
        try:
            task = self.application.celery_app.tasks[taskname]
        except KeyError:
            raise web.HTTPError(404, "Unknown task '%s'" % taskname)

        args, kwargs, options = self.get_task_args()
        timeout = options.pop('timeout', None)
        task_id = uuid()

        htimeout = None
        if timeout:
            htimeout = ioloop.IOLoop.instance().add_timeout(
                    timedelta(seconds=timeout),
                    partial(self.on_time, task_id))

        task.apply_async(args=args, kwargs=kwargs, task_id=task_id,
                         callback=partial(self.on_complete, htimeout),
                         **options)

    def on_complete(self, htimeout, result):
        if self._finished:
            return
        if htimeout:
            ioloop.IOLoop.instance().remove_timeout(htimeout)
        response = {'task-id': result.task_id, 'state': result.state}
        if result.successful():
            response['result'] = result.result
        else:
            response['traceback'] = result.traceback
            response['error'] = result.result
        self.write(response)
        self.finish()

    def on_time(self, task_id):
        revoke(task_id)
        result = AsyncResult(task_id, app=self.application.celery_app)
        self.write({'task-id': task_id, 'state': result.state})
        self.finish()


@route('/')
class MainHandler(web.RequestHandler):
    def get(self):
        self.write("Tasks: ")
        self.write(', '.join(filter(lambda x: not x.startswith('celery'),
                             self.application.celery_app.tasks.keys())))

########NEW FILE########
__FILENAME__ = producer
from __future__ import absolute_import

import sys

from functools import partial
from datetime import timedelta

from kombu import serialization

from celery.app.amqp import TaskProducer
from celery.backends.amqp import AMQPBackend
from celery.utils import timeutils

from .result import AsyncResult

is_py3k = sys.version_info >= (3, 0)


class NonBlockingTaskProducer(TaskProducer):

    conn_pool = None
    app = None
    result_cls = AsyncResult

    def __init__(self, channel=None, *args, **kwargs):
        super(NonBlockingTaskProducer, self).__init__(
                channel, *args, **kwargs)

    def publish(self, body, routing_key=None, delivery_mode=None,
                mandatory=False, immediate=False, priority=0,
                content_type=None, content_encoding=None, serializer=None,
                headers=None, compression=None, exchange=None, retry=False,
                retry_policy=None, declare=[], **properties):
        headers = {} if headers is None else headers
        retry_policy = {} if retry_policy is None else retry_policy
        routing_key = self.routing_key if routing_key is None else routing_key
        compression = self.compression if compression is None else compression
        exchange = exchange or self.exchange

        callback = properties.pop('callback', None)
        task_id = body['id']

        if callback and not callable(callback):
            raise ValueError('callback should be callable')
        if callback and not isinstance(self.app.backend, AMQPBackend):
            raise NotImplementedError(
                    'callback can be used only with AMQP backend')

        body, content_type, content_encoding = self._prepare(
            body, serializer, content_type, content_encoding,
            compression, headers)

        self.serializer = self.app.backend.serializer

        serialization.registry.enable(serializer)

        (self.content_type,
         self.content_encoding,
         self.encoder) = serialization.registry._encoders[self.serializer]

        conn = self.conn_pool.connection()
        publish = conn.publish
        result = publish(body, priority=priority, content_type=content_type,
                         content_encoding=content_encoding, headers=headers,
                         properties=properties, routing_key=routing_key,
                         mandatory=mandatory, immediate=immediate,
                         exchange=exchange, declare=declare)

        if callback:
            conn.consume(task_id.replace('-', ''),
                         partial(self.on_result, callback),
                         x_expires=self.prepare_expires(type=int))
        return result

    def decode(self, payload):
        payload = is_py3k and payload or str(payload)
        return serialization.decode(payload,
                                    content_type=self.content_type,
                                    content_encoding=self.content_encoding)

    def on_result(self, callback, method, channel, deliver, reply):
        reply = self.decode(reply)
        callback(self.result_cls(**reply))

    def prepare_expires(self, value=None, type=None):
        if value is None:
            value = self.app.conf.CELERY_TASK_RESULT_EXPIRES
        if isinstance(value, timedelta):
            value = timeutils.timedelta_seconds(value)
        if value is not None and type:
            return type(value * 1000)
        return value

    def __repr__(self):
        return '<NonBlockingTaskProducer: {0.channel}>'.format(self)

########NEW FILE########
__FILENAME__ = result
from __future__ import absolute_import
from __future__ import with_statement

import celery


class AsyncResult(celery.result.AsyncResult):
    def __init__(self, task_id, status=None, traceback=None, result=None,
                 **kwargs):
        super(AsyncResult, self).__init__(task_id)
        self._status = status
        self._traceback = traceback
        self._result = result

    @property
    def status(self):
        return self._status or super(AsyncResult, self).status
    state = status

    @property
    def traceback(self):
        if self._result is not None:
            return self._traceback
        else:
            return super(AsyncResult, self).traceback

    @property
    def result(self):
        return self._result or super(AsyncResult, self).result

########NEW FILE########
__FILENAME__ = utils
class route(object):
    """route decorator from https://github.com/peterbe/tornado-utils"""
    _routes = []

    def __init__(self, regexp):
        self._regexp = regexp

    def __call__(self, handler):
        """gets called when we class decorate"""
        self._routes.append((self._regexp, handler))
        return handler

    @classmethod
    def get_routes(cls):
        return cls._routes

########NEW FILE########
__FILENAME__ = __main__
from __future__ import absolute_import

import logging

from pprint import pformat

from celery.bin.base import Command

from tornado import ioloop
from tornado import httpserver
from tornado.options import options, define, parse_command_line

from .app import Application
from . import setup_nonblocking_producer
from celery.loaders.base import BaseLoader


define("port", default=8888, type=int, help="run on the given port")
define("address", default='127.0.0.1', type=str, help="the bind address")


class TCeleryCommand(Command):

    def run_from_argv(self, prog_name, argv=None):
        argv = list(filter(self.tornado_option, argv))
        parse_command_line([prog_name] + argv)

        logging.info("Starting http server on port %s..." % options.port)
        http_server = httpserver.HTTPServer(Application(celery_app=self.app))
        http_server.listen(options.port, options.address)

        bloader = BaseLoader(self.app)
        bloader.import_default_modules()

        logging.info("Registered tasks:")
        logging.info(pformat(list(self.app.tasks.keys())))

        logging.info("Setting up non-blocking producer...")
        setup_nonblocking_producer()

        ioloop.IOLoop.instance().start()

    def handle_argv(self, prog_name, argv=None):
        return self.run_from_argv(prog_name, argv)

    @staticmethod
    def tornado_option(arg):
        name, _, value = arg.lstrip('-').partition("=")
        name = name.replace('-', '_')
        return hasattr(options, name)


def main():
    try:
        cmd = TCeleryCommand()
        cmd.execute_from_commandline()
    except KeyboardInterrupt:
        pass


if __name__ == "__main__":
    main()

########NEW FILE########
__FILENAME__ = benchmarks
from __future__ import absolute_import

import sys
import time

from tornado import ioloop

from celery import Celery


celery1 = Celery('tasks', broker='amqp://')
celery2 = Celery('tasks', broker='amqp://')


@celery1.task
def add(x, y):
    return x + y


@celery2.task
def echo(x):
    return x


def bench_apply_async(ntimes):
    time_start = time.time()
    for i in range(ntimes):
        add.apply_async(args=[i, i])
    print("apply_async called {} times in {} seconds".format(
        ntimes, time.time() - time_start))


def bench_apply_async_nonblocking(ntimes, stop_io_loop=False):
    io_loop = ioloop.IOLoop.instance()

    def publish():
        time_start = time.time()
        for i in range(ntimes):
            echo.apply_async(args=[i])
        print("non blocking apply_async called {} times in {} seconds".format(
                ntimes, time.time() - time_start))
        if stop_io_loop:
            io_loop.stop()

    import tcelery
    tcelery.setup_nonblocking_producer(celery_app=celery2,
                                       io_loop=io_loop,
                                       on_ready=publish)
    io_loop.start()


if __name__ == "__main__":
    ntimes = int(sys.argv[1]) if len(sys.argv) > 1 else 100
    method = sys.argv[2] if len(sys.argv) == 3 else None
    try:
        if method:
            vars()[method](ntimes)
        else:
            bench_apply_async(ntimes)
            bench_apply_async_nonblocking(ntimes)
    except KeyboardInterrupt:
        pass

########NEW FILE########
__FILENAME__ = functests
import time
import unittest
import requests

from urlparse import urljoin
from tornado import ioloop, gen
from tornado.escape import json_encode, json_decode

import tasks


class TestCase(unittest.TestCase):
    base_url = "http://localhost:8888"

    def post(self, url, data=None):
        data = json_encode(data or {})
        response = requests.post(urljoin(self.base_url, url), data=data)
        msg = json_decode(response.content) if response.ok else None
        return response, msg

    def get(self, url, data=None):
        data = json_encode(data or {})
        response = requests.get(urljoin(self.base_url, url), data=data)
        return response, json_decode(response.content)


class AsyncTaskTests(TestCase):
    def test_acync_apply(self):
        response, msg = self.post('/apply-async/tasks.echo/',
                                  data={'args': ['foo']})
        self.assertTrue(response.ok)
        task_id = msg['task-id']

        time.sleep(0.25)

        response, msg = self.get('/tasks/result/%s/' % task_id)
        self.assertTrue(response.ok)
        self.assertEqual('SUCCESS', msg['state'])
        self.assertEqual("foo", msg['result'])

    def test_apply_async_with_args(self):
        response, msg = self.post('/apply-async/tasks.add/',
                                  data={'args': [1, 2]})
        self.assertTrue(response.ok)
        task_id = msg['task-id']

        time.sleep(0.25)

        response, msg = self.get('/tasks/result/%s/' % task_id)
        self.assertTrue(response.ok)
        self.assertEqual('SUCCESS', msg['state'])
        self.assertEqual(3, msg['result'])

    def test_apply_async_with_kwargs(self):
        response, msg = self.post('/apply-async/tasks.echo/',
                                  data={'args': ['foo'],
                                        'kwargs': {'timestamp': True}})
        self.assertTrue(response.ok)
        task_id = msg['task-id']

        time.sleep(0.25)

        response, msg = self.get('/tasks/result/%s/' % task_id)
        self.assertTrue(response.ok)
        self.assertEqual('SUCCESS', msg['state'])
        self.assertTrue(msg['result'].endswith('foo'))

    def test_unknown_task(self):
        response, msg = self.post('/apply-async/foo/')
        self.assertFalse(response.ok)

    @unittest.skip('no way to validate invalid task ids')
    def test_unknown_task_status(self):
        response, msg = self.get('/tasks/result/%s/' % 'foo')
        self.assertFalse(response.ok)


class TaskTests(TestCase):
    def test_apply(self):
        response, msg = self.post('/apply/tasks.echo/', data={'args': ['foo']})
        self.assertTrue(response.ok)
        self.assertEqual('foo', msg['result'])

    def test_apply_with_timeout(self):
        response, msg = self.post('/apply/tasks.sleep/',
                                  data={'args': [5], 'timeout': 0.5})
        self.assertTrue(response.ok)
        self.assertFalse('result' in msg)

    def test_apply_with_args(self):
        response, msg = self.post('/apply/tasks.add/', data={'args': [1, 2]})
        self.assertTrue(response.ok)
        self.assertEqual(3, msg['result'])

    def test_unknown_task(self):
        response, msg = self.post('/apply/foo')
        self.assertFalse(response.ok)


class TimingTests(TestCase):
    def test_eta(self):
        response, msg = self.post('/apply/tasks.echo/',
                                  data={'args': ['foo'], 'timeout': 0.5,
                                        'countdown': 5})
        self.assertTrue(response.ok)
        self.assertFalse('result' in msg)

    def test_expires(self):
        response, msg = self.post('/apply/tasks.echo/',
                                  data={'args': ['foo'],
                                        'countdown': 5, 'expires': 1})
        self.assertTrue(response.ok)
        self.assertEqual('REVOKED', msg['state'])
        self.assertFalse('result' in msg)


class TaskClassTests(unittest.TestCase):
    def test_async(self):
        def done(response):
            ioloop.IOLoop.instance().stop()
            self.assertEqual("hello", json_decode(response.body)["result"])
        yield gen.Task(tasks.echo.apply_async, args=['hello'], callback=done)
        ioloop.IOLoop.instance().start()

    def test_async_with_mult_args(self):
        def done(response):
            ioloop.IOLoop.instance().stop()
            self.assertEqual(3, json_decode(response.body)["result"])
        yield gen.Task(tasks.add.apply_async, args=[1, 2], callback=done)
        ioloop.IOLoop.instance().start()

    def test_async_with_kwargs(self):
        def done(response):
            ioloop.IOLoop.instance().stop()
            result = json_decode(response.body)["result"]
            self.assertTrue(result.endswith("hello"))
        yield gen.Task(tasks.echo, args=['hello'], kwargs={'timestamp': True},
                       callback=done)
        ioloop.IOLoop.instance().start()


if __name__ == "__main__":
    unittest.main()

########NEW FILE########
