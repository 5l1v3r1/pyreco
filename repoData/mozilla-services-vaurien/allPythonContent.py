__FILENAME__ = handlers_ext
import os

from vaurien.behaviors import get_behaviors
from vaurien.protocols import get_protocols


_BEHAVIOR = """\

.. _behaviors:

Behaviors
=========

Vaurien provides a collections of behaviors, all of them are listed on this
page.  You can also write your own behaviors if you need. Have a look at
:ref:`extending` to learn more.

"""


_PROTO = """\

.. _protocols:

Protocols
=========

Vaurien provides a collections of protocols, which are all listed on this page.
You can also write your own protocols if you need. Have a look at
:ref:`extending` to learn more.

"""


def generate_behaviors(app):
    return generate_plugins_doc(app, 'behaviors', get_behaviors().items(),
                                _BEHAVIOR)


def generate_protocols(app):
    return generate_plugins_doc(app, 'protocols', get_protocols().items(),
                                _PROTO)


def generate_plugins_doc(app, name, items, tmpl):
    ext = app.config['source_suffix']
    filename = os.path.join(app.srcdir, "%s%s" % (name, ext))
    items.sort()
    tmpl = ('.. do not edit: this file is generated automatically'.upper()
            + tmpl + '\n\n')

    with open(filename, "w") as doc:
        doc.write(tmpl)

        for name, klass in items:
            doc.write(name + '\n')
            doc.write('-' * len(name) + '\n\n')

            if klass.__doc__ is not None:
                text = klass.__doc__.replace('\n    ', '\n')
                doc.write(text + '\n')
            else:
                doc.write('No documentation. Boooo!\n\n')

            if len(klass.options) == 0:
                continue

            doc.write('\nOptions:\n\n')
            options = klass.options.items()
            options.sort()

            for name, option in options:
                if len(option) == 3:
                    desc, type_, default = option
                    desc = '%s (%s, default: %r)' % (desc, type_.__name__,
                                                     default)
                else:
                    desc, type_, default, choices = option
                    choices = ', '.join(['%r' % val for val in choices])
                    pattern = '%s (%s, default: %r, possible values: %s)'
                    desc = pattern % (desc, type_.__name__, default, choices)

                doc.write('- **%s**: %s\n' % (name, desc))
            doc.write("\n\n")
        doc.write("\n")


def generate_doc(app):
    generate_behaviors(app)
    generate_protocols(app)


def setup(app):
    app.connect('builder-inited', generate_doc)

########NEW FILE########
__FILENAME__ = conf
# -*- coding: utf-8 -*-
#
# Vaurien documentation build configuration file, created by
# sphinx-quickstart on Thu Oct 18 09:45:40 2012.
#
# This file is execfile()d with the current directory set to its containing dir.
#
# Note that not all possible configuration values are present in this
# autogenerated file.
#
# All configuration values have a default; values that are commented out
# serve to show the default.

import sys, os

# If extensions (or modules to document with autodoc) are in another directory,
# add these directories to sys.path here. If the directory is relative to the
# documentation root, use os.path.abspath to make it absolute, like shown here.
#sys.path.insert(0, os.path.abspath('.'))

# -- General configuration -----------------------------------------------------

# If your documentation needs a minimal Sphinx version, state it here.
#needs_sphinx = '1.0'

# Add any Sphinx extension module names here, as strings. They can be extensions
# coming with Sphinx (named 'sphinx.ext.*') or your custom ones.

class Mock(object):
    def __init__(self, *args, **kwargs):
        pass

    def __call__(self, *args, **kwargs):
        return Mock()

    @classmethod
    def __getattr__(self, name):
        if name in ('__file__', '__path__'):
            return '/dev/null'
        elif name[0] == name[0].upper():
            return type(name, (), {})

        return Mock()


MOCK_MODULES = ['gevent', 'gevent.socket', 'http_parser',
                'http_parser.pyparser']
on_rtd = os.environ.get('READTHEDOCS', None) == 'True'

for mod_name in MOCK_MODULES:
    sys.modules[mod_name] = Mock()

CURDIR = os.path.abspath(os.path.dirname(__file__))
sys.path.append(os.path.join(CURDIR, '..', '..'))
sys.path.append(os.path.join(CURDIR, '..'))

import vaurien

extensions = ['handlers_ext']

# Add any paths that contain templates here, relative to this directory.
templates_path = ['_templates']

# The suffix of source filenames.
source_suffix = '.rst'

# The encoding of source files.
#source_encoding = 'utf-8-sig'

# The master toctree document.
master_doc = 'index'

# General information about the project.
project = u'Vaurien'
copyright = u'2012, Mozilla'

# The version info for the project you're documenting, acts as replacement for
# |version| and |release|, also used in various other places throughout the
# built documents.
#
# The short X.Y version + .
release = version = vaurien.__version__

# The language for content autogenerated by Sphinx. Refer to documentation
# for a list of supported languages.
#language = None

# There are two options for replacing |today|: either, you set today to some
# non-false value, then it is used:
#today = ''
# Else, today_fmt is used as the format for a strftime call.
#today_fmt = '%B %d, %Y'

# List of patterns, relative to source directory, that match files and
# directories to ignore when looking for source files.
exclude_patterns = []

# The reST default role (used for this markup: `text`) to use for all documents.
#default_role = None

# If true, '()' will be appended to :func: etc. cross-reference text.
#add_function_parentheses = True

# If true, the current module name will be prepended to all description
# unit titles (such as .. function::).
#add_module_names = True

# If true, sectionauthor and moduleauthor directives will be shown in the
# output. They are ignored by default.
#show_authors = False

# The name of the Pygments (syntax highlighting) style to use.

# A list of ignored prefixes for module index sorting.
#modindex_common_prefix = []


# -- Options for HTML output ---------------------------------------------------

# The theme to use for HTML and HTML Help pages.  See the documentation for
# a list of builtin themes.

html_theme_path = ['_themes']
html_theme = 'mozilla'

# Theme options are theme-specific and customize the look and feel of a theme
# further.  For a list of options available for each theme, see the
# documentation.
#html_theme_options = {}

# Add any paths that contain custom themes here, relative to this directory.
#html_theme_path = []

# The name for this set of Sphinx documents.  If None, it defaults to
# "<project> v<release> documentation".
#html_title = None

# A shorter title for the navigation bar.  Default is the same as html_title.
#html_short_title = None

# The name of an image file (relative to this directory) to place at the top
# of the sidebar.
#html_logo = None

# The name of an image file (within the static path) to use as favicon of the
# docs.  This file should be a Windows icon file (.ico) being 16x16 or 32x32
# pixels large.
#html_favicon = None

# Add any paths that contain custom static files (such as style sheets) here,
# relative to this directory. They are copied after the builtin static files,
# so a file named "default.css" will overwrite the builtin "default.css".
html_static_path = ['_static']

# If not '', a 'Last updated on:' timestamp is inserted at every page bottom,
# using the given strftime format.
#html_last_updated_fmt = '%b %d, %Y'

# If true, SmartyPants will be used to convert quotes and dashes to
# typographically correct entities.
#html_use_smartypants = True

# Custom sidebar templates, maps document names to template names.
#html_sidebars = {}

# Additional templates that should be rendered to pages, maps page names to
# template names.
#html_additional_pages = {}

# If false, no module index is generated.
#html_domain_indices = True

# If false, no index is generated.
#html_use_index = True

# If true, the index is split into individual pages for each letter.
#html_split_index = False

# If true, links to the reST sources are added to the pages.
#html_show_sourcelink = True

# If true, "Created using Sphinx" is shown in the HTML footer. Default is True.
#html_show_sphinx = True

# If true, "(C) Copyright ..." is shown in the HTML footer. Default is True.
#html_show_copyright = True

# If true, an OpenSearch description file will be output, and all pages will
# contain a <link> tag referring to it.  The value of this option must be the
# base URL from which the finished HTML is served.
#html_use_opensearch = ''

# This is the file name suffix for HTML files (e.g. ".xhtml").
#html_file_suffix = None

# Output file base name for HTML help builder.
htmlhelp_basename = 'Vauriendoc'


# -- Options for LaTeX output --------------------------------------------------

latex_elements = {
# The paper size ('letterpaper' or 'a4paper').
#'papersize': 'letterpaper',

# The font size ('10pt', '11pt' or '12pt').
#'pointsize': '10pt',

# Additional stuff for the LaTeX preamble.
#'preamble': '',
}

# Grouping the document tree into LaTeX files. List of tuples
# (source start file, target name, title, author, documentclass [howto/manual]).
latex_documents = [
  ('index', 'Vaurien.tex', u'Vaurien Documentation',
   u'Mozilla', 'manual'),
]

# The name of an image file (relative to this directory) to place at the top of
# the title page.
#latex_logo = None

# For "manual" documents, if this is true, then toplevel headings are parts,
# not chapters.
#latex_use_parts = False

# If true, show page references after internal links.
#latex_show_pagerefs = False

# If true, show URL addresses after external links.
#latex_show_urls = False

# Documents to append as an appendix to all manuals.
#latex_appendices = []

# If false, no module index is generated.
#latex_domain_indices = True


# -- Options for manual page output --------------------------------------------

# One entry per manual page. List of tuples
# (source start file, name, description, authors, manual section).
man_pages = [
    ('index', 'vaurien', u'Vaurien Documentation',
     [u'Mozilla'], 1)
]

# If true, show URL addresses after external links.
#man_show_urls = False


# -- Options for Texinfo output ------------------------------------------------

# Grouping the document tree into Texinfo files. List of tuples
# (source start file, target name, title, author,
#  dir menu entry, description, category)
texinfo_documents = [
  ('index', 'Vaurien', u'Vaurien Documentation',
   u'Mozilla', 'Vaurien', 'One line description of project.',
   'Miscellaneous'),
]

# Documents to append as an appendix to all manuals.
#texinfo_appendices = []

# If false, no module index is generated.
#texinfo_domain_indices = True

# How to display URL addresses: 'footnote', 'no', or 'inline'.
#texinfo_show_urls = 'footnote'

########NEW FILE########
__FILENAME__ = loadtest
import json
import re
import random
import unicodedata

from funkload.FunkLoadTestCase import FunkLoadTestCase


class VaurienTest(FunkLoadTestCase):

    def __init__(self, *args, **kwargs):
        super(VaurienTest, self).__init__(*args, **kwargs)
        self.root = self.conf_get('main', 'url')

    def test_vaurien(self):
        res = self.get(self.root)
        self.assert_(res.code == 200)


if __name__ == '__main__':
    import unittest
    unittest.main()

########NEW FILE########
__FILENAME__ = wsgiapp
from gevent.local import local
from werkzeug.local import LocalProxy
from werkzeug.wrappers import Request
from contextlib import contextmanager

from gevent.wsgi import WSGIServer

_requests = local()
request = LocalProxy(lambda: _requests.request)


@contextmanager
def sessionmanager(environ):
    _requests.request = Request(environ)
    yield
    _requests.request = None


def logic():
    return "Hello " + request.remote_addr


def application(environ, start_response):
    status = '200 OK'

    with sessionmanager(environ):
        body = logic()

    headers = [
        ('Content-Type', 'text/html')
    ]

    start_response(status, headers)
    return [body]


if __name__ == '__main__':
    print 'Serving on port 8000'
    WSGIServer(('', 8000), application).serve_forever()

########NEW FILE########
__FILENAME__ = blackout
from vaurien.behaviors.dummy import Dummy


class Blackout(Dummy):
    """Immediately closes client socket, no other actions taken.

    """
    name = 'blackout'
    options = {}

    def on_before_handle(self, protocol, source, dest, to_backend):
        # close source socket
        source.close()
        source._closed = True
        return False

########NEW FILE########
__FILENAME__ = delay
import gevent
from vaurien.behaviors.dummy import Dummy


class Delay(Dummy):
    """Adds a delay before or after the backend is called.

    The delay can happen *after* or *before* the backend is called.
    """
    name = 'delay'
    options = {'sleep': ("Delay in seconds", int, 1),
               'before':
               ("If True adds before the backend is called. Otherwise"
                " after", bool, True)}
    options.update(Dummy.options)

    def on_before_handle(self, protocol, source, dest, to_backend):
        if self.option('before'):
            gevent.sleep(self.option('sleep'))
        return True

    def on_after_handle(self, protocol, source, dest, to_backend):
        if not self.option('before'):
            gevent.sleep(self.option('sleep'))

########NEW FILE########
__FILENAME__ = dummy


class Dummy(object):
    """Transparent behavior. Nothing's done.
    """
    name = 'dummy'
    options = {}

    def __init__(self):
        self.settings = {}

    def update_settings(self, settings):
        self.settings.update(settings)

    def _convert(self, value, type_):
        if isinstance(value, type_):
            return value
        if type_ == bool:
            value = value.lower()
            return value in ('y', 'yes', '1', 'on')
        return type_(value)

    def option(self, name):
        type_, default = self.options[name][1:3]
        value = self.settings.get(name, default)
        return self._convert(value, type_)

    def on_before_handle(self, protocol, source, dest, to_backend):
        return True

    def on_after_handle(self, protocol, source, dest, to_backend):
        return True

########NEW FILE########
__FILENAME__ = error
import os
import random

from vaurien.behaviors.dummy import Dummy
from vaurien.util import get_data


_ERRORS = {
    500: ("Internal Server Error",
          ('<p>The server encountered an internal error and was unable to '
           'complete your request.  Either the server is overloaded or there '
           'is an error in the application.</p>')),

    501: ("Not Implemented",
          ('<p>The server does not support the action requested by the '
           'browser.</p>')),

    502: ("Bad Gateway",
          ('<p>The proxy server received an invalid response from an upstream'
           ' server.</p>')),

    503: ("Service Unavailable",
          ('<p>The server is temporarily unable to service your request due '
           'to maintenance downtime or capacity problems.  Please try again '
           'later.</p>'))
}


_ERROR_CODES = _ERRORS.keys()

_TMP = """\
HTTP/1.1 %(code)s %(name)s
Content-Type: text/html; charset=UTF-8
Connection: close

<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 3.2 Final//EN">
<title>%(code)s %(name)s</title>
<h1>%(name)s</h1>
%(description)s
"""


def random_http_error():
    data = {}
    data['code'] = code = random.choice(_ERROR_CODES)
    data['name'], data['description'] = _ERRORS[code]
    return _TMP % data


class Error(Dummy):
    """Reads the packets that have been sent then send back "errors".

    Used in cunjunction with the HTTP Procotol, it will randomly send back
    a 501, 502 or 503.

    For other protocols, it returns random data.

    The *inject* option can be used to inject data within valid data received
    from the backend. The Warmup option can be used to deactivate the random
    data injection for a number of calls. This is useful if you need the
    communication to settle in some speficic protocols before the ramdom
    data is injected.

    The *inject* option is deactivated when the *http* protocol is used.
    """
    name = 'error'
    options = {'inject': ("Inject errors inside valid data", bool, False),
               'warmup': ("Number of calls before erroring out", int, 0)}
    options.update(Dummy.options)

    def __init__(self):
        super(Error, self).__init__()
        self.current = 0

    def on_before_handle(self, protocol, source, dest, to_backend):
        if self.current < self.option('warmup'):
            self.current += 1
            return super(Error, self).on_before_handle(protocol, source,
                                                       dest, to_backend)

        # read the data
        data = get_data(source)
        if not data:
            return False

        # error out
        if protocol.name == 'http' and to_backend:
            # we'll just send back a random error
            source.sendall(random_http_error())
            source.close()
            source._closed = True
            return False

        if self.option('inject'):
            if not to_backend:      # back to the client
                middle = len(data) / 2
                dest.sendall(data[:middle] + os.urandom(100) + data[middle:])
            else:                   # sending the data tp the backend
                dest.sendall(data)

        else:
            if not to_backend:
                # XXX find how to handle errors (which errors should we send)
                # depends on the protocol
                dest.sendall(os.urandom(1000))

            else:          # sending the data tp the backend
                dest.sendall(data)

        return True

########NEW FILE########
__FILENAME__ = hang
import gevent

from vaurien.behaviors.dummy import Dummy
from vaurien.util import get_data


class Hang(Dummy):
    """Reads the packets that have been sent then hangs.

    Acts like a *pdb.set_trace()* you'd forgot in your code ;)
    """
    name = 'hang'
    options = {}

    def on_before_handle(self, protocol, source, dest, to_backend):
        # consume the socket and hang
        data = get_data(source)
        while data:
            data = get_data(source)

        while True:
            gevent.sleep(1.)

########NEW FILE########
__FILENAME__ = config
# ***** BEGIN LICENSE BLOCK *****
# This Source Code Form is subject to the terms of the Mozilla Public
# License, v. 2.0. If a copy of the MPL was not distributed with this
# file,
# You can obtain one at http://mozilla.org/MPL/2.0/.
# ***** END LICENSE BLOCK *****

""" Configuration file reader / writer

https://wiki.mozilla.org/index.php?title=Services/Sync/Server/GlobalConfFile
"""
import re
import os
from os.path import abspath, normpath, expandvars, expanduser
from ConfigParser import RawConfigParser

_IS_NUMBER = re.compile('^-?[0-9].*')
_IS_ENV_VAR = re.compile('\$\{(\w.*)?\}')


def convert(value):
    """Converts a config value"""
    def _get_env(matchobj):
        var = matchobj.groups()[0]
        if var not in os.environ:
            raise KeyError(var)
        return os.environ[var]

    def _convert(value):
        if not isinstance(value, basestring):
            # already converted
            return value

        value = value.strip()
        if _IS_NUMBER.match(value):
            try:
                return int(value)
            except ValueError:
                pass
        elif value.startswith('"') and value.endswith('"'):
            return value[1:-1]
        elif value.lower() in ('true', 'false'):
            return value.lower() == 'true'
        return _IS_ENV_VAR.sub(_get_env, value)

    if isinstance(value, basestring) and '\n' in value:
        return [line for line in [_convert(line)
                                  for line in value.split('\n')]
                if line != '']

    return _convert(value)


class Config(RawConfigParser):

    def __init__(self, filename):
        # let's read the file
        RawConfigParser.__init__(self)
        if isinstance(filename, basestring):
            self.read(filename)
        else:
            self.readfp(filename)

    def _read(self, fp, filename):
        # first pass
        RawConfigParser._read(self, fp, filename)

        # let's expand it now if needed
        defaults = self.defaults()

        if 'extends' in defaults:
            extends = defaults['extends']
            if not isinstance(extends, list):
                extends = [extends]
            for file_ in extends:
                self._extend(file_)

    def _serialize(self, value):
        """values are serialized on every set"""
        if isinstance(value, bool):
            value = str(value).lower()
        elif isinstance(value, (int, long)):
            value = str(value)
        elif isinstance(value, (list, tuple)):
            value = '\n'.join(['    %s' % line for line in value]).strip()
        else:
            value = str(value)
        return value

    def _unserialize(self, value):
        """values are serialized on every get"""
        return convert(value)

    def get_map(self, section=None):
        """returns a dict representing the config set"""
        if section:
            return dict(self.items(section))

        res = {}
        for section in self.sections():
            for option, value in self.items(section):
                option = '%s.%s' % (section, option)
                res[option] = self._unserialize(value)
        return res

    def set(self, section, option, value):
        value = self._serialize(value)
        RawConfigParser.set(self, section, option, value)

    def mget(self, section, option):
        value = self.get(section, option)
        if not isinstance(value, list):
            value = [value]
        return value

    def get(self, section, option):
        value = RawConfigParser.get(self, section, option)
        return self._unserialize(value)

    def items(self, section):
        items = RawConfigParser.items(self, section)
        return [(option, self._unserialize(value)) for option, value in items]

    def _extend(self, filename):
        """Expand the config with another file."""
        if not os.path.isfile(filename):
            raise IOError('No such file: %s' % filename)
        parser = RawConfigParser()
        parser.read([filename])
        for section in parser.sections():
            if not self.has_section(section):
                self.add_section(section)
            for option, value in parser.items(section):
                if self.has_option(section, option):
                    continue
                RawConfigParser.set(self, section, option, value)


def load_into_settings(filename, settings):
    """Load config file contents into a Pyramid settings dict.

    This is a helper function for initialising a Pyramid settings dict from
    a config file.  It flattens the config file sections into dotted settings
    names and updates the given dictionary in place.

    You would typically use this when constructing a Pyramid Configurator
    object, like so::

        def main(global_config, **settings):
            config_file = global_config['__file__']
            load_info_settings(config_file, settings)
            config = Configurator(settings=settings)

    """
    filename = abspath(normpath(expandvars(expanduser(filename))))

    if not os.path.isfile(filename):
        raise ValueError("Unexistant filename '%s'" % filename)

    config = Config(filename)

    # Put values from the config file into the pyramid settings dict.
    for section in config.sections():
        setting_prefix = section.replace(":", ".")
        for name, value in config.get_map(section).iteritems():
            settings[setting_prefix + "." + name] = value

    # Store a reference to the Config object itself for later retrieval.
    settings['config'] = config
    return config


class SettingsDict(dict):
    """A dict subclass with some extra helpers for dealing with app settings.

    This class extends the standard dictionary interface with some extra helper
    methods that are handy when dealing with application settings.  It expects
    the keys to be dotted setting names, where each component indicates one
    section in the settings heirarchy.  You get the following extras:

        * setdefaults:  copy any unset settings from another dict
        * getsection:   return a dict of settings for just one subsection
        * sections:     return a list of sections for the settings

    """

    separator = "."

    def copy(self):
        """D.copy() -> a shallow copy of D.

        This overrides the default dict.copy method to ensure that the
        copy is also an instance of SettingsDict.
        """
        new_items = self.__class__()
        for k, v in self.iteritems():
            new_items[k] = v
        return new_items

    def sections(self):
        """Return a list of sections for this dict"""
        sections = []
        for key in self.iterkeys():
            if self.separator in key:
                sec, _ = key.rsplit(self.separator, 1)
                if sec not in sections:
                    sections.append(sec)
        return sections

    def getsection(self, section):
        """Get a dict for just one sub-section of the config.

        This method extracts all the keys belonging to the name section and
        returns those values in a dict.  The section name is removed from
        each key.  For example::

            >>> c = SettingsDict({"a.one": 1, "a.two": 2, "b.three": 3})
            >>> c.getsection("a")
            {"one": 1, "two", 2}
            >>>
            >>> c.getsection("b")
            {"three": 3}
            >>>
            >>> c.getsection("c")
            {}

        """
        section_items = self.__class__()
        # If the section is "" then get keys without a section.
        if not section:
            for key, value in self.iteritems():
                if self.separator not in key:
                    section_items[key] = value
        # Otherwise, get keys prefixed with that section name.
        else:
            prefix = section + self.separator
            for key, value in self.iteritems():
                if key.startswith(prefix):
                    section_items[key[len(prefix):]] = value
        return section_items

    def setdefaults(self, *args, **kwds):
        """Import unset keys from another dict.

        This method lets you update the dict using defaults from another
        dict and/or using keyword arguments.  It's like the standard update()
        method except that it doesn't overwrite existing keys.
        """
        for arg in args:
            if hasattr(arg, "keys"):
                for k in arg:
                    self.setdefault(k, arg[k])
            else:
                for k, v in arg:
                    self.setdefault(k, v)
        for k, v in kwds.iteritems():
            self.setdefault(k, v)


DEFAULT_SETTINGS = SettingsDict({
    # default ratios
    'vaurien.proxy': 'localhost:8000',
    'vaurien.backend': 'localhost:80',
    'vaurien.behavior': '100:dummy',
    'vaurien.bufsize': 8192,
    'vaurien.timeout': 30,
    'vaurien.stay_connected': False,
    'vaurien.pool_max_size': 100,
    'vaurien.pool_timeout': 30,
    'vaurien.sync': False,
    'vaurien.backlog': 8192,

    # stats config
    'statsd.enabled': False,
    'statsd.host': 'localhost',
    'statsd.port': 8125,
    'statsd.prefix': 'vaurien',
    'statsd.sample_rate': 1.0
})

########NEW FILE########
__FILENAME__ = metaserver
import sys
import argparse

from gevent.server import StreamServer
from gevent.socket import create_connection, error, gethostbyname

from vaurien.protocols.http import EOH, RE_LEN
from vaurien.behaviors.dummy import Dummy
from vaurien.run import LOG_LEVELS, configure_logger
from vaurien import logger, __version__
from vaurien.util import get_data, chunked


_TMP = """\
HTTP/1.1 %(code)s %(name)s
Content-Type: text/html; charset=UTF-8

<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 3.2 Final//EN">
<title>%(code)s %(name)s</title>
<h1>%(name)s</h1>
%(description)s
"""


def http_error(code='400', name='Bad Request', description='Boo'):
    data = {}
    data['code'] = code
    data['name'] = name
    data['description'] = description
    return _TMP % data


class MetaProxy(StreamServer):
    def __init__(self, host, port):
        self.behavior = Dummy()
        self.behavior_name = 'dummy'
        self.host = gethostbyname(host)
        self.port = port
        location = self.host, self.port
        StreamServer.__init__(self, location)

    def handle(self, client_sock, address):
        client_sock.setblocking(0)
        dest = None
        try:
            # getting the query
            data = get_data(client_sock)

            if not data:
                return

            # finding out what backend we want
            data = data.split('\r\n')

            PATH = data[0].split()
            elmts = PATH[1].split('/')
            try:
                port = int(elmts[1])
            except ValueError:
                client_sock.sendall(http_error(404, 'Not Found'))
                return

            NEW_PATH = '/'.join(elmts[0:1] + elmts[2:])
            data[0] = ' '.join(PATH[0:1] + [NEW_PATH] + PATH[2:])

            try:
                dest = create_connection((self.host, port))
            except error:
                client_sock.sendall(http_error(503, '%d not responding' %
                                    port))
                return

            # sending it to the backend
            dest.sendall('\r\n'.join(data))

            # Receiving the response
            buffer = get_data(dest)

            client_sock.sendall(buffer)

            # Reading the HTTP Headers
            while EOH not in buffer:
                data = get_data(dest)
                buffer += data
                client_sock.sendall(data)

            # content-length header - to see if we need to suck more
            # data.
            match = RE_LEN.search(buffer)
            if match:
                resp_len = int(match.group(1))
                left_to_read = resp_len - len(buffer)
                if left_to_read > 0:
                    for chunk in chunked(left_to_read, 1024):
                        data = get_data(dest, chunk)
                        buffer += data
                        client_sock.sendall(data)
            else:
                # embarrassing...
                # just sucking until recv() returns ''
                while True:
                    data = get_data(dest)
                    if data == '':
                        break
                    client_sock.sendall(data)
        finally:
            client_sock.close()
            if dest is not None:
                dest.close()


def main():
    parser = argparse.ArgumentParser(description='Runs a Meta proxy.')

    # other arguments
    parser.add_argument('--version', action='store_true', default=False,
                        help='Displays version and exits.')
    parser.add_argument('--host', default='localhost',
                        help='Host of the server')
    parser.add_argument('--port', default=9998, type=int,
                        help='Port of the server')

    parser.add_argument('--log-level', dest='loglevel', default='info',
                        choices=LOG_LEVELS.keys() + [key.upper() for key in
                                                     LOG_LEVELS.keys()],
                        help="log level")
    parser.add_argument('--log-output', dest='logoutput', default='-',
                        help="log output")

    # parsing the provided args
    args = parser.parse_args()

    if args.version:
        print(__version__)
        sys.exit(0)

    # configure the logger
    configure_logger(logger, args.loglevel, args.logoutput)
    http_server = MetaProxy(args.host, args.port)

    logger.info('Starting the Meta server: http://%s:%s' %
                (args.host, args.port))

    try:
        http_server.serve_forever()
    except KeyboardInterrupt:
        sys.exit(0)
    finally:
        logger.info('Bye!')


if __name__ == '__main__':
    main()

########NEW FILE########
__FILENAME__ = base
import copy
from vaurien.util import get_data


class BaseProtocol(object):

    name = ''
    options = {'reuse_socket': ("If True, the socket is reused.",
                                bool, False),
               'buffer': ("Buffer size", int, 8124),
               'keep_alive': ("Keep the connection alive", bool, False)
               }

    def __init__(self, settings=None, proxy=None):
        self.proxy = proxy
        if proxy is not None:
            self.logger = self.proxy._logger
        else:
            self.logger = None

        if settings is None:
            self.settings = {}
        else:
            self.settings = copy.copy(settings)

    def _abort_handling(self, to_backend, backend_sock):
        if not to_backend:
            # We want to close the socket if the backend sock is empty
            if not self.option('reuse_socket'):
                backend_sock.close()
                backend_sock._closed = True

    def update_settings(self, settings):
        self.settings.update(settings)

    def _convert(self, value, type_):
        if isinstance(value, type_):
            return value
        if type_ == bool:
            value = value.lower()
            return value in ('y', 'yes', '1', 'on')
        return type_(value)

    def option(self, name):
        type_, default = self.options[name][1:3]
        value = self.settings.get(name, default)
        return self._convert(value, type_)

    def _get_data(self, sock, buffer=None):
        if buffer is None:
            buffer = self.option('buffer')
        return get_data(sock, buffer)

    def __call__(self, source, dest, to_backend, behavior):
        if not behavior.on_before_handle(self, source, dest, to_backend):
            return True
        try:
            return self._handle(source, dest, to_backend)
        finally:
            behavior.on_after_handle(self, source, dest, to_backend)

########NEW FILE########
__FILENAME__ = http
import re
import copy

try:
    from http_parser.parser import HttpParser
except ImportError:
    from http_parser.pyparser import HttpParser

from vaurien.protocols.base import BaseProtocol


HOST_REPLACE = re.compile(r'\r\nHost: .+\r\n')
CRLF = '\r\n'


class Http(BaseProtocol):
    """HTTP protocol.
    """
    name = 'http'
    options = copy.copy(BaseProtocol.options)
    options['overwrite_host_header'] = ("If True, the HTTP Host header will "
                                        "be rewritten with backend address.",
                                        bool, True)

    def _close_both(self, source, dest):
        source.close()
        source._closed = True
        dest.close()
        dest._closed = True
        return False

    def _handle(self, source, dest, to_backend):
        buffer_size = self.option('buffer')

        # Getting the HTTP query and sending it to the backend.
        parser = HttpParser()
        while not parser.is_message_complete():
            data = self._get_data(source, buffer_size)
            if not data:
                return self._close_both(source, dest)
            nparsed = parser.execute(data, len(data))
            assert nparsed == len(data)
            if self.option('overwrite_host_header'):
                data = HOST_REPLACE.sub('\r\nHost: %s\r\n'
                                        % self.proxy.backend, data)
            dest.sendall(data)
        keep_alive_src = parser.should_keep_alive()
        method = parser.get_method()

        # Getting the HTTP response and sending it back to the source.
        parser = HttpParser()
        while not (parser.is_message_complete() or
                   (method == 'HEAD' and parser.is_headers_complete())):
            data = self._get_data(dest, buffer_size)
            if not data:
                return self._close_both(source, dest)
            nparsed = parser.execute(data, len(data))
            assert nparsed == len(data)
            source.sendall(data)
        keep_alive_dst = parser.should_keep_alive()

        # do we close the client ?
        if not keep_alive_src or not self.option('keep_alive'):
            source.close()
            source._closed = True

        if (not keep_alive_dst or not self.option('reuse_socket') or not
                self.option('keep_alive')):
            dest.close()
            dest._closed = True

        return keep_alive_dst and self.option('keep_alive')

########NEW FILE########
__FILENAME__ = memcache
import re

from vaurien.protocols.base import BaseProtocol
from vaurien.util import chunked


RE_LEN = re.compile('Content-Length: (\d+)', re.M | re.I)
RE_KEEPALIVE = re.compile('Connection: Keep-Alive')
RE_MEMCACHE_COMMAND = re.compile('(.*)\r\n')

EOH = '\r\n\r\n'
CRLF = '\r\n'


class Memcache(BaseProtocol):
    """Memcache protocol.
    """
    name = 'memcache'

    def _handle(self, source, dest, to_backend):
        # https://github.com/memcached/memcached/blob/master/doc/protocol.txt
        # Sending the query
        buffer = self._get_data(source)
        if not buffer:
            self._abort_handling(to_backend, dest)
            return

        # sending the first packet
        dest.sendall(buffer)

        # finding the command we sent.
        cmd = RE_MEMCACHE_COMMAND.search(buffer)

        if cmd is None:
            # wat ?
            self._abort_handling(to_backend, dest)
            return

        # looking at the command
        cmd = cmd.groups()[0]
        buffer_size = self.option('buffer')

        cmd_parts = cmd.split()
        mcmd = cmd_parts[0]

        if mcmd in ('set', 'add', 'replace', 'append'):
            cmd_size = len(cmd) + len(CRLF)
            data_size = int(cmd_parts[-1])
            total_size = cmd_size + data_size

            # grabbing more data if needed
            left_to_read = total_size - len(buffer) + len(CRLF)
            if left_to_read > 0:
                for chunk in chunked(left_to_read, buffer_size):
                    data = source.recv(chunk)
                    buffer += data
                    dest.sendall(data)

        # Receiving the response now
        buffer = self._get_data(dest, buffer_size)
        source.sendall(buffer)

        if buffer.startswith('VALUE'):
            # we're getting back a value.
            EOW = 'END' + CRLF
        else:
            EOW = CRLF

        while not buffer.endswith(EOW):
            data = self._get_data(dest, buffer_size)
            buffer += data
            source.sendall(data)

        # we're done
        return True    # keeping connected

########NEW FILE########
__FILENAME__ = mysql
import copy
from vaurien.protocols.tcp import TCP


class MySql(TCP):

    name = 'mysql'
    options = copy.copy(TCP.options)
    del options['keep_alive']

    def update_settings(self, settings):
        if 'keep_alive' in settings:
            del settings['keep_alive']
        super(MySql, self).update_settings(settings)

    def option(self, name):
        if name == 'keep_alive':
            return True
        return super(MySql, self).option(name)

########NEW FILE########
__FILENAME__ = redis
import re

from vaurien.protocols.base import BaseProtocol
from vaurien.util import chunked


RE_LEN = re.compile('Content-Length: (\d+)', re.M | re.I)
RE_KEEPALIVE = re.compile('Connection: Keep-Alive')
RE_MEMCACHE_COMMAND = re.compile('(.*)\r\n')

EOH = '\r\n\r\n'
CRLF = '\r\n'


class Redis(BaseProtocol):
    """Redis protocol.
    """
    name = 'redis'

    def _find(self, source, buffer, char, dest):
        pos = buffer.find(char)
        while pos == -1:
            data = self._get_data(source)
            if data == '':
                return -1, buffer
            dest.sendall(data)
            buffer += data
            pos = buffer.find(char)
        return pos, buffer

    def _handle(self, source, dest, to_backend):
        """ see http://redis.io/topics/protocol
        """
        # grabbing data
        bytepos, buffer = self._find(source, '', CRLF, dest)
        if bytepos == -1:
            return False

        num_args = int(buffer[1:bytepos])

        for arg in range(num_args):
            # next CRLF
            buffer = buffer[bytepos + len(CRLF):]
            bytepos, buffer = self._find(source, buffer, CRLF, dest)

            # reading the number of bytes
            num_bytes = int(buffer[1:bytepos])
            data_start = bytepos + len(CRLF)

            # reading the data (next CRLF)
            buffer = buffer[data_start:]
            __, buffer = self._find(source, buffer, CRLF, dest)
            data = buffer[:num_bytes]
            bytepos = num_bytes

        # Getting the answer back and sending it over.
        buffer = self._get_data(dest)
        source.sendall(buffer)

        if buffer[0] in ('+', '-', ':'):
            # simple reply, we're good
            return False    # disconnect mode ?

        buffer_size = self.option('buffer')
        bytepos, buffer = self._find(dest, buffer, CRLF, source)

        if buffer[0] == '$':
            # bulk reply
            size = int(buffer[1:bytepos])
            left_to_read = (size - len(buffer) + len(buffer[:bytepos]) +
                            len(CRLF) * 2)

            if left_to_read > 0:
                for chunk in chunked(left_to_read, buffer_size):
                    data = self._get_data(dest, chunk)
                    buffer += data
                    source.sendall(data)

            return False  # disconnect mode ?

        if buffer[0] == '*':
            # multi-bulk reply
            raise NotImplementedError()

        raise NotImplementedError()

########NEW FILE########
__FILENAME__ = smtp
import copy
from vaurien.protocols.tcp import TCP


class SMTP(TCP):
    """SMTP Protocol.

    """
    name = 'smtp'
    options = copy.copy(TCP.options)
    del options['keep_alive']

    def update_settings(self, settings):
        if 'keep_alive' in settings:
            del settings['keep_alive']
        super(SMTP, self).update_settings(settings)

    def option(self, name):
        if name == 'keep_alive':
            return True
        return super(SMTP, self).option(name)

########NEW FILE########
__FILENAME__ = tcp
import re

from vaurien.protocols.base import BaseProtocol


RE_LEN = re.compile('Content-Length: (\d+)', re.M | re.I)
RE_KEEPALIVE = re.compile('Connection: Keep-Alive')
RE_MEMCACHE_COMMAND = re.compile('(.*)\r\n')

EOH = '\r\n\r\n'
CRLF = '\r\n'


class TCP(BaseProtocol):
    """TCP handler.
    """
    name = 'tcp'

    def _handle(self, source, dest, to_backend):
        # default TCP behavior
        data = self._get_data(source)
        if data:
            dest.sendall(data)

            # If we are not keeping the connection alive
            # we can suck the answer back and close the socket
            if not self.option('keep_alive'):
                # just suck it until it's empty
                data = ''
                while True:
                    data = self._get_data(dest)
                    if data == '':
                        break
                    source.sendall(data)

                if not self.option('reuse_socket'):
                    dest.close()
                    dest._closed = True

                # we're done - False means we'll disconnect the client
                return False

        return data != ''

########NEW FILE########
__FILENAME__ = proxy
import gevent
import random
from uuid import uuid4

from gevent.server import StreamServer
from gevent.socket import create_connection
from gevent.select import select, error

from vaurien.util import parse_address, get_prefixed_sections, extract_settings
from vaurien.protocols import get_protocols
from vaurien.behaviors import get_behaviors

from vaurien._pool import FactoryPool


class DefaultProxy(StreamServer):

    def __init__(self, proxy, backend, protocol='tcp', behaviors=None,
                 settings=None, statsd=None, logger=None, **kwargs):
        self.settings = settings
        cfg = self.settings.getsection('vaurien')

        if behaviors is None:
            behaviors = get_behaviors()

        logger.info('Starting the Chaos TCP Server')
        parsed_proxy = parse_address(proxy)
        self.backend = backend
        dest = parse_address(backend)
        backlog = cfg.get('backlog', 8192)
        StreamServer.__init__(self, parsed_proxy, backlog=backlog, **kwargs)
        self.max_accept = 2000  # XXX option ?
        self.pool_max_size = cfg.get('pool_max_size', 1000)
        self.pool_timeout = cfg.get('pool_timeout', 30)
        self.async_mode = not cfg.get('sync', False)
        self._pool = FactoryPool(self._create_connection, self.pool_max_size,
                                 self.pool_timeout)
        self.dest = dest
        self.running = True
        self._statsd = statsd
        self._logger = logger
        self.behaviors = behaviors
        self.behaviors.update(get_prefixed_sections(self.settings, logger,
                                                    'behavior'))
        self.behavior = get_behaviors()['dummy']
        self.behavior_name = 'dummy'
        self.stay_connected = cfg.get('stay_connected', False)
        self.timeout = cfg.get('timeout', 30)
        self.protocol = cfg.get('protocol', protocol)

        # creating the handler with the passed options
        protocols = get_protocols()
        protocols.update(get_prefixed_sections(self.settings, logger,
                                               'protocol'))

        self.handler = protocols[self.protocol]

        # updating the handler settings
        args = settings['args']
        self.handler.update_settings(extract_settings(args, 'protocol',
                                                      self.protocol))
        self.handler.proxy = self

        logger.info('Options:')
        logger.info('* proxies from %s to %s' % (proxy, backend))
        logger.info('* timeout: %d' % self.timeout)
        logger.info('* stay_connected: %d' % self.stay_connected)
        logger.info('* pool_max_size: %d' % self.pool_max_size)
        logger.info('* pool_timeout: %d' % self.pool_timeout)
        logger.info('* async_mode: %d' % self.async_mode)

    def _create_connection(self):
        conn = create_connection(self.dest, timeout=self.timeout)
        if self.async_mode:
            conn.setblocking(0)
        return conn

    def get_behavior(self):
        return self.behavior, self.behavior_name

    def get_behavior_names(self):
        keys = get_behaviors().keys()
        keys.sort()
        return keys

    def handle(self, client_sock, address):
        client_sock.setblocking(0)
        behavior, behavior_name = self.get_behavior()

        statsd_prefix = '%s.%s.' % (self.protocol, uuid4())
        self.statsd_incr(statsd_prefix + 'start')

        try:
            with self._pool.reserve() as backend_sock:
                while True:
                    try:
                        res = select([client_sock, backend_sock], [], [],
                                     timeout=self.timeout)
                        rlist = res[0]
                    except error:
                        backend_sock.close()
                        backend_sock._closed = True
                        break

                    # gevent 1.x introduced 'closed'
                    if hasattr(client_sock, 'closed') and client_sock.closed:
                        raise ValueError("Client is gone")

                    greens = [gevent.spawn(self._weirdify,
                                           client_sock, backend_sock,
                                           sock is not backend_sock,
                                           statsd_prefix,
                                           behavior, behavior_name)
                              for sock in rlist]

                    res = [green.get() for green in greens]

                    got_data = all(res) and len(res) > 0

                    if not got_data and not self.stay_connected:
                        break

                if not self.handler.settings['reuse_socket']:
                    backend_sock.close()
                    backend_sock._closed = True
        finally:
            self.statsd_incr(statsd_prefix + 'end')
            client_sock.close()

    def statsd_incr(self, counter):
        if self._statsd:
            self._statsd.incr(counter)
        elif self._logger:
            self._logger.debug(counter)

    def _weirdify(self, client_sock, backend_sock, to_backend,
                  statsd_prefix, behavior, behavior_name):
        """This is where all the magic happens.

        Depending the configuration, we will chose to either drop packets,
        proxy them, wait a long time, etc, as defined in the configuration.
        """
        if hasattr(client_sock, 'closed') and client_sock.closed:
            raise ValueError("Client is gone")

        if to_backend:
            self.statsd_incr(statsd_prefix + 'to_backend')
            dest = backend_sock
            source = client_sock
        else:
            self.statsd_incr(statsd_prefix + 'to_client')
            source = backend_sock
            dest = client_sock

        self._logger.debug('starting weirdify %s' % to_backend)
        try:
            # XXX cache this ?
            args = self.settings['args']
            behavior.update_settings(extract_settings(args, 'behavior',
                                                      behavior_name))
            # calling the handler
            return self.handler(source, dest, to_backend, behavior)
        finally:
            self._logger.debug('exiting weirdify %s' % to_backend)


class RandomProxy(DefaultProxy):

    def __init__(self, *args, **kwargs):
        super(RandomProxy, self).__init__(*args, **kwargs)
        self.choices = []
        self.initialize_choices()

    def initialize_choices(self):
        total = 0
        behavior = self.settings.getsection('vaurien')['behavior']
        choices = {}

        for behavior in behavior.split(','):
            choice = behavior.split(':')
            if len(choice) != 2:
                raise ValueError('You need to use percentage:name')

            percent, behavior_name = choice
            percent = int(percent)
            if behavior_name not in self.behaviors:
                choices = self.behaviors.keys()
                msg = "%r is an unknown behavior. Pick one of: %s."
                raise ValueError(msg % (behavior_name,
                                        ', '.join(['%r' % choice
                                                   for choice in choices])))

            choices[behavior_name] = self.behaviors[behavior_name], percent
            total += percent

        if total > 100:
            raise ValueError('The behavior total needs to be 100 or less')
        elif total < 100:
            missing = 100 - total
            if 'dummy' in choices:
                choices['dummy'][1] += missing
            else:
                choices['dummy'] = get_behaviors()['dummy'], missing

        for name, (behavior, percent) in choices.items():
            self.choices.extend(
                [(self.behaviors[name], name) for i in range(percent)])

    def _weirdify(self, client_sock, backend_sock, to_backend,
                  statsd_prefix, behavior, behavior_name):
        behavior, behavior_name = self.get_behavior()
        return super(RandomProxy, self)._weirdify(client_sock, backend_sock,
                                                  to_backend, statsd_prefix,
                                                  behavior, behavior_name)

    def get_behavior(self):
        return random.choice(self.choices)


class OnTheFlyProxy(DefaultProxy):

    def set_behavior(self, **options):
        behavior_name = options.pop('name')
        self.behavior = self.behaviors[behavior_name]
        self.behavior_name = behavior_name
        for name, value in options.items():
            self.behavior.settings[name] = value
        self._logger.info('Handler changed to "%s"' % behavior_name)

########NEW FILE########
__FILENAME__ = run
import argparse
import sys
import logging

from vaurien.proxy import OnTheFlyProxy, RandomProxy
from vaurien.config import load_into_settings, DEFAULT_SETTINGS
from vaurien import __version__, logger
from vaurien.behaviors import get_behaviors
from vaurien.protocols import get_protocols


LOG_LEVELS = {
    "critical": logging.CRITICAL,
    "error": logging.ERROR,
    "warning": logging.WARNING,
    "info": logging.INFO,
    "debug": logging.DEBUG}

LOG_FMT = r"%(asctime)s [%(process)d] [%(levelname)s] %(message)s"
LOG_DATE_FMT = r"%Y-%m-%d %H:%M:%S"


class DevNull(object):
    def write(self, msg):
        pass


def close_on_exec(fd):
    try:
        import fcntl
    except ImportError:
        return

    flags = fcntl.fcntl(fd, fcntl.F_GETFD)
    flags |= fcntl.FD_CLOEXEC
    fcntl.fcntl(fd, fcntl.F_SETFD, flags)


def configure_logger(logger, level='INFO', output="-"):
    loglevel = LOG_LEVELS.get(level.lower(), logging.INFO)
    logger.setLevel(loglevel)
    if output == "-":
        h = logging.StreamHandler()
    else:
        h = logging.FileHandler(output)
        close_on_exec(h.stream.fileno())
    fmt = logging.Formatter(LOG_FMT, LOG_DATE_FMT)
    h.setFormatter(fmt)
    logger.addHandler(h)


def get_statsd_from_settings(settings):
    if settings['enabled']:
        from statsd import StatsdClient
        statsd = StatsdClient(host=settings['host'],
                              port=settings['port'],
                              prefix=settings['prefix'],
                              sample_rate=settings['sample_rate'])
    else:
        statsd = None
    return statsd


def build_args(parser, items, prefix):
    for name, klass in items:
        for option_name, option in klass.options.items():
            if len(option) == 3:
                description, type_, default = option
                choices = None
            else:
                description, type_, default, choices = option

            option_name = '--%s-%s-%s' % (prefix, name,
                                          option_name.replace('_', '-'))
            if type_ is bool:
                kws = {'action': 'store_true'}
            else:
                kws = {'action': 'store', 'type': type_}

            if choices is not None:
                kws = {'choices': choices}

            parser.add_argument(option_name, default=default,
                                help=description, **kws)


def main():
    # get the values from the default config
    defaults = DEFAULT_SETTINGS.items()
    defaults.sort()

    parser = argparse.ArgumentParser(description='Runs a Chaos TCP proxy.')

    # other arguments
    parser.add_argument('--config', help='Configuration file', default=None)
    parser.add_argument('--version', action='store_true', default=False,
                        help='Displays version and exits.')
    parser.add_argument('--http', action='store_true', default=False,
                        help='Start a simple http server to control vaurien')
    parser.add_argument('--http-host', default='localhost',
                        help='Host of the http server, if any')
    parser.add_argument('--http-port', default=8080, type=int,
                        help='Port of the http server, if any')
    parser.add_argument('--protocol', default='tcp', choices=get_protocols(),
                        help='Protocol used')

    for key, default in defaults:
        if key.startswith('vaurien'):
            key = key[len('vaurien.'):]
        key = key.replace('_', '-')
        type_ = default.__class__
        if type_ is bool:
            parser.add_argument('--%s' % key, default=default,
                                action='store_true')
        else:
            parser.add_argument('--%s' % key, default=default,
                                type=type_)

    parser.add_argument('--log-level', dest='loglevel', default='info',
                        choices=LOG_LEVELS.keys() + [key.upper() for key in
                                                     LOG_LEVELS.keys()],
                        help="log level")
    parser.add_argument('--log-output', dest='logoutput', default='-',
                        help="log output")

    # now for each registered behavior, we are going to provide its options
    build_args(parser, get_behaviors().items(), 'behavior')

    # same thing for the protocols
    build_args(parser, get_protocols().items(), 'protocol')

    # parsing the provided args
    args = parser.parse_args()

    if args.version:
        print(__version__)
        sys.exit(0)

    # configure the logger
    configure_logger(logger, args.loglevel, args.logoutput)

    # load the defaults
    settings = DEFAULT_SETTINGS.copy()

    # overwrite with the command line arguments
    for key in settings.keys():
        prefix = ''
        if key.startswith('vaurien'):
            key = key[len('vaurien.'):]
            prefix = 'vaurien.'

        try:
            value = getattr(args, key)
        except AttributeError:
            value = None

        if value is not None:
            settings[prefix + key] = value

    # overwrite with the config file if any
    if args.config is not None:
        try:
            load_into_settings(args.config, settings)
        except ValueError, e:
            print(e)
            sys.exit(1)

    # pass the args in the settings
    settings['args'] = args
    statsd = get_statsd_from_settings(settings.getsection('statsd'))

    # creating the proxy
    proxy_args = dict(proxy=settings['vaurien.proxy'],
                      backend=settings['vaurien.backend'],
                      settings=settings, statsd=statsd, logger=logger,
                      protocol=args.protocol)

    if args.http:
        # if we are using the http server, then we want to use the OnTheFly
        # proxy
        proxy = OnTheFlyProxy(**proxy_args)
        from vaurien.webserver import get_config
        from gevent.pywsgi import WSGIServer

        config = get_config()
        config.registry['proxy'] = proxy
        app = config.make_wsgi_app()

        # configure the web app logger
        # configure_logger(app.logger, args.loglevel, args.logoutput)

        # app.run(host=args.http_host, port=args.http_port)
        http_server = WSGIServer((args.http_host, args.http_port), app,
                                 log=DevNull())

        http_server.start()
        logger.info('Started the HTTP server: http://%s:%s' %
                    (args.http_host, args.http_port))
    else:
        # per default, we want to randomize
        proxy = RandomProxy(**proxy_args)

    try:
        proxy.serve_forever()
    except KeyboardInterrupt:
        sys.exit(0)
    finally:
        logger.info('Bye!')


if __name__ == '__main__':
    main()

########NEW FILE########
__FILENAME__ = support
import sys
import subprocess

from vaurien.webserver import get_config

from gevent.pywsgi import WSGIServer


class FakeProxy(object):
    """Fake proxy object, to mock the proxy in the tests"""

    def __init__(self, behaviors=None):
        self.behaviors = behaviors or ['default', 'blackout']
        self.behavior = 'default'
        self.behavior_options = {}

    def get_behavior(self):
        # return None as a callable, since this is for tests only.
        return None, self.behavior

    def set_behavior(self, name, **options):
        if name not in self.behaviors:
            raise KeyError(name)
        self.behavior = name
        self.behavior_options = options

    def get_behavior_names(self):
        return self.behaviors


def start_vaurien_httpserver(port):
    """Start a vaurien httpserver, controlling a fake proxy"""
    config = get_config()
    config.registry['proxy'] = FakeProxy()

    server = WSGIServer(('localhost', int(port)), config.make_wsgi_app(),
                        log=None)
    server.serve_forever()


def start_simplehttp_server(port=8888):
    cmd = [sys.executable, '-m', 'SimpleHTTPServer', str(port)]
    server = subprocess.Popen(cmd, stdout=subprocess.PIPE,
                              stderr=subprocess.PIPE)
    return server


if __name__ == '__main__':
    start_vaurien_httpserver(int(sys.argv[1]))

########NEW FILE########
__FILENAME__ = test_client
from subprocess import Popen
from unittest import TestCase
import sys
import time

from vaurienclient import Client


class TestClient(TestCase):
    def setUp(self):
        port = 8009
        cmd = '%s -m vaurien.tests.support %s' % (sys.executable, port)
        self.process = Popen(cmd.split(' '))

        # wait for the server to start
        time.sleep(1.)
        self.client = Client('localhost', port)

    def tearDown(self):
        self.process.terminate()
        self.process.wait()

    def test_set_valid_behavior(self):
        # check that we don't raise
        self.client.set_behavior('blackout')

    def test_set_invlid_behavior(self):
        self.assertRaises(ValueError, self.client.set_behavior,
                          'invalid_behavior')

    def test_get_default_behavior(self):
        # this should return the default behavior
        self.assertEquals(self.client.get_behavior(), 'default')

    def test_set_and_get_behavior(self):
        # after setting up the behavior, we should retrieve the informations
        # here
        self.client.set_behavior('blackout')
        self.assertEquals(self.client.get_behavior(), 'blackout')

    def test_set_behavior_with_options(self):
        self.client.set_behavior('blackout', foo='foo', bar='bar')
        self.assertEquals(self.client.get_behavior(), 'blackout')

    def test_list_behaviors(self):
        self.assertEquals(self.client.list_behaviors(),
                          ['default', 'blackout'])

########NEW FILE########
__FILENAME__ = test_config
from tempfile import mkstemp
from copy import copy
from unittest import TestCase
import sys
import os

from vaurien import proxy, run
from vaurien.run import main


_CONF = """\
[vaurien]
backend = 0.0.0.0:33

"""


class FakeProxy(object):

    args = kwargs = None

    def __init__(self, *args, **kwargs):
        FakeProxy.args = args
        FakeProxy.kwargs = kwargs

    def serve_forever(self):
        pass


class TestConfig(TestCase):
    def setUp(self):
        self.old = proxy.RandomProxy
        run.RandomProxy = proxy.RandomProxy = FakeProxy
        fd, self.config = mkstemp()
        os.close(fd)
        with open(self.config, 'w') as f:
            f.write(_CONF)

    def tearDown(self):
        run.RandomProxy = proxy.RandomProxy = self.old
        os.remove(self.config)

    def test_config(self):

        # make sure the config is taken into account
        old = copy(sys.argv)
        try:
            sys.argv = ['vaurien', '--config', self.config]
            main()
        finally:
            sys.argv[:] = old

        self.assertEqual(FakeProxy.kwargs['backend'], '0.0.0.0:33')

########NEW FILE########
__FILENAME__ = test_http_proxy
import unittest
import requests
import time

from vaurienclient import Client
from vaurien.util import start_proxy, stop_proxy
from vaurien.tests.support import start_simplehttp_server


_PROXY = 'http://localhost:8000'


# we should provide a way to set an option
# for all behaviors at once
#
_OPTIONS = ['--behavior-delay-sleep', '1']


class TestHttpProxy(unittest.TestCase):
    def setUp(self):
        self._proxy_pid = start_proxy(options=_OPTIONS, log_level='error',
                                      log_output='/dev/null',
                                      protocol='http')
        self._web = start_simplehttp_server()
        time.sleep(.3)
        try:
            if self._web.poll():
                raise ValueError("Could not start the proxy")

            self.client = Client()

            assert self.client.get_behavior() == 'dummy'
        except Exception:
            self.tearDown()
            raise

    def tearDown(self):
        stop_proxy(self._proxy_pid)
        self._web.terminate()

    def test_proxy(self):
        # let's do a few simple request first to make sure the proxy works
        self.assertEqual(self.client.get_behavior(), 'dummy')
        times = []
        for i in range(10):
            start = time.time()
            try:
                res = requests.get(_PROXY)
            finally:
                times.append(time.time() - start)

            self.assertEqual(res.status_code, 200)

        fastest = min(times)

        # now let's try the various behaviors
        with self.client.with_behavior('blackout'):
            # oh look we broke it
            self.assertRaises(requests.ConnectionError, requests.get, _PROXY)
            self.assertEqual(self.client.get_behavior(), 'blackout')

        with self.client.with_behavior('delay'):
            # should work but be slower
            start = time.time()
            try:
                res = requests.get(_PROXY)
            finally:
                duration = time.time() - start

            self.assertEqual(res.status_code, 200)
            self.assertTrue(duration > fastest + 1)

        # we should be back to normal
        self.assertEqual(self.client.get_behavior(), 'dummy')
        res = requests.get(_PROXY)
        self.assertEqual(res.status_code, 200)

########NEW FILE########
__FILENAME__ = test_http_server
from unittest import TestCase

import webtest

from vaurien.webserver import get_config
from vaurien.tests.support import FakeProxy


class TestHTTPServer(TestCase):
    def setUp(self):
        self.config = get_config()
        self.proxy = FakeProxy()
        self.config.registry['proxy'] = self.proxy

        self.app = self.config.make_wsgi_app()
        self.client = webtest.TestApp(self.app)

    def tearDown(self):
        self.app = None

    def test_behaviors_are_returned(self):
        # the behaviors should be returned as a list of behaviors, in json.
        res = self.client.get('/behaviors')
        self.assertEquals(res.json, {'behaviors': ['default', 'blackout']})

    def test_get_behavior(self):
        # test that we can know what is the behavior currently used
        res = self.client.get('/behavior')
        self.assertEquals(res.json, {'behavior': self.proxy.behavior})

    def test_set_unknown_behavior(self):
        # we should get errors back from the server if we try to set a behavior
        # which doesn't exist
        res = self.client.put_json('/behavior', {'name': 'doesnt_exist'},
                                   status=400)
        errors = res.json
        self.assertEquals(errors['status'], 'error')
        self.assertEquals(len(errors['errors']), 1)
        self.assertEquals(errors['errors'][0]['location'], 'body')
        self.assertEquals(errors['errors'][0]['name'], 'name')

    def test_set_valid_behavior_name(self):
        # it's possible to only set a behavior with its name
        behavior_name = self.proxy.behaviors[-1]
        res = self.client.put_json('/behavior', {'name': behavior_name})
        self.assertEquals(res.json, {'status': 'ok'})
        self.assertEquals(self.proxy.behavior, behavior_name)

    def test_set_valid_behavior_with_options(self):
        # it's possible to pass options with the behavior
        behavior_name = self.proxy.behaviors[-1]
        behavior = {'name': behavior_name}
        behavior_options = {'foo': 'bar', 'baz': 'babar'}
        behavior.update(behavior_options)
        res = self.client.put_json('/behavior', behavior)
        self.assertEquals(res.json, {'status': 'ok'})
        self.assertEquals(self.proxy.behavior, behavior_name)
        self.assertEquals(self.proxy.behavior_options, behavior_options)

########NEW FILE########
__FILENAME__ = test_proxy
import unittest
import requests
import time

from vaurienclient import Client
from vaurien.util import start_proxy, stop_proxy
from vaurien.tests.support import start_simplehttp_server


_PROXY = 'http://localhost:8000'


class TestSimpleProxy(unittest.TestCase):
    def setUp(self):
        self._proxy_pid = start_proxy(log_output='/dev/null',
                                      log_level='error')
        self._web = start_simplehttp_server()
        time.sleep(.2)
        try:
            if self._web.poll():
                raise ValueError("Could not start the proxy")

            self.client = Client()

            assert self.client.get_behavior() == 'dummy'
        except Exception:
            self.tearDown()
            raise

    def tearDown(self):
        stop_proxy(self._proxy_pid)
        self._web.terminate()

    def test_existing_behaviors(self):
        wanted = ['blackout', 'delay', 'dummy', 'error', 'hang']
        self.assertEqual(self.client.list_behaviors(), wanted)

    def test_proxy(self):
        # let's do a few simple request first to make sure the proxy works
        self.assertEqual(self.client.get_behavior(), 'dummy')
        for i in range(10):
            res = requests.get(_PROXY)
            self.assertEqual(res.status_code, 200)

        # now let's add a bit of havoc
        with self.client.with_behavior('blackout'):
            # oh look we broke it
            self.assertRaises(requests.ConnectionError, requests.get, _PROXY)
            self.assertEqual(self.client.get_behavior(), 'blackout')

        # we should be back to normal
        self.assertEqual(self.client.get_behavior(), 'dummy')
        res = requests.get(_PROXY)
        self.assertEqual(res.status_code, 200)

########NEW FILE########
__FILENAME__ = test_util
import unittest
from vaurien.util import chunked


class TestUtil(unittest.TestCase):

    def test_chunked(self):
        self.assertEqual(sum(list(chunked(7634, 2049))), 7634)

########NEW FILE########
__FILENAME__ = util
import subprocess
import sys


def start_web_server(port=8888):
    cmd = [sys.executable, '-m', 'SimpleHTTPServer', str(port)]
    server = subprocess.Popen(cmd, stdout=subprocess.PIPE,
                              stderr=subprocess.PIPE)
    return server

########NEW FILE########
__FILENAME__ = util
from errno import EAGAIN, EWOULDBLOCK
import sys
import time
import subprocess

from gevent.socket import gethostbyname
from gevent.socket import error
from gevent.socket import wait_read
from gevent import sleep


class ImportStringError(ImportError):
    """Provides information about a failed :func:`import_string` attempt."""

    #: String in dotted notation that failed to be imported.
    import_name = None
    #: Wrapped exception.
    exception = None

    def __init__(self, import_name, exception):
        self.import_name = import_name
        self.exception = exception

        msg = (
            'import_string() failed for %r. Possible reasons are:\n\n'
            '- missing __init__.py in a package;\n'
            '- package or module path not included in sys.path;\n'
            '- duplicated package or module name taking precedence in '
            'sys.path;\n'
            '- missing module, class, function or variable;\n\n'
            'Debugged import:\n\n%s\n\n'
            'Original exception:\n\n%s: %s')

        name = ''
        tracked = []
        for part in import_name.replace(':', '.').split('.'):
            name += (name and '.') + part
            imported = import_string(name, silent=True)
            if imported:
                tracked.append((name, getattr(imported, '__file__', None)))
            else:
                track = ['- %r found in %r.' % (n, i) for n, i in tracked]
                track.append('- %r not found.' % name)
                msg = msg % (import_name, '\n'.join(track),
                             exception.__class__.__name__, str(exception))
                break

        ImportError.__init__(self, msg)

    def __repr__(self):
        return '<%s(%r, %r)>' % (self.__class__.__name__, self.import_name,
                                 self.exception)


def import_string(import_name, silent=False):
    """Imports an object based on a string.  This is useful if you want to
    use import paths as endpoints or something similar.  An import path can
    be specified either in dotted notation (``xml.sax.saxutils.escape``)
    or with a colon as object delimiter (``xml.sax.saxutils:escape``).

    If `silent` is True the return value will be `None` if the import fails.

    For better debugging we recommend the new :func:`import_module`
    function to be used instead.

    :param import_name: the dotted name for the object to import.
    :param silent: if set to `True` import errors are ignored and
                   `None` is returned instead.
    :return: imported object
    """
    # force the import name to automatically convert to strings
    if isinstance(import_name, unicode):
        import_name = str(import_name)
    try:
        if ':' in import_name:
            module, obj = import_name.split(':', 1)
        elif '.' in import_name:
            module, obj = import_name.rsplit('.', 1)
        else:
            return __import__(import_name)
            # __import__ is not able to handle unicode strings in the fromlist
        # if the module is a package
        if isinstance(obj, unicode):
            obj = obj.encode('utf-8')
        try:
            return getattr(__import__(module, None, None, [obj]), obj)
        except (ImportError, AttributeError):
            # support importing modules not yet set up by the parent module
            # (or package for that matter)
            modname = module + '.' + obj
            __import__(modname)
            return sys.modules[modname]
    except ImportError, e:
        if not silent:
            raise ImportStringError(import_name, e), None, sys.exc_info()[2]


def parse_address(address):
    try:
        hostname, port = address.rsplit(':', 1)
        port = int(port)
    except ValueError:
        sys.exit('Expected HOST:PORT: %r' % address)
    return gethostbyname(hostname), port


def get_prefixed_sections(settings, prefix, logger=None):
    """Return a dict containing all the behaviors that are defined in the
    settings, in addition to all the behaviors of vaurien
    """
    behaviors = {}
    if logger is None:
        from vaurien import logger

    for section in settings.sections():
        if section.startswith('%s.' % prefix):
            prefixed_name = section[len('%s.' % prefix):]

            # have a look if we have a section named behavior:{behavior}
            settings = settings.getsection('%s.%s' % (prefix, prefixed_name))
            prefixed_location = settings.get('callable', None)
            if not prefixed_location:
                logger.warning('callable not found for %s' % prefixed_name)
                continue
            behavior = import_string(prefixed_location)
            behaviors[prefixed_name] = behavior
    return behaviors


_PROXIES = {}


def start_proxy(proxy_host='localhost', proxy_port=8000,
                backend_host='localhost', backend_port=8888,
                protocol='tcp',
                http=True, warmup=2,
                http_host='localhost', http_port=8080, options=None,
                log_level='info', log_output='-'):
    """Starts a proxy
    """
    proxy = '%s:%d' % (proxy_host, proxy_port)
    backend = '%s:%d' % (backend_host, backend_port)

    cmd = [sys.executable, '-m', 'vaurien.run', '--backend', backend,
           '--proxy', proxy, '--log-level', log_level, '--log-output',
           log_output, '--protocol', protocol]

    if http:
        cmd.extend(['--http', '--http-host', http_host,
                    '--http-port', str(http_port)])

    if options is not None:
        cmd.extend(options)

    proc = subprocess.Popen(cmd)
    time.sleep(warmup)
    if proc.poll():
        raise ValueError("Could not start the proxy")

    _PROXIES[proc.pid] = proc
    return proc.pid


def stop_proxy(pid):
    if pid not in _PROXIES:
        raise ValueError("Not found")
    proc = _PROXIES.pop(pid)
    proc.terminate()
    proc.wait()


def chunked(total, chunk):
    if total <= chunk:
        yield total
    else:
        data = total
        while True:
            if data > chunk:
                yield chunk
                data -= chunk
            else:
                yield data
                break


def get_data(sock, buffer=1024):
    while True:
        try:
            return sock.recv(buffer)
        except error, e:
            if e.args[0] not in (EWOULDBLOCK, EAGAIN):
                raise
            timeout = sock.gettimeout()
            if timeout == 0:
                # we are in async mode here so we just need to switch
                sleep(0)
            else:
                wait_read(sock.fileno(), timeout=timeout)


def extract_settings(args, prefix, name):
    settings = {}
    prefix = '%s_%s_' % (prefix, name)

    for arg in dir(args):
        if not arg.startswith(prefix):
            continue
        settings[arg[len(prefix):]] = getattr(args, arg)

    return settings

########NEW FILE########
__FILENAME__ = webserver
from cornice.service import Service
from pyramid.config import Configurator
from pyramid.events import NewRequest

behavior = Service('behavior', path='/behavior')
behaviors = Service('behaviors', path='/behaviors')


@behavior.put()
def set_behavior(request):
    try:
        data = request.json
        name = data['name']
    except ValueError:
        request.errors.add('body', '',
                           'the value is not a valid json object')
    except KeyError:
        request.errors.add('body', '',
                           'the value should contain a "name" key')
    else:
        try:
            request.proxy.set_behavior(**data)
        except KeyError:
            request.errors.add('body', 'name',
                               "the '%s' behavior does not exist" % name)
    return {'status': 'ok'}


@behavior.get()
def get_behavior(request):
    return {'behavior': request.proxy.get_behavior()[1]}


@behaviors.get()
def get_behaviors(request):
    return {'behaviors': request.proxy.get_behavior_names()}


def add_proxy_to_request(event):
    event.request.proxy = event.request.registry['proxy']


def get_config(global_config=None, **settings):
    if global_config is None:
        global_config = {}
    config = Configurator(settings=settings)
    config.include('cornice')
    config.scan('vaurien.webserver')

    config.add_subscriber(add_proxy_to_request, NewRequest)
    return config

########NEW FILE########
__FILENAME__ = _pool
from gevent.queue import PriorityQueue, Empty
import time
import contextlib
import sys

# Sentinel used to mark an empty slot in the MCClientPool queue.
# Using sys.maxint as the timestamp ensures that empty slots will always
# sort *after* live connection objects in the queue.
EMPTY_SLOT = sys.maxint, None


class FactoryPool(object):

    def __init__(self, factory, maxsize=200, timeout=60):
        self.factory = factory
        self.maxsize = maxsize
        self.timeout = timeout
        self.clients = PriorityQueue(maxsize)
        # If there is a maxsize, prime the queue with empty slots.
        if maxsize is not None:
            for _ in xrange(maxsize):
                self.clients.put(EMPTY_SLOT)

    @contextlib.contextmanager
    def reserve(self):
        """Context-manager to obtain a Client object from the pool."""
        ts, client = self._checkout_connection()
        try:
            yield client
        finally:
            self._checkin_connection(ts, client)

    def _checkout_connection(self):
        # If there's no maxsize, no need to block waiting for a connection.
        blocking = self.maxsize is not None

        # Loop until we get a non-stale connection, or we create a new one.
        while True:
            try:
                ts, client = self.clients.get(blocking)
            except Empty:
                # No maxsize and no free connections, create a new one.
                # XXX TODO: we should be using a monotonic clock here.
                # see http://www.python.org/dev/peps/pep-0418/
                now = int(time.time())
                return now, self.factory()
            else:
                now = int(time.time())
                # If we got an empty slot placeholder, create a new connection.
                if client is None:
                    return now, self.factory()
                # If the connection is not stale, go ahead and use it.
                if ts + self.timeout > now:
                    return ts, client
                # Otherwise, the connection is stale.
                # Close it, push an empty slot onto the queue, and retry.
                if hasattr(client, 'disconnect'):
                    client.disconnect()

                self.clients.put(EMPTY_SLOT)
                continue

    def _checkin_connection(self, ts, client):
        """Return a connection to the pool."""
        if hasattr(client, '_closed') and client._closed:
            self.clients.put(EMPTY_SLOT)
            return

        # If the connection is now stale, don't return it to the pool.
        # Push an empty slot instead so that it will be refreshed when needed.
        now = int(time.time())
        if ts + self.timeout > now:
            self.clients.put((ts, client))
        else:
            if self.maxsize is not None:
                self.clients.put(EMPTY_SLOT)

########NEW FILE########
