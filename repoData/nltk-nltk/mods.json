[
    "nltk.corpus.reader.framenet",
    "all",
    "senna",
    "misc.minimalset",
    "nltk.corpus.reader.pl196x",
    "nltk.internals",
    "bracket_parse",
    "nltk.corpus.reader.tagged",
    "stem.wordnet",
    "classify.util",
    "nltk.ccg",
    "school.words",
    "nltk.corpus.reader.ipipan",
    "rte_classify",
    "nltk.test.unit",
    "aligned",
    "inference.nonmonotonic",
    "parse.featurechart",
    "ccg.chart",
    "discourse_fixt",
    "nltk.tag.brill_trainer_orig",
    "nltk.chat.zen",
    "test.unit.test_corpus_views",
    "text",
    "nltk.chat.suntsu",
    "gale_church",
    "nltk.align.util",
    "inference.discourse",
    "app.wordnet_app",
    "examples.semantics.model0",
    "examples.semantics.model1",
    "nltk.classify.decisiontree",
    "util",
    "string_category",
    "nltk.corpus.reader.aligned",
    "categories",
    "nltk.tag",
    "school",
    "nltk.inference.prover9",
    "corpus.reader.semcor",
    "wsd",
    "sem.hole",
    "doctest_nose_plugin",
    "bleu",
    "parse.util",
    "reader.cmudict",
    "nltk.parse.dependencygraph",
    "nltk.tokenize.simple",
    "nltk.draw.tree",
    "cfg",
    "nltk.app.rdparser_app",
    "brill",
    "nltk.tag.brill",
    "nltk.app",
    "nltk.tag.hunpos",
    "reader.conll",
    "timit",
    "chunk.util",
    "compat",
    "draw.table",
    "nltk.featstruct",
    "classify.scikitlearn",
    "corpus.reader.aligned",
    "nltk.corpus.reader.lin",
    "eliza",
    "nltk.parse",
    "acl-08.grammar2",
    "acl-08.grammar1",
    "reader.plaintext",
    "chat.suntsu",
    "positivenaivebayes",
    "indian",
    "test.unit.test_corpora",
    "template",
    "nltk.cluster",
    "test.semantics_fixt",
    "corpus.reader.pl196x",
    "nltk.tbl.template",
    "segmentation",
    "reader.bracket_parse",
    "cluster.em",
    "test.classify_fixt",
    "downloader",
    "nltk.parse.pchart",
    "reader.verbnet",
    "test.align_fixt",
    "ccg.combinator",
    "nltk.inference.mace",
    "nltk.metrics.segmentation",
    "reader.util",
    "misc.sort",
    "metrics.agreement",
    "search",
    "drt",
    "cluster.util",
    "corpus.reader.util",
    "concordance_app",
    "rslp",
    "corpus.reader.string_category",
    "corpus.reader.lin",
    "nltk.test.gluesemantics_malt_fixt",
    "inference",
    "app",
    "nltk.sem.glue",
    "corpus.reader.plaintext",
    "api",
    "regexp",
    "tools",
    "unit",
    "nltk.draw.cfg",
    "nltk.corpus.reader.verbnet",
    "parse.malt",
    "nltk.classify.maxent",
    "tag.mapping",
    "gaac",
    "reader.framenet",
    "nltk.test.all",
    "sem.boxer",
    "demo",
    "tag.hunpos",
    "corpus.reader.ieer",
    "nltk.classify.positivenaivebayes",
    "sort",
    "collocations_app",
    "senseval",
    "featurechart",
    "reader.wordlist",
    "sem.cooper_storage",
    "nltk.tokenize.regexp",
    "nltk.sem.linearlogic",
    "stem.porter",
    "test.unit.utils",
    "stem.regexp",
    "school.generate",
    "tnt",
    "test.unit.test_naivebayes",
    "reader.aligned",
    "nltk.corpus.europarl_raw",
    "cmudict",
    "malt",
    "nltk.chat.eliza",
    "nltk.misc.sort",
    "nltk.parse.earleychart",
    "nltk.parse.nonprojectivedependencyparser",
    "spearman",
    "examples.school.parser",
    "ibm2",
    "ibm3",
    "ibm1",
    "nltk.chat.iesha",
    "test.wordnet_fixt",
    "wordnet_app",
    "corpus.reader.conll",
    "tag",
    "nltk.stem.api",
    "draw.dispersion",
    "nltk.cluster.util",
    "nltk.corpus.reader.wordlist",
    "nltk.classify.weka",
    "inference_fixt",
    "nltk.inference.tableau",
    "tableau",
    "reader.toolbox",
    "reader.api",
    "nltk.draw.util",
    "nltk.corpus.reader.switchboard",
    "classify",
    "examples.school.parse1",
    "examples.school.parse2",
    "examples.school.parse3",
    "rude",
    "sem.drt",
    "corpus.reader.wordnet",
    "mapping",
    "align.ibm3",
    "align.ibm2",
    "align.ibm1",
    "data",
    "test.runtests",
    "nltk.parse.api",
    "nltk.chunk.util",
    "metrics.scores",
    "nltk",
    "tagged",
    "corpus.reader.cmudict",
    "ieer",
    "zen",
    "feature",
    "chunk.regexp",
    "nltk.tag.stanford",
    "reader.timit",
    "earleychart",
    "parse.projectivedependencyparser",
    "nltk.misc.minimalset",
    "reader.nombank",
    "nltk.app.chartparser_app",
    "nltk.collocations",
    "corpus.reader.udhr",
    "collocations",
    "nltk.parse.util",
    "nltk.classify.tadm",
    "classify.maxent",
    "nltk.classify.megam",
    "test.doctest_nose_plugin",
    "nltk.test.inference_fixt",
    "chunk.api",
    "nltk.test.unit.test_hmm",
    "nltk.parse.shiftreduce",
    "udhr",
    "propbank",
    "pycomplete",
    "nltk.inference",
    "nltk.align",
    "nemo_app",
    "misc",
    "app.rdparser_app",
    "kmeans",
    "snowball",
    "test.compat_fixt",
    "nltk.cluster.api",
    "association",
    "nltk.chat.util",
    "tadm",
    "examples.school.count",
    "grammar",
    "nltk.cluster.kmeans",
    "parse.api",
    "suntsu",
    "nltk.draw.table",
    "test.probability_fixt",
    "tag.senna",
    "chat.zen",
    "em",
    "nltk.test.unit.utils",
    "tokenize.simple",
    "corpus.europarl_raw",
    "nltk.test.unit.test_tag",
    "chunk",
    "stem.rslp",
    "childes",
    "parse2",
    "unit.test_corpora",
    "nltk.lazyimport",
    "segmentation_fixt",
    "nltk.app.srparser_app",
    "nltk.examples",
    "corpus.reader.wordlist",
    "nltk.test.childes_fixt",
    "nltk.test.wordnet_fixt",
    "nltk.test.unit.test_naivebayes",
    "reader",
    "nltk.test.semantics_fixt",
    "decorators",
    "parse.recursivedescent",
    "classify.naivebayes",
    "nltk.ccg.api",
    "punkt",
    "test.gluesemantics_malt_fixt",
    "app.collocations_app",
    "nltk.corpus.reader.chunked",
    "nltk.corpus.reader.timit",
    "nltk.sem",
    "nltk.corpus.reader.indian",
    "generate",
    "reader.rte",
    "ppattach",
    "grammar1",
    "corpus.reader.sinica_treebank",
    "test_corpora",
    "nltk.book",
    "nltk.test.unit.test_classify",
    "app.chartparser_app",
    "nltk.metrics.agreement",
    "nltk.parse.malt",
    "parse.earleychart",
    "unit.test_collocations",
    "test_naivebayes",
    "ccg.api",
    "corpus.reader.api",
    "probability",
    "combinator",
    "nltk.metrics",
    "parse.dependencygraph",
    "nltk.tbl.rule",
    "featstruct",
    "corpus.reader.tagged",
    "stem.snowball",
    "nltk.tag.api",
    "classify.decisiontree",
    "tokenize.treebank",
    "examples.school",
    "reader.propbank",
    "stem.api",
    "inference.tableau",
    "unit.test_corpus_views",
    "weka",
    "chasen",
    "nltk.corpus.reader.ycoe",
    "nltk.test.unit.test_corpora",
    "brill_trainer",
    "run_doctests",
    "nltk.classify.api",
    "nltk.parse.stanford",
    "tools.run_doctests",
    "corpus.reader.childes",
    "reader.chasen",
    "corpus",
    "inference.api",
    "cluster.api",
    "inference.prover9",
    "gluesemantics_malt_fixt",
    "childes_fixt",
    "reader.tagged",
    "nltk.app.chunkparser_app",
    "brill_trainer_orig",
    "megam",
    "classify.svm",
    "nltk.corpus",
    "nltk.chunk.regexp",
    "reader.semcor",
    "semantics",
    "distance",
    "test.inference_fixt",
    "nltk.tree",
    "tree",
    "nltk.sem.util",
    "reader.ycoe",
    "nltk.corpus.reader.bnc",
    "nltk.metrics.confusionmatrix",
    "nltk.corpus.reader.nps_chat",
    "corpus.reader.framenet",
    "nltk.tokenize",
    "nltk.stem.wordnet",
    "prover9",
    "nltk.sem.relextract",
    "xmldocs",
    "plaintext",
    "confusionmatrix",
    "relextract",
    "europarl_raw",
    "erroranalysis",
    "wordfinder",
    "nltk.corpus.reader.plaintext",
    "school.parser",
    "test.unit.test_seekable_unicode_stream_reader",
    "test_corpus_views",
    "nltk.corpus.reader.rte",
    "lin",
    "tbl.feature",
    "semcor",
    "nltk.classify.scikitlearn",
    "nltk.corpus.reader.childes",
    "corpus.util",
    "test_classify",
    "nltk.corpus.reader.knbc",
    "linearlogic",
    "nltk.corpus.reader.ppattach",
    "nltk.grammar",
    "nltk.corpus.reader.semcor",
    "chart",
    "metrics",
    "mace",
    "reader.udhr",
    "school.parse1",
    "school.parse2",
    "school.parse3",
    "corpus.reader.ppattach",
    "misc.wordfinder",
    "svnmime",
    "nltk.corpus.reader.senseval",
    "chat.eliza",
    "unit.test_2x_compat",
    "knbc",
    "test_hmm",
    "nltk.app.wordnet_app",
    "examples.pt",
    "corpus.reader.nps_chat",
    "nltk.metrics.association",
    "nltk.align.api",
    "corpus_fixt",
    "nltk.tokenize.util",
    "rte",
    "reader.chunked",
    "nps_chat",
    "lexicon",
    "nltk.parse.chart",
    "nltk.jsontags",
    "nltk.tokenize.treebank",
    "treebank",
    "tbl.api",
    "nltk.metrics.distance",
    "corpus.reader.bracket_parse",
    "test_2x_compat",
    "nltk.stem.porter",
    "syn2sem",
    "sem.relextract",
    "acl-08",
    "nltk.tag.hmm",
    "drt_glue_demo",
    "chunkparser_app",
    "tokenize.util",
    "reader.lin",
    "nltk.chat.rude",
    "corpus.reader.knbc",
    "draw.tree",
    "semantics.model0",
    "semantics.model1",
    "reader.switchboard",
    "sem.chat80",
    "test.unit.test_stem",
    "stem.lancaster",
    "tag.util",
    "nltk.app.collocations_app",
    "test.unit.test_collocations",
    "tbl.erroranalysis",
    "tbl",
    "words",
    "toolbox",
    "corpus.reader.nombank",
    "nltk.test.compat_fixt",
    "unit.utils",
    "corpus.reader.dependency",
    "hole",
    "reader.string_category",
    "nonmonotonic_fixt",
    "nltk.sem.evaluate",
    "nltk.treetransforms",
    "test_tag",
    "nltk.classify.svm",
    "nltk.corpus.reader.toolbox",
    "compat_fixt",
    "sem.lfg",
    "nltk.tag.util",
    "corpus.reader.verbnet",
    "tbl.rule",
    "sem",
    "chat80",
    "verbnet",
    "lancaster",
    "nltk.chunk.api",
    "classify_fixt",
    "nltk.test.corpus_fixt",
    "classify.positivenaivebayes",
    "nltk.corpus.reader.nombank",
    "app.srparser_app",
    "web.conf",
    "tokenize.punkt",
    "unit.test_tag",
    "nltk.text",
    "test.segmentation_fixt",
    "hunpos",
    "parse.nonprojectivedependencyparser",
    "chartparser_app",
    "acl-08.police",
    "nltk.tbl.api",
    "nltk.tokenize.texttiling",
    "dependencygraph",
    "classify.rte_classify",
    "nltk.corpus.reader.cmudict",
    "police",
    "test_seekable_unicode_stream_reader",
    "texttiling",
    "parse.pchart",
    "reader.childes",
    "sem.evaluate",
    "nltk.probability",
    "maxent",
    "reader.dependency",
    "logic",
    "nltk.tag.brill_trainer",
    "papers.acl-08",
    "metrics.confusionmatrix",
    "cluster.gaac",
    "nltk.tbl.demo",
    "draw.cfg",
    "simple",
    "nltk.corpus.reader.bracket_parse",
    "nltk.corpus.reader.util",
    "nltk.util",
    "table",
    "nltk.classify",
    "pt",
    "nltk.corpus.reader.dependency",
    "nltk.test.runtests",
    "nltk.misc.babelfish",
    "nombank",
    "emacs.pycomplete",
    "scikitlearn",
    "nltk.chunk",
    "sem.linearlogic",
    "internals",
    "reader.indian",
    "nltk.corpus.reader.string_category",
    "nltk.corpus.reader.chasen",
    "nltk.tbl.feature",
    "global_replace",
    "cluster.kmeans",
    "nltk.data",
    "metrics.distance",
    "corpus.reader.rte",
    "test.unit.test_classify",
    "iesha",
    "reader.wordnet",
    "app.concordance_app",
    "sem.logic",
    "test.portuguese_en_fixt",
    "align",
    "nltk.corpus.reader.api",
    "nltk.metrics.spearman",
    "nltk.test.unit.test_collocations",
    "tools.svnmime",
    "nltk.app.wordfreq_app",
    "nltk.inference.nonmonotonic",
    "nltk.test.align_fixt",
    "chunked",
    "inference.mace",
    "parser",
    "nltk.tag.tnt",
    "ycoe",
    "nltk.align.ibm1",
    "nltk.corpus.reader.propbank",
    "nltk.tbl.erroranalysis",
    "utils",
    "unit.test_hmm",
    "nltk.ccg.chart",
    "parse",
    "cluster",
    "papers.acl-08.grammar1",
    "tools.find_deprecated",
    "corpus.reader.xmldocs",
    "papers.acl-08.grammar2",
    "nltk.app.nemo_app",
    "semantics_fixt",
    "reader.sinica_treebank",
    "wordnet",
    "nltk.test.doctest_nose_plugin",
    "nltk.test.segmentation_fixt",
    "nltk.downloader",
    "nltk.stem.regexp",
    "test_stem",
    "nltk.corpus.reader.wordnet",
    "discourse",
    "test_collocations",
    "nltk.tokenize.sexpr",
    "test.discourse_fixt",
    "tokenize.sexpr",
    "sem.skolemize",
    "nltk.inference.resolution",
    "draw.util",
    "nltk.examples.pt",
    "chat.iesha",
    "skolemize",
    "app.chunkparser_app",
    "nltk.test",
    "decisiontree",
    "grammar2",
    "classify.api",
    "nltk.ccg.combinator",
    "pchart",
    "nltk.parse.projectivedependencyparser",
    "nltk.chunk.named_entity",
    "viterbi",
    "corpus.reader.ipipan",
    "nltk.classify.util",
    "papers.acl-08.police",
    "ccg",
    "nltk.align.bleu",
    "corpus.reader.indian",
    "tag.brill_trainer_orig",
    "classify.megam",
    "unit.test_classify",
    "recursivedescent",
    "lazyimport",
    "tokenize.texttiling",
    "nltk.test.classify_fixt",
    "nltk.test.probability_fixt",
    "glue",
    "examples.semantics",
    "misc.chomsky",
    "corpus.reader.chasen",
    "web",
    "parse.stanford",
    "unit.test_naivebayes",
    "sinica_treebank",
    "help",
    "tag.api",
    "nltk.sem.drt_glue_demo",
    "sem.util",
    "metrics.spearman",
    "bnc",
    "wordnet_fixt",
    "nltk.wsd",
    "test.unit.test_hmm",
    "nltk.app.concordance_app",
    "nltk.misc.chomsky",
    "sequential",
    "reader.nps_chat",
    "evaluate",
    "papers",
    "stem.isri",
    "classify.weka",
    "nltk.chat",
    "boxer",
    "align.bleu",
    "nltk.sem.logic",
    "tag.sequential",
    "nltk.tag.mapping",
    "corpus.reader.chunked",
    "shiftreduce",
    "rdparser_app",
    "chat.rude",
    "corpus.reader.bnc",
    "classify.tadm",
    "nltk.corpus.reader.ieer",
    "app.wordfreq_app",
    "nltk.corpus.util",
    "tag.brill",
    "reader.ieer",
    "nltk.parse.featurechart",
    "nltk.classify.naivebayes",
    "projectivedependencyparser",
    "framenet",
    "tag.hmm",
    "nltk.cluster.gaac",
    "nltk_term_index",
    "reader.pl196x",
    "tokenize.api",
    "nltk.test.discourse_fixt",
    "parse.viterbi",
    "examples",
    "align.api",
    "nltk.tbl",
    "conll",
    "school.categories",
    "nltk.test.portuguese_en_fixt",
    "corpus.reader.senseval",
    "nltk.stem.isri",
    "find_deprecated",
    "nltk.sem.skolemize",
    "chat.util",
    "nltk.test.unit.test_corpus_views",
    "srparser_app",
    "naivebayes",
    "nltk.compat",
    "examples.school.words",
    "nltk.sem.cooper_storage",
    "porter",
    "corpus.reader.timit",
    "nltk.test.nonmonotonic_fixt",
    "tokenize.regexp",
    "corpus.reader",
    "nltk.sem.lfg",
    "misc.babelfish",
    "agreement",
    "stem",
    "parse.shiftreduce",
    "nltk.draw.dispersion",
    "nltk.inference.api",
    "app.nemo_app",
    "treetransforms",
    "ccg.lexicon",
    "test.corpus_fixt",
    "nltk.parse.viterbi",
    "chomsky",
    "unit.test_stem",
    "nltk.help",
    "dependency",
    "reader.ppattach",
    "align.gale_church",
    "sexpr",
    "lfg",
    "inference.resolution",
    "nltk.stem.snowball",
    "minimalset",
    "cooper_storage",
    "reader.senseval",
    "nltk.cluster.em",
    "ipipan",
    "align_fixt",
    "corpus.reader.propbank",
    "nltk.corpus.reader.xmldocs",
    "nltk.ccg.lexicon",
    "dispersion",
    "nltk.tokenize.stanford",
    "emacs",
    "test.nonmonotonic_fixt",
    "nltk.sem.hole",
    "parse.generate",
    "school.search",
    "nltk.test.unit.test_stem",
    "examples.school.search",
    "nltk.metrics.scores",
    "metrics.association",
    "corpus.reader.switchboard",
    "nltk.sem.drt",
    "tokenize",
    "reader.knbc",
    "examples.school.categories",
    "tools.nltk_term_index",
    "isri",
    "switchboard",
    "nltk.corpus.reader.conll",
    "nltk.tokenize.punkt",
    "tag.tnt",
    "count",
    "corpus.reader.ycoe",
    "nltk.parse.generate",
    "stanford",
    "conf",
    "nltk.sem.chat80",
    "unit.test_seekable_unicode_stream_reader",
    "test.childes_fixt",
    "wordfreq_app",
    "semantics.syn2sem",
    "tokenize.stanford",
    "nltk.stem.rslp",
    "align.util",
    "nltk.test.unit.test_2x_compat",
    "pl196x",
    "nltk.parse.recursivedescent",
    "nonprojectivedependencyparser",
    "model1",
    "model0",
    "nltk.tag.senna",
    "nltk.tag.sequential",
    "nltk.corpus.reader",
    "nltk.inference.discourse",
    "nltk.align.ibm3",
    "nltk.align.ibm2",
    "chat",
    "reader.xmldocs",
    "test.unit.test_2x_compat",
    "sem.drt_glue_demo",
    "nltk.classify.rte_classify",
    "nltk.misc.wordfinder",
    "test.all",
    "examples.school.generate",
    "metrics.segmentation",
    "nltk.toolbox",
    "nltk.test.unit.test_seekable_unicode_stream_reader",
    "nltk.misc",
    "book",
    "nltk.align.gale_church",
    "probability_fixt",
    "test",
    "nltk.tokenize.api",
    "nonmonotonic",
    "corpus.reader.toolbox",
    "wordlist",
    "tbl.demo",
    "draw",
    "test.unit",
    "parse1",
    "parse3",
    "nltk.stem",
    "nltk.corpus.reader.udhr",
    "tag.brill_trainer",
    "jsontags",
    "nltk.stem.lancaster",
    "portuguese_en_fixt",
    "nltk.draw",
    "scores",
    "reader.ipipan",
    "reader.bnc",
    "nltk.sem.boxer",
    "nltk.corpus.reader.sinica_treebank",
    "tag.stanford",
    "sem.glue",
    "svm",
    "parse.chart",
    "tbl.template",
    "hmm",
    "resolution",
    "school.count",
    "rule",
    "tools.global_replace",
    "chunk.named_entity",
    "named_entity",
    "runtests",
    "examples.semantics.syn2sem",
    "babelfish",
    "nltk.decorators",
    "test.unit.test_tag"
]