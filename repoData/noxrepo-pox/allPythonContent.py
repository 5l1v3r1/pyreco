__FILENAME__ = debug-pox
pox.py
########NEW FILE########
__FILENAME__ = skeleton
# Copyright 2013 <Your Name Here>
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at:
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""
A skeleton POX component

You can customize this to do whatever you like.  Don't forget to
adjust the Copyright above, and to delete the Apache license if you
don't want to release under Apache (but consider doing so!).

Rename this file to whatever you like, .e.g., mycomponent.py.  You can
then invoke it with "./pox.py mycomponent" if you leave it in the
ext/ directory.

Implement a launch() function (as shown below) which accepts commandline
arguments and starts off your component (e.g., by listening to events).

Edit this docstring and your launch function's docstring.  These will
show up when used with the help component ("./pox.py help --mycomponent").
"""

# Import some POX stuff
from pox.core import core                     # Main POX object
import pox.openflow.libopenflow_01 as of      # OpenFlow 1.0 library
import pox.lib.packet as pkt                  # Packet parsing/construction
from pox.lib.addresses import EthAddr, IPAddr # Address types
import pox.lib.util as poxutil                # Various util functions
import pox.lib.revent as revent               # Event library
import pox.lib.recoco as recoco               # Multitasking library

# Create a logger for this component
log = core.getLogger()


def _go_up (event):
  # Event handler called when POX goes into up state
  # (we actually listen to the event in launch() below)
  log.info("Skeleton application ready (to do nothing).")


@poxutil.eval_args
def launch (foo, bar = False):
  """
  The default launcher just logs its arguments
  """
  # When your component is specified on the commandline, POX automatically
  # calls this function.

  # Add whatever parameters you want to this.  They will become
  # commandline arguments.  You can specify default values or not.
  # In this example, foo is required and bar is not.  You may also
  # specify a keyword arguments catch-all (e.g., **kwargs).

  # For example, you can execute this component as:
  # ./pox.py skeleton --foo=3 --bar=4

  # Note that arguments passed from the commandline are ordinarily
  # always strings, and it's up to you to validate and convert them.
  # The one exception is if a user specifies the parameter name but no
  # value (e.g., just "--foo").  In this case, it receives the actual
  # Python value True.
  # The @pox.util.eval_args decorator interprets them as if they are
  # Python literals.  Even things like --foo=[1,2,3] behave as expected.
  # Things that don't appear to be Python literals are left as strings.

  # If you want to be able to invoke the component multiple times, add
  # __INSTANCE__=None as the last parameter.  When multiply-invoked, it
  # will be passed a tuple with the following:
  # 1. The number of this instance (0...n-1)
  # 2. The total number of instances for this module
  # 3. True if this is the last instance, False otherwise
  # The last is just a comparison between #1 and #2, but is convenient.

  log.warn("Foo: %s (%s)", foo, type(foo))
  log.warn("Bar: %s (%s)", bar, type(bar))

  core.addListenerByName("UpEvent", _go_up)


def breakfast ():
  """
  Serves a Pythonic breakfast
  """
  # You can invoke other functions from the commandline too.  We call
  # these multiple or alternative launch functions.  To execute this
  # one, you'd do:
  # ./pox.py skeleton:breakfast

  import random
  items = "egg,bacon,sausage,baked beans,tomato".split(',')
  random.shuffle(items)
  breakfast = items[:random.randint(0,len(items))]
  breakfast += ['spam'] * random.randint(0,len(breakfast)+1)
  random.shuffle(breakfast)
  if len(breakfast) == 0: breakfast = ["lobster thermidor aux crevettes"]

  log.warn("Breakfast is served:")
  log.warn("%s and spam", ", ".join(breakfast))

########NEW FILE########
__FILENAME__ = boot
#!/bin/sh -

# Copyright 2011,2012,2013 James McCauley
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at:
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# If you have PyPy 1.6+ in a directory called pypy alongside pox.py, we
# use it.
# Otherwise, we try to use a Python interpreter called python2.7, which
# is a good idea if you're using Python from MacPorts, for example.
# We fall back to just "python" and hope that works.

#TODO: Make runnable by itself (paths need adjusting, etc.).

''''true
export OPT="-u -O"
export FLG=""
if [ "$(basename $0)" = "debug-pox.py" ]; then
  export OPT=""
  export FLG="--debug"
fi

if [ -x pypy/bin/pypy ]; then
  exec pypy/bin/pypy $OPT "$0" $FLG "$@"
fi

if type python2.7 > /dev/null; then
  exec python2.7 $OPT "$0" $FLG "$@"
fi
exec python $OPT "$0" $FLG "$@"
'''

from __future__ import print_function

import logging
import logging.config
import os
import sys
import traceback
import time
import inspect
import types
import threading

import pox.core
core = pox.core.initialize()

import pox.openflow
import pox.openflow.of_01
from pox.lib.util import str_to_bool

# Function to run on main thread
_main_thread_function = None

try:
  import __pypy__
except ImportError:
  __pypy__ = None

def _do_import (name):
  """
  Try to import the named component.
  Returns its module name if it was loaded or False on failure.
  """

  def show_fail ():
    traceback.print_exc()
    print("Could not import module:", name)

  def do_import2 (base_name, names_to_try):
    if len(names_to_try) == 0:
      print("Module not found:", base_name)
      return False

    name = names_to_try.pop(0)

    if name in sys.modules:
      return name

    try:
      __import__(name, level=0)
      return name
    except ImportError:
      # There are two cases why this might happen:
      # 1. The named module could not be found
      # 2. Some dependent module (import foo) or some dependent
      #    name-in-a-module (e.g., from foo import bar) could not be found.
      # If it's the former, we might try a name variation (e.g., without
      # a leading "pox."), but if we ultimately can't find the named
      # module, we just say something along those lines and stop.
      # On the other hand, if the problem is with a dependency, we should
      # print a stack trace so that it can be fixed.
      # Sorting out the two cases is an ugly hack.

      message = str(sys.exc_info()[1].args[0])
      s = message.rsplit(" ", 1)

      # Sadly, PyPy isn't consistent with CPython here.
      #TODO: Check on this behavior in pypy 2.0.
      if s[0] == "No module named" and (name.endswith(s[1]) or __pypy__):
        # It was the one we tried to import itself. (Case 1)
        # If we have other names to try, try them!
        return do_import2(base_name, names_to_try)
      elif message == "Import by filename is not supported.":
        print(message)
        import os.path
        n = name.replace("/", ".").replace("\\", ".")
        n = n.replace( os.path.sep, ".")
        if n.startswith("pox.") or n.startswith("ext."):
          n = n[4:]
        print("Maybe you meant to run '%s'?" % (n,))
        return False
      else:
        # This means we found the module we were looking for, but one
        # of its dependencies was missing.
        show_fail()
        return False
    except:
      # There was some other sort of exception while trying to load the
      # module.  Just print a trace and call it a day.
      show_fail()
      return False

  return do_import2(name, ["pox." + name, name])


def _do_imports (components):
  """
  Import each of the listed components

  Returns map of component_name->name,module,members on success,
  or False on failure
  """
  done = {}
  for name in components:
    if name in done: continue
    r = _do_import(name)
    if r is False:
      return False
    members = dict(inspect.getmembers(sys.modules[r]))
    done[name] = (r,sys.modules[r],members)

  return done


def _do_launch (argv):
  component_order = []
  components = {}

  curargs = {}
  pox_options = curargs

  for arg in argv:
    if not arg.startswith("-"):
      if arg not in components:
        components[arg] = []
      curargs = {}
      components[arg].append(curargs)
      component_order.append(arg)
    else:
      arg = arg.lstrip("-").split("=", 1)
      arg[0] = arg[0].replace("-", "_")
      if len(arg) == 1: arg.append(True)
      curargs[arg[0]] = arg[1]

  _options.process_options(pox_options)
  _pre_startup()
  modules = _do_imports(n.split(':')[0] for n in component_order)
  if modules is False:
    return False

  inst = {}
  for name in component_order:
    cname = name
    inst[name] = inst.get(name, -1) + 1
    params = components[name][inst[name]]
    name = name.split(":", 1)
    launch = name[1] if len(name) == 2 else "launch"
    name = name[0]

    name,module,members = modules[name]

    if launch in members:
      f = members[launch]
      # We explicitly test for a function and not an arbitrary callable
      if type(f) is not types.FunctionType:
        print(launch, "in", name, "isn't a function!")
        return False

      if getattr(f, '_pox_eval_args', False):
        import ast
        for k,v in params.items():
          if isinstance(v, str):
            try:
              params[k] = ast.literal_eval(v)
            except:
              # Leave it as a string
              pass

      multi = False
      if f.func_code.co_argcount > 0:
        #FIXME: This code doesn't look quite right to me and may be broken
        #       in some cases.  We should refactor to use inspect anyway,
        #       which should hopefully just fix it.
        if (f.func_code.co_varnames[f.func_code.co_argcount-1]
            == '__INSTANCE__'):
          # It's a multi-instance-aware component.

          multi = True

          # Special __INSTANCE__ paramter gets passed a tuple with:
          # 1. The number of this instance (0...n-1)
          # 2. The total number of instances for this module
          # 3. True if this is the last instance, False otherwise
          # The last is just a comparison between #1 and #2, but it's
          # convenient.
          params['__INSTANCE__'] = (inst[cname], len(components[cname]),
           inst[cname] + 1 == len(components[cname]))

      if multi == False and len(components[cname]) != 1:
        print(name, "does not accept multiple instances")
        return False

      try:
        if f(**params) is False:
          # Abort startup
          return False
      except TypeError as exc:
        instText = ''
        if inst[cname] > 0:
          instText = "instance {0} of ".format(inst[cname] + 1)
        print("Error executing {2}{0}.{1}:".format(name,launch,instText))
        if inspect.currentframe() is sys.exc_info()[2].tb_frame:
          # Error is with calling the function
          # Try to give some useful feedback
          if _options.verbose:
            traceback.print_exc()
          else:
            exc = sys.exc_info()[0:2]
            print(''.join(traceback.format_exception_only(*exc)), end='')
          print()
          EMPTY = "<Unspecified>"
          code = f.__code__
          argcount = code.co_argcount
          argnames = code.co_varnames[:argcount]
          defaults = list((f.func_defaults) or [])
          defaults = [EMPTY] * (argcount - len(defaults)) + defaults
          args = {}
          for n, a in enumerate(argnames):
            args[a] = [EMPTY,EMPTY]
            if n < len(defaults):
              args[a][0] = defaults[n]
            if a in params:
              args[a][1] = params[a]
              del params[a]
          if '__INSTANCE__' in args:
            del args['__INSTANCE__']

          if f.__doc__ is not None:
            print("Documentation for {0}:".format(name))
            doc = f.__doc__.split("\n")
            #TODO: only strip the same leading space as was on the first
            #      line
            doc = map(str.strip, doc)
            print('',("\n ".join(doc)).strip())

          #print(params)
          #print(args)

          print("Parameters for {0}:".format(name))
          if len(args) == 0:
            print(" None.")
          else:
            print(" {0:25} {1:25} {2:25}".format("Name", "Default",
                                                "Active"))
            print(" {0:25} {0:25} {0:25}".format("-" * 15))

            for k,v in args.iteritems():
              print(" {0:25} {1:25} {2:25}".format(k,str(v[0]),
                    str(v[1] if v[1] is not EMPTY else v[0])))

          if len(params):
            print("This component does not have a parameter named "
                  + "'{0}'.".format(params.keys()[0]))
            return False
          missing = [k for k,x in args.iteritems()
                     if x[1] is EMPTY and x[0] is EMPTY]
          if len(missing):
            print("You must specify a value for the '{0}' "
                  "parameter.".format(missing[0]))
            return False

          return False
        else:
          # Error is inside the function
          raise
    elif len(params) > 0 or launch is not "launch":
      print("Module %s has no %s(), but it was specified or passed " \
            "arguments" % (name, launch))
      return False

  return True


class Options (object):
  def set (self, given_name, value):
    name = given_name.replace("-", "_")
    if name.startswith("_") or hasattr(Options, name):
      # Hey, what's that about?
      print("Illegal option:", given_name)
      return False
    has_field = hasattr(self, name)
    has_setter = hasattr(self, "_set_" + name)
    if has_field == False and has_setter == False:
      print("Unknown option:", given_name)
      return False
    if has_setter:
      setter = getattr(self, "_set_" + name)
      setter(given_name, name, value)
    else:
      if isinstance(getattr(self, name), bool):
        # Automatic bool-ization
        value = str_to_bool(value)
      setattr(self, name, value)
    return True

  def process_options (self, options):
    for k,v in options.iteritems():
      if self.set(k, v) is False:
        # Bad option!
        sys.exit(1)


_help_text = """
POX is a Software Defined Networking controller framework.

The commandline of POX is like:
pox.py [POX options] [C1 [C1 options]] [C2 [C2 options]] ...

Notable POX options include:
  --verbose       Print more debugging information (especially useful for
                  problems on startup)
  --no-openflow   Don't automatically load the OpenFlow module
  --log-config=F  Load a Python log configuration file (if you include the
                  option without specifying F, it defaults to logging.cfg)

C1, C2, etc. are component names (e.g., Python modules).  Options they
support are up to the module.  As an example, you can load a learning
switch app that listens on a non-standard port number by specifying an
option to the of_01 component, and loading the l2_learning component like:
  ./pox.py --verbose openflow.of_01 --port=6634 forwarding.l2_learning

The 'help' component can give help for other components.  Start with:
  ./pox.py help --help
""".strip()


class POXOptions (Options):
  def __init__ (self):
#    self.cli = True
    self.verbose = False
    self.enable_openflow = True
    self.log_config = None

  def _set_h (self, given_name, name, value):
    self._set_help(given_name, name, value)

  def _set_help (self, given_name, name, value):
    print(_help_text)
    #TODO: Summarize options, etc.
    sys.exit(0)

  def _set_version (self, given_name, name, value):
    print(core._get_python_version())
    sys.exit(0)

  def _set_no_openflow (self, given_name, name, value):
    self.enable_openflow = not str_to_bool(value)

#  def _set_no_cli (self, given_name, name, value):
#    self.cli = not str_to_bool(value)

  def _set_log_config (self, given_name, name, value):
    if value is True:
      # I think I use a better method for finding the path elsewhere...
      p = os.path.dirname(os.path.realpath(__file__))
      value = os.path.join(p, "..", "logging.cfg")
    self.log_config = value

  def _set_debug (self, given_name, name, value):
    value = str_to_bool(value)
    if value:
      # Debug implies no openflow and no CLI and verbose
      #TODO: Is this really an option we need/want?
      self.verbose = True
      self.enable_openflow = False
#      self.cli = False


_options = POXOptions()


def _pre_startup ():
  """
  This function is called after all the POX options have been read in
  but before any components are loaded.  This gives a chance to do
  early setup (e.g., configure logging before a component has a chance
  to try to log something!).
  """

  _setup_logging()

  if _options.verbose:
    logging.getLogger().setLevel(logging.DEBUG)

  if _options.enable_openflow:
    pox.openflow.launch() # Default OpenFlow launch


def _post_startup ():
  if _options.enable_openflow:
    pox.openflow.of_01.launch() # Usually, we launch of_01


def _setup_logging ():
  # First do some basic log config...

  # This is kind of a hack, but we need to keep track of the handler we
  # install so that we can, for example, uninstall it later.  This code
  # originally lived in pox.core, so we explicitly reference it here.
  pox.core._default_log_handler = logging.StreamHandler()
  formatter = logging.Formatter(logging.BASIC_FORMAT)
  pox.core._default_log_handler.setFormatter(formatter)
  logging.getLogger().addHandler(pox.core._default_log_handler)
  logging.getLogger().setLevel(logging.INFO)


  # Now set up from config file if specified...
  #TODO:
  #  I think we could move most of the special log stuff into
  #  the log module.  You'd just have to make a point to put the log
  #  module first on the commandline if you wanted later component
  #  initializations to honor it.  Or it could be special-cased?

  if _options.log_config is not None:
    if not os.path.exists(_options.log_config):
      print("Could not find logging config file:", _options.log_config)
      sys.exit(2)
    logging.config.fileConfig(_options.log_config,
                              disable_existing_loggers=True)


def set_main_function (f):
  global _main_thread_function
  if _main_thread_function == f: return True
  if _main_thread_function is not None:
    import logging
    lg = logging.getLogger("boot")
    lg.error("Could not set main thread function to: " + str(f))
    lg.error("The main thread function is already "
        + "taken by: " + str(_main_thread_function))
    return False
  _main_thread_function = f
  return True


def boot (argv = None):
  """
  Start up POX.
  """

  # Add pox directory to path
  base = sys.path[0]
  sys.path.insert(0, os.path.abspath(os.path.join(base, 'pox')))
  sys.path.insert(0, os.path.abspath(os.path.join(base, 'ext')))

  thread_count = threading.active_count()

  quiet = False

  try:
    if argv is None:
      argv = sys.argv[1:]

    # Always load cli (first!)
    #TODO: Can we just get rid of the normal options yet?
    pre = []
    while len(argv):
      if argv[0].startswith("-"):
        pre.append(argv.pop(0))
      else:
        break
    argv = pre + "py --disable".split() + argv

    if _do_launch(argv):
      _post_startup()
      core.goUp()
    else:
      #return
      quiet = True
      raise RuntimeError()

  except SystemExit:
    return
  except:
    if not quiet:
      traceback.print_exc()

    # Try to exit normally, but do a hard exit if we don't.
    # This is sort of a hack.  What's the better option?  Raise
    # the going down event on core even though we never went up?

    try:
      for _ in range(4):
        if threading.active_count() <= thread_count:
          # Normal exit
          return
        time.sleep(0.25)
    except:
      pass

    os._exit(1)
    return

  if _main_thread_function:
    _main_thread_function()
  else:
    #core.acquire()
    try:
      while True:
        if core.quit_condition.acquire(False):
          core.quit_condition.wait(10)
          core.quit_condition.release()
        if not core.running: break
    except:
      pass
    #core.scheduler._thread.join() # Sleazy

  try:
    pox.core.core.quit()
  except:
    pass

########NEW FILE########
__FILENAME__ = core
# Copyright 2011-2013 James McCauley
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at:
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""
Some of POX's core API and functionality is here, largely in the POXCore
class (an instance of which is available as pox.core.core).

This includes things like component rendezvous, logging, system status
(up and down events), etc.
"""

from __future__ import print_function

# Set up initial log state
import logging

import inspect
import time
import os

_path = inspect.stack()[0][1]
_ext_path = _path[0:_path.rindex(os.sep)]
_ext_path = os.path.dirname(_ext_path) + os.sep
_path = os.path.dirname(_path) + os.sep

SQUELCH_TIME = 5

_squelch = ''
_squelchTime = 0
_squelchCount = 0

def getLogger (name=None, moreFrames=0):
  """
  In general, you don't need to call this directly, and will use
  core.getLogger() instead.
  """
  if name is None:
    s = inspect.stack()[1+moreFrames]
    name = s[1]
    if name.endswith('.py'):
      name = name[0:-3]
    elif name.endswith('.pyc'):
      name = name[0:-4]
    if name.startswith(_path):
      name = name[len(_path):]
    elif name.startswith(_ext_path):
      name = name[len(_ext_path):]
    name = name.replace('/', '.').replace('\\', '.') #FIXME: use os.path or whatever

    # Remove double names ("topology.topology" -> "topology")
    if name.find('.') != -1:
      n = name.split('.')
      if len(n) >= 2:
        if n[-1] == n[-2]:
          del n[-1]
          name = '.'.join(n)

    if name.startswith("ext."):
      name = name.split("ext.",1)[1]

    if name.endswith(".__init__"):
      name = name.rsplit(".__init__",1)[0]

  l = logging.getLogger(name)
  g=globals()
  if not hasattr(l, "print"):
    def printmsg (*args, **kw):
      #squelch = kw.get('squelch', True)
      msg = ' '.join((str(s) for s in args))
      s = inspect.stack()[1]
      o = '['
      if 'self' in s[0].f_locals:
        o += s[0].f_locals['self'].__class__.__name__ + '.'
      o += s[3] + ':' + str(s[2]) + '] '
      o += msg
      if o == _squelch:
        if time.time() >= _squelchTime:
          l.debug("[Previous message repeated %i more times]" % (g['_squelchCount']+1,))
          g['_squelchCount'] = 0
          g['_squelchTime'] = time.time() + SQUELCH_TIME
        else:
          g['_squelchCount'] += 1
      else:
        g['_squelch'] = o
        if g['_squelchCount'] > 0:
          l.debug("[Previous message repeated %i more times]" % (g['_squelchCount'],))
        g['_squelchCount'] = 0
        g['_squelchTime'] = time.time() + SQUELCH_TIME
        l.debug(o)

    setattr(l, "print", printmsg)
    setattr(l, "msg", printmsg)

  return l


# Working around something (don't remember what)
log = (lambda : getLogger())()

from pox.lib.revent import *

# Now use revent's exception hook to put exceptions in event handlers into
# the log...
def _revent_exception_hook (source, event, args, kw, exc_info):
  try:
    c = source
    t = event
    if hasattr(c, "__class__"): c = c.__class__.__name__
    if isinstance(t, Event): t = t.__class__.__name__
    elif issubclass(t, Event): t = t.__name__
  except:
    pass
  log.exception("Exception while handling %s!%s...\n" % (c,t))
import pox.lib.revent.revent
pox.lib.revent.revent.handleEventException = _revent_exception_hook

class GoingUpEvent (Event):
  """ Fired when system is going up. """
  pass

class GoingDownEvent (Event):
  """ Fired when system is going down. """
  pass

class UpEvent (Event):
  """ Fired when system is up. """
  pass

class DownEvent (Event):
  """ Fired when system is down. """
  pass

class ComponentRegistered (Event):
  """
  This is raised by core whenever a new component is registered.
  By watching this, a component can monitor whether other components it
  depends on are available.
  """
  def __init__ (self, name, component):
    Event.__init__(self)
    self.name = name
    self.component = component

import pox.lib.recoco as recoco

class POXCore (EventMixin):
  """
  A nexus of of the POX API.

  pox.core.core is a reference to an instance of this class.  This class
  serves a number of functions.

  An important one is that it can serve as a rendezvous point for
  components.  A component can register objects on core, and they can
  then be accessed on the core object (e.g., if you register foo, then
  there will then be a pox.core.core.foo).  In many cases, this means you
  won't need to import a module.

  Another purpose to the central registration is that it decouples
  functionality from a specific module.  If myL2Switch and yourL2Switch
  both register as "switch" and both provide the same API, then it doesn't
  matter.  Doing this with imports is a pain.

  Additionally, a number of commmon API functions are vailable here.
  """
  _eventMixin_events = set([
    UpEvent,
    DownEvent,
    GoingUpEvent,
    GoingDownEvent,
    ComponentRegistered
  ])

  def __init__ (self):
    self.debug = False
    self.running = True
    self.starting_up = True
    self.components = {'core':self}

    import threading
    self.quit_condition = threading.Condition()

    self.version = (0,2,0)
    self.version_name = "carp"
    print(self.banner)

    self.scheduler = recoco.Scheduler(daemon=True)

    self._waiters = [] # List of waiting components

  @property
  def banner (self):
    return "{0} / Copyright 2011-2013 James McCauley, et al.".format(
     self.version_string)

  @property
  def version_string (self):
    return "POX %s (%s)" % ('.'.join(map(str,self.version)),self.version_name)

  def callDelayed (_self, _seconds, _func, *args, **kw):
    """
    Calls the function at a later time.
    This is just a wrapper around a recoco timer.
    """
    t = recoco.Timer(_seconds, _func, args=args, kw=kw,
                     scheduler = _self.scheduler)
    return t

  def callLater (_self, _func, *args, **kw):
    # first arg is `_self` rather than `self` in case the user wants
    # to specify self as a keyword argument
    """
    Call the given function with the given arguments within the context
    of the co-operative threading environment.
    It actually calls it sooner rather than later. ;)
    Much of POX is written without locks because it's all thread-safe
    with respect to itself, as it's written using the recoco co-operative
    threading library.  If you have a real thread outside of the
    co-operative thread context, you need to be careful about calling
    things within it.  This function provides a rather simple way that
    works for most situations: you give it a callable (like a method)
    and some arguments, and it will call that callable with those
    arguments from within the co-operative threader, taking care of
    synchronization for you.
    """
    _self.scheduler.callLater(_func, *args, **kw)

  def raiseLater (_self, _obj, *args, **kw):
    # first arg is `_self` rather than `self` in case the user wants
    # to specify self as a keyword argument
    """
    This is similar to callLater(), but provides an easy way to raise a
    revent event from outide the co-operative context.
    Rather than foo.raiseEvent(BarEvent, baz, spam), you just do
    core.raiseLater(foo, BarEvent, baz, spam).
    """
    _self.scheduler.callLater(_obj.raiseEvent, *args, **kw)

  def getLogger (self, *args, **kw):
    """
    Returns a logger.  Pass it the name you want if you'd like to specify
    one (e.g., core.getLogger("foo")).  If you don't specify a name, it
    will make one up based on the module name it is called from.
    """
    return getLogger(moreFrames=1,*args, **kw)

  def quit (self):
    """
    Shut down POX.
    """
    import threading
    if (self.starting_up or
        threading.current_thread() is self.scheduler._thread):
      t = threading.Thread(target=self._quit)
      t.daemon = True
      t.start()
    else:
      self._quit()

  def _quit (self):
    # Should probably do locking here
    if not self.running:
      return
    if self.starting_up:
      # Try again later
      self.quit()
      return

    self.running = False
    log.info("Going down...")
    import gc
    gc.collect()
    self.raiseEvent(GoingDownEvent())
    self.callLater(self.scheduler.quit)
    for i in range(50):
      if self.scheduler._hasQuit: break
      gc.collect()
      time.sleep(.1)
    if not self.scheduler._allDone:
      log.warning("Scheduler didn't quit in time")
    self.raiseEvent(DownEvent())
    log.info("Down.")
    #logging.shutdown()
    self.quit_condition.acquire()
    self.quit_condition.notifyAll()
    core.quit_condition.release()

  def _get_python_version (self):
    try:
      import platform
      return "{impl} ({vers}/{build})".format(
       impl=platform.python_implementation(),
       vers=platform.python_version(),
       build=platform.python_build()[1].replace("  "," "))
    except:
      return "Unknown Python"

  def _get_platform_info (self):
    try:
      import platform
      return platform.platform().split("\n")[0]
    except:
      return "Unknown Platform"

  def goUp (self):
    log.debug(self.version_string + " going up...")

    log.debug("Running on " + self._get_python_version())
    log.debug("Platform is " + self._get_platform_info())
    try:
      import platform
      vers = '.'.join(platform.python_version().split(".")[:2])
    except:
      vers = 'an unknown version'
    if vers != "2.7":
      l = logging.getLogger("version")
      if not l.isEnabledFor(logging.WARNING):
        l.setLevel(logging.WARNING)
      l.warn("POX requires Python 2.7. You're running %s.", vers)
      l.warn("If you run into problems, try using Python 2.7 or PyPy.")

    self.starting_up = False
    self.raiseEvent(GoingUpEvent())

    self.raiseEvent(UpEvent())

    self._waiter_notify()

    if self.running:
      log.info(self.version_string + " is up.")

  def _waiter_notify (self):
    if len(self._waiters):
      waiting_for = set()
      for entry in self._waiters:
        _, name, components, _, _ = entry
        components = [c for c in components if not self.hasComponent(c)]
        waiting_for.update(components)
        log.debug("%s still waiting for: %s"
                  % (name, " ".join(components)))
      names = set([n for _,n,_,_,_ in self._waiters])

      #log.info("%i things still waiting on %i components"
      #         % (names, waiting_for))
      log.warn("Still waiting on %i component(s)" % (len(waiting_for),))

  def hasComponent (self, name):
    """
    Returns True if a component with the given name has been registered.
    """
    return name in self.components

  def registerNew (self, __componentClass, *args, **kw):
    """
    Give it a class (and optional __init__ arguments), and it will
    create an instance and register it using the class name.  If the
    instance has a _core_name property, it will use that instead.
    It returns the new instance.
    core.registerNew(FooClass, arg) is roughly equivalent to
    core.register("FooClass", FooClass(arg)).
    """
    name = __componentClass.__name__
    obj = __componentClass(*args, **kw)
    if hasattr(obj, '_core_name'):
      # Default overridden
      name = obj._core_name
    self.register(name, obj)
    return obj

  def register (self, name, component=None):
    """
    Makes the object "component" available as pox.core.core.name.

    If only one argument is specified, the given argument is registered
    using its class name as the name.
    """
    #TODO: weak references?
    if component is None:
      component = name
      name = component.__class__.__name__
      if hasattr(component, '_core_name'):
        # Default overridden
        name = component._core_name

    if name in self.components:
      log.warn("Warning: Registered '%s' multipled times" % (name,))
    self.components[name] = component
    self.raiseEventNoErrors(ComponentRegistered, name, component)
    self._try_waiters()

  def call_when_ready (self, callback, components=[], name=None, args=(),
                       kw={}):
    """
    Calls a callback when components are ready.
    """
    if callback is None:
      callback = lambda:None
      callback.func_name = "<None>"
    if isinstance(components, basestring):
      components = [components]
    elif isinstance(components, set):
      components = list(components)
    else:
      try:
        _ = components[0]
        components = list(components)
      except:
        components = [components]
    if name is None:
      #TODO: Use inspect here instead
      name = getattr(callback, 'func_name')
      if name is None:
        name = str(callback)
      else:
        name += "()"
        if hasattr(callback, 'im_class'):
          name = getattr(callback.im_class,'__name__', '') + '.' + name
      if hasattr(callback, '__module__'):
        # Is this a good idea?  If not here, we should do it in the
        # exception printing in try_waiter().
        name += " in " + callback.__module__
    entry = (callback, name, components, args, kw)
    self._waiters.append(entry)
    self._try_waiter(entry)

  def _try_waiter (self, entry):
    """
    Tries a waiting callback.

    Calls the callback, removes from _waiters, and returns True if
    all are satisfied.
    """
    if entry not in self._waiters:
      # Already handled
      return
    callback, name, components, args_, kw_ = entry
    for c in components:
      if not self.hasComponent(c):
        return False
    self._waiters.remove(entry)
    try:
      if callback is not None:
        callback(*args_,**kw_)
    except:
      import traceback
      msg = "Exception while trying to notify " + name
      import inspect
      try:
        msg += " at " + inspect.getfile(callback)
        msg += ":" + str(inspect.getsourcelines(callback)[1])
      except:
        pass
      log.exception(msg)
    return True

  def _try_waiters (self):
    """
    Tries to satisfy all component-waiting callbacks
    """
    changed = True

    while changed:
      changed = False
      for entry in list(self._waiters):
        if self._try_waiter(entry):
          changed = True

  def listen_to_dependencies (self, sink, components=None, attrs=True,
                              short_attrs=False, listen_args={}):
    """
    Look through *sink* for handlers named like _handle_component_event.
    Use that to build a list of components, and append any components
    explicitly specified by *components*.

    listen_args is a dict of "component_name"={"arg_name":"arg_value",...},
    allowing you to specify additional arguments to addListeners().

    When all the referenced components are registered, do the following:
    1) Set up all the event listeners
    2) Call "_all_dependencies_met" on *sink* if it exists
    3) If attrs=True, set attributes on *sink* for each component
       (e.g, sink._openflow_ would be set to core.openflow)

    For example, if topology is a dependency, a handler for topology's
    SwitchJoin event must be defined as so:
       def _handle_topology_SwitchJoin (self, ...):

    *NOTE*: The semantics of this function changed somewhat in the
            Summer 2012 milestone, though its intention remains the same.
    """
    if components is None:
      components = set()
    elif isinstance(components, basestring):
      components = set([components])
    else:
      components = set(components)

    for c in dir(sink):
      if not c.startswith("_handle_"): continue
      if c.count("_") < 3: continue
      c = '_'.join(c.split("_")[2:-1])
      components.add(c)

    if None in listen_args:
      # This means add it to all...
      args = listen_args.pop(None)
      for k,v in args.iteritems():
        for c in components:
          if c not in listen_args:
            listen_args[c] = {}
          if k not in listen_args[c]:
            listen_args[c][k] = v

    if set(listen_args).difference(components):
      log.error("Specified listen_args for missing component(s): %s" %
                (" ".join(set(listen_args).difference(components)),))

    def done (sink, components, attrs, short_attrs):
      if attrs or short_attrs:
        for c in components:
          if short_attrs:
            attrname = c
          else:
            attrname = '_%s_' % (c,)
          setattr(sink, attrname, getattr(self, c))
      for c in components:
        if hasattr(getattr(self, c), "_eventMixin_events"):
          kwargs = {"prefix":c}
          kwargs.update(listen_args.get(c, {}))
          getattr(self, c).addListeners(sink, **kwargs)
      getattr(sink, "_all_dependencies_met", lambda : None)()


    self.call_when_ready(done, components, name=sink.__class__.__name__,
                         args=(sink,components,attrs,short_attrs))

    if not self.starting_up:
      self._waiter_notify()

  def __getattr__ (self, name):
    if name not in self.components:
      raise AttributeError("'%s' not registered" % (name,))
    return self.components[name]


core = None

def initialize ():
  global core
  core = POXCore()
  return core

# The below is a big hack to make tests and doc tools work.
# We should do something better.
def _maybe_initialize ():
  import sys
  if 'unittest' in sys.modules or 'nose' in sys.modules:
    initialize()
    return
  import __main__
  mod = getattr(__main__, '__file__', '')
  if 'pydoc' in mod:
    initialize()
    return
_maybe_initialize()

########NEW FILE########
__FILENAME__ = ctl
# Copyright 2013 James McCauley
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at:
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""
Simple datapath control framework for POX datapaths
"""

from pox.core import core
from pox.lib.ioworker.workers import *
from pox.lib.ioworker import *
from pox.lib.revent import *


# IOLoop for our IO workers
_ioloop = None

# Log
log = None


class CommandEvent (Event):
  """
  Event fired whenever a command is received
  """
  def __init__ (self, worker, cmd):
    super(CommandEvent,self).__init__()
    self.worker = worker
    self.cmd = cmd

  @property
  def first (self):
    return self.cmd.strip().split()[0]

  @property
  def args (self):
    return self.cmd.strip().split()[1:]

  def __str__ (self):
    return "<%s: %s>" % (self.worker, self.cmd)


class ServerWorker (TCPServerWorker, RecocoIOWorker):
  """
  Worker to accept connections
  """
  pass
  #TODO: Really should just add this to the ioworker package.


class Worker (RecocoIOWorker):
  """
  Worker to receive POX dpctl commands 
  """
  def __init__ (self, *args, **kw):
    super(Worker, self).__init__(*args, **kw)
    self._connecting = True
    self._buf = b''

  def _process (self, data):
    self._buf += data
    while '\n' in self._buf:
      fore,self._buf = self._buf.split('\n', 1)
      core.ctld.raiseEventNoErrors(CommandEvent, self, fore)


  def _handle_rx (self):
    self._buf += self.read()
    self._process(self.read())

  def _exec (self, msg):
    msg.split()


class Server (EventMixin):
  """
  Listens on a TCP socket for control
  """
  _eventMixin_events = set([CommandEvent])

  def __init__ (self, port = 7791):
    w = ServerWorker(child_worker_type=Worker, port = port)
    self.server_worker = w
    _ioloop.register_worker(w)


def create_server (port = 7791):
  # Set up logging
  global log
  if not log:
    log = core.getLogger()

  # Set up IO loop
  global _ioloop
  if not _ioloop:
    _ioloop = RecocoIOLoop()
    #_ioloop.more_debugging = True
    _ioloop.start()

  c = Server(port = int(port))
  return c


def server (port = 7791):
  c = create_server(int(port))
  core.register("ctld", c)


def launch (cmd, address = None, port = 7791):
  core.quit()
  if not address:
    address = "127.0.0.1"
  import socket
  core.getLogger('core').setLevel(100)
  log = core.getLogger('ctl')
  try:
    s = socket.create_connection((address,port), timeout=2)
  except:
    log.error("Couldn't connect")
    return
  try:
    s.settimeout(2)
    s.send(cmd + "\n")
    d = s.recv(4096).strip()
    core.getLogger("ctl").info(d)
  except socket.timeout:
    log.warn("No response")
  except:
    log.exception("While communicating")

########NEW FILE########
__FILENAME__ = nx_switch
# Copyright 2011,2012 Andreas Wundsam
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at:
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import inspect

import pox.openflow.libopenflow_01 as of
import pox.openflow.nicira_ext as nx
from pox.datapaths.switch import SoftwareSwitch, OFConnection

_slave_blacklist = set([of.ofp_flow_mod, of.ofp_packet_out, of.ofp_port_mod,
                        of.ofp_barrier_request])
_messages_for_all = set([of.ofp_port_status])


class NXSoftwareSwitch (SoftwareSwitch):
  """
  Software datapath with Nicira (NX) extensions

  Extension of the software switch that supports some of the Nicira (NX) vendor
  extensions that are part of Open vSwitch.

  In particular, this include the ability for a switch to connect to multiple
  controllers at the same time.

  In the beginning, all controllers start out as equals (ROLE_OTHER). Through
  the NX vendor message role_request, one controller can be promoted to
  ROLE_MASTER, in which case all other controllers are downgraded to slave
  status.

  The switch doesn't accept state-mutating messages (e.g., FLOW_MOD, see
  _slave_blacklist) from slave controllers.

  Messages are distributed to controllers according to their type:
    - symmetric message replies are sent to the controller that initiated them
      (e.g., STATS_REQUEST -> REPLY)
    - port_status messages are distributed to all controllers
    - all other messages are distributed to the master controller, or if none
      is present, any controller in ROLE_OTHER
  """

  def __init__ (self, *args, **kw):
    SoftwareSwitch.__init__(self, *args, **kw)
    self.role_by_conn={}
    self.connections = []
    self.connection_in_action = None
    # index of the next 'other' controller to get a message
    # (for round robin of async messages)
    self.next_other = 0

    # Set of connections to which we have sent hellos.  This is used to
    # as part of overriding the single-connection logic in the superclass.
    self._sent_hellos = set()

  def rx_message (self, connection, msg):
    """
    Handles incoming messages

    @overrides SoftwareSwitch.rx_message
    """

    self.connection_in_action = connection
    if not self.check_rights(msg, connection):
      self.log.warn("Message %s not allowed for slave controller %d", msg,
                    connection.ID)
      self.send_vendor_error(connection)
    else:
      SoftwareSwitch.rx_message(self, connection, msg)

    self.connection_in_action = None

  def check_rights (self, ofp, connection):
    if self.role_by_conn[connection.ID] != nx.ROLE_SLAVE:
      return True
    else:
      return not type(ofp) in _slave_blacklist

  def send_vendor_error (self, connection):
    err = of.ofp_error(type=of.OFPET_BAD_REQUEST, code=of.OFPBRC_BAD_VENDOR)
    connection.send(err)

  def send (self, message):
    connections_used = []
    if type(message) in _messages_for_all:
      for c in self.connections:
        c.send(message)
        connections_used.append(c)
    elif self.connection_in_action:
      #self.log.info("Sending %s to active connection %d",
      #              (str(message), self.connection_in_action.ID))
      self.connection_in_action.send(message)
      connections_used.append(self.connection_in_action)
    else:
      masters = [c for c in self.connections
                 if self.role_by_conn[c.ID] == nx.ROLE_MASTER]
      if len(masters) > 0:
        masters[0].send(message)
        connections_used.append(masters[0])
      else:
        others = [c for c in self.connections
                  if self.role_by_conn[c.ID] == nx.ROLE_OTHER]
        if len(others) > 0:
          self.next_other = self.next_other % len(others)
          #self.log.info("Sending %s to 'other' connection %d",
          #              (str(message), self.next_other))
          others[self.next_other].send(message)
          connections_used.append(others[self.next_other])
          self.next_other += 1
        else:
          self.log.info("Could not find any connection to send messages %s",
                        str(message))
    return connections_used

  def add_connection (self, connection):
    self.role_by_conn[connection.ID] = nx.ROLE_OTHER
    connection.set_message_handler(self.rx_message)
    self.connections.append(connection)
    return connection

  def set_connection (self, connection):
    self.add_connection(connection)

  def set_role (self, connection, role):
    self.role_by_conn[connection.ID] = role
    if role == nx.ROLE_MASTER:
      for c in self.connections:
        if c != connection:
          self.role_by_conn[c.ID] = nx.ROLE_SLAVE

  def _rx_hello (self, ofp, connection):
    # Override the usual hello-send logic
    if connection not in self._sent_hellos:
      self._sent_hellos.add(connection)
      self.send_hello(force=True)

  def _rx_vendor (self, vendor, connection):
    self.log.debug("Vendor %s %s", self.name, str(vendor))
    if vendor.vendor == nx.VENDOR_ID:
      try:
        data = nx.unpack_vendor_data_nx(vendor.data)
        if isinstance(data, nx.role_request_data):
          self.set_role(connection, data.role)
          reply = of.ofp_vendor(xid=vendor.xid, vendor = nx.VENDOR_ID,
                                data = nx.role_reply_data(role = data.role))
          self.send(reply)
          return
      except NotImplementedError:
        self.send_vendor_error(connection)
    else:
      return SoftwareSwitch._rx_vendor(self, vendor)

########NEW FILE########
__FILENAME__ = pcap_switch
# Copyright 2013 James McCauley
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at:
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""
Software switch with PCap ports

Example:
./pox.py --no-openflow datapaths.pcap_switch --address=localhost
"""

from pox.core import core
from pox.datapaths import do_launch
from pox.datapaths.switch import SoftwareSwitchBase, OFConnection
from pox.datapaths.switch import ExpireMixin
import pox.lib.pxpcap as pxpcap
from Queue import Queue
from threading import Thread
import pox.openflow.libopenflow_01 as of
from pox.lib.packet import ethernet
import logging

log = core.getLogger()

DEFAULT_CTL_PORT = 7791

_switches = {}

def _do_ctl (event):
  r = _do_ctl2(event)
  if r is None:
    r = "Okay."
  event.worker.send(r + "\n")

def _do_ctl2 (event):
  def errf (msg, *args):
    raise RuntimeError(msg % args)

  args = event.args

  def ra (low, high = None):
    if high is None: high = low
    if len(args) < low or len(args) > high:
      raise RuntimeError("Wrong number of arguments")
    return False

  try:
    if event.first == "add-port":
      ra(1,2)
      if len(event.args) == 1 and len(_switches) == 1:
        sw = _switches[_switches.keys()[0]]
        p = args[0]
      else:
        ra(2)
        if event.args[0] not in _switches:
          raise RuntimeError("No such switch")
        sw = _switches[event.args[0]]
        p = args[1]
      sw.add_interface(p, start=True, on_error=errf)
    elif event.first == "del-port":
      ra(1,2)
      if len(event.args) == 1:
        for sw in _switches.values():
          for p in sw.ports:
            if p.name == event.args[0]:
              sw.remove_interface(event.args[0])
              return
        raise RuntimeError("No such interface")
      sw = _switches[event.args[0]]
      sw.remove_interface(args[1])
    elif event.first == "show":
      ra(0)
      s = []
      for sw in _switches.values():
        s.append("Switch %s" % (sw.name,))
        for no,p in sw.ports.iteritems():
          s.append(" %3s %s" % (no, p.name))
      return "\n".join(s)

    else:
      raise RuntimeError("Unknown command")

  except Exception as e:
    log.exception("While processing command")
    return "Error: " + str(e)


def launch (address = '127.0.0.1', port = 6633, max_retry_delay = 16,
    dpid = None, ports = '', extra = None, ctl_port = None,
    __INSTANCE__ = None):
  """
  Launches a switch
  """

  if not pxpcap.enabled:
    raise RuntimeError("You need PXPCap to use this component")

  if ctl_port:
    if core.hasComponent('ctld'):
      raise RuntimeError("Only one ctl_port is allowed")

    if ctl_port is True:
      ctl_port = DEFAULT_CTL_PORT

    import ctl
    ctl.server(ctl_port)
    core.ctld.addListenerByName("CommandEvent", _do_ctl)

  _ports = ports.strip()
  def up (event):
    ports = [p for p in _ports.split(",") if p]

    sw = do_launch(PCapSwitch, address, port, max_retry_delay, dpid,
                   ports=ports, extra_args=extra)
    _switches[sw.name] = sw

  core.addListenerByName("UpEvent", up)


class PCapSwitch (ExpireMixin, SoftwareSwitchBase):
  # Default level for loggers of this class
  default_log_level = logging.INFO

  def __init__ (self, **kw):
    """
    Create a switch instance

    Additional options over superclass:
    log_level (default to default_log_level) is level for this instance
    ports is a list of interface names
    """
    log_level = kw.pop('log_level', self.default_log_level)

    self.q = Queue()
    self.t = Thread(target=self._consumer_threadproc)
    core.addListeners(self)

    ports = kw.pop('ports', [])
    kw['ports'] = []

    super(PCapSwitch,self).__init__(**kw)

    self._next_port = 1

    self.px = {}

    for p in ports:
      self.add_interface(p, start=False)

    self.log.setLevel(log_level)

    for px in self.px.itervalues():
      px.start()

    self.t.start()

  def add_interface (self, name, port_no=-1, on_error=None, start=False):
    if on_error is None:
      on_error = log.error

    devs = pxpcap.PCap.get_devices()
    if name not in devs:
      on_error("Device %s not available -- ignoring", name)
      return
    dev = devs[name]
    if dev.get('addrs',{}).get('ethernet',{}).get('addr') is None:
      on_error("Device %s has no ethernet address -- ignoring", name)
      return
    if dev.get('addrs',{}).get('AF_INET') != None:
      on_error("Device %s has an IP address -- ignoring", name)
      return
    for no,p in self.px.iteritems():
      if p.device == name:
        on_error("Device %s already added", name)

    if port_no == -1:
      while True:
        port_no = self._next_port
        self._next_port += 1
        if port_no not in self.ports: break

    if port_no in self.ports:
      on_error("Port %s already exists -- ignoring", port_no)
      return

    phy = of.ofp_phy_port()
    phy.port_no = port_no
    phy.hw_addr = dev['addrs']['ethernet']['addr']
    phy.name = name
    # Fill in features sort of arbitrarily
    phy.curr = of.OFPPF_10MB_HD
    phy.advertised = of.OFPPF_10MB_HD
    phy.supported = of.OFPPF_10MB_HD
    phy.peer = of.OFPPF_10MB_HD

    self.add_port(phy)

    px = pxpcap.PCap(name, callback = self._pcap_rx, start = False)
    px.port_no = phy.port_no
    self.px[phy.port_no] = px

    if start:
      px.start()

    return px

  def remove_interface (self, name_or_num):
    if isinstance(name_or_num, basestring):
      for no,p in self.px.iteritems():
        if p.device == name_or_num:
          self.remove_interface(no)
          return
      raise ValueError("No such interface")

    px = self.px[name_or_num]
    px.stop()
    px.port_no = None
    self.delete_port(name_or_num)

  def _handle_GoingDownEvent (self, event):
    self.q.put(None)

  def _consumer_threadproc (self):
    timeout = 3
    while core.running:
      try:
        data = self.q.get(timeout=timeout)
      except:
        continue
      if data is None:
        # Signal to quit
        break
      batch = []
      while True:
        self.q.task_done()
        port_no,data = data
        data = ethernet(data)
        batch.append((data,port_no))
        try:
          data = self.q.get(block=False)
        except:
          break
      core.callLater(self.rx_batch, batch)

  def rx_batch (self, batch):
    for data,port_no in batch:
      self.rx_packet(data, port_no)

  def _pcap_rx (self, px, data, sec, usec, length):
    if px.port_no is None: return
    self.q.put((px.port_no, data))

  def _output_packet_physical (self, packet, port_no):
    """
    send a packet out a single physical port

    This is called by the more general _output_packet().
    """
    px = self.px.get(port_no)
    if not px: return
    px.inject(packet)

########NEW FILE########
__FILENAME__ = switch
# Copyright 2012,2013 Colin Scott
# Copyright 2012,2013 James McCauley
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at:
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""
A software OpenFlow switch
"""

"""
TODO
----
* Don't reply to HELLOs -- just send one on connect
* Pass raw OFP packet to rx handlers as well as parsed
* Once previous is done, use raw OFP for error data when appropriate
* Check self.features to see if various features/actions are enabled,
  and act appropriately if they're not (rather than just doing them).
* Virtual ports currently have no config/state, but probably should.
* Provide a way to rebuild, e.g., the action handler table when the
  features object is adjusted.
"""


from pox.lib.util import assert_type, initHelper, dpid_to_str
from pox.lib.revent import Event, EventMixin
from pox.lib.recoco import Timer
from pox.openflow.libopenflow_01 import *
import pox.openflow.libopenflow_01 as of
from pox.openflow.util import make_type_to_unpacker_table
from pox.openflow.flow_table import FlowTable, TableEntry
from pox.lib.packet import *

import logging
import struct
import time


# Multicast address used for STP 802.1D
_STP_MAC = EthAddr('01:80:c2:00:00:00')


class DpPacketOut (Event):
  """
  Event raised when a dataplane packet is sent out a port
  """
  def __init__ (self, node, packet, port):
    assert assert_type("packet", packet, ethernet, none_ok=False)
    Event.__init__(self)
    self.node = node
    self.packet = packet
    self.port = port
    self.switch = node # For backwards compatability


class SoftwareSwitchBase (object):
  def __init__ (self, dpid, name=None, ports=4, miss_send_len=128,
                max_buffers=100, max_entries=0x7fFFffFF, features=None):
    """
    Initialize switch
     - ports is a list of ofp_phy_ports or a number of ports
     - miss_send_len is number of bytes to send to controller on table miss
     - max_buffers is number of buffered packets to store
     - max_entries is max flows entries per table
    """
    if name is None: name = dpid_to_str(dpid)
    self.name = name

    self.dpid = dpid

    if isinstance(ports, int):
      ports = [self.generate_port(i) for i in range(1, ports+1)]

    self.max_buffers = max_buffers
    self.max_entries = max_entries
    self.miss_send_len = miss_send_len
    self.config_flags = 0
    self._has_sent_hello = False

    self.table = FlowTable()
    self.table.addListeners(self)

    self._lookup_count = 0
    self._matched_count = 0

    self.log = logging.getLogger(self.name)
    self._connection = None

    # buffer for packets during packet_in
    self._packet_buffer = []

    # Map port_no -> openflow.pylibopenflow_01.ofp_phy_ports
    self.ports = {}
    self.port_stats = {}

    for port in ports:
      self.add_port(port)

    if features is not None:
      self.features = features
    else:
      # Set up default features

      self.features = SwitchFeatures()
      self.features.cap_flow_stats = True
      self.features.cap_table_stats = True
      self.features.cap_port_stats = True
      #self.features.cap_stp = True
      #self.features.cap_ip_reasm = True
      #self.features.cap_queue_stats = True
      #self.features.cap_arp_match_ip = True

      self.features.act_output = True
      self.features.act_enqueue = True
      self.features.act_strip_vlan = True
      self.features.act_set_vlan_vid = True
      self.features.act_set_vlan_pcp = True
      self.features.act_set_dl_dst = True
      self.features.act_set_dl_src = True
      self.features.act_set_nw_dst = True
      self.features.act_set_nw_src = True
      self.features.act_set_nw_tos = True
      self.features.act_set_tp_dst = True
      self.features.act_set_tp_src = True
      #self.features.act_vendor = True

    # Set up handlers for incoming OpenFlow messages
    # That is, self.ofp_handlers[OFPT_FOO] = self._rx_foo
    self.ofp_handlers = {}
    for value,name in ofp_type_map.iteritems():
      name = name.split("OFPT_",1)[-1].lower()
      h = getattr(self, "_rx_" + name, None)
      if not h: continue
      assert of._message_type_to_class[value]._from_controller, name
      self.ofp_handlers[value] = h

    # Set up handlers for actions
    # That is, self.action_handlers[OFPAT_FOO] = self._action_foo
    #TODO: Refactor this with above
    self.action_handlers = {}
    for value,name in ofp_action_type_map.iteritems():
      name = name.split("OFPAT_",1)[-1].lower()
      h = getattr(self, "_action_" + name, None)
      if not h: continue
      if getattr(self.features, "act_" + name) is False: continue
      self.action_handlers[value] = h

    # Set up handlers for stats handlers
    # That is, self.stats_handlers[OFPST_FOO] = self._stats_foo
    #TODO: Refactor this with above
    self.stats_handlers = {}
    for value,name in ofp_stats_type_map.iteritems():
      name = name.split("OFPST_",1)[-1].lower()
      h = getattr(self, "_stats_" + name, None)
      if not h: continue
      self.stats_handlers[value] = h

    # Set up handlers for flow mod handlers
    # That is, self.flow_mod_handlers[OFPFC_FOO] = self._flow_mod_foo
    #TODO: Refactor this with above
    self.flow_mod_handlers = {}
    for name,value in ofp_flow_mod_command_rev_map.iteritems():
      name = name.split("OFPFC_",1)[-1].lower()
      h = getattr(self, "_flow_mod_" + name, None)
      if not h: continue
      self.flow_mod_handlers[value] = h

  def _gen_port_name (self, port_no):
    return "%s.%s"%(dpid_to_str(self.dpid, True).replace('-','')[:12], port_no)

  def _gen_ethaddr (self, port_no):
    return EthAddr("02%06x%04x" % (self.dpid % 0x00FFff, port_no % 0xffFF))

  def generate_port (self, port_no, name = None, ethaddr = None):
    dpid = self.dpid
    p = ofp_phy_port()
    p.port_no = port_no
    if ethaddr is None:
      p.hw_addr = self._gen_ethaddr(p.port_no)
    else:
      p.hw_addr = EthAddr(ethaddr)
    if name is None:
      p.name = self._gen_port_name(p.port_no)
    else:
      p.name = name
    # Fill in features sort of arbitrarily
    p.config = OFPPC_NO_STP
    p.curr = OFPPF_10MB_HD
    p.advertised = OFPPF_10MB_HD
    p.supported = OFPPF_10MB_HD
    p.peer = OFPPF_10MB_HD
    return p

  @property
  def _time (self):
    """
    Get the current time

    This should be used for, e.g., calculating timeouts.  It currently isn't
    used everywhere it should be.

    Override this to change time behavior.
    """
    return time.time()

  def _handle_FlowTableModification (self, event):
    """
    Handle flow table modification events
    """
    # Currently, we only use this for sending flow_removed messages
    if not event.removed: return

    if event.reason in (OFPRR_IDLE_TIMEOUT,OFPRR_HARD_TIMEOUT,OFPRR_DELETE):
      # These reasons may lead to a flow_removed
      count = 0
      for entry in event.removed:
        if entry.flags & OFPFF_SEND_FLOW_REM and not entry.flags & OFPFF_EMERG:
          # Flow wants removal notification -- send it
          fr = entry.to_flow_removed(self._time, reason=event.reason)
          self.send(fr)
          count += 1
      self.log.debug("%d flows removed (%d removal notifications)",
          len(event.removed), count)

  def rx_message (self, connection, msg):
    """
    Handle an incoming OpenFlow message
    """
    ofp_type = msg.header_type
    h = self.ofp_handlers.get(ofp_type)
    if h is None:
      raise RuntimeError("No handler for ofp_type %s(%d)"
                         % (ofp_type_map.get(ofp_type), ofp_type))

    self.log.debug("Got %s with XID %s",ofp_type_map.get(ofp_type),msg.xid)
    h(msg, connection=connection)

  def set_connection (self, connection):
    """
    Set this switch's connection.
    """
    self._has_sent_hello = False
    connection.set_message_handler(self.rx_message)
    self._connection = connection

  def send (self, message, connection = None):
    """
    Send a message to this switch's communication partner
    """
    if connection is None:
      connection = self._connection
    if connection:
      connection.send(message)
    else:
      self.log.debug("Asked to send message %s, but not connected", message)

  def _rx_hello (self, ofp, connection):
    #FIXME: This isn't really how hello is supposed to work -- we're supposed
    #       to send it immediately on connection.  See _send_hello().
    self.send_hello()

  def _rx_echo_request (self, ofp, connection):
    """
    Handles echo requests
    """
    msg = ofp_echo_reply(xid=ofp.xid, body=ofp.body)
    self.send(msg)

  def _rx_features_request (self, ofp, connection):
    """
    Handles feature requests
    """
    self.log.debug("Send features reply")
    msg = ofp_features_reply(datapath_id = self.dpid,
                             xid = ofp.xid,
                             n_buffers = self.max_buffers,
                             n_tables = 1,
                             capabilities = self.features.capability_bits,
                             actions = self.features.action_bits,
                             ports = self.ports.values())
    self.send(msg)

  def _rx_flow_mod (self, ofp, connection):
    """
    Handles flow mods
    """
    self.log.debug("Flow mod details: %s", ofp.show())

    #self.table.process_flow_mod(ofp)
    #self._process_flow_mod(ofp, connection=connection, table=self.table)
    handler = self.flow_mod_handlers.get(ofp.command)
    if handler is None:
      self.log.warn("Command not implemented: %s" % command)
      self.send_error(type=OFPET_FLOW_MOD_FAILED, code=OFPFMFC_BAD_COMMAND,
                      ofp=ofp, connection=connection)
      return
    handler(flow_mod=ofp, connection=connection, table=self.table)

    if ofp.buffer_id is not None:
      self._process_actions_for_packet_from_buffer(ofp.actions, ofp.buffer_id,
                                                   ofp)

  def _rx_packet_out (self, packet_out, connection):
    """
    Handles packet_outs
    """
    self.log.debug("Packet out details: %s", packet_out.show())

    if packet_out.data:
      self._process_actions_for_packet(packet_out.actions, packet_out.data,
                                       packet_out.in_port, packet_out)
    elif packet_out.buffer_id is not None:
      self._process_actions_for_packet_from_buffer(packet_out.actions,
                                                   packet_out.buffer_id,
                                                   packet_out)
    else:
      self.log.warn("packet_out: No data and no buffer_id -- "
                    "don't know what to send")

  def _rx_echo_reply (self, ofp, connection):
    pass

  def _rx_barrier_request (self, ofp, connection):
    msg = ofp_barrier_reply(xid = ofp.xid)
    self.send(msg)

  def _rx_get_config_request (self, ofp, connection):
    msg = ofp_get_config_reply(xid = ofp.xid)
    msg.miss_send_len = self.miss_send_len
    msg.flags = self.config_flags
    self.log.debug("Sending switch config reply %s", msg)
    self.send(msg)

  def _rx_stats_request (self, ofp, connection):
    handler = self.stats_handlers.get(ofp.type)
    if handler is None:
      self.log.warning("Stats type %s not implemented", ofp.type)

      self.send_error(type=OFPET_BAD_REQUEST, code=OFPBRC_BAD_STAT,
                      ofp=ofp, connection=connection)
      return

    body = handler(ofp, connection=connection)
    if body is not None:
      reply = ofp_stats_reply(xid=ofp.xid, type=ofp.type, body=body)
      self.log.debug("Sending stats reply %s", reply)
      self.send(reply)

  def _rx_set_config (self, config, connection):
    self.miss_send_len = config.miss_send_len
    self.config_flags = config.flags

  def _rx_port_mod (self, port_mod, connection):
    port_no = port_mod.port_no
    if port_no not in self.ports:
      self.send_error(type=OFPET_PORT_MOD_FAILED, code=OFPPMFC_BAD_PORT,
                      ofp=port_mod, connection=connection)
      return
    port = self.ports[port_no]
    if port.hw_addr != port_mod.hw_addr:
      self.send_error(type=OFPET_PORT_MOD_FAILED, code=OFPPMFC_BAD_HW_ADDR,
                      ofp=port_mod, connection=connection)
      return

    mask = port_mod.mask

    for bit in range(32):
      bit = 1 << bit
      if mask & bit:
        handled,r = self._set_port_config_bit(port, bit, port_mod.config & bit)
        if not handled:
          self.log.warn("Unsupported port config flag: %08x", bit)
          continue
        if r is not None:
          msg = "Port %s: " % (port.port_no,)
          if isinstance(r, str):
            msg += r
          else:
            msg += ofp_port_config_map.get(bit, "config bit %x" % (bit,))
            msg += " set to "
            msg += "true" if r else "false"
          self.log.debug(msg)

  def _rx_vendor (self, vendor, connection):
    # We don't support vendor extensions, so send an OFP_ERROR, per
    # page 42 of spec
    self.send_error(type=OFPET_BAD_REQUEST, code=OFPBRC_BAD_VENDOR,
                    ofp=vendor, connection=connection)

  def _rx_queue_get_config_request (self, ofp, connection):
    """
    Handles an OFPT_QUEUE_GET_CONFIG_REQUEST message.
    """
    reply = ofp_queue_get_config_reply(xid=ofp.xid, port=ofp.port, queues=[])
    self.log.debug("Sending queue get config reply %s", reply)
    self.send(reply)

  def send_hello (self, force = False):
    """
    Send hello (once)
    """
    #FIXME: This is wrong -- we should just send when connecting.
    if self._has_sent_hello and not force: return
    self._has_sent_hello = True
    self.log.debug("Sent hello")
    msg = ofp_hello(xid=0)
    self.send(msg)

  def send_packet_in (self, in_port, buffer_id=None, packet=b'', reason=None,
                      data_length=None):
    """
    Send PacketIn
    """
    if hasattr(packet, 'pack'):
      packet = packet.pack()
    assert assert_type("packet", packet, bytes)
    self.log.debug("Send PacketIn")
    if reason is None:
      reason = OFPR_NO_MATCH
    if data_length is not None and len(packet) > data_length:
      if buffer_id is not None:
        packet = packet[:data_length]

    msg = ofp_packet_in(xid = 0, in_port = in_port, buffer_id = buffer_id,
                        reason = reason, data = packet)

    self.send(msg)

  def send_port_status (self, port, reason):
    """
    Send port status

    port is an ofp_phy_port
    reason is one of OFPPR_xxx
    """
    assert assert_type("port", port, ofp_phy_port, none_ok=False)
    assert reason in ofp_port_reason_rev_map.values()
    msg = ofp_port_status(desc=port, reason=reason)
    self.send(msg)

  def send_error (self, type, code, ofp=None, data=None, connection=None):
    """
    Send an error

    If you pass ofp, it will be used as the source of the error's XID and
    data.
    You can override the data by also specifying data.
    """
    err = ofp_error(type=type, code=code)
    if ofp:
      err.xid = ofp.xid
      err.data = ofp.pack()
    else:
      err.xid = 0
    if data is not None:
      err.data = data
    self.send(err, connection = connection)

  def rx_packet (self, packet, in_port, packet_data = None):
    """
    process a dataplane packet

    packet: an instance of ethernet
    in_port: the integer port number
    packet_data: packed version of packet if available
    """
    assert assert_type("packet", packet, ethernet, none_ok=False)
    assert assert_type("in_port", in_port, int, none_ok=False)
    port = self.ports.get(in_port)
    if port is None:
      self.log.warn("Got packet on missing port %i", in_port)
      return

    is_stp = packet.dst == _STP_MAC

    if (port.config & OFPPC_NO_RECV) and not is_stp:
      # Drop all except STP
      return
    if (port.config & OFPPC_NO_RECV_STP) and is_stp:
      # Drop STP
      return

    if self.config_flags & OFPC_FRAG_MASK:
      ipp = packet.find(ipv4)
      if ipp:
        if (ipp.flags & ipv4.MF_FLAG) or ipp.frag != 0:
          frag_mode = self.config_flags & OFPC_FRAG_MASK
          if frag_mode == OFPC_FRAG_DROP:
            # Drop fragment
            return
          elif frag_mode == OFPC_FRAG_REASM:
            if self.features.cap_ip_reasm:
              #TODO: Implement fragment reassembly
              self.log.info("Can't reassemble fragment: not implemented")
          else:
            self.log.warn("Illegal fragment processing mode: %i", frag_mode)

    self.port_stats[in_port].rx_packets += 1
    if packet_data is not None:
      self.port_stats[in_port].rx_bytes += len(packet_data)
    else:
      self.port_stats[in_port].rx_bytes += len(packet.pack()) # Expensive

    self._lookup_count += 1
    entry = self.table.entry_for_packet(packet, in_port)
    if entry is not None:
      self._matched_count += 1
      entry.touch_packet(len(packet))
      self._process_actions_for_packet(entry.actions, packet, in_port)
    else:
      # no matching entry
      if port.config & OFPPC_NO_PACKET_IN:
        return
      buffer_id = self._buffer_packet(packet, in_port)
      if packet_data is None:
        packet_data = packet.pack()
      self.send_packet_in(in_port, buffer_id, packet_data,
                          reason=OFPR_NO_MATCH, data_length=self.miss_send_len)

  def delete_port (self, port):
    """
    Removes a port

    Sends a port_status message to the controller

    Returns the removed phy_port
    """
    try:
      port_no = port.port_no
      assert self.ports[port_no] is port
    except:
      port_no = port
      port = self.ports[port_no]
    if port_no not in self.ports:
      raise RuntimeError("Can't remove nonexistent port " + str(port_no))
    self.send_port_status(port, OFPPR_DELETE)
    del self.ports[port_no]
    return port

  def add_port (self, port):
    """
    Adds a port

    Sends a port_status message to the controller
    """
    try:
      port_no = port.port_no
    except:
      port_no = port
      port = self.generate_port(port_no, self.dpid)
    if port_no in self.ports:
      raise RuntimeError("Port %s already exists" % (port_no,))
    self.ports[port_no] = port
    self.port_stats[port.port_no] = ofp_port_stats(port_no=port.port_no)
    self.send_port_status(port, OFPPR_ADD)

  def _set_port_config_bit (self, port, bit, value):
    """
    Set a port config bit

    This is called in response to port_mods.  It is passed the ofp_phy_port,
    the bit/mask, and the value of the bit (i.e., 0 if the flag is to be
    unset, or the same value as bit if it is to be set).

    The return value is a tuple (handled, msg).
    If bit is handled, then handled will be True, else False.
    if msg is a string, it will be used as part of a log message.
    If msg is None, there will be no log message.
    If msg is anything else "truthy", an "enabled" log message is generated.
    If msg is anything else "falsy", a "disabled" log message is generated.
    msg is only used when handled is True.
    """
    if bit == OFPPC_NO_STP:
      if value == 0:
        # we also might send OFPBRC_EPERM if trying to disable this bit
        self.log.warn("Port %s: Can't enable 802.1D STP", port.port_no)
      return (True, None)

    if bit not in (OFPPC_PORT_DOWN, OFPPC_NO_STP, OFPPC_NO_RECV, OFPPC_NO_RECV_STP,
                   OFPPC_NO_FLOOD, OFPPC_NO_FWD, OFPPC_NO_PACKET_IN):
      return (False, None)

    if port.set_config(value, bit):
      if bit == OFPPC_PORT_DOWN:
        # Note (Peter Peresini): Although the spec is not clear about it,
        # we will assume that config.OFPPC_PORT_DOWN implies
        # state.OFPPS_LINK_DOWN. This is consistent with Open vSwitch.

        #TODO: for now, we assume that there is always physical link present
        # and that the link state depends only on the configuration.
        old_state = port.state & OFPPS_LINK_DOWN
        port.state = port.state & ~OFPPS_LINK_DOWN
        if port.config & OFPPC_PORT_DOWN:
          port.state = port.state | OFPPS_LINK_DOWN
        new_state = port.state & OFPPS_LINK_DOWN
        if old_state != new_state:
          self.send_port_status(port, OFPPR_MODIFY)

      # Do default log message.
      return (True, value)

    # No change -- no log message.
    return (True, None)

  def _output_packet_physical (self, packet, port_no):
    """
    send a packet out a single physical port

    This is called by the more general _output_packet().

    Override this.
    """
    self.log.info("Sending packet %s out port %s", str(packet), port_no)

  def _output_packet (self, packet, out_port, in_port, max_len=None):
    """
    send a packet out some port

    This handles virtual ports and does validation.

    packet: instance of ethernet
    out_port, in_port: the integer port number
    max_len: maximum packet payload length to send to controller
    """
    assert assert_type("packet", packet, ethernet, none_ok=False)

    def real_send (port_no, allow_in_port=False):
      if type(port_no) == ofp_phy_port:
        port_no = port_no.port_no
      if port_no == in_port and not allow_in_port:
        self.log.warn("Dropping packet sent on port %i: Input port", port_no)
        return
      if port_no not in self.ports:
        self.log.warn("Dropping packet sent on port %i: Invalid port", port_no)
        return
      if self.ports[port_no].config & OFPPC_NO_FWD:
        self.log.warn("Dropping packet sent on port %i: Forwarding disabled",
                      port_no)
        return
      if self.ports[port_no].config & OFPPC_PORT_DOWN:
        self.log.warn("Dropping packet sent on port %i: Port down", port_no)
        return
      if self.ports[port_no].state & OFPPS_LINK_DOWN:
        self.log.debug("Dropping packet sent on port %i: Link down", port_no)
        return
      self.port_stats[port_no].tx_packets += 1
      self.port_stats[port_no].tx_bytes += len(packet.pack()) #FIXME: Expensive
      self._output_packet_physical(packet, port_no)

    if out_port < OFPP_MAX:
      real_send(out_port)
    elif out_port == OFPP_IN_PORT:
      real_send(in_port, allow_in_port=True)
    elif out_port == OFPP_FLOOD:
      for no,port in self.ports.iteritems():
        if no == in_port: continue
        if port.config & OFPPC_NO_FLOOD: continue
        real_send(port)
    elif out_port == OFPP_ALL:
      for no,port in self.ports.iteritems():
        if no == in_port: continue
        real_send(port)
    elif out_port == OFPP_CONTROLLER:
      buffer_id = self._buffer_packet(packet, in_port)
      # Should we honor OFPPC_NO_PACKET_IN here?
      self.send_packet_in(in_port, buffer_id, packet, reason=OFPR_ACTION,
                          data_length=max_len)
    elif out_port == OFPP_TABLE:
      # Do we disable send-to-controller when performing this?
      # (Currently, there's the possibility that a table miss from this
      # will result in a send-to-controller which may send back to table...)
      self.rx_packet(packet, in_port)
    else:
      self.log.warn("Unsupported virtual output port: %d", out_port)

  def _buffer_packet (self, packet, in_port=None):
    """
    Buffer packet and return buffer ID

    If no buffer is available, return None.
    """
    # Do we have an empty slot?
    for (i, value) in enumerate(self._packet_buffer):
      if value is None:
        # Yes -- use it
        self._packet_buffer[i] = (packet, in_port)
        return i + 1
    # No -- create a new slow
    if len(self._packet_buffer) >= self.max_buffers:
      # No buffers available!
      return None
    self._packet_buffer.append( (packet, in_port) )
    return len(self._packet_buffer)

  def _process_actions_for_packet_from_buffer (self, actions, buffer_id,
                                               ofp=None):
    """
    output and release a packet from the buffer

    ofp is the message which triggered this processing, if any (used for error
    generation)
    """
    buffer_id = buffer_id - 1
    if (buffer_id >= len(self._packet_buffer)) or (buffer_id < 0):
      self.log.warn("Invalid output buffer id: %d", buffer_id + 1)
      return
    if self._packet_buffer[buffer_id] is None:
      self.log.warn("Buffer %d has already been flushed", buffer_id + 1)
      return
    (packet, in_port) = self._packet_buffer[buffer_id]
    self._process_actions_for_packet(actions, packet, in_port, ofp)
    self._packet_buffer[buffer_id] = None

  def _process_actions_for_packet (self, actions, packet, in_port, ofp=None):
    """
    process the output actions for a packet

    ofp is the message which triggered this processing, if any (used for error
    generation)
    """
    assert assert_type("packet", packet, (ethernet, bytes), none_ok=False)
    if not isinstance(packet, ethernet):
      packet = ethernet.unpack(packet)

    for action in actions:
      #if action.type is ofp_action_resubmit:
      #  self.rx_packet(packet, in_port)
      #  return
      h = self.action_handlers.get(action.type)
      if h is None:
        self.log.warn("Unknown action type: %x " % (action.type,))
        self.send_error(type=OFPET_BAD_ACTION, code=OFPBAC_BAD_TYPE, ofp=ofp)
        return
      packet = h(action, packet, in_port)

  def _flow_mod_add (self, flow_mod, connection, table):
    """
    Process an OFPFC_ADD flow mod sent to the switch.
    """
    match = flow_mod.match
    priority = flow_mod.priority

    if flow_mod.flags & OFPFF_EMERG:
      if flow_mod.idle_timeout != 0 or flow_mod.hard_timeout != 0:
        # Emergency flow mod has non-zero timeouts. Do not add.
        self.log.warn("Rejecting emergency flow with nonzero timeout")
        self.send_error(type=OFPET_FLOW_MOD_FAILED,
                        code=OFPFMFC_BAD_EMERG_TIMEOUT,
                        ofp=flow_mod, connection=connection)
        return
      if flow_mod.flags & OFPFF_SEND_FLOW_REM:
        # Emergency flows can't send removal messages, we we might want to
        # reject this early.  Sadly, there's no error code for this, so we just
        # abuse EPERM.  If we eventually support Nicira extended error codes,
        # we should use one here.
        self.log.warn("Rejecting emergency flow with flow removal flag")
        self.send_error(type=OFPET_FLOW_MOD_FAILED,
                        code=OFPFMFC_EPERM,
                        ofp=flow_mod, connection=connection)
        return
      #NOTE: An error is sent anyways because the current implementation does
      #      not support emergency entries.
      self.log.warn("Rejecting emergency flow (not supported)")
      self.send_error(type=OFPET_FLOW_MOD_FAILED,
                      code=OFPFMFC_ALL_TABLES_FULL,
                      ofp=flow_mod, connection=connection)
      return

    new_entry = TableEntry.from_flow_mod(flow_mod)

    if flow_mod.flags & OFPFF_CHECK_OVERLAP:
      if table.check_for_overlapping_entry(new_entry):
        # Another entry overlaps. Do not add.
        self.send_error(type=OFPET_FLOW_MOD_FAILED, code=OFPFMFC_OVERLAP,
                        ofp=flow_mod, connection=connection)
        return

    if flow_mod.command == OFPFC_ADD:
      # Exactly matching entries have to be removed if OFPFC_ADD
      table.remove_matching_entries(match, priority=priority, strict=True)

    if len(table) >= self.max_entries:
      # Flow table is full. Respond with error message.
      self.send_error(type=OFPET_FLOW_MOD_FAILED,
                      code=OFPFMFC_ALL_TABLES_FULL,
                      ofp=flow_mod, connection=connection)
      return

    table.add_entry(new_entry)

  def _flow_mod_modify (self, flow_mod, connection, table, strict=False):
    """
    Process an OFPFC_MODIFY flow mod sent to the switch.
    """
    match = flow_mod.match
    priority = flow_mod.priority

    modified = False
    for entry in table.entries:
      # update the actions field in the matching flows
      if entry.is_matched_by(match, priority=priority, strict=strict):
        entry.actions = flow_mod.actions
        modified = True

    if not modified:
      # if no matching entry is found, modify acts as add
      self._flow_mod_add(flow_mod, connection, table)

  def _flow_mod_modify_strict (self, flow_mod, connection, table):
    """
    Process an OFPFC_MODIFY_STRICT flow mod sent to the switch.
    """
    self._flow_mod_modify(flow_mod, connection, table, strict=True)

  def _flow_mod_delete (self, flow_mod, connection, table, strict=False):
    """
    Process an OFPFC_DELETE flow mod sent to the switch.
    """
    match = flow_mod.match
    priority = flow_mod.priority

    out_port = flow_mod.out_port
    if out_port == OFPP_NONE: out_port = None # Don't filter
    table.remove_matching_entries(match, priority=priority, strict=strict,
                                  out_port=out_port, reason=OFPRR_DELETE)

  def _flow_mod_delete_strict (self, flow_mod, connection, table):
    """
    Process an OFPFC_DELETE_STRICT flow mod sent to the switch.
    """
    self._flow_mod_delete(flow_mod, connection, table, strict=True)

  def _action_output (self, action, packet, in_port):
    self._output_packet(packet, action.port, in_port, action.max_len)
    return packet
  def _action_set_vlan_vid (self, action, packet, in_port):
    if not isinstance(packet.payload, vlan):
      vl = vlan()
      vl.eth_type = packet.type
      vl.payload = packet.payload
      packet.type = ethernet.VLAN_TYPE
      packet.payload = vl
    packet.payload.id = action.vlan_vid
    return packet
  def _action_set_vlan_pcp (self, action, packet, in_port):
    if not isinstance(packet.payload, vlan):
      vl = vlan()
      vl.payload = packet.payload
      vl.eth_type = packet.type
      packet.payload = vl
      packet.type = ethernet.VLAN_TYPE
    packet.payload.pcp = action.vlan_pcp
    return packet
  def _action_strip_vlan (self, action, packet, in_port):
    if isinstance(packet.payload, vlan):
      packet.type = packet.payload.eth_type
      packet.payload = packet.payload.payload
    return packet
  def _action_set_dl_src (self, action, packet, in_port):
    packet.src = action.dl_addr
    return packet
  def _action_set_dl_dst (self, action, packet, in_port):
    packet.dst = action.dl_addr
    return packet
  def _action_set_nw_src (self, action, packet, in_port):
    nw = packet.payload
    if isinstance(nw, vlan):
      nw = nw.payload
    if isinstance(nw, ipv4):
      nw.srcip = action.nw_addr
    return packet
  def _action_set_nw_dst (self, action, packet, in_port):
    nw = packet.payload
    if isinstance(nw, vlan):
      nw = nw.payload
    if isinstance(nw, ipv4):
      nw.dstip = action.nw_addr
    return packet
  def _action_set_nw_tos (self, action, packet, in_port):
    nw = packet.payload
    if isinstance(nw, vlan):
      nw = nw.payload
    if isinstance(nw, ipv4):
      nw.tos = action.nw_tos
    return packet
  def _action_set_tp_src (self, action, packet, in_port):
    nw = packet.payload
    if isinstance(nw, vlan):
      nw = nw.payload
    if isinstance(nw, ipv4):
      tp = nw.payload
      if isinstance(tp, udp) or isinstance(tp, tcp):
        tp.srcport = action.tp_port
    return packet
  def _action_set_tp_dst (self, action, packet, in_port):
    nw = packet.payload
    if isinstance(nw, vlan):
      nw = nw.payload
    if isinstance(nw, ipv4):
      tp = nw.payload
      if isinstance(tp, udp) or isinstance(tp, tcp):
        tp.dstport = action.tp_port
    return packet
  def _action_enqueue (self, action, packet, in_port):
    self.log.warn("Enqueue not supported.  Performing regular output.")
    self._output_packet(packet, action.tp_port, in_port)
    return packet
#  def _action_push_mpls_tag (self, action, packet, in_port):
#    bottom_of_stack = isinstance(packet.next, mpls)
#    packet.next = mpls(prev = packet.pack())
#    if bottom_of_stack:
#      packet.next.s = 1
#    packet.type = action.ethertype
#    return packet
#  def _action_pop_mpls_tag (self, action, packet, in_port):
#    if not isinstance(packet.next, mpls):
#      return packet
#    if not isinstance(packet.next.next, str):
#      packet.next.next = packet.next.next.pack()
#    if action.ethertype in ethernet.type_parsers:
#      packet.next = ethernet.type_parsers[action.ethertype](packet.next.next)
#    else:
#      packet.next = packet.next.next
#    packet.ethertype = action.ethertype
#    return packet
#  def _action_set_mpls_label (self, action, packet, in_port):
#    if not isinstance(packet.next, mpls):
#      mock = ofp_action_push_mpls()
#      packet = push_mpls_tag(mock, packet)
#    packet.next.label = action.mpls_label
#    return packet
#  def _action_set_mpls_tc (self, action, packet, in_port):
#    if not isinstance(packet.next, mpls):
#      mock = ofp_action_push_mpls()
#      packet = push_mpls_tag(mock, packet)
#    packet.next.tc = action.mpls_tc
#    return packet
#  def _action_set_mpls_ttl (self, action, packet, in_port):
#    if not isinstance(packet.next, mpls):
#      mock = ofp_action_push_mpls()
#      packet = push_mpls_tag(mock, packet)
#    packet.next.ttl = action.mpls_ttl
#    return packet
#  def _action_dec_mpls_ttl (self, action, packet, in_port):
#    if not isinstance(packet.next, mpls):
#      return packet
#    packet.next.ttl = packet.next.ttl - 1
#    return packet


  def _stats_desc (self, ofp, connection):
    try:
      from pox.core import core
      return ofp_desc_stats(mfr_desc="POX",
                            hw_desc=core._get_platform_info(),
                            sw_desc=core.version_string,
                            serial_num=str(self.dpid),
                            dp_desc=type(self).__name__)
    except:
      return ofp_desc_stats(mfr_desc="POX",
                            hw_desc="Unknown",
                            sw_desc="Unknown",
                            serial_num=str(self.dpid),
                            dp_desc=type(self).__name__)


  def _stats_flow (self, ofp, connection):
    if ofp.body.table_id not in (TABLE_ALL, 0):
      return [] # No flows for other tables
    out_port = ofp.body.out_port
    if out_port == OFPP_NONE: out_port = None # Don't filter
    return self.table.flow_stats(ofp.body.match, out_port)

  def _stats_aggregate (self, ofp, connection):
    if ofp.body.table_id not in (TABLE_ALL, 0):
      return [] # No flows for other tables
    out_port = ofp.body.out_port
    if out_port == OFPP_NONE: out_port = None # Don't filter
    return self.table.aggregate_stats(ofp.body.match, out_port)

  def _stats_table (self, ofp, connection):
    # Some of these may come from the actual table(s) in the future...
    r = ofp_table_stats()
    r.table_id = 0
    r.name = "Default"
    r.wildcards = OFPFW_ALL
    r.max_entries = self.max_entries
    r.active_count = len(self.table)
    r.lookup_count = self._lookup_count
    r.matched_count = self._matched_count
    return r

  def _stats_port (self, ofp, connection):
    req = ofp.body
    if req.port_no == OFPP_NONE:
      return self.port_stats.values()
    else:
      return self.port_stats[req.port_no]

  def _stats_queue (self, ofp, connection):
    # We don't support queues whatsoever so either send an empty list or send
    # an OFP_ERROR if an actual queue is requested.
    req = ofp.body
    #if req.port_no != OFPP_ALL:
    #  self.send_error(type=OFPET_QUEUE_OP_FAILED, code=OFPQOFC_BAD_PORT,
    #                  ofp=ofp, connection=connection)
    # Note: We don't care about this case for now, even if port_no is bogus.
    if req.queue_id == OFPQ_ALL:
      return []
    else:
      self.send_error(type=OFPET_QUEUE_OP_FAILED, code=OFPQOFC_BAD_QUEUE,
                      ofp=ofp, connection=connection)


  def __repr__ (self):
    return "%s(dpid=%s, num_ports=%d)" % (type(self).__name__,
                                          dpid_to_str(self.dpid),
                                          len(self.ports))


class SoftwareSwitch (SoftwareSwitchBase, EventMixin):
  _eventMixin_events = set([DpPacketOut])

  def _output_packet_physical (self, packet, port_no):
    """
    send a packet out a single physical port

    This is called by the more general _output_packet().
    """
    self.raiseEvent(DpPacketOut(self, packet, self.ports[port_no]))


class ExpireMixin (object):
  """
  Adds expiration to a switch

  Inherit *before* switch base.
  """
  _expire_period = 2

  def __init__ (self, *args, **kw):
    expire_period = kw.pop('expire_period', self._expire_period)
    super(ExpireMixin,self).__init__(*args, **kw)
    if not expire_period:
      # Disable
      return
    self._expire_timer = Timer(expire_period,
                               self.table.remove_expired_entries,
                               recurring=True)


class OFConnection (object):
  """
  A codec for OpenFlow messages.

  Decodes and encodes OpenFlow messages (ofp_message) into byte arrays.

  Wraps an io_worker that does the actual io work, and calls a
  receiver_callback function when a new message as arrived.
  """

  # Unlike of_01.Connection, this is persistent (at least until we implement
  # a proper recoco Connection Listener loop)
  # Globally unique identifier for the Connection instance
  ID = 0

  # See _error_handler for information the meanings of these
  ERR_BAD_VERSION = 1
  ERR_NO_UNPACKER = 2
  ERR_BAD_LENGTH  = 3
  ERR_EXCEPTION   = 4

  # These methods are called externally by IOWorker
  def msg (self, m):
    self.log.debug("%s %s", str(self), str(m))
  def err (self, m):
    self.log.error("%s %s", str(self), str(m))
  def info (self, m):
    self.log.info("%s %s", str(self), str(m))

  def __init__ (self, io_worker):
    self.starting = True # No data yet
    self.io_worker = io_worker
    self.io_worker.rx_handler = self.read
    self.controller_id = io_worker.socket.getpeername()
    OFConnection.ID += 1
    self.ID = OFConnection.ID
    self.log = logging.getLogger("ControllerConnection(id=%d)" % (self.ID,))
    self.unpackers = make_type_to_unpacker_table()

    self.on_message_received = None

  def set_message_handler (self, handler):
    self.on_message_received = handler

  def send (self, data):
    """
    Send raw data to the controller.

    Generally, data is a bytes object. If not, we check if it has a pack()
    method and call it (hoping the result will be a bytes object).  This
    way, you can just pass one of the OpenFlow objects from the OpenFlow
    library to it and get the expected result, for example.
    """
    if type(data) is not bytes:
      if hasattr(data, 'pack'):
        data = data.pack()
    self.io_worker.send(data)

  def read (self, io_worker):
    #FIXME: Do we need to pass io_worker here?
    while True:
      message = io_worker.peek()
      if len(message) < 4:
        break

      # Parse head of OpenFlow message by hand
      ofp_version = ord(message[0])
      ofp_type = ord(message[1])

      if ofp_version != OFP_VERSION:
        info = ofp_version
        r = self._error_handler(self.ERR_BAD_VERSION, info)
        if r is False: break
        continue

      message_length = ord(message[2]) << 8 | ord(message[3])
      if message_length > len(message):
        break

      if ofp_type >= 0 and ofp_type < len(self.unpackers):
        unpacker = self.unpackers[ofp_type]
      else:
        unpacker = None
      if unpacker is None:
        info = (ofp_type, message_length)
        r = self._error_handler(self.ERR_NO_UNPACKER, info)
        if r is False: break
        io_worker.consume_receive_buf(message_length)
        continue

      new_offset, msg_obj = self.unpackers[ofp_type](message, 0)
      if new_offset != message_length:
        info = (msg_obj, message_length, new_offset)
        r = self._error_handler(self.ERR_BAD_LENGTH, info)
        if r is False: break
        # Assume sender was right and we should skip what it told us to.
        io_worker.consume_receive_buf(message_length)
        continue

      io_worker.consume_receive_buf(message_length)
      self.starting = False

      if self.on_message_received is None:
        raise RuntimeError("on_message_receieved hasn't been set yet!")

      try:
        self.on_message_received(self, msg_obj)
      except Exception as e:
        info = (e, message[:message_length], msg_obj)
        r = self._error_handler(self.ERR_EXCEPTION, info)
        if r is False: break
        continue

    return True

  def _error_handler (self, reason, info):
      """
      Called when read() has an error

      reason is one of OFConnection.ERR_X

      info depends on reason:
      ERR_BAD_VERSION: claimed version number
      ERR_NO_UNPACKER: (claimed message type, claimed length)
      ERR_BAD_LENGTH: (unpacked message, claimed length, unpacked length)
      ERR_EXCEPTION: (exception, raw message, unpacked message)

      Return False to halt processing of subsequent data (makes sense to
      do this if you called connection.close() here, for example).
      """
      if reason == OFConnection.ERR_BAD_VERSION:
        ofp_version = info
        self.log.warn('Unsupported OpenFlow version 0x%02x', info)
        if self.starting:
          message = self.io_worker.peek()
          err = ofp_error(type=OFPET_HELLO_FAILED, code=OFPHFC_INCOMPATIBLE)
          #err = ofp_error(type=OFPET_BAD_REQUEST, code=OFPBRC_BAD_VERSION)
          err.xid = self._extract_message_xid(message)
          err.data = 'Version unsupported'
          self.send(err)
        self.close()
        return False
      elif reason == OFConnection.ERR_NO_UNPACKER:
        ofp_type, message_length = info
        self.log.warn('Unsupported OpenFlow message type 0x%02x', ofp_type)
        message = self.io_worker.peek()
        err = ofp_error(type=OFPET_BAD_REQUEST, code=OFPBRC_BAD_TYPE)
        err.xid = self._extract_message_xid(message)
        err.data = message[:message_length]
        self.send(err)
      elif reason == OFConnection.ERR_BAD_LENGTH:
        msg_obj, message_length, new_offset = info
        t = type(msg_obj).__name__
        self.log.error('Different idea of message length for %s '
                       '(us:%s them:%s)' % (t, new_offset, message_length))
        message = self.io_worker.peek()
        err = ofp_error(type=OFPET_BAD_REQUEST, code=OFPBRC_BAD_LEN)
        err.xid = self._extract_message_xid(message)
        err.data = message[:message_length]
        self.send(err)
      elif reason == OFConnection.ERR_EXCEPTION:
        ex, raw_message, msg_obj = info
        t = type(ex).__name__
        self.log.exception('Exception handling %s' % (t,))
      else:
        self.log.error("Unhandled error")
        self.close()
        return False

  def _extract_message_xid (self, message):
    """
    Extract and return the xid (and length) of an openflow message.
    """
    xid = 0
    if len(message) >= 8:
      #xid = struct.unpack_from('!L', message, 4)[0]
      message_length, xid = struct.unpack_from('!HL', message, 2)
    elif len(message) >= 4:
      message_length = ord(message[2]) << 8 | ord(message[3])
    else:
      message_length = len(message)
    return xid

  def close (self):
    self.io_worker.shutdown()

  def get_controller_id (self):
    """
    Return a tuple of the controller's (address, port) we are connected to
    """
    return self.controller_id

  def __str__ (self):
    return "[Con " + str(self.ID) + "]"


class SwitchFeatures (object):
  """
  Stores switch features

  Keeps settings for switch capabilities and supported actions.
  Automatically has attributes of the form ".act_foo" for all OFPAT_FOO,
  and ".cap_foo" for all OFPC_FOO (as gathered from libopenflow).
  """
  def __init__ (self, **kw):
    self._cap_info = {}
    for val,name in ofp_capabilities_map.iteritems():
      name = name[5:].lower() # strip OFPC_
      name = "cap_" + name
      setattr(self, name, False)
      self._cap_info[name] = val

    self._act_info = {}
    for val,name in ofp_action_type_map.iteritems():
      name = name[6:].lower() # strip OFPAT_
      name = "act_" + name
      setattr(self, name, False)
      self._act_info[name] = val

    self._locked = True

    initHelper(self, kw)

  def __setattr__ (self, attr, value):
    if getattr(self, '_locked', False):
      if not hasattr(self, attr):
        raise AttributeError("No such attribute as '%s'" % (attr,))
    return super(SwitchFeatures,self).__setattr__(attr, value)

  @property
  def capability_bits (self):
    """
    Value used in features reply
    """
    return sum( (v if getattr(self, k) else 0)
                for k,v in self._cap_info.iteritems() )

  @property
  def action_bits (self):
    """
    Value used in features reply
    """
    return sum( (1<<v if getattr(self, k) else 0)
                for k,v in self._act_info.iteritems() )

  def __str__ (self):
    l = list(k for k in self._cap_info if getattr(self, k))
    l += list(k for k in self._act_info if getattr(self, k))
    return ",".join(l)

########NEW FILE########
__FILENAME__ = hub
# Copyright 2012 James McCauley
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at:
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""
Turns your complex OpenFlow switches into stupid hubs.
"""

from pox.core import core
import pox.openflow.libopenflow_01 as of
from pox.lib.util import dpidToStr

log = core.getLogger()


def _handle_ConnectionUp (event):
  msg = of.ofp_flow_mod()
  msg.actions.append(of.ofp_action_output(port = of.OFPP_FLOOD))
  event.connection.send(msg)
  log.info("Hubifying %s", dpidToStr(event.dpid))

def launch ():
  core.openflow.addListenerByName("ConnectionUp", _handle_ConnectionUp)

  log.info("Hub running.")

########NEW FILE########
__FILENAME__ = l2_flowvisor
# Copyright 2012 James McCauley
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at:
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""
A modification of l2_pairs to work with FlowVisor on looped topologies.

The spanning_tree component doesn't work with FlowVisor because FlowVisor
does not virtualize the NO_FLOOD bit on switch ports, which is what
the spanning_tree component would need to work properly.

This hack of l2_pairs uses the spanning tree construction from the
spanning_tree component, but instead of using it to modify port bits,
instead of ever actually flooding, it "simulates" flooding by just
adding all of the ports on the spanning tree as individual output
actions.

Requires discovery.
"""

# These next two imports are common POX convention
from pox.core import core
import pox.openflow.libopenflow_01 as of
import pox.openflow.spanning_tree as spanning_tree

# Even a simple usage of the logger is much nicer than print!
log = core.getLogger()


# This table maps (switch,MAC-addr) pairs to the port on 'switch' at
# which we last saw a packet *from* 'MAC-addr'.
# (In this case, we use a Connection object for the switch.)
table = {}


# A spanning tree to be used for flooding
tree = {}

def _handle_links (event):
  """
  Handle discovery link events to update the spanning tree
  """
  global tree
  tree = spanning_tree._calc_spanning_tree()


def _handle_PacketIn (event):
  """
  Handle messages the switch has sent us because it has no
  matching rule.
  """

  def drop ():
    # Kill buffer on switch
    if event.ofp.buffer_id is not None:
      msg = of.ofp_packet_out()
      msg.buffer_id = event.ofp.buffer_id
      msg.in_port = event.port
      event.connection.send(msg)

  packet = event.parsed

  if packet.type == packet.LLDP_TYPE or packet.dst.isBridgeFiltered():
     return drop()

  # Learn the source
  table[(event.connection,packet.src)] = event.port

  if not packet.dst.is_multicast:
    dst_port = table.get((event.connection,packet.dst))
  else:
    # Ideally, we'd install a flow entries that output multicasts
    # to all ports on the spanning tree.
    dst_port = None

  if dst_port is None:
    # We don't know where the destination is yet.  So, we'll just
    # send the packet out all ports in the spanning tree
    # and hope the destination is out there somewhere. :)
    msg = of.ofp_packet_out(data = event.ofp)

    tree_ports = [p[1] for p in tree.get(event.dpid, [])]

    for p in event.connection.ports:
      if p >= of.OFPP_MAX:
        # Not a normal port
        continue

      if not core.openflow_discovery.is_edge_port(event.dpid, p):
        # If the port isn't a switch-to-switch port, it's fine to flood
        # through it.  But if it IS a switch-to-switch port, we only
        # want to use it if it's on the spanning tree.
        if p not in tree_ports:
          continue

      msg.actions.append(of.ofp_action_output(port = p))

    event.connection.send(msg)

  else:
    # Since we know the switch ports for both the source and dest
    # MACs, we can install rules for both directions.
    msg = of.ofp_flow_mod()
    msg.match.dl_dst = packet.src
    msg.match.dl_src = packet.dst
    msg.actions.append(of.ofp_action_output(port = event.port))
    event.connection.send(msg)
    
    # This is the packet that just came in -- we want to
    # install the rule and also resend the packet.
    msg = of.ofp_flow_mod()
    msg.data = event.ofp # Forward the incoming packet
    msg.match.dl_src = packet.src
    msg.match.dl_dst = packet.dst
    msg.actions.append(of.ofp_action_output(port = dst_port))
    event.connection.send(msg)

    log.debug("Installing %s <-> %s" % (packet.src, packet.dst))


def launch ():
  def start ():
    core.openflow_discovery.addListenerByName("LinkEvent", _handle_links)
    core.openflow.addListenerByName("PacketIn", _handle_PacketIn)
    log.info("FlowVisor Pair-Learning switch running.")
  core.call_when_ready(start, "openflow_discovery")

########NEW FILE########
__FILENAME__ = l2_learning
# Copyright 2011-2012 James McCauley
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at:
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""
An L2 learning switch.

It is derived from one written live for an SDN crash course.
It is somwhat similar to NOX's pyswitch in that it installs
exact-match rules for each flow.
"""

from pox.core import core
import pox.openflow.libopenflow_01 as of
from pox.lib.util import dpid_to_str
from pox.lib.util import str_to_bool
import time

log = core.getLogger()

# We don't want to flood immediately when a switch connects.
# Can be overriden on commandline.
_flood_delay = 0

class LearningSwitch (object):
  """
  The learning switch "brain" associated with a single OpenFlow switch.

  When we see a packet, we'd like to output it on a port which will
  eventually lead to the destination.  To accomplish this, we build a
  table that maps addresses to ports.

  We populate the table by observing traffic.  When we see a packet
  from some source coming from some port, we know that source is out
  that port.

  When we want to forward traffic, we look up the desintation in our
  table.  If we don't know the port, we simply send the message out
  all ports except the one it came in on.  (In the presence of loops,
  this is bad!).

  In short, our algorithm looks like this:

  For each packet from the switch:
  1) Use source address and switch port to update address/port table
  2) Is transparent = False and either Ethertype is LLDP or the packet's
     destination address is a Bridge Filtered address?
     Yes:
        2a) Drop packet -- don't forward link-local traffic (LLDP, 802.1x)
            DONE
  3) Is destination multicast?
     Yes:
        3a) Flood the packet
            DONE
  4) Port for destination address in our address/port table?
     No:
        4a) Flood the packet
            DONE
  5) Is output port the same as input port?
     Yes:
        5a) Drop packet and similar ones for a while
  6) Install flow table entry in the switch so that this
     flow goes out the appopriate port
     6a) Send the packet out appropriate port
  """
  def __init__ (self, connection, transparent):
    # Switch we'll be adding L2 learning switch capabilities to
    self.connection = connection
    self.transparent = transparent

    # Our table
    self.macToPort = {}

    # We want to hear PacketIn messages, so we listen
    # to the connection
    connection.addListeners(self)

    # We just use this to know when to log a helpful message
    self.hold_down_expired = _flood_delay == 0

    #log.debug("Initializing LearningSwitch, transparent=%s",
    #          str(self.transparent))

  def _handle_PacketIn (self, event):
    """
    Handle packet in messages from the switch to implement above algorithm.
    """

    packet = event.parsed

    def flood (message = None):
      """ Floods the packet """
      msg = of.ofp_packet_out()
      if time.time() - self.connection.connect_time >= _flood_delay:
        # Only flood if we've been connected for a little while...

        if self.hold_down_expired is False:
          # Oh yes it is!
          self.hold_down_expired = True
          log.info("%s: Flood hold-down expired -- flooding",
              dpid_to_str(event.dpid))

        if message is not None: log.debug(message)
        #log.debug("%i: flood %s -> %s", event.dpid,packet.src,packet.dst)
        # OFPP_FLOOD is optional; on some switches you may need to change
        # this to OFPP_ALL.
        msg.actions.append(of.ofp_action_output(port = of.OFPP_FLOOD))
      else:
        pass
        #log.info("Holding down flood for %s", dpid_to_str(event.dpid))
      msg.data = event.ofp
      msg.in_port = event.port
      self.connection.send(msg)

    def drop (duration = None):
      """
      Drops this packet and optionally installs a flow to continue
      dropping similar ones for a while
      """
      if duration is not None:
        if not isinstance(duration, tuple):
          duration = (duration,duration)
        msg = of.ofp_flow_mod()
        msg.match = of.ofp_match.from_packet(packet)
        msg.idle_timeout = duration[0]
        msg.hard_timeout = duration[1]
        msg.buffer_id = event.ofp.buffer_id
        self.connection.send(msg)
      elif event.ofp.buffer_id is not None:
        msg = of.ofp_packet_out()
        msg.buffer_id = event.ofp.buffer_id
        msg.in_port = event.port
        self.connection.send(msg)

    self.macToPort[packet.src] = event.port # 1

    if not self.transparent: # 2
      if packet.type == packet.LLDP_TYPE or packet.dst.isBridgeFiltered():
        drop() # 2a
        return

    if packet.dst.is_multicast:
      flood() # 3a
    else:
      if packet.dst not in self.macToPort: # 4
        flood("Port for %s unknown -- flooding" % (packet.dst,)) # 4a
      else:
        port = self.macToPort[packet.dst]
        if port == event.port: # 5
          # 5a
          log.warning("Same port for packet from %s -> %s on %s.%s.  Drop."
              % (packet.src, packet.dst, dpid_to_str(event.dpid), port))
          drop(10)
          return
        # 6
        log.debug("installing flow for %s.%i -> %s.%i" %
                  (packet.src, event.port, packet.dst, port))
        msg = of.ofp_flow_mod()
        msg.match = of.ofp_match.from_packet(packet, event.port)
        msg.idle_timeout = 10
        msg.hard_timeout = 30
        msg.actions.append(of.ofp_action_output(port = port))
        msg.data = event.ofp # 6a
        self.connection.send(msg)


class l2_learning (object):
  """
  Waits for OpenFlow switches to connect and makes them learning switches.
  """
  def __init__ (self, transparent):
    core.openflow.addListeners(self)
    self.transparent = transparent

  def _handle_ConnectionUp (self, event):
    log.debug("Connection %s" % (event.connection,))
    LearningSwitch(event.connection, self.transparent)


def launch (transparent=False, hold_down=_flood_delay):
  """
  Starts an L2 learning switch.
  """
  try:
    global _flood_delay
    _flood_delay = int(str(hold_down), 10)
    assert _flood_delay >= 0
  except:
    raise RuntimeError("Expected hold-down to be a number")

  core.registerNew(l2_learning, str_to_bool(transparent))

########NEW FILE########
__FILENAME__ = l2_multi
# Copyright 2012-2013 James McCauley
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at:
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""
A shortest-path forwarding application.

This is a standalone L2 switch that learns ethernet addresses
across the entire network and picks short paths between them.

You shouldn't really write an application this way -- you should
keep more state in the controller (that is, your flow tables),
and/or you should make your topology more static.  However, this
does (mostly) work. :)

Depends on openflow.discovery
Works with openflow.spanning_tree
"""

from pox.core import core
import pox.openflow.libopenflow_01 as of
from pox.lib.revent import *
from pox.lib.recoco import Timer
from collections import defaultdict
from pox.openflow.discovery import Discovery
from pox.lib.util import dpid_to_str
import time

log = core.getLogger()

# Adjacency map.  [sw1][sw2] -> port from sw1 to sw2
adjacency = defaultdict(lambda:defaultdict(lambda:None))

# Switches we know of.  [dpid] -> Switch
switches = {}

# ethaddr -> (switch, port)
mac_map = {}

# [sw1][sw2] -> (distance, intermediate)
path_map = defaultdict(lambda:defaultdict(lambda:(None,None)))

# Waiting path.  (dpid,xid)->WaitingPath
waiting_paths = {}

# Time to not flood in seconds
FLOOD_HOLDDOWN = 5

# Flow timeouts
FLOW_IDLE_TIMEOUT = 10
FLOW_HARD_TIMEOUT = 30

# How long is allowable to set up a path?
PATH_SETUP_TIME = 4


def _calc_paths ():
  """
  Essentially Floyd-Warshall algorithm
  """

  def dump ():
    for i in sws:
      for j in sws:
        a = path_map[i][j][0]
        #a = adjacency[i][j]
        if a is None: a = "*"
        print a,
      print

  sws = switches.values()
  path_map.clear()
  for k in sws:
    for j,port in adjacency[k].iteritems():
      if port is None: continue
      path_map[k][j] = (1,None)
    path_map[k][k] = (0,None) # distance, intermediate

  #dump()

  for k in sws:
    for i in sws:
      for j in sws:
        if path_map[i][k][0] is not None:
          if path_map[k][j][0] is not None:
            # i -> k -> j exists
            ikj_dist = path_map[i][k][0]+path_map[k][j][0]
            if path_map[i][j][0] is None or ikj_dist < path_map[i][j][0]:
              # i -> k -> j is better than existing
              path_map[i][j] = (ikj_dist, k)

  #print "--------------------"
  #dump()


def _get_raw_path (src, dst):
  """
  Get a raw path (just a list of nodes to traverse)
  """
  if len(path_map) == 0: _calc_paths()
  if src is dst:
    # We're here!
    return []
  if path_map[src][dst][0] is None:
    return None
  intermediate = path_map[src][dst][1]
  if intermediate is None:
    # Directly connected
    return []
  return _get_raw_path(src, intermediate) + [intermediate] + \
         _get_raw_path(intermediate, dst)


def _check_path (p):
  """
  Make sure that a path is actually a string of nodes with connected ports

  returns True if path is valid
  """
  for a,b in zip(p[:-1],p[1:]):
    if adjacency[a[0]][b[0]] != a[2]:
      return False
    if adjacency[b[0]][a[0]] != b[1]:
      return False
  return True


def _get_path (src, dst, first_port, final_port):
  """
  Gets a cooked path -- a list of (node,in_port,out_port)
  """
  # Start with a raw path...
  if src == dst:
    path = [src]
  else:
    path = _get_raw_path(src, dst)
    if path is None: return None
    path = [src] + path + [dst]

  # Now add the ports
  r = []
  in_port = first_port
  for s1,s2 in zip(path[:-1],path[1:]):
    out_port = adjacency[s1][s2]
    r.append((s1,in_port,out_port))
    in_port = adjacency[s2][s1]
  r.append((dst,in_port,final_port))

  assert _check_path(r), "Illegal path!"

  return r


class WaitingPath (object):
  """
  A path which is waiting for its path to be established
  """
  def __init__ (self, path, packet):
    """
    xids is a sequence of (dpid,xid)
    first_switch is the DPID where the packet came from
    packet is something that can be sent in a packet_out
    """
    self.expires_at = time.time() + PATH_SETUP_TIME
    self.path = path
    self.first_switch = path[0][0].dpid
    self.xids = set()
    self.packet = packet

    if len(waiting_paths) > 1000:
      WaitingPath.expire_waiting_paths()

  def add_xid (self, dpid, xid):
    self.xids.add((dpid,xid))
    waiting_paths[(dpid,xid)] = self

  @property
  def is_expired (self):
    return time.time() >= self.expires_at

  def notify (self, event):
    """
    Called when a barrier has been received
    """
    self.xids.discard((event.dpid,event.xid))
    if len(self.xids) == 0:
      # Done!
      if self.packet:
        log.debug("Sending delayed packet out %s"
                  % (dpid_to_str(self.first_switch),))
        msg = of.ofp_packet_out(data=self.packet,
            action=of.ofp_action_output(port=of.OFPP_TABLE))
        core.openflow.sendToDPID(self.first_switch, msg)

      core.l2_multi.raiseEvent(PathInstalled(self.path))


  @staticmethod
  def expire_waiting_paths ():
    packets = set(waiting_paths.values())
    killed = 0
    for p in packets:
      if p.is_expired:
        killed += 1
        for entry in p.xids:
          waiting_paths.pop(entry, None)
    if killed:
      log.error("%i paths failed to install" % (killed,))


class PathInstalled (Event):
  """
  Fired when a path is installed
  """
  def __init__ (self, path):
    Event.__init__(self)
    self.path = path


class Switch (EventMixin):
  def __init__ (self):
    self.connection = None
    self.ports = None
    self.dpid = None
    self._listeners = None
    self._connected_at = None

  def __repr__ (self):
    return dpid_to_str(self.dpid)

  def _install (self, switch, in_port, out_port, match, buf = None):
    msg = of.ofp_flow_mod()
    msg.match = match
    msg.match.in_port = in_port
    msg.idle_timeout = FLOW_IDLE_TIMEOUT
    msg.hard_timeout = FLOW_HARD_TIMEOUT
    msg.actions.append(of.ofp_action_output(port = out_port))
    msg.buffer_id = buf
    switch.connection.send(msg)

  def _install_path (self, p, match, packet_in=None):
    wp = WaitingPath(p, packet_in)
    for sw,in_port,out_port in p:
      self._install(sw, in_port, out_port, match)
      msg = of.ofp_barrier_request()
      sw.connection.send(msg)
      wp.add_xid(sw.dpid,msg.xid)

  def install_path (self, dst_sw, last_port, match, event):
    """
    Attempts to install a path between this switch and some destination
    """
    p = _get_path(self, dst_sw, event.port, last_port)
    if p is None:
      log.warning("Can't get from %s to %s", match.dl_src, match.dl_dst)

      import pox.lib.packet as pkt

      if (match.dl_type == pkt.ethernet.IP_TYPE and
          event.parsed.find('ipv4')):
        # It's IP -- let's send a destination unreachable
        log.debug("Dest unreachable (%s -> %s)",
                  match.dl_src, match.dl_dst)

        from pox.lib.addresses import EthAddr
        e = pkt.ethernet()
        e.src = EthAddr(dpid_to_str(self.dpid)) #FIXME: Hmm...
        e.dst = match.dl_src
        e.type = e.IP_TYPE
        ipp = pkt.ipv4()
        ipp.protocol = ipp.ICMP_PROTOCOL
        ipp.srcip = match.nw_dst #FIXME: Ridiculous
        ipp.dstip = match.nw_src
        icmp = pkt.icmp()
        icmp.type = pkt.ICMP.TYPE_DEST_UNREACH
        icmp.code = pkt.ICMP.CODE_UNREACH_HOST
        orig_ip = event.parsed.find('ipv4')

        d = orig_ip.pack()
        d = d[:orig_ip.hl * 4 + 8]
        import struct
        d = struct.pack("!HH", 0,0) + d #FIXME: MTU
        icmp.payload = d
        ipp.payload = icmp
        e.payload = ipp
        msg = of.ofp_packet_out()
        msg.actions.append(of.ofp_action_output(port = event.port))
        msg.data = e.pack()
        self.connection.send(msg)

      return

    log.debug("Installing path for %s -> %s %04x (%i hops)",
        match.dl_src, match.dl_dst, match.dl_type, len(p))

    # We have a path -- install it
    self._install_path(p, match, event.ofp)

    # Now reverse it and install it backwards
    # (we'll just assume that will work)
    p = [(sw,out_port,in_port) for sw,in_port,out_port in p]
    self._install_path(p, match.flip())


  def _handle_PacketIn (self, event):
    def flood ():
      """ Floods the packet """
      if self.is_holding_down:
        log.warning("Not flooding -- holddown active")
      msg = of.ofp_packet_out()
      # OFPP_FLOOD is optional; some switches may need OFPP_ALL
      msg.actions.append(of.ofp_action_output(port = of.OFPP_FLOOD))
      msg.buffer_id = event.ofp.buffer_id
      msg.in_port = event.port
      self.connection.send(msg)

    def drop ():
      # Kill the buffer
      if event.ofp.buffer_id is not None:
        msg = of.ofp_packet_out()
        msg.buffer_id = event.ofp.buffer_id
        event.ofp.buffer_id = None # Mark is dead
        msg.in_port = event.port
        self.connection.send(msg)

    packet = event.parsed

    loc = (self, event.port) # Place we saw this ethaddr
    oldloc = mac_map.get(packet.src) # Place we last saw this ethaddr

    if packet.effective_ethertype == packet.LLDP_TYPE:
      drop()
      return

    if oldloc is None:
      if packet.src.is_multicast == False:
        mac_map[packet.src] = loc # Learn position for ethaddr
        log.debug("Learned %s at %s.%i", packet.src, loc[0], loc[1])
    elif oldloc != loc:
      # ethaddr seen at different place!
      if core.openflow_discovery.is_edge_port(loc[0].dpid, loc[1]):
        # New place is another "plain" port (probably)
        log.debug("%s moved from %s.%i to %s.%i?", packet.src,
                  dpid_to_str(oldloc[0].dpid), oldloc[1],
                  dpid_to_str(   loc[0].dpid),    loc[1])
        if packet.src.is_multicast == False:
          mac_map[packet.src] = loc # Learn position for ethaddr
          log.debug("Learned %s at %s.%i", packet.src, loc[0], loc[1])
      elif packet.dst.is_multicast == False:
        # New place is a switch-to-switch port!
        # Hopefully, this is a packet we're flooding because we didn't
        # know the destination, and not because it's somehow not on a
        # path that we expect it to be on.
        # If spanning_tree is running, we might check that this port is
        # on the spanning tree (it should be).
        if packet.dst in mac_map:
          # Unfortunately, we know the destination.  It's possible that
          # we learned it while it was in flight, but it's also possible
          # that something has gone wrong.
          log.warning("Packet from %s to known destination %s arrived "
                      "at %s.%i without flow", packet.src, packet.dst,
                      dpid_to_str(self.dpid), event.port)


    if packet.dst.is_multicast:
      log.debug("Flood multicast from %s", packet.src)
      flood()
    else:
      if packet.dst not in mac_map:
        log.debug("%s unknown -- flooding" % (packet.dst,))
        flood()
      else:
        dest = mac_map[packet.dst]
        match = of.ofp_match.from_packet(packet)
        self.install_path(dest[0], dest[1], match, event)

  def disconnect (self):
    if self.connection is not None:
      log.debug("Disconnect %s" % (self.connection,))
      self.connection.removeListeners(self._listeners)
      self.connection = None
      self._listeners = None

  def connect (self, connection):
    if self.dpid is None:
      self.dpid = connection.dpid
    assert self.dpid == connection.dpid
    if self.ports is None:
      self.ports = connection.features.ports
    self.disconnect()
    log.debug("Connect %s" % (connection,))
    self.connection = connection
    self._listeners = self.listenTo(connection)
    self._connected_at = time.time()

  @property
  def is_holding_down (self):
    if self._connected_at is None: return True
    if time.time() - self._connected_at > FLOOD_HOLDDOWN:
      return False
    return True

  def _handle_ConnectionDown (self, event):
    self.disconnect()


class l2_multi (EventMixin):

  _eventMixin_events = set([
    PathInstalled,
  ])

  def __init__ (self):
    # Listen to dependencies
    def startup ():
      core.openflow.addListeners(self, priority=0)
      core.openflow_discovery.addListeners(self)
    core.call_when_ready(startup, ('openflow','openflow_discovery'))

  def _handle_LinkEvent (self, event):
    def flip (link):
      return Discovery.Link(link[2],link[3], link[0],link[1])

    l = event.link
    sw1 = switches[l.dpid1]
    sw2 = switches[l.dpid2]

    # Invalidate all flows and path info.
    # For link adds, this makes sure that if a new link leads to an
    # improved path, we use it.
    # For link removals, this makes sure that we don't use a
    # path that may have been broken.
    #NOTE: This could be radically improved! (e.g., not *ALL* paths break)
    clear = of.ofp_flow_mod(command=of.OFPFC_DELETE)
    for sw in switches.itervalues():
      if sw.connection is None: continue
      sw.connection.send(clear)
    path_map.clear()

    if event.removed:
      # This link no longer okay
      if sw2 in adjacency[sw1]: del adjacency[sw1][sw2]
      if sw1 in adjacency[sw2]: del adjacency[sw2][sw1]

      # But maybe there's another way to connect these...
      for ll in core.openflow_discovery.adjacency:
        if ll.dpid1 == l.dpid1 and ll.dpid2 == l.dpid2:
          if flip(ll) in core.openflow_discovery.adjacency:
            # Yup, link goes both ways
            adjacency[sw1][sw2] = ll.port1
            adjacency[sw2][sw1] = ll.port2
            # Fixed -- new link chosen to connect these
            break
    else:
      # If we already consider these nodes connected, we can
      # ignore this link up.
      # Otherwise, we might be interested...
      if adjacency[sw1][sw2] is None:
        # These previously weren't connected.  If the link
        # exists in both directions, we consider them connected now.
        if flip(l) in core.openflow_discovery.adjacency:
          # Yup, link goes both ways -- connected!
          adjacency[sw1][sw2] = l.port1
          adjacency[sw2][sw1] = l.port2

      # If we have learned a MAC on this port which we now know to
      # be connected to a switch, unlearn it.
      bad_macs = set()
      for mac,(sw,port) in mac_map.iteritems():
        if sw is sw1 and port == l.port1: bad_macs.add(mac)
        if sw is sw2 and port == l.port2: bad_macs.add(mac)
      for mac in bad_macs:
        log.debug("Unlearned %s", mac)
        del mac_map[mac]

  def _handle_ConnectionUp (self, event):
    sw = switches.get(event.dpid)
    if sw is None:
      # New switch
      sw = Switch()
      switches[event.dpid] = sw
      sw.connect(event.connection)
    else:
      sw.connect(event.connection)

  def _handle_BarrierIn (self, event):
    wp = waiting_paths.pop((event.dpid,event.xid), None)
    if not wp:
      #log.info("No waiting packet %s,%s", event.dpid, event.xid)
      return
    #log.debug("Notify waiting packet %s,%s", event.dpid, event.xid)
    wp.notify(event)


def launch ():
  core.registerNew(l2_multi)

  timeout = min(max(PATH_SETUP_TIME, 5) * 2, 15)
  Timer(timeout, WaitingPath.expire_waiting_paths, recurring=True)

########NEW FILE########
__FILENAME__ = l2_nx
# Copyright 2012 James McCauley
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at:
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""
A quick-and-dirty learning switch for Open vSwitch

This learning switch requires Nicira extensions as found in Open vSwitch.
Furthermore, you must enable packet-in conversion.  Run with something like:
  ./pox.py openflow.nicira --convert-packet-in forwarding.l2_nx

This forwards based on ethernet source and destination addresses.  Where
l2_pairs installs rules for each pair of source and destination address,
this component uses two tables on the switch -- one for source addresses
and one for destination addresses.  Specifically, we use tables 0 and 1
on the switch to implement the following logic:
0. Is this source address known?
   NO: Send to controller (so we can learn it)
1. Is this destination address known?
   YES:  Forward out correct port
   NO: Flood

Note that unlike the other learning switches *we keep no state in the
controller*.  In truth, we could implement this whole thing using OVS's
learn action, but doing it something like is done here will still allow
us to implement access control or something at the controller.
"""

from pox.core import core
from pox.lib.addresses import EthAddr
import pox.openflow.libopenflow_01 as of
import pox.openflow.nicira as nx
from pox.lib.revent import EventRemove


# Even a simple usage of the logger is much nicer than print!
log = core.getLogger()


def _handle_PacketIn (event):
  packet = event.parsed

  if event.port > of.OFPP_MAX:
    log.debug("Ignoring special port %s", event.port)
    return

  # Add to source table
  msg = nx.nx_flow_mod()
  msg.match.of_eth_src = packet.src
  msg.actions.append(nx.nx_action_resubmit.resubmit_table(table = 1))
  event.connection.send(msg)

  # Add to destination table
  msg = nx.nx_flow_mod()
  msg.table_id = 1
  msg.match.of_eth_dst = packet.src
  msg.actions.append(of.ofp_action_output(port = event.port))
  event.connection.send(msg)

  log.info("Learning %s on port %s of %s"
           % (packet.src, event.port, event.connection))


def _handle_ConnectionUp (event):
  # Set up this switch.
  # After setting up, we send a barrier and wait for the response
  # before starting to listen to packet_ins for this switch -- before
  # the switch is set up, the packet_ins may not be what we expect,
  # and our responses may not work!

  # Turn on Nicira packet_ins
  msg = nx.nx_packet_in_format()
  event.connection.send(msg)

  # Turn on ability to specify table in flow_mods
  msg = nx.nx_flow_mod_table_id()
  event.connection.send(msg)

  # Clear second table
  msg = nx.nx_flow_mod(command=of.OFPFC_DELETE, table_id = 1)
  event.connection.send(msg)

  # Fallthrough rule for table 0: flood and send to controller
  msg = nx.nx_flow_mod()
  msg.priority = 1 # Low priority
  msg.actions.append(of.ofp_action_output(port = of.OFPP_CONTROLLER))
  msg.actions.append(nx.nx_action_resubmit.resubmit_table(table = 1))
  event.connection.send(msg)

  # Fallthrough rule for table 1: flood
  msg = nx.nx_flow_mod()
  msg.table_id = 1
  msg.priority = 1 # Low priority
  msg.actions.append(of.ofp_action_output(port = of.OFPP_FLOOD))
  event.connection.send(msg)

  def ready (event):
    if event.ofp.xid != 0x80000000:
      # Not the right barrier
      return
    log.info("%s ready", event.connection)
    event.connection.addListenerByName("PacketIn", _handle_PacketIn)
    return EventRemove

  event.connection.send(of.ofp_barrier_request(xid=0x80000000))
  event.connection.addListenerByName("BarrierIn", ready)


def launch ():
  def start ():
    if not core.NX.convert_packet_in:
      log.error("PacketIn conversion required")
      return
    core.openflow.addListenerByName("ConnectionUp", _handle_ConnectionUp)
    log.info("Simple NX switch running.")
  core.call_when_ready(start, ['NX','openflow'])

########NEW FILE########
__FILENAME__ = l2_nx_self_learning
# Copyright 2013 James McCauley
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at:
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""
This makes Nicira-extension capable switches into learning switches

This uses the "learn" action so that switches become learning switches
*with no controller involvement*.

  ./pox.py openflow.nicira forwarding.l2_nx_self_learning
"""

from pox.core import core
import pox.openflow.libopenflow_01 as of
import pox.openflow.nicira as nx


log = core.getLogger("l2_nx_self_learning")


def _handle_ConnectionUp (event):
  # Set up this switch.

  # Turn on ability to specify table in flow_mods
  msg = nx.nx_flow_mod_table_id()
  event.connection.send(msg)

  # Clear second table
  msg = nx.nx_flow_mod(command=of.OFPFC_DELETE, table_id = 1)
  event.connection.send(msg)

  # Learning rule in table 0
  msg = nx.nx_flow_mod()
  msg.table_id = 0

  learn = nx.nx_action_learn(table_id=1,hard_timeout=10)
  learn.spec.chain(
      field=nx.NXM_OF_VLAN_TCI, n_bits=12).chain(
      field=nx.NXM_OF_ETH_SRC, match=nx.NXM_OF_ETH_DST).chain(
      field=nx.NXM_OF_IN_PORT, output=True)

  msg.actions.append(learn)
  msg.actions.append(nx.nx_action_resubmit.resubmit_table(1))
  event.connection.send(msg)

  # Fallthrough rule for table 1: flood
  msg = nx.nx_flow_mod()
  msg.table_id = 1
  msg.priority = 1 # Low priority
  msg.actions.append(of.ofp_action_output(port = of.OFPP_FLOOD))
  event.connection.send(msg)



def launch ():
  def start ():
    core.openflow.addListenerByName("ConnectionUp", _handle_ConnectionUp)
    log.info("NX self-learning switch running.")
  core.call_when_ready(start, ['NX','openflow'])

########NEW FILE########
__FILENAME__ = l2_pairs
# Copyright 2012 James McCauley
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at:
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""
A super simple OpenFlow learning switch that installs rules for
each pair of L2 addresses.
"""

# These next two imports are common POX convention
from pox.core import core
import pox.openflow.libopenflow_01 as of


# Even a simple usage of the logger is much nicer than print!
log = core.getLogger()


# This table maps (switch,MAC-addr) pairs to the port on 'switch' at
# which we last saw a packet *from* 'MAC-addr'.
# (In this case, we use a Connection object for the switch.)
table = {}


# To send out all ports, we can use either of the special ports
# OFPP_FLOOD or OFPP_ALL.  We'd like to just use OFPP_FLOOD,
# but it's not clear if all switches support this, so we make
# it selectable.
all_ports = of.OFPP_FLOOD


# Handle messages the switch has sent us because it has no
# matching rule.
def _handle_PacketIn (event):
  packet = event.parsed

  # Learn the source
  table[(event.connection,packet.src)] = event.port

  dst_port = table.get((event.connection,packet.dst))

  if dst_port is None:
    # We don't know where the destination is yet.  So, we'll just
    # send the packet out all ports (except the one it came in on!)
    # and hope the destination is out there somewhere. :)
    msg = of.ofp_packet_out(data = event.ofp)
    msg.actions.append(of.ofp_action_output(port = all_ports))
    event.connection.send(msg)
  else:
    # Since we know the switch ports for both the source and dest
    # MACs, we can install rules for both directions.
    msg = of.ofp_flow_mod()
    msg.match.dl_dst = packet.src
    msg.match.dl_src = packet.dst
    msg.actions.append(of.ofp_action_output(port = event.port))
    event.connection.send(msg)
    
    # This is the packet that just came in -- we want to
    # install the rule and also resend the packet.
    msg = of.ofp_flow_mod()
    msg.data = event.ofp # Forward the incoming packet
    msg.match.dl_src = packet.src
    msg.match.dl_dst = packet.dst
    msg.actions.append(of.ofp_action_output(port = dst_port))
    event.connection.send(msg)

    log.debug("Installing %s <-> %s" % (packet.src, packet.dst))


def launch (disable_flood = False):
  global all_ports
  if disable_flood:
    all_ports = of.OFPP_ALL

  core.openflow.addListenerByName("PacketIn", _handle_PacketIn)

  log.info("Pair-Learning switch running.")

########NEW FILE########
__FILENAME__ = l3_learning
# Copyright 2012-2013 James McCauley
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at:
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""
A stupid L3 switch

For each switch:
1) Keep a table that maps IP addresses to MAC addresses and switch ports.
   Stock this table using information from ARP and IP packets.
2) When you see an ARP query, try to answer it using information in the table
   from step 1.  If the info in the table is old, just flood the query.
3) Flood all other ARPs.
4) When you see an IP packet, if you know the destination port (because it's
   in the table from step 1), install a flow for it.
"""

from pox.core import core
import pox
log = core.getLogger()

from pox.lib.packet.ethernet import ethernet, ETHER_BROADCAST
from pox.lib.packet.ipv4 import ipv4
from pox.lib.packet.arp import arp
from pox.lib.addresses import IPAddr, EthAddr
from pox.lib.util import str_to_bool, dpid_to_str
from pox.lib.recoco import Timer

import pox.openflow.libopenflow_01 as of

from pox.lib.revent import *

import time

# Timeout for flows
FLOW_IDLE_TIMEOUT = 10

# Timeout for ARP entries
ARP_TIMEOUT = 60 * 2

# Maximum number of packet to buffer on a switch for an unknown IP
MAX_BUFFERED_PER_IP = 5

# Maximum time to hang on to a buffer for an unknown IP in seconds
MAX_BUFFER_TIME = 5


class Entry (object):
  """
  Not strictly an ARP entry.
  We use the port to determine which port to forward traffic out of.
  We use the MAC to answer ARP replies.
  We use the timeout so that if an entry is older than ARP_TIMEOUT, we
   flood the ARP request rather than try to answer it ourselves.
  """
  def __init__ (self, port, mac):
    self.timeout = time.time() + ARP_TIMEOUT
    self.port = port
    self.mac = mac

  def __eq__ (self, other):
    if type(other) == tuple:
      return (self.port,self.mac)==other
    else:
      return (self.port,self.mac)==(other.port,other.mac)
  def __ne__ (self, other):
    return not self.__eq__(other)

  def isExpired (self):
    if self.port == of.OFPP_NONE: return False
    return time.time() > self.timeout


def dpid_to_mac (dpid):
  return EthAddr("%012x" % (dpid & 0xffFFffFFffFF,))


class l3_switch (EventMixin):
  def __init__ (self, fakeways = [], arp_for_unknowns = False):
    # These are "fake gateways" -- we'll answer ARPs for them with MAC
    # of the switch they're connected to.
    self.fakeways = set(fakeways)

    # If this is true and we see a packet for an unknown
    # host, we'll ARP for it.
    self.arp_for_unknowns = arp_for_unknowns

    # (dpid,IP) -> expire_time
    # We use this to keep from spamming ARPs
    self.outstanding_arps = {}

    # (dpid,IP) -> [(expire_time,buffer_id,in_port), ...]
    # These are buffers we've gotten at this datapath for this IP which
    # we can't deliver because we don't know where they go.
    self.lost_buffers = {}

    # For each switch, we map IP addresses to Entries
    self.arpTable = {}

    # This timer handles expiring stuff
    self._expire_timer = Timer(5, self._handle_expiration, recurring=True)

    self.listenTo(core)

  def _handle_expiration (self):
    # Called by a timer so that we can remove old items.
    empty = []
    for k,v in self.lost_buffers.iteritems():
      dpid,ip = k

      for item in list(v):
        expires_at,buffer_id,in_port = item
        if expires_at < time.time():
          # This packet is old.  Tell this switch to drop it.
          v.remove(item)
          po = of.ofp_packet_out(buffer_id = buffer_id, in_port = in_port)
          core.openflow.sendToDPID(dpid, po)
      if len(v) == 0: empty.append(k)

    # Remove empty buffer bins
    for k in empty:
      del self.lost_buffers[k]

  def _send_lost_buffers (self, dpid, ipaddr, macaddr, port):
    """
    We may have "lost" buffers -- packets we got but didn't know
    where to send at the time.  We may know now.  Try and see.
    """
    if (dpid,ipaddr) in self.lost_buffers:
      # Yup!
      bucket = self.lost_buffers[(dpid,ipaddr)]
      del self.lost_buffers[(dpid,ipaddr)]
      log.debug("Sending %i buffered packets to %s from %s"
                % (len(bucket),ipaddr,dpid_to_str(dpid)))
      for _,buffer_id,in_port in bucket:
        po = of.ofp_packet_out(buffer_id=buffer_id,in_port=in_port)
        po.actions.append(of.ofp_action_dl_addr.set_dst(macaddr))
        po.actions.append(of.ofp_action_output(port = port))
        core.openflow.sendToDPID(dpid, po)

  def _handle_GoingUpEvent (self, event):
    self.listenTo(core.openflow)
    log.debug("Up...")

  def _handle_PacketIn (self, event):
    dpid = event.connection.dpid
    inport = event.port
    packet = event.parsed
    if not packet.parsed:
      log.warning("%i %i ignoring unparsed packet", dpid, inport)
      return

    if dpid not in self.arpTable:
      # New switch -- create an empty table
      self.arpTable[dpid] = {}
      for fake in self.fakeways:
        self.arpTable[dpid][IPAddr(fake)] = Entry(of.OFPP_NONE,
         dpid_to_mac(dpid))

    if packet.type == ethernet.LLDP_TYPE:
      # Ignore LLDP packets
      return

    if isinstance(packet.next, ipv4):
      log.debug("%i %i IP %s => %s", dpid,inport,
                packet.next.srcip,packet.next.dstip)

      # Send any waiting packets...
      self._send_lost_buffers(dpid, packet.next.srcip, packet.src, inport)

      # Learn or update port/MAC info
      if packet.next.srcip in self.arpTable[dpid]:
        if self.arpTable[dpid][packet.next.srcip] != (inport, packet.src):
          log.info("%i %i RE-learned %s", dpid,inport,packet.next.srcip)
      else:
        log.debug("%i %i learned %s", dpid,inport,str(packet.next.srcip))
      self.arpTable[dpid][packet.next.srcip] = Entry(inport, packet.src)

      # Try to forward
      dstaddr = packet.next.dstip
      if dstaddr in self.arpTable[dpid]:
        # We have info about what port to send it out on...

        prt = self.arpTable[dpid][dstaddr].port
        mac = self.arpTable[dpid][dstaddr].mac
        if prt == inport:
          log.warning("%i %i not sending packet for %s back out of the " +
                      "input port" % (dpid, inport, str(dstaddr)))
        else:
          log.debug("%i %i installing flow for %s => %s out port %i"
                    % (dpid, inport, packet.next.srcip, dstaddr, prt))

          actions = []
          actions.append(of.ofp_action_dl_addr.set_dst(mac))
          actions.append(of.ofp_action_output(port = prt))
          match = of.ofp_match.from_packet(packet, inport)
          match.dl_src = None # Wildcard source MAC

          msg = of.ofp_flow_mod(command=of.OFPFC_ADD,
                                idle_timeout=FLOW_IDLE_TIMEOUT,
                                hard_timeout=of.OFP_FLOW_PERMANENT,
                                buffer_id=event.ofp.buffer_id,
                                actions=actions,
                                match=of.ofp_match.from_packet(packet,
                                                               inport))
          event.connection.send(msg.pack())
      elif self.arp_for_unknowns:
        # We don't know this destination.
        # First, we track this buffer so that we can try to resend it later
        # if we learn the destination, second we ARP for the destination,
        # which should ultimately result in it responding and us learning
        # where it is

        # Add to tracked buffers
        if (dpid,dstaddr) not in self.lost_buffers:
          self.lost_buffers[(dpid,dstaddr)] = []
        bucket = self.lost_buffers[(dpid,dstaddr)]
        entry = (time.time() + MAX_BUFFER_TIME,event.ofp.buffer_id,inport)
        bucket.append(entry)
        while len(bucket) > MAX_BUFFERED_PER_IP: del bucket[0]

        # Expire things from our outstanding ARP list...
        self.outstanding_arps = {k:v for k,v in
         self.outstanding_arps.iteritems() if v > time.time()}

        # Check if we've already ARPed recently
        if (dpid,dstaddr) in self.outstanding_arps:
          # Oop, we've already done this one recently.
          return

        # And ARP...
        self.outstanding_arps[(dpid,dstaddr)] = time.time() + 4

        r = arp()
        r.hwtype = r.HW_TYPE_ETHERNET
        r.prototype = r.PROTO_TYPE_IP
        r.hwlen = 6
        r.protolen = r.protolen
        r.opcode = r.REQUEST
        r.hwdst = ETHER_BROADCAST
        r.protodst = dstaddr
        r.hwsrc = packet.src
        r.protosrc = packet.next.srcip
        e = ethernet(type=ethernet.ARP_TYPE, src=packet.src,
                     dst=ETHER_BROADCAST)
        e.set_payload(r)
        log.debug("%i %i ARPing for %s on behalf of %s" % (dpid, inport,
         str(r.protodst), str(r.protosrc)))
        msg = of.ofp_packet_out()
        msg.data = e.pack()
        msg.actions.append(of.ofp_action_output(port = of.OFPP_FLOOD))
        msg.in_port = inport
        event.connection.send(msg)

    elif isinstance(packet.next, arp):
      a = packet.next
      log.debug("%i %i ARP %s %s => %s", dpid, inport,
       {arp.REQUEST:"request",arp.REPLY:"reply"}.get(a.opcode,
       'op:%i' % (a.opcode,)), str(a.protosrc), str(a.protodst))

      if a.prototype == arp.PROTO_TYPE_IP:
        if a.hwtype == arp.HW_TYPE_ETHERNET:
          if a.protosrc != 0:

            # Learn or update port/MAC info
            if a.protosrc in self.arpTable[dpid]:
              if self.arpTable[dpid][a.protosrc] != (inport, packet.src):
                log.info("%i %i RE-learned %s", dpid,inport,str(a.protosrc))
            else:
              log.debug("%i %i learned %s", dpid,inport,str(a.protosrc))
            self.arpTable[dpid][a.protosrc] = Entry(inport, packet.src)

            # Send any waiting packets...
            self._send_lost_buffers(dpid, a.protosrc, packet.src, inport)

            if a.opcode == arp.REQUEST:
              # Maybe we can answer

              if a.protodst in self.arpTable[dpid]:
                # We have an answer...

                if not self.arpTable[dpid][a.protodst].isExpired():
                  # .. and it's relatively current, so we'll reply ourselves

                  r = arp()
                  r.hwtype = a.hwtype
                  r.prototype = a.prototype
                  r.hwlen = a.hwlen
                  r.protolen = a.protolen
                  r.opcode = arp.REPLY
                  r.hwdst = a.hwsrc
                  r.protodst = a.protosrc
                  r.protosrc = a.protodst
                  r.hwsrc = self.arpTable[dpid][a.protodst].mac
                  e = ethernet(type=packet.type, src=dpid_to_mac(dpid),
                               dst=a.hwsrc)
                  e.set_payload(r)
                  log.debug("%i %i answering ARP for %s" % (dpid, inport,
                   str(r.protosrc)))
                  msg = of.ofp_packet_out()
                  msg.data = e.pack()
                  msg.actions.append(of.ofp_action_output(port =
                                                          of.OFPP_IN_PORT))
                  msg.in_port = inport
                  event.connection.send(msg)
                  return

      # Didn't know how to answer or otherwise handle this ARP, so just flood it
      log.debug("%i %i flooding ARP %s %s => %s" % (dpid, inport,
       {arp.REQUEST:"request",arp.REPLY:"reply"}.get(a.opcode,
       'op:%i' % (a.opcode,)), str(a.protosrc), str(a.protodst)))

      msg = of.ofp_packet_out(in_port = inport, data = event.ofp,
          action = of.ofp_action_output(port = of.OFPP_FLOOD))
      event.connection.send(msg)


def launch (fakeways="", arp_for_unknowns=None):
  fakeways = fakeways.replace(","," ").split()
  fakeways = [IPAddr(x) for x in fakeways]
  if arp_for_unknowns is None:
    arp_for_unknowns = len(fakeways) > 0
  else:
    arp_for_unknowns = str_to_bool(arp_for_unknowns)
  core.registerNew(l3_switch, fakeways, arp_for_unknowns)


########NEW FILE########
__FILENAME__ = topo_proactive
# Copyright 2013 James McCauley
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at:
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""
Installs forwarding rules based on topologically significant IP addresses.

We also issue those addresses by DHCP.  A host must use the assigned IP!
Actually, the last byte can be almost anything.  But addresses are of the
form 10.switchID.portNumber.x.

This is an example of a pretty proactive forwarding application.

The forwarding code is based on l2_multi.

Depends on openflow.discovery
Works with openflow.spanning_tree (sort of)
"""

from pox.core import core
import pox.openflow.libopenflow_01 as of
import pox.lib.packet as pkt

from pox.lib.addresses import IPAddr,EthAddr,parse_cidr
from pox.lib.addresses import IP_BROADCAST, IP_ANY
from pox.lib.revent import *
from pox.lib.util import dpid_to_str
from pox.proto.dhcpd import DHCPLease, DHCPD
from collections import defaultdict
from pox.openflow.discovery import Discovery
import time

log = core.getLogger("f.t_p")


# Adjacency map.  [sw1][sw2] -> port from sw1 to sw2
adjacency = defaultdict(lambda:defaultdict(lambda:None))

# Switches we know of.  [dpid] -> Switch and [id] -> Switch
switches_by_dpid = {}
switches_by_id = {}

# [sw1][sw2] -> (distance, intermediate)
path_map = defaultdict(lambda:defaultdict(lambda:(None,None)))


def dpid_to_mac (dpid):
  return EthAddr("%012x" % (dpid & 0xffFFffFFffFF,))


def _calc_paths ():
  """
  Essentially Floyd-Warshall algorithm
  """

  def dump ():
    for i in sws:
      for j in sws:
        a = path_map[i][j][0]
        #a = adjacency[i][j]
        if a is None: a = "*"
        print a,
      print

  sws = switches_by_dpid.values()
  path_map.clear()
  for k in sws:
    for j,port in adjacency[k].iteritems():
      if port is None: continue
      path_map[k][j] = (1,None)
    path_map[k][k] = (0,None) # distance, intermediate

  #dump()

  for k in sws:
    for i in sws:
      for j in sws:
        if path_map[i][k][0] is not None:
          if path_map[k][j][0] is not None:
            # i -> k -> j exists
            ikj_dist = path_map[i][k][0]+path_map[k][j][0]
            if path_map[i][j][0] is None or ikj_dist < path_map[i][j][0]:
              # i -> k -> j is better than existing
              path_map[i][j] = (ikj_dist, k)

  #print "--------------------"
  #dump()


def _get_raw_path (src, dst):
  """
  Get a raw path (just a list of nodes to traverse)
  """
  if len(path_map) == 0: _calc_paths()
  if src is dst:
    # We're here!
    return []
  if path_map[src][dst][0] is None:
    return None
  intermediate = path_map[src][dst][1]
  if intermediate is None:
    # Directly connected
    return []
  return _get_raw_path(src, intermediate) + [intermediate] + \
         _get_raw_path(intermediate, dst)


def _get_path (src, dst):
  """
  Gets a cooked path -- a list of (node,out_port)
  """
  # Start with a raw path...
  if src == dst:
    path = [src]
  else:
    path = _get_raw_path(src, dst)
    if path is None: return None
    path = [src] + path + [dst]

  # Now add the ports
  r = []
  for s1,s2 in zip(path[:-1],path[1:]):
    out_port = adjacency[s1][s2]
    r.append((s1,out_port))
    in_port = adjacency[s2][s1]

  return r


def ipinfo (ip):
  parts = [int(x) for x in str(ip).split('.')]
  ID = parts[1]
  port = parts[2]
  num = parts[3]
  return switches_by_id.get(ID),port,num


class TopoSwitch (DHCPD):
  _eventMixin_events = set([DHCPLease])
  _next_id = 100

  def __repr__ (self):
    try:
      return "[%s/%s]" % (dpid_to_str(self.connection.dpid),self._id)
    except:
      return "[Unknown]"


  def __init__ (self):
    self.log = log.getChild("Unknown")

    self.connection = None
    self.ports = None
    self.dpid = None
    self._listeners = None
    self._connected_at = None
    self._id = None
    self.subnet = None
    self.network = None
    self._install_flow = False
    self.mac = None

    self.ip_to_mac = {}

    # Listen to our own event... :)
    self.addListenerByName("DHCPLease", self._on_lease)

    core.ARPHelper.addListeners(self)


  def _handle_ARPRequest (self, event):
    if ipinfo(event.ip)[0] is not self: return
    event.reply = self.mac


  def send_table (self):
    if self.connection is None:
      self.log.debug("Can't send table: disconnected")
      return

    clear = of.ofp_flow_mod(command=of.OFPFC_DELETE)
    self.connection.send(clear)
    self.connection.send(of.ofp_barrier_request())

    # From DHCPD
    msg = of.ofp_flow_mod()
    msg.match = of.ofp_match()
    msg.match.dl_type = pkt.ethernet.IP_TYPE
    msg.match.nw_proto = pkt.ipv4.UDP_PROTOCOL
    #msg.match.nw_dst = IP_BROADCAST
    msg.match.tp_src = pkt.dhcp.CLIENT_PORT
    msg.match.tp_dst = pkt.dhcp.SERVER_PORT
    msg.actions.append(of.ofp_action_output(port = of.OFPP_CONTROLLER))
    #msg.actions.append(of.ofp_action_output(port = of.OFPP_FLOOD))
    self.connection.send(msg)

    core.openflow_discovery.install_flow(self.connection)

    src = self
    for dst in switches_by_dpid.itervalues():
      if dst is src: continue
      p = _get_path(src, dst)
      if p is None: continue

      msg = of.ofp_flow_mod()
      msg.match = of.ofp_match()
      msg.match.dl_type = pkt.ethernet.IP_TYPE
      #msg.match.nw_dst = "%s/%s" % (dst.network, dst.subnet)
      msg.match.nw_dst = "%s/%s" % (dst.network, "255.255.0.0")

      msg.actions.append(of.ofp_action_output(port=p[0][1]))
      self.connection.send(msg)

    """
    # Can just do this instead of MAC learning if you run arp_responder...
    for port in self.ports:
      p = port.port_no
      if p < 0 or p >= of.OFPP_MAX: continue
      msg = of.ofp_flow_mod()
      msg.match = of.ofp_match()
      msg.match.dl_type = pkt.ethernet.IP_TYPE
      msg.match.nw_dst = "10.%s.%s.0/255.255.255.0" % (self._id,p)
      msg.actions.append(of.ofp_action_output(port=p))
      self.connection.send(msg)
    """

    for ip,mac in self.ip_to_mac.iteritems():
      self._send_rewrite_rule(ip, mac)

    flood_ports = []
    for port in self.ports:
      p = port.port_no
      if p < 0 or p >= of.OFPP_MAX: continue

      if core.openflow_discovery.is_edge_port(self.dpid, p):
        flood_ports.append(p)

      msg = of.ofp_flow_mod()
      msg.priority -= 1
      msg.match = of.ofp_match()
      msg.match.dl_type = pkt.ethernet.IP_TYPE
      msg.match.nw_dst = "10.%s.%s.0/255.255.255.0" % (self._id,p)
      msg.actions.append(of.ofp_action_output(port=of.OFPP_CONTROLLER))
      self.connection.send(msg)

    msg = of.ofp_flow_mod()
    msg.priority -= 1
    msg.match = of.ofp_match()
    msg.match.dl_type = pkt.ethernet.IP_TYPE
    msg.match.nw_dst = "255.255.255.255"
    for p in flood_ports:
      msg.actions.append(of.ofp_action_output(port=p))
    self.connection.send(msg)


  def _send_rewrite_rule (self, ip, mac):
    p = ipinfo(ip)[1]

    msg = of.ofp_flow_mod()
    msg.match = of.ofp_match()
    msg.match.dl_type = pkt.ethernet.IP_TYPE
    msg.match.nw_dst = ip
    msg.actions.append(of.ofp_action_dl_addr.set_src(self.mac))
    msg.actions.append(of.ofp_action_dl_addr.set_dst(mac))
    msg.actions.append(of.ofp_action_output(port=p))
    self.connection.send(msg)


  def disconnect (self):
    if self.connection is not None:
      log.debug("Disconnect %s" % (self.connection,))
      self.connection.removeListeners(self._listeners)
      self.connection = None
      self._listeners = None


  def connect (self, connection):
    if connection is None:
      self.log.warn("Can't connect to nothing")
      return
    if self.dpid is None:
      self.dpid = connection.dpid
    assert self.dpid == connection.dpid
    if self.ports is None:
      self.ports = connection.features.ports
    self.disconnect()
    self.connection = connection
    self._listeners = self.listenTo(connection)
    self._connected_at = time.time()

    label = dpid_to_str(connection.dpid)
    self.log = log.getChild(label)
    self.log.debug("Connect %s" % (connection,))

    if self._id is None:
      if self.dpid not in switches_by_id and self.dpid <= 254:
        self._id = self.dpid
      else:
        self._id = TopoSwitch._next_id
        TopoSwitch._next_id += 1
      switches_by_id[self._id] = self

    self.network = IPAddr("10.%s.0.0" % (self._id,))
    self.mac = dpid_to_mac(self.dpid)

    # Disable flooding
    con = connection
    log.debug("Disabling flooding for %i ports", len(con.ports))
    for p in con.ports.itervalues():
      if p.port_no >= of.OFPP_MAX: continue
      pm = of.ofp_port_mod(port_no=p.port_no,
                          hw_addr=p.hw_addr,
                          config = of.OFPPC_NO_FLOOD,
                          mask = of.OFPPC_NO_FLOOD)
      con.send(pm)
    con.send(of.ofp_barrier_request())
    con.send(of.ofp_features_request())

    # Some of this is copied from DHCPD's __init__().
    self.send_table()

    def fix_addr (addr, backup):
      if addr is None: return None
      if addr is (): return IPAddr(backup)
      return IPAddr(addr)

    self.ip_addr = IPAddr("10.%s.0.1" % (self._id,))
    #self.router_addr = self.ip_addr
    self.router_addr = None
    self.dns_addr = None #fix_addr(dns_address, self.router_addr)

    self.subnet = IPAddr("255.0.0.0")
    self.pools = {}
    for p in connection.ports:
      if p < 0 or p >= of.OFPP_MAX: continue
      self.pools[p] = [IPAddr("10.%s.%s.%s" % (self._id,p,n))
                       for n in range(1,255)]

    self.lease_time = 60 * 60 # An hour
    #TODO: Actually make them expire :)

    self.offers = {} # Eth -> IP we offered
    self.leases = {} # Eth -> IP we leased


  def _get_pool (self, event):
    pool = self.pools.get(event.port)
    if pool is None:
      log.warn("No IP pool for port %s", event.port)
    return pool


  def _handle_ConnectionDown (self, event):
    self.disconnect()


  def _mac_learn (self, mac, ip):
    if ip.inNetwork(self.network,"255.255.0.0"):
      if self.ip_to_mac.get(ip) != mac:
        self.ip_to_mac[ip] = mac
        self._send_rewrite_rule(ip, mac)
        return True
    return False


  def _on_lease (self, event):
    if self._mac_learn(event.host_mac, event.ip):
        self.log.debug("Learn %s -> %s by DHCP Lease",event.ip,event.host_mac)


  def _handle_PacketIn (self, event):
    packet = event.parsed
    arpp = packet.find('arp')
    if arpp is not None:
      if event.port != ipinfo(arpp.protosrc)[1]:
        self.log.warn("%s has incorrect IP %s", arpp.hwsrc, arpp.protosrc)
        return

      if self._mac_learn(packet.src, arpp.protosrc):
        self.log.debug("Learn %s -> %s by ARP",arpp.protosrc,packet.src)
    else:
      ipp = packet.find('ipv4')
      if ipp is not None:
        # Should be destined for this switch with unknown MAC
        # Send an ARP
        sw,p,_= ipinfo(ipp.dstip)
        if sw is self:
          log.debug("Need MAC for %s", ipp.dstip)
          core.ARPHelper.send_arp_request(event.connection,ipp.dstip,port=p)

    return super(TopoSwitch,self)._handle_PacketIn(event)


class topo_addressing (object):
  def __init__ (self):
    core.listen_to_dependencies(self, listen_args={'openflow':{'priority':0}})

  def _handle_ARPHelper_ARPRequest (self, event):
    pass # Just here to make sure we load it

  def _handle_openflow_discovery_LinkEvent (self, event):
    def flip (link):
      return Discovery.Link(link[2],link[3], link[0],link[1])

    l = event.link
    sw1 = switches_by_dpid[l.dpid1]
    sw2 = switches_by_dpid[l.dpid2]

    # Invalidate all flows and path info.
    # For link adds, this makes sure that if a new link leads to an
    # improved path, we use it.
    # For link removals, this makes sure that we don't use a
    # path that may have been broken.
    #NOTE: This could be radically improved! (e.g., not *ALL* paths break)
    clear = of.ofp_flow_mod(command=of.OFPFC_DELETE)
    for sw in switches_by_dpid.itervalues():
      if sw.connection is None: continue
      sw.connection.send(clear)
    path_map.clear()

    if event.removed:
      # This link no longer okay
      if sw2 in adjacency[sw1]: del adjacency[sw1][sw2]
      if sw1 in adjacency[sw2]: del adjacency[sw2][sw1]

      # But maybe there's another way to connect these...
      for ll in core.openflow_discovery.adjacency:
        if ll.dpid1 == l.dpid1 and ll.dpid2 == l.dpid2:
          if flip(ll) in core.openflow_discovery.adjacency:
            # Yup, link goes both ways
            adjacency[sw1][sw2] = ll.port1
            adjacency[sw2][sw1] = ll.port2
            # Fixed -- new link chosen to connect these
            break
    else:
      # If we already consider these nodes connected, we can
      # ignore this link up.
      # Otherwise, we might be interested...
      if adjacency[sw1][sw2] is None:
        # These previously weren't connected.  If the link
        # exists in both directions, we consider them connected now.
        if flip(l) in core.openflow_discovery.adjacency:
          # Yup, link goes both ways -- connected!
          adjacency[sw1][sw2] = l.port1
          adjacency[sw2][sw1] = l.port2

    for sw in switches_by_dpid.itervalues():
      sw.send_table()


  def _handle_openflow_ConnectionUp (self, event):
    sw = switches_by_dpid.get(event.dpid)

    if sw is None:
      # New switch

      sw = TopoSwitch()
      switches_by_dpid[event.dpid] = sw
      sw.connect(event.connection)
    else:
      sw.connect(event.connection)



def launch (debug = False):
  core.registerNew(topo_addressing)
  from proto.arp_helper import launch
  launch(eat_packets=False)
  if not debug:
    core.getLogger("proto.arp_helper").setLevel(99)

########NEW FILE########
__FILENAME__ = help
# Copyright 2013 James McCauley
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at:
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""
Attempts to give help on other components
"""

from __future__ import print_function
import pox.boot as boot
import inspect
import sys

def _show_args (f,name):
  #TODO: Refactor with pox.boot

  if name == "launch": name = "default launcher"

  out = []

  EMPTY = "<Unspecified>"

  argnames,varargs,kws,defaults = inspect.getargspec(f)
  argcount = len(argnames)
  defaults = list((f.func_defaults) or [])
  defaults = [EMPTY] * (argcount - len(defaults)) + defaults

  args = {}
  for n, a in enumerate(argnames):
    args[a] = [EMPTY,EMPTY]
    if n < len(defaults):
      args[a][0] = defaults[n]
  multi = False
  if '__INSTANCE__' in args:
    multi = True
    del args['__INSTANCE__']

  if len(args) == 0:
    if argcount or kws:
      out.append(" Multiple.")
      varargs = kws = None
    else:
      out.append(" None.")
  else:
    out.append(" {0:25} {1:25}".format("Name", "Default"))
    out.append(" {0:25} {0:25}".format("-" * 15))

    for k,v in args.iteritems():
      k = k.replace("_","-")
      out.append(" {0:25} {1:25}".format(k,str(v[0])))

  if len(out):
    out.insert(0, "Parameters for {0}:".format(name))
    out.append("")

  if multi:
    out.append(" Note: This can be invoked multiple times.")
  if varargs or kws:
    out.append(" Note: This can be invoked with parameters not listed here.")

  out = '\n'.join(out)

  return out.strip()


def launch (no_args = False, short = False, **kw):
  """
  Shows help

  Usage: help <args> --component_name
         help <args> --component_name=launcher

  Args are:
    --short    Only summarize docs
    --no-args  Don't show parameter info
  """

  if len(kw) == 0:
    d = boot._help_text
    if short: d = d.split("\n")[0]
    print(d)
    sys.exit(0)

  if len(kw) != 1:
    if len(kw) > 1:
      print()
      print("Didn't understand what you wanted.  "
            "Showing help for help instead.")
    kw = {'help':True}

  component = kw.keys()[0]
  launcher = kw.values()[0]

  if component == 'help':
    # Special case!
    name = "pox.help"
  else:
    name = boot._do_import(component)

  if name is False:
    print("No such component:",component)
    sys.exit(1)

  mod = sys.modules[name]

  if launcher is not True and launcher not in mod.__dict__:
    print("No launch function named %s for %s" % (launcher, component))
    sys.exit(1)

  doc = inspect.getdoc(mod) or ''
  if short: doc = doc.split("\n")[0]

  if not doc:
    # Make sure we try to show SOMETHING...
    no_args = False

  launcher_doc = ""

  multi = ''
  args = ''

  if launcher is True and 'launch' in mod.__dict__:
    launcher = 'launch'
  if not no_args and launcher in mod.__dict__:
    f = mod.__dict__[launcher]
    if type(f) is not type(launch):
      # This isn't quite right if they didn't specify a launcher
      print(launch, "in", name, "isn't a function")

    launcher_doc = inspect.getdoc(f) or ''
    if short: launcher_doc = launcher_doc.split("\n")[0]

    if len(launcher_doc):
      launcher_doc = ' ' + launcher_doc.replace('\n', '\n ').strip()
      if launcher  == 'launch':
        launcher_doc = "Default launcher:\n" + launcher_doc
      else:
        launcher_doc = launcher + " launcher:\n" + launcher_doc

    args = _show_args(f,launcher)

  alldoc = [doc,launcher_doc,args,multi]

  alldoc = [x.strip() + "\n\n" for x in alldoc if len(x)]

  alldoc = ''.join(alldoc).strip() or 'No documentation available'

  print()
  print(alldoc)

  sys.exit(0)

########NEW FILE########
__FILENAME__ = host_tracker
# Copyright 2011 Dorgival Guedes
# Copyright 2013 James McCauley
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at:
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""
Tracks host location and configuration

Keep track of hosts in the network, where they are and how they are
configured (at least MAC/IP addresses).

For the time being, it keeps tables with the information; later, it should
transfer that information to Topology and handle just the actual
discovery/update of host information.

Timer configuration can be changed when needed (e.g., for debugging) using
the launch facility (check timeoutSec dict and PingCtrl.pingLim).

You can set various timeouts from the commandline.  Names and defaults:
  arpAware=60*2    Quiet ARP-responding entries are pinged after this
  arpSilent=60*20  This is for uiet entries not known to answer ARP
  arpReply=4       Time to wait for an ARP reply before retrial
  timerInterval=5  Seconds between timer routine activations
  entryMove=60     Minimum expected time to move a physical entry

Good values for testing:
  --arpAware=15 --arpSilent=45 --arpReply=1 --entryMove=4

You can also specify how many ARP pings we try before deciding it failed:
  --pingLim=2
"""

from pox.core import core

from pox.lib.addresses import EthAddr
from pox.lib.packet.ethernet import ethernet
from pox.lib.packet.ipv4 import ipv4
from pox.lib.packet.arp import arp

from pox.lib.recoco import Timer
from pox.lib.revent import Event, EventHalt

import pox.openflow.libopenflow_01 as of

import pox.openflow.discovery as discovery

from pox.lib.revent.revent import *

import time

import pox
log = core.getLogger()

# Times (in seconds) to use for differente timouts:
timeoutSec = dict(
  arpAware=60*2,   # Quiet ARP-responding entries are pinged after this
  arpSilent=60*20, # This is for uiet entries not known to answer ARP
  arpReply=4,      # Time to wait for an ARP reply before retrial
  timerInterval=5, # Seconds between timer routine activations
  entryMove=60     # Minimum expected time to move a physical entry
  )

# Address to send ARP pings from.
# The particular one here is just an arbitrary locally administered address.
DEFAULT_ARP_PING_SRC_MAC = '02:00:00:00:be:ef'


class HostEvent (Event):
  """
  Event when hosts join, leave, or move within the network
  """
  def __init__ (self, entry, new_dpid = None, new_port = None, join = False,
      leave = False, move = False):
    super(HostEvent,self).__init__()
    self.entry = entry
    self.join = join
    self.leave = leave
    self.move = move

    assert sum(1 for x in [join,leave,move] if x) == 1

    # You can alter these and they'll change where we think it goes...
    self._new_dpid = new_dpid
    self._new_port = new_port

    #TODO: Allow us to cancel add/removes

  @property
  def new_dpid (self):
    """
    New DPID for move events"
    """
    assert self.move
    return self._new_dpid

  @property
  def new_port (self):
    """
    New port for move events"
    """
    assert self.move
    return self._new_port


class Alive (object):
  """
  Holds liveliness information for MAC and IP entries
  """
  def __init__ (self, livelinessInterval=timeoutSec['arpAware']):
    self.lastTimeSeen = time.time()
    self.interval=livelinessInterval

  def expired (self):
    return time.time() > self.lastTimeSeen + self.interval

  def refresh (self):
    self.lastTimeSeen = time.time()


class PingCtrl (Alive):
  """
  Holds information for handling ARP pings for hosts
  """
  # Number of ARP ping attemps before deciding it failed
  pingLim=3

  def __init__ (self):
    super(PingCtrl,self).__init__(timeoutSec['arpReply'])
    self.pending = 0

  def sent (self):
    self.refresh()
    self.pending += 1

  def failed (self):
    return self.pending > PingCtrl.pingLim

  def received (self):
    # Clear any pending timeouts related to ARP pings
    self.pending = 0


class IpEntry (Alive):
  """
  This entry keeps track of IP addresses seen from each MAC entry and will
  be kept in the macEntry object's ipAddrs dictionary. At least for now,
  there is no need to refer to the original macEntry as the code is organized.
  """
  def __init__ (self, hasARP):
    if hasARP:
      super(IpEntry,self).__init__(timeoutSec['arpAware'])
    else:
      super(IpEntry,self).__init__(timeoutSec['arpSilent'])
    self.hasARP = hasARP
    self.pings = PingCtrl()

  def setHasARP (self):
    if not self.hasARP:
      self.hasARP = True
      self.interval = timeoutSec['arpAware']


class MacEntry (Alive):
  """
  Not strictly an ARP entry.
  When it gets moved to Topology, may include other host info, like
  services, and it may replace dpid by a general switch object reference
  We use the port to determine which port to forward traffic out of.
  """
  def __init__ (self, dpid, port, macaddr):
    super(MacEntry,self).__init__()
    self.dpid = dpid
    self.port = port
    self.macaddr = macaddr
    self.ipAddrs = {}

  def __str__(self):
    return ' '.join([str(self.dpid), str(self.port), str(self.macaddr)])

  def __eq__ (self, other):
    if other is None:
      return False
    elif type(other) == tuple:
      return (self.dpid,self.port,self.macaddr)==other

    if self.dpid != other.dpid: return False
    if self.port != other.port: return False
    if self.macaddr != other.macaddr: return False
    if self.dpid != other.dpid: return False
    # What about ipAddrs??
    return True

  def __ne__ (self, other):
    return not self.__eq__(other)


class host_tracker (EventMixin):
  """
  Host tracking component
  """
  _eventMixin_events = set([HostEvent])

  def __init__ (self, ping_src_mac = None, install_flow = True,
      eat_packets = True):

    if ping_src_mac is None:
      ping_src_mac = DEFAULT_ARP_PING_SRC_MAC

    self.ping_src_mac = EthAddr(ping_src_mac)
    self.install_flow = install_flow
    self.eat_packets = eat_packets

    # The following tables should go to Topology later
    self.entryByMAC = {}
    self._t = Timer(timeoutSec['timerInterval'],
                    self._check_timeouts, recurring=True)

    # Listen to openflow with high priority if we want to eat our ARP replies
    listen_args = {}
    if eat_packets:
      listen_args={'openflow':{'priority':0}}
    core.listen_to_dependencies(self, listen_args=listen_args)

  def _all_dependencies_met (self):
    log.info("host_tracker ready")

  # The following two functions should go to Topology also
  def getMacEntry (self, macaddr):
    try:
      result = self.entryByMAC[macaddr]
    except KeyError as e:
      result = None
    return result

  def sendPing (self, macEntry, ipAddr):
    """
    Builds an ETH/IP any-to-any ARP packet (an "ARP ping")
    """
    r = arp()
    r.opcode = arp.REQUEST
    r.hwdst = macEntry.macaddr
    r.hwsrc = self.ping_src_mac
    r.protodst = ipAddr
    # src is IP_ANY
    e = ethernet(type=ethernet.ARP_TYPE, src=r.hwsrc, dst=r.hwdst)
    e.payload = r
    log.debug("%i %i sending ARP REQ to %s %s",
              macEntry.dpid, macEntry.port, str(r.hwdst), str(r.protodst))
    msg = of.ofp_packet_out(data = e.pack(),
                            action = of.ofp_action_output(port=macEntry.port))
    if core.openflow.sendToDPID(macEntry.dpid, msg.pack()):
      ipEntry = macEntry.ipAddrs[ipAddr]
      ipEntry.pings.sent()
    else:
      # macEntry is stale, remove it.
      log.debug("%i %i ERROR sending ARP REQ to %s %s",
                macEntry.dpid, macEntry.port, str(r.hwdst), str(r.protodst))
      del macEntry.ipAddrs[ipAddr]
    return

  def getSrcIPandARP (self, packet):
    """
    Gets source IPv4 address for packets that have one (IPv4 and ARP)

    Returns (ip_address, has_arp).  If no IP, returns (None, False).
    """
    if isinstance(packet, ipv4):
      log.debug("IP %s => %s",str(packet.srcip),str(packet.dstip))
      return ( packet.srcip, False )
    elif isinstance(packet, arp):
      log.debug("ARP %s %s => %s",
                {arp.REQUEST:"request",arp.REPLY:"reply"}.get(packet.opcode,
                    'op:%i' % (packet.opcode,)),
               str(packet.protosrc), str(packet.protodst))
      if (packet.hwtype == arp.HW_TYPE_ETHERNET and
          packet.prototype == arp.PROTO_TYPE_IP and
          packet.protosrc != 0):
        return ( packet.protosrc, True )

    return ( None, False )

  def updateIPInfo (self, pckt_srcip, macEntry, hasARP):
    """
    Update given MacEntry

    If there is IP info in the incoming packet, update the macEntry
    accordingly. In the past we assumed a 1:1 mapping between MAC and IP
    addresses, but removed that restriction later to accomodate cases
    like virtual interfaces (1:n) and distributed packet rewriting (n:1)
    """
    if pckt_srcip in macEntry.ipAddrs:
      # that entry already has that IP
      ipEntry = macEntry.ipAddrs[pckt_srcip]
      ipEntry.refresh()
      log.debug("%s already has IP %s, refreshing",
                str(macEntry), str(pckt_srcip) )
    else:
      # new mapping
      ipEntry = IpEntry(hasARP)
      macEntry.ipAddrs[pckt_srcip] = ipEntry
      log.info("Learned %s got IP %s", str(macEntry), str(pckt_srcip) )
    if hasARP:
      ipEntry.pings.received()

  def _handle_openflow_ConnectionUp (self, event):
    if not self.install_flow: return

    log.debug("Installing flow for ARP ping responses")

    m = of.ofp_flow_mod()
    m.priority += 1 # Higher than normal
    m.match.dl_type = ethernet.ARP_TYPE
    m.match.dl_dst = self.ping_src_mac

    m.actions.append(of.ofp_action_output(port=of.OFPP_CONTROLLER))
    event.connection.send(m)

  def _handle_openflow_PacketIn (self, event):
    """
    Populate MAC and IP tables based on incoming packets.

    Handles only packets from ports identified as not switch-only.
    If a MAC was not seen before, insert it in the MAC table;
    otherwise, update table and enry.
    If packet has a source IP, update that info for the macEntry (may require
    removing the info from antoher entry previously with that IP address).
    It does not forward any packets, just extract info from them.
    """
    dpid = event.connection.dpid
    inport = event.port
    packet = event.parsed
    if not packet.parsed:
      log.warning("%i %i ignoring unparsed packet", dpid, inport)
      return

    if packet.type == ethernet.LLDP_TYPE: # Ignore LLDP packets
      return
    # This should use Topology later
    if not core.openflow_discovery.is_edge_port(dpid, inport):
      # No host should be right behind a switch-only port
      log.debug("%i %i ignoring packetIn at switch-only port", dpid, inport)
      return

    log.debug("PacketIn: %i %i ETH %s => %s",
              dpid, inport, str(packet.src), str(packet.dst))

    # Learn or update dpid/port/MAC info
    macEntry = self.getMacEntry(packet.src)
    if macEntry is None:
      # there is no known host by that MAC
      # should we raise a NewHostFound event (at the end)?
      macEntry = MacEntry(dpid,inport,packet.src)
      self.entryByMAC[packet.src] = macEntry
      log.info("Learned %s", str(macEntry))
      self.raiseEventNoErrors(HostEvent, macEntry, join=True)
    elif macEntry != (dpid, inport, packet.src):
      # there is already an entry of host with that MAC, but host has moved
      # should we raise a HostMoved event (at the end)?
      log.info("Learned %s moved to %i %i", str(macEntry), dpid, inport)
      # if there has not been long since heard from it...
      if time.time() - macEntry.lastTimeSeen < timeoutSec['entryMove']:
        log.warning("Possible duplicate: %s at time %i, now (%i %i), time %i",
                    str(macEntry), macEntry.lastTimeSeen,
                    dpid, inport, time.time())
      # should we create a whole new entry, or keep the previous host info?
      # for now, we keep it: IP info, answers pings, etc.
      e = HostEvent(macEntry, move=True, new_dpid = dpid, new_port = inport)
      self.raiseEventNoErrors(e)
      macEntry.dpid = e._new_dpid
      macEntry.inport = e._new_port

    macEntry.refresh()

    (pckt_srcip, hasARP) = self.getSrcIPandARP(packet.next)
    if pckt_srcip is not None:
      self.updateIPInfo(pckt_srcip,macEntry,hasARP)

    if self.eat_packets and packet.dst == self.ping_src_mac:
      return EventHalt

  def _check_timeouts (self):
    """
    Checks for timed out entries
    """
    for macEntry in self.entryByMAC.values():
      entryPinged = False
      for ip_addr, ipEntry in macEntry.ipAddrs.items():
        if ipEntry.expired():
          if ipEntry.pings.failed():
            del macEntry.ipAddrs[ip_addr]
            log.info("Entry %s: IP address %s expired",
                     str(macEntry), str(ip_addr) )
          else:
            self.sendPing(macEntry,ip_addr)
            ipEntry.pings.sent()
            entryPinged = True
      if macEntry.expired() and not entryPinged:
        log.info("Entry %s expired", str(macEntry))
        # sanity check: there should be no IP addresses left
        if len(macEntry.ipAddrs) > 0:
          for ip in macEntry.ipAddrs.keys():
            log.warning("Entry %s expired but still had IP address %s",
                        str(macEntry), str(ip_addr) )
            del macEntry.ipAddrs[ip_addr]
        self.raiseEventNoErrors(HostEvent, macEntry, leave=True)
        del self.entryByMAC[macEntry.macaddr]

########NEW FILE########
__FILENAME__ = debug_deadlock
# Copyright 2012 James McCauley
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at:
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""
Primitive help for debugging deadlocks.
Prints stack info for all threads.
(Might be more useful if it only printed stack frames that
were not changing, sort of like recoco_spy.)

This was initially factored out from a pox.py modification by
Colin or Andi.
"""

import sys
import time
import inspect
import traceback
import threading
from pox.core import core

def _trace_thread_proc ():
  try:
    while core.running:
      frames = sys._current_frames()
      for key in frames:
        frame = frames[key]
        print inspect.getframeinfo(frame)
        outer_frames = inspect.getouterframes(frame)
        for i in range(0, len(outer_frames)):
          print "     " + str(inspect.getframeinfo(outer_frames[i][0]))

      time.sleep(5)
  except:
    traceback.print_exc()


def launch ():

  _trace_thread = threading.Thread(target=_trace_thread_proc)
  _trace_thread.daemon = True

  # Start it up a bit in the future so that it doesn't print all over
  # init messages.
  core.callDelayed(3, _trace_thread.start)

########NEW FILE########
__FILENAME__ = packet_dump
# Copyright 2012 James McCauley
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at:
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""
A simple component that dumps packet_in info to the log.

Use --verbose for really verbose dumps.
Use --show to show all packets.
"""

from pox.core import core
import pox.openflow.libopenflow_01 as of
import pox.lib.packet as pkt
from pox.lib.util import dpidToStr

log = core.getLogger()

_verbose = None
_max_length = None
_types = None
_show_by_default = None

def _handle_PacketIn (event):
  packet = event.parsed

  show = _show_by_default
  p = packet
  while p:
    if p.__class__.__name__.lower() in _types:
      if _show_by_default:
        # This packet is hidden
        return
      else:
        # This packet should be shown
        show = True
        break
      return
    if not hasattr(p, 'next'): break
    p = p.next

  if not show: return

  msg = dpidToStr(event.dpid) + ": "
  msg = ""
  if _verbose:
    msg += packet.dump()
  else:
    p = packet
    while p:
      if isinstance(p, basestring):
        msg += "[%s bytes]" % (len(p),)
        break
      msg += "[%s]" % (p.__class__.__name__,)
      p = p.next

  if _max_length:
    if len(msg) > _max_length:
      msg = msg[:_max_length-3]
      msg += "..."
  core.getLogger("dump:" + dpidToStr(event.dpid)).debug(msg)


def launch (verbose = False, max_length = 110, full_packets = True,
            hide = False, show = False):
  global _verbose, _max_length, _types, _show_by_default
  _verbose = verbose
  _max_length = max_length
  force_show = (show is True) or (hide is False and show is False)
  if isinstance(hide, basestring):
    hide = hide.replace(',', ' ').replace('|', ' ')
    hide = set([p.lower() for p in hide.split()])
  else:
    hide = set()
  if isinstance(show, basestring):
    show = show.replace(',', ' ').replace('|', ' ')
    show = set([p.lower() for p in show.split()])
  else:
    show = set()

  if hide and show:
    raise RuntimeError("Can't both show and hide packet types")

  if show:
    _types = show
  else:
    _types = hide
  _show_by_default = not not hide
  if force_show:
    _show_by_default = force_show

  if full_packets:
    # Send full packets to controller
    core.openflow.miss_send_len = 0xffff

  core.openflow.addListenerByName("PacketIn", _handle_PacketIn)

  log.info("Packet dumper running")

########NEW FILE########
__FILENAME__ = recoco_spy
# Copyright 2012 James McCauley
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at:
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""
This is an extremely primitive start at some debugging.
At the moment, it is really just for recoco (maybe it belongs in there?).
"""

from pox.core import core
log = core.getLogger()
import time
import traceback
import pox.lib.recoco

_frames = []

def _tf (frame, event, arg):
  if _frames is None: return _tf
  #print " " * len(_frames) + event
  if event == 'call':
    _frames.append(frame)
    return _tf
  elif event == 'line':
    return _tf
  elif event == 'exception':
    #_frames.pop()
    return _tf
  elif event == 'return':
    _frames.pop()
  elif event == 'c_call':
    print "c_call"
    _frames.append((frame,arg))
  elif event == 'c_exception':
    _frames.pop()
  elif event == 'c_return':
    _frames.pop()


def _trace_thread_proc ():
  last = None
  last_time = None
  warned = None
  while True:
    try:
      time.sleep(1)
      c = len(_frames)
      if c == 0: continue
      f = _frames[-1]
      stopAt = None
      count = 0
      sf = f
      while sf is not None:
        if sf.f_code == pox.lib.recoco.Scheduler.cycle.im_func.func_code:
          stopAt = sf
          break
        count += 1
        sf = sf.f_back
      #if stopAt == None: continue

      f = "\n".join([s.strip() for s in
                      traceback.format_stack(f,count)])
      #f = " / ".join([s.strip() for s in
      #                traceback.format_stack(f,1)[0].strip().split("\n")])
      #f = "\n".join([s.strip() for s in
      #                traceback.format_stack(f)])

      if f != last:
        if warned:
          log.warning("Running again")
        warned = None
        last = f
        last_time = time.time()
      elif f != warned:
        if time.time() - last_time > 3:
          if stopAt is not None:
            warned = f
            log.warning("Stuck at:\n" + f)

      #from pox.core import core
      #core.f = f

    except:
      traceback.print_exc()
      pass



def launch ():
  def f ():
    import sys
    sys.settrace(_tf)
  core.callLater(f)

  import threading
  _trace_thread = threading.Thread(target=_trace_thread_proc)
  _trace_thread.daemon = True
  _trace_thread.start()

########NEW FILE########
__FILENAME__ = switch_info
# Copyright 2013 James McCauley
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at:
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""
Dumps info about switches when they first connect
"""

from pox.core import core
import pox.openflow.libopenflow_01 as of
from pox.lib.util import dpid_to_str

log = core.getLogger()

# Formatted switch descriptions we've logged
# (We rememeber them so that we only print them once)
_switches = set()

# .. unless always is True in which case we always print them
_always = False

def _format_entry (desc):
  def fmt (v):
    if not v: return "<Empty>"
    return str(v)
  dpid = dpid_to_str(desc.connection.dpid)
  ofp = desc.ofp.body
  s = []
  ports = [(p.port_no,p.name) for p in desc.connection.ports.values()]
  ports.sort()
  ports = " ".join(p[1] for p in ports)
  #if len(ports) > len(dpid)+12:
  #  ports = "%s ports" % (len(desc.connection.ports),)

  s.append("New Switch: " + dpid)
  s.append("Hardware:  " + fmt(ofp.hw_desc))
  s.append("Software:  " + fmt(ofp.sw_desc))
  s.append("SerialNum: " + fmt(ofp.serial_num))
  s.append("Desc:      " + fmt(ofp.dp_desc))
  s.append("Ports:     " + fmt(ports))

  # Let's get fancy
  width = max(len(line) for line in s)
  s.insert(0, "=" * width)
  s.insert(2, "-" * width)
  s.append(   "=" * width)

  return "\n".join(s)

def _handle_ConnectionUp (event):
  msg = of.ofp_stats_request(body=of.ofp_desc_stats_request())
  msg.type = 0 # For betta bug, can be removed
  event.connection.send(msg)

def _handle_SwitchDescReceived (event):
  s = _format_entry(event)
  if not _always and s in _switches:
    # We've already logged it.
    return
  _switches.add(s)
  ss = s.split("\n")

  logger = core.getLogger("info." + dpid_to_str(event.connection.dpid))
  for s in ss:
    logger.info(s)


def launch (always = False):
  global _always
  _always = always

  core.openflow.addListenerByName("ConnectionUp",
      _handle_ConnectionUp)
  core.openflow.addListenerByName("SwitchDescReceived",
      _handle_SwitchDescReceived)

########NEW FILE########
__FILENAME__ = addresses
# Copyright 2011,2012,2013 James McCauley
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at:
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""
Classes and utilities for addresses of various types.
"""

from __future__ import print_function
import struct
import socket

# Slightly tested attempt at Python 3 friendliness
import sys
if 'long' not in sys.modules['__builtin__'].__dict__:
  long = int


"""
# Unfinished oui name stuff formerly from packet library.

    oui = int(a[0]) << 16 | int(a[1]) << 8 | int(a[2])

    # check if globally unique
    if resolve_name and not (a[0] & 0x2):
        if _ethoui2name.has_key(oui):
            return "(%s):%02x:%02x:%02x" %( _ethoui2name[oui], a[3],a[4],a[5])
"""
_eth_oui_to_name = {}

def _load_oui_names ():
    import inspect
    import os.path
    filename = os.path.join(os.path.dirname(inspect.stack()[0][1]), 'oui.txt')
    f = None
    try:
        f = open(filename)
        for line in f.readlines():
            if len(line) < 1:
                continue
            if line[0].isspace():
                continue
            split = line.split(' ')
            if not '-' in split[0]:
                continue
            # grab 3-byte OUI
            oui_str  = split[0].replace('-','')
            # strip off (hex) identifer and keep rest of name
            end = ' '.join(split[1:]).strip()
            end = end.split('\t')
            end.remove('(hex)')
            oui_name = ' '.join(end)
            # convert oui to int
            oui = int(oui_str, 16)
            _eth_oui_to_name[oui] = oui_name.strip()
    except:
        import logging
        logging.getLogger().warn("Could not load OUI list")
    if f: f.close()
_load_oui_names()


class EthAddr (object):
  """
  An Ethernet (MAC) address type.
  """
  def __init__ (self, addr):
    """
    Understands Ethernet address is various forms.  Hex strings, raw byte
    strings, etc.
    """
    # Always stores as a 6 character string
    if isinstance(addr, bytes) or isinstance(addr, basestring):
      if len(addr) == 6:
        # raw
        pass
      elif len(addr) == 17 or len(addr) == 12 or addr.count(':') == 5:
        # hex
        if len(addr) == 17:
          if addr[2::3] != ':::::' and addr[2::3] != '-----':
            raise RuntimeError("Bad format for ethernet address")
          # Address of form xx:xx:xx:xx:xx:xx
          # Pick out the hex digits only
          addr = ''.join((addr[x*3:x*3+2] for x in xrange(0,6)))
        elif len(addr) == 12:
          pass
        else:
          # Assume it's hex digits but they may not all be in two-digit
          # groupings (e.g., xx:x:x:xx:x:x). This actually comes up.
          addr = ''.join(["%02x" % (int(x,16),) for x in addr.split(":")])
        # We should now have 12 hex digits (xxxxxxxxxxxx).
        # Convert to 6 raw bytes.
        addr = b''.join((chr(int(addr[x*2:x*2+2], 16)) for x in range(0,6)))
      else:
        raise RuntimeError("Expected ethernet address string to be 6 raw "
                           "bytes or some hex")
      self._value = addr
    elif isinstance(addr, EthAddr):
      self._value = addr.toRaw()
    elif type(addr) == list or (hasattr(addr, '__len__') and len(addr) == 6
          and hasattr(addr, '__iter__')):
      self._value = b''.join( (chr(x) for x in addr) )
    elif addr is None:
      self._value = b'\x00' * 6
    else:
      raise RuntimeError("Expected ethernet address to be a string of 6 raw "
                         "bytes or some hex")

  def isBridgeFiltered (self):
    """
    Checks if address is an IEEE 802.1D MAC Bridge Filtered MAC Group Address

    This range is 01-80-C2-00-00-00 to 01-80-C2-00-00-0F. MAC frames that
    have a destination MAC address within this range are not relayed by
    bridges conforming to IEEE 802.1D
    """
    return  ((ord(self._value[0]) == 0x01)
    	and (ord(self._value[1]) == 0x80)
    	and (ord(self._value[2]) == 0xC2)
    	and (ord(self._value[3]) == 0x00)
    	and (ord(self._value[4]) == 0x00)
    	and (ord(self._value[5]) <= 0x0F))

  @property
  def is_bridge_filtered (self):
    return self.isBridgeFiltered()

  def isGlobal (self):
    """
    Returns True if this is a globally unique (OUI enforced) address.
    """
    return not self.isLocal()

  def isLocal (self):
    """
    Returns True if this is a locally-administered (non-global) address.
    """
    return True if (ord(self._value[0]) & 2) else False

  @property
  def is_local (self):
    return self.isLocal()

  @property
  def is_global (self):
    return self.isGlobal()

  def isMulticast (self):
    """
    Returns True if this is a multicast address.
    """
    return True if (ord(self._value[0]) & 1) else False

  @property
  def is_multicast (self):
    return self.isMulticast()

  def toRaw (self):
    return self.raw

  @property
  def raw (self):
    """
    Returns the address as a 6-long bytes object.
    """
    return self._value

  def toTuple (self):
    """
    Returns a 6-entry long tuple where each entry is the numeric value
    of the corresponding byte of the address.
    """
    return tuple((ord(x) for x in self._value))

  def toStr (self, separator = ':', resolveNames  = False):
    """
    Returns the address as string consisting of 12 hex chars separated
    by separator.
    If resolveNames is True, it may return company names based on
    the OUI. (Currently unimplemented)
    """
    #TODO: show OUI info from packet lib ?
    return separator.join(('%02x' % (ord(x),) for x in self._value))

  def __str__ (self):
    return self.toStr()

  def __cmp__ (self, other):
    try:
      if type(other) == EthAddr:
        other = other._value
      elif type(other) == bytes:
        pass
      else:
        other = EthAddr(other)._value
      if self._value == other:
        return 0
      if self._value < other:
        return -1
      if self._value > other:
        return -1
      raise RuntimeError("Objects can not be compared?")
    except:
      return -other.__cmp__(self)

  def __hash__ (self):
    return self._value.__hash__()

  def __repr__ (self):
    return self.__class__.__name__ + "('" + self.toStr() + "')"

  def __len__ (self):
    return 6

  def __setattr__ (self, a, v):
    if hasattr(self, '_value'):
      raise TypeError("This object is immutable")
    object.__setattr__(self, a, v)


class IPAddr (object):
  """
  Represents an IPv4 address.
  """
  def __init__ (self, addr, networkOrder = False):
    """
    Initialize using several possible formats

    If addr is an int/long, then it is assumed to be in host byte order
    unless networkOrder = True
    Stored in network byte order as a signed int
    """

    # Always stores as a signed network-order int
    if isinstance(addr, basestring) or isinstance(addr, bytes):
      if len(addr) != 4:
        # dotted quad
        self._value = struct.unpack('i', socket.inet_aton(addr))[0]
      else:
        self._value = struct.unpack('i', addr)[0]
    elif isinstance(addr, IPAddr):
      self._value = addr._value
    elif isinstance(addr, int) or isinstance(addr, long):
      addr = addr & 0xffFFffFF # unsigned long
      self._value = struct.unpack("!i",
          struct.pack(('!' if networkOrder else '') + "I", addr))[0]
    else:
      raise RuntimeError("Unexpected IP address format")

  def toSignedN (self):
    """ A shortcut """
    return self.toSigned(networkOrder = True)

  def toUnsignedN (self):
    """ A shortcut """
    return self.toUnsigned(networkOrder = True)

  def toSigned (self, networkOrder = False):
    """ Return the address as a signed int """
    if networkOrder:
      return self._value
    v = socket.htonl(self._value & 0xffFFffFF)
    return struct.unpack("i", struct.pack("I", v))[0]

  def toRaw (self):
    return self.raw

  @property
  def raw (self):
    """
    Returns the address as a four-character byte string.
    """
    return struct.pack("i", self._value)

  def toUnsigned (self, networkOrder = False):
    """
    Returns the address as an integer in either network or host (the
    default) byte order.
    """
    if not networkOrder:
      return socket.htonl(self._value & 0xffFFffFF)
    return self._value & 0xffFFffFF

  def toStr (self):
    """ Return dotted quad representation """
    return socket.inet_ntoa(self.toRaw())

  def in_network (self, *args, **kw):
    return self.inNetwork(*args, **kw)

  def inNetwork (self, network, netmask = None):
    """
    Returns True if this network is in the specified network.
    network is a dotted quad (with or without a CIDR or normal style
    netmask, which can also be specified separately via the netmask
    parameter), or it can be a tuple of (address,network-bits) like that
    returned by parse_cidr().
    """
    if type(network) is not tuple:
      if netmask is not None:
        network = str(network)
        network += "/" + str(netmask)
      n,b = parse_cidr(network)
    else:
      n,b = network
      if type(n) is not IPAddr:
        n = IPAddr(n)

    return (self.toUnsigned() & ~((1 << (32-b))-1)) == n.toUnsigned()

  @property
  def is_multicast (self):
    return ((self.toSigned(networkOrder = False) >> 24) & 0xe0) == 0xe0

  @property
  def multicast_ethernet_address (self):
    """
    Returns corresponding multicast EthAddr

    Assumes this is, in fact, a multicast IP address!
    """
    if not self.is_multicast:
      raise RuntimeError("No multicast EthAddr for non-multicast IPAddr!")
    n = self.toUnsigned(networkOrder = False) & 0x7fffff
    return EthAddr("01005e" + ("%06x" % (n)))

  def __str__ (self):
    return self.toStr()

  def __cmp__ (self, other):
    if other is None: return 1
    try:
      if not isinstance(other, IPAddr):
        other = IPAddr(other)
      return cmp(self.toUnsigned(), other.toUnsigned())
    except:
      return -other.__cmp__(self)

  def __hash__ (self):
    return self._value.__hash__()

  def __repr__ (self):
    return self.__class__.__name__ + "('" + self.toStr() + "')"

  def __len__ (self):
    return 4

  def __setattr__ (self, a, v):
    if hasattr(self, '_value'):
      raise TypeError("This object is immutable")
    object.__setattr__(self, a, v)


class IPAddr6 (object):
  """
  Represents an IPv6 address.
  """
  @classmethod
  def from_raw (cls, raw):
    return cls(raw, raw=True)

  @classmethod
  def from_num (cls, num):
    o = b''
    for i in xrange(16):
      o = chr(num & 0xff) + o
      num >>= 8
    return cls.from_raw(o)

  def __init__ (self, addr = None, raw = False, network_order = False):
    # When we move to Python 3, we can use bytes to infer raw.
    if addr is None and isinstance(raw, (bytes,bytearray)):
      addr = raw
      raw = True
    if addr is None:
      return self.UNDEFINED
    if isinstance(addr, unicode) or (isinstance(addr, bytes) and not raw):
      ip4part = None
      if '.' in addr:
        addr,ip4part = addr.rsplit(':',1)
        if '.' in addr:
          raise RuntimeError('IPv4-compatible representation unimplemented')
        if ':' in ip4part:
          raise RuntimeError('Bad address format')
        addr += ':0:0'

      segs = addr.split(':')
      if addr.count('::') > 1:
        raise RuntimeError("Bad address format " + str(addr))
      if len(segs) < 3 or len(segs) > 8:
        raise RuntimeError("Bad address format " + str(addr))

      p = ([],[])
      side = 0
      for i,s in enumerate(segs):
        if len(s) == 0:
          #if side != 0:
            #if i != len(segs)-1:
            #  raise RuntimeError("Bad address format " + str(addr))
          side = 1
          continue
        s = int(s,16)
        if s < 0 or s > 0xffff:
          raise RuntimeError("Bad address format " + str(addr))
        p[side].append(s)

      o = p[0] + ([0] * (8-len(p[0])-len(p[1]))) + p[1]

      v = b''
      for b in o:
        v += struct.pack('!H', b)

      if ip4part is not None:
        v = v[:-4] + IPAddr(ip4part).toRaw()

      self._value = v
    elif isinstance(addr, type(self)):
      self._value = addr._value
    elif isinstance(addr, IPAddr):
      #FIXME: This is hacky.
      self._value = IPAddr6("::ffff:0:0:" + str(addr))
    elif isinstance(addr, bytearray):
      self._value = bytes(addr)
    elif isinstance(addr, bytes):
      self._value = addr
    else:
      raise RuntimeError("Unexpected IP address format")

  @property
  def raw (self):
    return self._value

  @property
  def ipv4 (self):
    return self.to_ipv4(check_ipv4=False)

  def to_ipv4 (self, check_ipv4 = True):
    """
    Only makes sense if this address is ipv4 mapped/compatible
    """
    if check_ipv4:
      if not self.is_ipv4:
        raise RuntimeError('Not an IPv4ish IPv6 address')
    return IPAddr(self._value[-4:])

  @property
  def num (self):
    o = 0
    for b in self._value:
      o = (o << 8) | ord(b)
    return o

  @property
  def is_multicast (self):
    return self.in_network('ff00::/8')

  @property
  def is_global_unicast (self):
    return self.in_network('2000::/3')

  @property
  def is_unique_local_unicast (self):
    return self.in_network('fc00::/7')

  @property
  def is_link_unicast (self):
    return self.in_network('fe80::/10')

  @property
  def is_ipv4 (self):
    return self.in_network('::/80')

  @property
  def is_ipv4_compatible (self):
    return self.in_network('::/96')

  @property
  def is_ipv4_mapped (self):
    return self.in_network('::ffff:0:0/96')

  @property
  def is_reserved (self):
    #TODO
    raise RuntimeError("Not implemented")

  @staticmethod
  def netmask_to_cidr (dq):
    """
    Takes a netmask as either an IPAddr or a string, and returns the number
    of network bits.  e.g., 255.255.255.0 -> 24
    Raise exception if subnet mask is not CIDR-compatible.
    """
    if isinstance(dq, basestring):
      dq = IPAddr6(dq)
    v = dq.num
    c = 0
    while v & (1<<127):
      c += 1
      v <<= 1
    v = v & ((1<<128)-1)
    if v != 0:
      raise RuntimeError("Netmask %s is not CIDR-compatible" % (dq,))
    return c

  @staticmethod
  def cidr_to_netmask (bits):
    """
    Takes a number of network bits, and returns the corresponding netmask
    as an IPAddr6.
    """
    v = (1 << bits) - 1
    v = v << (128-bits)
    return IPAddr6.from_num(v)

  @staticmethod
  def parse_cidr (addr_and_net, allow_host = False):
    """
    Parses addr/netbits or addr/netmask

    Returns (IPAddr6,netbits)
    """
    addr = addr_and_net
    def check (r0, r1):
      a = r0.num
      b = r1
      if (not allow_host) and (a & ((1<<b)-1)):
        raise RuntimeError("Host part of CIDR address is not zero (%s)"
                           % (addr,))
      return (r0,128-r1)
    addr = addr.split('/', 2)
    if len(addr) == 1:
      return check(IPAddr6(addr[0]), 0)
    try:
      wild = 128-int(addr[1])
    except:
      # Maybe they passed a netmask
      m = IPAddr6(addr[1]).num
      b = 0
      while m & (1<<127):
        b += 1
        m <<= 1
      if m & ((1<<127)-1) != 0:
        raise RuntimeError("Netmask " + str(addr[1])
                           + " is not CIDR-compatible")
      wild = 128-b
      assert wild >= 0 and wild <= 128
      return check(IPAddr6(addr[0]), wild)
    assert wild >= 0 and wild <= 128
    return check(IPAddr6(addr[0]), wild)

  def in_network (self, network, netmask = None):
    """
    Returns True if this address is in the specified network.

    network can be specified as:
    IPAddr6 with numeric netbits or netmask in netmask parameter
    textual network with numeric netbits or netmask in netmask parameter
    textual network with netbits or netmask separated by a slash
    tuple of textual address and numeric netbits
    tuple of IPAddr6 and numeric netbits
    """
    if type(network) is not tuple:
      if netmask is not None:
        network = str(network) + "/" + str(netmask)
      n,b = self.parse_cidr(network)
    else:
      n,b = network
      if type(n) is not IPAddr6:
        n = IPAddr6(n)

    return (self.num & ~((1 << (128-b))-1)) == n.num

  def to_str (self, zero_drop = True, section_drop = True, ipv4 = None):

    o = [ord(lo) | (ord(hi)<<8) for hi,lo in
         (self._value[i:i+2] for i in xrange(0,16,2))]

    if (ipv4 is None and self.is_ipv4_mapped) or ipv4:
      ip4part = o[-2:]
      o[-2:] = [1,1]
      def finalize (s):
        s = s.rsplit(':',2)[0]
        return s + ":" + str(IPAddr(self.raw[-4:]))
    else:
      def finalize (s):
        return s

    if zero_drop:
      def fmt (n):
        return ':'.join('%x' % (b,) for b in n)
    else:
      def fmt (n):
        return ':'.join('%04x' % (b,) for b in n)

    if section_drop:
      z = [] # [length,pos] of zero run
      run = None
      for i,b in enumerate(o):
        if b == 0:
          if run is None:
            run = [1,i]
            z.append(run)
          else:
            run[0] += 1
        else:
          run = None

      if len(z):
        # Sloppy!
        max_len = max([length for length,pos in z])
        if max_len > 1:
          z = [pos for length,pos in z if length == max_len]
          z.sort()
          pos = z[0]
          return finalize('::'.join((fmt(o[:pos]),fmt(o[pos+max_len:]))))

    return finalize(fmt(o))

  def __str__ (self):
    return self.to_str()

  def __cmp__ (self, other):
    if other is None: return 1
    try:
      if not isinstance(other, type(self)):
        other = type(self)(other)
      return cmp(self._value, other._value)
    except:
      return -cmp(other,self)

  def __hash__ (self):
    return self._value.__hash__()

  def __repr__ (self):
    return type(self).__name__ + "('" + self.to_str() + "')"

  def __len__ (self):
    return 16

  def __setattr__ (self, a, v):
    if hasattr(self, '_value'):
      raise TypeError("This object is immutable")
    object.__setattr__(self, a, v)

  def set_mac (self, eth):
    e = list(EthAddr(eth).toTuple())
    e[0] ^= 2
    e[3:3] = [0xff,0xfe]
    e = ''.join(chr(b) for b in e)
    return IPAddr6.from_raw(self._value[:8]+e)


IPAddr6.UNDEFINED = IPAddr6('::')
IPAddr6.ALL_NODES_LINK_LOCAL = IPAddr6('ff02::1')
IPAddr6.ALL_ROUTERS_LINK_LOCAL = IPAddr6('ff02::2')
IPAddr6.ALL_NODES_INTERFACE_LOCAL = IPAddr6('ff01::1')
IPAddr6.ALL_ROUTERS_INTERFACE_LOCAL = IPAddr6('ff01::2')
#ff02::1:3 link local multicast name resolution
#ff02::1:ff00:0/104 solicited-node
#ff02::2:ff00:0/104 node information query



def netmask_to_cidr (dq):
  """
  Takes a netmask as either an IPAddr or a string, and returns the number
  of network bits.  e.g., 255.255.255.0 -> 24
  Raise exception if subnet mask is not CIDR-compatible.
  """
  if isinstance(dq, basestring):
    dq = IPAddr(dq)
  v = dq.toUnsigned(networkOrder=False)
  c = 0
  while v & 0x80000000:
    c += 1
    v <<= 1
  v = v & 0xffFFffFF
  if v != 0:
    raise RuntimeError("Netmask %s is not CIDR-compatible" % (dq,))
  return c


def cidr_to_netmask (bits):
  """
  Takes a number of network bits, and returns the corresponding netmask
  as an IPAddr.  e.g., 24 -> 255.255.255.0
  """
  v = (1 << bits) - 1
  v = v << (32-bits)
  return IPAddr(v, networkOrder = False)


def parse_cidr (addr, infer=True, allow_host=False):
  """
  Takes a CIDR address or plain dotted-quad, and returns a tuple of address
  and count-of-network-bits.
  Can infer the network bits based on network classes if infer=True.
  Can also take a string in the form 'address/netmask', as long as the
  netmask is representable in CIDR.

  FIXME: This function is badly named.
  """
  def check (r0, r1):
    a = r0.toUnsigned()
    b = r1
    if (not allow_host) and (a & ((1<<b)-1)):
      raise RuntimeError("Host part of CIDR address is not zero (%s)"
                         % (addr,))
    return (r0,32-r1)
  addr = addr.split('/', 2)
  if len(addr) == 1:
    if infer is False:
      return check(IPAddr(addr[0]), 0)
    addr = IPAddr(addr[0])
    b = 32-infer_netmask(addr)
    m = (1<<b)-1
    if (addr.toUnsigned() & m) == 0:
      # All bits in wildcarded part are 0, so we'll use the wildcard
      return check(addr, b)
    else:
      # Some bits in the wildcarded part are set, so we'll assume it's a host
      return check(addr, 0)
  try:
    wild = 32-int(addr[1])
  except:
    # Maybe they passed a netmask
    m = IPAddr(addr[1]).toUnsigned()
    b = 0
    while m & (1<<31):
      b += 1
      m <<= 1
    if m & 0x7fffffff != 0:
      raise RuntimeError("Netmask " + str(addr[1]) + " is not CIDR-compatible")
    wild = 32-b
    assert wild >= 0 and wild <= 32
    return check(IPAddr(addr[0]), wild)
  assert wild >= 0 and wild <= 32
  return check(IPAddr(addr[0]), wild)


def infer_netmask (addr):
  """
  Uses network classes to guess the number of network bits
  """
  addr = addr.toUnsigned()
  if addr == 0:
    # Special case -- default network
    return 32-32 # all bits wildcarded
  if (addr & (1 << 31)) == 0:
    # Class A
    return 32-24
  if (addr & (3 << 30)) == 2 << 30:
    # Class B
    return 32-16
  if (addr & (7 << 29)) == 6 << 29:
    # Class C
    return 32-8
  if (addr & (15 << 28)) == 14 << 28:
    # Class D (Multicast)
    return 32-0 # exact match
  # Must be a Class E (Experimental)
    return 32-0


IP_ANY = IPAddr("0.0.0.0")
IP_BROADCAST = IPAddr("255.255.255.255")


if __name__ == '__main__':
  # A couple sanity checks
  #TODO: move to tests
  import code
  a = IPAddr('255.0.0.1')
  for v in [('255.0.0.1',True), (0xff000001, True), (0x010000ff, False)]:
    print("== " + str(v) + " =======================")
    a = IPAddr(v[0],v[1])
    print(a._value,-16777215)
    #print(hex(a._value),'ff000001')
    print(str(a),'255.0.0.1')
    print(hex(a.toUnsigned()),'010000ff')
    print(hex(a.toUnsigned(networkOrder=True)),'ff000001')
    print(a.toSigned(),16777471)
    print(a.toSigned(networkOrder=True),-16777215)
    print("----")
    print([parse_cidr(x)[1]==24 for x in
           ["192.168.101.0","192.168.102.0/24","1.1.168.103/255.255.255.0"]])
  code.interact(local=locals())

########NEW FILE########
__FILENAME__ = epoll_select
# Copyright 2012 Andreas Wundsam
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at:
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import select

class EpollSelect(object):
  """ a class that implements select.select() type behavior on top of epoll.
      Necessary, because select() only works on FD_SETSIZE (typically 1024) fd's at a time
  """

  def __init__(self):
    self.epoll = select.epoll()
    self.fd_to_obj = {}
    self.registered = {}
    self.lastrl = []
    self.lastrl_set = set()
    self.lastwl = []
    self.lastwl_set = set()

  def select(self, rl, wl, xl, timeout=0):
    """ emulate the select semantics on top of _epoll.
        Note this tries to emulate the behavior of select.select()
          - you can pass a raw fd, or an object that answers to #fileno().
          - will return the object that belongs to the fd
    """

    # a map of fd's that need to be modified.
    # fd -> flag to be set (0 for unregister fd)
    modify={}

    def modify_table(current_obj_list, old_fd_set, op):
      """ add operations to modify the registered fd's for operation / epoll mask 'op'
          Returns the old_fd_set you should pass in next time
          Also updates the fd_to_obj map.
          Yes, this is ugly. """
      current_fd_set = set()
      for obj in current_obj_list:
        # iterate through current_obj_list, udpate fd to obj mapping, and create set of fds
        fd = obj.fileno() if hasattr(obj, "fileno") else obj
        self.fd_to_obj[fd] = obj
        current_fd_set.add(fd)

      # new fds to register (for this op)
      new = current_fd_set - old_fd_set
      for fd in new:
        if not fd in modify:
          modify[fd] = self.registered[fd] if fd in self.registered else 0
        modify[fd] |= op
      # fd's to remove (at least for this op)
      expired = old_fd_set - current_fd_set
      for fd in expired:
        if not fd in modify:
          modify[fd] = self.registered[fd] if fd in self.registered else 0
        modify[fd] &= ~op

      return current_fd_set

    # optimization assumptions
    # rl is large and rarely changes
    if rl != self.lastrl:
      self.lastrl_set = modify_table(rl, self.lastrl_set, select.EPOLLIN|select.EPOLLPRI)
      self.lastrl = rl

    if wl != self.lastwl:
      self.lastwl_set = modify_table(wl, self.lastwl_set, select.EPOLLOUT)
      self.lastwl = wl

    # ignore XL. Tough luck, epoll /always/ checks for error conditions
    # you should, anyway

    # now execute the modify ops on the epoll object
    for (fd, mask) in modify.iteritems():
      if fd in self.registered:
        if mask == 0:
          self.epoll.unregister(fd)
          del self.registered[fd]
        else:
          self.epoll.modify(fd, mask)
          self.registered[fd] = mask
      else:
        if mask == 0:
          raise AssertionError("This should never happen - a new fd was scheduled for modification but neither for read nor write_")
        else:
          self.epoll.register(fd, mask)
          self.registered[fd] = mask

    # now for the real beef
    events = self.epoll.poll(timeout)

    # convert the events list of (fd, event) tuple to the three lists expected by select users
    retrl = []
    retwl = []
    retxl = []
    for (fd, event) in events:
      if event & (select.EPOLLIN|select.EPOLLPRI|select.EPOLLRDNORM|select.EPOLLRDBAND):
        retrl.append(self.fd_to_obj[fd])
      if event & (select.EPOLLOUT|select.EPOLLWRNORM|select.EPOLLWRBAND):
        retwl.append(self.fd_to_obj[fd])
      if event & (select.EPOLLERR|select.EPOLLHUP):
        retxl.append(self.fd_to_obj[fd])

    return (retrl, retwl, retxl)

  def close(self):
    self.epoll.close()

########NEW FILE########
__FILENAME__ = graph
# Copyright 2011 James McCauley
# Copyright 2012 James McCauley
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at:
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

#import networkx as nx
import pox.lib.graph.minigraph as nx
from collections import defaultdict
from copy import copy

LINK = 'link'

class Link (object):

  def reorder (self, l):
    """
    Flips a list of Links so that this node is first in each
    """
    return Link.order(l, self)

  @staticmethod
  def order (links, n):
    """
    Give a list of Links that each contain node n, flips any links so
    that n is always the first element of the link.
    """
    r = []
    for l in links:
      assert n in l
      if l._n[0] == n:
        r.append(l)
      else:
        r.append(l.flip())
    return r

  def __init__ (self, np1, np2):
    self._n = [np1[0],np2[0]]
    self._p = [np1[1],np2[1]]

  def _index (self, i):
    if i in self._n:
      i = self._n.index(i)
    assert i == 0 or i == 1
    return i

  def flip (self):
    """
    Returns the same link, but flipped (a,b) becomes (b,a)
    """
    return Link(self[1], self[0])

  def port (self, n):
    return self._p[_index(n)]

  def other_port (self, n):
    """
    Returns the other end's port.
    See other().
    """
    return self.other(n)[1]

  def other (self, n):
    """
    Returns the other end of a link.
    Given a node or (node,port) that is part of this link, it returns
    the opposite end's (node,port).
    """
    if type(n) is tuple:
      if self[0] == n:
        return self[1]
      assert self[1] == n
      return self[0]

    if self[0][0] == n:
      return self[1]
    assert self[1][0] == n
    return self[0]

  def __contains__ (self, n):
    """
    Does this link contain (node,port) or node?
    """
    if type(n) is tuple:
      return n in [self[0], self[1]]
    else:
      return n in [self._n]

  def __len__ (self):
    return 2

  def __getitem__ (self, i):
    """
    Gets (node,port) based on index
    """
    i = self._index(i)
    return (self._n[i], self._p[i])

  def __repr__ (self):
    return "Link(%s, %s)" % (self[0], self[1])


class Node (object):
  pass
  #TODO: Add back in some convenience methods that call real methods
  #      on the parent graph?  Or just remove?


def _void ():
  return None

class LeaveException (RuntimeError):
  pass

class Operator (object):
  def __repr__ (self):
    return "<%s>" % (self.__class__.__name__)

class Literal (Operator):
  def __init__ (self, v):
    self._v = v
  def __call__ (self, n, li=None):
    return self._v
  def __repr__ (self):
    return repr(self._v)

class Anything (Operator):
  def __call__ (self, n, li):
    return True

  def __repr__ (self):
    return "Anything"

class Self (Operator):
  def __call__ (self, n, li=None):
    return n
  def __repr__ (self):
    return "Self"

class Port (Operator):
  def __call__ (self, n, li):
    if li is None:
      raise RuntimeError("You can only use Port for link queries")
    return li[0][1]

  def __repr__ (self):
    return "Port"

class OtherPort (Operator):
  def __call__ (self, n, li):
    if li is None:
      raise RuntimeError("You can only use OtherPort for link queries")
    return li[1][1]

  def __repr__ (self):
    return "OtherPort"

class Other (Operator):
  def __call__ (self, n, li):
    if li is None:
      raise RuntimeError("You can only use Other for link queries")
    return li[1][0]

  def __repr__ (self):
    return "Other"

class Call (Operator):
  def __init__ (_self, *arg, **kw):
    _self._arg = []
    for v in arg:
      ao = None
      if isinstance(v, Operator):
        ao = v
      else:
        ao = Literal(v)
      _self._arg.append(ao)
    _self._kw = {}
    for k,v in kw.iteritems():
      ao = None
      if isinstance(v, Operator):
        ao = v
      else:
        ao = Literal(v)
      _self._kw[k].append(ao)

  def __call__ (self, n, li):
    arglist = []
    for arg in self._arg:
      arglist.append(arg(n,li))
    kws = {}
    for k,v in self._kw.iteritems():
      kws[k] = v(n)
    func = arglist.pop(0)
    return func(*arglist, **kws)

  def __repr__ (self):
    r = str(self._arg[0])
    args = [str(s) for s in self._arg[1:]]
    args.append(["%s=%s" % (k,str(v)) for k,v in self._kw])
    return "%s(%s)" % (self._arg[0], ', '.join(args))

class UnaryOp (Operator):
  def __init__ (self, operand):
    if isinstance(operand, Operator):
      self._operand = operand
    else:
      self._operand = Literal(operand)

  def __call__ (self, n, li):
    a = self._operand(n, li)
    return self._apply(a)

  def _apply (self, attr):
    raise RuntimeError("Unimplemented")

class BinaryOp (Operator):
  def __init__ (self, left, right):
    if isinstance(left, Operator):
      self._left = left
    else:
      self._left = Literal(left)
    if isinstance(right, Operator):
      self._right = right
    else:
      self._right = Literal(right)

  def __call__ (self, n, li):
    l = self._left(n, li)
    r = self._right(n, li)
    return self._apply(l, r)

  def _apply (self, l, r):
    raise RuntimeError("Unimplemented")

  def __repr__ (self):
    if hasattr(self, '_symbol'):
      return "%s %s %s" % (self._left, self._symbol, self._right)
    else:
      return "%s(%s, %s)" % (self.__class__.__name__, self._left, self._right)

class Or (BinaryOp):
  _symbol = "or"
  def _apply (self, l, r):
    return l or r

class And (BinaryOp):
  _symbol = "and"
  def _apply (self, l, r):
    return l and r

class LessThan (BinaryOp):
  _symbol = "<"
  def _apply (self, value):
    return value < self._value

class GreaterThan (BinaryOp):
  _symbol = ">"
  def _apply (self, l, r):
    return value > self._value

class LessThanEqualTo (BinaryOp):
  _symbol = "<="
  def _apply (self, l, r):
    return value <= self._value

class GreaterThanEqualTo (BinaryOp):
  _symbol = "=>"
  def _apply (self, l, r):
    return value > self._value

class Not (UnaryOp):
  def _apply (self, v):
    return not v

  def __repr__ (self):
    return "(Not %s)" % (self._operand,)

class Length (UnaryOp):
  def _apply (self, v):
    return len(v)

  def __repr__ (self):
    return "len(%s)" % (self._operand,)

class Index (BinaryOp):
  def _apply (self, l, r):
    return l[r]

  def __repr__ (self):
    return "%s[%s]" % (self._left, self._right)

_dummy = object()
class NodeOp (Operator):
  """
  Can be a binary operator, or if only one argument supplied, the
  left one defaults to the node.
  """
  def __init__ (self, left, right=_dummy):
    if right is _dummy:
      right = left
      left = Self()

    if isinstance(left, Operator):
      self._left = left
    else:
      self._left = Literal(left)
    if isinstance(right, Operator):
      self._right = right
    else:
      self._right = Literal(right)

  def __call__ (self, n, li):
    l = self._left(n, li)
    r = self._right(n, li)
    return self._apply(l, r)

  def _apply (self, l, r):
    raise RuntimeError("Unimplemented")

  def __repr__ (self):
    if hasattr(self, '_symbol'):
      return "%s %s %s" % (self._left, self._symbol, self._right)
    else:
      return "%s(%s, %s)" % (self.__class__.__name__, self._left, self._right)

class Equal (NodeOp):
  _symbol = "=="
  def _apply (self, l, r):
    #print "???", repr(l), repr(r), l == r
    return l == r

class Is (NodeOp):
  _symbol = "is"
  def _apply (self, l, r):
    return l is r

class Field (NodeOp):
  def __init__ (self, left, right=_dummy, optional=True):
    NodeOp.__init__(self, left, right)
    self._optional = optional

  def _apply (self, l, r):
    #print ">>",self._attr_name,hasattr(n, self._attr_name)
    do_call = r.endswith("()")
    if do_call: r = r[:-2]
    if not hasattr(l, r) and self._optional:
      raise LeaveException
    a = getattr(l, r)
    if do_call: a = a()
    #print ">>>",a
    return a
F = Field # Short alias

class IsInstance (NodeOp):
  def _apply (self, l, r):
    return isinstance(l, r)
  def __repr__ (self):
    return "isinstance(%s, %s)" % (self._left, self._right)

class IsType (NodeOp):
  def _apply (self, l, r):
    if isinstance(r, str):
      return type(l).__name__ == r
    return type(l) is r
  def __repr__ (self):
    return "type(%s) == %s" % (self._left, self._right)

class ConnectedTo (NodeOp):
  def _apply (self, l, r):
    return l.connected_to(r)
  def __repr__ (self):
    return "%s.connected_to(%s)" % (self._left, self._right)

class InValues (BinaryOp):
  def __init__ (self, left, right):
    super(Member, self).__init__(left, right)
    self._optional = optional

  def _apply (self, l, r):
    return l in r.values()

class In (BinaryOp):
  def _apply (self, l, r):
    return l in r

class Member (BinaryOp):
  _symbol = "."
  def __init__ (self, left, right, optional = True):
    super(Member, self).__init__(left, right)
    self._optional = optional

  def _apply (self, l, r):
    if not hasattr(l, r) and self._optional:
      raise LeaveException
    return getattr(l, r)


class Graph (object):
  def __init__ (self):
    self._g = nx.MultiGraph()
    self.node_port = {}

  def __contains__ (self, n):
    return n in self._g

  def add (self, node):
    self._g.add_node(node)
    self.node_port[node] = {}

  def remove (self, node):
    self._g.remove_node(node)

  def neighbors (self, n):
    return self._g.neighbors(n)

  def find_port (self, node1, node2):
    for n1, n2, k, d in self._g.edges([node1, node2], data=True, keys=True):
      return (d[LINK][node1][1], d[LINK][node2][1])
    return None

  def connected(self, node1, node2):
    return (self.find_port(node1, node2) != None)

  def disconnect_port (self, np):
    """
    Disconnects the given (node,port)
    """
    assert type(np) is tuple
    remove = []
    if self.port_for_node(np[0], np[1]) is None:
      return 0
    for n1,n2,k,d in self._g.edges([np[0], self.node_port[np[0]][np[1]][0]], data=True, keys=True):
      if np in d[LINK]:
        remove.append((n1,n2,k))
        del self.node_port[n1][d[LINK][n1][1]]
        del self.node_port[n2][d[LINK][n2][1]]
    for e in remove:
      #print "remove",e
      self._g.remove_edge(*e)
    return len(remove)

  def unlink (self, np1, np2):
    count = 0
    if isinstance(np1, tuple):
      count = disconnect_port(np1)
    elif isinstance(np2, tuple):
      count = disconnect_port(np2)
    else:
      for n1, n2, k, d in self._g.edges([np1, np2], data=True, keys=True):
        self._g.remove_edge(n1,n2,k)
        del self.node_port[n1][d[LINK][n1][1]]
        del self.node_port[n2][d[LINK][n2][1]]
        count = count + 1
    return count

  def link (self, np1, np2):
    """
    Links two nodes on given ports
    np1 is (node1, port1)
    np2 is (node2, port2)
    """
    #FIXME: the portless variation doesn't really make sense with
    #       allow_multiples yet.
    try:
      _ = np1[0]
    except:
      # portless (hacky)
      for free in xrange(1000):
        if free not in np1.ports:
          np1 = (np1,free)
          break
    try:
      _ = np2[0]
    except:
      # portless (hacky)
      for free in xrange(1000):
        if free not in np2.ports:
          np2 = (np2,free)
          break
    self._g.add_node(np1[0])
    self._g.add_node(np2[0])
    self.disconnect_port(np1)
    self.disconnect_port(np2)
    self._g.add_edge(np1[0],np2[0],link=Link(np1,np2))
    self.node_port[np1[0]][np1[1]] = np2
    self.node_port[np2[0]][np2[1]] = np1

  def find_links (self, query1=None, query2=()):
    # No idea if new link query stuff works.
    if query2 is None: query2 = query1
    if query1 == (): query1 = None
    if query2 == (): query2 = None
    o = set()
    for n1,n2,k,d in self._g.edges(data=True, keys=True):
      l = d[LINK]
      ok = False
      if query1 is None or self._test_node(l[0][0], args=(query1,), link=l):
        if query2 is None or self._test_node(l[1][0], args=(query2,), link=l):
          ok = True
      if not ok and (query1 != query2):
        if query2 is None or self._test_node(l[0][0], args=(query2,), link=l):
          if query1 is None or self._test_node(l[1][0], args=(query1,), link=l):
            ok = True
            l = l.flip()
      if ok:
        o.add(l)
    return list(o)

  def ports_for_node (self, node):
    """
    Map of local port -> (other, other_port)
    """
    ports = defaultdict(_void)
    for n1, n2, k, d in self._g.edges([node], data=True, keys=True):
      p = d[LINK]
      assert n1 is node
      assert ports.get(p[node]) is None
      ports[p[node][1]] = p.other(node)
    return ports

  def port_for_node(self, node, port):
    assert node in self.node_port
    return self.node_port[node].get(port)

  def disconnect_nodes(self, node1, node2):
    """ Disconnect node1 from node2. Either of node1 or node2
      can be a node, or a (node, port) pair
      Returns number of nodes disconnected
    """
    self.unlink(node1, node2)

  def disconnect_node(self, node1):
    """ Disconnecte node from all neighbours """
    for neighbor in self.neighbors(node1):
      self.disconnect_nodes(node1, neighbor)

  def get_one_link (self, query1=None, query2=(), **kw):
    return self.get_link(query1, query2, one=True, **kw)

  def get_link (self, query1=None, query2=(), **kw):
    """
    Keyword argument "default" lets you set a default value if
    no node is found.  Note that this means you must use
    Equal(F("default"), <value>) to actually check a field called
    "default" on a node.
    """
    if 'default' in kw:
      has_default = True
      default = kw['default']
      del kw['default']
    else:
      has_default = False
    one = False
    if 'one' in kw:
      one = kw['one']
      del kw['one']
    assert len(kw) == 0
    r = self.find_links(query1, query2)
    if len(r) > 1 and one:
      raise RuntimeError("More than one match")
    elif len(r) == 0:
      if has_default:
        return default
      raise RuntimeError("Could not get element")
    return r[0]

  def has_link (self, query1=None, query2=()):
    # Really bad implementation.  We can easily scape early.
    return len(self.find_links(query1, query2)) > 0

  def _test_node (self, n, args=(), kw={}, link=None):
    #TODO: Should use a special value for unspecified n2
    for k,v in kw.iteritems():
      if k == "is_a":
        if not isinstance(n,v): return False
      elif k == "type":
        if type(n) is not v: return False
      else:
        if not hasattr(n, k): return False
        if getattr(n, k) != v: return False
    for a in args:
      try:
        if not a(n, link):
          return False
      except LeaveException:
        return False
    return True

  def find (self, *args, **kw):
    r = []
    def test (n):
      return self._test_node(n, args, kw)
    for n in self._g.nodes():
      if test(n):
        r.append(n)
    return r

  def get_one (self, *args, **kw):
    kw['one'] = True
    return self.get(*args, **kw)

  def get (self, *args, **kw):
    """
    Keyword argument "default" lets you set a default value if
    no node is found.  Note that this means you must use
    Equal(F("default"), <value>) to actually check a field called
    "default" on a node.
    """
    if 'default' in kw:
      has_default = True
      default = kw['default']
      del kw['default']
    else:
      has_default = False
    one = False
    if 'one' in kw:
      del kw['one']
      one = True
    r = self.find(*args,**kw)
    if len(r) > 1 and one:
      raise RuntimeError("More than one match")
    elif len(r) == 0:
      if has_default:
        return default
      raise RuntimeError("Could not get element")
    return r[0]

  def has (self, *args, **kw):
    # Really bad implementation.  We can easily scape early.
    return len(self.find(*args,**kw)) > 0

  def __len__ (self):
    return len(self._g)

def test():
  class Node1 (object):
    _next_num = 0
    def __init__ (self):
      self._num = self.__class__._next_num
      self.__class__._next_num += 1

    def __repr__ (self):
      return "Node1 #" + str(self._num)

  class Node2 (object):
    _next_num = 0
    def __init__ (self):
      self._num = self.__class__._next_num
      self.__class__._next_num += 1

    def __repr__ (self):
      return "Node2 #" + str(self._num)

  class Node3 (Node1):
    _next_num = 0
    def __init__ (self):
      self._num = self.__class__._next_num
      self.__class__._next_num += 1

    def __repr__ (self):
      return "Node3 #" + str(self._num)
  g = Graph()
  n1 = Node1();n1.label=1
  n2 = Node2();n2.label=2
  n3 = Node3();n3.label=3

  g.add(n1)
  g.add(n2)
  g.add(n3)
  g.link((n1,0),(n2,0))
  g.link((n1,1),(n3,0))

  print g.find(is_a=Node1)
  print g.find(is_a=Node2)
  print g.find(type=Node1)
  print g.find(type=Node3)
  print g.find_links()
  print "=== NEIGHBORS ==="
  print g.neighbors(n1)
  print g.find_port(n1, n2)
  print g.connected(n1, n3)
  print g.ports_for_node(n3)

  print [(n, x[0], x[1][0], x[1][1]) for n in g.find(is_a=Node1) for x in g.ports_for_node(n).iteritems() ]

  g.disconnect_nodes(n1, n3)

  print g.find_links()
  g.link((n2, 1), (n3, 1))
  g.link((n1,1), (n3, 0))
  g.link((n1,0), (n2, 0))
  print g.find_links()
  g.disconnect_node(n3)
  print g.find_links()
  import code
  code.interact(local=locals())


if __name__ == "__main__":
  test()

########NEW FILE########
__FILENAME__ = minigraph
# Copyright 2012 James McCauley
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at:
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""
A minimal reimplementation of enough of NetworkX's MultiGraph so that
the NOM graph stuff should work.  This actually doesn't present an
ideal way to store the underlying graph, but it'll work for now.
"""

from collections import defaultdict as ddict


def _fix_nbunch (nbunch, cls = set):
  try:
    return cls(nbunch)
  except:
    return cls([nbunch])


class MultiGraph (object):
  def __init__ (self):
    self._next_key = 0

    self._edges = ddict(lambda:ddict(lambda:ddict(lambda:{})))
    # node -> node -> key -> {attr}

    self._nodes = {}
    # node -> {attr}

  def nodes (self, data = False):
    if not data:
      return self._nodes.keys()
    return self._nodes.items()

  def edges (self, nbunch = None, data = False, keys = False):
    def fix (a,b):
      if a>b: return (b,a)
      return (a,b)

    if nbunch is not None:
      nbunch = _fix_nbunch(nbunch)

    edges = {}

    for e1,otherEnd in self._edges.iteritems():
      for e2,rest in otherEnd.iteritems():
        if nbunch is not None:
          if e1 not in nbunch: continue
          if len(nbunch) > 1 and e2 not in nbunch: continue

        e = fix(e1,e2)
        if e in edges: continue

        edges[e] = rest

    r = []
    for nodes,edgelist in edges.iteritems():
      for k,d in edgelist.iteritems():
        if data and keys:
          r.append((nodes[0],nodes[1],k,d)) # Is the order right?
        elif data:
          r.append((nodes[0],nodes[1],d))
        elif keys:
          r.append((nodes[0],nodes[1],k))
        else:
          r.append(nodes)

    return r

  def neighbors (self, node):
    assert node in self._nodes
    return list(set(self._edges[node].keys()))

  def _gen_key (self):
    r = self._next_key
    self._next_key += 1
    return r

  def add_node (self, node, **attr):
    if node in self._nodes:
      self._nodes[node].update(attr)
    else:
      self._nodes[node] = attr

  def remove_node (self, node):
    others = self._edges[node].keys()
    del self._edges[node]
    for other in others:
      if other == node: continue
      del self._edges[other][node]
    del self._nodes[node]

  def add_edge (self, node1, node2, key=None, **attr):
    assert node1 is not node2
    self.add_node(node1)
    self.add_node(node2)
    if key is None: key = self._gen_key()
    e = self._edges[node1][node2][key]
    e.update(attr)
    self._edges[node2][node1][key] = e

  def add_edges_from (self, edges, **attr):
    for e in edges:
      if len(e) == 2:
        self.add_edge(*e)
      elif len(e) == 3:
        d = e[2].copy()
        d.update(attr)
        self.add_edge(e[0],e[1],**d)
      elif len(e) == 4:
        d = e[3].copy()
        d.update(attr)
        self.add_edge(e[0],e[1],key=e[3],**d)
      else:
        assert False

  def remove_edge (self, node1, node2, key=None):
    if key is None:
      key = self._edges[node1][node2].keys()[0] # First one is fine
    del self._edges[node1][node2][key]
    del self._edges[node2][node1][key]

  def add_path (self, nodes, **attr):
    for n in nodes:
      self.add_node(n, **attr)
    for n1,n2 in zip(nodes[:-1],nodes[1:]):
      self.add_edge(n1,n2)

  def __getitem__ (self, node):
    o = {}
    for k0,v0 in self._edges[node].iteritems():
      if k0 not in o: o[k0] = {}
      for k1,v1 in v0.iteritems():
        if k1 not in o[k0]: o[k0][k1] = {}
        o[k0][k1] = v1

    return o # This is self._edges but as a normal dict

########NEW FILE########
__FILENAME__ = nom
# Copyright 2012 James McCauley
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at:
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""
"""

from pox.lib.revent import *
from pox.core import core
from pox.lib.addresses import *
from pox.lib.graph.graph import *

class EntityEvent (Event):
  def __init__ (self, entity):
    Event.__init__(self)
    self.entity = entity

class EntityJoin (EntityEvent):
  """
  An entity has been added.

  Note that if there is a more specific join event defined for a particular
  entity, (e.g., SwitchJoin), this event will not be fired.

  TODO: or we could always raise EntityJoins along with SwitchJoins, which
  seems more intuitive to me.
  """
  pass

class EntityLeave (EntityEvent):
  """
  An entity has been removed

  Note that if there is a more specific leave event defined for a particular
  entity, (e.g., SwitchLeave), this event will not be fired.

  TODO: or we could always raise EntityLeaves along with SwitchLeaves, which
  seems more intuitive to me.
  """
  pass

class Update (Event):
  """
  Fired by Topology whenever anything has changed
  """
  def __init__ (self, event):
    Event.__init__(self)
    self.event = event

class Entity (Node):
  """
  Note that the Entity class is intentionally simple; It only serves as a
  convenient SuperClass type.

  It's up to subclasses to implement specific functionality (e.g.
  OpenFlow1.0 switch functionality).  The purpose of this design decision
  is to prevent protocol specific details from being leaked into this
  module... but this design decision does /not/ imply that pox.toplogy
  serves to define a generic interface to abstract entity types.
  """

class Host (Entity):
  """
  A generic Host entity.
  """
  def __init__(self):
    Entity.__init__(self)

class Switch (Entity):
  """
  Subclassed by protocol-specific switch classes,
  e.g. pox.openflow.topology.OpenFlowSwitch
  """

"""
class Port (Entity):
  def __init__ (self, num, hwAddr, name):
    Entity.__init__(self)
    self.number = num
    self.hwAddr = EthAddr(hwAddr)
    self.name = name
"""

class NOM (Graph, EventMixin):
  __eventMixin_events = [
    EntityJoin,
    EntityLeave,

    Update
  ]

  def __init__ (self):
    Graph.__init__(self)
    EventMixin.__init__(self)
    self._eventMixin_addEvents(self.__eventMixin_events)
    self._entities = {}
    self.log = core.getLogger(self.__class__.__name__)

  def getEntityByID (self, ID, fail=False):
    """
    Raises an exception if fail is True and the entity doesn't exist
    See also: The 'entity' property.
    """
    r = self.find(Or(Equal('DPID', ID),Equal(F('ID'), ID)))
    if len(r) == 0:
      if fail:
        raise RuntimeError("No entity with ID " + str(ID))
      else:
        return None
    assert len(r) == 1
    return r[0]

  def removeEntity (self, entity):
    if entity in self:
      self.remove(entity)
      self.log.info(str(entity) + " left")
      self.raiseEvent(EntityLeave, entity)

  def addEntity (self, entity):
    """ Will raise an exception if entity.id already exists """
    if entity in self:
      raise RuntimeError("Entity exists")
    self.add(entity)
    self.log.info(str(entity) + " joined")
    self.raiseEvent(EntityJoin, entity)

  def getEntitiesOfType (self, t=Entity, subtypes=True):
    if subtypes is False:
      return self.find(is_a=t)
    else:
      return self.find(type=t)

  def raiseEvent (self, event, *args, **kw):
    """
    Whenever we raise any event, we also raise an Update, so we extend
    the implementation in EventMixin.
    """
    rv = EventMixin.raiseEvent(self, event, *args, **kw)
    if type(event) is not Update:
      EventMixin.raiseEvent(self, Update(event))
    return rv

  def __str__(self):
    return "<%s len:%i>" % (self.__class__.__name__, len(self))

########NEW FILE########
__FILENAME__ = notify_demo
# Copyright 2013 James McCauley
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at:
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""
A demo of working with IOWorker clients and servers

Run the server as:
 lib.ioworker.notify_demo:server

Clients can be run in several ways...

To just listen for notifications and show them as log messages:
 lib.ioworker.notify_demo:client --server=127.0.0.1 --name=SirSpam

To send a notification and quit, append --msg="Spam eggs spam".

Run with the Python interpreter (the 'py' component), and you get a
notify("<message>") command:
 POX> notify("Grilled tomatoes")

Run with Tk (the 'tk' component) to get a GUI.
"""

from pox.lib.ioworker import *
from pox.lib.ioworker.workers import *
from pox.core import core

log = core.getLogger()


# ---------------------------------------------------------------------------
# Client Stuff
# ---------------------------------------------------------------------------

client_worker = None
username = None
single_message = None

def notify (msg):
  if msg is None: return
  if client_worker is None:
    log.error("Can't send notification -- not connected")
  msg = msg.split("\n")
  for m in msg:
    client_worker.send("N %s %s\n" % (username, m))

class ClientWorker (PersistentIOWorker):
  def __init__ (self, *args, **kw):
    self.data = b''
    super(ClientWorker,self).__init__(*args,**kw)

  def _handle_close (self):
    global client_worker
    if client_worker is self:
      client_worker = None
      log.info("Disconnect")
    super(ClientWorker, self)._handle_close()
    if single_message:
      core.quit()

  def _handle_connect (self):
    global client_worker
    if client_worker is not None:
      client_worker.close()
    log.info("Connect")
    super(ClientWorker, self)._handle_connect()
    client_worker = self
    if single_message:
      notify(single_message)
      self.shutdown()

  def _handle_rx (self):
    self.data += self.read()
    while '\n' in self.data:
      msg,self.data = self.data.split('\n',1)
      if msg.startswith("N "):
        _,name,content = msg.split(None,2)
        log.warn("** %s: %s **", name, content)
        if core.hasComponent('tk'):
          # If Tk is running, pop up the message.
          core.tk.dialog.showinfo("Message from " + name, content)


def setup_input ():
  def cb (msg):
    if msg is None: core.quit()
    setup_input() # Pop box back up
    notify(msg)
  if not core.running: return
  core.tk.dialog.askstring_cb(cb, "Notification",
      "What notification would you like to send?")


def client (server, name = "Unknown", port = 8111, msg = None):

  global loop, username, single_message
  username = str(name).replace(" ", "_")
  single_message = msg

  core.Interactive.variables['notify'] = notify

  loop = RecocoIOLoop()
  #loop.more_debugging = True
  loop.start()

  w = ClientWorker(loop=loop, addr=server, port=int(port))

  if not msg:
    # If we have Tk running, pop up an entry box
    core.call_when_ready(setup_input, ['tk'])


# ---------------------------------------------------------------------------
# Server Stuff
# ---------------------------------------------------------------------------

class ServerWorker (TCPServerWorker, RecocoIOWorker):
  pass

clients = set()

class NotifyWorker (RecocoIOWorker):
  def __init__ (self, *args, **kw):
    super(NotifyWorker, self).__init__(*args, **kw)
    self._connecting = True
    self.data = b''

  def _handle_close (self):
    log.info("Client disconnect")
    super(NotifyWorker, self)._handle_close()
    clients.discard(self)

  def _handle_connect (self):
    log.info("Client connect")
    super(NotifyWorker, self)._handle_connect()
    clients.add(self)

  def _handle_rx (self):
    self.data += self.read()
    while '\n' in self.data:
      msg,self.data = self.data.split('\n',1)
      if msg.startswith("N "):
        _,name,content = msg.split(None,2)
        log.warn("** %s: %s **", name, content)
        for c in clients:
          if c is not self:
            c.send(msg + "\n")


def server (port = 8111):
  global loop
  loop = RecocoIOLoop()
  #loop.more_debugging = True
  loop.start()

  w = ServerWorker(child_worker_type=NotifyWorker, port = int(port))
  loop.register_worker(w)

########NEW FILE########
__FILENAME__ = workers
# Copyright 2012-2013 James McCauley
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at:
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""
A collection of some useful IOWorkers

These were quickly adapted from another project.  The versions of the
server ones here haven't been tested.  The persistent ones at least
sort of have.  The backoff one is new.
"""

import errno
import socket
from pox.lib.addresses import IP_ANY, IPAddr
from pox.lib.ioworker import *
from pox.core import core

log = core.getLogger()


class LoggerBase (object):
  def _error (self, *args, **kw):
    log.error(type(self).__name__ + ": " + str(args[0]), *args[1:], **kw)
  def _warn (self, *args, **kw):
    log.warn(type(self).__name__ + ": " + str(args[0]), *args[1:], **kw)
  def _info (self, *args, **kw):
    log.info(type(self).__name__ + ": " + str(args[0]), *args[1:], **kw)
  def _debug (self, *args, **kw):
    log.debug(type(self).__name__ + ": " + str(args[0]), *args[1:], **kw)


class TCPServerWorkerBase (IOWorker, LoggerBase):
  def __init__ (self, ip = IP_ANY, port = None,
        backlog = 5, *args, **kw):
    """
    Listens on ip/port and fires _do_accept when there's a connection
    """
    #super(TCPServerWorkerBase,self).__init__(*args, **kw)
    IOWorker.__init__(self)

    s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
    self.socket = s
    s.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
    #s.setblocking(0)
    if port is None: port = 0
    s.bind((str(IPAddr(ip)), port))
    s.listen(backlog)

  @property
  def local_ip (self):
    return IPAddr(s.getsockname()[0])
  @property
  def local_port (self):
    return s.getsockname()[1]

  def _do_accept (self, loop, socket):
    """
    Override me
    """
    pass

  def _do_recv (self, loop):
    s,addr = self.socket.accept()
    s.setblocking(0)

    self._do_accept(loop, s)

  def _handle_close (self):
    # Just here to kill log message
    pass


class TCPServerWorker (TCPServerWorkerBase):
  def __init__ (self, child_worker_type, ip = IP_ANY, port = None,
      child_args = {}, *args, **kw):
    """
    Listens on ip/port and creates a child_worker_type for each connnection
    """
    super(TCPServerWorker,self).__init__(ip=ip,port=port,*args, **kw)

    self.child_worker_type = child_worker_type
    self.child_args = child_args

  def _do_accept (self, loop, socket):
    addr = socket.getpeername()
    self._debug("accepting %s:%i" % addr)
    out = loop.new_worker(socket = socket,
        _worker_type = self.child_worker_type,
        **self.child_args)
    return out


class RecocoServerWorker (TCPServerWorker, RecocoIOWorker):
  """
  Recoco TCP server worker
  """
  pass


class PersistentIOWorker (RecocoIOWorker, LoggerBase):
  """
  An IOWorker which opens a duplicate of itself when it closes

  Subclasses can add keyword parameters for constructor
  """

  _default_retry_delay = 2

  def __repr__ (self):
    return object.__repr__(self)

  def __init__ (self, **kw):
    """
    Initialize

    See _make_connection for arg list.

    callbacks take a single arg -- the worker in question
    If the disconnect callback returns False, a new connection will NOT
    be opened.
    """
    #IOWorker.__init__(self)

    # We pass None in as the socket, because we set it up in a moment in
    # _make_connection().  This probably means that it shouldn't be
    # a required argument for RecocoIOWorker...
    super(PersistentIOWorker,self).__init__(None)

    self.kw = kw

    self._connecting = True

    self._make_connection(**kw)

  def _make_connection (self, loop, addr, port,
      reconnect_delay = _default_retry_delay,
      connect_callback = None, disconnect_callback = None, **kw):

    self.loop = loop
    self.addr = addr #IPAddr(addr)
    self.port = port
    self.reconnect_delay = reconnect_delay
    self.connect_callback = connect_callback
    self.disconnect_callback = disconnect_callback

    s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
    self.socket = s
    s.setblocking(0)
    self._debug("Attempting to connect to %s:%s", self.addr, self.port)
    r = s.connect_ex((str(self.addr), self.port))
    if r in (0, errno.EINPROGRESS, errno.EAGAIN, 10035): # 10035=WSAEWOULDBLOCK
      # We either connected or connection is in progress
      pass
    else:
      #self._error("Couldn't connect to %s:%s", self.addr, self.port)
      #raise RuntimeError("Couldn't connect")
      core.callLater(self._handle_close)
      return
    
    self.loop.register_worker(self)

  @classmethod
  def begin (cls, **kw):
    #if len(args) >= 4:
    #  reconnect_delay = args[3]
    #else:
    reconnect_delay = kw.get('reconnect_delay',
        cls._default_retry_delay)

    try:
      w = cls(**kw)
      return w
    except:
      raise
      core.callDelayed(reconnect_delay, cls.begin, **kw)
      return None

  def open_later (self):
    core.callDelayed(self.reconnect_delay, self.begin, **self.kw)

  def _handle_close (self):
    self._debug("Disconnected")
    super(PersistentIOWorker, self)._handle_close()
    if self.disconnect_callback:
      if self.disconnect_callback(self) is False:
        return
    self.open_later()

  def _handle_connect (self):
    super(PersistentIOWorker, self)._handle_connect()
    if self.connect_callback:
      self.connect_callback(self)


class BackoffWorker (PersistentIOWorker):
  def __init__ (self, **kw):
    kw.setdefault('reconnect_delay', 0.5)
    self.max_retry_delay = kw.get('max_retry_delay',16)
    super(BackoffWorker,self).__init__(**kw)

  def _handle_connect (self):
    self.reconnect_delay = 0.5
    super(BackoffWorker, self)._handle_connect()

  def open_later (self):
    self.reconnect_delay *= 2
    self.reconnect_delay = int(self.reconnect_delay)
    if self.reconnect_delay > self.max_retry_delay:
      self.reconnect_delay = self.max_retry_delay
    self.kw['reconnect_delay'] = self.reconnect_delay
    self._debug("Try again in %s seconds", self.reconnect_delay)
    from pox.core import core
    core.callDelayed(self.reconnect_delay, self.begin, **self.kw)

########NEW FILE########
__FILENAME__ = mock_socket
# Copyright 2012 Andreas Wundsam
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at:
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""
This module provides a MockSocket that can be used to fake TCP
connections inside of the simulator
"""

class MockSocket (object):
  """
  A mock socket that works on a sending and a receiving message channel.
  Use MockSocket.pair() to get a pair of connected MockSockets

  TODO: model failure modes
  """
  def __init__(self, receiving, sending):
    self.receiving = receiving
    self.sending = sending

  def send (self, data):
    """
    Send data out on this socket.

    Data will be available for reading at the receiving socket pair.
    Note that this currently always succeeds and never blocks (unlimited
    receive buffer size)
    """
    return self.sending.send(data)

  def recv (self, max_size=None):
    """
    receive data on this sockect.

    If no data is available to be received, return "".
    Note that this is non-standard socket behavior and should be
    changed to mimic either blocking on non-blocking socket semantics
    """
    return self.receiving.recv(max_size)

  def set_on_ready_to_recv (self, on_ready):
    """
    set a handler function on_ready(socket, size) to be called when
    data is available for reading at this socket
    """
    self.receiving.on_data = lambda channel, size: on_ready(self, size)

  def ready_to_recv (self):
    return not self.receiving.is_empty()

  def ready_to_send (self):
    return self.sending.is_full()

  def shutdown (self, sig=None):
    """
    shutdown a socket.
    Currently a no-op on this MockSocket object.
    """
    pass
    #TODO: implement more realistic closing semantics

  def close (self):
    """
    close a socket. Currently a no-op on this MockSocket object.
    """
    pass
    #TODO: implement more realistic closing semantics

  def fileno (self):
    """
    return the pseudo-fileno of this Mock Socket.
    Currently always returns -1.
    """
    return -1
    #TODO: assign unique pseudo-filenos to mock sockets,
    #      so apps don't get confused.

  @classmethod
  def pair (cls):
    """ Return a pair of connected sockets """
    a_to_b = MessageChannel()
    b_to_a = MessageChannel()
    a = cls(a_to_b, b_to_a)
    b = cls(b_to_a, a_to_b)
    return (a,b)

class MessageChannel (object):
  """
  A undirectional reliable in order byte stream message channel
  (think TCP half-connection)
  """
  def __init__ (self):
    # Single element queue
    self.buffer = ""
    self.on_data = None
    self.on_data_running = False
    self.pending_on_datas = 0

  def send (self, msg):
    self.buffer += msg
    self._trigger_on_data()
    return len(msg)

  def _trigger_on_data (self):
    self.pending_on_datas += 1
    if self.on_data_running:
      # avoid recursive calls to on_data
      return

    while self.pending_on_datas > 0 and len(self.buffer) > 0:
      self.pending_on_datas -= 1
      if self.on_data:
        self.on_data_running = True
        self.on_data(self, len(self.buffer))
        self.on_data_running = False
      else:
        break

  def recv (self, max_size=None):
    """
    retrieve and return the data stored in this channel's buffer.
    If buffer is empty, return ""
    """
    if max_size and max_size < len(self.buffer):
      msg = self.buffer[0:max_size]
      self.buffer = self.buffer[max_size:]
    else:
      msg = self.buffer
      self.buffer = ""
    return msg

  def is_empty (self):
    return len(self.buffer) == 0

  def is_full (self):
    #  buffer length not constrained currently
    return False

  def __len__ (self):
    return len(self.buffer)

########NEW FILE########
__FILENAME__ = arp
# Copyright 2011 James McCauley
# Copyright 2008 (C) Nicira, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at:
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# This file is derived from the packet library in NOX, which was
# developed by Nicira, Inc.

#=====================================================================
#
#    0                   1                   2                   3
#    0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1
#   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
#   |          Hardware type        |             Protocol type     |
#   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
#   |                  Source hardware address :::                  |
#   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
#   |                  Source protocol address :::                  |
#   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
#   |               Destination hardware address :::                |
#   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
#   |               Destination protocol address :::                |
#   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
#   |                           Data :::                            |
#   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
#
#=====================================================================
import struct

from packet_base import packet_base
from ipv4 import ipv4

from ethernet import ethernet
from ethernet import ETHER_ANY
from ethernet import ETHER_BROADCAST

from ipv4 import IP_ANY
from ipv4 import IP_BROADCAST

from pox.lib.addresses import IPAddr, EthAddr

from packet_utils       import *

class arp (packet_base):
    "ARP/RARP packet struct"

    MIN_LEN = 28

    HW_TYPE_ETHERNET = 1
    PROTO_TYPE_IP    = 0x0800

    # OPCODES
    REQUEST     = 1 # ARP
    REPLY       = 2 # ARP
    REV_REQUEST = 3 # RARP
    REV_REPLY   = 4 # RARP

    def __init__(self, raw=None, prev=None, **kw):
        packet_base.__init__(self)

        self.prev = prev

        self.hwtype     = arp.HW_TYPE_ETHERNET
        self.prototype  = arp.PROTO_TYPE_IP
        self.hwsrc      = ETHER_ANY
        self.hwdst      = ETHER_ANY
        self.hwlen      = 6
        self.opcode     = 0
        self.protolen   = 4
        self.protosrc   = IP_ANY
        self.protodst   = IP_ANY
        self.next       = b''

        if raw is not None:
            self.parse(raw)

        self._init(kw)

    def parse (self, raw):
        assert isinstance(raw, bytes)
        self.next = None # In case of unfinished parsing
        self.raw = raw
        dlen = len(raw)
        if dlen < arp.MIN_LEN:
            self.msg('(arp parse) warning IP packet data too short to parse header: data len %u' % dlen)
            return

        (self.hwtype, self.prototype, self.hwlen, self.protolen,self.opcode) =\
        struct.unpack('!HHBBH', raw[:8])

        if self.hwtype != arp.HW_TYPE_ETHERNET:
            self.msg('(arp parse) hw type unknown %u' % self.hwtype)
            return
        if self.hwlen != 6:
            self.msg('(arp parse) unknown hw len %u' % self.hwlen)
            return
        else:
            self.hwsrc = EthAddr(raw[8:14])
            self.hwdst = EthAddr(raw[18:24])
        if self.prototype != arp.PROTO_TYPE_IP:
            self.msg('(arp parse) proto type unknown %u' % self.prototype)
            return
        if self.protolen != 4:
            self.msg('(arp parse) unknown proto len %u' % self.protolen)
            return
        else:
            self.protosrc = IPAddr(struct.unpack('!I',raw[14:18])[0])
            self.protodst = IPAddr(struct.unpack('!I',raw[24:28])[0])

        self.next = raw[28:]
        self.parsed = True

    def hdr(self, payload):
        buf = struct.pack('!HHBBH', self.hwtype, self.prototype,
            self.hwlen, self.protolen,self.opcode)
        if type(self.hwsrc) == bytes:
            buf += self.hwsrc
        else:
            buf += self.hwsrc.toRaw()
        if type(self.protosrc) is IPAddr:
          buf += struct.pack('!I',self.protosrc.toUnsigned())
        else:
          buf += struct.pack('!I',self.protosrc)
        if type(self.hwdst) == bytes:
            buf += self.hwdst
        else:
            buf += self.hwdst.toRaw()
        if type(self.protodst) is IPAddr:
          buf += struct.pack('!I',self.protodst.toUnsigned())
        else:
          buf += struct.pack('!I',self.protodst)
        return buf

    def _to_str(self):
        op = str(self.opcode)

        eth_type = None
        # Ethernet
        if hasattr(self.prev, 'type'):
            eth_type = self.prev.type
        # Vlan
        elif hasattr(self.prev, 'eth_type'):
            eth_type = self.prev.eth_type
        else:
            self.err('(arp) unknown datalink type')
            eth_type = ethernet.ARP_TYPE

        if eth_type == ethernet.ARP_TYPE:
            if self.opcode == arp.REQUEST:
                op = "REQUEST"
            elif self.opcode == arp.REPLY:
                op = "REPLY"
        elif eth_type == ethernet.RARP_TYPE:
            if self.opcode == arp.REV_REQUEST:
                op = "REV_REQUEST"
            elif self.opcode == arp.REV_REPLY:
                op = "REV_REPLY"

        s = "[ARP {0} hw:{1} p:{2} {3}>{4} {5}>{6}]".format(op,
                                                  self.hwtype,
                                                  self.prototype,
                                                  EthAddr(self.hwsrc),
                                                  EthAddr(self.hwdst),
                                                  IPAddr(self.protosrc),
                                                  IPAddr(self.protodst))
        return s

########NEW FILE########
__FILENAME__ = dhcp
# Copyright 2011,2013 James McCauley
# Copyright 2008 (C) Nicira, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at:
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# This file is derived from the packet library in NOX, which was
# developed by Nicira, Inc.

#======================================================================
#
#                     DHCP Message Format
#
#  0                   1                   2                   3
#   0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1
#   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
#   |     op (1)    |   htype (1)   |   hlen (1)    |   hops (1)    |
#   +---------------+---------------+---------------+---------------+
#   |                            xid (4)                            |
#   +-------------------------------+-------------------------------+
#   |           secs (2)            |           flags (2)           |
#   +-------------------------------+-------------------------------+
#   |                          ciaddr  (4)                          |
#   +---------------------------------------------------------------+
#   |                          yiaddr  (4)                          |
#   +---------------------------------------------------------------+
#   |                          siaddr  (4)                          |
#   +---------------------------------------------------------------+
#   |                          giaddr  (4)                          |
#   +---------------------------------------------------------------+
#   |                                                               |
#   |                          chaddr  (16)                         |
#   |                                                               |
#   |                                                               |
#   +---------------------------------------------------------------+
#   |                                                               |
#   |                          sname   (64)                         |
#   +---------------------------------------------------------------+
#   |                                                               |
#   |                          file    (128)                        |
#   +---------------------------------------------------------------+
#   |                                                               |
#   |                          options (variable)                   |
#   +---------------------------------------------------------------+
#
#======================================================================
import struct
import string
from packet_utils import *

from packet_base import packet_base
import pox.lib.util as util
from pox.lib.util import is_subclass
from pox.lib.addresses import *

_dhcp_option_unpackers = {}


class dhcp(packet_base):
    "DHCP Packet struct"

    STRUCT_BOUNDARY = 28
    MIN_LEN = 240

    SERVER_PORT = 67
    CLIENT_PORT = 68

    BROADCAST_FLAG = 0x8000

    BOOTREQUEST = 1
    BOOTREPLY = 2

    MSG_TYPE_OPT = 53
    NUM_MSG_TYPES = 8
    DISCOVER_MSG = 1
    OFFER_MSG = 2
    REQUEST_MSG = 3
    DECLINE_MSG = 4
    ACK_MSG = 5
    NAK_MSG = 6
    RELEASE_MSG = 7
    INFORM_MSG = 8

    SUBNET_MASK_OPT = 1
    GATEWAY_OPT = 3
    ROUTERS_OPT = 3 # Synonym for above
    TIME_SERVERS_OPT = 4
    DNS_SERVER_OPT = 6
    HOST_NAME_OPT = 12
    DOMAIN_NAME_OPT = 15
    MTU_OPT = 26
    BCAST_ADDR_OPT = 28

    VENDOR_OPT = 43

    REQUEST_IP_OPT = 50
    REQUEST_LEASE_OPT = 51
    OVERLOAD_OPT = 52
    SERVER_ID_OPT = 54
    PARAM_REQ_OPT = 55
    ERROR_MSG_OPT = 56
    T1_OPT = 58
    T2_OPT = 59
    CLIENT_ID_OPT = 61
    PAD_OPT = 0
    END_OPT = 255

    MAGIC = b'\x63\x82\x53\x63'

    def __init__(self, raw=None, prev=None, **kw):
        packet_base.__init__(self)

        self.prev = prev

        self.op = 0
        self.htype = 0
        self.hlen = 0
        self.hops = 0
        self.xid = 0
        self.secs = 0
        self.flags = 0
        self.ciaddr = IP_ANY
        self.yiaddr = IP_ANY
        self.siaddr = IP_ANY
        self.giaddr = IP_ANY
        self.chaddr = None
        self.sname = b''
        self.file = b''
        self.magic = self.MAGIC
        self._raw_options = b''

        if raw is not None:
            self.parse(raw)
        else:
            self.options = util.DirtyDict()

        self._init(kw)

    def _to_str(self):
        s  = '[DHCP op:'+str(self.op)
        s += ' htype:'+str(self.htype)
        s += ' hlen:'+str(self.hlen)
        s += ' hops:'+str(self.hops)
        s += ' xid:'+str(self.xid)
        s += ' secs:'+str(self.secs)
        s += ' flags:'+str(self.flags)
        s += ' ciaddr:'+str(self.ciaddr)
        s += ' yiaddr:'+str(self.yiaddr)
        s += ' siaddr:'+str(self.siaddr)
        s += ' giaddr:'+str(self.giaddr)
        s += ' chaddr:'
        if isinstance(self.chaddr, EthAddr):
            s += str(self.chaddr)
        elif self.chaddr is not None:
            s += ' '.join(["{0:02x}".format(x) for x in self.chaddr])
        s += ' magic:'+' '.join(
            ["{0:02x}".format(ord(x)) for x in self.magic])
        #s += ' options:'+' '.join(["{0:02x}".format(ord(x)) for x in
        #                          self._raw_options])
        if len(self.options):
          s += ' options:'
          s += ','.join(repr(x) for x in self.options.values())
        s += ']'
        return s

    def parse(self, raw):
        assert isinstance(raw, bytes)
        self.raw = raw
        dlen = len(raw)
        if dlen < dhcp.MIN_LEN:
            self.msg('(dhcp parse) warning DHCP packet data too short ' +
                     'to parse header: data len %u' % (dlen,))
            return None

        (self.op, self.htype, self.hlen, self.hops, self.xid,self.secs,
         self.flags, self.ciaddr, self.yiaddr, self.siaddr,
         self.giaddr) = struct.unpack('!BBBBIHHIIII', raw[:28])

        self.ciaddr = IPAddr(self.ciaddr)
        self.yiaddr = IPAddr(self.yiaddr)
        self.siaddr = IPAddr(self.siaddr)
        self.giaddr = IPAddr(self.giaddr)

        self.chaddr = raw[28:44]
        if self.hlen == 6:
            # Assume chaddr is ethernet
            self.chaddr = EthAddr(self.chaddr[:6])
        self.sname = raw[44:108]
        self.file = raw[102:236]
        self.magic = raw[236:240]

        self.hdr_len = dlen
        self.parsed = True

        if self.hlen > 16:
            self.warn('(dhcp parse) DHCP hlen %u too long' % (self.hlen),)
            return

        for i in range(4):
            if dhcp.MAGIC[i] != self.magic[i]:
                self.warn('(dhcp parse) bad DHCP magic value %s' %
                          str(self.magic))
                return

        self._raw_options = raw[240:]
        self.parseOptions()
        self.unpackOptions()
        self.parsed = True

    def unpackOptions(self):
      for k,v in self.options.items():
        unpack = _dhcp_option_unpackers.get(k, DHCPRawOption.unpack)
        try:
          self.options[k] = unpack(v,k)
        except Exception as e:
          self.warn("(dhcp parse) bad option %s: %s" % (k,e))
          #import traceback
          #traceback.print_exc()
          self.options[k] = DHCPRawOption.unpack(v,k,True)

    def parseOptions(self):
        self.options = util.DirtyDict()
        self.parseOptionSegment(self._raw_options)
        if dhcp.OVERLOAD_OPT in self.options:
            opt_val = self.options[dhcp.OVERLOAD_OPT]
            if len(opt_val) != 1:
                self.warn('DHCP overload option has bad len %u' %
                          (len(opt_val),))
                return
            if opt_val == 1 or opt_val == 3:
                self.parseOptionSegment(self.file)
            if opt_val == 2 or opt_val == 3:
                self.parseOptionSegment(self.sname)

    def parseOptionSegment(self, barr):
        ofs = 0;
        l = len(barr)
        while ofs < l:
            opt = ord(barr[ofs])
            if opt == dhcp.END_OPT:
                return
            ofs += 1
            if opt == dhcp.PAD_OPT:
                continue
            if ofs >= l:
                self.warn('DHCP option ofs extends past segment')
                return
            opt_len = ord(barr[ofs])
            ofs += 1         # Account for the length octet
            if ofs + opt_len > l:
                return False
            if opt in self.options:
                # Append option, per RFC 3396
                self.options[opt] += barr[ofs:ofs+opt_len]
            else:
                self.options[opt] = barr[ofs:ofs+opt_len]
            ofs += opt_len
        self.warn('DHCP end of option segment before END option')

    def packOptions (self):
        o = b''
        def addPart (k, v):
            o = b''
            o += chr(k)
            o += chr(len(v))
            o += bytes(v)
            if len(o) & 1: # Length is not even
                o += chr(dhcp.PAD_OPT)
            return o

        for k,v in self.options.iteritems():
            if k == dhcp.END_OPT: continue
            if k == dhcp.PAD_OPT: continue
            if isinstance(v, DHCPOption):
                v = v.pack()
            if isinstance(v, bytes) and (len(v) > 255):
                # Long option, per RFC 3396
                v = [v[i:i+255] for i in range(0, len(v), 255)]
            if isinstance(v, list): # Better way to tell?
                for part in v:
                    o += addPart(k, part)
            else:
                o += addPart(k, v)
        o += chr(dhcp.END_OPT)
        self._raw_options = o

        if isinstance(self.options, util.DirtyDict):
            self.options.dirty = False

    def add_option(self, option, code=None):
      if code is None:
        code = option.CODE
      self.options[code] = option

    def hdr(self, payload):
        if isinstance(self.options, util.DirtyDict):
            if self.options.dirty:
                self.packOptions()
        else:
            self.packOptions()

        if isinstance(self.chaddr, EthAddr):
          chaddr = self.chaddr.toRaw() + (b'\x00' * 10)
        fmt = '!BBBBIHHiiii16s64s128s4s'
        return struct.pack(fmt, self.op, self.htype, self.hlen,
                           self.hops, self.xid, self.secs, self.flags,
                           IPAddr(self.ciaddr).toSigned(),
                           IPAddr(self.yiaddr).toSigned(),
                           IPAddr(self.siaddr).toSigned(),
                           IPAddr(self.giaddr).toSigned(),
                           chaddr, self.sname, self.file,
                           self.magic) + self._raw_options

    def appendRawOption (self, code, val = None, length = None):
        """
        In general, a much better way to add options should just be
        to add them to the .options dictionary.
        """

        self._raw_options += chr(code)
        if length is None:
            if val is None:
                return
            length = len(val)
        self._raw_options += chr(length)
        self._raw_options += val


def dhcp_option_def (msg_type):
  """
  DPCP Option decorator
  """
  def f (cls):
    _dhcp_option_unpackers[msg_type] = cls.unpack
    cls.CODE = msg_type
    return cls
  return f

class DHCPOption (object):
  CODE = None

  @classmethod
  def unpack (cls, data, code = None):
    pass

  def pack (self):
    return b''

  @property
  def _name (self):
    n = type(self).__name__
    if n.startswith("DHCP"): n = n[4:]
    if n.endswith("Option"): n = n[:-6]
    if n == "": return "Option"
    return n

class DHCPRawOption (DHCPOption):
  def __init__ (self, data = b'', bad = False):
    self.data = data
    self.bad = bad # True if option wasn't parsed right

  @classmethod
  def unpack (cls, data, code = None, bad = False):
    self = cls()
    self.data = data
    self.bad = bad
    self.CODE = code
    return self

  def pack (self):
    return self.data

  def __repr__ (self):
    data = self.data
    if not all(ord(c)<127 and c in string.printable for c in data):
      data = " ".join("%02x" % (ord(x),) for x in data)
    else:
      data = "".join(x if ord(x) >= 32 else "." for x in data)
    if len(data) > 30:
      data = data[:30] + "..."
    n = self._name
    if n == 'Raw': n += str(self.CODE)
    return "%s(%s)" % (n, data)

class DHCPIPOptionBase (DHCPOption):
  """
  Superclass for options which are an IP address
  """
  def __init__ (self, addr = None):
    self.addr = IPAddr(0) if addr is None else IPAddr(addr)

  @classmethod
  def unpack (cls, data, code = None):
    self = cls()
    if len(data) != 4: raise RuntimeError("Bad option length")
    self.addr = IPAddr(data)
    return self

  def pack (self):
    return self.addr.toRaw()

  def __repr__ (self):
    return "%s(%s)" % (self._name, self.addr)

class DHCPIPsOptionBase (DHCPOption):
  """
  Superclass for options which are a list of IP addresses
  """
  def __init__ (self, addrs=[]):
    if isinstance(addrs, (basestring,IPAddr)):
      self.addrs = [IPAddr(addrs)]
    else:
      self.addrs = [IPAddr(a) for a in addrs]

  @classmethod
  def unpack (cls, data, code = None):
    self = cls()
    if (len(data) % 4) != 0: raise RuntimeError("Bad option length")
    while len(data):
      self.addrs.append(IPAddr(data[:4]))
      data = data[4:]
    return self

  def pack (self):
    r = b''
    for addr in self.addrs:
      r += addr.toRaw()
    return r

  @property
  def addr (self):
    if len(self.addrs) == 0: return None
    return self.addrs[0]

  def __repr__ (self):
    return "%s(%s)" % (self._name, self.addrs)

class DHCPSecondsOptionBase (DHCPOption):
  """
  Superclass for options which are a number of seconds as 4 bytes
  """
  def __init__ (self, seconds = None):
    self.seconds = seconds

  @classmethod
  def unpack (cls, data, code = None):
    self = cls()
    if len(data) != 4: raise RuntimeError("Bad option length")
    self.seconds, = struct.unpack('!I', data)
    return self

  def pack (self):
    return struct.pack('!I', self.seconds)

  def __repr__ (self):
    return "%s(%s)" % (self._name, self.seconds)

@dhcp_option_def(dhcp.MSG_TYPE_OPT)
class DHCPMsgTypeOption (DHCPOption):
  def __init__ (self, type=None):
    self.type = type

  @classmethod
  def unpack (cls, data, code = None):
    self = cls()
    if len(data) != 1: raise RuntimeError("Bad option length")
    self.type = ord(data[0])
    return self

  def pack (self):
    return chr(self.type)

  def __repr__ (self):
    t = {
        1:'DISCOVER',
        2:'OFFER',
        3:'REQUEST',
        4:'DECLINE',
        5:'ACK',
        6:'NAK',
        7:'RELEASE',
        8:'INFORM',
    }.get(self.type, "TYPE"+str(self.type))
    return "%s(%s)" % (self._name, t)

@dhcp_option_def(dhcp.SUBNET_MASK_OPT)
class DHCPSubnetMaskOption (DHCPIPOptionBase):
  pass

@dhcp_option_def(dhcp.ROUTERS_OPT)
class DHCPRoutersOption (DHCPIPsOptionBase):
  pass

@dhcp_option_def(dhcp.TIME_SERVERS_OPT)
class DHCPTimeServersOption (DHCPIPsOptionBase):
  pass

@dhcp_option_def(dhcp.DNS_SERVER_OPT)
class DHCPDNSServersOption (DHCPIPsOptionBase):
  pass

@dhcp_option_def(dhcp.HOST_NAME_OPT)
class DHCPHostNameOption (DHCPRawOption):
  pass

@dhcp_option_def(dhcp.DOMAIN_NAME_OPT)
class DHCPDomainNameOption (DHCPRawOption):
  pass

@dhcp_option_def(dhcp.BCAST_ADDR_OPT)
class DHCPBroadcastAddressOption (DHCPIPOptionBase):
  pass

@dhcp_option_def(dhcp.VENDOR_OPT)
class DHCPVendorOption (DHCPRawOption):
  pass

@dhcp_option_def(dhcp.REQUEST_IP_OPT)
class DHCPRequestIPOption (DHCPIPOptionBase):
  pass

@dhcp_option_def(dhcp.REQUEST_LEASE_OPT)
class DHCPIPAddressLeaseTimeOption (DHCPSecondsOptionBase):
  pass

@dhcp_option_def(dhcp.OVERLOAD_OPT)
class DHCPOptionOverloadOption (DHCPOption):
  def __init__ (self, value = None):
    self.value = value

  @classmethod
  def unpack (cls, data, code = None):
    self = cls()
    if len(data) != 1: raise RuntimeError("Bad option length")
    self.value = ord(data[0])
    return self

  def pack (self):
    return chr(self.value)

  def __repr__ (self):
    return "%s(%s)" % (self._name, self.value)

@dhcp_option_def(dhcp.SERVER_ID_OPT)
class DHCPServerIdentifierOption (DHCPIPOptionBase):
  pass

@dhcp_option_def(dhcp.ERROR_MSG_OPT)
class DHCPErrorMessageOption (DHCPRawOption):
  pass

@dhcp_option_def(dhcp.T1_OPT)
class DHCPRenewalTimeOption (DHCPSecondsOptionBase):
  pass

@dhcp_option_def(dhcp.T2_OPT)
class DHCPRebindingTimeOption (DHCPSecondsOptionBase):
  pass

@dhcp_option_def(dhcp.PARAM_REQ_OPT)
class DHCPParameterRequestOption (DHCPOption):
  def __init__ (self, options = []):
    self.options = options

  @classmethod
  def unpack (cls, data, code = None):
    self = cls()
    self.options = [ord(x) for x in data]
    return self

  def pack (self):
    opt = ((o.CODE if is_subclass(o, DHCPOption) else o) for o in self.options)
    return b''.join(chr(x) for x in opt)

  def __repr__ (self):
    names = []
    for o in sorted(self.options):
      n = _dhcp_option_unpackers.get(o)
      if n is None or not hasattr(n, 'im_self'):
        n = "Opt/" + str(o)
      else:
        n = n.im_self.__name__
        if n.startswith("DHCP"): n = n[4:]
        if n.endswith("Option"): n = n[:-6]
        if n == "": n = "Opt"
        n += '/' + str(o)
      names.append(n)

    return "%s(%s)" % (self._name, " ".join(names))

########NEW FILE########
__FILENAME__ = dns
# Copyright 2011,2012 James McCauley
# Copyright 2008 (C) Nicira, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at:
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# This file is derived from the packet library in NOX, which was
# developed by Nicira, Inc.

#======================================================================
#
#                     DNS Message Format
#
#     0  1  2  3  4  5  6  7  8  9  0  1  2  3  4  5
#   +--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+
#   |                      ID                       |
#   +--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+
#   |QR|   Opcode  |AA|TC|RD|RA|Z |AD|CD|   RCODE   |
#   +--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+
#   |                 Total Questions               |
#   +--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+
#   |                 Total Answerrs                |
#   +--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+
#   |              Total Authority RRs              |
#   +--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+
#   |               Total Additional RRs            |
#   +--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+
#   |                 Questions ...                 |
#   +--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+
#   |               Answer RRs  ...                 |
#   +--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+
#   |               Authority RRs..                 |
#   +--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+
#   |               Additional RRs.                 |
#   +--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+
#
# Question format:
#
#                                   1  1  1  1  1  1
#     0  1  2  3  4  5  6  7  8  9  0  1  2  3  4  5
#   +--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+
#   |                                               |
#   /                     QNAME                     /
#   /                                               /
#   +--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+
#   |                     QTYPE                     |
#   +--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+
#   |                     QCLASS                    |
#   +--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+
#
#
#
# All RRs have the following format:
#                                   1  1  1  1  1  1
#     0  1  2  3  4  5  6  7  8  9  0  1  2  3  4  5
#   +--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+
#   |                                               |
#   /                                               /
#   /                      NAME                     /
#   |                                               |
#   +--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+
#   |                      TYPE                     |
#   +--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+
#   |                     CLASS                     |
#   +--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+
#   |                      TTL                      |
#   |                                               |
#   +--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+
#   |                   RDLENGTH                    |
#   +--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--|
#   /                     RDATA                     /
#   /                                               /
#   +--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+
#
#
#======================================================================

# TODO:
#   SOA data
#   General cleaup/rewrite (code is/has gotten pretty bad)

import struct
from packet_utils import *
from packet_utils import TruncatedException as Trunc

from packet_base import packet_base

from pox.lib.addresses import IPAddr,IPAddr6,EthAddr

rrtype_to_str = {
   1: "A",  # host address
   2: "NS", #an authoritative name server
   3: "MD",        # a mail destination (Obsolete - use MX)
   4: "MF",        # a mail forwarder (Obsolete - use MX)
   5: "CNAME",     # the canonical name for an alias
   6: "SOA",       # marks the start of a zone of authority
   7: "MB" ,       # a mailbox domain name (EXPERIMENTAL)
   8: "MG" ,       # a mail group member (EXPERIMENTAL)
   9: "MR" ,       # a mail rename domain name (EXPERIMENTAL)
   10: "NULL" ,    # a null RR (EXPERIMENTAL)
   11: "WKS"  ,    # a well known service description
   12: "PTR"  ,    # a domain name pointer
   13: "HINFO",    # host information
   14: "MINFO",    # mailbox or mail list information
   15: "MX"   ,    # mail exchange
   16: "TXT",      # text strings
   28: "AAAA" # IPV6 address request
}

rrclass_to_str = {
  1   :"IN", #  1 the Internet
  2   :"CS", #  2 the CSNET class (Obsolete)
  3   :"CH", #  3 the CHAOS class
  4   :"HS", #  4 Hesiod [Dyer 87]
  255 :"* "  #  255 any class
}


class dns(packet_base):
    "DNS Packet struct"

    MDNS_ADDRESS  = IPAddr('224.0.0.251')
    MDNS6_ADDRESS = IPAddr6('ff02::fb')
    MDNS_ETH      = EthAddr('01:00:5E:00:00:fb')
    MDNS6_ETH     = EthAddr('33:33:00:00:00:fb')

    SERVER_PORT = 53
    MDNS_PORT   = 5353
    MIN_LEN     = 12

    def __init__(self, raw=None, prev=None, **kw):
        packet_base.__init__(self)

        self.prev = prev

        self.questions   = []
        self.answers     = []
        self.authorities = []
        self.additional  = []

        self.id = 0
        self.qr = False # Is Query
        self.opcode = 0
        self.aa = False # Authoritative Answer
        self.tc = False # Truncated
        self.rd = False # Recursion Desired
        self.ra = False # Recursion Available
        self.z = False
        self.ad = False
        self.cd = False
        self.rcode = 0
        # TODO: everything else here

        if raw is not None:
            self.parse(raw)

        self._init(kw)

    def _exc (self, e, part = None):
      """
      Turn exception into log message
      """
      msg = "(dns)"
      if part is not None:
        msg += " " + part
      msg += ": "
      msg += str(e)
      if isinstance(e, Trunc):
        self.msg(msg)
      else:
        self.err(msg)

    def hdr (self, payload):
        bits0 = 0
        if self.qr: bits0 |= 0x80
        bits0 |= (self.opcode & 0x7) << 4
        if self.rd: bits0 |= 1
        if self.tc: bits0 |= 2
        if self.aa: bits0 |= 4
        bits1 = 0
        if self.ra: bits1 |= 0x80
        if self.z: bits1 |= 0x40
        if self.ad: bits1 |= 0x20
        if self.cd: bits1 |= 0x10
        bits1 |= (self.rcode & 0xf)

        s = struct.pack("!HBBHHHH", self.id, bits0, bits1,
                        len(self.questions), len(self.answers),
                        len(self.authorities), len(self.additional))

        def makeName (labels, term):
          o = '' #TODO: unicode
          for l in labels.split('.'):
            o += chr(len(l))
            o += l
          if term: o += '\x00'
          return o

        name_map = {}

        def putName (s, name):
          pre = ''
          post = name
          while True:
            at = s.find(makeName(post, True))
            if at == -1:
              if post in name_map:
                at = name_map[post]
            if at == -1:
              post = post.split('.', 1)
              if pre: pre += '.'
              pre += post[0]
              if len(post) == 1:
                if len(pre) == 0:
                  s += '\x00'
                else:
                  name_map[name] = len(s)
                  s += makeName(pre, True)
                break
              post = post[1]
            else:
              if len(pre) > 0:
                name_map[name] = len(s)
                s += makeName(pre, False)
              s += struct.pack("!H", at | 0xc000)
              break
          return s

        def putData (s, r):
          if r.qtype in (2,12,5,15):
            return putName(s, r.rddata)
          elif r.qtype == 1:
            assert isinstance(r.rddata, IPAddr)
            return s + r.rddata.toRaw()
          else:
            return s + r.rddata

        for r in self.questions:
          s = putName(s, r.name)
          s += struct.pack("!HH", r.qtype, r.qclass)

        rest = self.answers + self.authorities + self.additional
        for r in rest:
          s = putName(s, r.name)
          s += struct.pack("!HHIH", r.qtype, r.qclass, r.ttl, 0)
          fixup = len(s) - 2
          s = putData(s, r)
          fixlen = len(s) - fixup - 2
          s = s[:fixup] + struct.pack('!H', fixlen) + s[fixup+2:]

        return s

    def parse(self, raw):
        assert isinstance(raw, bytes)
        self.raw = raw
        dlen = len(raw)
        if dlen < dns.MIN_LEN:
            self.msg('(dns) packet data too short to '
                     + 'parse header: data len %u' % (dlen,))
            return None

        bits0 = 0
        bits1 = 0
        total_questions = 0
        total_answers = 0
        total_auth_rr = 0
        total_add_rr = 0
        (self.id, bits0,bits1, total_questions, total_answers,
         total_auth_rr, total_add_rr)\
             = struct.unpack('!HBBHHHH', raw[:12])

        self.qr = True if (bits0 & 0x80) else False
        self.opcode = (bits0 >> 4) & (0x07)
        self.aa     = True if (bits0 & (0x04)) else False
        self.tc     = True if (bits0 & (0x02)) else False
        self.rd     = True if (bits0 & (0x01)) else False
        self.ra     = True if (bits1 & 0x80) else False
        self.z      = True if (bits1 & 0x40) else False
        self.ad     = True if (bits1 & 0x20) else False
        self.cd     = True if (bits1 & 0x10) else False
        self.rcode  = bits1 & 0x0f

        query_head = 12

        # questions
        for i in range(0,total_questions):
            try:
                query_head = self.next_question(raw, query_head)
            except Exception, e:
                self._exc(e, 'parsing questions')
                return None

        # answers
        for i in range(0,total_answers):
            try:
                query_head = self.next_rr(raw, query_head, self.answers)
            except Exception, e:
                self._exc(e, 'parsing answers')
                return None

        # authoritative name servers
        for i in range(0,total_auth_rr):
            try:
                query_head = self.next_rr(raw, query_head, self.authorities)
            except Exception, e:
                self._exc(e, 'parsing authoritative name servers')
                return None

        # additional resource records
        for i in range(0,total_add_rr):
            try:
                query_head = self.next_rr(raw, query_head, self.additional)
            except Exception, e:
                self._exc(e, 'parsing additional resource records')
                return None

        self.parsed = True

    def _to_str(self):
        flags = "|"

        if self.qr != 0:
            flags += "QR "
        if self.tc != 0:
            flags += "TR "
        if self.rd != 0:
            flags += "RD "
        if self.ra != 0:
            flags += "RA "
        if self.z != 0:
            flags += "Z "

        flags += "|"

        s = "(id:%x fl:%s op:%d nq:%d na:%d nath:%d nadd:%d)" % (self.id,
         flags, self.opcode, len(self.questions), len(self.answers),
         len(self.authorities), len(self.additional))

        if len(self.questions) > 0:
            for q in self.questions:
                s += "(q? "+str(q)+")"

        if len(self.answers) > 0:
            for a in self.answers:
                s += "(answ: "+str(a)+")"

        if len(self.authorities) > 0:
            for a in self.authorities:
                s += "(auth: "+str(a)+")"

        if len(self.additional) > 0:
            for a in self.additional:
                s += "(add: "+str(a)+")"

        return s

    # Utility methods for parsing.  Generally these would be pulled out
    # into a separate class. However, because the lengths are not known
    # until the fields have been parsed, it is more convenient to keep
    # them in the DNS class

    @classmethod
    def _read_dns_name_from_index(cls, l, index, retlist):
      try:
        while True:
            chunk_size = ord(l[index])

            # check whether we have an internal pointer
            if (chunk_size & 0xc0) == 0xc0:
                # pull out offset from last 14 bits
                offset = ((ord(l[index]) & 0x3) << 8 ) | ord(l[index+1])
                cls._read_dns_name_from_index(l, offset, retlist)
                index += 1
                break
            if chunk_size == 0:
                break
            index += 1
            retlist.append(l[index : index + chunk_size])
            index += chunk_size
        return index
      except IndexError:
        raise Trunc("incomplete name")

    @classmethod
    def read_dns_name_from_index(cls, l, index):
        retlist = []
        next = cls._read_dns_name_from_index(l, index, retlist)
        return (next + 1, ".".join(retlist))

    def next_rr(self, l, index, rr_list):
        array_len = len(l)

        # verify whether name is offset within packet
        if index > array_len:
            raise Trunc("next_rr: name truncated")

        index,name = self.read_dns_name_from_index(l, index)

        if index + 10 > array_len:
            raise Trunc("next_rr: truncated")

        (qtype,qclass,ttl,rdlen) = struct.unpack('!HHIH', l[index:index+10])
        if index+10+rdlen > array_len:
            raise Trunc("next_rr: data truncated")

        rddata = self.get_rddata(l, qtype, rdlen, index + 10)
        rr_list.append(dns.rr(name, qtype, qclass,ttl,rdlen,rddata))

        return index + 10 + rdlen

    def get_rddata(self, l, type, dlen, beg_index):
        if beg_index + dlen > len(l):
            raise Trunc('(dns) truncated rdata')
        # A
        if type == 1:
            if dlen != 4:
                raise Exception('(dns) invalid a data size',system='packet')
            return IPAddr(l[beg_index : beg_index + 4])
        # AAAA
        elif type == 28:
            if dlen != 16:
                raise Exception('(dns) invalid a data size',system='packet')
            return IPAddr6(l[beg_index : beg_index + dlen])
        # NS
        elif type == 2:
            return self.read_dns_name_from_index(l, beg_index)[1]
        # PTR
        elif type == 12:
            return  self.read_dns_name_from_index(l, beg_index)[1]
        # CNAME
        elif type == 5:
            return self.read_dns_name_from_index(l, beg_index)[1]
        # MX
        elif type == 15:
            #TODO: Save priority (don't just jump past it)
            return self.read_dns_name_from_index(l, beg_index + 2)[1]
        else:
            return l[beg_index : beg_index + dlen]

    def next_question(self, l, index):
        array_len = len(l)

        index,name = self.read_dns_name_from_index(l, index)

        if index + 4 > array_len:
            raise Trunc("next_question: truncated")

        (qtype,qclass) = struct.unpack('!HH', l[index:index+4])
        self.questions.append(dns.question(name, qtype, qclass))
        return index + 4

    # Utility classes for questions and RRs

    class question:

        def __init__(self, name, qtype, qclass):
            self.name   = name
            self.qtype  = qtype
            self.qclass = qclass

        def __str__(self):
            s = self.name
            if self.qtype in rrtype_to_str:
                s += " " + rrtype_to_str[self.qtype]
            else:
                s += " ??? "
            if self.qclass in rrclass_to_str:
                s += " " + rrclass_to_str[self.qclass]
            else:
                s += " ??? "

            return s

    class rr (object):
        A_TYPE     = 1
        NS_TYPE    = 2
        MD_TYPE    = 3
        MF_TYPE    = 4
        CNAME_TYPE = 5
        SOA_TYPE   = 6
        MB_TYPE    = 7
        MG_TYPE    = 8
        MR_TYPE    = 9
        NULL_TYPE  = 10
        WKS_TYPE   = 11
        PTR_TYPE   = 12
        HINFO_TYPE = 13
        MINFO_TYPE = 14
        MX_TYPE    = 15
        TXT_TYPE   = 16
        AAAA_TYPE  = 28

        def __init__ (self, _name, _qtype, _qclass, _ttl, _rdlen, _rddata):
            self.name   = _name
            self.qtype  = _qtype
            self.qclass = _qclass
            self.ttl    = _ttl
            self.rdlen  = _rdlen
            self.rddata = _rddata

        def __str__ (self):
            s = self.name
            if self.qtype in rrtype_to_str:
                s += " " + rrtype_to_str[self.qtype]
            else:
                s += " ??? "
            if self.qclass in rrclass_to_str:
                s += " " + rrclass_to_str[self.qclass]
            else:
                s += " ??? "
            s += " ttl:"+str(self.ttl)
            s += " rdlen:"+str(self.rdlen)
            s += " datalen:" + str(len(self.rddata))
            if len(self.rddata) == 4:
              #FIXME: can be smarter about whether this is an IP
              s+= " data:" + str(IPAddr(self.rddata))

            return s

########NEW FILE########
__FILENAME__ = eap
# Copyright 2011 James McCauley
# Copyright 2008 (C) Nicira, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at:
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# This file is derived from the packet library in NOX, which was
# developed by Nicira, Inc.

#======================================================================
#
# From RFC 3748 "Extensible Authentication Protocol (EAP)":
#
#    0                   1                   2                   3
#    0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1
#   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
#   |     Code      |  Identifier   |            Length             |
#   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
#   |    Data ...
#   +-+-+-+-+
#
#   Code
#
#      The Code field is one octet and identifies the Type of EAP packet.
#      EAP Codes are assigned as follows:
#
#         1       Request
#         2       Response
#         3       Success
#         4       Failure
#
#      Since EAP only defines Codes 1-4, EAP packets with other codes
#      MUST be silently discarded by both authenticators and peers.
#
#
#   Identifier
#
#      The Identifier field is one octet and aids in matching Responses
#      with Requests.
#
#   Length
#
#      The Length field is two octets and indicates the length, in
#      octets, of the EAP packet including the Code, Identifier, Length,
#      and Data fields.  Octets outside the range of the Length field
#      should be treated as Data Link Layer padding and MUST be ignored
#      upon reception.  A message with the Length field set to a value
#      larger than the number of received octets MUST be silently
#      discarded.
#
#   Data
#
#      The Data field is zero or more octets.  The format of the Data
#      field is determined by the Code field.
#
# Request and response packets have the following format.
#
#   0                   1                   2                   3
#   0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1
#  +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
#  |     Code      |  Identifier   |            Length             |
#  +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
#  |     Type      |  Type-Data ...
#  +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-
#
# Valid type values are as follows:
#
#       1       Identity
#       2       Notification
#       3       Nak (Response only)
#       4       MD5-Challenge
#       5       One Time Password (OTP)
#       6       Generic Token Card (GTC)
#     254       Expanded Types
#     255       Experimental use
#
#======================================================================
import struct
from packet_utils       import *

from packet_base import packet_base

class eap(packet_base):
    "Extensible Authentication Protocol packet"

    MIN_LEN = 4

    REQUEST_CODE = 1
    RESPONSE_CODE = 2
    SUCCESS_CODE = 3
    FAILURE_CODE = 4

    IDENTITY_TYPE     = 1
    NOTIFICATION_TYPE = 2
    NAK_TYPE          = 3
    MD5_TYPE          = 4
    OTP_TYPE          = 5
    GTC_TYPE          = 6
    EXPANDED_TYPE     = 254
    EXPERIMENTAL_TYPE = 255

    code_names = {REQUEST_CODE: "request",
                  RESPONSE_CODE: "response",
                  SUCCESS_CODE: "success",
                  FAILURE_CODE: "failure"}

    type_names = { IDENTITY_TYPE : "identity",
                   NOTIFICATION_TYPE : "notification",
                   NAK_TYPE         : "nak",
                   MD5_TYPE  : "md5-challenge",
                   OTP_TYPE  : "OTP",
                   GTC_TYPE  : "GTC",
                   EXPANDED_TYPE  : "expanded",
                   EXPERIMENTAL_TYPE : "experimental"
                 }

    @staticmethod
    def code_name(code):
        return eap.code_names.get(code, "code%d" % code)

    @staticmethod
    def type_name(type):
        return eap.type_names.get(type, "type%d" % type)

    def __init__(self, raw=None, prev=None, **kw):
        packet_base.__init__(self)

        self.prev = prev

        self.code = self.REQUEST_CODE
        self.id = 0
        self.length = 0

        if raw is not None:
            self.parse(raw)

        self._init(kw)

    def __str__(self):
        s = '[EAP %s id=%d' % (eap.code_name(self.code), self.id)
        if hasattr(self, 'type'):
            s += ' type=%s' % (eap.type_names[self.type],)
        return s + "]"

    def parse(self, raw):
        assert isinstance(raw, bytes)
        self.raw = raw
        dlen = len(raw)
        if dlen < self.MIN_LEN:
            self.msg('(eapol parse) warning EAP packet data too short to parse header: data len %u' % (dlen,))
            return

        (self.code, self.id, self.length) \
            = struct.unpack('!BBH', raw[:self.MIN_LEN])

        self.hdr_len = self.length
        self.payload_len = 0
        self.parsed = True

        if self.code == self.REQUEST_CODE:
            (self.type,) \
                = struct.unpack('!B', raw[self.MIN_LEN:self.MIN_LEN + 1 ])
            # not yet implemented
        elif self.code == self.RESPONSE_CODE:
            (self.type,) \
                = struct.unpack('!B', raw[self.MIN_LEN:self.MIN_LEN + 1 ])
            # not yet implemented
        elif self.code == self.SUCCESS_CODE:
            self.next = None    # Success packets have no payload
        elif self.code == self.REQUEST_CODE:
            self.next = None    # Failure packets have no payload
        else:
            self.msg('warning unsupported EAP code: %s' %
                     (eap.code_name(self.code),))

    def hdr(self, payload):
        return struct.pack('!BBH', self.code, self.id, self.length)

########NEW FILE########
__FILENAME__ = eapol
# Copyright 2011 James McCauley
# Copyright 2008 (C) Nicira, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at:
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# This file is derived from the packet library in NOX, which was
# developed by Nicira, Inc.

#======================================================================
#
# EAPOL Header Format (see IEEE 802.1X-2004):
#
# Octet 0: Protocol version (1 or 2).
# Octet 1: Packet type:
#   0 = EAP packet
#   1 = EAPOL-Start
#   2 = EAPOL-Logoff
#   3 = EAPOL-Key
#   4 = EAPOL-Encapsulated-ASF-Alert
# Octets 2-3: Length of packet body field (0 if packet body is absent)
# Octets 4-end: Packet body (present only for packet types 0, 3, 4)
#
#======================================================================
import struct
from packet_utils       import *

from packet_base import packet_base

from eap import *

class eapol(packet_base):
    "EAP over LAN packet"

    MIN_LEN = 4

    V1_PROTO = 1
    V2_PROTO = 2

    EAP_TYPE = 0
    EAPOL_START_TYPE = 1
    EAPOL_LOGOFF_TYPE = 2
    EAPOL_KEY_TYPE = 3
    EAPOL_ENCAPSULATED_ASF_ALERT = 4
    type_names = {EAP_TYPE: "EAP",
                  EAPOL_START_TYPE: "EAPOL-Start",
                  EAPOL_LOGOFF_TYPE: "EAPOL-Logoff",
                  EAPOL_KEY_TYPE: "EAPOL-Key",
                  EAPOL_ENCAPSULATED_ASF_ALERT: "EAPOL-Encapsulated-ASF-Alert"}

    @staticmethod
    def type_name(type):
        return eapol.type_names.get(type, "type%d" % type)

    def __init__(self, raw=None, prev=None, **kw):
        packet_base.__init__(self)

        self.prev = prev

        self.version = self.V1_PROTO
        self.type = self.EAP_TYPE
        self.bodylen = 0

        if raw is not None:
            self.parse(raw)

        self._init(kw)

    def __str__(self):
        s = '[EAPOL v%d %s]' % (self.version, self.type_name(self.type))
        return s

    def parse(self, raw):
        assert isinstance(raw, bytes)
        self.raw = raw
        dlen = len(raw)
        if dlen < self.MIN_LEN:
            self.msg('(eapol parse) warning EAPOL packet data too short to parse header: data len %u' % (dlen,))
            return

        (self.version, self.type, self.bodylen) \
            = struct.unpack('!BBH', raw[:self.MIN_LEN])

        self.parsed = True

        if self.type == self.EAP_TYPE:
            self.next = eap(raw=raw[self.MIN_LEN:], prev=self)
        elif (self.type == self.EAPOL_START_TYPE
              or self.type == self.EAPOL_LOGOFF_TYPE):
            pass                # These types have no payloads.
        else:
            self.msg('warning unsupported EAPOL type: %s' % (self.type_name(self.type),))

    def hdr(self, payload):
        return struct.pack('!BBH', self.version, self.type, self.bodylen)

########NEW FILE########
__FILENAME__ = ethernet
# Copyright 2011,2012,2013 James McCauley
# Copyright 2008 (C) Nicira, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at:
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# This file is derived from the packet library in NOX, which was
# developed by Nicira, Inc.

#======================================================================
# Ethernet header
#
#======================================================================

import struct

from packet_base import packet_base
from packet_utils import ethtype_to_str

from pox.lib.addresses import *

ETHER_ANY            = EthAddr(b"\x00\x00\x00\x00\x00\x00")
ETHER_BROADCAST      = EthAddr(b"\xff\xff\xff\xff\xff\xff")
BRIDGE_GROUP_ADDRESS = EthAddr(b"\x01\x80\xC2\x00\x00\x00")
LLDP_MULTICAST       = EthAddr(b"\x01\x80\xc2\x00\x00\x0e")
PAE_MULTICAST        = EthAddr(b'\x01\x80\xc2\x00\x00\x03') # 802.1x Port
                                                            #  Access Entity
NDP_MULTICAST        = EthAddr(b'\x01\x23\x20\x00\x00\x01') # Nicira discovery
                                                            #  multicast

class ethernet(packet_base):
  "Ethernet packet struct"

  resolve_names = False

  MIN_LEN = 14

  IP_TYPE    = 0x0800
  ARP_TYPE   = 0x0806
  RARP_TYPE  = 0x8035
  VLAN_TYPE  = 0x8100
  LLDP_TYPE  = 0x88cc
  PAE_TYPE   = 0x888e           # 802.1x Port Access Entity
  #MPLS_UNICAST_TYPE = 0x8847
  #MPLS_MULTICAST_TYPE = 0x8848
  MPLS_TYPE  = 0x8847
  MPLS_MC_TYPE = 0x8848         # Multicast
  IPV6_TYPE  = 0x86dd
  PPP_TYPE   = 0x880b
  LWAPP_TYPE = 0x88bb
  GSMP_TYPE  = 0x880c
  IPX_TYPE   = 0x8137
  IPX_TYPE   = 0x8137
  WOL_TYPE   = 0x0842
  TRILL_TYPE = 0x22f3
  JUMBO_TYPE = 0x8870
  SCSI_TYPE  = 0x889a
  ATA_TYPE   = 0x88a2
  QINQ_TYPE  = 0x9100

  INVALID_TYPE = 0xffff

  type_parsers = {}

  def __init__(self, raw=None, prev=None, **kw):
    packet_base.__init__(self)

    if len(ethernet.type_parsers) == 0:
      from vlan import vlan
      ethernet.type_parsers[ethernet.VLAN_TYPE] = vlan
      from arp  import arp
      ethernet.type_parsers[ethernet.ARP_TYPE]  = arp
      ethernet.type_parsers[ethernet.RARP_TYPE] = arp
      from ipv4 import ipv4
      ethernet.type_parsers[ethernet.IP_TYPE]   = ipv4
      from ipv6 import ipv6
      ethernet.type_parsers[ethernet.IPV6_TYPE] = ipv6
      from lldp import lldp
      ethernet.type_parsers[ethernet.LLDP_TYPE] = lldp
      from eapol import eapol
      ethernet.type_parsers[ethernet.PAE_TYPE]  = eapol
      from mpls import mpls
      ethernet.type_parsers[ethernet.MPLS_TYPE] = mpls
      ethernet.type_parsers[ethernet.MPLS_MC_TYPE] = mpls
      from llc import llc
      ethernet._llc = llc

    self.prev = prev

    self.dst  = ETHER_ANY
    self.src  = ETHER_ANY

    self.type = 0
    self.next = b''

    if raw is not None:
      self.parse(raw)

    self._init(kw)

  def parse (self, raw):
    assert isinstance(raw, bytes)
    self.next = None # In case of unfinished parsing
    self.raw = raw
    alen = len(raw)
    if alen < ethernet.MIN_LEN:
      self.msg('warning eth packet data too short to parse header: data len %u'
               % (alen,))
      return

    self.dst = EthAddr(raw[:6])
    self.src = EthAddr(raw[6:12])
    self.type = struct.unpack('!H', raw[12:ethernet.MIN_LEN])[0]

    self.hdr_len = ethernet.MIN_LEN
    self.payload_len = alen - self.hdr_len

    self.next = ethernet.parse_next(self, self.type, raw, ethernet.MIN_LEN)
    self.parsed = True

  @staticmethod
  def parse_next (prev, typelen, raw, offset=0, allow_llc=True):
    parser = ethernet.type_parsers.get(typelen)
    if parser is not None:
      return parser(raw[offset:], prev)
    elif typelen < 1536 and allow_llc:
      return ethernet._llc(raw[offset:], prev)
    else:
      return raw[offset:]

  @staticmethod
  def getNameForType (ethertype):
    """ Returns a string name for a numeric ethertype """
    return ethtype_to_str(ethertype)

  @property
  def effective_ethertype (self):
    return self._get_effective_ethertype(self)

  @staticmethod
  def _get_effective_ethertype (self):
    """
    Get the "effective" ethertype of a packet.

    This means that if the payload is something like a VLAN or SNAP header,
    we want the type from that deeper header.  This is kind of ugly here in
    the packet library, but it should make user code somewhat simpler.
    """
    if not self.parsed:
      return ethernet.INVALID_TYPE
    if self.type == ethernet.VLAN_TYPE or type(self.payload) == ethernet._llc:
      try:
        return self.payload.effective_ethertype
      except:
        return ethernet.INVALID_TYPE
    return self.type

  def _to_str(self):
    s = ''.join(('[',str(EthAddr(self.src)),'>',str(EthAddr(self.dst)),' ',
                ethernet.getNameForType(self.type),']'))
    return s

  def hdr(self, payload):
    dst = self.dst
    src = self.src
    if type(dst) is EthAddr:
      dst = dst.toRaw()
    if type(src) is EthAddr:
      src = src.toRaw()
    return struct.pack('!6s6sH', dst, src, self.type)

########NEW FILE########
__FILENAME__ = icmp
# Copyright 2011 James McCauley
# Copyright 2008 (C) Nicira, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at:
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# This file is derived from the packet library in NOX, which was
# developed by Nicira, Inc.

#======================================================================
#
#                            ICMP Header Format
#
#   0                   1                   2                   3
#   0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1
#  +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
#  |      Type     |      Code     |           Checksum            |
#  +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
#  |                             Data                              |
#  +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
#
#
#======================================================================
import struct
import random
from packet_utils       import *

from packet_base import packet_base

TYPE_ECHO_REPLY   = 0
TYPE_DEST_UNREACH = 3
TYPE_SRC_QUENCH   = 4
TYPE_REDIRECT     = 5
TYPE_ECHO_REQUEST = 8
TYPE_TIME_EXCEED  = 11

CODE_UNREACH_NET     = 0
CODE_UNREACH_HOST    = 1
CODE_UNREACH_PROTO   = 2
CODE_UNREACH_PORT    = 3
CODE_UNREACH_FRAG    = 4
CODE_UNREACH_SRC_RTE = 5

_type_to_name = {
    0   : "ECHO_REPLY",
    3   : "DEST_UNREACH",
    4   : "SRC_QUENCH",
    5   : "REDIRECT",
    8   : "ECHO_REQUEST",
    11  : "TIME_EXCEED",
}


# This is such a hack; someone really needs to rewrite the
# stringizing.
def _str_rest (s, p):
  if p.next is None:
    return s
  if isinstance(p.next, basestring):
    return "[%s bytes]" % (len(p.next),)
  return s+str(p.next)


#----------------------------------------------------------------------
#
#  Echo Request/Reply
#   0                   1                   2                   3
#   0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1
#  +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
#  |           Identifier          |        Sequence Number        |
#  +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
#  |                             Data                              |
#  +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
#
#----------------------------------------------------------------------
class echo(packet_base):
    "ICMP echo packet struct"

    MIN_LEN = 4

    def __init__(self, raw=None, prev=None, **kw):
        packet_base.__init__(self)

        self.prev = prev

        self.id  = random.randint(0, 65535)
        self.seq = 0

        if raw is not None:
            self.parse(raw)

        self._init(kw)

    def __str__(self):
        return "[ICMP id:%i seq:%i]" % (self.id, self.seq)

    def parse(self, raw):
        assert isinstance(raw, bytes)
        self.raw = raw

        dlen = len(raw)

        if dlen < self.MIN_LEN:
            self.msg('(echo parse) warning echo payload too short to '
                     'parse header: data len %u' % (dlen,))
            return

        (self.id, self.seq) = struct.unpack('!HH', raw[:self.MIN_LEN])

        self.parsed = True
        self.next = raw[echo.MIN_LEN:]

    def hdr(self, payload):
        return struct.pack('!HH', self.id, self.seq)


#----------------------------------------------------------------------
#
#  Destination Unreachable
#   0                   1                   2                   3
#   0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1
#  +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
#  |            Unused             |         Next-Hop MTU          |
#  +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
#  |       IP Header + 8 bytes of original datagram's data         |
#  +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
#
#----------------------------------------------------------------------
class unreach(packet_base):
    "ICMP unreachable packet struct"

    MIN_LEN = 4

    def __init__(self, raw=None, prev=None, **kw):
        packet_base.__init__(self)

        self.prev = prev

        self.unused = 0
        self.next_mtu = 0

        if raw is not None:
            self.parse(raw)

        self._init(kw)

    def __str__(self):
        s = ''.join(('[', 'm:', str(self.next_mtu), ']'))

        return _str_rest(s, self)

    def parse(self, raw):
        assert isinstance(raw, bytes)
        self.raw = raw
        dlen = len(raw)
        if dlen < self.MIN_LEN:
            self.msg('(unreach parse) warning unreachable payload too short '
                     'to parse header: data len %u' % dlen)
            return

        (self.unused, self.next_mtu) \
            = struct.unpack('!HH', raw[:self.MIN_LEN])

        self.parsed = True

        if dlen >= 28:
            # xxx We're assuming this is IPv4!
            import ipv4
            self.next = ipv4.ipv4(raw=raw[unreach.MIN_LEN:],prev=self)
        else:
            self.next = raw[unreach.MIN_LEN:]

    def hdr(self, payload):
        return struct.pack('!HH', self.unused, self.next_mtu)


class icmp(packet_base):
    "ICMP packet struct"

    MIN_LEN = 4

    def __init__(self, raw=None, prev=None, **kw):
        packet_base.__init__(self)

        self.prev = prev

        self.type = 0
        self.code = 0
        self.csum = 0

        if raw is not None:
            self.parse(raw)

        self._init(kw)

    def __str__(self):
        t = _type_to_name.get(self.type, str(self.type))
        s = '[t:%s c:%i chk:%x]' % (t, self.code, self.csum)
        return _str_rest(s, self)

    def parse(self, raw):
        assert isinstance(raw, bytes)
        dlen = len(raw)
        if dlen < self.MIN_LEN:
            self.msg('(icmp parse) warning ICMP packet data too short to '
                     + 'parse header: data len %u' % (dlen,))
            return

        (self.type, self.code, self.csum) \
            = struct.unpack('!BBH', raw[:self.MIN_LEN])

        self.parsed = True

        if (self.type == TYPE_ECHO_REQUEST or self.type == TYPE_ECHO_REPLY):
            self.next = echo(raw=raw[self.MIN_LEN:],prev=self)
        elif self.type == TYPE_DEST_UNREACH:
            self.next = unreach(raw=raw[self.MIN_LEN:],prev=self)
        else:
            self.next = raw[self.MIN_LEN:]

    def hdr(self, payload):
        self.csum = checksum(struct.pack('!BBH', self.type, self.code, 0) +
                             payload)
        return struct.pack('!BBH', self.type, self.code, self.csum)

########NEW FILE########
__FILENAME__ = icmpv6
# Copyright 2011-2013 James McCauley
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at:
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

#======================================================================
#
#                           ICMPv6 Header Format
#
#   0                   1                   2                   3
#   0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1
#  +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
#  |      Type     |      Code     |           Checksum            |
#  +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
#  |                             Data                              |
#  +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
#
#
#======================================================================

"""
This file parses ICMPv6 as well as NDP

See RFCs 4443 and 4861 in particular.
"""

#TODO: Move NDP into its own file?
#TODO: Clean this up in general
#TODO: Write tests (at least pack/unpack)

import struct
import random
import new
from packet_utils import *
from packet_base import packet_base

from pox.lib.addresses import IPAddr6,EthAddr
from pox.lib.util import hexdump, init_helper

# Errors
TYPE_DEST_UNREACH   = 1
TYPE_PACKET_TOO_BIG = 2
TYPE_TIME_EXCEED    = 3
TYPE_PARAM_PROB     = 4

# Informational
TYPE_ECHO_REQUEST           = 128
TYPE_ECHO_REPLY             = 129
TYPE_MC_LISTENER_QUERY      = 130
TYPE_MC_LISTENER_REPORT     = 131
TYPE_MC_LISTENER_DONE       = 132
TYPE_ROUTER_SOLICITATION    = 133 # NDP
TYPE_ROUTER_ADVERTISEMENT   = 134 # NDP
TYPE_NEIGHBOR_SOLICITATION  = 135 # NDP
TYPE_NEIGHBOR_ADVERTISEMENT = 136 # NDP
TYPE_REDIRECT               = 137 # NDP
TYPE_ROUTER_RENUMBER        = 138
TYPE_MC_LISTENER_REPORT_V2  = 143
TYPE_MRD_ADVERTISEMENT      = 151
TYPE_MRD_SOLICITATION       = 152
TYPE_MRD_TERMINATION        = 153

CODE_UNREACH_NO_ROUTE         = 0
CODE_UNREACH_ADMIN_PROHIBIT   = 1
CODE_UNREACH_BEYOND_SRC_SCOPE = 2
CODE_UNREACH_ADDR_UNREACHABLE = 3
CODE_UNREACH_PORT_UNREACHABLE = 4
CODE_UNREACH_SRC_POLICY_FAIL  = 5
CODE_UNREACH_DST_ROUTE_REJECT = 6
CODE_UNREACH_SRC_ROUTE_ERROR  = 7

CODE_TIME_HOP_EXCEEDED        = 0
CODE_TIME_FRAG_TIME_EXCEEDED  = 1

CODE_PARAM_BAD_HEADER         = 0
CODE_PARAM_BAD_NEXT_HEADER    = 1
CODE_PARAM_BAD_OPTION         = 2

#TODO: Use a class registry for this
_type_to_name = {
  1   : "TYPE_DEST_UNREACH",
  2   : "TYPE_PACKET_TOO_BIG",
  3   : "TYPE_TIME_EXCEED",
  4   : "TYPE_PARAM_PROB",
  128 : "TYPE_ECHO_REQUEST",
  129 : "TYPE_ECHO_REPLY",
  130 : "TYPE_MC_LISTENER_QUERY",
  131 : "TYPE_MC_LISTENER_REPORT",
  132 : "TYPE_MC_LISTENER_DONE",
  133 : "TYPE_ROUTER_SOLICITATION",
  134 : "TYPE_ROUTER_ADVERTISEMENT",
  135 : "TYPE_NEIGHBOR_SOLICITATION",
  136 : "TYPE_NEIGHBOR_ADVERTISEMENT",
  137 : "TYPE_REDIRECT",
  138 : "TYPE_ROUTER_RENUMBER",
  143 : "TYPE_MC_LISTENER_REPORT_V2",
  151 : "TYPE_MRD_ADVERTISEMENT",
  152 : "TYPE_MRD_SOLICITATION",
  153 : "TYPE_MRD_TERMINATION",
}


_nd_options = {}


def nd_option_def (cls):
  """
  Neighbor Discovery option decorator
  """
  _nd_options[cls.TYPE] = cls
  return cls


def _parse_ndp_options (raw, prev, offset = 0, buf_len = None):
  """
  Parse ICMPv6 options and return (new_offset,[option_list])
  """
  # This is pretty bad at the moment
  _offset = offset
  if buf_len is None: buf_len = len(raw)
  remaining = buf_len - offset
  r = []

  while offset < buf_len - 2:
    if (buf_len - offset) % 8 != 0:
      raise RuntimeError("Bad option data length")
    offset,o = NDOptionBase.unpack_new(raw, offset, buf_len, prev=prev)
    r.append(o)

  return offset,r


class NDOptionBase (packet_base):
  "Neighbor Discovery option base class"

  #LENGTH = <fixed padded payload length in bytes or None>
  #TYPE = <type>

  def __init__ (self, *args, **kw):
    self.prev = kw.pop('prev', None)
    self._init(*args, **kw)
    init_helper(self, kw)

  def __repr__ (self):
    s = type(self).__name__
    if s.startswith("NDOption"):
      s = s[8:]
    elif s.startswith("NDOpt"):
      s = s[5:]
    ss = self._fields()
    if ss:
      s += ' '
      s += " ".join(["%s:%s" % (k,v) for k,v in ss.iteritems()])
    return "[" + s + "]"

  @property
  def type (self):
    return self.prev.type
  @property
  def code (self):
    return self.prev.code

  def _fields (self):
    """
    Override to add fields to stringizing
    """
    return None

  def _init (self, *args, **kw):
    """
    Called during initialization

    Override me
    """
    pass

  def __len__ (self):
    """
    Payload length in bytes

    Override if your option type has flexible length
    """
    assert self.LENGTH is not None
    return self.LENGTH

  @staticmethod
  def unpack_new (raw, offset = 0, buf_len = None, prev = None):
    """
    Unpacks a new instance of the appropriate subclass from a buffer

    returns (new_offset, object)
    """
    if buf_len is None: buf_len = len(raw)

    if buf_len < 2:
      raise TruncatedException()
    t,l = struct.unpack_from("BB", raw, offset)
    if l == 0:
      raise RuntimeError("Zero-length NDP option")

    offset += 2
    length_bytes = l * 8 - 2
    if (buf_len - offset) < length_bytes:
      raise TruncatedException()

    c = _nd_options.get(t) #FIXME: Ugh, *class registry*
    if c is None:
      c = NDOptionGeneric
    if c.LENGTH is not None and c.LENGTH != length_bytes:
      raise RuntimeError("Bad length for NDP option")

    new_off,o = c._unpack_new(raw, offset, t, length_bytes, prev=prev)

    assert new_off == offset+length_bytes
    return new_off,o

  def pack (self):
    d = self._pack_body()
    while (len(d)+2) % 8: d += "\x00" # sloppy
    return struct.pack("BB", self.TYPE, (len(d)+2)/8) + d

  @classmethod
  def _unpack_new (cls, raw, offset, t, length, prev):
    """
    Unpacks the body portion of this option type into a new object

    Override me.
    """
    raise RuntimeError("Not implemented")
    #o = new.instance(cls)
    #o._init()
    #return offset+length,o

  def _pack_body (self):
    """
    Returns the body of this option packed into bytes

    Override me
    """
    raise RuntimeError("Not implemented")
    #return b''


class NDOptionGeneric (NDOptionBase):
  LENGTH = None
  TYPE = None

  def __repr__ (self):
    return "<NDP Option Type %s>" % (self.TYPE,)
 
  def _init (self, *args, **kw):
    self.raw = b''

  def __len__ (self):
    return len(self.raw)

  def _pack_body (self):
    return self.raw

  @classmethod
  def _unpack_new (cls, raw, offset, t, length, prev):
    """
    Unpacks the body portion of this option type into a new object

    Override me.
    """
    #o = new.instance(cls) # Weird; this doesn't work despite the fact
                           # that it should be a new style class.
    o = cls()
    o._init()
    o.TYPE = t
    o.prev = prev
    #o.LENGTH = length
    o.raw = raw[offset:offset+length]
    return offset+length,o


class NDOptLinkLayerAddress (NDOptionBase):
  """
  Superclass for this source/target LL address options

  Assumes L2 is Ethernet
  """
  LENGTH = 6

  def _init (self, *args, **kw):
    a = kw.pop('address',None)
    if a is None:
      self.address = None
    else:
      self.address = EthAddr(a)
  
  def _fields (self):
    return {'addr':self.address}

  @classmethod
  def _unpack_new (cls, raw, offset, t, length, prev):
    return offset+length,cls(address = EthAddr(raw[offset:offset+length]),
        prev=prev)

  def _pack_body (self):
    return self.address.raw
    

@nd_option_def
class NDOptSourceLinkLayerAddress (NDOptLinkLayerAddress):
  TYPE = 1

@nd_option_def
class NDOptTargetLinkLayerAddress (NDOptLinkLayerAddress):
  TYPE = 2

@nd_option_def
class NDOptPrefixInformation (NDOptionBase):
  LENGTH = 1 + 1 + 4 + 4 + 4 + 4 * 4
  TYPE = 3

  ON_LINK_FLAG = 0x80
  AUTONOMOUS_FLAG = 0x40

  def _init (self, *args, **kw):
    self.prefix_length = 0
    self.on_link = False
    self.is_autonomous = False
    self.valid_lifetime = 0
    self.preferred_lifetime = 0
    self.prefix = IPAddr6.UNDEFINED

  def _fields (self):
    r = {}
    if self.on_link: r['on_link'] = True
    if self.is_autonomous: r['autonomous'] = True
    r['valid'] = self.valid_lifetime
    r['preferred'] = self.preferred_lifetime
    r['prefix'] = "%s/%s" % (self.prefix, self.prefix_length)
    return r

  @classmethod
  def _unpack_new (cls, raw, offset, t, length, prev):
    o = cls()
    o.prefix_length,flags,o.valid_lifetime,o.preferred_lifetime = \
        struct.unpack_from('!BBII', raw, offset)
    offset += 1 + 1 + 4 + 4
    offset += 4 # Reserved
    o.prefix = IPAddr6(raw=raw[offset:offset+16])
    offset += 16
    o.on_link = (flags & cls.ON_LINK_FLAG) != 0
    o.is_autonomous = (flags & cls.AUTONOMOUS_FLAG) != 0
    o.prev = prev

    return offset,o

  @property
  def flags (self):
    f = 0
    if self.on_link: f |= self.ON_LINK_FLAG
    if self.is_autonomous: f |= self.AUTONOMOUS_FLAG
    return f

  def pack (self):
    s = struct.pack("!BBII", self.prefix_length, self.flags,
        self.valid_lifetime,self.preferred_lifetime)
    s += '\x00' * 4
    s += self.prefix.raw
    return s


@nd_option_def
class NDOptMTU (NDOptionBase):
  LENGTH = 6
  TYPE = 5

  def _init (self, *args, **kw):
    self.mtu = 0

  def _fields (self):
    return {'mtu':self.mtu}

  @classmethod
  def _unpack_new (cls, raw, offset, t, length, prev):
    o = cls()
    o.prev = prev
    _,o.mtu = struct.unpack_from('!HI', raw, offset)
    offset += 2 + 4
    return offset,o

  def pack (self):
    return struct.pack("!HI", 0, self.mtu)



#NOTE: icmp_base sort of ignores the usual packet_base API.  Hopefully
#      the way it does so doesn't break too much.  The API it supports
#      is closer to the way a newer version of the API would work.

class icmp_base (packet_base):
  "ICMPv6 base class"

  def __str__ (self):
    s = "[ICMPv6/" + self.__class__.__name__
    ss = self._fields()
    if ss:
      s += ' '
      s += " ".join(["%s:%s" % (k,v) for k,v in ss.iteritems()])
    return s + "]"

  def _fields (self):
    """
    Return map of fields used for string formatting.

    Override me to customize stringizing.
    """
    return {}

  def _init_ (self):
    """
    Called during initialization

    Override me

    In most other hierarchies that follow a similar pattern, this method
    would be named "_init", but that name is already used in the
    packet_base hierarchy.
    """
    pass

  @property
  def type (self):
    return self.prev.type
  @property
  def code (self):
    return self.prev.code

  def __init__ (self, prev=None, **kw):
    packet_base.__init__(self)
    self.prev = prev
    self.next = None

    self._init_()

    self._init(kw)
    self.parsed = True

  @classmethod
  def unpack_new (cls, raw, offset = 0, buf_len = None, prev = None):
    """
    Unpacks a new instance of this class from a buffer

    returns (new_offset, object)
    """
    raise RuntimeError("Unimplemented on class %s" % (cls.__name__,))
    #.parsed = True

  def pack (self):
    raise RuntimeError("Unimplemented on class %s" % (type(self).__name__,))


class ICMPGeneric (icmp_base):
  def _fields (self):
    return {'bytes':len(self.raw)}

  def _init_ (self):
    self.raw = b''

  @classmethod
  def unpack_new (cls, raw, offset = 0, buf_len = None, prev = None):
    o = cls()
    o.raw = raw[offset:offset+buf_len]
    o.prev = prev
    o.parsed = True
    return offset+buf_len,o

  def pack (self):
    return self.raw


class NDRouterSolicitation (icmp_base):
  "Router Solicitation"
  def _init_ (self):
    self.options = []

  def _fields (self):
    return {"num_opts":len(self.options)}

  @classmethod
  def unpack_new (cls, raw, offset = 0, buf_len = None, prev = None):
    o = cls()

    _offset = offset
    if buf_len is None: buf_len = len(raw)

    try:
      offset += 4 # Skip reserved
      offset,o.options = _parse_ndp_options(raw, prev, offset, buf_len)

      o.parsed = True
    except TruncatedException:
      pass

    o.prev = prev
    return offset,o

  def pack (self):
    o = '\x00' * 4 # _PAD4
    for opt in self.options:
      o += opt.pack()
    return o


class NDRouterAdvertisement (icmp_base):
  "Router Advertisement"
  MANAGED_FLAG = 0x80
  OTHER_FLAG = 0x40

  def __init__ (self, raw=None, prev=None, **kw):
    icmp_base.__init__(self)
    self.prev = prev

    self.hop_limit = 0
    self.is_managed = False
    self.is_other = False
    self.lifetime = 0 # seconds
    self.reachable = 0 # milliseconds
    self.retrans_timer = 0 # milliseconds
    self.options = []

    if raw is not None: self.parse(raw)
    self._init(kw)

  def _fields (self):
    f = ['hop_limit','lifetime','reachable',
         'retrans_timer']
    r = {}
    #if len(self.options): r['num_opts'] = len(self.options)
    if len(self.options): r["opts"] = self.options
    if self.is_managed: r['managed'] = True
    if self.is_other: r['other'] = True
    for ff in f:
      r[ff] = getattr(self, ff)
    return r

  @classmethod
  def unpack_new (cls, raw, offset = 0, buf_len = None, prev = None):
    o = cls()

    _offset = offset
    if buf_len is None: buf_len = len(raw)

    try:
      o.hop_limit,flags,o.lifetime,o.reachable,o.retrans_time = \
          struct.unpack_from("!BBHII", raw, offset)
      offset += 1 + 1 + 2 + 4 + 4
      offset,o.options = _parse_ndp_options(raw, prev, offset, buf_len)
      o.is_managed = flags & cls.MANAGED_FLAG
      o.is_other = flags & cls.OTHER_FLAG

      o.parsed = True
    except TruncatedException:
      pass

    o.raw = raw[_offset:offset]
    o.prev = prev
    return offset,o

  @property
  def flags (self):
    f = 0
    if self.is_managed: f |= self.MANAGED_FLAG
    if self.is_other: f |= self.OTHER_FLAG
    return f

  def pack (self):
    o = '\x00' * 4 # _PAD4

    o += struct.pack("!BBHII", self.hop_limit, self.flags, self.lifetime,
        self.reachable, self.retrans_time)

    for opt in self.options:
      o += opt.pack()
    return o


class NDNeighborSolicitation (icmp_base):
  "Neighbor Solicitation"
  def __init__ (self, raw=None, prev=None, **kw):
    icmp_base.__init__(self)
    self.prev = prev

    self.target = IPAddr6.UNDEFINED
    self.options = []

    if raw is not None: self.parse(raw)
    self._init(kw)

  def _fields (self):
    f = ['target']
    r = {'num_opts':len(self.options)}
    r["opts"]=self.options
    for ff in f:
      r[ff] = getattr(self, ff)
    return r

  @classmethod
  def unpack_new (cls, raw, offset = 0, buf_len = None, prev = None):
    o = cls()

    _offset = offset
    if buf_len is None: buf_len = len(raw)

    try:
      offset += 4 # Skip reserved
      o.target = IPAddr6(raw=raw[offset:offset+16])
      offset += 16
      offset,o.options = _parse_ndp_options(raw, prev, offset, buf_len)

      o.parsed = True
    except TruncatedException:
      pass

    o.raw = raw[_offset:offset]
    o.prev = prev
    return offset,o

  def pack (self):
    o = '\x00' * 4 # _PAD4
    o += self.target.raw
    for opt in self.options:
      o += opt.pack()
    return o


class NDNeighborAdvertisement (icmp_base):
  "Neighbor Advertisement"

  ROUTER_FLAG = 0x80
  SOLICITED_FLAG = 0x40
  OVERRIDE_FLAG = 0x20

  def __init__ (self, raw=None, prev=None, **kw):
    icmp_base.__init__(self)
    self.prev = prev

    self.target = IPAddr6.UNDEFINED
    self.options = []
    self.is_router = False
    self.is_solicited = False
    self.is_override = False

    if raw is not None: self.parse(raw)
    self._init(kw)

  def _fields (self):
    f = ['target']
    r = {}
    #if len(self.options): r['num_opts'] = len(self.options)
    if len(self.options): r["opts"] = self.options
    if self.is_router: r['router'] = True
    if self.is_solicited: r['solicited'] = True
    if self.is_override: r['override'] = True
    for ff in f:
      r[ff] = getattr(self, ff)
    return r

  @classmethod
  def unpack_new (cls, raw, offset = 0, buf_len = None, prev = None):
    o = cls()

    _offset = offset
    if buf_len is None: buf_len = len(raw)

    try:
      flags = ord(raw[offset])
      o.is_router = (flags & cls.ROUTER_FLAG) != 0
      o.is_solicited = (flags & cls.SOLICITED_FLAG) != 0
      o.is_override = (flags & cls.OVERRIDE_FLAG) != 0

      offset += 4 # Skip reserved
      o.target = IPAddr6(raw=raw[offset:offset+16])
      offset += 16
      offset,o.options = _parse_ndp_options(raw, prev, offset, buf_len)

      o.parsed = True
    except TruncatedException:
      pass

    o.raw = raw[_offset:offset]
    o.prev = prev
    return offset,o

  def pack (self):
    o = 0
    if self.is_router: o |= self.ROUTER_FLAG
    if self.is_solicited: o |= self.SOLICITED_FLAG
    if self.is_override : o |= self.OVERRIDE_FLAG
    o = chr(o)
    o += '\x00' * 3 # _PAD3
    o += self.target.raw
    for opt in self.options:
      o += opt.pack()
    return o


class TimeExceeded (icmp_base):
  "Time Exceeded Big Message"

  def __init__ (self, raw=None, prev=None, **kw):
    icmp_base.__init__(self)
    self.prev = prev
    self.next = None

    if raw is not None: self.parse(raw)
    self._init(kw)

  def _fields (self):
    f = ['mtu']
    r = {}
    for ff in f:
      r[ff] = getattr(self, ff)
    return r

  @classmethod
  def unpack_new (cls, raw, offset = 0, buf_len = None, prev = None):
    o = cls()

    _offset = offset
    if buf_len is None: buf_len = len(raw)

    try:
      offset += 4 # Unused

      o.next = raw[offset:buf_len]
      offset = buf_len

      o.parsed = True
    except TruncatedException:
      pass

    o.raw = raw[_offset:offset]
    o.prev = prev
    return offset,o

  def hdr (self, payload):
    return struct.pack('!I', 0) # Unused


class PacketTooBig (icmp_base):
  "Packet Too Big Message"

  def __init__ (self, raw=None, prev=None, **kw):
    icmp_base.__init__(self)
    self.prev = prev
    self.next = None

    self.mtu = 0

    if raw is not None: self.parse(raw)
    self._init(kw)

  def _fields (self):
    f = ['mtu']
    r = {}
    for ff in f:
      r[ff] = getattr(self, ff)
    return r

  @classmethod
  def unpack_new (cls, raw, offset = 0, buf_len = None, prev = None):
    o = cls()

    _offset = offset
    if buf_len is None: buf_len = len(raw)

    try:
      o.mtu = struct.unpack_from("!I", raw, offset)
      offset += 4

      o.next = raw[offset:buf_len]
      offset = buf_len

      o.parsed = True
    except TruncatedException:
      pass

    o.raw = raw[_offset:offset]
    o.prev = prev
    return offset,o

  def hdr (self, payload):
    return struct.pack('!I', self.mtu)


class unpack_new_adapter (object):
  """
  Mixin to support unpack_new on classes with old-style construction/parse()
  """
  @classmethod
  def unpack_new (cls, raw, offset = 0, buf_len = None, prev = None):
    raw = raw[offset:]
    if buf_len is not None:
      raw = raw[:buf_len]
    o = cls(raw=raw,prev=prev)
    #o.parse(raw)
    return offset+len(o.raw),o

#----------------------------------------------------------------------
#
#  Echo Request/Reply
#   0                   1                   2                   3
#   0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1
#  +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
#  |           Identifier          |        Sequence Number        |
#  +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
#  |                             Data                              |
#  +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
#
#----------------------------------------------------------------------
class echo (packet_base, unpack_new_adapter):
  "ICMP echo packet struct"

  MIN_LEN = 4

  def __init__ (self, raw=None, prev=None, **kw):
    packet_base.__init__(self)

    self.prev = prev

    self.id  = random.randint(0, 65535)
    self.seq = 0

    if raw is not None:
      self.parse(raw)

    self._init(kw)

  def __str__ (self):
    return "[ICMP6 echo id:%i seq:%i]" % (self.id, self.seq)

  def parse (self, raw):
    assert isinstance(raw, bytes)
    self.raw = raw

    dlen = len(raw)

    if dlen < self.MIN_LEN:
      self.msg('(echo parse) warning echo payload too short to '
                'parse header: data len %u' % (dlen,))
      return

    (self.id, self.seq) = struct.unpack('!HH', raw[:self.MIN_LEN])

    self.parsed = True
    self.next = raw[echo.MIN_LEN:]

  def hdr (self, payload):
    return struct.pack('!HH', self.id, self.seq)


#----------------------------------------------------------------------
#
#  Destination Unreachable
#   0                   1                   2                   3
#   0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1
#  +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
#  |                            Unused                             |
#  +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
#  |       IP Header + 8 bytes of original datagram's data         |
#  +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
#
#----------------------------------------------------------------------
class unreach (packet_base, unpack_new_adapter):
  "ICMP unreachable packet struct"

  MIN_LEN = 4

  def __init__ (self, raw=None, prev=None, **kw):

    self.prev = prev

    self.unused = 0

    if raw is not None:
      self.parse(raw)

    self._init(kw)

  def __str__ (self):
    s = ''.join(('[', 'm:', str(self.next_mtu), ']'))

    return _str_rest(s, self)

  def parse (self, raw):
    assert isinstance(raw, bytes)
    self.raw = raw
    dlen = len(raw)
    if dlen < self.MIN_LEN:
      self.msg('(unreach parse) warning unreachable payload too '
               + 'short to parse header: data len %u' % (dlen,))
      return

    (self.unused, _) = struct.unpack('!I', raw[:self.MIN_LEN])

    self.parsed = True

    import ipv6
    # xxx We're assuming this is IPv6!
    if dlen >= 8 + ipv6.MIN_LEN:
      self.next = ipv6.ipv6(raw=raw[unreach.MIN_LEN:],prev=self)
    else:
      self.next = raw[unreach.MIN_LEN:]

  def hdr (self, payload):
    return struct.pack('!I', self.unused)




class icmpv6 (packet_base):
  "ICMP packet struct"

  MIN_LEN = 4

  def __init__ (self, raw=None, prev=None, **kw):
    super(icmpv6, self).__init__()

    self.prev = prev

    self.type = 0
    self.code = 0
    self.csum = 0

    if raw is not None:
      self.parse(raw)

    self._init(kw)

  def _calc_checksum (self):
    ph = self.prev.srcip.raw + self.prev.dstip.raw
    ph += struct.pack('!IHBB', len(self.raw), 0, 0, 58) # 58 == ICMPv6
    return checksum(ph + self.raw, skip_word=21)

  @property
  def checksum_ok (self):
    if not self.prev: return True
    if getattr(self, 'raw', None) is None: return True
    return self.csum == self._calc_checksum()

  def _to_str (self):
    t = _type_to_name.get(self.type, str(self.type))
    cs = ''
    if not self.checksum_ok:
      cs = " BAD_CHECKSUM(%02x!=%02x)" % (self.csum, self._calc_checksum())
    s = '[ICMP+%s/%i%s]' % (t, self.code, cs)
    return s

  def parse (self, raw, buf_len=None):
    assert isinstance(raw, bytes)
    if buf_len is None:
      buf_len = len(raw)
      self.raw = raw[:buf_len]
    else:
      self.raw = raw
    dlen = len(self.raw)
    if dlen < self.MIN_LEN:
      self.msg('(icmp parse) warning ICMP packet data too short to '
                + 'parse header: data len %u' % (dlen,))
      return

    (self.type, self.code, self.csum) \
        = struct.unpack('!BBH', raw[:self.MIN_LEN])
    #self.parsed = True

    if not self.checksum_ok:
      self.msg("Bad ICMPv6 checksum")
      self.next = raw[self.MIN_LEN:]
      return
    else:
      self.parsed = True

    #TODO: Use a class registry
    cls = {
        TYPE_ECHO_REQUEST:echo,
        TYPE_ECHO_REPLY:echo,
        TYPE_PACKET_TOO_BIG:PacketTooBig,
        TYPE_TIME_EXCEED:TimeExceeded,
        TYPE_DEST_UNREACH:unreach,
        TYPE_ROUTER_SOLICITATION:NDRouterSolicitation,
        TYPE_NEIGHBOR_SOLICITATION:NDNeighborSolicitation,
        TYPE_ROUTER_ADVERTISEMENT:NDRouterAdvertisement,
        TYPE_NEIGHBOR_ADVERTISEMENT:NDNeighborAdvertisement,
        }.get(self.type)
    if cls is None:
      #cls = unknown
      self.next = raw[self.MIN_LEN:]
      return

    offset,self.next = cls.unpack_new(raw, offset=self.MIN_LEN,
        buf_len=buf_len,prev=self)


  def hdr (self, payload):
    payload_len = len(payload) + 4
    ph = self.prev.srcip.raw + self.prev.dstip.raw
    ph += struct.pack('!IHBBBBH', payload_len, 0, 0, 58, # 58 == ICMPv6
                      self.type, self.code, 0)
    self.csum = checksum(ph + payload, 0, 21)
    return struct.pack('!BBH', self.type, self.code, self.csum)

########NEW FILE########
__FILENAME__ = igmp
# Copyright 2012 James McCauley
# Copyright 2008 (C) Nicira, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at:
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# This file is derived from the packet library in NOX, which was
# developed by Nicira, Inc.

#======================================================================
#
#                          IGMP v1/v2
#
#                        1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 3 3
#    0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1
#   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
#   | Ver * | Type  | MRT/Unused ** | Checksum                      |
#   +-------+-------+---------------+-------------------------------+
#   | Group Address                                                 |
#   +-------------------------------+-------------------------------+
#
#   *  In v2, there is no Version field, and Type is the whole 8 bits
#   ** Max Response Time in v2 only
#
#======================================================================

#TODO: Support for IGMP v3

import struct
from packet_utils import *
from packet_base import packet_base
from pox.lib.addresses import *

MEMBERSHIP_QUERY     = 0x11
MEMBERSHIP_REPORT    = 0x12
MEMBERSHIP_REPORT_V2 = 0x16
LEAVE_GROUP_V2       = 0x17

# IGMP multicast address
IGMP_ADDRESS = IPAddr("224.0.0.22")

# IGMP IP protocol
IGMP_PROTOCOL = 2

class igmp (packet_base):
  """
  IGMP Message
  """

  MIN_LEN = 8
  IGMP_ADDRESS = IGMP_ADDRESS
  IGMP_PROTOCOL = IGMP_PROTOCOL

  MEMBERSHIP_QUERY     = MEMBERSHIP_QUERY
  MEMBERSHIP_REPORT    = MEMBERSHIP_REPORT
  MEMBERSHIP_REPORT_V2 = MEMBERSHIP_REPORT_V2
  LEAVE_GROUP_V2       = LEAVE_GROUP_V2

  def __init__(self, raw=None, prev=None, **kw):
    packet_base.__init__(self)

    self.prev = prev

    self.ver_and_type = 0
    self.max_response_time = 0
    self.csum = 0
    self.address = None
    self.extra = b''

    if raw is not None:
      self.parse(raw)

    self._init(kw)

  def hdr (self, payload):
    s = struct.pack("!BBHi", self.ver_and_type, self.max_response_time,
                    0, self.address.toSigned(networkOrder=False))
    s += self.extra
    self.csum = checksum(s)
    s = struct.pack("!BBHi", self.ver_and_type, self.max_response_time,
                    self.csum, self.address.toSigned(networkOrder=False))
    s += self.extra
    return s

  def parse (self, raw):
    assert isinstance(raw, bytes)
    self.raw = raw
    dlen = len(raw)
    if dlen < self.MIN_LEN:
      self.msg('packet data too short to parse')
      return None

    self.ver_and_type, self.max_response_time, self.csum, ip = \
        struct.unpack("!BBHi", raw[:self.MIN_LEN])
    self.extra = raw[self.MIN_LEN:]

    self.address = IPAddr(ip, networkOrder = False)

    s = struct.pack("!BBHi", self.ver_and_type, self.max_response_time,
                    0, self.address.toSigned(networkOrder=False))
    s += self.extra
    csum = checksum(s)
    if csum != self.csum:
      self.err("IGMP hecksums don't match")
    else:
      self.parsed = True

  def __str__ (self):
    s = "[IGMP "
    s += "vt:%02x %s" % (self.ver_and_type, self.address)
    return s + "]"

########NEW FILE########
__FILENAME__ = ipv4
# Copyright 2011 James McCauley
# Copyright 2008 (C) Nicira, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at:
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# This file is derived from the packet library in NOX, which was
# developed by Nicira, Inc.

#======================================================================
#
#                          IPv4 Header Format
#
#    0                   1                   2                   3
#    0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1
#   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
#   |Version|  IHL  |Type of Service|          Total Length         |
#   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
#   |         Identification        |Flags|      Fragment Offset    |
#   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
#   |  Time to Live |    Protocol   |         Header Checksum       |
#   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
#   |                       Source Address                          |
#   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
#   |                    Destination Address                        |
#   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
#   |                    Options                    |    Padding    |
#   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
#
#======================================================================

import struct
import time
from packet_utils       import *
from tcp import *
from udp import *
from icmp import *
from igmp import *

from packet_base import packet_base

from pox.lib.addresses import IPAddr, IP_ANY, IP_BROADCAST

class ipv4(packet_base):
    "IP packet struct"

    MIN_LEN = 20

    IPv4 = 4
    ICMP_PROTOCOL = 1
    TCP_PROTOCOL  = 6
    UDP_PROTOCOL  = 17
    IGMP_PROTOCOL = 2

    DF_FLAG = 0x02
    MF_FLAG = 0x01

    ip_id = int(time.time())

    def __init__(self, raw=None, prev=None, **kw):
        packet_base.__init__(self)

        self.prev = prev

        self.v     = 4
        self.hl    = ipv4.MIN_LEN / 4
        self.tos   = 0
        self.iplen = ipv4.MIN_LEN
        ipv4.ip_id = (ipv4.ip_id + 1) & 0xffff
        self.id    = ipv4.ip_id
        self.flags = 0
        self.frag  = 0
        self.ttl   = 64
        self.protocol = 0
        self.csum  = 0
        self.srcip = IP_ANY
        self.dstip = IP_ANY
        self.next  = b''

        if raw is not None:
            self.parse(raw)

        self._init(kw)

    def __str__(self):
        s = "[IP+%s %s>%s (cs:%02x v:%s hl:%s l:%s t:%s)]" % (
            ipproto_to_str(self.protocol),
            self.srcip, self.dstip,
            self.csum,
            self.v, self.hl, self.iplen, self.ttl)

        return s

    def parse(self, raw):
        assert isinstance(raw, bytes)
        self.next = None # In case of unfinished parsing
        self.raw = raw
        dlen = len(raw)
        if dlen < ipv4.MIN_LEN:
            self.msg('warning IP packet data too short to parse header: data len %u' % (dlen,))
            return

        (vhl, self.tos, self.iplen, self.id, self.frag, self.ttl,
            self.protocol, self.csum, self.srcip, self.dstip) \
             = struct.unpack('!BBHHHBBHII', raw[:ipv4.MIN_LEN])

        self.v = vhl >> 4
        self.hl = vhl & 0x0f

        self.flags = self.frag >> 13
        self.frag  = self.frag & 0x1fff

        self.dstip = IPAddr(self.dstip)
        self.srcip = IPAddr(self.srcip)

        if self.v != ipv4.IPv4:
            self.msg('(ip parse) warning IP version %u not IPv4' % self.v)
            return
        elif self.hl < 5:
            self.msg('(ip parse) warning IP header %u longer than len %u' \
                        % (self.hl, self.iplen))
            return
        elif self.iplen < ipv4.MIN_LEN:
            self.msg('(ip parse) warning invalid IP len %u' % self.iplen)
            return
        elif (self.hl * 4) >= self.iplen or (self.hl * 4) > dlen:
            self.msg('(ip parse) warning IP header %u longer than len %u' \
                        % (self.hl, self.iplen))
            return

        # At this point, we are reasonably certain that we have an IP
        # packet
        self.parsed = True

        length = self.iplen
        if length > dlen:
            length = dlen # Clamp to what we've got
        if self.protocol == ipv4.UDP_PROTOCOL:
            self.next = udp(raw=raw[self.hl*4:length], prev=self)
        elif self.protocol == ipv4.TCP_PROTOCOL:
            self.next = tcp(raw=raw[self.hl*4:length], prev=self)
        elif self.protocol == ipv4.ICMP_PROTOCOL:
            self.next = icmp(raw=raw[self.hl*4:length], prev=self)
        elif self.protocol == ipv4.IGMP_PROTOCOL:
            self.next = igmp(raw=raw[self.hl*4:length], prev=self)
        elif dlen < self.iplen:
            self.msg('(ip parse) warning IP packet data shorter than IP len: %u < %u' % (dlen, self.iplen))
        else:
            self.next =  raw[self.hl*4:length]

        if isinstance(self.next, packet_base) and not self.next.parsed:
            self.next = raw[self.hl*4:length]

    def checksum(self):
        data = struct.pack('!BBHHHBBHII', (self.v << 4) + self.hl, self.tos,
                                 self.iplen, self.id,
                                 (self.flags << 13) | self.frag, self.ttl,
                                 self.protocol, 0, self.srcip.toUnsigned(),
                                 self.dstip.toUnsigned())
        return checksum(data, 0)


    def hdr(self, payload):
        self.iplen = self.hl * 4 + len(payload)
        self.csum = self.checksum()
        return struct.pack('!BBHHHBBHII', (self.v << 4) + self.hl, self.tos,
                           self.iplen, self.id,
                           (self.flags << 13) | self.frag, self.ttl,
                           self.protocol, self.csum, self.srcip.toUnsigned(),
                           self.dstip.toUnsigned())

########NEW FILE########
__FILENAME__ = ipv6
# Copyright 2012,2013 James McCauley
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at:
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.


#======================================================================
#
#                          IPv6 Header Format
#
#    0                   1                   2                   3
#    0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1
#   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
#   |Version| Traffic Class |              Flow Label               |
#   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
#   |         Payload Length        |  Next Header  |   Hop Limit   |
#   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
#   |                                                               |
#   |                       Source Address                          |
#   |                                                               |
#   |                                                               |
#   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
#   |                                                               |
#   |                    Destination Address                        |
#   |                                                               |
#   |                                                               |
#   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
#
#======================================================================

"""
IPv6 packet classes

This is still rough.  There are a number of things remaining to do
(additional extension header types, payload inference), and there
are probably places where the API isn't quite right yet.  But it's
a start.
"""

import struct
from packet_utils import *
from tcp import *
from udp import *
from icmpv6 import *

from packet_base import packet_base

from pox.lib.addresses import IPAddr6
from pox.lib.util import init_helper


_extension_headers = {}

def extension_header_def (header_type):
  """
  Extension Header decorator
  """
  #TODO: Switch to using generic class registry
  def f (cls):
    _extension_headers[header_type] = cls
    cls.TYPE = header_type
    return cls
  return f


class ExtensionHeader (object):
  next_header_type = None


class NormalExtensionHeader (ExtensionHeader):
  """
  A superclass for many ExtensionHeaders

  Many Extension Headers follow the same basic format, which is also suggested
  for future Extension Headers in RFC 6564.
  """

  #TYPE = <type number>

  def __init__ (self, *args, **kw):
    self.payload_length = 0
    self._init(*args, **kw)

    init_helper(self, kw)

  def __len__ (self):
    """
    Returns the packed length
    """
    l = self.payload_length + 2
    return ((l + 7) / 8) - 1

  @classmethod
  def unpack_new (cls, raw, offset = 0, max_length = None):
    """
    Unpacks a new instance of this class from a buffer

    returns (new_offset, object)
    """
    if max_length and max_length < 2:
      raise TruncatedException()
    nh,l = struct.unpack_from("!BB", raw, offset)
    max_length -= 2
    l = l * 8 + 6
    if max_length is not None and max_length < l:
      raise TruncatedException()
    offset += 2
    d = cls._unpack_body(raw, offset, nh, l)
    offset += l
    d['payload_length'] = l
    d['next_header_type'] = nh
    return offset, cls(**d)

  def pack (self):
    o = struct.pack("!BB", self.next_header_type, len(self))
    return o + self._pack_body()

  def _init (self, *args, **kw):
    """
    Called during initialization

    Override me
    """
    pass

  def _pack_body (self):
    """
    Returns the body of this Extension Header packed into bytes

    Override me
    """
    return b''

  @classmethod
  def _unpack_body (cls, raw, offset, next_header_type, length):
    """
    Unpacks the body portion of an Extension Header

    Override me.
    """
    return {}


class FixedExtensionHeader (ExtensionHeader):
  """
  A superclass for fixed length Extension Headers
  """

  #TYPE = <type number>
  #LENGTH = <total length in bytes>

  def __init__ (self, *args, **kw):
    self.next_header_type = None
    self._init(*args, **kw)

    init_helper(self, kw)

  def __len__ (self):
    """
    Returns the packed length
    """
    return self.LENGTH

  @classmethod
  def unpack_new (cls, raw, offset = 0, max_length = None):
    """
    Unpacks a new instance of this class from a buffer
    """
    if max_length is not None and (max_length - offset) < cls.LENGTH:
      raise TruncatedException()

    nh = struct.unpack_from("!B", raw, offset)[0]
    d = cls._unpack_body(raw, offset + 1, nh, cls.LENGTH - 1)
    offset += cls.LENGTH
    d['next_header_type'] = nh
    return offset, cls(**d)

  def pack (self):
    o = struct.pack("!B", self.next_header_type) + self._pack_body()
    assert len(o) == self.LENGTH, "Bad packed length"
    return o

  def _init (self, *args, **kw):
    """
    Called during initialization

    Override me
    """
    pass

  def _pack_body (self):
    """
    Returns the body of this Extension Header packed into bytes

    Override me
    """
    return b''

  @classmethod
  def _unpack_body (self, raw, offset, next_header_type, length):
    """
    Unpacks the body portion of an Extension Header

    Override me.
    """
    return {}


class DummyExtensionHeader (NormalExtensionHeader):
  """
  Just saves the raw body data
  """
  def _init (self, *args, **kw):
    self.raw_body = b''
  def _pack_body (self):
    return self.raw_body
  @classmethod
  def _unpack_body (self, raw, offset, next_header_type, length):
    return {'raw_body':raw[offset:offset+length]}


class DummyFixedExtensionHeader (FixedExtensionHeader):
  """
  Just saves the raw body data
  """
  def _init (self, *args, **kw):
    self.raw_body = '\x00' * (self.LENGTH - 1)
  def _pack_body (self):
    return self.raw_body
  @classmethod
  def _unpack_body (self, raw, offset, next_header_type, length):
    return {'raw_body':raw[offset:offset+length]}


#TODO: Implement Extension Headers for real (they're pretty much just
#      placeholders at present)
#TODO: Implement the IPSec options (Authentication and ESP)

@extension_header_def(0)
class HopByHopOptions (DummyExtensionHeader):
  pass

@extension_header_def(43)
class Routing (DummyExtensionHeader):
  pass

@extension_header_def(44)
class Fragment (DummyFixedExtensionHeader):
  LENGTH = 8
  pass

@extension_header_def(60)
class DestinationOptions (DummyExtensionHeader):
  pass


class ipv6 (packet_base):
  """
  IPv6 packet class
  """

  MIN_LEN = 40

  ICMP6_PROTOCOL = 58
  TCP_PROTOCOL  = 6
  UDP_PROTOCOL  = 17
  IGMP_PROTOCOL = 2
  NO_NEXT_HEADER = 59

  def __init__ (self, raw=None, prev=None, **kw):
    packet_base.__init__(self)

    self.prev = prev

    self.v     = 6
    self.tc    = 0
    self.flow  = 0
    self.payload_length = 0
    self.next_header_type = None
    self.hop_limit = 0
    self.srcip = IPAddr6.UNDEFINED
    self.dstip = IPAddr6.UNDEFINED
    self.extension_headers = []

    self.next  = b''

    if raw is not None:
      self.parse(raw)

    self._init(kw)

  @property
  def payload_type (self):
    """
    The last header type
    """
    if len(self.extension_headers):
      if isinstance(self.extension_headers[-1], ExtensionHeader):
        return self.extension_headers[-1].next_header_type
    else:
      return self.next_header_type
    return None

  @payload_type.setter
  def payload_type (self, value):
    if len(self.extension_headers):
      if isinstance(self.extension_headers[-1], ExtensionHeader):
        self.extension_headers[-1].next_header_type = value
      else:
        raise RuntimeError("Can't set payload_type")
    else:
      self.next_header_type = value

  def parse (self, raw, offset=0):
    assert isinstance(raw, bytes)
    self.next = None # In case of unfinished parsing
    self.raw = raw
    if len(raw) < self.MIN_LEN:
      self.msg('warning IP packet data too short to parse header:'
               ' data len %u' % (len(raw),))
      return

    (vtcfl, self.payload_length, nht, self.hop_limit) \
        = struct.unpack('!IHBB', raw[offset:offset+8])
    self.srcip = IPAddr6(raw[offset+8:offset+24], raw=True)
    self.dstip = IPAddr6(raw[offset+24:offset+40], raw=True)
    self.next_header_type = nht
    offset += 40

    self.v = vtcfl >> 28
    self.tc = (vtcfl >> 20) & 0xff
    self.flow = vtcfl & 0xfffff

    if self.v != 6:
      self.msg('ip parse) warning IP version %u not IPv6' % self.v)
      return

    length = self.payload_length
    if length > len(raw):
      length = len(raw) # Clamp to what we've got
      self.msg('(ipv6) warning IP packet data incomplete (%s of %s)'
               % (len(raw), self.payload_length))

    while nht != ipv6.NO_NEXT_HEADER:
      c = _extension_headers.get(nht)
      if c:
        if length < 8:
          self.msg('(ipv6) warning, packet data incomplete')
          return
        try:
          offset,o = c.unpack_new(raw, offset, max_length = length)
          length -= len(o)
        except TruncatedException:
          self.msg('(ipv6) warning, packet data truncated')
          return
        self.extension_headers.append(o)
        nht = o.next_header_type
      else:
        break

    self.parsed = True

    #TODO: This should be done a better way (and shared with IPv4?).
    if nht == self.UDP_PROTOCOL:
      self.next = udp(raw=raw[offset:offset+length], prev=self)
    elif nht == self.TCP_PROTOCOL:
      self.next = tcp(raw=raw[offset:offset+length], prev=self)
    elif nht == self.ICMP6_PROTOCOL:
      self.next = icmpv6(raw=raw[offset:offset+length], prev=self)
#    elif nht == self.IGMP_PROTOCOL:
#      self.next = igmp(raw=raw[offset:offset+length], prev=self)
    elif nht == self.NO_NEXT_HEADER:
      self.next = None
    else:
      self.next =  raw[offset:offset+length]

    if isinstance(self.next, packet_base) and not self.next.parsed:
      self.next = raw[offset:offset+length]

  def add_header (self, eh):
    if self.extension_headers:
      assert isinstance(self.extension_headers[-1], ExtensionHeader)
      self.extension_headers[-1].next_header_type = eh.TYPE
    else:
      self._next_header_type = eh.TYPE

  def hdr (self, payload):
    vtcfl = self.v << 28
    vtcfl |= (self.flow & 0xfffff)
    vtcfl |= (self.tc & 0xff) << 20

    if self.next_header_type is None:
      if self.extension_headers:
        nht = self.extension_headers[0].TYPE
      else:
        #TODO: We should infer this?
        assert False, "Must set next header type"
    else:
      nht = self.next_header_type

    self.next_header_type = nht #FIXME: this is a hack

    # Ugh, this is also an ugly hack
    if hasattr(payload, 'pack'):
      self.payload_length = len(payload.pack())
    else:
      self.payload_length = len(payload)


    r = struct.pack("!IHBB", vtcfl, self.payload_length, nht, self.hop_limit)
    r += self.srcip.raw
    r += self.dstip.raw

    return r

  def _to_str (self):
    ehs = [ipproto_to_str(self.next_header_type)]
    for eh in self.extension_headers:
      ehs.append(ipproto_to_str(eh.next_header_type))
    s = "IPv6 %s>%s" % (self.srcip, self.dstip)
    return "[" + s + " " + "+".join(ehs) + "]"

  #def __str__ (self):
  #  s = "[IP%s+%s %s>%s (hl:%s)]" % (
  #      self.v,
  #      ipproto_to_str(self.next_header_type),
  #      self.srcip, self.dstip, self.hop_limit)
  #  return s

########NEW FILE########
__FILENAME__ = llc
# Copyright 2013 James McCauley
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at:
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import struct

from packet_base import packet_base
from ethernet import ethernet

from packet_utils import *


class llc (packet_base):
  "802.2 LLC header, possibly with SNAP header"

  MIN_LEN = 3

  def __init__ (self, raw=None, prev=None, **kw):
    packet_base.__init__(self)

    self.prev = prev

    self.next = None

    self.length = self.MIN_LEN
    self.dsap = None
    self.ssap = None
    self.control = None
    self.oui = None #FIXME: Stored as bytes; lib.addresses uses ints.
    self.eth_type = ethernet.INVALID_TYPE

    if raw is not None:
        self.parse(raw)

    self._init(kw)

  @property
  def has_snap (self):
    return self.oui is not None

  def __str__ (self):
    #TODO: include field values!
    s = "[LLC"
    if self.has_snap:
      s += "+SNAP t:%04x" % (self.eth_type,)
    else:
      s += " ssap:0x%02x dsap:0x%02x c:%s" % (self.ssap, self.dsap,
                                              self.control)
    s += "]"
    return s

  def parse (self, raw):
    assert isinstance(raw, bytes)
    self.raw = raw
    dlen = len(raw)
    if dlen < self.MIN_LEN:
      self.msg('(llc parse) warning: packet data too short')
      return

    self.length = 3
    (self.dsap, self.ssap, self.control) \
        = struct.unpack('!BBB', raw[:self.MIN_LEN])
    if ((self.control & 1) == 0) or ((self.control & 3) == 2):
      if dlen < self.length + 1:
        self.msg('(llc parse) warning: packet data too short')
        return
      self.control |= (ord(raw[3:4]) << 8)
      self.length = 4

    if (self.ssap & 0xfe) == 0xaa:
      if (self.dsap & 0xfe) == 0xaa:
        # Oh snap
        if dlen < self.length + 5:
          self.msg('(llc parse) warning: incomplete SNAP')
          return
        self.oui = raw[self.length:self.length+3]
        self.length += 3
        self.eth_type = struct.unpack("!H", raw[self.length:self.length+2])[0]
        self.length += 2

    self.parsed = True

    if self.oui == '\0\0\0':
      self.next = ethernet.parse_next(self, self.eth_type, raw, self.length,
                                      allow_llc = False)
    else:
      self.next = raw[self.length:]

  @property
  def effective_ethertype (self):
    return ethernet._get_effective_ethertype(self)

  @property
  def type (self):
    """
    This is just an alias for eth_type.

    It's annoying that the ethertype on an ethernet packet is in the
    'type' attribute, and for vlan/llc it's in the 'eth_type' attribute.
    We should probably normalize this. For now, we at least have this.
    """
    return self.eth_type

  def hdr (self, payload):
    r = struct.pack("!BB", self.dsap, self.ssap)
    if self.length == 3 or self.length == 8:
      # One byte control
      r += struct.pack("!B", self.control)
    else:
      #FIXME: this is sloppy
      r += chr(self.control & 0xff)
      r += chr((self.control>>8) & 0xff)
    if self.has_snap:
      # SNAP
      r += self.oui
      r += struct.pack("!H", self.eth_type)
    return r

########NEW FILE########
__FILENAME__ = lldp
# Copyright 2012 James McCauley
# Copyright 2008 (C) Nicira, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at:
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# This file is derived from the packet library in NOX, which was
# developed by Nicira, Inc.

#======================================================================
# IEEE 802.1AB Link Layer Discovery Protocol (lldp) header
# (http://standards.ieee.org/getieee802/download/802.1AB-2005.pdf)
#
# Copyright (C) 2007 Nicira Networks
#
# Ethernet type = 0x88cc
# Destination MAC = 01:80:c2:00:00:0e (LLDP_MULTICAST)
#
# LLDPDU format
#
# +------+-----+-----+-------+-------+------+---------+---------------+
# | Chassis ID |   Port ID   | TTL   | Optional ......| End of LLDPDU |
# |    TLV     |    TLV      | TLV   |
# +------+-----+-----+-------+-------+------+---------+---------------+
#
# TLV Format
#
# +------------+---------------------+--------------------------------+
# |  TLV type  | TLV information     |  TLV information string        |
# |            | string length       |                                |
# +------------+---------------------+--------------------------------+
#
# TLV Types:
#
# 0   - end of LLDPDU
# 1   - Chassis ID
# 2   - Port ID
# 3   - TTL
# 4   - Port description (optional)
# 5   - System name
# 6   - System description
# 7   - System capabilities
# 8   - Management address
# 127 - Organization specific TLVs
# 9-126 - reserved
#
# TODO:
# Error handling (malformed packets will definately cause this to puke)
#
#======================================================================

import struct
import time
from packet_utils import *

from packet_base import packet_base
from pox.lib.addresses import EthAddr
from pox.lib.util import initHelper

import logging
lg = logging.getLogger('packet')

#======================================================================
#                        LLDP PDU
#======================================================================

class lldp (packet_base):
  "802.1 AB lldp pdu"

  # chassis ID min = 2 + 1 + 1
  # PORT    ID min = 2 + 1 + 1
  # TTL        min = 2 + 2
  # End        min = 2
  MIN_LEN = (4 + 4 + 4 + 2 )

  #TODO: Remove these from here (they should be at module scope)?
  END_TLV         = 0
  CHASSIS_ID_TLV  = 1
  PORT_ID_TLV     = 2
  TTL_TLV         = 3
  PORT_DESC_TLV   = 4
  SYSTEM_NAME_TLV = 5
  SYSTEM_DESC_TLV = 6
  SYSTEM_CAP_TLV  = 7
  MANAGEMENT_ADDR_TLV = 8
  ORGANIZATIONALLY_SPECIFIC_TLV = 127

  tlv_parsers = {}

  def __init__ (self, raw=None, prev=None, **kw):
    packet_base.__init__(self)

    self.prev = prev

    self.next = None
    self.tlvs = []

    if raw is not None:
      self.parse(raw)

    self._init(kw)

  def next_tlv(self, array):

    if len(array) < 2:
      self.msg('(lldp tlv parse) warning TLV data too short to read '
               + 'type/len (%u)' % (len(array),))
      return

    (typelen,) = struct.unpack("!H",array[0:2])

    type = typelen >> 9
    length = typelen & 0x01ff

    if len(array) < length:
      self.msg('(lldp tlv parse) warning TLV data too short to parse (%u)'
               % (len(array),))
      return

    if type in lldp.tlv_parsers:
      self.tlvs.append(lldp.tlv_parsers[type](array[0: 2 + length]))
      return 2 + length
    else:
      self.msg('(lldp tlv parse) warning unknown tlv type (%u)'
               % (type,))
      self.tlvs.append(unknown_tlv(array[0: 2 + length]))
      return 2 + length

  def parse (self, raw):
    assert isinstance(raw, bytes)
    self.raw = raw
    dlen = len(raw)
    if dlen < lldp.MIN_LEN:
      self.msg('(lldp parse) warning LLDP packet data too short to parse '
               + 'header: data len %u' % (dlen,))
      return

    # point to the beginning of the pdu
    pduhead = 0

    # get Chassis ID
    ret = self.next_tlv(raw)
    if ret == None:
      self.msg( '(lldp parse) error parsing chassis ID tlv' )
      return
    pduhead += ret
    if self.tlvs[len(self.tlvs)-1].tlv_type != lldp.CHASSIS_ID_TLV:
      self.msg( '(lldp parse) error CHASSIS ID TLV missing' )
      return

    # get PORT ID
    ret = self.next_tlv(raw[pduhead:])
    if ret is None:
      self.msg( '(lldp parse) error parsing port ID TLV' )
      return
    pduhead += ret
    if self.tlvs[len(self.tlvs)-1].tlv_type != lldp.PORT_ID_TLV:
      self.msg( '(lldp parse) error port ID TLV missing' )
      return

    # get  TTL
    ret = self.next_tlv(raw[pduhead:])
    if ret == None:
      self.msg( '(lldp parse) error parsing TTL TLV' )
      return
    pduhead += ret
    if self.tlvs[len(self.tlvs)-1].tlv_type != lldp.TTL_TLV:
      self.msg( '(lldp parse) error port TTL TLV missing' )
      return

    # Loop over all other TLVs
    arr_len = len(raw)
    while True:
      ret = self.next_tlv(raw[pduhead:])
      if ret == None:
        self.msg( '(lldp parse) error parsing TLV' )
        return
      if self.tlvs[len(self.tlvs)-1].tlv_type == lldp.END_TLV:
        break
      if (pduhead + ret) >= arr_len:
        self.msg( '(lldp parse) error end of TLV list without END TLV' )
        return
      pduhead += ret

    self.parsed = True

  def add_tlv (self, tlv):
    self.tlvs.append(tlv)

  def __str__ (self):
    lstr = ''
    for tlv in self.tlvs:
      lstr += str(tlv)
    return '[LLDP ' + lstr + ']'

  def hdr (self, payload):
    packet = b''
    for tlv in self.tlvs:
      packet += tlv.pack()
    return packet


#======================================================================
#                          TLV definitions
#======================================================================

#NOTE: As with a bunch of the packet library, it'd be nice if things
#      like TLVs inherited from some base class common to other
#      "sub-packets" (and maybe even packets).

class tlv_base (object):
  """
  Supertype for LLDP TLVs
  """
  pass


class simple_tlv (tlv_base):
  tlv_type = None # Purposely illegal

  def __init__ (self, raw = None, **kw):
    self._init(kw)
    self.parsed   = False

    if raw is not None:
      self.parse(raw)

    self._init_helper(kw)

  def _init_helper (self, kw):
    if len(kw):
      if 'payload' in kw:
        self.payload = None
      initHelper(self, kw)
      self.parsed = True

  def parse (self, raw):
    # assume lldp has done the type/len checking
    (typelen,) = struct.unpack("!H", raw[0:2])
    tlv_type = typelen >> 9
    if self.tlv_type is not None:
      assert self.tlv_type == tlv_type
    self.tlv_type = tlv_type

    strlen = typelen & 0x01ff

    data = raw[2:2+strlen]
    if len(data) < strlen:
      raise TruncatedException()

    self._parse_data(data)
    self.parsed = True

  @property
  def strlen (self):
    return self._data_len()

  def pack (self):
    typelen = self.tlv_type << 9
    data = self._pack_data()
    typelen |= (len(data) & 0x01ff)
    return struct.pack('!H', typelen) + data

  def __str__ (self):
    return "<" + self.__class__.__name__ + ">"


  def _init (self, kw):
    """
    Initialize subclass-specific fields

    Override this.
    """
    pass

  def _data_len (self):
    """
    Returns length of the TLV information string

    Override this.
    """
    return len(self._pack_data())

  def _parse_data (self, data):
    """
    Store TLV information string

    Override this.
    """
    self.payload = data

  def _pack_data (self):
    """
    Return TLV information string

    Override this.
    """
    return self.payload


class unknown_tlv (simple_tlv):
  """
  Unknown TLVs are parsed into this class
  """
  tlv_type = None


class chassis_id (simple_tlv):
  tlv_type = lldp.CHASSIS_ID_TLV

  SUB_CHASSIS  = 1 # IETF RFC 2737
  SUB_IF_ALIAS = 2 # IETF RFC 2863
  SUB_PORT     = 3 # IETF RFC 2737
  SUB_MAC      = 4 # IEEE Std 802-2001
  SUB_NETWORK  = 5 #
  SUB_IF_NAME  = 6 # IETF RFC 2863
  SUB_LOCAL    = 7

  subtype_to_str = {}
  subtype_to_str[SUB_CHASSIS]  = "chassis"
  subtype_to_str[SUB_IF_ALIAS] = "interface alias"
  subtype_to_str[SUB_PORT]     = "port"
  subtype_to_str[SUB_MAC]      = "mac"
  subtype_to_str[SUB_NETWORK]  = "network"
  subtype_to_str[SUB_IF_NAME]  = "interface name"
  subtype_to_str[SUB_LOCAL]    = "local"

  def _init (self, kw):
    self.subtype  = 0
    self.id       = None

  def _parse_data (self, data):
    if len(data) < 2:
      raise MalformedException("TLV has invalid strlen")

    (self.subtype,) = struct.unpack("!B",data[0:1])
    self.id = data[1:]

  def _pack_data (self):
    return struct.pack("!B", self.subtype) + self.id

  def __str__ (self):
    if self.subtype == chassis_id.SUB_MAC:
      assert len(self.id) == 6
      id_str = str(EthAddr(self.id))
    else:
      id_str = ":".join(["%02x" % (ord(x),) for x in self.id])

    return ''.join(['<chasis ID:',id_str,'>'])


class port_id (simple_tlv):
  tlv_type = lldp.PORT_ID_TLV

  SUB_IF_ALIAS = 1 # IETF RFC 2863
  SUB_PORT     = 2 # IETF RFC 2737
  SUB_MAC      = 3 # IEEE Std 802-2001
  SUB_NETWORK  = 4 #
  SUB_IF_NAME  = 5 # IETF RFC 2863
  SUB_CIRC_ID  = 6 # IETF RFC 3046
  SUB_LOCAL    = 7

  subtype_to_str = {}
  subtype_to_str[SUB_IF_ALIAS] = "interface alias"
  subtype_to_str[SUB_PORT]     = "port"
  subtype_to_str[SUB_MAC]      = "mac"
  subtype_to_str[SUB_NETWORK]  = "network"
  subtype_to_str[SUB_IF_NAME]  = "interface name"
  subtype_to_str[SUB_CIRC_ID]  = "agent circuit ID"
  subtype_to_str[SUB_LOCAL]    = "local"

  def _init (self, kw):
    self.subtype = 0
    self.id      = None

  def _parse_data (self, data):
    if len(data) < 2:
      raise MalformedException("TLV has invalid strlen")

    (self.subtype,) = struct.unpack("!B",data[0:1])
    self.id = data[1:]

  def __str__ (self):
    if self.subtype == chassis_id.SUB_MAC:
      assert len(self.id) == 6
      id_str = str(EthAddr(self.id))
    else:
      id_str = ":".join(["%02x" % (ord(x),) for x in self.id])

    return ''.join(['<port ID:',id_str,'>'])

  def _pack_data (self):
    return struct.pack("!B", self.subtype) + self.id


class ttl (simple_tlv):
  tlv_type = lldp.TTL_TLV

  def _init (self, kw):
    self.ttl = 0

  def _parse_data (self, data):
    if len(data) != 2:
      raise MalformedException("TLV has invalid strlen (!= 2)")
    (self.ttl,) = struct.unpack("!H",data[0:2])

  def __str__ (self):
    return ''.join(['<ttl:',str(self.ttl),'>'])

  def _pack_data (self):
    return struct.pack('!H', self.ttl)


class end_tlv (simple_tlv):
  tlv_type = lldp.END_TLV

  def _parse_data (self, data):
    if len(data) != 0:
      raise MalformedException("TLV has invalid strlen (!= 0)")

  def __str__ (self):
    return '<tlv end>'

  def _pack_data (self):
    return b''


class system_description (simple_tlv):
  tlv_type = lldp.SYSTEM_DESC_TLV


class management_address (simple_tlv):
  tlv_type = lldp.MANAGEMENT_ADDR_TLV

  def _init (self, kw):
    self.address_subtype = 0
    self.address = b''
    self.interface_numbering_subtype = 0
    self.interface_number = 0
    self.object_identifier = b''

  def _parse_data (self, data):
    asl = ord(data[0]) - 1
    self.address_subtype = ord(data[1])
    self.address = data[2:2+asl]

    self.interface_numbering_subtype = ord(data[2+asl])
    self.interface_number = struct.unpack("!L",
                                      data[2+asl+1:2+asl+1+4])[0]
    osl = ord(data[7+asl])
    self.object_identifier = data[7+asl+1:7+asl+1+osl]

  def _data_len (self):
    return 1+1+len(self.address)+1+4+1+len(self.object_identifier)

  def _pack_data (self):
    r = struct.pack('!BB', len(self.address)+1, self.address_subtype)
    r += self.address
    r += struct.pack("!BLB", self.interface_numbering_subtype,
                     self.interface_number,
                     len(self.object_identifier))
    r += self.object_identifier
    return r


class system_name (simple_tlv):
  tlv_type = lldp.SYSTEM_NAME_TLV


class organizationally_specific (simple_tlv):
  tlv_type = lldp.ORGANIZATIONALLY_SPECIFIC_TLV

  def _init (self, kw):
    self.oui = '\x00\x00\x00'
    self.subtype = 0
    self.payload = b''

  def _parse_data (self, data):
    (self.oui,self.subtype) = struct.unpack("3sB", data[0:4])
    self.payload = data[4:]

  def _pack_data (self):
    return struct.pack('!3sB', self.oui, self.subtype) + self.payload


class port_description (simple_tlv):
  tlv_type = lldp.PORT_DESC_TLV


class system_capabilities (simple_tlv):
  tlv_type = lldp.SYSTEM_CAP_TLV

  cap_names = ["Other", "Repeater", "Bridge", "WLAN Access Point",
         "Router", "Telephone", "DOCSIS cable device",
         "Station Only"]

  def _init (self, kw):
    self.caps = [False] * 16
    self.enabled_caps = [False] * 16

  def _parse_data (self, data):
    (cap,en) = struct.unpack("!HH", data)
    del self.caps[:]
    del self.enabled_caps[:]
    for i in range(0, 16):
      self.caps.append(True if (cap and (1 << i)) else False)
      self.enabled_caps.append(True if (en and (1 << i)) else False)

  def _pack_data (self):
    cap = 0
    en = 0
    for i in range(0, 16):
      if self.caps[i]: cap |= (1 << i)
      if self.enabled_caps[i]: en |= (1 << i)
    return struct.pack('!HH', cap, en)

  def __str__ (self):
    r = []
    for i in range(0, 16):
      if self.caps[i]:
        if i < len(self.cap_names):
            s = self.cap_names[i]
        else:
            s = "Capability " + str(i)
        s += ":" + ("On" if self.enabled_caps[i] else "Off")
        r.append(s)
    return "<Capabilities: " + ', '.join(r) + ">"


# Add parsers to main lldp class
for t in [chassis_id, port_id, ttl, system_name, system_description,
      end_tlv, organizationally_specific, port_description,
      system_capabilities, management_address]:
  lldp.tlv_parsers[t.tlv_type] = t

########NEW FILE########
__FILENAME__ = mpls
# Copyright 2011,2013 James McCauley
# Copyright 2008 (C) Nicira, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at:
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# This file is derived from the packet library in NOX, which was
# developed by Nicira, Inc.

#======================================================================
#
#                     MPLS tag format
#
#    0               1               2               3             4
#    0 1 2 3 4 5 6 7 0 1 2 3 4 5 6 7 0 1 2 3 4 5 6 7 0 1 2 3 4 5 6 7
#   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
#   |              LABEL                    |  TC |S|    TTL        |
#   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
#
#======================================================================
import struct

from packet_base import packet_base
from ethernet import ethernet

from packet_utils import *


class mpls(packet_base):
    "mpls header"

    MIN_LEN = 4

    def __init__(self, raw=None, prev=None, **kw):
        packet_base.__init__(self)

        self.prev = prev

        self.next = None
        self.label = 0
        self.tc = 0
        self.s = 0
        self.ttl = 0
        if raw is not None:
            self.parse(raw)
        self._init(kw)

    def __str__(self):
        s = "[MPLS " + str(self.label)
        if self.tc: s += " " + str(self.tC)
        if self.s: s += " bos"
        s += " ttl=" + str(self.ttl) + "]"
        return s

    def parse(self, raw):
        assert isinstance(raw, bytes)
        self.raw = raw
        dlen = len(raw)
        if dlen < mpls.MIN_LEN:
            self.msg('(mpls parse) warning MPLS packet data too short to '
                     + 'parse header: data len %u' % (dlen,))
            return

        (label_high, label_low_tc_s, self.ttl) = \
            struct.unpack("!HBB", raw[:mpls.MIN_LEN])
        self.s = label_low_tc_s & 0x1
        self.tc = ((label_low_tc_s & 0xf) >> 1)
        self.label = (label_high << 4) | (label_low_tc_s >> 4)
        self.parsed = True
        if dlen >= 8 and not self.s:
          try:
            self.next = mpls(raw[mpls.MIN_LEN:])
            return
          except:
            # Recursion depth?
            pass
        self.next = raw[mpls.MIN_LEN:]

    def hdr(self, payload):
        label = self.label & 0xfffff
        tc = self.tc & 0x7
        s = self.s & 0x1
        ttl = self.ttl & 0xff
        label_high = label >> 4
        label_low_tc_s = ((label & 0xf) << 4) | (tc << 1) | s
        buf = struct.pack('!HBB', label_high, label_low_tc_s, ttl)
        return buf

########NEW FILE########
__FILENAME__ = packet_base
# Copyright 2011 James McCauley
# Copyright 2008 (C) Nicira, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at:
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# This file is derived from the packet library in NOX, which was
# developed by Nicira, Inc.

import logging
lg = logging.getLogger('packet')

from pox.lib.util import initHelper

class packet_base (object):
    """
    TODO: This description is somewhat outdated and should be fixed.

    Base class for packets.

    Classes that perform packet manipulation (parsing and contruction)
    should derive from this class.

    The general layout of such a subclass is as follows:

    class foo (packet_base):

        def __init__(data=None, prev=None):
          packet_base.__init__(self)

          # data: is the data for the packet as a "bytes" object.
          # prev: is a pointer to the previous header
          # which is expected to be of type packet_base
          self.parsed = False
          self.prev = prev

          # define field variables here
          self.bar = 0

          if arr != None:
              self.data = data # Phasing out?
              self.parse(data)

        def parse(self, data):
            # parse packet here and set member variables
            self.parsed = True # signal that packet was succesfully parsed

        def hdr(self, payload):
            # return fields as a string
            return struct.pack('!I',self.bar)

        def __str__(self):
            # optionally convert to human readable string
    """
    def __init__ (self):
        self.next = None
        self.prev = None
        self.parsed = False
        self.raw = None

    def _init (self, kw):
        if 'payload' in kw:
          self.set_payload(kw['payload'])
          del kw['payload']
        initHelper(self, kw)

    def msg(self, *args):
        """ Shortcut for logging """
        #TODO: Remove?
        lg.info(*args)

    def err(self, *args):
        """ Shortcut for logging """
        #TODO: Remove?
        lg.error(*args)

    def warn(self, *args):
        """ Shortcut for logging """
        #TODO: Remove?
        lg.warning(*args)

    def __nonzero__(self):
        return self.parsed is True

    def __len__(self):
        return len(self.pack())

    def __str__(self):
        if hasattr(self, "_to_str"):
          try:
            return self._to_str()
          except Exception as e:
            #import traceback
            #traceback.print_exc()
            lg.debug("str(%s): %s" % (self.__class__.__name__, e))
          return "[%s:Bad representation]" % (self.__class__.__name__,)
        return "[%s l:%i%s]" % (self.__class__.__name__, len(self),
            "" if self.next else " *")

    def dump(self):
        p = self
        m = []
        while p is not None:
          if not isinstance(p, packet_base):
            if isinstance(p, bytes):
              if len(p) == 0:
                m.append("[0 bytes]")
                break
              s = ''
              for t in range(min(len(p), 5)):
                s += "%02x " % (ord(p[t]),)
              if len(p) > 5: s += "..."
              s = s.rstrip()
              m.append("[%s bytes: " % (len(p),) + s + "]")
              break
            try:
              l = len(p)
              m.append("[%s l:%i]" % (p.__class__.__name__, l))
            except:
              m.append("[%s]" % (p.__class__.__name__,))
            break
          m.append(str(p))
          p = p.next
        return "".join(m)

    def find(self, proto):
        """
        Find the specified protocol layer based on its class type or name.
        """
        if not isinstance(proto, basestring):
            proto = proto.__name__
        if self.__class__.__name__ == proto and self.parsed:
            return self
        else:
            if self.next and isinstance(self.next, packet_base):
                return self.next.find(proto)
            else:
                return None

    @property
    def payload (self):
        """
        The packet payload property.
        Reading this property is generally the same as the "next" field.
        Setting this generally sets this packet's "next" field, as well as
        setting the new payload's "prev" field to point back to its new
        container (the same as the set_payload() method).
        """
        return self.next

    @payload.setter
    def payload (self, new_payload):
      self.set_payload(new_payload)

    def set_payload(self, payload):
        '''
        Set the packet payload.  Expects bytes or a packet_base subclass.
        '''
        if isinstance(payload, packet_base):
            self.next    = payload
            payload.prev = self
        elif type(payload) == bytes:
            self.next = payload
        else:
            raise TypeError("payload must be string or packet subclass")

    def parse(self, raw):
        '''Override me with packet parsing code'''
        raise NotImplementedError("parse() not implemented")

    def pre_hdr(self):
        '''Override to prepare before payload is packed'''
        pass

    def hdr(self, payload):
        '''Override me to return packet headers'''
        raise NotImplementedError("hdr() not implemented")

    @classmethod
    def unpack (cls, raw, prev=None):
        return cls(raw=raw, prev=prev)

    def pack(self):
        '''Convert header and payload to bytes'''

        if self.parsed is False and self.raw is not None and self.next is None:
          return self.raw

        self.pre_hdr()

        if self.next == None:
            return self.hdr(b'')
        elif isinstance(self.next, packet_base):
            rest = self.next.pack()
        else:
            rest = self.next

        return self.hdr(rest) + rest

########NEW FILE########
__FILENAME__ = packet_utils
# Copyright 2011,2012 James McCauley
# Copyright 2008 (C) Nicira, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at:
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# This file is derived from the packet library in NOX, which was
# developed by Nicira, Inc.

"""
Various functionality and data for the packet library
"""

import array
import struct
from socket import ntohs

_ethtype_to_str = {}
_ipproto_to_str = {}

# Map ethernet type to string
_ethtype_to_str[0x0800] = 'IP'
_ethtype_to_str[0x0806] = 'ARP'
_ethtype_to_str[0x8035] = 'RARP'
_ethtype_to_str[0x8100] = 'VLAN'
_ethtype_to_str[0x88cc] = 'LLDP'
_ethtype_to_str[0x888e] = 'PAE'
_ethtype_to_str[0x8847] = 'MPLS'
_ethtype_to_str[0x8848] = 'MPLS_MC' # Multicast
_ethtype_to_str[0x86dd] = 'IPV6'
_ethtype_to_str[0x880b] = 'PPP'
_ethtype_to_str[0x88bb] = 'LWAPP'
_ethtype_to_str[0x880c] = 'GSMP'
_ethtype_to_str[0x8137] = 'IPX'
_ethtype_to_str[0x0842] = 'WOL' # Wake On LAN
_ethtype_to_str[0x22f3] = 'TRILL'
_ethtype_to_str[0x8870] = 'JUMBO'
_ethtype_to_str[0x889a] = 'SCSI' # SCSI Over Ethernet
_ethtype_to_str[0x88a2] = 'ATA' # ATA Over Ethernet
_ethtype_to_str[0x9100] = 'QINQ'
_ethtype_to_str[0xffff] = 'BAD'


# IP protocol to string
#TODO: This should probably be integrated with the decorator used in
#      the ipv6 module.
_ipproto_to_str[0]  = 'HOP_OPTS'
_ipproto_to_str[1]  = 'ICMP'
_ipproto_to_str[2]  = 'IGMP'
_ipproto_to_str[4]  = 'IPIP'
_ipproto_to_str[6]  = 'TCP'
_ipproto_to_str[9]  = 'IGRP'
_ipproto_to_str[17] = 'UDP'
_ipproto_to_str[43] = 'IPV6_ROUTING'
_ipproto_to_str[44] = 'IPV6_FRAG'
_ipproto_to_str[47] = 'GRE'
_ipproto_to_str[58] = 'ICMP6'
_ipproto_to_str[59] = 'IPV6_NO_NEXT'
_ipproto_to_str[60] = 'DEST_OPTS'
_ipproto_to_str[89] = 'OSPF'


class MalformedException (RuntimeError):
  pass


class TruncatedException (RuntimeError):
  pass


def checksum (data, start = 0, skip_word = None):
  """
  Calculate standard internet checksum over data starting at start'th byte

  skip_word: If specified, it's the word offset of a word in data to "skip"
             (as if it were zero).  The purpose is when data is received
             data which contains a computed checksum that you are trying to
             verify -- you want to skip that word since it was zero when
             the checksum was initially calculated.
  """
  if len(data) % 2 != 0:
    arr = array.array('H', data[:-1])
  else:
    arr = array.array('H', data)

  if skip_word is not None:
    for i in range(0, len(arr)):
      if i == skip_word:
        continue
      start +=  arr[i]
  else:
    for i in range(0, len(arr)):
      start +=  arr[i]

  if len(data) % 2 != 0:
    start += struct.unpack('H', data[-1]+'\0')[0] # Specify order?

  start  = (start >> 16) + (start & 0xffff)
  start += (start >> 16)
  #while start >> 16:
  #  start = (start >> 16) + (start & 0xffff)

  return ntohs(~start & 0xffff)


def ethtype_to_str (t):
  """
  Given numeric ethernet type or length, return human-readable representation
  """
  if t <= 0x05dc:
    return "802.3/%04x" % (t,)
  return _ethtype_to_str.get(t, "%04x" % (t,))


def ipproto_to_str (t):
  """
  Given a numeric IP protocol number (or IPv6 next_header), give human name
  """
  if t in _ipproto_to_str:
    return _ipproto_to_str[t]
  else:
    return "%02x" % (t,)

########NEW FILE########
__FILENAME__ = rip
# Copyright 2012 James McCauley
# Copyright 2008 (C) Nicira, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at:
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# This file is derived from the packet library in NOX, which was
# developed by Nicira, Inc.

#======================================================================
#
#                           RIP Message Format
#
#                        1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 3 3
#    0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1
#   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
#   | Command       | Version       | Zero                          |
#   +---------------+---------------+-------------------------------+
#   |                                                               |
#   / RIP Entry (20 bytes)                                          /
#   /                                                               /
#   +---------------------------------------------------------------+
#
#
#                               RIP Entry
#
#                        1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 3 3
#    0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1
#   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
#   | Address Family                | Route Tag *                   |
#   +-------------------------------+-------------------------------+
#   | IP Address                                                    |
#   +---------------------------------------------------------------+
#   | Subnet Mask *                                                 |
#   +---------------------------------------------------------------+
#   | Next Hop *                                                    |
#   +---------------------------------------------------------------+
#   | Metric                                                        |
#   +---------------------------------------------------------------+
#
#   * RIP v2 only -- all zeros in RIP v1
#
#======================================================================

import struct
from packet_utils import *
from packet_base import packet_base
from pox.lib.addresses import *

# RIP v2 multicast address
RIP2_ADDRESS = IPAddr("224.0.0.9")

# RIP v1/v2 UDP port
RIP_PORT = 520

RIP_REQUEST = 1
RIP_RESPONSE = 2

class rip (packet_base):
  """
  RIP Message
  """

  MIN_LEN = 24
  RIP_PORT = RIP_PORT
  RIP2_ADDRESS = RIP2_ADDRESS

  def __init__(self, raw=None, prev=None, **kw):
    packet_base.__init__(self)

    self.prev = prev

    self.entries = []

    self.command = 0
    self.version = 0

    if raw is not None:
      self.parse(raw)

    self._init(kw)

  def hdr (self, payload):
    s = struct.pack("!BBH", self.command, self.version, 0)
    for e in self.entries:
      s += e.pack()
    return s

  def parse (self, raw):
    assert isinstance(raw, bytes)
    self.raw = raw
    dlen = len(raw)
    if dlen < self.MIN_LEN:
      self.msg('RIP packet data too short to parse')
      return None

    self.command, self.version, z = struct.unpack("!BBH", raw[:4])
    if z != 0:
      self.err("Zero field in RIP message not zero!")
      return None

    self.entries = []

    raw = raw[4:]
    while len(raw) >= 20:
      try:
        self.entries.append(RIPEntry(raw=raw[0:20]))
      except Exception, e:
        self.err('Exception parsing RIP entries: ' + str(e))
        return None
      raw = raw[20:]
    if len(raw) != 0:
      self.err('RIP had partial entry?  %s bytes left' % (len(raw),))

    self.parsed = True

  def __str__ (self):
    cmd = {RIP_REQUEST:"REQ",RIP_RESPONSE:"RESP"}.get(self.command,
                                                      str(self.command))

    s = "[RIP ver:%i cmd:%s num:%i|" % (self.version,
        cmd, len(self.entries))
    for e in self.entries:
      s += str(e) + "|"
    s = s[:-1] + "]"
    return s
RIPMessage = rip


class RIPEntry (packet_base):
  def __init__ (self, raw=None, prev=None, **kw):
    #TODO: netmask initializer?
    packet_base.__init__(self)

    self.address_family = 0
    self.route_tag = 0
    self.ip = None # IPAddr; bad default is to force setting
    self._netmask = 0 # An IPAddr, but netmask property lets you assign a
                      # dotquad string or an integer number of bits.
    self.next_hop = IP_ANY
    self.metric = 0

    if raw is not None:
      self.parse(raw)
    self._init(kw)

  @property
  def netmask (self):
    return self._netmask

  @netmask.setter
  def netmask (self, netmask):
    if isinstance(netmask, int):
      netmask = cidr_to_netmask(netmask)
    elif not isintance(netmask, IPAddr):
      netmask = IPAddr(netmask)
    self._netmask = netmask

  @property
  def network_bits (self):
    """
    Returns the number of network bits.  May raise an exception
    if the netmask is not CIDR-compatible.
    """
    return netmask_to_cidr(self._netmask)

  @network_bits.setter
  def network_bits (self, bits):
    self._netmask = cidr_to_netmask(bits)

  def hdr (self, payload):
    s = struct.pack("!HHiiii", self.address_family, self.route_tag,
                    self.ip.toSigned(networkOrder=False),
                    self.netmask.toSigned(networkOrder=False),
                    self.next_hop.toSigned(networkOrder=False),
                    self.metric)

    return s

  def parse (self, raw):
    self.address_family, self.route_tag, ip, netmask, next_hop, self.metric \
     = struct.unpack("!HHiiii", raw)
    self.ip = IPAddr(ip, networkOrder = False)
    self._netmask = IPAddr(netmask, networkOrder = False)
    self.next_hop = IPAddr(next_hop, networkOrder = False)

  def __str__ (self):
    s = "tag:%s ip:%s/%s nh:%s m:%s" % (self.route_tag, self.ip,
        self._netmask, self.next_hop, self.metric)
    return s

########NEW FILE########
__FILENAME__ = tcp
# Copyright 2011 James McCauley
# Copyright 2008 (C) Nicira, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at:
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# This file is derived from the packet library in NOX, which was
# developed by Nicira, Inc.

#======================================================================
#
#                           TCP Header Format
#
#   0                   1                   2                   3
#   0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1
#  +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
#  |          Source Port          |       Destination Port        |
#  +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
#  |                        Sequence Number                        |
#  +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
#  |                    Acknowledgment Number                      |
#  +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
#  |  Data |           |U|A|P|R|S|F|                               |
#  | Offset| Reserved  |R|C|S|S|Y|I|            Window             |
#  |       |           |G|K|H|T|N|N|                               |
#  +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
#  |           Checksum            |         Urgent Pointer        |
#  +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
#  |                    Options                    |    Padding    |
#  +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
#  |                             data                              |
#  +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
#
#======================================================================

import struct
from packet_utils       import *
from socket import htons
from socket import htonl

from packet_base import packet_base

import logging
lg = logging.getLogger('packet')

class tcp_opt:

    EOL      = 0
    NOP      = 1
    MSS      = 2
    WSOPT    = 3
    SACKPERM = 4
    SACK     = 5
    TSOPT    = 8

    def __init__(self, type, val):
        self.type = type
        self.val  = val

    def to_bytes(self):
        if self.type == tcp_opt.EOL or self.type == tcp_opt.NOP:
            return struct.pack('B',self.type)
        elif self.type == tcp_opt.MSS:
            return struct.pack('!BBH',self.type,4,self.val)
        elif self.type == tcp_opt.WSOPT:
            return struct.pack('!BBB',self.type,3,self.val)
        elif self.type == tcp_opt.SACKPERM:
            return struct.pack('!BB',self.type,2)
        elif self.type == tcp_opt.SACK:
            return struct.pack("!" + "II" * len(self.val),
                               *[x for p in self.val for x in p])
        elif self.type == tcp_opt.TSOPT:
            return struct.pack('!BBII',self.type,10,self.val[0],self.val[1])
        else:
            lg.info('(tcp_opt to_bytes) warning, unknown option type ' +
                    str(self.type))
            return ''

class tcp(packet_base):
    "TCP packet struct"

    MIN_LEN = 20

    FIN_flag = 0x01
    SYN_flag = 0x02
    RST_flag = 0x04
    PSH_flag = 0x08
    ACK_flag = 0x10
    URG_flag = 0x20
    ECN_flag = 0x40
    CWR_flag = 0x80

    @property
    def FIN (self): return True if self.flags & self.FIN_flag else False
    @property
    def SYN (self): return True if self.flags & self.SYN_flag else False
    @property
    def RST (self): return True if self.flags & self.RST_flag else False
    @property
    def PSH (self): return True if self.flags & self.PSH_flag else False
    @property
    def ACK (self): return True if self.flags & self.ACK_flag else False
    @property
    def URG (self): return True if self.flags & self.URG_flag else False
    @property
    def ECN (self): return True if self.flags & self.ECN_flag else False
    @property
    def CWR (self): return True if self.flags & self.CWR_flag else False

    @FIN.setter
    def FIN (self, value): self._setflag(self.FIN_flag, value)
    @SYN.setter
    def SYN (self, value): self._setflag(self.SYN_flag, value)
    @RST.setter
    def RST (self, value): self._setflag(self.RST_flag, value)
    @PSH.setter
    def PSH (self, value): self._setflag(self.PSH_flag, value)
    @ACK.setter
    def ACK (self, value): self._setflag(self.ACK_flag, value)
    @URG.setter
    def URG (self, value): self._setflag(self.URG_flag, value)
    @ECN.setter
    def ECN (self, value): self._setflag(self.ECN_flag, value)
    @CWR.setter
    def CWR (self, value): self._setflag(self.CWR_flag, value)

    def _setflag (self, flag, value):
      self.flags = (self.flags & ~flag) | (flag if value else 0)

    def __init__(self, raw=None, prev=None, **kw):
        packet_base.__init__(self)

        self.prev = prev

        self.srcport  = 0  # 16 bit
        self.dstport  = 0  # 16 bit
        self.seq      = 0  # 32 bit
        self.ack      = 0  # 32 bit
        self.off      = 0  # 4 bits
        self.res      = 0  # 4 bits
        self.flags    = 0  # reserved, 2 bits flags 6 bits
        self.win      = 0  # 16 bits
        self.csum     = 0  # 16 bits
        self.urg      = 0  # 16 bits
        self.tcplen   = 0  # Options? #TODO: FIXME
        self.options  = []
        self.next     = b''

        if raw is not None:
            self.parse(raw)

        self._init(kw)

    def __str__(self):
        f = ''
        if self.SYN: f += 'S'
        if self.ACK: f += 'A'
        if self.FIN: f += 'F'
        if self.RST: f += 'R'
        if self.PSH: f += 'P'
        if self.URG: f += 'U'
        if self.ECN: f += 'E'
        if self.CWR: f += 'C'

        s = '[TCP %s>%s seq:%s ack:%s f:%s]' % (self.srcport,
            self.dstport, self.seq, self.ack, f)

        return s

    def parse_options(self, raw):

        self.options = []
        dlen = len(raw)

        # option parsing
        i = tcp.MIN_LEN
        arr = raw

        while i < self.hdr_len:
            # Single-byte options
            if ord(arr[i]) == tcp_opt.EOL:
                break
            if ord(arr[i]) == tcp_opt.NOP:
                self.options.append(tcp_opt(tcp_opt.NOP,None))
                i += 1
                continue

            # Sanity checking
            if i + 2 > dlen:
                raise RuntimeError("Very truncated TCP option")
            if i + ord(arr[i+1]) > dlen:
                raise RuntimeError("Truncated TCP option")
            if ord(arr[i+1]) < 2:
                raise RuntimeError("Illegal TCP option length")

            # Actual option parsing
            if ord(arr[i]) == tcp_opt.MSS:
                if ord(arr[i+1]) != 4:
                    raise RuntimeError("MSS option length != 4")
                val = struct.unpack('!H',arr[i+2:i+4])[0]
                self.options.append(tcp_opt(tcp_opt.MSS,val))
            elif ord(arr[i]) == tcp_opt.WSOPT:
                if ord(arr[i+1]) != 3:
                    raise RuntimeError("WSOPT option length != 3")
                self.options.append(tcp_opt(tcp_opt.WSOPT, ord(arr[i+2])))
            elif ord(arr[i]) == tcp_opt.SACKPERM:
                if ord(arr[i+1]) != 2:
                    raise RuntimeError("SACKPERM option length != 2")
                self.options.append(tcp_opt(tcp_opt.SACKPERM, None))
            elif ord(arr[i]) == tcp_opt.SACK:
                if ord(arr[i+1]) >= 2 and ((ord(arr[i+1])-2) % 8) == 0:
                    num = (ord(arr[i+1]) - 2) / 8
                    val = struct.unpack("!" + "II" * num, arr[i+2:])
                    val = [(x,y) for x,y in zip(val[0::2],val[1::2])]
                    self.options.append(tcp_opt(tcp_opt.SACK, val))
                else:
                    raise RuntimeError("Invalid SACK option")
            elif ord(arr[i]) == tcp_opt.TSOPT:
                if ord(arr[i+1]) != 10:
                    raise RuntimeError("TSOPT option length != 10")
                (val1,val2) = struct.unpack('!II',arr[i+2:i+10])
                self.options.append(tcp_opt(tcp_opt.TSOPT,(val1,val2)))
            else:
                self.msg('(tcp parse_options) warning, unknown option %x '
                         % (ord(arr[i]),))
                self.options.append(tcp_opt(ord(arr[i]), arr[i+2:i+2+ord(arr[i+1])]))

            i += ord(arr[i+1])
        return i

    def parse(self, raw):
        assert isinstance(raw, bytes)
        self.next = None # In case of unfinished parsing
        self.raw = raw
        dlen = len(raw)
        if dlen < tcp.MIN_LEN:
            self.msg('(tcp parse) warning TCP packet data too short to parse header: data len %u' % (dlen,))
            return

        (self.srcport, self.dstport, self.seq, self.ack, offres, self.flags,
        self.win, self.csum, self.urg) \
            = struct.unpack('!HHIIBBHHH', raw[:tcp.MIN_LEN])

        self.off = offres >> 4
        self.res = offres & 0x0f

        self.hdr_len = self.off * 4
        self.payload_len = dlen - self.hdr_len

        self.tcplen = dlen
        if dlen < self.tcplen:
            self.msg('(tcp parse) warning TCP packet data shorter than TCP len: %u < %u' % (dlen, self.tcplen))
            return
        if (self.off * 4) < self.MIN_LEN or (self.off * 4) > dlen :
            self.msg('(tcp parse) warning TCP data offset too long or too short %u' % (self.off,))
            return

        try:
            self.parse_options(raw)
        except Exception as e:
            self.msg(e)
            return

        self.next   = raw[self.hdr_len:]
        self.parsed = True

    def hdr(self, payload, calc_checksum = True):
        if calc_checksum:
            self.csum = self.checksum(payload=payload)
            csum = self.csum
        else:
            csum = 0

        offres = self.off << 4 | self.res
        packet = struct.pack('!HHIIBBHHH',
            self.srcport, self.dstport, self.seq, self.ack,
            offres, self.flags,
            self.win, csum, self.urg)
        for option in self.options:
            packet += option.to_bytes()
        return packet

    def checksum(self, unparsed=False, payload=None):
        """
        Calculates the checksum.
        If unparsed, calculates it on the raw, unparsed data.  This is
        useful for validating that it is correct on an incoming packet.
        """
        ip_ver = None
        if self.prev.__class__.__name__  == 'ipv4':
          ip_ver = 4
        elif self.prev.__class__.__name__  == 'ipv6':
          ip_ver = 6
        else:
          self.msg('packet not in IP; cannot calculate checksum ' +
                    'over psuedo-header' )
          return 0

        if unparsed:
            payload_len = len(self.raw)
            payload = self.raw
        else:
            if payload is not None:
                pass
            elif isinstance(self.next, packet_base):
                payload = self.next.pack()
            elif self.next is None:
                payload = bytes()
            else:
                payload = self.next
            payload = self.hdr(None, calc_checksum = False) + payload
            payload_len = len(payload)

        if ip_ver == 4:
            ph = struct.pack('!IIBBH', self.prev.srcip.toUnsigned(),
                                       self.prev.dstip.toUnsigned(),
                                       0,
                                       self.prev.protocol,
                                       payload_len)

            return checksum(ph + payload, 0, 14)
        elif ip_ver == 6:
            ph = self.prev.srcip.raw + self.prev.dstip.raw
            ph += struct.pack('!IHBB', payload_len, 0, 0,
                              self.prev.next_header_type)

            return checksum(ph + payload, 0, 28)

########NEW FILE########
__FILENAME__ = udp
# Copyright 2011 James McCauley
# Copyright 2008 (C) Nicira, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at:
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# This file is derived from the packet library in NOX, which was
# developed by Nicira, Inc.

#======================================================================
#
#                            UDP Header Format
#
#                  0      7 8     15 16    23 24    31
#                 +--------+--------+--------+--------+
#                 |     Source      |   Destination   |
#                 |      Port       |      Port       |
#                 +--------+--------+--------+--------+
#                 |                 |                 |
#                 |     Length      |    Checksum     |
#                 +--------+--------+--------+--------+
#                 |
#                 |          data octets ...
#                 +---------------- ...
#======================================================================
import struct
from packet_utils import *
from dhcp import *
from dns  import *
from rip  import *

from packet_base import packet_base

# We grab ipv4 later to prevent cyclic dependency
#_ipv4 = None

class udp(packet_base):
    "UDP packet struct"

    MIN_LEN = 8

    def __init__(self, raw=None, prev=None, **kw):
        #global _ipv4
        #if not _ipv4:
        #  from ipv4 import ipv4
        #  _ipv4 = ipv4

        packet_base.__init__(self)

        self.prev = prev

        self.srcport = 0
        self.dstport = 0
        self.len = 8
        self.csum = 0

        if raw is not None:
            self.parse(raw)

        self._init(kw)

    def __str__(self):
        s = '[UDP %s>%s l:%s c:%02x]' % (self.srcport, self.dstport,
                                         self.len, self.csum)
        return s

    def parse(self, raw):
        assert isinstance(raw, bytes)
        self.raw = raw
        dlen = len(raw)
        if dlen < udp.MIN_LEN:
            self.msg('(udp parse) warning UDP packet data too short to parse header: data len %u' % dlen)
            return

        (self.srcport, self.dstport, self.len, self.csum) \
            = struct.unpack('!HHHH', raw[:udp.MIN_LEN])

        self.hdr_len = udp.MIN_LEN
        self.payload_len = self.len - self.hdr_len
        self.parsed = True

        if self.len < udp.MIN_LEN:
            self.msg('(udp parse) warning invalid UDP len %u' % self.len)
            return

        #TODO: DHCPv6, etc.

        if (self.dstport == dhcp.SERVER_PORT
                    or self.dstport == dhcp.CLIENT_PORT):
            self.next = dhcp(raw=raw[udp.MIN_LEN:],prev=self)
        elif (self.dstport == dns.SERVER_PORT
                    or self.srcport == dns.SERVER_PORT):
            self.next = dns(raw=raw[udp.MIN_LEN:],prev=self)
        elif (self.dstport == dns.MDNS_PORT
                    or self.srcport == dns.MDNS_PORT):
            self.next = dns(raw=raw[udp.MIN_LEN:],prev=self)
        elif ( (self.dstport == rip.RIP_PORT
                or self.srcport == rip.RIP_PORT) ):
#               and isinstance(self.prev, _ipv4)
#               and self.prev.dstip == rip.RIP2_ADDRESS ):
            self.next = rip(raw=raw[udp.MIN_LEN:],prev=self)
        elif dlen < self.len:
            self.msg('(udp parse) warning UDP packet data shorter than UDP len: %u < %u' % (dlen, self.len))
            return
        else:
            self.payload = raw[udp.MIN_LEN:]


    def hdr(self, payload):
        self.len = len(payload) + udp.MIN_LEN
        self.csum = self.checksum()
        return struct.pack('!HHHH', self.srcport, self.dstport, self.len, self.csum)

    def checksum(self, unparsed=False):
        """
        Calculates the checksum.
        If unparsed, calculates it on the raw, unparsed data.  This is
        useful for validating that it is correct on an incoming packet.
        """

        ip_ver = None
        if self.prev.__class__.__name__  == 'ipv4':
          ip_ver = 4
        elif self.prev.__class__.__name__  == 'ipv6':
          ip_ver = 6
        else:
          self.msg('packet not in IP; cannot calculate checksum ' +
                    'over psuedo-header' )
          return 0

        if unparsed:
            payload_len = len(self.raw)
            payload = self.raw
        else:
            if isinstance(self.next, packet_base):
                payload = self.next.pack()
            elif self.next is None:
                payload = bytes()
            else:
                payload = self.next
            payload_len = udp.MIN_LEN + len(payload)

            myhdr = struct.pack('!HHHH', self.srcport, self.dstport,
                                payload_len, 0)
            payload = myhdr + payload

        if ip_ver == 4:
            ph = struct.pack('!IIBBH', self.prev.srcip.toUnsigned(),
                                       self.prev.dstip.toUnsigned(),
                                       0,
                                       self.prev.protocol,
                                       payload_len)
            r = checksum(ph + payload, 0, 9)
            return 0xffff if r == 0 else r
        elif ip_ver == 6:
            ph = self.prev.srcip.raw + self.prev.dstip.raw
            ph += struct.pack('!IHBB', payload_len, 0, 0,
                              self.prev.next_header_type)
            r = checksum(ph + payload, 0, 23)
            return 0xffff if r == 0 else r

########NEW FILE########
__FILENAME__ = vlan
# Copyright 2011 James McCauley
# Copyright 2008 (C) Nicira, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at:
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# This file is derived from the packet library in NOX, which was
# developed by Nicira, Inc.

#======================================================================
#
#                      802.1q VLAN Header Format
#
#    0                   1                   2                   3
#    0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1
#   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
#   | PCP  |C|       VLANID         |       Encapsualted protocol   |
#   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
#
#======================================================================

import struct

from packet_base import packet_base
from ethernet import ethernet

from packet_utils       import *


class vlan(packet_base):
    "802.1q vlan header"

    MIN_LEN = 4

    def __init__(self, raw=None, prev=None, **kw):
        packet_base.__init__(self)

        self.prev = prev

        self.next = None

        self.pcp      = 0
        self.cfi      = 0
        self.id       = 0
        self.eth_type = 0

        if raw is not None:
            self.parse(raw)

        self._init(kw)

    def __str__(self):
        s = "[VLAN vlan={0} pcp={1} ether={2}]".format(self.id, self.pcp,
            ethtype_to_str(self.eth_type))
        return s

    def parse(self, raw):
        assert isinstance(raw, bytes)
        self.raw = raw
        dlen = len(raw)
        if dlen < vlan.MIN_LEN:
            self.msg('(vlan parse) warning VLAN packet data too short to '
                     + 'parse header: data len %u' % (dlen,))
            return

        (pcpid, self.eth_type) = struct.unpack("!HH", raw[:vlan.MIN_LEN])

        self.pcp = pcpid >> 13
        self.cfi = pcpid  & 0x1000
        self.id  = pcpid  & 0x0fff

        self.parsed = True

        self.next = ethernet.parse_next(self,self.eth_type,raw,vlan.MIN_LEN)

    @property
    def effective_ethertype (self):
      return ethernet._get_effective_ethertype(self)

    @property
    def type (self):
        """
        This is just an alias for eth_type.

        It's annoying that the ethertype on an ethernet packet is in the
        'type' attribute, and for vlan it's in the 'eth_type' attribute.
        We should probably normalize this. For now, we at least have this.
        """
        return self.eth_type

    def hdr (self, payload):
        pcpid  = self.pcp << 13
        pcpid |= self.cfi << 12
        pcpid |= self.id
        buf = struct.pack("!HH", pcpid, self.eth_type)
        return buf

########NEW FILE########
__FILENAME__ = dump_trace
# Copyright 2012,2013 James McCauley
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at:
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""
A simple hack of info.packet_dump that dumps pcap files to the console.

Use --infile=<filename> to specify the pcap file.
Use --verbose for really verbose dumps.
Use --show to show all packets.
Use --show=<types> to show specific types.
Use --hide=<types> to hide specific types.
Use --max-length=<chars> to limit line lengths.
"""

#TODO: Refactor with packet_dump

from pox.core import core
import pox.openflow.libopenflow_01 as of
import pox.lib.packet as pkt
from pox.lib.util import dpidToStr
import pox.lib.pxpcap.parser as pxparse
import pox.lib.pxpcap.writer as pxwriter

log = core.getLogger()

_verbose = None
_max_length = None
_types = None
_show_by_default = None


def cb (data, parser):
  packet = pkt.ethernet(data)

  #print "%04x %4s %s" % (d.effective_ethertype,len(d),d.dump())

  show = _show_by_default
  p = packet
  while p:
    if p.__class__.__name__.lower() in _types:
      if _show_by_default:
        # This packet is hidden
        return
      else:
        # This packet should be shown
        show = True
        break
      return
    if not hasattr(p, 'next'): break
    p = p.next

  if not show: return

  msg = ""
  if _verbose:
    msg += packet.dump()
  else:
    p = packet
    while p:
      if isinstance(p, basestring):
        msg += "[%s bytes]" % (len(p),)
        break
      msg += "[%s]" % (p.__class__.__name__,)
      p = p.next

  if _max_length:
    if len(msg) > _max_length:
      msg = msg[:_max_length-3]
      msg += "..."
  #core.getLogger("dump").info(msg)
  print msg


def launch (infile, verbose = False, max_length = 110,
            hide = False, show = False):
  global _verbose, _max_length, _types, _show_by_default
  _verbose = verbose
  if max_length is True or max_length == '0':
    _max_length = None
  else:
    _max_length = int(max_length)
  force_show = (show is True) or (hide is False and show is False)
  if isinstance(hide, basestring):
    hide = hide.replace(',', ' ').replace('|', ' ')
    hide = set([p.lower() for p in hide.split()])
  else:
    hide = set()
  if isinstance(show, basestring):
    show = show.replace(',', ' ').replace('|', ' ')
    show = set([p.lower() for p in show.split()])
  else:
    show = set()

  if hide and show:
    raise RuntimeError("Can't both show and hide packet types")

  if show:
    _types = show
  else:
    _types = hide
  _show_by_default = not not hide
  if force_show:
    _show_by_default = force_show

  data = open(infile, "r").read()
  p = pxparse.PCapParser(callback=cb)
  p.feed(data)

  core.quit()

########NEW FILE########
__FILENAME__ = parser
# Copyright 2012 James McCauley
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at:
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""
A parser for pcap data files.

It's not great, but does the job for now.
"""

#TODO:
# Swap names for _sec and _time?
# Add usec to the datetime one?

from datetime import datetime
from struct import unpack_from

class PCapParser (object):
  def __init__ (self, callback = None):
    self._buf = b''
    self._proc = self._proc_global_header
    self._prefix = ''
    self.version = None
    self.snaplen = None
    self.lltype = None

    self.callback = callback

  def _packet (self, data):
    if self.callback:
      self.callback(data, self)

  def _unpack (self, format, data, offset = 0):
    return unpack_from(self._prefix + format, data, offset)

  def _proc_global_header (self):
    header_len = 4 + 2 + 2 + 4 + 4 + 4 + 4
    if len(self._buf) < header_len: return

    magic = self._buf[0:4]
    header = self._buf[4:header_len]

    if magic == "\xd4\xc3\xb2\xa1":
      self._prefix = "<"
    elif magic == "\xa1\xb2\xc3\xd4":
      self._prefix = ">"
    else:
      raise RuntimeError("Wrong magic number")

    major,minor = self._unpack("HH", header[:4])
    self.version = float("%s.%s" % (major,minor))

    if self.version != 2.4:
      raise RuntimeError("Unknown PCap version: %s" % (self.version,))

    tz,accuracy,self.snaplen,self.lltype = self._unpack("LLLL", header[4:])

    self._buf = self._buf[header_len:]
    self._proc = self._proc_header

  def _proc_header (self):
    if len(self._buf) < 16: return
    self._sec_raw,self._usec,self._cap_size, self._wire_size \
        = self._unpack("LLLL", self._buf[:16])
    self._buf = self._buf[16:]
    self._proc = self._proc_packet

  @property
  def _sec (self):
    return datetime.fromtimestamp(self._sec_raw)

  @property
  def _time (self):
    s = self._sec_raw
    s += self._usec / 1000000.0
    return s

  def _proc_packet (self):
    if len(self._buf) < self._cap_size: return
    data = self._buf[:self._cap_size]
    self._buf = self._buf[self._cap_size:]
    self._proc = self._proc_header
    self._packet(data)

  def feed (self, data):
    self._buf += data

    s = len(self._buf)
    while s > 0:
      self._proc()
      new_s = len(self._buf)
      if new_s == s: break
      s = new_s

########NEW FILE########
__FILENAME__ = strip_openflow
# Copyright 2012,2013 James McCauley
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at:
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""
A hacky tool to grab packet in/out data from OpenFlow traffic.

Assumes packets are 1:1 with OF messages (as if captured using the
openflow.debug component).

 --infile=<filename>   Input file
 --outfile=<filename>  Output file
 --out-only            Don't include packet_ins
 --in-only             Don't include packet_outs
 --openflow-port=<num> Specify OpenFlow TCP port
"""

#TODO: Clean this up, follow multiple control traffic streams, decode
#      TCP, etc.

from pox.core import core
import pox.openflow.libopenflow_01 as of
import pox.lib.packet as pkt
from pox.lib.util import dpidToStr
import pox.lib.pxpcap.parser as pxparse
import pox.lib.pxpcap.writer as pxwriter

log = core.getLogger()

from pox.lib.pxpcap.writer import PCapRawWriter

_writer = None
_of_port = 6633
_in_only = False
_out_only = False

_pis = 0
_pos = 0

def pi_cb (data, parser):
  global _pis, _pos
  packet = pkt.ethernet(data)
  if packet.find('tcp'):
    if packet.find('tcp').dstport == _of_port or \
       packet.find('tcp').srcport == _of_port:
      p = packet.find('tcp').payload
      assert p[0] == '\x01'
      t = ord(p[1])
      packet_length = ord(p[2]) << 8 | ord(p[3])
      if packet_length != len(p):
        log.error("%s != %s" % (packet_length, len(p)))
      if t == of.OFPT_PACKET_IN:
        if _out_only: return
        l,p = of.ofp_packet_in.unpack_new(p)
        _pis += 1
      elif t == of.OFPT_PACKET_OUT:
        if _in_only: return
        l,p = of.ofp_packet_out.unpack_new(p)
        _pos += 1
      else:
        return
      assert l == len(p)

      _writer.write(p.data, time=parser._time, wire_size=parser._wire_size)


def launch (infile, outfile, in_only=False, out_only = False):
  """
  For stripping PI/PO data

  """
  global _writer, _of_port, _in_only, _out_only
  _in_only = in_only
  _out_only = out_only

  data = open(infile, "r").read()
  p = pxparse.PCapParser(callback=pi_cb)
  _writer = pxwriter.PCapRawWriter(open(outfile, "w"))
  p.feed(data)

  log.info("%i packet_ins, %i packet_outs", _pis, _pos)

  core.quit()

########NEW FILE########
__FILENAME__ = writer
# Copyright 2013 James McCauley
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at:
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""
Utilities for writing/synthesizing pcap files
"""

import time as pytime
import datetime
from struct import pack

#TODO: Incorporate the one from lib.socketcapture

class PCapRawWriter (object):
  def __init__ (self, outstream, flush = False):
    """
    outstream is the stream to write the PCAP trace to.
    """
    self._out = outstream
    self._flush = flush

    outstream.write(pack("IHHiIII",
      0xa1b2c3d4,      # Magic
      2,4,             # Version
      pytime.timezone, # TZ offset
      0,               # Accuracy of timestamps (apparently 0 is OK)
      0x7fffFFff,      # Snaplen
      1                # Ethernet
      ))

  def write (self, buf, time = None, wire_size = None):
    if len(buf) == 0: return
    if wire_size is None:
      wire_size = len(buf)

    assert wire_size >= len(buf), "cap size > wire size!"

    if time is None:
      t = pytime.time()
    elif isinstance(time, (datetime.datetime, datetime.time)):
      #TODO: TZ?
      t = pytime.mktime(time.timetuple()) + (time.microsecond / 1000000.0)
    else:
      t = time
    ut = t - int(t)
    t = int(t)
    ut = int(ut * 1000000)
    self._out.write(pack("IIII",
      t,ut,          # Timestamp
      len(buf),      # Saved size
      wire_size,     # Original size
      ))

    self._out.write(buf)
    if self._flush: self._out.flush()

########NEW FILE########
__FILENAME__ = consumer
# Copyright 2013 James McCauley
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at:
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""
Stuff for implementing simple producer/consumer work queues with recoco.
"""

from pox.core import core
from pox.lib.recoco import Task

from collections import deque

log = core.getLogger()

class BaseConsumer (Task):
  """
  A basic consumer for overriding.

  add_work() adds work (whatever that is)
  _do_work is given work and should do something with it
  _on_exception is called if _do_work() raises an exception
  """
  def __init__ (self, batch_size = 1, priority = 1, start = True):
    """
    batch_size is the maximum number of work items per scheduling
    priority is the Task priority
    """
    self.queue = deque() # work items
    self.running = True # Set to false to stop
    self.log = log

    super(BaseConsumer,self).__init__()
    self.priority = priority
    self.batch_size = batch_size
    if start:
      self.start()

  def add_work (self, work):
    """
    Add a work item
    """
    self.queue.appendleft(work)

    # Since we have work, make sure we're scheduled
    core.scheduler.schedule(self)

  def _on_exception (self, exception, work):
    """
    Override to handle cases where a work item causes an exception

    work is the problematic work item

    return True to keep going
    """
    self.log.error("While executing %s...", work)
    self.log.exception(exception)

    return True

  def _do_work (self, work):
    """
    Do work.

    Override me.
    """
    self.log.error("Don't know how to do work for %s!", work)

  def run (self):
    while core.running and self.running:
      for _ in xrange(min(self.batch_size, len(self.queue))):
        work = self.queue.pop()
        try:
          self._do_work(work)
        except Exception as e:
          if self._on_exception(e, work) is not True:
            self.log.debug("Quitting")
            self.running = False
            break

      if len(self.queue) == 0:
        yield False # Don't reschedule
      else:
        yield 0 # Reschedule ASAP (sleep 0)


class FlexConsumer (BaseConsumer):
  """
  A consumer where work items are callables and their parameters
  """
  def add_work (__self, __callable, *__args, **__kw):
    """
    Add a work item

    A work item is a callable with associated args/kwargs.
    """
    super(FlexConsumer, __self).add_work(__callable, __args, __kw)

  def _do_work (self, work):
    f, args, kw = work
    f(*args, **kw)

########NEW FILE########
__FILENAME__ = events
# Copyright 2011 James McCauley
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at:
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import pox.lib.recoco as recoco
import pox.lib.revent as revent
import threading

class ReventWaiter (revent.EventMixin):
  def __init__ (self):
    self.waitEvents = set()
    revent.EventMixin.__init__(self)
    self._events = recoco.deque()
    self._task = None
    self._scheduler = None
    self._wakeLock = threading.Lock()
    self._wakeable = False

  def registerForEvent (self, eventType, once=False, weak=False, priority=None):
    return self.addListener(eventType, self._eventHandler, once, weak, priority)

  def _eventHandler (self, *args, **kw):
    self._events.append((args, kw))
    self._check()

  def _check (self):
    if len(self._events) > 0:
      if self._task != None and self._scheduler != None:
        self._wakeLock.acquire()
        if self._wakeable:
          self._wakeable = False
          self._wakeLock.release()
          self._scheduler.schedule(self._task)
        else:
          self._wakeLock.release()

  def _reset (self):
    self._wakeLock.acquire()
    self._wakeable = True
    self._wakeLock.release()

  def getEvent (self):
    try:
      return self._events.popleft()
    except:
      return None

class WaitOnEvents (recoco.BlockingOperation):
  def __init__ (self, eventWaiter):
    self._waiter = eventWaiter

  def execute (self, task, scheduler):
    #Next two should go into reset()?
    task.rv = self._waiter
    self._waiter._task = task
    self._waiter._scheduler = scheduler
    self._waiter._reset()
    self._waiter._check()

########NEW FILE########
__FILENAME__ = examples
# Copyright 2011 Colin Scott
# Copyright 2011 James McCauley
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at:
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""
These are example uses of the recoco cooperative threading library. Hopefully
they will save time for developers getting used to the POX environment.
"""

from pox.core import core
import pox.openflow.libopenflow_01 as of
from pox.lib.revent import *
from pox.lib.recoco import *

class EventLoopExample (Task):
   """
   Suppose we have a component of our application that uses it's own event
   loop. recoco allows us to "add" our select loop to the other event
   loops running within pox.

   First note that we inherit from Task. The Task class is recoco's equivalent
   of python's threading.thread interface.
   """
   def __init__(self):
     Task.__init__(self)  # call our superconstructor

     self.sockets = self.get_sockets() # ... the sockets to listen to events on

     # Note! We can't start our event loop until the core is up. Therefore,
     # we'll add an event handler.
     core.addListener(pox.core.GoingUpEvent, self.start_event_loop)

   def start_event_loop(self, event):
     """
     Takes a second parameter: the GoingUpEvent object (which we ignore)
     """
     # This causes us to be added to the scheduler's recurring Task queue
     Task.start(self)

   def get_sockets(self):
     return []

   def handle_read_events(self):
      pass

   def run(self):
     """
     run() is the method that gets called by the scheduler to execute this task
      """
     while core.running:
       """
       This looks almost exactly like python's select.select, except that it's
       it's handled cooperatively by recoco

       The only difference in Syntax is the "yield" statement, and the
       capital S on "Select"
       """
       rlist,wlist,elist = yield Select(self.sockets, [], [], 3)
       events = []
       for read_sock in rlist:
         if read_sock in self.sockets:
           events.append(read_sock)

         if events:
           self.handle_read_events() # ...


"""
And that's it!

TODO: write example usages of the other recoco BlockingTasks, e.g. recoco.Sleep
"""

########NEW FILE########
__FILENAME__ = recoco
# Copyright 2011-2013 James McCauley
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at:
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from __future__ import print_function
from collections import deque
from Queue import PriorityQueue
from Queue import Queue
import time
import threading
from threading import Thread
import select
import traceback
import os
import socket
import pox.lib.util
import random
from pox.lib.epoll_select import EpollSelect

CYCLE_MAXIMUM = 2

# A ReturnFunction can return this to skip a scheduled slice at the last
# moment.
ABORT = object()

defaultScheduler = None

nextTaskID = 0
def generateTaskID ():
  global nextTaskID
  nextTaskID += 1
  return nextTaskID

class BaseTask  (object):
  id = None
  #running = False
  priority = 1

  @classmethod
  def new (cls, *args, **kw):
    """
    Creates a task and starts it on the default scheduler with the
    default priority.
    """
    o = cls(*args, **kw)
    o.start(fast=True)
    return o

  def __init__ (self, *args, **kw):
    #NOTE: keep in sync with Task.__init__ !
    #      (better yet, refactor)
    self.id = generateTaskID()
    self.gen = self.run(*args, **kw)
    self.rv = None
    self.rf = None # ReturnFunc

  def start (self, scheduler = None, priority = None, fast = False):
    """
    Schedules this task.

    See Scheduler.schedule() and Scheduler.fast_schedule() for the meaning
    of the 'fast' argument.
    """
    if scheduler is None: scheduler = defaultScheduler
    if priority != None: self.priority = priority
    if fast:
      scheduler.fast_schedule(self)
    else:
      scheduler.schedule(self)

  def execute (self):
    if self.rf is not None:
      v = self.rf(self)
      self.rf = None
      self.rv = None
      if v == ABORT:
        return False
    else:
      v = self.rv
      self.rv = None
    return self.gen.send(v)

  def run (self):
    print("Dummy task")
    yield 0


class Task (BaseTask):
  """
  Provides an interface close to threading.Thread
  """

  def __init__ (self, group=None, target=None, name=None, args=(), kwargs={}):
    #NOTE: keep in sync with BaseTask.__init__ !
    #      (better yet, refactor)
    assert(group == None) # Not supported
    self.id = generateTaskID()
    self.rv = None

    self.name = name
    if name == None: self.name = str(self.id)

    self.target = target
    self.args = args
    self.kwargs = kwargs

    self.gen = self.run(*args, **kwargs)

    BaseTask.__init__(self)

  def run (self):
    g = self.target(*self.args, **self.kwargs)
    g.next()
    while True:
      g.send((yield))

  def __str__ (self):
    return "<" + self.__class__.__name__ + "/tid" + str(self.name) + ">"


class Scheduler (object):
  """ Scheduler for Tasks """
  def __init__ (self, isDefaultScheduler = None, startInThread = True,
                daemon = False, useEpoll=False):
    self._ready = deque()
    self._hasQuit = False
    self._selectHub = SelectHub(self, useEpoll=useEpoll)
    self._thread = None
    self._event = threading.Event()

    self._lock = threading.Lock()
    self._callLaterTask = None
    self._allDone = False

    global defaultScheduler
    if isDefaultScheduler or (isDefaultScheduler is None and
                              defaultScheduler is None):
      defaultScheduler = self

    if startInThread:
      self.runThreaded(daemon)

  def __del__ (self):
    self._hasQuit = True
    super(Scheduler, self).__del__()

  def callLater (self, func, *args, **kw):
    """
    Calls func with the given arguments at some later point, within this
    scheduler.  This is a good way for another thread to call something in
    a co-op-thread-safe manner.
    """

    with self._lock:
      if self._callLaterTask is None:
        self._callLaterTask = CallLaterTask()
        self._callLaterTask.start()

    self._callLaterTask.callLater(func, *args, **kw)

  def runThreaded (self, daemon = False):
    self._thread = Thread(target = self.run)
    self._thread.daemon = daemon
    self._thread.start()

  def synchronized (self):
    return Synchronizer(self)

  def schedule (self, task, first = False):
    """
    Schedule the given task to run later.
    If first is True, the task will be the next to run.

    Unlike fast_schedule(), this method will not schedule a task to run
    multiple times.  The one exception is if a Task actually schedules
    itself.  The easiest way to avoid this is simply not to do it.
    See fast_schedule() and ScheduleTask for more info.
    """
    if threading.current_thread() is self._thread:
      # We're know we're good.
      #TODO: Refactor the following with ScheduleTask
      if task in self._ready:
        # It might make sense to keep a flag on the task, since checking
        # if it's in the ready list is not very efficient.
        # Not sure if it makes sense to print out a message here or not.
        import logging
        logging.getLogger("recoco").info("Task %s scheduled multiple " +
                                         "times", task)
        return False
      self.fast_schedule(task, first)
      return True

    st = ScheduleTask(self, task)
    st.start(fast=True)

  def fast_schedule (self, task, first = False):
    """
    Schedule the given task to run later.
    If first is True, the task will be the next to run.

    This method does not protect you from scheduling the same Task more
    than once, which you probably really don't want to do.

    If you are scheduling an existing Task (waking it) from another Task,
    you should either implement your own logic to ensure that you don't
    schedule it multiple times, or you should just use schedule().

    If you are scheduling an existing Task (waking it) from any thread
    besides the one the scheduler is running on, there's a race condition
    which makes it nontrivial to ensure that multiple schedulings never
    happen, and you should just use schedule() for such Tasks.

    If you are scheduling a new Task that you just created, this method
    is always safe.
    """

    # Sanity check.  Won't catch all cases.
    assert task not in self._ready

    if first:
      self._ready.appendleft(task)
    else:
      self._ready.append(task)

    self._event.set()

  def quit (self):
    self._hasQuit = True

  def run (self):
    try:
      while self._hasQuit == False:
        if len(self._ready) == 0:
          self._event.wait(CYCLE_MAXIMUM) # Wait for a while
          self._event.clear()
          if self._hasQuit: break
        r = self.cycle()
    finally:
      #print("Scheduler done")
      self._hasQuit = True
      self._selectHub._cycle()
      self._allDone = True

  def cycle (self):
    #if len(self._ready) == 0: return False

    # Patented hilarious priority system
    #TODO: Replace it with something better
    t = None
    try:
      while True:
        t = self._ready.popleft()
        if t.priority >= 1: break
        if len(self._ready) == 0: break
        if t.priority >= random.random(): break
        self._ready.append(t)
    except IndexError:
      return False

    #print(len(self._ready), "tasks")

    try:
      rv = t.execute()
    except StopIteration:
      return True
    except:
      try:
        print("Task", t, "caused exception and was de-scheduled")
        traceback.print_exc()
      except:
        pass
      return True

    if isinstance(rv, BlockingOperation):
      try:
        rv.execute(t, self)
      except:
        print("Task", t, "caused exception during a blocking operation and " +
              "was de-scheduled")
        traceback.print_exc()
    elif rv is False:
      # Just unschedule/sleep
      #print "Unschedule", t, rv
      pass
    elif type(rv) == int or type(rv) == long or type(rv) == float:
      # Sleep time
      if rv == 0:
        #print "sleep 0"
        self._ready.append(t)
      else:
        self._selectHub.registerTimer(t, rv)
    elif rv == None:
      raise RuntimeError("Must yield a value!")

    return True


#TODO: Read() and Write() BlockingOperations that use nonblocking sockets with
#      SelectHub and do post-processing of the return value.

class BlockingOperation (object):
  """
  A base class for what can be thought of as syscalls for Tasks.
  The separation between __init__ and execute may seem sort of artificial, but
  it serves an actual purpose, which is that it makes it impossible for a task
  to accidentally start to make a syscall (by instantiating a BlockingOperation)
  without actually yielding.
  """
  def __init__ (self):
    """ When the syscall is made by a task, this is executed """
    pass

  def execute (self, task, scheduler):
    """ Scheduler calls this to actually execute the syscall """
    pass


class CallBlocking (BlockingOperation):
  """
  Syscall that calls an actual blocking operation (like a real .recv()).
  In order to keep from blocking, it calls it on another thread.
  The return value is (ret_val, exc_info), one of which is always None.
  """
  @classmethod
  def new (_cls, _func, *_args, **_kw):
    return _cls(_func, *_args, **_kw)

  def __init__ (self, func, args=(), kw={}):
    self.t = None
    self.scheduler = None
    self.task = None

    self.func = func
    self.args = args
    self.kw = kw

  def _proc (self):
    try:
      self.task.rv = (self.func(*self.args, **self.kw), None)
    except:
      import sys
      self.task.rv = (None, sys.exc_info())

    self.scheduler.fast_schedule(self.task)

  def execute (self, task, scheduler):
    self.task = task
    self.scheduler = scheduler

    #NOTE: It might be nice to use a pool here
    self.t = threading.Thread(target=self._proc)
    #pool.add(self._proc)

    self.t.daemon = True
    self.t.start()


class Exit (BlockingOperation):
  """
  Syscall that kills the scheduler
  """
  def __init__ (self):
    pass

  def execute (self, task, scheduler):
    scheduler.quit()


class Sleep (BlockingOperation):
  """
  Sleep for specified amount of time (seconds)
  None means unscheduler (i.e., sleep until an outside force wakes it)
  0 means reschedule for later (no additional time)
  """
  def __init__ (self, timeToWake = None, absoluteTime = False):
    if absoluteTime == False and timeToWake != None: timeToWake += time.time()
    self._t = timeToWake

  def execute (self, task, scheduler):
    if self._t is None:
      # Just unschedule
      return
    if self._t is 0 or self._t < time.time():
      # Just reschedule
      scheduler.fast_schedule(task)
      return
    scheduler._selectHub.registerTimer(task, self._t, True) # A bit ugly


class Select (BlockingOperation):
  """
  Should be very similar to Python select.select()
  """
  def __init__ (self, *args, **kw):
    self._args = args
    self._kw = kw

  def execute (self, task, scheduler):
    scheduler._selectHub.registerSelect(task, *self._args, **self._kw)


defaultRecvFlags = 0
try:
  defaultRecvFlags = socket.MSG_DONTWAIT
except:
  pass

class Recv (BlockingOperation):
  def __init__ (self, fd, bufsize = 1024*8, flags = defaultRecvFlags,
                timeout = None):
    """
    Recv call on fd.
    """
    self._fd = fd
    self._length = bufsize
    self._timeout = timeout
    self._flags = flags

  def _recvReturnFunc (self, task):
    # Select() will have placed file descriptors in rv
    if len(task.rv[2]) != 0 or len(task.rv[0]) == 0:
      # Socket error
      task.rv = None
      return None
    sock = task.rv[0][0]
    task.rv = None
    try:
      return sock.recv(self._length, self._flags)
    except:
      traceback.print_exc()
      return None #

  def execute (self, task, scheduler):
    task.rf = self._recvReturnFunc
    scheduler._selectHub.registerSelect(task, [self._fd], None, [self._fd],
                                        timeout=self._timeout)


class Send (BlockingOperation):
  def __init__ (self, fd, data):
    self._fd = fd
    self._data = data
    self._sent = 0
    self._scheduler = None

  def _sendReturnFunc (self, task):
    # Select() will have placed file descriptors in rv
    sock = task.rv[1]
    if len(task.rv[2]) != 0:
      # Socket error
      task.rv = None
      return self._sent
    task.rv = None
    try:
      if len(self._data) > 1024:
        data = self._data[:1024]
        self._data = self._data[1024:]
      l = sock.send(data, flags = socket.MSG_DONTWAIT)
      self._sent += l
      if l == len(data) and len(self._data) == 0:
        return self._sent
      self._data = data[l:] + self._data
    except:
      pass

    # Still have data to send...
    self.execute(task, self._scheduler)
    return ABORT

  def execute (self, task, scheduler):
    self._scheduler = scheduler
    task.rf = self._sendReturnFunc
    scheduler._selectHub.registerSelect(task, None, [self._fd], [self._fd])

#TODO: just merge this in with Scheduler?
class SelectHub (object):
  """
  This class is a single select() loop that handles all Select() requests for
  a scheduler as well as timed wakes (i.e., Sleep()).
  """
  def __init__ (self, scheduler, useEpoll=False):
    # We store tuples of (elapse-time, task)
    self._sleepers = [] # Sleeping items stored as a heap
    self._incoming = Queue() # Threadsafe queue for new items

    self._scheduler = scheduler
    self._pinger = pox.lib.util.makePinger()
    self.epoll = EpollSelect() if useEpoll else None

    self._ready = False

    self._thread = Thread(target = self._threadProc)
    self._thread.daemon = True
    self._thread.start()

    # Ugly busy wait for initialization
    #while self._ready == False:

  def _threadProc (self):
    tasks = {}
    timeouts = []
    rets = {}

    while self._scheduler._hasQuit == False:
      #print("SelectHub cycle")

      if len(timeouts) == 0:
        timeout = None
      else:
        timeout = self._sleepers[0][0] - time.time()
        if timeout < 0: timeout = 0

      #NOTE: Everything you select on eventually boils down to file descriptors,
      #      which are unique, obviously.  It might be possible to leverage this
      #      to reduce hashing cost (i.e. by picking a really good hashing
      #      function), though this is complicated by wrappers, etc...
      rl = {}
      wl = {}
      xl = {}

      timeout = None
      timeoutTask = None

      now = time.time()

      expired = None

      for t,trl,twl,txl,tto in tasks.itervalues():
        if tto != None:
          if tto <= now:
            # Already expired
            if expired is None: expired = []
            expired.append(t)
            if tto-now > 0.1: print("preexpired",tto,now,tto-now)
            continue
          tt = tto - now
          if tt < timeout or timeout is None:
            timeout = tt
            timeoutTask = t

        if trl:
          for i in trl: rl[i] = t
        if twl:
          for i in twl: wl[i] = t
        if txl:
          for i in txl: xl[i] = t

      if expired:
        for t in expired:
          del tasks[t]
          self._return(t, ([],[],[]))

      if timeout is None: timeout = CYCLE_MAXIMUM
      if self.epoll:
        ro, wo, xo = self.epoll.select( rl.keys() + [self._pinger],
                                  wl.keys(),
                                  xl.keys(), timeout )
      else:
        ro, wo, xo = select.select( rl.keys() + [self._pinger],
                                  wl.keys(),
                                  xl.keys(), timeout )

      if len(ro) == 0 and len(wo) == 0 and len(xo) == 0 and timeoutTask != None:
        # IO is idle - dispatch timers / release timeouts
        del tasks[timeoutTask]
        self._return(timeoutTask, ([],[],[]))
      else:
        # We have IO events
        if self._pinger in ro:
          self._pinger.pongAll()
          while not self._incoming.empty():
            stuff = self._incoming.get(True)
            task = stuff[0]
            assert task not in tasks
            tasks[task] = stuff
            self._incoming.task_done()
          if len(ro) == 1 and len(wo) == 0 and len(xo) == 0:
            # Just recycle
            continue
          ro.remove(self._pinger)

        # At least one thread is going to be resumed
        for i in ro:
          task = rl[i]
          if task not in rets: rets[task] = ([],[],[])
          rets[task][0].append(i)
        for i in wo:
          task = wl[i]
          if task not in rets: rets[task] = ([],[],[])
          rets[task][1].append(i)
        for i in xo:
          task = xl[i]
          if task not in rets: rets[task] = ([],[],[])
          rets[task][2].append(i)

        for t,v in rets.iteritems():
          del tasks[t]
          self._return(t, v)
        rets.clear()

  def registerSelect (self, task, rlist = None, wlist = None, xlist = None,
                      timeout = None, timeIsAbsolute = False):
    if not timeIsAbsolute:
      if timeout != None:
        timeout += time.time()

    self._incoming.put((task, rlist, wlist, xlist, timeout))
    self._cycle()

  def _cycle (self):
    """
    Cycle the wait thread so that new timers or FDs can be picked up
    """
    self._pinger.ping()

  def registerTimer (self, task, timeToWake, timeIsAbsolute = False):
    """
    Register a task to be wakened up interval units in the future.
    It means timeToWake seconds in the future if absoluteTime is False.
    """
    return self.registerSelect(task, None, None, None, timeToWake,
                               timeIsAbsolute)

  def _return (self, sleepingTask, returnVal):
    #print("reschedule", sleepingTask)
    sleepingTask.rv = returnVal
    self._scheduler.fast_schedule(sleepingTask)


class ScheduleTask (BaseTask):
  """
  If multiple real threads (such as a recoco scheduler thread and any
  other thread, or any two other threads) try to schedule ("wake") the
  same Task with Scheduler.fast_schedule(), there is a race condition where
  the Task may get scheduled multiple times, which is probably quite bad.

  Scheduler.schedule() fixes this by creating one of these ScheduleTasks,
  and it's this ScheduleTask that actually calls fast_schedule().  This
  way, the Task is only ever *really* scheduled from the scheduler thread
  and the race condition doesn't exist.
  """
  def __init__ (self, scheduler, task):
    BaseTask.__init__(self)
    self._scheduler = scheduler
    self._task = task

  def run (self):
    #TODO: Refactor the following, since it is copy/pasted from schedule().
    if self._task in self._scheduler._ready:
      # It might make sense to keep a flag on the task, since checking
      # if it's in the ready list is not very efficient.
      # Not sure if it makes sense to print out a message here or not.
      import logging
      logging.getLogger("recoco").info("Task %s scheduled multiple " +
                                       "times", self._task)
    else:
      self._scheduler.fast_schedule(self._task, True)
    yield False


class SyncTask (BaseTask):
  def __init__ (self, *args, **kw):
    BaseTask.__init__(self)
    self.inlock = threading.Lock()
    self.outlock = threading.Lock()
    self.inlock.acquire()
    self.outlock.acquire()

  def run (self):
    self.inlock.release()
    self.outlock.acquire()


class Synchronizer (object):
  def __init__ (self, scheduler = None):
    if scheduler is None:
      scheduler = defaultScheduler
    self.scheduler = scheduler
    self.syncer = None
    self.enter = 0

  def __enter__ (self):
    self.enter += 1
    if self.enter == 1:
      self.syncer = SyncTask()
      self.syncer.start(self.scheduler) #NOTE: maybe add it to head of list?
      self.syncer.inlock.acquire()
    return self.syncer

  def __exit__ (self, type_, value, traceback):
    self.enter -= 1
    if self.enter == 0:
      self.syncer.outlock.release()


class Timer (Task):
  """
  A simple timer.

  timeToWake     Amount of time to wait before calling callback (seconds)
  callback       Some callable to be called when the timer expires
  absoluteTime   A specific time to fire (as from time.time())
  recurring      Whether to call repeatedly or just once
  args, kw       Args and keyword args for the callback
  scheduler      The recoco scheduler to use (None means default scheduler)
  started        If False, requires you to call .start() to begin timer
  selfStoppable  If True, the callback can return False to cancel the timer
  """
  def __init__ (self, timeToWake, callback, absoluteTime = False,
                recurring = False, args = (), kw = {}, scheduler = None,
                started = True, selfStoppable = True):
    if absoluteTime and recurring:
      raise RuntimeError("Can't have a recurring timer for an absolute time!")
    Task.__init__(self)
    self._self_stoppable = selfStoppable
    self._next = timeToWake
    self._interval = timeToWake if recurring else 0
    if not absoluteTime:
      self._next += time.time()

    self._cancelled = False

    self._recurring = recurring
    self._callback = callback
    self._args = args
    self._kw = kw

    if started: self.start(scheduler)

  def cancel (self):
    self._cancelled = True

  def run (self):
    while not self._cancelled:
      yield Sleep(timeToWake=self._next, absoluteTime=True)
      if self._cancelled: break
      self._next = time.time() + self._interval
      rv = self._callback(*self._args,**self._kw)
      if self._self_stoppable and (rv is False): break
      if not self._recurring: break
    yield False # Quit


class CallLaterTask (BaseTask):
  def __init__ (self):
    BaseTask.__init__(self)
    self._pinger = pox.lib.util.makePinger()
    from collections import deque
    self._calls = deque()

  def callLater (self, func, *args, **kw):
    assert callable(func)
    self._calls.append((func,args,kw))
    self._pinger.ping()

  def run (self):
    while True:
      yield Select([self._pinger], None, None)
      self._pinger.pongAll()
      try:
        while True:
          e = self._calls.popleft()
          try:
            e[0](*e[1], **e[2])
          except:
            import logging
            logging.getLogger("recoco").exception("Exception calling %s", e[0])
      except:
        pass


class BlockingTask (BaseTask):
  @classmethod
  def new (_cls, _func, _cb=None, *_args, **_kw):
    return _cls(_func, _cb, *_args, **_kw)

  def __init__ (self, func, callback=None, args=(), kw={}):
    """
    callback takes two parameters: rv and exc. One is always None.
    if callback is actually a tuple, the first one is called with
    the return value on normal exit, the second is called with
    exc_info on an exception.
    """
    BaseTask.__init__(self)
    self.func = func
    self.callback = callback
    self.args = args
    self.kw = kw

  def run (self):
    rv,exc = (yield CallBlocking(self.func, args=self.args, kw=self.kw))
    if self.callback is None:
      pass
    elif isinstance(self.callback, tuple):
      if exc is not None:
        if self.callback[1] is not None:
          self.callback[1](exc)
      else:
        if self.callback[0] is not None:
          self.callback[0](rv)
    else:
      self.callback(rv,exc)


# Sanity tests
if __name__ == "__main__":
  class TestTask (BaseTask):
    def __init__ (self, *args, **kw):
      BaseTask.__init__(self, *args, **kw)

    def run (self, a, b, inc = 1, sleep = 0):
      n = a
      while n <= b:
        print(n)
        n+=inc
        yield Select([],[],[],sleep)

  s = Scheduler(daemon=True)

  t = TestTask(5,10,sleep=10)
  t.start()

  t = TestTask(100,110,sleep=20)
  t.start()

  #TestTask(1000,1010,sleep=1).start()

  import code
  code.interact(local=locals())

  s.quit()

########NEW FILE########
__FILENAME__ = revent
# Copyright 2011 James McCauley
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at:
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

#TODO:
#-----
# decorator for adding event classes to a class?
# make mixin-able to existing classes
# make mixin-able to existing objects

"""
Revent is an event system wherein objects become a composition of data,
methods, and now events.  It fits with the publish/subscribe communication
pattern.

Events themselves are generally instances of some subclass of the Event
class.  In fact, they can be arbitrary values of any sort, though
subclasses of Event get special handling (and support for values of other
sorts may eventually be removed).

To subscribe to an event, you create a callback function and register it
with the source.  For example:

def bar_handler(self, event):
  print("bar!", event)

pox.core.addListener(UpEvent, bar_handler)


Often (especially if you are going to listen to multiple events from a
single source), it is easier to inherit from EventMixin just so that you
can use the listenTo() method.  For example:

class Sink (EventMixin):
  def __init__(self):
   # Listen to events sourced by pox.core
   pox.core.addListeners(self)
   self.listenTo(pox.core)

  def _handle_ComponentRegistered (self, event):
    # The name of this method has a special meaning to addListeners().
    # If a method name starts with _handle_ and ends with the name of
    # an event that the source publishes, the method is automatically
    # registered as an event handler.
    #
    # This method will now be called whenever pox.core triggers a
    # ComponentRegistered event.

    # Most event handlers are passed an event object as a parameter (though
    # individual Event classes can override this behavior by altering their
    # _invoke() method).
    component = event.component
    name = event.name
    print("I see you,", name, "!")


Event sources can also use the EventMixin library:

class Source (EventMixin):
  # Defining this variable tells the revent library what kind of events
  # this source can raise.
  _eventMixin_events = set([ComponentRegistered])

  def __init__ (self):
    foo()

  def foo (self):
    # We can raise events as follows:
    component = "fake_pox_component"
    self.raiseEvent(ComponentRegistered(component))

    # In the above invocation, the argument is an instance of
    # ComponentRegistered (which is a subclass of Event).  The following is
    # functionally equivalent, but has the nice property that
    # ComponentRegistered is never instantiated if there are no listeners.
    #self.raiseEvent(ComponentRegistered, component)
    # In both cases, "component" is passed to the __init__ method for the
    # ComponentRegistered class.

    # The above method invocation will raise an exception if an event
    # handler rauses an exception.  To project yourself from exceptions in
    # handlers, see raiseEventNoErrors().
"""

from __future__ import print_function

import operator

# weakrefs are used for some event handlers so that just having an event
# handler set will not keep the source (publisher) alive.
import weakref


_nextEventID = 0
def _generateEventID ():
  """
  Generates an event ID
  This is (at present) mostly so that an event can later be removed.
  Note that this function is not threadsafe.
  """
  global _nextEventID
  _nextEventID += 1
  return _nextEventID


def EventReturn (halt = False, remove = False):
  """
  Event handlers can return special values.  You can craft these with this
  function.

  If halt is True, further handlers will not be called for this particular
  event.

  If remove is True, the handler will be removed (i.e. unsubscribed) and
  will not be called anymore.

  Shortcut names are also available.  You can also simply do:
  return EventHalt
  return EventRemove
  return HaltAndRemove
  """
  return (halt, remove)

EventContinue = EventReturn(halt=False, remove=False)

# Event handlers can return this to stop further handling of this event
EventHalt = EventReturn(halt=True)

# A handler can return this if it wants to remove itself (unsubscribe)
EventRemove = EventReturn(remove=True)

# A handler can return this if it wants to both stop further processing
# and unsubscribe
EventHaltAndRemove = EventReturn(remove=True, halt=True)


class Event (object):
  """
  Superclass for events
  """
  def __init__ (self):
    self.halt = False
    self.source = None

  def _invoke (self, handler, *args, **kw):
    return handler(self, *args, **kw)

def handleEventException (source, event, args, kw, exc_info):
  """
  Called when an exception is raised by an event handler when the event
  was raised by raiseEventNoErrors().

  You can replace this method if you'd like to replace the default handling
  (printing an error message an a traceback) with your own (for example if
  you are using a logging system and would like to use that).  You can also
  replace it with None to have events fail silently.

  "source" is the object sourcing the event.  "event" is the event that was
  being raised when the exception occurred.  "args" and "kw" were the args
  and kwargs passed to raiseEventNoErrors.  "exc_info" is the exception
  info as returned by sys.exc_info()).
  """
  try:
    c = source
    t = event
    if hasattr(c, "__class__"): c = c.__class__.__name__
    if isinstance(t, Event): t = t.__class__.__name__
    elif issubclass(t, Event): t = t.__name__
  except:
    pass
  import sys
  sys.stderr.write("Exception while handling %s!%s...\n" % (c,t))
  import traceback
  traceback.print_exception(*exc_info)


class EventMixin (object):
  """
  Mixin for classes that want to source events
  """
  # _eventMixin_events contains the set of events that the subclassing
  # object will raise.
  # You can't raise events that aren't in this set -- unless you set this
  # to True in which all events are acceptable.
  _eventMixin_events = set()

  def _eventMixin_addEvents (self, events):
    for e in events:
      self._eventMixin_addEvent(e)
  def _eventMixin_addEvent (self, eventType):
    self._eventMixin_init()
    assert self._eventMixin_events is not True
    if False:
      pass
    #if self._eventMixin_events == True:
    #  # Do nothing, all events already accepted!
    #  # print warning?
    #  return
    elif self._eventMixin_events == None:
      self._eventMixin_events = set()
    self._eventMixin_events.add(eventType)

  def __init__ (self):
    self._eventMixin_init()

  def _eventMixin_init (self):
    if not hasattr(self, "_eventMixin_events"):
      setattr(self, "_eventMixin_events", True)
    if not hasattr(self, "_eventMixin_handlers"):
      setattr(self, "_eventMixin_handlers", {})

  def raiseEventNoErrors (self, event, *args, **kw):
    """
    Raise an event, catching exceptions thrown by the handler.
    If exceptions are caught, the global handleEventExceptions() is called.
    Also see raiseEvent()
    """
    #TODO: this should really keep subsequent events executing and print
    #      the specific handler that failed...
    try:
      return self.raiseEvent(event, *args, **kw)
    except:
      if handleEventException is not None:
        import sys
        handleEventException(self, event, args, kw, sys.exc_info())
    return None

  def raiseEvent (self, event, *args, **kw):
    """
    Raises an event.
    If "event" is an Event type, it will be initialized with args and kw,
    but only if there are actually listeners.
    Returns the event object, unless it was never created (because there
    were no listeners) in which case returns None.
    """
    self._eventMixin_init()

    classCall = False
    if isinstance(event, Event):
      eventType = event.__class__
      classCall = True
      if event.source is None: event.source = self
    elif issubclass(event, Event):
      # Check for early-out
      if event not in self._eventMixin_handlers:
        return None
      if len(self._eventMixin_handlers[event]) == 0:
        return None

      classCall = True
      eventType = event
      event = eventType(*args, **kw)
      args = ()
      kw = {}
      if event.source is None:
        event.source = self
    #print("raise",event,eventType)
    if (self._eventMixin_events is not True
        and eventType not in self._eventMixin_events):
      raise RuntimeError("Event %s not defined on object of type %s"
                         % (eventType, type(self)))

    # Create a copy so that it can be modified freely during event
    # processing.  It might make sense to change this.
    handlers = self._eventMixin_handlers.get(eventType, [])
    for (priority, handler, once, eid) in handlers:
      if classCall:
        rv = event._invoke(handler, *args, **kw)
      else:
        rv = handler(event, *args, **kw)
      if once: self.removeListener(eid)
      if rv is None: continue
      if rv is False:
        self.removeListener(eid)
      if rv is True:
        if classCall: event.halt = True
        break
      if type(rv) == tuple:
        if len(rv) >= 2 and rv[1] == True:
          self.removeListener(eid)
        if len(rv) >= 1 and rv[0]:
          if classCall: event.halt = True
          break
        if len(rv) == 0:
          if classCall: event.halt = True
          break
      #if classCall and hasattr(event, "halt") and event.halt:
      if classCall and event.halt:
        break
    return event

  def removeListeners (self, listeners):
    altered = False
    for l in listeners:
      if self.removeListener(l): altered = True
    return altered

  def _eventMixin_get_listener_count (self):
    """
    Returns the number of listeners.
    """
    return sum((len(x) for x in self._eventMixin_handlers.itervalues()))

  def removeListener (self, handlerOrEID, eventType=None):
    """
    handlerOrEID : a reference to a handler object, an event ID (EID)
                   identifying the event type, or (eventType, EID) pair
    eventType : the type of event to remove the listener(s) for
    """
    #TODO: This method could use an elegant refactoring.

    #print("Remove listener", handlerOrEID)
    self._eventMixin_init()
    handler = handlerOrEID

    altered = False
    if type(handler) == tuple:
      # It's a type/eid pair
      if eventType == None: eventType = handler[0]
      handlers = self._eventMixin_handlers[eventType]
      l = len(handlers)
      self._eventMixin_handlers[eventType] = [x for x in handlers
                                              if x[3] != handler[1]]
      altered = altered or l != len(self._eventMixin_handlers[eventType])
    elif type(handler) == int:
      # It's an EID
      if eventType == None:
        for event in self._eventMixin_handlers:
          handlers = self._eventMixin_handlers[event]
          l = len(handlers)
          self._eventMixin_handlers[event] = [x for x in handlers
                                              if x[3] != handler]
          altered = altered or l != len(self._eventMixin_handlers[event])
      else:
        l = len(handlers)
        handlers = self._eventMixin_handlers[eventType]
        self._eventMixin_handlers[eventType] = [x for x in handlers
                                                if x[3] != handler]
        altered = altered or l != len(self._eventMixin_handlers[event])
    else:
      if eventType == None:
        for event in self._eventMixin_handlers:
          handlers = self._eventMixin_handlers[event]
          l = len(handlers)
          self._eventMixin_handlers[event] = [x for x in handlers
                                              if x[1] != handler]
          altered = altered or l != len(self._eventMixin_handlers[event])
      else:
        handlers = self._eventMixin_handlers[eventType]
        l = len(handlers)
        self._eventMixin_handlers[eventType] = [x for x in handlers
                                                if x[1] != handler]
        altered = altered or l != len(self._eventMixin_handlers[eventType])

    return altered

  def addListenerByName (self, *args, **kw):
    """
    Add a listener by name. An eventType argument must be present, which is
    used as the name. A handler argument must also be present.

    Also see addListener().
    """
    kw['byName'] = True
    return self.addListener(*args,**kw)

  def addListener (self, eventType, handler, once=False, weak=False,
                   priority=None, byName=False):
    """
    Add an event handler for an event triggered by this object (subscribe).

    eventType : event class object (e.g. ConnectionUp). If byName is True,
                should be a string (e.g. "ConnectionUp")
    handler : function/method to be invoked when event is raised
    once : if True, this handler is removed after being fired once
    weak : If handler is a method on object A, then listening to an event
           on object B will normally make B have a reference to A, so A
           can not be released until after B is released or the listener
           is removed.
           If weak is True, there is no relationship between the lifetimes
           of the publisher and subscriber.
    priority : The order in which to call event handlers if there are
               multiple for an event type.  Should probably be an integer,
               where higher means to call it earlier.  Do not specify if
               you don't care.
    byName : True if eventType is a string name, else an Event subclass

    Raises an exception unless eventType is in the source's
    _eventMixin_events set (or, alternately, _eventMixin_events must
    be True).

    The return value can be used for removing the listener.
    """
    self._eventMixin_init()
    if (self._eventMixin_events is not True
        and eventType not in self._eventMixin_events):
      # eventType wasn't found
      fail = True
      if byName:
        # if we were supposed to find the event by name, see if one of the
        # event names matches
        for e in self._eventMixin_events:
          if issubclass(e, Event):
            if e.__name__ == eventType:
              eventType = e
              fail = False
              break
      if fail:
        raise RuntimeError("Event %s not defined on object of type %s"
                           % (eventType, type(self)))
    if eventType not in self._eventMixin_handlers:
      # if no handlers are already registered, initialize
      handlers = self._eventMixin_handlers[eventType] = []
      self._eventMixin_handlers[eventType] = handlers
    else:
      handlers = self._eventMixin_handlers[eventType]

    eid = _generateEventID()

    if weak: handler = CallProxy(self, handler, (eventType, eid))

    entry = (priority, handler, once, eid)

    handlers.append(entry)
    if priority is not None:
      # If priority is specified, sort the event handlers
      handlers.sort(reverse = True, key = operator.itemgetter(0))

    return (eventType,eid)

  def listenTo (self, source, *args, **kv):
    """
    Automatically subscribe to events on source.

    This method tries to bind all _handle_ methods on self to events
    on source.  Kind of the opposite of addListeners().

    See also: addListeners(), autoBindEvents()
    """
    return autoBindEvents(self, source, *args, **kv)

  def addListeners (self, sink, prefix='', weak=False, priority=None):
    """
    Automatically subscribe sink to our events.

    Tries to bind all _handle_ methods on sink to events that this object
    raises.  Kind of the opposite of listenTo().

    See also: listenTo(), autoBindEvents()
    """
    return autoBindEvents(sink, self, prefix, weak, priority)

  def clearHandlers(self):
    """
    Remove all handlers from this object
    """
    self._eventMixin_handlers = {}


def autoBindEvents (sink, source, prefix='', weak=False, priority=None):
  """
  Automatically set up listeners on sink for events raised by source.

  Often you have a "sink" object that is interested in multiple events
  raised by some other "source" object.  This method makes setting that
  up easy.
  You name handler methods on the sink object in a special way.  For
  example, lets say you have an object mySource which raises events of
  types FooEvent and BarEvent.  You have an object mySink which wants to
  listen to these events.  To do so, it names its handler methods
  "_handle_FooEvent" and "_handle_BarEvent".  It can then simply call
  autoBindEvents(mySink, mySource), and the handlers are set up.

  You can also set a prefix which changes how the handlers are to be named.
  For example, autoBindEvents(mySink, mySource, "source1") would use a
  handler named "_handle_source1_FooEvent".

  "weak" has the same meaning as with addListener().

  Returns the added listener IDs (so that you can remove them later).
  """
  if len(prefix) > 0 and prefix[0] != '_': prefix = '_' + prefix
  if hasattr(source, '_eventMixin_events') is False:
    # If source does not declare that it raises any events, do nothing
    print("Warning: source class %s doesn't specify any events!" % (
          source.__class__.__name__,))
    return []

  events = {}
  for e in source._eventMixin_events:
    if type(e) == str:
      events[e] = e
    else:
      events[e.__name__] = e

  listeners = []
  # for each method in sink
  for m in dir(sink):
    # get the method object
    a = getattr(sink, m)
    if callable(a):
      # if it has the revent prefix signature,
      if m.startswith("_handle" + prefix + "_"):
        event = m[8+len(prefix):]
        # and it is one of the events our source triggers
        if event in events:
          # append the listener
          listeners.append(source.addListener(events[event], a, weak=weak,
                                              priority=priority))
          #print("autoBind: ",source,m,"to",sink)
        elif len(prefix) > 0 and "_" not in event:
          print("Warning: %s found in %s, but %s not raised by %s" %
                (m, sink.__class__.__name__, event,
                 source.__class__.__name__))

  return listeners


class CallProxy (object):
  """
  Internal use.

  Custom proxy wrapper for /weak reference/ event handlers.  When the
  publisher or subscriber objects are lost, this cleans up by removing
  the listener entry in the publisher object.
  """
  def __init__ (self, source, handler, removeData):
    """
    source : Event source (publisher)
    handler : A "weak handler" callback
    removeData :  The identifier used for removal of the handler
    """
    self.source = weakref.ref(source, self._forgetMe)
    self.obj = weakref.ref(handler.im_self, self._forgetMe)
    self.method = handler.im_func
    self.removeData = removeData
    self.name = str(handler)

  def _forgetMe (self, o):
    # o is the weak reference object; we don't use it
    #print("Forgetting",self.removeData,self.method)
    source = self.source()
    if source is not None:
      source.removeListener(self.removeData)
    self.obj = None
  def __call__ (self, *args, **kw):
    #print("weak call")
    if self.obj is None: return
    o = self.obj()
    if o is not None:
      return self.method(o, *args, **kw)
    print("callProxy object is gone!")
    raise RuntimeError("callProxy object is gone!")
  def __str__ (self):
    return "<CallProxy for " + self.name + ">"

########NEW FILE########
__FILENAME__ = socketcapture
# Copyright 2012 James McCauley
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at:
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from pox.lib.addresses import *
import pox.lib.packet as pkt

from struct import pack
import time


class SocketWedge (object):
  def __init__ (self, socket):
    self._socket = socket

  def send (self, string, *args, **kw):
    r = self._socket.send(string, *args, **kw)
    self._send_out(string, r)
    return r

  def recv (self, bufsize, *args, **kw):
    r = self._socket.recv(bufsize, *args, **kw)
    self._recv_out(r)
    return r

  def __getattr__ (self, n):
    return getattr(self._socket, n)


class PCapWriter (object):
  def __init__ (self, outstream, socket = None, flush = False,
                local_addrs = (None,None,None),
                remote_addrs = (None,None,None)):
    """
    outstream is the stream to write the PCAP trace to.
    Ethernet addresses have to be faked, and it can be convenient to
    fake IP and TCP addresses as well.  Thus, you can specify local_addrs
    or remote_addrs.  These are tuples of (EthAddr, IPAddr, TCPPort).
    Any item that is None gets a default value.
    """
    self._out = outstream
    self._flush = flush

    if socket is not None:
      remote = socket.getpeername()
      local = socket.getsockname()
    else:
      remote = ("1.1.1.1",1)
      local = ("0.0.0.0",0)

    def create_packet (e1,e2,i1,i2,t1,t2):
      e = pkt.ethernet(
          src = e1,
          dst = e2,
          type = pkt.ethernet.IP_TYPE)
      i = pkt.ipv4(
          srcip = i1,
          dstip = i2,
          protocol = pkt.ipv4.TCP_PROTOCOL)
      t = pkt.tcp(
          srcport = t1,
          dstport = t2,
          off = 5,
          win = 1)
      t.ACK = True
      i.payload = t
      e.payload = i
      return e

    self._c_to_s = create_packet(
      local_addrs[0] or EthAddr("\x02" + "\x00" * 5),
      remote_addrs[0] or EthAddr("\x02" + "\x11" * 5),
      local_addrs[1] or IPAddr(local[0]),
      remote_addrs[1] or IPAddr(remote[0]),
      local_addrs[2] or local[1],
      remote_addrs[2] or remote[1],
      )

    self._s_to_c = create_packet(
      remote_addrs[0] or EthAddr("\x02" + "\x11" * 5),
      local_addrs[0] or EthAddr("\x02" + "\x00" * 5),
      remote_addrs[1] or IPAddr(remote[0]),
      local_addrs[1] or IPAddr(local[0]),
      remote_addrs[2] or remote[1],
      local_addrs[2] or local[1],
      )

    outstream.write(pack("IHHiIII",
      0xa1b2c3d4,    # Magic
      2,4,           # Version
      time.timezone, # TZ offset
      0,             # Accuracy of timestamps (apparently 0 is OK)
      0x7fffFFff,    # Snaplen
      1              # Ethernet
      ))

  def write (self, outgoing, buf):
    if len(buf) == 0: return
    e = self._c_to_s if outgoing else self._s_to_c
    e2 = self._c_to_s if not outgoing else self._s_to_c
    l = len(buf)
    e.payload.payload.payload = buf
    buf = e.pack()

    t = time.time()
    ut = t - int(t)
    t = int(t)
    ut = int(ut * 1000000)
    self._out.write(pack("IIII",
      t,ut,          # Timestamp
      len(buf),      # Saved size
      len(buf),      # Original size
      ))

    self._out.write(buf)
    if self._flush: self._out.flush()

    e.next.next.seq += l
    e2.next.next.ack += l


class CaptureSocket (SocketWedge):
  """
  Wraps a TCP socket and writes a faked PCAP format trace
  """
  def __init__ (self, socket, outstream, close = True,
                local_addrs = (None,None,None),
                remote_addrs = (None,None,None)):
    """
    socket is the socket to be wrapped.
    outstream is the stream to write the PCAP trace to.
    Ethernet addresses have to be faked, and it can be convenient to
    fake IP and TCP addresses as well.  Thus, you can specify local_addrs
    or remote_addrs.  These are tuples of (EthAddr, IPAddr, TCPPort).
    Any item that is None gets a default value.
    """
    super(CaptureSocket, self).__init__(socket)
    self._close = close
    self._writer = PCapWriter(outstream, socket=socket,
                              local_addrs=local_addrs,
                              remote_addrs=remote_addrs)


  def _recv_out (self, buf):
    try:
      self._writer.write(False, buf)
    except Exception:
      pass

  def _send_out (self, buf, r):
    try:
      self._writer.write(True, buf[:r])
    except Exception:
      pass

  def close (self, *args, **kw):
    if self._close:
      try:
        self._writer._out.close()
      except Exception:
        pass
    return self._socket.close(*args, **kw)


if __name__ == "__main__":
  """
  Test with:
  nc -v -v -l 9933
  """
  import socket
  sock = socket.create_connection(("127.0.0.1",9933))
  s = CaptureSocket(sock, file("test.pcap", "w"))
  while True:
    d = s.recv(1024)
    d = d.upper()
    import sys
    import time
    import random
    time.sleep(random.random() * 1.5)
    sys.stdout.write(d)
    s.send(d)

########NEW FILE########
__FILENAME__ = threadpool
# Copyright 2012 James McCauley
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at:
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""
Totally untested thread pool class.
Tries to not get more than "maximum" (but this is not a hard limit).
Kills off up to around half of its workers when more than half are idle.
"""

from __future__ import print_function
from __future__ import with_statement
from threading import Thread, RLock
from Queue import Queue


CYCLE_TIME = 3


class WorkerThread (Thread):
  def __init__ (self, pool):
    Thread.__init__(self)
    self._pool = pool
    self.daemon = True
    self.start()

  def run (self):
    with self._pool._lock:
      self._pool._total += 1

    while self._pool.running:
      with self._pool._lock:
        self._pool._available += 1
      try:
        func, args, kw = self._pool._tasks.get(True, CYCLE_TIME)
        if func is None: return
      except:
        continue
      finally:
        with self._pool._lock:
          self._pool._available -= 1
          assert self._pool._available >= 0

      try:
        func(*args, **kw)
      except Exception as e:
        print("Worker thread exception", e)
      self._pool._tasks.task_done()

    with self._pool._lock:
      self._pool._total -= 1
      assert self._pool._total >= 0


class ThreadPool (object):
  #NOTE: Assumes only one thread manipulates the pool
  #      (Add some locks to fix)
  def __init__ (self, initial = 0, maximum = None):
    self._available = 0
    self._total = 0
    self._tasks = Queue()
    self.maximum = maximum
    self._lock = RLock()
    for i in xrange(initial):
      self._new_worker

  def _new_worker (self):
    with self._lock:
      if self.maximum is not None:
        if self._total >= self.maximum:
          # Too many!
          return False
    WorkerThread(self)
    return True

  def add (_self, _func, *_args, **_kwargs):
    self.add_task(_func, args=_args, kwargs=_kwargs)

  def add_task (self, func, args=(), kwargs={}):
    while True:
      self._lock.acquire()
      if self._available == 0:
         self._lock.release()
         self._new_worker()
      else:
        break

    self._tasks.put((func, args, kwargs))

    if self.available > self._total / 2 and self.total > 8:
      for i in xrange(self._total / 2 - 1):
        self._tasks.put((None,None,None))

    self._lock.release()

  def join (self):
    self._tasks.join()

########NEW FILE########
__FILENAME__ = util
# Copyright 2011,2012,2013 James McCauley
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at:
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""
Various utility functions

Some of these are POX-specific, and some aren't.
"""

#TODO: Break into multiple modules?  (data structures, POX-specific, etc.)

from __future__ import print_function

import traceback
import struct
import sys
import os
import time
import socket
import collections


#FIXME: ugh, why can't I make importing pox.core work here?
import logging
log = logging.getLogger("util")


class DirtyList (list):
  """
  A list which keeps track of changes

  When the list is altered, callback (if any) is called, and dirty is set.
  """
  #TODO: right now the callback may be called more often than needed
  #      and it may not be called with good names/parameters.
  #      All you can really rely on is that it will be called in
  #      some way if something may have changed.
  def __init__ (self, *args, **kw):
    list.__init__(self, *args, **kw)
    self.dirty = False
    self.callback = None

  def __setslice__ (self, k, v):
    #TODO: actually check for change
    self._smudge('__setslice__', k, v)
    list.__setslice__(self, k, v)

  def __delslice__ (self, k):
    #TODO: actually check for change
    self._smudge('__delslice__', k, None)
    list.__delslice__(self, k)

  def append (self, v):
    self._smudge('append', None, v)
    list.append(self, v)

  def extend (self, v):
    self._smudge('extend', None, v)
    list.extend(self, v)

  def insert (self, i, v):
    self._smudge('insert', k, v)
    list.extend(self, v)

  def pop (self, i=-1):
    self._smudge('pop', i, None)
    list.pop(self, i)

  def remove (self, v):
    if v in self:
      self._smudge('remove', None, v)
    list.remove(self, v)

  def reverse (self):
    if len(self):
      self._smudge('reverse', None, None)
    list.reverse(self)

  def sort (self, *arg, **kw):
    #TODO: check for changes?
    self._smudge('sort', None, None)
    list.sort(self, *arg, **kw)

  def __setitem__ (self, k, v):
    if isinstance(k, slice):
      #TODO: actually check for change
      self._smudge('__setitem__slice',k,v)
    elif self[k] != v:
      self._smudge('__setitem__',k,v)
    list.__setitem__(self, k, v)
    assert good

  def __delitem__ (self, k):
    list.__delitem__(self, k)
    if isinstance(k, slice):
      #TODO: actually check for change
      self._smudge('__delitem__slice',k,v)
    else:
      self._smudge('__delitem__', k, None)

  def _smudge (self, reason, k, v):
    if self.callback:
      if self.callback(reason, k, v) is not True:
        self.dirty = True
    else:
      self.dirty = True


class DirtyDict (dict):
  """
  A dict that tracks whether values have been changed shallowly.

  If you set a callback, it will be called when the value changes, and
  passed three values: "add"/"modify"/"delete", key, value
  """
  def __init__ (self, *args, **kw):
    dict.__init__(self, *args, **kw)
    self.dirty = False
    self.callback = None

  def _smudge (self, reason, k, v):
    if self.callback:
      if self.callback(reason, k, v) is not True:
        self.dirty = True
    else:
      self.dirty = True

  def __setitem__ (self, k, v):
    if k not in self:
      self._smudge('__setitem__add',k,v)
    elif self[k] != v:
      self._smudge('__setitem__modify',k,v)
    dict.__setitem__(self, k, v)

  def __delitem__ (self, k):
    self._smudge('__delitem__', k, None)
    dict.__delitem__(self, k)


class DefaultDict (collections.defaultdict):
  """
  A dictionary that can create missing values

  This is similar to (and a subclass of) collections.defaultdict.  However, it
  calls the default factory passing it the missing key.
  """
  #TODO: Make key-passing a constructor option so that this can serve as a
  #      complete defaultdict replacement.
  def __missing__ (self, key):
    v = self.default_factory(key)
    self[key] = v
    return v


def set_extend (l, index, item, emptyValue = None):
  """
  Sets l[index] = item, padding l if needed

  Adds item to the list l at position index.  If index is beyond the end
  of the list, it will pad the list out until it's large enough, using
  emptyValue for the new entries.
  """
  #TODO: Better name?  The 'set' is a bit misleading.
  if index >= len(l):
    l += ([emptyValue] * (index - len(self) + 1))
  l[index] = item


def str_to_dpid (s):
  """
  Convert a DPID in the canonical string form into a long int.
  """
  if s.lower().startswith("0x"):
    s = s[2:]
  s = s.replace("-", "").split("|", 2)
  a = int(s[0], 16)
  if a > 0xffFFffFFffFF:
    b = a >> 48
    a &= 0xffFFffFFffFF
  else:
    b = 0
  if len(s) == 2:
    b = int(s[1])
  return a | (b << 48)
strToDPID = str_to_dpid


def dpid_to_str (dpid, alwaysLong = False):
  """
  Convert a DPID from a long into into the canonical string form.
  """
  if type(dpid) is long or type(dpid) is int:
    # Not sure if this is right
    dpid = struct.pack('!Q', dpid)

  assert len(dpid) == 8

  r = '-'.join(['%02x' % (ord(x),) for x in dpid[2:]])

  if alwaysLong or dpid[0:2] != (b'\x00'*2):
    r += '|' + str(struct.unpack('!H', dpid[0:2])[0])

  return r
dpidToStr = dpid_to_str # Deprecated


def assert_type(name, obj, types, none_ok=True):
  """
  Assert that a parameter is of a given type.

  Raise an Assertion Error with a descriptive error msg if not.

  name: name of the parameter for error messages
  obj: parameter value to be checked
  types: type or list or tuple of types that is acceptable
  none_ok: whether 'None' is an ok value
  """
  if obj is None:
    if none_ok:
      return True
    else:
      raise AssertionError("%s may not be None" % name)

  if not isinstance(types, (tuple, list)):
    types = [ types ]

  for cls in types:
    if isinstance(obj, cls):
      return True
  allowed_types = "|".join(map(lambda x: str(x), types))
  stack = traceback.extract_stack()
  stack_msg = "Function call %s() in %s:%d" % (stack[-2][2],
                                               stack[-3][0], stack[-3][1])
  type_msg = ("%s must be instance of %s (but is %s)"
              % (name, allowed_types , str(type(obj))))

  raise AssertionError(stack_msg + ": " + type_msg)


def init_helper (obj, kw):
  """
  Helper for classes with attributes initialized by keyword arguments.

  Inside a class's __init__, this will copy keyword arguments to fields
  of the same name.  See libopenflow for an example.
  """
  for k,v in kw.iteritems():
    if not hasattr(obj, k):
      raise TypeError(obj.__class__.__name__ + " constructor got "
      + "unexpected keyword argument '" + k + "'")
    setattr(obj, k, v)
initHelper = init_helper # Deprecated


def make_pinger ():
  """
  A pinger is basically a thing to let you wake a select().

  On Unix systems, this makes a pipe pair.  But on Windows, select() only
  works with sockets, so it makes a pair of connected sockets.
  """

  class PipePinger (object):
    def __init__ (self, pair):
      self._w = pair[1]
      self._r = pair[0]
      assert os is not None

    def ping (self):
      if os is None: return #TODO: Is there a better fix for this?
      os.write(self._w, ' ')

    def fileno (self):
      return self._r

    def pongAll (self):
      #TODO: make this actually read all
      os.read(self._r, 1024)

    def pong (self):
      os.read(self._r, 1)

    def __del__ (self):
      try:
        os.close(self._w)
      except:
        pass
      try:
        os.close(self._r)
      except:
        pass

    def __repr__ (self):
      return "<%s %i/%i>" % (self.__class__.__name__, self._w, self._r)

  class SocketPinger (object):
    def __init__ (self, pair):
      self._w = pair[1]
      self._r = pair[0]
    def ping (self):
      self._w.send(' ')
    def pong (self):
      self._r.recv(1)
    def pongAll (self):
      #TODO: make this actually read all
      self._r.recv(1024)
    def fileno (self):
      return self._r.fileno()
    def __repr__ (self):
      return "<%s %s/%s>" % (self.__class__.__name__, self._w, self._r)

  #return PipePinger((os.pipe()[0],os.pipe()[1]))  # To test failure case

  if os.name == "posix":
    return PipePinger(os.pipe())

  #TODO: clean up sockets?
  localaddress = '127.127.127.127'
  startPort = 10000

  import socket
  import select

  def tryConnect ():
    l = socket.socket()
    l.setblocking(0)

    port = startPort
    while True:
      try:
        l.bind( (localaddress, port) )
        break
      except:
        port += 1
        if port - startPort > 1000:
          raise RuntimeError("Could not find a free socket")
    l.listen(0)

    r = socket.socket()

    try:
      r.connect((localaddress, port))
    except:
      import traceback
      ei = sys.exc_info()
      ei = traceback.format_exception_only(ei[0], ei[1])
      ei = ''.join(ei).strip()
      log.warning("makePinger: connect exception:\n" + ei)
      return False

    rlist, wlist,elist = select.select([l], [], [l], 2)
    if len(elist):
      log.warning("makePinger: socket error in select()")
      return False
    if len(rlist) == 0:
      log.warning("makePinger: socket didn't connect")
      return False

    try:
      w, addr = l.accept()
    except:
      return False

    #w.setblocking(0)
    if addr != r.getsockname():
      log.info("makePinger: pair didn't connect to each other!")
      return False

    r.setblocking(1)

    # Turn off Nagle
    r.setsockopt(socket.IPPROTO_TCP, socket.TCP_NODELAY, 1)
    w.setsockopt(socket.IPPROTO_TCP, socket.TCP_NODELAY, 1)

    return (r, w)

  # Try a few times
  for i in range(0, 3):
    result = tryConnect()
    if result is not False:
      return SocketPinger(result)

  raise RuntimeError("Could not allocate a local socket pair")
makePinger = make_pinger # Deprecated


def is_subclass (cls, classinfo):
  """
  A more sensible version of the issubclass builtin
  """
  try:
    return issubclass(cls, classinfo)
  except TypeError:
    return False


def str_to_bool (s):
  """
  Given a string, parses out whether it is meant to be True or not
  """
  s = str(s).lower() # Make sure
  if s in ['true', 't', 'yes', 'y', 'on', 'enable', 'enabled', 'ok',
           'okay', '1', 'allow', 'allowed']:
    return True
  try:
    r = 10
    if s.startswith("0x"):
      s = s[2:]
      r = 16
    i = int(s, r)
    if i != 0:
      return True
  except:
    pass
  return False


def hexdump (data):
  """
  Converts raw data to a hex dump
  """
  if isinstance(data, (str,bytes)):
    data = [ord(c) for c in data]
  o = ""
  def chunks (data, length):
    return (data[i:i+length] for i in xrange(0, len(data), length))
  def filt (c):
    if c >= 32 and c <= 126: return chr(c)
    return '.'

  for i,chunk in enumerate(chunks(data,16)):
    if i > 0: o += "\n"
    o += "%04x: " % (i * 16,)
    l = ' '.join("%02x" % (c,) for  c in chunk)
    l = "%-48s" % (l,)
    l = l[:3*8-1] + "  " + l[3*8:]
    t = ''.join([filt(x) for x in chunk])
    l += '  |%-16s|' % (t,)
    o += l
  return o


def connect_socket_with_backoff (address, port, max_backoff_seconds=32):
  """
  Attempt to connect to the given address and port.

  If the connection attempt fails, exponentially back off, up to the maximum.

  return the connected socket, or raise an exception if the connection
  was unsuccessful by the time the maximum was reached.

  Note: blocks while connecting.
  """
  #TODO: Remove?  The backoff IOWorker seems like a better way to do this
  #      in general.
  backoff_seconds = 1
  sock = None
  print("connect_socket_with_backoff(address=%s, port=%d)"
        % (address, port), file=sys.stderr)
  while True:
    try:
      sock = socket.socket()
      sock.connect( (address, port) )
      break
    except socket.error as e:
      print("%s. Backing off %d seconds ..." % (str(e), backoff_seconds),
            file=sys.stderr)
      if backoff_seconds >= max_backoff_seconds:
        raise RuntimeError("Could not connect to controller %s:%d"
                           % (address, port))
      else:
        time.sleep(backoff_seconds)
      backoff_seconds <<= 1
  return sock


_scalar_types = (int, long, basestring, float, bool)

def is_scalar (v):
  """
  Is the given value a scalar-like object?
  """
  return isinstance(v, _scalar_types)


def is_listlike (o):
  """
  Is this a sequence that isn't like a string or bytes?
  """
  if isinstance(o, (bytes,str,bytearray)): return False
  return isinstance(o, collections.Iterable)


def fields_of (obj, primitives_only=False,
               primitives_and_composites_only=False, allow_caps=False,
               ignore=set()):
  """
  Returns key/value pairs of things that seem like public fields of an object.
  """
  #NOTE: The above docstring isn't split into two lines on purpose.
  #NOTE: See Python builtin vars().

  r = {}
  for k in dir(obj):
    if k.startswith('_'): continue
    if k in ignore: continue
    v = getattr(obj, k)
    if hasattr(v, '__call__'): continue
    if not allow_caps and k.upper() == k: continue
    if primitives_only:
      if not isinstance(v, _scalar_types):
        continue
    elif primitives_and_composites_only:
      if not isinstance(v, (int, long, basestring, float, bool, set,
                            dict, list)):
        continue
    #r.append((k,v))
    r[k] = v
  return r


def eval_args (f):
  """
  A decorator which causes arguments to be interpreted as Python literals

  This isn't a generic decorator, but is specifically meant for POX component
  launch functions -- the actual magic is in POX's boot code.
  The intention is for launch function/commandline arguments (normally all
  strings) to easily receive other types.
  """
  f._pox_eval_args = True
  return f


if __name__ == "__main__":
  #TODO: move to tests?
  def cb (t,k,v): print(v)
  l = DirtyList([10,20,30,40,50])
  l.callback = cb

  l.append(3)

  print(l)

########NEW FILE########
__FILENAME__ = color
# Copyright 2011 James McCauley
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at:
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# NOTE: Not platform independent -- uses VT escape codes

# Magic sequence used to introduce a command or color
MAGIC = "@@@"

# Colors for log levels
LEVEL_COLORS = {
  'DEBUG': 'CYAN',
  'INFO': 'GREEN',
  'WARNING': 'YELLOW',
  'ERROR': 'RED',
  'CRITICAL': 'blink@@@RED',
}

# Will get set to True if module is initialized
enabled = False

# Gets set to True if we should strip special sequences but
# not actually try to colorize
_strip_only = False

import logging
import sys

# Name to (intensity, base_value) (more colors added later)
COLORS = {
 'black' : (0,0),
 'red' : (0,1),
 'green' : (0,2),
 'yellow' : (0,3),
 'blue' : (0,4),
 'magenta' : (0,5),
 'cyan' : (0,6),
 'gray' : (0,7),
 'darkgray' : (1,0),
 'pink' : (1,1),
 'white' : (1,7),
}

# Add intense/bold colors (names it capitals)
for _c in [_n for _n,_v in COLORS.items() if _v[0] == 0]:
  COLORS[_c.upper()] = (1,COLORS[_c][1])

COMMANDS = {
  'reset' : 0,
  'bold' : 1,
  'dim' : 2,
  'bright' : 1,
  'dull' : 2,
  'bright:' : 1,
  'dull:' : 2,
  'blink' : 5,
  'BLINK' : 6,
  'invert' : 7,
  'bg:' : -1, # Special
  'level' : -2, # Special -- color of current level
  'normal' : 22,
  'underline' : 4,
  'nounderline' : 24,
}


# Control Sequence Introducer
CSI = "\033["

def _color (color, msg):
  """ Colorizes the given text """
  return _proc(MAGIC + color) + msg + _proc(MAGIC + 'reset').lower()

def _proc (msg, level_color = "DEBUG"):
  """
  Do some replacements on the text
  """
  msg = msg.split(MAGIC)
  #print "proc:",msg
  r = ''
  i = 0
  cmd = False
  while i < len(msg):
    m = msg[i]
    #print i,m
    i += 1
    if cmd:
      best = None
      bestlen = 0
      for k,v in COMMANDS.iteritems():
        if len(k) > bestlen:
          if m.startswith(k):
            best = (k,v)
            bestlen = len(k)
      special = None
      if best is not None and best[0].endswith(':'):
        special = best
        m = m[bestlen:]
        best = None
        bestlen = 0
      for k,v in COLORS.iteritems():
        if len(k) > bestlen:
          if m.startswith(k):
            best = (k,v)
            bestlen = len(k)
      if best is not None:
        #print "COMMAND", best
        m = m[bestlen:]
        if type(best[1]) is tuple:
          # Color
          brightness,color = best[1]
          if special is not None:
            if special[1] == -1:
              brightness = None
              color += 10
          color += 30
          if not _strip_only:
            r += CSI
            if brightness is not None:
              r += str(brightness) + ";"
            r += str(color) + "m"
        elif not _strip_only:
          # Command
          if best[1] == -2:
            r += _proc(MAGIC + LEVEL_COLORS.get(level_color, ""), level_color)
          else:
            r += CSI + str(best[1]) + "m"
    cmd = True
    r += m
  return r


def launch (entire=False):
  """
  If --entire then the whole message is color-coded, otherwise just the
  log level.

  Also turns on interpretation of some special sequences in the log
  format string.  For example, try:
   log --format="%(levelname)s: @@@bold%(message)s@@@normal" log.color
  """

  global enabled
  if enabled: return

  from pox.core import core
  log = core.getLogger()

  windows_hack = False

  # Try to work on Windows
  if sys.platform == "win32":
    try:
      from colorama import init
      windows_hack = True
      init()
    except:
      log.info("You need colorama if you want color logging on Windows")
      global _strip_only
      _strip_only = True

  from pox.core import _default_log_handler as dlf
  if not dlf:
    log.warning("Color logging disabled -- no default logger found")
    return
  #if not hasattr(dlf, 'formatter'):
  #  log.warning("Color logging disabled -- no formatter found")
  #  return
  #if not hasattr(dlf.formatter, '_fmt'):
  #  log.warning("Color logging disabled -- formatter unrecognized")
  #  return

  # Monkeypatch in a new format function...
  old_format = dlf.format
  if entire:
    def new_format (record):
      msg = _proc(old_format(record), record.levelname)
      color = LEVEL_COLORS.get(record.levelname)
      if color is None:
        return msg
      return _color(color, msg)
  else:
    def new_format (record):
      color = LEVEL_COLORS.get(record.levelname)
      oldlevelname = record.levelname
      if color is not None:
        record.levelname = _color(color, record.levelname)
      r = _proc(old_format(record), oldlevelname)
      record.levelname = oldlevelname
      return r
  dlf.format = new_format

  if windows_hack:
    if hasattr(dlf, "stream"):
      if dlf.stream is sys.__stderr__:
        dlf.stream = sys.stderr
        enabled = True
  else:
    enabled = True

########NEW FILE########
__FILENAME__ = level
# Copyright 2013 James McCauley
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at:
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from pox.core import core
import logging
import string

def launch (__INSTANCE__=None, **kw):
  """
  Allows configuring log levels from the commandline.

  For example, to turn off the verbose web logging, try:
  pox.py web.webcore log.level --web.webcore=INFO
  """
  for k,v in kw.iteritems():
    if v is True:
      # This means they did something like log.level --DEBUG
      v = k
      k = "" # Root logger
    try:
      v = int(v)
    except:
      old = v
      v = logging.DEBUG
      def dofail ():
        core.getLogger(k).error("Bad log level: %s. Defaulting to DEBUG.", old)

      if (len(old) == 0) or (len(old.strip(string.ascii_uppercase)) != 0):
        dofail()
      else:
        vv = getattr(logging, old, None)
        if not isinstance(vv, int):
          dofail()
        else:
          v = vv

    core.getLogger(k).setLevel(v)

########NEW FILE########
__FILENAME__ = ajax_transport
# Copyright 2012 James McCauley
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at:
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""
Connects the POX messenger bus to a JSON-RPC based web client.
Requires the "webserver" and "messenger" components.

A disclaimer:
  I think the term "AJAX" is dumb.  But this module was
  originally called httpjsonrpc_transport and had classes with
  names like HTTPJSONRPCConnection and I just couldn't take it.
"""

import time
import select
import threading

from pox.core import core
from pox.web.jsonrpc import JSONRPCHandler, make_error, ABORT
from pox.lib.recoco import Timer
from pox.messenger import Connection, Transport

log = core.getLogger()

SESSION_TIMEOUT = 60#120 # Seconds
CONNECTION_TIMEOUT = 30 # Seconds
MAX_TX_COUNT = 20 # Max messages to send at once


class AjaxTransport (Transport):
  """
  Messenger transport for Messenger Over JSON-RPC Over HTTP.
  """
  def __init__ (self, nexus = None):
    Transport.__init__(self, nexus)
    self._connections = {}
    self._t = Timer(SESSION_TIMEOUT, self._check_timeouts, recurring=True)

  def _check_timeouts (self):
    for c in self._connections.values():
      c._check_timeout()

  def _forget (self, connection):
    # From Transport
    if connection._session_id in self._connections:
      del self._connections[connection._session_id]
    else:
      #print "Failed to forget", connection
      pass

  def create_session (self):
    ses = AjaxConnection(self)
    self._connections[ses._session_id] = ses
    return ses

  def get_session (self, key):
    return self._connections.get(key, None)


def _result (m):
  return {'result':m}


class AjaxConnection (Connection):
  """
  Messenger connection for Messenger Over JSON-RPC Over HTTP.

  Note: The sequence numbers used by this module simply increment and
        never wrap.  This should mean like nine quadrillion, but it
        depends on your browser and I definitely haven't tested this. :)
  """
  def __init__ (self, transport):
    Connection.__init__(self, transport)
    self._cond = threading.Condition()
    self._quitting = False

    # We're really protected from attack by the session key, we hope, so
    # we currently start tx_seq at zero, which makes it easier for the
    # client.
    self._next_tx_seq = 0  # next seq to create
    self._sent_tx_seq = -1 # last seq sent
    self._rx_seq = None

    # Waiting outgoing messages as (seq, msg) pairs
    self._tx_buffer = []

    # Out-of-order messages we've gotten (the in-order ones are dispatched
    # immediately, so they're never buffered)
    self._rx_buffer = []

    self._touch()

    self._send_welcome()

  def _touch (self):
    self._touched = time.time()

  def _check_timeout (self):
    if (time.time() - self._touched) > SESSION_TIMEOUT:
      log.info("Session " + self._session_id + " timed out")
      self._close()

  def _close (self):
    super(AjaxConnection, self)._close()
    #TODO: track request sockets and cancel them?
    self._quitting = True

  def send (self, data):
    if self._is_connected is False: return False
    self._cond.acquire()
    self._tx_buffer.append((self._next_tx_seq, data))
    self._next_tx_seq += 1
    self._cond.notify()
    self._cond.release()

  def _get_tx_batch (self, seq, batch_size = None):
    """
    Returns the next batch of messages to send
    """
    if batch_size is None: batch_size = MAX_TX_COUNT
    o = []
    for m in self._tx_buffer:
      if m[0] < seq: continue
      o.append(m)
      if len(o) >= batch_size:
        break
    return o

  def tx (self, wfile, seq, batch_size):
    """
    Sends outgoing messages to a waiting client.

    Can block long-polling style for a while to wait
    until it has some to send.
    """
    ack = True
    if seq is None:
      seq = self._sent_tx_seq + 1
    else:
      if seq > self._sent_tx_seq + 1:
        # Client asked for something without asking for something before it
        log.debug("Client is living in the future (they sent seq %s but "
                  + "we are only at %s)", seq, self._sent_tx_seq+1)
        ack = False
        #NOTE: They get back from where we are, not from where requested

    if ack:
      # Throw away everything before what they're asking for
      while len(self._tx_buffer):
        if self._tx_buffer[0][0] >= seq: break
        del self._tx_buffer[0]

    with self._cond:
      data = self._get_tx_batch(seq = seq, batch_size = batch_size)
      if len(data) == 0:
        # Wait for messages
        start_time = time.time()
        while True:
          # Every couple seconds check if the socket is dead
          self._cond.wait(2)
          data = self._get_tx_batch(seq = seq, batch_size = batch_size)
          if len(data) > 0:
            # See if we can get a bit more data
            self._cond.wait(.05)
            data = self._get_tx_batch(seq = seq, batch_size = batch_size)
            break
          if self._quitting: break
          r,w,x = select.select([wfile],[],[wfile], 0)
          if len(r) or len(x):
            # Other side disconnected?
            #log.debug("Connection cancelled")
            ##self._cond.release()
            return ABORT
          if time.time() - start_time > CONNECTION_TIMEOUT:
            # Let them reconnect.
            return _result({'seq':seq,'messages':[]})
      # Okay, we have messages
      if self._quitting:
        #NOTE: we don't drain the messages first, but maybe we should?
        ##self._cond.release()
        return _result({'messages':[],'failure':'quit',
                        'seq':self._sent_tx_seq})

      if len(data) > 0:
        if seq < data[0][0]:
         # Bad news.  Requesting stuff we don't have.
         return _result({'messages':[],'failure':'expired',
                         'seq':self._sent_tx_seq})

        if data[0][0] != seq:
          log.info("First sequence sent is not the one asked for")
          seq = data[0][0]

        last = data[-1][0]
        if last > self._sent_tx_seq:
          self._sent_tx_seq = last

      data = [d[1] for d in data]

      #print "Sending",len(data),"of",len(self._tx_buffer)

      return _result({'seq':seq, 'messages':data})

  def rx (self, msg, seq):
    """
    Receive a message (or more than one) from RPC
    """
    good = True
    def do_rx (msg):
      if isinstance(msg, list):
        for m in msg:
          self._rx_message(m)
      else:
        self._rx_message(msg)

    if self._rx_seq is None:
      self._rx_seq = seq
    if seq is None:
      # Just do it
      do_rx(msg)
    elif seq == self._rx_seq:
      self._rx_seq += 1
      do_rx(msg)
      if len(self._rx_buffer) > 0:
        self._rx_buffer.sort()
        if self._rx_buffer[0][0] != self._rx_seq:
          log.info("Still out of order")
          good = False
        else:
          log.info("Resuming rx")
          # This is kind of ugly (recursion would be nicer)
          while self._rx_buffer[0][0] == self._rx_seq:
            m = self._rx_buffer.pop(0)
            self._rx_seq += 1
            do_rx(msg)
          if len(self._rx_buffer) > 0:
            log.info("Re-suspending rx")
            good = False
    else:
      good = False
      self._rx_buffer.append((seq, msg))
      if len(self._rx_buffer) == 1: # First time
        log.info("Got out of order message -- suspending rx")

    return _result({'ok':good,'ack':self._rx_seq})


class AjaxMsgHandler (JSONRPCHandler):
  """
  Handles JSON-RPC messages from webcore for messenger.
  """

  def _exec_stop (self, session_id):
    """
    End a session

    You can always just stop and wait for it to time out, but this is nice
    if you can swing it.
    """
    ses = self._get_session(session_id, create = False)
    if ses is not None:
      log.info("Session " + str(session_id) + " closed")
      ses._close()
    return {'result':True}

  def _exec_send (self, session_id, msg, seq = None):
    """
    Send a message (or messages)

    If seq is specified, it is a sequence number.  This can help
    eliminate problems with ordering.
    """
    ses = self._get_session(session_id)
    if ses is None:
      return make_error("No such session")
    r = ses.rx(msg, seq)
    if isinstance(r, dict) and 'result' in r:
      r['result']['session'] = ses._session_id
    return r

  def _exec_poll (self, session_id, seq = None, batch_size = None):
    """
    Get waiting messages

    If seq is specified, it is the sequence number of the first
    message you want.  This acks all previous messages.
    If batch_size is specified, it is how many messages you want.
    """
    ses = self._get_session(session_id)
    if ses is None:
      #return make_error("No such session")
      return {'messages':[], 'failure':'No session'}

    r = ses.tx(self.wfile, seq, batch_size)
    if isinstance(r, dict) and 'result' in r:
      r['result']['session'] = ses._session_id
    return r

  def _get_session (self, key, create = True):
    if key == "new!":
      if not create: return None
      return self._arg_transport.create_session()
    ses = self._arg_transport.get_session(key)
    if ses is not None:
      ses._touch()
    return ses


def launch (username='', password=''):
  def _launch ():
    transport = core.registerNew(AjaxTransport)

    # Set up config info
    cfg = {"transport":transport}
    if len(username) and len(password):
      cfg['auth'] = lambda u, p: (u == username) and (p == password)

    core.WebServer.set_handler("/_jrpcmsg/",AjaxMsgHandler,cfg,True)

  core.call_when_ready(_launch, ["WebServer","MessengerNexus"],
                       name = "ajax_transport")

########NEW FILE########
__FILENAME__ = example
# Copyright 2011,2012 James McCauley
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at:
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""
Messenger can be used in many ways.  This shows a few of them.

Creates a channel called "time" which broadcasts the time.
Creates a channel called "chat" which relays messages to its members.
Listens for channels called "echo_..." and responds to message in them.
Listens for messages on a channel named "upper" and responds in upper case.
Creates a bot ("GreetBot") which can be invited to other channels.

Note that the echo and upper are really similar, but echo uses the channel
mechanism (e.g., clients join a channel), whereas upper keeps track of
members itself and clients are not expected to actually join the upper
channel -- it's just used like an address to send messages to.
This is just showing that there are multiple ways to go about doing things.
"""

from pox.core import core
from pox.messenger import *

log = core.getLogger()

class UpperService (object):
  def __init__ (self, parent, con, event):
    self.con = con
    self.parent = parent
    self.listeners = con.addListeners(self)
    self.count = 0

    # We only just added the listener, so dispatch the first
    # message manually.
    self._handle_MessageReceived(event, event.msg)

  def _handle_ConnectionClosed (self, event):
    self.con.removeListeners(self.listeners)
    self.parent.clients.pop(self.con, None)

  def _handle_MessageReceived (self, event, msg):
    self.count += 1
    self.con.send(reply(msg, count = self.count,
                        msg = str(msg.get('msg').upper())))


class UpperBot (ChannelBot):
  def _init (self, extra):
    self.clients = {}

  def _unhandled (self, event):
    connection = event.con
    if connection not in self.clients:
      self.clients[connection] = UpperService(self, connection, event)


class EchoBot (ChannelBot):
  count = 0
  def _exec_msg (self, event, value):
    self.count += 1
    self.reply(event, msg = "%i: %s" % (self.count, value))


class GreetBot (ChannelBot):
  def _join (self, event, connection, msg):
    from random import choice
    greet = choice(['hello','aloha','greeings','hi',"g'day"])
    greet += ", " + str(connection)
    self.send({'greeting':greet})


class MessengerExample (object):
  def __init__ (self):
    core.listen_to_dependencies(self)

  def _all_dependencies_met (self):
    # Set up the chat channel
    chat_channel = core.MessengerNexus.get_channel("chat")
    def handle_chat (event, msg):
      m = str(msg.get("msg"))
      chat_channel.send({"msg":str(event.con) + " says " + m})
    chat_channel.addListener(MessageReceived, handle_chat)

    # Set up the time channel...
    time_channel = core.MessengerNexus.get_channel("time")
    import time
    def timer ():
      time_channel.send({'msg':"It's " + time.strftime("%I:%M:%S %p")})
    from pox.lib.recoco import Timer
    Timer(10, timer, recurring=True)

    # Set up the "upper" service
    UpperBot(core.MessengerNexus.get_channel("upper"))

    # Make GreetBot invitable to other channels using "invite"
    core.MessengerNexus.default_bot.add_bot(GreetBot)

  def _handle_MessengerNexus_ChannelCreate (self, event):
    if event.channel.name.startswith("echo_"):
      # Ah, it's a new echo channel -- put in an EchoBot
      EchoBot(event.channel)


def launch ():
  MessengerExample()

########NEW FILE########
__FILENAME__ = log_service
# Copyright 2011,2012 James McCauley
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at:
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""
This is a messenger service for working with the log.

It does two things:
  a) Listen on the "log" channel.  You can send messages to this
     channel with keys lowerLevels/RaiseLevels/setLevels to adjust
     global log levels.  See _process_commands() for more info.
  b) You can join any channel named log_<something> (your session
     ID is a good choice for the something), and a LogBot will
     join it.  This will result in receiving log messages.  In
     your join message (or afterwards), you can configure levels,
     the message formats, etc.  See LogService for more details.
"""

from pox.core import core
from pox.messenger import *
from pox.lib.revent.revent import autoBindEvents
import logging
import traceback

log = core.getLogger()

# These attributes are copied verbatim from the log record
_attributes = [
  'created','filename','funcName','levelname','levelno','lineno',
  'module','msecs','name','pathname','process','processName',
  'relativeCreated','thread','threadName','args',
]


class LogFilter (object):
  """
  Filters messages from the web server component

  It's a nasty situation when you're using the HTTP messenger transport
  to view the log when in debug mode, as every webserver log message
  creates a messenger message which creates a webserver message, ...

  This just turns off debug messages from the webserver.
  """
  def filter (self, record):
    if record.levelno != logging.DEBUG: return True
    if record.name == "web.webcore.server": return False
    return True


class LogHandler (logging.Handler):
  """
  A Python logging.Handler for the messenger

  Accepts dictionaries with configuration info:
  KEY            VALUE
  level          Minimum log level to output (probably one of CRITICAL,
                 ERROR, WARNING, INFO or DEBUG)
  format         fmt argument to logging.Formatter
  dateFormat     datefmt argument to logging.Formatter
  json           true if you want a bunch of attributes from the LogRecord to
                 be included.  In some cases these are stringized since  the
                 originals are objects and we don't pickle/jsonpickle them.
  subsystems     A list of logger names to listen to.  A "null"/None entry in
                 the list means the root logger (which is also the default).
  add_subsystems A list of ADDITIONAL subsystems to listen to.
  """
  #NOTE: We take advantage of the fact that the default value for the
  #      argument to getLogger() is None.  This is currently true, but
  #      isn't documented, so it might change in the future (though I
  #      don't see why it would!).  Doing this "the right way" results
  #      in much uglier code.

  def __init__ (self, channel, params):
    logging.Handler.__init__(self)
    self._channel = channel
    self.addFilter(LogFilter())
    self._json = False
    self._format = False # Not valid, should never be set
    self._dateFormat = None
    self.subsystems = []
    if "format" not in params:
      params["format"] = None # Force update
    if 'subsystems' not in params:
      self._add_subsystems([None])

    self._process_parameters(params)

  def _add_subsystems (self, subsystems):
    """
    Add log subsystems to listen to
    """
    for subsystem in subsystems:
      if subsystem in self.subsystems: continue
      try:
        logging.getLogger(subsystem).addHandler(self)
        self.subsystems.append(subsystem)
      except:
        pass

  def _drop_subsystems (self):
    """
    Stop listening to all log subsystems
    """
    for subsystem in self.subsystems:
      logging.getLogger(subsystem).removeHandler(self)
    self.subsystems = []

  def _process_parameters (self, params):
    if "level" in params:
      self.setLevel(params["level"])
    if "subsystems" in params:
      self._drop_subsystems()
      self._add_subsystems(params['subsystems'])
    if 'add_subsystems' in params:
      self._add_subsystems(params['add_subsystems'])
    if 'remove_subsystems' in params:
      #TODO
      log.error('remove_subsystems unimplemented')
    if "json" in params:
      self._json = params['json']
    if "setLevels" in params:
      levels = params['setLevels']
      if isinstance(levels, dict):
        for k,v in levels.iteritems():
          l = core.getLogger(k)
          l.setLevel(v)
      else:
        core.getLogger().setLevel(levels)

    doFormat = False
    if "format" in params:
      fmt = params['format']
      if fmt is not self._format:
        self._format = fmt
        doFormat = True
    if "dateFormat" in params:
      dateFormat = params['dateFormat']
      if dateFormat is not self._dateFormat:
        self._dateFormat = dateFormat
        doFormat = True

    if doFormat:
      self.setFormatter(logging.Formatter(self._format, self._dateFormat))

  def _close (self):
    self._drop_subsystems()

  def emit (self, record):
    o = {'message' : self.format(record)}
    #o['message'] = record.getMessage()
    if self._json:
      for attr in _attributes:
        o[attr] = getattr(record, attr)
      o['asctime'] = self.formatter.formatTime(record, self._dateFormat)
      if record.exc_info:
        o['exc_info'] = [str(record.exc_info[0]),
                         str(record.exc_info[1]),
                         traceback.format_tb(record.exc_info[2],1)]
        o['exc'] = traceback.format_exception(*record.exc_info)
    self._channel.send(o)


def _process_commands (msg):
  """
  Processes logger commands
  """
  def get (key):
    r = msg.get(key)
    if r is not None:
      if not isinstance(r, dict):
        r = {None:r}
    else:
      return {}
    return r

  lowerLevels = get("lowerLevels") # less verbose
  raiseLevels = get("raiseLevels") # more verbose
  setLevels = get("setLevels")

  for k,v in lowerLevels.iteritems():
    logger = core.getLogger(k)
    level = logging._checkLevel(v)
    if not l.isEnabledFor(level+1):
      logger.setLevel(v)

  for k,v in raiseLevels.iteritems():
    logger = core.getLogger(k)
    if not l.isEnabledFor(v):
      logger.setLevel(v)

  for k,v in setLevels.iteritems():
    logger = core.getLogger(k)
    logger.setLevel(v)

  message = msg.get("message", None)
  if message:
    level = msg.get("level", "DEBUG")
    if isinstance(level, basestring):
      import logging
      if not level.isalpha():
        level = logging.DEBUG
      else:
        level = level.upper()
        level = getattr(logging, level, logging.DEBUG)
    sub = msg.get("subsystem", "<external>")
    logging.getLogger(sub).log(level, message)


class LogBot (ChannelBot):
  def _init (self, extra):
    self._handler = None

  def _join (self, event, con, msg):
    #self.reply(event, hello = "Hello, %s!" % (con,))
    if self._handler is not None:
      log.warning("Multiple clients on channel " + self.channel.name)
    else:
      self._handler = LogHandler(self.channel, msg)

  def _leave (self, con, empty):
    if empty:
      self._handler._close()
      self._handler = None

  def _unhandled (self, event):
    _process_commands(event.msg)
    self._handler._process_parameters(event.msg)


def _handle_new_channel (event):
  if event.channel.name.startswith("log_"):
    # New channel named log_<something>?  Add a log bot.
    LogBot(event.channel)

def launch (nexus = "MessengerNexus"):
  def start (nexus):
    # One bot for default log channel
    real_nexus = core.components[nexus]
    LogBot(real_nexus.get_channel('log'))

    # This will create new channels on demand
    real_nexus.addListener(ChannelCreate, _handle_new_channel)

  core.call_when_ready(start, nexus, args=[nexus])

########NEW FILE########
__FILENAME__ = tcp_transport
# Copyright 2011,2012 James McCauley
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at:
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from pox.lib.revent.revent import *
from pox.core import core as core
from pox.messenger import *

log = core.getLogger()

from pox.lib.recoco.recoco import *

class TCPTransport (Task, Transport):
  def __init__ (self, address = "0.0.0.0", port = 7790, nexus = None):
    port = int(port)
    Task.__init__(self)
    Transport.__init__(self, nexus)
    self._addr = (address,port)
    self._connections = set()

  def _forget (self, connection):
    """ Forget about a connection (because it has closed) """
    if connection in self._connections:
      #print "forget about",connection
      self._connections.remove(connection)

  def run (self):
    listener = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
    listener.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
    listener.bind(self._addr)
    listener.listen(0)

    log.debug("Listening on %s:%i" % (self._addr))

    con = None
    while core.running:
      try:
        rlist, wlist, elist = yield Select([listener])
        if len(rlist) == 0:
          # Must have been interrupted
          break

        rc = TCPConnection(self, listener.accept()[0])
        self._connections.add(rc)
        rc.start()
      except:
        traceback.print_exc()
        break

    try:
      listener.close()
    except:
      pass
    log.debug("No longer listening for connections")


class TCPConnection (Connection, Task):
  def __init__ (self, transport, socket):
    self._socket = socket
    # Note: we cache name of the socket because socket.getpeername()
    # is unavailable after the socket was closed!
    self._socket_name = self._get_socket_name(socket)
    Connection.__init__(self, transport)
    Task.__init__(self)

    #self.start()
    self._send_welcome()

  def _close (self):
    super(TCPConnection, self)._close()
    try:
      self._socket.shutdown(socket.SHUT_RDWR)
    except:
      pass

  def send_raw (self, data):
    try:
      l = self._socket.send(data)
      if l == len(data): return
    except:
      pass
    #TODO: do something more graceful!
    self._close()

  def run (self):
    log.debug("%s started" % (self,))
    while self.is_connected:
      d = yield Recv(self._socket)
      if d is None or len(d) == 0:
        break
      #print "RECV", d
      self._rx_raw(d)
    self._close()
    log.debug("%s stopped" % (self,))

  def __str__ (self):
    s = "" + self.__class__.__name__ + " " + self._socket_name
    return s

  @staticmethod
  def _get_socket_name(socket):
    s = "%s:%i" % socket.getsockname()
    s += "/%s:%i" % socket.getpeername()
    return s


import pox.core

def launch (tcp_address = "0.0.0.0", tcp_port = 7790):
  def start ():
    t = TCPTransport(tcp_address, tcp_port)
    t.start()
  core.call_when_ready(start, "MessengerNexus", __name__)

########NEW FILE########
__FILENAME__ = test_client
#!/usr/bin/env python

# Copyright 2012 James McCauley
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at:
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""
This is NOT a POX component.  It's a little tool to test out the messenger.
"""

import socket
import threading
import json

class JSONDestreamer (object):
  import json
  decoder = json.JSONDecoder()
  def __init__ (self, callback = None):
    self._buf = ''
    self.callback = callback if callback else self.rx

  def push (self, data):
    if len(self._buf) == 0:
      data = data.lstrip()
    self._buf += data
    try:
      while len(self._buf) > 0:
        r,off = self.decoder.raw_decode(self._buf)

        self._buf = self._buf[off:].lstrip()
        self.callback(r)
    except ValueError:
      pass

  def rx (self, data):
    import json
    print "Recv:", json.dumps(data, indent=4)

jd = JSONDestreamer()
done = False

def reader (socket):
  global done
  while True:
    d = socket.recv(1024)
    if d == "":
      done = True
      break
    jd.push(d)

cur_chan = None
def channel (ch):
  global cur_chan
  cur_chan = ch

import readline

def main (addr = "127.0.0.1", port = 7790):
  print "Connecting to %s:%i" % (addr,port)
  port = int(port)

  sock = socket.create_connection((addr, port))

  t = threading.Thread(target=reader, args=(sock,))
  t.daemon = True
  t.start()

  while not done:
    try:
      #print ">",
      m = raw_input()
      if len(m) == 0: continue
      m = eval(m)
      if not isinstance(m, dict):
        continue
      if cur_chan is not None and 'CHANNEL' not in m:
        m['CHANNEL'] = cur_chan
      m = json.dumps(m)
      sock.send(m)
    except EOFError:
      break
    except KeyboardInterrupt:
      break
    except:
      import traceback
      traceback.print_exc()

if __name__ == "__main__":
  import sys
  main(*sys.argv[1:])

########NEW FILE########
__FILENAME__ = web_transport
# Copyright 2011,2012 James McCauley
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at:
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""
Connects the POX messenger bus to HTTP.

Requires the "webserver" component.

NOTE: The web_transport keeps its own session IDs.  Since it was first
      written, though, sessions IDs have become part of every
      Connection, and we could (but are not) reuse those.
"""

from SocketServer import ThreadingMixIn
from BaseHTTPServer import *
import time
import select

import random
import hashlib
import base64
import json

from pox.lib.recoco import Timer

from pox.messenger import Connection, Transport

from pox.core import core

from pox.web.webcore import *

log = core.getLogger()


class HTTPConnection (Connection):
  def __init__ (self, transport):
    Connection.__init__(self, transport)
    self._messages = []
    self._cond = threading.Condition()
    self._quitting = False

    # We're really protected from attack by the session key, we hope
    self._tx_seq = -1 #random.randint(0, 1 << 32)
    self._rx_seq = None

    #self._t = Timer(10, lambda : self.send({'hi':'again'}), recurring=True)

    self._touched = time.time()

    self._send_welcome()

  def _check_timeout (self):
    if (time.time() - self._touched) > 120:
      log.info("Session " + str(self) + " timed out")
      self._close()

  def _new_tx_seq (self):
    self._tx_seq = (self._tx_seq + 1) & 0x7fFFffFF
    return self._tx_seq

  def _check_rx_seq (self, seq):
    seq = int(seq)
    if self._rx_seq is None: self._rx_seq = seq

    if seq != self._rx_seq: return False

    self._rx_seq = (self._rx_seq + 1) & 0x7fFFffFF
    return True

  def _close (self):
    super(HTTPConnection, self)._close()
    #TODO: track request sockets and cancel them?
    self._quitting = True

  def send_raw (self, data):
    self._cond.acquire()
    self._messages.append(data)
    self._cond.notify()
    self._cond.release()

  def _do_rx_message (self, items):
    for item in items:
      self._rx_message(item)


class HTTPTransport (Transport):
  def __init__ (self, nexus = None):
    Transport.__init__(self, nexus)
    self._connections = {}
    #self._t = Timer(5, self._check_timeouts, recurring=True)
    self._t = Timer(60*2, self._check_timeouts, recurring=True)

  def _check_timeouts (self):
    for c in self._connections.values():
      c._check_timeout()

  def _forget (self, connection):
    # From MessengerTransport
    if connection._session_id in self._connections:
      del self._connections[connection._session_id]
    else:
      #print "Failed to forget", connection
      pass

  def create_session (self):
    ses = HTTPConnection(self)
    self._connections[ses._session_id] = ses
    return ses

  def get_session (self, key):
    return self._connections.get(key, None)



class CometRequestHandler (SplitRequestHandler):
  protocol_version = 'HTTP/1.1'

#  def __init__ (self, *args, **kw):
#    super(CometRequestHandler, self).__init__(*args, **kw)

  def _init (self):
    self.transport = self.args['transport']
    self.auth_function = self.args.get('auth', None)

  def _doAuth (self):
    if self.auth_function:
      auth = self.headers.get("Authorization", "").strip().lower()
      success = False
      if auth.startswith("basic "):
        try:
          auth = base64.decodestring(auth[6:].strip()).split(':', 1)
          success = self.auth_function(auth[0], auth[1])
        except:
          pass
      if success is not True:
        self.send_response(401, "Authorization Required")
        self.send_header("WWW-Authenticate",  'Basic realm="POX"')
        self.end_headers()
        return

  def _getSession (self):
    session_key = self.headers.get("X-POX-Messenger-Session-Key")
    if session_key is None:
      session_key = self.path.split('/')[-1]
    session_key = session_key.strip()
    if len(session_key) == 0:
      #TODO: return some bad response and log
      return None
    if session_key == "new":
      hmh = self.transport.create_session()
    else:
      hmh = self.transport.get_session(session_key)
    #print session_key, hmh.session_key
    return hmh

  def _enter (self):
    self._doAuth()
    hmh = self._getSession()
    if hmh is None:
      #TODO: return some bad response and log
      pass
    else:
      hmh._touched = time.time()
    return hmh

  def do_POST (self):
    hmh = self._enter()
    if hmh is None: return None

    l = self.headers.get("Content-Length", "")
    if l == "":
      data = json.loads(self.rfile.read())
    else:
      data = json.loads(self.rfile.read(int(l)))
    payload = data['data']
    # We send null payload for timeout poking and initial setup
    if 'seq' in data:
      if not hmh._check_rx_seq(data['seq']):
        # Bad seq!
        data = '{"seq":-1,"ses":"%s"}' % (hmh._session_id,)
        self.send_response(400, "Bad sequence number")
        self.send_header("Content-Type", "application/json")
        self.send_header("Content-Length", len(data))
        self.send_header("X-POX-Messenger-Sequence-Number", "-1")
        if self.auth_function: self.send_header("WWW-Authenticate",
                                                'Basic realm="POX"')
        self.end_headers()
        self.wfile.write(data)
        hmh._close()
        return
      if payload is not None:
        core.callLater(hmh._do_rx_message, payload)

    try:
      data = '{"seq":-1,"ses":"%s"}' % (hmh._session_id,)
      self.send_response(200, "OK")
      self.send_header("Content-Type", "application/json")
      self.send_header("Content-Length", len(data))
      self.send_header("X-POX-Messenger-Sequence-Number", "-1")
      if self.auth_function: self.send_header("WWW-Authenticate",
                                              'Basic realm="POX"')
      self.end_headers()
      self.wfile.write(data)
    except:
      import traceback
      traceback.print_exc()
      pass
    return

  def do_GET (self):
    hmh = self._enter()
    if hmh is None: return None

    hmh._cond.acquire()
    if len(hmh._messages) == 0:
      # Wait for messages
      while True:
        # Every couple seconds check if the socket is dead
        hmh._cond.wait(2)
        if len(hmh._messages): break
        if hmh._quitting: break
        r,w,x = select.select([self.wfile],[],[self.wfile], 0)
        if len(r) or len(x):
          # Other side disconnected?
          hmh._cond.release()
          return
    # Okay...
    if hmh._quitting:
      #NOTE: we don't drain the messages first, but maybe we should?
      try:
        data = '{"seq":-1,"ses":"%s"}' % (hmh._session_id,)
        self.send_response(200, "OK")
        self.send_header("Content-Type", "application/json")
        self.send_header("Content-Length", len(data))
        self.send_header("X-POX-Messenger-Sequence-Number", "-1")
        if self.auth_function: self.send_header("WWW-Authenticate",
                                                'Basic realm="POX"')
        self.end_headers()
        self.wfile.write(data)
      except:
        pass
      hmh._cond.release()
      return

    num_messages = min(20, len(hmh._messages))
    data = hmh._messages[:num_messages]
    old_seq = hmh._tx_seq
    seq = hmh._new_tx_seq()
    data = '{"seq":%i,"ses":"%s","data":[%s]}' % (seq, hmh._session_id,
                                                  ','.join(data))
    try:
      self.send_response(200, "OK")
      self.send_header("Content-Type", "application/json")
      self.send_header("Content-Length", len(data))
      self.send_header("X-POX-Messenger-Sequence-Number", str(seq))
      if self.auth_function: self.send_header("WWW-Authenticate",
                                              'Basic realm="POX"')
      self.end_headers()
      self.wfile.write(data)
      del hmh._messages[:num_messages]
    except:
      hmh._tx_seq = old_seq
    hmh._cond.release()


def launch (username='', password=''):
  def _launch ():
    transport = core.registerNew(HTTPTransport)

    # Set up config info
    config = {"transport":transport}
    if len(username) and len(password):
      config['auth'] = lambda u, p: (u == username) and (p == password)

    core.WebServer.set_handler("/_webmsg/",CometRequestHandler,config,True)

  core.call_when_ready(_launch, ["WebServer","MessengerNexus"],
                       name = "webmessenger")

########NEW FILE########
__FILENAME__ = cbench
# Copyright 2013 YAMAMOTO Takashi
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at:
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""
a dummy module for oflops cbench benchmark

this is intended to be comparable with ryu cbench app.
	https://github.com/osrg/ryu/blob/master/ryu/app/cbench.py
"""

from pox.core import core
import pox.openflow.libopenflow_01 as of


class CBench (object):
  def __init__ (self, connection):
    self.connection = connection
    connection.addListeners(self)

  def _handle_PacketIn (self, event):
    msg = of.ofp_flow_mod()
    self.connection.send(msg)

class cbench (object):
  def __init__ (self):
    core.openflow.addListeners(self)

  def _handle_ConnectionUp (self, event):
    CBench(event.connection)


def launch ():
  core.registerNew(cbench)

########NEW FILE########
__FILENAME__ = full_payload
# Copyright 2012 James McCauley
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at:
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""
This simple component makes it so that switches send full packet
payloads on table misses.
"""

from pox.core import core
from pox.lib.revent import EventRemove

def launch ():
  def set_miss_length (event = None):
    if not core.hasComponent('openflow'):
      return
    core.openflow.miss_send_len = 0x7fff
    core.getLogger().info("Requesting full packet payloads")
    return EventRemove

  if set_miss_length() is None:
    core.addListenerByName("ComponentRegistered", set_miss_length)

########NEW FILE########
__FILENAME__ = gephi_topo
# Copyright 2013 James McCauley
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at:
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""
Detects topology and streams it to Gephi

Gephi is a pretty awesome graph visualization/manipulation package.  It has
a plugin for streaming graphs back and forth between it and something else.
We use that (by opening a listening socket -- port 8282 by default) and
sending detected switches, links, and (optionally) hosts.

Based on POXDesk's tinytopo module.
Requires discovery.  host_tracker is optional.

pox.py openflow.discovery misc.gephi_topo host_tracker forwarding.l2_learning
"""

from pox.core import core
from pox.lib.util import dpid_to_str
from pox.lib.ioworker.workers import *
from pox.lib.ioworker import *

import json

log = core.getLogger()

class ServerWorker (TCPServerWorker, RecocoIOWorker):
  pass

clients = set()

class GephiWorker (RecocoIOWorker):
  def __init__ (self, *args, **kw):
    super(GephiWorker, self).__init__(*args, **kw)
    self._connecting = True
    self.data = b''

  def _handle_close (self):
    log.info("Client disconnect")
    super(GephiWorker, self)._handle_close()
    clients.discard(self)

  def _handle_connect (self):
    log.info("Client connect")
    super(GephiWorker, self)._handle_connect()
    core.GephiTopo.send_full(self)
    clients.add(self)

  def _handle_rx (self):
    self.data += self.read()
    while '\n' in self.data:
      # We don't currently do anything with this
      msg,self.data = self.data.split('\n',1)

      # This SHOULD be an HTTP request.

      #print msg
      pass


def an (n, **kw):
  kw['label'] = str(n)
  return {'an':{str(n):kw}}

def ae (a, b):
  a = str(a)
  b = str(b)
  if a > b:
    a,b=b,a
  return {'ae':{a+"_"+b:{'source':a,'target':b,'directed':False}}}

def de (a, b):
  a = str(a)
  b = str(b)
  if a > b:
    a,b=b,a
  return {'de':{a+"_"+b:{}}}

def dn (n):
  return {'dn':{str(n):{}}}

def clear ():
  return {'dn':{'filter':'ALL'}}


class GephiTopo (object):
  def __init__ (self):
    core.listen_to_dependencies(self)
    self.switches = set()
    self.links = set()
    self.hosts = {} # mac -> dpid

  def _handle_core_ComponentRegistered (self, event):
    if event.name == "host_tracker":
      event.component.addListenerByName("HostEvent",
          self.__handle_host_tracker_HostEvent)

  def send (self, data):
    for c in clients:
      c.send(json.dumps(data) + '\r\n')

  def send_full (self, client):
    out = []

    out.append(clear())

    for s in self.switches:
      out.append(an(s, kind='switch'))
    for e in self.links:
      out.append(ae(e[0],e[1]))
    for h,s in self.hosts.iteritems():
      out.append(an(h, kind='host'))
      if s in self.switches:
        out.append(ae(h,s))

    out = '\r\n'.join(json.dumps(o) for o in out)

    client.send(out + '\r\n')

  def __handle_host_tracker_HostEvent (self, event):
    # Name is intentionally mangled to keep listen_to_dependencies away
    h = str(event.entry.macaddr)
    s = dpid_to_str(event.entry.dpid)

    if event.leave:
      if h in self.hosts:
        if s in self.switches:
          self.send(de(h,s))
        self.send(dn(h))
        del self.hosts[h]
    else:
      if h not in self.hosts:
        self.hosts[h] = s
        self.send(an(h, kind='host'))
        if s in self.switches:
          self.send(ae(h, s))
        else:
          log.warn("Missing switch")

  def _handle_openflow_ConnectionUp (self, event):
    s = dpid_to_str(event.dpid)
    if s not in self.switches:
      self.send(an(s))
      self.switches.add(s)

  def _handle_openflow_ConnectionDown (self, event):
    s = dpid_to_str(event.dpid)
    if s in self.switches:
      self.send(dn(s))
      self.switches.remove(s)

  def _handle_openflow_discovery_LinkEvent (self, event):
    s1 = event.link.dpid1
    s2 = event.link.dpid2
    s1 = dpid_to_str(s1)
    s2 = dpid_to_str(s2)
    if s1 > s2: s1,s2 = s2,s1

    assert s1 in self.switches
    assert s2 in self.switches

    if event.added and (s1,s2) not in self.links:
      self.links.add((s1,s2))
      self.send(ae(s1,s2))

      # Do we have abandoned hosts?
      for h,s in self.hosts.iteritems():
        if s == s1: self.send(ae(h,s1))
        elif s == s2: self.send(ae(h,s2))

    elif event.removed and (s1,s2) in self.links:
      self.links.remove((s1,s2))
      self.send(de(s1,s2))


def launch (port = 8282):
  core.registerNew(GephiTopo)

  # In theory, we're supposed to be running a web service, but instead
  # we just spew Gephi graph streaming junk at everyone who connects. :)
  global loop
  loop = RecocoIOLoop()
  #loop.more_debugging = True
  loop.start()

  w = ServerWorker(child_worker_type=GephiWorker, port = int(port))
  loop.register_worker(w)

########NEW FILE########
__FILENAME__ = ip_loadbalancer
# Copyright 2013 James McCauley
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at:
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""
A very sloppy IP load balancer.

Run it with --ip=<Service IP> --servers=IP1,IP2,...

Please submit improvements. :)
"""

from pox.core import core
import pox
log = core.getLogger("iplb")

from pox.lib.packet.ethernet import ethernet, ETHER_BROADCAST
from pox.lib.packet.ipv4 import ipv4
from pox.lib.packet.arp import arp
from pox.lib.addresses import IPAddr, EthAddr
from pox.lib.util import str_to_bool, dpid_to_str

import pox.openflow.libopenflow_01 as of

import time
import random

FLOW_IDLE_TIMEOUT = 10
FLOW_MEMORY_TIMEOUT = 60 * 5



class MemoryEntry (object):
  """
  Record for flows we are balancing

  Table entries in the switch "remember" flows for a period of time, but
  rather than set their expirations to some long value (potentially leading
  to lots of rules for dead connections), we let them expire from the
  switch relatively quickly and remember them here in the controller for
  longer.

  Another tactic would be to increase the timeouts on the switch and use
  the Nicira extension which can match packets with FIN set to remove them
  when the connection closes.
  """
  def __init__ (self, server, first_packet, client_port):
    self.server = server
    self.first_packet = first_packet
    self.client_port = client_port
    self.refresh()

  def refresh (self):
    self.timeout = time.time() + FLOW_MEMORY_TIMEOUT

  @property
  def is_expired (self):
    return time.time() > self.timeout

  @property
  def key1 (self):
    ethp = self.first_packet
    ipp = ethp.find('ipv4')
    tcpp = ethp.find('tcp')

    return ipp.srcip,ipp.dstip,tcpp.srcport,tcpp.dstport

  @property
  def key2 (self):
    ethp = self.first_packet
    ipp = ethp.find('ipv4')
    tcpp = ethp.find('tcp')

    return self.server,ipp.srcip,tcpp.dstport,tcpp.srcport


class iplb (object):
  """
  A simple IP load balancer

  Give it a service_ip and a list of server IP addresses.  New TCP flows
  to service_ip will be randomly redirected to one of the servers.

  We probe the servers to see if they're alive by sending them ARPs.
  """
  def __init__ (self, connection, service_ip, servers = []):
    self.service_ip = IPAddr(service_ip)
    self.servers = [IPAddr(a) for a in servers]
    self.con = connection
    self.mac = self.con.eth_addr
    self.live_servers = {} # IP -> MAC,port

    try:
      self.log = log.getChild(dpid_to_str(self.con.dpid))
    except:
      # Be nice to Python 2.6 (ugh)
      self.log = log

    self.outstanding_probes = {} # IP -> expire_time

    # How quickly do we probe?
    self.probe_cycle_time = 5

    # How long do we wait for an ARP reply before we consider a server dead?
    self.arp_timeout = 3

    # We remember where we directed flows so that if they start up again,
    # we can send them to the same server if it's still up.  Alternate
    # approach: hashing.
    self.memory = {} # (srcip,dstip,srcport,dstport) -> MemoryEntry

    self._do_probe() # Kick off the probing

    # As part of a gross hack, we now do this from elsewhere
    #self.con.addListeners(self)

  def _do_expire (self):
    """
    Expire probes and "memorized" flows

    Each of these should only have a limited lifetime.
    """
    t = time.time()

    # Expire probes
    for ip,expire_at in self.outstanding_probes.items():
      if t > expire_at:
        self.outstanding_probes.pop(ip, None)
        if ip in self.live_servers:
          self.log.warn("Server %s down", ip)
          del self.live_servers[ip]

    # Expire old flows
    c = len(self.memory)
    self.memory = {k:v for k,v in self.memory.items()
                   if not v.is_expired}
    if len(self.memory) != c:
      self.log.debug("Expired %i flows", c-len(self.memory))

  def _do_probe (self):
    """
    Send an ARP to a server to see if it's still up
    """
    self._do_expire()

    server = self.servers.pop(0)
    self.servers.append(server)

    r = arp()
    r.hwtype = r.HW_TYPE_ETHERNET
    r.prototype = r.PROTO_TYPE_IP
    r.opcode = r.REQUEST
    r.hwdst = ETHER_BROADCAST
    r.protodst = server
    r.hwsrc = self.mac
    r.protosrc = self.service_ip
    e = ethernet(type=ethernet.ARP_TYPE, src=self.mac,
                 dst=ETHER_BROADCAST)
    e.set_payload(r)
    #self.log.debug("ARPing for %s", server)
    msg = of.ofp_packet_out()
    msg.data = e.pack()
    msg.actions.append(of.ofp_action_output(port = of.OFPP_FLOOD))
    msg.in_port = of.OFPP_NONE
    self.con.send(msg)

    self.outstanding_probes[server] = time.time() + self.arp_timeout

    core.callDelayed(self._probe_wait_time, self._do_probe)

  @property
  def _probe_wait_time (self):
    """
    Time to wait between probes
    """
    r = self.probe_cycle_time / float(len(self.servers))
    r = max(.25, r) # Cap it at four per second
    return r

  def _pick_server (self, key, inport):
    """
    Pick a server for a (hopefully) new connection
    """
    return random.choice(self.live_servers.keys())

  def _handle_PacketIn (self, event):
    inport = event.port
    packet = event.parsed

    def drop ():
      if event.ofp.buffer_id is not None:
        # Kill the buffer
        msg = of.ofp_packet_out(data = event.ofp)
        self.con.send(msg)
      return None

    tcpp = packet.find('tcp')
    if not tcpp:
      arpp = packet.find('arp')
      if arpp:
        # Handle replies to our server-liveness probes
        if arpp.opcode == arpp.REPLY:
          if arpp.protosrc in self.outstanding_probes:
            # A server is (still?) up; cool.
            del self.outstanding_probes[arpp.protosrc]
            if (self.live_servers.get(arpp.protosrc, (None,None))
                == (arpp.hwsrc,inport)):
              # Ah, nothing new here.
              pass
            else:
              # Ooh, new server.
              self.live_servers[arpp.protosrc] = arpp.hwsrc,inport
              self.log.info("Server %s up", arpp.protosrc)
        return

      # Not TCP and not ARP.  Don't know what to do with this.  Drop it.
      return drop()

    # It's TCP.
    
    ipp = packet.find('ipv4')

    if ipp.srcip in self.servers:
      # It's FROM one of our balanced servers.
      # Rewrite it BACK to the client

      key = ipp.srcip,ipp.dstip,tcpp.srcport,tcpp.dstport
      entry = self.memory.get(key)

      if entry is None:
        # We either didn't install it, or we forgot about it.
        self.log.debug("No client for %s", key)
        return drop()

      # Refresh time timeout and reinstall.
      entry.refresh()

      #self.log.debug("Install reverse flow for %s", key)

      # Install reverse table entry
      mac,port = self.live_servers[entry.server]

      actions = []
      actions.append(of.ofp_action_dl_addr.set_src(self.mac))
      actions.append(of.ofp_action_nw_addr.set_src(self.service_ip))
      actions.append(of.ofp_action_output(port = entry.client_port))
      match = of.ofp_match.from_packet(packet, inport)

      msg = of.ofp_flow_mod(command=of.OFPFC_ADD,
                            idle_timeout=FLOW_IDLE_TIMEOUT,
                            hard_timeout=of.OFP_FLOW_PERMANENT,
                            data=event.ofp,
                            actions=actions,
                            match=match)
      self.con.send(msg)

    elif ipp.dstip == self.service_ip:
      # Ah, it's for our service IP and needs to be load balanced

      # Do we already know this flow?
      key = ipp.srcip,ipp.dstip,tcpp.srcport,tcpp.dstport
      entry = self.memory.get(key)
      if entry is None or entry.server not in self.live_servers:
        # Don't know it (hopefully it's new!)
        if len(self.live_servers) == 0:
          self.log.warn("No servers!")
          return drop()

        # Pick a server for this flow
        server = self._pick_server(key, inport)
        self.log.debug("Directing traffic to %s", server)
        entry = MemoryEntry(server, packet, inport)
        self.memory[entry.key1] = entry
        self.memory[entry.key2] = entry
   
      # Update timestamp
      entry.refresh()

      # Set up table entry towards selected server
      mac,port = self.live_servers[entry.server]

      actions = []
      actions.append(of.ofp_action_dl_addr.set_dst(mac))
      actions.append(of.ofp_action_nw_addr.set_dst(entry.server))
      actions.append(of.ofp_action_output(port = port))
      match = of.ofp_match.from_packet(packet, inport)

      msg = of.ofp_flow_mod(command=of.OFPFC_ADD,
                            idle_timeout=FLOW_IDLE_TIMEOUT,
                            hard_timeout=of.OFP_FLOW_PERMANENT,
                            data=event.ofp,
                            actions=actions,
                            match=match)
      self.con.send(msg)


# Remember which DPID we're operating on (first one to connect)
_dpid = None

def launch (ip, servers):
  servers = servers.replace(","," ").split()
  servers = [IPAddr(x) for x in servers]
  ip = IPAddr(ip)

  # Boot up ARP Responder
  from proto.arp_responder import launch as arp_launch
  arp_launch(eat_packets=False,**{str(ip):True})
  import logging
  logging.getLogger("proto.arp_responder").setLevel(logging.WARN)

  def _handle_ConnectionUp (event):
    global _dpid
    if _dpid is None:
      log.info("IP Load Balancer Ready.")
      core.registerNew(iplb, event.connection, IPAddr(ip), servers)
      _dpid = event.dpid

    if _dpid != event.dpid:
      log.warn("Ignoring switch %s", event.connection)
    else:
      log.info("Load Balancing on %s", event.connection)

      # Gross hack
      core.iplb.con = event.connection
      event.connection.addListeners(core.iplb)


  core.openflow.addListenerByName("ConnectionUp", _handle_ConnectionUp)

########NEW FILE########
__FILENAME__ = mac_blocker
# Copyright 2012 James McCauley
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at:
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""
Gives a GUI for blocking individual MAC addresses.

Meant to work with reactive components like l2_learning or l2_pairs.

Start with --no-clear-tables if you don't want to clear tables on changes.
"""

from pox.core import core
from pox.lib.revent import EventHalt
from pox.lib.addresses import EthAddr
import pox.openflow.libopenflow_01 as of

from Tkinter import *

# Sets of blocked and unblocked MACs
blocked = set()
unblocked = set()

# Listbox widgets
unblocked_list = None
blocked_list = None

# If True, clear tables on every block/unblock
clear_tables_on_change = True

def add_mac (mac):
  if mac.is_multicast: return
  if mac.is_bridge_filtered: return
  if mac in blocked: return
  if mac in unblocked: return
  unblocked.add(mac)
  core.tk.do(unblocked_list.insert, None, END, str(mac))

def packet_handler (event):
  # Note the two MACs
  add_mac(event.parsed.src)
  add_mac(event.parsed.dst)

  # Check for blocked MACs
  if event.parsed.src in blocked:
    return EventHalt
  if event.parsed.dst in blocked:
    return EventHalt

def get (l):
  """ Get an element from a listbox """
  try:
    i = l.curselection()[0]
    mac = l.get(i)
    return i,mac
  except:
    pass
  return None,None

def clear_flows ():
  """ Clear flows on all switches """
  for c in core.openflow.connections:
    d = of.ofp_flow_mod(command = of.OFPFC_DELETE)
    c.send(d)

def move_entry (from_list, from_set, to_list, to_set):
  """ Move entry from one list to another """
  i,mac = get(from_list)
  if mac is None: return
  from_list.delete(i)
  to_list.insert(END, mac)
  mac = EthAddr(mac)
  to_set.add(mac)
  from_set.remove(mac)

  if clear_tables_on_change:
    # This is coming from another thread, so don't just send -- use
    # callLater so that it happens from the coop thread.
    core.callLater(clear_flows)

def do_block ():
  """ Handle clicks on block button """
  move_entry(unblocked_list, unblocked, blocked_list, blocked)

def do_unblock ():
  """ Handle clicks on unblock button """
  move_entry(blocked_list, blocked, unblocked_list, unblocked)

def setup ():
  """ Set up GUI """
  global unblocked_list, blocked_list
  top = Toplevel()
  top.title("MAC Blocker")

  # Shut down POX when window is closed
  top.protocol("WM_DELETE_WINDOW", core.quit)

  box1 = Frame(top)
  box2 = Frame(top)
  l1 = Label(box1, text="Allowed")
  l2 = Label(box2, text="Blocked")
  unblocked_list = Listbox(box1)
  blocked_list = Listbox(box2)
  l1.pack()
  l2.pack()
  unblocked_list.pack(expand=True,fill=BOTH)
  blocked_list.pack(expand=True,fill=BOTH)

  buttons = Frame(top)
  block_button = Button(buttons, text="Block >>", command=do_block)
  unblock_button = Button(buttons, text="<< Unblock", command=do_unblock)
  block_button.pack()
  unblock_button.pack()

  opts = {"side":LEFT,"fill":BOTH,"expand":True}
  box1.pack(**opts)
  buttons.pack(**{"side":LEFT})
  box2.pack(**opts)

  core.getLogger().debug("Ready")

def launch (no_clear_tables = False):
  global clear_tables_on_change
  clear_tables_on_change = not no_clear_tables

  def start ():
    core.openflow.addListenerByName("PacketIn",packet_handler,priority=1)
    core.tk.do(setup)

  core.call_when_ready(start, ['openflow','tk'])

########NEW FILE########
__FILENAME__ = nat
# Copyright 2013 James McCauley
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at:
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""
A kind of sloppy NAT component.

Required commandline parameters:
  --dpid            The DPID to NAT-ize
  --outside-port=X  The port on DPID that connects "upstream" (e.g, "eth0")

Optional parameters:
  --subnet=X        The local subnet to use (e.g., "192.168.0.1/24")
  --inside-ip=X     The inside-facing IP address the switch will claim to be

To get this to work with Open vSwitch, you probably have to disable OVS's
in-band control with something like:
  ovs-vsctl set bridge s1 other-config:disable-in-band=true

Please submit improvements. :)
"""

from pox.core import core
import pox
log = core.getLogger()

from pox.lib.packet.ipv4 import ipv4
from pox.lib.packet.arp import arp
import pox.lib.packet as pkt

from pox.lib.addresses import IPAddr
from pox.lib.addresses import EthAddr
from pox.lib.util import str_to_bool, dpid_to_str, str_to_dpid
from pox.lib.revent import EventMixin, Event
from pox.lib.recoco import Timer
import pox.lib.recoco as recoco

import pox.openflow.libopenflow_01 as of
from pox.proto.dhcpd import DHCPD, SimpleAddressPool

import time
import random

FLOW_TIMEOUT = 60
FLOW_MEMORY_TIMEOUT = 60 * 10


class Record (object):
  def __init__ (self):
    self.touch()
    self.outgoing_match = None
    self.incoming_match = None
    self.real_srcport = None
    self.fake_srcport = None
    self.outgoing_fm = None
    self.incoming_fm = None

  @property
  def expired (self):
    return time.time() > self._expires_at

  def touch (self):
    self._expires_at = time.time() + FLOW_MEMORY_TIMEOUT

  def __str__ (self):
    s = "%s:%s" % (self.outgoing_match.nw_src, self.real_srcport)
    if self.fake_srcport != self.real_srcport:
      s += "/%s" % (self.fake_srcport,)
    s += " -> %s:%s" % (self.outgoing_match.nw_dst, self.outgoing_match.tp_dst)
    return s


class NAT (object):
  def __init__ (self, inside_ip, outside_ip, gateway_ip, dns_ip, outside_port,
      dpid, subnet = None):

    self.inside_ip = inside_ip
    self.outside_ip = outside_ip
    self.gateway_ip = gateway_ip
    self.dns_ip = dns_ip # Or None
    self.outside_port = outside_port
    self.dpid = dpid
    self.subnet = subnet

    self._outside_portno = None
    self._gateway_eth = None
    self._connection = None

    # Which NAT ports have we used?
    # proto means TCP or UDP
    self._used_ports = set() # (proto,port)

    # Flow records indexed in both directions
    # match -> Record
    self._record_by_outgoing = {}
    self._record_by_incoming = {}

    core.listen_to_dependencies(self)

  def _all_dependencies_met (self):
    log.debug('Trying to start...')
    if self.dpid in core.openflow.connections:
      self._start(core.openflow.connections[self.dpid])
    else:
      core.openflow.addListenerByName('ConnectionUp',
          self.__handle_dpid_ConnectionUp)

    self.expire_timer = Timer(60, self._expire, recurring = True)

  def _expire (self):
    dead = []
    for r in self._record_by_outgoing.itervalues():
      if r.expired:
        dead.append(r)

    for r in dead:
      del self._record_by_outgoing[r.outgoing_match]
      del self._record_by_incoming[r.incoming_match]
      self._used_ports.remove((r.outgoing_match.nw_proto,r.fake_srcport))

    if dead and not self._record_by_outgoing:
      log.debug("All flows expired")

  def _is_local (self, ip):
    if ip.is_multicast: return True
    if self.subnet is not None:
      if ip.in_network(self.subnet): return True
      return False
    if ip.in_network('192.168.0.0/16'): return True
    if ip.in_network('10.0.0.0/8'): return True
    if ip.in_network('172.16.0.0/12'): return True
    return False

  def _pick_port (self, flow):
    """
    Gets a possibly-remapped outside port

    flow is the match of the connection
    returns port (maybe from flow, maybe not)
    """

    port = flow.tp_src

    if port < 1024:
      # Never allow these
      port = random.randint(49152, 65534)

    # Pretty sloppy!

    cycle = 0
    while cycle < 2:
      if (flow.nw_proto,port) not in self._used_ports:
        self._used_ports.add((flow.nw_proto,port))
        return port
      port += 1
      if port >= 65534:
        port = 49152
        cycle += 1

    log.warn("No ports to give!")
    return None

  @property
  def _outside_eth (self):
    if self._connection is None: return None
    #return self._connection.eth_addr
    return self._connection.ports[self._outside_portno].hw_addr

  def _handle_FlowRemoved (self, event):
    pass

  @staticmethod
  def strip_match (o):
    m = of.ofp_match()

    fields = 'dl_dst dl_src nw_dst nw_src tp_dst tp_src dl_type nw_proto'

    for f in fields.split():
      setattr(m, f, getattr(o, f))

    return m

  @staticmethod
  def make_match (o):
    return NAT.strip_match(of.ofp_match.from_packet(o))

  def _handle_PacketIn (self, event):
    if self._outside_eth is None: return

    #print
    #print "PACKET",event.connection.ports[event.port].name,event.port,
    #print self.outside_port, self.make_match(event.ofp)

    incoming = event.port == self._outside_portno

    if self._gateway_eth is None:
      # Need to find gateway MAC -- send an ARP
      self._arp_for_gateway()
      return

    packet = event.parsed
    dns_hack = False

    # We only handle TCP and UDP
    tcpp = packet.find('tcp')
    if not tcpp:
      tcpp = packet.find('udp')
      if not tcpp: return
      if tcpp.dstport == 53 and tcpp.prev.dstip == self.inside_ip:
        if self.dns_ip and not incoming:
          # Special hack for DNS since we've lied and claimed to be the server
          dns_hack = True
    ipp = tcpp.prev

    if not incoming:
      # Assume we only NAT public addresses
      if self._is_local(ipp.dstip) and not dns_hack: return
    else:
      # Assume we only care about ourselves
      if ipp.dstip != self.outside_ip: return

    match = self.make_match(event.ofp)

    if incoming:
      match2 = match.clone()
      match2.dl_dst = None # See note below
      record = self._record_by_incoming.get(match2)
      if record is None:
        # Ignore for a while
        fm = of.ofp_flow_mod()
        fm.idle_timeout = 1
        fm.hard_timeout = 10
        fm.match = of.ofp_match.from_packet(event.ofp)
        event.connection.send(fm)
        return
      log.debug("%s reinstalled", record)
      record.incoming_fm.data = event.ofp # Hacky!
    else:
      record = self._record_by_outgoing.get(match)
      if record is None:
        record = Record()

        record.real_srcport = tcpp.srcport
        record.fake_srcport = self._pick_port(match)

        # Outside heading in
        fm = of.ofp_flow_mod()
        fm.flags |= of.OFPFF_SEND_FLOW_REM
        fm.hard_timeout = FLOW_TIMEOUT

        fm.match = match.flip()
        fm.match.in_port = self._outside_portno
        fm.match.nw_dst = self.outside_ip
        fm.match.tp_dst = record.fake_srcport
        fm.match.dl_src = self._gateway_eth

        # We should set dl_dst, but it can get in the way.  Why?  Because
        # in some situations, the ARP may ARP for and get the local host's
        # MAC, but in others it may not.
        #fm.match.dl_dst = self._outside_eth
        fm.match.dl_dst = None

        fm.actions.append(of.ofp_action_dl_addr.set_src(packet.dst))
        fm.actions.append(of.ofp_action_dl_addr.set_dst(packet.src))
        fm.actions.append(of.ofp_action_nw_addr.set_dst(ipp.srcip))

        if dns_hack:
          fm.match.nw_src = self.dns_ip
          fm.actions.append(of.ofp_action_nw_addr.set_src(self.inside_ip))
        if record.fake_srcport != record.real_srcport:
          fm.actions.append(of.ofp_action_tp_port.set_dst(record.real_srcport))

        fm.actions.append(of.ofp_action_output(port = event.port))

        record.incoming_match = self.strip_match(fm.match)
        record.incoming_fm = fm

        # Inside heading out
        fm = of.ofp_flow_mod()
        fm.data = event.ofp
        fm.flags |= of.OFPFF_SEND_FLOW_REM
        fm.hard_timeout = FLOW_TIMEOUT
        fm.match = match.clone()
        fm.match.in_port = event.port
        fm.actions.append(of.ofp_action_dl_addr.set_src(self._outside_eth))
        fm.actions.append(of.ofp_action_nw_addr.set_src(self.outside_ip))
        if dns_hack:
          fm.actions.append(of.ofp_action_nw_addr.set_dst(self.dns_ip))
        if record.fake_srcport != record.real_srcport:
          fm.actions.append(of.ofp_action_tp_port.set_src(record.fake_srcport))
        fm.actions.append(of.ofp_action_dl_addr.set_dst(self._gateway_eth))
        fm.actions.append(of.ofp_action_output(port = self._outside_portno))

        record.outgoing_match = self.strip_match(fm.match)
        record.outgoing_fm = fm

        self._record_by_incoming[record.incoming_match] = record
        self._record_by_outgoing[record.outgoing_match] = record

        log.debug("%s installed", record)
      else:
        log.debug("%s reinstalled", record)
        record.outgoing_fm.data = event.ofp # Hacky!

    record.touch()

    # Send/resend the flow mods
    if incoming:
      data = record.outgoing_fm.pack() + record.incoming_fm.pack()
    else:
      data = record.incoming_fm.pack() + record.outgoing_fm.pack()
    self._connection.send(data)

    # We may have set one of the data fields, but they should be reset since
    # they won't be valid in the future.  Kind of hacky.
    record.outgoing_fm.data = None
    record.incoming_fm.data = None

  def __handle_dpid_ConnectionUp (self, event):
    if event.dpid != self.dpid:
      return
    self._start(event.connection)

  def _start (self, connection):
    self._connection = connection

    self._outside_portno = connection.ports[self.outside_port].port_no

    fm = of.ofp_flow_mod()
    fm.match.in_port = self._outside_portno
    fm.priority = 1
    connection.send(fm)

    fm = of.ofp_flow_mod()
    fm.match.in_port = self._outside_portno
    fm.match.dl_type = 0x800 # IP
    fm.match.nw_dst = self.outside_ip
    fm.actions.append(of.ofp_action_output(port=of.OFPP_CONTROLLER))
    fm.priority = 2
    connection.send(fm)

    connection.addListeners(self)

    # Need to find gateway MAC -- send an ARP
    self._arp_for_gateway()

  def _arp_for_gateway (self):
    log.debug('Attempting to ARP for gateway (%s)', self.gateway_ip)
    self._ARPHelper_.send_arp_request(self._connection,
                                      ip = self.gateway_ip,
                                      port = self._outside_portno,
                                      src_ip = self.outside_ip)

  def _handle_ARPHelper_ARPReply (self, event):
    if event.dpid != self.dpid: return
    if event.port != self._outside_portno: return
    if event.reply.protosrc == self.gateway_ip:
      self._gateway_eth = event.reply.hwsrc
      log.info("Gateway %s is %s", self.gateway_ip, self._gateway_eth)

  def _handle_ARPHelper_ARPRequest (self, event):
    if event.dpid != self.dpid: return

    dstip = event.request.protodst
    if event.port == self._outside_portno:
      if dstip == self.outside_ip:
        if self._connection is None:
          log.warn("Someone tried to ARP us, but no connection yet")
        else:
          event.reply = self._outside_eth
    else:
      if dstip == self.inside_ip or not self._is_local(dstip):
        if self._connection is None:
          log.warn("Someone tried to ARP us, but no connection yet")
        else:
          #event.reply = self._connection.eth_addr
          event.reply = self._connection.ports[event.port].hw_addr


class NATDHCPD (DHCPD):
  """
  Subclass of the DHCP daemon for NAT

  Basically it's the normal DHCP server, but it works on one specific DPID and
  can ignore a particular port.
  """
  def __init__ (self, dpid, outside_port, *args, **kw):
    self._outside_port_name = outside_port
    self._outside_port_no = None
    self._dpid = dpid
    super(NATDHCPD,self).__init__(*args,**kw)

  def _handle_ConnectionUp (self, event):
    if self._dpid != event.dpid: return
    ports = event.connection.ports
    if self._outside_port_name not in ports:
      log.warn("No port %s on DPID %s", self._outside_port_name,
          dpid_to_str(self._dpid))
      return
    self._outside_port_no = ports[self._outside_port_name].port_no

    return super(NATDHCPD,self)._handle_ConnectionUp(event)

  def _handle_PacketIn (self, event):
    if self._dpid != event.dpid: return
    if event.port == self._outside_port_no: return
    return super(NATDHCPD,self)._handle_PacketIn(event)


def launch (dpid, outside_port, subnet = '172.16.1.0/24',
            inside_ip = '172.16.1.1'):

  import pox.proto.dhcp_client as dc
  dc.launch(dpid = dpid, port = outside_port, port_eth = True)

  import pox.proto.arp_helper as ah
  ah.launch(use_port_mac = True)

  dpid = str_to_dpid(dpid)
  inside_ip = IPAddr(inside_ip)

  pool = SimpleAddressPool(network = subnet, first = 100, last = 199)

  core.registerNew(NATDHCPD, install_flow = True, pool = pool,
                   ip_address = inside_ip, router_address = inside_ip,
                   dns_address = inside_ip, dpid = dpid,
                   outside_port = outside_port)


  def got_lease (event):
    outside_ip = event.lease.address

    if not event.lease.routers:
      log.error("Can't start NAT because we didn't get an upstream gateway")
      return
    gateway_ip = event.lease.routers[0]

    if event.lease.dns_servers:
      dns_ip = event.lease.dns_servers[0]
    else:
      dns_ip = None

    log.debug('Starting NAT')

    n = NAT(inside_ip, outside_ip, gateway_ip, dns_ip, outside_port, dpid,
            subnet=subnet)
    core.register(n)


  def init ():
    log.debug('Waiting for DHCP lease on port %s', outside_port)
    core.DHCPClient.addListenerByName('DHCPLeased', got_lease)

  core.call_when_ready(init, ['DHCPClient'])

########NEW FILE########
__FILENAME__ = of_tutorial
# Copyright 2012 James McCauley
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at:
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""
This component is for use with the OpenFlow tutorial.

It acts as a simple hub, but can be modified to act like an L2
learning switch.

It's roughly similar to the one Brandon Heller did for NOX.
"""

from pox.core import core
import pox.openflow.libopenflow_01 as of

log = core.getLogger()



class Tutorial (object):
  """
  A Tutorial object is created for each switch that connects.
  A Connection object for that switch is passed to the __init__ function.
  """
  def __init__ (self, connection):
    # Keep track of the connection to the switch so that we can
    # send it messages!
    self.connection = connection

    # This binds our PacketIn event listener
    connection.addListeners(self)

    # Use this table to keep track of which ethernet address is on
    # which switch port (keys are MACs, values are ports).
    self.mac_to_port = {}


  def resend_packet (self, packet_in, out_port):
    """
    Instructs the switch to resend a packet that it had sent to us.
    "packet_in" is the ofp_packet_in object the switch had sent to the
    controller due to a table-miss.
    """
    msg = of.ofp_packet_out()
    msg.data = packet_in

    # Add an action to send to the specified port
    action = of.ofp_action_output(port = out_port)
    msg.actions.append(action)

    # Send message to switch
    self.connection.send(msg)


  def act_like_hub (self, packet, packet_in):
    """
    Implement hub-like behavior -- send all packets to all ports besides
    the input port.
    """

    # We want to output to all ports -- we do that using the special
    # OFPP_ALL port as the output port.  (We could have also used
    # OFPP_FLOOD.)
    self.resend_packet(packet_in, of.OFPP_ALL)

    # Note that if we didn't get a valid buffer_id, a slightly better
    # implementation would check that we got the full data before
    # sending it (len(packet_in.data) should be == packet_in.total_len)).


  def act_like_switch (self, packet, packet_in):
    """
    Implement switch-like behavior.
    """

    """ # DELETE THIS LINE TO START WORKING ON THIS (AND THE ONE BELOW!) #

    # Here's some psuedocode to start you off implementing a learning
    # switch.  You'll need to rewrite it as real Python code.

    # Learn the port for the source MAC
    self.mac_to_port ... <add or update entry>

    if the port associated with the destination MAC of the packet is known:
      # Send packet out the associated port
      self.resend_packet(packet_in, ...)

      # Once you have the above working, try pushing a flow entry
      # instead of resending the packet (comment out the above and
      # uncomment and complete the below.)

      log.debug("Installing flow...")
      # Maybe the log statement should have source/destination/port?

      #msg = of.ofp_flow_mod()
      #
      ## Set fields to match received packet
      #msg.match = of.ofp_match.from_packet(packet)
      #
      #< Set other fields of flow_mod (timeouts? buffer_id?) >
      #
      #< Add an output action, and send -- similar to resend_packet() >

    else:
      # Flood the packet out everything but the input port
      # This part looks familiar, right?
      self.resend_packet(packet_in, of.OFPP_ALL)

    """ # DELETE THIS LINE TO START WORKING ON THIS #


  def _handle_PacketIn (self, event):
    """
    Handles packet in messages from the switch.
    """

    packet = event.parsed # This is the parsed packet data.
    if not packet.parsed:
      log.warning("Ignoring incomplete packet")
      return

    packet_in = event.ofp # The actual ofp_packet_in message.

    # Comment out the following line and uncomment the one after
    # when starting the exercise.
    self.act_like_hub(packet, packet_in)
    #self.act_like_switch(packet, packet_in)



def launch ():
  """
  Starts the component
  """
  def start_switch (event):
    log.debug("Controlling %s" % (event.connection,))
    Tutorial(event.connection)
  core.openflow.addListenerByName("ConnectionUp", start_switch)

########NEW FILE########
__FILENAME__ = pidfile
# Copyright 2013 James McCauley
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at:
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""
Component to create PID files for running POX as a service
"""

from pox.core import core

import os
import atexit

_files = set()
_first_init = False


def _del_pidfiles ():
  if not _files: return
  try:
    msg = "Cleaning up %i pidfile" % (len(_files),)
    if len(_files) != 1: msg += 's'
    log.debug(msg)
  except:
    pass

  for f in list(_files):
    shortname = f
    if os.path.abspath(os.path.basename(f)) == f:
      shortname = os.path.basename(f)
    try:
      os.remove(f)
    except:
      msg = "Couldn't delete pidfile '%s'" % (shortname,)
      try:
        log.exception(msg)
      except:
        print(msg)
    _files.remove(f)


def _handle_DownEvent (event):
  _del_pidfiles()


def launch (file, force = False, __INSTANCE__ = None):
  global log
  log = core.getLogger()

  absfile = os.path.abspath(file)

  if absfile in _files:
    log.warn("pidfile '%s' specified multiple times", file)
    return

  global _first_init

  if not _first_init:
    try:
      atexit.register(_del_pidfiles)
    except:
      log.info('atexit not available')
    core.addListenerByName("DownEvent", _handle_DownEvent)
    _first_init = True

  if os.path.exists(absfile) and not force:
    log.error("Aborting startup: pidfile '%s' exists "
              "(use --force to override)", file)
    return False

  try:
    f = open(absfile, 'w')
    f.write("%s\n" % (os.getpid(),))
  except:
    log.exception("Failed to create pidfile '%s'", file)
    return False
  f.close()

  _files.add(absfile)

########NEW FILE########
__FILENAME__ = debug
# Copyright 2012 James McCauley
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at:
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

pcap_traces = False

def launch ():
  global pcap_traces
  pcap_traces = True

########NEW FILE########
__FILENAME__ = discovery
# Copyright 2011-2013 James McCauley
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at:
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# This file is loosely based on the discovery component in NOX.

"""
This module discovers the connectivity between OpenFlow switches by sending
out LLDP packets. To be notified of this information, listen to LinkEvents
on core.openflow_discovery.

It's possible that some of this should be abstracted out into a generic
Discovery module, or a Discovery superclass.
"""

from pox.lib.revent import *
from pox.lib.recoco import Timer
from pox.lib.util import dpid_to_str, str_to_bool
from pox.core import core
import pox.openflow.libopenflow_01 as of
import pox.lib.packet as pkt

import struct
import time
from collections import namedtuple
from random import shuffle, random


log = core.getLogger()


class LLDPSender (object):
  """
  Sends out discovery packets
  """

  SendItem = namedtuple("LLDPSenderItem", ('dpid','port_num','packet'))

  #NOTE: This class keeps the packets to send in a flat list, which makes
  #      adding/removing them on switch join/leave or (especially) port
  #      status changes relatively expensive. Could easily be improved.

  # Maximum times to run the timer per second
  _sends_per_sec = 15

  def __init__ (self, send_cycle_time, ttl = 120):
    """
    Initialize an LLDP packet sender

    send_cycle_time is the time (in seconds) that this sender will take to
      send every discovery packet.  Thus, it should be the link timeout
      interval at most.

    ttl is the time (in seconds) for which a receiving LLDP agent should
      consider the rest of the data to be valid.  We don't use this, but
      other LLDP agents might.  Can't be 0 (this means revoke).
    """
    # Packets remaining to be sent in this cycle
    self._this_cycle = []

    # Packets we've already sent in this cycle
    self._next_cycle = []

    # Packets to send in a batch
    self._send_chunk_size = 1

    self._timer = None
    self._ttl = ttl
    self._send_cycle_time = send_cycle_time
    core.listen_to_dependencies(self)

  def _handle_openflow_PortStatus (self, event):
    """
    Track changes to switch ports
    """
    if event.added:
      self.add_port(event.dpid, event.port, event.ofp.desc.hw_addr)
    elif event.deleted:
      self.del_port(event.dpid, event.port)

  def _handle_openflow_ConnectionUp (self, event):
    self.del_switch(event.dpid, set_timer = False)

    ports = [(p.port_no, p.hw_addr) for p in event.ofp.ports]

    for port_num, port_addr in ports:
      self.add_port(event.dpid, port_num, port_addr, set_timer = False)

    self._set_timer()

  def _handle_openflow_ConnectionDown (self, event):
    self.del_switch(event.dpid)

  def del_switch (self, dpid, set_timer = True):
    self._this_cycle = [p for p in self._this_cycle if p.dpid != dpid]
    self._next_cycle = [p for p in self._next_cycle if p.dpid != dpid]
    if set_timer: self._set_timer()

  def del_port (self, dpid, port_num, set_timer = True):
    if port_num > of.OFPP_MAX: return
    self._this_cycle = [p for p in self._this_cycle
                        if p.dpid != dpid or p.port_num != port_num]
    self._next_cycle = [p for p in self._next_cycle
                        if p.dpid != dpid or p.port_num != port_num]
    if set_timer: self._set_timer()

  def add_port (self, dpid, port_num, port_addr, set_timer = True):
    if port_num > of.OFPP_MAX: return
    self.del_port(dpid, port_num, set_timer = False)
    self._next_cycle.append(LLDPSender.SendItem(dpid, port_num,
          self.create_discovery_packet(dpid, port_num, port_addr)))
    if set_timer: self._set_timer()

  def _set_timer (self):
    if self._timer: self._timer.cancel()
    self._timer = None
    num_packets = len(self._this_cycle) + len(self._next_cycle)

    if num_packets == 0: return

    self._send_chunk_size = 1 # One at a time
    interval = self._send_cycle_time / float(num_packets)
    if interval < 1.0 / self._sends_per_sec:
      # Would require too many sends per sec -- send more than one at once
      interval = 1.0 / self._sends_per_sec
      chunk = float(num_packets) / self._send_cycle_time / self._sends_per_sec
      self._send_chunk_size = chunk

    self._timer = Timer(interval,
                        self._timer_handler, recurring=True)

  def _timer_handler (self):
    """
    Called by a timer to actually send packets.

    Picks the first packet off this cycle's list, sends it, and then puts
    it on the next-cycle list.  When this cycle's list is empty, starts
    the next cycle.
    """
    num = int(self._send_chunk_size)
    fpart = self._send_chunk_size - num
    if random() < fpart: num += 1

    for _ in range(num):
      if len(self._this_cycle) == 0:
        self._this_cycle = self._next_cycle
        self._next_cycle = []
        #shuffle(self._this_cycle)
      item = self._this_cycle.pop(0)
      self._next_cycle.append(item)
      core.openflow.sendToDPID(item.dpid, item.packet)

  def create_discovery_packet (self, dpid, port_num, port_addr):
    """
    Build discovery packet
    """

    chassis_id = pkt.chassis_id(subtype=pkt.chassis_id.SUB_LOCAL)
    chassis_id.id = bytes('dpid:' + hex(long(dpid))[2:-1])
    # Maybe this should be a MAC.  But a MAC of what?  Local port, maybe?

    port_id = pkt.port_id(subtype=pkt.port_id.SUB_PORT, id=str(port_num))

    ttl = pkt.ttl(ttl = self._ttl)

    sysdesc = pkt.system_description()
    sysdesc.payload = bytes('dpid:' + hex(long(dpid))[2:-1])

    discovery_packet = pkt.lldp()
    discovery_packet.tlvs.append(chassis_id)
    discovery_packet.tlvs.append(port_id)
    discovery_packet.tlvs.append(ttl)
    discovery_packet.tlvs.append(sysdesc)
    discovery_packet.tlvs.append(pkt.end_tlv())

    eth = pkt.ethernet(type=pkt.ethernet.LLDP_TYPE)
    eth.src = port_addr
    eth.dst = pkt.ETHERNET.NDP_MULTICAST
    eth.payload = discovery_packet

    po = of.ofp_packet_out(action = of.ofp_action_output(port=port_num))
    po.data = eth.pack()
    return po.pack()


class LinkEvent (Event):
  """
  Link up/down event
  """
  def __init__ (self, add, link):
    Event.__init__(self)
    self.link = link
    self.added = add
    self.removed = not add

  def port_for_dpid (self, dpid):
    if self.link.dpid1 == dpid:
      return self.link.port1
    if self.link.dpid2 == dpid:
      return self.link.port2
    return None


class Link (namedtuple("LinkBase",("dpid1","port1","dpid2","port2"))):
  @property
  def uni (self):
    """
    Returns a "unidirectional" version of this link

    The unidirectional versions of symmetric keys will be equal
    """
    pairs = list(self.end)
    pairs.sort()
    return Link(pairs[0][0],pairs[0][1],pairs[1][0],pairs[1][1])

  @property
  def end (self):
    return ((self[0],self[1]),(self[2],self[3]))

  def __str__ (self):
    return "%s.%s -> %s.%s" % (dpid_to_str(self[0]),self[1],
                               dpid_to_str(self[2]),self[3])

  def __repr__ (self):
    return "Link(dpid1=%s,port1=%s, dpid2=%s,port2=%s)" % (self.dpid1,
        self.port1, self.dpid2, self.port2)


class Discovery (EventMixin):
  """
  Component that attempts to discover network toplogy.

  Sends out specially-crafted LLDP packets, and monitors their arrival.
  """

  _flow_priority = 65000     # Priority of LLDP-catching flow (if any)
  _link_timeout = 10         # How long until we consider a link dead
  _timeout_check_period = 5  # How often to check for timeouts

  _eventMixin_events = set([
    LinkEvent,
  ])

  _core_name = "openflow_discovery" # we want to be core.openflow_discovery

  Link = Link

  def __init__ (self, install_flow = True, explicit_drop = True,
                link_timeout = None, eat_early_packets = False):
    self._eat_early_packets = eat_early_packets
    self._explicit_drop = explicit_drop
    self._install_flow = install_flow
    if link_timeout: self._link_timeout = link_timeout

    self.adjacency = {} # From Link to time.time() stamp
    self._sender = LLDPSender(self.send_cycle_time)

    # Listen with a high priority (mostly so we get PacketIns early)
    core.listen_to_dependencies(self,
        listen_args={'openflow':{'priority':0xffffffff}})

    Timer(self._timeout_check_period, self._expire_links, recurring=True)

  @property
  def send_cycle_time (self):
    return self._link_timeout / 2.0

  def install_flow (self, con_or_dpid, priority = None):
    if priority is None:
      priority = self._flow_priority
    if isinstance(con_or_dpid, (int,long)):
      con = core.openflow.connections.get(con_or_dpid)
      if con is None:
        log.warn("Can't install flow for %s", dpid_to_str(con_or_dpid))
        return False
    else:
      con = con_or_dpid

    match = of.ofp_match(dl_type = pkt.ethernet.LLDP_TYPE,
                          dl_dst = pkt.ETHERNET.NDP_MULTICAST)
    msg = of.ofp_flow_mod()
    msg.priority = priority
    msg.match = match
    msg.actions.append(of.ofp_action_output(port = of.OFPP_CONTROLLER))
    con.send(msg)
    return True

  def _handle_openflow_ConnectionUp (self, event):
    if self._install_flow:
      # Make sure we get appropriate traffic
      log.debug("Installing flow for %s", dpid_to_str(event.dpid))
      self.install_flow(event.connection)

  def _handle_openflow_ConnectionDown (self, event):
    # Delete all links on this switch
    self._delete_links([link for link in self.adjacency
                        if link.dpid1 == event.dpid
                        or link.dpid2 == event.dpid])

  def _expire_links (self):
    """
    Remove apparently dead links
    """
    now = time.time()

    expired = [link for link,timestamp in self.adjacency.iteritems()
               if timestamp + self._link_timeout < now]
    if expired:
      for link in expired:
        log.info('link timeout: %s', link)

      self._delete_links(expired)

  def _handle_openflow_PacketIn (self, event):
    """
    Receive and process LLDP packets
    """

    packet = event.parsed

    if (packet.effective_ethertype != pkt.ethernet.LLDP_TYPE
        or packet.dst != pkt.ETHERNET.NDP_MULTICAST):
      if not self._eat_early_packets: return
      if not event.connection.connect_time: return
      enable_time = time.time() - self.send_cycle_time - 1
      if event.connection.connect_time > enable_time:
        return EventHalt
      return

    if self._explicit_drop:
      if event.ofp.buffer_id is not None:
        log.debug("Dropping LLDP packet %i", event.ofp.buffer_id)
        msg = of.ofp_packet_out()
        msg.buffer_id = event.ofp.buffer_id
        msg.in_port = event.port
        event.connection.send(msg)

    lldph = packet.find(pkt.lldp)
    if lldph is None or not lldph.parsed:
      log.error("LLDP packet could not be parsed")
      return EventHalt
    if len(lldph.tlvs) < 3:
      log.error("LLDP packet without required three TLVs")
      return EventHalt
    if lldph.tlvs[0].tlv_type != pkt.lldp.CHASSIS_ID_TLV:
      log.error("LLDP packet TLV 1 not CHASSIS_ID")
      return EventHalt
    if lldph.tlvs[1].tlv_type != pkt.lldp.PORT_ID_TLV:
      log.error("LLDP packet TLV 2 not PORT_ID")
      return EventHalt
    if lldph.tlvs[2].tlv_type != pkt.lldp.TTL_TLV:
      log.error("LLDP packet TLV 3 not TTL")
      return EventHalt

    def lookInSysDesc ():
      r = None
      for t in lldph.tlvs[3:]:
        if t.tlv_type == pkt.lldp.SYSTEM_DESC_TLV:
          # This is our favored way...
          for line in t.payload.split('\n'):
            if line.startswith('dpid:'):
              try:
                return int(line[5:], 16)
              except:
                pass
          if len(t.payload) == 8:
            # Maybe it's a FlowVisor LLDP...
            # Do these still exist?
            try:
              return struct.unpack("!Q", t.payload)[0]
            except:
              pass
          return None

    originatorDPID = lookInSysDesc()

    if originatorDPID == None:
      # We'll look in the CHASSIS ID
      if lldph.tlvs[0].subtype == pkt.chassis_id.SUB_LOCAL:
        if lldph.tlvs[0].id.startswith('dpid:'):
          # This is how NOX does it at the time of writing
          try:
            originatorDPID = int(lldph.tlvs[0].id[5:], 16)
          except:
            pass
      if originatorDPID == None:
        if lldph.tlvs[0].subtype == pkt.chassis_id.SUB_MAC:
          # Last ditch effort -- we'll hope the DPID was small enough
          # to fit into an ethernet address
          if len(lldph.tlvs[0].id) == 6:
            try:
              s = lldph.tlvs[0].id
              originatorDPID = struct.unpack("!Q",'\x00\x00' + s)[0]
            except:
              pass

    if originatorDPID == None:
      log.warning("Couldn't find a DPID in the LLDP packet")
      return EventHalt

    if originatorDPID not in core.openflow.connections:
      log.info('Received LLDP packet from unknown switch')
      return EventHalt

    # Get port number from port TLV
    if lldph.tlvs[1].subtype != pkt.port_id.SUB_PORT:
      log.warning("Thought we found a DPID, but packet didn't have a port")
      return EventHalt
    originatorPort = None
    if lldph.tlvs[1].id.isdigit():
      # We expect it to be a decimal value
      originatorPort = int(lldph.tlvs[1].id)
    elif len(lldph.tlvs[1].id) == 2:
      # Maybe it's a 16 bit port number...
      try:
        originatorPort  =  struct.unpack("!H", lldph.tlvs[1].id)[0]
      except:
        pass
    if originatorPort is None:
      log.warning("Thought we found a DPID, but port number didn't " +
                  "make sense")
      return EventHalt

    if (event.dpid, event.port) == (originatorDPID, originatorPort):
      log.warning("Port received its own LLDP packet; ignoring")
      return EventHalt

    link = Discovery.Link(originatorDPID, originatorPort, event.dpid,
                          event.port)

    if link not in self.adjacency:
      self.adjacency[link] = time.time()
      log.info('link detected: %s', link)
      self.raiseEventNoErrors(LinkEvent, True, link)
    else:
      # Just update timestamp
      self.adjacency[link] = time.time()

    return EventHalt # Probably nobody else needs this event

  def _delete_links (self, links):
    for link in links:
      self.raiseEventNoErrors(LinkEvent, False, link)
    for link in links:
      self.adjacency.pop(link, None)

  def is_edge_port (self, dpid, port):
    """
    Return True if given port does not connect to another switch
    """
    for link in self.adjacency:
      if link.dpid1 == dpid and link.port1 == port:
        return False
      if link.dpid2 == dpid and link.port2 == port:
        return False
    return True


def launch (no_flow = False, explicit_drop = True, link_timeout = None,
            eat_early_packets = False):
  explicit_drop = str_to_bool(explicit_drop)
  eat_early_packets = str_to_bool(eat_early_packets)
  install_flow = not str_to_bool(no_flow)
  if link_timeout: link_timeout = int(link_timeout)

  core.registerNew(Discovery, explicit_drop=explicit_drop,
                   install_flow=install_flow, link_timeout=link_timeout,
                   eat_early_packets=eat_early_packets)

########NEW FILE########
__FILENAME__ = flow_table
# Copyright 2011,2012,2013 Colin Scott
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at:
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""
Implementation of an OpenFlow flow table
"""

from libopenflow_01 import *
from pox.lib.revent import *

import time
import math

# FlowTable Entries:
#   match - ofp_match (13-tuple)
#   counters - hash from name -> count. May be stale
#   actions - ordered list of ofp_action_*s to apply for matching packets
class TableEntry (object):
  """
  Models a flow table entry, with a match, actions, and options/flags/counters.

  Note: The current time can either be specified explicitely with the optional
        'now' parameter or is taken from time.time()
  """
  def __init__ (self, priority=OFP_DEFAULT_PRIORITY, cookie=0, idle_timeout=0,
                hard_timeout=0, flags=0, match=ofp_match(), actions=[],
                buffer_id=None, now=None):
    """
    Initialize table entry
    """
    if now is None: now = time.time()
    self.created = now
    self.last_touched = self.created
    self.byte_count = 0
    self.packet_count = 0
    self.priority = priority
    self.cookie = cookie
    self.idle_timeout = idle_timeout
    self.hard_timeout = hard_timeout
    self.flags = flags
    self.match = match
    self.actions = actions
    self.buffer_id = buffer_id

  @staticmethod
  def from_flow_mod (flow_mod):
    return TableEntry(priority=flow_mod.priority,
                      cookie=flow_mod.cookie,
                      idle_timeout=flow_mod.idle_timeout,
                      hard_timeout=flow_mod.hard_timeout,
                      flags=flow_mod.flags,
                      match=flow_mod.match,
                      actions=flow_mod.actions,
                      buffer_id=flow_mod.buffer_id)

  def to_flow_mod (self, flags=None, **kw):
    if flags is None: flags = self.flags
    return ofp_flow_mod(priority=self.priority,
                        cookie=self.cookie,
                        match=self.match,
                        idle_timeout=self.idle_timeout,
                        hard_timeout=self.hard_timeout,
                        actions=self.actions,
                        buffer_id=self.buffer_id,
                        flags=flags, **kw)

  @property
  def effective_priority (self):
    """
    Exact matches effectively have an "infinite" priority
    """
    return self.priority if self.match.is_wildcarded else (1<<16) + 1

  def is_matched_by (self, match, priority=None, strict=False, out_port=None):
    """
    Tests whether a given match object matches this entry

    Used for, e.g., flow_mod updates

    If out_port is any value besides None, the the flow entry must contain an
    output action to the specified port.
    """
    match_a = lambda a: isinstance(a, ofp_action_output) and a.port == out_port
    port_matches = (out_port is None) or any(match_a(a) for a in self.actions)

    if strict:
      return port_matches and self.match == match and self.priority == priority
    else:
      return port_matches and match.matches_with_wildcards(self.match)

  def touch_packet (self, byte_count, now=None):
    """
    Updates information of this entry based on encountering a packet.

    Updates both the cumulative given byte counts of packets encountered and
    the expiration timer.
    """
    if now is None: now = time.time()
    self.byte_count += byte_count
    self.packet_count += 1
    self.last_touched = now

  def is_idle_timed_out (self, now=None):
    if now is None: now = time.time()
    if self.idle_timeout > 0:
      if (now - self.last_touched) > self.idle_timeout:
        return True
    return False

  def is_hard_timed_out (self, now=None):
    if now is None: now = time.time()
    if self.hard_timeout > 0:
      if (now - self.created) > self.hard_timeout:
        return True
    return False

  def is_expired (self, now=None):
    """
    Tests whether this flow entry is expired due to its idle or hard timeout
    """
    if now is None: now = time.time()
    return self.is_idle_timed_out(now) or self.is_hard_timed_out(now)

  def __str__ (self):
    return type(self).__name__ + "\n  " + self.show()

  def __repr__ (self):
    return "TableEntry(" + self.show() + ")"

  def show (self):
    outstr = ''
    outstr += "priority=%s, " % self.priority
    outstr += "cookie=%x, " % self.cookie
    outstr += "idle_timeout=%d, " % self.idle_timeout
    outstr += "hard_timeout=%d, " % self.hard_timeout
    outstr += "match=%s, " % self.match
    outstr += "actions=%s, " % repr(self.actions)
    outstr += "buffer_id=%s" % str(self.buffer_id)
    return outstr

  def flow_stats (self, now=None):
    if now is None: now = time.time()
    dur_nsec,dur_sec = math.modf(now - self.created)
    return ofp_flow_stats(match=self.match,
                          duration_sec=int(dur_sec),
                          duration_nsec=int(dur_nsec * 1e9),
                          priority=self.priority,
                          idle_timeout=self.idle_timeout,
                          hard_timeout=self.hard_timeout,
                          cookie=self.cookie,
                          packet_count=self.packet_count,
                          byte_count=self.byte_count,
                          actions=self.actions)

  def to_flow_removed (self, now=None, reason=None):
    #TODO: Rename flow_stats to to_flow_stats and refactor?
    if now is None: now = time.time()
    dur_nsec,dur_sec = math.modf(now - self.created)
    fr = ofp_flow_removed()
    fr.match = self.match
    fr.cookie = self.cookie
    fr.priority = self.priority
    fr.reason = reason
    fr.duration_sec = int(dur_sec)
    fr.duration_nsec = int(dur_nsec * 1e9)
    fr.idle_timeout = self.idle_timeout
    fr.hard_timeout = self.hard_timeout
    fr.packet_count = self.packet_count
    fr.byte_count = self.byte_count
    return fr


class FlowTableModification (Event):
  def __init__ (self, added=[], removed=[], reason=None):
    Event.__init__(self)
    self.added = added
    self.removed = removed

    # Reason for modification.
    # Presently, this is only used for removals and is either one of OFPRR_x,
    # or None if it does not correlate to any of the items in the spec.
    self.reason = reason


class FlowTable (EventMixin):
  """
  General model of a flow table.

  Maintains an ordered list of flow entries, and finds matching entries for
  packets and other entries. Supports expiration of flows.
  """
  _eventMixin_events = set([FlowTableModification])

  def __init__ (self):
    EventMixin.__init__(self)

    # Table is a list of TableEntry sorted by descending effective_priority.
    self._table = []

  def _dirty (self):
    """
    Call when table changes
    """
    pass

  @property
  def entries (self):
    return self._table

  def __len__ (self):
    return len(self._table)

  def add_entry (self, entry):
    assert isinstance(entry, TableEntry)

    #self._table.append(entry)
    #self._table.sort(key=lambda e: e.effective_priority, reverse=True)

    # Use binary search to insert at correct place
    # This is faster even for modest table sizes, and way, way faster
    # as the tables grow larger.
    priority = entry.effective_priority
    table = self._table
    low = 0
    high = len(table)
    while low < high:
        middle = (low + high) // 2
        if priority >= table[middle].effective_priority:
          high = middle
          continue
        low = middle + 1
    table.insert(low, entry)

    self._dirty()

    self.raiseEvent(FlowTableModification(added=[entry]))

  def remove_entry (self, entry, reason=None):
    assert isinstance(entry, TableEntry)
    self._table.remove(entry)
    self._dirty()
    self.raiseEvent(FlowTableModification(removed=[entry], reason=reason))

  def matching_entries (self, match, priority=0, strict=False, out_port=None):
    entry_match = lambda e: e.is_matched_by(match, priority, strict, out_port)
    return [ entry for entry in self._table if entry_match(entry) ]

  def flow_stats (self, match, out_port=None, now=None):
    mc_es = self.matching_entries(match=match, strict=False, out_port=out_port)
    return [ e.flow_stats(now) for e in mc_es ]

  def aggregate_stats (self, match, out_port=None):
    mc_es = self.matching_entries(match=match, strict=False, out_port=out_port)
    packet_count = 0
    byte_count = 0
    flow_count = 0
    for entry in mc_es:
      packet_count += entry.packet_count
      byte_count += entry.byte_count
      flow_count += 1
    return ofp_aggregate_stats(packet_count=packet_count,
                               byte_count=byte_count,
                               flow_count=flow_count)

  def _remove_specific_entries (self, flows, reason=None):
    #for entry in flows:
    #  self._table.remove(entry)
    #self._table = [entry for entry in self._table if entry not in flows]
    if not flows: return
    self._dirty()
    remove_flows = set(flows)
    i = 0
    while i < len(self._table):
      entry = self._table[i]
      if entry in remove_flows:
        del self._table[i]
        remove_flows.remove(entry)
        if not remove_flows: break
      else:
        i += 1
    assert len(remove_flows) == 0
    self.raiseEvent(FlowTableModification(removed=flows, reason=reason))

  def remove_expired_entries (self, now=None):
    idle = []
    hard = []
    if now is None: now = time.time()
    for entry in self._table:
      if entry.is_idle_timed_out(now):
        idle.append(entry)
      elif entry.is_hard_timed_out(now):
        hard.append(entry)
    self._remove_specific_entries(idle, OFPRR_IDLE_TIMEOUT)
    self._remove_specific_entries(hard, OFPRR_HARD_TIMEOUT)

  def remove_matching_entries (self, match, priority=0, strict=False,
                               out_port=None, reason=None):
    remove_flows = self.matching_entries(match, priority, strict, out_port)
    self._remove_specific_entries(remove_flows, reason=reason)
    return remove_flows

  def entry_for_packet (self, packet, in_port):
    """
    Finds the flow table entry that matches the given packet.

    Returns the highest priority flow table entry that matches the given packet
    on the given in_port, or None if no matching entry is found.
    """
    packet_match = ofp_match.from_packet(packet, in_port, spec_frags = True)

    for entry in self._table:
      if entry.match.matches_with_wildcards(packet_match,
                                            consider_other_wildcards=False):
        return entry

    return None

  def check_for_overlapping_entry (self, in_entry):
    """
    Tests if the input entry overlaps with another entry in this table.

    Returns true if there is an overlap, false otherwise. Since the table is
    sorted, there is only a need to check a certain portion of it.
    """
    #NOTE: Assumes that entries are sorted by decreasing effective_priority
    #NOTE: Ambiguous whether matching should be based on effective_priority
    #      or the regular priority.  Doing it based on effective_priority
    #      since that's what actually affects packet matching.
    #NOTE: We could improve performance by doing a binary search to find the
    #      right priority entries.

    priority = in_entry.effective_priority

    for e in self._table:
      if e.effective_priority < priority:
        break
      elif e.effective_priority > priority:
        continue
      else:
        if e.is_matched_by(in_entry.match) or in_entry.is_matched_by(e.match):
          return True

    return False

########NEW FILE########
__FILENAME__ = keepalive
# Copyright 2012 James McCauley
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at:
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# This file is based on the discovery component in NOX, though it has
# been substantially rewritten.

"""
This module sends periodic echo requests to switches.

At the moment, it only works on the primary OF nexus.

It supports the following commandline options:
 --interval=X  Send an echo request every X seconds (default 20)
 --timeout=X   Expect response from switch within X seconds (default 3)
"""

from pox.core import core
import pox.openflow.libopenflow_01 as of
from pox.lib.recoco import Timer
import time

log = core.getLogger()

def _handle_timer (ofnexus):
  er = of.ofp_echo_request().pack()
  count = len(ofnexus.connections)
  t = time.time()
  dead = []

  for dpid,con in ofnexus.connections.iteritems():
    if t - con.idle_time > (_interval+_switch_timeout):
      dead.append(con)
      continue
    con.send(er)

  for con in dead:
    con.disconnect("timed out")


_running = False
_switch_timeout = None # This amount beyond interval
_interval = None

def launch (interval = 20, timeout = 3):
  global _interval, _switch_timeout
  _interval = float(interval)
  _switch_timeout = float(timeout)
  def start ():
    global _running
    if _running:
      log.error("Keepalive already running")
      return
    _running = True
    Timer(_interval, _handle_timer, recurring=True, args=(core.openflow,))
  core.call_when_ready(start, "openflow", __name__)

########NEW FILE########
__FILENAME__ = libopenflow_01
# Copyright 2011,2012 James McCauley
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at:
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# This file was originally based on pyopenflow.py from NOX, which was
# autogenerated from openflow.h via a program by KK Yap.  It has been
# substantially altered since then.

from __future__ import print_function

import struct
import operator
from itertools import chain, repeat
import sys
from pox.lib.packet.packet_base import packet_base
from pox.lib.packet.ethernet import ethernet
from pox.lib.packet.vlan import vlan
from pox.lib.packet.llc import llc
from pox.lib.packet.ipv4 import ipv4
from pox.lib.packet.udp import udp
from pox.lib.packet.tcp import tcp
from pox.lib.packet.icmp import icmp
from pox.lib.packet.arp import arp

from pox.lib.addresses import *
from pox.lib.util import assert_type
from pox.lib.util import initHelper
from pox.lib.util import hexdump
from pox.lib.util import is_listlike


EMPTY_ETH = EthAddr(None)

# ----------------------------------------------------------------------
# Logging
# ----------------------------------------------------------------------

_logger = None
def _log (debug=None, info=None, warn=None, error=None):
  if not _logger: return
  if debug: _logger.debug(debug)
  if info: _logger.info(info)
  if warn: _logger.warn(warn)
  if error: _logger.error(error)

# ----------------------------------------------------------------------

# ----------------------------------------------------------------------
# XID Management
# ----------------------------------------------------------------------

MAX_XID = 0x7fFFffFF


def XIDGenerator (start = 1, stop = MAX_XID):
  i = start
  while True:
    yield i
    i += 1
    if i > stop:
      i = start

def xid_generator (start = 1, stop = MAX_XID):
  return XIDGenerator(start, stop).next

def user_xid_generator ():
  return xid_generator(0x80000000, 0xffFFffFF)

generate_xid = xid_generator()

# ----------------------------------------------------------------------


# ----------------------------------------------------------------------
# Packing / Unpacking
# ----------------------------------------------------------------------

_PAD = b'\x00'
_PAD2 = _PAD*2
_PAD3 = _PAD*3
_PAD4 = _PAD*4
_PAD6 = _PAD*6

class UnderrunError (RuntimeError):
  """
  Raised when one tries to unpack more data than is available
  """
  pass

def _read (data, offset, length):
  if (len(data)-offset) < length:
    raise UnderrunError("wanted %s bytes but only have %s"
                        % (length, len(data)-offset))
  return (offset+length, data[offset:offset+length])

def _unpack (fmt, data, offset):
  size = struct.calcsize(fmt)
  if (len(data)-offset) < size: raise UnderrunError()
  return (offset+size, struct.unpack_from(fmt, data, offset))

def _skip (data, offset, num):
  offset += num
  if offset > len(data): raise UnderrunError()
  return offset

def _unpad (data, offset, num):
  (offset, o) = _read(data, offset, num)
  assert len(o.replace("\x00", "")) == 0
  return offset

def _readzs (data, offset, length):
  (offset, d) = _read(data, offset, length)
  d = d.split("\x00", 1)
  #if len(d[1].replace("\x00", "")) > 0:
  #  raise RuntimeError("Non-zero string padding")
  assert True if (len(d) == 1) else (len(d[1].replace("\x00", "")) == 0)
  return (offset, d[0])

def _readether (data, offset):
  (offset, d) = _read(data, offset, 6)
  return (offset, EthAddr(d))

def _readip (data, offset, networkOrder = True):
  (offset, d) = _read(data, offset, 4)
  return (offset, IPAddr(d, networkOrder = networkOrder))

# ----------------------------------------------------------------------


def _format_body (body, prefix):
  if hasattr(body, 'show'):
    #TODO: Check this (spacing may well be wrong)
    return body.show(prefix + '  ')
  else:
    return prefix + hexdump(body).replace("\n", "\n" + prefix)

TABLE_ALL = 0xff
TABLE_EMERGENCY = 0xfe


class _ofp_meta (type):
  """
  Metaclass for ofp messages/structures

  This takes care of making len() work as desired.
  """
  def __len__ (cls):
    try:
      return cls.__len__()
    except:
      return cls._MIN_LENGTH


class ofp_base (object):
  """
  Base class for OpenFlow messages/structures

  You should implement a __len__ method.  If your length is fixed, it
  should be a static method.  If your length is not fixed, you should
  implement a __len__ instance method and set a class level _MIN_LENGTH
  attribute to your minimum length.
  """
  __metaclass__ = _ofp_meta

  def _assert (self):
    r = self._validate()
    if r is not None:
      raise RuntimeError(r)
      return False # Never reached
    return True

  def _validate (self):
    return None

  def __ne__ (self, other):
    return not self.__eq__(other)

  @classmethod
  def unpack_new (cls, raw, offset=0):
    """
    Unpacks wire format into the appropriate message object.

    Returns newoffset,object
    """
    o = cls()
    r,length = o.unpack(raw, offset)
    assert (r-offset) == length, o
    return (r, o)


# ----------------------------------------------------------------------
# Class decorators
# ----------------------------------------------------------------------

_message_type_to_class = {}
_message_class_to_types = {} # Do we need this?
#_message_type_to_name = {}
#_message_name_to_type = {}
ofp_type_rev_map = {}
ofp_type_map = {}

def openflow_message (ofp_type, type_val, reply_to=None,
    request_for=None, switch=False, controller=False):
  #TODO: Reply stuff, switch/controller stuff

  #_message_name_to_type[ofp_type] = type_val
  #_message_type_to_name[type_val] = ofp_type
  ofp_type_rev_map[ofp_type] = type_val
  ofp_type_map[type_val] = ofp_type
  def f (c):
    c.header_type = type_val
    c._from_switch = switch
    c._from_controller = controller
    _message_type_to_class[type_val] = c
    _message_class_to_types.setdefault(c, set()).add(type_val)
    return c
  return f

def openflow_sc_message (*args, **kw):
  return openflow_message(switch=True, controller=True, *args, **kw)

def openflow_c_message (*args, **kw):
  return openflow_message(controller=True, *args, **kw)

def openflow_s_message (*args, **kw):
  return openflow_message(switch=True, *args, **kw)

_queue_prop_type_to_class = {}
_queue_prop_class_to_types = {} # Do we need this?
ofp_queue_prop_type_rev_map = {}
ofp_queue_prop_type_map = {}

def openflow_queue_prop (queue_prop_type, type_val):
  ofp_queue_prop_type_rev_map[queue_prop_type] = type_val
  ofp_queue_prop_type_map[type_val] = queue_prop_type
  def f (c):
    c.property = type_val
    _queue_prop_type_to_class[type_val] = c
    _queue_prop_class_to_types.setdefault(c, set()).add(type_val)
    return c
  return f

_action_type_to_class = {}
_action_class_to_types = {} # Do we need this?
ofp_action_type_rev_map = {}
ofp_action_type_map = {}

def openflow_action (action_type, type_val):
  ofp_action_type_rev_map[action_type] = type_val
  ofp_action_type_map[type_val] = action_type
  def f (c):
    c.type = type_val
    _action_type_to_class[type_val] = c
    _action_class_to_types.setdefault(c, set()).add(type_val)
    return c
  return f


class _StatsClassInfo (object):
  __slots__ = 'request reply reply_is_list'.split()

  def __init__ (self, **kw):
    self.request = None
    self.reply = None
    self.reply_is_list = False
    initHelper(self, kw)

  def __str__ (self):
    r = str(self.reply)
    if self.reply_is_list: r = "[%s]" % (r,)
    return "request:%s reply:%s" % (self.request, r)

_stats_type_to_class_info = {}
_stats_class_to_type = {}
ofp_stats_type_rev_map = {}
ofp_stats_type_map = {}

def openflow_stats_request  (stats_type, type_val=None, is_list=None,
    is_reply = False):
  if type_val is not None:
    ofp_stats_type_rev_map[stats_type] = type_val
    ofp_stats_type_map[type_val] = stats_type
  else:
    type_val = ofp_stats_type_rev_map.get(stats_type)

  def f (c):
    if type_val is not None:
      ti = _stats_type_to_class_info.get(stats_type)
      if ti is not None:
        _stats_type_to_class_info[type_val] = ti
        del _stats_type_to_class_info[stats_type]
      else:
        ti = _stats_type_to_class_info.setdefault(type_val,
            _StatsClassInfo())
      _stats_class_to_type[c] = type_val
    else:
      ti = _stats_type_to_class_info.setdefault(stats_type,
          _StatsClassInfo())

    if is_list is not None:
      ti.reply_is_list = is_list
    if is_reply:
      ti.reply = c
    else:
      ti.request = c

    if type_val is not None:
      yes = False
      if ti.reply is not None and issubclass(ti.reply,ofp_stats_body_base):
        ti.reply._type = type_val
        yes = True
      if ti.request is not None and issubclass(ti.request,ofp_stats_body_base):
        ti.request._type = type_val
        yes = True
      assert yes, "Type not set for " + str(stats_type)

    return c
  return f

def openflow_stats_reply (stats_type, type_val=None, is_list=None,
    is_reply = True):
  return openflow_stats_request(stats_type, type_val, is_list, is_reply)

# ----------------------------------------------------------------------


# ----------------------------------------------------------------------
# Constants, etc.
# ----------------------------------------------------------------------

ofp_error_type_rev_map = {
  'OFPET_HELLO_FAILED'    : 0,
  'OFPET_BAD_REQUEST'     : 1,
  'OFPET_BAD_ACTION'      : 2,
  'OFPET_FLOW_MOD_FAILED' : 3,
  'OFPET_PORT_MOD_FAILED' : 4,
  'OFPET_QUEUE_OP_FAILED' : 5,
}

ofp_hello_failed_code_rev_map = {
  'OFPHFC_INCOMPATIBLE' : 0,
  'OFPHFC_EPERM'        : 1,
}

ofp_bad_request_code_rev_map = {
  'OFPBRC_BAD_VERSION'    : 0,
  'OFPBRC_BAD_TYPE'       : 1,
  'OFPBRC_BAD_STAT'       : 2,
  'OFPBRC_BAD_VENDOR'     : 3,
  'OFPBRC_BAD_SUBTYPE'    : 4,
  'OFPBRC_EPERM'          : 5,
  'OFPBRC_BAD_LEN'        : 6,
  'OFPBRC_BUFFER_EMPTY'   : 7,
  'OFPBRC_BUFFER_UNKNOWN' : 8,
}

ofp_bad_action_code_rev_map = {
  'OFPBAC_BAD_TYPE'        : 0,
  'OFPBAC_BAD_LEN'         : 1,
  'OFPBAC_BAD_VENDOR'      : 2,
  'OFPBAC_BAD_VENDOR_TYPE' : 3,
  'OFPBAC_BAD_OUT_PORT'    : 4,
  'OFPBAC_BAD_ARGUMENT'    : 5,
  'OFPBAC_EPERM'           : 6,
  'OFPBAC_TOO_MANY'        : 7,
  'OFPBAC_BAD_QUEUE'       : 8,
}

ofp_flow_mod_failed_code_rev_map = {
  'OFPFMFC_ALL_TABLES_FULL'   : 0,
  'OFPFMFC_OVERLAP'           : 1,
  'OFPFMFC_EPERM'             : 2,
  'OFPFMFC_BAD_EMERG_TIMEOUT' : 3,
  'OFPFMFC_BAD_COMMAND'       : 4,
  'OFPFMFC_UNSUPPORTED'       : 5,
}

ofp_port_mod_failed_code_rev_map = {
  'OFPPMFC_BAD_PORT'    : 0,
  'OFPPMFC_BAD_HW_ADDR' : 1,
}

ofp_queue_op_failed_code_rev_map = {
  'OFPQOFC_BAD_PORT'  : 0,
  'OFPQOFC_BAD_QUEUE' : 1,
  'OFPQOFC_EPERM'     : 2,
}

ofp_port_config_rev_map = {
  'OFPPC_PORT_DOWN'    : 1,
  'OFPPC_NO_STP'       : 2,
  'OFPPC_NO_RECV'      : 4,
  'OFPPC_NO_RECV_STP'  : 8,
  'OFPPC_NO_FLOOD'     : 16,
  'OFPPC_NO_FWD'       : 32,
  'OFPPC_NO_PACKET_IN' : 64,
}

ofp_port_state_rev_map = {
  'OFPPS_STP_LISTEN'  : 0,
  'OFPPS_LINK_DOWN'   : 1,
  'OFPPS_STP_LEARN'   : 256,
  'OFPPS_STP_FORWARD' : 512,
  'OFPPS_STP_BLOCK'   : 768,
}
OFPPS_STP_MASK        = 768

ofp_port_features_rev_map = {
  'OFPPF_10MB_HD'    : 1,
  'OFPPF_10MB_FD'    : 2,
  'OFPPF_100MB_HD'   : 4,
  'OFPPF_100MB_FD'   : 8,
  'OFPPF_1GB_HD'     : 16,
  'OFPPF_1GB_FD'     : 32,
  'OFPPF_10GB_FD'    : 64,
  'OFPPF_COPPER'     : 128,
  'OFPPF_FIBER'      : 256,
  'OFPPF_AUTONEG'    : 512,
  'OFPPF_PAUSE'      : 1024,
  'OFPPF_PAUSE_ASYM' : 2048,
}

ofp_queue_properties_rev_map = {
  'OFPQT_MIN_RATE' : 0,
}
OFPQT_NONE         = 0

ofp_capabilities_rev_map = {
  'OFPC_FLOW_STATS'   : 1,
  'OFPC_TABLE_STATS'  : 2,
  'OFPC_PORT_STATS'   : 4,
  'OFPC_STP'          : 8,
  'OFPC_RESERVED'     : 16,
  'OFPC_IP_REASM'     : 32,
  'OFPC_QUEUE_STATS'  : 64,
  'OFPC_ARP_MATCH_IP' : 128,
}

ofp_config_flags_rev_map = {
  'OFPC_FRAG_NORMAL' : 0,
  'OFPC_FRAG_DROP'   : 1,
  'OFPC_FRAG_REASM'  : 2,
  'OFPC_FRAG_MASK'   : 3,
}

ofp_flow_mod_command_rev_map = {
  'OFPFC_ADD'           : 0,
  'OFPFC_MODIFY'        : 1,
  'OFPFC_MODIFY_STRICT' : 2,
  'OFPFC_DELETE'        : 3,
  'OFPFC_DELETE_STRICT' : 4,
}

ofp_flow_mod_flags_rev_map = {
  'OFPFF_SEND_FLOW_REM' : 1,
  'OFPFF_CHECK_OVERLAP' : 2,
  'OFPFF_EMERG'         : 4,
}

ofp_stats_reply_flags_rev_map = {
  'OFPSF_REPLY_MORE' : 1,
}

ofp_packet_in_reason_rev_map = {
  'OFPR_NO_MATCH' : 0,
  'OFPR_ACTION'   : 1,
}

ofp_flow_removed_reason_rev_map = {
  'OFPRR_IDLE_TIMEOUT' : 0,
  'OFPRR_HARD_TIMEOUT' : 1,
  'OFPRR_DELETE'       : 2,
}

ofp_port_reason_rev_map = {
  'OFPPR_ADD'    : 0,
  'OFPPR_DELETE' : 1,
  'OFPPR_MODIFY' : 2,
}

ofp_port_rev_map = {
  'OFPP_MAX'        : 65280,
  'OFPP_IN_PORT'    : 65528,
  'OFPP_TABLE'      : 65529,
  'OFPP_NORMAL'     : 65530,
  'OFPP_FLOOD'      : 65531,
  'OFPP_ALL'        : 65532,
  'OFPP_CONTROLLER' : 65533,
  'OFPP_LOCAL'      : 65534,
  'OFPP_NONE'       : 65535,
}

ofp_flow_wildcards_rev_map = {
  'OFPFW_IN_PORT'      : 1,
  'OFPFW_DL_VLAN'      : 2,
  'OFPFW_DL_SRC'       : 4,
  'OFPFW_DL_DST'       : 8,
  'OFPFW_DL_TYPE'      : 16,
  'OFPFW_NW_PROTO'     : 32,
  'OFPFW_TP_SRC'       : 64,
  'OFPFW_TP_DST'       : 128,
  'OFPFW_DL_VLAN_PCP'  : 1048576,
  'OFPFW_NW_TOS'       : 1<<21,
}

OFPFW_NW_DST_BITS      = 6
OFPFW_NW_SRC_BITS      = 6
OFPFW_NW_SRC_SHIFT     = 8
OFPFW_NW_DST_SHIFT     = 14
OFPFW_NW_SRC_ALL       = 8192
OFPFW_NW_SRC_MASK      = 16128
OFPFW_NW_DST_ALL       = 524288
OFPFW_NW_DST_MASK      = 1032192
# Note: Need to handle all flags that are set in this.
# glob-all masks in the packet handling methods.
# (Esp. ofp_match.from_packet)
# Otherwise, packets are not being matched as they should
OFPFW_ALL              = ((1 << 22) - 1)

NO_BUFFER = 4294967295

# ----------------------------------------------------------------------


# ----------------------------------------------------------------------
# Structure definitions
# ----------------------------------------------------------------------

#1. Openflow Header
class ofp_header (ofp_base):
  _MIN_LENGTH = 8
  def __init__ (self, **kw):
    self.version = OFP_VERSION
    #self.header_type = None # Set via class decorator
    self._xid = None
    if 'header_type' in kw:
      self.header_type = kw.pop('header_type')
    initHelper(self, kw)

  @property
  def xid (self):
    if self._xid is None:
      self._xid = generate_xid()
    return self._xid

  @xid.setter
  def xid (self, val):
    self._xid = val

  def _validate (self):
    if self.header_type not in ofp_type_map:
      return "type is not a known message type"
    return None

  def pack (self):
    assert self._assert()

    packed = b""
    packed += struct.pack("!BBHL", self.version, self.header_type,
        len(self), self.xid)
    return packed

  def unpack (self, raw, offset=0):
    offset,length = self._unpack_header(raw, offset)
    return offset,length

  def _unpack_header (self, raw, offset):
    offset,(self.version, self.header_type, length, self.xid) = \
        _unpack("!BBHL", raw, offset)
    return offset,length

  def __eq__ (self, other):
    if type(self) != type(other): return False
    if self.version != other.version: return False
    if self.header_type != other.header_type: return False
    if len(self) != len(other): return False
    if self.xid != other.xid: return False
    return True

  def show (self, prefix=''):
    outstr = ''
    outstr += prefix + 'version: ' + str(self.version) + '\n'
    outstr += prefix + 'type:    ' + str(self.header_type)# + '\n'
    outstr += " (" + ofp_type_map.get(self.header_type, "Unknown") + ")\n"
    try:
      outstr += prefix + 'length:  ' + str(len(self)) + '\n'
    except:
      pass
    outstr += prefix + 'xid:     ' + str(self.xid) + '\n'
    return outstr

  def __str__ (self):
    return self.__class__.__name__ + "\n  " + self.show('  ').strip()


class ofp_stats_body_base (ofp_base):
  """
  Base class for stats bodies
  """
  # Stats bodies don't actually have a type field in OpenFlow --
  # the type information is in the request or reply.  It's really
  # convenient, though, so we add it.  Note that you generally
  # don't need to set this yourself -- the openflow_stats_XXX
  # decorator will do it for you.
  _type = None

  """
  def unpack (self, data, offset=0, avail=None):
  """


class ofp_action_base (ofp_base):
  """
  Base class for actions

  This is sort of the equivalent of ofp_action_header in the spec.
  However, ofp_action_header as the spec defines it is not super
  useful for us, as it has the padding in it.
  """
  type = None

  @classmethod
  def unpack_new (cls, raw, offset=0):
    """
    Unpacks wire format into the appropriate action object.

    Returns newoffset,object
    """
    o = cls()
    r = o.unpack(raw, offset)
    assert (r-offset) == len(o), o
    return (r, o)


class ofp_queue_prop_base (ofp_base):
  """
  Base class for queue properties

  This is sort of the equivalent of ofp_queue_prop_header in the spec.
  However, ofp_queue_prop_header as the spec defines it is not super
  useful for us, as it has the padding in it.
  """
  property = None


#2. Common Structures
##2.1 Port Structures
class ofp_phy_port (ofp_base):
  def __init__ (self, **kw):
    self.port_no = 0
    self.hw_addr = EMPTY_ETH
    self.name = ""
    self.config = 0
    self.state = 0
    self.curr = 0
    self.advertised = 0
    self.supported = 0
    self.peer = 0
    initHelper(self, kw)

  def enable_config (self, mask):
    """
    Turn on selected config bits
    """
    return self.set_config(0xffFFffFF, mask)

  def disable_config (self, mask):
    """
    Turn off selected config bits
    """
    return self.set_config(0, mask)

  def set_config (self, config, mask):
    """
    Updates the specified config bits

    Returns which bits were changed
    """
    old = self.config
    self.config &= ~mask
    self.config |= config
    return old ^ self.config

  def __str__ (self):
    return "%s:%i" % (self.name, self.port_no)

  def _validate (self):
    if isinstance(self.hw_addr, bytes) and len(self.hw_addr) == 6:
      pass
    elif not isinstance(self.hw_addr, EthAddr):
      return "hw_addr is not a valid format"
    if len(self.name) > OFP_MAX_PORT_NAME_LEN:
      return "name is too long"
    return None

  def pack (self):
    assert self._assert()

    packed = b""
    packed += struct.pack("!H", self.port_no)
    packed += (self.hw_addr if isinstance(self.hw_addr, bytes) else
               self.hw_addr.toRaw())
    packed += self.name.ljust(OFP_MAX_PORT_NAME_LEN,'\0')
    packed += struct.pack("!LLLLLL", self.config, self.state, self.curr,
                          self.advertised, self.supported, self.peer)
    return packed

  def unpack (self, raw, offset=0):
    _offset = offset
    offset,(self.port_no,) = _unpack("!H", raw, offset)
    offset,self.hw_addr = _readether(raw, offset)
    offset,self.name = _readzs(raw, offset, OFP_MAX_PORT_NAME_LEN)
    offset,(self.config, self.state, self.curr, self.advertised,
            self.supported, self.peer) = _unpack("!LLLLLL", raw, offset)
    assert offset - _offset == len(self)
    return offset

  @staticmethod
  def __len__ ():
    return 48

  def __eq__ (self, other):
    if type(self) != type(other): return False
    if self.port_no != other.port_no: return False
    if self.hw_addr != other.hw_addr: return False
    if self.name != other.name: return False
    if self.config != other.config: return False
    if self.state != other.state: return False
    if self.curr != other.curr: return False
    if self.advertised != other.advertised: return False
    if self.supported != other.supported: return False
    if self.peer != other.peer: return False
    return True

  def __cmp__ (self, other):
    if type(other) != type(self): return id(self)-id(other)
    if self.port_no < other.port_no: return -1
    if self.port_no > other.port_no: return 1
    if self == other: return 0
    return id(self)-id(other)

  def __hash__(self, *args, **kwargs):
    return hash(self.port_no) ^ hash(self.hw_addr) ^ \
           hash(self.name) ^ hash(self.config) ^ \
           hash(self.state) ^ hash(self.curr) ^ \
           hash(self.advertised) ^ hash(self.supported) + \
           hash(self.peer)

  def show (self, prefix=''):
    outstr = ''
    outstr += prefix + 'port_no: ' + str(self.port_no) + '\n'
    outstr += prefix + 'hw_addr: ' + str(EthAddr(self.hw_addr)) + '\n'
    outstr += prefix + 'name: ' + str(self.name) + '\n'
    outstr += prefix + 'config: ' + str(self.config) + '\n'
    outstr += prefix + 'state: ' + str(self.state) + '\n'
    outstr += prefix + 'curr: ' + str(self.curr) + '\n'
    outstr += prefix + 'advertised: ' + str(self.advertised) + '\n'
    outstr += prefix + 'supported: ' + str(self.supported) + '\n'
    outstr += prefix + 'peer: ' + str(self.peer) + '\n'
    return outstr

  def __repr__(self):
    return self.show()


##2.2 Queue Structures
class ofp_packet_queue (ofp_base):
  _MIN_LENGTH = 8
  def __init__ (self, **kw):
    self.queue_id = 0
    self.properties = []

    initHelper(self, kw)

  def pack (self):
    assert self._assert()

    packed = b""
    packed += struct.pack("!LH", self.queue_id, len(self))
    packed += _PAD2 # Pad
    for i in self.properties:
      packed += i.pack()
    return packed

  def unpack (self, raw, offset=0):
    _offset = offset
    offset,(self.queue_id, length) = _unpack("!LH", raw, offset)
    offset = _skip(raw, offset, 2)
    length -= (4 + 2 + 2)

    offset,self.properties = _unpack_queue_props(raw, length, offset)

    assert offset - _offset == len(self)
    return offset

  def __len__ (self):
    l = 8
    for i in self.properties:
      l += len(i)
    return l

  def __eq__ (self, other):
    if type(self) != type(other): return False
    if self.queue_id != other.queue_id: return False
    if len(self) != len(other): return False
    if self.properties != other.properties: return False
    return True

  def show (self, prefix=''):
    outstr = ''
    outstr += prefix + 'queue_id: ' + str(self.queue_id) + '\n'
    outstr += prefix + 'len: ' + str(len(self)) + '\n'
    outstr += prefix + 'properties: \n'
    for obj in self.properties:
      outstr += obj.show(prefix + '  ')
    return outstr


class ofp_queue_prop_generic (ofp_queue_prop_base):
  _MIN_LENGTH = 8
  def __init__ (self, **kw):
    self.property = None # Purposely bad
    self.data = _PAD4

    initHelper(self, kw)

  def pack (self):
    assert self._assert()

    packed = b""
    packed += struct.pack("!HH", self.property, len(self))
    packed += self.data
    return packed

  def unpack (self, raw, offset=0):
    _offset = offset
    offset,(self.property, length) = _unpack("!HH", raw, offset)
    offset,self.data = _read(raw, offset, length-4)
    assert offset - _offset == len(self)
    return offset

  @staticmethod
  def __len__ ():
    return 4 + len(self.data)

  def __eq__ (self, other):
    if type(self) != type(other): return False
    if self.property != other.property: return False
    if len(self) != len(other): return False
    if self.data != other.data: return False
    return True

  def show (self, prefix=''):
    outstr = ''
    outstr += prefix + 'property: ' + str(self.property) + '\n'
    outstr += prefix + 'len: ' + str(len(self)) + '\n'
    return outstr


@openflow_queue_prop('OFPQT_NONE', 0)
class ofp_queue_prop_none (ofp_queue_prop_generic):
  pass


@openflow_queue_prop('OFPQT_MIN_RATE', 1)
class ofp_queue_prop_min_rate (ofp_base):
  def __init__ (self, **kw):
    self.rate = 0

    initHelper(self, kw)

  def pack (self):
    assert self._assert()

    packed = b""
    packed += struct.pack("!HH", self.property, len(self))
    packed += _PAD4
    packed += struct.pack("!H", self.rate)
    packed += _PAD6
    return packed

  def unpack (self, raw, offset=0):
    _offset = offset
    offset,(self.property, length, pad) = \
        _unpack("!HHL", raw, offset)
    offset,(self.rate,) = _unpack("!H", raw, offset)
    offset = _skip(raw, offset, 6)
    assert offset - _offset == len(self)
    return offset

  @staticmethod
  def __len__ ():
    return 16

  def __eq__ (self, other):
    if type(self) != type(other): return False
    if self.property != other.property: return False
    if self.rate != other.rate: return False
    return True

  def show (self, prefix=''):
    outstr = ''
    outstr += prefix + 'property: ' + str(self.property) + '\n'
    outstr += prefix + 'len: ' + str(len(self)) + '\n'
    outstr += prefix + 'rate: ' + str(self.rate) + '\n'
    return outstr


##2.3 Flow Match Structures
class ofp_match (ofp_base):
  adjust_wildcards = True # Set to true to "fix" outgoing wildcards

  @classmethod
  def from_packet (cls, packet, in_port = None, spec_frags = False):
    """
    Constructs an exact match for the given packet

    @param in_port The switch port the packet arrived on if you want
                   the resulting match to have its in_port set.
                   If "packet" is a packet_in, this is ignored.
    @param packet  A pox.packet.ethernet instance or a packet_in
    @param spec_frags Handle IP fragments as specified in the spec.
    """
    if isinstance(packet, ofp_packet_in):
      in_port = packet.in_port
      packet = ethernet(packet.data)
    assert assert_type("packet", packet, ethernet, none_ok=False)

    match = cls()

    if in_port is not None:
      match.in_port = in_port

    match.dl_src = packet.src
    match.dl_dst = packet.dst
    match.dl_type = packet.type
    p = packet.next

    # Is this in the spec?
    if packet.type < 1536:
      match.dl_type = OFP_DL_TYPE_NOT_ETH_TYPE
    # LLC then VLAN?  VLAN then LLC?
    if isinstance(p, llc):
      if p.has_snap and p.oui == '\0\0\0':
        match.dl_type = p.eth_type
        p = p.next
    if isinstance(p, vlan):
      match.dl_type = p.eth_type
      match.dl_vlan = p.id
      match.dl_vlan_pcp = p.pcp
      p = p.next
    else:
      match.dl_vlan = OFP_VLAN_NONE
      match.dl_vlan_pcp = 0

    if isinstance(p, ipv4):
      match.nw_src = p.srcip
      match.nw_dst = p.dstip
      match.nw_proto = p.protocol
      match.nw_tos = p.tos
      if spec_frags and ((p.flags & p.MF_FLAG) or p.frag != 0):
        # This seems a bit strange, but see page 9 of the spec.
        match.tp_src = 0
        match.tp_dst = 0
        return match
      p = p.next

      if isinstance(p, udp) or isinstance(p, tcp):
        match.tp_src = p.srcport
        match.tp_dst = p.dstport
      elif isinstance(p, icmp):
        match.tp_src = p.type
        match.tp_dst = p.code
    elif isinstance(p, arp):
      if p.opcode <= 255:
        match.nw_proto = p.opcode
        match.nw_src = p.protosrc
        match.nw_dst = p.protodst

    return match

  def clone (self):
    n = ofp_match()
    for k,v in ofp_match_data.iteritems():
      setattr(n, '_' + k, getattr(self, '_' + k))
    n.wildcards = self.wildcards
    return n

  def flip (self, in_port = True):
    """
    Return version of this match with src and dst fields swapped

    in_port can be:
      True  : Include same in_port in new match
      Other : Set Other as in_port in new match
    """
    reversed = self.clone()
    for field in ('dl','nw','tp'):
      setattr(reversed, field + '_src', getattr(self, field + '_dst'))
      setattr(reversed, field + '_dst', getattr(self, field + '_src'))
    if in_port is not True:
      reversed.in_port = in_port

    return reversed

  def __init__ (self, **kw):
    self._locked = False

    for k,v in ofp_match_data.iteritems():
      setattr(self, '_' + k, v[0])

    self.wildcards = self._normalize_wildcards(OFPFW_ALL)

    # This is basically initHelper(), but tweaked slightly since this
    # class does some magic of its own.
    for k,v in kw.iteritems():
      if not hasattr(self, '_'+k):
        raise TypeError(self.__class__.__name__ + " constructor got "
          + "unexpected keyword argument '" + k + "'")
      setattr(self, k, v)

  def get_nw_dst (self):
    if (self.wildcards & OFPFW_NW_DST_ALL) == OFPFW_NW_DST_ALL:
      return (None, 0)

    w = (self.wildcards & OFPFW_NW_DST_MASK) >> OFPFW_NW_DST_SHIFT
    return (self._nw_dst,32-w if w <= 32 else 0)

  def get_nw_src (self):
    if (self.wildcards & OFPFW_NW_SRC_ALL) == OFPFW_NW_SRC_ALL:
      return (None, 0)

    w = (self.wildcards & OFPFW_NW_SRC_MASK) >> OFPFW_NW_SRC_SHIFT
    return (self._nw_src,32-w if w <= 32 else 0)

  def set_nw_dst (self, *args, **kw):
    a = self._make_addr(*args, **kw)
    if a is None:
      self._nw_dst = ofp_match_data['nw_dst'][0]
      self.wildcards &= ~OFPFW_NW_DST_MASK
      self.wildcards |= ofp_match_data['nw_dst'][1]
      return
    self._nw_dst = a[0]
    self.wildcards &= ~OFPFW_NW_DST_MASK
    self.wildcards |= ((32-a[1]) << OFPFW_NW_DST_SHIFT)

  def set_nw_src (self, *args, **kw):
    a = self._make_addr(*args, **kw)
    if a is None:
      self._nw_src = ofp_match_data['nw_src'][0]
      self.wildcards &= ~OFPFW_NW_SRC_MASK
      self.wildcards |= ofp_match_data['nw_src'][1]
      return
    self._nw_src = a[0]
    self.wildcards &= ~OFPFW_NW_SRC_MASK
    self.wildcards |= ((32-a[1]) << OFPFW_NW_SRC_SHIFT)

  def _make_addr (self, ipOrIPAndBits, bits=None):
    if ipOrIPAndBits is None: return None
    b = None
    if type(ipOrIPAndBits) is tuple:
      ip = ipOrIPAndBits[0]
      b = int(ipOrIPAndBits[1])

    if (type(ipOrIPAndBits) is str) and (len(ipOrIPAndBits) != 4):
      if ipOrIPAndBits.find('/') != -1:
        #s = ipOrIPAndBits.split('/')
        s = parse_cidr(ipOrIPAndBits, infer=False)
        ip = s[0]
        b = int(s[1]) if b is None else b
      else:
        ip = ipOrIPAndBits
        b = 32 if b is None else b
    else:
      ip = ipOrIPAndBits
      b = 32 if b is None else b

    if type(ip) is str:
      ip = IPAddr(ip)

    if bits != None: b = bits
    if b > 32: b = 32
    elif b < 0: b = 0

    return (ip, b)

  def __setattr__ (self, name, value):
    if name == '_locked':
      super(ofp_match,self).__setattr__(name, value)
      return

    if self._locked:
      raise AttributeError('match object is locked')

    if name not in ofp_match_data:
      self.__dict__[name] = value
      return

    if name == 'nw_dst' or name == 'nw_src':
      # Special handling
      getattr(self, 'set_' + name)(value)
      return value

    if value is None:
      setattr(self, '_' + name, ofp_match_data[name][0])
      self.wildcards |= ofp_match_data[name][1]
    else:
      setattr(self, '_' + name, value)
      self.wildcards = self.wildcards & ~ofp_match_data[name][1]

    return value

  def __getattr__ (self, name):
    if name in ofp_match_data:
      if ( (self.wildcards & ofp_match_data[name][1])
           == ofp_match_data[name][1] ):
        # It's wildcarded -- always return None
        return None
      if name == 'nw_dst' or name == 'nw_src':
        # Special handling
        return getattr(self, 'get_' + name)()[0]
      return self.__dict__['_' + name]
    raise AttributeError("attribute not found: "+name)

  def _validate (self):
    # TODO
    return None

  def _prereq_warning (self):
    # Only checked when assertions are on
    if not _logger: return True
    om = self.clone()
    om.fix()

    if om == self: return True

    msg = "Fields ignored due to unspecified prerequisites: "
    wcs = []

    for name in ofp_match_data.keys():
      if getattr(self,name) is None: continue
      if getattr(om,name) is not None: continue
      wcs.append(name)

    msg = msg + " ".join(wcs)

    _log(warn = msg)
    _log(debug = "Problematic match: " + str(self))

    return True # Always; we don't actually want an assertion error

  def pack (self, flow_mod=False):
    assert self._assert()

    packed = b""
    if self.adjust_wildcards and flow_mod:
      wc = self._wire_wildcards(self.wildcards)
      assert self._prereq_warning()
    else:
      wc = self.wildcards
    packed += struct.pack("!LH", wc, self.in_port or 0)
    if self.dl_src is None:
      packed += EMPTY_ETH.toRaw()
    elif type(self.dl_src) is bytes:
      packed += self.dl_src
    else:
      packed += self.dl_src.toRaw()
    if self.dl_dst is None:
      packed += EMPTY_ETH.toRaw()
    elif type(self.dl_dst) is bytes:
      packed += self.dl_dst
    else:
      packed += self.dl_dst.toRaw()

    def check_ip(val):
      return (val or 0) if self.dl_type == 0x0800 else 0
    def check_ip_or_arp(val):
      return (val or 0) if self.dl_type == 0x0800 \
                           or self.dl_type == 0x0806 else 0
    def check_tp(val):
      return (val or 0) if self.dl_type == 0x0800 \
                           and self.nw_proto in (1,6,17) else 0

    packed += struct.pack("!HB", self.dl_vlan or 0, self.dl_vlan_pcp or 0)
    packed += _PAD # Hardcode padding
    packed += struct.pack("!HBB", self.dl_type or 0,
        check_ip(self.nw_tos), check_ip_or_arp(self.nw_proto))
    packed += _PAD2 # Hardcode padding
    def fix (addr):
      if addr is None: return 0
      if type(addr) is int: return addr & 0xffFFffFF
      if type(addr) is long: return addr & 0xffFFffFF
      return addr.toUnsigned()

    packed += struct.pack("!LLHH", check_ip_or_arp(fix(self.nw_src)),
        check_ip_or_arp(fix(self.nw_dst)),
        check_tp(self.tp_src), check_tp(self.tp_dst))

    return packed

  def _normalize_wildcards (self, wildcards):
    """
    nw_src and nw_dst values greater than 32 mean the same thing as 32.
    We normalize them here just to be clean and so that comparisons act
    as you'd want them to.
    """
    if ((wildcards & OFPFW_NW_SRC_MASK) >> OFPFW_NW_SRC_SHIFT) > 32:
      wildcards &= ~OFPFW_NW_SRC_MASK
      wildcards |= (32 << OFPFW_NW_SRC_SHIFT)
    if ((wildcards & OFPFW_NW_DST_MASK) >> OFPFW_NW_DST_SHIFT) > 32:
      wildcards &= ~OFPFW_NW_DST_MASK
      wildcards |= (32 << OFPFW_NW_DST_SHIFT)
    return wildcards

  def _wire_wildcards (self, wildcards):
    """
    Normalize the wildcard bits

    Note the following from the OpenFlow 1.1 spec:

      Protocol-specific fields within ofp_match will be ignored within
      a single table when the corresponding protocol is not specified in the
      match.  The IP header and transport header fields
      will be ignored unless the Ethertype is specified as either IPv4 or
      ARP. The tp_src and tp_dst fields will be ignored unless the network
      protocol specified is as TCP, UDP or SCTP. Fields that are ignored
      don't need to be wildcarded and should be set to 0.

    OpenFlow 1.0.1 Section 3.4 actually has an improved version of the above,
    but we won't quote it here because it seems to have a restrictive license.
    """
    #TODO: Set the masked fields to 0.
    if self.dl_type == 0x0800:
        # IP
        if  self.nw_proto not in (1,6,17):
          # not TCP/UDP/ICMP -> Clear TP wildcards for the wire
          return wildcards & ~(OFPFW_TP_SRC | OFPFW_TP_DST)
        else:
          return wildcards
    elif self.dl_type == 0x0806:
        # ARP: clear NW_TOS / TP wildcards for the wire
        return wildcards & ~( OFPFW_NW_TOS | OFPFW_TP_SRC | OFPFW_TP_DST)
    else:
        # not even IP. Clear NW/TP wildcards for the wire
        return wildcards & ~( OFPFW_NW_TOS | OFPFW_NW_PROTO
            | OFPFW_NW_SRC_MASK | OFPFW_NW_DST_MASK
            | OFPFW_TP_SRC | OFPFW_TP_DST)

  def fix (self):
    """
    Removes unmatchable fields

    The logic in this should exactly match that in _wire_wildcards()
    """
    if self.dl_type == 0x0800:
        # IP
        if  self.nw_proto not in (1,6,17):
          # not TCP/UDP/ICMP -> Clear TP wildcards for the wire
          self.tp_src = None
          self.tp_dst = None
          return
    elif self.dl_type == 0x0806:
        # ARP: clear NW_TOS / TP wildcards for the wire
        self.tp_src = None
        self.tp_dst = None
        self.nw_tos = None
        return
    else:
        # not even IP. Clear NW/TP wildcards for the wire
        self.nw_tos = None
        self.nw_proto = None
        self.nw_src = None
        self.nw_dst = None
        self.tp_src = None
        self.tp_dst = None
        return

  def _unwire_wildcards (self, wildcards):
    """
    Normalize the wildcard bits from the openflow wire representation.

    Note this atrocity from the OF1.1 spec:
    Protocol-specific fields within ofp_match will be ignored within
    a single table when the corresponding protocol is not specified in the
    match.  The IP header and transport header fields
    will be ignored unless the Ethertype is specified as either IPv4 or
    ARP. The tp_src and tp_dst fields will be ignored unless the network
    protocol specified is as TCP, UDP or SCTP. Fields that are ignored
    don't need to be wildcarded and should be set to 0.
    """
    if self._dl_type == 0x0800:
        # IP
        if  self._nw_proto not in (1,6,17):
          # not TCP/UDP/ICMP -> Set TP wildcards for the object
          return wildcards | (OFPFW_TP_SRC | OFPFW_TP_DST)
        else:
          return wildcards
    elif self._dl_type == 0x0806:
        # ARP: Set NW_TOS / TP wildcards for the object
        return wildcards | ( OFPFW_NW_TOS | OFPFW_TP_SRC | OFPFW_TP_DST)
    else:
        # not even IP. Set NW/TP wildcards for the object
        return wildcards | ( OFPFW_NW_TOS | OFPFW_NW_PROTO
                             | OFPFW_NW_SRC_MASK | OFPFW_NW_DST_MASK
                             | OFPFW_TP_SRC | OFPFW_TP_DST)


  @property
  def is_wildcarded (self):
    return self.wildcards & OFPFW_ALL != 0

  @property
  def is_exact (self):
    return not self.is_wildcarded

  def unpack (self, raw, offset=0, flow_mod=False):
    _offset = offset
    offset,(wildcards, self._in_port) = _unpack("!LH",raw, offset)
    offset,self._dl_src = _readether(raw, offset)
    offset,self._dl_dst = _readether(raw, offset)
    offset,(self._dl_vlan, self._dl_vlan_pcp) = \
        _unpack("!HB", raw, offset)
    offset = _skip(raw, offset, 1)
    offset,(self._dl_type, self._nw_tos, self._nw_proto) = \
        _unpack("!HBB", raw, offset)
    offset = _skip(raw, offset, 2)
    offset,self._nw_src = _readip(raw, offset)
    offset,self._nw_dst = _readip(raw, offset)
    offset,(self._tp_src, self._tp_dst) = _unpack("!HH", raw, offset)

    # Only unwire wildcards for flow_mod
    self.wildcards = self._normalize_wildcards(
        self._unwire_wildcards(wildcards) if flow_mod else wildcards)

    assert offset - _offset == len(self)
    return offset

  @staticmethod
  def __len__ ():
    return 40

  def hash_code (self):
    """
    generate a hash value for this match

    This generates a hash code which might be useful, but without locking
    the match object.
    """

    h = self.wildcards
    for f in ofp_match_data:
      v = getattr(self, f)
      if type(v) is int:
        h ^= v
      elif type(v) is long:
        h ^= v
      else:
        h ^= hash(v)

    return int(h & 0x7fFFffFF)

  def __hash__ (self):
    self._locked = True
    return self.hash_code()

  def matches_with_wildcards (self, other, consider_other_wildcards=True):
    """
    Test whether /this/ match completely encompasses the other match.

    if consider_other_wildcards, then the *other* match must also have
    no more wildcards than we do (it must be no wider than we are)

    Important for non-strict modify flow_mods etc.
    """
    assert assert_type("other", other, ofp_match, none_ok=False)

    # shortcut for equal matches
    if self == other: return True

    if consider_other_wildcards:
      # Check that other doesn't have more wildcards than we do -- it
      # must be narrower (or equal) to us.
      self_bits  = self.wildcards&~(OFPFW_NW_SRC_MASK|OFPFW_NW_DST_MASK)
      other_bits = other.wildcards&~(OFPFW_NW_SRC_MASK|OFPFW_NW_DST_MASK)
      if (self_bits | other_bits) != self_bits: return False

    def match_fail (mine, others):
      if mine is None: return False # Wildcarded
      return mine != others

    if match_fail(self.in_port, other.in_port): return False
    if match_fail(self.dl_vlan, other.dl_vlan): return False
    if match_fail(self.dl_src, other.dl_src): return False
    if match_fail(self.dl_dst, other.dl_dst): return False
    if match_fail(self.dl_type, other.dl_type): return False
    if match_fail(self.nw_proto, other.nw_proto): return False
    if match_fail(self.tp_src, other.tp_src): return False
    if match_fail(self.tp_dst, other.tp_dst): return False
    if match_fail(self.dl_vlan_pcp, other.dl_vlan_pcp): return False
    if match_fail(self.nw_tos, other.nw_tos): return False

    #FIXME: The two ??? checks below look like they compare other
    #       wildcards always -- even when consider_other_wildcards=False.
    #       Is this intentional?  (I think it might be subtly wrong and
    #       we actually may need to mask off some bits and do the
    #       inNetwork check or something...)

    self_nw_src = self.get_nw_src()
    if self_nw_src[0] is not None:
      other_nw_src = other.get_nw_src()
      if self_nw_src[1] > other_nw_src[1]: return False #???
      if not IPAddr(other_nw_src[0]).inNetwork(
            (self_nw_src[0], self_nw_src[1])): return False

    self_nw_dst = self.get_nw_dst()
    if self_nw_dst[0] is not None:
      other_nw_dst = other.get_nw_dst()
      if self_nw_dst[1] > other_nw_dst[1]: return False #???
      if not IPAddr(other_nw_dst[0]).inNetwork(
            (self_nw_dst[0], self_nw_dst[1])): return False

    return True

  def __eq__ (self, other):
    if type(self) != type(other): return False
    if self.wildcards != other.wildcards: return False
    if self.in_port != other.in_port: return False
    if self.dl_src != other.dl_src: return False
    if self.dl_dst != other.dl_dst: return False
    if self.dl_vlan != other.dl_vlan: return False
    if self.dl_vlan_pcp != other.dl_vlan_pcp: return False
    if self.dl_type != other.dl_type: return False
    if self.nw_tos != other.nw_tos: return False
    if self.nw_proto != other.nw_proto: return False
    if self.nw_src != other.nw_src: return False
    if self.nw_dst != other.nw_dst: return False
    if self.tp_src != other.tp_src: return False
    if self.tp_dst != other.tp_dst: return False
    return True

  def __str__ (self):
    return self.__class__.__name__ + "\n  " + self.show('  ').strip()

  def show (self, prefix=''):
    def binstr (n):
      s = ''
      while True:
        s = ('1' if n & 1 else '0') + s
        n >>= 1
        if n == 0: break
      return s
    def safehex(n):
      if n is None:
        return "(None)"
      else:
        return hex(n)

    def show_wildcards(w):
      parts = [ k.lower()[len("OFPFW_"):]
                for (k,v) in ofp_flow_wildcards_rev_map.iteritems()
                if v & w == v ]
      nw_src_bits = (w & OFPFW_NW_SRC_MASK) >> OFPFW_NW_SRC_SHIFT
      if nw_src_bits > 0:
        parts.append("nw_src(/%d)" % (32 - nw_src_bits))

      nw_dst_bits = (w & OFPFW_NW_DST_MASK) >> OFPFW_NW_DST_SHIFT
      if nw_dst_bits > 0:
        parts.append("nw_dst(/%d)" % (32 - nw_dst_bits))

      return "|".join(parts)

    outstr = ''
    outstr += prefix + 'wildcards: '
    outstr += show_wildcards(self.wildcards)
    outstr += ' (%s = %x)\n' % (binstr(self.wildcards), self.wildcards)
    def append (f, formatter=str):
      v = self.__getattr__(f)
      if v is None: return ''
      return prefix + f + ": " + formatter(v) + "\n"
    outstr += append('in_port')
    outstr += append('dl_src')
    outstr += append('dl_dst')
    outstr += append('dl_vlan')
    outstr += append('dl_vlan_pcp')
    outstr += append('dl_type', safehex)
    outstr += append('nw_tos')
    outstr += append('nw_proto')
    outstr += append('nw_src')
    outstr += append('nw_dst')
    outstr += append('tp_src')
    outstr += append('tp_dst')
    return outstr


class ofp_action_generic (ofp_action_base):
  _MIN_LENGTH = 8
  def __init__ (self, **kw):
    self.type = None # Purposely bad
    self.data = _PAD4

    initHelper(self, kw)

  def pack (self):
    assert self._assert()

    packed = b""
    packed += struct.pack("!HH", self.type, len(self))
    packed += self.data
    return packed

  def unpack (self, raw, offset=0):
    _offset = offset
    offset,(self.type, length) = _unpack("!HH", raw, offset)
    offset,self.data = _read(raw, offset, length-4)
    assert offset - _offset == len(self)
    return offset

  def __len__ (self):
    return 4 + len(self.data)

  def __eq__ (self, other):
    if type(self) != type(other): return False
    if self.type != other.type: return False
    if self.data != other.data: return False
    return True

  def show (self, prefix=''):
    outstr = ''
    outstr += prefix + 'type: ' + str(self.type) + '\n'
    outstr += prefix + 'len: ' + str(len(self)) + '\n'
    return outstr


@openflow_action('OFPAT_OUTPUT', 0)
class ofp_action_output (ofp_action_base):
  def __init__ (self, **kw):
    self.port = None # Purposely bad -- require specification
    self.max_len = 0xffFF

    initHelper(self, kw)

  def pack (self):
    if self.port != OFPP_CONTROLLER:
      self.max_len = 0

    assert self._assert()

    packed = b""
    packed += struct.pack("!HHHH", self.type, len(self), self.port,
                          self.max_len)
    return packed

  def unpack (self, raw, offset=0):
    _offset = offset
    offset,(self.type, length, self.port, self.max_len) = \
        _unpack("!HHHH", raw, offset)
    assert offset - _offset == len(self)
    return offset

  @staticmethod
  def __len__ ():
    return 8

  def __eq__ (self, other):
    if type(self) != type(other): return False
    if self.type != other.type: return False
    if len(self) != len(other): return False
    if self.port != other.port: return False
    if self.max_len != other.max_len: return False
    return True

  def show (self, prefix=''):
    outstr = ''
    outstr += prefix + 'type: ' + str(self.type) + '\n'
    outstr += prefix + 'len: ' + str(len(self)) + '\n'
    outstr += prefix + 'port: ' + str(self.port) + '\n'
    outstr += prefix + 'max_len: ' + str(self.max_len) + '\n'
    return outstr


@openflow_action('OFPAT_ENQUEUE', 11)
class ofp_action_enqueue (ofp_action_base):
  def __init__ (self, **kw):
    self.port = None # Require user to set
    self.queue_id = 0

    initHelper(self, kw)

  def pack (self):
    assert self._assert()

    packed = b""
    packed += struct.pack("!HHH", self.type, len(self), self.port)
    packed += _PAD6 # Pad
    packed += struct.pack("!L", self.queue_id)
    return packed

  def unpack (self, raw, offset=0):
    _offset = offset
    offset,(self.type, length, self.port) = _unpack("!HHH", raw, offset)
    offset = _skip(raw, offset, 6)
    offset,(self.queue_id,) = _unpack("!L", raw, offset)
    assert offset - _offset == len(self)
    return offset

  @staticmethod
  def __len__ ():
    return 16

  def __eq__ (self, other):
    if type(self) != type(other): return False
    if self.type != other.type: return False
    if len(self) != len(other): return False
    if self.port != other.port: return False
    if self.queue_id != other.queue_id: return False
    return True

  def show (self, prefix=''):
    outstr = ''
    outstr += prefix + 'type: ' + str(self.type) + '\n'
    outstr += prefix + 'len: ' + str(len(self)) + '\n'
    outstr += prefix + 'port: ' + str(self.port) + '\n'
    outstr += prefix + 'queue_id: ' + str(self.queue_id) + '\n'
    return outstr


@openflow_action('OFPAT_STRIP_VLAN', 3)
class ofp_action_strip_vlan (ofp_action_base):
  def __init__ (self):
    pass

  def pack (self):
    packed = struct.pack("!HHi", self.type, len(self), 0)
    return packed

  def unpack (self, raw, offset=0):
    _offset = offset
    offset,(self.type, length) = _unpack("!HH", raw, offset)
    offset = _skip(raw, offset, 4)
    assert offset - _offset == len(self)
    return offset

  @staticmethod
  def __len__ ():
    return 8

  def __eq__ (self, other):
    if type(self) != type(other): return False
    if self.type != other.type: return False
    if len(self) != len(other): return False
    return True

  def show (self, prefix=''):
    outstr = ''
    outstr += prefix + 'type: ' + str(self.type) + '\n'
    outstr += prefix + 'len: ' + str(len(self)) + '\n'
    return outstr


@openflow_action('OFPAT_SET_VLAN_VID', 1)
class ofp_action_vlan_vid (ofp_action_base):
  def __init__ (self, **kw):
    self.vlan_vid = 0

    initHelper(self, kw)

  def pack (self):
    assert self._assert()

    packed = b""
    packed += struct.pack("!HHH", self.type, len(self), self.vlan_vid)
    packed += _PAD2 # Pad
    return packed

  def unpack (self, raw, offset=0):
    _offset = offset
    offset,(self.type, length, self.vlan_vid) = \
        _unpack("!HHH", raw, offset)
    offset = _skip(raw, offset, 2)
    #TODO: check length for this and other actions
    assert offset - _offset == len(self)
    return offset

  @staticmethod
  def __len__ ():
    return 8

  def __eq__ (self, other):
    if type(self) != type(other): return False
    if self.type != other.type: return False
    if len(self) != len(other): return False
    if self.vlan_vid != other.vlan_vid: return False
    return True

  def show (self, prefix=''):
    outstr = ''
    outstr += prefix + 'type: ' + str(self.type) + '\n'
    outstr += prefix + 'len: ' + str(len(self)) + '\n'
    outstr += prefix + 'vlan_vid: ' + str(self.vlan_vid) + '\n'
    return outstr
ofp_action_set_vlan_vid = ofp_action_vlan_vid


@openflow_action('OFPAT_SET_VLAN_PCP', 2)
class ofp_action_vlan_pcp (ofp_action_base):
  def __init__ (self, **kw):
    self.vlan_pcp = 0

    initHelper(self, kw)

  def pack (self):
    assert self._assert()

    packed = b""
    packed += struct.pack("!HHB", self.type, len(self), self.vlan_pcp)
    packed += _PAD3 # Pad
    return packed

  def unpack (self, raw, offset=0):
    _offset = offset
    offset,(self.type, length, self.vlan_pcp) = \
        _unpack("!HHB", raw, offset)
    offset = _skip(raw, offset, 3)
    assert offset - _offset == len(self)
    return offset

  @staticmethod
  def __len__ ():
    return 8

  def __eq__ (self, other):
    if type(self) != type(other): return False
    if self.type != other.type: return False
    if len(self) != len(other): return False
    if self.vlan_pcp != other.vlan_pcp: return False
    return True

  def show (self, prefix=''):
    outstr = ''
    outstr += prefix + 'type: ' + str(self.type) + '\n'
    outstr += prefix + 'len: ' + str(len(self)) + '\n'
    outstr += prefix + 'vlan_pcp: ' + str(self.vlan_pcp) + '\n'
    return outstr
ofp_action_set_vlan_pcp = ofp_action_vlan_pcp


@openflow_action('OFPAT_SET_DL_DST', 5)
@openflow_action('OFPAT_SET_DL_SRC', 4)
class ofp_action_dl_addr (ofp_action_base):
  @classmethod
  def set_dst (cls, dl_addr = None):
    return cls(OFPAT_SET_DL_DST, dl_addr)
  @classmethod
  def set_src (cls, dl_addr = None):
    return cls(OFPAT_SET_DL_SRC, dl_addr)

  def __init__ (self, type = None, dl_addr = None):
    """
    'type' should be OFPAT_SET_DL_SRC or OFPAT_SET_DL_DST.
    """
    self.type = type
    self.dl_addr = EMPTY_ETH

    if dl_addr is not None:
      self.dl_addr = EthAddr(dl_addr)

  def _validate (self):
    if (not isinstance(self.dl_addr, EthAddr)
        and not isinstance(self.dl_addr, bytes)):
      return "dl_addr is not string or EthAddr"
    if isinstance(self.dl_addr, bytes) and len(self.dl_addr) != 6:
      return "dl_addr is not of size 6"
    return None

  def pack (self):
    assert self._assert()

    packed = b""
    packed += struct.pack("!HH", self.type, len(self))
    if isinstance(self.dl_addr, EthAddr):
      packed += self.dl_addr.toRaw()
    else:
      packed += self.dl_addr
    packed += _PAD6
    return packed

  def unpack (self, raw, offset=0):
    _offset = offset
    offset,(self.type, length) = _unpack("!HH", raw, offset)
    offset,self.dl_addr = _readether(raw, offset)
    offset = _skip(raw, offset, 6)
    assert offset - _offset == len(self)
    return offset

  @staticmethod
  def __len__ ():
    return 16

  def __eq__ (self, other):
    if type(self) != type(other): return False
    if self.type != other.type: return False
    if len(self) != len(other): return False
    if self.dl_addr != other.dl_addr: return False
    return True

  def show (self, prefix=''):
    outstr = ''
    outstr += prefix + 'type: ' + str(self.type) + '\n'
    outstr += prefix + 'len: ' + str(len(self)) + '\n'
    outstr += prefix + 'dl_addr: ' + str(self.dl_addr) + '\n'
    return outstr


@openflow_action('OFPAT_SET_NW_DST', 7)
@openflow_action('OFPAT_SET_NW_SRC', 6)
class ofp_action_nw_addr (ofp_action_base):
  @classmethod
  def set_dst (cls, nw_addr = None):
    return cls(OFPAT_SET_NW_DST, nw_addr)
  @classmethod
  def set_src (cls, nw_addr = None):
    return cls(OFPAT_SET_NW_SRC, nw_addr)

  def __init__ (self, type = None, nw_addr = None):
    """
    'type' should be OFPAT_SET_NW_SRC or OFPAT_SET_NW_DST
    """
    self.type = type

    if nw_addr is not None:
      self.nw_addr = IPAddr(nw_addr)
    else:
      self.nw_addr = IPAddr(0)

  def pack (self):
    assert self._assert()

    packed = b""
    packed += struct.pack("!HHl", self.type, len(self),
                          self.nw_addr.toSigned())
    return packed

  def unpack (self, raw, offset=0):
    _offset = offset
    offset,(self.type, length) = _unpack("!HH", raw, offset)
    offset,self.nw_addr = _readip(raw, offset)
    assert offset - _offset == len(self)
    return offset

  @staticmethod
  def __len__ ():
    return 8

  def __eq__ (self, other):
    if type(self) != type(other): return False
    if self.type != other.type: return False
    if len(self) != len(other): return False
    if self.nw_addr != other.nw_addr: return False
    return True

  def show (self, prefix=''):
    outstr = ''
    outstr += prefix + 'type: ' + str(self.type) + '\n'
    outstr += prefix + 'len: ' + str(len(self)) + '\n'
    outstr += prefix + 'nw_addr: ' + str(self.nw_addr) + '\n'
    return outstr


@openflow_action('OFPAT_SET_NW_TOS', 8)
class ofp_action_nw_tos (ofp_action_base):
  def __init__ (self, nw_tos = 0):
    self.nw_tos = nw_tos

  def pack (self):
    assert self._assert()

    packed = b""
    packed += struct.pack("!HHB", self.type, len(self), self.nw_tos)
    packed += _PAD3
    return packed

  def unpack (self, raw, offset=0):
    _offset = offset
    offset,(self.type, length, self.nw_tos) = _unpack("!HHB", raw, offset)
    offset = _skip(raw, offset, 3)
    assert offset - _offset == len(self)
    return offset

  @staticmethod
  def __len__ ():
    return 8

  def __eq__ (self, other):
    if type(self) != type(other): return False
    if self.type != other.type: return False
    if len(self) != len(other): return False
    if self.nw_tos != other.nw_tos: return False
    return True

  def show (self, prefix=''):
    outstr = ''
    outstr += prefix + 'type: ' + str(self.type) + '\n'
    outstr += prefix + 'len: ' + str(len(self)) + '\n'
    outstr += prefix + 'nw_tos: ' + str(self.nw_tos) + '\n'
    return outstr


@openflow_action('OFPAT_SET_TP_DST', 10)
@openflow_action('OFPAT_SET_TP_SRC', 9)
class ofp_action_tp_port (ofp_action_base):
  @classmethod
  def set_dst (cls, tp_port = None):
    return cls(OFPAT_SET_TP_DST, tp_port)
  @classmethod
  def set_src (cls, tp_port = None):
    return cls(OFPAT_SET_TP_SRC, tp_port)

  def __init__ (self, type=None, tp_port = 0):
    """
    'type' is OFPAT_SET_TP_SRC/DST
    """
    self.type = type
    self.tp_port = tp_port

  def pack (self):
    assert self._assert()

    packed = b""
    packed += struct.pack("!HHH", self.type, len(self), self.tp_port)
    packed += _PAD2
    return packed

  def unpack (self, raw, offset=0):
    _offset = offset
    offset,(self.type, length, self.tp_port) = \
        _unpack("!HHH", raw, offset)
    offset = _skip(raw, offset, 2)
    assert offset - _offset == len(self)
    return offset

  @staticmethod
  def __len__ ():
    return 8

  def __eq__ (self, other):
    if type(self) != type(other): return False
    if self.type != other.type: return False
    if len(self) != len(other): return False
    if self.tp_port != other.tp_port: return False
    return True

  def show (self, prefix=''):
    outstr = ''
    outstr += prefix + 'type: ' + str(self.type) + '\n'
    outstr += prefix + 'len: ' + str(len(self)) + '\n'
    outstr += prefix + 'tp_port: ' + str(self.tp_port) + '\n'
    return outstr


class ofp_action_vendor_base (ofp_action_base):
  """
  Base class for vendor actions
  """
  type = 65535 # OFPAT_VENDOR

  def _eq (self, other):
    """
    Return True if equal

    Overide this.
    """
    return True

  def _init (self, kw):
    """
    Initialize fields

    Overide this.
    """
    pass

  def _pack_body (self):
    """
    Pack body.
    """
    return b""

  def _unpack_body (self, raw, offset, avail):
    """
    Unpack body in raw starting at offset.

    Return new offset
    """
    return offset

  def _body_length (self):
    """
    Return length of body.

    This should include everything after the length field.
    Optionally override this.
    """
    return len(self._pack_body())

  def _show (self, prefix):
    """
    Format additional fields as text
    """
    return ""

  def __init__ (self, **kw):
    self._init(kw)
    assert hasattr(self, 'vendor')
    #self.vendor = 0
    initHelper(self, kw)

  def _pack_body (self):
    if hasattr(self.body, 'pack'):
      return self.body.pack()
    else:
      return bytes(self.body)

  def pack (self):
    assert self._assert()

    body = self._pack_body()

    packed = b""
    packed += struct.pack("!HHL", self.type, 8 + len(body), self.vendor)
    packed += body
    assert (len(packed) % 8) == 0, "Vendor action length not multiple of 8"
    return packed

  def unpack (self, raw, offset=0):
    _offset = offset
    offset,(self.type, length, self.vendor) = _unpack("!HHL", raw, offset)
    offset = self._unpack_body(raw, offset, length - 8)
    assert offset - _offset == len(self)
    return offset

  def __len__ (self):
    return 8 + self._body_length()

  def __eq__ (self, other):
    if type(self) != type(other): return False
    if self.type != other.type: return False
    if len(self) != len(other): return False
    if self.vendor != other.vendor: return False
    return self._eq(other)

  def show (self, prefix=''):
    outstr = ''
    outstr += prefix + 'type: ' + str(self.type) + '\n'
    outstr += prefix + 'len: ' + str(len(self)) + '\n'
    outstr += prefix + 'vendor: ' + str(self.vendor) + '\n'
    outstr += self._show(prefix)
    return outstr


@openflow_action('OFPAT_VENDOR', 65535)
class ofp_action_vendor_generic (ofp_action_base):
  def __init__ (self, **kw):
    self.vendor = 0
    self.body = b""

    initHelper(self, kw)

  def _pack_body (self):
    if hasattr(self.body, 'pack'):
      return self.body.pack()
    else:
      return bytes(self.body)

  def pack (self):
    assert self._assert()

    body = self._pack_body()

    packed = b""
    packed += struct.pack("!HHL", self.type, 8 + len(body), self.vendor)
    packed += body
    return packed

  def unpack (self, raw, offset=0):
    _offset = offset
    offset,(self.type, length, self.vendor) = _unpack("!HHL", raw, offset)
    offset,self.body = _read(raw, offset, length - 8)
    assert offset - _offset == len(self)
    return offset

  def __len__ (self):
    return 8 + len(self._pack_body())

  def __eq__ (self, other):
    if type(self) != type(other): return False
    if self.type != other.type: return False
    if len(self) != len(other): return False
    if self.vendor != other.vendor: return False
    return True

  def show (self, prefix=''):
    outstr = ''
    outstr += prefix + 'type: ' + str(self.type) + '\n'
    outstr += prefix + 'len: ' + str(len(self)) + '\n'
    outstr += prefix + 'vendor: ' + str(self.vendor) + '\n'
    return outstr


#3. Controller-to-Switch Messages

##3.1 Handshake
@openflow_s_message("OFPT_FEATURES_REPLY", 6,
    reply_to="ofp_features_request")
class ofp_features_reply (ofp_header):
  _MIN_LENGTH = 32
  def __init__ (self, **kw):
    ofp_header.__init__(self)
    self.datapath_id = 0
    self.n_buffers = 0
    self.n_tables = 0
    self.capabilities = 0
    self.actions = 0
    self.ports = []

    initHelper(self, kw)

  def pack (self):
    assert self._assert()

    packed = b""
    packed += ofp_header.pack(self)
    packed += struct.pack("!QLB", self.datapath_id, self.n_buffers,
                          self.n_tables)
    packed += _PAD3
    packed += struct.pack("!LL", self.capabilities, self.actions)
    for i in self.ports:
      packed += i.pack()
    return packed

  def unpack (self, raw, offset=0):
    offset,length = self._unpack_header(raw, offset)
    offset,(self.datapath_id, self.n_buffers, self.n_tables) = \
        _unpack("!QLB", raw, offset)
    offset = _skip(raw, offset, 3)
    offset,(self.capabilities, self.actions) = _unpack("!LL", raw, offset)
    portCount = (length - 32) / len(ofp_phy_port)
    self.ports = []
    for i in xrange(0, portCount):
      p = ofp_phy_port()
      offset = p.unpack(raw, offset)
      self.ports.append(p)
    assert length == len(self)
    return offset,length

  def __len__ (self):
    return 32 + len(self.ports) * len(ofp_phy_port)

  def __eq__ (self, other):
    if type(self) != type(other): return False
    if not ofp_header.__eq__(self, other): return False
    if self.datapath_id != other.datapath_id: return False
    if self.n_buffers != other.n_buffers: return False
    if self.n_tables != other.n_tables: return False
    if self.capabilities != other.capabilities: return False
    if self.actions != other.actions: return False
    if self.ports != other.ports: return False
    return True

  def show (self, prefix=''):
    outstr = ''
    outstr += prefix + 'header: \n'
    outstr += ofp_header.show(self, prefix + '  ')
    outstr += prefix + 'datapath_id: ' + str(self.datapath_id) + '\n'
    outstr += prefix + 'n_buffers: ' + str(self.n_buffers) + '\n'
    outstr += prefix + 'n_tables: ' + str(self.n_tables) + '\n'
    outstr += prefix + 'capabilities: ' + str(self.capabilities) + '\n'
    outstr += prefix + 'actions: ' + str(self.actions) + '\n'
    outstr += prefix + 'ports: \n'
    for obj in self.ports:
      outstr += obj.show(prefix + '  ')
    return outstr
ofp_switch_features = ofp_features_reply


##3.2 Switch Configuration
@openflow_c_message("OFPT_SET_CONFIG", 9)
class ofp_set_config (ofp_header): # uses ofp_switch_config
  def __init__ (self, **kw):
    ofp_header.__init__(self)
    self.flags = 0
    self.miss_send_len = OFP_DEFAULT_MISS_SEND_LEN

    initHelper(self, kw)

  def pack (self):
    assert self._assert()

    packed = b""
    packed += ofp_header.pack(self)
    packed += struct.pack("!HH", self.flags, self.miss_send_len)
    return packed

  def unpack (self, raw, offset=0):
    offset,length = self._unpack_header(raw, offset)
    offset,(self.flags, self.miss_send_len) = _unpack("!HH", raw, offset)
    assert length == len(self)
    return offset,length

  @staticmethod
  def __len__ ():
    return 12

  def __eq__ (self, other):
    if type(self) != type(other): return False
    if not ofp_header.__eq__(self, other): return False
    if self.flags != other.flags: return False
    if self.miss_send_len != other.miss_send_len: return False
    return True

  def show (self, prefix=''):
    outstr = ''
    outstr += prefix + 'header: \n'
    outstr += ofp_header.show(self, prefix + '  ')
    outstr += prefix + 'flags: ' + str(self.flags) + '\n'
    outstr += prefix + 'miss_send_len: ' + str(self.miss_send_len) + '\n'
    return outstr


##3.3 Modify State Messages
@openflow_c_message("OFPT_FLOW_MOD", 14)
class ofp_flow_mod (ofp_header):
  _MIN_LENGTH = 72
  def __init__ (self, **kw):
    ofp_header.__init__(self)
    if 'match' in kw:
      self.match = None
    else:
      self.match = ofp_match()
    self.cookie = 0
    self.command = OFPFC_ADD
    self.idle_timeout = 0
    self.hard_timeout = 0
    self.priority = OFP_DEFAULT_PRIORITY
    self._buffer_id = NO_BUFFER
    self.out_port = OFPP_NONE
    self.flags = 0
    self.actions = []
    self.data = None # Not in the spec!  Special magic!  Can be packet_in.

    # ofp_flow_mod/ofp_packet_out do some special handling of 'actions'...

    # Allow "action" as a synonym for "actions"
    if 'action' in kw and 'actions' not in kw:
      kw['actions'] = kw['action']
      del kw['action']

    initHelper(self, kw)

    # Allow use of actions=<a single action> for kw args.
    if not hasattr(self.actions, '__getitem__'):
      self.actions = [self.actions]

  @property
  def buffer_id (self):
    if self._buffer_id == NO_BUFFER: return None
    return self._buffer_id
  @buffer_id.setter
  def buffer_id (self, val):
    if val is None: val = NO_BUFFER
    self._buffer_id = val

  def _validate (self):
    if not isinstance(self.match, ofp_match):
      return "match is not class ofp_match"
    return None

  def pack (self):
    """
    Packs this object into its wire format.
    May normalize fields.
    NOTE: If "data" has been specified, this method may actually return
          *more than just a single ofp_flow_mod* in packed form.
          Specifically, it may also have a barrier and an ofp_packet_out.
    """
    po = None
    buffer_id = self.buffer_id
    if self.data:
      if not self.data.is_complete:
        _log(warn="flow_mod is trying to include incomplete data")
      else:
        self.buffer_id = self.data.buffer_id # Hacky
        if self.buffer_id is None:
          po = ofp_packet_out(data=self.data)
          po.in_port = self.data.in_port
          po.actions.append(ofp_action_output(port = OFPP_TABLE))
          #FIXME: Should maybe check that packet hits the new entry...
          #       Or just duplicate the actions? (I think that's the best idea)
        buffer_id = self.buffer_id
        self.buffer_id = None
    if buffer_id is None:
      buffer_id = NO_BUFFER

    assert self._assert()
    packed = b""
    packed += ofp_header.pack(self)
    packed += self.match.pack(flow_mod=True)
    packed += struct.pack("!QHHHHLHH", self.cookie, self.command,
                          self.idle_timeout, self.hard_timeout,
                          self.priority, buffer_id, self.out_port,
                          self.flags)
    for i in self.actions:
      packed += i.pack()

    if po:
      packed += ofp_barrier_request().pack()
      packed += po.pack()
    return packed

  def unpack (self, raw, offset=0):
    offset,length = self._unpack_header(raw, offset)
    offset = self.match.unpack(raw, offset, flow_mod=True)
    offset,(self.cookie, self.command, self.idle_timeout,
            self.hard_timeout, self.priority, self._buffer_id,
            self.out_port, self.flags) = \
            _unpack("!QHHHHLHH", raw, offset)
    offset,self.actions = _unpack_actions(raw,
        length-(32 + len(self.match)), offset)
    assert length == len(self)
    return offset,length

  def __len__ (self):
    l = 32 + len(self.match)
    for i in self.actions:
      l += len(i)
    return l

  def __eq__ (self, other):
    if type(self) != type(other): return False
    if not ofp_header.__eq__(self, other): return False
    if self.match != other.match: return False
    if self.cookie != other.cookie: return False
    if self.command != other.command: return False
    if self.idle_timeout != other.idle_timeout: return False
    if self.hard_timeout != other.hard_timeout: return False
    if self.priority != other.priority: return False
    if self.buffer_id != other.buffer_id: return False
    if self.out_port != other.out_port: return False
    if self.flags != other.flags: return False
    if self.actions != other.actions: return False
    if self.data != other.data: return False
    return True

  def show (self, prefix=''):
    outstr = ''
    outstr += prefix + 'header: \n'
    outstr += ofp_header.show(self, prefix + '  ')
    outstr += prefix + 'match: \n'
    outstr += self.match.show(prefix + '  ')
    outstr += prefix + 'cookie: ' + str(self.cookie) + '\n'
    outstr += prefix + 'command: ' + str(self.command) + '\n'
    outstr += prefix + 'idle_timeout: ' + str(self.idle_timeout) + '\n'
    outstr += prefix + 'hard_timeout: ' + str(self.hard_timeout) + '\n'
    outstr += prefix + 'priority: ' + str(self.priority) + '\n'
    outstr += prefix + 'buffer_id: ' + str(self.buffer_id) + '\n'
    outstr += prefix + 'out_port: ' + str(self.out_port) + '\n'
    outstr += prefix + 'flags: ' + str(self.flags) + '\n'
    outstr += prefix + 'actions: \n'
    for obj in self.actions:
      outstr += obj.show(prefix + '  ')
    return outstr


@openflow_c_message("OFPT_PORT_MOD", 15)
class ofp_port_mod (ofp_header):
  def __init__ (self, **kw):
    ofp_header.__init__(self)
    self.port_no = 0
    self.hw_addr = EMPTY_ETH
    self.config = 0
    self.mask = 0
    self.advertise = 0

    initHelper(self, kw)

  def _validate (self):
    if (not isinstance(self.hw_addr, bytes)
        and not isinstance(self.hw_addr, EthAddr)):
      return "hw_addr is not bytes or EthAddr"
    if len(self.hw_addr) != 6:
      return "hw_addr is not of size 6"
    return None

  def pack (self):
    assert self._assert()

    packed = b""
    packed += ofp_header.pack(self)
    packed += struct.pack("!H", self.port_no)
    if isinstance(self.hw_addr, bytes):
      packed += self.hw_addr
    else:
      packed += self.hw_addr.toRaw()
    packed += struct.pack("!LLL", self.config, self.mask, self.advertise)
    packed += _PAD4
    return packed

  def unpack (self, raw, offset=0):
    offset,length = self._unpack_header(raw, offset)
    offset,(self.port_no,) = _unpack("!H", raw, offset)
    offset,self.hw_addr = _readether(raw, offset)
    offset,(self.config, self.mask, self.advertise) = \
        _unpack("!LLL", raw, offset)
    offset = _skip(raw, offset, 4)
    assert length == len(self)
    return offset,length

  @staticmethod
  def __len__ ():
    return 32

  def __eq__ (self, other):
    if type(self) != type(other): return False
    if not ofp_header.__eq__(self, other): return False
    if self.port_no != other.port_no: return False
    if self.hw_addr != other.hw_addr: return False
    if self.config != other.config: return False
    if self.mask != other.mask: return False
    if self.advertise != other.advertise: return False
    return True

  def show (self, prefix=''):
    outstr = ''
    outstr += prefix + 'header: \n'
    outstr += ofp_header.show(self, prefix + '  ')
    outstr += prefix + 'port_no: ' + str(self.port_no) + '\n'
    outstr += prefix + 'hw_addr: ' + str(EthAddr(self.hw_addr)) + '\n'
    outstr += prefix + 'config: ' + str(self.config) + '\n'
    outstr += prefix + 'mask: ' + str(self.mask) + '\n'
    outstr += prefix + 'advertise: ' + str(self.advertise) + '\n'
    return outstr


##3.4 Queue Configuration Messages
@openflow_c_message("OFPT_QUEUE_GET_CONFIG_REQUEST", 20)
class ofp_queue_get_config_request (ofp_header):
  def __init__ (self, **kw):
    ofp_header.__init__(self)
    self.port = 0
    initHelper(self, kw)

  def pack (self):
    assert self._assert()

    packed = b""
    packed += ofp_header.pack(self)
    packed += struct.pack("!H", self.port)
    packed += _PAD2
    return packed

  def unpack (self, raw, offset=0):
    offset,length = self._unpack_header(raw, offset)
    offset,(self.port,) = _unpack("!H", raw, offset)
    offset = _skip(raw, offset, 2)
    assert length == len(self)
    return offset,length

  @staticmethod
  def __len__ ():
    return 12

  def __eq__ (self, other):
    if type(self) != type(other): return False
    if not ofp_header.__eq__(self, other): return False
    if self.port != other.port: return False
    return True

  def show (self, prefix=''):
    outstr = ''
    outstr += prefix + 'header: \n'
    outstr += ofp_header.show(self, prefix + '  ')
    outstr += prefix + 'port: ' + str(self.port) + '\n'
    return outstr


@openflow_s_message("OFPT_QUEUE_GET_CONFIG_REPLY", 21)
class ofp_queue_get_config_reply (ofp_header):
  _MIN_LENGTH = 16
  def __init__ (self, **kw):
    ofp_header.__init__(self)
    self.port = 0
    self.queues = []

    initHelper(self, kw)

  def pack (self):
    assert self._assert()

    packed = b""
    packed += ofp_header.pack(self)
    packed += struct.pack("!H", self.port)
    packed += _PAD6
    for i in self.queues:
      packed += i.pack()
    return packed

  def unpack (self, raw, offset=0):
    offset,length = self._unpack_header(raw, offset)
    offset,(self.port,) = _unpack("!H", raw, offset)
    offset = _skip(raw, offset, 6)
    remaining = length - 6 - 2 - len(ofp_header)

    del self.queues[:]

    # Not tested; probably buggy
    while remaining > 0:
      q = ofp_packet_queue()
      _offset = q.unpack(raw, offset)
      l = _offset - offset
      offset = _offset
      if l < 1: raise RuntimeError("Can't parse")
      remaining -= l
      self.queues.append(q)

    assert length == len(self)
    return offset,length

  def __len__ (self):
    l = 16
    for i in self.queues:
      l += len(i)
    return l

  def __eq__ (self, other):
    if type(self) != type(other): return False
    if not ofp_header.__eq__(self, other): return False
    if self.port != other.port: return False
    if self.queues != other.queues: return False
    return True

  def show (self, prefix=''):
    outstr = ''
    outstr += prefix + 'header: \n'
    outstr += ofp_header.show(self, prefix + '  ')
    outstr += prefix + 'port: ' + str(self.port) + '\n'
    outstr += prefix + 'queues: \n'
    for obj in self.queues:
      outstr += obj.show(prefix + '  ')
    return outstr


@openflow_c_message("OFPT_STATS_REQUEST", 16)
class ofp_stats_request (ofp_header):
  _MIN_LENGTH = 12
  def __init__ (self, **kw):
    ofp_header.__init__(self)
    self.type = None # Try to guess
    self.flags = 0
    self._body = b''
    self._body_packed = None # Cache

    initHelper(self, kw)

  def pack (self):
    if self.type is None:
      if isinstance(self.body, ofp_stats_body_base):
        self.type = self.body._type
      else:
        raise RuntimeError("Can't determine body type; specify it "
                           + "explicitly")

    assert self._assert()

    packed = b""
    packed += ofp_header.pack(self)
    packed += struct.pack("!HH", self.type, self.flags)
    packed += self._pack_body()
    return packed

  def _pack_body (self):
    if self._body_packed is None:
      if hasattr(self.body, 'pack'):
        self._body_packed = self._body.pack()
      else:
        self._body_packed = self._body
    return self._body_packed

  @property
  def body (self):
    return self._body
  @body.setter
  def body (self, data):
    self._body = data
    self._body_packed_cache = None

  def unpack (self, raw, offset=0):
    offset,length = self._unpack_header(raw, offset)
    offset,(self.type, self.flags) = _unpack("!HH", raw, offset)
    offset,body = _read(raw, offset, length - 12)
    si = _stats_type_to_class_info.get(self.type)
    if si is None:
      self.body = ofp_generic_stats_body()
      self.body.unpack(body, 0, len(body))
    else:
      if si.request is None:
        raise RuntimeError("No request for " + str(si))
      self.body = si.request()
      self.body.unpack(body, 0, len(body))
      #TODO: assert entire body is unpacked

    assert length == len(self)
    return offset,length

  def __len__ (self):
    return 12 + len(self._pack_body())

  def __eq__ (self, other):
    if type(self) != type(other): return False
    if not ofp_header.__eq__(self, other): return False
    if self.type != other.type: return False
    if self.flags != other.flags: return False
    if self._pack_body() != other._pack_body(): return False
    return True

  def show (self, prefix=''):
    outstr = ''
    outstr += prefix + 'header: \n'
    outstr += ofp_header.show(self, prefix + '  ')
    outstr += prefix + 'type: ' + str(self.type) + '\n'
    outstr += prefix + 'flags: ' + str(self.flags) + '\n'
    outstr += prefix + 'body:\n'
    outstr += _format_body(self.body, prefix + '  ') + '\n'
    return outstr


@openflow_s_message("OFPT_STATS_REPLY", 17,
    reply_to="ofp_stats_request")
class ofp_stats_reply (ofp_header):
  _MIN_LENGTH = 12
  def __init__ (self, **kw):
    ofp_header.__init__(self)
    self.type = None # Guess
    self.flags = 0
    self.body = b''
    self._body_data = (None, None)

    initHelper(self, kw)

  @property
  def is_last_reply (self):
    return (self.flags & 1) == 0
  @is_last_reply.setter
  def is_last_reply (self, value):
    self.flags = self.flags & 0xfffe
    if not value:
      self.flags |= 1

  @property
  def body_data (self):
    if self._body_data[0] is not self.body:
      def _pack(b):
        return b.pack() if hasattr(b, 'pack') else b

      data = b''
      if is_listlike(self.body):
        for b in self.body:
          data += _pack(b)
      else:
        data = _pack(self.body)
      self._body_data = (self.body, data)
    return self._body_data[1]

  def pack (self):
    if self.type is None:
      if is_listlike(self.body):
        if len(self.body):
          b = self.body[0]
        else:
          b = None # Will fail below
      else:
        b = self.body
      if isinstance(b, ofp_stats_body_base):
        self.type = b._type
      else:
        raise RuntimeError("Can't determine body type; specify it "
                           + "explicitly")

    assert self._assert()

    packed = b""
    packed += ofp_header.pack(self)
    packed += struct.pack("!HH", self.type, self.flags)
    packed += self.body_data
    return packed

  def unpack (self, raw, offset=0):
    offset,length = self._unpack_header(raw, offset)
    offset,(self.type, self.flags) = _unpack("!HH", raw, offset)
    offset,packed = _read(raw, offset, length - 12)
    t = _stats_type_to_class_info.get(self.type)
    if t is None:
      #FIXME: Put in a generic container?
      self.body = packed
    else:
      if t.reply is None:
        #FIXME: Put in a generic container?
        self.body = packed
      else:
        if not t.reply_is_list:
          self.body = t.reply()
          self.body.unpack(packed, 0, len(packed))
        else:
          prev_len = len(packed)
          self.body = []
          while len(packed):
            part = t.reply()
            off = part.unpack(packed, 0, len(packed))
            packed = packed[off:]
            assert len(packed) != prev_len
            prev_len = len(packed)
            self.body.append(part)

    assert length == len(self)
    return offset,length

  def __len__ (self):
    if isinstance(self.body, list):
      return 12 + sum(len(part) for part in self.body)
    return 12 + len(self.body)

  def __eq__ (self, other):
    if type(self) != type(other): return False
    if not ofp_header.__eq__(self, other): return False
    if self.type != other.type: return False
    if self.flags != other.flags: return False
    if self.body != other.body: return False
    return True

  def show (self, prefix=''):
    outstr = ''
    outstr += prefix + 'header: \n'
    outstr += ofp_header.show(self, prefix + '  ')
    outstr += prefix + 'type: ' + str(self.type) + '\n'
    outstr += prefix + 'flags: ' + str(self.flags) + '\n'
    outstr += prefix + 'body:\n'
    body = self.body
    if not is_listlike(body):
      body = [body]
    for b in body:
      outstr += _format_body(b, prefix + '  ') + '\n'
    return outstr


@openflow_stats_reply("OFPST_DESC", 0)
class ofp_desc_stats (ofp_stats_body_base):
  def __init__ (self, **kw):
    self.mfr_desc   = ""
    self.hw_desc    = ""
    self.sw_desc    = ""
    self.serial_num = ""
    self.dp_desc    = ""

    initHelper(self, kw)

  def _validate (self):
    if not isinstance(self.mfr_desc, str):
      return "mfr_desc is not string"
    if len(self.mfr_desc) > DESC_STR_LEN:
      return "mfr_desc is not of size 256"
    if not isinstance(self.hw_desc, str):
      return "hw_desc is not string"
    if len(self.hw_desc) > DESC_STR_LEN:
      return "hw_desc is not of size 256"
    if not isinstance(self.sw_desc, str):
      return "sw_desc is not string"
    if len(self.sw_desc) > DESC_STR_LEN:
      return "sw_desc is not of size 256"
    if not isinstance(self.serial_num, str):
      return "serial_num is not string"
    if len(self.serial_num) > SERIAL_NUM_LEN:
      return "serial_num is not of size 32"
    if not isinstance(self.dp_desc, str):
      return "dp_desc is not string"
    if len(self.dp_desc) > DESC_STR_LEN:
      return "dp_desc is not of size 256"
    return None

  def pack (self):
    assert self._assert()

    packed = b""
    packed += self.mfr_desc.ljust(DESC_STR_LEN,'\0')
    packed += self.hw_desc.ljust(DESC_STR_LEN,'\0')
    packed += self.sw_desc.ljust(DESC_STR_LEN,'\0')
    packed += self.serial_num.ljust(SERIAL_NUM_LEN,'\0')
    packed += self.dp_desc.ljust(DESC_STR_LEN,'\0')
    return packed

  def unpack (self, raw, offset, avail):
    _offset = offset
    offset,self.mfr_desc   = _readzs(raw, offset, DESC_STR_LEN)
    offset,self.hw_desc    = _readzs(raw, offset, DESC_STR_LEN)
    offset,self.sw_desc    = _readzs(raw, offset, DESC_STR_LEN)
    offset,self.serial_num = _readzs(raw, offset, SERIAL_NUM_LEN)
    offset,self.dp_desc    = _readzs(raw, offset, DESC_STR_LEN)
    assert offset - _offset == len(self)
    return offset

  @staticmethod
  def __len__ ():
    return 1056

  def __eq__ (self, other):
    if type(self) != type(other): return False
    if self.mfr_desc != other.mfr_desc: return False
    if self.hw_desc != other.hw_desc: return False
    if self.sw_desc != other.sw_desc: return False
    if self.serial_num != other.serial_num: return False
    if self.dp_desc != other.dp_desc: return False
    return True

  def show (self, prefix=''):
    outstr = ''
    outstr += prefix + 'mfr_desc: ' + str(self.mfr_desc) + '\n'
    outstr += prefix + 'hw_desc: ' + str(self.hw_desc) + '\n'
    outstr += prefix + 'sw_desc: ' + str(self.sw_desc) + '\n'
    outstr += prefix + 'serial_num: ' + str(self.serial_num) + '\n'
    outstr += prefix + 'dp_desc: ' + str(self.dp_desc) + '\n'
    return outstr

ofp_desc_stats_reply = ofp_desc_stats


class _empty_stats_request_body (ofp_stats_body_base):
  """
  Superclass for table stats requests with empty bodies

  OFPST_DESC and OFPST_TABLE have empty request bodies.  In order
  to make type guessing and unpacking consistent, we define
  classes for them anyway.
  """
  def __init__ (self, **kw):
    pass

  def pack (self):
    return b""

  def unpack (self, raw, offset, avail):
    if avail != 0:
      raise RuntimeError("Expected empty body")
    return offset

  @staticmethod
  def __len__ ():
    return 0

  def __eq__ (self, other):
    if type(self) != type(other): return False
    return True

  def show (self, prefix=''):
    return "<empty>"

@openflow_stats_request('OFPST_DESC', 0)
class ofp_desc_stats_request (_empty_stats_request_body):
  """
  See _empty_stats_request_body superclass documentation
  """
  pass

@openflow_stats_request('OFPST_TABLE', 3)
class ofp_table_stats_request (_empty_stats_request_body):
  """
  See _empty_stats_request_body superclass documentation
  """
  pass


@openflow_stats_request('OFPST_FLOW', 1)
class ofp_flow_stats_request (ofp_stats_body_base):
  def __init__ (self, **kw):
    self.match = ofp_match()
    self.table_id = TABLE_ALL
    self.out_port = OFPP_NONE
    initHelper(self, kw)

  def _validate (self):
    if not isinstance(self.match, ofp_match):
      return "match is not class ofp_match"
    return None

  def pack (self):
    assert self._assert()

    packed = b""
    packed += self.match.pack()
    packed += struct.pack("!BBH", self.table_id, 0, self.out_port)
    return packed

  def unpack (self, raw, offset, avail):
    _offset = offset
    offset = self.match.unpack(raw, offset)
    offset,(self.table_id, pad, self.out_port) = \
        _unpack("!BBH", raw, offset)
    assert pad == 0
    assert offset - _offset == len(self)
    return offset

  @staticmethod
  def __len__ ():
    return 4 + len(ofp_match)

  def __eq__ (self, other):
    if type(self) != type(other): return False
    if self.match != other.match: return False
    if self.table_id != other.table_id: return False
    if self.out_port != other.out_port: return False
    return True

  def show (self, prefix=''):
    outstr = ''
    outstr += prefix + 'match: \n'
    outstr += self.match.show(prefix + '  ')
    outstr += prefix + 'table_id: ' + str(self.table_id) + '\n'
    outstr += prefix + 'out_port: ' + str(self.out_port) + '\n'
    return outstr


@openflow_stats_reply('OFPST_FLOW', is_list = True)
class ofp_flow_stats (ofp_stats_body_base):
  _MIN_LENGTH = 88
  def __init__ (self, **kw):
    self.table_id = 0
    self.match = ofp_match()
    self.duration_sec = 0
    self.duration_nsec = 0
    self.priority = OFP_DEFAULT_PRIORITY
    self.idle_timeout = 0
    self.hard_timeout = 0
    self.cookie = 0
    self.packet_count = 0
    self.byte_count = 0
    self.actions = []

    initHelper(self, kw)

  def _validate (self):
    if not isinstance(self.match, ofp_match):
      return "match is not class ofp_match"
    return None

  def pack (self):
    assert self._assert()

    packed = b""
    packed += struct.pack("!HBB", len(self), self.table_id, 0)
    packed += self.match.pack()
    packed += struct.pack("!LLHHH", self.duration_sec,
                          self.duration_nsec, self.priority,
                          self.idle_timeout, self.hard_timeout)
    packed += _PAD6 # Pad
    packed += struct.pack("!QQQ", self.cookie, self.packet_count,
                          self.byte_count)
    for i in self.actions:
      packed += i.pack()
    return packed

  def unpack (self, raw, offset, avail):
    _offset = offset
    offset,(length, self.table_id, pad) = _unpack("!HBB", raw, offset)
    assert pad == 0
    offset = self.match.unpack(raw, offset)
    offset,(self.duration_sec, self.duration_nsec, self.priority,
            self.idle_timeout, self.hard_timeout) = \
            _unpack("!LLHHH", raw, offset)
    offset = _skip(raw, offset, 6)
    offset,(self.cookie, self.packet_count, self.byte_count) = \
        _unpack("!QQQ", raw, offset)
    assert (offset - _offset) == 48 + len(self.match)
    offset,self.actions = _unpack_actions(raw,
        length - (48 + len(self.match)), offset)
    assert offset - _offset == len(self)
    return offset

  def __len__ (self):
    l = 48 + len(self.match)
    for i in self.actions:
      l += len(i)
    return l

  def __eq__ (self, other):
    if type(self) != type(other): return False
    if len(self) != len(other): return False
    if self.table_id != other.table_id: return False
    if self.match != other.match: return False
    if self.duration_sec != other.duration_sec: return False
    if self.duration_nsec != other.duration_nsec: return False
    if self.priority != other.priority: return False
    if self.idle_timeout != other.idle_timeout: return False
    if self.hard_timeout != other.hard_timeout: return False
    if self.cookie != other.cookie: return False
    if self.packet_count != other.packet_count: return False
    if self.byte_count != other.byte_count: return False
    if self.actions != other.actions: return False
    return True

  def show (self, prefix=''):
    outstr = ''
    outstr += prefix + 'length: ' + str(len(self)) + '\n'
    outstr += prefix + 'table_id: ' + str(self.table_id) + '\n'
    outstr += prefix + 'match: \n'
    outstr += self.match.show(prefix + '  ')
    outstr += prefix + 'duration_sec: ' + str(self.duration_sec) + '\n'
    outstr += prefix + 'duration_nsec: ' + str(self.duration_nsec) + '\n'
    outstr += prefix + 'priority: ' + str(self.priority) + '\n'
    outstr += prefix + 'idle_timeout: ' + str(self.idle_timeout) + '\n'
    outstr += prefix + 'hard_timeout: ' + str(self.hard_timeout) + '\n'
    outstr += prefix + 'cookie: ' + str(self.cookie) + '\n'
    outstr += prefix + 'packet_count: ' + str(self.packet_count) + '\n'
    outstr += prefix + 'byte_count: ' + str(self.byte_count) + '\n'
    outstr += prefix + 'actions: \n'
    for obj in self.actions:
      outstr += obj.show(prefix + '  ')
    return outstr
ofp_flow_stats_reply = ofp_flow_stats


@openflow_stats_request('OFPST_AGGREGATE', 2)
class ofp_aggregate_stats_request (ofp_stats_body_base):
  def __init__ (self, **kw):
    self.match = ofp_match()
    self.table_id = TABLE_ALL
    self.out_port = OFPP_NONE

    initHelper(self, kw)

  def _validate (self):
    if not isinstance(self.match, ofp_match):
      return "match is not class ofp_match"
    return None

  def pack (self):
    assert self._assert()

    packed = b""
    packed += self.match.pack()
    packed += struct.pack("!BBH", self.table_id, 0, self.out_port)
    return packed

  def unpack (self, raw, offset, avail):
    _offset = offset
    offset = self.match.unpack(raw, offset)
    offset,(self.table_id, pad, self.out_port) = \
        _unpack("!BBH", raw, offset)
    assert pad == 0
    assert offset - _offset == len(self)
    return offset

  @staticmethod
  def __len__ ():
    return 44

  def __eq__ (self, other):
    if type(self) != type(other): return False
    if self.match != other.match: return False
    if self.table_id != other.table_id: return False
    if self.out_port != other.out_port: return False
    return True

  def show (self, prefix=''):
    outstr = ''
    outstr += prefix + 'match: \n'
    outstr += self.match.show(prefix + '  ')
    outstr += prefix + 'table_id: ' + str(self.table_id) + '\n'
    outstr += prefix + 'out_port: ' + str(self.out_port) + '\n'
    return outstr


@openflow_stats_reply('OFPST_AGGREGATE')
class ofp_aggregate_stats (ofp_stats_body_base):
  def __init__ (self, **kw):
    self.packet_count = 0
    self.byte_count = 0
    self.flow_count = 0

    initHelper(self, kw)

  def pack (self):
    assert self._assert()

    packed = b""
    packed += struct.pack("!QQL", self.packet_count, self.byte_count,
                          self.flow_count)
    packed += _PAD4 # Pad
    return packed

  def unpack (self, raw, offset, avail):
    _offset = offset
    offset,(self.packet_count, self.byte_count, self.flow_count) = \
        _unpack("!QQL", raw, offset)
    offset = _skip(raw, offset, 4)
    assert offset - _offset == len(self)
    return offset

  @staticmethod
  def __len__ ():
    return 24

  def __eq__ (self, other):
    if type(self) != type(other): return False
    if self.packet_count != other.packet_count: return False
    if self.byte_count != other.byte_count: return False
    if self.flow_count != other.flow_count: return False
    return True

  def show (self, prefix=''):
    outstr = ''
    outstr += prefix + 'packet_count: ' + str(self.packet_count) + '\n'
    outstr += prefix + 'byte_count: ' + str(self.byte_count) + '\n'
    outstr += prefix + 'flow_count: ' + str(self.flow_count) + '\n'
    return outstr
ofp_aggregate_stats_reply = ofp_aggregate_stats


@openflow_stats_reply('OFPST_TABLE', 3, is_list = True)
class ofp_table_stats (ofp_stats_body_base):
  def __init__ (self, **kw):
    self.table_id = 0
    self.name = ""
    self.wildcards = 0
    self.max_entries = 0
    self.active_count = 0
    self.lookup_count = 0
    self.matched_count = 0

    initHelper(self, kw)

  def _validate (self):
    if not isinstance(self.name, str):
      return "name is not string"
    if len(self.name) > OFP_MAX_TABLE_NAME_LEN:
      return "name is too long"
    return None

  def pack (self):
    assert self._assert()

    packed = b""
    packed += struct.pack("!B", self.table_id)
    packed += _PAD3
    packed += self.name.ljust(OFP_MAX_TABLE_NAME_LEN,'\0')
    packed += struct.pack("!LLLQQ", self.wildcards, self.max_entries,
                          self.active_count, self.lookup_count,
                          self.matched_count)
    return packed

  def unpack (self, raw, offset, avail):
    _offset = offset
    offset,(self.table_id,) = _unpack("!B", raw, offset)
    offset = _skip(raw, offset, 3)
    offset,self.name = _readzs(raw, offset, OFP_MAX_TABLE_NAME_LEN)
    offset,(self.wildcards, self.max_entries, self.active_count,
            self.lookup_count, self.matched_count) = \
            _unpack("!LLLQQ", raw, offset)
    assert offset - _offset == len(self)
    return offset

  @staticmethod
  def __len__ ():
    return 64

  def __eq__ (self, other):
    if type(self) != type(other): return False
    if self.table_id != other.table_id: return False
    if self.name != other.name: return False
    if self.wildcards != other.wildcards: return False
    if self.max_entries != other.max_entries: return False
    if self.active_count != other.active_count: return False
    if self.lookup_count != other.lookup_count: return False
    if self.matched_count != other.matched_count: return False
    return True

  def show (self, prefix=''):
    outstr = ''
    outstr += prefix + 'table_id: ' + str(self.table_id) + '\n'
    outstr += prefix + 'name: ' + str(self.name) + '\n'
    outstr += prefix + 'wildcards: ' + str(self.wildcards) + '\n'
    outstr += prefix + 'max_entries: ' + str(self.max_entries) + '\n'
    outstr += prefix + 'active_count: ' + str(self.active_count) + '\n'
    outstr += prefix + 'lookup_count: ' + str(self.lookup_count) + '\n'
    outstr += prefix + 'matched_count: ' + str(self.matched_count) + '\n'
    return outstr
ofp_table_stats_reply = ofp_table_stats


@openflow_stats_request("OFPST_PORT", 4)
class ofp_port_stats_request (ofp_stats_body_base):
  def __init__ (self, **kw):
    self.port_no = OFPP_NONE
    initHelper(self, kw)

  def pack (self):
    assert self._assert()

    packed = b""
    packed += struct.pack("!H", self.port_no)
    packed += _PAD6
    return packed

  def unpack (self, raw, offset, avail):
    _offset = offset
    offset,(self.port_no,) = _unpack("!H", raw, offset)
    offset = _skip(raw, offset, 6)
    assert offset - _offset == len(self)
    return offset

  @staticmethod
  def __len__ ():
    return 8

  def __eq__ (self, other):
    if type(self) != type(other): return False
    if self.port_no != other.port_no: return False
    return True

  def show (self, prefix=''):
    outstr = ''
    outstr += prefix + 'port_no: ' + str(self.port_no) + '\n'
    return outstr


@openflow_stats_reply("OFPST_PORT", is_list = True)
class ofp_port_stats (ofp_stats_body_base):
  def __init__ (self, **kw):
    self.port_no = OFPP_NONE
    self.rx_packets = 0
    self.tx_packets = 0
    self.rx_bytes = 0
    self.tx_bytes = 0
    self.rx_dropped = 0
    self.tx_dropped = 0
    self.rx_errors = 0
    self.tx_errors = 0
    self.rx_frame_err = 0
    self.rx_over_err = 0
    self.rx_crc_err = 0
    self.collisions = 0

    initHelper(self, kw)

  def pack (self):
    assert self._assert()

    packed = b""
    packed += struct.pack("!H", self.port_no)
    packed += _PAD6
    packed += struct.pack("!QQQQQQQQQQQQ", self.rx_packets,
                          self.tx_packets, self.rx_bytes, self.tx_bytes,
                          self.rx_dropped, self.tx_dropped,
                          self.rx_errors, self.tx_errors,
                          self.rx_frame_err, self.rx_over_err,
                          self.rx_crc_err, self.collisions)
    return packed

  def unpack (self, raw, offset, avail):
    _offset = offset
    offset,(self.port_no,) = _unpack("!H", raw, offset)
    offset = _skip(raw, offset, 6)
    offset,(self.rx_packets, self.tx_packets, self.rx_bytes,
            self.tx_bytes, self.rx_dropped, self.tx_dropped,
            self.rx_errors, self.tx_errors, self.rx_frame_err,
            self.rx_over_err, self.rx_crc_err, self.collisions) = \
            _unpack("!QQQQQQQQQQQQ", raw, offset)
    assert offset - _offset == len(self)
    return offset

  @staticmethod
  def __len__ ():
    return 104

  def __eq__ (self, other):
    if type(self) != type(other): return False
    if self.port_no != other.port_no: return False
    if self.rx_packets != other.rx_packets: return False
    if self.tx_packets != other.tx_packets: return False
    if self.rx_bytes != other.rx_bytes: return False
    if self.tx_bytes != other.tx_bytes: return False
    if self.rx_dropped != other.rx_dropped: return False
    if self.tx_dropped != other.tx_dropped: return False
    if self.rx_errors != other.rx_errors: return False
    if self.tx_errors != other.tx_errors: return False
    if self.rx_frame_err != other.rx_frame_err: return False
    if self.rx_over_err != other.rx_over_err: return False
    if self.rx_crc_err != other.rx_crc_err: return False
    if self.collisions != other.collisions: return False
    return True

  def __add__(self, other):
    if type(self) != type(other): raise NotImplemented()
    port_no = OFPP_NONE
    if self.port_no == other.port_no:
      port_no = self.port_no
    return ofp_port_stats(
        port_no=port_no,
        rx_packets = self.rx_packets + other.rx_packets,
        tx_packets = self.tx_packets + other.tx_packets,
        rx_bytes = self.rx_bytes + other.rx_bytes,
        tx_bytes = self.tx_bytes + other.tx_bytes,
        rx_dropped = self.rx_dropped + other.rx_dropped,
        tx_dropped = self.tx_dropped + other.tx_dropped,
        rx_errors = self.rx_errors + other.rx_errors,
        tx_errors = self.tx_errors + other.tx_errors,
        rx_frame_err = self.rx_frame_err + other.rx_frame_err,
        rx_over_err = self.rx_over_err + other.rx_over_err,
        rx_crc_err = self.rx_crc_err + other.rx_crc_err,
        collisions = self.collisions + other.collisions)

  def show (self, prefix=''):
    outstr = ''
    outstr += prefix + 'port_no: ' + str(self.port_no) + '\n'
    outstr += prefix + 'rx_packets: ' + str(self.rx_packets) + '\n'
    outstr += prefix + 'tx_packets: ' + str(self.tx_packets) + '\n'
    outstr += prefix + 'rx_bytes: ' + str(self.rx_bytes) + '\n'
    outstr += prefix + 'tx_bytes: ' + str(self.tx_bytes) + '\n'
    outstr += prefix + 'rx_dropped: ' + str(self.rx_dropped) + '\n'
    outstr += prefix + 'tx_dropped: ' + str(self.tx_dropped) + '\n'
    outstr += prefix + 'rx_errors: ' + str(self.rx_errors) + '\n'
    outstr += prefix + 'tx_errors: ' + str(self.tx_errors) + '\n'
    outstr += prefix + 'rx_frame_err: ' + str(self.rx_frame_err) + '\n'
    outstr += prefix + 'rx_over_err: ' + str(self.rx_over_err) + '\n'
    outstr += prefix + 'rx_crc_err: ' + str(self.rx_crc_err) + '\n'
    outstr += prefix + 'collisions: ' + str(self.collisions) + '\n'
    return outstr
ofp_port_stats_reply = ofp_port_stats


@openflow_stats_request("OFPST_QUEUE", 5)
class ofp_queue_stats_request (ofp_stats_body_base):
  def __init__ (self, **kw):
    self.port_no = OFPP_ALL
    self.queue_id = OFPQ_ALL

    initHelper(self, kw)

  def pack (self):
    assert self._assert()

    packed = b""
    packed += struct.pack("!H", self.port_no)
    packed += _PAD2
    packed += struct.pack("!L", self.queue_id)
    return packed

  def unpack (self, raw, offset, avail):
    _offset = offset
    offset,(self.port_no,pad,self.queue_id) = _unpack("!HHL", raw, offset)
    assert pad == 0
    assert offset - _offset == len(self)
    return offset

  @staticmethod
  def __len__ ():
    return 8

  def __eq__ (self, other):
    if type(self) != type(other): return False
    if self.port_no != other.port_no: return False
    if self.queue_id != other.queue_id: return False
    return True

  def show (self, prefix=''):
    outstr = ''
    outstr += prefix + 'port_no: ' + str(self.port_no) + '\n'
    outstr += prefix + 'queue_id: ' + str(self.queue_id) + '\n'
    return outstr


@openflow_stats_reply("OFPST_QUEUE", is_list = True)
class ofp_queue_stats (ofp_stats_body_base):
  def __init__ (self, **kw):
    self.port_no = 0
    self.queue_id = 0
    self.tx_bytes = 0
    self.tx_packets = 0
    self.tx_errors = 0

    initHelper(self, kw)

  def pack (self):
    assert self._assert()

    packed = b""
    packed += struct.pack("!H", self.port_no)
    packed += _PAD2
    packed += struct.pack("!LQQQ", self.queue_id, self.tx_bytes,
                          self.tx_packets, self.tx_errors)
    return packed

  def unpack (self, raw, offset, avail):
    _offset = offset
    offset,(self.port_no, pad, self.queue_id, self.tx_bytes,
            self.tx_packets, self.tx_errors) = \
            _unpack("!HHLQQQ", raw, offset)
    assert offset - _offset == len(self)
    return offset

  @staticmethod
  def __len__ ():
    return 32

  def __eq__ (self, other):
    if type(self) != type(other): return False
    if self.port_no != other.port_no: return False
    if self.queue_id != other.queue_id: return False
    if self.tx_bytes != other.tx_bytes: return False
    if self.tx_packets != other.tx_packets: return False
    if self.tx_errors != other.tx_errors: return False
    return True

  def show (self, prefix=''):
    outstr = ''
    outstr += prefix + 'port_no: ' + str(self.port_no) + '\n'
    outstr += prefix + 'queue_id: ' + str(self.queue_id) + '\n'
    outstr += prefix + 'tx_bytes: ' + str(self.tx_bytes) + '\n'
    outstr += prefix + 'tx_packets: ' + str(self.tx_packets) + '\n'
    outstr += prefix + 'tx_errors: ' + str(self.tx_errors) + '\n'
    return outstr
ofp_queue_stats_reply = ofp_queue_stats


@openflow_stats_request("OFPST_VENDOR", 65535, is_list = False)
@openflow_stats_reply("OFPST_VENDOR", 65535, is_list = False)
class ofp_vendor_stats_generic (ofp_stats_body_base):
  _MIN_LENGTH = 4
  def __init__ (self, **kw):
    self.vendor = None
    self.data = b""

    initHelper(self, kw)

  def _pack_body (self):
    if hasattr(self.data, "pack"):
      return self.data.pack()
    else:
      return self.data

  def pack (self):
    assert self._assert()

    packed = struct.pack("!L", self.vendor)
    packed += self._pack_body()
    return packed

  def unpack (self, raw, offset, avail):
    if avail is None: RuntimeError("Requires length")
    _offset = offset
    offset,(self.vendor,) = _unpack("!L", raw, offset)
    offset,self.data = _read(raw, offset, avail-4)
    return offset

  @staticmethod
  def __len__ ():
    return 4+len(self._pack_body())

  def __eq__ (self, other):
    if type(self) != type(other): return False
    if self.vendor != other.vendor: return False
    if self.data != other.data: return False
    return True

  def show (self, prefix=''):
    outstr = ''
    outstr += prefix + 'vendor id: ' + str(self.vendor) + '\n'
    outstr += prefix + 'data len: ' + str(len(self.data)) + '\n'
    return outstr


class ofp_generic_stats_body (ofp_stats_body_base):
  _MIN_LENGTH = 0
  def __init__ (self, **kw):
    self.data = b""

    initHelper(self, kw)

  def _pack_body (self):
    if hasattr(self.data, "pack"):
      return self.data.pack()
    else:
      return self.data

  def pack (self):
    assert self._assert()

    packed += self._pack_body()
    return packed

  def unpack (self, raw, offset, avail):
    if avail is None: RuntimeError("Requires length")
    _offset = offset
    offset,self.data = _read(raw, offset, avail)
    return offset

  @staticmethod
  def __len__ ():
    return len(self._pack_body())

  def __eq__ (self, other):
    if type(self) != type(other): return False
    if self.data != other.data: return False
    return True

  def show (self, prefix=''):
    outstr = ''
    outstr += prefix + 'data len: ' + str(len(self.data)) + '\n'
    return outstr


@openflow_c_message("OFPT_PACKET_OUT", 13)
class ofp_packet_out (ofp_header):
  _MIN_LENGTH = 16
  def __init__ (self, **kw):
    ofp_header.__init__(self)
    self._buffer_id = NO_BUFFER
    self.in_port = OFPP_NONE
    self.actions = []
    self._data = b''

    # ofp_flow_mod & ofp_packet_out do some special handling of 'actions'

    # Allow "action" as a synonym for "actions"
    if 'action' in kw and 'actions' not in kw:
      kw['actions'] = kw['action']
      del kw['action']
    initHelper(self, kw)

    # Allow use of actions=<a single action> for kw args.
    if not hasattr(self.actions, '__getitem__'):
      self.actions = [self.actions]

  @property
  def buffer_id (self):
    if self._buffer_id == NO_BUFFER: return None
    return self._buffer_id
  @buffer_id.setter
  def buffer_id (self, val):
    if val is None: val = NO_BUFFER
    self._buffer_id = val

  @property
  def data (self):
    return self._data
  @data.setter
  def data (self, data):
    if data is None:
      self._data = b''
    elif isinstance(data, packet_base):
      self._data = data.pack()
    elif isinstance(data, ofp_packet_in):
      # Enable you to easily resend a packet
      self._data = b''
      self.buffer_id = data.buffer_id
      if self.buffer_id is None:
        #TODO: It'd be nice to log and then ignore if data is incomplete
        #      Unfortunately, we currently have no logging in here, so we
        #      assert instead which is a either too drastic or too quiet.
        assert data.is_complete
        self._data = data._data
      self.in_port = data.in_port
    elif isinstance(data, bytes):
      self._data = data
    assert assert_type("data", self._data, (bytes,))

  def _validate (self):
    if self.buffer_id is not None and self.data != b'':
      return "can not have both buffer_id and data set"
    return None

  def pack (self):
    assert self._assert()

    actions = b''.join((i.pack() for i in self.actions))
    actions_len = len(actions)

    if self.data is not None:
      return b''.join((ofp_header.pack(self),
        struct.pack("!LHH", self._buffer_id, self.in_port, actions_len),
        actions, self.data))
    else:
      return b''.join((ofp_header.pack(self),
      struct.pack("!LHH", self._buffer_id, self.in_port, actions_len),
      actions))

  def unpack (self, raw, offset=0):
    _offset = offset
    offset,length = self._unpack_header(raw, offset)
    offset,(self._buffer_id, self.in_port, actions_len) = \
        _unpack("!LHH", raw, offset)
    offset,self.actions = _unpack_actions(raw, actions_len, offset)

    remaining = length - (offset - _offset)
    if remaining <= 0:
      self.data = None
    else:
      offset,self.data = _read(raw, offset, remaining)

    assert length == len(self)
    return offset,length

  def __len__ (self):
    return 16 + reduce(operator.add, (len(a) for a in self.actions),
        0) + (len(self.data) if self.data else 0)

  def __eq__ (self, other):
    if type(self) != type(other): return False
    if not ofp_header.__eq__(self, other): return False
    if self.buffer_id != other.buffer_id: return False
    if self.in_port != other.in_port: return False
    if self.actions != other.actions: return False
    return True

  def show (self, prefix=''):
    outstr = ''
    outstr += prefix + 'header: \n'
    outstr += ofp_header.show(self, prefix + '  ')
    outstr += prefix + 'buffer_id: ' + str(self.buffer_id) + '\n'
    outstr += prefix + 'in_port: ' + str(self.in_port) + '\n'
    outstr += prefix + 'actions_len: ' + str(len(self.actions)) + '\n'
    outstr += prefix + 'actions: \n'
    for obj in self.actions:
      if obj is None:
        raise RuntimeError("An element of self.actions was None! "
                           + "Bad formatting...")
      outstr += obj.show(prefix + '  ')
    return outstr


##3.7 Barrier Message
@openflow_s_message("OFPT_BARRIER_REPLY", 19,
    reply_to="ofp_barrier_request")
class ofp_barrier_reply (ofp_header):
  def __init__ (self, **kw):
    ofp_header.__init__(self)
    initHelper(self, kw)

  def pack (self):
    assert self._assert()

    packed = b""
    packed += ofp_header.pack(self)
    return packed

  #def unpack (self, raw, offset=0):
  #  offset,length = self._unpack_header(raw, offset)
  #  assert length == len(self)
  #  return offset,length

  @staticmethod
  def __len__ ():
    return 8

  def __eq__ (self, other):
    if type(self) != type(other): return False
    if not ofp_header.__eq__(self, other): return False
    return True

  def show (self, prefix=''):
    outstr = ''
    outstr += prefix + 'header: \n'
    outstr += ofp_header.show(self, prefix + '  ')
    return outstr


@openflow_c_message("OFPT_BARRIER_REQUEST", 18,
    request_for="ofp_barrier_reply")
class ofp_barrier_request (ofp_header):
  def __init__ (self, **kw):
    ofp_header.__init__(self)

    initHelper(self, kw)

  def pack (self):
    assert self._assert()

    packed = b""
    packed += ofp_header.pack(self)
    return packed

  #def unpack (self, raw, offset=0):
  #  offset,length = self._unpack_header(raw, offset)
  #  assert length == len(self)
  #  return offset,length

  @staticmethod
  def __len__ ():
    return 8

  def __eq__ (self, other):
    if type(self) != type(other): return False
    if not ofp_header.__eq__(self, other): return False
    return True

  def show (self, prefix=''):
    outstr = ''
    outstr += prefix + 'header: \n'
    outstr += ofp_header.show(self, prefix + '  ')
    return outstr


#4 Asynchronous Messages
@openflow_s_message("OFPT_PACKET_IN", 10)
class ofp_packet_in (ofp_header):
  _MIN_LENGTH = 18
  def __init__ (self, **kw):
    ofp_header.__init__(self)

    self.in_port = OFPP_NONE
    self._buffer_id = NO_BUFFER
    self.reason = 0
    self.data = None
    self._total_len = None

    if 'total_len' in kw:
      self._total_len = kw.pop('total_len')

    initHelper(self, kw)

  def _validate (self):
    if self.data and (self.total_len < len(self.data)):
      return "total len less than data len"

  @property
  def total_len (self):
    if self._total_len is None:
      return len(self.data) if self.data else 0
    return self._total_len

  @total_len.setter
  def total_len (self, value):
    self._total_len = value

  @property
  def buffer_id (self):
    if self._buffer_id == NO_BUFFER: return None
    return self._buffer_id
  @buffer_id.setter
  def buffer_id (self, val):
    if val is None: val = NO_BUFFER
    self._buffer_id = val

  @property
  def data (self):
    return self._data
  @data.setter
  def data (self, data):
    assert assert_type("data", data, (packet_base, str))
    if data is None:
      self._data = ''
    elif isinstance(data, packet_base):
      self._data = data.pack()
    else:
      self._data = data

  def pack (self):
    assert self._assert()

    packed = b""
    packed += ofp_header.pack(self)
    packed += struct.pack("!LHHBB", self._buffer_id, self.total_len,
                          self.in_port, self.reason, 0)
    packed += self.data
    #TODO: Padding?  See __len__
    return packed

  @property
  def is_complete (self):
    if self.buffer_id is not None: return True
    return len(self.data) == self.total_len

  def unpack (self, raw, offset=0):
    offset,length = self._unpack_header(raw, offset)
    offset,(self._buffer_id, self._total_len, self.in_port, self.reason,
            pad) = _unpack("!LHHBB", raw, offset)
    offset,self.data = _read(raw, offset, length-18)
    assert length == len(self)
    return offset,length

  def __len__ (self):
    #FIXME: This is probably wrong, but it's not clear from the
    #       spec what's supposed to be going on here.
    #if len(self.data) < 2:
    #  return 20 + len(self.data)
    return 18 + len(self.data)

  def __eq__ (self, other):
    if type(self) != type(other): return False
    if not ofp_header.__eq__(self, other): return False
    if self.buffer_id != other.buffer_id: return False
    if self.total_len != other.total_len: return False
    if self.in_port != other.in_port: return False
    if self.reason != other.reason: return False
    if self.data != other.data: return False
    return True

  def show (self, prefix=''):
    outstr = ''
    outstr += prefix + 'header: \n'
    outstr += ofp_header.show(self, prefix + '  ')
    outstr += prefix + 'buffer_id: ' + str(self.buffer_id) + '\n'
    outstr += prefix + 'total_len: ' + str(self._total_len) + '\n'
    outstr += prefix + 'in_port: ' + str(self.in_port) + '\n'
    outstr += prefix + 'reason: ' + str(self.reason) + '\n'
    outstr += prefix + 'data: ' + str(self.data) + '\n'
    return outstr


@openflow_s_message("OFPT_FLOW_REMOVED", 11)
class ofp_flow_removed (ofp_header):
  def __init__ (self, **kw):
    ofp_header.__init__(self)
    self.match = ofp_match()
    self.cookie = 0
    self.priority = 0
    self.reason = 0
    self.duration_sec = 0
    self.duration_nsec = 0
    self.idle_timeout = 0
    self.packet_count = 0
    self.byte_count = 0
    initHelper(self, kw)

  def _validate (self):
    if not isinstance(self.match, ofp_match):
      return "match is not class ofp_match"
    return None

  def pack (self):
    assert self._assert()

    packed = b""
    packed += ofp_header.pack(self)
    packed += self.match.pack()
    packed += struct.pack("!QHB", self.cookie, self.priority, self.reason)
    packed += _PAD
    packed += struct.pack("!LLH", self.duration_sec, self.duration_nsec,
                          self.idle_timeout)
    packed += _PAD2
    packed += struct.pack("!QQ", self.packet_count, self.byte_count)
    return packed

  def unpack (self, raw, offset=0):
    offset,length = self._unpack_header(raw, offset)
    offset = self.match.unpack(raw, offset)
    offset,(self.cookie, self.priority, self.reason) = \
        _unpack("!QHB", raw, offset)
    offset = _skip(raw, offset, 1)
    offset,(self.duration_sec, self.duration_nsec, self.idle_timeout) = \
        _unpack("!LLH", raw, offset)
    offset = _skip(raw, offset, 2)
    offset,(self.packet_count, self.byte_count) = \
        _unpack("!QQ", raw, offset)
    assert length == len(self)
    return offset,length

  @staticmethod
  def __len__ ():
    return 48 + len(ofp_match)

  def __eq__ (self, other):
    if type(self) != type(other): return False
    if not ofp_header.__eq__(self, other): return False
    if self.match != other.match: return False
    if self.cookie != other.cookie: return False
    if self.priority != other.priority: return False
    if self.reason != other.reason: return False
    if self.duration_sec != other.duration_sec: return False
    if self.duration_nsec != other.duration_nsec: return False
    if self.idle_timeout != other.idle_timeout: return False
    if self.packet_count != other.packet_count: return False
    if self.byte_count != other.byte_count: return False
    return True

  def show (self, prefix=''):
    outstr = ''
    outstr += prefix + 'header: \n'
    outstr += ofp_header.show(self, prefix + '  ')
    outstr += prefix + 'match: \n'
    outstr += self.match.show(prefix + '  ')
    outstr += prefix + 'cookie: ' + str(self.cookie) + '\n'
    outstr += prefix + 'priority: ' + str(self.priority) + '\n'
    outstr += prefix + 'reason: ' + str(self.reason) + '\n'
    outstr += prefix + 'duration_sec: ' + str(self.duration_sec) + '\n'
    outstr += prefix + 'duration_nsec: ' + str(self.duration_nsec) + '\n'
    outstr += prefix + 'idle_timeout: ' + str(self.idle_timeout) + '\n'
    outstr += prefix + 'packet_count: ' + str(self.packet_count) + '\n'
    outstr += prefix + 'byte_count: ' + str(self.byte_count) + '\n'
    return outstr


@openflow_s_message("OFPT_PORT_STATUS", 12)
class ofp_port_status (ofp_header):
  def __init__ (self, **kw):
    ofp_header.__init__(self)
    self.reason = 0
    self.desc = ofp_phy_port()

    initHelper(self, kw)

  def _validate (self):
    if not isinstance(self.desc, ofp_phy_port):
      return "desc is not class ofp_phy_port"
    return None

  def pack (self):
    assert self._assert()

    packed = b""
    packed += ofp_header.pack(self)
    packed += struct.pack("!B", self.reason)
    packed += _PAD * 7 # Pad
    packed += self.desc.pack()
    return packed

  def unpack (self, raw, offset=0):
    offset,length = self._unpack_header(raw, offset)
    offset,(self.reason,) = _unpack("!B", raw, offset)
    offset = _skip(raw, offset, 7)
    offset = self.desc.unpack(raw, offset)
    assert length == len(self)
    return offset,length

  @staticmethod
  def __len__ ():
    return 64

  def __eq__ (self, other):
    if type(self) != type(other): return False
    if not ofp_header.__eq__(self, other): return False
    if self.reason != other.reason: return False
    if self.desc != other.desc: return False
    return True

  def show (self, prefix=''):
    outstr = ''
    outstr += prefix + 'header: \n'
    outstr += ofp_header.show(self, prefix + '  ')
    outstr += prefix + 'reason: ' + str(self.reason) + '\n'
    outstr += prefix + 'desc: \n'
    outstr += self.desc.show(prefix + '  ')
    return outstr


@openflow_s_message("OFPT_ERROR", 1)
class ofp_error (ofp_header):
  _MIN_LENGTH = 12
  def __init__ (self, **kw):
    ofp_header.__init__(self)
    self.type = 0
    self.code = 0
    self.data = b''

    initHelper(self, kw)

  def pack (self):
    assert self._assert()

    packed = b""
    packed += ofp_header.pack(self)
    packed += struct.pack("!HH", self.type, self.code)
    packed += self.data
    return packed

  def unpack (self, raw, offset=0):
    offset,length = self._unpack_header(raw, offset)
    offset,(self.type, self.code) = _unpack("!HH", raw, offset)
    offset,self.data = _read(raw, offset, length - 12)
    assert length == len(self)
    return offset,length

  def __len__ (self):
    return 12 + len(self.data)

  def __eq__ (self, other):
    if type(self) != type(other): return False
    if not ofp_header.__eq__(self, other): return False
    if self.type != other.type: return False
    if self.code != other.code: return False
    if self.data != other.data: return False
    return True

  def show (self, prefix=''):
    outstr = ''
    outstr += prefix + 'header: \n'
    outstr += ofp_header.show(self, prefix + '  ')
    t = self.type
    c = self.code
    if t < len(ofp_error_type):
      n = ofp_error_type_map[t]
      t = "%s (%i)" % (n, t)
      n = 'ofp' + n.lower()[5:] + '_code_map'
      if n in sys.modules[__name__].__dict__:
        if c in sys.modules[__name__].__dict__[n]:
          c = "%s (%i)" % (sys.modules[__name__].__dict__[n][c], c)
    outstr += prefix + 'type: ' + str(t) + '\n'
    outstr += prefix + 'code: ' + str(c) + '\n'
    if len(self.data):
      outstr += prefix + 'datalen: %s\n' % (len(self.data),)
      outstr += prefix + hexdump(self.data).replace("\n", "\n" + prefix)
    return outstr.strip()


#5. Symmetric Messages
@openflow_sc_message("OFPT_HELLO", 0)
class ofp_hello (ofp_header):
  def __init__ (self, **kw):
    ofp_header.__init__(self)
    initHelper(self, kw)

  def pack (self):
    assert self._assert()

    packed = b""
    packed += ofp_header.pack(self)
    return packed

  #def unpack (self, raw, offset=0):
  #  offset,length = self._unpack_header(raw, offset)
  #  assert length == len(self)
  #  return offset,length

  @staticmethod
  def __len__ ():
    return 8

  def __eq__ (self, other):
    if type(self) != type(other): return False
    if not ofp_header.__eq__(self, other): return False
    return True

  def show (self, prefix=''):
    outstr = ''
    outstr += prefix + 'header: \n'
    outstr += ofp_header.show(self, prefix + '  ')
    return outstr


@openflow_sc_message("OFPT_ECHO_REQUEST", 2,
    request_for="ofp_echo_reply")
class ofp_echo_request (ofp_header):
  _MIN_LENGTH = 8
  def __init__ (self, **kw):
    ofp_header.__init__(self)
    self.body = b''
    initHelper(self, kw)

  def pack (self):
    assert self._assert()

    packed = b""
    packed += ofp_header.pack(self)
    packed += self.body
    return packed

  def unpack (self, raw, offset=0):
    offset,length = self._unpack_header(raw, offset)
    offset,self.body = _read(raw, offset, length - 8)
    assert length == len(self)
    return offset,length

  def __len__ (self):
    return 8 + len(self.body)

  def __eq__ (self, other):
    if type(self) != type(other): return False
    if not ofp_header.__eq__(self, other): return False
    if self.body != other.body: return False
    return True

  def show (self, prefix=''):
    outstr = ''
    outstr += prefix + 'header: \n'
    outstr += ofp_header.show(self, prefix + '  ')
    outstr += prefix + 'body:\n'
    outstr += _format_body(self.body, prefix + '  ') + '\n'
    return outstr


@openflow_sc_message("OFPT_ECHO_REPLY", 3,
    reply_to="ofp_echo_request")
class ofp_echo_reply (ofp_header):
  _MIN_LENGTH = 8
  def __init__ (self, **kw):
    ofp_header.__init__(self)
    self.body = b''
    initHelper(self, kw)

  def pack (self):
    assert self._assert()

    packed = b""
    packed += ofp_header.pack(self)
    packed += self.body
    return packed

  def unpack (self, raw, offset=0):
    offset,length = self._unpack_header(raw, offset)
    offset,self.body = _read(raw, offset, length - 8)
    assert length == len(self)
    return offset,length

  def __len__ (self):
    return 8 + len(self.body)

  def __eq__ (self, other):
    if type(self) != type(other): return False
    if not ofp_header.__eq__(self, other): return False
    if self.body != other.body: return False
    return True

  def show (self, prefix=''):
    outstr = ''
    outstr += prefix + 'header: \n'
    outstr += ofp_header.show(self, prefix + '  ')
    outstr += prefix + 'body:\n'
    outstr += _format_body(self.body, prefix + '  ') + '\n'
    return outstr


class ofp_vendor_base (ofp_header):
  header_type = 4 # OFPT_VENDOR
  """
  Base class for vendor messages
  """
  pass


@openflow_sc_message("OFPT_VENDOR", 4)
class ofp_vendor_generic (ofp_vendor_base):
  _MIN_LENGTH = 12
  _collect_raw = False

  def __init__ (self, **kw):
    ofp_header.__init__(self)
    self.vendor = 0
    self.data = b''
    initHelper(self, kw)

  def pack (self):
    assert self._assert()

    packed = b""
    packed += ofp_header.pack(self)
    packed += struct.pack("!L", self.vendor)
    if hasattr(self.data, "pack"):
      packed += self.data.pack()
    else:
      packed += self.data
    return packed

  def unpack (self, raw, offset=0):
    _offset = offset
    offset,length = self._unpack_header(raw, offset)
    offset,(self.vendor,) = _unpack("!L", raw, offset)
    offset,self.data = _read(raw, offset, length-12)
    if self._collect_raw:
      self.raw = raw[_offset, _offset+length]
    return offset,length

  def __len__ (self):
    return 12 + len(self.data)

  def __eq__ (self, other):
    if type(self) != type(other): return False
    if not ofp_header.__eq__(self, other): return False
    if self.vendor != other.vendor: return False
    if self.data != other.data: return False
    return True

  def show (self, prefix=''):
    outstr = ''
    outstr += prefix + 'header: \n'
    outstr += ofp_header.show(self, prefix + '  ')
    outstr += prefix + 'vendor: ' + str(self.vendor) + '\n'
    outstr += prefix + 'datalen: ' + str(len(self.data)) + '\n'
    #outstr += prefix + hexdump(self.data).replace("\n", "\n" + prefix)
    return outstr


@openflow_c_message("OFPT_FEATURES_REQUEST", 5,
    request_for="ofp_features_reply")
class ofp_features_request (ofp_header):
  def __init__ (self, **kw):
    ofp_header.__init__(self)

    initHelper(self, kw)

  def pack (self):
    assert self._assert()

    packed = b""
    packed += ofp_header.pack(self)
    return packed

  def unpack (self, raw, offset=0):
    offset,length = self._unpack_header(raw, offset)
    assert length == len(self)
    return offset,length

  @staticmethod
  def __len__ ():
    return 8

  def __eq__ (self, other):
    if type(self) != type(other): return False
    if not ofp_header.__eq__(self, other): return False
    return True

  def show (self, prefix=''):
    outstr = ''
    outstr += prefix + 'header: \n'
    outstr += ofp_header.show(self, prefix + '  ')
    return outstr


@openflow_c_message("OFPT_GET_CONFIG_REQUEST", 7,
    request_for="ofp_get_config_reply")
class ofp_get_config_request (ofp_header):
  def __init__ (self, **kw):
    ofp_header.__init__(self)

    initHelper(self, kw)

  def pack (self):
    assert self._assert()

    packed = b""
    packed += ofp_header.pack(self)
    return packed

  #def unpack (self, raw, offset=0):
  #  offset,length = self._unpack_header(raw, offset)
  #  assert length == len(self)
  #  return offset,length

  @staticmethod
  def __len__ ():
    return 8

  def __eq__ (self, other):
    if type(self) != type(other): return False
    if not ofp_header.__eq__(self, other): return False
    return True

  def show (self, prefix=''):
    outstr = ''
    outstr += prefix + 'header: \n'
    outstr += ofp_header.show(self, prefix + '  ')
    return outstr


@openflow_s_message("OFPT_GET_CONFIG_REPLY", 8,
    reply_to="ofp_get_config_request")
class ofp_get_config_reply (ofp_header): # uses ofp_switch_config
  def __init__ (self, **kw):
    ofp_header.__init__(self)
    self.flags = 0
    self.miss_send_len = OFP_DEFAULT_MISS_SEND_LEN

    initHelper(self, kw)

  def pack (self):
    assert self._assert()

    packed = b""
    packed += ofp_header.pack(self)
    packed += struct.pack("!HH", self.flags, self.miss_send_len)
    return packed

  def unpack (self, raw, offset=0):
    offset,length = self._unpack_header(raw, offset)
    offset,(self.flags, self.miss_send_len) = \
        _unpack("!HH", raw, offset)
    assert length == len(self)
    return offset,length

  @staticmethod
  def __len__ ():
    return 12

  def __eq__ (self, other):
    if type(self) != type(other): return False
    if not ofp_header.__eq__(self, other): return False
    if self.flags != other.flags: return False
    if self.miss_send_len != other.miss_send_len: return False
    return True

  def show (self, prefix=''):
    outstr = ''
    outstr += prefix + 'header: \n'
    outstr += ofp_header.show(self, prefix + '  ')
    outstr += prefix + 'flags: ' + str(self.flags) + '\n'
    outstr += prefix + 'miss_send_len: ' + str(self.miss_send_len) + '\n'
    return outstr


def _unpack_queue_props (b, length, offset=0):
  """
  Parses queue props from a buffer
  b is a buffer (bytes)
  offset, if specified, is where in b to start decoding
  returns (next_offset, [Pops])
  """
  if (len(b) - offset) < length: raise UnderrunError
  props = []
  end = length + offset
  while offset < end:
    (t,l) = struct.unpack_from("!HH", b, offset)
    if (len(b) - offset) < l: raise UnderrunError
    a = _queue_prop_type_to_class.get(t)
    if a is None:
      # Use generic prop header for unknown type
      a = ofp_queue_prop_generic()
    else:
      a = a()
    a.unpack(b[offset:offset+l])
    assert len(a) == l
    props.append(a)
    offset += l
  return (offset, props)

def _unpack_actions (b, length, offset=0):
  """
  Parses actions from a buffer
  b is a buffer (bytes)
  offset, if specified, is where in b to start decoding
  returns (next_offset, [Actions])
  """
  if (len(b) - offset) < length: raise UnderrunError
  actions = []
  end = length + offset
  while offset < end:
    (t,l) = struct.unpack_from("!HH", b, offset)
    if (len(b) - offset) < l: raise UnderrunError
    a = _action_type_to_class.get(t)
    if a is None:
      # Use generic action header for unknown type
      a = ofp_action_generic()
    else:
      a = a()
    a.unpack(b[offset:offset+l])
    assert len(a) == l
    actions.append(a)
    offset += l
  return (offset, actions)

def _init ():
  def formatMap (name, m):
    o = name + " = {\n"
    vk = sorted([(v,k) for k,v in m.iteritems()])
    maxlen = 2 + len(reduce(lambda a,b: a if len(a)>len(b) else b,
                            (v for k,v in vk)))
    fstr = "  %-" + str(maxlen) + "s : %s,\n"
    for v,k in vk:
      o += fstr % ("'" + k + "'",v)
    o += "}"
    return o
  """
  maps = []
  for k,v in globals().iteritems():
    if k.startswith("ofp_") and k.endswith("_map") and type(v) == dict:
      maps.append((k,v))
  for name,m in maps:
    rev = {}
    name = name[:-4]
    names = globals()[name]
    for n in names:
      rev[n] = globals()[n]

    globals()[name + '_rev_map'] = rev
    print(formatMap(name + "_rev_map", rev))
  return
  """
  maps = []
  for k,v in globals().iteritems():
    if (k.startswith("ofp_") and k.endswith("_rev_map")
        and type(v) == dict):
      maps.append((k[:-8],v))
  for name,m in maps:
    # Try to generate forward maps
    forward = dict(((v,k) for k,v in m.iteritems()))
    if len(forward) == len(m):
      if name + "_map" not in globals():
        globals()[name + "_map"] = forward
    else:
      print(name + "_rev_map is not a map")

    # Try to generate lists
    v = m.values()
    v.sort()
    if v[-1] != len(v)-1:
      # Allow ones where the last value is a special value (e.g., VENDOR)
      del v[-1]
    if len(v) > 0 and v[0] == 0 and v[-1] == len(v)-1:
      globals()[name] = v

    # Generate gobals
    for k,v in m.iteritems():
      globals()[k] = v


_init()


# Values from macro definitions
OFP_FLOW_PERMANENT = 0
OFP_DL_TYPE_ETH2_CUTOFF = 0x0600
DESC_STR_LEN = 256
OFPFW_ICMP_CODE = OFPFW_TP_DST
OFPQ_MIN_RATE_UNCFG = 0xffff
OFP_VERSION = 0x01
OFP_MAX_TABLE_NAME_LEN = 32
OFP_DL_TYPE_NOT_ETH_TYPE = 0x05ff
OFP_DEFAULT_MISS_SEND_LEN = 128
OFP_MAX_PORT_NAME_LEN = 16
OFP_SSL_PORT = 6633
OFPFW_ICMP_TYPE = OFPFW_TP_SRC
OFP_TCP_PORT = 6633
SERIAL_NUM_LEN = 32
OFP_DEFAULT_PRIORITY = 0x8000
OFP_VLAN_NONE = 0xffff
OFPQ_ALL = 0xffffffff

ofp_match_data = {
  'in_port' : (0, OFPFW_IN_PORT),
  'dl_src' : (EMPTY_ETH, OFPFW_DL_SRC),
  'dl_dst' : (EMPTY_ETH, OFPFW_DL_DST),
  'dl_vlan' : (0, OFPFW_DL_VLAN),
  'dl_vlan_pcp' : (0, OFPFW_DL_VLAN_PCP),
  'dl_type' : (0, OFPFW_DL_TYPE),
  'nw_tos' : (0, OFPFW_NW_TOS),
  'nw_proto' : (0, OFPFW_NW_PROTO),
  'nw_src' : (0, OFPFW_NW_SRC_ALL),
  'nw_dst' : (0, OFPFW_NW_DST_ALL),
  'tp_src' : (0, OFPFW_TP_SRC),
  'tp_dst' : (0, OFPFW_TP_DST),
}

########NEW FILE########
__FILENAME__ = nicira
# Copyright 2012,2013 James McCauley
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at:
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# For lots of documentation, see Open vSwitch's nicira-ext.h and ofp-msgs.h


from pox.core import core
from pox.lib.util import initHelper
from pox.lib.util import hexdump
from pox.lib.addresses import parse_cidr, IPAddr, EthAddr, IPAddr6
import pox.lib.packet as pkt

import pox.openflow.libopenflow_01 as of
from pox.openflow.libopenflow_01 import ofp_header, ofp_vendor_base
from pox.openflow.libopenflow_01 import _PAD, _PAD2, _PAD4, _PAD6
from pox.openflow.libopenflow_01 import _unpack, _read, _skip

import struct


# -----------------------------------------------------------------------
# OpenFlow Stuff
# -----------------------------------------------------------------------
# Technically, this stuff is part of OpenFlow 1.1+ and shouldn't be in
# this file.  Since we don't have 1.1+ support yet, it's here at least
# temporarily.
OFPR_INVALID_TTL = 2 # Packet has invalid TTL
OFPC_INVALID_TTL_TO_CONTROLLER = 4


# -----------------------------------------------------------------------
# Nicira extensions
# -----------------------------------------------------------------------

NX_VENDOR_ID = 0x00002320

def _init_constants ():
  actions = [
    "NXAST_SNAT__OBSOLETE",
    "NXAST_RESUBMIT",
    "NXAST_SET_TUNNEL",
    "NXAST_DROP_SPOOFED_ARP__OBSOLETE",
    "NXAST_SET_QUEUE",
    "NXAST_POP_QUEUE",
    "NXAST_REG_MOVE",
    "NXAST_REG_LOAD",
    "NXAST_NOTE",
    "NXAST_SET_TUNNEL64",
    "NXAST_MULTIPATH",
    "NXAST_AUTOPATH__DEPRECATED",
    "NXAST_BUNDLE",
    "NXAST_BUNDLE_LOAD",
    "NXAST_RESUBMIT_TABLE",
    "NXAST_OUTPUT_REG",
    "NXAST_LEARN",
    "NXAST_EXIT",
    "NXAST_DEC_TTL",
    "NXAST_FIN_TIMEOUT",
    "NXAST_CONTROLLER",
    "NXAST_DEC_TTL_CNT_IDS",
    "NXAST_WRITE_METADATA",
    "NXAST_PUSH_MPLS",
    "NXAST_POP_MPLS",
    "NXAST_SET_MPLS_TTL",
    "NXAST_DEC_MPLS_TTL",
    "NXAST_STACK_PUSH",
    "NXAST_STACK_POP",
    "NXAST_SAMPLE",
  ]
  for i,name in enumerate(actions):
    globals()[name] = i

_init_constants()

NXT_ROLE_REQUEST = 10
NXT_ROLE_REPLY = 11
NXT_SET_FLOW_FORMAT = 12
NXT_FLOW_MOD = 13
NXT_FLOW_MOD_TABLE_ID = 15
NXT_SET_PACKET_IN_FORMAT = 16
NXT_PACKET_IN = 17
NXT_FLOW_AGE = 18
NXT_SET_ASYNC_CONFIG = 19
NXT_SET_CONTROLLER_ID = 20
NXT_FLOW_MONITOR_CANCEL = 21
NXT_FLOW_MONITOR_PAUSED = 22
NXT_FLOW_MONITOR_RESUMED = 23

NXST_FLOW_MONITOR_REQUEST = 2
NXST_FLOW_MONITOR_REPLY = 2


#TODO: Replace with version in pox.lib?
def _issubclass (a, b):
  try:
    return issubclass(a, b)
  except TypeError:
    return False


class nicira_base (ofp_vendor_base):
  """
  Base class for Nicira extensions
  """
  _MIN_LENGTH = 16
  vendor = NX_VENDOR_ID
  #subtype = None # Set

  def _eq (self, other):
    """
    Return True if equal

    Overide this.
    """
    return True

  def _init (self, kw):
    """
    Initialize fields

    Overide this.
    """
    pass

  def _pack_body (self):
    """
    Pack body.
    """
    return b""

  def _unpack_body (self, raw, offset, avail):
    """
    Unpack body in raw starting at offset.

    Return new offset
    """
    return offset

  def _body_length (self):
    """
    Return length of body.

    Optionally override this.
    """
    return len(self._pack_body())

  def _show (self, prefix):
    """
    Format additional fields as text
    """
    return ""

  def __init__ (self, **kw):
    ofp_vendor_base.__init__(self)
    self._init(kw)
    assert hasattr(self, 'vendor')
    assert hasattr(self, 'subtype')
    initHelper(self, kw)

  def pack (self):
    assert self._assert()

    packed = b""
    packed += ofp_vendor_base.pack(self)
    packed += struct.pack("!LL", self.vendor, self.subtype)
    packed += self._pack_body()
    return packed

  def unpack (self, raw, offset=0):
    offset,length = self._unpack_header(raw, offset)
    offset,(self.vendor,self.subtype) = _unpack("!LL", raw, offset)
    offset = self._unpack_body(raw, offset, length-16)
    return offset,length

  def __len__ (self):
    return 16 + self._body_length()

  def __eq__ (self, other):
    if type(self) != type(other): return False
    if not ofp_vendor_base.__eq__(self, other): return False
    if self.vendor != other.vendor: return False
    if self.subtype != other.subtype: return False
    return self._eq(other)

  def __ne__ (self, other): return not self.__eq__(other)

  def show (self, prefix=''):
    outstr = ''
    outstr += prefix + 'header: \n'
    outstr += ofp_vendor_base.show(self, prefix + '  ')
    outstr += prefix + 'vendor: ' + str(self.vendor) + '\n'
    outstr += prefix + 'subtype: ' + str(self.subtype) + '\n'
    outstr += self._show(prefix)
    return outstr


class nx_flow_mod_table_id (nicira_base):
  """
  Used to enable the flow mod table ID extension

  When this is enabled, a slightly altered ofp_flow_mod can be used
  to set the table for a flow insertion.  A convenient version of this
  slightly altered flow_mod is available as ofp_flow_mod_table_id.
  """
  subtype = NXT_FLOW_MOD_TABLE_ID
  _MIN_LENGTH = 16 + 8

  def _init (self, kw):
    self.enable = True # Called "set" by OVS

  def _eq (self, other):
    """
    Return True if equal

    Overide this.
    """
    return self.enable == other.enable

  def _pack_body (self):
    """
    Pack body.
    """
    return struct.pack("!B", 1 if self.enable else 0) + (of._PAD * 7)

  def _unpack_body (self, raw, offset, avail):
    """
    Unpack body in raw starting at offset.

    Return new offset
    """
    offset,(enable,) = of._unpack("!B", raw, offset)
    offset = of._skip(raw, offset, 7)
    self.enable = True if enable else False
    return offset

  def _body_length (self):
    """
    Return length of body.

    Optionally override this.
    """
    return len(self._pack_body())

  def _show (self, prefix):
    """
    Format additional fields as text
    """
    return prefix + "set: " + str(self.enable) + "\n"


class ofp_flow_mod_table_id (of.ofp_flow_mod):
  """
  A subclass of ofp_flow_mod which has a table_id

  This is for use with the NXT_FLOW_MOD_TABLE_ID extension.
  """
  def __init__ (self, **kw):
    self.table_id = 0xff
    of.ofp_flow_mod.__init__(self, **kw)

  def splice_table_id (func):
    """
    Execute wrapped function with table_id temporarily stored as
    MSB of command field.
    """
    def splice(self, *args):
      assert self.command <= 0xff
      self.command |= self.table_id << 8
      try:
        retval = func(self, *args)
      finally:
        self.table_id = self.command >> 8
        self.command &= 0xff
      return retval
    return splice

  @splice_table_id
  def pack (self):
    return super(ofp_flow_mod_table_id, self).pack()

  @splice_table_id
  def unpack (self, raw, offset=0):
    return super(ofp_flow_mod_table_id, self).unpack()

  @splice_table_id
  def __eq__ (self, other):
    return super(ofp_flow_mod_table_id, self).__eq__(other)

  def show (self, prefix=''):
    outstr = ''
    outstr += prefix + 'header: \n'
    outstr += ofp_header.show(self, prefix + '  ')
    outstr += prefix + 'match: \n'
    outstr += self.match.show(prefix + '  ')
    outstr += prefix + 'cookie: ' + str(self.cookie) + '\n'
    outstr += prefix + 'command: ' + str(self.command) + '\n'
    outstr += prefix + 'table_id: ' + str(self.table_id) + '\n'
    outstr += prefix + 'idle_timeout: ' + str(self.idle_timeout) + '\n'
    outstr += prefix + 'hard_timeout: ' + str(self.hard_timeout) + '\n'
    outstr += prefix + 'priority: ' + str(self.priority) + '\n'
    outstr += prefix + 'buffer_id: ' + str(self.buffer_id) + '\n'
    outstr += prefix + 'out_port: ' + str(self.out_port) + '\n'
    outstr += prefix + 'flags: ' + str(self.flags) + '\n'
    outstr += prefix + 'actions: \n'
    for obj in self.actions:
      outstr += obj.show(prefix + '  ')
    return outstr


class nx_flow_mod (of.ofp_flow_mod, of.ofp_vendor_base):
  """
  A flow mod command that uses Nicira extended matches

  This has a table_id attribute, which only works if you have enabled
  the nx_flow_mod_table_id option.
  """
  _MIN_LENGTH = 32
  header_type = of.OFPT_VENDOR
  vendor = NX_VENDOR_ID
  subtype = NXT_FLOW_MOD

  def __init__ (self, **kw):
    self.table_id = 0
    of.ofp_flow_mod.__init__(self, **kw)

    if 'match' not in kw:
      # Superclass created an ofp_match -- replace it
      self.match = nx_match()

  def _validate (self):
    if not isinstance(self.match, nx_match):
      return "match is not class ofp_match"
    return None

  def pack (self):
    """
    Packs this object into its wire format.
    May normalize fields.
    NOTE: If "data" has been specified, this method may actually return
          *more than just a single ofp_flow_mod* in packed form.
          Specifically, it may also have a barrier and an ofp_packet_out.
    """
    po = None
    if self.data:
      #TODO: It'd be nice to log and then ignore if not data_is_complete.
      #      Unfortunately, we currently have no logging in here, so we
      #      assert instead which is a either too drastic or too quiet.
      assert self.data.is_complete
      assert self.buffer_id is None
      self.buffer_id = self.data.buffer_id
      if self.buffer_id is None:
        po = ofp_packet_out(data=self.data)
        po.in_port = self.data.in_port
        po.actions.append(ofp_action_output(port = OFPP_TABLE))
        # Should maybe check that packet hits the new entry...
        # Or just duplicate the actions? (I think that's the best idea)

    assert self._assert()
    match = self.match.pack()
    match_len = len(match)

    command = self.command
    command |= (self.table_id << 8)

    packed = b""
    packed += ofp_header.pack(self)
    packed += struct.pack("!LL", self.vendor, self.subtype)
    packed += struct.pack("!QHHHHLHHH", self.cookie, command,
                          self.idle_timeout, self.hard_timeout,
                          self.priority, self._buffer_id, self.out_port,
                          self.flags, match_len)
    packed += _PAD6
    packed += match
    packed += _PAD * ((match_len + 7)/8*8 - match_len)
    for i in self.actions:
      packed += i.pack()

    if po:
      packed += ofp_barrier_request().pack()
      packed += po.pack()

    assert len(packed) == len(self)

    return packed

  def unpack (self, raw, offset=0):
    _o = offset
    offset,length = self._unpack_header(raw, offset)
    offset,(vendor,subtype) = _unpack("!LL", raw, offset)
    offset,(self.cookie, self.command, self.idle_timeout,
            self.hard_timeout, self.priority, self._buffer_id,
            self.out_port, self.flags, match_len) = \
            _unpack("!QHHHHLHHH", raw, offset)
    offset = self._skip(raw, offset, 6)
    offset = self.match.unpack(raw, offset, match_len)
    offset,self.actions = of._unpack_actions(raw,
        length-(offset - _o), offset)
    assert length == len(self)
    return offset,length

  def __len__ (self):
    match_len = len(self.match)
    l = 8 + 4 + 4
    l += 8 + 2 + 2 + 2 + 2 + 4 + 2 + 2
    l += 2 # match_len
    l += 6 # pad
    l += match_len
    l += (match_len + 7)//8*8 - match_len
    for i in self.actions:
      l += len(i)
    return l


# Packet_in formats
NXPIF_OPENFLOW10 = 0 # Standard OpenFlow 1.0 packet_in format
NXPIF_NXM = 1        # Nicira Extended packet_in format

class nx_packet_in_format (nicira_base):
  subtype = NXT_SET_PACKET_IN_FORMAT
  _MIN_LENGTH = 16 + 4

  def _init (self, kw):
    self.format = NXPIF_NXM # Extended packet_in format

  def _eq (self, other):
    """
    Return True if equal

    Overide this.
    """
    return self.format == other.format

  def _pack_body (self):
    """
    Pack body.
    """
    return struct.pack("!I", self.format)

  def _unpack_body (self, raw, offset, avail):
    """
    Unpack body in raw starting at offset.

    Return new offset
    """
    offset,(self.format,) = of._unpack("!I", raw, offset)
    return offset

  def _show (self, prefix):
    """
    Format additional fields as text
    """
    s = prefix + "format: "
    if self.format == NXPIF_NXM:
      s += "NXM"
    elif self.format == NXPIF_OPENFLOW10:
      s += "OF1.0"
    else:
      s += str(self.format)
    return s + "\n"


NX_ROLE_OTHER = 0
NX_ROLE_MASTER = 1
NX_ROLE_SLAVE = 2

class nx_role_request (nicira_base):
  """
  Requests master/slave/other role type

  Can initialize with role=NX_ROLE_x or with, e.g., master=True.
  """
  subtype = NXT_ROLE_REQUEST
  _MIN_LENGTH = 16 + 4

  def _init (self, kw):
    self.role = NX_ROLE_OTHER

    if kw.pop("other", False):
      self.role = NX_ROLE_OTHER
    if kw.pop("master", False):
      self.role = NX_ROLE_MASTER
    if kw.pop("slave", False):
      self.role = NX_ROLE_SLAVE

  @property
  def master (self):
    return self.role == NX_ROLE_MASTER
  @property
  def slave (self):
    return self.role == NX_ROLE_SLAVE
  @property
  def other (self):
    return self.role == NX_ROLE_OTHER

  def _eq (self, other):
    """
    Return True if equal

    Overide this.
    """
    return self.role == other.role

  def _pack_body (self):
    """
    Pack body.
    """
    return struct.pack("!I", self.role)

  def _unpack_body (self, raw, offset, avail):
    """
    Unpack body in raw starting at offset.

    Return new offset
    """
    offset,(self.role,) = of._unpack("!I", raw, offset)
    return offset

  def _show (self, prefix):
    """
    Format additional fields as text
    """
    s = prefix + "role: "
    s += {NX_ROLE_OTHER:"other",NX_ROLE_MASTER:"master",
        NX_ROLE_SLAVE:"slave"}.get(self.role, str(self.role))
    return s + "\n"

class nx_role_reply (nx_role_request):
  subtype = NXT_ROLE_REPLY
  pass


# -----------------------------------------------------------------------
# Actions
# -----------------------------------------------------------------------

class nx_output_reg (of.ofp_action_vendor_base):
  def _init (self, kw):
    self.vendor = NX_VENDOR_ID
    self.subtype = NXAST_OUTPUT_REG
    self.offset = 0
    self.nbits = None
    self.reg = None # an nxm_entry class
    self.max_len = 0

  def _eq (self, other):
    if self.subtype != other.subtype: return False
    if self.offset != other.offset: return False
    if self.nbits != other.nbits: return False
    if self.reg != other.reg: return False
    if self.max_len != other.max_len: return False
    return True

  def _pack_body (self):
    nbits = self.nbits - 1
    assert nbits >= 0 and nbits <= 63
    assert self.offset >= 0 and self.offset < (1 << 10)
    ofs_nbits = self.offset << 6 | nbits

    o = self.reg()
    o._force_mask = False
    reg = o.pack(omittable=False, header_only=True)

    p = struct.pack('!HH4sH', self.subtype, ofs_nbits, reg, self.max_len)
    p += _PAD6
    return p

  def _unpack_body (self, raw, offset, avail):
    offset,(self.subtype, ofs_nbits, reg, self.max_len, _, _) = \
        of._unpack('!HH4sHHI', raw, offset)

    self.offset = ofs_nbits >> 6
    self.nbits = (ofs_nbits & 0x3f) + 1

    self.reg = _class_for_nxm_header(reg)

    return offset

  def _body_length (self):
    return 16

  def _show (self, prefix):
    s = ''
    s += prefix + ('subtype: %s\n' % (self.subtype,))
    s += prefix + ('offset: %s\n' % (self.offset,))
    s += prefix + ('nbits: %s\n' % (self.nbits,))
    s += prefix + ('reg: %s\n' % (self.reg,))
    s += prefix + ('max_len: %s\n' % (self.max_len,))
    return s


class nx_reg_move (of.ofp_action_vendor_base):
  def _init (self, kw):
    self.vendor = NX_VENDOR_ID
    self.subtype = NXAST_REG_MOVE
    self.nbits = None
    self.dst = None # an nxm_entry class
    self.dst_ofs = 0
    self.src = None # an nxm_entry_class
    self.src_ofs = 0

  def _eq (self, other):
    if self.subtype != other.subtype: return False
    if self.nbits != other.nbits: return False
    if self.dst != other.dst: return False
    if self.dst_ofs != other.dst_ofs: return False
    if self.src != other.src: return False
    if self.src_ofs != other.src_ofs: return False
    return True

  def _pack_body (self):
    if self.nbits is None:
      a = self.dst._get_size_hint() - self.dst_ofs
      b = self.src._get_size_hint() - self.src_ofs
      self.nbits = min(a,b)

    o = self.dst()
    o._force_mask = False
    dst = o.pack(omittable=False, header_only=True)

    o = self.src()
    o._force_mask = False
    src = o.pack(omittable=False, header_only=True)

    p = struct.pack('!HHHH4s4s', self.subtype, self.nbits, self.src_ofs,
            self.dst_ofs, src, dst)
    return p

  def _unpack_body (self, raw, offset, avail):
    offset,(self.subtype,self.nbits, self.src_ofs, self.dst_ofs, src, dst) = \
        of._unpack('!HHHH4s4s', raw, offset)

    self.dst = _class_for_nxm_header(dst)

    self.src = _class_for_nxm_header(src)

    return offset

  def _body_length (self):
    return 16

  def _show (self, prefix):
    s = ''
    s += prefix + ('subtype: %s\n' % (self.subtype,))
    s += prefix + ('offset: %s\n' % (self.offset,))
    s += prefix + ('nbits: %s\n' % (self.nbits,))
    s += prefix + ('src_ofs: %s\n' % (self.src_ofs,))
    s += prefix + ('dst_ofs: %s\n' % (self.dst_ofs,))
    s += prefix + ('src: %s\n' % (self.src,))
    s += prefix + ('dst: %s\n' % (self.dst,))
    return s


class nx_reg_load (of.ofp_action_vendor_base):
  def _init (self, kw):
    self.vendor = NX_VENDOR_ID
    self.subtype = NXAST_REG_LOAD
    self.offset = 0
    self.nbits = None
    self.dst = None # an nxm_entry class
    self.value = 0

  def _eq (self, other):
    if self.subtype != other.subtype: return False
    if self.offset != other.offset: return False
    if self.nbits != other.nbits: return False
    if self.dst != other.dst: return False
    if self.value != other.value: return False
    return True

  def _pack_body (self):
    if self.nbits is None:
      self.nbits = self.dst._get_size_hint() - self.offset
    nbits = self.nbits - 1
    assert nbits >= 0 and nbits <= 63
    assert self.offset >= 0 and self.offset < (1 << 10)
    ofs_nbits = self.offset << 6 | nbits

    o = self.dst()
    o._force_mask = False
    dst = o.pack(omittable=False, header_only=True)

    p = struct.pack('!HH4sQ', self.subtype, ofs_nbits, dst, self.value)
    return p

  def _unpack_body (self, raw, offset, avail):
    offset,(self.subtype,ofs_nbits, dst, self.value) = \
        of._unpack('!HH4sQ', raw, offset)

    self.offset = ofs_nbits >> 6
    self.nbits = (ofs_nbits & 0x3f) + 1

    self.dst = _class_for_nxm_header(dst)

    return offset

  def _body_length (self):
    return 16

  def _show (self, prefix):
    s = ''
    s += prefix + ('subtype: %s\n' % (self.subtype,))
    s += prefix + ('offset: %s\n' % (self.offset,))
    s += prefix + ('nbits: %s\n' % (self.nbits,))
    s += prefix + ('dst: %s\n' % (self.dst,))
    s += prefix + ('value: %s\n' % (self.value,))
    return s


class nx_action_controller (of.ofp_action_vendor_base):
  """
  Sends packet to controller

  This is similar to an output to OFPP_CONTROLLER, but allows setting
  the reason field and controller id to send to.
  """
  def _init (self, kw):
    self.vendor = NX_VENDOR_ID
    self.subtype = NXAST_CONTROLLER
    self.max_len = 0xffFF
    self.controller_id = 0
    self.reason = of.OFPR_ACTION

  def _eq (self, other):
    if self.subtype != other.subtype: return False
    if self.max_len != other.max_len: return False
    if self.controller_id != other.controller_id: return False
    if self.reason != other.reason: return False
    return True

  def _pack_body (self):
    p = struct.pack('!HHHB', self.subtype, self.max_len, self.controller_id,
        self.reason)
    p += of._PAD
    return p

  def _unpack_body (self, raw, offset, avail):
    offset,(self.subtype,self.max_len, self.controller_id, self.reason) = \
        of._unpack('!HHHB', raw, offset)
    offset = of._skip(raw, offset, 1)
    return offset

  def _body_length (self):
    return 8

  def _show (self, prefix):
    s = ''
    s += prefix + ('subtype: %s\n' % (self.subtype,))
    s += prefix + ('max_len: %s\n' % (self.max_len,))
    s += prefix + ('controller_id: %s\n' % (self.controller_id,))
    s += prefix + ('reason: %s\n' % (self.reason,))
    return s


class nx_action_push_mpls (of.ofp_action_vendor_base):
  """
  Push an MPLS label

  """
  def _init (self, kw):
    self.vendor = NX_VENDOR_ID
    self.subtype = NXAST_PUSH_MPLS
    self.ethertype = pkt.ethernet.MPLS_TYPE
    # The only alternative for ethertype is MPLS_MC_TYPE (multicast)

  def _eq (self, other):
    if self.subtype != other.subtype: return False
    if self.ethertype != other.ethertype: return False
    return True

  def _pack_body (self):
    p = struct.pack('!HHI', self.subtype, self.ethertype, 0) # 4 bytes pad
    return p

  def _unpack_body (self, raw, offset, avail):
    offset,(self.subtype,self.ethertype) = of._unpack('!HH', raw, offset)
    offset = of._skip(raw, offset, 4)
    return offset

  def _body_length (self):
    return 8

  def _show (self, prefix):
    s = ''
    s += prefix + ('subtype: %s\n' % (self.subtype,))
    s += prefix + ('ethertype: %s\n' % (self.ethertype,))
    return s


class nx_action_pop_mpls (of.ofp_action_vendor_base):
  """
  Pop an MPLS label
  """
  def _init (self, kw):
    self.vendor = NX_VENDOR_ID
    self.subtype = NXAST_POP_MPLS
    self.ethertype = None # Purposely bad

  def _eq (self, other):
    if self.subtype != other.subtype: return False
    if self.ethertype != other.ethertype: return False
    return True

  def _pack_body (self):
    p = struct.pack('!HHI', self.subtype, self.ethertype, 0) # 4 bytes pad
    return p

  def _unpack_body (self, raw, offset, avail):
    offset,(self.subtype,self.ethertype) = of._unpack('!HH', raw, offset)
    offset = of._skip(raw, offset, 4)
    return offset

  def _body_length (self):
    return 8

  def _show (self, prefix):
    s = ''
    s += prefix + ('subtype: %s\n' % (self.subtype,))
    s += prefix + ('ethertype: %s\n' % (self.ethertype,))
    return s


class nx_action_resubmit (of.ofp_action_vendor_base):
  """
  Used with both resubmit and resubmit_table.

  Generally, you want to use one of the factory methods.
  """
  @classmethod
  def resubmit (cls, in_port = of.OFPP_IN_PORT):
    return cls(subtype = NXAST_RESUBMIT, in_port = in_port, table = 0)

  @classmethod
  def resubmit_table (cls, table = 255, in_port = of.OFPP_IN_PORT):
    return cls(subtype = NXAST_RESUBMIT_TABLE, in_port = in_port,
               table = table)

  def _init (self, kw):
    self.vendor = NX_VENDOR_ID
    self.subtype = NXAST_RESUBMIT
    self.in_port = None # New in_port for checking flow table
    self.table = None   # NXAST_RESUBMIT_TABLE: table to use

  def _eq (self, other):
    if self.subtype != other.subtype: return False
    if self.in_port != other.in_port: return False
    if self.table != other.table: return False
    return True

  def _pack_body (self):
    p = struct.pack('!HHB', self.subtype, self.in_port, self.table)
    p += of._PAD3
    return p

  def _unpack_body (self, raw, offset, avail):
    offset,(self.subtype,self.in_port,self.table) = \
        of._unpack('!HHB', raw, offset)
    offset = of._skip(raw, offset, 3)
    return offset

  def _body_length (self):
    return 8

  def _show (self, prefix):
    s = ''
    s += prefix + ('subtype: %s\n' % (self.subtype,))
    s += prefix + ('in_port: %s\n' % (self.in_port,))
    s += prefix + ('table: %s\n' % (self.table,))
    return s


class nx_action_set_tunnel (of.ofp_action_vendor_base):
  """
  Set a 32-bit tunnel ID

  See also: nx_action_set_tunnel64
  """
  def _init (self, kw):
    self.vendor = NX_VENDOR_ID
    self.subtype = NXAST_SET_TUNNEL
    self.tun_id = None # Must set

  def _eq (self, other):
    if self.subtype != other.subtype: return False
    if self.tun_id != other.tun_id: return False
    return True

  def _pack_body (self):
    p = struct.pack('!HHI', self.subtype, 0, self.tun_id)
    return p

  def _unpack_body (self, raw, offset, avail):
    offset,(self.subtype,) = of._unpack('!H', raw, offset)
    offset = of._skip(raw, offset, 2)
    offset,(self.tun_id,) = of._unpack('!I', raw, offset)
    return offset

  def _body_length (self):
    return 8

  def _show (self, prefix):
    s = ''
    s += prefix + ('subtype: %s\n' % (self.subtype,))
    s += prefix + ('tub_id: %s\n' % (self.tun_id,))
    return s


class nx_action_set_tunnel64 (of.ofp_action_vendor_base):
  """
  Set a 64-bit tunnel ID

  See also: nx_action_set_tunnel
  """
  def _init (self, kw):
    self.vendor = NX_VENDOR_ID
    self.subtype = NXAST_SET_TUNNEL64
    self.tun_id = None # Must set

  def _eq (self, other):
    if self.subtype != other.subtype: return False
    if self.tun_id != other.tun_id: return False
    return True

  def _pack_body (self):
    p = struct.pack('!HHIQ', self.subtype, 0, 0, self.tun_id)
    return p

  def _unpack_body (self, raw, offset, avail):
    offset,(self.subtype,) = of._unpack('!H', raw, offset)
    offset = of._skip(raw, offset, 6)
    offset,(self.tun_id,) = of._unpack('!Q', raw, offset)
    return offset

  def _body_length (self):
    return 16

  def _show (self, prefix):
    s = ''
    s += prefix + ('subtype: %s\n' % (self.subtype,))
    s += prefix + ('tub_id: %s\n' % (self.tun_id,))
    return s


class nx_action_fin_timeout (of.ofp_action_vendor_base):
  def _init (self, kw):
    self.vendor = NX_VENDOR_ID
    self.subtype = NXAST_FIN_TIMEOUT
    self.fin_idle_timeout = 1 # New idle timeout, if nonzero.
    self.fin_hard_timeout = 1 # New hard timeout, if nonzero.

  def _eq (self, other):
    if self.subtype != other.subtype: return False
    if self.fin_idle_timeout != other.fin_idle_timeout: return False
    if self.fin_hard_timeout != other.fin_hard_timeout: return False
    return True

  def _pack_body (self):
    p = struct.pack('!HHH', self.subtype, self.fin_idle_timeout,
                    self.fin_hard_timeout)
    p += of._PAD2
    return p

  def _unpack_body (self, raw, offset, avail):
    offset,(self.subtype,self.fin_idle_timeout,self.fin_hard_timeout) = \
        of._unpack('!HHH', raw, offset)
    offset = of._skip(raw, offset, 2)
    return offset

  def _body_length (self):
    return 8

  def _show (self, prefix):
    s = ''
    s += prefix + ('subtype: %s\n' % (self.subtype,))
    s += prefix + ('fin_idle_timeout: %s\n' % (self.fin_idle_timeout,))
    s += prefix + ('fin_hard_timeout: %s\n' % (self.fin_hard_timeout,))
    return s

class nx_action_exit (of.ofp_action_vendor_base):
  def _init (self, kw):
    self.vendor = NX_VENDOR_ID
    self.subtype = NXAST_EXIT

  def _eq (self, other):
    if self.subtype != other.subtype: return False
    return True

  def _pack_body (self):
    p = struct.pack('!H', self.subtype)
    p += of._PAD6
    return p

  def _unpack_body (self, raw, offset, avail):
    offset,(self.subtype,) = \
        of._unpack('!H', raw, offset)
    offset = of._skip(raw, offset, 6)
    return offset

  def _body_length (self):
    return 8

  def _show (self, prefix):
    s = ''
    s += prefix + ('subtype: %s\n' % (self.subtype,))
    return s


class nx_action_dec_ttl (of.ofp_action_vendor_base):
  def _init (self, kw):
    self.vendor = NX_VENDOR_ID
    self.subtype = NXAST_DEC_TTL

  def _eq (self, other):
    if self.subtype != other.subtype: return False
    return True

  def _pack_body (self):
    p = struct.pack('!H', self.subtype)
    p += of._PAD6
    return p

  def _unpack_body (self, raw, offset, avail):
    offset,(self.subtype,) = of._unpack('!H', raw, offset)
    offset = of._skip(raw, offset, 6)
    return offset

  def _body_length (self):
    return 8

  def _show (self, prefix):
    s = ''
    s += prefix + ('subtype: %s\n' % (self.subtype,))
    return s


# -----------------------------------------------------------------------
# Learn action
# -----------------------------------------------------------------------

class nx_action_learn (of.ofp_action_vendor_base):
  """
  Allows table entries to add table entries

  There are different ways of adding flow_mod_specs.  For example, the
  following are all equivalent:

  learn = nx.nx_action_learn(table_id=1,hard_timeout=10)
  fms = nx.flow_mod_spec.new # Just abbreviating this
  learn.spec.append(fms( field=nx.NXM_OF_VLAN_TCI, n_bits=12 ))
  learn.spec.append(fms( field=nx.NXM_OF_ETH_SRC, match=nx.NXM_OF_ETH_DST ))
  learn.spec.append(fms( field=nx.NXM_OF_IN_PORT, output=True ))

  learn = nx.nx_action_learn(table_id=1,hard_timeout=10)
  learn.spec.chain(
      field=nx.NXM_OF_VLAN_TCI, n_bits=12).chain(
      field=nx.NXM_OF_ETH_SRC, match=nx.NXM_OF_ETH_DST).chain(
      field=nx.NXM_OF_IN_PORT, output=True)

  learn = nx.nx_action_learn(table_id=1,hard_timeout=10)
  learn.spec = [
      nx.flow_mod_spec(src=nx.nx_learn_src_field(nx.NXM_OF_VLAN_TCI),
                        n_bits=12),
      nx.flow_mod_spec(src=nx.nx_learn_src_field(nx.NXM_OF_ETH_SRC),
                        dst=nx.nx_learn_dst_match(nx.NXM_OF_ETH_DST)),
      nx.flow_mod_spec(src=nx.nx_learn_src_field(nx.NXM_OF_IN_PORT),
                        dst=nx.nx_learn_dst_output())
  ]

  """

  def _init (self, kw):
    self.vendor = NX_VENDOR_ID
    self.subtype = NXAST_LEARN

    self.idle_timeout = 0
    self.hard_timeout = 0
    self.priority = of.OFP_DEFAULT_PRIORITY
    self.cookie = 0
    self.flags = 0
    self.table_id = 0
    self.fin_idle_timeout = 0
    self.fin_hard_timeout = 0

    self.spec = flow_mod_spec_chain()

  @property
  def table (self):
    """
    Synonym for table_id
    """
    return self.table_id
  @table.setter
  def table (self, value):
    self.table_id = value

  def _eq (self, other):
    if self.subtype != other.subtype: return False
    if self.idle_timeout != other.idle_timeout: return False
    if self.hard_timeout != other.hard_timeout: return False
    if self.priority != other.priority: return False
    if self.cookie != other.cookie: return False
    if self.flags != other.flags: return False
    if self.table_id != other.table_id: return False
    if self.fin_idle_timeout != other.fin_idle_timeout: return False
    if self.fin_hard_timeout != other.fin_hard_timeout: return False
    return True

  def _pack_body (self):
    p = struct.pack('!HHHHQHBBHH',
                    self.subtype,
                    self.idle_timeout,
                    self.hard_timeout,
                    self.priority,
                    self.cookie,
                    self.flags,
                    self.table_id,
                    0,
                    self.fin_idle_timeout,
                    self.fin_hard_timeout)
    for fs in self.spec:
      p += fs.pack()
    if len(p) % 8:
      p += '\x00' * (8-(len(p)%8))
    return p

  def _unpack_body (self, raw, offset, avail):
    orig_offset = offset
    offset,(self.subtype, self.idle_timeout, self.hard_timeout,
            self.priority, self.cookie, self.flags, self.table_id, _,
            self.fin_idle_timeout,
            self.fin_hard_timeout) = of._unpack('!HHHHQHBBHH', raw, offset)
    avail -= (2+2+2+2+8+2+1+1+2+2)
    assert (avail & 1) == 0
    while avail > 0:
      newoff, fms = flow_mod_spec.unpack_new(raw, offset)
      if fms is None: break
      self.spec.append(fms)
      avail -= (newoff - offset)
      offset = newoff
    length = offset - orig_offset
    if length % 8:
      offset = of._skip(raw, offset, 8 - (length%8))
    return offset

  def _show (self, prefix):
    s = ''
    ff = ('idle_timeout hard_timeout priority cookie flags table_id '
         'fin_idle_timeout fin_hard_timeout').split()
    for f in ff:
      s += prefix
      s += f + ": "
      s += str(getattr(self, f))
      s += "\n"
    return s


NX_LEARN_SRC_FIELD     = 0
NX_LEARN_SRC_IMMEDIATE = 1

NX_LEARN_DST_MATCH     = 0
NX_LEARN_DST_LOAD      = 1
NX_LEARN_DST_OUTPUT    = 2

class nx_learn_spec (object):
  _is_src = False
  _is_dst = False
  data = None
  n_bits = None
  value = None

  def pack (self):
    return self.data if self.data else b''

  @classmethod
  def unpack_subclass (cls, spec, n_bits, raw, offset):
    """
    Returns (new_offset, object)
    """
    assert cls is not nx_learn_spec, "Must call on subclass"
    c = _flow_mod_spec_to_class(cls._is_src, spec)
    offset,o = c.unpack_new(n_bits, raw, offset)
    return offset, o

  @classmethod
  def unpack_new (cls, n_bits, raw, offset):
    """
    Returns (new_offset, object)
    """
    o = cls.__new__(cls)
    o.n_bits = n_bits
    datalen = len(o)
    if datalen != 0:
      offset,o.data = of._read(raw, offset, datalen)
    return offset,o

  def __len__ (self):
    # Implement.  Can't use .data field.
    assert False, "__len__ unimplemented in " + type(self).__name__

  def __repr__ (self):
    return "<%s n_bits:%s>" % (type(self).__name__, self.n_bits)


class nx_learn_spec_src (nx_learn_spec):
  _is_src = True

class nx_learn_spec_dst (nx_learn_spec):
  _is_dst = True


class _field_and_match (object):
  """
  Common functionality for src_field and dst_match
  """
  def __init__ (self, field, ofs = 0, n_bits = None):
    #if type(field) is type: field = field()
    data = field().pack(omittable = False, header_only = True)
    data += struct.pack("!H", ofs)
    if n_bits is None:
      n_bits = field._get_size_hint() - ofs
    elif n_bits < 0:
      n_bits = field._get_size_hint() - ofs - n_bits
    self.n_bits = n_bits
    self.data = data

  @property
  def ofs (self):
    return struct.unpack_from("!H", self.data, 4)[0]

  @property
  def field (self):
    t,_,_ = nxm_entry.unpack_header(self.data, 0)
    c = _nxm_type_to_class.get(t)
    if c is None:
      attrs = {'_nxm_type':t}
      attrs['_nxm_length'] = length/2 if has_mask else length
      c = type('nxm_type_'+str(t), (NXM_GENERIC,), attrs)
    return c

  def __len__ (self):
    return 6


class nx_learn_src_field (_field_and_match, nx_learn_spec_src):
  value = NX_LEARN_SRC_FIELD

  @property
  def matching (self):
    """
    Returns a corresponding nx_learn_dst_match
    """
    return nx_learn_dst_match(self.field, self.ofs, self.n_bits)


class nx_learn_src_immediate (nx_learn_spec_src):
  """
  An immediate value for a flow spec

  Probably generally a good idea to use one of the factory methods, e.g., u8().
  """
  value = NX_LEARN_SRC_IMMEDIATE

  def __init__ (self, data, n_bits = None):
    if n_bits is None:
      assert (len(data)&1) == 0, "data needs pad; n_bits cannot be inferred"
      n_bits = len(data)*8
    else:
      assert len(data)*8 >= n_bits, "n_bits larger than data"
    self.n_bits = n_bits
    self.data = data

  @classmethod
  def u8 (cls, dst, value):
    return cls(struct.pack("!H", value))

  @classmethod
  def u16 (cls, dst, value):
    return cls(struct.pack("!H", value))

  @classmethod
  def u32 (cls, dst, value):
    return cls(struct.pack("!L", value))

  def __len__ (self):
    return ((self.n_bits+15) // 16) * 2


class nx_learn_dst_match (_field_and_match, nx_learn_spec_dst):
  value = NX_LEARN_DST_MATCH


class nx_learn_dst_load (nx_learn_spec_dst):
  value = NX_LEARN_DST_LOAD

  def __init__ (self, field, ofs = 0, n_bits = None):
    data = field().pack(omittable = False, header_only = True)
    data += struct.pack("!H", ofs)
    if n_bits is None:
      n_bits = field._get_size_hint() - ofs
    elif n_bits < 0:
      n_bits = field._get_size_hint() - ofs - n_bits
    self.n_bits = n_bits
    self.data = data

  def __len__ (self):
    return ((self.n_bits+15) // 16) * 2


class nx_learn_dst_output (nx_learn_spec_dst):
  value = NX_LEARN_DST_OUTPUT

  def __init__ (self, dummy = True):
    assert dummy is True
    super(nx_learn_dst_output,self).__init__()

  def __len__ (self):
    return 0


def _flow_mod_spec_to_class (is_src, val):
  #TODO: Use a class registry and decorator for these instead of this hack
  if is_src:
    d = {
          NX_LEARN_SRC_FIELD: nx_learn_src_field,
          NX_LEARN_SRC_IMMEDIATE: nx_learn_src_immediate,
        }
  else:
    d = {
          NX_LEARN_DST_MATCH: nx_learn_dst_match,
          NX_LEARN_DST_LOAD: nx_learn_dst_load,
          NX_LEARN_DST_OUTPUT: nx_learn_dst_output,
        }

  return d.get(val)


class flow_mod_spec_chain (list):
  def chain (self, *args, **kw):
    self.append(flow_mod_spec.new(*args,**kw))
    return self

#class _meta_fms (type):
#  @property
#  def chain (self):
#    return _flow_mod_spec_chain()

class flow_mod_spec (object):
#  __metaclass__ = _meta_fms
  @classmethod
  def create (cls, src, dst = None, n_bits = None):
    #TODO: Remove me
    return cls(src, dst, n_bits)

  def __init__ (self, src, dst = None, n_bits = None):
    assert src._is_src
    if dst is None:
      # Assume same as src
      assert type(src) == nx_learn_src_field
      dst = src.matching
    assert dst._is_dst

    #TODO: Check whether there's enough space in dst
    # (This will require figuring out what the right length for output is...
    #  16 bits?)
    if n_bits is None:
      n_bits = src.n_bits
      if n_bits is None:
        n_bits = dst.n_bits
      else:
        if dst.n_bits is not None and dst.n_bits > n_bits:
          raise RuntimeError("dst n_bits greater than source n_bits "
                             "(%s and %s); cannot infer" % (n_bits,dst.n_bits))
      if n_bits is None:
        raise RuntimeError("cannot infer n_bits")

    #o = cls.__new__(cls)
    #o.src = src
    #o.dst = dst
    #o.n_bits = n_bits
    #return o
    #return cls(src, dst, n_bits)
    self.src = src
    self.dst = dst
    self.n_bits = n_bits

  def __repr__ (self):
    return "%s(src=%s, dst=%s, n_bits=%s)" % (
      type(self).__name__, self.src, self.dst, self.n_bits)

#  @staticmethod
#  def chain ():
#    return _flow_mod_spec_chain()

  @classmethod
  def new (cls, src=None, dst=None, **kw):
    if src is not None: kw['src'] = src
    if dst is not None: kw['dst'] = dst
    src = None
    dst = None
    srcarg = ()
    dstarg = ()
    srckw = {}
    dstkw = {}
    src_inst = None
    dst_inst = None
    n_bits = None

    for k,v in kw.iteritems():
      # This is handy, though there's potentially future ambiguity
      s = globals().get('nx_learn_' + k)
      if not s:
        s = globals().get('nx_learn_src_' + k)
        if not s:
          s = globals().get('nx_learn_dst_' + k)
      if not s:
        if k.startswith("src_"):
          srckw[k[4:]] = v
        elif k.startswith("dst_"):
          dstkw[k[4:]] = v
        elif k == "src":
          assert isinstance(v, nx_learn_spec_src)
          src_inst = v
        elif k == "dst":
          assert isinstance(v, nx_learn_spec_dst)
          dst_inst = v
        elif k == "n_bits":
          n_bits = v
        else:
          raise RuntimeError("Don't know what to do with '%s'", (k,))
        continue

      if s._is_src:
        assert src is None, "src already set"
        src = s
        srcarg = (v,)
      if s._is_dst:
        assert dst is None, "dst already set"
        dst = s
        dstarg = (v,)

    if src_inst:
      assert src is None, "can't set src and a spec type"
      assert len(srckw) == 0, "can't set src params with src instance"
    else:
      assert src is not None, "no src set"
      src_inst = src(*srcarg,**srckw)

    if dst_inst:
      assert dst is None, "can't set dst and a spec type"
      assert len(dstkw) == 0, "can't set dst params with dst instance"
    else:
      if dst is not None: dst_inst = dst(*dstarg,**dstkw)

    return cls.create(src_inst, dst_inst, n_bits)

  chain = new

  #def __init__ (self, src=None, dst=None, n_bits=0):
  #  self.src = src
  #  self.dst = dst
  #  self.n_bits = n_bits

  def pack (self):
    assert isinstance(self.src, nx_learn_spec_src),str(self.src)
    assert isinstance(self.dst, nx_learn_spec_dst),str(self.dst)
    assert self.n_bits < 1024
    v = self.src.value << 13 | self.dst.value << 11 | self.n_bits
    p = struct.pack("!H", v)
    p += self.src.pack() + self.dst.pack()
    return p

  @classmethod
  def unpack_new (cls, raw, offset = 0):
    """
    May return a None object if it's padding
    """
    offset,(v,) = of._unpack("!H", raw, offset)
    if v == 0:
      # Special case for padding
      return offset, None

    n_bits = v & 1023

    offset,src = nx_learn_spec_src.unpack_subclass((v >> 13) & 1,
        n_bits, raw, offset)
    offset,dst = nx_learn_spec_dst.unpack_subclass((v >> 11) & 3,
        n_bits, raw, offset)

    return offset, cls(src, dst, n_bits)


# -----------------------------------------------------------------------
# NXM support
# -----------------------------------------------------------------------

#def conv (n, s):
#  if s == 0: return b''
#  nn = struct.pack("B", n & 0xff)
#  n >>= 8
#  return conv(n, s - 1) + nn

class _nxm_raw (object):
  def _pack_value (self, v):
    return v
  def _unpack_value (self, v):
    return v


class _nxm_numeric (object):
  _size_table = [None, "!B", "!H", None, "!L", None, None, None, "!Q"]

  def _pack_value (self, v):
    size = self._size_table[self._nxm_length]
    return struct.pack(size, v)

  def _unpack_value (self, v):
    try:
      size = self._size_table[self._nxm_length]
      return struct.unpack(size, v)[0]
    except:
      raise RuntimeError("Can't unpack %i bytes for %s"
                         % (self._nxm_length, self.__class__.__name__))

class _nxm_ip (object):
  """
  Allows setting of IP address in many formats

  The value can be any format known by IPAddr.  If it's a string, it can
  also have a trailing /netmask or /cidr-bits.  If it's a tuple, the
  first is assumed to be any kind of IP address and the second is either
  a netmask or the number of network bits.
  """

  @property
  def value (self):
    return self._unpack_value(self._value)
  @value.setter
  def value (self, value):
    if isinstance(value, tuple) or isinstance(value, list):
      assert len(value) == 2
      ip = value[0]
      self.mask = value[1]
      #if isinstance(mask, (int,long)):
      #  self.mask = mask
    elif isinstance(value, basestring) and len(value)>4 and '/' in value:
      temp = parse_cidr(value, infer=False)
      ip = temp[0]
      self.mask = 32 if temp[1] is None else temp[1]
    else:
      ip = value

    self._value = self._pack_value(ip)

  def _pack_value (self, v):
    return IPAddr(v, networkOrder=False).toRaw()
  def _unpack_value (self, v):
    return IPAddr(v, networkOrder=True)
  def _pack_mask (self, v):
    if isinstance(v, (int, long)):
      # Assume CIDR
      if v > 32: v = 32
      elif v < 0: v = 0
      n = (0xffFFffFF << (32-v)) & 0xffFFffFF
      return IPAddr(n, networkOrder=False).toRaw()
    else:
      return IPAddr(v).toRaw()
  #def _unpack_mask (self, v):
  #  # Special unpacking for CIDR-style?


class _nxm_ipv6 (object):
  """
  Placeholder until we have real IPv6 support

  Allows setting of IP address in many formats

  The value can be any format known by IPAddr.  If it's a string, it can
  also have a trailing /netmask or /cidr-bits.  If it's a tuple, the
  first is assumed to be any kind of IP address and the second is either
  a netmask or the number of network bits.
  """

  @property
  def value (self):
    return self._unpack_value(self._value)
  @value.setter
  def value (self, value):
    if isinstance(value, tuple) or isinstance(value, list):
      assert len(value) == 2
      ip = value[0]
      self.mask = value[1]
    elif isinstance(value, (unicode,str)):
      ip,mask = IPAddr6.parse_cidr(value, allow_host = True)
      #self.mask = 128 if mask is None else mask
      self.mask = mask
    else:
      ip = value

    self._value = self._pack_value(ip)

  def _pack_value (self, v):
    return IPAddr6(v).raw
  def _unpack_value (self, v):
    return IPAddr6(v, raw=True)
  def _pack_mask (self, v):
    if isinstance(v, (int,long)):
      # Assume CIDR
      if v > 128: v = 128
      elif v < 0: v = 0
      n = (((1<<128)-1) << (128-v)) & ((1<<128)-1)
      return IPAddr6.from_num(n).raw
    else:
      return IPAddr6(v).raw
#  def _unpack_mask (self, v):
#    # Special unpacking for CIDR-style?


class _nxm_ether (object):
  def _pack_value (self, v):
    return EthAddr(v).toRaw()
  def _unpack_value (self, v):
    return EthAddr(v)


_nxm_type_to_class = {}
_nxm_name_to_type = {}

class nxm_entry (object):
  #_nxm_type = _make_type(0x, )
  #_nxm_length = # bytes of data not including mask (double for mask)
  _size_hint = None
  _force_mask = False

  #TODO: make mask-omittable a class-level attribute?

  @classmethod
  def _get_size_hint (self):
    """
    Number of significant bits
    """
    if self._size_hint is None:
      return self._nxm_length * 8
    return self._size_hint

  @property
  def nxm_vendor (self):
    return self._nxm_type >> 7
  @property
  def nxm_field (self):
    return self._nxm_type & 0x7f

  @staticmethod
  def unpack_header (raw, offset):
    """
    Parses the NXM_HEADER

    Returns (type,has_mask,length)
    """
    h, = struct.unpack_from("!L", raw, offset)
    offset += 4
    t = h >> 9
    has_mask = (h & (1<<8)) != 0
    length = h & 0x7f
    return t,has_mask,length

  @staticmethod
  def unpack_new (raw, offset):
    t,has_mask,length = nxm_entry.unpack_header(raw, offset)
    offset += 4
    offset,data = of._read(raw, offset, length)
    mask = None
    if has_mask:
      assert not (length & 1), "Odd length with mask"
      mask = data[length/2:]
      data = data[:length/2]

    #NOTE: Should use _class_for_nxm_header?
    c = _nxm_type_to_class.get(t)
    if c is None:
      #TODO: Refactor with learn spec field property?

      e = NXM_GENERIC()
      e._nxm_length = length
      if has_mask:
        e._nxm_length /= 2
      e._nxm_type = t

      # Alternate approach: Generate new subclass. To do: cache gen'd types?
      #attrs = {'_nxm_type':t}
      #attrs['_nxm_length'] = length/2 if has_mask else length
      #c = type('nxm_type_'+str(t), (NXM_GENERIC,), attrs)
      #e = c()
    else:
      e = c()
    assert data is not None
    assert len(data) == e._nxm_length, "%s != %s" % (len(data), e._nxm_length)
    assert mask is None or len(mask) == e._nxm_length
    e._value = data
    e._mask = mask
    if mask is not None:
      e._force_mask = True

    return offset, e

  def clone (self):
    n = self.__class__()
    n._nxm_type = self._nxm_type
    n._nxm_length = self._nxm_length
    n._force_mask = self._force_mask
    n.mask = self.mask
    n.value = self.value

    return n

  def __init__ (self, value = None, mask = None):
    super(nxm_entry, self).__init__()
    self._value = None
    self._mask = None
    if value is None and mask is None: return # Sloppy
    self.mask = mask
    self.value = value # In case value overrides mask (IP), do value last

  def get_length (self, omittable = False):
    # Calculating length is slightly tricky with mask omission, etc.,
    # so just pack it and find out, rather than duplicate the logic
    # here.
    return len(self.pack(omittable))

  def __len__ (self):
    return self.get_length()

  def _unpack_mask (self, m):
    return self._unpack_value(m)
  def _pack_mask (self, m):
    return self._pack_value(m)

  @property
  def is_reg (self):
    return False
  @property
  def allow_mask (self):
    return False

  @property
  def value (self):
    return self._unpack_value(self._value)
  @value.setter
  def value (self, value):
    self._value = self._pack_value(value)

  @property
  def mask (self):
    if self._mask is None: return None
    return self._unpack_mask(self._mask)
  @mask.setter
  def mask (self, value):
    if self.allow_mask is False:
      if value is not None:
        raise RuntimeError("entry has no mask")
    if value is None:
      # This would normally be up to the pack function, but we add it
      # here as a special case
      self._mask = None
    else:
      self._mask = self._pack_mask(value)

  def __eq__ (self, other):
    if type(self) != type(other): return False
    if self._nxm_type != other._nxm_type: return False
    if self.value != other.value: return False
    if self.mask != other.mask: return False
    if self.is_reg != other.is_reg: return False
    return True

  def pack (self, omittable = False, header_only = False):
    h = self._nxm_type << 9
    mask = self._mask

    if mask is not None:
      assert len(mask) == self._nxm_length, "mask is wrong length"

      if (mask.count("\x00") == self._nxm_length) and omittable:
        return b''

      if (mask.count("\xff") == self._nxm_length):
        mask = None

    if mask is None and self._force_mask:
      mask = "\xff" * self._nxm_length

    if mask is not None:
      h |= (1 << 8)
      h |= (self._nxm_length * 2)
    else:
      h |= self._nxm_length

    r = struct.pack("!L", h)
    if header_only: return r

    value = self._value
    assert value is not None
    assert len(value) == self._nxm_length, "value is wrong length"

    r += value
    if mask is not None:
      assert 0 == sum(ord(v)&(0xff&~ord(m)) for v,m in zip(value,mask)), \
             "nonzero masked bits"
      r += mask

    return r

  def __str__ (self):
    r = self.__class__.__name__ + "(" + str(self.value)
    if self.mask is not None:
      if self.mask.raw != ("\xff" * self._nxm_length):
        r += "/" + str(self.mask)
    #if self.is_reg: r += "[r]"
    return r + ")"

  def __repr__ (self):
    return str(self)


class _nxm_numeric_entry (_nxm_numeric, nxm_entry):
  pass

class _nxm_maskable (object):
  @property
  def allow_mask (self):
    return True

class _nxm_maskable_numeric_entry (_nxm_maskable, _nxm_numeric_entry):
  pass

class _nxm_reg (_nxm_maskable_numeric_entry):
  @property
  def is_reg (self):
    return True

class NXM_GENERIC (_nxm_raw, nxm_entry):
  @property
  def allow_mask (self):
    return True

  def __str__ (self):
    r = "NXM_%08x_%i" % (self.nxm_vendor, self.nxm_field)
    r += "("
    r += "".join("%02x" % (ord(x),) for x in self.value)
    #+ repr(self.value)
    if self.mask is not None:
      if self.mask != ("\xff" * self._nxm_length):
        r += "/" + repr(self.mask)
    return r + ")"


def _make_type (vendor, field):
  """
  Takes an NXM vendor and field and returns the whole type field
  """
  return (vendor << 7) | field


def _fix_types (t):
  """
  Helper for _make_nxm(_w)

  Normalizes lists of superclasses
  """
  try:
    _ = t[0]
    t = list(t)
  except:
    t = [t]
  ok = False
  for tt in t:
    if _issubclass(tt, nxm_entry):
      ok = True
      break
  if not ok:
    t.append(nxm_entry)
  #t = tuple(t)
  return t


def _make_nxm (__name, __vendor, __field, __len = None, type = None,
                 **kw):
  """
  Make a simple NXM entry class
  """
  if type is None:
    type = (_nxm_numeric_entry,)
  else:
    type = _fix_types(type)

  t = _make_type(__vendor, __field)
  kw['_nxm_type'] = t
  if __len is not None: kw['_nxm_length'] = __len
  import __builtin__
  typ = __builtin__.type
  c = typ(__name, tuple(type), kw)
  _nxm_type_to_class[t] = c
  _nxm_name_to_type[__name] = t
  assert __name not in globals()
  globals()[__name] = c
  return c


def _make_nxm_w (*args, **kw):
  """
  Make a simple wildcarded NXM entry class
  """
  t = _fix_types(kw.pop('type', _nxm_maskable_numeric_entry))
  ok = False
  for tt in t:
    if _issubclass(tt, _nxm_maskable):
      ok = True
      break
  if not ok:
    t.insert(0, _nxm_maskable)

  return _make_nxm(*args, type=t, **kw)


def _class_for_nxm_header (raw):
  """
  Given a raw nxm_entry header, return corresponding class

  If we don't have a class for this header type, we generate one.
  """
  t,has_mask,length = nxm_entry.unpack_header(raw, 0)
  c = _nxm_type_to_class.get(t)
  if c: return c

  # Need to generate a new nxm_entry type.
  # This code is totally untested.
  vendor = (t >> 7) & 0xffff
  field = t & 0x7f
  typename = "NXM_UNKNOWN_"
  typename += "%04x_%02x" % (vendor,field)
  if has_mask: typename += "_MASKABLE"
  types = [_nxm_raw]
  if has_mask:
    types.append(_nxm_maskable)
  return _make_nxm(typename, vendor, field, length, types)


# -----------------------------------------------------------------------
# OpenFlow 1.0-compatible nxm_entries
# -----------------------------------------------------------------------

_make_nxm("NXM_OF_IN_PORT", 0, 0, 2)

_make_nxm_w("NXM_OF_ETH_DST", 0, 1, 6, type=_nxm_ether)
_make_nxm_w("NXM_OF_ETH_SRC", 0, 2, 6, type=_nxm_ether)

# Packet ethertype
_make_nxm("NXM_OF_ETH_TYPE", 0, 3, 2)

_make_nxm_w("NXM_OF_VLAN_TCI", 0, 4, 2)

_make_nxm_w("NXM_OF_IP_TOS", 0, 5, 1)

_make_nxm_w("NXM_OF_IP_PROTO", 0, 6, 1)

_make_nxm_w("NXM_OF_IP_SRC", 0, 7, 4, type=_nxm_ip)
_make_nxm_w("NXM_OF_IP_DST", 0, 8, 4, type=_nxm_ip)

# Maskable in OVS 1.6+
_make_nxm_w("NXM_OF_TCP_SRC", 0, 9, 2)
_make_nxm_w("NXM_OF_TCP_DST", 0, 10, 2)

# Maskable in OVS 1.6+
_make_nxm_w("NXM_OF_UDP_SRC", 0, 11, 2)
_make_nxm_w("NXM_OF_UDP_DST", 0, 12, 2)

_make_nxm("NXM_OF_ICMP_TYPE", 0, 13, 1)
_make_nxm("NXM_OF_ICMP_CODE", 0, 14, 1)

_make_nxm("NXM_OF_ARP_OP", 0, 15, 2)

# The IP address in an ethernet+IP ARP packet
# Fully maskable in OVS 1.8+, only CIDR-compatible masks before that
_make_nxm_w("NXM_OF_ARP_SPA", 0, 16, 4, type=_nxm_ip)
_make_nxm_w("NXM_OF_ARP_TPA", 0, 17, 4, type=_nxm_ip)


# -----------------------------------------------------------------------
# Nicira register nxm_entries
# -----------------------------------------------------------------------

NXM_NX_MAX_REGS = 16

# Array with all the register entries indexed by their number
# (they are also available as NXM_NX_REG0, etc.)
NXM_NX_REG = []

def _init_regs ():
  for i in range(0, NXM_NX_MAX_REGS):
    assert len(NXM_NX_REG) == i
    n = "NXM_NX_REG" + str(i)
    r = _make_nxm_w(n, 1, i, 4, type=_nxm_reg)
    NXM_NX_REG.append(r)
    globals()[n] = r
_init_regs()

def NXM_IS_NX_REG (o):
  """
  Simulates macro from OVS
  """
  return o.is_reg


# -----------------------------------------------------------------------
# Nicira nxm_entries
# -----------------------------------------------------------------------

# Tunnel properties
_make_nxm_w("NXM_NX_TUN_ID", 1, 16, 8)
_make_nxm_w("NXM_NX_TUN_IPV4_SRC", 1, 31, 4, type=_nxm_ip)
_make_nxm_w("NXM_NX_TUN_IPV4_DST", 1, 32, 4, type=_nxm_ip)

# The ethernet address in an ethernet+IP ARP packet
_make_nxm("NXM_NX_ARP_SHA", 1, 17, 6, type=_nxm_ether)
_make_nxm("NXM_NX_ARP_THA", 1, 18, 6, type=_nxm_ether)

# Fully maskable in OVS 1.8+, only CIDR-compatible masks before that
_make_nxm_w("NXM_NX_IPV6_SRC", 1, 19, 16, type=_nxm_ipv6)
_make_nxm_w("NXM_NX_IPV6_DST", 1, 20, 16, type=_nxm_ipv6)

_make_nxm("NXM_NX_ICMPV6_TYPE", 1, 21, 1)
_make_nxm("NXM_NX_ICMPV6_CODE", 1, 22, 1)

# IPv6 Neighbor Discovery target address
_make_nxm_w("NXM_NX_ND_TARGET", 1, 23, 16, type=_nxm_ipv6)

# IPv6 Neighbor Discovery source link-layer address
_make_nxm("NXM_NX_ND_SLL", 1, 24, 6, type=_nxm_ether)

# IPv6 Neighbor Discovery target link-layer address
_make_nxm("NXM_NX_ND_TLL", 1, 25, 6, type=_nxm_ether)

# Bits for NXM_NX_IP_FRAG
NX_IP_FRAG_ANY = 1   # It's the first/only fragment
NX_IP_FRAG_LATER = 3 # It's not the first fragment

# IP fragment information
#TODO: A custom type or types would make this nicer to use.
#      For now, use with above flags.
_make_nxm_w("NXM_NX_IP_FRAG", 1, 26, 1)

# IPv6 flow label
_make_nxm("NXM_NX_IPV6_LABEL", 1, 27, 4)

# IP ECN bits
_make_nxm("NXM_NX_IP_ECN", 1, 28, 1)

_make_nxm("NXM_NX_IP_TTL", 1, 29, 1)

# Flow cookie
_make_nxm_w("NXM_NX_COOKIE", 1, 30, 8)


# MPLS label, traffic class, and bottom-of-stack flag
# Note that these are from OpenFlow 1.2 and I think BOS is from 1.3,
# so technically these don't belong here.  They do work with OVS through
# NXM match and flow mod, though.
_make_nxm("OXM_OF_MPLS_LABEL", 0x8000, 34, 4, _size_hint=20)
_make_nxm("OXM_OF_MPLS_TC", 0x8000, 35, 1, _size_hint=3)
_make_nxm("OXM_OF_MPLS_BOS", 0x8000, 36, 1, _size_hint=1)


#@vendor_s_message('NXT_SET_ASYNC_CONFIG', 19)
class nx_async_config (nicira_base):
  subtype = NXT_SET_ASYNC_CONFIG
  _MIN_LENGTH = 40
  def _init (self, kw):
    # For master or other role
    self.packet_in_mask = 0
    self.port_status_mask = 0
    self.flow_removed_mask = 0

    # For slave role
    self.packet_in_mask_slave = 0
    self.port_status_mask_slave = 0
    self.flow_removed_mask_slave = 0

  def set_packet_in (self, bit, master=True, slave=True):
    if master: self.packet_in_mask |= bit
    if slave: self.packet_in_mask_slave |= bit

  def set_port_status (self, bit, master=True, slave=True):
    if master: self.port_status_mask |= bit
    if slave: self.port_status_mask_slave |= bit

  def set_flow_removed (self, bit, master=True, slave=True):
    if master: selfflow_removed_mask |= bit
    if slave: self.flow_removed_mask_slave |= bit

  def _eq (self, other):
    """
    Return True if equal

    Overide this.
    """
    for a in "packet_in port_status flow_removed".split():
      a += "_mask"
      if getattr(self, a) != getattr(other, a): return False
      a += "_slave"
      if getattr(self, a) != getattr(other, a): return False
    return True

  def _pack_body (self):
    return struct.pack("!IIIIII",
        self.packet_in_mask, self.packet_in_mask_slave,
        self.port_status_mask, self.port_status_mask_slave,
        self.flow_removed_mask, self.flow_removed_mask_slave)

  def _unpack_body (self, raw, offset, avail):
    """
    Unpack body in raw starting at offset.

    Return new offset
    """
    offset,tmp = of._unpack("!IIIIII", raw, offset)
    self.packet_in_mask          = tmp[0]
    self.packet_in_mask_slave    = tmp[1]
    self.port_status_mask        = tmp[2]
    self.port_status_mask_slave  = tmp[3]
    self.flow_removed_mask       = tmp[4]
    self.flow_removed_mask_slave = tmp[5]

    return offset


#@vendor_s_message('NXT_PACKET_IN', 17)
class nxt_packet_in (nicira_base, of.ofp_packet_in):
  subtype = NXT_PACKET_IN
  _MIN_LENGTH = 34
  def _init (self, kw):
    ofp_header.__init__(self)

    self._buffer_id = None
    self.reason = 0
    self.data = None
    self._total_len = None
    self._match = None

    if 'total_len' in kw:
      self._total_len = kw.pop('total_len')

  def _validate (self):
    if self.data and (self.total_len < len(self.packed_data)):
      return "total len less than data len"

  @property
  def in_port (self):
    return self.match.of_in_port

  @property
  def match (self):
    if self._match is None:
      self._match = nx_match()
    return self._match
  @match.setter
  def match (self, v):
    self._match = v

  def pack (self):
    assert self._assert()

    match_len = len(self.match)

    packed = b""
    packed += ofp_header.pack(self)
    packed += struct.pack("!LL", NX_VENDOR_ID, self.subtype)
    packed += struct.pack("!LHBBQH", self._buffer_id, self.total_len,
                          self.reason, self.table_id, self.cookie,
                          match_len)
    packed += _PAD6
    packed += match.pack()
    packed += _PAD * ((match_len + 7)/8*8 - match_len)
    packed += _PAD2
    packed += self.packed_data
    return packed

  @property
  def packed_data (self):
    if self.data is None:
      return b''
    if hasattr(self.data, 'pack'):
      # I don't think this is ever encountered...
      return self.data.pack()
    else:
      return self.data

  def unpack (self, raw, offset=0):
    _offset = offset
    offset,length = self._unpack_header(raw, offset)
    offset,(vendor,subtype) = _unpack("!LL", raw, offset)
    assert subtype == self.subtype
    #print "vendor %08x  subtype %i" % (vendor,subtype)
    offset,(self._buffer_id, self._total_len, self.reason, self.table_id,
            self.cookie, match_len) = _unpack("!LHBBQH", raw, offset)
    offset = _skip(raw, offset, 6)

    self.match = None
    offset = self.match.unpack(raw, offset, match_len)

    offset = _skip(raw, offset, (match_len + 7)//8*8 - match_len)
    offset = _skip(raw, offset, 2)

    offset,self.data = _read(raw, offset, length-(offset-_offset))
    assert length == len(self)
    return offset,length

  def __len__ (self):
    match_len = len(self.match)
    l = 8 + 4 + 4
    l += 4 + 2 + 1 + 1 + 8 + 2
    l += 6
    l += match_len
    l += (match_len + 7)//8*8 - match_len
    l += 2
    l += len(self.packed_data)
    return l

  def __eq__ (self, other):
    if not of.ofp_packet_in.__eq__(self, other): return False
    if self.table_id != other.table_id: return False
    if self.cookie != other.cookie: return False
    if self.match != other.match: return False
    return True

  def __ne__ (self, other): return not self.__eq__(other)

  def show (self, prefix=''):
    outstr = ''
    outstr += prefix + 'header: \n'
    outstr += ofp_header.show(self, prefix + '  ')
    outstr += prefix + 'buffer_id: ' + str(self.buffer_id) + '\n'
    outstr += prefix + 'total_len: ' + str(self._total_len) + '\n'
    outstr += prefix + 'reason: ' + str(self.reason) + '\n'
    outstr += prefix + 'table_id: ' + str(self.table_id) + '\n'
    outstr += prefix + 'match: ' + str(self.match) + '\n'
    outstr += prefix + 'cookie: ' + str(self.cookie) + '\n'
    #from pox.lib.util import hexdump
    #outstr += prefix + 'data: ' + hexdump(self.data) + '\n'
    outstr += prefix + 'datalen: ' + str(len(self.data)) + '\n'
    return outstr

  def field (self, t):
    for i in self.match:
      if type(i) == t:
        return i
    return None


class nx_match (object):
  """
  A flexible match container

  This has some magic.  It acts as if it has properties for each
  registered nxm_entry type.  For example, there's a NXM_OF_IP_SRC
  nxm_entry type for the source IP address, so you can do:

    m = nx_match()
    m.of_ip_src = IPAddr("192.168.1.1")

  Since nxm_entries can have masks, you actually get a number of pseudo-
  properties, by appending "_mask", "_with_mask", or "_entry":

    m.of_ip_src_with_mask = ("192.168.1.0", "255.255.255.0")
    # or...
    m.of_ip_src = "192.168.1.0"
    m.of_ip_src_mask = "255.255.255.0"
    # or...
    m.of_ip_src_entry = NXM_OF_IP_SRC("192.168.1.1", "255.255.255.0")

  nxm_entries themselves may have magic.  For example, IP address
  nxm_entries understand CIDR bits as part of the value, so you can do:

    m.of_ip_src = "192.168.1.0/24"
    print m.of_ip_src
    > NXM_OF_IP_SRC(192.168.1.0/255.255.255.0)

  *The order you add entries is significant*.  If you have an entry
  with a prerequisite, you must add the prerequisite first.  It would be
  really nice if nx_match could automatically adjust orderings to try to
  satisfy nxm_entry prerequisties, and throw an exception if it's not
  possible.  This is a TODO item.
  """
  #TODO: Test!
  #TODO: Handle prerequisites (as described above)
  _locked = False # When True, can't add new attributes

  def __init__ (self, *parts, **kw):
    """
    Initialize this match

    You can initialize either from a list of parts or from a bunch of
    key/value pairs which are just like a shortcut for setting individual
    properties.
    """
    self._parts = list(parts)
    self._dirty()
    for k,v in kw:
      setattr(self, k, v)
    self._locked = True

  def unpack (self, raw, offset, avail):
    del self._parts[:]
    self._dirty()
    stop = avail+offset
    while offset < stop:
      _o = offset
      offset,entry = nxm_entry.unpack_new(raw, offset)
      if offset == _o:
        raise RuntimeError("No progress unpacking nxm_entries")
      self._parts.append(entry)

    #assert offset == stop
    return offset

  def pack (self, omittable = False):
    return ''.join(x.pack(omittable) for x in self._parts)

  def __eq__ (self, other):
    if not isinstance(other, self.__class__): return False
    return self._parts == other.__parts

  def clone (self):
    n = nx_match()
    for p in self._parts:
      n.append(p.clone())
    return n

  def __str__ (self):
    return ','.join(str(m) for m in self._parts)

  def show (self, prefix = ''):
    return prefix + str(self)

  @property
  def _map (self):
    if self._cache is None:
      self._cache = {}
      for i in self._parts:
        assert i._nxm_type not in self._cache
        self._cache[i._nxm_type] = i
    return self._cache

  def __len__ (self):
    return sum(len(x) for x in self._parts)

  def __getitem__ (self, index):
    return self._parts[index]

  def remove (self, t):
    """
    Remove an entry
    """
    if isinstance(t, nxm_entry):
      t = t._nxm_type
    if t not in self._map:
      return
    t = self._map[t]
    self._parts.remove(t)
    self._dirty()

  def find (self, t):
    """
    Returns nxm_entry of given type
    """
    if isinstance(t, nxm_entry) or _issubclass(t, nxm_entry):
      t = t._nxm_type
    return self._map.get(t)

  def index (self, t):
    """
    Returns index of nxm_entry of given type
    """
    if isinstance(t, nxm_entry):
      t = t._nxm_type
    if t not in self._map:
      return -1 # Exception?  None?
    return self._parts.find(t)

  def _dirty (self):
    self._cache = None

  def insert (self, position, item):
    if isinstance(t, nxm_entry) or _issubclass(t, nxm_entry):
      position = self.find(position)
      if position == None:
        self.append(item)
        return
    self._parts.insert(position, item)

  def insert_after (self, position, item):
    if isinstance(t, nxm_entry) or _issubclass(t, nxm_entry):
      position = self.find(position)
      if position == None:
        self.append(item)
        return
    self._parts.insert(position+1, item)

  def append (self, item):
    """
    Add another nxm_entry to this match
    """
    #TODO: check prereqs
    if not isinstance(item, nxm_entry):
      raise ValueError("Not an nxm_entry")
    if self.find(item) is not None:
      raise ValueError("Type already exists in this match")
    self._parts.append(item)
    self._dirty()

  def __iadd__ (self, other):
    self.append(other)

  @staticmethod
  def _fixname (name):
    name = name.upper()

    is_mask = with_mask = is_entry = False
    if name.endswith("_MASK"):
      if name.endswith("_WITH_MASK"):
        with_mask = True
        name = name.rsplit("_WITH_MASK", 1)[0]
      else:
        is_mask = True
        name = name.rsplit("_MASK", 1)[0]
    elif name.endswith("_ENTRY"):
      name = name.rsplit("_ENTRY", 1)[0]
      is_entry = True

    n = name
    for prefix in ('', 'NXM_', 'NXM_OF_', 'OXM_', 'OXM_OF_', 'NXM_NX_'):
      nxt = _nxm_name_to_type.get(prefix + n)
      if nxt is not None: break

    #print n, nxt, is_mask, with_mask, is_entry
    return n, nxt, is_mask, with_mask, is_entry

  def __getattr__ (self, name):
    name,nxt,is_mask,with_mask,is_entry = self._fixname(name)

    if nxt is None:
      raise AttributeError("No attribute " + name)

    if nxt not in self._map:
      if with_mask: return None,None
      if is_mask: return None # Exception?
      if is_entry: return None # Synthesize?
      return None

    v = self._map[nxt]
    if with_mask: return (v.value,v.mask)
    if is_mask: return v.mask
    if is_entry: return v
    return v.value

  def __setattr__ (self, name, value):
    if name.startswith('_'):
      return object.__setattr__(self, name, value)

    n,nxt,is_mask,with_mask,is_entry = self._fixname(name)

    if nxt is None:
      if self._locked:
        raise AttributeError("No attribute " + name)
      return object.__setattr__(self, name, value)

    entry = self.find(nxt)

    if is_entry: assert isinstance(value, nxm_entry)

    if is_entry and (value is None) and (entry is not None):
      # Shortcut entry removal
      # Allow for non is_entry?  Doing so is ambiguous if there are
      # ever nxm_entries with None as a legal value.
      self.remove(nxt)
      return

    if isinstance(value, nxm_entry):
      if nxt != nxm_entry._nxm_type:
        raise ValueError("Unmatched types")
      if entry is None:
        self.append(value)
      else:
        # hacky
        entry.value = value.value
        entry.mask = value.mask
    else:
      if entry is None:
        entry = _nxm_type_to_class[nxt]()
        self.append(entry)
      # hacky
      if with_mask:
        entry.mask = value[1]
        entry.value = value[0]
      elif is_mask:
        entry.mask = value
      else:
        entry.value = value


#from pox.lib.revent import Event
#class NXPacketIn (Event):
#  def __init__ (self, connection, ofp):
#    Event.__init__(self)
#    self.connection = connection
#    self.ofp = ofp
#    self.port = ofp.in_port
#    self.data = ofp.data
#    self._parsed = None
#    self.dpid = connection.dpid
#
#  def parse (self):
#    if self._parsed is None:
#      self._parsed = ethernet(self.data)
#    return self._parsed
#
#  @property
#  def parsed (self):
#    """
#    The packet as parsed by pox.lib.packet
#    """
#    return self.parse()
#
#core.openflow._eventMixin_events.add(NXPacketIn)


_old_unpacker = None

def _unpack_nx_vendor (raw, offset):
  v = _unpack("!L", raw, offset + 8)[1][0]
  if v != NX_VENDOR_ID:
    return _old_unpacker(raw, offset)
  subtype = _unpack("!L", raw, offset+8+4)[1][0]
  if subtype == NXT_PACKET_IN:
    npi = nxt_packet_in()
    return npi.unpack(raw, offset)[0], npi
  elif subtype == NXT_ROLE_REPLY:
    nrr = nx_role_reply()
    return nrr.unpack(raw, offset)[0], nrr
  else:
    print "NO UNPACKER FOR",subtype
    return _old_unpacker(raw, offset)


def _init_unpacker ():
  global _old_unpacker
  from pox.openflow.of_01 import unpackers
  _old_unpacker = unpackers[of.OFPT_VENDOR]
  unpackers[of.OFPT_VENDOR] = _unpack_nx_vendor


_old_handler = None

from pox.openflow import PacketIn

def _handle_VENDOR (con, msg):
  if isinstance(msg, nxt_packet_in) and core.NX.convert_packet_in:
    e = con.ofnexus.raiseEventNoErrors(PacketIn, con, msg)
    if e is None or e.halt != True:
      con.raiseEventNoErrors(PacketIn, con, msg)
#  elif isinstance(msg, nxt_role_reply):
#    pass
#    #TODO
  else:
    _old_handler(con, msg)


def _init_handler ():
  global _old_handler
  from pox.openflow.of_01 import handlerMap, _set_handlers

  _old_handler = handlerMap.get(of.OFPT_VENDOR)
  handlerMap[of.OFPT_VENDOR] = _handle_VENDOR
  _set_handlers()


class NX (object):
  """
  Nicira extension component
  """
  convert_packet_in = False


def launch (convert_packet_in = False):
  _init_handler()
  _init_unpacker()

  nx = NX()
  if convert_packet_in:
    nx.convert_packet_in = True

  core.register("NX", nx)

########NEW FILE########
__FILENAME__ = nicira_ext
# Copyright 2011 Andreas Wundsam
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at:
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

#TODO: Update the datapath to use nicira.py and then delete this file.

import struct

from pox.lib.util import initHelper

# Nicira Vendor extensions. Welcome to embrace-and-extend-town
VENDOR_ID = 0x00002320
# sub_types
ROLE_REQUEST = 10
ROLE_REPLY = 11
# role request / reply patterns
ROLE_OTHER = 0
ROLE_MASTER = 1
ROLE_SLAVE = 2

class nx_data(object):
  """ base class for the data field of Nicira vendor extension
      commands. Picked from the floodlight source code.
  """
  def __init__ (self, **kw):
    self.subtype = 0
    self.length = 4

    initHelper(self, kw)

  def _assert (self):
    return (True, None)

  def pack (self, assertstruct=True):
    if(assertstruct):
      if(not self._assert()[0]):
        return None
    packed = ""
    packed += struct.pack("!L", self.subtype)
    return packed

  def unpack (self, binaryString):
    if (len(binaryString) < 4):
      return binaryString
    (self.subtype,) = struct.unpack_from("!L", binaryString, 0)
    return binaryString[4:]

  def __len__ (self):
    return 4

  def __eq__ (self, other):
    if type(self) != type(other): return False
    if self.subtype !=  other.subtype: return False
    return True

  def __ne__ (self, other): return not self.__eq__(other)

  def show (self, prefix=''):
    outstr = ''
    outstr += prefix + 'header: \n'
    outstr += prefix + 'subtype: ' + str(self.subtype) + '\n'
    return outstr

class role_data(nx_data):
  """ base class for the data field of nx role requests."""
  def __init__ (self, subtype, **kw):
    nx_data.__init__(self)
    self.subtype = subtype
    self.role = ROLE_OTHER
    self.length = 8

    initHelper(self, kw)

  def _assert (self):
    return (True, None)

  def pack (self, assertstruct=True):
    if(assertstruct):
      if(not self._assert()[0]):
        return None
    packed = ""
    packed += nx_data.pack(self)
    packed += struct.pack("!L", self.role)
    return packed

  def unpack (self, binaryString):
    if (len(binaryString) < 8):
      return binaryString
    nx_data.unpack(self, binaryString[0:])
    (self.role,) = struct.unpack_from("!L", binaryString, 4)
    return binaryString[8:]

  def __len__ (self):
    return 8

  def __eq__ (self, other):
    if type(self) != type(other): return False
    if not nx_data.__eq__(self, other): return False
    if self.role !=  other.role: return False
    return True

  def __ne__ (self, other): return not self.__eq__(other)

  def show (self, prefix=''):
    outstr = ''
    outstr += prefix + 'header: \n'
    outstr += nx_data.show(self, prefix + '  ')
    outstr += prefix + 'role: ' + str(self.role) + '\n'
    return outstr

class role_request_data(role_data):
  """ Role request. C->S """
  def __init__ (self, **kw):
    role_data.__init__(self, ROLE_REQUEST, **kw)

class role_reply_data(role_data):
  """ Role reply S->C """
  def __init__ (self, **kw):
    role_data.__init__(self, ROLE_REPLY, **kw)

_nx_subtype_to_type = {
    ROLE_REQUEST: role_request_data,
    ROLE_REPLY: role_reply_data
}

def unpack_vendor_data_nx(data):
    if len(data) < 4: raise RuntimeError("NX vendor data<4 bytes")
    nx = nx_data()
    nx.unpack(data)
    if nx.subtype in _nx_subtype_to_type:
      res = _nx_subtype_to_type[nx.subtype]()
      res.unpack(data)
      return res
    else:
      raise NotImplementedError("subtype not implemented: %d" % nx.subtype)

########NEW FILE########
__FILENAME__ = of_01
# Copyright 2011,2012 James McCauley
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at:
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""
In charge of OpenFlow 1.0 switches.

NOTE: This module is loaded automatically on startup unless POX is run
      with --no-openflow .
"""
from pox.core import core
import pox
import pox.lib.util
from pox.lib.addresses import EthAddr
from pox.lib.revent.revent import EventMixin
import datetime
import time
from pox.lib.socketcapture import CaptureSocket
import pox.openflow.debug
from pox.openflow.util import make_type_to_unpacker_table
from pox.openflow import *

log = core.getLogger()

import socket
import select

# List where the index is an OpenFlow message type (OFPT_xxx), and
# the values are unpack functions that unpack the wire format of that
# type into a message object.
unpackers = make_type_to_unpacker_table()

try:
  PIPE_BUF = select.PIPE_BUF
except:
  try:
    # Try to get it from where PyPy (sometimes) has it
    import IN
    PIPE_BUF = IN.PIPE_BUF
  except:
    # (Hopefully) reasonable default
    PIPE_BUF = 512

import pox.openflow.libopenflow_01 as of

import threading
import os
import sys
import exceptions
from errno import EAGAIN, ECONNRESET, EADDRINUSE, EADDRNOTAVAIL


import traceback


def handle_HELLO (con, msg): #S
  #con.msg("HELLO wire protocol " + hex(msg.version))

  # Send a features request
  msg = of.ofp_features_request()
  con.send(msg)

def handle_ECHO_REPLY (con, msg):
  #con.msg("Got echo reply")
  pass

def handle_ECHO_REQUEST (con, msg): #S
  reply = msg

  reply.header_type = of.OFPT_ECHO_REPLY
  con.send(reply)

def handle_FLOW_REMOVED (con, msg): #A
  e = con.ofnexus.raiseEventNoErrors(FlowRemoved, con, msg)
  if e is None or e.halt != True:
    con.raiseEventNoErrors(FlowRemoved, con, msg)

def handle_FEATURES_REPLY (con, msg):
  connecting = con.connect_time == None
  con.features = msg
  con.original_ports._ports = set(msg.ports)
  con.ports._reset()
  con.dpid = msg.datapath_id

  if not connecting:
    con.ofnexus._connect(con)
    e = con.ofnexus.raiseEventNoErrors(FeaturesReceived, con, msg)
    if e is None or e.halt != True:
      con.raiseEventNoErrors(FeaturesReceived, con, msg)
    return

  nexus = core.OpenFlowConnectionArbiter.getNexus(con)
  if nexus is None:
    # Cancel connection
    con.info("No OpenFlow nexus for " +
             pox.lib.util.dpidToStr(msg.datapath_id))
    con.disconnect()
    return
  con.ofnexus = nexus
  con.ofnexus._connect(con)
  #connections[con.dpid] = con

  barrier = of.ofp_barrier_request()

  listeners = []

  def finish_connecting (event):
    if event.xid != barrier.xid:
      con.dpid = None
      con.err("failed connect")
      con.disconnect()
    else:
      con.info("connected")
      con.connect_time = time.time()
      e = con.ofnexus.raiseEventNoErrors(ConnectionUp, con, msg)
      if e is None or e.halt != True:
        con.raiseEventNoErrors(ConnectionUp, con, msg)
      e = con.ofnexus.raiseEventNoErrors(FeaturesReceived, con, msg)
      if e is None or e.halt != True:
        con.raiseEventNoErrors(FeaturesReceived, con, msg)
    con.removeListeners(listeners)
  listeners.append(con.addListener(BarrierIn, finish_connecting))

  def also_finish_connecting (event):
    if event.xid != barrier.xid: return
    if event.ofp.type != of.OFPET_BAD_REQUEST: return
    if event.ofp.code != of.OFPBRC_BAD_TYPE: return
    # Okay, so this is probably an HP switch that doesn't support barriers
    # (ugh).  We'll just assume that things are okay.
    finish_connecting(event)
  listeners.append(con.addListener(ErrorIn, also_finish_connecting))

  #TODO: Add a timeout for finish_connecting

  if con.ofnexus.miss_send_len is not None:
    con.send(of.ofp_set_config(miss_send_len =
                                  con.ofnexus.miss_send_len))
  if con.ofnexus.clear_flows_on_connect:
    con.send(of.ofp_flow_mod(match=of.ofp_match(),command=of.OFPFC_DELETE))

  con.send(barrier)

  """
  # Hack for old versions of cbench
  class C (object):
    xid = barrier.xid
  finish_connecting(C())
  """

def handle_STATS_REPLY (con, msg):
  e = con.ofnexus.raiseEventNoErrors(RawStatsReply, con, msg)
  if e is None or e.halt != True:
    con.raiseEventNoErrors(RawStatsReply, con, msg)
  con._incoming_stats_reply(msg)

def handle_PORT_STATUS (con, msg): #A
  if msg.reason == of.OFPPR_DELETE:
    con.ports._forget(msg.desc)
  else:
    con.ports._update(msg.desc)
  e = con.ofnexus.raiseEventNoErrors(PortStatus, con, msg)
  if e is None or e.halt != True:
    con.raiseEventNoErrors(PortStatus, con, msg)

def handle_PACKET_IN (con, msg): #A
  e = con.ofnexus.raiseEventNoErrors(PacketIn, con, msg)
  if e is None or e.halt != True:
    con.raiseEventNoErrors(PacketIn, con, msg)

def handle_ERROR_MSG (con, msg): #A
  err = ErrorIn(con, msg)
  e = con.ofnexus.raiseEventNoErrors(err)
  if e is None or e.halt != True:
    con.raiseEventNoErrors(err)
  if err.should_log:
    log.error(str(con) + " OpenFlow Error:\n" +
              msg.show(str(con) + " Error: ").strip())

def handle_BARRIER (con, msg):
  e = con.ofnexus.raiseEventNoErrors(BarrierIn, con, msg)
  if e is None or e.halt != True:
    con.raiseEventNoErrors(BarrierIn, con, msg)

# handlers for stats replies
def handle_OFPST_DESC (con, parts):
  msg = parts[0].body
  e = con.ofnexus.raiseEventNoErrors(SwitchDescReceived,con,parts[0],msg)
  if e is None or e.halt != True:
    con.raiseEventNoErrors(SwitchDescReceived, con, parts[0], msg)

def handle_OFPST_FLOW (con, parts):
  msg = []
  for part in parts:
    msg.extend(part.body)
  e = con.ofnexus.raiseEventNoErrors(FlowStatsReceived, con, parts, msg)
  if e is None or e.halt != True:
    con.raiseEventNoErrors(FlowStatsReceived, con, parts, msg)

def handle_OFPST_AGGREGATE (con, parts):
  msg = parts[0].body
  e = con.ofnexus.raiseEventNoErrors(AggregateFlowStatsReceived, con,
                                     parts[0], msg)
  if e is None or e.halt != True:
    con.raiseEventNoErrors(AggregateFlowStatsReceived, con, parts[0], msg)

def handle_OFPST_TABLE (con, parts):
  msg = []
  for part in parts:
    msg.extend(part.body)
  e = con.ofnexus.raiseEventNoErrors(TableStatsReceived, con, parts, msg)
  if e is None or e.halt != True:
    con.raiseEventNoErrors(TableStatsReceived, con, parts, msg)

def handle_OFPST_PORT (con, parts):
  msg = []
  for part in parts:
    msg.extend(part.body)
  e = con.ofnexus.raiseEventNoErrors(PortStatsReceived, con, parts, msg)
  if e is None or e.halt != True:
    con.raiseEventNoErrors(PortStatsReceived, con, parts, msg)

def handle_OFPST_QUEUE (con, parts):
  msg = []
  for part in parts:
    msg.extend(part.body)
  e = con.ofnexus.raiseEventNoErrors(QueueStatsReceived, con, parts, msg)
  if e is None or e.halt != True:
    con.raiseEventNoErrors(QueueStatsReceived, con, parts, msg)

def handle_VENDOR (con, msg):
  log.info("Vendor msg: " + str(msg))


# A list, where the index is an OFPT, and the value is a function to
# call for that type
# This is generated automatically based on handlerMap
handlers = []

# Message handlers
handlerMap = {
  of.OFPT_HELLO : handle_HELLO,
  of.OFPT_ECHO_REQUEST : handle_ECHO_REQUEST,
  of.OFPT_ECHO_REPLY : handle_ECHO_REPLY,
  of.OFPT_PACKET_IN : handle_PACKET_IN,
  of.OFPT_FEATURES_REPLY : handle_FEATURES_REPLY,
  of.OFPT_PORT_STATUS : handle_PORT_STATUS,
  of.OFPT_ERROR : handle_ERROR_MSG,
  of.OFPT_BARRIER_REPLY : handle_BARRIER,
  of.OFPT_STATS_REPLY : handle_STATS_REPLY,
  of.OFPT_FLOW_REMOVED : handle_FLOW_REMOVED,
  of.OFPT_VENDOR : handle_VENDOR,
}

statsHandlerMap = {
  of.OFPST_DESC : handle_OFPST_DESC,
  of.OFPST_FLOW : handle_OFPST_FLOW,
  of.OFPST_AGGREGATE : handle_OFPST_AGGREGATE,
  of.OFPST_TABLE : handle_OFPST_TABLE,
  of.OFPST_PORT : handle_OFPST_PORT,
  of.OFPST_QUEUE : handle_OFPST_QUEUE,
}

# Deferred sending should be unusual, so don't worry too much about
# efficiency
class DeferredSender (threading.Thread):
  """
  Class that handles sending when a socket write didn't complete
  """
  def __init__ (self):
    threading.Thread.__init__(self)
    core.addListeners(self)
    self._dataForConnection = {}
    self._lock = threading.RLock()
    self._waker = pox.lib.util.makePinger()
    self.sending = False

    self.start()

  def _handle_GoingDownEvent (self, event):
    self._waker.ping()

  def _sliceup (self, data):
    """
    Takes an array of data bytes, and slices into elements of
    PIPE_BUF bytes each
    """
    out = []
    while len(data) > PIPE_BUF:
      out.append(data[0:PIPE_BUF])
      data = data[PIPE_BUF:]
    if len(data) > 0:
      out.append(data)
    return out

  def send (self, con, data):
    with self._lock:
      self.sending = True

      data = self._sliceup(data)

      if con not in self._dataForConnection:
        self._dataForConnection[con] = data
      else:
        self._dataForConnection[con].extend(data)

      self._waker.ping()

  def kill (self, con):
    with self._lock:
      try:
        del self._dataForConnection[con]
      except:
        pass

      self._waker.ping()

  def run (self):
    while core.running:

      with self._lock:
        cons = self._dataForConnection.keys()

      rlist, wlist, elist = select.select([self._waker], cons, cons, 5)
      if not core.running: break

      with self._lock:
        if len(rlist) > 0:
          self._waker.pongAll()

        for con in elist:
          try:
            del self._dataForConnection[con]
          except:
            pass

        for con in wlist:
          try:
            alldata = self._dataForConnection[con]
            while len(alldata):
              data = alldata[0]
              try:
                l = con.sock.send(data)
                if l != len(data):
                  alldata[0] = data[l:]
                  break
                del alldata[0]
              except socket.error as (errno, strerror):
                if errno != EAGAIN:
                  con.msg("DeferredSender/Socket error: " + strerror)
                  con.disconnect()
                  del self._dataForConnection[con]
                break
              except:
                con.msg("Unknown error doing deferred sending")
                break
            if len(alldata) == 0:
              try:
                del self._dataForConnection[con]
                if len(self._dataForConnection) == 0:
                  self.sending = False
                  break
              except:
                pass
          except:
            try:
              del self._dataForConnection[con]
            except:
              pass

class DummyOFNexus (object):
  def raiseEventNoErrors (self, event, *args, **kw):
    log.warning("%s raised on dummy OpenFlow nexus" % event)
  def raiseEvent (self, event, *args, **kw):
    log.warning("%s raised on dummy OpenFlow nexus" % event)
  def _disconnect (self, dpid):
    log.warning("%s disconnected on dummy OpenFlow nexus",
                pox.lib.util.dpidToStr(dpid))

_dummyOFNexus = DummyOFNexus()


"""
class FileCloser (object):
  def __init__ (self):
    from weakref import WeakSet
    self.items = WeakSet()
    core.addListeners(self)
    import atexit
    atexit.register(self._handle_DownEvent, None)

  def _handle_DownEvent (self, event):
    for item in self.items:
      try:
        item.close()
      except Exception:
        log.exception("Couldn't close a file while shutting down")
    self.items.clear()

_itemcloser = FileCloser()
"""


class OFCaptureSocket (CaptureSocket):
  """
  Captures OpenFlow data to a pcap file
  """
  def __init__ (self, *args, **kw):
    super(OFCaptureSocket,self).__init__(*args, **kw)
    self._rbuf = bytes()
    self._sbuf = bytes()
    self._enabled = True
    #_itemcloser.items.add(self)

  def _recv_out (self, buf):
    if not self._enabled: return
    self._rbuf += buf
    l = len(self._rbuf)
    while l > 4:
      if ord(self._rbuf[0]) != of.OFP_VERSION:
        log.error("Bad OpenFlow version while trying to capture trace")
        self._enabled = False
        break
      packet_length = ord(self._rbuf[2]) << 8 | ord(self._rbuf[3])
      if packet_length > l: break
      try:
        self._writer.write(False, self._rbuf[:packet_length])
      except Exception:
        log.exception("Exception while writing controller trace")
        self._enabled = False
      self._rbuf = self._rbuf[packet_length:]
      l = len(self._rbuf)

  def _send_out (self, buf, r):
    if not self._enabled: return
    self._sbuf += buf
    l = len(self._sbuf)
    while l > 4:
      if ord(self._sbuf[0]) != of.OFP_VERSION:
        log.error("Bad OpenFlow version while trying to capture trace")
        self._enabled = False
        break
      packet_length = ord(self._sbuf[2]) << 8 | ord(self._sbuf[3])
      if packet_length > l: break
      try:
        self._writer.write(True, self._sbuf[:packet_length])
      except Exception:
        log.exception("Exception while writing controller trace")
        self._enabled = False
      self._sbuf = self._sbuf[packet_length:]
      l = len(self._sbuf)


class PortCollection (object):
  """
  Keeps track of lists of ports and provides nice indexing.

  NOTE: It's possible this could be simpler by inheriting from UserDict,
        but I couldn't swear without looking at UserDict in some detail,
        so I just implemented a lot of stuff by hand.
  """
  def __init__ (self):
    self._ports = set()
    self._masks = set()
    self._chain = None

  def _reset (self):
    self._ports.clear()
    self._masks.clear()

  def _forget (self, port_no):
    self._masks.add(port_no)
    self._ports = set([p for p in self._ports if p.port_no != port_no])

  def _update (self, port):
    self._masks.discard(port.port_no)
    self._ports = set([p for p in self._ports if p.port_no != port.port_no])
    self._ports.add(port)

  def __str__ (self):
    if len(self) == 0:
      return "<Ports: Empty>"
    l = ["%s:%i"%(p.name,p.port_no) for p in sorted(self.values())]
    return "<Ports: %s>" % (", ".join(l),)

  def __len__ (self):
    return len(self.keys())

  def __getitem__ (self, index):
    if isinstance(index, (int,long)):
      for p in self._ports:
        if p.port_no == index:
          return p
    elif isinstance(index, EthAddr):
      for p in self._ports:
        if p.hw_addr == index:
          return p
    else:
      for p in self._ports:
        if p.name == index:
          return p
    if self._chain:
      p = self._chain[index]
      if p.port_no not in self._masks:
        return p

    raise IndexError("No key %s" % (index,))

  def keys (self):
    if self._chain:
      k = set(self._chain.keys())
      k.difference_update(self._masks)
    else:
      k = set()
    k.update([p.port_no for p in self._ports])
    return list(k)

  def __iter__ (self):
    return iter(self.keys())

  def iterkeys (self):
    return iter(self.keys())

  def __contains__ (self, index):
    try:
      self[index]
      return True
    except Exception:
      pass
    return False

  def values (self):
    return [self[k] for k in self.keys()]

  def items (self):
    return [(k,self[k]) for k in self.keys()]

  def iterkeys (self):
    return iter(self.keys())
  def itervalues (self):
    return iter(self.values())
  def iteritems (self):
    return iter(self.items())
  def has_key (self, k):
    return k in self
  def get (self, k, default=None):
    try:
      return self[k]
    except IndexError:
      return default
  def copy (self):
    r = PortCollection()
    r._ports = set(self.values())


class Connection (EventMixin):
  """
  A Connection object represents a single TCP session with an
  openflow-enabled switch.
  If the switch reconnects, a new connection object is instantiated.
  """
  _eventMixin_events = set([
    ConnectionUp,
    ConnectionDown,
    PortStatus,
    FlowRemoved,
    PacketIn,
    ErrorIn,
    BarrierIn,
    RawStatsReply,
    SwitchDescReceived,
    FlowStatsReceived,
    AggregateFlowStatsReceived,
    TableStatsReceived,
    PortStatsReceived,
    QueueStatsReceived,
    FlowRemoved,
  ])

  # Globally unique identifier for the Connection instance
  ID = 0

  def msg (self, m):
    #print str(self), m
    log.debug(str(self) + " " + str(m))
  def err (self, m):
    #print str(self), m
    log.error(str(self) + " " + str(m))
  def info (self, m):
    pass
    #print str(self), m
    log.info(str(self) + " " + str(m))

  def __init__ (self, sock):
    self._previous_stats = []

    self.ofnexus = _dummyOFNexus
    self.sock = sock
    self.buf = ''
    Connection.ID += 1
    self.ID = Connection.ID
    # TODO: dpid and features don't belong here; they should be eventually
    # be in topology.switch
    self.dpid = None
    self.features = None
    self.disconnected = False
    self.disconnection_raised = False
    self.connect_time = None
    self.idle_time = time.time()

    self.send(of.ofp_hello())

    self.original_ports = PortCollection()
    self.ports = PortCollection()
    self.ports._chain = self.original_ports

    #TODO: set a time that makes sure we actually establish a connection by
    #      some timeout

  @property
  def eth_addr (self):
    dpid = self.dpid
    if self.dpid is None:
      raise RuntimeError("eth_addr not available")
    return EthAddr("%012x" % (dpid & 0xffFFffFFffFF,))

  def fileno (self):
    return self.sock.fileno()

  def close (self):
    self.disconnect('closed')
    try:
      self.sock.close()
    except:
      pass

  def disconnect (self, msg = 'disconnected', defer_event = False):
    """
    disconnect this Connection (usually not invoked manually).
    """
    if self.disconnected:
      self.msg("already disconnected")
    self.info(msg)
    self.disconnected = True
    try:
      self.ofnexus._disconnect(self.dpid)
    except:
      pass
    if self.dpid is not None:
      if not self.disconnection_raised and not defer_event:
        self.disconnection_raised = True
        self.ofnexus.raiseEventNoErrors(ConnectionDown, self)
        self.raiseEventNoErrors(ConnectionDown, self)

    try:
      #deferredSender.kill(self)
      pass
    except:
      pass
    try:
      self.sock.shutdown(socket.SHUT_RDWR)
    except:
      pass
    try:
      pass
      #TODO disconnect notification
    except:
      pass

  def send (self, data):
    """
    Send data to the switch.

    Data should probably either be raw bytes in OpenFlow wire format, or
    an OpenFlow controller-to-switch message object from libopenflow.
    """
    if self.disconnected: return
    if type(data) is not bytes:
      # There's actually no reason the data has to be an instance of
      # ofp_header, but this check is likely to catch a lot of bugs,
      # so we check it anyway.
      assert isinstance(data, of.ofp_header)
      data = data.pack()

    if deferredSender.sending:
      log.debug("deferred sender is sending!")
      deferredSender.send(self, data)
      return
    try:
      l = self.sock.send(data)
      if l != len(data):
        self.msg("Didn't send complete buffer.")
        data = data[l:]
        deferredSender.send(self, data)
    except socket.error as (errno, strerror):
      if errno == EAGAIN:
        self.msg("Out of send buffer space.  " +
                 "Consider increasing SO_SNDBUF.")
        deferredSender.send(self, data)
      else:
        self.msg("Socket error: " + strerror)
        self.disconnect(defer_event=True)

  def read (self):
    """
    Read data from this connection.  Generally this is just called by the
    main OpenFlow loop below.

    Note: This function will block if data is not available.
    """
    try:
      d = self.sock.recv(2048)
    except:
      return False
    if len(d) == 0:
      return False
    self.buf += d
    buf_len = len(self.buf)


    offset = 0
    while buf_len - offset >= 8: # 8 bytes is minimum OF message size
      # We pull the first four bytes of the OpenFlow header off by hand
      # (using ord) to find the version/length/type so that we can
      # correctly call libopenflow to unpack it.

      ofp_type = ord(self.buf[offset+1])

      if ord(self.buf[offset]) != of.OFP_VERSION:
        if ofp_type == of.OFPT_HELLO:
          # We let this through and hope the other side switches down.
          pass
        else:
          log.warning("Bad OpenFlow version (0x%02x) on connection %s"
                      % (ord(self.buf[offset]), self))
          return False # Throw connection away

      msg_length = ord(self.buf[offset+2]) << 8 | ord(self.buf[offset+3])

      if buf_len - offset < msg_length: break

      new_offset,msg = unpackers[ofp_type](self.buf, offset)
      assert new_offset - offset == msg_length
      offset = new_offset

      try:
        h = handlers[ofp_type]
        h(self, msg)
      except:
        log.exception("%s: Exception while handling OpenFlow message:\n" +
                      "%s %s", self,self,
                      ("\n" + str(self) + " ").join(str(msg).split('\n')))
        continue

    if offset != 0:
      self.buf = self.buf[offset:]

    return True

  def _incoming_stats_reply (self, ofp):
    # This assumes that you don't receive multiple stats replies
    # to different requests out of order/interspersed.
    if not ofp.is_last_reply:
      if ofp.type not in [of.OFPST_FLOW, of.OFPST_TABLE,
                                of.OFPST_PORT, of.OFPST_QUEUE]:
        log.error("Don't know how to aggregate stats message of type " +
                  str(ofp.type))
        self._previous_stats = []
        return

    if len(self._previous_stats) != 0:
      if ((ofp.xid == self._previous_stats[0].xid) and
          (ofp.type == self._previous_stats[0].type)):
        self._previous_stats.append(ofp)
      else:
        log.error("Was expecting continued stats of type %i with xid %i, " +
                  "but got type %i with xid %i" %
                  (self._previous_stats_reply.xid,
                    self._previous_stats_reply.type,
                    ofp.xid, ofp.type))
        self._previous_stats = [ofp]
    else:
      self._previous_stats = [ofp]

    if ofp.is_last_reply:
      handler = statsHandlerMap.get(self._previous_stats[0].type, None)
      s = self._previous_stats
      self._previous_stats = []
      if handler is None:
        log.warn("No handler for stats of type " +
                 str(self._previous_stats[0].type))
        return
      handler(self, s)

  def __str__ (self):
    #return "[Con " + str(self.ID) + "/" + str(self.dpid) + "]"
    if self.dpid is None:
      d = str(self.dpid)
    else:
      d = pox.lib.util.dpidToStr(self.dpid)
    return "[%s %i]" % (d, self.ID)


def wrap_socket (new_sock):
  fname = datetime.datetime.now().strftime("%Y-%m-%d-%I%M%p")
  fname += "_" + new_sock.getpeername()[0].replace(".", "_")
  fname += "_" + `new_sock.getpeername()[1]` + ".pcap"
  pcapfile = file(fname, "w")
  try:
    new_sock = OFCaptureSocket(new_sock, pcapfile,
                               local_addrs=(None,None,6633))
  except Exception:
    import traceback
    traceback.print_exc()
    pass
  return new_sock


from pox.lib.recoco.recoco import *

class OpenFlow_01_Task (Task):
  """
  The main recoco thread for listening to openflow messages
  """
  def __init__ (self, port = 6633, address = '0.0.0.0'):
    Task.__init__(self)
    self.port = int(port)
    self.address = address
    self.started = False

    core.addListener(pox.core.GoingUpEvent, self._handle_GoingUpEvent)

  def _handle_GoingUpEvent (self, event):
    self.start()

  def start (self):
    if self.started:
      return
    self.started = True
    return super(OpenFlow_01_Task,self).start()

  def run (self):
    # List of open sockets/connections to select on
    sockets = []

    listener = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
    listener.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
    try:
      listener.bind((self.address, self.port))
    except socket.error as (errno, strerror):
      log.error("Error %i while binding socket: %s", errno, strerror)
      if errno == EADDRNOTAVAIL:
        log.error(" You may be specifying a local address which is "
                  "not assigned to any interface.")
      elif errno == EADDRINUSE:
        log.error(" You may have another controller running.")
        log.error(" Use openflow.of_01 --port=<port> to run POX on "
                  "another port.")
      return

    listener.listen(16)
    sockets.append(listener)

    log.debug("Listening on %s:%s" %
              (self.address, self.port))

    con = None
    while core.running:
      try:
        while True:
          con = None
          rlist, wlist, elist = yield Select(sockets, [], sockets, 5)
          if len(rlist) == 0 and len(wlist) == 0 and len(elist) == 0:
            if not core.running: break

          for con in elist:
            if con is listener:
              raise RuntimeError("Error on listener socket")
            else:
              try:
                con.close()
              except:
                pass
              try:
                sockets.remove(con)
              except:
                pass

          timestamp = time.time()
          for con in rlist:
            if con is listener:
              new_sock = listener.accept()[0]
              if pox.openflow.debug.pcap_traces:
                new_sock = wrap_socket(new_sock)
              new_sock.setblocking(0)
              # Note that instantiating a Connection object fires a
              # ConnectionUp event (after negotation has completed)
              newcon = Connection(new_sock)
              sockets.append( newcon )
              #print str(newcon) + " connected"
            else:
              con.idle_time = timestamp
              if con.read() is False:
                con.close()
                sockets.remove(con)
      except exceptions.KeyboardInterrupt:
        break
      except:
        doTraceback = True
        if sys.exc_info()[0] is socket.error:
          if sys.exc_info()[1][0] == ECONNRESET:
            con.info("Connection reset")
            doTraceback = False

        if doTraceback:
          log.exception("Exception reading connection " + str(con))

        if con is listener:
          log.error("Exception on OpenFlow listener.  Aborting.")
          break
        try:
          con.close()
        except:
          pass
        try:
          sockets.remove(con)
        except:
          pass

    log.debug("No longer listening for connections")

    #pox.core.quit()


def _set_handlers ():
  handlers.extend([None] * (1 + sorted(handlerMap.keys(),reverse=True)[0]))
  for h in handlerMap:
    handlers[h] = handlerMap[h]
    #print handlerMap[h]
_set_handlers()


# Used by the Connection class
deferredSender = None

def launch (port = 6633, address = "0.0.0.0"):
  if core.hasComponent('of_01'):
    return None

  global deferredSender
  deferredSender = DeferredSender()

  if of._logger is None:
    of._logger = core.getLogger('libopenflow_01')

  l = OpenFlow_01_Task(port = int(port), address = address)
  core.register("of_01", l)
  return l

########NEW FILE########
__FILENAME__ = of_json
# Copyright 2011,2012 James McCauley
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at:
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""
Various stuff for converting between OpenFlow and JSON-friendly
data structures.

Lots of stuff could be improved and the naming is pretty awful.
"""

from pox.lib.util import fields_of,is_scalar
import pox.openflow.libopenflow_01 as of

def _fix_of_int (n):
  if isinstance(n, basestring):
    return getattr(of, n, None)
  return n

from pox.lib.packet import ethernet, ipv4
from pox.lib.packet.packet_utils import ethtype_to_str
from pox.lib.util import dpidToStr
from pox.lib.addresses import EthAddr, IPAddr

def _fix_ethertype (n):
  if isinstance(n, basestring):
    try:
      if n.startswith("802.3/"):
        n = n.split("/",1)[1]
      v = int(n, 16)
      return v
    except:
      pass
    if not n.endswith("_TYPE"):
      n += "_TYPE"
    return getattr(ethernet, n)
  return n

def _fix_proto (n):
  if isinstance(n, basestring):
    if not n.endswith("_PROTOCOL"):
      n += "_PROTOCOL"
    return getattr(ipv4, n)
  return n

from pox.lib.addresses import parse_cidr, EthAddr

def _fix_eth (n):
  if n is None: return None
  return EthAddr(n)

def _fix_ip (n):
  if n is None: return n
  return parse_cidr(n, infer = False)

import socket

def _fix_port (n):
  if isinstance(n, basestring):
    return socket.getservbyname(n)
  return n

def dict_to_match (jm):
  m = of.ofp_match()
  m.in_port = _fix_of_int(jm.get('in_port'))
  m.dl_src = _fix_eth(jm.get('dl_src'))
  m.dl_dst = _fix_eth(jm.get('dl_dst'))
  if 'dl_vlan'     in jm: m.dl_vlan     = jm['dl_vlan']
  if 'dl_vlan_pcp' in jm: m.dl_vlan_pcp = jm['dl_vlan_pcp']
  m.dl_type = _fix_ethertype(jm.get('dl_type'))
  if 'nw_tos'      in jm: m.nw_tos      = jm['nw_tos']
  m.nw_proto = _fix_proto(jm.get('nw_proto'))
  m.nw_src = _fix_ip(jm.get('nw_src'))
  m.nw_dst = _fix_ip(jm.get('nw_dst'))
  m.tp_src = _fix_port(jm.get('tp_src'))
  m.tp_dst = _fix_port(jm.get('tp_dst'))
  #print jm,"\n",m
  return m

def _unfix_null (v):
  return v
def _unfix_port (v):
  return of.ofp_port_map.get(v, v)
def _unfix_ip (v):
  v = v()
  if v[1] == 0:
    if v[0] is None: return None
    return str(v[0])
  return "%s/%i" % v
def _unfix_str (v):
  return str(v)
def _unfix_ethertype (v):
  if v <= 0x05dc:
    return v
  #NOTE: This may just result in a hex string.  In that case, we might
  #      want to just use a number.
  return ethtype_to_str(v)

_unfix_map = {k:_unfix_null for k in of.ofp_match_data.keys()}
_unfix_map['in_port'] = _unfix_port
_unfix_map['dl_src'] = _unfix_str
_unfix_map['dl_dst'] = _unfix_str
_unfix_map['dl_type'] = _unfix_ethertype
_unfix_map['get_nw_src'] = _unfix_ip
_unfix_map['get_nw_dst'] = _unfix_ip

def match_to_dict (m):
  d = {}
  #TODO: Use symbolic names
  for k,func in _unfix_map.iteritems():
    v = getattr(m, k)
    if v is None: continue
    if k.startswith('get_'): k = k[4:]
    v = func(v)
    if v is None: continue
    d[k] = v
  return d


def action_to_dict (a):
  d = {}
  d['type'] = of.ofp_action_type_map.get(a.type, a.type)
  for k,v in fields_of(a).iteritems():
    if k in ['type','length']: continue
    if k == "port":
      v = of.ofp_port_map.get(v,v)
    d[k] = v
  return d


def dict_to_action (d):
  d = d.copy()
  if 'port' in d:
    d['port'] = _fix_of_int(d['port'])

  t = d['type'].upper()
  del d['type']
  if not t.startswith("OFPAT_"): t = "OFPAT_" + t
  t = of.ofp_action_type_rev_map[t]
  cls = of._action_type_to_class[t]
  a = cls(**d)
  return a


def flow_stats_to_list (flowstats):
  """
  Takes a list of flow stats
  """
  stats = []
  for stat in flowstats:
    s = {}
    stats.append(s)
    for k,v in fields_of(stat).iteritems():
      if k == 'length': continue
      if k.startswith('pad'): continue
      if k == 'match': v = match_to_dict(v)
      elif k == 'actions':
        v = [action_to_dict(a) for a in v]
      s[k] = v
  return stats


def switch_desc_to_dict (desc):
  """
  Takes ofp_desc_stats response
  """
  r = {}
  for k in ['mfr_desc','hw_desc','sw_desc','serial_num','dp_desc']:
    r[k] = getattr(desc, k)
  return r


def dict_to_flow_mod (flow):
  match = flow.get('match')
  if match is None:
    match = of.ofp_match()
  else:
    match = dict_to_match(match)

  actions = flow.get('actions', [])
  if not isinstance(actions, list): actions = [actions]
  actions = [dict_to_action(a) for a in actions]
  if 'output' in flow:
    a = of.ofp_action_output(port=_fix_of_int(flow['output']))
    po.actions.append(a)

  fm = of.ofp_flow_mod(match = match)
  fm.actions = actions

  for k in ['cookie','idle_timeout','hard_timeout','priority']:
    if k in flow:
      setattr(fm, k, flow[k])

  return fm


import pox.lib.packet as packetlib
valid_packet_types = {}
def _init ():
  candidates = [x for x in dir(packetlib) if x.isalpha()]
  good = set()
  for c in candidates:
    if c.lower() not in candidates: continue
    if c.upper() not in candidates: continue
    valid_packet_types[c.lower()] = getattr(packetlib, c.lower())
_init()

def dict_to_packet (d, parent=None):
  if isinstance(d, list):
    d = b''.join(chr(x) for x in data)
  if isinstance(d, basestring):
    return d

  payload = d.get('payload')
  d = d.copy()

  assert d['class'] in valid_packet_types
  cls = valid_packet_types[d['class']]
  example = cls()
  del d['class']

  for k,v in d.iteritems():
    assert not k.startswith('_')
    assert hasattr(example, k)
    assert k not in ['prev','next','raw','parsed']

  o = cls(prev=parent,**d)

  if payload is not None:
    o.payload = dict_to_packet(payload, o)

  return o


from pox.lib.packet.packet_base import packet_base

def fix_parsed (m):
  """
  Translate parsed packet data to dicts and stuff
  """
  if m is None:
    return {"type":"raw","data":[]}
  if isinstance(m, basestring):
    return {"type":"raw","data":[ord(b) for b in m]}
  assert isinstance(m, packet_base)
  if not m.parsed:
    u = fix_parsed(m.raw)
    u['unparsed_type'] = m.__class__.__name__
    return u
  r = {}
  for k,v in fields_of(m, primitives_only = False).iteritems():
    if is_scalar(v):
      r[k] = v
    elif isinstance(v, (IPAddr, EthAddr)):
      r[k] = str(v)
  if hasattr(m, "payload"):
    r['payload'] = fix_parsed(m.payload)
  if 'raw' in r:
    #r['raw'] = [ord(b) for b in m['raw']]
    del r['raw']
  if 'next' in r: del r['next']
  r['type'] = m.__class__.__name__
  return r


def dict_to_packet_out (d):
  """
  Converts dict to packet_out
  Also, special key "output" is an output port.
  """
  po = of.ofp_packet_out()
  po.buffer_id = d.get('buffer_id', -1)
  po.in_port = _fix_of_int(d.get('in_port', of.OFPP_NONE))
  actions = d.get('actions', [])
  actions = [dict_to_action(a) for a in actions]
  po.actions = actions
  if 'output' in d:
    a = of.ofp_action_output(port=_fix_of_int(d['output']))
    po.actions.append(a)

  if 'data' in d:
    data = dict_to_packet(d['data'])
    if hasattr(data, 'pack'):
      data = data.pack()
    po.data = data

  return po


def list_switches (ofnexus = None):
  if ofnexus is None:
    from pox.core import core
    ofnexus = core.openflow

  r = []
  for dpid,con in ofnexus._connections.iteritems():
    ports = []
    for p in con.ports.values():
      pdict = {
        'port_no':p.port_no,
        'hw_addr':str(p.hw_addr),
        'name':p.name}
      for bit,name in of.ofp_port_config_map.items():
        if p.config & bit:
          pdict[name.split('OFPPC_', 1)[-1].lower()] = True
      for bit,name in of.ofp_port_state_map.items():
        if p.state & bit:
          pdict[name.split('OFPPS_', 1)[-1].lower()] = True
      ports.append(pdict)
    ports.sort(key=lambda item:item['port_no'])

    rr = {
          'dpid':dpidToStr(dpid),
          'n_tables':con.features.n_tables,
          'ports':ports}
    r.append(rr)

  r.sort(key=lambda item:item['dpid'])
  return r

########NEW FILE########
__FILENAME__ = of_service
# Copyright 2011,2012 James McCauley
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at:
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""
This is a messenger service for interacting with OpenFlow.

There are lots of things that aren't implemented.  Please add!

There's now a simple webservice based on this.  If you add
functionality here, you might want to see about adding it to
the webservice too.
"""

from pox.core import core
import pox.openflow.libopenflow_01 as of
from pox.messenger import *
import sys
import traceback
from pox.openflow.of_json import *
from pox.lib.util import dpidToStr,strToDPID


log = core.getLogger()

def _type_str (m):
  return of.ofp_type_map.get(m.header_type, str(m.header_type))


def _ofp_entry (event):
  ofp = event.ofp
  if isinstance(ofp, list):
    ofp = ofp[0];
  m = { 'xid' : ofp.xid,
        'dpid' : dpidToStr(event.connection.dpid),
        'type_str' : _type_str(ofp),
        'header_type' : ofp.header_type,
      }
  return m


class OFBot (ChannelBot):
  def _init (self, extra):
    self.enable_packet_ins = False
    self.oflisteners = core.openflow.addListeners(self)

  def _destroyed (self):
    core.openflow.removeListeners(self.oflisteners)

  def _handle_ConnectionUp (self, event):
    #self.send(_ofp_entry(event))
    m = { 'type_str' : 'ConnectionUp', 'dpid' : dpidToStr(event.dpid) }
    self.send(m)

  def _handle_ConnectionDown (self, event):
    m = { 'type_str' : 'ConnectionDown', 'dpid' : dpidToStr(event.dpid) }
    self.send(m)

  def _handle_BarrierIn (self, event):
    self.send(_ofp_entry(event))

  def _handle_ErrorIn (self, event):
    m = { 'type' : event.ofp.type, 'code' : event.ofp.code,
          'msg' : event.asString(),
        }
    m.update(_ofp_entry(event))
    self.send(m)

  def _handle_SwitchDescReceived (self, event):
    m = _ofp_entry(event)
    m['switch_desc'] = switch_desc_to_dict(event.stats)
    self.send(m)

  def _handle_FlowStatsReceived (self, event):
    m = _ofp_entry(event)
    m['flow_stats'] = flow_stats_to_list(event.stats)
    self.send(m)

  def _handle_PacketIn (self, event):
    if not self.enable_packet_ins: return
    if len(self.channel._members) == 0: return
    m = { 'buffer_id' : event.ofp.buffer_id,
          'total_len' : event.ofp._total_len,
          'in_port' : event.ofp.in_port,
          'reason' : event.ofp.reason,
          #'data' : event.data,
        }
    m['payload'] = fix_parsed(event.parsed)
    m.update(_ofp_entry(event))

#    import json
#    try:
#      json.dumps(m,indent=2)
#    except:
#      print json.dumps(m,encoding="latin1",indent=2)

    self.send(m)


  def _exec_cmd_packet_out (self, event):
    try:
      msg = event.msg
      dpid = strToDPID(msg['dpid'])
      con = core.openflow.getConnection(dpid)
      if con is None:
        raise RuntimeError("No such switch")
      po = dict_to_packet_out(msg)
      con.send(po)

    except:
      log.exception("Exception in packet_out")
      self.reply(event,
                 exception="%s: %s" % (sys.exc_info()[0],sys.exc_info()[1]),
                 traceback=traceback.format_exc())

  def _exec_cmd_get_flow_stats (self, event):
    try:
      msg = event.msg
      dpid = strToDPID(msg['dpid'])
      con = core.openflow.getConnection(dpid)
      if con is None:
        raise RuntimeError("No such switch")

      match = event.msg.get('match')
      table_id = event.msg.get('table_id', 0xff)
      out_port = event.msg.get('out_port', of.OFPP_NONE)

      sr = of.ofp_stats_request()
      sr.body = of.ofp_flow_stats_request()
      if match is None:
        match = of.ofp_match()
      else:
        match = dict_to_match(match)
      sr.body.match = match
      sr.body.table_id = table_id
      sr.body.out_port = out_port
      con.send(sr)
      self.reply(event,**{'type':'set_table','xid':sr.xid})

    except:
      #log.exception("Exception in get_flow_stats")
      log.debug("Exception in get_flow_stats - %s:%s",
                sys.exc_info()[0].__name__,
                sys.exc_info()[1])
      self.reply(event,
                 exception="%s: %s" % (sys.exc_info()[0],sys.exc_info()[1]),
                 traceback=traceback.format_exc())

  def _exec_cmd_set_table (self, event):
    try:
      msg = event.msg
      dpid = strToDPID(msg['dpid'])
      con = core.openflow.getConnection(dpid)
      if con is None:
        raise RuntimeError("No such switch")

      xid = of.generate_xid()

      fm = of.ofp_flow_mod()
      fm.xid = xid
      fm.command = of.OFPFC_DELETE
      con.send(fm)
      bar = of.ofp_barrier_request()
      bar.xid = xid
      con.send(bar)

      for flow in msg.get('flows',[]):
        fm = dict_to_flow_mod(flow)
        fm.xid = xid

        con.send(fm)
        #con.send(of.ofp_barrier_request(xid=xid))
      con.send(of.ofp_barrier_request(xid=xid))

      self.reply(event,**{'type':'set_table','xid':xid})

    except:
      #log.exception("Exception in set_table")
      log.debug("Exception in set_table - %s:%s",
                sys.exc_info()[0].__name__,
                sys.exc_info()[1])
      self.reply(event,
                 exception="%s: %s" % (sys.exc_info()[0],sys.exc_info()[1]),
                 traceback=traceback.format_exc())

  #TODO: You should actually be able to configure packet in messages...
  #      for example, enabling raw data of the whole packet, and
  #      raw of individual parts.
  def _exec_packetins_True (self, event):
    self.enable_packet_ins = True

  def _exec_packetins_False (self, event):
    self.enable_packet_ins = False

  def _exec_cmd_list_switches (self, event):
    r = list_switches()
    self.send(switch_list = r)


def launch (nexus = "MessengerNexus"):
  def _launch ():
    # Make invitable
    core.MessengerNexus.default_bot.add_bot(OFBot)

    # Just stick one in a channel
    OFBot("of_01")

    # For now, just register something arbitrary so that we can use
    # this for dependencies
    core.register(nexus + "_of_service", object())

  core.call_when_ready(_launch, [nexus, "openflow"])

########NEW FILE########
__FILENAME__ = spanning_tree
# Copyright 2012,2013 James McCauley
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at:
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""
Creates a spanning tree.

This component uses the discovery component to build a view of the network
topology, constructs a spanning tree, and then disables flooding on switch
ports that aren't on the tree by setting their NO_FLOOD bit.  The result
is that topologies with loops no longer turn your network into useless
hot packet soup.

This component is inspired by and roughly based on the description of
Glenn Gibb's spanning tree module for NOX:
  http://www.openflow.org/wk/index.php/Basic_Spanning_Tree

Note that this does not have much of a relationship to Spanning Tree
Protocol.  They have similar purposes, but this is a rather different way
of going about it.
"""

from pox.core import core
import pox.openflow.libopenflow_01 as of
from pox.lib.revent import *
from collections import defaultdict
from pox.openflow.discovery import Discovery
from pox.lib.util import dpidToStr
from pox.lib.recoco import Timer
import time

log = core.getLogger()

# Might be nice if we made this accessible on core...
#_adj = defaultdict(lambda:defaultdict(lambda:[]))

def _calc_spanning_tree ():
  """
  Calculates the actual spanning tree

  Returns it as dictionary where the keys are DPID1, and the
  values are tuples of (DPID2, port-num), where port-num
  is the port on DPID1 connecting to DPID2.
  """
  def flip (link):
    return Discovery.Link(link[2],link[3], link[0],link[1])

  adj = defaultdict(lambda:defaultdict(lambda:[]))
  switches = set()
  # Add all links and switches
  for l in core.openflow_discovery.adjacency:
    adj[l.dpid1][l.dpid2].append(l)
    switches.add(l.dpid1)
    switches.add(l.dpid2)

  # Cull links -- we want a single symmetric link connecting nodes
  for s1 in switches:
    for s2 in switches:
      if s2 not in adj[s1]:
        continue
      if not isinstance(adj[s1][s2], list):
        continue
      assert s1 is not s2
      good = False
      for l in adj[s1][s2]:
        if flip(l) in core.openflow_discovery.adjacency:
          # This is a good one
          adj[s1][s2] = l.port1
          adj[s2][s1] = l.port2
          good = True
          break
      if not good:
        del adj[s1][s2]
        if s1 in adj[s2]:
          # Delete the other way too
          del adj[s2][s1]

  q = []
  more = set(switches)

  done = set()

  tree = defaultdict(set)

  while True:
    q = sorted(list(more)) + q
    more.clear()
    if len(q) == 0: break
    v = q.pop(False)
    if v in done: continue
    done.add(v)
    for w,p in adj[v].iteritems():
      if w in tree: continue
      more.add(w)
      tree[v].add((w,p))
      tree[w].add((v,adj[w][v]))

  if False:
    log.debug("*** SPANNING TREE ***")
    for sw,ports in tree.iteritems():
      #print " ", dpidToStr(sw), ":", sorted(list(ports))
      #print " ", sw, ":", [l[0] for l in sorted(list(ports))]
      log.debug((" %i : " % sw) + " ".join([str(l[0]) for l in
                                           sorted(list(ports))]))
    log.debug("*********************")

  return tree


# Keep a list of previous port states so that we can skip some port mods
# If other things mess with port states, these may not be correct.  We
# could also refer to Connection.ports, but those are not guaranteed to
# be up to date.
_prev = defaultdict(lambda : defaultdict(lambda : None))

# If True, we set ports down when a switch connects
_noflood_by_default = False

# If True, don't allow turning off flood bits until a complete discovery
# cycle should have completed (mostly makes sense with _noflood_by_default).
_hold_down = False


def _handle_ConnectionUp (event):
  # When a switch connects, forget about previous port states
  _prev[event.dpid].clear()

  if _noflood_by_default:
    con = event.connection
    log.debug("Disabling flooding for %i ports", len(con.ports))
    for p in con.ports.itervalues():
      if p.port_no >= of.OFPP_MAX: continue
      _prev[con.dpid][p.port_no] = False
      pm = of.ofp_port_mod(port_no=p.port_no,
                          hw_addr=p.hw_addr,
                          config = of.OFPPC_NO_FLOOD,
                          mask = of.OFPPC_NO_FLOOD)
      con.send(pm)
    _invalidate_ports(con.dpid)

  if _hold_down:
    t = Timer(core.openflow_discovery.send_cycle_time + 1, _update_tree,
              kw={'force_dpid':event.dpid})


def _handle_LinkEvent (event):
  # When links change, update spanning tree

  (dp1,p1),(dp2,p2) = event.link.end
  if _prev[dp1][p1] is False:
    if _prev[dp2][p2] is False:
      # We're disabling this link; who cares if it's up or down?
      #log.debug("Ignoring link status for %s", event.link)
      return

  _update_tree()


def _update_tree (force_dpid = None):
  """
  Update spanning tree

  force_dpid specifies a switch we want to update even if we are supposed
  to be holding down changes.
  """

  # Get a spanning tree
  tree = _calc_spanning_tree()
  log.debug("Spanning tree updated")

  # Connections born before this time are old enough that a complete
  # discovery cycle should have completed (and, thus, all of their
  # links should have been discovered).
  enable_time = time.time() - core.openflow_discovery.send_cycle_time - 1

  # Now modify ports as needed
  try:
    change_count = 0
    for sw, ports in tree.iteritems():
      con = core.openflow.getConnection(sw)
      if con is None: continue # Must have disconnected
      if con.connect_time is None: continue # Not fully connected

      if _hold_down:
        if con.connect_time > enable_time:
          # Too young -- we should hold down changes.
          if force_dpid is not None and sw == force_dpid:
            # .. but we'll allow it anyway
            pass
          else:
            continue

      tree_ports = [p[1] for p in ports]
      for p in con.ports.itervalues():
        if p.port_no < of.OFPP_MAX:
          flood = p.port_no in tree_ports
          if not flood:
            if core.openflow_discovery.is_edge_port(sw, p.port_no):
              flood = True
          if _prev[sw][p.port_no] is flood:
            #print sw,p.port_no,"skip","(",flood,")"
            continue # Skip
          change_count += 1
          _prev[sw][p.port_no] = flood
          #print sw,p.port_no,flood
          #TODO: Check results

          pm = of.ofp_port_mod(port_no=p.port_no,
                               hw_addr=p.hw_addr,
                               config = 0 if flood else of.OFPPC_NO_FLOOD,
                               mask = of.OFPPC_NO_FLOOD)
          con.send(pm)

          _invalidate_ports(con.dpid)
    if change_count:
      log.info("%i ports changed", change_count)
  except:
    _prev.clear()
    log.exception("Couldn't push spanning tree")


_dirty_switches = {} # A map dpid_with_dirty_ports->Timer
_coalesce_period = 2 # Seconds to wait between features requests

def _invalidate_ports (dpid):
  """
  Registers the fact that port info for dpid may be out of date

  When the spanning tree adjusts the port flags, the port config bits
  we keep in the Connection become out of date.  We don't want to just
  set them locally because an in-flight port status message could
  overwrite them.  We also might not want to assume they get set the
  way we want them.  SO, we do send a features request, but we wait a
  moment before sending it so that we can potentially coalesce several.

  TLDR: Port information for this switch may be out of date for around
        _coalesce_period seconds.
  """
  if dpid in _dirty_switches:
    # We're already planning to check
    return
  t = Timer(_coalesce_period, _check_ports, args=(dpid,))
  _dirty_switches[dpid] = t

def _check_ports (dpid):
  """
  Sends a features request to the given dpid
  """
  _dirty_switches.pop(dpid,None)
  con = core.openflow.getConnection(dpid)
  if con is None: return
  con.send(of.ofp_barrier_request())
  con.send(of.ofp_features_request())
  log.debug("Requested switch features for %s", str(con))


def launch (no_flood = False, hold_down = False):
  global _noflood_by_default, _hold_down
  if no_flood is True:
    _noflood_by_default = True
  if hold_down is True:
    _hold_down = True

  def start_spanning_tree ():
    core.openflow.addListenerByName("ConnectionUp", _handle_ConnectionUp)
    core.openflow_discovery.addListenerByName("LinkEvent", _handle_LinkEvent)
    log.debug("Spanning tree component ready")
  core.call_when_ready(start_spanning_tree, "openflow_discovery")

########NEW FILE########
__FILENAME__ = topology
# Copyright 2011 James McCauley
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at:
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""
OpenFlow doesn't know anything about Topology, and Topology doesn't
know anything about OpenFlow.  This module knows something about both,
and hooks the two of them together.

Specifically, this module is somewhat like an adapter that listens to
events from other parts of the openflow substem (such as discovery), and
uses them to populate and manipulate Topology.
"""

import itertools

from pox.lib.revent import *
import libopenflow_01 as of
from pox.openflow import *
from pox.core import core
from pox.topology.topology import *
from pox.openflow.discovery import *
from pox.openflow.libopenflow_01 import xid_generator
from pox.openflow.flow_table import FlowTable,FlowTableModification,TableEntry
from pox.lib.util import dpidToStr
from pox.lib.addresses import *

import pickle
import itertools

# After a switch disconnects, it has this many seconds to reconnect in
# order to reactivate the same OpenFlowSwitch object.  After this, if
# it reconnects, it will be a new switch object.
RECONNECT_TIMEOUT = 30

log = core.getLogger()

class OpenFlowTopology (object):
  """
  Listens to various OpenFlow-specific events and uses those to manipulate
  Topology accordingly.
  """

  def __init__ (self):
    core.listen_to_dependencies(self, ['topology'], short_attrs=True)

  def _handle_openflow_discovery_LinkEvent (self, event):
    """
    The discovery module simply sends out LLDP packets, and triggers
    LinkEvents for discovered switches. It's our job to take these
    LinkEvents and update pox.topology.
    """
    link = event.link
    sw1 = self.topology.getEntityByID(link.dpid1)
    sw2 = self.topology.getEntityByID(link.dpid2)
    if sw1 is None or sw2 is None: return
    if link.port1 not in sw1.ports or link.port2 not in sw2.ports: return
    if event.added:
      sw1.ports[link.port1].addEntity(sw2, single=True)
      sw2.ports[link.port2].addEntity(sw1, single=True)
    elif event.removed:
      sw1.ports[link.port1].entities.discard(sw2)
      sw2.ports[link.port2].entities.discard(sw1)

  def _handle_openflow_ConnectionUp (self, event):
    sw = self.topology.getEntityByID(event.dpid)
    add = False
    if sw is None:
      sw = OpenFlowSwitch(event.dpid)
      add = True
    else:
      if sw._connection is not None:
        log.warn("Switch %s connected, but... it's already connected!" %
                 (dpidToStr(event.dpid),))
    sw._setConnection(event.connection, event.ofp)
    log.info("Switch " + dpidToStr(event.dpid) + " connected")
    if add:
      self.topology.addEntity(sw)
      sw.raiseEvent(SwitchJoin, sw)

  def _handle_openflow_ConnectionDown (self, event):
    sw = self.topology.getEntityByID(event.dpid)
    if sw is None:
      log.warn("Switch %s disconnected, but... it doesn't exist!" %
               (dpidToStr(event.dpid),))
    else:
      if sw._connection is None:
        log.warn("Switch %s disconnected, but... it's wasn't connected!" %
                 (dpidToStr(event.dpid),))
      sw._connection = None
      log.info("Switch " + str(event.dpid) + " disconnected")


class OpenFlowPort (Port):
  """
  A subclass of topology.Port for OpenFlow switch ports.

  Adds the notion of "connected entities", which the default
  ofp_phy_port class does not have.

  Note: Not presently used.
  """
  def __init__ (self, ofp):
    # Passed an ofp_phy_port
    Port.__init__(self, ofp.port_no, ofp.hw_addr, ofp.name)
    self.isController = self.number == of.OFPP_CONTROLLER
    self._update(ofp)
    self.exists = True
    self.entities = set()

  def _update (self, ofp):
    assert self.name == ofp.name
    assert self.number == ofp.port_no
    self.hwAddr = EthAddr(ofp.hw_addr)
    self._config = ofp.config
    self._state = ofp.state

  def __contains__ (self, item):
    """ True if this port connects to the specified entity """
    return item in self.entities

  def addEntity (self, entity, single = False):
    # Invariant (not currently enforced?):
    #   len(self.entities) <= 2  ?
    if single:
      self.entities = set([entity])
    else:
      self.entities.add(entity)

  def to_ofp_phy_port(self):
    return of.ofp_phy_port(port_no = self.number, hw_addr = self.hwAddr,
                           name = self.name, config = self._config,
                           state = self._state)

  def __repr__ (self):
    return "<Port #" + str(self.number) + ">"


class OpenFlowSwitch (EventMixin, Switch):
  """
  OpenFlowSwitches are Topology entities (inheriting from topology.Switch)

  OpenFlowSwitches are persistent; that is, if a switch reconnects, the
  Connection field of the original OpenFlowSwitch object will simply be
  reset to refer to the new connection.

  For now, OpenFlowSwitch is primarily a proxy to its underlying connection
  object. Later, we'll possibly add more explicit operations the client can
  perform.

  Note that for the purposes of the debugger, we can interpose on
  a switch entity by enumerating all listeners for the events listed
  below, and triggering mock events for those listeners.
  """
  _eventMixin_events = set([
    SwitchJoin, # Defined in pox.topology
    SwitchLeave,
    SwitchConnectionUp,
    SwitchConnectionDown,

    PortStatus, # Defined in libopenflow_01
    FlowRemoved,
    PacketIn,
    BarrierIn,
  ])

  def __init__ (self, dpid):
    if not dpid:
      raise AssertionError("OpenFlowSwitch should have dpid")

    Switch.__init__(self, id=dpid)
    EventMixin.__init__(self)
    self.dpid = dpid
    self.ports = {}
    self.flow_table = OFSyncFlowTable(self)
    self.capabilities = 0
    self._connection = None
    self._listeners = []
    self._reconnectTimeout = None # Timer for reconnection
    self._xid_generator = xid_generator( ((dpid & 0x7FFF) << 16) + 1)

  def _setConnection (self, connection, ofp=None):
    ''' ofp - a FeaturesReply message '''
    if self._connection: self._connection.removeListeners(self._listeners)
    self._listeners = []
    self._connection = connection
    if self._reconnectTimeout is not None:
      self._reconnectTimeout.cancel()
      self._reconnectTimeout = None
    if connection is None:
      self._reconnectTimeout = Timer(RECONNECT_TIMEOUT,
                                     self._timer_ReconnectTimeout)
    if ofp is not None:
      # update capabilities
      self.capabilities = ofp.capabilities
      # update all ports
      untouched = set(self.ports.keys())
      for p in ofp.ports:
        if p.port_no in self.ports:
          self.ports[p.port_no]._update(p)
          untouched.remove(p.port_no)
        else:
          self.ports[p.port_no] = OpenFlowPort(p)
      for p in untouched:
        self.ports[p].exists = False
        del self.ports[p]
    if connection is not None:
      self._listeners = self.listenTo(connection, prefix="con")
      self.raiseEvent(SwitchConnectionUp(switch = self,
                                         connection = connection))
    else:
      self.raiseEvent(SwitchConnectionDown(self))


  def _timer_ReconnectTimeout (self):
    """ Called if we've been disconnected for RECONNECT_TIMEOUT seconds """
    self._reconnectTimeout = None
    core.topology.removeEntity(self)
    self.raiseEvent(SwitchLeave, self)

  def _handle_con_PortStatus (self, event):
    p = event.ofp.desc
    if event.ofp.reason == of.OFPPR_DELETE:
      if p.port_no in self.ports:
        self.ports[p.port_no].exists = False
        del self.ports[p.port_no]
    elif event.ofp.reason == of.OFPPR_MODIFY:
      self.ports[p.port_no]._update(p)
    else:
      assert event.ofp.reason == of.OFPPR_ADD
      assert p.port_no not in self.ports
      self.ports[p.port_no] = OpenFlowPort(p)
    self.raiseEvent(event)
    event.halt = False

  def _handle_con_ConnectionDown (self, event):
    self._setConnection(None)

  def _handle_con_PacketIn (self, event):
    self.raiseEvent(event)
    event.halt = False

  def _handle_con_BarrierIn (self, event):
    self.raiseEvent(event)
    event.halt = False

  def _handle_con_FlowRemoved (self, event):
    self.raiseEvent(event)
    self.flowTable.removeFlow(event)
    event.halt = False

  def findPortForEntity (self, entity):
    for p in self.ports.itervalues():
      if entity in p:
        return p
    return None

  @property
  def connected(self):
    return self._connection != None

  def installFlow(self, **kw):
    """ install flow in the local table and the associated switch """
    self.flow_table.install(TableEntry(**kw))

  def serialize (self):
    # Skip over non-serializable data, e.g. sockets
    serializable = OpenFlowSwitch(self.dpid)
    return pickle.dumps(serializable, protocol = 0)

  def send(self, *args, **kw):
    return self._connection.send(*args, **kw)

  def read(self, *args, **kw):
   return self._connection.read(*args, **kw)

  def __repr__ (self):
    return "<%s %s>" % (self.__class__.__name__, dpidToStr(self.dpid))

  @property
  def name(self):
    return repr(self)


class OFSyncFlowTable (EventMixin):
  _eventMixin_events = set([FlowTableModification])
  """
  A flow table that keeps in sync with a switch
  """
  ADD = of.OFPFC_ADD
  REMOVE = of.OFPFC_DELETE
  REMOVE_STRICT = of.OFPFC_DELETE_STRICT
  TIME_OUT = 2

  def __init__ (self, switch=None, **kw):
    EventMixin.__init__(self)
    self.flow_table = FlowTable()
    self.switch = switch

    # a list of pending flow table entries : tuples (ADD|REMOVE, entry)
    self._pending = []

    # a map of pending barriers barrier_xid-> ([entry1,entry2])
    self._pending_barrier_to_ops = {}
    # a map of pending barriers per request entry -> (barrier_xid, time)
    self._pending_op_to_barrier = {}

    self.listenTo(switch)

  def install (self, entries=[]):
    """
    asynchronously install entries in the flow table

    will raise a FlowTableModification event when the change has been
    processed by the switch
    """
    self._mod(entries, OFSyncFlowTable.ADD)

  def remove_with_wildcards (self, entries=[]):
    """
    asynchronously remove entries in the flow table

    will raise a FlowTableModification event when the change has been
    processed by the switch
    """
    self._mod(entries, OFSyncFlowTable.REMOVE)

  def remove_strict (self, entries=[]):
    """
    asynchronously remove entries in the flow table.

    will raise a FlowTableModification event when the change has been
    processed by the switch
    """
    self._mod(entries, OFSyncFlowTable.REMOVE_STRICT)

  @property
  def entries (self):
    return self.flow_table.entries

  @property
  def num_pending (self):
    return len(self._pending)

  def __len__ (self):
    return len(self.flow_table)

  def _mod (self, entries, command):
    if isinstance(entries, TableEntry):
      entries = [ entries ]

    for entry in entries:
      if(command == OFSyncFlowTable.REMOVE):
        self._pending = [(cmd,pentry) for cmd,pentry in self._pending
                         if not (cmd == OFSyncFlowTable.ADD
                                 and entry.matches_with_wildcards(pentry))]
      elif(command == OFSyncFlowTable.REMOVE_STRICT):
        self._pending = [(cmd,pentry) for cmd,pentry in self._pending
                         if not (cmd == OFSyncFlowTable.ADD
                                 and entry == pentry)]

      self._pending.append( (command, entry) )

    self._sync_pending()

  def _sync_pending (self, clear=False):
    if not self.switch.connected:
      return False

    # resync the switch
    if clear:
      self._pending_barrier_to_ops = {}
      self._pending_op_to_barrier = {}
      self._pending = filter(lambda(op): op[0] == OFSyncFlowTable.ADD,
                             self._pending)

      self.switch.send(of.ofp_flow_mod(command=of.OFPFC_DELETE,
                                       match=of.ofp_match()))
      self.switch.send(of.ofp_barrier_request())

      todo = map(lambda(e): (OFSyncFlowTable.ADD, e),
                 self.flow_table.entries) + self._pending
    else:
      todo = [op for op in self._pending
              if op not in self._pending_op_to_barrier
              or (self._pending_op_to_barrier[op][1]
                  + OFSyncFlowTable.TIME_OUT) < time.time() ]

    for op in todo:
      fmod_xid = self.switch._xid_generator()
      flow_mod = op[1].to_flow_mod(xid=fmod_xid, command=op[0],
                                   flags=op[1].flags | of.OFPFF_SEND_FLOW_REM)
      self.switch.send(flow_mod)

    barrier_xid = self.switch._xid_generator()
    self.switch.send(of.ofp_barrier_request(xid=barrier_xid))
    now = time.time()
    self._pending_barrier_to_ops[barrier_xid] = todo

    for op in todo:
      self._pending_op_to_barrier[op] = (barrier_xid, now)

  def _handle_SwitchConnectionUp (self, event):
    # sync all_flows
    self._sync_pending(clear=True)

  def _handle_SwitchConnectionDown (self, event):
    # connection down. too bad for our unconfirmed entries
    self._pending_barrier_to_ops = {}
    self._pending_op_to_barrier = {}

  def _handle_BarrierIn (self, barrier):
    # yeah. barrier in. time to sync some of these flows
    if barrier.xid in self._pending_barrier_to_ops:
      added = []
      removed = []
      #print "barrier in: pending for barrier: %d: %s" % (barrier.xid,
      #    self._pending_barrier_to_ops[barrier.xid])
      for op in self._pending_barrier_to_ops[barrier.xid]:
        (command, entry) = op
        if(command == OFSyncFlowTable.ADD):
          self.flow_table.add_entry(entry)
          added.append(entry)
        else:
          removed.extend(self.flow_table.remove_matching_entries(entry.match,
              entry.priority, strict=command == OFSyncFlowTable.REMOVE_STRICT))
        #print "op: %s, pending: %s" % (op, self._pending)
        if op in self._pending: self._pending.remove(op)
        self._pending_op_to_barrier.pop(op, None)
      del self._pending_barrier_to_ops[barrier.xid]
      self.raiseEvent(FlowTableModification(added = added, removed=removed))
      return EventHalt
    else:
      return EventContinue

  def _handle_FlowRemoved (self, event):
    """
    process a flow removed event -- remove the matching flow from the table.
    """
    flow_removed = event.ofp
    for entry in self.flow_table.entries:
      if (flow_removed.match == entry.match
          and flow_removed.priority == entry.priority):
        self.flow_table.remove_entry(entry)
        self.raiseEvent(FlowTableModification(removed=[entry]))
        return EventHalt
    return EventContinue


def launch ():
  if not core.hasComponent("openflow_topology"):
    core.register("openflow_topology", OpenFlowTopology())

########NEW FILE########
__FILENAME__ = util
# Copyright 2011-2013 James McCauley
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at:
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import pox.openflow.libopenflow_01 as of
import struct
from pox.lib.revent import EventMixin
import pox.openflow

def make_type_to_unpacker_table ():
  """
  Returns a list of unpack methods.

  The resulting list maps OpenFlow types to functions which unpack
  data for those types into message objects.
  """

  top = max(of._message_type_to_class)

  r = [of._message_type_to_class[i].unpack_new for i in range(0, top)]

  return r


class DPIDWatcher (EventMixin):
  """
  Strains OpenFlow messages by DPID
  """

  #TODO: Reference count handling

  _eventMixin_events = pox.openflow.OpenFlowNexus._eventMixin_events

  def __init__ (self, dpid, nexus = None, invert = False):

    if nexus is None:
      from pox.core import core
      nexus = core.openflow

    self.invert = invert

    self._dpids = set()
    if isinstance(dpid, str):
      dpid = dpid.replace(',',' ')
      dpid = dpid.split()
    if isinstance(dpid, (list,tuple)):
      for d in dpid:
        self._add_dpid(d)
    else:
      self._add_dpid(dpid)

    #core.listen_to_dependencies(self)

    for ev in self._eventMixin_events:
      nexus.addListener(ev, self._handler)

  def _handler (self, event, *args, **kw):
    dpid = getattr(event, 'dpid', None)
    if dpid is None:
      return

    if self.invert:
      if event.dpid in self._dpids: return
    else:
      if event.dpid not in self._dpids: return

    if len(args) or len(kw):
      log.warn("Custom invoke for %s", event)
      # This is a warning because while I think this will always or almost
      # always work, I didn't feel like checking.

    self.raiseEventNoErrors(event)

  def _add_dpid (self, dpid):
    if dpid is True:
      # Special case -- everything!
      self._dpids = True
      return
    elif self._dpids is True:
      self._dpids = set()
    try:
      dpid = int(dpid)
    except:
      dpid = str_to_dpid(dpid)
    self._dpids.add(dpid)

########NEW FILE########
__FILENAME__ = webservice
# Copyright 2012 James McCauley
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at:
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""
A simple JSON-RPC-ish web service for interacting with OpenFlow.

This is not incredibly robust or performant or anything.  It's a demo.
It's derived from the of_service messenger service, so see it for some
more details.  Also, if you add features to this, please think about
adding them to the messenger service too.

Current commands include:
  set_table
    Sets the flow table on a switch.
    dpid - a string dpid
    flows - a list of flow entries
  get_switch_desc
    Gets switch details.
    dpid - a string dpid
  get_flow_stats
    Get list of flows on table.
    dpid - a string dpid
    match - match structure (optional, defaults to match all)
    table_id - table for flows (defaults to all)
    out_port - filter by out port (defaults to all)
  get_switches
    Get list of switches and their basic info.

Example - Make a hub:
curl -i -X POST -d '{"method":"set_table","params":{"dpid":
 "00-00-00-00-00-01","flows":[{"actions":[{"type":"OFPAT_OUTPUT",
 "port":"OFPP_ALL"}],"match":{}}]}}' http://127.0.0.1:8000/OF/
"""

import sys
from pox.lib.util import dpidToStr, strToDPID, fields_of
from pox.core import core
import pox.openflow.libopenflow_01 as of
from pox.openflow.of_json import *
from pox.web.jsonrpc import JSONRPCHandler, make_error
import threading

log = core.getLogger()


class OFConRequest (object):
  """
  Superclass for requests that send commands to a connection and
  wait for responses.
  """
  def __init__ (self, con, *args, **kw):
    self._response = None
    self._sync = threading.Event()
    self._aborted = False
    self._listeners = None
    self._con = con
    #self._init(*args, **kw)
    core.callLater(self._do_init, args, kw)

  def _do_init (self, args, kw):
    self._listeners = self._con.addListeners(self)
    self._init(*args, **kw)

  def _init (self, *args, **kw):
    #log.warn("UNIMPLEMENTED REQUEST INIT")
    pass

  def get_response (self):
    if not self._sync.wait(5):
      # Whoops; timeout!
      self._aborted = True
      self._finish()
      raise RuntimeError("Operation timed out")
    return self._response

  def _finish (self, value = None):
    if self._response is None:
      self._response = value
    self._sync.set()
    self._con.removeListeners(self._listeners)

  def _result (self, key, value):
    self._finish({'result':{key:value,'dpid':dpidToStr(self._con.dpid)}})


class OFSwitchDescRequest (OFConRequest):
  def _init (self):
    sr = of.ofp_stats_request()
    sr.type = of.OFPST_DESC
    self._con.send(sr)
    self.xid = sr.xid

  def _handle_SwitchDescReceived (self, event):
    if event.ofp.xid != self.xid: return
    r = switch_desc_to_dict(event.stats)
    self._result('switchdesc', r)

  def _handle_ErrorIn (self, event):
    if event.ofp.xid != self.xid: return
    self._finish(make_error("OpenFlow Error", data=event.asString()))


class OFFlowStatsRequest (OFConRequest):
  def _init (self, match=None, table_id=0xff, out_port=of.OFPP_NONE):
    sr = of.ofp_stats_request()
    sr.body = of.ofp_flow_stats_request()
    if match is None:
      match = of.ofp_match()
    else:
      match = dict_to_match(match)
    sr.body.match = match
    sr.body.table_id = table_id
    sr.body.out_port = out_port
    self._con.send(sr)
    self.xid = sr.xid

  def _handle_FlowStatsReceived (self, event):
    if event.ofp[0].xid != self.xid: return
    stats = flow_stats_to_list(event.stats)

    self._result('flowstats', stats)

  def _handle_ErrorIn (self, event):
    if event.ofp.xid != self.xid: return
    self._finish(make_error("OpenFlow Error", data=event.asString()))


class OFSetTableRequest (OFConRequest):

  def clear_table (self, xid = None):
    fm = of.ofp_flow_mod()
    fm.xid = xid
    fm.command = of.OFPFC_DELETE
    self._con.send(fm)
    bar = of.ofp_barrier_request()
    bar.xid = xid
    self._con.send(bar)
    #TODO: Watch for errors on these

  def _init (self, flows = []):
    self.done = False

    xid = of.generate_xid()
    self.xid = xid
    self.clear_table(xid=xid)

    self.count = 1 + len(flows)

    for flow in flows:
      fm = dict_to_flow_mod(flow)
      fm.xid = xid

      self._con.send(fm)
      self._con.send(of.ofp_barrier_request(xid=xid))

  def _handle_BarrierIn (self, event):
    if event.ofp.xid != self.xid: return
    if self.done: return
    self.count -= 1
    if self.count <= 0:
      self._result('flowmod', True)
      self.done = True

  def _handle_ErrorIn (self, event):
    if event.ofp.xid != self.xid: return
    if self.done: return
    self.clear_table()
    self.done = True
    self._finish(make_error("OpenFlow Error", data=event.asString()))


class OFRequestHandler (JSONRPCHandler):

  def _exec_set_table (self, dpid, flows):
    dpid = strToDPID(dpid)
    con = core.openflow.getConnection(dpid)
    if con is None:
      return make_error("No such switch")

    return OFSetTableRequest(con, flows).get_response()

  def _exec_get_switch_desc (self, dpid):
    dpid = strToDPID(dpid)
    con = core.openflow.getConnection(dpid)
    if con is None:
      return make_error("No such switch")

    return OFSwitchDescRequest(con).get_response()

  def _exec_get_flow_stats (self, dpid, *args, **kw):
    dpid = strToDPID(dpid)
    con = core.openflow.getConnection(dpid)
    if con is None:
      return make_error("No such switch")

    return OFFlowStatsRequest(con, *args, **kw).get_response()

  def _exec_get_switches (self):
    return {'result':list_switches()}



def launch (username='', password=''):
  def _launch ():
    cfg = {}
    if len(username) and len(password):
      cfg['auth'] = lambda u, p: (u == username) and (p == password)
    core.WebServer.set_handler("/OF/",OFRequestHandler,cfg,True)

  core.call_when_ready(_launch, ["WebServer","openflow"],
                       name = "openflow.webservice")

########NEW FILE########
__FILENAME__ = arp_helper
# Copyright 2011,2012,2013 James McCauley
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at:
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""
A utility module for handling some mundane parts of ARP
"""

"""
TODO
----
arp_responder should be refactored to use this.  Also, it should be possible
to have a simple ARP learner which keeps an ARP table without responding...
"""

from pox.core import core
import pox
log = core.getLogger()

from pox.lib.packet.ethernet import ethernet, ETHER_BROADCAST
from pox.lib.packet.arp import arp
from pox.lib.addresses import EthAddr, IPAddr
from pox.lib.util import dpid_to_str, str_to_bool
from pox.lib.revent import EventHalt, Event, EventMixin

import pox.openflow.libopenflow_01 as of



def send_arp_reply (reply_to, mac, src_mac = None, src_ip = None):
  """
  Send an ARP reply.

  src_mac can be None to use the "DPID MAC" or True to use the port Mac.
    (or it can be an EthAddr)
  """
  # reply_to should be a PacketIn event
  arpp = reply_to.parsed.find('arp')
  mac = EthAddr(mac)
  if src_mac is None:
    #src_mac = mac # Used to be this ???
    src_mac = reply_to.connection.eth_addr
  elif src_mac is True:
    src_mac = reply_to.connection.ports[reply_to.port].hw_addr
  else:
    src_mac = EthAddr(src_mac)
  r = arp()
  r.opcode = r.REPLY
  r.hwdst = arpp.hwsrc
  r.protodst = arpp.protosrc
  r.hwsrc = EthAddr(src_mac)
  r.protosrc = IPAddr("0.0.0.0") if src_ip is None else IPAddr(src_ip)
  e = ethernet(type=ethernet.ARP_TYPE, src=src_mac, dst=r.hwdst)
  e.payload = r
  msg = of.ofp_packet_out()
  msg.data = e.pack()
  msg.actions.append(of.ofp_action_output(port = reply_to.port))
  msg.in_port = of.OFPP_NONE
  reply_to.connection.send(msg)


def send_arp_request (connection, ip, port = of.OFPP_FLOOD,
                      src_mac = None, src_ip = None):
  """
  Send an ARP request

  src_mac can be None to use the "DPID MAC" or True to use the port Mac.
    (or it can be an EthAddr)
  """
  if src_mac is None:
    src_mac = connection.eth_addr
  elif src_mac is True:
    if port in (of.OFPP_FLOOD, of.OFPP_ALL):
      for p in connection.ports.values():
        if p.config & OFPPC_NO_FLOOD:
          if port == of.ofPP_FLOOD:
            continue
        if p.port_no < 0: continue
        if p.port_no > of.OFPP_MAX: continue # Off by one?
        send_arp_request(connection, ip, p.port_no,
                         src_mac=p.hw_addr, src_ip=src_ip)
      return
    src_mac = connection.ports[port].hw_addr
  else:
    src_mac = EthAddr(src_mac)
  r = arp()
  r.opcode = r.REQUEST
  r.hwdst = ETHER_BROADCAST
  r.protodst = IPAddr(ip)
  r.hwsrc = src_mac
  r.protosrc = IPAddr("0.0.0.0") if src_ip is None else IPAddr(src_ip)
  e = ethernet(type=ethernet.ARP_TYPE, src=src_mac, dst=r.hwdst)
  e.payload = r
  msg = of.ofp_packet_out()
  msg.data = e.pack()
  msg.actions.append(of.ofp_action_output(port = port))
  msg.in_port = of.OFPP_NONE
  connection.send(msg)


class ARPRequest (Event):
  @property
  def dpid (self):
    return self.connection.dpid

  def __str__ (self):
    return "ARPRequest for %s on %s"  % (self.ip, dpid_to_str(self.dpid))

  def __init__ (self, con, arpp, reply_from, eat_packet, port):
    super(ARPRequest,self).__init__()
    self.connection = con
    self.request = arpp # ARP packet
    self.reply_from = reply_from # MAC
    self.eat_packet = eat_packet
    self.port = port

    self.ip = arpp.protosrc
    self.reply = None # Set to desired EthAddr


class ARPReply (Event):
  @property
  def dpid (self):
    return self.connection.dpid

  def __str__ (self):
    return "ARPReply for %s on %s"  % (self.reply.protodst,
                                       dpid_to_str(self.dpid))

  def __init__ (self, con, arpp, eat_packet, port):
    super(ARPReply,self).__init__()
    self.connection = con
    self.reply = arpp
    self.eat_packet = eat_packet
    self.port = port


_default_src_mac = object()

class ARPHelper (EventMixin):
  _eventMixin_events = set([ARPRequest,ARPReply])
  _rule_priority = 0x7000 # Pretty high

  def __init__ (self, no_flow, eat_packets, use_port_mac = False):
    core.addListeners(self)
    self._install_flow = not no_flow
    self.eat_packets = eat_packets
    self.use_port_mac = use_port_mac

  def send_arp_request (self, connection, ip, port = of.OFPP_FLOOD,
                        src_mac = _default_src_mac, src_ip = None):
    if src_mac is _default_src_mac:
      src_mac = True if self.use_port_mac else None
    return send_arp_request(connection, ip, port, src_mac, src_ip)

  def send_arp_reply (self, reply_to, mac,
                      src_mac = _default_src_mac, src_ip = None):
    if src_mac is _default_src_mac:
      src_mac = True if self.use_port_mac else None
    return send_arp_reply(reply_to, mac, src_mac, src_ip)

  def _handle_GoingUpEvent (self, event):
    core.openflow.addListeners(self)
    log.debug("Up...")

  def _handle_ConnectionUp (self, event):
    if self._install_flow:
      fm = of.ofp_flow_mod()
      fm.priority = self._rule_priority
      fm.match.dl_type = ethernet.ARP_TYPE
      fm.actions.append(of.ofp_action_output(port=of.OFPP_CONTROLLER))
      event.connection.send(fm)

  def _handle_PacketIn (self, event):
    dpid = event.connection.dpid
    inport = event.port
    packet = event.parsed

    a = packet.find('arp')
    if not a: return

    if a.prototype != arp.PROTO_TYPE_IP:
      return

    if a.hwtype != arp.HW_TYPE_ETHERNET:
      return

    if a.opcode == arp.REQUEST:
      log.debug("%s ARP request %s => %s", dpid_to_str(dpid),
                a.protosrc, a.protodst)

      if self.use_port_mac:
        src_mac = event.connection.ports[inport].hw_addr
      else:
        src_mac = event.connection.eth_addr
      ev = ARPRequest(event.connection, a, src_mac,
                      self.eat_packets, inport)
      self.raiseEvent(ev)
      if ev.reply is not None:
        r = arp()
        r.hwtype = a.hwtype
        r.prototype = a.prototype
        r.hwlen = a.hwlen
        r.protolen = a.protolen
        r.opcode = arp.REPLY
        r.hwdst = a.hwsrc
        r.protodst = a.protosrc
        r.protosrc = a.protodst
        r.hwsrc = EthAddr(ev.reply)
        e = ethernet(type=packet.type, src=ev.reply_from, dst=a.hwsrc)
        e.payload = r
        log.debug("%s answering ARP for %s" % (dpid_to_str(dpid),
            str(r.protosrc)))
        msg = of.ofp_packet_out()
        msg.data = e.pack()
        msg.actions.append(of.ofp_action_output(port =
                                                of.OFPP_IN_PORT))
        msg.in_port = inport
        event.connection.send(msg)
        return EventHalt if ev.eat_packet else None

    elif a.opcode == arp.REPLY:
      log.debug("%s ARP reply %s => %s", dpid_to_str(dpid),
                a.protosrc, a.hwsrc)

      ev = ARPReply(event.connection,a,self.eat_packets,inport)
      self.raiseEvent(ev)
      return EventHalt if ev.eat_packet else None

    return EventHalt if self.eat_packets else None


def launch (no_flow=False, eat_packets=True, use_port_mac = False):
  core.registerNew(ARPHelper, str_to_bool(no_flow), str_to_bool(eat_packets),
                   str_to_bool(use_port_mac))

########NEW FILE########
__FILENAME__ = arp_responder
# Copyright 2011,2012 James McCauley
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at:
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""
An ARP utility that can learn and proxy ARPs, and can also answer queries
from a list of static entries.

This adds the "arp" object to the console, which you can use to look at
or modify the ARP table.

Add ARP entries on commandline like:
  arp_responder --<IP>=<MAC> --<IP>=<MAC>

Leave MAC unspecified if you want to use the switch MAC.
"""

from pox.core import core
import pox
log = core.getLogger()

from pox.lib.packet.ethernet import ethernet, ETHER_BROADCAST
from pox.lib.packet.arp import arp
from pox.lib.packet.vlan import vlan
from pox.lib.addresses import IPAddr, EthAddr
from pox.lib.util import dpid_to_str, str_to_bool
from pox.lib.recoco import Timer
from pox.lib.revent import EventHalt

import pox.openflow.libopenflow_01 as of

import time


# Timeout for ARP entries
ARP_TIMEOUT = 60 * 4


class Entry (object):
  """
  We use the MAC to answer ARP replies.
  We use the timeout so that if an entry is older than ARP_TIMEOUT, we
   flood the ARP request rather than try to answer it ourselves.
  """
  def __init__ (self, mac, static = None, flood = None):
    self.timeout = time.time() + ARP_TIMEOUT
    self.static = False
    self.flood = True
    if mac is True:
      # Means use switch's MAC, implies static/noflood
      self.mac = True
      self.static = True
      self.flood = False
    else:
      self.mac = EthAddr(mac)

    if static is not None:
      self.static = static
    if flood is not None:
      self.flood = flood

  def __eq__ (self, other):
    if isinstance(other, Entry):
      return (self.static,self.mac)==(other.static,other.mac)
    else:
      return self.mac == other
  def __ne__ (self, other):
    return not self.__eq__(other)

  @property
  def is_expired (self):
    if self.static: return False
    return time.time() > self.timeout


class ARPTable (dict):
  def __repr__ (self):
    o = []
    for k,e in self.iteritems():
      t = int(e.timeout - time.time())
      if t < 0:
        t = "X"
      else:
        t = str(t) + "s left"
      if e.static: t = "-"
      mac = e.mac
      if mac is True: mac = "<Switch MAC>"
      o.append((k,"%-17s %-20s %3s" % (k, mac, t)))

    for k,t in _failed_queries.iteritems():
      if k not in self:
        t = int(time.time() - t)
        o.append((k,"%-17s %-20s %3ss ago" % (k, '?', t)))

    o.sort()
    o = [e[1] for e in o]
    o.insert(0,"-- ARP Table -----")
    if len(o) == 1:
      o.append("<< Empty >>")
    return "\n".join(o)

  def __setitem__ (self, key, val):
    key = IPAddr(key)
    if not isinstance(val, Entry):
      val = Entry(val)
    dict.__setitem__(self, key, val)

  def __delitem__ (self, key):
    key = IPAddr(key)
    dict.__delitem__(self, key)

  def set (self, key, value=True, static=True):
    if not isinstance(value, Entry):
      value = Entry(value, static=static)
    self[key] = value


def _dpid_to_mac (dpid):
  # Should maybe look at internal port MAC instead?
  return EthAddr("%012x" % (dpid & 0xffFFffFFffFF,))


def _handle_expiration ():
  for k,e in _arp_table.items():
    if e.is_expired:
      del _arp_table[k]
  for k,t in _failed_queries.items():
    if time.time() - t > ARP_TIMEOUT:
      del _failed_queries[k]


class ARPResponder (object):
  def __init__ (self):
    # This timer handles expiring stuff
    self._expire_timer = Timer(5, _handle_expiration, recurring=True)

    core.addListeners(self)

  def _handle_GoingUpEvent (self, event):
    core.openflow.addListeners(self)
    log.debug("Up...")

  def _handle_ConnectionUp (self, event):
    if _install_flow:
      fm = of.ofp_flow_mod()
      fm.priority = 0x7000 # Pretty high
      fm.match.dl_type = ethernet.ARP_TYPE
      fm.actions.append(of.ofp_action_output(port=of.OFPP_CONTROLLER))
      event.connection.send(fm)

  def _handle_PacketIn (self, event):
    # Note: arp.hwsrc is not necessarily equal to ethernet.src
    # (one such example are arp replies generated by this module itself
    # as ethernet mac is set to switch dpid) so we should be careful
    # to use only arp addresses in the learning code!
    squelch = False

    dpid = event.connection.dpid
    inport = event.port
    packet = event.parsed
    if not packet.parsed:
      log.warning("%s: ignoring unparsed packet", dpid_to_str(dpid))
      return

    a = packet.find('arp')
    if not a: return

    log.debug("%s ARP %s %s => %s", dpid_to_str(dpid),
      {arp.REQUEST:"request",arp.REPLY:"reply"}.get(a.opcode,
      'op:%i' % (a.opcode,)), str(a.protosrc), str(a.protodst))

    if a.prototype == arp.PROTO_TYPE_IP:
      if a.hwtype == arp.HW_TYPE_ETHERNET:
        if a.protosrc != 0:

          if _learn:
            # Learn or update port/MAC info
            if a.protosrc in _arp_table:
              if _arp_table[a.protosrc] != a.hwsrc:
                log.warn("%s RE-learned %s: %s->%s", dpid_to_str(dpid),
                    a.protosrc, _arp_table[a.protosrc].mac, a.hwsrc)
            else:
              log.info("%s learned %s", dpid_to_str(dpid), a.protosrc)
            _arp_table[a.protosrc] = Entry(a.hwsrc)

          if a.opcode == arp.REQUEST:
            # Maybe we can answer

            if a.protodst in _arp_table:
              # We have an answer...

              r = arp()
              r.hwtype = a.hwtype
              r.prototype = a.prototype
              r.hwlen = a.hwlen
              r.protolen = a.protolen
              r.opcode = arp.REPLY
              r.hwdst = a.hwsrc
              r.protodst = a.protosrc
              r.protosrc = a.protodst
              mac = _arp_table[a.protodst].mac
              if mac is True:
                # Special case -- use ourself
                mac = _dpid_to_mac(dpid)
              r.hwsrc = mac
              e = ethernet(type=packet.type, src=_dpid_to_mac(dpid),
                            dst=a.hwsrc)
              e.payload = r
              if packet.type == ethernet.VLAN_TYPE:
                v_rcv = packet.find('vlan')
                e.payload = vlan(eth_type = e.type,
                                 payload = e.payload,
                                 id = v_rcv.id,
                                 pcp = v_rcv.pcp)
                e.type = ethernet.VLAN_TYPE
              log.info("%s answering ARP for %s" % (dpid_to_str(dpid),
                str(r.protosrc)))
              msg = of.ofp_packet_out()
              msg.data = e.pack()
              msg.actions.append(of.ofp_action_output(port =
                                                      of.OFPP_IN_PORT))
              msg.in_port = inport
              event.connection.send(msg)
              return EventHalt if _eat_packets else None
            else:
              # Keep track of failed queries
              squelch = a.protodst in _failed_queries
              _failed_queries[a.protodst] = time.time()

    if self._check_for_flood(dpid, a):
      # Didn't know how to handle this ARP, so just flood it
      msg = "%s flooding ARP %s %s => %s" % (dpid_to_str(dpid),
          {arp.REQUEST:"request",arp.REPLY:"reply"}.get(a.opcode,
          'op:%i' % (a.opcode,)), a.protosrc, a.protodst)

      if squelch:
        log.debug(msg)
      else:
        log.info(msg)

      msg = of.ofp_packet_out()
      msg.actions.append(of.ofp_action_output(port = of.OFPP_FLOOD))
      msg.data = event.ofp
      event.connection.send(msg.pack())

    return EventHalt if _eat_packets else None

  def _check_for_flood (self, dpid, a):
    """
    Return True if you want to flood this
    """
    if a.protodst in _arp_table:
      return _arp_table[a.protodst].flood
    return True


_arp_table = ARPTable() # IPAddr -> Entry
_install_flow = None
_eat_packets = None
_failed_queries = {} # IP -> time : queries we couldn't answer
_learn = None

def launch (timeout=ARP_TIMEOUT, no_flow=False, eat_packets=True,
            no_learn=False, **kw):
  global ARP_TIMEOUT, _install_flow, _eat_packets, _learn
  ARP_TIMEOUT = timeout
  _install_flow = not no_flow
  _eat_packets = str_to_bool(eat_packets)
  _learn = not no_learn

  core.Interactive.variables['arp'] = _arp_table
  for k,v in kw.iteritems():
    _arp_table[IPAddr(k)] = Entry(v, static=True)
  core.registerNew(ARPResponder)

########NEW FILE########
__FILENAME__ = dhcpd
# Copyright 2013 James McCauley
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at:
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""
A very quick and dirty DHCP server

This is currently missing lots of features and sort of limited with
respect to subnets and so on, but it's a start.
"""

from pox.core import core
import pox.openflow.libopenflow_01 as of
import pox.lib.packet as pkt

from pox.lib.addresses import IPAddr,EthAddr,parse_cidr
from pox.lib.addresses import IP_BROADCAST, IP_ANY
from pox.lib.revent import *
from pox.lib.util import dpid_to_str

log = core.getLogger()


def ip_for_event (event):
  """
  Use a switch's DPID as an EthAddr
  """
  eth = dpid_to_str(event.dpid,True).split("|")[0].replace("-",":")
  return EthAddr(eth)


class DHCPLease (Event):
  """
  Raised when a lease is given

  Call nak() to abort this lease
  """
  def __init__ (self, host_mac, ip):
    super(DHCPLease, self).__init__()
    self.host_mac = host_mac
    self.ip = ip
    self._nak = False

  def nak (self):
    self._nak = True


class AddressPool (object):
  """
  Superclass for DHCP address pools

  Note that it's just a subset of a list (thus, you can always just use
  a list as a pool).  The one exception is an optional "subnet_mask" hint.

  It probably makes sense to change this abstraction so that we can more
  easily return addresses from multiple ranges, and because some things
  (e.g., getitem) are potentially difficult to implement and not particularly
  useful (since we only need to remove a single item at a time).
  """
  def __init__ (self):
    """
    Initialize this pool.
    """
    pass

  def __contains__ (self, item):
    """
    Is this IPAddr in the pool?
    """
    return False

  def append (self, item):
    """
    Add this IP address back into the pool
    """
    pass

  def remove (self, item):
    """
    Remove this IPAddr from the pool
    """
    pass

  def __len__ (self):
    """
    Returns number of IP addresses in the pool
    """
    return 0

  def __getitem__ (self, index):
    """
    Get an IPAddr from the pool.

    Note that this will only be called with index = 0!
    """
    pass


class SimpleAddressPool (AddressPool):
  """
  Simple AddressPool for simple subnet based pools.
  """
  def __init__ (self, network = "192.168.0.0/24", first = 1, last = None,
                count = None):
    """
    Simple subnet-based address pool

    Allocates count IP addresses out of network/network_size, starting
    with the first'th.  You may specify the end of the range with either
    last (to specify the last'th address to use) or count to specify the
    number to use.  If both are None, use up to the end of all
    legal addresses.

    Example for all of 192.168.x.x/16:
      SimpleAddressPool("192.168.0.0/16", 1, 65534)
    """
    network,network_size = parse_cidr(network)

    self.first = first
    self.network_size = network_size
    self.host_size = 32-network_size
    self.network = IPAddr(network)

    if last is None and count is None:
      self.last = (1 << self.host_size) - 2
    elif last is not None:
      self.last = last
    elif count is not None:
      self.last = self.first + count - 1
    else:
      raise RuntimeError("Cannot specify both last and count")

    self.removed = set()

    if self.count <= 0: raise RuntimeError("Bad first/last range")
    if first == 0: raise RuntimeError("Can't allocate 0th address")
    if self.host_size < 0 or self.host_size > 32:
      raise RuntimeError("Bad network")
    if IPAddr(self.last | self.network.toUnsigned()) not in self:
      raise RuntimeError("Bad first/last range")

  def __repr__ (self):
    return str(self)

  def __str__ (self):
    t = self.network.toUnsigned()
    t = (IPAddr(t|self.first),IPAddr(t|self.last))
    return "<Addresses from %s to %s>" % t

  @property
  def subnet_mask (self):
    return IPAddr(((1<<self.network_size)-1) << self.host_size)

  @property
  def count (self):
    return self.last - self.first + 1

  def __contains__ (self, item):
    item = IPAddr(item)
    if item in self.removed: return False
    n = item.toUnsigned()
    mask = (1<<self.host_size)-1
    nm = (n & mask) | self.network.toUnsigned()
    if nm != n: return False
    if (n & mask) == mask: return False
    if (n & mask) < self.first: return False
    if (n & mask) > self.last: return False
    return True

  def append (self, item):
    item = IPAddr(item)
    if item not in self.removed:
      if item in self:
        raise RuntimeError("%s is already in this pool" % (item,))
      else:
        raise RuntimeError("%s does not belong in this pool" % (item,))
    self.removed.remove(item)

  def remove (self, item):
    item = IPAddr(item)
    if item not in self:
      raise RuntimeError("%s not in this pool" % (item,))
    self.removed.add(item)

  def __len__ (self):
    return (self.last-self.first+1) - len(self.removed)

  def __getitem__ (self, index):
    if index < 0:
      raise RuntimeError("Negative indices not allowed")
    if index >= len(self):
      raise IndexError("Item does not exist")
    c = self.first

    # Use a heuristic to find the first element faster (we hope)
    # Note this means that removing items changes the order of
    # our "list".
    c += len(self.removed)
    while c > self.last:
      c -= self.count

    while True:
      addr = IPAddr(c | self.network.toUnsigned())
      if addr not in self.removed:
        assert addr in self
        index -= 1
        if index < 0: return addr
      c += 1
      if c > self.last: c -= self.count


class DHCPD (EventMixin):
  _eventMixin_events = set([DHCPLease])

  def __init__ (self, ip_address = "192.168.0.254", router_address = (),
                dns_address = (), pool = None, subnet = None,
                install_flow = True):

    def fix_addr (addr, backup):
      if addr is None: return None
      if addr is (): return IPAddr(backup)
      return IPAddr(addr)

    self._install_flow = install_flow

    self.ip_addr = IPAddr(ip_address)
    self.router_addr = fix_addr(router_address, ip_address)
    self.dns_addr = fix_addr(dns_address, self.router_addr)

    if pool is None:
      self.pool = [IPAddr("192.168.0."+str(x)) for x in range(100,199)]
      self.subnet = IPAddr(subnet or "255.255.255.0")
    else:
      self.pool = pool
      self.subnet = subnet
      if hasattr(pool, 'subnet_mask'):
        self.subnet = pool.subnet_mask
      if self.subnet is None:
        raise RuntimeError("You must specify a subnet mask or use a "
                           "pool with a subnet hint")

    self.lease_time = 60 * 60 # An hour
    #TODO: Actually make them expire :)

    self.offers = {} # Eth -> IP we offered
    self.leases = {} # Eth -> IP we leased

    if self.ip_addr in self.pool:
      log.debug("Removing my own IP (%s) from address pool", self.ip_addr)
      self.pool.remove(self.ip_addr)

    core.openflow.addListeners(self)

  def _handle_ConnectionUp (self, event):
    if self._install_flow:
      msg = of.ofp_flow_mod()
      msg.match = of.ofp_match()
      msg.match.dl_type = pkt.ethernet.IP_TYPE
      msg.match.nw_proto = pkt.ipv4.UDP_PROTOCOL
      #msg.match.nw_dst = IP_BROADCAST
      msg.match.tp_src = pkt.dhcp.CLIENT_PORT
      msg.match.tp_dst = pkt.dhcp.SERVER_PORT
      msg.actions.append(of.ofp_action_output(port = of.OFPP_CONTROLLER))
      #msg.actions.append(of.ofp_action_output(port = of.OFPP_FLOOD))
      event.connection.send(msg)

  def _get_pool (self, event):
    """
    Get an IP pool for this event.

    Return None to not issue an IP.  You should probably log this.
    """
    return self.pool

  def _handle_PacketIn (self, event):
    # Is it to us?  (Or at least not specifically NOT to us...)
    ipp = event.parsed.find('ipv4')
    if not ipp or not ipp.parsed:
      return
    if ipp.dstip not in (IP_ANY,IP_BROADCAST,self.ip_addr):
      return
    nwp = ipp.payload
    if not nwp or not nwp.parsed or not isinstance(nwp, pkt.udp):
      return
    if nwp.srcport != pkt.dhcp.CLIENT_PORT:
      return
    if nwp.dstport != pkt.dhcp.SERVER_PORT:
      return
    p = nwp.payload
    if not p:
      log.debug("%s: no packet", str(event.connection))
      return
    if not isinstance(p, pkt.dhcp):
      log.debug("%s: packet is not DHCP", str(event.connection))
      return
    if not p.parsed:
      log.debug("%s: DHCP packet not parsed", str(event.connection))
      return

    if p.op != p.BOOTREQUEST:
      return

    t = p.options.get(p.MSG_TYPE_OPT)
    if t is None:
      return

    pool = self._get_pool(event)
    if pool is None:
      return

    if t.type == p.DISCOVER_MSG:
      self.exec_discover(event, p, pool)
    elif t.type == p.REQUEST_MSG:
      self.exec_request(event, p, pool)
    elif t.type == p.RELEASE_MSG:
      self.exec_release(event, p, pool)

  def reply (self, event, msg):
    orig = event.parsed.find('dhcp')
    broadcast = (orig.flags & orig.BROADCAST_FLAG) != 0
    msg.op = msg.BOOTREPLY
    msg.chaddr = event.parsed.src
    msg.htype = 1
    msg.hlen = 6
    msg.xid = orig.xid
    msg.add_option(pkt.DHCP.DHCPServerIdentifierOption(self.ip_addr))

    ethp = pkt.ethernet(src=ip_for_event(event),dst=event.parsed.src)
    ethp.type = pkt.ethernet.IP_TYPE
    ipp = pkt.ipv4(srcip = self.ip_addr)
    ipp.dstip = event.parsed.find('ipv4').srcip
    if broadcast:
      ipp.dstip = IP_BROADCAST
      ethp.dst = pkt.ETHERNET.ETHER_BROADCAST
    ipp.protocol = ipp.UDP_PROTOCOL
    udpp = pkt.udp()
    udpp.srcport = pkt.dhcp.SERVER_PORT
    udpp.dstport = pkt.dhcp.CLIENT_PORT
    udpp.payload = msg
    ipp.payload = udpp
    ethp.payload = ipp
    po = of.ofp_packet_out(data=ethp.pack())
    po.actions.append(of.ofp_action_output(port=event.port))
    event.connection.send(po)

  def nak (self, event, msg = None):
    if msg is None:
      msg = pkt.dhcp()
    msg.add_option(pkt.DHCP.DHCPMsgTypeOption(msg.NAK_MSG))
    msg.siaddr = self.ip_addr
    self.reply(event, msg)

  def exec_release (self, event, p, pool):
    src = event.parsed.src
    if src != p.chaddr:
      log.warn("%s tried to release %s with bad chaddr" % (src,p.ciaddr))
      return
    if self.leases.get(p.chaddr) != p.ciaddr:
      log.warn("%s tried to release unleased %s" % (src,p.ciaddr))
      return
    del self.leases[p.chaddr]
    pool.append(p.ciaddr)
    log.info("%s released %s" % (src,p.ciaddr))

  def exec_request (self, event, p, pool):
    if not p.REQUEST_IP_OPT in p.options:
      # Uhhh...
      return
    wanted_ip = p.options[p.REQUEST_IP_OPT].addr
    src = event.parsed.src
    got_ip = None
    if src in self.leases:
      if wanted_ip != self.leases[src]:
        pool.append(self.leases[src])
        del self.leases[src]
      else:
        got_ip = self.leases[src]
    if got_ip is None:
      if src in self.offers:
        if wanted_ip != self.offers[src]:
          pool.append(self.offers[src])
          del self.offers[src]
        else:
          got_ip = self.offers[src]
    if got_ip is None:
      if wanted_ip in pool:
        pool.remove(wanted_ip)
        got_ip = wanted_ip
    if got_ip is None:
      log.warn("%s asked for un-offered %s", src, wanted_ip)
      self.nak(event)
      return

    assert got_ip == wanted_ip
    self.leases[src] = got_ip
    ev = DHCPLease(src, got_ip)
    self.raiseEvent(ev)
    if ev._nak:
      self.nak(event)
      return
    log.info("Leased %s to %s" % (got_ip, src))

    reply = pkt.dhcp()
    reply.add_option(pkt.DHCP.DHCPMsgTypeOption(p.ACK_MSG))
    reply.yiaddr = wanted_ip
    reply.siaddr = self.ip_addr

    wanted_opts = set()
    if p.PARAM_REQ_OPT in p.options:
      wanted_opts.update(p.options[p.PARAM_REQ_OPT].options)
    self.fill(wanted_opts, reply)

    self.reply(event, reply)

  def exec_discover (self, event, p, pool):
    reply = pkt.dhcp()
    reply.add_option(pkt.DHCP.DHCPMsgTypeOption(p.OFFER_MSG))
    src = event.parsed.src
    if src in self.leases:
      offer = self.leases[src]
      del self.leases[src]
      self.offers[src] = offer
    else:
      offer = self.offers.get(src)
      if offer is None:
        if len(pool) == 0:
          log.error("Out of IP addresses")
          self.nak(event)
          return

        offer = pool[0]
        if p.REQUEST_IP_OPT in p.options:
          wanted_ip = p.options[p.REQUEST_IP_OPT].addr
          if wanted_ip in pool:
            offer = wanted_ip
        pool.remove(offer)
        self.offers[src] = offer
    reply.yiaddr = offer
    reply.siaddr = self.ip_addr

    wanted_opts = set()
    if p.PARAM_REQ_OPT in p.options:
      wanted_opts.update(p.options[p.PARAM_REQ_OPT].options)
    self.fill(wanted_opts, reply)

    self.reply(event, reply)

  def fill (self, wanted_opts, msg):
    """
    Fill out some options in msg
    """
    if msg.SUBNET_MASK_OPT in wanted_opts:
      msg.add_option(pkt.DHCP.DHCPSubnetMaskOption(self.subnet))
    if msg.ROUTERS_OPT in wanted_opts and self.router_addr is not None:
      msg.add_option(pkt.DHCP.DHCPRoutersOption(self.router_addr))
    if msg.DNS_SERVER_OPT in wanted_opts and self.dns_addr is not None:
      msg.add_option(pkt.DHCP.DHCPDNSServersOption(self.dns_addr))
    msg.add_option(pkt.DHCP.DHCPIPAddressLeaseTimeOption(self.lease_time))


def default (no_flow = False,
            network = "192.168.0.0/24",            # Address range
            first = 100, last = 199, count = None, # Address range
            ip = "192.168.0.254",
            router = (),                   # Auto
            dns = ()):                     # Auto
  """
  Launch DHCP server defaulting to 192.168.0.100-199
  """
  launch(no_flow, network, first, last, count, ip, router, dns)


def launch (no_flow = False,
            network = "192.168.0.0/24",            # Address range
            first = 1, last = None, count = None, # Address range
            ip = "192.168.0.254",
            router = (),                   # Auto
            dns = ()):                     # Auto
  """
  Launch DHCP server

  Defaults to serving 192.168.0.1 to 192.168.0.253

  network  Subnet to allocate addresses from
  first    First'th address in subnet to use (256 is x.x.1.0 in a /16)
  last     Last'th address in subnet to use
  count    Alternate way to specify last address to use
  ip       IP to use for DHCP server
  router   Router IP to tell clients. Defaults to 'ip'. 'None' will
           stop the server from telling clients anything
  dns      DNS IP to tell clients.  Defaults to 'router'.  'None' will
           stop the server from telling clients anything.
  """
  def fixint (i):
    i = str(i)
    if i.lower() == "none": return None
    if i.lower() == "true": return None
    return int(i)
  def fix (i):
    i = str(i)
    if i.lower() == "none": return None
    if i.lower() == "true": return None
    if i == '()': return ()
    return i
  first,last,count = map(fixint,(first,last,count))
  router,dns = map(fix,(router,dns))

  pool = SimpleAddressPool(network = network, first = first, last = last,
                           count = count)

  core.registerNew(DHCPD, install_flow = not no_flow, pool = pool,
                   ip_address = ip, router_address = router,
                   dns_address = dns)

  log.debug("DHCP serving a%s", str(pool)[2:-1])

########NEW FILE########
__FILENAME__ = dhcp_client
# Copyright 2013 James McCauley
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at:
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""
DHCP Client stuff
"""

from pox.core import core
log = core.getLogger()

import pox.lib.packet as pkt

from pox.lib.addresses import IPAddr, EthAddr
from pox.lib.util import dpid_to_str, str_to_dpid
from pox.lib.revent import EventMixin, Event
import pox.lib.recoco as recoco

import pox.openflow.libopenflow_01 as of

import time
import random


class DHCPOffer (Event):
  """
  Fired when an offer has been received

  If you want to immediately accept it, do accept().
  If you want to reject it, do reject().
  If you want to defer acceptance, do nothing.
  """
  def __init__ (self, p):
    super(DHCPOffer,self).__init__()

    self.offer = p

    self.address = p.yiaddr
    self.server = p.siaddr
    o = p.options.get(p.SERVER_ID_OPT)
    if o: self.server = o.addr

    o = p.options.get(p.SUBNET_MASK_OPT)
    self.subnet_mask = o.addr if o else None
    o = p.options.get(p.ROUTERS_OPT)
    self.routers = o.addrs if o else []
    o = p.options.get(p.DNS_SERVER_OPT)
    self.dns_servers = o.addrs if o else []
    o = p.options.get(p.REQUEST_LEASE_OPT)
    o = o.seconds if o is not None else 86400 # Hmmm...

    self._accept = None

  def reject (self):
    self._accept = False

  def accept (self):
    self._accept = True


class DHCPOffers (Event):
  """
  Fired when all offers in time window have been received
  """
  def __init__ (self, offers):
    super(DHCPOffers,self).__init__()
    self.offers = offers
    self.accepted = None

  def accept (self, offer):
    assert offer in self.offers
    self.accepted = offer


class DHCPLeased (Event):
  """
  Fired when a lease has been confirmed
  """
  def __init__ (self, lease):
    super(DHCPLeased,self).__init__()
    # Lease is the appropriate offer.
    self.lease = lease


class DHCPClientError (Event):
  pass


class DHCPClient (EventMixin):
  """
  A DHCP client

  Currently doesn't do lots of stuff "right" according the RFC2131 Section 4.4,
  and the state/timeout management is pretty bad.  It does mostly serve to get
  you an address under simple circumstances, though.
  Feel free to add improvements!
  """
  """
  TODO:
  * Bind port_name -> port_no later?
  * Renew
  * Keep track of lease times
  """

  _eventMixin_events = set([DHCPOffer, DHCPOffers, DHCPLeased,
                            DHCPClientError])

  _xid = random.randint(1000,0xffFFffFF)

  TOTAL_TIMEOUT = 8
  OFFER_TIMEOUT = 2
  REQUEST_TIMEOUT = 2
  DISCOVER_TIMEOUT = 2

  # Client states
  INIT = 'INIT'
  INIT_REBOOT = 'INIT_REBOOT'
  SELECTING = 'SELECTING'
  REBOOTING = 'REBOOTING'
  REQUESTING = 'REQUESTING'
  REBINDING = 'REBINDING'
  BOUND = 'BOUND'
  RENEWING = 'RENEWING'

  # Not real DHCP states
  NEW = '<NEW>'
  ERROR = '<ERROR>'
  IDLE = '<IDLE>'


  def __init__ (self, dpid, port,
                port_eth = None,
                auto_accept = False,
                install_flows = True,
                offer_timeout = None,
                request_timeout = None,
                total_timeout = None,
                discovery_timeout = None,
                name = None):
    """
    Initializes

    port_eth can be True to use the MAC associated with the port by the
      switch, None to use the 'dpid MAC', or an EthAddr.
    """

    # Accept first offer?
    # If True the first non-rejected offer is used immediately, without
    # waiting for the offer_timeout window to close.
    self.auto_accept = auto_accept

    self.install_flows = install_flows

    if name is None:
      self.log = log
    else:
      self.log = core.getLogger(name)

    if hasattr(dpid, 'dpid'):
      dpid = dpid.dpid
    self.dpid = dpid

    self.port_name = port
    self.port_eth = port_eth

    self._state = self.NEW
    self._start = None

    # We keep track of all offers we received
    self.offers = []

    # XID that messages should have to us should have
    self.offer_xid = None
    self.ack_xid = None

    # Accepted offer
    self.accepted = None

    # Requested offer
    self.requested = None

    # Bound offer
    self.bound = None

    # How long to wait total
    self.total_timeout = total_timeout or self.TOTAL_TIMEOUT
    self.total_timer = None

    # How long to wait for the first offer following a discover
    # If we don't hear one, we'll resend the discovery
    self.discover_timeout = discovery_timeout or self.DISCOVER_TIMEOUT
    self.discover_timer = None

    # How long to wait for offers after the first one
    self.offer_timeout = offer_timeout or self.OFFER_TIMEOUT
    self.offer_timer = None

    # How long to wait for ACK/NAK on requested offer
    self.request_timeout = request_timeout or self.REQUEST_TIMEOUT
    self.request_timer = None

    # We add and remove the PacketIn listener.  This is its event ID
    self._packet_listener = None

    self._try_start()
    if self.state != self.INIT:
      self._listen_for_connection()

  def _handle_ConnectionUp (self, event):
    self._try_start()

  def _listen_for_connection (self):
    core.openflow.addListenerByName('ConnectionUp', self._handle_ConnectionUp,
                                    once = True)

  def _try_start (self):
    if self.state != self.NEW:
      return
    
    dpid = self.dpid
    port = self.port_name

    con = core.openflow.connections.get(dpid, None)

    if con is None:
      #raise RuntimeError('DPID %s not connected' % (dpid_to_str(dpid),))
      self._listen_for_connection()
      return

    if isinstance(port, str):
      if port not in con.ports:
        self.log.error('No such port as %s.%s' % (dpid_to_str(dpid), port))
        #raise RuntimeError('No such port as %s.%s' % (dpid_to_str(dpid),port))
        self.state = self.ERROR
        return
      self.portno = con.ports[port].port_no

    if self.port_eth is None:
      self.port_eth = con.eth_addr
    elif self.port_eth is True:
      self.port_eth = con.ports[port].hw_addr

    self.state = self.INIT

  def _total_timeout (self):
    # If this goes off and we haven't finished, tell the user we failed
    self.log.warn('Did not complete successfully')
    self.state = self.ERROR

  @property
  def _secs (self):
    return time.time() - self._start

  @property
  def state (self):
    return self._state

  @state.setter
  def state (self, state):
    old = self._state

    self.log.debug("Transition: %s -> %s", old, state)

    def killtimer (name):
      name += '_timer'
      a = getattr(self, name)
      if a is not None:
        a.cancel()
      setattr(self, name, None)

    def set_state (s, debug = None, warn = None, info = None):
      def state_setter ():
        if debug: self.log.debug(debug)
        if warn: self.log.debug(warn)
        if info: self.log.debug(info)
        self.state = s
      return state_setter


    if old == self.INIT:
      killtimer('discover')
    elif old == self.SELECTING:
      killtimer('offer')
    elif old == self.REQUESTING:
      killtimer('request')
      self.requested = None


    # Make sure we're seeing packets if needed...

    def get_flow (broadcast = False):
      fm = of.ofp_flow_mod()
      if broadcast:
        fm.match.dl_dst = pkt.ETHER_BROADCAST
      else:
        fm.match.dl_dst = self.port_eth
      fm.match.in_port = self.portno
      fm.match.dl_type = pkt.ethernet.IP_TYPE
      fm.match.nw_proto = pkt.ipv4.UDP_PROTOCOL
      fm.match.tp_src = pkt.dhcp.SERVER_PORT
      fm.match.tp_dst = pkt.dhcp.CLIENT_PORT
      fm.priority += 1
      return fm

    if state not in (self.IDLE, self.ERROR, self.BOUND):
      if self._packet_listener is None:
        self._packet_listener = core.openflow.addListenerByName('PacketIn',
            self._handle_PacketIn)
        if self.install_flows:
          fm = get_flow(False)
          fm.actions.append(of.ofp_action_output(port = of.OFPP_CONTROLLER))
          self._con.send(fm)
          fm = get_flow(True)
          fm.actions.append(of.ofp_action_output(port = of.OFPP_CONTROLLER))
          self._con.send(fm)
    else:
      if self._packet_listener is not None:
        core.openflow.removeListener(self._packet_listener)
        self._packet_listener = None
        if self.install_flows:
          fm = get_flow(False)
          fm.command = of.OFPFC_DELETE_STRICT
          self._con.send(fm)
          fm = get_flow(True)
          fm.command = of.OFPFC_DELETE_STRICT
          self._con.send(fm)

    self._state = state

    if state == self.INIT:
      assert old in (self.NEW,self.INIT)
      # We transition INIT->INIT when discovery times out
      if old == self.NEW:
        # In this case, we want to set a total timeout
        killtimer('total')
        self.total_timer = recoco.Timer(self.total_timeout,
                                        self._do_total_timeout)
        self._start = time.time()
      self._discover()
      self.discover_timer = recoco.Timer(self.discover_timeout,
                                         set_state(self.INIT))
    elif state == self.SELECTING:
      assert old == self.INIT
      self.offer_timer = recoco.Timer(self.offer_timeout,
                                      self._do_accept)
    elif state == self.REQUESTING:
      assert old == self.SELECTING
      assert self.requested
      self._request()
      self.request_timer = recoco.Timer(self.request_timeout,
                                        set_state(self.INIT,info='Timeout'))
    elif state == self.BOUND:
      killtimer('total')
      ev = DHCPLeased(self.bound)
      self.log.info("Got %s/%s -> %s",
                    self.bound.address,
                    self.bound.subnet_mask,
                    ','.join(str(g) for g in self.bound.routers))

      self.raiseEventNoErrors(ev)
      #TODO: Handle expiring leases

    elif state == self.ERROR:
      #TODO: Error info
      self.raiseEventNoErrors(DHCPClientError())

  def _do_total_timeout (self):
    self.log.error('Did not successfully bind in time')
    self.state = self.ERROR

  def _add_param_requests (self, msg):
    req = pkt.DHCP.DHCPParameterRequestOption([
      pkt.DHCP.DHCPDNSServersOption,
      pkt.DHCP.DHCPRoutersOption,
      pkt.DHCP.DHCPSubnetMaskOption,
      ])
    msg.add_option(req)

  def _discover (self):
    self.offers = []

    msg = pkt.dhcp()
    self._add_param_requests(msg)

    self.offer_xid = self._send(msg, msg.DISCOVER_MSG)

  def _request (self):
    msg = pkt.dhcp()
    msg.siaddr = self.requested.server
    #self._add_param_requests(msg)
    msg.add_option(pkt.DHCP.DHCPServerIdentifierOption(msg.siaddr))
    msg.add_option(pkt.DHCP.DHCPRequestIPOption(self.requested.address))
    self.request_xid = self._send(msg, msg.REQUEST_MSG)

  @classmethod
  def _new_xid (cls):
    if cls._xid == 0xffffFFFF:
      cls._xid = 0
    else:
      cls._xid += 1

    return cls._xid

  def _send (self, msg, msg_type):
    msg.flags |= msg.BROADCAST_FLAG
    msg.htype = 1
    msg.hlen = 6
    msg.op = msg.BOOTREQUEST
    msg.secs = self._secs
    msg.xid = self._new_xid()
    msg.chaddr = self.port_eth

    #if msg.siaddr != pkt.ipv4.IP_ANY:
    #  msg.add_option(pkt.DHCP.DHCPServerIdentifierOption(self.msg.siaddr))
    msg.add_option(pkt.DHCP.DHCPMsgTypeOption(msg_type))

    self._send_dhcp(msg)

    return msg.xid

  def _send_dhcp (self, msg):
    ethp = pkt.ethernet(src=self.port_eth, dst=pkt.ETHER_BROADCAST)
    ethp.type = pkt.ethernet.IP_TYPE
    ipp = pkt.ipv4()
    ipp.srcip = pkt.IP_ANY #NOTE: If rebinding, use existing local IP?
    ipp.dstip = pkt.IP_BROADCAST
    ipp.protocol = ipp.UDP_PROTOCOL
    udpp = pkt.udp()
    udpp.srcport = pkt.dhcp.CLIENT_PORT
    udpp.dstport = pkt.dhcp.SERVER_PORT
    udpp.payload = msg
    ipp.payload = udpp
    ethp.payload = ipp
    po = of.ofp_packet_out(data=ethp.pack())
    po.actions.append(of.ofp_action_output(port=self.portno))
    self._con.send(po)

  @property
  def _con (self):
    return core.openflow.connections[self.dpid]

  def _handle_PacketIn (self, event):
    if event.dpid != self.dpid: return
    if event.port != self.portno: return

    # Is it to us?  (Or at least not specifically NOT to us...)
    ipp = event.parsed.find('ipv4')
    if not ipp or not ipp.parsed:
      return
    if self.bound and self.bound.address == ipp.dstip:
      pass # Okay.
    elif ipp.dstip not in (pkt.IP_ANY,pkt.IP_BROADCAST):
      return
    p = event.parsed.find('dhcp')
    if p is None:
      return
    if not isinstance(p.prev, pkt.udp):
      return
    udpp = p.prev
    if udpp.dstport != pkt.dhcp.CLIENT_PORT:
      return
    if udpp.srcport != pkt.dhcp.SERVER_PORT:
      return
    if p.op != p.BOOTREPLY:
      return
    t = p.options.get(p.MSG_TYPE_OPT)
    if t is None:
      return

    if t.type == p.OFFER_MSG:
      if p.xid != self.offer_xid:
        if self.state in (self.INIT,self.SELECTING):
          self.log.info('Received offer with wrong XID')
        else:
          self.log.debug('Received unexpected offer with wrong XID')
        return
      if self.state == self.INIT:
        # First offer switches states
        self.state = self.SELECTING
      if self.state != self.SELECTING:
        self.log.warn('Recieved an offer while in state %s', self.state)
        return
      self._exec_offer(event, p)
    elif t.type in (p.ACK_MSG, p.NAK_MSG):
      if p.xid != self.request_xid:
        if self.state in (self.REQUESTING):
          self.log.info('Received ACK/NAK with wrong XID')
        else:
          self.og.debug('Received unexpected ACK/NAK with wrong XID')
        return
      if self.state != self.REQUESTING:
        self.log.warn('Recieved an ACK/NAK while in state %s', self.state)
        return
      if t.type == p.NAK_MSG:
        self._exec_request_nak(event, p)
      else:
        self._exec_request_ack(event, p)

  def _exec_offer (self, event, p):
    o = DHCPOffer(p)
    self.offers.append(o)
    self.raiseEventNoErrors(o)

    if self.auto_accept and (o._accept is not False):
      # Good enough!
      o._accept = True
      self._do_accept()

  def _exec_request_ack (self, event, p):
    self.bound = self.requested
    self.state = self.BOUND

  def _exec_request_nak (self, event, p):
    self.log.warn('DHCP server NAKed our attempted acceptance of an offer')

    # Try again...
    self.state = INIT

  def _do_accept (self):
    ev = DHCPOffers(self.offers)
    for o in self.offers:
      if o._accept is True:
        ev.accepted = o
        break
    if ev.accepted is None:
      for o in self.offers:
        if o._accept is not False:
          ev.accepted = o
          break

    self.raiseEventNoErrors(ev)

    #TODO: Properly decline offers

    if ev.accepted is None:
      self.log.info('No offer accepted')
      self.state = self.IDLE
      return

    self.requested = ev.accepted

    self.state = self.REQUESTING


def launch (dpid, port, port_eth = None, name = None, __INSTANCE__ = None):
  """
  Launch

  port_eth unspecified: "DPID MAC"
  port_eth enabled: Port MAC
  port_eth specified: Use that
  """
  if port_eth in (True, None):
    pass
  else:
    port_eth = EthAddr(port_eth)

  dpid = str_to_dpid(dpid)
  try:
    port = int(port)
  except:
    pass

  def dhcpclient_init ():
    n = name
    if n is None:
      s = ''
      while True:
        if not core.hasComponent("DHCPClient" + s):
          n = "DHCPClient" + s
          break
        s = str(int('0' + s) + 1)
    else:
      if core.hasComponent(n):
        self.log.error("Already have component %s", n)
        return

    client = DHCPClient(port=port, dpid=dpid, name=n, port_eth=port_eth)
    core.register(n, client)

  core.call_when_ready(dhcpclient_init, ['openflow'])

########NEW FILE########
__FILENAME__ = dns_spy
# Copyright 2011-2012 James McCauley
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at:
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""
This component spies on DNS replies, stores the results, and raises events
when things are looked up or when its stored mappings are updated.

Similar to NOX's DNSSpy component, but with more features.
"""

from pox.core import core
import pox.openflow.libopenflow_01 as of
import pox.lib.packet as pkt
import pox.lib.packet.dns as pkt_dns

from pox.lib.addresses import IPAddr
from pox.lib.revent import *

log = core.getLogger()


class DNSUpdate (Event):
  def __init__ (self, item):
    Event.__init__()
    self.item = item

class DNSLookup (Event):
  def __init__ (self, rr):
    Event.__init__()

    self.name = rr.name
    self.qtype = rr.qtype

    self.rr = rr
    for t in pkt_dns.rrtype_to_str.values():
      setattr(self, t, False)
    t = pkt_dns.rrtype_to_str.get(rr.qtype)
    if t is not None:
      setattr(self, t, True)
      setattr(self, "OTHER", False)
    else:
      setattr(self, "OTHER", True)


class DNSSpy (EventMixin):
  _eventMixin_events = set([ DNSUpdate, DNSLookup ])

  def __init__ (self, install_flow = True):
    self._install_flow = install_flow

    self.ip_to_name = {}
    self.name_to_ip = {}
    self.cname = {}

    core.openflow.addListeners(self)

    # Add handy function to console
    core.Interactive.variables['lookup'] = self.lookup

  def _handle_ConnectionUp (self, event):
    if self._install_flow:
      msg = of.ofp_flow_mod()
      msg.match = of.ofp_match()
      msg.match.dl_type = pkt.ethernet.IP_TYPE
      msg.match.nw_proto = pkt.ipv4.UDP_PROTOCOL
      msg.match.tp_src = 53
      msg.actions.append(of.ofp_action_output(port = of.OFPP_CONTROLLER))
      event.connection.send(msg)

  def lookup (self, something):
    if something in self.name_to_ip:
      return self.name_to_ip[something]
    if something in self.cname:
      return self.lookup(self.cname[something])
    try:
      return self.ip_to_name.get(IPAddr(something))
    except:
      return None

  def _record (self, ip, name):
    # Handle reverse lookups correctly?
    modified = False
    val = self.ip_to_name.setdefault(ip, [])
    if name not in val:
      val.insert(0, name)
      modified = True

    val = self.name_to_ip.setdefault(name, [])
    if ip not in val:
      val.insert(0, ip)
      modified = True

    return modified

  def _record_cname (self, name, cname):
    modified = False
    val = self.cname.setdefault(name, [])
    if name not in val:
      val.insert(0, cname)
      modified = True

    return modified

  def _handle_PacketIn (self, event):
    p = event.parsed.find('dns')

    if p is not None and p.parsed:
      log.debug(p)

      for q in p.questions:
        if q.qclass != 1: continue # Internet only
        self.raiseEvent(DNSLookup, q)

      def process_q (entry):
        if entry.qclass != 1:
          # Not internet
          return

        if entry.qtype == pkt.dns.rr.CNAME_TYPE:
          if self._record_cname(entry.name, entry.rddata):
            self.raiseEvent(DNSUpdate, entry.name)
            log.info("add cname entry: %s %s" % (entry.rddata, entry.name))
        elif entry.qtype == pkt.dns.rr.A_TYPE:
          if self._record(entry.rddata, entry.name):
            self.raiseEvent(DNSUpdate, entry.name)
            log.info("add dns entry: %s %s" % (entry.rddata, entry.name))

      for answer in p.answers:
        process_q(answer)
      for addition in p.additional:
        process_q(addition)


def launch (no_flow = False):
  core.registerNew(DNSSpy, not no_flow)

########NEW FILE########
__FILENAME__ = pong
# Copyright 2012 James McCauley
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at:
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""
A simple component that always replies to ARPs and pings.

When running this component, pings (and pretty much nothing else!)
should always work.
"""

from pox.core import core
import pox.openflow.libopenflow_01 as of
import pox.lib.packet as pkt
from pox.lib.addresses import EthAddr

log = core.getLogger()


def _handle_PacketIn (event):
  packet = event.parsed

  if packet.find("arp"):
    # Reply to ARP
    a = packet.find("arp")
    if a.opcode == a.REQUEST:
      r = pkt.arp()
      r.hwtype = a.hwtype
      r.prototype = a.prototype
      r.hwlen = a.hwlen
      r.protolen = a.protolen
      r.opcode = r.REPLY
      r.hwdst = a.hwsrc
      r.protodst = a.protosrc
      r.protosrc = a.protodst
      r.hwsrc = EthAddr("02:00:DE:AD:BE:EF")
      e = pkt.ethernet(type=packet.type, src=r.hwsrc, dst=a.hwsrc)
      e.payload = r

      msg = of.ofp_packet_out()
      msg.data = e.pack()
      msg.actions.append(of.ofp_action_output(port = of.OFPP_IN_PORT))
      msg.in_port = event.port
      event.connection.send(msg)

      log.info("%s ARPed for %s", r.protodst, r.protosrc)

  elif packet.find("icmp"):
    # Reply to pings

    # Make the ping reply
    icmp = pkt.icmp()
    icmp.type = pkt.TYPE_ECHO_REPLY
    icmp.payload = packet.find("icmp").payload

    # Make the IP packet around it
    ipp = pkt.ipv4()
    ipp.protocol = ipp.ICMP_PROTOCOL
    ipp.srcip = packet.find("ipv4").dstip
    ipp.dstip = packet.find("ipv4").srcip

    # Ethernet around that...
    e = pkt.ethernet()
    e.src = packet.dst
    e.dst = packet.src
    e.type = e.IP_TYPE

    # Hook them up...
    ipp.payload = icmp
    e.payload = ipp

    # Send it back to the input port
    msg = of.ofp_packet_out()
    msg.actions.append(of.ofp_action_output(port = of.OFPP_IN_PORT))
    msg.data = e.pack()
    msg.in_port = event.port
    event.connection.send(msg)

    log.debug("%s pinged %s", ipp.dstip, ipp.srcip)


def launch ():
  core.openflow.addListenerByName("PacketIn", _handle_PacketIn)

  log.info("Pong component running.")

########NEW FILE########
__FILENAME__ = py
# Copyright 2012 James McCauley
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at:
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""
Provides a Python interpreter while running POX
"""

from __future__ import print_function

from pox.core import core
from pox.lib.util import str_to_bool
import time

def _monkeypatch_console ():
  """
  The readline in pypy (which is the readline from pyrepl) turns off output
  postprocessing, which disables normal NL->CRLF translation.  An effect of
  this is that output *from other threads* (like log messages) which try to
  print newlines end up just getting linefeeds and the output is all stair-
  stepped.  We monkeypatch the function in pyrepl which disables OPOST to
  turn OPOST back on again.  This doesn't immediately seem to break
  anything in the simple cases, and makes the console reasonable to use
  in pypy.
  """
  try:
    import termios
    import sys
    import pyrepl.unix_console
    uc = pyrepl.unix_console.UnixConsole
    old = uc.prepare
    def prep (self):
      old(self)
      f = sys.stdin.fileno()
      a = termios.tcgetattr(f)
      a[1] |= 1 # Turn on postprocessing (OPOST)
      termios.tcsetattr(f, termios.TCSANOW, a)
    uc.prepare = prep
  except:
    pass


class Interactive (object):
  """
  This is how other applications can interact with the interpreter.

  At the moment, it's really limited.
  """
  def __init__ (self):
    core.register("Interactive", self)
    self.enabled = False
    self.completion = False

    #import pox.license
    import sys
    self.variables = dict(locals())
    self.variables['core'] = core

    class pox_exit (object):
      def __call__ (self, code = 0):
        core.quit()
        sys.exit(code)
      def __repr__ (self):
        return "Use exit() or Ctrl-D (i.e. EOF) to exit POX"
    self.variables['exit'] = pox_exit()

    self.running = False

#    def start (event):
#      if core.Interactive.enabled is not True: return
#      import threading
#      t = threading.Thread(target=self.interact)
#      t.start()
#    core.addListenerByName("UpEvent", start)

  def interact (self):
    """ Begin user interaction """

    if self.completion:
      import readline, rlcompleter
      ns = globals().copy()
      ns.update(self.variables)
      # Note that things added to self.variables later won't be available.
      # To fix this, make a dict proxy that actually reads from self.variables
      # *and* globals().
      readline.set_completer(rlcompleter.Completer(ns).complete)
      readline.parse_and_bind("tab: complete")

    _monkeypatch_console()

    #print("This program comes with ABSOLUTELY NO WARRANTY.  This program " \
    #      "is free software,")
    #print("and you are welcome to redistribute it under certain conditions.")
    #print("Type 'help(pox.license)' for details.")
    time.sleep(1)

    import code
    import sys
    sys.ps1 = "POX> "
    sys.ps2 = " ... "
    self.running = True
    code.interact('Ready.', local=self.variables)
    self.running = False
    core.quit()


def launch (disable = False, completion = None, __INSTANCE__ = None):
  if not core.hasComponent("Interactive"):
    Interactive()

  import boot
  if not disable:
    boot.set_main_function(core.Interactive.interact)
  else:
    boot.set_main_function(None)
  core.Interactive.enabled = not disable
  if completion is not None:
    core.Interactive.completion = str_to_bool(completion)

########NEW FILE########
__FILENAME__ = httopo
# Copyright 2011 James McCauley
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at:
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""
Fires up topology, discovery, and host_tracker
"""

def launch ():
  import pox.topology
  pox.topology.launch()
  import pox.openflow.discovery
  pox.openflow.discovery.launch()
  import pox.openflow.topology
  pox.openflow.topology.launch()
  import pox.host_tracker
  pox.host_tracker.launch()

########NEW FILE########
__FILENAME__ = mixed_switches
# Copyright 2012 James McCauley
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at:
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""
A quick example of treating different datapaths differently.

Although it's not currently particularly well supported, there's
nothing to stop one from using different components with particular
switches.  There are multiple ways to do this, but this component
demonstrates a pretty straightforward one.

When components are loaded from the commandline, their launch()
function is run.  In many cases, this launch() function sets up
a listener for openflow.ConnectionUp events.  When one is raised,
the component handles it by setting up more event listeners on
that connection.

If we want to have some switches behave one way and others
behave another way, we simply don't let them set up their own
ConnectionUp handlers and take care of initializing the rest
of the component ourself.

Here we demonstrate that by making switches with odd-numbered
DPIDs be l2_pairs switches and even-numbered DPIDs be l2_learning
switches.
"""

from pox.core import core
import pox.forwarding.l2_pairs as l2p
import pox.forwarding.l2_learning as l2l

log = core.getLogger()

def _handle_ConnectionUp (event):
  if event.dpid & 1 == 1:
    log.info("Treating %s as l2_pairs", event.connection)
    event.connection.addListenerByName("PacketIn", l2p._handle_PacketIn)
  else:
    log.info("Treating %s as l2_learning", event.connection)
    l2l.LearningSwitch(event.connection, False)

def launch ():
  core.openflow.addListenerByName("ConnectionUp", _handle_ConnectionUp)
  log.info("Mixed switches demo running.")

########NEW FILE########
__FILENAME__ = pretty_log
# Copyright 2012-2013 James McCauley
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at:
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""
This is a very simple component which provides some kind of nice
log formatting.

It demonstrates launching another component (there should eventually
be a nice interface for doing this), and formatting color log messages.

Also, any arguments are passed to log.level, so you can use it as a
shortcut for that too.
"""

def launch (**kw):
  import pox.log.color
  pox.log.color.launch()
  import pox.log
  pox.log.launch(format="[@@@bold@@@level%(name)-23s@@@reset] " +
                        "@@@bold%(message)s@@@normal")
  import pox.log.level
  pox.log.level.launch(**kw)

########NEW FILE########
__FILENAME__ = spanning_tree
# Copyright 2012 James McCauley
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at:
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""
Demonstrates the spanning tree module so that the L2 switch
works decently on topologies with loops.
"""

def launch (forwarding = "l2"):
  import pox.log.color
  pox.log.color.launch()
  import pox.log
  pox.log.launch(format="[@@@bold@@@level%(name)-22s@@@reset] " +
                        "@@@bold%(message)s@@@normal")
  from pox.core import core
  import pox.openflow.discovery
  pox.openflow.discovery.launch()

  core.getLogger("openflow.spanning_tree").setLevel("INFO")
  if forwarding.lower() == "l3":
    import pox.forwarding.l3_learning as fw
  elif forwarding.lower() == "l2_multi":
    import pox.forwarding.l2_multi as fw
  else:
    import pox.forwarding.l2_learning as fw
  core.getLogger().debug("Using forwarding: %s", fw.__name__)
  fw.launch()

  import pox.openflow.spanning_tree
  pox.openflow.spanning_tree.launch()

########NEW FILE########
__FILENAME__ = topo
# Copyright 2011 James McCauley
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at:
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""
Fires up topology, discovery, and a l2 learning switch controller
"""

def launch ():
  import pox.topology
  pox.topology.launch()
  import pox.openflow.discovery
  pox.openflow.discovery.launch()
  import pox.openflow.topology
  pox.openflow.topology.launch()
  import pox.forwarding.l2_learning
  pox.forwarding.l2_learning.launch()

########NEW FILE########
__FILENAME__ = tk
# Copyright 2012 James McCauley
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at:
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""
Lets you use Tk with POX.

Highly experimental.
"""

from collections import deque
from pox.core import core

log = core.getLogger()

#TODO: Bind revent events across thread

class MessageBoxer (object):
  def __init__ (self, tk):
    import tkMessageBox, tkColorChooser, tkSimpleDialog, tkFileDialog
    fields = "ERROR INFO QUESTION WARNING ABORTRETRYIGNORE OKCANCEL "
    fields += "RETRYCANCEL YESNO YESNOCANCEL ABORT RETRY IGNORE OK "
    fields += "CANCEL YES NO"
    for f in fields.split():
      setattr(self, f, getattr(tkMessageBox, f))

    methods = "showinfo showwarning showerror askquestion "
    methods += "askokcancel askyesno askretrycancel"
    self._addmethods(tkMessageBox, methods, tk)

    methods = "askinteger askfloat askstring"
    self._addmethods(tkSimpleDialog, methods, tk)

    methods = "askcolor"
    self._addmethods(tkColorChooser, methods, tk)

    methods = "askopenfilename asksaveasfilename"
    self._addmethods(tkFileDialog, methods, tk)

  def _addmethods (self, module, methods, tk):
    for m in methods.split():
      def f (m):
        def f2 (*args, **kw):
          return getattr(module, m)(*args,**kw)
        def f4 (*args, **kw):
          _ = kw.pop('_', None)
          tk.do_ex(getattr(module, m), rv = _, args=args, kw=kw)
        def f5 (_, *args, **kw):
          tk.do_ex(f2, rv = _, args=args, kw=kw)
        return f4,f5
      a,b = f(m)
      setattr(self, m, a)
      setattr(self, m+"_cb", b)


class Tk (object):
  _core_name = "tk"

  def __init__ (self):
    self._q = deque()
    self.dialog = MessageBoxer(self)
    self.root = None
    self.automatic_quit = True

  def do_ex (self, code, rv=None, args=[], kw={}):
    self._q.append((code, rv, args, kw))
    self._ping()

  def _ping (self):
    if not self.root: return
    self.root.event_generate('<<Ping>>', when='tail')

  def do (__self, __code, __rv=None, *args, **kw):
    __self._q.append((__code, __rv, args, kw))
    __self._ping()

  def _dispatch (self, event):
    while len(self._q):
      self._dispatch_one(*self._q.popleft())

  def _dispatch_one (self, code, rv, args, kw):
    if callable(code):
      r = code(*args, **kw)
    else:
      def f ():
        l = {'self':self}
        l.update(kw)
        exec code in globals(), l
      r = f()
    if rv: core.callLater(rv, r)

  def run (self):
    import Tkinter
    root = Tkinter.Tk()
    root.bind('<<Ping>>', self._dispatch)

    self.root = root

    # Become live once in a while so that signals get handled
    def timer ():
      if self.automatic_quit and core.running == False:
        root.quit()
        return
      root.after(500, timer)
    timer()

    self.root.withdraw()

    self._dispatch(None)

    try:
      root.mainloop()
    except KeyboardInterrupt:
      pass
    log.debug("Quitting")


def launch ():
  import boot
  core.registerNew(Tk)
  boot.set_main_function(core.tk.run)

  """
  def pr (msg):
    print "From Tk:", msg
  core.callDelayed(5,lambda: core.tk.dialog.showinfo_cb(pr,
      "Hello", "Hello, World!"))
  """

########NEW FILE########
__FILENAME__ = topology
# Copyright 2011 James McCauley
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at:
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""
The Topology module is the root of an object model composed of entities
like switches, hosts, links, etc.  This object model is populated by other
modules.  For example, openflow.topology populates the topology object
with OpenFlow switches.

Note that this means that you often want to invoke something like:
   $ ./pox.py topology openflow.discovery openflow.topology
"""

from pox.lib.revent import *
from pox.core import core
from pox.lib.addresses import *
import traceback

import pickle


class EntityEvent (Event):
  def __init__ (self, entity):
    Event.__init__(self)
    self.entity = entity

class EntityJoin (EntityEvent):
  """
  An entity has been added.

  Note that if there is a more specific join event defined for a particular
  entity, (e.g., SwitchJoin), this event will not be fired.

  TODO: or we could always raise EntityJoins along with SwitchJoins, which
  seems more intuitive to me.
  """
  pass

class EntityLeave (EntityEvent):
  """
  An entity has been removed

  Note that if there is a more specific leave event defined for a particular
  entity, (e.g., SwitchLeave), this event will not be fired.

  TODO: or we could always raise EntityLeaves along with SwitchLeaves, which
  seems more intuitive to me.
  """
  pass

class SwitchEvent (EntityEvent): pass

class SwitchJoin (SwitchEvent):
  """
  As opposed to ConnectionUp, SwitchJoin occurs over large time scales
  (e.g. an administrator physically moving a switch).
  """
  def __init__ (self, switch):
    SwitchEvent.__init__(self, switch)
    self.switch = switch

class SwitchLeave (SwitchEvent):
  """
  As opposed to ConnectionDown, SwitchLeave occurs over large time scales
  (e.g. an administrator physically moving a switch).
  """
  pass

class SwitchConnectionUp(SwitchEvent):
  def __init__(self, switch, connection):
    SwitchEvent.__init__(self, switch)
    self.switch = switch
    self.connection = connection

class SwitchConnectionDown(SwitchEvent): pass

class HostEvent (EntityEvent): pass
class HostJoin (HostEvent): pass
class HostLeave (HostEvent): pass

class Update (Event):
  """
  Fired by Topology whenever anything has changed
  """
  def __init__ (self, event=None):
    Event.__init__(self)
    self.event = event

class Entity (object):
  """
  Note that the Entity class is intentionally simple; It only serves as a
  convenient SuperClass type.

  It's up to subclasses to implement specific functionality (e.g.
  OpenFlow1.0 switch functionality).  The purpose of this design decision
  is to prevent protocol specific details from being leaked into this
  module... but this design decision does /not/ imply that pox.toplogy
  serves to define a generic interface to abstract entity types.

  NOTE: /all/ subclasses must call this superconstructor, since
        the unique self.id is field is used by Topology
  """
  # This is a counter used so that we can get unique IDs for entities.
  # Some entities don't need this because they have more meaningful
  # identifiers.
  _next_id = 101
  _all_ids = set()
  _tb = {}

  def __init__ (self, id=None):
    if id:
      if id in Entity._all_ids:
        print("".join(traceback.format_list(self._tb[id])))
        raise Exception("ID %s already taken" % str(id))
    else:
      while Entity._next_id in Entity._all_ids:
        Entity._next_id += 1
      id = Entity._next_id

    self._tb[id] = traceback.extract_stack()
    Entity._all_ids.add(id)
    self.id = id

  def serialize(self):
    return pickle.dumps(self, protocol = 0)

  @classmethod
  def deserialize(cls):
    return pickle.loads(cls, protocol = 0)

class Host (Entity):
  """
  A generic Host entity.
  """
  def __init__(self,id=None):
    Entity.__init__(self, id)

class Switch (Entity):
  """
  Subclassed by protocol-specific switch classes,
  e.g. pox.openflow.topology.OpenFlowSwitch
  """
  def __init__(self, id=None):
    # Switches often have something more meaningful to use as an ID
    # (e.g., a DPID or MAC address), so they take it as a parameter.
    Entity.__init__(self, id)

class Port (Entity):
  def __init__ (self, num, hwAddr, name):
    Entity.__init__(self)
    self.number = num
    self.hwAddr = EthAddr(hwAddr)
    self.name = name

class Controller (Entity):
  def __init__(self, name, handshake_complete=False):
    self.id = name
    # TODO: python aliases?
    self.name = name
    self.handshake_complete = handshake_complete

  def handshake_completed(self):
    self.handshake_complete = True

class Topology (EventMixin):
  _eventMixin_events = [
    SwitchJoin,
    SwitchLeave,
    HostJoin,
    HostLeave,
    EntityJoin,
    EntityLeave,

    Update
  ]

  _core_name = "topology" # We want to be core.topology

  def __init__ (self, name="topology"):
    EventMixin.__init__(self)
    self._entities = {}
    self.name = name
    self.log = core.getLogger(name)

    # If a client registers a handler for these events after they have
    # already occurred, we promise to re-issue them to the newly joined
    # client.
    self._event_promises = {
      SwitchJoin : self._fulfill_SwitchJoin_promise
    }

  def getEntityByID (self, ID, fail=False):
    """
    Raises an exception if fail is True and the entity doesn't exist
    See also: The 'entity' property.
    """
    if fail:
      return self._entities[ID]
    else:
      return self._entities.get(ID, None)

  def removeEntity (self, entity):
    del self._entities[entity.id]
    self.log.info(str(entity) + " left")
    if isinstance(entity, Switch):
      self.raiseEvent(SwitchLeave, entity)
    elif isinstance(entity, Host):
      self.raiseEvent(HostLeave, entity)
    else:
      self.raiseEvent(EntityLeave, entity)

  def addEntity (self, entity):
    """ Will raise an exception if entity.id already exists """
    if entity.id in self._entities:
      raise RuntimeError("Entity exists")
    self._entities[entity.id] = entity
    self.log.debug(str(entity) + " (id: " + str(entity.id) + ") joined")
    if isinstance(entity, Switch):
      self.raiseEvent(SwitchJoin, entity)
    elif isinstance(entity, Host):
      self.raiseEvent(HostJoin, entity)
    else:
      self.raiseEvent(EntityJoin, entity)

  def getEntitiesOfType (self, t=Entity, subtypes=True):
    if subtypes is False:
      return [x for x in self._entities.itervalues() if type(x) is t]
    else:
      return [x for x in self._entities.itervalues() if isinstance(x, t)]

  def addListener(self, eventType, handler, once=False, weak=False,
                  priority=None, byName=False):
    """
    We interpose on EventMixin.addListener to check if the eventType is
    in our promise list. If so, trigger the handler for all previously
    triggered events.
    """
    if eventType in self._event_promises:
      self._event_promises[eventType](handler)

    return EventMixin.addListener(self, eventType, handler, once=once,
                                  weak=weak, priority=priority,
                                  byName=byName)

  def raiseEvent (self, event, *args, **kw):
    """
    Whenever we raise any event, we also raise an Update, so we extend
    the implementation in EventMixin.
    """
    rv = EventMixin.raiseEvent(self, event, *args, **kw)
    if type(event) is not Update:
      EventMixin.raiseEvent(self, Update(event))
    return rv

  def serialize (self):
    """
    Picklize our current entities.

    Returns a hash: { id -> pickled entitiy }
    """
    id2entity = {}
    for id in self._entities:
      entity = self._entities[id]
      id2entity[id] = entity.serialize()
    return id2entity

  def deserializeAndMerge (self, id2entity):
    """
    Given the output of topology.serialize(), deserialize each entity, and:
      - insert a new Entry if it didn't already exist here, or
      - update a pre-existing entry if it already existed
    """
    for entity_id in id2entity.keys():
      pickled_entity = id2entity[entity_id].encode('ascii', 'ignore')
      entity = pickle.loads(pickled_entity)
      entity.id = entity_id.encode('ascii', 'ignore')
      try:
        # Try to parse it as an int
        entity.id = int(entity.id)
      except ValueError:
        pass

      existing_entity = self.getEntityByID(entity.id)
      if existing_entity:
        self.log.debug("New metadata for %s: %s " % (str(existing_entity), str(entity)))
        # TODO: define an Entity.merge method (need to do something about his update!)
      else:
        self.addEntity(entity)

  def _fulfill_SwitchJoin_promise(self, handler):
    """ Trigger the SwitchJoin handler for all pre-existing switches """
    for switch in self.getEntitiesOfType(Switch, True):
      handler(SwitchJoin(switch))

  def __len__(self):
    return len(self._entities)

  def __str__(self):
    # TODO: display me graphically
    strings = []
    strings.append("topology (%d total entities)" % len(self._entities))
    for id,entity in self._entities.iteritems():
      strings.append("%s %s" % (str(id), str(entity)))

    return '\n'.join(strings)

########NEW FILE########
__FILENAME__ = jsonrpc
# Copyright 2011,2012 James McCauley
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at:
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""
A library for implementing JSON-RPC based web services

This is lightweight, low on features, and not a whole lot of effort
has been paid to really complying with the JSON-RPC spec.  Feel
free to improve it. ;)

It'd be nice to factor the JSON-RPC stuff out so that it could
be used with something besides just HTTP.

Also, it has some capability for compatibility with Qooxdoo.
"""

import json
import sys
from pox.web.webcore import *
from pox.core import core
log = core.getLogger()


# A long polling handler can return this if it notices that the
# connection has closed.
ABORT = object()


class JSONRPCHandler (SplitRequestHandler):
  """
  Meant for implementing JSON-RPC web services

  Implement RPC methods by prefacing them with "_exec_".

  config keys of note:
   "auth" is a function which takes a username and password and returns
       True if they are a valid user.  If set, turns on authentication.
   "auth_realm" is the optional authentication realm name.
   "qx" turns on Qooxdoo mode by default (it's usually switched on by
       seeing a "service" key in the request).

  There are a couple of extensions to JSON-RPC:

  If you want to use positional AND named parameters, in a request, use
  "params" for the former and "kwparams" for the latter.

  There's an optional "service" key in requests.  This comes from qooxdoo.
  If it is given, look for the _exec_ method on some otherobject instead
  of self.  Put the additional services in an arg named 'services'.
  """
  protocol_version = 'HTTP/1.1'

  QX_ERR_ILLEGAL_SERVICE = 1
  QX_ERR_SERVICE_NOT_FOUND = 2
  QX_ERR_CLASS_NOT_FOUND = 3
  QX_ERR_METHOD_NOT_FOUND = 4
  QX_ERR_PARAMETER_MISMATCH = 5
  QX_ERR_PERMISSION_DENIED = 6

  QX_ORIGIN_SERVER = 1
  QX_ORIGIN_METHOD = 2

  ERR_PARSE_ERROR = -32700             # WE USE THIS
  ERR_INVALID_REQUEST = -32600
  ERR_METHOD_NOT_FOUND = -32601        # WE USE THIS
  ERR_INVALID_PARAMS = -32602
  ERR_INTERNAL_ERROR = -32603          # WE USE THIS
  ERR_SERVER_ERROR = -32000 # to -32099  WE USE THIS

  ERR_METHOD_ERROR = 99 # We use this for errors in methods

  ERROR_XLATE = {
    ERR_PARSE_ERROR      : (1, QX_ERR_ILLEGAL_SERVICE), # Nonsense
    ERR_METHOD_NOT_FOUND : (1, QX_ERR_METHOD_NOT_FOUND),
    ERR_INTERNAL_ERROR   : (),
    ERR_SERVER_ERROR     : (),
  }

  _qx = False

  def _init (self):
    # Maybe the following arg-adding feature should just be part of
    # SplitRequestHandler?

    for k,v in self.args.iteritems():
      setattr(self, "_arg_" + k, v)

    self.auth_function = self.args.get('auth', None)
    self.auth_realm = self.args.get('auth_realm', "JSONRPC")

    self._qx = self.args.get('qx', self._qx)

  def _send_auth_header (self):
    if self.auth_function:
      self.send_header('WWW-Authenticate',
                       'Basic realm="%s"' % (self.auth_realm,))

  def _do_auth (self):
    if not self.auth_function:
      return True

    auth = self.headers.get("Authorization", "").strip().lower()
    success = False
    if auth.startswith("basic "):
      try:
        auth = base64.decodestring(auth[6:].strip()).split(':', 1)
        success = self.auth_function(auth[0], auth[1])
      except:
        pass
    if not success:
      self.send_response(401, "Authorization Required")
      self._send_auth_header()
      self.end_headers()
    return success

  def _translate_error (self, e):
    if not 'error' in e: return
    if self._qx:
      if e['code'] < 0:
        c,o = ERROR_XLATE.get(e['code'], (1, self.QX_ERR_ILLEGAL_SERVICE))
        e['code'] = c
        e['origin'] = o
      else:
        e['origin'] = QX_ORIGIN_METHOD

  def _handle (self, data):
    try:
      try:
        service = self
        if 'services' in self.args:
          if 'service' in data:
            service = self.args['services'].get(data['service'], self)
            self._qx = True # This is a qooxdoo request
        method = "_exec_" + data.get('method')
        method = getattr(service, method)
      except:
        response = {}
        response['error'] = {'code':self.ERR_METHOD_NOT_FOUND,
                             'message':'Method not found'}
        return response

      params = data.get('params', [])
      if isinstance(params, dict):
        kw = params
        params = []
      else:
        kw = data.get('kwparams', {})

      try:
        r = method(*params,**kw)

        #TODO: jsonrpc version?

        return r
      except:
        response = {}
        t,v,_ = sys.exc_info()
        response['error'] = {'message': "%s: %s" % (t,v),
                             'code':self.ERR_METHOD_ERROR}
        import traceback
        response['error']['data'] = {'traceback':traceback.format_exc()}
        log.exception("While handling %s...", data.get('method'))
        return response

    except:
      response = {}
      t,v,_ = sys.exc_info()
      response['error'] = {'message': "%s: %s" % (t,v),
                           'code':self.ERR_INTERNAL_ERROR}
      return response

  def do_POST (self):
    if not self._do_auth():
      return

    dumps_opts = {}

    #FIXME: this is a hack
    if 'pretty' in self.path:
      dumps_opts = {'sort_keys':True, 'indent':2}

    def reply (response):
      orig = response
      #if not isinstance(response, basestring):
      if isinstance(response, list):
        for r in response: self._translate_error(r)
      else:
        self._translate_error(response)
      response = json.dumps(response, default=str, **dumps_opts)
      response = response.strip()
      if len(response) and not response.endswith("\n"): response += "\n"
      try:
        self.send_response(200, "OK")
        self.send_header("Content-Type", "application/json")
        self.send_header("Content-Length", len(response))
        self.end_headers()
        self.wfile.write(response)
      except IOError as e:
        if e.errno == 32:
          if isinstance(orig, dict) and 'error' in orig:
            log.info("Socket closed when writing error response")
          else:
            log.warning("Socket closed when writing response")
            #log.debug(" response was: " + response)
        else:
          log.exception("Exception while trying to send JSON-RPC response")
        try:
          self.wfile.close()
        except:
          pass
        return False
      except:
        log.exception("Exception while trying to send JSON-RPC response")
        return False
      return True

    l = self.headers.get("Content-Length", "")
    data = ''
    if l == "":
      data = self.rfile.read()
    else:
      data = self.rfile.read(int(l))
    try:
      data = json.loads(data)
    except:
      response = {}
      response['error'] = {'code':self.ERR_PARSE_ERROR,
                           'message':'Parse error'}
      return reply(response)

    single = False
    if not isinstance(data, list):
      data = [data]
      single = True

    responses = []

    for req in data:
      response = self._handle(req) # Should never raise an exception
      if response is ABORT:
        return
      if 'id' in req or 'error' in response:
        response['id'] = req.get('id')
        responses.append(response)

    if len(responses) == 0:
      responses = ''
    else:
      if single:
        responses = responses[0]

    reply(responses)


class QXJSONRPCHandler (JSONRPCHandler):
  """
  A subclass of JSONRPCHandler which speaks something closer to
  qooxdoo's version JSON-RPC.
  """
  _qx = True
  #TODO: Implement the <SCRIPT> based GET method for cross-domain


def make_error (msg = "Unknown Error",
                code = JSONRPCHandler.ERR_SERVER_ERROR,
                data = None):
  e = {'code':code,'message':msg}
  if data is not None:
    e['data'] = data
  r = {'error':e}
  return r

########NEW FILE########
__FILENAME__ = webcore
# Copyright 2011,2012 James McCauley
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at:
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""
Webcore is a basic web server framework based on the SocketServer-based
BaseHTTPServer that comes with Python.  The big difference is that this
one can carve up URL-space by prefix, such that "/foo/*" gets handled by
a different request handler than "/bar/*".  I refer to this as "splitting".

You should also be able to make a request handler written without splitting
run under Webcore.  This may not work for all request handlers, but it
definitely works for some. :)  The easiest way to do this is with the
wrapRequestHandler() function, like so:
  from CGIHTTPServer import CGIHTTPRequestHandler as CHRH
  core.WebServer.set_handler("/foo", wrapRequestHandler(CHRH))

.. now URLs under the /foo/ directory will let you browse through the
filesystem next to pox.py.  If you create a cgi-bin directory next to
pox.py, you'll be able to run executables in it.

For this specific purpose, there's actually a SplitCGIRequestHandler
which demonstrates wrapping a normal request handler while also
customizing it a bit -- SplitCGIRequestHandler shoehorns in functionality
to use arbitrary base paths.

BaseHTTPServer is not very fast and needs to run on its own thread.
It'd actually be great to have a version of this written against, say,
CherryPy, but I did want to include a simple, dependency-free web solution.
"""

from SocketServer import ThreadingMixIn
from BaseHTTPServer import *
from time import sleep
import select
import threading

import random
import hashlib
import base64

from pox.core import core

import os
import posixpath
import urllib
import cgi
import errno
try:
    from cStringIO import StringIO
except ImportError:
    from StringIO import StringIO

log = core.getLogger()
try:
  weblog = log.getChild("server")
except:
  # I'm tired of people running Python 2.6 having problems with this.
  #TODO: Remove this someday.
  weblog = core.getLogger("webcore.server")

def _setAttribs (parent, child):
  attrs = ['command', 'request_version', 'close_connection',
           'raw_requestline', 'requestline', 'path', 'headers', 'wfile',
           'rfile', 'server', 'client_address']
  for a in attrs:
    setattr(child, a, getattr(parent, a))

  setattr(child, 'parent', parent)

import SimpleHTTPServer
from SimpleHTTPServer import SimpleHTTPRequestHandler


class SplitRequestHandler (BaseHTTPRequestHandler):
  """
  To write HTTP handlers for POX, inherit from this class instead of
  BaseHTTPRequestHandler.  The interface should be the same -- the same
  variables should be set, and the same do_GET(), etc. methods should
  be called.

  In addition, there will be a self.args which can be specified
  when you set_handler() on the server.
  """
  # Also a StreamRequestHandler

  def __init__ (self, parent, prefix, args):
    _setAttribs(parent, self)

    self.parent = parent
    self.args = args
    self.prefix = prefix

    self._init()

  def _init (self):
    """
    This is called by __init__ during initialization.  You can
    override it to, for example, parse .args.
    """
    pass

  def handle_one_request (self):
    raise RuntimeError("Not supported")

  def handle(self):
    raise RuntimeError("Not supported")

  def _split_dispatch (self, command, handler = None):
    if handler is None: handler = self
    mname = 'do_' + self.command
    if not hasattr(handler, mname):
        self.send_error(501, "Unsupported method (%r)" % self.command)
        return
    method = getattr(handler, mname)
    return method()

  def log_request (self, code = '-', size = '-'):
    weblog.debug(self.prefix + (':"%s" %s %s' %
              (self.requestline, str(code), str(size))))

  def log_error (self, fmt, *args):
    weblog.error(self.prefix + ':' + (fmt % args))

  def log_message (self, fmt, *args):
    weblog.info(self.prefix + ':' + (fmt % args))


_favicon = ("47494638396110001000c206006a5797927bc18f83ada9a1bfb49ceabda"
 + "4f4ffffffffffff21f904010a0007002c000000001000100000034578badcfe30b20"
 + "1c038d4e27a0f2004e081e2172a4051942abba260309ea6b805ab501581ae3129d90"
 + "1275c6404b80a72f5abcd4a2454cb334dbd9e58e74693b97425e07002003b")
_favicon = ''.join([chr(int(_favicon[n:n+2],16))
                   for n in xrange(0,len(_favicon),2)])

class CoreHandler (SplitRequestHandler):
  """
  A default page to say hi from POX.
  """
  def do_GET (self):
    """Serve a GET request."""
    self.do_content(True)

  def do_HEAD (self):
    """Serve a HEAD request."""
    self.do_content(False)

  def do_content (self, is_get):
    if self.path == "/":
      self.send_info(is_get)
    elif self.path.startswith("/favicon."):
      self.send_favicon(is_get)
    else:
      self.send_error(404, "File not found on CoreHandler")

  def send_favicon (self, is_get = False):
    self.send_response(200)
    self.send_header("Content-type", "image/gif")
    self.send_header("Content-Length", str(len(_favicon)))
    self.end_headers()
    if is_get:
      self.wfile.write(_favicon)

  def send_info (self, is_get = False):
    r = "<html><head><title>POX</title></head>\n"
    r += "<body>\n<h1>POX Webserver</h1>\n<h2>Components</h2>\n"
    r += "<ul>"
    for k in sorted(core.components):
      v = core.components[k]
      r += "<li>%s - %s</li>\n" % (cgi.escape(str(k)), cgi.escape(str(v)))
    r += "</ul>\n\n<h2>Web Prefixes</h2>"
    r += "<ul>"
    m = [map(cgi.escape, map(str, [x[0],x[1],x[3]]))
         for x in self.args.matches]
    m.sort()
    for v in m:
      r += "<li><a href='{0}'>{0}</a> - {1} {2}</li>\n".format(*v)
    r += "</ul></body></html>\n"

    self.send_response(200)
    self.send_header("Content-type", "text/html")
    self.send_header("Content-Length", str(len(r)))
    self.end_headers()
    if is_get:
      self.wfile.write(r)


class StaticContentHandler (SplitRequestHandler, SimpleHTTPRequestHandler):
  # We slightly modify SimpleHTTPRequestHandler to serve from given
  # directories and inherit from from Python, but
  # modified to serve from given directories and to inherit from
  # SplitRequestHandler.

  """
  A SplitRequestHandler for serving static content

  This is largely the same as the Python SimpleHTTPRequestHandler, but
  we modify it to serve from arbitrary directories at arbitrary
  positions in the URL space.
  """

  server_version = "StaticContentHandler/1.0"

  def send_head (self):
    # We override this and handle the directory redirection case because
    # we want to include the per-split prefix.
    path = self.translate_path(self.path)
    if os.path.isdir(path):
      if not self.path.endswith('/'):
        self.send_response(301)
        self.send_header("Location", self.prefix + self.path + "/")
        self.end_headers()
        return None
    return SimpleHTTPRequestHandler.send_head(self)

  def list_directory (self, dirpath):
    # dirpath is an OS path
    try:
      d = os.listdir(dirpath)
    except OSError as e:
      if e.errno == errno.EACCES:
        self.send_error(403, "This directory is not listable")
      elif e.errno == errno.ENOENT:
        self.send_error(404, "This directory does not exist")
      else:
        self.send_error(400, "Unknown error")
      return None
    d.sort(key=str.lower)
    r = StringIO()
    r.write("<!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 3.2 Final//EN\">\n")
    path = posixpath.join(self.prefix, cgi.escape(self.path).lstrip("/"))
    r.write("<html><head><title>" + path + "</title></head>\n")
    r.write("<body><pre>")
    parts = path.rstrip("/").split("/")
    r.write('<a href="/">/</a>')
    for i,part in enumerate(parts):
      link = urllib.quote("/".join(parts[:i+1]))
      if i > 0: part += "/"
      r.write('<a href="%s">%s</a>' % (link, cgi.escape(part)))
    r.write("\n" + "-" * (0+len(path)) + "\n")

    dirs = []
    files = []
    for f in d:
      if f.startswith("."): continue
      if os.path.isdir(os.path.join(dirpath, f)):
        dirs.append(f)
      else:
        files.append(f)

    def entry (n, rest=''):
      link = urllib.quote(n)
      name = cgi.escape(n)
      r.write('<a href="%s">%s</a>\n' % (link,name+rest))

    for f in dirs:
      entry(f, "/")
    for f in files:
      entry(f)

    r.write("</pre></body></html>")
    r.seek(0)
    self.send_response(200)
    self.send_header("Content-Type", "text/html")
    self.send_header("Content-Length", str(len(r.getvalue())))
    self.end_headers()
    return r

  def translate_path (self, path, include_prefix = True):
    """
    Translate a web-path to a local filesystem path

    Odd path elements (e.g., ones that contain local filesystem path
    separators) are stripped.
    """

    def fixpath (p):
      o = []
      skip = 0
      while True:
        p,tail = posixpath.split(p)
        if p in ('/','') and tail == '': break
        if tail in ('','.', os.path.curdir, os.path.pardir): continue
        if os.path.sep in tail: continue
        if os.path.altsep and os.path.altsep in tail: continue
        if os.path.splitdrive(tail)[0] != '': continue

        if tail == '..':
          skip += 1
          continue
        if skip:
          skip -= 1
          continue
        o.append(tail)
      o.reverse()
      return o

    # Remove query string / fragment
    if "?" in path: path = path[:path.index("?")]
    if "#" in path: path = path[:path.index("#")]
    path = fixpath(path)
    if path:
      path = os.path.join(*path)
    else:
      path = ''
    if include_prefix:
      path = os.path.join(os.path.abspath(self.args['root']), path)
    return path


def wrapRequestHandler (handlerClass):
  return type("Split" + handlerClass.__name__,
              (SplitRequestHandler, handlerClass, object), {})


from CGIHTTPServer import CGIHTTPRequestHandler
class SplitCGIRequestHandler (SplitRequestHandler,
                              CGIHTTPRequestHandler, object):
  """
  Runs CGIRequestHandler serving from an arbitrary path.
  This really should be a feature of CGIRequestHandler and the way of
  implementing it here is scary and awful, but it at least sort of works.
  """
  __lock = threading.Lock()
  def _split_dispatch (self, command):
    with self.__lock:
      olddir = os.getcwd()
      try:
        os.chdir(self.args)
        return SplitRequestHandler._split_dispatch(self, command)
      finally:
        os.chdir(olddir)


class SplitterRequestHandler (BaseHTTPRequestHandler):
  def __init__ (self, *args, **kw):
    #self.rec = Recording(args[0])
    #self.args = args
    #self.matches = self.matches.sort(key=lambda e:len(e[0]),reverse=True)
    #BaseHTTPRequestHandler.__init__(self, self.rec, *args[1:], **kw)
    BaseHTTPRequestHandler.__init__(self, *args, **kw)

  def log_request (self, code = '-', size = '-'):
    weblog.debug('splitter:"%s" %s %s',
                 self.requestline, str(code), str(size))

  def log_error (self, fmt, *args):
    weblog.error('splitter:' + fmt % args)

  def log_message (self, fmt, *args):
    weblog.info('splitter:' + fmt % args)

  def handle_one_request(self):
    self.raw_requestline = self.rfile.readline()
    if not self.raw_requestline:
        self.close_connection = 1
        return
    if not self.parse_request(): # An error code has been sent, just exit
        return

    handler = None

    while True:
      for m in self.server.matches:
        if self.path.startswith(m[0]):
          #print m,self.path
          handler = m[1](self, m[0], m[3])
          #pb = self.rec.getPlayback()
          #handler = m[1](pb, *self.args[1:])
          _setAttribs(self, handler)
          if m[2]:
            # Trim. Behavior is not "perfect"
            handler.path = self.path[len(m[0]):]
            if m[0].endswith('/'):
              handler.path = '/' + handler.path
          break

      if handler is None:
        handler = self
        if not self.path.endswith('/'):
          # Handle splits like directories
          self.send_response(301)
          self.send_header("Location", self.path + "/")
          self.end_headers()
          break

      break

    return handler._split_dispatch(self.command)


class SplitThreadedServer(ThreadingMixIn, HTTPServer):
  matches = [] # Tuples of (Prefix, TrimPrefix, Handler)

#  def __init__ (self, *args, **kw):
#    BaseHTTPRequestHandler.__init__(self, *args, **kw)
#    self.matches = self.matches.sort(key=lambda e:len(e[0]),reverse=True)

  def set_handler (self, prefix, handler, args = None, trim_prefix = True):
    # Not very efficient
    assert (handler is None) or (issubclass(handler, SplitRequestHandler))
    self.matches = [m for m in self.matches if m[0] != prefix]
    if handler is None: return
    self.matches.append((prefix, handler, trim_prefix, args))
    self.matches.sort(key=lambda e:len(e[0]),reverse=True)

  def add_static_dir (self, www_path, local_path=None, relative=False):
    """
    Serves a directory of static content.
    www_path is the prefix of the URL that maps to this directory.
    local_path is the directory to serve content from.  If it's not
    specified, it is assume to be a directory with the same name as
    www_path.
    relative, if True, means that the local path is to be a sibling
    of the calling module.
    For an example, see the launch() function in this module.
    """
    if not www_path.startswith('/'): www_path = '/' + www_path

    if local_path is None:
      local_path = www_path[1:]
      if relative:
        local_path = os.path.basename(local_path)
    if relative:
      import inspect
      path = inspect.stack()[1][1]
      path = os.path.dirname(path)
      local_path = os.path.join(path, local_path)

    local_path = os.path.abspath(local_path)

    log.debug("Serving %s at %s", local_path, www_path)

    self.set_handler(www_path, StaticContentHandler,
                     {'root':local_path}, True);


def launch (address='', port=8000, static=False):
  httpd = SplitThreadedServer((address, int(port)), SplitterRequestHandler)
  core.register("WebServer", httpd)
  httpd.set_handler("/", CoreHandler, httpd, True)
  #httpd.set_handler("/foo", StaticContentHandler, {'root':'.'}, True)
  #httpd.set_handler("/f", StaticContentHandler, {'root':'pox'}, True)
  #httpd.set_handler("/cgis", SplitCGIRequestHandler, "pox/web/www_root")
  if static is True:
    httpd.add_static_dir('static', 'www_root', relative=True)
  elif static is False:
    pass
  else:
    static = static.split(",")
    for entry in static:
      if entry.lower() == "":
        httpd.add_static_dir('static', 'www_root', relative=True)
        continue
      if ':' not in entry:
        directory = entry
        prefix = os.path.split(directory)
        if prefix[1] == '':
          prefix = os.path.split(prefix[0])
        prefix = prefix[1]
        assert prefix != ''
      else:
        prefix,directory = entry.split(":")
      directory = os.path.expanduser(directory)
      httpd.add_static_dir(prefix, directory, relative=False)

  def run ():
    try:
      log.debug("Listening on %s:%i" % httpd.socket.getsockname())
      httpd.serve_forever()
    except:
      pass
    log.info("Server quit")

  thread = threading.Thread(target=run)
  thread.daemon = True
  thread.start()

########NEW FILE########
__FILENAME__ = pox
#!/bin/sh -

# Copyright 2011-2012 James McCauley
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at:
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# If you have PyPy 1.6+ in a directory called pypy alongside pox.py, we
# use it.
# Otherwise, we try to use a Python interpreter called python2.7, which
# is a good idea if you're using Python from MacPorts, for example.
# We fall back to just "python" and hope that works.

''''true
#export OPT="-u -O"
export OPT="-u"
export FLG=""
if [ "$(basename $0)" = "debug-pox.py" ]; then
  export OPT=""
  export FLG="--debug"
fi

if [ -x pypy/bin/pypy ]; then
  exec pypy/bin/pypy $OPT "$0" $FLG "$@"
fi

if type python2.7 > /dev/null 2> /dev/null; then
  exec python2.7 $OPT "$0" $FLG "$@"
fi
exec python $OPT "$0" $FLG "$@"
'''

from pox.boot import boot

if __name__ == '__main__':
  boot()

########NEW FILE########
__FILENAME__ = skeleton_generator
#!/usr/bin/env python
#
# Copyright 2011-2012 Andreas Wundsam
# Copyright 2013 James McCauley
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at:
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""
Generates skeleton unit tests for POX modules
"""

from fnmatch import fnmatchcase
import hashlib
from optparse import OptionParser
import sys
from os import path
import os
import re
import stat
from string import Template

SCRIPT_DIR=path.dirname(path.abspath(sys.modules['__main__'].__file__))
ROOT=path.abspath(path.join(SCRIPT_DIR,".."))
UNIT_TEST=path.join(ROOT, "tests/unit")

parser = OptionParser(
    usage="usage: %prog [--force] <module_glob> [<module_glob>...]",
    description="Generates skeleton unit tests for pox modules",
    epilog="Arguments: module_glob: fully qualified python module name, "
           "e.g., pox.openflow.topology. Supports shell-type globs, e.g., "
           "pox.openflow.*")
parser.add_option("-f", "--force", help="force overwriting existing unit "
    "tests, even when no valid autogeneration signature is found",
    action="store_true", dest="force", default=False)

(options, args) = parser.parse_args()

if len(args) == 0:
  parser.print_usage()
  exit(10)

modules=[]

for root, dirs, files in os.walk(ROOT):
  assert root.startswith(ROOT)
  root = root[len(ROOT)+1:]
  if not root.startswith("pox"): continue

  files = [f for f in files if f.endswith(".py")]
  #print root
  for f in files:
    packagename = root.replace(path.sep,".")
    modules.append(packagename + "." + f[:-3])

def mkdir(d):
  if not os.path.exists(d):
    print "mkdir %s" % d
    os.makedirs(d)
  else:
    print "mkdir %s [exists]" % d

template = Template(
"""#!/usr/bin/env python

# Copyright 20xx Some Developer
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at:
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import itertools
import os.path
import sys
import unittest

sys.path.append(os.path.join(os.path.dirname(__file__),
    *itertools.repeat("..", ${path_depth})))

from ${module} import *

class ${test_class_name} (unittest.TestCase):
  pass

""")

def generate_test(module):
  print "Generating test for module: %s" % module
  lastdot = module.rfind(".")
  package = module[0:lastdot] if lastdot > 0 else ""
  name = module[lastdot+1:]
  test_package = re.sub(r'^pox\.', '', package)

  dst_dir = path.join(UNIT_TEST, *test_package.split('.'))
  mkdir(dst_dir)
  camel_name = re.sub(r'(_|^)+(.)', lambda(m): m.group(2).upper(), name)
  test_class_name = camel_name + "Test"
  test_file = path.join(dst_dir, name + "_test.py")

  test = template.substitute( {
    'path_depth' : 1 + module.count("."),
    'module' : module,
    'test_class_name' : test_class_name
    })

  def sha1(msg):
    s = hashlib.sha1()
    s.update(msg)
    return s.hexdigest()

  sha1sum = sha1(test)
  hashed_test = re.sub(r'\n', "\n### auto generate sha1: "
      + sha1sum + "\n", test, 1)

  def write_test(update=False):
    with open(test_file, "w") as f:
      f.write(hashed_test)
      f.close()
    os.chmod(test_file, stat.S_IWUSR|stat.S_IRUSR|stat.S_IXUSR
        |stat.S_IXGRP|stat.S_IRGRP|stat.S_IXOTH|stat.S_IROTH)

  if not os.path.exists(test_file) or options.force:
    print "Creating test %s in %s" % (test_class_name, test_file)
    write_test()
  else:
    f = open(test_file, "r")
    existing = f.read()
    f.close()
    genline = existing.split("\n")[1]
    match = re.match(r'### auto generate sha1: ([a-f0-9]+)', genline)
    if match:
      read_sha1 =  match.group(1)
      existing_non_hashed = re.sub(r'\n[^\n]*\n', '\n', existing, 1)
      calculated_sha1 = sha1(existing_non_hashed)
      if read_sha1 == calculated_sha1:
        print "Updating test %s in %s" % (test_class_name, test_file)
        write_test(True)
      else:
        print ("Test for %s in %s already exists (and sha1 sums don't "
               "match: %s<=>%s)") % (test_class_name,
               test_file, read_sha1, calculated_sha1)
    else:
      print ("Test for %s in %s already exists (and no autogeneration "
             "sig found)") % (test_class_name, test_file)

count = 0
for module in modules:
  if any(fnmatchcase(module,glob) for glob in args):
    count += 1
    generate_test(module)
print "Created/updated",count,"tests"

########NEW FILE########
__FILENAME__ = switch_test
#!/usr/bin/env python
#
# Copyright 2011-2012 Andreas Wundsam
# Copyright 2011-2012 Colin Scott
# Copyright 2011-2013 James McCauley
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at:
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import unittest
import sys
import os.path
from copy import copy

sys.path.append(os.path.dirname(__file__) + "/../../..")

from pox.openflow.libopenflow_01 import *
from pox.openflow.flow_table import FlowTable
from pox.datapaths.switch import *

class MockConnection(object):
  def __init__(self, do_packing):
    self.received = []
    self.do_packing = do_packing

  @property
  def last(self):
    return self.received[-1]

  def set_message_handler(self, handler):
    self.on_message_received = handler

  def to_switch(self, msg):
    self.on_message_received(self, msg)

  # from switch
  def send(self, msg):
    if type(msg) is not bytes:
      if self.do_packing and hasattr(msg, 'pack'):
          dummy = msg.pack()
    self.received.append(msg)


class SwitchImplTest (unittest.TestCase):
  _do_packing = False

  def setUp(self):
    self.conn = MockConnection(self._do_packing)
    self.switch = SoftwareSwitch(1, name="sw1")
    self.switch.set_connection(self.conn)
    self.packet = ethernet(
        src=EthAddr("00:00:00:00:00:01"),
        dst=EthAddr("00:00:00:00:00:02"),
        payload=ipv4(srcip=IPAddr("1.2.3.4"),
        dstip=IPAddr("1.2.3.5"),
        payload=udp(srcport=1234, dstport=53, payload="haha")))

  def test_hello(self):
    c = self.conn
    c.to_switch(ofp_hello(xid=123))
    self.assertEqual(len(c.received), 1)
    self.assertTrue(isinstance(c.last, ofp_hello),
          "should have received hello but got %s" % c.last)

  def test_echo_request(self):
    c = self.conn
    c.to_switch(ofp_echo_request(xid=123))
    self.assertEqual(len(c.received), 1)
    self.assertTrue(isinstance(c.last, ofp_echo_reply) and c.last.xid == 123,
          "should have received echo reply but got %s" % c.last)

  def test_barrier(self):
    c = self.conn
    c.to_switch(ofp_barrier_request(xid=123))
    self.assertEqual(len(c.received), 1)
    self.assertTrue(isinstance(c.last, ofp_barrier_reply)
        and c.last.xid == 123,
        "should have received echo reply but got %s" % c.last)

  def test_flow_mod(self):
    c = self.conn
    s = self.switch
    c.to_switch(ofp_flow_mod(xid=124, priority=1,
        match=ofp_match(in_port=1, nw_src="1.2.3.4")))
    self.assertEqual(len(c.received), 0)
    self.assertEqual(len(s.table), 1)
    e = s.table.entries[0]
    self.assertEqual(e.priority,1)
    self.assertEqual(e.match, ofp_match(in_port=1, nw_src="1.2.3.4"))

  def test_packet_out(self):
    c = self.conn
    s = self.switch
    received = []
    s.addListener(DpPacketOut, lambda(event): received.append(event))

    packet = self.packet
    c.to_switch(ofp_packet_out(data=packet,
        actions=[ofp_action_output(port=2)]))
    self.assertEqual(len(c.received), 0)
    self.assertEqual(len(received), 1)
    event = received[0]
    self.assertEqual(event.port.port_no,2)
    self.assertEqual(event.packet.pack(), packet.pack())

  def test_send_packet_in(self):
    c = self.conn
    s = self.switch
    s.send_packet_in(in_port=1, buffer_id=123, packet=self.packet,
        reason=OFPR_NO_MATCH)
    self.assertEqual(len(c.received), 1)
    self.assertTrue(isinstance(c.last, ofp_packet_in) and c.last.xid == 0,
        "should have received packet_in but got %s" % c.last)
    self.assertEqual(c.last.in_port,1)
    self.assertEqual(c.last.buffer_id,123)
    self.assertEqual(c.last.data, self.packet.pack())

  def test_rx_packet(self):
    c = self.conn
    s = self.switch
    received = []
    s.addListener(DpPacketOut, lambda(event): received.append(event))
    # no flow entries -> should result in a packet_in
    s.rx_packet(self.packet, in_port=1)
    self.assertEqual(len(c.received), 1)
    self.assertTrue(isinstance(c.last, ofp_packet_in),
        "should have received packet_in but got %s" % c.last)
    self.assertTrue(c.last.buffer_id > 0)

    # let's send a flow_mod with a buffer id
    c.to_switch(ofp_flow_mod(xid=124, buffer_id=c.last.buffer_id, priority=1,
                             match=ofp_match(in_port=1, nw_src="1.2.3.4"),
                             actions = [ ofp_action_output(port=3) ]
                             ))

    # that should have send the packet out port 3
    self.assertEqual(len(received), 1)
    event = received[0]
    self.assertEqual(event.port.port_no,3)
    self.assertEqual(event.packet, self.packet)

    # now the next packet should go through on the fast path
    c.received = []
    received = []
    s.rx_packet(self.packet, in_port=1)
    self.assertEqual(len(c.received), 0)

    self.assertEqual(len(received), 1)
    event = received[0]
    self.assertEqual(event.port.port_no,3)
    self.assertEqual(event.packet, self.packet)

  def test_delete_port(self):
    c = self.conn
    s = self.switch
    original_num_ports = len(self.switch.ports)
    p = self.switch.ports.values()[0]
    s.delete_port(p)
    new_num_ports = len(self.switch.ports)
    self.assertTrue(new_num_ports == original_num_ports - 1,
                    "Should have removed the port")
    self.assertEqual(len(c.received), 1)
    self.assertTrue(isinstance(c.last, ofp_port_status),
          "should have received port_status but got %s" % c.last)
    self.assertTrue(c.last.reason == OFPPR_DELETE)

  def test_add_port(self):
    c = self.conn
    s = self.switch
    port_count = len(self.switch.ports)
    old_port = s.delete_port(1)
    self.assertTrue(port_count - 1 == len(self.switch.ports),
                    "Should have removed port")
    self.assertFalse(old_port.port_no in self.switch.ports,
                     "Should have removedport")
    s.add_port(old_port)
    self.assertTrue(old_port.port_no in self.switch.ports,
                    "Should have added port")
    self.assertEqual(len(c.received), 2)
    self.assertTrue(isinstance(c.last, ofp_port_status),
          "should have received port_status but got %s" % c.last)
    self.assertTrue(c.last.reason == OFPPR_ADD)

  def test_port_mod_failed(self):
    c = self.conn

    # test wrong port
    msg = ofp_port_mod()
    msg.port_no = 1234
    c.to_switch(msg)
    self.assertEqual(len(c.received), 1)
    self.assertTrue(isinstance(c.last, ofp_error))
    self.assertTrue(c.last.type == OFPET_PORT_MOD_FAILED)
    self.assertTrue(c.last.code == OFPPMFC_BAD_PORT)

    # test wrong hw_addr
    msg.port_no = 1
    msg.hw_addr = EthAddr("11:22:33:44:55:66")
    c.to_switch(msg)
    self.assertEqual(len(c.received), 2)
    self.assertTrue(isinstance(c.last, ofp_error))
    self.assertTrue(c.last.type == OFPET_PORT_MOD_FAILED)
    self.assertTrue(c.last.code == OFPPMFC_BAD_HW_ADDR)

  def test_port_mod_link_down(self):
    c = self.conn
    s = self.switch

    # test wrong port
    msg = ofp_port_mod()
    msg.port_no = 1
    msg.hw_addr = s.ports[1].hw_addr
    msg.mask = OFPPC_PORT_DOWN
    msg.config = OFPPC_PORT_DOWN
    c.to_switch(msg)
    self.assertEqual(len(c.received), 1)
    self.assertTrue(isinstance(c.last, ofp_port_status))


# Do tests with packing independently to make it easier to spot
# packing-related bugs.  (Maybe?)
class PackingTest (SwitchImplTest):
  _do_packing = True


#class SwitchFlowTableTest(unittest.TestCase):
class ProcessFlowModTest(unittest.TestCase):
  _do_packing = False

  def setUp(self):
    self.conn = MockConnection(self._do_packing)
    self.switch = SoftwareSwitch(1, name="sw1")
    self.switch.set_connection(self.conn)
    self.packet = ethernet(
        src=EthAddr("00:00:00:00:00:01"),
        dst=EthAddr("00:00:00:00:00:02"),
        payload=ipv4(srcip=IPAddr("1.2.3.4"),
        dstip=IPAddr("1.2.3.5"),
        payload=udp(srcport=1234, dstport=53, payload="haha")))

  def test_process_flow_mod_add(self):
    """ test that simple insertion of a flow works"""
    c = self.conn
    s = self.switch
    t = s.table

    # test wrong port
    msg = ofp_flow_mod(priority=5, cookie=0x31415926, actions=[ofp_action_output(port=5)])
    c.to_switch(msg)

    self.assertEqual(len(t.entries), 1)
    e = t.entries[0]
    self.assertEqual(e.priority, 5)
    self.assertEqual(e.cookie, 0x31415926)
    self.assertEqual(e.actions, [ ofp_action_output(port=5)])

  def test_process_flow_mod_modify(self):
    """ test that simple removal of a flow works"""
    c = self.conn
    s = self.switch

    def table():
      t = FlowTable()
      t.add_entry(TableEntry(priority=6, cookie=0x1, match=ofp_match(dl_src=EthAddr("00:00:00:00:00:01"),nw_src="1.2.3.4"), actions=[ofp_action_output(port=5)]))
      t.add_entry(TableEntry(priority=5, cookie=0x2, match=ofp_match(dl_src=EthAddr("00:00:00:00:00:02"), nw_src="1.2.3.0/24"), actions=[ofp_action_output(port=6)]))
      t.add_entry(TableEntry(priority=1, cookie=0x3, match=ofp_match(), actions=[]))
      return t

    s.table = table()
    t = s.table
    msg = ofp_flow_mod(command = OFPFC_MODIFY, match=ofp_match(), actions = [ofp_action_output(port=1)])
    c.to_switch(msg)
    self.assertEquals([e.cookie for e in t.entries if e.actions == [ofp_action_output(port=1)] ], [1,2,3])
    self.assertEquals(len(t.entries), 3)

    s.table = table()
    t = s.table
    msg = ofp_flow_mod(command = OFPFC_MODIFY, match=ofp_match(nw_src="1.2.0.0/16"), actions = [ofp_action_output(port=8)])
    c.to_switch(msg)
    self.assertEquals([e.cookie for e in t.entries if e.actions == [ofp_action_output(port=8)] ], [1,2])
    self.assertEquals(len(t.entries), 3)

    # non-matching OFPFC_MODIFY acts as add
    s.table = table()
    t = s.table
    msg = ofp_flow_mod(cookie=5, command = OFPFC_MODIFY, match=ofp_match(nw_src="2.2.0.0/16"), actions = [ofp_action_output(port=8)])
    c.to_switch(msg)
    self.assertEquals(len(t.entries), 4)
    self.assertEquals([e.cookie for e in t.entries if e.actions == [ofp_action_output(port=8)] ], [5])

  def test_process_flow_mod_modify_strict(self):
    """ test that simple removal of a flow works"""
    c = self.conn
    s = self.switch

    def table():
      t = FlowTable()
      t.add_entry(TableEntry(priority=6, cookie=0x1, match=ofp_match(dl_src=EthAddr("00:00:00:00:00:01"),nw_src="1.2.3.4"), actions=[ofp_action_output(port=5)]))
      t.add_entry(TableEntry(priority=5, cookie=0x2, match=ofp_match(dl_src=EthAddr("00:00:00:00:00:02"), nw_src="1.2.3.0/24"), actions=[ofp_action_output(port=6)]))
      t.add_entry(TableEntry(priority=1, cookie=0x3, match=ofp_match(), actions=[]))
      return t

    s.table = table()
    t = s.table
    msg = ofp_flow_mod(command = OFPFC_MODIFY_STRICT, priority=1, match=ofp_match(), actions = [ofp_action_output(port=1)])
    c.to_switch(msg)
    self.assertEquals([e.cookie for e in t.entries if e.actions == [ofp_action_output(port=1)] ], [3])
    self.assertEquals(len(t.entries), 3)

    s.table = table()
    t = s.table
    msg = ofp_flow_mod(command = OFPFC_MODIFY_STRICT, priority=5, match=ofp_match(dl_src=EthAddr("00:00:00:00:00:02"), nw_src="1.2.3.0/24"), actions = [ofp_action_output(port=8)])
    c.to_switch(msg)
    self.assertEquals([e.cookie for e in t.entries if e.actions == [ofp_action_output(port=8)] ], [2])
    self.assertEquals(len(t.entries), 3)




if __name__ == '__main__':
  unittest.main()

########NEW FILE########
__FILENAME__ = addresses_test
# Copyright 2012 Colin Scott
# Copyright 2012,2013 James McCauley
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at:
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import unittest
import sys
import os.path
from pox.lib.addresses import *
from copy import copy

try:
  import nose
  _fail_decorator = nose.tools.raises(RuntimeError)
except:
  _fail_decorator = unittest.expectedFailure


class MockEthAddrTest(unittest.TestCase):
  def test_basic(self):
    self.assertEqual("00:11:22:33:44:55", str(EthAddr("00:11:22:33:44:55")),
        "str(eth) doesn't match original string")

#  def test_int_ctor(self):
#    int_val = EthAddr("00:00:00:00:01:00").toInt()
#    self.assertEqual(int_val, 1<<8)
#    with_int_ctor = EthAddr(int_val)
#    self.assertEqual(int_val, with_int_ctor.toInt())
#    self.assertEqual(str(with_int_ctor), "00:00:00:00:01:00")

class MockIPAddrTest (unittest.TestCase):
  def test_in_network (self):
    self.assertTrue(IPAddr("192.168.1.1").inNetwork("192.168.1.0/24"))

  def test_multicast (self):
    self.assertTrue(str(IPAddr("224.0.0.9").multicast_ethernet_address)
        == "01:00:5e:00:00:09")

  @_fail_decorator
  def test_bad_cidr_fail (self):
    parse_cidr("192.168.1.0/16", infer=False, allow_host=False)

  def test_bad_cidr_succeed (self):
    a,b=parse_cidr("192.168.1.0/255.255.255.0", infer=False, allow_host=False)
    self.assertEqual(a,IPAddr("192.168.1.0"))
    self.assertEqual(b,24)

  def test_byte_order (self):
    self.assertEqual(IPAddr(IPAddr('1.2.3.4').toSigned()).raw,
        '\x01\x02\x03\x04')

#TODO: Clean up these IPv6 tests
class IPv6Tests (unittest.TestCase):
  def test_basics_part1 (self):
    """
    Basic IPv6 address tests (part 1)
    """
    a = IPAddr6('2001:0db8:85a3:0000:0000:8a2e:0370:7334')
    assert str(a) == '2001:db8:85a3::8a2e:370:7334','minimal repr'
    assert a.to_str(zero_drop=False) == \
        '2001:0db8:85a3::8a2e:0370:7334', 'no zero drop'
    assert a.to_str(section_drop=False) == \
        '2001:db8:85a3:0:0:8a2e:370:7334', 'no section drop'
    assert a.to_str(section_drop=False, zero_drop=False) == \
        '2001:0db8:85a3:0000:0000:8a2e:0370:7334', 'full length'
    assert str(IPAddr6('0:0:0:0:0:0:0:1')) == '::1', 'loopback'
    assert str(IPAddr6('0:0:0:0:0:0:0:0')) == '::', 'unspecified'
    assert str(IPAddr6('2001:db8:0:0:0:0:2:1')) == '2001:db8::2:1'
    assert str(IPAddr6('2001:db8:0000:1:1:1:1:1')) == '2001:db8:0:1:1:1:1:1'
    assert str(IPAddr6('2001:db8:0:0:1:0:0:1')) == '2001:db8::1:0:0:1'
    assert str(IPAddr6('1:0:0:2:0:0:0:3')) == '1:0:0:2::3'

  def test_part2 (self):
    """
    Basic IPv6 address tests (part 2)
    """
    h = '\xfe\x80\x00\x00\x00\x00\x00\x00\xba\x8d\x12\xff\xfe\x2a\xdd\x6e'
    a = IPAddr6.from_raw(h)
    assert str(a) == 'fe80::ba8d:12ff:fe2a:dd6e'
    assert a.raw == h

    assert a.num == 0xfe80000000000000ba8d12fffe2add6e
    assert IPAddr6.from_num(a.num) == a

    assert a.is_multicast is False
    assert IPAddr6("FF02:0:0:0:0:0:0:1").is_multicast

    assert IPAddr6('2001:db8:1:2::').set_mac('00:1D:BA:06:37:64') \
        == '2001:db8:1:2:021d:baff:fe06:3764'

    assert IPAddr6('0:0:0:0:0:FFFF:222.1.41.90') == '::ffff:222.1.41.90'
    assert IPAddr6('::ffff:C0A8:5') == '::ffff:192.168.0.5'
    assert IPAddr6('::ffff:192.168.0.5') == '::ffff:c0a8:5'

########NEW FILE########
__FILENAME__ = epoll_select_test
#!/usr/bin/env python
#
# Copyright 2011-2012 Andreas Wundsam
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at:
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import unittest
import sys
import os.path
import SocketServer
import threading
import socket
import signal

from copy import copy

sys.path.append(os.path.dirname(__file__) + "/../../..")

from pox.lib.epoll_select import EpollSelect

class TCPEcho(SocketServer.StreamRequestHandler):
  def handle(self):
    data = self.rfile.readline()
    print "got data: %s" % data
    self.wfile.write(data)

class ForkingTCPServer(SocketServer.ThreadingMixIn, SocketServer.TCPServer):
  def start(self):
    self.pid = os.fork()
    if self.pid == 0:
      # child
      self.serve_forever()

  def stop(self):
    os.kill(self.pid, signal.SIGKILL)

def sort_fdlists(rl,wl,xl) :
  key = lambda(x): x.fileno() if hasattr(x, "fileno") else x

  return (
            sorted(rl, key=key),
            sorted(wl, key=key),
            sorted(xl, key=key)
        )

@unittest.skipUnless(sys.platform.startswith("linux"), "requires Linux")
class EpollSelectTest(unittest.TestCase):
  def setUp(self):
    self.es = EpollSelect()
    self.server = ForkingTCPServer(("localhost", 0), TCPEcho)
    self.ip, self.port = self.server.server_address
    self.server.start()

  def tearDown(self):
    self.es.close()
    self.server.stop()

  def test_create(self):
    pass

  def test_read_one_socket(self):
    c = socket.create_connection( (self.ip, self.port))
    ret  = self.es.select([c], [], [c], 0.1)
    self.assertEqual(([],[],[]), ret)
    # socket is ready to send?
    ret  = self.es.select([c], [c], [c], 0.1)
    self.assertEqual(([],[c],[]), ret)
    # send stuff
    c.send("Hallo\n")
    # now we have something to read, right?
    ret  = self.es.select([c], [], [c], 0.5)
    self.assertEqual(([c],[],[]), ret)

  def test_write_more_sockets(self):
    c1 = socket.create_connection( (self.ip, self.port))
    c2 = socket.create_connection( (self.ip, self.port))
    c3 = socket.create_connection( (self.ip, self.port))
    # note don't throw away the socket -- else it will be garbage collected
    raw = c3.fileno()
    seq = [ [c1], [c2], [c1,c2], [c1,c2, raw], [c1], [raw]]

    check = lambda a,b: self.assertEqual(sort_fdlists(*a), sort_fdlists(*b))

    #just the writes
    for sockets in seq:
     check(([],sockets,[]),self.es.select(sockets, sockets, sockets, 0))

    # writes and reads in different order
    for sockets in seq:
      check( ([],[],[]), self.es.select(sockets, [], sockets, 0))
      check( ([],sockets,[]), self.es.select(sockets, sockets, sockets, 0))

if __name__ == '__main__':
  unittest.main()

########NEW FILE########
__FILENAME__ = io_worker_test
#!/usr/bin/env python
#
# Copyright 2011-2012 Andreas Wundsam
# Copyright 2011-2012 Colin Scott
# Copyright 2011-2013 James McCauley
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at:
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import itertools
import os.path
import sys
import unittest

sys.path.append(os.path.join(os.path.dirname(__file__),
    *itertools.repeat("..", 3)))

from pox.lib.mock_socket import MockSocket
from pox.lib.ioworker import IOWorker, RecocoIOLoop
from nose.tools import eq_

class IOWorkerTest(unittest.TestCase):
  def test_basic_send(self):
    i = IOWorker()
    i.send("foo")
    self.assertTrue(i._ready_to_send)
    self.assertEqual(i.send_buf, "foo")
    i._consume_send_buf(3)
    self.assertFalse(i._ready_to_send)

  def test_basic_receive(self):
    i = IOWorker()
    self.data = None
    def d(worker):
      self.data = worker.peek()
    i.rx_handler = d
    i._push_receive_data("bar")
    self.assertEqual(self.data, "bar")
    # d does not consume the data
    i._push_receive_data("hepp")
    self.assertEqual(self.data, "barhepp")

  def test_receive_consume(self):
    i = IOWorker()
    self.data = None
    def consume(worker):
      self.data = worker.peek()
      worker.consume_receive_buf(len(self.data))
    i.rx_handler = consume
    i._push_receive_data("bar")
    self.assertEqual(self.data, "bar")
    # data has been consumed
    i._push_receive_data("hepp")
    self.assertEqual(self.data, "hepp")


class RecocoIOLoopTest(unittest.TestCase):
  def test_basic(self):
    loop = RecocoIOLoop()
    (left, right) = MockSocket.pair()
    loop.new_worker(left)

  def test_stop(self):
    loop = RecocoIOLoop()
    loop.stop()

  def test_run_read(self):
    loop = RecocoIOLoop()
    (left, right) = MockSocket.pair()
    worker = loop.new_worker(left)

    # callback for ioworker to record receiving
    self.received = None
    def r(worker):
      self.received = worker.peek()
    worker.rx_handler = r

    # 'start' the run (dark generator magic here).
    # Does not actually execute run, but 'yield' a generator
    g = loop.run()
    # g.next() will call it, and get as far as the 'yield select'
    select = g.next()

    # send data on other socket half
    right.send("hallo")

    # now we emulate the return value of the select ([rlist],[wlist], [elist])
    g.send(([worker], [], []))

    # that should result in the socket being red the data being handed
    # to the ioworker, the callback being called. Everybody happy.
    self.assertEquals(self.received, "hallo")

  def test_run_close(self):
    loop = RecocoIOLoop()
    (left, right) = MockSocket.pair()
    worker = loop.new_worker(left)

    self.assertFalse(worker in loop._workers,
        "Should not add to _workers yet, until we start up the loop")
    self.assertTrue(len(loop._pending_commands) == 1,
        "Should have added pending create() command")
    worker.close()
    # This causes the worker to be scheduled to be closed -- it also 
    # calls pinger.ping(). However, the Select task won't receive the ping
    # Until after this method has completed! Thus, we only test whether
    # worker has been added to the pending close queue
    self.assertTrue(len(loop._pending_commands) == 2,
        "Should have added pending close() command")

  def test_run_write(self):
    loop = RecocoIOLoop()
    (left, right) = MockSocket.pair()
    worker = loop.new_worker(left)

    worker.send("heppo")
    # 'start' the run (dark generator magic here).
    # Does not actually execute run, but 'yield' a generator
    g = loop.run()
    # g.next() will call it, and get as far as the 'yield select'
    select = g.next()

    # now we emulate the return value of the select ([rlist],[wlist], [elist])
    g.send(([], [worker], []))

    # that should result in the stuff being sent on the socket
    self.assertEqual(right.recv(), "heppo")

########NEW FILE########
__FILENAME__ = mock_socket_test
#!/usr/bin/env python
#
# Copyright 2011-2012 Andreas Wundsam
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at:
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import unittest
import sys
import os.path
from copy import copy

sys.path.append(os.path.dirname(__file__) + "/../../..")

from pox.lib.mock_socket import MockSocket

class MockSocketTest(unittest.TestCase):
  def setUp(self):
    pass

  def test_simple_send(self):
    (a, b) = MockSocket.pair()
    a.send("Hallo")
    self.assertEquals(b.recv(), "Hallo")
    b.send("Servus")
    self.assertEquals(a.recv(), "Servus")

  def test_ready_to_recv(self):
    (a, b) = MockSocket.pair()
    a.send("Hallo")
    self.assertFalse(a.ready_to_recv())
    self.assertTrue(b.ready_to_recv())
    self.assertEquals(b.recv(), "Hallo")
    self.assertFalse(b.ready_to_recv())

    self.assertFalse(a.ready_to_recv())
    b.send("Servus")
    self.assertTrue(a.ready_to_recv())
    self.assertEquals(a.recv(), "Servus")
    self.assertFalse(a.ready_to_recv())

  def test_on_ready_to_recv(self):
    self.seen_size = -1
    self.called = 0
    def ready(socket, size):
      self.called += 1
      self.seen_size = size

    (a, b) = MockSocket.pair()
    b.set_on_ready_to_recv(ready)
    self.assertEquals(self.called, 0)
    a.send("Hallo")
    self.assertEquals(self.called, 1)
    self.assertEquals(self.seen_size, 5)

    # check that it doesn't get called on the other sockets data
    b.send("Huhu")
    self.assertEquals(self.called, 1)

  def test_empty_recv(self):
    """ test_empty_recv: Check that empty reads on socket return ""
       Note that this is actually non-sockety behavior and should probably be changed. This
       test documents it as intended for now, though
    """
    (a, b) = MockSocket.pair()
    self.assertEquals(a.recv(), "")

if __name__ == '__main__':
  unittest.main()

########NEW FILE########
__FILENAME__ = module_load_test
#!/usr/bin/env python
#
# Copyright 2011-2012 Andreas Wundsam
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at:
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

""" A simple nose based test unit test that discovers all modules in the pox directory and tries to load them """

import sys
from os import path
import os

import unittest
SCRIPT_DIR=path.dirname(path.abspath(__file__))
ROOT=path.abspath(path.join(SCRIPT_DIR,"../.."))
sys.path.append(os.path.dirname(__file__) + "/../..")

packages = {}

modules = []

for root, dirs, files in os.walk(ROOT):
  assert root.startswith(ROOT)
  root = root[len(ROOT)+1:]
  if not root.startswith("pox"): continue

  if not path.exists(path.join(root, "__init__.py")):
    continue
  modules.append(root.replace(path.sep,"."))

  files = [f for f in files if f.endswith(".py") and not f.startswith("__init__") and f != "setup.py"]
  #print root
  for f in files:
    packagename = root.replace(path.sep,".")
    modules.append( packagename + "." + f[:-3])

def test_load_modules():
  # This is a test /generator/. It yields a separate loading test for each module
  # Nosetests is required
  for module in modules:
    yield load_module, module

def load_module(module):
  loaded_module = __import__(module)


if __name__ == '__main__':
  import nose
  nose.main(defaultTest=__name__)


########NEW FILE########
__FILENAME__ = flow_table_test
#!/usr/bin/env python
#
# Copyright 2011-2012 Andreas Wundsam
# Copyright 2011-2012 Colin Scott
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at:
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from collections import namedtuple

import time

import unittest
import sys
import os.path
import itertools

sys.path.append(os.path.dirname(__file__) + "/../../..")
from pox.openflow.libopenflow_01 import *
from pox.openflow.flow_table import *
from pox.openflow import *
from pox.openflow.topology import *

class TableEntryTest(unittest.TestCase):
  def test_create(self):
    e = TableEntry(priority=5, cookie=0xDEADBEEF, match=ofp_match(), actions=[ofp_action_output(port=1)])
    self.assertEqual(e.priority, 5)
    self.assertEqual(e.cookie, 0xDEADBEEF)
    self.assertEqual(e.actions, [ ofp_action_output(port=1) ])

  def test_from_flow_mod(self):
    e = TableEntry.from_flow_mod(ofp_flow_mod(priority=5, cookie=0x31415926, actions=[ofp_action_output(port=5)]))
    self.assertEqual(e.priority, 5)
    self.assertEqual(e.cookie, 0x31415926)
    self.assertEqual(e.actions, [ ofp_action_output(port=5) ])

  def test_to_flow_mod(self):
    e = TableEntry(priority=5,cookie=0xDEADBEEF, match=ofp_match(), actions=[ofp_action_output(port=1)])
    f = e.to_flow_mod(command = OFPFC_ADD)
    self.assertEqual(f.priority, 5)
    self.assertEqual(e.cookie, 0xDEADBEEF)
    self.assertEqual(e.actions, [ ofp_action_output(port=1)])

  def test_is_expired(self):
    e = TableEntry(now=0, idle_timeout=5, hard_timeout=10)
    self.assertEqual(e.idle_timeout, 5)
    self.assertEqual(e.hard_timeout, 10)
    self.assertFalse(e.is_expired(now=1))
    self.assertFalse(e.is_expired(now=5))
    self.assertTrue(e.is_expired(now=7))
    e.touch_packet(12, now=5)
    self.assertEqual(e.byte_count, 12)
    self.assertEqual(e.packet_count, 1)
    self.assertFalse(e.is_expired(now=1))
    self.assertFalse(e.is_expired(now=7))
    self.assertFalse(e.is_expired(now=10))
    e.touch_packet(12, now=9)
    self.assertTrue(e.is_expired(now=11))

    e2 = TableEntry(now=0, idle_timeout=0, hard_timeout=10)
    self.assertFalse(e2.is_expired(now=1))
    self.assertFalse(e2.is_expired(now=9))
    self.assertTrue(e2.is_expired(now=11))

class FlowTableTest(unittest.TestCase):
  def test_remove_matching_entries(self):
    """ test that simple removal of a flow works"""
    def table():
      t = FlowTable()
      t.add_entry(TableEntry(priority=6, cookie=0x1, match=ofp_match(dl_src=EthAddr("00:00:00:00:00:01"),nw_src="1.2.3.4"), actions=[ofp_action_output(port=5)]))
      t.add_entry(TableEntry(priority=5, cookie=0x2, match=ofp_match(dl_src=EthAddr("00:00:00:00:00:02"), nw_src="1.2.3.0/24"), actions=[ofp_action_output(port=6)]))
      t.add_entry(TableEntry(priority=1, cookie=0x3, match=ofp_match(), actions=[]))
      return t

    for (match, priority, strict, remaining) in (
          (ofp_match(), 0, False, []), #non-strict wildcard removes everything
          (ofp_match(), 0, True, [1,2,3]), # strict wildcard with wrong prio removes nothing
          (ofp_match(), 1, True, [1,2]), # strict wildcard with right prio removes only flow 3
          (ofp_match(nw_src="1.2.3.0/24"), 1, False, [3]), # non-strict subnet removes 1+2
          (ofp_match(nw_src="1.2.3.0/24"), 6, True, [1,2,3]), # does not match dl_src => noop
          (ofp_match(dl_src=EthAddr("00:00:00:00:00:02"), nw_src="1.2.3.0/24"), 5, True, [1,3]), # exactly matches #2
          ):
      t=table()
      t.remove_matching_entries(match, priority=priority, strict=strict)
      self.assertEqual([e.cookie for e in t._table], remaining)

  def test_remove_expired_entries(self):
    """ test that flow can get expired as time passes """
    t = FlowTable()
    for (cookie, idle, hard) in ( (1, 5, 20), (2, 5, 20), (3, 0, 20), (4, 0, 0) ):
      t.add_entry(TableEntry(now=0, cookie=cookie, idle_timeout=idle, hard_timeout=hard))

    for (time, touch, remaining) in (
            (1, [], [1,2,3,4]), # at time 1, everyone's happy
            (3, [2], [1,2,3,4]), # at time 3, flow 2 gets touched
            (6, [], [2,3,4]), # at time 6, flow 1 expires
            (9, [], [3,4]), # at time 9, flow 2 expires
            (21, [], [4]), # at time 21, flow 3 expires
            (99999999, [], [4]), # 4 would still live at the end of days
            ):
      [e.touch_packet(1, now=time) for e in t.entries if e.cookie in touch]
      t.remove_expired_entries(now=time)
      self.assertEqual(sorted([e.cookie for e in t.entries]), remaining)

  # def test_check_for_overlap_entries(self):




if __name__ == '__main__':
  unittest.main()


########NEW FILE########
__FILENAME__ = libopenflow_01_test
#!/usr/bin/env python
#
# Copyright 2011-2012 Andreas Wundsam
# Copyright 2011-2012 James McCauley
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at:
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import unittest
import sys
import os.path
from copy import copy
sys.path.append(os.path.dirname(__file__) + "/../../..")

from pox.openflow.libopenflow_01 import *
from pox.datapaths.switch import *

def extract_num(buf, start, length):
  """ extracts a number from a raw byte string. Assumes network byteorder  """
  # note: purposefully does /not/ use struct.unpack, because that is used by the code we validate 
  val = 0
  for i in range(start, start+length):
    val <<= 8
    val += ord(buf[i])
  return val

class ofp_match_test(unittest.TestCase):
  def test_bit_wildcards(self):
    """ some checking of the bit-level wildcard magic in ofp_match"""
    m = ofp_match()

    # all match entries should start out as wildcarded
    for k,v in ofp_match_data.iteritems():
         self.assertEquals(getattr(m, k), None, "Attr %s should be wildcarded and reported as None" % k)
         self.assertEquals(m.wildcards & v[1], v[1])

    # try setting and unsetting specific bit-level match entries
    for change in [ ("in_port", 1, OFPFW_IN_PORT), ("dl_vlan", 2, OFPFW_DL_VLAN), ("tp_dst", 22, OFPFW_TP_DST) ]:
      setattr(m, change[0], change[1])
      self.assertEquals(getattr(m, change[0]), change[1], "Attr %s should have been set to %s" % change[0:2])
      self.assertEquals(m.wildcards & change[2], 0, "with %s set to %s, wildcard bit %x should get unset" % change)
      setattr(m, change[0], None)
      self.assertEquals(m.wildcards & change[2], change[2], "with %s reset from %s, wildcard bit %x should be set again" % change)

  def test_ip_wildcard_magic(self):
    """ ofp_match: check IP wildcard magic"""

    # do this for both nw_src and nw_dst
    for (attr, bitmask, shift) in ( ("nw_src", OFPFW_NW_SRC_MASK, OFPFW_NW_SRC_SHIFT), ( "nw_dst", OFPFW_NW_DST_MASK, OFPFW_NW_DST_SHIFT) ):
      m = ofp_match()
      self.assertEquals(getattr(m, "get_"+attr)(), (None, 0), "get_%s for unset %s should return (None,0)" % (attr, attr))

      self.assertTrue( ((m.wildcards & bitmask) >> shift) >= 32)

      # set a bunch of ip addresses with or without networks
      for ipnet in ( "10.0.0.0/8", "172.16.0.0/16", "192.168.24.0/24", "1.2.3.4/30", "212.11.225.3"):
        parts = ipnet.split("/")
        ip = parts[0]
        bits = int(parts[1]) if len(parts)>1 else 32
        # set the IP address
        setattr(m, attr, ipnet)

        # gets converted to just the ip address during query
        self.assertEqual(getattr(m, attr), ip)

        # the get_#{attr} method gives a tuple of (ip, cidr-bits)
        self.assertEqual( getattr(m, "get_"+attr)(), (ip, bits))

        # the appropriate bits in the wildcard should be set
        self.assertEqual( (m.wildcards & bitmask) >> shift, 32-bits)

      # reset to 0.0.0.0/0 results in full wildcard
      setattr(m, attr, "0.0.0.0/0")
      self.assertEquals(getattr(m, "get_"+attr)(), (None, 0), "get_%s for unset %s should return (None,0)" % (attr, attr))
      self.assertTrue( ((m.wildcards & bitmask) >> shift) >= 32)

  def test_match_with_wildcards(self):
    """ ofp_match: test the matches_with_wildcards method """
    def create(wildcards=(), **kw):
      m = ofp_match(in_port=1, dl_type=0, dl_src=EthAddr("00:00:00:00:00:01"), dl_dst=EthAddr("00:00:00:00:00:02"), dl_vlan=5, nw_proto=6, nw_src="10.0.0.1", nw_dst="11.0.0.1", tp_src = 12345, tp_dst=80)

      if isinstance(wildcards, str):
        wildcards = [wildcards]

      for w in wildcards:
        setattr(m, w, None)

      for (k,v) in kw.iteritems():
        m.__setattr__(k,v)
      return m

    def assertMatch(ref, other, msg=""):
      self.assertTrue(ref.matches_with_wildcards(other), "%s - %s should match %s " % (msg, ref.show(), other.show()))

    def assertNoMatch(ref, other, msg=""):
      self.assertFalse(ref.matches_with_wildcards(other), "%s - %s should NOT match %s " % (msg, ref.show(), other.show()))

    ref = create()
    #print ref

    # same instances match
    assertMatch(ref, ref)
    # equal instances match
    assertMatch(ref, create())

    # ofp_match with additional wildcard bits set match the ref, but not the other way round
    for wildcards in ( [ "in_port" ], [ "dl_vlan" ], [ "dl_src", "dl_dst" ] ):
      wilder = create(wildcards=wildcards)
      assertMatch(wilder, ref)
      assertNoMatch(ref, wilder)

    # when fields are wildcarded, we can change around the actual values and it will still match
    for changes in ( { "in_port": 15 }, { "dl_src": "12:34:56:78:90:ab", "dl_vlan": 7 }, { "tp_dst" : 22 } ):
      wild = create()
      concrete = create()
      for (k,v) in changes.iteritems():
        setattr(wild, k, None)
        setattr(concrete, k, v)
      assertMatch(wild, concrete)
      assertNoMatch(concrete, wild)

    # play around with nw src addresses
    assertMatch(create(nw_src="10.0.0.0/24"), ref)
    assertMatch(create(nw_src="10.0.0.0/24"), create(nw_src="10.0.0.0/25"))
    assertNoMatch(create(nw_src="10.0.0.0/25"), create(nw_src="10.0.0.0/24"))
    assertMatch(create(nw_src="10.0.0.0/25"), create(nw_src="10.0.0.127"))
    assertNoMatch(create(nw_src="10.0.0.0/25"), create(nw_src="10.0.0.128"))

class ofp_command_test(unittest.TestCase):
  # custom map of POX class to header type, for validation
  ofp_type = {
    ofp_features_reply: OFPT_FEATURES_REPLY,
    ofp_set_config: OFPT_SET_CONFIG,
    ofp_flow_mod: OFPT_FLOW_MOD,
    ofp_port_mod: OFPT_PORT_MOD,
    ofp_queue_get_config_request: OFPT_QUEUE_GET_CONFIG_REQUEST,
    ofp_queue_get_config_reply: OFPT_QUEUE_GET_CONFIG_REPLY,
    ofp_stats_request: OFPT_STATS_REQUEST,
    ofp_stats_reply: OFPT_STATS_REPLY,
    ofp_packet_out: OFPT_PACKET_OUT,
    ofp_barrier_reply: OFPT_BARRIER_REPLY,
    ofp_barrier_request: OFPT_BARRIER_REQUEST,
    ofp_packet_in: OFPT_PACKET_IN,
    ofp_flow_removed: OFPT_FLOW_REMOVED,
    ofp_port_status: OFPT_PORT_STATUS,
    ofp_error: OFPT_ERROR,
    ofp_hello: OFPT_HELLO,
    ofp_echo_request: OFPT_ECHO_REQUEST,
    ofp_echo_reply: OFPT_ECHO_REPLY,
    ofp_vendor_generic: OFPT_VENDOR,
    ofp_features_request: OFPT_FEATURES_REQUEST,
    ofp_get_config_request: OFPT_GET_CONFIG_REQUEST,
    ofp_get_config_reply: OFPT_GET_CONFIG_REPLY,
    ofp_set_config: OFPT_SET_CONFIG
    }

  def assert_packed_header(self, pack, ofp_type, length, xid):
    """ check openflow header fields in packed byte array """
    def assert_num(name, start, length, expected):
      val = extract_num(pack, start, length)
      self.assertEquals(val, expected, "packed header check: %s for ofp type %s should be %d (is %d)" % (name, ofp_type_map[ofp_type], expected, val))

    assert_num("OpenFlow version", 0, 1, 1)
    assert_num("header_type", 1, 1, ofp_type)
    assert_num("length in header", 2, 2, length)
    assert_num("xid", 4, 4, xid)

  def _test_pack_unpack(self, o, xid, ofp_type=None):
    """ check that packing and unpacking an ofp object works, and that lengths etc. are correct """
    show = lambda(o): o.show() if hasattr(o, "show") else str(show)

    if not ofp_type:
      ofp_type = self.ofp_type[type(o)]

    self.assertTrue(o._assert(), "pack_unpack for %s -- original object should _assert to true"%show(o))
    # show the object to make sure that works
    o.show()
    # pack object
    pack = o.pack()
    # byte array length should equal calculated length
    self.assertEqual(len(o), len(pack), "pack_unpack for %s -- len(object)=%d != len(packed)=%d" % (type(o), len(o), len(pack)))
    # check header fields in packed byte array
    self.assert_packed_header(pack, ofp_type, len(o), xid)
    # now unpack
    unpacked = type(o)()
    unpacked.unpack(pack)
    self.assertEqual(o, unpacked, "pack_unpacked -- original != unpacked\n===Original:\n%s\n===Repacked:%s\n" % (show(o), show(unpacked)))
    return unpacked

  def test_header_pack_unpack(self):
    for kw in ( { "header_type": OFPT_PACKET_OUT, "xid": 1 },
                { "header_type": OFPT_FLOW_MOD, "xid": 2 }):
      # Can't directly pack a header, since it has no length...
      class H (ofp_header):
        def __len__ (self):
          return 8
      o = H(**kw)
      self._test_pack_unpack(o, kw["xid"], kw["header_type"])

  def test_pack_all_comands_simple(self):
    xid_gen = xid_generator()
    for cls in ( ofp_features_reply,
                   ofp_set_config,
                   ofp_get_config_reply,
                   ofp_flow_mod,
                   ofp_port_mod,
                   ofp_queue_get_config_request,
                   ofp_queue_get_config_reply,
                   ofp_stats_request,
                   ofp_stats_reply,
                   ofp_packet_out,
                   ofp_barrier_reply,
                   ofp_barrier_request,
                   ofp_packet_in,
                   ofp_flow_removed,
                   ofp_port_status,
                   ofp_error,
                   ofp_hello,
                   ofp_echo_request,
                   ofp_echo_reply,
                   ofp_features_request,
                   ofp_get_config_request,
                   ofp_get_config_reply,
                   ofp_set_config ):
      xid = xid_gen()
      args = {}

      # Customize initializer
      if cls is ofp_stats_reply:
        args['body'] = ofp_desc_stats(sw_desc="POX")
      elif cls is ofp_stats_request:
        args['body'] = ofp_vendor_stats_generic(vendor=0xcafe)

      o = cls(xid=xid, **args)
      self._test_pack_unpack(o, xid)

  out = ofp_action_output
  dl_addr = ofp_action_dl_addr
  some_actions = ([], [out(port=2)], [out(port=2), out(port=3)], [ out(port=OFPP_FLOOD) ], [ dl_addr.set_dst(EthAddr("00:"*5 + "01")), out(port=1) ])


  def test_pack_custom_packet_out(self):
    xid_gen = xid_generator()
    packet = ethernet(src=EthAddr("00:00:00:00:00:01"), dst=EthAddr("00:00:00:00:00:02"),
            payload=ipv4(srcip=IPAddr("1.2.3.4"), dstip=IPAddr("1.2.3.5"),
                payload=udp(srcport=1234, dstport=53, payload="haha"))).pack()

    for actions in self.some_actions:
      for attrs in ( { 'data': packet }, { 'buffer_id': 5 } ):
        xid = xid_gen()
        o = ofp_packet_out(xid=xid, actions=actions, **attrs)
        self._test_pack_unpack(o, xid, OFPT_PACKET_OUT)

  def test_pack_flow_mod_openflow_dl_type_wildcards(self):
    """ Openflow 1.1 spec clarifies that wildcards should not be set when the protocol in
        question is not matched i.e., dl_type != 0x800 -> no wildcards for IP.
        Test this here """
    def show_wildcards(w):
      parts = [ k.lower()[len("OFPFW_"):] for (k,v) in ofp_flow_wildcards_rev_map.iteritems() if v & w == v ]
      nw_src_bits = (w & OFPFW_NW_SRC_MASK) >> OFPFW_NW_SRC_SHIFT
      nw_src_bits = (w & OFPFW_NW_SRC_MASK) >> OFPFW_NW_SRC_SHIFT
      if(nw_src_bits > 0): parts.append("nw_src(/%d)" % (32 - nw_src_bits))

      nw_dst_bits = (w & OFPFW_NW_DST_MASK) >> OFPFW_NW_DST_SHIFT
      if(nw_dst_bits > 0): parts.append("nw_dst(/%d)" % (32 - nw_dst_bits))
      return "|".join(parts)

    def test_wildcards(match, expected):
      (packed,) = struct.unpack_from("!L", match.pack(flow_mod=True))
      self.assertEquals(packed, expected, "packed: %s <> expected: %s" % (show_wildcards(packed), show_wildcards(expected)))

    # no dl type specified -> wildcards for nw/dl are cleared
    test_wildcards(ofp_match(), OFPFW_ALL & ~ (OFPFW_NW_TOS | OFPFW_NW_PROTO | OFPFW_NW_SRC_MASK | OFPFW_NW_DST_MASK | OFPFW_TP_SRC | OFPFW_TP_DST))
    all_normalized = (OFPFW_ALL & ~ (OFPFW_NW_SRC_MASK | OFPFW_NW_DST_MASK)) | \
            OFPFW_NW_SRC_ALL | OFPFW_NW_DST_ALL

    # dl type = ARP -> certain wildcards live
    test_wildcards(ofp_match(dl_type=0x806), all_normalized & ~ (OFPFW_NW_TOS | OFPFW_TP_SRC | OFPFW_TP_DST | OFPFW_DL_TYPE))
    # dl type = IP -> more wildcards live
    test_wildcards(ofp_match(dl_type=0x800), all_normalized & ~ (OFPFW_TP_SRC | OFPFW_TP_DST | OFPFW_DL_TYPE))
    # dl type = IP, nw_proto=UDP -> alll wildcards live
    test_wildcards(ofp_match(dl_type=0x800,nw_proto=6), all_normalized & ~(OFPFW_DL_TYPE | OFPFW_NW_PROTO))


  def test_pack_custom_flow_mod(self):
    out = ofp_action_output
    xid_gen = xid_generator()

    for match in ( ofp_match(),
        ofp_match(in_port=1, dl_type=0x88cc, dl_src=EthAddr("00:00:00:00:00:01"), dl_dst=EthAddr("00:00:00:00:00:02")),
        ofp_match(in_port=1, dl_type=0x0806, dl_src=EthAddr("00:00:00:00:00:01"), dl_dst=EthAddr("00:00:00:00:00:02"), nw_src="10.0.0.1", nw_dst="11.0.0.1"),
        ofp_match(in_port=1, dl_type=0x0800, dl_src=EthAddr("00:00:00:00:00:01"), dl_dst=EthAddr("00:00:00:00:00:02"), dl_vlan=5, nw_proto=6, nw_src="10.0.0.1", nw_dst="11.0.0.1", tp_src = 12345, tp_dst=80)):
      for actions in self.some_actions:
        for command in ( OFPFC_ADD, OFPFC_DELETE, OFPFC_DELETE_STRICT, OFPFC_MODIFY_STRICT, OFPFC_MODIFY_STRICT ):
          for attrs in ( {}, { 'buffer_id' : 123 }, { 'idle_timeout': 5, 'hard_timeout': 10 } ):
            xid = xid_gen()
            o = ofp_flow_mod(xid=xid, command=command, match = match, actions=actions, **attrs)
            unpacked = self._test_pack_unpack(o, xid, OFPT_FLOW_MOD)

            self.assertEqual(unpacked.match, match)
            self.assertEqual(unpacked.command, command)
            self.assertEqual(unpacked.actions, actions)
            for (check_attr,val) in attrs.iteritems():
              self.assertEqual(getattr(unpacked, check_attr), val)

class ofp_action_test(unittest.TestCase):
  def assert_packed_action(self, cls, packed, a_type, length):
    self.assertEqual(extract_num(packed, 0,2), a_type, "Action %s: expected type %d (but is %d)" % (cls, a_type, extract_num(packed, 0,2)))
    self.assertEqual(extract_num(packed, 2,2), length, "Action %s: expected length %d (but is %d)" % (cls, length, extract_num(packed, 2,2)))

  def test_pack_all_actions_simple(self):
    def c(cls, a_type, kw, length):
      action = cls(**kw)
      packed = action.pack()
      self.assertEqual(len(action), len(packed))
      self.assert_packed_action(cls, packed, a_type, length)
      unpacked = cls()
      unpacked.unpack(packed)
      self.assertEqual(action, unpacked)
      for (k, v) in kw.iteritems():
        self.assertEqual(getattr(unpacked, k), v)
      return packed


    c(ofp_action_output, OFPAT_OUTPUT, { 'port': 23 }, 8 )
    c(ofp_action_enqueue, OFPAT_ENQUEUE, { 'port': 23, 'queue_id': 1 }, 16 )
    c(ofp_action_vlan_vid, OFPAT_SET_VLAN_VID, { 'vlan_vid' : 123}, 8 )
    c(ofp_action_vlan_pcp, OFPAT_SET_VLAN_PCP, { 'vlan_pcp' : 123}, 8 )
    p = c(ofp_action_dl_addr.set_dst, OFPAT_SET_DL_DST, { 'dl_addr' : EthAddr("01:02:03:04:05:06").toRaw() }, 16 )
    self.assertEquals(extract_num(p, 4,6), 0x010203040506)
    p = c(ofp_action_dl_addr.set_src, OFPAT_SET_DL_SRC, { 'dl_addr' : EthAddr("ff:ee:dd:cc:bb:aa").toRaw() }, 16 )
    self.assertEquals(extract_num(p, 4,6), 0xffeeddccbbaa, "Ethernet in packed is %x, but should be ff:ee:dd:cc:bb:aa" % extract_num(p, 4, 6))
    p = c(ofp_action_nw_addr.set_dst, OFPAT_SET_NW_DST, { 'nw_addr' : IPAddr("1.2.3.4") }, 8 )
    self.assertEquals(extract_num(p, 4,4), 0x01020304)
    p = c(ofp_action_nw_addr.set_src, OFPAT_SET_NW_SRC, { 'nw_addr' : IPAddr("127.0.0.1") }, 8 )
    self.assertEquals(extract_num(p, 4,4), 0x7f000001)
    c(ofp_action_nw_tos, OFPAT_SET_NW_TOS, { 'nw_tos' : 4 }, 8)
    p = c(ofp_action_tp_port.set_dst, OFPAT_SET_TP_DST, { 'tp_port' : 80 }, 8)
    self.assertEquals(extract_num(p, 4,2), 80)
    p = c(ofp_action_tp_port.set_src, OFPAT_SET_TP_SRC, { 'tp_port' : 22987 }, 8)
    self.assertEquals(extract_num(p, 4,2), 22987)
#    c(ofp_action_push_mpls, OFPAT_PUSH_MPLS, {'ethertype':0x8847}, 8)
#    c(ofp_action_pop_mpls, OFPAT_POP_MPLS, {'ethertype':0x0800}, 8)
#    c(ofp_action_mpls_dec_ttl, OFPAT_DEC_MPLS_TTL, {}, 8)
#    c(ofp_action_mpls_label, OFPAT_SET_MPLS_LABEL, {'mpls_label': 0xa1f}, 8)
#    c(ofp_action_mpls_tc, OFPAT_SET_MPLS_TC, {'mpls_tc': 0xac}, 8)
#    c(ofp_action_mpls_ttl, OFPAT_SET_MPLS_TTL, {'mpls_ttl': 0xaf}, 8)

if __name__ == '__main__':
  unittest.main()

########NEW FILE########
__FILENAME__ = nicira_test
# Copyright 2011-2013 James McCauley
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at:
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import unittest
import sys
import os.path
sys.path.append(os.path.dirname(__file__) + "/../../..")

import pox.openflow.nicira as nx
from pox.lib.addresses import EthAddr, IPAddr
import pox.openflow.libopenflow_01 as of

class basics_test (unittest.TestCase):
  """
  Do some tests on the Nicira extensions

  This isn't totally comprehensive (that is, we don't currently try every
  combination of masked/unmasked, etc.  But it should serve as a basic
  sanity test.
  """
  longMessage = True

  # Add an _init_action_XXXX method to override action creation
  # (otherwise they're initialized with no arguments).
  def _init_action_nx_reg_move (self, cls):
    return cls(dst=nx.NXM_NX_REG1,src=nx.NXM_NX_REG2,nbits=3,src_ofs=2)

  def _init_action_nx_reg_load (self, cls):
    return cls(dst=nx.NXM_NX_REG3,value=42,nbits=16)

  def _init_action_nx_output_reg (self, cls):
    return cls(reg=nx.NXM_NX_TUN_ID,nbits=16)

  def _init_action_nx_action_resubmit (self, cls):
    # Use a factory method
    return cls.resubmit_table()

  def _init_action_nx_action_set_tunnel (self, cls):
    return cls(tun_id=101)

  def _init_action_nx_action_set_tunnel64 (self, cls):
    return cls(tun_id=101)

  def _init_action_nx_action_learn (self, cls):
    learn = self._make_learn_action()
    assert type(learn)==cls
    return learn

  def _init_action_nx_action_pop_mpls (self, cls):
    return cls(ethertype=101)


  def test_unpack_weird_header (self):
    """
    Test the unpacking of a header we don't have a class for
    """
    # Make a weird header...
    class nxm_weird (nx._nxm_maskable, nx._nxm_numeric_entry):
      _nxm_type = nx._make_type(0xdead,0x42)
      _nxm_length = 4
    original = nx.nx_reg_load(dst=nxm_weird,value=42,nbits=32)

    original_packed = original.pack()

    # Currently, the action unpacking API still sucks...
    unoriginal = nx.nx_reg_load()
    offset = unoriginal.unpack(original_packed, 0)
    self.assertEqual(offset, len(original_packed),
                     "Didn't unpack entire entry")
    unoriginal_packed = unoriginal.pack()

    self.assertEqual(unoriginal.dst.__name__, "NXM_UNKNOWN_dead_42",
                     "Didn't generate new class correctly?")

    self.assertEqual(original_packed, unoriginal_packed, "Pack/Unpack failed")


  def test_action_pack_unpack (self):
    """
    Pack and unpack a bunch of actions
    """
    for name in dir(nx):
      a = getattr(nx, name)
      if not nx._issubclass(a, of.ofp_action_vendor_base): continue
      print "Trying",name,"...",
      init = getattr(self, "_init_action_" + name, lambda c: c())
      original = init(a)
      original_packed = original.pack()
      #print len(original_packed)

      # Currently, the action unpacking API still sucks...
      unoriginal = a()
      offset = unoriginal.unpack(original_packed, 0)
      self.assertEqual(offset, len(original_packed),
                       "Didn't unpack entire entry " + name)
      unoriginal_packed = unoriginal.pack()

      self.assertEqual(original, unoriginal,
                       "Pack/Unpack failed for " + name)
      print "Success!"


  def test_nxm_ip (self):
    """
    Test the check for nonzero bits of a masked entry
    """
    def try_bad ():
      e = nx.NXM_OF_IP_SRC(IPAddr("192.168.56.1"),IPAddr("255.255.255.0"))
      e.pack()
    self.assertRaisesRegexp(AssertionError, '^nonzero masked bits$', 
        try_bad)


  def _make_learn_action (self):
    fms = nx.flow_mod_spec.new
    learn = nx.nx_action_learn(table_id=1,hard_timeout=10)
    learn.spec.append(fms( field=nx.NXM_OF_VLAN_TCI, n_bits=12 ))
    learn.spec.append(fms( field=nx.NXM_OF_ETH_SRC, match=nx.NXM_OF_ETH_DST ))
    learn.spec.append(fms( field=nx.NXM_OF_IN_PORT, output=True ))

    #learn.spec = [
    #    nx.flow_mod_spec(src=nx.nx_learn_src_field(nx.NXM_OF_VLAN_TCI),
    #                     n_bits=12),
    #    nx.flow_mod_spec(src=nx.nx_learn_src_field(nx.NXM_OF_ETH_SRC),
    #                     dst=nx.nx_learn_dst_match(nx.NXM_OF_ETH_DST)),
    #    nx.flow_mod_spec(src=nx.nx_learn_src_field(nx.NXM_OF_IN_PORT),
    #                     dst=nx.nx_learn_dst_output())
    #]

    #learn.spec.chain(
    #  field=nx.NXM_OF_VLAN_TCI, n_bits=12).chain(
    #  field=nx.NXM_OF_ETH_SRC, match=nx.NXM_OF_ETH_DST).chain(
    #  field=nx.NXM_OF_IN_PORT, output=True)

    return learn


  def test_flow_mod_spec (self):
    """
    Check flow_mod_specs are correct

    Not comprehensive.
    """
    learn = self._make_learn_action()
    good = """00 0c 00 00 08 02 00 00  00 00 08 02 00 00
              00 30 00 00 04 06 00 00  00 00 02 06 00 00
              10 10 00 00 00 02 00 00""".split()
    good = ''.join([chr(int(x,16)) for x in good])
    self.assertEqual(good, ''.join(x.pack() for x in learn.spec))


  def test_match_pack_unpack (self):
    """
    Pack and unpack a bunch of match entries
    """

    # Note that this does not currently really take into account constraints
    # on masks (e.g., EthAddr masks only having broadcast bit).

    for nxm_name,nxm_type in nx._nxm_name_to_type.items():
      nxm_class = nx._nxm_type_to_class[nxm_type]
      mask = None

      #print nxm_name

      # If more exotic nxm types are added (e.g., with different types for
      # values and masks), we'll need to add additional if statements here...
      if issubclass(nxm_class, nx._nxm_numeric_entry):
        value = 0x0a
        mask  = 0x0f
      elif issubclass(nxm_class, nx._nxm_raw):
        value = 'aabb'
        # Currently never check mask for raw
      elif issubclass(nxm_class, nx._nxm_ipv6):
        import pox.lib.addresses as addresses
        #self.assertFalse('IPAddr6' in dir(addresses), 'IPv6 is available, '
        #                 'so this test needs to be fixed.')
        value = 'ff02::/126'
      elif issubclass(nxm_class, nx._nxm_ip):
        value = IPAddr('192.168.56.0')
        mask  = IPAddr('255.255.255.0')
      elif issubclass(nxm_class, nx._nxm_ether):
        value = EthAddr('01:02:03:04:05:06')
        # Currently never check mask for ether
      else:
        self.fail("Unsupported NXM type for " + nxm_name)

      if not issubclass(nxm_class, nx._nxm_maskable):
        mask = None

      original = nxm_class(value, mask)
      original_packed = original.pack()

      offset,unoriginal = nx.nxm_entry.unpack_new(original_packed, 0)
      self.assertEqual(offset, len(original_packed),
                       "Didn't unpack entire entry " + nxm_name)
      unoriginal_packed = unoriginal.pack()

      self.assertEqual(original, unoriginal,
                       "Pack/Unpack failed for " + nxm_name)


if __name__ == '__main__':
  unittest.main()

########NEW FILE########
__FILENAME__ = topology_test
#!/usr/bin/env python
#
# Copyright 2011-2012 James McCauley
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at:
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""
OpenFlow stuff for topology
"""
import time

import unittest
import sys
import os.path
import itertools

sys.path.append(os.path.dirname(__file__) + "/../../..")
from pox.openflow.libopenflow_01 import *
#from pox.openflow.flow_table import *
from pox.openflow import *
from pox.openflow.topology import *

class MockSwitch(EventMixin):
  _eventMixin_events = [FlowRemoved, BarrierIn, SwitchConnectionUp, SwitchConnectionDown ]
  def __init__(self):
    EventMixin.__init__(self)
    self.connected = True
    self._xid_generator = itertools.count(1).next
    self.sent = []

  def send(self, msg):
    #print "Hey: %s" % msg
    self.sent.append(msg)

  @property
  def last(self):
    return self.sent[-1]

class MockConnection(EventMixin):
  def __init__(self):
    self.dpid =1


class OFSyncFlowTableTest(unittest.TestCase):
  def setUp(self):
    self.s = MockSwitch()
    self.conn = MockConnection()
    self.t = OFSyncFlowTable(self.s)

  def test_reconnect_pending(self):
    t = self.t
    s = self.s

    seen_ft_events = []
    t.addListener(FlowTableModification, lambda(event): seen_ft_events.append(event))

    entry = TableEntry(priority=5, cookie=0x31415926, match=ofp_match(dl_src=EthAddr("00:00:00:00:00:01")), actions=[ofp_action_output(port=5)])
    t.install(entry)

    # entry is pending
    self.assertEqual(t.num_pending, 1)
    self.assertEqual(len(t), 0)

    self.assertEqual(len(s.sent), 2)
    self.assertTrue(isinstance(s.sent[-2], ofp_flow_mod))
    self.assertTrue(isinstance(s.sent[-1], ofp_barrier_request))

    # oops switch disconnected
    s.raiseEvent(SwitchConnectionDown(s))
    # reconnect
    s.raiseEvent(SwitchConnectionUp(s, self.conn))

    # our guy should clear and reinstall the flows
    self.assertEqual(len(s.sent), 6)
    self.assertTrue(isinstance(s.sent[-4], ofp_flow_mod) and s.sent[-4].command == OFPFC_DELETE and s.sent[-4].match == ofp_match())
    self.assertTrue(isinstance(s.sent[-3], ofp_barrier_request))
    self.assertTrue(isinstance(s.sent[-2], ofp_flow_mod) and s.sent[-2].command == OFPFC_ADD and s.sent[-2].match == entry.match)
    self.assertTrue(isinstance(s.sent[-1], ofp_barrier_request))

  def test_install_remove(self):
    t = self.t
    s = self.s

    seen_ft_events = []
    t.addListener(FlowTableModification, lambda(event): seen_ft_events.append(event))

    entry = TableEntry(priority=5, cookie=0x31415926, match=ofp_match(dl_src=EthAddr("00:00:00:00:00:01")), actions=[ofp_action_output(port=5)])
    t.install(entry)

    # entry is pending
    self.assertEqual(t.num_pending, 1)
    self.assertEqual(len(t), 0)
    self.assertEqual(len(s.sent), 2)
    self.assertTrue(isinstance(s.sent[-2], ofp_flow_mod))
    self.assertTrue(isinstance(s.sent[-1], ofp_barrier_request))
    self.assertEqual(len(seen_ft_events), 0)

    # send a barrier in -> now entry should be installed
    s.raiseEvent(BarrierIn(self.conn, ofp_barrier_reply(xid=s.sent[-1].xid)))
    self.assertEqual(len(t), 1)
    self.assertEqual(t.entries[0], entry)
    self.assertEqual(t.num_pending, 0)
    self.assertEqual(len(seen_ft_events), 1)
    self.assertTrue(isinstance(seen_ft_events[0], FlowTableModification) and seen_ft_events[-1].added == [entry])

    # schedule for removal
    t.remove_strict(entry)
    self.assertEqual(len(t), 1)
    self.assertEqual(t.entries[0], entry)
    self.assertEqual(t.num_pending, 1)
    self.assertTrue(isinstance(s.sent[-2], ofp_flow_mod) and s.sent[-2].command == OFPFC_DELETE_STRICT)
    self.assertTrue(isinstance(s.sent[-1], ofp_barrier_request))

    # send a barrier in -> now entry should be removed
    s.raiseEvent(BarrierIn(self.conn, ofp_barrier_reply(xid=s.sent[-1].xid)))
    self.assertEqual(len(t), 0)
    self.assertEqual(t.num_pending, 0)
    self.assertEqual(len(seen_ft_events), 2)
    self.assertTrue(isinstance(seen_ft_events[-1], FlowTableModification) and seen_ft_events[-1].removed == [entry])

  def test_handle_FlowRemoved(self):
    """ test that simple removal of a flow works"""
    t = self.t
    t.flow_table.add_entry(TableEntry(priority=5, cookie=0x31415926, match=ofp_match(dl_src=EthAddr("00:00:00:00:00:01")), actions=[ofp_action_output(port=5)]))
    t.flow_table.add_entry(TableEntry(priority=5, cookie=0x31415927, match=ofp_match(dl_src=EthAddr("00:00:00:00:00:02")), actions=[ofp_action_output(port=6)]))
    self.assertEqual(len(t), 2)
    # remove the first flow
    t._handle_FlowRemoved(FlowRemoved(self.conn, ofp_flow_removed(priority=5, cookie=0x31415926, match=ofp_match(dl_src=EthAddr("00:00:00:00:00:01")))))
    self.assertEqual(len(t), 1)
    self.assertEqual(t.entries[0].cookie, 0x31415927)
    # removing a non-matching-flow => NOOP
    for non_matching in [
        { 'cookie': 0x31415926, 'match':ofp_match(dl_src=EthAddr("00:00:00:00:00:01")) }, # already gone
        { 'cookie': 0x31415928, 'match':ofp_match(dl_src=EthAddr("00:00:00:00:00:02")) }, # cookie doesn't fit
        { 'cookie': 0x31415927, 'match':ofp_match(dl_src=EthAddr("00:00:00:00:00:02"), nw_src=IPAddr("1.2.3.4")) }, # extra match field
        ]:
      t._handle_FlowRemoved(FlowRemoved(self.conn, ofp_flow_removed(**non_matching)))
      self.assertEqual(len(t), 1)
      self.assertEqual(t.entries[0].cookie, 0x31415927)


if __name__ == '__main__':
  unittest.main()



########NEW FILE########
__FILENAME__ = pox-log
#!/usr/bin/env python

# Copyright 2011,2013 James McCauley
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at:
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""
Display POX logs remotely

Connects to the POX messenger bus via TCP, and listens to a log channel.

Requires the messenger, messenger.tcp_transport, and messenger.log_service
components to be running.
"""

import json
import sys
import socket
import argparse
#from pox.messenger.test_client import JSONDestreamer

import uuid
uniq = str(uuid.uuid4())
mychannel = 'log_' + str(uuid.uuid4())



parser = argparse.ArgumentParser(description='Connect to the POX log service')
parser.add_argument('loggers', metavar='loggers', nargs='*',
                   help='loggers to listen to (logger[=level])')
parser.add_argument('--level', dest='default_level', default='INFO',
                    help="Default log level")
parser.add_argument('--address', dest='address', default='127.0.0.1',
                    help="Messenger service address")
parser.add_argument('--port', dest='port', default='7790', type=int,
                    help="Messenger service port")

args = parser.parse_args()

host = args.address
port = args.port


class JSONDestreamer (object):
  import json
  decoder = json.JSONDecoder()
  def __init__ (self, callback = None):
    self._buf = ''
    self.callback = callback if callback else self.rx

  def push (self, data):
    if len(self._buf) == 0:
      data = data.lstrip()
    self._buf += data
    try:
      while len(self._buf) > 0:
        r,off = self.decoder.raw_decode(self._buf)

        self._buf = self._buf[off:].lstrip()
        self.callback(r)
    except ValueError:
      pass


class LogJSONDestreamer (JSONDestreamer):
  def rx (self, data):
    if data.get('CHANNEL') != mychannel: return

    print "%s|%s|%s" % (data['levelname'], data['name'], data['message'])


jd = LogJSONDestreamer()

while True:
  try:
    sock = socket.socket()
    sock.connect((host,port))
    print >>sys.stderr, "== Connected =="
    msg = {
        'CHANNEL' : '',
        'cmd' : 'join_channel',
        'channel' : mychannel,
        'json' : True,
    }
    sock.send(json.dumps(msg))
    msg = {
        'CHANNEL' : mychannel,
        'setLevels' : {"":args.default_level},
    }
    for logger_name in args.loggers:
      logger_name = logger_name.split("=")
      if len(logger_name) == 1:
        logger_name = logger_name[0]
        level = args.default_level
      else:
        logger_name,level = logger_name
      level = level.upper()
      msg['setLevels'][logger_name] = level
    sock.send(json.dumps(msg))

    try:
      while True:
        d = sock.recv(1024)
        if len(d) == 0: raise RuntimeError()
        jd.push(d)
    except KeyboardInterrupt:
      break
    except RuntimeError as e:
      print >>sys.stderr, "== Disconnected =="
      try:
        sock.close()
      except:
        pass
  except KeyboardInterrupt:
    break
  except:
    pass

########NEW FILE########
__FILENAME__ = pox-pydoc
#! /usr/bin/python2.7
# -*- coding: latin-1 -*-
"""Generate Python documentation in HTML or text for interactive use.

In the Python interpreter, do "from pydoc import help" to provide online
help.  Calling help(thing) on a Python object documents the object.

Or, at the shell command line outside of Python:

Run "pydoc <name>" to show documentation on something.  <name> may be
the name of a function, module, package, or a dotted reference to a
class or function within a module or module in a package.  If the
argument contains a path segment delimiter (e.g. slash on Unix,
backslash on Windows) it is treated as the path to a Python source file.

Run "pydoc -k <keyword>" to search for a keyword in the synopsis lines
of all available modules.

Run "pydoc -p <port>" to start an HTTP server on a given port on the
local machine to generate documentation web pages.

For platforms without a command line, "pydoc -g" starts the HTTP server
and also pops up a little window for controlling it.

Run "pydoc -w <name>" to write out the HTML documentation for a module
to a file named "<name>.html".

Module docs for core modules are assumed to be in

    http://docs.python.org/library/

This can be overridden by setting the PYTHONDOCS environment variable
to a different URL or to a local directory containing the Library
Reference Manual pages.
"""

__author__ = "Ka-Ping Yee <ping@lfw.org>"
__date__ = "26 February 2001"

__version__ = "$Revision: 84174 $"
__credits__ = """Guido van Rossum, for an excellent programming language.
Tommy Burnette, the original creator of manpy.
Paul Prescod, for all his work on onlinehelp.
Richard Chamberlain, for the first implementation of textdoc.
"""

import sys
sys.path.append('..')

# Known bugs that can't be fixed here:
#   - imp.load_module() cannot be prevented from clobbering existing
#     loaded modules, so calling synopsis() on a binary module file
#     changes the contents of any existing module with the same name.
#   - If the __file__ attribute on a module is a relative path and
#     the current directory is changed with os.chdir(), an incorrect
#     path will be displayed.

import sys, imp, os, re, types, inspect, __builtin__, pkgutil
from repr import Repr
from string import expandtabs, find, join, lower, split, strip, rfind, rstrip
from traceback import extract_tb
try:
    from collections import deque
except ImportError:
    # Python 2.3 compatibility
    class deque(list):
        def popleft(self):
            return self.pop(0)

# --------------------------------------------------------- common routines

def pathdirs():
    """Convert sys.path into a list of absolute, existing, unique paths."""
    dirs = []
    normdirs = []
    for dir in sys.path:
        dir = os.path.abspath(dir or '.')
        normdir = os.path.normcase(dir)
        if normdir not in normdirs and os.path.isdir(dir):
            dirs.append(dir)
            normdirs.append(normdir)
    return dirs

def getdoc(object):
    """Get the doc string or comments for an object."""
    result = inspect.getdoc(object) or inspect.getcomments(object)
    return result and re.sub('^ *\n', '', rstrip(result)) or ''

def splitdoc(doc):
    """Split a doc string into a synopsis line (if any) and the rest."""
    lines = split(strip(doc), '\n')
    if len(lines) == 1:
        return lines[0], ''
    elif len(lines) >= 2 and not rstrip(lines[1]):
        return lines[0], join(lines[2:], '\n')
    return '', join(lines, '\n')

def classname(object, modname):
    """Get a class name and qualify it with a module name if necessary."""
    name = object.__name__
    if object.__module__ != modname:
        name = object.__module__ + '.' + name
    return name

def isdata(object):
    """Check if an object is of a type that probably means it's data."""
    return not (inspect.ismodule(object) or inspect.isclass(object) or
                inspect.isroutine(object) or inspect.isframe(object) or
                inspect.istraceback(object) or inspect.iscode(object))

def replace(text, *pairs):
    """Do a series of global replacements on a string."""
    while pairs:
        text = join(split(text, pairs[0]), pairs[1])
        pairs = pairs[2:]
    return text

def cram(text, maxlen):
    """Omit part of a string if needed to make it fit in a maximum length."""
    if len(text) > maxlen:
        pre = max(0, (maxlen-3)//2)
        post = max(0, maxlen-3-pre)
        return text[:pre] + '...' + text[len(text)-post:]
    return text

_re_stripid = re.compile(r' at 0x[0-9a-f]{6,16}(>+)$', re.IGNORECASE)
def stripid(text):
    """Remove the hexadecimal id from a Python object representation."""
    # The behaviour of %p is implementation-dependent in terms of case.
    return _re_stripid.sub(r'\1', text)

def _is_some_method(obj):
    return inspect.ismethod(obj) or inspect.ismethoddescriptor(obj)

def allmethods(cl):
    methods = {}
    for key, value in inspect.getmembers(cl, _is_some_method):
        methods[key] = 1
    for base in cl.__bases__:
        methods.update(allmethods(base)) # all your base are belong to us
    for key in methods.keys():
        methods[key] = getattr(cl, key)
    return methods

def _split_list(s, predicate):
    """Split sequence s via predicate, and return pair ([true], [false]).

    The return value is a 2-tuple of lists,
        ([x for x in s if predicate(x)],
         [x for x in s if not predicate(x)])
    """

    yes = []
    no = []
    for x in s:
        if predicate(x):
            yes.append(x)
        else:
            no.append(x)
    return yes, no

def visiblename(name, all=None):
    """Decide whether to show documentation on a variable."""
    # Certain special names are redundant.
    _hidden_names = ('__builtins__', '__doc__', '__file__', '__path__',
                     '__module__', '__name__', '__slots__', '__package__',
                     '__dict__', '__weakref__')
    if name in _hidden_names: return 0
    # Private names are hidden, but special names are displayed.
    if name.startswith('__') and name.endswith('__'): return 1
    if all is not None:
        # only document that which the programmer exported in __all__
        return name in all
    elif name.startswith('_handle_'):
        return 1
    else:
        return not name.startswith('_')

def classify_class_attrs(object):
    """Wrap inspect.classify_class_attrs, with fixup for data descriptors."""
    def fixup(data):
        name, kind, cls, value = data
        if inspect.isdatadescriptor(value):
            kind = 'data descriptor'
        return name, kind, cls, value
    return map(fixup, inspect.classify_class_attrs(object))

# ----------------------------------------------------- module manipulation

def ispackage(path):
    """Guess whether a path refers to a package directory."""
    if os.path.isdir(path):
        for ext in ('.py', '.pyc', '.pyo'):
            if os.path.isfile(os.path.join(path, '__init__' + ext)):
                return True
    return False

def source_synopsis(file):
    line = file.readline()
    while line[:1] == '#' or not strip(line):
        line = file.readline()
        if not line: break
    line = strip(line)
    if line[:4] == 'r"""': line = line[1:]
    if line[:3] == '"""':
        line = line[3:]
        if line[-1:] == '\\': line = line[:-1]
        while not strip(line):
            line = file.readline()
            if not line: break
        result = strip(split(line, '"""')[0])
    else: result = None
    return result

def synopsis(filename, cache={}):
    """Get the one-line summary out of a module file."""
    mtime = os.stat(filename).st_mtime
    lastupdate, result = cache.get(filename, (0, None))
    if lastupdate < mtime:
        info = inspect.getmoduleinfo(filename)
        try:
            file = open(filename)
        except IOError:
            # module can't be opened, so skip it
            return None
        if info and 'b' in info[2]: # binary modules have to be imported
            try: module = imp.load_module('__temp__', file, filename, info[1:])
            except: return None
            result = (module.__doc__ or '').splitlines()[0]
            del sys.modules['__temp__']
        else: # text modules can be directly examined
            result = source_synopsis(file)
            file.close()
        cache[filename] = (mtime, result)
    return result

class ErrorDuringImport(Exception):
    """Errors that occurred while trying to import something to document it."""
    def __init__(self, filename, exc_info):
        exc, value, tb = exc_info
        self.filename = filename
        self.exc = exc
        self.value = value
        self.tb = tb

    def __str__(self):
        exc = self.exc
        if type(exc) is types.ClassType:
            exc = exc.__name__
        return 'problem in %s - %s: %s' % (self.filename, exc, self.value)

def importfile(path):
    """Import a Python source file or compiled file given its path."""
    magic = imp.get_magic()
    file = open(path, 'r')
    if file.read(len(magic)) == magic:
        kind = imp.PY_COMPILED
    else:
        kind = imp.PY_SOURCE
    file.close()
    filename = os.path.basename(path)
    name, ext = os.path.splitext(filename)
    file = open(path, 'r')
    try:
        module = imp.load_module(name, file, path, (ext, 'r', kind))
    except:
        raise ErrorDuringImport(path, sys.exc_info())
    file.close()
    return module

def safeimport(path, forceload=0, cache={}):
    """Import a module; handle errors; return None if the module isn't found.

    If the module *is* found but an exception occurs, it's wrapped in an
    ErrorDuringImport exception and reraised.  Unlike __import__, if a
    package path is specified, the module at the end of the path is returned,
    not the package at the beginning.  If the optional 'forceload' argument
    is 1, we reload the module from disk (unless it's a dynamic extension)."""
    try:
        # If forceload is 1 and the module has been previously loaded from
        # disk, we always have to reload the module.  Checking the file's
        # mtime isn't good enough (e.g. the module could contain a class
        # that inherits from another module that has changed).
        if forceload and path in sys.modules:
            if path not in sys.builtin_module_names:
                # Avoid simply calling reload() because it leaves names in
                # the currently loaded module lying around if they're not
                # defined in the new source file.  Instead, remove the
                # module from sys.modules and re-import.  Also remove any
                # submodules because they won't appear in the newly loaded
                # module's namespace if they're already in sys.modules.
                subs = [m for m in sys.modules if m.startswith(path + '.')]
                for key in [path] + subs:
                    # Prevent garbage collection.
                    cache[key] = sys.modules[key]
                    del sys.modules[key]
        module = __import__(path)
    except:
        # Did the error occur before or after the module was found?
        (exc, value, tb) = info = sys.exc_info()
        if path in sys.modules:
            # An error occurred while executing the imported module.
            raise ErrorDuringImport(sys.modules[path].__file__, info)
        elif exc is SyntaxError:
            # A SyntaxError occurred before we could execute the module.
            raise ErrorDuringImport(value.filename, info)
        elif exc is ImportError and extract_tb(tb)[-1][2]=='safeimport':
            # The import error occurred directly in this function,
            # which means there is no such module in the path.
            return None
        else:
            # Some other error occurred during the importing process.
            raise ErrorDuringImport(path, sys.exc_info())
    for part in split(path, '.')[1:]:
        try: module = getattr(module, part)
        except AttributeError: return None
    return module

# ---------------------------------------------------- formatter base class

class Doc:
    def document(self, object, name=None, *args):
        """Generate documentation for an object."""
        args = (object, name) + args
        # 'try' clause is to attempt to handle the possibility that inspect
        # identifies something in a way that pydoc itself has issues handling;
        # think 'super' and how it is a descriptor (which raises the exception
        # by lacking a __name__ attribute) and an instance.
        if inspect.isgetsetdescriptor(object): return self.docdata(*args)
        if inspect.ismemberdescriptor(object): return self.docdata(*args)
        try:
            if inspect.ismodule(object): return self.docmodule(*args)
            if inspect.isclass(object): return self.docclass(*args)
            if inspect.isroutine(object): return self.docroutine(*args)
        except AttributeError:
            pass
        if isinstance(object, property): return self.docproperty(*args)
        return self.docother(*args)

    def fail(self, object, name=None, *args):
        """Raise an exception for unimplemented types."""
        message = "don't know how to document object%s of type %s" % (
            name and ' ' + repr(name), type(object).__name__)
        raise TypeError, message

    docmodule = docclass = docroutine = docother = docproperty = docdata = fail

    def getdocloc(self, object):
        """Return the location of module docs or None"""

        try:
            file = inspect.getabsfile(object)
        except TypeError:
            file = '(built-in)'

        docloc = os.environ.get("PYTHONDOCS",
                                "http://docs.python.org/library")
        basedir = os.path.join(sys.exec_prefix, "lib",
                               "python"+sys.version[0:3])
        if (isinstance(object, type(os)) and
            (object.__name__ in ('errno', 'exceptions', 'gc', 'imp',
                                 'marshal', 'posix', 'signal', 'sys',
                                 'thread', 'zipimport') or
             (file.startswith(basedir) and
              not file.startswith(os.path.join(basedir, 'site-packages')))) and
            object.__name__ not in ('xml.etree', 'test.pydoc_mod')):
            if docloc.startswith("http://"):
                docloc = "%s/%s" % (docloc.rstrip("/"), object.__name__)
            else:
                docloc = os.path.join(docloc, object.__name__ + ".html")
        else:
            docloc = None
        return docloc

# -------------------------------------------- HTML documentation generator

class HTMLRepr(Repr):
    """Class for safely making an HTML representation of a Python object."""
    def __init__(self):
        Repr.__init__(self)
        self.maxlist = self.maxtuple = 20
        self.maxdict = 10
        self.maxstring = self.maxother = 100

    def escape(self, text):
        return replace(text, '&', '&amp;', '<', '&lt;', '>', '&gt;')

    def repr(self, object):
        return Repr.repr(self, object)

    def repr1(self, x, level):
        if hasattr(type(x), '__name__'):
            methodname = 'repr_' + join(split(type(x).__name__), '_')
            if hasattr(self, methodname):
                return getattr(self, methodname)(x, level)
        return self.escape(cram(stripid(repr(x)), self.maxother))

    def repr_string(self, x, level):
        test = cram(x, self.maxstring)
        testrepr = repr(test)
        if '\\' in test and '\\' not in replace(testrepr, r'\\', ''):
            # Backslashes are only literal in the string and are never
            # needed to make any special characters, so show a raw string.
            return 'r' + testrepr[0] + self.escape(test) + testrepr[0]
        return re.sub(r'((\\[\\abfnrtv\'"]|\\[0-9]..|\\x..|\\u....)+)',
                      r'<font color="#c040c0">\1</font>',
                      self.escape(testrepr))

    repr_str = repr_string

    def repr_instance(self, x, level):
        try:
            return self.escape(cram(stripid(repr(x)), self.maxstring))
        except:
            return self.escape('<%s instance>' % x.__class__.__name__)

    repr_unicode = repr_string

class HTMLDoc(Doc):
    """Formatter class for HTML documentation."""

    # ------------------------------------------- HTML formatting utilities

    _repr_instance = HTMLRepr()
    repr = _repr_instance.repr
    escape = _repr_instance.escape

    def page(self, title, contents):
        """Format an HTML page."""
        return '''
<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN">
<html><head><title>Python: %s</title>
</head><body bgcolor="#f0f0f8">
%s
</body></html>''' % (title, contents)

    def heading(self, title, fgcol, bgcol, extras=''):
        """Format a page heading."""
        return '''
<table width="100%%" cellspacing=0 cellpadding=2 border=0 summary="heading">
<tr bgcolor="%s">
<td valign=bottom>&nbsp;<br>
<font color="%s" face="helvetica, arial">&nbsp;<br>%s</font></td
><td align=right valign=bottom
><font color="%s" face="helvetica, arial">%s</font></td></tr></table>
    ''' % (bgcol, fgcol, title, fgcol, extras or '&nbsp;')

    def section(self, title, fgcol, bgcol, contents, width=6,
                prelude='', marginalia=None, gap='&nbsp;'):
        """Format a section with a heading."""
        if marginalia is None:
            marginalia = '<tt>' + '&nbsp;' * width + '</tt>'
        result = '''<p>
<table width="100%%" cellspacing=0 cellpadding=2 border=0 summary="section">
<tr bgcolor="%s">
<td colspan=3 valign=bottom>&nbsp;<br>
<font color="%s" face="helvetica, arial">%s</font></td></tr>
    ''' % (bgcol, fgcol, title)
        if prelude:
            result = result + '''
<tr bgcolor="%s"><td rowspan=2>%s</td>
<td colspan=2>%s</td></tr>
<tr><td>%s</td>''' % (bgcol, marginalia, prelude, gap)
        else:
            result = result + '''
<tr><td bgcolor="%s">%s</td><td>%s</td>''' % (bgcol, marginalia, gap)

        return result + '\n<td width="100%%">%s</td></tr></table>' % contents

    def bigsection(self, title, *args):
        """Format a section with a big heading."""
        title = '<big><strong>%s</strong></big>' % title
        return self.section(title, *args)

    def preformat(self, text):
        """Format literal preformatted text."""
        text = self.escape(expandtabs(text))
        return replace(text, '\n\n', '\n \n', '\n\n', '\n \n',
                             ' ', '&nbsp;', '\n', '<br>\n')

    def multicolumn(self, list, format, cols=4):
        """Format a list of items into a multi-column list."""
        result = ''
        rows = (len(list)+cols-1)/cols
        for col in range(cols):
            result = result + '<td width="%d%%" valign=top>' % (100/cols)
            for i in range(rows*col, rows*col+rows):
                if i < len(list):
                    result = result + format(list[i]) + '<br>\n'
            result = result + '</td>'
        return '<table width="100%%" summary="list"><tr>%s</tr></table>' % result

    def grey(self, text): return '<font color="#909090">%s</font>' % text

    def namelink(self, name, *dicts):
        """Make a link for an identifier, given name-to-URL mappings."""
        for dict in dicts:
            if name in dict:
                return '<a href="%s">%s</a>' % (dict[name], name)
        return name

    def classlink(self, object, modname):
        """Make a link for a class."""
        name, module = object.__name__, sys.modules.get(object.__module__)
        if modname == '__builtin__': #MM
          return classname(object, object.__module__) #MM
        if hasattr(module, name) and getattr(module, name) is object:
            return '<a href="%s.html#%s">%s</a>' % (
                module.__name__, name, classname(object, modname))
        return classname(object, modname)

    def modulelink(self, object):
        """Make a link for a module."""
        return '<a href="%s.html">%s</a>' % (object.__name__, object.__name__)

    def modpkglink(self, data):
        """Make a link for a module or package to display in an index."""
        name, path, ispackage, shadowed = data
        if shadowed:
            return self.grey(name)
        if path:
            url = '%s.%s.html' % (path, name)
        else:
            url = '%s.html' % name
        if ispackage:
            text = '<strong>%s</strong>&nbsp;(package)' % name
        else:
            text = name
        return '<a href="%s">%s</a>' % (url, text)

    def markup(self, text, escape=None, funcs={}, classes={}, methods={}):
        """Mark up some plain text, given a context of symbols to look for.
        Each context dictionary maps object names to anchor names."""
        escape = escape or self.escape
        results = []
        here = 0
        pattern = re.compile(r'\b((http|ftp)://\S+[\w/]|'
                                r'RFC[- ]?(\d+)|'
                                r'PEP[- ]?(\d+)|'
                                r'(self\.)?(\w+))')
        while True:
            match = pattern.search(text, here)
            if not match: break
            start, end = match.span()
            results.append(escape(text[here:start]))

            all, scheme, rfc, pep, selfdot, name = match.groups()
            if scheme:
                url = escape(all).replace('"', '&quot;')
                results.append('<a href="%s">%s</a>' % (url, url))
            elif rfc:
                url = 'http://www.rfc-editor.org/rfc/rfc%d.txt' % int(rfc)
                results.append('<a href="%s">%s</a>' % (url, escape(all)))
            elif pep:
                url = 'http://www.python.org/dev/peps/pep-%04d/' % int(pep)
                results.append('<a href="%s">%s</a>' % (url, escape(all)))
            elif text[end:end+1] == '(':
                results.append(self.namelink(name, methods, funcs, classes))
            elif selfdot:
                results.append('self.<strong>%s</strong>' % name)
            else:
                results.append(self.namelink(name, classes))
            here = end
        results.append(escape(text[here:]))
        return join(results, '')

    # ---------------------------------------------- type-specific routines

    def formattree(self, tree, modname, parent=None):
        """Produce HTML for a class tree as given by inspect.getclasstree()."""
        result = ''
        for entry in tree:
            if type(entry) is type(()):
                c, bases = entry
                result = result + '<dt><font face="helvetica, arial">'
                result = result + self.classlink(c, modname)
                if bases and bases != (parent,):
                    parents = []
                    for base in bases:
                        parents.append(self.classlink(base, modname))
                    result = result + '(' + join(parents, ', ') + ')'
                result = result + '\n</font></dt>'
            elif type(entry) is type([]):
                result = result + '<dd>\n%s</dd>\n' % self.formattree(
                    entry, modname, c)
        return '<dl>\n%s</dl>\n' % result

    def docmodule(self, object, name=None, mod=None, *ignored):
        """Produce HTML documentation for a module object."""
        name = object.__name__ # ignore the passed-in name
        try:
            all = object.__all__
        except AttributeError:
            all = None
        parts = split(name, '.')
        links = []
        for i in range(len(parts)-1):
            links.append(
                '<a href="%s.html"><font color="#ffffff">%s</font></a>' %
                (join(parts[:i+1], '.'), parts[i]))
        linkedname = join(links + parts[-1:], '.')
        head = '<big><big><strong>%s</strong></big></big>' % linkedname
        try:
            path = inspect.getfile(object)
            if path.endswith('.pyc'): path = path[:-1]
            url = path
            if sys.platform == 'win32':
                import nturl2path
                url = nturl2path.pathname2url(path)
            if path.startswith('./'): path = path[2:]
            filelink = '<a href="../../hg/pox/file/tip/%s">%s</a>' % (url, path)
        except TypeError:
            filelink = '(built-in)'
        info = []
        if hasattr(object, '__version__'):
            version = str(object.__version__)
            if version[:11] == '$' + 'Revision: ' and version[-1:] == '$':
                version = strip(version[11:-1])
            info.append('version %s' % self.escape(version))
        if hasattr(object, '__date__'):
            info.append(self.escape(str(object.__date__)))
        if info:
            head = head + ' (%s)' % join(info, ', ')
        docloc = self.getdocloc(object)
        if docloc is not None:
            docloc = '<br><a href="%(docloc)s">Module Docs</a>' % locals()
        else:
            docloc = ''
        result = self.heading(
            head, '#ffffff', '#7799ee',
            '<a href=".">index</a><br>' + filelink + docloc)

        modules = inspect.getmembers(object, inspect.ismodule)

        classes, cdict = [], {}
        for key, value in inspect.getmembers(object, inspect.isclass):
            # if __all__ exists, believe it.  Otherwise use old heuristic.
            if (all is not None or
                (inspect.getmodule(value) or object) is object):
                if visiblename(key, all):
                    classes.append((key, value))
                    cdict[key] = cdict[value] = '#' + key
        for key, value in classes:
            for base in value.__bases__:
                key, modname = base.__name__, base.__module__
                module = sys.modules.get(modname)
                if modname != name and module and hasattr(module, key):
                    if getattr(module, key) is base:
                        if not key in cdict:
                            cdict[key] = cdict[base] = modname + '.html#' + key
        funcs, fdict = [], {}
        for key, value in inspect.getmembers(object, inspect.isroutine):
            # if __all__ exists, believe it.  Otherwise use old heuristic.
            if (all is not None or
                inspect.isbuiltin(value) or inspect.getmodule(value) is object):
                if visiblename(key, all):
                    funcs.append((key, value))
                    fdict[key] = '#-' + key
                    if inspect.isfunction(value): fdict[value] = fdict[key]
        data = []
        for key, value in inspect.getmembers(object, isdata):
            if visiblename(key, all):
                data.append((key, value))

        doc = self.markup(getdoc(object), self.preformat, fdict, cdict)
        doc = doc and '<tt>%s</tt>' % doc
        result = result + '<p>%s</p>\n' % doc

        if hasattr(object, '__path__'):
            modpkgs = []
            for importer, modname, ispkg in pkgutil.iter_modules(object.__path__):
                modpkgs.append((modname, name, ispkg, 0))
            modpkgs.sort()
            contents = self.multicolumn(modpkgs, self.modpkglink)
            result = result + self.bigsection(
                'Package Contents', '#ffffff', '#aa55cc', contents)
        elif modules:
            contents = self.multicolumn(
                modules, lambda key_value, s=self: s.modulelink(key_value[1]))
            result = result + self.bigsection(
                'Modules', '#ffffff', '#aa55cc', contents)

        if classes:
            classlist = map(lambda key_value: key_value[1], classes)
            contents = [
                self.formattree(inspect.getclasstree(classlist, 1), name)]
            for key, value in classes:
                contents.append(self.document(value, key, name, fdict, cdict))
            result = result + self.bigsection(
                'Classes', '#ffffff', '#ee77aa', join(contents))
        if funcs:
            contents = []
            for key, value in funcs:
                contents.append(self.document(value, key, name, fdict, cdict))
            result = result + self.bigsection(
                'Functions', '#ffffff', '#eeaa77', join(contents))
        if data:
            contents = []
            for key, value in data:
                contents.append(self.document(value, key))
            result = result + self.bigsection(
                'Data', '#ffffff', '#55aa55', join(contents, '<br>\n'))
        if hasattr(object, '__author__'):
            contents = self.markup(str(object.__author__), self.preformat)
            result = result + self.bigsection(
                'Author', '#ffffff', '#7799ee', contents)
        if hasattr(object, '__credits__'):
            contents = self.markup(str(object.__credits__), self.preformat)
            result = result + self.bigsection(
                'Credits', '#ffffff', '#7799ee', contents)

        return result

    def docclass(self, object, name=None, mod=None, funcs={}, classes={},
                 *ignored):
        """Produce HTML documentation for a class object."""
        realname = object.__name__
        name = name or realname
        bases = object.__bases__

        contents = []
        push = contents.append

        # Cute little class to pump out a horizontal rule between sections.
        class HorizontalRule:
            def __init__(self):
                self.needone = 0
            def maybe(self):
                if self.needone:
                    push('<hr>\n')
                self.needone = 1
        hr = HorizontalRule()

        # List the mro, if non-trivial.
        mro = deque(inspect.getmro(object))
        if len(mro) > 2:
            hr.maybe()
            push('<dl><dt>Method resolution order:</dt>\n')
            for base in mro:
                push('<dd>%s</dd>\n' % self.classlink(base,
                                                      object.__module__))
            push('</dl>\n')

        def spill(msg, attrs, predicate):
            ok, attrs = _split_list(attrs, predicate)
            if ok:
                hr.maybe()
                push(msg)
                for name, kind, homecls, value in ok:
                    push(self.document(getattr(object, name), name, mod,
                                       funcs, classes, mdict, object))
                    push('\n')
            return attrs

        def spilldescriptors(msg, attrs, predicate):
            ok, attrs = _split_list(attrs, predicate)
            if ok:
                hr.maybe()
                push(msg)
                for name, kind, homecls, value in ok:
                    push(self._docdescriptor(name, value, mod))
            return attrs

        def spilldata(msg, attrs, predicate):
            ok, attrs = _split_list(attrs, predicate)
            if ok:
                hr.maybe()
                push(msg)
                for name, kind, homecls, value in ok:
                    base = self.docother(getattr(object, name), name, mod)
                    if (hasattr(value, '__call__') or
                            inspect.isdatadescriptor(value)):
                        doc = getattr(value, "__doc__", None)
                    else:
                        doc = None
                    if doc is None:
                        push('<dl><dt>%s</dl>\n' % base)
                    else:
                        doc = self.markup(getdoc(value), self.preformat,
                                          funcs, classes, mdict)
                        doc = '<dd><tt>%s</tt>' % doc
                        push('<dl><dt>%s%s</dl>\n' % (base, doc))
                    push('\n')
            return attrs

        attrs = filter(lambda data: visiblename(data[0]),
                       classify_class_attrs(object))
        mdict = {}
        for key, kind, homecls, value in attrs:
            mdict[key] = anchor = '#' + name + '-' + key
            value = getattr(object, key)
            try:
                # The value may not be hashable (e.g., a data attr with
                # a dict or list value).
                mdict[value] = anchor
            except TypeError:
                pass

        while attrs:
            if mro:
                thisclass = mro.popleft()
            else:
                thisclass = attrs[0][2]
            attrs, inherited = _split_list(attrs, lambda t: t[2] is thisclass)

            if thisclass is __builtin__.object:
                attrs = inherited
                continue
            elif thisclass is object:
                tag = 'defined here'
            elif thisclass.__name__ == "EventMixin":
                # Special case -- don't show
                attrs = inherited
                continue
            else:
                tag = 'inherited from %s' % self.classlink(thisclass,
                                                           object.__module__)
            tag += ':<br>\n'

            # Sort attrs by name.
            try:
                attrs.sort(key=lambda t: t[0])
            except TypeError:
                attrs.sort(lambda t1, t2: cmp(t1[0], t2[0]))    # 2.3 compat

            from pox.lib.revent import EventMixin
            if hasattr(object, '_eventMixin_events') and issubclass(object, EventMixin):
              events = list(object._eventMixin_events)
              if len(events) > 0:
                events.sort(key=lambda t: t.__name__)
	        hr.maybe()
	        push('<dl><dt>Class-level events:</dt>\n')
                for e in events:
                  push('<dd>%s</dd>\n' % self.classlink(e,
                                                      object.__module__))
                push('</dl>\n')

            # Pump out the attrs, segregated by kind.
            attrs = spill('Methods %s' % tag, attrs,
                          lambda t: t[1] == 'method')
            attrs = spill('Class methods %s' % tag, attrs,
                          lambda t: t[1] == 'class method')
            attrs = spill('Static methods %s' % tag, attrs,
                          lambda t: t[1] == 'static method')
            attrs = spilldescriptors('Data descriptors %s' % tag, attrs,
                                     lambda t: t[1] == 'data descriptor')
            attrs = spilldata('Data and other attributes %s' % tag, attrs,
                              lambda t: t[1] == 'data')
            assert attrs == []
            attrs = inherited

        contents = ''.join(contents)

        if name == realname:
            title = '<a name="%s">class <strong>%s</strong></a>' % (
                name, realname)
        else:
            title = '<strong>%s</strong> = <a name="%s">class %s</a>' % (
                name, name, realname)
        if bases:
            parents = []
            for base in bases:
                parents.append(self.classlink(base, object.__module__))
            title = title + '(%s)' % join(parents, ', ')
        doc = self.markup(getdoc(object), self.preformat, funcs, classes, mdict)
        doc = doc and '<tt>%s<br>&nbsp;</tt>' % doc

        return self.section(title, '#000000', '#ffc8d8', contents, 3, doc)

    def formatvalue(self, object):
        """Format an argument default value as text."""
        return self.grey('=' + self.repr(object))

    def docroutine(self, object, name=None, mod=None,
                   funcs={}, classes={}, methods={}, cl=None):
        """Produce HTML documentation for a function or method object."""
        realname = object.__name__
        name = name or realname
        anchor = (cl and cl.__name__ or '') + '-' + name
        note = ''
        skipdocs = 0
        if inspect.ismethod(object):
            imclass = object.im_class
            if cl:
                if imclass is not cl:
                    note = ' from ' + self.classlink(imclass, mod)
            else:
                if object.im_self is not None:
                    note = ' method of %s instance' % self.classlink(
                        object.im_self.__class__, mod)
                else:
                    note = ' unbound %s method' % self.classlink(imclass,mod)
            object = object.im_func

        if name == realname:
            title = '<a name="%s"><strong>%s</strong></a>' % (anchor, realname)
        else:
            if (cl and realname in cl.__dict__ and
                cl.__dict__[realname] is object):
                reallink = '<a href="#%s">%s</a>' % (
                    cl.__name__ + '-' + realname, realname)
                skipdocs = 1
            else:
                reallink = realname
            title = '<a name="%s"><strong>%s</strong></a> = %s' % (
                anchor, name, reallink)
        if inspect.isfunction(object):
            args, varargs, varkw, defaults = inspect.getargspec(object)
            argspec = inspect.formatargspec(
                args, varargs, varkw, defaults, formatvalue=self.formatvalue)
            if realname == '<lambda>':
                title = '<strong>%s</strong> <em>lambda</em> ' % name
                argspec = argspec[1:-1] # remove parentheses
        else:
            argspec = '(...)'

        decl = title + argspec + (note and self.grey(
               '<font face="helvetica, arial">%s</font>' % note))

        if skipdocs:
            return '<dl><dt>%s</dt></dl>\n' % decl
        else:
            doc = self.markup(
                getdoc(object), self.preformat, funcs, classes, methods)
            doc = doc and '<dd><tt>%s</tt></dd>' % doc
            return '<dl><dt>%s</dt>%s</dl>\n' % (decl, doc)

    def _docdescriptor(self, name, value, mod):
        results = []
        push = results.append

        if name:
            push('<dl><dt><strong>%s</strong></dt>\n' % name)
        if value.__doc__ is not None:
            doc = self.markup(getdoc(value), self.preformat)
            push('<dd><tt>%s</tt></dd>\n' % doc)
        push('</dl>\n')

        return ''.join(results)

    def docproperty(self, object, name=None, mod=None, cl=None):
        """Produce html documentation for a property."""
        return self._docdescriptor(name, object, mod)

    def docother(self, object, name=None, mod=None, *ignored):
        """Produce HTML documentation for a data object."""
        lhs = name and '<strong>%s</strong> = ' % name or ''
        return lhs + self.repr(object)

    def docdata(self, object, name=None, mod=None, cl=None):
        """Produce html documentation for a data descriptor."""
        return self._docdescriptor(name, object, mod)

    def index(self, dir, shadowed=None):
        """Generate an HTML index for a directory of modules."""
        modpkgs = []
        if shadowed is None: shadowed = {}
        for importer, name, ispkg in pkgutil.iter_modules([dir]):
            modpkgs.append((name, '', ispkg, name in shadowed))
            shadowed[name] = 1

        modpkgs.sort()
        contents = self.multicolumn(modpkgs, self.modpkglink)
        return self.bigsection(dir, '#ffffff', '#ee77aa', contents)

# -------------------------------------------- text documentation generator

class TextRepr(Repr):
    """Class for safely making a text representation of a Python object."""
    def __init__(self):
        Repr.__init__(self)
        self.maxlist = self.maxtuple = 20
        self.maxdict = 10
        self.maxstring = self.maxother = 100

    def repr1(self, x, level):
        if hasattr(type(x), '__name__'):
            methodname = 'repr_' + join(split(type(x).__name__), '_')
            if hasattr(self, methodname):
                return getattr(self, methodname)(x, level)
        return cram(stripid(repr(x)), self.maxother)

    def repr_string(self, x, level):
        test = cram(x, self.maxstring)
        testrepr = repr(test)
        if '\\' in test and '\\' not in replace(testrepr, r'\\', ''):
            # Backslashes are only literal in the string and are never
            # needed to make any special characters, so show a raw string.
            return 'r' + testrepr[0] + test + testrepr[0]
        return testrepr

    repr_str = repr_string

    def repr_instance(self, x, level):
        try:
            return cram(stripid(repr(x)), self.maxstring)
        except:
            return '<%s instance>' % x.__class__.__name__

class TextDoc(Doc):
    """Formatter class for text documentation."""

    # ------------------------------------------- text formatting utilities

    _repr_instance = TextRepr()
    repr = _repr_instance.repr

    def bold(self, text):
        """Format a string in bold by overstriking."""
        return join(map(lambda ch: ch + '\b' + ch, text), '')

    def indent(self, text, prefix='    '):
        """Indent text by prepending a given prefix to each line."""
        if not text: return ''
        lines = split(text, '\n')
        lines = map(lambda line, prefix=prefix: prefix + line, lines)
        if lines: lines[-1] = rstrip(lines[-1])
        return join(lines, '\n')

    def section(self, title, contents):
        """Format a section with a given heading."""
        return self.bold(title) + '\n' + rstrip(self.indent(contents)) + '\n\n'

    # ---------------------------------------------- type-specific routines

    def formattree(self, tree, modname, parent=None, prefix=''):
        """Render in text a class tree as returned by inspect.getclasstree()."""
        result = ''
        for entry in tree:
            if type(entry) is type(()):
                c, bases = entry
                result = result + prefix + classname(c, modname)
                if bases and bases != (parent,):
                    parents = map(lambda c, m=modname: classname(c, m), bases)
                    result = result + '(%s)' % join(parents, ', ')
                result = result + '\n'
            elif type(entry) is type([]):
                result = result + self.formattree(
                    entry, modname, c, prefix + '    ')
        return result

    def docmodule(self, object, name=None, mod=None):
        """Produce text documentation for a given module object."""
        name = object.__name__ # ignore the passed-in name
        synop, desc = splitdoc(getdoc(object))
        result = self.section('NAME', name + (synop and ' - ' + synop))

        try:
            all = object.__all__
        except AttributeError:
            all = None

        try:
            file = inspect.getabsfile(object)
        except TypeError:
            file = '(built-in)'
        result = result + self.section('FILE', file)

        docloc = self.getdocloc(object)
        if docloc is not None:
            result = result + self.section('MODULE DOCS', docloc)

        if desc:
            result = result + self.section('DESCRIPTION', desc)

        classes = []
        for key, value in inspect.getmembers(object, inspect.isclass):
            # if __all__ exists, believe it.  Otherwise use old heuristic.
            if (all is not None
                or (inspect.getmodule(value) or object) is object):
                if visiblename(key, all):
                    classes.append((key, value))
        funcs = []
        for key, value in inspect.getmembers(object, inspect.isroutine):
            # if __all__ exists, believe it.  Otherwise use old heuristic.
            if (all is not None or
                inspect.isbuiltin(value) or inspect.getmodule(value) is object):
                if visiblename(key, all):
                    funcs.append((key, value))
        data = []
        for key, value in inspect.getmembers(object, isdata):
            if visiblename(key, all):
                data.append((key, value))

        modpkgs = []
        modpkgs_names = set()
        if hasattr(object, '__path__'):
            for importer, modname, ispkg in pkgutil.iter_modules(object.__path__):
                modpkgs_names.add(modname)
                if ispkg:
                    modpkgs.append(modname + ' (package)')
                else:
                    modpkgs.append(modname)

            modpkgs.sort()
            result = result + self.section(
                'PACKAGE CONTENTS', join(modpkgs, '\n'))

        # Detect submodules as sometimes created by C extensions
        submodules = []
        for key, value in inspect.getmembers(object, inspect.ismodule):
            if value.__name__.startswith(name + '.') and key not in modpkgs_names:
                submodules.append(key)
        if submodules:
            submodules.sort()
            result = result + self.section(
                'SUBMODULES', join(submodules, '\n'))

        if classes:
            classlist = map(lambda key_value: key_value[1], classes)
            contents = [self.formattree(
                inspect.getclasstree(classlist, 1), name)]
            for key, value in classes:
                contents.append(self.document(value, key, name))
            result = result + self.section('CLASSES', join(contents, '\n'))

        if funcs:
            contents = []
            for key, value in funcs:
                contents.append(self.document(value, key, name))
            result = result + self.section('FUNCTIONS', join(contents, '\n'))

        if data:
            contents = []
            for key, value in data:
                contents.append(self.docother(value, key, name, maxlen=70))
            result = result + self.section('DATA', join(contents, '\n'))

        if hasattr(object, '__version__'):
            version = str(object.__version__)
            if version[:11] == '$' + 'Revision: ' and version[-1:] == '$':
                version = strip(version[11:-1])
            result = result + self.section('VERSION', version)
        if hasattr(object, '__date__'):
            result = result + self.section('DATE', str(object.__date__))
        if hasattr(object, '__author__'):
            result = result + self.section('AUTHOR', str(object.__author__))
        if hasattr(object, '__credits__'):
            result = result + self.section('CREDITS', str(object.__credits__))
        return result

    def docclass(self, object, name=None, mod=None):
        """Produce text documentation for a given class object."""
        realname = object.__name__
        name = name or realname
        bases = object.__bases__

        def makename(c, m=object.__module__):
            return classname(c, m)

        if name == realname:
            title = 'class ' + self.bold(realname)
        else:
            title = self.bold(name) + ' = class ' + realname
        if bases:
            parents = map(makename, bases)
            title = title + '(%s)' % join(parents, ', ')

        doc = getdoc(object)
        contents = doc and [doc + '\n'] or []
        push = contents.append

        # List the mro, if non-trivial.
        mro = deque(inspect.getmro(object))
        if len(mro) > 2:
            push("Method resolution order:")
            for base in mro:
                push('    ' + makename(base))
            push('')

        # Cute little class to pump out a horizontal rule between sections.
        class HorizontalRule:
            def __init__(self):
                self.needone = 0
            def maybe(self):
                if self.needone:
                    push('-' * 70)
                self.needone = 1
        hr = HorizontalRule()

        def spill(msg, attrs, predicate):
            ok, attrs = _split_list(attrs, predicate)
            if ok:
                hr.maybe()
                push(msg)
                for name, kind, homecls, value in ok:
                    push(self.document(getattr(object, name),
                                       name, mod, object))
            return attrs

        def spilldescriptors(msg, attrs, predicate):
            ok, attrs = _split_list(attrs, predicate)
            if ok:
                hr.maybe()
                push(msg)
                for name, kind, homecls, value in ok:
                    push(self._docdescriptor(name, value, mod))
            return attrs

        def spilldata(msg, attrs, predicate):
            ok, attrs = _split_list(attrs, predicate)
            if ok:
                hr.maybe()
                push(msg)
                for name, kind, homecls, value in ok:
                    if (hasattr(value, '__call__') or
                            inspect.isdatadescriptor(value)):
                        doc = getdoc(value)
                    else:
                        doc = None
                    push(self.docother(getattr(object, name),
                                       name, mod, maxlen=70, doc=doc) + '\n')
            return attrs

        attrs = filter(lambda data: visiblename(data[0]),
                       classify_class_attrs(object))
        while attrs:
            if mro:
                thisclass = mro.popleft()
            else:
                thisclass = attrs[0][2]
            attrs, inherited = _split_list(attrs, lambda t: t[2] is thisclass)

            if thisclass is __builtin__.object:
                attrs = inherited
                continue
            elif thisclass is object:
                tag = "defined here"
            else:
                tag = "inherited from %s" % classname(thisclass,
                                                      object.__module__)

            # Sort attrs by name.
            attrs.sort()

            # Pump out the attrs, segregated by kind.
            attrs = spill("Methods %s:\n" % tag, attrs,
                          lambda t: t[1] == 'method')
            attrs = spill("Class methods %s:\n" % tag, attrs,
                          lambda t: t[1] == 'class method')
            attrs = spill("Static methods %s:\n" % tag, attrs,
                          lambda t: t[1] == 'static method')
            attrs = spilldescriptors("Data descriptors %s:\n" % tag, attrs,
                                     lambda t: t[1] == 'data descriptor')
            attrs = spilldata("Data and other attributes %s:\n" % tag, attrs,
                              lambda t: t[1] == 'data')
            assert attrs == []
            attrs = inherited

        contents = '\n'.join(contents)
        if not contents:
            return title + '\n'
        return title + '\n' + self.indent(rstrip(contents), ' |  ') + '\n'

    def formatvalue(self, object):
        """Format an argument default value as text."""
        return '=' + self.repr(object)

    def docroutine(self, object, name=None, mod=None, cl=None):
        """Produce text documentation for a function or method object."""
        realname = object.__name__
        name = name or realname
        note = ''
        skipdocs = 0
        if inspect.ismethod(object):
            imclass = object.im_class
            if cl:
                if imclass is not cl:
                    note = ' from ' + classname(imclass, mod)
            else:
                if object.im_self is not None:
                    note = ' method of %s instance' % classname(
                        object.im_self.__class__, mod)
                else:
                    note = ' unbound %s method' % classname(imclass,mod)
            object = object.im_func

        if name == realname:
            title = self.bold(realname)
        else:
            if (cl and realname in cl.__dict__ and
                cl.__dict__[realname] is object):
                skipdocs = 1
            title = self.bold(name) + ' = ' + realname
        if inspect.isfunction(object):
            args, varargs, varkw, defaults = inspect.getargspec(object)
            argspec = inspect.formatargspec(
                args, varargs, varkw, defaults, formatvalue=self.formatvalue)
            if realname == '<lambda>':
                title = self.bold(name) + ' lambda '
                argspec = argspec[1:-1] # remove parentheses
        else:
            argspec = '(...)'
        decl = title + argspec + note

        if skipdocs:
            return decl + '\n'
        else:
            doc = getdoc(object) or ''
            return decl + '\n' + (doc and rstrip(self.indent(doc)) + '\n')

    def _docdescriptor(self, name, value, mod):
        results = []
        push = results.append

        if name:
            push(self.bold(name))
            push('\n')
        doc = getdoc(value) or ''
        if doc:
            push(self.indent(doc))
            push('\n')
        return ''.join(results)

    def docproperty(self, object, name=None, mod=None, cl=None):
        """Produce text documentation for a property."""
        return self._docdescriptor(name, object, mod)

    def docdata(self, object, name=None, mod=None, cl=None):
        """Produce text documentation for a data descriptor."""
        return self._docdescriptor(name, object, mod)

    def docother(self, object, name=None, mod=None, parent=None, maxlen=None, doc=None):
        """Produce text documentation for a data object."""
        repr = self.repr(object)
        if maxlen:
            line = (name and name + ' = ' or '') + repr
            chop = maxlen - len(line)
            if chop < 0: repr = repr[:chop] + '...'
        line = (name and self.bold(name) + ' = ' or '') + repr
        if doc is not None:
            line += '\n' + self.indent(str(doc))
        return line

# --------------------------------------------------------- user interfaces

def pager(text):
    """The first time this is called, determine what kind of pager to use."""
    global pager
    pager = getpager()
    pager(text)

def getpager():
    """Decide what method to use for paging through text."""
    if type(sys.stdout) is not types.FileType:
        return plainpager
    if not sys.stdin.isatty() or not sys.stdout.isatty():
        return plainpager
    if 'PAGER' in os.environ:
        if sys.platform == 'win32': # pipes completely broken in Windows
            return lambda text: tempfilepager(plain(text), os.environ['PAGER'])
        elif os.environ.get('TERM') in ('dumb', 'emacs'):
            return lambda text: pipepager(plain(text), os.environ['PAGER'])
        else:
            return lambda text: pipepager(text, os.environ['PAGER'])
    if os.environ.get('TERM') in ('dumb', 'emacs'):
        return plainpager
    if sys.platform == 'win32' or sys.platform.startswith('os2'):
        return lambda text: tempfilepager(plain(text), 'more <')
    if hasattr(os, 'system') and os.system('(less) 2>/dev/null') == 0:
        return lambda text: pipepager(text, 'less')

    import tempfile
    (fd, filename) = tempfile.mkstemp()
    os.close(fd)
    try:
        if hasattr(os, 'system') and os.system('more "%s"' % filename) == 0:
            return lambda text: pipepager(text, 'more')
        else:
            return ttypager
    finally:
        os.unlink(filename)

def plain(text):
    """Remove boldface formatting from text."""
    return re.sub('.\b', '', text)

def pipepager(text, cmd):
    """Page through text by feeding it to another program."""
    pipe = os.popen(cmd, 'w')
    try:
        pipe.write(text)
        pipe.close()
    except IOError:
        pass # Ignore broken pipes caused by quitting the pager program.

def tempfilepager(text, cmd):
    """Page through text by invoking a program on a temporary file."""
    import tempfile
    filename = tempfile.mktemp()
    file = open(filename, 'w')
    file.write(text)
    file.close()
    try:
        os.system(cmd + ' "' + filename + '"')
    finally:
        os.unlink(filename)

def ttypager(text):
    """Page through text on a text terminal."""
    lines = split(plain(text), '\n')
    try:
        import tty
        fd = sys.stdin.fileno()
        old = tty.tcgetattr(fd)
        tty.setcbreak(fd)
        getchar = lambda: sys.stdin.read(1)
    except (ImportError, AttributeError):
        tty = None
        getchar = lambda: sys.stdin.readline()[:-1][:1]

    try:
        r = inc = os.environ.get('LINES', 25) - 1
        sys.stdout.write(join(lines[:inc], '\n') + '\n')
        while lines[r:]:
            sys.stdout.write('-- more --')
            sys.stdout.flush()
            c = getchar()

            if c in ('q', 'Q'):
                sys.stdout.write('\r          \r')
                break
            elif c in ('\r', '\n'):
                sys.stdout.write('\r          \r' + lines[r] + '\n')
                r = r + 1
                continue
            if c in ('b', 'B', '\x1b'):
                r = r - inc - inc
                if r < 0: r = 0
            sys.stdout.write('\n' + join(lines[r:r+inc], '\n') + '\n')
            r = r + inc

    finally:
        if tty:
            tty.tcsetattr(fd, tty.TCSAFLUSH, old)

def plainpager(text):
    """Simply print unformatted text.  This is the ultimate fallback."""
    sys.stdout.write(plain(text))

def describe(thing):
    """Produce a short description of the given thing."""
    if inspect.ismodule(thing):
        if thing.__name__ in sys.builtin_module_names:
            return 'built-in module ' + thing.__name__
        if hasattr(thing, '__path__'):
            return 'package ' + thing.__name__
        else:
            return 'module ' + thing.__name__
    if inspect.isbuiltin(thing):
        return 'built-in function ' + thing.__name__
    if inspect.isgetsetdescriptor(thing):
        return 'getset descriptor %s.%s.%s' % (
            thing.__objclass__.__module__, thing.__objclass__.__name__,
            thing.__name__)
    if inspect.ismemberdescriptor(thing):
        return 'member descriptor %s.%s.%s' % (
            thing.__objclass__.__module__, thing.__objclass__.__name__,
            thing.__name__)
    if inspect.isclass(thing):
        return 'class ' + thing.__name__
    if inspect.isfunction(thing):
        return 'function ' + thing.__name__
    if inspect.ismethod(thing):
        return 'method ' + thing.__name__
    if type(thing) is types.InstanceType:
        return 'instance of ' + thing.__class__.__name__
    return type(thing).__name__

def locate(path, forceload=0):
    """Locate an object by name or dotted path, importing as necessary."""
    parts = [part for part in split(path, '.') if part]
    module, n = None, 0
    while n < len(parts):
        nextmodule = safeimport(join(parts[:n+1], '.'), forceload)
        if nextmodule: module, n = nextmodule, n + 1
        else: break
    if module:
        object = module
        for part in parts[n:]:
            try: object = getattr(object, part)
            except AttributeError: return None
        return object
    else:
        if hasattr(__builtin__, path):
            return getattr(__builtin__, path)

# --------------------------------------- interactive interpreter interface

text = TextDoc()
html = HTMLDoc()

class _OldStyleClass: pass
_OLD_INSTANCE_TYPE = type(_OldStyleClass())

def resolve(thing, forceload=0):
    """Given an object or a path to an object, get the object and its name."""
    if isinstance(thing, str):
        object = locate(thing, forceload)
        if not object:
            raise ImportError, 'no Python documentation found for %r' % thing
        return object, thing
    else:
        return thing, getattr(thing, '__name__', None)

def render_doc(thing, title='Python Library Documentation: %s', forceload=0):
    """Render text documentation, given an object or a path to an object."""
    object, name = resolve(thing, forceload)
    desc = describe(object)
    module = inspect.getmodule(object)
    if name and '.' in name:
        desc += ' in ' + name[:name.rfind('.')]
    elif module and module is not object:
        desc += ' in module ' + module.__name__
    if type(object) is _OLD_INSTANCE_TYPE:
        # If the passed object is an instance of an old-style class,
        # document its available methods instead of its value.
        object = object.__class__
    elif not (inspect.ismodule(object) or
              inspect.isclass(object) or
              inspect.isroutine(object) or
              inspect.isgetsetdescriptor(object) or
              inspect.ismemberdescriptor(object) or
              isinstance(object, property)):
        # If the passed object is a piece of data or an instance,
        # document its available methods instead of its value.
        object = type(object)
        desc += ' object'
    return title % desc + '\n\n' + text.document(object, name)

def doc(thing, title='Python Library Documentation: %s', forceload=0):
    """Display text documentation, given an object or a path to an object."""
    try:
        pager(render_doc(thing, title, forceload))
    except (ImportError, ErrorDuringImport), value:
        print value

def writedoc(thing, forceload=0):
    """Write HTML documentation to a file in the current directory."""
    try:
        object, name = resolve(thing, forceload)
        page = html.page(describe(object), html.document(object, name))
        file = open(name + '.html', 'w')
        file.write(page)
        file.close()
        print 'wrote', name + '.html'
    except (ImportError, ErrorDuringImport), value:
        print value

def writedocs(dir, pkgpath='', done=None):
    """Write out HTML documentation for all modules in a directory tree."""
    if done is None: done = {}
    for importer, modname, ispkg in pkgutil.walk_packages([dir], pkgpath):
        writedoc(modname)
    return

class Helper:

    # These dictionaries map a topic name to either an alias, or a tuple
    # (label, seealso-items).  The "label" is the label of the corresponding
    # section in the .rst file under Doc/ and an index into the dictionary
    # in pydoc_data/topics.py.
    #
    # CAUTION: if you change one of these dictionaries, be sure to adapt the
    #          list of needed labels in Doc/tools/sphinxext/pyspecific.py and
    #          regenerate the pydoc_data/topics.py file by running
    #              make pydoc-topics
    #          in Doc/ and copying the output file into the Lib/ directory.

    keywords = {
        'and': 'BOOLEAN',
        'as': 'with',
        'assert': ('assert', ''),
        'break': ('break', 'while for'),
        'class': ('class', 'CLASSES SPECIALMETHODS'),
        'continue': ('continue', 'while for'),
        'def': ('function', ''),
        'del': ('del', 'BASICMETHODS'),
        'elif': 'if',
        'else': ('else', 'while for'),
        'except': 'try',
        'exec': ('exec', ''),
        'finally': 'try',
        'for': ('for', 'break continue while'),
        'from': 'import',
        'global': ('global', 'NAMESPACES'),
        'if': ('if', 'TRUTHVALUE'),
        'import': ('import', 'MODULES'),
        'in': ('in', 'SEQUENCEMETHODS2'),
        'is': 'COMPARISON',
        'lambda': ('lambda', 'FUNCTIONS'),
        'not': 'BOOLEAN',
        'or': 'BOOLEAN',
        'pass': ('pass', ''),
        'print': ('print', ''),
        'raise': ('raise', 'EXCEPTIONS'),
        'return': ('return', 'FUNCTIONS'),
        'try': ('try', 'EXCEPTIONS'),
        'while': ('while', 'break continue if TRUTHVALUE'),
        'with': ('with', 'CONTEXTMANAGERS EXCEPTIONS yield'),
        'yield': ('yield', ''),
    }
    # Either add symbols to this dictionary or to the symbols dictionary
    # directly: Whichever is easier. They are merged later.
    _symbols_inverse = {
        'STRINGS' : ("'", "'''", "r'", "u'", '"""', '"', 'r"', 'u"'),
        'OPERATORS' : ('+', '-', '*', '**', '/', '//', '%', '<<', '>>', '&',
                       '|', '^', '~', '<', '>', '<=', '>=', '==', '!=', '<>'),
        'COMPARISON' : ('<', '>', '<=', '>=', '==', '!=', '<>'),
        'UNARY' : ('-', '~'),
        'AUGMENTEDASSIGNMENT' : ('+=', '-=', '*=', '/=', '%=', '&=', '|=',
                                '^=', '<<=', '>>=', '**=', '//='),
        'BITWISE' : ('<<', '>>', '&', '|', '^', '~'),
        'COMPLEX' : ('j', 'J')
    }
    symbols = {
        '%': 'OPERATORS FORMATTING',
        '**': 'POWER',
        ',': 'TUPLES LISTS FUNCTIONS',
        '.': 'ATTRIBUTES FLOAT MODULES OBJECTS',
        '...': 'ELLIPSIS',
        ':': 'SLICINGS DICTIONARYLITERALS',
        '@': 'def class',
        '\\': 'STRINGS',
        '_': 'PRIVATENAMES',
        '__': 'PRIVATENAMES SPECIALMETHODS',
        '`': 'BACKQUOTES',
        '(': 'TUPLES FUNCTIONS CALLS',
        ')': 'TUPLES FUNCTIONS CALLS',
        '[': 'LISTS SUBSCRIPTS SLICINGS',
        ']': 'LISTS SUBSCRIPTS SLICINGS'
    }
    for topic, symbols_ in _symbols_inverse.iteritems():
        for symbol in symbols_:
            topics = symbols.get(symbol, topic)
            if topic not in topics:
                topics = topics + ' ' + topic
            symbols[symbol] = topics

    topics = {
        'TYPES': ('types', 'STRINGS UNICODE NUMBERS SEQUENCES MAPPINGS '
                  'FUNCTIONS CLASSES MODULES FILES inspect'),
        'STRINGS': ('strings', 'str UNICODE SEQUENCES STRINGMETHODS FORMATTING '
                    'TYPES'),
        'STRINGMETHODS': ('string-methods', 'STRINGS FORMATTING'),
        'FORMATTING': ('formatstrings', 'OPERATORS'),
        'UNICODE': ('strings', 'encodings unicode SEQUENCES STRINGMETHODS '
                    'FORMATTING TYPES'),
        'NUMBERS': ('numbers', 'INTEGER FLOAT COMPLEX TYPES'),
        'INTEGER': ('integers', 'int range'),
        'FLOAT': ('floating', 'float math'),
        'COMPLEX': ('imaginary', 'complex cmath'),
        'SEQUENCES': ('typesseq', 'STRINGMETHODS FORMATTING xrange LISTS'),
        'MAPPINGS': 'DICTIONARIES',
        'FUNCTIONS': ('typesfunctions', 'def TYPES'),
        'METHODS': ('typesmethods', 'class def CLASSES TYPES'),
        'CODEOBJECTS': ('bltin-code-objects', 'compile FUNCTIONS TYPES'),
        'TYPEOBJECTS': ('bltin-type-objects', 'types TYPES'),
        'FRAMEOBJECTS': 'TYPES',
        'TRACEBACKS': 'TYPES',
        'NONE': ('bltin-null-object', ''),
        'ELLIPSIS': ('bltin-ellipsis-object', 'SLICINGS'),
        'FILES': ('bltin-file-objects', ''),
        'SPECIALATTRIBUTES': ('specialattrs', ''),
        'CLASSES': ('types', 'class SPECIALMETHODS PRIVATENAMES'),
        'MODULES': ('typesmodules', 'import'),
        'PACKAGES': 'import',
        'EXPRESSIONS': ('operator-summary', 'lambda or and not in is BOOLEAN '
                        'COMPARISON BITWISE SHIFTING BINARY FORMATTING POWER '
                        'UNARY ATTRIBUTES SUBSCRIPTS SLICINGS CALLS TUPLES '
                        'LISTS DICTIONARIES BACKQUOTES'),
        'OPERATORS': 'EXPRESSIONS',
        'PRECEDENCE': 'EXPRESSIONS',
        'OBJECTS': ('objects', 'TYPES'),
        'SPECIALMETHODS': ('specialnames', 'BASICMETHODS ATTRIBUTEMETHODS '
                           'CALLABLEMETHODS SEQUENCEMETHODS1 MAPPINGMETHODS '
                           'SEQUENCEMETHODS2 NUMBERMETHODS CLASSES'),
        'BASICMETHODS': ('customization', 'cmp hash repr str SPECIALMETHODS'),
        'ATTRIBUTEMETHODS': ('attribute-access', 'ATTRIBUTES SPECIALMETHODS'),
        'CALLABLEMETHODS': ('callable-types', 'CALLS SPECIALMETHODS'),
        'SEQUENCEMETHODS1': ('sequence-types', 'SEQUENCES SEQUENCEMETHODS2 '
                             'SPECIALMETHODS'),
        'SEQUENCEMETHODS2': ('sequence-methods', 'SEQUENCES SEQUENCEMETHODS1 '
                             'SPECIALMETHODS'),
        'MAPPINGMETHODS': ('sequence-types', 'MAPPINGS SPECIALMETHODS'),
        'NUMBERMETHODS': ('numeric-types', 'NUMBERS AUGMENTEDASSIGNMENT '
                          'SPECIALMETHODS'),
        'EXECUTION': ('execmodel', 'NAMESPACES DYNAMICFEATURES EXCEPTIONS'),
        'NAMESPACES': ('naming', 'global ASSIGNMENT DELETION DYNAMICFEATURES'),
        'DYNAMICFEATURES': ('dynamic-features', ''),
        'SCOPING': 'NAMESPACES',
        'FRAMES': 'NAMESPACES',
        'EXCEPTIONS': ('exceptions', 'try except finally raise'),
        'COERCIONS': ('coercion-rules','CONVERSIONS'),
        'CONVERSIONS': ('conversions', 'COERCIONS'),
        'IDENTIFIERS': ('identifiers', 'keywords SPECIALIDENTIFIERS'),
        'SPECIALIDENTIFIERS': ('id-classes', ''),
        'PRIVATENAMES': ('atom-identifiers', ''),
        'LITERALS': ('atom-literals', 'STRINGS BACKQUOTES NUMBERS '
                     'TUPLELITERALS LISTLITERALS DICTIONARYLITERALS'),
        'TUPLES': 'SEQUENCES',
        'TUPLELITERALS': ('exprlists', 'TUPLES LITERALS'),
        'LISTS': ('typesseq-mutable', 'LISTLITERALS'),
        'LISTLITERALS': ('lists', 'LISTS LITERALS'),
        'DICTIONARIES': ('typesmapping', 'DICTIONARYLITERALS'),
        'DICTIONARYLITERALS': ('dict', 'DICTIONARIES LITERALS'),
        'BACKQUOTES': ('string-conversions', 'repr str STRINGS LITERALS'),
        'ATTRIBUTES': ('attribute-references', 'getattr hasattr setattr '
                       'ATTRIBUTEMETHODS'),
        'SUBSCRIPTS': ('subscriptions', 'SEQUENCEMETHODS1'),
        'SLICINGS': ('slicings', 'SEQUENCEMETHODS2'),
        'CALLS': ('calls', 'EXPRESSIONS'),
        'POWER': ('power', 'EXPRESSIONS'),
        'UNARY': ('unary', 'EXPRESSIONS'),
        'BINARY': ('binary', 'EXPRESSIONS'),
        'SHIFTING': ('shifting', 'EXPRESSIONS'),
        'BITWISE': ('bitwise', 'EXPRESSIONS'),
        'COMPARISON': ('comparisons', 'EXPRESSIONS BASICMETHODS'),
        'BOOLEAN': ('booleans', 'EXPRESSIONS TRUTHVALUE'),
        'ASSERTION': 'assert',
        'ASSIGNMENT': ('assignment', 'AUGMENTEDASSIGNMENT'),
        'AUGMENTEDASSIGNMENT': ('augassign', 'NUMBERMETHODS'),
        'DELETION': 'del',
        'PRINTING': 'print',
        'RETURNING': 'return',
        'IMPORTING': 'import',
        'CONDITIONAL': 'if',
        'LOOPING': ('compound', 'for while break continue'),
        'TRUTHVALUE': ('truth', 'if while and or not BASICMETHODS'),
        'DEBUGGING': ('debugger', 'pdb'),
        'CONTEXTMANAGERS': ('context-managers', 'with'),
    }

    def __init__(self, input=None, output=None):
        self._input = input
        self._output = output

    input  = property(lambda self: self._input or sys.stdin)
    output = property(lambda self: self._output or sys.stdout)

    def __repr__(self):
        if inspect.stack()[1][3] == '?':
            self()
            return ''
        return '<pydoc.Helper instance>'

    _GoInteractive = object()
    def __call__(self, request=_GoInteractive):
        if request is not self._GoInteractive:
            self.help(request)
        else:
            self.intro()
            self.interact()
            self.output.write('''
You are now leaving help and returning to the Python interpreter.
If you want to ask for help on a particular object directly from the
interpreter, you can type "help(object)".  Executing "help('string')"
has the same effect as typing a particular string at the help> prompt.
''')

    def interact(self):
        self.output.write('\n')
        while True:
            try:
                request = self.getline('help> ')
                if not request: break
            except (KeyboardInterrupt, EOFError):
                break
            request = strip(replace(request, '"', '', "'", ''))
            if lower(request) in ('q', 'quit'): break
            self.help(request)

    def getline(self, prompt):
        """Read one line, using raw_input when available."""
        if self.input is sys.stdin:
            return raw_input(prompt)
        else:
            self.output.write(prompt)
            self.output.flush()
            return self.input.readline()

    def help(self, request):
        if type(request) is type(''):
            request = request.strip()
            if request == 'help': self.intro()
            elif request == 'keywords': self.listkeywords()
            elif request == 'symbols': self.listsymbols()
            elif request == 'topics': self.listtopics()
            elif request == 'modules': self.listmodules()
            elif request[:8] == 'modules ':
                self.listmodules(split(request)[1])
            elif request in self.symbols: self.showsymbol(request)
            elif request in self.keywords: self.showtopic(request)
            elif request in self.topics: self.showtopic(request)
            elif request: doc(request, 'Help on %s:')
        elif isinstance(request, Helper): self()
        else: doc(request, 'Help on %s:')
        self.output.write('\n')

    def intro(self):
        self.output.write('''
Welcome to Python %s!  This is the online help utility.

If this is your first time using Python, you should definitely check out
the tutorial on the Internet at http://docs.python.org/tutorial/.

Enter the name of any module, keyword, or topic to get help on writing
Python programs and using Python modules.  To quit this help utility and
return to the interpreter, just type "quit".

To get a list of available modules, keywords, or topics, type "modules",
"keywords", or "topics".  Each module also comes with a one-line summary
of what it does; to list the modules whose summaries contain a given word
such as "spam", type "modules spam".
''' % sys.version[:3])

    def list(self, items, columns=4, width=80):
        items = items[:]
        items.sort()
        colw = width / columns
        rows = (len(items) + columns - 1) / columns
        for row in range(rows):
            for col in range(columns):
                i = col * rows + row
                if i < len(items):
                    self.output.write(items[i])
                    if col < columns - 1:
                        self.output.write(' ' + ' ' * (colw-1 - len(items[i])))
            self.output.write('\n')

    def listkeywords(self):
        self.output.write('''
Here is a list of the Python keywords.  Enter any keyword to get more help.

''')
        self.list(self.keywords.keys())

    def listsymbols(self):
        self.output.write('''
Here is a list of the punctuation symbols which Python assigns special meaning
to. Enter any symbol to get more help.

''')
        self.list(self.symbols.keys())

    def listtopics(self):
        self.output.write('''
Here is a list of available topics.  Enter any topic name to get more help.

''')
        self.list(self.topics.keys())

    def showtopic(self, topic, more_xrefs=''):
        try:
            import pydoc_data.topics
        except ImportError:
            self.output.write('''
Sorry, topic and keyword documentation is not available because the
module "pydoc_data.topics" could not be found.
''')
            return
        target = self.topics.get(topic, self.keywords.get(topic))
        if not target:
            self.output.write('no documentation found for %s\n' % repr(topic))
            return
        if type(target) is type(''):
            return self.showtopic(target, more_xrefs)

        label, xrefs = target
        try:
            doc = pydoc_data.topics.topics[label]
        except KeyError:
            self.output.write('no documentation found for %s\n' % repr(topic))
            return
        pager(strip(doc) + '\n')
        if more_xrefs:
            xrefs = (xrefs or '') + ' ' + more_xrefs
        if xrefs:
            import StringIO, formatter
            buffer = StringIO.StringIO()
            formatter.DumbWriter(buffer).send_flowing_data(
                'Related help topics: ' + join(split(xrefs), ', ') + '\n')
            self.output.write('\n%s\n' % buffer.getvalue())

    def showsymbol(self, symbol):
        target = self.symbols[symbol]
        topic, _, xrefs = target.partition(' ')
        self.showtopic(topic, xrefs)

    def listmodules(self, key=''):
        if key:
            self.output.write('''
Here is a list of matching modules.  Enter any module name to get more help.

''')
            apropos(key)
        else:
            self.output.write('''
Please wait a moment while I gather a list of all available modules...

''')
            modules = {}
            def callback(path, modname, desc, modules=modules):
                if modname and modname[-9:] == '.__init__':
                    modname = modname[:-9] + ' (package)'
                if find(modname, '.') < 0:
                    modules[modname] = 1
            def onerror(modname):
                callback(None, modname, None)
            ModuleScanner().run(callback, onerror=onerror)
            self.list(modules.keys())
            self.output.write('''
Enter any module name to get more help.  Or, type "modules spam" to search
for modules whose descriptions contain the word "spam".
''')

help = Helper()

class Scanner:
    """A generic tree iterator."""
    def __init__(self, roots, children, descendp):
        self.roots = roots[:]
        self.state = []
        self.children = children
        self.descendp = descendp

    def next(self):
        if not self.state:
            if not self.roots:
                return None
            root = self.roots.pop(0)
            self.state = [(root, self.children(root))]
        node, children = self.state[-1]
        if not children:
            self.state.pop()
            return self.next()
        child = children.pop(0)
        if self.descendp(child):
            self.state.append((child, self.children(child)))
        return child


class ModuleScanner:
    """An interruptible scanner that searches module synopses."""

    def run(self, callback, key=None, completer=None, onerror=None):
        if key: key = lower(key)
        self.quit = False
        seen = {}

        for modname in sys.builtin_module_names:
            if modname != '__main__':
                seen[modname] = 1
                if key is None:
                    callback(None, modname, '')
                else:
                    desc = split(__import__(modname).__doc__ or '', '\n')[0]
                    if find(lower(modname + ' - ' + desc), key) >= 0:
                        callback(None, modname, desc)

        for importer, modname, ispkg in pkgutil.walk_packages(onerror=onerror):
            if self.quit:
                break
            if key is None:
                callback(None, modname, '')
            else:
                loader = importer.find_module(modname)
                if hasattr(loader,'get_source'):
                    import StringIO
                    desc = source_synopsis(
                        StringIO.StringIO(loader.get_source(modname))
                    ) or ''
                    if hasattr(loader,'get_filename'):
                        path = loader.get_filename(modname)
                    else:
                        path = None
                else:
                    module = loader.load_module(modname)
                    desc = (module.__doc__ or '').splitlines()[0]
                    path = getattr(module,'__file__',None)
                if find(lower(modname + ' - ' + desc), key) >= 0:
                    callback(path, modname, desc)

        if completer:
            completer()

def apropos(key):
    """Print all the one-line module summaries that contain a substring."""
    def callback(path, modname, desc):
        if modname[-9:] == '.__init__':
            modname = modname[:-9] + ' (package)'
        print modname, desc and '- ' + desc
    def onerror(modname):
        # Ignore non-ImportError exceptions raised whilst trying to
        # import modules
        pass
    try: import warnings
    except ImportError: pass
    else: warnings.filterwarnings('ignore') # ignore problems during import
    ModuleScanner().run(callback, key, onerror=onerror)

# --------------------------------------------------- web browser interface

def serve(port, callback=None, completer=None):
    import BaseHTTPServer, mimetools, select

    # Patch up mimetools.Message so it doesn't break if rfc822 is reloaded.
    class Message(mimetools.Message):
        def __init__(self, fp, seekable=1):
            Message = self.__class__
            Message.__bases__[0].__bases__[0].__init__(self, fp, seekable)
            self.encodingheader = self.getheader('content-transfer-encoding')
            self.typeheader = self.getheader('content-type')
            self.parsetype()
            self.parseplist()

    class DocHandler(BaseHTTPServer.BaseHTTPRequestHandler):
        def send_document(self, title, contents):
            try:
                self.send_response(200)
                self.send_header('Content-Type', 'text/html')
                self.end_headers()
                self.wfile.write(html.page(title, contents))
            except IOError: pass

        def do_GET(self):
            path = self.path
            if path[-5:] == '.html': path = path[:-5]
            if path[:1] == '/': path = path[1:]
            if path and path != '.':
                try:
                    obj = locate(path, forceload=1)
                except ErrorDuringImport, value:
                    self.send_document(path, html.escape(str(value)))
                    return
                if obj:
                    self.send_document(describe(obj), html.document(obj, path))
                else:
                    self.send_document(path,
'no Python documentation found for %s' % repr(path))
            else:
                heading = html.heading(
'<big><big><strong>Python: Index of Modules</strong></big></big>',
'#ffffff', '#7799ee')
                def bltinlink(name):
                    return '<a href="%s.html">%s</a>' % (name, name)
                names = filter(lambda x: x != '__main__',
                               sys.builtin_module_names)
                contents = html.multicolumn(names, bltinlink)
                indices = ['<p>' + html.bigsection(
                    'Built-in Modules', '#ffffff', '#ee77aa', contents)]

                seen = {}
                for dir in sys.path:
                    indices.append(html.index(dir, seen))
                contents = heading + join(indices) + '''<p align=right>
<font color="#909090" face="helvetica, arial"><strong>
pydoc</strong> by Ka-Ping Yee &lt;ping@lfw.org&gt;</font>'''
                self.send_document('Index of Modules', contents)

        def log_message(self, *args): pass

    class DocServer(BaseHTTPServer.HTTPServer):
        def __init__(self, port, callback):
            host = 'localhost'
            self.address = (host, port)
            self.url = 'http://%s:%d/' % (host, port)
            self.callback = callback
            self.base.__init__(self, self.address, self.handler)

        def serve_until_quit(self):
            import select
            self.quit = False
            while not self.quit:
                rd, wr, ex = select.select([self.socket.fileno()], [], [], 1)
                if rd: self.handle_request()

        def server_activate(self):
            self.base.server_activate(self)
            if self.callback: self.callback(self)

    DocServer.base = BaseHTTPServer.HTTPServer
    DocServer.handler = DocHandler
    DocHandler.MessageClass = Message
    try:
        try:
            DocServer(port, callback).serve_until_quit()
        except (KeyboardInterrupt, select.error):
            pass
    finally:
        if completer: completer()

# ----------------------------------------------------- graphical interface

def gui():
    """Graphical interface (starts web server and pops up a control window)."""
    class GUI:
        def __init__(self, window, port=7464):
            self.window = window
            self.server = None
            self.scanner = None

            import Tkinter
            self.server_frm = Tkinter.Frame(window)
            self.title_lbl = Tkinter.Label(self.server_frm,
                text='Starting server...\n ')
            self.open_btn = Tkinter.Button(self.server_frm,
                text='open browser', command=self.open, state='disabled')
            self.quit_btn = Tkinter.Button(self.server_frm,
                text='quit serving', command=self.quit, state='disabled')

            self.search_frm = Tkinter.Frame(window)
            self.search_lbl = Tkinter.Label(self.search_frm, text='Search for')
            self.search_ent = Tkinter.Entry(self.search_frm)
            self.search_ent.bind('<Return>', self.search)
            self.stop_btn = Tkinter.Button(self.search_frm,
                text='stop', pady=0, command=self.stop, state='disabled')
            if sys.platform == 'win32':
                # Trying to hide and show this button crashes under Windows.
                self.stop_btn.pack(side='right')

            self.window.title('pydoc')
            self.window.protocol('WM_DELETE_WINDOW', self.quit)
            self.title_lbl.pack(side='top', fill='x')
            self.open_btn.pack(side='left', fill='x', expand=1)
            self.quit_btn.pack(side='right', fill='x', expand=1)
            self.server_frm.pack(side='top', fill='x')

            self.search_lbl.pack(side='left')
            self.search_ent.pack(side='right', fill='x', expand=1)
            self.search_frm.pack(side='top', fill='x')
            self.search_ent.focus_set()

            font = ('helvetica', sys.platform == 'win32' and 8 or 10)
            self.result_lst = Tkinter.Listbox(window, font=font, height=6)
            self.result_lst.bind('<Button-1>', self.select)
            self.result_lst.bind('<Double-Button-1>', self.goto)
            self.result_scr = Tkinter.Scrollbar(window,
                orient='vertical', command=self.result_lst.yview)
            self.result_lst.config(yscrollcommand=self.result_scr.set)

            self.result_frm = Tkinter.Frame(window)
            self.goto_btn = Tkinter.Button(self.result_frm,
                text='go to selected', command=self.goto)
            self.hide_btn = Tkinter.Button(self.result_frm,
                text='hide results', command=self.hide)
            self.goto_btn.pack(side='left', fill='x', expand=1)
            self.hide_btn.pack(side='right', fill='x', expand=1)

            self.window.update()
            self.minwidth = self.window.winfo_width()
            self.minheight = self.window.winfo_height()
            self.bigminheight = (self.server_frm.winfo_reqheight() +
                                 self.search_frm.winfo_reqheight() +
                                 self.result_lst.winfo_reqheight() +
                                 self.result_frm.winfo_reqheight())
            self.bigwidth, self.bigheight = self.minwidth, self.bigminheight
            self.expanded = 0
            self.window.wm_geometry('%dx%d' % (self.minwidth, self.minheight))
            self.window.wm_minsize(self.minwidth, self.minheight)
            self.window.tk.willdispatch()

            import threading
            threading.Thread(
                target=serve, args=(port, self.ready, self.quit)).start()

        def ready(self, server):
            self.server = server
            self.title_lbl.config(
                text='Python documentation server at\n' + server.url)
            self.open_btn.config(state='normal')
            self.quit_btn.config(state='normal')

        def open(self, event=None, url=None):
            url = url or self.server.url
            try:
                import webbrowser
                webbrowser.open(url)
            except ImportError: # pre-webbrowser.py compatibility
                if sys.platform == 'win32':
                    os.system('start "%s"' % url)
                else:
                    rc = os.system('netscape -remote "openURL(%s)" &' % url)
                    if rc: os.system('netscape "%s" &' % url)

        def quit(self, event=None):
            if self.server:
                self.server.quit = 1
            self.window.quit()

        def search(self, event=None):
            key = self.search_ent.get()
            self.stop_btn.pack(side='right')
            self.stop_btn.config(state='normal')
            self.search_lbl.config(text='Searching for "%s"...' % key)
            self.search_ent.forget()
            self.search_lbl.pack(side='left')
            self.result_lst.delete(0, 'end')
            self.goto_btn.config(state='disabled')
            self.expand()

            import threading
            if self.scanner:
                self.scanner.quit = 1
            self.scanner = ModuleScanner()
            threading.Thread(target=self.scanner.run,
                             args=(self.update, key, self.done)).start()

        def update(self, path, modname, desc):
            if modname[-9:] == '.__init__':
                modname = modname[:-9] + ' (package)'
            self.result_lst.insert('end',
                modname + ' - ' + (desc or '(no description)'))

        def stop(self, event=None):
            if self.scanner:
                self.scanner.quit = 1
                self.scanner = None

        def done(self):
            self.scanner = None
            self.search_lbl.config(text='Search for')
            self.search_lbl.pack(side='left')
            self.search_ent.pack(side='right', fill='x', expand=1)
            if sys.platform != 'win32': self.stop_btn.forget()
            self.stop_btn.config(state='disabled')

        def select(self, event=None):
            self.goto_btn.config(state='normal')

        def goto(self, event=None):
            selection = self.result_lst.curselection()
            if selection:
                modname = split(self.result_lst.get(selection[0]))[0]
                self.open(url=self.server.url + modname + '.html')

        def collapse(self):
            if not self.expanded: return
            self.result_frm.forget()
            self.result_scr.forget()
            self.result_lst.forget()
            self.bigwidth = self.window.winfo_width()
            self.bigheight = self.window.winfo_height()
            self.window.wm_geometry('%dx%d' % (self.minwidth, self.minheight))
            self.window.wm_minsize(self.minwidth, self.minheight)
            self.expanded = 0

        def expand(self):
            if self.expanded: return
            self.result_frm.pack(side='bottom', fill='x')
            self.result_scr.pack(side='right', fill='y')
            self.result_lst.pack(side='top', fill='both', expand=1)
            self.window.wm_geometry('%dx%d' % (self.bigwidth, self.bigheight))
            self.window.wm_minsize(self.minwidth, self.bigminheight)
            self.expanded = 1

        def hide(self, event=None):
            self.stop()
            self.collapse()

    import Tkinter
    try:
        root = Tkinter.Tk()
        # Tk will crash if pythonw.exe has an XP .manifest
        # file and the root has is not destroyed explicitly.
        # If the problem is ever fixed in Tk, the explicit
        # destroy can go.
        try:
            gui = GUI(root)
            root.mainloop()
        finally:
            root.destroy()
    except KeyboardInterrupt:
        pass

# -------------------------------------------------- command-line interface

def ispath(x):
    return isinstance(x, str) and find(x, os.sep) >= 0

def cli():
    """Command-line interface (looks at sys.argv to decide what to do)."""
    import getopt
    class BadUsage: pass

    # Scripts don't get the current directory in their path by default
    # unless they are run with the '-m' switch
    if '' not in sys.path:
        scriptdir = os.path.dirname(sys.argv[0])
        if scriptdir in sys.path:
            sys.path.remove(scriptdir)
        sys.path.insert(0, '.')

    try:
        opts, args = getopt.getopt(sys.argv[1:], 'gk:p:w')
        writing = 0

        for opt, val in opts:
            if opt == '-g':
                gui()
                return
            if opt == '-k':
                apropos(val)
                return
            if opt == '-p':
                try:
                    port = int(val)
                except ValueError:
                    raise BadUsage
                def ready(server):
                    print 'pydoc server ready at %s' % server.url
                def stopped():
                    print 'pydoc server stopped'
                serve(port, ready, stopped)
                return
            if opt == '-w':
                writing = 1

        if not args: raise BadUsage
        for arg in args:
            if ispath(arg) and not os.path.exists(arg):
                print 'file %r does not exist' % arg
                break
            try:
                if ispath(arg) and os.path.isfile(arg):
                    arg = importfile(arg)
                if writing:
                    if ispath(arg) and os.path.isdir(arg):
                        writedocs(arg)
                    else:
                        writedoc(arg)
                else:
                    help.help(arg)
            except ErrorDuringImport, value:
                print value

    except (getopt.error, BadUsage):
        cmd = os.path.basename(sys.argv[0])
        print """pydoc - the Python documentation tool

%s <name> ...
    Show text documentation on something.  <name> may be the name of a
    Python keyword, topic, function, module, or package, or a dotted
    reference to a class or function within a module or module in a
    package.  If <name> contains a '%s', it is used as the path to a
    Python source file to document. If name is 'keywords', 'topics',
    or 'modules', a listing of these things is displayed.

%s -k <keyword>
    Search for a keyword in the synopsis lines of all available modules.

%s -p <port>
    Start an HTTP server on the given port on the local machine.

%s -g
    Pop up a graphical interface for finding and serving documentation.

%s -w <name> ...
    Write out the HTML documentation for a module to a file in the current
    directory.  If <name> contains a '%s', it is treated as a filename; if
    it names a directory, documentation is written for all the contents.
""" % (cmd, os.sep, cmd, cmd, cmd, cmd, os.sep)

if __name__ == '__main__': cli()

########NEW FILE########
__FILENAME__ = reindent-pox
#! /usr/bin/env python

# Released to the public domain, by Tim Peters, 03 October 2000.

"""reindent [-d][-r][-v] [ path ... ]

-d (--dryrun)   Dry run.   Analyze, but don't make any changes to, files.
-r (--recurse)  Recurse.   Search for all .py files in subdirectories too.
-n (--nobackup) No backup. Does not make a ".bak" file before reindenting.
-v (--verbose)  Verbose.   Print informative msgs; else no output.
-h (--help)     Help.      Print this usage information and exit.

Change Python (.py) files to use 2-space indents and no hard tab characters.
Also trim excess spaces and tabs from ends of lines, and remove empty lines
at the end of files.  Also ensure the last line ends with a newline.

If no paths are given on the command line, reindent operates as a filter,
reading a single source file from standard input and writing the transformed
source to standard output.  In this case, the -d, -r and -v flags are
ignored.

You can pass one or more file and/or directory paths.  When a directory
path, all .py files within the directory will be examined, and, if the -r
option is given, likewise recursively for subdirectories.

If output is not to standard output, reindent overwrites files in place,
renaming the originals with a .bak extension.  If it finds nothing to
change, the file is left alone.  If reindent does change a file, the changed
file is a fixed-point for future runs (i.e., running reindent on the
resulting .py file won't change it again).

The hard part of reindenting is figuring out what to do with comment
lines.  So long as the input files get a clean bill of health from
tabnanny.py, reindent should do a good job.

The backup file is a copy of the one that is being reindented. The ".bak"
file is generated with shutil.copy(), but some corner cases regarding
user/group and permissions could leave the backup file more readable that
you'd prefer. You can always use the --nobackup option to prevent this.
"""

__version__ = "1"

import tokenize
import os, shutil
import sys

verbose    = 0
recurse    = 0
dryrun     = 0
makebackup = True

def usage(msg=None):
    if msg is not None:
        print >> sys.stderr, msg
    print >> sys.stderr, __doc__

def errprint(*args):
    sep = ""
    for arg in args:
        sys.stderr.write(sep + str(arg))
        sep = " "
    sys.stderr.write("\n")

def main():
    import getopt
    global verbose, recurse, dryrun, makebackup
    try:
        opts, args = getopt.getopt(sys.argv[1:], "drnvh",
                        ["dryrun", "recurse", "nobackup", "verbose", "help"])
    except getopt.error, msg:
        usage(msg)
        return
    for o, a in opts:
        if o in ('-d', '--dryrun'):
            dryrun += 1
        elif o in ('-r', '--recurse'):
            recurse += 1
        elif o in ('-n', '--nobackup'):
            makebackup = False
        elif o in ('-v', '--verbose'):
            verbose += 1
        elif o in ('-h', '--help'):
            usage()
            return
    if not args:
        r = Reindenter(sys.stdin)
        r.run()
        r.write(sys.stdout)
        return
    for arg in args:
        check(arg)

def check(file):
    if os.path.isdir(file) and not os.path.islink(file):
        if verbose:
            print "listing directory", file
        names = os.listdir(file)
        for name in names:
            fullname = os.path.join(file, name)
            if ((recurse and os.path.isdir(fullname) and
                 not os.path.islink(fullname) and
                 not os.path.split(fullname)[1].startswith("."))
                or name.lower().endswith(".py")):
                check(fullname)
        return

    if verbose:
        print "checking", file, "...",
    try:
        f = open(file)
    except IOError, msg:
        errprint("%s: I/O Error: %s" % (file, str(msg)))
        return

    r = Reindenter(f)
    f.close()
    if r.run():
        if verbose:
            print "changed."
            if dryrun:
                print "But this is a dry run, so leaving it alone."
        if not dryrun:
            bak = file + ".bak"
            if makebackup:
                shutil.copyfile(file, bak)
                if verbose:
                    print "backed up", file, "to", bak
            f = open(file, "w")
            r.write(f)
            f.close()
            if verbose:
                print "wrote new", file
        return True
    else:
        if verbose:
            print "unchanged."
        return False

def _rstrip(line, JUNK='\n \t'):
    """Return line stripped of trailing spaces, tabs, newlines.

    Note that line.rstrip() instead also strips sundry control characters,
    but at least one known Emacs user expects to keep junk like that, not
    mentioning Barry by name or anything <wink>.
    """

    i = len(line)
    while i > 0 and line[i-1] in JUNK:
        i -= 1
    return line[:i]

class Reindenter:

    def __init__(self, f):
        self.find_stmt = 1  # next token begins a fresh stmt?
        self.level = 0      # current indent level

        # Raw file lines.
        self.raw = f.readlines()

        # File lines, rstripped & tab-expanded.  Dummy at start is so
        # that we can use tokenize's 1-based line numbering easily.
        # Note that a line is all-blank iff it's "\n".
        self.lines = [_rstrip(line).expandtabs() + "\n"
                      for line in self.raw]
        self.lines.insert(0, None)
        self.index = 1  # index into self.lines of next line

        # List of (lineno, indentlevel) pairs, one for each stmt and
        # comment line.  indentlevel is -1 for comment lines, as a
        # signal that tokenize doesn't know what to do about them;
        # indeed, they're our headache!
        self.stats = []

    def run(self):
        tokenize.tokenize(self.getline, self.tokeneater)
        # Remove trailing empty lines.
        lines = self.lines
        while lines and lines[-1] == "\n":
            lines.pop()
        # Sentinel.
        stats = self.stats
        stats.append((len(lines), 0))
        # Map count of leading spaces to # we want.
        have2want = {}
        # Program after transformation.
        after = self.after = []
        # Copy over initial empty lines -- there's nothing to do until
        # we see a line with *something* on it.
        i = stats[0][0]
        after.extend(lines[1:i])
        for i in range(len(stats)-1):
            thisstmt, thislevel = stats[i]
            nextstmt = stats[i+1][0]
            have = getlspace(lines[thisstmt])
            want = thislevel * 2
            if want < 0:
                # A comment line.
                if have:
                    # An indented comment line.  If we saw the same
                    # indentation before, reuse what it most recently
                    # mapped to.
                    want = have2want.get(have, -1)
                    if want < 0:
                        # Then it probably belongs to the next real stmt.
                        for j in xrange(i+1, len(stats)-1):
                            jline, jlevel = stats[j]
                            if jlevel >= 0:
                                if have == getlspace(lines[jline]):
                                    want = jlevel * 2
                                break
                    if want < 0:           # Maybe it's a hanging
                                           # comment like this one,
                        # in which case we should shift it like its base
                        # line got shifted.
                        for j in xrange(i-1, -1, -1):
                            jline, jlevel = stats[j]
                            if jlevel >= 0:
                                want = have + getlspace(after[jline-1]) - \
                                       getlspace(lines[jline])
                                break
                    if want < 0:
                        # Still no luck -- leave it alone.
                        want = have
                else:
                    want = 0
            assert want >= 0
            have2want[have] = want
            diff = want - have
            if diff == 0 or have == 0:
                after.extend(lines[thisstmt:nextstmt])
            else:
                for line in lines[thisstmt:nextstmt]:
                    if diff > 0:
                        if line == "\n":
                            after.append(line)
                        else:
                            after.append(" " * diff + line)
                    else:
                        remove = min(getlspace(line), -diff)
                        after.append(line[remove:])
        return self.raw != self.after

    def write(self, f):
        f.writelines(self.after)

    # Line-getter for tokenize.
    def getline(self):
        if self.index >= len(self.lines):
            line = ""
        else:
            line = self.lines[self.index]
            self.index += 1
        return line

    # Line-eater for tokenize.
    def tokeneater(self, type, token, (sline, scol), end, line,
                   INDENT=tokenize.INDENT,
                   DEDENT=tokenize.DEDENT,
                   NEWLINE=tokenize.NEWLINE,
                   COMMENT=tokenize.COMMENT,
                   NL=tokenize.NL):

        if type == NEWLINE:
            # A program statement, or ENDMARKER, will eventually follow,
            # after some (possibly empty) run of tokens of the form
            #     (NL | COMMENT)* (INDENT | DEDENT+)?
            self.find_stmt = 1

        elif type == INDENT:
            self.find_stmt = 1
            self.level += 1

        elif type == DEDENT:
            self.find_stmt = 1
            self.level -= 1

        elif type == COMMENT:
            if self.find_stmt:
                self.stats.append((sline, -1))
                # but we're still looking for a new stmt, so leave
                # find_stmt alone

        elif type == NL:
            pass

        elif self.find_stmt:
            # This is the first "real token" following a NEWLINE, so it
            # must be the first token of the next program statement, or an
            # ENDMARKER.
            self.find_stmt = 0
            if line:   # not endmarker
                self.stats.append((sline, self.level))

# Count number of leading blanks.
def getlspace(line):
    i, n = 0, len(line)
    while i < n and line[i] == " ":
        i += 1
    return i

if __name__ == '__main__':
    main()

########NEW FILE########
