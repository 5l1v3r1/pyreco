__FILENAME__ = conf
# -*- coding: utf-8 -*-
#
# Drogulus documentation build configuration file, created by
# sphinx-quickstart on Tue Mar 13 15:19:40 2012.
#
# This file is execfile()d with the current directory set to its containing
# dir.
#
# Note that not all possible configuration values are present in this
# autogenerated file.
#
# All configuration values have a default; values that are commented out
# serve to show the default.

import sys
import os
import sphinx_bootstrap_theme

# If extensions (or modules to document with autodoc) are in another directory,
# add these directories to sys.path here. If the directory is relative to the
# documentation root, use os.path.abspath to make it absolute, like shown here.
sys.path.insert(0, os.path.abspath('..'))
from drogulus.version import get_version, VERSION

# -- General configuration ----------------------------------------------------

# If your documentation needs a minimal Sphinx version, state it here.
#needs_sphinx = '1.0'

# Add any Sphinx extension module names here, as strings. They can be
# extensions coming with Sphinx (named 'sphinx.ext.*') or your custom ones.
extensions = ['sphinx.ext.autodoc', 'sphinx.ext.viewcode']

# Add any paths that contain templates here, relative to this directory.
templates_path = ['_templates']

# The suffix of source filenames.
source_suffix = '.rst'

# The encoding of source files.
#source_encoding = 'utf-8-sig'

# The master toctree document.
master_doc = 'index'

# General information about the project.
project = u'Drogulus'
copyright = u'2012-2013, Nicholas H.Tollervey'

# The version info for the project you're documenting, acts as replacement for
# |version| and |release|, also used in various other places throughout the
# built documents.
#
# The short X.Y version.
version = '.'.join([str(i) for i in VERSION[:2]])
# The full version, including alpha/beta/rc tags.
release = get_version()

# The language for content autogenerated by Sphinx. Refer to documentation
# for a list of supported languages.
#language = None

# There are two options for replacing |today|: either, you set today to some
# non-false value, then it is used:
#today = ''
# Else, today_fmt is used as the format for a strftime call.
#today_fmt = '%B %d, %Y'

# List of patterns, relative to source directory, that match files and
# directories to ignore when looking for source files.
exclude_patterns = ['_build']

# The reST default role (used for this markup: `text`) to use for all
# documents.
#default_role = None

# If true, '()' will be appended to :func: etc. cross-reference text.
#add_function_parentheses = True

# If true, the current module name will be prepended to all description
# unit titles (such as .. function::).
#add_module_names = True

# If true, sectionauthor and moduleauthor directives will be shown in the
# output. They are ignored by default.
#show_authors = False

# The name of the Pygments (syntax highlighting) style to use.
pygments_style = 'sphinx'

# A list of ignored prefixes for module index sorting.
#modindex_common_prefix = []


# -- Options for HTML output --------------------------------------------------

# The theme to use for HTML and HTML Help pages.  See the documentation for
# a list of builtin themes.
html_theme = 'bootstrap'
html_theme_path = sphinx_bootstrap_theme.get_html_theme_path()

# Theme options are theme-specific and customize the look and feel of a theme
# further.  For a list of options available for each theme, see the
# documentation.
html_theme_options = {
    'source_link_position': 'None',
}

# Add any paths that contain custom themes here, relative to this directory.
#html_theme_path = []

# The name for this set of Sphinx documents.  If None, it defaults to
# "<project> v<release> documentation".
#html_title = None

# A shorter title for the navigation bar.  Default is the same as html_title.
#html_short_title = None

# The name of an image file (relative to this directory) to place at the top
# of the sidebar.
#html_logo = None

# The name of an image file (within the static path) to use as favicon of the
# docs.  This file should be a Windows icon file (.ico) being 16x16 or 32x32
# pixels large.
#html_favicon = None

# Add any paths that contain custom static files (such as style sheets) here,
# relative to this directory. They are copied after the builtin static files,
# so a file named "default.css" will overwrite the builtin "default.css".
html_static_path = ['_static']

# If not '', a 'Last updated on:' timestamp is inserted at every page bottom,
# using the given strftime format.
#html_last_updated_fmt = '%b %d, %Y'

# If true, SmartyPants will be used to convert quotes and dashes to
# typographically correct entities.
#html_use_smartypants = True

# Custom sidebar templates, maps document names to template names.
#html_sidebars = {}

# Additional templates that should be rendered to pages, maps page names to
# template names.
#html_additional_pages = {}

# If false, no module index is generated.
#html_domain_indices = True

# If false, no index is generated.
#html_use_index = True

# If true, the index is split into individual pages for each letter.
#html_split_index = False

# If true, links to the reST sources are added to the pages.
#html_show_sourcelink = True

# If true, "Created using Sphinx" is shown in the HTML footer. Default is True.
#html_show_sphinx = True

# If true, "(C) Copyright ..." is shown in the HTML footer. Default is True.
#html_show_copyright = True

# If true, an OpenSearch description file will be output, and all pages will
# contain a <link> tag referring to it.  The value of this option must be the
# base URL from which the finished HTML is served.
#html_use_opensearch = ''

# This is the file name suffix for HTML files (e.g. ".xhtml").
#html_file_suffix = None

# Output file base name for HTML help builder.
htmlhelp_basename = 'Drogulusdoc'


# -- Options for LaTeX output -------------------------------------------------

# The paper size ('letter' or 'a4').
#latex_paper_size = 'letter'

# The font size ('10pt', '11pt' or '12pt').
#latex_font_size = '10pt'

# Grouping the document tree into LaTeX files. List of tuples
# (source start file, target name, title, author, documentclass
# [howto/manual]).
latex_documents = [('index', 'Drogulus.tex', u'Drogulus Documentation',
                   u'Nicholas H.Tollervey', 'manual'), ]

# The name of an image file (relative to this directory) to place at the top of
# the title page.
#latex_logo = None

# For "manual" documents, if this is true, then toplevel headings are parts,
# not chapters.
#latex_use_parts = False

# If true, show page references after internal links.
#latex_show_pagerefs = False

# If true, show URL addresses after external links.
#latex_show_urls = False

# Additional stuff for the LaTeX preamble.
#latex_preamble = ''

# Documents to append as an appendix to all manuals.
#latex_appendices = []

# If false, no module index is generated.
#latex_domain_indices = True


# -- Options for manual page output -------------------------------------------

# One entry per manual page. List of tuples
# (source start file, name, description, authors, manual section).
man_pages = [
    ('index', 'drogulus', u'Drogulus Documentation',
     [u'Nicholas H.Tollervey'], 1)
]


# -- Options for Epub output --------------------------------------------------

# Bibliographic Dublin Core info.
epub_title = u'Drogulus'
epub_author = u'Nicholas H.Tollervey'
epub_publisher = u'Nicholas H.Tollervey'
epub_copyright = u'2012-2013, Nicholas H.Tollervey'

# The language of the text. It defaults to the language option
# or en if the language is not set.
#epub_language = ''

# The scheme of the identifier. Typical schemes are ISBN or URL.
#epub_scheme = ''

# The unique identifier of the text. This can be a ISBN number
# or the project homepage.
#epub_identifier = ''

# A unique identification for the text.
#epub_uid = ''

# HTML files that should be inserted before the pages created by sphinx.
# The format is a list of tuples containing the path and title.
#epub_pre_files = []

# HTML files shat should be inserted after the pages created by sphinx.
# The format is a list of tuples containing the path and title.
#epub_post_files = []

# A list of files that should not be packed into the epub file.
#epub_exclude_files = []

# The depth of the table of contents in toc.ncx.
#epub_tocdepth = 3

# Allow duplicate toc entries.
#epub_tocdup = True

########NEW FILE########
__FILENAME__ = constants
# -*- coding: utf-8 -*-
"""
Defines constants used by the Kademlia DHT network. Where possible naming is
derived from the original Kademlia paper as are the suggested default values.
"""

# Copyright (C) 2012-2013 Nicholas H.Tollervey.
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU Affero General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU Affero General Public License for more details.
#
# You should have received a copy of the GNU Affero General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.

#: Represents the degree of parallelism in network calls.
ALPHA = 3

#: The maximum number of contacts stored in a k-bucket. Must be an even number.
K = 20

#: The default maximum time a NodeLookup is allowed to take (in seconds).
LOOKUP_TIMEOUT = 600

#: The timeout for network connections (in seconds).
RPC_TIMEOUT = 5

#: The timeout for receiving complete message once a connection is made (in
#: seconds). Ensures there are no stale deferreds in the node's _pending
#: dictionary.
RESPONSE_TIMEOUT = 1800  # half an hour

#: How long to wait before an unused k-bucket is refreshed (in seconds).
REFRESH_TIMEOUT = 3600  # 1 hour

#: How long to wait before a node replicates any data it stores (in seconds).
REPLICATE_INTERVAL = REFRESH_TIMEOUT

#: How long to wait before a node checks whether any buckets need refreshing or
#: data needs republishing (in seconds).
REFRESH_INTERVAL = REFRESH_TIMEOUT / 6  # Every 10 minutes.

#: The number of failed remote procedure calls allowed for a contact. If this
#: is equalled or exceeded then the contact is removed from the routing table.
ALLOWED_RPC_FAILS = 5

#: The number of nodes to attempt to use to store a value in the DHT.
DUPLICATION_COUNT = K

#: The duration (in seconds) that is added to a value's creation time in order
#: to work out its expiry timestamp. -1 denotes no expiry point.
EXPIRY_DURATION = -1

#: Defines the errors that can be reported between nodes in the DHT.
ERRORS = {
    # The request simply didn't make any sense.
    1: 'Bad request',
    # The request was parsed but not recognised.
    2: 'Unknown request',
    # The request was parsed and recognised but the node encountered a problem
    # when dealing with it.
    3: 'Internal error',
    # The request was too big for the node to handle.
    4: 'Request too big',
    # Unsupported version of the protocol.
    5: 'Unsupported protocol',
    # The request could not be cryptographically verified.
    6: 'Unverifiable provenance',
    # The key for an item did not match as expected.
    7: 'Key mismatch',
    # The value is superceded (a newer version is known to the node already).
    8: 'Superceded value'
}

########NEW FILE########
__FILENAME__ = crypto
# -*- coding: utf-8 -*-
"""
Contains functions for cryptographically signing / verifying items stored in
the DHT.
"""

# Copyright (C) 2012-2013 Nicholas H.Tollervey.
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU Affero General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU Affero General Public License for more details.
#
# You should have received a copy of the GNU Affero General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.

from Crypto.PublicKey import RSA
from Crypto.Hash import SHA512
from Crypto.Signature import PKCS1_v1_5
import msgpack


def construct_hash(value, timestamp, expires, name, meta, created_with):
    """
    The hash is a SHA512 hash of the concatenated SHA512 hashes of the
    msgpack encoded 'value', 'timetamp, 'expires', 'name', 'meta' and
    'created_with' fields (in that order).

    It ensures that the 'value', 'timestamp', 'expires', 'name', 'meta' and
    'created_with' fields have not been tampered with.
    """
    hashes = []
    for item in (value, timestamp, expires, name, meta, created_with):
        packed = msgpack.packb(item)
        hashed = SHA512.new(packed).digest()
        hashes.append(hashed)
    compound_hashes = ''.join(hashes)
    return SHA512.new(compound_hashes)


def construct_key(public_key, name=''):
    """
    Given a string representation of a user's public key and the human
    readable string to use as a key in the DHT this function will return a
    digest of the SHA512 hash to use as the actual key to use within the DHT.

    This ensures that the provenance (public key) and meaning of the key
    determine its value in the DHT.
    """
    # Simple normalisation: no spaces or newlines around the public key
    key_hash = SHA512.new(public_key.strip())
    if name:
        # If the key has a meaningful name, create a compound key based upon
        # the SHA512 values of both the public_key and name.
        name_hash = SHA512.new(name)
        compound_key = key_hash.digest() + name_hash.digest()
        compound_hash = SHA512.new(compound_key)
        return compound_hash.digest()
    else:
        # Not a compound key, so just return the hash of the public_key
        return key_hash.digest()


def generate_signature(value, timestamp, expires, name, meta, created_with,
                       private_key):
    """
    Given the value, timestamp, expires, name, meta and created_with values of
    an outgoing value carrying message will use the private key to generate a
    cryptographic hash to the message to be used to sign / validate the
    message.

    This ensures that the 'value', 'timestamp', 'expires', 'name', 'meta' and
    'created_with' fields have not been tampered with.

    The hash is created with the private key of the person storing the
    key/value pair. It is, in turn, based upon the SHA512 hash of the SHA512
    hashes of the 'value', 'timestamp', 'expires', 'name', 'meta' and
    'created_with' fields.
    """
    compound_hash = construct_hash(value, timestamp, expires, name, meta,
                                   created_with)
    key = RSA.importKey(private_key)
    signer = PKCS1_v1_5.new(key)
    return signer.sign(compound_hash)


def validate_signature(value, timestamp, expires, name, meta, created_with,
                       signature, public_key):
    """
    Uses the public key to validate the cryptographic signature based upon
    a hash of the values in the 'value', 'timestamp', 'expires', 'name', 'meta'
    and 'created_with' fields of a value carrying message.
    """
    generated_hash = construct_hash(value, timestamp, expires, name, meta,
                                    created_with)
    try:
        public_key = RSA.importKey(public_key.strip())
    except ValueError:
        # Catches malformed public keys.
        return False
    verifier = PKCS1_v1_5.new(public_key)
    return verifier.verify(generated_hash, signature)


def validate_message(message):
    """
    Given an item stored within the DHT this function will return a tuple
    containing two fields:

    * a boolean to indicate its validity,
    * an error number based upon constants.ERRORS (in the case of a fail) or
      None (if success).

    The message contains a public_key field which is used to validate the
    message's 'sig' field with a list of SHA512 hashes of the message's
    'value', 'timestamp', 'name', 'meta' and 'created_with' fields. This proves
    the provenance of the data and ensures that these fields have not been
    tampered with.

    Furthermore, once the validity of the public_key field is proven through
    the proceeding check, the 'key' field is verified to be a SHA512 hash of
    the SHA512 hashes of the 'public_key' and 'name' fields. This ensures the
    correct key is used to locate the data in the DHT.
    """
    if not validate_signature(message.value, message.timestamp,
                              message.expires, message.name, message.meta,
                              message.created_with, message.sig,
                              message.public_key):
        # Invalid signature so bail with the appropriate error number
        return (False, 6)
    # If the signature is correct then the public key must be valid. Ensure
    # that the key used to store the value in the DHT is valid.
    generated_key = construct_key(message.public_key, message.name)
    if generated_key != message.key:
        # The key cannot be derived from the public_key and name fields.
        return (False, 7)
    # It checks out so return truthy.
    return (True, None)

########NEW FILE########
__FILENAME__ = contact
# -*- coding: utf-8 -*-
"""
Defines a contact (another node) on the network.
"""

# Copyright (C) 2012-2013 Nicholas H.Tollervey.
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU Affero General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU Affero General Public License for more details.
#
# You should have received a copy of the GNU Affero General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.
from drogulus.utils import long_to_hex


class Contact(object):
    """
    Represents another known node on the network.
    """

    def __init__(self, id, address, port, version, last_seen=0):
        """
        Initialises the contact object with its unique id within the DHT, IP
        address, port, the Drogulus version the contact is running and a
        timestamp when the last connection was made with the contact (defaults
        to 0). The id, if passed in as a numeric value, will be converted into
        a hexadecimal string.
        """
        if isinstance(id, long) or isinstance(id, int):
            self.id = long_to_hex(id)
        else:
            self.id = id
        self.address = address
        self.port = port
        self.version = version
        self.last_seen = last_seen
        # failed_RPCs keeps track of the number of failed RPCs to this contact.
        # If this number reaches a threshold then it is evicted from the
        # kbucket and replaced with a contact that is more reliable.
        self.failed_RPCs = 0

    def __eq__(self, other):
        """
        Override equals to work with a string representation of the contact's
        id.
        """
        if isinstance(other, Contact):
            return self.id == other.id
        elif isinstance(other, str):
            return self.id == other
        else:
            return False

    def __ne__(self, other):
        """
        Override != to work with a string representation of the contact's id.
        """
        return not self == other

    def __repr__(self):
        """
        Returns a tuple containing information about this contact.
        """
        return str((self.id, self.address, self.port, self.version,
                    self.last_seen, self.failed_RPCs))

    def __str__(self):
        """
        Override the string representation of the object to be something
        useful.
        """
        return self.__repr__()

########NEW FILE########
__FILENAME__ = datastore
# -*- coding: utf-8 -*-
"""
Contains class definitions that define the local data store for the node.
"""

# Copyright (C) 2012-2013 Nicholas H.Tollervey.
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU Affero General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU Affero General Public License for more details.
#
# You should have received a copy of the GNU Affero General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.

import UserDict
import time


class DataStore(UserDict.DictMixin):
    """
    Base class for implementations of the storage mechanism for the DHT.
    """

    def keys(self):
        """
        Return a list of the keys in this data store.
        """
        return NotImplemented

    def last_updated(self, key):
        """
        Get the time that a key/value pair identified by the key were last
        updated in this data store.
        """
        return NotImplemented

    def original_publisher_id(self, key):
        """
        Get the node ID of the original publisher of the key/value pair
        identified by "key".
        """
        return NotImplemented

    def original_publish_time(self, key):
        """
        Get the time that key was originally published.
        """
        return NotImplemented

    def set_item(self, key, value):
        """
        Set the value of the key/value pair identified by "key"; this should
        set the "last published" value for the key/value pair to the current
        time.
        """
        return NotImplemented

    def __getitem__(self, key):
        """
        Get the value identified by "key".
        """
        return NotImplemented

    def __setitem__(self, key, value):
        """
        Convenience wrapper to setItem. This accepts a tuple of the format:
        (value, lastPublished, originallyPublished, originalPublisherID).
        """
        self.set_item(key, value)

    def __delitem__(self, key):
        """
        Delete the specified key and associated value.
        """
        raise KeyError()


class DictDataStore(DataStore):
    """
    A datastore using Python's in-memory dictionary.
    """

    def __init__(self):
        self._dict = {}

    def keys(self):
        """
        Return a list of the keys in this data store.
        """
        return self._dict.keys()

    def last_updated(self, key):
        """
        Get the time the key/value pair identified by key was last updated in
        this data store.
        """
        return self._dict[key][1]

    def original_publisher_id(self, key):
        """
        Get the original publisher of the data's node ID.
        """
        return self._dict[key][0].public_key

    def original_publish_time(self, key):
        """
        Get the time the key/value pair identified by key was originally
        published
        """
        return self._dict[key][0].timestamp

    def set_item(self, key, value):
        """
        Set the value of the key/value pair identified by key.
        """
        last_updated = time.time()
        self._dict[key] = (value, last_updated)

    def __getitem__(self, key):
        """
        Get the value identified by key.
        """
        return self._dict[key][0]

    def __delitem__(self, key):
        """
        Delete the specified key (and its value)
        """
        del self._dict[key]

########NEW FILE########
__FILENAME__ = kbucket
# -*- coding: utf-8 -*-
"""
Defines contact related storage (the so called k-buckets).
"""

# Copyright (C) 2012-2013 Nicholas H.Tollervey.
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU Affero General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU Affero General Public License for more details.
#
# You should have received a copy of the GNU Affero General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.

from drogulus.constants import K
from drogulus.utils import hex_to_long


class KBucketFull(Exception):
    """ Raised when the bucket is full. """
    pass


class KBucket(object):
    """
    A bucket to store contact information about other nodes in the network.
    From the original Kademlia paper:

    "Kademlia nodes store contact information about each other to route query
    messages. For each 0 <= i < 160, every node keeps a list of <IP address,
    port, Node ID> triples for nodes of distance between 2i and 2(i+1) from
    itself. We call these lists k-buckets. Each k-bucket is kept sorted by time
    last seen -- least-recently seen node at the head, most-recently seen at
    the tail. For small values of i, the k-buckets will generally be empty (as
    no appropriate nodes will exist). For large values of i, the lists can
    grow to size k, where k is a system-wide replication parameter. k is
    chosen such that any given k nodes are very unlikely to fail within an
    hour of each other (for example k = 20)"

    Nota Bene: This implementation of Kademlia uses a 512 bit key space
    based upon SHA512 rather than the original 160 bit SHA1 implementation, so
    i will be < 512.
    """

    def __init__(self, range_min, range_max):
        """
        Initialises the object with the lower / upper bound limits of the
        k-bucket's 512-bit ID space.
        """
        self.range_min = range_min
        self.range_max = range_max
        # Holds the contacts for the k-bucket.
        self._contacts = []
        # Indicates when the k-bucket was last accessed. Used to make sure the
        # k-bucket doesn't become stale and out of date given changing
        # conditions in the network of contacts.
        self.last_accessed = 0

    def add_contact(self, contact):
        """
        Adds a contact to the k-bucket. If this is a new contact then it will
        be appended to the _contacts list. If the contact is already in the
        k-bucket then it is moved to the end of the _contacts list. The most
        recently seen contact is always at the end of the _contacts list. If
        the size of the k-bucket exceeds the constant k then a KBucketFull
        exception is raised.
        """
        if contact in self._contacts:
            self._contacts.remove(contact)
            self._contacts.append(contact)
        elif len(self._contacts) < K:
            self._contacts.append(contact)
        else:
            raise KBucketFull("No space in bucket to insert contact.")

    def get_contact(self, id):
        """
        Returns a contact stored in the k-bucket with the given id. Will raise
        a ValueError if the contact is not in the k-bucket (the default
        behaviour of calling ``index`` with a value that's not in the list).
        """
        index = self._contacts.index(id)
        return self._contacts[index]

    def get_contacts(self, count=0, exclude_contact=None):
        """
        Returns a list of up to "count" number of contacts within the
        k-bucket. If "count" is zero or less, then all contacts will be
        returned. If there are less than "count" number of contacts in the
        k-bucket, all contacts will be returned.

        If "exclude_contact" is passed (as either a Contact instance or id str)
        then, if this is found within the list of returned values, it will be
        discarded before the result is returned.
        """
        # Get current length of contact list.
        current_len = len(self._contacts)
        # Check count argument
        if count <= 0:
            # Return all contacts
            count = current_len
        if not self._contacts:
            # There are no contacts so return an empty list.
            contact_list = []
        elif current_len < count:
            # Number of contacts is less than requested amount so return all
            # contacts.
            contact_list = self._contacts[:current_len]
        else:
            # Enough contacts in the list, so only return the amount
            # requested.
            contact_list = self._contacts[:count]
        if exclude_contact in contact_list:
            # Remove the excluded contact.
            contact_list.remove(exclude_contact)
        return contact_list

    def remove_contact(self, id):
        """
        Removes a contact with the given id from the k-bucket.
        """
        self._contacts.remove(id)

    def key_in_range(self, key):
        """
        Checks if a key is within the range covered by this k-bucket. Returns
        a boolean to indicate if a certain key should be placed within this
        k-bucket.
        """
        if isinstance(key, str):
            key = hex_to_long(key)
        return self.range_min <= key < self.range_max

    def __len__(self):
        """
        Returns the number of contacts stored in this k-bucket.
        """
        return len(self._contacts)

########NEW FILE########
__FILENAME__ = node
# -*- coding: utf-8 -*-
"""
Contains code that defines the behaviour of the local node in the DHT network.
"""

# Copyright (C) 2012-2013 Nicholas H.Tollervey.
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU Affero General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU Affero General Public License for more details.
#
# You should have received a copy of the GNU Affero General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.

from twisted.python import log
from twisted.internet import reactor, defer
from twisted.internet.endpoints import clientFromString
import time
from uuid import uuid4

from drogulus import constants
from drogulus.utils import sort_contacts
from drogulus.net.messages import (Error, Ping, Pong, Store, FindNode, Nodes,
                                   FindValue, Value)
from drogulus.net.protocol import DHTFactory
from routingtable import RoutingTable
from datastore import DictDataStore
from contact import Contact
from drogulus.crypto import validate_message, construct_key
from drogulus.version import get_version


class RoutingTableEmpty(Exception):
    """
    Fired when a lookup is attempted without any peers in the local node's
    routing table.
    """
    pass


class ValueNotFound(Exception):
    """
    Fired when a NodeLookup cannot find a value associated with a specified
    key.
    """
    pass


def response_timeout(message, protocol, node):
    """
    Called when a pending message (identified with a uuid) awaiting a response
    via a given protocol object times-out. Closes the connection and removes
    the deferred from the "pending" dictionary.
    """
    uuid = message.uuid
    pending = node._pending
    if uuid in pending:
        pending[uuid].cancel()
        del pending[uuid]
        protocol.transport.abortConnection()
        node._routing_table.remove_contact(message.node)


class NodeLookup(defer.Deferred):
    """
    Encapsulates a lookup in the DHT given a particular target key and message
    type. Will callback when a result is found or errback otherwise. If
    defined, will timeout with an errback.

    From the original Kademlia paper:

    "The most important procedure a Kademlia participant must perform is to
    locate the k closest nodes to some given node ID. We call this procedure a
    node lookup. Kademlia employs a recursive algorithm for node lookups. The
    lookup initiator starts by picking α nodes from its closest non-empty
    k-bucket (or, if that bucket has fewer than α entries, it just takes the α
    closest nodes it knows of). The initiator then sends parallel, asynchronous
    FIND NODE RPCs to the α nodes it has chosen. α is a system-wide concurrency
    parameter, such as 3.

    In the recursive step, the initiator resends the FIND NODE to nodes it has
    learned about from previous RPCs. (This recursion can begin before all α of
    the previous RPCs have returned). Of the k nodes the initiator has heard of
    closest to the target, it picks α that it has not yet queried and resends
    the FIND NODE RPC to them. Nodes that fail to respond quickly are removed
    from consideration until and unless they do respond. If a round of FIND
    NODEs fails to return a node any closer than the closest already seen, the
    initiator resends the FIND NODE to all of the k closest nodes it has not
    already queried. The lookup terminates when the initiator has queried and
    gotten responses from the k closest nodes it has seen. When α = 1 the
    lookup algorithm resembles Chord’s in terms of message cost and the latency
    of detecting failed nodes. However, Kademlia can route for lower latency
    because it has the flexibility of choosing any one of k nodes to forward a
    request to."

    READ THIS CAREFULLY! Here's how this implementation works:

    self.target - the target key for the lookup.
    self.message_type - the message class (either FindNode or FindValue).
    self.local_node - the local node that created the NodeLookup.
    self.shortlist - an ordered list containing nodes close to the target.
    self.contacted - a set of nodes that have been contacted for this lookup.
    self.nearest_node - the node nearest to the target so far.
    self.pending_requests - a dictionary of currently pending requests.
    constants.ALPHA - the number of concurrent asynchronous calls allowed.
    constants.K - the number of closest nodes to return when complete.
    constants.LOOKUP_TIMEOUT - the default maximum duration for a lookup.

    0. If "timeout" number of seconds elapse before the lookup is finished then
       cancel any pending requests and errback with an OutOfTime error. The
       "timeout" value can be overridden but defaults to
       constants.LOOKUP_TIMEOUT seconds.

    1. Locally known nodes from the routing table seed self.shortlist.

    2. The nearest node to the target in self.shortlist is set as
       self.nearest_node.

    3. No more than constants.ALPHA nearest nodes that are in self.shortlist
       but not in self.contacted are sent a message that is an instance of
       self.message_type. Each request is added to the self.pending_requests
       list. The length of self.pending_requests must never be more than
       constants.ALPHA.

    4. As each node is contacted it is added to the self.contacted set.

    5. If a node doesn't reply or an error is encountered it is removed from
       self.shortlist and self.pending_requests. Start from step 3 again.

    6. When a response to a request is returned successfully remove the request
       from self.pending_requests.

    7. If it's a FindValue message and a suitable value is returned (see note
       at the end of these comments) cancel all the other pending calls in
       self.pending_requests and fire a callback with the returned value.
       If the value is invalid remove the node from self.shortlist and start
       from step 3 again without cancelling the other pending calls.

    8. If a list of closer nodes is returned by a peer add them to
       self.shortlist and sort - making sure nodes in self.contacted are not
       mistakenly re-added to the shortlist.

    9. If the nearest node in the newly sorted self.shortlist is closer to the
       target than self.nearest_node then set self.nearest_node to the new
       closer node and start from step 3 again.

    10. If self.nearest_node remains unchanged DO NOT start a new call.

    11. If there are no other requests in self.pending_requests then check that
        the constants.K nearest nodes in the self.contacted set are all closer
        than the nearest node in self.shortlist. If they are, and it's a
        FindNode message call back with the constants.K nearest nodes in the
        self.contacted set. If the message is a FindValue, errback with a
        ValueNotFound error.

    12. If there are still nearer nodes in self.shortlist to some of those in
        the constants.K nearest nodes in the self.contacted set then start
        from step 3 again (forcing the local node to contact the close nodes
        that have yet to be contacted).

    Note on validating values: In the future there may be constraints added to
    the FindValue query (such as only accepting values created after time T).
    """

    def __init__(self, target, message_type, local_node,
                 timeout=constants.LOOKUP_TIMEOUT, canceller=None):
        """
        Sets up the lookup to search for a certain target key with a particular
        message_type using the DHT state found in the local_node. Will cancel
        after timeout seconds. See the documentation for
        twisted.internet.defer.Deferred for explanation of canceller.
        """
        defer.Deferred.__init__(self, canceller)
        self.target = target
        self.message_type = message_type
        self.local_node = local_node
        # A set of nodes that have been contacted for this lookup.
        self.contacted = set()
        # Holds currently pending requests.
        self.pending_requests = {}
        if timeout:
            reactor.callLater(timeout, self.cancel)
        # To hold peers in the DHT that are known to the local node that are
        # possibly close to the target key. Closest nodes come first.
        self.shortlist = self.local_node._routing_table.\
            find_close_nodes(target)
        if self.target != self.local_node.id:
            # Update the last_accessed attribute of the affected k-bucket.
            self.local_node._routing_table.touch_kbucket(target)
        if not self.shortlist:
            # The node knows of no other nodes within the DHT.
            self.errback(RoutingTableEmpty())
            return
        # Holds the currently closest node to the target.
        self.nearest_node = self.shortlist[0]
        # Start the lookup process
        self._lookup()

    def _cancel_pending_requests(self):
        """
        Causes the deferreds waiting on pending requests to be cancelled in
        a clean fashion.
        """
        requests = self.pending_requests.values()
        for request in requests:
            request.cancel()
        self.pending_requests = {}

    def cancel(self):
        """
        Cancels this lookup in a clean fashion. This function is dedicated to
        @terrycojones whose efforts at cancelling deferreds deserve some sort
        of tribute. ;-)
        """
        self._cancel_pending_requests()
        defer.Deferred.cancel(self)

    def _handle_error(self, uuid, contact, error):
        """
        Callback to handle error conditions.

        If a node doesn't reply or an error is encountered it is removed from
        self.shortlist and self.pending_requests. Start the _lookup again.
        """
        if contact in self.shortlist:
            self.shortlist.remove(contact)
        if uuid in self.pending_requests:
            del self.pending_requests[uuid]
        log.msg('Error during interaction with %r' % contact)
        log.msg(error)
        self._lookup()

    def _blacklist(self, contact):
        """
        Removes a contact from the shortlist and routing table while adding it
        to the global blacklist of misbehaving peers.
        """
        if contact in self.shortlist:
            self.shortlist.remove(contact)
        self.local_node._routing_table.blacklist(contact)
        log.msg('Blacklisting %r' % contact)

    def _handle_response(self, uuid, contact, response):
        """
        Callback to handle expected responses (unexpected responses result in
        the remote node being blacklisted and a TypeError being thrown).

        When a response to a request is returned successfully remove the
        request from self.pending_requests.

        If it's a FindValue message and a suitable value is returned (see note
        at the end of these comments) cancel all the other pending calls in
        self.pending_requests and fire a callback with with the returned value.
        If the value is invalid blacklist the node, remove it from
        self.shortlist and start from step 3 again without cancelling the other
        pending calls.

        If a list of closer nodes is returned by a peer add them to
        self.shortlist and sort - making sure nodes in self.contacted are not
        mistakenly re-added to the shortlist.

        If the nearest node in the newly sorted self.shortlist is closer to the
        target than self.nearest_node then set self.nearest_node to the new
        closer node and start from step 3 again.

        If self.nearest_node remains unchanged DO NOT start a new lookup call.

        If there are no other requests in self.pending_requests then check that
        the constants.K nearest nodes in the self.contacted set are all closer
        than the nearest node in self.shortlist. If they are, and it's a
        FindNode message call back with the constants.K nearest nodes found in
        the self.contacted set. If the message is a FindValue, errback with a
        ValueNotFound error.

        If there are still nearer nodes in self.shortlist to some of those in
        the constants.K nearest nodes in the self.contacted set then start
        from step 3 again (forcing the local node to contact the close nodes
        that have yet to be contacted).

        Note on validating values: In the future there may be constraints added
        to the FindValue query (such as only accepting values created after
        time T).
        """
        # Remove originating request from pending requests.
        del self.pending_requests[uuid]

        # Ensure the response is of the expected type[s].
        if not ((isinstance(response, Value) and
                 self.message_type == FindValue) or
                isinstance(response, Nodes)):
            # Blacklist the problem contact from the routing table (since it
            # doesn't behave).
            self._blacklist(contact)
            raise TypeError("Unexpected response type from %r" % contact)

        # Is the response the expected Value we're looking for..?
        if isinstance(response, Value):
            # Check if it's a suitable value (the key matches)
            if response.key == self.target:
                # Ensure the Value has not expired.
                if response.expires < time.time():
                    # Do not blacklist expired nodes but simply remove them
                    # from the shortlist (handled by the errback).
                    raise ValueError("Expired value returned by %r" % contact)
                # Cancel outstanding requests.
                self._cancel_pending_requests()
                # Ensure the returning contact is removed from the shortlist
                # (so it's possible to discern the closest non-returning node)
                if contact in self.shortlist:
                    self.shortlist.remove(contact)

                # Success! The correct Value has been found. Fire the instance
                # with the result.
                self.callback(response)
            else:
                # Blacklist the problem contact from the routing table since
                # it's not behaving properly.
                self._blacklist(contact)
                raise ValueError("Value with wrong key returned by %r" %
                                 contact)
        else:
            # Otherwise it must be a Nodes message containing closer nodes.
            # Add the returned nodes to the shortlist. Sort the shortlist in
            # order of closeness to the target and ensure the shortlist never
            # gets longer than K.
            candidate_contacts = [candidate for candidate in response.nodes
                                  if candidate not in self.shortlist]
            self.shortlist = sort_contacts(candidate_contacts +
                                           self.shortlist, self.target)
            # Check if the nearest_node remains unchanged.
            if self.nearest_node == self.shortlist[0]:
                # Check for remaining pending requests.
                if not self.pending_requests:
                    # Check all the candidates in the shortlist have been
                    # contacted.
                    candidates = [candidate for candidate in self.shortlist if
                                  candidate in self.contacted]
                    if len(candidates) == len(self.shortlist):
                        # There is a result.
                        if self.message_type == FindValue:
                            # Can't find a value at the key.
                            msg = ("Unable to find value for key: %r" %
                                   self.target)
                            self.errback(ValueNotFound(msg))
                        else:
                            # Success! Found nodes close to the specified
                            # target key.
                            self.callback(self.shortlist)
                    else:
                        # There are still un-contacted peers in the shortlist
                        # so restart the lookup in order to check them.
                        self._lookup()
                else:
                    # There are still pending requests to complete but do not
                    # restart the lookup
                    pass
            else:
                # There is a new nearest node.
                self.nearest_node = self.shortlist[0]
                # Restart the lookup given the newly found nodes in the
                # shortlist.
                self._lookup()

    def _lookup(self):
        """
        Sends parallel lookup messages to the self.shortlist of contacts.

        No more than constants.ALPHA nearest nodes that are in self.shortlist
        but not in self.contacted are sent a message that is an instance of
        self.message_type. Each request is added to the self.pending_requests
        list. The length of self.pending_requests must never be more than
        constants.ALPHA.

        As each node is contacted it is added to the self.contacted set.
        """
        for contact in self.shortlist:
            if contact not in self.contacted:
                # Guard to ensure only ALPHA requests are ever active at any
                # one time
                if len(self.pending_requests) >= constants.ALPHA:
                    break

                uuid, deferred = self.local_node.send_find(contact,
                                                           self.target,
                                                           self.message_type)
                self.pending_requests[uuid] = deferred
                self.contacted.add(contact)

                def callback(result):
                    """
                    Passes the result to the NodeLookup instance to handle.
                    """
                    self._handle_response(uuid, contact, result)

                def errback(error):
                    """
                    Passes the error to the NodeLookup instance to handle.
                    """
                    self._handle_error(uuid, contact, error)

                deferred.addCallback(callback)
                deferred.addErrback(errback)


class Node(object):
    """
    This class represents a single local node in the DHT encapsulating its
    presence in the network.

    All interactions with the DHT network by a client application are
    performed via this class (or a subclass).
    """

    def __init__(self, id, client_string='ssl:%s:%d'):
        """
        Initialises the object representing the node with the given id.
        """
        # The node's ID within the distributed hash table.
        self.id = id
        # The routing table stores information about other nodes on the DHT.
        self._routing_table = RoutingTable(id)
        # The local key/value store containing data held by this node.
        self._data_store = DictDataStore()
        # A dictionary of IDs for messages pending a response and associated
        # deferreds to be fired when a response is completed.
        self._pending = {}
        # The template string to use when initiating a connection to another
        # node on the network.
        self._client_string = client_string
        # The version of Drogulus that this node implements.
        self.version = get_version()
        log.msg('Initialised node with id: %r' % self.id)

    def join(self, seed_nodes=None):
        """
        Causes the Node to join the DHT network. This should be called before
        any other DHT operations. The seed_nodes argument must be a list of
        already known contacts describing existing nodes on the network.
        """
        if not seed_nodes:
            raise ValueError('Seed nodes required for node to join network')
        for contact in seed_nodes:
            self._routing_table.add_contact(contact)
        # Looking up the node's ID on the network will populate the routing
        # table with fresh nodes as well as tell us who our nearest neighbours
        # are.

        # TODO: Add callback to kick off refresh of k-buckets in future..?
        raise Exception('FIX ME!')
        # Ensure the refresh of k-buckets is set up properly.
        return NodeLookup(self.id, FindNode, self)

    def message_received(self, message, protocol):
        """
        Handles incoming messages.
        """
        # Update the routing table.
        peer = protocol.transport.getPeer()
        other_node = Contact(message.node, peer.host, peer.port,
                             message.version, time.time())
        log.msg('Message received from %s' % other_node)
        log.msg(message)
        self._routing_table.add_contact(other_node)
        # Sort on message type and pass to handler method. Explicit > implicit.
        if isinstance(message, Ping):
            self.handle_ping(message, protocol)
        elif isinstance(message, Pong):
            self.handle_pong(message)
        elif isinstance(message, Store):
            self.handle_store(message, protocol, other_node)
        elif isinstance(message, FindNode):
            self.handle_find_node(message, protocol)
        elif isinstance(message, FindValue):
            self.handle_find_value(message, protocol)
        elif isinstance(message, Error):
            self.handle_error(message, protocol, other_node)
        elif isinstance(message, Value):
            self.handle_value(message, other_node)
        elif isinstance(message, Nodes):
            self.handle_nodes(message)

    def send_message(self, contact, message):
        """
        Sends a message to the specified contact, adds it to the _pending
        dictionary and ensures it times-out after the correct period. If an
        error occurs the deferred's errback is called.
        """
        d = defer.Deferred()
        # open network call.
        client_string = self._client_string % (contact.address, contact.port)
        client = clientFromString(reactor, client_string)
        connection = client.connect(DHTFactory(self))
        # Ensure the connection will potentially time out.
        connection_timeout = reactor.callLater(constants.RPC_TIMEOUT,
                                               connection.cancel)

        def on_connect(protocol):
            # Cancel pending connection_timeout if it's still active.
            if connection_timeout.active():
                connection_timeout.cancel()
            # Send the message and add a timeout for the response.
            protocol.sendMessage(message)
            self._pending[message.uuid] = d
            reactor.callLater(constants.RESPONSE_TIMEOUT, response_timeout,
                              message, protocol, self)

        def on_error(error):
            log.msg('***** ERROR ***** interacting with %s' % contact)
            log.msg(error)
            self._routing_table.remove_contact(message.node)
            if message.uuid in self._pending:
                del self._pending[message.uuid]
            d.errback(error)

        connection.addCallback(on_connect)
        connection.addErrback(on_error)
        return d

    def trigger_deferred(self, message, error=False):
        """
        Given a message, will attempt to retrieve the deferred and trigger it
        with the appropriate callback or errback.
        """
        if message.uuid in self._pending:
            deferred = self._pending[message.uuid]
            if error:
                error.message = message
                deferred.errback(error)
            else:
                deferred.callback(message)
            # Remove the called deferred from the _pending dictionary.
            del self._pending[message.uuid]

    def handle_ping(self, message, protocol):
        """
        Handles an incoming Ping message. Returns a Pong message using the
        referenced protocol object.
        """
        pong = Pong(message.uuid, self.id, self.version)
        protocol.sendMessage(pong, True)

    def handle_pong(self, message):
        """
        Handles an incoming Pong message.
        """
        self.trigger_deferred(message)

    def handle_store(self, message, protocol, sender):
        """
        Handles an incoming Store message. Checks the provenance and timeliness
        of the message before storing locally. If there is a problem, removes
        the untrustworthy peer from the routing table. Otherwise, at
        REPLICATE_INTERVAL minutes in the future, the local node will attempt
        to replicate the Store message elsewhere in the DHT if such time is
        <= the message's expiry time.

        Sends a Pong message if successful otherwise replies with an
        appropriate Error.
        """
        # Check provenance
        is_valid, err_code = validate_message(message)
        if is_valid:
            # Ensure the node doesn't already have a more up-to-date version
            # of the value.
            current = self._data_store.get(message.key, False)
            if current and (message.timestamp < current.timestamp):
                # The node already has a later version of the value so
                # return an error.
                details = {
                    'new_timestamp': '%d' % current.timestamp
                }
                raise ValueError(8, constants.ERRORS[8], details,
                                 message.uuid)
            # Good to go, so store value.
            self._data_store.set_item(message.key, message)
            # Reply with a pong so the other end updates its routing table.
            pong = Pong(message.uuid, self.id, self.version)
            protocol.sendMessage(pong, True)
            # At some future time attempt to replicate the Store message
            # around the network IF it is within the message's expiry time.
            reactor.callLater(constants.REPLICATE_INTERVAL,
                              self.republish, message)
        else:
            # Remove from the routing table.
            log.msg('Problem with Store command: %d - %s' %
                    (err_code, constants.ERRORS[err_code]))
            self._routing_table.blacklist(sender)
            # Return an error.
            details = {
                'message': 'You have been blacklisted.'
            }
            raise ValueError(err_code, constants.ERRORS[err_code], details,
                             message.uuid)

    def handle_find_node(self, message, protocol):
        """
        Handles an incoming FindNode message. Finds the details of up to K
        other nodes closer to the target key that *this* node knows about.
        Responds with a "Nodes" message containing the list of matching
        nodes.
        """
        target_key = message.key
        # List containing tuples of information about the matching contacts.
        other_nodes = [(n.id, n.address, n.port, n.version) for n in
                       self._routing_table.find_close_nodes(target_key)]
        result = Nodes(message.uuid, self.id, other_nodes, self.version)
        protocol.sendMessage(result, True)

    def handle_find_value(self, message, protocol):
        """
        Handles an incoming FindValue message. If the local node contains the
        value associated with the requested key replies with an appropriate
        "Value" message. Otherwise, responds with details of up to K other
        nodes closer to the target key that the local node knows about. In
        this case a "Nodes" message containing the list of matching nodes is
        sent to the caller.
        """
        match = self._data_store.get(message.key, False)
        if match:
            result = Value(message.uuid, self.id, match.key, match.value,
                           match.timestamp, match.expires, match.created_with,
                           match.public_key, match.name, match.meta, match.sig,
                           match.version)
            protocol.sendMessage(result, True)
        else:
            self.handle_find_node(message, protocol)

    def handle_error(self, message, protocol, sender):
        """
        Handles an incoming Error message. Currently, this simply logs the
        error and closes the connection. In future this *may* remove the
        sender from the routing table (depending on the error).
        """
        # TODO: Handle error 8 (out of date data)
        log.msg('***** ERROR ***** from %s' % sender)
        log.msg(message)

    def handle_value(self, message, sender):
        """
        Handles an incoming Value message containing a value retrieved from
        another node on the DHT. Ensures the message is valid and calls the
        referenced deferred to signal the arrival of the value.

        TODO: How to handle invalid messages and errback the deferred.
        """
        # Check provenance
        is_valid, err_code = validate_message(message)
        if is_valid:
            self.trigger_deferred(message)
        else:
            log.msg('Problem with incoming Value: %d - %s' %
                    (err_code, constants.ERRORS[err_code]))
            log.msg(message)
            # Remove the remote node from the routing table.
            self._routing_table.remove_contact(sender.id, True)
            error = ValueError(constants.ERRORS[err_code])
            self.trigger_deferred(message, error)

    def handle_nodes(self, message):
        """
        Handles an incoming Nodes message containing information about other
        nodes on the network that are close to a requested key.
        """
        self.trigger_deferred(message)

    def send_ping(self, contact):
        """
        Sends a ping request to the given contact and returns a deferred
        that is fired when the reply arrives or an error occurs.
        """
        new_uuid = str(uuid4())
        ping = Ping(new_uuid, self.id, self.version)
        return self.send_message(contact, ping)

    def send_store(self, contact, public_key, name, value, timestamp, expires,
                   created_with, meta, signature):
        """
        Sends a Store message to the given contact. The value contained within
        the message is stored against a key derived from the public_key and
        name. Furthermore, the message is cryptographically signed using the
        value, timestamp, expires, name and meta values.
        """
        uuid = str(uuid4())
        compound_key = construct_key(public_key, name)
        store = Store(uuid, self.id, compound_key, value, timestamp, expires,
                      created_with, public_key, name, meta, signature,
                      self.version)
        return self.send_message(contact, store)

    def send_find(self, contact, target, message_type):
        """
        Sends a Find[Node|Value] message to the given contact with the
        intention of obtaining information at the given target key. The type of
        find message is specified by message_type.
        """
        new_uuid = str(uuid4())
        find_message = message_type(new_uuid, self.id, target, self.version)
        deferred = self.send_message(contact, find_message)
        return (new_uuid, deferred)

    def _process_lookup_result(self, nearest_nodes, public_key, name, value,
                               timestamp, expires, created_with, meta,
                               signature, length):
        """
        Given a list of nearest nodes will return a list of send_store based
        deferreds for the item to be stored in the DHT. The list will contain
        up to "length" number of deferreds.
        """
        list_of_deferreds = []
        for contact in nearest_nodes[:length]:
            deferred = self.send_store(contact, public_key, name, value,
                                       timestamp, expires, created_with,
                                       meta, signature)
            list_of_deferreds.append(deferred)
        return list_of_deferreds

    def replicate(self, public_key, name, value, timestamp, expires,
                  created_with, meta, signature, duplicate):
        """
        Will replicate args to "duplicate" number of nodes in the distributed
        hash table. Returns a deferred that will fire with a list of send_store
        deferreds when "duplicate" number of closest nodes have been
        identified.

        Obviously, the list can be turned in to a deferred_list to fire when
        the store commands have completed.

        Even if "duplicate" is > K no more than K items will be contained
        within the list result.
        """
        if duplicate < 1:
            # Guard to ensure meaningful duplication count.
            raise ValueError('Duplication count may not be less than 1')

        result = defer.Deferred()
        compound_key = construct_key(public_key, name)
        lookup = NodeLookup(compound_key, FindNode, self)

        def on_success(nodes):
            """
            A list of close nodes have been found so send store messages to
            the "duplicate" closest number of them and fire the "result"
            deferred with the resulting DeferredList of pending deferreds.
            """
            deferreds = self._process_lookup_result(nodes, public_key, name,
                                                    value, timestamp, expires,
                                                    created_with, meta,
                                                    signature, duplicate)
            result.callback(deferreds)

        def on_error(error):
            """
            Catch all for errors during the lookup phase. Simply pass them on
            via the "result" deferred.
            """
            result.errback(error)

        lookup.addCallback(on_success)
        lookup.addErrback(on_error)
        return result

    def retrieve(self, key):
        """
        Given a key, will try to retrieve associated value from the distributed
        hash table. Returns a deferred that will fire when the operation is
        complete or failed.

        As the original Kademlia explains:

        "For caching purposes, once a lookup succeeds, the requesting node
        stores the <key, value> pair at the closest node it observed to the
        key that did not return the value."

        This method adds a callback to the NodeLookup to achieve this end.
        """
        lookup = NodeLookup(key, FindValue, self)

        def cache(result):
            """
            Called once the lookup succeeds in order to store the item at the
            node closest to the key that did not return the value.
            """
            caching_contact = None
            for candidate in lookup.shortlist:
                if candidate in lookup.contacted:
                    caching_contact = candidate
                    break
            if caching_contact:
                log.msg("Caching to %r" % caching_contact)
                self.send_store(caching_contact, result.public_key,
                                result.name, result.value, result.timestamp,
                                result.expires, result.created_with,
                                result.meta, result.sig)
            return result

        lookup.addCallback(cache)
        return lookup

    def republish(self, message):
        """
        Will check and republish a locally stored message to the wider network.

        From the original Kademlia paper:

        "To ensure the persistence of key-value pairs, nodes must periodically
        republish keys. Otherwise, two phenomena may cause lookups for valid
        keys to fail. First, some of the k nodes that initially get a key-value
        pair when it is published may leave the network. Second, new nodes may
        join the network with IDs closer to some published key than the nodes
        on which the key-value pair was originally published. In both cases,
        the nodes with a key-value pair must republish it so as once again to
        ensure it is available on the k nodes closest to the key.

        To compensate for nodes leaving the network, Kademlia republishes each
        key-value pair once an hour. A naive implementation of this strategy
        would require many messages - each of up to k nodes storing a key-value
        pair would perform a node lookup followed by k - 1 STORE RPCs every
        hour. Fortunately, the republish process can be heavily optimized.
        First, when a node receives a STORE RPC for a given key-value pair, it
        assumes the RPC was also issued to the other k - 1 closest nodes, and
        thus the recipient will not republish the key-value pair in the next
        hour. This ensures that as long as republication intervals are not
        exactly synchronized, only one node will republish a given key-value
        pair every hour.

        A second optimization avoids performing node lookups before
        republishing keys. As described in Section 2.4, to handle unbalanced
        trees, nodes split k-buckets as required to ensure they have complete
        knowledge of a surrounding subtree with at least k nodes. If, before
        republishing key-value pairs, a node u refreshes all k-buckets in this
        subtree of k nodes, it will automatically be able to figure out the
        k closest nodes to a given key. These bucket refreshes can be amortized
        over the republication of many keys.

        To see why a node lookup is unnecessary after u refreshes buckets in
        the sub-tree of size >= k, it is necessary to consider two cases. If
        the key being republished falls in the ID range of the subtree, then
        since the subtree is of size at least k and u has complete knowledge of
        the subtree, clearly u must know the k closest nodes to the key. If,
        on the other hand, the key lies outside the subtree, yet u was one of
        the k closest nodes to the key, it must follow that u's k-buckets for
        intervals closer to the key than the subtree all have fewer than k
        entries. Hence, u will know all nodes in these k-buckets, which
        together with knowledge of the subtree will include the k closest nodes
        to the key.

        When a new node joins the system, it must store any key-value pair to
        which is is one of the k closest. Existing nodes, by similarly
        exploiting complete knowledge of their surrounding subtrees, will know
        which key-value pairs the new node should store. Any node learning of a
        new node therefore issues STORE RPCs to transfer relevant key-value
        pairs to the new node. To avoid redundant STORE RPCs, however, a node
        only transfers a key-value pair if it's [sic] own ID is closer to the
        key than are the IDs of other nodes."

        Messages are only republished if the following requirements are met:

        * They still exist in the local data store.
        * They have not expired.
        * They have not been updated for REPLICATE_INTERVAL seconds.
        """
        pass

########NEW FILE########
__FILENAME__ = routingtable
# -*- coding: utf-8 -*-
"""
Contains code that represents Kademlia's routing table tree structure.
"""

# Copyright (C) 2012-2013 Nicholas H.Tollervey.
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU Affero General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU Affero General Public License for more details.
#
# You should have received a copy of the GNU Affero General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.

import time
import random
import kbucket
from drogulus import constants
from drogulus.utils import long_to_hex, hex_to_long, sort_contacts


class RoutingTable(object):
    """
    From the original paper:

    "The routing table is a binary tree whose leaves are k-buckets. Each
    k-bucket contains nodes with some common prefix in their ID. The prefix is
    the k-bucket's position in the the binary tree. Thus, each k-bucket covers
    some range of the ID space, and together the k-buckets cover the entire
    512-bit ID space with no overlap."
    """

    def __init__(self, parent_node_id):
        """
        The parentNodeID is the 512-bit ID of the node to which this routing
        table belongs.
        """
        # Create the initial (single) k-bucket covering the range of the
        # entire 512-bit ID space
        self._buckets = [kbucket.KBucket(range_min=0, range_max=2 ** 512)]
        self._parent_node_id = parent_node_id
        # Cache containing nodes eligible to replace stale k-bucket entries
        self._replacement_cache = {}
        # Set of nodes (contact ids) that have been blacklisted due to "bad"
        # behaviour.
        self._blacklist = set()

    def _kbucket_index(self, key):
        """
        Returns the index of the k-bucket responsible for the specified key
        string.
        """
        if isinstance(key, str):
            key = hex_to_long(key)
        # Bound check for key too small.
        if key < 0:
            raise ValueError('Key out of range')
        for i, bucket in enumerate(self._buckets):
            if bucket.key_in_range(key):
                return i
        # Key was too big given the key space.
        raise ValueError('Key out of range.')

    def _random_key_in_bucket_range(self, bucket_index):
        """
        Returns a random key in the specified k-bucket's range.
        """
        # Get a random integer within the required range.
        keyValue = random.randrange(self._buckets[bucket_index].range_min,
                                    self._buckets[bucket_index].range_max)
        return long_to_hex(keyValue)

    def _split_bucket(self, old_bucket_index):
        """
        Splits the specified k-bucket into two new buckets which together
        cover the same range in the key/ID space.
        """
        # Resize the range of the current (old) k-bucket.
        old_bucket = self._buckets[old_bucket_index]
        split_point = old_bucket.range_max - (
            old_bucket.range_max - old_bucket.range_min) / 2
        # Create a new k-bucket to cover the range split off from the old
        # bucket.
        new_bucket = kbucket.KBucket(split_point, old_bucket.range_max)
        old_bucket.range_max = split_point
        # Now, add the new bucket into the routing table tree.
        self._buckets.insert(old_bucket_index + 1, new_bucket)
        # Finally, copy all nodes that belong to the new k-bucket into it...
        for contact in old_bucket._contacts:
            if new_bucket.key_in_range(contact.id):
                new_bucket.add_contact(contact)
        # ...and remove them from the old bucket
        for contact in new_bucket._contacts:
            old_bucket.remove_contact(contact)

    def blacklist(self, contact):
        """
        Marks the referenced contact as blacklisted because it has misbehaved
        in some way. For example, it may have attempted to propagate a non
        valid value or responded to a node lookup with an incorrect response.
        Once blacklisted a contact is never allowed to be in the routing
        table or replacement cache.
        """
        self.remove_contact(contact.id, forced=True)
        self._blacklist.add(contact.id)

    def add_contact(self, contact):
        """
        Add the given contact to the correct k-bucket; if it already exists,
        its status will be updated.
        """
        if contact.id in self._blacklist:
            return
        if contact.id == self._parent_node_id:
            return
        # Initialize/reset the "failed RPC" counter since adding it to the
        # routing table is the result of a successful RPC.
        contact.failed_RPCs = 0
        bucket_index = self._kbucket_index(contact.id)
        try:
            self._buckets[bucket_index].add_contact(contact)
        except kbucket.KBucketFull:
            # The bucket is full; see if it can be split (by checking if its
            # range includes the host node's id)
            if self._buckets[bucket_index].key_in_range(self._parent_node_id):
                self._split_bucket(bucket_index)
                # Retry the insertion attempt
                self.add_contact(contact)
            else:
                # We can't split the k-bucket
                #
                # NOTE: This implementation follows section 4.1 of the 13 page
                # version of the Kademlia paper (optimized contact accounting
                # without PINGs - results in much less network traffic, at the
                # expense of some memory)
                #
                # Put the new contact in our replacement cache for the
                # corresponding k-bucket (or update it's position if it exists
                # already).
                if not bucket_index in self._replacement_cache:
                    self._replacement_cache[bucket_index] = []
                if contact in self._replacement_cache[bucket_index]:
                    self._replacement_cache[bucket_index].remove(contact)
                elif len(self._replacement_cache[bucket_index]) >= constants.K:
                    # Use k to limit the size of the contact replacement cache.
                    self._replacement_cache[bucket_index].pop(0)
                self._replacement_cache[bucket_index].append(contact)

    def find_close_nodes(self, key, rpc_node_id=None):
        """
        Finds up to "K" number of known nodes closest to the node/value with
        the specified key. If rpc_node_id is supplied the referenced node will
        be excluded from the returned contacts.

        The result is a list of "K" node contacts of type dht.contact.Contact.
        Will only return fewer than "K" contacts if not enough contacts are
        known.

        The result is ordered from closest to furthest away from the target
        key.
        """
        bucket_index = self._kbucket_index(key)
        closest_nodes = self._buckets[bucket_index].get_contacts(
            constants.K, rpc_node_id)
        # How far away to jump beyond the containing bucket of the given key.
        bucket_jump = 1
        number_of_buckets = len(self._buckets)
        # Flags that indicate if it's possible to jump higher or lower through
        # the buckets.
        can_go_lower = bucket_index - bucket_jump >= 0
        can_go_higher = bucket_index + bucket_jump < number_of_buckets
        while (len(closest_nodes) <
               constants.K and (can_go_lower or can_go_higher)):
            # Continue to fill the closestNodes list with contacts from the
            # nearest unchecked neighbouring k-buckets. Have chosen to opt for
            # readability rather than conciseness.
            if can_go_lower:
                # Neighbours lower in the key index.
                remaining_slots = constants.K - len(closest_nodes)
                jump_to_neighbour = bucket_index - bucket_jump
                neighbour = self._buckets[jump_to_neighbour]
                contacts = neighbour.get_contacts(remaining_slots, rpc_node_id)
                closest_nodes.extend(contacts)
                can_go_lower = bucket_index - (bucket_jump + 1) >= 0
            if can_go_higher:
                # Neighbours higher in the key index.
                remaining_slots = constants.K - len(closest_nodes)
                jump_to_neighbour = bucket_index + bucket_jump
                neighbour = self._buckets[jump_to_neighbour]
                contacts = neighbour.get_contacts(remaining_slots, rpc_node_id)
                closest_nodes.extend(contacts)
                can_go_higher = (bucket_index + (bucket_jump + 1) <
                                 number_of_buckets)
            bucket_jump += 1

        # Order the nodes from closest to furthest away from the target key and
        # ensure we only return K contacts (in certain circumstances K+1
        # results are generated).
        return sort_contacts(closest_nodes, key)

    def get_contact(self, contact_id):
        """
        Returns the (known) contact with the specified node ID. Will raise
        a ValueError if no contact with the specified ID is known.
        """
        bucket_index = self._kbucket_index(contact_id)
        contact = self._buckets[bucket_index].get_contact(contact_id)
        return contact

    def get_refresh_list(self, start_index=0, force=False):
        """
        Finds all k-buckets that need refreshing, starting at the
        k-bucket with the specified index. This bucket and those further away
        from it will be refreshed. Returns node IDs to be searched for
        in order to refresh those k-buckets in the routing table. If the
        "force" parameter is True then all buckets with the specified range
        will be refreshed, regardless of the time they were last accessed.
        """
        bucket_index = start_index
        refresh_IDs = []
        for bucket in self._buckets[start_index:]:
            last_refreshed = int(time.time()) - bucket.last_accessed
            if force or last_refreshed >= constants.REFRESH_TIMEOUT:
                search_ID = self._random_key_in_bucket_range(bucket_index)
                refresh_IDs.append(search_ID)
            bucket_index += 1
        return refresh_IDs

    def remove_contact(self, contact_id, forced=False):
        """
        Attempt to remove the contact with the specified contactID from the
        routing table.

        The operation will only succeed if either the number of failed RPCs
        made against the contact is >= constants.ALLOWED_RPC_FAILS or the
        'forced' flag is set to True (defaults to False).

        If there are any contacts in the replacement cache for the affected
        bucket then the most up-to-date contact in the replacement cache will
        be used as a replacement.
        """
        bucket_index = self._kbucket_index(contact_id)
        try:
            contact = self._buckets[bucket_index].get_contact(contact_id)
        except ValueError:
            # Fail silently since the contact isn't in the routing table
            # anyway.
            return
        contact.failed_RPCs += 1
        if forced or contact.failed_RPCs >= constants.ALLOWED_RPC_FAILS:
            # Remove the contact from the bucket.
            self._buckets[bucket_index].remove_contact(contact_id)
            if bucket_index in self._replacement_cache:
                # If required, remove the old contact from the replacement
                # cache.
                if contact in self._replacement_cache[bucket_index]:
                    self._replacement_cache[bucket_index].remove(contact)
                # If possible, replace the stale contact with the most recent
                # contact stored in the replacement cache.
                if len(self._replacement_cache[bucket_index]) > 0:
                    self._buckets[bucket_index].add_contact(
                        self._replacement_cache[bucket_index].pop())

    def touch_kbucket(self, key):
        """
        Update the lastAccessed timestamp of the k-bucket which covers
        the range containing the specified key string in the key/ID space.

        The lastAccessed field is used to ensure a k-bucket doesn't become
        stale.
        """
        bucket_index = self._kbucket_index(key)
        self._buckets[bucket_index].last_accessed = int(time.time())

########NEW FILE########
__FILENAME__ = messages
# -*- coding: utf-8 -*-
"""
Contains classes that represent messages sent down the wire between nodes on
the network. Also contains functions for encoding/decoding to/from
MessagePack. Every message contains at least three mandatory fields: uuid
(identifying the interaction), node (the ID of the sender of the message) and
version (indicating the version of Drogulus the sender is running).

Named tuples are used because they are lightweight, immutable and indexable
(thus mimicing the dict like structure of the msgpack encoded message passed
down the wire). See http://bugs.python.org/issue9391 for Hettinger's advice on
adding docstrings to namedtuples and the reason why the classes are declared
in the way that they are.
"""

# Copyright (C) 2012-2013 Nicholas H.Tollervey.
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU Affero General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU Affero General Public License for more details.
#
# You should have received a copy of the GNU Affero General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.

from collections import namedtuple
import msgpack
from validators import VALIDATORS
from drogulus.constants import ERRORS


class Error(namedtuple('Error',
                       ['uuid', 'node', 'code', 'title', 'details',
                        'version'])):
    """

    Represents an error message to be sent to the calling node on the network.

    * uuid - the ID of the request that generated the error.
    * node - the ID of the node sending the message.
    * code - the code that identifies the specific error.
    * title - a description of the type of error generated.
    * details - diagnostic details expressed as a dict of string key/values.
    * version - the protocol version the message conforms to.
    """
    pass


class Ping(namedtuple('Ping', ['uuid', 'node', 'version'])):
    """
    A "ping" message is sent to another node on the network to determine if it
    is still contactable.

    * uuid - the ping's request ID (a random value generated by the requestor
             that uniquely identifies the request).
    * node - the ID of the node sending the message.
    * version - the protocol version the message conforms to.
    """
    pass


class Pong(namedtuple('Pong', ['uuid', 'node', 'version'])):
    """
    A "pong" message is sent as a confirmation response. This is usually the
    result of a ping request but may be used to confirm reciept of any other
    sort of request when no further data is expected to be returned.

    * uuid - the request ID of the source of the response.
    * node - the ID of the node sending the message.
    * version - the protocol version the message conforms to.
    """
    pass


class Store(namedtuple('Store', ['uuid', 'node', 'key', 'value', 'timestamp',
                                 'expires', 'created_with', 'public_key',
                                 'name', 'meta', 'sig', 'version'])):
    """
    A "store" message instructs another node on the network to store the given
    key/value pair.

    * uuid - the ID of the Store request (generated by the requestee).
    * node - the ID of the node sending the message.
    * key - the SHA512 value of the compound key used as the actual key on the
            DHT.
    * value - the value to be stored in the DHT.
    * timestamp - a timestamp indicating when this key/value pair was
                  *originally* generated as an integer representing the time
                  in seconds since the Epoch (so called POSIX time, see
                  https://en.wikipedia.org/wiki/Unix_time).
    * expires - a timestamp indicating a point in time after which this
                key/value pair can be removed (expired) from the DHT. Expressed
                as an integer representing the time in seconds since the Epoch
                (so called POSIX time). If the value is less than or equal to
                zero then the key/value pair should never expire.
    * created_with - the version of the protocol used to generate the item.
    * public_key - the public key of the person storing the value.
    * name - the human-readable name of the key.
    * meta - a dictionary containing key/value strings for user defined
             metadata.
    * sig - the cryptographic signature for the value, timestamp, expires,
            name, meta and created_with fields.
    * version - the protocol version the message conforms to.

    The provenance of the message is guaranteed through cryptography:

    The 'sig' field is created with the private key of the person storing the
    key/value pair. It's derived from the SHA512 hash of the SHA512 hashes of
    the 'value', 'timestamp', 'expires', 'name', 'meta' and 'created_with'
    fields. This mechanism ensures that the public_key used in the compound key
    is valid (i.e. it validates the sig field given the correct SHA512 hash)
    and also ensures that the 'value', 'timestamp', 'expires', 'name', 'meta'
    and 'created_with' fields have not been tampered with.

    The 'key' value is a compound key. It is a SHA512 hash of the SHA512 hashes
    of the 'public_key' and 'name' fields. The 'public_key' and 'name' fields
    are used to ensure that the compound 'key' field is correct.
    """
    pass


class FindNode(namedtuple('FindNode', ['uuid', 'node', 'key', 'version'])):
    """
    A "find node" message requests k nodes from the other nodes on the network
    that are closest to the given key. The value k is the maximum number of
    nodes that can be stored in a k-bucket and is set in the constants module.
    The original Kademlia paper names this variable and recommends its value
    as 20.

    * uuid - the ID of the FindNode request (generated by the requestee).
    * node - the ID of the node sending the message.
    * key - the key in the DHT that is being targetted.
    * version - the protocol version the message conforms to.
    """
    pass


class Nodes(namedtuple('Nodes', ['uuid', 'node', 'nodes', 'version'])):
    """
    A response to either a FindNode or FindValue request that contains a list
    of nodes on the DHT that are close to the requested key.

    * uuid - the ID of the request that is causing the response.
    * node - the ID of the node sending the message.
    * nodes - a list of nodes on the DHT that are close to the requested key.
    * version - the protocol version the message conforms to.
    """
    pass


class FindValue(namedtuple('FindValue', ['uuid', 'node', 'key', 'version'])):
    """
    A "find value" message will cause the other node to return the
    corresponding value if the given key is in its store. Otherwise it returns
    k nodes that it knows about that are closest to the given key.

    * uuid - the ID of the FindValue request (generated by the requestee).
    * node - the ID of the node sending the message.
    * key - the key in the DHT whose value is being requested.
    * version - the protocol version the message conforms to.
    """
    pass


class Value(namedtuple('Value', ['uuid', 'node', 'key', 'value', 'timestamp',
                                 'expires', 'created_with', 'public_key',
                                 'name', 'meta', 'sig', 'version'])):
    """
    A response to a FindValue request. Contains all the information known by
    the responder about the key/value pair. Such complete information can be
    used to check the provenance of the data as described in the documentation
    for the Store message described above.

    * uuid - the ID of the request that is causing the response.
    * node - the ID of the node sending the message.
    * key - the SHA512 value of the compound key used as the actual key on the
            DHT.
    * value - the value found in the DHT.
    * timestamp - a timestamp indicating when this key/value pair was
                  *originally* generated as a floating point number
                  representing the time in seconds since the Epoch (so called
                  POSIX time, see https://en.wikipedia.org/wiki/Unix_time).
    * expires - a timestamp indicating a point in time after which this
                key/value pair can be removed (expired) from the DHT. Expressed
                as an integer representing the time in seconds since the Epoch
                (so called POSIX time). If the value is less than or equal to
                zero then the key/value pair should never expire.
    * created_with - the version of the protocol used to generate the item.
    * public_key - the public key of the person who stored the value.
    * name - the human-readable name of the key.
    * meta - a dictionary containing key/value strings for user defined
             metadata.
    * sig - the cryptographic signature for the value, timestamp, expires,
            name, meta and created_with fields.
    * version - the protocol version the message conforms to.
    """
    pass


def to_msgpack(message):
    """
    Returns a string representation of the message object encoded using
    msgpack.
    """
    name = message.__class__.__name__.lower()
    data = message._asdict()
    data['message'] = name
    return msgpack.packb(data)


def from_msgpack(raw):
    """
    Returns an instance of the correct message class given the msgpack encoded
    data in the raw string. Encapsulates a variety of cleaning and checking of
    the raw message from the (potentially dangerous) external network.
    """
    data = msgpack.unpackb(raw, use_list=False)
    message = data['message']
    # Explicit is better than implicit (Zen of Python).
    if message == 'error':
        return make_message(Error, data)
    elif message == 'ping':
        return make_message(Ping, data)
    elif message == 'pong':
        return make_message(Pong, data)
    elif message == 'store':
        return make_message(Store, data)
    elif message == 'findnode':
        return make_message(FindNode, data)
    elif message == 'nodes':
        return make_message(Nodes, data)
    elif message == 'findvalue':
        return make_message(FindValue, data)
    elif message == 'value':
        return make_message(Value, data)
    else:
        # Unknown request.
        raise ValueError(2, ERRORS[2], {'context':
                         '%s is not a valid message type.' % message})


def make_message(klass, data):
    """
    Returns an instance of the referenced namedtuple based class that is
    created from the raw data. Data will be validated and an exception raised
    if this fails.
    """
    fields = klass._fields
    args = []
    errors = {}
    # Validate the values before adding them to the argument list. Store any
    # errors so they can be reported back.
    for field in fields:
        if not field in data:
            errors[field] = 'Missing field.'
            continue
        validator = VALIDATORS[field]
        value = data[field]
        if not validator(value):
            errors[field] = 'Invalid value.'
            continue
        args.append(value)
    if errors:
        raise ValueError(2, ERRORS[2], errors)
    else:
        return klass(*args)

########NEW FILE########
__FILENAME__ = protocol
# -*- coding: utf-8 -*-
"""
Contains a definition of the low-level networking protocol used by the
Drogulus.
"""

# Copyright (C) 2012-2013 Nicholas H.Tollervey.
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU Affero General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU Affero General Public License for more details.
#
# You should have received a copy of the GNU Affero General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.

from twisted.internet import protocol
from twisted.python import log
from twisted.protocols.basic import NetstringReceiver
from messages import Error, to_msgpack, from_msgpack
from drogulus.constants import ERRORS
from drogulus.version import get_version
from uuid import uuid4


class DHTProtocol(NetstringReceiver):
    """
    The low level networking protocol.

    Msgpack (http://msgpack.org/) encoded payloads are transported as
    netstrings (http://cr.yp.to/proto/netstrings.txt).

    The payload is simply a dictionary of attributes. Please see the classes
    representing each type of request/response type for what these attributes
    represent.

    To the external world messages come in, messages go out (and implementation
    details are hidden).
    """

    def except_to_error(self, exception):
        """
        Given a Python exception will return an appropriate Error message
        instance.
        """
        if isinstance(exception, Exception) and len(exception.args) == 4:
            # Exception includes all the information we need.
            code = exception.args[0]
            title = exception.args[1]
            details = exception.args[2]
            uuid = exception.args[3]
        else:
            uuid = str(uuid4())
            code = 3
            title = ERRORS[code]
            details = {}
        return Error(uuid, self.factory.node.id, code, title, details,
                     get_version())

    def stringReceived(self, raw):
        """
        Handles incoming requests by unpacking them and instantiating the
        correct request class before passing them to the Node instance for
        further processing. If the message cannot be unpacked or is invalid
        an appropriate error message is returned to the originating caller.
        """
        try:
            message = from_msgpack(raw)
            self.factory.node.message_received(message, self)
        except Exception, ex:
            # Catch all for anything unexpected
            log.msg('***** ERROR *****')
            log.msg(ex)
            self.sendMessage(self.except_to_error(ex), True)

    def sendMessage(self, msg, loseConnection=False):
        """
        Sends the referenced message to the connected peer on the network. If
        loseConnection is set to true the connection will be dropped once the
        message has been sent.
        """
        self.sendString(to_msgpack(msg))
        if loseConnection:
            self.transport.loseConnection()


class DHTFactory(protocol.Factory):
    """
    DHT Factory class that uses the DHTProtocol.
    """

    protocol = DHTProtocol

    def __init__(self, node):
        """
        Instantiates the factory with a node object representing the local
        node within the network.
        """
        self.node = node

########NEW FILE########
__FILENAME__ = validators
# -*- coding: utf-8 -*-
"""
Contains functions that are used to validate the type and content of fields
in messages sent between nodes in the DHT.
"""

# Copyright (C) 2012-2013 Nicholas H.Tollervey.
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU Affero General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU Affero General Public License for more details.
#
# You should have received a copy of the GNU Affero General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.

from drogulus.constants import ERRORS


def validate_timestamp(val):
    """
    Returns a boolean indication that a field is a valid timestamp - a
    floating point number representing the time in seconds since the Epoch (so
    called POSIX time, see https://en.wikipedia.org/wiki/Unix_time).
    """
    return isinstance(val, float)


def validate_code(val):
    """
    Returns a boolean indication that an error code is valid.
    """
    return val in ERRORS.keys()


def validate_string(val):
    """
    Returns a boolean to indicate that a field is a string of some sort.
    """
    return isinstance(val, basestring)


def validate_meta(val):
    """
    Returns a boolean to indicate that a meta-data field is a dictionary of
    key / value strings.
    """
    if isinstance(val, dict):
        for k, v in val.iteritems():
            if not (validate_string(k) and validate_string(v)):
                return False
    else:
        return False
    return True


def validate_node(val):
    """
    Returns a boolean to indicate if the passed in tuple conforms to a
    specification of another node within the DHT. A valid node is a tuple with
    four items:

    * A string representation of the SHA512 ID of the node.
    * A string representation of the node's IP address.
    * An integer representation of the node's port within a valid range of
      port values.
    * A string representation of the version of Drogulus the remote node
      conforms to.
    """
    if isinstance(val, tuple):
        if len(val) == 4:
            valid_id = validate_string(val[0])
            valid_adr = validate_string(val[1])
            valid_version = validate_string(val[3])
            port = val[2]
            if isinstance(port, int):
                return (valid_id and valid_adr and valid_version and
                        (port >= 0 and port <= 49151))
    return False


def validate_nodes(val):
    """
    Returns a boolean to indicate that a field is a tuple that may contain
    information about nodes.
    """
    if isinstance(val, tuple):
        for node in val:
            if not validate_node(node):
                return False
    else:
        return False
    return True


def validate_value(val):
    """
    Returns a boolean to indicate that a value stored in the DHT is valid.
    Currently *all* values are valid although in the future, size may be
    limited.
    """
    return True

"""
Lookup for the correct validation function for each type of field a message
may contain. Explicit is better than implicit (Zen of Python).
"""
VALIDATORS = {
    'uuid': validate_string,
    'node': validate_string,
    'code': validate_code,
    'title': validate_string,
    'details': validate_meta,
    'version': validate_string,
    'key': validate_string,
    'value': validate_value,
    'timestamp': validate_timestamp,
    'expires': validate_timestamp,
    'public_key': validate_string,
    'name': validate_string,
    'meta': validate_meta,
    'created_with': validate_string,
    'sig': validate_string,
    'nodes': validate_nodes
}

########NEW FILE########
__FILENAME__ = node
# -*- coding: utf-8 -*-
"""
Encapsulates a node in the drogulus.
"""

# Copyright (C) 2012-2013 Nicholas H.Tollervey.
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU Affero General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU Affero General Public License for more details.
#
# You should have received a copy of the GNU Affero General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.

import time
from constants import DUPLICATION_COUNT, EXPIRY_DURATION
from crypto import generate_signature, construct_key
from dht.node import Node


class Drogulus(object):
    """
    Represents a node in the Drogulus distributed hash table. This is the
    class that generally should be instantiated.
    """

    def __init__(self, private_key, public_key, alias=None):
        self.private_key = private_key
        self.public_key = public_key
        self._node = Node()
        if alias:
            self.alias = alias
        else:
            self.alias = {}

    def join(self):
        """
        Causes the node to join the distributed hash table. Returns a deferred
        that fires when the operation is complete.
        """
        pass

    def whois(self, public_key):
        """
        Given the public key of an entity that uses the drogulus will return a
        deferred that fires when information about them stored in the DHT is
        retrieved.
        """
        return self.get(public_key, None)

    def get(self, public_key, key_name):
        """
        Gets the value associated with a compound key made of the passed in
        public key and meaningful key name. Returns a deferred that fires when
        the value is retrieved.
        """
        target = construct_key(public_key, key_name)
        return self._node.retrieve(target)

    def set(self, key_name, value, duplicate=DUPLICATION_COUNT, meta=None,
            expires=EXPIRY_DURATION):
        """
        Stores a value at a compound key made from the local node's public key
        and the passed in meaningful key name. Returns a deferred that fires
        when the value has been stored to duplicate number of nodes. An
        optional meta dictionary and expires duration (to be added to the
        current time) can also be specified.
        """
        timestamp = time.time()

        if meta is None:
            meta = {}

        if expires < 1:
            expires = -1
        else:
            expires = timestamp + expires

        signature = generate_signature(value, timestamp, expires, key_name,
                                       meta, self.private_key)

        return self._node.replicate(self.public_key, key_name, value,
                                    timestamp, expires, meta, signature,
                                    duplicate)

########NEW FILE########
__FILENAME__ = utils
# -*- coding: utf-8 -*-
"""
Contains generic utillity functions used in various different parts of
Drogulus.
"""

# Copyright (C) 2012-2013 Nicholas H.Tollervey.
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU Affero General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU Affero General Public License for more details.
#
# You should have received a copy of the GNU Affero General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.

from constants import K


def long_to_hex(raw):
    """
    Given a raw numeric value (like a node's ID for example) returns it
    expressed as a hexadecimal string.
    """
    # Turn it into hex string (remembering to drop the '0x' at the start).
    as_hex = hex(raw)[2:]
    # If the integer is 'long' knock off the 'L'.
    if as_hex[-1] == 'L':
        as_hex = as_hex[:-1]
    # If required, correct length by appending 'padding' zeros.
    if len(as_hex) % 2 != 0:
        as_hex = '0' + as_hex
    as_hex = as_hex.decode('hex')
    return as_hex


def hex_to_long(raw):
    """
    Given a hexadecimal string representation of a number (like a key or
    node's ID for example) returns the numeric (long) value.
    """
    return long(raw.encode('hex'), 16)


def distance(key_one, key_two):
    """
    Calculate the XOR result between two string variables returned as a long
    type value.
    """
    val_key_one = hex_to_long(key_one)
    val_key_two = hex_to_long(key_two)
    return val_key_one ^ val_key_two


def sort_contacts(contacts, target_key):
    """
    Given a list of contacts, efficiently sorts it so that the contacts closest
    to the target key are at the head. If the list is longer than K then only
    the K closest contacts will be returned.
    """
    # Key function
    def node_key(node):
        """
        Returns the node's distance to the target key.
        """
        return distance(node.id, target_key)

    contacts.sort(key=node_key)
    return contacts[:K]

########NEW FILE########
__FILENAME__ = version
# -*- coding: utf-8 -*-
"""
An over engineered way of setting the version. Based upon a simplification of
how Django (http://djangoproject.com/) does it. ;-)
"""

# Copyright (C) 2012-2013 Nicholas H.Tollervey.
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU Affero General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU Affero General Public License for more details.
#
# You should have received a copy of the GNU Affero General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.


#: MAJOR, MINOR, RELEASE, STATUS [alpha, beta, final], VERSION
VERSION = (0, 0, 0, 'alpha', 0)


def get_version():
    """
    Returns a string representation of the version information of this project.
    """
    return '.'.join([str(i) for i in VERSION])

########NEW FILE########
__FILENAME__ = test_contact
# -*- coding: utf-8 -*-
"""
Ensures details of contacts (other nodes on the network) are represented
correctly.
"""
from drogulus.dht.contact import Contact
from drogulus.version import get_version
import unittest


class TestContact(unittest.TestCase):
    """
    Ensures the Contact class works as expected.
    """

    def test_init(self):
        """
        Ensures an object is created as expected.
        """
        id = '12345'
        address = '192.168.0.1'
        port = 9999
        version = get_version()
        last_seen = 123
        contact = Contact(id, address, port, version, last_seen)
        self.assertEqual(id, contact.id)
        self.assertEqual(address, contact.address)
        self.assertEqual(port, contact.port)
        self.assertEqual(version, contact.version)
        self.assertEqual(last_seen, contact.last_seen)
        self.assertEqual(0, contact.failed_RPCs)

    def test_init_with_long_id(self):
        """
        If the ID is passed in as a long value ensure it's translated to the
        correct string representation of the hex version.
        """
        id = 12345L
        address = '192.168.0.1'
        port = 9999
        version = get_version()
        last_seen = 123
        contact = Contact(id, address, port, version, last_seen)
        expected = '09'
        self.assertEqual(expected, contact.id)
        self.assertEqual(12345L, long(contact.id.encode('hex'), 16))

    def test_init_with_int_id(self):
        """
        If the ID is passed in as an int value ensure it's translated to the
        correct string representation of the hex version.
        """
        id = 12345
        address = '192.168.0.1'
        port = 9999
        version = get_version()
        last_seen = 123
        contact = Contact(id, address, port, version, last_seen)
        expected = '09'
        self.assertEqual(expected, contact.id)
        self.assertEqual(12345L, long(contact.id.encode('hex'), 16))

    def test_eq(self):
        """
        Makes sure equality works between a string representation of an ID and
        a contact object.
        """
        id = '12345'
        address = '192.168.0.1'
        port = 9999
        version = get_version()
        last_seen = 123
        contact = Contact(id, address, port, version, last_seen)
        self.assertTrue(id == contact)

    def test_ne(self):
        """
        Makes sure non-equality works between a string representation of an ID
        and a contact object.
        """
        id = '12345'
        address = '192.168.0.1'
        port = 9999
        version = get_version()
        last_seen = 123
        contact = Contact(id, address, port, version, last_seen)
        self.assertTrue('54321' != contact)

    def test_str(self):
        """
        Ensures the string representation of a contact is something useful.
        """
        id = '12345'
        address = '192.168.0.1'
        port = 9999
        version = get_version()
        last_seen = 123
        contact = Contact(id, address, port, version, last_seen)
        expected = "('12345', '192.168.0.1', 9999, '%s', 123, 0)" % version
        self.assertEqual(expected, str(contact))

########NEW FILE########
__FILENAME__ = test_datastore
# -*- coding: utf-8 -*-
"""
Ensures datastore related classes work as expected.
"""
from drogulus.dht.datastore import DataStore, DictDataStore
from drogulus.net.messages import Value
from drogulus.crypto import construct_key, generate_signature
import unittest
import time
from uuid import uuid4


# Useful throw-away constants for testing purposes.
PRIVATE_KEY = """-----BEGIN RSA PRIVATE KEY-----
MIICXgIBAAKBgQC+n3Au1cbSkjCVsrfnTbmA0SwQLN2RbbDIMHILA1i6wByXkqEa
mnEBvgsOkUUrsEXYtt0vb8Qill4LSs9RqTetSCjGb+oGVTKizfbMbGCKZ8fT64ZZ
gan9TvhItl7DAwbIXcyvQ+b1J7pHaytAZwkSwh+M6WixkMTbFM91fW0mUwIDAQAB
AoGBAJvBENvj5wH1W2dl0ShY9MLRpuxMjHogo3rfQr/G60AkavhaYfKn0MB4tPYh
MuCgtmF+ATqaWytbq9oUNVPnLUqqn5M9N86+Gb6z8ld+AcR2BD8oZ6tQaiEIGzmi
L9AWEZZnyluDSHMXDoVrvDLxPpKW0yPjvQfWN15QF+H79faJAkEA0hgdueFrZf3h
os59ukzNzQy4gjL5ea35azbQt2jTc+lDOu+yjUic2O7Os7oxnSArpujDiOkYgaih
Dny+/bIgLQJBAOhGKjhpafdpgpr/BjRlmUHXLaa+Zrp/S4RtkIEkE9XXkmQjvVZ3
EyN/h0IVNBv45lDK0Qztjic0L1GON62Z8H8CQAcRkqZ3ZCKpWRceNXK4NNBqVibj
SiuC4/psfLc/CqZCueVYvTwtrkFKP6Aiaprrwyw5dqK7nPx3zPtszQxCGv0CQQDK
51BGiz94VAE1qQYgi4g/zdshSD6xODYd7yBGz99L9M77D4V8nPRpFCRyA9fLf7ii
ZyoLYxHFCX80fUoCKvG9AkEAyX5iCi3aoLYd/CvOFYB2fcXzauKrhopS7/NruDk/
LluSlW3qpi1BGDHVTeWWj2sm30NAybTHjNOX7OxEZ1yVwg==
-----END RSA PRIVATE KEY-----"""


PUBLIC_KEY = """-----BEGIN PUBLIC KEY-----
MIGfMA0GCSqGSIb3DQEBAQUAA4GNADCBiQKBgQC+n3Au1cbSkjCVsrfnTbmA0SwQ
LN2RbbDIMHILA1i6wByXkqEamnEBvgsOkUUrsEXYtt0vb8Qill4LSs9RqTetSCjG
b+oGVTKizfbMbGCKZ8fT64ZZgan9TvhItl7DAwbIXcyvQ+b1J7pHaytAZwkSwh+M
6WixkMTbFM91fW0mUwIDAQAB
-----END PUBLIC KEY-----"""


class TestDataStore(unittest.TestCase):
    """
    Ensures the base class is defined as expected (no functionality is built
    in to the class). Basically, a bunch of trivial sanity tests.
    """

    def test_keys(self):
        """
        Check the DataStore base class has a keys method.
        """
        self.assertTrue(hasattr(DataStore, 'keys'))
        ds = DataStore()
        self.assertEqual(NotImplemented, ds.keys())

    def test_last_updated(self):
        """
        Check the DataStore base class has a last_updated method.
        """
        self.assertTrue(hasattr(DataStore, 'last_updated'))
        ds = DataStore()
        self.assertEqual(NotImplemented, ds.last_updated('foo'))

    def test_original_publisher_id(self):
        """
        Check the DataStore base class has an original_publisher_id method.
        """
        self.assertTrue(hasattr(DataStore, 'original_publisher_id'))
        ds = DataStore()
        self.assertEqual(NotImplemented, ds.original_publisher_id(123))

    def test_original_publish_time(self):
        """
        Check the DataStore base class has an original_publish_time method.
        """
        self.assertTrue(hasattr(DataStore, 'original_publish_time'))
        ds = DataStore()
        self.assertEqual(NotImplemented, ds.original_publish_time(123))

    def test_set_item(self):
        """
        Check the DataStore base class has a set_item method.
        """
        self.assertTrue(hasattr(DataStore, 'set_item'))
        ds = DataStore()
        self.assertEqual(NotImplemented, ds.set_item(123, 'value'))

    def test__getitem__(self):
        """
        Check the DataStore base class has a __getitem__ method.
        """
        self.assertTrue(hasattr(DataStore, '__getitem__'))
        ds = DataStore()
        self.assertEqual(NotImplemented, ds['item'])

    def test__setitem__(self):
        """
        Check the DataStore base class has a __setitem__ method.
        """
        self.assertTrue(hasattr(DataStore, '__setitem__'))

    def testDelete(self):
        """
        Check the DataStore base class has a __delitem__ method.
        """
        self.assertTrue(hasattr(DataStore, '__delitem__'))
        ds = DataStore()
        with self.assertRaises(KeyError):
            del ds['item']


class TestDictDataStore(unittest.TestCase):
    """
    Ensures that the in-memory Python dict based data store works as expected.
    """

    def setUp(self):
        """
        A message to play with.
        """
        self.uuid = str(uuid4())
        self.node = '9876543210abcd'.decode('hex')
        self.value = 1.234
        self.timestamp = time.time()
        self.expires = self.timestamp + 1000
        self.public_key = PUBLIC_KEY
        self.name = 'a_human_readable_key_name'
        self.key = construct_key(self.public_key, self.name)
        self.meta = {
            'mime': 'numeric',
            'description': 'a test value'
        }
        self.version = '0.1'
        self.sig = generate_signature(self.value, self.timestamp, self.expires,
                                      self.name, self.meta, self.version,
                                      PRIVATE_KEY)
        self.message = 'value'
        self.mock_value = Value(self.uuid, self.node, self.key, self.value,
                                self.timestamp, self.expires, self.version,
                                self.public_key, self.name, self.meta,
                                self.sig, self.version)

    def test__init__(self):
        """
        Ensures the DictDataStore is instantiated to an expected state.
        """
        store = DictDataStore()
        self.assertTrue(hasattr(store, '_dict'))
        self.assertEqual({}, store._dict)

    def test_keys(self):
        """
        Ensure the keys method works as expected.
        """
        store = DictDataStore()
        self.assertEqual([], store.keys())
        store['foo'] = self.mock_value
        self.assertTrue('foo' in store.keys())

    def test_last_published(self):
        """
        Ensures the expected value is returned from last_updated for a given
        key (a float representing a timestamp).
        """
        store = DictDataStore()
        store['foo'] = self.mock_value
        self.assertIsInstance(store.last_updated('foo'), float)

    def test_original_publisher_id(self):
        """
        Ensures the correct value is returned from original_publisher_id for a
        given key.
        """
        store = DictDataStore()
        store['foo'] = self.mock_value
        self.assertEqual(self.public_key, store.original_publisher_id('foo'))

    def test_original_publish_time(self):
        """
        Ensures the correct value is returned from original_publish_time for a
        given key.
        """
        store = DictDataStore()
        store['foo'] = self.mock_value
        self.assertEqual(self.timestamp, store.original_publish_time('foo'))

    def test_set_item(self):
        """
        Ensures that the set_item method works as expected.
        """
        store = DictDataStore()
        store.set_item('foo', self.mock_value)
        self.assertEqual(1, len(store.keys()))
        self.assertEqual('foo', store.keys()[0])
        self.assertEqual(self.mock_value, store['foo'])

    def test__getitem__(self):
        """
        Ensures that the __getitem__ method works as expected.
        """
        store = DictDataStore()
        store.set_item('foo', self.mock_value)
        self.assertEqual(self.mock_value, store['foo'])

    def test__delitem__(self):
        """
        Ensures that the __delitem__ method works as expected.
        """
        store = DictDataStore()
        store.set_item('foo', self.mock_value)
        self.assertEqual(1, len(store.keys()))
        del store['foo']
        self.assertEqual(0, len(store.keys()))

########NEW FILE########
__FILENAME__ = test_kbucket
# -*- coding: utf-8 -*-
"""
Ensures the kbucket (used to store contacts in the network) works as expected.
"""
from drogulus.dht.kbucket import KBucket, KBucketFull
from drogulus.dht.contact import Contact
from drogulus.constants import K
import unittest


class TestKBucket(unittest.TestCase):
    """
    Ensures the KBucket class works as expected.
    """

    def test_init(self):
        """
        Ensures an object is created as expected.
        """
        range_min = 12345
        range_max = 98765
        bucket = KBucket(range_min, range_max)
        # Min/Max are set correctly
        self.assertEqual(range_min, bucket.range_min,
                         "KBucket rangeMin not set correctly.")
        self.assertEqual(range_max, bucket.range_max,
                         "KBucket rangeMax not initialised correctly.")
        # The contacts list exists and is empty
        self.assertEqual([], bucket._contacts,
                         "KBucket contact list not initialised correctly.")
        # Last access timestamp is correct
        self.assertEqual(0, bucket.last_accessed)

    def test_add_new_contact(self):
        """
        Ensures that a new contact, when added to the kbucket is appended to
        the end of the _contacts list (as specified in the original Kademlia
        paper) signifying that it is the most recently seen contact within
        this bucket.
        """
        range_min = 12345
        range_max = 98765
        bucket = KBucket(range_min, range_max)
        contact1 = Contact("1", "192.168.0.1", 9999, 123)
        bucket.add_contact(contact1)
        self.assertEqual(1, len(bucket._contacts),
                         "Single contact not added to k-bucket.")
        contact2 = Contact("2", "192.168.0.2", 8888, 123)
        bucket.add_contact(contact2)
        self.assertEqual(2, len(bucket._contacts),
                         "K-bucket's contact list not the expected length.")
        self.assertEqual(contact2, bucket._contacts[-1:][0],
                         "K-bucket's most recent (last) contact wrong.")

    def test_add_existing_contact(self):
        """
        Ensures that if an existing contact is re-added to the kbucket it is
        simply moved to the end of the _contacts list (as specified in the
        original Kademlia paper) signifying that it is the most recently seen
        contact within this bucket.
        """
        range_min = 12345
        range_max = 98765
        bucket = KBucket(range_min, range_max)
        contact1 = Contact("1", "192.168.0.1", 9999, 123)
        bucket.add_contact(contact1)
        contact2 = Contact("2", "192.168.0.2", 8888, 123)
        bucket.add_contact(contact2)
        bucket.add_contact(contact1)
        # There should still only be two contacts in the bucket.
        self.assertEqual(2, len(bucket._contacts),
                         "Too many contacts in the k-bucket.")
        # The end contact should be the most recently added contact.
        self.assertEqual(contact1, bucket._contacts[-1:][0],
                         "The expected most recent contact is wrong.")

    def test_add_contact_to_full_bucket(self):
        """
        Ensures that if one attempts to add a contact to a bucket whose size is
        greater than the constant K, then the KBucketFull exception is raised.
        """
        range_min = 12345
        range_max = 98765
        bucket = KBucket(range_min, range_max)
        for i in range(K):
            contact = Contact("%d" % i, "192.168.0.%d" % i, 9999, 123)
            bucket.add_contact(contact)
        with self.assertRaises(KBucketFull):
            contact_too_many = Contact("12345", "192.168.0.2", 8888, 123)
            bucket.add_contact(contact_too_many)

    def test_get_contact(self):
        """
        Ensures it is possible to get a contact from the k-bucket with a valid
        id.
        """
        range_min = 12345
        range_max = 98765
        bucket = KBucket(range_min, range_max)
        for i in range(K):
            contact = Contact("%d" % i, "192.168.0.%d" % i, 9999, 123)
            bucket.add_contact(contact)
        for i in range(K):
            self.assertTrue(bucket.get_contact("%d" % i),
                            "Could not get contact with id %d" % i)

    def test_get_contact_with_bad_id(self):
        """
        Ensures a ValueError exception is raised if one attempts to get a
        contact from the k-bucket with an id that doesn't exist in the
        k-bucket.
        """
        range_min = 12345
        range_max = 98765
        bucket = KBucket(range_min, range_max)
        contact = Contact("12345", "192.168.0.2", 8888, 123)
        bucket.add_contact(contact)
        with self.assertRaises(ValueError):
            bucket.get_contact("54321")

    def test_get_contacts_all(self):
        """
        Ensures get_contacts works as expected.
        """
        range_min = 12345
        range_max = 98765
        bucket = KBucket(range_min, range_max)
        for i in range(K):
            contact = Contact("%d" % i, "192.168.0.%d" % i, 9999, 123)
            bucket.add_contact(contact)
        result = bucket.get_contacts()
        self.assertEqual(20, len(result))

    def test_get_contacts_empty(self):
        """
        If the k-bucket is empty, the result of getContacts is an empty list.
        """
        range_min = 12345
        range_max = 98765
        bucket = KBucket(range_min, range_max)
        result = bucket.get_contacts()
        self.assertEqual(0, len(result))

    def test_get_contacts_count_too_big(self):
        """
        If the "count" argument is bigger than the number of contacts in the
        bucket then all the contacts are returned.
        """
        range_min = 12345
        range_max = 98765
        bucket = KBucket(range_min, range_max)
        for i in range(10):
            contact = Contact("%d" % i, "192.168.0.%d" % i, 9999, 123)
            bucket.add_contact(contact)
        result = bucket.get_contacts(count=20)
        self.assertEqual(10, len(result))

    def test_get_contacts_with_exclusion(self):
        """
        If a contact is passed as the excludeContact argument then it won't be
        in the result list.
        """
        range_min = 12345
        range_max = 98765
        bucket = KBucket(range_min, range_max)
        for i in range(K):
            contact = Contact("%d" % i, "192.168.0.%d" % i, 9999, 123)
            bucket.add_contact(contact)
        result = bucket.get_contacts(count=20, exclude_contact=contact)
        self.assertEqual(19, len(result))
        self.assertFalse(contact in result)

    def test_remove_contact(self):
        """
        Ensures it is possible to remove a contact with a certain ID from the
        k-bucket.
        """
        range_min = 12345
        range_max = 98765
        bucket = KBucket(range_min, range_max)
        for i in range(K):
            contact = Contact("%d" % i, "192.168.0.%d" % i, 9999, 123)
            bucket.add_contact(contact)
        for i in range(K):
            id = "%d" % i
            bucket.remove_contact(id)
            self.assertFalse(id in bucket._contacts,
                             "Could not remove contact with id %d" % i)

    def test_remove_contact_with_bad_id(self):
        """
        Ensures a ValueError exception is raised if one attempts to remove a
        non-existent contact from a k-bucket.
        """
        range_min = 12345
        range_max = 98765
        bucket = KBucket(range_min, range_max)
        contact = Contact("12345", "192.168.0.2", 8888, 123)
        bucket.add_contact(contact)
        with self.assertRaises(ValueError):
            bucket.remove_contact("54321")

    def test_key_in_range_yes(self):
        """
        Ensures that a key within the appropriate range is identified as such.
        """
        bucket = KBucket(1, 9)
        self.assertTrue(bucket.key_in_range(2))

    def test_key_in_range_no_too_low(self):
        """
        Ensures a key just below the k-bucket's range is identified as out of
        range.
        """
        bucket = KBucket(5, 9)
        self.assertFalse(bucket.key_in_range(2))

    def test_key_in_range_no_too_high(self):
        """
        Ensures a key just above the k-bucket's range is identified as out of
        range.
        """
        bucket = KBucket(1, 5)
        self.assertFalse(bucket.key_in_range(7))

    def test_key_in_range_handles_string(self):
        """
        Ensures the keyInRange method decodes a string representation of a key
        correctly, before testing if it's within range.
        """
        bucket = KBucket(1, 66)
        self.assertTrue(bucket.key_in_range('A'))

    def test_len(self):
        """
        Ensures the number of nodes in the k-bucket is returned by __len__.
        """
        range_min = 12345
        range_max = 98765
        bucket = KBucket(range_min, range_max)
        contact = Contact("12345", "192.168.0.2", 8888, 123)
        bucket.add_contact(contact)
        self.assertEqual(1, len(bucket))

########NEW FILE########
__FILENAME__ = test_node
# -*- coding: utf-8 -*-
"""
Ensures code that represents a local node in the DHT network works as
expected
"""
from drogulus.dht.node import (RoutingTableEmpty, response_timeout, NodeLookup,
                               Node, ValueNotFound)
from drogulus.dht.routingtable import RoutingTable
from drogulus.constants import (ERRORS, RPC_TIMEOUT, RESPONSE_TIMEOUT, K,
                                REPLICATE_INTERVAL, ALPHA, DUPLICATION_COUNT)
from drogulus.dht.contact import Contact
from drogulus.version import get_version
from drogulus.net.protocol import DHTFactory
from drogulus.net.messages import (Error, Ping, Pong, Store, FindNode, Nodes,
                                   FindValue, Value)
from drogulus.crypto import construct_key, generate_signature
from drogulus.utils import long_to_hex, sort_contacts
from twisted.trial import unittest
from twisted.test import proto_helpers
from twisted.python import log
from twisted.internet import defer, task, reactor
from twisted.python.failure import Failure
from mock import MagicMock, patch
from uuid import uuid4
import time


# Useful throw-away constants for testing purposes.
PRIVATE_KEY = """-----BEGIN RSA PRIVATE KEY-----
MIICXgIBAAKBgQC+n3Au1cbSkjCVsrfnTbmA0SwQLN2RbbDIMHILA1i6wByXkqEa
mnEBvgsOkUUrsEXYtt0vb8Qill4LSs9RqTetSCjGb+oGVTKizfbMbGCKZ8fT64ZZ
gan9TvhItl7DAwbIXcyvQ+b1J7pHaytAZwkSwh+M6WixkMTbFM91fW0mUwIDAQAB
AoGBAJvBENvj5wH1W2dl0ShY9MLRpuxMjHogo3rfQr/G60AkavhaYfKn0MB4tPYh
MuCgtmF+ATqaWytbq9oUNVPnLUqqn5M9N86+Gb6z8ld+AcR2BD8oZ6tQaiEIGzmi
L9AWEZZnyluDSHMXDoVrvDLxPpKW0yPjvQfWN15QF+H79faJAkEA0hgdueFrZf3h
os59ukzNzQy4gjL5ea35azbQt2jTc+lDOu+yjUic2O7Os7oxnSArpujDiOkYgaih
Dny+/bIgLQJBAOhGKjhpafdpgpr/BjRlmUHXLaa+Zrp/S4RtkIEkE9XXkmQjvVZ3
EyN/h0IVNBv45lDK0Qztjic0L1GON62Z8H8CQAcRkqZ3ZCKpWRceNXK4NNBqVibj
SiuC4/psfLc/CqZCueVYvTwtrkFKP6Aiaprrwyw5dqK7nPx3zPtszQxCGv0CQQDK
51BGiz94VAE1qQYgi4g/zdshSD6xODYd7yBGz99L9M77D4V8nPRpFCRyA9fLf7ii
ZyoLYxHFCX80fUoCKvG9AkEAyX5iCi3aoLYd/CvOFYB2fcXzauKrhopS7/NruDk/
LluSlW3qpi1BGDHVTeWWj2sm30NAybTHjNOX7OxEZ1yVwg==
-----END RSA PRIVATE KEY-----"""


PUBLIC_KEY = """-----BEGIN PUBLIC KEY-----
MIGfMA0GCSqGSIb3DQEBAQUAA4GNADCBiQKBgQC+n3Au1cbSkjCVsrfnTbmA0SwQ
LN2RbbDIMHILA1i6wByXkqEamnEBvgsOkUUrsEXYtt0vb8Qill4LSs9RqTetSCjG
b+oGVTKizfbMbGCKZ8fT64ZZgan9TvhItl7DAwbIXcyvQ+b1J7pHaytAZwkSwh+M
6WixkMTbFM91fW0mUwIDAQAB
-----END PUBLIC KEY-----"""


class FakeClient(object):
    """
    A class that pretends to be a client endpoint returned by Twisted's
    clientFromString. To be used with the mocks.
    """

    def __init__(self, protocol, success=True, timeout=False,
                 replace_cancel=False):
        """
        The protocol instance is set up as a fake by the test class. The
        success flag indicates if the client is to be able to work
        successfully. The timeout flag indicates if the deferred is to fire
        as if a connection has been made.
        """
        self.protocol = protocol
        self.success = success
        self.timeout = timeout
        self.replace_cancel = replace_cancel
        if replace_cancel:
            self.cancel_function = MagicMock()

    def connect(self, factory):
        d = defer.Deferred()
        if self.timeout:
            # This is a hack to ensure the cancel method is within scope of the
            # test function (as an attribute of the FakeClient object to
            # ensure it has fired. :-(
            if self.replace_cancel:
                d.cancel = self.cancel_function
            return d
        else:
            if self.success:
                d.callback(self.protocol)
            else:
                d.errback(Exception("Error!"))
            return d


def fakeAbortConnection():
    """
    Fakes the abortConnection method to be attached to the StringTransport used
    in the tests below.
    """
    pass


class TestTimeout(unittest.TestCase):
    """
    Ensures the timeout function works correctly.
    """

    def setUp(self):
        self.node_id = '1234567890abc'
        self.node = Node(self.node_id)
        self.factory = DHTFactory(self.node)
        self.protocol = self.factory.buildProtocol(('127.0.0.1', 0))
        self.transport = proto_helpers.StringTransport()
        self.protocol.makeConnection(self.transport)
        self.uuid = str(uuid4())

    def test_response_timeout(self):
        """
        Test the good case.
        """
        self.protocol.transport.abortConnection = MagicMock()
        self.node._routing_table.remove_contact = MagicMock()
        deferred = defer.Deferred()
        self.node._pending[self.uuid] = deferred
        # Create a simple Ping message.
        version = get_version()
        msg = Ping(self.uuid, self.node_id, version)
        response_timeout(msg, self.protocol, self.node)
        # The record associated with the uuid has been removed from the pending
        # dictionary.
        self.assertEqual({}, self.node._pending)
        # The deferred has been cancelled.
        self.assertIsInstance(deferred.result.value, defer.CancelledError)
        # abortConnection() has been called once.
        self.assertEqual(1, self.protocol.transport.abortConnection.call_count)
        # The remove_contact method of the routing table has been called once.
        self.node._routing_table.remove_contact.\
            assert_called_once_with(msg.node)

    def test_message_timout_missing(self):
        """
        Ensure no state is changed if the message's uuid is missing from the
        pending dict.
        """
        # There is no change in the number of messages in the pending
        # dictionary.
        self.node._pending[self.uuid] = 'a deferred'
        another_uuid = str(uuid4())
        version = get_version()
        msg = Ping(another_uuid, self.node_id, version)
        response_timeout(msg, self.protocol, self.node)
        self.assertIn(self.uuid, self.node._pending)


class TestNodeLookup(unittest.TestCase):
    """
    Ensures the NodeLookup class works as expected. See the NodeLookup class's
    documentation for a relatively simple explanation of how the class is
    supposed to function.
    """

    def setUp(self):
        """
        Following the pattern explained here:

        http://twistedmatrix.com/documents/current/core/howto/trial.html
        """
        self.node_id = '1234567890abc'
        self.node = Node(self.node_id)
        self.remote_node_count = 20
        for i in range(self.remote_node_count):
            contact = Contact(long_to_hex(i), '192.168.0.%d' % i, 9999,
                              self.node.version, 0)
            self.node._routing_table.add_contact(contact)
        self.factory = DHTFactory(self.node)
        self.protocol = self.factory.buildProtocol(('127.0.0.1', 0))
        self.transport = proto_helpers.StringTransport()
        self.transport.abortConnection = fakeAbortConnection
        self.protocol.makeConnection(self.transport)
        self.clock = task.Clock()
        reactor.callLater = self.clock.callLater
        self.value = 'value'
        self.uuid = str(uuid4())
        self.timestamp = time.time()
        self.expires = self.timestamp + 1000
        self.name = 'name'
        self.meta = {'meta': 'value'}
        self.version = get_version()
        self.signature = generate_signature(self.value, self.timestamp,
                                            self.expires, self.name, self.meta,
                                            self.version, PRIVATE_KEY)
        self.key = construct_key(PUBLIC_KEY, self.name)
        self.timeout = 1000
        self.target_key = long_to_hex(100)
        node_list = []
        for i in range(101, 121):
            contact_id = long_to_hex(i)
            contact_address = '192.168.1.%d' % i
            contact_port = 9999
            contact_version = self.version
            contact_last_seen = self.timestamp - (i * 100)
            contact = Contact(contact_id, contact_address, contact_port,
                              contact_version, contact_last_seen)
            node_list.append(contact)
        self.nodes = tuple(sort_contacts(node_list, self.target_key))

    def test_init(self):
        """
        The simplest case - ensure the object is set up correctly.
        """
        lookup = NodeLookup(self.key, FindNode, self.node)
        self.assertIsInstance(lookup, defer.Deferred)
        self.assertEqual(lookup.target, self.key)
        self.assertEqual(lookup.message_type, FindNode)
        self.assertEqual(lookup.local_node, self.node)
        self.assertIsInstance(lookup.contacted, set)
        self.assertIsInstance(lookup.pending_requests, dict)
        self.assertIsInstance(lookup.shortlist, list)
        self.assertEqual(lookup.nearest_node, lookup.shortlist[0])

    def test_lookup_called_by_init(self, ):
        """
        Ensure that the __init__ method kicks off the lookup by calling the
        NodeLookup's _lookup method.
        """
        # Patch NodeLookup._lookup
        patcher = patch('drogulus.dht.node.NodeLookup._lookup')
        mock_lookup = patcher.start()
        NodeLookup(self.key, FindNode, self.node, self.timeout)
        self.assertEqual(1, mock_lookup.call_count)
        # Tidy up.
        patcher.stop()

    def test_init_timeout_called(self):
        """
        Ensure the cancel method is called after timeout seconds.
        """
        patcher = patch('drogulus.dht.node.NodeLookup._lookup')
        patcher.start()
        lookup = NodeLookup(self.key, FindNode, self.node, self.timeout)
        lookup.cancel = MagicMock()
        self.clock.advance(self.timeout)
        lookup.cancel.called_once_with(lookup)
        self.failureResultOf(lookup).trap(defer.CancelledError)
        patcher.stop()

    def test_init_finds_close_nodes(self):
        """
        Ensure that __init__ attempts to call find_close_nodes on the routing
        table.
        """
        self.node._routing_table.find_close_nodes = MagicMock()
        NodeLookup(self.key, FindNode, self.node)
        self.node._routing_table.find_close_nodes.\
            assert_called_once_with(self.key)

    def test_init_touches_kbucket(self):
        """
        If the target key is not the local node's id then touch_kbucket needs
        to be called to update the last_accessed attribute of the K-bucket
        containing the target key.
        """
        self.node._routing_table.touch_kbucket = MagicMock()
        NodeLookup(self.key, FindNode, self.node)
        self.node._routing_table.touch_kbucket.\
            assert_called_once_with(self.key)

    def test_init_skips_touch_kbucket_if_node_id_is_key(self):
        """
        The touch_kbucket operation only needs to happen if the target key is
        NOT the local node's id.
        """
        self.node._routing_table.touch_kbucket = MagicMock()
        NodeLookup(self.node.id, FindNode, self.node)
        self.assertEqual(0, self.node._routing_table.touch_kbucket.call_count)

    def test_init_no_known_nodes(self):
        """
        Checks that if the local node doesn't know of any other nodes then
        the resulting lookup calls back with a RoutingTableEmpty exception.
        """
        self.node._routing_table = RoutingTable(self.node.id)
        lookup = NodeLookup(self.key, FindNode, self.node)
        self.assertIsInstance(lookup, defer.Deferred)
        self.assertTrue(lookup.called)

        def errback_check(result):
            self.assertIsInstance(result.value, RoutingTableEmpty)

        lookup.addErrback(errback_check)

    def test_cancel_pending_requests(self):
        """
        Ensures any deferreds stored in self.pending_requests are cancelled.
        """
        # Avoids the creation of surplus to requirements deferreds during the
        # __init__ of the lookup object.
        patcher = patch('drogulus.dht.node.NodeLookup._lookup')
        patcher.start()
        lookup = NodeLookup(self.key, FindNode, self.node)
        d1 = defer.Deferred()
        d2 = defer.Deferred()
        d3 = defer.Deferred()
        errback1 = MagicMock()
        errback2 = MagicMock()
        errback3 = MagicMock()
        d1.addErrback(errback1)
        d2.addErrback(errback2)
        d3.addErrback(errback3)
        lookup.pending_requests[1] = d1
        lookup.pending_requests[2] = d2
        lookup.pending_requests[3] = d3
        lookup.cancel()
        self.assertEqual(1, errback1.call_count)
        self.assertIsInstance(errback1.call_args[0][0].value,
                              defer.CancelledError)
        self.assertEqual(1, errback2.call_count)
        self.assertIsInstance(errback2.call_args[0][0].value,
                              defer.CancelledError)
        self.assertEqual(1, errback3.call_count)
        self.assertIsInstance(errback3.call_args[0][0].value,
                              defer.CancelledError)
        self.assertEqual(0, len(lookup.pending_requests))
        # Tidy up.
        patcher.stop()

    def test_cancel(self):
        """
        Ensures the cancel function attempts to tidy up correctly.
        """
        errback = MagicMock()
        lookup = NodeLookup(self.key, FindNode, self.node)
        lookup._cancel_pending_requests = MagicMock()
        lookup.addErrback(errback)
        lookup.cancel()
        self.assertEqual(1, lookup._cancel_pending_requests.call_count)
        self.assertEqual(1, errback.call_count)
        self.assertIsInstance(errback.call_args[0][0].value,
                              defer.CancelledError)

    def test_lookup_none_pending_none_contacted(self):
        """
        Ensures the lookup method works with no pending requests nor any nodes
        previously contacted.
        """

        def side_effect(*args):
            """
            Ensures the mock returns something useful.
            """
            uuid = str(uuid4())
            deferred = defer.Deferred()
            return (uuid, deferred)

        self.node.send_find = MagicMock(side_effect=side_effect)

        lookup = NodeLookup(self.key, FindNode, self.node)
        # The _lookup method is called by __init__ from the state being checked
        # by this test (i.e. no pending requests or any previously contacted
        # nodes).
        self.assertEqual(ALPHA, self.node.send_find.call_count)
        self.assertEqual(ALPHA, len(lookup.pending_requests))
        self.assertEqual(ALPHA, len(lookup.contacted))

    def test_lookup_some_pending_some_contacted(self):
        """
        Ensures the lookup method works with some pending slots available and
        some nodes previously contacted.
        """
        def side_effect(*args):
            """
            Ensures the mock returns something useful.
            """
            uuid = str(uuid4())
            deferred = defer.Deferred()
            return (uuid, deferred)

        self.node.send_find = MagicMock(side_effect=side_effect)

        lookup = NodeLookup(self.key, FindNode, self.node)
        # Reset the state of lookup.
        lookup.pending_requests = {}
        lookup.contacted = set()
        self.node.send_find.call_count = 0

        # Add a single pending request.
        pending_uuid = str(uuid4())
        pending_deferred = defer.Deferred()
        lookup.pending_requests[pending_uuid] = pending_deferred
        # Add a single contact to the contacted list.
        lookup.contacted.add(lookup.shortlist[0])
        # Test the state.
        self.assertEqual(1, len(lookup.pending_requests))
        self.assertEqual(1, len(lookup.contacted))

        # Re-run _lookup and test.
        lookup._lookup()
        self.assertEqual(ALPHA - 1, self.node.send_find.call_count)
        self.assertEqual(ALPHA, len(lookup.pending_requests))
        self.assertEqual(ALPHA, len(lookup.contacted))

    def test_lookup_all_pending_some_contacted(self):
        """
        Ensures the lookup method works as expected with no more pending slots
        left available and some nodes previously contacted.

        This situation should never occur but I'm testing it to ensure the
        guard against sending surplus expensive network calls works.
        """
        def side_effect(*args):
            """
            Ensures the mock returns something useful.
            """
            uuid = str(uuid4())
            deferred = defer.Deferred()
            return (uuid, deferred)

        self.node.send_find = MagicMock(side_effect=side_effect)

        lookup = NodeLookup(self.key, FindNode, self.node)
        # Ensure we have a good starting state (all [ALPHA] pending_requests
        # slots are taken, only ALPHA nodes have been contacted, there are
        # still [K] candidate nodes in the shortlist).
        self.assertEqual(ALPHA, self.node.send_find.call_count)
        self.assertEqual(ALPHA, len(lookup.pending_requests))
        self.assertEqual(ALPHA, len(lookup.contacted))
        self.assertEqual(K, len(lookup.shortlist))

        # Re-run _lookup and ensure no further network calls are made.
        lookup._lookup()
        self.assertEqual(ALPHA, self.node.send_find.call_count)

    def test_lookup_none_pending_all_contacted(self):
        """
        Ensures the lookup method works with no pending requests and all known
        nodes having previously been contacted.
        """
        def side_effect(*args):
            """
            Ensures the mock returns something useful.
            """
            uuid = str(uuid4())
            deferred = defer.Deferred()
            return (uuid, deferred)

        self.node.send_find = MagicMock(side_effect=side_effect)

        lookup = NodeLookup(self.key, FindNode, self.node)
        # Put lookup in the state to test.
        lookup.pending_requests = {}
        for contact in lookup.shortlist:
            lookup.contacted.add(contact)
        self.node.send_find.call_count = 0

        # Re-run _lookup and test
        lookup._lookup()
        self.assertEqual(0, self.node.send_find.call_count)

    def test_lookup_adds_callback(self):
        """
        Ensures the lookup method adds the expected callback to the deferreds
        that represent requests to other nodes in the DHT.
        """
        patcher = patch('drogulus.dht.node.NodeLookup._handle_response')
        mock_handle_response = patcher.start()

        def side_effect(*args):
            """
            Ensures the mock returns something useful.
            """
            uuid = str(uuid4())
            deferred = defer.Deferred()
            deferred.callback("result")
            return (uuid, deferred)

        self.node.send_find = MagicMock(side_effect=side_effect)
        NodeLookup(self.key, FindNode, self.node)
        # Check the expected callbacks have been called correctly
        self.assertEqual(ALPHA, mock_handle_response.call_count)
        # Ensure the errback was called with the expected values
        # Arg 1 = string (uuid).
        self.assertEqual(str, mock_handle_response.call_args[0][0].__class__)
        # Arg 2 = Contact instance.
        self.assertEqual(Contact,
                         mock_handle_response.call_args[0][1].__class__)
        # Arg 3 = result.
        self.assertEqual("result", mock_handle_response.call_args[0][2])
        # Tidy up.
        patcher.stop()

    def test_lookup_adds_errback(self):
        """
        Ensures the lookup method adds the expected errback to the deferreds
        that represent requests to other nodes in the DHT.
        """
        patcher = patch('drogulus.dht.node.NodeLookup._handle_error')
        mock_handle_error = patcher.start()

        def side_effect(*args):
            """
            Ensures the mock returns something useful.
            """
            uuid = str(uuid4())
            deferred = defer.Deferred()
            deferred.errback(Exception('Error'))
            return (uuid, deferred)

        self.node.send_find = MagicMock(side_effect=side_effect)
        NodeLookup(self.key, FindNode, self.node)
        # Check the expected errbacks have been called correctly
        self.assertEqual(ALPHA, mock_handle_error.call_count)
        # Ensure the errback was called with the expected values
        # Arg 1 = string (uuid).
        self.assertEqual(str, mock_handle_error.call_args[0][0].__class__)
        # Arg 2 = Contact instance.
        self.assertEqual(Contact, mock_handle_error.call_args[0][1].__class__)
        # Arg 3 = Failure instance (to wrap the exception).
        self.assertEqual(Failure, mock_handle_error.call_args[0][2].__class__)
        # Tidy up.
        patcher.stop()

    def test_handle_error(self):
        """
        Ensures the _handle_error function works as expected and cleans things
        up / continues the lookup.

        If a node doesn't reply or an error is encountered it is removed from
        self.shortlist and self.pending_requests. Start the _lookup again.
        """
        def side_effect(*args):
            """
            Ensures the mock returns something useful.
            """
            uuid = str(uuid4())
            deferred = defer.Deferred()
            return (uuid, deferred)

        self.node.send_find = MagicMock(side_effect=side_effect)
        lookup = NodeLookup(self.key, FindNode, self.node)
        # Ensure there is a good start condition.
        self.assertEqual(ALPHA, len(lookup.pending_requests))
        shortlist_length = len(lookup.shortlist)

        lookup._lookup = MagicMock()
        deferred = lookup.pending_requests[lookup.pending_requests.keys()[0]]
        deferred.errback(Exception())
        self.assertEqual(ALPHA - 1, len(lookup.pending_requests))
        self.assertEqual(shortlist_length - 1, len(lookup.shortlist))
        self.assertEqual(1, lookup._lookup.call_count)

    def test_handle_error_not_in_shortlist(self):
        """
        Ensures that there is no error thrown if the request that caused the
        error is not in the shortlist any more. This should never happen but
        the test is included to check the guard.
        """
        def side_effect(*args):
            """
            Ensures the mock returns something useful.
            """
            uuid = str(uuid4())
            deferred = defer.Deferred()
            return (uuid, deferred)

        self.node.send_find = MagicMock(side_effect=side_effect)
        lookup = NodeLookup(self.key, FindNode, self.node)
        # Ensure there is a good start condition.
        self.assertEqual(ALPHA, len(lookup.pending_requests))

        lookup._lookup = MagicMock()
        deferred = lookup.pending_requests[lookup.pending_requests.keys()[0]]
        # Remove all the contacts from the shortlist
        lookup.shortlist = []
        deferred.errback(Exception())
        # No error! Pending requests has been processed correctly and there is
        # no change to the shortlist. Since only one deferred was fired then
        # _lookup should only have been called once.
        self.assertEqual(ALPHA - 1, len(lookup.pending_requests))
        self.assertEqual(0, len(lookup.shortlist))
        self.assertEqual(1, lookup._lookup.call_count)

    def test_handle_error_not_in_pending_requests(self):
        """
        Ensures that there is no error thrown if the request that caused the
        error is not in the pending_requests dict any more. This should never
        happen but the test is included to check the guard.
        """
        def side_effect(*args):
            """
            Ensures the mock returns something useful.
            """
            uuid = str(uuid4())
            deferred = defer.Deferred()
            return (uuid, deferred)

        self.node.send_find = MagicMock(side_effect=side_effect)
        lookup = NodeLookup(self.key, FindNode, self.node)
        # Ensure there is a good start condition.
        self.assertEqual(ALPHA, len(lookup.pending_requests))
        shortlist_length = len(lookup.shortlist)

        lookup._lookup = MagicMock()
        deferred = lookup.pending_requests[lookup.pending_requests.keys()[0]]
        # Remove all the contacts from the pending_requests
        lookup.pending_requests = {}
        deferred.errback(Exception())
        # No error!
        self.assertEqual(0, len(lookup.pending_requests))
        self.assertEqual(shortlist_length - 1, len(lookup.shortlist))
        self.assertEqual(1, lookup._lookup.call_count)

    def test_blacklist(self):
        """
        Make sure that the NodeLookup's blacklist method works as expected: the
        misbehaving peer is removed from the shortlist and added to the routing
        table's "global" blacklist.
        """
        def side_effect(*args):
            """
            Ensures the mock returns something useful.
            """
            uuid = str(uuid4())
            deferred = defer.Deferred()
            return (uuid, deferred)

        self.node.send_find = MagicMock(side_effect=side_effect)
        lookup = NodeLookup(self.key, FindNode, self.node)

        problem_contact = lookup.shortlist[0]
        self.node._routing_table.blacklist = MagicMock()
        lookup._blacklist(problem_contact)
        self.assertNotIn(problem_contact, lookup.shortlist)
        self.assertEqual(1, self.node._routing_table.blacklist.call_count)

    def test_handle_response_wrong_message_type(self):
        """
        Ensure that something that's not a Find[Node|Value] message results in
        the responding contact being blacklisted and an exception being thrown.
        """
        def side_effect(*args):
            """
            Ensures the mock returns something useful.
            """
            uuid = str(uuid4())
            deferred = defer.Deferred()
            return (uuid, deferred)

        self.node.send_find = MagicMock(side_effect=side_effect)
        lookup = NodeLookup(self.key, FindNode, self.node)

        uuid = lookup.pending_requests.keys()[0]
        contact = Contact(self.node.id, '192.168.1.1', 54321, self.version)
        version = get_version()
        msg = Ping(uuid, self.node_id, version)

        lookup._blacklist = MagicMock()
        ex = self.assertRaises(TypeError, lookup._handle_response, uuid,
                               contact, msg)
        self.assertEqual('Unexpected response type from %r' % contact,
                         ex.message)
        lookup._blacklist.assert_called_once_with(contact)

    def test_handle_response_wrong_value_for_findnode_message(self):
        """
        Ensures that if a Value response is returned for a FindNode request
        then the misbehaving peer is blacklisted and an exception is thrown.
        """
        def side_effect(*args):
            """
            Ensures the mock returns something useful.
            """
            uuid = str(uuid4())
            deferred = defer.Deferred()
            return (uuid, deferred)

        self.node.send_find = MagicMock(side_effect=side_effect)
        lookup = NodeLookup(self.key, FindNode, self.node)

        uuid = lookup.pending_requests.keys()[0]
        contact = Contact(self.node.id, '192.168.1.1', 54321, self.version)
        msg = Value(uuid, self.node.id, self.key, self.value, self.timestamp,
                    self.expires, self.version, PUBLIC_KEY, self.name,
                    self.meta, self.signature, self.node.version)
        lookup._blacklist = MagicMock()
        ex = self.assertRaises(TypeError, lookup._handle_response, uuid,
                               contact, msg)
        self.assertEqual('Unexpected response type from %r' % contact,
                         ex.message)
        lookup._blacklist.assert_called_once_with(contact)

    def test_handle_response_request_removed_from_pending_requests(self):
        """
        Ensure the pending request that triggered the response being handled by
        the callback is removed from the pending_requests.
        """
        def side_effect(*args):
            """
            Ensures the mock returns something useful.
            """
            uuid = str(uuid4())
            deferred = defer.Deferred()
            return (uuid, deferred)

        self.node.send_find = MagicMock(side_effect=side_effect)
        lookup = NodeLookup(self.key, FindValue, self.node)

        uuid = lookup.pending_requests.keys()[0]
        contact = Contact(self.node.id, '192.168.1.1', 54321, self.version)
        msg = Value(uuid, self.node.id, self.key, self.value, self.timestamp,
                    self.expires, self.version, PUBLIC_KEY, self.name,
                    self.meta, self.signature, self.node.version)
        lookup._handle_response(uuid, contact, msg)
        self.assertNotIn(uuid, lookup.pending_requests.keys())

    def test_handle_response_value_results_in_node_lookup_callback(self):
        """
        Ensures that if a valid Value message is being handled then all other
        pending requests are cancelled and the NodeLookup object calls back
        with the passed in Value object.
        """
        def side_effect(*args):
            """
            Ensures the mock returns something useful.
            """
            uuid = str(uuid4())
            deferred = defer.Deferred()
            return (uuid, deferred)

        self.node.send_find = MagicMock(side_effect=side_effect)
        lookup = NodeLookup(self.key, FindValue, self.node)

        uuid = lookup.pending_requests.keys()[0]
        other_request1 = lookup.pending_requests.values()[1]
        other_request2 = lookup.pending_requests.values()[2]
        other_request1.cancel = MagicMock()
        other_request2.cancel = MagicMock()
        contact = Contact(long_to_hex(1), '192.168.0.1', 9999, self.version)
        msg = Value(uuid, self.node.id, self.key, self.value, self.timestamp,
                    self.expires, self.version, PUBLIC_KEY, self.name,
                    self.meta, self.signature, self.node.version)
        lookup._handle_response(uuid, contact, msg)
        # Ensure the lookup has fired.
        self.assertTrue(lookup.called)
        # Check the pending requests have been cancelled.
        self.assertEqual(1, other_request1.cancel.call_count)
        self.assertEqual(1, other_request2.cancel.call_count)
        # Make sure the pending_requests dict is empty.
        self.assertEqual(0, len(lookup.pending_requests))
        # Ensure the contact that provided the result is NOT in the shortlist.
        self.assertNotIn(contact, lookup.shortlist)

        # Ensure the result of the callback is the returned Value object.
        def callback(result):
            self.assertEqual(msg, result)
        lookup.addCallback(callback)

    def test_handle_response_value_message_wrong_key(self):
        """
        Ensures that if we get a valid Value response but the key doesn't match
        the one being requested then the misbehaving node is blacklisted and
        an exception is thrown.
        """
        def side_effect(*args):
            """
            Ensures the mock returns something useful.
            """
            uuid = str(uuid4())
            deferred = defer.Deferred()
            return (uuid, deferred)

        self.node.send_find = MagicMock(side_effect=side_effect)
        lookup = NodeLookup(self.key, FindValue, self.node)

        uuid = lookup.pending_requests.keys()[0]
        contact = Contact(self.node.id, '192.168.1.1', 54321, self.version)
        key = construct_key(PUBLIC_KEY, 'foo')
        signature = generate_signature(self.value, self.timestamp,
                                       self.expires, 'foo', self.meta,
                                       self.version, PRIVATE_KEY)
        msg = Value(uuid, self.node.id, key, self.value, self.timestamp,
                    self.expires, self.version, PUBLIC_KEY, self.name,
                    self.meta, signature, self.node.version)
        lookup._blacklist = MagicMock()
        ex = self.assertRaises(ValueError, lookup._handle_response, uuid,
                               contact, msg)
        self.assertEqual('Value with wrong key returned by %r' % contact,
                         ex.message)
        lookup._blacklist.assert_called_once_with(contact)

    def test_handle_response_value_message_expired(self):
        """
        Ensures the NodeLookup errbacks given an expired value response.
        """
        def side_effect(*args):
            """
            Ensures the mock returns something useful.
            """
            uuid = str(uuid4())
            deferred = defer.Deferred()
            return (uuid, deferred)

        self.node.send_find = MagicMock(side_effect=side_effect)
        lookup = NodeLookup(self.key, FindValue, self.node)

        uuid = lookup.pending_requests.keys()[0]
        contact = Contact(self.node.id, '192.168.1.1', 54321, self.version)
        timestamp = time.time() - 1000
        expires = timestamp + 10
        signature = generate_signature(self.value, self.timestamp,
                                       self.expires, 'foo', self.meta,
                                       self.version, PRIVATE_KEY)
        msg = Value(uuid, self.node.id, self.key, self.value, timestamp,
                    expires, self.version, PUBLIC_KEY, self.name, self.meta,
                    signature, self.node.version)
        ex = self.assertRaises(ValueError, lookup._handle_response, uuid,
                               contact, msg)
        self.assertEqual('Expired value returned by %r' % contact,
                         ex.message)

    @patch('drogulus.dht.node.sort_contacts')
    def test_handle_response_nodes_message_adds_to_shortlist(self, mock_sort):
        """
        Ensures that a Nodes message adds the returned nodes to the shortlist
        in the correct order (closest to target at the head of the list).
        """
        def sort_side_effect(*args):
            """
            Ensures the sort algorithm returns some arbitrary value.
            """
            return [1, 2, 3]

        mock_sort.side_effect = sort_side_effect

        def send_find_side_effect(*args):
            """
            Ensures the mock send_find returns something useful.
            """
            uuid = str(uuid4())
            deferred = defer.Deferred()
            return (uuid, deferred)

        self.node.send_find = MagicMock(side_effect=send_find_side_effect)
        target_key = long_to_hex(999)
        lookup = NodeLookup(target_key, FindNode, self.node)
        shortlist = lookup.shortlist

        uuid = lookup.pending_requests.keys()[0]
        contact = Contact(self.node.id, '192.168.1.1', 54321, self.version)
        msg = Nodes(self.uuid, self.node.id, self.nodes, self.node.version)
        lookup._handle_response(uuid, contact, msg)
        mock_sort.assert_called_once_with(list(self.nodes) + shortlist,
                                          target_key)
        self.assertEqual([1, 2, 3], lookup.shortlist)

    def test_handle_response_nodes_no_duplicates_in_shortlist(self):
        """
        Ensures that if the response contains nodes that are already found in
        the shortlist they are not duplicated.
        """
        def send_find_side_effect(*args):
            """
            Ensures the mock send_find returns something useful.
            """
            uuid = str(uuid4())
            deferred = defer.Deferred()
            return (uuid, deferred)

        self.node.send_find = MagicMock(side_effect=send_find_side_effect)
        target_key = long_to_hex(999)
        lookup = NodeLookup(target_key, FindNode, self.node)
        shortlist = lookup.shortlist

        uuid = lookup.pending_requests.keys()[0]
        contact = Contact(self.node.id, '192.168.1.1', 54321, self.version)
        # Respond with all the current nodes in the shortlist.
        msg = Nodes(self.uuid, self.node.id, shortlist, self.node.version)
        lookup._handle_response(uuid, contact, msg)
        # There shouldn't be any duplicate entries.
        self.assertEqual(shortlist, lookup.shortlist)

    def test_handle_response_nodes_message_update_nearest_node(self):
        """
        Ensure that if the response contains contacts/nodes that are nearer to
        the target than the current nearest known node nearest_node is updated
        to reflect this change of state.
        """
        def side_effect(*args):
            """
            Ensures the mock send_find returns something useful.
            """
            uuid = str(uuid4())
            deferred = defer.Deferred()
            return (uuid, deferred)

        self.node.send_find = MagicMock(side_effect=side_effect)
        target_key = long_to_hex(999)
        lookup = NodeLookup(target_key, FindNode, self.node)
        old_nearest_node = lookup.nearest_node

        lookup._lookup = MagicMock()
        uuid = lookup.pending_requests.keys()[0]
        contact = Contact(self.node.id, '192.168.1.1', 54321, self.version)
        msg = Nodes(self.uuid, self.node.id, self.nodes, self.node.version)
        lookup._handle_response(uuid, contact, msg)
        # Check the nearest_node has been updated to the correct value and that
        # the lookup has been restarted.
        self.assertNotEqual(old_nearest_node, lookup.nearest_node)
        self.assertEqual(lookup.nearest_node, lookup.shortlist[0])
        self.assertEqual(1, lookup._lookup.call_count)

    def test_handle_response_nodes_message_do_not_update_nearest_node(self):
        """
        If the response contains contacts/nodes that are NOT closer to the
        target than the current nearest known node then nearest_node is NOT
        updated and a new lookup is NOT triggered.
        """
        def side_effect(*args):
            """
            Ensures the mock send_find returns something useful.
            """
            uuid = str(uuid4())
            deferred = defer.Deferred()
            return (uuid, deferred)

        self.node.send_find = MagicMock(side_effect=side_effect)
        target_key = long_to_hex(0)
        lookup = NodeLookup(target_key, FindNode, self.node)
        old_nearest_node = lookup.nearest_node

        lookup._lookup = MagicMock()
        uuid = lookup.pending_requests.keys()[0]
        contact = Contact(self.node.id, '192.168.1.1', 54321, self.version)
        msg = Nodes(self.uuid, self.node.id, self.nodes, self.node.version)
        lookup._handle_response(uuid, contact, msg)
        # Check the nearest_node has NOT been updated nor has the lookup been
        # restarted.
        self.assertEqual(old_nearest_node, lookup.nearest_node)
        self.assertEqual(lookup.nearest_node, lookup.shortlist[0])
        self.assertEqual(0, lookup._lookup.call_count)

    def test_handle_response_still_nodes_uncontacted_in_shortlist(self):
        """
        Ensure that if there are no more pending requests but there are still
        uncontacted nodes in the shortlist then restart the lookup.
        """
        def side_effect(*args):
            """
            Ensures the mock send_find returns something useful.
            """
            uuid = str(uuid4())
            deferred = defer.Deferred()
            return (uuid, deferred)

        self.node.send_find = MagicMock(side_effect=side_effect)
        target_key = long_to_hex(0)
        lookup = NodeLookup(target_key, FindNode, self.node)

        # Only one item in pending_requests.
        pending_keys = lookup.pending_requests.keys()
        for i in range(1, len(lookup.pending_requests)):
            del lookup.pending_requests[pending_keys[i]]
        self.assertEqual(1, len(lookup.pending_requests))
        # Add K-1 items from shortlist to the contacted set.
        for i in range(K - 1):
            lookup.contacted.add(lookup.shortlist[i])
        # Ensure lookup is called with the 20th (uncontacted) contact.
        not_contacted = lookup.shortlist[K - 1]
        self.assertNotIn(not_contacted, lookup.contacted)
        lookup._lookup = MagicMock()
        uuid = lookup.pending_requests.keys()[0]
        contact = Contact(self.node.id, '192.168.1.1', 54321, self.version)
        msg = Nodes(self.uuid, self.node.id, self.nodes, self.node.version)
        lookup._handle_response(uuid, contact, msg)
        # Lookup is called once.
        self.assertEqual(1, lookup._lookup.call_count)
        # Lookup results in the expected call with the un-contacted node.
        self.node.send_find.called_once_with(not_contacted, target_key,
                                             FindNode)

    def test_handle_response_all_shortlist_contacted_return_nodes(self):
        """
        Ensure that if there are no more pending requests and all the nodes in
        the shortlist have been contacted then return the shortlist of nearest
        nodes to the target key if the lookup is a FindNode.
        """
        def side_effect(*args):
            """
            Ensures the mock send_find returns something useful.
            """
            uuid = str(uuid4())
            deferred = defer.Deferred()
            return (uuid, deferred)

        self.node.send_find = MagicMock(side_effect=side_effect)
        target_key = long_to_hex(0)
        lookup = NodeLookup(target_key, FindNode, self.node)

        # Only one item in pending_requests.
        pending_keys = lookup.pending_requests.keys()
        for i in range(1, len(lookup.pending_requests)):
            del lookup.pending_requests[pending_keys[i]]
        self.assertEqual(1, len(lookup.pending_requests))
        # Add all items from shortlist to the contacted set.
        for contact in lookup.shortlist:
            lookup.contacted.add(contact)
        # Cause the callback to fire.
        lookup._lookup = MagicMock()
        uuid = lookup.pending_requests.keys()[0]
        contact = Contact(self.node.id, '192.168.1.1', 54321, self.version)
        msg = Nodes(self.uuid, self.node.id, self.nodes, self.node.version)
        lookup._handle_response(uuid, contact, msg)
        # Lookup is not called.
        self.assertEqual(0, lookup._lookup.call_count)
        # The lookup has fired.
        self.assertTrue(lookup.called)

        # The result is the ordered shortlist of contacts closest to the
        # target.
        def handle_callback(result):
            """
            Checks the result is the expected list of contacts.
            """
            # It's a list.
            self.assertIsInstance(result, list)
            # It's the lookup's shortlist.
            self.assertEqual(result, lookup.shortlist)
            # It's in order.
            ordered = sort_contacts(lookup.shortlist, target_key)
            self.assertEqual(ordered, result)

        lookup.addCallback(handle_callback)

    def test_handle_response_all_shortlist_contacted_no_value_found(self):
        """
        Ensure that if there are no more pending requests and all the nodes in
        the shortlist have been contacted yet the target key has not yet been
        found (because it's a FindValue query) then errback with a
        ValueNotFound exception.
        """
        def side_effect(*args):
            """
            Ensures the mock send_find returns something useful.
            """
            uuid = str(uuid4())
            deferred = defer.Deferred()
            return (uuid, deferred)

        self.node.send_find = MagicMock(side_effect=side_effect)
        target_key = long_to_hex(0)
        lookup = NodeLookup(target_key, FindValue, self.node)

        # Only one item in pending_requests.
        pending_keys = lookup.pending_requests.keys()
        for i in range(1, len(lookup.pending_requests)):
            del lookup.pending_requests[pending_keys[i]]
        self.assertEqual(1, len(lookup.pending_requests))
        # Add all items from shortlist to the contacted set.
        for contact in lookup.shortlist:
            lookup.contacted.add(contact)
        # Cause the callback to fire.
        lookup._lookup = MagicMock()
        uuid = lookup.pending_requests.keys()[0]
        contact = Contact(self.node.id, '192.168.1.1', 54321, self.version)
        msg = Nodes(self.uuid, self.node.id, self.nodes, self.node.version)
        lookup._handle_response(uuid, contact, msg)
        # Lookup is not called.
        self.assertEqual(0, lookup._lookup.call_count)
        # The lookup has fired.
        self.assertTrue(lookup.called)

        # The error is a ValueNotFound exception.
        def handle_errback(error):
            """
            Ensures the expected exception is raised.
            """
            self.assertIsInstance(error.value, ValueNotFound)
            self.assertEqual("Unable to find value for key: %r" % target_key,
                             error.getErrorMessage())

        lookup.addErrback(handle_errback)


class TestNode(unittest.TestCase):
    """
    Ensures the Node class works as expected.
    """

    def setUp(self):
        """
        Following the pattern explained here:

        http://twistedmatrix.com/documents/current/core/howto/trial.html
        """
        self.node_id = '1234567890abc'
        self.node = Node(self.node_id)
        self.factory = DHTFactory(self.node)
        self.protocol = self.factory.buildProtocol(('127.0.0.1', 0))
        self.transport = proto_helpers.StringTransport()
        self.transport.abortConnection = fakeAbortConnection
        self.protocol.makeConnection(self.transport)
        self.clock = task.Clock()
        reactor.callLater = self.clock.callLater
        self.value = 'value'
        self.uuid = str(uuid4())
        self.timestamp = 1350544046.084875
        self.expires = 1352221970.14242
        self.name = 'name'
        self.meta = {'meta': 'value'}
        self.version = get_version()
        self.key = construct_key(PUBLIC_KEY, self.name)
        self.target_key = long_to_hex(100)
        self.signature = generate_signature(self.value, self.timestamp,
                                            self.expires, self.name,
                                            self.meta, self.version,
                                            PRIVATE_KEY)
        node_list = []
        for i in range(101, 121):
            contact_id = long_to_hex(i)
            contact_address = '192.168.1.%d' % i
            contact_port = 9999
            contact_version = self.version
            contact_last_seen = self.timestamp - (i * 100)
            contact = Contact(contact_id, contact_address, contact_port,
                              contact_version, contact_last_seen)
            node_list.append(contact)
        self.nodes = tuple(sort_contacts(node_list, self.target_key))

    def test_init(self):
        """
        Ensures the class is instantiated correctly.
        """
        node = Node(123)
        self.assertEqual(123, node.id)
        self.assertTrue(node._routing_table)
        self.assertEqual({}, node._data_store)
        self.assertEqual({}, node._pending)
        self.assertEqual('ssl:%s:%d', node._client_string)
        self.assertEqual(get_version(), node.version)

    def test_refresh_k_buckets(self):
        """
        Ensure that k-buckets are refreshed after the expected period of time.
        """
        assert False

    def test_refresh_k_buckets_scheduled(self):
        """
        Ensure that the action to refresh k-buckets is scheduled correctly.
        """
        assert False

    def test_join_returns_node_lookup_deferred(self):
        """
        Ensures the Node's join method returns a deferred that is fired when
        the Node has joined the DHT.
        """
        assert False

    def test_join_no_seed_nodes(self):
        """
        Ensures the Node's join method complains when no seed nodes are
        provided.
        """
        ex = self.assertRaises(ValueError, self.node.join, [])
        self.assertEqual('Seed nodes required for node to join network',
                         ex.message)

    def test_join_adds_seed_nodes_to_routing_table(self):
        """
        Ensures that the join method populates the node's routing table with
        the seed nodes.
        """
        # Check the node's routing table is empty (a single k-bucket containing
        # zero contacts).
        assert False
        self.assertEqual(1, self.node._routing_table._buckets)
        self.assertEqual(0, self.node._routing_table._buckets[0])

        # Ensure the add_contact method has been called on the routing table
        # in the expected way.
        self.node.join(self.nodes)

    def test_join_not_able_to_join(self):
        """
        Ensure that the deferred returned from the join method fires an
        errback if the Node was unable to join the DHT given the set of valid
        seed nodes.
        """
        assert False

    def test_message_received_calls_routing_table(self):
        """
        Ensures an inbound message updates the routing table.
        """
        self.node._routing_table.add_contact = MagicMock()
        # Create a simple Ping message.
        uuid = str(uuid4())
        version = get_version()
        msg = Ping(uuid, self.node_id, version)
        # Receive it...
        self.node.message_received(msg, self.protocol)
        # Check it results in a call to the routing table's add_contact method.
        peer = self.protocol.transport.getPeer()
        self.assertEqual(1, self.node._routing_table.add_contact.call_count)
        arg1 = self.node._routing_table.add_contact.call_args[0][0]
        self.assertTrue(isinstance(arg1, Contact))
        self.assertEqual(msg.node, arg1.id)
        self.assertEqual(peer.host, arg1.address)
        self.assertEqual(peer.port, arg1.port)
        self.assertEqual(msg.version, arg1.version)
        self.assertTrue(isinstance(arg1.last_seen, float))

    def test_message_received_ping(self):
        """
        Ensures a Ping message is handled correctly.
        """
        self.node.handle_ping = MagicMock()
        # Create a simple Ping message.
        uuid = str(uuid4())
        version = get_version()
        msg = Ping(uuid, self.node_id, version)
        # Receive it...
        self.node.message_received(msg, self.protocol)
        # Check it results in a call to the node's handle_ping method.
        self.node.handle_ping.assert_called_once_with(msg, self.protocol)

    def test_message_received_pong(self):
        """
        Ensures a Pong message is handled correctly.
        """
        self.node.handle_pong = MagicMock()
        # Create a simple Pong message.
        uuid = str(uuid4())
        version = get_version()
        msg = Pong(uuid, self.node_id, version)
        # Receive it...
        self.node.message_received(msg, self.protocol)
        # Check it results in a call to the node's handle_pong method.
        self.node.handle_pong.assert_called_once_with(msg)

    def test_message_received_store(self):
        """
        Ensures a Store message is handled correctly.
        """
        self.node.handle_store = MagicMock()
        # Create a simple Store message.
        msg = Store(self.uuid, self.node.id, self.key, self.value,
                    self.timestamp, self.expires, self.version, PUBLIC_KEY,
                    self.name, self.meta, self.signature, self.version)
        # Receive it...
        self.node.message_received(msg, self.protocol)
        # Dummy contact.
        contact = Contact(self.node.id, '192.168.1.1', 54321, self.version)
        # Check it results in a call to the node's handle_store method.
        self.node.handle_store.assert_called_once_with(msg, self.protocol,
                                                       contact)

    def test_message_received_find_node(self):
        """
        Ensures a FindNode message is handled correctly.
        """
        self.node.handle_find_node = MagicMock()
        # Create a simple Ping message.
        uuid = str(uuid4())
        version = get_version()
        key = '12345abc'
        msg = FindNode(uuid, self.node_id, key, version)
        # Receive it...
        self.node.message_received(msg, self.protocol)
        # Check it results in a call to the node's handle_find_node method.
        self.node.handle_find_node.assert_called_once_with(msg, self.protocol)

    def test_message_received_find_value(self):
        """
        Ensures a FindValue message is handled correctly.
        """
        self.node.handle_find_value = MagicMock()
        # Create a simple Ping message.
        uuid = str(uuid4())
        version = get_version()
        key = '12345abc'
        msg = FindValue(uuid, self.node_id, key, version)
        # Receive it...
        self.node.message_received(msg, self.protocol)
        # Check it results in a call to the node's handle_find_value method.
        self.node.handle_find_value.assert_called_once_with(msg, self.protocol)

    def test_message_received_error(self):
        """
        Ensures an Error message is handled correctly.
        """
        self.node.handle_error = MagicMock()
        # Create an Error message.
        uuid = str(uuid4())
        version = get_version()
        code = 1
        title = ERRORS[code]
        details = {'foo': 'bar'}
        msg = Error(uuid, self.node_id, code, title, details, version)
        # Receive it...
        self.node.message_received(msg, self.protocol)
        # Dummy contact.
        contact = Contact(self.node.id, '192.168.1.1', 54321, self.version)
        # Check it results in a call to the node's handle_error method.
        self.node.handle_error.assert_called_once_with(msg, self.protocol,
                                                       contact)

    def test_message_received_value(self):
        """
        Ensures a Value message is handled correctly.
        """
        self.node.handle_value = MagicMock()
        # Create a Value message.
        uuid = str(uuid4())
        msg = Value(uuid, self.node.id, self.key, self.value, self.timestamp,
                    self.expires, self.version, PUBLIC_KEY, self.name,
                    self.meta, self.signature, self.node.version)
        # Receive it...
        self.node.message_received(msg, self.protocol)
        # Dummy contact.
        contact = Contact(self.node.id, '192.168.1.1', 54321, self.version)
        # Check it results in a call to the node's handle_value method.
        self.node.handle_value.assert_called_once_with(msg, contact)

    def test_message_received_nodes(self):
        """
        Ensures a Nodes message is handled correctly.
        """
        self.node.handle_nodes = MagicMock()
        # Create a nodes message.
        msg = Nodes(self.uuid, self.node.id,
                    ((self.node.id, '127.0.0.1', 1908, '0.1')),
                    self.node.version)
        # Receive it...
        self.node.message_received(msg, self.protocol)
        # Check it results in a call to the node's handle_nodes method.
        self.node.handle_nodes.assert_called_once_with(msg)

    def test_handle_ping(self):
        """
        Ensures the handle_ping method returns a Pong message.
        """
        # Mock
        self.protocol.sendMessage = MagicMock()
        # Create a simple Ping message.
        uuid = str(uuid4())
        version = get_version()
        msg = Ping(uuid, self.node_id, version)
        # Handle it.
        self.node.handle_ping(msg, self.protocol)
        # Check the result.
        result = Pong(uuid, self.node.id, version)
        self.protocol.sendMessage.assert_called_once_with(result, True)

    def test_handle_ping_loses_connection(self):
        """
        Ensures the handle_ping method loses the connection after sending the
        Pong.
        """
        # Mock
        self.protocol.transport.loseConnection = MagicMock()
        # Create a simple Ping message.
        uuid = str(uuid4())
        version = get_version()
        msg = Ping(uuid, self.node_id, version)
        # Handle it.
        self.node.handle_ping(msg, self.protocol)
        # Ensure the loseConnection method was also called.
        self.protocol.transport.loseConnection.assert_called_once_with()

    @patch('drogulus.dht.node.validate_message')
    def test_handle_store_checks_with_validate_message(self, mock_validator):
        """
        Ensure that the validate_message function is called as part of
        handle_store.
        """
        # Mock
        mock_validator.return_value = (1, 2)
        self.protocol.sendMessage = MagicMock()
        # Create a fake contact and valid message.
        msg = Store(self.uuid, self.node.id, self.key, self.value,
                    self.timestamp, self.expires, self.version, PUBLIC_KEY,
                    self.name, self.meta, self.signature, self.version)
        other_node = Contact(self.node.id, '127.0.0.1', 1908,
                             self.version, time.time())
        self.node.handle_store(msg, self.protocol, other_node)
        mock_validator.assert_called_once_with(msg)

    @patch('drogulus.dht.node.reactor.callLater')
    def test_handle_store(self, mock_call_later):
        """
        Ensures a valid Store message is handled correctly.
        """
        # Mock
        self.protocol.sendMessage = MagicMock()
        # Incoming message and peer
        msg = Store(self.uuid, self.node.id, self.key, self.value,
                    self.timestamp, self.expires, self.version, PUBLIC_KEY,
                    self.name, self.meta, self.signature, self.version)
        other_node = Contact(self.node.id, '127.0.0.1', 1908,
                             self.version, time.time())
        self.node.handle_store(msg, self.protocol, other_node)
        # Ensure the message is in local storage.
        self.assertIn(self.key, self.node._data_store)
        # Ensure call_later has been called to republish the value.
        mock_call_later.assert_called_once_with(REPLICATE_INTERVAL,
                                                self.node.republish,
                                                msg)
        # Ensure the response is a Pong message.
        result = Pong(self.uuid, self.node.id, self.version)
        self.protocol.sendMessage.assert_called_once_with(result, True)

    def test_handle_store_old_value(self):
        """
        Ensures that a Store message containing an out-of-date version of a
        value already known to the node is handled correctly:

        * The current up-to-date value is not overwritten.
        * The node responds with an appropriate error message.
        """
        # Create existing up-to-date value
        newer_msg = Store(self.uuid, self.node.id, self.key, self.value,
                          self.timestamp, self.expires, self.version,
                          PUBLIC_KEY, self.name, self.meta, self.signature,
                          self.version)
        self.node._data_store.set_item(newer_msg.key, newer_msg)
        # Incoming message and peer
        old_timestamp = self.timestamp - 9999
        old_value = 'old value'
        old_sig = generate_signature(old_value, old_timestamp, self.expires,
                                     self.name, self.meta, self.version,
                                     PRIVATE_KEY)
        old_msg = Store(self.uuid, self.node.id, self.key, old_value,
                        old_timestamp, self.expires, self.version, PUBLIC_KEY,
                        self.name, self.meta, old_sig, self.version)
        other_node = Contact(self.node.id, '127.0.0.1', 1908,
                             self.version, time.time())
        # Check for the expected exception.
        ex = self.assertRaises(ValueError, self.node.handle_store, old_msg,
                               self.protocol, other_node)
        details = {
            'new_timestamp': '%d' % self.timestamp
        }
        self.assertEqual(ex.args[0], 8)
        self.assertEqual(ex.args[1], ERRORS[8])
        self.assertEqual(ex.args[2], details)
        self.assertEqual(ex.args[3], self.uuid)
        # Ensure the original message is in local storage.
        self.assertIn(self.key, self.node._data_store)
        self.assertEqual(newer_msg, self.node._data_store[self.key])

    def test_handle_store_new_value(self):
        """
        Ensures that a Store message containing a new version of a
        value already known to the node is handled correctly.
        """
        # Mock
        self.protocol.sendMessage = MagicMock()
        # Create existing up-to-date value
        old_timestamp = self.timestamp - 9999
        old_value = 'old value'
        old_sig = generate_signature(old_value, old_timestamp, self.expires,
                                     self.name, self.meta, self.version,
                                     PRIVATE_KEY)
        old_msg = Store(self.uuid, self.node.id, self.key, old_value,
                        old_timestamp, self.expires, self.version, PUBLIC_KEY,
                        self.name, self.meta, old_sig, self.version)
        self.node._data_store.set_item(old_msg.key, old_msg)
        self.assertIn(self.key, self.node._data_store)
        self.assertEqual(old_msg, self.node._data_store[self.key])
        # Incoming message and peer
        new_msg = Store(self.uuid, self.node.id, self.key, self.value,
                        self.timestamp, self.expires, self.version,
                        PUBLIC_KEY, self.name, self.meta, self.signature,
                        self.version)
        other_node = Contact(self.node.id, '127.0.0.1', 1908,
                             self.version, time.time())
        # Store the new version of the message.
        self.node.handle_store(new_msg, self.protocol, other_node)
        # Ensure the message is in local storage.
        self.assertIn(self.key, self.node._data_store)
        self.assertEqual(new_msg, self.node._data_store[self.key])
        # Ensure the response is a Pong message.
        result = Pong(self.uuid, self.node.id, self.version)
        self.protocol.sendMessage.assert_called_once_with(result, True)

    def test_handle_store_bad_message(self):
        """
        Ensures an invalid Store message is handled correctly.
        """
        # Incoming message and peer
        msg = Store(self.uuid, self.node.id, self.key, 'wrong value',
                    self.timestamp, self.expires, self.version, PUBLIC_KEY,
                    self.name, self.meta, self.signature, self.version)
        other_node = Contact('12345678abc', '127.0.0.1', 1908,
                             self.version, time.time())
        self.node._routing_table.add_contact(other_node)
        # Sanity check for expected routing table start state.
        self.assertEqual(1, len(self.node._routing_table._buckets[0]))
        # Handle faulty message.
        ex = self.assertRaises(ValueError, self.node.handle_store, msg,
                               self.protocol, other_node)
        # Check the exception
        self.assertEqual(ex.args[0], 6)
        self.assertEqual(ex.args[1], ERRORS[6])
        details = {
            'message': 'You have been blacklisted.'
        }
        self.assertEqual(ex.args[2], details)
        self.assertEqual(ex.args[3], self.uuid)
        # Ensure the message is not in local storage.
        self.assertNotIn(self.key, self.node._data_store)
        # Ensure the contact is not in the routing table
        self.assertEqual(0, len(self.node._routing_table._buckets[0]))
        # Ensure the contact is not in the replacement cache
        self.assertEqual(0, len(self.node._routing_table._replacement_cache))

    def test_handle_store_loses_connection(self):
        """
        Ensures the handle_store method with a good Store message loses the
        connection after sending the Pong message.
        """
        # Mock
        self.protocol.transport.loseConnection = MagicMock()
        # Incoming message and peer
        msg = Store(self.uuid, self.node.id, self.key, self.value,
                    self.timestamp, self.expires, self.version, PUBLIC_KEY,
                    self.name, self.meta, self.signature, self.version)
        other_node = Contact(self.node.id, '127.0.0.1', 1908,
                             self.version, time.time())
        self.node.handle_store(msg, self.protocol, other_node)
        # Ensure the loseConnection method was also called.
        self.protocol.transport.loseConnection.assert_called_once_with()

    def test_handle_find_nodes(self):
        """
        Ensure a valid FindNodes message is handled correctly.
        """
        # Mock
        self.protocol.sendMessage = MagicMock()
        # Populate the routing table with contacts.
        for i in range(512):
            contact = Contact(2 ** i, "192.168.0.%d" % i, 9999, self.version,
                              0)
            self.node._routing_table.add_contact(contact)
        # Incoming FindNode message
        msg = FindNode(self.uuid, self.node.id, self.key, self.version)
        self.node.handle_find_node(msg, self.protocol)
        # Check the response sent back
        other_nodes = [(n.id, n.address, n.port, n.version) for n in
                       self.node._routing_table.find_close_nodes(self.key)]
        result = Nodes(msg.uuid, self.node.id, other_nodes, self.version)
        self.protocol.sendMessage.assert_called_once_with(result, True)

    def test_handle_find_nodes_loses_connection(self):
        """
        Ensures the handle_find_nodes method loses the connection after
        sending the Nodes message.
        """
        # Mock
        self.protocol.transport.loseConnection = MagicMock()
        # Populate the routing table with contacts.
        for i in range(512):
            contact = Contact(2 ** i, "192.168.0.%d" % i, 9999, self.version,
                              0)
            self.node._routing_table.add_contact(contact)
        # Incoming FindNode message
        msg = FindNode(self.uuid, self.node.id, self.key, self.version)
        self.node.handle_find_node(msg, self.protocol)
        # Ensure the loseConnection method was also called.
        self.protocol.transport.loseConnection.assert_called_once_with()

    def test_handle_find_value_with_match(self):
        """
        Ensures the handle_find_value method responds with a matching Value
        message if the value exists in the datastore.
        """
        # Store value.
        val = Store(self.uuid, self.node.id, self.key, self.value,
                    self.timestamp, self.expires, self.version, PUBLIC_KEY,
                    self.name, self.meta, self.signature, self.version)
        self.node._data_store.set_item(val.key, val)
        # Mock
        self.protocol.sendMessage = MagicMock()
        # Incoming FindValue message
        msg = FindValue(self.uuid, self.node.id, self.key, self.version)
        self.node.handle_find_value(msg, self.protocol)
        # Check the response sent back
        result = Value(msg.uuid, self.node.id, val.key, val.value,
                       val.timestamp, val.expires, val.created_with,
                       val.public_key, val.name, val.meta, val.sig,
                       val.version)
        self.protocol.sendMessage.assert_called_once_with(result, True)

    def test_handle_find_value_no_match(self):
        """
        Ensures the handle_find_value method calls the handle_find_nodes
        method with the correct values if no matching value exists in the
        local datastore.
        """
        # Mock
        self.node.handle_find_node = MagicMock()
        # Incoming FindValue message
        msg = FindValue(self.uuid, self.node.id, self.key, self.version)
        self.node.handle_find_value(msg, self.protocol)
        # Check the response sent back
        self.node.handle_find_node.assert_called_once_with(msg, self.protocol)

    def test_handle_find_value_loses_connection(self):
        """
        Ensures the handle_find_value method loses the connection after
        sending the a matched value.
        """
        # Store value.
        val = Store(self.uuid, self.node.id, self.key, self.value,
                    self.timestamp, self.expires, self.version, PUBLIC_KEY,
                    self.name, self.meta, self.signature, self.version)
        self.node._data_store.set_item(val.key, val)
        # Mock
        self.protocol.transport.loseConnection = MagicMock()
        # Incoming FindValue message
        msg = FindValue(self.uuid, self.node.id, self.key, self.version)
        self.node.handle_find_value(msg, self.protocol)
        # Ensure the loseConnection method was also called.
        self.protocol.transport.loseConnection.assert_called_once_with()

    def test_handle_error_writes_to_log(self):
        """
        Ensures the handle_error method writes details about the error to the
        log.
        """
        log.msg = MagicMock()
        # Create an Error message.
        uuid = str(uuid4())
        version = get_version()
        code = 1
        title = ERRORS[code]
        details = {'foo': 'bar'}
        msg = Error(uuid, self.node_id, code, title, details, version)
        # Dummy contact.
        contact = Contact(self.node.id, '192.168.1.1', 54321, self.version)
        # Receive it...
        self.node.handle_error(msg, self.protocol, contact)
        # Check it results in two calls to the log.msg method (one to signify
        # an error has happened, the other the actual error message).
        self.assertEqual(2, log.msg.call_count)

    @patch('drogulus.dht.node.validate_message')
    def test_handle_value_checks_with_validate_message(self, mock_validator):
        """
        Ensure that the validate_message function is called as part of
        handle_value.
        """
        mock_validator.return_value = (1, 2)
        # Create a fake contact and valid message.
        other_node = Contact(self.node.id, '127.0.0.1', 1908,
                             self.version, time.time())
        msg = Value(self.uuid, self.node.id, self.key, self.value,
                    self.timestamp, self.expires, self.version, PUBLIC_KEY,
                    self.name, self.meta, self.signature, self.node.version)
        # Handle it.
        self.node.handle_value(msg, other_node)
        mock_validator.assert_called_once_with(msg)

    def test_handle_value_with_valid_message(self):
        """
        Ensure a valid Value is checked and results in the expected call to
        trigger_deferred.
        """
        # Mock
        self.node.trigger_deferred = MagicMock()
        # Create a fake contact and valid message.
        other_node = Contact(self.node.id, '127.0.0.1', 1908,
                             self.version, time.time())
        msg = Value(self.uuid, self.node.id, self.key, self.value,
                    self.timestamp, self.expires, self.version, PUBLIC_KEY,
                    self.name, self.meta, self.signature, self.node.version)
        # Handle it.
        self.node.handle_value(msg, other_node)
        self.node.trigger_deferred.assert_called_once_with(msg)

    def test_handle_value_with_bad_message(self):
        """
        Ensure a bad message results in an error sent to trigger_deferred along
        with expected logging and removal or the other node from the local
        node's routing table.
        """
        # Mocks
        self.node._routing_table.remove_contact = MagicMock()
        self.node.trigger_deferred = MagicMock()
        patcher = patch('drogulus.dht.node.log.msg')
        mockLog = patcher.start()
        # Create a fake contact and valid message.
        other_node = Contact(self.node.id, '127.0.0.1', 1908,
                             self.version, time.time())
        msg = Value(self.uuid, self.node.id, self.key, 'bad_value',
                    self.timestamp, self.expires, self.version, PUBLIC_KEY,
                    self.name, self.meta, self.signature, self.node.version)
        # Handle it.
        self.node.handle_value(msg, other_node)
        # Logger was called twice.
        self.assertEqual(2, mockLog.call_count)
        # other node was removed from the routing table.
        self.node._routing_table.remove_contact.\
            assert_called_once_with(other_node.id, True)
        # trigger_deferred called as expected.
        self.assertEqual(1, self.node.trigger_deferred.call_count)
        self.assertEqual(self.node.trigger_deferred.call_args[0][0], msg)
        self.assertIsInstance(self.node.trigger_deferred.call_args[0][1],
                              ValueError)
        # Tidy up.
        patcher.stop()

    def test_handle_nodes(self):
        """
        Ensure a Nodes message merely results in the expected call to
        trigger_deferred.
        """
        self.node.trigger_deferred = MagicMock()
        msg = Nodes(self.uuid, self.node.id,
                    ((self.node.id, '127.0.0.1', 1908, '0.1')),
                    self.node.version)
        self.node.handle_nodes(msg)
        self.node.trigger_deferred.assert_called_once_with(msg)

    @patch('drogulus.dht.node.clientFromString')
    def test_send_message(self, mock_client):
        """
        Ensure send_message returns a deferred.
        """
        # Mock, mock, glorious mock; nothing quite like it to test a code
        # block. (To the tune of "Mud, mud, glorious mud!")
        mock_client.return_value = FakeClient(self.protocol)
        # Mock the callLater function
        patcher = patch('drogulus.dht.node.reactor.callLater')
        mockCallLater = patcher.start()
        # Create a simple Ping message.
        uuid = str(uuid4())
        version = get_version()
        msg = Ping(uuid, self.node_id, version)
        # Dummy contact.
        contact = Contact(self.node.id, '127.0.0.1', 54321, self.version)
        # Check for the deferred.
        result = self.node.send_message(contact, msg)
        self.assertTrue(isinstance(result, defer.Deferred))
        # Ensure the timeout function was called
        call_count = mockCallLater.call_count
        # Tidy up.
        patcher.stop()
        # Check callLater was called twice - once each for connection timeout
        # and message timeout.
        self.assertEqual(2, call_count)

    @patch('drogulus.dht.node.clientFromString')
    def test_send_message_on_connect_adds_message_to_pending(self,
                                                             mock_client):
        """
        Ensure that when a connection is made the on_connect function wrapped
        inside send_message adds the message and deferred to the pending
        messages dictionary.
        """
        # Mock.
        mock_client.return_value = FakeClient(self.protocol)
        # Create a simple Ping message.
        uuid = str(uuid4())
        version = get_version()
        msg = Ping(uuid, self.node_id, version)
        # Dummy contact.
        contact = Contact(self.node.id, '127.0.0.1', 54321, self.version)
        deferred = self.node.send_message(contact, msg)
        self.assertIn(uuid, self.node._pending)
        self.assertEqual(self.node._pending[uuid], deferred)
        # Tidies up.
        self.clock.advance(RPC_TIMEOUT)

    @patch('drogulus.dht.node.clientFromString')
    def test_send_message_timeout_connection_cancel_called(self, mock_client):
        """
        If attempting to connect times out before the connection is eventuially
        made, ensure the connection's deferred is cancelled.
        """
        mock_client.return_value = FakeClient(self.protocol, True, True, True)
        # Create a simple Ping message.
        uuid = str(uuid4())
        version = get_version()
        msg = Ping(uuid, self.node_id, version)
        # Dummy contact.
        contact = Contact(self.node.id, '127.0.0.1', 54321, self.version)
        self.node.send_message(contact, msg)
        self.clock.advance(RPC_TIMEOUT)
        self.assertNotIn(uuid, self.node._pending)
        self.assertEqual(1,
                         mock_client.return_value.cancel_function.call_count)

    @patch('drogulus.dht.node.clientFromString')
    def test_send_message_timeout_remove_contact(self, mock_client):
        """
        If the connection deferred is cancelled ensure that the node's
        _routing_table.remove_contact is called once.
        """
        mock_client.return_value = FakeClient(self.protocol, True, True, False)
        self.node._routing_table.remove_contact = MagicMock()
        # Create a simple Ping message.
        uuid = str(uuid4())
        version = get_version()
        msg = Ping(uuid, self.node_id, version)
        # Dummy contact.
        contact = Contact(self.node.id, '127.0.0.1', 54321, self.version)
        self.node.send_message(contact, msg)
        self.clock.advance(RPC_TIMEOUT)
        self.assertNotIn(uuid, self.node._pending)
        self.node._routing_table.remove_contact.\
            assert_called_once_with(self.node.id)

    @patch('drogulus.dht.node.clientFromString')
    def test_send_message_response_timeout_call_later(self, mock_client):
        """
        Ensure that when a connection is made the on_connect function wrapped
        inside send_message calls callLater with the response_timeout function.
        """
        mock_client.return_value = FakeClient(self.protocol)
        # Mock the timeout function
        patcher = patch('drogulus.dht.node.response_timeout')
        mockTimeout = patcher.start()
        # Create a simple Ping message.
        uuid = str(uuid4())
        version = get_version()
        msg = Ping(uuid, self.node_id, version)
        # Dummy contact.
        contact = Contact(self.node.id, '127.0.0.1', 54321, self.version)
        deferred = self.node.send_message(contact, msg)
        self.assertIn(uuid, self.node._pending)
        self.assertEqual(self.node._pending[uuid], deferred)
        self.clock.advance(RESPONSE_TIMEOUT)
        # Ensure the timeout function was called
        self.assertEqual(1, mockTimeout.call_count)
        # Tidy up.
        patcher.stop()

    @patch('drogulus.dht.node.clientFromString')
    def test_send_message_sends_message(self, mock_client):
        """
        Ensure that the message passed in to send_message gets sent down the
        wire to the recipient.
        """
        mock_client.return_value = FakeClient(self.protocol)
        self.protocol.sendMessage = MagicMock()
        # Create a simple Ping message.
        uuid = str(uuid4())
        version = get_version()
        msg = Ping(uuid, self.node_id, version)
        # Dummy contact.
        contact = Contact(self.node.id, '127.0.0.1', 54321, self.version)
        self.node.send_message(contact, msg)
        self.protocol.sendMessage.assert_called_once_with(msg)
        # Tidy up.
        self.clock.advance(RPC_TIMEOUT)

    @patch('drogulus.dht.node.clientFromString')
    def test_send_message_errback_if_errors(self, mock_client):
        """
        Ensure that if there's an error during connection or sending of the
        message then the errback is fired.
        """
        mock_client.return_value = FakeClient(self.protocol, success=False)
        errback = MagicMock()
        self.node._routing_table.remove_contact = MagicMock()
        patcher = patch('drogulus.dht.node.log.msg')
        mockLog = patcher.start()
        # Create a simple Ping message.
        uuid = str(uuid4())
        version = get_version()
        msg = Ping(uuid, self.node_id, version)
        # Set up a dummy pending request to ensure it is cleaned up by the
        # errback
        self.node._pending[uuid] = defer.Deferred()
        # Dummy contact.
        contact = Contact(self.node.id, '127.0.0.1', 54321, self.version)
        deferred = self.node.send_message(contact, msg)
        deferred.addErrback(errback)
        # The errback is called and the error is logged automatically.
        self.assertEqual(1, errback.call_count)
        self.assertEqual(2, mockLog.call_count)
        # Clean up occurs as expected.
        self.assertEqual(1, self.node._routing_table.remove_contact.call_count)
        # The dummy pending request has been removed from _pending.
        self.assertNotIn(uuid, self.node._pending)
        # Tidy up.
        patcher.stop()
        self.clock.advance(RPC_TIMEOUT)

    def test_trigger_deferred_no_match(self):
        """
        Ensures that there are no changes to the _pending dict if there are
        no matches for the incoming message's uuid.
        """
        to_not_match = str(uuid4())
        self.node._pending[to_not_match] = defer.Deferred()
        # Create a simple Pong message.
        uuid = str(uuid4())
        version = get_version()
        msg = Pong(uuid, self.node_id, version)
        # Trigger.
        self.node.trigger_deferred(msg)
        # Check.
        self.assertEqual(1, len(self.node._pending))
        self.assertIn(to_not_match, self.node._pending)

    def test_trigger_deferred_with_error(self):
        """
        Ensures that an errback is called on the correct deferred given the
        incoming message's uuid if the error flag is passed in.
        """
        uuid = str(uuid4())
        deferred = defer.Deferred()
        self.node._pending[uuid] = deferred
        handler = MagicMock()
        deferred.addErrback(handler)
        # Create an Error message.
        version = get_version()
        code = 1
        title = ERRORS[code]
        details = {'foo': 'bar'}
        msg = Error(uuid, self.node_id, code, title, details, version)
        # Sanity check.
        self.assertEqual(1, len(self.node._pending))
        # Trigger.
        error = ValueError('Information about the erroneous message')
        self.node.trigger_deferred(msg, error)
        # The deferred has fired with an errback.
        self.assertTrue(deferred.called)
        self.assertEqual(1, handler.call_count)
        self.assertEqual(handler.call_args[0][0].value, error)
        self.assertEqual(handler.call_args[0][0].value.message, msg)
        self.assertEqual(handler.call_args[0][0].__class__, Failure)

    def test_trigger_deferred_with_ok_message(self):
        """
        Ensures that a callback is triggered on the correct deferred given the
        incoming message's uuid.
        """
        # Set up a simple Pong message.
        uuid = str(uuid4())
        deferred = defer.Deferred()
        self.node._pending[uuid] = deferred
        handler = MagicMock()
        deferred.addCallback(handler)
        version = get_version()
        msg = Pong(uuid, self.node_id, version)
        # Sanity check.
        self.assertEqual(1, len(self.node._pending))
        # Trigger.
        self.node.trigger_deferred(msg)
        # The deferred has fired with a callback.
        self.assertTrue(deferred.called)
        self.assertEqual(1, handler.call_count)
        self.assertEqual(handler.call_args[0][0], msg)
        # The deferred is removed from pending.
        self.assertEqual(0, len(self.node._pending))

    def test_trigger_deferred_cleans_up(self):
        """
        Ensures that once the deferred is triggered it is cleaned from the
        node's _pending dict.
        """
        # Set up a simple Pong message.
        uuid = str(uuid4())
        deferred = defer.Deferred()
        self.node._pending[uuid] = deferred
        handler = MagicMock()
        deferred.addCallback(handler)
        version = get_version()
        msg = Pong(uuid, self.node_id, version)
        # Sanity check.
        self.assertEqual(1, len(self.node._pending))
        # Trigger.
        self.node.trigger_deferred(msg)
        # The deferred is removed from pending.
        self.assertEqual(0, len(self.node._pending))

    def test_handle_pong(self):
        """
        Ensures that a pong message triggers the correct deferred that was
        originally created by an outgoing (ping) message.
        """
        # Mock
        self.node.trigger_deferred = MagicMock()
        # Create a simple Pong message.
        uuid = str(uuid4())
        version = get_version()
        msg = Pong(uuid, self.node_id, version)
        # Handle it.
        self.node.handle_pong(msg)
        # Check the result.
        result = Pong(uuid, self.node.id, version)
        self.node.trigger_deferred.assert_called_once_with(result)

    @patch('drogulus.dht.node.clientFromString')
    def test_send_ping_returns_deferred(self, mock_client):
        """
        Ensures that sending a ping returns a deferred.
        """
        mock_client.return_value = FakeClient(self.protocol)
        # Dummy contact.
        contact = Contact(self.node.id, '127.0.0.1', 54321, self.version)
        deferred = self.node.send_ping(contact)
        self.assertIsInstance(deferred, defer.Deferred)
        # Tidy up.
        self.clock.advance(RPC_TIMEOUT)

    def test_send_ping_calls_send_message(self):
        """
        Ensures that sending a ping calls the node's send_message method with
        the ping message.
        """
        # Mock
        self.node.send_message = MagicMock()
        # Dummy contact.
        contact = Contact(self.node.id, '127.0.0.1', 54321, self.version)
        self.node.send_ping(contact)
        self.assertEqual(1, self.node.send_message.call_count)
        called_contact = self.node.send_message.call_args[0][0]
        self.assertEqual(contact, called_contact)
        message_to_send = self.node.send_message.call_args[0][1]
        self.assertIsInstance(message_to_send, Ping)

    @patch('drogulus.dht.node.construct_key')
    def test_send_store_makes_compound_key(self, mock):
        """
        Ensure the construct_key function is called with the expected arguments
        as part of send_store.
        """
        mock.return_value = 'test'
        contact = Contact(self.node.id, '127.0.0.1', 54321, self.version)
        self.node.send_store(contact, PUBLIC_KEY, self.name, self.value,
                             self.timestamp, self.expires, self.meta,
                             self.version, self.signature)
        mock.assert_called_once_with(PUBLIC_KEY, self.name)

    def test_send_store_calls_send_message(self):
        """
        Ensure send_message is called as part of send_store.
        """
        self.node.send_message = MagicMock()
        contact = Contact(self.node.id, '127.0.0.1', 54321, self.version)
        self.node.send_store(contact, PUBLIC_KEY, self.name, self.value,
                             self.timestamp, self.expires, self.meta,
                             self.version, self.signature)
        self.assertEqual(1, self.node.send_message.call_count)

    def test_send_store_creates_expected_store_message(self):
        """
        Ensure the message passed in to send_message looks correct.
        """
        self.node.send_message = MagicMock()
        contact = Contact(self.node.id, '127.0.0.1', 54321, self.version)
        self.node.send_store(contact, PUBLIC_KEY, self.name, self.value,
                             self.timestamp, self.expires, self.version,
                             self.meta, self.signature)
        self.assertEqual(1, self.node.send_message.call_count)
        called_contact = self.node.send_message.call_args[0][0]
        self.assertEqual(called_contact, contact)
        message_to_send = self.node.send_message.call_args[0][1]
        self.assertIsInstance(message_to_send, Store)
        self.assertTrue(message_to_send.uuid)
        self.assertEqual(message_to_send.node, self.node.id)
        self.assertEqual(message_to_send.key, self.key)
        self.assertEqual(message_to_send.value, self.value)
        self.assertEqual(message_to_send.timestamp, self.timestamp)
        self.assertEqual(message_to_send.expires, self.expires)
        self.assertEqual(message_to_send.created_with, self.version)
        self.assertEqual(message_to_send.public_key, PUBLIC_KEY)
        self.assertEqual(message_to_send.name, self.name)
        self.assertEqual(message_to_send.meta, self.meta)
        self.assertEqual(message_to_send.sig, self.signature)
        self.assertEqual(message_to_send.version, self.node.version)

    @patch('drogulus.dht.node.clientFromString')
    def test_send_find_returns_uuid_and_deferred(self, mock_client):
        """
        Ensures that sending a Find[Node|Value] message returns a deferred.
        """
        mock_client.return_value = FakeClient(self.protocol)
        # Dummy contact.
        contact = Contact(self.node.id, '127.0.0.1', 54321, self.version)
        target = '123456'
        find_class = FindNode
        uuid, deferred = self.node.send_find(contact, target, find_class)
        self.assertIsInstance(uuid, str)
        self.assertIsInstance(deferred, defer.Deferred)
        # Tidy up.
        self.clock.advance(RPC_TIMEOUT)

    def test_send_find_as_findnode_calls_send_message(self):
        """
        Ensures that sending a FindNode message causes the node's send_message
        method to be called with the expected message.
        """
        # Mock
        self.node.send_message = MagicMock()
        # Dummy contact.
        contact = Contact(self.node.id, '127.0.0.1', 54321, self.version)
        target = '123456'
        find_class = FindNode
        uuid, deferred = self.node.send_find(contact, target, find_class)
        self.assertEqual(1, self.node.send_message.call_count)
        called_contact = self.node.send_message.call_args[0][0]
        self.assertEqual(contact, called_contact)
        message_to_send = self.node.send_message.call_args[0][1]
        self.assertIsInstance(message_to_send, FindNode)
        self.assertEqual(target, message_to_send.key)

    def test_send_find_as_findvalue_calls_send_message(self):
        """
        Ensures that sending a FindValue message causes the node's send_message
        method to be called with the expected message.
        """
        # Mock
        self.node.send_message = MagicMock()
        # Dummy contact.
        contact = Contact(self.node.id, '127.0.0.1', 54321, self.version)
        target = '123456'
        find_class = FindValue
        uuid, deferred = self.node.send_find(contact, target, find_class)
        self.assertEqual(1, self.node.send_message.call_count)
        called_contact = self.node.send_message.call_args[0][0]
        self.assertEqual(contact, called_contact)
        message_to_send = self.node.send_message.call_args[0][1]
        self.assertIsInstance(message_to_send, FindValue)
        self.assertEqual(target, message_to_send.key)

    def test_process_lookup_result_returns_deferred_list(self):
        """
        Ensures a DeferredList of the expected length is returned from
        _process_lookup_result.
        """
        result = self.node._process_lookup_result(self.nodes, PUBLIC_KEY,
                                                  self.name, self.value,
                                                  self.timestamp, self.expires,
                                                  self.meta, self.version,
                                                  self.signature, 3)
        self.assertIsInstance(result, list)
        self.assertEqual(3, len(result))

    def test_process_lookup_result_sends_expected_number_of_send_store(self):
        """
        Ensure the _process_lookup_result calls the send_store method correctly
        for the expected number of times.
        """
        self.node.send_store = MagicMock()
        self.node._process_lookup_result(self.nodes, PUBLIC_KEY, self.name,
                                         self.value, self.timestamp,
                                         self.expires, self.meta,
                                         self.version, self.signature, 3)
        self.assertEqual(3, self.node.send_store.call_count)
        self.assertEqual(self.nodes[0],
                         self.node.send_store.call_args_list[0][0][0])
        self.assertEqual(PUBLIC_KEY,
                         self.node.send_store.call_args_list[0][0][1])
        self.assertEqual(self.name,
                         self.node.send_store.call_args_list[0][0][2])
        self.assertEqual(self.value,
                         self.node.send_store.call_args_list[0][0][3])
        self.assertEqual(self.timestamp,
                         self.node.send_store.call_args_list[0][0][4])
        self.assertEqual(self.expires,
                         self.node.send_store.call_args_list[0][0][5])
        self.assertEqual(self.meta,
                         self.node.send_store.call_args_list[0][0][6])
        self.assertEqual(self.version,
                         self.node.send_store.call_args_list[0][0][7])
        self.assertEqual(self.signature,
                         self.node.send_store.call_args_list[0][0][8])

    def test_process_lookup_result_uses_closest_nodes(self):
        """
        Ensure that the nodes targetted by the send_store calls are the ones
        closest to the target key.
        """
        self.node.send_store = MagicMock()
        self.node._process_lookup_result(self.nodes, PUBLIC_KEY, self.name,
                                         self.value, self.timestamp,
                                         self.expires, self.meta,
                                         self.version, self.signature, 3)
        self.assertEqual(3, self.node.send_store.call_count)
        for i in range(3):
            self.assertEqual(self.nodes[i].id,
                             self.node.send_store.call_args_list[i][0][0].id)

    def test_replicate_returns_a_deferred(self):
        """
        Ensures the replicate method returns a deferred.
        """
        # Patch NodeLookup._lookup
        patcher = patch('drogulus.dht.node.NodeLookup._lookup')
        patcher.start()
        result = self.node.replicate(PUBLIC_KEY, self.name, self.value,
                                     self.timestamp, self.expires, self.meta,
                                     self.version, self.signature,
                                     DUPLICATION_COUNT)
        self.assertIsInstance(result, defer.Deferred)
        # Tidy up.
        patcher.stop()

    def test_replicate_stops_bad_duplication_count(self):
        """
        Ensure replicate complains if a bad duplication count is used.
        """
        ex = self.assertRaises(ValueError, self.node.replicate, PUBLIC_KEY,
                               self.name, self.value, self.timestamp,
                               self.expires, self.meta, self.version,
                               self.signature, 0)
        self.assertEqual('Duplication count may not be less than 1',
                         ex.message)

    def test_replicate_uses_node_lookup_with_expected_values(self):
        """
        Ensure that the replicate method does a node lookup with the expected
        target key.
        """
        patcher = patch('drogulus.dht.node.NodeLookup')
        mock_lookup = patcher.start()
        self.node.replicate(PUBLIC_KEY, self.name, self.value, self.timestamp,
                            self.expires, self.meta, self.version,
                            self.signature, DUPLICATION_COUNT)
        self.assertEqual(1, mock_lookup.call_count)
        expected_target = construct_key(PUBLIC_KEY, self.name)
        self.assertEqual(expected_target, mock_lookup.call_args[0][0])
        self.assertEqual(FindNode, mock_lookup.call_args[0][1])
        self.assertEqual(self.node, mock_lookup.call_args[0][2])
        # Tidy up.
        patcher.stop()

    def test_replicate_deferred_fires_with_expected_deferred_list(self):
        """
        Make sure the deferred is fired with a list of the expected length when
        the node lookup completes.
        """
        for i in range(K):
            contact = Contact(long_to_hex(i), '192.168.0.%d' % i, 9999,
                              self.node.version, 0)
            self.node._routing_table.add_contact(contact)

        def side_effect(*args):
            """
            Ensures the mock send_find returns something useful.
            """
            uuid = str(uuid4())
            deferred = defer.Deferred()
            # fire the deferred with a default Nodes message
            msg = Nodes(self.uuid, self.node.id, self.nodes, self.node.version)
            deferred.callback(msg)
            return (uuid, deferred)

        self.node.send_find = MagicMock(side_effect=side_effect)
        result = self.node.replicate(PUBLIC_KEY, self.name, self.value,
                                     self.timestamp, self.expires, self.meta,
                                     self.version, self.signature,
                                     DUPLICATION_COUNT)

        def check_callback(items):
            """
            Contains checks to ensure the deferred fires with the expected
            list.
            """
            self.assertIsInstance(items, list)
            for deferred in items:
                self.assertIsInstance(deferred, defer.Deferred)

        self.assertTrue(result.called)
        result.addCallback(check_callback)

    def test_replicate_handles_errors_as_expected(self):
        """
        Ensure error conditions are made visible in the expected way.
        """
        # Will fail because self.node's routing table is empty.
        result = self.node.replicate(PUBLIC_KEY, self.name, self.value,
                                     self.timestamp, self.expires, self.meta,
                                     self.version, self.signature,
                                     DUPLICATION_COUNT)

        def check_errback(error):
            """
            Ensure we get the expected error
            """
            self.assertIsInstance(error.value, RoutingTableEmpty)

        self.assertTrue(result.called)
        result.addErrback(check_errback)

    def test_retrieve(self):
        """
        Ensures that the Node instance's retrieve method returns the expected
        NodeLookup object.
        """
        for i in range(K):
            contact = Contact(long_to_hex(i), '192.168.0.%d' % i, 9999,
                              self.node.version, 0)
            self.node._routing_table.add_contact(contact)
        patcher = patch('drogulus.dht.node.NodeLookup._lookup')
        mock_lookup = patcher.start()
        key = construct_key(PUBLIC_KEY, 'key_name')
        lookup = self.node.retrieve(key)
        self.assertIsInstance(lookup, NodeLookup)
        self.assertEqual(lookup.target, key)
        self.assertEqual(lookup.message_type, FindValue)
        self.assertEqual(lookup.local_node, self.node)
        self.assertEqual(1, mock_lookup.call_count)
        # Tidy up.
        patcher.stop()

    def test_retrieve_fires_cache(self):
        """
        Ensures that the retrieval of a value causes the caching of the found
        value to the node closest to the key that did not return the value.
        """
        for i in range(K):
            contact = Contact(long_to_hex(i), '192.168.0.%d' % i, 9999,
                              self.node.version, 0)
            self.node._routing_table.add_contact(contact)

        def side_effect(*args):
            """
            Ensures the mock returns something useful.
            """
            uuid = str(uuid4())
            deferred = defer.Deferred()
            return (uuid, deferred)

        self.node.send_find = MagicMock(side_effect=side_effect)
        key = long_to_hex(0)
        lookup = self.node.retrieve(key)

        self.node.send_store = MagicMock()
        msg = Value(str(uuid4()), key, self.key, self.value, self.timestamp,
                    self.expires, self.version, PUBLIC_KEY, self.name,
                    self.meta, self.signature, self.node.version)
        lookup.callback(msg)
        self.assertEqual(1, self.node.send_store.call_count)
        closest_contact = lookup.shortlist[0]
        self.node.send_store.assert_called_once_with(closest_contact,
                                                     msg.public_key, msg.name,
                                                     msg.value, msg.timestamp,
                                                     msg.expires,
                                                     msg.created_with,
                                                     msg.meta, msg.sig)

        def callback_checker(result):
            """
            Ensures the result is as expected.
            """
            self.assertEqual(msg, result)
        lookup.addCallback(callback_checker)

########NEW FILE########
__FILENAME__ = test_routingtable
# -*- coding: utf-8 -*-
"""
Ensures the routing table (a binary tree used to link kbuckets with key ranges
in the DHT) works as expected.
"""
from drogulus.dht.routingtable import RoutingTable
from drogulus.dht.contact import Contact
from drogulus.dht.kbucket import KBucket
from drogulus import constants
from drogulus.utils import long_to_hex, distance
from drogulus.version import get_version
import unittest
import time
from mock import MagicMock


class TestRoutingTable(unittest.TestCase):
    """
    Ensures the RoutingTable class works as expected.
    """

    def setUp(self):
        """
        Common vars.
        """
        self.version = get_version()

    def test_init(self):
        """
        Ensures an object is created as expected.
        """
        parent_node_id = 'abc'
        r = RoutingTable(parent_node_id)
        # Ensure the initial kbucket is created.
        self.assertEqual(1, len(r._buckets))
        # Ensure the parent's node ID is stored.
        self.assertEqual(parent_node_id, r._parent_node_id)

    def test_kbucket_index_single_bucket(self):
        """
        Ensures the expected index is returned when only a single bucket
        exists.
        """
        parent_node_id = 'abc'
        r = RoutingTable(parent_node_id)
        # a simple test with only one kbucket in the routing table.
        test_key = 'abc123'
        expected_index = 0
        actual_index = r._kbucket_index(test_key)
        self.assertEqual(expected_index, actual_index)

    def test_kbucket_index_multiple_buckets(self):
        """
        Ensures the expected index is returned when multiple buckets exist.
        """
        parent_node_id = 'abc'
        r = RoutingTable(parent_node_id)
        r._split_bucket(0)
        split_point = (2 ** 512) / 2
        lower_key = split_point - 1
        higher_key = split_point + 1
        expected_lower_index = 0
        expected_higher_index = 1
        actual_lower_index = r._kbucket_index(lower_key)
        actual_higher_index = r._kbucket_index(higher_key)
        self.assertEqual(expected_lower_index, actual_lower_index)
        self.assertEqual(expected_higher_index, actual_higher_index)

    def test_kbucket_index_as_string_and_int(self):
        """
        Ensures that the specified key can be expressed as both a string
        and integer value.
        """
        parent_node_id = 'abc'
        r = RoutingTable(parent_node_id)
        # key as a string
        test_key = 'abc123'
        expected_index = 0
        actual_index = r._kbucket_index(test_key)
        self.assertEqual(expected_index, actual_index)
        # key as an integer
        test_key = 1234567
        actual_index = r._kbucket_index(test_key)
        self.assertEqual(expected_index, actual_index)

    def test_kbucket_index_out_of_range(self):
        """
        If the requested id is not within the range of the keyspace then a
        ValueError should be raised.
        """
        parent_node_id = 'abc'
        r = RoutingTable(parent_node_id)
        # Populate the routing table with contacts.
        for i in range(512):
            contact = Contact(2 ** i, "192.168.0.%d" % i, 9999, self.version,
                              0)
            r.add_contact(contact)
        with self.assertRaises(ValueError):
            # Incoming id that's too small.
            r.find_close_nodes(-1)
        with self.assertRaises(ValueError):
            # Incoming id that's too big
            big_id = 2 ** 512
            r.find_close_nodes(big_id)

    def test_random_key_in_bucket_range(self):
        """
        Ensures the returned key is within the expected bucket range.
        """
        parent_node_id = 'abc'
        r = RoutingTable(parent_node_id)
        bucket = KBucket(1, 2)
        r._buckets[0] = bucket
        expected = 1
        actual = int(r._random_key_in_bucket_range(0).encode('hex'), 16)
        self.assertEqual(expected, actual)

    def test_random_key_in_bucket_range_long(self):
        """
        Ensures that random_key_in_bucket_range works with large numbers.
        """
        minimum = 978675645342314253647586978
        maximum = 978675645342314253647586979
        parent_node_id = 'abc'
        r = RoutingTable(parent_node_id)
        bucket = KBucket(minimum, maximum)
        r._buckets[0] = bucket
        expected = minimum
        actual = int(r._random_key_in_bucket_range(0).encode('hex'), 16)
        self.assertEqual(expected, actual)

    def test_split_bucket(self):
        """
        Ensures that the correct bucket is split in two and that the contacts
        are found in the right place.
        """
        parent_node_id = 'abc'
        r = RoutingTable(parent_node_id)
        bucket = KBucket(0, 10)
        contact1 = Contact(2, '192.168.0.1', 9999, 0)
        bucket.add_contact(contact1)
        contact2 = Contact(4, '192.168.0.2', 8888, 0)
        bucket.add_contact(contact2)
        contact3 = Contact(6, '192.168.0.3', 8888, 0)
        bucket.add_contact(contact3)
        contact4 = Contact(8, '192.168.0.4', 8888, 0)
        bucket.add_contact(contact4)
        r._buckets[0] = bucket
        # Sanity check
        self.assertEqual(1, len(r._buckets))
        r._split_bucket(0)
        # Two buckets!
        self.assertEqual(2, len(r._buckets))
        bucket1 = r._buckets[0]
        bucket2 = r._buckets[1]
        # Ensure the right number of contacts are in each bucket in the correct
        # order (most recently added at the head of the list).
        self.assertEqual(2, len(bucket1._contacts))
        self.assertEqual(2, len(bucket2._contacts))
        self.assertEqual(contact1, bucket1._contacts[0])
        self.assertEqual(contact2, bucket1._contacts[1])
        self.assertEqual(contact3, bucket2._contacts[0])
        self.assertEqual(contact4, bucket2._contacts[1])
        # Split the new bucket again, ensuring that only the target bucket is
        # modified.
        r._split_bucket(1)
        self.assertEqual(3, len(r._buckets))
        bucket3 = r._buckets[2]
        # kbucket1 remains un-changed
        self.assertEqual(2, len(bucket1._contacts))
        # kbucket2 only contains the lower half of its original contacts.
        self.assertEqual(1, len(bucket2._contacts))
        self.assertEqual(contact3, bucket2._contacts[0])
        # kbucket3 now contains the upper half of the original contacts.
        self.assertEqual(1, len(bucket3._contacts))
        self.assertEqual(contact4, bucket3._contacts[0])
        # Split the bucket at position 0 and ensure the resulting buckets are
        # in the correct position with the correct content.
        r._split_bucket(0)
        self.assertEqual(4, len(r._buckets))
        bucket1, bucket2, bucket3, bucket4 = r._buckets
        self.assertEqual(1, len(bucket1._contacts))
        self.assertEqual(contact1, bucket1._contacts[0])
        self.assertEqual(1, len(bucket2._contacts))
        self.assertEqual(contact2, bucket2._contacts[0])
        self.assertEqual(1, len(bucket3._contacts))
        self.assertEqual(contact3, bucket3._contacts[0])
        self.assertEqual(1, len(bucket4._contacts))
        self.assertEqual(contact4, bucket4._contacts[0])

    def test_blacklist(self):
        """
        Ensures a misbehaving peer is correctly blacklisted. The remove_contact
        method is called and the contact's id is added to the _blacklist set.
        """
        parent_node_id = 'abc'
        r = RoutingTable(parent_node_id)
        contact = Contact('abc', '192.168.0.1', 9999, 0)
        r.remove_contact = MagicMock()
        r.blacklist(contact)
        r.remove_contact.called_once_with(contact, True)
        self.assertIn(contact.id, r._blacklist)

    def test_add_contact_with_parent_node_id(self):
        """
        If the newly discovered contact is, in fact, this node then it's not
        added to the routing table.
        """
        parent_node_id = 'abc'
        r = RoutingTable(parent_node_id)
        contact = Contact('abc', '192.168.0.1', 9999, 0)
        r.add_contact(contact)
        self.assertEqual(len(r._buckets[0]), 0)

    def test_add_contact_with_blacklisted_contact(self):
        """
        If the newly discovered contact is, in fact, already in the local
        node's blacklist then ensure it doesn't get re-added.
        """
        parent_node_id = 'abc'
        r = RoutingTable(parent_node_id)
        contact1 = Contact(2, '192.168.0.1', 9999, 0)
        contact2 = Contact(4, '192.168.0.2', 9999, 0)
        r.blacklist(contact2)
        r.add_contact(contact1)
        self.assertEqual(len(r._buckets[0]), 1)
        r.add_contact(contact2)
        self.assertEqual(len(r._buckets[0]), 1)

    def test_add_contact_simple(self):
        """
        Ensures that a newly discovered node in the network is added to the
        correct kbucket in the routing table.
        """
        parent_node_id = 'abc'
        r = RoutingTable(parent_node_id)
        contact1 = Contact(2, '192.168.0.1', 9999, 0)
        contact2 = Contact(4, '192.168.0.2', 9999, 0)
        r.add_contact(contact1)
        self.assertEqual(len(r._buckets[0]), 1)
        r.add_contact(contact2)
        self.assertEqual(len(r._buckets[0]), 2)

    def test_add_contact_with_bucket_split(self):
        """
        Ensures that newly discovered nodes are added to the appropriate
        kbucket given a bucket split.
        """
        parent_node_id = 'abc'
        r = RoutingTable(parent_node_id)
        for i in range(20):
            contact = Contact(i, '192.168.0.%d' % i, 9999, self.version, 0)
            r.add_contact(contact)
        # This id will be just over the max range for the bucket in position 0
        large_id = ((2 ** 512) / 2) + 1
        contact = Contact(large_id, '192.168.0.33', 9999, self.version, 0)
        r.add_contact(contact)
        self.assertEqual(len(r._buckets), 2)
        self.assertEqual(len(r._buckets[0]), 20)
        self.assertEqual(len(r._buckets[1]), 1)

    def test_add_contact_with_bucket_full(self):
        """
        Checks if a bucket is full and a new contact within the full bucket's
        range is added then it gets put in the replacement cache.
        """
        parent_node_id = 'abc'
        r = RoutingTable(parent_node_id)
        # Fill up the bucket
        for i in range(20):
            contact = Contact(i, '192.168.0.%d' % i, 9999, self.version, 0)
            r.add_contact(contact)
        # Create a new contact that will be added to the replacement cache.
        contact = Contact(20, '192.168.0.20', 9999, self.version, 0)
        r.add_contact(contact)
        self.assertEqual(len(r._buckets[0]), 20)
        self.assertTrue(0 in r._replacement_cache)
        self.assertEqual(contact, r._replacement_cache[0][0])

    def test_add_contact_with_full_replacement_cache(self):
        """
        Ensures that if the replacement cache is full (length = k) then the
        oldest contact within the cache is replaced with the new contact that
        was just seen.
        """
        parent_node_id = 'abc'
        r = RoutingTable(parent_node_id)
        # Fill up the bucket and replacement cache
        for i in range(40):
            contact = Contact(str(i), "192.168.0.%d" % i, 9999, self.version,
                              0)
            r.add_contact(contact)
        # Sanity check of the replacement cache.
        self.assertEqual(len(r._replacement_cache[0]), 20)
        self.assertEqual('20', r._replacement_cache[0][0].id)
        # Create a new contact that will be added to the replacement cache.
        new_contact = Contact('40', "192.168.0.20", 9999, self.version, 0)
        r.add_contact(new_contact)
        self.assertEqual(len(r._replacement_cache[0]), 20)
        self.assertEqual(new_contact, r._replacement_cache[0][19])
        self.assertEqual('21', r._replacement_cache[0][0].id)

    def test_add_contact_with_existing_contact_in_replacement_cache(self):
        """
        Ensures that if the contact to be put in the replacement cache already
        exists in the replacement cache then it is bumped to the most recent
        position.
        """
        parent_node_id = 'abc'
        r = RoutingTable(parent_node_id)
        # Fill up the bucket and replacement cache
        for i in range(40):
            contact = Contact(str(i), '192.168.0.%d' % i, 9999, self.version,
                              0)
            r.add_contact(contact)
        # Sanity check of the replacement cache.
        self.assertEqual(len(r._replacement_cache[0]), 20)
        self.assertEqual('20', r._replacement_cache[0][0].id)
        # Create a new contact that will be added to the replacement cache.
        new_contact = Contact('20', '192.168.0.20', 9999, self.version, 0)
        r.add_contact(new_contact)
        self.assertEqual(len(r._replacement_cache[0]), 20)
        self.assertEqual(new_contact, r._replacement_cache[0][19])
        self.assertEqual('21', r._replacement_cache[0][0].id)

    def test_add_contact_id_out_of_range(self):
        """
        Ensures a Contact with an out-of-range id cannot be added to the
        routing table.
        """
        parent_node_id = 'abc'
        r = RoutingTable(parent_node_id)
        with self.assertRaises(TypeError):
            # id too small
            contact = Contact(-1, '192.168.0.1', 9999, self.version, 0)
            r.add_contact(contact)
        with self.assertRaises(ValueError):
            # id too big
            big_id = (2 ** 512)
            contact = Contact(big_id, '192.168.0.1', 9999, self.version, 0)
            r.add_contact(contact)

    def test_find_close_nodes_single_kbucket(self):
        """
        Ensures K number of closest nodes get returned.
        """
        parent_node_id = 'abc'
        r = RoutingTable(parent_node_id)
        # Fill up the bucket and replacement cache
        for i in range(40):
            contact = Contact(i, "192.168.0.%d" % i, 9999, self.version, 0)
            r.add_contact(contact)
        result = r.find_close_nodes(hex(1))
        self.assertEqual(constants.K, len(result))

    def test_find_close_nodes_fewer_than_K(self):
        """
        Ensures that all close nodes are returned if their number is < K.
        """
        parent_node_id = 'abc'
        r = RoutingTable(parent_node_id)
        # Fill up the bucket and replacement cache
        for i in range(10):
            contact = Contact(i, "192.168.0.%d" % i, 9999, self.version, 0)
            r.add_contact(contact)
        result = r.find_close_nodes(hex(1))
        self.assertEqual(10, len(result))

    def test_find_close_nodes_multiple_buckets(self):
        """
        Ensures that nodes are returned from neighbouring k-buckets if the
        k-bucket containing the referenced ID doesn't contain K entries.
        """
        parent_node_id = 'abc'
        r = RoutingTable(parent_node_id)
        # Fill up the bucket and replacement cache
        for i in range(512):
            contact = Contact(2 ** i, "192.168.0.%d" % i, 9999, self.version,
                              0)
            r.add_contact(contact)
        result = r.find_close_nodes(long_to_hex(2 ** 256))
        self.assertEqual(constants.K, len(result))

    def test_find_close_nodes_exclude_contact(self):
        """
        Ensure that nearest nodes are returned except for the specified
        excluded node.
        """
        parent_node_id = 'abc'
        r = RoutingTable(parent_node_id)
        # Fill up the bucket and replacement cache
        for i in range(20):
            contact = Contact(i, "192.168.0.%d" % i, 9999, self.version, 0)
            r.add_contact(contact)
        result = r.find_close_nodes(hex(1), rpc_node_id=contact.id)
        self.assertEqual(constants.K - 1, len(result))

    def test_find_close_nodes_in_correct_order(self):
        """
        Ensures that the nearest nodes are returned in the correct order: from
        the node closest to the target key to the node furthest away.
        """
        parent_node_id = 'abc'
        r = RoutingTable(parent_node_id)
        # Fill up the bucket and replacement cache
        for i in range(512):
            contact = Contact(2 ** i, "192.168.0.%d" % i, 9999, self.version,
                              0)
            r.add_contact(contact)
        target_key = long_to_hex(2 ** 256)
        result = r.find_close_nodes(target_key)
        self.assertEqual(constants.K, len(result))

        # Ensure results are in the correct order.
        def key(node):
            return distance(node.id, target_key)
        sorted_nodes = sorted(result, key=key)
        self.assertEqual(sorted_nodes, result)
        # Ensure the order is from lowest to highest in terms of distance
        distances = [distance(x.id, target_key) for x in result]
        self.assertEqual(sorted(distances), distances)

    def test_get_contact(self):
        """
        Ensures that the correct contact is returned.
        """
        parent_node_id = 'abc'
        r = RoutingTable(parent_node_id)
        contact1 = Contact('a', '192.168.0.1', 9999, self.version, 0)
        r.add_contact(contact1)
        result = r.get_contact('a')
        self.assertEqual(contact1, result)

    def test_get_contact_does_not_exist(self):
        """
        Ensures that a ValueError is returned if the referenced contact does
        not exist in the routing table.
        """
        parent_node_id = 'abc'
        r = RoutingTable(parent_node_id)
        contact1 = Contact('a', '192.168.0.1', 9999, self.version, 0)
        r.add_contact(contact1)
        self.assertRaises(ValueError, r.get_contact, 'b')

    def test_get_refresh_list(self):
        """
        Ensures that only keys from stale k-buckets are returned.
        """
        parent_node_id = 'abc'
        r = RoutingTable(parent_node_id)
        bucket1 = KBucket(1, 2)
        # Set the lastAccessed flag on bucket 1 to be out of date
        bucket1.last_accessed = int(time.time()) - 3700
        r._buckets[0] = bucket1
        bucket2 = KBucket(2, 3)
        bucket2.last_accessed = int(time.time())
        r._buckets.append(bucket2)
        expected = 1
        result = r.get_refresh_list(0)
        self.assertEqual(1, len(result))
        self.assertEqual(expected, int(result[0].encode('hex'), 16))

    def test_get_forced_refresh_list(self):
        """
        Ensures that keys from all k-buckets (no matter if they're stale or
        not) are returned.
        """
        parent_node_id = 'abc'
        r = RoutingTable(parent_node_id)
        bucket1 = KBucket(1, 2)
        # Set the lastAccessed flag on bucket 1 to be out of date
        bucket1.last_accessed = int(time.time()) - 3700
        r._buckets[0] = bucket1
        bucket2 = KBucket(2, 3)
        bucket2.last_accessed = int(time.time())
        r._buckets.append(bucket2)
        result = r.get_refresh_list(0, True)
        # Even though bucket 2 is not stale it still has a key for it in
        # the result.
        self.assertEqual(2, len(result))
        self.assertEqual(1, int(result[0].encode('hex'), 16))
        self.assertEqual(2, int(result[1].encode('hex'), 16))

    def test_remove_contact(self):
        """
        Ensures that a contact is removed, given that it's failedRPCs counter
        exceeds or is equal to constants.ALLOWED_RPC_FAILS
        """
        parent_node_id = 'abc'
        r = RoutingTable(parent_node_id)
        contact1 = Contact('a', '192.168.0.1', 9999, self.version, 0)
        contact2 = Contact('b', '192.168.0.2', 9999, self.version, 0)
        r.add_contact(contact1)
        # Contact 2 will have the wrong number of failedRPCs
        r.add_contact(contact2)
        contact2.failed_RPCs = constants.ALLOWED_RPC_FAILS
        # Sanity check
        self.assertEqual(len(r._buckets[0]), 2)

        r.remove_contact('b')
        self.assertEqual(len(r._buckets[0]), 1)
        self.assertEqual(contact1, r._buckets[0]._contacts[0])

    def test_remove_contact_with_unknown_contact(self):
        """
        Ensures that attempting to remove a non-existent contact results in a
        ValueError exception.
        """
        parent_node_id = 'abc'
        r = RoutingTable(parent_node_id)
        contact1 = Contact('a', '192.168.0.1', 9999, self.version, 0)
        r.add_contact(contact1)
        # Sanity check
        self.assertEqual(len(r._buckets[0]), 1)
        result = r.remove_contact('b')
        self.assertEqual(None, result)
        self.assertEqual(len(r._buckets[0]), 1)
        self.assertEqual(contact1, r._buckets[0]._contacts[0])

    def test_remove_contact_with_cached_replacement(self):
        """
        Ensures that the removed contact is replaced by the most up-to-date
        contact in the affected k-bucket's cache.
        """
        parent_node_id = 'abc'
        r = RoutingTable(parent_node_id)
        contact1 = Contact('a', '192.168.0.1', 9999, self.version, 0)
        contact2 = Contact('b', '192.168.0.2', 9999, self.version, 0)
        r.add_contact(contact1)
        # Contact 2 will have the wrong number of failedRPCs
        r.add_contact(contact2)
        contact2.failed_RPCs = constants.ALLOWED_RPC_FAILS
        # Add something into the cache.
        contact3 = Contact('c', '192.168.0.3', 9999, self.version, 0)
        r._replacement_cache[0] = [contact3, ]
        # Sanity check
        self.assertEqual(len(r._buckets[0]), 2)
        self.assertEqual(len(r._replacement_cache[0]), 1)

        r.remove_contact('b')
        self.assertEqual(len(r._buckets[0]), 2)
        self.assertEqual(contact1, r._buckets[0]._contacts[0])
        self.assertEqual(contact3, r._buckets[0]._contacts[1])
        self.assertEqual(len(r._replacement_cache[0]), 0)

    def test_remove_contact_with_not_enough_RPC_fails(self):
        """
        Ensures that the contact is not removed if it's failedRPCs counter is
        less than constants.ALLOWED_RPC_FAILS
        """
        parent_node_id = 'abc'
        r = RoutingTable(parent_node_id)
        contact1 = Contact('a', '192.168.0.1', 9999, self.version, 0)
        contact2 = Contact('b', '192.168.0.2', 9999, self.version, 0)
        r.add_contact(contact1)
        r.add_contact(contact2)
        # Sanity check
        self.assertEqual(len(r._buckets[0]), 2)

        r.remove_contact('b')
        self.assertEqual(len(r._buckets[0]), 2)

    def test_remove_contact_with_not_enough_RPC_but_forced(self):
        """
        Ensures that the contact is removed despite it's failedRPCs counter
        being less than constants.ALLOWED_RPC_FAILS because the 'forced' flag
        is used.
        """
        parent_node_id = 'abc'
        r = RoutingTable(parent_node_id)
        contact1 = Contact('a', '192.168.0.1', 9999, self.version, 0)
        contact2 = Contact('b', '192.168.0.2', 9999, self.version, 0)
        r.add_contact(contact1)
        r.add_contact(contact2)
        # Sanity check
        self.assertEqual(len(r._buckets[0]), 2)

        r.remove_contact('b', forced=True)
        self.assertEqual(len(r._buckets[0]), 1)

    def test_remove_contact_removes_from_replacement_cache(self):
        """
        Ensures that if a contact is signalled to be removed it is also cleared
        from the replacement_cache that would otherwise be another route for
        it to be re-added to the routing table.
        """
        parent_node_id = 'abc'
        r = RoutingTable(parent_node_id)
        contact1 = Contact('a', '192.168.0.1', 9999, self.version, 0)
        contact2 = Contact('b', '192.168.0.2', 9999, self.version, 0)
        r.add_contact(contact1)
        r.add_contact(contact2)
        r._replacement_cache[0] = []
        r._replacement_cache[0].append(contact2)
        # Sanity check
        self.assertEqual(len(r._buckets[0]), 2)
        self.assertEqual(len(r._replacement_cache[0]), 1)

        r.remove_contact('b', forced=True)
        self.assertEqual(len(r._buckets[0]), 1)
        self.assertNotIn(contact2, r._replacement_cache)

    def test_touch_kbucket(self):
        """
        Ensures that the lastAccessed field of the affected k-bucket is updated
        appropriately.
        """
        parent_node_id = 'abc'
        r = RoutingTable(parent_node_id)
        # At this point the single k-bucket in the routing table will have a
        # lastAccessed time of 0 (zero). Sanity check.
        self.assertEqual(0, r._buckets[0].last_accessed)
        # Since all keys are in the range of the single k-bucket any key will
        # do for the purposes of testing.
        r.touch_kbucket('xyz')
        self.assertNotEqual(0, r._buckets[0].last_accessed)

########NEW FILE########
__FILENAME__ = test_messages
# -*- coding: utf-8 -*-
"""
A set of sanity checks to ensure that the messages are defined as expected.
"""
from drogulus.net.messages import (Error, Ping, Pong, Store, FindNode, Nodes,
                                   FindValue, Value, to_msgpack, from_msgpack,
                                   make_message)
from drogulus.constants import ERRORS
from drogulus.crypto import construct_key, generate_signature
import unittest
import msgpack
import time
from uuid import uuid4


# Useful throw-away constants for testing purposes.
PRIVATE_KEY = """-----BEGIN RSA PRIVATE KEY-----
MIICXgIBAAKBgQC+n3Au1cbSkjCVsrfnTbmA0SwQLN2RbbDIMHILA1i6wByXkqEa
mnEBvgsOkUUrsEXYtt0vb8Qill4LSs9RqTetSCjGb+oGVTKizfbMbGCKZ8fT64ZZ
gan9TvhItl7DAwbIXcyvQ+b1J7pHaytAZwkSwh+M6WixkMTbFM91fW0mUwIDAQAB
AoGBAJvBENvj5wH1W2dl0ShY9MLRpuxMjHogo3rfQr/G60AkavhaYfKn0MB4tPYh
MuCgtmF+ATqaWytbq9oUNVPnLUqqn5M9N86+Gb6z8ld+AcR2BD8oZ6tQaiEIGzmi
L9AWEZZnyluDSHMXDoVrvDLxPpKW0yPjvQfWN15QF+H79faJAkEA0hgdueFrZf3h
os59ukzNzQy4gjL5ea35azbQt2jTc+lDOu+yjUic2O7Os7oxnSArpujDiOkYgaih
Dny+/bIgLQJBAOhGKjhpafdpgpr/BjRlmUHXLaa+Zrp/S4RtkIEkE9XXkmQjvVZ3
EyN/h0IVNBv45lDK0Qztjic0L1GON62Z8H8CQAcRkqZ3ZCKpWRceNXK4NNBqVibj
SiuC4/psfLc/CqZCueVYvTwtrkFKP6Aiaprrwyw5dqK7nPx3zPtszQxCGv0CQQDK
51BGiz94VAE1qQYgi4g/zdshSD6xODYd7yBGz99L9M77D4V8nPRpFCRyA9fLf7ii
ZyoLYxHFCX80fUoCKvG9AkEAyX5iCi3aoLYd/CvOFYB2fcXzauKrhopS7/NruDk/
LluSlW3qpi1BGDHVTeWWj2sm30NAybTHjNOX7OxEZ1yVwg==
-----END RSA PRIVATE KEY-----"""


PUBLIC_KEY = """-----BEGIN PUBLIC KEY-----
MIGfMA0GCSqGSIb3DQEBAQUAA4GNADCBiQKBgQC+n3Au1cbSkjCVsrfnTbmA0SwQ
LN2RbbDIMHILA1i6wByXkqEamnEBvgsOkUUrsEXYtt0vb8Qill4LSs9RqTetSCjG
b+oGVTKizfbMbGCKZ8fT64ZZgan9TvhItl7DAwbIXcyvQ+b1J7pHaytAZwkSwh+M
6WixkMTbFM91fW0mUwIDAQAB
-----END PUBLIC KEY-----"""


class TestMessages(unittest.TestCase):
    """
    Ensures the message classes are *defined* as expected and the relevant
    fields can be indexed.
    """

    def setUp(self):
        self.uuid = str(uuid4())
        self.node = '9876543210abcd'.decode('hex')

    def test_error(self):
        """
        Expected behaviour of an error message.
        """
        error = Error(self.uuid, self.node, 2, 'This is an error',
                      {'foo': 'bar'}, '0.1')
        self.assertEqual(self.uuid, error.uuid)
        self.assertEqual(self.node, error.node)
        self.assertEqual(2, error.code)
        self.assertEqual('This is an error', error.title)
        self.assertEqual({'foo': 'bar'}, error.details)
        self.assertEqual('0.1', error.version)

    def test_ping(self):
        """
        Expected behaviour of a ping message.
        """
        ping = Ping(self.uuid, self.node, '0.1')
        self.assertEqual(self.uuid, ping.uuid)
        self.assertEqual(self.node, ping.node)
        self.assertEqual('0.1', ping.version)

    def test_pong(self):
        """
        Expected behaviour of a pong message.
        """
        pong = Pong(self.uuid, self.node, '0.1')
        self.assertEqual(self.uuid, pong.uuid)
        self.assertEqual(self.node, pong.node)
        self.assertEqual('0.1', pong.version)

    def test_store(self):
        """
        Expected behaviour of a store message.
        """
        store = Store(self.uuid, self.node, 'abc123', 'value',
                      1350544046.084875, 0.0, '0.1', 'abcdefg', 'name',
                      {'meta': 'value'}, 'sig', '0.1')
        self.assertEqual(self.uuid, store.uuid)
        self.assertEqual(self.node, store.node)
        self.assertEqual('abc123', store.key)
        self.assertEqual('value', store.value)
        self.assertEqual(1350544046.084875, store.timestamp)
        self.assertEqual(0.0, store.expires)
        self.assertEqual('0.1', store.created_with)
        self.assertEqual('abcdefg', store.public_key)
        self.assertEqual('name', store.name)
        self.assertEqual({'meta': 'value'}, store.meta)
        self.assertEqual('sig', store.sig)
        self.assertEqual('0.1', store.version)

    def test_find_node(self):
        """
        Expected behaviour of a findnode message.
        """
        fn = FindNode(self.uuid, self.node, 'key', '0.1')
        self.assertEqual(self.uuid, fn.uuid)
        self.assertEqual(self.node, fn.node)
        self.assertEqual('key', fn.key)
        self.assertEqual('0.1', fn.version)

    def test_nodes(self):
        """
        Expected behaviour of a nodes message.
        """
        nodes = Nodes(self.uuid, self.node,
                     ((self.node, '127.0.0.1', 1908, '0.1')), '0.1')
        self.assertEqual(self.uuid, nodes.uuid)
        self.assertEqual(self.node, nodes.node)
        self.assertEqual(((self.node, '127.0.0.1', 1908, '0.1')), nodes.nodes)
        self.assertEqual('0.1', nodes.version)

    def test_find_value(self):
        """
        Expected behaviour of a findvalue message.
        """
        fv = FindValue(self.uuid, self.node, 'key', '0.1')
        self.assertEqual(self.uuid, fv.uuid)
        self.assertEqual(self.node, fv.node)
        self.assertEqual('key', fv.key)
        self.assertEqual('0.1', fv.version)

    def test_value(self):
        """
        Expected behaviour of a value message.
        """
        val = Value(self.uuid, self.node, 'abc123', 'value', 1350544046.084875,
                    0.0, '0.1', 'abcdefg', 'name', {'meta': 'value'}, 'sig',
                    '0.1')
        self.assertEqual(self.uuid, val.uuid)
        self.assertEqual(self.node, val.node)
        self.assertEqual('abc123', val.key)
        self.assertEqual('value', val.value)
        self.assertEqual(1350544046.084875, val.timestamp)
        self.assertEqual(0.0, val.expires)
        self.assertEqual('0.1', val.created_with)
        self.assertEqual('abcdefg', val.public_key)
        self.assertEqual('name', val.name)
        self.assertEqual({'meta': 'value'}, val.meta)
        self.assertEqual('sig', val.sig)
        self.assertEqual('0.1', val.version)


class TestMessagePackConversion(unittest.TestCase):
    """
    Ensures functions for encoding and decoding messages in to and from
    MessagePack strings to message objects work as expected.
    """

    def setUp(self):
        """
        Gives us some messages to play with.
        """
        self.uuid = str(uuid4())
        self.node = '9876543210abcd'.decode('hex')
        self.value = 1.234
        self.timestamp = time.time()
        self.expires = self.timestamp + 1000
        self.public_key = PUBLIC_KEY
        self.name = 'a_human_readable_key_name'
        self.key = construct_key(self.public_key, self.name)
        self.meta = {
            'mime': 'numeric',
            'description': 'a test value'
        }
        self.version = '0.1'
        self.sig = generate_signature(self.value, self.timestamp, self.expires,
                                      self.name, self.meta, self.version,
                                      PRIVATE_KEY)
        self.message = 'value'
        self.nodes = (('hash1', '127.0.0.1', 1908, '0.1'),
                     ('hash2', '0.0.0.0', 1908, '0.1'))
        self.mock_message = Value(self.uuid, self.node, self.key, self.value,
                                  self.timestamp, self.expires, self.version,
                                  self.public_key, self.name, self.meta,
                                  self.sig, self.version)

    def test_to_msgpack(self):
        """
        Simple good case.
        """
        result = to_msgpack(self.mock_message)
        unpacked = msgpack.unpackb(result)
        for k in ['uuid', 'key', 'value', 'timestamp', 'public_key', 'name',
                  'meta', 'sig', 'version', 'message']:
            self.assertIn(k, unpacked.keys())
            self.assertEqual(unpacked[k], getattr(self, k))

    def test_from_msgpack_error(self):
        """
        Ensures a valid error message is correctly parsed.
        """
        mock_message = msgpack.packb({
            'message': 'error',
            'uuid': self.uuid,
            'node': self.node,
            'code': 1,
            'title': ERRORS[1],
            'details': {'key': 'value'},
            'version': self.version
        })
        result = from_msgpack(mock_message)
        self.assertIsInstance(result, Error)
        self.assertEqual(result.uuid, self.uuid)
        self.assertEqual(result.node, self.node)
        self.assertEqual(result.code, 1)
        self.assertEqual(result.title, ERRORS[1])
        self.assertEqual(result.details, {'key': 'value'})
        self.assertEqual(result.version, self.version)

    def test_from_msgpack_ping(self):
        """
        Ensures a valid ping message is correctly parsed.
        """
        mock_message = msgpack.packb({
            'message': 'ping',
            'uuid': self.uuid,
            'node': self.node,
            'version': self.version
        })
        result = from_msgpack(mock_message)
        self.assertIsInstance(result, Ping)
        self.assertEqual(result.uuid, self.uuid)
        self.assertEqual(result.node, self.node)
        self.assertEqual(result.version, self.version)

    def test_from_msgpack_pong(self):
        """
        Ensures a valid pong message is correctly parsed.
        """
        mock_message = msgpack.packb({
            'message': 'pong',
            'uuid': self.uuid,
            'node': self.node,
            'version': self.version
        })
        result = from_msgpack(mock_message)
        self.assertIsInstance(result, Pong)
        self.assertEqual(result.node, self.node)
        self.assertEqual(result.uuid, self.uuid)
        self.assertEqual(result.version, self.version)

    def test_from_msgpack_store(self):
        """
        Ensures a valid store message is correctly parsed.
        """
        mock_message = msgpack.packb({
            'message': 'store',
            'uuid': self.uuid,
            'node': self.node,
            'key': self.key,
            'value': self.value,
            'timestamp': self.timestamp,
            'expires': self.expires,
            'created_with': self.version,
            'public_key': self.public_key,
            'name': self.name,
            'meta': self.meta,
            'sig': self.sig,
            'version': self.version
        })
        result = from_msgpack(mock_message)
        self.assertIsInstance(result, Store)
        self.assertEqual(result.uuid, self.uuid)
        self.assertEqual(result.node, self.node)
        self.assertEqual(result.key, self.key)
        self.assertEqual(result.value, self.value)
        self.assertEqual(result.timestamp, self.timestamp)
        self.assertEqual(result.expires, self.expires)
        self.assertEqual(result.created_with, self.version)
        self.assertEqual(result.public_key, self.public_key)
        self.assertEqual(result.name, self.name)
        self.assertEqual(result.meta, self.meta)
        self.assertEqual(result.sig, self.sig)
        self.assertEqual(result.version, self.version)

    def test_from_msgpack_findnode(self):
        """
        Ensures a valid findnode message is correctly parsed.
        """
        mock_message = msgpack.packb({
            'message': 'findnode',
            'uuid': self.uuid,
            'node': self.node,
            'key': self.key,
            'version': self.version
        })
        result = from_msgpack(mock_message)
        self.assertIsInstance(result, FindNode)
        self.assertEqual(result.uuid, self.uuid)
        self.assertEqual(result.node, self.node)
        self.assertEqual(result.key, self.key)
        self.assertEqual(result.version, self.version)

    def test_from_msgpack_nodes(self):
        """
        Ensures a valid nodes message is correctly parsed.
        """
        mock_message = msgpack.packb({
            'message': 'nodes',
            'uuid': self.uuid,
            'node': self.node,
            'nodes': self.nodes,
            'version': self.version
        })
        result = from_msgpack(mock_message)
        self.assertIsInstance(result, Nodes)
        self.assertEqual(result.uuid, self.uuid)
        self.assertEqual(result.node, self.node)
        self.assertEqual(result.nodes, self.nodes)
        self.assertEqual(result.version, self.version)

    def test_from_msgpack_findvalue(self):
        """
        Ensures a valid findvalue message is correctly parsed.
        """
        mock_message = msgpack.packb({
            'message': 'findvalue',
            'uuid': self.uuid,
            'node': self.node,
            'key': self.key,
            'version': self.version
        })
        result = from_msgpack(mock_message)
        self.assertIsInstance(result, FindValue)
        self.assertEqual(result.uuid, self.uuid)
        self.assertEqual(result.node, self.node)
        self.assertEqual(result.key, self.key)
        self.assertEqual(result.version, self.version)

    def test_from_msgpack_value(self):
        """
        Ensures a valid value message is correctly parsed.
        """
        mock_message = to_msgpack(self.mock_message)
        result = from_msgpack(mock_message)
        self.assertIsInstance(result, Value)
        self.assertEqual(result.uuid, self.uuid)
        self.assertEqual(result.node, self.node)
        self.assertEqual(result.key, self.key)
        self.assertEqual(result.value, self.value)
        self.assertEqual(result.timestamp, self.timestamp)
        self.assertEqual(result.expires, self.expires)
        self.assertEqual(result.created_with, self.version)
        self.assertEqual(result.public_key, self.public_key)
        self.assertEqual(result.name, self.name)
        self.assertEqual(result.meta, self.meta)
        self.assertEqual(result.sig, self.sig)
        self.assertEqual(result.version, self.version)

    def test_from_msgpack_unknown_request(self):
        """
        Ensures the correct exception is raised if the message is not
        recognised.
        """
        # "pang" is "bang" in Swedish (apparently).
        mock_message = msgpack.packb({
            'message': 'pang',
            'uuid': self.uuid,
            'node': self.node,
            'version': self.version
        })
        with self.assertRaises(ValueError) as cm:
            from_msgpack(mock_message)
        ex = cm.exception
        self.assertEqual(2, ex.args[0])
        self.assertEqual(ERRORS[2], ex.args[1])
        self.assertEqual('pang is not a valid message type.',
                         ex.args[2]['context'])


class TestMakeMessage(unittest.TestCase):
    """
    Ensures that the make_message function performs as expected.
    """

    def test_make_message(self):
        """
        The good case returns an instance of the given class based upon the
        data provided.
        """
        uuid = str(uuid4())
        node = '9876543210abcd'.decode('hex')
        result = make_message(Ping, {'uuid': uuid, 'node': node,
                                     'version': '0.1'})
        self.assertIsInstance(result, Ping)
        self.assertEqual(uuid, result.uuid)
        self.assertEqual(node, result.node)
        self.assertEqual('0.1', result.version)

    def test_make_message_bad_values(self):
        """
        The values to be used to instantiate the class should be valid. If not
        the correct exception is raised.
        """
        with self.assertRaises(ValueError) as cm:
            make_message(Ping, {'uuid': 1, 'node': 2, 'version': 3})
        ex = cm.exception
        self.assertEqual(2, ex.args[0])
        self.assertEqual(ERRORS[2], ex.args[1])
        details = ex.args[2]
        self.assertEqual('Invalid value.', details['uuid'])
        self.assertEqual('Invalid value.', details['node'])
        self.assertEqual('Invalid value.', details['version'])

    def test_make_message_missing_fields(self):
        """
        The correct fields must all exist in the provided data dictionary.
        """
        with self.assertRaises(ValueError) as cm:
            make_message(Ping, {'foo': 1, 'bar': 2})
        ex = cm.exception
        self.assertEqual(2, ex.args[0])
        self.assertEqual(ERRORS[2], ex.args[1])
        details = ex.args[2]
        self.assertEqual('Missing field.', details['uuid'])
        self.assertEqual('Missing field.', details['node'])
        self.assertEqual('Missing field.', details['version'])

########NEW FILE########
__FILENAME__ = test_protocol
# -*- coding: utf-8 -*-
"""
Ensures the low level networking functions of the DHT behave as expected.
"""
from drogulus.version import get_version
from drogulus.constants import ERRORS
from drogulus.net.protocol import DHTFactory
from drogulus.net.messages import Pong, to_msgpack, from_msgpack
from drogulus.dht.node import Node
from twisted.trial import unittest
from twisted.test import proto_helpers
from mock import MagicMock
from uuid import uuid4
import hashlib
import time
import re


class TestDHTProtocol(unittest.TestCase):
    """
    Ensures the DHTProtocol works as expected.
    """

    def setUp(self):
        """
        Following the pattern explained here:

        http://twistedmatrix.com/documents/current/core/howto/trial.html
        """
        hasher = hashlib.sha512()
        hasher.update(str(time.time()))
        self.node_id = hasher.digest()
        self.node = Node(self.node_id)
        self.factory = DHTFactory(self.node)
        self.protocol = self.factory.buildProtocol(('127.0.0.1', 0))
        self.transport = proto_helpers.StringTransport()
        self.protocol.makeConnection(self.transport)

    def _to_netstring(self, raw):
        """
        Converts a raw msgpacked value into a netstring.
        """
        return '%d:%s,' % (len(raw), raw)

    def _from_netstring(self, raw):
        """
        Strips netstring related length and trailing comma from raw string.
        """
        # extract length:content
        length, content = raw.split(':', 1)
        # remove trailing comma
        return content[:-1]

    def test_except_to_error_with_exception_args(self):
        """
        Ensure an exception created by drogulus (that includes meta-data in
        the form of exception args) is correctly transformed into an Error
        message instance.
        """
        uuid = str(uuid4())
        details = {'context': 'A message'}
        ex = ValueError(1, ERRORS[1], details, uuid)
        result = self.protocol.except_to_error(ex)
        self.assertEqual(uuid, result.uuid)
        self.assertEqual(self.node.id, result.node)
        self.assertEqual(1, result.code)
        self.assertEqual(ERRORS[1], result.title)
        self.assertEqual(details, result.details)

    def test_except_to_error_with_regular_exception(self):
        """
        Ensure that a generic Python exception is correctly transformed in to
        an Error message instance.
        """
        ex = ValueError('A generic exception')
        result = self.protocol.except_to_error(ex)
        self.assertEqual(self.node.id, result.node)
        self.assertEqual(3, result.code)
        self.assertEqual(ERRORS[3], result.title)
        self.assertEqual({}, result.details)
        uuidMatch = ('[a-f0-9]{8}-[a-f0-9]{4}-[a-f0-9]{4}-[a-f0-9]{4}-' +
                     '[a-f0-9]{12}')
        self.assertTrue(re.match(uuidMatch, result.uuid))

    def test_except_to_error_with_junk(self):
        """
        Given that this is a function that cannot fail it must be able to cope
        with input that is not an Exception. A sanity check for some defensive
        programming.
        """
        result = self.protocol.except_to_error('foo')
        self.assertEqual(self.node.id, result.node)
        self.assertEqual(3, result.code)
        self.assertEqual(ERRORS[3], result.title)
        self.assertEqual({}, result.details)
        uuidMatch = ('[a-f0-9]{8}-[a-f0-9]{4}-[a-f0-9]{4}-[a-f0-9]{4}-' +
                     '[a-f0-9]{12}')
        self.assertTrue(re.match(uuidMatch, result.uuid))

    def test_string_received_except_to_error(self):
        """
        Sanity test to check error handling works as expected.
        """
        # Mock
        self.transport.loseConnection = MagicMock()
        # Send bad message
        self.protocol.dataReceived('1:a,')
        # Check we receive the expected error in return
        raw_response = self.transport.value()
        msgpack_response = self._from_netstring(raw_response)
        err = from_msgpack(msgpack_response)
        self.assertEqual(3, err.code)
        self.assertEqual(ERRORS[3], err.title)
        self.assertEqual({}, err.details)
        uuidMatch = ('[a-f0-9]{8}-[a-f0-9]{4}-[a-f0-9]{4}-[a-f0-9]{4}-' +
                     '[a-f0-9]{12}')
        self.assertTrue(re.match(uuidMatch, err.uuid))
        # Ensure the loseConnection method was also called.
        self.transport.loseConnection.assert_called_once_with()

    def test_string_received_good_message(self):
        """
        Ensures the correct method on the local node object is called with the
        expected arguments.
        """
        # Mock
        self.node.message_received = MagicMock(return_value=True)
        # Create a simple Ping message
        uuid = str(uuid4())
        version = get_version()
        msg = Pong(uuid, self.node_id, version)
        # Receive it...
        raw = to_msgpack(msg)
        self.protocol.stringReceived(raw)
        # Check it results in a call to the node's message_received method.
        self.node.message_received.assert_called_once_with(msg, self.protocol)

    def test_send_message(self):
        """
        Ensure the message passed into the protocol is turned into a netstring
        version of a msgpacked message.
        """
        # Create a simple Ping message
        uuid = str(uuid4())
        version = get_version()
        msg = Pong(uuid, self.node_id, version)
        # Send it down the wire...
        self.protocol.sendMessage(msg)
        # Check it's as expected.
        expected = self._to_netstring(to_msgpack(msg))
        actual = self.transport.value()
        self.assertEqual(expected, actual)

    def test_send_message_no_lose_connection(self):
        """
        Ensures that a the default for sending a message does NOT result in
        the connection being lost.
        """
        # Mock
        self.transport.loseConnection = MagicMock()
        # Create a simple Ping message
        uuid = str(uuid4())
        version = get_version()
        msg = Pong(uuid, self.node_id, version)
        # Send it down the wire...
        self.protocol.sendMessage(msg)
        # Check it's as expected.
        expected = self._to_netstring(to_msgpack(msg))
        actual = self.transport.value()
        self.assertEqual(expected, actual)
        # Ensure the loseConnection method was not called.
        self.assertEqual(0, len(self.transport.loseConnection.mock_calls))

    def test_send_message_with_lose_connection(self):
        """
        This check ensures the loseConnection method has been called on the
        protocol's transport when the appropriate flag has been passed in.
        """
        # Mock
        self.transport.loseConnection = MagicMock()
        # Create a simple Ping message
        uuid = str(uuid4())
        version = get_version()
        msg = Pong(uuid, self.node_id, version)
        # Send it down the wire with the loseConnection flag set to True
        self.protocol.sendMessage(msg, True)
        # Check it's as expected.
        expected = self._to_netstring(to_msgpack(msg))
        actual = self.transport.value()
        self.assertEqual(expected, actual)
        # Ensure the loseConnection method was also called.
        self.transport.loseConnection.assert_called_once_with()

########NEW FILE########
__FILENAME__ = test_validators
# -*- coding: utf-8 -*-
"""
A set of sanity checks to ensure that function concerning message validation
work correctly.
"""
from drogulus.net.validators import (validate_timestamp, validate_code,
                                     validate_string, validate_meta,
                                     validate_node, validate_nodes,
                                     validate_value, VALIDATORS)
import unittest
import time


class TestValidators(unittest.TestCase):
    """
    Ensures the validator functions work as expected
    """

    def test_validate_timestamp(self):
        """
        The good case passes.
        """
        self.assertTrue(validate_timestamp(time.time()))

    def test_validate_timestamp_wrong_type(self):
        """
        Timestamps are floating point numbers.
        """
        self.assertFalse(validate_timestamp(123))

    def test_validate_code(self):
        """
        The good error code passes.
        """
        self.assertTrue(validate_code(1))

    def test_validate_code_unknown(self):
        """
        Using an unknown error code number fails.
        """
        self.assertFalse(validate_code(0))

    def test_validate_code_wrong_type(self):
        """
        Error codes are integers.
        """
        self.assertFalse(validate_code('1'))

    def test_validate_string_str(self):
        """
        Regular Python strings pass.
        """
        self.assertTrue(validate_string('hello'))

    def test_validate_string_unicode(self):
        """
        Unicode strings pass.
        """
        self.assertTrue(validate_string(u'hello'))

    def test_validate_string_wrong_type(self):
        """
        It fails if the value is not a string.
        """
        self.assertFalse(validate_string(1))

    def test_validate_meta(self):
        """
        A dictionary containing key/value strings passes.
        """
        self.assertTrue(validate_meta({'foo': 'bar'}))

    def test_validate_meta_wrong_type(self):
        """
        If the meta-data isn't a dictionary then fail.
        """
        self.assertFalse(validate_meta(('foo', 'bar')))

    def test_validate_meta_bad_key(self):
        """
        All keys must be strings.
        """
        self.assertFalse(validate_meta({1: 'foo'}))

    def test_validate_meta_bad_value(self):
        """
        All values must be strings.
        """
        self.assertFalse(validate_meta({'foo': 1}))

    def test_validate_node(self):
        """
        A tuple containing id and IP address strings, a port integer and
        version string passes.
        """
        self.assertTrue(validate_node(('id', '127.0.0.1', 1908, '0.1')))

    def test_validate_node_wrong_type(self):
        """
        The node should be expressed within a tuple.
        """
        self.assertFalse(validate_node(['id', '127.0.0.1', 1908, '0.1']))

    def test_validate_node_bad_id(self):
        """
        The node's id should be a string.
        """
        self.assertFalse(validate_node((123, '127.0.0.1', 1908, '0.1')))

    def test_validate_node_bad_ip_address(self):
        """
        The IP address should be a string.
        """
        self.assertFalse(validate_node(('id', [127, 0, 0, 1], 1908, '0.1')))

    def test_validate_node_bad_port(self):
        """
        The port should be an integer.
        """
        self.assertFalse(validate_node(('id', '127.0.0.1', '1908', '0.1')))

    def test_validate_node_invalid_port_too_low(self):
        """
        The port should be a positive integer
        """
        self.assertTrue(validate_node(('id', '127.0.0.1', 0, '0.1')))
        self.assertFalse(validate_node(('id', '127.0.0.1', -1, '0.1')))

    def test_validate_node_invalid_port_too_high(self):
        """
        The port should be <= 49151.
        """
        self.assertTrue(validate_node(('id', '127.0.0.1', 49151, '0.1')))
        self.assertFalse(validate_node(('id', '127.0.0.1', 49152, '0.1')))

    def test_validate_node_invalid_version(self):
        """
        The version number should be a string.
        """
        self.assertFalse(validate_node(('id', '127.0.0.1', 1908, 0.1)))

    def test_validate_nodes(self):
        """
        A tuple of zero or more nodes is valid.
        """
        self.assertTrue(validate_nodes((('id', '127.0.0.1', 1908, '0.1'),)))

    def test_validate_nodes_wrong_type(self):
        """
        Nodes can only be expressed in tuples.
        """
        self.assertFalse(validate_nodes([('id', '127.0.0.1', 1908, '0.1')]))

    def test_validate_nodes_bad_node(self):
        """
        A tuple of nodes is only valid is the nodes contained therein are also
        valid.
        """
        self.assertFalse(validate_nodes(((123, [127, 0, 0, 1], 1908, '0.1'))))

    def test_validate_value(self):
        """
        Checks the validity of values stored in the DHT. Currently always
        returns True but in the future may place limits on value sizes.
        """
        self.assertTrue(validate_value('foo'))

    def test_validate_VALIDATORS(self):
        """
        Ensures that the VALIDATORS dict maps the field names to validator
        functions correctly.
        """
        self.assertEqual(16, len(VALIDATORS))
        self.assertEqual(VALIDATORS['uuid'], validate_string)
        self.assertEqual(VALIDATORS['node'], validate_string)
        self.assertEqual(VALIDATORS['code'], validate_code)
        self.assertEqual(VALIDATORS['title'], validate_string)
        self.assertEqual(VALIDATORS['details'], validate_meta)
        self.assertEqual(VALIDATORS['version'], validate_string)
        self.assertEqual(VALIDATORS['key'], validate_string)
        self.assertEqual(VALIDATORS['value'], validate_value)
        self.assertEqual(VALIDATORS['timestamp'], validate_timestamp)
        self.assertEqual(VALIDATORS['expires'], validate_timestamp)
        self.assertEqual(VALIDATORS['created_with'], validate_string)
        self.assertEqual(VALIDATORS['public_key'], validate_string)
        self.assertEqual(VALIDATORS['name'], validate_string)
        self.assertEqual(VALIDATORS['meta'], validate_meta)
        self.assertEqual(VALIDATORS['sig'], validate_string)
        self.assertEqual(VALIDATORS['nodes'], validate_nodes)

########NEW FILE########
__FILENAME__ = test_constants
# -*- coding: utf-8 -*-
"""
Ensures the DHT implementation has the required constants defined
"""
from drogulus import constants
import unittest


class TestConstants(unittest.TestCase):
    """
    Ensures the drogulus.dht.constants module contains the required / expected
    declarations.
    """

    def test_ALPHA(self):
        """
        The alpha number represents the degree of parallelism in network calls.
        """
        self.assertIsInstance(constants.ALPHA, int,
                              "constants.ALPHA must be an integer.")

    def test_K(self):
        """
        The k number (so named from the original Kademlia paper) defines the
        maximum number of contacts stored in a k-bucket. This should be an even
        number.
        """
        self.assertIsInstance(constants.K, int,
                              "constants.K must be an integer.")
        self.assertEqual(0, constants.K % 2)

    def test_LOOKUP_TIMEOUT(self):
        """
        The lookup timeout defines the default maximum amount of time a node
        lookup is allowed to take.
        """
        self.assertIsInstance(constants.LOOKUP_TIMEOUT, int,
                              "constants.LOOKUP_TIMEOUT must be an integer.")

    def test_RPC_TIMEOUT(self):
        """
        The rpc timeout number defines the timeout for network operations in
        seconds.
        """
        self.assertIsInstance(constants.RPC_TIMEOUT, int,
                              "constants.RPC_TIMEOUT must be an integer.")

    def test_REFRESH_TIMEOUT(self):
        """
        The refresh timeout defines how long to wait (in seconds) before an
        unused k-bucket is refreshed.
        """
        self.assertIsInstance(constants.REFRESH_TIMEOUT, int,
                              "constants.REFRESH_TIMEOUT must be an integer.")

    def test_REPLICATE_INTERVAL(self):
        """
        The replication interval defines how long to wait (in seconds) before a
        node replicates (republishes / refreshes) any data it stores.
        """
        self.assertIsInstance(constants.REPLICATE_INTERVAL, int,
                              "constants.REPLICATE_INTERVAL must be an " +
                              "integer.")

    def test_REFRESH_INTERVAL(self):
        """
        The refresh interval defines how long to wait (in seconds) before a
        node checks whether any buckets need refreshing or data needs
        republishing.
        """
        self.assertIsInstance(constants.REFRESH_INTERVAL, int,
                              "constants.REFRESH_INTERVAL must be an integer.")

    def test_ALLOWED_RPC_FAILS(self):
        """
        The allowed number of rpc failures defines the number of failed
        communication attempts are allowed to a peer before it is removed from
        the routing table.
        """
        self.assertIsInstance(constants.ALLOWED_RPC_FAILS, int,
                              "constants.ALLOWED_RPC_FAILS must be an " +
                              "integer.")

    def test_DUPLICATION_COUNT(self):
        """
        The duplication count defines the number of nodes to attempt to use to
        initially store a value in the DHT.
        """
        self.assertIsInstance(constants.DUPLICATION_COUNT, int,
                              "constants.DUPLICATION_COUNT must be an " +
                              "integer.")

    def test_EXPIRY_DURATION(self):
        """
        The expiry duration is the number of seconds that added to a value's
        creation time in order to work out its expiry timestamp.
        """
        self.assertIsInstance(constants.EXPIRY_DURATION, int,
                              "constants.EXPIRY_DURATION must be an integer.")

    def test_ERRORS(self):
        """
        The ERRORS dictionary defines the error codes (keys) and associated
        messages (values) that are used in error messages sent between nodes in
        the DHT.
        """
        self.assertIsInstance(constants.ERRORS, dict,
                              "constants.ERRORS must be a dictionary.")

########NEW FILE########
__FILENAME__ = test_crypto
# -*- coding: utf-8 -*-
"""
A set of sanity checks to ensure that the messages are defined as expected.
"""
from drogulus.crypto import (generate_signature, validate_signature,
                             validate_message, construct_hash,
                             construct_key)
from drogulus.net.messages import Value
import unittest
import hashlib
import msgpack
import time


# Useful throw-away constants for testing purposes.
PRIVATE_KEY = """-----BEGIN RSA PRIVATE KEY-----
MIICXgIBAAKBgQC+n3Au1cbSkjCVsrfnTbmA0SwQLN2RbbDIMHILA1i6wByXkqEa
mnEBvgsOkUUrsEXYtt0vb8Qill4LSs9RqTetSCjGb+oGVTKizfbMbGCKZ8fT64ZZ
gan9TvhItl7DAwbIXcyvQ+b1J7pHaytAZwkSwh+M6WixkMTbFM91fW0mUwIDAQAB
AoGBAJvBENvj5wH1W2dl0ShY9MLRpuxMjHogo3rfQr/G60AkavhaYfKn0MB4tPYh
MuCgtmF+ATqaWytbq9oUNVPnLUqqn5M9N86+Gb6z8ld+AcR2BD8oZ6tQaiEIGzmi
L9AWEZZnyluDSHMXDoVrvDLxPpKW0yPjvQfWN15QF+H79faJAkEA0hgdueFrZf3h
os59ukzNzQy4gjL5ea35azbQt2jTc+lDOu+yjUic2O7Os7oxnSArpujDiOkYgaih
Dny+/bIgLQJBAOhGKjhpafdpgpr/BjRlmUHXLaa+Zrp/S4RtkIEkE9XXkmQjvVZ3
EyN/h0IVNBv45lDK0Qztjic0L1GON62Z8H8CQAcRkqZ3ZCKpWRceNXK4NNBqVibj
SiuC4/psfLc/CqZCueVYvTwtrkFKP6Aiaprrwyw5dqK7nPx3zPtszQxCGv0CQQDK
51BGiz94VAE1qQYgi4g/zdshSD6xODYd7yBGz99L9M77D4V8nPRpFCRyA9fLf7ii
ZyoLYxHFCX80fUoCKvG9AkEAyX5iCi3aoLYd/CvOFYB2fcXzauKrhopS7/NruDk/
LluSlW3qpi1BGDHVTeWWj2sm30NAybTHjNOX7OxEZ1yVwg==
-----END RSA PRIVATE KEY-----"""


PUBLIC_KEY = """-----BEGIN PUBLIC KEY-----
MIGfMA0GCSqGSIb3DQEBAQUAA4GNADCBiQKBgQC+n3Au1cbSkjCVsrfnTbmA0SwQ
LN2RbbDIMHILA1i6wByXkqEamnEBvgsOkUUrsEXYtt0vb8Qill4LSs9RqTetSCjG
b+oGVTKizfbMbGCKZ8fT64ZZgan9TvhItl7DAwbIXcyvQ+b1J7pHaytAZwkSwh+M
6WixkMTbFM91fW0mUwIDAQAB
-----END PUBLIC KEY-----"""


BAD_PUBLIC_KEY = """-----BEGIN PUBLIC KEY-----
HELLOA0GCSqGSIb3DQEBAQUAA4GNADCBiQKBgQC+n3Au1cbSkjCVsrfnTbmA0SwQ
LN2RbbDIMHILA1i6wByXkqEamnEBvgsOkUUrsEXYtt0vb8Qill4LSs9RqTetSCjG
b+oGVTKizfbMbGCKZ8fT64ZZgan9TvhItl7DAwbIXcyvQ+b1J7pHaytAZwkSwh+M
6WixkMTbFM91fW0mUwIDAQAB
-----END PUBLIC KEY-----"""


ALT_PUBLIC_KEY = """-----BEGIN PUBLIC KEY-----
MIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEAxec+GS3c3qzE4WgKoQMJ
GgBJG/0oOdRb6UKnqJ6p3/vb9iw//OqMbLYCYKtU4JfaTritjwNd0bWhMa4Q09Jc
z2fL9uG1j/d66iasGWooEpBICzBPiao7rQYtxbHzoUV+a1jzv7HcEQrdBYbGEbSc
A1o8gbMAj4oMh+neJFPxHKLxMHMPEW+lmPvFGcUIVUOyvZl0mAn5PSJnXOenB9Zg
tG/zEXoI+YfPpSQ6CgAFU1JFRMCXEAvr/lSkSKN6uGeu2bZDWT597Qddc+DI+XFW
39pEBxh2H59WNiK1f/DRBvgGUgBrCZAxyTwrjE9fi/1z0lFRw9pH7V6SaJtK1KWh
WQIDAQAB
-----END PUBLIC KEY-----"""


class TestMessageCryptoFunctions(unittest.TestCase):
    """
    Ensures that functions for signing and validating messages work as
    expected.
    """

    def setUp(self):
        """
        Set some values used in all tests.
        """
        self.signature = ('\x80 \xf6\x155\x93Z\xdf1t*\xc6\xc8b\x9b~\xc0\xa6' +
                          '\xf8\xa7\xc0\xd5\x91\xa2Q\xd7\\\xd1\x1a\x0eX' +
                          '\x855>\xc4\xa3\xa1l\xe26\x9d\x94\x9f\x92\t\xf8' +
                          '\x8f\xe6iblp\x84}\x0cc(\xb7c\xba\x97J\x87u\x9f' +
                          '\xd6\x1a]A\x870\x1df\xe8i\xe8\xbe\xf2\xc6\x8f' +
                          '\xd0\x8f\xd18\xb8\\\xbc\x01\x1a\x1fP\xd6I\x06' +
                          '\xf3K\xb1\x1e@\xc4ma61\xd4\x12\xf4!\x9dm3\x01n' +
                          '\x17\xbcr\xe0\xf4Y-\xc7=\x87\xc4Xv\x84\xfa')
        self.value = 'value'
        self.timestamp = 1350544046.084875
        self.expires = 1352221970.14242
        self.name = 'name'
        self.meta = {'meta': 'value'}
        self.version = '0.1'
        self.key = construct_key(PUBLIC_KEY, self.name)

    def test_generate_signature(self):
        """
        Ensures that the given values result in the expected signature
        given a certain private key and said signature can be validated with
        the related public key.
        """
        expected = self.signature
        actual = generate_signature(self.value, self.timestamp, self.expires,
                                    self.name, self.meta, self.version,
                                    PRIVATE_KEY)
        self.assertEqual(expected, actual)
        # Check the resulting signature can be validated with the public key
        check = validate_signature(self.value, self.timestamp, self.expires,
                                   self.name, self.meta, self.version,
                                   expected, PUBLIC_KEY)
        self.assertEqual(True, check)

    def test_validate_signature(self):
        """
        Ensures that given some values and an associated valid signature the
        validate_signature returns True for the correct public key.
        """
        check = validate_signature(self.value, self.timestamp, self.expires,
                                   self.name, self.meta, self.version,
                                   self.signature, PUBLIC_KEY)
        self.assertEqual(True, check)

    def test_validate_signature_bad_sig(self):
        """
        Ensures that an invalid signature results in a False.
        """
        signature = 'helloworld'
        check = validate_signature(self.value, self.timestamp, self.expires,
                                   self.name, self.meta, self.version,
                                   signature, PUBLIC_KEY)
        self.assertEqual(False, check)

    def test_validate_signature_bad_public_key(self):
        """
        Ensures that given a valid signature but wrong public key, validation
        results in False.
        """
        check = validate_signature(self.value, self.timestamp, self.expires,
                                   self.name, self.meta, self.version,
                                   self.signature, BAD_PUBLIC_KEY)
        self.assertEqual(False, check)

    def test_validate_signature_wrong_public_key(self):
        """
        Ensures that given a valid signature but wrong public key, validation
        results in False.
        """
        check = validate_signature(self.value, self.timestamp, self.expires,
                                   self.name, self.meta, self.version,
                                   self.signature, ALT_PUBLIC_KEY)
        self.assertEqual(False, check)

    def test_validate_message_good(self):
        """
        Ensures the validate_message function returns True for a valid message.
        """
        val = Value(1, 1, self.key, self.value, self.timestamp, self.expires,
                    self.version, PUBLIC_KEY, self.name, self.meta,
                    self.signature, self.version)
        expected = (True, None)
        actual = validate_message(val)
        self.assertEqual(expected, actual)

    def test_validate_message_wrong_value(self):
        """
        Ensures the validate_message function returns False if the message's
        value field has been altered.
        """
        val = Value(1, 1, self.key, 'bad_value', self.timestamp, self.expires,
                    self.version, PUBLIC_KEY, self.name, self.meta,
                    self.signature, self.version)
        expected = (False, 6)
        actual = validate_message(val)
        self.assertEqual(expected, actual)

    def test_validate_message_wrong_timestamp(self):
        """
        Ensures the validate_message function returns False if the message's
        timestamp field has been altered.
        """
        val = Value(1, 1, self.key, self.value, 1350544046.084876,
                    self.expires, self.version, PUBLIC_KEY, self.name,
                    self.meta, self.signature, self.version)
        expected = (False, 6)
        actual = validate_message(val)
        self.assertEqual(expected, actual)

    def test_validate_message_wrong_expires(self):
        """
        Ensures the validate_message function returns False if the message's
        expires field has been altered.
        """
        val = Value(1, 1, self.key, self.value, self.timestamp, 0.0,
                    self.version, PUBLIC_KEY, self.name, self.meta,
                    self.signature, self.version)
        expected = (False, 6)
        actual = validate_message(val)
        self.assertEqual(expected, actual)

    def test_validate_message_wrong_created_with(self):
        """
        Ensures the validate_message function returns False if the message's
        created_with field has been altered.
        """
        val = Value(1, 1, self.key, self.value, self.timestamp, self.expires,
                    '1.1.foo', PUBLIC_KEY, self.name, self.meta,
                    self.signature, self.version)
        expected = (False, 6)
        actual = validate_message(val)
        self.assertEqual(expected, actual)

    def test_validate_message_wrong_name(self):
        """
        Ensures the validate_message function returns False if the message's
        name field has been altered.
        """
        val = Value(1, 1, self.key, self.value, self.timestamp, self.expires,
                    self.version, PUBLIC_KEY, 'bad_name', self.meta,
                    self.signature, self.version)
        expected = (False, 6)
        actual = validate_message(val)
        self.assertEqual(expected, actual)

    def test_validate_message_wrong_meta(self):
        """
        Ensures the validate_message function returns False if the message's
        meta field has been altered.
        """
        val = Value(1, 1, self.key, self.value, self.timestamp, self.expires,
                    self.version, PUBLIC_KEY, self.name,
                    {'bad_meta': 'value'}, self.signature, self.version)
        expected = (False, 6)
        actual = validate_message(val)
        self.assertEqual(expected, actual)

    def test_validate_message_bad_public_key(self):
        """
        Ensure the correct result is returned if the message is invalid
        because of a bad public key.
        """
        val = Value(1, 1, self.key, self.value, self.timestamp, self.expires,
                    self.version, ALT_PUBLIC_KEY, self.name, self.meta,
                    self.signature, self.version)
        expected = (False, 6)
        actual = validate_message(val)
        self.assertEqual(expected, actual)

    def test_validate_message_bad_sig(self):
        """
        Ensure the correct result is returned if the message is invalid
        because of a bad signature.
        """
        bad_signature = ('\x1c\x10s\x1b\x83@r\x11\x83*2\xa1l\x0f\xba*\xd7C' +
                         '\xd4\xa7\x07\xe3\x90\xcc\xc4\x16\xe9 \xadg\x03\xbf' +
                         '\x9c\\\xe2\xfe\x88\xdb\\=,-\xd1/\xa9I2\xc2S\xe7' +
                         '\x07c\xf9X%\x1c\x939\xe6\xa8\x10_\xf3\xeeRlj\xc5i~' +
                         '\x94\xcd\xbd\xb24ujq\xa9Nw\xd0\xad\xa7\xde_\x9cpxj' +
                         '\xdd\x8a\xe8\xfd\xaf\xcbRn\xb7C\xb1q\x13c\xc9' +
                         '\x89@w\xac\xc4\xf8\x87\x9ct\x1a\xa6')
        val = Value(1, 1, self.key, self.value, self.timestamp, self.expires,
                    self.version, PUBLIC_KEY, self.name, self.meta,
                    bad_signature, self.version)
        expected = (False, 6)
        actual = validate_message(val)
        self.assertEqual(expected, actual)

    def test_validate_message_bad_key_from_public_key(self):
        """
        Ensure the correct result is returned if the message is invalid
        because of an incorrect 'key' value with wrong public key
        """
        key = construct_key(ALT_PUBLIC_KEY, 'name')
        val = Value(1, 1, key, self.value, self.timestamp, self.expires,
                    self.version, PUBLIC_KEY, self.name, self.meta,
                    self.signature, self.version)
        expected = (False, 7)
        actual = validate_message(val)
        self.assertEqual(expected, actual)

    def test_validate_message_bad_key_from_name(self):
        """
        Ensure the correct result is returned if the message is invalid
        because of an incorrect 'key' value with wrong name.
        """
        key = construct_key(PUBLIC_KEY, 'wrong_name')
        val = Value(1, 1, key, self.value, self.timestamp, self.expires,
                    self.version, PUBLIC_KEY, self.name, self.meta,
                    self.signature, self.version)
        expected = (False, 7)
        actual = validate_message(val)
        self.assertEqual(expected, actual)

    def test_construct_hash(self):
        """
        Ensures that the hash is correctly generated.
        """
        value = 'foo'
        timestamp = time.time()
        expires = timestamp + 1000
        name = 'bar'
        meta = {'baz': 'qux'}
        created_with = '0.0.0.alpha.0'
        hashes = []
        for item in (value, timestamp, expires, name, meta, created_with):
            packed = msgpack.packb(item)
            hasher = hashlib.sha512()
            hasher.update(packed)
            hashes.append(hasher.digest())
        compound_hashes = ''.join(hashes)
        hasher = hashlib.sha512()
        hasher.update(compound_hashes)
        expected = hasher.digest()
        actual = construct_hash(value, timestamp, expires, name, meta,
                                created_with)
        self.assertEqual(expected, actual.digest())

    def test_construct_key(self):
        """
        Ensures that a DHT key is constructed correctly given correct inputs.
        """
        name = 'foo/bar.baz'
        pk_hasher = hashlib.sha512()
        pk_hasher.update(PUBLIC_KEY)
        pk_hash = pk_hasher.digest()
        name_hasher = hashlib.sha512()
        name_hasher.update(name)
        name_hash = name_hasher.digest()
        hasher = hashlib.sha512()
        hasher.update(pk_hash + name_hash)
        expected = hasher.digest()
        actual = construct_key(PUBLIC_KEY, name)
        self.assertEqual(expected, actual)

    def test_construct_key_empty_name(self):
        """
        Ensures that a DHT key is constructed given only the public key.
        """
        pk_hasher = hashlib.sha512()
        pk_hasher.update(PUBLIC_KEY)
        expected = pk_hasher.digest()
        actual = construct_key(PUBLIC_KEY)
        self.assertEqual(expected, actual)

########NEW FILE########
__FILENAME__ = test_node
# -*- coding: utf-8 -*-
"""
Tests for the core Drogulus class
"""
from drogulus.node import Drogulus
import unittest


class TestDrogulus(unittest.TestCase):
    """
    Ensures the core Drogulus class works as expected.
    """

    def __init__(self):
        self.drogulus = Drogulus()

########NEW FILE########
__FILENAME__ = test_utils
# -*- coding: utf-8 -*-
"""
Ensures the generic functions used in various places within the DHT
implementation work as expected.
"""
from drogulus.utils import long_to_hex, hex_to_long, distance, sort_contacts
from drogulus.dht.contact import Contact
from drogulus.version import get_version
from drogulus import constants
import unittest


class TestUtils(unittest.TestCase):
    """
    Ensures the generic utility functions work as expected.
    """

    def setUp(self):
        """
        Common vars.
        """
        self.version = get_version()

    def test_long_to_hex(self):
        """
        Ensure a long number produces the correct result.
        """
        raw = 123456789L
        result = long_to_hex(raw)
        self.assertEqual(raw, long(result.encode('hex'), 16))

    def test_hex_to_long(self):
        """
        Ensure a valid hex value produces the correct result.
        """
        raw = 'abcdef0123456789'
        result = hex_to_long(raw)
        self.assertEqual(raw, long_to_hex(result))

    def test_distance(self):
        """
        Sanity check to ensure the XOR'd values return the correct distance.
        """
        key1 = 'abc'
        key2 = 'xyz'
        expected = 1645337L
        actual = distance(key1, key2)
        self.assertEqual(expected, actual)

    def test_sort_contacts(self):
        """
        Ensures that the sort_contacts function returns the list ordered in
        such a way that the contacts closest to the target key are at the head
        of the list.
        """
        contacts = []
        for i in range(512):
            contact = Contact(2 ** i, "192.168.0.%d" % i, 9999, self.version,
                              0)
            contacts.append(contact)
        target_key = long_to_hex(2 ** 256)
        result = sort_contacts(contacts, target_key)

        # Ensure results are in the correct order.
        def key(node):
            return distance(node.id, target_key)
        sorted_nodes = sorted(result, key=key)
        self.assertEqual(sorted_nodes, result)
        # Ensure the order is from lowest to highest in terms of distance
        distances = [distance(x.id, target_key) for x in result]
        self.assertEqual(sorted(distances), distances)

    def test_sort_contacts_no_longer_than_k(self):
        """
        Ensure that no more than constants.K contacts are returned from the
        sort_contacts function despite a longer list being passed in.
        """
        contacts = []
        for i in range(512):
            contact = Contact(2 ** i, "192.168.0.%d" % i, 9999, self.version,
                              0)
            contacts.append(contact)
        target_key = long_to_hex(2 ** 256)
        result = sort_contacts(contacts, target_key)
        self.assertEqual(constants.K, len(result))

########NEW FILE########
__FILENAME__ = test_version
# -*- coding: utf-8 -*-
"""
A rather silly test but added all the same for completeness and to check the
initial test suite works as expected.
"""
from drogulus.version import VERSION, get_version
import unittest


class TestVersion(unittest.TestCase):
    """
    Ensures the drogulus.version module works as expected.
    """

    def test_VERSION(self):
        """
        Ensures the VERSION is expressed correctly.
        """
        self.assertEqual(tuple, type(VERSION))
        self.assertTrue(isinstance(VERSION[0], int),
                        "VERSION's MAJOR element must be an integer")
        self.assertTrue(isinstance(VERSION[1], int),
                        "VERSION's MINOR element must be an integer")
        self.assertTrue(isinstance(VERSION[2], int),
                        "VERSION's RELEASE element must be an integer")
        self.assertTrue(isinstance(VERSION[3], str),
                        "VERSION's STATUS element must be an string")
        self.assertTrue(VERSION[3] in ('alpha', 'beta', 'final'),
                        "VERSION's STATUS element must be either 'alpha', " +
                        "'beta' or 'final' (currently set to %s)" % VERSION[3])
        self.assertTrue(isinstance(VERSION[4], int),
                        "VERSION's VERSION element must be an integer")

    def test_get_version(self):
        """
        Ensures the get_version function returns a dot separated expression of
        the VERSION.
        """
        expected = '.'.join([str(i) for i in VERSION])
        actual = get_version()
        self.assertEqual(expected, actual)

########NEW FILE########
__FILENAME__ = build
#!/usr/bin/env python
"""
Uses Jinja2 to generate the static drogul.us website.
"""
import os
import sys
from jinja2 import Environment, FileSystemLoader

path = os.path.abspath(os.path.dirname(sys.argv[0]))

env = Environment(loader=FileSystemLoader(os.path.join(path, 'templates')))

pages = ['code', 'contact', 'why', 'what', 'how', 'index']

home = []
rss_list = []
article_list = []

for page in pages:
    filename = page + '.html'
    template = env.get_template(filename)
    outfile = open(os.path.join(path, 'site', filename), 'wb')
    x = template.render()
    outfile.write(x)
    outfile.close()

########NEW FILE########
