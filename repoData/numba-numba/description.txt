This directory contains python script for benchmarking the performance of
numba.

Running the benchmark
-----------------------

    python runall.py


Adding new bencharmk
---------------------

The "runall.py" will discover scripts if name prefix "bm_".  Each benchmark
script should contains two no-argument functions: "python_main" and
"numba_main".  They represent the entry point for the benchmark for python
code and numba code, respectively.  The timing is produced by `numba.utils
.benchmark`.  The best time is reported and it is normalized against the
python timing.



Extensible type objects for Python
==================================

Often Python extensions needs to communicate things on the ABI level
about PyObjects. In essence, one would like more slots in PyTypeObject
for a custom purpose (dictionary lookups would be too slow).
This tiny library implements a metaclass that can be used for this.

SEP 200 contains more background and API documentation:

https://github.com/numfocus/sep/blob/master/sep200.rst

Contents:

 * ``include/extensibletype.h`` should be included by any library
   that wants to implement SEP 200

 * ``demo/`` contains (crufty) proof-of-concept and benchmarking code


% Feeding the Fire 
% Blaze Development ( 3 Months In )
% Continuum Analytics 

# State of the Blaze

![](barnraising.jpg)

# Backend

The Backend Journey

- C!
- Numba!
- Stack VM!
- Register VM!
- Forth!
- Code Generation!
- Numba again!
- llvmpy!
- MLVM!
- Stack VM again!
- Register VM again!
- Interpreter!
- Code Generation again!
- **Runtime**
    - Dispatch to all the things! ( but mostly Numba )

# Vision

* Blaze is 
    * a generalization of NumPy
    * a datashape description language
    * a generalized notion of data access
    * a way to view data stores as arrays and tables

![](numpy_plus.png)

# 

```python
from blaze import Array, dshape
ds = dshape('2, 2, int')

a = Array([1,2,3,4], ds)
```

```python
>>> a
Array
  datashape := 2 2 int64
  values    := [CArray(ptr=36111200)]
  metadata  := [manifest, array_like, chunked]
  layout    := Chunked(dim=0)

[[1, 2],
 [3, 4]]
```

# End-User Perspectives 

Blaze is built around separation of concerns.

* Domain experts
    - Richer structure to express high level ideas.
* Algorithm writers 
    - More information ( type, shape, layout ) to do clever optimizations.
* Researchers
    - A platform in which to explore data and task
      parallelism.


Zen of Blaze
------------

* Express more logic at a high level. ( More Python, Less C )
* Better knowledge informs better code generation and execution.
* Don't copy data when we can push code to data.

# Blaze Source Tree

```
git clone git@github.com:ContinuumIO/blaze.git
```

```
blaze/
    carray/
    datashape/
    dist/
    engine/
    expr/
    include/
    layouts/
    persistence/
    rosetta/
    rts/
    samples/
    sources/
    stratego/

    byteproto.py
    byteprovider.py
    datadescriptor.py
    idx.py
    lib.py
    plan.py
    printer.py
    slicealgebra.py
    table.py
```

# Chunked Arrays

* CArray is the beating heart of Blaze. It is the canonical storage
backend when the user has no preferences on local storage.

* No distinction between storage:
    * Storage on disk.
    * Storage on memory

#

```python
>>> from blaze.carray import carray
>>> a = carray(xrange(10000))
carray((10000,), int64)
    nbytes: 256; cbytes: 8.00 KB; ratio: 0.03
    cparams := _cparams(clevel=5, shuffle=True)
[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24
 25 26 27 28 29 30 31 ... ]
```

# Modifications

Modifications ( i.e. hacks ) to CArray.

```python
>>> print a.nchunks
2

# Lifting in-memory chunks into Pthon
>>> for c in a.chunks:
...     print c, '\n'
... 
[   0    1    2 ..., 4093 4094 4095] 

[4096 4097 4098 ..., 8189 8190 8191] 

# Pointers to chunks in memory
>>> a.chunks[0].pointer
44653344L

>>> a.leftovers
44653510L
```

Lifting some of CArray internals up into Blaze. Keep the core the
same.

# Datashape

Small DSL, not Python subset!

- Inline 

```python
>>> from blaze import dshape
>>> dshape('3, 3, int32')
```

- IPython Magic

```python
In [0]: %load_ext blaze.datashape.magic
```

- Modules

```haskell
type Pixel A = 800, 600, A, A
type Foo x y = Either( (x,int32),(y, int32) )

type Stock = {
  name   : string,
  min    : int64,
  max    : int64,
  mid    : int64,
  volume : float,
  close  : float,
  open   : float,
}
```

# Types?

- Not your grandfather's type system.
- Leverage the last 20 years of research.
    - Unlike some other languages ( \*cough\* R, Matlab, Julia \*cough\* )
- Datashape is very simple as type systems go. Inference is
  a solved problem. ( sans Records )

# Constructors

A **type constructor** is used to construct new types from given ones.

Datashape types with free parameters in their constructor are called
**parameterized types**.

```
SquareMatrix T = N, N, T
```

Datashape types without free parameters in their constructor are called
**alias types**.

```
SquareIntMatrix = N, N, int32
```

# Product Types

The product operator (,) is used to construct product types. It is a type constructor of two arguments.

```haskell
a, b
```

It is also left associative:

```haskell
((a, b), c) = a, b, c
```

# Sum Types

A sum type is a type representing a collection of heterogeneously typed
values. There are four instances of sum types in Blaze’s type system:

- Variants
- Unions
- Options
- Ranges

# Types, Trees and ADTs, oh my!

Sum types represent branching possibilities of types.

Product types represent sequential combinations of types joined with
external structure.

#

![](tree.png)

#

Type            Notation
-------         ------
Unit Types      ```1```
Type Variable   ```X```
Option Types    ```1 + X```
Sum Types       ```X + Y```
Product Types   ```X • Y```
Disjoint Unions ```X + Y + ... Z```


- ```python
3, 3, int32
```

- ```
1 • 1 • 1
```

- ```
Either(X, Y), int32
```

- ```
(X + Y) • 1
```

- ```
(X • 1) + (Y • 1) 
```

- ```
Either(na, X)
```

- ```
1 + X
```

# Expressions

```
a = NDArray([1,2,3])
e = a+a
e.eval()
```

ATerm IR

```
Add(Array(39558864){dshape("3 int64")}, Array(39558864){dshape("3 int64")})
```

Numba Code Generation

```
def ufunc0(op0, op1):
    return (op0 + op1)
```

# ATerm

Human readable representation of ASTs.

It's just Python. Can often just ``eval`` into Python.

```
x
f(x,y)
[1,2,3]
```

Annotations

```python
x{p}
y{p,q}
[1,2,3]{p}
```

```python
f(
    x{dshape("5, int"), contigious},
    y{dshape("5, float"), contigious}
)
```

Pattern Matching

```python
matches("f(x,y)", "f(<term>, <term>)") # True
matches("f(1,g(2,3))", "f(1,g(<int>, <int>))") # True
matches("f(1,g(2,3))", "f(<str>,g(2,3))") # False
```

Term Rewriting

```haskell
E: DNF(Not(Or(A,B))) -> And(Not(A),Not(B))
```

# Inference

Just from the dshape annotations we can infer *a lot* just by
applying simple algorithms before we even hit execution.

Not just type information. Metadata, metacompute. Anything we can
annotate on and write down signatures for!

```
g = (A*B+C*D)**2
```

Operator Constraints
--------------------

```
(+) :: (a,b) -> (a,b) -> (a,b)
(*) :: (a,b) -> (b,c) -> (a,c)
```

Term Constraints
----------------


```
           A : (s, t)
           B : (u, v)
           C : (w, x)
           D : (y, z)

          AB : (a, b)
          CD : (c, d)
     AB + CD : (e, f)
(AB + CD)**2 : (g, h)
```

Constraint Generation
---------------------

```
t = u, a = s, b = v   in AB
x = y, c = w, d = z   in CD
a = c = e, b = d = f  in AB + CD
e = f = g = h         in (AB + CD)**2
```

#

Substitution
------------

```
a = b = c = d = e = f = g = h = s = v = w = z
t = u
x = y
```


Solution
--------

```
A : (a,t)
B : (t,a)
C : (a,x)
D : (x,a)
```


```
g = (A*B+C*D)**2
```

We now have much more knowledge about the expression.

# Layouts

![](layout.png)

#

Example of a order 4 (H_4) curve over a 2D array

```
 0    3    4    5
 1    2    7    6
14   13    8    9
15   12   11   10

 +    +---------+
 |    |         |
 +----+    +----+
           |
 +----+    +----+
 |    |         |
 +    +----+----+
```

#

Coordinate translations for different layouts.

# Hilbert Curve

```python
def rot(n, x, y, rx, ry):
    if ry == 0:
        if rx == 1:
            x = n-1 - x
            y = n-1 - y
        x, y = y, x
    return x,y

def xy2d(order, x, y):
    n = order / 2
    d = 0
    while n > 0:
        rx = 1 if (x & n) else 0
        ry = 1 if (y & n) else 0
        d += n * n * ((3 * rx) ^ ry)
        x,y = rot(n, x, y, rx, ry)
        n /= 2
    return d

```

# Z Order

```python
def mask(n):
    n &= mask1
    n = (n | (n << 8)) & 0x00FF00FF
    n = (n | (n << 4)) & 0x0F0F0F0F
    n = (n | (n << 2)) & 0x33333333
    n = (n | (n << 1)) & 0x55555555
    return n

def unmask(n):
    n &= mask2
    n = (n ^ (n >> 1)) & 0x33333333
    n = (n ^ (n >> 2)) & 0x0F0F0F0F
    n = (n ^ (n >> 4)) & 0x00FF00FF
    n = (n ^ (n >> 8)) & 0x0000FFFF
    return n

def decode(n):
    return unmask(n), unmask(n >> 1)

def encode(x, y):
    return mask(x) | (mask(y) << 1)

```

# RTS

0. Generate Graph
1. Type Inference
2. Traverse expressions in ATerm expressions.
3. Try to find a function specialized for type, layout and metadata.
       - Use numba to generate kernel ( ``ATerm -> Python AST`` )
       - Link against fast 3rd party library for specialized
         problems.
4. Load Data & Manage Memory
       - Shuffle blocks onto heap
       - Allocate temporaries as needed by data descriptor
       - Unallocate blocks
       - Query data from SQL
       - Copy data to socket ( ZeroMQ, MPI, ... ) if needed
5. Dispatch

- Future: parallel execution
- Future: heterogeneous computation backends ( GPU, cluster )

# What does this give us?

- Blazing fast math
- ... with minimal temporaries
- ... over arbitrary large data
- ... with arbitrary layout
- ![](awesome.gif)

# Long Road Ahead

![](sunrise.jpg)

# Compiling Strategy: Numba vs Cython vs PyPy

+---------------------------+---------------------------+-----------------------+
| Numba                     | Cython                    | PyPy                  |
+===========================+===========================+=======================+
| - Runtime                 | - Ahead of time           | - Runtime tracing     |
|     - Static or dynamic   |     - build step          |   JIT                 |
| - Ahead of time           |                           |                       |
|                           |                           |                       |
+---------------------------+---------------------------+-----------------------+

# Compiler IR: Numba vs Cython vs PyPy

+---------------------------+---------------------------+-----------------------+
| Numba                     | Cython                    | PyPy                  |
+===========================+===========================+=======================+
| - LLVM                    | - C/C++                   | - PyPy JIT            |
|                           |                           |                       |
+---------------------------+---------------------------+-----------------------+


# Typing: Numba vs Cython vs PyPy

+---------------------------+---------------------------+-----------------------+
| Numba                     | Cython                    | PyPy                  |
+===========================+===========================+=======================+
| - Type inferred           | - Explicit types &        | - Full Python         |
| - Single type at each     |   type inference          |   compatability       |
|   control flow point (    | - Quick fallback to       |                       |
|   like RPython)           |   objects                 |                       |
| - Variable reuse          |                           |                       |
| - Python semantics for    | - Python semantics for    |                       |
|   objects                 |   objects                 |                       |
+---------------------------+---------------------------+-----------------------+



# Demo

## Linear Regression with Gradient Descent

# Pure Python + Numpy

```python
def gradient_descent(X, Y, theta, alpha, num_iters):
    m = Y.shape[0]
    theta_x = 0.0
    theta_y = 0.0
    for i in range(num_iters):
        predict = theta_x + theta_y * X
        err_x = (predict - Y)
        err_y = (predict - Y) * X
        theta_x = theta_x - alpha * (1.0 / m) * err_x.sum()
        theta_y = theta_y - alpha * (1.0 / m) * err_y.sum()
    theta[0] = theta_x
    theta[1] = theta_y
```

# Numba

```python
from numba import jit, f8, int32, void
@jit(void(f8[:], f8[:], f8[:], f8, int32))
def gradient_descent(X, Y, theta, alpha, num_iters):
    m = Y.shape[0]
    theta_x = 0.0
    theta_y = 0.0
    for i in range(num_iters):
        err_acc_x = 0.0
        err_acc_y = 0.0
        for j in range(X.shape[0]):
            predict = theta_x + theta_y * X[j]
            err_acc_x += predict - Y[j]
            err_acc_y += (predict - Y[j]) * X[j]
        theta_x = theta_x - alpha * (1.0 / m) * err_acc_x
        theta_y = theta_y - alpha * (1.0 / m) * err_acc_y
    theta[0] = theta_x
    theta[1] = theta_y
```

# NumbaPro

```python
import numbapro
from numba import jit, f8, int32, void
@jit(void(f8[:], f8[:], f8[:], f8, int32))
def gradient_descent(X, Y, theta, alpha, num_iters):
    m = Y.shape[0]
    theta_x = 0.0
    theta_y = 0.0
    for i in range(num_iters):
        predict = theta_x + theta_y * X
        err_x = (predict - Y)
        err_y = (predict - Y) * X
        theta_x = theta_x - alpha * (1.0 / m) * err_x.sum()
        theta_y = theta_y - alpha * (1.0 / m) * err_y.sum()
    theta[0] = theta_x
    theta[1] = theta_y
```

# Dynamic Code Generation

* Numba as a code generation backend
* Used in blaze
    * Lazy expression graph ⇒ Numba Python AST ⇒ LLVM


# Thanks

## Questions?

# Get Anaconda for Numba and NumbaPro

Go to https://store.continuum.io/cshop/anaconda

- Full license for Anaconda, or
- 30 days trial, or
- Anaconda CE for opensource software only (no NumbaPro)

# Example: Mandelbrot

```python
    @autojit
    def mandel(x, y, max_iters):
        i = 0
        c = complex(x,y)
        z = 0.0j
        for i in range(max_iters):
            z = z ** 2 + c
            if (z.real ** 2 + z.imag ** 2) >= 4:
                return i

        return 255
```

# Example Mandelbrot

```python
    @autojit
    def create_fractal(min_x, max_x, min_y, max_y, image, iters):
        height = image.shape[0]
        width = image.shape[1]

        pixel_size_x = (max_x - min_x) / width
        pixel_size_y = (max_y - min_y) / height
        for x in range(width):
            real = min_x + x * pixel_size_x
            for y in range(height):
                imag = min_y + y * pixel_size_y
                color = mandel(real, imag, iters)
                image[y, x] = color

        return image
```

# Example Mandelbrot

## 1000x speedup !!!

![Mandelbrot](mandel.jpg)

# Example: Sum

## Python

```python
    @jit(f8(f8[:]))
    def sum1d(A):
        n = A.shape[0]
        s = 0.0
        for i in range(n):
            s += A[i]
        return s

```

# Example: Sum

## LLVM IR

```LLVM
"loop_body_6:8":
    ...
    %24 = getelementptr i64* %23, i32 0
    %25 = load i64* %24, !invariant.load !0
    %26 = mul i64 %19, %25
    %27 = add i64 0, %26
    %28 = getelementptr i8* %21, i64 %27
    %29 = bitcast i8* %28 to double*
    %30 = load double* %29
    %31 = fadd double %s_2, %30
    br label %"for_increment_5:4"

```

# Example: Sum

## x86 Assembly


```Assembly
    ...
    LBB0_5:
        movq	16(%rbx), %rcx
        movq	40(%rbx), %rdx
        movq	24(%rsp), %rax
        movq	(%rdx), %rdx
        imulq	%rax, %rdx
        vaddsd	(%rdx,%rcx), %xmm0, %xmm0
        incl	%eax
        movslq	%eax, %rax
        movq	%rax, 24(%rsp)
```


# Features

NumPy Arrays

```python

    # Type inference for NumPy code
    np.zeros((M, N), dtype=np.float32)

```

Python code:

    * Closures
    * Extension types
    * List comprehensions
    * etc

Inferfacing with C:

    * Structs/pointers
    * Supports ctypes
        * Future: support CFFI, C++

Dynamic:

    * Just-in-time specialization
        * Dynamic extension types
        * Dynamic callbacks
        * etc

# Future

* Integration with (and extension of) C++, Cython
* Task parallelism
* OpenCL
* Just-in-time specializing extension types
    * Data-Polymorphic attributes
    * Specialize methods on attribute and parameter types


# GPU Support

numbapro gpu stuff

prange
------
* Synonymous with **cython.parallel.prange**
* Parallel OpenMP-like loops
* Automatic variable privatization

<!--- array expressions? -->

% Numba:
  An Array-Oriented Just-in-Time Specializing Compiler for Python
% Siu Kwan Lam & Mark Florisson
% January 9, 2013

# Why Python?

- Rapid development cycle
- Powerful libraries
- Allows interfacing with native code
    - Excellent for glue
- ... but, slow!
    - especially for computation-heavy code: numerical algorithms

# Why Numba?

## Breaking the speed barrier

- Provides **JIT** for **array-oriented programming** in CPython
- Numerical loops
- Low-level C-like code in pure Python
    - pointers, structs, callbacks

# Why Numba?

## Work with existing tools

- Works with existing CPython extensions
- Goal: Integration with scientific software stack
    - NumPy/SciPy/Blaze
        - indexing and slicing
        - array expressions
        - math
    - C, C++, Fortran, Cython, CFFI, Julia?
    
# Why Numba?

## Minimum effort for Maximum hardware utilization

- High level tools for domains experts to exploit modern hardware
    - multicore CPU
    - manycore GPU
- Easily take advantage of parallelism and accelerators

<!--- Add graphic for array-oriented programming -->


# Software Stack

![Software Stack](software_stack.jpg)

# @jit, @autojit

- Instead of JIT-ing all Python code, we target the hotspot
- Use decorators to mark functions or classes for *just-in-time* compilation

# Static runtime compilation

```python
@jit(double(double[:, :]))
def func(array):
    ...
```

# Dynamic just-in-time specialization

```python
@autojit
def func(array):
    ...
```

# JIT a Class

```python
@jit
class Shrubbery(object):
    @void(int_, int_)
    def __init__(self, w, h):
        # All instance attributes must be defined in the initializer
        self.width = w
        self.height = h
        # Types can be explicitly specified through casts
        self.some_attr = double(1.0)

    @int_()
    def area(self):
        return self.width * self.height

    @void()
    def describe(self):
        print("This shrubbery is ", self.width,
              "by", self.height, "cubits.")

```


Numba Documentation
===================

The numba documentation is split over two repositories:

    The user and developer documentation:

        https://github.com/numba/numba (the 'docs' directory)

    The webpage, numba.pydata.org:

        https://github.com/numba/numba-webpage

User and Developer Documentation
================================
The documentation is under the 'docs' directory of the numba repo (this directory).

To build the documentation, you need the basicstrap theme and sphinxjp.themecore:

    $ pip install sphinxjp.themes.basicstrap
    $ pip install sphinxjp.themecore

You can edit the source files under docs/source/, after which you can build and
check the documentation:

    $ make html
    $ open _build/html/index.html

This documentation can be uploaded to http://numba.pydata.org/numba-doc/dev/index.html
using the gh-pages.py script under docs/:

    $ python gh-pages.py version # version can be 'dev' or '0.8' etc

then verify the repository under the 'gh-pages' directory and use 'git push'.

Webpage
=======
The numba webpage on numba.pydata.org can be fetched from here: https://github.com/numba/numba-webpage

After pushing documentation to a new version, you will want to update the website. Some notable files:

    index.rst       # Update main page
    _templates/sidebar_versions.html    # Update sidebar links
    doc.rst         # Update after adding a new version for numba docs
    download.rst    # Updata after uploading new numba version to pypi

After updating run:

    $ make html

and check out _build/html/index.html. To push to numba.pydata.org:

    $ python _scripts/gh-pages.py

then verify the repository under the 'gh-pages' directory.
Make sure the CNAME file is present and contains a single line 'numba.pydata.org'.
Finally, use 'git push' to update the website.




Files Organization
------------------

Files are organized in a specific manner to differentiate between version specific files and common files.  The mechanism is transparent to the user of the asdl module (in this directory).

Version specific files are placed under "py$major_$minor", where $major and $minor represents the major and minor version tuple of Python; for example, "py2_7" is for Python2.7.

Common files are placed inside the "common" directory


File Lookup Order
-----------------

Version-specific files are searched first.  If they don't exist, the common ones are used.


Usage
-----

	import schema
	sch = schema.load("Python.asdl")
	sch.verify(some_ast)

Testing
-------

Run tests in the current directory:

$ python -m unittest discover -vft tests

The __generate_rng.py file will re-create the _rng_generated.py file but is otherwise not necessary.

Tests in this directory are excluded by the test runner. It contains
issues that are broken and need to be fixed (and moved out of this
directory).
Numba
=====

Numba is an Open Source NumPy-aware optimizing compiler for Python
sponsored by Continuum Analytics, Inc.  It uses the
remarkable LLVM compiler infrastructure to compile Python syntax to
machine code.

It is aware of NumPy arrays as typed memory regions and so can speed-up
code using NumPy arrays.  Other, less well-typed code will be translated
to Python C-API calls effectively removing the "interpreter" but not removing
the dynamic indirection.

Numba is also not a tracing jit.  It *compiles* your code before it gets
run either using run-time type information or type information you provide
in the decorator.

Numba is a mechanism for producing machine code from Python syntax and typed
data structures such as those that exist in NumPy.

Dependencies
============

  * LLVM 3.3
  * llvmpy (from llvmpy/llvmpy fork)
  * numpy (version 1.6 or higher)
  * argparse (for pycc in python2.6)

Installing
=================

The easiest way to install numba and get updates is by using the Anaconda
Distribution: https://store.continuum.io/cshop/anaconda/

```bash
    $ conda install numba
```

If you wanted to compile Numba from source,
it is recommended to use conda environment to maintain multiple isolated
development environments.  To create a new environment for Numba development:

```bash
    $ conda create -p ~/dev/mynumba python numpy llvmpy
```

To select the installed version, append "=VERSION" to the package name,
where, "VERSION" is the version number.  For example:

```bash
    $ conda create -p ~/dev/mynumba python=2.7 numpy=1.6 llvmpy
```

to use Python 2.7 and Numpy 1.6.


Custom Python Environments
==========================

If you're not using anaconda, you will need LLVM with RTTI enabled:

* Compile LLVM 3.3

See https://github.com/llvmpy/llvmpy for the most up-to-date instructions.

```bash
    $ wget http://llvm.org/releases/3.3/llvm-3.3.src.tar.gz
    $ tar zxvf llvm-3.3.src.tar.gz
    $ cd llvm-3.3.src
    $ ./configure --enable-optimized --prefix=LLVM_BUILD_DIR
    $ # It is recommended to separate the custom build from the default system
    $ # package.
    $ # Be sure your compiler architecture is same as version of Python you will use
    $ #  e.g. -arch i386 or -arch x86_64.  It might be best to be explicit about this.
    $ REQUIRES_RTTI=1 make install
```

* Install llvmpy

```bash
    $ git clone https://github.com/llvmpy/llvmpy
    $ cd llvmpy
    $ LLVM_CONFIG_PATH=LLVM_BUILD_DIR/bin/llvm-config python setup.py install
```

* Installing Numba

```bash
    $ git clone https://github.com/numba/numba.git
    $ cd numba
    $ pip install -r requirements.txt
    $ python setup.py build_ext --inplace
    $ python setup.py install
```

or simply

```bash
    $ pip install numba
```

**NOTE:** Make sure you install *distribute* instead of setuptools. Using setuptools
          may mean that source files do not get cythonized and may result in an
          error during installation.

Documentation
=============

http://numba.pydata.org/numba-doc/dev/index.html

Mailing Lists
=============

Join the numba mailing list numba-users@continuum.io :

https://groups.google.com/a/continuum.io/d/forum/numba-users

Some old archives are at: http://librelist.com/browser/numba/

Website
=======

See if our sponsor can help you (which can help this project): http://www.continuum.io

http://numba.pydata.org

Continuous Integration
======================

https://travis-ci.org/numba/numba

